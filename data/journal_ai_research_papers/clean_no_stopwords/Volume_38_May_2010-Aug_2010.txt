Journal Artificial Intelligence Research 38 (2010) 535-568

Submitted 05/10; published 08/10

Logical Foundations RDF(S) Datatypes
Jos de Bruijn
Stijn Heymans

bruijn@kr.tuwien.ac.at
heymans@kr.tuwien.ac.at

Vienna University Technology
Favoritenstrae 9-11, A-1040 Vienna, Austria

Abstract
Resource Description Framework (RDF) Semantic Web standard provides
data language, simply called RDF, well lightweight ontology language, called
RDF Schema. investigate embeddings RDF logic show standard logic
programming description logic technology used reasoning RDF.
subsequently consider extensions RDF datatype support, considering entailment,
defined RDF semantics specification, D* entailment, semantic weakening
entailment, introduced ter Horst. use embeddings properties logics
establish novel upper bounds complexity deciding entailment. subsequently
establish two novel lower bounds, establishing RDFS entailment PTime-complete
simple-D entailment coNP-hard, considering arbitrary datatypes,
size entailing graph. results indicate RDFS may lightweight
one may expect.

1. Introduction
Resource Description Framework (RDF) (Klyne & Carroll, 2004), together
vocabulary description language RDF Schema (RDFS) (Brickley & Guha, 2004), constitutes
basic language Semantic Web. Statements RDF triples form hs, p, oi.
Sets triples called RDF graphs: intuitively, triple viewed edge
node node label p. Here, s, o, p constant symbols uniform resource
identifiers (URIs) literals (e.g., strings) anonymous identifiers, called blank nodes.
Consider, example, graphs = {ho, rdf:type, Ai, hA, rdfs:subClassOf, Bi}
E = {ho, rdf:type, Bi}. Hayes (2004) defines notions RDF RDFS entailment.
that, compared RDF entailment, RDFS entailment gives additional meaning
rdfs:subClassOf statements: RDFS-entails E, RDF-entail E.
RDF semantics specification (Hayes, 2004) defines four increasingly expressive normative entailment relations RDF graphs, namely simple, RDF, RDFS,
entailment, latter extends RDFS entailment support datatypes (e.g.,
strings integers). Furthermore, defines extensional RDFS (eRDFS) entailment
possible extension RDFS entailment line description logic-based
languages OWL DL (Patel-Schneider, Hayes, & Horrocks, 2004) OWL 2 DL
(Motik, Patel-Schneider, & Parsia, 2009b). Intuitively, difference RDFS
eRDFS entailment regimes that, latter, whenever ontological relation (e.g.,
subclass property domain) implicitly holds interpretation, corresponding RDF
statement (rdfs:subClassOf, rdfs:domain, respectively) must true, whereas
c
2010
AI Access Foundation. rights reserved.

fide Bruijn & Heymans

always case RDFS entailment regime. following example illustrates
difference.
Example 1. Let graph
{hmother, rdfs:subPropertyOf, parenti, hparent, rdfs:domain, P ersoni}
says P erson domain parent, property mother subproperty parent. Using eRDFS entailment conclude P erson
domain mother:
|=erdfs hmother, rdfs:domain, P ersoni
since must case subject mother triple type P erson; thus,
P erson implicitly domain mother. cannot draw conclusion using
RDFS entailment; RDFS, explicitly asserted domain constraints derived.
also consider D* entailment (ter Horst, 2005), semantic weakening entailment purpose efficient computation consequences. D*
entailment extends RDFS entailment, expensive terms computational
complexity.
several investigations formal properties RDF semantics
(Gutierrez, Hurtado, & Mendelzon, 2004; Gutierrez, Hurtado, Mendelzon, & Perez, 2010;
de Bruijn, Franconi, & Tessaris, 2005; ter Horst, 2005): Gutierrez et al. (2004, 2010) reconstruct semantics graph database perspective, de Bruijn et al. (2005)
reconstruct semantics logical language perspective. investigation
RDF semantics ter Horst (2005) stays close RDF specification. Additionally,
ter Horst shows entailment rules computing RDFS entailment presented
original specification (Hayes, 2004) complete respect RDFS semantics.
reconstructions led number complexity results RDF entailment.
particular, simple, RDF, RDFS entailment NP-complete combined size
graphs. high complexity due presence blank nodes (essentially existentially
quantified variables): entailed graph known ground, respective problems
turn decidable polynomial time. bounds shown
tight. show Section 5, bound tight RDFS entailment,
simple RDF entailment, decided logarithmic space.
investigate relationship RDF logic embed various RDF
entailment regimes F-Logic (Kifer, Lausen, & Wu, 1995), syntactic extension
first-order logic (FOL) object oriented modeling constructs. F-Logic constructs
explicitly specify attributes, well generalization/specialization instantiation
relationships. Like RDFS, syntax F-Logic seemingly higher-order features,
namely, identifier used class, instance, attribute. However,
semantics F-Logic strictly first-order (Kifer et al., 1995). turns
attribute value construct F-Logic exactly equivalent triple construct RDF,
typing (class membership) construct F-Logic close spirit one
RDF.
addition, consider embedding large subset extensional RDFS FOL
tractable description logic language DL-LiteR (Calvanese, Giacomo, Lembo, Lenzerini,
536

fiLogical Foundations RDF(S) Datatypes

& Rosati, 2007), thereby showing that, certain restrictions, extensional RDFS
seen standard first-order knowledge representation language.
contributions paper summarized follows.
1. define embeddings simple, RDF, RDFS, extensional RDFS F-Logic,
show simple, RDF, RDFS entailment decided using standard logic
programming techniques, embeddings Horn fragment F-Logic.
2. define alternative, direct embedding extensional RDFS Horn fragment F-Logic fragment RDF graphs, namely RDFS
vocabulary used standard way. subsequently exploit earlier results
relationship F-Logic statements description logic statements
(de Bruijn & Heymans, 2008) show extensional RDFS reasoning ground
RDF graphs reduced reasoning tractable description logic DL-LiteR
(Calvanese et al., 2007).
3. extend embeddings mentioned 1. support datatypes, considering
D* entailment. embeddings extensions simple, RDF,
RDFS entailment D* datatype support essentially Horn fragment
F-Logic. extensions simple, RDF, RDFS datatype support
embedded Horn fragment F-Logic suitably restricting datatypes
may considered.
4. analyze complexity deciding mentioned entailment relations.
mentioned embeddings obtain number novel complexity upper bounds, namely,
simple RDF entailment, well extensions datatypes (under suitable
restrictions), LogSpace size entailing graph large fragment
extensional RDFS entailment NP combined size graphs
PTime size entailing graph. also establish novel PTime lower bound
RDFS entailment novel coNP lower bound simple entailment extended
datatype support, considering arbitrary datatypes, size
entailing graph. See Table 2 page 553 overview complexity results
RDF.
structure remainder paper follows. Section 2 review logics
consideration, namely F-Logic DL-LiteR . Section 3 review RDF(S)
semantics, define embeddings F-Logic FOL, show faithfulness embeddings,
demonstrate relationship DL-LiteR . Section 4 consider extensions
RDF entailment regimes datatype support based D* entailment
embeddings extensions logic. Section 5 extensively investigate
complexity various RDF entailment regimes. conclude paper outline
future work Section 6.
paper extends paper published International Semantic Web Conference
(de Bruijn & Heymans, 2007) embeddings D* entailment regimes
novel lower bounds complexity deciding RDFS, D* , entailment.
537

fide Bruijn & Heymans

reasons legibility, definitions various RDF-related notions interpretation may found Appendix A, embeddings RDF entailment regimes may
found Appendix B, proofs Sections 3 4 may found Appendix C.

2. Preliminaries
section review F-Logic DL-LiteR .
2.1 Frame Logic
consider Frame Logic (F-Logic) defined Kifer, Lausen, Wu (1995). simplify
matters, constructs necessary embedding RDF,
consider function symbols, parameterized methods, functional (single-valued) methods,
inheritable methods, compound molecules, following de Bruijn Heymans (2008).
signature F-language L form = hC, Pi C P disjoint sets
constant predicate symbols; predicate symbol associated arity n 0. Let
V set variable symbols. Terms atomic formulas constructed usual: x V
c C terms >, , p(t1 , . . . , tn ), t1 = t2 atomic formulas, p P
n-ary predicate symbol, t1 , . . . , tn terms.
molecule F-Logic one following statements: (i) is-a assertion
form t1 : t2 , states individual t1 type t2 , (ii) data molecule (called
method Kifer et al., 1995) form t1 [t2 t3 ], t1 , t2 , t3 terms,
states individual t1 attribute t2 value t3 . F-Logic molecule ground
contain variables.
Formulas F-language L either atomic formulas, molecules, compound formulas constructed usual way atomic formulas, molecules,
logical connectives , , , , quantifiers , auxiliary symbols ( ).
denote universal closure, i.e., universal quantification every variable free
occurrence formula, ().
theory set formulas. theory formula called equality-free equality
symbol = appear it.
F-Logic Horn formulas form ()B1 . . . Bn H, B1 ,. . . , Bn , H
atomic formulas molecules. F-Logic Datalog formulas F-Logic Horn formulas
every variable H occurs equality-free Bi . latter condition called
safeness.
F-structure tuple = hU, U , IC , , IP i, U non-empty set U
binary relation U . constant symbol c C interpreted element domain:
IC (c) U . n-ary predicate symbol p P interpreted relation domain
U : IP (p) U n . associates binary relation U k U : (k) U U .
Variable assignments B defined usual way.
Given F-structure I, variable assignment B, term L, tI,B defined as:
I,B
x = xB variable symbol x tI,B = IC (t) C.
Satisfaction atomic formulas molecules I, given variable assignment B,
denoted (I, B) |=f , defined
(I, B) |=f >,
(I, B)6|=f ,
538

fiLogical Foundations RDF(S) Datatypes

I,B
(I, B) |=f p(t1 , . . . , tn ) iff (tI,B
1 , . . . , tn ) IP (p),
I,B
I,B
(I, B) |=f t1 = t2 iff t1 = t2 ,
(I, B) |=f t1 : t2 iff tI,B
U tI,B
1
2 ,
I,B I,B
(I, B) |=f t1 [t2 t3 ] iff ht1 , t3 (tI,B
2 ).
extends arbitrary formulas usual way. F-structure satisfies formula
, denoted |=f , (I, B) |=f every variable assignment B. satisfies theory L
satisfies formulas ; case, called model . theory F-entails
formula L, denoted |=f , iff every model , |=f .
Herbrand F-structure F-structure = hU, U , IC , , IP U
set constants every constant symbol c C, IC (c) = c. abuse notation,
Herbrand structures use denote structure set ground atomic
formulas satisfied structure. Finally, Herbrand F-structure minimal Herbrand
model theory model Herbrand F-structure I0 model
I0 I.






Classical first-order logic (FOL) F-Logic without molecules. Contextual first-order logic
classical FOL C P required disjoint, predicate symbols
associated arity, every structure = hU, U , IC , , IP i, IP assigns
relation IiP (p) U n every p P, every nonnegative integer i. denote satisfaction
entailment classical contextual first-order logic using symbols |= |=c ,
respectively. Contextual FOL sometimes also referred FOL punning.
F-Logic straightforwardly embedded FOL, shown (Kifer et al., 1995,
Theorem 18.1).
Proposition 1. Let F-Logic theory formula contain
binary ternary predicate symbols isa data, respectively, let 0 0
FOL theory formula obtained replacing every is-a molecule : b
isa(a, b) every data molecule a[b c] data(a, b, c). Then,
|=f iff 0 |= 0
2.2 DL-LiteR
DL-LiteR (Calvanese et al., 2007) language consists pairwise disjoint sets concept
(NC ), role (NR ), individual (NI ) identifiers. Concepts roles DL-LiteR
defined follows:
Cl | R
Cr | R | | R
R, R0 P | P
NC P NR , Cl Cr left- (resp., right-)hand side concepts, R R0
roles.
DL-LiteR knowledge base K = (T , A) consists TBox , set inclusion
axioms forms
Cl v Cr
R v R0
539

fide Bruijn & Heymans

DL syntax FOL syntax
(A, X)
A(X)
(P, X, )
P (X, )

(P , X, ) P (Y, X)
(R, X)
y((R, X, y))
(A, X)
(A, X)
(R, X)
y((R, X, y))
new variable

DL syntax
(Cl v Cr )
(R1 v R2 )
(A(a))
(P (a1 , a2 ))

FOL syntax
x((Cl , x) (Cr , x))
x, y((R1 , x, y) (R2 , x, y))
A(a)
P (a1 , a2 )

Table 1: Mapping DL-LiteR FOL
ABox A, set concept role membership assertions forms
A(a)

P (a1 , a2 )

a, a1 , a2 NI .
define semantics DL-LiteR translation FOL, form
mapping function , defined Table 1.1 mapping extends naturally sets
axioms assertions.
Given DL-LiteR knowledge base K = (T , A), FOL equivalent K FOL
theory = (K) = (T ) (A).
Contextual DL-LiteR like DL-LiteR , except sets concept (NC ), role (NR ),
individual (NI ) identifiers required disjoint. semantics contextual
DL-LiteR knowledge base K = (T , A) given mapping (K),
yields contextual FOL theory. Note contextual DL-LiteR essentially subset
QL profile OWL 2 (Motik, Grau, Horrocks, Wu, Fokoue, & Lutz, 2009a).

3. RDF RDF Schema
first review definitions RDF syntax semantics. proceed
embedding graphs axiomatization entailment regimes F-Logic,
finally embedding extensional RDFS FOL DL-LiteR .
3.1 RDF(S) Syntax Semantics
proceed review definitions RDF syntax (Klyne & Carroll, 2004)
semantics (Hayes, 2004).
vocabulary V = hC, PL, Li consists set C RDF URI references (simply referred
URIs), set PL plain literals (i.e., Unicode character strings optional
language tag), set L typed literals (i.e., pairs (s, u) Unicode string
URI u, denoting datatype); see (Klyne & Carroll, 2004, Sections 6.4, 6.5, 6.6)
details specific form symbols. Note C, PL, L mutually
disjoint. symbols V collectively referred names.
Let B set blank nodes disjoint set names V . Terms
names blank nodes. generalized RDF graph set generalized triples hs, p, oi
1. Borgida (1996) discusses relationship description logics first-order logic detail.

540

fiLogical Foundations RDF(S) Datatypes

subject, predicate, object s, p, C PL L B. normal RDF graph set
normal triples hs, p, oi, C B, p C, C PL L B.2 ground triple
triple contain blank nodes. ground generalized, respectively normal
RDF graph set ground generalized, respectively normal triples. bl(hs, p, oi) B
(resp., bl(S) B) denote set blank nodes triple hs, p, oi (resp., graph S).
remainder, whenever speaking triples RDF graphs, mean generalized
triples, respectively generalized RDF graphs, unless stated otherwise.
interpretation tuple = hIR, IP, LV, IS, IL, IEXTi, IR non-empty set,
called domain, IP set properties, LV IR set literal values PL LV,
mapping : C IR IP, IL mapping IL : L IR, IEXT extension
function IEXT : IP 2(IRIR) .
Given interpretation I, subset blank nodes B 0 B, mapping : B 0
IR, used interpret blank nodes, given term define tI,A as:
C, tI,A = IS(t),
L, tI,A = IL(t),

PL, tI,A = t,
B 0 , tI,A = A(t).

interpretation satisfies triple hs, p, oi respect mapping : B 0 IR,
bl(hs, p, oi) B 0 , denoted (I, A) |= hs, p, oi, pI,A IP hsI,A , oI,A IEXT(pI,A ).
satisfies graph respect mapping : bl(S) IR, denoted (I, A) |= S,
(I, A) |= hs, p, oi every hs, p, oi S.
interpretation satisfies RDF graph S, denoted |= S, (I, A) |=
mapping : bl(S) IR; case, model S. interpretation sinterpretation (simple interpretation).
notions rdf -, rdfs-, erdfs-interpretation defined additional conditions s-interpretation. example, s-interpretation rdf -interpretation
every object k, k IP iff hk, IS(rdf:Property)i IEXT (IS(rdf:type)) satisfies
triple hrdf:nil, rdf:type, rdf:Listi. Triples required satisfied every
x-interpretation called x-axiomatic triples, x {rdf, rdfs, erdfs} simply axiomatic
triples entailment regime clear context. precise definitions rdf -,
rdfs-, erdfs-interpretation found Appendix A.
Entailment Satisfiability Given vocabulary V entailment regime x
{s, rdf, rdfs, erdfs}, generalized (resp., normal) RDF graph x-entails generalized (resp.,
normal) RDF graph E, denoted |=x E, every x-interpretation V model
also model E.
Given entailment regime x {s, rdf, rdfs, erdfs}, generalized (resp., normal) RDF
graph x-satisfiable model x-interpretation; otherwise xunsatisfiable. following observations made satisfiability various
entailment regimes; observations concerning normal RDF graphs due Hayes
(2004).
Proposition 2.
1. Every generalized every normal RDF graph s-satisfiable.
2. Every normal RDF graph rdf-satisfiable.
2. Normal RDF graphs correspond RDF graphs defined Hayes (2004). contrast normal RDF,
generalized RDF graphs allow blank nodes literals predicate, literals subject positions.

541

fide Bruijn & Heymans

3. generalized RDF graph rdf-unsatisfiable.
4. normal (and generalized) RDF graph rdfs- erdfs-unsatisfiable.
3.2 Embedding RDF Logic
translate graph conjunction data molecules, URIs literals
constant symbols blank nodes existentially quantified variables. axiomatize
entailment regimes using sets formulas independent graphs.
remainder assume RDF graphs finite.
Given vocabulary V = hC, PL, Li, F-language L conforms V
signature form = hC 0 , Pi, C 0 C PL L.3
Definition 1. Let V vocabulary, let RDF graph V , let bl(S) = {b1 , . . . , bn }
set blank nodes appearing S, let hs, p, oi triple S, let L
F-language conforms V . Then,
tr(hs, p, oi) = s[p o]
^

tr(S) = b1 , . . . , bn
{tr(hs, p, oi) | hs, p, oi S}
formulas L.
axiomatizations entailment regimes theories x , x {s, rdf, rdfs,
erdfs}, defined Appendix B.
F-Logic formula prenex normal form existential quantifiers,
sk() denotes Skolemization , i.e., every existentially quantified variable replaced
globally unique new constant symbol. extends theories natural way.
Proposition 3. Let RDF graph vocabulary V let x {s, rdf, rdfs}
entailment regime. Then, sk(tr(S)) x equivalently rewritten set F-Logic
Horn formulas.
erdfs cannot equivalently rewritten set Horn formulas,
use universal quantification antecedents implications erdfs .
show faithfulness embedding.
Theorem 1. Let E RDF graphs vocabulary V , let x {s, rdf, rdfs, erdfs}
entailment regime. Then,
|=x E
x-satisfiable

iff

tr(S) x |=f tr(E)

iff

tr(S) x model.

following corollary follows immediately Theorem 1 classical results
Skolemization (see, e.g., Fitting, 1996).
Corollary 1. Let E RDF graphs vocabulary V , let x {s, rdf, rdfs,
erdfs} entailment regime. Then,
|=x E sk(tr(S)) x |=f tr(E).
3. Even though typed literals pairs RDF, treat simply constant symbols embedding.

542

fiLogical Foundations RDF(S) Datatypes

Observe rdf , rdf , erdf infinite due infinite set RDF axiomatic
triples. However, checking RDF entailment need finite subset x . Given
RDF graph S, let xS obtained x removing formulas originating
axiomatic triples involving container membership properties (i.e., rdf: 1, rdf: 2, . . . )
appearing S, exception axiomatic triples involving rdf: 1.
Proposition 4. Let E RDF graphs let x {s, rdf, rdfs, erdfs} entailment
regime. Then,
|=x E sk(tr(S)) xSE |=f tr(E).
Proposition 3 sk(tr(S)) , tr(S)sk rdf , sk(tr(S)) rdfs
equivalent sets Horn formulas. Therefore, Proposition 4 implies simple, RDF,
RDFS entailment computed using reasoners compute ground entailment
F-Logic Horn theories, FLORA-2 (Yang, Kifer, & Zhao, 2003). Notice tr(E)
seen boolean conjunctive query (i.e., yes/no query), existentially
quantified variables tr(E) non-distinguished variables.
3.3 Direct Embedding Extensional RDFS
consider alternative, direct embedding extensional RDFS entailment
regime. embedding, rather axiomatizing entailment regime, embeds ontological statements, e.g., rdfs:subClassOf statements, directly formulas.
first define notion standard use RDF(S) vocabulary, intuitively
corresponds using vocabulary locations change semantics
RDF(S) ontology vocabulary (e.g., hrdf:type, rdfs:subPropertyOf, ai).
Definition 2. Let RDF graph. Then, standard use RDF(S)
vocabulary
rdf:type, rdfs:subClassOf, rdfs:domain, rdfs:range, rdfs:subPropertyOf
appear subject object positions triple
rdfs:ContainerMembershipProperty, rdfs:Resource, rdfs:Class, rdfs:Datatype,
rdf:Property appear object positions rdf:type-triples S.
ready define direct embedding trerdfs extensional RDFS entailment regime graphs standard use RDFS vocabulary. trerdfs deals
important part RDF(S) vocabulary, axiomatization eRDFS semantics
remainder RDF(S) vocabulary may found Appendix B, form
theory erdfs-V , V vocabulary.
543

fide Bruijn & Heymans

Definition 3. Let hs, p, oi RDF triple. Then,
trerdfs (hs, type, Datatypei) =
=
Propertyi)
trerdfs (hs, type, oi) =
trerdfs (hs, subClassOf, oi) =
trerdfs (hs, subPropertyOf, oi) =
trerdfs (hs, domain, oi) =
trerdfs (hs, range, oi) =
trerdfs (hs, p, oi) =

trerdfs (hs, type, ContainerMembership-

: Datatype x(x : x : Literal),
: ContainerMembershipProperty
x, y(x[s y] x[member y]),
: o,
x(x : x : o),
x, y(x[s y] x[o y]),
x, y(x[s y] x : o),
x, y(x[s y] : o),
s[p o], otherwise.

Let RDF graph let bl(S) = {b1 , . . . , bn } set blank nodes S. Then,
^
trerdfs (S) = { b1 , . . . , bn ( {trerdfs (hs, p, oi) | hs, p, oi S})}
say term occurs property position occurs predicate
triple, subject object rdfs:subPropertyOf triple, subject
rdfs:domain rdfs:range triple, graph contains ht, rdf:type, rdf:Propertyi
ht, rdf:type, ContainerMembershipPropertyi. term occurs class position occurs subject object rdfs:subClassOf triple, object rdfs:domain,
rdfs:range, rdf:type triple, subject triple ht, rdf:type, rdfs:Classi,
subject triple ht, rdf:type, rdfs:Datatypei.
Let RDF graph standard use RDF(S) vocabulary. property
(resp., class) vocabulary consists names appearing property (resp., class)
positions RDF(S) axiomatic triples standard use RDF(S)
vocabulary.
Given two RDF graphs E standard use RDF(S) vocabulary,
write E E property, resp. class vocabularies E subsets property, resp.
class vocabularies S, blank nodes class property positions E,4
rdfs:Resource, rdfs:Class, rdf:Property appear E.
Theorem 2. Let E RDF graphs standard use RDFS vocabulary
E E S. Then,
|=erdfs E iff trerdfs (S) erdfs-V |=f trerdfs (E)
define erdfs-V
analogously erdfs

, i.e., contain statements concerning
container membership properties appearing graph S, exception rdf: 1.
following proposition follows argument analogous proof Property 4.
Proposition 5. Let E RDF graphs standard use RDFS vocabulary
E E S. Then,
erdfs
|=erdfs E iff sk(trerdfs (S)) erdfs-V
(E).
SE |=f tr

4. restriction use blank nodes entailed graph mentioned extended
abstract paper (de Bruijn & Heymans, 2007). error.

544

fiLogical Foundations RDF(S) Datatypes

whenever E contain terms rdfs:subClassOf, rdfs:subPropertyOf, rdfs:domain, rdfs:range, trerdfs (E) conjunction atomic molecules
prefixed existential quantifiers (i.e., conjunctive query).
sk(trerdfs (S)) erdfs-V
SE finite set Horn formulas. Therefore,
graphs satisfy mentioned conditions, query answering techniques used F-Logic
reasoners FLORA-2 (Yang et al., 2003) used checking extensional RDFS
entailment.
3.4 Embedding Extensional RDFS First-Order Logic
consider embedding extensional RDFS entailment first-order logic (FOL),
based direct embedding extensional RDFS F-Logic defined above.
say F-Logic theory translatable contextual FOL contain
unary binary predicates every molecule form t1 [t2 t3 ] t1 : t2 holds
t2 constant symbol. F O() contextual FOL theory obtained replacing:
every data molecule t1 [t2 t3 ] atomic formula t2 (t1 , t3 )
every is-a molecule t1 : t2 atomic formula t2 (t1 ).
following proposition follows immediately earlier result (de Bruijn & Heymans,
2008, Theorem 3.2).
Proposition 6. Let , respectively , equality-free F-Logic theory, respectively formula, translatable contextual FOL. Then,
|=f iff F O() |=c F O().
say RDF graph non-higher-order graph contain blank
nodes class property positions, standard use RDFS vocabulary.
Observe non-higher-order RDF graph, trerdfs (S) erdfs-V translatable
contextual FOL. Notice also every ground RDF graph standard use
RDFS vocabulary non-higher-order RDF graph.
Theorem 3. Let E non-higher-order RDF graphs E E S. Then,
|=erdfs E iff F O(trerdfs (S) erdfs-V ) |=c F O(trerdfs (E)).
Proof. Follows immediately Theorem 2, fact F O(trerdfs (S))
F O(trerdfs (E)) contain equality symbol, Proposition 6.
Concerning relationship DL-LiteR , make following observation.
Proposition 7. Let ground non-higher-order graph.5 Then, F O(trerdfs (S)erdfs-V )
equivalently rewritten FOL equivalent = (K) contextual DL-LiteR
knowledge base K.
Analogous Proposition 5, one may discard axiomatic triples concerning container
membership properties used, thus one needs reason finite
knowledge base.
5. Note that, considering variant DL-LiteR allows existentially quantified variables
ABox also allowed OWL DL restriction could relaxed non-ground non-higherorder RDF graph.

545

fide Bruijn & Heymans

4. Extensions Datatypes
entailment regimes dealt previous section consider many
useful datatypes (e.g., strings, integers). fact, rdf:XMLLiteral datatype
considered. RDF semantics specification (Hayes, 2004) defines notion
entailment (datatype entailment), extends RDFS entailment support
datatypes. Ter Horst (2005) defines notion D* entailment, also extension
RDFS entailment, semantically weaker entailment. first review D*
entailment, review entailment. semantics originally defined
extensions RDFS entailment. However, one might extend entailment regimes
considered datatype support. Therefore, consider extensions simple, RDF,
RDFS, extensional RDFS entailment kinds datatype semantics. first
review datatype semantics, present embeddings semantics
F-Logic. Finally, discuss notion normalization may used remove equality
statements embeddings speed processing.
4.1 Extension RDF Entailment Regimes Datatypes
Datatypes define sets concrete data values (e.g., strings integers), along
lexical representations. datatype tuple = hLd , V , L2V consisting
lexical space Ld , set character strings (e.g., 0, 1, 01, . . . ,
case integer datatype),
value space V , set values (e.g., numbers 0, 1, 2, . . . , case
integer datatype),
lexical-to-value mapping L2V , mapping lexical space
value space (e.g., {0 7 0, 1 7 1, 01 7 1, . . .}, integer datatype).
simple datatype map partial mapping URIs datatypes. simple datatype
map datatype map D(rdf:XMLLiteral) = xml xml built-in XML
literal datatype defined RDF specification (Klyne & Carroll, 2004). dom(D)
ran(D) denote domain range D, respectively.
Given simple datatype map D, call typed literal (s, u) L well-typed u
dom(D) LD(u) ; (s, u) ill-typed u dom(D)
/ LD(u) .
review notions D* entailment. Similar previous section,
definitions D* - D-interpretations found Appendix A.
D* entailment Given simple datatype map D, RDF graph s-D* entails RDF
graph E, denoted |=s-D* E, every s-D* -interpretation model model
E.
Given datatype map D, RDF graph x-D*-entails RDF graph E, denoted
|=x-D* E, every x-D* -interpretation model model E, x
{rdf, rdfs, erdfs}.
Notice dom(D) = {rdf:XMLLiteral} x {rdf, rdfs, erdfs}, x-D* entailment corresponds x-entailment, exception considering rdf -D* entailment, triple hrdf:XMLLiteral, rdf:type, rdfs:Datatypei additionally entailed.
addition, dom(D) = , s-D* -entailment corresponds s-entailment.
546

fiLogical Foundations RDF(S) Datatypes

following example shows equality may introduced D* semantics.
Example 2. Consider datatype map contains XML schema string datatype
(Peterson, Gao, Malhotra, Sperberg-McQueen, & Thompson, 2009). Certain equalities hold
plain literals without language tags typed literals datatype, set
plain literals without language tags corresponds value space string datatype.
So, equalities = (a, string) xxx = (xxx, string) necessarily hold.
Similar equalities datatypes. example, datatype map contains
integer decimal, equalities (1, integer) = (1, decimal)
(1, decimal) = (1.0, decimal) necessarily hold.
entailment Given simple datatype map D, RDF graph s-D-entails RDF
graph E, denoted |=s-D E, every s-D-interpretation model model
E.
Given datatype map D, RDF graph x-D-entails RDF graph E, denoted
|=x-D E, every x-D-interpretation model model E, x
{rdf, rdfs, erdfs}. RDF graph x-D-entails RDF graph E, denoted |=x-D E,
every x-D-interpretation model also model E.
two main differences D* entailment entailment: (i) entailment allows easy extension towards languages express equality
URIs denoting datatypes; whenever two URIs denote datatype, typed literals
two URIs datatypes interpreted way (see Example 3); (ii)
entailment directly links class extension datatype value space
datatype. latter complicates evaluation entailment somewhat, likely
main motivation introduction D* entailment. complication becomes clear
declaring blank nodes members specific datatypes, illustrated Example 4.
Example 3. Consider extension entailment equality imposing following
condition interpretations:
(+) interpretation satisfies triple hx, owl:sameAs, yi respect
blank node assignment iff xI,A = I,A .
consider datatype map = {bool 7 boolean}, boolean defined follows:
Lboolean = {1, 0, t, f },
V boolean = {true, f alse},
L2V boolean = {1 7 true, 0 7 f alse, 7 true, f 7 f alse},
RDF graph = {hmyBool, owl:sameAs, booli, ha, b, (1, myBool)i}. D-interpretations, typed literals datatype URIs interpreted interpreted well. Therefore, entailment extended condition (+)
triple ha, b, (t, myBool)i derived S: (1, myBool) (t, myBool)
interpreted L2V boolean (1) = L2V boolean (t) = true; hence, (1, myBool)
(t, myBool) interpreted way every interpretation. Similarly,
shown triples ha, b, (1, bool)i ha, b, (t, bool)i entailed S.
547

fide Bruijn & Heymans

None derivations valid considering D* entailment extended condition (+). fact, myBool domain D, (1, myBool) interpreted
arbitrary (abstract) symbol; treated way URI.
Example 4. Consider datatype map includes XML schema datatypes string
integer (Peterson et al., 2009), disjoint value spaces. Consider also
graph = {h : x, rdf:type, stringi, h : x, rdf:type, integeri}. rdfs-D*-interpretation class extensions string integer necessarily
value spaces respective datatypes. Therefore, may object k IR
neither integer string, class extensions string
integer. Consequently, rdfs-D*-interpretation model
rdfs-D*-satisfiable.
rdfs-D-interpretation class extensions string integer necessarily
value spaces respective datatypes. Since value spaces disjoint,
object class extension string class extension
integer. Therefore, rdfs-D-satisfiable.
4.2 Embeddings Datatypes Logic
Given datatype map D, use set formulas L, defined Appendix B, axiomatize semantics entailment regime {x-D*, x-D}, x {s, rdf, rdfs, erdfs}.
Analogous Proposition 3, have:
Proposition 8. Let RDF graph vocabulary V . Then, sk(tr(S)) ,
{s-D*, rdf-D*, rdfs-D*, s-D, rdf-D, rdfs-D}, equivalently rewritten set FLogic Horn formulas.
first show faithfulness embedding D* entailment.
Theorem 4. Let E RDF graphs vocabulary V , let datatype map,
let x {s, rdf, rdfs, erdfs} entailment regime. Then,
|=x-D* E tr(S) x-D* |=f tr(E)
x-D*-satisfiable iff tr(S) x-D* model.
turn x-D-entailment. turns considering datatype maps
arbitrary datatypes, one needs reason case (see Proposition 14 Section 5),
complicates matters. therefore restrict definite datatypes,
bring complication. example definite datatype map one includes
set datatypes OWL 2 EL QL profiles (Motik et al., 2009a).
Definition 4. datatype map definite
value space every datatype ran(D) infinite,
n 1 distinct datatypes d1 , . . . , dn ran(D) holds either (a) value
spaces disjoint, i.e., V di V dj = (1 < j n) (b) intersection
infinite, i.e., V d1 V dn infinite set,
548

fiLogical Foundations RDF(S) Datatypes

two datatypes d1 , d2 ran(D) holds d1 V d2 .
Theorem 5. Let E RDF graphs vocabulary V , let definite datatype
map, let x {s, rdf, rdfs, erdfs} entailment regime. Then,
|=x-D E tr(S) x-D |=f tr(E)
x-D-satisfiable iff tr(S) x-D model.
4.3 Normalization Datatypes
set equality statements axiomatizations x-D* x-D potentially large
and, general, polynomial size vocabulary V . addition, requires equality
reasoning, tends deteriorate performance reasoner. discuss
normalize embedding graph F-Logic, thereby removing need expressing
equality.
Given vocabulary V , assume strict (e.g., lexicographical)
order < set

literals PL L. given datatype map D, define V = udom(D) V D(u) , i.e.,
values D. v V , define literals represent value v as:
v = {(s, u) L | L2V D(u) (s) = v} {l PL | l = v}. representation v, denoted
r(v), least element v according order <.
Given set formulas L L conforms V , datatype normalization
, denoted ()n , obtained replacing every plain literal l PL r(l)
replacing every well-typed literal (s, u) L r(L2V D(u) (s)).
Observe equality statements normalizations (tr(S) x-D )n
(tr(S) x-D* )n trivial statements form = t, literal. Therefore,
statements may discarded.
following proposition follows straightforwardly shape axiomatizations definition normalization.
Proposition 9. Let E RDF graphs vocabulary V , let datatype map D,
let {s-D*, rdf-D*, rdfs-D*, erdfs-D*, s-D, rdf-D, rdfs-D, erdfs-D}. Then,
tr(S) |=f tr(E) iff (tr(S) )n |=f (tr(E))n

5. Complexity
section review complexity various RDF entailment relations present
several novel results, exploiting embeddings presented Sections 3 4.
complexity non-ground simple entailment RDFS entailment, upper bounds
ground entailment known literature, analogous results RDF entailment follow immediately. Recall that, although set axiomatic triples infinite,
finite subset, linear size graphs, needs taken account
checking entailment (cf. Proposition 4).
Proposition 10 (Gutierrez et al., 2004, 2010; ter Horst, 2005; de Bruijn et al., 2005).
decision problems |=s E, |=rdf E, |=rdf E, |=rdfs-D* E, given RDF graphs
549

fide Bruijn & Heymans

E, NP-complete combined size E, polynomial size S.
E ground, respective problems PTime.
addition, problems |=erdf E |=rdfs-D E NP-hard.
membership proofs Gutierrez et al. (2004, 2010), ter Horst (2005), de Bruijn
et al. (2005) rely fact set (relevant) entailed triples given graph
computed polynomial time using RDFS entailment rules (ter Horst, 2005);
problem reduced subgraph homomorphism. Corollary 1
fact problem checking ground entailment Datalog (Dantsin, Eiter, Gottlob,
& Voronkov, 2001) polynomial size data (i.e., tr(S)) obtain novel
argument membership.
NP-hardness non-ground entailment shown reduction
known NP-hard problem (ter Horst, 2005).
embedding F-Logic (Theorem 1), obtain following upper bound
complexity simple RDF entailment.
Proposition 11. Let E RDF graphs. E fixed, problems |=s E
|=rdf E decidable LogSpace size S. problems |=s E |=rdf E
decidable LogSpace combined size graphs E ground.
Proof Sketch. easy see fact could potentially recursively derived rdf rdf:type[rdf:type rdf:Property]; however, rdf:type[rdf:type
rdf:Property] rdf . Thus, sk(tr(S)) sk(tr(S)) rdf may treated nonrecursive
Datalog programs.
proposition follows straightforwardly Corollary 1 fact ground
entailment nonrecursive Datalog LogSpace size data (Abiteboul, Hull,
& Vianu, 1995), data input RDF graphs.
turns cannot obtain LogSpace upper bound RDFS entailment.
fact, turns ground rdfs-, hence ground rdfs-D* - rdfs-D-entailment,
PTime-hard.
Proposition 12. exist ground RDF graphs E decision problems
|=rdf E, |=rdfs-D* E, |=rdfs-D E PTime-hard.
Proof. proceed reduction PTime-hard problem path system accessibility
(Jones & Laaser, 1974; Gary & Johnson, 1979), defined as:
Instance: set X nodes, subsets S, X source terminal nodes, relation
R X X X.
Question: node x X accessible x exist accessible nodes y, z X
hx, y, zi R. accessible terminal node ?
remainder sp short rdfs:subPropertyOf.
encode problem RDFS. graph G constructed follows:
every source node x include triple hx, sp, spi,
every terminal node x include triple ha, sp, xi,
every tuple hx, y, zi R include triple hx, y, zi.
550

fiLogical Foundations RDF(S) Datatypes

show node X accessible iff G |=rdf ht, sp, spi. follows
exists accessible node iff G |=rdf ha, sp, spi.
() proceed induction. Base case: ht, sp, spi G, clearly
G |=rdf ht, sp, spi.
Induction step: consider ht, y, zi R y, z accessible. ht, y, zi
included G G |=rdf hy, sp, spi G |=rdf hz, sp, spi, since z accessible.
Condition 10 Table 5 implies G |=rdf ht, sp, zi. transitivity sp (condition 9
Table 5) subsequently conclude G |=rdf ht, sp, spi.
() Assume, contrary, X accessible. straightforward
construct rdfs-interpretation |=rdf G 6|=rdf ht, sp, spi, contradiction.
Using correspondence Proposition 7, results complexity reasoning
DL-LiteR (Calvanese et al., 2007), classical results skolemization (Fitting,
1996) obtain following result extensional RDFS entailment. Recall notion
standard use RDFS vocabulary Definition 2.
Proposition 13. Let E RDF graphs standard use RDFS vocabulary E E S. Then, problem deciding |=erdf E NP-complete,
NLogSpace-complete E ground.
Proof. Assume E ground. first demonstrate membership.
F O(sk(trerdfs (S)) erdfs-V ) theory contextual FOL equivalent contextual DL-LiteR knowledge base (by Proposition 7). E ground, then,
straightforward consequence Theorems 2 3,
erdfs-V
) |=c F O(trerdfs (E)).
|=erdf E iff F O(sk(trerdfs (S)) SE

contextual DL-LiteR theory c (resp., formula c ) straightforwardly rewritten
corresponding classical DL-LiteR theory (resp., formula )
c |=c c iff |= .
Since transformation linear size knowledge base, complexity
deciding satisfiability entailment contextual DL-LiteR knowledge bases
DL-LiteR knowledge bases, namely NLogSpace (Calvanese et al., 2007).
Hardness shown reduction known NLogSpace-hard problem: Graph reachability (Papadimitriou, 1994) encoded using subclass statements: edges
graph represented RDF graph rdfs:subClassOf-triples reachable
iff |=erdfs {hs, rdfs:subClassOf, ti}.
result immediately leads following NP algorithm deciding |=erdf E,
case E ground:
1. Guess mapping blank nodes E ground terms F O(sk(trerdfs (S))erdfs-V
SE ).
erdfs-V
erdfs
erdfs
2. Check whether F O(sk(tr
(S)) SE ) |=c F O(tr
(E)).
algorithm clearly sound complete, since theory F O(sk(trerdfs (S)) erdfs-V
SE )
universal.
NP-hardness follows NP-hardness simple entailment (Proposition 10),
straightforwardly encoded extensional RDFS entailment.
551

fide Bruijn & Heymans

x-D-entailment arbitrary datatype maps obtain following novel lower
bound.
Proposition 14. RDF graphs E datatype map deciding
|=s-D E coNP-hard size S.
Proof. proceed reduction complement graph k-colorability k 3,
i.e., nonexistence k-coloring. problem coNP-complete (Gary & Johnson,
1979):
Instance: graph G = hV, Ei positive integer k |V | k 3.
Question: k-coloring assignment nodes colors f : V {1, 2, . . . , k}
two adjacent nodes share color, i.e., hu, vi E, f (u) 6= f (v).
case k-coloring?
Let datatype map includes rdf:XMLLiteral maps URI
datatype D(d) ordered value space cardinality k, let smallest RDF
graph that:
every v V , hv, rdf:type, di
every hu, vi E, hu, R, vi S,
R URI, let H = {h :x, R, :xi}, :x blank node.
show G k-coloring |=s-D H.
() Assume, contrary, 6|=s-D H, means s-D-interpretation |= 6|= H. Therefore, (*) IR
hs, si IEXT(IS(R)). Consider hu, vi E; (*) IS(u) 6= IS(v). Since
hu, rdf:type, di, hv, rdf:type, di S, IS(u), IS(v) D(d), condition 20 Table 8.
let f (v) = IS(v) every v V . f k-coloring, contradiction.
() Analogously, exists k-coloring, one construct s-D-interpretation
model S, H.
polynomial (resp., logspace) datatype map datatype map holds
0
deciding well-typedness literals deciding L2V D(u) (s) = L2V D(u ) (s0 ) l =
L2V D(u) (s), l plain literal (s, u), (s0 , u0 ) well-typed literals, done
PTime (resp., LogSpace).
Considering definite datatype maps, obtain following lower bound Theorem
5 data complexity Datalog, exploiting Skolemization, analogous Corollary 1,
exploiting fact need take account subset RDF(S)
axiomatic triples, analogous Proposition 4.
Proposition 15. Let definite polynomial datatype map. Then, decision problems
|=s-D E, |=rdf-D E, |=rdfs-D E NP-complete combined size E,
polynomial size S. E ground, respective problems PTime.
turns that, analogous case without datatypes, refine
upper bounds simple- rdf -entailment.
Lemma 1. Let theory let logspace datatype map. Then, ()n
computed LogSpace.
552

fiLogical Foundations RDF(S) Datatypes

Entailment
|=s ,|=rdf ,|=rdf
|=s ,|=rdf
|=rdf
|=erdf
|=erdf

Restrictions
none
none
none
none
stand. RDFS

|=erdf

stand. RDFS

Restrictions E
none
ground
ground
none
stand. RDFS
stand. RDFS,
ground

Complexity
NP-complete
LogSpace
P-complete
NP-hard
NP-complete
NLogSpace-complete

Table 2: Complexity Entailment |=x E RDF, measured combined size
E
Entailment
x=s
x=rdf
x=rdfs


LogSpace
LogSpace
P-complete

D*
LogSpace
LogSpace
P-complete

definite
LogSpace
LogSpace
P-complete


coNP-hard
coNP-hard
coNP-hard

Table 3: Complexity Entailment |=x-D E |=x-D* E, measured size
Proof. WL denote set plain well-typed literals, < lexicographical ordering WL. l plain literal, define v l = l; (s, u) well-typed
literal, v (s,u) = L2V D(u)(s) . following algorithm returns representation literal
00
l WL LogSpace: iterate literals l0 < l, least literal l00 v l = v l
00
found; observe deciding l0 < l deciding v l = v l done LogSpace.
lemma obtain following upper bound, considerations analogous
Proposition 11 fact axioms \rdf introduce recursion.
Proposition 16. Let E RDF graphs let logspace datatype map. Then,
problems |=s-D* E |=rdf-D* E decidable LogSpace size S,
combined size graphs E ground.
Furthermore, definite, problems |=s-D E |=rdf-D E decidable
LogSpace size S, combined size graphs E ground.
Table 2 summarizes complexity reasoning entailment regimes RDF;
stand. RDFS stands standard use RDFS vocabulary; E
E E S. results first fourth line table, upper bound
ground rdfs-entailment previously known (Gutierrez et al., 2004; de Bruijn et al.,
2005; ter Horst, 2005). best knowledge, results novel.
Table 3 summarizes complexity reasoning datatypes, measured size
entailing graph S. Definite stands entailment restricted definite datatype
maps. LogSpace results require datatype map logspace well, i.e.,
must decidable LogSpace whether two literals equal interpretation given
D. suspect many datatype maps interest logspace examples
XML schema datatypes (Peterson et al., 2009). upper bounds rdfs- rdfs-D*553

fide Bruijn & Heymans

entailment known literature (ter Horst, 2005). best knowledge,
results table novel.

6. Conclusions Future Work
presented embeddings different RDF entailment regimes F-Logic,
shown deductive database description logic technology used
reasoning RDF.
Known complexity results fields deductive databases description logics
resulted several novel upper bounds, particular, ground simple- rdf -entailment
LogSpace, respective extensions D* datatype semantics; non-ground
(resp., ground) erdfs-entailment graphs standard use RDFS vocabulary
NP (resp., NLogSpace). best knowledge first known upper
bounds extensional RDFS entailment nontrivial subset RDF graphs.
case extensions simple-, rdf -, rdfs-entailment datatype support, upper
bounds non-ground ground entailment D* entailment
considering definite datatypes, require reasoning case.
addition, established several lower bounds reductions known
hard problems. particular, rdfs-entailment turns PTime-hard simpleentailment extended datatype support turns coNP-hard, size
entailing graph. also found matching lower bound NLogSpace result
ground erdfs-entailment graphs standard use RDFS vocabulary.
negative result concerning ground rdfs-entailment (i.e., PTime-hardness) might
come surprise language seems far less expressive PTime-hard
languages (e.g., variable-free Datalog (Dantsin et al., 2001) DL-LiteR,u , extension
DL-LiteR (Calvanese et al., 2007)). PTime-hardness proof suggests complexity originates possibility use RDFS vocabulary arbitrary places RDF
statements, e.g., rdfs:subPropertyOf object position triple. Indeed, ground
entailment minimal RDFS fragment Munoz, Perez, Gutierrez (2009)
decided O(nlogn).6 suspect minimal RDFS fragment extended
many useful features, class property declarations RDFS metadata
vocabulary, without compromising O(nlogn) upper bound. topic future
work.
negative result concerning entailment, even considering RDFS vocabulary (i.e., coNP-hardness), suggests one restrict oneself weaker datatype
semantics D* one use definite datatype maps, precludes
use finite datatypes bool int (Peterson et al., 2009). latter approach
taken specification tractable fragments (also called profiles) OWL 2 (Motik
et al., 2009a), datatype semantics similar semantics.
investigation reported paper formed basis specification
combinations RIF-BLD rules (RIF Working Group, 2010a), essentially Horn
logic formulas, RDF graphs. RIF RDF OWL specification (RIF Working
Group, 2010b) gives model-theoretic account semantics RIF-RDF combinations
6. minimal RDFS disallows use RDF(S) vocabulary besides properties RDF(S)
ontology vocabulary, allows use properties predicate position triples.

554

fiLogical Foundations RDF(S) Datatypes

suggests combinations embedded RIF-BLD rules, based
embedding Section 3.2. particular challenge future work combination RDF
graphs extensions RIF-BLD allow nonmonotonic negation rules,
interaction negation blank nodes.
Another topic future investigation precise relationship extensional
RDFS OWL. particular, relationship extensional RDFS standard use RDFS vocabulary OWL 2 QL fragment OWL 2 (Motik et al.,
2009a), based contextual DL-LiteR . embedding proof Proposition
7 provides promising starting point.

Acknowledgments
Jos de Bruijn partially supported European Commission projects
Knowledge Web (IST-2004-507482) ONTORULE (FP7 231875). Stijn Heymans
partially supported Austrian Science Fund (FWF) projects P20305 P20840
European Commission project ONTORULE (FP7 231875).

Appendix A. RDF(S) Semantics
appendix define notions RDF, RDFS, eRDFS, D* , interpretations
(Hayes, 2004; ter Horst, 2005). Recall definition interpretation Section 3.1.
RDF Interpretations

RDF vocabulary consists following symbols:

rdf:type rdf:Property rdf:XMLLiteral rdf:nil rdf:List rdf:Statement rdf:subject
rdf:predicate rdf:object rdf:first rdf:rest rdf:Seq rdf:Bag rdf:value rdf:Alt
rdf: 1 rdf: 2 . . .
RDF ontology vocabulary consists symbols rdf:type rdf:Property. Note
rdf: i, positive integer i, part RDF vocabulary. Thus, RDF
vocabulary infinite. remainder, omit prefix rdf: using RDF
vocabulary.
typed literal (s, XMLLiteral) well-typed XML literal lexical space
XMLLiteral, defined (Klyne & Carroll, 2004, Section 5.1); XML value s,
denoted xml (s), one-to-one correspondence s. lexical space
XMLLiteral, (s, XMLLiteral) ill-typed XML literal.
Given interpretation I, class extension object x IR set elements
connected x via type, i.e., instances x. defined ICEXT(x) = {k | hk, xi
IEXT(IS(type))}.
interpretation vocabulary V = hC, PL, Li rdf-interpretation V includes RDF vocabulary conditions 14 Table 4 hold I.
RDFS Interpretations

RDFS vocabulary consists of:

rdfs:domain rdfs:range rdfs:Resource rdfs:Literal rdfs:Datatype rdfs:Class
rdfs:subClassOf rdfs:subPropertyOf rdfs:member rdfs:Container rdfs:label
rdfs:ContainerMembershipProperty rdfs:comment rdfs:seeAlso rdfs:isDefinedBy
555

fide Bruijn & Heymans

1

2
3

4

IS(type), IS(subject), IS(predicate), IS(object), IS(first), IS(rest),
IS(value), IS( 1), IS( 2), . . . IP
IS(nil) ICEXT(IS(List))
IP = ICEXT(IS(Property))
(s, XMLLiteral) L well-typed XML literal,
IL((s, XMLLiteral)) = xml (s), IL((s, XMLLiteral)) LV,
IL((s, XMLLiteral)) ICEXT(IS(XMLLiteral))
(s, XMLLiteral) L ill-typed XML literal,
IL((s, XMLLiteral))
/ LV IL((s, XMLLiteral))
/ ICEXT(IS(XMLLiteral))

Table 4: Conditions RDF interpretations
RDFS ontology vocabulary consists symbols rdfs:subClassOf, rdfs:subPropertyOf, rdfs:domain, rdfs:range, rdfs:Class, rdfs:Datatype. remainder
omit prefix rdfs: using RDFS vocabulary.
say rdf -interpretation vocabulary V rdfs-interpretation V
includes RDFS vocabulary conditions 515 depicted Table 5 hold I.
shortcut, define IEXTp (o) = {s | hs, IS(o)i IEXT(IS(p))}.
RDF (resp, RDFS) axiomatic triple triple satisfied every rdf -(resp,
rdfs-) interpretation. Conditions 1 5 correspond RDF(S) axiomatic triples
following way; see also (Hayes, 2004, Sections 3.1 4.1):
IS(s) IP corresponds axiomatic triple hs, type, rdf:Propertyi,
IS(s) IEXTp (o) corresponds axiomatic triple hs, p, oi,
IS(s) ICEXT(IS(c)) corresponds axiomatic triple hs, type, ci.
Extensional RDFS Interpretations normative RDFS semantics, reviewed above,
also called intensional RDFS semantics. RDF semantics specification (Hayes,
2004) also defines extensional RDFS semantics (eRDFS).
rdfs-interpretation erdfs-interpretation conditions depicted Table 6
hold.
D* Interpretations Given vocabulary V simple datatype map D, s-interpretation V s-D*-interpretation V includes dom(D) conditions 1619 Table
7 satisfied u dom(D).
Given vocabulary V datatype map D, rdf (resp., rdfs, erdfs)-interpretation
V rdf -D* (resp., rdfs-D* , erdfs-D* )-interpretation s-D* -interpretation.
Interpretations Given vocabulary V simple datatype map D, s-D* -interpretation V s-D-interpretation satisfies conditions 2022 Table 8
u dom(D).
Given vocabulary V datatype map D, rdf (resp., rdfs, erdfs)-interpretation
V rdf -D (resp., rdfs-D, erdfs-D)-interpretation s-D-interpretation.
556

fiLogical Foundations RDF(S) Datatypes

5

6
7
8
9
10
11
12
13
14
15

IS(type), IS(member), IS(seeAlso), IS(isDefinedBy), IS(comment),
IS(label), IS(value), IS( 1), IS( 2), . . . IEXTdomain (Resource)
IS(domain), IS(range), IS(subPropertyOf) IEXTrdfs:domain (Property)
IS(subClassOf) IEXTrdfs:domain (Class)
IS(subject), IS(predicate), IS(object) IEXTdomain (Statement)
IS(first), IS(rest) IEXTdomain (List)
IS(subject), IS(predicate), IS(object), IS(member), IS(first), IS(seeAlso),
IS(isDefinedBy), IS(value), IS( 1), IS( 2), . . . IEXTrange (Resource)
IS(comment), IS(label) IEXTrange (Literal)
IS(subPropertyOf) IEXTrange (Property)
IS(type), IS(domain), IS(range), IS(subClassOf) IEXTrange (Class)
IS(rest) IEXTrange (List)
IS(Alt), IS(Bag), IS(Seq) IEXTsubClassOf (Container)
IS(ContainerMembershipProperty) IEXTsubClassOf (Property)
IS(isDefinedBy) IEXTsubPropertyOf (seeAlso)
IS(XMLLiteral) ICEXT(IS(Datatype))
IS(XMLLiteral) IEXTsubClassOf (Literal)
IS(Datatype) IEXTsubClassOf (Class)
IS( 1), IS( 2), . . . ICEXT(IS(ContainerMembershipProperty))
IR = ICEXT(IS(Resource))
LV = ICEXT(IS(Literal))
hx, yi IEXT(IS(domain)) hu, vi IEXT(x), u ICEXT(y)
hx, yi IEXT(IS(range)) hu, vi IEXT(x), v ICEXT(y)
IEXT(IS(subPropertyOf)) transitive reflexive IP
hx, yi IEXT(IS(subPropertyOf)), IEXT(x) IEXT(y)
x ICEXT(Class), x IEXTsubClassOf (Resource)
hx, yi IEXT(IS(subClassOf)), ICEXT(x) ICEXT(y)
IEXT(IS(subClassOf)) transitive reflexive ICEXT(Class)
x ICEXT(ContainerMembershipProperty), x IEXTsubPropertyOf (member)
x ICEXT(Datatype), x IEXTsubClassOf (Literal)

Table 5: Conditions RDFS interpretations

70
80
100
120

hx, yi IEXT(IS(domain)) (if hu, vi IEXT(x), u ICEXT(y))
hx, yi IEXT(IS(range)) (if hu, vi IEXT(x), v ICEXT(y))
hx, yi IEXT(IS(subPropertyOf)) x, IP IEXT(x) IEXT(y)
hx, yi IEXT(IS(subClassOf))
x, ICEXT(Class) ICEXT(x) ICEXT(y)

Table 6: Conditions eRDFS interpretations

557

fide Bruijn & Heymans

16 IS(u) = D(u)
17 IS(u) ICEXT(IS(Datatype))
(s, u) L LD(u) , IL((s, u)) = L2V D(u) (s) LV
18
IL((s, u)) ICEXT(D(u))
(s, u) L
/ LD(u) , IL((s, u))
/ LV
19
IL((s, u))
/ ICEXT(D(u))
Table 7: Conditions D* interpretations
20 ICEXT(IS(u)) = V D(u) LV
(s, u0 ) L, IS(u0 ) = IS(u) LD(u) ,
21
IL((s, u0 )) = L2V D(u) (s)
22 (s, u0 ) L, IS(u0 ) = IS(u)
/ LD(u) , IL((s, u0 ))
/ LV
Table 8: Conditions D-interpretations

Appendix B. Embeddings
appendix contains axiomatization x entailment regimes x {s, rdf, rdf,
erdfs} axiomatization datatype entailment regimes x-D* , x-D , referenced
Sections 3 4.
Following convention Appendix omit prefixes rdf: rdfs: using
RDF RDF vocabularies.
B.1 RDF Entailment Regimes
axiomatization s, rdf , rdfs, erdfs entailment regimes, denoted x ,
x {s, rdf, rdfs, erdfs}, defined Table 9.
B.2 Datatype Entailment Regimes
axiomatization D* entailment regimes, denoted x-D* x-D , respectively, x {s, rdf, rdfs, erdfs}, defined Table 10.
Note entailment requires whenever two URIs mapped
individual given interpretation, URIs used interchangeably typed literals.
However, since equality URIs cannot stated RDF(S) indeed inferred
need consider case embeddings.
B.3 Extensional RDFS
Let V = hC, PL, Li vocabulary. mapping function trerdfs , defined Section
3.3, deals eRDFS semantics RDF(S) vocabulary direct
embedding. define theory erdfs-V , deals remainder
RDF(S) vocabulary.
558

fiLogical Foundations RDF(S) Datatypes

=
rdf = {tr(hs, p, oi) | hs, p, oi RDF axiomatic triple}
{t[type XMLLiteral] | L well-typed XML literal}
{illD(t) | L ill-typed XML literal}
{x(y, z(y[x z]) x[type Property]),
x(x[type XMLLiteral] illD(x) )}
rdfs = rdf {tr(hs, p, oi) | hs, p, oi RDFS axiomatic triple}
{t[type Literal] | PL}
{x(x[type Resource]),
u, v, x, y(x[domain y] u[x v] u[type y]),
u, v, x, y(x[range y] u[x v] v[type y]),
x(x[type Property] x[subPropertyOf x]),
x, y, z(x[subPropertyOf y] y[subPropertyOf z] x[subPropertyOf z]),
x, y(x[subPropertyOf y] z1 , z2 (z1 [x z2 ] z1 [y z2 ])),
x(x[type Class] x[subClassOf Resource]),
x, y(x[subClassOf y] z(z[type x] z[type y])),
x(x[type Class] x[subClassOf x]),
x, y, z(x[subClassOf y] y[subClassOf z] x[subClassOf z]),
x(x[type ContainerMembershipProperty] x[subPropertyOf member]),
x(x[type Datatype] x[subClassOf Literal]),
x(x[type Literal] illD(x) )}
erdfs = rdfs {x, y(u, v(u[x v] u[type y]) x[domain y]),
x, y(u, v(u[x v] v[type y]) x[range y]),
x, y(x[type Property] y[type Property] u, v(u[x v]
u[y v]) x[subPropertyOf y]),
x, y(x[type Class] y[type Class] u(u[type x] u[type y])
x[subClassOf y])}

Table 9: Axiomatization RDF entailment regimes.

erdfs-V = {trerdfs (hs, p, oi) | hs, p, oi RDF(S) axiomatic triple
standard use RDF(S) vocabulary}
{t : XMLLiteral | L well-typed XML literal}
{t : illxml | L ill-typed XML literal}
{t : Literal | PL}
{x(x : Literal x : illxml )}

Appendix C. Proofs
appendix contains proofs propositions theorems Sections 3 4.
C.1 Proof Proposition 2
Consider generalized RDF graph S, interpretation = hIR, IP, IS, IEXTi
holds IP = IR includes every term S, IS(c) = c URI c, IL(l) = l
typed literal l, every triple hs, p, oi S, (s, o) IEXT (p), blank node
559

fide Bruijn & Heymans

V -D*-= = {l = (s, u) | l PL, (s, u) L well-typed literal,
l = L2V D(u) (s)}
{(s, u) = (s0 , u0 ) | (s, u), (s0 , u0 ) L distinct well-typed literals
0
L2V D(u) (s) = L2V D(u ) (s0 )}
x-D* = x V -D*-=
{(s, u)[type u] | (s, u) L well-typed literal}
{illD(t) | L ill-typed literal}
{u[type Datatype] | u dom(D)}
{x(illD(x) x[type u] ) | u dom(D)}
x-D = x-D*
{(s, u0 )[type u] | (s, u0 ) L well-typed literal,
0
u dom(D), L2V D(u ) (s) V D(u) }
{s[type u] | PL, u dom(D), V D(u) }
{x(x[type u] dt(x, u)) | u dom(D)}
{x(dt(x, u1 ) dt(x, u2 )) | u1 , u2 dom(D).V D(u1 ) V D(u2 ) = }
{dt(l, u) | l PL, u dom(D), l 6 V D(u) }
0
{dt((s, u), u0 ) | (s, u) L, u0 dom(D), L2V D(u) (s) 6 V D(u ) }
Table 10: Axiomatization datatype entailment regimes, x {s, rdf, rdfs, erdfs}.
assignment : bl(S) IR maps every blank node itself. Clearly, (I, A) |= S, |= S,
s-interpretation. Therefore, s-satisfiable.
easy see following generalized RDF graph rdf -, hence rdfs-
erdfs-unsatisfiable, negation condition 4 Table 4:
= {h(<notXML, XMLLiteral), type, XMLLiterali}: (<notXML, XMLLiteral)
ill-typed XML literal, condition 4 Table 4, IL((<notXML, XMLLiteral))
/
ICEXT(IS(XMLLiteral)). However, graph satisfied rdf -interpretation,
must case IL((<notXML, XMLLiteral)) ICEXT(IS(XMLLiteral)), contradiction.
Hayes (2004) observed one create similar situation normal RDF graph
range constraint; graph rdfs- hence erdfs-unsatisfiable.
C.2 Proof Theorem 1
first show 6|=x E iff tr(S) x 6|=f tr(E). follows immediately
|=x E iff tr(S) x |=f tr(E).
() Let V = hC, PL, Li vocabulary E let L F-language
conforms V . Assume 6|=x E. means x-interpretation
= hIR, IP, LV, IS, IL, IEXTi |= 6|= E. construct corresponding
F-structure = hU, U , IC , , IP following way:
(i) U = IR IP,
(ii) (t) = IS(t) every URI reference C, (t) = every plain literal PL,
(t) = IL(t) every typed literal L,
560

fiLogical Foundations RDF(S) Datatypes

(iii) (k) = IEXT(k) every k IP (k) = every k
/ IP,
(iv) IP (illD) = {u | L ill-typed XML literal IL(t) = u}.
straightforward verify |=f tr(S) x I6|=f
x 6|=f tr(E).

tr(E).

Hence, tr(S)

() Assume tr(S) x 6|=f tr(E). means (by (Fitting, 1996, Theorem 5.9.4)
Proposition 6) Herbrand F-structure = hU, U , IC , , IP
|=f tr(S) x I6|=f tr(E). Since Herbrand F-structure, U includes constant
symbols, IC maps every constant symbol itself. construct corresponding
interpretation = hIR, IP, LV, IS, IL, IEXTi follows:
(i) IP = {p | hp, (Property)i (IF (type))} {p | s, o.hs, oi (p)},
(ii) LV = PL {xml(s) | ((s, XMLLiteral) L (s, XMLLiteral) well-typed XML
literal)} {l | hl, (Literal)i (IF (type))},
(iii) IR = U LV,
(iv) IS(t) = (t) every URI C, IL((s, u)) = xml(s) (s, u) L well-typed
XML literal; IL((s, u)) = ((s, u)) (s, u) L (s, u) L well-typed
XML literal,
(v) p U hs, oi (p): hs0 , o0 IEXT(p), s0 (resp., o0 ) is:
(t, XMLLiteral) L (t, XMLLiteral) well-typed XML literal
((t, XMLLiteral)) = (resp., = o), s0 = xml(t) (resp., o0 = xml(t));
otherwise s0 = (resp., o0 = o).
One verify x-interpretation, |= S, 6|= E. Hence, 6|= E.
second part theorem shown analogously.
C.3 Proof Proposition 4
Corollary 1 |=x E iff sk(tr(S)) x |=f tr(E). Therefore, need
show sk(tr(S)) xSE |=f tr(E) iff sk(tr(S)) x |=f tr(E).
() Trivial, since sk(tr(S)) xSE sk(tr(S)) x .
() Consider case x = erdfs. Let minimal Herbrand model sk(tr(S)) x
let I0 obtained removing triples involving container membership properties
n appear x \xSE . verify, e.g., case analysis shape
triples S, I0 minimal model sk(tr(S)) xSE . Similarly, one verify
|=f tr(E), I0 |=f tr(E).
Analogous x {s, rdf, rdfs}.
C.4 Proof Theorem 2
prove directions contraposition.
() Assume trerdfs (S) erdfs-V 6|=f trerdfs (E). means Herbrand Fstructure = hU, U , IC , , IP |=f trerdfs (S) erdfs-V I6|=f trerdfs (E).
561

fide Bruijn & Heymans

define xml0 (x) = xml(s) x well-typed XML literal (s, XMLLiteral); otherwise
xml0 (x) = x. construct corresponding interpretation = hIR, IP, LV, IS, IL, IEXTi
follows:
(i) LV = {xml0 (l) | l U (Literal)},
(ii) IP = IR = U LV {type, subClassOf, domain, range, subPropertyOf},
(iii) IS(t) = every URI reference S, E, RDF(S) vocabulary,
(iv) IL(t) = xml0 (t) L,
(v) p U hs, oi (p), hxml0 (s), xml0 (o)i IEXT(p),
(vi) IEXT(type) smallest relation
(a) IEXT(type) {hxml0 (s), xml0 (o)i | U o};
(b) ICEXT(Resource) = ICEXT(Class) = IR;
(c) ICEXT(Property) = IP,
(vii) IEXT(domain) set tuples hx, yi, x, IR, (if hu, vi IEXT(x),
u ICEXT(y)); analogous IEXT(subClassOf), IEXT(subPropertyOf),
IEXT(range) (see Table 6 precise conditions).
One verify |= S, 6|= E, since E standard use RDFS
vocabulary, E include occurrences Resource, Class, Property, class
property vocabularies E subsets respective vocabularies S.
clearly satisfies conditions 14 Table 4, conditions 615 Table 5, conditions
0
7 120 Table 6. verify satisfies condition 5 Table 4 one needs keep
mind ICEXT(Resource) = ICEXT(Class) = IR ICEXT(Property) = IP. So,
erdfs-interpretation thus 6|=erdfs E.
() Assume 6|=erdf E. means erdfs-interpretation I0 that,
URI t, IS(t) = (making I0 similar Herbrand interpretation) I0 |=
I0 6|= E. Let = hIR, IP, LV, IS, IL, IEXTi erdfs-interpretation obtained I0
IP = IR ICEXT(IS(Class)) = IR, IEXT minimally extended
satisfy semantic conditions Tables 4, 5, 6. Clearly, must
erdfs-interpretation |= S. also have, restrictions class property
vocabularies well non-occurrence E Resource, Class, Property,
6|= E.
construct corresponding F-Logic interpretation = hU, U , IC , , IP follows:
(i) U = IR, (ii) (t) = every URI plain literal t, (t) = every L, (iii)
(k) = IEXT(k) every k U , (iv) U = IEXT(IS(type)).
straightforwardly verified |=f trerdfs (S) erdfs-V I6|=f trerdfs (E).
Therefore, must case trerdfs (S) erdfs-V 6|=f trerdfs (E).
562

fiLogical Foundations RDF(S) Datatypes

C.5 Proof Proposition 7
obtained F O(trerdfs (S) erdfs-V ) following way:
(i) Class membership property value statements forms A(a), P (a1 , a2 )
included such,
(ii) Subclass subproperty statements included such,
(iii) Domain constraints form x, y(P (x, y) A(x)) rewritten role-typing
statements form x(y(P (x, y)) A(x)),
(iv) Range constraints form x, y(P (x, y) A(y)) rewritten role-typing statements form x(y(P (y, x)) A(x)),
(v) Constraints form x(A(x) B(x) ) rewritten x(A(x) B(x)).
F O(trerdfs (S)) obviously equivalent, easy verify FOL
equivalent contextual DL-LiteR knowledge base.
C.6 Proof Theorem 4
first establish second part theorem, i.e., x-D*-satisfiable iff tr(S) x-D*
model.
() Let V = hC, PL, Li vocabulary let L F-language conforms
V . Assume x-D*-satisfiable. means x-D*-interpretation
= hIR, IP, LV, IS, IL, IEXTi |= S. construct corresponding F-structure
= hU, U , IC , , IP following way (analogous construction
direction proof Theorem 1):
(i) U = IR IP,
(ii) (t) = IS(t) every URI reference C, (t) = every plain literal PL,
(t) = IL(t) every typed literal L,
(iii) (k) = IEXT(k) every k IP,
(iv) IP (illD) = {u | L ill-typed literal IL(t) = u}.
Clearly, |=f tr(S).
literal L ill-typed XML literal, clearly ill-typed literal.
Then, ill-typed literal IS(t) LV (by condition 19 Table 7),
hence ill-typed literal IS(t) ICEXT(Literal) IS(t)
ICEXT(XMLLiteral), condition 4 Table 4 (if x = rdf, x = rdfs, x = erdfs)
condition 6 Table 5 (if x = rdfs x = erdfs). Satisfaction x established
straightforwardly.
Consider well-typed literal (s, u) plain literal l. case l = L2V D(u) (s),
IL((s, u)) = l, condition 18 Table 7, thus ((s, u)) = (l) = l |=f l = (s, u),
(ii). Analogous case two distinct well-typed literals. Therefore, |=f V -D*-= .
563

fide Bruijn & Heymans

Consider definition x-D* Table 10. established |=f x
Satisfaction second, first, third, fourth sets formulas table
follows immediately from, respectively, (iv), conditions 18, 17, 19 Table 7.
Therefore, |=f x-D* .
establishes |=f tr(S) x-D* .
V -D*-= .

() Assume tr(S) x-D* model. Let = tr(S) x-D* .
Let obtained replacing every occurrence = adding
usual congruence axioms (cf. Fitting, 1996, Chapter 9). known axiomatization
equality preserves satisfiability entailment first-order logic (Fitting, 1996, Theorem
9.3.9). also case F-Logic, Proposition 1.
extend signature set URI references C 0 , disjoint C,
cardinality |bl(S)|; i.e., signature 0 = hC PL L C 0 , P {}i. Since
model (as has), exists, classical results, Herbrand F-structure
|=f . U = C C 0 PL L.
u U , define follows:
u C u dom(D), (u) = D(u),
(s, u) L well-typed literal u dom(D), ((s, u)) = L2V D(u) (s),
otherwise, (u) = u.
construct corresponding interpretation = hIR, IP, LV, IS, IL, IEXTi:
(i) IP = {(p) | hp, (Property)i (IF (type))} {(p) | s, o.hs, oi (p)},
(ii) LV = PL {L2V D(u) (s) | (s, u) L, u dom(D), (s, u) well-typed literal)}
{(l) | hl, (Literal)i (IF (type)) & (x = rdfs x = erdfs)},
(iii) IR = U LV,
(iv) IS(u) = (u) every URI reference u C; IL((s, u)) = ((s, u)) every (s, u)
L,
(v) p IP, IEXT smallest set hs, oi (p) implies h(s), (o)i
IEXT((p)).
easy see |= S. Remains verify x-D*-interpretation. Verifying
x-interpretation straightforward. remains verify satisfaction
conditions Table 7.
Satisfaction condition 16 follows directly definition . condition
17, u dom(D) thus u[type Datatype] x-D* . satisfies x-D*
hIF (u), (Datatype)i (IF (type)), h(IF (u)), (IF (Datatype))i
IEXT((IF (type))). construction IS, yields IS(u) ICEXT(IS(Datatype)).
Consider (s, u) L u dom(D) LD(u) . Then, (s, u) welltyped, IL((s, u)) = L2V D(u) (s) LV. definition x-D* , (s, u)[type
u] x-D* ; follows L2V D(u) (s) ICEXT(D(u)). establishes satisfaction
condition 18.
564

fiLogical Foundations RDF(S) Datatypes

Condition 19 satisfied fact LV contain ill-typed literals. Indeed,
PL {L2V D(u) (s) | (s, u) L, u dom(D), (s, u) well-typed literal)}
contain ill-typed literals x rdfs erdfs, ill-typed literal
|=f t[type Literal], last axiom definition rdfs Table 9.
easy verify, directions, 6|= E iff I6|=f tr(E). first part
theorem follows.
C.7 Proof Theorem 5
first show correspondence satisfiability.
() Let V = hC, PL, Li vocabulary E, let rdf x-D-interpretation
satisfies let L F-language conforms V . construct Fstructure = hU, U , IC , , IP corresponds I, using steps (i)(iv) ()
direction proof Theorem 4, additional step
(v) IP (dt) = {hx, ui | x ICEXT(u) u ran(D)}.
argument () direction proof Theorem 4 follows |=f tr(S)
x-D* . Consider x-D \ x-D* , defined Table 10. Satisfaction first set follows
immediately conditions 20 21 Table 8. Satisfaction second set follows
immediately condition 20 Table 8. Satisfaction third set follows immediately
(v).
Consider two u1 , u2 dom(D) V D(u1 ) V D(u2 ) = . condition 20
Table 8, ICEXT(IS(u1 ))ICEXT(IS(u2 )) = . (v) follows k U
hk, (u1 )i IP (dt) hk, (u2 )i IP (dt). Consequently, I6|=f x(dt(x, u1 )
dt(x, u2 )) thus fourth set sentences satisfied.
Consider (s, u) L u0 dom(D) IL((s, u)) = L2V D(u) (s)
/
0)
0
D(u
V
. condition 20 Table 8, ICEXT(IS(u0 )) = V D(u ) , thus IL((s, u))
/
0
0
0
ICEXT(IS(u )). (v) follows hIF ((s, u)), (u )i
/ IP (dt) thus I6|=f dt((s, u), u ),
establishing satisfaction sixth set. argument fifth set obtained
replacing (s, u) L l PL.
thus obtain |=f x-D . Therefore, tr(S) x-D model.
() Assume = tr(S) x-D model.
Let obtained proof Theorem 4 let = hU, U , IC ,
, IP Herbrand F-structure model . construct corresponding
interpretation = hIR, IP, LV, IS, IL, IEXTi following way. W.l.o.g. assume
value space V , ran(D), contains typed literal L.
observe (*) two d1 , d2 dom(D) must hold either V D(d1 )
D(d
2 ) disjoint overlap infinite, since definite. addition, V D(d1 )
V
V D(d2 ) disjoint, then, satisfaction fourth set definition x-D , (**)
I6|=f t[type d1 ] t[type d2 ] C C 0 .
given URI u C C 0 define mapping follows:
u dom(D), (u) = D(u),
hu, u0 (type), u0 dom(D), (u) = v, v
565

fide Bruijn & Heymans

v V D(u1 ) V D(un ) , u1 , . . . , un dom(D) datatype
identifiers hu, u1 i, . . . , hu, un (type);
u0 C v = (u0 );
0

(s, u0 ) L u0 dom(D) v = L2V D(u ) (s);
v must exist, u cannot member two disjoint datatypes, (**),
V D(u1 ) V D(un ) infinite set, Definition 4,
otherwise, (u) = u.
given literal l PL L define as:
l = (s, u) L well-typed literal, (s, u) = L2V D(u) (s),
otherwise (l) = (l).
One verify two distinct t1 , t2 C PL L, either (t1 ) =
(t2 ) ht1 , t2 IP () (by definition V -D*-= ) (t1 ) 6= (t2 ).
construct RDF interpretation = hIR, IP, LV, IS, IL, IEXTi, similar construction () direction proof Theorem 4. Note respective constructions differ steps (ii) (v).
(i) IP = {(p) | hp, (Property)i (IF (type))} {(p) | s, o.hs, oi (p)},

(ii) LV = PL {V | ran(D)} {(l) | hl, (Literal)i (IF (type)) & (x =
rdfs x = erdfs)},
(iii) IR = U LV,
(iv) IS(u) = (u) every u C; IL((s, u)) = ((s, u)) every (s, u) L,
(v) IEXT smallest set
ICEXT(IS(u)) = V D(u) every u dom(D),
p IP hs, oi (p), h(s), (o)i IEXT((p)).
Satisfaction conditions including 19 established analogous ()
direction proof Theorem 4. Notice condition 20 satisfied (v).
Consider typed literal = (s, u0 ) L datatype identifier u dom(D).
IS(u0 ) = IS(u), must case D(u0 ) = D(u), construction I.
0
0
LD(u ) , (s, u0 ) well-typed literal, thus IL((s, u0 )) = L2V D(u ) = L2V D(u) ,
0
(iv).
/ LD(u ) , (s, u0 ) ill-typed literal IL((s, u0 )) = (s, u0 )
/ LV,
LV contain ill-typed literals. Therefore, conditions 21 22 Table 8
satisfied.
Consequently, x-D-interpretation. |= thus x-Dsatisfiable.
second part theorem follows observation that, directions,
6|= E iff I6|=f tr(E).
566

fiLogical Foundations RDF(S) Datatypes

References
Abiteboul, S., Hull, R., & Vianu, V. (1995). Foundations Databases. Addison-Wesley.
Borgida, A. (1996). relative expressiveness description logics predicate logics.
Artificial Intelligence, 82 (12), 353367.
Brickley, D., & Guha, R. V. (2004). RDF vocabulary description language 1.0: RDF schema.
Recommendation 10 February 2004, W3C.
Calvanese, D., Giacomo, G. D., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning efficient query answering description logics: dl-lite family. Journal
Automated Reasoning, 39, 385429.
Dantsin, E., Eiter, T., Gottlob, G., & Voronkov, A. (2001). Complexity expressive
power logic programming. ACM Computing Surveys (CSUR), 33 (3), 374425.
de Bruijn, J., Franconi, E., & Tessaris, S. (2005). Logical reconstruction normative RDF.
Proceedings Workshop OWL: Experiences Directions (OWLED-2005).
de Bruijn, J., & Heymans, S. (2007). Logical foundations (e)RDF(S): Complexity
reasoning. Proceedings 6th International Semantic Web Conference
(ISWC2007), pp. 8699. Springer.
de Bruijn, J., & Heymans, S. (2008). relationship description logic-based
f-logic-based ontologies. Fundamenta Informaticae, 82 (3), 213236.
Fitting, M. (1996). First Order Logic Automated Theorem Proving (second edition).
Springer.
Gary, M. R., & Johnson, D. S. (1979). Computers Intractability Guide
Theory NP-Completeness. W.H. Freeman Company, New York, NY, USA.
Gutierrez, C., Hurtado, C., & Mendelzon, A. O. (2004). Foundations semantic web
databases. Proceedings 23rd ACM Symposium Principles Database
Systems (PODS2004), pp. 95106. ACM Press.
Gutierrez, C., Hurtado, C. A., Mendelzon, A. O., & Perez, J. (2010). Foundations
semantic web databases. Journal Computer System Sciences. Press.
Hayes, P. (2004). RDF semantics. Recommendation 10 February 2004, W3C.
Jones, N. D., & Laaser, W. T. (1974). Complete problems deterministic polynomial
time. Proceedings 6th Annual ACM Symposium Theory Computing
(STOC1974), pp. 4046, Seattle, Washington, USA. ACM Press.
Kifer, M., Lausen, G., & Wu, J. (1995). Logical foundations object-oriented framebased languages. Journal ACM, 42 (4), 741843.
Klyne, G., & Carroll, J. J. (2004). Resource description framework (RDF): Concepts
abstract syntax. Recommendation 10 February 2004, W3C.
Motik, B., Grau, B. C., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2009a). OWL 2 web
ontology language profiles. Recommendation 27 October 2009, W3C.
Motik, B., Patel-Schneider, P. F., & Parsia, B. (2009b). OWL 2 web ontology language
structural specification functional-style syntax. Recommendation 27 October
2009, W3C.
567

fide Bruijn & Heymans

Munoz, S., Perez, J., & Gutierrez, C. (2009). Simple efficient minimal RDFS. Journal
Web Semantics, 7 (3), 220234.
Papadimitriou, C. H. (1994). Computational Complexity. Addison Wesley.
Patel-Schneider, P. F., Hayes, P., & Horrocks, I. (2004). OWL web ontology language
semantics abstract syntax. Recommendation 10 February 2004, W3C.
Peterson, D., Gao, S., Malhotra, A., Sperberg-McQueen, C. M., & Thompson, H. S. (2009).
W3C XML schema definition language (XSD) 1.1 part 2: Datatypes. Working draft
3 December 2009, W3C.
RIF Working Group (2010a). RIF basic logic dialect. Recommendation 22 June 2010, W3C.
RIF Working Group (2010b). RIF RDF OWL compatibility. Recommendation 22 June
2010, W3C.
ter Horst, H. J. (2005). Completeness, decidability complexity entailment RDF
schema semantic extension involving OWL vocabulary. Journal Web
Semantics, 3 (23), 79115.
Yang, G., Kifer, M., & Zhao, C. (2003). FLORA-2: rule-based knowledge representation inference infrastructure semantic web. Proceedings Second International Conference Ontologies, Databases Applications Semantics
(ODBASE2003). Springer.

568

fiJournal Artificial Intelligence Research 38 (2010) 687-755

Submitted 01/10; published 08/10

Automatic Induction Bellman-Error Features
Probabilistic Planning
Jia-Hong Wu
Robert Givan

JW @ ALUMNI . PURDUE . EDU
GIVAN @ PURDUE . EDU

Electrical Computer Engineering
Purdue University, W. Lafayette, 47907 USA

Abstract
Domain-specific features important representing problem structure throughout machine
learning decision-theoretic planning. planning, state features provided, domainindependent algorithms approximate value iteration learn weighted combinations
features often perform well heuristic estimates state value (e.g., distance
goal). Successful applications real-world domains often require features crafted human experts. Here, propose automatic processes learning useful domain-specific feature sets
little human intervention. methods select add features describe state-space regions high inconsistency Bellman equation (statewise Bellman error) approximate
value iteration. method applied using real-valued-feature hypothesis space
corresponding learning method selecting features training sets state-value pairs.
evaluate method hypothesis spaces defined relational propositional feature
languages, using nine probabilistic planning domains. show approximate value iteration
using relational feature space performs state-of-the-art domain-independent stochastic
relational planning. method provides first domain-independent approach plays Tetris
successfully (without human-engineered features).

1. Introduction
substantial gap performance domain-independent planners domainspecific planners. Domain-specific human input able produce effective planners
competition planning domains well many game applications backgammon, chess,
Tetris. deterministic planning, work TLPLAN (Bacchus & Kabanza, 2000) shown
simple depth-first search domain-specific human input, form temporal logic formulas
describing acceptable paths, yields effective planner wide variety competition domains.
stochastic planning, feature-based value-function representations used humanselected features great success applications backgammon (Sutton & Barto, 1998;
Tesauro, 1995) Tetris (Bertsekas & Tsitsiklis, 1996). usage features provided human experts often critical success systems using value-function approximations.
Here, consider problem automating transition domain-independent planning
domain-specific performance, replacing human input automatically learned domain properties. thus study style planner learns encountering problem instances improve
performance subsequently encountered problem instances domain.
focus stochastic planning using machine-learned value functions represented linear
combinations state-space features. goal augment state-space representation
c
2010
AI Access Foundation. rights reserved.

fiW U & G IVAN

planning new machine-discovered features facilitate accurate representation
value function. resulting learned features used representing value function
problem instances domain, allowing amortization learning costs across
solution multiple problem instances. Note property contrast competition
planners, especially deterministic planning, retain useful information problem instances. Thus, approach solving planning problems regarded automatically
constructing domain-specific planners, using domain-independent techniques.
learn features correlate well statewise Bellman error value functions encountered planning, using provided feature language corresponding learner select
features space. evaluate approach using relational propositional feature
spaces. recent approaches acquiring features stochastic planning substantial differences approach discuss detail Section 5 (Patrascu, Poupart,
Schuurmans, Boutilier, & Guestrin, 2002; Gretton & Thiebaux, 2004; Sanner & Boutilier, 2009;
Keller, Mannor, & Precup, 2006; Parr, Painter-Wakefield, Li, & Littman, 2007). previous work
evaluated selection relational features correlation statewise Bellman error.
Recent theoretical results (Parr et al., 2007) uncontrolled Markov processes show exactly capturing statewise Bellman error new features, repeatedly, lead convergence
uncontrolled optimal value value function selected linear-fixed-point methods weight
training. Unfortunately machine-learning approaches selecting features, results
transferred approximations statewise Bellman-error features: case, results
work Parr et al. (2007) weaker imply convergence. Also, none theory transferred controlled case interest here, analysis much
difficult effective (greedy) policy consideration value-function training
changing.
consider controlled case, known theoretical properties similar Parr
et al. (2007) shown. Lacking theory, purpose demonstrate capability
statewise Bellman error features empirically, rich representations require machine
learning techniques lack approximation guarantees. Next, give overview approach, introducing Markov decision processes, value functions, Bellman error, feature hypothesis
languages feature learning methods.
use Markov decision processes (MDPs) model stochastic planning problems. MDP
formal model single agent facing sequence action choices pre-defined action space,
transitioning within pre-defined state space. assume underlying stationary
stochastic transition model available action state transitions occur according
agents action choices. agent receives reward action choice according state
visited (and possibly action chosen), objective accumulating much reward
possible (possibly favoring reward received sooner, using discounting, averaging time,
requiring reward received finite horizon).
MDP solutions represented state-value functions assigning real numbers states. Informally, MDP solution techniques, desire value function respects action transitions
good states either large immediate rewards actions available lead
good states; well-known property formalized Bellman equations recursively
characterize optimal value function (see Section 2). degree given value function
fails respect action transitions way, formalized next section, referred
Bellman error value function, computed state.
688

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Intuitively, statewise Bellman error high magnitude regions state space
appear undervalued (or overvalued) relative action choices available. state high
Bellman error locally inconsistent value function; example, state inconsistently labeled
low value action available leads high-value states. approach
use machine learning fit new features regions local inconsistency current value
function. fit perfect, new features guarantee represent Bellman update
current value function. Repeated Bellman updates, called value iteration, known
converge optimal value function. add learned features representation
train improved value function, adding new features available feature set.
method learning new features using approximate value function
regarded boosting-style learning approach. linear combination features
viewed weighted combination ensemble simple hypotheses. new feature learned
viewed simple hypothesis selected match training distribution focused regions
previous ensemble getting wrong (as reflected high statewise Bellman error throughout
region). Growth ensemble sequentially adding simple hypotheses selected correct
error ensemble far refer boosting style learning.
important note method scores candidate features correlation statewise
Bellman error current value function, minimizing statewise Bellman error
value function found using new candidate feature. pre-feature-addition scoring much
less expensive scoring involves retraining weights new feature, especially
repeated many times different candidates, relative current value function.
use pre-feature-addition scoring select features controlled setting enables much
aggressive search new features previously evaluated post-feature-addition approach
discussed work Patrascu et al. (2002).
approach considered selecting features feature-description language
learning method exists effectively select features match state-value training data.
consider two different feature languages empirical evaluation. Human-constructed
features typically compactly described using relational language (such English) wherein
feature value determined relations objects domain. Likewise, consider
relational feature language, based domain predicates basic domain description. (The
domain description may written, example, standard planning language PPDDL
Younes, Littman, Weissman, & Asmuth, 2005.) Here, take logical formulas one free variable
represent features count number true instantiations formula state
evaluated. example, number holes feature used many Tetris experiments
(Bertsekas & Tsitsiklis, 1996; Driessens, Ramon, & Gartner, 2006) interpreted counting
number empty squares board filled squares them.
numeric features provide mapping states natural numbers.
addition relational feature language, consider using propositional feature representation learning structure. Although propositional representation less expressive
relational one, exist effective off-the-shelf learning packages utilize propositional representations. Indeed, show reformulate feature learning task
related classification problem, use standard classification tool, decision-tree learner C4.5
(Quinlan, 1993), create binary-valued features. reformulation classification considers
sign, magnitude, statewise Bellman error, attempting learn features
characterize positive-sign regions state space (or likewise negative-sign regions).
689

fiW U & G IVAN

standard supervised classification problem thus formulated C4.5 applied generate
decision-tree feature, use new feature value-function representation.
propositional approach easier implement may attractive relational one
obvious advantage using relational representation, computing exact
statewise Bellman error state significantly expensive estimating sign.
experiments, however, find relational approach produces superior results
propositional learner. relational approach also demonstrates ability generalize features
problem sizes domain, asset unavailable propositional representations.
present experiments nine domains. experiment starts single, constant feature, mapping states number, forcing also constant value function makes
distinctions states. learn domain-specific features weights automatically
generated sampled state trajectories, adjusting weights new feature added.
evaluate performance policies select actions greedily relative learned value
functions. evaluate learners using stochastic computer-game Tetris seven planning domains two international probabilistic planning competitions (Younes et al., 2005;
Bonet & Givan, 2006). method provides first domain-independent approach playing
Tetris successfully (without human-engineered features). relational learner also demonstrates
superior success ratio probabilistic planning-competition domains compared
propositional approach probabilistic planners FF-Replan (Yoon, Fern, & Givan, 2007)
FOALP (Sanner & Boutilier, 2006, 2009). Additionally, show propositional learner
outperforms work Patrascu et al. (2002) SysAdmin domain evaluated there.

2. Background
present relevant background use Markov Decision Processes planning.
2.1 Markov Decision Processes
define terminology Markov decision processes. thorough discussion
Markov decision processes, see books Bertsekas Tsitsiklis (1996) Sutton Barto
(1998). Markov decision process (MDP) tuple (S, A, R, T, s0 ). Here, finite state
space containing initial state s0 , selects non-empty finite available action set A(s)
state S. reward function R assigns real reward state-action-state triple (s, a, )
action enabled state s, i.e., A(s). transition probability function maps
state-action pairs (s, a) probability distributions S, P(S), A(s).
Given discount factor 0 < 1 policy mapping state action A(s),
value function V (s) gives expected discounted reward obtained state selecting action
(s) state encountered discounting future rewards factor per time step.

least one optimal policy V (s), abbreviated V (s), less V (s)
every state s, policy . following Q function evaluates action respect
future-value function V ,
X
Q(s, a, V ) =
(s, a, )[R(s, a, ) + V (s )].


Recursive Bellman equations use Q() describe V V follows. First, V (s) =
Q(s, (s), V ). Then, V (s) = maxaA(s) Q(s, a, V ). Also using Q(), select ac690

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

tion greedily relative value function. policy Greedy(V ) selects, state s, action
arg maxaA(s) Q(s, a, V ).
Value iteration iterates operation
U(V )(s) = max

aA(s)

X

(s, a, )[R(s, a, ) + V (s )],



computing Bellman update U(V ) V , producing sequence value functions converging
sup-norm V , regardless initial V used.
define statewise Bellman error B(V, s) value function V state
U(V )(s) V (s). inducing new features based correlation statewise
Bellman error, based sign statewise Bellman error. sup-norm distance
value function V optimal value function V bounded using Bellman error magnitude, defined maxsS |B(V, s)| (e.g., see Williams & Baird, 1993). use term
statewise Bellman error emphasize distinction widely used sup-norm Bellman
error.
note computing U(V ), thus statewise Bellman error, involve summation
entire state space, whereas fundamental motivations require avoiding summations.
many MDP problems interest, transition matrix sparse way set states
reachable one step non-zero probability small, current state. problems,
statewise Bellman error computed effectively using appropriate representation .
generally, sparse manner, sum effectively approximately evaluated
sampling next states according distribution represented .
2.2 Modeling Goal-oriented Problems
Stochastic planning problems goal-oriented, objective solving problem
guide agent toward designated state region (i.e., goal region). model problems
structuring reward transition functions R action goal state leads
positive reward zero-reward absorbing state, reward zero everywhere else.
retain discounting represent preference shorter paths goal. Alternatively,
problems modeled stochastic shortest path MDPs without discounting (Bertsekas, 1995).
techniques easily generalized formalisms allow varying action costs well,
model variation work.
formally, define goal-oriented MDP MDP meeting following constraints. Here, use variables states actions A(s). require
contain zero-reward absorbing state , i.e., R(, a, s) = 0 (, a, ) = 1
a. transition function must assign either one zero triples (s, a, ), call
region states (s, a, ) one goal region. reward function constrained
R(s, a, ) zero unless = . constructing goal-oriented MDPs problem
representations, may introduce dummy actions carry transitions involving described
here.
2.3 Compactly Represented MDPs
work, consider propositional relational state representations.
691

fiW U & G IVAN

relational MDPs, spaces A(s) relationally represented, i.e.,
finite set objects O, state predicates P , action names N used define spaces
follows. state fact application p(o1 , . . . , ) n-argument state predicate p object
arguments oi , n1 . state set state facts, representing exactly true facts
state. action instance a(o1 , . . . , oS
n ) application n-argument action name n objects
oi , n. action space = sS A(s) set action instances.
MDPs compactly represented state action spaces also use compact representations
transition reward functions. One compact representation PPDDL planning
language, informally discussed next subsection formally presented work Younes
et al. (2005).
propositional problems, action space explicitly specified state space compactly specified providing finite sequence basic state properties called state attributes,
Boolean, integer, real values. propositional state vector values state
attributes.
Given relational MDP, equivalent propositional MDP easily constructed grounding, explicit action space constructed forming action-name applications
set state attributes computed forming state-predicate applications, thus removing use
set objects representation.
2.4 Representing PPDDL Planning Problems using MDPs
discuss represent goal-oriented stochastic planning problems defined standardized
planning languages PPDDL (Younes et al., 2005) goal-oriented MDPs. limit
focus problems goal regions described (conjunctive) sets state facts.
reference follow approach used work Fern, Yoon, Givan (2006) regarding
converting planning problems compactly represented MDPs manner facilitates generalization problem instances. first discuss several difficult representational issues
finally pull discussion together formal definition MDP analyze represent
given PPDDL problem instance. consider quantified and/or disjunctive goals,
handling goals would interesting useful extension work.
2.4.1 P LANNING OMAINS



P ROBLEMS

planning domain distribution problem instances sharing state predicates PW ,
action names N , action definitions. Actions take objects parameters, defined
giving discrete finite probability distributions action outcomes, specified
using add delete lists state facts action parameters.
Given domain definition, problem instance domain specifies finite object set O,
initial state si goal condition G. initial state given set state facts goal
condition given conjunction state facts, constructed predicates PW .
1. state predicate associated arity indicating number objects relates. state predicate
applied number objects domain form ground state fact either true false
state; states different possible ways select true state facts. Likewise, action name
associated arity natural number indicating number objects action act upon. action name
applied number objects form grounded action.

692

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

2.4.2 PPDDL R EPRESENTATION
PPDDL standard planning language international probabilistic planning competitions.
PPDDL, planning domain syntax planning problem syntax defined. completely
define planning instance, one specify domain definition problem definition using
respective syntax. Conditional effects quantified preconditions allowed domain
definition.
planning competitions, customary specify planning domains providing problem generators accept size parameters input output PPDDL problem instances.
generators thus specify size-parameterized planning domains. important note, however, problem generators provided recent planning competitions specify planning
domains according definition used here. particular, problem generators vary
action set state predicates instances generated. relationship
different problem instances generated generators much looser required
definition, domains somewhat like arbitrary collections planning
problems.
logical language allows generalization problems problems
share state action language, limit empirical evaluation Section 7 domains
provided problem generators specify planning domains defined here,
i.e., without varying action definitions instances (or easily code
generator). refer domains generators planning domains fixed action
definitions.
2.4.3 G ENERALIZATION B ETWEEN P ROBLEMS VARYING IZE
object set varies size, without bound, across problem instances domain,
infinitely many possible states within different instances single domain. MDP
analyze finite state space, model planning domain infinite set MDPs
seeking good policy (in form good value function), one MDP
problem instance2 .
value function infinite set MDPs mapping disjoint union state
spaces MDPs real numbers. value function used greedily policy
MDPs set. However, explicit representation value function would
infinite size. Here, use knowledge representation techniques compactly represent
value functions infinite set problem instance MDPs given planning domain.
compact representation derives generalization across domains, approach fundamentally finding good generalizations MDPs within single planning domain.
representation value functions planning domains given Sections 2.5 4.
section, discuss represent single finite MDP single planning problem
instance. However, note objective work find good value functions
infinite collections MDPs represent planning domains. Throughout paper,
assume planning domain provided along means sampling example problems
domain, sampling parameterized difficulty (generally, problem size)
2. paper consider two candidate representations features; one these, relational representation,
capable generalizing problem sizes. propositional representation, restrict training
testing problem instances size.

693

fiW U & G IVAN

easy example problems selected. Although, PPDDL provide problem
distributions, benchmark planning domains often provided problem generators defining
distributions: generators available, use them, otherwise code
distributions problem instances.
2.4.4 G ENERALIZING B ETWEEN P ROBLEMS



VARYING G OALS

facilitate generalization problem instances different goals, following work
Martin Geffner (2004) Fern et al. (2006), translate PPDDL instance description
MDP state specifies true state also goal is. Action
transitions MDP never change goal, presence goal within state
description allows value functions (that defined conditioning state) depend
goal well. goal region MDP simply MDP states specified
current state information matches specified goal information.
Formally, translating PPDDL problem instances compact MDPs, enrich given set
world-state predicates PW adding copy predicate indicating desired state
predicate. name goal-description copy predicate p prepending word goal-
name. set goal-description copies predicates PW denoted PG , take
PW PG state predicates MDP corresponding planning instance. Intuitively,
presence goal-p(a,b) state indicates goal condition requires fact p(a, b)
part world state. use goal predicates constructing compact MDP
PPDDL description constructing initial state, goal conditions true
goal predicates.
use domain Blocksworld example illustrate reformulation (the
domain also used example Fern et al., 2006). goal condition Blocksworld
problem described conjunction ground on-top-of facts. world-state predicate
on-top-of PW . discussed above, implies predicate goal-on-top-of PG .
Intuitively, one ground instance predicate, goal-on-top-of(b1,b2), means state
goal region, block b1 directly top block b2.
2.4.5 TATES



AVAILABLE ACTIONS

PPDDL allows definition domains states meet preconditions
action applied. However, MDP formalism requires least one available action every
state. translating PPDDL problem instance MDP define action transitions
action taken dead state transitions deterministically absorbing state.
consider states undesirable plan trajectories, give added transitions
reward negative one unless source state goal state.
2.4.6 R ESULTING MDP
pull together elements formally describe MDP = (S, A, R, T, s0 )
given PPDDL planning problem instance. discussed Section 2.3, set defined
specifying predicates objects available. PPDDL description specifies sets N
action names objects, well set PW world predicates. construct enriched
set P = PW PG state predicates define state space sets applications
predicates objects O. set A(s) state set PPDDL action instances built
694

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

N satisfies preconditions, except set empty, A(s) set
PPDDL action instances built N O. latter case, say state dead.
reward function R defined discussed previously Section 2.2; i.e., R(s, a, ) = 1
goal condition G true s, R(s, a, ) = 1 non-goal dead state, zero otherwise.
define (s, a, ) according semantics PPDDL augmented semantics
Section 2.2T (s, a, ) one satisfies G, dead, = , zero otherwise.3
Transiting one state another never changes goal condition description states given
predicates PG . MDP initial state s0 PPDDL problem initial state si augmented
goal condition G using goal predicates PG . propositional representation
desired, easily constructed directly relational representation grounding.
2.5 Linear Approximation Value Functions
many previous authors done (Patrascu et al., 2002; Sanner & Boutilier, 2009; Bertsekas &
Tsitsiklis, 1996; Tesauro, 1995; Tsitsiklis & Roy, 1997), address large compactly represented and/or implicitly representing value functions terms state-space features
f : R. features f must select real value state. describe two approaches
representing selecting features Section 4.
Recall Section 1 goal learn value function family related MDP
problems. assume state-space features defined across union state spaces
family.
represent
value functions using linear combination l features extracted s, i.e.,
P
V (s) = li=0 wi fi (s), f0 (s) = 1. goal find features fi (each mapping states real
values) weights wi V closely approximates V . Note single set features
weight vector defines value function MDPs features defined.
Various methods proposed select weights wi linear approximations (see, e.g.,
Sutton, 1988 Widrow & Hoff, 1960). Here, review use trajectory-based approximate
value iteration (AVI) approach. training methods easily substituted. AVI constructs
1
2

finite sequence value functions
one. value function
Pl V , V , . . . , V , returns last

represented V (s) = i=0 wi fi (s). determine weights wi+1 V , draw set
training states s1 , s2 , . . . , sn following policy Greedy(V ) different example problems
sampled provided problem distribution current level problem difficulty. (See
Section 3 discussion control problem difficulty.) number trajectories drawn
maximum length trajectory parameters AVI method. training state s,
compute Bellman update U(V )(s) MDP model problem instance.
compute wi+1 training states using
wi+1 = wi +

1 X
fi (sj )(U(V )(sj ) V (sj )),
ni

(1)

j

learning rate ni number states s1 , s2 , . . . , sn fi (s)
non-zero. Weight updates using weight-update formula descend gradient L2 distance
V U(V ) training states, features first rescaled normalize
3. Note according definitions Section 2.2, dead states technically goal states,
negative rewards.

695

fiW U & G IVAN

effective learning rate correct feature values rare occurrence training set.4 Pseudocode AVI method drawing training sets following policy available Online
Appendix 1 (available JAIR website), page 2.
Here, use greedy policy draw training examples order focus improvement
relevant states. state distributions generated biased current
policy; particular, another option worth considering, especially feature learning stuck, would
long random walk distribution discussed work Fern, Yoon, Givan (2004).
leave detailed exploration issue future work. substantial discussion
issues arise selecting training distribution, please see book Sutton Barto (1998).
worth noting on-policy training shown converge optimal value function
closely related reinforcement learning setting using SARSA algorithm (Singh, Jaakkola,
Littman, & Szepesvari, 2000).
general, AVI often gives excellent practical results, greedy gradient-descent
method environment convex due maximization operation Bellman error
function. such, guarantee quality weight vector found, even case
convergence. Convergence guaranteed, and, experiments, divergent weight
training fact problem required handling. note feature-discovery methods
used weight-selection algorithms approximate linear programming,
properties AVI undesirable application.
implemented small modifications basic weight update rule order use AVI
effectively setting; described Section 5 Online Appendix 1 (available JAIR
website).

3. Feature-Discovering Value-function Construction
planning, state features provided, domain-independent algorithms AVI learn
weighted combinations features often perform well heuristic estimates state value
(e.g., distance goal). describe methods select add features describe
state-space regions high inconsistency Bellman equation (statewise Bellman error)
approximate value iteration. methods applied using real-valued-feature hypothesis
space corresponding learning method selecting features match real-valued function
training set states. Here, use learner select features match statewise
Bellman error function.
noted above, use boosting style learning approach finding value functions, iterating
selecting weights generating new features focusing Bellman error
current value function. value function representation viewed weighted ensemble
single-feature hypotheses. start value function trivial feature, constant
feature always returning value one, initial weight zero. iteratively retrain
weights select new features matching regions states current weighted ensemble
high statewise Bellman error.
take learning small problems approach learn features first problems
relatively lower difficulty, increase problem difficulty time, discussed below. Lower
difficulty problems typically smaller state spaces and/or shorter paths positive
4. deriving gradient-descent weight-update formula, feature fi scaled ri =

696

q

n
,
ni

giving fi = ri fi .

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

r
Initial feature vector
r
Initial weight vector w
Initial problem difficulty

Difficulty
target level
time?

Yes

r
Final r
w



Increase problem
difficulty
r D. Keep
.

Learn new feature
correlating Bellman
error states
training
r set, add
. Keep current
problem difficulty D.

r
w

r

Select w approximately
minimizing
error
r Bellman
r
V = w

Done

Reweighted value
r r
function V = w

Yes

Performance
current difficulty
meets threshold?



Generate feature
training set

Figure 1: Control flow feature learning. Boxes double borders represent assumed subroutines method. assume problem distribution parameterized
problem difficulty (such problem size).

feedback (e.g. goal states). Learning initially difficult problems typically lead
inability find positive feedback random-walk behavior; result learning first lower
difficulty problems found effective (Martin & Geffner, 2004; Yoon, Fern, & Givan,
2002). show experimentally Section 7 good value functions high difficulty problems
indeed learned fashion problems lower, increasing difficulties.
approach relies two assumed subroutines, instantiated different ways
providing different algorithms subroutines. First, method weight selection assumed;
method takes input problem domain fixed set features, selects weight vector
value function problem domain using provided features. intend method
heuristically approximately minimize L Bellman error choice weight vector,
practice may easier adjust weights approximate L2 Bellman error. Second, feature
hypothesis space corresponding learner assumed provided system designer.
control flow approach shown Figure 1. iteration fixed problem
distribution selects weights current feature set (using method attempting minimize
L Bellman error) define new value function V , selects training set states feature
learning, learns new feature correlating well statewise Bellman error V , adding
feature feature set. user-provided performance-threshold function detects
increase problem difficulty. formalization control flow given Figure 2, form
pseudo-code.
697

fiW U & G IVAN

Feature-discovering Value-function Construction



Inputs:
Initial feature vector 0 , initial weight vector
w 0,
Sequence problem distributions D1 , D2 , , Dmax increasing difficulty,
Performance threshold function .
// (D, V ) tests performance value function V distribution D.



Outputs:
Feature vector , weight vector
w





0,
w
w 0, 1

1.

(d > max time)




Select
w approximately minimizing Bellman error V =
w Dd



(Dd ,
w )

2.
3.
4.
5.

+ 1

6.

else
Generate sequence training states using Dd

7.
8.
9.
10.




Learn new feature f correlating Bellman error feature B(
w , )
states






( ; f ),
w (
w ; 0)


return ,
w

Notes:
1. B(, ) statewise-Bellman error function, defined Section 2.1.
2. code approximate value iteration AVI, shown Online Appendix 1 (available JAIR website)
page 2, example implementation line 3.



3. code draw(Greedy(
w ), N
), shown Online Appendix 1 page 2, example impletraining

mentation line 7. Ntraining number states feature training set. Duplicated states removed
specified Section 3.1.



4. beam-search code learning relational features beam-search-learn(score(, T, B(
w , )))
example implementation line 8, beam-search-learn shown figure 3 Section 3, score
defined Section 4.2.

Figure 2: Pseudo-code learning set features.
experiments reported Section 7, evaluate following choices assumed
subroutines. experiments use AVI select weights feature sets. evaluate two
choices feature hypothesis space corresponding learner, one relational one propositional, described Section 4.
Separate training sets drawn weight selection feature learning; former
depend weight selection method, described AVI Section 2.5, latter
described section.
Problem difficulty increased sampled performance greedy policy current
difficulty exceeds user-specified performance thresholds. planning-domain experiments,
698

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

performance parameters measured success ratio (percentage trials find goal) average successful plan length (the average number steps goal among successful trials).
non-goal-oriented domains Tetris SysAdmin use different performance measures: average total reward Tetris Bellman error SysAdmin (to facilitate comparison Patrascu
et al., 2002).
also assume user-provided schedule problem difficulty increases problems
difficulty parameterized one parameter (e.g., size may measured number
objects type); domain-independent automation increase difficulty
topic future research. give difficulty-increase schedules performance thresholds
experiments section presenting experiments, Section 7.
3.1 Training Set Generation
training set selection new feature set states. training set constructed
repeatedly sampling example problem instance problem distribution current level
difficulty, applying current greedy policy Greedy(V ) problem instance create
trajectory states encountered. Every state (removing duplicates) encountered added
training set. size feature-selection training set maximum length training
trajectory specified user parameters algorithm.
Retaining duplicate states training set another option considered. preliminary empirical results favored option, certainly worth exploration.
note goal finding near-optimal value function necessarily make reference
state distribution: widely used notion near-optimal theory MDPs
sup-norm distance V . Moreover, state distribution represented duplicates
training sets typically distribution badly flawed policy; heeding distribution
prevent correcting Bellman error critical states visited policy, visited
rarely. (These states may be, instance, rarely visited good exits visited state region
misunderstood current value function.) point, primary justification
removing duplicates empirical performance demonstrated Section 7.
Similar reasoning would suggest removing duplicate states training sets AVI weight
training, described Section 2.5. many large AVI training sets generated
experiments, duplicate removal must carefully handled control runtime; historical reasons,
experiments shown include duplicate removal AVI.
possible problem occurs current greedy policy cannot reach enough states complete desired training set. 200 consecutive trajectories drawn without visiting new state
desired training set size reached, process modified follows. point,
method attempts complete training set drawing trajectories using random walk (again
using sampled example problems current problem distribution). process leads
200 consecutive trajectories without new state, method terminates training-set generation
uses current training set even though smaller target size.
3.2 Applicability Method
Feature-discovering value-function construction described require complete access
underlying MDP model. AVI updates training set generation based
following computations model:
699

fiW U & G IVAN

1. Given state ability compute action set A(s).
2. Given state s, action A(s), value function V , ability compute Q-value
Q(s, a, V ).
3. Given state action A(s), ability draw state next state distribution
defined (s, a, ).
4. Given state s, ability compute features selected feature language
computations state required selected feature learner. examples,
(a) Section 4, introduce relational feature language learner require knowledge set domain predicates (and arities) state conjunctive
set predicate facts (see Section 2.3),
(b) and, also Section 4, describe propositional feature language learner
require knowledge set propositional state attributes state truth
assignment attributes.
first three items enable computation Bellman update last item enables
computation estimated value function given weights features defining well
selection new features feature learner. requirements amount substantial access
problem model; result method must considered model-based technique.
consequence requirements algorithm cannot directly applied
standard reinforcement learning setting model access via acting world
without ability reset selected states; setting Bellman error computations particular
states cannot necessarily carried out. would possible construct noisy Bellman error
training set model-free setting would appropriate future work explore use
training set feature learning.
PPDDL planning domains studied provide information needed perform
computations, method also applies domains natural represent PPDDL.
analyzed method computations implemented. instance,
Tetris experiments Section 7.2, underlying model represented providing hand-coded
routines computations within domain.
3.3 Analysis
MDP value iteration guaranteed converge optimal value function conducted
tabular value-function representation presence discounting (Bertsekas, 1995). Although
weight selection AVI designed mimic value iteration, avoiding tabular representation,
general guarantee weight updates track value iteration thus converge
optimal value function. particular, may weighted combination features
represents optimal value function, likewise none represents Bellman update U(V )
value function V produced AVI weight training process. learning system introduces
new features existing feature ensemble response problem: training set used
select new feature pairs states statewise Bellman error. learned feature exactly
captures statewise Bellman-error concept (by exactly capturing training set generalizing
700

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

successfully) new feature space contain Bellman update value function used
generate training data.
aim find features approximate Bellman error feature, take
function mapping states statewise Bellman error. Theoretical properties Bellman error
features uncontrolled Markov processes (i.e., without max operator Bellman equation) recently discussed work Parr et al. (2007), addition
features (or close approximations thereof) proven reduce weighted L2 -norm distance best weight setting true (uncontrolled) value V , linear fixed-point
methods used train weights feature addition. Prior work (in Wu & Givan,
2005), parallel it, empirically exploring effects selecting Bellman
error features complex controlled case, leading results reported here.
clear simply add Bellman error feature directly, set corresponding weight one, resulting value function would desired Bellman update U(V )
current value function V . Adding features iteration would thus give us way
conduct value iteration exactly, without enumerating states. added feature would
describe Bellman error value function defined terms previously added features, posing
serious computational cost issue evaluating added features. particular, Bellman
error feature value function V estimated particular state high confidence
evaluating value function V state polynomial-sized sample next states
action (based Chernoff bounds).
However, value function V based upon previously added Bellman-error feature,
evaluation V requires sampling (again, possible action) compute.
manner, amount sampling needed high confidence grows exponentially number
successive added features type. levels sampling collapse one expectation
intervening choices actions, often case decision-theoretic sampling.
feature selection method attempt tractably approximate exact value iteration method
learning concise efficiently computable descriptions Bellman-error feature
iteration.
method thus viewed heuristic approximation exact value iteration. Exact
value iteration instance method obtained using explicit state-value table
feature representation generating training sets feature learning containing states
obtain exact value iteration would also omit AVI training instead set weight one.
feature language learner shown approximate explicit features tightly
enough (so resulting approximate Bellman update contraction L norm),
easy prove tightening approximations V result weights set one. However,
practical results experiments, use feature representations learners
approximation bound relative explicit features known.

4. Two Candidate Hypothesis Spaces Features
section describe two hypothesis spaces features, relational feature space
propositional feature space, along respective feature learning methods.
two feature spaces, assume learner provided training set states paired
statewise Bellman error values.
701

fiW U & G IVAN

Note two feature-space-learner pairs lead two instances general method
others easily defined defining new feature spaces corresponding learners.
paper empirically evaluate two instances presented here.
4.1 Relational Features
relational MDP defined terms set state predicates. state predicates basic
elements define feature-representation language. Below, define generalpurpose means enriching basic set state predicates. resulting enriched predicates
used predicate symbols standard first-order predicate logic. consider
formula logic one free variable feature, follows5 .
state relational MDP first-order interpretation. first-order formula one free
variable function states natural numbers maps state number
objects state satisfy formula. take first-order formulas real-valued
features normalizing real number zero onethis normalization done
dividing feature value maximum value feature take, typically
total number objects domain, smaller domains objects (and
quantifiers) typed. similar feature representation used work Fawcett (1996).
feature representation used relational experiments, learner describe
next subsection considers existentially quantified conjunctions literals (with one free
variable) features. space formulas thus effective feature space relational
experiments.
Example 4.1: Take Blocksworld table object example, on(x, y)
predicate domain asserts block x top object y,
may block table. possible feature domain described
on(x, y), first-order formula x one free variable. formula
means object immediately block object x,
essentially excludes table object block held arm (if any)
object set described feature. n blocks problems, un-normalized value
feature n states block held arm, n 1 states
block held arm.
4.1.1 E NRICHED P REDICATE ET
interesting examples possible enriched predicate set define. enrich
set state predicates P , add binary predicate p transitive closure form
predicate p+ predicates min-p max-p identifying minimal maximal elements
predicate. goal-based domains, recall problem representation (from Section 2.4)
includes, predicate p, goal version predicate called goal-p represent desired
state predicate p goal. Here, also add means-ends analysis predicate correct-p
represent p facts present current state goal.
So, objects x y, correct-p(x,y) true p(x, y) goal-p(x,y)
true. p+(x, y) true objects x connected path binary relation p. relation
max-p(x) true object x maximal element respect p, i.e., exists object
5. Generalizations allow multiple free variables straightforward unclear utility time.

702

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

p(x, y) true. relation min-p(x) true object x minimal element respect
p, i.e., exists object p(y, x) true.
formally define feature grammar Online Appendix 1 (available JAIR website)
page 3.
Example 4.1 (cont.): feature correct-on(x, y) means x stacked top
object current state goal state. feature on+(x, y)
means current state, x directly object y, i.e., sequence
relations traversing path x y, inclusively. feature max-on+(x)
means x table object block-towers placed table, since
table object object. feature min-on+(x) means
object top x, i.e., x clear.
4.2 Learning Relational Features
select first-order formulas candidate features using beam search beam width W .
present pseudo-code beam search Figure 3. search starts basic features derived
automatically domain description repeatedly derives new candidate features
best scoring W features found far, adding new features candidates keeping
best scoring W features times. new candidates added fixed depth times,
best scoring feature found overall selected added value-function representation.
Candidate features scored beam search correlation Bellman error feature
formalized below.
Specifically, score candidate feature f correlation coefficient Bellman
error feature B(V, ) estimated training set. correlation coefficient functions

(s)}
defined corr-coef(, ) = E{(s) (s)}E{(s)}E{
. Instead using known

distribution compute value, use states training set compute sampled
version using following equations approximate true expectation E true standard
deviation random variable X:
1 X
X(s ),
Es {X(s)} =
|s |


X,s =

corr-coef-sampled(, , ) =



1 X
(X(s ) E{X(s)})2 ,
|s |


Es {(s) (s)} Es {(s)}Es { (s)}
.
,s ,s

scoring function feature selection regularized version correlation coefficient
feature target function
score(f, , ) = |corr-coef-sampled(f, , )|(1 depth(f )),
depth feature depth beam search first occurs,
parameter learner representing degree regularization (bias towards low-depth features).
703

fiW U & G IVAN

beam-search-learn
Inputs:

Feature scoring function fscore : features [0, 1]

Outputs:

New feature f

System parameters:

W : Beam width
maxd : Max number beam-search iterations
: Degree regularization, defined Section 4.2

1.
2.
3.
4.
5.
6.
7.
8.

set basic features, defined Section 4.2.
1, F I.
repeat
Set beam B highest scoring W candidates F .
Candidate feature set F B.
candidate f1 B
candidate f2 (B I), f2 6= f1
F = F combine(f1 , f2 ).

9.
10.
11.

+ 1.
(d > maxd ) (highest score far (1 d)).
return maximum scoring feature f F .

Notes:
1. Feature scoring function fscore(f ) used rank candidates lines 4 11. discussion sample
scoring function, used relational experiments, given Section 4.2.
2. Candidate scores cached calls fscore, candidate scored twice.
3. value (1 d) largest score feature depth have.

Figure 3: Pseudo-code beam search.

value score(f, , B(V, )) score well feature f correlates Bellman error feature. Note features non-negative, still well correlated
Bellman error (which negative), presence constant feature representation allows non-negative feature shifted automatically needed.
remains specify features hypothesis space considered initial,
basic, features beam search, specify means constructing complex features
simpler ones use extending beam search. first take state predicate set P
domain enrich P described Section 4.1. enrichment P , take basic
features existentially quantified applications (possibly negated) state predicates variables
zero one free variable6 . grammar basic features defined follows.
6. domain distinguishes objects naming constants, allow constants arguments
predicates well.

704

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Definition: basic feature existentially quantified hliterali expression
one free variable (see Figure 3 Online Appendix 1, available JAIR website,
page 3).
feature free variables treated technically one-free-variable feature
variable used; results binary feature value either zero total number
objects, instantiating free variable different ways always results truth value.
assume throughout every existential quantifier automatically renamed away every
variable system. also take basic features human-provided features
may available, add features experiments paper order clearly
evaluate methods ability discover domain structure own.
stage beam search add new candidate features (retaining W best scoring
features previous stage). new candidate features created follows. feature
beam combined conjunctively other, basic feature. method combination two features described Figure 4. figure shows non-deterministic pseudo-code
combining two input features, way making non-deterministic choices results
new candidate feature. pseudo-code refers feature formulas f1 f2 describing
two features. places, formulas others written free variable exposed,
f1 (x) f2 (y). Also substitution variable notated replacing notation,
f1 (z).
combination conjoining feature formulas, shown line 2 Figure 4; however,
additional complexity resulting combining two free variables possibly equating
bound variables two features. two free variables either equated (by substitution) one existentially quantified combination done, line 1. two pairs
variables, chosen one contributing feature, may also equated, resulting
quantifier front, described line 3. Every combination feature candidate.
beam-search construction lead logically redundant features cases
syntactically redundant well. avoid syntactically redundant features end beam
search selecting highest scoring feature already feature set. Logical redundancy syntactic redundancy difficult detect. avoid redundancy
automatically using ordering beam search reduce generation symmetric expressions . However, testing logical equivalence features
language NP-hard (Chandra & Merlin, 1977), deploy complete equivalence test
here.
Example 4.2: Assume two basic features z p(x, z) w q(y, w). set
possible candidates generated combining two features are:
line 3 Figure 4 runs zero times,
1. (x z p(x, z)) (w q(y, w)), xf1 (x) f2 (y)
2. (z p(x, z)) (y w q(y, w)), f1 (x) yf2 (y),
3. (z p(x, z)) (w q(x, w)), f1 (x) f2 (x)
line 3 runs one time,
4. u ((z p(u, z)) (q(y, u))), equating x w item 1 above,
5. u (x p(x, u)) (q(y, u)), equating x z item 1 above,
705

fiW U & G IVAN

combine
Inputs:

Features f1 (x), f2 (y)

Outputs:

Set features {o1 }

return set features o1 result from:
1.

Perform one
a. f1 = (x)f1 (x)
b. f2 = (y)f2 (y)
c. f2 = f2 (x)

2.

o1 = f1 f2

3.

Perform following variable equating step zero, one, two times:
a. Let v variable occurring f1 o1 .
Let e1 expression form (v)1 (v) occurs o1
b. Let w variable occurring f2 o1 .
Let e2 expression form (w)2 (w) occurs o1
c. Let u new variable, used o1
d. o2 = replace e1 1 (u) replace e2 2 (u) o1
e. o1 = (u)o2

Notes:
1. choice 1a, 1b, 1c, choice number iterations step 3, choices e1 e2
steps 3a 3b non-deterministic choices.
2. feature produced run non-deterministic algorithm included set
features returned combine.
3. assumed f1 f2 variables common, renaming necessary operation.

Figure 4: non-deterministic algorithm combining two feature formulas.

6. u (p(x, u) (w q(u, w))), equating z item 2 above,
7. u (p(x, u) (y q(y, u))), equating z w item 2 above,
8. u (p(x, u) ( q(x, u))), equating z w item 3 above.
first three computed using cases 1a, 1b, 1c, respectively. remaining
five derive first three equating bound variables f1 f2 .
Features generated depth k language easily require enumerating k-tuples
domain objects. Since cost evaluation grows exponentially k, bound
706

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

maximum number quantifiers scope point feature formula q, refuse
consider feature violating bound.
values W , , d, q parameters controlling relational learner evaluate
paper. set parameters discussed experimental setup description
Section 6.
provide brief discussion motivations feature combination method. First,
note additive combination features represent disjunctions features7 ; hence,
consider conjunction feature combination. Here, chosen conjoin features
multiple ways, varying handling/combining free bound variables. believe
choice uniquely effective, provide example realization proposed featurediscovery architecture.
choice feature representation combination method must trade cost
evaluation choices potential gain quality selected features. Here,
chosen limit individual features conjunction; effectively, limited features
Horn clauses predicates negations, univariate heads.
4.3 Propositional Features
discuss second candidate hypothesis space features, using propositional representation. use decision trees represent propositional features. detailed discussion
classification using decision trees found book Mitchell (1997). decision tree
binary tree internal nodes labeled binary tests states, edges labeled yes
representing results binary tests, leaves labeled classes (in case, either zero
one). path tree root leaf label l identifies labeling set
stateseach state consistent state-test results path viewed labeled l tree.
way, decision tree real number labels leaves viewed labeling states
real numbers, thus feature.
learn decision trees training sets labeled states using well known C4.5 algorithm
(Quinlan, 1993). algorithm induces tree greedily matching training data root
down. use C4.5 induce new featuresthe key algorithm construct suitable
training sets C4.5 induced features useful reducing Bellman error.
include possible state tests decision trees induce every grounded predicate
application8 state predicates, well every previously selected decision-tree feature
(each binary test leaf labels zero one).
4.4 Learning Propositional Features
construct binary features, use sign Bellman error feature, magnitude. sign statewise Bellman error state serves indication whether
state undervalued overvalued current approximation, least respect exactly
representing Bellman update current value function. identify collection
undervalued states new feature, assigning appropriate positive weight feature
7. Representing disjunction overlapping features using additive combination done third feature
representing conjunction, using inclusion/exclusion negative weight conjunction.
8. grounded predicate application predicate applied appropriate number objects problem instance.

707

fiW U & G IVAN

increase value. Similarly, identifying overvalued states new feature assigning
negative weight decrease value. note domains interest generally
large state-space enumeration, need classification learning generalize notions
overvalued undervalued across state space training sets sample states.
enable method ignore states approximately converged, discard states
statewise Bellman error near zero either training set. Specifically, among states negative statewise Bellman error, discard state error closer zero median
within set; among states positive statewise Bellman error. sophisticated methods discarding training data near intended boundary considered
future research; often introduce additional parameters method. Here, seek
initial simple evaluation overall approach. discarding, define +
set remaining training pairs states positive statewise Bellman error,
likewise negative statewise Bellman error.
use + positive examples negative examples supervised
classification algorithm; case, C4.5 used. hypothesis space classification space
decision trees built tests selected primitive attributes defining state space
goal; case, also use previously learned features decision trees attributes.
concept resulting supervised learning treated new feature linear approximation architecture, initial weight zero.
intent, ideally, develop approximately optimal value function. value function
expected Bellman error many states, every state; however, low state-wise
error states contribute high sup-norm Bellman error. discarding training
states low statewise Bellman error reflects tolerance low error threshold
representing degree approximation sought. Note technical motivation selecting
features based upon Bellman error focuses reducing sup-norm Bellman error; given
motivation, interested finding exact boundary positive negative
Bellman error identifying states large magnitude Bellman error (so
large-magnitude error addressed feature addition).
observe limited need separately learn feature matching due
following representability argument. Consider binary feature F complement F ,
exactly one F F true state. Given presence constant feature feature
set, adding F F feature set yields set representable value functions (assigning
weight w F effect assigning weight w F adding w weight
constant feature).
4.5 Discussion
discuss generalization capability, learning time, heuristic elements feature
learning method.
4.5.1 G ENERALIZATION ACROSS VARYING OMAIN IZES
propositional feature space described varies size number objects relational
domain varied. result, features learned one domain size generally meaningful (or
even necessarily defined) domain sizes. relational approach is, contrast, able
generalize naturally different domains sizes. experiments report ability
708

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

propositional technique learn within domain size directly, attempt use
approach learning small problems gain performance large problems. major
limitation producing good results large domains.
4.5.2 L EARNING IME
primary motivation giving generalization domain sizes order employ propositional approach resulting learner use highly efficient, off-the-shelf classification
algorithms. learning times reported Section 7 show propositional learner learns new
features orders magnitude faster relational learner.
4.5.3 H EURISTIC E LEMENTS



ETHOD

mentioned earlier, algorithm heuristically approximates repeated addition Bellman
error features linear value-function approximation order carry value iteration. Also
mentioned earlier, value iteration guaranteed converge optimal value function.
However, due scale problems target, heuristic approximations required. discuss
motivations heuristic approximation employ briefly here.
First, compute exact Bellman error features. Instead, use machine learning fit
training set sample states Bellman error values. selection training set
done heuristically, using trajectories drawn current greedy policy. use on-policy
selection training data loosely motivated on-policy convergence results reinforcement
learning (Singh et al., 2000), serves focus training relevant states. (See Section 3.1.)
Second, relational instance feature framework, beam-search method use
select highest scoring relational feature (with best fit Bellman error) ad-hoc, greedy,
severely resource bounded. fit obtained Bellman error purely heuristic. provide
heuristic method machine learning problem example, intend future
research provide better relational learners resulting better planning performance. Heuristic
elements current method discussed Appendix A.3. work
viewed providing reduction stochastic planning structured machine learning numeric
functions. (See Section 3.)
Third, propositional instance feature framework,, learner C4.5 selects hypotheses greedily. Also, reduction C4.5 classification relies explicit tolerance approximation form threshold used filter training data near-zero Bellman error.
motivation approximation tolerance focus learner high Bellman error states
allow method ignore almost converged states. (See Section 4.4.)
Fourth, fundamental work use linear approximation value function
gradient-descent-based weight selection (in case AVI). approximation methods key
approach handling large state spaces create need feature discovery. AVI method
includes empirically motivated heuristic methods controlling step size sign changes
weights. (See Section 5 Online Appendix 1, available JAIR website.)
Fifth, rely human input select sequence problem difficulties encountered
feature discovery well performance thresholds problem difficulty increases.
believe aspect algorithm automated future research. (See Section 3.)
709

fiW U & G IVAN

5. Related Work
Automatic learning relational features approximate value-function representation surprisingly frequently studied quite recently, remains poorly understood. Here,
review recent work related one dimensions contribution.
5.1 Feature Selection Based Bellman Error Magnitude
Feature selection based Bellman error recently studied uncontrolled (policyevaluation) context work Keller et al. (2006) Parr et al. (2007), attribute-value
explicit state spaces rather relational feature representations. Feature selection based
Bellman error compared feature selection methods uncontrolled context
theoretically empirically work Parr, Li, Taylor, Painter-Wakefield, Littman
(2008).
Here, extend work controlled decision-making setting study incorporation
relational learning selection appropriate knowledge representation value functions
generalize problems different sizes within domain.
main contribution work Parr et al. (2007) formally showing, uncontrolled
case policy evaluation, using (possibly approximate) Bellman-error features provably tightens approximation error bounds, i.e., adding exact Bellman error-feature provably reduces
(weighted L2 -norm) distance optimal value function achieved optimizing weights linear combination features. result extended weaker form
approximated Bellman-error features, uncontrolled case. limitation uncontrolled case substantial difference setting work. limited experiments shown
use explicit state-space representations, technique learns completely new set features
policy evaluation conducted policy iteration. contrast, method accumulates
features value iteration, point limiting focus single policy. Constructing
new feature set policy evaluation procedure amenable formal analysis
retaining learned features throughout value iteration policy implicitly considered value iteration (the greedy policy) potentially changing throughout. However,
using relational feature learning, runtime cost feature learning currently high make
constructing new feature sets repeatedly practically feasible.
Parr et al. (2007) builds prior work Keller et al. (2006) also studied uncontrolled setting. work provides theoretical results general framework, provides
specific approach using Bellman error attribute value representations (where state represented real vector) order select new features. approach provides apparent leverage
problems state real vector, structured logical interpretation, typical
planning benchmarks.
5.2 Feature Discovery via Goal Regression
previous methods (Gretton & Thiebaux, 2004; Sanner & Boutilier, 2009) find useful features
first identifying goal regions (or high reward regions), identifying additional regions regressing action definitions previously identified regions. principle exploited
given state feature indicates value state, able achieve feature
one step also indicate value state. Regressing feature definition action
710

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

definitions yields definition states achieve feature one step. Repeated regression identify many regions states possibility transitioning
action sequence high-reward region.
exponentially many action sequences relative plan length,
exponentially many regions discovered way, well exponential increase size
representation region. exponentials terms number regression steps
taken. control exponential growth number features considered, regression
implemented pruning optimizations control eliminate overlap regions
detected inexpensively well dropping unlikely paths. However, without scoring
technique (such fit Bellman-error used paper) select features, regression still
generates large number useless new features. currently effective regression-based
first-order MDP planner, described work Sanner Boutilier (2009), effective
disallowing overlapping features allow optimizations weight computation. Yet clearly
human-designed feature sets fact overlapping features.
inductive technique avoids issues considering compactly represented features,
selecting match sampled statewise Bellman error training data. provide extensive
empirical comparison First-Order Approximate Linear Programming technique (FOALP)
work Sanner Boutilier (2009) empirical results. empirical evaluation
yields stronger results across wide range probabilistic planning benchmarks goalregression approach implemented FOALP (although aspects approaches
goal-regression candidate generation vary comparison well).
Regression-based approaches feature discovery related method fitting Bellman
error exploit fact states reach valuable states must valuable, i.e. seek local consistency. fact, regression goal viewed special
case iteratively fitting features Bellman error current value function. Depending
exact problem formulation, k, Bellman error k-step-to-go value function
non-zero (or otherwise nontrivially structured) region states reach goal first
k + 1 steps. Significant differences Bellman error approach regression-based
feature selection arise states reach goal different probabilities different
horizons. approach fits magnitude Bellman error, smoothly consider
degree state reaches goal horizon. approach also immediately generalizes setting useful heuristic value function provided automatic feature
learning, whereas goal-regression approach appears require goal regions begin regression.
spite issues, believe approaches appropriate valuable
considered important sources automatically derived features future work.
Effective regression requires compact declarative action model, always available9 .
inductive technique present require even PDDL action model, deductive component computation Bellman error individual states. representation
statewise Bellman error computed sufficient technique. empirical results show performance planner Tetris, model represented
giving program that, given state input, returns explicit next state distribution
state. FOALP inapplicable representations due dependence logical deductive rea9. example, Second International Probabilistic Planning Competition, regression-based FOALP planner
required human assistance domain providing needed domain information even though standard
PDDL model provided competition sufficient planner.

711

fiW U & G IVAN

soning. believe inductive deductive approaches incorporating logical representation
important complementary.
goal regression approach special case general approach generating candidate features transforming currently useful features. Others considered include
abstraction, specialization, decomposition (Fawcett, 1996). Research human-defined concept transformations dates back least landmark AI program (Davis & Lenat, 1982).
work uses one means generating candidate features: beam search logical formulas
increasing depth. means candidate generation advantage strongly favoring concise inexpensive features, may miss complex accurate/useful features.
approach directly generalizes means generating candidate features.
centrally distinguishes approach previous work leveraging feature transformations
use statewise Bellman error score candidate features. FOALP (Sanner & Boutilier, 2006,
2009) uses scoring function, includes non-pruned candidate features linear program
used find approximately optimal value function; Zenith system (Fawcett, 1996) uses
scoring function provided unspecified critic.
5.3 Previous Scoring Functions MDP Feature Selection
method, work Patrascu et al. (2002), selects features estimating minimizing
L1 error value function results retraining weights candidate feature
included. L1 error used work instead Bellman error difficulty retraining
weights minimize Bellman error. method focuses fitting Bellman error
current approximation (without retraining new feature), avoids expensive
retraining computation search able search much larger feature space effectively.
work Patrascu et al. (2002) contains discussion relational representation, L1
scoring method could certainly used features represented predicate logic; work date
tried (potentially expensive) approach.
5.4 Related Work
include discussion additional, distantly related research directions Appendix A, divided following subsections:
1. relevant feature selection methods (Fahlman & Lebiere, 1990; Utgoff & Precup, 1997,
1998; Rivest & Precup, 2003; Mahadevan & Maggioni, 2007; Petrik, 2007);
2. Structural model-based model-free solution methods Markov decision processes, including
(a) Relational reinforcement learning (RRL) systems (Dzeroski, DeRaedt, & Driessens,
2001; Driessens & Dzeroski, 2004; Driessens et al., 2006),
(b) Policy learning via boosting (Kersting & Driessens, 2008),
(c) Fitted value iteration (Gordon, 1995),
(d) Exact value iteration methods first-order MDPs (Boutilier, Reiter, & Price, 2001;
Holldobler & Skvortsova, 2004; Kersting, Van Otterlo, & De Raedt, 2004);
712

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

3. Inductive logic programming algorithms (Muggleton, 1991; Quinlan, 1996; Karalic & Bratko,
1997);
4. Approximate policy iteration relational domains (Fern et al., 2006), discussion
relational decision-list-policy learners (Khardon, 1999; Martin & Geffner, 2004; Yoon et al.,
2002);
5. Automatic extraction domain knowledge (Veloso, Carbonell, Perez, Borrajo, Fink, &
Blythe, 1995; Kambhampati, Katukam, & Qu, 1996; Estlin & Mooney, 1997; Fox & Long,
1998; Gerevini & Schubert, 1998).

6. Experimental Setting
present experiments nine stochastic planning domains, including reward-oriented
goal-oriented domains. use Pentium 4 Xeon 2.8GHz machines 3GB memory. section, give general overview experiments giving detailed results discussion
individual domains Section 7. Here, first, briefly discuss selection evaluation domains
Section 6.1. Second, Section 6.2 set evaluation relational feature learner
comparison variants replace key aspects algorithm random choice determine
importance. Additional details, including many experimental parameter settings, found
Online Appendix 1 (available JAIR website) Section 3.
6.1 Domains Considered
evaluation domains below, necessary specify discount factor modeling
domain MDP discounting. discount factor effectively specifies tradeoff
goals reducing expected plan length increasing success rate. parameter
method, domain studied, feature-learning method applied
choice . Here, simplicity, choose 0.95 throughout experiments. note
discount factor used YS DMIN domain formalization compare
previous work Patrascu et al. (2002).
6.1.1 ETRIS
Section 7.2 evaluate performance relational propositional learners using
stochastic computer-game ETRIS, reward-oriented domain goal player
maximize accumulated reward. compare results performance set handcrafted features, performance randomly selected features.
6.1.2 P LANNING C OMPETITION OMAINS
Section 7.3, evaluate performance relational learner seven goal-oriented planning domains two international probabilistic planning competitions (IPPCs) (Younes et al.,
2005; Bonet & Givan, 2006). comparison purposes, evaluate performance propositional learner two seven domains (B LOCKSWORLD variant B OXWORLD described
below). Results two domains illustrate difficulty learning useful propositional features complex planning domains. also compare results relational planner
two recent competition stochastic planners FF-Replan (Yoon et al., 2007) FOALP (Sanner &
713

fiW U & G IVAN

Boutilier, 2006, 2009) performed well planning competitions. Finally,
compare results obtained randomly selecting relational features tuning weights
them. complete description of, PPDDL source for, domains used, please see
work Younes et al. (2005) Bonet Givan (2006).
Every goal-oriented domain problem generator first second IPPC considered inclusion experiments. inclusion, require planning domain fixed
action definitions, defined Section 2.4, addition ground conjunctive goal regions. Four domains properties directly, adapted three domains
properties:
1. B OXWORLD, modify problem generator goal region always ground
conjunctive expression. call resulting domain C ONJUNCTIVE -B OXWORLD.
2. F ILEWORLD, construct obvious lifted version, create problem generator restricted three folders domain action definitions vary number
folders. call resulting domain L IFTED -F ILEWORLD 3.
3. OWERS H ANOI, create problem generator.
resulting selection provides seven IPPC planning domains empirical study. provide
detailed discussions adapted domains Section 2 Online Appendix 1 (available JAIR
website), well discuss reasons exclusion domains.
6.1.3 YS DMIN
conclude experiments comparing propositional learner previous method Patrascu et al. (2002), using YS DMIN domain used evaluation there. empirical
comparison YS DMIN domain shown Section 7.4.
6.2 Randomized Variants Method
major contribution introduction evaluation feature learning framework
controlled setting based scoring Bellman-error (BE Scoring). empirical work instantiates framework relational feature-learning algorithm design based greedy
beam-search. Here, compare performance instance framework variants
replace key aspects randomized choice, illustrating relative importance features. two random-choice experiments, adapt method one following two
ways:
1. Labeling training states random scores instead Bellman Error scores. target
value feature training set random number -1 1. algorithm called
Random Scoring.
2. Narrowing beam search randomly rather greedily. eliminate scoring beam search, instead using random selection narrow beam; end
beam search scoring used select best resulting candidate. algorithm called
Random Beam Narrowing.
714

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

original algorithm, labels training data Bellman error narrows beam greedily rather randomly, called Greedy Beam Search/BE Scoring plots.
comparisons, consider relational feature representation, beam
search method used. Experiments two variants introduced here, presented
Sections 7.2.4 7.3.4, show original method selects features perform much better
randomly selected features, greediness beam search often (but always)
important achieving good performance.

7. Experimental Results
present experimental results ETRIS, planning competition domains, YS DMIN
section, starting introduction structure result presentation.
7.1 Read Results
task evaluating feature-learning planning system subtle complex. particularly
factor relational case generalization problem sizes learning small
problems must evaluated. resulting data extensive highly structured, requiring
training reader understand interpret. introduce reader structure
results.
experiments propositional learning (or randomly selected propositional features), problem size never varies within one run learner, propositional representation Section 4.3 cannot generalize sizes. run separate experiment
size considered. experiment two independent trials; trial starts single trivial
feature repeatedly adds features termination condition met. feature addition, AVI used select weights combining features form value function,
performance value function measured (by sampling performance greedy policy).
compute average (of two trials) performance function number
features used. Since results single line plot performance function number
features, several different fixed-problem-size learners compared one figure, one
line each, done example Figures 7 14. performance measure used varies
appropriately domain presented below.
study ability relational representation Section 4.1 generalize sizes.
study properly understood backdrop flowchart Figure 1.
described flowchart, one trial learner learn sequence features encounter
sequence increasing problem difficulties. One iteration learner either add new
feature increase problem difficulty (depending current performance). either case,
weights retrained AVI performance measurement resulting greedy policy
taken. different trials may increase size different points, cannot meaningfully
average measurements two trials. Instead, present two independent trials separately
two tables, Figures 5 12. first trial, also present data
second time line plot showing performance function number features, problem
size changes annotated along line, plots Figures 6 13. Note success
ratio generally increases along line features added, falls problem size
increased. (In ETRIS, however, measure rows erased rather success ratio, rows
715

fiW U & G IVAN

erased generally increases either addition new feature addition new rows
available grid.)
interpret tables showing trials relational learner, useful focus first
two rows, labeled # features Problem difficulty. rows, taken together, show
progress learner adding features increasing problem size. column table
represents result indicated problem size using indicated number learned features.
one column next, change one rowsif performance
policy shown column high enough, problem difficulty increases,
otherwise number features increases. adding subtlety interpreting tables, note several adjacent columns increase number features,
sometimes splice two columns save space. Thus, several features
added consecutively one problem size, slowly increasing performance, may show
first last columns problem size, consequent jump number
features columns. likewise sometimes splice columns several consecutive columns increase problem difficulty. found splicings save space
increase readability practice reading tables.
Performance numbers shown column (success ratio average plan length, number
rows erased, ETRIS) refer performance weight-tuned policy resulting
feature set problem difficulty. also show column performance value
function (without re-tuning weights) target problem size. Thus, show quality measures
policy found feature learning current problem size point
target problem size, illustrate progress learning small problems target size
via generalization.
study problem deciding stop adding features. Instead,
propositional relational experiments, trials stopped experimenter judgment additional results expensive value giving evaluating algorithm. However,
stop trials still improving unless unacceptable resource consumption
occurred.
Also, trial, accumulated real time trial measured shown point
trial. use real time rather CPU time reflect non-CPU costs paging due
high memory usage.
7.2 Tetris
present experimental results ETRIS.
7.2.1 OVERVIEW



ETRIS

game ETRIS played rectangular board area, usually size 10 20, initially
empty. program selects one seven shapes uniformly random player rotates
drops selected piece entry side board, piles onto remaining fragments
pieces placed previously. implementation, whenever full row squares
occupied fragments pieces, row removed board fragments top
removed row moved one row; reward also received row removed.
process selecting locations rotations randomly drawn pieces continues board
full new piece cannot placed anywhere board. ETRIS stochastic since
716

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

next piece place always randomly drawn, stochastic element
game. ETRIS also used experimental domain previous MDP reinforcement learning
research (Bertsekas & Tsitsiklis, 1996; Driessens et al., 2006). set human-selected features
described book Bertsekas Tsitsiklis (1996) yields good performance
used weighted linearly approximated value functions. cannot fairly compare performance
domain probabilistic planners requiring PPDDL input found natural
PPDDL definition ETRIS.
performance metric ETRIS number rows erased averaged 10,000 trial
games. reward-scaling parameter rscale (defined Section 5 Online Appendix 1 page 8)
selected 1.
7.2.2 ETRIS R ELATIONAL F EATURE L EARNING R ESULTS
represent ETRIS grid using rows columns objects. use three primitive predicates:
fill(c, r), meaning square column c, row r occupied; below(r1 , r2 ), meaning row
r1 directly row r2 ; beside(c1 , c2 ), meaning column c1 directly left
column c2 . quantifiers used relational ETRIS hypothesis space typed using types
row column.
also state predicates representing piece drop; however, efficiency
reasons planner computes state value function grid, next piece.
limitation value-function expressiveness allows significantly cheaper Bellman-backup computation. one-step lookahead greedy policy execution provides implicit reasoning
piece dropped, piece grid next states.
conduct relational ETRIS experiments 10-column, n-row board, n initially
set 5 rows. threshold increasing problem difficulty adding one row score
least 15 + 20(n 5) rows erased. target problem size experiments 20 rows.
results relational ETRIS experiments given Figures 5 6 discussed below.
7.2.3 ETRIS P ROPOSITIONAL F EATURE L EARNING R ESULTS
propositional learner, describe ETRIS state 7 binary attributes represent
7 pieces currently dropped, along one additional binary attribute
grid square representing whether square occupied. adjacency relationships
grid squares represented procedurally coded action dynamics. Note
number state attributes depends size ETRIS grid, learned features
apply problems grid size. result, show separate results selected problem
sizes.
evaluate propositional feature learning 10-column ETRIS grids four different sizes: 5
rows, 7 rows, 9 rows, 20 rows. Results four trials shown together Figure 7
average accumulated time required reach point Figure 7 shown Figure 8.
results discussed below.
7.2.4 E VALUATING MPORTANCE B ELLMAN - ERROR CORING G REEDY
B EAM - SEARCH ETRIS
Figure 9 compares original algorithm alternatives vary either training set
scoring greediness beam search, discussed Section 6.2. two alternatives, use
717

fiW U & G IVAN

Trial #1
# features
Problem difficulty
Score
Accumulated time (Hr.)
Target size score

0
5
0.2
0.0
0.3

1
5
0.5
2
1.3

2
5
1.0
4.2
1.4

3
5
3.0
5.2
1.8

11
5
18
20
178

11
6
31
21
238

12
6
32
24
261

17
6
35
39
176

17
7
55
42
198

18
7
56
46
211

18
8
80
50
217

18
9
102
57
221

18
10
121
65
220

18
15
234
111
268

18
20
316
178
317

Trial #2
# features
Problem difficulty
Score
Accumulated time (Hr.)
Target size score

0
5
0.2
0.0
0.3

1
5
0.6
2.4
1.7

8
5
16
15
104

8
6
28
15
113

12
6
36
27
108

12
7
53
29
116

14
7
56
39
130

14
11
133
66
192

15
11
136
76
196

15
12
151
87
199

16
12
156
97
206

16
13
167
103
211

17
13
168
110
211

26
13
175
211
219

26
14
192
220
225

27
14
210
236
218

27
17
238
276
231

28
17
251
295
231

29
17
240
318
233

33
17
241
408
231

Figure 5: ETRIS performance (averaged 10,000 games). Score shown average rows
erased, problem difficulty shown number rows ETRIS board.
number columns always 10. Difficulty increases average score greater
15+20*(n-5), n number rows ETRIS board. Target problem
size 20 rows. columns omitted discussed Section 7.1.

Average Rows Erased

Tetris, Relational, Trial 1
350
300
250
200
150
100
50
0

1020
1015

106

106

105

105
0

1010
107

2

4

6

8

10

12

14

16

18

Number Features

Figure 6: Plot average number lines erased 10,000 ETRIS games run
AVI training learning relational features (trial 1). Vertical lines indicate
difficulty increases (in number rows), labeled along plot.

718

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Average Rows Erased

Tetris, Propositional
14
12
10
8
6
4
2
0
0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50

Number Features
105

107

109

1020

Figure 7: Plot average number lines erased 10,000 ETRIS games iteration
AVI training learning propositional features, averaged two trials.

Accumulated Time (Hr.)

Tetris, Propositional
160
140
120
100
80
60
40
20
0
0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50

Number Features
105

107

109

1020

Figure 8: Plot accumulated time required reach point Figure 7, averaged two
trials.

schedule used original Greedy Beam Search/BE Scoring algorithm ETRIS
starting 10 5 problem size. However, performance two alternatives never
good enough increase problem size.
7.2.5 E VALUATING H UMAN - DESIGNED F EATURES ETRIS
addition evaluating relational propositional feature learning approach, also evaluate
human-selected features described book Bertsekas Tsitsiklis (1996) perform
selected problem sizes. problem size, start weights zero use AVI
719

fiW U & G IVAN

Average Rows Erased

Impact Greedy Beam Search Scoring
18
16
14
12
10
8
6
4
2
0
0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50

Number Relational Features
Greedy Beam Search/BE Scoring (original algorithm)
Random Scoring (variant 1)
Random Beam Narrowing (variant 2)

Figure 9: Plot average number lines erased 10,000 ETRIS games relational features
learned original algorithm two alternatives discussed Section 6.2.
Random Scoring Random Beam Narrowing, results averages two
independent trials. Trials two variants terminated fail make
progress several feature additions. comparison purposes, trial one original
Greedy Beam Search/BE Scoring method shown, reaching threshold difficulty
increase eleven feature additions (trial two even better).

Average rows erased, Trial 1
Average rows erased, Trial 2

10 5 10 7 10 9 10 20
19
86
267 17,954
19
86
266 18,125

Figure 10: average number lines erased 10,000 ETRIS games best weighted
combination human features found two trials AVI four problem
sizes.

process described Section 2.5 train weights 21 features performance appears
30
3
1+k/100
human-designed features
converge. change learning rate 1+k/100
require larger step-size converge rapidly. human-designed features normalized
value 0 1 experiments. run two independent trials problem size
report performance best-performing weight vector found trial, Figure 10.
7.2.6 P ERFORMANCE C OMPARISON B ETWEEN IFFERENT PPROACHES



ETRIS

Several general trends emerge results ETRIS. First all, addition new learned
features almost always increasing performance resulting tuned policy (on current
size target size), best performance point reached. suggests fact
720

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Relational Prop. 10 5 Prop.10 7 Prop.10 9 Prop.10 20
Average feature learning
time (Min.)

167

44

52

60

44

Figure 11: Table average feature learning time relational propositional approaches.
selecting useful features. also find clear evidence ability relational representation
usefully generalize problem sizes: substantial performance developed target
problem size without ever training directly size.
find best performance learned propositional features much lower
learned relational features problem sizes shown here, even though larger feature training set
size many learned features used propositional approach. suggests
rich relational representation indeed able better capture dynamics ETRIS
propositional representation.
find performance using random features ETRIS significantly worse
using learned features, demonstrating performance improvements feature learning
due useful feature selection (using Bellman error), simply due increasing number
features.
learned relational feature performance 10 20 ETRIS far worse obtained
using human-selected features AVI size. However, 10 5 ETRIS
relational feature performance close human-designed features. human-designed
features engineered perform well 10 20 ETRIS hence concepts useful
performing well smaller problem sizes may exist features.
7.2.7 IME L EARN E ACH F EATURE
Figure 11 show average time required learn relational feature propositional feature
ETRIS.
time required learn relational feature significantly longer required learn
propositional feature, even though propositional approach larger feature training set size
used.
7.2.8 C OMPARISON



P REVIOUS ETRIS - SPECIFIC L EARNERS

evaluating domain-independent techniques ETRIS, must first put aside strong performance already shown many times literature domain-dependent techniques domain.
Then, must face problem published domain-independent comparison points
order define state-of-the-art target surpass. latter problem, provide baseline
two different approaches random feature selection, show targeted feature selection dramatically improves random selection. former problem, include
discussion domain-specific elements key previous published results ETRIS.
many previous domain-specific efforts learning play ETRIS (Bertsekas
& Tsitsiklis, 1996; Szita & Lorincz, 2006; Lagoudakis, Parr, & Littman, 2002; Farias & Van Roy,
2004; Kakade, 2001). Typically, provide human-crafted domain-dependent features, deploy domain-independent machine learning techniques combine features (often tuning
721

fiW U & G IVAN

weights linear combination). example, domain-specific feature counting number
covered holes board frequently used. feature plausibly derived human
reasoning rules game, realizing holes difficult fill later
action lead low scores. prior work, selection feature hand,
automated feature-selection process (such scoring correlation Bellman error).
frequently used domain-specific features include column height difference height adjacent columns, apparently selected relevant human reasoning rules
game.
key research question address, then, whether useful features derived automatically, decision-making situation like ETRIS approached domain-independent
system without human intervention. method provided domain-state representation using primitive horizontal vertical positional predicates, single constant feature.
knowledge, research published evaluation ETRIS rely
domain-specific human inputs discussed. expected, performance
ETRIS much weaker achieved domain-specific systems cited.
7.3 Probabilistic Planning Competition Domains
Throughout evaluations learners planning domains, use lower plan-length cutoff
1000 steps evaluating success ratio iterative learning features, speed learning.
use longer cutoff 2000 steps final evaluation policies comparison
planners evaluations target problem size. reward-scaling parameter rscale
(defined Section 5 Online Appendix 1 page 8) selected 1 throughout planning
domains.
domains multi-dimensional problem sizes, remains open research problem
change problem size different dimensions automatically increase difficulty learning.
Here, C ONJUNCTIVE -B OXWORLD Z ENOTRAVEL, hand-design sequence increasing problem sizes.
discussed Section 6.1.2, evaluate feature learners total seven probabilistic planning competition domains. following paragraphs, provide full discussion
B LOCKSWORLD C ONJUNCTIVE -B OXWORLD, abbreviated results five domains. provide full discussion five domains Appendix B.
relational feature learner finds useful value-function features four domains
(B LOCKSWORLD, C ONJUNCTIVE -B OXWORLD, IREWORLD, L IFTED -F ILEWORLD 3).
three domains (Z ENOTRAVEL, E XPLODING B LOCKSWORLD, OWERS H ANOI),
relational feature learner makes progress representing useful fixed-size value function
training sizes, fails find features generalize well problems larger sizes.
7.3.1 B LOCKSWORLD
probabilistic, non-reward version B LOCKSWORLD first IPPC, actions pickup
putdown small probability placing handled block table object instead
selected destination.
relational learner, start 3 blocks problems. increase n blocks n + 1
blocks whenever success ratio exceeds 0.9 average successful plan length less
30(n 2). target problem size 20 blocks. Results shown Figures 12 13.
722

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Trial #1
# features
Problem difficulty
Success ratio
Plan length
Accumulated time (Hr.)
Target size SR
Target size Slen.

0
1
2
2
3
3
3
3
3
3
3
4
4
5
10
15
1.00 1
1 0.95 1
1
1 0.97
89 45 20 133 19
33 173 395
0.5 1.0 1.5 2.2 3.3 3.9 10
36
0
0
0
0 0.98 0.96 0.98 0.97




761 724 754 745

Trial #2
# features
Problem difficulty
Success ratio
Plan length
Accumulated time (Hr.)
Target size SR
Target size Slen.

0
3
1
80
0.5
0


1
2
2
3
3
3
3
3
3
4
4
5
10
15
1
1 0.94 1
1
1 0.96
48 19 125 17
34 167 386
1.0 1.4 2.0 3.3 3.8 9.4 33
0
0
0 0.97 0.98 0.98 0.98



768 750 770 741

Figure 12: B LOCKSWORLD performance (averaged 600 problems) relational learner.
add one feature per column success ratio exceeds 0.9 average successful plan
length less 30(n 2), n blocks, increase problem difficulty
next column. Plan lengths shown successful trials only. Problem difficulties
measured number blocks, target problem size 20 blocks. columns
omitted discussed Section 7.1.

propositional learner, results problem sizes 3, 4, 5, 10 blocks shown
Figure 14.
relational learner consistently finds value functions perfect near-perfect success
ratio 15 blocks. performance compares favorably recent RRL (Driessens
et al., 2006) results deterministic B LOCKSWORLD, goals severely restricted to,
instance, single atoms, success ratio performance around 0.9 three ten blocks
(for single goal) still lower achieved here. results B LOCKSWORLD show
average plan length far optimal. observed large plateaus induced value
function: state regions states given value greedy policy wanders.
problem merits study understand feature-induction break
plateaus. Separately, studied ability local search break plateaus (Wu,
Kalyanam, & Givan, 2008).
performance target size clearly demonstrates successful generalization sizes
relational representation.
propositional results demonstrate limitations propositional learner regarding lack
generalization sizes. good value functions induced small
problem sizes (3 4 blocks), slightly larger sizes 5 10 blocks render method ineffective.
10 block problems, initial random greedy policy cannot improved never finds
723

fiW U & G IVAN

Success Ratio

Blocksworld, Relational, Trial 1
3 blocks

1

3 blocks

3 blocks

4, 5, 10 blocks
15 blocks

0.95
4 blocks
0.9
0.85
0.80

Successful Plan Length

0

1

2

400

3
15 blocks

300
200
3 blocks

100

3 blocks

4 blocks

10 blocks

3 blocks

5 blocks
4 blocks

0
0

1

2

3

Number Features

Figure 13: B LOCKSWORLD success ratio average successful plan length (averaged 600
problems) first trial Figure 12 using relational learner.

goal. addition, results demonstrate learning additional features good policy
found degrade performance, possibly AVI performs worse higher dimensional
weight space results.
7.3.2 C ONJUNCTIVE -B OXWORLD
probabilistic, non-reward version B OXWORLD first IPPC similar
familiar Logistics domain used deterministic planning competitions, except explicit connectivity graph cities defined. Logistics, airports aircraft play important role
since possible move trucks one airport (and locations adjacent it) another airport (and locations adjacent it). B OXWORLD, possible move boxes
without using aircraft since cities may connected truck routes. stochastic
element introduced domain truck moved one city another,
small chance ending unintended city. described Section 6.1, use
C ONJUNCTIVE -B OXWORLD, modified version B OXWORLD, experiments.
start 1-box problems relational learner increase n boxes n + 1 boxes
whenever success ratio exceeds 0.9 average successful plan length better 30n.
feature-learning problem difficulties use 5 cities. use two target problem sizes: 15 boxes
724

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Blocksworld, Propositional

Success Ratio

1
0.8
0.6
0.4
0.2

Successful Plan Length

450
400
350
300
250
200
150
100
50
0

Accumulated Time (Hr.)

0

90
80
70
60
50
40
30
20
10
0

0

2

4

6

8

10

0

2

4

6

8

10

0

2

4

6

8

10

Number Features

3 blocks

4 blocks

5 blocks

10 blocks

Figure 14: B LOCKSWORLD performance success ratio average successful plan length (averaged 600 problems), accumulated run-time propositional learner, averaged two trials.

725

fiW U & G IVAN

Trial #1
# features
0
1
2
Problem difficulty
1
1
1
Success ratio
0.97 1
1
Plan length
226 84 23
Accumulated time (Hr.) 7.2 10 13
0.98 1
1
Target size #1 SR
Target size #1 Slen.
1056 359 93
Target size #2 SR
0.16 0.90 0.97
Target size #2 Slen.
1583 996 238

2
2
1
37
14
1
91
0.97
230

2
3
1
44
16
1
90
0.96
233

2
5
1
54
21
1
92
0.98
244

2
10
1
77
42
1
90
0.96
240

2
11
1
80
49
1
92
0.98
238

2
12
1
313
57
1
355
0.90
1024

2
13
1
87
65
1
90
0.98
240

2
15
1
92
84
1
91
0.96
239

Trial #2
# features
0
1
2
Problem difficulty
1
1
1
Success ratio
0.97 1
1
Plan length
235 85 24
Accumulated time (Hr.) 7.3 11 14
Target size #1 SR
0.96 1
1
1019 365 90
Target size #1 Slen.
Target size #2 SR
0.19 0.9 0.97
Target size #2 Slen.
1574 982 226

2
2
1
34
16
1
91
0.97
230

2
3
1
43
18
1
91
0.98
233

2
5
1
54
23
1
92
0.98
233

2
9
1
72
39
1
89
0.97
242

2
10
1
299
45
1
359
0.92
1006

2
11
1
80
51
1
89
0.98
231

2
12
1.00
310
60
1
363
0.91
1026

2
13
1
84
68
1
90
0.97
240

2
15
1
91
86
1
90
0.96
233

Figure 15: C ONJUNCTIVE -B OXWORLD performance (averaged 600 problems). add one
feature per column success ratio greater 0.9 average successful plan
length less 30n, n boxes, increase problem difficulty next
column. Problem difficulty shown number boxes. Throughout learning
process number cities 5. Plan lengths shown successful trials only. Two
target problem sizes used. Target problem size #1 15 boxes 5 cities. Target
problem size #2 10 boxes 10 cities. columns omitted discussed
Section 7.1.

5 cities, 10 boxes 10 cities. Relational learning results shown Figures 15 16,
results propositional learner 5 cities 1, 2, 3 boxes shown Figures 17.
interpreting C ONJUNCTIVE -B OXWORLD results, important focus average
successful plan-length metric. C ONJUNCTIVE -B OXWORLD problems, random walk able
solve problem nearly always, often long plans10 . learned features enable
direct solutions reflected average plan-length metric.
two relational features required significantly improved performance problems
tested. Unlike domains evaluate, C ONJUNCTIVE -B OXWORLD domain
10. note that, oddly, IPPC competition domain used action preconditions prohibiting moving box away
destination. preconditions bias random walk automatically towards goal. consistency
competition results, retain odd preconditions, although preconditions necessary good
performance algorithm.

726

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Success Ratio

Conjuctive-Boxworld, 5 Cities, Relational, Trial 1
1 box

1

1, 2, 3, 5, 10, 15 boxes

1 box

0.95
0.90
0

1

2

250

Successful Plan Length

1 box
200
150
100

15 boxes
10 boxes

1 box
5 boxes
3 boxes

50

2 boxes
1 box

0
0

1

2

Number Features

Figure 16: C ONJUNCTIVE -B OXWORLD success ratio average successful plan length (averaged
600 problems) first trial using relational learner.

learned features straightforwardly describable English. first feature counts many
boxes correctly target city. second feature counts many boxes trucks.
note lack features rewarding trucks right place (resulting
longer plan lengths due wandering value-function plateaus). features easily written knowledge representation (e.g. count trucks located cities destinations
package truck), require quantification cities packages. severe
limitation quantification currently method efficiency reasons prevents consideration
features point. also worth noting regression-based feature discovery, studied work Gretton Thiebaux (2004) Sanner Boutilier (2009), expected
identify features regarding trucks regressing goal action unloading
package destination. Combining Bellman-error-based method regression-based
methods promising future direction.
Nevertheless, relational learner discovers two concise useful features dramatically
reduce plan length relative initial policy random walk. significant success
automated domain-independent induction problem features.
727

fiW U & G IVAN

Conjunctive-Boxworld, Propositional

Success Ratio

1
0.8
0.6
0.4
0.2

Successful Plan Length

0
0

2

4

6

8

10

0

2

4

6

8

10

0

2

4

6

8

10

500
450
400
350
300
250
200
150
100
50
0

Accumulated Time (Hr.)

450
400
350
300
250
200
150
100
50
0

Number Features
1 box

2 box

3 box

Figure 17: C ONJUNCTIVE -B OXWORLD performance (averaged 600 problems) accumulated run-time propositional learner, averaged two trials. Throughout learning process number cities 5.

728

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

One trial relational feature learner C ONJUNCTIVE -B OXWORLD takes several days,
even though fixed number cities training problems five cities. New techniques required improving efficiency feature learning provide results
training larger numbers cities. results demonstrate current representation
learning methods adequately manage small city graphs even larger larger numbers
boxes deliver, resulting value functions successfully generalize 10-city problems.
domain, well known weakness AVI apparent. AVI often works practice,
theoretical guarantee quality weight vector found AVI training. (Alternatively, approximate linear programming step could replace AVI training provide
expensive perhaps robust weight selection.) C ONJUNCTIVE -B OXWORLD results,
AVI training goes astray selecting weights 12 box domain size Trial 1. result,
selected weights overemphasize first feature, neglecting second feature. revealed
data shown plan-length performance degrades significantly one column
data. AVI repeated next problem size (13 boxes), good performance restored.
similar one-column degradation plan length occurs trial 2 10-box 12-box sizes.
propositional experiments C ONJUNCTIVE -B OXWORLD, note that, generally,
adding learned propositional features degrades success-rate performance relative initial
random walk policy introducing ineffective loops greedy policy. resulting greedy
policies find goal fewer steps random walk, generally pay unacceptable drop
success ratio so. one exception policy found one-box problems using two
propositional features, significantly reduces plan length preserving success ratio. Still,
result much weaker relational feature language.
problems get severe problem size increases, 3-box problems suffering severe
degradation success rate modest gains successful plan length. Also please note
accumulated runtime experiments large, especially 3-box problems. AVI
training expensive policies find goal. Computing greedy policy
state long trajectory requires considering action, number available actions
quite large domain. reasons, propositional technique evaluate sizes
larger three boxes.
7.3.3 UMMARY R ESULTS



DDITIONAL OMAINS

Figures 18 20, present summary results five additional probabilistic planning domains. detailed results full discussion domains, please see Appendix B.
summary results, see feature learning approach successfully finds features perform well across increasing problem sizes two five domains, IREWORLD L IFTED F ILEWORLD 3. three domains (Z ENOTRAVEL, OWERS H ANOI, E XPLODING
B LOCKSWORLD), feature learning able make varying degrees progress fixed small problem sizes, progress (sometimes quite limited) generalize well size increases.
7.3.4 E VALUATING R ELATIVE MPORTANCE B ELLMAN - ERROR CORING
G REEDY B EAM - SEARCH G OAL - ORIENTED OMAINS
Figure 21 compares original algorithm alternatives vary either training set
scoring greediness beam search, discussed Section 6.2. trial variant,
generate greedy policy domain using feature selection within relational representation
729

fiW U & G IVAN

Tireworld, Trial 1

Success Ratio

1
0.9

4 nodes

4, 5 nodes

6 nodes

20, 30 nodes

6 nodes

9 nodes

9, 10 nodes

3

4

4 nodes

0.8
0.7
0.6
4 nodes

0.5
0.4
0

Successful Plan Length

0

1

2

5

6

20, 30 nodes

5

4 nodes

4

4 nodes

4 nodes

3

9, 10 nodes
6, 9 nodes

2

4, 5, 6 nodes

1
0
0

1

2

3

4

5

Number Features

Zenotravel, Trial 1
Success Ratio

1
3 cities, 1 person, 1 aircraft

0.8
0.6

3 cities, 2 people, 2 aircraft

0.4

3 cities, 2 people, 2 aircraft

0
0.2

Successful Plan Length

0

1

2

3

4

5

6

7

8

9

500
400

3 cities, 2 people, 2 aircraft

3 cities, 2 people, 2 aircraft

300
200

3 cities, 1 person, 1 aircraft

100
0
0

1

2

3

4

5

6

7

8

9

Number Features

Figure 18: Summary results IREWORLD Z ENOTRAVEL. full discussion detailed
results, please see Appendix B.

730

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Exploding Blocksworld, Trial 1

Success Ratio

1
0.8

3 blocks

3 blocks
3 blocks

0.6

3 blocks
4 blocks

0.4

4 blocks

0.2
0

Successful Plan Length

0

1

2

3

4

5

6

7

8

9

10

6
5

4 blocks

4

4 blocks

3
3 blocks

3 blocks

2

3 blocks

3 blocks

1
0
0

1

2

3

4

5

6

7

8

9

10

Number Features

Tower Hanoi, Trial 1

Success Ratio

1
2 discs

0.8
0.6

4 discs

0.4

3 discs

0.2

5 discs

4 discs
0

Successful Plan Length

0

1

2

3

4

5

6

7

20
9

8

38
10

50
40
30

3 discs

20
10

4 discs

2 discs
0
0

1

2

3

4

5

6

7

8

Number Features

Figure 19: Summary results E XPLODING B LOCKSWORLD OWERS
discussion detailed results, please see Appendix B.

731



H ANOI. full

fiW U & G IVAN

Success Ratio

Lifted-Fileworld3, Trial 1
1 file

1

1 file

1 file

1 2 files

14 16 files

16 files

2 14 files

16 20 files

0.95
0.90
0

1

2

3

4

5

6

7

Successful Plan Length

60
16 files
14 files

20 files

40

14 files
15 files

13 files
12 files
10 files

11 files

16 files

16 files

20
1 file

1 file
1 file

4 files

2 files

3 files
2 files

1 file

0
0

1

2

3

4

5

6

7

Number Features

Figure 20: Summary results L IFTED -F ILEWORLD 3. full discussion detailed results,
please see Appendix B.

(alternating AVI training, difficulty increase, feature generation original algorithm).
trial, domain, select best performing policy, running algorithm
target problem difficulty reached improvement least three feature additions;
latter case generating least nine features. evaluate greedy policy acquired
manner, measuring average target-problem-size performance domain, average
results two trials. results shown Figure 21.
domain alternative Random Scoring perform comparably original Greedy
Beam Search/BE Scoring, exception three domain/size combinations learners
perform poorly (Z ENOTRAVEL, 10-block E XPLODING B LOCKSWORLD, 5-disc OWERS
H ANOI ). alternative Random Beam Narrowing sometimes adequate replace original
approach, domains, greedy beam search critical performance.
7.3.5 C OMPARISON



FF-R EPLAN



FOALP

compare performance learned policies FF-Replan FOALP
PPDDL evaluation domains used above. use problem generators provided planning
competitions generate 30 problems tested problem size except OWERS H ANOI
732

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Domain
Size
Greedy Beam/BE Scoring (orig.) SR
Greedy Beam/BE Scoring (orig.) SLen.
Random Scoring (var. 1) SR
Random Scoring (var. 1) SLen.
Random Beam Narrowing (var. 2) SR
Random Beam Narrowing (var. 2) SLen.
Random walk SR
Random walk SLen.

BW
20
0.98
748
0

0.01
258
0


Box Box Tire Zeno EX-BW EX-BW TOH TOH File
(15,5) (10,10) 30 (10,2,2)
5
10
4
5 30
1
0.98 0.92 0.11
0.34
0.03 0.51 0.00 1
90
235
5
1137
6
23
4
14 65
0.99 0.21 0.67 0.05
0.27
0.01 0.24 0.03 1
946 1582
6
910
6
12
13 26 215
1
0.99 0.91 0.13
0.35
0.02 0.25 0.01 1
90
242
6
1127
8
19
38 84 250
0.97 0.18 0.18 0.06
0.13
0
0.09 0.00 1
1038 1579
6
865
4

14 14 251

Figure 21: Target-problem-size performance (averaged 600 problems) relational features
learned original algorithm two alternatives discussed Section 6.2,
random walk, averaged best results two independent trials
target problem size.

L IFTED -F ILEWORLD 3, one fixed problem problem size. evaluate
performance planner 30 times problem, report Fig. 22 success ratio
planner problem size (averaged attempts). policies, learned
two independent trials shown above, indicated RFAVI #1 RFAVI #2. planner
30-minute time limit attempt. average time required finish successful attempt
largest problem size domain reported Figure 23.
two trials learner domain, evaluate policy performed best trial (first) target problem size. (Here, policy set features
corresponding weight vector learned AVI trial.) Performance measured
success rate, ties broken plan length. remaining ties broken taking later
policy trial tied. case, consider policy policy
learned trial.
results show planners performance incomparable FF-Replan (winning domains, losing others) generally dominates FOALP.
RFAVI performs best planners larger B LOCKSWORLD, C ONJUNCTIVE B OXWORLD, IREWORLD problems. RFAVI essentially tied FF-Replan performance
L IFTED -F ILEWORLD 3. RFAVI loses FF-Replan remaining three domains, E XPLODING
B LOCKSWORLD, Z ENOTRAVEL, OWERS H ANOI. Reasons difficulties last
three domains discussed sections presenting results domains. note
FOALP learned policy Z ENOTRAVEL, E XPLODING B LOCKSWORLD, OWERS
H ANOI , L IFTED -F ILEWORLD 3.
RFAVI relies random walk explore plateaus states differentiated selected
features. reliance frequently results long plan lengths times results failure.
recently reported elsewhere early results ongoing work remedying problem
using search place random walk (Wu et al., 2008).
RFAVI learning approach different non-learning online replanning used
FF-Replan, problem determinized, dropping probability parameters.
733

fiW U & G IVAN

RFAVI #1
RFAVI #2
FF-Replan
FOALP

15 blocks BW
1 (483)
1.00 (463)
0.93 (52)
1 (56)

20 blocks BW
1 (584)
1.00 (578)
0.91 (71)
0.73 (73)

25 blocks BW
0.85 (1098)
0.85 (1099)
0.7 (96)
0.2 (96)

30 blocks BW
0.75 (1243)
0.77 (1227)
0.23 (118)
0.07 (119)

RFAVI #1
RFAVI #2
FF-Replan
FOALP

(10BX,5CI)Box
1 (76)
1 (75)
1 (70)
1 (35)

(10BX,10CI)Box
0.97 (225)
0.97 (223)
0.98 (256)
0.70 (257)

(10BX,15CI)Box
0.93 (459)
0.93 (454)
0.93 (507)
0.28 (395)

(15BX,5CI)Box
1 (90)
1 (90)
1 (88)
0.99 (56)

RFAVI #1
RFAVI #2
FF-Replan
FOALP

20 nodes Tire
0.87 (5)
0.85 (4)
0.76 (2)
0.92 (4)

30 nodes Tire
0.85 (7)
0.84 (7)
0.73 (3)
0.90 (5)

40 nodes Tire
0.98 (6)
0.97 (6)
0.83 (3)
0.91 (5)

(10CI,2PR,2AT)Zeno
0.06 (1240)
0.07 (1252)
1 (99)
N/A

RFAVI #1
RFAVI #2
FF-Replan
FOALP

5 blocks EX-BW
0.25 (8)
0.25 (8)
0.91 (7)
N/A

10 blocks EX-BW 4 discs TOH
0.02 (30)
0.43 (4)
0.01 (35)
0.47 (4)
0.45 (20)
0.57 (3)
N/A
N/A

5 discs TOH
0 ()
0 ()
0.37 (7)
N/A

(20BX,20CI)Box
0.82 (959)
0.82 (989)
0.35 (1069)
0.0 (711)

30 files Lifted-File
1 (65)
1 (65)
1 (66)
N/A

Figure 22: Comparison planner (RFAVI) FF-Replan FOALP. Success ratio
total 900 attempts (30 attempts OWERS H ANOI L IFTED -F ILEWORLD 3)
problem size reported, followed average successful plan length
parentheses. two rows RFAVI map two learning trials shown paper.

30 BW (20,20) BX 40 Tire (10,2,2) Zeno 10 EX-BW 5 TOH 30 Files
RFAVI #1
106s
83s
1s
51s
2s

1s
RFAVI #2
105s
86s
0s
51s
3s

1s
FF-Replan 872s
739s
0s
1s
8s
3s
10s
FOALP
16s
173s
24s
N/A
N/A
N/A
N/A
Figure 23: Average runtime successful attempts, results shown Figure 22,
largest problem size domain.

734

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

important topic future research try combine benefits obtained different
planners across domains.
dominance RFAVI FOALP results implies RFAVI state
art among first-order techniques work problem lifted form use lifted
generalization. Although FOALP uses first-order structure feature representation, learned
features aimed satisfying goal predicates individually, whole. believe
goal-decomposition technique sometimes work well small problems scale well
large problems.
comparisons, also noted FOALP read PPDDL domain descriptions directly, requires human-written domain axioms learning, unlike completely
automatic technique (requiring numeric parameters characterizing domain).
requirement human-written domain axioms one reasons FOALP compete
competition domains learned policy domains
tested here.
C ONJUNCTIVE -B OXWORLD11 , note FF-Replan uses outcomes problem determinization discriminate likely unlikely outcomes truck-movement
actions. result, plans frequently selected rely unlikely outcomes (perhaps choosing
move truck undesired location, relying unlikely outcome accidentally moving
desired location). plans usually fail, resulting repeated replanning FF luckily selects high-likelihood outcome plan execution happens get desired low-likelihood
outcome. behavior effect similar behavior learned value function exhibits because, discussed Section 7.3.2, learner failed find feature rewarding appropriate
truck moves. planners result long plan lengths due many unhelpful truck moves. However, learned policy conducts random walk trucks much efficiently (and thus
successfully) online replanning FF-Replan, especially larger problem sizes.
believe even dramatic improvements available improved knowledge representation features.
7.4 SysAdmin
full description YS DMIN domain provided work Guestrin, Koller, Parr
(2001). Here, summarize description. YS DMIN domain, machines connected
different topologies. machine might fail step, failure probability depends
number failed machines connected it. agent works toward minimizing number
failed machines rebooting machines, one machine rebooted time step. problem
n machines fixed topology, dynamic state space sufficiently described n
propositional variables, representing on/off status certain machine.
test domain purpose direct comparison performance propositional techniques published results work Patrascu et al. (2002). test exactly
topologies evaluated measure performance measure reported there, sup-norm Bellman
error.
evaluate method exact problems (same MDPs) used evaluation
work Patrascu et al. (2002) testing domain. Two different kinds topologies tested:
11. hand-convert nested universal quantifiers conditional effects original BOXWORLD domain definition
equivalent form without universal quantifiers conditional effects allow FF-Replan read domain.

735

fiW U & G IVAN





Cycle Topology

3-legs Topology

Figure 24: Illustration two topologies YS DMIN domain (10 nodes). node
represents machine. label indicates server machine, specified work
Patrascu et al. (2002).

3-legs cycle. 3-legs topology three three-node legs (each linear sequence three
connected nodes) connected single central node one end. cycle topology arranges
ten nodes one large cycle. 10 nodes topology. two topologies
illustrated Figure 24. target learning domain keep many machines
operational possible, number operating machines directly determines reward
step. Since 10 nodes basic features on/off statuses
nodes, total 1024 states. reward-scaling parameter rscale (defined Section 5
Online Appendix 1, available JAIR website, page 8) selected 10.
work Patrascu et al. (2002) uses L (sup norm) Bellman error performance
measurement YS DMIN. technique, described above, seeks reduce mean Bellman
error directly L Bellman error. report L Bellman error, averaged two
trials, Figure 25. Also included Figure 25 results shown work Patrascu et al.
(2002). select best result shown (from various algorithmic approaches) 3-legs
cycle topologies shown paper. correspond d-o-s setting cycle
topology d-x-n setting 3-legs topology, terminology paper.
topologies show algorithm reduces L Bellman error effectively per
feature well effectively overall experiments previously reported work
Patrascu et al. (2002). topologies also show Bellman error eventually diverges AVI cannot
handle complexity error function dimensionality increases. algorithm still
achieve low Bellman error remembering restoring best-performing weighted feature set
weakened performance detected.
note superior performance reducing Bellman error could due entirely
part use AVI weight training instead approximate linear programming (ALP),
method used Patrascu et al. However, systematic superiority known AVI ALP,
results suggest superior performance feature learning itself.
736

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

SysAdmin, 3-Legs Topology
33

10

12

9

Bellman Error

8
7
6
5
4
3
2
1
0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30

Number Features
3-legs, Learned

3-legs, Patrascu

SysAdmin, Cycle Topology
25 42

10
9

Bellman Error

8
7
6
5
4
3
2
1
0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31

Number Features
Cycle, Learned
Cycle, Patrascu

Figure 25: L Bellman error YS DMIN domain (10 nodes) two topologies. Values
results work Patrascu et al. (2002) taken Figure 2 3
work Patrascu et al. (2002).

7.5 Demonstration Generalization Across Problem Sizes
asset relational feature representation presented paper learned relational
features applicable problem size domain. section 2.4, discussed
737

fiW U & G IVAN

Target problem sizes
10 20 Tetris 15 blocks BW (15 box, 5 city) BX 30 nodes Tire 30 files Lifted-File
Intermediate problem sizes 10 10 Tetris 10 blocks BW (10 box, 5 city) BX 15 nodes Tire 10 files Lifted-File
Generalize target size
Learn intermediate size
Random walk

55
119
0.1

1 (171)
1 (170)
0 ()

1 (76)
1 (188)
0.97 (893)

0.88 (4)
0.89 (4)
0.29 (6)

1 (25)
1 (25)
1 (88)

Figure 26: Performance intermediate-sized problems generalization. show
performance value functions learned target problem sizes evaluated
intermediate-sized problems, demonstrate generalization sizes. comparison, also intermediate-sized problems, show performance value functions learned directly intermediate size well performance random
walk. Generalization results intermediate size learning results averages two
trials. ETRIS, average accumulated rows erased shown. goal-oriented
domains, success ratio successful plan length (in parentheses) shown
domain.

modeling planning domain infinite set MDPs, one problem instance
domain. infinite set MDPs, feature vector plus weight vector defines single
value function well defined every problem instance MDP. discuss question whether framework find single feature/weight vector combination generalizes
good performance across problem sizes, i.e., value function V defined combination,
whether Greedy(V ) performs similarly well different problem sizes.
Throughout Section 7, demonstrated direct application learned feature/weight
vectors target problem sizes, (without retraining weights)these results shown
target-size lines result tables domain. ETRIS, B LOCKSWORLD, C ONJUNCTIVE B OXWORLD, IREWORLD, L IFTED -F ILEWORLD 3, target-size lines demonstrate direct
successful generalization target sizes even current problem sizes significantly smaller.
(In domains, either notion problem size (S YS DMIN), insufficient planning progress significantly increase problem size learning small problems (E XPLOD ING B LOCKSWORLD , Z ENOTRAVEL , OWERS H ANOI ).)
subsection, consider generalization (larger) target sizes selected intermediate sizes five domains. Specifically, take weight vectors feature vectors
resulting end trials (i.e. weight vector retrained target sizes), apply
directly selected intermediate problem sizes without weight retraining. trials terminate learning reaches target problem sizes12 , take weights features result
best performing policy terminating problem sizes. generalization results shown
Figure 26; comparison, table also shows performance intermediate-sized
problems value function learned directly size, well performance
random walk size.
12. Note one trials ETRIS terminates reaching target size due non-improving performance,
two trials L IFTED -F ILEWORLD 3 terminate target-size performance already reaches optimality
learning reaches target size. Still, although value functions learned smaller sizes
target size, value functions evaluated generalization learned significantly larger sizes
intermediate evaluation size.

738

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

domain shown random walk result much weaker generalization result,
showing presence generalization learned value functions across problem sizes.
four goal-oriented planning domains, applying value functions learned target sizes equals
performance achieved value functions learned directly intermediate sizes (with better
performance C ONJUNCTIVE -B OXWORLD). ETRIS, however, generalization result
match result learning intermediate size. note domains, solution
strategy invariant respect problem size (e.g. destroying incorrect towers form correct
ones B LOCKSWORLD). domains best plan/strategy may change dramatically
size. example, ETRIS, larger number rows board allows strategies temporary
stack uncompleted rows, smaller number rows favors strategies complete rows quickly
possible. Thus one necessarily expect generalization domain sizes every
domainthis conclusion expected hold whether considering generalization
value functions policies.
included discussion policy-based generalization related work section (Appendix A.4), focusing previous work approximate policy iteration. However, note
policies generalize problems different sizes less well defined
value functions generalize problems. previous API work, defined
policies select actions states domain size; work define value functions
assign numeric values states domain size. None work guarantees finding good
optimal policy value function; far know, problems admit good compact value
functions, admit good compact policies, admit both, neither.

8. Discussion Future Research
presented general framework automatically learning state-value functions featurediscovery gradient-based weight training. framework, greedily select features
provided hypothesis space (which parameter method) best correlate Bellman
error features, use AVI find weights associate features.
proposed two different candidate hypothesis spaces features. One two
spaces relational one features first-order formulas one free-variable, beamsearch process used greedily select hypothesis. hypothesis space considered propositional feature representation features decision trees. hypothesis
space, use standard classification algorithm C4.5 (Quinlan, 1993) build feature best
correlates sign statewise Bellman error, instead using sign magnitude.
performance feature-learning planners evaluated using reward-oriented
goal-oriented planning domains. demonstrated relational planner represents
state-of-the-art feature-discovering probabilistic planning techniques. propositional planner
perform well relational planner, cannot generalize problem instances,
suggesting knowledge representation indeed critical success feature-discovering
planners.
Although present results propositional feature-learning approach relation featurelearning approach, knowledge representation difference difference
approaches. Historically, propositional approach originally conceived reduction
classification learning, attempt capture magnitude Bellman error
739

fiW U & G IVAN

feature selection, rather focuses sign error. contrast, relational approach
counts objects order match magnitude Bellman error.
difference, cannot attribute performance differences
approaches knowledge representation choice. differences performance could due
choice match sign propositional feature selection. possible future experiment
identify sources performance variation would use propositional representation involving
regression trees (Dzeroski, Todorovski, & Urbancic, 1995) capture magnitude error.
representation might possibly perform somewhat better decision-tree representation
shown here, course would still enable generalization sizes relational
feature learner exhibits.
Bellman-error reduction course one source guidance might followed
feature discovery. experiments IPPC planning domains, find many
domains successful plan length achieved much longer optimal, discussed
Section 7.3.5. possible remedy deploying search previous work (Wu et al.,
2008) learn features targeting dynamics inside plateaus, use features decisionmaking plateaus encountered.

Acknowledgments
material based upon work supported part National Science Foundation Grant
No. 0905372.

Appendix A. Related Work
A.1 Feature Selection Approaches
A.1.1 F EATURE ELECTION

VIA

C ONSTRUCTIVE F UNCTION PPROXIMATION

Automatic feature extraction sequential decision-making studied work Utgoff
Precup (1997), via constructive function approximation (Utgoff & Precup, 1998). work
viewed forerunner general framework, limited propositional representations,
binary-valued features, new features single-literal extensions old features conjunction. Also work Rivest Precup (2003) variant Cascade-Correlation (Fahlman
& Lebiere, 1990), constructive neural network algorithm, combined TD-learning learn
value functions reinforcement learning. Cascade-Correlation incrementally adds hidden units
multi-layered neural networks, hidden unit essentially feature built upon set
numerically-valued basic features. work provides framework generalizing prior efforts reduction supervised learning, explicit reliance Bellman error signal,
feature hypothesis space corresponding learner deployed. particular,
demonstrate framework binary propositional features using C4.5 learner rich
numeric-valued relational features using greedy beam-search learner. work provides first
evaluation automatic feature extraction benchmark planning domains several planning
competitions.
work Utgoff Precup (1997) implicitly relies Bellman error,
explicit construction Bellman error training set discussion selecting features correlate
740

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Bellman error. instance, work focuses first refining current feature weight
updates converging poorly (high variance weight updates), whereas work focuses first
finding feature correlates statewise Bellman error, regardless whether feature refines
current feature. addition, work selects features online weights current
features adjusted, stationary target value function Bellman
error considered selection next new feature. contrast, work separates weight
training new feature selection completely. (These differences perhaps part due
reinforcement learning setting used Utgoff & Precup, 1997, opposed planning setting
work.)
selection hidden unit feature Cascade-Correlation (Fahlman & Lebiere, 1990) based
covariance feature values errors output units. output units
estimating value function, training data providing Bellman update value function,
output unit error Bellman error. Thus, hidden units learned work Rivest
Precup (2003) approximations Bellman-error features learned features are, although made explicit work. making goal capturing Bellman error explicit
here, provide general reduction facilitates use learning method capture
resulting feature-learning training sets. particular, able naturally demonstrate generalization across domain sizes several large domains, using relational feature learner. contrast,
single test domain work Rivest Precup (2003) small fixed size. Nonetheless,
work important precursor approach.
A.1.2 F EATURE C ONSTRUCTION

VIA

PECTRAL NALYSIS

Feature-learning frameworks value functions based upon spectral analysis state-space connectivity presented work Mahadevan Maggioni (2007) Petrik (2007).
frameworks, features eigenvectors connectivity matrices constructed random walk (Mahadevan & Maggioni, 2007) eigenvectors probabilistic transition matrices (Petrik, 2007).
features capture aspects long-term problem behaviours, opposed short-term behaviours
captured Bellman-error features. Bellman-error reduction requires iteration capture longterm behaviors.
Reward functions considered feature construction work Mahadevan Maggioni (2007); work Petrik (2007), reward functions incorporated
learning Krylov basis features, variant Bellman error features (Parr et al., 2008), complement eigenvector features. However, even Petriks framework, reward incorporated
features used policy evaluation rather controlled environment consider.
Essential work use machine learning factored representations handle
large statespaces generalize problems different sizes. spectral
analysis frameworks limited respect (at least current state development). approach Petrik (2007) presented explicit statespaces, factorization approach
scaling large discrete domains proposed work Mahadevan Maggioni (2007).
approach, features learned dimension factorization, independent
dimensions. believe assumption independence dimensions inappropriate
many domains, including benchmark planning domains considered work. Mahadevan Maggioni factorization approach also suffers drawbacks propositional
approach: solution recomputed problems different sizes domain
741

fiW U & G IVAN

lacks flexibility generalize problems different sizes provided relational
approach.
A.2 Structural Model-based Model-free Solution Methods Markov Decision
Processes
A.2.1 R ELATIONAL R EINFORCEMENT L EARNING
work Dzeroski et al. (2001), relational reinforcement learning (RRL) system learns
logical regression trees represent Q-functions target MDPs. work related since
use relational representations automatically construct functions capture state value.
addition Q-function trees, policy tree learner also introduced work Dzeroski
et al. (2001) finds policy trees based Q-function trees. learn explicit policy
description instead use greedy policies evaluation.
logical expressions RRL regression trees used decision points computing
value function (or policy) rather numerically valued features linear combination,
method. Generalization across problem sizes achieved learning policy trees; learned value
functions apply training problem sizes. date, empirical results approach
failed demonstrate ability represent value function usefully familiar planning
benchmark domains. good performance shown simplified goals placing
particular block onto particular block B, technique fails capture structure richer
problems constructing particular arrangements Blocksworld towers. RRL
entered international planning competitions. difficulties representing complex
relational value functions persist extensions original RRL work (Driessens & Dzeroski,
2004; Driessens et al., 2006), limited applicability shown benchmark planning
domains used work.
A.2.2 P OLICY L EARNING VIA B OOSTING
work Kersting Driessens (2008), boosting approach introduced incrementally
learn features represent stochastic policies. policy-iteration variant featurelearning framework, clearly differs work policy representations learned instead
value function representations. Using regression tree learner TILDE (Blockeel & De Raedt,
1998), feature learner demonstrated advantages previous RRL work task accomplishing on(A,B) 10-block problem. Applicability simple continuous domain (the corridor
world) also demonstrated. line RRL work, limited applicability benchmark
planning domains shown here. One probable source limited applicability model-free
reinforcement-learning setting system model problem dynamics explicitly.
A.2.3 F ITTED VALUE TERATION
Gordon (1995) presented method value iteration called fitted value iteration suitable
large state spaces require direct feature selection. Instead, method relies
provided kernel function measuring similarity states. Selection kernel function
viewed kind feature selection, kernel identifies state aspects significant
measuring similarity. knowledge, techniques class applied
large relational planning problems like evaluated paper. note selection
742

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

single relational kernel domains would measure state similarity domain-independent
manner thus believe kernel could adapt individual domains way
work does. Thus would expect inferior performance approach; however,
remains investigated. Selection domain-specific kernels stochastic planning domains,
automatically, also yet explored.
A.2.4 E XACT VALUE TERATION F IRST- ORDER MDP
Previous work used lifted techniques exactly solve first-order MDPs reformulating exact
solution techniques explicit MDPs, value iteration. Boutilier et al. (2001) Holldobler Skvortsova (2004) independently used two different first-order languages (situation
calculus fluent calculus, respectively) define first-order MDPs. works, Bellman update procedure value iteration reformulated using respective calculus, resulting
two first-order dynamic-programming methods: symbolic dynamic programming (SDP), firstorder value iteration (FOVI). simple boxworld example human-assisted computation
demonstrated SDP work, method serves basis FOALP (Sanner & Boutilier,
2009), replaces exact techniques heuristic approximation order scale techniques
benchmark planning domains. Application FOVI planning domains demonstrated
colored blocksworld benchmark, limited 10 blocks (Holldobler, Karabaev, &
Skvortsova, 2006).
work Kersting et al. (2004), constraint logic programming used define relational
value iteration method. MDP components, states, actions, rewards, first abstracted
form Markov decision program, lifted version MDP. relational Bellman operation
(ReBel) used define updates Q-values state values. Empirical study ReBel
approach limited 10-step backups single-predicate goals blocksworld
logistics domains.
Exact techniques suffer difficulty representing full complexity state-value
function arbitrary goals even mildly complex domains. previous works serve illustrate central motivation using problem features compactly approximate structure
complex value function, thus motivate automatic extraction features studied
work.
A.3 Comparison Inductive Logic Programming Algorithms
problem selecting numeric function relational states match Bellman-error training
set first-order regression problem available systems described
Inductive logic programming (ILP) literature (Quinlan, 1996; Karalic & Bratko, 1997).
important note ILP work studied learning classifiers relational
data (Muggleton, 1991), concerned learning numeric functions relational
data (such states). latter problem called first-order regression within ILP literature, received less study relational classification. Here, choose design
proof-of-concept relational learner experiments rather use one previous
systems. Separate work needed compare utility relational learner previous
regression systems; purpose demonstrate utility Bellman-error training data
finding decision-theoretic value-function features. simple learner suffices create
state-of-the-art domain-independent planning via automatic feature selection.
743

fiW U & G IVAN

ILP classification systems often proceed either general specific, specific
general, seeking concept match training data. regression, however,
easy ordering numeric functions searched. design instead method searches
basic logical expression language simple expressions complex expressions, seeking
good matches training data. order control branching factor, still allowing
complex expressions considered, heuristically build long expressions
short expressions score best. words, use beam search space expressions.
several heuristic aspects method. First, define heuristic set basic expressions search begins. Second, define heuristic method combining
expressions build complex expressions. two heuristic elements designed
logical formula without disjunction, one free variable, built repeated combination basic expressions. Finally, assumption high-scoring expressions built
high-scoring parts heuristic (and often true). critical heuristic assumption
makes likely learner often miss complex features match training data well.
known method guarantees tractably finding features.
A.4 Approximate Policy Iteration Relational Domains
planners use greedy policies derived learned value functions. Alternatively, one directly learn representations policies. policy-tree learning work Dzeroski et al.
(2001), discussed previously Appendix A.2.1, one example. Recent work uses relational decision-list language learn policies small example problems generalize well
perform large problems (Khardon, 1999; Martin & Geffner, 2004; Yoon et al., 2002). Due
inductive nature line work, however, selected policies occasionally contain severe
flaws, mechanism provided policy improvement. policy improvement quite
challenging due astronomically large highly structured state spaces relational policy
language.
work Fern et al. (2006), approximate version policy iteration addressing
issues presented. Starting base policy, approximate policy iteration iteratively generates
training data improved policy (using policy rollout) uses learning algorithm
work Yoon et al. (2002) capture improved policy compact decision-list language
again. Similar work, learner work Fern et al. (2006) aims take flawed
solution structure improve quality using conventional MDP techniques (in case, finding
improved policy policy rollout) machine learning. Unlike work, work Fern
et al. (2006) improved policies learned form logical decision lists. work
viewed complementary previous work exploring structured representation value
functions work explored structured representation policies. approaches
likely relevant important long-term effort solve structured stochastic decisionmaking problems.
note feature-based representation, considered generally MDP literature, used represent value functions rather policies. Compact representation policies
done via value functions (with greedy execution) directly, example, using decision lists. previous API work discussed uses direct representation policies, never
uses compact representation value functions. Instead, sampling value functions used
policy evaluation step policy iteration.
744

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

One imagine different novel approach API compact feature-based
representation used value functions, greedy execution policy representation.
approach, feature discovery similar explore value iteration could designed assist policy evaluation phase policy iteration. leave development
evaluation idea future work. expect two approaches API, well
current approach value iteration, advantages disadvantages vary domain
ways yet well understood. domains natural compact direct policy
representations (run see tarantula), whereas others naturally compactly represented
via value functions (prefer restaurants good review ratings). Research area must
eventually develop means combine compact representations effectively.
A.5 Automatic Extraction Domain Knowledge
substantial literature learning plan using methods direct representation
value function reactive policy, especially deterministic planning literature.
techniques related acquire domain specific knowledge via planning experience domain. Much literature targets control knowledge particular search-based
planners (Estlin & Mooney, 1997; Kambhampati et al., 1996; Veloso et al., 1995), distant
approach focus particular planning technology used limitation
deterministic domains. unclear generalize work value-function construction
probabilistic domains.
However, broader learning-to-plan literature also contains work producing declarative
learned domain knowledge could well exploited feature discovery value function representation. work Fox Long (1998), pre-processing module called TIM
able infer useful domain-specific problem-specific structures, typing objects
state invariants, descriptions domain definition initial states. invariants
targeted work improving planning efficiency Graphplan based planner, suggest
future work could exploit invariants discovering features value function representation. Similarly, work Gerevini Schubert (1998), DISCOPLAN infers state constraints
domain definition initial state order improve performance SAT-based planners; again, constraints could incorporated feature search like method
date.

Appendix B. Results Discussions Five Probabilistic Planning Competition
Domains
Section 7.3, presented results relational propositional feature learners
B LOCKSWORLD C ONJUNCTIVE -B OXWORLD. present results relational
feature learner following five probabilistic planning competition domains: IREWORLD,
Z ENOTRAVEL, E XPLODING B LOCKSWORLD, OWERS H ANOI, L IFTED -F ILEWORLD 3.
B.1 Tireworld
use IREWORLD domain second IPPC. agent needs drive vehicle
graph start node goal node. moving one node adjacent node,
vehicle certain chance suffering flat tire (while still arriving adjacent node).
745

fiW U & G IVAN

Trial #1
# features
0
1
2
3
3
3
4
4
5
Problem difficulty
4
4
4
4
5
6
6
9
9
Success ratio
0.52 0.81 0.84 0.86 0.86 0.84 0.88 0.85 0.86
Plan length
4
3
4
2
2
2
3
3
4
Accumulated time (Hr.) 0.3 3.1 12 17 18 18 19 21 22
0.17 0.53 0.81 0.83 0.83 0.82 0.90 0.91 0.91
Target size SR
Target size Slen.
5
4
9
5
4
4
6
6
6

5
10
0.86
4
23
0.91
6

Trial #2
# features
0
1
2
3
3
3
4
4
4
Problem difficulty
4
4
4
4
5
6
6
10 20
0.52 0.81 0.85 0.86 0.93 0.81 0.89 0.85 0.86
Success ratio
Plan length
4
3
3
2
3
2
3
4
4
Accumulated time (Hr.) 0.5 3.7 6.9 10 11 11 12 14 18
Target size SR
0.19 0.49 0.80 0.82 0.91 0.62 0.92 0.91 0.90
Target size Slen.
7
3
9
4
5
2
5
5
6

4
30
0.88
5
24
0.88
6

5
20
0.91
5
29
0.92
5

5
30
0.91
5
36
0.92
6

Figure 27: IREWORLD performance (averaged 600 problems) relational learner. add
one feature per column success ratio exceeds 0.85 average successful plan
length less 4n, n nodes, increase problem difficulty next
column. Plan lengths shown successful trials only. Problem difficulties measured
number nodes, target problem size 30 nodes. columns omitted
discussed Section 7.1.

flat tire replaced spare tire, spare tire present node
containing vehicle, vehicle carrying spare tire. vehicle pick spare
tire already carrying one one present node containing vehicle.
default setting second-IPPC problem generator domain defines problem distribution
includes problems policy achieving goal probability one.
problems create tradeoff goal-achievement probability expected number steps
goal. strongly planner favors goal achievement versus short trajectories goal
determined choice discount factor made Section 6.1.
start 4-node problems relational learner increase n nodes n + 1
nodes whenever success ratio exceeds 0.85 average successful plan length better
4n steps. target problem size 30 nodes. results shown Figures 18 27.
IREWORLD, relational learner able find features generalize well large
problems. learner achieves success ratio 0.9 30 node problems. unknown
whether policy exceed success ratio problem distribution; however, neither
comparison planner, FOALP FF-Replan, finds higher success-rate policy.
note improvements success rate domain necessarily associated
increases plan length success-rate improvements may due path deviations
acquire spare tires.
746

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Trial #1
# features
Problem difficulty
Success ratio
Plan length
Accumulated time (Hr.)
Target size SR
Target size Slen.

0
3,1,1
0.79
253
0.75
0.06
916

1
3,1,1
0.8
255
1.7
0.08
1024

1
3,2,2
0.59
413
3.4
0.09
1064

2
3,2,2
0.52
440
7.1
0.09
1114

3
3,2,2
0.54
437
11
0.12
1050

4
3,2,2
0.55
450
15
0.11
1125

5
3,2,2
0.54
411
19
0.10
1111

6
3,2,2
0.52
440
25
0.08
1115

7
3,2,2
0.56
426
30
0.11
1061

8
3,2,2
0.53
428
36
0.08
1174

9
3,2,2
0.55
451
41
0.12
1195

Trial #2
# features
Problem difficulty
Success ratio
Plan length
Accumulated time (Hr.)
Target size SR
Target size Slen.

0
3,1,1
0.77
262
1.3
0.05
814

1
3,1,1
0.79
254
2.3
0.10
1008

2
3,1,1
0.80
233
3.3
0.10
1007

2
3,2,2
0.55
391
5.3
0.09
1067

3
3,2,2
0.55
425
8.9
0.09
1088

4
3,2,2
0.50
415
13
0.08
1014

5
3,2,2
0.53
422
17
0.10
1078

6
3,2,2
0.12
0
22
0.02
0

7
3,2,2
0.12
0
29
0.02
0

8
3,2,2
0.12
0
36
0.02
0

9
3,2,2
0.10
0
43
0.01
0

Figure 28: Z ENOTRAVEL performance (averaged 600 problems) relational learner.
problem difficulty shown table lists numbers cities, travelers, aircraft,
target problem size 10 cities, 2 travelers, 2 aircraft. add one feature
per column success ratio exceeds 0.8, increase problem difficulty
next column. Plan lengths shown successful trials only.

B.2 Zenotravel
use Z ENOTRAVEL domain second IPPC. goal domain fly travelers original location destination. Planes (finite-range, discrete) fuel levels,
need re-fuelled fuel level reaches zero cont inue flying. available activity
(boarding, debarking, flying, zooming, refueling) divided two stages, activity
X modelled two actions start-X finish-X. finish-X activity (high) probability
nothing. start action taken, corresponding finish action must taken
(repeatedly) succeeds conflicting action started. structure allows
failure rates finish actions simulate action costs (which used explicitly
problem representation competition). plane moved locations flying
zooming. Zooming uses fuel flying, higher success probability.
start problem difficulty 3 cities, 1 traveler, 1 aircraft using relational
feature learner. Whenever success ratio exceeds 0.8, increase number n travelers
aircraft 1 number cities less 5n 2, increase number cities one
otherwise. target problem size 10 cities, 2 travelers, 2 aircraft. Z ENOTRAVEL results
relational learner shown Figures 18 28.
747

fiW U & G IVAN

relational learner unable find features enable AVI achieve threshold success
rate (0.8) 3 cities, 2 travelers, 2 aircraft, although 9 relational features learned. trials
stopped improvement performance achieved several iterations feature
addition. Using broader search (W = 160, q = 3, = 3) able find better features
extend solvable size several cities success rate 0.9 (not shown results
paper use search parameters, reported Wu & Givan, 2007), runtime also
increases dramatically, weeks. believe speed effectiveness relational learning
needs improved excel domain, likely major factor improved knowledge
representation features key concepts Z ENOTRAVEL easily represented.
Trial two Figure 28 shows striking event adding single new feature useful value
function results value function greedy policy cannot find goal all,
success ratio degrades dramatically immediately. Note small problem size,
ten percent problems trivial, initial state satisfies goal. addition
sixth feature trial two, problems policy solve. reflects
unreliability AVI weight-selection technique aspect feature discovery:
all, AVI free assign zero weight new feature, not. Additional study
control AVI and/or replacement AVI linear programming methods indicated
phenomenon; however, rare event extensive experiments.
B.3 Exploding Blocksworld
also use E XPLODING B LOCKSWORLD second IPPC evaluate relational planner.
domain differs normal Blocksworld largely due blocks certain probability detonated put down, destroying objects beneath (but
detonating block). Blocks already detonated detonated again. goal
state domain described tower fragments, fragments generally required
table. Destroyed objects cannot picked up, blocks cannot put destroyed objects (but destroyed object still part goal necessary relationships
established destroyed).
start 3-block problems using relational learner increase n blocks n + 1
blocks whenever success ratio exceeds 0.7. target problem sizes 5 10 blocks.
E XPLODING B LOCKSWORLD results relational learner shown Figures 19 29.
results E XPLODING B LOCKSWORLD good enough planner increase
difficulty beyond 4-block problems, results show limited generalization 5-block
problems, little generalization 10-block problems.
performance domain quite weak. believe due presence many
dead-end states reachable high probability. states either table
one blocks needed goal destroyed, object question achieved
required properties. planner find meaningful relevant features: planner discovers
undesirable destroy table, instance. However, resulting partial understanding domain cannot augmented random walk (as domains
B LOCKSWORLD C ONJUNCTIVE -B OXWORLD) enable steady improvement value, leading goal; random walk domain invariably lands agent dead end. short
successful plan length, low probability reaching goal, (not shown here) high unsuccessful plan length (caused wandering dead end region) suggest need new techniques
748

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Trial #1
# features
0
1
2
3
Problem difficulty
3
3
3
3
Success ratio
0.56 0.58 0.56 0.63
Plan length
1
2
1
2
Accumulated time (Hr.) 0.6 1.4 2.2 3.1
0.12 0.12 0.14 0.22
Target size #1 SR
Target size #1 Slen.
3
3
3
5
Target size #2 SR
0
0
0 0.00
Target size #2 Slen.


10

4
3
0.56
1
4.2
0.20
4
0.00
4

Trial #2
# features
0
1
2
3
4
Problem difficulty
3
3
3
3
3
Success ratio
0.56 0.56 0.55 0.63 0.55
Plan length
1
2
1
2
1
Accumulated time (Hr.) 0.6 1.3 2.1 2.9 3.7
Target size #1 SR
0.14 0.15 0.12 0.18 0.17
4
3
4
6
4
Target size #1 Slen.
Target size #2 SR
0
0
0 0.01 0.00
Target size #2 Slen.


19 18

5
6
7
7
8
9
3
3
3
4
4
4
0.68 0.62 0.71 0.4 0.45 0.43
1
2
2
4
5
4
5.9 8.7 11 12 20 28
0.31 0.16 0.34 0.33 0.31 0.31
6
9
6
6
5
5
0.03 0 0.02 0.03 0.02 0.02
24 19 26 23 22

5
3
0.75
2
4.6
0.33
6
0.02
26

5
4
0.45
4
5.3
0.31
6
0.01
27

6
4
0.45
5
14
0.32
6
0.01
15

7
4
0.43
5
22
0.31
6
0.02
21

8
4
0.42
4
31
0.28
5
0.01
15

10
4
0.44
5
38
0.29
5
0.01
15

9
4
0.36
4
39
0.30
5
0.01
18

Figure 29: E XPLODING B LOCKSWORLD performance (averaged 600 problems) relational
learner. Problem difficulties measured number blocks. add one feature per
column success ratio exceeds 0.7, increase problem difficulty next
column. Plan lengths shown successful trials only. Target problem size #1 5
blocks, target problem size #2 10 blocks.

aimed handling dead-end regions handle domain. results demonstrate technique relies random walk (or form search) learned features need
completely describe desired policy.
B.4 Towers Hanoi
use domain OWERS H ANOI first IPPC. probabilistic version wellknown problem, agent move one two discs simultaneously, small probability
going dead-end state move, probability depends whether largest disc
moved type disc move (one two time) used. note
one planning problem problem size here.
important note 100% success rate generally unachievable domain due
unavoidable dead-end states.
749

fiW U & G IVAN

Trial #1
# features
Problem difficulty
Success ratio
Plan length
Accumulated time (Hr.)
Target size #1 SR
Target size #1 Slen.
Target size #2 SR
Target size #2 Slen.

0
1
1
2
3
3
4
5
6
7
8
8 20 38
2
2
3
3
3
4
4
4
4
4
4
5
5
5
0.70 0.75 0.11 0.44 0.73 0
0
0
0
0 0.51 0
0
0
4
2
43
26
4





4



0.0 0.0 0.1 0.2 0.3 0.4 0.5 1.1 1.2 2.1 2.2 2.3 18 53
0.07 0.15 0.01 0.08 0.03 0
0
0
0
0 0.52 0.53 0 0.43
13
9
90
95
37





4
4

4
0.00 0
0
0 0.00 0
0
0
0
0
0
0
0
0
11



107









Trial #2
# features
Problem difficulty
Success ratio
Plan length
Accumulated time (Hr.)
Target size #1 SR
Target size #1 Slen.
Target size #2 SR
Target size #2 Slen.

0
0
1
2
3
3
4
5
6
7
8
2
3
3
3
3
4
4
4
4
4
4
0.71 0.23 0.14 0.42 0.75 0
0
0
0
0 0.53
4
12
37
25
4





4
0.0 0.0 0.2 0.3 0.3 0.4 0.5 1.1 1.9 2.3 2.6
0.1 0.09 0.0 0.09 0.03 0
0
0
0
0 0.49
14
11 105 95
41





4
0.00 0.1
0
0 0.00 0
0
0
0
0
0
16
29


107






8
5
0

2.7
0

0


20
5
0

6
0

0


38
5
0

16
0

0


Figure 30: OWERS H ANOI performance (averaged 600 problems) relational learner.
add one feature per column success ratio exceeds 0.7n1 n discs,
increase problem difficulty next column. Plan lengths shown successful trials
only. Problem difficulties measured number discs, target problem size #1
4 discs size #2 5 discs. columns omitted discussed Section 7.1.

start 2-disc problem relational learner increase problem difficulty
n discs n + 1 discs whenever success ratio exceeds 0.7n1 . target problem sizes
4 5 discs. OWERS H ANOI results relational learner shown Figures 19 30.
learner clearly able adapt three- four-disc problems, achieving around 50%
success rate four disc problem trials. optimal solution four disc problem
success rate 75%. policy uses single disc moves large disc moved
uses double disc moves. Policies use single disc moves double disc moves
achieve success rates 64% 58%, respectively, four disc problem. learned solution
occasionally moves disc way get closer goal, reducing success.
Unfortunately, trials show increasing number new features needed adapt
larger problem size, trials even 38 total features enough adapt
five-disc problem. Thus, know approach extend even five discs. Moreover,
results indicate poor generalization problem sizes.
believe difficult learner (and humans) represent good value function
across problem sizes. Humans deal domain formulating good recursive policy,
establishing direct idea value state. Finding recursive policy automatically
interesting open research question outside scope paper.
750

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

B.5 Lifted-Fileworld3
described Section 6.1, use domain L IFTED -F ILEWORLD 3, straightforwardly
lifted form F ILEWORLD first IPPC, restricted three folders. reach goal filing
files, action needs taken file randomly determine folder file
go into. actions taking folder, putting file folder, returning folder
cabinet. goal reached files correctly filed targeted folders.
note F ILEWORLD L IFTED -F ILEWORLD 3 benign domains.
reachable dead ends non-optimal actions, directly reversible.
Random walk solves domain success rate one even thirty files. technical challenge
posed minimize unnecessary steps minimize plan length. optimal policy
solves n-file problem 2n + 1 2n + 5 steps, depending random file types
generated.
Rather preset plan-length threshold increasing difficulty (as function n),
adopt policy increasing difficulty whenever method fails improve plan length adding
features. Specifically, success ratio exceeds 0.9 one feature added without improving
plan length, remove feature increase problem difficulty instead.13
start 1 file problems relational learner increase n files n + 1 files
whenever performance improve upon feature addition. target problem size 30
files. L IFTED -F ILEWORLD 3 results relational learner shown Figures 20 31.
results show planner acquires optimal policy 30-file target size problem
learning four features, two trials. results domain reveal
weakness AVI weight-selection method. Although four features enough define optimal policy, problem difficulty increases, AVI often fails find weight assignment producing
policy. happens, feature addition triggered, trial 1.
domain, results show extra features prevent AVI finding good weights
subsequent iterations, optimal policy recovered larger feature set. Nonetheless, another indication improved performance may available via work alternative
weight-selection approaches, orthogonal topic feature selection.

References
Bacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledge
planning. Artificial Intelligence, 116, 123191.
Bertsekas, D. P. (1995). Dynamic Programming Optimal Control. Athena Scientific.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Blockeel, H., & De Raedt, L. (1998). Top-down induction first-order logical decision trees.
Artificial Intelligence, 101, 285297.
Bonet, B., & Givan, R. (2006). Non-deterministic planning track 2006 international planning
competition. Website. http://www.ldc.usb.ve/ bonet/ipc5/.
13. possible specify plan-length threshold function triggering increase difficulty domain,
done domains. find domain quite sensitive choice function, end
must chosen trigger difficulty increase feature addition fruitless current difficulty.
So, directly implemented automatic method triggering difficulty increase.

751

fiW U & G IVAN

Trial #1
# features
0 1 2
1 1 1
Problem difficulty
Success ratio
1 1 1
14 8 4
Plan length
Accumulated time (Hr.) 0.0 0.0 0.0
Target size SR
1 1 1
Target size Slen.
251 134 87

3
1
1
3
0.0
0


3
2
1
7
0.1
0


4
2
1
6
0.1
0


4
3
1
9
0.1
0


4
4
1
11
0.2
1.00
87

4
12
1
29
5.9
1
93

4
13
1
31
7.3
1
65

4
14
1
49
8.9
1
90

5
14
1
37
10
1
91

5
15
1
35
13
1
65

5
16
1
55
15
1
91

6
16
1
37
17
1
65

7
16
1
37
19
1
65

7
18
1
41
37
1
65

7
19
1
43
49
1
111

7
20
1
45
62
1
65

Trial #2
# features
0 1 2
Problem difficulty
1 1 1
Success ratio
1 1 1
14 8 4
Plan length
Accumulated time (Hr.) 0.0 0.0 0.0
1 1 1
Target size SR
Target size Slen.
251 135 88

3
1
1
3
0.0
0


3
2
1
7
0.1
0


4
2
1
6
0.1
0


4
3
1
9
0.1
0


4
4 4 4 4
4
5 8 9 10
1
1 1 1 1
12 14 21 23 25
0.2 0.6 2.5 3.1 3.9
0.96 1 1 1 1
85 88 82 82 91

4
14
1
33
9.0
1
96

4
15
1
35
11
1
87

4
16
1
62
13
1
91

4
17
1
65
19
1
93

4
18
1
41
27
1
97

4
19
1
43
30
1
65

4
20
1
49
34
1
65

4
23
1
91
50
1
107

4
24
1
53
66
1
82

4
25
1
55
74
1
65

4
8
1
21
2.4
1.00
82

4
10
1
25
3.8
1
91

4
11
1
30
4.8
1
88

Figure 31: L IFTED -F ILEWORLD 3 performance (averaged 600 problems) relational
learner. add one feature per column success ratio exceeds 0.9 adding one
extra feature improve plan length, increase problem difficulty
next column (after removing extra feature). Plan lengths shown successful trials
only. Problem difficulties measured number files, target problem size
30 files. columns omitted discussed Section 7.1.

Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming first-order MDPs.
Proceedings Seventeenth International Joint Conference Artificial Intelligence,
pp. 690700.
Chandra, A., & Merlin, P. (1977). Optimal implementation conjunctive queries relational data
bases. Proceedings Ninth Annual ACM Symposium Theory Computing, pp.
7790.
Davis, R., & Lenat, D. (1982). Knowledge-Based Systems Artificial Intelligence. McGraw-Hill,
New York.
Driessens, K., & Dzeroski, S. (2004). Integrating guidance relational reinforcement learning.
Machine Learning, 57, 271304.
Driessens, K., Ramon, J., & Gartner, T. (2006). Graph kernels gaussian processes relational
reinforcement learning. Machine Learning, 64, 91119.
Dzeroski, S., DeRaedt, L., & Driessens, K. (2001). Relational reinforcement learning. Machine
Learning, 43, 752.
Dzeroski, S., Todorovski, L., & Urbancic, T. (1995). Handling real numbers ILP: step towards
better behavioural clones. Proceedings Eighth European Conference Machine
Learning, pp. 283286.
752

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Estlin, T. A., & Mooney, R. J. (1997). Learning improve efficiency quality planning.
Proceedings Fifteenth International Joint Conference Artificial Intelligence, pp.
12271232.
Fahlman, S., & Lebiere, C. (1990). cascade-correlation learning architecture. Advances
Neural Information Processing Systems 2, pp. 524 532.
Farias, V. F., & Van Roy, B. (2004). Tetris: study randomized constraint sampling. Probabilistic Randomized Methods Design Uncertainty. Springer-Verlag.
Fawcett, T. (1996). Knowledge-based feature discovery evaluation functions. Computational
Intelligence, 12(1), 4264.
Fern, A., Yoon, S., & Givan, R. (2004). Learning domain-specific control knowledge random
walks. Proceedings Fourteenth International Conference Automated Planning
Scheduling, pp. 191199.
Fern, A., Yoon, S., & Givan, R. (2006). Approximate policy iteration policy language bias:
Solving relational Markov decision processes. Journal Artificial Intelligence Research, 25,
75118.
Fox, M., & Long, D. (1998). automatic inference state invariants TIM. Journal Artificial
Intelligence Research, 9, 367421.
Gerevini, A., & Schubert, L. (1998). Inferring state constraints domain-independent planning.
Proceedings Fifteenth National Conference Artificial Intelligence, pp. 905912.
Gordon, G. (1995). Stable function approximation dynamic programming. Proceedings
Twelfth International Conference Machine Learning, pp. 261268.
Gretton, C., & Thiebaux, S. (2004). Exploiting first-order regression inductive policy selection.
Proceedings Twentieth Conference Uncertainty Artificial Intelligence, pp. 217
225.
Guestrin, C., Koller, D., & Parr, R. (2001). Max-norm projections factored MDPs. Proceedings Seventeenth International Joint Conference Artificial Intelligence, pp. 673680.
Holldobler, S., Karabaev, E., & Skvortsova, O. (2006). FluCaP: heuristic search planner
first-order MDPs. Journal Artificial Intelligence Research, 27, 419439.
Holldobler, S., & Skvortsova, O. (2004). logic-based approach dynamic programming.
Proceedings Workshop Learning Planning Markov ProcessesAdvances
Challenges Nineteenth National Conference Artificial Intelligence, pp. 3136.
Kakade, S. (2001). natural policy gradient. Advances Neural Information Processing
Systems 14, pp. 15311538.
Kambhampati, S., Katukam, S., & Qu, Y. (1996). Failure driven dynamic search control partial
order planners: explanation based approach. Artificial Intelligence, 88(1-2), 253315.
Karalic, A., & Bratko, I. (1997). First order regression. Machine Learning, 26, 147176.
Keller, P., Mannor, S., & Precup, D. (2006). Automatic basis function construction approximate dynamic programming reinforcement learning. Proceedings Twenty-Third
International Conference Machine Learning, pp. 449456.
753

fiW U & G IVAN

Kersting, K., Van Otterlo, M., & De Raedt, L. (2004). Bellman goes relational. Proceedings
Twenty-First International Conference Machine Learning, pp. 465472.
Kersting, K., & Driessens, K. (2008). Non-parametric policy gradients: unified treatment
propositional relational domains. Proceedings Twenty-Fifth International Conference Machine learning, pp. 456463.
Khardon, R. (1999). Learning action strategies planning domains. Artificial Intelligence, 113(12), 125148.
Lagoudakis, M. G., Parr, R., & Littman, M. L. (2002). Least-squares methods reinforcement
learning control. SETN 02: Proceedings Second Hellenic Conference AI, pp.
249260.
Mahadevan, S., & Maggioni, M. (2007). Proto-value functions: Laplacian framework learning representation control Markov decision processes. Journal Machine Learning
Research, 8, 21692231.
Martin, M., & Geffner, H. (2004). Learning generalized policies planning examples using
concept languages. Applied Intelligence, 20, 919.
Mitchell, T. M. (1997). Machine Learning. McGraw-Hill.
Muggleton, S. (1991). Inductive logic programming. New Generation Computing, 8(4), 295318.
Parr, R., Li, L., Taylor, G., Painter-Wakefield, C., & Littman, M. (2008). analysis linear
models, linear value-function approximation, feature selection reinforcement learning.
Proceedings Twenty-Fifth International Conference Machine Learning, pp. 752
759.
Parr, R., Painter-Wakefield, C., Li, L., & Littman, M. (2007). Analyzing feature generation
value-function approximation. Proceedings Twenty-Fourth International Conference
Machine Learning, pp. 737744.
Patrascu, R., Poupart, P., Schuurmans, D., Boutilier, C., & Guestrin, C. (2002). Greedy linear valueapproximation factored Markov decision processes. Proceedings Eighteenth
National Conference Artificial Intelligence, pp. 285291.
Petrik, M. (2007). analysis Laplacian methods value function approximation MDPs.
Proceedings twentith International Joint Conference Artificial Intelligence, pp.
25742579.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann.
Quinlan, J. R. (1996). Learning first-order definitions functions. Journal Artificial Intelligence
Research, 5, 139161.
Rivest, F., & Precup, D. (2003). Combining TD-learning cascade-correlation networks.
Proceedings Twentieth International Conference Machine Learning, pp. 632639.
Sanner, S., & Boutilier, C. (2006). Practical linear value-approximation techniques first-order
MDPs. Proceedings Twenty-Second Conference Uncertainty Artificial Intelligence, pp. 409417.
Sanner, S., & Boutilier, C. (2009). Practical solution techniques first-order MDPs. Artificial
Intelligence, 173(5-6), 748788.
754

fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING

Singh, S., Jaakkola, T., Littman, M., & Szepesvari, C. (2000). Convergence results single-step
on-policy reinforcement-learning algorithms. Machine Learning, 38(3), 287308.
Sutton, R. S. (1988). Learning predict methods temporal differences. Machine Learning,
3, 944.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.
Szita, I., & Lorincz, A. (2006). Learning tetris using noisy cross-entropy method. Neural
Computation, 18, 29362941.
Tesauro, G. (1995). Temporal difference learning TD-Gammon. Communications ACM,
38(3), 5868.
Tsitsiklis, J., & Roy, B. V. (1997). analysis temporal-difference learning function approximation. IEEE Transactions Automatic Control, 42(5), 674690.
Utgoff, P. E., & Precup, D. (1997). Relative value function approximation. Tech. rep., University
Massachusetts, Department Computer Science.
Utgoff, P. E., & Precup, D. (1998). Constuctive function approximation. Motoda, & Liu (Eds.),
Feature Extraction, Construction, Selection: Data-Mining Perspective, pp. 219235.
Kluwer.
Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating planning
learning: PRODIGY architecture. Journal Experimental Theoretical AI, 7(1),
81120.
Widrow, B., & Hoff, Jr, M. E. (1960). Adaptive switching circuits. IRE WESCON Convention
Record, 96104.
Williams, R. J., & Baird, L. C. (1993). Tight performance bounds greedy policies based
imperfect value functions. Tech. rep., Northeastern University.
Wu, J., & Givan, R. (2007). Discovering relational domain features probabilistic planning.
Proceedings Seventeenth International Conference Automated Planning
Scheduling, pp. 344351.
Wu, J., Kalyanam, R., & Givan, R. (2008). Stochastic enforced hill-climbing. Proceedings
Eighteenth International Conference Automated Planning Scheduling, pp. 396403.
Wu, J., & Givan, R. (2005). Feature-discovering approximate value iteration methods. Proceedings Symposium Abstraction, Reformulation, Approximation, pp. 321331.
Yoon, S., Fern, A., & Givan, R. (2002). Inductive policy selection first-order MDPs. Proceedings Eighteenth Conference Uncertainty Artificial Intelligence, pp. 568576.
Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning. Proceedings Seventeenth International Conference Automated Planning Scheduling, pp. 352358.
Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic track
international planning competition. Journal Artificial Intelligence Research, 24, 851887.

755

fiJournal Artificial Intelligence Research 38 (2010) 189-221

Submitted 10/09; published 05/10

Constructing Reference Sets Unstructured,
Ungrammatical Text
Matthew Michelson

mmichelson@fetch.com

Fetch Technologies
841 Apollo St, Ste 400
El Segundo, CA 90245 USA

Craig A. Knoblock

knoblock@isi.edu

University Southern California
Information Sciences Institute
4676 Admiralty Way
Marina del Rey, CA 90292 USA

Abstract
Vast amounts text Web unstructured ungrammatical, classified ads, auction listings, forum postings, etc. call text posts. Despite
inconsistent structure lack grammar, posts full useful information. paper presents work semi-automatically building tables relational information, called
reference sets, analyzing posts directly. Reference sets applied number tasks ontology maintenance information extraction. reference-set
construction method starts small amount background knowledge, constructs tuples representing entities posts form reference set. also describe
extension approach special case even small amount background knowledge impossible discover use. evaluate utility machineconstructed reference sets, compare manually constructed reference sets
context reference-set-based information extraction. results show reference sets
constructed method outperform manually constructed reference sets. also compare reference-set-based extraction approach using machine-constructed reference
set supervised extraction approaches using generic features. results demonstrate
using machine-constructed reference sets outperforms supervised methods, even
though supervised methods require training data.

1. Introduction
vast amounts unstructured, ungrammatical data Web. Sources
data include classified ads, auction listings, bulletin board/forum postings. call
unstructured, ungrammatical data posts. Figure 1 shows example posts, case
set classified ads cars Craigslist site. consider posts unstructured
one cannot assume ordering terms consistent post
post. instance, Figure 1 cannot assume car make (e.g., Audi) precede
car model (e.g., A4). Further, consider posts ungrammatical would
yield useful grammatical parse (it would yield nouns almost exclusively).
Although posts unstructured ungrammatical, full useful information.
posts Figure 1 contain information cars different varieties cars
c
2010
AI Access Foundation. rights reserved.

fiMichelson & Knoblock

Figure 1: Example posts cars

sale, price, etc. Therefore, analyzing posts corpus information yield
number insights.
paper focus analyzing posts build reference sets, relational
tables entities attributes. instance, reference set cars would include
attributes car make (e.g., Mercury), car model (Sable), car trim (GS).
Reference sets used background information number tasks, particular, recent interest using reference sets background knowledge
information extraction (Michelson & Knoblock, 2007, 2008; Mansuri & Sarawagi, 2006; Cohen & Sarawagi, 2004). completeness, describe previous work reference-set-based
information extraction detail Section 2.
goal exploit dense information content posts construct reference sets
little human intervention possible. Posts numerous, freely available,
generally large number useful attributes packed short strings. Further, posts
sometimes cover obscure entities one might find general Web text (another
possible corpus mining reference set). instance, many categories
items auction sites specific particular. items may mentioned
frequently Web text outside posts. Therefore, posts attractive data source
building reference sets.
contrast approach manually constructing reference sets, poses number
challenges. importantly, user must discover correct source(s)
build reference set. reference sets built extracting information
semi-structured websites using wrappers (Muslea, Minton, & Knoblock, 2001; Crescenzi,
Mecca, & Merialdo, 2001), challenge parsing data, rather choosing
correct sources. often cases difficult find sources enumerate
reference set interest, therefore building reference set becomes challenging
problem finding multiple sources use, aggregating records, taking care
duplicates. instance, demonstrate results, difficult find single sources
enumerates specific attributes model numbers laptops.
Dell Inspiron 1720, Inspiron E1405, 2650, name few. happens across
IBM laptops, Dell laptops, HP laptops, etc. create reference set encompasses
laptop model numbers would require finding scraping multitude websites.
Yet, useful attribute extraction since difference Inspiron 1720
E1405 important end user. However, posts generally aggregation
items people interested in, using posts reference set one discover
exhaustive list.
190

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Further, data reference sets constantly changing. example, considering laptop domain, new laptop model numbers released every months new
hardware improvements made. Therefore, even comprehensive laptop reference set
built multiple sources, become stale months, reference set need updated time sources updated new laptops.
creates additional challenge creating reference sets wrapped sources
sources must constantly monitored changes assure reference
set reflects changes.
Lastly, stated above, much work motivated using reference sets
background knowledge aid information extraction (Section 2). However, even user
extract reference set Web sources using wrappers, guarantee
reference set appropriate given data extraction. Concretely, assume goal
extract car information Craigslist classifieds Figure 1, assume
user built reference set American cars using Web sources. reference set
useful posts cars outside United States. call mismatch
reference set posts coverage problem entities
posts covered records reference set.
coverage mismatches also happen data constantly changing,
laptops described above. case, websites new laptops used create
reference set, might mismatch used laptops generally sold
classified ads (in fact, demonstrate effect results). Therefore,
number advantages building reference sets posts instead Web sources,
although course could complementary processes.
paper elaborates previous work building reference sets posts (Michelson & Knoblock, 2009). First, describe previous method detail. Second,
previous method exploits small amount background knowledge build reference
set, paper also significantly extend algorithm handle special case
background knowledge source known. demonstrate even
totally unknown source still construct reference set useful extraction.
rest paper follows. Section 2 describes detail process
using reference sets information extraction. Section 3 describes method
constructing reference sets posts themselves. Section 4 presents experiments
analyzes results. Section 5 discusses related work, Section 6 presents
conclusions future work.

2. Previous Work using Reference Sets Information Extraction
motivate work constructing reference sets putting context discovering reference sets use information extraction. particular, focus
task extracting information posts using reference sets, shown
previously aid task quite bit (Michelson & Knoblock, 2005, 2007). Information
extraction task parsing desired attributes text (posts case).
Using example posts Figure 1, extraction, would like posts Figure 1
separated make attribute, model attribute, trim attribute. Specifically, third post could annotated extractions MAKE={Honda} (which
191

fiMichelson & Knoblock

implied!), MODEL={Accord}, TRIM = {EX}. done, would allow
structured queries integration posts, using extracted attributes instead
full text post.
Given posts conform English grammar, Natural Language Processing approaches extraction would work posts (Ciravegna, 2001). Further, since posts
unstructured, wrapper methods would work either (Muslea et al., 2001; Crescenzi
et al., 2001). Instead, recent work showed extraction posts benefits exploiting reference sets (Michelson & Knoblock, 2005, 2007).
Previous work exploiting reference sets extraction uses two step process, shown
Figure 2. first step, algorithm discovers best matches post
tuples reference set. Then, second step, algorithm performs
information extraction comparing tokens post attributes matches
reference set. example, token Accord would extracted model
since would match model attribute matching tuple reference set.
key idea without labeled data, system perform information extraction
relying solely information reference set, rather grammatical
structural patterns. Recent work shows perform reference-set-based extraction
automatically (Michelson & Knoblock, 2007) using techniques machine learning
(Michelson & Knoblock, 2008).

Figure 2: Reference-set based extraction
previous work reference-set-based extraction assumes user manually
constructed reference set supply algorithm. strong assumption
many potential difficulties stated above. Therefore, helps motivate
approach take paper, building reference sets posts, little (or no) human
intervention. method paper rely labeled data, may
require small amount background knowledge produce clean useful reference
sets. machine-constructed reference sets applied plugging
reference-set-based extraction framework automatic extraction posts.
192

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Within context information extraction, emphasize two main
benefits using posts construct reference set. First, challenge
discovering sources manually build reference set overcome since
posts used. Second, since reference set constructed
posts, overlapping coverage definition. show experiments,
approach especially useful covering attributes particularly difficult
cover manual reference sets, laptop model numbers, constantly change
hard enumerate.
note although motivate work building reference-sets context
information extraction, machine constructed reference sets useful many
tasks require background knowledge. use structured entities fill
taxonomies, help construct ontologies Semantic Web, simply see tuples
reference set might exist posts, help topic classification query
formulation. emphasize information extraction task described one
application reference sets, useful proxy comparing utility
various reference sets (as experiments). However, work described
paper focuses specific task reference set construction, rather extraction
described elsewhere.

3. Reference Set Construction
intuition constructing reference sets posts reference set tuples often
form hierarchy-like structures, call entity trees. Consider simple reference
set three cars Figure 3. tuple reference set cars two attributes,
make model. model specific version make (i.e., Accord
Honda), Accord attribute value child node Honda value.
said Civic value, generate entity tree rooted
value Honda, two children: Civic Accord. argument applies turn
Ford tuple entity tree. However, entity trees rooted Honda Ford
disjoint, since share ancestors. reference set really forest
entity trees. So, algorithm constructs set entity trees, traverse
them, outputting tuple path root leaf, union tuples
creates reference set. Therefore, construct reference set posts, goal really
build forest entity trees posts.
general approach building reference sets posts decomposes two highlevel steps, shown Figure 4. first step breaks posts bigrams. example,
post, Honda civic cool yields bigrams: {Honda, civic}, {civic, is}, etc.1 Creating
bigrams pre-processing step, since second step algorithm takes full set
bigrams input generates reference set.
second step algorithm three sub-components. First, algorithm generates initial set entity trees based upon bigrams (shown step 2.1). Next,
1. Note algorithm considers ordered bigrams, rather combination token pairs.
done efficiency, since measured average post length 8.6 tokens across thousands
posts, would generate 40,320 possible token pairs check, per post, pairs
considered.

193

fiMichelson & Knoblock

Figure 3: reference set entity trees

iteratively adds new attributes entity trees general token attributes,
define (step 2.2). Finally, algorithm traverses entity tree root
leaf, outputting path generate reference set (step 2.3). discuss methods
creating entity trees discovering general tokens detail following subsections.

Posts

Step 1

--------------------------------------------------------------------------

Construct Bi-Grams

Step 2.1:
Create Entity Trees
Step 2

Step 2.2:
Discover general tokens
Step 2.3:
Form Reference Set

Figure 4: Constructing reference sets posts

194

fiConstructing Reference Sets Unstructured, Ungrammatical Text

3.1 Creating Entity Trees
stated above, first step approach converts set input posts set
bigrams. build entity trees bigrams use modified version Sanderson
Croft (1999) heuristic finding token subsumptions, notion token x
subsumes y, child node x entity tree contains x. define
rule subsumption given terms x as:2
x subsumes P (x|y) 0.75 P (y|x) P (x|y)
example, consider four posts shown Table 1. consider token
pair Honda Civic see conditional probability Honda given Civic
(P (Honda|Civic)) 1.0, P (Civic|Honda) 0.5 (since Honda occurs four posts
Honda occurs Civic two). Therefore, subsumption rule fires, Civic
becomes child node Honda. Similarly, Accord becomes child Honda, resulting
entity tree Figure 3.
Table 1: Four example posts
Honda civic cool
Look cheap Honda civic
Honda accord rules
Honda accord 4 u!

Since consider ordered bigrams, building entity trees based Sanderson
Croft heuristic requires assumption order entity tree reflected
posts. is, users tend order attributes general (e.g., car makes)
specific (e.g., car models). Also, ordering needs hold least enough
posts make subsumption rule fire.
Yet, approach builds entity trees, constructs useful reference sets
used effectively extraction, shown experiments. Therefore, approach
leverages little ordering find bigrams build reference set,
use extract values posts ordering assumption hold.
Further, given approach finds effective entity trees reflects notion
users tend order attributes general specific. case,
discovered entity trees would little utility extraction later.
Sanderson Croft heuristic defined single tokens x y, yet
attribute values unigrams. Therefore, handle bigrams, add constraint
x subsumes subsumes x, merge x single node (attribute value).
instance, given attribute values Crown Victoria Crown subsumes Victoria
Victoria subsumes Crown merge single value Crown Victoria
(which subsumed common parent Ford). note bigram actually
merged using approach. extend n-grams, one simply checks token pairs
subsumption.
2. Note, require terms x co-occur least rule considered.

195

fiMichelson & Knoblock

reference sets constructed algorithm experiments, 5.49%
attribute values n-grams containing single token, large enough
percentage validate including merge heuristic approach. Therefore, technique solely applicable case reference set values single tokens. However, cases merging heuristic perform well, discuss
detail discussion Section 4.3.
directionality imposed Sanderson Croft heuristic important
approach. Specifically, Sanderson Croft heuristic uses conditional probabilities
imposes directionality relationship tokens allows
form subsumption relationships. is, x subsumes y, x parent based
directionality imposed conditional probability. need directionality
entity trees must relative subsumption ordering align trees
reference set. specifically, using example Figure 3, building
reference set entity trees, know columns reference set
aligned based positions entity tree. So, roots entity tree form
leftmost column reference set table (Honda, Ford), children (Honda, Accord,
Focus) form next right column, etc., leaves entity trees. So,
tracing paths root leaf, sure tuples outputted disjoint
trees still align correctly columns reference set ordering
imposed directionality.
contrast probabilistic measures term co-occurrences Pointwise Mutual Information (PMI).3 Specifically, PMI symmetric therefore
provides strong measure term relationships, unclear order terms based
measure, therefore, even one use symmetric relationship find
reference set tuples, unclear align disjoint tuples (e.g., Honda Ford tuples)
based metric since impose relative ordering attributes.
reason, require asymmetric measure.
3.2 Discovering General Tokens
constructed initial entity trees, iterate posts discover
possible terms occur across trees. Specifically, subsumption determined
conditional probabilities tokens, second token much frequent
first token, conditional probability low yield subsumption.
occurs attribute value appears across entity trees (reference set tuples).
Since second term occurs frequently first across tuples, call
general token effect.
example general token effect seen trim attribute cars.
instance, consider posts Table 2 show general token effect trim
value LE. posts show LE trim occurring Corolla model, Camry
model, Grand model, Pathfinder. Since LE happens across many different
posts many varying bigrams, call general token, conditional probability
never high enough subsumption. Thus never inserted entity tree.
3. terms x y, PMI defined P I(x, y) = log

196

p(x,y)
p(x)p(y)

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Table 2: Posts general trim token: LE
2001 Nissan Pathfinder LE - $15000
Toyota Camry LE 2003 - 20000 $15250
98 Corolla LE 145K, Remote entry w/ alarm, $4600
1995 Pontiac Grand LE (Northern NJ) $700
compensate general token peculiarity, iteratively run subsumption
process, iteration first, consider conditional probability using
set first tokens bigrams share common second token bigram.
Note, however, set contains bigrams whose first token already node entity
tree, otherwise algorithm may counting noise conditional probability.
reason run first iteration. algorithm iterates
longer generates new attribute values.
make clear, consider LE trim. possible cross-tree attribute would occur disjoint subtrees rooted CAMRY, COROLLA,
PATHFINDER. iterating, algorithm considers following conditional probability
subsumption, assuming models Camry, Corolla Pathfinder already
discovered:
P ({CAM RY COROLLA P HF DER}|LE)
Now, conditional probability fits heuristic subsumption, LE added
child nodes CAMRY, COROLLA PATHFINDER respective
entity trees. Iterating important step since method tests general token
subsumption terms occurs bigram already entity trees.
So, LE occurred tokens, none entity tree already,
method ignores noise. approach must iterate since new general tokens
considered occur attribute entity tree, approach may discover
new general token add entity tree, turn allows approach
discover another new general token. experiments describe effects iterating
versus not. final step approach Figure 4 turns entity trees
reference set tracing paths trees, outputting nodes columns
reference set tuples.
However, blindly applying subsumption method lead noisy entity trees.
common occurrence auction listings, instance, include term Free Shipping
Free Handling. phrases occur frequently enough posts, subsumption
rule fire, creating entity tree rooted Free children Shipping Handling.
Clearly noisy tree used would introduce noisy extractions. Therefore,
following two subsections describe different approaches handling noise process
constructing entity trees.
3.3 Seed-Based Reference Set Construction
first approach dealing noise exploits small amount background knowledge,
called seeds, focus construction entity trees. Specifically, use method
Figure 4 build entity trees, added constraint entity tree must
197

fiMichelson & Knoblock

rooted given seed value. gave Honda seed, one entity tree
rooted Honda would constructed. Even entity trees discovered,
discarded. easy discover exhaustive list seeds Web including
many seeds issue algorithm simply removes entity tree consists
solely root constructed reference set (i.e., singleton set).
One key intuitions behind approach set root nodes entity
trees generally much easier discover online nodes farther trees.
instance, consider laptops, manufacturers laptops (the roots) fairly easy
discover enumerate. However, one traverses farther entity trees, say
model numbers, becomes hard find information. Yet, small set seeds
enough improve process reference set construction substantially, show
results compare reference sets constructed without seed-based
constraint. Also, importantly, attributes farther tree change time
(new model numbers released often), seeds infrequently change (there
new computer manufacturers). So, using reference set information extraction,
coverage becomes less issue considering roots versus attributes
reference set tuple.
manner construct reference set directly posts, using seeds
constrain noise generated final reference set. Table 3 describes full
algorithm constructing entity trees using seeds, turned reference
set outputting tuple path root leaf tree.
3.4 Locking-Based Reference Set Construction
seed-based method handles noise exploiting small amount background knowledge. describe second approach dealing noise case
seeds impossible discover costly find use.
approach revolves around locking mechanism. seeds seed-based
method constrain possible entity trees limiting attributes become roots
entity trees. This, turn, leads cleaner useful reference sets. Therefore,
lacking seeds, goal introduce constraining mechanism prevents
noise introduced entity trees. approach lock levels
entity trees certain points, locking new attribute values
introduced level entity trees.
Since many attributes discover specifications general attributes
(such car models specify makes), point although may discovering new values specific attributes (car models), saturated
discover parent attribute (car makes). Further, saturate parent
attributes, algorithm introduce new values representing new parents,
likely noise. So, algorithm lock parent attribute saturation point,
allow discovery new attributes level locked attribute
hierarchies.
Consider example shown Figure 5. iteration algorithm discovered
two entity trees, one rooted car make Ford one rooted car make
Honda. makes also models associated (their children).
198

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Table 3: Entity tree construction using seeds
MineReferenceSet(Posts P , Seeds S)
/* First, break posts bigrams */
Bigrams B MakeBigrams(P )
/* Build entity trees rooted seeds */
AddedNodes N {}
{x, y} B
/* {x, y} bigram */
x
/* check x seed */
x subsumes
child x entity tree
N N
/*Find childrens children, children, etc.*/
N null
{s, t} B
N
N N -s
subsumes
child tree
N N
/* Iterate discover general token nodes */
/* Start unique nodes already entity trees */
AllEntityNodes UniqueList(All Entity Trees)
/* Keep iterating find new terms */
FoundNewTerms true
FoundNewTerms true
FoundNewTerms false
/* Consider terms {p0 , . . ., pn } entity trees
form bigrams non-entity tree term q */

( {p0 , . . ., pn }, q) s.t. {p0 , . . ., pn } AllEntityNodes

{p0 , . . ., pn } subsumes q
/* consider P ( pi |q) */
q becomes child pi trees
AllEntityNodes AllEntityNodes q
FoundNewTerms true

bottom figure shows future time (iteration t+y), point system
decides lock make attribute, model trim. Therefore, algorithm
still add car models (as Taurus model Ford make) car trims
(as LX trim Civic model). However, since make attribute locked,
make attributes allowed, therefore hierarchy would rooted
make Brand model New (which noise) allowed.
shown right crossed out.
manner, locking acts like pre-pruner attribute values similar spirit
seeds. intent algorithm lock attributes right time
minimize number noisy attributes may introduced later iterations.
works noise often introduced algorithm iterates,
199

fiMichelson & Knoblock

Figure 5: Locking car attributes
beginning. example, instead post-pruning away hierarchy rooted Brand,
algorithm instead prevented added locking make attribute.
assumption deeper levels tree, posts need examined
attributes represented levels trees rarer. However, higher
level tree, common attribute value therefore fewer posts
need examined. assumption exploit justify locking top
manner. is, lock roots entity trees children
assume need see fewer posts discover roots children.
assumption carries tree, lock leaves last need see
posts generate leaves. So, locking approach terminates attributes
(i.e., levels entity trees) become locked, since point processing
posts that.
Based assumption, model locking mechanism requesting service.
assumption need look fewer posts higher trees,
help eliminate noise (justified experiments comparing locking
locking). rather process posts once, instead algorithm
request batches posts process them, building entity trees using approach
Figure 4. receiving next batch posts, algorithm builds new set
entity trees, compares previously discovered ones, algorithm decides
whether lock level. lock, requests posts examine. keeps
requesting posts examine levels entity trees locked. note, however,
batch comes processing, combined previously seen
posts. way, gradual build number posts system examines
given level, sense algorithm iterates examines previous
posts time receives new batch.
Therefore, leverage notion locking process requires continuous requests posts user locks attributes. Essentially, request,
machine compares discover using given posts discover
200

fiConstructing Reference Sets Unstructured, Ungrammatical Text

using previous set given posts (note newly requested set supersedes
previous set). example, algorithm may start examining 100 posts build
reference set. Then, levels entity trees locked, algorithm requests
100 posts analyzes 200 posts build reference set. algorithm
compares discover using first 100 posts discover using
combined 200 posts. algorithm thinks cannot discover useful attributes
200 posts 100 posts, locks certain attributes (Again, note 100
posts subset 200 posts).
comparison locking, algorithm compares entropies generating
given attribute (e.g., member given level entity tree), based upon likelihood
token labeled given attribute. So, cars domain would calculate
entropy token labeled make, model, trim (note label names
given post-hoc, machine simply regards attribute1 , attribute2 , etc.).
clarity, define pmake (x) probability arbitrary token x labeled
make attribute (e.g., falling level entity tree associated make),
define entropy, H(make) as:4
X

H(make) =

pmake (x) log(pmake (x))

xtokens

So, given attribute A, use pA (x) define H(A) as:
H(A) =

X

pA (x) log(pA (x))

xtokens

entropy labeling particular attribute interpreted uncertainty
labeling tokens given attribute. So, see posts,
entropy change seeing 100 posts seeing 200 posts, uncertainty
labeling attribute steady need keep mining attribute
posts. However, cannot directly compare entropies across runs, since
underlying amounts data different. So, use normalized entropy instead. is,
attribute (e.g., make), given N posts, define normalized entropy H(A)N :
H(A)N =

H(A)
logN

Although entropy provides measure uncertainly token labels,
provide sufficient comparison runs varying numbers posts. provide
explicit comparison, analyze percent difference normalized entropies
across runs. instance, using attribute A, would compare entropies runs
across 100 posts 200 posts (defined H(A)100 H(A)200 respectively), computing
percent difference them:
P D(H(A)100 , H(A)200 ) =

1
2

|H(A)100 H(A)200 |
(H(A)100 + H(A)200 )

value minimum (ideally 0), know lock attribute 100 posts,
since using 200 posts yield information entropies essentially
4. assumes built reference set compute probabilities pmake (x).

201

fiMichelson & Knoblock

(i.e., uncertainty steady). So, algorithm locks attribute
finds minimum percent difference entropies across runs attribute.
minimum found using greedy search previously calculated PD values. Table 4
summarizes technique locking attributes mining reference set.
Table 4: Locking attributes
LockingAttributes(Attributes A, Posts Pi , Posts Pj ,
ReferenceSet RSi , ReferenceSet RSj , LockedAttributes L)
/* Pi first set posts */
/* Pj next set j posts, Pi Pj */
/* RSi RSj reference sets Pi Pj
respectively used posts compute likelihoods pA (x) */

/* L set previously locked attributes */
attribute
locked
/* Compute entropies H(a)i H(a)j defined */
H(a)i Compute entropy given Pi RSi
H(a)j Compute entropy given Pj RSj
PD(H(a)i , H(a)j ) minimum previous values
Parent(a) L /* Parent locked */
Lock(a)
LLa
return L

two small items note. First, add heuristic attribute may
lock parent attribute already locked, prevent children locking parents.
Second, although discussion repeatedly mentions machine requesting
posts user, note algorithm automatically request posts
sources using technology RSS feeds, alleviating human involvement beyond
supplying URL source.
Therefore, using technique lock attributes go, even
generating new children attribute values, parents locked, acts
automatic pruning method. Further, know stop asking posts,
stopping criteria number posts need run mining algorithm.
stopping criteria important since assumption algorithm exhausted
possible reference set membership locks levels. Note, assumption could
violated algorithm supplied enough posts (since would never lock
levels).
Table 5 ties aspects together describing Iterative Locking Algorithm
(ILA) mining reference set tuples posts without seeds. Essentially, approach
seed-based method: batch posts, algorithm constructs
entity trees scanning data iterating general tokens. key difference
ILA constrain roots entity trees seeds, instead uses
locking block attributes added trees. Further, locking approach
processes batches posts time, flow different requests batch
posts, builds/refines entity trees, tests trees locking conditions,
proceeds next batch posts.
202

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Table 5: ILA method mining reference sets
MineReferenceSet(Posts, x, y)
# x number posts start
# number posts add iteration
Posts Px GetPosts(x)
ReferenceSet RSx BuildReferenceSet(Px )
/* Algorithm Table 3, except
ignore constraint tree roots seeds */

finished false
LockedAttributes L {}
while(finished false)
x x+y
Posts Py GetPosts(x)
ReferenceSet RSy BuildReferenceSet(Py , L)
/* Table 3, except
add nodes unlocked levels trees */

Attributes GetAttributes(RSx )
/* GetAttributes returns columns found reference set */
L L LockingAttributes(A, Px , Py , RSx , RSy , L)
|L| equals |A| /* size, attributes locked */
finished true
Px Py
RSx RSy

4. Experiments
goal research construct reference sets tasks information
extraction posts. However, directly comparing reference sets constructed various
ways number problems. First, unclear directly compare reference sets
quantitatively. problem noted elsewhere well context comparing
hierarchies (e.g., Bast, Dupret, Majumdar, & Piwowarski, 2006). instance,
clear measures define similarities comparing hierarchies. Second, without
context, hard judge reference sets. is, one reference set may huge
comprehensive, high utility task ontology construction, might
little use extraction due coverage mismatches. Another reference set may quite
noisy (therefore bad ontology construction), actually preferred extraction
since coverage better.
Therefore, instead measuring goodness reference sets directly, instead put
context information extraction task using reference-set-based
extraction posts. compare extraction results use results
proxy utility reference set. assumption extraction results
reflect reference sets utility since noisy reference set lead poor extraction,
would reference set poor coverage posts.
following subsections test two different approaches constructing reference sets: seed-based approach locking based approach (ILA).
4.1 Experiments: Seed-based Approach
first experiment, test effectiveness using seed-based approach
building reference sets. experiment, compare seed-based approach
full, manually constructed reference sets extracted online sources (which call
203

fiMichelson & Knoblock

manual approach) version seed-based approach constrain
entity trees rooted seed values (called seeds). comparing seedbased method manually constructed reference set, test coverage issues
stem collecting reference sets online (versus posts themselves). Further,
comparison allows us analyze trade-off high cost building manual
reference set (versus low cost finding seeds) gains accuracy using
manual reference set. Using seeds tests effectiveness constraining entity
tree roots seeds. is, expect seeds method generates much
noisier reference set (leading poor extraction) seed-based method requires
constraint.
Therefore, first experiment, use manual seed approaches
baselines compare seed-based reference set. procedure,
experimental data sets, build three different reference sets (one manual, one based
seeds, one without seeds) pass reference sets system
exploit perform automatic extraction (Michelson & Knoblock, 2007).
compare extraction results using standard metrics recall, precision, F1 measure. Since difference extraction algorithm reference set provided,
extraction results serve proxy quality reference set terms
well overlaps posts (the coverage) clean (since noise leads
poor extractions), want test.
goal extraction task extract values given attributes. instance, using Figure 1, extract model={Accord} trim={EX}. However,
approach constructing reference sets supply attribute names.
method discovers attribute values Honda Accord, internally labels
associated attribute names attribute0 attribute1 , instead Make Model.
Therefore, clarify results manually label attribute names given manually constructed reference sets. feel much hindrance method.
user find set seeds, user also able find appropriate attributes
names. fact, significantly challenging discover attribute values
finding names.
4.1.1 Data Seed-based Experiments
used three real-world data sets experimental data. first set contains classified ads used cars sale classified site Craigslist.org. these, labeled 1,000 posts test extraction make (e.g., Honda), model (e.g., Civic),
trim (e.g., DX) attributes. second set consists classified ads used laptops
Craigslist.org well. labeled 1,000 posts extracting manufacturer
(e.g., IBM), model (e.g., Thinkpad), model number (e.g., T41). last data set contains posts skis sale eBay. labeled 1,000 posts extraction
brand (e.g., Rossignol), model (e.g., Bandit), model specification (e.g., B3,
called spec). data summarized Table 6.
need full, manually constructed reference sets comparison. Cars domain,
collected 27,000 car tuples pulling data Edmunds.com car buying site
cars combining data classic car site, SuperLambAuto.com.
204

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Table 6: Three experimental data sets
Name
Cars
Laptops
Skis

Source
Craigslist
Craigslist
eBay

Attributes
make, model, trim
manufacturer, model, model num.
brand, model, model spec.

Num. Posts
2,568
2,921
4,981

Laptops domain, scraped 279 laptops online retailer Overstock.com. Lastly,
Skis domain, built 213 ski tuples skis.com website cleaned
remove certain stop words.5
seeds seed-based method also came freely available sources.
car domain, seeds consist 102 car makes, Edmunds. laptop seeds
40 manufacturers, culled Wikipedia, ski seeds 18 ski brands pulled
Skis.com.
4.1.2 Results Seed-based Experiments
Table 7 shows field-level extraction results attribute domain, comparing
three methods.6 Again, manual method uses full reference set constructed
online sources (shown parentheses table), seed method method
without seed-based constraint, full technique called seed-based.
Table 8 summarizes results, showing number attributes seed-based
method outperformed techniques terms F1 -measure. also shows number
attributes seed-based technique within 5% methods F1 -measure
(including attributes seed-based method outperforms method).
F1 -measure within 5% competitive result.
results show seed-based method builds cleaner reference set
fully automatic approach ignores seeds since seed-based approach outperforms
seed approach every single attribute. seed-based method builds cleaner,
effective reference set, leads effective extraction.
results also support notion using posts generate reference set yields reference sets better coverage constructed manually
single source. seed-based method outperform manual reference sets
majority attributes (5/9), seed-based methods reference set better represents
specific attributes (ski model, ski model spec., laptop model, laptop model
num.), attributes likely cause coverage problems. attributes, 53.15% unique attribute values seed-based reference set exist
manually constructed reference set. Therefore, coverage quite different, given
seed-based approach performs better attributes, coverage better.
example, important note Overstock sells new computers,
laptops sale Craigslist generally used, older laptops. So, match
5. posts reference sets experiments available www.mmichelson.com.
6. Field-level results strict extraction correct tokens labeled
are, extra tokens labeled.

205

fiMichelson & Knoblock

Table 7: Extraction results comparing seed-based method
Make
Manual (Edmunds)
seed
Seed-based
Model
Manual (Edmunds)
seed
Seed-based
Trim
Manual (Edmunds)
seed
Seed-based

Cars
Recall
92.51
79.31
89.15
Recall
79.50
64.77
73.50
Recall
38.01
23.45
31.08

Prec.
99.52
84.30
99.50
Prec.
91.86
84.62
93.08
Prec.
63.69
54.10
50.59

F1 -Meas.
95.68
81.73
94.04
F1 -Meas.
85.23
73.38
82.14
F1 -Meas.
47.61
32.71
38.50

Brand
Manual (Skis.com)
seed
Seed-based
Model
Manual (Skis.com)
seed
Seed-based
Model Spec.
Manual (Skis.com)
seed
Seed-based

Skis
Recall
83.62
60.59
80.30
Recall
28.12
51.86
62.07
Recall
18.28
42.37
50.97

Prec.
87.05
55.03
96.02
Prec.
67.95
51.25
78.79
Prec.
59.44
63.55
64.93

F1 -Meas.
85.30
57.68
87.46
F1 -Meas.
39.77
51.55
69.44
F1 -Meas.
27.96
50.84
57.11

Laptops
Manufacturer
Recall
Manual (Overstock) 84.41
seed
51.27
Seed-based
73.01
Model
Recall
Manual (Overstock) 43.19
seed
54.47
Seed-based
70.42
Model Num.
Recall
Manual (Overstock) 6.05
seed
25.58
Seed-based
34.42

Prec.
95.59
46.22
95.12
Prec.
80.88
49.52
77.34
Prec.
78.79
77.46
86.05

F1 -Meas.
89.65
48.61
82.61
F1 -Meas.
56.31
51.87
73.72
F1 -Meas.
11.23
38.46
49.17

Table 8: Summary results seed-based method versus others
Outperforms
Within 5%

Seed vs. seed
9/9
9/9

Seed vs. Manual
5/9
7/9

manufacturers (since laptop manufacturers dont change quickly), even
used laptops six months older new ones sale mismatch
models many model numbers. coverage mismatch using
manual reference sets clear laptop model numbers ski model
specifications. attributes change quite frequently time new
models come out. contrast ski brands laptop manufacturers (our seeds)
change much less frequently enumerated less concern toward
coverage. note chose Wikipedia comprehensive list laptop
manufacturers, Wikipedia enumerates far fewer models model numbers
Overstock reference set would worse choice manual reference set.
206

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Also, note seed-based technique competitive 7/9 attributes
compared full, manually constructed reference sets. Yet, number seeds
drastically smaller number tuples manually constructed reference sets.
So, even though starting much tinier set knowledge, still retain much
benefit knowledge leveraging it, rather explicitly enumerate
tuple attributes ourselves. important much easier find
seeds. Therefore, cost (in manual terms) much lower seed-based approach,
give accuracy performance compared manual approach building
reference sets.
one attribute manual reference set drastically outperforms seed-based
method trim attribute cars, difference roughly 9% F1 -measure.
mostly due fact use field level results, seed-based
technique constructs trim attribute sometimes leaves certain attribute tokens.
instance, consider example extracted trim 4 Dr DX. Here,
seed-based technique includes DX reference set tuples attribute. Meanwhile,
manually constructed reference set contains possible tokens since scraped
comprehensive source (its attribute value 4 Dr DX 4WD). So, although seed-based
technique finds DX token labels correctly trim, misses 4 Dr part
extraction, whole extraction counted incorrect using field level results.
Overall, machine-constructed reference sets yield better extraction results attributes occur higher entity trees. extraction results best
attributes roots entity trees, attributes children roots,
leaves entity trees. largely discovery issue. set possible
attribute values generally grows one traverses tree (e.g., values
laptop models manufacturers, model numbers models, etc.). Therefore,
algorithm needs see posts overcome lack evidence discover
attributes farther entity trees. So, seeing many posts generate
enough evidence compensate issue.
One limitation seed-based technique versus manual construction reference
sets inclusion certain attributes. Surprisingly, enough
repetition posts discovering years cars attributes. due
various factors including variety year representations (all four digits, two digits,
strange spellings, etc.) placement posts years (since consider
bigrams subsumptions). However, full manual reference set contain years
extract attribute, seed-based method cannot. Therefore, since
seed-based method unable learn fit year attributes entity
tree, fails extract it, remove attribute extraction results (as
results essentially 0). Nonetheless, although manual reference set may include
attribute cannot discovered automatically, reference set might terrible
coverage posts, limiting utility. So, feel important deal coverage,
seed-based method does.

207

fiMichelson & Knoblock

4.1.3 Results Iterating General Tokens
also tested effect iterating capture general tokens versus simply stopping
first pass posts. use extraction results proxy comparing
reference sets. case, assumption iterative method capture
general tokens therefore construct fuller reference set yields better extraction
results algorithm stops first pass posts. Table 9 shows
comparable F1 -measure results extraction comparing Single Pass Iterative
approach.

Table 9: Comparing iterating iterating (seed-based method)
Cars
Make
Model
Trim

Single Pass (F1 )
93.29
78.42
16.44

Iterative (F1 )
94.04
82.14
38.50

Single Pass (F1 )
81.77
73.52
49.50

Iterative (F1 )
82.61
73.72
49.17

Single Pass (F1 )
87.30
67.03
42.75

Iterative (F1 )
87.46
69.44
57.11

Laptops
Manufacturer
Model
Model Num.
Skis
Brand
Model
Model Spec.

expected, iterative technique yields better results. iterative method outperforms single-pass approach every attribute except one (Laptop Model Numbers,
F1 -measure decreases -0.33%). Interestingly, iterating, algorithm
improves attributes deeper levels entity trees. is, comparing
extraction results roots entity trees, almost difference. However, second level entity trees slight improvement (around +3.5%
F1 -measure Car Models +2.5% Ski Models), comparing leaves
entity trees improvement (+22% increase Car Trims, +15% increase Ski Model Specifications). So, seems iterating fact capture
general tokens used successful extractions, seems general
tokens seem occur farther trees. note algorithm iterates
times domain, since almost always helps extraction (sometimes quite
dramatically), useful component seed-based approach constructing reference
sets.
208

fiConstructing Reference Sets Unstructured, Ungrammatical Text

4.1.4 Entity Tree Analysis
Although extraction experiments serve best metric actual utility seedbased reference sets, also ran experiments generated entity trees themselves.
examined whether attribute values consistent placement entity trees (the
column homogeny). instance, given known car models Civic measure
model values mostly placed car model attributes (second level tree)
misplaced car trims (third level). However, measuring directly without domain
expertise difficult. Instead, compare attribute values seed-based reference
set manually constructed reference sets, values match,
measure attribute (i.e., columns match) not. yields
measure column homogeny seed-based reference set, based manual
reference set, assumed clean. However, approximate measure
values seed-based reference set match manual reference set, since
differ coverage (see previous results).
Nonetheless, results approximate measurement indicate good level homogeny amongst seed-based attributes. skis, 1.7% found attribute values
wrong column, cars 2.9% values wrong columns.
skis cars common error placing specific attribute (model spec car
trim) one spot higher entity tree been. However, approximation misleading laptops. laptops domain, found perfect column homogeny
using measure, measure column homogeny
attributes match seed-based manual reference sets. Yet,
obvious column homogeny errors, cpu speeds placed model numbers. Since
match manual reference set, ignored homogeny
measuring experiment. Given enough domain expertise, manual
calculation set determined 8.09% tuples seed-based set
cpu speed variant model number incorrect. However, even 8%
good result homogeny.
4.1.5 Comparison Supervised Methods
Although experiments meant test utility reference set (not extraction algorithm itself), one aspect analyze reducing burden user
seed-based approach. is, comparing seed-based reference set (which uses
automatic extractor) supervised machine learning approach extraction,
examine amount labeled data needed supervised system garner similar
results. yields insight gain terms labor cost generating set
seeds much less costly labeling data train classifier, would like
examine much labeled data needed get comparable extraction results.
analyze user effort, compare seed-based results common machine learning approach extraction: Conditional Random Fields (CRF) (Lafferty, McCallum, & Pereira, 2001). used MALLET (McCallum, 2002) implement two
different CRF extractors. One, called CRF-Orth, uses orthographic features tokens extraction, capitalization, number containment, etc. second extractor,
CRF-Win, uses orthographic features also considers two-word sliding win209

fiMichelson & Knoblock

dow around token feature. extractors built reflect common features
techniques CRF-based extraction. Then, perform 10-fold cross validation
extractor (varying amount data training) noting fold independent,
compare average field-level extraction results using supervised approaches
automatic approach using seed-based reference set.
first experiment compares seed-based method CRF using 10%
data training. experiment compares seed-based method supervised
method using small enough amount labeled data reflect real-world cost constraints.
seed-based method outperforms CRFs majority attributes,
effective method extraction also cost effective since outperforms supervised
methods supplied realistic amount training data. Table 10 shows
summary extraction results experiment, similar format Table 8
show number times seed-based method outperforms competitive
another method.
Table 10: Summary results comparing seed-based method CRFs (10% training data)
Outperforms
Within 5%

Seed vs. CRF-Win
7/9
9/9

Seed vs. CRF-Orth
6/9
7/9

Table 10 shows seed-based method outperforms two CRF extractors
majority attributes, even though cost creating seed list significantly
less cost labeling data creating features training specific CRFs.
Further, table shows technique relies heavily structure, CRF-Win,
performs worse extraction posts compared methods.
One aspect analyze based results amount training data needed
supervised methods outperform seed-based methods. analysis,
trained CRFs 10%, 30%, 50% data, note amount
training data CRFs outperform seed-based method. certain cases, even
50% data used training, CRF outperform seed-based method (we
denote amount >50% table). Table 11 shows amount data needed
CRF oupteform seed-based method, broken specific attribute
domain.
results see quite cases either 50% data (or
even more) needed supervised approaches outperform seed-based method
(3/9 CRF-Orth 5/9, majority, CRF-Win). Therefore, large gain
terms cost using seeds, much labeled data would needed
supervised systems. fact, attributes extractors never outperformed
seed-based approach, even given 50% data training. Further, note
once, CRF-Orth Skis domain, less 50% data required
outperform seed-based method attributes. case, using 30%
data training sufficient outperform seed-based method attribute,
labeling 30% data domain far costlier generating list 18 ski
210

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Table 11: Amount training data outperform seed-based approach
Cars
Make
Model
Trim

CRF-Orth
>50%
50%
10%

CRF-Win
>50%
>50%
30%

CRF-Orth
50%
30%
10%

CRF-Win
>50%
>50%
10%

CRF-Orth
30%
30%
10%

CRF-Win
50%
30%
30%

Laptops
Manufacturer
Model
Model Num.
Skis
Brand
Model
Model Spec.

brands used seeds. Lastly, domain would 10% data allow CRFs
outperform seed-based method attributes. Therefore, seed-based method
provides much less costly approach extraction task based amount training
data needed.
one case CRF methods perform well relatively small amount
training data, laptop model number. attribute fits well orthographic
features (since usually capital letters numbers it), extractor
generalize well 10% training data extracting it. argues certain
attributes may benefit extracted using generalized features (such
CRF-Orth) versus reference-set membership (as method does). Therefore, plan
investigate hybrid methods combine best CRF-based extractors
reference-set based extractors.
set experiments demonstrate utility seed-based approach. Comparing seed-based method baseline manually constructed reference set,
showed seed-based method outperforms manual reference set majority
attributes (especially coverage difficult), requiring less user effort
construct. Therefore, reference set constructed using seeds better coverage
manually constructed reference sets used effectively, even though
cheaper construct. Further, showed constraint seed-based method
uses (constraining roots seeds) indeed strong impact results,
versus using constraint. Lastly, compared using seed-based approach
supervised machine learning approach judge comparable amount training data
needed outperform seed-based method, show indeed, takes quite bit
training data compared small number seeds.
211

fiMichelson & Knoblock

4.2 Experiments: Locking Approach
next set experiments analyze locking-based approach building reference sets.
stated above, locking based technique appropriate special case seeds
costly impossible find. Therefore, locking based approach alternative
seed method described previous experiments. experimental procedure
experiments exactly above. use data sets compare
reference sets constructed different ways (seed-based, seed, locked)
passing extraction mechanism comparing extraction results
proxy reference sets utility.
locking algorithm, must specify number posts add locking
iteration. set value 200, large enough limit total possible number
iterations (versus say, 20), also small enough allow algorithm converge
seeing posts (versus, say 1,000, may coarse). Table 12 shows
total number posts (and iterations) required locking algorithm lock
levels entity trees, therefore converge, returning constructed reference set.
note domains, total number posts required locking algorithm
converge less total number posts domain. Table 12 also shows
total number posts domain.

Table 12: Locking convergence results
Domain
Cars
Laptops
Skis

Total Posts Required
Locking
2,000
2,400
4,400

Total Possible Posts

Iterations

2,568
2,921
4,981

10
12
22

Table 13 shows comparative field-level extraction results different domains,
using reference sets generated different methods (seed-based, seed,
locked).
Based upon results Table 13, see locking good alternative simply
locking (no seeds). cars skis domains, one difference
F1 -measure statistically significant using two-tailed test 95% confidence (the
Car Trim attribute). However, laptops domain, locking method outperforms
seed attributes, largely due increase precision, direct result
locking noise entity trees. Therefore, good strategy attempt
locking approach (versus seed approach) since based upon results,
worst case, minimal negative effect generated reference set (evidenced
Car Trim attribute), yield significantly cleaner reference set best
case (as shown laptop results). Further, locking algorithm converged (i.e.,
able lock levels saw posts) domains, able produce
reference sets without burden requiring additional posts.
212

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Table 13: Extraction results comparing locking method
Make
Locked
seed
Seed-based
Model
Locked
seed
Seed-based
Trim
Locked
seed
Seed-based

Cars
Recall
79.64
79.31
89.15
Recall
65.30
64.77
73.50
Recall
19.54
23.45
31.08

Prec.
84.46
84.30
99.50
Prec.
83.24
84.62
93.08
Prec.
52.13
54.10
50.59

F1 -Meas.
81.84
81.73
94.04
F1 -Meas.
72.22
73.38
82.14
F1 -Meas.
28.28
32.71
38.50

Brand
Locked
seed
Seed-based
Model
Locked
seed
Seed-based
Model Spec.
Locked
seed
Seed-based

Skis
Recall
60.84
60.59
80.30
Recall
51.33
51.86
62.07
Recall
39.14
42.37
50.97

Prec.
55.26
55.03
96.02
Prec.
48.93
51.25
78.79
Prec.
56.35
63.55
64.93

F1 -Meas.
57.91
57.68
87.46
F1 -Meas.
50.10
51.55
69.44
F1 -Meas.
46.29
50.84
57.11

Manufacturer
Locked
seed
Seed-based
Model
Locked
seed
Seed-based
Model Num.
Locked
seed
Seed-based

Laptops
Recall Prec.
60.42 74.35
51.27 46.22
73.01 95.12
Recall Prec.
61.91 76.18
54.47 49.52
70.42 77.34
Recall Prec.
27.91 81.08
25.58 77.46
34.42 86.05

F1 -Meas.
66.67
48.61
82.61
F1 -Meas.
68.31
51.87
73.72
F1 -Meas.
41.52
38.46
49.17

4.3 Experiments: Assumptions Constructing Reference Sets
section examine assumptions made data
able construct reference sets using seed-based method (or locking method,
necessary). First, mentioned previously need assume
constructed reference set filled single token attributes, roughly 6%
attributes constructed reference sets n-grams using seed-based method.
note, however, researchers also discussed difficulty discovering n-grams
concept hierarchies text. example, previous work discards concepts
topic hierarchy consist multiple terms (Bast et al., 2006).
Despite fact merging heuristic yield n-gram values attributes,
cases heuristic breaks down. Specifically, perform well domains
attribute values multiple tokens, tokens occur
various frequencies. example, consider users selling items sports teams,
San Diego Chargers helmet, San Francisco 49rs t-shirt. case,
Diego Francisco tokens subsumed San creating unnecessary
entity tree, rather joining terms together. main failure
merging approach: algorithm force subsumption relationship
213

fiMichelson & Knoblock

merging rule fails fire. However, note merging heuristic never causes
subsumption rule fire, rather fails therefore creates errant entity
trees. Therefore, since never destroys information entity tree (e.g., never causes
subsumption fail) consider two approaches improving merge heuristic. First,
could make approach aggressive merging. Second, could perform posthoc analysis constructed entity trees fix errors. instance, one could use
outside information, ontology corpus statistics, determine likelihood
Franscisco child San versus merged single term therefore
cleaning hierarchy account failed merging. Improving merging method
future research challenge.
might seem necessary attributes always appear adjacent
one another posts (e.g., make model trim tokens them),
case. fact, average, across three domains measured 0.115 tokens
attribute posts. significantly larger 0, implies
indeed tokens attributes number posts. Further,
might seem must always see correct order posts (e.g., never see Car
trim attribute Car make attribute) order successfully construct reference
sets. However, again, due unstructured nature posts, see
case. fact, see perfect ordering less half posts three
domains (45.2%), perfect ordering full ordering defined entity tree (e.g.,
Car post make attribute model attribute trim attribute, order).
fact, cars 0.61% posts Car trim attribute coming
attributes, strange random ordering. Therefore, need assume
ordering always correct extraneous tokens
attributes. need assume attribute single token.
enough cases ordering reflect entity tree, words
seen together, subsumption heuristic fire produce correct entity
tree.
Yet, certain number assumptions make order construct reference set. First, must assume reasonable hierarchical structure
entity trees (e.g., Car makes general Car models). Although constraint
holds enormous set categories (e.g., items sale, descriptive categories
geographical person data, etc.) categories lack characteristic (e.g., personal ads). see case analyze information
hotels, using Bidding Travel extraction data set previous work (Michelson
& Knoblock, 2008). data set, goal extract hotel information, hotel
names local areas posts internet forum users talk deals
received hotel accommodations. give seed-based method set
hotel names seeds (from data set) try build reference set roughly
2,500 posts BiddingForTravel.com, expect construct entity trees local
areas children hotel names. However, resulting reference set constructed
well. fact, algorithm finds 20 hotel tuples 132 possible. mostly
due fact even users themselves, created posts, cannot decide
consistent hierarchical structure data. Analyzing posts, users put hotel
name immediately local area 40.58% time local area immediately
214

fiConstructing Reference Sets Unstructured, Ungrammatical Text

hotel name 27.17% time. Therefore, even users
least two intepretations representing data entity trees, ambiguous
whether expect hotel names roots areas roots. note
often case hotel users flip mentions attributes. So,
assumption make posts structured,
structure entity trees consistent (and agreed upon) algorithm
reconstruct entity trees based users posts. is, case, entity
trees rooted either hotel names, local areas, mixture see
reflected users posts. Further, data particularly difficult constructing
reference sets terms attributes freely intermixed. is, tokens
hotel name local area sometimes interspersed, makes difficult
machine determine terms go together attribute. largely due
limiting bi-grams order (which efficiency), perhaps
extend algorithm consider possible combinations bigrams (perhaps
extending method distributed approach) could handle issue.

5. Related Work
focus research creating reference sets posts. reference sets
flattened entity trees, work closely resembles research creating
term hierarchies (subsumptions) text. alternative methods building
term hierarchies. However, methods well suited Sanderson Croft
method (1999) chose problem. First, since data ungrammatical,
cannot use subsumption methods rely Formal Concept Analysis, relate
verbs nouns text discover subsumptions (Cimiano, Hotho, & Staab, 2005).
plenty nouns posts, almost verbs. Further, since algorithm runs
iteratively due general token problem, need method runs efficiently.
algorithm using Sanderson Croft method runs O(kn) time n
number tokens posts, k number iterations general tokens, since
process scans posts create bigrams calculate probabilities
considers high enough probabilities. contrast methods
term subsumption use Principle Component Analysis (PCA) (Dupret & Piwowarski,
2006; Bast et al., 2006) run O(n3 ) time respect token-by-token matrix
(which may sparse). Therefore, PCA methods suitable large number
tokens one iteration. also previous work uses outside
information sources, links image tags users supply
Flickr, aid building term hierarchies (Schmitz, 2006). explicit
links terms users. Lastly, previous work uses Google determine
term dependencies (Makrehchi & Kamel, 2007). However, cannot assume terms
encounter posts occur across many webpages. fact, method work even
posts place mentions entities entire Web (provided
enough posts). However, case, might occur posts
obscure items, could leverage Google-based method. Further, although
alternative approaches building term hierarchies, also one larger,
fundamental difference problem previous work ontology creation.
215

fiMichelson & Knoblock

previous methods build single, monolithic conceptual hierarchy. case,
instead aim build number disjoint entity trees, flatten
reference set.
Along lines discovering term hierarchies text, also work aims
extract features text product reviews. Since entity trees method
constructs often include product features (e.g., Laptop models), work constructs similar
output methods. Approaches feature extraction include association rule mining
finding frequent product features (Hu & Liu, 2004) leveraging Web aid
feature extraction (Popescu & Etzioni, 2005). However, methods rely natural
language processing, part-of-speech (POS) tagging parse reviews possible
features. However, posts grammatical enough support part-of-speech tagging,
cannot use features data.
Recently, even large commercial search engines begun construct
reference sets Web data. Google built Google Squared,7 allows users
type query category returns square reference set related
category. product provides intuitive interface including/excluding attributes
(columns) naming appropriately. However, tested application
experimental domains (providing queries cars, laptops, skis) found
columns square broken constituent attributes finely
reference sets. instance, laptops skis, single attribute (called
item name) essentially functions post describing entity. laptops,
item name combines manufacturer, model, model number single attribute,
skis combines brand, model, model spec. cars, square sometimes
combined make model car item name. Yet, encouraging
large company finds reference sets important useful enough devote
application them, therefore feel methods could greatly
complement technology providing means build even finer grained reference sets
include squares.
stated, goal work build reference sets, used number
tasks, including ontology maintenance, query formulation, information extraction.
Given chose information extraction mechanism evaluating reference
sets, completeness describe related work information extraction put application constructed reference sets context. also point readers previous
work reference-set-based information extraction, also present comparisons
extraction methods (Michelson & Knoblock, 2005, 2007, 2008, 2009).
note information extraction techniques based CRFs
directly use reference sets form either single columns reference set (dictionaries) (Cohen & Sarawagi, 2004) full, relational databases (Mansuri & Sarawagi, 2006),
fact, approaches focus extraction unstructured text, similar posts.
Again, work paper complements methods well either constructed reference set split column-wise produce dictionaries, reference-set
used relational database.
7. www.google.com/squared

216

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Similarly reference-set-based extraction methods described above, extraction methods use ontologies background information (Embley, Campbell,
Jiang, Liddle, Lonsdale, Ng, & Smith, 1999). Later versions work even talk
using ontology-based information extraction means semantically annotate unstructured data car classifieds (Ding, Embley, & Liddle, 2006). Although ways
methods use background information differ (the ontology-based method performs keyword-lookup ontology along structural contextual rules,
reference-set-based methods use either machine-learning string-similarity methods
match posts reference-set members), reference-set construction method presented
complement ontology-based extraction well. One difficulty ontologybased method creating maintaining ontology expensive data engineering
task. Perhaps reference-set construction methods one ease burden
providing method discover ontology instances automatically map relations. Along lines methods use informal ontologies, Wikipedia,
background information (Wu, Hoffmann, & Weld, 2008; Kazama & Torisawa, 2007).
Again, method complementary here, especially unclear whether Wikipedia
would cover obscure tuples could generate reference set.
fact, showed Laptop domain, Wikipedia source laptops nearly
comprehensive Overstock, appropriately cover
posts way generated reference set did.
previous approaches use outside information aid extraction (such
ontologies reference sets), also quite unsupervised methods extraction. Although use reference sets, include completeness
addressing extraction problem. One set techniques focuses finding relations
Web. Aggregating relations sometimes yield reference sets, table person X born country (Cafarella, Downey, Soderland, & Etzioni, 2005;
Hassan, Hassan, & Emam, 2006; Pasca, Lin, Bigham, Lifchits, & Jain, 2006). However,
research differs reference-set-based methods posts extract
relations Web pages allows learn exploit specific extraction patterns. patterns assume similar structures occur make learned
extraction patterns useful, structural assumptions posts cannot made
beyond redundancy bigrams. Again, however, work complements quite
well, methods could perhaps used together build reference sets
Web pages posts.
note task extracting information posts may associated reference set (e.g., apartment listings, entity tree would hard
define) received attention past well. So, space extraction posts
without reference sets covered complementing previous work
reference-set-based extraction posts work extraction posts.
particular, previous work uses information structure ads perform
extraction (e.g., idea certain types posts attributes often multi-token)
(Grenager, Klein, & Manning, 2005). similar work uses prototype learning extraction posts seed examples attributes
extract, called prototypes, provided background knowledge (Haghighi & Klein,
2006). machine-constructed reference sets could provide prototypes automating
217

fiMichelson & Knoblock

approach even further. One interesting approach used posts
associated reference set presented Chang, et. al.
(2007), extraction algorithm encodes uses various constraints extraction.
One supported constraint dictionary membership. described previously,
dictionaries built directly reference sets approach constructs.

6. Conclusion
paper presents method constructing reference sets unstructured, ungrammatical text Web. discovered, reference sets used tasks including ontology maintenance, query formulation, information extraction. demonstrate
utility machine constructed reference-sets comparing manually constructed reference sets information extraction task, show machine
constructed reference sets yield better extraction results.
future plan investigate synonym discovery relationship automatically constructing reference sets. instance, may able automatically
merge branches hierarchy synonyms referring object (such
Lenovo IBM laptops). Further, plan investigate topic dynamic data
integration using automatically mined reference sets. is, system discovers
reference set, would want bring related sources data integration.

Acknowledgments
research based upon work supported part National Science Foundation
award number CMMI-0753124, part Air Force Office Scientific Research
grant number FA9550-07-1-0416, part Defense Advanced Research
Projects Agency (DARPA), Department Interior, NBC, Acquisition
Services Division, Contract No. NBCHD030010.
U.S. Government authorized reproduce distribute reports Governmental purposes notwithstanding copyright annotation thereon. views conclusions
contained herein authors interpreted necessarily representing official policies endorsements, either expressed implied,
organizations person connected them.

References
Bast, H., Dupret, G., Majumdar, D., & Piwowarski, B. (2006). Discovering term taxonomy
term similarities using principal component analysis. Semantics, Web
Mining., LNAI 4289, pp. 103120. Springer.
Cafarella, M. J., Downey, D., Soderland, S., & Etzioni, O. (2005). Knowitnow: fast,
scalable information extraction web. Proceedings conference
Human Language Technology Empirical Methods Natural Language Processing
(HLT-EMNLP), pp. 563570. Association Computational Linguistics.
218

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Chang, M.-W., Ratinov, L., & Roth, D. (2007). Guiding semi-supervision constraintdriven learning. Proceedings 45th Annual Meeting Association
Computational Linguistics, pp. 280287. Association Computational Linguistics.
Cimiano, P., Hotho, A., & Staab, S. (2005). Learning concept hierarchies text corpora
using formal concept analysis. Journal Artificial Intelligence Research, 24, 305339.
Ciravegna, F. (2001). Adaptive information extraction text rule induction
generalisation.. Proceedings 17th International Joint Conference Artificial
Intelligence, pp. 12511256. Morgan Kaufman.
Cohen, W., & Sarawagi, S. (2004). Exploiting dictionaries named entity extraction: combining semi-markov extraction processes data integration methods. Proceedings
10th ACM International Conference Knowledge Discovery Data Mining,
pp. 8998. ACM Press.
Crescenzi, V., Mecca, G., & Merialdo, P. (2001). Roadrunner: Towards automatic data
extraction large web sites. Proceedings 27th International Conference
Large Data Bases, pp. 109118. VLDB Endowment.
Ding, Y., Embley, D. W., & Liddle, S. W. (2006). Automatic creation simplified querying semantic web content: approach based information-extraction ontologies.
ASWC, LNCS 4185, pp. 400414. Springer.
Dupret, G., & Piwowarski, B. (2006). Principal components automatic term hierarchy
building. SPIRE, LNCS 4209, pp. 3748. Springer.
Embley, D. W., Campbell, D. M., Jiang, Y. S., Liddle, S. W., Lonsdale, D. W., Ng, Y. K.,
& Smith, R. D. (1999). Conceptual-model-based data extraction multiple-record
web pages. Data Knowl. Eng., 31 (3), 227251.
Grenager, T., Klein, D., & Manning, C. D. (2005). Unsupervised learning field segmentation models information extraction. Proceedings 43rd Annual Meeting
Association Computational Linguistics, pp. 371378. Association Computational Linguistics.
Haghighi, A., & Klein, D. (2006). Prototype-driven learning sequence models.
Proceedings main conference Human Language Technology Conference
North American Chapter Association Computational Linguistics, pp.
320327. Association Computational Linguistics.
Hassan, H., Hassan, A., & Emam, O. (2006). Unsupervised information extraction approach using graph mutual reinforcement. Proceedings Conference Empirical Methods Natural Language Processing (EMNLP), pp. 501508. Association
Computational Linguistics.
Hu, M., & Liu, B. (2004). Mining summarizing customer reviews. Proceedings
10th ACM International Conference Knowledge Discovery Data Mining,
pp. 168177. ACM Press.
219

fiMichelson & Knoblock

Kazama, J., & Torisawa, K. (2007). Exploiting wikipedia external knowledge
named entity recognition. Proceedings Joint Conference Empirical Methods Natural Language Processing Computational Natural Language Learning
(EMNLP-CoNLL), pp. 698707. Association Computational Linguistics.
Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional random fields: Probabilistic models segmenting labeling sequence data. Proceedings 18th
International Conference Machine Learning, pp. 282289. Morgan Kaufmann.
Makrehchi, M., & Kamel, M. S. (2007). Automatic taxonomy extraction using google
term dependency.. Proceedings IEEE/WIC/ACM International Conference
Web Intelligence, pp. 321325. IEEE Computer Society.
Mansuri, I. R., & Sarawagi, S. (2006). Integrating unstructured data relational
databases. Proceedings International Conference Data Engineering, p. 29.
IEEE Computer Society.
McCallum, A. (2002).
Mallet:
http://mallet.cs.umass.edu.



machine

learning



language

toolkit.

Michelson, M., & Knoblock, C. A. (2005). Semantic annotation unstructured ungrammatical text. Proceedings 19th International Joint Conference Artificial
Intelligence, pp. 10911098. Morgan Kaufmann.
Michelson, M., & Knoblock, C. A. (2007). Unsupervised information extraction unstructured, ungrammatical data sources world wide web. International Journal
Document Analysis Recognition (IJDAR), Special Issue Noisy Text Analytics, 10, 211226.
Michelson, M., & Knoblock, C. A. (2008). Creating relational data unstructured
ungrammatical data sources. Journal Artificial Intelligence Research (JAIR), 31,
543590.
Michelson, M., & Knoblock, C. A. (2009). Exploiting background knowledge build
reference sets information extraction. Proceedings 21st international jont
conference Artifical intelligence, pp. 20762082. Morgan Kaufmann.
Muslea, I., Minton, S., & Knoblock, C. A. (2001). Hierarchical wrapper induction
semistructured information sources. Autonomous Agents Multi-Agent Systems,
4 (1/2), 93114.
Pasca, M., Lin, D., Bigham, J., Lifchits, A., & Jain, A. (2006). Organizing searching
world wide web facts - step one: one-million fact extraction challenge.
Proceedings 21st National Conference Artificial Intelligence (AAAI), pp.
14001405. AAAI Press.
Popescu, A.-M., & Etzioni, O. (2005). Extracting product features opinions
reviews. HLT 05: Proceedings conference Human Language Technology
Empirical Methods Natural Language Processing, pp. 339346, Morristown,
NJ, USA. Association Computational Linguistics.
220

fiConstructing Reference Sets Unstructured, Ungrammatical Text

Sanderson, M., & Croft, B. (1999). Deriving concept hierarchies text. Proceedings
22nd International ACM Conference Research Development Information
Retrieval, pp. 206213. ACM Press.
Schmitz, P. (2006). Inducing ontology flickr tags. Proceedings Workshop
Collaborative Web Tagging.
Wu, F., Hoffmann, R., & Weld, D. S. (2008). Information extraction wikipedia:
moving long tail. Proceedings 14th ACM international conference
Knowledge discovery data mining, pp. 731739. ACM Press.

221

fiJournal Artificial Intelligence Research 38 (2010) 415-473

Submitted 01/10; published 07/10

Resource-Driven Mission-Phasing Techniques Constrained
Agents Stochastic Environments
Jianhui Wu
Edmund H. Durfee

jianhuiw@umich.edu
durfee@umich.edu

Computer Science Engineering, University Michigan
Ann Arbor, MI 48109 USA

Abstract
agents resources dictate actions possibly take, plan
resources holds time carefully, considering inherent limitations (such
power payload restrictions), competing needs agents resources,
stochastic nature environment. agents can, general, achieve
objectives use even create opportunities change resources
hold various times. Driven resource constraints, agents could break
overall missions optimal series phases, optimally reconfiguring resources
phase, optimally using assigned resources phase, given knowledge
stochastic environment.
paper, formally define analyze constrained, sequential optimization
problem single-agent multi-agent contexts. present family mixed
integer linear programming (MILP) formulations problem optimally create
phases (when phases predefined) accounting costs limitations phase creation.
formulations simultaneously also find optimal allocations resources
phase optimal policies using allocated resources phase, exploit
structure across coupled problems. allows find solutions significantly faster
(orders magnitude faster larger problems) alternative solution techniques,
demonstrate empirically.

1. Introduction
omnipresent issue realistic application domains autonomous agents agents
resource-limited. Resources enable action. example, agent camera
capture image, agent gripper manipulate objects, agent auxiliary
battery pack take actions must recharge, agent additional
memory chip solve larger computational problems. Given resources possesses,
agent utilize take best sequences actions can, depending
objectives environment.
paper, consider situation agents degree control
resources choose possess, subject inherent (unavoidable) limitations
agents themselves, well contention resources. Agents inherent limitations stem
call capacity constraints. example, mobile robot agent (say, Mars
Rover) might weight limitations payload carry, cannot carry
camera gripper time. physical configuration resources might
preclude combinations, gripper arm necessarily obstructs camera view.
power drawn across combinations peripherals might exceed agents power supply,
c
2010
AI Access Foundation. rights reserved.

fiWu & Durfee

computational cycles demanded combination time interval might exceed
agents processing power. short, number reasons, agent might lack
capacity effectively possess resources might find useful, case
needs determine subset combination resources will, expectation, allow
act effectively time, given uncertainty future evolution environment.
multiagent setting, agent might fail possess potentially useful resource
capacity constraints, also resource scarcity constraints.
example, might fewer instruments type, working cameras grippers,
robots (Mars Rovers), case cooperative agent get one
resources expects make better use agents would get
it. Along similar lines, number licenses running particular piece software
limited, cooperative agents allocate best possible way
collective benefit. Or, number satellites remotely control order acquire needed
images restricted, assignments agents done judiciously.
Dolgov Durfee (2006) looked kinds problems, studying efficient techniques
agents assess value alternative resource combination (bundle) assignments terms execution policies (and expected utilities policies)
resources enable. work focused question finding optimal static resource
allocation agent (or multiple agents) agent(s) make sequential decisions
stochastic environment.
significant new contribution work present paper consider sequentiality agents actions also allocation resources.1 single
agent case, agent might plan change, midst execution, utilizes limited capacity. example, might return toolbox base station drop
one instrument (e.g., camera) pick another (e.g., gripper). might power
one peripheral power another, terminate one process create another.
multiagent case, agents might particular times swap possesses controls different
instruments, holds licenses various software packages.
precisely, paper present formulations defining, algorithms solving, several classes single- multi-agent sequential resource allocation decision problems
agents acting stochastic environments. problems characterized agents operating multiple phases, set resources held agent (and thus actions
perform) constant within phase, change one phase another.
challenges tackle paper thus involve deciding resource constraints
drive agents overall missions best broken planned phases,
agents decide resources hold phase. shall see, questions
intertwined other, also questions agents formulate
policies pursuing objectives phase.
1.1 Simple Illustrating Single-Agent Example
drive home problem simple form, provide running example
use illustrate formalisms, notations, algorithms coming sections,
present simple schematic example illustrate Single-agent Resource-driven
1. paper brings together significantly extends work previously reported conferences (Wu & Durfee,
2005, 2007a).

416

fiResource-Driven Mission-Phasing Techniques

a1 (0.1), noop (0.8)

1

2

-5

-20
a1 (0.9), noop (0.2)

a2 (1.0), noop (1.0)

3

a4 (0.1), noop (0.5)

a5 (0.2), noop (0.8)

-5
a4 (0.1), noop (0.3)
), noop
a3 (0.9

(0.05)

a3 (0.1), noop (0.95)

4

-5

5
a4 (0.8), noop (0.2)

-5

a5 (0.8), noop (0.2)

6

200

Figure 1: simple single-agent example.

Mission Phasing (S-RMP) problem. present simple multiagent example problem
later paper.
problem, shown Figure 1, agent begins state S1 moves among states
S1 S5 reaches stops state S6 . Associated state Si
reward ri agent receives reaching state, so, example, reaching state S2 bad
(incurring reward -20) reaching state S6 good (providing reward +200).
agent degree control trajectory among states based action
chooses take state. example, state S1 choice two actions, a1
noop (where noop action taking action, passively letting environment
dynamics change agents state). shown figure, takes action a1
probability 0.1 reaching state S2 , 0.9 reaching state S3 , whereas noop reaches
states S2 S3 probabilities 0.8 0.2 respectively. So, look agents first
decision, would appear choose action a1 noop reduce likelihood
higher negative reward reaching S2 .
However, actually take action a1 , agent needs particular resource,
call o1 . generally, actions ai agent take, needs
resource oi , noop action (which notational convenience sometimes
refer a0 ), require resources. Thus, setting state
S1 agent anticipated taking actions a1 , a3 , a5 , say, would want set
resources o1 , o3 , o5 .
Unfortunately agent simple example, say capacity limited
single resource given time. Now, setting
S1 need decide resource would, expectation, allow make action
choices would maximize total reward time reaches S6 . simple
417

fiWu & Durfee

instance type problem solved Dolgov Durfee (2006), show
solution shortly stepping stone algorithm.
S-RMP problem, consider generalization Dolgov Durfees problem,
agent access instances resources oi state S1 , also
states. agent sets state S1 resource considers
valuable, traverses states reaches one states, say state Si .
state Si , agent reconfigure resources, subject always capacity constraints,
thus switch new phase execution, set actions take
different. thus refer states like Si (and, degenerate way, S1 ) phase-switching
states. Referring back earlier examples capacity-limited agents, phase-switching
state could correspond agent arriving location holding cache instruments (a
toolbox), could correspond reaching time, place, situation (e.g., holding
pattern) environment less dynamic agent safely power
peripherals power others. Simple human examples phase-switching states
include state enter parking lot, access car,
state highway entrance ramp, driver given buffer change
driving behaviors car speed prepare safely merge high-speed traffic.
shall see, even problems phase-switching states static predefined
agent, phase-switching opportunities complicate agents decisions
actions take, might choose actions based rewards reaching
states also based benefits future action choices reaching phase-switching states.
Further, classes problems, agent might able decompose problem
phases deciding states would like phase-switching states. example,
could choose would like toolboxes (or entrance ramps) placed environment,
circumstances would like buffered environmental dynamics
reconfigures itself. agent would generally face constraints creating phase-switching
states, bounds number states (e.g., might limited number
toolboxes distribute), incur cost time creates state buffered
(e.g., every holding pattern introduces costly delays).
Thus, referring back Figure 1, Single-agent Resource-driven Mission Phasing (SRMP) problem generally involves optimally deciding states (besides start state S1 )
designate phase-switching states, optimally allocating resources states,
optimally choosing actions enabled resources phase. shall
see later, multiagent extension requires multiple agents agree
phase-switching states, since resource reallocation means potentially swapping (control
over) different resources, switch best (re)distribute limited resources
amongst themselves.
1.2 Paper Overview
idea reconfiguring resources improve agent performance fairly straightforward, preceding example suggests challenging problem reconfigure
resources optimally. primary goal study paper design computationally efficient algorithms exactly solve class challenging problems. Toward end,
develop suite algorithms formulate complex resource-driven mission-phasing
problems compact mathematical formulations. Thereafter, simultaneously solving
418

fiResource-Driven Mission-Phasing Techniques

problem decomposition (phase creation), resource (re)configuration, policy formulation
problems, algorithms fruitfully exploit problem structure, often results
significant reduction computational cost.
paper organized follows. Section 2 introduces background techniques. Section 3
starts relatively simple single-agent resource-driven mission-phasing problem
phase-switching states known priori. Exploiting fixed phase-switching states,
work particular, efficient algorithm. describe solution algorithms solving
general resource-driven mission-phasing problems, agent needs determine
reconfigure resources, reconfigure resources, optimal
executable policies subject (re)configured resources. Section 4 extends resourcedriven mission-phasing techniques presented Section 3 class multiagent systems
sequentially allocating resources among group cooperative agents. section follows
similar progression Section 3, terms giving agents increasing latitude
determining reallocate resources. Then, contrast work related work
Section 5, finally, Section 6 concludes paper summary work,
discussion questions remain open together possible future research directions.

2. Background
formulate single- multi-agent resource-driven mission phasing problems using
well-established formalism Markov Decision Processes (MDPs), extensions constrained MDPs. section summarizes relevant aspects previously-developed
formalisms, illustrates using example previously discussed Section 1.1.
2.1 Markov Decision Processes
general, classical discrete-time, fully-observable Markov Decision Process finite
state space finite action space defined four-tuple hS, A, P, Ri (Puterman,
1994), where:
finite state space, represented set n states {1, ...i, ...n}.
finite action space. state S, Ai represents set actions
executed state i.
P = {pi,a,j } represents state transition probability pi,a,j probability
agent reaches state j executes action state i.
P
P
state action a, j pi,a,j must greater one. j pi,a,j = 1 means

P agent always stay system executing action state i,
j pi,a,j < 1 means probability agent system
(which equivalently interpreted agent entering sink state agent
would stay forever) executing action state (Kallenberg, 1983).
R = {ri,a } (bounded) reward function ri,a reward agent
receive executes action state i.
Running Example: MDP Encoding.
easily represented MDP:

example introduced Section 1.1 (Figure 1)

419

fiWu & Durfee

= {S1 , S2 , ...S6 }.
= {a0 = noop, a1 , a2 , ...a5 }.
P = {pS1 ,a0 ,S2 = 0.8, pS1 ,a1 ,S2 = 0.1, ...}.
R = {rS1 ,a0 = 5, rS1 ,a1 = 5, ...}.
Markov decision process extension well-known Markov chain. main
property MDP possesses Markov property (Bellman, 1957): current
state MDP time known, transitions new state time + 1 depend
current state action chosen it, independent previous history
states.
MDP, decision-making agent chooses actions based upon observation
current state world, motivation maximizing aggregate reward.
deterministic stationary policy MDP defined mapping states actions: :
Ai . objective decision-making agent find optimal
policy maximizes predefined cumulative function rewards. Let {i0 , i1 , ..., , ...}
{a0 , a1 , ..., , ...} represent particular state action sequences generated following
policy starting state i0 , let E[ ] denote expectation function. typical
cumulative reward function non-discounted MDP defined as:
U () = E[


X

rit ,at ]

t=0

Similarly, cumulative reward function discounted MDP discount factor
defined as:2

X
()t rit ,at ]
U () = E[
t=0

Although general mission-phasing techniques paper also apply discounted MDPs contracting MDPs (Kallenberg, 1983; Puterman, 1994; Sutton &
Barto, 1998), illustrate paper using transient, non-discounted
MDPs.3 NonP
discounted MDPs described above. transient MDP (in j pi,a,j < 1
states), agent eventually leave corresponding Markov chain, running policy
finite number steps (Kallenberg, 1983). words, given finite state space,
assumed agent visits state finite number times
P policy,
turn means total expected reward function U () = E[
t=0 rit ,at ] bounded even
non-discounted MDP. running example problem

Section
1.1 example
P
kind MDP, state S6 acts sink state ( j p6,a,j = 0).
2.2 Linear Programming
value iteration policy iteration algorithms widely used solving classical MDPs
(Kallenberg, 1983; Puterman, 1994; Sutton & Barto, 1998). However, surprisingly hard
extend algorithms incorporate additional constraints without considerably increasing
2. paper, (a)b represents exponent, ab represents superscript.
3. transient MDP interest work subclass contracting MDPs.

420

fiResource-Driven Mission-Phasing Techniques

size state space and/or action space MDP model. reason,
number researchers proposed utilized alternative solution approach,
based upon mathematical programming (Altman, 1998; Feinberg, 2000; Dolgov & Durfee,
2006). procedure formulating MDP linear program (whose solution yields
optimal policy maximizing total expected reward) described below. work extends
approach.
Let xi,a , often called occupation measure visitation frequency (e.g., Dolgov
& Durfee, 2006),
denote expected number times action executed state i.
P P
function xi,a ri,a used represent total expected reward,
problem finding optimal policy MDP equivalent solving following linear
program:
XX
max
xi,a ri,a
(1)




subject to:
X
XX
pi,a,j xi,a
xj,a = j +




: j



xi,a 0

: i,

j probability agent
P state
P j, constraint (named
P initially
probability conservation constraint) xj,a = j + pi,a,j xi,a guarantees
expected number times state j visited must equal initial probability distribution
state j plus expected number times state j entered via possible transitions.
linear program Eq. 1 solved, trivial derive optimal policy
specifies action(s) take given state. Specifically, policy assigns probability
x
P i,a
executing action state maximize total expected reward. statea xi,a
action probability value zero one, optimal policy randomized;
otherwise deterministic.
Running Example: MDP Policy Formulation. consider problem introduced
Section 1.1 (Figure 1) ignore agents capacity constraints (such agent
every state resources needed full set actions = {a0 , a1 , ...a5 }),
corresponds classical (what refer unconstrained) MDP. Using
policy formulation algorithm, agent easily compute optimal policy,
[S1 a1 , S2 noop/a2 , S3 a3 , S4 a4 , S5 a5 , S6 noop], total expected
reward 174.65.
2.3 Constrained MDPs
Formulating unconstrained MDPs linear programs makes straightforward take
account additional constraints, including agent capacity constraints resource constraints. Several constrained optimization problems investigated Dolgov
Durfee (2006). follows, summarize work.
constrained MDP models agent capacity limitations represented hM, , Ci,
where:
classical MDP (Section 2.1), represented hS, A, P, Ri.
421

fiWu & Durfee

= {i } indicates probability distribution initial states.
C agent capacity constraints, represented hO, C, U, , i, where:
= {o} finite set indivisible non-consumable execution resources, e.g., =
{camera, spectrometer, gripper, etc.}.
C = {c} finite set capacities agent, e.g., C = {weight, space, etc.}.
U = {uo,a,i } represents resource requirements executing actions, uo,a,i
{0, 1} indicates whether agent requires resource execute action state
i.4 example, uo=camera, a=take picture, i=any state = 1 says prerequisite
taking picture camera.
= {o,c } defines resource capacity costs, o,c amount agent capacity
c required hold one unit resource o. example, o=camera, c=weight = 2
o=camera, c=space = 1 says carrying camera consume two units
carrying weight one unit carrying space agent.
= {c } specifies limits agent capacities, e.g., c=weight = 4 denotes
maximum weight four units agent carry.
Running Example: Constraint Formulation.
tion 1.1, agent constraint components are:

simple running example Sec-

= {o1 , o2 , ...o5 }.
C = {hold}.
U = {uoi ,ai ,si = 1 : 1 5}.
= {oi ,chold = 1 : 1 5}.
= {chold = 1}.
linear programming formulation (Eq. 1) paves way incorporating agent capacity constraints. Namely, capacity limitations modeled adding following
mathematical constraints (shown Eq. 2) occupation measures xi,a linear program
Eq. 1.
X
XX
o,c (
uo,a,i xi,a ) c
: c
(2)






(z) step function, defined
(z) =



1
0

z>0
otherwise

constraint indicates that, given resource requirement parameter uo,a,i = 1, agent
employ o,c amount capacity c hold resource decides execute
action one states policy.
4. simplify presentation, assumed resource requirement binary, implies
agent interested one unit particular resource, results presented
paper generalized non-binary resource requirement cases without much difficulty.

422

fiResource-Driven Mission-Phasing Techniques

Note (z) function nonlinear function. general, directly solving nonlinear
constrained optimization problems difficult. Fortunately, simple way transform nonlinear constraint Eq. 2 linear constraints introducing integer
variables (Dolgov & Durfee, 2006). reformulation Equation 2 depicted below.
P P

uo,a,i xi,a

:
X
X
o,c c
: c


{0, 1}

:

, binary integer set {0, 1}, introduced indicate whetherP
thePagent uses
limited capacity hold resource
o. X constant less sup xi,a ,
P P
P P

uo,a,i xi,a
never exceeds one (because uo,a,i xi,a
applied
guarantee
X
P Pthat
P
P

xi,a X). One way compute X solve unconstrained

xi,a sup
MDP:
XX
X = max
xi,a
(3)




subject to:
X
XX
xj,a = j +
pi,a,j xi,a


: j





xi,a 0

: i,

summarize, constrained MDP models agents capacity limitations
formulated mathematical program Eq. 4 (i.e., putting Eq. 1 integer
linear constraints together), whose solution yield optimal capacity usage configuration
optimal executable policy.

max

XX


xi,a ri,a

subject to:
X
XX
xj,a = j +
pi,a,j xi,a




P P


uo,a,i

xi,a

X
X
o,c c

(4)



: j





:
: c



xi,a 0

: i,

{0, 1}

:

Eq. 4, pi,a,j , ri,a , j , uo,a,i , o,c , c , X constants, xi,a continuous
variables binary integer variables, indicates Eq. 4 mixed integer
linear program (MILP).
423

fiWu & Durfee

Mixed integer linear programming discrete version linear programming
additional requirement particular variables must integers. Although MILPs NPhard number integer variables, solved variety highly optimized
algorithms tools (Cook, Cunningham, Pulleyblank, & Schrijver, 1998; Wolsey, 1998).
Recently, substantial progress using MILPs automated planning (Earl &
DAndrea, 2005; Kautz & Walser, 2000; van Beek & Chen, 1999; Vossen, Ball, Lotem, & Nau,
1999). automated resource-driven mission-phasing techniques (which also NP-hard
shown later) presented paper based upon MILP well.
Running Example: Constrained MDP Solution. simple running example
Section 1.1, constraint permits agent hold one resource (and thus capable
executing action noop one state). Given MDP constraint
parameters problem, computing constant X = 70.24 using Eq. 3, apply
MILP solver CPLEX (www.ilog.com) easily derive optimal solution
MILP:
[(x1,0 , x1,1 ), (x2,0 , x2,2 ), (x3,0 , x3,3 ), (x4,0 , x4,4 ), (x5,0 , x5,5 ), x6,0 ]
=[(3.47, 0), (3.03, 0), (5.21, 0), (4.95, 0), (0, 1.25), 1]
[1 , 2 , 3 , 4 , 5 ] = [0, 0, 0, 0, 1]
is, optimal policy [S1 noop, S2 noop, S3 noop, S4 noop, S5
a5 , S6 noop], corresponding total expected reward reduced 65.02 (from 174.65
unconstrained case) due limitation agent capacity. optimal
policy constrained agent uses single policy throughout entire mission.
use example go along illustrate degree automated missionphasing techniques improve expected reward.

3. Resource Reconfiguration Single-Agent Systems
turn new techniques results build work others summarized previous section. particular, extend representations techniques
solving constrained MDPs resources allocated prior execution, sequential constrained MDPs resource allocations change execution particular states
reached. previously mentioned described example problem (Section 1.1),
refer intervals agents resources cannot change phase,
states connect phases (representing opportunitybut obligationto change
resource allocation) phase-switching states. assume full complement
resources (e.g., full toolbox) available phase-switching state, agent
cannot pick discard resource except phase-switching state; relaxing assumption discussed future work (Section 6.2).
extreme, every state phase-switching state, agent effectively
unconstrained (unless exist action whose necessary resources total capacity
requirements alone exceed agents capacity limits). general, however,
restrictions states (or should) phase-switching states. consider
several cases section. range phase-switching states inherently
predetermined environment (e.g., placement toolboxes, shelters
424

fiResource-Driven Mission-Phasing Techniques

domain dynamics, dictated agent), number phase-switching states
bounded environment states designated phase-switching states
decided agent (e.g., number toolboxes shelters fixed agent
choose placed), number phase-switching states unbounded
creating phase-switching state incurs cost (e.g., toolboxes shelters
bought placed agent wishes) agent want selective
spend creating phase-switching state improvement phase-switching
state make expected reward.
section begins giving formal definition single-agent resource-driven missionphasing (S-RMP) problem Section 3.1, Section 3.2 analyzes discusses
computational complexity S-RMP problem, illustrating standard approaches
computationally intractable solving problem. Section 3.3 Section 3.4 present, analyze, illustrate solution algorithms variations S-RMP problem mentioned
above. present experimental results Section 3.5, effectiveness efficiency
automated mission-phasing techniques empirically evaluated. Finally, Section 3.6
summarizes contributions work described section.
3.1 Problem Definition
Formally, single-agent resource-driven mission-phasing (S-RMP) optimization problem
generalization constrained MDP optimization problem presented Section 2.3, composed Markov decision process M, initial probability distribution , agent capacity
constraint C, resource reconfiguration constraint5 R, where:
classical MDP, described Section 2.1.
= {i } probability distribution states, probability
agent starts state i.
C agent capacity constraint, described Section 2.3.
R resource reconfiguration constraint (sometimes also called phase-switching constraint) specifies restrictions creating phase-switching states constrained agent reconfigure resources adjust use limited capacities.
typical resource reconfiguration constraint R formulated h, (and one
generalizations discussed Section 3.4.2), where:
= {i } indicates phase-switching state creation costs, denotes cost
making state phase-switching state.
0 specifies cost limit creating phase-switching states.
notational convenience, also define set eligible phase-switching
states (indicating states potentially become phase-switching state).
definition, (not necessarily proper) subset S, , .
is, state inherently ineligible phase-switching state cost make
phase-switching state exceeds agents cost limit .
5. resource reconfiguration comes along phase switching, following discussion, resource
reconfiguration constraints sometimes called phase-switching constraints improve readability.

425

fiWu & Durfee

Running Example: Resource Reconfiguration Constraints. Given example
Section 1.1, many possible specifications Resource Reconfiguration
Constraints.
1 > : 6= 1, = {S1 } constrained MDP
situation described Section 2.3.
= 0 : (so, = S), case described beginning section
every state phase-switching state, thus equates unconstrained
MDP unless agent least one action needs resources whose capacity requirements exceed capacity constraint.
predefined, = 0 : > : . case
phase-switching states dictated agent.
= 1 : i, = n 0 < n < |S|, = case
agent select subset n states phase-switching states.
> 0 : i, = , = case agent
could turn (and all) states phase-switching states, costs incurred
subtracted agents reward might choose leave (or most!) states
non-phase-switching states.
Given inputs M, , C, R, objective S-RMP optimization problem
maximize total expected utility capacity-restricted agent identifying set
phase-switching states 0 = {sk } decompose overall problem collection
phases, and, phase k, determining resource configuration k executable
policy k adopted agent entry phase (at state sk ).
Specifically, constrained optimization perspective, S-RMP optimization problem formulated follows:
Objective:
maximize utility overall policy
subject following constraints:
i) set phase-switching states 0 = {sk } satisfy phase-switching constraint
R.
ii) Within phase k, resource configuration k satisfy agent capacity constraint C.
iii) Within phase k, policy k executable respect resource configuration k .
iv) overall policy composed phase policies k , i.e., phase policy k adopted
agent encounters phase-switching state sk 0 midst
execution.
426

fiResource-Driven Mission-Phasing Techniques

Clearly, S-RMP optimization problem involves three intertwined components: i) problem decomposition, ii) resource configuration, and, iii) policy formulation. Problem decomposition (which creates phase-switching states) lays foundation resource configuration
reconfiguration; resource configuration dictates policies executable phase;
policy formulation determines transitions within among phases well rewards
accrued agent, turn determines utility problem decomposition
resource (re)configuration.
three component problems combinations investigated number research fields (but none prior approaches computationally
tractable S-RMP optimization problem tightly couples problem decomposition,
resource configuration, policy formulation). comprehensive discussion contrasts
work prior work postponed Section 5 computationally efficient solution
approach presented.
3.2 Computational Complexity Analysis
describing new solution techniques S-RMP problems, first analyze
computational complexity S-RMP optimization problem illustrate standard
approaches computationally tractable solving it.
Theorem 3.1. S-RMP optimization NP-complete.
Proof: proof S-RMP optimization NP-hard trivial, one
special cases, includes one phase (i.e., agent configure resources
beginning mission execution), proven NP-hard reduction
well-known KNAPSACK problem (Dolgov, 2006; Dolgov & Durfee, 2006).
presence NP proven following way. MDP n states,
clear n phases (i.e., n phases extreme situation
every state phase-switching state). featuring phase id (assuming phase
unique id) state representation, generalized MDP n2 states
constructed polynomial time phase policies combined overall policy
generalized MDP polynomial time too. Given generalized MDP policy,
problem reduced solving Markov chain. Since Markov chain verified
polynomial time, S-RMP optimization NP.
Given presence NP NP-hard, S-RMP optimization proven NPcomplete.
S-RMPs complexity evident considering straightforward solution methods
would perform. previous work (Wu, 2008), compare solution method
brute-force search algorithm MDP-expansion-based approach. briefly summarize
comparison here. brute-force search algorithm enumerates possible problem
decomposition schemes (legal combinations phase-switching states), and, scheme
enumerates possible ways configure reconfigure resources, and, finally, possible problem decomposition resource (re)configuration, derives optimal phase policies
executable respect configured resources. quickly becomes intractable
non-trivial S-RMP optimization problems. MDP-expansion-based approach instead
427

fiWu & Durfee

incorporates resources state representation models resource reconfiguration activities explicit actions, efficient brute-force algorithm, still scales
poorly folding resources states increases state space size exponentially.
Neither approaches exploit key problem structure stemming coupled
problems. brute-force approach deals S-RMP component problems isolation
sequentially, MDP-based approach combines resource-configuration
policy-formulation components nave way results exponentially larger policy
formulation problem. contrast, see, new solution algorithms take advantage problem structure formulating problem decomposition, resource configuration,
policy formulation problems compact mathematical program solving component problems simultaneously, using highly optimized tool. shown Section 3.5,
algorithms presented section often find exact solutions complex S-RMP
problem within reasonable time.
3.3 Exploiting Fixed Phase-Switching States
far, formally defined S-RMP optimization problem theoretically analyzed
computational complexity. next subsections, present illustrate
computationally efficient automated mission-phasing algorithms solving S-RMP optimization problems.
begin first examining simple variation S-RMP optimization problem
phase-switching states predetermined; is, phase-switching states
given agent, , = 0. variation fits problems
opportunities reconfigure resources switch policies (e.g., placement
equipment and/or technicians needed (un)loading refitting) dictated agents
environment rather choice agent. Exploiting fact phase-switching
states fixed, devise particular, efficient algorithm (while general
generally slower algorithm presented Section 3.4).
Decomposition techniques planning stochastic domains widely used large environments many states (and detailed discussion problem decomposition techniques
given Section 5). approaches, states partitioned small regions,
policy computed region, local policies pieced together
obtain overall policy (Parr, 1998; Precup & Sutton, 1998; Lane & Kaelbling, 2001).
automated mission-phasing techniques analogous decomposition techniques
partitioning mission multiple phases leads smaller state action spaces
phase though motivation mission phasing handle constraints policies
agents execute rather reduce computational cost policy formulation.
Nonetheless, exploit ideas.
algorithm solving S-RMP optimization problems predefined phase-switching
states based upon abstract MDPs. abstract MDP composed abstract states,
corresponds mission phase. action abstract state policy
used corresponding phase (which conceptually similar options, Sutton, Precup, &
Singh, 1999). assumed none constraints associated
one phase. discussion general constraints postponed next subsection.
Since assumed agent constraints one phase cannot affected policy
choices another phase, abstract MDP unconstrained MDP (at abstract level)
428

fiResource-Driven Mission-Phasing Techniques

even though internally phase still constrained MDP. algorithm thus uses policy
iteration approach abstract level together embedded MILP solver within phases.
embedded MILP solver finds possible executable policies expected rewards
phases, different policies may different probabilities reaching
various phase-switching states edges phase. outer policy iteration
algorithm abstract level iteratively searches combination phase policies
maximizes reward across whole mission.
detailed procedure abstract MDP solver illustrated below:
1. Partitioning mission phases.
phase-switching states given, partitioning mission multiple phases
straightforward. Start phase-switching state, keep expanding
connected transitions encountering phase-switching states. resulting
state space phase state space corresponding phase-switching state.6
2. Policy iteration.
following policy iteration algorithm adopted state space partitioned.
(a) phase-switching state s, solve MDP corresponding phase beginning state unconstrained MDP, compute state value
V (s). V (s) used initial values phase-switching states since
provide informed (as opposed random) estimates experience tend
work well, especially under-constrained problems.
(b) abstract MDP, phase treated abstract state policy
phase treated abstract action phases abstract state. policy
iteration algorithm alternates following two steps:
Policy improvement: Rather enumerating possible policies (abstract actions) phase (abstract state), algorithm uses constrained MDP solver
(that shown Eq. 4) calculate optimal policy phase, given
current values V (s) associated (outgoing) neighboring phase-switching
states.
Policy evaluation: Given abstract actions, calculate V (s) phase-switching
state s. small state spaces, standard linear algebra methods often
best solutions policy evaluation. larger state spaces, simplified value
iteration algorithm might preferable (simplified policy
phase fixed) (Puterman, 1994).
Unlike much best-response hill-climbing work, abstract MDP fixed state
transition functions fixed reward functions abstract level phase level
agent enters phase always phase-switching state, guarantees
policy iteration algorithm return optimal solution.
Theorem 3.2. abstract MDP policy iteration procedure converge optimal
solution.
6. Note exploiting factored state representations lead other, efficient (although generally
approximate) algorithms partitioning (Kim & Dean, 2001; Guestrin, Koller, Parr, & Venkataraman,
2003).

429

fiWu & Durfee

Proof: iteration, new abstract policy strict improvement previous
one. Since total expected reward abstract MDP bounded (because total expected reward corresponding unconstrained MDP bounded), iteration procedure
eventually converge.
convergence point, phase MDPs abstract MDP satisfy Bellman
optimality equation (because nature linear programming solver policy
iteration algorithm), indicating derived policy optimal policy.
Running Example: Optimizing Predetermined Phase-Switching States.
return running example introduced Section 1.1 illustrate total expected
reward improved agent reconfigure resources states. Let us say
agent told able reconfigure resources switch policies states S1 , S3
S4 . three phase-switching states decompose example problem three phases.
corresponding abstract MDP constructed shown Figure 2, composed
three abstract states.
Using abstract MDP policy-iteration algorithm described using parameters (especially executable policy cannot one action
noop), state values phase-switching states eventually converge
V (S1 ) = 113.65

V (S3 ) = 120.65

V (S4 ) = 123.05

optimal policy phase [S1 a1 , S2 noop] (with resource o1 ), optimal policy
phase II [S2 noop, S3 noop, S5 a5 , S6 noop] (with resource o5 ), optimal
policy phase III [S2 noop, S4 noop, S5 a5 , S6 noop] (also resource o5 ).
total expected reward 113.65, 74.8% higher expected reward
constrained MDP case (where resource allocation happens state S1 ) thanks
additional phase-switching states.
Thanks policy iteration procedure, abstract MDP solver generally converges
quickly. However, noted two limitations inherent abstract MDP
solver. One limitations abstract MDP solver requires phase-switching
states known priori, restricts applicability (although combine
phase-switching-state heuristic search techniques). limitation due
possible existence constraints running across multiple phases. abstract MDP solver
cannot cope constraints associated multiple abstract states, restrictions
expected number visits particular state belongs multiple phases.
contrast, general S-RMP solution algorithms present next section
limitations.
3.4 Determining Optimal Phase-Switching States
general S-RMP optimization problem, phase-switching states completely predetermined. Instead, given defined set eligible phase-switching states , set costs {i }
(where denotes cost making eligible state phase-switching state), cost
0
limit
P , objective agent find optimal phase-switching set subject
0 , along optimal resource configurations optimal executable policies
within phase, maximize expected cumulative reward.
430

fiResource-Driven Mission-Phasing Techniques

Phase
S1

Phase II

S2

S2

S3
S5
S4

S2
S6

S5
Phase III
S6

Figure 2: abstract MDP three phases.

mentioned, abstract MDP solver presented Section 3.3 cannot directly used
general S-RMP optimization problem. section, construct mixed integer linear
program, solution yields optimal set phase-switching states maximizing
total expected reward, well optimal resource configurations executable policies
within phase. make simplifying assumption state positive probability
j initial state always phase-switching state. assumption makes
presentation clearer representation concise, well sidestepping question
default agent policy might (since would use could
configure resources initial state).
Let xki,a expected number times action executed state within phase k.
P P
P
Clearly, state reachable phase k, xki,a = 0. Let jk = xkj,a pi,a,j
xki,a pi,a,j state transition probability, jk provides way characterize
transitions among phases. state j phase-switching state, jk = 0 k,
P
) must
since within phase expected number times visiting state j ( xkj,aP
P equal
expected number times entering state
P j possible transitions ( pi,a,j
xki,a ). state j phase-switching state, k jk = j . Recall j initial probability
P k
distribution state j.
k j = j guarantees total expected number times
visiting state j must equal initial probability distribution state j plus total expected
number times entering state j possible transitions.
Now, formulate S-RMP optimization problem mixed integer linear
program, shown Eq. 5. formulation builds MILP constrained
given Eq. 4, incorporates phase information. objective function
P P PMDP
k r
x
i,a MILP represents total expected reward accumulated across


k i,a
431

fiWu & Durfee

phases, ri,a MDP reward function.

max

XXX
k



xki,a ri,a

(5)



subject to:
probability conservation constraints:
X
XX
pi,a,j xki,a
xkj,a = jk +




X

k
k
xi,a

jk = j

: j

0

: k, i,

capacity constraints:
P P
k

uo,a,i xi,a
ko
X
X
o,c ko c


ko

: k, j



: o, k
: c, k

{0, 1}

: o, k

phase-switching constraints:
jk
j
X
X
j j

: k, j

j

j {0, 1}

: j

P P
P
stated above, constraint xkj,a = jk + pi,a,j xki,a models conservation
probability within phase.

P k
= indicates probability conservation constraint across
constraint
P P
P
P P
P k k jP Pj k
phases, i.e., k j = k ( xj,a pi,a,j xki,a ) = xj,a pi,a,j xi,a =
P
j , xi,a = k xki,a total expected number times action executed
state i.
P P
P
uo,a,i xki,a
capacity constraints X
ko o,c ko c arePa multi-phase
P
version capacity constraints discussed Eq. 4, X = max xi,a
computed using Eq. 3.

432

fiResource-Driven Mission-Phasing Techniques

k

j constraint Xj j binary variable, j = 1 state j
phase-switching state, j = 0 otherwise. prove X sup jk follows:
sup jk = sup(

X

xkja



sup

X

XX


paij xkia )



xkja





XXX




xkia

k

=X
k

Therefore, constraint constraint j {0, 1} guarantee k : Xj >
0 j = 1, implies state must phase-switching state
transition leakage state phase.
P
constraint j j j says cost creating phase-switching states
must greater cost limit .
constraints denote ranges variables. Note range restrictions jk .
definition, j ko solution Eq. 5 indicate phase-switching states
resource configuration (within phase), respectively. solved Eq. 5,
use resulting values xki,a derive optimal overall policy follows.
1. Compute optimal policy phase.
k =
state i, action executed probability i,a
xk
P i,ak .
xi,a

k } denote phase policy
following discussion, use k = {i,a

phase k.
2. Determine phase policy adopt phase-switching state.
also trivial. agent choose phase policy k probability
phase-switching state maximizing total expected reward, xki =

xk
P k
P k xik
xi,a .

Running Example: Selecting Optimal Fixed Number Phase-Switching States.
illustrate solution algorithm running example depicted Figure 1. Recall
that, shown Section 3.3, agent allowed reconfigure resources
switch policy S1 , S3 S4 , total expected reward 113.65 (higher reward
65.02 one-shot constrained MDP case, still much lower optimal reward 174.65
unconstrained MDP case). Rather starting predefined phase-switching states,
assume 1 = 0, i{2,...,6} = 1, = 2. say, two additional phaseswitching states besides initial state S1 chosen agent states
system.
use transition probability pi,a,j , reward ri,a , initial probability distribution j ,
resource requirement cost uo,a,i , capacity cost o,c , capacity limit c , constant value
433

fiWu & Durfee

X Section 1.1. phase-switching costs cost limit given above.
optimal integer solution mixed integer linear program Eq. 5 is:
[1 , 2 , 3 , 4 , 5 , 6 ] = [1, 0, 1, 0, 1, 0]
fi 1 1 1 1 1 fi fi
fi
fi 1 , 2 , 3 , 4 , 5 fi fi 1, 0, 0, 0, 0 fi
fi 2 2 2 2 2 fi fi
fi
fi , , , , fi = fi 0, 0, 1, 0, 0 fi
1
2
3
4
5
fi
fi
fi fi
fi 3 , 3 , 3 , 3 , 3 fi fi 0, 0, 0, 0, 1 fi
1
2
3
4
5

is, optimal set phase-switching states 0 = {S1 , S3 , S5 }. Examining
continuous variables xki,a (not shown many them) shows
total expected reward agent 173.80, close optimal unconstrained
reward 174.65. derived solution choose resource o1 adopt policy [S1
a1 , S2 noop] S1 , switch resource o3 policy [S3 a3 , S4 noop] S3 , switch
resource o5 policy [S2 noop, S5 a5 , S6 noop] S5 .
3.4.1 Variation: Maximizing Total Reward, Accounting Cost
subsection demonstrates extensibility MILP-based algorithm showing
easily revised work another useful variation S-RMP optimization problem
phase-switching states predetermined (Section 3.3) cost creating
phase-switching states bounded (Section 3.4). assume state could
phase-switching state, many states desired could phase-switching states,
(similarly Section 3.4) cost associated treating state phaseswitching state. However, instead subject cost limits, costs
calibrated rewards associated executing policies. optimization problem
maximize total expected reward, accounting costs creating phase-switching
states, without predetermining phase-switching states many
be. shown below, designing algorithm problems trivial. simple
mathematical reformulation Eq. 5. details presented Eq. 6 (which omits
probability conservation capacity constraints unchanged Eq. 5).
max

XXX
k



xki,a ri,a



X



(6)



subject to:
probability conservation constraints (unchanged)
capacity constraints (unchanged)
phase-switching constraints:
jk
j
X
j {0, 1}

: k, j
: j


cost creating phase-switching state i, objective function
represents P
P P P
k
represents total expected reward policy minus
k

xi,a ri,a
cost creating phase-switching states.
434

fiResource-Driven Mission-Phasing Techniques

Case
unconstrained (Section 2.1)
one-shot (Section 2.3)
3 fixed phases (Section 3.3)
2 added chosen phases (Section 3.4)
unlimited phases balancing cost (Section 3.4.1)

Phase-Switching States
{s1 , s2 , s3 , s4 , s5 , s6 }
{s1 }
{s1 , s3 , s4 }
{s1 , s3 , s5 }
{s1 , s5 }

Expected Utility
-75.35
65.02
13.65
73.80
102.55

Table 1: Comparison solutions example problem, given cost creating
additional phase-switching state 50.

Running Example: Selecting Optimal Phase-Switching States Based Cost.
Let us revisit running example illustrate algorithm used solve
variation S-RMP optimization problem. Suppose 1 = 0 (assuming initial
state already phase-switching state) = c state. Using MILP
formulation (Eq. 6), find 0 < c 0.85 optimal phase-switching states
[S1 , S3 , S4 , S5 ], 0.85 < c 21.25, optimal phase-switching states [S1 , S3 , S5 ],
21.25 < c 87.53, optimal phase-switching states [S1 , S5 ], c > 87.53
optimal decision create additional phase-switching states besides initial state
S1 . expected, number phase-switching states decreases cost creating phaseswitching states increases.
specific example, c = 50, optimal set phase-switching states {S1 , S5 }.
optimal resource configuration executable policy phase initiated S1
{o3 } [S1 noop, S2 noop, S3 a3 , S4 noop], respectively; optimal resource
configuration executable policy phase initiated S5 {o5 } [S2 noop, S3
noop, S4 noop, S5 a5 ], respectively. policy utility 152.55 (reward)501 (cost) =
102.55.
better understand compare solution example solutions derived
previous sections, Table 1 shows solution utilities (where utility defined
expected reward policy minus cost creating phase-switching states).
surprisingly, utility solution presented subsection higher others
since derived algorithm (Eq. 6) explicitly balances costs expected
benefits creating phase-switching states.
3.4.2 Variation: Cost Associated State Features
final variation briefly describe, similarities multiagent approach
described later Section 4, case conditions enable resource reconfiguration (phase switching) associated subset world features, rather fully
grounded state. simple example, consider situation resources (e.g., software
packages, control satellite, etc.) licensed/leased particular times
particular intervals, hourly. is, agent identify, start hour,
resources (within capacity constraints) hold next hour. could
number states (e.g., physical locations, pending task queue, etc.), resource reconfiguration take place them. Similarly, example robot reconfigures
435

fiWu & Durfee

resources toolbox, critical feature phase switch state whose
location feature corresponds toolbox, regardless state features (e.g., direction
facing battery level).
generally, let us say MDP state space consists L disjoint subsets
S1 , S2 , ..., Sl , ..., SL , subset contains states identical values
phase-switching feature(s) (e.g., states Sl clock time t). Thus, state within
Sl phase-switching state states Sl phase-switching states well. Let
l denote cost making Sl states phase-switching states, i.e., cost
enable phase switching worlds critical feature(s) take common value(s)
Sl , let denote cost limit creating phase-switching states. Clearly,
generalization previous phase-switching constraint: every Sl contains exactly
one state, representation equivalent phase-switching constraint R previously
presented Section 3.1.
new mixed integer linear program generalized phase-switching constraint
formulated Eq. 7, similar Eq. 5, except minor revisions
portion phase-switching constraints. before, constraints unchanged Eq. 5
repeated.
XXX
max
xki,a ri,a
(7)
k





subject to:
probability conservation constraints (unchanged)
capacity constraints (unchanged)
phase-switching constraints:
jk
l
X
X
l l

: k, l, jSl

l

l {0, 1}

: l

binary variable l denotes whether Sl phase-switching set.
Running Example: Selecting Optimal Phase Switching Features. running
example, suppose state space composed Sl=1 = {S1 }, Sl=2 = {S2 , S3 },
Sl=3 = {S4 , S5 }, Sl=4 = {S6 }, l=1 = 0, l6=1 = 1, = 1. solution
Eq. 7 yield policy reward 165.68 using phase-switching states {S1 , S4 , S5 },
spending one unit cost creates phase-switching state S4 phase-switching
state S5 .
3.5 Experimental Evaluation
point, described variations single-agent resource-driven mission-phasing
problems techniques solving them, using simple example illustrate ideas.
Ultimately, significance techniques hinges computational efficiency
solving problems difficult. section, give empirical evaluation
techniques focusing problems complex state space larger resource
436

fiResource-Driven Mission-Phasing Techniques

set. experiments implemented simplified Mars rover domain simulation
autonomous rover operates stochastic environment. Following much literature
similar problems (Bererton, Gordon, & Thrun, 2003; Dolgov & Durfee, 2006), Mars
rover domain represented using grid world.
3.5.1 Experimental Setup
grid world (see Figure 3c) number wall locations rover
cannot move. locations associated execution resource, which,
held rover, allows rover move confidence safety location
desired next location. example, resources could sensors conditions
different locations (dusty, foggy, overgrown, etc.), different kinds wheels (for navigating
sand, rocks, etc.). rover agent also move without holding appropriate resource
location, result greater uncertainty action outcomes (it could blunder
slip, thus arrive different location desired) possibly cause damage
rover, detailed shortly.
addition, multiple tasks randomly distributed grid world.
rover reaches location task, rover currently carries task-required execution resource, rover choose perform action (that carries task)
receive reward. task carried out, mission accomplished rover
leave system (the experimental run terminates).
experiences running variety experiments indicate trends results
presented section sensitive exact parameter settings, sake
reproducibility, describe detailed parameters below. procedure building
random grid world illustrated Figure 3. n n grid world built, 40%
locations randomly chosen wall locations, 10% locations randomly chosen
task locations. avoid simple test problems, use grid worlds whose number
reachable locations (from rovers starting location) greater half total number
locations (i.e., greater n2 /2).
task location, task could accomplished rover generate
reward. make problem interesting challenging, distinguish tasks setting
different rewards them. sort tasks Manhattan distances starting location
rover (the smallest distance first), let ith task reward i. Therefore,
always true rover would desire pursue high-reward tasks low-reward
tasks closer rover might easier safer complete.
rover always starts (START) location left bottom corner grid
(which never assigned wall), objective maximize expected reward.
time step, rover chooses action action set {wait, up, left, down, right,
safe-up, safe-left, safe-down, safe-right, do}. Actions wait, up, left, down, right
executed without requiring rover carry particular resource. contrast, performing
safe-moving action safe-up, safe-left, safe-down, safe-right non-wall location requires
particular resource (related location), randomly uniformly selected
resource set problem built. Analogously, performing action task location
requires particular resource also randomly uniformly selected. pointed
performing action needs one resource, resource may (by chance)
437

fiWu & Durfee

40% walls

START
location


(a)



10% tasks,
closer START,
lower reward









(b)




1





non-task
location, random
resource movement

2
3



task location,
random resource movement
random resource task




(c)

Figure 3: procedure creating random grid world. (a) 40% locations randomly chosen walls. (b) 10% locations randomly chosen tasks. (c)
resource requirements randomly set.

438

fiResource-Driven Mission-Phasing Techniques

enable agent move safely multiple locations, and/or carry multiple tasks.
resource requirement information known rover priori.
following lists detailed action parameters used experiments:
wait executed non-wall location without requiring resource.
execution action, rover stay current location probability 0.95,
system probability 0.05 (e.g., running battery).
up, down, left, right executed non-wall location without requiring resource. actions achieves intended effect probability 0.4, moves
rover three directions (except intended direction)
probability 0.1, keeps rover current location probability 0.1, causes
damage rover (and rover system) probability 0.2.
Furthermore, rover bumps wall, stay current location.
safe-up, safe-down, safe-left, safe-right executed location whose required resource currently held rover. Compared unsafe-moving action,
safe-moving action achieves intended effect much higher probability
0.95, fails (leaves system) lower probability 0.05. Similarly before,
rover bumps wall, stays current location.
executed tasks whose required resources currently held rover.
action executed, rover receives reward task current
location, leaves system (since mission accomplished).
capacity rover restricted: capacity limit , carrying resource
incur one unit capacity cost. say, rover carry resources.
run experiments Core 2 Duo machine use CPLEX 10.1 MILP solver.
experiments, average data point computed 20 randomly generated problems.
3.5.2 Improvements Solution Quality
start evaluation showing improved reward using phasing strategy
approach consider possibility switching resources midst
execution. Let us first consider case five supply stations distributed
environment (the first station always START location remaining four
stations randomly uniformly distributed non-wall locations problem
generated). parameters set follows: n = 8, i.e., size grid world 8
8, |O| = 9, i.e., nine different types resources system. Figure 4
gives average rewards experiments, error bars graphed
results throughout paper show standard deviation. Clearly, exploiting resource
reconfiguration opportunities (using abstract MDP solver presented Section 3.3)
considerably improve performance rover, e.g., receiving reward average
40% higher reward taking advantage supply stations, rover
carry three resources.
Figure 4 also compares performance rover case locations
supply stations randomly pre-selected case locations
number supply stations (i.e., five phases, given i=ST ART = 0, i6=ST ART = 1,
439

fiWu & Durfee

4.5

4

5 optimal phases

average reward

3.5

5 fixed phases

3

nonphasing

2.5

2

1.5

1

0.5

0

1

2

3

4

5

6

7

8

9

number carried resources

Figure 4: Exploiting fixed phase-switching states increases agents reward, finding
optimal phase-switching states increases reward.

4.5

4

average reward

3.5

3

2.5

2

1.5

1

0.5

0

1

1.5

2

2.5

3

3.5

4

4.5

5

5.5

6

number phases

Figure 5: reward increases number phases increases.

= 4) determined rover itself. expected, finding optimal phase-switching
states (which done using MILP algorithm presented Section 3.4) valuable
tightly constrained environments. example, average, yields reward 46%
higher approach randomly selects phase-switching states number
carried resources limited = 3.
Figure 5 examines effectiveness resource-driven mission-phasing approach
another perspective, showing average reward rover function number
phase-switching states built environment (with system parameters
n = 8, |O| = 9, = 3). see (as expected) breaking mission multiple
phases significantly improve total expected reward constrained rover.
440

fiResource-Driven Mission-Phasing Techniques

example, setting two additional supply stations 8 8 grid world environment (and
breaking three phases) almost double average reward rover
gain without using phasing.
3.5.3 Computational Efficiency
major objective work presented section design computationallyefficient solution approach S-RMP optimization problem. Section 3.2 given
theoretical analysis computational complexity S-RMP optimization problem;
subsection intended empirically evaluate efficiency solution approach
presented section solving complex S-RMP optimization problems. make
presentation concise, runtime performance MILP-based algorithm described
Section 3.4 shown, i.e., focusing standard S-RMP optimization problem defined
Section 3.1.7
two prior straightforward algorithms described Section 3.2 (the brute-force search
approach based upon enumeration MDP-based approach incorporating resource features MDP state representation) also used solve S-RMP optimization
problem. Enumerating decompositions, then, each, enumerating possible resource configurations reconfigurations thought (very slow) brute-force
search algorithm formulated MILP. Therefore, report empirical results,
since state-of-art MILP solvers (such CPLEX use) usually follow sophisticated branch-and-bound (B&B) strategies, well established mathematical
programming literature B&B approach is, general, significantly better
straightforward brute-force search (in runtime finding optimal solution
anytime performance finding good solution). search Artificial Intelligence
Operations Research literatures indicates MDP-based approach
existing approach (besides brute-force search) directly applicable S-RMP
optimization problem. thus focus comparing MILP-based algorithm
MDP-based algorithm following discussion.
MDP-based algorithm, new drop-all action |O| new pick-one actions
added original action space (instead adding 2|O| resource reconfiguration
actions). say, rather performing resource reconfiguration one step,
agent switches new bundle resources first implementing drop-all action
sequentially performing pick-one actions desired resources.
experience revised algorithm computationally efficient version
exponential-size action space.
Note MDP resulting incorporating resource features state representation still constrained MDP phase-switching constraints place restrictions
states resource-reconfiguration-related actions performed in. constrained
MDP solver (Eq. 4) shown efficient solving large constrained MDPs (Dolgov,
2006), work uses solving remodeled constrained MDPs.8
7. experiments (Wu, 2008) also show trends results variations S-RMP optimization problem similar described subsection.
8. MILP formulation solving remodeled constrained MDP, number binary variables equals
number states specified S-RMP problem definition. is, runtime MDP-based
algorithm exponential input size doubly exponential.

441

fiWu & Durfee

120

runtime (seconds)

100

80

60

40

20

0

1

2

3

4

5

6

7

8

9

10

number phases

Figure 6: runtime increases decreases number phases increases.

provide better idea computational complexity experimental domain
solution techniques, begin showing hard resource-driven mission-phasing
problem is, particularly along dimension number phases created.
use parameters Figure 5, analyze runtime instead. results shown
Figure 6, demonstrates running time deriving optimal S-RMP solution
varies number supply stations created environment increases.
figure, solid line shows average, error bars show standard deviation, data
point, shown , corresponds single run.
shown figure, running time low number phases small,
gradually increases number phases increases. surprising,
number variables (both continuous variables binary variables) MILP formulation
linear number phases. However, interesting observation that,
point, runtime starts decrease although size MILP still keeps increasing.
believe because, number allowable phases large, several
different ways set phase-switching states achieving maximum reward.
words, S-RMP optimization problem large number phase-switching states
becomes under-constrained, might large number different optimal solutions.
MILP-based algorithm presented work effectively exploit property,
reduce computational costs. Based upon complexity profile, highlight ability
solving hard problem instances, following experiments set phase-switching cost limit
2 (except case examine running time changes number
phases increases). means three phases system, assuming
creating additional phase-switching state incurs one unit cost.
Figure 7 compares average time finding optimal solution MILPbased algorithm standard MDP-based algorithm relative number phases
(top-left figure), number carried resources c (top-right figure), number resource
types |O| (bottom-left figure), size9 grid world n (bottom-right figure).
9. Recall grid world size n n.

442

fiResource-Driven Mission-Phasing Techniques

500
MDPbased
MILPbased

runtime (seconds)

runtime (seconds)

500
400
300
200
100
0

1

2

3

4

5

6

MDPbased
MILPbased
400
300
200
100
0

7

number phases

3

4

5

6

7

500
MDPbased
MILPbased

runtime (seconds)

runtime (seconds)

2

number carried resources

500
400
300
200
100
0

1

4

6

8

10

MDPbased
MILPbased
400
300
200
100
0

12

number resource types

5

6

7

8

9

10

size grid world

Figure 7: Runtime comparison MILP-based algorithm MDP-based algorithm. MILP-based algorithm finds exact solution S-RMP optimization
problem faster standard MDP-based algorithm. Parameters set follows. Top-left figure: n = 8, = 3, |O| = 9, = {0, 1.., 6}. Top-right figure: n = 8,
= {1, ..., 7}, |O| = 9, = 2. Bottom-left figure: n = 8, = 3, |O| = {3, 4, ..., 12},
= 2. Bottom-right figure: n = {5, 6, ..., 10}, = 3, |O| = 9, = 2.

see MILP-based algorithm expectation considerably faster MDP-based
algorithm, particularly complex problem instances.
top-left figure, results MILP-based algorithm shown
Figure 6, already discussed. Notably, unlike three figures,
curve MDP-based algorithm figure monotonically increase value
input parameter increases. input parameter figure, number
phases, affect size state space expanded MDP. Furthermore,
constrained MDP method (Eq. 4) used solve expanded MDP exploit problem
structure problem becomes under-constrained. explains running time
decreases point (but time still much higher MILP-based
approach).
top-right figure also demonstrates trend running time MILP-based
algorithm decreasing value input parameter (i.e., number resources
carried rover) particular threshold. reason
443

fiWu & Durfee

used explain Figure 6 MILP-based algorithm, MILP solver utilizes
branch-and-bound, effectively discover exploit fact problem becomes
under-constrained. contrast, MDP-based algorithm incorporating resource features
state representation leads MDP whose size grows rapidly number
resources carried increases, thus results significant increase
running time.
illustrated bottom-left figure bottom-right figure, average runtime
MILP-based algorithm also increases considerably slowly MDP-based
algorithm, although, unlike top-left top-right figures, runtime monotonically increases either number resource types size grid world increases.
because, general, increases two parameters make problem become
under-constrained themselves.
reason significant reduction computational cost MILP-based
approach formulate S-RMP optimization problem compact (as opposed exponential) formulation, paves way taking advantage state-of-the-art MILP
solvers effectively solve coupled problems problem decomposition, resource configuration, policy formulation. important emphasize MILP-based approach
uses approximation techniques (and find optimal solutions). compactness
formulation MILP-based approach folds process solving NPcomplete S-RMP problem process solving NP-complete MILP (where MILP
solved efficiently state-of-the-art solvers).
Specifically, MDP-based approach models resources MDP representation regardless valuations subsets resources, reasons generalized
MDP determine optimal way configuring reconfiguring resources. contrast,
MILP-based solver finds exact S-RMP solution taking advantage embedded
branch-and-bound MILP method discard subsets fruitless candidate solutions (through
upper lower estimated bounds). Although MILP-based approach MDP-based
approach similar worst-case runtimes, i.e., requiring exponential time enumerate
possible ways sequentially configuring resources (which reasonable S-RMP NPcomplete), average-case performance MILP-based approach often much better
MDP-based approach effectiveness branch-and-bound algorithm
pruning suboptimal solutions. particularly significant cases suboptimal
decompositions detected easily early large number possible resource
configurations executable policies discarded without much computational
effort.
3.6 Summary
point, analyzed several variations single-agent resource-driven missionphasing problem, corresponding several cases phase-switching constraints, presented
suite computationally efficient algorithms finding using mission phases.
shown analysis experiments approach considerably reduce
computational cost finding exact solution complex S-RMP optimization problem
comparison prior approaches. remainder paper, extend
techniques multiagent stochastic systems.
444

fiResource-Driven Mission-Phasing Techniques

4. Resource Reallocation Multiagent Systems
Additional complications arise agent deciding resources hold
part multiagent system, potential competition scarce, shared resources.
example, might satellites remotely control acquire desired
images, small number licenses simultaneously run software package. individual
agent might unable procure desired resources (even capacity
restrict amount resources hold) agents may want
resources well. cooperative agents, optimal allocation distribute resources
agents maximize agents aggregate reward, meaning shared resource (such
control satellites sensor) given agent use best, given
goals, potential actions, resources possessed.
problem general doubly-exponential. could agent need consider
exponentially many combinations resources might possess, collectively
agents could need consider exponentially many joint combinations individual
combinations, filtering exceed shared resource constraints, returning
best remain. Dolgov Durfee (2005, 2006) showed much efficient
algorithm possible exploits problem structure case agents valuation
resource bundle based expected value MDP policy utilizes
actions made possible holding resources bundle. summarize work
Section 4.2, approach similar solution method resource assignment
single agent capacity constraints described Section 2.3, like work solves
one-shot allocation problem. Hence, like work consider possibility
agents might able redistribute resources among midst mission
execution.
section thus focuses solving sequential resource redistribution (reallocation) problems, along problem optimizing agents policies execution phases
redistribution events, building ideas Dolgov Durfees work well SRMP techniques presented previous section. remainder section thus largely
follows parallel structure preceding S-RMP presentation. begin (Section 4.1)
introducing simple problem use running examples remainder
section. summarize (and using example illustrate) prior work
Dolgov Durfee (2005, 2006) one-shot allocation Section 4.2, define sequential multiagent resource-driven mission phasing problem Section 4.3. analyzing
problems complexity (Section 4.4), consider sequence variations problem
(again paralleling S-RMP description), beginning case phase-switching
states pre-defined (Section 4.5) chosen (Section 4.6),
each, present, analyze, illustrate solution algorithms. efficiency optimality
techniques empirically evaluated Section 4.7. Finally, Section 4.8 summarizes
contributions work presented section.
4.1 Multiagent Example
describe simple multiagent resource-allocation example problem use
illustrate various solution approaches throughout section. example, two
cooperative agents attempt maximize total expected reward ten time step
interval. agent three tasks. time step, agent choose continue
445

fiWu & Durfee

Task 1
----------------------

Task 2
----------------------

Task 3
----------------------

Reward:
RL :
DL:
Resource:

Reward:
RL :
DL:
Resource:

Reward:
RL :
DL:
Resource:

10
1
4

1

12
2
10

2

28
5
8

1

2

Task 1
----------------------

Task 2
----------------------

Task 3
----------------------

Reward:
RL :
DL:
Resource:

Reward:
RL :
DL:
Resource:

Reward:
RL :
DL:
Resource:

26
1
7

1

2

6
3
8

1

12
6
10

2

Figure 8: simple two-agent example.

previously started task (if one required resources still assigned
agent), start new task (and abort current task one), simply nothing.
addition, say task aborted previously (and thus failed)
re-tried, task accomplished once.
Figure 8 shows detailed information tasks example problem, including
release (RL) time (i.e., earliest time task started successfully), deadline (DL)
(i.e., latest time task finish successfully), reward task completes successfully,
resource prerequisites. example, agent 1 start (or continue) task 1,
incur reward 10 accomplished, time step within interval [1, 4) given
one unit resource 1 time. concentrate multiagent issues,
problem assume agent sufficient capacity carry resources 1
2. uncertainty problem amount time required execute task. Here,
say that, agent starts task abort execution, agent
probability 0.3, 0.4, 0.3 accomplishing within one, two, three time steps,
respectively.10
multiple instances resources 1 2, problem degenerates
two independent unconstrained MDP problems, one agent. illustrated
Figure 9, agent hold resources needs throughout full time interval. Using
standard policy formulation algorithm (e.g., value iteration), easily compute
optimal unconstrained policy agent, yields total expected reward across
two agents 93.64.
4.2 Background: Integrated Resource Allocation Policy Formulation
Stochastic planning multiagent environments typically much challenging
single-agent environments, particularly agent partial view global
environment. Previous complexity analyses shown general decentralized Markov
decision process (Dec-MDP) NEXP complete (Bernstein, Zilberstein, & Immerman, 2000;
10. problem representation simplification TAEMS modeling approach (Lesser, Decker, Wagner,
Carver, Garvey, Horling, Neiman, Podorozhny, Prasad, Raja, Vincent, Xuan, & Zhang, 2004; Wagner,
Raja, & Lesser, 2006) used DARPA COORDINATORS project (Wagner, Phelps, Guralnik, &
VanRiper, 2004; Wu & Durfee, 2007b).

446

fiResource-Driven Mission-Phasing Techniques

1

1

1

1

1

1

1

1

1

1

2

2

2

2

2

2

2

2

2

1

1

1

1

1

1

1

1

1

2

2

2

2

2

2

2

2

2

2

3

4

5

6

7

8

9

10

Figure 9: Optimal resource allocation resources unlimited.

Goldman & Zilberstein, 2004). Fortunately, many application domains, actions taken
one agent may impact agents transitions. example, delivery
robots operate large open environment, interactions may rare easily avoidable.
development efficient algorithms loosely-coupled systems gained much
attention among many researchers (e.g., Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling, Dean,
& Boutilier, 1998; Becker, Zilberstein, Lesser, & Goldman, 2004; Dolgov & Durfee, 2005).
approach specifically draws upon prior approach designed Dolgov Durfee
(2005, 2006), extends work summarized Section 2.3 multiagent resource
allocation case. work assumes group cooperative agents coupled
sharing resources (i.e., actions selected one agent might restrict actions available
others), actions executed one agent cannot impact rewards transitions
others. typical resource-allocation research literature, work also assumes
that, resources distributed, utility agent achieve
function resource assignment depend resources given
agents use resources.
multiagent constrained MDP scarce shared resources represented
tuple hM, , Ci, next specified. Note specification essentially represents independent instance constrained MDP (Section 2.3) agent, except (the set
resources) (the bounds number copies resource) shared across
agents.
= {Mm } set classical MDPs, Mm represents agent ms MDP, modeled

way described Section 2.1. is, Mm = hS , , {pm
i,a,j }, {ri,a }i


finite state space agent m, finite action space agent m,
pm
i,a,j probability agent reaches state j executes action
reward agent receives performs action state i.
state i, ri,a
= {m } specifies initial probability distribution states agent m,
im probability agent initially state i.
C represents resource constraints agents system, represented
hO, C, U, , , where:
447

fiWu & Durfee

finite set shared, indivisible, non-consumable execution resources.11
C = {C } specifies finite set capacities agent m.
U = {U } gives resource requirements agents actions,
binary parameter um
o,a,i {0, 1} indicates whether agent requires resource
execute action state i.
= {m } represents capacity costs agent m.
} captures capacity limits agent m.
= {m
= {o } specifies (shared) resource limitations, maximum number
copies resource distributed agents system.
Running Example: Multiagent Constraint Formulation. simple running example Section 4.1, agents constraint components C summarized below,
represents state unspecified values u zero.
= {o1 , o2 }.
C = {{hold}, {hold}}.
U = {{u1o1 ,a1 , = 1, u1o2 ,a2 , = 1, u1o1 ,a3 , = 1, u1o2 ,a3 , = 1}, {u2o1 ,a1 , = 1, u2o2 ,a1 , =
1, u2o1 ,a2 , = 1, u2o2 ,a3 , = 1}}.
= {{o11 ,chold = 1, o12 ,chold = 1}, {o21 ,chold = 1, o22 ,chold = 1}}.
= {{c1hold = 2}, {c2hold = 2}}.
= {o1 = 1, o2 = 1}.
algorithm devised Dolgov Durfee (2006) presented Eq. 8, clarity
leaving capacity constraints focus multiagent constraints. Analogously
single-agent case, continuous variable xm
i,a represents expected number times
agent executes action state i, binary variable
represents whether one
unit resource assigned agent prior execution.

max

XXX





xm
i,a ri,a

(8)



11. simplicity, assume resources shared. agents also draw cache
private resources straightforward extension would add unnecessary complication
presentation.

448

fiResource-Driven Mission-Phasing Techniques

subject to:
probability conservation constraints:
X
XX


xm
pm
j,a = j +
i,a,j xi,a

xm
i,a



: m, j



0

: m, i,

resource constraints:
P P


uo,a,i xi,a


X
X


o,c

c

: m,
: c,



X






=

:

{0, 1}

: m,

P P P

objective function xm
i,a ri,a represents sum cumulative rewards
among agents, based upon assumption agents coupled
resources (i.e., actions taken one agent impact agents rewards
transitions).
P
P P


constraint xm
j,a = j +

pi,a,j xi,a guarantees probability conservation
every state every agent, multiagent version probability conservation
constraint single-agent MDP formulation (Eq. 1).
P P
X constant equal greater sup xm
i,a (where finite horizon MDP,
X set finite horizon

since

agent
execute actions within
P P


uo,a,i xi,a

implies xm
horizon). constraint
i,a must zero (i.e.,
X
=
1
(i.e., agent must
action cannot executed agent state i) um
o,a,i

resource execute actionPa P
state i) = 0. xm
i,a unrestricted
definition.

x
otherwise since X less um
i,a
o,a,i
P
constraint
= guarantees total amount resource allocated
across agents must equal amount available resource (assuming resources

P bemcompletely assigned). constraint easily relaxed constraint
introducing additional dummy agent keep unallocated resources.
optimal joint policy easily derived solution MILP
similar way discussed Section 2.2. is, maximize total expected reward
xm
group agents, agent choose probability P i,a
state
xi,a
i.
Running Example: Multiagent Constrained MDP Solution. Continuing simple
running example Section 4.1, apply solution technique find optimal
allocation resources 1 2 outset agents assuming one
copy available. Eq. 8 finds optimal one-shot allocation give resources
agent 1 let agent 2 idle entire execution, shown Figure 10, total
449

fiWu & Durfee

1

1

1

1

1

1

1

1

1

1

2

2

2

2

2

2

2

2

2

2

3

4

5

6

7

8

9

10

Figure 10: Optimal one-shot resource allocation resources scarce.

expected reward 49.64 case, much lower reward (93.64) unconstrained
case.
4.3 Multiagent Resource-Driven Mission Phasing Problem Definition
Multiagent Resource-driven Mission Phasing (M-RMP) problem sequential version
Dolgov Durfees (one-shot) multiagent resource allocation problem described.
general multiagent mission-phasing problem solved exactly using S-RMP
solution approach presented Section 3 joint state action spaces interacting
agents (assuming agent full view joint state), solution
methodology would suffer curse dimensionality since sizes joint state
action spaces grow exponentially number agents. Thus, exploit
loose-coupling assumption: agents interact (now potentially repeated)
contention shared resources, otherwise transition reward independent.
multiagent case sequential resource (re)allocation, phase corresponds
particular distribution shared resources among agents. say transition
one phase another occurs agents reach state relinquish
possession resources currently hold, acquire resources next
phase.12 However, unlike single-agent case agent knows reached
phase-switching state, multiagent case agent observe local state,
detecting joint phase-switching state would require agents communicate state
information individually track full joint state. turn means would
need policy maps (exponentially larger space of) joint states local actions,
effectively introducing transition reward dependencies exploding complexity
problem.
work instead agents exploit deterministically-changing feature joint
state observe: (synchronized) clock. Phase switchingredistributing
resources software licenses control satellites sensorsoccurs pre-arranged
(and preferably carefully chosen) times. already saw Section 3.4.2 (single-agent) RMP
12. principle different subsets agents could swap resources among themselves, paper
consider case agents engage swaps, though course since agent acquire
resources relinquishes effect could subset agents materially involved
given swap.

450

fiResource-Driven Mission-Phasing Techniques

variation phase-switching states grouped based value(s) (subset of)
feature(s). M-RMP builds variation, effectively partitioning exponentially-sized
joint state space subsets based states time feature, determining time(s)
resource (re)distributions take place, matter details
agents states whether finished using currently-held resources yet.
Phasing based time advantages limitations. One key advantage
requires agents know runtime know
time (and common knowledge). domains reliable mutual observation
communication runtime impractical (for example, military operations), synchronizing actions based clock time long norm. second advantage
future time guaranteed reached. contrast, agents need conditions
met exchange resources (for example, need location and/or
idle), applications might impossible guarantee state ever
occur. force cases occur, agents would need know others
states (where others and/or soon current tasks end) reach hand-off
point. M-RMP techniques describe principle extended cases,
practice greater need agents global state awareness, lesser expect
problems exhibit kinds structure M-RMP exploits.
paper, also assume resource redistributions always succeed (resources
somehow get misplaced transfer); discussion future work (Section 6.2)
talk implications relaxing assumption.
Based preceding, formally define multiagent resource-driven missionphasing (M-RMP) problem. generalization multiagent constrained MDP described Section 4.2, tuple hM, , C, Ri, components M, , C
defined Section 4.2, R defined follows.
R specifies constraints resource reallocation. capture efforts required
resource reallocation activities costs h{t }, i:13
{t } indicates resource reallocation costs, denotes cost reconfiguring resource assignment time t. Note associated time
regardless resources many reassigned. variation
resource reallocation constraints reallocation cost depends amount
resources transferred discussed analyzed Section 4.6.1
presenting solution algorithm M-RMP optimization problem defined
section.
specifies limit amount cost could spent resource reallocation. example, t=any time = 1 = 4 means four resource
reconfiguration events could scheduled particular mission execution.
Running Example: M-RMP Formulation. Continuing simple running example
Section 4.1 building encoding Section 4.2, agents reallocation constraints R summarized below, assuming agents reallocate resources three times
besides initial time 1.
13. different buffer pool research (Lehman & Carey, 1986; Sacco & Schkolnick, 1982), often
assumes buffer size changed immediately free charge.

451

fiWu & Durfee

= {1 = 0, = 1 : 2 10}.
= 3.
objective M-RMP optimization problem maximize total expected
reward group agents within finite time horizon judiciously reallocating limited, shared resources among agents time. Although much simpler general
decentralized MDP problem, automated multiagent mission-phasing problem still
computationally challenging needs determine initially allocate
limited shared resources, also reallocate resources, best way reallocating resources times are, best executable policies respect
reallocated resources are. S-RMP, three component problems mission decomposition, resource allocation, policy formulation strongly intertwined. utility
decomposing problem phases utility allocating resources phase
unknown executable policies formulated evaluated, policies cannot
formulated phases built resources allocated.
4.4 Computational Complexity Analysis
section starts theoretically analyzing computational complexity M-RMP
optimization problem.
Theorem 4.1. M-RMP optimization NP-complete.
Proof: trivial prove M-RMP optimization problem NP-hard. Given
special case one-shot resource allocation policy formulation proven
NP-complete reduction KNAPSACK problem (Dolgov, 2006), M-RMP
optimization NP-hard.
Given solution M-RMP problem, satisfaction resource constraints
resource reallocation constraints verified linear time. that, agent,
incorporating policy MDP model, M-RMP optimization problem becomes
Markov chain, solved polynomial time. is, M-RMP optimization
NP.
NP NP-hard, M-RMP optimization NP-complete.
Given result, surprising prior approaches (summarized below)
could applied finding exact solution M-RMP optimization problem
computationally efficient.
Decentralized MDP. Modeling resources MDP state representation formulating resource-reconfiguration activities actions possible (but slow) way solve
S-RMP problem (Section 3), generally infeasible M-RMP problem.
Since outcome agents resource-reallocation action (e.g., acquiring resource)
depends whether another agent takes corresponding action (e.g., releasing resource) time, resulting Decentralized MDP (Dec-MDP)
transition independent. general Dec-MDP NEXP-complete (Bernstein et al.,
2000), meaning M-RMP involves solving NEXP-complete problem input
exponential number resources.
452

fiResource-Driven Mission-Phasing Techniques

Combinatorial stochastic optimization. Although phase M-RMP problem one-shot resource-allocation policy-formulation problem, directly using
integrated combinatorial stochastic optimization approach (Section 4.2) solve
phase independently piecing phase policies together is, general,
infeasible. Besides enumerate possible decompositions, solving phase
independently requires knowing initial state probability distribution jm Eq. 8.
Unfortunately, jm phase generally depends policy preceding phase,
policy preceding phase usually optimized respect already
knowing expected utilities attainable current future phases.

Auction-based resource allocation. resource allocation approach based using auctions (Pekec & Rothkopf, 2003; De Vries & Vohra, 2003), agent bids set valuations possible sequential resource assignments central auction,
decides sequentially allocate resources among agents. Unfortunately,
approach scale. example, group = 5 agents wants maximize
total expected reward within = 10 time steps, (re)distributing = 5 shared resources k = 3 times (twice initial allocation), agent needs
t1
solve Ck1
(2)ok = 1, 179, 648 non-trivial problems evaluate possible sequential
resource assignments. Then, auction faces winner determination problem (WDP)
5 agents submits 1, 179, 648 bids daunting task.

S-RMP problem, solution formulate problem simultaneously solve coupled problems mission decomposition, resource allocation, policy
formulation, exploit interactions among reduce computational cost.
4.5 Exploiting Fixed Resource Reallocation Schedule
Section 3.3, begin simple variant problem, schedule
reallocating resources predetermined, i.e., resource reallocation cost = 0 time step
specified predefined schedule, > 0 otherwise, cost limit = 0.
Section 4.4 explained directly applying (one-shot) integrated combinatorial
stochastic optimization approach phase independently piecing phase policies
together generally infeasible. approach instead links phases together modeling
transition probability conservation. details given following MILP. Note that,
highlight M-RMPs emphasis resource (re)allocation, continue throughout
remainder section omit capacity constraints.

max

XXX






453


xm
i,a ri,a

(9)

fiWu & Durfee

subject to:
probability conservation constraints:
X
XX


xm
pm
j,a = j +
i,a,j xi,a

xm
i,a



0

: m, i,

resource constraints:
P
P

uo,a,i xi,a
iSk
m,k


X
m,k
=



m,k


: m, j



{0, 1}

: k, m,
: o, k
: k, m,

probability conservation constraints Eq. 8, resource
constraints associated (superscripted by) phase k.
indicate whether
agent assigned one
Phase-specific binary variables m,k

P
= says amount
unit resource phase k. constraint m,k

resource allocated phase k must equal amount available (again, assume
m,k
linked constraint
dummy agent hold unwanted resources). xm
i,a
P

xm
i,a

P


um
o,a,i xi,a


m,k
(where Sk represents set states within phase k). is,

0 (i.e., action executable state agent within phase k) um
o,a,i = 1 (i.e.,

iSk



requires resource o) m,k
= 0 (i.e., agent resource phase k)


resource o. Otherwise, xi,a restricted since actions executed
finite time horizon .
Deriving optimal sequential resource allocation joint policy solution
Eq. 9 straightforward. start time phase k, resources redistributed
following way: m,k
= 1, unit resource assigned agent m. Every agent


= Pxi,a
adopt policy i,a
maximize total expected reward group
xi,a
agents.
Running Example: Optimizing Predetermined Phase-Switching Schedule.
Returning running example (Section 4.1), see whether total expected reward improved resources reallocated execution. Let us say
predetermined schedule says resources redistributed times 1, 3, 6, 8,
decomposing example problems time horizon four phases roughly equal duration.
Formulating solving M-RMP problem Eq. 9 yields sequential allocation depicted Figure 11. Compared one-shot distribution (Section 4.2, Figure 10), agent 2
longer idles entire horizon, total expected reward increases 65.04, 31%
higher attained one-shot allocation.
4.6 Determining Optimal Resource Reallocation Schedule
Without predetermined resource reallocation schedule, agents free (within constraints) determine reassign resources achieve remaining
goals better. (Section 4.3), given inputs M, , C, R, M-RMP optimization
454

fiResource-Driven Mission-Phasing Techniques

1

1

1

1

1

2

2

2

2

2

1

1

1

2

2

2

4

3

5

6

7

8

1

1

2

2
9

10

Figure 11: Optimal sequential resource allocation four predefined phases.

problem find optimal resource reallocation schedule (subject resource reallocation constraints R), find optimal resource allocation among agents (subject
resource constraints C) within phase, well derive optimal executable phase
policies agent. complexity problem limitations straightforward
approaches solving described Section 4.4.
instead extend MILP Eq. 9 also reason problem decomposition.
extension shown Eq. 10, (probability conservation) constraints unchanged
Eq. 9 omitted. model constraints total resource reallocation costs
occurrences resource-reallocation events, new formulation represents resource constraints time step (instead phase), introduces supplementary constraints
model phase transitions.
XXX

max
xm
(10)
i,a ri,a






subject to:
probability conservation constraints (unchanged)
resource constraints:
XX

m,t
um
o,a,i xi,a
X

: t, m,



iSt

m,t
=



m,t


: o,

{0, 1}

: t, m,

reallocation constraints:
m,t1
m,t



: o, > 1,

t=1 = 1
X



{0, 1}

:

, xm , um , , definitions before. represents set
ri,a


i,a
o,a,i
indicates
whether
resource
states associated time t. New binary variable m,t


455

fiWu & Durfee

2

1

1

1

1

2

2

2

2

3

1

1

1

2

2

2

1

1

2

2

1

4

5

6

7

8

9

10

Figure 12: Optimal sequential resource allocation four phases without predefined schedule.

assigned agent time t, resource constraints guarantee total amount
allocated resources must equal total amount available resources time point.
model cost constraints resource reallocation, Eq. 10 introduces new binary
variables represent whether resources redistributed time t. sidestep
question default resource allocation might be, assumed resources
always initially allocated beginning execution, i.e., t=1 = 1. Note
m,t
om,t1 never greater one since m,t
om,t1 binary values


m,t1
m,t
thus points must one agent
{0, 1} ; constraint
procures different resource time compared time 1. words, resource
reassignment
time lead = 1, means use constraint
P
limit total cost resource reallocation.

definition, one-to-one mapping possible sequential resource allocations possible integer solutions. addition, given particular sequential resource
allocation, MILP would reduced linear program whose solution space equivalent
executable policy space (because resource constraints would prune unexecutable actions). words, MILP solution space includes best way allocating resources
together best way utilizing allocated resources, finding optimal
solution MILP equivalent finding optimal way sequentially allocating
utilizing resources.

Running Example: Optimizing Fixed Number Phase-Switching Times.
Consider happens agents determine set reallocation times
given upper bound four size set, i.e., t=1 = 0, t6=1 = 1, = 3.
Using Eq. 10, optimal schedule reallocate resources computed {1, 4, 5, 8}. Figure 12
depicts detailed allocation. schedule gives high priority allots sufficient time
agents accomplish high-reward tasks (i.e., task 3 agent 1, task 1 agent
2). result, total expected reward two agents increases 72.25,
11.1% higher fixed set 4 reallocation times evenly spaced
(Section 4.5, Figure 11), 45.5% higher one-shot case (Section 4.2, Figure 10).
456

fiResource-Driven Mission-Phasing Techniques

4.6.1 Variation: Maximizing Total Reward, Accounting Cost
S-RMP problem (Section 3.4.1), consider variation M-RMP problem
neither resource-reallocation schedule predefined (Section 4.5) number
times reallocating resources restricted (Section 4.6), rather cost incurred
time resources reallocated cost calibrated utility MDP
policy. Thus optimization problem maximize total expected reward, accounting
costs redistributing resources execution.
begin examining binary-cost case where, resource reallocation scheduled
time t, charge group agents constant fee regardless resources
many redistributed time. general, coping binary
reallocation costs relatively easy Eq. 10 paved way characterize time
steps resource reassignments.
Eq. 11 shows changed components solution
algorithm
problem,
compared
P
P P
P



,

r
Eq. 10. Eq. 11 adopts new objective function xm

i,a
i,a

P
removes constraint longer applicable since agents
reallocate resources frequently desire.
XXX
X

max
xm

(11)
i,a ri,a


subject to:







probability conservation constraints (unchanged)
resource constraints (unchanged)
reallocation (cost) constraints:
m,t1
m,t



: o, > 1,

t=1 = 1
{0, 1}

:

Next consider difficult variation cost incurred redistributing
resources based amount resources transferred among agents. Since
assumed agents cooperative, matter agent involved
exchange pays resource transfer costs. Without loss generality, let us say agent
obtains one unit resource time someone else,
pays cost cm,t

agent releasing resource pays cost.
used represent whether resource currently held agent time
before, m,t

t. cost agent pay getting resource time represented
m,t
m,t1
cm,t
) function (z) piecewise linear function, defined as:
(o

z z>0
(z) =
0 otherwise
piecewise linear constraint equivalently represented using multiple linear constraints introducing continuous variables m,t
. new MILP formulation shown
Eq. 12, groups changed constraints compared Eq. 10 shown.
XXX
XXX

m,t
xm
max
cm,t
(12)
i,a ri,a









457





fiWu & Durfee

2

1

1

1

1

2

2

2

2

3

1

1

1

1

1

2

2

2

2

2

1

4

5

6

7

8

9

10

Figure 13: Optimal sequential resource allocation, given transfer cost 5 per unit.

subject to:
probability conservation constraints (unchanged)
resource constraints (unchanged)
reallocation (cost) constraints:
m,t=1
= m,t=1



: o,

m,t1
m,t
m,t



m,t


: o, > 1,

0

: o, t,

om,t1 .
m,t
0 m,t
constrained m,t
is, > 1, m,t




m,t
m,t
m,t1
m,t
m,t1
words, 1 >
(i.e., = 1,
= 0), m,t


0Punder

circumstances.
Note


objective
function

Eq.
12


maximize
P P P m,t m,t
P P P m,t m,t
P P



co


co , implying second term


xi,a ri,a
small possible optimal solution yields highest expected utility.
m,t
is, m,t
= 1
reach lower bound optimal solution Eq. 12, i.e.,
m,t
m,t1
m,t
>
(i.e., agent acquires resource time t) = 0 otherwise,
represent piecewise linear cost
exactly matches expectation using m,t

m,t1
function (m,t


).


Running Example: Optimizing Total Reward Accounting Cost. Consider
algorithm manages transfer resources transfer incurs cost
running example problem Section 4.1. transferring one unit resource costs
5, optimal sequential resource allocation, shown Figure 13, transfer
four units resources entire execution (two units initial time 1, one unit
time 4, one unit time 5). surprisingly, transfer cost increases, amount
resources transferred decreases, vice versa.
Table 2 compares resulting schedule schedules derived previous sections,
incorporating cost 5 resource transfer. expected, algorithm
Eq. 12 yields reallocation schedule highest utility, 48.72.
4.7 Experimental Evaluation
analyzed computational complexity M-RMP problem Section 4.4; here,
empirically evaluate effectiveness computational efficiency MILP-based solution
458

fiResource-Driven Mission-Phasing Techniques

Case
one-shot (Figure 10)
4 fixed times (Figure 11)
3 added times (Figure 12)
unlimited times balancing cost (Figure 13)

Total Resource (Re)Assignments
2
7
5
4

Utility
39.64
30.04
47.25
48.72

Table 2: Comparison resource reallocation schedules example problem, given
transfer cost 5 per unit.

algorithms developed section, using grid world environment similar used
S-RMP evaluation Section 3.5.14
4.7.1 Experimental Setup
test problem instance includes cooperative agents agent operates
nn grid world independent others. starting location agent always
center grid world.15 objective group agents maximize total
expected reward within time steps. Like single-agent test problems (Section 3.5),
grid world generated, 40% locations randomly chosen walls, 10%
randomly chosen task locations. rewards tasks randomly set, i.e.,
ith task (in random order) given reward i.
task temporally constrained release time deadline. release time
time step task becomes available, i.e., attempting task
return zero reward. deadline task becomes unavailable, i.e., finishing
task also return zero reward. temporal constraints randomly set.
tasks release time integer uniformly randomly selected range [1, 2]
time horizon, deadline always three time steps later. Thus, task
time window [ti , ti + 3) ti random integer [1, 2]. task repeated
multiple times (and time give reward) within time window.
action space agent {wait, up, left, down, right, safe-up, safe-left, safe-down,
safe-right, do}. actions except action exactly definitions
(Section 3.5). resource prerequisite action also before,
outcome longer always terminates execution immediately. Instead, terminates
probability 0.05, otherwise agent stays location (with probability 0.95)
repeat task move another task time horizon reached.
change makes test problems interesting complex, since agent uses
resources throughout experiment rather completing first task.
system constrained resource limitations. |O| different resource types
system. Further, one instance resource type, shared
agents.
14. empirical evaluation domain problems similar (but complex than) running
example used section (Figure 8) found work Wu Durfee (2007a).
15. Starting center makes problem interesting challenging starting corner, allowing
agent potentially visit larger fraction grid world sooner.

459

fiWu & Durfee

25

5 optimal phases
average reward

20

5 fixed phases
15

nonphasing

10

5

0

2

3

4

5

6

7

8

9

10

number agents

Figure 14: Exploiting fixed phases increases reward, finding optimal phases
increases reward.

4.7.2 Improvements Solution Quality
Figure 14 demonstrates improvement sequential resource allocation approaches
prior one-shot resource allocation approach. x-axis figure represents
number agents world, y-axis specifies total expected reward
group agents.16 parameters set follows: = 10, n = 5, |O| = 5.
see that, taking account resource reallocation opportunities execution,
agents gain considerably higher reward. example, case five fixed
resource (re)allocation times (one initial time step four randomly
uniformly selected test problem defined) available midst execution,
mission-phasing approach, using Eq. 9 denoted 5-fixed-phases, average achieves
reward 50% higher exploiting resource-reallocation opportunities.
also see (as expected) finding using optimal resource-allocation phaseswitching time points improve system performance, e.g., 5-optimal-phases
approach (using Eq. 10 assuming four additional phase-switching points besides
one initial time step created) achieves average reward 20% higher
aforementioned 5-fixed-phases solution.
Another interesting observation Figure 14 improvement sequential resource allocation one-shot resource allocation increases number agents increases.
because, given number resources fixed 5, agents are,
scarcer resources are. Hence, assigning resource right agent right
time becomes increasingly important performance constrainedness system
increases.
Figure 15 uses parameters Figure 14 (i.e., = 10, n = 5, |O| = 5),
holds number agents constant = 5, shows much better agents
choose phase-switching times (Eq. 10) number phase-switching times
16. section, average data point computed 20 random test problems.

460

fiResource-Driven Mission-Phasing Techniques

25

average reward

20

15

10

5

0

1

2

3

4

5

6

7

8

9

10

number phases

Figure 15: reward increases phase-switching cost limit (that determines number phases) increases.

allowed rises. However, note that, unlike S-RMP optimization problem, even agents
reallocate resources every time step, usually cannot achieve reward
unconstrained case unlimited resources (which reward 37.2 average
test problems). because, time step, agents might able
acquire desired resources simply enough resources
go around.
4.7.3 Computational Efficiency
understand impact number phases computational cost choose
hard M-RMP test problems computational efficiency evaluation follow,
run experiments parameters Figure 15, collect examine results
average runtime finding exact solutions test problems. shown Figure 16,
MILP-based solution approach exploit over-constrainedness (when number phases
small) under-constrainedness (when number phases large) improve efficiency.
complexity profile indicates average, parameter settings, problems
difficult constrained 3 phases (that = 2 usual t=1 = 0).
experiments follow, one parameter varied time others retain
default settings, variations create larger complex instances used
generate Figure 16. Hence, phase-switching cost limit default set 3 avoid
simpler over-constrained problems.
compare MILP-based algorithm (Eq. 10) WDP-based algorithm (using
auction-based resource allocation strategy), computationally-efficient
approach among three prior related approaches discussed Section 4.4. Recall
WDP-based algorithm involves two steps. First, agent submits valuations possible
1
sequential resource allotments central agent. number bids CK1
(2)|O|K (as
explained Section 4.4). Second, central agent solves winner determination problem.
461

fiWu & Durfee

70

runtime (seconds)

60

50

40

30

20

10

0

1

2

3

4

5

6

7

8

9

10

number phases

Figure 16: runtime increases decreases number times resource
reallocation increases.

Let us assume central agent perfect filtering method (although usually
not), needs consider evaluate valid combinations bids.
1
1
assumption reduces number possible combinations (CK1
(2)|O|K )m CK1

(m)|O|K base exponentiation (m)|O|K different
ways allocate one resource among agents.
However, even enhancement, WDP-based algorithm still computationally
intractable moderately complex M-RMP problems (where often cannot find exact
solution within 100 hours cpu time). Note lower bound running time
1
1
(2)|O|K tbid +CK1
(m)|O|K teval
WDP-based algorithm approximated CK1
tbid average runtime evaluating sequential resource allotment (i.e., bid)
modeling solving unconstrained finite-horizon MDP, teval average runtime
evaluating feasible combination agents bids. work uses sampling method
estimate runtime, i.e., tbid teval estimated 100,000 random runs.
Figure 17 compares average runtime results various parameter settings.17 Note
y-axis logarithmic scale. results illustrate emphasize
MILP-based algorithm, formulates simultaneously solves coupled problems
mission decomposition, resource allocation, policy formulation using single compact
MILP formulation, effectively fruitfully exploit inter-relationships among
component problems. result, significantly faster WDP-based approach
considers component problems isolation.
4.8 Summary
section, presented, analyzed, empirically evaluated MILP-based approach automates process finding using optimal resource reallocation schedules
17. Neither MILP WDP uses parallel computation.

462

fiResource-Driven Mission-Phasing Techniques

15

15

10
WDPbased
MILPbased

runtime (seconds)

runtime (seconds)

10

10

10

5

10

0

10

WDPbased
MILPbased
10

10

5

10

0

2

4

6

8

10

10

number phases
15

8

10

15

10
WDPbased
MILPbased

runtime (seconds)

runtime (seconds)

6

number resource types

10

10

10

5

10

0

10

4

WDPbased
MILPbased
10

10

5

10

0

6

8

10

12

10

14

horizon

4

6

8

10

number agents

Figure 17: Runtime comparison MILP-based algorithm WDP-based algorithm. Parameters set follows: Top-left figure n = 5, = 10, = 5,
|O| = 5, = {1, 2, ..., 9}. Top-right figure n = 5, = 10, = 5,
|O| = {4, 5, ..., 10}, = 3. Bottom-left figure n = 5, = {6, 7, ..., 14},
= 5, |O| = 5, = 3. Bottom-right figure n = 5, = 10, = {3, 4, ..., 10},
|O| = 5, = 3.

463

fiWu & Durfee

group agents operating complex environments resource limitations
uncertainties. analytical experimental results shown approach
greatly reduce computational cost compared prior approaches.

5. Related Work
resource-driven mission phasing (RMP) problem involves three intertwined component
problems: mission (problem) decomposition, resource configuration, policy formulation.
component problems studied wide variety research fields.
combinations two also gained much attention recent years. section
gives overview related work, discusses prior approaches directly
applicable RMP problem interest paper.
presented Section 3.1 Section 4.3, RMP problems defined extending unconstrained MDP model include resource constraints phase-switching
constraints. organization section follows way definition. begins
discussion policy formulation techniques, followed discussion resource configuration techniques. reviews problem decomposition techniques combinations
policy formulation and/or resource configuration work. section concludes
discussion mode-transition research related work fit clearly
previous categories.
5.1 Policy Formulation.
well-known Markov decision process described Section 2.1. formulating
sequential decision-making problem MDP model, number efficient (polynomialtime) solvers, value iteration policy iteration algorithms, used
compute optimal policy (Puterman, 1994).
However, directly applying algorithms resource-constrained systems,
resource-driven mission-phasing problem, typically involves incorporating resource features
MDP state representation (and actions conditioned resource availability),
result exponential increase size state space (Meuleau et al.,
1998), i.e., well known curse dimensionality challenge. shown empirical results (Section 3.5.3) exponential-size state space result computational
inefficiency.
5.2 Resource Configuration.
domains impossible (or expensive) resolve resource constraints
modifying agents physical architecture (for example, adding another battery robot
already deployed Mars), improving performance constrained agent limited architecture active subject recent years, i.e., class bounded optimality problems (Russell, 2002). Cooperative Intelligent Real-Time Control Architecture
(CIRCA) one research effort (Musliner, Durfee, & Shin, 1993, 1995). CIRCA uses
simple greedy, myopic approach compute feasible policies. starts building
optimal unconstrained policy without worrying real-time requirements,
greedily repairs policy executable real-time system.
464

fiResource-Driven Mission-Phasing Techniques

surprisingly, (fast) greedy approach adopted CIRCA might result suboptimal policies cannot fully utilize agents capacity. Several recent studies
proposed alternative algorithms searching policy executable within agent
capacity constraints optimizes expected (possibly discounted) reward accrued
entire agent execution. example, Altman (1998) adopted Lagrangian dual
LP approach solve constrained MDPs total cost criteria. Feinberg (2000) analyzed
complexity constrained discounted MDPs. particular relevance work
paper study strongly-coupled resource allocation policy formulation problems
Dolgov Durfee (2006). approach implements simultaneous combinatorial optimization stochastic optimization via reduction mixed integer linear programming,
recapped Section 2.2. However, prior studies constrained agents
based upon assumption agents limited capacity configured resources
procures prior execution cannot reconfigured plan execution.
5.3 Problem Decomposition.
literature stochastic planning, number decomposition algorithms
proposed speed planning process. discovery recurrent classes MDPs
one decomposition strategy, find exact state space decomposition
environment uncertainties (Puterman, 1994; Boutilier, Dean, & Hanks, 1999).
recurrent class represents special absorbing subset state space, means
agent enters recurrent class remains forever matter policy adopts.
Puterman (1994) suggested variation Fox-Landi algorithm (Fox & Landi, 1968)
discover recurrent classes. discovery recurrent classes, MDP solver
derive optimal overall policy building optimal policy recurrent class
independently constructing solving reduced MDP consisting transient
states (i.e., removing recurrent classes MDP).
course, application problems exactly decomposed independent subproblems. However, many composed multiple weakly-coupled sub-problems
number states transitions connecting two neighboring sub-problems relatively small. number heuristic decomposition methods designed exploit
weakly-coupled relationships. example, robot navigation domain (Parr, 1998;
Precup & Sutton, 1998; Lane & Kaelbling, 2001), doorways (or similar connection structures,
bridges) used break large environment blocks states, e.g., one block
room. Two neighboring blocks connected small number doorway
states. weakly-coupled state space decomposed several pieces,
methods used efficiently build overall policy based upon sub-problem policies. One common method let sub-problem iteratively exchange information
neighboring sub-problems, repeatedly revise sub-policy (if necessary) based upon
updated knowledge utilities values neighbors overall (approximately)
optimal solution derived (Dean & Lin, 1995).
Besides application stochastic planning, decomposition techniques also
shown beneficial resource management many realistic application domains. Several resource allocation algorithms developed problem allocating set
heterogeneous resources availability constraints maximize given utility function (Wu
& Castanon, 2004; Palomar & Chiang, 2006; Reveliotis, 2005). example, Wu Cas465

fiWu & Durfee

tanon (2004) presented approximate solution algorithm using decomposition combined
dynamic programming, experimental results showed algorithm produces
near-optimal results much reduced computational effort.
addition Artificial Intelligence (AI) techniques discussed above, decomposition
techniques, often integrated hierarchical control (also called multilevel control
literature), received much attention recent years Operations Research,
Operations Management, Systems Theory, Control Theory, several fields (Sethi,
Yan, Zhang, & Zhang, 2002; Antoulas, Sorensen, & Gugercin, 2001; Xiao, Johansson, & Boyd,
2004; Phillips, 2002; Teneketzis, Javid, & Sridhar, 1980). Many manufacturing systems
large complex; management systems requires recognizing reacting
wide variety events could deterministic stochastic. Obtaining exact optimal
policies run systems often difficult theoretically computationally.
exploiting fact real-world systems often characterized several decision subsystems, e.g., company consists departments marketing, production, personnel,
on, one popular way deal computational complexity challenge develop
methods hierarchical decision-making systems. fundamental ideas
reduce overall complex problem multiple smaller, manageable sub-problems, solve
sub-problems, coordinate solutions sub-problems overall system
objectives constraints satisfied (Sethi et al., 2002).
summarize, well established utilizing decomposition greatly reduce computational costs many situations. However, aforementioned prior decomposition
techniques directly applicable RMP optimization problem. underlying
reason decomposition points good reducing computational efforts
necessarily (and possibly completely unrelated to) optimal points constrained agents
reconfigure resources. worth emphasizing RMP decomposition tackles capacity
constraints instead computation time constraints. Indeed, general, mission decomposition RMP solution reduce computational requirements
policy one phase usually optimized respect policies planned
possible subsequent phases.
5.4 Mode Transition.
Finally, important distinguish resource-driven mission-phasing research
mode-transition research implemented fields Operations Research Control
Theory (Schrage & Vachtsevanos, 1999; Wills, Kannan, Sander, Guler, Heck, Prasad, Schrage,
& Vachtsevanos, 2001; Karuppiah, Grupen, Hanson, & Riseman, 2005). first glance,
two research fields lot common: work transitions one subproblem another, take account resource reconfigurations. However,
pointed emphasize distinct aspects, applicable different application
domains.
First all, mode-transition approach, operational modes usually tightly associated explicit actions (e.g., hover fly-forward modes helicopter example
described Schrage & Vachtsevanos, 1999), corresponding particular states (e.g.,
sleep, search, seed, final modes defined Bojinov, Casal, & Hogg, 2002), characterized
explicit purposes (e.g., passing narrow tunnel traversing rough
terrain requires self-reconfiguring robot adjust shape achieve goal better, Rus
466

fiResource-Driven Mission-Phasing Techniques

& Vona, 2001). contrast explicit definition representation modes modetransition research, phases RMP problem usually much difficult identify.
phasing information hidden MDP model, finding optimal phases usually
challenging task.
Second, mode-transition research, mode transition resource reconfiguration
often triggered real-time events, e.g., responding unexpected disastrous event
reconfiguring resources fault toleration (Drozeski, 2005). contrast, resourcedriven mission-phasing study assumes decision-making agent complete information
environment prior execution, one main objectives find
optimal points reconfiguring resources capacity usage. is, phase switching
RMP choice agent instead reactive response exogenous event.
specifically, RMP techniques presented paper utilize sequential decision-making
identify optimal resource reconfiguration policy switching states. emphasize
reconfigure resources switch policies agent(s) would (or would less
likely to) enter predicament encountering undesirable events, instead studying
reconfigure resources real-time respond unexpected event.
Finally, much prior mode-transition research, particularly Control Theory literature,
investigates perform smooth functional transition among modes, work
paper simply assumes aggregate resource (re)configuration actions,
sequence primitive actions arranging resources. paper
address details agents mechanically implement mode-transition resourcereconfiguration actions.

6. Conclusion
work paper designed, analyzed, evaluated suite computationally efficient
algorithms automatically identify utilize resource reconfiguration opportunities
resource-constrained environments. analytical experimental results illustrated
emphasized mission phasing approach, incorporating problem decomposition,
resource allocation, policy formulation, help constrained agents judiciously effectively exploit resource reconfiguration opportunities improve performance.
section concludes paper summary main contributions work
discussion several promising future research directions.
6.1 Summary Contributions
. work explicitly took account known opportunities midst execution
reconfigure resources switch policies, designed computationally efficient algorithms (including abstract MDP algorithm single-agent resource reconfiguration
problems MILP-based algorithm multiagent resource reallocation problems)
optimize use fixed opportunities complex stochastic systems. empirical results (Figure 4 Figure 14) confirmed exploiting phase-switching
opportunities considerably improve performance, particularly tightly constrained
systems (the reward doubles test cases).
. extension utilizing fixed phase-switching opportunities, Section 3.4 (for singleagent systems) Section 4.6 (for multiagent systems) presented MILP-based algo467

fiWu & Durfee

rithms able automate process finding using mission phases
stochastic, constrained systems, eliminates need phases
predefined, also avoids potential sub-optimality caused phases improperly
predefined.
. automated resource-driven mission-phasing algorithms presented work
computationally efficient. capturing whole mission-phasing problem compact mathematical formulation simultaneously solving coupled problems
mission decomposition, resource allocation, policy formulation, presented
algorithms effectively exploit problem structure, results significant reduction computational cost comparison approach considers mission
decomposition, resource allocation, policy formulation isolation (e.g., reduction
hours seconds shown Figure 17).
. Unlike much prior work agents reactively (and often greedily) reconfigure resources exogenous events occur, work, based upon Markov decision processes
sequential decision-making theory, proactively determine optimally utilize resource reconfiguration opportunities. provides new computationally efficient
resource-reconfiguration mechanism resource-constrained environments.
6.2 Future Work
Although paper presented suite algorithms improve agent performance constrained stochastic systems, still much interesting work remaining. Below, point
promising research directions overcome limitations work
presented paper.
. Resource Constraints Time Limitations
Resource-driven mission-phasing problems NP-complete. Although solution approaches designed work exploit problem structure reduce computational
cost, finding exact solution complex RMP problem might still difficult, particularly time-limited environments. One approach handling problems
adopt approximate methods. preliminary investigations developing anytime
algorithms solving problems resource constraints time limitations
shown promise (Wu, 2008) work remains area, including comparing
methods grounded RMP concepts heuristic greedy techniques allocating resources agents.
. Flexible Resource Reallocation Options
work discussed paper assumed clear delineation two kinds
states: states resources (re)allocated way desired (phase-switching
states) states resource allocations cannot change. generally, might
case states could exist limited resource reallocations could occur (e.g., partially filled toolbox, subset agents swap
resources), leading challenging reasoning problems agents decide
states seek avail of. Further, agent could even potentially
468

fiResource-Driven Mission-Phasing Techniques

create state fly dropping resources well-chosen state
gainfully retrieved (perhaps another agent) future time. Obviously, problems
get increasingly complicated kinds ways, modeling resources part state
incorporating actions picking dropping resources becomes important,
leading MDP-based solution techniques described paper (e.g., Sections 3.2
3.5.3). Finding methods kind flexibility without incurring
costs MDP-based techniques challenging direction future work.
. Resource Reallocation Decentralized MDPs
limiting assumption made work that, resource reallocation scheduled, participant agents always able successfully redistribute resources among
scheduled time, regardless state features values
are. plan relax assumption future consider sequential resource
allocation problems additional constraints agents able
exchange resources. example, physical agents might able exchange
resources location time. Or, another example, task might interruptible started, means may
impossible reassign resources used task task completed.
Decentralized MDPs one possible way solve problems. preliminary work (Wu & Durfee, 2006), included paper, developed
MILP-based algorithm solving transition independent Dec-MDPs. work linked
Dec-MDP formulation MILP formulation, pointed one way
characterize resource constraints MILP formulation. future, dig
deeper direction.
. Application Evaluation Settings
work far focused testing techniques problems small enough
solve using slower standard approaches (to confirm techniques optimal)
generated spaces problems allow us probe efficacy techniques
settings vary controlled ways. Applying techniques extensive
realistic domains important avenue follow identify strengths
weaknesses better. example application particularly interested in,
prompted work early stages, intelligent real-time control. Systems
CIRCA (Musliner et al., 1993, 1995) use AI techniques construct real-time control
plans composed set sense-act tasks scheduled frequencies
ensure safe operation. Often, desired sense-act tasks cannot fit
schedule, important combination tasks must chosen. applications
controlling unmanned aircraft (Atkins, Abdelzaher, Shin, & Durfee, 2001),
different combinations might better different phases activity (takeoff, cruising,
landing, etc.). Similarly, formation aircraft, aircraft responsible
detecting reacting particular event shift time progresses mission
(Musliner, Goldman, & Krebsbach, 2005). prior work used heuristic, local
search techniques find good solutions phasing problems, techniques
paper potential finding optimal mission decompositions.
469

fiWu & Durfee

Acknowledgments
material based upon work supported part DARPA/IPTO COORDINATORs
program Air Force Research Laboratory Contract No. FA875005C0030,
Air Force Office Scientific Research Contract No. FA9550-07-1-0262.
views conclusions contained document authors,
interpreted representing official policies, either expressed implied, Defense
Advanced Research Projects Agency, Air Force, U.S. Government.
authors thank Dmitri Dolgov three anonymous reviewers helpful
suggestions comments, Stefan Witwicki Jim Boerkoel help proofreading article.

References
Altman, E. (1998). Constrained Markov decision processes total cost criteria: Lagrange
approach dual LP. Methods Models Operations Research, 48, 387417.
Antoulas, A. C., Sorensen, D. C., & Gugercin, S. (2001). survey model reduction methods
large-scale systems. Contemporary Mathematics, 280, 193220.
Atkins, E. M., Abdelzaher, T. F., Shin, K. G., & Durfee, E. H. (2001). Planning resource
allocation hard real-time, fault-tolerant plan execution. Autonomous Agents
Multi-Agent Systems, 4 (1-2), 5778.
Becker, R., Zilberstein, S., Lesser, V. R., & Goldman, C. V. (2004). Solving transition independent decentralized Markov decision processes. Journal Artificial Intelligence
Research, 22, 423455.
Bellman, R. (1957). Markov decision process. Journal Mathematical Mechanics, 6,
679684.
Bererton, C. A., Gordon, G. J., & Thrun, S. (2003). Auction mechanism design multi-robot
coordination. Advances Neural Information Processing Systems, pp. 879886.
Bernstein, D. S., Zilberstein, S., & Immerman, N. (2000). complexity decentralized control Markov decision processes. Proceedings 16th Conference Uncertainty
Artificial Intelligence, pp. 3237.
Bojinov, H., Casal, A., & Hogg, T. (2002). Multiagent control self-reconfigurable robots.
Artificial Intelligence, 142, 99120.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research, 11, 194.
Cook, W., Cunningham, W., Pulleyblank, W., & Schrijver, A. (1998). Combinatorial Optimization. John Wiley & Sons, New York.
De Vries, S., & Vohra, R. (2003). Combinatorial auctions: survey. INFORMS Journal
Computing, 15 (3), 284309.
Dean, T., & Lin, S. H. (1995). Decomposition techniques planning stochastic domains.
Proceedings 14th International Joint Conference Artificial Intelligence, pp.
304309.
470

fiResource-Driven Mission-Phasing Techniques

Dolgov, D. A. (2006). Integrated Resource Allocation Planning Stochastic Multiagent
Environments. Ph.D. thesis, Computer Science Department, University Michigan.
Dolgov, D. A., & Durfee, E. H. (2005). Computationally-efficient combinatorial auctions
resource allocation weakly-coupled MDPs. Proceedings 4th International
Joint Conference Autonomous Agents Multiagent Systems, pp. 657664.
Dolgov, D. A., & Durfee, E. H. (2006). Resource allocation among agents MDP-induced
preferences. Journal Artificial Intelligence Research, 27, 505549.
Drozeski, G. R. (2005). Fault-Tolerant Control Architecture Unmanned Aerial Vehicles.
Ph.D. thesis, Georgia Institute Technology.
Earl, M., & DAndrea, R. (2005). Iterative MILP methods vehicle control problems. IEEE
Transactions Robotics, 21 (6), 11581167.
Feinberg, E. (2000). Constrained discounted Markov decision processes Hamiltonian
cycles. Mathematics Operations Research, 25, 130140.
Fox, B., & Landi, D. M. (1968). algorithm identifying ergodic subchains
transient states stochastic matrix. Communications ACM, 2, 619621.
Goldman, C. V., & Zilberstein, S. (2004). Decentralized control cooperative systems:
Categorization complexity analysis. Journal Artificial Intelligence Research, 22,
143174.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
factored MDPs. J. Artif. Int. Res., 19 (1), 399468.
Kallenberg, L. (1983). Linear Programming Finite Markovian Control Problems. Mathematisch Centrum, Amsterdam.
Karuppiah, D., Grupen, R., Hanson, A., & Riseman, E. (2005). Smart resource reconfiguration
exploiting dynamics perceptual tasks. IEEE/RSJ International Conference
Intelligent Robots Systems, pp. 1513 1519.
Kautz, H., & Walser, J. (2000). Integer optimization models AI planning problems. Knowledge Engineering Review, 15(1), 101117.
Kim, K.-E., & Dean, T. (2001). Solving factored MDPs via non-homogeneous partitioning.
IJCAI01: Proceedings 17th international joint conference Artificial intelligence, pp. 683689.
Lane, T., & Kaelbling, L. P. (2001). Toward hierarchical decomposition planning
uncertain environments. Proceedings 2001 IJCAI Workshop Planning
Uncertainty Incomplete Information, pp. 17.
Lehman, T. J., & Carey, M. J. (1986). study index structures main memory database
management systems. Proceedings 12th International Conference Large
Data Bases, pp. 294303.
Lesser, V., Decker, K., Wagner, T., Carver, N., Garvey, A., Horling, B., Neiman, D., Podorozhny, R., Prasad, M. N., Raja, A., Vincent, R., Xuan, P., & Zhang, X. (2004). Evolution GPGP/TAEMS domain-independent coordination framework. Autonomous
Agents Multi-Agent Systems, 9 (1), 87143.
471

fiWu & Durfee

Meuleau, N., Hauskrecht, M., Kim, K.-E., Peshkin, L., Kaelbling, L. P., Dean, T., & Boutilier,
C. (1998). Solving large weakly coupled Markov decision processes. Proceedings
15th National Conference Artificial Intelligence, pp. 165172.
Musliner, D. J., Durfee, E. H., & Shin, K. G. (1993). CIRCA: cooperative intelligent real
time control architecture. IEEE Transactions Systems, Man, Cybernetics, 23 (6),
15611574.
Musliner, D. J., Durfee, E. H., & Shin, K. G. (1995). World modeling dynamic
construction real-time control plans. Artificial Intelligence, 74 (1), 83127.
Musliner, D. J., Goldman, R. P., & Krebsbach, K. D. (2005). Deliberation scheduling strategies
adaptive mission planning real-time environments. Anderson, M., & Oates, T.
(Eds.), Metacognition Computation, Vol. SS-05-04 AAAI Technical Report, pp.
98105. AAAI Press.
Palomar, D., & Chiang, M. (2006). tutorial decomposition methods network utility
maximization. IEEE Journal Communications, 24 (8), 1439 1451.
Parr, R. (1998). Flexible decomposition algorithms weakly coupled Markov decision problems. Proceedings 14th Conference Uncertainty Artificial Intelligence, pp.
422430.
Pekec, A., & Rothkopf, M. (2003). Combinatorial auction design. Management Science,
49 (11), 14851503.
Phillips, A. (2002). Functional decomposition vehicle control system. Proceedings
2002 American Control Conference, pp. 37133718.
Precup, D., & Sutton, R. (1998). Multi-time models temporally abstract planning. Advances Neural Information Processing Systems, 10, 10501056.
Puterman, M. L. (1994). Markov Decision Processes. John Wiley & Sons, New York.
Reveliotis, S. A. (2005). Real-Time Management Resource Allocation Systems: Discrete
Event Systems Approach. Springer-Verlag New York.
Rus, D., & Vona, M. (2001). Crystalline robots: Self-reconfiguration compressible unit
modules. Autonomous Robots, 10 (1), 107124.
Russell, S. (2002). Rationality intelligence. Elio, R. (Ed.), Common Sense, Reasoning,
Rationality. Oxford University Press, USA.
Sacco, G., & Schkolnick, M. (1982). mechanism managing buffer pool relational
database system using hot set model. Proceedings 8th International Conference
Large Data Bases, 257262.
Schrage, D., & Vachtsevanos, G. (1999). Software-enabled control intelligent UAVs. Proceedings 1999 International Symposium Computer Aided Control System Design,
pp. 528532.
Sethi, S. P., Yan, H., Zhang, H., & Zhang, Q. (2002). Optimal hierarchical controls dynamic stochastic manufacturing systems: survey. Manufacturing & Service Operations
Management, 4 (2), 133170.
472

fiResource-Driven Mission-Phasing Techniques

Sutton, R., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: framework
temporal abstraction reinforcement learning. Artificial Intelligence Journal, 112,
181211.
Sutton, R., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press, Cambridge, MA.
Teneketzis, D., Javid, S. H., & Sridhar, B. (1980). Control weakly-coupled Markov chains.
Proceedings 1980 19th IEEE Conference Decision Control including
Symposium Adaptive Processes, pp. 137143.
van Beek, P., & Chen, X. (1999). CPlan: constraint programming approach planning.
Proceedings 16th National Conference Artificial Intelligence, pp. 585590.
Vossen, T., Ball, M., Lotem, A., & Nau, D. (1999). use integer programming models
AI planning. Proceedings 16th International Joint Conference Artificial
Intelligence, pp. 304309.
Wagner, T., Phelps, J., Guralnik, V., & VanRiper, R. (2004). application view COORDINATORS: Coordination managers first responders. AAAI, pp. 908915.
Wagner, T., Raja, A., & Lesser, V. (2006). Modeling uncertainty implications
sophisticated control TAEMS agents. Autonomous Agents Multi-Agent Systems,
13 (3), 235292.
Wills, L., Kannan, S., Sander, S., Guler, M., Heck, B., Prasad, J., Schrage, D., & Vachtsevanos,
G. (2001). open platform reconfigurable control. Control Systems Magazine,
IEEE, 21 (3), 4964.
Wolsey, L. A. (1998). Integer Programming. John Wiley & Sons, New York.
Wu, C., & Castanon, D. (2004). Decomposition techniques temporal resource allocation.
IEEE Conference Decision Control, pp. 3798 3803.
Wu, J. (2008). Mission-Phasing Techniques Constrained Agents Stochastic Environments. Ph.D. thesis, University Michigan.
Wu, J., & Durfee, E. H. (2005). Automated resource-driven mission phasing techniques
constrained agents. Proceedings 4th International Joint Conference Autonomous Agents Multiagent Systems, pp. 331338.
Wu, J., & Durfee, E. H. (2006). Mixed-integer linear programming transition-independent
decentralized MDPs. Proceedings 5th International Joint Conference Autonomous Agents Multiagent Systems, pp. 10581059.
Wu, J., & Durfee, E. H. (2007a). Sequential resource allocation multi-agent systems
uncertainties. Proceedings 6th International Joint Conference Autonomous
Agents Multiagent Systems, pp. 760767.
Wu, J., & Durfee, E. H. (2007b). Solving large TAEMS problems efficiently selective
exploration decomposition. Proceedings 6th International Joint Conference
Autonomous Agents Multiagent Systems, pp. 291298.
Xiao, L., Johansson, M., & Boyd, S. P. (2004). Simultaneous routing resource allocation
via dual decomposition. IEEE Transactions Communications, 52 (7), 11361144.

473

fiJournal Artificial Intelligence Research 38 (2010) 569-631

Submitted 12/09; published 08/10

Cause Identification Aviation Safety Incident Reports
via Weakly Supervised Semantic Lexicon Construction
Muhammad Arshad Ul Abedin
Vincent Ng
Latifur Khan

arshad@student.utdallas.edu
vince@hlt.utdallas.edu
lkhan@utdallas.edu

Department Computer Science
Erik Jonsson School Engineering & Computer Science
University Texas Dallas
800 W. Campbell Road; MS EC31
Richardson, TX 75080 U.S.A.

Abstract
Aviation Safety Reporting System collects voluntarily submitted reports aviation safety incidents facilitate research work aiming reduce incidents. effectively reduce incidents, vital accurately identify incidents occurred.
precisely, given set possible causes, shaping factors, task cause identification involves identifying shaping factors responsible
incidents described report. investigate two approaches cause identification.
approaches exploit information provided semantic lexicon, automatically constructed via Thelen Riloffs Basilisk framework augmented linguistic
algorithmic modifications. first approach labels report using simple heuristic, looks words phrases acquired semantic lexicon learning
process report. second approach recasts cause identification text classification problem, employing supervised transductive text classification algorithms
learn models incident reports labeled shaping factors using models
label unseen reports. experiments show heuristic-based approach
learning-based approach (when given sufficient training data) outperform baseline
system significantly.

1. Introduction
Safety paramount importance comes aviation industry. 2007 alone,
4659 incidents1 , including 26 fatal accidents 750 casualties2 . improve
aviation safety situation, Aviation Safety Reporting System (ASRS) established
1976 make safety incident data available researchers. ASRS collects voluntarily submitted reports aviation safety incidents written flight crews, attendants, controllers
related parties. reports contain number fixed fields free text narrative describing incident. However, data grown quite large years
getting increasingly difficult, impossible, analyze reports human
means. become necessary reports analyzed automated means.
1. http://asrs.arc.nasa.gov/
2. http://www.flightsafety.gov/
c
2010
AI Access Foundation. rights reserved.

fiAbedin, Ng & Khan

take full advantage data reduce safety incidents, necessary extract
reports happened why. known, possible
identify correlations incidents causes, take fruitful measures
toward eliminating causes. However, fixed fields reports devoted various
aspects happened incidents, fixed field indicates
incidents causes. Instead, reporter discusses report narrative thinks
caused incident, along incident description. Thus cause incident
extracted analyzing free text narrative. example, report shown next
illustrate task:
Report#424362. descending lit encountered Instrument Meteorological Conditions; rime ice; rain; moderate chop. turned
heading Auto-Pilot direct lit attitude indicator remained
bank. XCHKING; noticed Radio Magnetic IndicatorS 55 degree
headings. switched #2 corrected course. Auto-Pilot flight
director kicked off. continued problems altitude select
Auto-Pilot attempted re-engage it. radar vectors
approach descent 2300 feet noticed altitude 2000 feet
Mean Sea Level. stopped descent climbed 2300 feet Mean Sea
Level. Air Traffic Control noted altitude deviation time noticed.
thankful backup time flight director problems
cockpit. occurred end 13 hour crew day; bad weather; instrument problems; lack crew rest. First Officer (Pilot Flying)
right seat; 4 hours rest due inability go sleep
night before. tired trip lit-ORL-lit. eaten
7 hours.3
Posse et al. (2005) identify 14 important cause types, shaping factors,
influence occurrence aviation safety incident described ASRS report.
shaping factors contextual factors influenced reporters behavior
incident thus contributed occurrence incident. factors
attributed humans (e.g., pilot flight attendant psychological Pressure,
overly heavy Taskload, unprofessional Attitude impacts performance),
related surrounding environment (e.g., Physical Environment snow,
Communication Environment auditory interference). detailed description
14 shaping factors found Section 2.1.
report, find incident influenced three shaping factors,
namely Physical Environment (which concerns bad weather, mentioned above), Resource
Deficiency (which concerns problems equipment), Duty Cycle (which refers
physical exhaustion due long hours duty without adequate rest replenishment).
three shaping factors indicated different words phrases report.
instance, bad weather condition expressed using phrases rime ice, rain
moderate chop, details equipment problem appear sentence fragments like
3. improve readability, report preprocessed original form using steps described
Section 2.2.

570

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

attitude indicator remained bank, 55 degree headings flight director problems.
issue long hours duty illustrated sentence fragments like 13 hour
crew day tired trip. goal cause identification task aviation
safety domain, then, identify 14 shaping factors contributed incident
described report using lexical cues appearing report narrative.
However, mentioned earlier, sheer volume data makes prohibitive
analyze reports manually identify associated shaping factors. Thus,
focus research automated cause identification ASRS reports, involves
automatically analyzing report narrative identifying responsible shaping factors.
brings problem domain Natural Language Processing (NLP).
Since set texts (i.e., report narratives) set possible labels
texts (i.e., shaping factors), task naturally cast text classification
task. However, unlike topic-based text classification, cause-based text classification
addressed extensively NLP community. Previous work causal analysis quite
different nature cause-based text classification task. specifically, previous
cause analysis works involve text classification, focusing instead determining
existence causal relation two sentences events. instance,
work causal analysis question answering, question may involve
cause(s) event (e.g., Kaplan & Berry-Rogghe, 1991; Garcia, 1997; Khoo, Chan, & Niu,
2000; Girju, 2003). Here, focus finding causal relationship two sentence
components. another example, causal analysis equipment malfunction reports
attempted Grishman Ksiezyk (1990), whose work restricted analysis
reports related one specific piece equipment studied. analyze cause-effect
relations events leading malfunction described reports.
Cause identification aviation safety reports rather challenging problem,
result number factors specific ASRS dataset. First, unlike many NLP problems
underlying corpus composed set well-edited texts newspaper
reports, reviews, legal medical documents4 , ASRS reports mostly written
informal manner, since edited except removing author-identity
information, reports tend contain spelling grammatical mistakes. Second,
employ large amount domain-specific acronyms, abbreviations terminology. Third,
incident described report may caused one shaping factor.
Thus reports multiple shaping factor labels, making task challenging
binary classification, even multi-class problems instance one
label. all, scarcity labeled data task, coupled highly imbalanced
class distributions, makes difficult acquire accurate classifier via supervised learning.
Previous work cause identification ASRS reports done primarily
researchers NASA (see Posse et al., 2005) and, knowledge, involved manual
analysis reports. Specifically, NASA brought together experts aviation safety,
human factors, linguistics English language participate series brainstorming
sessions, generated collection seed keywords, simple expressions template
expressions related shaping factor. labeled reports shaping
factors looking related expressions report narrative. However,
4. Recently, work started processing blogs, may grammatical either, blogs
typically full domain-specific terminology.

571

fiAbedin, Ng & Khan

major weakness associated approach: involves large amount human effort
identifying relevant keywords expressions, yet resulting list keywords
expressions means exhaustive. Moreover, evaluated approach
20 manually labeled reports. small-scale evaluation means satisfactory
judged current standard NLP research. One contributions research
annotation 1333 ASRS reports shaping factors, serve standard
evaluation dataset different cause identification methods compared.
paper, investigate two alternative approaches cause identification,
exploit information provided automatically constructed semantic lexicon.
specifically, view large amount human involvement NASAs work,
aim replace manual selection seed words bootstrapping approach
automatically constructs semantic lexicon. Specifically, motivated Thelen Riloffs
(2002) Basilisk framework, learn semantic lexicon, consists set words
phrases semantically related shaping factors, follows. Starting small
set seed words phrases, augment seeds iteration automatically
finding fixed number words phrases related seeds corpus adding
seed list. importantly, however, propose four modifications
Basilisk framework potentially improve quality generated lexicon.
first linguistic modification: addition using parse-based features (e.g., subjectverb verb-object features) Basilisk, employ features computed
robustly (e.g., N-grams). remaining three algorithmic modifications
Basilisk framework, involving (1) use probabilistic semantic similarity measure, (2)
use common word pool, (3) enforcement minimum support maximum
generality constraints words extraction patterns, favors addition
frequently-occurring content-bearing words disfavors overly-general extraction patterns.
mentioned above, investigate two approaches cause identification exploit
automatically learned semantic lexicon. first approach heuristic approach,
which, motivated Posse et al. (2005), labels report shaping factor contains
least word phrase relevant shaping factor. Unlike Posse et al.s
work, relevant words phrases employed heuristic procedure
manually identified, automatically acquire words phrases via semisupervised semantic lexicon learning procedure described above. second approach
machine-learning approach somewhat orthogonal NASAs approach: instead
human identify seed words phrases relevant shaping factor,
humans annotate small subset available incident reports shaping
factors, apply machine learning algorithm train classifier automatically
label unseen report, using combinations N-gram features words phrases
automatically acquired aforementioned semantic lexicon learning procedure.
see, acquire cause identifier using Support Vector Machines (SVMs),
shown effective topic-based text classification. Since small
number labeled reports, also attempt combine labeled unlabeled reports using
transductive version SVMs.
Since approaches rely simple linguistic knowledge sources involve N-grams
words phrases automatically acquired semantic lexicon learning procedure, one may argue use simple features sufficient cause
572

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

identification. important point means arguing
features sufficient cause identification. However, use simple features
relevant task motivated work performed NASA researchers,
who, mentioned above, manually identified seed words phrases shaping
factor (Posse et al., 2005). semantic lexicon learning procedure precisely aims learn
words phrases. error analysis reveals simple linguistic features
sufficient learning cause identification (and sophisticated knowledge
sources needed improve performance), one first attempts tackle cause
identification task, believe use simple features good starting point
establishes baseline future studies domain-specific problem
compared.
evaluate aforementioned two approaches manually annotated ASRS reports. experiments show number interesting results. First, best performance
achieved using heuristic approach, label report basis presence
automatically acquired lexicon words phrases report, achieving F-measure
50.21%. importantly, method significantly surpasses performance
baseline system, labels report basis presence small set manually
identified seed words phrases. results suggest employing automatically
acquired semantic lexicon relevant useful cause-based text classification
ASRS reports. Second, words phrases learned semantic lexicon, used
features training SVMs classification approach, improve performance
SVM classifier trained solely N-gram based features amount
training data small. However, increase amount training data (by crossvalidation), using lexicon words phrases features addition unigrams
bigrams helps improve classifier performance statistically significantly. particular,
observed F-measure 53.66% SVM classifiers using combination
unigrams, bigrams lexicon words phrases features. results confirm
words phrases learned semantic lexicon relevant valuable
features identifying responsible shaping factors. Nevertheless, magnitude
improvement indicates still much room improvement, may
achieved using deeper semantic features.
summary, believe work automated cause identification makes five
primary contributions:
show instead manually analyzing incident reports identify
relevant shaping factors, possible reduce amount human effort required
task manually analyzing small subset reports identifying
shaping factors rest reports using automated methods.
propose several modifications Thelen Riloffs (2002) semi-supervised lexicon learning framework, show Modified Basilisk framework allows us
acquire semantic lexicon yields significantly better performance cause
identification original Basilisk framework. Equally importantly, none
modifications geared towards cause identification task, hence
applicable generally semantic lexicon learning task. fact, addi573

fiAbedin, Ng & Khan

tional experiments suggest Modified Basilisk yields better accuracy Original
Basilisk bootstrapping general semantic categories.
show semantic lexicon learning useful cause identification ASRS
reports. particular, words phrases learned semantic lexicon
profitably used improve heuristic-based approach learning-based
approach (when given sufficient training data) cause identification. addition,
believe similar cause identification task causes described
text, may useful learn semantic lexicon containing key words
phrases related different types possible causes use key words
phrases features machine learning.
attempt deduce weaknesses approaches help direct future
research, performed analysis errors made best-performing
system, namely heuristic approach using semantic lexicon learned
modified Basilisk method randomly chosen subset test reports.
manually annotated subset reports relevant shaping factors.
set annotated reports, made publicly available, serve
standard evaluation set task future research also comparing
approaches cause identification.
rest paper organized follows. Section 2, discuss dataset,
shaping factors, reports preprocessed annotated. Section 3 defines
baseline, simply looks small set manually extracted seed words
phrases report narratives. Section 4, describe semantic lexicon learning
procedure, based Basilisk lexicon learning procedure (Thelen & Riloff,
2002) augmented modifications. Section 5, discuss heuristic-based
learning-based approaches cause identification. evaluate two approaches
Section 6 discuss related work Section 7. Finally, Section 8, summarize
conclusions discuss future work.

2. Dataset
dataset used research aviation safety incident reports publicly available
website Aviation Safety Reporting System5 . used 140,599 reports collected period January 1998 December 2007. report contains
free text narrative written reporter several fixed fields incident like
time place incident, environment information, details aircrafts
involved, reporting persons credentials, details like anomaly, detector, resolution
consequence incident itself, description situation. words,
fixed fields report contain various information happened,
physical circumstances, cover incident took place. discussed
Posse et al. (2005) Ferryman, Posse, Rosenthal, Srivastava, Statler (2006),
narrative report contains information shaping factors incident.
5. Available http://asrs.arc.nasa.gov/search/database.html

574

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

reason, decided analyze free-text narrative report using NLP techniques identify shaping factor(s) incident may be, constructed
corpus task combining narratives 140,599 reports.
2.1 Shaping Factors
incidents described ASRS reports happen variety reasons. Posse et al.
(2005) focus 14 shaping factors, simply shapers. Following short description
shaping factors, taken verbatim work Posse et al..
1. Attitude: indication unprofessional antagonistic attitude controller
flight crew member.
2. Communication Environment: Interferences communications cockpit
noise, auditory interference, radio frequency congestion, language barrier.
3. Duty Cycle: strong indication unusual working period e.g., long day, flying
late night, exceeding duty time regulations, short inadequate rest
periods.
4. Familiarity: indication lack factual knowledge, new unfamiliar company, airport, aircraft.
5. Illusion: Illusions include bright lights cause something blend in, black hole,
white out, sloping terrain.
6. Physical Environment: Unusual physical conditions could impair flying
make things difficult, unusually hot cold temperatures inside cockpit,
cluttered workspace, visual interference, bad weather, turbulence.
7. Physical Factors: Pilot ailment could impair flying make things difficult, tired, fatigued, drugged, incapacitated, influenced alcohol,
suffering vertigo, illness, dizziness, hypoxia, nausea, loss sight, loss hearing.
8. Preoccupation: preoccupation, distraction, division attention creates
deficit performance, preoccupied, busy (doing something else),
distracted.
9. Pressure: Psychological pressure, feeling intimidated, pressured, pressed
time, low fuel.
10. Proficiency: general deficit capabilities, inexperience, lack training,
qualified, current, lack proficiency.
11. Resource Deficiency: Absence, insufficient number, poor quality resource,
overworked unavailable controller, insufficient out-of-date chart, equipment malfunction, inoperative, deferred, missing equipment.
575

fiAbedin, Ng & Khan

12. Taskload: Indicators heavy workload many tasks once, shorthanded crew.
13. Unexpected: Something sudden surprising expected.
14. Other: Anything else could shaper, shift change, passenger discomfort, disorientation.
2.2 Preprocessing
semantic lexicon learning approach cause identification, need identify
(1) part-of-speech (POS) word text, (2) phrases chunks
sentences, (3) grammatical roles words governing words. Ideally,
achieve high accuracies three tagging tasks, would manually annotate section
ASRS corpus appropriate annotations (e.g., POS tags, chunks) train
appropriate taggers tag rest corpus. However, laborintensive task, beyond scope paper. Therefore, used publicly
available tools trained standard corpora three tasks. inevitable
produce accurate automatic annotations corpus, see,
caused problem task.
corpus, first identify sentence boundaries using tool MXTERMINATOR6 . Second, run POS tagger CRFTagger (Phan, 2006b), uses Penn
Treebank tag set (Marcus, Santorini, & Marcinkiewicz, 1993), sentences detected
MXTERMINATOR. Third, run chunker CRFChunker (Phan, 2006a) tagged
text identify different types phrases. Also, Minipar parser (Lin, 1998) run
sentences identify grammatical roles words. However, report text
preprocessed applying tools reasons described following paragraphs.
reports ASRS data set usually informally written, using various domain
specific abbreviations acronyms. general, observed van Delden Gomez
(2004), Posse et al. (2005) Ferryman et al. (2006), narratives tend written
short, abbreviated manner, tend contain poor grammar. Also, text
converted upper-case. Following example narrative report:
TAXIING RAMP LAF NIGHT. MADE WRONG TURN
CROSSED RWY 10/28; ACTIVE TIME.
SIGN INDICATE RWY XING. CLRED DIRECTIONS XING. ACFT FIELD
TIME. MENTION ATIS SIGNS
CONSTRUCTION RAMP AREA. CTLR DIDNT QUESTION
US; BROUGHT SIT CROSSED
ACTIVE RWY. COMMUTER OPS 3 DAYS HVY FLYING;
REDUCED REST; RWY SIGNS BUSY LAST MIN COMMUTER PAPER WORK CHANGES; CONTRIBUTED RWY
INCURSION. 12 HR DAY 6 HR FLT TIME.
6. ftp://ftp.cis.upenn.edu/pub/adwait/jmx/, trained Wall Street Journal corpus

576

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

reports need preprocessing NLP techniques applied them,
since off-the-shelf tools (e.g., POS tagger) trained mixed-case texts.
example, running CRFTagger (which trained WSJ corpus correct cases)
first two sentences yield following:
1. TAXIING/NNP FROM/NNP THE/DT RAMP/NNP AT/IN LAF/NNP AT/IN
NIGHT/NN ./.
2. MADE/NNP A/DT WRONG/NNP TURN/NNP AND/CC CROSSED/VBD
RWY/NNP 10/28/CD ;/: THE/DT ACTIVE/NNP AT/IN THE/DT TIME/NN ./.
seen, tagger mislabels words TAXIING, FROM, MADE, WRONG
ACTIVE proper nouns (NNP), instead tagging verb, preposition, verb,
adjective adjective respectively. occurs good feature detecting proper
nouns sentence case first character. Since words begin capital
letter, tagger mistakes significant portion words NNP. Another reason
tagger performs poorly corpus lot abbreviations appear text.
example, XING HVY short crossing heavy. since
likely known POS tagger trained standard well-edited corpus, would
identified unknown words, likely tagged nouns instead verb
adjective respectively. Similar problems observed parsers chunkers.
reason, decided preprocess text expanding abbreviations
restoring cases words.
expand acronyms abbreviations, rely official list acronyms
abbreviations used ASRS reports7 . small number cases, abbreviation
acronym may one expansion. example, ARR may mean either arrival
arrive. cases arbitrarily chose one possibilities8 . Then, restore case,
set English word lists, place names person names9 applied text
identify known words. word report text appeared word lists,
converted lower case. unknown words left uppercase. result
process aforementioned narrative follows:
TAXIING ramp LAF night. made wrong turn crossed
runway 10/28; active time. sign indicate
runway crossing. cleared directions crossing.
aircraft field time. mention Automatic Terminal
Information Service signs construction ramp area.
controller DIDNt question us; brought situation
crossed active runway. commuter operations 3 days heavy flying;
7. See http://akama.arc.nasa.gov/ASRSDBOnline/pdf/ASRS_Decode.pdf.
8. better option would disambiguate alternative expansions based context (e.g.,
method followed Banko & Brill, 2001). However, number ambiguities acronyms
abbreviations list small (10, exact), either POS variations
word. Thus effect ambiguities performance NLP tools expected
minimal.
9. http://wordlist.sourceforge.net/

577

fiAbedin, Ng & Khan

reduced rest; runway signs busy last minute commuter paper work
changes; contributed runway incursion. 12 hour day 6 hour flight time.
ran POS tagger, CRFTagger, processed text observe
errors. example, tagged version aforementioned two sentences are:
1. TAXIING/VBG from/IN the/DT ramp/NN at/IN LAF/NNP at/IN night/NN ./.
2. made/VBN a/DT wrong/JJ turn/NN and/CC crossed/VBD runway/NN 10/28/CD
;/: the/DT active/JJ at/IN the/DT time/NN ./.
sentences correctly tagged. However, case restoration method
arguably simplistic. Hence, determine need perform fine-grained case
restoration, sought measure much would gain accurately restoring
case words sentences present heuristic method. check this,
randomly picked 100 sentences corpus. first ran POS tagger
sentences case-restored aforementioned heuristic case restoration
method. Then, manually corrected capitalization sentences re-ran
POS tagger case-restored sentences. tags thus generated compared,
found 99.7% agreement, means likely gain much terms
POS tagging accuracy correctly case restored text heuristically case restored
text. five differences 2049 words, three NNPs mislabeled NNs,
essentially effect outcomes research. Therefore, marginal utility
applying sophisticated case restoration methods seem enough justify
additional effort necessary, limit preprocessing step expansion abbreviations acronyms followed heuristic case restoration procedure described above.
complete flow preprocessing shown Figure 1.
2.3 Human Annotation Procedure
Recall need reports labeled shaping factors training cause identification classifiers testing performance two approaches cause identification.
Additionally, order learn semantic lexicon via bootstrapping, need small set
seed words phrases related shaping factor starting point. result,
performing language normalization, performed two types annotations: (1) labeling
set reports shaping factors, (2) identifying set seed words phrases
reports. annotation procedure described detail following sections.
2.3.1 Annotating Reports Shaping Factors
NASA previously developed heuristic approach tackle cause identification
task (Posse et al., 2005), approach evaluated 20 manually annotated reports,
far satisfactory far establishing strong baseline method concerned.
Thus decided annotate set reports evaluating automatic cause
identification methods.
complete set 140,599 reports, chose random set 1333 reports
annotation. subset divided two parts. first part, consisting 233 reports,
578

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Figure 1: Flow chart text preprocessing
annotated two persons (one undergraduate student one graduate student).
report, asked answer following question:
shaping factor(s) responsible incident described report?
annotators trained similar way labeled 20 reports used
evaluation NASA researchers (see Posse et al., 2005). Specifically, background
reading, annotators referred works Posse et al. Ferryman et al. (2006),
describe shaping factors, also give examples words
phrases indicate influence shaping factors described incidents.
definitions shapers repeated Section 2.1. Following Posse et al.s method,
annotators explicitly instructed adhere definitions much possible
annotating reports shaping factors. annotations completed,
inter-annotator agreement computed using Krippendorffs (2004) statistics
described Artstein Poesio (2008), using Measuring Agreement Set-valued
Items (MASI) scoring metric (Passonneau, 2004). observed inter-annotator agreement,
, case found 0.72, indicates reliable agreement. 233
reports, completely agreed annotations 80 reports, completely disagreed
100 reports partially agreed 53 reports. annotators asked discuss
discrepancies. discussion, found discrepancies could
579

fiAbedin, Ng & Khan

primarily attributed vagueness descriptions shaping factors Posse et
al.s paper, interpreted differently two annotators.
annotators agreed descriptions shapers interpreted,
resolved differences annotation. discussion, remaining 1100
reports annotated one annotators. annotator also asked
annotate subset reports (100 reports) cross-verification purpose10 ,
inter-annotator agreement, , case observed 0.66. 1333 reports
annotated first annotator divided three sets: training set (233 reports)
training cause identification classifiers, held-out development set (100 reports)
parameter tuning, test set (1000 reports) evaluating performance
approaches cause identification. distribution shaping factors training,
development test sets shown second, third fourth columns Table 1.
2.3.2 Extracting Seed Words Phrases
separate process, first author went first 233 reports annotators
worked on, selected words phrases relevant shaping factors.
judgment whether word phrase relevant shaping factor based careful
reading description shaping factors works Posse et al. (2005)
Ferryman et al. (2006), well example seed words selected NASA experts
shown two papers. specific task case was:
report, word phrase indicative
shaping factors? is, identify assign appropriate
shaping factor.
Note seed words phrases chosen without regard shaping factor
annotation document; picked possibility relevant
respective shaping factors. number seed words phrases shaping
factor shown last column Table 1. see, 177 seed words phrases
manually selected 233 training reports. completeness, also show
seed words phrases extracted reports Appendix A. facilitate
research topic, annotated data used research made available
http://www.utdallas.edu/~maa056000/asrs.html.
Since gold standard compare list annotated
words phrases, difficult directly compute precision. However, get rough
idea precision, asked one annotators examine list identify
words phrases list believes correct. disagreement
one word. yields precision 99.44%, provides suggestive evidence
annotation fairly reliable. manually identified words phrases
used baseline cause identification system (see Section 3) also served seeds
semantic lexicon learning procedure (see Section 4).
10. fairly standard procedure NLP research cross-annotate subset data
complexity cost individual annotation high. See works Zaidan, Eisner, Piatko (2007)
Kersey, Di Eugenio, Jordan, Katz (2009), instance.

580

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Table 1: Distribution shaping factors training, test development sets
Shaping factor
Reports Reports
Reports
Seed
training set
test set development words
test set
Attitude
17
30
5
8
Communication Environment
11
90
18
5
Duty Cycle
9
26
3
10
Familiarity
12
50
8
9
Illusion
1
2
0
1

36
217
36
8
Physical Environment
43
265
40
45
Physical Factors
10
35
3
8
Preoccupation
25
110
10
9
Pressure
5
30
3
10
Proficiency
43
247
23
12
Resource Deficiency
112
507
33
47
Taskload
6
29
7
2
Unexpected
3
10
1
3
Total
233
1000
100
177

3. Baseline System Cause Identification
discussed introduction, goal research label incident reports
shaping factors caused incidents. evaluate performance cause
identification methods, need baseline uses amount training data
methods described paper performs reasonably well test set.
Given cause identification relatively new under-investigated task, standard
baseline adopted task. fact, knowledge, related works
cause identification aviation safety domain conducted researchers
NASA (see Posse et al., 2005; Ferryman et al., 2006). result, construct baseline
system motivated Posse et al.s work. Specifically, baseline takes input set
seed words phrases manually collected shaping factors (see Section 2.3.2),
labels report Occurrence Heuristic: seed word phrase found
report, baseline annotates report shaping factor associated
seed. example, 11 hour duty day seed phrase associated shaping
factor Duty Cycle. Then, Occurrence Heuristic label report contains
phrase 11 hour duty daywith Duty Cycle. approach simple attractive
(1) need training, (2) evaluated easily, searching
seed words narrative report labeled, (3) report potentially
labeled one shaping factors. seed words phrases indeed
relevant respective shaping factors, identify reports related
shaping factors high degree precision.
581

fiAbedin, Ng & Khan

4. Semantic Lexicon Learning
described Section 3, baseline uses seed words phrases manually extracted
233 reports combination Occurrence Heuristic label reports
shaping factors. However, reports used evaluation may contain exactly
words phrases, may contain different variations, synonyms, words
phrases semantically similar seed words phrases. Thus baseline
may able label reports correctly looking words phrases
seed words list.
address potential problem, propose use semantic lexicon learning algorithms learn words phrases semantically similar seed words phrases
reports corpus containing narratives 140,599 reports. Using weakly supervised bootstrapping algorithm may allow us learn large number useful words
phrases corpus would required huge amounts human effort
done manually. Below, first describe general bootstrapping approach Section 4.1.
Then, Section 4.2, describe Basilisk framework learning semantic lexicon
unannotated corpus (Thelen & Riloff, 2002). Finally, Section 4.3, discuss
modifications Basilisk framework.
4.1 Weakly Supervised Lexicon Learning
mentioned earlier, employ weakly supervised bootstrapping approach building
semantic lexicon. use manually extracted seed words phrases
shaping factor (described Section 2.3.2) create initial semantic lexicon.
select words phrases unannotated reports semantically similar
words already appearing semantic lexicon. reports corpus need
labeled shaping factors. semantic similarity two words measured
using features extracted corpus word. process repeated iteratively:
iteration, certain number words added semantic lexicon,
words augmented lexicon used seeds following iteration.
process shown Figure 2.

Figure 2: Flow chart lexicon learning procedure

582

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

4.2 Basilisk Framework
Basilisk (Bootstrapping Approach SemantIc Lexicon Induction using Semantic Knowledge)
instantiation aforementioned generic semantic lexicon learning framework (Thelen & Riloff, 2002). Basilisk framework works first identifying patterns
extracting noun phrases corpus appear one three syntactic roles:
subject, direct object, prepositional phrase object. example, discussed Thelen Riloff, sentence John arrested collaborated Smith
murdered Brown, extraction patterns <subject> arrested, extracts
John, murdered <object> extracts Brown collaborated <pp object>
extracts Smith. Then, semantic category Sk , pattern pool constructed
patterns tend extract words Sk . measure tendency pattern Pj
extract words Sk , R log F metric used, defined as:
R log F (Pj ) =

Fj
log (Fj )
Nj

(1)

Here, Fj number (distinct) words Sk pattern Pj extracts, Nj
total number (distinct) words corpus Pj extracts. metric high
high precision patterns (i.e., patterns extract primarily words Sk ) high recall
patterns (i.e., patterns extract large number words Sk ). iteration i,
top (20 + i) patterns (in terms R log F scores) put pattern pool Sk .
Depleted patterns (i.e., patterns extracted words already semantic
lexicon) considered step. Then, head nouns phrases extracted
resulting patterns pattern pool put word pool Sk .
Next, subset words word pool selected added seed words
list. words word pool chosen relevant Sk .
specifically, word Wi word pool Sk , first AvgLog score calculated,
defined follows:

AvgLog (Wi , Sk ) =

W
Pi
X

log2 (Fj + 1)

j=1

W Pi

(2)

Here, W Pi number patterns extract word Wi , pattern Pj
extracts Wi , Fj number words extracted Pj belong Sk . Then,
semantic category Sk , five words chosen highest AvgLog score
category Sk .
multi-category learning, Thelen Riloff (2002) experimented different scoring metrics reported achieved best performance calculating diff
score word. given word word pool semantic category, diff
score takes consideration score word gets categories, returns
score based words score semantic category relative categories.
precisely, diff score defined follows:
dif f (Wi , Sk ) = AvgLog (Wi , Sk ) max (AvgLog (Wi , Sl ))
l6=k

583

(3)

fiAbedin, Ng & Khan

Here, Sk semantic category Wi evaluated. Thus diff score
high strong evidence Wi belongs semantic category Sk little evidence
belongs semantic categories. semantic category, diff score
calculated word categorys word pool, top five words
highest diff score added lexicon category. Two additional checks
made stage: (1) word word pool added category
earlier iteration, word discarded, (2) word found
one word pool added category highest score11 .
completed semantic categories, iteration ends, next iteration
begins augmented lexicon.
4.3 Modifications Basilisk Framework
see later subsection, analysis framework reveals
cases words selected Basilisk may relevant ones. reason,
propose three algorithmic modifications Basilisk framework: (1) using new semantic
similarity measure, (2) merging word pools one single pool assigning words
semantic categories, (3) imposing minimum support maximum generality criteria
patterns words added pattern pools word pools. addition, propose
one linguistic modification, employ type feature computed
robust manner words phrases corpus, namely, N-gram features.
rest subsection discusses modifications.
4.3.1 Modification 1: New Semantic Similarity Measure
seen Section 4.2, Basilisk framework uses AvgLog scoring function measure
semantic similarity words. diff score multi-category learning also uses
AvgLog function compute evidence word belonging semantic category
relative categories. However, closer examination AvgLog function shows
may able properly predict semantic similarity circumstances.
understand reason, let us first make following observations: pattern Pj occurs
1000 times, extracts words category Sk 5 times, unlikely Pj strongly
related Sk . Similarly, word Wi occurs 1000 times, extracted pattern Pj 5
times, Pj small influence classification Wi . However, AvgLog score
able take factors consideration, precisely considers
absolute number semantic category members extracted patterns extract
word frequency extraction. see case, let us consider
word Wi extracted three patterns P1 , P2 P3 , frequencies shown
Table 2. P1 , P2 P3 extract five distinct seed words, AvgLog score
word W would 2.32, irrespective fact patterns actually extract word
seed words list tiny fraction occurrence corpus. P1 extracts
seed word 5% occurrence, P2 1% time, P3 , pattern extracts W
often, extracts lexicon word 0.5% times appears text. Clearly,
11. approach effectively assumes word belong one category. reasonable
assumption specific task since shaping factors distinct meanings.

584

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

patterns would suggest Wi related semantic category, yet gets
good score.
Table 2: Illustration problem AvgLog: unrelated words may high
similarity score. Wi word appears corpus extracted
patterns P1 , P2 P3

Patterns extract Wi
Number times Wi extracted pattern Pj
Number times pattern Pj occurs text
Number times word category Sk extracted pattern Pj
Number category words extracted pattern Pj
log2 (Fj + 1)
AvgLog (Wi )

P1
10
100
5
5
2.32

P2
P3
20
70
500 1000
5
5
5
5
2.32 2.32
2.32

Keeping mind, propose probabilistic metric, SemProb, computes
probability word Wi belongs semantic category Sk given extracted
patterns P1 , P2 , . . . , Pn . specifically, SemProb calculated follows:
SemP rob (Wi , Sk ) = P rob (Sk |Wi )
X
=
P rob (Sk |Pj ) P rob (Pj |Wi )

(4)

Pj

words, SemProb assumes semantic category Sk word Wi
conditionally independent given Pj , pattern extracts Wi . probabilities
equation estimated using maximum likelihood estimation corpus. Specifically,
compute P rob (Pj |Wi ), divide number times Pj extracts Wi corpus
total number times Wi appears corpus. compute P rob (Sk |Pj ), divide
number times Pj extracts word semantic category Sk total number
times Pj appears corpus. given word Wi given semantic category
Sk , sum products two quantities patterns extract Wi
gives probability category Sk given word Wi . method suffer
problem faced AvgLog since depends probability word extracted
patterns patterns probability extracting words category.
example Table 2, SemProb metric word Wi 0.0105, illustrating
low probability Wi belonging semantic category Sk is. details given
Table 3.
4.3.2 Modification 2: Common Word Pool
Since compute Eqn (4) every word word pool categories
assign word semantic category probability highest, change
framework one common word pool semantic categories.
585

fiAbedin, Ng & Khan

Table 3: Illustration effectiveness SemProb: unrelated words get low similarity
score.

Patterns extract Wi
Number times Wi extracted pattern Pj
Number times pattern Pj occurs text
Number times word category Sk extracted pattern Pj
P rob (Wi extracted Pj )
P rob (Pj extracts word Sk )
P rob (Wi extracted Pj ) P rob (Pj extracts word Sk )
SemP rob (Wi , Sk ) = P rob (Wi belongs semantic category Sk )

P1
10
100
5
0.1
0.05
0.005

P2
P3
20
70
500
1000
5
5
0.2
0.7
0.01
0.005
0.002 0.0035
0.0105

still separate pattern pools different semantic categories, words related
patterns pattern pools put common word pool, allocated
probable semantic category there. separate word pools
semantic category, add fixed number words category
iterations. constraint may undesirably cause word added category
likely. However, since one word pool modification,
constraint add fixed number words category,
assign word likely category. Thus number words added
different categories may vary iteration.
4.3.3 Modification 3: Minimum Support Maximum Generality
scenarios SemProb metric produce undesirable results.
example, consider infrequent word Wi occurs entire corpus exactly once.
Assume pattern Pj , extracts Wi , extracts words semantic category Sk
70% probability. So, according SemProb, probability Wi belongs Sk becomes
70%. However, sufficient evidence Wi belongs Sk . cases
uncommon, imposed minimum word frequency constraint words
put word pool, words appear less certain number times
considered. pattern appears infrequently corpus also lead
problem. Consider infrequent pattern, Pj , appears exactly twice corpus
extracts two words. one words happen seed word,
word 50% probability belong category seed word Pj
R log F value 0.5. However, since Pj infrequent, convey good evidence
membership semantic category, allow Pj put words
word pool. Therefore, disallow low frequency patterns included
pattern pool adding constraint patterns put pattern pool must also
minimum pattern frequency. Besides two constraints imposed frequency
occurrence words patterns, employ two additional constraints. first
586

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

maximum pattern generality constraint: motivated Rychly Kilgarriff (2007),
remove consideration patterns general (i.e., patterns extract
many words), imposing upper limit number distinct words pattern
added pattern pool extract. second maximum word frequency
constraint: since content-bearing words likely lower frequency (see Davidov
& Rappoport, 2006), impose upper limit maximum number times word
appears corpus. four thresholds associated four frequency-based
constraints tuned automatically using held-out development set.
4.3.4 Modification 4: N-gram Patterns
addition parse-tree-based subject-verb verb-object patterns already employed
Basilisk, also employ N-gram-based extraction patterns, goal robustly capturing context words appear. construct N-gram extraction
patterns follows. noun adjective, X, corpus, create two N-gram
patterns extracting X: (a) preceding N words + hXi, (b) hXi + succeeding
N words. example, sentence ... solid line thunderstorms detected ...,
bigram patterns thunderstorms would be: line hXi hXi detected.
complete sentence approaching ATL area solid line thunderstorms
detected vicinity airport, words extracting bigram patterns
would be:
ATL: approaching hXi, hXi area
area: ATL hXi, hXi solid
solid: area hXi, hXi line
line: solid hXi, hXi thunderstorms
thunderstorms: line hXi, hXi detected
vicinity: hXi, hXi
airport: hXi
addition constructing N-gram patterns extracting words, also construct
N-gram patterns extracting phrases. so, first remove articles (a, an, the)
possessive pronouns adjectives (e.g., my, his) beginning phrases
corpus. noun phrase adjective phrase, X, appears corpus,
create two N-gram patterns extracting X: (a) preceding N words + hXi, (b)
hXi + succeeding N words. example, sentence last 5 legs
approaching end 8 hour duty day 7 hour hard time flying day, would
extract following phrases following bigram patterns:
5 legs: last hXi, hXi approaching
end: approaching hXi, hXi
587

fiAbedin, Ng & Khan

8 hour duty day: end hXi, hXi 7
7 hour hard time flying day: day hXi
Thus use three types patterns experiments: bigram patterns extracting
words, bigram patterns extracting phrases, parse-tree-based subject-verb verbobject patterns. patterns generated reports corpus generated
combining narratives 140,599 unlabeled reports described Section 2.2.
see, three types patterns beneficial use far performance
concerned. Section 6, show automatically select best subset
patterns use based development set.

5. Semantic Lexicon-Based Approaches Cause Identification
ASRS Reports
investigate heuristic-based approach learning-based approach cause identification, exploit information provided automatically acquired semantic
lexicon. section describes details two approaches.
5.1 Heuristic-Based Approach
heuristic-based approach operates essentially way baseline cause
identification system described Section 3, Occurrence Heuristic used label
report shaping factors. difference words phrases used
Occurrence Heuristic baseline manually identified, whereas
heuristic-based approach acquired Modified Basilisk procedure.
5.2 Learning-Based Approach
learning-based approach cause identification problem recast classification task. Note multi-class multi-labeled classification task: 14
classes report labeled one class. number approaches
proposed tackle multi-class multi-labeled classification tasks. rest
section, describe three existing approaches multi-class multi-labeled text classification explore experiments (Section 5.2.1), provide overview
theory Support Vector Machines (SVMs), underlying learning algorithm use
train classifiers employed three approaches (Section 5.2.2).
5.2.1 Three Approaches Multi-Class Multi-Labeled Text Classification
One-Versus-All. approach, train one binary classifier shaping factor
Sk determine whether report labeled Sk . specifically, follow
One-Versus-All classification scheme: given Sk , reports training set
contains Sk set labels (assigned annotator) positive instances
binary classifier rest reports training set negative instances.
training, apply classifiers report test set independently
reports, label report Sk corresponding classifier classifies
588

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

report positive. Thus convert cause identification multi-class multi-labeled
document classification task.
learning algorithm used principle train classifiers OneVersus-All scheme, use Support Vector Machines12 training testing classifiers,
primarily due successes various text classification tasks. classifier trained
two types features: (1) unigrams bigrams report narratives, (2)
words phrases semantic lexicon. feature values TF*IDF values.
shaping factor-labeled data set 1333 reports substantially larger
set 20 reports annotated NASA researchers (see Section 1), arguably fairly
small machine learning perspective. Hence, conceivable performance
SVM classifiers would limited small size training data. result,
investigate whether improve One-Versus-All approach using transductive
SVM, version inductive SVM described attempts improve
classifier performance combining labeled unlabeled data (see Section 5.2.2
overview transductive learning). cause identification task, unlabeled
reports test set serve unlabeled data transductive learning procedure.
MetaLabeler. second approach, employ MetaLabeler (Tang, Rajan, & Narayanan,
2009) classifying multi-class multi-labeled text data. Here, model first learned
predicts number labels instance may have. addition, set binary classifier models, one possible label, learned predict likelihood label
instance. instance classified, first model predicts K, number
possible labels instance, output second set classifiers, K
labels chosen highest likelihood instance.
implementation approach, first model learned using SVMmulticlass ,
implementation multi-class SVM described Crammer Singer (2002)13 .
second set classifiers set described Section 5.2.2. case,
given instance x, decision functions f (x) = w x b classifiers
evaluated, positive decision values sorted. top K labels corresponding
highest values decision functions assigned instance.
multiclass classifier set binary classifiers trained using types
features One-Versus-All approach, namely unigrams bigrams reports,
words phrases semantic lexicon. feature values also
One-Versus-All approach, namely TF*IDF values.
Ensembles Pruned Sets. Pruned Sets approach (Read, Pfahringer, & Holmes,
2008), multi-class multi-label text classification problem transformed multiclass single-label text classification problem selecting subset label combinations
frequently occurring dataset assigning unique pseudo-label chosen
label combination.
first step algorithm choose label sets training. step,
label sets chosen meet minimum frequency requirement training
set. Using minimum frequency constraint prunes away infrequently occurring label sets
frequency less p, leaving label combinations frequent thus
12. implemented SVMlight software package Joachims (1999)
13. Available http://svmlight.joachims.org/svm_multiclass.html

589

fiAbedin, Ng & Khan

important. training instances labeled pruned label sets
also removed training set. minimum cardinality parameter, b, used
reintroduce pruned instances back training set order minimize
information loss pruning process. First label sets rejected instances
broken smaller subsets least size b. new subsets
frequency higher p reintroduced, pruned training instances whose label
sets supersets newly accepted label sets reinstated training set.
role parameter b case ensure many instances small
label sets put back, cause average number labels reduce,
resulting smaller number labels per instance classification time.
next step learn classifiers selected label sets. First, accepted label
set assigned unique pseudo-label, thus transforming multi-label classification problem single-label classification problem. ensemble classifiers learned
predict pseudo-labels given instance (using multi-class SVM implementation MetaLabeler), classifier ensemble trained different
random sample training data. Since (1) label sets training classifiers
represent subset label combinations present original training data
(2) test data may contain label combinations present training
data, ensemble classifiers allows system generate label combinations
observed training time. example, let label combinations {l1 , l3 } {l2 , l3 }
present training data. Then, one classifier ensemble labels test instance
{l1 , l3 } another classifier ensemble labels instance {l2 , l3 },
instance may labeled {l1 , l2 , l3 } (depending actual voting policy
effect classification time) even combination present training data.
classifiers ensemble built using two types features One-VersusAll approach, namely unigrams bigrams reports words phrases
semantic lexicon learned modified Basilisk framework.
Finally, classifying instance, classifiers assigns one pseudo-label
instance. pseudo-labels mapped back original label combination
vote actual label counted normalized dividing number
classifiers, , order bring prediction possible label range
0.0 1.0. threshold used label prediction value
greater equal assigned instance. scheme used make possible
assign label combinations unseen training time test instances.
5.2.2 Overview Support Vector Machines
SVMs shown effective text classification (Joachims, 1999).
describe two versions SVMs: (1) inductive SVMs, learn classifier solely
labeled data, (2) transductive SVMs, learn classifier labeled
unlabeled data.
Inductive SVMs. Given training set consisting data points belonging two classes,
inductive SVM aims find separating hyperplane maximizes distance
separating hyperplane nearest data points. nearest data points act
support vectors plane.
590

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

formally, let data set data points
= {(xi , ci ) |xi Rn , ci {1, 1} , 1 m}

(5)

point xi represented n-dimensional vector associated class label
ci . inductive SVM classifier attempts find hyperplane w x b = 0
maximum distance nearest data points opposite labels. hyperplane would
middle two hyperplanes containing support vectors class.
2
. Therefore,
two hyperplanes wxb = 1 wxb = 1, distance |w|
desired separating hyperplane found solving following quadratic programming
optimization problem:
Minimize
subject

1
|w|2
2
ci (w xi b) 1, 1

(6)

However, practice many classes linearly separable. handle cases, set
slack variables used represent misclassification point xi . problem
becomes:
X
1
|w|2 + C

Minimize
2


subject

ci (w xi b) 1 , > 0, 1

(7)

additional variables representing training errors C constant representing trade-off training error margin. details found Cortes
Vapnik (1995). experiments, use radial basis function (RBF)
kernel,



2
every dot product replaced function k (x, x ) = exp |x, x | , > 0.
addition, C chosen cross-validation training set.
Transductive SVMs. transductive setting, addition set labeled data
points, also exploit set unlabeled data points, = {xi |xi Rn , 1 k},
taken test set. described Joachims (1999), goal minimize
expected number classification errors test set. expected error rate
defined Vapnik (1998) follows:
Z
1X
(8)
(hL (xi ) , ci ) dP (x1 , c1 ) . . . dP (xk , ck )
R (L) =
k


L = , hL hypothesis learned L, (a, b) zero = b
one otherwise. labeling ci test data hyperplane maximizes
separations training testing positive negative instances found solving
following quadratic programming optimization problem, modified version
Eqn (7):
X
X
1
j
|w|2 + C
+ C
Minimize
2


subject

j

ci (w xi b) 1 , > 0, 1

cj w xj b 1 j , j > 0, 1 j k
591

(9)

fiAbedin, Ng & Khan

Similar inductive SVM Section 5.2.2, use RBF kernel experiments
involving transductive SVM.

6. Evaluation
goal evaluation study effectiveness two approaches cause identification, namely semantic lexicon learning approach classification approach.
testing performance approaches randomly chosen set reports
manually annotated shaping factors caused incidents described (Section 2.3.1). start describing experimental setup (Section 6.1),
followed baseline results (Section 6.2) performance two approaches
(Sections 6.3 6.4). describe experiment increase amount
training data available classification approach investigate impacts
performance (Section 6.5). that, perform analysis errors bestperforming approach (Section 6.6) conduct additional experiments attempt
gain better insight cause identification task help direct future research
(Section 6.7). Finally, present summary major conclusions draw
experiments (Section 6.8).
6.1 Experimental Setup
described Section 2.3, 140,599 reports entire corpus, manually
annotated 1333 incident reports shaping factors. used first 233
(1) manually extract initial seed words phrases semantic lexicon
learning procedure, (2) train classifiers identifying shaping factors associated
report. remaining reports, used 1000 reports test data 100 reports
development data (for parameter tuning).
6.1.1 Evaluation Metrics
mentioned Section 2.1, 14 shaping factors, report may labeled
one shaping factors. evaluate performance cause
identification approaches based well automatic annotations match human
annotations reports test set. evaluation, use precision, recall
F-measure, computed described Sebastiani (2002). Specifically,
shaping factor Si , = 1, 2, . . . 14, let ni number reports test set
human annotator labeled Si , i.e., number true Si -labeled reports test
set. Further, let pi number reports automatic labeling scheme Ci
labeled Si , let tpi number reports Ci labeled correctly Si .
Then, shaping factor Si , following performance metrics:
Precisioni fraction reports really caused shaping factor Si among
reports labeled Si labeling scheme.
P recisioni =

592

tpi
pi

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Recalli percentage reports really caused shaping factor Si labeled
labeling scheme shaping factor Si .
Recalli =

tpi
ni

Thus obtain measure labeling schemes performance shaping
factors. obtain overall performance labeling scheme, sum counts
(i.e., ni , pi tpi ) shaping factors compute micro-averaged precision,
recall F-measure aggregated counts described Sebastiani repeated
follows:
P
tpi
P recision = Pi
pi
Pi
tpi
Recall = Pi
ni
2 P recision Recall
F -measure =
P recision + Recall
Thus labeling scheme one set overall scores reflecting performance
classes.
6.1.2 Statistical Significance Tests
determine whether labeling scheme better another, apply two statistical
significance tests McNemars test (Everitt, 1977; Dietterich, 1998) stratified approximate randomization test (Noreen, 1989) test whether difference performances really statistically significant. McNemars test compares two labeling schemes
basis errors (i.e., whether labeling schemes making mistakes), stratified approximate randomization test compares labeling schemes
F-measure. tests extensively used machine learning NLP literature. particular, stratified approximate randomization standard significance test
employed organizers Message Understanding Conferences determine
difference F-measure scores achieved two information extraction systems significant (see Chinchor, 1992; Chinchor, Hirschman, & Lewis, 1993). Since ultimately
concerned difference F-measure scores two labeling schemes cause
identification, discussion statistical significance rest section focused solely stratified approximate randomization test. tests, determine
significance level p < 0.05.
6.2 Baseline System
Recall use baseline heuristic method described Section 3,
Occurrence Heuristic used label report using seed words phrases manually
extracted 233 training reports. Results, shown Experiment 1 section
Table 4, reported terms precision (P), recall (R), F-measure (F). last
two columns show whether particular automatic labeling scheme significantly better
593

fiAbedin, Ng & Khan

baseline respect McNemars test (MN) stratified approximate randomization test (AR) [Statistical significance insignificance denoted X
X, respectively]. evaluated 1000 reports test set, baseline achieves
precision 56.48%, recall 40.47% F-measure 47.15%.
Table 4: Report labeling performance different methods.
Approach Feature Set
P
R
F MN
AR
Experiment 1: Baseline
Heuristic Seed words
56.48 40.47 47.15 N/A N/A
Experiment 2: Semantic lexicon approach
Lexicon modified Basilisk
53.15 47.57 50.21
X
X
Heuristic
Lexicon original Basilisk
49.23 42.78 45.78
X
X
Experiment 3: Supervised One-Versus-All classification approach
Unigrams
37.54 64.50 47.46
X
X
Unigrams bigrams
42.19 47.39 44.64
X
X
SVM
Lexicon words
48.72 37.08 42.11
X
X
Unigrams lexicon words
37.05 65.96 47.45
X
X
Unigrams, bigrams, lexicon words 51.19 36.59 42.68
X
X
Experiment 4: Transductive One-Versus-All classification approach
Unigrams
11.84 67.78 20.16
X
X
Unigrams bigrams
50.00 33.86 40.38
X
X
SVM
Lexicon modified Basilisk
42.83 30.64 35.73
X
X
Unigrams lexicon words
51.30 38.29 43.85
X
X
Unigrams, bigrams, lexicon words 55.90 32.77 41.32
X
X
Experiment 5: MetaLabeler approach
Unigrams
58.80 16.63 25.92
X
X
Unigrams bigrams
66.02 20.51 31.30
X
X
SVM
Lexicon words
63.23 17.11 26.93
X
X
Unigrams lexicon words
70.29 20.39 31.61
X
X
Unigrams, bigrams, lexicon words 68.79 24.21 35.82
X
X
Experiment 6: Ensembles pruned sets approach
Unigrams
22.44 63.05 33.09
X
X
Unigrams bigrams
22.22 67.42 33.42
X
X
SVM
Lexicon modified Basilisk
20.72 73.67 32.35
X
X
Unigrams lexicon words
23.72 85.25 37.12
X
X
Unigrams, bigrams, lexicon words 16.93 71.42 27.37
X
X
Experiment 7: Additional training data 5-fold cross-validation
Unigrams
42.21 63.65 50.76
X
X
Unigrams bigrams
43.58 58.31 49.88
X
X
SVM
Lexicon words
56.06 40.41 46.97
X
X
Unigrams lexicon words
54.75 52.43 53.56
X
X
Unigrams, bigrams, lexicon words 54.81 52.55 53.66
X
X

594

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

6.3 Experiments Semantic Lexicon Approach
Recall semantic lexicon learning approach, label report test set using
Occurrence Heuristic combination semantic lexicon learned modified
Basilisk framework described Section 4.3. showing results approach,
first describe tune parameters modified Basilisk framework.
6.3.1 Parameters
modified Basilisk framework five parameters tune. first four thresholds resulting four frequency-based constraints involving minimum support
maximum generality (see Modification 3 Section 4.3.3). specifically, four
threshold parameters (1) minimum frequency word (M inW ), (2) maximum frequency word (M axW ), (3) minimum frequency pattern (M inP ),
(4) maximum number words extracted pattern (M axP ). addition, recall
Section 4.3.4 three types patterns (namely, subject-verb/verb-object patterns, bigram patterns extracting words, bigram patterns extracting phrases).
fifth parameter pattern parameter, determines subset
three types patterns use. goal tune five parameters jointly
development set. words, want find parameter combination yields
best F-measure Occurrence Heuristic used label reports development set. However, maintain computational tractability, need limit number
values parameter take. Specifically, limit five different combinations four threshold parameters (see Table 5), combination,
find subset three types patterns yields best F-measure development set. Hence total number experiments need run 35 (= 7 (the number
(non-empty) subsets three types patterns) 5 (the number combinations
first four parameters)). experiment indicates combination 3 Table 5,
together bigram patterns extracting phrases, yields best F-measure
development set, therefore chosen best parameter combination involving
five parameters.
new words phrases acquired first two iterations modified Basilisk
using parameter combination shown Appendix B. see new
words acquired first two iterations eight 14 categories. reasons
(1) unlike original Basilisk framework, modified Basilisk employs common
word pool, thus longer requiring five words must added category
bootstrapping iteration; (2) application minimum support words led
filtering infrequently-extracted words. two reasons together ensure
modified Basilisk framework focuses learning high-precision words category.
6.3.2 Results
semantic lexicon learned using best parameter combination (based performance development set) used label reports test set. see
row 1 Experiment 2 Table 4, Modified Basilisk approach achieves precision
53.15%, recall 47.57% F-measure 50.21%. comparison baseline,
method lower precision higher recall. increased recall shows
595

fiAbedin, Ng & Khan

Table 5: Combinations four threshold parameters modified Basilisk framework.
Combination
Combination
Combination
Combination
Combination
Combination

1
2
3
4
5

inW
25
25
10
10
10

axW
2500
2500
2500
2500
5000

inP
250
100
250
250
250

axP
100
100
100
250
100

reports covered expanded lexicon. However, learned lexicon also contains
general words resulted drop precision. Overall, higher Fmeasure, statistically significantly better baseline according
significance tests. vindicates premise learning words phrases
relevant shaping factors help us identify shaping factors reports.
6.3.3 Results Using Original Basilisk
better understand whether proposed linguistic algorithmic modifications
Basilisk framework (see Section 4.3) indeed beneficial cause identification
task, repeated experiment described above, except replaced lexicon
generated using modified Basilisk framework one generated using original
Basilisk framework. specifically, implemented original Basilisk framework
described Thelen Riloff (2002), one minor difference: case
bigram patterns extracting phrases, word pools described Section 4.2 populated
entire phrases instead head words. done seed words list
extracted Section 2.3.2 contains words phrases hence would like learn
entire phrases.
parameter tune original Basilisk framework pattern parameter,
which, mentioned above, determines subset three types patterns use.
Therefore, construct seven lexicons (corresponding seven non-empty subsets
three types patterns) using original Basilisk framework, determine
lexicon yields best performance development set. experiment indicates
best development result achieved bigram patterns extracting
phrases used. Applying corresponding semantic lexicon combination
Occurrence Heuristic classify reports test set, observe precision 49.23%,
recall 42.78% F-measure 45.78% (see row 2 Experiment 2 section
Table 4). lower precision higher recall indicates lexicon learned
words general (i.e., words appear many reports little
discriminative power). new words phrases acquired first two iterations
original Basilisk shown Appendix C. seen, original Basilisk framework
adds lot words, many relevant shaping factors
added, semantically similar seed words shaping factor.
596

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Hence, although recall improves small amount, precision drops significantly, leading
precipitation F-measure. results suggest proposed modifications
original Basilisk framework indeed beneficial far cause identification task
concerned.
6.4 Experiments Classification Approach
Recall classification approach cause identification, train SVM classifier
shaping factor Sk determine whether report labeled Sk . desired,
approach allows report test set potentially receive multiple labels, since
resulting 14 SVM classifiers applied independently report. investigate
effect different feature sets performance cause identification, employ five
feature sets experiments: (1) unigrams only; (2) unigrams bigrams; (3) lexicon
words only; (4) unigrams lexicon words; (5) unigrams, bigrams lexicon words.
unigrams bigrams generated reports training set first
removing stop-words ignoring case information, semantic lexicon
one constructed modified Basilisk framework. showing results
supervised transductive experiments, first describe parameters associated
classification approach.
6.4.1 Parameters
SVM classifier, two parameters tune. first parameter
percentage features use. Feature selection shown improve performance
text classification tasks (Yang & Pedersen, 1997). result, employ information
gain (IG), one effective methods feature selection according Yang
Pedersens experimental results. Since assume words semantic lexicon
relevant cause identification, apply feature selection lexicon words.
Rather, apply feature selection unigrams bigrams. specifically,
unigrams used features (as first five feature sets mentioned
beginning subsection), select N % unigrams highest IG,
value N tuned using development set. unigrams bigrams used
features (as second fifth feature sets), combine unigrams bigrams
one feature set select N % unigrams bigrams highest IG,
value N tuned using development set. experiments, tested 10
values N : 10, 20, . . ., 100.
second parameter associated SVM classifiers classification threshold.
default, SVM sets classification threshold 0, meaning every data point
classification value 0 classified positive, rest classified
negative. However, since SVM classifier trained optimize classification accuracy,
best classification threshold may 0 cause identification task,
goal optimize F-measure. result, parameterize classification threshold,
allowing take one 21 values: 2.0, 1.8, . . . , 1.8, 2.0.
usual, tune two parameters described jointly rather independently.
words, possible value combination percentages features
597

fiAbedin, Ng & Khan

classification threshold, compute F-measure classifiers development set
classes choose value pair yields maximum F-measure.
get better idea two parameters impact performance, show
Figure 3 F-measure changes development set vary values
two parameters, experiment underlying SVM classifiers employ
unigrams features. see, best F-measure achieved employing
top 50% unigrams classification threshold 0.8. Using default parameter values
(no feature selection classification threshold 0) yields F-measure approximately
18%. Overall, results provide suggestive evidence parameters
large impact performance.
F-measure Vs. classification threshold
different percentages unigram features
100
Top 10% Unigrams
Top 20% Unigrams
Top 30% Unigrams
Top 40% Unigrams
Top 50% Unigrams
Top 60% Unigrams
Top 70% Unigrams
Top 80% Unigrams
Top 90% Unigrams
Top 100% Unigrams

90
80

F-measure (%)

70
60
50
40
30
20
10
0
-2

-1.5

-1

-0.5
0
0.5
Classification threshold

1

1.5

2

Figure 3: Variation F-measure different percentages unigram features classification thresholds used SVM classification.

6.4.2 Supervised One-Versus-All Classifiers: Results Discussions
Results supervised One-Versus-All classification approach using five feature sets
described shown Experiment 3 section Table 4.14 see,
feature sets 1 (unigrams only) 4 (unigrams lexicon words) used, achieve
best results F-measure scores 47.46% 47.45%, respectively. However, even
best results statistically indistinguishable baseline result (according
approximate randomization test), significantly worse result produced
14. Recall supervised approach, SVM classifiers trained 233 reports
training set.

598

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

modified Basilisk approach (row 1 Experiment 2) [see Appendix D, contains
statistical significance test results obtained applying stratified approximate randomization test pair experiments Table 4].
fact, also indicate Occurrence Heuristic made effective use
learned semantic lexicon SVM classifiers: SVM classifiers trained
lexicon words features (row 3 Experiment 3) produced significantly worse
F-measure score (42.11%) Occurrence Heuristic (50.21%), due large
drops recall precision. Overall, results suggest supervised approach performs worse heuristic-based semantic lexicon approach task.
hypothesize limited amount training data available SVM learner contributed poor performance supervised approach. test hypothesis
Section 6.5
Two additional observations worth mentioning. First, comparing rows 1 4
Experiment 3, see lexicon words useful cause identification
presence unigrams. Second, comparing rows 1 2 rows 4 5 Experiment
3, see using bigrams hurts performance. likely reason attributed
feature selection method: since choose top N % features, bigram features
significantly outnumber unigram features, thus potentially diminishing effect
latter. One solution problem employ separate parameters selecting
unigrams bigrams, decided choice, would lead explosion
size parameter space.
6.4.3 Transductive One-Versus-All Classifiers: Results Discussions
investigate whether useful exploit unlabeled data, employ transductive SVM
combine labeled unlabeled data. Essentially, repeated experiments
supervised One-Versus-All classification approach, except trained transductive
SVM classifier using (labeled) reports training set (unlabeled)
reports test set described Section 5.2.2. two parameters percentage
features used classification threshold tuned jointly maximize F-measure
development set, described supervised approach, except transductive
SVMs used parameter tuning step trained using training set labeled data
development set unlabeled data.
Results transductive SVM classifiers shown Experiment 4 section
Table 4. Overall, transductive results significantly worse corresponding
results Experiment 3. However, conclusions draw transductive
results slightly different drawn supervised results. First, using
bigrams significantly improves performance lexicon words absent (comparing
rows 1 2 Experiment 3) hurts performance lexicon words present
(comparing rows 4 5). Second, adding lexicon words unigram-only feature
set (comparing rows 1 4) significantly improves performance, suggesting potential
usefulness lexicon features. Nevertheless, Experiments 3 4 indicate (1)
using lexicon words features far adequate, (2) best performance
achieved lexicon words added unigrams features.
599

fiAbedin, Ng & Khan

6.4.4 Results Additional Supervised Approaches
Next, present results two additional supervised approaches, namely MetaLabeler ensembles pruned sets (Section 5.2.1). feature sets used
approaches used One-Versus-All method. OneVersus-All method, approaches use SVM underlying learning algorithm
classifier training.
MetaLabeler. parameter needs tuned MetaLabeler approach
percentage features use (N ), selected based classification performance (F-measure) development set.
Results MetaLabeler approach shown Experiment 5 section Table 4. interesting points results. First, MetaLabeler
method results much better precision methods. Second, method
shows consistent performance improvement bigram features added, seen
comparing first second, fourth fifth rows MetaLabeler results.
Third, inclusion lexicon word features also found improve performance,
seen comparing first fourth, second fifth, rows MetaLabeler
results. two observations show MetaLabeler approach properly take
advantage increasingly richer feature sets used experiments, best
performance occurring types features used (fifth row). Unfortunately,
approach suffers poor recall, fact prevents even matching, let alone
surpassing, F-measure scores methods. Since method discards less
probable labels assigns labels documents, precision much improved
recall suffers.
Ensembles Pruned Set. Among parameters ensembles pruned sets
approach, number classifiers ensemble, , size sample
training data classifier ensemble trained, chosen
ones used Read et al. (2008), namely 10 63% respectively. rest
parameters pruned set approach, namely minimum cardinality (b), minimum
support (p), percentage features use (N ), threshold label assignment (t)
selected jointly based classification performance (F-measure) development
set. values specific value b chosen 2, 3 5. possible
values p tested experiment 3, 5 10. threshold parameter chosen
values 0.1, 0.2, . . . , 1.0, percentage features, N chosen
values 10%, 20%, . . . , 100%. Thus 900 parameter combinations feature set,
parameter combinations, combination performance
development test set best (in terms F-measure) chosen running system
test set.
Results pruned set approach shown Experiment 6 section Table 4.
Here, see best performance combination unigram lexicon word features,
better performance using unigrams lexicon words individually. However,
performance degraded inclusion bigrams combination. Precision
much lower methods, indicates selection label
sets training set 233 reports may adequate.
600

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

6.5 Experiments Using Additional Training Data
results experiments somewhat surprising: best-performing supervised classification approach One-Versus-All approach performs significantly worse
modified Basilisk approach. hypothesize poor performance attributed scarcity (labeled) training data. test hypothesis, conducted
set experiments increased amount training data One-Versus-All
supervised classification approach applying cross-validation. specifically, take
test set 1000 reports split five disjoint subsets equal size, T1 , T2 , . . . , T5 .
Then, construct training set merging Tj , 6= j,
original training set 233 reports. that, train SVM classifier merged
training set test set Ti . done five folds, compute
F-measure entire test set. words, results report set
experiments F-measure scores averaged five folds. experimented
five set features used supervised experiments Section 6.4. two
parameters, percentage features used classification threshold, tuned
exactly way supervised experiments.
Results set experiments shown Experiment 7 section Table 4.
comparison results Experiment 3, F-measure increases uniformly significantly.
provides empirical evidence performance supervised classifiers limited
amount data trained. feature sets 4 (unigrams
lexicon words) 5 (unigrams, bigrams lexicon words), achieve best results
F-measure scores 53.56% 53.66% respectively difference
statistically insignificant. two results turn significantly better
modified Basilisk (row 1 Experiment 2), according approximate randomization
test. addition, except feature set 3 (lexicon words only), results obtained
experiment significantly better baseline, according approximate
randomization test. Overall, results suggest difficulty cause identification
task: comparing rows 4 Experiments 3 5, see F-measure increases
6% number training reports increased 233 1033.
points deserve mentioning. previous learning-based experiments, using lexicon words features yields worst result set experiments,
combining unigrams lexicon words still yields one best results. Nevertheless,
comparison Experiment 3, using bigrams still improve performance,
hurt performance (from statistical significance point view). Perhaps
importantly, comparing rows 1 4 Experiment 7, see augmenting unigrams
lexicon words yields significantly better performance. indicates lexicon
words indeed useful features cause identification, usefulness may
revealed small labeled training set used, seen Experiment 3. Learning algorithms attempt learn features important relevant given classification
task based training examples see, training examples,
better able learn relevance features. results show
poignant illustration phenomenon: SVM learner able use lexicon word
features effectively given large number training instances. seen
clearly SVM learning curves Section 6.7.3. indicates lexicon
601

fiAbedin, Ng & Khan

words useful features sufficiently large training data. However,
lexicon words may still used effectively ways linguistic features even
training set small, see results Experiment 2, uses
lexicon words combination Occurrence Heuristic achieve performances
statistically significantly better baseline.
6.6 Error Analysis Lessons Learned
order gain clearer insight cause identification problem help direct
future research, manually analyzed errors made best-performing system (i.e.,
heuristic based approach using semantic lexicon learned modified Basilisk
framework) randomly chosen 100-report subset test set. specifically,
looked false negatives (cases annotator labeled report shaping
factor system not) false positives (cases system labeled
report shaping factor annotator not). false negative, tried
determine system failed correctly label report, false positive,
tried determine system labeled report erroneously. Table 6 shows
number false positives false negatives along reasons errors
discovered analysis. following sections discuss errors reasons
detail. Note since shaping factor may indicated one keyword
single report, one reason false negative (positive) error.
Thus sum frequencies different types false negative (positive) errors greater
total number false negatives (positives).
Table 6: Error analysis details: different reasons false positive false negative
errors.
False negatives
Sentence fragments bigger phrases
Implicit causes cannot identified keywords
Phrases learned
False positives
Keyword general
Keyword indicates concept appears report
contribute incident
Wrongly learned keyword
Keyword used negative context
Keyword used hypothetical context

58
24
23
14
83
50
32

Percentage
41.38%
39.66%
24.14%

6
3
1

7.23%
3.61%
1.20%

60.24%
38.55%

False negatives. false negative error, read report narrative identify
word, phrase sentence fragment may indicate shaping factor
system missed. analysis, identified three reasons false negatives
follows:
602

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

1. Required sentence fragments larger phrase. identified 24 sentence
fragments bigger phrases (i.e., consist two phrases).
example, sentence fragment never DCA consists 4
phrases: never been, to, DCA before. Together, convey meaning
reporter unfamiliar DCA, possible identify single
word phrase conveys meaning. Since framework learns
phrases, possible learn sentence fragments.
2. Cause identifiable specific words phrases. 21 instances, specific
word, phrase sentence fragment could identified could pinpoint shaping
factors responsible incident. example, number reports, including
report#566757, describe incidents miscommunication
pilot air traffic controller, miscommunication must understood
following conversation. human reading report easily understand
pilot claiming controller said one thing controller claiming
said something different, detect kind scenario, machine would need
generate complete model discourse identifies specific topic
conversation, participants, claims participant makes topic,
fact claims contradictory, also fact contradiction arises
miscommunication them. preprocessed narrative report
shown Appendix E.
3. Missing phrases. 14 cases necessary phrase missing semantic
lexicon learned modified Basilisk framework. 14 phrases, six
phrases infrequent considered modified Basilisk framework due
minimum frequency criterion. example, phrase temperature flux
appears entire corpus hence considered system.
Two phrases verb phrases, could learned focused
learning noun phrases adjective phrases. four phrases
semantically similar seed word shaping factors. example,
phrase garbled transmission semantically similar seed word
shaping factor Communication Environment, disturbance, static, radio
discipline, congestion noise. Finally, two phrases
learned system, learned time put
word pool, words higher scores selected instead.
False positives. case false positives, looked report narrative
keyword found content determine indication shaping
factor incident described report incorrect. different reasons
identified follows.
1. general keywords. observed large number false positives due
keywords general (i.e., keywords extracted learned
shaping factor may appear phrases related shaping
factor). example, keyword failure correct indicator Resource Deficiency
appears text like complete electrical failure, alternator failure, etc.,
appears text like failure follow Air Traffic Control instructions,
603

fiAbedin, Ng & Khan

indicate Resource Deficiency shaping factor. identified 50 cases
caused keywords general.
2. Concept present contributing incident. Another frequently faced
problem sometimes concepts identified keywords present
report, act shaper incident described report.
example, report#324831, reporter mentions flying solo,
indication Taskload, incident due Physical Environments, namely
snow foggy weather. fact flying solo merely mentioned
part description overall situation. preprocessed version report
also given Appendix E. total, observed 32 cases.
3. Incorrectly learned words phrases. six cases semantic lexicon learner learned incorrect words phrases related
shaping factors assigned. example, framework incorrectly learned word shaping factor Resource Deficiency, thus
number reports mislabeled Resource Deficiency.
4. Negative context. three cases keyword appeared
negative context, typically signaled contextual valence shifter
hardly (Polanyi & Zaenen, 2006). example, keyword aircraft damage, indicator Resource Deficiency, appears report#569901 apparent
aircraft damage, results false positive.
5. Hypothetical context. one case keyword appeared
hypothetical context reporter conjectures possible scenario.
keyword single pilot, indicator Taskload, appeared report#534432
could happen pilot especially single pilot, resulting false positive.
Lessons learned. error analysis provides valuable insight nature
problem well hints one proceed order improve performance
system. analyzing frequent errors, present following lessons
learned analysis. First all, useful learn high-precision keywords
phrases general ones largest part false positive errors attributed
general keywords. However, high-precision keywords phrases
likely low frequencies, hence one would adapt learning methods
learn useful words phrases infrequent ones. Second, one must take account
fact relevant portions text may larger phrases, even going
clause sentences. cannot identified learning words phrases, N-grams
reasonable size. Thus, robust methods needed learn useful sentence
fragments useful sentence structures. Finally, cases one cannot hope
identify using methods look keywords, phrases, sentence fragments even sentence
structures, i.e., cases cause incident understood
discourse, cases concept present description yet plays part
incident. Much deeper analysis simple bag-of-anything models needed
avoiding two types errors, represent almost one third
errors analyzed subset. former needs method distinguish relevant
604

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

sentences irrelevant ones. example, Patwardhan Riloff (2007) discuss relevant
sentence classifier trained small set seed patterns set documents
marked relevant irrelevant useful context. latter problem
requires discourse analysis method that, discussed earlier, model conversations
identify relations correctly. shows though possible identify shaping
factors reports using words phrases certain extent, much deeper natural
language techniques needed accurately identify full range causes.
6.7 Additional Analyses
section present outcomes number additional analyses performed
cause identification task approaches task. Section 6.7.1 study
relative difficulties classifying different shaping factors. Sections 6.7.2 6.7.3
show learning curves semantic lexicon based approach learning based
approach respectively, i.e., performances two approaches vary
provided different amounts training data. Finally Section 6.7.4 discuss
outcomes experiment conducted determine modifications Basilisk
framework useful learning general semantic categories.
6.7.1 Per-Class Results
get insight classes difficult classify, perform analysis
per-class performance two labeling schemes: best heuristic-based method (i.e.,
Occurrence Heuristic using lexicon learned modified Basilisk framework) [see
first part Table 7] best learning-based method (i.e., 5-fold SVM classifiers
using unigrams, bigrams lexicon words features) [see second part Table 7].
conjunction Table 1, two classes stand prominently difficult classify
Illusion Taskload. classes little representation training,
test development sets, small number seed words, result poor
performance approaches. easily identifiable classes Physical
Environment, Physical Factors, Resource Deficiency Preoccupation,
labeling schemes F-measures better 40%. general classes better
representation training, testing development sets, also reasonable
number words phrases semantic lexicon. believe difference
characteristics classes valuable insight helpful future work.
6.7.2 Lexicon Learning Curve
mentioned Section 2.3.2, used total 177 seed words phrases.
first glance, number seeds may seem large far bootstrapping experiments
concerned. However, considering fact 177 seeds distributed 14
shaping factors, average 12.6 words phrases per shaping factor.
Nevertheless, would still interesting examine cause identification performance
affected reduce number seeds shaping factor used Modified
Basilisk bootstrapping process. result, ran set experiments measure
cause identification performance uses semantic lexicon learned Modified Basilisk
given different number seed words, parameters specific Modified
605

fiAbedin, Ng & Khan

Table 7: Per-class performance results. upper table shows per-class performance
Occurrence Heuristic using lexicon learned modified Basilisk framework.
lower table shows per-class performance 5-fold SVM classifiers using unigrams,
bigrams lexicon words features.

Shaping Factor
Attitude
Communication Environment
Duty Cycle
Familiarity
Illusion

Physical Environment
Physical Factors
Preoccupation
Pressure
Proficiency
Resource Deficiency
Taskload
Unexpected
Overall

TP
3
9
3
31
0
25
195
22
78
14
40
360
0
4
784

FN
27
81
23
19
2
192
70
13
32
16
207
147
29
6
864

TN
957
888
973
872
996
766
638
958
822
902
723
225
965
976
11661

FP
13
22
1
78
2
17
97
7
68
68
30
268
6
14
691

Precision
18.75%
29.03%
75.00%
28.44%
0.00%
59.52%
66.78%
75.86%
53.42%
17.07%
57.14%
57.32%
0.00%
22.22%
53.15%

Recall
10.00%
10.00%
11.54%
62.00%
0.00%
11.52%
73.58%
62.86%
70.91%
46.67%
16.19%
71.01%
0.00%
40.00%
47.57%

F-measure
13.04%
14.88%
20.00%
38.99%
0.00%
19.31%
70.02%
68.75%
60.94%
25.00%
25.24%
63.44%
0.00%
28.57%
50.21%

Shaping Factor
Attitude
Communication Environment
Duty Cycle
Familiarity
Illusion

Physical Environment
Physical Factors
Preoccupation
Pressure
Proficiency
Resource Deficiency
Taskload
Unexpected
Overall

TP
2
20
10
18
0
52
182
20
55
6
102
399
0
0
866

FN
28
70
16
32
2
165
83
15
55
24
145
108
29
10
782

TN
964
871
962
924
998
685
623
955
848
961
639
247
971
990
11638

FP
6
39
12
26
0
98
112
10
42
9
114
246
0
0
714

Precision
25.00%
33.90%
45.45%
40.91%
0.00%
34.67%
61.90%
66.67%
56.70%
40.00%
47.22%
61.86%
0.00%
0.00%
54.81%

Recall
6.67%
22.22%
38.46%
36.00%
0.00%
23.96%
68.68%
57.14%
50.00%
20.00%
41.30%
78.70%
0.00%
0.00%
52.55%

F-measure
10.53%
26.85%
41.67%
38.30%
0.00%
28.34%
65.12%
61.54%
53.14%
26.67%
44.06%
69.27%
0.00%
0.00%
53.66%

606

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Basilisk set described Section 6.3.1. specifically, chose top 3, 4, 5, 6,
7, 10, 15 20 seed words phrases shaping factor (in terms frequency
entire corpus), ran modified Basilisk framework ten iterations using
aforementioned parameters.
Note, however, shaping factors number manually selected
seed words phrases. example, Illusion, Taskload Unexpected 1, 2 3
seed words phrases respectively, whereas Resource Deficiency Physical Environment
47 45 respectively (see last column Table 1). Hence, experiments
number seeds used shaping factor exceeds number manually
selected seeds shaper, manually selected seeds used. example, since
Unexpected three manually selected seeds, used experiments
least three seeds used shaping factor.
Occurrence Heuristic used lexicons thus generated evaluate
performance test set. resulting learning curve, terms F-measure
test set 1000 reports, shown Figure 4. addition, since baseline
compare performance based seed words, baseline learning curve
corresponding reduced seed words set also shown. expected, increasing
number seed words monotonically improves F-measure. However, improvement
baseline particularly small fewer seven seed words used,
highest improvement observed seven seed words phrases. on, adding
seeds improves overall performance, improvement baseline slowly
diminishes.
Lexicon Learning Curve
50
48
46

F-measure (%)

44
42
40
38
36
Baseline
Performance learned lexicon

34
32
30
0

2

4

6

8
10
12
Number Seeds

14

16

18

20

Figure 4: Variation F-measure different number seeds words per category.

607

fiAbedin, Ng & Khan

SVM Learning Curve
60
F-measure Test Set
58
56

F-measure (%)

54
52
50
48
46
44
42
40
0

100

200

300 400 500 600 700
Number Training Instances

800

900 1000

Figure 5: Variation F-measure different number training reports.

6.7.3 SVM Learning Curve
discussed Section 6.5, hypothesize failure SVM classifiers perform better baseline due scarcity training instances available
learner. One may argue SVM shown work well small datasets.
So, natural question is: much smaller training set see
statistically significant drop cause identification performance? answer question,
plot learning curve One-Versus-All classification approach, using features
combination unigrams, bigrams, lexicon word features five-fold cross validation
setting, setting yields best performance Table 4. Specifically,
generated random subsets training sets sizes 50, 100, . . . , 1000 instances. Parameters, namely percentage features classification threshold, chosen
way original experiment described Section 6.5, F-measure
evaluated entire test set. curve shown Figure 5, data point
computed averaging results five independent runs. see,
general trend performance improvement increase number training
instances. addition, trained 50% training set, see cause
identification system started perform statistically significantly worse system
trained available instances according stratified approximate
randomization test.
608

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

6.7.4 General Usefulness Modifications Basilisk
order test whether modifications made Basilisk framework useful
lexicon learning general, added two general categories shaping factors
bootstrapping experiments, namely People Equipment. two categories
added because, firstly, words phrases added categories would easy verify
(i.e., whether words phrases representing people equipment), secondly,
similar original context Basilisk framework originally evaluated (i.e., learning words categories BUILDING, EVENT, HUMAN, LOCATION,
TIME, WEAPON terrorism reports). two additional categories added
seed lexicon described Section 2.3.2, bootstrapped running Original Basilisk Modified Basilisk separately ten iterations, parameters specific
Basilisk frameworks set way described Section 6.3.1. seed
words two categories selected manner done Thelen
Riloff (2002), i.e., phrases corpus sorted frequency five
frequent phrases belonging categories manually identified. seed
words used two categories:
People: Captain, controller, First Officer, RPTR, passenger
Equipment: aircraft, airplane, Collision Avoidance System II, engine, Auto-Pilot
order verify words phrases learned two frameworks correctly
belong assigned category, first author computer science graduate student
affiliated research went generated lexicons. Appendices F G
show lexicons generated Original Basilisk Modified Basilisk respectively.
facilitate analysis, divide words phrases generated lexicon three
categories: (1) determined correct human judges; (2)
determined correct one judge; (3) determined incorrect
judges.
lexicon generated Original Basilisk, find category People, 29
50 words phrases determined correct judges, 6 determined
exactly one judges correct; category Equipment, 6 50 words
phrases correct according judges, 22 correct according exactly one
judges. hand, lexicon generated Modified Basilisk, find
category People, 44 50 words phrases determined correct
judges, 3 determined exactly one judges correct; category
Equipment, 34 50 words phrases correct according judges, 9
correct according exactly one judges. comparison clearly shows
modifications made Basilisk framework specific particular
task; rather, modifications improved lexicon building performance general.
6.8 Summary Conclusions
end section providing summary major conclusions draw
experiments.
609

fiAbedin, Ng & Khan

heuristic approach cause identification, labels report using Occurrence Heuristic combination words phrases automatically acquired
using Modified Basilisk framework, surpasses performance baseline system, applies Occurrence Heuristic combination seed words
phrases manually identified training documents. difference F-measure
two systems statistically significant according McNemars test
stratified approximate randomization test. suggests words
phrases semantic lexicon learned via Modified Basilisk relevant effective
cause identification.
Adding learned lexicon words N-gram-based feature set training SVM
classifiers beneficial cause identification training set sufficiently
large, exhibited statistically significant increase F-measure. provides
suggestive evidence words phrases semantic lexicon learned via
Modified Basilisk relevant useful features cause identification.
used combination Occurrence Heuristic, semantic lexicon learned
Modified Basilisk framework offers significantly better performance
cause identification task one obtained using original Basilisk framework. Additional experiments reveal Modified Basilisk useful
cause identification, also offers performance superior Original Basilisk
bootstrapping general semantic categories People Equipment.
Among three multi-class multi-labeled text classification approaches experimented with, One-Versus-All works significantly better MetaLabeler Pruned
Sets cause identification. Transductive learning, used combination
One-Versus-All approach, significantly hurts performance, suggesting unlabeled data cannot profitably exploited given fairly small amount labeled
data.
best system achieves F-measure around 53.7%, indicates cause
identification difficult task, lot room improvement.
provide directions future research, performed analysis errors made
best-performing system. particular, found performance currently
limited part several factors. First, number cases
relevant text indicating responsible shaping factor may larger phrases.
Second, indicators shaping factor may mentioned report without influencing incident described report. Finally, cases
shaping factors cannot identified simply looking words, phrases even
sentence fragments much deeper analysis required cases.
Increasing number seed words phrases employed Modified Basilisk improves cause identification performance, marginal performance improvement
added seed diminishes successive additions. words, results
seem suggest using seed words unlikely improve much
current performance; rather would promising start small number
high frequency seeds improve upon bootstrapping process.
610

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

learning curve plotted One-Versus-All classification approach shows
cause identification performance increases number training instances.
particular, trained 50% training set, see resulting cause
identification system performs statistically significantly worse one trained
available instances.
Overall, approaches rely automatically learned lexicon words phrases
adequate cause identification, relevant task. mentioned previously, use motivated labor-intensive procedure NASA
researchers employed manually identifying seed words phrases shaping factor (Posse et al., 2005). work represents one first attempts tackle cause
identification task, believe use simple features good starting point
establishes baseline future studies problem compared.
main take home message research though possible solve
problem set solve, namely automated cause identification, learning
relevant keywords sentence fragments suitable bag-of-words models,
remains significant portion data remains unlabeled mislabeled
methods. match performance level achieved topical text classification
tasks, much deeper linguistic analysis like relevant sentence detection discourse analysis
methods like identifying disagreements, disputes hostile attitudes needed.
lesson cornerstone research area.

7. Related Work
section, describe works related research. particular,
discussion focuses causal analysis well approaches semantic lexicon construction text classification, organized follows. First, discuss causal analysis
appeared different fields. Second, discuss different semantic lexicon
learning algorithms. Third, discuss works deal extraction pattern learning.
Fourth, describe different algorithms unsupervised word clustering thesaurus
building. Finally, include discussion related work multi-class multi-labeled text
classification.
Causal analysis. Major research causality performed mainly fields
philosophy psychology. field philosophy, seminal works causality
conducted Hume (1739, 1748), provides one influential definitions
cause object followed another, objects, similar first,
followed objects similar second. Or, words, where, first object
been, second never existed. basis later, much stronger
definitions causation (e.g., Lewis, 1973; Ganeri, Noordhof, & Ramachandran, 1996).
Notable investigations causation field psychology include Cheng (1997),
defines causation terms probabilistic contrast model; Griffiths Tenenbaum
(2005), discuss learning cause effect relationships using causal graphical
models; Halpern Pearl (2005), provide explanations causality means
structural equations governing random variables representing events. Although
611

fiAbedin, Ng & Khan

works provide important background definitions contributing understanding
causality, order identify causes naturally written text must turn NLP.
field NLP, little work cause identification similar problem.
Research causality focuses mainly identifying causal relations two sentence
components. instance, Girju (2003) describes method automatically discovering
lexico-semantic patterns refer causation. particular, focuses explicit
intra-sentential pattern hN P1 verb N P2 i, verb simple causative. also shows
patterns used improve performance system answering
cause-effect type questions. Khoo et al. (2000) use graphical pattern matching identify
causal relations medical article abstracts. use hand-crafted patterns
matched parse trees sentences. subtrees parse tree match
patterns extracted causes effects. Similarly, Garcia (1997) uses hand-crafted
extraction patterns identify causal relations sentences French language.
limitation approaches focus identifying causal relations
sentence, whereas reports multi-sentence discourses.
Grishman Ksiezyk (1990) use domain modeling, discourse analysis causal inference find cause-effect relations events leading equipment malfunctions
short equipment failure reports. specifically, first apply syntactic analysis
produce parse trees sentences reports using augmented context-free
grammar. apply semantic analysis map (1) verbs syntactic relations
domain-specific predicates relations (2) noun phrases references components
domain model. Finally, apply discourse analysis predicates construct
time-graph showing temporal causal relationships elementary facts.
temporal relations derived text structures words (e.g., when, then,
etc.) order appearance text, causal relations determined querying simulation model equipment built using domain knowledge. Specifically,
possible causal link posed query model test relation holds.
Overall, method relies heavily domain model equipment studied,
research focuses one specific piece equipment.
NASAs research identifying causes incidents report narratives
performed Posse et al. (2005), describe specific experiment
brought together experts manually analyze report narratives identify words,
phrases expressions related shaping factors, mentioned earlier. Later
work Ferryman et al. (2006) take manually extracted expressions ground truth
compare anomalies described reports shaping factors derived
applying expressions reports. Specifically, attempt learn
expressions automatically; rather, focus finding possible correlations
shaping factors anomalies.
Algorithms semantic lexicon learning. number semantic lexicon learning
algorithms follow iterative bootstrapping approach, starting small number
semantically labeled seed words. Roark Charniak (1998) propose method constructing semantic lexicons based co-occurrence statistics nouns conjunctions, lists
appositives. start small seed nouns list, iteratively add similar words
list. word similarity measured ratio many times word occur
612

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

together seed word number times word appear corpus.
construction, rank words log-likelihood statistic (Dunning, 1993). However,
due general brevity reports, co-occurrences lists rather
corpus, useful us use context-based similarities like Thelen Riloff
(2002). describe Basilisk framework learning semantic lexicon using extraction patterns features. apply weakly supervised bootstrapping approach
start small manually constructed seed lexicon iteratively add semantically
similar words it. This, described detail Section 4.2, basis
lexicon learning approach.
number improvements Basilisk framework, generally bootstrapping approaches, proposed. Basilisk framework, number iterations
parameter chosen arbitrarily. Rather making arbitrary choice,
Yangarber (2003) proposes method detecting termination unsupervised semantic
pattern learning processes. method requires documents must labeled
relevant irrelevant. Since information available corpus, useful us. Curran, Murphy, Scholz (2007) suggest improvement traditional
bootstrapping methods discarding words contexts appear related
one category, order minimize semantic drift enforce mutual exclusion.
hand, handle cases comparing conditional probabilities
different categories words belong. Zhang, Zhou, Huang, Wu (2008)
present bootstrapping graph mutual reinforcement-based bootstrapping (GMR)
(Hassan, Hassan, & Emam, 2006), modification Basilisk method. Similar us,
explore using N-grams capture context, use different set pattern
word scoring formulas. learning multiple categories simultaneously, introduce
scoring system based entropy pattern. report better results Basilisk
MUC-4 dataset (see Sundheim, 1992).
Among non-bootstrapping approaches, Ando (2004) presents new method constructing semantic lexicons unannotated corpus using set semantic classes set
seed words phrases semantic class. uses spectral analysis improve
feature vectors projecting useful portions vectors subspace removing harmful portions vectors. resultant feature vectors used
centroid-based classifier using cosine similarity measure label words. Avancini,
Lavelli, Sebastiani, Zanoli (2006) take classification approach semantic lexicon
construction. cast problem term (meaning words phrases) categorization task (dual document categorization task), similar bag-of-word
model, represent terms bag-of-documents. use variation adaptive
boosting algorithm, AdaBoost.M H KR , trained small seed lexicon
used classify noun terms corpus zero, one semantic categories.
Algorithms learning extraction patterns. approach semantic lexicon construction uses extraction patterns features, present methods aim
improve extraction pattern collection process. Riloff (1996) describes AutoSlog-TS
system learns extraction patterns untagged text. However, needs pre-classified
corpus text classified relevant irrelevant; mentioned earlier,
access information. Phillips Riloff (2007) present method boot613

fiAbedin, Ng & Khan

strapping algorithm learn role-identifying nouns, used learn important
extraction patterns, also role-identifying expressions. However, focus mainly
identifying roles words events.
Patwardhan Riloff (2007) provide another extraction pattern learning approach
using relevant regions. require documents pre-classified relevant
irrelevant documents. Using small set seed patterns, classify sentences
documents relevant irrelevant sentences. semantically appropriate extraction patterns learned using semantic affinity metric separated primary
secondary patterns. approach also directly usable us due unavailability
documents pre-classified relevant irrelevant categories.
Recently, Internet increasingly used natural language research. Patwardhan Riloff (2006) use AutoSlog-TS system (Riloff, 1996) learn domain specific
extraction patterns processing documents retrieved querying web selected
domain-specific words. Using web interesting promising enhancement and,
mentioned Section 8, intend extend work using Google corpus (Brants &
Franz, 2006).
Algorithms thesaurus building unsupervised word clustering. Another
area research closely related semantic lexicon learning thesaurus building.
Building thesaurus requires discovering groups semantically similar words, though
stops short assigning semantic class labels words. Thus shares problem
measuring semantic similarity grouping similar words semantic lexicon building
task. discuss several approaches thesaurus building task.
Clustering used extensively thesaurus building, mostly unsupervised nature ability handle large volumes data. seminal work
direction Pereira, Tishby, Lee (1993), present unsupervised method
soft clustering words using distributions words different contexts. approach generates overlapping word clusters, grouping words based contexts
appear in. Baker McCallum (1998) use Pereira et al.s distributional clustering technique perform feature space reduction supervised classification nave Bayes
using clusters features. Lin Pantel (2001) present approach generating
collection sets semantically similar words, concepts, using clustering method,
UNICON, dependency relations features. Pantel Lin (2002) present another
clustering approach, clustering committee, using contextual features point wise
mutual information feature values, compare better Lin Pantels
results. Rohwer Freitag (2004) present clustering-based automatic thesaurus building
process unannotated corpus. propose information theoretic co-clustering
algorithm groups together highly frequent words clusters similar part-of-speech
category. pursue additional process, lexicon optimization, grow lexicon
assigning less frequent words likely clusters.
Among non-cluster-based methods, Davidov Rappoport (2006) present unsupervised method discovering groups words similar meanings. achieve
(1) identifying high frequency words content words, (2) identifying symmetric
lexical relationship patterns, (3) applying graph clique-set algorithm generate word
categories co-occurrence information content words symmetric patterns.
614

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Concentrating performance issues plague attempts build thesaurus
large corpus, Rychly Kilgarriff (2007) present two methods improving performance
general context-based thesaurus building algorithms. first method compare
word pairs context common. second method use
heuristic removing contexts general (i.e., contexts
certain number distinct words). research, adopted second method
(see Section 4.3). also applied partitioned sequential approach construction
process. Though thesaurus building usually require annotated corpus set
seed words phrases, directly applicable task growing semantic
lexicon learn words specific semantic categories.
method control words learned classes discovered
word groups belong to. may possible adapt method semantic lexicon
growing classifying word groups semantic classes using seed words
phrases. However, method extended extract noun adjective phrases.
Algorithms multi-class multi-labeled text classification. mentioned previously, cause identification, cast text classification problem, multi-class
multi-labeled text classification problem, since 14 shaping factors total
document may labeled one shaping factors. several
popular approaches solving multi-class multi-labeled text classification problem.
first, one approaches followed research, independently train binary
classifier class, apply classifier test instance isolation.
case, underlying learner Support Vector Machines (Joachims, 1998). Godbole
Sarawagi (2004) suggest number improvements scheme, namely, including class
labels suggested preliminary set classifiers features, removing negative examples
close classification hyperplane, selectively removing classes
one-versus-others classifications scheme. Another notable method, followed Tsoumakas
Vlahavas (2007) Read et al. (2008), treat unique set labels
new label, thus converting problem multi-class single-labeled one. works
differ construction new labels. former, called RAndom
k-LabELsets, RAKEL, builds ensemble classifiers randomly sampling label sets
size k; whereas latter adopts method filtering observed label sets minimum
support. Tang et al. (2009), hand, take different approach: train one
classifier predicts number labels test instance would have, choose
many labels instance based output another classifier ranks labels
likelihood instance. works use SVM underlying learner.
addition, approaches make assumption classes correlated high
degree. However, analysis dataset present evidence strong
correlation. 140 documents multiple labels test set, 68 unique
label sets, seven frequency least five. Thus increasing number
labels would aggravate already imbalanced class distribution.
Among approaches, mention two systems use probabilistic generative models. McCallum Nigam (1999) propose system starts small set keywords
unlabeled documents, learns nave Bayes classifier bootstrapping process
keyword-induced labels using hierarchical shrinkage expectation maximization
615

fiAbedin, Ng & Khan

held-out data set. Ueda Saito (2002) present another generative model called Parametric Mixture Models, treats multi-labeled text parametric mixture words
relevant label. work closely related Latent Dirichlet Allocation (Blei,
Ng, & Jordan, 2003). generative models usually assume document related
particular topic would high frequency words related topic. research,
documents mostly devoted description event occurred, cause
event mentioned briefly. makes generative models less suitable
task hand generative models would likely generate models related events
causes. comprehensive review different approaches multi-class
multi-label text classification found work Tsoumakas Katakis (2007).

8. Conclusions
investigated two approaches cause identification task, goal
understand aviation safety incident happened via identification causes,
shaping factors, responsible incident. approaches exploit information
provided semantic lexicon, automatically constructed via Thelen Riloffs
(2002) Basilisk framework augmented three algorithmic modifications (namely,
use probabilistic similarity measure, use common word pool, enforcement minimum support maximum generality constraints words extraction
patterns) one linguistic modification (the use N-gram-based extraction patterns).
heuristic-based approach labels report employing Occurrence Heuristic,
simply looks words phrases acquired semantic lexicon learning process report. learning-based approach labels report employing inductive
transductive support vector machines learn models reports labeled shaping factors. experimental results indicate heuristic-based approach
supervised learning approach (when given sufficient training data) significantly outperform baseline, which, motivated NASAs work, labels report simply using
Occurrence Heuristic combination set manually-identified seed words
phrases. importantly, results heuristic-based approach indicate modifications original Basilisk framework beneficial far cause identification
concerned, results learning-based approach indicates usefulness lexicon
words used combination unigrams features training SVM
classifier. Overall, set prove possible automate cause
identification task manually analyzing small number reports using information thus generated train machine learning methods identify shaping factors
rest reports. experiments able prove feasibility approach,
also usefulness learning semantic lexicon using words features.
Nevertheless, best system achieves F-measure around 53.7%, indicates
cause identification difficult task, lot room improvement.
particular, analysis errors made best system 100 randomly chosen test
documents provides valuable insights task well directions future research.
experience current research, intend extend work
following directions. First foremost, plan extend approach handle text
fragments bigger phrases. Second, order improve quality labeling,
616

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

propose work improving lexicon learning performance using different
semantic similarity measures. instance, would like study performance
semantic similarities weighting functions suggested Curran Moens (2002)
context. Third, plan use thoroughly normalized text better parsing
tagging, well relevant region information (Ko, Park, & Seo, 2004; Patwardhan
& Riloff, 2007). Fourth, propose augment semantic lexicon, specifically using
Google N-grams corpus (Brants & Franz, 2006) extract frequent N-gram patterns
words. Fifth, propose explore recent lexicon construction methods
like unsupervised word clustering (Pantel & Ravichandran, 2004), spectral analysis, mutual
exclusion bootstrapping, co-clustering exploiting symmetric patterns. Finally, order
handle shaping factors difficult identify words occurring
reports, propose employ much deeper analysis text semantic level.
also taken step making annotated incident reports publicly available,
hope stimulate research under-investigated problem NLP
community.

Acknowledgments
authors would like thank anonymous reviewers provided us comments
invaluable improving quality paper. research supported
part NASA grant NNX08AC35A. opinions, findings, conclusions recommendations expressed paper authors necessarily reflect
views official policies, either expressed implied, NASA.

617

fiAbedin, Ng & Khan

Appendix A: Seed Words
seed words manually extracted 233 reports training set (see
Section 2.3.2 details).
Shaping Factor
Attitude
Communication
Environment
Duty Cycle
Familiarity
Illusion

Physical
Environment

Physical Factors
Preoccupation
Pressure
Proficiency

Resource
Deficiency

Taskload
Unexpected

Seed words
get HOMEITIS, attitude, inattentiveness, get THEREITIS, complacency, overconfidence, sarcastic, inattention
disturbance, static, radio discipline, congestion, noise
11 hour duty day, inadequate rest, last 4 legs, heavy flying, reduced
rest, all-night flight, 12 hour day, red eye, ten leg day, night
familiarization, familiar, new, first departure, unfamiliar, unfamiliarity, familiar, low time, first landing
bright lights
noise abatement policy, disoriented, confused, medical emergency,
economic considerations, disorientation, drunk passenger, confusion
cold, clouds, dark, setting sun, sun glare, obscured, visibility, hazy
stratus, birds, fog bank, solid overcast, snow, weather, rime, gust, low
weather, surface winds, jet blast, lightning, sea gulls, high ceilings,
hot, tailwind, chop, dark, sea gull, winds, scattered, high tailwinds, extremely dark, bright, icing, turbulence, RPTED wind,
terrain, bird strike, crosswind, thunderstorm, glare, reduced visibility, high flying birds, fog, severe winter weather, cloud, ice
tired, HYPOXIA, tiredness, tired, fatigued, disorientation, fatigue, rest
distracted, preoccupied, mental lapse, busy, DISTRS, distraction,
attention, inattention, absorbed
hurry, running late, pressure, low fuel, fuel considerations, behind
schedule, late, peer pressure, pressure, rushing
mistakes, mistaken, new hire, inexperience, forgotten, less 100
hours, newly rated, training, recent pilot, inadvertently, bad turn,
MISINTERPED
loose connection, erratic, blown, overheated, bang, collapse, idea,
unavailable, placarded, crack, Service, damage, smoke, inoperative, failure, leak, deferred items, communication failure, loss,
unreliable, FDRS problem, bump, shaking, master caution, inadequately lighted, unreadable, disconnected, malfunction, shudder, absence, hazard, inaccurate, UNFLAGGED, fire, broken, fluctuations,
compressor stall, deferral, unusable, wrong, intermittently, warning,
discrepancies, faulty, deferred, intermittent, missing
single pilot, solo
unexpected, suddenly, UNFORECAST

618

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Appendix B: Sample Lexicon Words Learned Modified Basilisk
semantic lexicon words learned modified Basilisk framework
first two iterations.
Shaping Factor
Attitude
Communication
Environment
Duty Cycle
Familiarity
Illusion

Physical
Environment
Physical Factors
Preoccupation

Pressure
Proficiency
Resource
Deficiency
Taskload
Unexpected

New words

aligned, fairly new, familiar
initial confusion, minimum fuel emergency, misunderstanding,
weather emergency
TRWS, conflict message, cumulonimbus, large cells, numerous thunderstorms, occasionally severe, thunderstorm cells, weather buildups,
weather cell, weather en route
first factor
adequate attention, much attention, close attention, close enough
attention, crew attention, enough attention, much attention, proper
attention, strict attention, close attention

different, amiss, awry, obviously wrong, resulting loss, seriously
wrong, slight loss, temporary loss, terribly wrong, wrong

619

fiAbedin, Ng & Khan

Appendix C: Sample Lexicon Words Learned Original Basilisk
semantic lexicon words learned original Basilisk framework first
two iterations.
Shaping Factor
Attitude

Communication
Environment

Duty Cycle

Familiarity

Illusion



Physical
Environment

Physical Factors

Preoccupation

New words
Air Traffic Control security, aileron yoke displacement, anomalous VFR Omni-Directional Radio Range information, assured TFR
avoidance, betrayal, concern urgency, forgetting air carrier X,
magnified problem, operational complacency, unseen unknown
turbulence
9001 noise, BNA runway 31 approach plate, LIGHTSPEED 20K
noise, Non- noise, OVERSPD bell, active noise, clearance delivery
transmission, left engine stall, static Emergency Locator Transmitter, stuck trim elevator movement
10 plus 16 layover, 2 different time frames, 3 back-to-back continuous duty trips, 4 hour break, 69 minutes, 8 hour 15 minute flight time
day, Pacific Daylight Time departure, TPA flight, XC15 departure,
scheduled 2- leg continuous duty
partial unfamiliarity, perceived familiarity, Command familiarity, Command unfamiliarity, blue panel indication light, dispatch
work desks, generally unfamiliar, inexperience unfamiliarity, new
everyday, past experience familiarity
1 1/2 Nautical Mile SSW, 1/2-1/4 point, 10 end, 50 feet side, Elmendorf required use, 1/2 mile downwind, airspace E, foxtrot
intersection, lateral boundaries, mile right
misinformation, Flight Management System/heading anomalies, confusion/conflict, disoriented confused, intense panic, micro sleep,
miss numerous times, mistake inconvenience, note closure problem,
start terror
MHT class Celsius, STRATO-cumulus, Thur morning, clouds underneath, compacted snow ice, fair weather cumulus, next morning
weather, puffy cumulus clouds, thin scattered clouds, well developed
cumulus clouds
HYPOXIA/carbon monoxide, Minimum Equipment List 24-32-02,
basically tired, cardiac distress, indicating system problem, internal
bleeding, interrupted fuel flow, oncoming seizure, stress overload,
upper respiratory problems
Captain First Officer attention, Terminal Radar Approach Control Facility distraction, close enough attention, consequently attention, good enough attention, lip service, mind attention, much
mind, real attention, real close attention
Continued next page

620

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Shaping Factor
Pressure

Proficiency

Resource
Deficiency

Taskload

Unexpected

New words
Minimum Equipment List pressure, consistent answer, elevator pressure, intense pressure, part # Coordinated Universal Time, repercussion, right engine pressure, significant pressure, slow gear, wheel
pressure
& P school, CL65 ground school, basic flight training, hard lesson,
initial annual proficiency training, occurrence strive, rating
training, several military flying clubs, situation event, time limited
simulator sessions
Air Traffic Control loss, altitude deviation/loss, apparently inoperative, either inoperative, even reexamining, intermittent inoperative, known traffic conflict loss, observed loss, recently Los,
thankfully accurate
16500 # turboprop, A320 type aircraft, AVIAT husky A1 two place
tail DRAGGER aircraft, Cessna 402 type aircraft, Cessna model
421 type aircraft, L1011-250, LGA-MHT flight, McDonnell Douglas
MD11, solo cross country FLTS, solo cross country privileges
significant, 1 jolt, approximately 5-10 sec, choppy aircraft, consistently moderate, contributing workload factor, industry issue,
severe, rapid immediate, real cushion

621

fiAbedin, Ng & Khan

Appendix D: Additional Stratified Approximate Randomization Tests

MLW

OLW

SVM-U

SVM-UB

SVM-L

SVM-UL

SVM-UBL

SVMT-U

SVMT-UB

SVMT-L

SVMT-UL

SVMT-UBL

SVM5-U

SVM5-UB

SVM5-L

SVM5-UL

SVM5-UBL

Methoda
SW
MLW
OLW
SVM-U
SVM-UB
SVM-L
SVM-UL
SVM-UBL
SVMT-U
SVMT-UB
SVMT-L
SVMT-UL
SVMT-UBL
SVM5-U
SVM5-UB
SVM5-L
SVM5-UL
SVM5-UBL

SW

ascertain statistical significance difference F-measure scores
different report labeling methods, performed stratified approximate randomization
test 9,999 shuffles pairs results Experiments 1 5 Table 4.
table shows method column statistically significantly better
method row level p < 0.05. before, statistical significance
insignificance denoted X X, respectively.

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
-

a. Legend: SW = Occurrence Heuristic using seed words, MLW = Occurrence Heuristic using modified
Basilisk lexicon, OLW = Occurrence Heuristic using original Basilisk lexicon, SVM-U = SVM using
unigrams, SVM-UB = SVM using unigrams bigrams, SVM-L = SVM using lexicon words, SVM-UL
= SVM using unigrams lexicon words, SVM-UBL = SVM using unigrams, bigrams lexicon
words, SVMT-U = transductive SVM using unigrams, SVMT-UB = transductive SVM using unigrams
bigrams, SVMT-L = transductive SVM using lexicon words, SVMT-UL = transductive SVM using
unigrams lexicons, SVMT-UBL = transductive SVM using unigrams, bigrams lexicon words,
SVM5-U = 5-fold SVM using unigrams, SVM5-UB = 5-fold SVM using unigrams bigrams, SVM5-L
= 5-fold SVM using lexicon words, SVM5-UL = 5-fold SVM using unigrams lexicon words, SVM5UBL = 5-fold SVM using unigrams, bigrams lexicon words.

622

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Appendix E: Sample Preprocessed Reports
Report ACN#324831
RETURNING waukegan regional airport practice area located 5-20 mile
W airport; flying solo student pilot; 3000 feet Mean Sea Level Visual
Flight Rules. cloud area 5 mile W airport obscured view ahead reduced
altitude proceed Visual Flight Rules returned 3000 feet passing thin
cloud line. area n; containing fix references airport location; shrouded
clouds fog ground level. true lake michigan shoreline
E. ground also substantially snow covered. although airspace airport
undoubtedly clear; practice area; orientation field lost me.
climbed 4500 feet increase overview; without benefit. returning 3000 feet;
flew believed n airfield landfall airport. must
S; however; proceeding flew ord class B airspace. coinciding
lost; contacted waukegan tower; realizing flown Federal Aviation
Regulation had. directed contact ord approach frequency given;
beginning ord approach vectored back waukegan airport; frequency changed
tower control blessedly cleared land. time lost 1 hour 15 minutes
1 1/2 hours.
Report ACN#566757
following event occurred REPOSITIONING; taxi; W side
side isp airport. initially contacted longitude island tower asking permission REPOS
W side OPS Base Operations Office tower (the side). controller
replied start taxi via taxiway W hold short runway 6. read back
instructions stating start taxi via taxiway W holding short runway 6. taxiing;
aircraft taxiway W holding short runway 6; performing run-up.
controller asked able get around aircraft. replied able.
controller said use caution taxiing around aircraft cross runway 6.
taxiing across runway 6; noticed aircraft short final runway 6. clear
runway aircraft touched down. controller came frequency
said instructed hold short runway 6. replied cleared across
runway 6. controller said call tower park. replied roger; call
park. called talked controller minutes later said
instructed hold short runway 6. told cleared across
runway. feel pilots controllers need listen decipher
said acting it.

623

fiAbedin, Ng & Khan

Appendix F: Lexicon Learned Original Basilisk Categories People
Equipment
following table shows words phrases learned original Basilisk framework
categories people equipment (see Section 6.7.4).
Category
People

Equipment

New words
Agreed judges correct: ABQ tower procedure specialist, ACN 126721 reporter, AFSFO, AVP tower specialist, Air Route
Traffic Control Center specialist, Air Traffic Control facility reps,
BDR tower specialist, BHM control, BUF field operations officer,
CAE tower specialist, Chicago quality control, DFW maintenance
manager, Flight Service Station dispatcher, SFOLM Captain,
SII program manager, Stearman pilot, TLH supervisor, bur local
controller, casino manager, cos Air Traffic Control chief, flight test
engineers, local balloon repairman, outbound Captain First Officer, repair facility pilot, shift boss, spokesperson, station management individual, technician desk, tower supervisor/manager
Identified one judge correct: Flight Standards District
Office ORL, maintenance supervisor, approach controller verbatim, freighter aircraft approach, tower, passenger
fatigue
Agreed judges incorrect: ACN 670635, ACN 682482,
AT6 aircraft, B737-300/500 SRM, EMB service manual, Non-air
carrier aircraft, RPTR ACN 518698, RPTR ACN 601074, RPTR
ACN 658075, RPTR ACN 664336, RPTR ACN 676343, RPTR ACN
88920, cabin company, aircraft center, reliable research resources
Agreed judges correct: Collision Avoidance System II 10 Distance Measuring Equipment screen, Collision Avoidance
System II B737-200, Collision Avoidance System II EHSI, Collision
Avoidance System II IVSI display, Collision Avoidance System II
Missed Approach Point page, Collision Avoidance System II RR,
Continued next page

624

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Category

New words
Identified one judge correct: Collision Avoidance System II VSI overlay, Resolution Advisory stopped aircraft, Collision Avoidance System II stop climb alert, Collision Avoidance
System II traffic ; climb advisory, Collision Avoidance System II traffic ; traffic aural warning, Collision Avoidance System
II 3 mile circle, Collision Avoidance System II 5 mile scale, Collision Avoidance System II 6 mile scale, Collision Avoidance System II POPUP traffic, Collision Avoidance System II Resolution
Advisory alerts, Collision Avoidance System II Resolution Advisory
climb priority, Collision Avoidance System II Resolution Advisory
climb warning, Collision Avoidance System II Resolution Advisory
signals, Collision Avoidance System II Resolution Advisory zone,
Collision Avoidance System II Resolution Advisory/Traffic Advisory
alert, Collision Avoidance System II Resolution Advisory/Traffic Advisory alerts/advisories, Collision Avoidance System II Resolution
Advisory/altitude deviation, Collision Avoidance System II Traffic
Advisory Resolution Advisory alerts, Collision Avoidance System II WINDSHEAR warning, Collision Avoidance System II advisory alert, Collision Avoidance System II advisory alert warning,
Collision Avoidance System II warning aircraft
Agreed judges incorrect: Collision Avoidance System II 10 Oclock 2 1/2 3 mile, Collision Avoidance System II Resolution Advisory climb command, Collision Avoidance
System II Resolution Advisory area, Collision Avoidance System
II Resolution Advisory climb descent, Collision Avoidance System II Resolution Advisory data tag, Collision Avoidance System
II Resolution Advisory descent, Collision Avoidance System II Resolution Advisory green band target, Collision Avoidance System II
Resolution Advisory increase climb, Collision Avoidance System II
Resolution Advisory maneuvering, Collision Avoidance System II
Resolution Advisory messages, Collision Avoidance System II Resolution Advisory recovery procedure, Collision Avoidance System
II Resolution Advisory requirement, Collision Avoidance System II
Resolution Advisory requiring climb, Collision Avoidance System
II Resolution Advisory resolution, Collision Avoidance System II
Traffic Advisory notification, Collision Avoidance System II Traffic
Advisory/Resolution Advisory aircraft, Collision Avoidance System
II Traffic Advisory/Resolution Advisory event, Collision Avoidance
System II action requirements, Collision Avoidance System II advice,
Collision Avoidance System II advisories instructions, Collision
Avoidance System II caution, Collision Avoidance System II quit

625

fiAbedin, Ng & Khan

Appendix G: Lexicon Learned Modified Basilisk Categories People
Equipment
following table shows words phrases learned modified Basilisk framework
categories people equipment (see Section 6.7.4).
Category
People

Equipment

New words
Agreed judges correct: First Officer, First Officer, ; First Officer, CP, Captain, Captain RPTR, Captain trainee,
Co-Captain, Co-pilot, First Officer, First Officer # 2, Initial Operating Experience Captain, PAXS, Pilot Flying First Officer,
Potomac controller, RPTING Captain, RPTING First Officer, RPTING pilot, RPTR Captain, RPTR pilot, S/O, ZOA supervisor, air
carrier pilot, aircraft X pilot, aircraft commander, passenger, analyst, First Officer, baron pilot, biplane pilot, controller,
facility person, first observer, flight attendant # 3, flight attendants
passenger, flying Captain, forward observer, passenger, passenger crew, passenger flight attendants, right seat pilot, second observer, sic, specialist, student Captain, supervisor/Controller,
tower Controller, tower operator, training pilot
Identified one judge correct: RPTR, gate passenger,
First Officer
Agreed judges incorrect: departure departure,
neither Captain, CLRLY
Agreed judges correct: # 1 Auto-Pilot, #
2 Auto-Pilot, 3 AUTOPLTS, AUTOFLT, AUTOTHROTTLE,
AUTOTHROTTLE Auto-Pilot, AUTOTHROTTLES, AUTOTHROTTLES Auto-Pilot, AUTOTHRUST, Auto-Pilot
# 1, Auto-Pilot # 2, Auto-Pilot B, Auto-Pilot AUTOTHRUST, Auto-Pilot PMs, Auto-Pilot throttles, AutoPilot/AUTOTHROTTLES, Cessna 180, Collision Avoidance System
II system, ENGS # 2 # 3, aircraft ABCD, aircraft Auto-Pilot,
aircraft engine, allowed aircraft, automatic pilot, automatic throttle,
automatic throttles, autopilot, center Auto-Pilot, craft, emergency
engine, left Auto-Pilot, left hand engine, parked plane, right AutoPilot
Identified one judge correct:
problem engine, maintenance aircraft, later aircraft, aircraft aircraft, Collision
Avoidance System II alert, # 1 Constant Speed Drive, Auto-Pilot
AUTOTHROTTLES, WDB 2, perf
Agreed judges incorrect: aircraft beginning, aircraft
parallel, normal aircraft, person property, persons property,
aircraft, time aircraft

626

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

References
Ando, R. K. (2004). Semantic lexicon construction: Learning unlabeled data via
spectral analysis. Proceedings 8th Conference Computational Natural
Language Learning, pp. 916.
Artstein, R., & Poesio, M. (2008). Inter-coder agreement computational linguistics.
Computional Linguistics, 34 (4), 555596.
Avancini, H., Lavelli, A., Sebastiani, F., & Zanoli, R. (2006). Automatic expansion
domain-specific lexicons term categorization. ACM Transactions Speech
Language Processing (TSLP), 3 (1), 130.
Baker, L. D., & McCallum, A. K. (1998). Distributional clustering words text classification. Proceedings 21st Annual International ACM SIGIR Conference
Research Development Information Retrieval, pp. 96103.
Banko, M., & Brill, E. (2001). Mitigating paucity-of-data problem: Exploring effect training corpus size classifier performance natural language processing.
Proceedings 1st International Conference Human Language Technology
Research.
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. Journal
Machine Learning Research, 3, 9931022.
Brants, T., & Franz, A. (2006). Web 1T 5-gram Version 1. Linguistic Data Consortium,
Philadelphia, USA.
Cheng, P. W. (1997). covariation causation: causal power theory. Psychological
Review, 104 (2), 367405.
Chinchor, N. (1992). statistical significance MUC-4 results. Proceedings
4th Message Understanding Conference, pp. 3050.
Chinchor, N., Hirschman, L., & Lewis, D. D. (1993). Evaluating message understanding systems: analysis Third Message Understanding Conference (MUC-3).
Computational Linguistics, 19, 409449.
Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learning, 20 (3), 273
197.
Crammer, K., & Singer, Y. (2002). algorithmic implementation multiclass kernelbased vector machines. Journal Machine Learning Research, 2, 265292.
Curran, J. R., & Moens, M. (2002). Improvements automatic thesaurus extraction.
Proceedings ACL 2002 Workshop Unsupervised Lexical Acquisition, pp.
5966.
Curran, J. R., Murphy, T., & Scholz, B. (2007). Minimising semantic drift mutual
exclusion bootstrapping. Proceedings 10th Conference Pacific Association Computational Linguistics, pp. 172180.
627

fiAbedin, Ng & Khan

Davidov, D., & Rappoport, A. (2006). Efficient unsupervised discovery word categories
using symmetric patterns high frequency words. Proceedings 21st International Conference Computational Linguistics 44th Annual Meeting
Association Computational Linguistics, pp. 297304.
Dietterich, T. G. (1998). Approximate statistical tests comparing supervised classification learning algorithms. Neural Computation, 10 (7), 18951923.
Dunning, T. (1993). Accurate methods statistics surprise coincidence. Computational Linguistics, 19 (1), 6174.
Everitt, B. S. (1977). Analysis Contingency Tables. Chapman Hall.
Ferryman, T. A., Posse, C., Rosenthal, L. J., Srivastava, A. N., & Statler, I. C. (2006).
happened, why: Toward understanding human error based automated
analyses incident reports Volume II. Tech. rep. NASA/TP2006-213490, National
Aeronautics Space Administration.
Ganeri, J., Noordhof, P., & Ramachandran, M. (1996). Counterfactuals preemptive
causation. Analysis, 56 (4), 219225.
Garcia, D. (1997). COATIS, NLP system locate expressions actions connected
causality links. Proceedings 10th European Workshop Knowledge
Acquisition, Modeling Mangement, pp. 347352.
Girju, R. (2003). Automatic detection causal relations question answering. Proceedings ACL 2003 Workshop Multilingual Summarization Question
Answering, pp. 7683.
Godbole, S., & Sarawagi, S. (2004). Discriminative methods multi-labeled classification.
Proceedings 8th Pacific-Asia Conference Knowledge Discovery Data
Mining, pp. 2230.
Griffiths, T. L., & Tenenbaum, J. B. (2005). Structure strength causal induction.
Cognitive Psychology, 51, 334384.
Grishman, R., & Ksiezyk, T. (1990). Causal temporal text analysis: role
domain model. Proceedings 13th International Conference Computational
Linguistics, pp. 126131.
Halpern, J. Y., & Pearl, J. (2005). Causes explanations: structural-model approach.
Part I: Causes. British Journal Philosophy Science, 56, 843887.
Hassan, H., Hassan, A., & Emam, O. (2006). Unsupervised information extraction approach
using graph mutual reinforcement. Proceedings 2006 Conference Empirical
Methods Natural Language Processing, pp. 501508.
Hume, D. (1999 (Original work published 1748)). Enquiry Concerning Human Understanding. Oxford University Press, USA.
Hume, D. (2000 (Original work published 1739)). Treatise Human Nature. Oxford
University Press, USA.
Joachims, T. (1999). Advances Kernel Methods - Support Vector Learning, chap. Making
large-Scale SVM Learning Practical. MIT-Press.
628

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Joachims, T. (1998). Text categorization suport vector machines: Learning many
relevant features. Proceedings 10th European Conference Machine Learning, pp. 137142.
Joachims, T. (1999). Transductive inference text classification using support vector
machines. Proceedings 16th International Conference Machine Learning,
pp. 200209.
Kaplan, R., & Berry-Rogghe, G. (1991). Knowledge-based acquisition causal relationships
text. Knowledge Acquisition, 3 (3), 317337.
Kersey, C., Di Eugenio, B., Jordan, P., & Katz, S. (2009). KSC-PaL: peer learning agent
encourages students take initiative. Proceedings 4th Workshop
Innovative Use NLP Building Educational Applications, pp. 5563.
Khoo, C. S. G., Chan, S., & Niu, Y. (2000). Extracting causal knowledge medical
database using graphical patterns. Proceedings 38th Annual Meeting
Association Computational Linguistics, pp. 336343.
Ko, Y., Park, J., & Seo, J. (2004). Improving text categorization using importance
sentences. Information Processing Management, 40 (1), 6579.
Krippendorff, K. (2004). Content analysis: introduction methodology. Sage Publications, Inc.
Lewis, D. (1973). Causation. Journal Philosophy, 70 (17), 556567.
Lin, D. (1998). Dependency-based evaluation MINIPAR. Proceedings LREC
Workshop Evaluation Parsing Systems, pp. 317329.
Lin, D., & Pantel, P. (2001). Induction semantic classes natural language text.
Proceedings 7th ACM SIGKDD International Conference Knowledge Discovery Data Mining, pp. 317322.
Marcus, M. P., Santorini, B., & Marcinkiewicz, M. A. (1993). Building large annotated
corpus English: Penn Treebank. Computational Linguistics, 19 (2), 313330.
Special Issue Using Large Corpora.
McCallum, A., & Nigam, K. (1999). Text classification bootstrapping keywords,
EM shrinkage. Proceedings ACL Workshop Unsupervised Learning
Natural Language Processing, pp. 5258.
Noreen, E. W. (1989). Computer-Intensive Methods Testing Hypotheses : Introduction. Wiley.
Pantel, P., & Lin, D. (2002). Discovering word senses text. Proceedings 8th
ACM SIGKDD International Conference Knowledge Discovery Data Mining,
pp. 613619.
Pantel, P., & Ravichandran, D. (2004). Automatically labeling semantic classes. Proceedings Human Language Technology Conference North American Chapter
Association Computational Linguistics, pp. 321328.
Passonneau, R. (2004). Computing reliability coreference annotation. Proceedings
Fourth International Conference Language Resources Evaluation, Vol. 4,
pp. 15031506.
629

fiAbedin, Ng & Khan

Patwardhan, S., & Riloff, E. (2006). Learning domain-specific information extraction patterns web. Proceedings COLING/ACL Workshop Information
Extraction Beyond Document, pp. 6673.
Patwardhan, S., & Riloff, E. (2007). Effective information extraction semantic affinity
patterns relevant regions. Proceedings 2007 Joint Conference Empirical Methods Natural Language Processing Computational Natural Language
Learning, pp. 717727.
Pereira, F. C. N., Tishby, N., & Lee, L. (1993). Distributional clustering English words.
Proceedings 31st Annual Meeting Association Computational Linguistics, pp. 183190.
Phan, X.-H. (2006a). CRFChunker: CRF English Phrase Chunker. http://crfchunker.
sourceforge.net/.
Phan, X.-H. (2006b). CRFTagger: CRF English POS Tagger.
sourceforge.net/.

http://crftagger.

Phillips, W., & Riloff, E. (2007). Exploiting role-identifying nouns expressions information extraction. Proceedings International Conference Recent Advances
Natural Language Processing.
Polanyi, L., & Zaenen, A. (2006). Contextual valence shifters. Computing Attitude
Affect Text: Theory Applications, pp. 110. Springer Verlag.
Posse, C., Matzke, B., Anderson, C., Brothers, A., Matzke, M., & Ferryman, T. (2005).
Extracting information narratives: application aviation safety reports.
Proceedings 2005 IEEE Aerospace Conference, pp. 36783690.
Read, J., Pfahringer, B., & Holmes, G. (2008). Multi-label classification using ensembles
pruned sets. Proceedings 8th IEEE International Conference Data
Mining, pp. 9951000.
Riloff, E. (1996). Automatically generating extraction patterns untagged text.
Proceedings 13th National Conference Artificial Intelligence, pp. 10441049.
Roark, B., & Charniak, E. (1998). Noun-phrase co-occurrence statistics semi-automatic
semantic lexicon construction. Proceedings 17th International Conference
Computational Linguistics, pp. 11101116.
Rohwer, R., & Freitag, D. (2004). Towards full automation lexicon construction.
Proceedings Computational Lexical Semantics Workshop HLT-NAACL 2004,
pp. 916.
Rychly, P., & Kilgarriff, A. (2007). efficient algorithm building distributional
thesaurus (and Sketch Engine developments). Proceedings ACL 2007
Demo Poster Sessions, pp. 4144.
Sebastiani, F. (2002). Machine learning automated text categorization. ACM Computing
Surveys, 34 (1), 147.
Sundheim, B. M. (1992). Overview fourth message understanding evaluation
conference. Proceedings Fourth Message Understanding Conference, pp. 3
21.
630

fiCause Identification via Weakly Supervised Semantic Lexicon Construction

Tang, L., Rajan, S., & Narayanan, V. K. (2009). Large scale multi-label classification via
metalabeler. Proceedings International World Wide Web Conference, pp. 211
220.
Thelen, M., & Riloff, E. (2002). bootstrapping method learning semantic lexicons
using extraction pattern contexts. Proceedings 2002 Conference Empirical
Methods Natural Language Processing, pp. 214221.
Tsoumakas, G., & Katakis, I. (2007). Multi-label classification: overview. International
Journal Data Warehousing Mining, 3 (3), 113.
Tsoumakas, G., & Vlahavas, I. P. (2007). Random k -labelsets: ensemble method
multilabel classification. Proceedings 18th European Conference Machine
Learning, Vol. 4701 Lecture Notes Computer Science, pp. 406417.
Ueda, N., & Saito, K. (2002). Parametric mixture models multi-labeled text. Advances
Neural Information Processing Systems 15, pp. 721728.
van Delden, S., & Gomez, F. (2004). Retrieving NASA problem reports: case study
natural language information retrieval. Data Knowledge Engineering, 48 (2),
231246.
Vapnik, V. N. (1998). Statistical Learning Theory. Wiley.
Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization. Proceedings 14th International Conference Machine Learning,
pp. 412420.
Yangarber, R. (2003). Counter-training discovery semantic patterns. Proceedings
41st Annual Meeting Association Computational Linguistics, pp.
343350.
Zaidan, O. F., Eisner, J., & Piatko, C. (2007). Using annotator rationales improve machine learning text categorization. Proceedings Human Language Technology Conference North American Chapter Association Computational
Linguistics, pp. 260267.
Zhang, Q., Zhou, Y., Huang, X., & Wu, L. (2008). Graph mutual reinforcement based
bootstrapping. Information Retrieval Technology, 4993/2008, 203212.

631

fiJournal Artificial Intelligence Research 38 (2010) 371-413

Submitted 2/10; published 7/10

Approximate Model-Based Diagnosis
Using Greedy Stochastic Search
Alexander Feldman

a.b.feldman@tudelft.nl

Delft University Technology
Mekelweg 4, 2628 CD, Delft, Netherlands

Gregory Provan

g.provan@cs.ucc.ie

University College Cork
College Road, Cork, Ireland

Arjan van Gemund

a.j.c.vangemund@tudelft.nl

Delft University Technology
Mekelweg 4, 2628 CD, Delft, Netherlands

Abstract
propose StochAstic Fault diagnosis AlgoRIthm, called Safari, trades
guarantees computing minimal diagnoses computational efficiency. empirically
demonstrate, using 74XXX ISCAS85 suites benchmark combinatorial circuits,
Safari achieves several orders-of-magnitude speedup two well-known deterministic algorithms, CDA HA , multiple-fault diagnoses; further, Safari compute
range multiple-fault diagnoses CDA HA cannot. also prove Safari
optimal range propositional fault models, widely-used weak-fault
models (models ignorance abnormal behavior). discuss optimality Safari class strong-fault circuit models stuck-at failure modes. modeling
algorithm Markov chain, provide exact bounds minimality diagnosis computed. Safari also displays strong anytime behavior, return diagnosis
non-trivial inference time.

1. Introduction
Model-Based Diagnosis (MBD) area artificial intelligence uses system model,
together observations system behavior, isolate sets faulty components (diagnoses) explain observed behavior according minimality criterion.
standard MBD formalization (Reiter, 1987) frames diagnostic problem terms set
logical clauses include mode-variables describing nominal fault status
system components; diagnostic status system computed given
observation systems sensors. MBD provides sound complete approach
enumerating multiple-fault diagnoses, exact algorithms guarantee finding diagnosis optimal respect number faulty components, probabilistic likelihood,
etc.
biggest challenge (and impediment industrial deployment) computational
complexity MBD problem. MBD problem determining exists diagnosis k faults NP-hard arbitrary propositional models consider
article (Bylander, Allemang, Tanner, & Josephson, 1991; Friedrich, Gottlob, & Nejdl,
1990). Computing set diagnoses harder still, since possibly exponenc
2010
AI Access Foundation. rights reserved.

fiFeldman, Provan, & van Gemund

tially many diagnoses. Since almost proposed MBD algorithms complete
exact, authors proposing possible trade-offs completeness faster
consistency checking employing methods BCP (Williams & Ragno, 2007),
complexity problem still remains major challenge MBD.
overcome complexity problem, propose novel approximation approach
multiple-fault diagnosis, based stochastic algorithm. Safari (StochAstic Fault diagnosis AlgoRIthm) sacrifices guarantees optimality, diagnostic systems
faults described terms arbitrary deviation nominal behavior, Safari
compute diagnoses several orders magnitude faster competing algorithms.
contributions follows. (1) paper introduces approximation algorithm
computing diagnoses within MBD framework, based greedy stochastic algorithm.
(2) show compute minimal-cardinality diagnoses weak fault models
polynomial time (calling incomplete SAT-solver implements Boolean Constraint
Propagation1 (BCP) only), general frameworks (such sub-class strong
fault models) also amenable class algorithm. (3) model Safari search
Markov chain show performance optimality trade-offs algorithm makes.
(4) apply algorithm suite benchmark combinatorial circuits, demonstrating order-of-magnitude speedup two state-of-the-art deterministic algorithms, CDA
HA , multiple-fault diagnoses. (5) compare performance Safari
range Max-SAT algorithms benchmark problems. results indicate that,
whereas search complexity deterministic algorithms tested increases exponentially fault cardinality, search complexity stochastic algorithm appears
independent fault cardinality. Safari great practical significance,
compute large fraction minimal-cardinality diagnoses discrete systems large
complex diagnosed existing deterministic algorithms.

2. Technical Background
discussion continues formalizing MBD notions. paper uses traditional
diagnostic definitions (de Kleer & Williams, 1987), except use propositional logic
terms (conjunctions literals) instead sets failing components.
Central MBD, model artifact represented propositional formula
set variables. Discerning two subsets variables assumable observable 2
variables gives us diagnostic system.
Definition 1 (Diagnostic System). diagnostic system DS defined triple DS =
hSD, COMPS, OBSi, SD propositional theory set variables V , COMPS
V , OBS V , COMPS set assumables, OBS set observables.
Throughout paper assume OBS COMPS = SD 6|=.
propositional theories used system descriptions interest MBD. Diagnostic systems characterized restricted set models, restriction making problem
1. formulae Conjunctive Normal Form (CNF), BCP implemented unit resolution
rule.
2. MBD literature assumable variables also referred component, failure-mode,
health variables. Observable variables also called measurable, control variables.

372

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

computing diagnosis amenable algorithms like one presented paper.
consider two main classes models.
Definition 2 (Weak-Fault Model). diagnostic system DS = hSD, COMPS, OBSi belongs
class WFM iff COMPS = {h1 , h2 , . . . , hn }, SD equivalent (h1 F1 ) (h2
F2 ) . . . (hn Fn ) COMPS V = , V set variables appearing
propositional formulae F1 , F2 , . . . , Fn .
Note conventional selection sign health variables h1 , h2 , . . . hn . Alternatively, negative literals, e.g., f1 , f2 , . . . , fn used express faults, case
weak-fault model form (f1 F1 ) . . . (fn Fn ). authors use ab
abnormal ok healthy.
Weak-fault models sometimes referred models ignorance abnormal
behavior (de Kleer, Mackworth, & Reiter, 1992), implicit fault systems. Alternatively,
model may specify faulty behavior components. following definition,
aim simplifying formalism throughout paper, adopt slightly restrictive
representation faults, allowing single fault-mode per assumable variable.
easily generalized introducing multi-valued logic suitable encodings (Hoos, 1999).
Definition 3 (Strong-Fault Model). diagnostic system DS = hSD, COMPS, OBSi belongs
class SFM iff SD equivalent (h1 F1,1 ) (h1 F1,2 ) . . . (hn Fn,1 )
(hn Fn,2 ) 1 i, j n, k {1, 2}, {hi } COMPS, F{j,k} propositional
formula, none hi appears Fj,k .
Membership testing WFM SFM classes performed efficiently many
cases, example, model represented explicitly Def. 2 Def. 3.
2.1 Running Example
use Boolean circuit shown Fig. 1 running example illustrating
notions algorithms paper. subtractor, shown there, consists seven
components: inverter, two or-gates, two xor-gates, two and-gates. expression
h (o i) models normative (healthy) behavior inverter, variables i,
o, h represent input, output health respectively. Similarly, and-gate modeled
h [o (i1 i2 )] or-gate h [o (i1 i2 )]. Finally, xor-gate specified
h [o (i1 i2 )].
propositional formulae copied gate Fig. 1 variables
renamed way properly connect circuit disambiguate assumables,
thus obtaining propositional formula Boolean subtractor, given by:
SDw = {h1 [i (y p)]} {h2 [d (x i)]} [h3 (j p)]
[h4 (m l j)] [h5 (b k)] [h6 (x l)]
[h7 (k p)]

(1)

strong-fault model Boolean circuit shown Fig. 1 constructed assigning
fault-modes different gate types. assume that, malfunctioning,
output xor-gate value one inputs, or-gate stuck-at-one,
373

fiFeldman, Provan, & van Gemund

x

p

h1

h3



j

h2



h5

b

h6

l

h4

h7



k

Figure 1: subtractor circuit
and-gate stuck-at-zero, inverter behaves like buffer. gives us
following strong-fault model formula Boolean subtractor circuit:
SDs = SDw [h1 (i y)] [h2 (d x)] (h3 j)
(h4 m) (h5 b) [h6 (x l)] (h7 k)

(2)

models (SDs SDw ), set assumable variables COMPS = {h1 , h2 , . . . , h7 }
set observable variables OBS = {x, y, p, d, b}.
2.2 Diagnosis Minimal Diagnosis
traditional query MBD computes terms assumable variables explanations system description observation.
Definition 4 (Health Assignment). Given diagnostic system DS = hSD, COMPS, OBSi,
assignment variables COMPS defined health assignment.
health assignment conjunction propositional literals. cases convenient use set negative positive literals . two sets denoted
Lit () Lit + (), respectively.
example, nominal assignment 1 = h1 h2 . . . h7 . health
assignment 2 = h1 h2 h3 h4 h5 h6 h7 means two and-gates Fig. 1
malfunctioning. follows formal definition consistency-based diagnosis.
Definition 5 (Diagnosis). Given diagnostic system DS = hSD, COMPS, OBSi, observation , instantiation variables OBS, health assignment ,
diagnosis iff SD 6|=.
Traditionally, authors (de Kleer & Williams, 1987) arrive minimal diagnosis computing minimal hitting set minimal conflicts (broadly, minimal health assignments
incompatible system description observation), paper makes
use conflicts, hence equivalent, direct definition above.
total 96 possible diagnoses given SDw observation 1 = x p
b d. Example diagnoses 3 = h1 h2 . . . h7 4 = h1 h2 h3 . . . h7 .
Trivially, given weak-fault model, faulty health assignment (in example
374

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

= h1 . . . h7 ) diagnosis instantiation observable variables OBS
(cf. Def. 2).
analysis algorithm need opposite notion diagnosis, i.e., health
assignments inconsistent model observation. MBD literature
assignments usually called conflicts. Conflicts, however, necessarily instantiate
variables COMPS. paper always use full health instantiations, use
term conflict avoided prevent confusion.
MBD literature, range types preferred diagnosis proposed.
turns MBD problem optimization problem. following definition
consider common subset-ordering.
Definition 6 (Minimal Diagnosis). diagnosis defined minimal, diagnosis
exists Lit ( ) Lit ( ).
Consider weak-fault model SDw circuit shown Fig. 1 observation
2 = x p b d. example, two minimal diagnoses 5 =
h1 h2 h3 h4 h5 h6 h7 6 = h1 h2 . . . h5 h6 h7 . diagnosis
7 = h1 h2 h3 h4 h5 h6 h7 non-minimal negative literals 5 form
subset negative literals 7 .
Note set minimal diagnoses characterizes diagnoses weak-fault
model, hold general strong-fault models (de Kleer et al., 1992).
latter case, faulty components may exonerate other, resulting health
assignment containing proper superset negative literals another diagnosis
diagnosis. example, given SDs 3 = x p b d, follows
8 = h1 h2 h3 h4 . . . h7 diagnosis, 9 = h1 h2 h3 h4 . . . h7
diagnosis, despite fact negative literals 9 form superset
negative literals 8 .
Definition 7 (Number Minimal Diagnoses). Let set (SD ) contain minimal diagnoses system description SD observation . number minimal
diagnoses, denoted | (SD )|, defined cardinality (SD ).
Continuing running example, | (SDw 2 )| = 8 | (SDs 3 )| = 2. number
non-minimal diagnoses SDw 2 61.
Definition 8 (Cardinality Diagnosis). cardinality diagnosis, denoted ||,
defined number negative literals .
Diagnosis cardinality gives us another partial ordering: diagnosis defined minimal
cardinality iff minimizes number negative literals.
Definition 9 (Minimal-Cardinality Diagnosis). diagnosis defined minimalcardinality diagnosis exists | | < | |.
cardinality minimal-cardinality diagnosis computed system description SD
observation denoted MinCard (SD ). example model SDw
observation 4 = x p b d, follows MinCard (SDw 4 ) = 2. Note
case minimal diagnoses also minimal-cardinality diagnoses.
375

fiFeldman, Provan, & van Gemund

minimal cardinality diagnosis minimal diagnosis, opposite need hold.
general case, minimal diagnoses minimal-cardinality diagnoses. Consider example SDw 2 given earlier section, two resulting
minimal diagnoses 5 6 . two, 5 minimal-cardinality diagnosis.
Definition 10 (Number Minimal-Cardinality Diagnoses). Let set (SD ) contain minimal-cardinality diagnoses system description SD observation .
number minimal-cardinality diagnoses, denoted | (SD )|, defined
cardinality (SD ).
Computing number minimal-cardinality diagnoses running example results
| (SDw 2 )| = 2, | (SDs 3 )| = 2, | (SDw 4 )| = 4.
2.3 Converting Propositional Formulae Clausal Form
approach related satisfiability, Safari uses SAT solver. SAT solvers commonly accept input Conjunctive Normal Form (CNF), although exist SAT
solvers work directly propositional formulae (Thiffault, Bacchus, & Walsh, 2004).
Converting propositional formula CNF done (Tseitin, 1983) without
(Forbus & de Kleer, 1993) introduction intermediate variables. cases important structural information lost, may lead performance degradation
checking formula consistent computing solution.
Lemma 1. fault-model SD = F1 F2 . . . Fn (SD WFM SD SFM)
n = |COMPS| component variables converted CNF time O(|COMPS|)
time converting largest subformula Fi (1 n) CNF.
Proof (Sketch). conversion SD CNF done (1) converting subformula
Fi CNF (2) concatenating resulting CNFs final CNF equivalent SD.
complexity (1) O(n) complexity (2) is, worst-case, O(2m ) < ,
largest number variables subformula Fi . result, total time
converting SD dominated linear |COMPS|.
Lemma 1 useful cases subformula Fi small. case many
practical situations SD composed small component models. also case
experimental benchmark (cf. Sec. 6) model combinational circuit
conjunction fault models simple logic gates (x-bit and-gates, typically x < 10,
xor-gates, etc.). Ideally, Safari would use non-CNF SAT solver, practical reasons
constrained reasoning diagnostic models concise CNF encodings.
Consider, example, formula (x1 y1 ) (x2 y2 ) (xn yn ),
Disjunctive Normal Form3 (DNF) and, converted CNF, 2n clauses. Although
similar examples propositional formulae exponentially many clauses CNF
representations easy find, artificial rarely encountered MBD.
Furthermore, Boolean circuits tested performance Safari
show exponential blow-up converted CNF.
3. Note DNF formulae also propositional formulae.

376

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

2.4 Complexity Diagnostic Inference
section discusses complexity problems interested, namely
problem computing single set minimal diagnoses, using two minimality
criteria, subset-minimality () cardinality-minimality (). assume input CNF
formula defined variable set V , = |COMPS| assumable (or fault)
variables. Table 1 introduces notation use define 4 types diagnosis.
Table 1: Summary definitions types diagnosis interest
Symbol

Diagnoses






1
1



Preference Criterion





(subset-minimality)
(cardinality-minimality)
(subset-minimality)
(cardinality-minimality)

complexity computing set diagnoses harder computing single
diagnosis, since number diagnoses is, worst case, exponential input size
(number components). problem bounded problem counting
number diagnoses. problem shown #co-NP -Complete (Hermann
& Pichler, 2007).
restrict clauses Horn definite Horn, reduce complexity
problems solving, expense decreased model expressiveness.
Horn-clause restriction, SD WFM, determining first minimal diagnosis exists
P . restriction, SD SFM, deciding first minimal diagnosis
exists NP-hard (Friedrich et al., 1990). cases (SD WFM, SFM) deciding
next diagnosis exists NP-hard.
diagnosis problems interest article intractable worst-case.
complexity closely-related problem, Propositional Abduction Problems (PAPs),
studied Eiter Gottlob (1995). show propositional PAP,
problem determining solution exists P2 -complete. Computing minimal diagnosis
search problem, hence difficult pose decision question proving
complexity results. Consequently, one note computing diagnosis minimal
respect / requires O(log |COMPS|) calls NP oracle (Eiter & Gottlob,
1995), asking oracle step diagnosis containing k faulty components
exists.
Results abduction problems indicate task approximate diagnosis intractable. Roth (1996) addressed problems abductive inference, approximating inference. Roth focuses counting number satisfying assignments
range AI problems, including instances PAPs. addition, Roth shows
approximating number satisfying assignments problems intractable.
Abdelbar (2004) studied complexity approximating Horn abduction problems,
showing even particular Horn restriction propositional problem interest,
approximation problem intractable. particular, abduction problem
costs assigned assumables (which used model preference-ordering ),
377

fiFeldman, Provan, & van Gemund

examined complexity finding Least Cost Proof (LCP) evidence
(OBS), cost proof taken sum costs hypotheses
must assumed order complete proof. problem shown
NP -hard approximate LCP within fixed ratio r cost optimal solution,
r < 0.
Safari approximates intractable problems denoted Table 1. show
WFM, Safari efficiently compute single diagnosis minimal using
satisfiability oracle. SD SFM, Safari generates sound possibly sub-optimal
diagnosis (or set diagnoses). referred papers indicating intractable
approximate, within fixed ratio, minimal diagnosis. following, adopt
stochastic approach cannot provide fixed-ratio guarantees. However, Safari trades
optimality efficiency compute diagnoses high likelihood.

3. Stochastic MBD Algorithm
section discuss algorithm computing multiple-fault diagnoses using stochastic search.
3.1 Simple Example (Continued)
Consider Boolean subtractor shown Fig. 1, weak-fault model SDw given (1),
observation 4 preceding section. four minimal diagnoses associated
SDw 4 are: 1 = h1 h2 h3 h4 h5 h6 h7 , 2 = h1 h2 h3 h4 h5 h6 h7 ,
3 = h1 h2 . . . h6 h7 , 4 = h1 h2 h3 . . . h6 h7 .
nave deterministic algorithm would check consistency 2|COMPS| possible health assignments diagnostic problem, 128 case running example.
Furthermore, deterministic algorithms first enumerate health assignments small
cardinality high priori probability, renders algorithms impractical
situations minimal diagnosis higher cardinality. performance
surprising even using state-of-the art MBD algorithms utilize, example conflict learning, partial compilation, considering bad worst-case complexity finding
minimal diagnoses (cf. Sec. 2.4).
follows, show two-step diagnostic process requires fewer consistency checks. first step involves finding random non-minimal diagnosis starting
point (cf. Sec. 3.2 details computing random SAT solutions equal likelihood).
second step attempts minimize fault cardinality diagnosis repeated
modification diagnosis.
first step find one random, possibly non-minimal diagnosis SDw 4 .
diagnosis obtain classical DPLL solver modifying two ways: (1)
determine instance satisfiable also extract satisfying solution
(2) find random satisfiable solution every time solver invoked. modifications
trivial, DPLL solvers typically store current variable assignments easy
choose variable value randomly (according uniform distribution) instead
deterministically branching. latter modification may possibly harm DPLL
variable value selection heuristics, later paper see
378

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

concern type problems considering diagnostic systems typically
underconstrained.
subtractor example call DPLL solver SDw 4 input
consider random solution (and obviously diagnosis) 5 = h1 h2 h3 h4 h5
h6 h7 (|5 | = 4). second step stochastic algorithm, try minimize
5 repetitively choosing random negative literal, flipping value positive (thus
obtaining candidate smaller number faults), calling DPLL solver.
new candidate diagnosis, try improve newly discovered diagnosis,
otherwise mark attempt failure choose another negative literal.
constant number failures (two example), terminate search
store best diagnosis discovered far process.
changing sign h7 5 discover new health assignment
consistent SDw 4 , hence diagnosis discard it. Instead,
algorithm attempts changing h6 h6 5 , time successfully obtaining new
diagnosis 6 = h1 h2 h3 h4 h5 h6 h7 cardinality 3. Next algorithm
tries find diagnosis even smaller cardinality randomly choosing h1 h7
6 , respectively, trying change sign, attempts return inconsistency.
Hence climb aborted 6 stored current best diagnosis.
Repeating process another random initial DPLL solution, gives us new diagnosis 7 = h1 h2 h3 h4 h5 h6 h7 . Changing sign h7 , again, leads
inconsistency, next two flips (of h4 h2 ) lead double-fault diagnosis
8 = h1 h2 . . . h6 h7 . diagnosis 8 improved
minimal. Hence next two attempts improve 8 fail 8 stored result.
process illustrated Fig. 2, search 6 left 8 right.
Gates shown solid black suspected faulty health assignment
participate tested consistency, inconsistent candidates crossed-out.
Let us consider result. found two diagnoses: 6 8 , 6
minimal diagnosis. done price 11 calls DPLL subroutine.
suboptimal diagnosis 6 value cardinality near one minimal
diagnosis. Hence demonstrated way find approximation minimal
diagnoses, drastically reducing number consistency checks comparison
deterministic algorithm, sacrificing optimality. Next formalize experience
algorithm, behavior analyze extensively section follows.
Diagnosing strong-fault model known strictly difficult weak-fault
model (Friedrich et al., 1990). many diagnostic instances problem alleviated
fact exist, although without guarantee, continuities diagnostic search
space similar one weak-fault models. Let us discuss process finding
minimal diagnosis subtractors strong-fault model SDs observation 2 (both
Sec. 2.1).
six distinct diagnoses 9 , . . . , 14 SDs 2 shown Fig. 3.
9 10 minimal |9 | = |10 | = 3. visible Fig. 3 diagnoses
component variables h2 h5 false, h1 h7 true (healthy). Hence,
satisfying assignment SDs 2 would contain h1 h2 h5 h7 . Starting
maximal-cardinality diagnosis 14 , must flip variables h3 , h4 , h6 order
reach two minimal diagnoses. key insight that, shown Fig. 3, always
379

fiFeldman, Provan, & van Gemund

Figure 2: example stochastic diagnostic process
h2
9
13
14
h2
9
11
14

h5

h4

h6

h3

h1

h7

























h5

h4

h6

h3

h1

h7

























h2
10
12
14
h2
10
13
14

h5

h4

h6

h3

h1

h7

























h5

h4

h6

h3

h1

h7

























Figure 3: Diagnoses strong-fault model
possible flipping single literal time health faulty receiving another
consistent assignment (diagnosis).
follows formalize experience far stochastic algorithm
finding minimal diagnoses.
3.2 Greedy Stochastic Algorithm
Algorithm 1 shows pseudocode Safari.
380

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Algorithm 1 Safari: greedy stochastic hill climbing algorithm approximating
set minimal diagnoses
1: function Safari(DS, , M, N ) returns trie
inputs: DS = hSD, COMPS, OBSi, diagnostic system
, term, observation
, integer, climb restart limit
N , integer, number tries
local variables: SDcnf , CNF
m, n, integers
, , terms
R, set terms, result
2:
SDcnf WffToCNF(SD)
3:
n = 1, 2, . . . , N
4:
RandomDiagnosis(SDcnf , )
Get random SAT solution.
5:
m0
6:
<
7:
ImproveDiagnosis()
Flip unflipped health variable.

8:
SDcnf 6|=
Consistency check.
9:

10:
m0
11:
else
12:
mm+1
13:
end
14:
end
15:
unless IsSubsumed(R, )
16:
AddToTrie(R, )
17:
RemoveSubsumed(R, )
18:
end unless
19:
end
20:
return R
21: end function

Safari accepts two input parameters: N . N independent searches
start randomly generated starting points. algorithm tries improve
cardinality initial diagnoses (while preserving consistency) randomly flipping fault literals. change sign literal done one direction only: faulty
healthy. attempt find minimal diagnosis terminates unsuccessful attempts improve current diagnosis stored . Thus, increasing lead
better exploration search space and, possibly, diagnoses lower cardinality,
decreasing improve overall speed algorithm.
Safari uses number utility functions. WffToCNF converts propositional
formula SD CNF (cf. Sec 2.3). ImproveDiagnosis subroutine takes term
argument changes sign random negative literal . negative
literals, function returns original argument.
381

fiFeldman, Provan, & van Gemund

implementation RandomDiagnosis uses modified DPLL solver returning
random SAT solution SD . Consider original DPLL algorithm (Davis, Logemann,
& Loveland, 1962) without unit resolution rule. One show if, event
branching, algorithm chooses unassigned variables polarity equal
probability, DPLL algorithm equally likely compute satisfiable solution (if
exists). Note order variables assigned matter. course,
DPLL algorithm may end-up partial assignment, i.e., variables
dont care. problem partial assignment extended
full satisfiable assignment randomly choosing signs unassigned variables
uniform distribution. Taking consideration unit resolution rule,
change likelihood modified DPLL solver finding particular solution
changes order variables assigned. formal proof modified
DPLL solver computes SAT assignment equal probability beyond scope
paper, idea build probabilistic model progress DPLL solver.
probabilistic model balanced tree nodes iterate branching performing
unit resolution (assigning values zero unit clauses). branching probability
set equal leaf nodes (SAT solutions) equal depth, one show
equal likelihood arriving SAT solution. up-to-date SAT solvers based
DPLL, creating randomized DPLL solver computes satisfiable solution
equal probability difficult. course, random polarity decisions may effect negatively
branching heuristics (Marques-Silva, 1999) analysis also beyond scope
paper.
Similar deterministic methods MBD, Safari uses SAT-based procedure
checking consistency SD. increase implementation efficiency Safari,
combine BCP-based LTMS engine (McAllester, 1990) full-fledged DPLL solver
two-stage consistency checking. Experimentation shows combining LTMS DPLL
way allows order-of-magnitude Safari speed-up compared pure DPLL,
soundness completeness properties consistency checking preserved.
implemented two-stage consistency checking follows. First, Safari calls
BCP-based LTMS (Forbus & de Kleer, 1993) check SD |=. result
UNSAT candidate diagnosis.4 LTMS result UNSAT,
means consistency candidate unknown call complete DPLL
engine needed. full DPLL checking use POSIT (Freeman, 1995) MiniSat
(Een & Sorensson, 2003).
Safari benefits two-stage SAT procedure typical MBD instance
involves many consistency checks (O(|COMPS|2 ) N = 1, = |COMPS|). SD
change search time small number assumption clauses
updated, incremental nature LTMS greatly improves search efficiency.
Even though DPLL running time per instance LTMS (DPLL performs
BCP unit propagation), DPLL construction expensive avoided
possible. DPLL initialization typically slow involves building data structures
clauses variables, counting literals, initializing conflict databases, etc.
hand, implementation LTMS incremental (does reinitialized
4. shown BCP consistency check SD returns UNSAT, formula
UNSAT (the opposite necessarily true).

382

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

consistency check) efficient maintains counters clause.
counter keeps number unassigned literals. Assigning value variable
requires decrementing clause counters. counter becomes zero,
contradiction handler signaled.
guarantee two diagnostic searches, starting random diagnoses,
would lead minimal diagnosis. prevent this, store generated
diagnoses trie R (Forbus & de Kleer, 1993), straightforward extract
resulting diagnoses recursively visiting nodes. diagnosis added trie R
function AddToTrie, iff subsuming diagnosis contained R (the IsSubsumed
subroutine checks condition). adding diagnosis resulting trie R,
diagnoses contained R subsumed removed call RemoveSubsumed.
3.3 Basic Properties Greedy Stochastic Search
continue topics completeness optimality, show Safari
sound, i.e., returns diagnoses only.
Lemma 2 (Soundness). Safari sound.
Proof (Sketch). consistency check line 8 Alg. 1 guarantees terms
holds SD 6|= added result set R. According Def. 5
terms diagnoses.
One key factors success proposed algorithm exploitation
continuity search-space diagnosis models, continuity mean
monotonically reduce cardinality non-minimal diagnosis. exploitation continuity property, Safari configured guarantee finding minimal
diagnosis weak fault models polynomial number calls satisfiability oracle.
hypothesis comes next well studied prior work (de Kleer et al., 1992),
determines conditions minimal diagnoses represent diagnoses
model observation. paper interested hypothesis computational
viewpoint: defines class models possible establish theoretical bound
optimality performance Safari.
Hypothesis 1 (Minimal Diagnosis Hypothesis). Let DS = hSD, COMPS, OBSi diagnostic system diagnosis arbitrary observation . Minimal Diagnosis Hypothesis (MDH) holds DS iff health assignment Lit () Lit ( ),
also diagnosis.
easy show MDH holds weak-fault models. theories
SD 6 WFM MDH holds (e.g., one directly construct theory conjunction
terms MDH holds). Unfortunately, necessary condition known MDH
hold arbitrary SD. lemma comes next direct consequence MDH
weak-fault models.
Lemma 3. Given diagnostic system DS = hSD, COMPS, OBSi, SD WFM,
diagnosis observation , follows non-minimal iff another diagnosis
obtained changing sign exactly one negative literal .
383

fiFeldman, Provan, & van Gemund

Proof (Sketch). Def. 2 SD WFM, follows minimal diagnosis,
diagnosis obtained flipping one positive literal also diagnosis. Applying
argument direction gives us statement.
Safari operates performing subset flips non-minimal diagnoses, attempting compute minimal diagnoses. next formalize notion flips, order characterize
Safari able compute minimal diagnosis.
Definition 11 (Subset Flip ). Given diagnostic system DS = hSD, COMPS, OBSi
health assignment non-empty set negative literals (Lit () 6= ), subset
flip turns one negative literals positive literal, i.e., creates health
assignment one positive literal.
next characterize flips based whether produce consistent models flip.
Definition 12 (Valid Subset Flip). Given diagnostic system DS = hSD, COMPS, OBSi,
observation , non-minimal diagnosis , valid flip exists perform
subset flip create SD 6|=.
Given notions, define continuity diagnosis search space terms literal
flipping.
Definition 13 (Continuity). system model SD observation satisfy continuity
property respect set diagnoses (SD), iff diagnosis k (SD)
exists sequence = h1 , 2 , , k1 , k , k+1 , , n i, =
1, 2, , n 1, possible go i+1 via valid subset flip, (SD ),
n (SD ).
definition allows trivial continuity cases model observation lead minimal diagnoses (no non-minimal diagnoses). see Sec. 6,
models observations diagnoses minimal rare practice (of course,
problems created artificially). Note Safari algorithm still works
theoretical properties preserved even case trivial continuity.
Given Def. 13, easily show following two lemmata:
Lemma 4. SD satisfies MDH, satisfies continuity property.
Proof. Follows directly Hypothesis 1 Def 13.
Lemma 5. SD WFM satisfies continuity property.
Proof (Sketch). straightforward show SD WFM SD satisfies MDH.
Lemma 4 follows SD satisfies continuous property.
greedy algorithm starts initial diagnosis randomly flips faulty assumable variables. use MDH property show that, starting non-minimal
diagnosis , greedy stochastic diagnosis algorithm monotonically reduce size
seed diagnosis obtain minimal diagnosis appropriately flipping fault
variable faulty healthy; view flipping search, search continuous diagnosis space.
384

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Proposition 1. Given diagnostic system DS = hSD, COMPS, OBSi, observation ,
SD WFM, Safari configured = |COMPS| N = 1 returns one minimal
diagnosis.
Proof. diagnosis improvement loop starts, worst case, health assignment
conjunction negative literals only. Necessarily, case, diagnosis
SD WFM. diagnosis subsumed would found
consistency checks (provided exists) set equal number literals
repetitions randomly choosing literal flip next. If,
trying negative literals , diagnosis, Lemma 3 follows
minimal diagnosis.
simple inductive argument, continue process obtain
minimal diagnosis.
Proposition 1 follows upper bound O(|COMPS|) consistency
checks finding single minimal diagnosis. practical cases, however,
interested finding approximation minimal-cardinality diagnoses. result
complexity optimally configured Safari algorithm becomes O(|COMPS|2 S),
number minimal-cardinality diagnoses given observation. Section 5
discusses detail computation multiple minimal-cardinality diagnoses.
number assumable variables system practical significance may exceed
thousands, rendering optimally configured Safari computationally expensive.
Sec 4 see computationally efficient configure < |COMPS|,
still possible find minimal diagnosis high probability.
simple show flip-based search algorithms complete continuous diagnosis search spaces given weak fault models, i.e., SD WFM, models follow
MDH, i.e., Lemma 3. formally characterize guarantee finding minimal diagnosis Safari terms continuous diagnosis space. Note sufficient,
necessary, condition; example, may configure Safari flip multiple literals
time circumvent problems getting trapped discontinuous diagnosis spaces.
Theorem 1. Given diagnostic system DS = hSD, COMPS, OBSi, starting diagnosis
, Safari configured = |COMPS| N = 1 guaranteed compute minimal
diagnosis diagnosis space continuous.
Proof. Given initial diagnosis , Safari attempts compute minimal diagnosis
performing subset flips. diagnosis space continuous, know exists
sequence valid flips leading minimal diagnosis. Hence Safari guaranteed find
minimal diagnosis .
Finally, show Safari provides strong probabilistic guarantee computing
minimal diagnoses.
Theorem 2. probability Safari, configured = |COMPS|, computing
minimal diagnoses diagnostic system DS = hSD, COMPS, OBSi observation
denoted Pr . Given continuous diagnosis space (SD, ), holds Pr 1
N .
385

fiFeldman, Provan, & van Gemund

Proof (Sketch). Since (1) search space continuous, (2) step non-zero
probability flipping unflipped literal, (3) polynomial upper bound
steps (|COMPS|) computing diagnosis, Safari compute non-minimal diagnosis
non-zero probability. Hence N , Safari compute minimal diagnoses.

3.4 Complexity Inference Using Greedy Stochastic Search
next look complexity Safari, stochastic approach computing sound
incomplete diagnoses. show primary determinant inference complexity consistency checking. Safari randomly computes partial assignment ,
checks extended create satisfying assignment consistency
check, i.e., checks consistency SD. solving satisfiability problem (SAT), NP-complete (Cook, 1971). show use incomplete
satisfiability checking reduce complexity, cost completeness guarantees.
following, call complexity consistency check, assume
components fail, i.e., = |COMPS|.
Lemma 6. Given diagnostic system DS = hSD, COMPS, OBSi SD WFM,
worst-case complexity finding minimal diagnosis O( 2 ), cost
consistency check.
Proof. upper bound succeeding consistency checks finding single
minimal diagnosis since maximum steps computing healthy
diagnosis. Safari performs consistency check flip step
algorithm must flip literals, total complexity O( 2 ).
practical cases, however, interested finding approximation minimal-cardinality diagnoses.

result complexity optimally configured Safari


||
algorithm becomes , || cardinality minimal-cardinality
diagnoses given observation (cf. Sec. 6.6).
complexity BCP well-known, allowing us get precise bounds
worst-case complexity computing one minimal-diagnosis Safari. follows
assume SD represented CNF (cf. Sec. 2.3).
Lemma 7. Given diagnostic system DS = hSD, COMPS, OBSi, SD WFM, SD
c clauses n variables, worst-case complexity WFM finding
minimal diagnosis O( 2 cn) using BCP consistency checks.5
Proof (Sketch). implementation BCP (Forbus & de Kleer, 1993) maintains total
c counters number unsatisfied literals clause. consistency check requires
decrementing counters n variables SD. gives us upper
bound O(cn) execution time BCP. Combining complexity BCP
Lemma 6 gives us desired result.
5. efficient implementations BCP exist (Zhang & Stickel, 1996).

386

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

4. Optimality Analysis (Single Diagnosis)
contrast deterministic algorithms, Safari algorithm absolute guarantee optimum solution (minimal diagnosis) found. provide
intuition behind performance Safari algorithm means approximate,
analytical model estimates probability reaching diagnostic solution specific
minimality.
4.1 Optimality Safari Weak-Fault Models
start considering single run algorithm without retries
assume existence one minimal diagnosis. Next, extend model
considering retries.
4.1.1 Basic Model
Consider diagnostic system DS = hSD, COMPS, OBSi SD WFM,
observation manifests one minimal diagnosis . argument
follows configure Safari = 1, N = 1, assume starting
solution trivial faulty diagnosis.
Safari randomly chooses faulty variable flips it, saying
success new candidate diagnosis, failure otherwise. Let k denote
number steps algorithm successfully traverses direction minimal
diagnosis cardinality ||. Thus k also measures number variables whose values
flipped faulty healthy process climbing.
Let f (k) denote probability distribution function (pdf) k. following
derive probability p(k) successfully making transition k k + 1. diagnosis
step k k positive literals |COMPS| k negative literals. probability
next variable flip successful equals probability next negative positive
flip H k negative literals conflict negative literal belonging
diagnosis solution . Consequently, || k literals COMPS| || k literals
allowed flip, therefore success probability equals:
p (k) =

||
|COMPS| || k
=1
|COMPS| k
|COMPS| k

(3)

search process modeled terms Markov chain depicted Fig. 4,
k equals state algorithm. Running inconsistency modeled
transitions state denoted fail.
probability exactly attaining step k (and subsequently failing) given by:
f (k) = (1 p(k + 1))

k


p(i)

(4)

i=0

Substituting (3) (4) gives us pdf k:

k

||
||
1
f (k) =
|COMPS| k + 1
|COMPS|
i=0

387

(5)

fiFeldman, Provan, & van Gemund

k=0

1 p(0)

p(0)

k=1

1 p(1)

p(1)

k=2

1 p(2)

p(i)

k=i

p(n 1)

1 p(i + 1)

k=n

1

fail

Figure 4: Model Safari run = 1 single diagnosis (n = |COMPS| ||)

optimum goal state k = |COMPS| || failure probability term (5) correct
equals unity.
p independent k, f would geometrically distributed, implies
chance reaching goal state k = |COMPS||| slim. However, fact p decreases
k moves probability mass tail distribution, works favor
reaching higher-k solutions. instance, single-fault solutions (|| = 1) distribution
becomes uniform. Figure 5 shows pdf problem instances |COMPS| = 100
increasing fault cardinality ||. order decrease sampling noise, empirical f (k)
values Fig. 5 computed taking average 10 samples k.
0.1

0.1
|| = 1
|| = 5
|| = 10

0.08

|| = 1
|| = 5
|| = 10

0.08

f(k)

0.06

f(k)

0.06
0.04

0.04

0.02

0.02

0

0

20

40

60

80

100

k

0

0

20

40

60

80

100

k

Figure 5: Empirical (left) analytic (right) f (k) retries single diagnosis
next section show retries move probability mass towards
optimum, increasing tail distribution, needed (almost always) reaching
optimality.
4.1.2 Modeling Retries
section extend model account retries, profound effect
resulting pdf f . Again, consider transition step k k + 1,
algorithm spend = 1, . . . , retries exiting failure.
388

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

seen algorithm (cf. Alg. 1), variable flip produces inconsistency retry
executed incremented.
elementary combinatorics compute probability diagnosis
flipping different negative literals step k. Similar (3), stage k
|COMPS| k faulty literals chosen (as variable flips leading
inconsistency recorded attempted again, difference choosing
variables advance one another). probability advancing stage
k stage k + 1 becomes:
||
p (k) = 1


|COMPS|k


(6)

progress Safari modeled values > 1 Markov chain, similar
one shown Fig. 4 transition probability p replaced p . resulting
pdf number successful steps becomes:
#
"
k
||
||




(7)
1 |COMPS|i
f (k) = |COMPS|k+1


i=0



seen (5) restricted case (7) = 1.
retry effect shape pdf profound. Whereas single-fault solutions
shape = 0 uniform, = 1 probability mass already located
optimum k = |COMPS| ||. Fig. 6 plots f number problem instances
increasing . expected, effect extremely significant. Note case
real system, = |COMPS| pdf would consist single, unit probability spike
|COMPS| ||.
Although unable find analytic treatment transition model above,
graphs immediately show large probability moving k = |COMPS| ||
large. Hence, expect pdf considerable probability mass located
k = |COMPS| ||, depending relative |COMPS|.
4.2 Optimality Safari Strong-Fault Models
analysis seen WFM easy, starting non-minimal
diagnosis, reach subset minimal diagnosis. discussed detail below,
necessarily case strong-fault models. many practical cases, however,
strong-fault models exhibit, least partially, behavior similar MDH, thus allowing greedy
algorithms like Safari achieve results close optimal values.
4.2.1 Partial Continuity Strong-Fault Stuck-At Models
follows restrict attention large subclass SFM, called SFSM
(Struss & Dressler, 1992).
Definition 14 (Strong-Fault Stuck-At Model). system DS = hSD, COMPS, OBSi belongs class SFSM iff SD equivalent (h1 F1 ) (h1 l1 ) (hn
Fn ) (hn ln ) 1 i, j n, {hi } COMPS, Fj propositional formula,
none hi appears Fj , lj positive negative literal Fj .
389

fiFeldman, Provan, & van Gemund

M=2

M=2

0.04

0.04
|| = 5
|| = 10

0.03
f(k)

f(k)

0.03

0.02

0.01

0

|| = 5
|| = 10

0.02

0.01

0

20

40

60

80

0

100

0

20

40

k
M=4

100

60

80

100

0.12
|| = 5
|| = 10

0.1

|| = 5
|| = 10

0.1
0.08
f(k)

0.08
f(k)

80

M=4

0.12

0.06

0.06

0.04

0.04

0.02

0.02

0

60
k

0

20

40

60

80

100

k

0

0

20

40
k

Figure 6: Empirical (left) analytic (right) f (k) multiple retries single diagnosis

MDH (cf. Hypothesis 1) hold SFSM models. Consider adder whose inputs
outputs zeroes, whose gate models stuck-at-1 faulty.
case, nominal assignment diagnosis, but, example, stuck-at-1 output gate
diagnosis (there contradiction zero output).
Many practical observations involving SFSM models, however, lead partial continuity. means groups diagnoses differ one literal, i.e.,
flip based search improve cardinality diagnosis. next formalize notion.
Definition 15 (Partial Continuity). system model SD observation satisfy
partial continuity property respect set (SD ), iff every diagnosis
satisfying Lit () \ Lit (i ) exists finite sequence valid subset
flips .
one extreme spectrum, SD satisfy partial continuity property
respect set diagnoses extreme, partial continuity
390

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

property satisfied respect singleton (consider, example, SD WFM
consists single faulty diagnosis).
Note continuous property trivally satisfied respect diagnosis
k (SD ), i.e., always exists sequence containing k ( = hk i).
interested non-trivial cases, || > 1.
Consider system SD observation satisfy partial continuity property
respect diagnosis k . say diagnoses flip sequence
contains k form continuous subspace. Alternatively, given diagnostic system SD
observation , continuous diagnostic subspace SD set diagnoses (SD)
property that, diagnosis , another diagnosis
|Lit ()| |Lit ()| = 1.
Unfortunately, general SFSM case, cannot derive bounds sizes
continuous subspaces, hence, optimality Safari. follows,
help examples, illustrate fact partial continuity depends
model observation express optimality Safari function
topologically-dependent property. Later, Sec. 6, collect empirical data continuous
subspaces leading near-optimal diagnoses exist class benchmark SFSM circuits.
first example illustrates notion discontinuity (lack partial continuity
respect diagnoses). show rare example model observation
leading set diagnoses contains diagnoses cardinality + q (q > 1),
diagnoses cardinality + 1, + 2, , + q 1.
Discontinuity Example Consider, example, Boolean circuit shown Fig. 7
modeled propositional formula:

[h1 (y x)] [h1 (y x)]
(8)
SDd =
[h2 (y x)] [h2 (y x)]
observation = x y. Note, SDd 6 SFSM. exactly two diagnoses
SDd : 15 = h1 h2 16 = h1 h2 . Note model cannot single
faults. 15 minimal, |15 | = 0, |16 | = 2, algorithm starts 16
possible reach minimal diagnosis 15 performing single flips. Similarly
construct models impose arbitrarily bad bound optimality Safari.
models, however, common see greedy algorithm performs
well wide class strong-fault models.
h1
x


h2

Figure 7: two inverters circuit
Obviously, continuity distribution cardinalities set diagnoses necessary (but sufficient) condition Safari progress. models impose arbitrary
difficulty Safari, leading suboptimal diagnoses cardinality.
391

fiFeldman, Provan, & van Gemund

Example Partial Continuity continue running example started Sec. 2.
First, create system description SDsa SFSM model. Let SDsa = SDw SDf ,
SDw given (1). second part SDsa , strong fault description SDf ,
specifies output faulty gate must stuck-at-1:
SDf = (h1 i) (h2 d) (h3 j) (h4 m)
(h5 b) (h6 l) (h7 k)

(9)

clear SDsa SFSM. next compute diagnoses SDsa 1 (1 = x
p b d). one minimal diagnosis SDsa 1 5 = h1 h2 h3 h7
(cf. Fig. 8). choose two literals h3 h4 5 change signs h3
h4 , create two new health assignments: 15 = h1 h2 h3 h4 h5 h6 h7
16 = h1 h2 h3 h4 h5 h6 h7 . checked 15 16
diagnoses, i.e., SDsa 1 15 6|= SDsa 1 16 6|=. Note 15 16
diagnoses weak-part model, i.e., {15 , 16 } (SDw 1 ). follows
MDH fact 5 minimal diagnosis SDw 1 . Furthermore, 15 also
diagnosis strong-fault stuck-at model (15 (SDsa 1 )) SDw 1 h3
lead contradictory value j strong-fault part SDf . similar argument
applies 16 : SDw 1 h4 contradict SDf . Equivalently, negating h3
5 , makes j stuck-at-1, results diagnosis, negating h4 5 , makes
stuck-at-1, also results diagnosis, negating h3 h4 5 also result
diagnosis (consider fact fault mode h4 sets only, impose
constraints j). argument extended similarly h5 , h6 , h7 . Hence,
assignment COMPS containing h1 h2 diagnosis SDsa 1 , matter
combination signs take h3 , h4 , h5 , h6 , h7 . Note health assignment
containing h4 diagnosis conditioned k = 1.
x=1
y=1
p=1

h2

d=0

h6

h1
i=1

l=0
h4

h3

m=0

j=1

h5

b=1

h7
k=1

Figure 8: Continuous subspace strong-fault, stuck-at-1 model subtractor
Consider alternative way computing set ambiguous diagnoses SDsa 1 . Given
SDsa 1 5 , compute consistent assignment internal variables (for example
propagation). exactly one assignment = j k l m,
SDsa 1 5 6|= (cf. Fig. 8). Note components h1 , h3 , h5 , h7 ,
change state component (healthy faulty) lead different output
value. example output j h3 or-gate 1 gate healthy
392

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

inputs 1 j would also 1 stuck-at-1 or-gate (h3 ). result, diagnostic
reasoner determine components dashed region Fig. 8 healthy faulty
(stuck-at-1). Equivalently, one change signs h3 , h5 , h7 diagnosis 5
resulting assignments still diagnoses. call set components modeled
h1 , h3 , h5 , h7 ambiguity group. Clearly, Safari start diagnosis
17 = h1 h2 h3 h4 h5 h6 h7 (|17 | = 4) reach 5 (|5 | = 1)
performing valid subset flips.
make reasoning precise, restrict class SFSM models exclude malformed circuits ones disconnected inputs outputs, etc. Furthermore,
assume component exactly one output (the set component output variables denoted COUT). latter big restriction multi-output component
models replaced multiple components, single output.6
Definition 16 (Well-Formed Diagnostic System (Wfds)). diagnostic system DS =
hSD, COMPS, OBSi well-formed (DS Wfds) iff observation
diagnosis (SD ), exactly one assignment component outputs
COUT SD 6|=.
Consider SFSM model SD = (h1 F1 ) (h1 l1 ) (hn Fn ) (hn ln ).
denote COMPS set hi (1 n) respective li literals
negative (cf. Def. 14), i.e., COMPS set components whose failure modes stuckat-0. Similarly, use COMPS+ set component variables whose stuck-at li literals
positive (COMPS COMPS+ = COMPS, COMPS COMPS+ = ). Wfds,
observation diagnosis force output component either negative
positive value. denote set health variables whose respective component
outputs forced negative values G (DS, , ). Similarly, G+ (DS, , )
components whose outputs positive values. define notion
component ambiguity group.
Definition 17 (Component Ambiguity Group). Given system DS = hSD, COMPS, OBSi,
SD SFSM, SD Wfds, observation , diagnosis (SD), component
ambiguity group U(DS, , ), U COMPS, defined U(DS, , ) = {G (DS, , )
COMPS } {G+ (DS, , ) COMPS+ }.
Finally, show component ambiguity group leads continuous subspace.
general case cannot say much size component ambiguity groups.
experimentation, noticed difficult assign inputs SFSM
values generate small continuous subspaces (either SD |=, SD leads
large component ambiguity groups). course, possible consider adder,
multiplier, example, whose inputs zeroes whose gate models stuck-at-1
faulty, number inputs/circuit combinations small.
Proposition 2. diagnostic system SD, SD SFSM, SD Wfds, observation
entail continuous diagnostic subspaces.
6. multi-output Boolean function replaced composition single-output Boolean functions.

393

fiFeldman, Provan, & van Gemund

Proof. Def. 16 fact SD Wfds follows output values
subset components sign models stuck-at value. denote
set COMPS , COMPS COMPS. health assignment differs signs
components belonging COMPS also diagnosis. set diagnoses SD
contains possible assignments assumables COMPS diagnoses form
continuous space (cf. Def. 17).
best illustrate Proposition 2, consider or-gate modeled h3 Fig. 8. output
1 either gate healthy one gates inputs 1, gate
stuck-at-1. situation, possible determine component healthy
faulty.
Clearly, |U(DS, , )| lower bound progress Safari stuck-at models.
shown Safari starts diagnosis maximum cardinality
given subspace, Safari guaranteed (for = |COMPS|) improve cardinality
least |U(DS, , )|. practice, Safari proceed even stuckat ambiguity groups one factor diagnostic uncertainty. stuck-at component
effectively disconnects inputs outputs, hence gates fan-in region
constrained. instance, continuing example, h5 , predecessors cone
h5 (components h3 , h4 , h5 , h6 , h7 ) constitute continuous health subspace.
Contrary component ambiguity group, set conditional health state
another component. thorough study stuck-at continuity outside scope
paper shall see Sec. 6, continuous subspaces justify Safari experiments
stuck-at models.
4.2.2 Performance Modeling Stuck-At Models
study optimality Safari strong-fault models, first define case
algorithm cannot improve non-minimal diagnosis changing sign
faulty literal. Note existence cases sufficient condition Safari
suboptimal, possible reach minimal diagnosis first changing sign
faulty literal, thus circumventing missing diagnosis.
preceding section know number invalid flips depend
k, i.e., determined observation vector fault modes. probability
Safari progress non-minimal diagnosis becomes
p(k) = 1

||+|X|

|COMPS|k


(10)

|X| number invalid flips. ratio number invalid flips |X|
|COMPS| call SFM density d. density gives average probability trying
invalid flip throughout diagnostic search. approximation probability
success Safari is:
p(k) = 1

||

|COMPS|k


394



(11)

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Plugging p (4) allows us predict f (k) SFM models assumptions
hold. pdf, measured implementation Safari generated (4)
(11) shown Fig. 9 different values density d.
= 4, |COMPS| = 100, || = 10

= 4, |COMPS| = 100, || = 10

0.12

0.12
d=0
= 0.1
= 0.25
= 0.5

0.1

0.08
f(k)

f(k)

0.08
0.06

0.06

0.04

0.04

0.02

0.02

0

0

20

40

60

d=0
= 0.1
= 0.25
= 0.5

0.1

80

100

k

0

0

20

40

60

80

100

k

Figure 9: Empirical (left) analytic (right) f (k) various diagnostic densities, multiple
retries single diagnosis

Fig. 9 visible increasing density leads shift probability
density length walk k left. effect, however, profound
even large values d, easily compensated increasing , discussed
preceding sections.
interesting note bounds computed SD (independent ),
bounds used improve performance Safari.
4.3 Validation
preceding sections illustrated progress Safari synthetic circuits
exposing specific behavior (diagnoses). remainder section plot pdf
greedy search one small benchmark circuits (for information
74181 model cf. Sec. 6).
progress Safari weak-fault model 74181 circuit shown Fig. 10.
chosen difficult observation leading minimal diagnosis cardinality 7 (left)
easy observation leading single fault diagnosis (right). plots show
probability mass shifts right increasing effect profound
smaller cardinality.
effect stuck-at-0 stuck-at-1 fault modes (SFM) probability
success Safari shown Fig. 11.
Obviously, case effect increasing smaller, although still depending
difficulty observation vector. Last, even small values , absolute
probability Safari finding minimal diagnosis sizeable, allowing use Safari
395

fiFeldman, Provan, & van Gemund

74181, || = 7

74181, || = 1

0.5

0.5
M=1

M=1

M=2

0.4

M=2

0.4

M=3
0.3

M=3
0.3

0.2

0.2

0.1

0.1

0

0

10

20

M=4

f(k)

f(k)

M=4

30
k

40

50

0
30

60

40

50
k

60

70

Figure 10: Empirical f (k) weak-fault model 74181 circuit observations
leading two different minimal-cardinality diagnoses various

74181, || = 6, S-A-0

74181, || = 6, S-A-1

0.2

0.2
M=1

0.15

M=4
0.1

0.05

0
20

M=2

0.15

M=3
f(k)

f(k)

M=1

M=2

M=3
M=4

0.1

0.05

30

40
k

50

60

0
10

20

30

40

50

60

k

Figure 11: Empirical f (k) stuck-at-0 stuck-at-1 strong-fault models 74181
circuit various

practical anytime algorithm always returns diagnosis, optimality
depends time allocated computation.

5. Optimality Analysis (Multiple Diagnoses)
preceding section described process computing one diagnosis Safari (N =
1). section discuss use Safari computing (or counting) minimalcardinality diagnoses (N > 1). rest section assume Safari
configured = |COMPS|.
396

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Consider system description SD (SD WFM) observation . number
minimal diagnoses | (SD )| exponential |COMPS|. Furthermore, practice, diagnosticians interested sampling set minimal-cardinality diagnoses
(SD ) (recall (SD ) (SD )) minimal-cardinality diagnoses
cover significant part posteriori diagnosis probability space (de Kleer, 1990).
follows, see Safari well suited task.
Theorem 3. probability Safari configured = |COMPS| computing minimal diagnosis cardinality || system |COMPS| component variables approaches
|COMPS||| |COMPS|/|| .
Proof (Sketch). Assume minimal diagnosis cardinality || exists. Proposition 1
follows Safari configured = |COMPS| guaranteed compute minimal
diagnoses. Starting faulty assignment, consider step k improving
diagnosis cardinality. state k contains one diagnosis, state k+1, Safari
either (1) flip literal belonging diagnosis (note literal may belong
one diagnosis) subsequently prevent Safari reaching diagnosis
(2) flip literal belonging diagnosis already invalidated (i.e., one
literals flipped earlier step).
probability solution cardinality || survives flip iteration k (i.e.,
invalidated) is:
p (k) = 1

|COMPS| || k
||
=
|COMPS| k
|COMPS| k

(12)

Similarly basic model (Sec. 4.1.1), probability diagnosis survives
returned algorithm:
|COMPS|||1



f (|COMPS| || 1) =

|COMPS|||1

p(i) =

i=0


i=0

|COMPS| ||
|COMPS|

(13)

Rewriting right hand side Eq. (13) gives us:
f (|COMPS| || 1) =

(|COMPS| ||)!
||!(|COMPS| ||)!
=
(|| + 1)(|| + 2) |COMPS|
|COMPS|!

(14)

Since
1
(|COMPS| ||)!
=
|COMPS|!
(|COMPS| || + 1)(|COMPS| || + 2) |COMPS|

(15)

holds
(|COMPS| ||)!
= |COMPS|||
|COMPS|!
|COMPS|/||
lim

(16)

result, small || relative |COMPS|,
f (|COMPS| || 1) = ||!|COMPS|||
gives us theorem.
397

(17)

fiFeldman, Provan, & van Gemund

distribution hi (||) cardinalities minimal diagnoses (SD ) depends
topology SD ; i.e., create SD hi (||). denote
cardinality distribution minimal diagnoses computed Safari h(||).
Theorem 3 gives us termination criterion Safari used enumerating
counting minimal-cardinality diagnoses. Instead running Safari
P fixed N ,
sufficient compute area output distribution function
h. value
P
converge single value, hence terminate Safari change
h
drops fixed threshold. Note Safari efficient enumerating minimalcardinality diagnoses, computed probability exponentially higher
probability computing minimal diagnoses higher-cardinality, shown
Theorem 3.
Corollary 1. Safari computes diagnoses equal cardinality equal probability.
Proof (Sketch). Theorem 3 follows probability success f Safari
computing diagnosis depends || actual composition .
corollary gives us simple termination criterion Safari cases
minimal diagnoses also minimal-cardinality diagnoses; proven
case minimal-cardinality diagnoses computed probability.
see that, given input cardinality distribution hi (||), Safari produces
output distribution h(||) highly skewed right, due Theorem 3. facilitate
study Safari transforms hi (||) h(||) use Monte Carlo simulation
Safari. advantage Monte Carlo simulation much simpler analysing
run-time behavior Safari studying algorithm itself.
Algorithm 2 Monte Carlo simulation Safari
1: function SafariSimulate(, N ) returns cardinality distribution
inputs: , set minimal diagnoses
N , integer, number tries
local variables: hi , h, vectors, cardinality distributions
b, vector, fault distribution, n, i, c, integers
2:
hi CardinalityDistribution( )
3:
n 1, 2, . . . , N
4:
c 1, 2, . . . , |hi |
5:
b[c] c hi [c]
6:
end
7:
1, 2, . . . , | |

8:
c DiscreteInverseRandomValue Pb b
9:
b[c] b[c] c
10:
end
11:
h[c] h[c] + 1
12:
end
13:
return h
14: end function
398

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Algorithm 2 simulates diagnoses input set minimal diagnoses
reached Safari N tries. auxiliary subroutine CardinalityDistribution
computes input distribution hi iterating diagnoses . store input
cardinality distribution hi resulting cardinality distribution h vectors (note
vector sums lines 7 8 division vector scalar line 8).
outermost loop Alg. 2 (lines 3 12) simulates N runs Safari. done
computing updating auxiliary vector b, contains distribution
component variables according cardinalities diagnoses variables
belong to. Initially, b initialized number literals single faults position 1,
number literals double faults position 2 (for example three double
faults hi , b[2] = 6), etc. done lines 4 6 Alg. 2. assume diagnoses
share literals. restriction easily dropped counting assumables
input (the latter assumption change results section).
Lines 7 10 simulate process actual bit flipping Safari. step
simulation draws random literal probability distribution function (pdf ) Pb b ;
done DiscreteInverseRandomValue function line 8. bit flip
invalidates diagnosis set , i.e., diagnosis cardinality c cannot reached
Safari. diagnosis invalidated, vector b updated, example,
simulation invalidates quadruple fault, b[4] = b[4] 4 (line 9). Note number
iterations loop lines 7 10 equals number diagnoses . result
terminating loop, value integer variable c equal cardinality
last invalidated diagnosis. latter diagnosis Safari computes
run. remains update resulting pdf right cardinality (line 11).
simulation Alg. 2 links distribution actual diagnoses
distribution cardinalities diagnoses returned Safari. arbitrarily set, apply Alg. 2 range typical input distributions. results
simulation well results running Safari synthetic problems
input distributions shown Fig. 12.
Fig. 12 shows (1) Alg. 2 predicts actual behavior Safari (compare second
third column plots), (2) Safari computes diagnoses small cardinality
agreement Theorem 3. case output distribution steep
exponential cardinalities set input minimal diagnoses grow exponentially. Table 2 summarizes parameters exponential fits input cardinality
distributions shown Fig. 12 (a initial (zero) cardinality, decay constant,
R2 coefficient determination). seen Safari suited computing
multiple diagnoses small probability occurrence. next section provide
alternative argument leading similar conclusions.

6. Experimental Results
section discusses empirical results measured implementation Safari. order compare optimality performance Safari various diagnostic algorithms,
performed million diagnosis computations 64 dual-CPU nodes belonging cluster. node contains two 2.4 GHz AMD Opteron DP 250 processors
4 Gb RAM.
399

fiFeldman, Provan, & van Gemund

degenerate input

prediction (model)

0.5
0

1

h(||)

1

h(||)

h(||)

1

0.5
0

0

50
||

100

0

0.5
0

50
||

100

0
0

50
||

100

h(||)

h(||)

0.2
0.1

20

exponential input

10
||

0

h(||)

h(||)
20
||

40

0

prediction (model)
0.3

5

10

||

0.2
0.1
0

40

0.3

h(||)

h(||)

h(||)
0

20
||

SAFARI

0.4

0

0.5
0

0

reverse exponential input

0.2

20

1

0.5

40

10
||

SAFARI

0
20
||

0.1

prediction (model)

0
0

0.2

20

1

0.2

100

0
0

0.4

50
||

0.3

0
10
||

0

SAFARI

0.3

0.05

100

0.5

prediction (model)

0.1

50
||

SAFARI

h(||)

h(||)

h(||)

0.5

0

0

1

normal input

h(||)

100

1

0

h(||)

50
||

prediction (model)

1

0

0.5
0

uniform input

0

SAFARI

0.2
0.1

0

5
||

10

0

0

5
||

Figure 12: Predicted actual cardinality distributions
400

10

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Table 2: Fit coefficients exponential goodness fit cardinality distribution
Fig. 12




R2

576
423
69 470
385

0.44
0.34
4.26
0.33

1
0.99
1
0.95

Input Distribution
Uniform
Normal
Exponential
Reverse Exponential

default configuration Safari (when stated otherwise) = 8 N = 4;
is, Safari configured maximum number 8 retries giving
climb, total 4 attempts. provide precise average run-time optimality
performance data, stochastic algorithms (i.e., ones based SLS Max-SAT Safari)
repeatedly run 10 times model observation vector.
6.1 Implementation Notes Test Set Description
implemented Safari approximately 1 000 lines C code (excluding LTMS,
interface, DPLL code) part Lydia package.7
Traditionally, MBD algorithms tested diagnostic models digital circuits
like ones included ISCAS85 benchmark suite (Brglez & Fujiwara, 1985).
models derived ISCAS85 large (from traditional diagnostic perspective),
also considered four medium-sized circuits 74XXX family (Hansen, Yalcin,
& Hayes, 1999). order provide weak- strong-fault cases, translated
circuit weak, stuck-at-0 (S-A-0), stuck-at-1 (S-A-1) model. stuck-at
models, output faulty gate assumed constant (cf. Def. 14).
performance diagnostic algorithms depends various degrees observation
vectors (algorithm designers strive produce algorithms, performance
dependent observation vectors). Hence, performed experimentation
number different observations model. implemented algorithm
(Alg. 3) generates observations leading diagnoses different minimal-cardinality,
varying 1 nearly maximum respective circuits (for 74XXX models
maximum). experiments omit nominal scenarios trivial
viewpoint MBD.
Algorithm 3 uses number auxiliary functions. RandomInputs (line 3) assigns
uniformly distributed random values input (note generation
observation vectors partition observable variables OBS inputs outputs
use input/output information comes original 74XXX/ISCAS85
circuits simulation). Given healthy health assignment diagnostic system, ComputeNominalOutputs (line 4) performs simulation propagating input
assignment . result assignment contains values output variable
OUT.
7. Lydia, Safari, diagnostic benchmark downloaded http://fdir.org/lydia/.

401

fiFeldman, Provan, & van Gemund

Algorithm 3 Algorithm generation observation vectors
1: function MakeAlphas(DS, N, K) returns set observations
inputs: DS = hSD, COMPS, OBSi, diagnostic system
OBS = OUT, =
N , integer, number tries Safari
K, integer, maximal number diagnoses per cardinality
local variables: , , n , , terms
c, integer, best cardinality far
A, set terms (observation vectors), result
2:
k 1, 2, . . . , K
3:
RandomInputs(IN)
4:
ComputeNominalOutputs(DS, )
5:
c0
6:
v
7:
n Flip(, v)
8:
SmallestCardinalityDiagnosis(Safari(SD, n , |COMPS|, N ))
9:
|| > c
10:
c ||
11:
n
12:
end
13:
end
14:
end
15:
return
16: end function
loop lines 6 13 increases cardinality greedily flipping values
output variables. new candidate observation n , Alg. 3 uses diagnostic oracle
Safari compute minimal diagnosis cardinality c. Safari returns
one diagnosis (up N ), use SmallestCardinalityDiagnosis choose one
smallest cardinality. cardinality c diagnosis increases comparison
previous iteration, observation added list.
running Alg. 3 get K observations leading faults cardinality 1, 2, . . . , m,
cardinality MFMC diagnosis (Feldman, Provan, & van Gemund,
2008b) respective circuit. Alg. 3 clearly shows bootstrapping problem. order
create potentially difficult observations Safari, require Safari solve
difficult observations. Although seen Sec. 5 Safari heavily biased
towards generating diagnoses small cardinality, guarantee. alleviate
problem, generation observation vectors, configured Safari compute
subset-minimal diagnoses = |COMPS| N increased 20.
Table 3 provides overview fault diagnosis benchmark used experiments.
third fourth columns show number observable assumable variables,
characterize size circuits. next three columns show number observation
vectors tested weak, S-A-0, S-A-1 models. stuck-at
models, chosen weak-fault model observations consistent
402

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Table 3: overview 74XXX/ISCAS85 benchmark circuits
Name

Description

74182
74L85
74283
74181

4-bit
4-bit
4-bit
4-bit

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

27-channel interrupt controller
32-bit SEC circuit
8-bit ALU
32-bit SEC circuit
16-bit SEC/DEC
12-bit ALU
8-bit ALU
9-bit ALU
32-bit multiplier
32-bit adder

Variables
|OBS| |COMPS|

carry-lookahead generator
magnitude comparator
adder
ALU

Observations
Weak S-A-0 S-A-1

14
14
14
22

19
33
36
65

250
150
202
350

150
58
202
143

82
89
202
213

43
73
86
73
58
373
72
301
64
315

160
202
383
546
880
1 193
1 669
2 307
2 416
3 512

301
835
1 182
836
846
1 162
756
2 038
404
1 557

301
235
217
836
846
134
625
158
274
255

301
835
335
836
846
123
743
228
366
233

respective system descriptions (as strong-fault models often case SD |=,
considered scenarios).
6.2 Comparison Complete Algorithms
Table 4 shows results comparing Safari implementations two state-of-the-art
complete deterministic diagnostic algorithms: modification completeness CDA
(Williams & Ragno, 2007) HA (Feldman & van Gemund, 2006). Table 4 shows,
model algorithm, percentage tests diagnosis could
computed within cut-off time 1 minute.
visible three rightmost columns Table 4, Safari could find diagnoses observation vectors, performance two deterministic algorithms
(columns two seven) degraded increase model size cardinality
observation vector. Furthermore, observed degradation performance
CDA HA increased cardinality minimal-cardinality diagnoses,
performance Safari remained unaffected.
6.3 Comparison Algorithms Based ALLSAT Model Counting
compared performance Safari pure SAT-based approach,
uses blocking clauses avoiding duplicate diagnoses (Jin, Han, & Somenzi, 2005).
Although SAT encodings worked efficiently variety domains,
planning, weak health modeling makes diagnostic problem underconstrained
uninformed ALLSAT strategy (i.e., search exploiting continuity imposed
weak-fault modeling) quite inefficient, even small models.
403

fiFeldman, Provan, & van Gemund

Table 4: Comparison CDA , HA , Safari [% tests solved]
Name

Weak

CDA
S-A-0

74182
74L85
74283
74181

100
100
100
79.1

100
100
100
98.6

100
100
100
97.7

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

74.1
29
11.6
3.8
0
0
0
0
0
0

75.4
45.5
44.7
4.7
0
0
0
0
0
0

73.1
27.7
32.2
5.4
0
0
0
0
0
0

S-A-1

Weak

HA
S-A-0

S-A-1

Weak

100
100
100
100

100
100
100
100

100
100
100
100

100
100
100
100

100
100
100
100

100
100
100
100

100
100
100
100
100
100
100
100
100
100

100
100
100
100
100
100
100
100
100
100

100
100
100
100
100
100
100
100
100
100

71.1
24.1
12.4
10.8
6.1
5
1.1
1.1
3.5
3.9

94.7
77.9
62.2
10.6
6
64.2
3.8
8.2
5.1
7.8

69.1
25.9
41.5
12.2
6.5
44.7
2.2
5.7
3.3
12

Safari
S-A-0 S-A-1

substantiate claim, experimented state-of-the-art satisfiability
solver RelSat, version 2.02 (Bayardo & Pehoushek, 2000). Instead enumerating
solutions filtering minimal diagnoses only, performed model-counting, whose
relation MBD extensively studied (Kumar, 2002). possible solve
two smallest circuits, solver terminate larger models within
predetermined time 1 hour. results shown Table 5.
second column Table 5 shows model count returned RelSat, sample single-fault observations benchmark. third column reports time
model counting. slow performance relatively small diagnostic instances leads us
conclusion specialized solvers like Safari better suited finding minimal
diagnoses off-the-shelf ALLSAT (model counting) implementations encode
inference properties similar encoded Safari.
used state-of-the-art, non-exact model counting method SampleCount
(Gomes, Hoffmann, Sabharwal, & Selman, 2007) compute lower bounds model
counts. results shown third fourth columns Table 5. Configured
default settings ( = 3.5, = 2, z = 20, cutoff 10 000 flips), SampleCount could
find lower bounds circuits larger c1355. Although performance SampleCount significantly better RelSAT, fact SampleCount computes lower
bounds scale large circuits prevent us building diagnosis algorithm
based approximate model counting.
satisfiability-based method diagnosing optimized version ISCAS85
used Smith, Veneris, Viglas (2004). recent paper (Smith, Veneris, Ali, &
Viglas, 2005), SAT-based approach replaced Quantified Boolean Formula
(QBF) solver computing multiple-fault diagnoses. methods report good absolute
404

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Table 5: Model count time counting
RelSat
Models
Time [s]

Name

SampleCount
Models
Time [s]

74182
74L85
74283
74181

3.9896 107
8.3861 1014
1.0326 1015
5.6283 1015

1
340
> 3 600
> 3 600

3.526359 106
7.412344 1013
3.050026 1014
1.538589 1027

0.2
0.3
0.3
1.1

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552












7.2045 1018
3.6731 1020
9.4737 1039
1.4668 1028
2.1704 1031
9.0845 1015
4.8611 1019
9.3551 1016
1.0300 1018
1.0049 1016

> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600
> 3 600

1.496602 1067
7.549183 1083
8.332702 10166
7.488300 10233







9.9
13.1
42.7
99.8







execution time single double-faults (and believe scale well higher
cardinalities), require modifications initial circuits (i.e., introduce cardinality
test constraints) suggest specialized heuristics SAT solvers order improve
search performance. Comparison performance Safari timings reported
papers would difficult due number reasons like use different
optimized benchmark sets, trading-off memory speed, rewriting original circuits, etc.
6.4 Performance Greedy Stochastic Search
Table 6 shows absolute performance Safari (M = |COMPS|, N = 4). varies
millisecond small models, approx. 30 largest strong-fault
model. fast absolute times show Safari suitable on-line reasoning tasks,
autonomy depends speedy computation diagnoses.
model, minimum maximum time computing diagnosis
computed. values shown columns tmin tmax , respectively. small
range tmax tmin confirms theoretical results Safari insensitive fault
cardinalities diagnoses computes. performance CDA HA ,
hand, dependent fault cardinality quickly degrades increasing fault
cardinality.
6.5 Optimality Greedy Stochastic Search
results produced complete diagnostic methods (CDA HA ) know
exact cardinalities minimal-cardinality diagnoses observations.
considering observations, lead single double faults, evaluated
405

fiFeldman, Provan, & van Gemund

Table 6: Performance Safari [ms]
Weak
Name

tmin

S-A-0
tmax

74182
74L85
74283
74181

0.41
0.78
0.92
2.04

1.25
7.47
4.84
6.94

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

8.65
14.19
48.08
95.03
237.77
500.54
984.31
1 950.12
2 105.28
4 557.4

38.94
31.78
88.87
141.59
349.96
801.12
1 300.98
2 635.71
2 688.34
6 545.21

tmin
0.39
0.72
0.88
2.13

S-A-1
tmax
4.41
1.89
3.65
22.4

tmin
0.40
0.69
0.92
2.07

tmax
0.98
4.77
5.2
7.19

7.58
30.59
7.96
38.27
11.03
30.32
10.79
31.11
37.08
80.74
38.47
81.34
76.57
150.29
83.14
135.29
196.13
300.11
217.32
442.91
646.95 1 776.72
463.24
931.8
1 248.5
2 516.46
976.56 2 565.18
3 346.49 7 845.41 2 034.5
4 671.17
2 246.84 3 554.4 1 799.18 2 469.48
9 975.04 32 210.71 5 338.97 12 101.61

average optimality Safari. Table 7 shows optimality results greedy
search. second column Table 7 shows number observation vectors leading
single faults weak-fault model. third column shows average cardinality
Safari. second third column repeated S-A-0 S-A-1 models.
Table 7 shows that, SD WFM, average cardinality returned Safari
near-optimal single double faults. c1355 model shows worst-case
results single-fault observations, c499 difficult weak-fault model
computing double-fault diagnosis. results improved increasing N
discussed Sec. 4.
strong-fault models, results close optimal small models
quality diagnosis deteriorates c3540 bigger. surprising, considering
modest number retries number flips Safari configured.
6.6 Computing Multiple Minimal-Cardinality Diagnoses
next show results experiments supporting claims made Sec. 5. that,
first chosen observations could compute | (SD )|
deterministic algorithm like CDA HA (mostly observations leading single double
faults). configured Safari = |COMPS| N = 10| (SD )|.
Finally, diagnoses computed Safari filtered minimal-cardinality
ones. results summarized Table 8.
Table 8 repeats columns weak, S-A-0, S-A-1 models data
columns interpreted follows. columns marked | | show
minimal maximal number minimal-cardinality diagnoses per model computed
deterministic algorithm. columns Mc show percentage minimal-cardinality
406

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Table 7: Optimality Safari [average cardinality]
Single Faults
S-A-0
S-A-1
# Card. # Card.

Name

Weak
# Card.

74182
74L85
74283
74181

50
50
50
50

1
1.04
1.08
1.19

37
18
34
36

1
1.02
1.59
2.81

40
40
46
46

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

58
84
50
84
52
29
8
14
13
27

1.19
1.49
1
1.66
1.05
1.03
1.01
1
1
1.01

52
53
39
82
49
39
23
9
13
11

1.06
1.49
1.1
1
2.91
1.77
2.5
3.54
28.83
17.37

37
84
40
84
52
28
16
12
12
18

1
1.03
1.88
2.6

Weak
# Card.

Double Faults
S-A-0
S-A-1
# Card. # Card.

50
50
50
50

2
2.12
2.2
2.25

38
17
45
36

1.04 82
1.01 115
1.05 50
1.02
6
4.79
2.06 13
3.74
5.4
7
28.68
1
23.38 16

2.46
3.27
2.01
2.15

2.12

2
2
2

80
34
34
7
2
24
1
3
1
4

2
2.06
2.41
3.61

18
35
42
43

2
2.07
2.6
3.16

2.25 48
3.01 115
2.14 35
2
18
3
3
2.78 15
4.9

3.7
1
27

18.5
6

2.15
2.03
2.07
2.07
3.17
3.27

3.8

27.53

Table 8: % minimal-cardinality diagnoses computed Safari
Weak
Mc

Name

| |

74182
74L85
74283
74181

1 25
1 78
1 48
1 133

100
99.2
97.9
97.4

c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

1 99
1 22
2 646
5 2 770
2 1 447
1 76
1 384
1 235
1 154
1 490

94.2
78.5
99.9
79.4
96.6
100
81.5
97.7
100
93.1

S-A-0
Mc Mf

| |

0
2
3
1

12
14
1 16
1 16

100
100
93.8
88.6

0
0
0
4.07

1 20
1 49
1 29
1 57

100
99.7
84.9
96.7

0
0
4
6.36

1 40
1 15
1 160
2 648
2 579
1 20
1 153
1 24
1 73
4 236

89.7
96.3
96.9
95.7
85.2
97.1
88.8
81.7
78.1
90.8

0
6
0
0
1.85
0
7.98
7.04
5.1
13.55

1 18
1 16
1 210
2 347
2 374
1 181
1 171
1 30
1 101
1 168

97
94.8
97.5
95.2
82.3
89.7
78.2
93.4
82.1
78

0
0
0
0.52
1.24
0
7.27
8.24
1.22
12.1

7.14
1.51
0
1.02
2.61
2.34
8.52
1.74
13.1
2.17

| |

S-A-1
Mc Mf

Mf

diagnoses returned Safari (from minimal-cardinality diagnoses)
| (SD )| > 1. columns Mf show percentage observations Safari
could compute minimal-cardinality diagnosis.
407

fiFeldman, Provan, & van Gemund

results shown Table 8 show even moderate values N (N 27 770),
Safari capable computing significant portion minimal-cardinality diagnoses.
portion varies 78.5% 100% weak-fault models 78% 100%
strong-fault models. percentage cases Safari could reach minimalcardinality diagnosis limited (at 13.55%) mainly cases
exists one single-fault diagnosis. Note even cases Safari cannot
compute minimal-cardinality diagnoses, result Safari still useful.
example, subset-minimal diagnosis small cardinality differing one two literals
nevertheless brings useful diagnostic information (a discussion diagnostic metrics
beyond scope paper).
6.7 Experimentation Summary
applied Safari suite benchmark combinatorial circuits encoded using
weak-fault models stuck-at strong fault models, shown significant performance
improvements multiple-fault diagnoses, compared two state-of-the-art deterministic
algorithms, CDA HA . results indicate Safari shows least order-ofmagnitude speedup CDA HA multiple-fault diagnoses. Moreover, whereas
search complexity deterministic algorithms tested increases exponentially fault
cardinality, search complexity stochastic algorithm appears independent
fault cardinality.
compared performance Safari algorithm based MaxSAT, Safari shows least order-of-magnitude speedup computing diagnoses.
compared optimality Safari algorithm based SLS MaxSAT, Safari consistently computes diagnoses smaller cardinality whereas SLS
Max-SAT diagnostic algorithm often fails compute diagnosis.

7. Related Work
paper (1) generalizes Feldman, Provan, van Gemund (2008a), (2) introduces important theoretical results strong-fault models, (3) extends experimental results
there, (4) provides comprehensive optimality analysis Safari.
gross level, one classify types algorithms applied solve
MBD based search compilation. search algorithms take input diagnostic model observation, search diagnosis, may minimal
respect minimality criterion. Examples search algorithms include -based
algorithms, CDA (Williams & Ragno, 2007) hitting set algorithms (Reiter,
1987). Compilation algorithms pre-process diagnostic model form
efficient on-line diagnostic inference. Examples algorithms include ATMS
(de Kleer, 1986) prime-implicant methods (Kean & Tsiknis, 1993), DNNF (Darwiche, 1998), OBDD (Bryant, 1992). knowledge, approaches adopt
exact methods compute diagnoses; contrast, Safari adopts stochastic approach
computing diagnoses.
first glance, seems like MBD could efficiently solved using encoding
SAT (Jin et al., 2005), constraint satisfaction (Freuder, Dechter, Ginsberg, Selman, &
Tsang, 1995) Bayesian network (Kask & Dechter, 1999) problem. However, one needs
408

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

take account increase formula size (over direct MBD encoding), addition
underconstrained nature MBD problems.
Safari close resemblance Max-SAT (Hoos & Stutzle, 2004) conducted extensive experimentation complete (partial weighted) SLS-based
Max-SAT. results experiments long, published separate technical report (Feldman, Provan, & van Gemund, 2009a). results show
although Max-SAT compute diagnoses many cases, performance MaxSAT degrades increasing circuit size cardinality injected faults.
particular, Safari outperforms Max-SAT least order-of-magnitude class
diagnostic problems considered. case SLS-based Max-SAT, optimality
Max-SAT-based inference significantly worse Safari.
show Safari exploits particular property MBD problems, called diagnostic
continuity, improves optimality Safari compared to, example, straightforward ALLSAT encodings (Jin et al., 2005). experimentally confirm favorable
performance optimality Safari. Although Safari close resemblance MaxSAT, Safari exploits specific landscape properties diagnostic problems, allow
(1) simple termination criteria (2) optimality bounds. Due hybrid nature
Safari (the use LTMS SAT), Safari avoids getting stuck local optima performs better Max-SAT based methods. Incorporating approaches Max-SAT,
particular SAPS (Hutter, Tompkins, & Hoos, 2002), future versions Safari may
help solving general abduction problems, may expose continuous
properties models considered.
Stochastic algorithms discussed framework constraint satisfaction
(Freuder et al., 1995) Bayesian network inference (Kask & Dechter, 1999). latter
two approaches used solving suitably translated MBD problems. often
case, though, encodings difficult search specialized ones.
MBD instance constraint optimization, particular constraints failure
variables. MBD developed algorithms exploit domain properties,
proposed approach differs significantly almost MBD algorithms appear
literature. advanced MBD algorithms deterministic, Safari borrows
SLS algorithms that, rather backtracking, may randomly flip variable assignments
determine satisfying assignment. Complete MBD algorithms typically make use
preferences, e.g., fault-mode probabilities, improve search efficiency; Safari uses
technique top stochastic search space diagnoses.
closely-related diagnostic approach Fijany, Vatan, Barrett, James, Williams,
Mackey (2003), map minimal-hitting set problem problem finding
assignment bounded weight satisfying monotone SAT problem, propose
use efficient SAT algorithms computing diagnoses. approach Fijany et al.
shown speedups comparison diagnosis algorithms; main drawback
number extra variables clauses must added SAT encoding,
even significant strong fault models multi-valued variables. contrast,
approach works directly given diagnosis model requires conversion another
representation.
work bears closest resemblance preference-based Cost-Based Abduction
(CBA) (Charniak & Shimony, 1994; Santos Jr., 1994). algorithmic work
409

fiFeldman, Provan, & van Gemund

area, primary paper adopts stochastic local search Abdelbar, Gheita,
Amer (2006). paper, present hybrid two-stage method based
Iterated Local Search (ILS) Repetitive Simulated Annealing (RSA). ILS stage
algorithm uses simple hill-climbing method (randomly flipping assumables)
local search phase, tabu search perturbation phase. RSA repeatedly applies
Simulated Annealing (SA), starting time random initial state. hybrid
method initially starts arbitrary state, greedily-chosen state. applies
ILS algorithm; algorithm fails find optimal solution fixed number
hill-climbing steps8 fixed number R repetitions perturbation-local
search cycle,9 ILS-based search terminated RSA algorithm run optimal
solution found.
work differs Abdelbar et al. (2006) several ways. First, initial
state generated using random SAT solution. hill-climbing phase use next
similar Abdelbar et al.; however, randomly restart hill-climbing
identify better diagnosis, rather applying tabu search simulated annealing.
approach simpler Abdelbar et al., case weak fault models
guaranteed optimal; future work plan compare approach
Abdelbar et al. strong fault models.
2009 Safari competed diagnostic algorithms NGDE (de Kleer, 2009)
RODON (Bunus, Isaksson, Frey, & Munker, 2009) synthetic track first
diagnostic competition DXC09 (Kurtoglu, Narasimhan, Poll, Garcia, Kuhn, de Kleer, van
Gemund, & Feldman, 2009). conditions DXC09 experiments
conducted similar ones described paper. CPU memory performance Safari order magnitude better competing algorithms despite
fact NGDE RODON performed better complete algorithms discussed
section. paper, addition computational metrics, informally
used minimality diagnosis optimality criterion. DXC09 organizers, however, defined utility metric approximates expected repair effort circuit
(Feldman, Provan, & van Gemund, 2009b). utility metric, Safari scored slightly
worse two competing algorithms, expected Safari trades
diagnostic precision computational efficiency. refer reader DXC papers
mentioned thorough analysis competition results.

8. Conclusion Future Work
described greedy stochastic algorithm computing diagnoses within modelbased diagnosis framework. shown subset-minimal diagnoses computed
optimally weak fault models important subset strong fault models,
almost minimal-cardinality diagnoses computed general fault models.
8. Hill-climbing proceeds follows: given current state cost f (s), neighbouring state
generated flipping randomly chosen assumable hypothesis. f (s ) better f (s),
becomes current state; otherwise, discarded. iterations elapse without change
current state, local search exits.
9. Perturbation-local search, starting current state cost f (s), randomly chooses
assumable variable h, applies tabu search identify better state flipping h based tabu
status.

410

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

argue Safari broad practical significance, compute significant fraction minimal-cardinality diagnoses systems large complex
diagnosed existing deterministic algorithms.
future work, plan experiment models combination weak strong
failure-mode descriptions. also plan experimenting wider variety stochastic
methods, simulated annealing genetic search, using larger set benchmark
models. Last, plan apply algorithms wider class abduction constraint
optimization problems.

References
Abdelbar, A. M. (2004). Approximating cost-based abduction NP-hard. Artificial Intelligence, 159 (1-2), 231239.
Abdelbar, A. M., Gheita, S. H., & Amer, H. A. (2006). Exploring fitness landscape
run-time behaviour iterated local search algorithm cost-based abduction.
Experimental & Theoretical Artificial Intelligence, 18 (3), 365386.
Bayardo, R. J., & Pehoushek, J. D. (2000). Counting models using connected components.
Proc. AAAI00, pp. 157162.
Brglez, F., & Fujiwara, H. (1985). neutral netlist 10 combinational benchmark circuits
target translator fortran. Proc. ISCAS85, pp. 695698.
Bryant, R. E. (1992). Symbolic Boolean manipulation ordered binary-decision diagrams. ACM Computing Surveys, 24 (3), 293318.
Bunus, P., Isaksson, O., Frey, B., & Munker, B. (2009). RODON - model-based diagnosis
approach DX diagnostic competition. Proc. DX09, pp. 423430.
Bylander, T., Allemang, D., Tanner, M., & Josephson, J. (1991). computational complexity abduction. Artificial Intelligence, 49, 2560.
Charniak, E., & Shimony, S. E. (1994). Cost-based abduction MAP explanation. Artificial Intelligence, 66 (2), 345374.
Cook, S. A. (1971). complexity theorem-proving procedures. Proc. STOC71, pp.
151158.
Darwiche, A. (1998). Model-based diagnosis using structured system descriptions. Journal
Artificial Intelligence Research, 8, 165222.
Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.
Communications ACM, 5 (7), 394397.
de Kleer, J. (1986). assumption-based TMS. Artificial Intelligence, 28 (2), 127162.
de Kleer, J. (1990). Using crude probability estimates guide diagnosis. Artificial Intelligence, 45 (3), 381291.
de Kleer, J. (2009). Minimum cardinality candidate generation. Proc. DX09, pp. 397
402.
de Kleer, J., Mackworth, A., & Reiter, R. (1992). Characterizing diagnoses systems.
Artificial Intelligence, 56 (2-3), 197222.
411

fiFeldman, Provan, & van Gemund

de Kleer, J., & Williams, B. (1987). Diagnosing multiple faults. Artificial Intelligence,
32 (1), 97130.
Een, N., & Sorensson, N. (2003). extensible SAT-solver. Proc. SAT03, Vol. 2919
Lecture Notes Computer Science, pp. 502518. Springer.
Eiter, T., & Gottlob, G. (1995). complexity logic-based abduction. Journal
ACM, 42 (1), 342.
Feldman, A., Provan, G., & van Gemund, A. (2008a). Computing minimal diagnoses
greedy stochastic search. Proc. AAAI08, pp. 911918.
Feldman, A., Provan, G., & van Gemund, A. (2008b). Computing observation vectors
max-fault min-cardinality diagnoses. Proc. AAAI08, pp. 911918.
Feldman, A., Provan, G., & van Gemund, A. (2009a). family model-based diagnosis
algorithms based Max-SAT. Tech. rep. ES-2009-02, Delft University Technology.
Feldman, A., Provan, G., & van Gemund, A. (2009b). Lydia approach combinational
model-based diagnosis. Proc. DX09, pp. 403408.
Feldman, A., & van Gemund, A. (2006). two-step hierarchical algorithm model-based
diagnosis. Proc. AAAI06, pp. 827833.
Fijany, A., Vatan, F., Barrett, A., James, M., Williams, C., & Mackey, R. (2003). novel
model-based diagnosis engine: Theory applications. Proc. IEEE Aerospace03,
Vol. 2, pp. 901910.
Forbus, K., & de Kleer, J. (1993). Building Problem Solvers. MIT Press.
Freeman, J. W. (1995). Improvements Propositional Satisfiability Search Algorithms.
Ph.D. thesis, University Pennsylvania.
Freuder, E. C., Dechter, R., Ginsberg, M. L., Selman, B., & Tsang, E. P. K. (1995). Systematic versus stochastic constraint satisfaction. Proc. IJCAI95, Vol. 2, pp. 20272032.
Friedrich, G., Gottlob, G., & Nejdl, W. (1990). Physical impossibility instead fault
models. Proc. AAAI90, pp. 331336.
Gomes, C. P., Hoffmann, J., Sabharwal, A., & Selman, B. (2007). sampling model
counting. Proc. IJCAI07, pp. 22932299.
Hansen, M., Yalcin, H., & Hayes, J. (1999). Unveiling ISCAS-85 benchmarks: case
study reverse engineering. IEEE Design & Test, 16 (3), 7280.
Hermann, M., & Pichler, R. (2007). Counting complexity propositional abduction.
Proc. IJCAI07, pp. 417422.
Hoos, H. (1999). SAT-encodings, search space structure, local search performance.
Proc. IJCAI99, pp. 296303.
Hoos, H., & Stutzle, T. (2004). Stochastic Local Search: Foundations Applications.
Morgan Kaufmann Publishers Inc.
Hutter, F., Tompkins, D. A. D., & Hoos, H. H. (2002). Scaling probabilistic smoothing:
Efficient dynamic local search SAT. Proc. CP02, pp. 233248.
412

fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search

Jin, H., Han, H., & Somenzi, F. (2005). Efficient conflict analysis finding satisfying
assignments Boolean circuit. Proc. TACAS05, pp. 287300.
Kask, K., & Dechter, R. (1999). Stochastic local search Bayesian networks. Proc.
AISTAT99, pp. 113122.
Kean, A., & Tsiknis, G. K. (1993). Clause management systems. Computational Intelligence,
9, 1140.
Kumar, T. K. S. (2002). model counting characterization diagnoses. Proc. DX02,
pp. 7076.
Kurtoglu, T., Narasimhan, S., Poll, S., Garcia, D., Kuhn, L., de Kleer, J., van Gemund, A.,
& Feldman, A. (2009). First international diagnosis competition - DXC09. Proc.
DX09, pp. 383396.
Marques-Silva, J. P. (1999). impact branching heuristics propositional satisfiability
algorithms. Proc. EPIA99, pp. 6274.
McAllester, D. A. (1990). Truth maintenance. Proc. AAAI90, Vol. 2, pp. 11091116.
Reiter, R. (1987). theory diagnosis first principles. Artificial Intelligence, 32 (1),
5795.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1-2),
273302.
Santos Jr., E. (1994). linear constraint satisfaction approach cost-based abduction.
Artificial Intelligence, 65 (1), 128.
Smith, A., Veneris, A., Ali, M. F., & Viglas, A. (2005). Fault diagnosis logic debugging
using Boolean satisfiability. IEEE Transactions CAD Integrated Circuits
Systems, 24 (10), 16061621.
Smith, A., Veneris, A., & Viglas, A. (2004). Design diagnosis using Boolean satisfiability.
Proc. ASP-DAC04, pp. 218223.
Struss, P., & Dressler, O. (1992). Physical negation - integrating fault models General Diagnostic Engine. Readings Model-Based Diagnosis, pp. 153158. Morgan
Kaufmann Publishers Inc.
Thiffault, C., Bacchus, F., & Walsh, T. (2004). Solving non-clausal formulas DPLL
search. Proc. CP04, pp. 663678.
Tseitin, G. (1983). complexity proofs propositional logics. Siekmann, J., &
Wrightson, G. (Eds.), Automation Reasoning: Classical Papers Computational
Logic (19671970), Vol. 2. Springer-Verlag.
Williams, B., & Ragno, R. (2007). Conflict-directed A* role model-based embedded systems. Journal Discrete Applied Mathematics, 155 (12), 15621595.
Zhang, H., & Stickel, M. E. (1996). efficient algorithm unit propagation. Proc.
AI-MATH96, pp. 166169.

413

fiJournal Artificial Intelligence Research 38 (2010) 271-305

Submitted 12/09; published 06/10

Developing Approaches Solving Telecommunications
Feature Subscription Problem
David Lesaint

david.lesaint@bt.com

Business Modelling Operational Transformation,
BT Research,
UK.

Deepak Mehta
Barry OSullivan
Luis Quesada
Nic Wilson

d.mehta@4c.ucc.ie
b.osullivan@4c.ucc.ie
l.quesada@4c.ucc.ie
n.wilson@4c.ucc.ie

Cork Constraint Computation Centre,
University College Cork,
Ireland.

Abstract
Call control features (e.g., call-divert, voice-mail) primitive options users
subscribe off-line personalise service. configuration feature subscription involves choosing sequencing features catalogue subject constraints
prevent undesirable feature interactions run-time. subscription requested
user inconsistent, one problem find optimal relaxation, generalisation feedback vertex set problem directed graphs, thus NP-hard
task. present several constraint programming formulations problem. also
present formulations using partial weighted maximum Boolean satisfiability mixed integer linear programming. study formulations experimentally comparing
variety randomly generated instances feature subscription problem.

1. Introduction
Information communication services, news feeds internet telephony, playing
increasing, potentially disruptive, role daily lives. result, service providers
seek develop personalisation solutions allowing customers control enrich
service. telephony, instance, personalisation relies provisioning call control
features. feature increment functionality which, activated, modifies basic
service behaviour systematic non-systematic ways, e.g., do-not-disturb, multi-media
ring-back tones, call-divert-on-busy, credit-card-calling.
Modern service delivery platforms provide ability implement features modular
applications compose demand setting live sessions, is, consistently feature subscriptions preconfigured participants. architectural style
commonly found platforms based Session Initiation Protocol (Rosenberg,
Schulzrinne, Camarillo, Johnston, Peterson, Sparks, Handley, & Schooler, 2002; Sparks,
2007) notably, Internet Multimedia Subsystem (Poikselka, Mayer, Khartabil, & Niemi,
2006), consists chaining applications end-points. context, personalic
2010
AI Access Foundation. rights reserved.

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

sation approach consists exposing catalogues call-control features subscribers
letting select sequence features choice.
sequences features acceptable, however, due possible occurrence
feature interactions (Calder, Kolberg, Magill, & Reiff-Marganiec, 2003). feature interaction way feature modifies influences behaviour another feature
generating systems overall behaviour (Bond, Cheung, Purdy, Zave, & Ramming,
2004). instance, do-not-disturb feature block incoming call cancel
effect subsequent feature subscribed callee. undesirable interaction:
shown Figure 1, call originating caller X never reach call-logging feature
callee Y. However, call-logging placed do-not-disturb features
play role.

Figure 1: example undesirable feature interaction.
Distributed Feature Composition (dfc) provides method formal architecture
address feature interactions (Jackson & Zave, 1998, 2003; Bond et al., 2004). method
consists constraining selection sequencing features prescribing constraints
prevent undesirable interactions. feature interaction resolution constraints
represented catalogue precedence exclusion constraints. precedence constraint,
j, means features j part sequence must precede
j. exclusion constraint j means cannot together
sequence. Note exclusion constraint j expressed pair
two precedence constraints j j i. Undesirable interactions avoided
rejecting sequence satisfy catalogue precedence constraints.
Informally, feature subscription defined set features, set precedence
constraints specified user set precedence constraints prescribed feature catalogue. task find sequence user-selected features subject
catalogue precedence constraints user-specified precedence constraints. may
always possible construct sequence, case task find relaxation feature subscription consistent closest initial requirements
user (Lesaint, Mehta, OSullivan, Quesada, & Wilson, 2008b). paper, show
checking consistency feature subscription polynomial time, finding
optimal relaxation subscription, inconsistent, NP-hard.
present several formulations finding optimal relaxation feature subscription using constraint programming. present simple constraint optimisation problem
formulation problem investigate impact maintaining three different levels
consistency decision variables within depth-first branch bound. first one
arc consistency (Rossi, van Beek, & Walsh, 2006a), commonly used. second
singleton arc consistency third restricted singleton arc consistency (rsac).
also present formulation problem based soft global constraint, call
SoftPrec (Lesaint, Mehta, OSullivan, Quesada, & Wilson, 2009). present
272

fiApproaches Solving Telecommunications Feature Subscription Problem

formulation based weighted constraint satisfaction problem framework (Rossi, van
Beek, & Walsh, 2006b). also consider partial weighted maximum satisfiability (Biere,
Heule, van Maaren, & Walsh, 2009), mixed integer linear programming. present
formulations using approaches discuss differences respect
constraint programming formulations.
Notice finding optimal relaxation feature subscription generalisation
well-known feedback vertex set problem well feedback arc set problem (Garey
& Johnson, 1979). Given directed graph G = hV, Ei set vertices V set
edges E, feedback vertex (arc) set problem find smallest V 0 V (E 0
E) whose deletion makes graph acyclic. Although paper focus
particular telecommunication problem, techniques studied also applicable
domains feedback vertex/arc set problem encountered, e.g., circuit design,
deadlock prevention, vlsi testing, stabilization synchronous systems (Festa, Pardalos,
& Resende, 1999, Section 5). also applications chemistry comes
sorting list samples complex mixtures according compositions presence
missing data, i.e., components measured samples (Fried, Hordijk,
Prohaska, Stadler, & Stadler, 2004).
remainder paper organised follows. Section 2 presents necessary
background required paper. introduce notion feature subscription
Section 3. Section 4 reformulate original problem order relate easily
well-known problems existing literature. Section 5 present algorithm
dealing symmetries introduced original subscription reformulated.
introduce notion relaxation inconsistent subscription Section 6 prove
finding optimal relaxation inconsistent subscription NP-Hard. Section
7 model problem finding optimal relaxation constraint optimisation
problem. Section 8, present two constraint programming approaches based
notions global constraints weighted constraint satisfaction problems.
Sections 9 10, partial weighted maximum satisfiability mixed integer linear
programming formulations problem described. empirical evaluation
approaches shown Section 11. Finally conclusions future directions
presented Section 12.

2. Background
section present set concepts binary relations constraint programming
used next sections.
2.1 Binary Relations
binary relation finite set X association elements X elements X.
Let R binary relation finite set X. relation R set X irreflexive
x X hx, xi R. relation R set X transitive
x, z X, [hx, yi R][hy, zi R] [hx, zi R]. transitive closure
binary relation R set X smallest transitive relation X contains R.
use notation R denote transitive closure R. relation R set X
asymmetric x, X, [hx, yi R] [hy, xi 6 R]. relation R set
273

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

X total x, X, either hx, yi R hy, xi R. strict partial
order binary relation irreflexive transitive. strict total order binary
b
relation transitive, asymmetric total. transpose relation R, denoted R,
set {hy, xi|hx, yi R}. restriction R set , denoted RY , set
{hx, yi R|{x, y} }. binary relation R set X also viewed directed
graph nodes correspond elements X ordered pairs R correspond
edges graph.
2.2 Constraint Programming
Constraint Programming (cp) successfully used many applications planning, scheduling, resource allocation, routing, bio-informatics (Wallace, 1996). Problems primarily stated Constraint Satisfaction Problems (csps), finite set
variables finite domains, together finite set constraints. solution
csp assignment value variable constraints satisfied simultaneously. basic approach solving csp instance use backtracking search
algorithm interleaves two processes: constraint propagation labelling. Constraint
propagation helps pruning values cannot lead solution problem. Labelling
involves assigning values variables may lead solution.
binary constraint said arc consistent every value domain every
variable, exists value domain pair values satisfies
constraint variables. non-binary constraint generalised arc consistent
value variable scope, exists value every
variable scope tuple satisfies constraint (Rossi et al., 2006a).
csp said Arc Consistent (ac) constraints (generalised) arc consistent.
csp said Singleton Arc Consistent (sac) non-empty domains
assignment variable resulting subproblem made ac (Bessiere, Stergiou,
& Walsh, 2008). Mixed consistency means maintaining different levels consistency
different variables problem. shown maintaining sac variables
ac remaining variables certain problems, job shop scheduling
radio link frequency assignment, reduce solution time (Lecoutre & Patrick, 2006).
Various generalisations csps developed, objective find
solution optimal respect certain criteria costs, preferences priorities.
One significant Constraint Optimisation Problem (cop). goal
find optimal solution either maximises minimises objective function
depending upon problem. simplest cop formulation retains csp limitation
allowing hard constraints adds objective function variables.
depth-first branch bound search algorithm generally used find solution
cop optimal value. case maximisation, branch bound search
algorithm keeps current optimal value solution traversing search tree.
value lower bound optimal value objective function. node
search tree, search algorithm computes overestimation global value.
value upper bound best solution extends current partial solution.
lower bound greater equal upper bound, solution greater
274

fiApproaches Solving Telecommunications Feature Subscription Problem

value current optimal value cannot found current node, current
branch pruned algorithm backtracks.

3. Configuring Feature Subscriptions
Distributed Feature Composition (dfc) feature implemented one
modules called Feature Box Types (fbt) fbt many run-time instances called
feature boxes. simplicity, paper assume feature implemented
single feature box associate features feature boxes.

SOURCE REGION

TARGET REGION
features

CATALOGUE

CL
OCS
OCS

TCS TDR CFU

CL

CL

<

TCS

<

TDR

<

CL

<

<

<>

CFU

SUBSCRIPTIONS

CONFIGURATION
target sub.

source sub. X

OCS

TDR

TCS

target sub. Z

CL

TCS

ROUTING

zone X

ZONES

feature
box types

X

src=x
trg=y

OCS

feature
boxes
zone

src=x
trg=y

TDR

TCS


zone Z

src=x
trg=z

CL

src=x
trg=z

TCS

src=x
trg=z

Z

Figure 2: DFC: Catalogues, subscriptions sessions.
Dfc establishes dialogue endpoints routing set-up request encapsulating source target addresses associated source target feature boxes
respectively. Addresses may change along way dfc routers evolve connection
path accordingly. Starting feature box initiating call, feature boxes incorporated one terminating box reached. router used
step locate next box relay set-up request. shown third row
Figure 2, routing method decomposes connection path source target
region region partitioned zones. source (target) zone sequence
feature boxes execute source (target) address. first source zone
associated source address encapsulated initial set-up request, i.e, zone
275

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

X Figure 2. change source address source region, caused instance
identification feature, triggers creation new source zone. change occurs
zone cannot expanded further, routers switch target region. Likewise,
change target address target region, performed Time-Dependent-Routing
(tdr) Figure 2, triggers creation new target zone. change occurs
zone cannot expanded Z Figure 2, request sent final
box identified encapsulated target address.
Dfc routers concerned locating feature boxes assembling zones
regions. make decisions type ordering feature boxes appearing
zone. simply fetch information pre-configured feature subscription
associated address region zone use construct zone.
instance, zone Z Figure 2 results sequence feature box types
subscribed Z target region.
Subscriptions pre-configured feature catalogue published service
provider. catalogue set features. Features classified source, target
reversible (i.e., subset features source target) based whether
subscribed source region, target region both. instance,
catalogue shown first row Figure 2 includes Originating-Call-Screening (ocs)
source feature, Terminating-Call-Screening (tcs), Time-Dependent-Routing (tdr),
Call-Forwarding-Unconditional (cfu) target features, Call-Logging (cl)
reversible feature. source feature activated behalf caller target feature
activated behalf callee.
Constraints formulated designers pairs source features pairs target
features prevent undesirable feature interactions (Zave, 2003). precedence constraint
imposes routing order two features. order specified respect
direction outgoing call features source (e.g., ocs must precede cl Figure 2)
respect direction incoming call features target (e.g., cl must
precede tcs). exclusion constraint makes two features mutually exclusive,
case cl cfu Figure 2. encode exclusion constraint two features fi
fj pair precedence constraints fi fj fj fi . sake simplicity,
treat precedence constraints ordered pairs, i.e., precedence constraint fi fj
also viewed hfi , fj i.
Definition 1 (Catalogue). catalogue tuple hFs , Hs , Ft , Ht where:
Fs finite set source features,
Ft finite set target features,
Fs Ft finite set reversible features,
Hs set source precedence constraints Fs ,
Ht set target precedence constraints Ft .
source (target) subscription associated address subset source (target) catalogue features, set catalogue precedence constraints source (target)
features, set user precedence constraints source (target) features.
276

fiApproaches Solving Telecommunications Feature Subscription Problem

instance, target subscription shown second row Figure 2 includes
target features tdr tcs user precedence tdr tcs meaning tdr
appear tcs connection path.
Definition 2 (Feature Subscription). Given catalogue hFs , Hs , Ft , Ht i, feature subscription defined pair tuples Ss = hFs , Hs , Ps St = hFt , Ht , Pt where:
Fs Ft user selected source target features respectively Fs
Fs , Ft Ft Fs Ft = Ft Fs , i.e., reversible feature Fs Ft appears
Fs Ft ;
Hs set source catalogue precedence constraints Fs given Hs = Hs Fs
{(f g) (Fs Ft )2 : g f Ht };
Ht set target catalogue precedence constraints Ft given Ht = Ht Ft
{(f g) (Fs Ft )2 : g f Hs };
Ps set source user precedence constraints Fs , satisfies Ps {(f
g) (Fs Ft )2 : g f Pt };
Pt set target user precedence constraints Ft , satisfies Pt {(f
g) (Fs Ft )2 : g f Ps }.
Configuring feature subscription involves selecting, parameterising sequencing
features region consistently catalogue constraints integrity rules
(Jackson & Zave, 2003). particular, source target regions subscription must
include reversible features inverse order, i.e. source target regions
configured independently.
Definition 3 (Consistency Feature Subscriptions). say feature subscription
= hhFs , Hs , Ps i, hFt , Ht , Pt ii consistent exists strict total order Ts
Fs strict total order Tt Ft
1. Ts Hs Ps
2. Tt Ht Pt
3. f, g Fs Ft , f g Ts g f Tt .
following configuration services may provided users submitting feature
subscription:
(verification) Check consistency subscription.
(filtering) feature subscription consistent, compute anti-subscription,
i.e., set features precedence constraints would make inconsistent
added.
(partial completion) feature subscription consistent, compute
transitive closure region, i.e., (Hs Ps ) (Ht Pt ) .
277

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

(completion) feature subscription consistent, compute pair strict
total orders source target features points 1, 2 3 Definition 3
respected.
(relaxation) feature subscription inconsistent, suggest consistent subscriptions obtained removing one features user precedences.
formalise tasks next section describe time complexities
reformulating original definition feature subscription.

4. Reformulating Original Definition Feature Subscription
definition, catalogue includes two sets features two sets precedence constraints. section, reformulate catalogue merging source target
feature sets merging source target precedence sets. transform feature
subscriptions accordingly show consistency subscription equivalent
acyclicity transformation. new definitions simpler reformulation
allows us establish relations well-known problems existing literature.
principle reformulation catalogue inverse merge target
precedences source precedences. Specifically, catalogue hFs , Hs , Ft , Ht rect i, H
ct transpose Ht
formulated hFc , Hc hFs Ft , Hs H
2
ct . definitions (consistent) feature subscription
hi, ji Ft : hi, ji Ht hj, ii H
adapted follows.
Definition 4 (Feature Subscription). feature subscription catalogue hFc , Hc
tuple hF, H, P i, F Fc , H = Hc F , P set (user defined) precedence
constraints F .
Definition 5 (Consistency Reformulated Feature Subscription). feature subscription hF, H, P catalogue hFc , Hc defined consistent exists
total order F H P .
Definition 6 (Corresponding Subscription). Let hFs , Hs , Ft , Ht original catalogue
ct reformulation. Given feature subscription =
hFc , Hc hFs Ft , Hs H






hhFs , Hs , Ps i, hFt , Ht , Pt ii catalogue hFs , Hs , Ft , Ht feature subscription r =
hF r , H r , P r catalogue hFc , Hc i, say r corresponds following
co , P r = P P
co .
holds: F r = Fso Fto , H r = Hso H



Due composition source target catalogues single catalogue,
feature subscription consistent source target regions consistent
DFC sense.
Proposition 1 (Equivalence Subscription Consistency). Let hFs , Hs , Ft , Ht origct reformulation. feature subscription
inal catalogue hFc , Hc hFs Ft , Hs H







= hhFs , Hs , Ps i, hFt , Ht , Pt ii catalogue hFs , Hs , Ft , Ht consistent
corresponding subscription r = hF r , H r , P r catalogue hFc , Hc consistent.
278

fiApproaches Solving Telecommunications Feature Subscription Problem

co , P r = P P
co .
Proof. Definition 6 F r = Fso Fto , H r = Hso H



r
r
r
r
() consistent exists total order F H r P r .
r . total orders F F
Let Tso = r Fso let Tto = T\
Ft




co F F ,
respectively. Since, Tso Hso Pso , Tto Hto Pto , Tso equivalent



also consistent.
() consistent exist two total orders Tso Tto Fso Fto respectively
co Fso Fto .
Tso Hso Pso , Tto Hto Pto , Tso equivalent


r

c acyclic. implies consistent (see Definition 5), since
prove Ts

co . Note that,
r H r P r , r total order F r extending Tso

co hf, f 0 Tso . prove
f, f 0 Fso hf, f 0 Tso

co acyclic contradiction. Assume Tso
co acyclic. Thus exists
Tso


cycle, and, particular, cycle minimum cardinality, say, k. Therefore exists
co , define
f1 , . . . , fk , F r = 0, . . . , k, hfi , fi+1 Tso

fk+1 = f1 f0 = fk . Suppose fi Fso \ Fto 1. Then, must
hfi1 , fi Tso hfi , fi+1 Tso implies hfi1 , fi+1 Tso transitivity Tso .
still cycle omit fi , contradicts minimality cycle
length k. shown, 1, fi Fto hfi , fi+1 Tto . Transitivity
Tto implies hf1 , fk+1 Tto , i.e., hf1 , f1 Tto , contradicts Tto strict total
order.

Proposition 2 (Complexity Consistency Checking). Determining whether feature subscription hF, H, P consistent checked O(|F | + |H| + |P |).
Proof. use Topological Sort (Cormen, Leiserson, & Rivest, 1990). Topological Sort
interested ordering nodes directed graph directed edge
hi, ji set edges graph node less node j order.
order use Topological Sort detecting whether feature subscription consistent,
associate nodes features edges precedence constraints. Then, subscription
consistent edges hi, ji graph associated subscription,
precedes j order computed Topological Sort. complexity Topological
Sort linear respect size graph (i.e., sum number nodes
number edges graph) detecting whether feature subscription consistent
O(|F | + |H| + |P |).
Definition 7 (Anti-subscription). Given catalogue hFc , Hc consistent feature subscription = hF, H, P i, anti-subscription tuple hFa , Pa defined follows. f Fc
element Fa directed graph associated subscription obtained adding feature f , i.e., hF {f }, Hc F {f } P i, cyclic; i, j F , j
Pa directed graph associated subscription obtained adding
precedence j, i.e., hF {i, j}, Hc F {i,j} P {i j}i, cyclic.
definition anti-subscription suggests one way computing anti-subscription
given subscription. order test whether feature/precedence belongs antisubscription check consistency resulting subscription. O(|Fc |)
279

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

features O(|Fc |2 ) precedences, worst-case time complexity computing antisubscription O(|Fc |2 (|F | + |H| + |P |)).
Definition 8 (Partial Order Consistent Subscription). Given consistent subscription
hF, H, P i, partial order subscription transitive closure (H P )
relation H P .
worst-case complexity finding transitive closure O(|F |3 ).
Definition 9 (Total Order Consistent Subscription). total order consistent subscription topological sort directed graph hF, H P i, i.e., total order extending
relation H P .
worst-case complexity finding total order linear time respect
size corresponding graph.

5. Symmetry Inherent Reformulation
One services provided end-user configuring feature subscription
computation compatible pairs total orders source target features.
section, show original subscription, defined Section 3, reformulated, described Section 4, symmetries introduced. Two total orders
reformulated subscription symmetric correspond pair total orders (on source target features) original subscription. formally,
let = hhFso , Hso , Pso i, hFto , Hto , Pto ii subscription catalogue hFs , Hs , Ft , Ht i,
r = hF r , H r , P r corresponding subscription catalogue hFc , Hc
ct i, i.e., F r = F F , H r = H H
co , P r = P P
co . pair
hFs Ft , Hs H







total orders hTs , Tt compatible Conditions (1), (2) (3) Definition 3
hold. many-to-one relation set total orders r (see Definition
9) set compatible pairs total orders .
Let us consider subscription Fso = {1, 2, 3}, Fto = {2, 3, 4}, Hso = {1 2},

Ht = {4 3}, Pso Pto empty. corresponding r would F r = {1, 2, 3, 4},
H r = {1 2, 3 4}, P r = . r consistent. set total orders
r , set compatible pairs total orders shown Table 1.
cardinality former set six, latter five. last two total orders
r correspond last compatible pair total orders . due fact
union total order source features transpose total order
target features necessarily total order. example last pair total
orders Table 1, union 3 1 2 3 4 2 result total order,
since order 1 4.
repetition computation symmetric pairs total orders original subscription total orders reformulated subscription desirable.
order compute compatible pair total orders once, use algorithm
GetSolutions(S r ), shown Algorithm 1. algorithm two nested loops.
first loop selects total order set reversible features extends
total order generate set total orders source features set total orders
target features. second loop total order source features total order
280

fiApproaches Solving Telecommunications Feature Subscription Problem

Table 1: Total orders F r , Fso , Fto .
Sr

r

F
Fs
Fto
1234
123 432
1324
132 423
1342
132 243
3124
312 423
3142
312 243
3412

target features selected previously generated sets. Due fact
source features target features ordered independently GetSolutions(S r ),
unnecessary ordering imposed source features target features.
Algorithm 1 GetSolutions(S r )
Require:
r = hF r , H r , P r consistent subscription, F r = Fso Fto , Fso set
source features, Fto set target features, Fro = Fso Fto set
reversible features corresponding subscription .
GetTotalOrders(hF, Oi) generates set total orders extend
given acyclic binary relation defined set features F .
, R , , set (H r P r ) , Fro , Fso , Fto respectively.
Ensure: PTOs set pairs compatible total orders Fso Fto respectively.
1: PTOs
2: RTOs GetTotalOrders(hFro , R i)
3: r RTOs
4:
STOs GetTotalOrders(hFso , r i)
5:
TTOs GetTotalOrders(hFto , r i)
6:
STOs, TTOs
ct i}
7:
PTOs PTOs {hs ,
8: return PTOs
algorithm computes saves total orders given set reversible features
RT Os, given total order set reversible features computes saves
total orders source target features ST Os Os respectively. However,
presented algorithm purpose clarity. practice, total order
computed lazily, i.e., total order computed needed, thus avoiding need
keeping total orders generated memory.
amortised time complexity computing total orders extending given
acyclic binary relation linear respect number total orders (Pruesse &
Ruskey, 1994). Assuming r total orders Fro , total
281

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

orders Fso Fto consistent given total order Fro respectively,
time complexity GetSolutions O(r ). computation pairs
compatible total orders could impractical size resulting set large.
Therefore, cases computation number total orders could restricted
pre-specified number, heuristic used select r Line 3,
Line 6 Algorithm 1.
may pairs total orders Fso Fto desirable
others. instance, would desirable present end-user pairs
total orders easy extend (in terms addition feature user
precedence). One way use notion anti-subscription (see Definition
7). pair total orders associated anti-subscription. size
anti-subscription sum number features precedences involved
it. pairs total orders ordered increasing size corresponding
anti-subscriptions. size anti-subscription sense reflects constrained
pair total orders respect future addition number features
user precedences end-user may consider his/her subscription future.

6. Relaxations Feature Subscriptions
input feature subscription consistent goal relax dropping one
features user precedence constraints generate consistent feature subscription
closest initial users requirements. Therefore, introduce function w :
F P N assigns weights features user precedence constraints, indicating
importance user features user precedences. weights could
elicited directly data mining analysis user interactions. rest
paper feature subscriptionPis denoted byPS = hF, H, P, wi. value subscription
defined Value(S) = f F w(f ) + P w().
Definition 10 (Relaxation). relaxation feature subscription hF, H, P, wi catalogue hFc , Hc subscription hF 0 , H 0 , P 0 , w0 F 0 F , H 0 = HF 0 , P 0 P F 0
w0 w restricted F 0 P 0 .
Definition 11 (Optimal Relaxation). Let RS set consistent relaxations
feature subscription S. say Si RS optimal relaxation maximum
value among consistent relaxations, i.e., exist Sj RS
Value(Sj ) > Value(Si ).
Proposition 3 (Complexity Finding Optimal Relaxation). Finding optimal relaxation feature subscription NP-hard.
Proof. Given directed graph G = hV, Ei, Feedback Vertex Set Problem find
smallest V 0 V whose deletion makes graph acyclic. problem known NPhard (Garey & Johnson, 1979). prove finding optimal relaxation NP-hard
reduction feedback vertex set problem. feedback vertex set problem
reduced problem associating nodes directed graph V features
F , edges E catalogue precedence constraints H. set P define w
w(f ) = 1, f F . Thus, finding optimal relaxation = hF, H, P, wi corresponds
282

fiApproaches Solving Telecommunications Feature Subscription Problem

finding biggest set nodes V 00 deletion V V 00 G results
acyclic graph. Therefore, conclude finding optimal relaxation inconsistent
subscription NP-hard.
challenging operation feature subscriptions find optimal relaxation
subscription consistent, since NP-Hard. remainder paper
focus particular task.

7. Basic COP Model Finding Optimal Relaxation
section model problem finding optimal relaxation feature subscription hF, H, P, wi catalogue hFc , Hc constraint optimisation problem (Lesaint,
Mehta, OSullivan, Quesada, & Wilson, 2008c).
Variables Domains. associate feature F two variables: Boolean
variable bfi integer variable pfi . Boolean variable bfi instantiated 1 0
depending whether feature included subscription not, respectively. domain integer variable pfi {1, . . . , |F |}. Assuming computed subscription
consistent, integer variable pfi corresponds position feature sequence, consistent optimal relaxation. associate user precedence
constraint (i j) P Boolean variable bpij . Boolean variable bpij instantiated
1 0 depending whether j respected computed subscription not,
respectively. variable v associated value subscription, initial lower
bound 0 initial upper bound sum weights features
user precedences.
Constraints. catalogue precedence constraint (i j) H feature
feature j expressed follows:
bfi bfj (pfi < pfj ).
Note constraint activated selection variables bfi bfj instantiated
1. user precedence constraint (i j) P placed j
subscription expressed follows:
bpij (bfi bfj (pfi < pfj )).
Note user precedence constraint holds features j included
subscription also feature placed j, is, selection variables bfi
bfj instantiated 1 pfi < pfj true.
value subscription equal sum weights included features
included user precedences. constraint expressed following:
X
X
v=
bfi w(i) +
bpij w(i j).
(1)


(ij)P

Enforcing arc consistency Equation (1), general, exponential (Zhang & Yap, 2000).
Therefore, cp solvers perform bounds consistency constraint, equivalent
283

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

enforcing arc consistency following pair constraints, seen
decomposition Equation (1):
X
X
bpij w(i j).
(2)
v
bfi w(i) +


v

X

(ij)P

bfi w(i) +



X

bpij w(i j).

(3)

(ij)P

order reason complexities enforcing different consistency techniques
always assume two inequality constraints used instead equality constraint.
Objective.

objective find optimal relaxation feature subscription.

investigated impact maintaining three different levels consistency
within branch bound search. first arc consistency rest mixed consistencies. following sections shall describe consistency techniques present
worst-case time complexities enforced instance feature subscription,
formulated described above. results complexities presented
based assumption Boolean variables associated inclusion/exclusion features user precedences decision variables. remark
problem arc-consistent instantiating Boolean variables also
globally consistent.
7.1 Arc Consistency
Let e sum number user precedences number catalogue precedences,
let n sum number features number user precedences,
let number features. complexity achieving arc consistency (ac)
(catalogue/user) precedence constraint constant respect number variables.
catalogue precedence constraint made arc-consistent Boolean variables
involved constraint initialised domains position variables
modified. Thus, catalogue precedence constraint made arc-consistent
(1 + 1 + (d 1) + (d 1)) times, effectively 2d times. user precedence constraint
made arc-consistent 2d + 1 times. Since are, total, e precedence
constraints, worst-case time complexity imposing arc consistency precedence
constraints O(e d), also optimal. addition, arc consistency also enforced
linear inequalities (2) (3), complexity linear respect
number Boolean variables. Whenever Boolean variable instantiated constraint
revised since n Boolean variables, made arc-consistent n
times. Therefore, worst-case time complexity enforcing arc consistency linear
inequalities O(n2 ), optimal. Thus, worst-case time complexity enforcing
ac instance basic cp model finding optimal relaxation O(e + n2 ).
7.2 Singleton Arc Consistency
Maintaining higher level consistency expensive terms time. However,
values removed domains variables, search effort
284

fiApproaches Solving Telecommunications Feature Subscription Problem

reduced may save time. shall investigate effect maintaining Singleton
Arc Consistency (sac) Boolean variables ac remaining variables
denote sacb . used sac-1 (Debruyne & Bessiere, 1997) algorithm
enforcing sac Boolean variables. Enforcing sac Boolean variables sac-1
manner works traversing list 2n variable-value pairs. instantiation
Boolean variable x value 0/1, domain wipeout enforcing ac
value removed corresponding domain ac enforced. time value
removed, list traversed again. Since 2n variable-value pairs, number
calls underlying arc consistency algorithm 4n2 . Thus worst-case
time complexity sacb O(n2 (e + n2 )).
sacb optimal worst-case time complexity. sacb arc consistency
enforced subproblem obtained restricting Boolean variable single value
2n times, time arc consistency established scratch. However, one
take incremental property arc consistency account obtain optimal version
sacb . Following work Lecoutre (2009) arc consistency algorithm said
incremental worst-case time complexity applied
given network P applied times P two
consecutive executions, least one value deleted. sum domain
sizes variables involved problem P . idea behind optimal version
want achieve arc consistency scratch subproblem, but,
instead, benefit incremental property underlying arc consistency algorithm.
results asymptotic complexity O(e + n2 ) enforcing arc consistency 2n
times. Thus, time complexity optimal version sacb would O(n (e + n2 )).
7.3 Restricted Singleton Arc Consistency
main problem sac-1 deleting single value triggers loop again.
Restricted Singleton Arc Consistency (rsac) avoids considering variable-value
pair (Prosser, Stergiou, & Walsh, 2000). investigate effect enforcing
(rsac) Boolean variables ac remaining variables, denote rsacb .
worst-case time complexity rsacb O(n (e + n2 )).

8. CP Models
section present two cp approaches. first approach uses global constraint achieves higher level consistency taking account cycles
precedence constraints. second approach model problem weighted constraint satisfaction problem.
8.1 Global Constraint
global constraint captures relation several variables. takes account
structure problem prune values. instance, user selected set
features, F = {1, 2, 3, 4} features constrained catalogue precedences
1 2, 2 1, 3 4 4 3, three features required included
subscription one infer problem inconsistent without search.
285

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

possible inferring cycles precedence constraints using prune
bounds objective function.
soft global precedence constraint SoftPrec proposed Lesaint et al. (2008a).
holds strict partial order selected features subject
relevant hard (catalogue) precedence constraints selected soft (user) precedence
constraints, value subscription within provided bounds. shown
Lesaint et al. (2008a), achieving ac SoftPrec NP-complete since
way determine polynomial time whether strict partial order whose value
given bounds. Therefore, ac approximated pruning domains
variables based filtering rules follow definition SoftPrec.
time-complexity achieving pruning O(|F |3 ), polynomial. upper
bound value subscription pruned based incompatibilities
inferred pairs features, dependencies user precedences
corresponding features. pruning rules SoftPrec used within branch
bound search find optimal relaxation feature subscription.
Let hF, H, P, wi subscription. Let bf vector Boolean variables associated
F . say feature included bf(i) = 1, excluded bf(i) = 0.
abuse notation using bf(i) mean bf(i) = 1, bf(i) mean bf(i) = 0. similar
convention adopted Boolean variables. Let bp |F |2 matrix Boolean
variables. bp intended represent strict partial order included features F 0
compatible catalogue constraints restricted F 0 .
Definition 12 (SoftPrec). Let = hF, H, P, wi feature subscription, bf bp
vectors Boolean variables, v integer variable, SoftPrec(S, bf, bp, v) holds

1. bp strict partial order restricted bf, i.e.,
i, j F : bp(i, j) bf(i) bf(j)
(restricted),
i, j F : bp(i, j) bp(j, i)
(asymmetric),
i, j, k F : bp(i, j) bp(j, k) bp(i, k) (transitive),
2. bp compatible H restricted bf, i.e.,
(i j) H : bf(i) bf(j) bp(i, j),
3. v =

P



bf(i) w(i) +

P

(ij)P

bp(i, j) w(i j).

set constraints cp model contains SoftPrec. decision variables
model bf bp. solution SoftPrec consistent relaxation
subscription hF, H, P, wi. Notice feedback vertex set problem (Garey & Johnson,
1979) expressed terms SoftPrec associating vertices features arcs
catalogue precedence constraints. Therefore, achieving generalised arc consistency
SoftPrec NP-hard.
286

fiApproaches Solving Telecommunications Feature Subscription Problem

8.2 Weighted CSP Model
classical csp framework extended associating weights (or costs)
tuples (Larrosa, 2002). Weighted Constraint Satisfaction Problem (wcsp) specific
extension relies specific valuation structure S(k) defined follows.
Definition 13 (Valuation Structure). S(k) triple ({0, . . . , k}, , ) where: k {1, . . . , }
either strictly positive natural number infinity, {0, 1, . . . , k} set naturals less
equal k, sum valuation structure defined as: ab = min{k, a+b},
standard order among naturals.
wcsp instance defined valuation structure S(k), set variables (as
classical csp instances) set constraints. domain associated variable
cost function constraint. precisely, constraint C
tuple built domains associated variables involved C,
value {0, 1, . . . , k} assigned t. constraint C assigns cost k tuple
t, means C forbids t. Otherwise, permitted C corresponding cost.
cost instantiation variables sum (using operator ) constraints
involving variables instantiated. instantiation consistent cost strictly less
k. goal wcsp problem find full consistent assignment variables
minimum cost. wcsp formulation finding optimal relaxation input
subscription hF, H, P, wi, inconsistent, outlined below.
maximum acceptable cost
X
X
k=
w(i) +
w().


P

associate feature F integer variable pfi . domain integer
variable, D(pfi ), {0, . . . , |F |}. pfi instantiated 0, indicates excluded
subscription.
unary cost function Ci : D(pfi ) {0, w(i)} assigns costs assignments variable
pfi following way:

0
> 0
Ci (a) =
w(i) = 0
catalogue precedence constraint (i j) H associated binary cost function
Hij : D(pfi ) D(pfj ) {0, k} assigns costs assignments variables pfi pfj
following way:

0 = 0 b = 0 < b
Hij (a, b) =
k otherwise
user precedence constraint (i j) P associated binary cost function Pij :
D(pfi ) D(pfj ) {0, w(i j)} assigns costs assignments variables pfi pfj
following way:

0
6= 0 b 6= 0 < b
Pij (a, b) =
w(i j) otherwise
Note user precedence constraint holds features j included
subscription also feature placed j, is, integer variables pfi
pfj instantiated value greater 0 pfi < pfj true.
287

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

9. Boolean Satisfiability
Boolean Satisfiability Problem (sat) decision problem instance
expression propositional logic. problem decide whether assignment
true false values variables make expression true. expression
normally written conjunctive normal form. Partial Weighted Maximum Boolean
Satisfiability Problem (pwmsat) extension sat includes notions hard
soft clauses. solution respect hard clauses. Soft clauses associated
weights. goal find assignment satisfies hard clauses minimises
sum weights unsatisfied soft clauses. section present Boolean
satisfiability formulations finding optimal relaxation feature subscription.
9.1 Atom-based Encoding
atom-based encoding, atom, like f g, associated propositional variable
asymmetricity transitivity properties precedence relation explicitly
encoded. atom-based encoding finding optimal relaxation feature subscription
hF, H, P, wi outlined below.
Variables. Let PrecDom set possible precedence constraints defined
F , i.e., {i j : {i, j} F 6= j}). feature F Boolean
variable bfi , true false depending whether feature included
computed subscription. precedence constraint (i j) Boolean variable
bpij , true false depending whether precedence constraint holds
computed subscription. bpij true, then, roughly speaking, means features
j included, precedes j.
Clauses. weighted-clause represented tuple hw, ci, w weight
clause c. Note hard clauses associated weight >, represents
infinite penalty satisfying them.
catalogue precedence constraint, (i j) H, must satisfied features
j included computed subscription. modelled adding following
hard clause:
h>, (bfi bfj bpij )i.
precedence relation transitive asymmetric order ensure
subscription graph acyclic. ensure asymmetricity, following clause added
every pair {i j, j i} PrecDom:
h>, (bpij bpji )i.

(4)

bpij bpji false. However, one true one
false.
ensure transitivity, every {i j, j k} PrecDom, following clause added:
h>, (bpij bpjk bpik )i.

(5)

Note Rule (5) need applied hi, j, ki 6= k since precedence constraints reflexive Rule (4).
288

fiApproaches Solving Telecommunications Feature Subscription Problem

precedence constraint (i j) PrecDom satisfied corresponding
features j features included. ensured considering following clauses:
h>, (bpij bfi )i

h>, (bpij bfj )i.

need penalise solution include feature F user precedence
constraint (i j) P . done adding following clauses:
hw(i), (bfi )i

hw(i j), (bpij )i.

cost violating clauses weight feature weight user
precedence constraint j respectively.
Reducing Variables Clauses. straightforward realise atom
based encoding described previous section requires (n2 ) Boolean variables
(n3 ) clauses, n number features1 . describe two techniques
reduce number variables clauses. subscription contains cycle
transitive closure H P contains cycle. Therefore, instead associating
Boolean variable possible precedence constraint, sufficient associate
Boolean variables precedence constraints transitive closure H P .
Reducing Boolean variables also reduce transitive clauses, especially
input subscription graph dense. Otherwise, Rule (5) generate |F | (|F | 1)
(|F | 2) transitivity clauses Rule (4) generate (|F | (|F | 1))/2 asymmetricity
clauses. example, subscription hF, H, P, wi F = {1, 2, 3, 4, 5, 6}, H = {1
2, 2 1, 3 4, 4 3, 5 6, 6 5}, P = , Rules (4) (5) generate 120
transitivity clauses 15 asymmetricity clauses respectively. Since relaxation
given subscription respecting clauses generated Rule (4) acyclic, 120 transitivity
clauses 12 asymmetricity clauses redundant. Thus, PrecDom instead set
transitive closure H P , Rules (4) (5) would generate redundant
clauses. reduce number transitivity clauses h>, (bpij bpjk bpik )i
considering none j i, k j, k H, especially
input subscription graph sparse. reason transitivity clauses
always entailed due enforcement catalogue precedence constraints.
reduction number clauses might reduce memory requirement also might
impact efficiency unit propagation, turn may reduce runtime.
9.2 Symbol-based Encoding
Another sat approach based symbol-based encoding partial order constraints
presented Codish et al. (2009). Partial order constraints (Codish, Lagoon, & Stuckey,
2008) basically propositional formulae except propositions also statements
partial order finite set symbols. symbol-based encoding transitivity
asymmetricity properties precedence relation enforced implicitly.
also Boolean variable bfi associated feature F indicating whether
included excluded. Boolean variable bpij associated precedence
1. Given function g(n), (g(n)) denotes set functions f (n) exist positive constants
c1 , c2 n0 0 c1 g(n) f (n) c2 g(n) n n0 (Cormen et al., 1990).

289

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

constraint (i j) H P . catalogue constraint (i j) H following clause
added: h>, (bfi bfj bpij )i. precedence constraint j (H P )
following clauses added: h>, (bpij bfi )i h>, (bpij bfj )i. precedence
constraint j (H P ) propositional constraint bpij Ji jK encoded2 .
intuitively means bpij true precedes j. Two different ways encoding
precedence constraint Ji jK presented Codish et al. (2009), called
unary encoding binary encoding. brief description presented
Section 9.2.1 Section 9.2.2, provide basis theoretical comparisons.
Advanced techniques encoding objective function also proposed
Codish et al. (2009). However encoding objective function orthogonal
way precedences encoded. purpose compare encoding
precedence constraints, omit details encoding objective function
symbol-based encoding proposed Codish et al. (2009). Instead, assume
approach objective function encoded done atom-based case. Therefore,
pwmsat setting following soft clauses added features user precedences:
hw(i), bfi hw(i j), bpij i.
9.2.1 Unary Encoding
symbol-based unary encoding (Codish et al., 2009) feature associated
ordered set Boolean variables represents unary encoding position.
unary encoding non-negative integer n assignment values sequence
n Boolean variables hm1 , . . . , mn m1 m2 mn . integer-value
representation number variables mi taking value 1. example, sequence
11100000 represents number = 3 using n = 8 variables. pair consecutive
variables sequence, say mk mk+1 , clause h>, (mk+1 mk )i introduced
encoding order enforce mk+1 assigned 1 predecessor sequence,
mk , must assigned 1. Let j two non-negative integer variables
assigned values less equal n. Let hi1 , . . . , hj1 , . . . , jn sequences
n Boolean variables represent unary-encodings j respectively. unaryencoding j denoted hi1 , . . . , hj1 , . . . , jn i, means number
variables assigned values 1 sequence hi1 , . . . , less number variables
assigned values 1 sequence hj1 , . . . , jn i. Notice hi1 , . . . , hj1 , . . . , jn holds
holds, j1 holds, hi1 , . . . , hj2 , . . . , jn , 0i holds. hj2 , . . . , jn , 0i
encodes integer 0 n 1, predecessor hj1 , . . . , jn i.
inequality hi1 , . . . , hj2 , . . . , jn , 0i encoded follows: 1 k n1, ik jk+1 .
resulting weighted clauses bpij Ji jK hbpij i, hbpij j1 i,
1 k n 1, h>, (bpij ik jk+1 )i. Overall, symbol-based unary encoding
requires (n2 ) propositional variables (n per feature) involves (k n) clauses (n per
precedence constraint), k = |H P |.
9.2.2 Binary Encoding
symbol-based binary encoding feature associated ordered set
Boolean variables represents binary log encoding position. binary encod2. Ji jK Boolean formula satisfiable precedes j.

290

fiApproaches Solving Telecommunications Feature Subscription Problem

ing non-negative integer n sequence values assigned
k variables v1 , . . . , vk ,
P
k = dlog2 ne. value representation 1mk 2km vm . example, sequence 101 represents number 5 using 3 variables. precedence constraint
encoded using lexicographical comparator (Apt, 2003). Given two numbers binary
encoded form hi1 , . . . , ik hj1 , . . . , jk i, precedence constraint hi1 , . . . , ik < hj1 , . . . , jk
holds exists > 0 im < jm l < m, il = jl . resulting encoding conjunctive normal form. Therefore, Tseitin transformation3
(Tseitin, 1968) used obtain corresponding formula conjunctive normal form.
given precedence constraint, Tseitin transformation introduces (log n) variables
clauses, since log n length formula associated given precedence
constraint. Overall, symbol-based binary encoding requires (n log n) propositional
variables involves (k log n) clauses, k = |H P |.
9.3 Comparison Encodings
Unit Propagation (up) central component search-based sat solver. Given unit
clause l, unit propagation applies following rules: (1) every clause containing l removed, (2) l removed every clause contains literal. rules
applied fixed-point reached. application two rules leads new set
clauses equivalent old one. Unit propagation detects inconsistency
empty clause generated.
Let ae, seu , seb denote atom-based encoding, symbol-based unary encoding,
symbol-based binary encoding respectively. difference encodings
way encode acyclicity. ae acyclicity encoded explicitly adding transitivity
asymmetricity clauses. seu seb acyclicity encoded implicitly associating
feature set Boolean variables represent position (an integer value)
precedence constraint expressed terms positions. Boolean variables
denoting inclusion (or exclusion) features user precedences called problem
variables. variables common encodings. optimal relaxation
expressed terms problem variables. order show unit propagation
one encoding stronger unit propagation another encoding, need map
decisions one encoding one. Unfortunately, possible map
decisions atom-based symbol-based encodings. example,
assignment position variable symbol-based encodings cannot expressed
terms assignments variables ae. Nevertheless, following, prove
unit propagation ae stronger unit propagation seb set assignments
restricted problem variables.
Proposition 4. Given set assignments restricted problem variables, unit
propagation detects inconsistency seb also detects inconsistency ae,
converse true.
3. Given propositional formula, Tseitin transformation obtains equivalent formula conjunctive
normal form associating new variable every subformula original formula applying
following equivalences: (i) s0 (s1 s2 ) {(s0 s1 s2 ), (s0 s1 ), (s0 s2 )}, (ii) s0 (s1 s2 )
{(s0 s1 s2 ), (s0 s1 ), (s0 s2 )}, (iii) s0 s1 {(s0 s1 ), (s0 s1 )}.

291

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

Proof. atom-based symbol-based binary encoding differ encoding acyclicity, i.e., encoding transitivity asymmetricity properties
precedence relation. symbol-based binary encoding transitivity asymmetricity properties implicitly captured clauses corresponding propositional
constraints form bpij Ji jK. Therefore, order prove detects inconsistency seb also detects inconsistency ae, sufficient show bpij
falsified due violation Ji jK seb unit propagation, happens ae.
clauses corresponding Ji jK defined terms problem variables
none clauses unary4 . Therefore, falsify bpij seb . trivially
implies that, set problem variables instantiated, ae detects
inconsistency detected seb .
show exists case inconsistency detected
ae detected seb . Let F = {i, j, k} set features, H = ,
P = {i j, j k, k i} set user precedence constraints. encodings
Boolean variable per user precedence constraint: bpij , bpjk bpki assume
bpij , bpjk bpki set true. ae unit resolution bpij bpjk
transitive clause bpij bpjk bpik yields bpik , unit-resolution bpik
bpki bpik yields bpki , results empty clause resolved bpki .
seb , ordered set Boolean variables associated feature. 3
features, two Boolean variables required per feature. Therefore feature i, j
k associated hi1 , i2 i, hj1 , j2 i, hk1 , k2 respectively used encode
precedence constraint. precedence constraint, say j, set clauses
encode propositional constraint bpij (i1 j1 ) ((i1 j1 ) (i2 j2 )) also
added. formulae associated j k k encoded similarly. Although
bpij bpjk set true, infer bpik , since none clauses obtained
applying Tseitin transformation unary. Therefore, unlike ae, seb detect
inconsistency.
Thus, infer unit propagation detects inconsistency seb also
detects inconsistency ae, converse true.
Given set assignments restricted problem variables, unit propagation detects
inconsistency seu also detects inconsistency ae, converse also true.
follows directly explanation symbol-based unary encoding
atom-based encoding. Notice encodings detect cycles consisting two features
form j j i. cycles involve two features j, j k, k
infer k result cycle consisting two features k.

10. Mixed Integer Linear Programming
linear programming goal optimise objective function subject linear equality inequality constraints. variables forced integer-valued,
problem called Mixed Integer Linear Programming (mip) problem. standard way
4. 2 features, clauses corresponding Ji jK seb unary, case
inconsistency detected exists. However, inconsistency detected
atom-based encoding.

292

fiApproaches Solving Telecommunications Feature Subscription Problem

expressing problems presenting function optimised, linear constraints respected domain variables involved. basic cop
formulation atom-based pwmsat formulation finding optimal relaxation
feature subscription hF, H, P, wi translated mip formulation. translation
pwmsat formulation mip straightforward. particular formulation
observed cplex able solve even simple problems within time limit 4
hours. paper, present mip formulation corresponds basic
cop formulation presented Section 2.2.
Variables. F , use binary variable bfi real variable pfi . binary
variable bfi equal 1 0 depending whether feature included not. real
variable pfi , 1 pfi |F |, bfi set 1, used determine position feature
computed subscription. user precedence constraint (i j) P , use
binary variable bpij . instantiated 1 0 depending whether precedence
constraint j holds not.
Linear Inequalities. features j included computed subscription
(i j) H position feature must less position feature j.
effect, need translate underlying implication (bfi bfj (pfi < pfj ))
following linear inequality:
pfi pfj + n bfi + n bfj 2n 1 .

(6)

Here, n constant equal number features, |F |, selected user.
bfi bfj 1, Inequality (6) force (pfi < pfj ). Note
required user precedence constraint (i j) P , since violated.
user precedence (i j) P equivalent implication bpij (pfi < pfj )bfi bfj ,
turn equivalent conjunction three implications (bpij (pfi < pfj )),
(bpij bfi ) (bpij bfj ). implications translated following
inequalities:
(7)
pfi pfj + n bpij n 1
bpij bfi 0

(8)

bpij bfj 0 .

(9)

Inequality (7) means bpij = 1 forces pfi < pfj true. Also, bpij = 1
bfi bfj equal 1 Inequalities (8) (9) respectively.
Objective Function. objective find optimal relaxation feature subscription configuration problem hF, H, P, wi maximises sum weights
features user precedence constraints selected:
X
X
Maximise
w(i) bfi +
w(i j) bpij .


(ij)P

11. Experimental Results
section, shall describe empirical evaluation finding optimal relaxation
randomly generated feature subscriptions using constraint programming, partial weighted
maximum Boolean satisfiability integer linear programming.
293

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

11.1 Problem Generation Experimental Settings
order compare different approaches generated experimented variety
random catalogues many classes random feature subscriptions. random
selections performed uniform distributions. random catalogue defined
tuple hfc , Bc , Tc i. Here, fc number features, Bc number binary
constraints Tc {, , } set types constraints. Note j means
given subscription features j cannot exist together. random
catalogue generated selecting Bc pairs features randomly fc (fc 1)/2 pairs
features. selected pair features associated type constraint
selected randomly Tc . random feature subscription defined tuple
hfu , pu , wi. Here, fu number features selected randomly fc features,
pu number user precedence constraints pairs features
selected randomly fu (fu 1)/2 pairs features, w integer greater 0.
feature user precedence constraint associated integer weight
selected randomly 1 w inclusive.
generated catalogues following forms: h50, 250, {, }i, h50, 500, {, , }i
h50, 750, {, }i. random catalogue, generated classes feature subscriptions following forms: h10, 5, 4i, h15, 20, 4i, h20, 10, 4i, h25, 40, 4i, h30, 20, 4i, h35, 35, 4i,
h40, 40, 4i, h45, 90, 4i h50, 5, 4i. Note h50, 250, {, }i default catalogue
value w 4 default, unless stated otherwise. catalogue 10 instances
feature subscriptions generated mean results reported paper5 .
remark 4 randomly generated instances consistent 270 generated
instances. consistent instances instances feature subscription class h10, 5, 4i
catalogue h50, 250, {, }i.
experiments performed pc pentium 4 (cpu 1.8 ghz 768mb
ram) processor. performances approaches measured terms search
nodes (#nodes) runtime seconds (time). time reported time spent
finding optimal solution proving optimality. used time limit 14,400
seconds (i.e., 4 hours) cut search. initial bounds computed
approaches.
11.2 Evaluation Constraint Programming Formulations
basic constraint optimisation problem model presented Section 7 first investigated effect Maintaining Arc Consistency (mac) within branch bound search.
also studied effect maintaining different levels consistency different sets
variables within problem. particular investigated, (1) maintaining singleton arc
consistency Boolean variables mac remaining variables (see Section 7.2),
(2) maintaining restricted singleton arc consistency Boolean variables mac
remaining variables (see Section 7.3); former denoted msacb latter mrsacb . branch bound search algorithms tested two different
variable ordering heuristics: dom/deg (Bessiere & Regin, 1996) dom/wdeg (Boussemart,
Hemery, Lecoutre, & Sais, 2004). dom domain size, deg original degree
5. generated instances available http://4c.ucc.ie/~lquesada/FeatureSubscription/page/
instances.htm.

294

fiApproaches Solving Telecommunications Feature Subscription Problem

variable, wdeg weighted degree variable. experiments
basic constraint optimisation problem formulation done using choco6 (version 2.1)
Java library constraint programming systems. results three branch
bound search algorithms dom/deg variable ordering heuristic presented
Table 2 dom/wdeg variable ordering heuristic presented Table 3.
Table 2: Average results mac, mrsacb msacb dom/deg heuristic.
hfu , pu
h20, 10i
h25, 40i
h30, 20i
h35, 35i
h40, 40i

time
0.2
9.8
5.6
125.2
1,716.9

MAC
#nodes
1,691
70,233
29,076
479,650
5,307,530

MRSACb
time
#nodes
0.0
45
0.5
174
0.6
179
7.3
1,269
68.8
9,830

MSACb
time
#nodes
0.0
44
0.6
156
0.7
157
8.1
1,083
75.1
8,466

Table 3: Average results mac, mrsacb msacb dom/wdeg heuristic.
hfu , pu
h20, 10i
h25, 40i
h30, 20i
h35, 35i
h40, 40i

time
0.1
3.3
2.4
76.9
889.0

MAC
#nodes
701
20,096
10,511
248,447
2,255,713

MRSACb
time
#nodes
0.0
42
0.5
164
0.5
161
5.5
932
45.9
6,105

MSACb
time
#nodes
0.0
41
0.6
145
0.6
142
6.3
798
52.9
5,184

Tables 2 3 clearly show maintaining (r)sac Boolean variables ac
integer variables dominates maintaining ac variables. best
knowledge first time significant improvement observed
maintaining partial form singleton arc consistency search. problem
size increases difference terms number nodes visited mrsacb msacb
increases. Note mrsacb usually visits nodes visited msacb ,
difference significant. suggests level consistency
enforced rsac instances feature subscription problem close
enforced sac. Despite visiting nodes, mrsacb usually requires less time msacb .
average, three search algorithms perform better dom/wdeg heuristic
dom/deg heuristic. Note remainder paper results
correspond basic cop model obtained using mrsacb dom/wdeg variable
ordering heuristic.
remark underlying algorithms mac mrsacb enforce ac
rsacb respectively optimal worst-case time complexity. However, underlying
algorithm msacb enforces sacb optimal worst-case time complexity.
Implementing algorithm enforce sacb optimal worst-case time complexity
cumbersome also higher space requirement. works Bessiere et al.
(2004, 2005) provide evidence optimal algorithm enforcing sac used
preprocessor expensive terms running time space. Therefore,
6. http://choco.sourceforge.net/

295

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

maintaining search, case, could even expensive. Indeed
exists sub-optimal efficient algorithms enforcing singleton arc consistency
constraints networks, proposed Lecoutre et al. (2005) and, remains see whether
efficient algorithms reduce running time msacb .
Notice sacb prune values rsacb . However, practice, difference
pruning instances feature subscriptions much, evident
based number nodes time shown Tables 2 3. recall rsacb
enforces partial sacb . given node search tree, rsacb enforces arc consistency
one time assignment value Boolean variable, whereas sacb
enforce arc consistency n times worst-case. n sum
Boolean variables associated features user precedences. Nevertheless, practice,
observed much less. example, instance feature subscription
class h40, 40i arc consistency enforced 7 times variable-value pair,
much less n = 80. also justifies use non-optimal version
algorithm enforce sacb .
wcsp formulation finding optimal relaxation feature subscription
also tested. purpose toulbar2 (a generic solver wcsp) used7 . general
results terms time poor. remark solution wcsp model total
order features whose position variables assigned values greater 0. Due
holes (when feature excluded) different assignments position variables may lead
total order. Thus, search effort could spent wcsp formulation.
recall basic cop model decision variables Boolean variables
indicate inclusion/exclusion features user precedences position
variables. Therefore, optimal solution basic cop model may necessarily
total order included features. Nevertheless, obtained computing
topological sort included user precedences catalogue precedences defined
included features.
order remove symmetries wcsp formulation, described Section 8.2,
augmented. One way could associate costs values (greater 0)
position variables way unique assignment values
variables, optimal given strict partial order. preliminary investigation
suggested number nodes reduced expense increasing time.
current setting, wcsp approach used black box. Indeed, certain
improvements made may improve performance terms time.
example, stronger soft consistency techniques applied similar singleton arc
consistency cop model, efficient feature subscription problem.
also investigated impact using global constraint SoftPrec. global
constraint implemented choco. results obtained using denoted
sp. Five variants SoftPrec investigated Lesaint et al. (2009).
results presented paper correspond variant observed best
terms time, Lesaint et al. (2009) denoted sp4 . results Tables 68 show SoftPrec always outperforms mrsacb average. However, Lesaint et al.
(2008a) theoretically showed pruning achieved maintaining rsac Boolean
7. http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro

296

fiApproaches Solving Telecommunications Feature Subscription Problem

variables cop model ac remaining variables incomparable
pruning achieved using SoftPrec.
11.3 Evaluation Boolean Satisfiability Formulations
evaluation atom-based pwmsat encoding feature subscription carried
three different solvers: (a) sat4j8 (version 2.1.1), efficient library sat solvers
Java implements minisat specification (Een & Sorensson, 2003); (b) minisat+9
(version 1.13+), pseudo-Boolean solver implemented top minisat (Een & Sorensson,
2006); (c) clasp10 (version 1.3.0), answer set solver supports Boolean constraint
solving (Gebser, Kaufmann, & Schaub, 2009). two last solvers pseudo-Boolean
solvers, pwmsat instances translated linear pseudo-Boolean instances
associating clause linear pseudo-Boolean constraint, defining objective
function weighted sum soft clauses pwmsat model (de Givry, Larrosa,
Meseguer, & Schiex, 2003).
results evaluation summarized Table 4. remark results
sat4j solver, especially dense catalogues, roughly 10 times faster terms
time compared presented Lesaint et al. (2008c). simply due
advances version sat4j used obtain results. Despite that,
sat4j significantly outperformed minisat+ clasp. observed one
order-of-magnitude gap cases catalogue sparse. clasp minisat+
seem incomparable instances. Even though clasp performed better
toughest category instances h45, 90i, clasp spent 27% time solving whole set
instances. also noticed clasp seems sensitive number features
sparse instances. observed gap one order-of-magnitude categories
h45, 90i h50, 4i h50, 250, {, }i catalogue sat4j minisat+, gap
observed clasp significant.
Table 4: Results atom-based encoding using different SAT solvers.
hf, pi
h30, 20i
h35, 35i
h40, 40i
h45, 90i
h50, 4i

h50, 250, {, }i
sat4j
clasp
minisat+
0.6
0.1
1.2
2.7
0.8
3.0
18.2
6.9
8.0
1,156.4 111.1
119.6
90.8
79.0
11.9

h50, 500, {, , }i
sat4j
clasp
minisat+
0.5
0.0
0.7
0.7
0.1
1.3
1.2
0.1
2.0
3.6
0.4
5.7
3.7
0.6
3.8

h50, 750, {, }i
sat4j
clasp
minisat+
0.8
0.2
0.7
2.5
0.8
2.0
8.0
3.2
4.5
46.7
13.8
25.5
147.1
43.8
12.8

compare atom-based encoding symbol-based unary binary
encodings described Section 9.2. order fair comparison
encodings need solve instances feature subscription machine
using solver. access instances feature subscription
seu seb encodings, use results experiments run Daniel Le Berre11
three encodings: ae, seu seb instances feature subscription
8.
9.
10.
11.

http://www.sat4j.org/
http://minisat.se/MiniSat+.html
http://www.cs.uni-potsdam.de/clasp/
http://www.cril.univ-artois.fr/~leberre/

297

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

using sat4j solver (version 2.1.0) pc pentium 4 (cpu 3 ghz). Codish et al. (2009)
also made results public.
Table 5 presents results feature subscriptions different sizes different catalogues
three encodings: ae, seu , seb . experimental results show ae is, general,
efficient seb , consistent fact unit propagation ae
strictly stronger unit propagation seb . Note ae two orders-ofmagnitude faster seb . Notice seb never outperforms seu ae
class feature subscription.
Table 5: Mean results terms time obtained using ae, seu , seb encodings sat4j.
subscription
h10, 5i
h15, 20i
h20, 10i
h25, 40i
h30, 20i
h35, 35i
h40, 40i
h45, 90i
h50, 4i

h50, 250, {, }i
ae
seu
seb
0.05
0.12
0.17
0.12
0.69
0.32
0.15
0.76
0.36
0.41
1.70
1.87
0.58
1.66
1.22
1.40
3.46
7.12
9.20
9.06
21.03
484.16 161.37
1,844.01
30.72
7.09
11.97

h50, 500, {, , }i
ae
seu
seb
0.07 0.29
0.15
0.13 0.95
0.30
0.17 1.24
0.42
0.27 1.75
1.23
0.31 2.21
1.49
0.57 3.15
3.35
0.91 3.73
5.31
2.34 8.85
22.11
2.39 4.91
8.77

h50, 750, {, }i
ae
seu
seb
0.07
0.31
0.16
0.14
1.12
0.47
0.18
1.32
0.79
0.35
2.44
5.90
0.47
3.58
9.16
1.33
7.19
49.65
3.22
15.67
153.75
24.64
64.79
1205.12
61.57 41.87
618.66

Although results reported Tables 1, 2 3 works Codish et al. (2008,
2009) suggest seb much better ae, results shown Table 5 contradict
conclusion. results obtained using seb significantly outperformed obtained using ae. apparent conflict could one several reasons. results
reported Codish et al. (2008) based different instances different encodings
instances used symbol-based encoding much easier fact
large size instances 50 features already consistent. Also, experiments
different encodings conducted different machines. Codish et al. (2008, 2009)
obtained results symbol-based encoding atom-based encodings using
different solvers. experiments seb done using solver, implemented top minisat, ae results obtained using sat4j solver.
apparent Table 4 use different solvers make huge difference
terms runtime. fact, observed huge improvement ae tested
minisat+ solver. latter fact suggests speed observed Codish et al.
(2008, 2009) could mostly use minisat. Also, notice results
depicted Table 5 accordance fact unit propagation atom-based
encoding strictly stronger unit propagation symbol-based binary encoding.
Although unit propagation ae encoding equivalent unit propagation seu
encoding assignments restricted problem variables, empirically always
possible observe due exploration search trees different orders. Table 5
shows ae seu incomparable terms time. Therefore, possible
conclude superiority two approaches. also informed
instances symbol-based encodings also include computation objective
function, comparison value objective function upper bound
described Codish et al. (2009). However, needed applying pwmsat
solver sat4j. extra clauses may indeed prevent symbol-based approaches
298

fiApproaches Solving Telecommunications Feature Subscription Problem

perform best. Nevertheless, clauses symbol-based encodings
coming encoding precedence constraints.
Finding optimal relaxation feature subscription using sat solver decomposed three tasks: (a) encoding strict partial order, (b) encoding
objective function, (c) underlying search algorithm sat solver. Improving tasks improve whole approach solving problem.
paper focused task (a), mainly encoding precedence
constraints. remark (a), (b) (c) orthogonal tasks, techniques
tasks (b) (c) certainly used techniques task (a).
different encodings precedence constraints fairly compared (or
best suited) techniques tasks (b) (c) used. Codish et al. (2008, 2009) propose
several techniques (b) (c), e.g., encoding sum constraint use
dichotomic search optimisation aspect. may possible improve results
atom-based encoding using techniques.
11.4 Comparison CP, SAT MIP-based approaches
performances using constraint programming (cp), partial weighted maximum satisfiability (sat) mixed integer linear programming (mip) approaches presented
Tables 6, 7 8. mip model problem solved using ilog cplex12 (version
10.1). cp approaches results presented mrsacb global constraint
denoted sp. sat approaches use results obtained using clasp
minisat+. approaches solved instances within time limit. Since general finding optimal relaxation NP-hard, need investigate approach
reasonable time. best approach terms time represented bold letters
class feature subscription.
Table 6: Catalogue h50, 250, {, }i.
MIP
hfu , pu
h30, 20i
h35, 35i
h40, 40i
h45, 90i
h50, 4i

#nodes
208
905
2,616
9,818
1,754

time
0.4
2.0
9.1
77.4
6.1

CP
MRSACb
SP
#nodes
time
#nodes
time
161
0.5
115
0.2
932
5.6
744
2.8
6,105
45.9
2,707
12.3
104,789 1,256.1
103,065
971.3
26,494
218.1
9,133
36.5

SAT
CLASP
MINISAT+
#nodes
time #nodes
time
5,258
0.1
3,938
1.2
11,565
0.8
9,757
3.0
37,331
6.9
20,368
8.0
310,595
111.1
133,303
119.6
196,684
79.0
26,087
11.9

results presented Table 6 suggest mip approach performs better
cp sat approaches hardest feature subscription instances sparse catalogue
h50, 250, {, }i, particular h45, 90i h50, 4i classes feature subscriptions,
remaining classes feature subscription catalogue h50, 250, {, }i, sat approach based clasp solver winner. dense catalogue h50, 750, {, }i,
mip approach significantly slower approaches. Notice results mip approach improved significantly compared results
presented Lesaint et al. (2008c). usage real-valued variables
positions features. results presented Tables 7 8 catalogues
12. http://www.ilog.com/products/cplex/

299

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

Table 7: Catalogue h50, 500, {, , }i.
MIP
hfu , pu
h30, 20i
h35, 35i
h40, 40i
h45, 90i
h50, 4i

#nodes
48
112
160
573
258

CP
time
0.4
1.1
1.8
18.2
1.5

MRSACb
#nodes
time
66
0.2
158
1.0
229
1.8
687
9.6
768
6.2

SP
#nodes
time
53
0.1
111
0.4
188
1.0
620
6.1
954
3.6

SAT
CLASP
MINISAT+
#nodes
time #nodes
time
2,066
0.0
4,298
0.7
2,999
0.1
6,838
1.3
4,005
0.1
8,897
2.0
7,265
0.4
19,791
5.7
8,887
0.6
16,511
3.8

Table 8: Catalogue h50, 750, {, }i.
MIP
hfu , pu
h30, 20i
h35, 35i
h40, 40i
h45, 90i
h50, 4i

#nodes
3,761
13,485
28,461
43,958
163,686

time
9.3
67.9
229.0
539.1
1,644.4

CP
MRSACb
SP
#nodes
time #nodes
time
578
2.2
168
0.4
1,997
11.4
396
1.9
5,229
36.7
993
5.8
19,190
207.8
2,902
29.7
31,580
253.1
5,569
28.2

SAT
CLASP
MINISAT+
#nodes
time
#nodes
time
4,633
0.2
5,125
0.7
9,285
0.8
12,611
2.0
20,905
3.2
22,284
4.5
60,676 13.8
60,531
25.5
130,920
43.8
45,802 12.8

h50, 500, {, , }i h50, 750, {, }i, respectively, suggest sat approaches
perform significantly better mip cp approaches. particular, sat approach based clasp solver winner classes except h50, 4i class
feature subscription catalogue h50, 750, {, }i, outperformed cp
approach based global constraint sat approach based minisat+.
Even though mrsacb SoftPrec outperformed least one
approaches cases, never worst respect total time required
solving instances shown Figure 3. particular cp approach based
SoftPrec competitive cases catalog dense. Figure 3 also
shows pseudo-Boolean solvers clasp minisat+ perform better terms
total time compared approaches. noted clasp
minisat+ implemented C++ use restarts, mrsacb SoftPrec
implemented Java-based choco solver use restarts. clasp
minisat+ perform poorly compared respect number nodes visited
search. shows time spent clasp minisat+ node
considerably less time spent remaining approaches. course
opportunity improve per-node speed cp approaches implementing
C++ based solver. also remark clasp minisat+ consume
memory cp-based approaches mip approach. illustrate this, also
computed sum problem sizes instances approaches. Here,
problem size instance sum number variables, domain sizes
variables, arity constraints. Figure 4 depicts plot
total problem size approach. total problem size clasp minisat+
roughly two orders-of-magnitude approaches. We, therefore, conclude
clasp minisat+ offer scalability.
300

fiApproaches Solving Telecommunications Feature Subscription Problem

1e+07

search nodes (logscale)

CLASP

MINISAT+

MIP

MRSAC

SP
1e+06
0

5

10

15
time (seconds)

20

25

30

Figure 3: Total time nodes required solve instances different approaches.

units problem size -- see text (logscale)

1e+08

1e+07

1e+06

100000
MIP

MRSAC

SP
approach

CLASP

MINISAT+

Figure 4: Total problem size instances different approaches.

301

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

12. Conclusions Future Work

paper focussed task finding optimal relaxation feature subscription users preferences violate technical constraints defined set
distributed feature composition rules. reformulated problem finding optimal
relaxation, showed generalisation Feedback Vertex Set problem,
makes problem NP-hard. developed cpbased methods finding optimal relaxation feature subscription. particular presented three models: basic constraint
optimisation problem model, model based global constraint, weighted csp
model. basic cop model, studied effect maintaining arc consistency
two mixed consistencies branch bound search. experimental results suggest
maintaining (restricted) singleton arc consistency Boolean variables arc consistency integer variables outperforms mac significantly. former approach
outperformed empirically cp approach based SoftPrec global constraint.
also compared cpbased approaches sat-based approaches mixed
integer linear programming approach. partial weighted maximum satisfiability case
presented atom-based encoding investigated two symbol-based encodings.
set assignments restricted problem variables unit propagation atombased encoding strictly stronger unit propagation symbol-based binary
encoding, former equivalent unit propagation symbol-based unary
encoding. Empirically, atom-based encoding better symbol-based binary
encoding, incomparable symbol-based unary encoding. Overall,
results suggest catalogue sparse mip better terms runtime hard
instances. catalogue dense sat approach based clasp better terms
runtime. sat approach based minisat+ cp approach based global
constraint also competitive dense catalogues. Overall, pseudo-Boolean
solvers clasp minisat+ perform better terms total time compared
approaches.
approaches considered paper mostly one-stage approaches sense
exploration started without approximation optimum value.
future would like consider two-stage approach where, first stage, heuristic
used compute approximation optimal solution, second stage,
exploration carried taking approximate value initial lower bound.
cp approach based wcsp explored least. may possible improve
performance using different models overcome problem symmetric solutions
stronger consistency techniques similar singleton arc consistency case
basic cop model. current settings performance approaches terms
time includes time taken prove optimality solution. future, would
like compare presented approaches also local search methods terms
anytime profiles (i.e. solution qualities time). would interesting investigate
impact restarts approaches.
302

fiApproaches Solving Telecommunications Feature Subscription Problem

Acknowledgments
material based upon work supported Science Foundation Ireland Grant
No. 05/IN/I886, 08/PI/I1912, Embark Post Doctoral Fellowships No. CT1080049908
No. CT1080049909. authors would like thank Hadrien Cambazard, Daniel Le
Berre Alan Holland support using choco, sat4j cplex respectively.
authors would also like thank Simon de Givry help wcsp formulation
problem. Thanks also Michael Codish providing symbol-based encoding
instances Daniel Le Berre. thank reviewers providing valuable comments
helped us improve quality paper.

References
Apt, K. (2003). Principles Constraint Programming. Cambridge University Press.
Bessiere, C., & Debruyne, R. (2004). Optimal suboptimal singleton arc consistency
algorithms. Proceedings Nineteenth International Joint Conference Artificial Intelligence (IJCAI 2005), pp. 5459.
Bessiere, C., & Regin, J.-C. (1996). MAC combined heuristics: Two reasons forsake FC (and cbj?) hard problems. Proceedings Second International
Conference Principles Practice Constraint Programming (CP 1996), pp.
6175.
Bessiere, C., Stergiou, K., & Walsh, T. (2008). Domain filtering consistencies non-binary
constraints. Artificial Intelligence, 172 (6-7), 800822.
Biere, A., Heule, M. J. H., van Maaren, H., & Walsh, T. (Eds.). (2009). Handbook
Satisfiability, Vol. 185 Frontiers Artificial Intelligence Applications, chap. 19,
p. 980. IOS Press.
Bond, G. W., Cheung, E., Purdy, H., Zave, P., & Ramming, C. (2004). Open Architecture
Next-Generation Telecommunication Services. ACM Transactions Internet
Technology, 4 (1), 83123.
Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting systematic search
weighting constraints.. de Mantaras, R. L., & Saitta, L. (Eds.), Proceedings
16th European Conference Artificial Intelligence (ECAI 2004), pp. 146150. IOS
Press.
Calder, M., Kolberg, M., Magill, E. H., & Reiff-Marganiec, S. (2003). Feature Interaction:
Critical Review Considered Forecast. Computer Networks, 41 (1), 115141.
Codish, M., Lagoon, V., & Stuckey, P. J. (2008). Telecommunications feature subscription
partial order constraint problem. Proceedings 24th International Conference
Logic Programming (ICLP 2008), pp. 749753.
Codish, M., Genaim, S., & Stuckey, P. (2009). declarative encoding telecommunications
feature subscription SAT. Proceedings 11th ACM SIGPLAN conference
Principles practice declarative programming (PPDP 2009), pp. 255266, New
York, NY, USA. ACM.
303

fiLesaint, Mehta, OSullivan, Quesada, & Wilson

Codish, M., Lagoon, V., & Stuckey, P. (2008). Logic programming satisfiability. Theory
Practice Logic Programming, 8 (1), 121128.
Cormen, T., Leiserson, C., & Rivest, R. (1990). Introduction Algorithms. MIT Press.
de Givry, S., Larrosa, J., Meseguer, P., & Schiex, T. (2003). Solving max-sat weighted
csp.. pp. 363376.
Debruyne, R., & Bessiere, C. (1997). practical filtering techniques constraint
satifaction problem. Proceedings 15th International Joint Conference
Artificial Intelligence (IJCAI 1997), pp. 412417, Nagoya, Japan.
Een, N., & Sorensson, N. (2003). extensible SAT-solver. Proceedings Sixth
International Conference Theory Applications Satisfiability Testing (SAT
2003), pp. 502518.
Een, N., & Sorensson, N. (2006). Translating pseudo-boolean constraints SAT. Journal
Satisfiability, Boolean Modeling Computation (JSAT), 2 (1-4), 126.
Festa, P., Pardalos, P., & Resende, M. (1999). Feedback set problems. Tech. rep. 99.2.2,
AT&T Labs Research.
Fried, C., Hordijk, W., Prohaska, S., Stadler, C., & Stadler, P. (2004). footprint sorting
problem. Journal Chemical Information Modeling, 44 (2), 332338.
Garey, M., & Johnson, D. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman Company.
Gebser, M., Kaufmann, B., & Schaub, T. (2009). conflict-driven answer set solver
clasp: Progress report. Proceedings 10th International Conference Logic
Programming Nonmonotonic Reasoning (LPNMR 2009), pp. 509514, Berlin,
Heidelberg. Springer-Verlag.
Jackson, M., & Zave, P. (1998). Distributed Feature Composition: Virtual Architecture
Telecommunications Services. IEEE Transactions Software Engineering (TSE),
24 (10), 831847.
Jackson, M., & Zave, P. (2003). DFC Manual. AT&T.
Larrosa, J. (2002). Node arc consistency weighted CSP. Proceedings
Eighteenth National Conference Artificial Intelligence (AAAI 2002), pp. 4853,
Menlo Park, CA, USA. American Association Artificial Intelligence.
Lecoutre, C., & Patrick, P. (2006). Maintaining singleton arc consistency. Proceedings
3rd International Workshop Constraint Propagation Implementation
(CPAI2006), pp. 4761, Nantes, France.
Lecoutre, C. (2009). Constraint Networks: Techniques Algorithms. Wiley Blackwell.
Lecoutre, C., & Cardon, S. (2005). greedy approach establish singleton arc consistency. Proceedings Nineteenth International Joint Conference Artificial
Intelligence (IJCAI 2005), pp. 199204.
Lesaint, D., Mehta, D., OSullivan, B., Quesada, L., & Wilson, N. (2009). Soft Global
Precedence Constraint. Proceedings 21st International Joint Conference
Artificial Intelligence (IJCAI-09), Pasadena, CA, USA.
304

fiApproaches Solving Telecommunications Feature Subscription Problem

Lesaint, D., Mehta, D., OSullivan, B., Quesada, L., & Wilson, N. (2008a). Consistency
techniques finding optimal relaxation feature subscription. Proceeding
20th IEEE International Conference Tools Artificial Intelligence(ICTAI
2008), pp. 283290.
Lesaint, D., Mehta, D., OSullivan, B., Quesada, L., & Wilson, N. (2008b). Personalisation
Telecommunications Services Combinatorial Optimisation. Proceedings
Twentieth Conference Innovative Applications Artificial Intelligence (IAAI
2008), pp. 16931698, Chicago, USA. AAAI Press.
Lesaint, D., Mehta, D., OSullivan, B., Quesada, L., & Wilson, N. (2008c). Solving
Telecommunications Feature Subscription Configuration Problem. Proceedings
14th International Conference Principles Practice Constraint Programming (CP 2008), pp. 6781.
Poikselka, M., Mayer, G., Khartabil, H., & Niemi, A. (2006). IMS: IP Multimedia
Concepts Services (2nd edition). John Wiley Sons.
Prosser, P., Stergiou, K., & Walsh, T. (2000). Singleton Consistencies. Dechter, R.
(Ed.), Proceedings 6th International Conference Principles Practice
Constraint Programming(CP 2000), pp. 353368.
Pruesse, G., & Ruskey, F. (1994). Generating linear extensions fast. SIAM Journal
Computing, 23 (2), 373386.
Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston, A., Peterson, J., Sparks, R., Handley, M., & Schooler, E. (2002). SIP: Session initiation protocol RFC 3261 (proposed
standard updated RFCs 3265, 3853, 4320)..
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006a). Handbook Constraint Programming,
chap. 3. Elsevier Science Inc.
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006b). Handbook Constraint Programming,
chap. 9. Elsevier Science Inc.
Sparks, R. (2007). SIP: Basics Beyond. ACM Queue, 5 (2), 2233.
Tseitin, G. S. (1968). complexity derivations propositional calculus. Studies
Mathematics Mathematical Logic, Part II, 115125.
Wallace, M. (1996). Practical applications constraint programming. Constraints Journal,
1 (1), 139168.
Zave, P. (2003). Experiment Feature Engineering. McIver, A., & Morgan, C.
(Eds.), Programming Methodology, pp. 353377. Springer-Verlag.
Zhang, Y., & Yap, R. (2000). Arc consistency n-ary monotonic linear constraints.
Proceedings 6th International Conference Principles Practice Constraint Programming (CP 2002), pp. 470483, Sigapore. Springer-Verlag.

305

fiJournal Artificial Intelligence Research 38 (2010) 513-534

Submitted 04/10; published 08/10

Algorithms Closed
Rational Behavior (CURB) Sets
Michael Benisch
George B. Davis
Tuomas Sandholm

mbenisch@cs.cmu.edu
gbd@cs.cmu.edu
sandholm@cs.cmu.edu

School Computer Science
Carnegie Mellon University
5000 Forbes Ave
Pittsburgh, PA 15213 USA

Abstract
provide series algorithms demonstrating solutions according fundamental game-theoretic solution concept closed rational behavior (CURB) sets
two-player, normal-form games computed polynomial time (we also discuss extensions n-player games). First, describe algorithm identifies players best
responses conditioned belief player play within given subset
strategy space. algorithm serves subroutine series polynomial-time
algorithms finding minimal CURB sets, one minimal CURB set, smallest
minimal CURB set game. show complexity finding Nash equilibrium exponential size games smallest CURB set. Related this,
show smallest CURB set arbitrarily small portion game,
also arbitrarily larger supports enclosed Nash equilibrium.
test algorithms empirically find commonly studied academic games
tend either large small minimal CURB sets.

1. Introduction
noncooperative multi-agent settings, game-theoretic solution concepts help players choose
strategies, help modelers predict outcomes, help mechanism designers guarantee properties systems create. Significant attention given algorithms computing solutions according concepts subgame perfect Nash equilibrium (e.g., minimax
search --pruning), Nash equilibrium (Lemke & Howson, 1964; Porter, Nudelman,
& Shoham, 2004; Sandholm, Gilpin, & Conitzer, 2005), correlated equilibrium (Gilboa &
Zemel, 1989), iterative dominance (Knuth, Papadimitriou, & Tsitsiklis, 1988; Conitzer &
Sandholm, 2005a), related concepts (Conitzer & Sandholm, 2005b).
Nash equilibrium concept, player weakly prefers strategy
long players deviate theirs, remains important pointvalued game-theoretic solution concept. However, shown that, even twoplayer games binary utilities, computing single Nash equilibrium PPAD-complete
(Chen & Deng, 2006; Abbott, Kane, & Valiant, 2005), suggesting algorithms exist
computing equilibria worst-case polynomial time (Daskalakis, Goldberg, &
Papadimitriou, 2009).
c
2010
AI Access Foundation. rights reserved.

fiBenisch, Davis, & Sandholm

fundamental solution concepts known advantages
Nash equilibria, andas showsolutions according concepts
found polynomial time, even worst case. Specifically, study fundamental
concept closed rational behavior (CURB) strategy sets two-player, normal-form
games. game multiple Nash equilibria, point, single
(potentially mixed) strategy player. contrast, CURB set contain multiple
strategies player, stable long players choose (potentially mixed)
strategies within set.
CURB sets based notion rationalizability, introduced Pearce
(1984) Bernheim (1984). Rationalizability is, now, widely known, robust gametheoretic solution concept used study various applications, first-price
auctions (Battigalli & Siniscalchi, 2003). main insight rationality restricts players
ever playing strategies best responses given beliefs hold
opponents. Strategies best responses set consistent beliefs
opposing strategies said rationalizable. two-player games, process
iteratively eliminating strategies dominated, strategies best
responses opponent strategy, captures concept rationalizability. emulates
players assumptions opponent never play strategy best
response one players remaining strategies (Pearce, 1984).
set players rationalizable strategies property players best
response pure mixed strategy inside set lies outside set words,
set CURB. However, CURB set may also CURB subsets, demonstrates
CURB sets extend notion rationalizability. Basu Weibull (1991) introduced
notion minimal CURB set, CURB set contain CURB subsets,
proved minimal CURB set guaranteed contain supports least
one Nash equilibrium.
minimal CURB set solution concept since motivated several perspectives academic literature, including following:
Mixed-strategy Nash equilibria (the type guaranteed exist every game)
highly unstable, player may indifferent strategies.
Strict Nash equilibria, players strictly prefer strategies equilibrium,
stable alternative, guaranteed exist. Minimal CURB sets
always exist referred nearest set-valued generalization
strict Nash equilibria, since smallest sets strategies include
ways choosing among indifferences equilibrium (Basu & Weibull, 1991).
CURB set viewed subspace strategies within best-response
dynamic (even best-response dynamic mixed strategies) stay. Thus, CURB
sets used solution concept describe strategy subspace
iteratively adapting agents eventually settle (Hurkens, 1995).
Voorneveld et.al. enumerated number properties minimal CURB sets
illustrate stability set-based solution concepts point-valued concepts,
Nash equilibria (Voorneveld, Kets, & Norde, 2005).
514

fiAlgorithms Closed Rational Behavior (CURB) Sets

order solution concept operational, must also accompanied algorithms applying it. Finding minimal CURB sets previously considered
challenging (Pruzhansky, 2003), and, prior work CURB sets, little done
problem computational standpoint. knowledge, work
predate Pruzhansky, studied sequential games perfect information.
games relatively simple, contain exactly one minimal CURB set,
straightforward algorithm quickly find exploiting sequential representation
(Pruzhansky, 2003). paper, present first thorough computational treatment
CURB sets general two-player games. show that, settings, minimal CURB
sets actually easy find: time complexity polynomial size game,
even worst case.
primary source complexity algorithms linear programming-based
subroutine finding players best responses (i.e., utility-maximizing pure strategies)
conditioned belief player play within given subset
strategy space. problem solved fast two players, case involves
solving simple linear feasibility program, mathematical program use
degree p 1, p number players, p = 3 constraints already
quadratic. plus side, CURB set algorithms make polynomial number
calls subroutine. future research able identify polynomial-time algorithms
finding players best responses n-player games, CURB set algorithms
also polynomial time settings. Additionally, algorithms useful
templates development algorithms compute related solution concepts
n-player games (Brandt, Brill, Fischer, & Harrenstein, 2009; Jordan & Wellman, 2010).
rest paper organized follows. begin preliminaries
notations definitions. Next, present analyze algorithm finding
conditional best responses, serves main subroutine CURB set finding
algorithms. present analyze family polynomial-time algorithms twoplayer, normal-form games compute games minimal CURB sets, single one
minimal CURB sets, smallest minimal CURB set. Finally, discuss additional
applications results, including potential CURB set algorithms bound
theoretical complexity finding Nash equilibria.

2. Preliminaries
describe analyze algorithms classic game-theoretic setting two-player,
normal-form game represented matrix rows corresponding pure strategies
(or actions) one player, player r, columns corresponding pure strategies
other, player c. (For shorthand, often omit term pure refer pure
strategy simply strategy.) typical game theory, players assumed
fully-rational, utility-maximizing agents.
row game matrix corresponds strategy, sr , set player rs
strategies, Sr . Likewise, column corresponds strategy, sc , set
player cs strategies, Sc . cell corresponding strategies sr sc contains two entries,
one indicating real-valued utility row player sr sc played, ur (sr , sc ),
indicating column player two strategies played,
515

fiBenisch, Davis, & Sandholm

uc (sr , sc ). Using entities, also refer game, G, tuple, G = hSr , Sc , ur , uc i.
size game, refer n, total number strategies contains,
n = |Sr | + |Sc |.
mixed strategy, mixture, probability distribution pure strategies,
function,
Pi , maps player pure strategies probability, mi : Si
[0, 1] sSi mi (s) = 1. supports mixture pure strategies
mixture non-zero probability. set possible mixtures supports
set strategies, Si , denoted (Si ), thought simplex degree
|Si | 1. pure strategy represented point-mass mixture, mixture
probability mass one strategy.
strategy profile set pure mixed strategies, one player.
mixed-strategy profile played, players utility assumed expected utility, given summing players utility possible pure-strategy profile
weighted

Pprofiles joint probability according mixtures, e.g., ur (mr , mc ) =
P

(s
)
r
r
sc Sc mc (sc )ur (sr , sc ). occasionally use notation refer
sr Sr
player players player i. used subscript strategy-related
entity two players, intend refer one instance entity
per player (e.g., mi mixed-strategy profile containing one mixture per player
i).
Player best responses mixed strategy player(s), mi , given
function (mi ). pure strategies maximize player utility
player(s) play mi .
set players pure strategies, Si , define (Si ) function

returns player best responses every mixture supports Si , (Si ) =
mM (Si ) (m). Section 3, describe algorithm computing pure strategies
(Si ) serves subroutine CURB set algorithms, refer
strategies computes conditionally rational. define (S) (without subscript i)
union sets (Si ) players.
CURB set, S, formally defined set pure strategies (with least one strategy
player) contains best responses mixture itself: CURB
players believe strategy outside played positive probability
opponents, strategies indeed played rational players. Using
notation above, set, S, CURB (S) S. (The entire game trivially CURB
definition.) refer number strategies CURB set size.
intersection two CURB sets, S1 S2 , set strategies attained taking
intersection strategy sets, SI = S1 S2 . Two CURB sets overlap share
strategy (i.e., intersection non-empty).
Nash equilibrium pure- mixed-strategy profile, {mr , mc }, players
strategy least good best response others, ur (mr , mc ) = ur (sr , mc )
uc (mr , mc ) = uc (mr , sc ), sr r (mc ) sc c (mr ). strict Nash equilibrium
pure-strategy profile, {sr , sc }, players strategy best response
others, r (sc ) = {sr } c (sr ) = {sc }. CURB set contains one strategy per
player also pure-strategy Nash equilibrium.
516

fiAlgorithms Closed Rational Behavior (CURB) Sets

3. Finding Conditional Best Responses
Finding players best responses conditioned belief player
play within subset total strategy space, problem interest
right, plays central role computation CURB sets. section describes
polynomial-time algorithm, conditionally rational, that. algorithm row player; column players variant symmetric. inputs
algorithm set row-player strategies consider, Sr , set column-player
strategies may played against, Sc , row players utility function, ur .
function conditionally rational(Sr , Sc , ur )
Sr
row strategy, sr Sr
exists feasible solution following linear feasibility program:
find psc
X

p sc

= 1

(1)

sc Sc

X

X



psc ur (sr , sc )

sc Sc

psc ur (s0r , sc )

s0r Sr \ sr

(2)

sc Sc

p sc



0 sc Sc

(3)

Sr Sr sr
return Sr
row strategy, sr Sr , linear feasibility program (LFP) (i.e., linear program
objective) constructed find mixture probabilities column-player
strategies, psc , sr row players best response. constraints LFP
ensure mixture valid (sums one), row players utility playing
sr psc greater equal strategy. LFP feasible
solution, sr added set best responses returned.
computational complexity algorithms described paper depend
total number strategies game, n, complexity solving LFP
number variables constraints bounded n, denote LFP(n).
LFPs solved low-order polynomial time, even worst case, fastest
known algorithms LFPs better worst-case guarantees fastest known linear
programming algorithms (Ye, 2006). experiments, solve LFP using simplex
algorithm, exponential worst-case time complexity, known outperform
polynomial-time linear programming algorithms practice.
Proposition 1. conditionally rational algorithm returns players best responses every mixture input strategy set, nothing else. worst-case time
complexity (n) LFP(n).
517

fiBenisch, Davis, & Sandholm

Proof. Since conditionally rational runs program strategies includes
return set LFP feasible, must correct. Since LFP
executed strategy, size bounded n, conditionally rational
complexity shown.

4. Finding CURB Sets
turn attention problem finding CURB sets. algorithm
finds smallest CURB set contains given seed strategy within given subgame.
(The returned set necessarily minimally CURB.) algorithm repeatedly alternates
players, time calling conditionally rational add strategies necessary maintaining CURB property. iteration passes without strategies
added, algorithm converged.
function min containing CURB(sr , G = hSr , Sc , ur , uc i)
Sr {sr }, Sc
converged false
converged
converged true
{r, c}
,u )
Si0 conditionally rational(Si , Si


0
Si \ Si 6=
converged false

Si Si Si0
return Sr Sc
worth noting second-to-last line algorithm (Si Si Si0 )
necessary merge old strategies, Si , newly identified strategies, Si0 ,
Si0 always superset Si . If, instead, Si replaced Si0 , would
possible seed strategy eliminated algorithms first iteration.
example, consider following game.

sr1
sr2

sc1
1,1
0,1

sc2
0,0
1,0

strategy sr2 used seed, first iteration Sr initialized {sr2 }, Sc
set {sc1 }, finally Sr set {sr1 }. Thus, without merge algorithm
would output subgame contain seed strategy.
Proposition 2. min containing CURB algorithm worst-case runtime (n2 )
LFP(n).
Proof. Every two calls made conditionally rational must add strategy
return set, min containing CURB terminate. Since n strategies added
way, complexity min containing CURB (n2 ) LFP(n).
518

fiAlgorithms Closed Rational Behavior (CURB) Sets

Theorem 1. min containing CURB algorithm correct, is, returned set, ,
smallest set strategies 1) contains given seed strategy, sr , 2)
CURB.
Proof. convergence algorithm implies strategies outside best
responses mixture supports . Therefore, (S ) , CURB.
prove smallest CURB set containing sr , use induction
strategies added.
Base Case: Initially, contains sr c (sr ). point, subset
smallest CURB set containing sr .
Inductive Step: time new strategy, , added , necessarily best
response mixture, (S ), strategies already contained . Since
strategies never removed execution, remain valid mixture.
Therefore, strategy added necessary maintain CURB property.
present three algorithms use min containing CURB determine
games minimal CURB sets. facilitate discussion algorithms, first present
three results regarding CURB set structure, which, best knowledge,
previously known.
Theorem 2. two intersecting strategy sets CURB, intersection
also CURB.
Proof. Consider two CURB sets, SA SB , nonempty intersection, SI .
mixture strategies SI belonging (without loss generality) row player,
exists set pure strategies column players best responses, Sc . SA
CURB, also contains strategies Sc (i.e., Sc SA ); likewise Sc SB .
Therefore, Sc within intersection, SI .
Since intersection two CURB sets must CURB contained sets,
also following two corollaries.
Corollary 1. Distinct minimal CURB sets cannot overlap (i.e., share rows columns).
Corollary 2. strategy belongs one minimal CURB set.
4.1 Finding Minimal CURB Sets
broadest query one make regarding minimal CURB set structure game
asking minimal CURB sets. useful, example, adaptive
agent context identify regions strategy space learning agents likely
settle (Hurkens, 1995).
MC algorithm first checking pair strategies size-two
CURB sets (i.e., pure-strategy Nash equilibria) adding return set minimal
CURB sets. Since operation (n2 ), done preprocessing step
without affecting algorithms worst-case time complexity, strategies finds
eliminated future consideration. MC algorithm determines
minimal CURB sets remaining subgame calling min containing CURB
row strategy, turn, seed.
519

fiBenisch, Davis, & Sandholm

first, call min containing CURB using entire remaining subgame input.
However, accelerate subsequent calls min containing CURB maintaining map
strategy smallest CURB set discovered far.
(The entries added map also stored candidate minimal CURB sets.)
new strategy used seed, use smallest known CURB set containing strategy
second input min containing CURB. Whenever smaller CURB set containing
new seed identified, eliminate candidate minimal CURB sets contain
newly found one. strategy used seed, MC terminates
returns remaining candidate minimal CURB sets.
Proposition 3. MC algorithm finds games minimal CURB sets,
nothing else. worst-case runtime (n3 ) LFP(n). best-case runtime (n2 ).
Proof. Corollary 1, minimal CURB set strategy must either equal,
contained by, CURB set strategy found. Therefore, restricting
min containing CURB search smallest CURB set strategy
found far valid, main loop MC discover minimal CURB sets
game. Since CURB set minimal must contained one minimal
CURB sets discovered, removed smaller CURB set discovered (or added
smaller set previously discovered).
worst case, MC must call min containing CURB n times, full game
parameter, giving time complexity (n3 ) LFP(n). best-case complexity follows
best-case game strategy part pure-strategy Nash equilibrium.
4.2 Finding One Minimal CURB Set
Rather finding minimal CURB sets game, may desirable find single
minimal CURB set. complete quickly, first choose random seed strategy
check part size-two CURB sets (i.e., part pure-strategy Nash equilibrium),
takes O(n) time. fails, use min containing CURB algorithm
randomly-chosen strategy seed full game second input. Since
resulting CURB set might minimal, recur within choosing, seed,
contained strategy yet used. repeat strategies
current set used seeds, point terminate return remaining
set. constitutes one MC algorithm.
game one CURB set, one MC faster MC
never leave CURB set starts. exact speed one MC practice
depend first seed chosen. happens small CURB set, one MC
run fast. worst case, entire game CURB set, one MC executes
steps MC.
Proposition 4. one MC algorithm returns one games minimal CURB sets.
worst-case time complexity (n3 ) LFP(n). best-case time complexity (n).
Proof. minimal CURB sets, entire game minimally CURB
returned. minimal CURB sets, one
discovered strategy inside used seed.
520

fiAlgorithms Closed Rational Behavior (CURB) Sets

worst case, whole game minimally CURB, one MC must call
min containing CURB algorithm n times, full game input, giving time complexity (n3 ) LFP(n). best-case complexity follows best-case game
strategy CURB set size two chosen seed.
4.3 Finding Smallest Minimal CURB Set
different type query, one may interested finding one games smallest
minimal CURB sets. important, example, CURB set used future
computations complexity future computations increases size
CURB set (e.g., Nash equilibrium finding discuss later paper).
find one games smallest minimal CURB sets using pseudo-parallelization MC.
First, use preprocessor MC checks pair strategies
size-two CURB set returns one, found. fails, construct candidate set
row strategy containing strategy. insert sets priority queue,
sets containing fewest strategies given highest priority. repeatedly pop
smallest candidate set queue, add necessary best responses keep
CURB calling conditionally rational player. new strategies
added either player, resulting set inserted back queue, prioritized
based new size. algorithm terminates candidate set removed
queue fails admit new best responses. set returned one
games smallest minimal CURB sets (we denote size set n ). call
algorithm small MC.
Proposition 5. small MC algorithm returns one games smallest minimal CURB
sets. worst-case runtime (n n2 ) LFP(n). best-case runtime (n2 ).
Proof. time small MC terminates, conditionally rational called
row column strategy set new best responses added.
Therefore, returned set CURB. Since candidate sets queue must
large, larger returned set (and future exploration add strategies
sets), set least small smallest CURB set game,
games smallest CURB sets also minimal.
Whenever candidate set fathomed, least one new strategy must added
small MC terminate. Since n candidate sets, n strategies returned
set, worst case n n sets fathomed termination. Since examination candidate set involves call conditionally rational, complexity
small MC claimed. Priority queue operations logarithmic size
game, worst case n n operations. Thus, overall worst-case
complexity (n n2 + n n log n) LFP(n), (n n2 ) LFP(n). proof
best-case complexity Proposition 3.
4.4 Experimental Results
implemented algorithms conducted experiments performance using instance generators main benchmark collection solving normal-form
games, GAMUT (Nudelman, Wortman, Shoham, & Leyton-Brown, 2004). GAMUT
521

fiBenisch, Davis, & Sandholm

collection includes variety commonly studied game types academic game
theory literature. also specifically designed test different aspects scalability
game-solving algorithms, example, generators allow one create multiple
game instances given size.1 section show complexity algorithms depends primarily size game size smallest CURB set.
proceed explore distribution CURB set sizes different game types.
first report runtime algorithms two representative GAMUT game
distributions: random games, covariant games. Figure 1 (left) shows
minimal CURB set finding algorithms scales game size data set 1000
random, square normal-form games 20 100 strategies. results show
small MC faster MC random games, consistent time
complexities, considering many random games small CURB sets.
worst-case time complexity one MC MC same, experimentally one MC
faster needs find one minimal CURB set. also see that, large
random games, small MC performs slightly better one MC, since games tend
contain small large CURB sets one MC likely start larger
ones. hand, games large CURB sets, one MC tends faster,
show later.
observed performance random games, illustrated Figure 1 (left),
typical many GAMUT instance distributions. However, show potentially
differing performance, also report experiments covariant game class,
utilities players drawn distribution specified covariance.
(In experiments set covariance parameter 0.5.) class (and setting)
shown particularly challenging Nash equilibrium finding algorithms,
Lemke-Howson Porter-Nudelman-Shoham algorithms (Lemke & Howson,
1964; Porter et al., 2004). Figure 1 (right) shows MC algorithm scales similarly
random covariant games, two algorithms lose speed advantages
applied class.
distribution CURB sets random games shown solid dots Figure 2.
random games small smallest CURB sets (in fact, often sets size two),
not, tend large smallest CURB sets. hand, distribution
smallest CURB set sizes covariant games (shown Figure 2, hollow squares) almost
small smallest CURB sets many large smallest CURB sets. consistent
observed hardness games support enumeration-based Nash equilibrium
finding algorithms, typically try find equilibria small supports first (Porter
et al., 2004). disparity also explains lowered performance covariant games
two minimal CURB finding algorithms time complexities dependent
size smallest minimal CURB set, small MC one MC.
Figure 3 shows distribution smallest CURB set size 1000 instances
twenty-four distributions emitted GAMUT generators. Using variety
game generators, done here, become primary way testing game-solving
algorithms (Porter et al., 2004; Sandholm et al., 2005), used parameter
settings distributions prior papers. covariant games, suffixes Pos,
1. benchmark GAMUT games fixed size, Chicken, Prisoners
Dilemma, Battle Sexes, trivial solve computational perspective.

522

fiAlgorithms Closed Rational Behavior (CURB) Sets

Random games
500

all_MC
one_MC
small_MC

400
300

Runtime (sec)

Runtime (sec)

500

Covariant games

200
100
0

all_MC
one_MC
small_MC

400
300
200
100
0

20 30 40 50 60 70 80 90 100
Game size (n)

20 30 40 50 60 70 80 90 100
Game size (n)

Figure 1: Scalability algorithms game size random (left) covariant (right)
games.

Small games (n = 20)
100

Covariant
Random

80

% games

% games

100

Large games (n = 40)

60
40
20
0

80

Covariant
Random

60
40
20
0

0

5

10

15

20

0 5 10 15 20 25 30 35 40

Smallest CURB set size

Smallest CURB set size

Figure 2: Distribution smallest CURB set size random covariant (r = 0.5) games,
n = 20 n = 40 (3,000 games generated distribution
value n).

Rand, Zero refer positive, random, zero covariance parameters, respectively.
distributions take graph input, CG, RG, SG refer complete,
random, star graphs.
distributions, like random covariant games, exhibited mediumsized smallest CURB sets. instances smallest CURB set extreme:
either pure strategy equilibrium entire game. generators,
instances lie extreme. Interestingly, generators (e.g., Polymatrix)
produced significant number games CURB sets one specific, nonextremal sizes. also notable using different graph parameters Local Effect
Polymatrix games effect smallest CURB set size distributions, suggesting
523

fiBenisch, Davis, & Sandholm

BidirectionalLEG-CG

20

0

0

5

10

15

20

% games

% games

% games
0

0

10

15

0

0

0

5

10

15

20

PolymatrixGame-CG
100
80
60
40
20
0
0

5
10
15
20
Smallest CURB set size

TravelersDilemma
100
80
60
40
20
0

5
10
15
20
Smallest CURB set size

5
10
15
20
Smallest CURB set size

20

Smallest CURB set size

0

UniformLEG-SG

5
10
15
20
Smallest CURB set size

15

CovariantGame-Zero

5
10
15
20
Smallest CURB set size

100
80
60
40
20
0

10

100
80
60
40
20
0

PolymatrixGame-SW

5
10
15
20
Smallest CURB set size

5

Smallest CURB set size

20

100
80
60
40
20
0

UniformLEG-RG

0

5

100
80
60
40
20
0

5
10
15
20
Smallest CURB set size

100
80
60
40
20
0

0

MinimumEffortGame
% games

0

20

Smallest CURB set size

% games

% games

20

100
80
60
40
20
0

15

100
80
60
40
20
0

PolymatrixGame-Road

% games
5
10
15
20
Smallest CURB set size

15

10

CovariantGame-Rand

% games

% games

% games

0

UniformLEG-CG

0

10

5

100
80
60
40
20
0

Smallest CURB set size

LocationGame

5
10
15
20
Smallest CURB set size

100
80
60
40
20
0

5

100
80
60
40
20
0

PolymatrixGame-RG

0

0

Smallest CURB set size

5
10
15
20
Smallest CURB set size

100
80
60
40
20
0

20

% games
0

DispersionGame

0

15

100
80
60
40
20
0

Smallest CURB set size

100
80
60
40
20
0

10

CovariantGame-Pos
% games

% games

BinaryRandomGame
100
80
60
40
20
0

5

Smallest CURB set size

% games

15

% games

10

Smallest CURB set size

BidirectionalLEG-SG

% games

5

BidirectionalLEG-RG
100
80
60
40
20
0

5
10
15
20
Smallest CURB set size

WarOfAttrition
% games

0

100
80
60
40
20
0

% games

% games

% games

BertrandOligopoly
100
80
60
40
20
0

100
80
60
40
20
0
0

5
10
15
20
Smallest CURB set size

Figure 3: Distribution smallest CURB set size sets 1000 games n = 20
various GAMUT distributions.

type graph used may change fundamental structure types
games.
better understand minimal CURB set finding algorithms scale size
smallest CURB set, bucketed n = 20 random covariant games according
size smallest CURB sets. (For n = 40, buckets medium-sized smallest
CURB sets nearly empty, making impossible us estimate mean runtimes
meaningful accuracy.) Figure 4 plots average runtime 95% confidence intervals
bucket. games small CURB sets, small MC fastest,
outperformed one MC MC size smallest CURB set grows.
524

fiAlgorithms Closed Rational Behavior (CURB) Sets

somewhat surprising runtime performance latter two algorithms due
leveraging information across calls min containing CURB different seeds.
small MC performs searches parallel, information unavailable.
Random games
2

all_MC
one_MC
small_MC

1.5

Runtime (sec)

Runtime (sec)

2

Covariant games

1
0.5
0

all_MC
one_MC
small_MC

1.5
1
0.5
0

0

5
10
15
20
Smallest CURB set size

0

5
10
15
20
Smallest CURB set size

Figure 4: Average runtime games n = 20, varying smallest CURB set sizes.

5. CURB Sets Nash Equilibria
Minimal CURB sets Nash equilibria model strategy subspaces mutually
reinforced given rationality agents common knowledge. original
work minimal CURB sets, Basu Weibull showed every minimal CURB set
contains supports least one Nash equilibrium (Basu & Weibull, 1991). observe
result suggests secondary use finding minimal CURB sets: algorithms
used preprocess game Nash equilibrium finding algorithm restrict
attention one games minimal CURB sets, rather running entire
game. show, theoretically yield arbitrarily large reduction
search space.
common prior preprocessing technique Nash equilibrium finding, iterated
removal dominated strategies, attempts eliminate strategies cannot played
probability Nash equilibrium (Knuth et al., 1988; Gilboa, Kalai, & Zemel, 1993).
true another recent preprocessing technique, generalized eliminability
method (Conitzer & Sandholm, 2005b). One comparative advantage minimal CURB
set-based elimination eliminate strategies played equilibria,
guaranteeing resulting set still contains supports least one.
First, show CURB set-based preprocessor reduce search space size
arbitrary amount even games prior preprocessing techniques cannot eliminate
anything.
Theorem 3. r,c,r0 , c0 r 2, c 2, 1 < r0 r, 1 < c0 c,
exists normal form games size r c, following properties:
a) contains minimal CURB set shape r0 c0 ,
525

fiBenisch, Davis, & Sandholm

b) iterated elimination dominated strategies (even domination mixed strategies)
cannot eliminate strategies,
c) recursive preprocessing technique (that eliminate strategies belong
equilibrium long equilibrium remains) (Conitzer & Sandholm, 2006)
eliminate one strategy per player,
d) general eliminability method (Conitzer & Sandholm, 2005b) cannot eliminate
strategies.
Proof. first present family games, . Let r0 c0 denote game family
size r0 c0 . following generator produces game r0 , c0 2. Assign
utilities,
u(sr1 , sc1 ) = u(sr2 , sc2 ) = (0, 1) u(sr1 , sc2 ) = u(sr2 , sc1 ) = (1, 0).
0

Then, [2, b r2 c], set
0

, 1) u(sr2i1 , sc2 ) = ( 2i2
u(sr2i1 , sc1 ) = ( r 2i+2
r0
r 0 , 0),
0

u(sr2i , sc1 ) = ( r (2i1)
, 0) u(sr2i , sc2 ) = ( 2i1
r0
r 0 , 1).
r0 odd one remaining row. case, set following utilities,
0

1
r0 odd, u(sr0 , sc1 ) = ( r10 , 12 ) u(sr0 , sc2 ) = ( r r1
0 , 2 ).
0

Next, j [2, b c2 c], set
0

u(sr1 , sc2j1 ) = (0, c 2j+2
) u(sr2 , sc2j1 ) = (1, 2j2
c0
c0 ),
0

u(sr1 , sc2j ) = (1, c (2j1)
) u(sr2 , sc2j ) = (0, 2j1
c0
c0 ).
c0 odd one remaining column. case, set following utilities,
0

c0 odd, u(sr1 , sc0 ) = ( 12 , c10 ) u(sr2 , sc0 ) = ( 21 , c c1
0 ).
example, game 3,4 follows.
3,4
sr1
sr2
sr3

sc1
0,1
1,0
1 1
3, 2

sc2
1,0
0,1
2 1
3,2

sc3
0, 12
1, 12
-3,-3

sc4
1, 14
0, 34
-3,-4

game generated way Nash equilibrium row player mixes
evenly first two strategies, column player mixes evenly among
strategies. game also equilibrium column player mixes evenly
first two strategies, row player mixes evenly among strategies. Thus,
every strategy r0 c0 part equilibrium. Additionally, column strategy
526

fiAlgorithms Closed Rational Behavior (CURB) Sets

best response mixture first two row strategies (and, column strategy,
one two best response), vice-versa. Thus, r0 c0 single minimal CURB
set includes entire game.
construct r c game, minimally CURB r0 c0 subset, putting
game r0 c0 top left game (rr0 )(cc0 ) bottom right. utilities
set arbitrary negative values, two exactly same. resulting
game shown Figure 5.

Figure 5: r c game arbitrary reduction r0 c0 CURB set, irreducible prior
techniques.
irreducible (iterated) dominance general eliminability every
strategy participates Nash equilibrium. game irreducible (other
single strategy per player) recursive preprocessor row players utilities
distinct within column, column players utilities distinct within
row (except last row column game, odd number rows
columns).
Three factors curb promise minimal CURB set algorithms powerful preprocessors Nash equilibrium finding. First, fastest Nash equilibrium finding algorithms,
requiring exponential time worst case, tend run faster CURB set
finding algorithms many types games (at least best known implementations
algorithms). Second, smallest CURB set arbitrarily large (up size
entire game, case preprocessor eliminate strategies
consideration). Third, show, even smallest minimal CURB set
identified, remaining search space (CURB set size) arbitrarily larger
size supports contained Nash equilibrium.
prove this, use following family games contain large minimal
CURB sets small-support equilibria. integer k > 0, define game k
follows. previous proof, assign utilities u(sr1 , sc1 ) = u(sr2 , sc2 ) = (0, 1)
u(sr1 , sc2 ) = u(sr2 , sc1 ) = (1, 0), let Z arbitrarily large value (essentially ).
Then, [3, 2 + k],
u(sri , sc1 ) = (Z, ), u(sr1 , sci ) = (, Z),
u(sri , sci ) = (0, 0),
u(sri , sci1 ) = (1 + , 0), u(sri1 , sci ) = (0, 1 + ),
527

fiBenisch, Davis, & Sandholm

j > + 1 j 2 + n,
u(sri , scj ) = (0, Z), u(srj , sci ) = (Z, 0)
example, game 2 follows.
2
sr1
sr2
sr3
sr4

sc1
0,1
1,0
Z,
Z,

sc2
1,0
0,1
1+,0
Z, 0

sc3
,Z
0,1+
0,0
1+,0

sc4
,Z
0,Z
0,1 +
0,0

respect strategic structure games class, following
results.
Lemma 1. > 2, row (column) players strategy sri (sci ) best response
column (row) players strategy sci1 (sri1 ). column (row) players strategy sc1 (sr1 )
best response row (column) players strategy srn+2 (scn+2 ).
Proposition 6. k single minimal CURB set includes entire game.
Proof. Strategies sr1 , sr2 , sc1 , sc2 must included minimal CURB set,
best responses subgame containing them, subgame
admits pure-strategy Nash equilibrium. Based Lemma 1, see = 3,
row (column) players strategy sr3 (sc3 ) best response column (row) players
second strategy. forces third strategy player minimal CURB set
containing first two strategies player, inductively additional strategy
added way.
Proposition 7. k , Nash equilibrium mixed-strategy profile
sr1 , sr2 , sc1 , sc2 played probability 21 .
Proof. Assume, contradiction, case, is, exists mixture,
mr , rows Mr , comprising row players profile Nash equilibrium,
sr1
/ Mr . Along assumption, definition Nash equilibrium implies
must exist mixture, mc , columns Mc r (mc ) = Mr c (mr ) = Mc .
Since sr1 Mr assumption, exists > 1 sri lowest numbered
support Mr , definition specifies outcome, u(sri , scj ) = (0, Z),
j > + 1.
column players Nash equilibrium supports cannot contain scj ,
placing positive probability strategy lead highly negative expected
payoff playing pure strategy sc1 provides guaranteed payout least 0.
exclude strategies, sci+1 (the highest-numbered remaining column strategy)
remaining strategy, sc1 , provides non-zero utility mixtures rows
i. words, dominates column strategies row players supports Mr ,
aside one: sc1 .
528

fiAlgorithms Closed Rational Behavior (CURB) Sets

Since dominated strategies cannot played equilibrium, Mc constrained
subset {sc1 , sci+1 }. Mc contains sc1 , Mr must include srj j > 2, due
highly negative expected payoff mixture including strategies (as discussed
above). case, remaining possible equilibrium row mixture pure
strategy sr2 , best response sc3 . Since, Corollary 2, n pure
Nash equilibrium, cannot constitute equilibrium, contradicting assumption.
Alternatively, Mc include sc1 , mc must pure strategy sci+1 ,
Lemma 1 provides pure-strategy best response pure strategy > 2.
would, again, form pure strategy Nash equilibrium, shown cannot exist.
reasoning also inverted show contradiction caused
assumption Mc contain sc1 .
shown row players equilibrium mixture must contain r1 r2 ,
column players equilibrium mixture must contain c1 c2 strategies
either players supports, since would lead one highly negative
utility.
game demonstrates possible construct large CURB sets
loose around supports enclosed Nash equilibrium, giving us following general
result.
Theorem 4. Nash equilibrium supports consisting two strategies player
Nash equilibrium arbitrarily large minimal CURB set.
results imply minimal CURB set algorithms always effective
preprocessors Nash equilibrium finding. However, game instances small
CURB set relatively tight minimal CURB set,2 algorithms potential
yield significant speed improvement.
Furthermore, existence polynomial-time algorithm detecting games
smallest CURB set (small MC) allows us offer following theoretical result potential
general interest.
Theorem 5. complexity finding Nash equilibrium two-player normal-form
game super-polynomial size games smallest CURB set (not
size full game).
relationship complexity finding minimal CURB set
finding Nash equilibrium surprising several ways. one, obvious
finding minimal CURB set easier finding Nash equilibrium, since, like
Nash equilibria, CURB sets exponential space possible supports chosen maximization processes players. Yet theoretical, worst-case
perspective, Nash equilibrium finding PPAD-complete (which widely believed
strictly harder complexity class P) and, showed earlier paper, minimal
CURB set finding polynomial time.
worth noting games small support equilibria, include games
small CURB sets, already known easily solvable Nash equilibria
2. game relatively tight CURB set, Nash equilibrium found quickly enumerating
strategies CURB left supports.

529

fiBenisch, Davis, & Sandholm

using techniques support enumeration. particular, games whose smallest
CURB set size logarithmic full game size, support enumeration CURB
set preprocessing permit guarantee polynomial runtime finding Nash equilibrium.
CURB set preprocessing additional advantage also used simplify
games larger equilibrium supports, support enumeration exponential.
example, consider Gk game class described Sandholm, Gilpin Conitzer (2005),
generates games single equilibrium, equilibrium contains half
strategies support. also determined games single CURB set,
CURB set includes exactly supports equilibrium. Games class
padded, using embedding technique Theorem 3, become arbitrarily
large games without introducing additional equilibria CURB sets. games,
CURB set detection offers polynomial-time method reducing game point
algorithms based support enumeration applied.
complexity two problems (Nash equilibrium finding CURB
set finding) practice? Figure 6 shows, average runtimes smallest CURB
set finding algorithm Lemke-Howson Nash equilibrium finding algorithm (using
implementation Gambit, McKelvey, McLennan, & Turocy, 2004) seem scale similarly
input game size (when one explicitly generate pathological cases
produce exponential behavior latter, Savani & von Stengel, 2004). fact, CURB
set algorithms slower (by two orders magnitude) average Lemke-Howson.
experimental performance agrees intuition, reverse theoretical
state knowledge regarding worst-case complexity.

1000

small_MC
Lemke Howson

100
10
1
0.1
0.01

Covariant games
Logscale runtime (sec)

Logscale runtime (sec)

Random games

20 30 40 50 60 70 80 90 100
Game size (n)

1000

small_MC
Lemke Howson

100
10
1
0.1
0.01
20 30 40 50 60 70 80 90 100
Game size (n)

Figure 6: Average runtime 95% confidence intervals small MC Lemke Howson
function game size.

worth pointing algorithm builds part work one
CURB set problems (finding minimal CURB sets) presented working
paper (Klimm, Sandholm, & Weibull, 2010), appears scale favorably
ours. However, algorithm directly compared Lemke-Howson
Nash equilibrium finding algorithms, relative value related preprocessing
remains seen.
530

fiAlgorithms Closed Rational Behavior (CURB) Sets

root cause complexity Nash equilibrium search proved elusive, two
candidates considered potential culprits shown affect worstcase complexity: games two players binary utilities difficult
general case, even restrictions apply simultaneously (Chen & Deng, 2006; Abbott
et al., 2005). fact bounding smallest CURB set size serve bound
difficulty Nash equilibrium search suggests isolate cause
equilibrium search complexity endemic minimal CURB sets, rather games
general. regard, observe special two-player game used Chen
Deng show PPAD-completeness (Chen & Deng, 2006) single minimal CURB
set, remains Abbott et al.s (Abbott et al., 2005) transformation binary
utilities.

6. Conclusions
presented thorough computational treatment CURB sets, important set-valued,
game-theoretic solution concept, including several algorithms finding CURB sets
two-player, normal-form games. algorithms find minimal CURB sets (all MC),
one minimal CURB set (one MC), smallest minimal CURB set (small MC),
polynomial time. algorithms based basic properties CURB sets prove,
fact minimal CURB sets cannot overlap. algorithms use dovetailing
priority queue, exploiting information across overlapping, non-minimal CURB
sets, improve speed.
Experiments random games showed that, unsurprisingly, small MC tends
fastest, one MC second, MC slowest. However, covariant games speed
advantage former two disappears. runtime algorithms primarily
determined size smallest CURB set, covariant games, tend
larger CURB sets, algorithms (especially one MC) suffer.
algorithms also enable study CURB set size distributions different game
classes. showed instance distributions GAMUT mainly extremal,
sense given game generator yield mostly games pure-strategy equilibria
and/or games game sole minimal CURB set. However, curiously,
generators yield significant number games smallest CURB sets
specific non-extremal sizes.
also examined potential using algorithms preprocessors Nash equilibrium finding algorithms. proved technique eliminate arbitrarily large
portion game consideration, guaranteeing remaining subgame
contains least one Nash equilibrium full game. case even games
prior preprocessing techniques, including iterated removal dominated strategies, powerless.
downside, showed smallest CURB set arbitrarily large and/or
arbitrarily loose. Furthermore, many distributions, showed current Nash equilibrium finding algorithms run faster, average, CURB set algorithms.
surprising theoretical worst-case complexity two problems reverse.
demonstrated worst-case complexity finding Nash equilibrium polynomial known aspects game except size smallest CURB set. Taken
531

fiBenisch, Davis, & Sandholm

together CURB set finding algorithms polynomial time even worst
case, fact Nash equilibrium finding super-polynomial worst case (unless PPAD=P), observe essence worst-case complexity finding Nash
equilibrium complexity finding Nash equilibrium within minimal CURB set.
CURB set definition number players, presented
algorithms two-player setting. larger number players, obstacle
finding minimal CURB sets finding conditional best responses quickly subroutine.
showed problem solved fast two playersin settings involves
solving simple linear feasibility program. However, mathematical program use
degree p 1, p number players, three players constraints
already quadratic. plus side, algorithms make polynomial number
calls subroutine. Therefore, future research able identify polynomial-time
algorithms finding players conditional best responses n-player games,
CURB set algorithms also polynomial time settings.

Acknowledgments
material based upon work supported National Science Foundation ITR grant
0205435, IGERT grant 9972762, IIS grants 0121678, 0427858, 0905390, well
Office Naval Research grant N00014-02-1-0973, Sloan Fellowship. would
also like thank anonymous reviewers, Vincent Conitzer, Andrew Gilpin
helpful input advice.

References
Abbott, T., Kane, D., & Valiant, P. (2005). complexity two-player win-lose games.
Proceedings Symposium Foundations Computer Science (FOCS), pp.
113122.
Basu, K., & Weibull, J. W. (1991). Strategy subsets closed rational behavior. Economics Letters, 36 (2), 141146.
Battigalli, P., & Siniscalchi, M. (2003). Rationalizable bidding first-price auctions. Games
Economic Behavior, 45 (1), 3872.
Bernheim, B. D. (1984). Rationalizable strategic behavior. Econometrica, 52 (4), 100728.
Brandt, F., Brill, M., Fischer, F., & Harrenstein, P. (2009). Computational aspects
Shapleys saddles. Proceedings International Conference Autonomous
Agents Multi-Agent Systems (AAMAS), pp. 209216.
Chen, X., & Deng, X. (2006). Settling complexity two-player Nash-equilibrium.
Proceedings Symposium Foundations Computer Science (FOCS), pp.
261272.
Conitzer, V., & Sandholm, T. (2005a). Complexity (iterated) dominance. Proceedings
ACM Conference Electronic Commerce (ACM EC), pp. 8897.
532

fiAlgorithms Closed Rational Behavior (CURB) Sets

Conitzer, V., & Sandholm, T. (2005b). generalized strategy eliminability criterion
computational methods applying it.. Proceedings National Conference
Artificial Intelligence (AAAI), pp. 483488.
Conitzer, V., & Sandholm, T. (2006). technique reducing normal form games compute Nash equilibrium. Proceedings International Conference Automated
Agents Multi-Agent Systems (AAMAS), pp. 537544.
Daskalakis, C., Goldberg, P. W., & Papadimitriou, C. H. (2009). complexity computing nash equilibrium. Communications ACM, 52 (2), 8997.
Gilboa, I., Kalai, E., & Zemel, E. (1993). compleixty eliminating dominated strategies. Mathematics Operations Research, 18, 553565.
Gilboa, I., & Zemel, E. (1989). Nash correlated equilibria: complexity considerations. Games Economic Behavior, 1, 8093.
Hurkens, S. (1995). Learning forgetful players. Games Economic Behavior, 11 (1),
304329.
Jordan, P., & Wellman, M. (2010). Algorithms finding approximate formations games.
Proceedings National Conference Artificial Intelligence (AAAI), pp. 798
804.
Klimm, M., Sandholm, T., & Weibull, J. W. (2010). Finding minimal sCURB sets
finite games. Mimeo, 3/24/2010.
Knuth, D. E., Papadimitriou, C. H., & Tsitsiklis, J. N. (1988). note strategy elimination
bimatrix games. Letters, 7 (3), 103107.
Lemke, C., & Howson, J. (1964). Equilibrium points bimatrix games. Journal
Society Industrial Applied Mathematics, 12, 413423.
McKelvey, R. D., McLennan, A. M., & Turocy, T. L. (2004). Gambit: Software tools
game theory, version 0.97.1.5. http://econweb.tamu.edu/gambit.
Nudelman, E., Wortman, J., Shoham, Y., & Leyton-Brown, K. (2004). Run GAMUT:
comprehensive approach evaluating game-theoretic algorithms.. Proceedings
International Conference Automated Agents Multi-Agent Systems (AAMAS), pp. 880887.
Pearce, D. G. (1984). Rationalizable strategic behavior problem perfection.
Econometrica, 52 (4), 102950.
Porter, R., Nudelman, E., & Shoham, Y. (2004). Simple search methods finding
Nash equilibrium. Proceedings National Conference Artificial Intelligence
(AAAI), pp. 664669.
Pruzhansky, V. (2003). finding CURB sets extensive games. International Journal
Game Theory, 32 (2), 205210.
Sandholm, T., Gilpin, A., & Conitzer, V. (2005). Mixed-integer programming methods
finding Nash equilibria. Proceedings National Conference Artificial
Intelligence (AAAI), pp. 495501.
533

fiBenisch, Davis, & Sandholm

Savani, R., & von Stengel, B. (2004). Exponentially many steps finding Nash equilibrium bimatrix game. Proceedings Symposium Foundations
Computer Science (FOCS), pp. 258267.
Voorneveld, M., Kets, W., & Norde, H. (2005). axiomatization minimal CURB sets.
International Journal Game Theory, 33, 479490.
Ye, Y. (2006). Improved complexity results solving real-number linear feasibility problems. Mathematical Programming, 106 (2), 339363.

534

fiJournal Artificial Intelligence Research 38 (2010) 1-48

Submitted 11/09; published 05/10

Using Local Alignments Relation Recognition
Sophia Katrenko
Pieter Adriaans
Maarten van Someren

S.Katrenko@uva.nl
P.W.Adriaans@uva.nl
M.W.vanSomeren@uva.nl

Informatics Institute, University Amsterdam
Science Park 107, 1098XG Amsterdam, Netherlands

Abstract
paper discusses problem marrying structural similarity semantic relatedness Information Extraction text. Aiming accurate recognition relations,
introduce local alignment kernels explore various possibilities using
task. give definition local alignment (LA) kernel based Smith-Waterman
score sequence similarity measure proceed range possibilities computing similarity elements sequences. show distributional similarity
measures obtained unlabeled data incorporated learning task semantic knowledge. experiments suggest LA kernel yields promising results
various biomedical corpora outperforming two baselines large margin. Additional
series experiments conducted data sets seven general relation types,
performance LA kernel comparable current state-of-the-art results.

1. Introduction
Despite fact much work done automatic relation extraction (or recognition) past decades, remains popular research topic. main reason
keen interest relation recognition lies utility. concepts semantic relations
identified, used variety applications question answering
(QA), ontology construction, hypothesis generation others.
ontology construction, relation studied is-a relation (or hypernymy), organizes concepts taxonomy (Snow, Jurafsky, & Ng, 2006). information retrieval, semantic relations used two ways, refine queries actual
retrieval, manipulate output returned search engine (e.g. identifying
whether fragment text contains given relation not). widely used relations
query expansion hypernymy (or broader terms thesaurus) synonymy.
Semantic relations also useful different stages question answering.
taken account identifying type question considered actual answer extraction time (van der Plas, 2008). Yet another application
relations constructing new scientific hypothesis given evidence found text.
type knowledge discovery text often based co-occurrence analysis and, many
cases, corroborated via experiments laboratories (Swanson & Smalheiser, 1999).
Another reason extraction semantic relations interest lies diversity
relations. Different relations need different extraction methods. Many existing information
extraction systems originally designed work generic data (Grishman & Sundheim, 1996), became evident domain knowledge often necessary successful

c
2010
AI Access Foundation. rights reserved.

fiKatrenko, Adriaans, & van Someren

extraction. instance, relation extraction biomedical domain would require
accurate recognition named entities gene names (Clegg, 2008), area
food needs information relevant named entities toxic substances.
Also generic relations syntactic information often sufficient. Consider,
instance, following sentences (with arguments relations written italics):
(1)

Mary looked back whispered: know every tree forest, every scent.
(Part-Whole relation)

(2)

person infected particular flu virus strain develops antibodies
virus. (Cause-Effect relation)

(3)

apples basket. (Content-Container relation)

sentences exemplify binary relations, namely Part-Whole (tree part
forest), Cause-Effect (virus causes flu) Content-Container (apples contained
basket). easily notice syntactic context (1) (3) same, namely,
arguments cases connected preposition in. However,
context highly ambiguous even though allows us reduce number
potential semantic relations, still sufficient able discriminate
Part - Whole Content - Container relation. words, world knowledge
trees, forests, apples baskets necessary classify relations correctly.
situation changes even drastically consider example (2). Here, explicit
indication causation. Nevertheless, knowing flu virus is,
able infer Cause - Effect relation holds.
examples (1), (2) (3) highlight several difficulties characterize semantic
relation extraction. Generic relations often occur nominal complexes flu
virus (2) lack sentential context boosts approaches paraphrasing (Nakov,
2008). However, even noun compounds one combine world knowledge
compounds context arrive correct interpretation.
Computational approaches relation recognition problem often rely two-step
procedure. First, relation arguments identified. Depending relation hand,
step often involves named entity recognition arguments relations.
second step check whether relation holds. relation arguments provided (e.g.,
basket apples (3)), relation extraction reduced second step. Previous
work relation extraction suggests case accuracy relation recognition
much higher case discovered automatically (Bunescu
et al., 2005). Furthermore, existing solutions relation extraction (including work
presented paper) focus relation examples occur within single sentence
consider discourse (McDonald, 2005). Recognizing relations wider scope
interesting enterprise, would require take account anaphora resolution
types linguistic analysis.
Approaches relation extraction based hand-written patterns timeconsuming many cases need expert formulate test patterns. Although
patterns often precise, usually produce poor recall (Thomas et al., 2000).
general, hand-written patterns two types. first type sequential based
2

fiUsing Local Alignments Relation Recognition

frequently occurring sequences words sentence. Hand-written sequential patterns
initially used extraction Hypernymy (Hearst, 1992), several attempts
extend relations. second type patterns (Khoo, Chan, & Niu, 2000) take
syntactic structure sentence account. dependency structure sentence
usually represented tree patterns become subtrees. patterns
sometimes referred graphical patterns. identify examples Cause-Effect
relation, Khoo et al. (2000) applied type patterns texts medical domain.
study showed graphical patterns sensitive errors made parsers,
cover examples test data extract many spurious instances.
alternative using hand-written patterns supervised Machine Learning. Then,
relations labeled used train classifier recognize relations new
texts. One approach learn generalized extraction patterns patterns expressed
characters, words syntactic categories words. approaches involve clustering
based co-occurrence (Davidov & Rappoport, 2008). recent years kernel-based methods
become popular handle high-dimensional problems (Zelenko et al.,
2003; Bunescu & Mooney, 2006; Airola et al., 2008). methods transform text fragments, complete sentences segments around named entitites verbs, vectors,
apply Support Vector Machines classify new fragments.
Machine Learning methods use prior knowledge given system
addition labeled examples (Scholkopf, 1997, p. 17). use prior knowledge often
motivated by, example, poor quality data data sparseness. Prior knowledge
used many ways, changing representation existing training examples adding
examples unlabelled data. NLP tasks, prior knowledge exists form
manually (or automatically) constructed ontologies large collections unannotated data.
enrich textual data thereby improve recognition relations (Sekimizu,
Park, & Tsujii, 1998; Tribble & Fahlman, 2007). Recently, Zhang et al. (2008) showed
semantic correlation words learned unlabelled text collections, transferred
among documents used improve document classification. general,
use large collections text allows us derive almost information needed, done
varying accuracy. contrast, existing resources created humans provide
precise information, less likely cover possible areas interest.
paper, work Bunescu Mooney (2006), use syntactic
structure sentences, particular, dependency paths. stems observation
linguistic units organized complex structures understanding words
word senses relate often requires contextual information. Relation extraction
viewed supervised classification problem. training set consists examples
given relation goal construct model applied new, unseen
data set, recognize instances given relation new data set. recognition
relations use kernel-based classifier applied dependency paths. However,
instead vector-based kernel directly use similarity dependency paths
show information existing ontologies large text corpora employed.
paper organized follows. start reviewing existing kernel methods
work sequences (Section 2). Section 3, give definition local alignment kernel
based Smith-Waterman measure. proceed discussing used
context natural language processing (NLP) tasks, particularly extracting
3

fiKatrenko, Adriaans, & van Someren

relations text (Section 3.2). method described, report two types
data sets (biomedical generic) used experiments (Section 4) elaborate
experiments (Sections 5 6). Section 7 discusses findings detail.
Section 8 concludes paper discussing possible future directions.

2. Kernel Methods
past years witnessed boost interest kernel methods, theoretical analysis
practical applications various fields (Burges, 1998; Shawe-Taylor & Christianini,
2000). idea method works different structures representations,
starting simplest representation using limited number attributes complex
structures trees, seems indeed attractive.
define kernel function, recall standard setting supervised classification. training set n objects (instances) (x1 , y1 ), . . . , (xn , yn ) x1 , . . . , xn X
input examples input space X corresponding labels y1 , . . . , yn {0,1},
goal infer function h : X {0, 1} approximates target function t.
However, h still err data reflected loss function, l(h(xi ), yi ).
Several loss functions proposed literature far, best known
zero-one loss. loss function outputs 1 time method errs
data point (h(xi ) 6= yi ), 0 otherwise.
key idea kernel methods lies implicit mapping objects highdimensional space (by using mapping function ) considering inner product
(similarity) k(xi , xj ) =< (xi ), (xj ) >, rather representing explicitly. Functions used kernel methods
symmetric positive semi-definite,
Pbe
n Pn
whereby positive semi-definiteness defined i=1 j=1 ci cj k(xi , xj ) 0 n > 0,
objects x1 , . . . , xn X , choice real numbers c1 , . . . , cn R. function
positive semi-definite, algorithm may find global optimal solution.
requirements w.r.t. symmetry positive semi-definiteness met, kernel called
valid.
Using idea kernel mapping, Cortes Vapnik (1995) introduced support vector
machines (SVM) method seeks linear separation two classes
input points function f (x) f (x) = wT (x) + b, wT Rp , b R
h(x) = sign(f (x)). Here, wT stands slope linear function b
offset. Often, exist several functions separate data well,
equally good. hyperplane separates mapped examples largest possible
margin would best option (Vapnik, 1982).
SVMs solve following optimization problem:
n

X
1
k w k2 +C
l(h(xi ), yi )
f (x)=wT x+b 2
argmin

(4)

i=1

Equation 4, first part equation corresponds margin maximization
(by minimizing 12 k w k2 ), second takes account error training
set minimized (where C penalty term). hyperplane found
may correspond non-linear boundary original input space. exist number
4

fiUsing Local Alignments Relation Recognition

standard kernels linear kernel, Gaussian kernel others. Information
data problem motivate choice particular kernel.
shown Haussler (1999) complex kernel (referred convolution kernel )
defined using simpler kernels.
forms machine learning representations using prior knowledge defined
along methods exploiting it. Inductive logic programming offers one possible
solution use explicitly, form additional Horn clauses (Camacho, 1994).
Bayesian learning paradigm information hypothesis without seeing data encoded Bayesian prior (Mitchell, 1997) higher level distribution hierarchical
Bayesian setting. less obvious though represent use prior knowledge
learning frameworks. case SVMs, three possible ways incorporating
prior knowledge (Lauer & Bloch, 2008). named sampling methods (prior knowledge used generate new data), kernel methods (prior knowledge incorporated
kernel function by, instance, creating new kernel), optimization methods
(prior knowledge used reformulate optimization problem by, example, adding
additional constraints). choice kernel based general statistical properties
domain, attractive possibility incorporate explicit domain knowledge
kernel. improve kernel smoothing space: instances
similar higher probability belonging class kernel without
prior knowledge.
follows, review number kernels strings proposed
research community past years. natural domain look
biomedical field many problems formulated string classification
(protein classification amino acid sequences, name few). Sequence representation
is, however, applicable biomedical area, also considered
many natural language processing tasks. introducing kernels used
biomedicine, move NLP domain present recent work relation extraction
employing kernel methods.
2.1 Spectrum Kernel
Leslie, Eskin, Noble (2002) proposed discriminative approach protein classification.
sequence x X , authors define m-spectrum set contiguous
subsequences x whose length equal m. possible m-long subsequences q
indexed frequency occurrence (q (x)). Consequently, feature map
sequence x alphabet equals (x) = (q (x))qAm . spectrum kernel two
sequences x defined inner product corresponding feature maps:
kS (x, y) =< (x), (y) >.
Now, even assuming contiguous subsequences small m, feature space consider
large. authors propose detect subsequences length using suffix
tree method guarantees fast computation kernel matrix. spectrum kernel
tested task protein homology detection, best results achieved
setting relatively small number (3). novelty Leslie et al.s (2002) method
lies generality low computational complexity.

5

fiKatrenko, Adriaans, & van Someren

2.2 Mismatch Kernels
mismatch kernel introduced later Leslie et al. (2004) essentially extension latter. obvious limitation spectrum kernel considered
subsequences contiguous match exactly. mismatch kernel contiguity preserved match criterion changed. words, instead looking
possible subsequences length given subsequence, one searching
possible subsequences length allowing r mismatches. comparison
result larger subset subsequences, kernels defined way still calculated rather fast. kernel formulated similarly spectrum kernel
major difference computing feature map
P sequences. precisely, feature
map sequence x defined m,r (x) = qS m,r (q) m,r (q) = ( (q))Am .
(q) binary indicates whether sequence belongs set m-length sequences
differ q r elements (1) (0). clear r set
0, mismatch kernel reduced spectrum kernel. complexity mismatch
kernel computation linear respect sum sequence lengths.
authors also show mismatch kernel yields state-of-the-art performance protein classification task also outputs subsequences informative
biological point view.
2.3 Kernel Methods NLP
One merits kernel methods possibility designing kernels different structures, strings trees. NLP field (and relation extraction, particular)
work roughly falls two categories. first, kernels defined plain
text using sequences words. second uses linguistic structures dependency
paths trees output shallow parsing. short review take
chronological perspective rather start methods based sequences
proceed approaches make use syntactic information.
year spectrum kernel designed, Lodhi et al. (2002) introduced string subsequence kernels provide flexible means work text data.
particular, subsequences necessarily contiguous weighted according
length (using decay factor ). length subsequences fixed advance.
authors claim even without use linguistic information kernels
able capture semantic information. reflected better performance
text classification task compared bag-of-words approach. Lodhi et al.s (2002)
kernel works sequences characters, kernel proposed Cancedda et al. (2003)
applied word sequences. String kernels also extended syllable kernels
proved well text categorization (Saunders, Tschach, & Shawe-Taylor, 2002).
kernels defined recursively, computation efficient.
instance, time complexity Lodhi et al.s (2002) kernel O(n|s||t|), n
length subsequence, documents.
2.3.1 Subsequence Kernels
recognition binary relations, natural way consider words located
around relation arguments. approach taken Bunescu Mooney
6

fiUsing Local Alignments Relation Recognition

(2005b) whose choice sequences motivated textual patterns found corpora.
instance, observed relations expressed subject-verb-object constructions others part noun prepositional phrases. result, three types
sequences considered: fore-between (words two named entities),
(words two entities) between-after (words two
entities). length sequences restricted. handle data sparseness, authors
generalize existing sequences using PoS tags, entity types WordNet synsets.
generalized subsequence kernel recursively defined number weighted sparse subsequences two sequences share. absence syntactic information, assumption
made long subsequences likely represent positive examples
penalized. subsequence kernel computed three types sequences
resulting relation kernel defined sum three subkernels. Experimental results
biomedical corpus encouraging, showing relation kernel performs better
manually written patterns approach based longest common subsequences.
method proposed Giuliano et al. (2006) largely inspired work Bunescu
Mooney (2005b). However, instead looking subsequences three types sequences, authors treat bag-of-words define called global kernel
follows. First, sequence type (pattern) P represented vector whose elements
counts many times token used P . local kernel defined similarly
using words surrounding named entities (left right context). final shallow
linguistic kernel defined combination global local kernels. Experiments biomedical corpora suggest kernel outperforms subsequence kernel
Bunescu Mooney.
2.3.2 Distributional Kernels
Recently, Seaghdha Copestake (2008) introduced distributional kernels co- occurrence probability distributions. co-occurrence statistics use form
either syntactic relations n-grams. show possible derive kernels
distances Jensen-Shannon divergence (JSD) Euclidean distance (L2 ) (Lee, 1999).
JSD smoothed version Kullback-Leibler divergence, information-theoretic measure dissimilarity two probability distributions. main motivation behind
approach lies fact distributional similarity measures proved useful
NLP tasks. extract co-occurrence information, authors use two corpora, British
National Corpus (BNC) Web 1T 5-Gram Corpus (which contains 5-grams
observed frequency counts collected Web). Distributional kernels
proved successful number tasks compound interpretation, relation
extraction verb classification. them, JSD kernel clearly outperforms
Gaussian linear kernels. Moreover, estimating distributional similarity BNC
corpus yields performance similar results obtained Web 1T 5-Gram Corpus.
interesting finding BNC corpus used estimate similarity
syntactic relations whereas latter corpus contains n-grams only. importantly,
method Seaghdha Copestake provides empirical support claim using
distributional similarity beneficial relation extraction.

7

fiKatrenko, Adriaans, & van Someren

2.3.3 Kernels Syntactic Structures
Kernels defined unpreprocessed text data seem attractive applied
directly text language. However, general are, lose precision compared methods use syntactic analysis. Re-ranking parsing
trees (Collins & Duffy, 2001) one first applications kernel methods NLP
problems. accomplish goal, authors rely subtrees pair trees
common. Later on, Moschitti (2006) explored convolution kernels dependency
constituency structures semantic role labeling question classification. work
introduces novel kernel called partial tree kernel (PT). essentially built
two kernels proposed before, subtree kernel (ST) contains descendant nodes
target root (including leaves) subset tree kernel (SST) flexible
allows internal subtrees necessarily encompass leaves. partial tree
generalization subset tree whereby partial structures grammar allowed (i.e.,
parts production rules [VP [V]] form valid PT). Moschitti demonstrated
PTs obtain better performance dependency structures SSTs, latter
yield better results constituent trees.
2.3.4 Kernel Shallow Parsing Output
Zelenko et al. (2003) use shallow parsing designed kernels extract relations text.
contrast full parsing, shallow parsing produces partial interpretations sentences.
node tree enriched information roles (that correspond
arguments relation). similarity two trees determined similarity
nodes. Depending similarity computed, Zelenko et al. define two types
kernels, contiguous subtree kernels sparse kernels. types tested two types
relations, person-affiliation organization-location exhibiting good performance.
particular, sparse kernels outperform contiguous subtree kernels leading conclusion
partial matching important dealing typically sparse natural language
data. However, computation sparse kernel takes O(mn3 ) time (where n
number children two relation examples, i.e. shallow trees, consideration,
n), algorithm contiguous subtree kernel runs time O(mn).
2.3.5 Shortest Path Kernel
Bunescu Mooneys (2005a) shortest path kernel represents yet another approach
relation extraction kernel-based relies information found dependency trees.
main assumption entire dependency structure relevant, one
focus path connecting two relation arguments instead. similar
paths are, likely two relation examples belong category. spirit
previous work, Bunescu Mooney seek generalizations existing paths
adding information sources like part speech (PoS) categories named entity types.
shortest path relation arguments extracted kernel two
sequences (paths) x = {x1 , . . . , xn } x0 = {x01 , . . . , x0m } computed follows:

8

fiUsing Local Alignments Relation Recognition

0

kB (x, x ) =



0Q
n

0
i=1 f (xi , xi )

6= n
m=n

(5)

Equation 5, f (xi , x0i ) number features shared xi x0i . Bunescu
Mooney (2005a) use several features word (e.g., protesters), part speech tag (e.g.,
N N S), generalized part speech tag (e.g., N oun), entity type (e.g., P ERSON )
applicable. addition, direction feature ( ) employed. reproduce
example paper.
Example 1 Given two dependency paths exemplify relation Located
actions Brcko arrival Beijing, paths expanded
additional features mentioned above. easy see comparing path (6)
path (7) gives us score 18 (3111213 = 18).





Brcko



actions
NNP

P RP
[] N N []
[]
N oun

P ERSON
N oun
LOCAT ION













(6)


Beijing

NNP

[]

N oun
LOCAT ION

(7)





arrival

[] N N
[]
P RP
N oun
P ERSON








time complexity shortest path kernel O(n), n stands length
dependency path.
Dependency paths also considered recent work relation recognition (Erkan,
Ozgur, & Radev, 2007). Here, Erkan et al. (2007) use dependency paths input
compare means cosine similarity edit distance. authors motivate
choice need compare dependency paths different length. Further, various machine learning methods used classification, including SVM transuctive SVM
(TSVM), extension SVM (Joachims, 1999). particular, TSVM makes use
labeled unlabeled data first classifying unlabeled examples searching
maximum margin separates positive negative instances sets.
authors conclude edit distance performs better cosine similarity measure,
TSVM slightly outperforms SVM.
Airola et al. (2008) propose graph kernel makes use entire dependency
structure. work, sentence represented two subgraphs, one
built dependency analysis, corresponds linear structure
sentence. Further, kernel defined paths two vertices graph.
method Airola et al. (2008) achieves state-of-the-art performance biomedical
data sets, discussed, together shortest path kernel work

9

fiKatrenko, Adriaans, & van Someren

Erkan et al. (2007), Section 5 relation extraction biomedical domain
paper.
Finally, kernels defined graphs syntactic structures, also
graphs semantic network. illustrated Seaghdha (2009), uses graph
kernels graph built hyponymy relations WordNet. Even though
syntactic information utilized, kernels proved perform well extraction
various generic relations.
kernels reviewed section deal sequences trees albeit different ways. empirical findings suggest kernels allow partial matching usually
perform better compared methods similarity defined exact match.
alleviate problem exact matching, researchers suggested generalizing
elements existing structures (Bunescu & Mooney, 2005a) others opted flexible
comparison. view, types methods complement (Saunders
et al., 2002). flexible partial matching methods are, may suffer low precision penalization mismatch low. holds approaches use
generalization strategies may easily overgeneralize. possible solution would
combine both, provided mismatches penalized well generalizations
semantically plausible rather based part speech categories. idea
explored present paper evaluated relation recognition task.
nutshell, goals paper following: (i) study possibilities
using local alignment kernel relation extraction text, (ii) exploration
use prior knowledge alignment kernel (iii) extensive evaluation
automatic recognition two types relations, biomedical generic.

3. Local Alignment Kernel
One note short overview kernels designed NLP many
researchers use partial structures propose variants subsequence kernels (Bunescu
& Mooney, 2005b), partial tree kernel (Moschitti, 2006), kernel shallow parsing
output (Zelenko et al., 2003) relation extraction. paper focus dependency
paths input formulate following requirements kernel function:
allow partial matching similarity measured paths
different length
possible incorporate prior knowledge
Recall prior knowledge mean information comes either larger corpora existing resources ontologies. instance, knowing development
synonymous evolution contexts help recognize two different words
close semantically. information especially useful meaning relevant
detecting relations may differ form.
following subsection define local alignment kernel satisfies
requirements show incorporate prior knowledge.

10

fiUsing Local Alignments Relation Recognition

3.1 Smith-Waterman Measure Local Alignments
work motivated recent advances biomedical field. shown
possible design valid kernels based similarity measure strings (Saigo,
Vert, & Akutsu, 2006). example, Saigo, Vert, Ueda, Akutsu (2004) consider
Smith-Waterman (SW) similarity measure (Smith & Waterman, 1981) (see below) measure similarity two sequences amino acids.
String distance measures divided measures based terms, edit-distance
Hidden Markov models (HMM) (Cohen, Ravikumar, & Fienberg, 2003). Term-based
distances measures based TF-IDF score, consider pair word sequences
two sets words ignoring order. contrast, string edit distances (or string similarity
measures) treat entire sequences compare using transformation operations,
convert sequence x sequence x0 . Examples Levenshtein distance,
Needleman-Wunsch (Needleman & Wunsch, 1970) Smith-Waterman (Smith
& Waterman, 1981) measures. Levenshtein distance used natural
language processing field component variety tasks, including semantic role
labeling (Sang et al., 2005), construction paraphrase corpora (Dolan, Quirk, & Brockett,
2004), evaluation machine translation output (Leusch, Ueffing, & Ney, 2003), others.
Smith-Waterman measure mostly used biological domain, are, however,
applications modified Smith-Waterman measure text data well (Monge &
Elkan, 1996; Cohen et al., 2003). HMM-based measures present probabilistic extensions
edit distances (Smith, Yeganova, & Wilbur, 2003).
hypothesis string similarity measures best basis kernel
relation extraction. case, order words appear likely relevant
sparse data usually prevents estimation probabilities (as work Smith et al.,
2003). general, two sequences aligned several possible ways. possible
search either alignment spans entire sequences (global alignment),
alignment based similar subsequences (local alignment). case
sequences amino acids relation extraction, local patterns likely
important factor determines similarity. Therefore need similarity measure
emphasizes local alignments.
Formally, define pairwise alignment L elements two sequences
x = x1 x2 . . . xn x0 = x01 x02 . . . x0m , pairing = {l (i, j)}, l = 1, . . . , L, 1 n,
1 j m, 1 l n, 1 l m. Example 2 (ii), third element first sequence
aligned first element second one, denoted 1 (3, 1).
Example 2 Given sequences x=abacde x0 =ace, two possible alignments (with gaps
indicated -) follows.
(i) global alignment



b
-


-

c
c


-

e
e

Alignment:

= {1 (1, 1), 2 (4, 2), 3 (6, 3)}




c
c


-

e
e

Alignment:

= {1 (3, 1), 2 (4, 2), 3 (6, 3)}

(ii) local alignment

-

b
-

11

fiKatrenko, Adriaans, & van Someren

example, number gaps inserted x0 align x number
elements match cases. Yet, biological
linguistic context may prefer alignment (ii), closely matching substrings,
local alignments, better indicator similarity shared items far apart.
is, therefore, better use measure puts less weight gaps
start end strings (as Example 2 (ii)). done using local
alignment mechanism searches similar subsequences two sequences.
Local alignments employed sequences dissimilar different length,
global alignments considered sequences roughly length.
measures mentioned above, Smith-Waterman measure local alignment
measure, Needleman-Wunsch measure compares two sequences based global
alignments.
Definition 1 (Global alignment) Given two sequences x = x1 . . . xn x0 = x01 . . . x0m ,
global alignment pair sequences y0 length,
obtained inserting zero gaps first element either x x0 ,
element x x0 .
Definition 2 (Local alignment) Given two sequences x = x1 . . . xn x0 = x01 . . . x0m ,
local alignment pair subsequences x x0 , whose similarity
maximal.
clarify mean local global alignments, give definition
Smith-Waterman Needleman-Wunsch measures. Given two sequences x = x1 x2 . . . xn
x0 = x01 x02 . . . x0m length n respectively, Smith-Waterman measure defined
similarity score best local alignment:

sw(x, x0 ) =

max

A(x,x0 )

s(x, x0 , )

(8)

equation above, s(x, x0 , ) score local alignment sequence x x0
denotes set possible alignments. best local alignment efficiently
found using dynamic programming. this, one fills matrix SW partial
alignments follows:

0



SW(i 1, j 1) + d(xi , x0j )
SW (i, j) = max
1in,
SW(i 1, j) G


1jm
SW(i, j 1) G

(9)

Equation 9, d(xi , x0j ) denotes substitution score two elements xi x0j
G stands gap penalty. Using equation possible find partial alignments,
stored matrix cell (i, j) reflects score alignment x1 . . . xi

12

fiUsing Local Alignments Relation Recognition


c
e

0
0
0
0


0
2
1
0

b
0
1
1
0


0
2
1
0

c
0
1
4
3


0
0
3
3

e
0
0
2
5


c
e

(a) Smith-Waterman measure

0
0
0
0


0
2
1
0

b
0
1
1
0


0
0
0
0

c
0
-1
2
1


0
-1
1
1

e
0
-1
0
3

(b) Needleman-Wunsch measure

Table 1: Matrices computing Smith-Waterman Needleman-Wunsch scores sequences x=abacde x0 =ace, gap G = 1, substitution score d(xi , x0j ) = 2
xi = x0j , d(xi , x0j ) = 1 xi 6= x0j .

x01 . . . x0j . cell largest value matrix contains Smith-Waterman
score.
Needleman-Wunsch measure, searches global alignments, defined similarly, except fact cells matrix contain negative scores:

NW(i 1, j 1) + d(xi , x0j )
NW (i, j) = max
NW(i 1, j) G
1in,

NW(i, j 1) G
1jm

(10)

Smith-Waterman measure seen modification Needleman-Wunsch
method. disallowing negative scores matrix, regions high dissimilarity
avoided and, result, local alignments preferred. Moreover, NeedlemanWunsch score equals largest value last column last row, Smith-Waterman
similarity score corresponds largest value matrix.
Let us reconsider Example 2 show global local alignments alignments
two sequences x=abacde x0 =ace obtained. arrive actual alignments, one
set gap parameter G substitution scores. Assume use following
settings: gap G = 1, substitution score d(xi , x0j ) = 2 xi = x0j , d(xi , x0j ) = 1
xi 6= x0j . values chosen illustrative purpose only, realistic
case, e.g., alignment protein sequences, choice substitution scores usually
motivated biological evidence. gapping, Smith Waterman (1981) suggested
use gap value least equal difference match (d(xi , x0j ),
xi = x0j ) mismatch (d(xi , x0j ), xi 6= x0j ). Then, Smith-Waterman NeedlemanWunsch similarity scores x x0 calculated according Equation 9
Equation 10 given Table 1.
First, first row first column matrix initialized 0. Then,
matrix filled computing maximum score cell defined Equation 9
Equation 10. score best local alignment equal largest element
13

fiKatrenko, Adriaans, & van Someren

matrix (5), Needleman-Wunsch score 3. Note possible trace back
steps taken arrive final alignment (the cells boldface). left-right
step corresponds insertion, top-down step deletion (these lead gaps),
diagonal step implies alignment two sequences elements.
Since prefer use local alignments dependency paths, natural choice would
use Smith-Waterman measure kernel function. However, Saigo et al. (2004)
observed Smith-Waterman measure may result valid kernel
may positive semi-definite. give definition LA kernel, states
two sequences similar many local alignments high scores,
Equation 11.
kL (x, x0 ) =

X

0

es(x,x ,)

(11)

A(x,x0 )

Here, s(x, x0 , ) local alignment score ( 0) scaling parameter.
define LA kernel kL (as Equation 11) two sequences x x0 , needed
take account transformation operations used local alignments. First, one
define kernel elements corresponds individual alignments, ka . Second,
since type alignment allows gaps, another kernel gapping, kg . Last
least, recall local alignments parts sequences may aligned,
elements x x0 may left out. elements influence alignment
score kernel used cases, k0 , set constant, k0 (x, x0 ) = 1. Finally,
LA kernel composition several kernels (k0 , ka , kg ), spirit
convolution kernels (Haussler, 1999).
According Saigo et al. (2004), similarity aligned sequences elements (ka kernel)
defined follows:

0
|x| =
6 1 |x0 | =
6 1
0
ka (x, x ) =
(12)
0)
d(x,x
e
otherwise
either x, x0 one element, kernel would result 0. Otherwise,
calculated using substitution score d(x, x0 ) x x0 . score reflects
similar two sequences elements and, depending domain, computed using
prior knowledge given domain.
gapping kernel defined similarly alignment kernel Equation 12, whereby
scaling parameter preserved, gap penalties used instead similarity
function two elements:
0

kg (x, x0 ) = e(g(|x|)+g(|x |))

(13)

Here, g stands gap function. Naturally, gap length 0 function returns
zero. gaps length n, reasonable define gap terms gap opening
gap extension e, g(n) = + e (n 1). case possible decide whether longer
gaps penalized shorter ones, much. instance,
14

fiUsing Local Alignments Relation Recognition

three consecutive gaps alignment, first gap counted gap opening,
two gap extension. consecutive gaps (i.e., gaps length n > 1) gap
equal importance, gap opening equal gap extension. If, however,
length gaps matter, one would prefer penalize gap opening more,
give little weight gap extension.
kernels combined follows:
k(r) (x, x0 ) = k0 (ka kg )r1 ka k0

(14)

Equation 14, k(r) (x, x0 ) stands alignment r elements x x0 possibly
r 1 gaps. Similarity aligned elements calculated ka , gapping kg . Since
could r 1 gaps, corresponds following part equation:
(ka kg )r1 . Further, rth aligned element, one ka added. Given
discussion above, k0 added initial final part. follows Equation 14,
elements x x0 aligned, k(r) equals k0 , 1. elements x
x0 aligned gaps, value k(r) (ka )r .
Finally, LA kernel equal sum taken possible local alignments
sequences x x0 :

0

kL (x, x ) =


X

k(i) (x, x0 )

(15)

i=0

results biological domain suggest kernels based Smith-Waterman
distance relevant comparison amino acids string kernels (Saigo et al.,
2006). clear whether holds applied natural language processing tasks.
view, could depend parameters used, substitution
matrix penalty gaps.
3.1.1 Computational complexity
LA kernel, many kernels discussed Section 2, efficiently calculated using dynamic programming. two sequences x x0 , length n respectively,
complexity proportional n m. Additional costs may come substitution matrix, which, unlike biomedical domain, become large. However,
look-up substitution scores done efficient manner well, leads
fast kernel computation. instance, calculating kernel matrix largest data
set used paper, AImed (3,763 instances), takes 805 seconds 2.93 GHz Intel(R)
Core(TM)2 machine.
3.2 Designing Local Alignment Kernel Relation Extraction
Smith-Waterman measure based transformations, particular deletions elements different strings. However, elements different may still
similar degree. similarities used part similarity measure.
example, two elements words different synonyms,
count less different completely unrelated. call
15

fiKatrenko, Adriaans, & van Someren

similarities substitution scores (Equation 12) define two different ways:
basis distributional similarity basis semantic relatedness ontology.
Example 1 would like able infer Brcko similar Beijing, even
though two words match exactly. Furthermore, phrases arrival
Beijing arrival January, would like kernel say Brcko
similar Beijing January. use information prior knowledge
makes possible measure similarity two words, one test set
training set, even match exactly. review two types
measures based statistical distributions relatedness WordNet.
3.2.1 Distributional Similarity Measures
number distributional similarity measures proposed years, including
Cosine, Dice Jaccard coefficients. Distributional similarity measures extensively studied (Lee, 1999; Weeds, Weir, & McCarthy, 2004). main hypothesis
behind distributional measures words occurring context
similar meaning (Firth, 1957). Context defined either using proximity text,
employing grammatical relations. paper, use first option context
sequence words text length set advance.
Measure

Formula

Cosine

d(xi , x0j ) = P

Dice

d(xi , x0j ) =

L2

d(xi , x0j ) =

P (c|xi )P (c|x0j )
P
0 2
2
c P (c|xi )
c P (c|xj )

P

c

2F (xi )F (x0j )
F (xi )F (x0j )

qP

c (P (c|xi )

P (c|x0j ))2

Table 2: list functions used estimate distributional similarity measures.
chosen following measures: Dice, Cosine L2 (Euclidean) whose definitions given Table 2. definition Cosine L2, possible use either
frequency counts probability estimates derived unsmoothed relative frequencies.
Here, adopt definitions given Lee (1999), based probability estimates P . Recall x x0 two sequences would wish compare,
corresponding elements xi x0j . Further, c stands context. definition
Dice coefficient, F (xi ) = {c : P (c|xi ) > 0}. mainly interested symmetric measures
(d(xi , x0j ) = d(x0j , xi )) symmetric positive semi-definite matrix required kernel methods. Euclidean measure defined Table 2 necessarily vary 0
1. reason, given list pairs words (xi , x0j ) xi fixed j = 1, . . . ,
corresponding L2 score, maximum value maxj d(xi , x0j ) detected used
normalize scores list. Furthermore, unlike Dice Cosine, return 1
case two words equal, Euclidean score equals 0. next step, substract
obtained normalized value 1 ascertain scores within interval [0, 1]
16

fiUsing Local Alignments Relation Recognition

largest value (1) assigned identical words. view, procedure
make comparison selected distributional similarity measures respect
influence LA kernel transparent.
Distributional similarity measures suitable information available.
case data annotated means taxonomy (e.g., WordNet),
possible consider measures defined taxonomy. Availability hand-crafted
resources, WordNet, comprise various relations concepts, enables
making distinctions different concepts subtle way.
3.2.2 WordNet Relatedness Measures
generic relations, commonly used resource WordNet (Fellbaum, 1998),
lexical database English. WordNet, words grouped together synsets
synset consists list synonymous words collocations (e.g., fountain pen),
pointers describe relations synset synsets (Fellbaum, 1998).
WordNet employed different purposes studying semantic constraints
certain relation types (Girju, Badulescu, & Moldovan, 2006; Katrenko & Adriaans, 2008),
enriching training set (Giuliano et al., 2007; Nulty, 2007).
compare two concepts given synsets c1 c2 use five different measures
proposed past years. rely notions length
shortest path two concepts c1 c2 , len(c1 , c2 ), depth node
WordNet hierarchy (which equal length path root given
synset ci ), dep(ci ), least common subsumer (or lowest super-ordinate) c1
c2 , lcs(c1 , c2 ), turn synset. measures exclusively based
notions belong conceptual similarity proposed Palmer Wu (1995) (simwup
Equation 16) formula scaled semantic similarity introduced Leacock
Chodorow (1998) (simlch Equation 17). 1 major difference lies
fact simlch consider least common subsumer c1 c2 uses
maximum depth WordNet hierarchy instead. Conceptual similarity ignores
focuses subhierarchy includes synsets.

simwup (c1 , c2 ) =

2 dep(lcs(c1 , c2 ))
len(c1 , lcs(c1 , c2 )) + len(c2 , lcs(c1 , c2 )) + 2 dep(lcs(c1 , c2 ))

simlch (c1 , c2 ) = log

len(c1 , c2 )
2 maxcW ordN et dep(c)

(16)

(17)

Aiming combining information several sources, Resnik (1995) introduced yet another measure grounded information content (simres Equation 18). Intuitively,
two synsets c1 c2 located deeper hierarchy path one synset
another short, similar. path two synsets long
least common subsumer placed relatively close root, indicates synsets
1. equations similarity measures defined WordNet, subscripts refer similarity measure
(e.g., lch, wup simlch simwup , respectively)

17

fiKatrenko, Adriaans, & van Someren

c1 c2 much common. quantify intuition, necessary derive
probability estimate lcs(c1 , c2 ) done employing existing corpora.
precisely, p(lcs(c1 , c2 )) stands probability encountering instance concept
lcs(c1 , c2 ).
simres (c1 , c2 ) = log p(lcs(c1 , c2 ))

(18)

One biggest shortcomings Resniks method fact least
common subsumer appears Equation 18. One easily imagine full-blown hierarchy
relatedness concepts subsumed lcs(ci , cj ) heavily vary.
words, using lcs only, one able make subtle distinctions two
pairs concepts share least common subsumer. overcome this, Jiang
Conrath (1997) proposed solution takes account information synsets
compared (simjcn Equation 19). comparing Equation 19 Equation 18,
notice equation incorporates probability encountering
lcs(c1 , c2 ), also probability estimates c1 c2 .
simjcn (c1 , c2 ) = 2 log p(lcs(c1 , c2 )) (log p(c1 ) + log p(c2 ))

(19)

Lin (1998) defined similarity two concepts using much commonality
differences involved. Similarly two previous approaches, uses
information theoretic notions derives similarity measure simlin given Equation 20.

simlin (c1 , c2 ) =

2 log p(lcs(c1 , c2 ))
log p(c1 ) + log p(c2 )

(20)

past, semantic relatedness measures evaluated different NLP tasks (Budanitsky & Hirst, 2006; Ponzetto & Strube, 2007) concluded measure
performs best problems. evaluation, use semantic relatedness
validation generic relations study depth contribute final results.
3.2.3 Substitution Matrix Relation Extraction
now, discussed two possible ways calculating substitution score d(, ),
using either distributional similarity measures, measures defined WordNet. However,
dependency paths generated parsers may contain words (or lemmata),
also syntactic functions subjects, objects, modifiers, others. take
account, revise definition d(, ). assume sequences x = x1 x2 . . . xn
x0 = x01 x02 . . . x0m contain words (xi W W refers set words) syntactic
functions accompanied direction (xi
/ W ). elements W unique words (or
lemmata) found dependency paths, instance, paths
actions Brcko arrival Beijing Example (1) Section 2.3.5,
W = {his, actions, in, Brcko, arrival, Beijing}. dependency paths use present
work include information syntactic functions, instance awareness
joy. case, W = {awareness, come, joy} W = {
18

prep f rom

prep f rom nsubj



, }.



nsubj

come

fiUsing Local Alignments Relation Recognition

Then,

d(xi , x0j )




1
0
d0 (xi , x0j ) =


0



0

xi , x0j W
xi , x0j
/ W & xi = x0j
0
xi , xj
/ W & xi 6= x0j
xi W & x0j
/W
xi
/ W & x0j W

(21)

Equation (21) states whenever element xi sequence x compared
element x0j sequence x0 , substitution score equal either (i) similarity
score case elements words (lemmata), (ii) 1, elements
syntactic function, (iii) 0, case.
follows discussion similarity measures above, two ways define
d(xi , x0j ), using either distributional similarity xi x0j (Section 3.2.1),
WordNet similarity, provided annotated WordNet synsets (Section 3.2.2).

4. Experimental Set-up
section, describe data sets used experiments provide
information data collections used estimating distributional similarity.
4.1 Data
evaluate performance LA kernel, consider two types text data, domainspecific data, comes biomedical domain generic domain-independent
data represents variety well-known widely used relations PartWhole Cause-Effect.
Like work, extract dependency path two nodes corresponding
arguments binary relation. also assume analysis results tree since
acyclic graph, exists unique path pair nodes.
consider, however, structures might derived full syntactic analysis
in, example, subtrees (Moschitti, 2006).
4.1.1 Biomedical Relations
Corpora use three corpora come biomedical field contain annotations either interacting proteins - BC-PPI2 (1,000 sentences), AImed (Bunescu & Mooney,
2005b) interactions among proteins genes LLL (77 sentences training set
87 test set, Nedellec, 2005). BC-PPI corpus created sampling sentences BioCreAtive challenge, AImed corpus sampled Medline
collection. LLL corpus composed querying Medline term Bacillus subtilis. difference among three corpora lies directionality interactions.
Table 3 shows, relations AImed corpus strictly symmetric, LLL asymmetric BC-PPI contains types. differences number training instances
AImed corpus explained fact correspond dependency
2. Available http://www2.informatik.hu-berlin.de/~hakenber/.

19

fiKatrenko, Adriaans, & van Someren

paths named entities. parsing fails produces several disconnected graphs per
sentence, dependency path extracted.
Parser
LinkParser
LinkParser
Stanford
Stanford
Enju

Data set
LLL (train)
LLL (test)
BC-PPI
AImed
AImed

#examples
618
476
664
3763
5272

#pos
153
83
250
922
918

direction
asymmetric
asymmetric
mixed
symmetric
symmetric

a. Even though actual annotations test data given, number interactions
test data set provided LLL organizers.

Table 3: Statistics biomedical data sets LLL, BC-PPI, AImedd. table, #pos
stands number positive examples per data set #examples indicates
number examples total.

goal relation extraction three cases output correct interactions
biomedical entities (genes proteins) found input data.
biomedical entities already provided, need named entity recognition.
discrepancy training test sets used LLL challenge.
Unlike training set, sentence example least one interaction,
test set contains sentences interaction. organizers LLL challenge distinguish sentences without coreferences. Sentences coreferences
usually appositions, shown one examples below. first sentence (4.1.1)
example sentence without coreferences (with interaction ykuD SigK),
whereas second one sentence coreference (with interaction spoIVA
sigmaE). precisely, spoIVA refers phrase one genes
known interact sigmaE. therefore infer spoIVA interacts sigmaE. Sentences without coreferences form subset, refer LLL-nocoref,
sentences coreferences part separate subset LLL-coref.
(22) ykuD transcribed SigK RNA polymerase T4 sporulation.
(23) Finally, show proper localization SpoIVA required expression one
genes which, like spoIVA, control mother cell
transcription factor sigmaE.
assumed relations sentences coreferences harder recognize. show LA kernel performs subsets, report experimental results full set test data (LLL-all), subsets (LLL-coref LLL-nocoref).
Syntactic analysis analyzed BC-PPI corpus Stanford parser. LLL
corpus already preprocessed LinkParser output checked
experts. enable comparison previous work, used AImed corpus parsed

20

fiUsing Local Alignments Relation Recognition

Stanford parser 3 Enju parser 4 (which exactly correspond input
experiments Erkan et al., 2007 Stre et al., 2008). Unlike Stanford parser,
Enju based Head-driven Phrase Structure Grammar (HPSG). output
Enju parser presented two ways, either predicate argument structure
phrase structure tree. Predicate argument structures describe relations words
sentence, phrase structure presents sentence structure form clauses
phrases. addition, Enju trained GENIA corpus includes model
parsing biomedical texts.
(24) Cbf3 contains three proteins, Cbf3a, Cbf3b Cbf3c.

contains

dobj

nsubj

proteins

Cbf3

num

conj

conj conj

three

Cbf3a
nsubj

Cbf3b
dobj

Cbf3 contains proteins
nsubj
dobj
Cbf3 contains proteins
nsubj
dobj
Cbf3 contains proteins

Cbf3b

conj

Cbf3a
Cbf3b
conj
Cbf3c
conj

Figure 1: Stanford parser output representation Example (24).
Figure 1 shows dependency tree obtained Stanford parser sentence
(24). sentence mentions three interactions among proteins, precisely,
Cbf3 Cbf3a, Cbf3 Cbf3b, Cbf3 Cbf3c. three dependency
paths contain words (lemmata) syntactic functions (such subj subject) plus
direction traversing tree. Figure 2 presents output sentence provided
Enju parser. upper part refers phrase structure tree lower part
shows paths extracted predicate argument structure. two parsers clearly
differ output. First, Stanford parser conveniently generates paths
three interaction pairs Enju analyzer not. Second, output
Stanford parser excludes prepositions conjunctions attached syntactic
functions whereas Enju analyzer lists parsing results. differences
3. Available http://nlp.stanford.edu/software/lex-parser.shtml.
4. Available http://www-tsujii.is.s.u-tokyo.ac.jp/enju/.

21

fiKatrenko, Adriaans, & van Someren

lead different input sequences later fed LA kernel. Consequently,
variations input may translate differences final performance.

Cbf3
Cbf3
Cbf3

ARG1/verb



ARG1/verb



ARG1/verb



contain
contain
contain

ARG2/verb



ARG2/verb



ARG2/verb



protein
protein
protein

ARG1/app



ARG1/app



ARG1/app



,
,
,

ARG2/app



ARG2/app



ARG2/app



Cbf3a
Cbf3a
Cbf3a

ARG1/coord



ARG1/coord



,

ARG2/coord





Cbf3b

ARG2/coord



Cbf3c

Figure 2: Enjus output representation Example (24).
addition, work employing AImed, dependency paths
Figure 1 Figure 2 preprocessed following way. actual named entities
arguments relation replaced label, e.g. PROTEIN. Consequently,
nsubj

dobj

conj

first path Figure 1 becomes PROTEIN contains proteins PROTEIN.
able compare results AImed performance reported work
Erkan et al. (2007) Stre et al. (2008), use exactly dependency paths
argument labels. However, study whether using labels instead actual named entities
impact final results LLL data set, carry two experiments.
first one, dependency paths contain named entities, whereas second contain
labels. second experiment referred adding word LABEL name (as
LLL-all-LABEL Table 7).
4.1.2 Generic Relations
second type relations consider generic relations. arguments
sometimes annotated using external resources WordNet, makes possible
use semantic relatedness measures defined them. example approach

22

fiUsing Local Alignments Relation Recognition

data used SemEval-2007 challenge, Task 04: Classification Semantic Relations
Nominals (Girju et al., 2009).
goal Task 4 classify seven semantic relations (Cause - Effect, Instrument - Agency, Product - Producer, Origin - Entity, Theme - Tool, Part Whole Content - Container), whose examples collected Web using
predefined queries. words, given set examples relation, expected output would binary classification whether example belongs given
relation not. arguments relation annotated synsets WordNet
hierarchy, Figure 3. Given sentence pair (spiritual awareness, joy)
corresponding synsets joy%1:12:00 awareness%1:09:00, would mean classifier decide whether pair example Cause-Effect relation.
particular sentence retrieved quering Web phrase joy comes *.
synsets manually selected WordNet hierarchy. seven semantic
relations used challenge, gives seven binary classification problems.

Genuine <e1>joy</e1> comes <e2>spiritual awareness</e2> life absolute clarity direction, living purpose.
WordNet(e1) = joy%1:12:00, WordNet(e2) = awareness%1:09:00,
Query: joy comes *, Cause-Effect(e2, e1) = true

Figure 3: annotated example Cause - Effect SemEval-2007, Task 4
training data set.

relation type
Origin - Entity
Product - Producer
Theme - Tool
Instrument - Agency
Part - Whole
Content - Container
Cause - Effect

#examples (train)
140
140
140
140
140
140
140

#pos (train)
54
85
58
71
65
65
73

#examples (test)
81
93
71
78
72
74
80

direction
asymmetric
asymmetric
asymmetric
asymmetric
asymmetric
asymmetric
asymmetric

Table 4: Distribution SemEval-2007, Task 4 examples (training test data),
#pos stands number positive examples per data set #examples
indicates number examples total.

Syntactic analysis generate dependency paths, seven data sets used SemEval 2007, Task 4, analyzed Stanford parser. dependency path sentence
Figure 3 given (25).
23

fiKatrenko, Adriaans, & van Someren

(25) awareness#n#1

prep f rom



nsubj

come joy#n#1

Here, words annotated WordNet PoS tag attached, followed sense.
instance, awareness noun current context first sense used,
corresponds awareness#n#1.
4.2 Substitution Matrix
build substitution matrix LA kernel, use either distributional similarity
WordNet semantic relatedness measures. data set dependency paths,
contains unique elements (words syntactic functions), size matrix t.
k elements words, number substitution scores computed
distributional similarity (or semantic relatedness) measures equals k(k + 1)/2. due
fact measures use symmetric. substitution matrix built
corpus used experiments, results three substitution matrices
biomedical domain (for BC-PPI, LLL, AImed) seven substitution matrices
generic relations. follows, discuss settings used calculating
substitution matrix detail.
Distributional similarity estimated either using contextual information (O
Seaghdha & Copestake, 2008), exploring grammatical relations words (Lee,
1999). work opt contextual information. motivated presence
words belonging different parts speech dependency paths. instance,
even though, according dependency grammar theory (Melcuk, 1988), adjectives
govern words, may still occur dependency paths. words, even
parsing fail, may produce unreliable syntactic structures. able compare
words part speech, decided estimate distributional similarity based
contextual information, rather grammatical relations.
computing distributional similarity, may happen given word xi
occur corpus. handle cases, always set d(xi , xi ) = 1 (the largest possible
similarity score), d(xi , x0j ) = 0 xi 6= x0j (the lowest possible similarity score).
4.2.1 Biomedical domain
estimate distributional similarity biomedical domain, use TREC 2006
Genomics collection (Hersch, Cohen, Roberts, & Rakapalli, 2006) contains 162,259
documents 49 journals. documents preprocessed removing HTMLtags, citations text reference sections stemmed Porter stemmer (van
Rijsbergen, Robertson, & Porter, 1980). Furthermore, query-likelihood approach
Dirichlet smoothing (Chen & Goodman, 1996) used retrieve document passages given
query. passages ranked according likelihood generating query. Dirichlet smoothing used avoid zero probabilities poor probability estimates (which may
happen words occur documents). k unique words occurring set
dependency paths sequences fed queries collect corpus estimating similarity.
Immediate context surrounding pair words used calculate distributional
similarity words. set context window 2 (2 tokens right 2

24

fiUsing Local Alignments Relation Recognition

tokens left word focus) perform kind preprocessing
PoS tagging.
4.2.2 Generic relations
generic relations, use WordNet relatedness measures described Section 3.2.2.
already shown WordNet relatedness measures work synsets,
assumes words manually annotated information WordNet.
Since done relations arguments (see example Figure 3),
words sentences (and, correspondingly, dependency paths), build
substitution matrix follows. two words annotated WordNet, substitution score equals value returned relatedness measure used. word
pair, equals 1 whenever words identical, 0 otherwise. 5 example,
consider words dependency path (25) Wu-Palmer (wup) relatedness
measure, substitution scores obtain follows:

d(awareness#n#1, awareness#n#1) = 1
d(awareness#n#1, come) = 0
d(awareness#n#1, joy#n#1) = 0.35
d(prep from, come) = 0
d(prep from, joy#n#1) = 0
d(come, nsubj) = 0
d(nsubj, nsubj) = 1
d(joy#n#1, joy#n#1) = 1

d(awareness#n#1, prep from) = 0
d(awareness#n#1, nsubj) = 0
d(prep from, prep from) = 1
d(prep from, nsubj) = 0
d(come, come) = 1
d(come, joy#n#1) = 0
d(nsubj, joy#n#1) = 0

Figure 4: substitution scores dependency path (25) using wup measure.
Syntactic relations (prep from, subj) accompanied direction
dependency tree traversal (either ).

dependency path (25), 5 unique elements (t), 2 annotated
WordNet synsets (k). Consequently, 5*6/2 = 15 substitution scores total,
3 computed using WordNet relatedness.
compute WordNet relatedness, use WordNet::Similarity package WordNet 3.0 (Pedersen, Patwardhan, & Michelizzi, 2004).
4.3 Baselines Kernel Settings
section, discuss two baselines kernel settings.
4.3.1 Baselines
test well local alignment kernels perform compared kernels proposed past,
implemented shortest path kernel described work Bunescu Mooney
5. also applies cases relation arguments could annotated WordNet
information.

25

fiKatrenko, Adriaans, & van Someren

(2005a) (Section 2.3.5) one baselines (Baseline I). method seems
natural choice operates data structures (dependency paths).
Similarly Bunescu Mooneys (2005a) work, experiments use lemma, part
speech tag direction, consider entity type negative polarity items.
choice LA kernel paper motivated ability
compare sequences flexible way, also possibility explore additional
information (not present training set) via substitution matrix. baseline,
Baseline II, used test whether choice similarity measures affects results.
case, substitution scores d(, ) calculated using distributional similarity
WordNet relatedness, generated randomly within interval [0, 1].
4.3.2 Kernel settings
kernels compute used together support vector machine tool LibSVM
(Chang & Lin, 2001) detect hyperplanes separating positive examples negative
ones. plugging kernel matrices 10-fold cross-validation LibSVM,
normalized Equation 26.

0

0

k(x, y)

k(x , ) = p

k(x, x)k(y, y)

(26)

handle imbalanced data sets (most notably AImed BC-PPI), examples
weighted using inverse-class probability (i.e. training examples class weighted
1/prob(A) prob(A) fraction training examples class A). significance
tests done using two-tailed paired t-test confidence level 95% ( = 0.05).
addition, experiments tuned penalty parameter C (Equation 4)
range (26 , 24 , . . . , 212 ).
use LA kernel, one set following parameters: gap opening cost,
gap extension cost, scaling parameter . cross-validation experiments,
gap opening cost set 1.2, extension cost 0.2 scaling parameter
1. choice scaling value motivated experiments amino acids
biological domain (Saigo et al., 2004). initial experiments, present
study parameter values varied.

5. Experiment I: Domain-Specific Relations
goal evaluation study behavior LA kernel domain-specific
relations biomedical domain. section, report experiments conducted
three biomedical corpora using LA kernel based distributional similarity measures, two baselines results published previously (e.g., using graph kernel Airola
et al., 2008 tree kernel Stre et al., 2008). best knowledge, string
kernels applied dependency paths yet. However, gap-weighted string
kernel (described Section 2) also allows gapping thus compared LA
kernel. test Lodhi et al.s (2002) kernel performs dependency paths, use

26

fiUsing Local Alignments Relation Recognition

three corpora. tuned parameters string kernel set length
subsequences 4 decay factor 0.5. 6
5.1 LLL BC-PPI Data Sets
subsection presents results two biomedical data sets, BC-PPI LLL. Whenever
possible, also discuss performance previously reported literature.
10-fold cross-validation results BC-PPI corpus presented Table 5
LLL training data set Table 6. LA kernel based distributional similarity
measures (LA-Dice, LA-Cosine LA-L2) performs significantly better two baselines. Recall Baseline corresponds shortest path approach (Section 2.3.5)
Baseline II LA kernel randomly generated substitution scores. contrast
Baseline I, able handle sequences different lengths including gaps. According
Equation 5, comparison two sequences different lengths results 0-score.
Nevertheless, still yields high recall, precision much lower. explained
fact shortest path uses PoS tags. Even though two sequences
length different, comparison may still result non-zero score, provided
part speech tags match. Furthermore, Baseline II suggests accurate estimation substitution scores important achieving good performance. Baseline II may
yield better results Baseline I, randomly generated substitution scores degrade
performance.
Method
LA-Dice
LA-Cosine
LA-L2
Baseline
Baseline II
Gap-weighted string kernel (Lodhi et al., 2002)

Precision
75.56
76.40
77.56
32.04
66.36
72.00

Recall
79.72
80.66
79.31
75.63
54.48
75.31

F-score
77.56
78.13
78.42
45.00
59.80
73.62

Table 5: 10-fold cross-validation BC-PPI data set.
first glance, choice distributional similarity measures affect
overall performance yielded LA kernel. BC-PPI data, method based
L2 measure outperforms methods based Dice (p.07) Cosine,
differences latter case significant. statistically significant differences
observed method based Dice Cosine.
contrast BC-PPI data set, kernels use Dice Cosine measures
LLL data set significantly outperform one based L2 (at p1.22107
p1.33106 , respectively).
data sets, LA method using distributional similarity measures significantly
outperforms baselines. Interestingly, gap-weighted string kernel Lodhi et al.
(2002) yields good performance seems better choice subsequence
6. Lodhi et al. (2002) mentioned paper F1 numbers (with respect SSK) seem
peak subsequence length 4 7.

27

fiKatrenko, Adriaans, & van Someren

kernel based shallow linguistic information (Giuliano et al., 2006). Recent work
LLL (Fundel, Kueffner, & Zimmer, 2007) employs dependency information but, contrast
method, serves representation extraction rules defined. Airola
et al. (2008) apply graph kernel-based approach extract interactions use, among
others, LLL AImed data sets. seen Table 6, method yields results
comparable gap-weighted string kernel dependency paths.
best knowledge, performance achieved LA kernel LLL training set
highest (in terms F-score) among results reported
literature.
Method
LA-Dice
LA-Cosine
LA-L2
Baseline
Baseline II
Graph kernel (Airola et al., 2008)
Gap-weighted string kernel (Lodhi et al., 2002)
Shallow linguistic kernel (Giuliano et al., 2006)
Rule-based method (Fundel et al., 2007)

Precision
88.76
88.63
86.80
39.02
65.82
72.5
83.66
62.10
68

Recall
81.62
82.09
75.04
100.00
41.32
87.2
71.11
61.30
83

F-score
85.03
85.23
80.49
56.13
50.76
76.8
76.88
61.70
75

Table 6: 10-fold cross-validation LLL-all training data set.
also apply method LLL test data (Table 7). 7 Even though performance test set poorer, LA-Dice outperforms baselines. addition,
gap-weighted string kernel (Lodhi et al., 2002) seems perform much worse test
set. LA kernel, precision high, recall decreases (and drastically
data subset includes co-references). might due fact
sentences incomplete parses generated and, consequently, dependency paths
entities found. 91 567 possible interaction pairs generated
test data, dependency path extracted. contrast, approach reported
Giuliano et al. (2006) make use syntactic information, data subset
without coreferences achieves higher recall.
hand, lower recall also caused using actual names proteins
genes arguments. work reported before, relation arguments
named entities often replaced types (e.g., PROTEIN) used
input learning algorithm. conducted additional experiments using named entity
types dependency paths, led great improvement terms recall
F-score (Table 7, LLL-coref-LABEL, LLL-nocoref-LABEL, LLL-coref-LABEL). method
clearly outperforms shallow linguistic kernel also achieves better results
best-performing system LLL competition (Sbest ), which, according Nedellec (2005),
applied Markov logic syntactic paths.
7. Airola et al. (2008) report performance LLL data set and, reason, information
graph all-paths kernel included Table 7.

28

fiUsing Local Alignments Relation Recognition

Data set
LLL-coref
LLL-nocoref
LLL-all
LLL-all
LLL-all
LLL-coref-LABEL
LLL-nocoref-LABEL
LLL-all-LABEL
LLL-coref
LLL-nocoref
LLL-all
LLL-all
LLL-all

Method
LA-Dice
LA-Dice
LA-Dice
Baseline
Baseline II
LA-Dice
LA-Dice
LA-Dice
Shallow linguistic kernel (Giuliano
Shallow linguistic kernel (Giuliano
Shallow linguistic kernel (Giuliano
Gap-weighted string kernel (Lodhi
Sbest (Nedellec, 2005)

et
et
et
et

al.,
al.,
al.,
al.,

2006)
2006)
2006)
2002)

Precision
52.3
70.7
72.7
48.6
12.9
60.0
69.0
74.5
29.0
54.8
56.0
56.0
60.9

Recall
37.9
53.7
48.1
43.3
45.7
51.7
53.7
53.0
31.0
62.9
61.4
16.8
46.2

F-score
44.0
61.0
57.9
45.8
20.1
55.5
60.4
61.9
30.0
58.6
58.6
25.9
52.6

Table 7: Results LLL test data set.

5.2 AImed Data Set
Yet another data set consider AImed. data set often used
experiments relation extraction biomedical domain, enables comparison
methods. noted, however, particular case, corpus
collection documents (abstracts). may lead two ways performing 10-fold
cross-validation. One possibility lies randomly splitting data 10 parts,
cross-validation level documents. experiments report
done using first setting directly compared methods described
work Stre et al. (2008), Erkan et al. (2007) Giuliano et al. (2006). addition,
use dependency paths LA kernel ones employed Stre et al.
Erkan et al.. results Airola et al. (2008) Bunescu (2007) obtained
cross-validating level documents.
conducted experiments setting distributional measure Dice, referred
LA-Dice Table 8. upper part table used dependency paths generated
Stanford parser lower part obtained Enju. discussed
Section 2, Erkan et al. (2007) use similarity measures compare dependency paths,
consider additional sources whose information incorporated
learning procedure. They, however, experiment supervised (SVM) semi-supervised
learning (TSVM), number training instances varied. Table 8 shows best
performance achieved Erkan et al.s (2007) method. Among models based
SVM, one Cosine distance, SVM-Cos, yields best results. TSVM
setting, one Edit measure performs best. observe LA-Dice slightly
outperforms has, particular, high precision.
work, Stre et al. (2008) explore several parsers combinations features.
features include paths Enju, also word dependencies generated
data-driven KSDEP parser, word features. KSDEP parser based probabilistic

29

fiKatrenko, Adriaans, & van Someren

shift-reduce algorithm (Sagae & Tsujii, 2007). general, method Stre et al. also
uses SVM, case focuses tree kernels (discussed Section 2.3.3). make
fair comparison, conducted experiments paths obtained deep syntactic analysis
(Enju parser) compared scores Stre et al.s (2008) results. contrast
previous experiments, achieve higher recall lower precision. Overall, LA
kernel yields better performance one reported Stre et al. However,
different sets features combined (parses Enju KSDEP plus word features Enju+KSDEP+W Table 8), overall performance improved.
Method
LA-Dice
Baseline (Bunescu, 2007)
Baseline II
SVM-Cos (Erkan et al., 2007)
TSVM-Edit (Erkan et al., 2007)
Gap-weighted string kernel (Lodhi et al., 2002)
LA-Dice
Tree kernel (Stre et al., 2008)
Tree kernel (Stre et al., 2008)
Graph kernel (Airola et al., 2008)
Shallow linguistic kernel (Giuliano et al., 2006)

Parser
Stanford
Collins
Stanford
Stanford
Stanford
Stanford
Enju
Enju
Enju+KSDEP+W
Charniak-Lease
none

Precision
69.09
69.08
48.89
61.99
59.59
67.25
71.16
76.0
78.1
52.9
60.9

Recall
54.63
35.00
25.06
54.99
60.68
54.67
46.71
39.7
62.7
61.8
57.2

F-score
61.02
46.46
33.07
58.09
59.96
60.31
56.40
52.0
69.5
56.4
59.0

Table 8: 10-fold cross-validation AImed data set.
Bunescu (2007) reports evaluation results AImed corpus form
precision-recall curve. consider highest precision obtained experiments (69.09 71.16, depending input), roughly corresponds recall
35% plot (referred Baseline Table 8). sum, shortest path approach
never approaches performance LA kernel biomedical data sets
studied here. baseline, Baseline II, achieves lowest scores
methods presented here.
Table 8 illustrates various methods trained AImed corpus,
also many different parsers used. noted graph kernel
trained tested syntactic representation generated Charniak-Lease
parser, shortest path kernel explored dependency paths obtained
Collins parser. Charniak-Lease parser statistical parser trained biomedical
data (Lease & Charniak, 2005), whose phrase structures transformed dependencies. Likewise, Collins parser statistical parser (Collins, 1999). leads
question whether choice syntactic parser significant impact extraction
results. compare impact syntactic parsers relation extraction AImed,
Miyao et al. (2008) conducted complex study eight parsers (including Stanford analyzer) five parse representations 8 . consider two cases. first one,
parsers trained biomedical data. Regardless parser used
experiments, accuracy extraction task similar. second experiment,
8. either various dependency tree formats (e. g., Stanford dependency format), phrase
structures, predicate-arguments structures.

30

fiUsing Local Alignments Relation Recognition

parsers re-trained domain-specific data. case, shown
relation extraction results improved. actual gain, however, vary
one parser another.
AImed data, LA kernel Dice measure gives state-of-the-art results.
outperformed approaches use information dependency
paths.
5.3 LA Kernel Parameters
Saigo et al. (2004) already shown scaling parameter (Equation 11)
significant impact accuracy. also carried additional experiments varying
gap values value . Results visualized Figure 5. opening extension
gap values separated slash symbol values X-axis form a/b
read opening gap set extension gap equal b.
kernel matrices normalized examples weighted. According previous
experiments, results yielded Dice measure significantly differ
ones achieved Cosine measure selected Dice measure conduct
experiments. performance BC-PPI data set shown Figure 5.

F-score
76
74
72
70
68
66
64
62
60
58

76
74
72
70
68
66
64
62
60
58

12/2
12/12
gaps

24/2
24/12

0.1

0.3

0.5

0.8

1

5

scaling

Figure 5: Varying gaps scaling () parameter BC-PPI data set (10-fold
cross-validation): F-score.

31

fiKatrenko, Adriaans, & van Someren

80
79
78
77
76
75
74
73
72
71
70

Precision
90
85
80
75
70
65

5

60

1

12/2

0.8
12/12
gaps

scaling

0.5

24/2

0.3
24/12

0.1

Figure 6: Varying gaps scaling () parameter BC-PPI data set (10-fold
cross-validation): Precision.

75
70

Recall

65

90

60

80

55

70

50

60

45

50

5

40

1

12/2

0.8
12/12
gaps

0.5

24/2

scaling

0.3
24/12

0.1

Figure 7: Varying gaps scaling () parameter BC-PPI data set (10-fold
cross-validation): Recall.
32

fiUsing Local Alignments Relation Recognition

results Figure 5 indicate decreasing leads decrease overall performance. Moreover, varying gap values causes subtle changes F-score,
changes drastic changes due lower .
Changes F-score likely explained variances precision
recall. investigate matter, look measures depend parameter
changes. set low value, one expect nearly diminish impact
substitution matrix, i.e. similarity among elements. reason hypothesize
larger values scaling parameter result higher recall. Indeed, Figure 7
supports hypothesis recall plot resembles one F-score. Varying
parameter values much lower impact precision (Figure 6) nonetheless precision
decrease parameter becomes larger.
Overall, seems influence final results most, although gap values make
contribution well. According results obtained, setting extension gap e
large value (or equal opening gap o) undesirable. Since scaling parameter
applied substitution matrix gap values well, setting
0.5 decreases effects gap penalization similarity elements. Consequently,
best performance achieved setting 1. suggests final performance
LA kernel influenced combination parameters choice crucial
obtaining good performance.

6. Experiment II: Generic Relations
Another series experiments carried seven generic relations SemEval
- 2007 challenge, Task 4. choice data sets case motivated two
factors. First, semantic relations used differ relations biomedical
domain. Second, since arguments relations annotated WordNet, becomes
possible explore information WordNet use prior knowledge LA
kernel.
Many participants challenge considered WordNet either explicitly (Tribble &
Fahlman, 2007; Kim & Baldwin, 2007), part complex system (Giuliano et al.,
2007). Since always obvious use WordNet yields best performance, many researchers made additional decisions use supersenses (Hendrickx et al., 2007), selection predefined number high-level concepts (Nulty, 2007),
cutting WordNet hierarchy certain level (Bedmar et al., 2007). systems
one Nakov (2007) based solely information collected Web.
Even though became evident best performing systems used WordNet, variance results remarkable clear whether difference performance
explained machine learning methods used, combination features,
factors.
SemEval-2007 Task-4 data set includes relation examples nominal
compounds (like coffee maker), greatly reduces availability information
two arguments dependency paths. relation arguments case linked
one grammatical relation (e.g., coffee maker linked grammatical relation
nn, corresponds noun compound). assume, therefore, information coming
WordNet especially helpful dependency paths short.

33

fiKatrenko, Adriaans, & van Someren

experiments used 5 relatedness measures defined earlier Section 3.2 plus one additional
measure called random. random measure indicates relatedness values
two relation arguments generated randomly (within [0, 1]) thus
suitable baseline (Baseline II). Similarly experiments biomedical domain,
another baseline shortest path kernel (Baseline I). Note Task 4 overview
paper, Girju et al. (2007) reported three baselines, which, case, (i) guessing
true false examples, depending class majority class test
set (Baseline III), (ii) always guessing true (Baseline IV), (iii) guessing true false
probability corresponds class distribution test set (Baseline V).
first question interest implications choice semantic relatedness
measure performance LA kernel. answer question, perform
10-fold cross-validation training set (Figure 9, Figure 10 Figure 11). Among
5 measures jcn resnik fail perform better random score.
cases, Resnik score outperformed measures. behaviour LeacockChodorow score (lch) jcn varies one semantic relation another. instance, use
jcn seems boost precision Cause-Effect, Part-Whole, Product - Producer,
Theme - Tool. remaining three relations clearly best-performing
measure.
check whether differences relatedness measures, carried
significance tests comparing measures relations. findings summarized
Table 9. Here, symbol two relatedness measures stands measure
equivalence, or, words, indicates significant difference. Similarly
experiments biomedical field, significance tests conducted using
two-tailed paired t-test confidence level 95%. addition, two measures
b, > b means performs significantly better b. instance, ranking
Cause - Effect Table 9 read follows. two best performing measures
wup lch, significantly outperform lin, followed random res, which,
turn, yield significantly better results jcn. seen table wup
lch clearly best performing measures seven relations (each best
measure six seven relations).
Relation type
Cause - Effect
Instrument - Agency
Product - Producer
Origin - Entity
Theme - Tool
Part - Whole
Content - Container

Ranking
wup lch > lin
wup lch > lin
wup lch > lin
wup lch > lin
lch > lin wup
wup lin lch
wup > lch > lin

>
>

>
>
>


res random > jcn
res > jcn random
jcn res > random
res jcn > random
res > jcn > random
res > jcn random
res > jcn random

Table 9: Ranking relatedness measures respect accuracy training sets ( stands measure equivalence, > b indicates measure
significantly outperforms b).

34

fiUsing Local Alignments Relation Recognition

relation, applied best performing measure training set
particular relation test data. results reported Table 10. average, LA
kernel employing WordNet relatedness measures significantly outperforms two baselines.
Moreover, compared best results SemEval-2007 competition (Beamer
et al., 2007), method approaches performance yielded best system (bestSV ).
system used various lexical, syntactic, semantic feature sets, also
expanded training set adding examples many different sources. already
mentioned Section 2 recent work Seaghdha (2009) explores WordNet
structure graph kernels classify semantic relations. overall performance
achieved method (Table 10) comparable one LA kernel,
unclear whether semantic relations one approaches performs
better.
Relation type
Cause - Effect
Instrument - Agency
Product - Producer
Origin - Entity
Theme - Tool
Part - Whole
Content - Container
Average
Baseline
Baseline II
Baseline III
Baseline IV
Baseline V
bestSV
Gap-weighted string kernel (Lodhi et al., 2002)
WordNet kernels (O Seaghdha, 2009)

Accuracy
61.25
75.64
75.27
74.07
73.24
80.56
71.62
73.09
58.23
55.83
57.0
48.5
48.5
76.3
61.19
74.1

Precision
62.50
73.17
76.71
75.86
67.86
70.00
74.29
71.48
52.50
61.61
81.3
48.5
48.5
79.7
66.2
-

Recall
60.98
78.95
90.32
61.11
65.52
80.77
68.42
72.30
54.30
55.50
42.9
100.0
57.1
69.8
47.52
-

F-score
61.73
75.95
82.96
67.69
66.67
75.00
71.23
71.60
49.19
53.93
30.8
64.8
48.5
72.4
43.02
71.0

measure
lch
wup
lch
wup
lch
wup
wup

Table 10: Results SemEval-2007, Task 4 test data set (selecting best performing
measure training set relation).

addition, report results SemEval Task 4 test set per relatedness measure
(Table 11), averages seven relations. Similarly findings
training set, wup lch best performing measures test data well.
One would expect optimal use prior knowledge allow us reduce
number training instances without significant changes performance. study
(and whether) amount training data influences results test set, split
training set several subsets, creating model subset applying
SemEval-2007, Task 4 test data. split corresponds split used challenge
organizers. Figure 8 9 suggests, relations recognized well even relatively
small data sample used. exception Theme-Tool relation increasing
9. model trained 35 Origin-Entity examples classifies none test examples positive,
reason point Figure 8 relation given 35 training examples.

35

fiKatrenko, Adriaans, & van Someren

training data clearly helps. finding line results Giuliano et al. (2007)
whose system combination kernels data. results also indicate
relations one (Theme-Tool) extracted well, even quarter
training set used.
Relatedness measure
wup
lch
lin
res
jcn
random

Accuracy
72.91
72.96
65.27
62.94
55.55
56.57

Precision
71.20
72.31
62.01
62.51
52.25
53.10

Recall
72.56
70.93
67.07
59.66
69.28
52.94

F-score
71.62
71.02
63.65
60.46
57.07
52.83

Table 11: Results SemEval-2007, Task 4 test data set, averages 7 relations
per WordNet relatedness measure.

Learning curve
100
90
80
70

F-score

60
50
Cause-Effect
Instrument-Agency
Product-Producer
Origin-Entity
Theme-Tool
Part-Whole
Content-Container

40
30
20
10
0

35

70
105
training examples

140

Figure 8: Learning curve SemEval-2007, Task 4 test data set.
recent work SemEval Task 4 data set includes investigation distributional kernels (O Seaghdha & Copestake, 2008), pattern clusters (Davidov & Rappoport,
2008), relational similarity (Nakov & Hearst, 2008), WordNet kernels. Unlike WordNet
kernels, first three approaches use WordNet. Seaghdha Copestake (2008)
report accuracy 70.7 F-score 67.5 best results yielded distributional kernels best performance Davidov Rappoports (2008) method
accuracy 70.1, F-score 70.6. WordNet kernels, similarly findings
LA kernel, yield better accuracy methods using WordNet (74.1),

36

fiUsing Local Alignments Relation Recognition

Cause-Effect
100

precision
recall
F-score

90
80
70
60
50
40
30
20
10
0

wup

lin

lch
res
similarity measure

jcn

random

Instrument-Agency
100

precision
recall
F-score

90
80
70
60
50
40
30
20
10
0

wup

lin

lch
res
similarity measure

jcn

random

Product-Producer
100

precision
recall
F-score

90
80
70
60
50
40
30
20
10
0

wup

lin

lch
res
similarity measure

jcn

random

Figure 9: 10-fold cross-validation training set (Cause - Effect, Instrument Agency Product - Producer relations).

37

fiKatrenko, Adriaans, & van Someren

Origin-Entity
100

precision
recall
F-score

90
80
70
60
50
40
30
20
10
0

wup

lin

lch
res
similarity measure

jcn

random

Theme-Tool
100

precision
recall
F-score

90
80
70
60
50
40
30
20
10
0

wup

lin

lch
res
similarity measure

jcn

random

Part-Whole
100

precision
recall
F-score

90
80
70
60
50
40
30
20
10
0

wup

lin

lch
res
similarity measure

jcn

random

Figure 10: 10-fold cross-validation training set (Origin - Entity, Theme - Tool
Part - Whole relations).

38

fiUsing Local Alignments Relation Recognition

Content-Container
100

precision
recall
F-score

90
80
70
60
50
40
30
20
10
0

wup

lin

lch
res
similarity measure

jcn

random

Figure 11: 10-fold cross-validation training set (Content - Container relation).

F-score comparable performance reported Seaghdha Copestake (2008)
Davidov Rappoport (2008).

7. Discussion
section revisit goals stated end Section 2 discuss
findings detail.
7.1 LA Kernel Relation Extraction
introduced LA kernel, proven effective biomedical problems,
NLP domain showed well suited relation extraction. particular, experiments two different domains either outperform existing methods yield
performance par existing state-of-the-art kernels.
One motivations using LA kernel relation extraction task
exploit prior knowledge. Here, explore two possibilities, distributional similarity
information provided WordNet.
7.1.1 Distributional Similarity Measures
setting, consider three distributional measures already studied
before. instance, Lee (1999) uses detect similar nouns based verb-object
co-occurrence pairs. results suggest Jaccard coefficient (which related
Dice measure) one best performing measures followed others including
Cosine. Euclidean distance fell group largest error rates. Given previous
work Lee (1999), one would expect Euclidean distance achieve worse results
39

fiKatrenko, Adriaans, & van Someren

two measures. Indeed, LLL corpus, LA kernel employing L2 shows
significant decrease performance. measures, method using Dice
significantly outperforms one based L2 measure LLL corpus
significant improvement BC-PPI data set. Based experiments
conducted, conclude LA kernel using Dice Cosine measures performs
similarly LLL data set BC-PPI corpus. Given results various biomedical corpora (and different settings experimented with), obtained experimental
support choosing Dice Cosine measure Euclidean distance.
7.1.2 WordNet Similarity Measures
generic relations, semantic relatedness plays significant role. difference
F-score models use semantic relatedness kernel relatedness
values generated randomly (Baseline II) amounts nearly 20%. measures exhibit
different performance seven generic relations considered.
observe, instance, wup, lch, lin almost always yield best results, matter
relation considered. found Resnik score Jiang Conraths measure
yield lower results measures. Even though F-scores per relation vary
quite substantially (by placing Cause-Effect, Theme-Tool, Origin-Entity among
difficult relations extract), two measures, wup lch, top-performing
measures seven relations. two measures explore WordNet taxonomy using
length paths two concepts, depth WordNet hierarchy and,
consequently, belong path-based measures. three measures, res, lin
jcn information content based measures, relatedness two concepts
defined amount information share. experiments LA
kernel generic relation recognition suggest that, particular case, path-based
measures preferred information content based measures.
stress, however, evaluation semantic relatedness measures context relation recognition, one means draw conclusion
top measures NLP tasks stay same. example, Budanitsky
Hirst (2006) use semantic relatedness measures detect malapropism show
Jiang Conraths measure (jcn) yields best results, followed Lins measure (lin),
one Leacock Chodorow (lch), Resniks measure (res).
results quite similar findings consider res measure, jcn
top accuracy ranking list seven semantic relations
studied.
7.2 Factors Parameters Influence LA Kernel Performance
experiments two domains shown LA kernel either outperforms existing
methods corpora, yields performance par existing state-of-the-art
kernels.
7.2.1 Baselines
advantage LA kernel Bunescu shortest path method (Baseline I)
capable handling paths different lengths. allowing gaps penalizing them,
40

fiUsing Local Alignments Relation Recognition

final kernel matrix becomes less sparse. shortest path approach also attempts
generalize dependency paths, usually overgeneralizes leads high
recall scores (Table 5 Table 6) poor overall performance. One explanation
overgeneralization may method accounts well structural similarity (provided
sequences length) fails provide finer distinctions among dependency
paths. Consider, example, two sequences trip makes tram coffee makes
guy, whereby first path represents negative instance Product-Producer
relation second path corresponds positive one. Even though match
exactly, elements match nouns singular. Consequently, comparison
according shortest path method result relatively high similarity score.
contrast, LA kernel consider similarity elements pairs trip-coffee
tram-guy obtain low scores.
addition, Baseline II, based randomly generated substitution scores,
performs poor data sets (or comparable Baseline I). leads us conclusion
accurate estimation similarities another reason LA kernel performs well
relation extraction.
7.2.2 Comparison Methods
already pointed out, obvious shortcoming Baseline inability
handle dependency paths different length. reason, also applied
gap-weighted string kernel (Lodhi et al., 2002) data sets. case, dependency
paths compared flexible way gapping allowed, additional
information used. kernel outperforms Baseline increasing precision relation
extraction preserving relatively high recall. data set fails yield
good results LLL test data, believe due differences LLL
training test data. data sets, LA kernel achieves better performance
gap-weighted string kernel. margin, however, different different data sets.
biomedical domain, differences two methods clearly seen
BC-PPI LLL data sets, results AImed corpus comparable.
However, methods tested AImed get higher scores unless use
features dependency paths. holds types cross-validation used
corpus. generic relations, difference LA kernel gapweighted string kernel much larger. particular, case gap-weighted kernel,
precision high, recall much lower. explained fact generic
relations benefit knowledge found WordNet recall achieved LA kernel
is, therefore, high. gap-weighted kernel access information found
dependency paths and, reason, fails find relations.
LA kernel also achieves best performance LLL training set, outperforming
graph kernel (Airola et al., 2008), shallow linguistic kernel (Giuliano et al., 2006)
rule-based system Fundel et al. (2007). three used different input
methods, varying plain text dependency structures. reason, direct
comparison unfortunately possible, conclude methods employing
dependency information always among best performing approaches.

41

fiKatrenko, Adriaans, & van Someren

Two approaches whose performance reported AImed data set include tree kernel (Stre et al., 2008) TSVM (Erkan et al., 2007).
explore syntactic information different ways. Stre et al. consider subtrees,
method Erkan et al. similarities approach relies
dependency path comparison. comparison, use information already
available dependency paths (SVM setting), dependency paths (TSVM setting). According Lauer Bloch (2008), TSVMs fall category using prior
knowledge sampling methods, explores prior knowledge generating new
examples. contrast, employ information large unlabeled text sources order
enable finer comparison dependency paths always work supervised learning
setting. Using evaluation procedure work Stre et al. Erkan et al.
show LA kernel outperforms methods, differences data set
much smaller data sets used.
7.2.3 LA Parameters
demonstrated choice LA parameters crucial achieving good performance. experiments, scaling parameter contributes overall performance
most, parameters gap values taken account well.
approaches infinity, LA kernel approximates Smith-Waterman distance,
increasing necessarily positive impact final performance.
finding line results reported Saigo et al. (2004) homology detection
task. best performance yielded setting scaling parameter 1 bit higher,
penalizing gap extension less gap opening.

8. Conclusions Future Work
presented novel approach relation extraction based local alignments sequences. Using LA kernel provides us opportunity explore various
sources information study role relation recognition. Possible future directions include, therefore, examination distributional similarity measures, studying
impact extraction generic relations, looking sources information could helpful relation recognition. may interesting consider
relational similarity (Turney, 2006), looks correspondence relation
instances. case, one able infer doctor corresponds scalpel
similar way fisherman net (where (scalpel, doctor) (net, fisherman)
examples Instrument - Agency).
Despite sparseness problem might occur WordNet-based measures
used, measures advantage distributional measures treating elements compared concepts rather words. NLP community, steps
already taken solve problem clustering words large corpora aiming
word sense discovery (Pennacchiotti & Pantel, 2006). Recently, Mohammad (2008)
thesis investigated compatibility distributional measures ontological ones.
using corpus statistics thesaurus, author introduced distributional profiles
senses defined distance measures them. Even though new approach calculat-

42

fiUsing Local Alignments Relation Recognition

ing similarity tested generic corpora, would certain interest apply
domain-specific data.
Overall, local alignment kernels provide flexible means work data sequences.
First, allow partial match sequences particularly important
dealing text. Second, possible incorporate prior knowledge learning
process preserving kernel validity. general, LA kernels applied
NLP problems long input data form sequences.

Acknowledgments
authors wish thank Simon Carter Gerben de Vries comments
proofreading, three anonymous reviewers highly valuable feedback.
also acknowledge input Adaptive Information Management (AIM) group
University Amsterdam. preliminary version work dicussed
22nd International Conference Computational Linguistics (CoLing 2008)
Seventh International Tbilisi Symposium Language, Logic Computation (2007).
work carried context Virtual Laboratory e-Science project
(www.vl-e.nl). project supported BSIK grant Dutch Ministry
Education, Culture Science (OC&W) part ICT innovation program
Ministry Economic Affairs (EZ).

References
Airola, A., Pyysalo, S., Bjorne, J., Pahikkala, T., Ginter, F., & Salakoski, T. (2008). Allpaths graph kernel protein-protein interaction extraction evaluation crosscorpus learning. BMC Bioinformatics, 9 (Suppl II).
Beamer, B., Bhat, S., Chee, B., Fister, A., Rozovskaya, A., & Girju, R. (2007). UIUC:
Knowledge-rich Approach Identifying Semantic Relations Nominals.
Proceedings Workshop Semantic Evaluations (SemEval), Prague, Czech
Republic.
Bedmar, I. S., Samy, D., & Martinez, J. L. (2007). UC3M: Classification semantic relations
nominals using sequential minimal optimization. SemEval-2007.
Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures lexical semantic
relatedness. Computational Linguistics, 32 (1), 1347.
Bunescu, R. C. (2007). Learning Information Extraction. Ph.D. thesis, Department
Computer Sciences, University Texas Austin.
Bunescu, R. C., Ge, R., Kate, R. J., Marcotte, E. M., Mooney, R. J., Ramani, A. K., &
Wong, Y. W. (2005). Comparative experiments learning information extractors
proteins interactions. Artificial Intelligence Medicine, 33, 139155.
Bunescu, R. C., & Mooney, R. J. (2005a). shortest path dependency kernel relation
extraction. Joint Conference Human Language Technology / Empirical Methods
Natural Language Processing (HLT/EMNLP), Vancouver, BC.

43

fiKatrenko, Adriaans, & van Someren

Bunescu, R. C., & Mooney, R. J. (2005b). Subsequence kernels relation extraction.
Proceedings 19th Conference Neural Information Processing Systems,
Vancouver, BC.
Bunescu, R. C., & Mooney, R. J. (2006). Text Mining Natural Language Processing,
chap. Extracting Relations Text. Word Sequences Dependency Paths.
Springer.
Burges, C. J. C. (1998). tutorial support vector machines pattern recognition.
Data Mining Knowledge Discovery, 2 (2), 121167.
Camacho, R. (1994). use background knowledge inductive logic programming.
Report.
Cancedda, N., Gaussier, E., Goutte, C., & Renders, J.-M. (2003). Word-sequence kernels.
Journal Machine Learning Research, 3, 10591082.
Chang, C.-C., & Lin, C.-J. (2001). LIBSVM: library support vector machines. Software
available http://www.csie.ntu.edu.tw/~cjlin/libsvm.
Chen, S. F., & Goodman, J. (1996). empirical study smoothing techniques language
modeling. ACL96.
Clegg, A. B. (2008). Computational-Linguistic Approaches Biological Text Mining. Ph.D.
thesis, University London.
Cohen, W. W., Ravikumar, P., & Fienberg, S. (2003). comparison string distance
metrics name-matching tasks. IIWeb 2003, pp. 7378.
Collins, M. (1999). Head-Driven Statistical Models Natural Language Parsing. Ph.D.
thesis, University Pennsylvania.
Collins, M., & Duffy, N. (2001). Convolution kernels natural language. Advances
Neural Information Processing Systems 14, pp. 625632. MIT Press.
Cortes, C., & Vapnik, V. (1995). Support vector networks. Machine Learning, 20 (3),
273297.
Davidov, D., & Rappoport, A. (2008). Classification semantic relationships
nominals using pattern clusters. Proceedings ACL-08:HLT, pp. 227235.
Dolan, W. B., Quirk, C., & Brockett, C. (2004). Unsupervised construction large paraphrase corpora: Exploiting massively parallel news sources. COLING 2004, Geneva,
Switzerland.
Erkan, G., Ozgur, A., & Radev, D. R. (2007). Semi-supervised classification extracting
protein interaction sentences using dependency parsing. 2007 Joint Conference
Empirical Methods Natural Language Processing Computational Natural
Language Learning, pp. 228237.
Fellbaum, C. (1998). WordNet: Electronic Lexical Database. MIT Press.
Firth, J. R. (1957). synopsis linguistic theory 19301955. Studies Linguistic Analysis.
Philological Society, Oxford. Reprinted Palmer, F. (ed.), 1968.
Fundel, K., Kueffner, R., & Zimmer, R. (2007). RelEx - relation extraction using dependency
parse trees. Bioinformatics, 23 (3).
44

fiUsing Local Alignments Relation Recognition

Girju, R., Badulescu, A., & Moldovan, D. (2006). Automatic discovery part-whole relations. Computational Linguistics, 32 (1), 83135.
Girju, R., Nakov, P., Nastase, V., Szpakowicz, S., Turney, P., & Yuret, D. (2007). SemEval2007 Task 04: Classification semantic relations nominals. ACL 2007.
Girju, R., Nakov, P., Nastase, V., Szpakowicz, S., Turney, P., & Yuret, D. (2009). Classification semantic relations nominals. Language Resources Evaluation,
43 (2), 105121.
Giuliano, C., Lavelli, A., Pighin, D., & Romano, L. (2007). FBK-IRST: Kernel methods
semantic relation extraction. SemEval-2007.
Giuliano, C., Lavelli, A., & Romano, L. (2006). Exploiting shallow linguistic information
relation extraction biomedical literature. EACL 2006.
Grishman, R., & Sundheim, B. (1996). Message Understanding Conference - 6: brief
history. Proceedings 16th International Conference Computational Linguistics.
Haussler, D. (1999). Convolution kernels discrete structures. Tech. rep. UCS-CRL-99-10,
UC Santa Cruz.
Hearst, M. (1992). Automatic acquisition hyponyms large text data. Proceedings
COLING-92, pp. 539545.
Hendrickx, I., Morante, R., Sporleder, C., & van den Bosch, A. (2007). ILK: Machine
learning semantic relations shallow features almost data. SemEval2007.
Hersch, W., Cohen, A. M., Roberts, P., & Rakapalli, H. K. (2006). TREC 2006 genomics
track overview. Proceedings 15th Text Retrieval Conference.
Jiang, J. J., & Conrath, D. W. (1997). Semantic similarity based corpus statistics
lexical taxonomy. Proceedings International Conference Research
Computational Linguistics (ROCLING X), pp. 1933.
Joachims, T. (1999). Transductive inference text classification using Support Vector
Machines. Proceedings ICML.
Katrenko, S., & Adriaans, P. (2008). Semantic types generic relation arguments:
Detection evaluation. Proceedings 46th Annual Meeting Association Computational Linguistics: Human Language Technologies (ACL/HLT),
Columbus, USA.
Khoo, C. S. G., Chan, S., & Niu, Y. (2000). Extracting causal knowledge medical database using graphical patterns. Proceedings 38th Annual Meeting
Association Computational Linguistics, pp. 336343, Morristown, NJ, USA.
Association Computational Linguistics.
Kim, S. N., & Baldwin, T. (2007). MELB-KB: Nominal classifications noun compound
interpretation. SemEval-2007.
Lauer, F., & Bloch, G. (2008). Incorporating Prior Knowledge Support Vector Machines
Classification: Review. Neurocomputing, 71, 15781594.
45

fiKatrenko, Adriaans, & van Someren

Leacock, C., & Chodorow, M. (1998). Combining local context WordNet similarity
word sense identification. MIT Press, Cambridge, MA.
Lease, M., & Charniak, E. (2005). Parsing biomedical literature. Proceedings IJCNLP.
Lee, L. (1999). Measures distributional similarity. Proceedings 37th annual meeting Association Computational Linguistics Computational Linguistics,
pp. 2532.
Leslie, C., Eskin, E., Cohen, A., Weston, J., & Noble, W. S. (2004). Mismatch string kernels
discriminative protein classification. Bioinformatics, 20 (4), 467476.
Leslie, C., Eskin, E., & Noble, W. S. (2002). spectrum kernel: string kernel SVM
protein classification. Pacific Symposium Biocomputing 7, pp. 566575.
Leusch, G., Ueffing, N., & Ney, H. (2003). novel string-to-string distance measure
applications machine translation evaluation. Machine Translation Summit IX,
pp. 240247, New Orleans, LO.
Lin, D. (1998). information-theoretic definition similarity. Proceedings 15th
International Conference Machine Learning, pp. 296304.
Lodhi, H., Saunders, C., Shawe-Taylor, J., Christianini, N., & Watkins, C. (2002). Text
classification using string kernels. Journal Machine Learning Research, 2, 419444.
McDonald, R. (2005). Extracting relations unstructured text. Tech. rep. MS-CIS-0506, UPenn.
Melcuk, I. (1988). Dpendency syntax: theory practice. SUNY Press.
Mitchell, T. (1997). Machine Learning. McGraw Hill.
Miyao, Y., Stre, R., Sagae, K., Matsuzaki, T., & Tsuji, J. (2008). Task-oriented evaluation
syntactic parsers representations. Proceedings ACL-08:HLT, pp. 46
54.
Mohammad, S. (2008). Measuring Semantic Distance using distributional profiles concepts. Ph.D. thesis, Graduate Department Computer Science University
Toronto.
Monge, A. E., & Elkan, C. (1996). field matching problem: Algorithms applications.
KDD 1996, pp. 267270.
Moschitti, A. (2006). Efficient convolution kernels dependency constituent syntactic
trees. ECML 2006, pp. 318329.
Nakov, P. (2007). UCB: System description SemEval task #4. SemEval-2007.
Nakov, P. (2008). Paraphrasing verbs noun compound interpretation. Proceedings
Workshop Multiword Expressions (MWE08), conjunction Language
Resources Evaluation conference, Marrakech, Morocco, 2008.
Nakov, P., & Hearst, M. A. (2008). Solving relational similarity problems using web
corpus. Proceedings ACL-08:HLT.
Nedellec, C. (2005). Learning Language Logic - Genic Interaction Extraction Challenge.
Proceedings Learning Language Logic workshop.
46

fiUsing Local Alignments Relation Recognition

Needleman, S. B., & Wunsch, C. D. (1970). general method applicable search
similarities amino acid sequence two proteins. Journal Molecular Biology,
48 (3), 443453.
Nulty, P. (2007). UCD-PN: Classification semantic relations nominals using
WordNet web counts. SemEval-2007.
Seaghdha, D. (2009). Semantic classification WordNet kernels. Proceedings
North American Chapter Association Computational Linguistics - Human
Language Technologies Conference (NAACL-HLT), Boulder, CO.
Seaghdha, D., & Copestake, A. (2008). Semantic classification distributional kernels.
Proceedings CoLing 2008, Manchester, UK.
Palmer, M., & Wu, Z. (1995). Verb semantics English-Chinese translation. Tech. rep.,
Technical Report No. MS-CIS-95-39, Department Computer & Information Science,
University Pennsylvania.
Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet::Similarity - Measuring
Relatedness Concepts. Proceedings Nineteenth National Conference
Artificial Intelligence (AAAI-04), pp. 10241025, San Jose, CA.
Pennacchiotti, M., & Pantel, P. (2006). Ontologizing semantic relations. ACL-44: Proceedings 21st International Conference Computational Linguistics
44th annual meeting Association Computational Linguistics, pp. 793800,
Morristown, NJ, USA. Association Computational Linguistics.
Ponzetto, S. P., & Strube, M. (2007). Knowledge Derived Wikipedia Computing
Semantic Relatedness. Journal Artificial Intelligence Research, 30, 181212.
Resnik, P. (1995). Using information content evaluate semantic similarity. Proceedings
14th International Joint Conference Artificial Intelligence, pp. 448453.
Stre, R., Sagae, K., & Tsuji, J. (2008). Syntactic features protein-protein interaction
extraction. 2nd International Symposium Languages Biology Medicine,
pp. 6.16.14.
Sagae, K., & Tsujii, J. (2007). Dependency parsing domain adaptation LR models
parser ensembles. Proceedings EMNLP-CoNLL.
Saigo, H., Vert, J.-P., & Akutsu, T. (2006). Optimizing amino acid substitution matrices
local alignment kernel. BMC Bioinformatics, 7:246.
Saigo, H., Vert, J.-P., Ueda, N., & Akutsu, T. (2004). Protein homology detection using
string alignment kernels. Bioinformatics, 20 (11), 16821689.
Sang, E. F. T. K., Canisius, S., van den Bosch, A., & Bogers, T. (2005). Applying spelling
error correction techniques improving semantic role labeling. Proceedings
Ninth Conference Natural Language Learning, CoNLL-2005, Ann Arbor, MI.
Saunders, C., Tschach, H., & Shawe-Taylor, J. (2002). Syllables string kernel
extensions. ICML 2002.
Scholkopf, B. (1997). Support vector learning. Ph.D. thesis, Berlin Technical University.

47

fiKatrenko, Adriaans, & van Someren

Sekimizu, T., Park, H. S., & Tsujii, J. (1998). Identifying interaction genes
gene products based frequently seen verbs Medline abstracts. Genome
Informatics, 9, 6271.
Shawe-Taylor, J., & Christianini, N. (2000). Support Vector Machines KernelBased Learning Methods. Cambridge University Press.
Smith, L. H., Yeganova, L., & Wilbur, W. J. (2003). Hidden Markov models optimized
sequence alignment. Computational Biology Chemistry, 27 (1), 77 84.
Smith, T. F., & Waterman, M. S. (1981). Identification common molecular subsequences.
Journal Molecular Biology, 147, 195197.
Snow, R., Jurafsky, D., & Ng, A. Y. (2006). Learning named entity hyponyms question
answering. Proceedings COLING/ACL.
Swanson, D. R., & Smalheiser, N. R. (1999). Implicit text linkages Medline records:
Using Arrowsmith aid scientific discovery. Library Trends, 48 (1).
Thomas, J., Milward, D., Ouzounis, C., & Pulman, S. (2000). Automatic extraction
protein interactions scientific abstracts. Proceedings Pacific Symposium
Biocomputing.
Tribble, A., & Fahlman, S. E. (2007). CMU-AT: Semantic distance background knowledge identifying semantic relations. SemEval-2007.
Turney, P. D. (2006). Similarity semantic relations. Computational Linguistics, 32 (3),
379416.
van der Plas, L. (2008). Automatic Lexico-Semantic Acquisition Question Answering.
Ph.D. thesis, University Groningen.
van Rijsbergen, C. J., Robertson, S. E., & Porter, M. F. (1980). New models probabilistic
information retrieval. Tech. rep. 5587, British Library Research Development
Report.
Vapnik, V. (1982). Estimation Dependences Based Empirical Data. New York:
SPringer Verlag.
Weeds, J., Weir, D., & McCarthy, D. (2004). Characterising measures lexical distributional similarity. Proceedings CoLing 2004.
Zelenko, D., Aone, C., & Richardella, A. (2003). Kernel methods relation extraction.
Journal Machine Learning Research, 3, 10831106.
Zhang, Y., Schneider, J., & Dubrawski, A. (2008). Learning semantic correlation:
alternative way gain unlabeled text. Proceedings 22nd Conference
Neural Information Processing Systems, Vancouver, BC.

48

fiJournal Artificial Intelligence Research 38 (2010) 633-685

Submitted 03/10; published 08/10

Non-Transferable Utility Coalitional Games
via Mixed-Integer Linear Constraints
Gianluigi Greco

ggreco@mat.unical.it

Dipartimento di Matematica
Universita della Calabria
I-87036 Rende, Italy

Enrico Malizia
Luigi Palopoli
Francesco Scarcello

emalizia@deis.unical.it
palopoli@deis.unical.it
scarcello@deis.unical.it

DEIS
Universita della Calabria
I-87036 Rende, Italy

Abstract
Coalitional games serve purpose modeling payoff distribution problems scenarios agents collaborate forming coalitions order obtain higher worths
acting isolation. classical Transferable Utility (TU) setting, coalition worths
freely distributed amongst agents. However, several application scenarios,
case Non-Transferable Utility setting (NTU) must considered,
additional application-oriented constraints imposed possible worth distributions.
paper, approach define NTU games proposed based describing allowed distributions via set mixed-integer linear constraints applied
underlying TU game. shown games allow non-transferable conditions
worth distributions specified natural succinct way. properties
relationships among prominent solution concepts NTU games hold
applied (mixed-integer) constrained games investigated. Finally, thorough analysis carried assess impact issuing constraints computational
complexity solution concepts.

1. Introduction
Cooperative game theory providesunder concept coalitional gamesan elegant
framework modeling multi-agent systems agents might collaborate
agents, forming coalitions order guarantee advantage. Within
framework, coalition N (where N set players, also called
grand-coalition), assigned certain worth v(S) R, outcome game
vector real payoffs (xi )iN meant specify distribution worth granted
players result game.
Coalitional games often classified according mechanisms underlying payoff
distributions. best known widely studied class therein coalitional
games transferable utility (or TU games) (Osborne & Rubinstein, 1994),
constraints whatsoever imposed way coalitional worths distributed
amongst coalition members. context, several outcomes might associated

c
2010
AI Access Foundation. rights reserved.

fiGreco, Malizia, Palopoli, & Scarcello

given game, hence relevant question understand outcomes properly
capture rational behavior players. matter extensively studied
economics social sciences (Aumann & Hart, 2002). fact, various solution concepts
proposed literature identify worth distributions embody
rational concept stability, i.e., somehow immune deviations caused
groups players may decide leave grand-coalition form sub-coalitions
order claim higher worths.
cases, however, players cannot freely distribute coalition worth
pure TU framework appropriate modeling purposes (Aumann & Peleg,
1960). deal scenarios, coalitional games without transferable utility (or NTU
games) introduced literature, worth function defined
return allowed worth distributions (called consequences, setting) associated
given coalition, rather associating one real value it. fact,
easily understood NTU games general TU ones, since game
latter kind expressed NTU game possible worth distribution among
members coalition consequence S.
1.1 Modeling NTU Specifications via Mixed-Integer Linear Constraints
TU Games
Enhancing TU games application-oriented constraints set possible outcomes approach exploited literature order model nontransferable scenarios. first occurrence name constrained games goes back
seventies, due Aumann Dreze (1974), considered games coalition structures, players partitioned groups S1 , . . . , Sk , outcome
(xi )iN must allocate total payoff v(S
P j ) exactly amongst members group Sj ,
is, satisfy equalities iSj xi = v(Sj ), 1 j k. However, Aumann
Dreze noticed turn considering constraints TU games novel
idea, since core nucleolus (which two prominent solution concepts TU
games) indeed defined Gillies (1959) Schmeidler (1969), respectively, games
outcomes restricted subsets R|N | .
Recently, constrained games reconsidered pragmatic perspective
modeling relevant application scenarios, price formation (Byford, 2007)
autonomic wireless networks (Jiang & Baras, 2007). matter fact, however,
received considerably little attention years. particular, general framework proposed literature systematic study (analytical, well
computational) properties kind approaches conducted far.
paper, embark systematic formalization constrained games,
investigate framework allowing succinctly specify non-transferable conditions
outcomes underlying TU game, via set constraints expressed mixed-integer
linear (in)equalities.1 Note constrained games defined top underlying
TU specification, hence expected retain nice properties
transferable setting. However, ability restricting set possible outcomes makes
1. good source basic notions results mixed-integer linear programming book
Nemhauser Wolsey (1988).

634

fiMixed-Integer Constrained Coalitional Games

fit general framework NTU games, smoothly inherit
solution concepts shall use.
allowing integer variables, constrained games studied paper improve
expressiveness classical NTU formalizations, admissible outcomes might
possibly restricted non-convex non-comprehensive regions (definitions
properties recalled Section 3.2). Indeed, NTU games attracted much attention earlier literature allow specify arbitrary consequences (Aumann & Hart,
2002). Rather, according classical definition due Aumann Peleg (1960),
NTU game actually game must satisfy additional conditions as, particular, convexity comprehensiveness. view features several nice properties
mathematical perspective (Weber, 1994; McLean, 2002), influenced several proposals defining NTU games appeared literature, additional
conditions often considered. However, view appropriate model application
scenarios required properties naturally hold.
fact, framework constrained games proposed paper viewed
framework (succinctly) define NTU games convexity comprehensiveness
necessarily hold. important peculiarity approach knowledge representation perspective. intuitive exemplification scenarios peculiarity
might useful illustrated below.
Example 1.1. Three brothers, Tim, John Jim, aged 10, 8 5, resp., collected
piggy money-box small Euro coins (values 1, 2, 5, 10 cents) Mom
every week given since age four. Now, time come
break money-box divide content. order avoid quarrels among kids,
Mom decides distribution go ages, Tim deserve
least 10/8 money John get John, turn, receive least 8/5 Jims
money share. (Jim happy that, agrees comply Moms rule).
money-box gets broken little treasure seven Euros ninety Euro cents,
resulting available coin set including one-hundred 1-cent coins, seventy 2-cent
coins, fifty 5-cents coins, thirty 10-cent coins, divided amongst kids.
Note scenario based non-transferable condition treasure
cannot freely distributed amongst brothers. specific distribution rule, however,
fit classical NTU formalization Aumann Peleg (1960).
hand, easily seen scenario modeled means
set linear (in)equalities, variables taking values set Z integer
numbers. example, admissible outcomes indeed identified solutions
following set mixed-integer linear (in)equalities (the three brothers Tim, John
Jim denoted using indexes 1, 2 3, respectively):

635

fiGreco, Malizia, Palopoli, & Scarcello





























xi = 1 i1 + 2 i2 + 5 i5 + 10 i10 , 1 3
11 + 21 + 31 = 100
12 + 22 + 32 = 70
15 + 25 + 35 = 50
110 + 210 + 310 = 30
x1 10/8 x2
x2 8/5 x3
i1 , i2 , i5 , i10 0, 1 3
xi R, i1 , i2 , i5 , i10 Z, 1 3

Note auxiliary variables ij denote number coins value j taken
player i, first five equalities encode restrictions domains variables defined
available coin set, subsequent two inequalities encode Moms rule (which
seen, instance, playing role central market regulation authority).
1.2 Contribution Organization
Despite intuitiveness modeling approach adopted Example 1.1,
reference framework literature accounting it, specificity
Moms rule money distribution constrained available coin set,
allowed outcomes form convex set.
Proposing investigating framework may serve model kinds scenarios
main contribution paper. detail:
define formal framework NTU games based mixed-integer linear constraints applied underlying TU game, discuss modeling capabilities,
show main solution concepts NTU gamesin particular, core, bargaining
set, kernel, nucleolus, Shapley valuespecialize within novel framework.
analyze impact constraints basic properties solution concepts.
Moreover, highlight similarities differences featured constrained games
opposed TU games, investigating particular whether outcome stable
(under concepts) TU game remains stable constraints issued.
assess impact adding constraints computational complexity underlying concepts. particular, consider games characteristic function
form (von Neumann & Morgenstern, 1944) within setting worths given
oracles. context, discuss intrinsic difficulty checking whether
given worth distribution core bargaining set, deciding
non-emptiness solutions. Complexity results constrained games also
compared characterizing TU games.
rest paper organized follows. Section 2, overview basic
notions cooperative game theory. formal framework constrained games defined
Section 3. properties novel framework illustrated Section 4,
analysis computational viewpoint carried Section 5. discussion
concluding remarks reported Section 6.

636

fiMixed-Integer Constrained Coalitional Games

2. Coalitional Games
important issue cooperative game theory determine payoff distributions
agents scenarios collaborate forming coalitions, order obtain
higher worths acting isolation. context, one usually take care
relevant problems emerging coalition formation process, coalition
value calculation coalition structure generation problemsan excellent overview
problems state-of-the-art algorithm facing latter one found
work Rahwan, Ramchurn, Jennings, Giovannucci (2009).
Coalitional games introduced von Neumann Morgenstern (1944)
order model payoff distributions problems scenarios utility freely transferred among players. cases, coalitional games described associating
payoff possible coalition. Thus, coalitional game transferable utility (TU)
pair hN, vi, N finite set players, v function (v : 2N 7 R)
associates every coalition N real number v(S), called worth S.
Scenarios utility cannot freely transferred among players first formalized
Aumann Peleg (1960). scenarios, games described specifying
possible payoff distributions players coalition, rather one
(global) payoff. coalition N , let |S| denote cardinality S, let RS
|S|-dimensional real coordinate space, whose coordinates labeled members
S; particular, given payoff vector x RS , xi denotes component associated
player S. Then, coalitional game without transferable utility (NTU)
pair hN, V i, N finite set players, V function associating every
coalition N set payoff vectors V (S) RS , also called consequences.
Note NTU games generalizations TU games. particular, according
standard encoding2 discussed, e.g., handbook edited Aumann Hart (2002)
book Peleg Sudholter (2007), TU game hN, vi viewed throughout
paper NTU game hN, Vv i, where:


fiX
Sfi
Vv (S) = x R fi
xi v(S) , N.
(1)


Let G = hN, V NTU game. consequence x V (N ) imputation G
following two properties hold (see, e.g., Peleg, 1963; Peleg & Sudholter, 2007):

(1) Efficiency: V (N ), player N xi yi property
also known weak Pareto optimality;
(2) Individual Rationality: player N , xi max{ yi | yi V ({i}) }.
set imputations NTU game G denoted X(G). G actually TU
game, i.e., G = hN, vi (or, equivalently, G = hN, Vv i), immediate check that:


fiX
Nfi
X(G) = x R fi
xi = v(N ) xj v({j}), j N .


2. Indeed, encoding allows solution concepts originally defined TU games smoothly
generalized NTU frameworkas shall discuss later section.

637

fiGreco, Malizia, Palopoli, & Scarcello

particular, note xj v({j}) encodes individual rationality player j x.
outcome G imputation taken X(G) specifying payoff distribution
players game. outcome represent kind agreement amongst
players, stable respect possibility subsets players get
incentive deviate it, forming coalitions own. Depending criterium adopted define concept stability, various (solution) concepts coalitional
games defined. relevant solution concepts coalitional gamessuch
core, bargaining set, nucleolus, kernel, Shapley valuehave
originally defined within TU framework (see, e.g., Osborne & Rubinstein, 1994). Several
efforts subsequently paid apply concepts within general NTU
framework (see, e.g., Aumann & Hart, 2002). Natural extensions defined
cases, natural counterparts still missing looked others.
following, shall provide overview definitions basic solution
concepts TU games canonical extensions NTU games.
2.1 Core
concept core goes back work Edgeworth (1881). TU framework,
formalized Gillies (1959), first extended NTU framework
Aumann (1961). fact, solution concept enjoys canonical
extension NTU case, one presented next.
Let G = hN, V NTU game. coalition N , vector RS
real numbers called S-feasible V (S). Let x consequence RN . Then,
pair (y, S) objection x S-feasible payoff vector yk > xk
k Sin case, coalition also said block x via y.
Definition 2.1. core C (G) NTU game G = hN, V set imputations
x objection; is,
C (G) = {x X(G) |S N, V (S) yk > xk , k } .



Thus, imputation x core stable coalition whose members receive higher payoff x leaving grand-coalition.
application Definition 2.1 TU games exactly coincides original
formulation Gillies (1959). Moreover, easily seen that, applied TU
games, Definition 2.1 equivalently restated illustrated next (see, e.g., Osborne &
Rubinstein, 1994). coalition
N payoff vector x RN , define x(S)
P
value expression xi .
Definition 2.2. core C (G) TU game G = hN, vi set imputations
x X(hN, Vv i) that, coalition N , x(S) v(S).


Thus, core coalitional game transferable utility |N | players defined
set inequalities |N | variables and, fact, polytope RN .

638

fiMixed-Integer Constrained Coalitional Games

2.2 Bargaining Set
concept bargaining set defined Aumann Maschler (1964), many
variants even within TU context (see, e.g., Maschler, 1992). natural extension
NTU framework given Peleg (1963), discussed next.
Let G = hN, V NTU game, x consequence V (N ). Let N
coalition, S-feasible payoff vector (i.e., V (S)). pair (y, S)
objection player player j x S, j
/ S, yk > xk k S.
counterobjection objection (y, S) j x pair (z, ) j ,

/ , z -feasible payoff vector zk xk k \ zk yk
k S. exist counterobjection (y, S), say (y, S)
justified objection.
Definition 2.3. bargaining set B(G) NTU game G set imputations
x justified objection.

Note definitions straightforwardly apply TU games, coincide
one originally proposed Aumann Maschler (1964). sake
completeness, recall (resp., z) S-feasible (resp., -feasible) payoff
vector TU game hN, vi Vv (S)
P(resp., z Vv (T )) holds;
P is, y(S) v(S)
(resp., z(T ) v(T ))recall y(S) = yi (resp., z(T ) = zi ).
2.3 Nucleolus

nucleolus solution concept introduced Schmeidler (1969). definition based
notion excess e(S, x, V ) coalition imputation x, measure
dissatisfaction x.
case TU games (where v denotes worth function), widely accepted
canonical definition excess e(S, x, Vv ) = v(S) x(S). Then, vector
x RN , let us define (x) vector excesses associated coalitions
(but empty one) arranged non-increasing order:
(x) = (e(S1 , x, V ), e(S2 , x, V ), . . . , e(S2|N| 1 , x, V )).
Let (x)[i] denote i-th element (x). pair imputations x y, say
(x) lexicographically smaller (y), denoted (x) (y), exists
positive integer q (x)[i] = (y)[i] < q (x)[q] < (y)[q].
Since excess measure dissatisfaction, imputations lexicographically minimizing vector excesses natural candidates stable outcomes
game. indeed idea underlying definition nucleolus,
defined Schmeidler (1969) TU games.
Definition 2.4. nucleolus N (G) TU game G = hN, vi set
N (G) = {x X(hN, Vv i) | X(G) (y) (x)}.



games fit TU framework, definition still used
provided suitable generalization concept excess conceived.
639

fiGreco, Malizia, Palopoli, & Scarcello

influential approach define excess functions NTU games proposed Kalai (1975),
axiomatized properties functions satisfy retain
nice features underlying TU specifications. properties follows:
1. Let x, RN . xi = yi players S, e(S, x, V ) = e(S, y, V ) holds,
function V ;
2. Let x, RN . xi < yi players S, e(S, x, V ) > e(S, y, V ) holds,
function V ;
3. Let x RS . vector V (S) that, S, yi > xi ,
e(S, x, V ) = 0 holds, function V ;
4. e(S, x, V ) continuous jointly x V .
example, prototypical excess function discussed Kalai following:



, .
eK (S, x, V ) = sup R | V (S) yi = xi +
|S|

(2)

function coincides canonical excess function v(S)x(S) whenever applied
TU games (Kalai, 1975).
2.4 Kernel
kernel solution concept originally introduced TU framework Davis
Maschler (1965) help understand properties bargaining set.
TU game hN, vi, define surplus si,j (x) player player j
imputation x value si,j (x) = maxS|iS,j / e(S, x, Vv ) = maxS|iS,j / (v(S) x(S)).
Definition 2.5. kernel K (G) TU game G = hN, vi set:
K (G) = {x X(hN, Vv i) | si,j (x) > sj,i(x) xj = v({j}), i, j N, 6= j}.



Note definition TU games based notion excess.
Intuitively, surplus player j x highest payoff player
gain (or minimal amount lose, negative value) without cooperation
j, forming coalitions players satisfied x; thus, si,j (x)
weight possible threat j. particular, player bargaining
power j x si,j (x) > sj,i (x); however, player j immune threat whenever
xj = v({j}), since case j obtain v({j}) even operating alone. say
player outweighs player j x si,j (x) > sj,i(x) xj > v({j}). kernel
set imputations player outweighs another one.
Generalizing kernel NTU games based considering generalizations
excess function, nucleolus. Again, influential approach, recalled next,
due Kalai. However, worthwhile noticing approaches also
proposed literature (see, e.g., Orshan & Zarzuelo, 2000; Peleg & Sudholter, 2007).
Indeed, differently solution concepts discussed far, variations kernel (and
640

fiMixed-Integer Constrained Coalitional Games

related concepts, prekernel, focus extensions cited above)
NTU games still subject research debate (cf. Serrano, 1997).
Let G = hN, V NTU game. say payoff vector RN transfer
player j player tj 0, ti 0, tk = 0, player k N \ {i, j}. transfer
justified imputation x, every real number , 0 < < 1, vector = x +
(such yk = xk + tk , k N ) individually rational vector V (N )
(x + t) (x)of course, excess function G satisfying Kalais axiomatization must
used order define excess vectors. kernel K (G) G set: K (G) =
{x X(G) | justified transfer player j player x, i, j N, 6= j}.
2.5 Shapley Value
Shapley value solution concept introduced TU framework Shapley (1953).
concept associates every TU game G = hN, vi unique payoff vector (G) RN ,
component (G)i , called Shapley value player i, indicates
worth assigned player i, based upon ability cooperation measured
expected marginal contribution player forming coalitions (as formalized below).
Let permutation set N players. player i, denote pi
set players preceding . marginal contribution player coalition pi
v(pi {i}) v(pi ). permutations chosen uniformly random set
possible permutations,
P expected marginal contribution player game G
value (G)i = |N1 |! v(pi {i}) v(pi ) or, equivalently:
(G)i =

X

SN \{i}

|S|!(|N | |S| 1)!
(v(S {i}) v(S)) .
|N |!

Shapley value unique payoff vector satisfying following properties,
constitute axiomatic characterization3 :
P
(1) Efficiency:
(G)i = v(N ).

(2) Symmetry: Two players j symmetric if, N i, j
/ S,
v(S {i}) = v(S {j}). players players j symmetric, (G)i = (G)j .
(3) Dummy: player dummy if, N \ {i}, v(S {i}) v(S) = v({i}).
player dummy player, (G)i = v({i}).
(4) Additivity: Let G = hN, wi TU game, G = hN, v + wi TU game
(v+w)(S) = v(S)+w(S) coalition N . Then, (G )i = (G)i +(G )i .

Note Shapley value might satisfy individual rationality, thus
necessarily imputation. Payoff distributions efficient, necessarily
individually rational, called pre-imputations literature.
Generalizing Shapley value NTU framework straightforward. Different
extensions Shapley value NTU games proposed. them,
3. characterization reported one found often literature. However,
original axiomatic formulation Shapley requires carrier axiom instead efficiency
dummy axioms; two axiomatizations equivalent (Shapley, 1953; Winter, 2002).

641

fiGreco, Malizia, Palopoli, & Scarcello

evaluated NTU version TU game, coincides standard Shapley value
TU games. discuss generalization proposed Shapley (1969)
formulation reported McLean (2002), refer interested reader latter
work extended treatment subject values NTU games, paper
Hart (2004) comparison notable three them.
Let G = hN, V NTU game. vector RN strictly positive real numbers,
let G game hN, v
(
)
X
v (S) = sup
zi | z V (S) .


TU game G said defined G v (S) finite S.
Definition 2.6. Let G = hN, V NTU game. vector x RN Shapley NTU
value payoff G exists vector RN strictly positive real numbers
that: x V (N ); G defined G; xi = (G )i player N . set
Shapley NTU values G denoted (G).

Shapley NTU values fulfill, adaptations, axioms characterizing
standard TU Shapley values. Actually, axioms suffice uniquely characterize
NTU counterpart, axioms issued order define unambiguously
NTU Shapley value. axiomatization NTU case given Aumann (1985).
interested reader referred work McLean (2002), issue.
2.6 Properties Solution Concepts TU Games
conclude recalling well-known properties solution concepts discussed
above, applied TU games.
Proposition 2.7 (see, e.g., Osborne & Rubinstein, 1994). Let G = hN, vi TU game
X(G) 6= . Then:
(1) |N (G)| = 1;
(2) N (G) K (G) (hence, K (G) 6= );
(3) K (G) B(G) (hence, B(G) 6= );
(4) C (G) B(G); and,
(5) C (G) 6= implies N (G) C (G).
Note relationship Shapley value solution
concepts (just recall Shapley value necessarily imputation).

3. Constrained Games via Mixed-Integer Linear (In)Equalities
Assume TU game G = hN, vi given consider problem modeling
dealing constraints imposed feasible worth distributions amongst players G.
642

fiMixed-Integer Constrained Coalitional Games

constraints might implied nature domain hand (e.g.,
worth arbitrarily divisible), reflect hard preferences expressed
players regulation authorityrecall Example 1.1. approach
encode application-oriented constraints within classical coalitional TU game setting
defining set mixed-integer linear (in)equalities, satisfied
imputations game G. approach first formalized below; subsequently, shall
illustrate modeling capabilities discuss relationships TU framework.
start recalling mixed-integer linear (in)equality linear (in)equality
variables might constrained take values set Z integers.
set LC mixed-integer linear (in)equalities, denote real (LC) int(LC) sets
variables LC defined R Z, respectively. Moreover, assume worth
distributions constrained defining inequalities via player auxiliary variables.
player variable form xi , N player underlying TU game,
meant encode worth assigned player outcomes
game. (possibly empty) set auxiliary variables LC set
real (LC) int(LC) \ {xi | N }. Auxiliary variables sometimes useful modeling
purposes, illustrated Example 1.1.
Let us proceed formalization. Let G = hN, vi TU game, recall
Section 2 G viewed NTU game hN, Vv i. Let LC set mixedinteger linear (in)equalities. Define (LC) set solutions LC. Moreover,
coalition N , let (LC)[S] denote projection (LC) onto subspace associated
payoff domains players S; is, vector index set belongs (LC)[S]
vector x (LC) xi = yi holds, S.
Intuitively, constrained game LC defined restricting consequences
underlying TU game G belonging solution space set LC mixed-integer
linear (in)equalities projected onto subspace associated player variablesrecall
auxiliary variables may occur LC. formalized below.
Definition 3.1 (Mixed-Integer Constrained Games). Let G = hN, vi TU game
let LC set mixed-integer linear (in)equalities. Then, (mixed-integer) constrained
game G|LC NTU game hN, VLC VLC (S) = Vv (S) (LC)[S]. is,


fiX
Sfi
VLC (S) = x R fi
xi v(S) x (LC)[S] , N.


3.1 Modeling Capabilities Constrained Games

Constraining TU game G via set LC (in)equalities involve integer variables
(i.e., int(LC) = ) abstraction approaches literature consider
specific sets (in)equalities real variables (such Aumann & Dreze, 1974; Byford,
2007; Jiang & Baras, 2007). particular, capability might exploited to:
(1) State hard preferences worth distributions.
example, consider game G = hN, vi set players N = {1, 2, 3, 4},
v(N ) = 10. Assume players 3 4 together require get least

643

fiGreco, Malizia, Palopoli, & Scarcello

half worth. Then, requirement modeled as:

x3 + x4 5
x1 , x2 , x3 , x4 R
Moreover, allowing integer variables, completely novel modeling capabilities emerge
setting w.r.t. earlier approaches. Indeed, integer variables used isolate
non-convex regions, might needed model specific application requirements
NTU nature, exemplified below.
(2) Consider alternative scenarios.
allowing integer variables, may model alternative preferences players, i.e.,
may enforce disjunctions preferences. instance, consider scenario
either players 1 2 must get together 3, players 2 3 must get
together 5. case, two constraints (i.e., x1 + x2 3
x2 + x3 5) goal define set (in)equalities prescribing least
one satisfied. end, auxiliary integer variable used:

x1 + x2 3 + U




x2 + x3 5 + U (1 y)
0y1



x ,x ,x R

1 2 3
yZ

constant value U upper bound worth coalition. Indeed,
case = 1, constraint x1 + x2 3 + U trivially satisfied (because U
sufficiently large), thus, enforce x2 +x3 5. Symmetrically, = 0,
constraint x2 + x3 5 + U trivially satisfied, thus, enforce x1 + x2 3.
course, simple manipulations, one may easily specify kinds alternatives, e.g., fact least (or most) k given constraints satisfied.

(3) Restrict worth functions specific domains.
domains required integer intervals, rather obvious. instance,
assume x3 take values domain {4, 5, 6, 7, 8, 9, 10}. Then, may
simply consider following constraints:

4 x3 10
x ,x ,x R
1 2 4
x3 Z

order model general scenarios, (as point (2) above) mixedinteger linear (in)equalities defined auxiliary variables. instance, assume
player 2 wants either take whole worth (even forming
coalitions players) or, whenever possible, get nothing.
modeled constraints, additional variable win fact, notice

644

fiMixed-Integer Constrained Coalitional Games

v(N ) constant value game given hand:

x2 = v(N ) w



0w1
x ,x ,x ,x R


1 2 3 4
wZ

Note Example 1.1 basically presents realistic case, several auxiliary
variables used restrict money distributions available coin set.
basic modeling capabilities constrained games discussed,
order illustrate possible applications resulting framework, convenient
preliminarily observe two properties (which related use integer variables).
First, easy check that, constrained games, may deal imputation
sets arbitrary sizes.4
Proposition 3.2. Let G = hN, vi TU game let X X(G) arbitrary finite
set imputations. Then, finite set constraints LC X(G|LC ) = X .
addition, integer variables might used succinctly specify exponentially many
imputations via polynomially many (in)equalities.
Proposition 3.3. exists class C = {G|nLC }n>0 constrained games
game G|nLC n + 1 players, LC consists 2 n + 1 inequalities, |X(G|LC )| = 2n .
believe setting emerging properties rather appealing
knowledge representation perspective. Indeed, one may exploit constrained games
naturally model scenarios non-transferable conditions emerge, devising
compact specifications desired restrictions utilities may transferred among
coalition members. fact, various circumstances envisaged usage
constrained games natural choice; instance, whenever worth distributed
among agents comes set indivisible goods, exemplified below.
Example 3.4 (Distributing indivisible goods). certain region country
famous hosting several producers two kinds goods, named .
producer {1, . . . , n}, let denote quantity pieces produced i,
respectively. assembling together one piece one piece , novel kind indivisible
good obtained and, fact, commercializing assembled product much
advantageous business selling separately. Therefore, agreement found
amongst producers area order assemble pieces overall
available, provided resulting units assembled product (fairly) distributed
amongst involved producers, would like independently commercialize them.
scenario easily modeled within framework follows. First, associate
every coalition {1, . . . , n}, number pieces assembled product
produce. Thus, define:
X
X
v(S) = min(
,
).




4. sake exposition, proofs propositions stated section reported Appendix.

645

fiGreco, Malizia, Palopoli, & Scarcello

Then, since assembled product indivisible, possible worth distribution
vector non-negative integers, immediately modeled via following set
constraints LC = {xi 0, xi Z, 1 n}. particular, (LC) convex region,
earlier modeling perspectives NTU games, present handbook
edited Aumann Hart (2002), apply here.

cases, however, worth might practically assumed divisible,
specific constraints regulate actual distribution. Notably, even cases, integer
variables may play crucial role illustrated next.
Example 3.5 (Service composition). Assume service acquired 100
Eurosfor sake simplicity, assume money divisible, otherwise worth
distributions might simply restricted discrete domain Example 3.4
Example 1.1. Supplying service implies executing tasks, named t1 , . . . , tm .
Assume also set {1, . . . , n} agents, one capable carrying
tasks, let sij denote ability agent perform task tj (sij = 1
means agent able perform tj , whereas sij = 0 means capable
so).PThus, coalition {1, . . . , n} capable supporting service case
sij 1, j {1, . . . , m}.
Assume, moreover, order complete , tasks must completed, agents contributing must able exchange partial results returned
performing required tasks. Establishing communication infrastructure guaranteeing
needed result-transfers take place specific cost coalition S,
denote com(S) < 100. Hence, amount money might finally distributed
amongst players described following worth function:

P

100 com(S)
sj 1, j {1, . . . , m}
v(S) =
0
otherwise.
Note scenario defines classical TU game G = h{1, . . . , n}, vi. However,
things may significantly different assume agent sustain internal
cost, say cij , whenever actually performing task tj , that, hence, may decide
perform task all, convenient. Indeed, case, letting ji {0, 1}
variable denoting whether actually performing tj , P
natural state


total internal cost agent (which given expression
j=1 j cj )
exceed agent gets worth distribution. Hence, utilities cannot freely
distributed and, proper modeling realistic scenario, game
enriched following set constraints:
X

ji = 1, j {1, . . . , m}










X



ji cij , {1, . . . , n}
xi
j=1
LC =



0 ji sij , {1, . . . , n}, j {1, . . . , m}






x1 , . . . , xn R




j Z, {1, . . . , n}, j {1, . . . , m}
646

fiMixed-Integer Constrained Coalitional Games

respect formalization, worthwhile noting (LC) empty
service cannot provided all, indeed X(G|LC ) would empty turn. Otherwise,
i.e., (LC) 6= , imputations G|LC correspond worth distributions associated
legal staffing tasks, rather arbitrary possible worth distributions
(as would plain TU case).
worthwhile contrasting formulation alternative TU one,
constraints LC directly encoded definition worth function, instead
using separate component thereof, done NTU framework proposing here.
instance, one may add condition v(S) = 100 com(S) requirement
exists element x (LC) task tj , player
ji 6= 0 (in x). way, ensure payoff 100 com(S) assigned
coalition formed players perform task conforming
cost constraints, jointly complete refined modeling perspective
exactly one underlying class linear programming games (see, e.g., Owen, 1975).
However, approach would prescribe payoff 100 com(S) actually
distributed amongst players S. fact, focusing accurately modeling
worth function, cannot guarantee outcome game (according chosen
solution concept) fulfils desired constraints distribution payoffs single
players. words, using constraints definition worth function may
useful certain cases careful modeling purposes, cannot general replace
use external constraints actually constrain allowed worth distributions.
important remark, note structure example may
well used guideline formalization application scenarios. Indeed,
basic idea use mixed-integer linear constraints define solutions combinatorial problems associated feasible worth distributions (reflecting, e.g., costs
solutions). Thus, contextualized approach case staffing
problem, similar encodings used define constrained games suited deal
scheduling planning problems, cite few.
3.2 Closer Look Constrained Games
resort presentation framework constrained games analyzing structure consequences, role played individual rationality
requirement context. analysis provide important bases subsequent
treatment analytical computational properties NTU solution concepts
applied constrained games.
3.2.1 Consequences Constrained Games
order understand nature constrained games, convenient take closer
look structure function VLC . fact, principle NTU game hN, V
impose requirement function associating set consequence V (S)
coalition N , NTU games attracted much attention literature
actually allow arbitrary consequences specified (Aumann & Hart, 2002). Indeed,
sets consequences usually required satisfy additional conditions,
(de facto) conceived guarantee nice properties hold solution concepts
647

fiGreco, Malizia, Palopoli, & Scarcello

interest. assumptions often considered literature
(not necessarily required simultaneously hold) recalled next. N , V (S)
might required be:
(1) (Upper) Bounded: real number R x V (S),
S, xi holds;
(2) Closed: V (S) contains boundaries;
(3) Compact: V (S) closed bounded;
(4) Comprehensive: x V (S), RN (i S)(yi xi ), V (S);
(5) Convex: pair x, V (S), real number t, 0 < < 1, vector
(1 t)x + ty belongs V (S).
(6) Non-empty: |V (S)| > 0.
case constrained games, explicitly ask requirements
satisfied, thereby giving rise setting powerful modeling capabilities (as
discussed Section 3.1). differences constrained games classical NTU
games illustrated next.
Consider function VLC associated constrained game G|LC . first difference
concerns property (1), VLC (S) required bounded (as TU case,
individual payoffs players bounded general, since requirement sum exceed worth v(S) associated Ssee Equation (1)
Section 2). Actually, substantial difference given that, possible worth
distribution G|LC corresponding solution concept illustrated Section 2,
payoff player bounded.
Similarly, easy see might cases property (2) hold
context constrained games. Indeed, VLC (S) might closed whenever LC
contains strict inequality excludes boundary VLC (S). However, known
cases undesirable solution concepts, hence shall consider
constraints based non-strict inequalities only. Property (3) combination
first two properties, thus lines reasoning still apply.
differences remaining three properties, instead, characterize framework
constrained games basis modeling capabilities. fact, ability
handle sets consequences comprehensive convex, possibly
empty coalition, important peculiarity constrained games knowledge
representation perspective. Indeed, may lose comprehensiveness time constraint
payoff distribution given states players required get least
certain worth; may lose convexity (as well comprehensiveness) time integrality
constraints involved. Moreover, may deal empty set consequences
coalition whenever feasible way distribute worth associated
according constraints players must satisfy.
Example 3.6. Consider TU game G = hN, vi N = {1, 2, 3}, v({1, 2, 3}) = 3,
v(S) = 0 {1, 2, 3}. Consider scenario worth G restricted
648

fiMixed-Integer Constrained Coalitional Games

integer value (i.e., payoff distributions taken Z{1,2,3} ), players
1 2 require get least 2. constraints modeled follows:

x1 + x2 2
LC =
x1 , x2 , x3 Z
Note (LC)[{1, 2, 3}] = {x Z{1,2,3} | x1 + x2 2}, (LC)[{1, 2}] = {x Z{1,2} |
x1 +x2 2}, (LC)[{1, 3}] = Z{1,3} , (LC)[{2, 3}] = Z{2,3} , (LC)[{1}] = Z{1} , (LC)[{2}] =
Z{2} , (LC)[{3}] = Z{3} . Then, constrained game G|LC = hN, VLC that:
VLC ({1, 2, 3}) =
=
VLC ({1, 2})
=
VLC ({1, 3})
=
=
VLC ({2, 3})
VLC ({i})
=

{x R{1,2,3} | x1 + x2 + x3 3} (LC)[{1, 2, 3}] =
{x Z{1,2,3} | x1 + x2 + x3 3, x1 + x2 2};
{x R{1,2} | x1 + x2 0} (LC)[{1, 2}] = ;
{x R{1,3} | x1 + x3 0} (LC)[{1, 3}] = {x Z{1,3} | x1 + x3 0};
{x R{2,3} | x2 + x3 0} (LC)[{2, 3}] = {x Z{2,3} | x2 + x3 0};
{x R{i} | xi 0} (LC)[{i}] = {x Z{i} | xi 0}; (i {1, 2, 3})

Despite simple constraints considered G, immediate check (e.g.)
VLC (N ) comprehensive convex, VLC ({1, 2}) empty. Indeed,
integrality constraints immediately lead loose comprehensiveness convexity. Moreover, fact players 1 2 require get least 2 implies coalition {1, 2}
never form deviate grand-coalition, given two players cannot
guarantee worth acting without player 3 (indeed, v({1, 2}) = 0).
3.2.2 Individual Rationality Constrained Games
important issue pointed constrained games related individual
rationality requirement set imputations. Let G = hN, V NTU game,
recall Section 2 imputation x X(G) must player
N , xi max{ yi | yi V ({i}) }.
Consider constrained game G|LC G = hN, Vv underlying TU game.
Definition 3.1, set VLC ({i}) coincides Vv ({i}) (LC)[{i}]. Then, individual rationality requirement, player i, xi max{ yi | yi Vv ({i})(LC)[{i}] }.
Note special case occurs VLC ({i}) = Vv ({i}) (LC)[{i}] = . case,
indeed, max{ yi | yi VLC ({i}) } defined (as real value). approach might
therefore observe game over-constrained, stop analysis.
approach is, fact, consistent several NTU formalizations requiring set
consequences non-empty, possible coalition (see Section 3.2.1).
However, Example 3.6 already pointed empty sets consequences
may naturally emerge constrained games, VLC (S) = reflects fact
coalition cannot form deviate grand-coalition, worth distribution
principle granted members alone (according underlying TU
game), satisfies constraints hand. Consequently, finer-grained perspective
considered deal individual rationality requirement, special case
VLC ({i}) = , player N .
basic observation VLC ({i}) = necessarily implies xi > v({i}) holds,
imputation x VLC (N ). Thus, extreme scenarios, individual rationality
649

fiGreco, Malizia, Palopoli, & Scarcello

constraint conceptually satisfied (though formally undefined) possible imputation
x, since constraints LC require xi larger v({i}). Technically, stress
conclusion implied defining max{} = , standard extension
max empty sets.
light perspective, show individual rationality preserved constraints added given TU game.
Proposition 3.7. Let G = hN, vi TU game let x payoff vector
individually rational w.r.t. G (i.e., xi v({i}), player N ). Then, set
LC constraints, x individually rational w.r.t. constrained game G|LC .

4. Solution Concepts Constrained Games
Constrained coalitional games special cases NTU games, therefore inherit
various solution concepts discussed Section 2. Thus, constrained (and, such, NTU) game G|LC , interest compute core, bargaining
set, nucleolus, kernel, Shapley value. section, study properties concepts, highlighting similarities differences featured constrained
games opposed TU games.
nutshell, show properties TU games stated Proposition 2.7
still hold constrained games solution concepts, bargaining set
might empty games. Moreover, portion core TU game G
satisfies constraints preserved, sense subset core
constrained game G|LC built top G. hand, solutions
concepts, preservation property holds special cases only.
illustrating results, useful state property relating imputation
set constrained game imputation set underlying TU game.
Proposition 4.1. Let G|LC constrained game G = hN, vi.
(LC)[N ] X(G|LC ).

Then, X(G)

Proof. Let x payoff vector X(G) (LC)[N ]. Since x X(G) x Vv (N ).
also assuming x (LC)[N ] hence x VLC (N )recall,
Definition 3.1, VLC (N ) = Vv (N ) (LC)[N ]. x X(G), x also efficient w.r.t.
G, meaning Vv (N ), player N xi yi . Moreover, since
VLC (N ) Vv (N ), x also efficient w.r.t. G|LC . Finally, Proposition 3.7, know x
individually rational w.r.t. G|LC . Thus, x X(G|LC ).
Based result, show imputation x X(G) also belongs X(G|LC ),
following shall show x satisfies constraints LC, thereby avoiding
explicitly reason efficiency individual rationality x.
4.1 Relationships Among Solution Concepts
start analysis investigating whether properties basic solution concepts
(as appear Proposition 2.7) preserved setting constrained games.

650

fiMixed-Integer Constrained Coalitional Games

4.1.1 Counterparts Proposition 2.7.(1) Proposition 2.7.(2)
Let us begin focusing first two properties Proposition 2.7, pertain
nucleolus. TU framework, nucleolus always consists exactly one imputation.
constrained framework, properties solution concept intimately related
closeness (LC) (and, turn, X(G|LC )), i.e., whether (LC) contains
boundaries. Recall Section 3 (LC) might closed due
occurrence strict inequalities LC.
Proposition 4.2. exists constrained game G|LC (with int(LC) = )
X(G|LC ) 6= N (G|LC ) = (for excess function eK Equation (2)
page 640).
Proof. Consider game G players {1, 2}, v({1, 2}) = 1 v({1}) = v({2}) =
0. Given constraint LC = {x1 < 12 , x1 R}, one may note X(G|LC ) 6= . Indeed,
observe max{x1 | x1 VLC ({1})} = max{x2 | x2 VLC ({2})} = 0, since VLC ({i}) =
Vv ({i}) (LC)[{i}] = {xi R{i} | xi 0} (LC)[{i}] = {xi R{i} | xi 0},
{1, 2}. Thus, payoff vector x X(G|LC ) required satisfy x1 0
x2 0, order individually rational. particular, claim X(G|LC ) = {x
R{1,2} | x1 + x2 = 1, x1 < 12 , x1 0, x2 0}. Indeed, vector x VLC (N ) = {x RN |
x1 + x2 1, x1 < 12 } x1 < 12 x2 < 12 efficient, given
vector VLC (N ) x1 < y1 < 12 x2 < y2 < 12 , y1 + y2 < 1. Moreover,
vector x VLC (N ) x1 < 12 , x2 > 12 , x1 + x2 < 1 also efficient,
given existence vector VLC (N ) x1 < y1 = x1 + 1x22 x1 < 12
x2 < y2 = x2 + 1x22 x1 , (therefore) y1 + y2 = 1.
Consider imputation x x1 + x2 = 1 x1 < 12 (and hence x2 > 12 ).
Then, always build imputation 6= x y1 = x1 + ( 12 x1 )/2 > x1
y2 = 1 y1 < x2 ; notice y1 < 12 holds. new imputation, case
(y) (x) holds w.r.t. excess function eK Equation (2). Indeed, recalling
VLC ({i}) = {xi R{i} | xi 0} xi 0 yi 0 hold, {1, 2},
(x) = (0, x1 , x2 ) (y) = (0, y1 , y2 ). Thus, imputation x
belongs N (G|LC ), i.e., N (G|LC ) = . Note (LC) closed.
practical applications linear programming, one may deal non-strict inequalities
(see, e.g., Papadimitriou & Steiglitz, 1998); cases (i.e., whenever X(G|LC )
closed hence compact, since always bounded), nucleolus empty.
property observed hold Kalai (1975) along relationship nucleolus
kernel. properties restated context follows.
Proposition 4.3 (cf. Kalai, 1975). Let G|LC constrained game X(G|LC ) 6= .
Then,
(1) X(G|LC ) compact, |N (G|LC )| 1;
(2) N (G|LC ) K (G|LC ) (hence, K (G|LC ) 6= whenever X(G|LC ) compact).
following, examples counterexamples built avoiding use strict
inequalities.
651

fiGreco, Malizia, Palopoli, & Scarcello

4.1.2 Counterparts Propositions 2.7.(3), (4), (5)
Let us move analyze counterpart Proposition 2.7.(3). end, first
notice that, unlike TU case, bargaining set sometimes empty.
Proposition 4.4. exists constrained game G|LC (with int(LC) = )
X(G|LC ) 6= B(G|LC ) = .
Proof. Consider TU game G players {1, 2, 3, 4}, whose worths follows:
v({1, 2, 3, 4}) = 3, v({1, 2}) = 2, v({2, 3, 4}) = 3, v({1, 3, 4}) = 3, v({2}) = 1, v(S) = 0
coalition {1, 2, 3, 4}. Consider moreover following set constraints:

x1 + x2 + x3 + x4 = 3




x
2 + x3 + x4 = 3
x1 + x3 = 1
LC =


x + x4 = 1


1
x1 , x2 , x3 , x4 R

Let x payoff vector x1 = 0 x2 = x3 = x4 = 1. Observe x satisfies
constraints LC. Moreover, x imputation X(G); thus, Proposition 4.1, x
belongs X(G|LC ). fact, x vector (LC) and, therefore,
imputation X(G|LC ). Thus, prove B(G|LC ) = , show x
contained B(G|LC ). end, consider objection (y, {1, 2}) player 1
player 3, y1 = 13 y2 = 53 . Note y1 + y2 = v({1, 2}) = 2, y2 > 1 y1 > 0,
thus {1, 2}-feasible. Moreover, recall v({3}) = v({3, 4}) = v({2, 3}) = 0.
follows counterobjections 3 1 (y, {1, 2}) may constructed
coalition {2, 3, 4}. Assume (z, {2, 3, 4}) one counterobjection. player
2, belongs intersection two coalitions {1, 2} {2, 3, 4}, z2 y2 > 1
holds. constraint z2 + z3 + z4 = 3, entails z3 + z4 < 2. However,
impossible since also z3 x3 = 1 z4 x4 = 1. Thus,
possible counterobjections objection (y, {1, 2}) x. follows x
belong B(G|LC ) and, hence, B(G|LC ) = , even though X(G|LC ) 6= .
consequence, derive counterpart Proposition 2.7.(3) hold
constrained games. Indeed, may consider game G|LC defined proof
Proposition 4.4 observe that, since X(G|LC ) 6= , Proposition 4.3, know
K (G|LC ) 6= .
Corollary 4.5. constrained game G|LC (with int(LC) = ) B(G|LC ) =
K (G|LC ) 6= (and thus K (G|LC ) 6 B(G|LC )).
complete picture pertaining bargaining set, showing
core always included it. provides counterpart Proposition 2.7.(4).
Proposition 4.6. Let G|LC constrained game. Then, C (G|LC ) B(G|LC ).
Proof. Consider imputation x C (G|LC ) assume contradiction x
/ B(G|LC ).
this, must exist objection (y, S) x. Therefore, must case
S-feasible payoff vector G|LC yk > xk , k S. implies x
/ C (G|LC ):
contradiction. Thus, x B(G|LC ).
652

fiMixed-Integer Constrained Coalitional Games

Figure 1: Illustration Solution Concepts Example 4.8.
finally stress counterpart Proposition 2.7.(5) already known
work Kalai (1975), restated settings constrained games follows.
Proposition 4.7 (cf. Kalai, 1975). Let G|LC constrained game. Then, C (G|LC ) 6=
implies N (G|LC ) C (G|LC ).
4.2 Preservation Solution Concepts
continue investigation turning problem assessing whether outcome
stable (under solution concept) TU game remains stable constraints
issued. crucial issue extent imputation set affected
constraints imposed game. issue illustrated next.
Example 4.8. Consider TU game G = hN, vi N = {1, 2}, v({1, 2}) = 2,
v({1}) = v({2}) = 0. immediate check X(G) = {x R{1,2} | x1 + x2 = 2 x1
0 x2 0}. solution concepts G follows (see Figure 1 illustration):
Core. imputation x X(G) coalition {1, 2}, case
x(S) v(S). Thus, C (G) = X(G).
Bargaining Set. Since C (G) B(G) (recall Proposition 2.7) since B(G) X(G),
immediately B(G) = C (G) = X(G).
Nucleolus. Let x X(G) imputation. Considering standard excess function
TU games, either (x) = (0, x2 , x1 ) (x) = (0, x1 , x2 ),
depending whether x1 x2 x2 > x1 . Indeed, recall v({1, 2}) =
x({1, 2}) = 2 v({1}) = v({2}) = 0. Thus, lexicographically minimum excess
vector obtained imputation x x1 = x2 = 1, i.e., N (G) = {x}.
Kernel. Since N (G) K (G) (recall Proposition 2.7), x K (G). Consider
imputation x X(G) x 6= x. Assume x1 > 1 (the line
reasoning applies case x2 > 1), thus x2 < 1. standard
excess function TU games, s1,2 (x) = x1 s2,1 (x) = x2 surpluses x,
653

fiGreco, Malizia, Palopoli, & Scarcello

v({1}) = v({2}) = 0. Then, s2,1 > s1,2 holds, order x K (G),
x1 = v({1}) = 0, case, x1 > 1. follows
K (G) = {x}.
Shapley Value. Note two players G symmetric hence Shapley
value must same. Thus, (G) = (1, 1).
Now, consider constraints LC = {x1 +x2 1, x1 , x2 R}. Then, easily checked
X(G|LC ) = {x R{1,2} | x1 + x2 = 1 x1 0 x2 0}, hence X(G) X(G|LC ) = .
applying line reasoning (and considering Kalais excess function
Equation (2) nucleolus kernel), derive C (G|LC ) = B(G|LC ) = X(G|LC )
N (G|LC ) = K (G|LC ) = {y}, y1 = y2 = 12 (see, again, Figure 1).
Moreover, Shapley NTU values G|LC , note vectors = (1 , 2 )
1 = 2 = > 0 G|LC definedfor
every vector
P G|LC . fact,
= (1 , 2 ) 1 6= 2 value v|LC (N ) = sup
zi | z V (N ) infinite.
Indeed, pre-imputations players necessarily individually rational, hence
game one player may get unbounded negative value, long one gets
unbounded positive value sum 2. Now, every = (, ), worth
function TU game G|LC v|LC ({1}) = v|LC ({2}) = 0, v|LC (N ) = . Since
two players symmetric, Shapley values family games form
(G|LC ) = ( 2 , 2 ). Therefore, consequence x V |LC (N ) different ( 12 , 12 ) admits
vector = (1 , 2 ), 1 = 2 , xi = (G|LC )i players 1 2.
conclude singleton {y} also set Shapley NTU values G|LC .
Thus, solutions concepts constrained game G|LC completely unrelated
G.

Note that, example, fact solution concept preserved
chance. Indeed, recall core, bargaining set, nucleolus, kernel defined
refinements set possible imputations. Therefore, extreme scenario
X(G) X(G|LC ) = holds (for constrained game G|LC built top TU game G),
none solution concepts preserved.
Fact 4.9. Let G|LC constrained game X(G) X(G|LC ) = . Then,
(1) C (G) C (G|LC ) = ;
(2) B(G) B(G|LC ) = ;
(3) N (G) N (G|LC ) = ; and,
(4) K (G) K (G|LC ) = .
Moreover, recall Shapely NTU values refinements set possible payoff
distributions associated grand-coalition (and, particular, pre-imputations
TU games). Thus, (G) 6 VLC (N ) (as Example 4.8), solution concept cannot
preserved. general, since (G) pre-imputation, following holds.
Fact 4.10. Let G|LC constrained game, G = hN, vi. Assume VLC (N ) {x
Vv (N ) | x efficient } = . Then, (G) 6 (G|LC ).
654

fiMixed-Integer Constrained Coalitional Games

light observations, however interest analyze whether
preservation properties hold respect (pre)imputations G G|LC .
example, interest establish relationship payoff vectors
C (G) X(G|LC ) (i.e., vectors core TU gameand thus imputations
gameand also imputations constrained game) payoff vectors
C (G|LC ) X(G) (i.e., vectors core constrained gameand thus
imputations gameand also imputations TU game). Exploring
relationships, solution concept, addressed rest section.
4.2.1 Core
first result concerns core, shows imputations core
TU game satisfy constraints also core resulting constrained game.
Proposition 4.11. Let G|LC constrained game. Then, C (G) X(G|LC ) C (G|LC )
X(G).
Proof. Let G = hN, vi TU game, recall Section 2 G equivalently
viewed NTU game hN, Vv i. Assume x payoff vector C (G), hence
X(G). Then, coalition N vector Vv (S) yi > xi , S.
Definition 3.1, NTU game G|LC = hN, VLC i, case VLC (S) Vv (S),
N . Therefore, coalition N vector VLC (S)
yi > xi , S. is, x X(G|LC ), x belongs C (G|LC ).
However, inclusion strict cases, even imputation affected
constraints, i.e., even X(G) = X(G|LC ).
Proposition 4.12. exists constrained game G|LC (with int(LC) = )
X(G) = X(G|LC ), C (G) = C (G|LC ) 6= . Thus, C (G) X(G|LC ) C (G|LC ) X(G).
Proof. Consider TU game G = hN, vi N = {1, 2, 3}, v({1}) = 1, v({2}) = 1,
v({3}) = 2, v({1, 2}) = 3, v({1, 3}) = 0, v({2, 3}) = 0, v({1, 2, 3}) = 4. Notice
X(G) = {x} x1 = 1, x2 = 1, x3 = 2; C (G) = . particular,
latter equality, consider pair (y, {1, 2}) y1 = y2 = 32 . Since y({1, 2}) =
v({1, 2}), y1 > x1 y2 > x2 , (y, {1, 2}) objection x, therefore
belong C (G).
Consider following set constraints:

x1 + x2 2
LC =
x1 , x2 R
easily seen x satisfies LC. Thus, x X(G|LC ) holds Proposition 4.1. Moreover,
since (LC)[{i}] = R{i} holds player N , constraint
worths singleton coalitions, individual rationality constraint G|LC prescribes
x X(G|LC ): x1 v({1}) = 1, x2 v({2}) = 1, x3 v({3}) = 2. Since
v({1, 2, 3}) = 4, x fact imputation X(G|LC ). Thus, X(G) = X(G|LC ).
conclude proof, let us observe that, constrained game G|LC ,
{1, 2}-feasible vector z z1 > x1 z2 > x2 ; indeed, observe z1 + z2 2
holds constraints, x1 + x2 = 2. is, objection x,
therefore imputation C (G|LC ).
655

fiGreco, Malizia, Palopoli, & Scarcello

4.2.2 Bargaining Set
far bargaining set concerned, show constrained games
whose bargaining set completely unrelated underlying TU games.
objections counterobjections necessarily restricted set
possible imputations. Thus, constraints may radically alter feasibility properties
certain payoff vectors, yet without affecting imputation set. shown
following two propositions.
Proposition 4.13. exists constrained game G|LC (with int(LC) = )
X(G) = X(G|LC ), B(G) X(G|LC ) 6 B(G|LC ) X(G).
Proof. Consider TU game G = hN, vi N = {1, 2, 3, 4, 5}, v({1, 2, 3, 4, 5}) = 8,
v({2, 3, 4}) = 8, v({1, 3, 4}) = 7, v({1, 2}) = 2, v({5}) = 1, v(S) = 0
coalition N . Consider imputation x x1 = 0, x2 = 1, x3 = 3, x4 = 3,
x5 = 1. claim x B(G). Indeed, let (y, S) objection x. objection
carried three different coalitions, counterobjection:
First, = {2, 3, 4}, y2 > x2 = 1, y3 > x3 = 3, y4 > x4 = 3, y2 + y3 +
y4 v({2, 3, 4}) = 8. case (y, S) objection player 1
player 5. former case, (z, {1}) z1 = x1 = 0 trivial counterobjection
(y, S); latter case, (z, {5}) z5 = x5 = 1 counterobjection (y, S).
Second, = {1, 3, 4}, y1 > x1 = 0, y3 > x3 = 3, y4 > x4 = 3,
y1 + y3 + y4 v({1, 3, 4}) = 7. case, (y, S) objection player
player 2 player 5. observed above, (z, {5}) z5 = x5 = 1
trivial counterobjection objection 5. Thus, let us assume
(y, S) objection player 2. (y, S) objection player 3 4,
may consider pair (z, {1, 2}) z1 = y1 z2 = x2 . Indeed, note
y1 < 1 holds and, thus, z1 + z2 < 1 + x2 = 2 = v({1, 2}). Therefore, z
{1, 2}-feasible, (z, {1, 2}) counterobjection (y, S). hand,
(y, S) objection player 1 player 2 x, may consider pair
(w, {2, 3, 4}) w2 = x2 , w3 = y3 , w4 = y4 . Note y3 + y4 < 7 and,
thus, w2 + w3 + w4 < x2 + 7 = 1 + 7 = v({2, 3, 4}). Then, w {2, 3, 4}-feasible,
(w, {2, 3, 4}) counterobjection (y, S).
Finally, = {1, 2}, y1 > x1 = 0, y2 > x2 = 1, y1 +y2 v({1, 2}) = 2.
case, (y, S) objection player 3, 4, 5. Let us consider
first two cases, since (z, {5}) z5 = x5 = 1 trivial counterobjection
objections 5. (y, S) objection player 1 (against player 3 4),
may consider pair (z, {2, 3, 4}) z2 = y2 , z3 = x3 , z4 = x4 . Note
y2 < 2 and, thus, z2 +z3 +z4 < 2+x3 +x4 = 2+6 = v({2, 3, 4}) = 8. Hence, (z, {2, 3, 4})
counterobjection (y, S). (y, S) objection player 2 (against player 3
4), may consider pair (w, {1, 3, 4}) w1 = y1 , w3 = x3 , w4 = x4 .
Note y1 < 1 and, thus, w1 + w3 + w4 < 1 + x3 + x4 = 1 + 6 = v({1, 3, 4}) = 7.
Hence, (w, {1, 3, 4}) counterobjection (y, S).

656

fiMixed-Integer Constrained Coalitional Games

Consider following set constraints:

x2 + x3 + x4 7
LC =
x2 , x3 , x4 R
immediate check X(G) = X(G|LC ); indeed, individual rationality
player 5 forces x5 1; given v({1, 2, 3, 4, 5}) = 8, constraint therefore
logically implied individually rational vectors VLC (N ). However, LC plays crucial
role concerning formation coalition {2, 3, 4}. Indeed, consider objection
(y, {1, 2}) player 1 player 3 x, y1 = 12 y2 = 32 . counterobjection
(z, ) (y, {1, 2}) must = {2, 3, 4}. Thus, z2 y2 = 32 , z3 x3 = 3,
z4 x4 = 3 must hold. follows z2 + z3 + z4 > 7 and, hence, z 6 VLC (T ). Since (y, S)
justified objection, x 6 B(G|LC ).
Proposition 4.14. exists constrained game G|LC (with int(LC) = )
X(G) = X(G|LC ), B(G|LC ) X(G) 6 B(G) X(G|LC ).
Proof. Consider TU game G = hN, vi N = {1, 2, 3}, v({1}) = v({2}) = 1,
v({3}) = 0, v({1, 3}) = v({2, 3}) = 4, v({1, 2}) = 5, v({1, 2, 3}) = 3. Consider
imputation x x1 = x2 = x3 = 1. observe x
/ B(G). Indeed, consider
objection (y, {1, 2}) player 1 player 3 y1 = 1 + 12 y2 = 3 + 12
(observe y({1, 2}) = v({1, 2}). Player 3 cannot counterobject either singleton,
since v({3}) < x3 , coalition {2, 3}, since vector z R{2,3}
z2 y2 > 3 z3 x1 = 1, z({2, 3}) > 4 = v({2, 3}). follows x 6 B(G).
Consider following set constraints:

x1 + x2 4
LC =
x1 , x2 R
immediate check X(G) = X(G|LC ). Moreover, let us notice player
justified objection player 1 2 x, since counterobject singletons;
indeed, observe v({i}) = 1 = xi , {1, 2}. Consider, then, objection
(y, {1, 2}) player 1 player 3, y1 x1 = 1 y2 x2 = 1. Since, must
belong VLC ({1, 2}), y2 3 holds. Thus, pair (z, {2, 3}) z2 = 3 y2
z3 = x3 = 1 counterobjection (y, {1, 2}), z({2, 3}) = 4 = v({2, 3}).
symmetry game definition, line reasoning applies show
also player 2 justified objections player 3. Therefore, x B(G|LC ).
4.2.3 Nucleolus Kernel
Let us move analyze nucleolus kernel. case bargaining set,
preservation property holds, demonstrated next.
Proposition 4.15. exists constrained game G|LC (with int(LC) = )
X(G) = X(G|LC ) 6= , K (G) K (G|LC ) = , N (G) N (G|LC ) = (for Kalais excess
function Equation (2) page 640).

657

fiGreco, Malizia, Palopoli, & Scarcello

Proof. Consider TU game G = hN, vi N = {1, 2, 3}, v({1, 2, 3}) = 3,
v({1, 2}) = 5, v({1, 3}) = 4, v({2, 3}) = 3, v(S) = 0, coalition N .
Consider imputation x belongs K (G), consider expressions: s1,3 (x)
s3,1 (x) = (5 x1 x2 ) (3 x2 x3 ) = 2 x1 + x3 s1,2 (x) s2,1 (x) = (4 x1 x3 )
(3 x2 x3 ) = 1 x1 + x2 . Definition 2.5, get 2 x1 + x3 > 0 implies
x3 = 0, 2 x1 + x3 < 0 implies x1 = 0, 1 x1 + x2 > 0 implies x2 = 0,
1 x1 + x2 < 0 implies x1 = 0. simple algebraic calculations, relationships
together individual rationality x (i.e., x1 0, x2 0, x3 0) entail
x1 x2 = 1 x1 x3 = 2 must hold. turn, since x1 + x2 + x3 = 3, latter two
equations uniquely determine value x. particular, K (G) singleton {x}
x1 = 2, x2 = 1 x3 = 0. Moreover, since N (G) K (G) |N (G)| = 1 (see
Proposition 2.7), N (G) = K (G).
Consider following set constraints:

x1 + x2 3



x1 + x3 3
LC =
x + x3 3


2
x1 , x2 , x3 R

Notice constraints modify imputation set, is, X(G) =
X(G|LC ) 6= . Moreover, observe V |LC = Vv , v worth function game
G = hN, v v ({1, 2, 3}) = v ({1, 2}) = v ({1, 3}) = v ({2, 3}) = 3, v (S) = 0
coalitions N . this, excess function eK reported Equation (2) coincides canonical TU excess, definitions kernel NTU nucleolus NTU
coincide TU games (cf. Kalai, 1975). kernel nucleolus G|LC
G . Finally, easily checked K (G ) singleton {x } x1 = 1,
x2 = 1 x3 = 1 (and, thus, K (G ) = N (G )). follows K (G) K (G|LC ) =
N (G) N (G|LC ) = .
4.2.4 Shapley Value
Let us conclude analysis Shapley value. Below, show solution concept preserved whenever set pre-imputations modified constraints.
Proposition 4.16. Let G|LC constrained game. sets pre-imputations G
G|LC coincide, (G|LC ) = {(G)}.

Proof. Let pX(G) = {x RN | x(N ) = v(N )} set pre-imputations TU
G = hN, vi; fact, recall pX(G) contains efficient payoff vectors Vv (N ) = {x
RN | x(N ) v(N )}. Let pX(G|LC ) = {x Rn | x(N ) v(N )x (LC)[N ]x efficient}
set pre-imputations G|LC . Since pX(G) = pX(G|LC ), must case
(LC)[N ] Vv (N ) = {x Rn | x(N ) v(N )}. Therefore, VLC (N ) = Vv (N ) (LC)[N ] =
Vv (N ). coalition vector RS , consider vector x RN
xi = yi , S, xi = (v(N ) y(S))/|N \ S|, (N \ S). Note
x(N ) = v(N ) and, hence, x Vv (N ) x (LC)[N ]. Therefore, belongs (LC)[S].
Thus, (LC)[S] = RS and, hence, VLC (S) = Vv (S) (LC)[S] = Vv (S), N .
Finally, since VLC (N ) = Vv (N ) also holds (and thus VLC (S) = Vv (S), N ),
follows (G|LC ) = {(G)} (see, e.g., McLean, 2002).
658

fiMixed-Integer Constrained Coalitional Games

However, Shapley value (G) preserved general, even (G) imputation, imputation sets affected constraints.
Proposition 4.17. exists constrained game G|LC (with int(LC) = )
(G) X(G), X(G) = X(G|LC ), (G)
/ (G|LC ).
Proof. Consider TU game G = hN, vi N = {1, 2, 3}, v({1, 2, 3}) = 3,
v({1, 2}) = 4, v({1, 3}) = 3, v({2, 3}) = 3, v(S) = 0, coalition N .
simple calculations, one may compute Shapley value (G), notice (G)1 = 7/6,
(G)2 = 7/6, (G)3 = 4/6. Thus, (G) X(G).
Consider following set constraints:

x1 + x2 3
LC =
x1 , x2 R
notice modify imputation set, is, X(G) = X(G|LC ) 6= .
Indeed, inequality x1 + x2 3 logically implied worth grand-coalition
(which forces x1 + x2 + x3 3) individual rationality players (i.e., x1 0,
x2 0, x3 0). sake completeness, note constrained game G
fit hypothesis Proposition 4.16 since pX(G) 6= pX(G|LC ) (indeed, payoff
vector x x1 + x2 > 3 x(N ) v(N ) = 3 pre-imputation G G|LC ,
x1 + x2 3 satisfied).
Moreover, observe V |LC = Vv , v worth function game G =
hN, v v ({1, 2, 3}) = v ({1, 2}) = v ({1, 3}) = v ({2, 3}) = 3, v (S) = 0
coalitions N . suffices conclude (G|LC ) = {(G )} (see, e.g., McLean,
2002). However, easily checked (G ) (G )1 = (G )2 = (G )3 = 1.
Thus, (G)
/ (G|LC ).

5. Complexity Analysis
section, shall look core bargaining set (constrained) coalitional
games computational viewpoint. particular, aim shed light impact
issuing constraints w.r.t. intrinsic complexity notions, assess whether
price paid increased expressiveness constrained gamesfor sake
completeness, background notions complexity theory reported Appendix.
argue fact sensible analyze computational properties,
corresponds analyzing feasibility using concepts thesis bounded
rationality, is, decisions taken realistic agents cannot involve unbounded resources support reasoning (Simon, 1972). Moreover, worthwhile noting studying
matters might hopefully guide design effective computation algorithms.
leave future work complexity analysis solution concepts,
would interesting consider various kinds Kalais excess functions different
computational properties.
5.1 Setup Problems Analyzed
analysis follows, assume games provided characteristic function form,
i.e., deal scenarios coalition worths returned given function (von
659

fiGreco, Malizia, Palopoli, & Scarcello

Neumann & Morgenstern, 1944). instance, games discussed Example 3.4
Example 3.5 characteristic function form. Moreover, following general
framework proposed Bilbao (2000), assume input reasoning problem
consists constrained game G|LC worth function v given oracle.
particular, shall consider two types oracles:
(1) Oracles computable polynomial time size ||G|LC || game representation.
5 instance, game Example 3.4 fits framework, well game
Example 3.5, provided cost function com(S) (of establishing communication
infrastructure agents S) comes oracle computable polynomial time.
(2) Oracles computable non-deterministic polynomial time size ||G|LC ||
game representation. instance, game Example 3.5 may fit setting
cautious perspective require that, coalition S, value
v(S) = 100 com(S) actually obtained imputation. is,
add condition element x (LC) task tj ,
player ji 6= 0 (in x), i.e., task actually
performed coalition conforming costs constraints. Here,
also require course com(S) computable non-deterministic polynomial
time. Note powerful worth-functions used encode NP-complete
problems reflecting results complex algorithmic procedures, arising
allocation, scheduling routing scenarios, name few.
Let us remark framework worth function oracle computable
polynomial time encompasses settings games (implicitly) described
kind compact structures, simple calculations encodings
performed compute worth given coalitionnoticeable influential
settings type graph hypergraph games (Deng & Papadimitriou, 1994),
marginal contribution nets (Ieong & Shoham, 2005), games multi-issue domains
(Conitzer & Sandholm, 2004), weighted voting games (Elkind & Pasechnik, 2009;
Elkind, Goldberg, Goldberg, & Wooldridge, 2009). Therefore, membership results
immediately carry various classes games cited above, whereas hardness results
specific oracle setting, hold general (sub)settings.
Within setting discussed above, shall next focus checking whether given
imputation satisfies conditions needed core bargaining set. Thus,
given constrained game G|LC vector x, following problems considered:
Core-Check: x C (G|LC )?
BargainingSet-Check: x B(G|LC )?
addition, recall Section 4 core bargaining set might empty
constrained games. Thus, sensible well study following problems:
5. usual, implicitly assumed game representation includes list players, that,
every coalition S, ||S|| ||G|LC ||. Otherwise, one formally say, e.g., oracles
computable polynomial time combined size G|LC S.

660

fiMixed-Integer Constrained Coalitional Games

Problem

Constrained

Constrained
(int(LC) {xi |i N })

Constrained
(int(LC) = )

TU

Core-Check
BargainingSet-Check
Core-NonEmptiness
BargainingSet-NonEmptiness

DP -complete
P
2 -complete
P
2 -complete
P
3 -complete

co-NP-complete
P
2 -complete
P
2 -complete
P
3 -complete

co-NP-complete
P
2 -complete
P
2 -complete
P
3 -complete

co-NP-complete
P
2 -complete
co-NP-complete
trivial

Figure 2: Complexity Results Constrained Games. Hardness results hold even cohesive games worth functions given polynomial-time oracles. Membership
results hold non-deterministic polynomial-time worth-function oracles, without assumption representation real numbers.

Core-NonEmptiness: C (G|LC ) 6= ?
BargainingSet-NonEmptiness: B(G|LC ) 6= ?
Overview Results. summary results reported Figure 2. Note
four settings emerge analysis: TU games, constrained games without integer
variables (i.e., int(LC) = ), constrained games without auxiliary integer variables (i.e.,
int(LC) {xi | N }), arbitrary constrained games. fact, stress hardness
results established without use auxiliary real variables, membership results
(for constrained games) hold even variables kind actually occur. Thus, auxiliary
real variables play computational role setting constrained games.
Concerning checking problems, Figure 2 evidences Core-Check co-NPhard TU games, co-NP constrained games auxiliary integer variables
allowedas said above, bound membership result number
considered auxiliary real variables. allowing use auxiliary integer variables,
Core-Check becomes DP -hard, fact complete class. Thus, auxiliary integer
variables cause slight increase complexity solution concept. hand,
emerged occurrence real variableseither player variables auxiliary ones
integer player variables completely immaterial computational perspective.
far BargainingSet-Check concerned, deliver good news
adding constraints alter complexity w.r.t. TU case. Indeed, problem
P
P
2 -hard TU games, 2 whichever constraints considered.
Concerning non-emptiness problems, show instead constraints may radically
alter computational properties. Indeed, CoreNonEmptiness raises one level
polynomial hierarchy, co-NP absence constraints (Malizia, Palopoli, &
Scarcello, 2007) P
2 , BargainingSet-NonEmptiness trivial TU games
(since concept always non-empty there), becomes P
3 -complete constrained
games. Interestingly, cases, auxiliary integer variables play role.
Indeed, hardness results established basic case int(LC) = (and without
auxiliary variables), membership results hold arbitrary constraints.
following, hardness results shown hold simplest case
(deterministic) polynomial-time worth-function oracles. Moreover, membership results
assume a-priori bound representation size real numbers. end,
661

fiGreco, Malizia, Palopoli, & Scarcello

non-trivial technical matters faced next, show algorithms safely work
polynomially many bits, solution concept considered paper.
5.2 Hardness Results (on Cohesive Games Polynomial-Time Oracles)
section, shall establish hardness results. particular, order highlight
intrinsic difficulty associated solution concepts, constructions reported
kinds worth functions simple computational viewpoint,
given via oracles computable polynomial time, also algebraic
viewpoint, induce cohesive games.
recall (TU) game cohesive
worth function v that,
P
partition players N , v(N ) SS v(S) holds (Osborne & Rubinstein, 1994)a
condition often imposed order guarantee grand-coalition actually forms. Note
earlier proofs complexity results compactly specified games (see, e.g., Deng &
Papadimitriou, 1994; Greco, Malizia, Palopoli, & Scarcello, 2009b; Ieong & Shoham, 2005)
generally exploit constructions games cohesive and, hence,
entail hardness results stated paper. fact, results interestingly show
cohesivity simplify reasoning solution concepts coalitional games.
order establish hardness results, exploit number reductions refer
Boolean formulae. Let Boolean formula, let vars() = {W1 , . . . , Wn } set
Boolean variables occurring . Recall literal either Boolean variable Wi
negation Wi . former called positive literal, latter called negative
literal. denote vars() = {Wi | Wi vars()} set negative literals
variables occurring . Literals associated game players proofs.
set players S, define (S) truth assignment Wi vars() true Wi
occurs S, false, otherwise. fact (S) satisfies denoted (S) |= .
Moreover, say coalition vars()vars() consistent w.r.t. set variables
vars() if, Wi , |{Wi , Wi } S| = 1 holds. case = vars(),
simply say consistent.
start demonstrating hardness results various membership-checking problems. first result co-NP-hardness Core-Check, established
basis rather standard arguments reported sake completeness.
particular, reader may find useful check reduction exploited proof
based games cohesive, makes different earlier complexity results
given literature specific kinds compactly specified games.
Theorem 5.1. Core-Check co-NP-hard, even cohesive TU games polynomialtime oracles input vector imputation.
Proof. Recall deciding whether Boolean formula variables X1 , . . . , Xn
satisfiable, i.e., deciding whether exists truth assignment variables
making true, co-NP-complete problem (Johnson, 1990).
Given formula , build polynomial time TU game G() = hN, vi,
N = vars() {w, e} where, set players S, v that:

1 = N,
v(S) =
1 e
/ w (S) |= ,

0 otherwise.
662

fiMixed-Integer Constrained Coalitional Games

Consider, now, vector x xe = 1 xp = 0 player p, note
x imputation. claim that: x C (G()) satisfiable.
() x C (G()) implies coalition S-feasible payoff vector
yi > xi , S. Consider coalition/assignment e
/
w S, observe x(S) = 0. Since x C (G()), must v(S) = 0,
entails (S) satisfy , definition worth function. Given
one-to-one correspondence coalitions (with e
/ w S)
truth assignments , conclude satisfiable.
() x
/ C (G()), must exist coalition N x(S) < v(S),
possible x(S) = 0 v(S) = 1. construction worth function,
follows N , e
/ S, w (S) |= . is, satisfiable.
Finally, observe role player w guarantee game cohesive.
Indeed, partition N , one set contains w, hence
may get 1 coalition worth.
considering constrained games arbitrary input vectors (i.e., necessarily
imputations), Core-Check turns slightly difficult previous
case. fact, stress use auxiliary integer variables crucial order
establish result illustrated next.
Theorem 5.2. Core-Check DP -hard, even cohesive constrained games polynomial-time oracles.
Proof. Given pair Boolean formulae (, ), deciding whether satisfiable
satisfiable prototypical DP -complete problem (Johnson, 1990). Assume, w.l.o.g.,
= c1 . . .cm , ci = ti,1 ti,2 ti,3 , {1, . . . , m}. is, conjunctive
normal form every clause contains exactly three literals. Moreover, let vars( ) =
{Y1 , . . . , } vars() = {X1 , . . . , Xn }, assume w.l.o.g. vars() vars( ) = .
Consider TU game G() = hN, vi built proof Theorem 5.1, recall
N = vars() {w, e} vector x (where xe = 1 xp = 0, player
p N p 6= e) belongs C (G()) satisfiable.
Consider following set constraints:

1 TYj 0, j {1, . . . , }



(ti,1 ) + (ti,2 ) + (ti,3 ) 1, {1, . . . , m}
LC =
x R, p N


p
TYj Z, j {1, . . . , }

(ti,h ) denotes expression 1 Tti,h ti,h negative literal, expression
Tti,h ti,h positive literal. Note players N actually constrained LC.
Therefore, (LC) = , (LC)[N ] = trivially holds (since (LC)[N ] restriction
empty set RN ). Otherwise, i.e., (LC) 6= , (LC)[N ] = RN therefore
constraints immaterial. course, (LC) = , imputation
G()|LC ; otherwise, solution concepts G() preserved G()|LC , since
constraints play role case.
663

fiGreco, Malizia, Palopoli, & Scarcello

Observe that, j {1, . . . , }, TYj constrained domain {0, 1}
encode truth value Boolean variable Yj . Clearly, LC computed
polynomial time , immediate check (LC) 6=
satisfiable. follows vector x core G()|LC x belongs
core G() (i.e., satisfiable) (LC) 6= (i.e., satisfiable).
turn study bargaining set. Notice class graph games
(which instance general framework considering here) completeness
BargainingSet-Check P
2 recently established Greco et al. (2009b).
Clearly enough, result already implies BargainingSet-Check P
2 -hard
TU games polynomial-time oracles. Below, show hardness result still
holds games polynomial-time oracles moreover cohesive.
Theorem 5.3. BargainingSet-Check P
2 -hard, even cohesive TU games
polynomial-time oracles input vector imputation.
Proof. show polynomial-time reduction problem deciding whether quantified Boolean formula H = Y1 , . . . , Yn Z1 , . . . , Zq valid, well-known P
2complete problem (Johnson, 1990). Let = {Y1 , . . . , Yn } Z = {Z1 , . . . , Zq } denote
sets universally existentially quantified variables, respectively.
Based H, build game G(H) = hN, vi, N = vars() vars() {a, }
where, set players S, v that:

2 = N,



1 |S| = n consistent w.r.t. {Y1 , . . . , Yn },
v(S) =
1 consistent, |{a, } S| = 1, (S) |= ,



0 otherwise.
Let x imputation xa = xa = 1 xp = 0, player p.
construction G(H) x defined guarantee two basic properties,
intuitively illustrated next:

(1) Recall objection (y, S) player player j x S,
j
/ S, y(S) v(S) yk > xk , k S. Since v(S) > x(S) must hold
objection (y, S), case objections one-to-one associated truth
assignments variables Y; indeed, v(S) = 1 (and x(S) = 0).
Let (Y \ S) truth assignment associated coalition S.
(2) Recall counterobjection (z, ) objection (y, S) player player j
x
/ , j , z(T ) v(T ), zk yk , k S, zk xk ,
k \ S. (y, S) objection player j
/ {a, }, (z, {j})
zj = 0 trivial counterobjection. hand, counterobjections (z, )
objections (y, S) necessarily = , z(T )
1 xa = xa = 1. particular, z(T ) = 1 must hold. Thus, counterobjections
one-to-one associated possible satisfying truth assignments
variables H, moreover obtained extensions assignment (Y \ S).

664

fiMixed-Integer Constrained Coalitional Games

Definition 2.3, x bargaining set G(H) objection
(i.e., assignment (Y \ S) variables Y), counterobjection (i.e., satisfying
assignment obtained extending (Y \ S)). Therefore, following claim holds, whose
formal proof reported Appendix:
Claim A. x B(G(H)) H valid.
conclude proof, note game cohesive. Indeed, coalition
v(S) = 1, case |S {Y1 , . . . , Yn , Y1 , . . . , Yn }| = n. Thus, given three
coalitions S1 , S2 S3 v(S1 ) = v(S2 ) = v(S3 ) = 1, must case two
overlap players. Therefore, partition N contains two
coalitions getting worth greater 0, result follows since v(N ) = 2.
remainder section prove hardness results non-emptiness problems.
start showing adding constraints game causes complexity nonemptiness problem core raise one level polynomial hierarchyfrom
co-NP absence constraints (Malizia et al., 2007) P
2 . Note proof
below, integer auxiliary variables play role.
Theorem 5.4. Core-NonEmptiness P
2 -hard, even cohesive constrained games
polynomial-time oracles, integer auxiliary variables allowed.
Proof. Deciding whether quantified Boolean formula F = X1 , . . . , Xn Y1 , . . . , Yq
valid well-known P
2 -complete problem (Johnson, 1990).
Based F , build polynomial time game G(F ) = hN, vi, N = vars()
vars() {a} where, set players S, v that:

3 n = N,
v(S) =
n
consistent (S) 6|= ,

0
otherwise.

addition, build polynomial time set LC that, 1 n, contains
following constraints:

xXi + xXi = 1




x Xi 0



xXi 0
LC =
xa = 2 n





,x R
x

Xi Xi
xa R
First, note LC forces xXi + xXi = 1, forces xa take value 2 n. Thus, since
v(N ) = 3 n, imputation x constrained game G(F )|LC distribute
worth players associated variables {Y1 , . . . , Yq }. imputation x
associated assignment (x) variables {X1 , . . . , Xn } Xi true
(x) xXi < 1note associating 1 false, here.
understand salient features reduction, recall objection (y, S)
imputation x VLC (S) yk > xk k S. Since y(S) > x(S)
holds, take care coalitions N consistent (S)
satisfying truth assignment. Recall VLC (S) = {x RS | x(S) v(S)} (LC)[S];
665

fiGreco, Malizia, Palopoli, & Scarcello

thus, objection (y, S) Xi (resp., Xi S), yXi 1 (resp.,
yXi 1). Therefore, cannot include players {X1 , X1 , ..., Xn , Xn } getting worth 1
x. follows set possible objections (y, S) imputation x corresponds
superset truth assignments (S) satisfying extensions
(x). correspondence allows us establish following result (whose formal proof
deferred Appendix).
Claim B. C (G(F )|LC ) 6= F valid.
conclude proof, notice G(F )|LC cohesive. Indeed, coalition
v(S) = n must consistent, thus |S (vars() vars())| = n + q. Therefore, given
three coalitions S1 , S2 S3 v(S1 ) = v(S2 ) = v(S3 ) = n, must case
two overlap players. follows partition N contains
two coalitions getting worth n.
non-emptiness problems bargaining set trivial TU games, since
concept always non-empty there. longer case constrained games,
problem turns quite difficult. proof Theorem 5.4, integer
auxiliary variables play role result shown below.
Theorem 5.5. BargainingSet-NonEmptiness P
3 -hard,even cohesive constrained
games polynomial-time oracles,and integer auxiliary variables allowed.
Proof. Deciding validity formula P = X1 , . . . , Xm Y1 , . . . , Yn Z1 , . . . , Zq
well-known P
3 -complete problem (Johnson, 1990).
Based P , build polynomial time game G(P ) = hN, vi, N = vars()
vars() {a, w} where, set players S, v that:


+ 1 = N


1
w |S| = n + 1




consistent w.r.t. {Y1 , . . . , Yn },

v(S) =
1
= {Xi , Xi },


1
\ {a} consistent





(S) |= ,


0
otherwise.
also build polynomial time set LC that, 1 m, contains following
constraints:

xXi + xXi = 1




x Xi 0



xXi 0
xa = 1




xXi , xXi R

xa R

First, observe that, constraints fact v(N ) =
m+1, imputation game players Yj , 1 j n, players Zr , 1 r q,
get payoff 0. Moreover, imputation x index i, 1 m,
xXi > 0 xXi > 0 cannot belong bargaining set G(P )|LC , objection
666

fiMixed-Integer Constrained Coalitional Games

1
(y, {w, Y1 , ..., Yn }) player yYj = n+1
justified. Indeed, (z, )
counterobjection , would za xa = 1 (indeed, xa = 1 prescribed
LC). Moreover, definition worth function, would
\ {a} consistent, i.e., {1..., m}, |T {Xi , Xi }| = 1. Assume Xi
(the line reasoning applies Xi ). Then, zXi xXi > 0 must hold
would z(T ) > 1, impossible since v(T ) 1 since v(T ) z(T ) holds
counterobjection. Thus, set imputations x might possibly belong
bargaining set restricted variables xXi xXi take distinct values
set {0, 1}. result, associate imputation x constrained game
G(P )|LC assignment (x) variables {X1 , . . . , Xm } Xi true
(x) xXi = 0. Note associating 0 true here.
fact, order show correctness reduction, may basically follow
spirit proof Theorem 5.4. imputation x (with properties illustrated
above), set possible objections (y, S) corresponds set possible truth
assignments (Y \ S) variables = {Y1 , ..., Yn }. Objections might
possibly justified restricted player a, counterobjections
correspond satisfying assignments extending (x) (Y \ S). Thus, following
shown, whose detailed proof reported Appendix.

Claim C. B(G(P )|LC ) 6= P valid.
Finally, note game cohesive. Indeed, consider partition players
N , coalition v(S) = 1. case consistent
w.r.t. vars(), cannot exist coalition v(S ) = 1
= {Xi , Xi } i. addition, exist one coalition
SP
v(S ) = 1 (for |S | = n + 1, w , consistent w.r.t. {Y1 , . . . , Yn }).
Thus, SS v(S) 2. Similarly,
P coalition
consistent w.r.t. vars(), SS v(S) + 1. Indeed, might contain coalitions
{X1 , X1 }, . . . , {Xm , Xm }, plus one coalition consistent w.r.t. {Y1 , . . . , Yn }
gets worth 1. particular, cannot contain two coalitions consistent
w.r.t. {Y1 , . . . , Yn } v(S ) = v(S ) = 1, w contained both.
5.3 Membership Results
complete picture complexity arising context constrained games
proving membership results that, together proofs previous section, provide
completeness results reported Figure 2. particular, shall consider case
worth function v oracle computed deterministic polynomial time
size ||G|LC || constrained game, deferring discussion
results extended case v oracle computable non-deterministic
polynomial time Section 5.3.1.
start analysis stating complexity checking whether vector
imputation.
Lemma 5.6. Deciding whether vector imputation DP constrained games.
particular, problem co-NP constrained games without auxiliary integer
variables, P constrained games without integer variables.
667

fiGreco, Malizia, Palopoli, & Scarcello

Proof. Let G = hN, vi TU game let LC set constraints. Let x vector
assigning payoff value player N . Recall x imputation X(G|LC )
if: (1) x VLC (N ) = {x RN | x(N ) v(N )} (LC)[N ]; (2) x efficient; (3) x
individually rational.
(1) Checking whether x(N ) v(N ) feasible polynomial time. Moreover, checking
whether x (LC)[N ] feasible NP. Indeed, consider set linear
inequalities LC derived LC replacing player variables values according x. Note LC mixed integer linear program defined variables
(if any) real (LC) int(LC) \ {xi | N }, x (LC)[N ] LC
satisfiable. well-known results mixed integer linear programming (see, e.g.,
Nemhauser & Wolsey, 1988), LC admits solution admits solution
represented polynomially many bits (in size LC ). Thus,
problem solved first guessing NP vector x assigning value
variable real (LC) int(LC) \ {xi | N }, subsequently checking whether x
satisfies constraints LC (which feasible polynomial time). course,
int(LC) {xi | N }, LC linear program without integer variables.
special case, satisfiability LC checked P (see, e.g., Papadimitriou &
Steiglitz, 1998).
(2) Recall x efficient x VLC (N ), player N
xi xi . Consider set linear inequalities LC derived LC adding
|N | + 1 inequalities: x(N ) v(N ), xi > xi N . Then, x efficient
LC satisfiable. latter task feasible co-NP, since LC
mixed integer linear program whose satisfiability checked NPsee (1).
special case int(LC) = , LC contain integer variables and, hence,
(un)satisfiability checked polynomial time.
(3) Recall x individually rational player N , xi max{ xi | xi
VLC ({i}) }. Consider set linear inequalities LC
derived LC adding
two inequalities xi v({i}) xi > xi . individual rationality holds
LC
satisfiable, N . point (2) above, task feasible
co-NP general, polynomial time whenever int(LC) = .
conclude deciding whether x imputation conjunction
problem (1), feasible NP, problems (2) (3), feasible
co-NP. Thus, problem DP .
case int(LC) {xi | N } holds, (1) feasible polynomial time and,
hence, deciding whether x imputation co-NP.
Finally, int(LC) = , problems (1), (2), (3) feasible polynomial time.
Let us consider membership Core-Check. proof routine
reported sake completeness only.
Theorem 5.7. Core-Check DP . particular, co-NP constrained
games without auxiliary integer variables.

668

fiMixed-Integer Constrained Coalitional Games

Proof. Let x input vector game G|LC , G = hN, vi. check
x satisfies conditions core x indeed imputation.
Concerning former task, recall complementary problem deciding whether
x core amounts finding coalition vector x VLC (S)
xi > xi , S. Consider set linear inequalities LCS derived LC adding
|S| + 1 inequalities x(S) v(S), xi > xi S. Then, x core
coalition LCS satisfiable. task therefore solved guessing
NP coalition together vector x assigning value variable LCS ,
subsequently checking x indeed satisfy constraints LCS . follows
deciding whether x satisfies conditions core feasible co-NP.
Concerning task checking whether x imputation, use results
Lemma 5.6. Thus, general games, Core-Check solved conjunction
problem co-NP problem DP . course, problem feasible DP .
Moreover, int(LC) {xi | N } holds, Core-Check feasible co-NP.
Deriving membership result BargainingSet-Check constrained games requires sophisticated line reasoning. start recalling that, TU games,
shown BargainingSet-Check P
2 (Greco et al., 2009b). fact,
result established exploiting characterization bargaining set
hold presence constraints. Below, exploiting completely different
proof technique, shall show that, surprisingly, presence constraints
alter computational properties problem.
following proofs, recall given set LC linear (in)equalities n
real variables, set (LC) polyhedron Rn , whose faces given halfspaces
associated (in)equalities LC, whose vertices given intersection n
inequalities LC, hence represented polynomially many bits size
LC (see, e.g., Papadimitriou & Steiglitz, 1998; Nemhauser & Wolsey, 1988). bounded
polyhedron called polytope. Moreover, use following notation. Let N
set players let yS set variables {yk | k S}. denote LCyS copy
system mixed-integer linear inequalities LC every player variable xi ,
S, renamed yi , every variable v LC renamed vyS .
Lemma 5.8. Let G = hN, vi TU game, LC set constraints, x
imputation G|LC belong B(G|LC ). Then, exists justified objection
x representable polynomially many bits.
/ S,
Proof. Since x
/ B(G|LC ), two players j, coalition j
S-feasible vector (y, S) justified objection j x. Let
LCi,j,S system consisting (in)equalities LCyS plus |S| + 1 inequalities:
y(S) v(S) yk > xk , k S. Then, set (LCi,j,S )[yS ] consists S-feasible
vectors (y, S) objection j x.
Let us consider possible candidate counterobjections. N j

/ , let LCi,j,S,T system including (in)equalities LCyS LCzT , plus
inequalities y(S) v(S), yk > xk , k S, z(T ) v(T ), zk yk , k S,
zk xk , k \ S. Note (LCi,j,S,T )[yS ] contains vectors index set
exists counterobjection , hence form (z, ),
669

fiGreco, Malizia, Palopoli, & Scarcello

Figure 3: Illustration Claim D, coalitions T1 , T2 , T3 .
objection (y, S) j x. follows set vectors (y, S)
justified objection j x set:
[
(LCi,j,S )[yS ] \
(LCi,j,S,T )[yS ].
|iT
/ jT

conclude proof claim following.

i,j,S,T )[y ] contains point (i.e., justified obClaim D. (LCi,j,S )[yS ] \ |iT

/ jT (LC
jection x) represented polynomially many bits.
prove claim, let us consider following geometrical arguments: Consider first
case LCi,j,S LCi,j,S,T (for |
/ j ST ) contain integer variables,
i,j,S,T )[y ].
let P maximal convex subset (LCi,j,S )[yS ] \ |iT

/ jT (LC

vertices P , points R , given intersection |S| (independent) halfspaces facets (LCi,j,S )[yS ] (LCi,j,S,T )[yS ], thus
represented polynomially many bits. fact, P might contain
boundaries. Thus, vertices actually belongs P , result straightforwardly holds. hand, P possibly open segment endpoints b
(representable polynomially many bits), middle point ym necessarily belongs
P (since P convex) represented polynomially many bits. Finally,
polytope P two vertices (as shown Figure 3), must
least three vertices , b , c belong face P . Therefore,
barycenter triangle vertices , b , c belongs P ,
represented polynomially many bits, case , b , c .
670

fiMixed-Integer Constrained Coalitional Games

conclude proof, observe integer variables LCi,j,S LCi,j,S,T (for
|
/ j ) easily preprocessed. Roughlythe technical details
reported Appendix, since (LCi,j,S )[yS ] polytope construction LCi,j,S
since, therefore, vertices represented polynomially many bits, integer
components interest (basically falling within (LCi,j,S )[yS ]) represented
polynomially many bits, well. Thus, find point polynomially many bits
asked Claim D, iterate possible combinations
integer values

i,j,S
i,j,S,T )[y ]
and, step, evaluate expression (LC
)[yS ] \ |iT

/ jT (LC
replacing integer values combination values hand. course, resulting
expression involve integer variables, inequalities still representable
polynomially many bits, therefore line reasoning applies.
Armed lemma, state complexity BargainingSet-Check.
Theorem 5.9. BargainingSet-Check P
2.
Proof. show complementary problem deciding whether vector x
bargaining set given constrained game G|LC P
2 . start checking whether
x imputation DP (cf. Lemma 5.6)recall DP contained P
2 .
case, Lemma 5.8 guess non-deterministic polynomial time justified objection
x, is, coalition S, two players j
/ S, vector (y, S)
objection j x. Consider system LC (in)equalities obtained
LCi,j,S (recall definition proof Lemma 5.8) replacing player variables
associated coalition respective values y. course, (y, S) objection
LC satisfiable. well-known results mixed integer linear programming
(see, e.g., Nemhauser & Wolsey, 1988), LC admits solution admits
solution represented polynomially many bits. Therefore, within
non-deterministic step, also guess assignment (call w ) variables
LC , check polynomial time w actually satisfies constraints (i.e.,
actually objection).
conclude algorithm solving BargainingSet-Check, check
counterobjection (z, ) objection (y, S) j x. task
requires co-NP oracle call. particular, oracle works checking complementary
condition NP. end, non-deterministic step, first guesses coalition
j
/ . Consider system LC including (in)equalities LCzT , plus
inequalities z(T ) v(T ), zk yk , k S, zk xk , k \ S. Then,
counterobjection (z, ) (y, S) vector z LC satisfiable.
case above, solution LC guaranteed exist represented
polynomially many bits, solution (call w ) guessed within
non-deterministic step oracle. fact, check w actually satisfies LC
trivially feasible polynomial time.
turn analyze non-emptiness problems. start non-emptiness
core, co-NP-complete problem TU games (Malizia et al., 2007).
Constraints play role here, since shown Core-NonEmptiness P
2hard (cf. Theorem 5.4). Below, confirm exact complexity problem.

671

fiGreco, Malizia, Palopoli, & Scarcello

Theorem 5.10. Core-NonEmptiness P
2.
Proof. Let us adopt notation used proof Lemma 5.8. Let N
coalition, LCS set mixed-integer linear (in)equalities including (in)equalities
LCxN LCyS , plus inequalities y(S) v(S) yi > xi , S. get:
[
C (G|LC ) = X(G|LC ) \
(LCS )[xN ].
SN

Let LCX set (in)equalities LCxN plus inequality x(N ) v(N ). Moreover,
player i, let LCi set (in)equalities LCxN LCy , plus inequalities
{i}

x(N ) v(N ) xi < yi v({i}). Then, set (LCi )[xN ] consists vectors
individually rational (w.r.t. player i). Thus,

C (G|LC ) =

X

(LC )[xN ] \

[



!

(LC )[xN ]



\

[

(LCS )[xN ].

SN

particular, note efficiency condition imputations guaranteed. Indeed,
points efficient removed, belong set (LCN )[xN ],
considered = N .
applying line reasoning Claim (in Lemma 5.8)
expressions, that, C (G|LC ) empty, contains imputation
representable polynomially many bits. Thus, decide non-emptiness
core first guessing NP vector x. Then, may call DP oracle (corresponding
invocation NP co-NP oracle) check x imputation (cf.
Lemma 5.6), finally verify x core call co-NP
oracle. particular, latter oracle works checking complementary condition
NP, i.e., checks whether x core. end, oracle guesses nondeterministic step coalition S. Consider system LC formed (in)equalities
LCyS plus |S| + 1 inequalities: y(S) v(S) yk > xk , k S. Then,
objection (y, S) x vector LC satisfiable. Again, LC admits
solution admits solution represented polynomially many
bits. Therefore, within non-deterministic step, also guess assignment
(call w ) variables LC , check polynomial time w actually
satisfies constraints.
Now, complete picture bargaining set.
Theorem 5.11. BargainingSet-NonEmptiness P
3.
Proof. Consider setting proof Lemma 5.8. Let j two players
N . coalition j 6 S, let LCi,j,S system consisting
(in)equalities LCxN LCyS plus |S| + 1 inequalities: y(S) v(S) yk > xk ,
k S. Moreover, pair sets players \ j \ S,
let LCi,j,S,T system mixed integer inequalities including inequalities
systems LCxN , LCyS , LCzT , plus inequalities y(S) v(S), yk > xk k S,
672

fiMixed-Integer Constrained Coalitional Games

z(T ) v(T ), zk yk k S, zk xk k \ S. is,
proceed way proof Lemma 5.8, components vector
x variables linear program, previous lemma fixed values.
Observe (LCi,j,S,T )[xN yS ] contains pairs hx, yi exists
counterobjection (z, ) objection (y, S) j x, (LCi,j,S )[xN yS ]
consists pairs hx, yi S-feasible vector j 6
(y, S) objection x. Then, set
[
(i, j, S) = (LCi,j,S )[xN yS ] \
(LCi,j,S,T )[xN yS ]
|iT
/ jT

set pairs hx, yi (y, S) justified objection j x.
Therefore,
[
B(G|LC ) = X(G|LC ) \
(i, j, S)[xN ],
SN iSj
/

where, considering efficiency individual rationality (see notation proof
Theorem 5.10),
[
(LCi )[xN ].
X(G|LC ) = (LCX )[xN ] \ (LCN )[xN ] \


slightly adapting proof Claim (in Lemma 5.8), one may show
bargaining set empty, exists vector x B(G|LC ) represented
polynomially many bits. Therefore, BargainingSet-NonEmptiness solved
first guessing non-deterministic polynomial time vector x. Then, may call
DP oracle check x imputation (cf. Lemma 5.6), finally verify
x indeed bargaining set call P
2 oracle, order solve
BargainingSet-Check input x (cf. Theorem 5.9).
5.3.1 Extension General Worth Functions
membership results above, assumed worth functions polynomial-time computable and, within setting, shown various hardness results
indeed tight. Thus, reader might inclined believe that, considering
powerful worth functions, complexity problems may consistently increase. Surprisingly, case. Indeed, show nothing paid
powerful worth functions encode NP-complete problems considered.
end, let vG|LC denote worth function game G|LC , define worthfunction graph class C constrained games set tuples WC = {h(G|LC , S), wi |
G|LC C vG|LC (S) = w}. Recall, e.g., work Johnson (1990),
function computable non-deterministic polynomial time integer k
WC (i) k-balanced, i.e., ||w|| (||G|LC || + ||S||)k , (ii) k-decidable, i.e.,
non-deterministic Turing machine decides whether given tuple belongs WC
O(||t||k ) time. precisely, since vG|LC partial (standard) single-valued function
(multi-valued functions also considered literature), class functions
consider called NPSV (see, e.g., Selman, 1994).
673

fiGreco, Malizia, Palopoli, & Scarcello

complexity various solution concepts TU games within setting worth
functions given oracles computable NPSV analyzed extended
version work Greco et al. (2009b). There, emerged membership
results Figure 2 hold class C games worth functions. roughly,
basic observation consider NPSV worth-functions, non-deterministic
algorithm guesses polynomial-time coalition game G|LC C,
time (with polynomial-time delay) guess worth w additional
string c (of polynomial size w.r.t. ||G|LC || + ||S||), acts certificate decide
whether tuple h(G|LC , S), wi belongs NP set WC . Thus, complexity
(non-deterministic) algorithm uses value vG|LC (S) guess coalition
affected replacing polynomial-time worth-functions NPSV worth-functions.
exploiting line reasoning, easy adapt proofs membership results order
deal general worth functions.
Theorem 5.12. membership results Figure 2 hold class C games whose
worth functions NPSV.

6. Discussion Conclusion
Imposing linear constraints outcomes games approach explored
several authors context non-cooperative strategic games (e.g., Charnes, 1953;
Semple, 1997; Ryan, 1998). However, context cooperative games approach
received considerably less attention and, indeed, general framework proposed
literature analysis properties conducted far.
paper, faced issue conducting systematic study constrained
games within framework constraints defined mixed-integer linear (in)equalities imposed underlying TU game. Seemingly close class constrained
games class linear programming games (see, e.g., Owen, 1975), worth
v(S) coalition implicitly given linear program (e.g., maximum
given objective function feasible region (LC) defined terms set linear
(in)equalities LC). course, approach differs setting constrained games
role LC is, instead, govern distribution worths within NTU
perspective. Moreover, differently classical NTU formalizations, constrained games
allow define non-convex non-comprehensive sets worth distributions,
appealing modeling capability emerged useful several application domains.
Finally, resulting game framework analyzed respect preservation
computational properties relevant solution concepts.
worthwhile noticing framework discussed paper shares
spirit recent arguments Shoham (2008), advocated use broader vocabulary fairly terse one characterizing early foundations game theory. Also
relevant proposals reconsidered basic concepts cooperative games
light modeling perspective closer requirements computer science applications: seminal influential directions type give rise, particular, coalitional
skill games (Bachrach & Rosenschein, 2008), qualitative coalitional games (Wooldridge &
Dunne, 2004), coalitional resource games (Wooldridge & Dunne, 2006), Bayesian coalitional
games (Ieong & Shoham, 2008), multi-attribute coalitional games (Ieong & Shoham, 2006),
674

fiMixed-Integer Constrained Coalitional Games

temporal qualitative coalitional games (Agotnes, van der Hoek, & Wooldridge, 2006),
cooperative Boolean games (Dunne, van der Hoek, Kraus, & Wooldridge, 2008).
light approaches, interesting avenue research may consider
expressive kinds constraints, formulated instance via logic-based languages,
preference criteria adopted place hard constraints.
avenues research related technical questions explored
paper. First, complexity analysis focused notions core
bargaining set, founded concepts objections counterobjections.
course, would interesting complement results analysis kernel,
nucleolus, Shapely value. Actually, hardness results kernel nucleolus
TU (graphical) games recently illustrated Greco et al. (2009b), indeed
trivially provide lower bounds complexity solution concepts
setting constrained games. However, providing tighter computational bounds requires
deeper understanding computational aspects underlying Kalais axiomatization,
outside scope paper. Furthermore, Shapley value, interest
study extensions provided literature NTU games
assess behavior applied constrained games.
Moreover, hardness results shown hold even restricting underlying TU games use cohesive worth functions only. might interest study
complexity different specific kinds functions considered (for instance, monotone,
superadditive, weakly superadditive, convex ones6 ). Similarly, assessing extent
considering specific kinds worth functions affects analytical properties studied
Section 4 interesting question leave research.
Finally, modeling viewpoint, recall framework proposed paper
exploits one set linear (in)equalities constrain outcomes coalitions. Thus,
light adding modeling power framework, might interest study natural generalization coalition equipped specific set linear (in)equalities.
particular, setting would call conceiving suitable mechanisms compactly represent (exponentially many) different sets constraints, defining formal measures
expressivity compact representations constraint-based NTU games.
Acknowledgments
coalitional game framework dealing linear constraints imposed TU games
first illustrated authors extended abstract published proceedings
8th International Conference Autonomous Agents Multiagent Systems (Greco,
Malizia, Palopoli, & Scarcello, 2009a). There, solution concepts defined
studied, based proposing ad-hoc adaptations solution concepts
TU games. Following suggestions anonymous referees, constrained game
framework proposed present paper fits instead framework NTU games,
general form. Thus, solution concepts studied paper given
suitable specializations standard solution concepts defined NTU games.
6. worth function v : 2N 7 R monotone v(S) v(T ) holds, pair coalitions S, N
; v superadditive v(S ) v(S) + v(T ) holds, pair coalitions S, N
= ; v weakly superadditive v(S {i}) v(S) + v({i}), N N \ S; v
convex v(S ) + v(S ) v(S) + v(T ), S, N (see, e.g., Peleg & Sudholter, 2007).

675

fiGreco, Malizia, Palopoli, & Scarcello

Appendix A. Computational Complexity
appendix recall basic definitions complexity theory, referring
reader work Johnson (1990) topic.
A.1 Complexity Decision Problems: P, NP, co-NP
Decision problems maps strings (encoding input instance fixed alphabet,
e.g., binary alphabet {0, 1}) set {yes, no}. class P set decision
problems solved deterministic Turing machine polynomial time
respect input size, is, respect length string encodes
input instance. given input x, size usually denoted ||x||.
Throughout paper, often refer computations carried non-deterministic
Turing machines, too. Recall Turing machines that, points
computation, may one single next action perform, choice several
possible next actions. non-deterministic Turing machine answers decision problem
given input x: (i ) least one sequence choices leading halt
accepting state x yes instance; (ii ) possible sequences choices lead
rejecting state x instance.
class decision problems solved non-deterministic Turing machines
polynomial time denoted NP. Problems NP enjoy remarkable property:
yes instance x certificate yes instance, polynomial length
checked polynomial time (in size ||x||). example, problem
deciding whether Boolean formula variables X1 , . . . , Xn satisfiable, i.e.,
deciding whether exists truth assignment variables making true,
well-known problem NP; fact, satisfying truth assignment obviously
certificate yes instance, i.e., satisfiable.
class problems whose complementary problems NP denoted co-NP.
example, problem deciding whether Boolean formula satisfiable
co-NP. course, class P contained NP co-NP.
class DP class problems defined conjunction two
problems, one NP one co-NP, respectively. instance, DP
decide whether, given pair Boolean formulae (, ), satisfiable not.
A.2 Complexity Classes: Polynomial Hierarchy
Throughout paper, also refer particular type computation called computation
oracles. Intuitively, oracles subroutines unary cost.
P
P
classes P
k , k , k , forming polynomial hierarchy, defined follows:
P
P
P
P
k1 , P = Pk1 , P = co-P
P
0 = 0 = P k 1, k = NP
k
k
k
co-P
denotes

class

problems
whose
complementary
problem

solvable
P
k
k.
P
P
Here, k (resp., k ) models computability non-deterministic (resp., deterministic)
P
polynomial-time Turing machine may use oracle P
k1 . Note 1 coincides
NP, P
1 coincides co-NP.
well-known problem k-th level polynomial hierarchy deciding
validity quantified Boolean formula k quantifier alternations. quantified Boolean
676

fiMixed-Integer Constrained Coalitional Games

formula (short: QBF) k quantifier alternations form Q1 X1 Q2 X2 ...Qk Xk ,
k 1, Xi (1 k) set variables, Qi {, } (1
Sk k), Qi 6= Qi+1
(1 < k), Boolean formula variables i=1 Xi . set
quantified Boolean formulae k quantifier alternations Q1 = (resp., Q1 = )
denoted QBFk, (resp., QBFk, ). Deciding validity quantified Boolean formula
P
QBFk, (resp., QBFk, ) well-known problem P
k (resp., k ). Note
k = 1, problem coincides problem deciding whether Boolean formula
satisfiable (resp., satisfiable), indeed NP (resp., co-NP).
A.3 Reductions Among Decision Problems
decision problem A1 polynomially reducible decision problem A2 , denoted
A1 p A2 , polynomial time computable function h that, every x, h(x)
defined x yes instance A1 h(x) yes instance A2 .
decision problem complete class C polynomial hierarchy (beyond P)
belongs C every problem C polynomially reducible A. Thus, problems
complete class C difficult problems C.
worthwhile observing problems discussed section known
complete classes membership pointed out. particular,
deciding validity QBFk, (resp., QBFk, ) formula prototypical P
k -complete
(resp., P
-complete)
problem.
k

Appendix B. Proofs Section 3
Proposition 3.2 Let G = hN, vi TU game let X X(G) arbitrary finite
set imputations. Then, finite set constraints LC X(G|LC ) = X .
Proof. Consider game G = hN, vi, set X = {x1 , . . . , xk } imputations G,
set constraints:

xi = x1i 1 + + xki k , 1 |N |




0 yj 1, 1 j k
LC =
y1 + + yk = 1


x , . . . , xn R


11
, . . . , yk Z
x1i , . . . , xki (for 1 |N |) constants.
immediate check VLC (N ) = X . Moreover, observe vector
xj VLC (N ) (1 j k) efficient, since cannot dominated vector
X (just notice X set imputations G). Finally, notice imputation
x X individually rational w.r.t. G. Thus, Proposition 3.7, x individually rational
w.r.t. constrained game too. follows VLC (N ) = X(G|LC ).
Proposition 3.3 exists class C = {G|nLC }n>0 constrained games
game G|nLC n + 1 players, LC consists 2 n + 1 inequalities, |X(G|LC )| = 2n .

677

fiGreco, Malizia, Palopoli, & Scarcello

Proof. Consider class C = {G|nLC }n>0 game G n = hN, vi N =
{1, . . . , n, n + 1}, v(N ) = n, v(S)
Pn= 0, coalition N , LC = {0n xi n1, xi
Z, 1 n} {xn+1 n i=1 xi }. easily checked |X(G|LC )| = 2 .

Proposition 3.7 Let G = hN, vi TU game let x payoff vector individually rational w.r.t. G (i.e., xi v({i}), player N ). Then, set LC
constraints, x individually rational w.r.t. constrained game G|LC .
Proof. Let x payoff vector xi v({i}), player N . Consider
constrained game G|LC player N . VLC ({i}) = Vv ({i}) (LC)[{i}] = ,
trivially xi > . Otherwise, i.e., VLC ({i}) 6= , notice
max{ yi | yi VLC ({i}) } v({i}). Thus, xi max{ yi | yi VLC ({i}) }.

Appendix C. Proofs Claims Section 5
Claim A. x B(G(H)) H valid.
Proof. Let us study structure possible objection x. Recall (y, S)
objection player player j x if: S, j
/ S, y(S) v(S)
yk > xk , k S. Thus, observe v(S) = 1 must hold, order improve
payoffs members, worth value equal 2 obtained
grand-coalition. addition, since xa = xa = 1 since y(S) v(S) = 1, must also
case {a, } = , players get 1 current imputation x. Due
definition worth function, entails consistent variables Y,
i.e., set n players corresponding literals universally quantified variables.
thus associate possible objection (y, S) x (where y(S) 1 yk > 0,
k S) truth-value assignment variables that, 1 n, Yi assigned
false Yi (and true Yi S). According notation, means
objection associated truth-value assignment (Y \ S). define
converse, well. truth-value assignment universally quantified variables,
associated objection pair (y, S) = {Yk | (Yk ) = false} {Yk |
1
Yk Y, (Yk ) = true}, yp = |S|
, p S. Note (y, S) objection

player player x, (Y \ S) = .
Indeed, (y, S) objection player j
/ {a, }, (z, {j}) zj = 0
trivial counterobjection, since v({j}) = xj = 0 j
/ S. follows set
objections possibly justified restricted player player
. Next, consider case objection a, exactly arguments
hold objections . Let (y, S) objection player x.
counterobjection (z, ) must (and
/ ). Thus, order
za xa = 1, must case v(T ) 1 and, actually, v(T ) = 1, due
definition worth function. particular, latter (with fact za = 1) entails
that, player p 6= p , holds zp = 0. Thus, must empty,
members get something according y, \{a} consistent, (T ) |= .
particular, since = , according satisfying assignment, Yi true (T )
Yi
/ S. follows (T ) coincides (Y \ S) universally
quantified variables, thus fact extension truth-value assignment
678

fiMixed-Integer Constrained Coalitional Games

set variables occurring formula . Conversely, note every satisfying
assignment extends (Y \ S) corresponds counterobjection (y, S).
Given observations, show claim: x B(G(H)) H valid.
() Assume x B(G(H)). Let truth-value assignment universally
quantified variables, let (y, S) objection x associated .
particular, (Y \ S) = , construction. Since x B(G(H)), exists valid
counterobjection (z, ) (y, S), seen corresponding truthvalue assignment (T ) extension (Y \ S) set variables vars(),
(T ) |= . follows H valid.
() Assume x
/ B(G(H)). Then, justified objection (y, S) (or
) x. follows discussion truth-value assignment
able extend assignment (Y \ S) variables vars(),
satisfy . Indeed, extension would associated counterobjection
(y, S). follows H valid.
Claim B. C (G(F )|LC ) 6= F valid.
Proof.
() Assume x C (G(F )|LC ), i.e., N , S-feasible payoff vector
yi > xi S. claim (x) truth assignment
variables {X1 , . . . , Xn } witnessing validity F . Indeed, assume, sake
contradiction, truth assignment variables {Y1 , . . . , Yq }
(x) 6|= . Consider coalition consistent
(S) = (x) . definition worth function, v(S) = n. Moreover, observe
x(S) < n holds, definition assignment (x) given xYj = 0
xYj = 0, imputation x variable Yj (1 j q). Note, fact,
Xi Xi true (x) xXi < 1, Xi Xi false
miniS (1xi )
(x) xXi = 0 (because case xXi = 1 holds). Now, let =
n+q
notice > 0, since xi < 1 is, particular, prescribed definition
(x). Consider vector RS yi = xi + S. Note
y(S) n |S| = n + q; moreover, VLC (S) holds v(S) = n
constraints satisfied (just notice contains exactly one player
{Xi , Xi }, variable Xi , associated payoff less equal
1 constraints xXi + xXi = 1 play role
one player Xi Xi hence given variable yXi (resp., yXi ) yXi 1
(resp., yXi 1) always exists non negative value yXi (resp., yXi )
yXi + yXi = 1). Since yi > xi , S, conclude x
/ C (G(F )|LC ),
impossible.
() Assume truth assignment variables {X1 , . . . , Xn } witnessing
validity F , let x imputation (x) coincides ,
particular xXi = 1 (resp., xXi = 0) Xi false (resp., true) . claim
x C (G(F )|LC ). Indeed, assume sake contradiction,
coalition S-feasible payoff vector yi > xi S. Since
679

fiGreco, Malizia, Palopoli, & Scarcello

v(S) y(S) > x(S) since x(S) 0, given definition worth function,
actually case consistent (and, thus, (S) truth assignment)
(S) satisfying. particular, recall VLC (S) = {x RS | x(S)
v(S)} (LC)[S]; thus, player Xi (resp., Xi S), yXi 1 (resp.,
yXi 1). Therefore, cannot include player {X1 , X1 , ..., Xn , Xn } getting
worth 1 x. follows (S) extension (x), moreover
satisfying. Thus, (x) would witness validity F , impossible.
Claim C. B(G(P )|LC ) 6= P valid.
Proof. Consider imputation x xa = 1, xXi xXi take distinct values
set {0, 1}, variable Xi {X1 , ..., Xm }. objection (y, S) x must
v(S) = 1 (which indeed maximum available worth coalition
N ) player xi = 1. follows objections necessarily
form (y, S) w S, |S| = n+1, consistent w.r.t. {Y1 , . . . , Yn }. words,
objection (y, S) x contains w plus one universal player per universally
quantified variable, thus uniquely associated truth-value assignment
universally quantified variables = {Y1 , . . . , Yn }. Let (Y \ S) denote assignment,
set Yj = true Yj
/ S, 1 j n. define also converse:
given truth value assignment universally quantified variables, associated
objection pair (y, S) = {Yj | (Yj ) = false}{Yj | (Yj ) = true}{w},
1
, every k S.
yk = |S|
Now, (y, S) objection player j
/ {a, X1 , . . . , Xm , X1 , . . . , Xm },
(z, {j}) zj = 0 trivial counterobjection. Indeed, player j belong
may either element {Y1 , . . . , Yn } element {Z1 , . . . , Zq }. either
cases, v({j}) = xj = 0. hand, (y, S) objection player Xi (or,
Xi ), (z, {Xi , Xi }) zXi = xXi zXi = xXi counterobjection,
v({Xi , Xi }) = z({Xi , Xi }) = 1 {Xi , Xi } = . follows set objections
possibly justified restricted objections player a. Let (y, S)
objection player x. counterobjection (z, ) must
. Thus, order za xa = 1, must case v(T ) 1 and, actually,
v(T ) = 1, due definition worth function. particular, latter entails
player p 6= p , holds zp = 0. Thus, must empty
and, particular, possibility \ {a} consistent, (T ) |= . Finally,
since = x(p) = 0 p p 6= a, (T ) satisfying
assignment where: Xi true (T ) Xi true (x); Yi true
(T ) Yi
/ S, thus Yi true (Y \ S). is, (T ) complete
assignment extends partial assignments (x) (Y \ S).
exploiting observations, prove claim.
() Assume exists x B(G(P )|LC ). seen imputation x
associated truth-value assignment (x) variables {X1 , . . . , Xm }
recall imputation x index i, 1 m, xXi > 0
xXi > 0 cannot belong bargaining set G(P )|LC . Moreover, seen
every assignment universally quantified variables corresponds
680

fiMixed-Integer Constrained Coalitional Games

possible objection (y, S) x, since x belongs bargaining set must
exist valid counterobjection (z, ) (y, S) associated satisfying truth-value
assignment extends partial assignments (x) . means
x witness validity P .
() P valid assignment X variables {X1 , . . . , Xm }
witnesses validity. Consider imputation x that, 1 m, xXi = 0
xXi = 1 X (Xi ) = true, xXi = 1 xXi = 0 otherwise. Moreover,
xa = 1 players get 0. Since, every extension X universally
quantified variables (corresponding possible objection (y, S) x), exists
extension variables satisfies (corresponding counterobjection
(y, S)), follows x B(G(P )|LC ).

i,j,S,T )[y ] contains point (i.e., justified obClaim D. (LCi,j,S )[yS ] \ |iT

/ jT (LC
jection x) represented polynomially many bits.
Proof. case (LCi,j,S )[yS ] (LCi,j,S,T )[yS ] (for |
/ j )
contain integer variables already addressed proof Lemma 5.8. next
show preprocess integer variables, occur programs hand.
Recall first (LCi,j,S )[yS ] bounded, since LCi,j,S contains |S| + 1 inequalities:
y(S) v(S) yk > xk , k S. implies assume, w.l.o.g., (LCi,j,S )
bounded turn. Indeed, standard arguments linear programming follows
point (LCi,j,S )[yS ] obtained projection point (LCi,j,S ) whose
auxiliary components (i.e., associated variables yS ) bounded
polynomial size LCi,j,S . Thus, bound made explicit definition
LCi,j,S , without altering projection (LCi,j,S )[yS ].
Second, observe also assume, w.l.o.g, (LCi,j,S,T ) bounded too,

/ j . Indeed, definition LCi,j,S,T , may constrain
variable yS range within minimum maximum values may assume
(LCi,j,S )[yS ]note extreme values represented polynomially many
bits, since achieved
vertices (LCi,j,S )[yS ]. modification
i,j,S
i,j,S,T )[y ]. Thus, (LCi,j,S,T )[y ] bounded,
alter set (LC
)[yS ] \ |iT


/ jT (LC
(LCi,j,S,T ) assumed bounded, toosee above.
resume main proof show integer variables easily prefC denote
processed. Let LC program {LCi,j,S } {LCi,j,S,T |
/ j }, let L
fC) represented
linear relaxation LC, recall vertex polytope (L
f
polynomially many bits. Since (LC) contained (LC), values components vertices bounds every integer component vector (LC),
thus represented polynomially many bits. Let U set admissible
values integer components. Let I(LC) denote set possible assignments values integer variables LC U , assignment z I(LC),
let LChzi denote linear program integer variable int(LC) replaced
corresponding value z. Now, pair assignments z w belonging I(LCi,j,S )
I(LCi,j,S,T ), respectively, let us say w matches z (w.r.t. yS ) z w
coincide restrictions yS int(LCi,j,S )int(LCi,j,S,T ).
Furthermore, let W
i,j,S,T )).
set non-integer variables yS , is, yS \ (int(LCi,j,S ) |iT
/ jT int(LC
681

fiGreco, Malizia, Palopoli, & Scarcello


i,j,S,T )[y ] contains point
Then, set (LCi,j,S )[yS ] \ |iT

/ jT (LC
represented polynomially many bits (resp., empty) element
z I(LCi,j,S ) (resp., element z I(LCi,j,S )):


[
[
(LCi,j,S hzi)[W] \
(LCi,j,S,T hwi)[W]
|iT
/ jT

wI(LCi,j,S,T ) | w matches z

contains element represented polynomially many bits (resp., empty).
Note expression form original one, integer
variable occurs it. conclude, observe LCi,j,S hzi LCi,j,S,T hwi (T |
/
j ) represented polynomially many bits (w.r.t. size original
mixed-integer linear programs), since obtained mapping integer variables
values representable polynomially many bits.

References
Agotnes, T., van der Hoek, W., & Wooldridge, M. (2006). Temporal qualitative coalitional
games. Nakashima, H., Wellman, M. P., Weiss, G., & Stone, P. (Eds.), Proceedings
5th International Conference Autonomous Agents Multiagent Systems
(AAMAS 2006), pp. 177184, Hakodate, Japan.
Aumann, R. J. (1961). core cooperative game without side payments. Transactions
American Mathematical Society, 98, 539552.
Aumann, R. J. (1985). axiomatization non-transferable utility value. Econometrica, 53 (3), 599612.
Aumann, R. J., & Dreze, J. H. (1974). Cooperative games coalition structures. International Journal Game Theory, 3 (4), 217237.
Aumann, R. J., & Hart, S. (Eds.). (1992, 1994, 2002). Handbook Game Theory
Economic Applications, Volume 1,2 3, Vol. 11 Handbooks Economics.
North-Holland, Amsterdam, Netherlands.
Aumann, R. J., & Maschler, M. (1964). bargaining set cooperative games.
Advances Game Theory, pp. 443476. Princeton University Press, Princeton, NJ,
USA.
Aumann, R. J., & Peleg, B. (1960). Von Neumann-Morgenstern solutions cooperative
games without side payments. Bulletin American Mathematical Society, 66 (3),
173179.
Bachrach, Y., & Rosenschein, J. S. (2008). Coalitional skill games. Padgham, L., Parkes,
D. C., Muller, J., & Parsons, S. (Eds.), Proceedings 7th International Conference Autonomous Agents Multiagent Systems (AAMAS 2008), pp. 10231030,
Estoril, Portugal.
Bilbao, J. M. (2000). Cooperative Games Combinatorial Structures, Vol. 26 Theory
Decision Library C. Kluwer Academinc Publishers, Reading, MA, USA.
Byford, M. C. (2007). constrained coalitional approach price formation. North
American Summer Meetings Econometric Society, Durham, NC, USA.
682

fiMixed-Integer Constrained Coalitional Games

Charnes, A. (1953). Constrained games linear programming. Proceedings National
Academy Sciences United States America, 39 (7), 639641.
Conitzer, V., & Sandholm, T. (2004). Computing shapley values, manipulating value division schemes, checking core membership multi-issue domains. McGuinness,
D. L., & Ferguson, G. (Eds.), Proceedings 19th National Conference Artificial
Intelligence (AAAI-04), pp. 219225, San Jose, CA, USA.
Davis, M., & Maschler, M. (1965). kernel cooperative game.. Naval Research
Logistics Quarterly, 12, 223259.
Deng, X., & Papadimitriou, C. H. (1994). complexity cooperative solution concepts. Mathematics Operations Research, 19 (2), 257266.
Dunne, P. E., van der Hoek, W., Kraus, S., & Wooldridge, M. (2008). Cooperative boolean
games. Padgham, L., Parkes, D. C., Muller, J., & Parsons, S. (Eds.), Proceedings
7th International Conference Autonomous Agents Multiagent Systems
(AAMAS 2008), pp. 10151022, Estoril, Portugal.
Edgeworth, F. Y. (1881). Mathematical Psychics: essay mathematics moral
sciences. C. Kegan Paul & Co., London.
Elkind, E., Goldberg, L. A., Goldberg, P. W., & Wooldridge, M. (2009). computational complexity weighted voting games. Annals Mathematics Artificial
Intelligence, 56 (2), 109131.
Elkind, E., & Pasechnik, D. (2009). Computing nucleolus weighted voting games.
Mathieu, C. (Ed.), Proceedings 20th Annual ACM-SIAM Symposium
Discrete Algorithms (SODA09), pp. 327335, New York, NY, USA.
Gillies, D. B. (1959). Solutions general non-zero-sum games. Tucker, A. W., & Luce,
R. D. (Eds.), Contributions Theory Games, Volume IV, Vol. 40 Annals
Mathematics Studies, pp. 4785. Princeton University Press, Princeton, NJ, USA.
Greco, G., Malizia, E., Palopoli, L., & Scarcello, F. (2009a). Constrained coalitional games:
formal framework, properties, complexity results (extended abstract). Sierra,
C., Castelfranchi, C., Decker, K. S., & Sichman, J. S. (Eds.), Proceedings
8th International Conference Autonomous Agents Multiagent Systems (AAMAS 2009), pp. 12951296, Budapest, Hungary.
Greco, G., Malizia, E., Palopoli, L., & Scarcello, F. (2009b). complexity compact coalitional games. Boutilier, C. (Ed.), Proceedings 21th International Joint Conference Artificial Intelligence (IJCAI-09), pp. 147152, Pasadena,
CA, USA. extended version available technical report arXiv:0810.3136
(http://arxiv.org/abs/0810.3136).
Hart, S. (2004). comparison non-transferable utility values. Theory Decision,
56 (12), 3546.
Ieong, S., & Shoham, Y. (2005). Marginal contribution nets: compact representation
scheme coalitional games. Riedl, J., Kearns, M. J., & Reiter, M. K. (Eds.), Proceedings 6th ACM Conference Electronic Commerce (EC05), pp. 193202,
Vancouver, BC, Canada.
683

fiGreco, Malizia, Palopoli, & Scarcello

Ieong, S., & Shoham, Y. (2006). Multi-attribute coalitional games. Feigenbaum, J.,
Chuang, J., & Pennock, D. M. (Eds.), Proceedings 7th ACM Conference
Electronic Commerce (EC06), pp. 170179, Ann Arbor, MI, USA.
Ieong, S., & Shoham, Y. (2008). Bayesian coalitional games. Fox, D., & Gomes, C. P.
(Eds.), Proceedings 23rd National Conference Artificial Intelligence (AAAI08), pp. 95100, Chicago, IL, USA.
Jiang, T., & Baras, J. S. (2007). Fundamental tradeoffs constrained coalitional games
autonomic wireless networks. Proceedings 5th International Symposium
Modeling Optimization Mobile, Ad Hoc, Wireless Networks (WiOpt07),
pp. 18, Limassol, Cyprus.
Johnson, D. S. (1990). catalog complexity classes. van Leeuwen, J. (Ed.), Handbook
Theoretical Computer Science, Volume A: Algorithms Complexity, pp. 67161.
MIT Press, Cambridge, MA, USA.
Kalai, E. (1975). Excess functions cooperative games without sidepayments. SIAM
Journal Applied Mathematics, 29 (1), 6071.
Malizia, E., Palopoli, L., & Scarcello, F. (2007). Infeasibility certificates complexity
core coalitional games. Veloso, M. M. (Ed.), Proceedings 20th
International Joint Conference Artificial Intelligence (IJCAI-07), pp. 14021407,
Hyderabad, India.
Maschler, M. (1992). bargaining set, kernel, nucleolus. Aumann, R. J., & Hart,
S. (Eds.), Handbook Game Theory, Volume 1, Vol. 11 Handbooks Economics,
chap. 18. North-Holland, Amsterdam, Netherlands.
McLean, R. P. (2002). Values non-transferable utility games. Aumann, R. J., & Hart,
S. (Eds.), Handbook Game Theory, Volume 3, Vol. 11 Handbooks Economics,
chap. 55. North-Holland, Amsterdam, Netherlands.
Nemhauser, G. L., & Wolsey, L. A. (1988). Integer combinatorial optimization. WileyInterscience Series Discrete Mathematics Optimization. Wiley-Interscience,
New York, NY, USA.
Orshan, G., & Zarzuelo, J. M. (2000). bilateral consistent prekernel ntu games.
Games Economic Behavior, 32 (1), 6784.
Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press,
Cambridge, MA, USA.
Owen, G. (1975). core linear production games. Mathematical Programming,
9 (1), 358370.
Papadimitriou, C., & Steiglitz, K. (1998). Combinatorial Optimization: Algorithms
Complexity (2nd edition). Dover Publications.
Peleg, B. (1963). Bargaining sets cooperative games without side payments. Israel Journal
Mathematics, 1 (4), 197200.
Peleg, B., & Sudholter, P. (2007). Introduction Theory Cooperative Games (2nd
edition). Theory Decision Library. Springer, Berlin, Germany.

684

fiMixed-Integer Constrained Coalitional Games

Rahwan, T., Ramchurn, S. D., Jennings, N. R., & Giovannucci, A. (2009). Anytime algorithm optimal coalition structure generation. Journal Artificial Intelligence
Research, 34, 521567.
Ryan, M. J. (1998). Constrained games, intervening duality experimenter-experiment
interactions. European Journal Operational Research, 110 (2), 326341.
Schmeidler, D. (1969). nucleolus characteristic function game. SIAM Journal
Applied Mathematics, 17 (6), 11631170.
Selman, A. L. (1994). taxonomy complexity classes functions. Journal Computer
System Sciences, 48 (2), 357381.
Semple, J. (1997). Constrained games evaluating organizational performance. European
Journal Operational Research, 96 (1), 103112.
Serrano, R. (1997). Reinterpreting kernel. Journal Economic Theory, 77 (1), 5880.
Shapley, L. S. (1953). value n-person games. Kuhn, H. W., & Tucker, A. W. (Eds.),
Contributions Theory Games, Volume II, Vol. 28 Annals Mathematics
Studies, pp. 307317. Princeton University Press, Princeton, NJ, USA.
Shapley, L. S. (1969). Utility comparison theory games. La Decision, pp.
251263. Editions du Centre National de le Recherche Scientifique, Paris.
Shoham, Y. (2008). Computer science game theory. Communications ACM,
51 (8), 7479.
Simon, H. A. (1972). Theories bounded rationality. McGuire, C. B., & Radner, R.
(Eds.), Decision Organization, Vol. 12 Studies Mathematical Managerial
Economics, pp. 161176. North-Holland, Amsterdam, Netherlands.
von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior
(1st edition). Princeton University Press, Princeton, NJ, USA.
Weber, R. J. (1994). Games coalitional form. Aumann, R. J., & Hart, S. (Eds.),
Handbook Game Theory, Volume 2, Vol. 11 Handbooks Economics, chap. 36.
North-Holland, Amsterdam, Netherlands.
Winter, E. (2002). shapley value. Aumann, R. J., & Hart, S. (Eds.), Handbook
Game Theory, Volume 3, Vol. 11 Handbooks Economics, chap. 53. North-Holland,
Amsterdam, Netherlands.
Wooldridge, M., & Dunne, P. E. (2004). computational complexity qualitative
coalitional games. Artificial Intelligence, 158 (1), 2773.
Wooldridge, M., & Dunne, P. E. (2006). computational complexity coalitional
resource games. Artificial Intelligence, 170 (10), 835871.

685

fiJournal Articial Intelligence Research 38 (2010) 339-369

Submitted 11/09; published 07/10

Mixed Strategies Combinatorial Agency
Moshe Babaio

moshe@microsoft.com

Microsoft Research - Silicon Valley
Mountain View, CA 94043 USA

Michal Feldman

mfeldman@huji.ac.il

School Business Administration
Center Study Rationality,
Hebrew University Jerusalem,
Jerusalem, Israel

Noam Nisan

noam@cs.huji.ac.il

School Computer Science,
Hebrew University Jerusalem,
Jerusalem, Israel

Abstract
many multiagent domains set agents exert eort towards joint outcome, yet
individual eort levels cannot easily observed. typical example scenario
routing communication networks, sender observe whether packet
reached destination, often information actions intermediate
routers, inuences nal outcome. study setting principal needs
motivate team agents whose combination hidden eorts stochastically determines
outcome. companion paper devise study basic combinatorial agency model
setting, principal restricted inducing pure Nash equilibrium.
study various implications restriction. First, show that, contrast
case observable eorts, inducing mixed-strategies equilibrium may benecial
principal. Second, present sucient condition technologies gain
generated. Third, bound principals gain various families technologies. Finally,
study robustness mixed equilibria coalitional deviations computational
hardness optimal mixed equilibria.

1. Introduction
paper study Combinatorial Agency Mixed Strategies, section reviews
background Combinatorial Agency pure strategies present results
mixed strategies.
1.1 Background: Combinatorial Agency
well studied principal-agent problem deals principal motivate
rational agent exert costly eort towards welfare principal. diculty
model agents action (i.e. whether exerts eort not) invisible
principal nal outcome, probabilistic also inuenced
c
2010
AI Access Foundation. rights reserved.

fiBabaioff, Feldman & Nisan

factors, visible1 . problem well studied many contexts classical
economic theory refer readers introductory texts economic theory
work Mass-Colell, Whinston, Green (1995), Chapter 14. settings,
properly designed contract, payments contingent upon nal outcome,
inuence rational agent exert required eort.
many multiagent settings, however, set agents work together towards joint
outcome. Handling combinations agents rather single agent focus
work Babaio, Feldman, Nisan (2006a). much work previously done
motivating teams agents (e.g., Holmstrom, 1982; Strausz, 1996), emphasis
dealing complex combinatorial structure dependencies agents actions.
general case, combination eorts exerted n dierent agents may result
dierent expected gain principal. general question asks, given exact
specication expected utility principal combination agents actions,
conditional payments principal oer agents maximize
net utility?
view problem hidden actions computational settings complementary
problem problem hidden information heart eld Algorithmic
Mechanism Design (Nisan, Roughgarden, Tardos, & Vazirani, 2007; Nisan & Ronen, 2001).
recent years, computer science articial intelligence showed lot interest
algorithmic mechanism design. particular, imported concepts game theory
mechanism design solving problems arise articial intelligence application
domains, computer networks routers autonomous software agents.
Communication networks serve typical application setting. Since many computer networks (such Internet mobile ad-hoc networks) used administered
multiple entities dierent economic interests, performance determined
actions among various interacting self-interested parties. Thus, taking account
economic strategic considerations together technical ones may crucial
settings. Indeed, recent years seen urry research employing game theoretic models analysis better understanding eect strategic considerations
network design performance.
example discussed work Feldman, Chuang, Stoica, Shenker
(2007) Quality Service routing network: every intermediate link router may
exert dierent amount eort (priority, bandwidth, etc.) attempting forward
packet information. nal outcome whether packet reached destination
clearly visible, rarely feasible monitor exact amount eort exerted
intermediate link ensure really exert appropriate amount
eort? example, Internet routing, IP routers may delay drop packets,
mobile ad hoc networks, devices may strategically drop packets conserve constrained
energy resources. Aside forwarding decisions, done sequential manner,
eort decisions take place prior actual packet transmission, done
simultaneous manner. many examples decisions, among
quality hardware, appropriate tuning routers, more. focus
1. Invisible meant wide sense includes precisely measurable, costly determine,
non-contractible (meaning upheld court law).

340

fiMixed Strategies Combinatorial Agency

a-priori eort decisions, since crucial quality transmission,
harder detect agents shirk respect matters.
general model presented work Babaio et al. (2006a), n agents
set possible actions, combination actions players results
outcome, happens probabilistically. main part specication
problem model function (the technology) species distribution
n-tuple agents actions. Additionally, problem species principals utility
possible outcome, agent, agents cost possible action.
principal motivates agents oering contract species
payment possible outcome whole project. Key actions
players non-observable (hidden-actions) thus contract cannot make
payments directly contingent actions players, rather outcome
whole project.
Given set contracts, agent optimizes utility; i.e., chooses action
maximizes expected payment minus cost action. Since outcome depends
actions players together, agents put game assumed
reach Nash Equilibrium (NE). principals problem designing optimal
contract: i.e. vector contracts dierent agents induce equilibrium
optimize expected utility outcome minus expected total payment.
main diculty determining required Nash equilibrium point.
interest paper, work Babaio et al. (2006a), focused
binary case: agent two possible actions exert eort shirk
two possible outcomes success failure. motivating examples come
following restricted concrete structured subclass problem instances:
Every agent performs subtask succeeds low probability agent
exert eort higher probability > , agent exert eort.
whole project succeeds deterministic Boolean function success subtasks.
example, Boolean functions represent respective cases
agents complementary (i.e., project succeeds agents
succeed) substitutive (i.e., project succeeds least one
agents succeeds). Yet, restricted subclass problem instances technologies
represented read-once networks two specied source sink nodes,
every edge labeled single agent, project succeeds (e.g., packet
information reaches destination) successful path source
sink nodes.
1.2 Paper: Mixed Equilibria
focus work Babaio et al. (2006a) notion Nash-equilibrium
pure strategies: allow principal attempt inducing equilibrium
agents mixed strategies actions. observable-actions case (where
principal condition payments agents individual actions) restriction
pure strategies without loss generality: mixed actions never help since simply
provide convex combination would obtained pure actions.
341

fiBabaioff, Feldman & Nisan

Yet, surprisingly, show case hidden-actions case
studying: cases, Mixed-Nash equilibrium provide better expected utility
principal obtain equilibrium pure strategies. particular,
already happens case two substitutive agents certain (quite restricted) range
parameters (see Section 3).
inducing mixed strategy equilibria might benecial principal, mixed
Nash equilibrium much weaker solution concept pure Nash equilibrium,
already observed Harsanyi (1973). opposed Nash equilibria pure strategies,
guarantees one obtains expectation. addition, player deviate
equilibrium strategy without lowering expected payo even expects
players stick equilibrium strategies. Moreover, best-response dynamics converge
pure proles, natural dynamics leading mixed Nash equilibrium.
result, principal cannot gain much inducing Nash equilibrium mixed
strategies, might willing tolerate instability notion. main goal
quantify principals gain inducing mixed equilibrium, rather pure.
that, analyze worst ratio (over principals values) principals optimal
utility mixed equilibrium, optimal utility pure equilibrium. term
ratio price purity (POP) instance study.
price purity least 1 denition, larger is, principal
gain inducing mixed equilibrium compared pure one. prove
super-modular technologies (e.g. technologies increasing returns scale)
contains particular Boolean function, price purity trivial (i.e., P OP =
1). Moreover, show Boolean function, assignment
parameters (agents individual success probabilities) obtained structured
technology non trivial POP (i.e., P OP > 1). (Section 4).
price purity may strictly greater 1, obtain quite large number
results bounding ratio (Section 5). bounds range linear bound
general families technologies (e.g., P OP n anonymous sub-modular
technology) constant bounds restricted cases (e.g., P OP 1.154... family
anonymous technologies, P OP 2 technology 2 agents).
Additionally, study properties mixed equilibrium. show mixed
Nash equilibria delicate pure ones. particular, show unlike
pure case, optimal contract also strong equilibrium (Aumann, 1959)
(i.e., resilient deviations coalitions), optimal mixed contract (in least two
agents truly mix) never satises requirements strong equilibrium (Section 6).
Finally, study computational hardness optimal mixed Nash equilibrium,
show hardness results pure case hold mixed case well
(Section 7).

2. Model Preliminaries
focus simple binary action, binary outcome scenario agent two
possible actions (exert eort shirk) two possible outcomes (failure,
success). begin presenting model pure actions (which generalization
model Winter, 2004), move mixed case. principal employs set
342

fiMixed Strategies Combinatorial Agency

agents N size n. agent N set two possible actions Ai = {0, 1} (binary
action), low eort action (0) cost 0 (ci (0) = 0), high eort action (1)
cost ci > 0 (ci (1) = ci ). played prole actions determine, probabilistic way,
contractible outcome, {0, 1}, outcomes 0 1 denote project failure
success, respectively (binary-outcome). outcome determined according success
function : A1 . . . [0, 1], t(a1 , . . . , ) denotes probability project
success players play action prole = (a1 , . . . , ) A1 . . . = A.
use notation (t, c) denote technology (a success function vector costs,
one agent). assume everything eort agents common
knowledge.
principals value successful project given scalar v > 0, gains
value project failure. hidden-actions model actions players
invisible, nal outcome visible others, may design enforceable
contracts based outcome. assume principal pay agents
ne (known limited liability constraint). contract agent thus given
scalar value pi 0 denotes payment gets case project success.
project fails, agent gets money (this contrast observable-actions
model payment agent contingent action). contracts
agents public, agents know making eort decisions.
Given setting, agents put game, utility agent
prole actions = (a1 , . . . , ) given ui (a) = pi t(a) ci (ai ).
usual, denote ai Ai (n 1)-dimensional vector actions agents
excluding agent i. i.e., ai = (a1 , . . . , ai1 , ai+1 , . . . , ). agents assumed
reach Nash equilibrium, equilibrium exists. principals problem (which
problem paper)
design contracts pi maximize expected
utility u(a, v) = t(a) (v pi ), actions a1 , . . . , Nash-equilibrium.
case multiple Nash equilibria, model let principal choose desired
one, suggest agents, thus focusing best Nash equilibrium.2
wish concentrate motivating agents, rather coordination
agents, assume eort agent always leads better probability
success. Formally, N, ai Ai t(1, ai ) > t(0, ai ). also assume
t(a) > 0 A.
next consider extended game agent mix exerting eort
shirking (randomize two possible pure actions). Let qi denote probability
agent exerts eort, let qi denote (n 1)-dimensional vector investment
probabilities agents except agent i. extend denition success
function range mixed strategies, taking expectation.
t(q1 , . . . , qn ) =



n

( qiai (1 qi )(1ai ) )t(a1 , . . . , )

a{0,1}n i=1

2. pure case (Babaio, Feldman, & Nisan, 2006b), best Nash equilibrium also strong
equilibrium, case delicate mixed case (see Section 6). variants NE
exist. One variant, similar spirit strong implementation mechanism design, would
take worst Nash equilibrium, even, stronger yet, require single equilibrium exists
(as work Winter, 2004).

343

fiBabaioff, Feldman & Nisan

Note agent (qi , qi ) holds t(qi , qi ) = qi t(1, qi ) + (1 qi )
t(0, qi ). mixed equilibrium prole least one agent mixes probability
pi [0, 1] called non-degenerate mixed equilibrium.
pure strategies, marginal contribution agent i, given ai Ai , dened
be: (ai ) = t(1, ai ) t(0, ai ). mixed case dene marginal contribution
agent i, given qi be: (qi ) = t(1, qi ) t(0, qi ). Since monotone,
positive function.
next characterize payment result agent mixing exerting
eort shirking.
Claim 2.1 Agent best response mix exerting eort shirking probability qi (0, 1) indierent ai = 1 ai = 0. Thus, given prole
strategies qi , agent mixes if:
pi =

ci
ci
=
(qi )
t(1, qi ) t(0, qi )

payment makes indierent exerting eort and(shirking.
)

q
.
expected utility agent i, exerts eort probability qi is: ui (q) = ci it(q)

(qi )
Proof: Recall ui (q) = t(q) pi qi ci , thus ui (q) = qi ui (1, qi ) + (1 qi ) ui (0, qi ).
Since maximizes utility, qi (0, 1), must case ui (1, qi ) = ui (0, qi ).
ci
.
2
Solving pi get pi = (q
)
prole mixed strategies q = (q1 , . . . , qn ) Mixed Nash equilibrium agent
i, qi agent best response, given qi .
principals expected utility mixed Nash prole q given
=
u(q, v)
ci
(v P ) t(q), P total payment case success, given P = i|qi >0 (q
.
)

optimal mixed contract principal equilibrium mixed strategy prole q (v)
maximizes principals utility value v. Babaio et al. (2006a) show
similar characterization optimal pure contract A. agent exerts eort paid
ci
(ai ) , utilities above, given pure prole.
pure Nash case, given value v, optimal pure contract principal set agents
(v) exert eort equilibrium, set maximizes principals utility
value v.
simple crucial observation, generalizing similar one work Babaio
et al. (2006a) pure Nash case, shows optimal mixed contract exhibits
monotonicity properties value.
Lemma 2.2 (Monotonicity lemma): technology (t, c) expected utility
principal optimal mixed contract, success probability optimal mixed
contract, expected payment optimal mixed contract, monotonically
non-decreasing value.
proof postponed Appendix A, also shows monotonicity
also holds observable-actions case. Additionally, lemma holds general
settings, agent arbitrary action set (not restricted binary-actions
model considered here).
344

fiMixed Strategies Combinatorial Agency

wish quantify gain inducing mixed Nash equilibrium, inducing pure
Nash. dene price purity worse ratio (over v) maximum
utilities obtained mixed pure strategies.
Denition 2.3 price purity P OP (t, c) technology (t, c) dened worse
ratio, v, principals optimal utility mixed case optimal utility
pure case. Formally,
)
(

t(q (v)) v i|q (v)>0 (qci (v))


(
)
P OP (t, c) = Supv>0

ci

t(S (v)) v (v) (ai )
(v) denotes optimal pure contract q (v) denotes optimal mixed contract,
value v.
price purity least 1, may greater 1, later show. Additionally, obtained value transition point pure case (a point
principal indierent two optimal pure contracts).
Lemma 2.4 technology (t, c), price purity obtained nite v
transition point two optimal pure contracts.
2.1 Structured Technology Functions
order concrete, next present technology functions whose structure
described easily derived independent agent tasks call structured
technology functions. subclass gives us natural examples technology functions,
also provides succinct natural way represent technology success functions.
structured technology function, individual succeeds fails task
independently. projects success failure deterministically depends, maybe complex way, set successful sub-tasks. Thus assume monotone Boolean
function f : {0, 1}n {0, 1} indicates whether project succeeds function
success n agents tasks.
structured technology function dened t(a1 , . . . , ) probability
f (x1 , . . . , xn ) = 1 bits x1 , . . . , xn chosen according following
distribution: ai = 0 xi = 1 probability [0, 1) (and xi = 0 probability
1 ); otherwise, i.e. ai = 1, xi = 1 probability > (and xi = 0
probability 1 ). Thus, structured technology dened n, f parameters
{i , }iN .
Let us consider two simple structured technology functions, OR. First
consider
technology: f (x1 , . . . , xn ) logical conjunction xi (f (x) =

x
).
Thus project succeeds agents succeed tasks. shown

graphically read-once network Figure 1(a). technology, probability
success product individual
success probabilities. Agent succeeds

probability iai i1ai , thus t(a) = iai i1ai .
Next,consider technology: f (x1 , . . . , xn ) logical disjunction xi
(f (x) = xi ). Thus project succeeds least one agents succeed
345

fiBabaioff, Feldman & Nisan



x1 x2

xn

x1
x2






xn
(b) technology

(a) technology

Figure 1: technologies. (a), project successful packet routed
along linear path (where agent controls edge), (b), project
successful packet routed least along one edge.

tasks. shown graphically read-once network Figure 1(b). technology,
probability success 1 minus probability
fail. Agent fails
probability (1 )ai (1 )1ai , thus t(a) = 1 (1 )ai (1 )1ai .
two simple examples. One consider interesting examples
Majority function (the project succeed majority agents successful),
OR-Of-ANDs technology, disjunction conjunctions (several teams,
project succeed agents one teams successful). additional
examples see work Babaio et al. (2006a).
success function called anonymous
symmetric respect players.

I.e. t(a1 , . . . , ) depends ai . example, anonymous technology
parameters 1 > > > 0 agent succeed probability
eort, probability > eort. agents exert eort, success
probability 1 (1 )m (1 )nm .
technology identical costs exists c agent i, ci = c.
case identical costs POP independent c, use P OP (t) denote
POP technology identical costs. abuse notation denote technology
identical costs success function t. Throughout paper, unless explicitly stated
otherwise, assume identical costs. technology identical costs anonymous
anonymous.

3. Example: Mixed Nash Outperforms Pure Nash!
actions observable (henceforth, observable-actions case), agent
exerts eort paid exactly cost, principals utility equals social welfare.
case, social welfare mixed strategies convex combination social
welfare pure strategies; thus, clear optimal utility always obtained pure
strategies. However, surprisingly enough, hidden-actions case, principal might
gain higher utility mixed strategies allowed. demonstrated following
example:

346

fiMixed Strategies Combinatorial Agency

Figure 2: Optimal mixed contracts technologies 2 agents. areas indicated 0,
1, 2 correspond areas optimal 0, 1, 2 agents, respectively,
exert eort probability 1. white area corresponds agents exert eort
non-trivial probability, q. xed , q increases v.

Example 3.1 Consider anonymous technology two agents, c = 1, =
1 = 2 = 1 1 = 1 2 = 0.09 v = 348. holds t(0, 0) = 1 (1 )2 =
0.172, t(0, 1) = t(1, 0) = 1 (1 )(1 ) = 0.9181, t(1, 1) = 1 (1 )2 = 0.992.
Consider mixed strategy q1 = q2 = 0.92. holds that: t(0, 0.92) = 0.08 t(0, 0) +
0.92 t(0, 1) = 0.858, t(1, 0.92) = 0.92 t(1, 1) + 0.08 t(1, 0) = 0.986, t(0.92, 0.92) =
0.082 t(0, 0) + 0.08 0.92 t(0, 1) 2 + 0.922 t(1, 1) = 0.976. payment player
1
= 7.837, thus principals
successful project pi (0.92, 0.92) = t(1,0.92)t(0,0.92)
utility mixed strategies q1 = q2 = 0.92 v = 348 u((0.92, 0.92), 348) =
t(0.92, 0.92) (348 2 7.837) = 324.279.
principals utility mixed prole q1 = q2 = 0.92 324.279,
optimal contract pure strategies obtained agents exert eort achieves
utility 318.3. implies moving pure strategies mix strategies, one
gains least 324.27/318.3 > 1.0187 factor improvement (which approximately 1.8%).
worse ratio exists general case (in necessarily hold
= 1 ) = 0.0001, = 0.9 v = 233. case get optimal pure
contract one agent, gives utility 208.7, mixed contract q1 = q2 = 0.92
gives utility 213.569, ratio least 1.0233 (approximately 2.3%).
complete example, Diagram 2 presents optimal contract 2 agents,
function (when = 1 ) v. shows parameters v,
optimal contract obtained agents exert eort equal probabilities.
following lemma (proved Appendix A.1) shows optimal mixed contracts
anonymous technology (with n agents) specic structure. is,
agents shirk, mix exactly probability.

347

fiBabaioff, Feldman & Nisan

Lemma 3.2 anonymous technology (any > , c, n) value v, either
optimal mixed contract pure contract, or, optimal mixed contract k {2, . . . n}
agents exert eort equal probabilities q1 = . . . = qk (0, 1), rest agents
exert eort.

4. Pure Nash Good Enough?
Next, identify class technologies price purity 1; is,
principal cannot improve utility moving pure Nash equilibrium mixed Nash
equilibrium. technologies marginal contribution agent nondecreasing eort agents. Formally, two pure action proles a, b
denote b j, bj j aj (eort bj least high eort aj ).
Denition 4.1 technology success function exhibits (weakly) increasing returns
scale (IRS)3 every i, every pure proles b
t(bi , bi ) t(ai , bi ) t(bi , ai ) t(ai , ai )
technology exhibits IRS (Winter, 2004; Babaio et al., 2006a). IRS
technologies show P OP = 1.
Theorem 4.2 Assume super-modular. cost vector c, P OP (t, c) = 1.
Moreover, non-degenerate mixed contract never optimal.
Proof: mixed prole q = (q1 , q2 , . . . , qn ), let S(q) support q, is, S(q)
qi > 0, agent S(q) let Si = S(q) \ {i} support q
excluding i. Similarly, pure prole = (a1 , a2 , . . . , ) let S(a) support a.
ci
. Similarly,
mixed prole q, agent S(q) paid pi (qi ) = t(1,qi )t(0,q
)
ci
pure prole a, agent S(a) paid pi (S(a) \ {i}) = pi (ai ) = t(S(a))t(S(a)\{i})
,
t(T ) success probability aj = 1 j , aj = 0 j
/ . also
denote (T ) = t(T ) t(T \ {i}).
show q non-degenerate mixed prole (i.e., least one agent q exerts
eort probability qi (0, 1)), prole agent S(q) exerts eort
probability 1 yields higher utility principal.
Lemma 5.3 (see Section 5), holds pi (qi ) minT Si pi (T ), pi (T ) =
ci
(T ) . exhibits IRS, (T ) increasing function denition (see Section 4), therefore minT Si pi (T ) = pi (Si ). Therefore holds S(q),
pi (qi ) pi (Si ), thus:


pi (qi )
pi (Si )
iS(q)

iS(q)

3. Note exhibits IRS super-modular.

348

fiMixed Strategies Combinatorial Agency

addition, due monotonicity t, holds t(q) < t(S(q)). Therefore,



u(q, v) = t(q) v
pi (qi )


iS(q)

< t(S(q)) v

t(S(q)) v


iS(q)




pi (qi )

pi (Si )

iS(q)

= u(S(q), v)
u(S(q), v) principals utility pure prole agents
S(q) exert eort probability 1, rest exert eort.
2
show (on subset bits) function structured
technology based function exhibits IRS, is, function
choices parameters (any n {i , }iN ), structured technology exhibits
IRS. Boolean function, assignment parameters
created structured technology essentially 2 inputs (Lemma B.1 Appendix B),
thus non-trivial POP (recall Example 3.1). proof following theorem
see Appendix B.
Theorem 4.3 Let f monotone Boolean function n 2 inputs,
constant conjunction subset input bits. exist parameters
{i , }ni=1 POP structured technology parameters (and
identical cost c = 1) greater 1.0233.
Thus, goal give upper bounds POP various technologies.

5. Quantifying Gain Mixing
section present bounds price purity general technologies, following
bounds special case technology.
5.1 POP General Technologies
rst show POP bounded principals price unaccountability (Babaio et al., 2006b), whose denition follows.
Denition 5.1 principals price unaccountability P OUP (t, c) technology (t, c)
dened worst ratio (over v) principals utility observable-actions
case hidden-actions case:

(v)) v
t(Soa
(v) ci
iSoa

P OUP (t, c) = Supv>0
ci
t(S (v)) v (v) (a
)
(v) optimal pure contract observable-actions case, (v)
Soa
optimal pure contract hidden-actions case.

349

fiBabaioff, Feldman & Nisan

Theorem 5.2 technology holds P OUP (t) P OP (t).
Proof: P OUP (t) P OP (t) dened supremum utilities ratio given
value v. present bound v, thus holds supremum. denominator
case same: optimal utility principal hidden-actions case
pure strategies. numerator POP optimal principal utility hiddenactions case mixed strategies. Obviously, optimal principal utility
observable-actions case mixed strategies. already observed
observable-actions case mixed strategies cannot help principal (see Section 3), i.e.,
principal utility mixed strategies equals principal utility pure strategies.
assertion theorem follows observing optimal principal utility
pure strategies observable-action case numerator P OUP .
2
However, bound rather weak. best see this, note principals price
unaccountability might unbounded (e.g., Babaio et al., 2006b). Yet, shown
Section 4.2, P OP (AN D) = 1.
section provide better bounds technologies identical costs. begin
characterizing payments mixed contract. show mixed prole,
agent support contract paid least minimal payment single
agent pure prole support, maximal payment.
mixed prole q = (q1 , q2 , . . . , qn ), let S(q) support q, is, S(q)
qi > 0. Similarly, pure prole = (a1 , a2 , . . . , ) let S(a)
ci
support a. mixed prole q, agent S(q) paid pi (qi ) = t(1,qi )t(0,q
.
)
Similarly, pure prole a, agent S(a) paid pi (S(a) \ {i}) = pi (ai ) =
ci
t(S(a))t(S(a)\{i}) , t(T ) success probability aj = 1 j , aj = 0
j
/ T.
Lemma 5.3 mixed prole q = (q1 , q2 , . . . , qn ), agent S(q) let Si =
S(q) \ {i} support q excluding i. holds
maxT Si pi (T ) pi (qi ) minT Si pi (T )
Proof: show agent S(q), increase success probability
exerting eort players play mixed strategies, convex combination
increases success probability

support play pure strategies.

nthe aagents

Recall that: t(q1 , . . . , qn ) = a{0,1}n ( i=1 qi (1 qi )(1ai ) )t(a1 , . . . , ).
Let technology restricted support = S(q), is, i1 , . . . ,
agents (ai1 , ai2 , . . . , aiS ) dened value a, aj = 0
agent j
/ S, aj = aik j = ik S. dened mixed strategies
expected way. Thus,
(qi ) = t(1, qi ) t(0, qi )
= (1, qSi ) (0, qSi )

aj
=
(
qj (1 qj )(1aj ) ) (1, a)
a{0,1}|S|1 jSi

=



(





(



a{0,1}|S|1 jSi

qj j

(1 qj )(1aj ) )(t (1, a) (0, a))

a{0,1}|S|1 jSi

350

qj j (1 qj )(1aj ) )t (0, a)


fiMixed Strategies Combinatorial Agency

conclude (qi ) convex combination (bi ) b support S(b)
Si . Therefore, minT Si (t({i} ) t(T )) (qi ) maxT Si (t({i} ) t(T )).
Thus,
maxT Si 1/(t({i} ) t(T )) = 1/minT Si (t({i} ) t(T ))
1/i (qi ) = pi (qi )
1/maxT Si (t({i} ) t(T ))
= minT Si 1/(t({i} ) t(T ))
2
follows, consider two general families technologies n agents: anonymous technologies technologies exhibit decreasing returns scale (DRS). DRS
technologies technologies decreasing marginal contribution (more eort others
decrease contribution agent). families present bound n
POP.
begin formal denition DRS technologies.
Denition 5.4 technology success function exhibits (weakly) decreasing returns
scale (DRS)4 every i, every b
t(bi , bi ) t(ai , bi ) t(bi , ai ) t(ai , ai )
Theorem 5.5 anonymous technology (non-anonymous) technology exhibits DRS, holds P OP (t) n.
proof theorem well proofs claims appear later
section, see Appendix C. also prove bound POP technology 2
agents (even anonymous), improved bound anonymous case.
Theorem 5.6 technology (even non-anonymous) 2 agents, holds
P OP (t) 2. anonymous P OP (t) 3/2.
provide bounds non-anonymous technologies, left open
problem future research. believe linear bound anonymous DRS
technologies tight conjecture exists universal constant C
bounds POP technology. Moreover, simulations seem indicate nonanonymous technology 2 agents yields highest possible POP. motivates
us explore POP technology detail.
5.2 POP Technology
technology (even non-anonymous) exhibits DRS (see Appendix A.1), implies
bound n POP technology. Yet, anonymous technology
present improved bounds POP. particular, = 1 < 1/2 bound
POP 1.154....
4. Note exhibits DRS submodular.

351

fiBabaioff, Feldman & Nisan

Theorem 5.7 anonymous technology n agents:
n

n (n 1). (b) POP goes 1 n goes
1. 1 > > > 0: (a) P OP 1(1)

(for xed ) goes 1 (for xed n 2).
2.

1
2

> = 1 > 0: (a) P OP

0 goes

1
2


2(32 3)

(=
3( 32)

1.154..). (b) POP goes 1 goes

(for xed n 2).

bounds anonymous technologies case = 1
much better general bounds, still tight. highest POP able
obtain simulations 1.0233 > , 1.0187 = 1 (see Section 3),
deriving exact bound analytically left open problem.

6. Robustness Mixed Nash Equilibria
order induce agent truly mix exerting eort shirking, pi must
equal exactly ci /i (qi ) (see claim 2.1). Even increase pi , agent
longer indierent ai = 0 ai = 1, equilibrium falls apart.
ci
contrast pure case, pi (a
maintain required
)
equilibrium. delicacy exhibits robustness obtained equilibrium
deviations coalitions (as opposed unilateral deviations Nash). strong
equilibrium (Aumann, 1959) requires subgroup players (henceforth coalition)
coordinate joint deviation every member coalition strictly improves
utility.
Denition 6.1 mixed strategy prole q [0, 1]n strong equilibrium (SE)
exist coalition N strategy prole q [0, 1]
, q ) > u (q).
, ui (q


work Babaio et al. (2006b) show payments induce
pure strategy prole best pure Nash equilibrium (i.e., pure Nash equilibrium
maximizes principals utility), also strong equilibrium. contrast
pure case, next show non-degenerate mixed Nash equilibrium q
exist least two agents truly mix (i.e., = j s.t. qi , qj (0, 1)), never strong
equilibrium. coalition = {i|qi (0, 1)} deviate q
exerts eort probability 1, agent strictly improves utility (see
proof Appendix D).
Theorem 6.2 mixed optimal contract q includes least two agents truly mix
(i = j s.t. qi , qj (0, 1)), q strong equilibrium.
technology, example, holds non-degenerate mixed equilibrium least two agents truly mix (see lemma 3.2). Therefore, non-degenerate contract
technology strong equilibrium.
generically mixed Nash contract strong equilibrium pure Nash
contract always is, pricipal wishes induce strong Nash equilibrium (e.g.,
agents coordinate moves), restrict inducing pure Nash
equilibrium, loss bounded POP (see Section 5).
352

fiMixed Strategies Combinatorial Agency

7. Algorithmic Aspects
computational hardness nding optimal mixed contract depends representation technology accessed. black-box access
special case read-once networks, generalize hardness results pure case
(Babaio et al., 2006b) mixed case. main open question whether possible
nd optimal mixed contract polynomial time, given table representation
technology (the optimal pure contract found polynomial time case).
generalization theorems follow (see proofs Appendix E).

Theorem 7.1 Given input black box success function (when costs
identical), value v, number queries needed, worst case, nd
optimal mixed contract exponential n.

Even technology structured technology restricted sourcepair reliability read-once network (see (Babaio et al., 2006b)), computing optimal
mixed contract hard.
Theorem 7.2 optimal mixed contract problem read networks #P -hard
(under Turing reductions).

8. Conclusions Open Problems
paper studies model principal induces set agents exert eort
individual contracts based nal outcome project. focus
paper question much principal benet inducing Nash equilibrium
mixed strategies instead restricted pure Nash equilibrium (as assumed
original model). nd case observable actions mixed equilibria
cannot yield principal higher utility level pure ones, indeed happen
hidden actions. Yet, whether mixed equilibria improve principals utility
depends technology project. give sucient conditions technologies
mixed strategies yield gain principal. Moreover, provide bounds
principals gain various families technologies. Finally, show optimal
contract non-degenerated mixed Nash equilibrium strong equilibrium (in contrast
pure one) nding optimal contract computationally challenging.
model results raise several open problems directions future work.
would interesting study principals gain (from mixed strategies) dierent
families technologies, series-parallel technologies. Additionally, model
extended beyond binary eort level used here. Moreover, focus inducing
mixed Nash equilibrium, equilibrium might unique. One consider
solution concepts unique Nash equilibrium iterative elimination dominated
strategies. Finally, might interest study performance gap pure
mixed Nash equilibria domains beyond combinatorial agency.
353

fiBabaioff, Feldman & Nisan

9. Acknowledgments
Michal Feldman partially supported Israel Science Foundation (grant number
1219/09) Leon Recanati Fund Jerusalem school business administration.

Appendix A. General
Lemma 2.2 ( Monotonicity lemma) technology (t, c) expected utility
principal optimal mixed contract, success probability optimal mixed
contract, expected payment optimal mixed contract, monotonically
non-decreasing value.
Proof: Suppose proles mixed actions q 1 q 2 optimal v1 v2 < v1 ,
respectively. Let P 1 P 2 total payment case successful project, corresponding
minimal payments induce q 1 q 2 Nash equilibria, respectively. utility
linear function value, u(a, v) = t(a) (v P ) (P total payments case
successful project). q 1 optimal v1 , u(q 1 , v1 ) u(q 2 , v1 ), t(a) 0
v1 > v2 , u(q 2 , v1 ) u(q 2 , v2 ). conclude u(q 1 , v1 ) u(q 2 , v2 ), thus utility
monotonic non-decreasing value.
Next show success probability monotonic non-decreasing value. q 1
optimal v1 , thus:
t(q 1 ) (v1 P 1 ) t(q 2 ) (v1 P 2 )
q 2 optimal v2 , thus:
t(q 2 ) (v2 P 2 ) t(q 1 ) (v2 P 1 )
Summing two equations, get (t(q 1 ) t(q 2 )) (v1 v2 ) 0, implies
v1 > v2 t(q 1 ) t(q 2 ).
Finally show expected payment monotonic non-decreasing value.
q 2 optimal v2 t(q 1 ) t(q 2 ), observe that:
t(q 2 ) (v2 P 2 ) t(q 1 ) (v2 P 1 ) t(q 2 ) (v2 P 1 )
equivalently, P 2 P 1 , wanted show.
2
note lemma also holds case proles pure actions,
observable-actions case (by exactly arguments).
Lemma 2.4 technology (t, c), price purity obtained nite v
transition point two optimal pure contracts.
Proof: Clearly large enough value v , ratio 1, cases agents exert
maximal eort. small enough values principal choose contract
agent cases (and ratio 1). true value smaller
agents cost, optimal contract contract agent cases. Let v
supremum values principal choose contract agent
cases. Now, ratio continuous function compact range [v, v ], thus
supremum obtained, value v .
354

fiMixed Strategies Combinatorial Agency

seen POP obtained value v, next prove obtained
transition point pure case. P OP = 1 claim clearly holds, thus
consider case P OP > 1. Let v maximal value POP
obtained. Assume contradiction v transition point two optimal
pure contracts, q optimal pure mixed cases, respectively.
P OP > 1, q non-degenerate u(q, v) > u(a, v). Let P (a) P (q) denote total
payment case success q, respectively. next consider two options.
rst consider case t(a) t(q). show case, utilities ratio
v , > 0 worse utilities ratio v, get contradiction.
> 0 small enough, optimal pure contract still a, u(q, v ) > 0. Let q
optimal mixed contract v . holds
P OP

u(q , v )
u(q, v )
u(q, v) t(q)
u(q, v)

=
>
u(a, v )
u(a, v )
u(a, v) t(a)
u(a, v)

last strict inequality following argument.
u(q, v) t(q)
u(q, v)
>
u(a, v) t(a)
u(a, v)



t(q) u(a, v) < t(a) u(q, v)



P (q) < P (a)

P (q) < P (a) u(q, v) = t(q)(v P (q)) > t(a)(v P (a)) = u(a, v) t(a) t(q).
Next consider case t(q) > t(a). P (q) < P (a), argument
presented shows utilities ratio v , > 0, worse
utilities ratio v, get contradiction. hand, P (q) P (a) show
utilities ratio v + , > 0, least large utilities ratio
v, contradiction v maximal value POP obtained. > 0
small enough, optimal pure contract still (as v transition point
pure contracts). Let q optimal mixed contract v + . holds
P OP

u(q, v + )
u(q, v) + t(q)
u(q, v)
u(q , v + )

=

u(a, v + )
u(a, v + )
u(a, v) + t(a)
u(a, v)

last inequality following argument.
u(q, v) + t(q)
u(q, v)

u(a, v) + t(a)
u(a, v)

t(q) u(a, v) t(a) u(q, v)



P (q) P (a)

holds assumption.
2
following corollary Lemma 2.4 helpful nding POP technologies
2 agents.
Corollary A.1 Assume technology 2 agents identical costs exhibits
DRS, POP obtained transition point pure case, contract
agents.
Proof: Lemma 2.4 POP obtained transition point pure case.
single transition point, 0 agents 2 agents, claim holds. contracting
single agent sometimes optimal, must case single agent
contracted agent (possibly weakly) highest success probability (agent
355

fiBabaioff, Feldman & Nisan

t({i}) t({j}) j = i, implies = t({i})t() t({j})t() = j ).
Thus need show POP obtained transition point v
0 agents contract agent i. Assume q optimal mixed contract
v, P (q) total payment case success. q gives utility
contract {i}, done.
Otherwise, u(q, v) > u({i}, v) , Corollary C.9 holds P (q) c1 , thus
t(q) > t({i}). implies utilities ratio value v + > 0 small enough
worse ratio v (by argument presented Lemma 2.4 case
t(q) > t(a)).
2
A.1 Analysis Technology

Lemma 3.2 anonymous technology (any > , c, n) value v, either
optimal mixed contract pure contract, or, optimal mixed contract k {2, . . . n}
agents exert eort equal probabilities q1 = . . . = qk (0, 1), rest agents
exert eort.
Proof: First, observe cannot case agents one exert eort,
single agent mix probability 0 < qi < 1. principal would rather
change prole qi = 1 (pays same, gets higher success probability). Suppose
contradiction contract induces prole (qi , qj , qij ) qi , qj (0, 1]
qi = qj (qi > qj without loss generality) optimal. agent k, denote
probability failure agent k task (qk ). is, (qk ) = 1 (qk + (1 qk )) =
1 + ( )qk = + qk = .
show suciently small > 0, mixed prole q = (qi , qj + (qji ) , qij )
(q )

(qi )
}, ) obtains better contract,
(for q [0, 1]. i.e., < min{qi , (1 qi ) (q
j)
contradiction optimality original contract.


technology,t(q) = 1 kN (qk ) = 1 (q), (q) = kN (qk ).
also denote ij (q) = k=i,j (qk ). change success probability related
(
)

new product (qi ) qj + ji :

(qi )



(qj )

(

)
(qj )
= (qi ) qj +
(qi )
)
(
(qj )
= ((qi ) ) (qj ) +
(qi )
(qj )
(qj )
= (qi )(qj ) (qj ) +
(qi ) 2 2
(qi )
(qi )
(qj )
= (qi )(qj ) 2 2
(qi )
356

fiMixed Strategies Combinatorial Agency

Therefore new success probability t(q ) increased change:
j
, qij )

(
)
(qj )
= 1 (qi ) qj +
ij (q)
(qi )
)
(
(qj )
= 1 (qi )(qj ) 2 2
ij (q)
(qi )
(
)
2 2 (q)
2 2 (q)
= t(q) +
= t(q) 1 +
((qi ))2
t(q) ((qi ))2

t(q ) = t(qi , qj +

2 2

(q)

denote z() = t(q)((q
2 , thus t(q ) = t(q) (1 + z()), z() > 0 .
))
showing success probability increases, left show suciently small , total payment decreases. payment agent l given by:

pl =

c
c (ql )
c

=
=
t(1, ql ) t(0, ql )
( ) m=l (qm )
( ) t(q)

change payment agent k
c (qk )
c (qk )

( ) t(q) ( ) t(q )
(
)
(qk )
c
=
(qk )
t(q) ( )
(1 + z())
(
)
c
=
(qk ) (qk ) + (qk ) z()
t(q) ( ) (1 + z())
(
)
= W () (qk ) (qk ) + (qk ) z()

pk pk =

c
W () = t(q)()(1+z())
agent k = i, j, (qk ) = (qk ) get pk pk = W () (qk ) z(). agent i,
(qi ) (qi ) = get pi pi = W () ( + (qi ) z()). agent j, (qj ) (qj ) =

(qji ) get pj pj = W () ( (qji ) + (qj ) z()).
summing agents get
(q )

(q )


kN

pk


kN

pk =



(pk pk )

kN

= (pi pi ) + (pj pj ) +



(pk pk )

k=i,j

)

(qj )
+ z()
(qk )
= W ()
(qi )
kN
( (
)
)

(qj )
= W () 1
+ z()
(qk )
(qi )
(

kN

357

fiBabaioff, Feldman & Nisan

positive following observations. W () > 0 z() > 0 , clearly

(qj )
kN (qk ) > 0. Additionally, (1 (qi ) ) > 0 = < 0, (qi ) < (qj )
pi > p j .
conclude, show success probability q greater success
probability q, payments lower, thus utility principal increases
moves q q , contradiction optimality q.
2
Observation A.2 technology exhibits DRS.
Proof: Let ra , rb [0, 1]n two proles actions, rb ra (for i, rib ria ).
b ) (r , r b ) (r b , r ) (r , r ). Indeed,
need show every i, ti (rib , ri







b
b
ti (rib , ri
) ti (ria , ri
) = 1 (1 rib ) (1 rjb ) (1 (1 ria ) (1 rjb ))
j=i


= (rib ria ) (1 rjb )

j=i

j=i



(rib



ria )


(1 rja )
j=i

= 1 (1 rib )



(1 rja ) (1 (1 ria ) (1 rja ))
j=i

=


ti (rib , ri
)



j=i


ti (ria , ri
)

2

Appendix B. Pure Nash Good Enough?
Lemma B.1 Let f : {0, 1}n {0, 1} n 2 monotone Boolean function
constant conjunction subset input bits. exist
assignment two bits restricted function disjunction
two bits.
Proof: induction number bits function depends on. base case n = 2,
monotone function constant conjunction subset
input bits disjunction two input bits.
Let xi variable f depends (which must exist since f constant). Let
|x
=a

f
= f (a, xi ) denote function f restricted xi = a. denote h = f |xi =0
|x
g = f =1 . f monotone, f = x f |xi =1 + f |xi =0 = g x + h, f |xi =1 f |xi =0 (that
is, xi , f (0, xi ) = 1 f (1, xi ) = 1, f (1, xi ) = 0 f (0, xi ) = 0).
h constant conjunction subset input bits, continue
induction using h setting x = 0. Similarly g constant conjunction
subset input bits, continue induction using g setting x = 1.
left case h g conjunctions subset
variables (where constant 1 considered conjunction empty set
variables, easy verify h g cannot constant 0). Since f depends
xi , h = g, since h g, exists variable xj (j = i)
358

fiMixed Strategies Combinatorial Agency

set variables whose conjunction h g. set variables
xi xj 1, left xi + xj .
2
Theorem B.2 Let f monotone Boolean function n 2 inputs,
constant conjunction subset input bits. exist parameters
{i , }ni=1 POP structured technology parameters (and
identical cost c = 1) greater 1.0233.
Proof: Lemma B.1 assignment two variables restricted
function two variables function. two variables choose
parameters according worst POP know technology (see Section 3).
rest variables choose parameters value
worst utilities ratio achieved, rest agents exert eort provide success
probabilities (almost) success probabilities dictated assignment. Next
make argument formal.
Recall Lemma B.1 assignment two variables
restricted function two variables function. Let i1 i2 indices
two variables. Section 3 observed technology two agents
values v = 233, 1 = 2 = 0.0001 1 = 2 = 0.9, POP least 1.0233.
embed instance technology n agents considering value
v = 233 success probabilities follows: agents i1 i1 , let i1 = i2 = 0.0001
i1 = i2 = 0.9. rest agents, x suciently small > 0. set = 1
= 1 2 set 1 assignment, set = 2 = set
0 assignment.
> 0 small enough payment needed induce every agent = i1 , i2
exert eort (for prole eorts others) greater v inversely
proportional increase success probability due eort, goes
zero . Thus, small enough agents = i1 , i2 exert eort
optimal contract, agent provide almost sure success case
assignment variable 1, almost sure failure case assignment
variable zero. created technology essentially technology
agents i1 i2 i1 = i2 = 0.0001, i1 = i2 = 0.9, value v = 233
POP least 1.0233.
2

Appendix C. Quantifying Gain Mixing
C.1 POP n Agents
observe technology, POP bounded ratio success
probability agents exert eort, success probability none agents
exert eort. simple bound shows success probability none agents
exert eort least positive constant, POP bounded constant.
Observation C.1 technology (t, c) set agents N , P OP (t)
359

t(N )
t() .

fiBabaioff, Feldman & Nisan

Proof: given value v, utility principal optimal mixed Nash
v t(N ), utility principal optimal pure Nash least
)
t(N )
v t(), thus POP bounded vt(N
2
vt() = t() .
point consider technologies identical costs. following lemma
shows anonymous technologies well technology exhibits DRS POP
n.
Lemma C.2 Assume technology n agents following holds:
optimal mixed contract q support S, pure prole support

t(a)

t(S)
|S|

agent , pure prole b support R holds t(1, ai )
t(0, ai ) t(1, bi ) t(0, bi ).
P OP (t) n.
Proof: rst observe P (a), total payment prole case
success, P (q), total payment prole q. S, set agents
paid subset set agents paid q. agent
paid least much q, paid (by second condition,
increase success probability q convex combination increase success
probability pure proles support R S). Thus, P (a) P (q), U (a) > 0.
conclude
t(q)(v P (q))
t(q)
t(S)
u(q, v)



|S|
u(a, v)
t(a)(v P (a))
t(a)
t(a)
last inequality derived rst condition. implies POP
bounded n.
2
Corollary C.3 anonymous technology n agents, P OP (t) n.
Proof: Assume value v mixed prole q optimal, support size
k. Let tm success probability agents exert eort, let = tm tm1 . Let
= argmaxmk .
denition second condition holds. rst condition holds as:
ktm k(t0 +tm t0 ) t0 +k(tm t0 ) t0 +k(tm tm1 ) = t0 +km t0 +(tk t0 ) = tk
2
Corollary C.4 technology n agents exhibits DRS identical
costs, P OP (t) n.
Proof: Let agent agent maximal individual contribution S, support
q (t({i}) t({j}) j S). DRS ensures two conditions Lemma C.2
hold.
2
following holds technology n agents (even non-anonymous), exhibits DRS. particular, even single agent > 1/2 get bound 2
POP.
360

fiMixed Strategies Combinatorial Agency

Observation C.5 Assume technology n agents (with identical costs) exhibits
t(N )
DRS, P OP (t) t({i})
, agent maximal individual contribution (t({i})
t({j}) j N ).
Proof: Let agent j agent maximal individual contribution S, support
q. Following proof Lemma C.2, t({i}) t({j}) P (q) P ({j}) P ({i}),
u(q, v) > 0 ,this implies u({i}, v) u({j}, v) > 0. Thus optimal pure contract
gives utility least u({i}, v) > 0, therefore v bound
u(q, v)
u(q, v)
t(q)(v P (q))
t(S)
t(N )

=


u(a , v)
u({i}, v)
t({i})(v P ({i}))
t({i})
t({i})
implies POP bounded

t(N )
t({i}) .

2

Corollary C.6 anonymous technology n agents exhibits DRS, holds
P OP (t) ttn1 .
C.2 POP Anonymous
exhibits DRS, following direct corollary Observation C.5.
Corollary C.7 anonymous technology n agents, holds P OP (OR)
tn
t1 .
Theorem 5.7 anonymous technology n agents:
n

1. 1 > > > 0: (a) P OP 1(1)
n (n 1). (b) POP goes 1 n goes

(for xed ) goes 1 (for xed n 2).
2.

1
2

> = 1 > 0: (a) P OP

0 goes

1
2


2(32 3)

(=
3( 32)

1.154..). (b) POP goes 1 goes

(for xed n 2).

Proof: Based Corollary C.7, P OP

t(1n )
,
t(1,0n1 )

results based bound.

1. Proof part 1(a):
t(1n )
1 (1 )n
1 (1 )n
1 (1 )n
=

=
t(1, 0n1 )
1 (1 )(1 )n1
1 (1 )

Additionally,


1 (1 )n
=
(1 )j = 1 +
(1 )j 1 +
(1 ) = n (n 1)
1 (1 )
n1

n1

n1

j=0

j=1

j=1

concludes proof.
361

fiBabaioff, Feldman & Nisan

2. Proof part 1(b):
t(1n )
1 (1 )n
=
t(1, 0n1 )
1 (1 )(1 )n1
expression goes 1 xed > > 0, n goes , (1 )n
(1 )n1 goes zero.
1(1)n
,


Additionally, saw P OP
goes 1, POP goes 1.

thus clear n xed

3. Proof part 2(a): rst bound POP case anonymous 2
agents = 1 < 1/2. case POP bounded
t(1, 1)
(2 )
= 2
t(0, 1)
+1

2
derivative ratio (22
3 1.
2 +1)2 , equals zero =
maximum point since second derivative negative, ratio point
equals 1.154... Therefore, t(1,1)
t(1,0) 1.154... Observation C.8 shows
n 2 holds

t(1n )
t(1,0n1 )



t(1,1)
t(0,1)

4. Proof part 2(b): expression


thus bound holds n.

t(1n )
t(1,0n1 )

=

1 n
1(1)n1

goes 1 goes 0

1
2.

2
anonymous technology n agents = 1 < 1/2 bound
POP 1.154...
Observation C.8 Let ORn, denote anonymous technology n agents =
1 < 1/2. k 3 holds
P OP (ORk, )

ORk, (1k )
ORk1, (1k1 )

ORk, (1, 0k1 )
ORk1, (1, 0k2 )

thus k 3 holds
P OP (ORk, )

ORk, (1k )
OR2, (1, 1)

1.154...
k1
ORk, (1, 0 )
OR2, (1, 0)

Proof: technology ORk, holds
ORk, (1k )
1 k
=
ORk, (1, 0k1 )
1 (1 )k1
Thus need show k 3
1 k
1 k1

1 (1 )k1
1 (1 )k2
362

fiMixed Strategies Combinatorial Agency

holds
1 k (1 )k2 + k+1 (1 )k2 1 k1 (1 )k1 + k (1 )k1
holds
k1 (1 ) + (1 )k2 (1 (1 )) + k (1 )k2 ((1 ) ) 0
dividing 2 (1 ), holds
k3 + (1 )k3 + k2 (1 )k3 (1 2 ) 0
holds 1 thus (1 )k3 k3 k2 (1 )k3 (1 2 ) 0.

2

C.3 POP 2 Agents
Let us consider case n = 2, prove better bound POP.
shown POP IRS technology 1. Since anonymous technology 2 agents
exhibits either IRS DRS, need handle DRS case. Let 1 = t1 t0
2 = t2 t1 . Assume 1 = 2 1 (DRS).
following corollary Lemma 5.3.
Corollary C.9 DRS technology 2 agents, assume w.l.o.g. t({1}) t({2})
denote 1 = t({1}) t(). mixed prole q = (q1 , q2 ) holds agent
paid least c1 .
Proof: t({1}) t({2}) implies 1 = t({1}) t() t({2}) t(), DRS
implies 1 = t({1}) t() t({1, 2}) t({1}) t({2}) t() t({1, 2}) t({2}),
2
thus Lemma 5.3 implies agent paid least c1 .
Theorem C.10 anonymous technology 2 agents, holds P OP (t)
3/2.
Proof: Let u((q1 , q2 ), v) utility principal mixed prole (q1 , q2 ) value
project v. Let P (q1 , q2 ) denote total payment agents project
successful. Similarly, let u((a1 , a2 ), v) utility principal pure prole (a1 , a2 )
value v.
given value v, let (q1 , q2 ) optimal mixed contract, let (a1 , a2 )
u((q1 ,q2 ),v)
optimal pure contract. show value v holds u((a
3/2,
1 ,a2 ),v)
sucient prove theorem.
optimal mixed prole pure prole, ratio 1, thus need handle
case prole (q1 , q2 ) pure (a non-degenerate mixed contract). case,
u((q1 , q2 ), v) = t(q1 , q2 )(vP (q1 , q2 )) > 0, holds vP (q1 , q2 ) > 0. corollary C.9
implies u((1, 0), v) > 0 P (q1 , q2 ) c1 . Thus u((a1 , a2 ), v) u((1, 0), v) > 0,
u((q1 , q2 ), v)
u((q1 , q2 ), v)
t(q1 , q2 )(v P (q1 , q2 ))
t(q1 , q2 )
t(1, 1)
t2




=
c
u((a1 , a2 ), v)
u((1, 0), v)
t(1, 0)(v 1 )
t(1, 0)
t(1, 0)
t1
363

fiBabaioff, Feldman & Nisan

consider two cases. First consider case t0 2 . case
t2
t0 + 1 + 2
2 + 2 + 2
2+
1
3
u((q1 , q2 ), v)

=

=
=1+

u((a1 , a2 ), v)
t1
t0 + 1
2 + 2
1+
1+
2
replace t0 2 use Lemma C.13.
Next consider case t0 < 2 . case look value v
principal independent contracting 1 2 agents. v = v holds
c
t(1, 0) (v c1 ) = t(1, 1) (v 2c2 ), thus v 2 = v (t2 t1 ) = t2 2c2 t1
, thus
2
c


holds v = (2 )2 (2 t2 t1 ). value v v enough bound ratio
1 ,q2 ),v)
value v v enough bound ratio u((q
u((1,1),v) . bound
ratios separately.
2
1 +2
Lemma C.13, case 0 t0 < 2 , tt21 = t0 +
(1+)
= 1 + 1 .
t0 +1
2

value v v
)
(
v 2c1
u((q1 , q2 ), v)
t(q1 , q2 )(v P (q1 , q2 ))
t2 v P (q1 , q2 )
1





1
+

u((1, 0), v)
t(1, 0)(v c1 )
t1
v c1

v c1
)
) (
(
1
1
1 v
1+

c 1 1

u((q1 ,q2 ),v)
u((1,0),v) ,

Now,

2
t2

v
c

=

2
t0 +(1+)2

1
=
1 1



2
2 +(1+)2

1
(2
(2 )2

=

1
2+ ,

conclude

1
2
2
=

=
2 t2 t1 2
(2 1) t2
t2 t1 ) 1
1
(2 1)(2 + )

Thus
u((q1 , q2 ), v)

u((1, 0), v)

(

1
1+


) (
1

v
c

1
1 1

)

(


1
1+


) (
1

1
(2 1)(2 + )

)

Lemma C.11 shows function RHS bounded 3/2 1.
1 ,q2 ),v)
Finally, value v v , enough bound ratio u((q
u((1,1),v) .
v
u((q1 , q2 ), v)
t(q1 , q2 )(v P (q1 , q2 ))
=

2c
u((1, 1), v)
t(1, 1)(v 2 )
v

2c
1
2c
2

=

v
v

2c
2
2c2

Intuitively, fraction goes 1 goes 1, implies suciently small
fraction less 3/2. Formally,
v

2c
2
2c2

=1+

v
)
(
1

1+2


2c
2



v

2
(2
(2 )2

2c
2
2c
2

2(1 1 )
1+2
=1+ v
c 2 2

(

1


)


v
c

1

2 2

1
2( 1)2
2( 1)2
1+
=1+

2





2


(2 1)t1
t2 t1 ) 2
2
1
2
364

fiMixed Strategies Combinatorial Agency

1+

2( 1)
(2 1)

2(1)

nd maximum RHS. derivative 1 + (21)

maximum obtained = 1 +


= 1 +

2
2 ),


2
2

2(22 4+1)
.
(21)2 2



(it maximum second derivative negative

maximum 1 +


2

(1+ 2)(1+ 22 )

2

< 1.35.

Lemma C.11 1 holds
(
) (
)
1
1
1+
1
3/2

(2 1)(2 + )
Proof:
(
f () =
Let h() =

3+ 3
4 ,

1
1+


22 +33
(21) .

) (
1

1
(2 1)(2 + )

)

(
=

derivative h()

1
1
+2

)


82 +123
,
2 (21)2

22 + 3 3
(2 1)
maximum

value maximum lower 2.072.
1
look = 8/5. function 1 +2
increasing function (for 1),
(
)
1
get , f () 1 +2 2.072 = 13
18 2.072 < 3/2 conclude
proof show f () decreasing function , = 8/5. derivative
f ()
2(24 + 43 42 9 + 3)
2 (2 1)2 (2 + )2
Thus need show 24 + 43 42 9 + 3 > 0 = 8/5.
holds 43 42 = 42 (1) > 0 > 1, 24 9+3 24 9+3 = 1067
625 > 0
4
3
(as function 2 9 + 3 derivative 8 9 positive
91/3 /2, thus monotonically increasing function = 8/5 > 1.05 > 91/3 /2
).
2
Theorem C.12 technology (even non-anonymous) 2 agents identical
costs, holds P OP (t) 2.
Proof: technology anonymous, already proved stronger claim. Assume
not, w.l.o.g. assume t(1, 0) t(0, 1). shown prole
(0, 1) never optimal, implies (by argument seen case
technology anonymous),
P OP

u((q1 , q2 ), v)
u((q1 , q2 ), v)
t(1, 1)


u((a1 , a2 ), v)
u((1, 0), v)
t(1, 0)

technology exhibits IRS, know POP=1. conclude proof show
t(1,1)
technology exhibits IRS t(1,1)
t(1,0) 2. Assume t(1,0) > 2,
show technology exhibits IRS. true since

t(1,1)
t(1,0)

> 2 implies:

t(1, 1) t(1, 0) > t(1, 0) t(1, 0) t(0, 0)
365

fiBabaioff, Feldman & Nisan

t(1, 0 > t(0, 1) also holds
t(1, 1) t(0, 1) > t(1, 1) t(1, 0) t(1, 0) t(0, 1) t(0, 1) t(0, 0)
2

implies IRS.
Lemma C.13 b 0 x > 0

a+x
a+y



b+x
b+y .

Appendix D. Robustness Mixed Nash Equilibria
Theorem 6.2 mixed optimal contract q includes least two agents truly mix
(i, j s.t. qi , qj (0, 1)), q strong equilibrium.
Proof: Let Q support q (i.e., Q = {i|qi > 0}), let k = |Q|. Recall
ci
optimal payments induce strategy prole q pi = (q
(where (qi ) =
)
t(1, qi ) t(0, qi )) Q, pi = 0 N \ Q. Let = {i|qi (0, 1)}
(|| 2 assumption), consider deviation coalition pure strategy
prole q , , qi = 1. q denote new prole (i.e., q = (q , q )).
next show , ui (q) < ui (q ), thus q resilient deviation
. Since qi (0, 1), must indierent ai = 0 ai = 1 (see claim 2.1);
therefore, utility q is:
ui (q) = ui (0, qi ) = ci

t(0, qi )
(qi )

utility q is:
ci
ui (q ) = t(q )pi ci = t(q )
ci = ci
(qi )






(

t(q )
1
(qi )

)

(
= ci

t(q ) t(1, qi ) + t(0, qi )
(qi )

)

Therefore, ui (q ) > ui (q) t(q ) t(1, qi ) > 0, holds assumption
|| 2 monotonicity t.
2

Appendix E. Algorithmic Aspects
E.1 Results Mixed Case
next show black box model, exponential number queries needed
determine optimal mixed contract. proved optimal pure contract
(for completeness present claim Theorem E.2, taken (Babaio et al., 2006a)),
show also holds mixed case.
Theorem 7.1 Given input black box success function (when costs
identical), value v, number queries needed, worst case, nd
optimal mixed contract exponential n.
Proof: show optimal mixed contract technology presented Theorem E.2 value c(k + 1/2) support exactly , thus claim direct result
Theorem E.2.
366

fiMixed Strategies Combinatorial Agency

Assume q optimal mixed contract value c(k + 1/2). support q must
size k, otherwise payment case success least c(k +1) > c(k +1/2)
(as agent support must paid least c), implies negative utility.
support size k exactly , least one agent
paid c/ > c(k + 1/2) suciently small > 0. Thus case utility
negative.
2
Next show read-one network optimal mixed contract #P -hard.
based theorem work Babaio et al. (2006a) cited Theorem E.3 below.
Theorem 7.2 Optimal Mixed Contract Problem Read Networks #P -hard
(under Turing reductions).
Proof: use reduction presented Theorem E.3. prove x close enough
1/2, transition point E E {x} pure case, optimal mixed
contract pure (also E E {x}). implies use argument
Theorem E.3 calculate network reliability (which #P -hard) using algorithm
optimal mixed contract.
Lemma E.1 presents generalization lemma work Babaio et al.
(2006a) mixed case. lemma implies value v x rst entered
support optimal mixed contract q, contract x optimal value
v t(E). single edge, optimal mixed contracts pure, thus x exerts
eort probability 1. Additionally, contract original graph (with edges E)
optimal value v (1 x ), thus x close enough 1/2, v large enough
optimal mixed contract agents exerting eort probability 1 (pure).
2

Let g h two Boolean functions disjoint inputs let f = g h (i.e., take
networks series). optimal mixed contract f v, denoted qS ,
composed h-part g-part, call mixed prole parts qT qR
respectively.

Lemma E.1 Let qS optimal mixed contract f = g h v. Then, qT
optimal mixed contract h v tg (qR ), qR optimal mixed contract g
v th (qT ).
proof proof pure case, presented work Babaio et al.
(2006b).
E.2 Results work Babaio et al. (2006b) Pure Case
following results cited work Babaio et al. (2006b), completeness.
Theorem E.2 Given input black box success function (when costs
identical), value v, number queries needed, worst case, nd
optimal contract exponential n.
Proof: Consider following family technologies. small > 0 k = n/2
dene success probability given set follows. |T | < k, t(T ) = |T | .
|T | > k, t(T ) = 1 (n |T |) . set agents size k, technology
tT dened t(T ) = 1 (n |T |) t(T ) = |T | = size k.
367

fiBabaioff, Feldman & Nisan

value v = c (k + 1/2), optimal contract tT (for contract
utility principal v c k = 1/2 c > 0, contract utility
negative).
( n )
2 sets size k, cannot always
algorithm queries n/2
determine optimal contract (as
( n of) sets queried might
optimal one). conclude n/2
1 queries needed determine optimal
contract, exponential n.
2
Let t(E) denote probability success edge succeeds probability
e . rst notice even computing value t(E) hard problem: called
network reliability problem known #P hard (Provan & Ball, 1983).
little eort reveal problem easier:
Theorem E.3 Optimal Contract Problem Read Networks #P -hard (under
Turing reductions).
Proof: show algorithm problem used solve network
reliability problem. Given instance network reliability problem < G, {e }eE >
(where e denotes es probability success), dene instance optimal contract
problem follows: rst dene new graph G obtained Anding G
new player x, x close 12 x = 1 x . edges, let e = e
e = e /2. choosing x close enough 12 , make sure player x enter
optimal contract large values v, agents contracted (if
nd optimal contract value, easy nd value
original network optimal contract E, keep doubling value asking
c
larger
optimal contract. nd value, choose x s.t. 12
x
value). Let us denote x = 1 2x .
critical value v player x enters optimal contract G , found
using binary search algorithm supposedly nds optimal contract
network value. Note critical value v, principal indierent
set E E {x}. write expression indierence, terms
t(E) ti (E) , observe following.
(
t(E)x v


iE

c
x ti (E \ i)

)

(
= t(E)(1x ) v


iE

c
c

(1 x ) ti (E \ i) t(E) x

)


(1 x ) c
(x )2 v
thus, always nd optimal contract also able compute value
t(E).
2
t(E) =

References
Aumann, R. (1959). Acceptable Points General Cooperative n-Person Games. Contributions Theory Games, Vol. 4.
368

fiMixed Strategies Combinatorial Agency

Babaio, M., Feldman, M., & Nisan, N. (2006a). Combinatorial agency. ACM EC06,
pp. 1828.
Babaio, M., Feldman, M., & Nisan, N. (2006b). Combinatorial agency. Full version.
Feldman, M., Chuang, J., Stoica, I., & Shenker, S. (2007). Hidden-Action Multi-Hop
Routing.. IEEE JSAC Special Issue Non-Cooperative Behavior Networking.
Harsanyi, J. C. (1973). Games randomly disturbed payos: new rationale mixedstrategy equilibrium points. International Journal Game Theory, 2 (1), 123.
Holmstrom, B. (1982). Moral Hazard Teams. Bell Journal Economics, 13, 324340.
Mass-Colell, A., Whinston, M., & Green, J. (1995). Microeconomic Theory. Oxford University Press.
Nisan, N., & Ronen, A. (2001). Algorithmic mechanism design. Games Economic
Behaviour, 35, 166 196. preliminary version appeared STOC 1999.
Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. V. (2007). Algorithmic Game
Theory. Cambridge University Press.
Provan, J. S., & Ball, M. O. (1983). complexity counting cuts computing
probability graph connected. SIAM J. Comput., 12 (4), 777788.
Strausz, R. (1996). Moral hazard sequential teams. Departmental Working Paper. Free
University Berlin.
Winter, E. (2004). Incentives Discrimination. American Economic Review, 94, 764773.

369

fiJournal Articial Intelligence Research 38 (2010) 85-133

Submitted 05/09; published 05/10

BnB-ADOPT:
Asynchronous Branch-and-Bound DCOP Algorithm
William Yeoh

wyeoh@usc.edu

Computer Science Department,
University Southern California,
Los Angeles, CA 90089, USA

Ariel Felner

felner@bgu.ac.il

Information Systems Engineering,
Deutsche Telekom Labs,
Ben-Gurion University Negev,
Beer-Sheva, 85104, Israel

Sven Koenig

skoenig@usc.edu

Computer Science Department,
University Southern California,
Los Angeles, CA 90089, USA

Abstract
Distributed constraint optimization (DCOP) problems popular way formulating
solving agent-coordination problems. DCOP problem problem several agents coordinate values sum resulting constraint costs minimal. often
desirable solve DCOP problems memory-bounded asynchronous algorithms. introduce Branch-and-Bound ADOPT (BnB-ADOPT), memory-bounded asynchronous DCOP search
algorithm uses message-passing communication framework ADOPT (Modi, Shen,
Tambe, & Yokoo, 2005), well known memory-bounded asynchronous DCOP search algorithm,
changes search strategy ADOPT best-first search depth-first branch-and-bound
search. experimental results show BnB-ADOPT finds cost-minimal solutions one
order magnitude faster ADOPT variety large DCOP problems fast
NCBB, memory-bounded synchronous DCOP search algorithm, DCOP
problems. Additionally, often desirable find bounded-error solutions DCOP problems
within reasonable amount time since finding cost-minimal solutions NP-hard. existing bounded-error approximation mechanism allows users specify absolute error bound
solution cost relative error bound often intuitive. Thus, present two
new bounded-error approximation mechanisms allow relative error bounds implement
top BnB-ADOPT.

1. Introduction
distributed constraint optimization (DCOP) problem consists agents, responsible taking
(= assigning itself) value nite domain values. agents coordinate values,
subject constraints. Two agents constrained share constraint.
constraint associated constraint cost, depends values constrained agents.
(complete) solution assignment values agents, partial solution assignment
values subset agents. solution cost (partial complete) solution sum
constraint costs constraints resulting given assignment values agents. Solving
DCOP problem optimally means nding solution minimal solution cost NP-hard (Modi
et al., 2005).
Formulating agent-coordination problems constraint optimization (COP) problems, specic
type weighted constraint satisfaction problems (Schiex, Fargier, & Verfaillie, 1995; Bistarelli,

c
2010
AI Access Foundation. rights reserved.

fiYeoh, Felner & Koenig

a1

a2
a3

a1
a4

a2
a3

(a)

a4

a1
0
0
1
1
a2
0
0
1
1

a2
0
1
0
1
a3
0
1
0
1

Constraint Cost
5
8
20
3
Constraint Cost
5
4
3
3

(b)

a1
0
0
1
1
a2
0
0
1
1

a3
0
1
0
1
a4
0
1
0
1

Constraint Cost
5
10
20
3
Constraint Cost
3
8
10
3

(c)

Figure 1: Example DCOP Problem
Montanari, Rossi, Schiex, Verfaillie, & Fargier, 1999), general formulating
common constraint satisfaction problems (Dechter, 2003). Constraint satisfaction problems
constraints either satised unsatised. Solving constraint satisfaction problem
means nding solution constraints satised. example application
scheduling jobs job-shop, constraints express jobs performed
certain machines jobs performed jobs. could
potentially multiple solutions satisfy constraints. However, solutions might
desirable others. example, one might prefer solution shortest completion time.
Unfortunately, constraint satisfaction problems cannot capture preferences. However, COP
problems able using constraint costs represent preferences.
DCOP algorithms better suited compared COP algorithms problems naturally distributed. result, DCOP algorithms applied coordinating unmanned
aerial vehicles (Schurr, Okamoto, Maheswaran, Scerri, & Tambe, 2005), scheduling meetings (Maheswaran, Tambe, Bowring, Pearce, & Varakantham, 2004b; Petcu & Faltings, 2005b; Greenstadt,
Grosz, & Smith, 2007; Zivan, 2008; Yeoh, Varakantham, & Koenig, 2009), coordinating sensor networks (Lesser, Ortiz, & Tambe, 2003; Zhang, Xing, Wang, & Wittenburg, 2003; Modi et al., 2005;
Jain, Taylor, Tambe, & Yokoo, 2009; Stranders, Farinelli, Rogers, & Jennings, 2009; Zivan, Glinton,
& Sycara, 2009), synchronizing trac lights (Junges & Bazzan, 2008), planning truck routes (Ottens
& Faltings, 2008) managing power distribution networks (Kumar, Faltings, & Petcu, 2009).
common visualize DCOP problem constraint graph vertices
agents edges constraints. DCOP algorithms operate pseudo-tree,
spanning tree (completely connected) constraint graph property edges
constraint graph connect vertex one ancestor descendant vertices
constraint tree (Freuder & Quinn, 1985; Bayardo & Miranker, 1995). edge constraint
graph part pseudo-tree backedge. agent c pseudo-child agent
agent p agent c descendant agent agent p pseudo-tree constrained
via backedge. Similarly, agent p pseudo-parent agent agent c. Sibling subtrees represent
independent DCOP subproblems (since two agents dierent sibling subtrees share constraint).
Figure 1(a) shows constraint graph example DCOP problem four agents
take value 0 value 1, Figure 1(b) shows one possible pseudo-tree assignments
values agents a3 a4 independent DCOP subproblems (the dotted line backedge),
Figure 1(c) shows constraint costs. example DCOP problem, cost-minimal solution
results agents take value 1. minimal solution cost 12.
1.1 DCOP Algorithms
provide taxonomy DCOP algorithms. Figure 2 shows taxonomy. DCOP algorithms
divided two groups: complete incomplete DCOP algorithms. Complete DCOP algorithms nd cost-minimal solutions incomplete DCOP algorithms often faster typically
nd suboptimal solutions.
86

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

DCOP Algorithms

Incomplete Algorithms
e.g., DBA, DSA, MGM,
k-optimal algorithms

Complete Algorithms

Partially Centralized Algorithms
e.g., OptAPO

Fully Decentralized
Algorithms

Search Algorithms
e.g., SBB, ADOPT,
NCBB, AFB

Inference Algorithms
e.g., DPOP

Figure 2: Taxonomy DCOP Algorithms
1.1.1 Incomplete DCOP Algorithms
Incomplete DCOP algorithms typically use local search nd locally optimal solutions
thus potentially get trapped local minima. Nevertheless, since solving DCOP problems optimally
NP-hard, DCOP algorithms desirable large DCOP problems nding costminimal solutions might slow. DBA (Yokoo & Hirayama, 1996), DSA (Fitzpatrick & Meertens,
2003), MGM (Maheswaran, Pearce, & Tambe, 2004a) recent class k-optimal DCOP
algorithms (Pearce & Tambe, 2007; Bowring, Pearce, Portway, Jain, & Tambe, 2008; Greenstadt,
2009) examples incomplete DCOP algorithms.
1.1.2 Complete DCOP Algorithms
Complete DCOP algorithms generally divided two groups, namely partially centralized
fully decentralized DCOP algorithms.
Partially Centralized DCOP Algorithms
Partially centralized DCOP algorithms allow agents transfer constraint information
(= information regarding constraints involved in) central agent processing. OptAPO (Mailler & Lesser, 2004) example partially centralized DCOP algorithm
uses cooperative mediation, certain agents act mediators solve overlapping DCOP
subproblems centrally.
Fully Decentralized DCOP Algorithms
Fully decentralized DCOP algorithms central agents collect constraint information agents constrained them. Rather, every agent access
constraint information. Fully decentralized DCOP algorithms generally divided two
groups, namely DCOP inference search algorithms.
DCOP inference algorithms: DCOP inference algorithms typically use dynamic programming propagate aggregated constraint costs one agent another agent thus reduce
87

fiYeoh, Felner & Koenig

DCOP
Algorithm
SBB
ADOPT
NCBB
AFB
BnB-ADOPT

Search
Strategy
DFBnB
best-first
DFBnB
DFBnB
DFBnB

Agent
Operation
sequential & synchronous
concurrent & asynchronous
sequential & synchronous
concurrent & asynchronous
concurrent & asynchronous

Communication
point-to-point neighbors
point-to-point neighbors
point-to-point neighbors
broadcast agents
point-to-point neighbors

Agent
Ordering
chain
tree
tree
chain
tree

Table 1: Properties DCOP Search Algorithms

DCOP problem size one agent step. repeat procedure DCOP
problem size reduced one agent solution space (= space possible partial solutions) thus cannot reduced anymore. sole remaining agent sucient
knowledge nd cost-minimal solution. DPOP (Petcu & Faltings, 2005b) example
DCOP inference algorithm. number messages sent agents linear
number agents. However, memory requirements exponential induced
width DCOP problem. induced width depends number backedges
pseudo-tree. large number agents minus one constraint graph
fully connected every agent thus constrained every agent.
DCOP search algorithms: DCOP search algorithms use search strategies search
solution space nd cost-minimal solution. ADOPT (Modi et al., 2005) uses best-rst
search, SBB (Hirayama & Yokoo, 1997), NCBB (Chechetka & Sycara, 2006), AFB (Gershman, Meisels, & Zivan, 2009) new DCOP search algorithm, BnB-ADOPT, use
depth-rst branch-and-bound search. memory requirements polynomial
number agents. However, number messages sent agents exponential
number agents.
Therefore, groups fully decentralized DCOP algorithms desirable dierent
conditions tradeo space (memory requirements) time (number messages
sent).
1.2 Motivation
describe motivation behind work.
1.2.1 BnB-ADOPT
study DCOP search algorithms memory-bounded. property important applications, sensor networks, every agent/sensor xed amount
memory available. result, several DCOP search algorithms, SBB, ADOPT, NCBB
AFB, developed limitation mind. described earlier, memory requirements
polynomial number agents. Table 1 shows properties DCOP search algorithms well properties new DCOP search algorithm, BnB-ADOPT. describe
property detail justify properties BnB-ADOPT.
Search strategy: ADOPT uses best-rst search search solution space, SBB,
NCBB AFB use depth-rst branch-and-bound (DFBnB) search. Best-rst search repeatedly searches next best partial solution nds cost-minimal solution. next
best partial solution cost-minimal partial solution among partial solutions
yet found. Depth-rst branch-and-bound search starts nding complete (but

88

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

often suboptimal) solution stores solution cost upper bound. continues
search solution whose solution cost less upper bound. stores solution
cost solution upper bound, search proceeds longer nd
solution whose solution cost less upper bound.
centralized search, known search problems depth-bounded search trees
often solved faster depth-rst branch-and-bound search memory-bounded
best-rst search memory-bounded best-rst search algorithms, RBFS (Korf,
1993), need repeatedly reconstruct partial solutions purged memory. Depthrst branch-and-bound search algorithms memory-bounded suer
problem (Zhang & Korf, 1995). Since DCOP problems search problems depthbounded search trees, hypothesize depth-rst branch-and-bound search might faster
best-rst search. Therefore, decided BnB-ADOPT use depth-rst branchand-bound search.
Agent operation: Agents SBB NCBB operate sequentially. agents tokens
active agents remain idle. token-holding agents done, pass
tokens remain idle. hand, agents ADOPT AFB operate
concurrently (= times). Agents operate concurrently might able solve DCOP
problems faster agents operate sequentially since former agents perform
potentially useful computation instead wait agents. Therefore,
decided agents BnB-ADOPT operate concurrently. Agents SBB NCBB
also operate synchronously. Communication agents often form messages.
Synchronous agents operate cycles (Modi et al., 2005). cycle time required
agent process incoming messages queue send outgoing messages,
processed receiving agents next cycle (see Section 6.1 details).
Therefore, agents wait last agent done sending messages start
new cycle. hand, asynchronous agents, agents ADOPT AFB,
able operate independently other, often increases robustness (Silaghi,
Landwehr, & Larrosa, 2004). example, synchronous agents aected single
communication link suers congestion small number asynchronous agents
aected. therefore decided agents BnB-ADOPT operate asynchronously.
Communication:
DCOP search algorithms SBB, ADOPT NCBB restrict
communication agents share constraints. restriction motivated applications
sensor networks communication restricted neighboring agents/sensors due
limited communication radius. Neighboring sensors share constraints since need
coordinate sense areas near them. DCOP search algorithms AFB
restriction allow agents broadcast messages agents. decided
agents BnB-ADOPT obey restrictions applications sensor networks
thus communicate neighboring agents.
Agent ordering: DCOP search algorithms mentioned start pre-processing
step arranges agents pseudo-tree. DCOP search algorithms SBB
AFB arrange agents chain, ADOPT NCBB arrange agents tree.
tree ordering capture independent DCOP subproblems (represented sibling subtrees)
chain ordering not. DCOP search algorithms operate trees thus
operate independent DCOP subproblems independently, DCOP search algorithms
operate chains not. Therefore, decided BnB-ADOPT arrange
agents tree.
ADOPT preferred properties mentioned except uses best-rst search.
therefore introduce BnB-ADOPT, memory-bounded asynchronous DCOP search algorithm
89

fiYeoh, Felner & Koenig

uses message passing communication framework ADOPT changes search strategy
ADOPT best-rst search depth-rst branch-and-bound search.
1.2.2 Bounded-Error Approximations
Solving DCOP problems optimally NP-hard, makes advantageous allow users trade
solution cost smaller runtime. also desirable error resulting solution
cost bounded provide guarantees solution cost. ADOPT is, best knowledge,
DCOP search algorithm property. Absolute Error Mechanism allows users
specify absolute error bound solution cost, example, solution cost
10 larger minimal solution cost. However, often much desirable
specify relative error bound solution cost, example, solution cost
10 percent larger minimal solution cost or, equivalently, 1.1 times larger
minimal solution cost. cannot done Absolute Error Mechanism without knowing
minimal solution cost priori. Thus, propose two approximation mechanisms allow users
specify relative error bound solution cost, namely Relative Error Mechanism
Weighted Heuristics Mechanism, implement top BnB-ADOPT. approximation
mechanisms allow BnB-ADOPT nd solutions bounded errors faster cost-minimal
solutions.
1.3 Experimental Results
experimentally compare ADOPT, BnB-ADOPT NCBB three dierent DCOP problem
types, namely graph coloring problems, sensor network problems meeting scheduling problems.
results show BnB-ADOPT one order magnitude faster (measured number
non-concurrent constraint checks number cycles) ADOPT variety large
DCOP problems. BnB-ADOPT also inferred faster SBB since ADOPT faster
SBB (Modi et al., 2005). BnB-ADOPT also fast NCBB DCOP
problems. results suboptimal variants BnB-ADOPT show Weighted Heuristics
Mechanism dominates Absolute Error Mechanism Relative Error Mechanism.
1.4 Article Structure
article organized follows: formalize DCOP problems Section 2 describe
DCOP search algorithm, BnB-ADOPT, Section 3. describe approximation mechanisms
allow BnB-ADOPT nd solutions bounded error Section 4. outline correctness
completeness proofs BnB-ADOPT Section 5. Lastly, present experimental evaluations
Section 6 conclusions Section 7.

2. DCOP Problems
section, formally dene distributed constraint optimization (DCOP) problems describe
solution space.
2.1 Definition DCOP Problems
DCOP problem dened following elements:
nite set agents = {a1 , a2 , ..., };
set nite domains = {Dom(a1 ), Dom(a2 ), ..., Dom(an )}, Dom(ai ) domain
possible oating point values agent ai A;

90

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

a1









0

0





b



a2

a2



B

C

5







8

a3
10 14

a4
3

20

a3
8

8

13

a3

a4
10

3

3

25

a4
7

3

a3
8

23

a4
6

c



10





3





g

E
h



e

F
j

k

(a)

G
l



f

H
n




p

q

J
r



K


u

v

(b)

Figure 3: AND/OR Search Tree
set binary constraints F = {f1 , f2 , ..., fm }, constraint fi : Dom(ai1 )
Dom(ai2 ) R+ , species non-negative constraint cost function values
distinct agents ai1 ai2 share constraint.
denition assumes agent takes one value rather multiple values,
example, dierent value constraint involved in. DCOP problems
commonly formulated agent responsible assignments values
multiple variables. However, exist techniques reduce DCOP problems DCOP
problems (Burke & Brown, 2006). Thus, use terms agent variable interchangeably.
denition also assumes constraints binary (= two agents) rather n-ary
(= n agents). One able extend BnB-ADOPT solve DCOP problems nary constraints using techniques proposed extend ADOPT solve DCOP
problems n-ary constraints (Modi et al., 2005). Additionally, assume messages sent
agents delayed nite amount time never lost.
2.2 Search Trees
solution space DCOP problems visualized search trees. Traditional search trees
or, synonymously, search trees (Marinescu & Dechter, 2009) assign values agents sequentially.
utilize fact values agents belong independent DCOP subproblems
assigned sequentially. AND/OR search trees based pseudo-trees remedy
issue (Marinescu & Dechter, 2009). Thus, use AND/OR search trees refer
search trees article. depth bounded (twice) number agents.
Figure 3(a) shows search tree based pseudo-tree Figure 1(b). Figure 3(b)
labels node search tree identier allow us refer nodes easily. Circular
nodes nodes (labeled upper-case letters) correspond agents. example,
agent node C agent a2 . Left branches nodes correspond agents taking value
0 right branches correspond agents taking value 1. Square nodes nodes
(labeled lower-case letters) correspond partial solutions root node
nodes. example, partial solution node f {(a1 , 1), (a2 , 1)}. subtree rooted
node represents DCOP subproblem assumes partial solution node.
example, subtree rooted node f represents DCOP subproblem assigning values
agents a3 a4 given {(a1 , 1), (a2 , 1)}. number independent DCOP subproblems
within DCOP subproblem indicated number branches exiting node.
example, two branches exiting node f , indicating two independent DCOP
subproblems, namely assigning values agents a3 a4 . numbers nodes
delta costs nodes. delta cost node dened sum
constraint costs constraints partial solution involve agent parent node.

91

fiYeoh, Felner & Koenig

example, partial solution node v {(a1 , 1), (a2 , 1), (a4 , 1)}. two constraints
partial solution, namely constraint agents a1 a2 , constraint cost 3,
constraint agents a2 a4 , also constraint cost 3. Since parent
node node v node K agent a4 , delta cost node v 3, namely constraint cost
latter constraint. former constraint included since involve agent a4 .
solution cost partial solution node sum delta costs nodes
along branch root node node. example, solution cost partial
solution node v (= 6) sum delta costs nodes b, f v. example DCOP
problem, cost-minimal solution union partial solutions nodes v (all agents
take value 1). Thus, minimal solution cost (= 12) sum delta costs nodes b, f ,
v.

3. BnB-ADOPT
section, present Branch-and-Bound ADOPT (BnB-ADOPT). describe BnBADOPT modication ADOPT since approach requires readers in-depth
understanding ADOPT. Instead, give stand-alone description BnB-ADOPT requires
knowledge ADOPT, intention creating self-contained hopefully easy-to-read
description.
3.1 Search Strategies ADOPT BnB-ADOPT
rst describe centralized versions search strategies ADOPT BnB-ADOPT omit
technical details since described detail later sections.
3.1.1 Search Strategy ADOPT
ADOPT (Modi et al., 2005) popular DCOP search algorithm (Modi & Ali, 2004; Ali, Koenig,
& Tambe, 2005; Bowring, Tambe, & Yokoo, 2006; Davin & Modi, 2006; Pecora, Modi, & Scerri,
2006; Choxi & Modi, 2007; Silaghi & Yokoo, 2009; Matsui, Silaghi, Hirayama, Yokoo, & Matsuo,
2009) traverses search tree best-rst search order. describe simplied version
best-rst search. complete version found (Marinescu & Dechter, 2007). Bestrst search maintains list initially contains child nodes root node.
repeatedly performs following operations: expands node smallest solution
cost list removing node list adding grandchild nodes
node list. example DCOP problem, best-rst search expands nodes
search tree Figure 3 rst time following order, numbers parentheses
indicate solution costs partial solutions expanded nodes: (0), b (0), f (3), c (5),
v (6), (8), (8) (9).
Figure 4 shows simplied trace ADOPT example DCOP problem. ADOPT terminates
fteen steps minimal solution cost 12. numbers nodes delta costs
r
nodes. lower bound LBX
r optimistic estimate minimal solution cost.
smallest underestimated solution cost, solutions. underestimated solution cost
solution sum delta costs nodes solution whose parent node
root node whose grandparent node expanded. example, underestimated
solution cost solution {(a1 , 1), (a2 , 1), (a3 , 1), (a4 , 1)} 3 node b expanded nodes f ,
r
v expanded. upper bound U BX
r pessimistic estimate minimal solution
cost. solution cost solution smallest solution cost found far. ADOPT
r
r
terminates upper bound U BX
r larger lower bound LBX r . order
memory-bounded, ADOPT maintains one branch search tree (shaded grey gure)
root node currently expanded node thus needs repeatedly reconstruct nodes

92

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

LBrXr = 0









b





B

C



c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

r



K


u



v



0

0

a2

a2

5



J

a3

8
a4

10 14 3

a3
8

a1







8 13 10 3 25 7



a3

0
a2
8

10 14 3

=5
= infinity

0

a4

a3
8



3
a4

8 13 10 3 25 7

3

a1





20
a3

a4

a3

8 23 6 10 3



a3

0

0
a2
8

a4

10 14 3

a3





a3

0

8
a4

10 14 3

a3
8

8

3

a3

a1





8 23 6 10 3





a3



a3

0
a2
8

10 14 3

=8
= infinity

0

a4

a3

0

8

10 14 3

8

8





3

a3



a3
10 14 3

8

= 12
= infinity

0

0
a2

a3





a3

8

8 13 10 3 25 7

10 14 3

8





a3

0
a2
8

10 14 3

a3
8



a3

8 13 10 3 25 7

3
a4

3

a3

8 23 6 10 3





a3

3

8 13 10 3 25 7





a3

0

0
a2
8

a4

10 14 3

a3
8

10 14 3

8

a1





3

a3

8 13 10 3 25 7



a3

0
a2

10 14 3

8

20
a4

a3

8 13 10 3 25 7





0

0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

3
a4

3

a3

a4

8 23 6 10 3

Step 15

Figure 4: Trace Simplied Memory-Bounded Best-First Search (Centralized ADOPT)

93

a4

8 23 6 10 3

= 12
= 12

0

a3

a4

8 23 6 10 3

Step 14

LBrXr
UBrXr

8
a4

3

a3

a2
5



a4

8 23 6 10 3

a2
5





3
a4

a1 UBrXr = infinity



Step 13


a3

LBrXr = 12

3
a4

8 13 10 3 25 7

Step 12

20
a4





20
a3

a4

a4

8 23 6 10 3

a2
5



a4

= 12
= infinity
0

8

3

a3

Step 11

LBrXr
UBrXr

a2

a3

3
a4

a1 UBrXr = infinity



8 23 6 10 3

0

a4

a3

LBrXr = 8

a3

a2
5



a4

20
a4



3
a4

8 13 10 3 25 7

a1

a4

8 23 6 10 3

0

a4



20



3

a3

a2
5



a4

=8
= infinity

a3

a4

3
a4

Step 8

LBrXr
UBrXr

0

a3

a3

a1 UBrXr = infinity



8 23 6 10 3

a2

a4



20
a4

8

20
a4

Step 10

LBrXr
UBrXr

8
a4

3

0

5



a4

8 23 6 10 3

a2
5





10 14 3

a3

LBrXr = 8

a3

a2

Step 9
a1

8
a4



3
a4

8 13 10 3 25 7

a1



3
a4

8 13 10 3 25 7





a3



20
a3

a4





20
a3

a4



0
a2

Step 5

a2

a3

a4

8 23 6 10 3

0

5



a4

8 23 6 10 3

0

a4

3

a3

a2

Step 7

a2
5





3

a3

a2
5



a4

3
a4

a1 UBrXr = infinity



a1 UBrXr = infinity



a3

8 13 10 3 25 7



3
a4

8 13 10 3 25 7

Step 6
LBrXr
UBrXr

20
a4

LBrXr = 8

3
a4

8 13 10 3 25 7



8



20
a3

a4





20
a3

a4

10 14 3

a3

Step 4

a2
5





8
a4

LBrXr = 8

=5
= infinity

a2

LBrXr = 8





a3

Step 2

LBrXr
UBrXr

0

5



a4

a1 UBrXr = infinity





0
a2

5



a4

8 23 6 10 3

a2

Step 3


3

a3

0
a2

Step 1

a2
5







3
a4

a1 UBrXr = infinity





20
a3

a4

Identifiers
LBrXr
UBrXr

LBrXr = 3

a1 UBrXr = infinity



fiYeoh, Felner & Koenig

LBrXr = 0









b





B

C



c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

r



K


u



v



0

0

a2

a2

5



J

a3

8
a4

10 14 3

a3
8

a1









a3

0
a2
8

10 14 3

=0
= infinity

0

a4

a3

8 13 10 3 25 7

8





3
a4

8 13 10 3 25 7

3

a1



20
a3

a4

a1





a3



a3





a3

8

8 13 10 3 25 7

8

10 14 3

a3

a1





8



a3

3

a3

8 23 6 10 3





a3
10 14 3

8

0
a2

10 14 3

8



a3

0
a2
8

a4

10 14 3

a3
8



a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 13 10 3 25 7



3

a3

8 23 6 10 3





a3

8

10 14 3

8





0

0
a2

a3

8
a4

10 14 3

a3
8

20
a4

3

a3

a4

8 13 10 3 25 7

3

a3

a4

8 23 6 10 3



3
a4

3

a1 UBrXr = 18



20
a3

8 13 10 3 25 7

Step 9

a4

8 23 6 10 3

LBrXr = 12

0

a4

3

a3

a2



a2

a3

a4

Step 8

LBrXr = 12
UBrXr = 18

0

a4

3

a3

8 13 10 3 25 7

5



a4

8 23 6 10 3

a2
5



a4

20
a4

a1 UBrXr = 18



3

a3

a1



20
a4



0



20



a4

8 23 6 10 3

LBrXr = 0

=0
= 18
0

a4

3

a3

Step 5

LBrXr
UBrXr

8

a4

a2
5



a4

8 23 6 10 3

a2

a3

3

a3

8 13 10 3 25 7

Step 7

0

a3

3

0

a4

20
a4

a1 UBrXr = 18



a3

a2
5



a4

LBrXr = 3
UBrXr = 18

8
a4

8



3
a4

8 13 10 3 25 7

a1



3
a4

a2
5





10 14 3

a3



20
a3

a4

Step 6


8
a4

LBrXr = 0

=0
= infinity
0

a4



20
a3

a4

a3

Step 2

LBrXr
UBrXr

a2



0

8

10 14 3

=0
= 18

a2

a3



0
a2

Step 4

LBrXr
UBrXr

0

a4



0
a2
5



a4

8 23 6 10 3

0

5



a4

8 23 6 10 3

a2
5





3

a3

a2

Step 3




Step 1

a2
5







3
a4

a1 UBrXr = infinity



20
a3

a4

Identifiers
LBrXr
UBrXr

LBrXr = 0

a1 UBrXr = infinity



a3

8 23 6 10 3

Step 10





0
a2

5



a4

0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 23 6 10 3

Step 11

LBrXr = 12

a1 UBrXr = 12









0
a2

5





0
a2

a3
10 14 3

8
a4

a3
8

20
a4

a3

8 13 10 3 25 7

3
a4

3

a3

a4

8 23 6 10 3

Step 12

Figure 5: Trace Simplied Depth-First Branch-and-Bound Search (Centralized BnB-ADOPT)
purged memory. example, Step 3, ADOPT branch node f memory.
next node best-rst search expands node c, ADOPT discards branch node f
Step 4. Steps 6 7, needs reconstruct discarded branch node f order
expand node v Step 8.
3.1.2 Search Strategy BnB-ADOPT
describe simplied version depth-rst branch-and-bound search. complete version
r
r
found (Marinescu & Dechter, 2009). use denitions LBX
r U BX r
described earlier Figure 4. Depth-rst branch-and-bound search maintains stack initially
contains child nodes root node. expands node top

94

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

stack removing node stack performing following check. solution
r
cost node smaller upper bound U BX
r , prunes node repeats
operation. Otherwise, adds grandchild nodes node top stack
r
repeats operation. terminates upper bound U BX
r larger lower bound
r
LBX r . Depth-rst branch-and-bound search add grandchild nodes expanded
node (and child nodes root node) decreasing order solution costs
instead random order top stack. ordering ensures depth-rst branchand-bound search expands grandchild node smallest solution cost rst. use
improvement throughout article. example DCOP problem, depth-rst branch-andbound search expands nodes search tree following order, prunes
nodes brackets: (0), c (5), (8), j (13), g (15), [h (19)], (8), n (11), k (16), [m (18)], [l (21)],
b (0), f (3), v (6) (9). Figure 5 shows trace depth-rst branch-and-bound search
example DCOP problem. memory-bounded without repeatedly reconstruct nodes
purged memory expands nodes best-rst search expand,
node j Step 4. depth-rst branch-and-bound search terminates twelve steps
minimal solution cost 12, three steps fewer ADOPT.
3.2 Description BnB-ADOPT
provide incremental description BnB-ADOPT. First, provide notations key
terms BnB-ADOPT. Then, describe BnB-ADOPT updates bounds, adheres memory
limitations, performs depth-rst search performs branch-and-bound. Finally, introduce
enhanced nal version BnB-ADOPT show pseudocode trace example
DCOP problem.
3.2.1 Notation Key Terms
adopt following notation ADOPT describe BnB-ADOPT:
V alInit(a) Dom(a) initial value agent A;
CD(a) set child pseudo-child agents agent A;
C(a) CD(a) set child agents agent A;
pa(a) parent agent agent except root agent;
P (a) set ancestor agents (including parent agent) agent A;
SCP (a) P (a) set ancestor agents (including parent agent) agent
parent pseudo-parent agents agent one (or more) descendant agents;
CP (a) SCP (a) set ancestor agents (including parent agent) agent
parent pseudo-parent agents agent a.
adopt following key terms ADOPT describe BnB-ADOPT:
Context (X): context X agent set values ancestor agents agent
a. context X r root agent r always equal {}.

Delta cost (): delta cost X
(d) sum constraint costs constraints
involve agent one ancestor agents, assumption agent
takes value ancestor agents take values context X . search tree,


X
(a, d). example,
(d) delta cost node partial solution X
a2
{(a1 ,1)} (1) delta cost node f Figure 3.

95

fiYeoh, Felner & Koenig



Gamma cost (): gamma costs X
(d) X dened follows:



X
(d) := X (d) +



c
X
(a,d)

(1)

cC(a)

X
:=

min


{X
(d)}

dDom(a)

(2)


agents a, values contexts X . Thus, gamma cost X
(d) sum
constraint costs constraints involve agent one descendant agents (that
is, either agent one ancestor agents, agent one descendant
agents, descendant agent ancestor agent agent two descendant agents
agent a) minimized possible values descendant agents, assumption
agent takes value ancestor agents take values context X . search


(a, d).
tree, X
(d) gamma cost node partial solution X
a2

example, {(a1 ,1)} (1) gamma cost node f Figure 3. gamma cost X
sum
constraint costs constraints involve agent one descendant agents
minimized possible values agent descendant agents, assumption
ancestor agents agent take values context X . search tree,

gamma cost X
gamma cost node whose agent agent whose parent
a2
gamma cost node C
node partial solution X . example, {(a
1 ,1)}
Figure 3. Therefore, gamma cost node sum delta cost
gamma costs child nodes, gamma cost node minimum
gamma costs child nodes. example, gamma cost node f Figure 3
sum delta cost gamma costs nodes J K, gamma cost
node C Figure 3 minimum gamma costs nodes e f .
r
Solving DCOP problem optimally means determine X
r root agent r or, equivalently,
r
gamma cost root node since X r minimal solution cost. dicult
agents cache information allows determine cost-minimal solution.

3.2.2 Updating Bounds
Every agent BnB-ADOPT stores updates several bounds gamma costs, namely
a,c




lba,c
X (d), LBX (d), LBX , ubX (d), U BX (d) U BX values d, child agents c

contexts X , maintaining following bound property:

LBX


LBX
(d)
a,c
lbX (d)





X


X
(d)
c
X
(a,d)


U BX


(3)




(4)
(5)


U BX
(d)
a,c
ubX (d)

search tree,


LBX
U BX lower upper bounds, respectively, (on gamma cost)
node whose agent agent whose parent node partial solution X ;


LBX
(d) U BX (d) lower upper bounds, respectively, (on gamma cost)
node partial solution X (a, d);
a,c
lba,c
X (d) ubX (d) lower upper bounds, respectively, (on gamma cost)
node whose agent agent c whose parent node partial solution X (a, d).

96

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

a2
a2
a2
example, LB{(a
U B{(a
bounds node C Figure 3, LB{(a
(1)
1 ,1)}
1 ,1)}
1 ,1)}
a2 ,a3
a2 ,a3
a2
U B{(a1 ,1)} (1) bounds node f , lb{(a1 ,1)} (1) ub{(a1 ,1)} (1) bounds node J.
a3
a3
2 ,a3
2 ,a3
lba{(a
(1), uba{(a
(1), LB{(a
U B{(a
bounds node J, agent
1 ,1)}
1 ,1)}
1 ,1),(a2 ,1)}
1 ,1),(a2 ,1)}
a2 maintains rst two bounds agent a3 maintains last two bounds.
agent uses following update equations values d, child agents c
a,c
a,c
contexts X initialize bounds lba,c
X (d) ubX (d), heuristic values hX (d)
a,c
c
oating point numbers admissible thus satisfy 0 hX (d) X (a,d) :

a,c
lba,c
X (d) := hX (d)

uba,c
X (d)

:=

(6)
(7)

Agent uses repeatedly following update equations values d, child agents c,
contexts X contexts X c (= X (a, d)) tighten bounds:
a,c
c
lba,c
X (d) := max{lbX (d), LBX c }
a,c


LBX
lbX (d)
(d) := X (d) +

(8)
(9)

cC(a)

LBX
:=

uba,c
X (d) :=

U BX
(d)

:=


U BX
:=


min {LBX
(d)}
dDom(a)
c
min{uba,c
X (d), U BX c }


X
uba,c
(d) +
X (d)
cC(a)

min


{U BX
(d)}

dDom(a)

(10)
(11)
(12)
(13)

updates maintain bound property improve bounds monotonically, is,
lower bounds monotonically non-decreasing upper bounds monotonically nona


increasing.1 nite amount time, U BX
LBX agents contexts X .
r
r
BnB-ADOPT terminates termination condition U BX r LBX r root agent r
r
r
r
r
satised. Then, U BX
r LBX r bound property U BX r LBX r together imply
r
r
r
U BX r = X r = LBX r , DCOP problem solved optimally.
Figure 6 shows simplied trace updates (lower upper) bounds example
DCOP problem. assume updates proceed sequentially leaf agents root
agent. Due simplication, lower upper bounds node identical
gamma cost independent heuristic values. numbers nodes bounds.
Two agents maintain bounds nodes except root node. gure shows bounds
parent agent maintains rather bounds child agent maintains. example,
number node B bounds agent a1 rather agent a2 maintains. bounds
child agent maintains computed taking minimum bounds child
nodes node. Agents update bound node sum delta cost
bounds child nodes according update equations 9 12. update
bound node minimum bounds child nodes according update
equations 10 13. detailed description trace follows:
Step 1: Leaf agent a3 updates bounds nodes g, h, k, l, o, p,
delta costs according update equations 9 12 bounds nodes D, F , H
1. Leaf agents use update equations. Since child agents, sums child agents
(d) = U B (d) = (d) leaf agents a, values contexts X .
evaluate 0. example, LBX

Xa
Xa

97

fiYeoh, Felner & Koenig





0



0







b



0

0



0



B

C



0

0



0

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



K


0



u



v



0

0
0

10 14 3

0
8

0
0

0

8 13 10 3 25 7

Identifiers

0
0
3

0

8 23 6 10 3

Step 1

18



18

10 14 3

3

8
8

30
3

7

8 13 10 3 25 7

12
3

3

6

3

8 23 6 10 3

Step 2

12
12

18







10

19

12









0

18



0

0

10
10 14 3

19
3

8
8

30
3

7

8 13 10 3 25 7

12
3

3

6

3

8 23 6 10 3

Step 3

Figure 6: Simplied Trace Updates (Lower Upper) Bounds
J minimum bounds child nodes according update equations 10
13. Similarly, leaf agent a4 updates bounds nodes i, j, m, n, q, r, u
v delta costs according update equations 9 12 bounds nodes
E, G, K minimum bounds child nodes according update
equations 10 13. bounds nodes K shown gure since
(yet) maintained agent a2 .
Step 2: Agent a2 updates bounds nodes K maintains bounds
nodes leaf agents a3 a4 maintain according update equations 8
11, bounds nodes c f sum delta costs bounds
child nodes according update equations 9 12 bounds nodes B
C minimum bounds child nodes according update equations 10
13. bounds nodes B C shown gure since (yet)
maintained agent a1 .
Step 3: Agent a1 updates bounds nodes B C maintains bounds
nodes agent a2 maintains according update equations 8 11,
bounds nodes b sum delta costs bounds child
nodes according update equations 9 12 bounds node minimum
bounds child nodes according update equations 10 13. Since
lower upper bounds node equal gamma cost, lower upper bounds
root node equal gamma cost, turn equal minimal solution
cost. propagation terminates three steps minimal solution cost 12.
3.2.3 Adhering Memory Limitations
description BnB-ADOPT far assumes memory limitations. However, BnB-ADOPT
memory-bounded DCOP search algorithm memory requirements per agent linear
number agents. describe BnB-ADOPT adheres memory limitations
using techniques introduced ADOPT apply BnB-ADOPT well.
simplied trace Figure 6 assumes every agent maintains bounds values d,
child agents c contexts X . number contexts exponential depth
agent pseudo-tree. example DCOP problem, agent a3 four dierent contexts
four dierent combinations values ancestor agents a1 a2 . agent cannot maintain
98

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

exponential number bounds due memory limitations. Therefore, every agent maintains
bounds one context given time. context stored variable X
agent a. size context linear number agents. number bounds
agent linear product domain cardinality number child agents.
Thus, memory requirements per agent linear number agents domain
cardinality magnitude bounds (and variables) constant agent.
3.2.4 Performing Depth-First Search
description BnB-ADOPT far applies ADOPT well. However, BnB-ADOPT uses
depth-rst branch-and-bound search ADOPT uses best-rst search. describe
BnB-ADOPT implements depth-rst search.
Agents BnB-ADOPT send messages similar ADOPT processes
dierently. send messages three dierent types, namely VALUE, COST TERMINATE
messages. start, every agent initializes context X , uses update equations 6, 9, 10, 7, 12

13 initialize bounds takes best value da := arg mindDom(a) {LBX
(d)}. sends
VALUE messages child agents COST message parent agent. repeatedly
waits incoming messages, processes them, possibly takes dierent value sends
VALUE messages child agents COST message parent agent. description
three message types agents process follows:
VALUE messages: agent context X value da sends VALUE messages
child agents desired context X (a, da ), context augmented
value. Leaf agents child agents thus send VALUE messages. VALUE
messages thus propagate contexts pseudo-tree.
agent receives VALUE message, checks whether context identical
desired context VALUE message. not, agent changes context
desired context VALUE message. either case, executes common program
(see below).
COST messages: agent sends COST messages parent agent identity


a, context X bounds LBX
U BX . root agent parent
agent thus send COST messages. COST messages thus propagate bounds
pseudo-tree.
agent receives COST message, checks whether context context
COST message compatible. Two contexts compatible agent takes dierent
values two contexts. are, agent uses update equations 8 13
bounds COST message improve bounds value message. either
case, executes common program (see below).
r
r
TERMINATE messages: termination condition U BX
r LBX r satised,
root agent r sends TERMINATE messages (without parameters) child agents
inform search complete terminates. agent receives
TERMINATE message, sends TERMINATE messages child agents terminates
well. Leaf agents child agents thus send TERMINATE messages.
TERMINATE messages thus propagate pseudo-tree agents terminate.

common program follows:
Context change: agent changed context X , executes following statements:
uses update equations 6, 9, 10, 7, 12 13 initialize bounds takes best

value da := arg mindDom(a) {LBX
(d)}. sends VALUE messages child agents
COST message parent agent.
99

fiYeoh, Felner & Koenig





0



0







b



0

0



5



B

C



0

0



5

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



K


5



u



v



8

0

0

10 14 3

8

X

0

X

X

X

X

X X

X X

X X

X X

X X

X X





0

18



0

Identifiers

10

8
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

0





8

0



8

0



18



8

0



8

0



18

18







8

10

3

X X

X X

0

X
0

8 13 10 3

X

18



X

X

X

X

X X

X X

X X

X X





19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X





10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

3



18

0



18

3



18



18

0



18

3



18

X





10
10 14 3

X
3
8

20

3

X



X

X

0

0

0

0

X X

X X

X X

X X

X X

X X





X

20

X

X

X

X

0

X X

X X

X X

X X

X X

Cycle 6

3
0

0

0

X X 23 6 10 3





3
X

20

X

X

X

X

0

X X

X X

X X

X X

X X

12
0

6

3

X X 23 6 10 3

Cycle 8

12





18



18

12
12

X





3

X



Cycle 7



X

3

Cycle 5

3



X

8





0

18



X

0

Cycle 4

0



X
3

X

0

Cycle 2

0



X

0

Cycle 1

0



X

0

X

20

X

X

X

X

0

X X

X X

X X

X X

X X

12
0

6

3

X X 23 6 10 3

Cycle 9

Figure 7: Trace Updates Lower Bounds
context change: agent change context X , executes following




statements: U BX
LBX (d ) value , context agent augmented
value cannot completed solution whose solution cost smaller solution

cost best solution found far context X (= U BX
) agent thus takes


best value := arg mindDom(a) {LBX (d)}. sends VALUE messages child
agents COST message parent agent.
Assume context X agent change. nite amount time,




U BX
agent takes best value repeats
LBX (d ) value .


procedure. nite amount time, U BX
LBX (d) values d, implies





U BX LBX . agent takes every value U BX
LBX since LBX (d)

remains unchanged U BX monotonically non-increasing agent changes value
dierent value, prevents agent changing value back


U BX
LBX . BnB-ADOPT thus performs depth-rst search. Then, nite amount time,
r
r
r
r
r
r
r
U BX r LBX r bound property U BX
r LBX r together imply U BX r = X r = LBX r
root agent r, DCOP problem solved optimally.
Figures 7 8 show traces updates lower upper bounds, respectively,
example DCOP problem. BnB-ADOPT uses zero heuristic values. initial context every
100

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm





inf



inf







b



inf

inf



inf



B

C



inf

inf



inf

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



inf



K


u



v



inf

inf
inf

10 14 3

8

X

inf

X

X

X

X

X X

X X

X X

X X

X X

X X





10

inf
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 2

18



18



18

inf



18

inf



18



18

inf



18

inf



18

18





inf

10

3

X X

X X

inf

X
inf

8 13 10 3

X

18



X

X

X

X

X X

X X

X X

X X





19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X





10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

18



18

inf



18

inf



18



18

inf



18

inf



18

X





10
10 14 3

X
3
8

inf

inf

X



X

X

inf

inf

inf

inf

X X

X X

X X

X X

X X

X X





X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

Cycle 6

inf
inf

inf

inf

X X 23 6 10 3





inf
X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

12
inf

6

3

X X 23 6 10 3

Cycle 8

12





18



18

12
12

X





inf

X



Cycle 7



X

3

Cycle 5

18



X

8





inf

18



X

inf

Cycle 4

18



X
3

X

inf

Cycle 1

18

X

inf





0

18



inf

Identifiers


X

inf

X

inf

X

X

X

X

inf

X X

X X

X X

X X

X X

12
inf

6

3

X X 23 6 10 3

Cycle 9

Figure 8: Trace Updates Upper Bounds
agent assigns value 0 ancestor agents agent. partition time cycles. Agents
maintain bounds one context given time. Nodes gures crossed
agent maintain bounds. nodes shaded partial solution equal
context agent parent node augmented value. example, agents
a1 , a3 a4 take value 0 Cycle 2, agent a2 takes value 1. context agent a1
{}, context agent a2 {(a1 , 0)} contexts agents a3 a4 {(a1 , 0), (a2 , 0)}.
description trace follows:
Cycle 1: Root agent a1 initializes context X a1 {}. initializes lower bounds
nodes B (= lbaX1a,a1 2 (0)) C (= lbaX1a,a1 2 (1)) 0 since uses zero heuristic values.
a1
updates lower bound node (= LBX
a1 (0)) sum delta cost (= 0)
lower bound node B (= 0) according update equations. updates lower bound
a1
node b (= LBX
a1 (1)) sum delta cost (= 0) lower bound node C (= 0)
a1
according update equations. updates lower bound node (= LBX
a1 )
minimum lower bound node (= 0) lower bound node b (= 0) according
update equations. initializes upper bounds nodes B C innity. updates
upper bounds nodes a, b innity according update equations. takes

101

fiYeoh, Felner & Koenig

best value. take either value 0 value 1 since lower bounds nodes
b 0. takes value 0 sends VALUE message child agent a2 .
Agent a2 initializes context X a2 {(a1 , 0)}. initializes lower bounds nodes D, E,
F G 0. updates lower bounds nodes c, B 5, 8 5, respectively.
initializes upper bounds nodes D, E, F G innity. updates upper bounds
nodes c, B innity. bounds node B agent a2 maintains shown
gures. takes best value 0, sends VALUE messages child agents a3
a4 sends COST message parent agent a1 .
Leaf agent a3 initializes context X a3 {(a1 , 0), (a2 , 0)}. updates lower bounds
nodes g h delta costs 10 14, respectively, since leaf agents child
agents. updates lower bound node 10. updates upper bounds nodes g
h delta costs 10 14, respectively, since leaf agents child agents.
updates upper bound node 10. bounds node leaf agent a3 maintains
shown gures. takes best value 0 sends COST message
parent agent a2 .
Leaf agent a4 initializes context X a4 {(a1 , 0), (a2 , 0)}. updates lower bounds
nodes j delta costs 3 8, respectively. updates lower bound node E
3. updates upper bounds nodes j delta costs 3 8, respectively.
updates upper bound node E 3. bounds node E leaf agent a4 maintains
shown gures. takes best value 0 sends COST message
parent agent a2 .
summary, following messages sent Cycle 1:
message (VALUE, {(a1 , 0)}) agent a1 agent a2 ;
message (VALUE, {(a1 , 0), (a2 , 0)}) agent a2 agent a3 ;
message (VALUE, {(a1 , 0), (a2 , 0)}) agent a2 agent a4 ;
message (COST, a2 , {(a1 , 0)}, 5, ) agent a2 agent a1 ;
message (COST, a3 , {(a1 , 0), (a2 , 0)}, 10, 10) agent a3 agent a2 ;
message (COST, a4 , {(a1 , 0), (a2 , 0)}, 3, 3) agent a4 agent a2 .
Cycle 2: Root agent a1 receives COST message sent child agent a2 Cycle 1. Since
context agent a1 (= {}) compatible context message (= {(a1 , 0)}),
improves bounds. updates bounds node B bounds message (= 5
innity, respectively). updates bounds nodes a, b A. change value
a1
a1
) = 5 value da1 = 0) still smaller
since lower bound node (= LBX
a1 (d
a1
upper bound node (= U BX a1 = ). sends VALUE message child agent
a2 .
Agent a2 receives VALUE message sent parent agent a1 Cycle 1. context
(= {(a1 , 0)}) remains unchanged since desired context message
(= {(a1 , 0)}). Agent a2 also receives COST messages sent child agents a3 a4
Cycle 1. Since context agent a2 (= {(a1 , 0)}) compatible contexts
messages (= {(a1 , 0), (a2 , 0)}), improves bounds. updates bounds node
bounds rst message (= 10 10, respectively) bounds node E
bounds second message (= 3 3, respectively). updates bounds nodes c,
a2
a2
) = 18 value
B. changes value since lower bound node c (= LBX
a2 (d
a2
a2
= 0) longer smaller upper bound node B (= U BX a2 = 18). takes
best value 1, sends VALUE messages child agents a3 a4 sends COST message
parent agent a1 .

102

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Leaf agents a3 a4 receive VALUE messages sent parent agent a2 Cycle 1.
contexts (= {(a1 , 0), (a2 , 0)}) remain unchanged since desired
context message (= {(a1 , 0), (a2 , 0)}). send COST messages
parent agent a2 .
summary, messages sent Cycle 2 identical ones sent Cycle 1,
except messages sent agent a2 , follows:
message (VALUE, {(a1 , 0), (a2 , 1)}) agent a2 agent a3 ;
message (VALUE, {(a1 , 0), (a2 , 1)}) agent a2 agent a4 ;
message (COST, a2 , {(a1 , 0)}, 8, 18) agent a2 agent a1 .
VALUE messages dierent agent a2 changed value 0 1. COST
message dierent agent a2 changed bounds.
Cycles 3-9: messages sent Cycle 3 identical ones sent Cycle 2,
except messages sent agents a3 a4 , follows:
message (COST, a3 , {(a1 , 0), (a2 , 1)}, 8, 8) agent a3 agent a2 ;
message (COST, a4 , {(a1 , 0), (a2 , 1)}, 3, 3) agent a4 agent a2 .
COST messages dierent agents a3 a4 changed contexts.
termination condition holds nite amount time upper bound node
a1
a1
(= U BX
a1 = 12) larger lower bound node (= LBX a1 = 12). Root agent a1
sends TERMINATE messages child agents, TERMINATE messages propagate
pseudo-tree agents terminate. BnB-ADOPT terminates nine cycles
minimal solution cost 12.
3.2.5 Performing Branch-and-Bound
rene description BnB-ADOPT explaining agents implement branchand-bound search make BnB-ADOPT faster. Every agent BnB-ADOPT also maintains

variable threshold HX
, initializes innity. threshold root agent always
remains innity. Every agent uses threshold pruning, meaning change
value earlier previously.
First change: agent change context X , previously executed following




statements: U BX
LBX (d ) value , agent took best value.
sent VALUE messages child agents COST message parent agent. Now,





HX
LBX (d ), agent also takes best value. Thus, min{T HX , U BX }


LBX
(d
),


agent
takes


best
value

thus
potentially
changes

value,




earlier previously. min{T HX
,
U
B
}


pruning
quantity.

Xa
Second change: agent context X value da sends VALUE messages
child agents, previously contained desired context X (a, da ).




VALUE messages also contain desired threshold min{T HX
, U BX } X (d )

a,c
c C(a)\c lbX (d ) child agent c. agent c receives VALUE message, sets
threshold desired threshold proceeds described earlier. desired



reaches
threshold set lower bound LBX
(d ) agent value
c
pruning quantity (and agent thus potentially changes value) lower bound LBX
c
agent c reaches desired threshold. property veried follows:

103

fiYeoh, Felner & Koenig



c




LBX
c min{T HX , U BX } X (d )




lba,c
X (d )

(14)

c C(a)\c








lba,c
X (d ) min{T HX , U BX } X (d )
a,c





min{T HX
, U BX } X (d ) lb (d )
X




lba,c
X (d )

(15)

c C(a)\c






lba,c
X (d )

(16)

c C(a)\c



a,c





min{T HX
, U BX } X (d ) + lb (d ) +
X







min{T HX
, U BX } X (d ) +




lba,c
X (d )

(17)

c C(a)\c



lba,c
X (d )

(18)

c C(a)




min{T HX
, U BX } LBX (d )

(19)

3.2.6 Enhancements
continue rene description BnB-ADOPT explaining number additional enhancements, introduced ADOPT.
Reduced contexts: agents use reduced contexts, subsets contexts
described previously. reduced context X1a agent contains values ancestor
agents p SCP (a), context X2a described previously contains values



ancestor agents p P (a). agents use reduced contexts since X
= X X (d) =
1
2
1

X2a (d) values d. Agents use reduced contexts need change
contexts thus initialize bounds less often receive VALUE messages since
contexts often identical desired contexts VALUE messages.
example DCOP problem, reduced context agent a4 contains values
agent a2 rather values agents a1 a2 . Therefore, following pairs nodes
search tree actually node: nodes q, nodes j r, nodes u,
nodes n v.
VALUE COST messages: agent sends VALUE messages child agents,
previously contained desired context desired threshold. desired context
context agent augmented value. agent receives VALUE message,
previously checked whether context identical desired context VALUE
message. not, agent changed context desired context
VALUE message. Agents update contexts dierently reduce size
VALUE messages. agent sends VALUE messages child pseudo-child agents
identity, value desired threshold, innity pseudo-child agents.
agent receives VALUE message, sets threshold desired threshold message
parent agent. also checks whether value ancestor agent VALUE
message recent value ancestor agent context. is,
agent changes value ancestor agent context value ancestor agent
VALUE message. However, context agent contain values
parent pseudo-parent agents also values ancestor agents parent
pseudo-parent agents one (or more) descendant agents, ancestor agents
constrained agent cannot send VALUE messages agent. However,
send VALUE messages pseudo-child agents, least one descendant agent
agent, information propagates pseudo-tree COST messages
reaches agent. agent receives COST message, checks whether
104

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

value ancestor agent context COST message recent
value ancestor agent context. is, agent changes value
ancestor agent context value ancestor agent context COST
message. example DCOP problem simple allow us illustrate propagation
information pseudo-tree. However, imagine new agent a5 child agent
agent a4 constrained agents a1 a4 . context agent a4 contains
value agent a1 agent a1 cannot send VALUE messages agent a4 . However, agent
a1 sends VALUE messages agent a5 . Agent a5 changes value agent a1 context
sends COST messages context agent a4 , changes value agent
a1 context well.
agents need determine whether value agent VALUE messages
contexts COST messages recent value agent contexts. Every
agent therefore also maintains counter IDa increments whenever changes
value. Therefore, larger ID indicates recent value. values agents contexts
labeled IDs, VALUE messages contain identity sending agent,
value, ID desired threshold.
Bounds: Whenever agent changes context X , previously initialized bounds
took best value. (reduced) context child agent agent strict
subset (reduced) context agent since parent pseudo-parent agents
agent might (parent or) pseudo-parent agents child agent descendant
agents. context child agent c contain values agents whose values
changed context agent a, agent initialize lower bounds lba,c
X (d)
upper bounds uba,c
(d)

agent
c


values



takes


best
value.
Agents
Xa
use optimization need initialize bounds less often way.
example DCOP problem, agent a2 changes context {(a1 , 0)} {(a1 , 1)} (where
IDs omitted simplicity), initialize lower bounds lbaX2a,a2 4 (d) upper
bounds ubaX2a,a2 4 (d) child agent a4 values since context agent a4
contain value agent a1 .
Additionally, agent changes context due COST message child agent c
new context X compatible context COST message, agent
a,c
set lower bound lba,c
X (d) upper bound ubX (d) agent c value agent
COST message bounds COST message takes best value.
Agents use optimization bounds COST message informed
initialized bounds. example DCOP problem simple allow us illustrate
optimization. However, imagine new agent a5 child agent agent a4
constrained agents a1 a4 . Assume context agent a4 {(a1 , 0), (a2 , 0)}
(where IDs omitted simplicity) receives COST message agent
a5 context {(a1 , 1), (a4 , 0)}. Agent a4 changes context {(a1 , 1), (a2 , 0)}, sets
4 ,a5
4 ,a5
lower bound lba{(a
(0) upper bound uba{(a
(0) bounds
1 ,1),(a2 ,0)}
1 ,1),(a2 ,0)}
COST message initializes bounds takes best value.

3.2.7 Pseudocode
Figure 9 shows BnB-ADOPT pseudocode every agent. pseudocode index
variables context since context implicitly given variable X . uses
predicate Compatible(X, X ) = (a,d,ID)X,(a ,d ,ID )X (a =
= ) determines two
contexts X X compatible, is, agent takes two dierent values two contexts
[Lines 35, 44, 46, 48 51]. pseudocode also uses procedure PriorityMerge(X, X )
executes X := {(a , , ID ) X | (a,d,ID)X (a = )} {(a , , ID ) X | (a,d,ID)X (a =

105

fiYeoh, Felner & Koenig

procedure Start()
[01]
X := {(p, ValInit(p), 0) | p SCP (a)};
[02]
IDa := 0;
[03]
forall c C(a), Dom(a)
[04]
InitChild(c, d);
[05]
InitSelf ();
[06]
Backtrack();
[07]
loop forever
[08]
(message queue empty)
[09]
while(message queue empty)
[10]
pop msg message queue;
[11]
Received(msg);
[12]
Backtrack();
procedure InitChild(c, d)
[13]
lba,c (d) := ha,c (d);
[14]
uba,c (d) := ;
procedure InitSelf ()

[15]
da := arg mindDom(a) { (d) + cC(a) lba,c (d)};


[16]
ID := ID + 1;
[17]
H := ;
procedure Backtrack()
[18]
forall Dom(a)
[19]
LB (d) := (d) + cC(a) lba,c (d);

[20]
UB (d) := (d) + cC(a) uba,c (d);

[21]
LB := mindDom(a) {LB (d)};
[22]
UB := mindDom(a) {UB (d)};
[23]
(LB (da ) min{T H , UB })
[24]
da := arg mindDom(a) {LB (d)} (choose previous da possible);
[25]
new da chosen
[26]
IDa := IDa + 1;
[27]
((a root UB LB ) termination message received)
[28]
Send(TERMINATE) c C(a);
[29]
terminate execution;


[30]
Send(VALUE, a, da , IDa , min{T H , UB } (da ) c C(a)\c lba,c (da )) c C(a);


[31]
Send(VALUE, a, , ID , ) c CD(a) \ C(a);
[32]
Send(COST, a, X , LB , UB ) pa(a) root;
procedure Received(VALUE, p, dp , IDp , H p )
[33]
X := X ;
[34]
PriorityMerge((p, dp , ID p ), X );
[35]
(!Compatible(X , X ))
[36]
forall c C(a), Dom(a)
[37]
(p SCP (c))
[38]
InitChild(c, d);
[39]
InitSelf ();
[40]
(p = pa(a))
[41]
H := H p ;
procedure Received(COST, c, X c , LB c , UB c )
[42]
X := X ;
[43]
PriorityMerge(X c , X );
[44]
(!Compatible(X , X ))
[45]
forall c C(a), Dom(a)
[46]
(!Compatible({(p, dp , ID p ) X | p SCP (c)},X ))
[47]
InitChild(c,d);
[48]
(Compatible(X c , X ))
[49]
lba,c (d) := max{lba,c (d), LB c } unique (a , d, ID) X c = a;
[50]
uba,c (d) := min{uba,c (d), UB c } unique (a , d, ID) X c = a;
[51]
(!Compatible(X , X ))
[52]
InitSelf ();
procedure Received(TERMINATE)
[53]
record termination message received;

Figure 9: Pseudocode BnB-ADOPT
ID ID )} {(a, d, ID) X | (a ,d ,ID )X (a = ID > ID )} thus replaces values

106

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

agents context X recent values, available, agents context X [Lines
34 43].
code identical every agent except variable self variable points
agent itself. start, BnB-ADOPT calls Start() every agent. agent receives
VALUE message ancestor agent, Received handler VALUE messages
called p ancestor agent, dp value ancestor agent, IDp
ID ancestor agent H p desired threshold agent ancestor agent
parent agent (and innity otherwise) [Line 11]. agent receives COST message
child agent, Received handler COST messages called c child
c
agent, X c context child agent, LB c lower bound LBX
c child agent
c
c
U B upper bound U BX c child agent [Line 11]. Finally, agent receives
TERMINATE message parent agent, Received handler TERMINATE
messages called without arguments [Line 11].
BnB-ADOPT uses message passing communication framework ADOPT
memory requirements. uses similar VALUE, COST TERMINATE messages,
similar strategy update context agent based VALUE messages ancestor
agents COST messages child agents, semantics bounds
update equations update bounds. BnB-ADOPT ADOPT use thresholds BnBADOPT uses thresholds pruning ADOPT uses reconstruct partial solutions
purged memory. Thus, BnB-ADOPT uses dierent threshold initialization [Line
17], dierent desired threshold calculation [Line 30] dierent termination condition [Line 27].
BnB-ADOPT also diers ADOPT maintains IDs agents use indicate
recency values labels values agents contexts IDs.
3.2.8 Trace
Figures 10 11 show traces updates lower upper bounds, respectively,
example DCOP problem, Table 2 shows trace update variables. BnB-ADOPT
uses heuristic values haX1a,a1 2 (0) := 3, haX1a,a1 2 (1) := 6, haX2a,a2 3 (0) := 2, haX2a,a2 3 (1) := 2, haX2a,a2 4 (0) := 2
haX2a,a2 4 (1) := 2 contexts X a1 X a2 . heuristic values chosen hand. Every
agent assigns value ancestor agents initial context 0. partition time
cycles Figures 7 8 continue use conventions made context gures.
Cycle 1: Root agent a1 initializes context X a1 {} [Line 1]. initializes lower bounds
nodes B (= lbaX1a,a1 2 (0)) C (= lbaX1a,a1 2 (1)) heuristic values 3 6, respectively
a1
[Line 13]. updates lower bound node (= LBX
a1 (0)) sum delta cost
(= 0) lower bound node B (= 3) according update equations [Line 19].
a1
updates lower bound node b (= LBX
a1 (1)) sum delta cost (= 0)
lower bound node C (= 6) according update equations [Line 19]. updates
a1
lower bound node (= LBX
a1 ) minimum lower bound node (= 3)
lower bound node b (= 6) according update equations [Line 21]. initializes
upper bounds nodes B C innity [Line 14]. updates upper bounds nodes a,
b innity according update equations [Lines 20 22]. takes best
value 0 since lower bound node (= 3) smaller lower bound node b (= 6)
[Line 15], initializes ID IDa1 1 [Lines 2 16], initializes threshold H a1 innity
[Line 17] sends VALUE messages child agent a2 pseudo-child agent a3 [Lines 30
31].
Agent a2 initializes context X a2 {(a1 , 0, 0)} [Line 1]. initializes lower bounds
nodes D, E, F G heuristic value 2 [Line 13]. updates lower bounds nodes
c, B 9, 12 9, respectively [Lines 19 21]. initializes upper bounds
nodes D, E, F G innity [Line 14]. updates upper bounds nodes c, B
innity [Lines 20 22]. bounds node B agent a2 maintains shown
107

fiYeoh, Felner & Koenig

Cycle
X a1
da1
ID a1
H a1
LB a1 (0)
LB a1 (1)
LB a1
U B a1 (0)
U B a1 (1)
U B a1
lba1 ,a2 (0)
lba1 ,a2 (1)
uba1 ,a2 (0)
uba1 ,a2 (1)
X a2
da2
ID a2
H a2
LB a2 (0)
LB a2 (1)
LB a2
U B a2 (0)
U B a2 (1)
U B a2
lba2 ,a3 (0)
lba2 ,a3 (1)
uba2 ,a3 (0)
uba2 ,a3 (1)
lba2 ,a4 (0)
lba2 ,a4 (1)
uba2 ,a4 (0)
uba2 ,a4 (1)
X a3
da3
ID a3
H a3
LB a3 (0)
LB a3 (1)
LB a3
U B a3 (0)
U B a3 (1)
U B a3
X a4
da4
ID a4
H a4
LB a4 (0)
LB a4 (1)
LB a4
U B a4 (0)
U B a4 (1)
U B a4

1

2

3

4

5

6

7

8

9

0
1

3
6
3



3
6


(a1 , 0, 0)
0
1

9
12
9



2
2


2
2


(a1 , 0, 0)
(a2 , 0, 0)
0
1

10
14
10
10
14
10
(a2 , 0, 0)
0
1

3
8
3
3
8
3

0
1

9
6
6



9
6


(a1 , 0, 1)
1
2

18
12
12
18

18
10
2
10

3
2
3

(a1 , 0, 1)
(a2 , 0, 1)
0
1

10
14
10
10
14
10
(a2 , 0, 1)
0
1

3
8
3
3
8
3

0
1

12
6
6
18

18
12
6
18

(a1 , 0, 1)
1
2

18
12
12
18

18
10
2
10

3
2
3

(a1 , 0, 1)
(a2 , 1, 2)
0
2
8
8
13
8
8
13
8
(a2 , 1, 2)
1
2
8
10
3
3
10
3
3

0
1

12
6
6
18

18
12
6
18

(a1 , 0, 1)
0
3
18
18
19
18
18
19
18
10
8
10
8
3
3
3
3
(a1 , 0, 1)
(a2 , 1, 2)
0
2
8
8
13
8
8
13
8
(a2 , 1, 2)
1
2
8
10
3
3
10
3
3

1
2

18
6
6
18

18
18
6
18

(a1 , 0, 1)
0
3
18
18
19
18
18
19
18
10
8
10
8
3
3
3
3
(a1 , 0, 1)
(a2 , 0, 3)
0
3
10
10
14
10
10
14
10
(a2 , 0, 3)
0
3
3
3
8
3
3
8
3

1
2

18
6
6
18

18
18
6
18

(a1 , 1, 2)
1
4
18
25
8
8



2
2


3
3
3
3
(a1 , 1, 2)
(a2 , 0, 3)
1
4
10
25
7
7
25
7
7
(a2 , 0, 3)
0
3
3
3
8
3
3
8
3

1
2

18
8
8
18

18
18
8
18

(a1 , 1, 2)
1
4
18
30
8
8
30

30
7
2
7

3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
12
23
6
6
23
6
6
(a2 , 1, 4)
1
4
13
10
3
3
10
3
3

1
2

18
8
8
18
30
18
18
8
18
30
(a1 , 1, 2)
1
4
18
30
12
12
30
12
12
7
6
7
6
3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
12
23
6
6
23
6
6
(a2 , 1, 4)
1
4
13
10
3
3
10
3
3

1
2

18
12
12
18
12
12
18
12
18
12
(a1 , 1, 2)
1
4
18
30
12
12
30
12
12
7
6
7
6
3
3
3
3
(a1 , 1, 2)
(a2 , 1, 4)
1
5
6
23
6
6
23
6
6
(a2 , 1, 4)
1
4
3
10
3
3
10
3
3

Table 2: Trace Update Variables BnB-ADOPT

108

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm





3



6







b



3

6



9



B

C



3

6



9

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



K


9



u



v



12

2

2

10 14 3

8

X

2

X

X

X

X

X X

X X

X X

X X

X X

X X





6

18



2

Identifiers

10

12
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

6





12

6



12

6



18



12

6



12

6



18

18







12

10

3

X X

X X

2

X
2

8 13 10 3

X

18



X

X

X

X

X X

X X

X X

X X





19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X





10

19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

8



18

6



18

8



18



18

6



18

8



18

X





X

X

X

X

X X

X X

X X

25
X

2

X X 25 7

8
3

3

8

X



2

3

X X

X X





X

30

X

X

X

X

7

X X

X X

X X

X X

X X

Cycle 6

8
3

2

3

X X 23 6 10 3



8
X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 8

12





18



18

12
12

X







8

X



Cycle 7



X

3

Cycle 5

8



X

8





6

18



X

6

Cycle 4

6



X
3

X

2

Cycle 2

6



X

2

Cycle 1

6



X

6

X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 9

Figure 10: Trace Update Lower Bounds BnB-ADOPT
gure. takes best value 0 [Line 15], initializes ID 1 [Lines 2 16],
initializes threshold innity [Line 17] sends VALUE messages child agents a3
a4 COST message parent agent a1 [Lines 30-32].
Leaf agent a3 initializes context X a3 {(a1 , 0, 0), (a2 , 0, 0)} [Line 1]. updates lower
bounds nodes g h delta costs 10 14, respectively, since leaf agents
child agents [Line 19]. updates lower bound node 10 [Line 21]. updates
upper bounds nodes g h delta costs 10 14, respectively, since leaf agents
child agents [Line 20]. updates upper bound node 10 [Line 22].
bounds node leaf agent a3 maintains shown gure. takes
best value 0 [Line 15], initializes ID 1 [Lines 2 16], initializes threshold innity
[Line 17] sends COST message parent agent a2 [Line 32].
Leaf agent a4 initializes (reduced) context X a4 {(a2 , 0, 0)} [Line 1]. updates lower
bounds nodes j delta costs 3 8, respectively [Line 19]. updates
lower bound node E 3 [Line 21]. updates upper bounds nodes j
delta costs 3 8, respectively [Line 20]. updates upper bound node E 3 [Line
22]. bounds node E leaf agent a4 maintains shown gure. takes

109

fiYeoh, Felner & Koenig





inf



inf







b



inf

inf



inf



B

C



inf

inf



inf

c











g

E
h



e

F
j

k

G
l



f

H
n




p

q

J
r



inf



K


u



v



inf

inf
inf

10 14 3

8

X

inf

X

X

X

X

X X

X X

X X

X X

X X

X X

10





inf
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 2

18



18



18

inf



18

inf



18



18

inf



18

inf



18

18





inf

10

3

X X

X X

inf

X
inf

8 13 10 3

X

18



X

X

X

X

X X

X X

X X

X X





19

10

3

X X

X X

8

8 13 10 3

Cycle 3

X
X

X

X

X X

X X

X X

X X

10





19
3

10 14 3

8

X

X

X

X

X X

X X

X X

X X

X X

X X

18



18

inf



18

inf



18



18

inf



18

inf



18

X





X

X

X

X

X X

X X

X X

inf
X

inf

X X 25 7

inf
3

3

8

X



inf

3

X X

X X





X

30

X

X

X

X

7

X X

X X

X X

X X

X X

Cycle 6

inf
3

inf

3

X X 23 6 10 3

30

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 8

12





18



18

12
12

X





30
X

X





30

X



Cycle 7



X

3

Cycle 5

18



X

8





inf

18



X

inf

Cycle 4

18



X
3

X

inf

Cycle 1

18

X

inf





inf

18



inf

Identifiers


X

inf

X

30

X

X

X

X

7

X X

X X

X X

X X

X X

12
3

6

3

X X 23 6 10 3

Cycle 9

Figure 11: Trace Update Upper Bounds BnB-ADOPT
best value 0 [Line 15], initializes ID 1 [Lines 2 16], initializes threshold
innity [Line 17] sends COST message parent agent a2 [Line 32].
summary, following messages sent Cycle 1:
message (VALUE, a1 , 0, 1, ) agent a1 agent a2 ;
message (VALUE, a1 , 0, 1, ) agent a1 agent a3 ;
message (VALUE, a2 , 0, 1, ) agent a2 agent a3 ;
message (VALUE, a2 , 0, 1, ) agent a2 agent a4 ;
message (COST, a2 , {(a1 , 0, 0)}, 9, ) agent a2 agent a1 ;
message (COST, a3 , {(a1 , 0, 0), (a2 , 0, 0)}, 10, 10) agent a3 agent a2 ;
message (COST, a4 , {(a2 , 0, 0)}, 3, 3) agent a4 agent a2 .
Cycle 2: Root agent a1 receives COST message sent child agent a2 Cycle 1. Since
context agent a1 (= {}) compatible context message (= {(a1 , 0, 0)}),
improves bounds. updates bounds node B bounds message (= 9
innity, respectively) [Lines 48-50]. updates bounds nodes a, b [Lines 18-22].
110

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

a1
a1
change value since lower bound node (= LBX
) = 9 value
a1 (d
a1
a1
a1
= 0) still smaller pruning quantity (= min{T HX a1 , U BX a1 } = min(, ) =
). sends VALUE messages child agent a2 pseudo-child agent a3 [Lines 30-31].

Agent a2 receives VALUE message sent parent agent a1 Cycle 1. updates
context {(a1 , 0, 0)} {(a1 , 0, 1)} since ID agent a1 context (= 0) smaller
ID message (= 1) [Line 34]. threshold (= ) remains unchanged since
desired threshold (= ) message. Agent a2 also receives COST
messages sent child agents a3 a4 Cycle 1. Since context (= {(a1 , 0, 1)}) compatible contexts messages (= {(a1 , 0, 0), (a2 , 0, 0)} {(a2 , 0, 0)}, respectively),
improves bounds. updates bounds node bounds rst message
(= 10 10, respectively) bounds node E bounds second message (= 3
3, respectively) [Lines 48-50]. updates bounds nodes c, B [Lines 18-22].
a2
a2
) = 18 value da2 = 0)
changes value since lower bound node c (= LBX
a2 (d
a2
a2
longer smaller pruning quantity (= min{T HX a2 , U BX
a2 } = min(, 18) = 18).
takes best value 1 [Line 24], increments ID 2 [Lines 25-26], sends VALUE messages
child agents a3 a4 [Lines 30-31] sends COST message parent agent a1
[Line 32].
Leaf agent a3 receives VALUE messages sent parent agent a2 pseudo-parent
agent a1 Cycle 1. updates context {(a1 , 0, 0), (a2 , 0, 0)} {(a1 , 0, 1), (a2 , 0, 1)}
since IDs agents a1 a2 context (= 0 0, respectively) smaller
IDs messages (= 1 1, respectively) [Line 34]. threshold (= ) remains
unchanged since desired threshold (= ) message. bounds
reinitialized since context compatible previous context [Line 35]. sends
COST message parent agent a2 [Line 32].
Leaf agent a4 receives VALUE message sent parent agent a2 Cycle 1. updates
contexts {(a2 , 0, 0)} {(a2 , 0, 1)} since ID agent a2 context (= 0) smaller
ID message (= 1) [Line 34]. threshold (= ) remains unchanged since
desired threshold (= ) message. bounds reinitialized since
context compatible previous context [Line 35]. sends COST message
parent agent a2 [Line 32].
summary, messages sent Cycle 2 identical ones sent Cycle 1,
except messages sent agents a2 , a3 a4 , follows:
message (VALUE, a2 , 1, 2, 8) agent a2 agent a3 ;
message (VALUE, a2 , 1, 2, 8) agent a2 agent a4 ;
message (COST, a2 , {(a1 , 0, 1)}, 12, 18) agent a2 agent a1 .
message (COST, a3 , {(a1 , 0, 1), (a2 , 0, 1)}, 10, 10) agent a3 agent a2 ;
message (COST, a4 , {(a2 , 0, 1)}, 3, 3) agent a4 agent a2 .
VALUE messages dierent agent a2 changed value 0 1. COST
messages dierent agent a2 changed bounds context agents a3
a4 changed contexts.
Cycles 3-9: messages sent Cycle 3 identical ones sent Cycle 2,
except messages sent agents a3 a4 , follows:
message (COST, a3 , {(a1 , 0, 1), (a2 , 1, 2)}, 8, 8) agent a3 agent a2 ;
message (COST, a4 , {(a2 , 1, 2)}, 3, 3) agent a4 agent a2 .

111

fiYeoh, Felner & Koenig

COST messages dierent agents a3 a4 changed contexts.
termination conditions holds nite amount time upper bound node
a1
a1
(= U BX
a1 = 12) larger lower bound node (= LBX a1 = 12) [Line 27]. Root
agent a1 sends TERMINATE messages child agents [Line 28], TERMINATE
messages propagate pseudo-tree [Line 28] agents terminate. BnB-ADOPT
terminates nine cycles minimal solution cost 12.

4. Bounded-Error Approximations
section, present three approximation mechanisms allow BnB-ADOPT trade
solution cost smaller runtime. bound error solution cost user-dened
error bound. First, modify Absolute Error Mechanism ADOPT (Modi et al., 2005)
work BnB-ADOPT. approximation mechanism allows users specify absolute error
bound solution cost (for example, solution cost 10 larger
minimal solution cost). However, often much desirable specify relative error bound
solution cost (for example, solution cost 10 percent larger
minimal solution cost or, equivalently, 1.1 times larger minimal solution cost). cannot
done Absolute Error Mechanism without knowing minimal solution cost priori.
Thus, introduce two approximation mechanisms allow users specify relative error bound
solution cost, namely Relative Error Mechanism Weighted Heuristics Mechanism.
approximation mechanisms let root agent r (and root agent) maintain
limit limr . root agent uses limit way termination condition
r
r
approximation mechanisms updates dierently. termination condition U BX
r LBX r
r
r
Line 27 pseudocode BnB-ADOPT replaced U BX r lim . root agent updates
limit Lines 26 27 pseudocode, outside preceding statement.
4.1 Absolute Error Mechanism
Absolute Error Mechanism ADOPT requires user-dened absolute error bound 0 b <
species solution cost b larger minimal solution cost.
approximation mechanism easily modied BnB-ADOPT setting limit follows:
limr

:=

r
b + LBX
r

(20)

BnB-ADOPTAEM resulting variant BnB-ADOPT Absolute Error Mechanism.
BnB-ADOPTAEM terminates upper bound root node (which equal solution
cost solution smallest solution cost found far) larger limit (which
equal absolute error bound b plus lower bound root node, lower
bound minimal solution cost). BnB-ADOPTAEM terminates solution cost
equal upper bound root node although minimal solution cost could small
lower bound root node. thus terminates solution cost b larger
minimal solution cost. Figure 12 shows trace BnB-ADOPTAEM absolute error
bound b = 24 example DCOP problem. BnB-ADOPTAEM terminates three cycles
suboptimal solution cost 18, six cycles faster BnB-ADOPT.
4.2 Relative Error Mechanism
often much desirable specify relative error bound solution cost rather
absolute error bound. Fortunately, Absolute Error Mechanism BnB-ADOPT easily
changed Relative Error Mechanism setting limit follows. Relative Error
112

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm



3





lim 1 = 27

UB 1 = infinity



lim 1 = 30

UB 1 = infinity

6



6





3

6



9

6



12



3

6



9

6



12

9







2

12
2

10 14 3

8

X

X

18



2

2

X

X

X

X

X X

X X

X X

X X

X X

X X





10

12
3

10 14 3

8

X

X

2

2

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1





6
6

18



lim 1 = 30

UB 1 = 18

12

10

3

X X

X X

2

X
2

8 13 10 3

Cycle 2

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 12: Trace Update Lower Bounds BnB-ADOPTAEM b = 24


3





lim 1 = 9

UB 1 = infinity



lim 1 = 18

UB 1 = infinity

6



6





3

6



9

6



12



3

6



9

6



12

9







2

12
2

10 14 3

8

X

X

18



2

2

X

X

X

X

X X

X X

X X

X X

X X

X X





10

12
3

10 14 3

8

X

X

2

2

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1

Cycle 2





6
6

18



lim 1 = 18

UB 1 = 18

12

10

3

X X

X X

2

X
2

8 13 10 3

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 13: Trace Update Lower Bounds BnB-ADOPTREM p = 3
Mechanism requires user-dened relative error bound 1 p < species solution
cost p times larger minimal solution cost:
limr

r
:= p LBX
r

(21)

BnB-ADOPTREM resulting variant BnB-ADOPT Relative Error Mechanism.
BnB-ADOPTREM terminates upper bound root node (which equal solution
cost solution smallest solution cost found far) larger limit (which
equal relative error bound p times lower bound root node, lower
bound minimal solution cost). BnB-ADOPTREM terminates solution cost
equal upper bound root node although minimal solution cost could small
lower bound root node. thus terminates solution cost p times
larger minimal solution cost. Figure 13 shows trace BnB-ADOPTREM relative
error bound p = 3 example DCOP problem. BnB-ADOPTREM terminates three cycles
suboptimal solution cost 18, six cycles faster BnB-ADOPT.
4.3 Weighted Heuristics Mechanism
second way implementing relative error bound BnB-ADOPT since BnB-ADOPT
uses admissible heuristic values. common practice context A* trade solution
cost smaller runtime using weighted heuristic values (Pohl, 1973), derived
admissible heuristic values multiplying user-dened weight 1 w < .
resulting heuristic values inadmissible. A* longer guaranteed nd cost-minimal
solutions guaranteed terminate solution cost w times larger
minimal solution cost (Pohl, 1970). approximation mechanism easily modied
BnB-ADOPT setting limit follows:
limr

:=

113

r
LBX
r

(22)

fiYeoh, Felner & Koenig



9





lim 1 = 9

UB 1 = infinity



lim 1 = 17

lim 1 = 18

17 UBa1 = infinity



18 UBa1 = 18





9

18



17

18



20



9

18



17

18



20

17







6

20
6

10 14 3

8

X

X

21



6

6

X

X

X

X

X X

X X

X X

X X

X X

X X





10

20
6

10 14 3

8

X

X

6

X

X

X

X

X X

X X

X X

X X

X X

X X

Cycle 1

Cycle 2





18

21



6

18

20

10

6

X X

X X

6

X
6

8 13 10 3

X

X

X

X

X

X X

X X

X X

X X

Cycle 3

Figure 14: Trace Update Lower Bounds BnB-ADOPTW HM w = 3
initializing lower bounds lba,c
X (d) follows:
lba,c
X (d)

:= w ha,c
X (d)

(23)

agents a, values d, child agents c contexts X . BnB-ADOPTW HM
resulting variant BnB-ADOPT Weighted Heuristics Mechanism. BnB-ADOPTW HM
terminates upper bound root node (which equal solution cost solution
smallest solution cost found far) larger limit (which equal lower
bound root node, lower bound w times minimal solution cost). BnBADOPTW HM terminates solution cost equal upper bound root node
although minimal solution cost could small lower bound root node divided
w. thus terminates solution cost w times larger minimal
solution cost. Figure 14 shows trace BnB-ADOPTW HM w = 3 example DCOP
problem. BnB-ADOPTW HM terminates three cycles suboptimal solution cost 18,
six cycles faster BnB-ADOPT.

5. Correctness Completeness
section, prove correctness completeness BnB-ADOPT suboptimal
variants. denitions, lemmata, theorems corollaries hold BnB-ADOPT suboptimal variants except mentioned otherwise. Therefore, agent uses following update
equation values d, child agents c contexts X initialize bounds lba,c
X (d):
a,c
lba,c
X (d) := w hX (d)

(24)

weight w oating point number satises 1 w < heuristic values
ha,c
X (d) oating point numbers satisfy
c
0 ha,c
X (d) X (a,d)

(25)

Messages sent end cycle received beginning cycle. largest
duration time message sent time processed, largest duration
cycle.
Lemma 1. two contexts X X arbitrary agent agree values ancestor


= X
agents p SCP (a) agent a, X
.
Proof. denition, X X (reduced) context contains values ancestor agents

sum constraint costs constraints
p SCP (a) agent a. gamma cost X
114

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

involve agent one descendant agents minimized possible values agent
descendant agents, assumption ancestor agents agent take values

thus depends values ancestor agents (including
context X. gamma cost X
parent agent) agent parent pseudo-parent agents agent one (or more)
descendant agents, is, values ancestor agents p SCP (a) agent a. Therefore,




= X
X
. Similarly, X = X .
Definition 1. Contexts correct IDs values agents contexts equal
IDs agents, implies values agents contexts equal
values agents.
Lemma 2. context X arbitrary agent change period time,


lower bounds lba,c
X (d), LBX (d) LBX monotonically non-decreasing upper
a,c


bounds ubX (d), U BX (d) U BX monotonically non-increasing period time
values Dom(a) child agents c C(a).

Proof. Since context X change, delta values X
(d) constant bounds
(once initialized) updated according update equations 8 13. Thus, lower bounds
monotonically non-decreasing upper bounds monotonically non-increasing.

Lemma 3. value arbitrary ancestor agent p SCP (a) arbitrary agent
change current time future time + |A| ( + ) + ,
value agent p ID context agent equal value agent p ID,
respectively, time time t.
Proof. Assume value arbitrary ancestor agent p SCP (a) arbitrary agent
change current time future time + |A| ( + ) + .
following two cases.
Case 1: agent p parent pseudo-parent agent agent a, sent VALUE message
agent value ID time + , is, cycle took
value time since duration cycle larger . (The
agents send VALUE messages end every cycle.) Agent receives VALUE message
time + since messages delivered nite delay . updates value
agent p ID context time + + since update done cycle
duration cycle larger . Thus, value agent p ID
context agent equal value agent p ID, respectively,
time time + + + + 2 since agent p change
value time time t.
Case 2: agent p parent pseudo-parent agent agent a, one pseudo-child
agents c descendant agent agent a. Agent p sent VALUE message agent c
value ID time + . Agent c receives VALUE message time + .
updates value agent p ID context sends COST message parent
agent pa(c) updated context time + + . (The agents send COST messages
end every cycle.) Agent pa(c) receives COST message time + 2 + .
updates value agent p ID context sends COST message parent
agent pa(pa(c)) updated context time + 2 ( + ). process continues
agent updates value agent p ID context time + n ( + ),
n |A| number messages chain messages. Thus, value agent p
ID context agent equal value agent p ID, respectively,
time time + n ( + ) + |A| ( + ) + since agent
p change value time time t.

115

fiYeoh, Felner & Koenig

Corollary 1. values ancestor agents p SCP (a) arbitrary agent
change current time future time + |A| ( + ) + , context
agent correct time time t.
c
c
c
Lemma 4. LBX
c w X c w U BX c times child agents c C(a) arbitrary
a,c
a,c
c
c
agent contexts X , lbX (d) w X
(a,d) w ubX (d) times context
X agent a, values Dom(a) child agents c C(a).

Proof. prove lemma induction number times agent changes context
a,c
updates bounds lba,c
X (d) ubX (d) arbitrary value arbitrary child agent c
agent initializes bounds. conclusion lemma holds agent context
X initializes bounds since
a,c
lba,c
X (d) = w hX (d)

(Eq. 24)

w

(Eq. 25)

c
X
(a,d)


= w uba,c
X (d)

(Eq. 7)

(unchanged new) context X agent (induction basis). assume lemma
holds agent changed context updated bounds number times (induction assumption). show also holds agent changes context updates bounds one
time (induction step). following two cases (where split operations
receiving COST message two parts).
Case 1: conclusion lemma holds agent changes context X X
receiving VALUE COST message two contexts agree values
ancestor agents p SCP (c) since agent change bounds thus
(d) = lba,c
lba,c
X (d)
X
c
w X
(a,d)

(induction assumption)

c
w X
(a,d)
a,c
ubX (d)
c
X
(a,d)
c
X (a,d)

(Lemma 1)

=
uba,c
(d)
X

(premise case)

=

=

(premise case)
(induction assumption)
(Lemma 1)

receiving VALUE COST message (since contexts X X agree values
ancestor agents p SCP (c)).
Case 2: conclusion lemma holds agent updates bounds lba,c
X (d)
a,c
a,c
a,c


ubX (d) lbX (d) ubX (d), respectively, receiving COST message child
c
c
c
agent c bounds LBX
compatible context X
c U BX c context X
agent value since

116

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

a,ca (d) = max{lba,ca (d), LB c c }
lb
X
X
X
c
c
max{w X
(a,d) , w X c }

(Eq. 8)
(induction assumption premise lemma)

c
c
= max{w X
(a,d) , w X (a,d) }

=w
a,ca (d)
ub
X

(Lemma 1)

c
X
(a,d)

c
= min{uba,c
X (d), U BX c }
c
c
min{X
(a,d) , X c }

(Eq. 11)
(induction assumption premise lemma)

c
c
= min{X
(a,d) , X (a,d) }

=

(Lemma 1)

c
X
(a,d)

receiving COST message (since contexts X (a, d) X c agree values
ancestor agents p SCP (c)).
a,c
c
Thus, lba,c
X (d) w X (a,d) w ubX (d) times values Dom(a) child
agents c C(a).






Lemma 5. LBX
(d) w X (d) w U BX (d) LBX w X w U BX times

values Dom(a) context X arbitrary agent A.

Proof. prove lemma induction depth agent pseudo-tree. lemma
holds leaf agent pseudo-tree context X since


LBX
(d) = X (d)

(Eq. 9)


X
(d)

X (d)

X
(d)

(Eq. 1)
(Eq. 12)

=

U BX
(d) =
=

(Eq. 1)





values times. Thus, LBX
(d) = X (d) w X (d) = w U BX (d) values
times. Furthermore,


LBX
=

=


U BX


min


{LBX
(d)}

(Eq. 10)

dDom(a)

min


{X
(d)}

(see above)

dDom(a)


= X

= min

(Eq. 2)
(Eq. 13)


{U BX
(d)}
dDom(a)

=

min


{X
(d)}

(see above)

dDom(a)

= X


(Eq. 2)





times. Thus, LBX
= X w X = w U BX times (induction basis). assume
lemma holds agents depth pseudo-tree (induction assumption). show
also holds agents depth 1 pseudo-tree time update
bounds (induction step). lemma holds agent context X since

117

fiYeoh, Felner & Koenig





LBX
(d) = X (d) +

lba,c
X (d)

(Eq. 9)

cC(a)




X
(d) +

c
w X
(a,d)

(induction assumption Lemma 4)

cC(a)

w X
(d)


U BX
(d) = X (d) +

(Eq. 1)



uba,c
X (d)

(Eq. 12)

cC(a)




X
(d) +

c
X
(a,d)

(induction assumption Lemma 4)

cC(a)

= X
(d)

(Eq. 1)




Thus, LBX
(d) w X (d) w U BX (d) times values Dom(a). Furthermore,


LBX
=



min


{LBX
(d)}

(Eq. 10)

dDom(a)

min


{w X
(d)}

(see above)

dDom(a)

=w

min


{X
(d)}

dDom(a)


= w X


U BX


=


(Eq. 2)


min {U BX
(d)}
dDom(a)

min

(Eq. 13)


{X
(d)}

(see above)

dDom(a)


= X


(Eq. 2)




Thus, LBX
w X w U BX times.

Definition 2. potential agent context X

LBX
(d)}.



dDom(a) {w


U BX
(d)

Lemma 6. context X arbitrary agent longer changes, potential
agent monotonically non-increasing decreases positive constant every time
agent changes value.


Proof. lower bounds LBX
(d) monotonically non-decreasing upper bounds U BX (d)
monotonically non-increasing values according Lemma 2 since context X
agent longer changes. Therefore, potential agent monotonically non-increasing.


Furthermore, agent changes value new value mindDom(a) {LBX
(d)} < LBX (d)

[Line 24]. Thus, lower bound LBX (d) must strictly increased time
agent changed value time changes value new value. Thus,
potential decreased positive constant, namely smallest possible increase

lower bound LBX
(d). Assume constraint costs, weights heuristic values integers.
Then, smallest possible increase bounded one possible values

LBX
(d) combinations constraint costs weighted heuristic values. similar statement
holds constraint costs, weights heuristic values oating point numbers since
transformed integers multiplying suciently large integer.

Lemma 7. agents change values nite number times.
118

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Proof. Assume lemma hold choose agent changes value
innite number times whose ancestor agents p SCP (a) change values nite
number times. Then, exists time ancestor agents change values
longer. exists (later) time agent longer changes context X according
Corollary 1. Every time agent changes value afterwards, potential decreases
positive constant according Lemma 6, towards minus innity. However, potential cannot


become negative since LBX
(d) w U BX (d) values according Lemma 5,
contradiction. Thus, agents change values nite number times.

Lemma 8. BnB-ADOPT suboptimal variants terminate earlier, U BX



LBX nite amount time agents contexts X .

Proof. prove lemma induction depth agent pseudo-tree. exists
time agent changes value longer according Lemma 7. exists (later)
time contexts agents correct longer change according Corollary 1. Let
X context agent point time agents a. exists (even later)
a,c




time bounds lba,c
X (d), LBX (d), LBX , ubX (d), U BX (d) U BX longer change

agents a, values child agents c since (1) lower bounds lba,c
X (d), LBX (d)
a,c



LBX monotonically non-decreasing upper bounds lbX (d), U BX (d) U BX

monotonically non-increasing agents a, values child agents c according Lemma






2, (2) LBX
(d) w X (d) w U BX (d) LBX w X w U BX agents
a,c
a,c
values according Lemma 5, (3) lbX (d) w ubX (d) agents a, values
child agents c according Lemma 4 (4) smallest possible increases lower bounds
smallest possible decreases upper bounds larger positive constant since
possible values bounds combinations constraint costs heuristic values,
explained detail proof Lemma 6. Consider rst COST message agent
sends time earliest time COST messages processed
receiving agents. lemma holds leaf agent pseudo-tree context X since


LBX
(d) = X (d)

= X
(d)

(Eq. 9)
(Eq. 1)



U BX
(d) = X (d)

= X
(d)

(Eq. 12)
(Eq. 1)

values considered time. Furthermore,

LBX
=

=


U BX


min


{LBX
(d)}

min


{X
(d)}

(Eq. 10)

dDom(a)

(see above)

dDom(a)


= X

= min

(Eq. 2)
(Eq. 13)


{U BX
(d)}
dDom(a)

=

min


{X
(d)}

(see above)

dDom(a)


= X


(Eq. 2)



considered time. Thus, U BX
= LBX considered time (induction basis).
assume lemma holds agents depth pseudo-tree considered time
(induction assumption). show also holds agents depth 1 pseudotree considered time (induction step). agent context X

119

fiYeoh, Felner & Koenig



LBX
(d) = X (d) +



lba,c
X (d)

(Eq. 9)

c
max{lba,c
X (d), LBX c }

(Eq. 8)

cC(a)

= X
(d) +



cC(a)

X
(d) +



c
LBX
c

cC(a)




X
(d)

+



c
U BX
c

(induction assumption)

cC(a)

X
(d) +



c
min{uba,c
X (d), U BX c }

cC(a)

=


X
(d)

+



uba,c
X (d)

(Eq. 11)

cC(a)

= U BX
(d)

(Eq. 12)


value considered time since bounds longer change. Thus, U BX
(d)

(d)


value



considered
time.
Since
agent



change

value

LBX





considered time, must hold LBX
(d)
<
min{T
H
,
U
B
}
[Line
23]

LB

Xa
Xa
X (d) =

mindDom(a) {LBX
(d)}
[Line
24].

rst
disjunct
implies






min{T HX
, U BX } U BX

U BX
(d)

LBX (d)

(Eq. 13)
(see above)



< min{T HX
, U BX }

(rst disjunct)

value d, contradiction. second disjunct implies


U BX
U BX (d)

LBX
(d)

=

min

(Eq. 13)
(see above)


{LBX
(d)}

(second disjunct)

dDom(a)


= LBX


(Eq. 10)



value thus U BX
LBX .

Theorem 1. BnB-ADOPT suboptimal variants terminate nite amount time.


Proof. BnB-ADOPT suboptimal variants terminate earlier, U BX
LBX
nite amount time agents contexts X according Lemma 8.
r
r
r
r
particular, U BX
root agent r, limr = LBX
r LBX r lim
r BnB-ADOPT
r
r

b

0

BnB-ADOPT

limr = p LBX
BnB-ADOPTW HM , limr = b + LBX
r
r
AEM
p 1 BnB-ADOPTREM according Section 4. Thus, termination condition
r
r
r
r
U BX
suboptimal
r LBX r BnB-ADOPT termination condition U BX r lim
variants satised.
r
Theorem 2. BnB-ADOPT terminates minimal solution cost X
r.

120

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Proof. BnB-ADOPT terminates nite amount time according Theorem 1. solution
r
r
r
cost BnB-ADOPT upper bound U BX
r root agent r. U BX r LBX r upon termination
r
r
r
according termination condition. w U BX r w X r LBX r according Lemma 5.
r
r
r
Therefore, U BX
r = X r = LBX r since w = 1.
Theorem 3. BnB-ADOPTAEM terminates solution cost bounded
r
user-dened absolute error bound b plus minimal solution cost X
r.
Proof. BnB-ADOPTAEM terminates nite amount time according Theorem 1.
r
r
r
solution cost BnB-ADOPTAEM upper bound U BX
r root agent r. U BX r lim =
r
r
r
b + LBX r upon termination according termination condition. LBX r w X r according
r
r
Lemma 5. Therefore, U BX
r b + X r since w = 1.
Theorem 4. BnB-ADOPTREM terminates solution cost bounded
r
user-dened relative error bound p times minimal solution cost X
r.
Proof. BnB-ADOPTREM terminates nite amount time according Theorem 1.
r
r
r
solution cost BnB-ADOPTREM upper bound U BX
r root agent r. U BX r lim =
r
r
r
p LBX r upon termination according termination condition. LBX r w X r according
r
r
Lemma 5. Therefore, U BX
r p X r since w = 1.
Theorem 5. BnB-ADOPTW HM terminates solution cost bounded
r
user-dened weight w times minimal solution cost X
r.
Proof. BnB-ADOPTW HM terminates nite amount time according Theorem 1.
r
r
r
solution cost BnB-ADOPTW HM upper bound U BX
r root agent r. U BX r lim =
r
r
r
upon
termination
according


termination
condition.
LB

w


according

LBX
r
Xr
Xr
r
r
Lemma 5. Therefore, U BX

w


.
r
Xr

6. Experimental Evaluations
section, compare BnB-ADOPT two memory-bounded DCOP search algorithms
also restrict communication agents share constraints, namely ADOPT NCBB.
also compare three suboptimal variants BnB-ADOPT other. use distributed
DFS algorithm max-degree heuristic (Hamadi, Bessiere, & Quinqueton, 1998) used
ADOPT construct pseudo-trees. use DP2 (Ali et al., 2005) used ADOPT
pre-calculate heuristic values ADOPT BnB-ADOPT. DP2 solves relaxed version
given DCOP problem (where backedges ignored) dynamic programming based approach.
NCBB calculates heuristic values search rather pre-processing step.
6.1 Runtime Metrics
use two common runtime metrics, namely non-concurrent constraint checks (Meisels, Kaplansky,
Razgon, & Zivan, 2002) cycles (Modi et al., 2005).
Non-concurrent constraint checks (NCCCs): NCCCs weighted sum processing
communication time. Every agent maintains counter N CCC , initialized
0. agent assigns N CCC := N CCC + 1 every time performs constraint check
account time takes perform constraint check. assigns N CCC :=

max{N CCC , N CCC + t} every time receives message agent account

time takes wait agent send message (N CCC ) transmission time
message (t). use = 0 simulate fast communication = 1000 simulate
slow communication. number NCCCs largest counter value agent.

121

fiYeoh, Felner & Koenig

Sensors
1
3

2

Targets
5

6

7

8

9

4
10

11

12

13

Constraints

unit

Figure 15: Example: Allocating Targets

Figure 16: Example: Scheduling Meetings

NCCCs good runtime metric ratio processing communication time
estimated reliably.
Cycles: Cycles time slices. cycle time required agent process incoming
messages queue send outgoing messages, processed receiving
agents next cycle. Thus, number cycles indicates length longest chain
messages agents. Cycles good runtime metric communication time
much larger processing time. Cycles become better better runtime metric
future since communication time expected remain relatively stable
processing time expected decrease (Silaghi, Lass, Sultanik, Regli, Matsui, & Yokoo, 2008).
6.2 DCOP Problem Types
use three DCOP problem types experiments, namely graph coloring problems, sensor
network problems meeting scheduling problems.
Graph coloring: Graph coloring problems involve coloring vertices graph, taking
restrictions colors adjacent vertices account. agents vertices,
domains colors, constraints adjacent vertices. vary
number vertices 5 15, constraint density (= ratio number
constraints number agents) 2 (sparse graphs) 3 (dense graphs)
range constraint costs range 0 1 (small range) range 0 10,000 (large
range). agent always three possible values. average experimental results
50 DCOP problem instances randomly generated constraints randomly generated
integer constraint costs.
Sensor network: Sensor network problems involve assigning targets sensors sensor
network, taking restrictions availability sensors, restrictions number
sensors need track target priorities targets account.
agents targets, domains time slots tracked,
constraints adjacent targets (Maheswaran et al., 2004b). Figure 15 shows sensor
network targets located grid target surrounded four sensors,
needed track target. vary number targets 4 15.
always use 8 time slots. cost assigning time slot target also assigned
adjacent target innity (to precise: 1,000,000) since sensor cannot track
targets time slot. cost targets tracked time
slot 100. costs range 0 100. average experimental results
50 DCOP problem instances randomly generated integer constraint costs.
Meeting scheduling: Meeting scheduling problems involve scheduling meetings
employees company, taking restrictions availability well priorities
account. agents meetings, domains time slots
held, constraints meetings share participants (Maheswaran et al.,
122

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Graph Coloring, Density = 2
Communication Cost = 0

Graph Coloring, Density = 2
Communication Cost = 1000

1.E+08
ADOPT
BnB-ADOPT
NCBB

1.E+04

NCCC

NCCC

1.E+05

1.E+03
1.E+02

ADOPT
BnB-ADOPT
NCBB

1.E+07
1.E+06
1.E+05

5

6

7

8

9

10

11

12

13

14

5

6

7

Number Vertices

8

9

(a)
Graph Coloring, Density = 2

12

13

14

Graph Coloring, Density = 3
Communication Cost = 0

1.E+06

ADOPT
BnB-ADOPT
NCBB

NCCC

1.E+05
Cycles

11

(b)

1.E+04

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+04
1.E+03
1.E+02

1.E+02
5

6

7

8
9
10 11
Number Vertices

12

13

7

14

8

9

11

12

13

14

(d)

Graph Coloring, Density = 3
Communication Cost = 1000

1.E+09

10

Number Vertices

(c)

Graph Coloring, Density = 3
1.E+05

Cycles

ADOPT
BnB-ADOPT
NCBB

1.E+08
NCCC

10

Number Vertices

1.E+07
1.E+06
1.E+05

1.E+04
ADOPT
BnB-ADOPT
NCBB

1.E+03
1.E+02

7

8

9

10

11

12

13

14

7

8

9

10

11

12

13

14

Number Vertices

Number Vertices

(e)

(f)

Figure 17: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Graph Coloring
Problems Constraint Costs Ranging 0 10,000

2004b). Figure 16 shows hierarchical organization 4 units supervisor three
subordinates. example, supervisor 2 three subordinates 5, 6 7. unit,
assume possible meetings: one entire unit (e.g., 2, 5, 6, 7), two parent-child meetings
(e.g., 2, 5 2, 7) two sibling-sibling meetings (e.g., 5, 6 6, 7). vary number
meetings 5 (1 unit) 20 (4 units). always use 8 time slots. cost assigning
time slot meeting least one participant another meeting
time slot innity (to precise: 1,000,000) since person cannot attend
one meeting time. cost non-scheduled meeting 100. costs
range 0 100. average experimental results 50 DCOP problem instances
randomly generated integer constraint costs.

123

fiYeoh, Felner & Koenig

1.E+05

Graph Coloring, Density = 2
Communication Cost = 0

1.E+08
1.E+07
NCCC

NCCC

1.E+04

Graph Coloring, Density = 2
Communication Cost = 1000

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05

1.E+01

1.E+04
0-1

0-10

0-100

0-1,000 0-10,000

0-1

Range Constraint Costs

0-10

0-100

0-1,000 0-10,000

Range Constraint Costs

(a)

(b)

Graph Coloring, Density = 2
1.E+06

1.E+04

Graph Coloring, Density = 3
Communication Cost = 0

NCCC

Cycles

1.E+05
1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04
1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+01

1.E+01
0-1

0-10

0-100

0-1,000 0-10,000

0-1

Range Constraint Costs

(c)

1.E+09

0-100

0-1,000 0-10,000

(d)

Graph Coloring, Density = 3
Communication Cost = 1000

Graph Coloring, Density = 3
1.E+05

1.E+08

1.E+04
Cycles

NCCC

0-10

Range Constraint Costs

1.E+07
1.E+06

ADOPT
BnB-ADOPT
NCBB

1.E+05

1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04

1.E+01
0-1

0-10

0-100

0-1,000 0-10,000

Range Constraint Costs

0-1

0-10

0-100

0-1,000 0-10,000

Range Constraint Costs

(e)

(f)

Figure 18: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Graph Coloring
Problems 10 Vertices

6.3 Experimental Results: Optimal DCOP Search Algorithms
rst compare BnB-ADOPT ADOPT NCBB. Figure 17 shows experimental results
graph coloring problems constraint costs ranging 0 10,000, varied
number vertices, Figure 18 shows experimental results graph coloring problems
10 vertices, varied range constraint costs. Figures 17(a-c) 18(a-c) show
results coloring sparse graphs, Figures 17(d-f) 18(d-f) show results coloring
dense graphs. y-axes log scale show runtimes NCCCs cycles. DCOP search
algorithms sparse graphs faster dense graphs because, example, larger
likelihood independent DCOP subproblems sparse graphs. BnB-ADOPT generally faster
NCBB sparse graphs dense graphs BnB-ADOPT allows agents send
messages parent agents pseudo-tree (along edges pseudo-tree) NCBB

124

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Sensor Network
Communication Cost = 1000

1.E+06

1.E+09

1.E+05

1.E+08
NCCC

NCCC

Sensor Network
Communication Cost = 0

1.E+04
1.E+03

ADOPT
BnB-ADOPT
NCBB

1.E+02

ADOPT
BnB-ADOPT
NCBB

1.E+07
1.E+06
1.E+05

1.E+01

1.E+04
4

5

6

4

7 8 9 10 11 12 13 14 15
Number Targets

5

6

(a)

(b)

Sensor Network

Meeting Scheduling
Communication Cost = 0

1.E+05

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05
NCCC

Cycles

1.E+04
1.E+03
1.E+02

1.E+04
ADOPT
BnB-ADOPT
NCBB

1.E+03

1.E+01

1.E+02
4

5

6

5

7 8 9 10 11 12 13 14 15
Number Targets

6

7

(c)

13

14

15

Meeting Scheduling
1.E+05

1.E+07

1.E+04
Cycles

1.E+08

1.E+06
ADOPT
BnB-ADOPT
NCBB

1.E+05

8
9 10 11 12
Number Meetings

(d)

Meeting Scheduling
Communication Cost = 1000

NCCC

7 8 9 10 11 12 13 14 15
Number Targets

1.E+03
ADOPT
BnB-ADOPT
NCBB

1.E+02

1.E+04

1.E+01
5

6

7

8
9 10 11 12
Number Meetings

13

14

15

(e)

5

6

7

8
9 10 11 12
Number Meetings

13

14

15

(f)

Figure 19: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Sensor Network
Meeting Scheduling Problems

allows agents also send messages pseudo-parent agents (along backedges pseudotree). Thus, agents NCBB receive updates faster agents BnB-ADOPT. eect
prevalent dense graphs since backedges dense graphs. However, dierence
BnB-ADOPT NCBB becomes negligible communication slow.
Figure 17 shows BnB-ADOPT least half order magnitude faster ADOPT
number vertices small. speedup ADOPT increases number vertices
gets larger DCOP problems thus become complex. Similarly, Figure 18 shows
speedup ADOPT increases range constant costs increases DCOP problems
thus become complex. However, ADOPT faster BnB-ADOPT simple DCOP
problems. example, ADOPT requires fewer cycles BnB-ADOPT DCOP problems
constraint costs ranging 0 1. Figure 19 shows trend sensor network meeting
scheduling problems. reason behavior follows. ADOPT uses memory-bounded best125

fiYeoh, Felner & Koenig

Sensor Network
Communication Cost = 0

1.E+05

Sensor Network
Communication Cost = 1000

1.E+06

NCCC

NCCC

1.E+04
1.E+03
ADOPT

1.E+02

1.E+05
ADOPT

BnB-ADOPT

BnB-ADOPT

1.E+01

1.E+04
0.5

0.6

0.7
0.8
Weight

0.9

1

0.5

0.6

(a)

0.9

1

0.9

1

(b)

Sensor Network
1.E+03

Sensor Network
Unique Contexts Explored

1.E+02
No.
Contexts

Cycles

0.7
0.8
Weight

1.E+02
ADOPT

ADOPT
BnB-ADOPT

BnB-ADOPT

1.E+01

1.E+01
0.5

0.6

0.7
0.8
Weight

0.9

1

0.5

0.6

(c)

0.7
0.8
Weight

(d)
Sensor Network
Repeated Contexts Explored

No.
Contexts

1.E+03
1.E+02

ADOPT
BnB-ADOPT

1.E+01
1.E+00
0.5

0.6

0.7
0.8
Weight

0.9

1

(e)

Figure 20: Experimental Results Cause Speedup ADOPT BnB-ADOPT
rst search thus exploits heuristic values well needs repeatedly reconstruct partial
solutions purged memory, especially heuristic values poorly informed. BnBADOPT uses depth-rst branch-and-bound search thus exploit heuristic values
quite well repeatedly reconstruct partial solutions. ADOPT thus
faster BnB-ADOPT DCOP problems well informed heuristic values, simple
DCOP problems.
conrm intuition additional experiment sensor network problems four
targets dierent informedness heuristic values. use heuristic values cha,c
X (d) 0.5
c 1, ha,c
X (d) heuristic values calculated DP2, used now. Figures 20(a-c)
show number NCCCs dierent weights c. heuristic values well informed (large
weights), ADOPT indeed faster BnB-ADOPT. Since ADOPT relies heuristic
values BnB-ADOPT, speedup ADOPT much larger BnB-ADOPT
heuristic values get informed. Figures 20(d) 20(e) show number unique

126

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

(= dierent) repeated contexts per agent dierent weights c. heuristic values
well informed (large weights), agents ADOPT explore fewer unique contexts agents BnBADOPT since focused search. However, heuristic values poorly
informed (small weights), explore unique contexts. Agents ADOPT explore many
repeated contexts agents BnB-ADOPT since need reconstruct partial solutions
purged memory. Agents BnB-ADOPT explore repeated contexts even though
reconstruct partial solutions. reason behavior distributed nature
BnB-ADOPT. example, assume context agent {(a1 , 0), (a2 , 0)} next
context centralized variant BnB-ADOPT would {(a1 , 1), (a2 , 1)} (where IDs omitted
simplicity). agent updates context {(a1 , 1), (a2 , 0)} receives message
agent a1 takes value 1. agent updates context {(a1 , 1), (a2 , 1)}
receives message agent a2 takes value 1. Thus, agent explores intermediate
context {(a1 , 1), (a2 , 0)} centralized variant BnB-ADOPT would explore. counts
repeated context agent explores context intentionally future. Overall, BnB-ADOPT
tends faster ADOPT heuristic values poorly informed (small weights). Thus,
BnB-ADOPT great potential DCOP search algorithm since heuristic values often poorly
informed complex DCOP problems, DCOP problems large numbers agents, large
domains, large numbers constraints large ranges constraint costs.
6.4 Experimental Results: Suboptimal Variants BnB-ADOPT
compare three suboptimal variants BnB-ADOPT other. experimental
setup identical one optimal DCOP search algorithms, except follows: graph
coloring problems, number vertices 10, range constraint costs 0 10,000
constraint density 2; sensor network problems, number targets 9; meeting
scheduling problems, number meetings 10. measure runtimes cycles. (The results
NCCCs similar.) However, report normalized runtimes, is, runtimes divided
runtime nding cost-minimal solution BnB-ADOPT. Thus, normalized runtime
0.25 refers one quarter number cycles takes nd cost-minimal solution
BnB-ADOPT. Similarly, report normalized solution costs, is, solution costs divided
minimal solution costs. Thus, normalized solution cost 2.5 refers solution cost
two half times larger minimal solution cost. vary relative error bound (which
worst acceptable normalized solution cost) 1.0 4.0. relative error bound p
BnB-ADOPTREM w BnB-ADOPTW HM . pre-calculate minimal solution costs
set correct value b BnB-ADOPTAEM . example, minimal solution cost 100
relative error bound 2.5, p = 2.5 BnB-ADOPTREM , w = 2.5 BnB-ADOPTW HM
b = (2.5 1) 100 = 150 BnB-ADOPTAEM .
Figure 21(a-c) shows experimental results graph coloring problems. Figure 21(a) shows
normalized solution costs three suboptimal variants increase relative error
bound increases. However, solution costs remain much smaller error bound.
example, normalized solution costs three suboptimal variants less 1.3 (rather
3) relative error bound 3. normalized solution costs BnB-ADOPTAEM
usually larger normalized solution costs BnB-ADOPTREM relative error
r
r
bound. reason behavior BnB-ADOPTAEM terminates U BX
=
r lim
r
r
r
r
b + LBX r = (p 1) X r + LBX r , X r minimal solution cost. Thus, solution cost
r
r
r
BnB-ADOPTAEM U BX
r LBX r (p 1) X r larger minimal solution
r
r
r
cost. hand, BnB-ADOPTREM terminates U BX
r lim = p LBX r . Thus,
r
r
r
solution cost BnB-ADOPTREM U BX r LBX r (p 1) LBX r larger
minimal solution cost. absolute error bound BnB-ADOPTAEM thus smaller
r
r
absolute error bound BnB-ADOPTREM since X
r LBX r initially strictly greater
r
r
absolute error bound BnB-ADOPTREM since X r > LBX
r search.

127

fiYeoh, Felner & Koenig

Graph Coloring
Solution Cost BnB-ADOPT Variants

Graph Coloring
Computation Time BnB-ADOPT Variants
1.00
Normalized Runtimes
(Cycles)

Normalized Costs

1.35
1.30
1.25
1.20
1.15

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

1.10
1.05
1.00
1.00

1.50

2.00
2.50
3.00
Relative Error Bound

3.50

0.80

0.40
0.20
0.00
1.00

4.00

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60

1.50

2.00
2.50
3.00
Relative Error Bound

(a)
Graph Coloring
Performance BnB-ADOPT Variants

Sensor Network
Performance BnB-ADOPT Variants
1.00

0.80

Normalized Runtimes
(Cycles)

Normalized Runtimes
(Cycles)

4.00

(b)

1.00
Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

3.50

1.05

1.10
1.15
1.20
Normalized Costs

1.25

1.30

0.80

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

1.02

1.04

(c)

1.06
1.08
1.10
Normalized Costs

1.12

1.14

(d)
Meeting Scheduling
Performance BnB-ADOPT Variants
Normalized Runtimes
(Cycles)

1.00
0.80

Weighted Heuristics (WHM)
Absolute Error (AEM)
Relative Error (REM)

0.60
0.40
0.20
0.00
1.00

1.05

1.10
1.15
Normalized Costs

1.20

1.25

(e)

Figure 21: Experimental Results Comparing Suboptimal Variants BnB-ADOPT
Figure 21(b) shows normalized runtimes three suboptimal variants decrease
relative error bound increases. decrease almost 0 relative error bound 2.0.
Therefore, three suboptimal variants terminate almost immediately nding rst solution.
normalized runtimes BnB-ADOPTAEM usually smaller normalized runtimes
BnB-ADOPTREM relative error bound since BnB-ADOPTAEM terminate
suboptimal solution cost within absolute error bound yet within absolute error
bound BnB-ADOPTREM absolute error bound BnB-ADOPTAEM strictly greater
absolute error bound BnB-ADOPTREM . words, BnB-ADOPTAEM terminate
r
r
r
suboptimal solution cost (p 1) LBX
r < U BX r (p 1) X r BnB-ADOPTREM
not.
Figure 21(c) shows normalized runtimes needed achieve given normalized solution cost.
BnB-ADOPTW HM terminates faster BnB-ADOPTAEM , turn terminates faster
BnB-ADOPTREM . example, normalized runtime needed achieve normalized solu-

128

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

tion cost 1.05 0.18 BnB-ADOPTW HM , 0.30 BnB-ADOPTAEM 0.35 BnBADOPTREM . Thus, BnB-ADOPTW HM suboptimal variant BnB-ADOPT best
performance. Figures 21(d-e) show trend sensor network meeting scheduling problems.

7. Conclusions
article, introduced Branch-and-Bound ADOPT (BnB-ADOPT), memory-bounded
DCOP search algorithm. BnB-ADOPT uses message passing communication framework
ADOPT changes search strategy ADOPT best-rst search depth-rst branchand-bound search make ADOPT faster taking advantage fact DCOP problems
depth-bounded search trees. properties BnB-ADOPT similar ADOPT.
BnB-ADOPT allows agents operate concurrently (in order decrease runtime) asynchronously (in order increase robustness). BnB-ADOPT restricts communication agents
share constraints (in order restrictions applications sensor networks). Finally,
BnB-ADOPT orders agents pseudo-tree (in order take advantage independent DCOP
subproblems). experimental results showed BnB-ADOPT nds cost-minimal solutions
one order magnitude faster ADOPT variety large DCOP problems fast
NCBB DCOP problems. reason behavior following: Agents
NCBB operate sequentially thus often idle. ADOPT construct fewer partial solutions
BnB-ADOPT reconstruct partial solutions purged memory.
advantage ADOPT respect number constructed partial solutions decreases
disadvantage respect number reconstructed partial solutions increases heuristic
values become poorly informed. Thus, BnB-ADOPT great potential DCOP search
algorithm since heuristic values often poorly informed complex DCOP problems
DCOP problems large numbers agents, large domains, large numbers constraints large
ranges constraint costs.
also investigated three approximation mechanisms trade solution cost BnBADOPT smaller runtime, namely Absolute Error Mechanism ADOPT (resulting
BnB-ADOPTAEM ), new Relative Error Mechanism (resulting BnB-ADOPTREM )
new Weighted Heuristics Mechanism (resulting BnB-ADOPTW HM ). two new approximation mechanisms allow users specify relative error bound, often meaningful
absolute error bound. Weighted Heuristics Mechanism dominated Absolute Error Mechanism Relative Error Mechanism experiments apply
DCOP search algorithms well since benet using heuristic values focus
searches (Yeoh, Koenig, & Sun, 2008b).
future, plan improve BnB-ADOPT following ways: First, would like
reduce number sent messages handle lost messages. Second, would like study
dierent pseudo-tree arrangements (Atlas & Decker, 2007; Sultanik, Lass, & Regli, 2009)
pre-processing techniques (Matsui et al., 2009) aect eciency BnB-ADOPT. Finally,
would like compare BnB-ADOPT approximation mechanisms DCOP algorithms,
including OptAPO, DPOP variants (Petcu & Faltings, 2005a, 2006).

Acknowledgments
article extension two earlier publications (Yeoh, Felner, & Koenig, 2008a; Yeoh et al.,
2008b) contains additional expositions, examples proofs. thank Anton Chechetka
providing us implementation NCBB anonymous reviewers helpful
comments. research done Ariel Felner spent sabbatical University
Southern California, visiting Sven Koenig. research partly supported U.S. Army

129

fiYeoh, Felner & Koenig

Research Laboratory (ARL) U.S. Army Research Oce (ARO) award Sven Koenig
grant W911NF-08-1-0468, Oce Naval Research (ONR) award Sven Koenig grant
N00014-09-1-1031, National Science Foundation (NSF) award Sven Koenig grant
0413196 Israeli Science Foundation (ISF) award Ariel Felner grants 728/06
305/09. views conclusions contained document authors
interpreted representing ocial policies, either expressed implied, sponsoring
organizations, agencies, companies U.S. government.

References
Ali, S., Koenig, S., & Tambe, M. (2005). Preprocessing techniques accelerating DCOP
algorithm ADOPT. Proceedings International Joint Conference Autonomous
Agents Multiagent Systems (AAMAS), pp. 10411048.
Atlas, J., & Decker, K. (2007). complete distributed constraint optimization method nontraditional pseudotree arrangements. Proceedings International Joint Conference
Autonomous Agents Multiagent Systems (AAMAS), pp. 736743.
Bayardo, R., & Miranker, D. (1995). space-time trade-o solving constraint satisfaction problems. Proceedings International Joint Conference Articial Intelligence
(IJCAI), pp. 558562.
Bistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H. (1999). Semiring-based
CSPs valued CSPs: Basic properties comparison. Constraints, 4 (3), 199240.
Bowring, E., Pearce, J., Portway, C., Jain, M., & Tambe, M. (2008). k-optimal distributed
constraint optimization algorithms: New bounds algorithms. Proceedings International Joint Conference Autonomous Agents Multiagent Systems (AAMAS), pp.
607614.
Bowring, E., Tambe, M., & Yokoo, M. (2006). Multiply-constrained distributed constraint optimization. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 14131420.
Burke, D., & Brown, K. (2006). Eciently handling complex local problems distributed constraint
optimisation. Proceedings European Conference Articial Intelligence (ECAI), pp.
701702.
Chechetka, A., & Sycara, K. (2006). No-commitment branch bound search distributed
constraint optimization. Proceedings International Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 14271429.
Choxi, H., & Modi, P. (2007). distributed constraint optimization approach wireless network
optimization. Proceedings AAAI-07 Workshop Conguration, pp. 18.
Davin, J., & Modi, P. (2006). Hierarchical variable ordering multiagent agreement problems.
Proceedings International Joint Conference Autonomous Agents Multiagent
Systems (AAMAS), pp. 14331435.
Dechter, R. (Ed.). (2003). Constraint Processing. Morgan Kaufmann.
Fitzpatrick, S., & Meertens, L. (2003). Distributed coordination anarchic optimization.
Lesser, V., Ortiz, C., & Tambe, M. (Eds.), Distributed Sensor Networks: Multiagent
Perspective, pp. 257295. Kluwer.
Freuder, E., & Quinn, M. (1985). Taking advantage stable sets variables constraint satisfaction problems. Proceedings International Joint Conference Articial Intelligence
(IJCAI), pp. 10761078.

130

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Gershman, A., Meisels, A., & Zivan, R. (2009). Asynchronous Forward-Bounding distributed
COPs. Journal Articial Intelligence Research, 34, 6188.
Greenstadt, R. (2009). overview privacy improvements k-optimal DCOP algorithms (extended abstract). Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 12791280.
Greenstadt, R., Grosz, B., & Smith, M. (2007). SSDPOP: Improving privacy DCOP
secret sharing. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 10981100.
Hamadi, Y., Bessiere, C., & Quinqueton, J. (1998). Distributed intelligent backtracking. Proceedings European Conference Articial Intelligence (ECAI), pp. 219223.
Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem. Proceedings International Conference Principles Practice Constraint Programming
(CP), pp. 222236.
Jain, M., Taylor, M., Tambe, M., & Yokoo, M. (2009). DCOPs meet real world: Exploring
unknown reward matrices applications mobile sensor networks. Proceedings
International Joint Conference Articial Intelligence (IJCAI), pp. 181186.
Junges, R., & Bazzan, A. (2008). Evaluating performance DCOP algorithms real world,
dynamic problem. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 599606.
Korf, R. (1993). Linear-space best-rst search. Articial Intelligence, 62 (1), 4178.
Kumar, A., Faltings, B., & Petcu, A. (2009). Distributed constraint optimization structured
resource constraints. Proceedings International Joint Conference Autonomous
Agents Multiagent Systems (AAMAS), pp. 923930.
Lesser, V., Ortiz, C., & Tambe, M. (Eds.). (2003). Distributed Sensor Networks: Multiagent
Perspective. Kluwer.
Maheswaran, R., Pearce, J., & Tambe, M. (2004a). Distributed algorithms DCOP: graphical game-based approach. Proceedings International Conference Parallel
Distributed Computing Systems (PDCS), pp. 432439.
Maheswaran, R., Tambe, M., Bowring, E., Pearce, J., & Varakantham, P. (2004b). Taking DCOP
real world: Ecient complete solutions distributed event scheduling. Proceedings
International Joint Conference Autonomous Agents Multiagent Systems (AAMAS),
pp. 310317.
Mailler, R., & Lesser, V. (2004). Solving distributed constraint optimization problems using cooperative mediation. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 438445.
Marinescu, R., & Dechter, R. (2007). Best-rst AND/OR search graphical models. Proceedings
AAAI Conference Articial Intelligence (AAAI), pp. 11711176.
Marinescu, R., & Dechter, R. (2009). AND/OR branch-and-bound search combinatorial optimization graphical models. Articial Intelligence, 173 (16-17), 14571491.
Matsui, T., Silaghi, M., Hirayama, K., Yokoo, M., & Matsuo, H. (2009). Directed soft arc consistency
pseudo trees. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 10651072.
Meisels, A., Kaplansky, E., Razgon, I., & Zivan, R. (2002). Comparing performance distributed
constraints processing algorithms. Proceedings Distributed Constraint Reasoning
Workshop, pp. 8693.

131

fiYeoh, Felner & Koenig

Modi, P., & Ali, S. (2004). Distributed constraint reasoning unreliable communication.
Zhang, W., & Sorge, V. (Eds.), Frontiers Articial Intelligence Applications, Vol. 112,
pp. 141150. IOS Press.
Modi, P., Shen, W.-M., Tambe, M., & Yokoo, M. (2005). ADOPT: Asynchronous distributed constraint optimization quality guarantees. Articial Intelligence, 161 (1-2), 149180.
Ottens, B., & Faltings, B. (2008). Coordinating agent plans distributed constraint optimization. Proceedings ICAPS-08 Workshop Multiagent Planning.
Pearce, J., & Tambe, M. (2007). Quality guarantees k-optimal solutions distributed constraint
optimization problems. Proceedings International Joint Conference Articial
Intelligence (IJCAI), pp. 14461451.
Pecora, F., Modi, P., & Scerri, P. (2006). Reasoning dynamically posting n-ary constraints
ADOPT. Proceedings Distributed Constraint Reasoning Workshop, pp. 5771.
Petcu, A., & Faltings, B. (2005a). Approximations distributed optimization. Proceedings
International Conference Principles Practice Constraint Programming (CP), pp.
802806.
Petcu, A., & Faltings, B. (2005b). scalable method multiagent constraint optimization.
Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 1413
1420.
Petcu, A., & Faltings, B. (2006). ODPOP: algorithm open/distributed constraint optimization. Proceedings National Conference Articial Intelligence (AAAI), pp. 703708.
Pohl, I. (1970). First results eect error heuristic search. Machine Intelligence, 5,
219236.
Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamic
weighting computational issues heuristic problem solving. Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 1217.
Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued constraint satisfaction problems: Hard
easy problems. Proceedings International Joint Conference Articial Intelligence
(IJCAI), pp. 631637.
Schurr, N., Okamoto, S., Maheswaran, R., Scerri, P., & Tambe, M. (2005). Evolution teamwork
model. Sun, R. (Ed.), Cognition Multi-Agent Interaction: Cognitive Modeling
Social Simulation, pp. 307327. Cambridge University Press.
Silaghi, M., Landwehr, J., & Larrosa, J. (2004). Asynchronous branch & bound A* disWCSPs
heuristic function based consistency-maintenance. Zhang, W., & Sorge, V. (Eds.),
Frontiers Articial Intelligence Applications, Vol. 112, pp. 4962. IOS Press.
Silaghi, M., Lass, R., Sultanik, E., Regli, W., Matsui, T., & Yokoo, M. (2008). operation point
units distributed constraint solvers. Proceedings Distributed Constraint Reasoning
Workshop, pp. 116.
Silaghi, M., & Yokoo, M. (2009). ADOPT-ing: Unifying asynchronous distributed optimization
asynchronous backtracking. Autonomous Agents Multi-Agent Systems, 19 (2), 89123.
Stranders, R., Farinelli, A., Rogers, A., & Jennings, N. (2009). Decentralised coordination mobile
sensors using Max-Sum algorithm. Proceedings International Joint Conference
Articial Intelligence (IJCAI), pp. 299304.
Sultanik, E., Lass, R., & Regli, W. (2009). Dynamic conguration agent organizations.
Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 305
311.

132

fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm

Yeoh, W., Felner, A., & Koenig, S. (2008a). BnB-ADOPT: asynchronous branch-and-bound
DCOP algorithm. Proceedings International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 591598.
Yeoh, W., Koenig, S., & Sun, X. (2008b). Trading solution cost smaller runtime DCOP
search algorithms (short paper). Proceedings International Joint Conference
Autonomous Agents Multiagent Systems (AAMAS), pp. 14451448.
Yeoh, W., Varakantham, P., & Koenig, S. (2009). Caching schemes DCOP search algorithms.
Proceedings International Joint Conference Autonomous Agents Multiagent
Systems (AAMAS), pp. 609616.
Yokoo, M., & Hirayama, K. (1996). Distributed breakout algorithm solving distributed constraint
satisfaction problems. Proceedings International Conference Multiagent Systems
(ICMAS), pp. 401408.
Zhang, W., & Korf, R. (1995). Performance linear-space search algorithms. Articial Intelligence,
79 (2), 241292.
Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2003). analysis application distributed
constraint satisfaction optimization algorithms sensor networks. Proceedings
International Joint Conference Autonomous Agents Multiagent Systems (AAMAS),
pp. 185192.
Zivan, R. (2008). Anytime local search distributed constraint optimization. Proceedings
AAAI Conference Articial Intelligence (AAAI), pp. 393398.
Zivan, R., Glinton, R., & Sycara, K. (2009). Distributed constraint optimization large teams
mobile sensing agents. Proceedings International Conference Intelligent Agent
Technology (IAT), pp. 347354.

133

fiJournal Artificial Intelligence Research 38 (2010) 223-269

Submitted 11/09; published 05/10

Grounding FO FO(ID) Bounds
Johan Wittocx
Maarten Marien
Marc Denecker

johan.wittocx@cs.kuleuven.be
maarten.marien@cs.kuleuven.be
marc.denecker@cs.kuleuven.be

Katholieke Universiteit Leuven
Department Computer Science
Celestijnenlaan 200A, 3001 Heverlee, Belgium

Abstract
Grounding task reducing first-order theory finite domain equivalent
propositional theory. used preprocessing phase many logic-based reasoning systems.
systems provide rich first-order input language user rely efficient propositional
solvers perform actual reasoning.
Besides first-order theory finite domain, input grounders contains many applications also additional data. exploiting data, size grounders output often
reduced significantly. common practice improve efficiency grounder context
manually adding semantically redundant information input theory, indicating
grounder exploit data. paper present method compute
add redundant information automatically. method therefore simplifies task
writing input theories grounded efficiently current systems.
first present method classical first-order logic (FO) theories. extend
FO(ID), extension FO inductive definitions, allows concise
comprehensive input theories. discuss implementation issues experimentally validate
practical applicability method.

1. Introduction
Grounding, propositionalization, task reducing first-order theory finite domain
equivalent propositional theory, called grounding. Grounding used preprocessing phase
many logic-based reasoning systems. serves provide user rich input language,
enabling system rely efficient propositional solvers perform actual reasoning.
Examples systems rely grounding found area finite first-order model
generation (Claessen & Sorensson, 2003; McCune, 2003; East, Iakhiaev, Mikitiuk, & Truszczynski,
2006; Mitchell, Ternovska, Hach, & Mohebali, 2006; Torlak & Jackson, 2007; Wittocx, Marien, &
Denecker, 2008d). systems turn used part theorem provers (Claessen & Sorensson,
2003) lightweight software verification (Jackson, 2006). Currently, almost Answer Set
Programming (ASP) systems rely grounding preprocessing phase (Gebser, Schaub, & Thiele,
2007; Perri, Scarcello, Catalano, & Leone, 2007; Syrjanen, 2000; Syrjanen, 2009). Also planning
systems (Kautz & Selman, 1996) relational data mining (Krogel, Rawles, Zelezny, Flach, Lavrac,
& Wrobel, 2003) grounding frequently used. large number applications indicates
importance grounding logic-based reasoning systems need develop efficient grounders.
basic (naive) grounding method instantiating variables input theory
possible combinations domain elements. Grounding way polynomial size
domain exponential maximum width formula input theory, may easily
produce groundings unwieldy size. Several techniques developed efficiently produce
smaller groundings. two main categories techniques. first, input theory
rewritten maximum width formulas decreases. Methods like clause splitting
(Schulz, 2002) partitioning (Ramachandran & Amir, 2005) belong category.

c
2010
AI Access Foundation. rights reserved.

fiWittocx, Marien, & Denecker

second type techniques applicable besides finite domain, additional data
available. often case practical model generation problems, ones
typical ASP. graph problem data could encoding input graph; context
planning, could description initial goal state, etc. Sometimes data explicitly
available, e.g., form database, sometimes implicit, e.g., set ground facts
input theory. second type techniques aims efficiently computing small groundings
taking data account.
Observe types techniques combined grounder. paper mainly
focus technique second category. explain intuition underlying method, consider
following model generation problem.
Example 1. Let T1 first-order logic theory vocabulary {Edge, Sub}, consisting
two sentences
uv (Sub(u, v) Edge(u, v))

(1)

xyz (Sub(x, y) Sub(x, z) = z),

(2)

T1 expresses Sub subgraph Edge one outgoing edge vertex. Computing subgraph given graph G = hV, Ei cast model generation problem
input theory T1 data G. data represented structure subvocabulary
1 = {Edge} domain V EdgeI = E. solution obtained generating model
T1 expands interpretation Sub.
Applying naive grounding algorithm produces |V |2 instantiations (1) |V |3 instantiations (2). taking data account, atoms Edge = substituted
truth value . Simplifying resulting grounding eliminates |E| instantiations (1)
|V | instantiations (2). Smart grounding algorithms interleave substitution simplification
grounding process order avoid creating unnecessary parts grounding.
Observe substituting atoms 1 simplifying still produces grounding size
O(|V |3 ). Indeed, simplified grounding (2) set binary clauses Sub(i, j) Sub(i, k)
i, j, k V 6= j. set size |V |3 |V |.
grounders apply reasoning ground theory reduce even further. example,
simplified grounding (1) consists clauses Sub(i, j) (i, j) 6 E. Since
unit clauses, certainly true every model ground theory. follows
binary clauses Sub(i, j) Sub(i, k) either Sub(i, j) Sub(i, k) belongs
simplified grounding (1) certainly true every model ground theory thus
omitted simplified grounding (2). result grounding size |E ./1=1 E|,
./1=1 denotes natural join matching first columns. sparse graph, |E ./1=1 E|
much smaller |V |3 . However, since reasoning ground theory avoid creating
instantiations formula, significantly speed grounding process.
One way avoid large grounding without relying reasoning ground theory
adding redundant information formulas. method frequently used ASP. example,
xyz(Edge(x, y) Sub(x, y) Edge(x, z) Sub(x, z) = z)

(3)

equivalent (2) given (1), grounding (without reasoning ground theory) equal
one obtained kind reasoning ground theory illustrated above. illustrates
adding redundant information may sometimes dramatically reduce size grounding.
Since current grounders optimized ground formulas like (3) without trying instances,
grounding may also speed lot.
However, manually adding redundancy formulas disadvantages: leads complex hence, less readable theories. Worse, might introduce errors. requires good understanding used grounder, since depends grounder information beneficial
add where. Also, human developer could easily miss useful information.
224

fiGrounding FO FO(ID) Bounds

motivates study automated methods deriving redundant information
principled ways adding formulas. develop algorithm that, given model generation
problem input theory input data , derives redundant information, form
pair symbolic upper lower bound subformula . bounds
formula vocabulary . instance, Example 1, algorithm compute
Edge(x, y) upper bound Sub(x, y), meaning Edge(x, y) true, Sub(x, y)
true either. also show insert bounds formulas . example, inserting
upperbound Edge(x, y) Sub(x, y) upperbound Edge(x, z) Sub(x, z) transforms (2)
(3).
rest paper organized follows. next section recall notions
first-order logic (FO) introduce notations used throughout paper. Section 3
formally define grounding model generation additional data. Section 4 introduce
upper- lowerbounds formulas. present any-time algorithm compute
context FO input theories. show bounds used rewrite input theory
equivalent theory smaller grounding.
Although many search problems cast concisely naturally FO model generation
problems, problems require richer logics FO. One logic FO(ID), extension
FO inductive definitions. definitions used represent, e.g., concept
reachability graph. Section 5 extend rewriting method FO(ID).
Section 6 discuss implement algorithm compute bounds. case study,
show one particular grounding algorithm adapted exploit bounds directly.
also present experimental results indicate impact method grounding size
time. end related work conclusions.
current paper extends previous work (Wittocx, Marien, & Denecker, 2008c). Besides
proofs main propositions thorough experimental validation, also following
parts added:
theoretical result stating rewriting method certainly yields smaller groundings
(Proposition 23);
extension rewriting method FO(ID) (Section 5);
section implementation issues (Section 6).

2. Preliminaries
section, introduce conventions notations used paper. assume reader
familiar FO.
2.1 First-Order Logic
vocabulary tuple hP , F , V P , F V respectively sets predicate
symbols, function symbols variables. identify constants zero-arity function symbols.
Abusing notation, often leave V simply write hP , F represent . vocabulary
subvocabulary , denoted , P P , F F V V .
Throughout paper variables denoted lowercase letters, predicate function symbols
uppercase letters. predicate function symbol associated arity n N. often
denote predicate symbol P P/n function symbol F F/n indicate arities.
Tuples sets variables denoted x, y, z. term inductively defined
variable x term;
F/n function symbol t1 , . . . , tn terms , F (t1 , . . . , tn ) term.
225

fiWittocx, Marien, & Denecker

Tuples terms denoted t, t1 , t2 , . . . . first-order logic formula inductively defined

P/n predicate symbol t1 , . . . , tn terms, P (t1 , . . . , tn ) formula.
t1 t2 two terms, t1 = t2 formula.
formulas x variable, , , , x x formulas.
use , t1 6= t2 shorthands respectively , ( ) ( )
(t1 = t2 ). atom formula form P (t) t1 = t2 . literal atom negation
atom.
occurrence formula subformula formula positive, respectively negative,
occurs scope even, respectively odd, number negations.
formula , often write [x] indicate x free variables. is, x,
occurs , scope quantifier . variable x term t,
formula [x/t] denotes result replacing free occurrences x t. notation
extended tuples variables terms length. sentence formula without
free variables. theory finite set sentences.
-interpretation consists domain
domain element xI variable x V ;
relation P Dn predicate symbol P/n P ;
function F : Dn function symbol F/n F .
-structure interpretation relation function symbols . restriction
-interpretation vocabulary denoted I| . Vice versa, called expansion
I| . variable x domain element d, I[x/d] interpretation assigns
x corresponds symbols. notation extended tuples variables
domain elements length. interpretation called finite domain finite.
value tI term interpretation I, satisfaction relation |= defined
usual (e.g., Enderton, 2001). called model formula |= . denote T1 |= T2
every model theory T1 also model theory T2 .
query expression form {x | }, free variables among x. tuple
domain elements answer {x | } structure I[x/d] |= . set answers
{x | } denoted {x | }I .
2.2 Rewriting Term Normal Form
paper use following well-known equivalences rewrite formulas logically
equivalent formulas.
1. Moving quantifiers
xy



xy



yx

(4)

yx

(5)

x ( )



(x ) (x )

(6)

x ( )



(x ) (x )

(7)

x ( )



(x )

x occur free

(8)

x ( )



(x )

x occur free

(9)

226

fiGrounding FO FO(ID) Bounds

2. Moving negations
( )



() ()

(10)

( )



() ()

(11)

(x )



x ()

(12)

(x )



x ()

(13)

3. Flattening terms
P (t1 , . . . , ti , . . . , tn ) x (x = ti P (t1 , . . . , ti1 , x, ti+1 , . . . , tn ))

(14)

x occur P (t1 , . . . , tn ).
facilitate presentation, sometimes require formulas term normal form
(TNF). say formula TNF, every atomic subformula form P (x),
F (x) = x = y, negations occur directly front atoms. Using (10)(14), every
formula transformed equivalent formula TNF. say theory TNF
sentences are.
2.3 SAT
vocabulary propositional F = every predicate symbol P arity zero.
propositional theory (PC theory) theory propositional vocabulary. propositional clause
disjunction propositional literals. PC theory conjunctive normal form (CNF)
sentences clauses. Boolean satisfiability problem (SAT) NP-complete problem
deciding PC theory whether satisfiable. NP search problem corresponding SAT
problem problem computing witness decision problem form model
theory. SAT solvers typically operate constructing model.
Contemporary SAT solvers exhibit impressive performance. such, many NP problems
solved efficiently translating SAT. instance, done areas model
generation (Claessen & Sorensson, 2003; McCune, 2003), planning (Kautz & Selman, 1996)
relational data mining (Krogel et al., 2003). modern SAT solvers expect CNF theory
input, instead general PC theory. input satisfiable theory, return model
witness answer.

3. Model Generation Grounding
Model generation problem computing model logic theory , usually context
given finite domain, typically Herbrand Universe. model generator allows decide
satisfiability theory context fixed domain. useful, e.g., context
lightweight verification (Jackson, 2006). Beyond determining satisfiability, broad class
problems answers naturally given models declarative domain theory.
example, model theory specifying scheduling domain typically contains (correct)
schedule. Thus, model generator applied theory solve scheduling problem
domain.1 idea model generation declarative problem solving paradigm
pioneered area ASP (Marek & Truszczynski, 1999; Niemela, 1999). area, answers
problem given models ASP theory.
mentioned introduction, many practical model generation problems contain additional
data besides input theory finite domain. data implicit input theory.
1. set problems kind, see, e.g., benchmarks ASP-competition (http://dtai.cs.kuleuven.
be/events/ASP-competition).

227

fiWittocx, Marien, & Denecker

example, ASP problems split two parts: non-ground theory list ground facts.
latter part essentially represents given data. contexts (Mitchell & Ternovska, 2005;
Torlak & Jackson, 2007; Wittocx et al., 2008d), data given (partial) structure interpreting
part vocabulary input theory. paper assume without loss generality
data represented structure. practice, often case preprocessing,
e.g., materializing view database, needs done data format (see also
Section 5.3.2).
3.1 Model Expansion Search Problem
Model generation input theory input structure called model expansion. Model expansion logic L, denoted MX(L), defined follows.
Definition 1. Let L-theory vocabulary , subvocabulary finite
-structure. model expansion search problem input hT, problem computing
-structure |= | = .
vocabulary called input vocabulary problem, vocabulary \ expansion
vocabulary. called input structure. denote |=I solution
model expansion search problem input hT, i. Similarly, formula denote
|=I expands satisfies .
Observe = , model expansion reduces model checking, = h, i, reduces
model generation given finite size. Also, theory vocabulary
containing function symbols arity greater zero, Herbrand model generation
simulated model expansion. Indeed, let = h, F i, structure Herbrand
universe C = C every constant C F .
illustrate model expansion two examples. examples paper, often use
many-sorted FO, since leads concise readable sentences. many-sorted FO,
domain interpretation partitioned sorts (or types), variable associated sort,
n-ary predicate symbol n-tuple associated sorts n-ary function symbol
associated (n + 1)-tuple sorts. interpretation variable x associated sort
s, xI sI , sI denotes set domain elements sort s. Similarly, P/n
associated sorts (s1 , . . . , sn ), P sI1 sIn , F/n associated sorts (s1 , . . . , sn+1 ),
F : sI1 sIn sIn+1 . often denote P P (s1 , . . . , sn ) F F (s1 , . . . , sn ) : sn+1
indicate associated sorts.
Example 2 (Graph Colouring). graph colouring problem problem colouring given
graph given set colours adjacent vertices different colours. express
problem MX(FO), let V tx Col sorts let = h{Edge(V tx, V tx)}, i. sort Col
denotes given set colours, given graph represented V tx Edge. Let
vocabulary hP , {Colour(V tx) : Col}i theory consists sentence
v1 v2 (Edge(v1 , v2 ) Colour(v1 ) 6= Colour(v2 )).
model expansion input theory input vocabulary expresses graph colouring
problem. Indeed, |=I , ColourM proper colouring graph represented .
Example 3 (SAT). represent SAT problem MX(FO), let vocabulary containing
two sorts Atom Clause, representing atoms clause input CNF theory,
two predicates P osIn(Atom, Clause) N egIn(Atom, Clause), represent positive,
respectively negative, occurrences atoms clauses. theory given
c ((P osIn(a, c) rue(a)) (N egIn(a, c) rue(a)))

228

fiGrounding FO FO(ID) Bounds

= hP {T rue(Atom)}, expresses SAT problem: |=I , propositional
structure represented rueM model CNF theory represented . Indeed, theory
forces every clause contains least one true literal.
shown Mitchell Ternovska (2005), follows Fagins (1974) theorem model
expansion FO captures NP, following sense:
fixed problem deciding whether exists model expanding
input structure NP.
Vice versa, NP decision problem X class finite -structures
vocabulary first-order -theory model expansion input theory
expresses X, i.e., belongs X iff exists -structure |=I .
result proves NP problem X expressed MX(FO) problem, hence
shows broad applicability MX(FO) solvers solve NP problems.
illustrated examples above, intention theory intuitive representation problem X. NP problems represented natural manner MX(FO).
instance, problem deciding whether graph connected expressed MX(FO),
requires non-trivial encoding fixpoint operator FO. Model expansion richer
logics FO better suited problems. Section 5 consider MX FO(ID),
extension FO inductive definitions.
3.2 Reducing MX(FO) SAT
rest paper, let theory vocabulary , subvocabulary
finite -structure domain D.
Since every FO theory , deciding whether model expanding NP,
problem reduced SAT problem Tprop polynomial time. However, want find
models expanding using SAT solver, need method translate models Tprop
models . Moreover, interested finding models expanding , oneto-one correspondence models models Tprop needed. paper
focus reductions preserve models, setting ASP paradigm (Marek &
Truszczynski, 1999; Niemela, 1999).
Let vocabulary Tprop . one-to-one correspondence models
expanding models Tprop , possible represent -structures expanding
-structures. natural way accomplish choosing contains
symbol Pd every P/n P Dn , symbol Fd,d0 every F/n F
(d, d0 ) Dn+1 . -structure making Pd , respectively Fd,d0 true corresponds structure
P , respectively F (d) = d0 . manner, every -structure expanding
corresponding -structure. Vice versa, every -structure satisfying requirement
every function symbol F/n Dn , exactly one d0 Fd,d0 true
A, corresponds -structure domains . is, one-to-one
correspondence -structures satisfying every function symbol F/n Dn
formula


!
_
^
^

Fd,d0
(15)
Fd,d0 Fd,d0
d0

d01

d02 D\d01

1

2

-structures domain D.
Denote dom(I ) vocabulary extended new constant symbol every D.
call new constants domain constants. Abusing notation, denote domain
elements corresponding domain constants d. formula [x] tuple

229

fiWittocx, Marien, & Denecker

domain constants, call [x/d] instance . -interpretation expanding
formula containing domain constants, denote |= expansion dom(I )
defined interpreting every domain constant corresponding domain element, satisfies .
Definition 2. Two formulas 1 2 dom(I ) -equivalent |=I 1 iff |=I 2 ,
every -interpretation .
following straightforward results -equivalence.
Lemma 3.
1. Two logically equivalent formulas -equivalent.
V
2. dD [x/d] -equivalent x [x].
W
3. dD [x/d] -equivalent x [x].
4. 0 0 -equivalent respectively , 0 , 0 0 , 0 0 , x 0
x 0 -equivalent respectively , , , x x .
5. subformula -equivalent 0 , result replacing 0
-equivalent .
formula ground normal form (GNF) contains quantifiers atomic
subformulas form P (d1 , . . . , dn ), F (d1 , . . . , dn ) = d1 = d2 , d1 , . . . , dn ,
domain constants. theory GNF sentences GNF. GNF theory essentially
propositional: replacing GNF theory every atom P (d) Pd , F (d) = d0 Fd,d0 , di = dj
> if, respectively, = j 6= j, adding formula (15) every function symbol F/n
Dn , obtain propositional theory Tprop models Tprop correspond.
Also note similarity GNF TNF theories.
Definition 4. grounding respect GNF theory Tg dom(I )
Tg -equivalent. Tg called reduced contain symbols .
3.2.1 Grounding Algorithms
rest section, assume theory TNF. explained Section 2.2,
make assumption without loss generality. introduce, reference, grounding
respect obtained naive grounding algorithm mentioned introduction.
call grounding full grounding define formally induction.
Definition 5. full grounding Grfull (, ) TNF sentence respect defined



literal





Gr
(
)

Gr
(
)
equal 1 2
full
2
full 1
Grfull () = Grfull (1 ) Grfull (2 ) equal 1 2
(16)

V


equal x [x]

dD Grfull ([x/d])


W
Gr
([x/d])
equal x [x]
full
dD
full grounding respect theory consisting full groundings
sentences respect .
denote full grounding Grfull (T, ), Grfull (T ) clear context.
follows directly Lemma 3 Grfull (T, ) indeed grounding respect .
size full grounding exponential maximal nesting depth quantifiers sentences
, polynomial domain size .

230

fiGrounding FO FO(ID) Bounds

inductive definition like (16) evaluated top-down bottom-up way. approaches applied current grounders. one hand, grounders go top-down
syntax trees sentences . subformula form x [x], respectively x [x] reached, grounding [x/d] constructed every domain constant d,
replaced conjunction, respectively disjunction, groundings.
grounder dlv system (Perri et al., 2007) grounders gringo (Gebser et al., 2007)
GidL (Wittocx, Marien, & Denecker, 2008b) take approach.
grounders go bottom-up syntax trees. subformula [x] table
computed consisting tuples corresponding groundings [x/d]. tables computed
first atomic formulas subsequently compound formulas. example, let [x, y, z]
formula [x, y] [y, z] assume tables computed.
table computed taking natural join tables value y,
constructing grounding [x/dx , y/dy , z/dz ] (possibly simplified) conjunction
groundings [x/dx , y/dy ] [y/dy , z/dz ]. Examples grounders bottom-up approach
lparse (Syrjanen, 2000; Syrjanen, 2009), kodkod (Torlak & Jackson, 2007) mxg (Mitchell
et al., 2006).
obtain reduced grounding respect one could first construct full grounding
replace every subformula dom(I ) > |= otherwise.
result simplified recursively replacing , > , etc. resulting
grounding one computed current grounding algorithms often lot smaller
full grounding. denote Grred (T, ), Grred (T ) clear context.
Smart grounding algorithms use approach outlined above, try avoid creating
full grounding substituting ground formulas input vocabulary soon possible.
example, grounder top-down approach constructs grounding x [x], grounding
instances [x/d] one one making conjunction. process, instances
[x/d] detected certainly true omitted. soon instance [x/d] detected
certainly false, returned grounding x [x].
grounder using bottom-up approach reduce size tables computes
storing tuples default value, e.g., >, corresponding grounding. particular,
[x] formula , stores tuples 6|= [x/d]. reducing size
tables way, reduced grounding obtained much efficiently.

4. Grounding Bounds
section present method reducing grounding size. mentioned introduction,
based computing bounds subformulas input theory . bound subformula
[x] formula input vocabulary . describes set tuples [x/d]
certainly true (false) every model expanding . larger set described
bound, precise bound is. Observe fact bounds formulas means
evaluated using given structure .
Section 4.1, formally define bounds. indicate bounds inserted
obtain new theory 0 . reduced grounding 0 often lot smaller reduced
grounding . precise inserted bounds are, smaller grounding 0 becomes.
However, see 0 general weaker additional axioms
added 0 obtain equivalence . additional axioms need grounded well
that, careful, total size grounded theory decrease all.
Section 4.3, search sufficient conditions bounds guarantee smaller grounding.
Section 4.4, show derive bounds. method works two stages. First, bounds
subformulas computed using any-time algorithm. longer algorithm runs,
precise bounds derived. Often, bounds derived stage lead smaller
groundings, reason explained previous paragraph. second stage, bounds
231

fiWittocx, Marien, & Denecker

satisfy conditions guarantee smaller groundings derived ones computed
first stage.
4.1 Bounds
distinguish two kinds bounds.
Definition 6. certainly true bound (ct-bound) respect formula [x]
formula ct [y] x |= x (ct [y] [x]). Vice versa, certainly false
bound (cf-bound) respect [x] formula cf [z] z x
|= x (cf [z] [x]).
mention clear context.
Intuitively, ct-bound ct [x] provides every structure lower bound set
tuples true every model expanding . Indeed, every |=I
{x | ct }I {x | }M . Vice versa, cf-bound cf provides lower bound set tuples
false: {x | cf }I {x | }M every |=I . Observe negation
ct-bound, respectively cf-bound, gives upper bound set tuples false,
respectively true, least one model expanding .
Example 4 (Example 1 ctd.). Let 1 subformula Sub(x, y) Sub(x, z) T1 .
Edge(x, y) Edge(x, z) cf-bound 1 respect T1 1 . Indeed, one derive (1) T1 entails
xyz ((Edge(x, y) Edge(x, z)) 1 ) .
Observe > ct-bound every sentence . Indeed, every sentence , |=
therefore |= > . Also, ct-bound well cf-bound every formula. call
trivial bound. Intuitively, trivial bound contains information all: {x | }I =
every x. According following definition, least precise bound.
Definition 7. Let [y] [z] two (ct- cf-) bounds [x]. say [y] precise
[z] x ([z] [y]) valid.
precise bound [x] , provides larger lower bound {x | }I
{x | }I every .
Definition 8. c-map C mapping subformulas tuples
(C ct (), C cf ()), C ct () C cf () respectively ct- cf-bound
respect .
notion precision pointwise extends c-maps. is, C1 C2 two c-maps ,
C1 precise C2 iff every subformula , C1ct () precise C2ct ()
C1cf () precise C2cf ().
Let model C c-map . definition ct- cf-bounds
follows immediately every subformula [x] , |= x (C ct () ) |=
x (C cf () ) hold. say structure satisfies C precisely property.
Definition 9. Let C c-map . theory C defined
C ={x (C ct () ) | [x] subformula }
{x (C cf () ) | [x] subformula }.
structure satisfies C |= C.

232

fiGrounding FO FO(ID) Bounds

Clearly, C c-map |=I , |= C. call two formulas [x]
[x] C-equivalent {x | }I = {x | }I structure satisfies C. Equivalently,
C-equivalent C |= x ( ).
c-map inconsistent formula certainly true false tuple, according
c-map:
Definition 10. c-map C inconsistent x (C ct () C cf ()) valid
subformula [x] . c-map C -inconsistent |= x (C ct () C cf ()) subformula
.
Proposition 11. exists -inconsistent c-map , 6|=I every
. exists inconsistent c-map , 6|=I every .
Proof. Let C -inconsistent c-map [x] subformula |=
x (C ct () C cf ()). exists tuple domain elements [x/d] |= C ct ()
[x/d] |= C cf (). Assume towards contradiction |=I . |= C, hence
[x/d] |= C ct () [x/d] |= C cf () . Since | = , follows [x/d] |=
[x/d] |= . contradiction.
prove second statement, let C inconsistent c-map . C also
-inconsistent c-map every -structure . such, model expanding
.
4.2 C-Transformation
rest section, fix c-map C . show insert bounds C
sentences . insertion based following lemma.
Lemma 12. Let [x] subformula . C-equivalent C ct () C cf ().
Proof. prove C |= x ( ( C ct ())) C |= x ( ( C cf ())).
former immediately follows fact C |= x (C ct () ), latter fact
C |= x (C cf () ) .
corollary lemma 12 following lemma.
Lemma 13. Let sentence subformula . 0 result replacing
subformula C ct (), C cf () ( C cf ()) C ct (), |= iff
|= 0 every satisfies C.
Observe C ct () = C cf () = , C ct () C cf () logically equivalent
. Hence, case sentence 0 Lemma 13 essentially sentence . Intuitively,
adding trivial bounds sentence change sentence all.
bounds assigned C inserted applying transformation Lemma 13
subformulas . result called c-transformation , formally defined
follows.
Definition 14 (c-transformation). c-transformation subformula respect C,
denoted Chi, formula (0 C cf ()) C ct () 0 defined


atom





Chi
equal



Chi Chi equal
0 :=

Chi Chi equal




x Chi
equal x



x Chi
equal x
233

fiWittocx, Marien, & Denecker

c-transformation ChT respect C consists c-transformation respect C
every sentence .
Lemma 13, derive following.
Lemma 15. ChT C-equivalent.
general ChT logically equivalent. ChT may models satisfy C,
therefore cannot models . example, let C c-map assigns (>, ) every
sentence (, ) every subformula . sentences ChT form
> hence ChT simplifies >, general equivalent . obtain ChT
theory equivalent , must add C.
Theorem 16. C c-map C theory defined Definition 9, ChT C
equivalent .
Proof. Let model . |= C, Lemma 13, |= ChT C.
hand, |= ChT C, Lemma 13, |= .
Corollary 17. C c-map , ChT C -equivalent structure .
4.3 Atom-Based Atom-Equal C-Maps
Corollary 17 implies compute grounding respect first computing
c-map C grounding ChT C. approach beneficial reduced
grounding ChT C smaller reduced grounding , constructed least
fast. general conditions satisfied. precise c-map C is, smaller
reduced grounding ChT becomes, larger reduced grounding C is:
Proposition 18. C1 precise C2 , Grred (C1 hT i) smaller Grred (C2 hT i).
Moreover, every subformula occurs Grred (C1 hT i) also occurs Grred (C2 hT i).
Proof. (Sketch) Let [x] subformula tuple domain elements. suffices
show C2 hi[x/d] replaced >, respectively , grounding, also case
C1 hi[x/d]. proven induction. base case, assume atom.
C2 hi[x/d] formula (( C2cf ()) C2ct ())[x/d]. formula replaced >
grounding, three possibilities: formula , [x/d] |= C2ct () [x/d] |= C2cf ().
Since C1 precise C2 , [x/d] |= C2ct () implies [x/d] |= C1ct () [x/d] |= C2cf ()
implies [x/d] |= C1cf (). conclude C2 hi[x/d] replaced > grounding,
also case C1 hi[x/d]. inductive case similar.
Proposition 19. C1 precise C2 , Grred (C1 ) larger Grred (C2 ).
Proof. (Sketch) Every sentence C1 form x (C1ct () ) x (C1cf () ).
number instances C1ct () reduced grounding C1 equal number
[x/d] |= C1ct (). Similarly C1cf () . Since C2 less precise C1 , number
instances Grred (C2 ) corresponding sentences x (C2ct () ) x (C2cf () )
smaller.
c-map useful reduce grounding size therefore precise, order
avoid large theory Grred (C), still precise enough decrease size Grred (ChT i).
section, present sufficient conditions ensure properties. first define class
c-maps avoid blow-up Grred (C) ensuring C replaced equivalent, smaller
easy-to-find theory C . such, Grred (C) replaced smaller theory Grred (C ).
class present, C subset C, namely set sentences C stem atomic
subformulas :
234

fiGrounding FO FO(ID) Bounds

Definition 20. Define theory C
C ={x (C ct () ) | [x] atomic subformula }
{x (C cf () ) | [x] atomic subformula }.
call C atom-based C |= C.
Example 5 (Example 1 ctd.). Let C2 c-map assigns (, (Edge(x, y) Edge(x, z)))
Sub(x, y) Sub(x, z) (, ) every subformula. C2 atom-based, since (C 2 )A
equivalent >, C 2 contains sentence
xyz ((Edge(x, y) Edge(x, z)) (Sub(x, y) Sub(x, z))).

(17)

Let C3 c-map assigns (, Edge(x, y)) Sub(x, y), (, Edge(x, z)) Sub(x, z)
corresponds C2 subformulas T1 . C3 atom-based. Indeed, (C 3 )A consists
(equivalent) sentences
xy (Edge(x, y) Sub(x, y))

(18)

xz (Edge(x, z) Sub(x, z))

(19)

C 3 consists sentences (17), (18) (19). (18) (19) imply (17), therefore,
(C 3 )A |= C 3 .
Clearly, c-map assigning (, ) every non-atomic subformula example atombased c-map. such, c-map transformed atom-based one replacing every
bound assigned non-atomic subformula . next section, show compute
interesting atom-based c-maps.
Observe Grred (C ) contains unit clauses. Combining definition atom-based
c-map Theorem 16 immediately gives following result.
Proposition 21. Let C atom-based c-map . ChT iC equivalent,
hence -equivalent every -structure .
obtain small groundings using bounds, important information bounds
exploited wherever possible. particular, ct- cf-bound assigned atom P (x),
similar bound assigned every atom form P (y). call c-map atom-equal
exactly property atomic subformulas . is, C atom-equal assigns
essentially bounds atomic subformulas predicate function symbol:
Definition 22. c-map C TNF theory atom-equal every predicate symbol
cf
P/n exist formulas ct
P [x1 , . . . , xn ] P [x1 , . . . , xn ] every atom P (y1 , . . . , yn )
ct
cf
occurs , C (P (y1 , . . . , yn )) equal ct
P [x1 /y1 , . . . , xn /yn ] C (P (y1 , . . . , yn )) equal
cf
P [x1 /y1 , . . . , xn /yn ], similarly function symbols.
Note predicate function symbol occurs theory , every
c-map atom-equal.
Example 6 (Example 1 ctd.). Let T2 theory obtained adding sentence w Sub(w, w)
T1 . predicate occurs T2 predicate Sub. Let C4 c-map
T2 assigns following bounds atomic subformulas T2 Sub: (, Edge(u, v))
Sub(u, v), (, Edge(x, y)) Sub(x, y), (, Edge(x, z)) Sub(x, z) (, Edge(w, w))
cf
Sub(w, w). C4 atom-equal. Indeed, take ct
Sub = Sub = Edge(x1 , x2 ),
conditions Definition 22 satisfied predicate Sub.

235

fiWittocx, Marien, & Denecker

atom-equal c-map C, C general contains many equivalent sentences. example,
c-map C4 Example 6, (C 4 )A contains amongst others, equivalent sentences (18)
(19). also contains w Edge(w, w) Sub(w, w), implied (18). result,
C atom-equal c-map, grounding C naive way yields grounding contains several
formulas once. following proposition, assume redundancy removed.
words, assume grounding algorithm C never adds GNF formula
grounding. accomplished grounding instead C sentences
cfb
ctb
cfb
x (ctb
P P (x)) x (P P (x)) every predicate symbol P , P P
Definition 22, similarly function symbols.
Proposition 23. Let C atom-based, atom-equal c-map TNF theory . model
expanding , Grred (ChT C ) large Grred (T ).
proof, denote size theory Tg |Tg |.
Proof. outline proof follows. First, show every subformula occurs
Grred (ChT i), occurs Grred (T ). Then, prove atom occurring Grred (C ) occurs
Grred (ChT i). Next, show every atom occurring Grred (C ) occurs least
Grred (T ). Since assumed Grred (C ) contain formula once, follows
|Grred (ChT i)| |Grred (T )| |Grred (C )|, concludes proof.
directly apply Proposition 18 show every subformula Grred (ChT i) occurs
Grred (T ): C 0 trivial c-map, Grred (T ) equal Grred (C 0 hT i), clearly C
precise C 0 .
show none atoms occurring Grred (C ) occur Grred (ChT i). Let P (d)
atom occurring Grred (ChT i). atomic subformula P (x)
6 {x | C ct (P (x))}I 6 {x | C cf (P (x))}I . C atom-equal, follows
subformula P (y) occurring , neither {y | C ct (P (y))}I {y | C cf (P (y))}I . Therefore
P (d) occur Grred (C ).
remains show every atom occurs Grred (C ) also occurs Grred (T ). Let
model Grred (T ). model exists assumed model expanding . Let
P (d) atom occur Grred (T ). P predicate input vocabulary,
P (d) occur Grred (C ) either. hand, P expansion vocabulary,
structure 0 obtained swapping truth value P (d) also model Grred (T ).
Since Grred (ChT C ) -equivalent Grred (T ) P 6 , follows |= Grred (C )
0 |= Grred (C ). Grred (C ) contains unit clauses, conclude P (d)
occur Grred (C ).
following algorithm create small grounding respect : first
compute atom-based, atom-equal c-map C (We present algorithm
Section 4.4). C -inconsistent, output stop. Else, output Grred (ChT C ).
follows Propositions 11 21 result algorithm indeed grounding
respect . Observe first step algorithm independent . one
solve several model expansion problems fixed input theory input vocabulary ,
varying , suffices compute C once.
perform last step algorithm, one could apply off-the-shelf grounder input
ChT C .
4.4 Computing Bounds
present algorithm compute (non-trivial) c-map C. based work
approximate reasoning FO (Wittocx, Marien, & Denecker, 2008a). general resulting cmap neither atom-based atom-equal, atom-based, atom-equal c-map derived
it.
236

fiGrounding FO FO(ID) Bounds

4.4.1 Refining C-Maps
Constructing non-trivial c-map done starting least precise c-map, i.e., one
assigns (, ) every subformula , gradually refining it. refinement step
consists three operations:
1. Choose subformula .
2. Compute current c-map C new ct-bound rct cf-bound rcf . Below,
elaborate step: present six different ways obtain new ct- cf-bounds, called
refinement bounds, C. sentences represented syntax trees,
node corresponds subformula . Bottom-up refinement bounds bounds
node computed considering bounds assigned C children. Vice versa, top-down
refinement bounds computed looking parents siblings node. Axiom
refinement bounds bounds roots, i.e., sentences , input, copy
functional refinement bounds practice mainly bounds atomic subformulas .
3. Substitute C ct () C ct () rct , respectively C cf () C cf () rcf .
According following lemma, refinement step yields new bound precise
one assigned C.
Lemma 24. two ct-bounds respect , also ct-bound
. Moreover, precise precise . holds cf-bounds.
Proof. Let two ct-bounds [x]. definition, |= x ( ) |= x ( ).
Therefore |= x (( ) ), proves ct-bound . Since |= ( )
|= ( ), precise bound . proof cf-bounds
similar.
conclude repeatedly applying refinement steps leads precise c-map.
resulting algorithm any-time algorithm. Section 6 discuss stop criterion
algorithm. also give examples reach fixpoint, examples
cannot.
present different ways obtain refinement bounds.
Input Refinement Let [x] formula input vocabulary . Since |= x ([x] [x])
|= x ([x] [x]), clear [x] ct-bound [x] cf-bound [x].
call input refinement ct- cf-bounds.
Axiom Refinement sentence , > axiom refinement ct-bound .
refinement bound states sentence true every model .
Bottom-Up Refinement compound subformula , depending structure, Table 1
gives bottom-up refinement ct-bound rct cf-bound rcf respect C. rather
straightforward obtain formulas. instance, formula bottom-right table
indicates formula , certainly false tuples
certainly false. Or, formally, |= C cf () |= C cf () ,
|= C cf () C cf () ( ).
Top-Down Refinement case top-down refinements, bounds formula used
construct refinement bounds one direct subformulas (i.e., one children
syntax tree). top-down refinement ct-bounds rct cf-bounds rcf given
Table 2. table, tuple denotes free variables occur x0
denotes new variable. illustrate refinement bounds. explanation

237

fiWittocx, Marien, & Denecker




rct

rcf

cf

ct

C ()

C ()

ct

x

x C ()

x C cf ()

x

x C ct ()

x C cf ()



C ct () C ct ()

C cf () C cf ()

ct



ct

C cf () C cf ()

C () C ()

Table 1: Bottom-up refinement bounds



rct


x

C cf ()
C ct ()

x

C ct () x0 (x 6= x0 C cf ()[x/x0 ])



C ct ()



(C ct () C cf ())



rcf



C ct ()

x

C () x (x 6= x0 C ct ()[x/x0 ])

x

C cf ()



(C cf () C ct ())



C cf ()

0

cf

Table 2: Top-down refinement bounds

238

fiGrounding FO FO(ID) Bounds

bounds certain sense precise ones obtained, refer work
approximate reasoning (Wittocx et al., 2008a).
Let formula x P (x, y). Recall intuitively, ct-bound C ct () indicates
domain elements d, x P (x, d) certainly true. arbitrary d0 D, P (d0 , d)
must true. Hence, C ct () ct-bound . Indeed, since x occur free C ct (),
|= xy (C ct () P (x, y)) follows |= (C ct () x P (x, y)).
let formula P (x) Q(x, y). know P (d1 ) Q(d1 , d2 ) certainly false,
Q(d1 , d2 ) certainly true, P (d1 ) must certainly false. Hence, C cf () C ct ()
cf-bound P (x).
Let formula x P (x, y) assume x P (x, dy ) certainly true, d0x ,
except dx , P (d0x , dy ) certainly false. conclude P (dx , dy ) must true.
precisely expressed formula C ct () x0 (x 6= x0 C cf ()[x/x0 ]).
Functional Refinement [x, y] formula F (x) = y, functional refinement bounds
take account F function. functional refinement ct-bound rct cf-bound rcf
given by:
rct := 0 (y 0 6= C cf ()[y/y 0 ])
rcf := 0 (C ct ()[y/y 0 ] 6= 0 )
0 new variable. Informally, first formulas indicates F (x) certainly
equal every 0 6= y, F (x) certainly equal 0 . second one says F (x)
certainly equal F (x) certainly equal 0 0 6= y.
Copy Refinement Let [x1 , . . . , xn ] [y1 , . . . , ym ] two formulas [x1 /z, . . . , xn /z]
[y1 /z, . . . , ym /z] same, modulo renaming non-free variables. is,
exactly syntax tree, variables may differ. Denote E(, ) set
equalities xi = yj occurrence
V xi , yj occurs corresponding position
ct
. formula y1 . . . yV
(C
()

E(, )) copy refinement ct-bound

formula y1 . . . ym (C cf () E(, )) copy refinement cf-bound . also say
copy-refinement bounds .
Example 7. Let formula P (x1 , x1 ) Q(x2 , s) formula P (y1 , y2 ) Q(y2 , t).
[x1 /z, x2 /z] equal [y1 /z, y2 /z] modulo renaming t, formulas satisfy
requirement copy refinement. set E(, ) given {x1 = y1 , x1 = y2 , x2 = y2 }
hence,
y1 y2 (C ct () x1 = y1 x1 = y2 x2 = y2 )
copy refinement ct-bound . Observe C ct () contain bounded occurrences
x1 x2 , formula equivalent simpler formula C ct ()[y1 /x1 , y2 /x1 ] x1 = x2 .
One-Step Refinements call rct (rcf ) refinement ct-bound (cf-bound) respect
C input, axiom, bottom-up, top-down, functional copy refinement ct-bound (cf-bound)
respect C. Lemma 25 states refinement ct-bound (cf-bound) indeed ct-bound
(cf-bound).
Lemma 25. rct refinement ct-bound respect C, ct-bound .
Similarly cf-bounds.
Proof. proof consists simple analysis cases. proved cases
introduced input, bottom-up top-down refinement. proof cases similar.
Definition 26. Let C c-map , subformula , rct refinement ct-bound
rcf refinement cf-bound respect C. assignment C r corresponds C, except
assigns C r () = (C ct () rct , C cf ()) C r () = (C ct (), C cf () rcf ) called one-step
refinement C.
239

fiWittocx, Marien, & Denecker

Lemma 24 25 obtain following result.
Proposition 27. Every one-step refinement c-map c-map .
already mentioned beginning section, one compute c-map
first assigning (, ) every subformula repeatedly applying one-step refinements.
call nondeterministic any-time algorithm refinement algorithm.
Example 8 (Example 1 ctd.). Figure 1 shows possible run refinement algorithm input
. Here, sentences T1 represented syntax trees. numbers indicate
step bounds refined. trivial bounds shown.
step (1), ct-bound first sentence replaced > using axiom refinement.
course, new bound simplified >. following steps, figure shows simplified
bounds. step (2) (3) bounds subformula Edge(u, v) refined input refinement.
Then, top-down refinement used set ct-bound Sub(u, v) Edge(u, v) >. Next,
top-down refinement, Edge(u, v) becomes ct-bound Sub(u, v) cf-bound
Sub(u, v).
similar way, cf-bound 6= z derived subformula Sub(x, y) Sub(x, z) (step (7)
(12)). Then, copy refinement, cf-bounds Sub(x, y) becomes uv (Edge(u, v) u =
x v = y), wich simplifies Edge(x, y). Likewise, simplification, Edge(x, z) copy
refinement cf-bound Sub(x, z). Finally, two steps bottom-up refinement used set
ct-bound (Sub(x, y) Sub(x, z)) 6= z Edge(x, y) Edge(x, z).
step, fixpoint reached: every one-step refinement performed yields
bound logically equivalent one tries refine.
Example 9. Consider simplified planning problem, actions scheduled
action ap precondition action a0 , ap performed earlier time point
a0 . problem described theory T3 , consisting sentence
a0 ap t0 P rec(ap , a0 ) Do(a0 , t0 ) (tp tp < t0 Do(ap , tp )).
sentence, follows chain actions must executed a0 executed,
a0 cannot executed ith timepoint. Therefore, > 0, following formula
cf-bound Do(a0 , t0 ) 2 = {P rec, <}:
a1 ai (P rec(a1 , a0 ) . . . P rec(ai , ai1 )) t1 ti (t1 < t0 . . . ti < ti1 ).
Denote formula . n > 0 sufficient number steps, refinement algorithm
derive n := 1 . . . n cf-bound Do(a0 , t0 ). Clearly, n1 6= n2 , n1
logically equivalent n2 . indicates refinement algorithm reach fixpoint
input T3 2 .
shown examples, several issues concerning practical implementation
refinement algorithm.
1. Due non-deterministic nature algorithm, heuristic needed choose
bounds refine kind refinement apply. reasonable choice first apply
possible axiom input refinements. Then, top-down refinement formula applied
bound parent one siblings syntax tree recently refined.
Similarly, bottom-up refinement applied bound one children refined.
strategy used Example 1.
2. bounds simplified regular time points, i.e., replaced equivalent smaller formulas. bounds simplified, grow size, rapidly
leading formulas unwieldy size. simplification algorithm discussed Section 6.
240

fiGrounding FO FO(ID) Bounds

u, v





(5) ct: Edge(u, v)

(1) ct: >

(4) ct: >

Edge(u, v)

(2) ct: Edge(u, v)
(3) cf: Edge(u, v)

(6) cf: Edge(u, v)

Sub(u, v)

x, y, z



(11) ct: 6= z



(7) ct: >

(10) ct: >

y=z

(16) ct: 6= z
Edge(x, y) Edge(x, z)

(8) ct: = z
(9) cf: 6= z

(12) cf: 6= z



(15) cf: 6= z
Edge(x, y) Edge(x, z)
(13) cf: Edge(x, y)

Sub(x, y)

Sub(x, z)

(14) cf: Edge(x, z)

Figure 1: Refining c-map

241

fiWittocx, Marien, & Denecker

3. able detect fixpoint reached, one needs find two bounds
equivalent. general undecidable. detect fixpoint least cases, one
could use FO theorem prover (and restrict running time).
case fixpoint cannot reached detected, another stop criterion needed. example,
one could restrict number one-step refinements, total time refinement algorithm use. Another stop criterion, simple fixpoint check discussed Section 6.
4.4.2 Extracting Atom-Based Atom-Equal C-Map
c-maps obtained refinement algorithm general neither atom-based atom-equal.
derive arbitrary c-map C atom-equal c-map least precise C, first
collect predicate P bounds assigned occurrences P theory.
disjunction bounds assigned new bound occurrence P . bounds
assigned atoms P essentially same, atom-equal c-map.
present method formally:
Definition 28. Let C c-map TNF theory P/n predicate. Let P (x11 , . . . , x1n ),
. . . , P (xm1 , . . . , xmn ) occurrences P let y1 , . . . , yn n new variables. Denote
ict , respectively icf , formulas
x0i1 x0in (C ct (P (xi1 , . . . , xin ))[xi1 /x0i1 , . . . , xin /x0in ] y1 = x0i1 . . . yn = x0in )

x0i1 x0in (C cf (P (xi1 , . . . , xin ))[xi1 /x0i1 , . . . , xin /x0in ] y1 = x0i1 . . . yn = x0in ),
variables x0ij new variables. ct-copy closure P (xk1 , . . . , xkn ) respect
W
C disjunction 1im ict [y1 /xk1 , . . . , yn /xkn ]. cf-copy closure P (xk1 , . . . , xkn )
W
formula 1in icf [y1 /xk1 , . . . , yn /xkn ]. copy-closure atoms form F (x) = defined
similarly.
denote ct-copy closure atom copyCct (), cf-copy closure copyCcf ().
Definition 29. copy-closure C c-map assigns (copyCct (), copyCcf ()) every
atomic subformula , corresponds C subformulas.
Example 10. Let T4 theory consisting sentences x (P (x) R(x)) (Q(y)
R(y)) let C5 c-map 3 = {P, R} assigns (P (x), ) R(x) (Q(y), ) R(y).
copy-closure C5 assigns
((x0 (P (x0 ) x0 = x)) (x0 (Q(x0 ) x0 = x)), (x0 ( x0 = x)) (x0 ( x0 = x)))
R(x). bounds simplify (P (x) Q(x), ). Likewise, copy-closure C5 assigns
R(y) bounds simplify (P (y) Q(y), ).
Proposition 30. copy-closure c-map atom-equal c-map.
Proof. follows immediately definition atom-equal c-map
W since everyWpredicate
symbol P (or function symbol F ), bounds, namely formulas 1in ict 1in icf
mentioned definition 28, assigned every atom P (respectively F ).
Recall c-map C atom-based C implied C , i.e., sentences C stem
bounds atomic subformulas . method derive atom-based c-map arbitrary
c-map based following observation. Let C c-map let [x]
subformula . C ct () formula C ct () C ct (), i.e., bottom-up refinement
ct-bound respect C, |= x (C ct () ) implied |= x (C ct () )
|= x (C ct () ). easy check property holds bottom-up
refinement bounds:
242

fiGrounding FO FO(ID) Bounds

Lemma 31. Let C c-map [x] subformula , let rct rcf
bottom-up refinement bounds respect C. set direct subformulas , i.e.,
children syntax tree, 0 theory given
0 := {y C ct () | [y] S} {y C cf () | [y] S},
0 |= x rct 0 |= x rcf .
Definition 32. c-map C called bottom-up c-map every non-atomic subformula
, C ct () bottom-up ct-refinement bound respect C, C cf ()
bottom-up cf-refinement bound respect C.
next proposition follows directly Lemma 31.
Proposition 33. bottom-up c-map C atom-based.
Observe bottom-up c-map C completely determined bounds assigns
atomic subformulas . Hence, given c-map, one derive bottom-up c-map
retaining bounds atomic subformulas computing corresponding bottom-up
c-map. conclude derive atom-based, atom-equal c-map arbitrary c-map
deriving atom-based c-map copy-closure.
Example 11 (Example 1 ctd.). Let C6 fixpoint shown Figure 1. c-map atom-equal
(and equivalent copy-closure). bottom-up c-map derived C6 shown Figure 2.
Observe c-map less precise C6 . instance, cf-bound assigned C6
conjunction Sub(x, y) Sub(x, z) disjunction two bounds, namely bound 6= z, obtained
top-down refinement, bound Edge(x, y) Edge(x, z), obtained bottom-up refinement.
c-map Figure 2, latter bound present.
c-map Figure 2, c-transformation Sub(x, y) Sub(x, z) given
((Sub(x, y) Edge(x, y)) (Sub(x, z) Edge(x, z))) (Edge(x, y) Edge(x, z)).
formula contains repeated constraints Edge(x, y) Edge(x, z) variables x, z.
general bottom-up c-maps produce many repetitions. could easily eliminated
speed grounding process, depends used grounding algorithm ones
best deleted.

5. Inductive Definitions
Although NP problems cast MX(FO) problems, modelling problems using pure
FO extremely complex. practice, modelling often enhanced considerably using
extensions FO constructs inductive definitions, subsorts, aggregates, partial functions
arithmetic. enriched language implemented model generator idp (Wittocx
et al., 2008b; Wittocx & Marien, 2008).2
paper focus grounding extension FO inductive definitions.
well-known arbitrary domains, inductively definable concepts reachability
FO-expressible. finite domains however, encoded (e.g., encoding fixpoint
construction), process tedious leads large theories. section extend
refinement algorithm FO(ID) (Denecker, 2000; Denecker & Ternovska, 2008). language
extends FO construct representing common types inductive definitions: monotone induction non-monotone induction induction well-founded order
iterated inductive definitions. definitions many applications real-life computational problems, e.g., planning problems problems involving reachability dynamic systems
(Denecker & Ternovska, 2008, 2007). time, FO(ID) also integration FO
logic programming.
2. idp downloaded http://dtai.cs.kuleuven.be/krr/software.html

243

fiWittocx, Marien, & Denecker

u, v





ct: Edge(u, v)

ct: >

ct: >

Edge(u, v)

ct: Edge(u, v)
cf: Edge(u, v)

cf: Edge(u, v)

Sub(u, v)

ct: xyz (y = z Edge(x, y) Edge(x, z))

x, y, z



ct: = z Edge(x, y) Edge(x, z)

ct: Edge(x, y) Edge(x, z)



y=z

ct: = z
cf: 6= z

cf: Edge(x, y) Edge(x, z)

cf: Edge(x, y)



Sub(x, y)

Sub(x, z)

cf: Edge(x, z)

Figure 2: bottom-up c-map

244

fiGrounding FO FO(ID) Bounds

5.1 Three-Valued Structures
FO(ID) standard two-valued semantics, three-valued structures used formal
semantics definitions. Indeed, inductive definition defines set describing construct
it. semantics, intermediate stages construction recorded three-valued sets,
representing object whether belongs set not, whether yet
derived. therefore recall basic concepts three-valued logic.
denote truth values true, false unknown respectively t, f u. three-valued
-interpretation consists domain


domain element xI variable x;


function P : Dn {t, f, u} predicate symbol P/n;


function F : Dn function symbol F/n.

P (d) 6= u every tuple domain elements predicate symbol P , two-valued:

corresponds interpretation assigns P iff P (d) = every predicate P
corresponds symbols.
truth order set truth values induced f < u < t, precision order p
induced u <p f u <p t. orders extended three-valued -structures: J
correspond F , define


J iff P (d) P J (d) every P ;


p J iff P (d) p P J (d) every d, P .

Observe two-valued structures maximally precise three-valued structures.

hand, least precise three-valued structure assigns P (d) = u every P .

define truth value I()
formula three-valued interpretation domain
standard Kleene semantics:
(t1 , . . . , tn )) := P I(tI, . . . , tI );
I(P
n
1
1 2 ) := lub {I(
1 ), I(
2 )};
I(
1 2 ) := glb {I
1 , I(
2 )};
I(


I(x
) := lub {I[x/d]()
| D};


I(x
) := glb {I[x/d]()
| D}.
atom form P (d), tuple domain constants, called domain atom.
(d)/v] interpretation assigns
truth value v domain atom P (d), denote I[P
v P (d) corresponds symbols. notation extended sets domain
atoms.
5.2 Inductive Definitions
FO(ID) theory set FO sentences definitions. definition finite set rules
form3
x (P (x) ),
3. Usually, nested terms allowed arguments P , facilitate presentation, allow variables
arguments paper.

245

fiWittocx, Marien, & Denecker

P predicate FO formula. free variables among x. P (x)
called head rule, body. Predicates occur head rule called
defined predicates . set defined predicates denoted Def(). symbols
called open respect . set open symbols denoted Open().
Observe FO(ID) theory appearance FO theory augmented collection
logic programs. illustrated Denecker Ternovska (2008), entails FO(ID)s
definitions used represent mathematical concepts, also sort common
sense knowledge often represented logic programs, (local forms of) closed world
assumption, inheritance, exceptions, defaults, causality, etc.
semantics definitions given well-founded model (Van Gelder, Ross, & Schlipf,
1991). argued Denecker Ternovska (2008), well-founded semantics correctly formalizes
semantics mentioned types inductive definitions mathematics. borrow
presentation semantics Denecker Vennekens (2007).
Definition 34. Let definition three-valued structure. well-founded induction
sequence hJ i0 three-valued structures

1. J0 assigns P J0 (d) = u, P defined predicate corresponds open symbols;

2. limit ordinal , J = lubp {J | < };
3. every ordinal , J+1 relates J one following ways:

(a) J+1 = J [P (d)/t] domain atom P (d) P J (d) = u rule

x (P (x) ) , J [x/d]() = t.

(b) J+1 = J [U/f], U set domain atoms, P (d) U , P J (d) =
u rules x (P (x) ) , J+1 [x/d]() = f.

Intuitively, (a) says domain atom P (d) made true rule P (x)
head body [x/d] already true. hand (b) explains P (d)
made false possibility making corresponding body true, except circular
reasoning. set U , commonly called unfounded set, witness this: making atoms
U false also makes corresponding bodies false.
well-founded induction called terminal cannot extended anymore. limit
terminal well-founded induction last element. Denecker Vennekens (2007) show
terminal well-founded induction limit, corresponds well Open() , denoted wfm (I).
well-founded model
founded model extending I|
three-valued general.
two-valued structure satisfies definition = wfm (I). FO(ID) theory
finite set FO sentences definitions. satisfies satisfies definitions sentences
. definition J |Open() -structure, exists one expansion
J |= . definition called total |Open() -structure J
precisely one expansion J satisfies . Intuitively, total definitions correspond
well-formed definitions: every defined predicate P , define tuple domain elements
whether belongs relation denoted P not. definition total, typically
indicates error. Hence practice, definitions occur MX(FO(ID)) specifications
total. example, case MX(FO(ID)) specifications used second ASPcompetition (Denecker, Vennekens, Bond, Gebser, & Truszczynski, 2009). general, checking
whether definition total undecidable. However, several broad easily recognizable
classes total definitions. example, monotone stratified definitions total.
give examples definitions MX(FO(ID)) problems.

246

fiGrounding FO FO(ID) Bounds

Example 12. Definition 1 defines relation C transitive closure relation R.


xy (T C(x, y) R(x, y)).
1 =
xy (T C(x, y) z (T C(x, z) C(z, y))).
Example 13. cast problem finding Hamiltonian path given graph MX(FO(ID))
problem, let
= h{Edge/2},
= {P {Ham/2, Reached/1}, {Start/0}i.
Predicate Ham represents edges form path Reached vertices
path. constant Start represents first vertex path. Let theory
v1 v2 (Ham(v1 , v2 ) Edge(v1 , v2 )).
v1 v2 v3 (Ham(v1 , v2 ) Ham(v1 , v3 ) v2 = v3 ).
v1 v2 v3 (Ham(v1 , v3 ) Ham(v2 , v3 ) v1 = v2 ).
v Ham(v, Start).
v Reached(v).


v (Reached(v) v = Start).
.
v (Reached(v) w (Reached(w) Ham(w, v))).
model expansion input structure input vocabulary expresses Hamiltonian path
problem: every model |=I , collection edges (v1 , v2 ) HamM forms Hamiltonian
path graph represented EdgeI .
well-known concept use later section completion definition.
completion definition FO theory weaker , defined follows.
Definition 35. completion definition FO theory contains every P Def()
sentence
x (P (x) ((x = 1 1 ) . . . (x = n n ))),
1 (P (y 1 ) 1 ), . . . , n (P (y n ) n ) rules P head.
denote completion Comp(). Clearly, every body rule occurs
Comp(). theory denote Comp(T ) result replacing definitions
completion. following result states completion weaker .
Theorem 36 (Denecker & Ternovska, 2008). |= Comp() |= Comp(T ) every definition
FO(ID) theory .
SAT(ID) problem problem deciding whether given propositional FO(ID) theory
satisfiable. Currently exist three SAT(ID) solvers. IDsat (Pelov & Ternovska, 2005) works
translating SAT(ID) problem equivalent SAT problem calls SAT solver.
MidL (Marien, Wittocx, & Denecker, 2007) MiniSAT(ID) (Marien, Wittocx, Denecker, &
Bruynooghe, 2008) take native approach. Marien (2009) provides details specific form
propositional FO(ID) theories accepted solvers, method transform arbitrary
propositional FO(ID) theories form.
5.3 Grounding Inductive Definitions
Like MX(FO) problems, MX(FO(ID)) problems reduced SAT(ID) problems grounding.
section extend grounding refinement algorithm Section 4 FO(ID). Without
loss generality (Marien, Gilis, & Denecker, 2004), assume none predicates
input vocabulary defined definition , predicate defined one
definition. Moreover, assume every rule body TNF.
247

fiWittocx, Marien, & Denecker

5.3.1 Full Reduced Grounding
Let FO(ID) theory. FO, grounding Tg respect propositional
FO(ID) theory -equivalent . extend notion full reduced grounding
definitions.
Definition 37. full grounding rule x P (x) respect set {P (d)
Grfull ([x/d]) | Dn }, n number variables x. Similarly, reduced grounding
x (P (x) ) set {P (d) Grred ([x/d]) | Dn }. full (reduced) grounding
definition union full (reduced) groundings rules .
full (reduced) grounding FO(ID) theory set full (reduced) groundings
sentences definitions .
5.3.2 Definitions Depending
say definition depends expansion symbols Open() 6 . depend
expansion symbols, interpretation every predicate Def() every model
expanding . Indeed, definition |=I , |Open() completely
determined . Therefore also wfm (M ) depends .
deductive database literature describes several algorithms compute wfm (M ) definition depend expansion symbols. defined definitions
every rule body conjunction atoms. them, Rete algorithm
(Forgy, 1982) semi-naive evaluation technique (Ullman, 1988), easily adapted
handle full FO bodies.
Assume definition depend expansion symbols. Let vocabulary
hP Def(), F -structure | = |= . clearly, |=I
iff |=I structure . However, grounding \ respect obtained
efficiently, since Grred (T \ , ) necessarily smaller Grred (T, ). Indeed, \
subtheory , Grred (T \ , ) contain symbols Def(), Grred (T, ) does.
Observe also set c-maps superset set c-maps ,
since bounds assigned former c-maps formulas , instead . such,
c-maps computed refinement algorithm might yield efficient grounding
compared c-maps computed .
5.3.3 Bounds Definitions
extend refinement algorithm FO(ID).
Definition 38. formula subformula FO(ID) theory subformula sentence
subformula rule body definition . c-map assignment
ct- cf-bound every subformula .
Note c-map assign bounds heads rules definition.
strategy compute c-map FO(ID) theory simple: construct completion
apply refinement algorithm Comp(T ) obtain c-map C Comp(T ). restriction
C subformulas c-map . Indeed, every subformula occurs Comp(T )
since |= Comp(T ), Comp(T ) |= x (C ct () ) Comp(T ) |= x (C cf () ), also
|= x (C ct () ) |= x (C cf () ).
order use c-map grounding, lift definition c-transformation FO(ID)
theories.
Definition 39. Let C c-map theory definition . c-transformation
rule x (P (t) ) given x (P (t) Chi). c-transformation Chi

248

fiGrounding FO FO(ID) Bounds

definition set c-transformations rules . c-transformation set
c-transformations formulas definitions .
also lift notion C-equivalence definitions.
Definition 40. Two definitions 1 2 C-equivalent every structure satisfies C,
|= 1 iff |= 2 .
However, Lemma 15 hold FO(ID) theories: definition , Chi necessarily
C-equivalent .
Example 14. Let empty vocabulary theory
P
{P P }.
theory unsatisfiable definition {P P } one model, P false.
contradicts sentence . Clearly, > ct-bound P . C c-map
assigning (>, ) P , Ch{P P }i = {P (P ) >}, equivalent {P >}.
definition model assigns true P . Since model also satisfies C, conclude
{P P } Ch{P P }i C-equivalent.
Definition 41. Let definition . call c-map C -tolerant Chi
C-equivalent. call C -tolerant -tolerant every definition .
following, say formula occurs positively (negatively) definition occurs
positively (negatively) body rule .
Proposition 42. Let definition theory . c-map C -tolerant
every subformula contains predicate P Def(), following hold:
1. total, C ct () = C cf () = .
2. occurs positively P occurs positively , C ct () = .
3. occurs negatively P occurs negatively , C cf () = .
Note c-map Example 14 violates second condition. prove Proposition 42
inductively constructing structure satisfies C, sequence three-valued structures
well-founded induction Chi. |= , show terminal
sequence property constructed, proving also satisfies Chi. 6|= ,
sequence property constructed last element less precise I.
shows satisfy Chi either. construct well-founded induction
Chi, prove step extends well-founded induction also valid step
extend Chi. Step (3a) Definition 34 covered Lemma 43, step (3b) Lemma 44.
Lemma 43. Let structure satisfies c-map C let J p three two-valued. J()


valued interpretation J|
p J(Chi)
every subformula
T.
Proof. prove lemma induction. First assume [x] atom. Chi formula




ct ()) must
( C cf ()) C ct (). J()
= u, clearly J(Chi)
p J().
J()
= f, J(C


cf ()) = f
false, since |= C. Therefore J(Chi)
= f. hand, J()
= t, J(C

hence, J(Chi)
= t.
inductive cases similar base case. prove one them. Assume

formula . Chi formula ((Chi Chi) C cf ()) C ct (). J()
= f,




ct ()) = f, conclude
J()
= J()
= f, induction J(Chi)
= J(Chi)
= f. Since also J(C


cf ()) = f. Also J()


J(Chi)
= f. hand J()
= t, J(C
= J()
= t,



therefore J(Chi)
= J(Chi)
= t. Hence J(Chi)
= t.
249

fiWittocx, Marien, & Denecker

Lemma 44. Let definition C c-map satisfies three conditions
Proposition 42. Let structure satisfies C J p three-valued interpretation
two-valued. U set domain atoms defined unknown J,
every
J|

subformula J[U/f]() 6= u, following hold:


J[U/f]()
J[U/f](Chi)
occurs negatively ;


J[U/f]()
J[U/f](Chi)
occurs positively ;


Proof. Denote H := J[U/f].
J()
6= u, result follows immediately Lemma 43.


=u
prove case J()
= u induction. Assume atom P (x). Since J()
J
cf
H() 6= u, know P (x ) U H() = f. Therefore H(Chi) = H(( C ())
C ct ()) = H(C ct ()). occurs negatively , prove H() H(Chi).
Since H() = f, inequality holds regardless value C ct () C cf () H.
hand, occurs positively, prove H() H(Chi). Since H() = f
H(Chi) = H(C ct ()), inequality hold H(C ct ()) = f. conditions C
ensure C ct () = , conclude indeed H(C ct ()) = f.
omit inductive cases, since similar base case.
Proof Proposition 42. Let structure satisfies C. prove |= iff
|= Chi. total, proof trivial, since Chi equivalent.
assume total let hJ i0 well-founded induction Chi
I. prove J two-valued, J <p I, exists J+1
hJ i0+1 well-founded induction Chi. Also observe limit
ordinal hJ i0< well-founded induction Chi, holds
hJ i0 .
sufficient conclude proof. Indeed, |= , keep extending sequence
end I, derive |= Chi. 6|= , eventually extend
well-founded induction structure J+1 6p I. then, well-founded model Chi
also precise J+1 , shows 6|= Chi.
Assume J two-valued J <p I. total, exists J+1
hJ i0+1 well-founded induction . prove also well-founded
induction Chi. two possibilities:
J+1 = J [P (d)/t] domain atom P (d) rule x (P (x) )
J [x/d]() = t. Lemma 43, also J [x/d](Chi) = t. Hence, hJ i0+1
well-founded induction Chi.
J+1 = J [U/f] every P (d) U rule x (P (x) ) , J+1 [x/d]() = f.
Lemma 44, conclude also J+1 [x/d](Chi) = f. Therefore, hJ i0+1 wellfounded induction Chi.

Proposition 42 derive following procedure compute -tolerant c-map
theory . First compute c-map C necessarily -tolerant. Then, every
definition every subformula , replace C ct () C cf () , required
satisfy conditions Proposition 42.
conclude following algorithm produces correct grounding FO(ID) theory :
1. Compute c-map C .
2. C inconsistent respect , output stop.
3. Else, derive atom-based, T-tolerant c-map C 0 C.
4. Output Grred (C 0 hT C 0 ), using off-the-shelf grounder FO(ID).
250

fiGrounding FO FO(ID) Bounds

6. Implementation Experiments
far focussed mostly grounding size. Proposition 23 guaranteed grounding
bounds produces smaller groundings. section concerned efficiency
practical implementation grounding bounds. first issue mentioned end
Section 4.4.2: atom-based c-map C computed refinement algorithm contains many repeated
constraints variables. ground ChT efficiently, repetitions avoided much
possible. Secondly, efficient grounder consults bounds soon possible. particular,
use bounds avoid unnecessary instantiations variables, rather remove
instantiations afterwards. case study, show detail adapt basic top-down
style grounding algorithm efficiently exploit bounds. sketch principles
applied bottom-up style grounder.
second part section discuss aspects implementing refinement algorithm. mentioned Section 4.4.1, several issues concerning practical implementation algorithm. particular, method simplify bounds needed, well good
stop criterion. show issues addressed representing bounds first-order
binary decision diagrams.
Finally, report implementation, called GidL, refinement grounding algorithm. present experimental results show impact using bounds grounding size
time.
6.1 Case Study: Top-Down Grounding Bounds
rest section, assume TNF fix -consistent, atom-based c-map C
. call formula form x disjunctive formula. Vice versa, conjunctive
formula formula form x .
present simple top-down style grounding algorithm exploits bounds without
constructing ChT C explicitly. algorithm shown Algorithm 1. Basically, consults
bounds assigned C whenever substitutes free variables formula [x] domain
constants d. according bounds, [x/d] certainly true, i.e., [x/d] |= C ct (),
grounding [x/d] computed. Instead, algorithm proceeds [x/d] equal
>. Similarly [x/d] certainly false. way, algorithm avoids creating unnecessary
instantiations. One check C trivial c-map, Algorithm 1 reduces straightforward
top-down style grounding algorithm produces Grfull (T ).
Line 1 Algorithm 1 checks whether one sentences certainly false.
case, clearly unsatisfiable (cf. Definition 10), reported immediately.
sentence grounded, line 4 checks whether sentence certainly true according C.
sentences certainly true grounded. Observe checks simple syntactic
checks executed constant time.
Function groundConj gets input formula [x] returns grounding x [x].
particular, sentence, result applying groundConj grounding .
groundConj, universal quantifiers implicitly pushed inside conjunctions. is, [x]
conjunction 1 . . . n , every [1, n], grounding x computed
applying groundConj . conjunction groundings returned grounding x .
According equivalence (6) Section 2.2, transformation yields equivalent formula.
Function groundConj consults c-map variables substituted domain constants input formula atom. such, groundConj ignores (eliminates) bounds
assigned conjunctive formulas. mentioned end Section 4.4.2, important
avoid repeated constraints variable.
groundConj([x]), substitutions [x/d] [x/d] 6|= C ct () grounded
(see, e.g., line 12). Indeed, substitutions yield formula certainly true models
expanding , therefore omitted ground conjunction C computed.
251

fiWittocx, Marien, & Denecker

Algorithm 1: Ground Bounds
Input: , , C
Output: grounding Tg respect
1
2

3
4

5
6

7
8
9
10
11

12

C cf () = > sentence return ;
Tg := ;
// Ground sentences
every sentence
C ct () 6= > Add groundConj() Tg ;
// Ground definitions
every definition
Add groundDef() Tg ;
// Add grounding C
every atomic subformula [x]
every [x/d] |= C ct ()
Add [x/d] Tg ;
every [x/d] |= C cf ()
Add [x/d] Tg ;
return Tg ;

Function groundConj([x])
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

C := ;
switch [x]
case literal
6|= C ct ()[x/d]
|= C cf ()[x/d] return ;
else Add [x/d] C;
case = [x, y]
return groundConj([x, y]);
V
case =S
C := groundConj(i );
case disjunctive formula
6|= C ct ()[x/d]
|= C cf ()[x/d] return ;
else Add groundDisj([x/d]) C;
return

V

C;

252

fiGrounding FO FO(ID) Bounds

Function groundDisj([x])
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

:= ;
switch [x]
case literal
6|= C cf ()[x/d]
|= C ct ()[x/d] return >;
else Add [x/d] D;
case = [x, y]
return groundDisj([x, y]);
W
case =S
:= groundDisj(i );
case conjunctive formula
6|= C cf ()[x/d]
|= C ct ()[x/d] return >;
else Add groundConj([x/d]) D;
return

W

D;

Function groundDef()

8

g := ;
every rule x (P (x) [y])
z := x \ y;
every 6|= C cf ([y/d])
|= C ct ([y/d]) g := >;
else g := groundConj([y/d]);
n := number variables z;
0
0
Add P (x)[y/d, z/d ] g g every Dn ;

9

return g ;

1
2
3
4
5
6
7

253

fiWittocx, Marien, & Denecker

[x/d] grounded, checked whether substitution yields formula certainly
false (see, e.g., line 13). case, whole conjunction C certainly false,
therefore returned immediately. Observe implicitly formula C ct () (C cf () )
grounded. Hence correctness groundConj follows Lemma 13.
Function groundDisj dual groundConj. input [x], returns grounding x [x].
implicitly pushes existential quantifiers disjunctions eliminates bounds assigned
disjunctive formulas.
Function groundDef returns grounding input definition . grounds rules
one-by-one. rule x (P (x) [y]), substitutions [y/d] possibly true
tried (line 4). [y/d] certainly true, replaced > (line 5).
lines 7-11 Algorithm 1, theory C grounded. Recall necessary obtain
grounding -equivalent (see Proposition 21). Observe C trivial c-map,
output produced lines 7-11 executed.
computationally expensive steps Algorithm 1 steps truth values
(some the) bounds assigned C computed. large bounds, steps become
infeasible. Indeed, expression complexity FO PSPACE-complete (Stockmeyer, 1974).
such, grounding complex bounds may take time space constructing
full grounding simplifying afterwards. stop criterion Section 6.2.3 refinement
algorithm designed avoid complex bounds. experiments Section 6.3 show
carefully restricting complexity bounds leads faster grounding.
stress Algorithm 1 one example grounding algorithm exploits bounds.4
principle consulting bounds soon possible applied adapt grounding
algorithms well. example, recall bottom-up style grounder starts storing instances
atomic subformulas table. exploit bounds efficiently, bottom-up grounder
consult bounds constructing tables leave out, e.g., instances certainly
false. such, avoids unnecessary large tables, turn improves speed subsequent
grounding steps.
6.2 Implementing Refinement Algorithm Querying Bounds
section discuss aspects implementing refinement algorithm. mentioned
above, applying simplification method first-order formulas simplify bounds regular
time points essential good implementation. One use Goubaults (1995) method
purpose. end, bounds need represented first-order binary decision diagrams.
show section representation applied without much overhead
applying one-step refinements. Moreover, using binary decision diagrams leads extra benefits:
obtain cheap equivalence check bounds elegant algorithm query bounds,
needed implement Algorithm 1. end section discuss stop criterion
refinement algorithm discuss implementation.
6.2.1 First-Order Binary Decision Trees Diagrams
borrow definition first-order BDDs Goubault (1995). Let , 1 2 three
formulas. ternary if-then-else operator denoted _, defined _ 1 ; 2 :=
( 1 ) ( 2 ). formula _ 1 ; 2 also represented graph shown Figure 3.
Definition 45 (Goubault, 1995). FO binary decision trees (BDTs) kernels defined
simultaneous induction:
atom kernel;
4. question whether top-down grounders made efficient bottom-up grounders outside
scope paper, still undecided.

254

fiGrounding FO FO(ID) Bounds


yEEE
EE

EE

E"
|y
2
1
Figure 3: Graph representation formula _ 1 ; 2
BDT x variable, x kernel;
> BDTs;
kernel 1 2 BDTs, _ 1 ; 2 BDT.
Observe graph representation BDT tree whose nodes atoms existentially
quantified BDTs.
Goubault (1995) showed every FO formula exists BDT 0 0
equivalent. actual implementation, sharing, reducing ordering applied obtain
simplified compact representation BDTs. representations called reduced ordered
binary decision diagrams (BDDs). Sharing means isomorphic subtrees stored
address memory. Reducing involves exhaustively replacing subtrees form _ ; .
BDT ordered kernels appear fixed order every path graph representation
.
mentioned above, several important benefits using BDDs represent bounds
formula:
implementation refinement algorithm using BDDs allows us use simplification
algorithm BDDs Goubault (1995).
explained Section 4.4, detect refinement algorithm reached fixpoint,
one needs check equivalence bounds. Often, BDDs representing two equivalent
formulas equal.5 Hence, cheap (but necessarily incomplete) equivalence check two
bounds consists checking syntactic equality two BDDs representing them. Since
equal BDDs stored address, check done constant time.
show Section 6.2.2, querying bound [x], i.e., finding tuples
[x/d] |= , easily implemented directly BDD representation . Querying
bound one main operations performed grounding algorithm exploits bounds
directly (such Algorithm 1).
hand, using BDDs result much overhead computing c-map.
, [x, y] represented BDDs, BDD representing , x , x , ,
[x/x0 , y] computed efficiently (Bryant, 1986; Goubault, 1995). implies every
one-step refinement c-map C implemented efficiently, even bounds assigned C
BDDs.
6.2.2 Querying Bound
Algorithm 1, main operation performed bound [x] querying: finding tuples
domain constants |= [x/d]. Finding tuple 6|= [x/d] corresponds
querying . show querying bound [x] done directly BDD
representation simple backtracking algorithm.
5. propositional BDDs, always case.

255

fiWittocx, Marien, & Denecker

P (x)
yEEE
EE

EE

E"
|y
Q(x,
y)
R(x)
RRR
l
R
l
R
R
l

lRR
l l RRRRR
)
ul

>
Figure 4: BDD representing formula (P (x) Q(x, y)) (P (x) R(x))
idea traverse BDD, starting root, trying end leaf >.
inner node [y] _ 1 ; 2 , free variables node replaced domain constants dy .
|= [y/dy ], algorithm continues via 1 , otherwise via 2 . ends , backtracks.
hand, ends >, performed substitutions constitute answer .
Function query implements sketched query algorithm. gets bound [x] input
returns substitution [x/d] |= [x/d]. substitution exists, returns FAIL.
algorithm easily adapted return answers [x] instead one.
Function query([x])
1
2
3
4
5
6
7
8
9

= > return empty substitution;
else = [y] _ 1 ;
every tuple |= [y/d]
:= query(1 [y/d]);
6= FAIL return [y/d]
else = [y] _ ; 2
every tuple 6|= [y/d]
:= query(2 [y/d]);
6= FAIL return [y/d]

14

else form [y] _ 1 ; 2
every tuple D|y|
|= [y/d] := query(1 [y/d]);
else := query(2 [y/d]);
6= FAIL return [y/d]

15

return FAIL;

10
11
12
13

lines 3 7, algorithm needs find tuples respectively |= [y/d]
6|= [y/d]. [y] atom P (y), implemented consulting table P .
kernel x [x, y], function query applied recursively find tuples. Indeed, answer
(d0 , d) [x, y] provides tuple |= [y/d]. Vice versa, 6|= [y/d] [x, y/d]
answer.
illustrate query algorithm example.
Example 15. Let [x, y] BDD shown figure 4, let {a, b} domain ,
P = {b}, RI = {} QI = {(b, b)}. find answer [x, y], query algorithm starts
root P (x). Since none children equal , every domain constant tried. Assume
domain constant tried first. 6 P , algorithm continues node R(a) _ >; .
else child node 6 RI , algorithm returns root tries
256

fiGrounding FO FO(ID) Bounds

domain element b. Since b P , goes node Q(b, y) _ >; . Since else child node
, algorithm tries substitutions (b, y/d) QI . Thus, substituted
b. Finally, answer [x/b, y/b] returned.
6.2.3 Stop Criterion Refinement Algorithm
shown Section 4.4, c-map refinement algorithm reach fixpoint certain inputs.
Also, even case fixpoint found, computing may take long time, bounds
assigned fixpoint complex querying becomes inefficient. Using
bounds may severely slow grounding. indicates need good stop criterion.
Simple Stop Criteria simple stop criterion limits number one-step refinements
may performed given maximum number m. may depend theory .
instance, set C (number subformulas ), C fixed constant.
slightly less naive technique, combined previous, limits complexity
bounds putting fixed upper bound N number nodes BDD representation
bound may have. one-step refinement would lead new bound nodes N ,
refinement performed. limits number applicable one-step refinements,
probability reaching fixpoint increases.
Stop Criteria via Estimators experiments present Section 6.3 indicate
exist appropriate values C N produce positive results examples. Still,
problems, grounding slows severely, size produced grounding
decrease. One problems following clique problem (entry 6 Table 4).
Example 16. Recall clique maximally connected graph. Let
= h{Edge/2}, i,
= hP {Clique/1},
theory
xy (Clique(x) Clique(y) (x = Edge(x, y))).
x ((y (Clique(y) x 6= Edge(x, y))) Clique(x)).
EdgeI symmetric, i.e., represents undirected graph, model expanding clique
contained strictly larger clique . Within small number iterations,
refinement algorithm finds Clique(x) ct-bound x0 x 6= x0 Edge(x, x0 ). formula
expresses Clique(x) certainly true every solution x directly connected every
vertex input graph. Clearly, graphs, vertex satisfies condition. So,
graphs, would equally precise ct-bound, would allow much faster querying.
situation worse cf-bound Clique(x). Since undirected graph, every
single vertex clique, thus occurs least one solutions, cf-bound necessarily
unsatisfiable respect . Yet, implementation refinement algorithm came
x0 (Edge(x, x0 ) x 6= x0 (x00 (x0 6= x00 Edge(x0 , x00 )))) cf-bound. query algorithm
outlined takes cubic time number vertices find x satisfies formula.
avoid problems illustrated example above, one could estimate reward
bound versus cost evaluating it. Recall precise bounds yield smaller grounding
sizes. Therefore, reward bound dictated precision. Given , possible
find good estimate number answers (Demolombe, 1980), turn
measure precision . fixed query algorithm, one also estimate cost cost()
computing answer query . following, assume reward bound
positive real number, cost strictly positive real number.
257

fiWittocx, Marien, & Denecker

Given reward cost bounds, complexity bound limited
restricting ratio
cost()
r() :=
.
reward() + 1
one-step refinement would replace bound 1 2 , r(1 ) < r(2 ), refinement
performed. Clearly, bounds assigned c-map C computed according
restriction, r() r() holds. Observe apply restriction, input structure
needed. However, obtained bounds independent .
beyond scope paper describe detail estimators reward cost
bounds. fairly naive estimator used experiments next section assigns ratios
order O(|DI |), respectively O(|DI |3 ), ct-bound, respectively cf-bound, mentioned
Example 16. such, |DI | large enough, bounds avoided.
6.2.4 Implementation Refinement Algorithm
implementation refinement algorithm, including heuristic choosing refinement
bounds (Section 4.4.1) stop criterion, presented Algorithm 6. algorithm maintains
queue Q one-step refinements applied. represented tuple hr, i,
r type refinement, e.g., axiom refinement, formula r
applied.
Algorithm 6: Refinement Algorithm
1
2
3
4
5
6
7
8
9
10
11
12
13

Q := ; C := trivial c-map ;
sentences Q.push(haxiom, i);
subformulas
Q.push(hct-input, i); Q.push(hcf-input, i);
Q 6= maximum number refinements reached
hr, := Q.pop();
r ct-refinement
:= r-refinement bound respect C;
:= simplify(C ct () );
6= C ct () complex
C ct () := ;
hr, r-refinement bound contains C ct ()
Q.push(hr, i);

15

else
...

16

return C;

14

// Similar code cf-refinements

explained Section 4.4.1, implementation starts scheduling possible axiom-
input-refinements. later stage bound changed (line 11), refinement bounds
contain bound scheduled applied (line 13). example, assume contains
formula ct-bound refined. bottom-up ct-refinement
scheduled since bottom-up ct-refinement bound formula given C ct () C ct (),
contains C ct (). reason also top-down cf-refinement scheduled.
algorithm applies scheduled refinements, unless maximum number refinement steps
reached (line 5). part discussed stop criterion applied line 10. newly

258

fiGrounding FO FO(ID) Bounds

computed bound complex, i.e., BDD representation contains many nodes ratio
r() certain threshold, used.
BDDs used represent bounds assigned C, line 8 implemented linear time
size C. use Goubaults simplification algorithm BDDs implementing line 9,
worst case complexity step non-elementary size C ct () (Goubault, 1995).
estimators used implement line 10 take linear time size . may seem
complexity simplification method limits practical applicability Algorithm 6. However,
since large BDDs usually pass test line 10, simplification method rarely applied
large BDDs. experiments next section, running time refinement algorithm
negligible compared running time grounding algorithm.
6.3 Experiments
implemented Algorithm 1 Algorithm 6, using BDDs represent bounds. resulting
grounder called GidL. section, present experiments, obtained GidL, show
impact using bounds grounding size time.
input GidL, used 37 benchmark problems, mainly taken Asparagus.6 details
experiments available http://dtai.cs.kuleuven.be/krr/software.html.
used four different versions GidL:
GidLnb : Assigns h, bound every atomic subformula input vocabulary,
h, every subformula. such, creates reduced grounding input
theory.
GidLbu : Assigns h, bound every atomic subformula input vocabulary
applies bottom-up refinements obtain bottom-up c-map.
GidLmn : Limits refinement algorithm 4 (number subformulas ) one-step refinements
allows maximum 4 internal nodes BDD used represent bounds. According previous experiments (Wittocx et al., 2008b), best setting limiting
number nodes.
GidLr : Limits refinement algorithm 4 (number subformulas ) one-step refinements.
limits complexity derived bounds estimating number answers
cost, described previous section.
Table 3, influence bounds grounding size shown. second third column
show ratio grounding size obtained GidLmn GidLr compared Grred (T ).
GidLnb GidLbu , ratio always equal 1. interpreting Table 3, important
note small reductions grounding size important. reason reductions
obtained refinement algorithm also obtained applying unit propagation
grounding (see Section 7 discussion). Since exist efficient implementations
unit propagation, beneficial let refinement algorithm find small reductions
relatively high cost. see GidLmn GidLr reduce grounding size
50% around 30% benchmarks. 7, respectively 6, benchmarks spectacular
reduction 95%.
important reductions size reductions grounding time. Table 4 shows
running times different versions GidL, (between brackets) ratio running
time running time GidLnb . running time refinement algorithm included (it
never took 0.02 seconds). time-out (###) 600 seconds used.
many benchmarks, reduction grounding time respect GidLnb due
reduction grounding size. Yet also several benchmarks time decreases lot,
6. http://asp.haiti.cs.uni-potsdam.de/

259

fiWittocx, Marien, & Denecker

almost reduction size. mostly due creation bottom-up c-map,
seen running times GidLbu . Applying bottom-up refinements leads assignment
non-trivial bounds non-atomic subformulas. allows earlier pruning top-down style
grounder, hence faster grounding.
Table 4, see GidLmn performs quite well. half benchmarks,
44% faster GidLnb . also 20% faster GidLbu half
benchmarks. outliers however. benchmarks 6 11, far slower GidLbu ,
producing significantly smaller grounding. indicates use complex bound
relatively small reward. Compared GidLmn , GidLr faster robust, indicating
using estimators reward cost bounds pays cases. two
benchmarks, naive estimator makes wrong guess. benchmark 1, bound high cost
reward allowed, benchmark 7, bound low cost high reward allowed
GidLr . part future work implement improved estimators.
conclude experiments grounding bounds applicable practice. often
leads smaller grounding sizes standard benchmark problems, bounds carefully
restricted, yields significant speed up. Since time compute bounds small compared
overall grounding time, computing essentially free.
general, smaller grounding necessarily lead faster propositional model generation.
example, grounding size (and time) increases symmetry breaking formulas added,
formulas may drastically improve overall solving time (Torlak & Jackson, 2007). Another
example clause-learning SAT solvers: clauses learnt solvers redundant,
may improve solving time orders magnitude. question arises whether method
grounding bounds may lead slower overall model generation time compared grounding
without bounds. case. experiments show general, grounding
bounds faster grounding without bounds. Since grounding bounds also produces smaller
groundings, subsequent initialization phase SAT solver executed faster. T1 T2
two groundings obtained grounding input theory structure with, respectively
without bounds, shown7 typical simplification steps applied initialization
phase transform T1 T2 exactly simplified theory T3 . Thus, initialization,
SAT solver applied exactly theory, whether grounder used bounds.
follows general, overall model generation time increase bounds applied
grounding.

7. Related Work
previous sections described method obtain fast compact grounding. Several
methods described literature. like preprocessing
techniques rewrite input theory. techniques involve reasoning propositional
level. section provide overview. indicate ones applied improve
GidL. also give overview existing grounders.
7.1 Methods Optimize Grounding
Derivation Bounds knowledge, methods proposed literature derive bounds
less general one presented paper. illustrated Table 5, show
several grounders impact manually adding redundant information. grounders
table except GidL, manually adding redundancy may serious impact.
grounders, need add redundancy sometimes avoided writing input theory
specific format. example, grounder gringo (Gebser et al., 2007) uses syntactic check
derive bounds: derives predicate q input vocabulary bound predicate p p
7. exact formulation proof property beyond scope paper.

260

fiGrounding FO FO(ID) Bounds

Nr
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37

Benchmark name
15puzzle
Battleship
Blocked N-queens
Blocksworld
Bounded spanningtree
Clique
Hierarchical clustering
Graph colouring
Debugging
Fastfood
FO-hamcircuit
Golomb ruler
Graph partitioning
Algebraic groups
Hamiltonian circuit
Tower Hanoi
Knighttour
Labyrinth
Magic series
Maze generation
Mirror puzzle
Missionaries
N-queens
Pigeonhole
Disjunctive scheduling
Slitherlink
Social golfer
Sokoban
Solitaire
Spanningtree
Sudoku
Tarski
Toughnut
Train scheduling
Waterbucket
Weight bounded dominating set
Wire routing
Average
# < 1.00
# < 0.50
# < 0.05

GidLmn
1.00
0.89
0.02
0.33
0.12
1.00
0.03
1.00
0.86
1.00
0.94
0.54
0.94
0.99
0.01
1.00
0.00
0.99
1.00
0.90
1.00
0.03
1.00
1.00
0.83
0.04
1.00
0.59
1.00
0.06
0.75
1.00
0.00
0.25
0.36
1.00
0.92
0.66
24
12
7

GidLr
1.00
1.00
0.02
0.33
0.12
1.00
0.72
1.00
1.00
1.00
0.99
1.00
1.00
1.00
0.01
1.00
0.00
0.99
1.00
0.90
1.00
0.03
1.00
1.00
0.83
0.04
1.00
0.59
0.73
0.06
0.75
1.00
0.00
0.25
0.36
1.00
0.99
0.70
20
11
6

Table 3: Impact bounds grounding size

261

fiWittocx, Marien, & Denecker

Nr
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
Total
Avg. gain
Median gain

GidLnb
6.13
0.19
9.66
22.33
8.52
3.13
0.32
2.57
0.30
###
###
14.05
0.03
9.68
70.75
2.32
12.22
8.80
1.83
2.77
0.12
17.4
4.62
4.92
151.15
0.25
5.47
2.78
0.43
6.86
###
4.42
4.23
4.06
3.16
1.45
0.06
2186.98

GidLbu
2.00 (0.33)
0.18 (0.95)
10.83 (1.12)
16.76 (0.75)
8.52 (1.00)
3.73 (1.19)
0.34 (1.06)
2.71 (1.05)
0.30 (1.00)
### (1.00)
5.87 (0.01)
3.54 (0.25)
0.04 (1.33)
9.58 (0.99)
71.50 (1.01)
1.83 (0.79)
10.35 (0.85)
8.83 (1.00)
1.76 (0.96)
2.80 (1.01)
0.11 (0.92)
18.08 (1.04)
4.60 (1.00)
5.01 (1.02)
151.66 (1.00)
0.13 (0.52)
5.47 (1.00)
2.66 (0.96)
0.43 (1.00)
6.79 (0.99)
2.34 (0.00)
4.53 (1.02)
4.23 (1.00)
2.14 (0.53)
3.07 (0.97)
1.42 (0.98)
0.06 (1.00)
974.20 (0.45)
12 %
0%

GidLmn
2.07
(0.34)
0.16
(0.84)
2.22
(0.23)
5.80
(0.26)
3.01
(0.35)
51.77 (16.54)
0.05
(0.16)
2.69
(1.05)
0.48
(1.60)
17.59
(0.03)
37.86
(0.06)
4.13
(0.29)
0.03
(1.00)
11.20
(1.16)
2.56
(0.04)
1.96
(0.84)
0.06
(0.00)
8.83
(1.00)
1.79
(0.98)
0.51
(0.18)
0.12
(1.00)
2.29
(0.13)
4.62
(1.00)
4.90
(1.00)
172.50
(1.14)
0.02
(0.08)
5.37
(0.98)
1.57
(0.56)
0.46
(1.07)
0.59
(0.09)
1.07
(0.00)
3.67
(0.83)
0.53
(0.13)
0.65
(0.16)
1.76
(0.56)
0.03
(0.02)
0.08
(1.33)
355.00
(0.16)
0%
44 %

GidLr
5.73 (0.93)
0.17 (0.89)
2.67 (0.28)
5.80 (0.26)
1.16 (0.14)
3.73 (1.19)
0.31 (0.97)
2.72 (1.06)
0.47 (1.57)
16.52 (0.03)
6.06 (0.01)
3.40 (0.24)
0.02 (0.67)
9.60 (0.99)
1.81 (0.03)
1.83 (0.79)
0.10 (0.01)
8.73 (0.99)
1.81 (0.99)
0.17 (0.06)
0.10 (0.83)
2.68 (0.15)
4.64 (1.00)
4.90 (1.00)
171.54 (1.13)
0.02 (0.08)
5.41 (0.99)
1.54 (0.55)
0.49 (1.14)
0.57 (0.08)
1.06 (0.00)
3.64 (0.82)
0.53 (0.13)
0.47 (0.12)
2.04 (0.65)
0.03 (0.02)
0.08 (1.33)
272.55 (0.12)
40%
33%

(For GidLmn GidLr , time compute bounds included.)

Table 4: Impact bounds grounding time

262

fiGrounding FO FO(ID) Bounds

gringo
dlv
lparse
psgrnd
gidl

constr
76.33
339.37
63.25
44.79
0.26

redun
1.59
4.23
0.78
0.72
0.42

defin
0.60
2.81
63.58
n/a
n/a

Table 5: Grounding times (in seconds) Hamiltonian circuit problem input graph
200 nodes 1800 edges. Encoding constr uses constraint state edge
cycle edge graph. Encoding redun adds redundancy include
bound rules constraints. Encoding defin contains redundancy, limits
possible edges cycle edges graph defining search space
cycle.

defined choice rule form, e.g., {p(X)} :- q(X). However, rule replaced
{p(X)} :- dom(X), dom denotes domain, constraint :- p(X),not q(X),dom(X)
added, q still bound p, detected gringo, seen Table 5.
grounder dlv system (Perri et al., 2007) may derive bounds reasoning
propositional level. explain below, order rules constraints grounded
crucial importance method pay off. Since dlv grounds rules constraints, using
constraint state q bound p improve grounding time.
Propagation Propositional Level One techniques produce smaller groundings
consists applying constraint propagation method ground theory Tg replacing
>, respectively , every ground literal derived true, respectively false. resulting
theory simplified. technique applied grounder psgrnd (East et al., 2006),
uses unit propagation (Davis & Putnam, 1960) complete one-atom lookahead (Li & Anbulagan,
1997) propagation methods. latter performed grounding finished, former
triggered time unit clause added grounding. inconsistency detected
unit propagation, grounding process terminated immediately. Observe technique
yields small groundings improve grounding speed, except (rare) case
propagation method detects inconsistency grounding. Indeed, avoid computing
ground instances formulas input theory.
propositional constraint propagation method applied grounding constructed, derived information could used refine bounds. instance, unit-propagation
derives domain atom P (d1 , . . . , dn ) true, x1 = d1 . . . xn = dn ct-bound
P (x1 , . . . , xn ). bounds could used speed construction rest grounding.
method effective, however, careful fine-tuning order sentences
grounded required. may even necessary alternatingly compute partial groundings
different sentences. best knowledge, process worked implemented unit-propagation one-atom lookahead underlying propagation method.
hand, ASP grounders apply following limited propagation method: rules
defining predicate P grounded, concluded domain atom P (d) certainly true
occurs ground rule form P (d) >, certainly false occur
head ground rule. case, good grounding order derived dependency
graph input theory (e.g., Cadoli & Schaerf, 2005; Perri et al., 2007). GidL, strategy
implemented grounding definitions.
Sharing second technique called sharing consists detecting subformulas ground
theory Tg occur once. subformula detected, occurrences Tg
replaced new atom P , sentence P added. large formula occurs
263

fiWittocx, Marien, & Denecker

often Tg , may result significant grounding size reduction. Also, sharing improves
propagation SAT solvers.
Shlyakhter, Sridharan, Seater, Jackson (2003) present algorithm detect identical subformulas first-order level, Torlak Jackson (2007) propositional level. GidL,
implemented simple sharing technique using dynamic
V programming. adapted function
groundConj soVthat instead returning conjunction C, creates new atom P , adds
sentence P C grounding, returns P . groundConj applied
multiple times
V
input , predicate P returned time, P C added once.
Function groundDisj adapted similar fashion.
Clause splitting Clause splitting well-known rewriting technique applied MACE style
model generation (McCune, 2003). consists splitting first-order clause
xyz (1 [x, z 1 ] 2 [y, z 2 ])

(20)

x 6 z 2 , 6 z 1 z = z 1 z 2 two new clauses
xz 1 (1 [x, z 1 ] S(z 1 z 2 ))

(21)

yz 2 (S(z 1 z 2 ) 2 [y, z 2 ]).

(22)

Here, new predicate symbol. full grounding (20) size O(|D|3 ), full
grounding (21) (22) size O(|D|2 ).
sharing implemented adapting functions groundConj groundDisj explained
above, effect clause splitting obtained moving quantifiers according equivalences (4), (5), (8) (9) Section 2.2. instance, apply equivalences (4) (8)
replace (20) xz (1 (y 2 )). Grounding latter applying sharing effect
clause splitting. Similarly, grounding size xyz (1 [x, z 1 ] 2 [y, z 2 ]) reduced
replacing formula xz (1 (y 2 )).
simple heuristic guide clause splitting described Claessen Sorensson (2003)
directly applied choose quantifiers move inside. conclude clause splitting
could easily incorporated GidL.
Database Techniques Several techniques optimizing querying databases used
optimize grounding. Examples join-ordering strategies, backjumping indexing techniques.
One basic techniques improve grounding speed consists reordering (long) conjunctions disjunctions literals speed grounding. order best depends
grounding algorithm. Different strategies described by, e.g, Leone, Perri, Scarcello (2001),
Syrjanen (1998, 2009) database literature (Garcia-Molina, Ullman, & Widom, 2000).
problem implementing similar technique GidL. Also, reordering nodes
BDD representation bounds could optimize querying. part future work investigate
reordering strategies BDDs.
One important methods dlv grounder use backjumping technique (Perri
et al., 2007) efficiently find instances conjunction 1 . . . n possibly true,
given (an overestimation of) possibly true instances conjuncts . GidL,
backjumping technique applied implement line 12 function groundDisj. Indeed,
formula 1 . . . n , line 12 amounts finding possible instances ,
cf-bounds 1 , . . . , n provide overestimation possibly true instances conjuncts.
Similarly, backjumping technique applied improve line 12 groundConj, possibly
false instances disjunction calculated.
Catalano, Leone, Perri (2008) present adaptation indexing strategies grounding.
Partition-Based Reasoning Ramachandran Amir (2005) describe sophisticated grounding
technique reduce grounding size FO theories, depending availability
264

fiGrounding FO FO(ID) Bounds

graphical structure theories. technique directly applicable case, since
produces groundings necessarily -equivalent input theory. guarantee
ground theory satisfiable iff input problem satisfiable.
7.2 Grounders
non-native approach ground MX(FO(ID)) problem consists first translating
equivalent normal logic program well-founded semantics. translation described
Marien et al. (2004). Next, (slightly adapted) grounder ASP used ground logic
program. approach taken MXidL (Marien, Wittocx, & Denecker, 2006).
first native grounding algorithm MX(FO) MX(FO(ID)) described Patterson, Liu, Ternovska, Gupta (2007). based relational algebra takes bottom-up
approach (see Section 3.2.1). construct grounding sentence , first creates possible
groundings atomic subformulas. combines groundings using relational algebra
operations, working way syntax tree. Finally, grounding obtained. Mitchell
et al. (2006) report implementation, called mxg, algorithm.
kodkod (Torlak & Jackson, 2007) MX grounder syntactic variant FO. Like mxg,
works bottom-up way. represents intermediate groundings (sparse) matrices. One
features kodkod allows user give part solution MX problem
three-valued structure. Specifically, user force atoms P (d), P
expansion predicate, certainly true (or certainly false). kodkod takes advantage
information produce smaller groundings. GidL also allows three-valued structure input.
applying refinement algorithm, set tuples user indicates P
true used initial ct-bound P instead . Similarly cf-bound.
leads efficient compact groundings.
mace (McCune, 2003) paradox (Claessen & Sorensson, 2003) finite model generators
FO. work choosing domain grounding input theory SAT. resulting
grounding unsatisfiable, domain size increased process repeated. grounding
algorithm mace paradox basically constructs full grounding simplifies afterwards.
Small groundings obtained first rewriting input theory using, e.g., clause splitting. Also
methods build grounding incrementally applied systems avoid recomputing
every grounding scratch.
East et al. (2006) developed grounder psgrnd X(P pb ). P pb fragment FO(ID),
extended pseudo-boolean constraints. explained above, psgrnd performs reasoning
ground theory reduce memory usage grounding size. experiments performed East
et al. (2006) show carefully designed data structures key importance build efficient
grounder.
ASP grounders take input normal logic program transform equivalent ground
normal logic program. such, grounders deal (deeply) nested formulas. Currently, three ASP grounders: lparse (Syrjanen, 2000; Syrjanen, 2009), gringo (Gebser
et al., 2007) grounding component dlv (Perri et al., 2007). use techniques
database theory perform grounding efficiently.
Finally, mention grounder spec2SAT (Cadoli & Schaerf, 2005). input theories
np-spec language, language Datalog-like syntax semantics based model minimality. grounding algorithm implemented spec2SAT basically simplified version
grounding algorithm dlv.
would interesting compare efficiency mentioned grounders experimentally. However, currently possible conduct experiment scientifically fair way.
several reasons this. First, grounders different input language, making
impossible run input. Also, several output languages grounders.
richer output language leads compact fast grounding. instance, prob-

265

fiWittocx, Marien, & Denecker

lems, lparses output size necessarily cubic input domain size, GidLs output format
allows quadratic size. Thirdly, even input output languages grounders
same, expert could easily manipulate experiments carefully choosing modelling style.
example, manually add bounds input theories, GidL advantage.
bodies rules ordered, dlv likely produce good results. Etc. Finally,
large amount data processed grounders, carefully designed data structures optimized implementation core grounding algorithm important achieve fast grounding
(East et al., 2006). However, several mentioned grounders yet optimized
sense. such, difficult derive conclusions grounding algorithms experimentally
comparing efficiency current implementations algorithms.

8. Conclusions
presented method compute given theory, upper lower bounds subformulas
theory. showed bounds used efficiently creating small groundings
context Model Expansion FO FO(ID). method frees user manually
discovering bounds adding theory.
presented top-down style grounding algorithm incorporates bounds. discussed
implementation issues showed experiments method works practice: many
benchmark problems, leads significant reductions grounding size time.
Future work includes extension algorithm compute bounds richer logics, as,
e.g., extensions FO aggregates arithmetic. implementation side, plan use
sophisticated estimators evaluate whether computed bound beneficial grounding.

Acknowledgments
Research supported Research Foundation-Flanders (FWO-Vlaanderen) GOA 2003/08
Inductive Knowledge Bases. Johan Wittocx research assistant Research FoundationFlanders (FWO-Vlaanderen).

References
Baral, C., Brewka, G., & Schlipf, J. S. (Eds.). (2007). Logic Programming Nonmonotonic
Reasoning, 9th International Conference, LPNMR 2007, Tempe, AZ, USA, May 15-17, 2007,
Proceedings, Vol. 4483 Lecture Notes Computer Science. Springer.
Bryant, R. E. (1986). Graph-based algorithms boolean function manipulation. IEEE Transactions
Computers, 35, 677691.
Cadoli, M., & Schaerf, A. (2005). Compiling problem specifications SAT. Artificial Intelligence,
162 (1-2), 89120.
Catalano, G., Leone, N., & Perri, S. (2008). demand indexing DLV instantiator.
Faber, W., & Lee, J. (Eds.), Workshop Answer Set Programming Computing
Paradigms (ASPOCP).
Claessen, K., & Sorensson, N. (2003). New techniques improve MACE-style model finding.
Workshop Model Computation (MODEL).
Davis, M., & Putnam, H. (1960). computing procedure quantification theory. Journal
ACM, 7 (3), 201215.

266

fiGrounding FO FO(ID) Bounds

Demolombe, R. (1980). Estimation number tuples satisfying query expressed predicate
calculus language. International Conference Large Data Bases (VLDB), pp. 5563.
IEEE Computer Society.
Denecker, M. (2000). Extending classical logic inductive definitions. Lloyd, J. W., Dahl, V.,
Furbach, U., Kerber, M., Lau, K.-K., Palamidessi, C., Pereira, L. M., Sagiv, Y., & Stuckey,
P. J. (Eds.), International Conference Computational Logic (CL), Vol. 1861 Lecture Notes
Computer Science, pp. 703717. Springer.
Denecker, M., & Ternovska, E. (2007). Inductive situation calculus. Artificial Intelligence, 171 (5-6),
332360.
Denecker, M., & Ternovska, E. (2008). logic nonmonotone inductive definitions. ACM Transactions Computational Logic (TOCL), 9 (2), Article 14.
Denecker, M., & Vennekens, J. (2007). Well-founded semantics algebraic theory nonmonotone inductive definitions.. Baral et al. (Baral, Brewka, & Schlipf, 2007), pp. 8496.
Denecker, M., Vennekens, J., Bond, S., Gebser, M., & Truszczynski, M. (2009). second answer
set programming competition. Erdem, E., Lin, F., & Schaub, T. (Eds.), International Conference Logic Programming Nonmonotonic Reasoning (LPNMR), Vol. 5753 Lecture
Notes Computer Science, pp. 637654. Springer.
East, D., Iakhiaev, M., Mikitiuk, A., & Truszczynski, M. (2006). Tools modeling solving
search problems. AI Communications, 19 (4), 301312.
Enderton, H. B. (2001). Mathematical Introduction Logic (Second edition). Academic Press.
Fagin, R. (1974). Generalized first-order spectra polynomial-time recognizable sets. Complexity
Computation, 7, 4374.
Forgy, C. (1982). Rete: fast algorithm many patterns/many objects match problem.
Artificial Intelligence, 19 (1), 1737.
Garcia-Molina, H., Ullman, J. D., & Widom, J. (2000). Database System Implementation. PrenticeHall.
Gebser, M., Schaub, T., & Thiele, S. (2007). GrinGo : new grounder answer set programming..
Baral et al. (Baral et al., 2007), pp. 266271.
Goubault, J. (1995). BDD-based simplification skolemization procedure. Logic Journal
IGPL, 3 (6), 827855.
Jackson, D. (2006). Software Abstractions: Logic, Language, Analysis. MIT Press, Cambridge,
MA.
Kautz, H. A., & Selman, B. (1996). Pushing envelope: Planning, propositional logic stochastic search. National Conference Artificial Intelligence Innovative Applications
Artificial Intelligence (AAAI/IAAI), pp. 11941201. AAAI Press.
Krogel, M.-A., Rawles, S., Zelezny, F., Flach, P. A., Lavrac, N., & Wrobel, S. (2003). Comparative
evaluation approaches propositionalization. Horvath, T. (Ed.), International Conference Inductive Logic Programming (ILP), Vol. 2835 Lecture Notes Computer Science,
pp. 197214. Springer.
Leone, N., Perri, S., & Scarcello, F. (2001). Improving ASP instantiators join-ordering methods.
Eiter, T., Faber, W., & Truszczynski, M. (Eds.), International Conference Logic Programming Nonmonotonic Reasoning (LPNMR), Vol. 2173 Lecture Notes Computer
Science, pp. 280294. Springer.
Li, C. M., & Anbulagan (1997). Heuristics based unit propagation satisfiability problems.
International Joint Conference Artificial Intelligence (IJCAI), pp. 366371. Morgan
Kaufman.
267

fiWittocx, Marien, & Denecker

Marek, V. W., & Truszczynski, M. (1999). Stable models alternative logic programming
paradigm. Apt, K. R., Marek, V. W., Truszczynski, M., & Warren, D. S. (Eds.), Logic
Programming Paradigm: 25-Year Perspective, pp. 375398. Springer-Verlag.
Marien, M. (2009). Model Generation ID-Logic. Ph.D. thesis, Department Computer Science,
K.U.Leuven, Leuven, Belgium.
Marien, M., Gilis, D., & Denecker, M. (2004). relation ID-Logic Answer Set
Programming.. Alferes, J. J., & Leite, J. A. (Eds.), European Conference Logics
Artificial Intelligence (JELIA), Vol. 3229 Lecture Notes Computer Science, pp. 108120.
Springer.
Marien, M., Wittocx, J., & Denecker, M. (2006). IDP framework declarative problem solving.
Search Logic: Answer Set Programming SAT, pp. 1934.
Marien, M., Wittocx, J., & Denecker, M. (2007). MidL: SAT(ID) solver. 4th Workshop
Answer Set Programming: Advances Theory Implementation, pp. 303308.
Marien, M., Wittocx, J., Denecker, M., & Bruynooghe, M. (2008). SAT(ID): Satisfiability propositional logic extended inductive definitions. Kleine Buning, H., & Zhao, X. (Eds.),
International Conference Theory Applications Satisfiability Testing (SAT), Vol. 4996
Lecture Notes Computer Science, pp. 211224. Springer.
McCune, W. (2003). Mace4 reference manual guide. CoRR, cs.SC/0310055.
Mitchell, D. G., & Ternovska, E. (2005). framework representing solving NP search
problems.. Veloso, & Kambhampati (Veloso & Kambhampati, 2005), pp. 430435.
Mitchell, D. G., Ternovska, E., Hach, F., & Mohebali, R. (2006). Model expansion framework
modelling solving search problems. Tech. rep. TR 2006-24, Simon Fraser University,
Canada.
Niemela, I. (1999). Logic programs stable model semantics constraint programming
paradigm. Annals Mathematics Artificial Intelligence, 25 (3-4), 241273.
Patterson, M., Liu, Y., Ternovska, E., & Gupta, A. (2007). Grounding model expansion
k-guarded formulas inductive definitions. Veloso, M. M. (Ed.), International Joint
Conference Artificial Intelligence (IJCAI), pp. 161166.
Pelov, N., & Ternovska, E. (2005). Reducing inductive definitions propositional satisfiability.
Gabbrielli, M., & Gupta, G. (Eds.), International Conference Logic Programming (ICLP),
Vol. 3668 Lecture Notes Computer Science, pp. 221234. Springer.
Perri, S., Scarcello, F., Catalano, G., & Leone, N. (2007). Enhancing DLV instantiator backjumping techniques. Annals Mathematics Artificial Intelligence, 51 (2-4), 195228.
Ramachandran, D., & Amir, E. (2005). Compact propositional encodings first-order theories..
Veloso, & Kambhampati (Veloso & Kambhampati, 2005), pp. 340345.
Schulz, S. (2002). comparison different techniques grounding near-propositional cnf formulae.
Haller, S. M., & Simmons, G. (Eds.), International Florida Artificial Intelligence Research
Society Conference (FLAIRS), pp. 7276. AAAI Press.
Shlyakhter, I., Sridharan, M., Seater, R., & Jackson, D. (2003). Exploiting subformula sharing
automatic analysis quantified formulas. Poster presented Theory Applications
Satisfiability Testing (SAT), 6th International Conference.
Stockmeyer, L. J. (1974). complexity decision problems automata logic. Ph.D. thesis,
Massachusetts Institute Technology.
Syrjanen, T. (1998). Implementation local grounding logic programs stable model semantics. Tech. rep. B18, Helsinki University Technology, Finland.

268

fiGrounding FO FO(ID) Bounds

Syrjanen, T. (2000).
lparse.ps.gz.

Lparse 1.0 users manual. http://www.tcs.hut.fi/Software/smodels/

Syrjanen, T. (2009). Logic Programs Cardinality Constraints: Theory Practice. Doctoral
dissertation, TKK Dissertations Information Computer Science TKK-ICS-D12, Helsinki
University Technology, Faculty Information Natural Sciences, Department Information Computer Science, Espoo, Finland.
Torlak, E., & Jackson, D. (2007). Kodkod: relational model finder. Grumberg, O., & Huth, M.
(Eds.), International Conference Tools Algorithms Construction Analysis
Systems (TACAS), Vol. 4424 Lecture Notes Computer Science, pp. 632647. Springer.
Ullman, J. D. (1988). Principles database knowledge-base systems, Vol. I. Computer Science
Press, Inc., New York, NY, USA.
Van Gelder, A., Ross, K. A., & Schlipf, J. S. (1991). well-founded semantics general logic
programs. Journal ACM, 38 (3), 620650.
Veloso, M. M., & Kambhampati, S. (Eds.). (2005). Proceedings, Twentieth National Conference
Artificial Intelligence Seventeenth Innovative Applications Artificial Intelligence
Conference, July 9-13, 2005, Pittsburgh, Pennsylvania, USA. AAAI Press / MIT Press.
Wittocx, J., & Marien, M. (2008). idp system. http://www.cs.kuleuven.be/~dtai/krr/
software/idpmanual.pdf.
Wittocx, J., Marien, M., & Denecker, M. (2008a). Approximate reasoning first-order logic theories.
Brewka, G., & Lang, J. (Eds.), International Conference Knowledge Representation
Reasoning (KR), pp. 103112. AAAI Press.
Wittocx, J., Marien, M., & Denecker, M. (2008b). GidL: grounder FO+ . Pagnucco, M., &
Thielscher, M. (Eds.), Workshop Nonmonotonic Reasoning (NMR), pp. 189198. University
New South Wales.
Wittocx, J., Marien, M., & Denecker, M. (2008c). Grounding bounds. Fox, D., & Gomes,
C. P. (Eds.), AAAI Conference Artificial Intelligence, pp. 572577. AAAI Press.
Wittocx, J., Marien, M., & Denecker, M. (2008d). idp system: model expansion system
extension classical logic. Workshop Logic Search (LaSh), pp. 153165.

269

fiJournal Artificial Intelligence Research 38 (2010) 475-511

Submitted 04/10; published 08/10

Minimum Relative Entropy Principle
Learning Acting
Pedro A. Ortega
Daniel A. Braun

peortega@dcc.uchile.cl
dab54@cam.ac.uk

Department Engineering
University Cambridge
Cambridge CB2 1PZ, UK

Abstract
paper proposes method construct adaptive agent universal
respect given class experts, expert designed specifically particular
environment. adaptive control problem formalized problem minimizing
relative entropy adaptive agent expert suitable
unknown environment. agent passive observer, optimal solution
well-known Bayesian predictor. However, agent active, past actions need
treated causal interventions I/O stream rather normal probability
conditions. shown solution new variational problem given
stochastic controller called Bayesian control rule, implements adaptive
behavior mixture experts. Furthermore, shown mild assumptions,
Bayesian control rule converges control law suitable expert.

1. Introduction
behavior environment control signal fully known,
designer choose agent produces desired dynamics. Instances problem include hitting target cannon known weather conditions, solving maze
map controlling robotic arm manufacturing plant. However,
environment unknown, designer faces problem adaptive control.
example, shooting cannon lacking appropriate measurement equipment, finding
way unknown maze designing autonomous robot Martian exploration.
Adaptive control turns far difficult non-adaptive counterpart.
good policy carefully trade explorative versus exploitative actions,
i.e. actions identification environments dynamics versus actions control
desired way. Even environments dynamics known belong particular class optimal agents available, constructing corresponding optimal
adaptive agent general computationally intractable even simple toy problems (Duff,
2002). Thus, finding tractable approximations major focus research.
Recently, proposed reformulate problem statement classes
control problems based minimization relative entropy criterion. example,
large class optimal control problems solved efficiently problem statement
reformulated minimization deviation dynamics controlled system
uncontrolled system (Todorov, 2006, 2009; Kappen, Gomez, & Opper, 2010).
work, similar approach introduced adaptive control. class agents
c
2010
AI Access Foundation. rights reserved.

fiOrtega & Braun

given, agent tailored different environment, adaptive controllers
derived minimum relative entropy principle. particular, one construct
adaptive agent universal respect class minimizing average relative
entropy environment-specific agent.
However, extension straightforward. syntactical difference
actions observations taken account formulating variational
problem. specifically, actions treated interventions obeying rules
causality (Pearl, 2000; Spirtes, Glymour, & Scheines, 2000; Dawid, 2010). distinction
made, variational problem unique solution given stochastic control rule
called Bayesian control rule. control rule particularly interesting
translates adaptive control problem on-line inference problem applied
forward time. Furthermore, work shows mild assumptions, adaptive
agent converges environment-specific agent.
paper organized follows. Section 2 introduces notation sets adaptive
control problem. Section 3 formulates adaptive control minimum relative entropy
problem. initial, nave approach, need causal considerations motivated.
Then, Bayesian control rule derived revised relative entropy criterion.
Section 4, conditions convergence examined proof given. Section 5
illustrates usage Bayesian control rule multi-armed bandit problem
undiscounted Markov decision processes. Section 6 discusses properties Bayesian
control rule relates previous work literature. Section 7 concludes.

2. Preliminaries
following agent environment formalized causal models I/O
sequences. Agent environment coupled exchange symbols following standard
interaction protocol discrete time, observation control signals. treatment
dynamics fully probabilistic, particular, actions observations
random variables, contrast typical decision-theoretic agent formulation
treating observations random variables (Russell & Norvig, 2010). proofs
provided appendix.
Notation. set denoted calligraphic letter like A. words set & alphabet
element & symbol used mean thing respectively. Strings finite
concatenations symbols sequences infinite
concatenations. denotes set


strings length n based A, := n0 set finite strings. Furthermore, := {a1 a2 . . . |ai = 1, 2, . . .} defined set one-way
infinite sequences based alphabet A. Tuples written parentheses (a1 , a2 , a3 )
strings a1 a2 a3 . notation ai := a1 a2 . . . ai shorthand string starting first index. Also, symbols underlined glue together like ao
aoi := a1 o1 a2 o2 . . . ai oi . function log(x) meant taken w.r.t. base 2, unless
indicated otherwise.
Interactions. possible I/O symbols drawn two finite sets. Let denote
set inputs (observations) let denote set outputs (actions). set Z := AO
interaction set. string aot ao<t interaction string (optionally ending
476

fiA Minimum Relative Entropy Principle Learning Acting

ot ) ak ok O. Similarly, one-sided infinite sequence a1 o1 a2 o2 . . .
interaction sequence. set interaction strings length denoted Z .
sets (finite) interaction strings sequences denoted Z Z respectively.
interaction string length 0 denoted .
I/O System. Agents environments formalized I/O systems. I/O system
probability distribution Pr interaction sequences Z . Pr uniquely determined
conditional probabilities
Pr(at |ao<t ),

Pr(ot |ao<t )

(1)

aot Z . conditional probabilities either represent generative law
(propensity) case issuing symbol evidential probability (plausibility)
case observing symbol. two interpretations applies particular case
becomes apparent I/O system coupled another I/O system.

Agent
P

a1 o1 a2 o2 a3 o3 a4 o4 a5 o5

Environment
Q

Figure 1: model interactions. agent P environment Q define probability distribution interaction sequences.

Interaction System. Let P, Q two I/O systems. interaction system (P, Q)
coupling two systems giving rise generative distribution G describes
probabilities actually govern I/O stream two systems coupled. G
specified equations
G(at |ao<t ) := P(at |ao<t )
G(ot |ao<t ) := Q(ot |ao<t )
valid aot Z . Here, G models true probability distribution interaction
sequences arises coupling two systems I/O streams. specifically,
system P, P(at |ao<t ) probability producing action given history
ao<t P(ot |ao<t ) predicted probability observation ot given history
477

fiOrtega & Braun

ao<t . Hence, P, sequence o1 o2 . . . input stream sequence a1 a2 . . .
output stream. contrast, roles actions observations reversed
case system Q. Thus, sequence o1 o2 . . . output stream sequence
a1 a2 . . . input stream. previous model interaction fairly general, many
interaction protocols translated scheme. convention, given
interaction system (P, Q), P agent constructed designer, Q
environment controlled agent. Figure 1 illustrates setup.
Control Problem. environment Q said known iff agent P property
aot Z ,
P(ot |ao<t ) = Q(ot |ao<t ).
Intuitively, means agent knows statistics environments future
behavior past, particular, knows effects given controls.
environment known, designer agent build custom-made policy
P resulting generative distribution G produces interaction sequences
desirable. done multiple ways. instance, controls chosen
resulting policy maximizes given utility criterion; resulting
trajectory interaction system stays close enough prescribed trajectory. Formally,
Q known, conditional probabilities P(at |ao<t ) aot Z
chosen resulting generative distribution G interaction sequences given

G(at |ao<t ) = P(at |ao<t )

G(ot |ao<t ) = Q(ot |ao<t ) = P(ot |ao<t )
desirable, P said tailored Q.
Adaptive Control Problem. environment Q unknown, task designing appropriate agent P constitutes adaptive control problem. Specifically,
work deals case designer already class agents tailored
class possible environments. Formally, assumed Q going drawn
probability P (m) set Q := {Qm }mM possible systems interaction starts, countable set. Furthermore, one set P := {Pm }mM
systems M, Pm tailored Qm interaction system
(Pm , Qm ) generative distribution Gm produces desirable interaction sequences.
designer construct system P behavior close possible
custom-made system Pm realization Qm Q?

3. Adaptive Systems
main goal paper show problem adaptive control outlined
previous section reformulated universal compression problem.
informally motivated follows. Suppose agent P implemented machine
interfaced environment Q. Whenever agent interacts environment,
agents state changes necessary consequence interaction. change
state take place many possible ways: updating internal memory; consulting
478

fiA Minimum Relative Entropy Principle Learning Acting

random number generator; changing physical location orientation; forth.
Naturally, design agent facilitates interactions complicates others.
instance, agent designed explore natural environment, might
incur low memory footprint recording natural images,
memory-inefficient recording artificially created images. one abstracts away
inner workings machine decides encode state transitions binary
strings, minimal amount resources bits required implement
state changes derived directly associated probability distribution P.
context adaptive control, agent constructed minimizes
expected amount changes necessary implement state transitions, equivalently,
maximally compresses experience. Thereby, compression taken
stand-alone principle design adaptive agents.
3.1 Universal Compression Nave Construction Adaptive Agents
coding theory, problem compressing sequence observations unknown
source known adaptive coding problem. solved constructing universal compressors, i.e. codes adapt on-the-fly source within predefined class
(MacKay, 2003). codes obtained minimizing average deviation predictor true source, constructing codewords using predictor.
subsection, procedure used derive adaptive agent (Ortega & Braun, 2010).
Formally, deviation predictor P true distribution Pm measured
relative entropy 1 . first approach would construct agent B
minimize total expected relative entropy Pm . constructed follows. Define
history-dependent relative entropies action observation ot
X
Pm (at |ao<t )

(ao<t ) :=
Dm
Pm (at |ao<t ) log
Pr(at |ao<t )



ot
(ao<t ) :=
Dm

X
ot

Pm (ot |ao<t ) log

Pm (ot |ao<t )
,
Pr(ot |ao<t )

Pm (ot |ao<t ) = Qm (ot |ao<t ) Qm known Pr
argument variational problem. Then, one removes dependency past
averaging possible histories:
X


:=
(ao<t )
Pm (ao<t )Dm
Dm
ao<t

ot
Dm

:=

X

ot
(ao<t ).
Pm (ao<t )Dm

ao<t

Finally, total expected relative entropy Pr Pm obtained summing
time steps averaging choices true environment:
:= lim sup


X

P (m)




X
=1




.
+ Dm
Dm

(2)

1. relative entropy also known KL-divergence measures average amount extra
bits necessary encode symbols due usage (wrong) predictor.

479

fiOrtega & Braun

Using (2), one define variational problem respect Pr. agent B one
looking system Pr minimizes total expected relative entropy (2), i.e.
B := arg min D(Pr).
Pr

solution Equation 3 system B defined set equations
X
B(at |ao<t ) =
Pm (at |ao<t )wm (ao<t )


B(ot |ao<t ) =

X


Pm (ot |ao<t )wm (ao<t )

(3)

(4)

valid aot Z , mixture weights
P (m)Pm (ao<t )

P (m )Pm (ao<t )
P (m)Pm (ao<t )
.
wm (ao<t ) := P

P (m )Pm (ao<t )
wm (ao<t ) := P

(5)

reference, see work Haussler Opper (1997) Opper (1998). clear
B Bayesian mixture agents Pm . one defines conditional
probabilities
P (at |m, ao<t ) := Pm (at |ao<t )
(6)
P (ot |m, ao<t ) := Pm (at |ao<t )

aot Z , Equation 4 rewritten
B(at |ao<t ) =
B(ot |ao<t ) =

X


X


P (at |m, ao<t )P (m|ao<t ) = P (at |ao<t )
P (ot |m, ao<t )P (m|ao<t ) = P (ot |ao<t )

(7)

P (m|ao<t ) = wm (ao<t ) P (m|ao<t ) = wm (ao<t ) posterior
probabilities elements given past interactions. Hence, conditional
probabilities (4) minimize total expected divergence predictive
distributions P (at |ao<t ) P (ot |ao<t ) one obtains standard probability theory,
particular, Bayes rule. interesting, provides teleological interpretation
Bayes rule.
behavior B described follows. given time t, B maintains
mixture systems Pm . weighting given mixture coefficients
wm . Whenever new action new observation ot produced (by agent
environment respectively), weights wm updated according Bayes rule.
addition, B issues action suggested system Pm drawn randomly according
weights wt .
However, important problem B arises due fact
system passively observing symbols, also actively generating them.
subjective interpretation probability theory, conditionals play role observations
480

fiA Minimum Relative Entropy Principle Learning Acting

made agent generated external source. interpretation suits
symbols o1 , o2 , o3 , . . . issued environment. However, symbols generated system require fundamentally different belief update.
Intuitively, difference explained follows. Observations provide information
allows agent inferring properties environment. contrast, actions
carry information environment, thus incorporated differently
belief agent. following section illustrate problem simple
statistical example.
3.2 Causality
Causality study functional dependencies events. stands contrast
statistics, which, abstract level, said study equivalence dependencies
(i.e. co-occurrence correlation) amongst events. Causal statements differ fundamentally
statistical statements. Examples highlight differences many,
smokers get lung cancer? opposed smokers lung cancer?; assign
f (x) opposed compare = f (x) programming languages; F/m
opposed F = Newtonian physics. study causality recently enjoyed
considerable attention researchers fields statistics machine learning.
Especially last decade, significant progress made towards formal
understanding causation (Shafer, 1996; Pearl, 2000; Spirtes et al., 2000; Dawid, 2010).
subsection, aim provide essential tools required understand causal
interventions. in-depth exposition causality, reader referred
specialized literature.
illustrate need causal considerations case generated symbols, consider
following thought experiment. Suppose statistician asked design model
simple time series X1 , X2 , X3 , . . . decides use Bayesian method. Assume
collects first observation X1 = x1 . computes posterior probability density function
(pdf) parameters model given data using Bayes rule:
p(|X1 = x1 ) = R

p(X1 = x1 |)p()
,
p(X1 = x1 | )p( )

p(X1 = x1 |) likelihood x1 given p() prior pdf .
use model predict next observation drawing sample x2 predictive
pdf
Z
p(X2 = x2 |X1 = x1 ) = p(X2 = x2 |X1 = x1 , ) p(|X1 = x1 ) d,
p(X2 = x2 |X1 = x1 , ) likelihood x2 given x1 . Note x2
drawn p(X2 = x2 |X1 = x1 , ). understands nature x2 different
x1 : x1 informative change belief state Bayesian model,
x2 non-informative thus reflection models belief state. Hence, would
never use x2 condition Bayesian model. Mathematically, seems imply

p(|X1 = x1 , X2 = x2 ) = p(|X1 = x1 )
481

fiOrtega & Braun

x2 generated p(X2 |X1 = x1 ) itself. simple independence assumption correct following elaboration example show.
statistician told source waiting simulated data point x2
order produce next observation X3 = x3 depend x2 . hands x2
obtains new observation x3 . Using Bayes rule, posterior pdf parameters

p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X1 = x1 |) p()
R
(8)
p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X1 = x1 | ) p( )
p(X3 = x3 |X1 = x1 , X2 = x2 , ) likelihood new data x3 given old
data x1 , parameters simulated data x2 . Notice looks almost like
posterior pdf p(|X1 = x1 , X2 = x2 , X3 = x3 ) given
R

p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X2 = x2 |X1 = x1 , ) p(X1 = x1 |) p()
p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X2 = x2 |X1 = x1 , ) p(X1 = x1 | ) p( )

exception latter case, Bayesian update contains likelihoods
simulated data p(X2 = x2 |X1 = x1 , ). suggests Equation 8 variant
posterior pdf p(|X1 = x1 , X2 = x2 , X3 = x3 ) simulated data x2 treated
different way data x1 x3 .
Define pdf p pdfs p (), p (X1 |), p (X3 |X1 , X2 , ) identical
p(), p(X1 |) p(X3 |X2 , X1 , ) respectively, differ p (X2 |X1 , ):
p (X2 |X1 , ) = (X2 x2 ).
Dirac delta function. is, p identical p assumes
value X2 fixed x2 given X1 . p , simulated data x2 non-informative:
log2 p (X2 = x2 |X1 , ) = 0.
one computes posterior pdf p (|X1 = x1 , X2 = x2 , X3 = x3 ), one obtains result
Equation 8:
R

p (X3 = x3 |X1 = x1 , X2 = x2 , ) p (X2 = x2 |X1 = x1 , ) p (X1 = x1 |) p ()
p (X3 = x3 |X1 = x1 , X2 = x2 , )p (X2 = x2 |X1 = x1 , ) p (X1 = x1 | ) p ( )
p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X1 = x1 |) p()
=R
.
p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X1 = x1 | ) p( )

Thus, order explain Equation 8 posterior pdf given observed data x1 x3
generated data x2 , one intervene p order account fact x2
non-informative given x1 . words, statistician, defining value
X2 herself2 , changed (natural) regime brings series X1 , X2 , X3 , . . .,
mathematically expressed redefining pdf.
Two essential ingredients needed carry interventions. First, one needs
know functional dependencies amongst random variables probabilistic model.
provided causal model, i.e. unique factorization joint probability
2. Note conceptually broken two steps: first, samples x2 p(X2 |X1 = x1 );
second, imposes value X2 = x2 setting p (X2 |X1 , ) = (X2 x2 ).

482

fiA Minimum Relative Entropy Principle Learning Acting

distribution random variables encoding causal dependencies. general
case, defines partial order random variables. previous thought experiment, causal model joint pdf p(, X1 , X2 , X3 ) given set conditional
pdfs
p(), p(X1 |), p(X2 |X1 , ), p(X3 |X1 , X2 , ).
Second, one defines intervention sets X value x, denoted X x,
operation causal model replacing conditional probability X Dirac
delta function (X x) Kronecker delta xX continuous discrete variable X
respectively. thought experiment, easily seen
p (, X1 = x1 , X2 = x2 , X3 = x3 ) = p(, X1 = x1 , X2 x2 , X3 = x3 )
thereby,
p (|X1 = x1 , X2 = x2 , X3 = x3 ) = p(|X1 = x1 , X2 x2 , X3 = x3 ).
Causal models contain additional information available joint probability
distribution alone. appropriate model given situation depends story
told. Note intervention lead different results respective causal
models differ. Thus, causal model
p(X3 ), p(X2 |X3 ), p(X1 |X2 , X3 ), p(|X1 , X2 , X3 )
intervention X2 x2 would differ p , i.e.
p (, X1 = x1 , X2 = x2 , X3 = x3 ) 6= p(, X1 = x1 , X2 x2 , X3 = x3 ),
even though causal models represent joint probability distribution.
following, paper use shorthand notation x := X x random variable
obvious context.
3.3 Causal Construction Adaptive Agents
Following discussion previous section, adaptive agent P going constructed minimizing expected relative entropy expected Pm , time
treating actions interventions. Based definition conditional probabilities
Equation 6, total expected relative entropy characterize P using interventions going defined. Assuming environment chosen first, symbol depends
functionally environment previously generated symbols, causal model
given
P (m), P (a1 |m), P (o1 |m, a1 ), P (a2 |m, a1 , o1 ), P (o2 |m, a1 , o1 , a2 ), . . .
Importantly, interventions index set intervened probability distributions derived
base probability distribution. Hence, set fixed intervention sequences form
a1 , a2 , . . . indexes probability distributions observation sequences o1 , o2 , . . ..
this, one defines set criteria indexed intervention sequences,
483

fiOrtega & Braun

clear solution. Define history-dependent intervened relative
entropies action observation ot

(ao<t ) :=
Cm

X


ot
(ao<t ) :=
Cm

X
ot

P (at |m, ao<t ) log2

P (at |m, ao<t )
Pr(at |ao<t )

P (ot |m, ao<t ) log2

P (ot |m, ao<t )
,
Pr(ot |ao<t )

Pr given arbitrary agent. Note past actions treated interventions.
particular, P (at |m, ao<t ) represents knowledge state past actions already
issued next action known yet. Then, averaging previous relative
entropies pasts yields

=
Cm

X

ao<t
ot
=
Cm


(ao<t )
P (ao<t |m)Cm

X

ao<t

ot
(ao<t ).
P (ao<t |m)Cm

(ao ) C ot (ao ),
again, knowledge state time represented Cm
<t
<t

averages taken treating past actions interventions. Finally, define total exat + C ot ) time, averaged
pected relative entropy Pr Pm sum (Cm

possible draws environment:

C := lim sup


X

P (m)




X
=1




+ Cm
Cm
.

(9)

variational problem consists choosing agent P system Pr minimizing
C = C(Pr), i.e.
P := arg min C(Pr).
(10)
Pr

following theorem shows variational problem unique solution,
central theme paper.
Theorem 1. solution Equation 10 system P defined set equations
X

P(at |ao<t ) = P (at |ao<t ) =



P(ot |ao<t ) = P (ot |ao<t ) =

P (at |m, ao<t )vm (ao<t )

X


P (ot |m, ao<t )vm (ao<t )

(11)

valid aot Z , mixture weights
Qt1

=1 P (o |m, ao< )
.
Qt1


=1 P (o |m , ao< )
P (m )

vm (ao<t ) = vm (ao<t ) := P

P (m)

484

(12)

fiA Minimum Relative Entropy Principle Learning Acting

Bayesian Control Rule: Given set operation modes {P (|m, )}mM
interaction sequences Z prior distribution P (m)
parameters M, probability action at+1 given
X
P (at+1 |m, aot )P (m|aot ),
(13)
P (at+1 |aot ) =


posterior probability operation modes given recursion
P (ot |m, ao<t )P (m|ao<t )
.


P (ot |m , ao<t )P (m |ao<t )

P (m|aot ) = P

Table 1: Summary Bayesian control rule.
theorem says optimal solution variational problem (10) precisely
predictive distribution actions observations treating actions interventions
observations conditionals, i.e. solution one would obtain applying
standard probability causal calculus. provides teleological interpretation
agent P akin nave agent B constructed Section 3.1. behavior P differs
important aspect B. given time t, P maintains mixture systems
Pm . weighting systems given mixture coefficients vm . contrast
B, P updates weights vm whenever new observation ot produced
environment. update follows Bayes rule treats past actions interventions
dropping evidence provide. addition, P issues action suggested
system drawn randomly according weights vm .
3.4 Summary
Adaptive control formalized problem designing agent unknown environment chosen class possible environments. environment-specific agents
known, Bayesian control rule allows constructing adaptive agent combining
agents. resulting adaptive agent universal respect environment
class. context, constituent agents called operation modes adaptive
agent. represented causal models interaction sequences, i.e. conditional
probabilities P (at |m, ao<t ) P (ot |m, ao<t ) aot Z ,
index parameter characterizing operation mode. probability distribution
input stream (output stream) called hypothesis (policy) operation mode.
Table 1 collects essential equations Bayesian control rule. particular,
rule stated using recursive belief update.

4. Convergence
aim section develop set sufficient conditions convergence
provide proof convergence. simplify exposition, analysis limited
485

fiOrtega & Braun

case controllers finite number input-output models.

4.1 Policy Diagrams
following use policy diagrams useful informal tool analyze effect
policies environments. Figure 2 illustrates example.

state space


ao



policy

Figure 2: policy diagram. One imagine environment collection states
connected transitions labeled I/O symbols. zoom highlights state
taking action collecting observation leads state .
Sets states transitions represented enclosed areas similar Venn
diagram. Choosing particular policy environment amounts partially
controlling transitions taken state space, thereby choosing probability
distribution state transitions (e.g. Markov chain given environmental
dynamics). probability mass concentrates certain areas state space,
choosing policy thought choosing subset environments
dynamics. following, policy represented subset state space
(enclosed directed curve) illustrated above.

Policy diagrams especially useful analyze effect policies different hypotheses environments dynamics. agent endowed set operation
modes seen hypotheses environments underlying dynamics,
given observation models P (ot |m, ao<t ), associated policies, given action models P (at |m, ao<t ), M. sake simplifying interpretation
policy diagrams, assume existence state space : (A O) mapping
I/O histories states. Note however assumptions made obtain
results section.
4.2 Divergence Processes
central question section investigate whether Bayesian control rule converges correct control law not. is, whether P (at |aot ) P (at |m , ao<t )
true operation mode, i.e. operation mode P (ot |m , ao<t ) =
Q(ot |ao<t ). obvious discussion rest section,
general true.
easily seen Equation 13, showing convergence amounts show
posterior distribution P (m|ao<t ) concentrates probability mass subset operation
486

fiA Minimum Relative Entropy Principle Learning Acting

modes essentially output stream ,
X
X
P (at |m, ao<t )P (m|ao<t )
P (at |m , ao<t )P (m|ao<t ) P (at |m , ao<t ).
mM

mM

Hence, understanding asymptotic behavior posterior probabilities
P (m|aot )
crucial here. particular, need understand conditions quantities
converge zero. posterior rewritten
Q
P (aot |m)P (m)
P (m) =1 P (o |m, ao< )
.
=P
P (m|aot ) = P
Qt




P (aot |m )P (m )
P (m )
=1 P (o |m , ao< )

summands one index dropped denominator, one
obtains bound
P (m|aot )


P (m) P (o |m, ao< )
,
P (m )
P (o |m , ao< )
=1

valid M. inequality, seen convenient
analyze behavior stochastic process


dt (m km) :=


X
=1

ln

P (o |m , ao< )
P (o |m, ao< )

divergence process reference . Indeed, dt (m km)
,

P (m)
P (m) P (o |m, ao< )

= lim
edt (m km) = 0,



P (m )
P (o |m , ao< ) P (m )

lim

=1

thus clearly P (m|aot ) 0. Figure 3 illustrates simultaneous realizations
divergence processes controller. Intuitively speaking, processes provide lower
bounds accumulators surprise value measured information units.
divergence process random walk whose value time depends whole
history time t1. makes divergence processes cumbersome characterize
fact statistical properties depend particular policy applied;
hence, given divergence process different growth rates depending policy
(Figure 4). Indeed, behavior divergence process might depend critically
distribution actions used. example, happen divergence process
stays stable one policy, diverges another. context Bayesian
control rule problem aggravated, time step, policy
applied determined stochastically. specifically, true operation mode,
dt (m km) random variable depends realization aot drawn




=1

P (a |m , ao )P (o |m , ao ),
487

fiOrtega & Braun

dt
1
2
3
4


0

Figure 3: Realization divergence processes 1 4 associated controller
operation modes m1 m4 . divergence processes 1 2 diverge, whereas 3
4 stay dotted bound. Hence, posterior probabilities m1
m2 vanish.

dt
1

2
3

2

1
0

3


Figure 4: application different policies lead different statistical properties
divergence process.

488

fiA Minimum Relative Entropy Principle Learning Acting

m1 , m2 , . . . , mt drawn P (m1 ), P (m2 |ao1 ), . . . , P (mt |ao<t ).
deal heterogeneous nature divergence processes, one introduce
temporal decomposition demultiplexes original process many sub-processes
belonging unique policies. Let Nt := {1, 2, . . . , t} set time steps time t.
Let Nt , let m, M. Define sub-divergence dt (m km) random variable
X P (o |m , ao )
<
gm (m; ) :=
ln
P (o |m, ao< )


drawn

Pm ({ao } |{ao } ) :=







P (a |m , ao< )
P (o |m , ao< ) ,


:= Nt \ {ao } given conditions kept constant.
definition, plays role policy used sample actions time
steps . Clearly, realization divergence process dt (m km) decomposed
sum sub-divergences, i.e.
X
gm (m; Tm ),
dt (m km) =
(14)


{Tm }mM forms partition Nt . Figure 5 shows example decomposition.
dt
1
2
3



0

Figure 5: Decomposition divergence process (1) sub-divergences (2 & 3).
averages sub-divergences play important role analysis. Define
average realizations gm (m; )
X
Pm ({ao } |{ao } )gm (m; ).
Gm (m; ) :=
(ao )

Notice Nt ,
X
P (o |m , ao< )
P (a |m , ao< )P (o |m , ao< ) ln
0,
Gm (m; { }) =
P (o |m, ao< )
ao


Gibbs inequality. particular,

Gm (m ; { }) = 0.

Clearly, holds well Nt :


Gm (m; ) 0,

Gm (m ; ) = 0.
489

(15)

fiOrtega & Braun

4.3 Boundedness
general, divergence process complex: virtually classes distributions
interest control go well beyond assumptions i.i.d. stationarity.
increased complexity jeopardize analytic tractability divergence process,
predictions asymptotic behavior made anymore. specifically,
growth rates divergence processes vary much realization realization, posterior distribution operation modes vary qualitatively
realizations. Hence, one needs impose stability requirement akin ergodicity limit
class possible divergence-processes class analytically tractable.
purpose following property introduced.
divergence process dt (m km) said bounded variation iff > 0,
C 0, M, Nt
fi
fi
fi
fi
figm (m; ) Gm (m; )fi C
probability 1 .

dt

1

2

3



0

Figure 6: divergence process bounded variation, realizations (curves 2 &
3) sub-divergence stay within band around mean (curve 1).
Figure 6 illustrates property. Boundedness key property going
used construct results section. first important result posterior
probability true input-output model bounded below.
Theorem 2. Let set operation modes controller
divergence process dt (m km) bounded variation. Then, > 0, > 0,
N,

P (m |aot )
|M|

probability 1 .
4.4 Core

one wants identify operation modes whose posterior probabilities vanish,
enough characterize modes whose hypothesis match
true hypothesis. Figure 7 illustrates problem. Here, three hypotheses along
associated policies shown. H1 H2 share prediction made region differ
490

fiA Minimum Relative Entropy Principle Learning Acting

region B. Hypothesis H3 differs everywhere others. Assume H1 true. long
apply policy P2 , hypothesis H3 make wrong predictions thus divergence
process diverge expected. However, evidence H2 accumulated.
one applies policy P1 long enough time controller eventually
enter region B hence accumulate counter-evidence H2 .
H1

H2

B


H3

B


P3

P1
P2

Figure 7: hypothesis H1 true agrees H2 region A, policy P2 cannot
disambiguate three hypotheses.

long enough mean? P1 executed short period,
controller risks visiting disambiguating region. unfortunately, neither right
policy right length period run known beforehand. Hence, agent
needs clever time-allocating strategy test policies finite time intervals.
motivates following definition.
core operation mode , denoted [m ], subset containing
operation modes behaving like policy. formally, operation mode

/ [m ] (i.e. core) iff C 0, > 0, > 0 t0 N,
t0 ,
Gm (m; ) C
probability 1 , Gm (m; ) sub-divergence dt (m km), Pr{
} Nt .
words, agent apply policy time step probability
least , strategy expected sub-divergence Gm (m; ) dt (m km) grows
unboundedly, core . Note demanding strictly positive
probability execution time step guarantees agent run
possible finite time-intervals. following theorem shows, posterior probabilities
operation modes core vanish almost surely.
Theorem 3. Let set operation modes agent
divergence process dt (m km) bounded variation.
/ [m ], P (m|aot ) 0
almost surely.
4.5 Consistency
Even operation mode core , i.e. given essentially indistinguishable control, still happen different
policies. Figure 8 shows example this. hypotheses H1 H2 share region
491

fiOrtega & Braun

differ region B. addition, operation modes policies P1 P2 respectively confined region A. Note operation modes core other.
However, policies different. means unclear whether multiplexing
policies time ever disambiguate two hypotheses. undesirable, could
impede convergence right control law.
H2

H1
B

B
P2

P1





Figure 8: example inconsistent policies. operation modes core
other, different policies.

Thus, clear one needs impose restrictions mapping hypotheses policies. respect Figure 8, one make following observations:
1. operation modes policies select subsets region A. Therefore,
dynamics preferred dynamics B.
2. Knowing dynamics preferred dynamics B allows us
drop region B analysis choosing policy.
3. Since hypotheses agree region A, choose policy order
consistent selection criterion.
motivates following definition. operation mode said consistent
iff [m ] implies < 0, t0 , t0
ao<t ,
fi
fi
fi
fi
fiP (at |m, aot ) P (at |m , aot )fi < .

words, core , ms policy converge policy.
following theorem shows consistency sufficient condition convergence
right control law.
Theorem 4. Let set operation modes agent that:
divergence process dt (m km) bounded variation; m, M, consistent
. Then,
P (at |ao<t ) P (at |m , ao<t )
almost surely .
492

fiA Minimum Relative Entropy Principle Learning Acting

4.6 Summary
section, proof convergence Bayesian control rule true operation
mode provided finite set operation modes. convergence result
hold, two necessary conditions assumed: boundedness consistency. first one,
boundedness, imposes stability divergence processes partial influence
policies contained within set operation modes. condition regarded
ergodicity assumption. second one, consistency, requires hypothesis makes
predictions another hypothesis within relevant subset dynamics,
hypotheses share policy. relevance formalized core
operation mode. concepts proof strategies strengthen intuition potential
pitfalls arise context controller design. particular could show
asymptotic analysis recast study concurrent divergence processes
determine evolution posterior probabilities operation modes, thus abstracting
away details classes I/O distributions. extension results
infinite sets operation modes left future work. example, one could think
partitioning continuous space operation modes essentially different regions
representative operation modes subsume neighborhoods (Grunwald, 2007).

5. Examples
section illustrate usage Bayesian control rule two examples
common reinforcement learning literature: multi-armed bandits Markov
decision processes.
5.1 Bandit Problems
Consider multi-armed bandit problem (Robbins, 1952). problem stated follows.
Suppose N -armed bandit, i.e. slot-machine N levers. pulled, lever
provides reward drawn Bernoulli distribution bias hi specific lever.
is, reward r = 1 obtained probability hi reward r = 0 probability
1hi . objective game maximize time-averaged reward iterative
pulls. continuum range stationary strategies, one parameterized N
probabilities {si }N
i=1 indicating probabilities pulling lever. difficulty arising
bandit problem balance reward maximization based knowledge already
acquired attempting new actions improve knowledge. dilemma known
exploration versus exploitation tradeoff (Sutton & Barto, 1998).
ideal task Bayesian control rule, possible bandit
known optimal agent. Indeed, bandit represented N -dimensional bias vector
= [m1 , . . . , mN ] = [0; 1]N . Given bandit, optimal policy consists
pulling lever highest bias. is, operation mode given by:
hi = P (ot = 1|m, = i) = mi

si = P (at = i|m) =

493

(

1 = maxj {mj },
0 else.

fiOrtega & Braun

m2

0

a)

1

b)
m1 m2

m2

1

1

m2 m1 , 3

m3
0

m1

0
0

m1

1

1

Figure 9: space bandit configurations partitioned N regions according
optimal lever. Panel b show 2-armed 3-armed bandit cases
respectively.

apply Bayesian control rule, necessary fix prior distribution
bandit configurations. Assuming uniform distribution, Bayesian control rule
Z
(16)
P (at+1 = i|m)P (m|aot )
P (at+1 = i|aot ) =


update rule given
Q
r
N

mj j (1 mj )fj
P (m) =1 P (o |m, )
=
P (m|aot ) = R
Qt



B(rj + 1, fj + 1)
=1 P (o |m , ) dm
P (m )
j=1

(17)

rj fj counts number times reward obtained
pulling lever j number times reward obtained respectively. Observe
summation discrete operation modes replaced integral
continuous space configurations. last expression see posterior
distribution lever biases given product N Beta distributions. Thus,
sampling action amounts first sample operation mode obtaining bias
mi Beta distribution parameters ri + 1 fi + 1, choosing
action corresponding highest bias = arg maxi mi . pseudo-code seen
Algorithm 1.
Simulation: Bayesian control rule described compared two
agents: -greedy strategy decay (on-line) Gittins indices (off-line).
test bed consisted bandits N = 10 levers whose biases drawn uniformly
beginning run. Every agent play 1000 runs 1000 time steps each.
Then, performance curves individual runs averaged. -greedy strategy
selects random action small probability given otherwise plays
lever highest expected reward. parameters determined empirically
values = 0.1, = 0.99 several test runs. adjusted way
maximize average performance last trials simulations. Gittins
method, indices computed horizon 1300 using geometric discounting
= 0.999, i.e. close one approximate time-averaged reward. results
shown Figure 10.
494

fiA Minimum Relative Entropy Principle Learning Acting

Algorithm 1 BCR bandit.
= 1, . . . , N
Initialize ri fi zero.
end
= 1, 2, 3, . . .
Sample using (17).
{ Interaction }
Set arg maxi mi issue a.
Obtain environment.

Avg. Reward

{Update belief}
= 1
ra = ra + 1
else
fa = fa + 1
end
end

0.85
0.80

Bayesian control rule
-greedy
Gittins indices

0.75
0.70
0

200

400

600

800

1000

0

200

400

600

800

1000

% Best Lever

100
80
60
40
20
0

Figure 10: Comparison N -armed bandit problem Bayesian control rule (solid
line), -greedy agent (dashed line) using Gittins indices (dotted line).
1,000 runs averaged. top panel shows evolution average
reward. bottom panel shows evolution percentage times
best lever pulled.

495

fiOrtega & Braun

seen -greedy strategy quickly reaches acceptable level performance,
seems stall significantly suboptimal level, pulling optimal lever 60%
time. contrast, Gittins strategy Bayesian control rule show essentially asymptotic performance, differ initial transient phase
Gittins strategy significantly outperforms Bayesian control rule. least three
observations worth making here. First, Gittins indices pre-computed
off-line. time complexity scales quadratically horizon, computations
horizon 1300 steps took several hours machines. contrast, Bayesian
control rule could applied without pre-computation. Second, even though Gittins
method actively issues optimal information gathering actions Bayesian control
rule passively samples actions posterior distribution operation modes,
end methods rely convergence underlying Bayesian estimator.
implies methods information bottleneck, since Bayesian estimator requires amount information converge. Thus, active information gathering
actions affect utility transient phase, permanent state. efficient algorithms bandit problems found literature (Auer, CesaBianchi, &
Fischer, 2002).
5.2 Markov Decision Processes
Markov Decision Process (MDP ) defined tuple (X , A, T, r): X state space;
action space; Ta (x; x ) = Pr(x |a, x) probability action
taken state x X lead state x X ; r(x, a) R := R immediate
reward obtained state x X action A. interaction proceeds time steps
= 1, 2, . . . time t, action issued state xt1 X , leading reward
rt = r(xt1 , ) new state xt starts next time step + 1. stationary closedloop control policy : X assigns action state. MDPs always
exists optimal stationary deterministic policy thus one needs consider
policies. undiscounted MDPs average rewardPper time step fixed policy
initial state x defined (x) = limt E [ 1t =0 r ]. shown (Bertsekas,
1987) (x) = (x ) x, x X assumption Markov chain
policy ergodic. Here, assume MDPs ergodic stationary policies.
order keep intervention model particularly simple3 , follow Q-notation
Watkins (1989). optimal policy characterized terms optimal
average reward optimal relative Q-values Q(x, a) state-action pair (x, a)
solutions following system non-linear equations (Singh, 1994):

3. brute-force adaptive agent problem would roughly look follows. First, agent
starts prior distribution MDPs, e.g. product Dirichlet distributions transition
probabilities. Then, cycle, agent samples full transition matrix distribution
solves using dynamic programming. computed optimal policy, uses issue
next action, discards policy. Subsequently, updates distribution MDPs using
next observed state. However, main text follow different approach avoids solving
MDP every time step.

496

fiA Minimum Relative Entropy Principle Learning Acting

state x X action A,
Q(x, a) + = r(x, a) +

X

x X


h

Q(x
,

)
Pr(x |x, a) max



fi

h
fi
= r(x, a) + Ex max
x,

.
Q(x
,

)
fi


(18)



optimal policy defined (x) := arg maxa Q(x, a) state x X .
setup allows straightforward solution Bayesian control rule,
learnable MDP (characterized Q-values average reward)
known solution . Accordingly, operation mode given = [Q, ] =
R|A||O|+1 . obtain likelihood model inference m, realize Equation 18
rewritten predicts instantaneous reward r(x, a) sum mean
instantaneous reward plus noise term given Q-values average reward
MDP labeled
r(x, a) = Q(x, a) + max
Q(x , ) + max
Q(x , ) E[max
Q(x , )|x, a]



|
{z
}
{z
}
|
noise

mean instantaneous reward (x,a,x )

Assuming reasonably approximated normal distribution N(0, 1/p)
precision p, write likelihood model immediate reward r using
Q-values average reward, i.e.
r

n p
p

2
P (r|m, x, a, x ) =
(19)
exp (r (x, a, x )) .
2
2

order determine intervention model operation mode, simply exploit
properties Q-values, gives
(
1 = arg maxa Q(x, )
P (a|m, x) =
(20)
0 else.
apply Bayesian control rule, posterior distribution P (m|at , xt ) needs
computed. Fortunately, due simplicity likelihood model, one easily devise
conjugate prior distribution apply standard inference methods (see Appendix A.5). Actions determined sampling operation modes posterior executing
action suggested corresponding intervention models. resulting algorithm
similar Bayesian Q-learning (Dearden, Friedman, & Russell, 1998; Dearden, Friedman, & Andre, 1999), differs way actions selected. pseudo-code listed
Algorithm 2.
Simulation: tested MDP-agent grid-world example. give intuition
achieved performance, results contrasted achieved R-learning.
used R-learning variant presented work Singh (1994, Algorithm 3)
together uncertainty exploration strategy (Mahadevan, 1996). corresponding
update equations

Q(x, a) (1 )Q(x, a) + r + max
Q(x , )



(21)

(1 ) + r + max
Q(x
,

)

Q(x,
a)
,



497

fiOrtega & Braun

Algorithm 2 BCR-MDP Gibbs sampler.
Initialize entries zero.
Set initial state x x0 .
= 1, 2, 3, . . .
{Gibbs sweep}
Sample using (30).
Q(y, b) visited states
Sample Q(y, b) using (31).
end
{ Interaction }
Set arg maxa Q(x, ) issue a.
Obtain = (r, x ) environment.
{Update hyperparameters}
)(x,a,x )+p r
(x, a, x ) (x,a,x
(x,a,x )+p
(x, a, x ) (x, a, x ) + p
Set x x .
end

goal

membranes

b) Bayesian control rule

c) R-learning, C=5

d) R-learning, C=30

initial 5,000 steps

a) 7x7 Maze

e) R-learning, C=200

f) Average Reward
0.4
0.3

C=30
C=5

0.2

low
probability

C=200
0.1

last 5,000 steps

high
probability

Bayesian control rule
0.0
0

125

250

375

500

x1000 time steps

Figure 11: Results 77 grid-world domain. Panel (a) illustrates setup. Columns
(b)-(e) illustrate behavioral statistics algorithms. upper lower
row calculated first last 5,000 time steps randomly
chosen runs. probability state color-encoded, arrows
represent frequent actions taken agents. Panel (f) presents
curves obtained averaging ten runs.

498

fiA Minimum Relative Entropy Principle Learning Acting

Average Reward
BCR
R-learning, C = 200
R-learning, C = 30
R-learning, C = 5

0.3582 0.0038
0.2314 0.0024
0.3056 0.0063
0.2049 0.0012

Table 2: Average reward attained different algorithms end run.
mean standard deviation calculated based 10 runs.

, > 0 learning rates. exploration strategy chooses fixed probability
C
pexp > 0 action maximizes Q(x, a) + F (x,a)
, C constant, F (x, a)
represents number times action tried state x. Thus, higher values
C enforce increased exploration.
study (Mahadevan, 1996), grid-world described especially useful
test bed analysis RL algorithms. purposes, particular interest
easy design experiments containing suboptimal limit-cycles. Figure 11, panel
(a), illustrates 7 7 grid-world. controller learn policy leads
initial location goal state. step, agent move adjacent
space (up, down, left right). agent reaches goal state next position
randomly set square grid (with uniform probability) start another trial.
also one-way membranes allow agent move one direction
other. experiments, membranes form inverted cups
agent enter side leave bottom, playing role
local maximum. Transitions stochastic: agent moves correct square
9
probability p = 10
free adjacent spaces (uniform distribution)
1
probability 1 p = 10 . Rewards assigned follows. default reward r = 0.
agent traverses membrane obtains reward r = 1. Reaching goal state
assigns r = 2.5. parameters chosen simulation following.
MDP-agent, chosen hyperparameters 0 = 1 0 = 1 precision p = 1.
R-learning, chosen learning rates = 0.5 = 0.001, exploration
constant set C = 5, C = 30 C = 200. total 10 runs carried
algorithm. results presented Figure 11 Table 2. R-learning
learns optimal policy given sufficient exploration (panels & e, bottom row), whereas
Bayesian control rule learns policy successfully. Figure 11f, learning curve
R-learning C = 5 C = 30 initially steeper Bayesian controller. However,
latter attains higher average reward around time step 125,000 onwards. attribute
shallow initial transient phase distribution operation modes
flat, also reflected initially random exploratory behavior.

6. Discussion
key idea work extend minimum relative entropy principle, i.e.
variational principle underlying Bayesian estimation, problem adaptive control.
499

fiOrtega & Braun

coding point view, work extends idea maximal compression
observation stream whole experience agent containing agents actions
observations. minimizes amount bits write saving/encoding
I/O stream, also minimizes amount bits required produce/decode
action (MacKay, 2003, Ch. 6).
extension non-trivial, important caveat coding I/O sequences: unlike observations, actions carry information could used
inference adaptive coding actions issued decoder itself. problem
inference ones actions logically inconsistent leads paradoxes
(Nozick, 1969). seemingly innocuous issue turned intricate
investigated intensely recent past researchers focusing issue
causality (Pearl, 2000; Spirtes et al., 2000; Dawid, 2010). work contributes body
research providing evidence actions cannot treated using probability
calculus alone.
causal dependencies carefully taken account, minimizing relative
entropy leads rule adaptive control called Bayesian control rule.
rule allows combining class task-specific agents agent universal
respect class. resulting control law simple stochastic control rule
completely general parameter-free. analysis paper shows, control
rule converges true control law mild assumptions.
6.1 Critical Issues
Causality. Virtually every adaptive control method literature successfully treats
actions conditionals observation streams never worries causality.
Thus, bother interventions? decision-theoretic setup, decision
maker chooses policy maximizing
P expected utility U outcomes
, i.e. := arg max E[U |] = Pr(|)U (). Choosing formally
equivalent choosing Kronecker delta function probability distribution
policies. case, conditional probabilities Pr(|) Pr(|) coincide,
since
Pr(, ) = Pr()Pr(|) = Pr(|) = Pr(, ).
sense, choice policy causally precedes interactions.
discussed Section 3 however, uncertainty policy (i.e. Pr() 6=
), causal belief updates crucial. Essentially, problem arises
uncertainty policy resolved interactions. Hence, treating
actions interventions seamlessly extends status random variables.
prior probabilities/likelihood models/policies come from? predictor
Bayesian control rule essentially Bayesian predictor thereby entails (almost) modeling paradigm. designer define class hypotheses
environments, construct appropriate likelihood models, choose suitable
prior probability distribution capture models uncertainty. Similarly, sufficient domain knowledge, analogous procedure applied construct suitable
operation modes. However, many situations difficult even
500

fiA Minimum Relative Entropy Principle Learning Acting

intractable problem itself. example, one design class operation modes
pre-computing optimal policies given class environments. Formally, let
class hypotheses modeling environments let class policies. Given
utility criterion U , define set operation modes := {m } constructing operation mode := (, ), , := arg max E[U |, ].
However, computing optimal policy many cases intractable.
cases, remedied characterizing operation modes optimality
equations solved probabilistic inference example MDP
agent Section 5.2. Recently, applied similar approach adaptive control
problems linear quadratic regulators (Braun & Ortega, 2010).
Problems Bayesian methods. Bayesian control rule treats adaptive control
problem Bayesian inference problem. Hence, problems typically associated
Bayesian methods carry agents constructed Bayesian control
rule. problems analytical computational nature. example,
many probabilistic models posterior distribution
closed-form solution. Also, exact probabilistic inference general computationally
intensive. Even though large literature efficient/approximate inference algorithms particular problem classes (Bishop, 2006), many
suitable on-line probabilistic inference realistic environment classes.
Bayesian control rule versus Bayes-optimal control. Directly maximizing (subjective) expected utility given environment class minimizing
expected relative entropy given class operation modes. two methods
based different assumptions optimality principles. such, Bayesian
control rule Bayes-optimal controller. Indeed, easy design experiments
Bayesian control rule converges exponentially slower (or converge
all) Bayes-optimal controller maximum utility. Consider following
simple example: Environment 1 k-state MDP k consecutive actions
reach state reward +1. interception B-action leads back
initial state. Consider second environment like first actions
B interchanged. Bayes-optimal controller figures true environment k
actions (either k consecutive Bs). Consider Bayesian control rule:
optimal action Environment 1 A, Environment 2 B. uniform ( 21 , 21 ) prior
operation modes stays uniform posterior long reward
observed. Hence Bayesian control rule chooses time-step B
equal probability. policy takes 2k actions accidentally choose
row (or Bs) length k. Bayesian control rule optimal
too. Bayes-optimal controller converges time k, Bayesian control
rule needs exponentially longer. One way remedy problem might allow
Bayesian control rule sample actions operation mode several
time steps row rather randomizing controllers every cycle. However,
one considers non-stationary environments strategy
also break down. Consider, example, increasing MDP k = 10 , Bayes-optimal
controller converges 100 steps, Bayesian control rule converge
realizations, boundedness assumption violated.
501

fiOrtega & Braun

6.2 Relation Existing Approaches
ideas underlying work unique Bayesian control rule.
following selection previously published work recent Bayesian reinforcement
learning literature related ideas found.
Compression principles. literature, important amount work
relating compression intelligence (MacKay, 2003; Hutter, 2004b). particular,
even proposed compression ratio objective quantitative measure
intelligence (Mahoney, 1999). Compression also used basis theory
curiosity, creativity beauty (Schmidhuber, 2009).
Mixture experts. Passive sequence prediction mixing experts studied
extensively literature (Cesa-Bianchi & Lugosi, 2006). study onlinepredictors (Hutter, 2004a), Bayes-optimal predictors mixed. Bayes-mixtures
also used universal prediction (Hutter, 2003). control case, idea
using mixtures expert-controllers previously evoked models like
MOSAIC-architecture (Haruno, Wolpert, & Kawato, 2001). Universal learning
Bayes mixtures experts reactive environments studied work
Poland Hutter (2005) Hutter (2002).
Stochastic action selection. idea using actions random variables,
problems entails, expressed work Hutter (2004b, Problem
5.1). study Section 3 regarded thorough investigation open
problem. stochastic action selection approaches found thesis Wyatt (1997) examines exploration strategies (PO)MDPs, learning automata
(Narendra & Thathachar, 1974) probability matching (Duda, Hart, & Stork,
2001) amongst others. particular, thesis discusses theoretical properties
extension probability matching context multi-armed bandit problems.
There, proposed choose lever according likely optimal
shown strategy converges, thus providing simple method guiding
exploration.
Relative entropy criterion. usage minimum relative entropy criterion
derive control laws underlies KL-control methods developed work Todorov
(2006, 2009) Kappen et al. (2010). There, shown large class
optimal control problems solved efficiently problem statement
reformulated minimization deviation dynamics controlled
system uncontrolled system. related idea conceptualize planning
inference problem (Toussaint, Harmeling, & Storkey, 2006). approach based
equivalence maximization expected future return likelihood
maximization applicable MDPs POMDPs. Algorithms based
duality become active field current research. See example work
Rasmussen Deisenroth (2008), fast model-based RL techniques
used control continuous state action spaces.
502

fiA Minimum Relative Entropy Principle Learning Acting

7. Conclusions
work introduces Bayesian control rule, Bayesian rule adaptive control.
key feature rule special treatment actions based causal calculus
decomposition adaptive agent mixture operation modes, i.e. environmentspecific agents. rule derived minimizing expected relative entropy
true operation mode carefully distinguishing actions observations. Furthermore, Bayesian control rule turns exactly predictive distribution
next action given past interactions one would obtain using probability
causal calculus. Furthermore, shown agents constructed Bayesian
control rule converge true operation mode mild assumptions: boundedness,
related ergodicity; consistency, demanding two indistinguishable hypotheses share policy.
presented Bayesian control rule way solve adaptive control problems
based minimum relative entropy principle. Thus, Bayesian control rule either
regarded new principled approach adaptive control novel optimality
criterion heuristic approximation traditional Bayes-optimal control. Since
takes similar form Bayes rule, adaptive control problem could translated
on-line inference problem actions sampled stochastically posterior
distribution. important note, however, problem statement formulated
usual Bayes-optimal approach adaptive control same.
future relationship two problem statements deserves investigation.

Acknowledgments
thank Marcus Hutter, David Wingate, Zoubin Ghahramani, Jose Aliste, Jose Donoso,
Humberto Maturana anonymous reviewers comments earlier versions
manuscript and/or inspiring discussions. thank Ministerio de Planificacion de Chile
(MIDEPLAN) Bohringer-Ingelheim-Fonds (BIF) funding.

Appendix A. Proofs
A.1 Proof Theorem 1
Proof. proof follows line argument solution Equation 3
crucial difference
treated interventions. Consider without loss
P actions
Equation 9. Note relative entropy
generality summand P (m)Cm
written difference two logarithms, one term depends Pr varied.
Therefore, one pull term write constant c. yields

c

X


P (m)

X

ao<t

P (ao<t |m)

X


503

P (at |m, ao<t ) ln Pr(at |ao<t ).

fiOrtega & Braun

Substituting P (ao<t |m) P (m|ao<t )P (ao<t )/P (m) using Bayes rule rearrangement terms leads
XX
X
=c
P (m|ao<t )P (ao<t )
P (at |m, ao<t ) ln Pr(at |ao<t )
ao<t

=c

X

P (ao<t )



X


ao<t

P (at |ao<t ) ln Pr(at |ao<t ).

P
inner sum form x p(x) ln q(x), i.e. cross-entropy q(x) p(x),
minimized q(x) = p(x) x. Let P denote optimum distribution
Pr. choosing optimum one obtains P(at |ao<t ) = P (at |ao<t ) . Note
solution variational problem P
independent P
weighting P (ao<t ). Since


argument applies summand P (m)Cm
P (m)Cm Equation 9,
variational problems mutually independent. Hence,
P(at |ao<t ) = P (at |ao<t )

P(ot |ao<t ) = P (ot |ao<t )

aot Z . P (at |ao<t ), introduce variable via marginalization
apply chain rule:
X
P (at |ao<t ) =
P (at+1 |m, ao<t )P (m|ao<t ).


term P (m|aot ) developed

P (ao<t |m)P (m)


P (ao<t |m )P (m )
Qt1
P (m) =1 P (a |m, ao< )P (o |m, ao< )
=P
Qt1



P (m )
=1 P (a |m , ao< )P (o |m , ao< )
Qt1
P (m) =1 P (o |m, ao< )
.
=P
Qt1


P (m )
=1 P (o |m , ao< )

P (m|ao<t ) = P

first equality obtained applying Bayes rule second using chain
rule probabilities. get last equality, one applies interventions causal
factorization. Thus, P (a |m, ao< ) = 1 P (o |m, ao< ) = P (o |m, ao< ).
equations characterizing P (ot |ao<t ) obtained similarly.
A.2 Proof Theorem 2
Proof. pointed (14), particular realization divergence process
dt (m km) decomposed
X
dt (m km) =
gm (m ; Tm ),


gm (m ; Tm ) sub-divergences dt (m km) Tm form partition Nt .
However, since dt (m km) bounded variation M, one > 0,
C(m) 0, M, Nt Nt , inequality
fi
fi
fi
fi
figm (m ; Tm ) Gm (m ; Tm )fi C(m)
504

fiA Minimum Relative Entropy Principle Learning Acting

holds probability 1 . However, due (15),
Gm (m ; Tm ) 0
M. Thus,

gm (m ; Tm ) C(m).

previous inequalities hold simultaneously divergence process
bounded well. is, inequality
dt (m km) C(m)

(22)

holds probability (1 )M := |M|. Choose
(m)
(m) := max{0, ln PP(m
) }.
(m)
Since 0 ln PP(m
Using
) (m), added right hand side (22).

definition dt (m km), taking exponential rearranging terms one obtains


P (m )






=1

(m)

P (o |m , ao< ) e

P (m)




=1

P (o |m, ao< )

(m) := C(m) + (m) 0. Identifying posterior probabilities
dividing sides normalizing constant yields inequality
P (m |aot ) e(m) P (m|aot ).
2

inequality holds simultaneously probability (1 )M
particular := minm {e(m) }, is,
P (m |aot ) P (m|aot ).
since valid M, maxm {P (m|aot )}
P (m |aot )

1
M,

one gets


,


probability
1 arbitrary > 0 related equation :=

M2
1
1 .
A.3 Proof Theorem 3
Proof. divergence process dt (m km) decomposed sum sub-divergences
(see Equation 14)
X
gm (m; Tm ).
(23)
dt (m km) =




Furthermore, every
M, one > 0, C 0,
N Nt
fi
fi
fi
fi
figm (m; ) Gm (m; )fi C(m)
505

fiOrtega & Braun

probability 1 . Applying bound summands (23) yields lower
bound
X
X

gm (m; Tm )
Gm (m; Tm ) C(m)




(1 )M ,

holds probability
:= |M|. Due Inequality 15, one




6= , Gm (m; Tm ) 0. Hence,
X

Gm (m; Tm ) C(m) Gm (m; Tm ) C


C := maxm {C(m)}. members set Tm determined stochastically;
specifically, ith member included Tm probability P (m |aoi ) /M
> 0 Theorem 2. since
/ [m ], one Gm (m; Tm )

probability 1 arbitrarily chosen > 0. implies
lim dt (m km) lim Gm (m; Tm ) C





probability 1 , > 0 arbitrary related = 1 (1 )M +1 .
Using result upper bound posterior probabilities yields final result
P (m) dt (m km)
e
= 0.
P (m )

0 lim P (m|aot ) lim


A.4 Proof Theorem 4
Proof. use abbreviations pm (t) := P (at |m, ao<t ) wm (t) := P (m|ao<t ).
Decompose P (at |ao<t )
X
X
pm (t)wm (t) +
pm (t)wm (t).
(24)
P (at |ao<t ) =
m[m
/ ]

m[m ]

first sum right-hand side lower-bounded zero upper-bounded
X
X
pm (t)wm (t)
wm (t)
m[m
/ ]

m[m
/ ]

pm (t) 1. Due Theorem 3, wm (t) 0 almost surely. Given > 0
> 0, let t0 (m) time t0 (m), wm (t) < . Choosing
t0 := maxm {t0 (m)}, previous inequality holds t0 simultaneously
probability (1 )M . Hence,
X
X
pm (t)wm (t)
wm (t) < .
(25)
m[m
/ ]

m[m
/ ]

bound second sum (24) one proceeds follows. every member [m ],
one pm (t) pm (t) . Hence, following similar construction above,
one choose t0 t0 [m ], inequalities
fi
fi
fi
fi
fipm (t) pm (t)fi <
506

fiA Minimum Relative Entropy Principle Learning Acting

hold simultaneously precision > 0. Applying second sum Equation 24
yields bounds
X
X
X


pm (t) + wm (t).
pm (t)wm (t)
pm (t) wm (t)
m[m ]

m[m ]

pm (t)





m[m ]

multiplicative constants placed front sum. Note
1

X

m[m ]

wm (t) = 1

X

m[m
/ ]

wm (t) > 1 .

Use inequalities allows simplifying lower upper bounds respectively:
X
pm (t)
wm (t) > pm (t)(1 ) pm (t) 2 ,
m[m ]

pm (t) +

X


m[m ]

(26)

wm (t) pm (t) + < pm (t) + 2 .

Combining inequalities (25) (26) (24) yields final result:
fi
fi
fi
fi

P
(a
|ao
(t)
)

p
fi
fi < (2 + ) = ,


<t

holds probability 1 arbitrary > 0 related = 1
arbitrary precision .





1

A.5 Gibbs Sampling Implementation MDP Agent
Inserting likelihood given Equation 19 Equation 13 Bayesian control rule,
one obtains following expression posterior
P (m|at , ot ) =
=

P (x |m, x, a)P (r|m, x, a, x )P (m|a<t , o<t )






P (x |m , x, a)P (r|m , x, a, x )P (m |a<t , o<t ) dm
P (r|m, x, a, x )P (m|a<t , o<t )
R
,




P (r|m , x, a, x )P (m |a<t , o<t ) dm
R

(27)

replaced sum integration , finite-dimensional real space
containing average reward Q-values observed states,
simplified term P (x |m, x, a) constant M.
likelihood model P (r|m , x, a, x ) Equation 27 encodes set independent normal distributions immediate reward means (x, a, x ) indexed triples
(x, a, x ) X X . words, given (x, a, x ), rewards drawn
normal distribution unknown mean (x, a, x ) known variance 2 . sufficient statistics given n(x, a, x ), number times transition x x
action a, r(x, a, x ), mean rewards obtained transition.
conjugate prior distribution well known given normal distribution
hyperparameters 0 0 :
r
n
2
0


0
.
(28)
exp 2 (x, a, x ) 0
P (m (x, a, x )) = N(0 , 1/0 ) =
2
507

fiOrtega & Braun

posterior distribution given
P (m (x, a, x )|at , ot ) = N((x, a, x ), 1/(x, a, x ))
posterior hyperparameters computed
0 0 + p n(x, a, x ) r(x, a, x )
0 + p n(x, a, x )
(x, a, x ) = 0 + p n(x, a, x ).

(x, a, x ) =

(29)

introducing shorthand V (x) := maxa Q(x, a), write posterior distribution
P (|at , ot ) = N(, 1/S)
(30)

=

1 X
(x, a, x )((x, a, x ) Q(x, a) + V (x )),

x,a,x
X
S=
(x, a, x ).
x,a,x

posterior distribution Q-values difficult obtain,
Q(x, a) enters posterior distribution linearly non-linearly . However,
fix Q(x, a) within max operations, amounts treating V (x)
constant within single Gibbs step, conditional distribution approximated



P (Q(x, a)|at , ot ) N Q(x, a), 1/S(x, a)
(31)


Q(x, a) =

X
1
(x, a, x )((x, a, x ) + V (x )),
S(x, a)
x
X
(x, a, x ).
S(x, a) =
x

expect approximation hold resulting update rule constitutes contraction operation forms basis stochastic approximation algorithms (Mahadevan, 1996). result, Gibbs sampler draws values normal distributions. cycle adaptive controller, one carry several Gibbs sweeps
obtain sample improve mixing Markov chain. However, experimental
results shown single Gibbs sweep per state transition performs reasonably well.
new parameter vector drawn, Bayesian control rule proceeds taking
optimal action given Equation 20. Note entries transitions
occurred need represented explicitly; similarly, Q-values visited
states need represented explicitly.
508

fiA Minimum Relative Entropy Principle Learning Acting

References
Auer, P., CesaBianchi, N., & Fischer, P. (2002). Finite-time analysis multiarmed
bandit problem. Machine Learning, 47, 235256.
Bertsekas, D. (1987). Dynamic Programming: Deterministic Stochastic Models.
Prentice-Hall, Upper Saddle River, NJ.
Bishop, C. M. (2006). Pattern Recognition Machine Learning. Springer.
Braun, D. A., & Ortega, P. A. (2010). minimum relative entropy principle adaptive
control linear quadratic regulators. 7th conference informatics control,
automation robotics, Vol. 3, pp. 103108.
Cesa-Bianchi, N., & Lugosi, G. (2006). Prediction, Learning Games. Cambridge University Press.
Dawid, A. P. (2010). Beware DAG!. Journal Machine Learning Research, (to
appear).
Dearden, R., Friedman, N., & Andre, D. (1999). Model based bayesian exploration.
Proceedings Fifteenth Conference Uncertainty Artificial Intelligence, pp.
150159.
Dearden, R., Friedman, N., & Russell, S. (1998). Bayesian q-learning. AAAI
98/IAAI 98: Proceedings fifteenth national/tenth conference Artificial intelligence/Innovative applications artificial intelligence, pp. 761768. American Association Artificial Intelligence.
Duda, R. O., Hart, P. E., & Stork, D. G. (2001). Pattern Classification (Second edition).
Wiley & Sons, Inc.
Duff, M. O. (2002). Optimal learning: computational procedures bayes-adaptive markov
decision processes. Ph.D. thesis. Director-Andrew Barto.
Grunwald, P. (2007). Minimum Description Length Principle. MIT Press.
Haruno, M., Wolpert, D., & Kawato, M. (2001). Mosaic model sensorimotor learning
control. Neural Computation, 13, 22012220.
Haussler, D., & Opper, M. (1997). Mutual information, metric entropy cumulative
relative entropy risk. Annals Statistics, 25, 24512492.
Hutter, M. (2002). Self-optimizing pareto-optimal policies general environments
based bayes-mixtures. COLT.
Hutter, M. (2003). Optimality universal Bayesian prediction general loss alphabet.
Journal Machine Learning Research, 4, 971997.
Hutter, M. (2004a). Online prediction bayes versus experts. Tech. rep.. Presented
EU PASCAL Workshop Learning Theoretic Bayesian Inductive Principles
(LTBIP-2004).
Hutter, M. (2004b). Universal Artificial Intelligence: Sequential Decisions based Algorithmic Probability. Springer, Berlin.
509

fiOrtega & Braun

Kappen, B., Gomez, V., & Opper, M. (2010). Optimal control graphical model inference
problem. JMLR (to appear).
MacKay, D. J. C. (2003). Information Theory, Inference, Learning Algorithms. Cambridge University Press.
Mahadevan, S. (1996). Average reward reinforcement learning: Foundations, algorithms,
empirical results. Machine Learning, 22 (1-3), 159195.
Mahoney, M. V. (1999). Text compression test artificial intelligence. AAAI/IAAI,
pp. 486502.
Narendra, K., & Thathachar, M. A. L. (1974). Learning automata - survey. IEEE
Transactions Systems, Man, Cybernetics, SMC-4 (4), 323334.
Nozick, R. (1969). Newcombs problem two principles choice. Rescher, N. (Ed.),
Essays Honor Carl G. Hempel, pp. 114146. Reidel.
Opper, M. (1998). bayesian approach online learning. Online Learning Neural
Networks, 363378.
Ortega, P. A., & Braun, D. A. (2010). bayesian rule adaptive control based causal
interventions. third conference artificial general intelligence, pp. 121126.
Pearl, J. (2000). Causality: Models, Reasoning, Inference. Cambridge University Press,
Cambridge, UK.
Poland, J., & Hutter, M. (2005). Defensive universal learning experts. ALT.
Rasmussen, C. E., & Deisenroth, M. P. (2008). Recent Advances Reinforcement Learning,
Vol. 5323 Lecture Notes Computer Science, LNAI, chap. Probabilistic Inference
Fast Learning Control, pp. 229242. Springer-Verlag.
Robbins, H. (1952). aspects sequential design experiments. Bulletin American
Mathematical Socierty, 58, 527535.
Russell, S., & Norvig, P. (2010). Artificial Intelligence: Modern Approach (3rd edition).
Prentice-Hall.
Schmidhuber, J. (2009). Simple algorithmic theory subjective beauty, novelty, surprise,
interestingness, attention, curiosity, creativity, art, science, music, jokes. Journal
SICE, 48 (1), 2132.
Shafer, G. (1996). art causal conjecture. MIT Press.
Singh, S. P. (1994). Reinforcement learning algorithms average-payoff markovian decision
processes. National Conference Artificial Intelligence, pp. 700705.
Spirtes, P., Glymour, C., & Scheines, R. (2000). Causation, Prediction Search (2nd
edition). Springer-Verlag, New York.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge, MA.
Todorov, E. (2006). Linearly solvable markov decision problems. Advances Neural
Information Processing Systems, Vol. 19, pp. 13691376.
510

fiA Minimum Relative Entropy Principle Learning Acting

Todorov, E. (2009). Efficient computation optimal actions. Proceedings National
Academy Sciences U.S.A., 106, 1147811483.
Toussaint, M., Harmeling, S., & Storkey, A. (2006). Probabilistic inference solving
(po)mdps. Tech. rep. EDI-INF-RR-0934, University Edinburgh.
Watkins, C. (1989). Learning Delayed Rewards. Ph.D. thesis, University Cambridge,
Cambridge, England.
Wyatt, J. (1997). Exploration Inference Learning Reinforcement. Ph.D. thesis,
Department Artificial Intelligence, University Edinburgh.

511

fiJournal Artificial Intelligence Research 38 (2010) 307-338

Submitted 01/10; published 06/10

Fast Set Bounds Propagation Using BDD-SAT Hybrid
Graeme Gange
Peter J. Stuckey

ggange@csse.unimelb.edu.au
pjs@csse.unimelb.edu.au

National ICT Australia, Victoria Laboratory
Department Computer Science Software Engineering
University Melbourne, Vic. 3010, Australia

Vitaly Lagoon

lagoon@cadence.com

Cadence Design Systems
270 Billerica Rd, Chelmsford, 01824, USA

Abstract
Binary Decision Diagram (BDD) based set bounds propagation powerful approach
solving set-constraint satisfaction problems. However, prior BDD based techniques incur significant overhead constructing manipulating graphs search.
present set-constraint solver combines BDD-based set-bounds propagators
learning abilities modern SAT solver. Together number improvements
beyond basic algorithm, solver highly competitive existing propagation
based set constraint solvers.

1. Introduction
often convenient model constraint satisfaction problem (CSP) using finite set
variables set relationships them. common approach solving finite domain
CSPs using combination backtracking search constraint propagation algorithm.
propagation algorithm attempts enforce consistency values domains
constraint variables removing values domains variables cannot
form part complete solution system constraints. common level
consistency set bounds consistency (Gervet, 1997) solver keeps track
set elements definitely set. Many solvers use set bounds
consistency including ECLiPSe (IC-PARC, 2003), Gecode (GECODE, 2008), ILOG
SOLVER (ILOG, 2004).
Set bounds propagation supported solvers since stronger notions propagation
domain propagation require representing exponentially large domains possible
values. However, Lagoon Stuckey (2004) demonstrated possible use reduced
ordered binary decision diagrams (BDDs) compact representation set domains
set constraints, thus permitting set domain propagation. domain propagator
ensures every value domain set variable extended complete
assignment variables constraint. use BDD representation comes
several additional benefits. ability easily conjoin existentially quantify
BDDs allows removal intermediate variables, thus strengthening propagation,
also makes construction propagators global constraints straightforward.
Given natural way BDDs used model set constraint problems,
therefore worthwhile utilising BDDs construct types set solver. Indeed
c
2010
AI Access Foundation. rights reserved.

fiGange, Stuckey, & Lagoon

previously demonstrated (Hawkins, Lagoon, & Stuckey, 2004, 2005) set
bounds propagation efficiently implemented using BDDs represent constraints
domains variables. major benefit BDD-based approach frees
us need laboriously construct set bounds propagators new constraint
hand. Moreover, correctness optimality BDD-based propagators follow
construction. advantages BDD-based representation identified still
apply, resulting solver performs favourably compared existing set
bounds solvers.
set bounds propagation using BDDs still constructs BDDs propagation,
considerable overhead. paper show perform BDD-based
set bounds propagation using marking algorithm perform linear scans BDD
representation constraint without constructing new BDDs. resulting set bounds
propagators substantially faster using BDDs.
contributions paper are:
Efficient set bounds propagators: new BDDs constructed propagation, fast.
Graph reuse: reuse single BDD multiple copies constraint,
hence handle larger problems.
Ordering flexibility: restricted single global ordering Booleans
constructing BDDs.
Filtering: keep track parts set variable really make
difference, reduce amount propagation.
Pure set-bounds propagation tends perform badly, however, problems large
number similar regions search space must explored. therefore embed
set-bounds propagators MiniSAT (Een & Sorensson, 2003), provide SAT-style clause
learning.
next section, introduce propagation-based solving set problems, briefly
discuss SAT solving. Section 3 discuss binary decision diagrams (BDDs)
implement set bounds propagation using BDDs. Section 4, present
propagation algorithm used hybrid solver, together number variations
upon standard algorithm. Section 5, show incorporate reason generation
BDD propagation build hybrid solver Section 6 test performance
solver variety set-constraint problems, compare set-constraint
solvers. Section 7 discuss related work, concluding Section 8.

2. Propagation-based Solving
Propagation based approaches solving set constraint problems represent problem
using domain storing possible values set variable, propagators
constraint, remove values domain variable inconsistent values variables. Propagation combined backtracking search find solutions.
308

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

domain complete mapping fixed finite set variables V finite
collections finite sets integers. domain variable v set D(v). domain
D1 said stronger domain D2 , written D1 D2 , D1 (v) D2 (v)
v V. domain D1 equal domain D2 , written D1 = D2 ,
V D1 (v) = D2 (v)
variables v V. domain interpreted constraint vV v D(v).
set constraints often interested restricting variables take convex
domains. set sets K convex a, b K c b implies c K. use
interval notation [a, b] b represent (minimal) convex set K including
b. finite collection sets K = {a1 , a2 , . . . , }, define convex closure
K: conv (K) = [aK a, aK a]. extend concept convex closure domains
defining ran(D) domain ran(D)(v) = conv (D(v)) v V.
valuation set mappings set variables V sets integer values,
written {v1 7 d1 , . . . , vn 7 dn }. valuation extended apply constraints
involving variables obvious way. Let vars function returns set
variables appearing expression, constraint valuation. abuse notation,
say valuation element domain D, written D, (vi ) D(vi )
vi vars().
2.1 Constraints, Propagators Propagation
constraint restriction placed allowable values set variables. shall
use primitive set constraints (membership) k v, (equality) u = v, (subset) u w,
(union) u = v w, (intersection) u = v w, (cardinality) |v| = k, (upper cardinality bound)
|v| k, (lexicographic order) u < v, u, v, w set variables, k integer.
also construct complicated constraints (possibly existentially quantified)
conjunctions primitive set constraints. define solutions constraint c
set valuations vars(c) make constraint true.
associate propagator every constraint. propagator f monotonically
decreasing function domains domains, D1 D2 implies f (D1 ) f (D2 ),
f (D) D. propagator f correct constraint c domains
D: { | D} solns(c) = { | f (D)} solns(c)
propagation solver solv (F, D) set propagators F domain repeatedly applies propagators F starting domain fixpoint reached.
solv (F, D) weakest domain f (D ) = f F .
Example 1 small example set-constraint problem would to, given universe
consisting elements {1, 2, 3, 4}, find values variables x, y, z z = x y,
|x| = 3, |y| = 3, |z| = 2, 3
/ z, 1 z 2
/ y.
unique solution problem = {x 7 {1, 2, 4}, 7 {1, 3, 4}, z 7 {1, 4}}.
2.2 Set Bounds Consistency
domain (set) bounds consistent constraint c every variable v vars(c)
upper bound D(v) union values v solutions c D,
lower bound D(v) intersection values v solutions c D.
309

fiGange, Stuckey, & Lagoon

define set bounds propagator constraint c
(
{i | solns(D c) (v)} v vars(c)
ub(c)(D)(v) =
ub(v)
otherwise
lb(c)(D)(v) =

(

{i | solns(D c) (v)}
lb(v)

v vars(c)
otherwise

sb(c)(D)(v) = [lb(c)(D)(v), ub(c)(D)(v)]
sb(c)(D) always bounds consistent c.
Example 2 Continuing example previous section, initial bounds
variables x, y, z D(x) = D(y) = D(z) = [, {1, 2, 3, 4}], values explicitly
included excluded domains. first 3
/ z added, 1 z finally
2
/ y, bounds reduced, consequences changes propagated
among variables follows:
Propagator
D(x)
D(y)
D(z)
[, {1, 2, 3, 4}]
[, {1, 2, 3, 4}]
[, {1, 2, 3, 4}]
3
/z
[, {1, 2, 3, 4}]
[, {1, 2, 3, 4}]
[, {1, 2, 4}]
1z
[, {1, 2, 3, 4}]
[, {1, 2, 3, 4}]
[{1}, {1, 2, 4}]
z =xy
[{1}, {1, 2, 3, 4}]
[{1}, {1, 2, 3, 4}]
[{1}, {1, 2, 4}]
2
/y
[{1}, {1, 2, 3, 4}]
[{1}, {1, 3, 4}]
[{1}, {1, 2, 4}]
|y| = 3
[{1}, {1, 2, 3, 4}]
[{1, 3, 4}, {1, 3, 4}] [{1}, {1, 2, 4}]
z =xy
[{1}, {1, 2, 4}]
[{1, 3, 4}, {1, 3, 4}]
[{1}, {1, 4}]
|z| = 2
[{1}, {1, 2, 4}]
[{1, 3, 4}, {1, 3, 4}] [{1, 4}, {1, 4}]
|x| = 3
[{1, 2, 4}, {1, 2, 4}] [{1, 3, 4}, {1, 3, 4}] [{1, 4}, {1, 4}]
1 z fixed, 1 added lb(z). Since z = x y, element lb(z) must
also lb(x) lb(y). 2
/ set, |ub(y)| = 3 since |ub(y)| |y| = 3
means = ub(y) = {1, 3, 4}. means 2
/ z since z = x y. Since 3
/ ub(z),
least one x must contain 3. 3 lb(y) set, determined
3
/ ub(x). Since |ub(z)| = 2 forces z = ub(z) = {1, 4}. Finally constraint
|x| = 3 results value x becoming fixed. corresponding valuation
= {x 7 {1, 2, 4}, 7 {1, 3, 4}, z 7 {1, 4}}, solution provided Example 1.
2.3 Boolean Satisfiability (SAT)
Boolean Satisfiability SAT solvers special case propagation-based solvers, restricted Boolean variables clause constraints.
Davis-Putnam-Logemann-Loveland (DPLL) algorithm (Davis, Logemann, & Loveland, 1962), modern SAT solvers based, also propagation-based
approach solving SAT problems. interleaves two phases search, unfixed
variable assigned value, propagation (so called unit propagation).
Modern SAT solvers incorporate sophisticated engineering propagate constraints
fast, record nogoods part search lead failure, automate search
310

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

SAT Engine

Search

conflict
analysis

unit propagation

Clause Database

Figure 1: Architecture SAT solver.
keeping track often variable part reason causing failure (activity)
concentrating search variables high activity. Modern SAT solvers also frequently
restart search scratch relying nogoods recording prevent repeated search,
activity drive search profitable areas. See e.g., report Een
Sorensson (2003) good introduction modern SAT solving.
rough architecture modern SAT solver illustrated Figure 1. Search starts
unit propagation process interacts clause database may detect failure,
initiates conflict analysis. Unit propagation records literal made
true, clause explains literal become true. Conflict analysis uses graph
explanations construct nogood resolvent clauses causing failure
adds strength unit propagation. stored clause database
causes search backjump. prevents search revisiting set decisions.
detailed activity counters record variables responsible
failure, variables chosen labelling search.

3. Binary Decision Diagrams
assume set B Boolean variables total ordering . Boolean variable
take value 0 (false) 1 (true). make use following Boolean operations:
(conjunction), (disjunction), (negation), (implication), (bi-implication)
(existential quantification). denote V F formula x1 xn F V =
V F mean V F V = vars(F ) \ V .
{x1 , . . . , xn },
Reduced Ordered Binary Decision Diagrams well-known method representing
Boolean functions Boolean variables using directed acyclic graphs single root.
Every internal node n(v, f, t) BDD r labelled Boolean variable v B,
two outgoing arcs false arc (to BDD f ) true arc (to BDD t). Leaf
nodes either F (false) (true). node represents single test labelled
variable; traversing tree appropriate arc followed depending value
311

fiGange, Stuckey, & Lagoon

7654
0123
v3 E
EE
"
7654
0123

v4

|
7654
0123
v5

|
7654
0123
v6 E
EE
"
7654
0123
v7 DD
D!
" }r

F



7654
0123
x1 F
FF
|
"
7654
0123
7654
0123
x2 F
x2 F
FF
FF
" |
"
|
7654
0123
7654
0123
7654
0123
x3 F
x3
x3 F
FF
FF
"7654
"
|
|
0123
7654
0123
x4 F
x4
FF
"7654
|
0123
x5 EE
E"
}
" |



(a)

F

(b)

Figure 2: BDDs (a) v3 v4 v5 v6 v7 . (b) x1 + x2 + x3 + x4 + x5 2. node
n(v, f, t) shown circle labelled v dotted arc f BDD, solid arc
BDD.

variable. Define size |r| number internal nodes BDD r, VAR(r)
set variables v B appearing internal node r.
Reduced Ordered Binary Decision Diagrams (BDDs) (Bryant, 1986) require
BDD is: reduced, contains identical nodes (nodes variable label
identical true false arcs) redundant tests (no node true
false arcs leading node); ordered, arc node labelled
v1 node labelled v2 v1 v2 . BDD nice property function
representation canonical variable reordering. permits efficient implementations
many Boolean operations.
Boolean variable v said fixed BDD r either every node n(v, f, t) r
constant F node, every node n(v, f, t) f constant F node. variables
identified linear time scan domain BDD (see e.g., Hawkins et al.,
2005). convenience, BDD, write JK denote BDD representing
conjunction fixed variables .

Example 3 Figure 2(a) gives example BDD representing formula v3 v4
v5 v6 v7 . Figure 2(b) gives example complex BDD representing formula
x1 + x2 + x3 + x4 + x5 2 interpret Booleans 0-1 integers. One verify
valuation {x1 7 1, x2 7 0, x3 7 1, x4 7 0, x5 7 0} makes formula true
following path right, left, right, left, left root.
3.1 Set Propagation using BDDs
key step building set propagation using BDDs realize represent
finite set domain using BDD.
3.1.1 Representing domains
v set variable ranging subsets {1, . . . , N }, represent v using
Boolean variables V (v) = {v1 , . . . , vN } B, vi true iff v. order
312

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

variables v1 v2 vN . represent valuation using formula

R() =

^

vvars()




^

^

vi

i(v)

i{1,...,N }(v)



vi .

W
domain variable v, D(v) represented = aD(v) R({v 7 a}).
formula represented BDD. set bounds v obtained extracting
fixed variables BDD, JK.
example valuation Example 1 represented formula R():
x1 x2 x3 x4 y1 y2 y3 y4 z1 z2 z3 z4 .
domain D(v) = [{3, 6, 7}, {1, 2, 3, 6, 7, 8, 9}] represented BDD Figure 2(a) since v3 , v6 v7 true 3, 6, 7 definitely set, v4 v5
false 4 5 definitely set.
3.1.2 Representing constraints
similarly model set constraint c BDD B(c) using Boolean variable
representation V (v) set variables v. ordering variables BDD carefully
build small representations formulae. pointwise order Boolean variables
defined follows. Given set variables u v w ranging sets {1, . . . , N }
order Boolean variables u1 v1 w1 u2 v2 w2 uN vN wN .
representation B(c) simply solns(c) R(). primitive set constraints (using
pointwise order) size linear N . details see work Hawkins et al.
(2005). BDD representation |x| 2 shown Figure 2(b), N = 5.
3.1.3 BDD-based Set Bounds Propagation
build set bounds propagator, less definition, since BDDs
represent domains constraints.
= B(c)

^

D(v )

v vars(c)

sb(c)(D)(v) = V (v) JK
simply conjoin domains constraint obtaining , extract fixed variables
result, project relevant part variable v. set bounds
propagation improved removing fixed variables soon possible.
improved definition given Hawkins et al. (2004). Overall complexity made
O(|B(c)|).
updated set bounds used simplify BDD representing propagator.
Since fixed variables never interact propagation projected
B(c), replace B(c) VAR(JK) .
313

fiGange, Stuckey, & Lagoon

bdd2sat(node) {
switch node {
F: return (0, {}) ;
: return (1, {});
n(v, f, t):
(visit[node] 6= ) return(visit[node],{});
let n new Boolean variable;
visit[node] = n ;
(f , Cf ) = bdd2sat(f );
(t , Ct ) = bdd2sat(t);
return (n , {v n , v f n , v n , v f n ,
f n , f n } Cf Ct );
}
}
Figure 3: Pseudo-code Tseitin transformation BDD rooted node n
Boolean variable encoding truth value node.
3.2 Tseitin Transformation
possible convert Boolean circuit pure SAT representation; method
generally attributed Tseitin (1968). Figure 3 gives pseudo code
translation BDD rooted node, returning pair (Boolean variable, set clauses).
clauses enforce Boolean variable takes truth value BDD. Like
BDD algorithms relies marking visited nodes ensure node visited
once. assumes array visit[] initially bottom , first visiting node
stores corresponding Boolean variable visit[]. comprehensive discussion
Tseitin transformation presented Een Sorensson (2006).
constraint enforced fixing variable corresponding root node
true. advantage replacing BDD Tseitin representation use
unmodified SAT solver tackle BDD-based set constraint problems. shall see
Section 6 approach cannot compete handling BDDs directly.

4. Faster Set-bounds Propagation
set bounds propagation using BDDs much faster set domain propagation
often better set domain propagation (or variations propagation sets)
still creates new BDDs. necessary long prepared give
simplifying BDDs possible set bounds propagation.
represent domains variables BDDs, rather arrays Boolean
domains. domain array where, variable v ranging subsets {1, . . . , N }:
0
/ D[vi ] indicates v, 1
/ D[vi ] indicates
/ v. D[vi ] = {0, 1}, dont know
whether v. Hence D(v) = [{i|0
/ D[vi ]}, {i|1 D[vi ]}].
BDD representation constraint B(c) built before. significant difference
since constraints communicate set bounds variables
314

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

need share global variable order hence necessary modify variable
order used construct B(c) c, use automatic variable reordering (which
available BDD packages) construct B(c). Another advantage
reuse BDD constraint c(x) variables x constraint c(y) variables
(as long range initial sets), is, constraint different
variables. Hence build one BDD, rather one instance
constraint.
set bounds propagator sb(c(x)) constraint c(x) implemented follows.
generic BDD representation r constraint c(y) constructed. propagator copies
domain description actual parameters x1 , . . . , xn onto domain description E
formal parameters 1 , . . . , n . constructs array E E[yij ] = D[xji ]. Let
V = {yij | 1 j n, 1 N } set Boolean variables occurring
constraint c(y). propagator executes code bddprop(r, V, E) shown Figures 4
5 returns (r , V , E ). r = F propagator returns false domain, otherwise
propagator copies back domains formal parameters actual parameters
D[xji ] = E[yij ]. come back V argument next subsection.
procedure bddprop(r, V, E) traverses BDD r follows. visit node
n(v, f, t) BDD top-down memoing manner. record if, current
domain, node reach F node, reach node. f child
reach node add support variable v taking value 0. Similarly
child reach add support variable v taking 1. node reach
F record variable v matters computation BDD.
visit reduce variable set propagator matter, remove values
support domain. procedure assumes global time variable
incremented propagation, used memo marking phase.
top(n, V ) function returns variable root node n largest variable (under
) V n = n = F.
presented bddprop time complexity O(|r| |V |) |r| number nodes
appearing BDD r. practice complexity O(|r| + |V |) since |V | factor arises
handling long arcs, node n(v, f, t) child node (f t) labelled
Boolean different next order v. set constraints length
long arc typically bounded arity set constraint. possible create
version bddprop strictly O(|r|) careful handling long arcs. so,
practice slower form presented here. bddprop space complexity
O(|V | + |r|) first component maintaining domains variables second
memoing BDD nodes.
Example 4 Consider BDD constraint x = z N = 2 shown Figure 6(a). Assuming domain E E[y1 ] = {1} (1 y) E[z2 ] = {1} (2 z),
remaining variables take value {0, 1}, algorithm traverses edges shown
double lines Figure 6(b). path x1 , x2 following f arc reaches hence 0
added E [x1 ] E [x2 ]. result E[x1 ] E[x2 ] set {1}. Hence
determined 1 x 2 x.
Also, nodes z1 actually visited, left node y2 reaches F
right node reaches . Hence matters[z1 ] matters[y2 ] marked
315

fiGange, Stuckey, & Lagoon

bddprop(r,V ,E) {
(v V ) {
E [v] = {};
}
(reachf , reacht ) = bddp(r, V, E);
(reacht ) return (F, , E);
vars = ;
(v V ) {
(E [v] 6= E[v]) {
E[v] = E [v];
}
(E[v] = {0, 1} matters[v] time) vars = vars {v};
}
return (r, vars , E);
}
Figure 4: Pseudo-code BDD-propagation.
current time. set vars collected bddprop empty, since remaining variables
fixed.
4.1 Waking Less Often
practice bounds propagation solver blindly apply propagator fixpoint, keeps track propagators must still fixpoint, executes
may be. set bounds usually managed follows. set
variable v attached list propagators c involve v. Whenever v changes,
propagators rescheduled execution.
better BDD based propagators. algorithm bddprop
collects set Boolean variables matter BDD, change result.
variable matter becomes fixed, set bounds propagation cannot learn
new information. modify wakeup process follows. propagator stores
list vars Boolean variables matter given current domain. Boolean
variable xji becomes fixed traverse list propagators involving xji wake
propagators xji occurs vars. executing propagator revise set vars
stored propagator. Note optimization could applied standard
approach, requires overhead computing vars folded bddprop.
possible instead propagator wake-up literals, rather variables.
case, observe fixing variable v true matters node n(v, f, t) iff reachable
f F reachable converse holds v. terms pseudo-code
Figure 5, line
(reachf reacht ) matters[v] = time;
may therefore replaced
316

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

bddp(node,V ,E) {
(in set(fset, node)) { return (1, 0)};
switch node {
F: return (1,0);
: return (0,1);
n(v, f, t):
(visit[node] time) return save[node];
reachf = 0; reacht = 0;
(0 E[v]) {
(rf0 , rt0 ) = bddp(f, V, E);
reachf = reachf rf0 ;
reacht = reacht rt0 ;
(rt0 ) {
(v V, v v top(f, V ))
E [v ] = E[v ];

E [v] = E [v] 0;
}
}
(1 E[v]) {
(rf1 , rt1 ) = bddp(t, V, E);
reachf = reachf rf1 ;
reacht = reacht rt1 ;
(rt1 ) {
(v V, v v top(t, V ))
E [v ] = E[v ];

E [v] = E [v] 1;
}
}
(reachf reacht ) matters[v] = time;
save[node] = (reachf , reacht ); (reacht) { insert(fset, node) };
visit[node] = time;
return (reachf , reacht );
}
}
Figure 5: Pseudo-code processing constraint graph propagation. Modifications necessary using dead-subgraph memoization shown right.

(rt0 rf 1) matters[v] = time;
(rt1 rf 0) matters[v] = time;

allows propagators wake less frequently, propagator execution slower
due keeping track additional reachability information.
317

fiGange, Stuckey, & Lagoon

7654
0123
x1 C
CC
CC
C!
7654
0123
y1


0123
z
7654

{ 1
{{{
! }{{
7654
0123
x2 C
CC
CC
C!
7654
0123
y2



7654
0123
z2

{{{

{

! }{{

}
7654
0123
y1

7654
0123
z1




}
7654
0123

2


7654
0123
z
|| 2
|
ff ~|vt |

F



(a)

7654
0123
x1CCC
CCCC
CCCC
C %
7654
0123
y1




7654
z1

0123
{{{

{
!
}{{
7654
0123
x2CCC
CCCC
CCCC
C %
7654
0123
y2



ff
7654
0123


{{{z2


{
{
{{
!
{{{


7654
0123
y1

7654
0123
z1





7654
0123

2

ff
7654
0123
z
|||| 2
|||

ff
zvt |||

F



(b)

Figure 6: (a) BDD representing x = z N = 2. (b) edges traversed
bddprop, E[y1 ] = {1} E[z2 ] = {1} E[v] = {0, 1} otherwise, shown
doubled.
4.2 Dead Subgraph Memoization Shortcutting
algorithm presented always explores reachable parts graph order
determine set supported values. However, number improvements MultiDecision Diagrams (MDDs) presented Cheng Yap (2008) reduce
portion graph must traversed order enforce consistency. dead
subgraph memoization, avoids traversal subgraphs cannot provide support
values, shortcutting, recognizes situations necessary
find one path ensure consistency. readily adapted BDD-based
set constraint solver.
4.2.1 Dead Subgraph Memoization
key observation dead subgraph memoization that, search progresses, paths
along graph ever removed. such, becomes unreachable
node n, subgraph incident n need never explored solver
backtracks. Thus, set dead nodes maintained, possible progressively
eliminate subgraphs propagation.
keep instance constraint c(x) failure set, fset records
nodes reach (and hence equivalent F). propagation, node n
shown path , added failure set fset. node processed,
first check fsetif so, terminate early, otherwise proceed normal.
modifications necessary shown right Figure 5. simplicity
pseudo-code treats fset global.
method efficiently maintaining failure sets presented Cheng Yap
(2008), uses sparse-set data structures provide efficient lookup, insertion backtracking. set fset maintained pair arrays: sparse dense counter
318

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

insert(S, n) {
S.sparse[n] = S.members
S.dense[S.members] = n
S.members++
}
set(S, n) {
index = S.sparse[n]
return index < S.members
S.dense[index] == n
}
(a) Sparse set operations

insert(S, n) {
old index = S.sparse[n]
swap value = S.dense[S.members]
S.sparse[n] = S.members
S.dense[S.members] = n
S.sparse[swap value] = old index
S.dense[old index] = swap value
S.members++
}
set(S, n) {
return S.sparse[n] < S.members
}
(b) Modified sparse-set operations

Figure 7: Pseudo-code conventional sparse-set operations, corresponding modified versions.

members. n fset sparse[n] < members dense[sparse[n]] = n. operations
insertion testing shown Figure 7(a). Crucially backtrack earlier forms
set simply resetting members value time.
structures improved slightly observation checking membership
occur significantly often insertion. Pseudo-code modified sparse-set
operations given Figure 7(b). insertion operations become expensive,
overall computation time reduced.

Example 5 Consider set illustrated Figure 8(a). elements set {1, 7}.
determine element 4 set S0 , sparse[4] strictly less
members, indicated arrow Figure 8(a).
insert element v using standard sparse-set operations, merely overwrite
dense[members] v, set value sparse[v] members. shown
Figure 8(b), inserting 3 S0 . point, sparse[3] sparse[4] value
2. test 4 S0 , sufficient determine sparse[4] < members. One must also
check dense[sparse [4]] = 4.
inserting v using modified operations, illustrated Figure 8(c), swap
values sparse[v] sparse [dense[members]], likewise switch values
dense[members] dense[sparse [v]]. maintains property v sparse[v] <
members.
319

fiGange, Stuckey, & Lagoon

0
sparse

dense

1

2

0

1

7

3

4

6

2

5

6

0

7
sparse

1

4

1
0

dense

3

2

1

7

3

4

2

2

3

2

5

6

7
1

3

3

(a) S0 = {1, 7}

(b) S0 {3}
0

sparse

dense

1

2

0

1

7

3

4

2

6

3

5

6

7
1

4

3

(c) S0 {3} using modified operations

Figure 8: sparse representation sets. (a) possible state data structure representing S0 = {1, 7}. (b) Inserting 3 data structure using standard operations.
sparse [3] updated point next element dense, corresponding entry
dense points back 3. Notably, sparse [3] sparse [4] point dense[2]. (c)
Inserting 3 data structure using modified operations. operation,
sparse dense arrays maintained v dense[sparse[v]] = v.
Dead subgraph memoization comes space cost O(|r|) store failure set
f set. reduces time complexity bddprop O((|r||f set|)|V |) O(|r||f set|+
|V |) practice.
4.2.2 Shortcutting
Shortcutting optimization propagation BDD notices values
current domains variables vi , vi+1 , , vN fully supported,
need examine rest nodes involving variables. keep high water mark
hwater shows least variable whose values supported. ever reach
node numbered high water mark need prove reaches ,
need fully explore sub-graph it.
modified propagation algorithm taking account shortcutting (and dead subgraph
minimization) given Figures 9 10. high water mark hwater originally larger
greatest variable appearing BDD.
principle difference imp bddp reach node variable
high water mark use simplified form shortcut bddp checks whether
node reach . complexity update high water mark hwater
find values v supported (E[v] = E [v]). shortcut bddp careful
mark variables nodes visited reach mattering propagator.
320

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

imp bddp(node,V ,E) {
(in set(fset, node)) return (1, 0);
switch node {
F : return (1,0);
: return (0,1);
n(v, f, t):
(visit[node] time) return save[node];
(v hwater) return shortcut bddp(node, V, E);
reachf = 0; reacht = 0; maxvar = v;
(0 E[v]) {
(rf0 , rt0 ) = imp bddp(f, V, E);
reachf = rf0 ; reacht = rt0 ;
(rt0 ) {
maxvar = top(f, V );
E [v] = E [v] 0;
(hwater top(f, V ) E [v] == E[v]) {
hwater = v;
reachf = 1;
goto cleanup;
}
}
}
(1 E[v]) {
(rf1 , rt1 ) = imp bddp(t, V, E);
reachf = reachf rf1 ; reacht = reacht rt1 ;
(rt1 ) {
maxvar = max(maxvar, top(t, V );
E [v] = E [v] 1;
(hwater top(t, V ) E [v] == E[v]) {
hwater = v;
}
}
}
(reacht ):
insert(fset, node);
cleanup:
(v V, v v maxvar)
E [v] = E[v];
(reachf reacht ) matters[v] = time;
save[node] = (reachf , reacht );
visit[node] = time;
return (reachf , reacht );
}
}

Figure 9: Pseudo-code processing constraint graph propagation, using deadsubgraph memoization shortcutting.
Example 6 Consider BDD constraint |y z| = 1 N = 3 shown
Figure 11(a). variables fixed, first explore false paths, find
node. provides complete support y2 , x3 , y3 , high-water mark updated
y2 . searching support x2 false, longer need find support anything
beneath high-water mark need find single path true node
labelled y2 . high water mark increases y1 . Likewise, finding support
x1 , everything point already supported, explore first path
. edges explored shown doubled 11(b).
Example 6 also illustrates impact shortcutting highly dependent
order branches searched, structure constraint
321

fiGange, Stuckey, & Lagoon

shortcut bddp(node,V ,E) {
(in set(fset, node)) return (1,0);
switch node {
: return (0,1);
n(v, f, t):
rf0 = 0;
(visit[node] time) return save[node];
(0 E[v]) {
(rf0 , rt0 ) = shortcut bddp(f, V, E);
(rt0 ) {
(1 E[v]) { matters[v] = time; rf0 = 1; }
visit[node] = time; save[node] = (rf0 , 1);
return save[node];
}
}
(1 E[v]) {
(rf1 , rt1 ) = shortcut bddp(t, V, E);
(rt1 ) {
(rf0 ) { matters[v] = time; rf1 = 1; }
visit[node] = time; save[node] = (rf1 , 1);
return save[node];
}
}
insert(fset, node);
return (1, 0);
}
}
Figure 10: Pseudo-code shortcut phase.

explore true branches first, rather false branches, would need explore
nodes find support variables. Clearly shortcutting change asymptotic
time space complexity algorithm. Note shortcutting BDDs complex
approach used Cheng Yap (2008) since treat long arcs
MDDs.

5. Hybrid SAT Solver
Despite fast propagation, pure set bounds-based solver nevertheless suffers
inability analyze reasons failure, results repeated exploration similar
dead subtrees. limits performance solver many hard problem instances.
order address this, construct hybrid solver embeds BDD-based set
bounds propagators within efficient SAT solver. Search conflict analysis per322

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

7654
0123
x1 C
CC
CC
C!
7654
0123
y1 C
CC
CC
C!
}
7654
0123
7654
0123
x2 C
x2 C
CC
CC
CC
CC
C!
C!
7654
0123
7654
0123
y2 C
y2
CC
CC
C! }
7654
0123
x3 C
CC
CC
C!
7654
0123
y3
}t

ff }t





7654
0123
x1CCC
CCCC
CCCC
C %
7654
0123
y1 C
CC
CC
C!
ff
7654
0123
7654
0123
x2 C
x2CCC
CC
CCCC
CCCC
CC
C %
C!
7654
0123
7654
0123
y2 C
y2
CC
CC
C! }
7654
0123
x3 C
CC
CC
C!
7654
0123
y3

F





(a)

F
(b)

Figure 11: (a) BDD representing |x y| 1 N = 3. node n(v, f, t) shown
circle around v dotted arrow f full arrow t. (b) edges traversed
imp bddp, E[v] = {0, 1} v, shown doubled.
formed SAT solver, BDD propagators used generate inferences
clauses SAT solver use propagation.
5.1 Efficient Reason Generation
Key successful SAT solver recording nogoods, small subsets current
variable assignments independently result failure. allows similar subtrees
eliminated consideration, hence significantly reducing search space.
order construct nogoods, necessary explain reason literal
set. order determine chain reasoning resulted contradiction.
pure SAT solver easy, variable either decision variable, associated
clause caused propagation.
BDD-based propagation methods, however, automatically provide explanations
inference. naive approach generating reason clause BDD inference
enumerate fixed variables occur propagator, construct clause
negations:
^
_
li l l
li
li f ix(B)

li f ix(B)

Unfortunately, often results large reason clauses, particularly case
merged propagators global constraints. smaller clauses result stronger nogoods
generated SAT solver, preferable determine minimal set variables
required cause propagation, include variables clause.
method constructing minimal clauses demonstrated Hawkins
Stuckey (2006), method involves constructing new BDDs, eliminating redundant
variables minimal BDD constructed, reading variables remaining
323

fiGange, Stuckey, & Lagoon

BDD. Given propagation algorithm herein avoids expensive BDD operations,
wish use explanation.
Given set assignments {l0 , . . . , lk } entail literal l respect constraint
C, also true


^
li
C l
i{0...k}

result, problem finding minimal reason given inference BDD
equivalent fixing l unfixing many variables possible without rendering
reachable.
algorithm presented Subbarayan (2008) provides method traversing static graph, avoiding need construct intermediate BDDs. algorithm,
given Figure 12, traverses node n(v, f, t) top-down memoing manner.
node, records if, given current domain, node reachable. variable
v assigned value, also records reachable conflicting edge;
edges must become relaxed, otherwise partial assignment longer
conflict.
graph traversed second time, time breadth-first manner.
variable v, nodes reached corresponding v variable may relaxed
without opening path , v unfixed. v remains fixed, v marked part
reason, node corresponding value v marked reachable.
Otherwise, v minimal reason, f nodes marked
reached. procedure returns reason clause. procedure O(|r|) time
space complexity, note O(|r|) per new propagation explained!
Example 7 Consider constraint assignments obtained Example 4. determined E[y1 ] = {1}E[z2 ] = {1} E[x2 ] = {1} (or equivalently, 1 y2 z 2 x).
such, naive reason clause explain 2 x would y1 z2 x2 ; however,
possible construct smaller clause this.
order construct minimal reason E[x2 ] = {1}, first set E[x2 ] = {0}.
corresponding graph shown Figure 13(a), nodes consistent
partial assignment shown doubled. Note solid edge x2 consistent
assignment, reachable along doubled path root node.
algorithm determines set nodes reachable
nodes shown doubled Figure 13(b). nodes must remain unreachable along
final reason; such, nodes must remain fixed x2 node leftmost
z2 node.
Finally, algorithm progressively unfixes variables would provide
path (in case, y1 ). final path shown Figure 13(c), resulting inference
E[z2 ] = {1} E[x2 ] = {1}; corresponding reason clause x2 z2 .
5.2 Lazy Reason Generation
simplest way use reason generation called eager generation, whenever
BDD propagator makes new inference, minimal reason clause generated added
324

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

construct reason(r,V ,D,var,sign) {
Let r = n(v, t, f )
Dold = D[var];
D[var] = {1 sign};
forall (nodes n r) visit[n] :=
mark reason(r,V,D);
reached [v] = {r};
(sign)
mark reason(node,V ,D) {
reason = var;
(visit[node] 6= ) return visit[node];
else
Let node = n(v, t, f )
reason = var;
reachhi = mark reason(t, V, D);
(v V ) {
reachlow = mark reason(f, V, D);
fixedvar = false;
reacht = false;
(n reached[v ]) {
(0 D[v])
fixedvar = fixedvar fixed [n];
reacht = reacht reachlow ;
}
else
(fixedvar v 6= var) {
fixed[node] = reachlow ;
(0 D[v])
(1 D[v])
reason = reason v;
reacht = reacht reachhi ;
else
else
reason = reason v;
fixed[node] = reachhi ;
}
visit[node]
= reacht;
(n(vn , fn , tn ) reached[v ]) {
return reacht ;
(fixedvar 1 D[v ])
}
reached[vn ] = reached[vn ] tn ;
(fixedvar 0 D[v ])
reached[vn ] = reached[vn ] fn ;
}
}
D[var] = Dold ;
return reason;
}
Figure 12: Pseudo-code reason generation algorithm Subbarayan (2008). Constructs minimal set variables required cause inference var = sign.
SAT solver. clauses, however, cannot make meaningful contribution search
conflict detected cannot cause propagation solver backtracks
beyond fixed variable, conflict clauses constructed conflict.
degree overhead adding maintaining large set clauses
solver, may better delay constructing reasons actually required
explain conflict.
instead apply reason generation SAT conflict analysis asks
explanation literal set BDD solver. call lazy generation.
325

fiGange, Stuckey, & Lagoon

7654
0123
x1CCC
CCCC
CCCC
C %
7654
0123
y1




7654
z1

0123
{{{{{{{

{
%
{{{{
7654
0123
x2 C
CC
CC
C!
7654
0123
y2



ff
7654
0123


{{{z2


{
{
{{
!
{{{


7654
0123
y1

7654
0123
z1






0123
y2
7654

ff
7654
0123
z2
|||||
||||


zrzt |

F



7654
0123
x1EEE
EEEE
EEEE
E &
7654
0123
y1
ffff
ff
ff
ffff
ffffffff 7654
z1
ff
ff 0123
ffffffffxxxxxxx
ff
ffx
% ffffx xxxx
7654
0123
x2 C
CC
CC
C!
@ABC
GFED
?>=<
89:;
y2


ff
@ABC
?>=<
89:;
GFED
z2
|||

|
|
||

|||


7654
0123
y1

7654
0123
z1





{
7654
0123
y2



ff
7654
0123
z
2


ff{ s{t

F
(a)



(b)

w
7654
0123
y1
ff
7654
0123
z1





x
7654
y2
0123

ff
GFED
?>=<
89:;
z2
@ABC
}}}}}}
}


zrzt }}}

F

7654
0123
x1EEE
EEEE
EEEE
E &
7654
0123
y1
fifi
fi
fi
fifi ff
fifififi 7654
z1
fi
fi 0123
fifififi{{{{{{{
fi
fi{{
& fifiy {{{
@ABC
GFED
?>=<
89:;
x2 C
CC
CC
C!
7654
0123
y2


0123
7654
z

|| 2

|

|
" }||



(c)

Figure 13: (a) BDD representing x = z N = 2, E[y1 ] = {1}, E[z2 ] = {1}
E[x2 ] = {0}. Edges consistent partial assignment shown doubled. (b)
Nodes must remain unreachable reason shown doubled. (c) Edges reachable
along minimal reason shown doubled, nodes remain fixed.

order so, must determine state propagator caused inference.
implement recording order literals become fixed propagator.
generating reason variable v becoming fixed, look variable
propagator, unfix variable v time(v) time(v ), restore
reason constructed.
5.3 Hybrid Architecture
hybrid SAT solver embeds BDD propagators inside SAT engine. architecture
illustrated Figure 14. usual SAT engine architecture shown left. BDD
propagation added shown right. Unit propagation causes Boolean literals
fixed may require BDD propagators need awoken. attach
Boolean variable representing part set variable x BDD propagators involving
set variable. unit propagation reaches fixpoint, trail fixed literals traversed
BDD propagator includes one literals scheduled execution.
using filtering, scheduled literal one matters propagator.
execute scheduled BDD propagators using imp bddp. BDD propagator
fixes literals added trail unit propagation engine.
using eager reason generation also immediately build clause explaining
propagation add clause database record clause reason
propagation literal.
using lazy reason generation, instead record reason simply pointer
BDD propagator causes literal fixed. conflict analysis demands
explanation literal, call reason generation BDD propagator, using
326

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

SAT Engine
Search

BDD Propagator
Filtering

conflict
analysis

unit
propagation

imp_bddp

reason
generation

Clause Database

Figure 14: Architecture hybrid BDD-SAT solver.

state time literal fixed, build explaining clause.
used conflict analysis. replace reason literal trail generated
explanation clause also add explanation clause database.
implementation inherits almost features underlying SAT solver. Eager
reason clauses added nogoods, deleted SAT solver decides eliminate
nogoods, lazy reason clauses generated demand conflict analysis.
added clause database even though necessary, since makes memoing
explanations already performed simpler. hybrid solver make use
restarting activity based search, restarts, although also extend search capabilities
allow simple static searches preferable set problems tackle.

6. Experimental Results
built hybrid SAT solver implementing algorithms described above. solver
based MiniSAT 2.0 (dated 070721) (Een & Sorensson, 2003), modified
include BDD-based propagation engine. BDDs constructed using BuDDy
BDD package (http://sourceforge.net/projects/buddy/) BDDs constructed
beginning execution, converted static graph used propagation. Indeed,
many smaller problems solved Section 6, majority solution time
used constructing BDDs.
BDD propagators executed lower priority level unit propagation,
order detect conflict early possible. Reason clauses generated setbounds propagator added SAT solver learnt clauses, otherwise number
clauses added solver propagation hard problems overwhelm solver.
Experiments conducted 3.00GHz Core2 Duo 2 Gb RAM running
Ubuntu GNU/Linux 8.10. problems terminated completed within 10 minutes.
327

fiGange, Stuckey, & Lagoon

experimented 3 classes set benchmarks: social golfers, Steiner systems,
Hamming codes. Unless otherwise specified, hybrid solver always executed using lazy
reason generation.
compare Gecode 3.1.0 set bounds propagation solver since acknowledged one fastest solvers available, well ECLiPSE 6.0 #100. also compare published results Cardinal (Azevedo, 2007) Length-Lex (Yip &
Van Hentenryck, 2009) solvers problems.
6.1 Social Golfers
common set benchmark Social Golfers problem, consists arranging
N = g golfers g groups players w weeks, two players
play together once. Again, use model used Lagoon
Stuckey (2004), using w g matrix set variables vij 1 w 1 j g.
V V

g
w
< (v , . . . , v ))
partition
|v
|
=


i1
ig
ij
i=1
V
i=1
V j=1V

V
w1 w
|v

v
|

1

v

v
j1
jl
i,j{1...w}, i6=j
k,l{1...g} ik
i=1
j=i+1 i1
(

Vw

global constraint partition< ensures arguments pairwise disjoint imposes
lexicographic order arguments, i.e. vi1 < < vig . corresponding propagator
based single BDD. construct BDD propagators constraint forms
|v v | 1, v v |v| = s. Note first form would typically decomposed
u = v v |u| 1 normal set bounds propagator.
hybrid solver constructs one BDD 4 terms equation,
instantiating constraints accordingly.
Table 1 shows results using static search strategy easy problems. search
fixes elements sets vij order v11 , v12 , . . . , v1g , v21 , . . . , vwg , always trying first
place least element set excluding set. compare
reported results original BDD-SAT hybrid solver Hawkins Stuckey (2006)
versus number variations hybrid. base base solver Figures 4 5,
+f indicates filtering Section 4.1 added, +s indicates dead subgraph
memoization shortcutting added (Section 4.2) using original sparse set code, +i
optimizations improved sparse set code. also combine filtering
optimizations. table shows time number fails variant,
solvers identical failure behaviour grouped together. Note filtering
change search reordering propagations hence changing nogoods
generated, optimizations cannot except shortcutting change
results filtering (and hence change search). filtering improves base line,
dead subgraph memoization shortcutting not, although see benefit
improved sparse set operations. Comparing solver Hawkins Stuckey
(2006), run () 2.4GHz Pentium 4, find that, slightly different number
backtracks slightly faster machine withstanding, solver presented
roughly order magnitude faster.
Table 2 shows results using VSIDS search easy problems. compares
solver Hawkins Stuckey (2006) Tseitin decomposition. results
328

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

Problem
2,5,4
2,6,4
2,7,4
2,8,5
3,5,4
3,6,4
3,7,4
4,5,4
4,6,5
4,7,4
4,9,4
5,4,3
5,5,4
5,7,4
5,8,3
6,4,3
6,5,3
6,6,3
7,5,3
7,5,5
Total

Hawkins
time
fails
0.10
11
0.10
45
0.20
90
0.80
472
0.10
11
0.20
48
0.70
81
0.20
11
0.70
81
0.80
105
1.90
32
12.00
9568
2.30
1167
1.50
159
0.90
12
2.10
908
0.90
282
0.40
5
18.20
6152
0.80
100
44.90
19340

base
0.03
0.04
0.06
2.84
0.02
0.04
0.12
0.03
0.25
0.11
0.18
2.58
0.42
0.18
0.06
0.51
0.13
0.05
3.79
0.20
11.64

+s
0.02
0.04
0.07
3.15
0.02
0.05
0.08
0.03
0.27
0.14
0.18
3.00
0.48
0.25
0.10
0.60
0.14
0.04
4.67
0.20
13.53

Static Search
Hybrid
+i
fails
+f
0.02
19
0.02
0.05
126
0.05
0.07
148
0.07
3.13
8856
0.47
0.04
19
0.02
0.07
129
0.05
0.11
165
0.10
0.04
19
0.02
0.26
559
0.07
0.15
171
0.18
0.18
40
0.14
2.92
10294
2.35
0.46
1328
0.33
0.21
217
0.24
0.07
10
0.08
0.57
1699
0.33
0.16
278
0.09
0.05
5
0.03
4.45
7616
2.10
0.18
121
0.18
13.19
31819
6.92

fails
19
153
265
1119
19
156
282
19
77
288
40
10209
1293
335
10
1079
261
5
5702
121
21452

+fs
0.02
0.05
0.07
0.50
0.03
0.06
0.14
0.02
0.10
0.17
0.14
2.69
0.40
0.25
0.06
0.32
0.11
0.03
3.08
0.21
8.45

+fi
0.02
0.04
0.07
0.50
0.02
0.06
0.12
0.03
0.09
0.17
0.14
2.69
0.36
0.24
0.10
0.33
0.14
0.04
2.97
0.20
8.33

fails
19
153
265
1119
19
156
282
19
77
288
40
10188
1297
335
10
922
257
5
6302
121
21874

Table 1: First-solution performance results Social Golfers problem using static,
first-element set ordering. Instances marked () unsatisfiable, entries marked
complete within 10 minutes.

Table 1, overall VSIDS better static search. table illustrates
difficulty comparing systems using VSIDS search, since small differences
drastically change search space. solver +f best except bad-performance
7,5,3. base solver around 5 times faster per failure solver Hawkins
Stuckey (2006). Tseitin decomposition competitive, even discount
results 7,5,3.
social golfers, dead-subset memoization shortcutting provide advantage
(when discount drastically different search 7,5,3 using VSIDS). number
nodes processed reduced slightly, enough repay additional cost
computation node.
Table 3 compares reason generation strategies: eager reasoning constructs reasons soon inference detected; lazy reasoning reasons necessary
determine first UIP perform conflict clause minimization.
Table 3 compares base solver without filtering (since dead subgraph memoization shortcutting help here) harder social golfer problems using static
search. shows time (base) well number reasons generated fails order
find first solution. harder examples filtering highly beneficial.
see number reasons generated lazy reasoning half required
eager reasoning, doesnt make much difference computation time, since
propagation dominates time spent solver. Interestingly adding reasons eagerly also seems generate slightly better nogoods search usually smaller. Table 4
shows results using VSIDS search harder instances. appears advantages
329

fiGange, Stuckey, & Lagoon

Problem
2,5,4
2,6,4
2,7,4
2,8,5
3,5,4
3,6,4
3,7,4
4,5,4
4,6,5
4,7,4
4,9,4
5,4,3
5,5,4
5,7,4
5,8,3
6,4,3
6,5,3
6,6,3
7,5,3
7,5,5
Total

Hawkins
time
fails
0.10
22
0.10
64
0.20
119
1.30
622
0.10
24
0.30
58
0.60
92
0.40
122
1.30
304
1.00
98
2.00
59
5.60
5876
1.90
581
1.50
104
1.70
425
0.20
71
4.30
2801
1.00
275
18.00
7018
2.00
139
43.60
18874

base
0.04
0.02
0.03
0.10
0.04
0.05
0.06
0.05
0.26
0.09
0.16
1.23
4.14
0.16
0.08
0.18
0.25
0.07
8.81
0.14
15.96

+s
0.03
0.03
0.03
0.12
0.04
0.04
0.06
0.06
0.26
0.11
0.18
1.42
5.16
0.13
0.10
0.17
0.27
0.06
11.08
0.11
19.46

+i
0.03
0.02
0.03
0.11
0.02
0.04
0.06
0.06
0.26
0.10
0.18
1.35
4.80
0.13
0.10
0.17
0.29
0.07
10.72
0.12
18.66

VSIDS Search
Hybrid
fails
+f
fails
4
0.02
4
20
0.03
20
13
0.04
13
109
0.10
109
51
0.03
51
80
0.06
80
78
0.07
79
108
0.04
116
309
0.13
158
102
0.10
103
36
0.14
36
5869
0.56
3139
9846
0.91
2487
77
0.11
84
29
0.10
29
425
0.14
479
369
0.18
409
36
0.07
70
18949
39.35
93789
47
0.10
47
36557
42.28
101302

+fs
0.02
0.02
0.05
0.10
0.03
0.04
0.06
0.06
0.14
0.09
0.18
0.69
0.77
0.13
0.10
0.30
0.17
0.08
2.47
0.13
5.63

+fi
0.03
0.02
0.04
0.10
0.04
0.04
0.10
0.06
0.15
0.08
0.15
0.67
0.74
0.12
0.10
0.28
0.16
0.09
2.38
0.10
5.45

fails
4
20
13
109
51
80
79
116
205
103
36
3184
1754
84
29
1013
397
70
4554
47
11948

Tseitin
time
fails
0.03
7
0.04
37
0.06
55
0.09
78
0.05
170
0.07
268
0.12
469
0.14
1143
0.49
3156
0.25
1020
0.63
1037
4.74
26769
0.58
3475
1.16
3596
0.52
918
2.83
17595
1.85
8675
1.09
3547
45.54
77786
0.93
1977
61.21
151778

Table 2: First-solution performance results Social Golfers problem using VSIDS
search strategy.
Social Golfers
Problem
7,5,3
2,6,5
4,6,5
6,10,3
9,10,3
10,10,3
Total

base
6.34
0.14
0.46
0.90
16.91
109.43
134.18

Lazy Reason Generation
reasons
fails
+f
reasons
62630
13071
5.49
65447
1673
581
0.03
317
7058
1067
0.38
7026
6675
871
0.72
6973
15522
3857
15.74
15103
28110
11462
130.04
32580
121668
30909
152.40
127446

fails
13079
66
1037
946
3708
13128
31964

base
8.76
0.17
0.55
1.04
27.88
198.90
237.30

Eager Reason
reasons
fails
117323
13273
3026
581
11833
1066
9942
820
34181
4039
81270
12755
257575
32534

Generation
+f
reasons
7.38
117657
0.04
740
0.48
11967
0.87
10101
25.77
32945
187.11
79461
221.65
252871

Table 3: First-solution performance results harder Social Golfers problems, using static
least-element set search method. Results given comparing eager lazy reason
generation.

lazy reasoning increased use VSIDS, presumably better nogoods
useful driving search.
Finally Table 5 compares number different systems. use model
social-golfers described work Yip Van Hentenryck (2009), addition
fixes first week, first group second week eliminate symmetric solutions.
use instances reported Yip Van Hentenryck (2009). show results
base solver without filtering. compare Gecode 3.1.0 Eclipse 6.0
#100, implement set bounds propagation combined limited cardinality
reasoning, identical MiniZinc model social-golfers running 3GHz Core2Duo.
Gecode arguably represents state art set bounds propagation solving. also
compare published results Cardinal solver (Azevedo, 2007), uses
330

fails
12598
66
1028
849
3853
12338
30732

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

Social Golfers
Problem
7,5,3
2,6,5
4,6,5
6,10,3
9,10,3
10,10,3
Total

base
0.20
0.02
0.06
0.22
0.92
1.51
2.93

Lazy
reasons
2096
38
176
188
1743
1917
6158

Reason
fails
217
4
18
7
110
139
495

Generation
+f
reasons
1.03
12638
0.02
38
0.06
176
0.18
188
0.45
666
0.64
641
2.38
14347

fails
2608
4
18
7
68
46
2751

base
0.22
0.03
1.28
0.34
1.59
2.06
5.52

Eager Reason
reasons
fails
4328
212
350
4
28026
1565
1824
7
6685
134
7707
200
48920
2122

Generation
+f
reasons
2.18
63780
0.04
350
0.08
1604
0.34
1823
1.20
6310
1.08
4310
4.92
78177

fails
4911
4
40
7
107
57
5126

Table 4: First-solution performance results harder Social Golfers problems, using
VSIDS search method. Results given comparing eager lazy reason generation.
complex cardinality reasoning set solving, using () Pentium 4 2.4GHz machine,
recently published results Length-Lex solver Yip Van Hentenryck
(2009), maintains bounds sets variables terms length-lex order (see Gervet
& Van Hentenryck, 2006; Yip & Van Hentenryck, 2009 details) running () C2DM 2.53GHz machine. pure set bounds solvers cannot compete approach
since search space without using nogood recording big. None
systems except Length-lex solve instances. One see drastic
difference number failures Gecode, uses set bounds propagation
without learning, versus base solver. Gecode sometimes require less failures
easy problems since combines cardinality reasoning bounds reasoning, hard
problems advantages learning prune similar searches parts tree
dominates completely. stronger pruning Length-lex compared set bounds
means often improve fails compared base learning robust.
hybrid solver overall around order magnitude faster Length-Lex.
6.2 Steiner Systems
Another commonly used benchmark set constraint solvers calculation small
Steiner systems. Steiner system S(t, k, N ) set X cardinality N collection
C subsets X cardinality k (called blocks), elements
X

exactly one block. Steiner system must exactly = Nt / kt blocks (Theorem
19.2 van Lint & Wilson, 2001).
model Steiner problem similarly Lagoon Stuckey (2004) extended
case general Steiner Systems. model block set variable s1 , . . . , sm ,
constraints:

^

(|si | = k)

i=1
m1
^


^

(|si sj | 1 si < sj )

i=1 j=i+1

comparison results Azevedo (2007) Yip Van Hentenryck (2009),
construct dual model additional variables d1 , . . . , dN , additional constraints
331

fiGange, Stuckey, & Lagoon

Problem
4,4,2
5,4,2
6,4,2
7,4,2
4,4,3
5,4,3
6,4,3
4,4,4
5,4,4
3,5,2
4,5,2
5,5,2
6,5,2
7,5,2
8,5,2
9,5,2
3,5,3
4,5,3
5,5,3
6,5,3
7,5,3
2,5,4
3,5,4
4,5,4
5,5,4
3,5,5
4,5,5
5,5,5
6,5,5
7,5,5
2,6,3
3,6,3
4,6,3
5,6,3
6,6,3
2,6,4
3,6,4
2,6,5
3,6,5
4,6,5
5,6,5
3,6,6
2,7,2
2,7,3
2,7,4
3,7,4
4,7,4
5,7,4
2,7,5
2,7,6
2,7,7
5,8,3
4,8,4
2,8,5
4,9,4
6,10,3
9,10,3
10,10,3
4,10,4
5,10,4
Total

Gecode
0.00
0
0.00
0
0.00
0
0.00
0
0.00
6
1.72
5781
0.01
45
0.00
0
0.00
0
0.00
1
0.00
2
0.00
2
0.00
6
0.01
17
0.01
22
0.01
17
0.01
49
0.03
73
0.03
105
110.33
335531


0.09
1090
0.11
605
0.09
298
0.19
410
0.00
1
0.01
13
0.04
45
0.03
30
8.11
12274
0.00
0
0.01
30
0.01
23
0.09
311
0.15
388
1.91
16608
3.68
15948


547.91
1893577
275.38
584532
96.89
145371
0.01
8
0.00
1
0.00
10
5.64
39833
13.40
46621
10.54
24216
11.32
18785




0.01
0


26.92
56844


8.93
11854






17.33
16345
34.62
36294



Eclipse
0.56
0.54
0.55
0.62
0.56
11.21
0.66
0.57
0.61
0.54
0.57
0.61
0.66
0.71
0.81
0.86
0.58
0.65
0.76


1.26
1.10
0.98
1.40
0.65
0.74
0.84
0.96
161.12
0.56
0.69
0.71
1.08
1.32
8.12
10.16



265.40
0.82
0.60
0.64
17.43
27.23
19.38
17.17


0.86

46.03

12.18



17.10
46.58


Cardinal

165.63
94.67



1.89
3.13
28.65



1.20
1.75
4.62



2.82
6.37
12.46
17.18

1.01

42.45



length-lex
0.01
0
0.01
0
0.01
0
0.01
0
0.01
0
0.40
732
0.02
29
0.06
111
0.05
57
0.01
0
0.01
0
0.01
0
0.01
0
0.02
1
0.02
1
0.02
1
0.01
1
0.01
1
0.02
5
0.41
316
74.59
46117
0.01
11
0.02
24
0.14
194
1.87
1947
0.06
93
4.72
6876
54.27
50623
29.21
15769
0.01
1
0.00
0
0.01
1
0.01
1
0.02
6
0.04
10
0.01
14
0.03
42
0.05
118
2.54
3351
32.60
31270
28.76
6758
0.82
661
0.01
0
0.01
1
0.01
0
0.03
21
0.05
26
0.36
152
0.31
574
0.78
1271
0.28
0
34.52
45477
0.06
18
0.25
307
0.21
94
5.86
2941
233.80
45437
210.80
25246
0.27
104
0.58
149
719.11
286960

base
0.01
0.02
0.02
0.02
0.01
0.46
0.03
0.02
0.02
0.02
0.01
0.02
0.01
0.04
0.06
0.12
0.02
0.03
0.03
0.80
6.32
0.02
0.03
0.07
0.98
0.02
0.05
0.07
0.15
3.28
0.02
0.03
0.04
0.04
0.39
0.04
0.06
0.13
0.15
0.45
15.24
0.04
0.03
0.02
0.02
0.07
0.08
0.22
0.45
1.44
0.06
0.09
0.12
0.56
0.19
0.91
16.66
110.80
0.52
0.76
162.39

+f
3
4
8
13
9
1877
57
3
8
1
3
5
8
14
24
40
10
18
30
2516
13071
21
36
191
2592
0
29
64
167
4728
4
4
11
15
932
58
97
581
532
1067
26495
0
0
0
19
69
62
243
1944
6031
0
71
67
2145
90
871
3857
11462
409
576
83262

0.01
0.02
0.02
0.04
0.02
0.35
0.04
0.02
0.03
0.02
0.03
0.02
0.03
0.04
0.05
0.14
0.02
0.01
0.03
0.56
5.50
0.02
0.02
0.08
0.74
0.02
0.04
0.06
0.15
8.17
0.02
0.01
0.02
0.04
0.27
0.02
0.05
0.05
0.08
0.35
2.85
0.03
0.03
0.03
0.05
0.07
0.08
0.16
0.07
0.18
0.05
0.11
0.10
0.23
0.19
0.73
15.64
129.66
0.46
0.65
168.58

3
4
8
13
9
1799
57
3
8
1
3
5
8
14
24
40
10
16
30
2345
13079
21
36
189
2356
0
27
64
221
11736
4
4
11
15
959
58
97
66
178
1037
7295
0
0
0
19
72
63
234
133
566
0
70
67
291
100
946
3708
13128
419
596
62265

Table 5: Comparison solvers using different propagation mechanisms, using
model instances described Yip Van Hentenryck (2009). denotes failure
complete test-case 10 minutes (or 15 minutes Cardinal). blank entry means
published result compare.
shown:
^
N
^

(j si dj )

i=1 j=1
N
^

(|dj | =

j=1

332

mk
)
N

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

Problem
2,3,7
2,3,9
2,3,13
2,3,15
2,3,19
2,3,21
2,3,25
2,3,27
2,3,31
2,3,33

Gecode
time
fails
0.00
0
0.00
3
0.03
18
0.04
0
0.65
144
2.61
413









Eclipse
time
0.53
0.56
1.20
2.15
8.09






Card
time
0.01
0.05
0.61
0.91
7.94
39.07

48.52

Length-lex
time
fails
0.00
0
0.01
1
0.05
10
0.09
0
0.46
164
1.04
448
14.07
5100
23.55
7066
5.29
0

Static Hybrid
base
fails
0.01
0
0.02
1
0.06
9
0.07
0
0.37
78
0.82
225
7.10
2474
12.88
3401
5.38
0
443.07
111923

VSIDS Hybrid
base
fails
0.03
5
0.02
17
0.02
24
0.32
295
0.07
106
39.19
42688


229.59
113373


19.30
8228

Tseitin
time
fails
0.04
59
0.81
3804
1.93
7879
143.81
124205
14.01
34089











Table 6: First-solution performance results alternate Steiner Systems instances using
dual model. Gecode sequential hybrid use sequential least-element set search
strategy dual variables. VSIDS hybrid Tseitin decomposition use VSIDS
search. denotes failure complete test-case 10 minutes due either timeout
memory error. blank entry means published result compare.


create BDD propagators constraint forms |v| = mk
N |v v |


1 v < v |v| = k |v | = k. note non-BDD based set bounds solvers last
form would typically five separate constraints. channelling component j v v
explicitly represented. Instead, underlying Boolean variables re-used.

Table 6, use model search strategy used Azevedo (2007), restricting
number times given element occur sets s1 , . . . , sm . compare
Gecode Eclipse using MiniZinc model, well published results
Cardinal Length-Lex. model used hybrid solver constructs one
constraint pair set variables, conjoining cardinality, intersection ordering
constraints. instances significant amount search occurs, see
massive improvement beyond performance pure set bounds propagation
solvers. hybrid solver Length-Lex robust. see hybrid
requires least search somewhat faster Length-Lex. also compare
versus VSIDS search. Steiner problems illustrate specialized search strategy
better generic VSIDS approach. see Tseitin decomposition
competitive problems

6.3 Fixed-weight Hamming Codes
problem finding maximal Hamming codes also expressed set-constraint
problem. Hamming code distance length l set l-bit codewords
pair codewords must least bits differ. variation problem
find maximal codes codewords exactly w bits set.
333

fiGange, Stuckey, & Lagoon

Problem
8,4,4
9,4,3
9,4,4
9,4,5
9,4,6
10,4,3
10,4,4
10,4,5
10,4,6
10,4,7
10,6,5

Fixed-weight Hamming Codes
Length-lex
Static Hybrid
time
fails
+f
+fs
+fi
0.07
110
0.16
0.17
0.16
2.05
4617
7.13
7.47
7.25










0.40
908
1.67
1.66
1.61
359.30
629822


















1.99
4415



0.03
158
78.99
78.14
78.92

Gecode
time
fails




















280.97
2175542

fails
897
29985


10541





92349

Table 7: Results hard Hamming instances static least-element set search order,
additional symmetry breaking.
Problem
8,4,4
9,4,3
9,4,4
9,4,5
9,4,6
10,4,3
10,4,4
10,4,5
10,4,6
10,4,7
10,6,5

+f
0.08
0.30
56.55
69.28
0.43
102.64
53.72

509.13
110.65
0.71

Fixed-weight Hamming Codes
VSIDS Hybrid
Tseitin
+fs
+fi
fails
time
fails
0.08
0.10
282
11.15
50530
0.26
0.24
1627
16.18
67876
45.95
43.39 210183


59.56
56.65 307786


0.39
0.36
2589
14.84
55292
90.37
86.09 638214


38.72
37.04
91781







404.65
385.48 987682


101.37
103.20
727465


0.57
0.54
5057
157.86
693148

Table 8: Results hard Hamming instances VSIDS, additional symmetry
breaking.
formulation problem is:

^

(|si | = w)

i=1
m1
^


^

(|si sj | si < sj )

i=1 j=i+1

= (s ) (s s) symmetric difference. similar structure
formulation Steiner Systems; however, rather fixed number
sets, find maximal code repeatedly adding new sets corresponding
constraints solution found. unsatisfiability n codewords proves
maximal code n 1 codewords. create BDD propagators constraint form
|v v | v < v |v| = w |v | = w.
compare two different models fixed-weight Hamming code problems, one
using description above, another first two sets fixed remove
symmetries. compare Gecode, published results Length-Lex
334

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

Problem
8,4,4
9,4,3
9,4,4
9,4,5
9,4,6
10,4,3
10,4,4
10,4,5
10,4,6
10,4,7
10,6,5

Gecode
time
fails
15.29
29869
66.72
216598




47.72
101832










0.07
546

Fixed-weight Hamming Codes
Length-lex
Static Hybrid
time
fails
+f
+fs
+fi
0.07
110
0.04
0.04
0.04
2.05
4617
0.28
0.29
0.28


18.09
17.95
17.99


55.90
56.52
57.14
0.40
908
0.04
0.04
0.04
359.30
629822


















1.99
4415
6.16
6.24
6.29
0.03
158
0.02
0.02
0.02

fails
51
2130
43318
71777
208




22857
70

Table 9: Results hard Hamming instances sequential least-element set search
order, fixed first second sets.
Problem
8,4,4
9,4,3
9,4,4
9,4,5
9,4,6
10,4,3
10,4,4
10,4,5
10,4,6
10,4,7
10,6,5

+f
0.03
0.08
1.28
4.82
0.06
2.76
20.53
143.50
64.10
2.21
0.03

Fixed-weight Hamming Codes
VSIDS Hybrid
Tseitin
+fs
+fi
fails
time
fails
0.05
0.03
61
1.06
6194
0.06
0.06
300
3.19
19952
1.10
1.04
4466
319.05
407762
4.20
4.03
21651
186.64
244474
0.05
0.06
256
1.31
8328
2.56
2.37
16755
120.22
226380
15.45
14.66
34503


104.29 104.39
184051


51.76
48.96 131379


2.05
1.96
13533
58.06
112269
0.04
0.03
145
0.10
1044

Table 10: Results hard Hamming instances VSIDS search strategy, fixed
first second sets.
hybrid using static search strategy (the least element set strategy used Social
Golfers), well hybrid solver Tseitin decomposition using VSIDS search.
systems compare without shortcutting optimized implementation.
Since sure model used Length-Lex report results
models.
Tables 7 10 show results 11 hard instances reported Hawkins et al.
(2005). Clearly problems VSIDS hybrid robust. solve
one instance basic model, additional symmetry breaking.
example also clearly shows potential advantages shortcutting improved
data structures: change search improve time 18% 21%
respectively base model, 24% 26% respectively improved model.
Tseitin decomposition competitive.

7. Related Work
Set-constraint problems active area research past decade. Many
earlier solvers, beginning PECOS (Puget, 1992), used set-bounds repre335

fiGange, Stuckey, & Lagoon

sentation combined fixed set propagation rules constraint. general
approach also used Conjunto (Gervet, 1997), ECLi PSe (IC-PARC, 2003), ILOG
Solver (ILOG, 2004) Mozart (Muller, 2001). However, set-bounds relatively
weak approximation domain set variable, variety variations developed improve propagation strength set-constraint solvers. include solvers
combine set-bounds representation either cardinality information,
proposed Azevedo (2002, 2007), lexicographic bounds information (Sadler & Gervet,
2004) (Gervet & Van Hentenryck, 2006; Yip & Van Hentenryck, 2009).
BDD-based approaches set-constraint solving, presented Hawkins
et al. (2005) differs greatly approaches, possible perform propagation
arbitrary constraints; Lagoon Stuckey (2004) also demonstrated feasibility
BDD-based solver maintains complete domain representation set variables.
directly BDD-based algorithms used construct earlier hybrid solver
presented Hawkins Stuckey (2006), conceptually similar solver presented paper. solver presented much efficient, includes improvements filtering shortcutting present solver Hawkins Stuckey
(2006). solver Damiano Kukula (2003) also combines BDD solving SAT
solving, rather building BDDs high-level problem description lazily
constructing SAT representation, instead takes CNF SAT representation constructs
BDD collection clauses primary goal variable elimination.
essentially equivalent base solver.
underlying BDD propagation algorithm similar propagation case constraint SICStus PRolog (SICS, 2009) Multi-valued Decision Diagrams (MDDs) (see
e.g., Cheng & Yap, 2008). Indeed adapted dead subgraph memoization
shortcutting devices Cheng Yap (2008) BDD propagation. Propagators case
MDDs presently use filtering generate reasons.
Finally hybrid set solver present paper example lazy clause
generation solver (Ohrimenko, Stuckey, & Codish, 2007, 2009). BDD propagators
understood lazily creating clausal representation set constraints encoded
BDD, search progresses.

8. Concluding Remarks
paper improved BDD-based techniques set-bounds propagation,
demonstrated approach avoids need expensive BDD construction
manipulation operations. traversal-based method, combined filtering
reduce number redundant propagator executions dead subgraph memoization
shortcutting, least order magnitude faster previous techniques
construct BDDs runtime (Hawkins et al., 2005).
Furthermore, integrated modern SAT solver clause learning augmented method generating nogoods, new hybrid solver capable solving
hard problem instances several orders magnitude faster pure bounds set solvers.
Overall hybrid solver robust highly competitive propagation
based set-solvers aware of.
336

fiFast Set Bounds Propagation Using BDD-Sat Hybrid

many set problems significant numbers symmetries large
body work solving set problems symmetry breaking techniques (see e.g., Puget,
2005). would interesting combine symmetry breaking hybrid solver.

9. Acknowledgments
Part work published previously (Gange, Lagoon, & Stuckey, 2008). NICTA
funded Australian Government represented Department Broadband,
Communications Digital Economy Australian Research Council.

References
Azevedo, F. (2002). Constraint Solving Multi-valued Logics. Ph.D. thesis, Faculdade
de Ciencias e Tecnologia, Universidade Nova de Lisboa.
Azevedo, F. (2007). Cardinal: finite sets constraint solver. Constraints, 12 (1), 93129.
Bryant, R. (1986). Graph-based algorithms Boolean function manipulation. IEEE Trans.
Comput., 35 (8), 677691.
Cheng, K., & Yap, R. (2008). Maintaining generalized arc consistency ad hoc r-ary
constraints. 14th International Conference Principles Process Constraint
Programming, pp. 509523.
Damiano, R., & Kukula, J. (2003). Checking satisfiability conjunction BDDs.
Proceedings Design Automation Conference, pp. 818823.
Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.
Communications ACM, 5, 394397.
Een, N., & Sorensson, N. (2003). extensible SAT-solver. Giunchiglia, E., & Tacchella,
A. (Eds.), Proceedings SAT 2003, Vol. 2919 LNCS, pp. 502518.
Een, N., & Sorensson, N. (2006). Translating pseudo-boolean constraints SAT. Journal
Satisfiability, Boolean Modeling Computation, 2, 126.
Gange, G., Lagoon, V., & Stuckey, P. (2008). Fast set bounds propagation using BDDs.
18th European Conference Artificial Intelligence, pp. 505509.
GECODE (2008). Gecode. www.gecode.org. Accessed Jan 2008.
Gervet, C. (1997). Interval propagation reason sets: Definition implementation
practical language. Constraints, 1 (3), 191246.
Gervet, C., & Van Hentenryck, P. (2006). Length-lex ordering set CSPs. Proceedings
National Conference Artificial Intelligence, pp. 4853.
Hawkins, P., Lagoon, V., & Stuckey, P. (2004). Set bounds (split) set domain propagation using ROBDDs. 17th Australian Joint Conference Artificial Intelligence,
Vol. 3339 LNCS, pp. 706717.
Hawkins, P., Lagoon, V., & Stuckey, P. (2005). Solving set constraint satisfaction problems
using ROBDDs. Journal Artificial Intelligence Research, 24, 106156.
337

fiGange, Stuckey, & Lagoon

Hawkins, P., & Stuckey, P. (2006). hybrid BDD SAT finite domain constraint solver.
Proceedings 8th International Symposium Practical Aspects Declarative
Languages, Vol. 3819 LNCS, pp. 103117.
IC-PARC (2003). ECLiPSe constraint logic programming system. [Online, accessed
Oct 2008]. http://www.eclipse-clp.org/.
ILOG (2004). ILOG Solver. [Online, accessed Oct 2008]. http://www.ilog.com/.
Lagoon, V., & Stuckey, P. (2004). Set domain propagation using ROBDDs. Proceedings 10th International Conference Principles Practice Constraint
Programming, Vol. 3258 LNCS, pp. 347361.
van Lint, J. H., & Wilson, R. M. (2001). Course Combinatorics (2nd edition). Cambridge University Press.
Muller, T. (2001). Constraint Propagation Mozart. Doctoral dissertation, Universitat des
Saarlandes, Naturwissenschaftlich-Technische Fakultat I, Fachrichtung Informatik,
Saarbrucken, Germany.
Ohrimenko, O., Stuckey, P., & Codish, M. (2007). Propagation = lazy clause generation.
Bessiere, C. (Ed.), Proceedings 13th International Conference Principles
Practice Constraint Programming, Vol. 4741 LNCS, pp. 544558. SpringerVerlag.
Ohrimenko, O., Stuckey, P., & Codish, M. (2009). Propagation via lazy clause generation.
Constraints, 14 (3), 357391.
Puget, J.-F. (1992). PECOS: high level constraint programming language. Proceedings
SPICIS92, Singapore.
Puget, J.-F. (2005). Symmetry breaking revisited. Constraints, 10 (1), 2346.
Sadler, A., & Gervet, C. (2004). Hybrid set domains strengthen constraint propagation
reduce symmetries. Wallace, M. (Ed.), Proceedings 10th International
Conference Principles Practice Constraint Programming (CP04), No. 3258
LNCS. Springer-Verlag.
SICS (2009). Sicstus prolog. www.sics.se/sicstus.
Subbarayan, S. (2008). Efficent reasoning nogoods constraint solvers BDDs.
Proceedings Tenth International Symposium Practical Aspects Declarative
Languages, Vol. 4902 LNCS, pp. 5357.
Tseitin, G. (1968). complexity derivation propositional calculus. Studies
Constructive Mathematics Mathematical Logic, Part 2, 115125.
Yip, J., & Van Hentenryck, P. (2009). Evaluation length-lex set variables. Proceedings 15th International Conference Principles Practice Constraint
Programming, pp. 817832.

338

fiJournal Artificial Intelligence Research 38 (2010) 135-187

Submitted 12/09; published 05/10

Survey Paraphrasing Textual Entailment Methods
Ion Androutsopoulos
Prodromos Malakasiotis

ION @ AUEB . GR
RULLLER @ AUEB . GR

Department Informatics
Athens University Economics Business
Patission 76, GR-104 34 Athens, Greece

Abstract
Paraphrasing methods recognize, generate, extract phrases, sentences, longer natural language expressions convey almost information. Textual entailment methods,
hand, recognize, generate, extract pairs natural language expressions, human
reads (and trusts) first element pair would likely infer element
also true. Paraphrasing seen bidirectional textual entailment methods two
areas often similar. kinds methods useful, least principle, wide range
natural language processing applications, including question answering, summarization, text generation, machine translation. summarize key ideas two areas considering turn
recognition, generation, extraction methods, also pointing prominent articles resources.

1. Introduction
article survey computational methods paraphrasing textual entailment. Paraphrasing methods recognize, generate, extract (e.g., corpora) paraphrases, meaning phrases,
sentences, longer texts convey same, almost information. example, (1)
(2) paraphrases. people would also accept (3) paraphrase (1) (2), though
could argued (3) construction bridge necessarily completed,
unlike (1) (2).1 fine distinctions, however, usually ignored paraphrasing textual
entailment work, say paraphrases may convey almost information.
(1)
(2)
(3)

Wonderworks Ltd. constructed new bridge.
new bridge constructed Wonderworks Ltd.
Wonderworks Ltd. constructor new bridge.

Paraphrasing methods may also operate templates natural language expressions, like (4)
(6); slots X filled arbitrary noun phrases. Templates specified
syntactic semantic level may also used, slot fillers may required
particular syntactic relations (e.g., verb-object) words constituents, satisfy semantic
constraints (e.g., requiring denote book).
(4)
(5)
(6)

X wrote .
written X.
X writer .

1 Readers familiar tense aspect theories recognized (1)(3) involve accomplishment
Vendlers (1967) taxonomy. accomplishments completion point necessarily reached (3), unlike (1)(2).

c
2010
AI Access Foundation. rights reserved.

fiA NDROUTSOPOULOS & ALAKASIOTIS

Textual entailment methods, hand, recognize, generate, extract pairs hT, Hi
natural language expressions, human reads (and trusts) would infer H
likely also true (Dagan, Glickman, & Magnini, 2006). example, (7) textually entails (8), (9)
textually entail (10).2
(7)
(8)
(9)
(10)

drugs slow Alzheimers disease work best earlier administer them.
Alzheimers disease slowed using drugs.
Drew Walker, Taysides public health director, said: important stress confirmed
case rabies.
case rabies confirmed.

paraphrasing, textual entailment methods may operate templates. example,
discourse painters, composers, work, (11) textually entails (12), noun phrases
X . However, (12) textually entail (11), denotes symphony composed
X. require textual entailment templates hold possible slot fillers, (11)
textually entails (12) examples discourse, reverse hold.
(11)
(12)

X painted .
work X.

general, cannot judge two natural language expressions paraphrases correct
textual entailment pair without selecting particular readings expressions, among
may possible due multiple word senses, syntactic ambiguities etc. example, (13) textually
entails (14) financial sense bank, (13) refers bank river.
(13)
(14)

bomb exploded near French bank.
bomb exploded near building.

One possibility, then, examine language expressions (or templates) particular
contexts make intended readings clear. Alternatively, may want treat correct
textual entailment pair hT, Hi possible readings H, human
reads would infer H likely also true; then, system reports (13) textually
entails (14), response counted correct, regardless intended sense bank.
Similarly, paraphrases would possible readings conveying almost information.
lexical substitution task SEMEVAL (McCarthy & Navigli, 2009), systems required find appropriate substitute particular word context given sentence,
seen special case paraphrasing textual entailment, restricted pairs words.
SEMEVAL task, however, includes requirement must possible use two words
(original replacement) exactly context. similar manner, one could adopt
stricter definition paraphrases, would require (or almost
same) meaning, also expressions used interchangeably grammatical sentences. case, although (15) (16) paraphrases, underlined parts not,
cannot swapped two sentences; resulting sentences would ungrammatical.
(15)
(16)

Edison invented light bulb 1879, providing long lasting source light.
Edisons invention light bulb 1879 provided long lasting source light.

similar stricter definition textual entailment would impose additional requirement H
replace grammatical sentences.
2 Simplified

examples RTE-2 (Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, & Szpektor, 2006).

136

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

1.1 Possible Applications Paraphrasing Textual Entailment Methods
natural language expressions paraphrasing textual entailment methods consider
always statements. fact, many methods developed question answering
(QA) systems mind. QA systems document collections (Voorhees, 2001; Pasca, 2003;
Harabagiu & Moldovan, 2003; Molla & Vicedo, 2007), question may phrased differently
document contains answer, taking variations account improve system
performance significantly (Harabagiu, Maiorano, & Pasca, 2003; Duboue & Chu-Carroll, 2006;
Harabagiu & Hickl, 2006; Riezler, Vasserman, Tsochantaridis, Mittal, & Liu, 2007). example,
QA system may retrieve relevant documents passages, using input question query
information retrieval Web search engine (Baeza-Yates & Ribeiro-Neto, 1999; Manning, 2008),
check retrieved texts textually entails candidate answer (Moldovan & Rus,
2001; Duclaye, Yvon, & Collin, 2003).3 input question (17) search engine returns
passage (18), system may check (18) textually entails candidate answers (19),
replaced interrogative (17) expressions (18) named
entity recognizer (Bikel, Schwartz, & Weischedel, 1999; Sekine & Ranchhod, 2009) would ideally
recognized person names.4
(17)
(18)

(19)

sculpted Doryphoros?
Doryphoros one best known Greek sculptures classical era Western Art.
Greek sculptor Polykleitos designed work example canon rule, showing
perfectly harmonious balanced proportions human body sculpted form. sculpture
known Roman marble replica found Herculaneum conserved Naples
National Archaeological Museum, but, according Francis Haskell Nicholas Penny, early connoisseurs passed royal Bourbon collection Naples without notable comment.
Polykleitos/Francis Haskell/Nicholas Penny sculpted Doryphoros.

input question may also paraphrased, allow more, potentially relevant passages
obtained. Question paraphrasing also useful mapping user questions lists frequently
asked questions (FAQs) accompanied answers (Tomuro, 2003); natural language
interfaces databases often generate question paraphrases allow users understand
queries understood (McKeown, 1983; Androutsopoulos, Ritchie, & Thanisch, 1995).
Paraphrasing textual entailment methods also useful several natural language
processing applications. text summarization (Mani, 2001; Hovy, 2003), example, important processing stage typically sentence extraction, identifies important sentences
texts summarized. stage, especially generating single summary
several documents (Barzilay & McKeown, 2005), important avoid selecting sentences (e.g.,
different news articles event) convey information (paraphrases)
sentences already selected, sentences whose information follows
already selected sentences (textual entailment).
Sentence compression (Knight & Marcu, 2002; McDonald, 2006; Cohn & Lapata, 2008; Clarke
& Lapata, 2008; Cohn & Lapata, 2009; Galanis & Androutsopoulos, 2010), often also processing
stage text summarization, seen special case sentence paraphrasing, suggested
3 Culicover

(1968) discussed different types paraphrasing entailment, proposed earliest computational
treatment paraphrasing textual entailment aware of, goal retrieving passages texts
answer natural language queries. thank one anonymous reviewers pointing us Culicovers work.
4 Passage (18) based Wikipedias page Doryphoros.

137

fiA NDROUTSOPOULOS & ALAKASIOTIS

Zhao et al. (2009), additional constraint resulting sentence must shorter
original one still grammatical; example, sentence matching (5) (6) could shortened
converting paraphrase form (4). sentence compression work, however, allows
less important information original sentence discarded. Hence, resulting sentence
entailed by, necessarily paraphrase original one. following example, (21)
compressed form (20) produced human.5
(20)
(21)

Mother Catherine, 82, mother superior, attend hearing Friday, said.
Mother Catherine, 82, mother superior, attend.

compressed sentence necessarily paraphrase original one, may first
produce (grammatical) candidate compressions textually entailed original sentence;
hence, mechanism generate textually entailed sentences useful. Additional mechanisms
needed, however, rank candidates depending space save degree
maintain important information; discuss additional mechanisms kind.
Information extraction systems (Grishman, 2003; Moens, 2006) often rely manually automatically crafted patterns (Muslea, 1999) locate text snippets report particular types
events identify entities involved; example, patterns like (22)(24), similar patterns
operating syntax trees, possibly additional semantic constraints, might used locate
snippets referring bombing incidents identify targets. Paraphrasing textual entailment methods used generate additional semantically equivalent extraction patterns (in
case paraphrasing) patterns textually entail original ones (Shinyama & Sekine, 2003).
(22)
(23)
(24)

X bombed
bomb exploded near X
explosion destroyed X

machine translation (Koehn, 2009), ideas paraphrasing textual entailment research
embedded measures processes automatically evaluate machine-generated
translations human-authored ones may use different phrasings (Lepage & Denoual,
2005; Zhou, Lin, & Hovy, 2006a; Kauchak & Barzilay, 2006; Pado, Galley, Jurafsky, & Manning,
2009); return issue following sections. Paraphrasing methods also used
automatically generate additional reference translations human-authored ones training machine translation systems (Madnani, Ayan, Resnik, & Dorr, 2007). Finally, paraphrasing
textual entailment methods employed allow machine translation systems cope
source language words longer phrases encountered training corpora
(Zhang & Yamamoto, 2005; Callison-Burch, Koehn, & Osborne, 2006a; Marton, Callison-Burch, &
Resnik, 2009; Mirkin, Specia, Cancedda, Dagan, Dymetman, & Szpektor, 2009b). use example Mirkin et al. (2009b), phrase-based machine translation system never encountered
expression file lawsuit training, knows pattern (25) textually entails
(26), may able produce acceptable translation converting (27) (28),
translating (28). information would lost translation, (28) paraphrase
(27), translation may still preferable outcome translating directly (27).
(25)

X filed lawsuit Z.

5 Example

Clarke et al.s paper, Written News Compression Corpus (Clarke & Lapata, 2008); see Appendix A.

138

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

(26)
(27)
(28)

X accused Z.
Cisco filed lawsuit Apple patent violation.
Cisco accused Apple patent violation.

natural language generation (Reiter & Dale, 2000; Bateman & Zock, 2003), example
producing texts describing entities formal ontology (ODonnell, Mellish, Oberlander, & Knott, 2001; Androutsopoulos, Oberlander, & Karkaletsis, 2007), paraphrasing used
avoid repeating phrasings (e.g., expressing properties similar entities),
produce alternative expressions improve text coherence, adhere writing style (e.g., avoid
passives), satisfy constraints (Power & Scott, 2005). Among possible applications,
paraphrasing textual entailment methods employed simplify texts, example replacing specialized (e.g., medical) terms expressions non-experts understand (Elhadad &
Sutaria, 2007; Deleger & Zweigenbaum, 2009), automatically score student answers
reference answers (Nielsen, Ward, & Martin, 2009).
1.2 Relation Paraphrasing Textual Entailment Logical Entailment
represent meanings natural language expressions logical formulae, example
first-order predicate logic, may think textual entailment paraphrasing terms logical
entailment (|=). logical meaning representations H H , hT, Hi
correct textual entailment pair (T B) |= H ; B knowledge base, simplicity
assumed form single conjunctive formula, contains meaning postulates
(Carnap, 1952) knowledge assumed shared language users.6 Let us consider
example below, logical terms starting capital letters constants; assume
different word senses would give rise different predicate symbols. Let us also assume B
contains . (T ) |= H holds, i.e., H true interpretation (e.g., modeltheoretic) constants, predicate names domain-dependent atomic symbols,
hold. sound complete automated reasoner (e.g., based resolution, case
first-order predicate logic) could used confirm logical entailment holds. Hence,
textually entails H, assuming meaning postulate available. reverse, however,
hold, i.e., (H ) 6|= ; implication () would made bidirectional
() reverse hold.


:

Leonardo da Vinci painted Mona Lisa.



: isPainterOf(DaVinci, MonaLisa)

H

:

H


Mona Lisa work Leonardo da Vinci.

: isWorkOf(MonaLisa, DaVinci)
: x isPainterOf(x, y) isWorkOf(y, x)

Similarly, logical meaning representations T1 T2 1 2 , T1 paraphrase T2 iff (1 B) |= 2 (2 B) |= 1 , B contains meaning postulates
common sense knowledge. Ideally, sentences like (1)(3) would represented formula, making clear paraphrases, regardless contents B. Otherwise, may
6 Zaenen

et al. (2005) provide examples showing linguistic world knowledge cannot often separated.

139

fiA NDROUTSOPOULOS & ALAKASIOTIS

sometimes unclear T1 T2 considered paraphrases, may unclear
knowledge considered part B.
Since natural language expressions often ambiguous, especially context, may
want adopt looser definitions, textually entails H iff possible readings
H, represented H , (T B) |= H , similarly paraphrases. Thinking
textual entailment paraphrasing terms logical entailment allows us borrow notions
methods logic. Indeed, paraphrasing textual entailment recognition methods map
natural language expressions logical formulae, examine logical entailments hold.
not, however, possible approach. Many other, most, methods currently operate
surface strings syntactic representations, without mapping natural language expressions formal
meaning representations. Note, also, methods map natural language logical formulae,
important work form logic provides adequate support logical entailment
checks; full first-order predicate logic may inappropriate, semi-decidable.
apply logic-based definition textual entailment, formulated statements,
questions, let us use identical fresh constants (in effect, Skolem constants) across questions
represent unknown entities questions ask for; mark constants question marks
subscripts, logical entailment checks treated ordinary constants. following example, user asks H, system generates . Assuming meaning postulate
available B, (T B) |= H , i.e., interpretation predicate symbols constants,
(T B) true, H necessarily also true. Hence, textually entails H. practice,
means system manages find answer , perhaps phrasing closer
sentence document collection, answer used respond H.
(generated) :


painted Mona Lisa?

: isAgent(W? ) isPainterOf(W? , MonaLisa)

H(asked) :

Whose work Mona Lisa?

H

: isAgent(W? ) isWorkOf(MonaLisa,W? )



: x isPainterOf(x, y) isWorkOf(y, x)

logic-based definition question paraphrases formulated similar manner,
bidirectional logical entailment. Note also logic-based paraphrasing textual entailment
methods may actually represent interrogatives free variables, instead fresh constants,
may rely unification obtain values (Moldovan & Rus, 2001; Rinaldi, Dowdall, Kaljurand,
Hess, & Molla, 2003).
1.3 Classification Paraphrasing Textual Entailment Methods
six workshops paraphrasing and/or textual entailment (Sato & Nakagawa, 2001;
Inui & Hermjakob, 2003; Dolan & Dagan, 2005; Drass & Yamamoto, 2005; Sekine, Inui, Dagan,
Dolan, Giampiccolo, & Magnini, 2007; Callison-Burch, Dagan, Manning, Pennacchiotti, & Zanzotto, 2009) recent years.7 Recognizing Textual Entailment (RTE) challenges (Dagan et al.,
2006; Bar-Haim et al., 2006; Giampiccolo, Magnini, Dagan, & Dolan, 2007; Giampiccolo, Dang,
7

proceedings five recent workshops available ACL Anthology.

140

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Magnini, Dagan, & Dolan, 2008), currently fifth year, provide additional significant thrust.8
Consequently, large number published articles, proposed methods, resources related paraphrasing textual entailment.9 special issue textual entailment also recently
published, editorial provides brief overview textual entailment methods (Dagan, Dolan,
Magnini, & Roth, 2009).10 best knowledge, however, present article first
extensive survey paraphrasing textual entailment.
provide clearer view different goals assumptions methods
proposed, classify along two dimensions: whether paraphrasing textual entailment methods; whether perform recognition, generation, extraction paraphrases
textual entailment pairs. distinctions always clear literature, especially
distinctions along second dimension, explain below. also possible classify
methods along dimensions, example depending whether operate language expressions templates; whether operate phrases, sentences longer texts.
main input paraphrase textual entailment recognizer pair language expressions
(or templates), possibly particular contexts. output judgement, possibly probabilistic, indicating whether members input pair paraphrases correct textual entailment
pair; judgements must agree much possible humans. hand,
main input paraphrase textual entailment generator single language expression (or template) time, possibly particular context. output set paraphrases input,
set language expressions entail entailed input; output set must large
possible, including errors possible. contrast, particular language expressions
templates provided paraphrase textual entailment extractor. main input
case corpus, example monolingual corpus parallel comparable texts, different
English translations French novel, clusters multiple monolingual news articles,
articles cluster reporting event. system outputs pairs paraphrases
(possibly templates), pairs language expressions (or templates) constitute correct textual
entailment pairs, based evidence corpus; goal produce many output
pairs possible, errors possible. Note boundaries recognizers, generators, extractors may always clear. example, paraphrase generator may invoke
paraphrase recognizer filter erroneous candidate paraphrases; recognizer generator
may consult collection template pairs produced extractor.
note articles reporting actual applications paraphrasing textual entailment methods larger systems (e.g., QA, information extraction, machine translation, discussed
Section 1.1) currently relatively few, compared number articles propose new paraphrasing textual entailment methods test vitro, despite fact articles
second kind often point possible applications methods propose. relatively
small number application articles may indicator paraphrasing textual entailment
methods used extensively larger systems yet. believe may due least
two reasons. First, efficiency methods needs improved, may require combining recognition, generation, extraction methods, example iteratively produce
training data; return point following sections. Second, literature paraphrasing
8 RTE

challenges initially organized European PASCAL Network Excellence, subsequently
part NISTs Text Analysis Conference.
9 textual entailment portal established, part ACL wiki, help organize relevant material.
10 slides Dagan, Roth, Zazottos ACL 2007 tutorial textual entailment also publicly available.

141

fiA NDROUTSOPOULOS & ALAKASIOTIS

textual entailment vast, makes difficult researchers working larger systems
assimilate key concepts identify suitable methods. hope article help address
second problem, also acting introduction may help new researchers improve
paraphrasing textual entailment methods further.
Sections 2, 3, 4 consider turn recognition, generation, extraction methods
paraphrasing textual entailment. three sections, attempt identify
explain prominent ideas, pointing also relevant articles resources. Section 5,
conclude discuss possible directions future research. URLs publicly available
resources mention listed appendix A.

2. Paraphrase Textual Entailment Recognition
Paraphrase textual entailment recognizers judge whether two given language expressions
(or templates) constitute paraphrases correct textual entailment pair. Different methods may
operate different levels representation input expressions; example, may treat
input expressions simply surface strings, may operate syntactic semantic representations input expressions, representations combining information different levels.
2.1 Logic-based Approaches Recognition
One possibility map language expressions logical meaning representations,
rely logical entailment checks, possibly invoking theorem provers (Rinaldi et al., 2003; Bos
& Markert, 2005; Tatu & Moldovan, 2005, 2007). case textual entailment, involves
generating pairs formulae hT , H H (or possible readings), checking
(T B) |= H , B contains meaning postulates common sense knowledge, already
discussed. practice, however, may difficult formulate reasonably complete B.
partial solution problem obtain common sense knowledge resources like WordNet
(Fellbaum, 1998) Extended WordNet (Moldovan & Rus, 2001). latter also includes logical
meaning representations extracted WordNets glosses. example, since assassinate
hyponym (more specific sense) kill WordNet, axiom like following added B
(Moldovan & Rus, 2001; Bos & Markert, 2005; Tatu & Moldovan, 2007).
x assassinate(x, y) kill(x, y)
Additional axioms obtained FrameNets frames (Baker, Fillmore, & Lowe, 1998;
Lonneker-Rodman & Baker, 2009), discussed example Tatu et al. (2005), similar resources. Roughly speaking, frame representation prototypical situation (e.g., purchase), also identifies situations main roles (e.g., buyer, entity bought), types
entities (e.g., person) play roles, possibly relations (e.g., causation, inheritance)
prototypical situations (other frames). VerbNet (Schuler, 2005) also specifies, among
information, semantic frames English verbs. On-line encyclopedias also used obtain background knowledge extracting particular types information (e.g., is-a relationships)
articles (Iftene & Balahur-Dobrescu, 2007).
Another approach use particular B (meaning postulates common sense knowledge),
measure difficult satisfy H , case textual entailment recognition, compared satisfying own. possible measure difference size
142

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

minimum model satisfies H , compared size minimum model
satisfies (Bos & Markert, 2005); intuitively, model assignment entities,
relations etc. terms, predicate names, domain-dependent atomic symbols. greater
difference knowledge required B (T B) |= H hold, difficult
becomes speakers accept textually entails H. Similar bidirectional logical entailment
checks used recognize paraphrases (Rinaldi et al., 2003).
2.2 Recognition Approaches Use Vector Space Models Semantics
alternative using logical meaning representations start mapping word
input language expressions vector shows strongly word cooccurs particular
words corpora (Lin, 1998b), possibly also taking account syntactic information,
example requiring cooccurring words participate particular syntactic dependencies (Pado
& Lapata, 2007). compositional vector-based meaning representation theory used
combine vectors single words, eventually mapping one two input expressions
single vector attempts capture meaning; simplest case, vector expression
could sum product vectors words, elaborate approaches also
proposed (Mitchell & Lapata, 2008; Erk & Pado, 2009; Clarke, 2009). Paraphrases
detected measuring distance vectors two input expressions, example
computing cosine similarity. See also work Turney Pantel (2010) survey
vector space models semantics.
Recognition approaches based vector space models semantics appear explored much less approaches discussed article, mostly paraphrase recognition (Erk & Pado, 2009). could also used textual entailment recognition, however,
checking vector H particularly close part (e.g., phrase sentence) . Intuitively, would check H says included says, though must careful
negations expressions preserve truth values (Zaenen et al., 2005; MacCartney
& Manning, 2009), (29)(30). return idea matching H part below.
(29)
(30)

: denied BigCo bought SmallCo.
H: BigCo bought SmallCo.

2.3 Recognition Approaches Based Surface String Similarity
Several paraphrase recognition methods operate directly input surface strings, possibly
applying pre-processing, part-of-speech (POS) tagging named-entity recognition,
without computing elaborate syntactic semantic representations. example,
may compute string edit distance (Levenshtein, 1966) two input strings, number
common words, combinations several string similarity measures (Malakasiotis & Androutsopoulos, 2007), including measures originating machine translation evaluation (Finch,
Hwang, & Sumita, 2005; Perez & Alfonseca, 2005; Zhang & Patrick, 2005; Wan, Dras, Dale, &
Paris, 2006). latter developed automatically compare machine-generated translations human-authored reference translations. well known measure BLEU (Papineni,
Roukos, Ward, & Zhu, 2002; Zhou et al., 2006a), roughly speaking examines percentage
word n-grams (sequences consecutive words) machine-generated translations also
occur reference translations, takes geometric average percentages obtained
different values n. Although n-gram based measures criticised machine transla143

fiA NDROUTSOPOULOS & ALAKASIOTIS

tion evaluation (Callison-Burch, Osborne, & Koehn, 2006b), example unaware
synonyms longer paraphrases, combined measures build paraphrase (and textual entailment) recognizers (Zhou et al., 2006a; Kauchak & Barzilay, 2006; Pado
et al., 2009), may help address problems automated machine translation evaluation.
textual entailment recognition, one input language expressions (T ) often much longer
one (H). part surface string similar Hs, indication
H may entailed . illustrated (31)(32), H included verbatim .11
Note, however, surface string similarity (e.g., measured string edit distance) H
entire example low, different lengths H.
(31)

(32)

: Charles de Gaulle died 1970 age eighty. thus fifty years old when, unknown officer recently promoted rank brigadier general, made famous broadcast
London rejecting capitulation France Nazis debacle May-June 1940.
H: Charles de Gaulle died 1970.

Comparing H sliding window surface string size H (in example, six
consecutive words ) keeping largest similarity score sliding window
H may provide better indication whether entails H (Malakasiotis, 2009). many
correct textual entailment pairs, however, using single sliding window fixed length may still
inadequate, H may correspond several non-continuous parts ; (33)(34),
example, H corresponds three underlined parts .12
(33)
(34)

: Gaspe, also known la Gaspesie French, North American peninsula south shore
Saint Lawrence River, Quebec.
H: Gaspe peninsula Quebec.

One possible solution attempt align words (or phrases) H ,
consider H correct textual entailment pair sufficiently good alignment found,
simplest case large percentage words aligned words H. Another approach would
use window variable length; window could be, example, shortest span
contains words aligned words H (Burchardt, Pennacchiotti, Thater, &
Pinkal, 2009). case, need careful negations expressions
preserve truth values, already mentioned. Note, also, although effective word alignment
methods developed statistical machine translation (Brown, Della Pietra, Della Pietra,
& Mercer, 1993; Vogel, Ney, & Tillmann, 1996; Och & Ney, 2003), often perform poorly
textual entailment pairs, H often different lengths, necessarily
convey information, textual entailment training datasets much smaller
used machine translation; see MacCartney et al.s (2008) work related discussion
word alignment method developed especially textual entailment pairs.13
2.4 Recognition Approaches Based Syntactic Similarity
Another common approach work syntax level. Dependency grammar parsers (Melcuk,
1987; Kubler, McDonald, & Nivre, 2009) popular paraphrasing textual entailment re11 Example

dataset RTE-3 (Giampiccolo et al., 2007).
example dataset RTE-3 (Giampiccolo et al., 2007).
13 Cohn et al. (2008) discuss publicly available corpus manually word-aligned paraphrases constructed.
word-aligned paraphrasing textual entailment datasets found ACL Textual Entailment Portal.
12 Modified

144

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

mathematician solved problem problem solved young mathematician

solved
subj

solved

obj

obj aux

mathematician

problem

problem

det

det

det











mathematician
det


mod
young

Figure 1: Two sentences similar viewed level dependency trees.
search, natural language processing areas recently. Instead showing hierarchically
syntactic constituents (e.g., noun phrases, verb phrases) sentence, output dependency
grammar parser graph (usually tree) whose nodes words sentence whose
(labeled) edges correspond syntactic dependencies words, example dependency
verb head noun subject noun phrase, dependency noun
adjective modifies it. Figure 1 shows dependency trees two sentences. exact
form trees edge labels would differ, depending parser; simplicity, show
prepositions edges. ignore word order auxiliary passive (right) sentence, take account edge passive sentence corresponds subj
edge active (left) one, difference extra adjective passive sentence. Hence,
easy figure dependency trees two sentences similar meanings,
despite differences word order. Strictly speaking, right sentence textually entails left
one, reverse, word young right sentence.
paraphrase recognizers simply count common edges dependency trees
input expressions (Wan et al., 2006; Malakasiotis, 2009) use tree similarity measures.
large similarity score (e.g., threshold) indicates input expressions may paraphrases. Tree edit distance (Selkow, 1977; Tai, 1979; Zhang & Shasha, 1989) another example
similarity measure applied dependency parse trees; computes sequence operator applications (e.g., add, replace, remove node edge) minimum
cost turns one tree other.14 obtain accurate predictions, important devise
appropriate inventory operators assign appropriate costs operators training
stage (Kouylekov & Magnini, 2005; Mehdad, 2009; Harmeling, 2009). example, replacing
noun one synonyms less costly replacing unrelated word;
removing dependency verb adverb perhaps less costly removing
dependency verb head noun subject object.
textual entailment recognition, one may compare Hs parse tree subtrees parse
tree (Iftene & Balahur-Dobrescu, 2007; Zanzotto, Pennacchiotti, & Moschitti, 2009). may
possible match Hs tree single subtree , effect single syntactic window ,
illustrated Figure 2, shows dependency trees (33)(34); recall (34)
match single window (33) surface string level.15 also example
operating higher level surface strings may reveal similarities may less clear lower
14 EDITS ,
15 Figure

suite recognize textual entailment computing edit distances, publicly available.
2 based output Stanfords parser. One might argue North modify American.

145

fiA NDROUTSOPOULOS & ALAKASIOTIS

peninsula
subj
Gaspe
det

aux

det




mod

mod

North

mod

American

mod



known
mod

mod

also





obj

obj

North

Quebec

det mod mod




south



obj

obj

Gaspesie

River

mod
la

mod

det mod mod

mod




Saint

Lawrence

obj
French

Figure 2: example dependency treespeninsula
may make easier match short sentence (subsubj
aux
mod one.
tree inside dashed line) part det
longer
Gaspe






obj

det

levels. Another example (35)(36);
although (35) includes
Quebecverbatim (36), textually
entail (36).16 clear one compares syntactic representations two sentences:
Israel subject established (36), (35). difference, however,
evident surface string level, sliding window (35) would match exactly (36), wrongly
suggesting textual entailment.
(35)
(36)

: National Institute Psychobiology Israel established 1979.
H: Israel established 1979.

Similar arguments made favour computing similarities semantic level (Qiu,
Kan, & Chua, 2006); example, active passive forms sentence may mapped
logical formula, making similarity clearer surface syntax level.
syntactic semantic representations input expressions, however, cannot always computed
accurately (e.g., due parser errors), may introduce noise; and, possibly
noise, methods operate syntactic semantic level necessarily outperform
practice methods operate surface strings (Wan et al., 2006; Burchardt, Reiter, Thater, &
Frank, 2007; Burchardt et al., 2009).
2.5 Recognition via Similarity Measures Operating Symbolic Meaning Representations
Paraphrases may also recognized computing similarity measures graphs whose edges
correspond syntactic dependencies, reflect semantic relations mentioned input expressions (Haghighi, 2005), example relation buyer entity bought. Relations kind may identified applying semantic role labeling methods (Marquez, Carreras,
16 Modified

example Haghighi et al.s (2005) work.

146

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Litkowski, & Stevenson, 2008) input language expressions. also possible compute
similarities meaning representations based FrameNets frames (Burchardt et al.,
2007). latter approach advantage semantically related expressions may invoke
frame (as announcement, announce, acknowledge) interconnected frames (e.g.,
FrameNet links frame invoked arrest frame invoked trial via path temporal precedence relations), making similarities implications easier capture (Burchardt et al.,
2009).17 prototypical semantic roles PropBank (Palmer, Gildea, & Kingsbury, 2005) associates verb may also used similar manner, instead FrameNets frames. Similarly,
case textual entailment recognition, one may compare Hs semantic representation (e.g.,
semantic graph frame) parts representation.
WordNet (Fellbaum, 1998), automatically constructed collections near synonyms (Lin, 1998a;
Moore, 2001; Brockett & Dolan, 2005), resources like NOMLEX (Meyers, Macleod, Yangarber,
Grishman, Barrett, & Reeves, 1998) C VAR (Habash & Dorr, 2003) provide nominalizations verbs derivationally related words across different POS categories (e.g., invent
invention), used match synonyms, hypernymshyponyms, or, generally, semantically related words across two input expressions. According WordNet, (37)(38)
shares direct hyponym (more specific meaning) stock, slumped direct hyponym
dropped, company indirect hyponym (two levels down) organization.18
treating semantically similar words (e.g., synonyms, hypernyms-hyponyms small hierarchical distance) identical (Rinaldi et al., 2003; Finch et al., 2005; Tatu, Iles, Slavick, Novischi, &
Moldovan, 2006; Iftene & Balahur-Dobrescu, 2007; Malakasiotis, 2009; Harmeling, 2009),
considering (e.g., counting) semantically similar words across two input language expressions
(Brockett & Dolan, 2005; Bos & Markert, 2005), paraphrase recognizers may able cope
paraphrases similar meanings, common words.
(37)
(38)

shares company dropped.
organizations stock slumped.

textual entailment recognition, may desirable allow words distant
hyponyms words H, compared paraphrase recognition. example, X computer
textually entails X artifact, computer hyponym artifact four levels down.
Measures exploit WordNet (or similar resources) compute semantic similarity
two words or, generally, two texts also proposed (Leacock, Miller, &
Chodorow, 1998; Lin, 1998c; Resnik, 1999; Budanitsky & Hirst, 2006; Tsatsaronis, Varlamis, &
Vazirgiannis, 2010).19 directional, making suitable textual entailment recognition (Corley & Mihalcea, 2005). Roughly speaking, measures kind consider
(e.g., sum lengths of) paths WordNets hierarchies (or similar resources) connect
senses corresponding (e.g., similar) words across two texts. may also take
account information frequencies words two texts rarely
encountered documents large collection (inverse document frequency). rationale
frequent words input texts rarely used general corpus important,
17 Consult,

example, work Erk Pado (2006) description system annotate texts
FrameNet frames. FATE corpus (Burchardt & Pennacchiotti, 2008), version RTE 2 test set (Bar-Haim et al.,
2006) FrameNet annotations, publicly available.
18 Modified example work Tsatsaronis (2009)
19 Pedersens WordNet::Similarity package implements many measures.

147

fiA NDROUTSOPOULOS & ALAKASIOTIS

Training stage
(P1,1, P2,1) X
(P1,2, P2,2)

(P1,n, P2,n)

<f1,1, , fm,1> X
<f1,2, , fm,2>

<f1,n, , fm,n>

Vector creation
Preprocessing

Learning
Algorithm
Trained
Classifier

Classification stage
(P1, P2) ?

<f1, , fm> ?

Vector creation

Trained
Classifier

Preprocessing
Decision:

Figure 3: Paraphrase textual entailment recognition via supervised machine learning.
information retrieval; hence, paths connect assigned greater weights. Since
often consider paths word senses, many measures would ideally combined
word sense disambiguation (Yarowski, 2000; Stevenson & Wilks, 2003; Kohomban & Lee,
2005; Navigli, 2008), not, however, always accurate enough practical purposes.
2.6 Recognition Approaches Employ Machine Learning
Multiple similarity measures, possibly computed different levels (surface strings, syntactic
semantic representations) may combined using machine learning (Mitchell, 1997; Alpaydin, 2004), illustrated Figure 3.20 pair input language expressions hP1 , P2 i, i.e.,
pair expressions wish check paraphrases correct textual entailment pair,
represented feature vector h f1 , . . . , fm i. vector contains scores multiple similarity measures applied pair, possibly features. example, many systems also
include features check polarity differences across two input expressions,
confirmed case rabies vs. case rabies confirmed, modality differences,
case may confirmed vs. case confirmed (Haghighi, 2005; Iftene &
Balahur-Dobrescu, 2007; Tatu & Moldovan, 2007). Bos Markert (2005) also include features
indicating theorem prover managed prove logical representation one
input expressions entails contradicts it. supervised machine learning algorithm trains
classifier manually classified (as correct incorrect) vectors corresponding training input
pairs. trained, classifier classify unseen pairs correct incorrect paraphrases
textual entailment pairs examining features (Bos & Markert, 2005; Brockett & Dolan, 2005;
Zhang & Patrick, 2005; Finch et al., 2005; Wan et al., 2006; Burchardt et al., 2007; Hickl, 2008;
Malakasiotis, 2009; Nielsen et al., 2009).
preprocessing stage commonly applied input pair language expressions,
converting feature vector (Zhang & Patrick, 2005). Part preprocessing may provide
20 WEKA (Witten & Frank, 2005) provides implementations several well known machine learning algorithms, including C 4.5 (Quinlan, 1993), Naive Bayes (Mitchell, 1997), SVMs (Vapnik, 1998; Cristianini & Shawe-Taylor, 2000;
Joachims, 2002), AdaBoost (Freund & Schapire, 1995; Friedman, Hastie, & Tibshirani, 2000). efficient implementations SVMs, LIBSVM SVM - LIGHT, also available. Maximum Entropy classifiers also
effective; see chapter 6 book Speech Language Processing (Jurafsky & Martin, 2008) introduction;
Stanfords implementation frequently used.

148

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

information required compute features; example, POS tagger
parser would applied.21 preprocessing may also normalize input pairs; example,
stemmer may applied; dates may converted consistent format; names persons, organizations, locations etc. may tagged semantic categories using named entity recognizer;
pronouns or, generally, referring expressions, may replaced expressions refer
(Hobbs, 1986; Lappin & Leass, 1994; Mitkov, 2003; Molla, Schwitter, Rinaldi, Dowdall, & Hess,
2003; Yang, Su, & Tan, 2008); morphosyntactic variations may normalized (e.g., passive
sentences may converted active ones).22
Instead mapping hP1 , P2 pair feature vector contains mostly scores measuring similarity P1 P2 , possible use vectors encode directly parts P1
P2 , parts syntactic semantic representations. Zanzotto et al. (2009) project
hP1 , P2 pair vector that, roughly speaking, contains features fragments P1 P2
parse trees. Leaf nodes corresponding identical similar words (according WordNetbased similarity measure) across P1 P2 replaced co-indexed slots, allow features
general. Zanzotto et al. define measure (actually, different versions it) that, effect, computes similarity two pairs hP1 , P2 hP10 , P20 counting parse tree fragments
(features) shared P1 P10 , shared P2 P20 . measure used
kernel Support Vector Machine (SVM) learns separate positive textual entailment pairs
hP1 , P2 = hT, Hi negative ones. (valid) kernel thought similarity measure
projects two objects highly dimensional vector space, computes inner product
projected objects; efficient kernels compute inner product directly original objects,
without computing projections highly dimensional vector space (Vapnik, 1998; Cristianini & Shawe-Taylor, 2000; Joachims, 2002). Zanzotto et al.s work, object hT, Hi
pair, projection vector contains parse tree fragments H features.
Consult, example, work Zanzotto Dell Arciprete (2009) Moschitti (2009)
discussion kernels used paraphrase textual entailment recognition.
2.7 Recognition Approaches Based Decoding
Pairs paraphrasing textual entailment expressions (or templates) like (39), often called rules,
may produced extraction mechanisms (to discussed Section 4) used
recognizers much as, often addition synonyms hypernyms-hyponyms.
(39)

X fond X likes

Given paraphrasing rule (39) information child synonym kid
candy hyponym sweet, recognizer could figure (40) textually entails (43)
gradually transforming (40) (43) shown below.23
(40)

Children fond sweets.

21 Brills (1992) POS tagger well-known publicly available. Stanfords tagger (Toutanova, Klein, Manning, &
Singer, 2003) another example publicly available POS tagger. Commonly used parsers include Charniaks (2000),
Collins (2003), Link Grammar Parser (Sleator & Temperley, 1993), MINIPAR, principle-based parser (Berwick,
1991) similar PRINCIPAR (Lin, 1994), MaltParser (Nivre, Hall, Nilsson, Chanev, Eryigit, Kuebler, Marinov, &
Marsi, 2007), Stanfords parser (Klein & Manning, 2003).
22 Porters stemmer (1997) well-known. example publicly available named-entity recognizer Stanfords.
23 Modified example Bar-Haim et al.s (2009) work.

149

fiA NDROUTSOPOULOS & ALAKASIOTIS

(41)
(42)
(43)

Kids fond sweets.
Kids like sweets.
Kids like candies.

Another recognition approach, then, search sequence rule applications
transformations (e.g., replacing synonyms, hypernyms-hyponyms) turns one input
expressions (or syntactic semantic representation) other. call search decoding,
similar decoding stage machine translation (to discussed Section 3),
sequence transformations turns source-language expression target-language
expression sought. case, sequence found, two input expressions constitute
positive paraphrasing textual entailment pair, depending rules used; otherwise, pair
negative. rule associated confidence score (possibly learnt training dataset)
reflects degree rule preserves original meaning paraphrase recognition,
degree confident produces entailed expression, may search
sequence transformations maximum score (or minimum cost), much approaches
compute minimum (string tree) edit distance two input expressions. pair
input expressions classified positive maximum-score sequence exceeds
confidence threshold (Harmeling, 2009). One would also consider contexts rules
applied, rule may valid contexts, instance different
possible senses words involves. possible solution associate rule vector
represents contexts used (e.g., vector frequently occurring words
training contexts rule applies), use rule contexts similar
associated context vector; slotted rules, one also model types slot values (e.g., types
named entities) rule used work Pantel, Bhagat, Coppola, Chklovski,
Hovy (2007), Szpektor, Dagan, Bar-Haim, Goldberger (2008).
Resouces like WordNet extraction methods, however, provide thousands millions rules,
giving rise exponentially large number transformation sequences consider.24
operating level semantic representations, sequence sought effect proof
two input expressions paraphrases valid textual entailment pair, may obtained
exploiting theorem provers, discussed earlier. Bar-Haim et al. (2007) discuss search
sequences transformations, seen proofs syntactic level, input language
expressions reformulations represented dependency trees. subsequent work (BarHaim et al., 2009), introduce compact forests, data structure allows dependency trees
multiple intermediate reformulations represented single graph, make search
efficient. also combine approach SVM-based recognizer; sequences
transformations used bring closer H, SVM recognizer employed judge
transformed H consitute positive textual entailment pair not.
2.8 Evaluating Recognition Methods
Experimenting paraphase textual entailment recognizers requires datasets containing
positive negative input pairs. using discriminative classifiers (e.g., SVMs), negative
training pairs must ideally near misses, otherwise may little use (Schohn & Cohn,
2000; Tong & Koller, 2002). Near misses also make test data challenging.
24 Collections transformation rules resources used obtain rules listed ACL Textual
Entailment Portal. Mirkin et al. (2009a) discuss evaluate collections textual entailment rules.

150

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

method
Corley & Mihalcea (2005)
Das & Smith (2009)
Finch et al. (2005)
Malakasiotis (2009)
Qiu et al. (2006)
Wan et al. (2006)
Zhang & Patrick (2005)
BASE 1
BASE 2

accuracy (%)
71.5
76.1
75.0
76.2
72.0
75.6
71.9
66.5
69.0

precision (%)
72.3
79.6
76.6
79.4
72.5
77.0
74.3
66.5
72.4

recall (%)
92.5
86.1
89.8
86.8
93.4
90.0
88.2
100.0
86.3

F-measure (%)
81.2
82.9
82.7
82.9
81.6
83.0
80.7
79.9
78.8

Table 1: Paraphrase recognition results MSR corpus.

widely used benchmark dataset paraphrase recognition Microsoft Research
(MSR) Paraphrase Corpus. contains 5,801 pairs sentences obtained clusters online news
articles referring events (Dolan, Quirk, & Brockett, 2004; Dolan & Brockett, 2005).
pairs initially filtered heuristics, require, example, word edit distance
two sentences pair neither small (to avoid nearly identical sentences)
large (to avoid many negative pairs); sentences among first three
articles cluster (articles referring event), rationale initial
sentences often summarize events. candidate paraphrase pairs filtered
SVM -based paraphrase recognizer (Brockett & Dolan, 2005), trained separate manually classified
pairs obtained similar manner, biased overidentify paraphrases. Finally, human
judges annotated remaining sentence pairs paraphrases not. resolving disagreements,
approximately 67% 5,801 pairs judged paraphrases. dataset divided
two non-overlapping parts, training (30% pairs) testing (70%). Zhang Patrick
(2005) others pointed heuristics used construct corpus may
biased towards particular types paraphrases, excluding example paraphrases
share common words.
Table 1 lists published results paraphrase recognition experiments MSR corpus
aware of. include two baselines used: BASE1 classifies pairs paraphrases;
BASE 2 classifies two sentences paraphrases surface word edit distance
threshold, tuned training part corpus. Four commonly used evaluation measures
used: accuracy, precision, recall, F-measure equal weight precision recall.
measures defined below. TP (true positives) FP (false positives) numbers pairs
correctly incorrectly, respectively, classified positive (paraphrases). TN (true
negatives) FN (false negatives) numbers pairs correctly incorrectly,
respectively, classified negative (not paraphrases).
precision =
accuracy =

TP
TP+FP ,

recall =

TP+TN
TP+TN+FP+FN ,

F-measure =

TP
TP+FN ,
2precisionrecall
precision+recall

systems Table 1 better recall precision, implies tend over-classify
pairs paraphrases, possibly sentences pair least common words
refer event. Systems higher recall tend lower precision, vice versa,
one would expect. high F-measure BASE1 largely due perfect recall; precision
151

fiA NDROUTSOPOULOS & ALAKASIOTIS

method
Bensley & Hickl (2008)
Iftene (2008)
Siblini & Kosseim (2008)
Wang & Neumann (2008)
BASE 1
BASE 2

accuracy (%)
74.6
72.1
68.8
70.6
50.0
54.9

precision (%)

65.5


50.0
53.6

recall (%)

93.2


100.0
73.6

F-measure (%)

76.9


66.7
62.0

Table 2: Textual entailment recognition results (for two classes) RTE-4 corpus.

significantly lower, compared systems. BASE2 , uses string edit distance,
competitive baseline corpus. Space permit listing published evaluation results
paraphrase recognition methods discussed. Furthermore, comparing results
obtained different datasets always meaningful.
textual entailment recognition, widely used benchmarks RTE challenges. example, RTE-3 corpus contains 1,600 hT, Hi pairs (positive negative). Four
application scenarios textual entailment recognition might useful considered: information extraction, information retrieval, question answering, summarization. 200
training 200 testing pairs scenario; Dagan et al. (2009) explain constructed. RTE-4 corpus constructed similar way, contains test pairs, 250
four scenarios. difference RTE-4 judges classified pairs
three classes: true entailment pairs, false entailment pairs H contradicts (Harabagiu, Hickl,
& Lacatusu, 2006; de Marneffe, Rafferty, & Manning, 2008), false pairs reading
lead conclusion H; similar pilot task included RTE-3 (Voorhees, 2008).
pairs latter two classes merged, two classes (true false) desirable.
also note RTE-3 included pilot task requiring systems justify answers. Many
participants, however, used technical mathematical terminology explanations,
always appreciated human judges; also, entailments often obvious
judges, extent justification considered necessary (Voorhees, 2008). Table 2 lists
best accuracy results RTE-4 participants (for two classes only), along results two
baselines described previously; precision, recall, F-measure scores also shown, available. four measures defined paraphrase recognition, positives negatives
textual entailment pairs.25 Again, space permit listing published evaluation results
textual entailment recognition methods discussed, comparing results obtained
different datasets always meaningful.
also possible evaluate recognition methods indirectly, measuring impact
performance larger natural language processing systems (Section 1.1). instance, one could
measure difference performance QA system, degree redundancy
generated summary reduced using paraphrase and/or textual entailment recognizers.

25 Average precision, borrowed information retrieval evaluation, also used RTE challenges.
Bergmair (2009), however, argues using RTE challenges proposes alternative measures.

152

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

3. Paraphrase Textual Entailment Generation
Unlike recognizers, paraphrase textual entailment generators given single language expression (or template) input, required produce many output language expressions
(or templates) possible, output expressions paraphrases constitute, along
input, correct textual entailment pairs. generators assume input single
sentence (or sentence template), adopt assumption remainder section.
3.1 Generation Methods Inspired Statistical Machine Translation
Many generation methods borrow ideas statistical machine translation (SMT).26 Let us first introduce central ideas SMT, benefit readers unfamiliar them. SMT methods
rely large bilingual multilingual parallel corpora, example proceedings European parliament, without constructing meaning representations often, least recently,
without even constructing syntactic representations.27 Let us assume wish translate
sentence F, whose words f1 , f2 , . . . , f|F| order, foreign language native language. Let us also denote N candidate translation, whose words a1 , a2 , . . . , a|N| . best
translation, denoted N , N maximum probability translation F, i.e:
N = arg max P(N|F) = arg max
N

N

P(N)P(F|N)
= arg max P(N)P(F|N)
N
P(F)

(44)

Since F fixed, denominator P(F) constant ignored searching
N . P(N) called language model P(F|N) translation model.
modeling purposes, common assume F fact originally written native
language transmitted us via noisy channel, introduced various deformations.
possible deformations may include, example, replacing native word one
foreign ones, removing inserting words, moving words left right etc. commonly
used IBM models 1 5 (Brown et al., 1993) provide increasingly richer inventory word
deformations; recent phrase-based SMT systems (Koehn, Och, & Marcu, 2003) also allow
directly replacing entire phrases phrases.
foreign sentence
ff F thus seen
result applying sequence transformations = d1 , d2 , . . . , d|D| N, common
search N maximizes (45); search called decoding.
N = arg max P(N) max P(F, D|N)
N



(45)

exhaustive search usually intractable. Hence, heuristic search algorithms (e.g., based beam
search) usually employed (Germann, Jahr, Knight, Marcu, & Yamada, 2001; Koehn, 2004).28
Assuming simplicity individual deformations di () mutually independent,
P(F, D|N) computed product probabilities Ds individual deformations. Given
bilingual parallel corpus words aligned across languages, estimate probabilities
26

introduction SMT, see chapter 25 book Speech Language Processing (Jurafsky & Martin,
2008), chapter 13 book Foundations Statistical Natural Language Processing (Manning & Schuetze,
1999). extensive discussion, consult work Koehn (2009).
27 See Koehns Statistical Machine Translation site commonly used SMT corpora tools.
28 frequently used SMT system includes decoding facilities Moses.

153

fiA NDROUTSOPOULOS & ALAKASIOTIS

possible deformations di (). practice, however, parallel corpora indicate word alignment. Hence, common find probable word alignment corpus given initial
estimates individual deformation probabilities, re-estimate deformation probabilities
given resulting alignment, iterate (Brown et al., 1993; Och & Ney, 2003).29
translation model P(F, D|N) estimates probability obtaining F N via D;
interested Ns high probabilities leading F. also want, however, N grammatical, use language model P(N) check grammaticality. P(N) probability
encountering N native language; estimated large monolingual corpus
language, typically assuming probability encountering word ai depends preceding n 1 words. n = 3, P(N) becomes:
P(N) = P(a1 ) P(a2 |a1 ) P(a3 |a1 , a2 ) P(a4 |a2 , a3 ) P(a|N| |a|N|2 , a|N|1 )

(46)

language model typically also includes smoothening mechanisms, cope n-grams
rare present monolingual corpus, would lead P(N) = 0.30
principle, SMT system could used generate paraphrases, could trained
sufficiently large monolingual corpus parallel texts. N F sentences
language, N different given F, convey (or almost
same) information. main problem readily available monolingual parallel
corpora sizes used SMT, train language model them. One possibility
use multiple translations source texts; example, different English translations
novels originally written languages (Barzilay & McKeown, 2001), multiple English
translations Chinese news articles, Multiple-Translation Chinese Corpus. Corpora
kind, however, still orders magnitude smaller used SMT.
bypass lack large monolingual parallel corpora, Quirk et al. (2004) use clusters
news articles referring event. articles cluster always report
information and, hence, parallel texts. Since talk event, however,
often contain phrases, sentences, even longer fragments similar meanings; corpora
kind often called comparable. cluster, Quirk et al. select pairs similar
sentences (e.g., small word edit distance, identical sentences) using methods like
employed create MSR corpus (Section 2.8).31 sentence pairs word aligned
machine translation, resulting alignments used create table phrase pairs
phrase-based SMT systems (Koehn et al., 2003). phrase pair hP1 , P2 consists contiguous
words (taken phrase, though necessarily syntactic constituent) P1 one sentence
aligned different contiguous words P2 another sentence. Quirk et al. provide following
examples discovered pairs.

29 GIZA ++

often used train IBM models align words.
chapter 4 book Speech Language Processing (Jurafsky & Martin, 2008) chapter 6 book
Foundations Statistical Natural Language Processing (Manning & Schuetze, 1999) introduction language
models. SRILM (Stolcke, 2002) commonly used tool create language models.
31 Wubben et al. (2009) discuss similar methods pair news titles. Barzilay & Elhadad (2003) Nelken & Shieber
(2006) discuss general methods align sentences monolingual comparable corpora. Sentence alignment methods
bilingual parallel comparable corpora discussed, example, Gale Church (1993), Melamed (1999),
Fung Cheung (2004), Munteanu Marcu (2006); see also work Wu (2000). Sentence alignment methods
parallel corpora may perform poorly comparable corpora (Nelken & Shieber, 2006).
30 See

154

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

P1

P2

injured
Bush administration
margin error
...

wounded
White House
error margin
...

Phrase pairs occur frequently aligned sentences may assigned higher probabilities; Quirk et al. use probabilities returned IBM model 1. decoder first constructs lattice
represents possible paraphrases input sentence produced replacing
phrases counterparts phrase table; i.e., possible deformations di () phrase
replacements licensed phrase table.32 Unlike machine translation, words
phrases need replaced, Quirk et al. also allow degenerate identity deformation ( ) = ; assigning high probability identity deformation leads conservative
paraphrases, fewer phrase replacements. decoder uses probabilities di () compute P(F, D|N) equation (45), language model compute P(N). best scored N
returned paraphrase F; n highly scored Ns could also returned. generally,
table phrase pairs may also include synonyms obtained WordNet similar resources,
pairs paraphrases (or templates) discovered paraphrase extraction methods; effect, Quirk
et al.s construction monolingual phrase table paraphrase extraction method. language
model may also applied locally replacement words deformation context
assess whether new words fit original context (Mirkin et al., 2009b).
Zhao et al. (2008, 2009) demonstrated combining phrase tables derived multiple resources improves paraphrase generation. also proposed scoring candidate paraphrases
using additional, application-dependent model, called usability model; example,
sentence compression (Section 1.1) usability model rewards Ns fewer words F.
Equation (45) becomes (47), U(F, N) usability model weights assigned
three models; similar weights used (45).
N = arg max U(F, N)1 P(N)2 max P(F, D|N)3
N



(47)

Zhao et al. actually use log-linear formulation (47); select weights maximize objective function rewards many correct (as judged human evaluators) phrasal
replacements.33 One may replace translation model paraphrase recognizer (Section 2)
returns confidence score; log-linear formulation, (47) becomes (48), R(F, N)
confidence score recognizer.
N = arg max[1 logU(F, N) + 2 log P(N) + 3 logR(F, N)]
N

(48)

Including hyponyms-hypernyms textual entailment rules (Section 2.7) phrase table
would generate sentences N textually entail entailed (depending direction
32 Chevelu

et al. (2009) discuss decoders could developed especially paraphrase generation.
reluctant paraphrasing setting (Dras, 1998), example revising document satisfy length requirements, readability measures, externally imposed constraints, may desirable use objective function
rewards making changes possible, provided constraints satisfied. Dras (1998) discusses formulation
problem terms integer programming.
33

155

fiA NDROUTSOPOULOS & ALAKASIOTIS

rules whether replace hyponyms hypernyms reverse) F. SMT-inspired methods,
however, used mostly paraphrase generation, textual entailment generation.
Paraphrases also generated using pairs machine translation systems translate
input expression new language, often called pivot language, back original
language. resulting expression often different input one, especially two
translation systems employ different methods. using different pairs machine translation systems different pivot languages, multiple paraphrases may obtained. Duboue Chu-Carroll
(2006) demonstrated benefit using approach paraphrase questions, additional
machine learning classifier filter generated paraphrases; classifier uses features
cosine similarity candidate generated paraphrase original question, lengths
candidate paraphrase original question, features showing whether questions type (e.g., asking person name), etc. advantage approach
machine translation systems treated black boxes, trained
readily available parallel corpora different languages. disadvantage translation errors
directions may lead poor paraphrases. return pivot languages Section 4.
principle, output generator may produced mapping input representation
meaning, process usually presupposes parsing, passing meaning representation, new meaning representations logically entailed original one, natural
language generation system (Reiter & Dale, 2000; Bateman & Zock, 2003) produce paraphrases
entailed language expressions. approach would similar using language-independent
meaning representations (an interlingua) machine translation, meaning representations would need language-independent, since one language involved. approach
similar syntactic transfer machine translation may also adopted (McKeown, 1983).
case, input language expression (assumed sentence) first parsed. resulting syntactic representation modified ways preserve, affect slightly, original meaning
(e.g., turning sentence active passive), ways produce syntactic representations
entailed language expressions (e.g., pruning certain modifiers subordinate clauses). New language expressions generated new syntactic representations, possibly invoking
surface realization components natural language generation system. Parsing, however,
input expression may introduce errors, producing correct meaning representation input,
required, may far trivial. Furthermore, natural language generator may
capable producing language expressions limited variety, missing possible paraphrases
entailed language expressions. perhaps meaning representation syntactic transfer
seem currently popular paraphrase textual entailment generation.
3.2 Generation Methods Use Bootstrapping
input output expressions slotted templates, possible apply bootstrapping
large monolingual corpus (e.g., entire Web), instead using machine translation methods.
Let us assume, example, wish generate paraphrases (49), given
pairs seed values X , (50) (51).
(49)
(50)
(51)

X author .
hX = Jack Kerouac,Y = Roadi
hX = Jules Verne,Y = Mysterious Islandi

retrieve corpus sentences contain seed pairs:
156

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

(52)
(53)
(54)

Jack Kerouac wrote Road.
Mysterious Island written Jules Verne.
Jack Kerouac known novel Road.

replacing known seeds corresponding slot names, obtain new templates:
(55)
(56)
(57)

X wrote .
written X.
X known novel .

example, (55) (56) paraphrases (49); however, (57) textually entails (49),
paraphrase (49). want generate paraphrases, must keep (55) (56) only;
want generate templates entail (49), must keep (57) too. generated candidate
templates may neither paraphrases of, entail (or entailed by) original template. good
paraphrase textual entailment recognizer (Section 2) human loop would able filter
bad candidate templates; see also Duclaye et al.s (2003) work, Expectation Maximization
(Mitchell, 1997) used filter candidate templates. Simpler filtering techniques may also
used. example, Ravichandran et al. (2002, 2003) assign candidate template pseudoprecision score; roughly speaking, score computed number retrieved sentences
match candidate template X values seed pair, divided
number retrieved sentences match template X seed value value,
necessarily corresponding seed value.
obtained new templates, search corpus new sentences match them;
example, sentence (58) matches generated template (56). new sentences, seed
values obtained, slot values correspond types expressions (e.g., person names)
recognized reasonably well, example using named entity recognizer gazetteer
(e.g., large list book titles); (58) would obtain new seed pair (59). iterations
may used generate templates seeds, templates seeds
discovered maximum number iterations reached.
(58)
(59)

Frankenstein written Mary Shelley.
hX = Mary Shelley,Y = Frankensteini

Figure 4 illustrates bootstrapping paraphrase generator works. Templates textually entail
textually entailed initial template, seed slot values provided,
generated similarly, paraphrase recognizer replaced textual entailment recognizer.
slot values recognized reliably, also obtain initial seed slot values automatically retrieving directly sentences match original templates identifying
slot values retrieved sentences.34 also given mechanism identify sentences
interest corpus (e.g., sentences involving particular terms, names known diseases
medicines), also obtain initial templates automatically, identifying sentences
interest, identifying slot values (e.g., named entities particular categories) sentences,
using contexts slot values initial templates. effect, generation task becomes
extraction one, since given corpus, neither initial templates seed slot values.
TEASE (Szpektor, Tanev, Dagan, & Coppola, 2004) well-known bootstrapping method
34 Seed

slot values per semantic relation also obtained databases (Mintz, Bills, Snow, & Jurafsky, 2009).

157

fiA NDROUTSOPOULOS & ALAKASIOTIS

kind, produces textual entailment pairs, example pairs like (60)(61), given monolingual (non-parallel) corpus dictionary terms. (60) textually implies (61), example
contexts like (62)(63), reverse.35
(60)
(61)
(62)
(63)

X prevents
X reduces risk
Aspirin prevents heart attack.
Aspirin reduces heart attack risk.

specify directionality produced template pairs, example whether (60)
textually entails (61) vice versa, additional mechanisms proposed attempt
guess directionality; discuss one mechanism, LEDIR (Bhagat, Pantel, & Hovy, 2007),
Section 4.1 below. Although TEASE also used generator, particular input templates
provided, discuss Section 4.2, along bootstrapping extraction methods,
since full form requires initial templates (nor seed slot values). reader reminded
boundaries recognizers, generators, extractors always clear.
Similar bootstrapping methods used generate information extraction patterns (Riloff
& Jones, 1999; Xu, Uszkoreit, & Li, 2007). methods, however, require corpora annotated instances particular types events extracted (Huffman, 1995; Riloff, 1996b;
Soderland, Fisher, Aseltine, & Lehnert, 1995; Soderland, 1999; Muslea, 1999; Califf & Mooney,
2003), texts mention target events near-miss texts (Riloff, 1996a).
Marton et al. (2009) used similar approach, without iterations, generate paraphrases
unknown source language phrases phrase-based SMT system (Section 1.1). unknown
phrase, collected contexts phrase occurred monolingual corpus source
language, searched phrases (candidate paraphrases) corpus occurred
contexts. subsequently produced feature vectors unknown phrase
candidate paraphrases, vector showing often corresponding phrase cooccurred
words. candidate paraphrases ranked similarity vectors
vector unknown phrase. unknown phrases effect replaced best
paraphrases SMT system knew map target language phrases, improved
SMT systems performance.
TEASE

3.3 Evaluating Generation Methods
generation applications, example rephrasing queries QA system (Section 1.1),
desirable produce correct outputs (correct paraphrases, expressions constitute
correct textual entailment pairs along input), also produce many correct outputs
possible. two goals correspond high precision recall, respectively. particular input
si , precision pi recall ri generator defined follows (cf. Section 2.8). TPi
number correct outputs input si , FPi number wrong outputs si , FNi
number outputs si incorrectly generated (missed).
pi =

TPi
TPi +FPi ,

ri =

TPi
TPi +FNi

precision recall scores method set inputs {si } defined using
micro-averaging macro-averaging:
35 Example

work Szpektor et al. (2004).

158

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

<X=Jack Kerouac, Y=On road>
<X=Jules Verne, Y=The Mysterious Island>

Search engine

<X=Virginia Wolf, Y=Mrs. Dalloway>
<X=Mary Shelley, Y=Frankestein>

Jack Kerouac wrote road
Mysterious Island written Jules Verne
Jack Kerouac known novel road

Identify new seeds

Known seeds slots

X wrote
written X
X known novel

Virginia Wolf wrote Mrs. Dalloway
Frankestein written Mary Shelley

X wrote
written X

Search engine

Paraphrase Recognizer

Figure 4: Generating paraphrases X wrote bootstrapping.

macro-precision = pi , macro-recall = ri
micro-precision =

TPi
,
(TPi +FPi )

micro-recall =

TPi
(TPi +FNi )

case, however, recall cannot computed generation, FNi unknown;
numerous correct paraphrases input si may missed, even (if
infinite) language expressions entail entailed si .36
Instead reporting recall, common report (along precision) average number
outputs, sometimes called yield, defined below, assume n test inputs.
better option report yield different precision levels, since usually tradeoff
two figures, controlled parameter tuning (e.g., selecting different values
thresholds involved methods).
yield =

1 n
(TPi + FPi )
n i=1

Note use fixed set test inputs {si }, store sets Oref
correct
outputs reference generation method produces si , treat Oref
set
possible correct outputs may generated si , precision recall
computed, without human effort new generation method, say M, evaluated.
FNi number outputs Oref
produced si M; FPi number
Ms outputs si Oref
; TPi number Ms outputs si included
ref
Oi . Callison-Burch et al. (2008) propose evaluation approach kind call
paraphrase generation. use phrase alignment heuristics (Och & Ney, 2003; Cohn et al., 2008)
36 Accuracy (Section 2.8) also impossible compute case; apart knowing FN , number

outputs correctly generated (TNi ) infinite.

159

fiA NDROUTSOPOULOS & ALAKASIOTIS

obtain aligned phrases (e.g., resign, tender resignation, leave office voluntarily)
manually word-aligned sentences meanings (from Multiple-Translation Chinese
Corpus). Roughly speaking, use {si } phrases alignments found;
ref
si , Oref
contains phrases si aligned to. Since Oi , however, contains much fewer
phrases possible correct paraphrases si , resulting precision score (possibly
pessimistic) lower bound, resulting recall scores measure extent managed
discover (relatively few) paraphrases Oref
, pointed Callison-Burch et al.
best knowledge, widely adopted benchmark datasets paraphrase
textual entailment generation, unlike recognition, comparing results obtained different
datasets always meaningful. lack generation benchmarks probably due fact
although possible assemble large collection input language expressions, practically impossible specify advance numerous (if infinite) correct outputs generator
may produce, already discussed. principle, one could use paraphrase textual entailment
recognizer automatically judge output generator paraphrase of, forms correct
entailment pair corresponding input expression. Current recognizers, however, yet
accurate enough, automatic evaluation measures machine translation (e.g., BLEU, Section
2.3) cannot employed, exactly weakness cannot detect paraphrases
textual entailment. alternative, costly solution use human judges, also allows
evaluating aspects outputs, fluency (Zhao et al., 2009), machine translation. One also evaluate performance generator indirectly, measuring impact
performance larger natural language processing systems (Section 1.1).

4. Paraphrase Textual Entailment Extraction
Unlike recognition generation methods, extraction methods given particular input language expressions. typically process large corpora extract pairs language expressions
(or templates) constitute paraphrases textual entailment pairs. generated pairs stored
used subsequently recognizers generators applications (e.g., additional entries phrase tables SMT systems). extraction methods produce pairs sentences (or
sentence templates) pairs shorter expressions. Methods discover synonyms, hypernymhyponym pairs or, generally, entailment relations words (Lin, 1998a; Hearst, 1998;
Moore, 2001; Glickman & Dagan, 2004; Brockett & Dolan, 2005; Hashimoto, Torisawa, Kuroda,
De Saeger, Murata, & Kazama, 2009; Herbelot, 2009) seen performing paraphrase
textual entailment extraction restricted pairs single words.
4.1 Extraction Methods Based Distributional Hypothesis
possible paraphrase extraction approach store word n-grams occur large
monolingual corpus (e.g., n 5), along left right contexts, consider paraphrases n-grams occur frequently similar contexts. example, n-gram represented vector showing words typically precede follow n-gram, values
vector indicating strongly word co-occurs n-gram; example, pointwise
mutual information values (Manning & Schuetze, 1999) may used. Vector similarity measures,
example cosine similarity Lins measure (1998a), employed identify n-grams
160

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

occur similar contexts comparing vectors.37 approach shown
viable large monolingual corpora; Pasca Dienes (2005) used Web snapshot approximately billion Web pages; Bhagat Ravichandran (2008) used 150 GB news articles
reported results deteriorate rapidly smaller corpora. Even lightweight linguistic
processing (e.g., POS tagging, without parsing) performed, processing large datasets requires
significant processing power, although linear computational complexity possible appropriate hashing context vectors (Bhagat & Ravichandran, 2008). Paraphrasing approaches
kind based Harriss Distributional Hypothesis (1964), states words similar
contexts tend similar meanings. bootstrapping methods Section 3.2 based
similar hypothesis phrases (or templates) occurring similar contexts (or similar slot
values) tend similar meanings, hypothesis seen extension Harriss.
Lin Pantels (2001) well-known extraction method, called DIRT, also based extended Distributional Hypothesis, operates syntax level. DIRT first applies dependency
grammar parser monolingual corpus. Parsing corpus generally time-consuming and,
hence, smaller corpora used, compared methods require parsing; Lin
Panel used 1 GB news texts experiments. Dependency paths extracted
dependency trees corpus. Let us consider, example, sentences (64) (67). dependency trees shown Figure 5; similarity two sentences less obvious
Figure 1, different verbs involved. Two dependency paths
extracted trees Figure 5 shown (65) (68). labels edges
augmented POS-tags words connect (e.g., N:subj:V instead simply subj).38
first last words extracted paths replaced slots, shown boxed numbered
POS -tags. Roughly speaking, paths (65) (68) correspond surface templates (66)
(69), respectively, paths actually templates specified syntactic level.
(64)
(65)
(66)
(67)
(68)
(69)

mathematician found solution problem.
N1 :subj:V found V :obj:N solution N:to: N2
N1 found [a] solution N2
problem solved young mathematician.
N3 :obj:V solved V :by: N4
N3 solved N4 .

DIRT imposes restrictions paths extracted dependency trees;
example, start end noun slots. paths extracted, looks
pairs paths occur frequently slot fillers. (65) (68) occur frequently
fillers (e.g., N1 = N4 = mathematician, N2 = N3 = problem), included
pair DIRTs output (with N1 = N4 N2 = N3). measure based mutual information
(Manning & Schuetze, 1999; Lin & Pantel, 2001) used detect paths common fillers.
Lin Pantel call pairs templates DIRT produces inference rules,
directionality templates pair; intention seems produce pairs
near paraphrases. resulting pairs actually often textual entailment pairs, paraphrases,
37 Zhitomirsky-Geffet

Dagan (2009) discuss bootstrapping approach, whereby vector similarity scores (initially computed using pointwise mutual information values vectors) used improve values vectors;
vector similarity scores re-computed.
38 consistency previous examples, show slightly different labels used Lin Pantel.

161

fiA NDROUTSOPOULOS & ALAKASIOTIS

found
subj

solved
obj

mathematician

solution

det


obj aux

det


problem







mathematician

det

problem



det


mod
young

det


Figure 5: Dependency trees sentences (64) (67).
directionality entailment unspecified.39 Bhagat et al. (2007) developed method,
called LEDIR, classify template pairs hP1 , P2 DIRT similar methods produce three
classes: (i) paraphrases, (ii) P1 textually entails P2 reverse, (iii) P2 textually entails
P1 reverse; addition LEDIR, DIRT becomes method extracts separately
pairs paraphrase templates pairs directional textual entailment templates. Roughly speaking, LEDIR examines semantic categories (e.g., person, location etc.) words fill P1
P2 slots corpus; categories obtained following WordNets hypernym-hyponym
hierarchies filler words certain level, applying clustering words
corpus using clusters filler words categories.40 P1 occurs fillers
substantially larger number categories P2 , LEDIR assumes P1 general
meaning P2 and, hence, P2 textually entails P1 ; similarly reverse direction.
substantial difference number categories, P1 P2 taken paraphrases. Szpektor
Dagan (2008) describe method similar DIRT produces textual entailment pairs unary
(single slot) templates (e.g., X takes nap X sleeps) using directional similarity measure
unary templates.
Extraction methods based (extended) Distributional Hypothesis often produce pairs
templates correct paraphrasing textual entailment pairs, although share many
common fillers. fact, pairs involving antonyms frequent; according Lin Pantel (2001),
DIRT finds X solves similar X worsens ; problem
reported experiments LEDIR (Bhagat et al., 2007) distributional approaches operate
surface level (Bhagat & Ravichandran, 2008).
Ibrahim et al.s (2003) method similar DIRT, assumes monolingual parallel
corpus available (e.g., multiple English translations novels), whereas DIRT require
parallel corpora. Ibrahim et al.s method extracts pairs dependency paths aligned
sentences share matching anchors. Anchors allowed nouns pronouns,
match identical, noun compatible pronoun,
semantic category etc. (70)(71), square brackets subscripts indicate matching anchors.41
pair templates (72)(73) would extracted (70)(71); simplicity, show
sentences templates surface strings, although method operates dependency trees
39 Template

pairs produced DIRT available on-line.
introduction clustering methods, consult chapter 14 Foundations Statistical Natural Language Processing (Manning & Schuetze, 1999).
41 Simplified example Ibrahim et al.s work (2003).
40

162

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

paths. Matching anchors become matched slots. Heuristic functions used score anchor
matches (e.g., identical anchors preferred matching nouns pronouns) resulting
template pairs; roughly speaking frequently rediscovered template pairs rewarded, especially
occur many different anchors.
(70)
(71)
(72)
(73)

[clerk]1 liked [Bovary]2 .
[He]1 fond [Bovary]2 .
X liked .
X fond .

operating aligned sentences monolingual parallel corpora, Ibrahim et al.s method may
avoid, extent, producing pairs unrelated templates simply happen share common
slot fillers; resulting pairs templates also likely paraphrases, rather simply
textual entailment pairs, since obtained aligned sentences monolingual parallel
corpus. Large monolingual parallel corpora, however, difficult obtain non-parallel
corpora, already discussed. alternative identify anchors related sentences comparable corpora (Section 3.1), easier obtain. Shinyama Sekine (2003) find pairs
sentences share anchors within clusters news articles reporting event.
method, anchors named entities (e.g., person names) identified using named entity
recognizer, pronouns noun phrases refer named entities; heuristics employed
identify likely referents. Dependency trees constructed pair sentences,
pairs dependency paths extracted trees treating anchors slots.
4.2 Extraction Methods Use Bootstrapping
Bootstrapping approaches also used extraction, generation (Section 3.2),
additional complication particular input template seed values slots start
from. address complication, TEASE (Szpektor et al., 2004) starts lexicon terms
knowledge domain, example names diseases, symptoms etc. case medical domain;
extent, lexicons constructed automatically domain-specific corpus (e.g.,
medical articles) via term acquisition techniques (Jacquemin & Bourigault, 2003). TEASE
extracts (non-parallel) monolingual corpus pairs textual entailment templates
used lexicons terms slot fillers. already shown resulting pair templates,
(60)(61), Section 3.2; repeat (74)(75) below. Recall TEASE indicate
directionality resulting template pairs, example whether (74) textually entails (75) vice
versa, mechanisms like LEDIR (Section 4.1) could used guess directionality.
(74)
(75)

X prevents
X reduces risk

Roughly speaking, TEASE first identifies noun phrases cooccur frequently term
lexicon, excluding common noun phrases. uses terms cooccurring
noun phrases seed slot values obtain templates, new templates obtain
slot values, much Figure 4. TEASE, however, templates actually slotted dependency
paths, method includes stage merges compatible templates form general
ones.42 particular input templates provided, TEASE used generator (Section 3.2).
42 Template

pairs produced TEASE available on-line.

163

fiA NDROUTSOPOULOS & ALAKASIOTIS

Barzilay McKeown (2001) also used bootstrapping method, extract paraphrases
parallel monolingual corpus; used multiple English translations novels. Unlike
previously discussed bootstrapping approaches, method involves two classifiers (in effect, two
sets rules). One classifier examines words candidate paraphrases consist of, second
one examines contexts. two classifiers use different feature sets (different views
data), output classifier used improve performance one
iterative manner; case co-training (Blum & Mitchell, 1998). specifically,
POS tagger, shallow parser, stemmer first applied corpus, sentences
aligned across different translations. Words occur sentences aligned pair
treated seed positive lexical examples; pairs words two sentences
become seed negative lexical examples. aligned sentences (76)(77), obtain three seed
positive lexical examples, shown (78)(80), many seed negative lexical examples, two
shown (81)(82).43 Although seed positive lexical examples pairs identical
words, algorithm iterates new positive lexical examples produced, may
synonyms (e.g., comfort console) pairs longer paraphrases, explained
below.
(76)
(77)
(78)
(79)
(80)
(81)
(82)

tried comfort her.
tried console Mary.
hexpression1 = he, expression2 = he, +i
hexpression1 = tried, expression2 = tried, +i
hexpression1 = to, expression2 = to, +i
hexpression1 = he, expression2 = tried,
hexpression1 = he, expression2 = to,

contexts positive (similarly, negative) lexical examples corresponding sentences used construct positive (or negative) context rules, i.e., rules used
obtain new pairs positive (or negative) lexical examples. Barzilay McKeown (2001) use
POS tags l words lexical examples contexts, experiments
set l = 3. simplicity, however, let us assume l = 2; then, instance, (76)(77)
positive lexical example (79), obtain positive context rule (83). rule says
two aligned sentences contain two sequences words, say 1 2 , one sentence,
1 2 preceded pronoun, followed (possibly different) verb, 1 2 positive lexical examples. Identical subscripts POS
tags denote identical words; example, (83) requires 1 2 preceded
pronoun, verbs follow may different.
(83)

hleft1 = (pronoun1 ), right1 = (to1 , verb), left2 = (pronoun1 ), right1 = (to1 , verb), +i

iteration, k strongest positive negative context rules retained.
strength context rule precision, i.e., positive context rules, number positive
lexical examples whose contexts matched rule divided number positive
negative lexical examples matched, similarly negative context rules. Barzilay McKeown
(2001) used k = 10, also discarded context rules whose strength 95%.
resulting (positive negative) context rules used identify new (positive negative)
43 Simplified

example work Barzilay McKeown (2001).

164

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Slot 1

planes

bombers

start

Baghdad
bombed

forces

Iraqi

Slot 2

Baghdad
start

Iraqi
Iraqi
Slot 3

planes

capital
military

end

capital

bombed



base



army
Slot 4

end

forces

Figure 6: Word lattices obtained sentence clusters Barzilay Lees method.
lexical examples. aligned (84)(85), rule (83) would figure tried
synonym attempted; two words would treated new positive lexical example, shown
(86).
(84)
(85)
(86)

tried run away.
attempted escape.
hexpression1 = tried, expression2 = attempted, +i

context rules may also produce multi-word lexical examples, like one shown (87).
obtained lexical examples generalized replacing words POS tags, giving
rise paraphrasing rules. (87) obtain positive paraphrasing rule (88); again, POS
subscripts denote identical words, whereas superscripts denote identical stems. rule (88)
says sequence words consisting verb, to, another verb paraphrase
sequence consisting initial verb, to, another verb stem
second verb first sequence, provided two sequences occur aligned sentences.
(87)
(88)

hexpression
1 = start talk, expression2 = start talking, +i


ff
generalized expression1 = (verb0 , to, verb1 ), generalized expression2 = (verb0 , verb1 ), +

paraphrasing rules also filtered strength, precision
predict paraphrasing contexts. remaining paraphrasing rules used obtain lexical
examples, also filtered precision predict paraphrasing contexts.
new positive negative lexical examples added existing ones,
used obtain, score, filter new positive negative context rules, well rescore
filter existing ones. resulting context rules employed obtain lexical examples, paraphrasing rules, on, new positive lexical examples obtained
corpus, maximum number iterations exceeded. Wang et al. (2009) added
scoring measures Barzilay McKeowns (2001) method filter rank paraphrase pairs
produces, used extended method extract paraphrases technical terms clusters
bug reports.
4.3 Extraction Methods Based Alignment
Barzilay Lee (2003) used two corpora genre, different sources (news
articles two press agencies). call two corpora comparable, use term
165

fiA NDROUTSOPOULOS & ALAKASIOTIS

slightly different meaning previously discussed methods; sentences corpus
clustered separately, cluster intended contain sentences (from single corpus)
referring events type (e.g., bomb attacks), sentences (or documents) referring
events (e.g., particular bombing). cluster, word lattice produced
aligning clusters sentences Multiple Sequence Alignment (Durbin, Eddy, Krogh, &
Mitchison, 1998; Barzilay & Lee, 2002). solid lines Figure 6 illustrate two possible resulting
lattices, two different clusters; omit stop-words. sentence cluster corresponds
path clusters lattice. lattice, nodes shared high percentage (50%
Barzilay Lees experiments) clusters sentences considered backbone nodes. Parts
lattice connect otherwise consecutive backbone nodes replaced slots, illustrated
Figure 6. two lattices example correspond surface templates (89)(90).
(89)
(90)

X bombed .
bombed X.

encountered fillers slot also recorded. two slotted lattices (templates) different corpora share many fillers, taken pair paraphrases (Figure 6). Hence,
method also uses extended Distributional Hypothesis (Section 4.1).
Pang et al.s method (2003) produces finite state automata similar Barzilay Lees
(2003) lattices, requires parallel monolingual corpus; Pang et al. used Multiple-Translation
Chinese Corpus (Section 3.1) experiments. parse trees aligned sentences constructed merged illustrated Figure 7; vertical lines inside nodes indicate sequences
necessary constituents, whereas horizontal lines correspond disjunctions.44 example
Figure 7, sentences consist noun phrase (NP) followed verb phrase (VP); reflected root node merged tree. sentences, noun phrase cardinal number
(CD) followed noun (NN); however, particular cardinal numbers nouns different
across two sentences, leading leaf nodes disjunctions. rest merged tree
constructed similarly; consult Pang al. details. Presumably one could also generalize
cardinal numbers, types named entities etc.
merged tree converted finite state automaton traversing tree depthfirst manner introducing ramification node disjunction encountered. Figure 8
shows automaton corresponds merged tree Figure 7. language expressions
produced automaton (all paths start end node) paraphrases.
Hence, unlike extraction methods, Pang et al.s (2003) method produces automata, rather
pairs templates, automata used similar manner. recognition, example,
two strings accepted automaton, paraphrases; generation, could
look automaton accepts input expression, output expressions
generated automaton. Barzilay Lees (2003) method, however, Pang et
al.s (2003) method intended extract mostly paraphrase, simply textual entailment pairs.
Bannard Callison-Burch (2005) point bilingual parallel corpora much easier
obtain, much larger sizes, monolingual parallel comparable corpora
extraction methods employ. Hence, set extract paraphrases bilingual parallel corpora commonly used statistical machine translation (SMT). already discussed Section 3.1,
phrase-based SMT systems employ tables whose entries show phrases one language may
44 Example

Pang et al.s work (2003).

166

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Parse trees
aligned sentences




CD
twelve

NP

VP

NN
people

VB
died

NP
CD
12

VP

NN
persons

AUX


VB
killed

merge
trees
NP VP
AUX

CD NN

12

persons

twelve

people

VB

VB
killed


died

Figure 7: Merging parse trees aligned sentences Pang et al.s method.
12

died

persons

start

end
people

twelve



killed

Figure 8: Finite state automaton produced Pang et al.s method.
replaced phrases another language; phrase tables kind may produced applying
phrase alignment heuristics (Och & Ney, 2003; Cohn et al., 2008) word alignments produced
commonly used IBM models. case English-German parallel corpus, phrase
table may contain entries like following, show control aligned
unter kontrolle corpus, unter kontrolle also aligned check; hence,
control check candidate paraphrase pair.45
English phrase

German phrase

...
control
...
check
...

...
unter kontrolle
...
unter kontrolle
...

precisely, paraphrase English phrases, Bannard Callison-Burch (2005) employ
pivot language (German, example above) bilingual parallel corpus English
pivot language. construct phrase table parallel corpus, table
estimate probabilities P(e| f ) P( f |e), e f range English pivot
language phrases table. example, P(e| f ) may estimated number entries (rows)
contain e f , divided number entries contain f , multiple rows
multiple alignments e f corpus, similarly P( f |e). best paraphrase e2
English phrase e1 table computed equation (91), f ranges
pivot language phrases phrase table .
e2 = arg max P(e2 |e1 ) = arg max
e2 6=e1

45 Example

P( f |e1 )P(e2 | f , e1 ) arg emax
P( f |e1 )P(e2 | f )
2 6=e1

e2 6=e1 f

f

work Bannard Callison-Burch (2005).

167

(91)

fiA NDROUTSOPOULOS & ALAKASIOTIS

Multiple bilingual corpora, different pivot languages, used; (91) becomes (92), C
ranges corpora, f ranges pivot language phrases Cs phrase table.
e2 = arg max



e2 6=e1 C
f (C)

P( f |e1 )P(e2 | f )

(92)

Bannard Callison-Burch (2005) also considered adding language model (Section 3.1)
method favour paraphrase pairs used interchangeably sentences; roughly
speaking, language model assesses well one element pair replace sentences latter occurs, scoring grammaticality sentences replacement.
subsequent work, Callison-Burch (2008) extended method require paraphrases
syntactic types, since replacing phrase one different syntactic type generally leads
ungrammatical sentence.46 Zhou et al. (2006b) employed method similar Bannard
Callison-Burchs extract paraphrase pairs corpus, used resulting pairs SMT
evaluation, comparing machine-generated translations human-authored ones. Riezler
et al. (2007) adopted similar pivot approach obtain paraphrase pairs bilingual phrase tables, used resulting pairs paraphrasing rules obtain paraphrases (longer) questions
submitted QA system; also used log-linear model (Section 3.1) rank resulting
question paraphrases combining probabilities invoked paraphrasing rules, language
model score resulting question paraphrase, features.47
pivot language approaches discussed shown produce millions paraphrase pairs large bilingual parallel corpora. paraphrases, however, typically short
(e.g., four five words), since longer phrases rare phrase tables. methods also
significantly affected errors automatic word phrase alignment (Bannard & CallisonBurch, 2005). take consideration word alignment errors, Zhao et al. (2008) use log-linear
classifier score candidate paraphrase pairs share common pivot phrase, instead using
equations (91) (92). effect, classifier uses probabilities P( f |e1 ) P(e2 | f ) (91)
(92) features, also uses additional features assess quality word alignment
e1 f , well f e2 . subsequent work, Zhao et al. (2009) also consider
English phrases e1 e2 paraphrases, aligned different pivot phrases
f1 f2 , provided f1 f2 paraphrase pair pivot language. Figure 9
illustrates original extended pivot approaches Zhao et al. paraphrase pairs h f1 , f2
pivot language extracted scored bilingual parallel corpus original approach, reversing roles two languages. scores h f1 , f2 pairs, roughly
speaking correspond P( f2 | f1 ), included additional features classifier scores
resulting English paraphrases, along scores corresponding P( f1 |e1 ), P(e2 | f2 ), features
assess word alignments phrases involved.
Zhao et al.s (2008, 2009) method also extends Bannard Callison-Burchs (2005) producing pairs slotted templates, whose slots filled words particular parts speech
(e.g., Noun1 considered Noun2 Noun2 considers Noun1 ).48 Hence, Zhao et al.s patterns
general, reliable parser language paraphrase required; let us assume
paraphrase English. Roughly speaking, slots formed removing subtrees
46

implementation Callison-Burchs (2008) method paraphrase rules produced available on-line.
et al. (2007) also employ paraphrasing method based SMT system trained question-answer pairs.
48 collection template pairs produced Zhao et al.s method available on-line.

47 Riezler

168

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

e1

paraphrase

e2

e1

paraphrase

f1

align

align

f

e2

paraphrase

f2

Figure 9: Illustration Zhao et al.s pivot approaches paraphrase extraction.
dependency trees English sentences replacing removed subtrees POS
tags roots; words pivot language sentences aligned removed words
corresponding English sentences also replaced slots. language model also used,
paraphrases replaced longer sentences. Zhao et al.s experiments show method outperforms DIRT, able output many paraphrase pairs method Bannard
Callison-Burch, better precision, i.e., fewer wrongly produced pairs. generated
paraphrases (93%), however, contain one slot, method still sensitive word
alignment errors (Zhao et al., 2009), although features check word alignment quality
alleviate problem.
Madnani et al. (2007) used pivot approach similar Bannard Callison-Burchs (2005)
obtain synchronous (normally bilingual) English-to-English context-free grammar rules
bilingual parallel corpora. Parsing English text English-to-English synchronous rules
automatically paraphrases it; hence resulting synchronous rules used paraphrase generation (Section 3). rules associated probabilities, estimated bilingual
corpora. log-linear combination probabilities features invoked rules
used guide parsing. Madnani et al. employed English-to-English rules parse and, thus,
paraphrase human-authored English reference translations Chinese texts. showed using additional automatically generated reference translations tuning Chinese-to-English
SMT system improves performance, compared using human-authored references.
note alignment-based methods section appear used extract
paraphrase pairs, (unidirectional) textual entailment pairs.
4.4 Evaluating Extraction Methods
evaluating extraction methods, would ideally measure precision (what percentage extracted pairs correct paraphrase textual entailment pairs) recall (what
percentage correct pairs could extracted actually extracted).
generation, however, recall cannot computed, number correct pairs
could extracted large corpus (by ideal method) unknown. Instead, one may
count number extracted pairs (the total yield method), possibly different precision levels. Different extraction methods, however, produce pairs different kinds (e.g., surface
strings, slotted surface templates, slotted dependency paths) different kinds corpora (e.g.,
monolingual multilingual parallel comparable corpora); hence, direct comparisons extraction methods may impossible. Furthermore, different scores obtained, depending whether
extracted pairs considered particular contexts not, whether required
interchangeable grammatical sentences (Bannard & Callison-Burch, 2005; Barzilay & Lee, 2003;
169

fiA NDROUTSOPOULOS & ALAKASIOTIS

Callison-Burch, 2008; Zhao et al., 2008). output extraction method may also include pairs
relatively minor variations (e.g., active vs. passive, verbs vs. nominalizations, variants
X company bought vs. X bought ), may cause methods produce large numbers minor variants appear better really are; points also apply evaluation
generation methods (Section 3.3), though discussed mostly extraction literature. Detecting grouping variants (e.g., turning passives nominalizations active
forms) may help avoid bias may also improve quality extracted pairs making
occurrences (grouped) expressions less sparse (Szpektor & Dagan, 2007).
generation, principle one could use paraphrase textual entailment recognizer
automatically score extracted pairs. However, recognizers yet accurate enough; hence,
human judges usually employed. extracting slotted textual entailment rules (e.g., X
painted textually entails work X), Szpektor et al. (2007) report human judges
find easier agree whether particular instantiations rules (in particular contexts)
correct incorrect, opposed asking assess directly correctness rules.
better evaluation strategy, then, show judges multiple sentences match lefthand side rule, along corresponding transformed sentences produced
applying rule, measure percentage sentence pairs judges consider correct
textual entailment pairs; measure thought precision individual rule.
Rules whose precision exceeds (high) threshold considered correct (Szpektor et al., 2007).
Again, one may also evaluate extraction methods indirectly, example measuring
much extracted pairs help information extraction (Bhagat & Ravichandran, 2008; Szpektor
& Dagan, 2007, 2008) expanding queries (Pasca & Dienes, 2005), measuring
well extracted pairs, seen paraphrasing rules, perform phrase alignment monolingual
parallel corpora (Callison-Burch et al., 2008), measuring extent SMT summarization
evaluation measures improved taking consideration extracted pairs (CallisonBurch et al., 2006a; Kauchak & Barzilay, 2006; Zhou et al., 2006b).

5. Conclusions
Paraphrasing textual entailment currently popular research topic. Paraphrasing seen
bidirectional textual entailment and, hence, similar methods often used both. Although
kinds methods described terms logical entailment, usually intended
capture human intuitions may strict logical entailment; although logic-based
methods developed, methods operate surface, syntactic, shallow semantic
level, dependency trees particularly popular representation.
Recognition methods, classify input pairs natural language expressions (or templates)
correct incorrect paraphrases textual entailment pairs, often rely supervised machine
learning combine similarity measures possibly operating different representation levels (surface, syntactic, semantic). recently, approaches search sequences transformations
connect two input expressions also gaining popularity, exploit paraphrasing
textual entailment rules extracted large corpora. RTE challenges provide significant
thrust recognition work, helped establish benchmarks attract researchers.
Generation methods, meaning methods generate paraphrases input natural language
expression (or template), expressions entail entailed input expression, currently based mostly bootstrapping ideas statistical machine translation. fewer
170

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Main ideas discussed
Logic-based inferencing
Vector space semantic models
Surface string similarity measures
Syntactic similarity measures
Similarity measures symbolic meaning representations
Machine learning algorithms
Decoding (transformation sequences)
Word/sentence alignment
Pivot language(s)
Bootstrapping
Distributional hypothesis
Synchronous grammar rules

R-TE
X
X
X
X
X
X
X

R-P
X
X
X
X
X
X
X

G-TE

X
X

G-P

X
X
X
X
X
X
X

E-TE

E-P

X

X
X

X
X
X
X
X

Table 3: Main ideas discussed tasks mostly used in. R: recognition; G: generation, E: extraction; TE: textual entailment, P: paraphrasing.

publications generation, compared recognition (and extraction), focus
paraphrasing; furthermore, established challenges benchmarks, unlike recognition.
Nevertheless, generation may provide opportunities novel research, especially researchers
experience statistical machine translation, may example wish develop alignment
decoding techniques especially paraphrasing textual entailment generation.
Extraction methods extract paraphrases textual entailment pairs (also called rules)
corpora, usually off-line. used construct resources (e.g., phrase tables collections rules) exploited recognition generation methods, tasks (e.g.,
statistical machine translation, information extraction). Many extraction methods based
Distributional Hypothesis, though often operate different representation levels. Alignment
techniques originating statistical machine translation recently also popular allow
existing large bilingual parallel corpora exploited. Extraction methods also differ depending
whether require parallel, comparable, simply large corpora, monolingual bilingual.
generation, extraction research focused paraphrasing, established
challenges benchmarks.
Table 3 summarizes main ideas discussed per task, Table 4 lists corresponding main resources typically required. underlying ideas generation extraction
methods effect same, shown Table 3, even methods perform different tasks;
recognition work relied rather different ideas. Generation extraction mostly focused
paraphrasing, already noted, fewer ideas explored generation
extraction (unidirectional) textual entailment.
expect see interplay among recognition, generation, extraction methods
near future. example, recognizers generators may use extracted rules larger extent;
recognizers may used filter candidate paraphrases textual entailment pairs extraction
generation approaches; generators may help produce monolingual parallel corpora
recognition benchmarks. also expect see paraphrasing textual entailment methods
used often larger natural language processing tasks, including question answering,
information extraction, text summarization, natural language generation, machine translation.
171

fiA NDROUTSOPOULOS & ALAKASIOTIS

Main ideas discussed
Logical-based inferencing
Vector space semantic models
Surface string similarity measures
Syntactic similarity measures
Similarity measures operating
symbolic meaning representations
Machine learning algorithms
Decoding (transformation sequences)
Word/sentence alignment
Pivot language(s)
Bootstrapping
Distributional hypothesis
Synchronous grammar rules

Main typically required resources
Parser producing logical meaning representations, inferencing engine,
resources extract meaning postulates common sense knowledge from.
Large monolingual corpus, possibly parser.
preprocessing tools, e.g., POS tagger, named-entity recognizer,
also required methods.
Parser.
Lexical semantic resources, possibly parser and/or semantic role labeling
produce semantic representations.
Training/testing datasets, components/resources needed compute features.
Synonyms, hypernyms-hyponyms, paraphrasing/TE rules.
Large parallel comparable corpora (monolingual multilingual), possibly
parser.
Multilingual parallel corpora.
Large monolingual corpus, recognizer.
Monolingual corpus (possibly parallel comparable).
Monolingual parallel corpus.

Table 4: Main ideas discussed main resources typically require.

Acknowledgments
thank three anonymous reviewers valuable comments. work funded
Greek PENED project Combined research areas information retrieval, natural language
processing, user modeling aiming development advanced search engines document
collections, co-funded European Union (80%) Greek General Secretariat
Research Technology (20%).

Appendix A. On-line Resources Mentioned
A.1 Bibliographic Resources, Portals, Tutorials
ACL 2007 tutorial textual entailment: http://www.cs.biu.ac.il/dagan
/TE-Tutorial-ACL07.ppt.
ACL Anthology: http://www.aclweb.org/anthology/.
Textual Entailment Portal: http://www.aclweb.org/aclwiki/index.php?
title=Textual Entailment Portal.
A.2 Corpora, Challenges, Datasets
Cohn et al.s paraphrase corpus: Word-aligned paraphrases;
http://www.dcs.shef.ac.uk/tcohn/paraphrase corpus.html.
FATE: RTE-2 dataset FrameNet annotations;
http://www.coli.uni-saarland.de/projects/salsa/fate/.
MSR Paraphrase Corpus: Paraphrase recognition benchmark dataset;
http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/.
172

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Multiple-Translation Chinese Corpus: Multiple English translations Chinese news articles;
http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2002T01.
RTE challenges, PASCAL Network Excellence: Textual entailment recognition challenges
datasets; http://pascallin.ecs.soton.ac.uk/Challenges/.
RTE track NISTs Text Analysis Conference: Continuation PASCALs RTE;
http://www.nist.gov/tac/tracks/.
Written News Compression Corpus: Sentence compression corpus;
http://jamesclarke.net/research/.
A.3 Implementations Machine Learning Algorithms
LIBSVM: SVM implementation; http://www.csie.ntu.edu.tw/cjlin/libsvm/.
Stanfords Maximum Entropy classifier: http://nlp.stanford.edu/software/index.shtml.
SVM-Light: SVM implementation; http://svmlight.joachims.org/.
Weka: Includes implementations many machine learning algorithms;
http://www.cs.waikato.ac.nz/ml/weka/.
A.4 Implementations Similarity Measures
EDITS: Suite recognize textual entailment computing edit distances; http://edits.fbk.eu/.
WordNet::Similarity: Implementations WordNet-based similarity measures;
http://wn-similarity.sourceforge.net/.
A.5 Parsers, POS Taggers, Named Entity Recognizers, Stemmers
Brills POS tagger: http://en.wikipedia.org/wiki/Brill tagger.
Charniaks parser: http://flake.cs.uiuc.edu/cogcomp/srl/CharniakServer.tgz.
Collins parser: http://people.csail.mit.edu/mcollins/code.html.
Link Grammar Parser: http://www.abisource.com/projects/link-grammar/.
MaltParser: http://w3.msi.vxu. se/nivre/research/MaltParser.html.
MINIPAR: http://www.cs.ualberta.ca/lindek/minipar.htm.
Porters stemmer: http://tartarus.org/martin/PorterStemmer/.
Stanfords named-entity recognizer, parser, tagger: http://nlp.stanford.edu/software/index.shtml.
173

fiA NDROUTSOPOULOS & ALAKASIOTIS

A.6 Statistical Machine Translation Tools Resources
Giza++: Often used train IBM models align words; http://www.fjoch.com/GIZA++.html.
Koehns Statistical Machine Translation site: Pointers commonly used SMT tools, resources;
http://www.statmt.org/.
Moses: Frequently used SMT system includes decoding facilities;
http://www.statmt.org/moses/.
SRILM: Commonly used create language models;
http://www.speech.sri.com/projects/srilm/.
A.7 Lexical Resources, Paraphrasing Textual Entailment Rules
Callison-Burchs paraphrase rules: Paraphrase rules extracted multilingual parallel corpora
via pivot language(s); implementation method used also available;
http://cs.jhu.edu/ccb/.
DIRT rules: Template pairs produced DIRT; http://demo.patrickpantel.com/.
Extended WordNet: Includes meaning representations extracted WordNets glosses;
http://wordnet.princeton.edu/.
FrameNet: http://framenet.icsi.berkeley.edu/.
Nomlex: English nominalizations verbs; http://nlp.cs.nyu.edu/nomlex/
TEASE rules: Textual entailment rules produced TEASE;
http://www.cs.biu.ac.il/szpekti/TEASE collection.zip.
VerbNet: http://verbs.colorado.edu/mpalmer/projects/verbnet.html.
WordNet: http://xwn.hlt.utdallas.edu/.
Zhao et al.s paraphrase rules: Paraphrase rules slots corresponding POS tags, extracted
multilingual parallel corpora via pivot language(s);
http://ir.hit.edu.cn/phpwebsite/index.php?
module=documents&JAS DocumentManager op=viewDocument&JAS Document id=268.

References
Alpaydin, E. (2004). Introduction Machine Learning. MIT Press.
Androutsopoulos, I., Oberlander, J., & Karkaletsis, V. (2007). Source authoring multilingual
generation personalised object descriptions. Nat. Lang. Engineering, 13(3), 191233.
Androutsopoulos, I., Ritchie, G. D., & Thanisch, P. (1995). Natural language interfaces databases
introduction. Nat. Lang. Engineering, 1(1), 2981.
Baeza-Yates, R., & Ribeiro-Neto, B. (1999). Modern Information Retrieval. Addison Wesley.
174

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Baker, C. F., Fillmore, C. J., & Lowe, J. B. (1998). Berkeley FrameNet project. Proc.
17th Int. Conf. Comp. Linguistics, pp. 8690, Montreal, Quebec, Canada.
Bannard, C., & Callison-Burch, C. (2005). Paraphrasing bilingual parallel corpora. Proc.
43rd Annual Meeting ACL, pp. 597604, Ann Arbor, MI.
Bar-Haim, R., Berant, J., & Dagan, I. (2009). compact forest scalable inference entailment paraphrase rules. Proc. Conf. EMNLP, pp. 10561065, Singapore.
Bar-Haim, R., Dagan, I., Dolan, B., Ferro, L., Giampiccolo, D., Magnini, B., & Szpektor, I. (2006).
2nd PASCAL recognising textual entailment challenge. Proc. 2nd PASCAL Challenges Workshop Recognising Textual Entailment, Venice, Italy.
Bar-Haim, R., Dagan, I., Greental, I., & Shnarch, E. (2007). Semantic inference lexicalsyntactic level. Proc. 22nd Conf. Artificial Intelligence, pp. 871876, Vancouver,
BC , Canada.
Barzilay, R., & Elhadad, N. (2003). Sentence alignment monolingual comparable corpora.
Proc. Conf. EMNLP, pp. 2532, Sapporo, Japan.
Barzilay, R., & Lee, L. (2002). Bootstrapping lexical choice via multiple-sequence alignment.
Proc. Conf. EMNLP, pp. 164171, Philadelphia, PA.
Barzilay, R., & Lee, L. (2003). Learning paraphrase: unsupervised approach using multiplesequence alignment. Proc. HLT Conf. NAACL, pp. 1623, Edmonton, Canada.
Barzilay, R., & McKeown, K. (2001). Extracting paraphrases parallel corpus. Proc.
39th Annual Meeting ACL, pp. 5057, Toulouse, France.
Barzilay, R., & McKeown, K. R. (2005). Sentence fusion multidocument news summarization.
Comp. Linguistics, 31(3), 297327.
Bateman, J., & Zock, M. (2003). Natural language generation. Mitkov, R. (Ed.), Oxford
Handbook Comp. Linguistics, chap. 15, pp. 284304. Oxford University Press.
Bensley, J., & Hickl, A. (2008). Workshop: Application LCCs GROUNGHOG system RTE -4.
Proc. Text Analysis Conference, Gaithersburg, MD.
Bergmair, R. (2009). proposal evaluation measures RTE. Proc. ACL Workshop
Applied Textual Inference, pp. 1017, Singapore.
Berwick, R. C. (1991). Principles principle-based parsing. Berwick, R. C., Abney, S. P.,
& Tenny, C. (Eds.), Principle-Based Parsing: Computation Psycholinguistics, pp. 137.
Kluwer, Dordrecht, Netherlands.
Bhagat, R., Pantel, P., & Hovy, E. (2007). LEDIR: unsupervised algorithm learning directionality inference rules. Proc. Conf. EMNLP Conf. Computational
Nat. Lang. Learning, pp. 161170, Prague, Czech Republic.
Bhagat, R., & Ravichandran, D. (2008). Large scale acquisition paraphrases learning surface
patterns. Proc. 46th Annual Meeting ACL: HLT, pp. 674682, Columbus, OH.
Bikel, D. M., Schwartz, R. L., & Weischedel, R. M. (1999). algorithm learns whats
name. Machine Learning, 34(1-3), 211231.
Blum, A., & Mitchell, T. (1998). Combining labeled unlabeled data co-training. Proc.
11th Annual Conf. Computational Learning Theory, pp. 92100, Madison, WI.
175

fiA NDROUTSOPOULOS & ALAKASIOTIS

Bos, J., & Markert, K. (2005). Recognising textual entailment logical inference. Proc.
Conf. HLT EMNLP, pp. 628635, Vancouver, BC, Canada.
Brill, E. (1992). simple rule-based part speech tagger. Proc. 3rd Conf. Applied
Nat. Lang. Processing, pp. 152155, Trento, Italy.
Brockett, C., & Dolan, W. (2005). Support Vector Machines paraphrase identification corpus
construction. Proc. 3rd Int. Workshop Paraphrasing, pp. 18, Jeju island, Korea.
Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., & Mercer, R. L. (1993). mathematics
statistical machine translation: Parameter estimation. Comp. Linguistics, 19(2), 263311.
Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures lexical semantic relatedness. Comp. Linguistics, 32(1), 1347.
Burchardt, A., & Pennacchiotti, M. (2008). FATE: FrameNet-annotated corpus textual entailment. Proc. 6th Language Resources Evaluation Conference, Marrakech,
Marocco.
Burchardt, A., Pennacchiotti, M., Thater, S., & Pinkal, M. (2009). Assessing impact frame
semantics textual entailment. Nat. Lang. Engineering, 15(4).
Burchardt, A., Reiter, N., Thater, S., & Frank, A. (2007). semantic approach textual entailment: System evaluation task analysis. Proc. ACL - PASCAL Workshop Textual
Entailment Paraphrasing, pp. 1015, Prague, Czech Republic. ACL.
Califf, M., & Mooney, R. (2003). Bottom-up relational learning pattern matching rules information extraction. Journal Machine Learning Research, 4, 177210.
Callison-Burch, C. (2008). Syntactic constraints paraphrases extracted parallel corpora.
Proc. Conf. EMNLP, pp. 196205, Honolulu, HI.
Callison-Burch, C., Cohn, T., & Lapata, M. (2008). ParaMetric: automatic evaluation metric
paraphrasing. Proc. 22nd Int. Conf. Comp. Linguistics, pp. 97104, Manchester,
UK .
Callison-Burch, C., Dagan, I., Manning, C., Pennacchiotti, M., & Zanzotto, F. M. (Eds.). (2009).
Proc. ACL - IJCNLP Workshop Applied Textual Inference. Singapore.
Callison-Burch, C., Koehn, P., & Osborne, M. (2006a). Improved statistical machine translation
using paraphrases. Proc. HLT Conf. NAACL, pp. 1724, New York, NY.
Callison-Burch, C., Osborne, M., & Koehn, P. (2006b). Re-evaluating role BLEU machine
translation research. Proc. 11th Conf. EACL, pp. 249256, Trento, Italy.
Carnap, R. (1952). Meaning postulates. Philosophical Studies, 3(5).
Charniak, E. (2000). maximum-entropy-inspired parser. Proc. 1st Conf. NAACL, pp.
132139, Seattle, WA.
Chevelu, J., Lavergne, T., Lepage, Y., & Moudenc, T. (2009). Introduction new paraphrase
generation tool based Monte-Carlo sampling. Proc. 47th Annual Meeting ACL
4th Int. Joint Conf. Nat. Lang. Processing AFNLP, pp. 249252, Singapore.
Clarke, D. (2009). Context-theoretic semantics natural language: overview. Proc.
EACL workshop Geometrical Models Nat. Lang. Semantics, pp. 112119, Athens,
Greece.
176

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Clarke, J., & Lapata, M. (2008). Global inference sentence compression: integer linear
programming approach. Journal Artificial Intelligence Research,, 31(1), 399429.
Cohn, T., Callison-Burch, C., & Lapata, M. (2008). Constructing corpora development
evaluation paraphrase systems. Comp. Linguistics, 34(4), 597614.
Cohn, T., & Lapata, M. (2008). Sentence compression beyond word deletion. Proc. 22nd
Int. Conf. Comp. Linguistics, Manchester, UK.
Cohn, T., & Lapata, M. (2009). Sentence compression tree transduction. Journal Artificial
Intelligence Research, 34(1), 637674.
Collins, M. (2003). Head-driven statistical models natural language parsing. Comput. Linguistics, 29(4), 589637.
Corley, C., & Mihalcea, R. (2005). Measuring semantic similarity texts. Proc. ACL
Workshop Empirical Modeling Semantic Equivalence Entailment, pp. 1318, Ann
Arbor, MI.
Cristianini, N., & Shawe-Taylor, J. (2000). Introduction Support Vector Machines
Kernel-based Learning Methods. Cambridge University Press.
Culicover, P. (1968). Paraphrase generation information retrieval stored text. Mechanical
Translation Computational Linguistics, 11(12), 7888.
Dagan, I., Dolan, B., Magnini, B., & Roth, D. (2009). Recognizing textual entailment: Rational,
evaluation approaches. Nat. Lang. Engineering, 15(4), ixvii. Editorial special
issue Textual Entailment.
Dagan, I., Glickman, O., & Magnini, B. (2006). PASCAL recognising textual entailment challenge. Quinonero-Candela, J., Dagan, I., Magnini, B., & dAlche Buc, F. (Eds.), Machine
Learning Challenges. Lecture Notes Computer Science, Vol. 3944, pp. 177190. SpringerVerlag.
Das, D., & Smith, N. A. (2009). Paraphrase identification probabilistic quasi-synchronous recognition. Proc. 47th Annual Meeting ACL 4th Int. Joint Conf. Nat. Lang.
Processing AFNLP, pp. 468476, Singapore.
de Marneffe, M., Rafferty, A., & Manning, C. (2008). Finding contradictions text. Proc.
46th Annual Meeting ACL: HLT, pp. 10391047, Columbus, OH.
Deleger, L., & Zweigenbaum, P. (2009). Extracting lay paraphrases specialized expressions
monolingual comparable medical corpora. Proc. 2nd Workshop Building
Using Comparable Corpora: Parallel Non-parallel Corpora, pp. 210, Singapore.
Dolan, B., & Dagan, I. (Eds.). (2005). Proc. ACL workshop Empirical Modeling Semantic Equivalence Entailment. Ann Arbor, MI.
Dolan, B., Quirk, C., & Brockett, C. (2004). Unsupervised construction large paraphrase corpora: Eploiting massively parallel news sources. Proc. 20th Int. Conf. Comp.
Linguistics, pp. 350356, Geneva, Switzerland.
Dolan, W. B., & Brockett, C. (2005). Automatically constructing corpus sentential paraphrases.
Proc. 3rd Int. Workshop Paraphrasing, pp. 916, Jeju island, Korea.
177

fiA NDROUTSOPOULOS & ALAKASIOTIS

Dras, M. (1998). Search constraint-based paraphrasing. Proc. 2nd Int. Conf. Natural
Lang. Processing Industrial Applications, pp. 213219, Moncton, Canada.
Drass, M., & Yamamoto, K. (Eds.). (2005). Proc. 3rd Int. Workshop Paraphrasing. Jeju
island, Korea.
Duboue, P. A., & Chu-Carroll, J. (2006). Answering question wish asked:
impact paraphrasing question answering. Proc. HLT Conf. NAACL, pp.
3336, New York, NY.
Duclaye, F., Yvon, F., & Collin, O. (2003). Learning paraphrases improve question-answering
system. Proc. EACL Workshop Nat. Lang. Processing Question Answering,
pp. 3541, Budapest, Hungary.
Durbin, R., Eddy, S., Krogh, A., & Mitchison, G. (1998). Biological Sequence Analysis. Cambridge
University Press.
Elhadad, N., & Sutaria, K. (2007). Mining lexicon technical terms lay equivalents. Proc.
Workshop BioNLP, pp. 4956, Prague, Czech Republic.
Erk, K., & Pado, S. (2006). Shalmaneser toolchain shallow semantic parsing. Proc.
5th Language Resources Evaluation Conference, Genoa, Italy.
Erk, K., & Pado, S. (2009). Paraphrase assessment structured vector space: Exploring parameters
datasets. Proc. EACL Workshop Geometrical Models Nat. Lang. Semantics,
pp. 5765, Athens, Greece.
Fellbaum, C. (1998). WordNet: Electronic Lexical Database. MIT Press.
Finch, A., Hwang, Y. S., & Sumita, E. (2005). Using machine translation evaluation techniques
determine sentence-level semantic equivalence. Proc. 3rd Int. Workshop Paraphrasing, pp. 1724, Jeju Island, Korea.
Freund, Y., & Schapire, R. E. (1995). decision-theoretic generalization on-line learning
application boosting. Proc. 2nd European Conf. Computational Learning
Theory, pp. 2337, Barcelona, Spain.
Friedman, J., Hastie, T., & Tibshirani, R. (2000). Additive logistic regression: statistical view
boosting. Annals Statistics, 28(2), 337374.
Fung, P., & Cheung, P. (2004). Multi-level bootstrapping extracting parallel sentences
quasi-comparable corpus. Proc. 20th Int. Conf. Comp. Linguistics, pp. 1051
1057, Geneva, Switzerland.
Galanis, D., & Androutsopoulos, I. (2010). extractive supervised two-stage method sentence
compression. Proc. HLT Conf. NAACL, Los Angeles, CA.
Gale, W., & Church, K. (1993). program aligning sentences bilingual corpora. Comp.
Linguistics, 19(1), 75102.
Germann, U., Jahr, M., Knight, K., Marcu, D., & Yamada, K. (2001). Fast decoding optimal
decoding machine translation. Proc. 39th Annual Meeting ACL, pp. 228235,
Toulouse, France.
Giampiccolo, D., Dang, H., Magnini, B., Dagan, I., & Dolan, B. (2008). fourth PASCAL recognizing textual entailment challenge. Proc. Text Analysis Conference, pp. 19,
Gaithersburg, MD.
178

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Giampiccolo, D., Magnini, B., Dagan, I., & Dolan, B. (2007). third PASCAL recognizing textual entailment challenge. Proc. ACL-Pascal Workshop Textual Entailment
Paraphrasing, pp. 19, Prague, Czech Republic.
Glickman, O., & Dagan, I. (2004). Acquiring lexical paraphrases single corpus. Nicolov, N., Bontcheva, K., Angelova, G., & Mitkov, R. (Eds.), Recent Advances Nat. Lang.
Processing III, pp. 8190. John Benjamins.
Grishman, R. (2003). Information extraction. Mitkov, R. (Ed.), Oxford Handbook Comp.
Linguistics, chap. 30, pp. 545559. Oxford University Press.
Habash, N., & Dorr, B. (2003). categorial variation database english. Proc. HLT
Conf. NAACL, pp. 1723, Edmonton, Canada.
Haghighi, A. D. (2005). Robust textual inference via graph matching. Proc. Conf.
EMNLP , pp. 387394, Vancouver, BC , Canada.
Harabagiu, S., & Hickl, A. (2006). Methods using textual entailment open-domain question
answering. Proc. 21st Int. Conf. Comp. Linguistics 44th Annual Meeting
ACL, pp. 905912, Sydney, Australia.
Harabagiu, S., Hickl, A., & Lacatusu, F. (2006). Negation, contrast contradiction text processing. Proc. 21st National Conf. Artificial Intelligence, pp. 755762, Boston,
.
Harabagiu, S., & Moldovan, D. (2003). Question answering. Mitkov, R. (Ed.), Oxford
Handbook Comp. Linguistics, chap. 31, pp. 560582. Oxford University Press.
Harabagiu, S. M., Maiorano, S. J., & Pasca, M. A. (2003). Open-domain textual question answering
techniques. Nat. Lang. Engineering, 9(3), 231267.
Harmeling, S. (2009). Inferring textual entailment probabilistically sound calculus. Nat.
Lang. Engineering, 15(4), 459477.
Harris, Z. (1964). Distributional Structure. Katz, J., & Fodor, J. (Eds.), Philosphy Linguistics, pp. 3349. Oxford University Press.
Hashimoto, C., Torisawa, K., Kuroda, K., De Saeger, S., Murata, M., & Kazama, J. (2009). Largescale verb entailment acquisition Web. Proc. Conf. EMNLP, pp. 1172
1181, Singapore.
Hearst, M. (1998). Automated discovery Wordnet relations. Fellbaum, C. (Ed.), WordNet:
Electronic Lexical Database. MIT Press.
Herbelot, A. (2009). Finding word substitutions using distributional similarity baseline immediate context overlap. Proc. Student Research Workshop 12th Conf. EACL,
pp. 2836, Athens, Greece.
Hickl, A. (2008). Using discourse commitments recognize textual entailment. Proc.
22nd Int. Conf. Comp. Linguistics, pp. 337344, Manchester, UK.
Hobbs, J. (1986). Resolving pronoun references. Readings Nat. Lang. Processing, pp. 339
352. Morgan Kaufmann.
Hovy, E. (2003). Text summarization. Mitkov, R. (Ed.), Oxford Handbook Comp. Linguistics, chap. 32, pp. 583598. Oxford University Press.
179

fiA NDROUTSOPOULOS & ALAKASIOTIS

Huffman, S. (1995). Learning information extraction patterns examples. Proc. IJCAI
Workshop New Approaches Learning Nat. Lang. Processing, pp. 127142, Montreal,
Quebec, Canada.
Ibrahim, A., Katz, B., & Lin, J. (2003). Extracting structural paraphrases aligned monolingual
corpora. Proc. ACL Workshop Paraphrasing, pp. 5764, Sapporo, Japan.
Iftene, A. (2008). UAIC participation RTE 4. Proc. Text Analysis Conference, Gaithersburg, MD.
Iftene, A., & Balahur-Dobrescu, A. (2007). Hypothesis transformation semantic variability rules
used recognizing textual entailment. Proc. ACL - PASCAL Workshop Textual
Entailment Paraphrasing, pp. 125130, Prague, Czech Republic.
Inui, K., & Hermjakob, U. (Eds.). (2003). Proc. 2nd Int. Workshop Paraphrasing: Paraphrase Acquisition Applications. Sapporo, Japan.
Jacquemin, C., & Bourigault, D. (2003). Term extraction automatic indexing. Mitkov, R.
(Ed.), Oxford Handbook Comp. Linguistics, chap. 33, pp. 599615. Oxford University
Press.
Joachims, T. (2002). Learning Classify Text Using Support Vector Machines: Methods, Theory,
Algorithms. Kluwer.
Jurafsky, D., & Martin, J. H. (2008). Speech Language Processing (2nd edition). Prentice Hall.
Kauchak, D., & Barzilay, R. (2006). Paraphrasing automatic evaluation. Proc. HLT
Conf. NAACL, pp. 455462, New York, NY.
Klein, D., & Manning, C. D. (2003). Accurate unlexicalized parsing. Proc. 41st Annual
Meeting ACL, pp. 423430, Sapporo, Japan.
Knight, K., & Marcu, D. (2002). Summarization beyond sentence extraction: probalistic approach
sentence compression. Artificial Intelligence, 139(1), 91107.
Koehn, P. (2004). Pharaoh: beam search decoder phrase-based statistical machine translation
models. Proc. 6th Conf. Association Machine Translation Americas,
pp. 115124, Washington, DC.
Koehn, P. (2009). Statistical Machine Translation. Cambridge University Press.
Koehn, P., Och, F. J., & Marcu, D. (2003). Statistical phrase-based translation. Proc. HLT
Conf. NAACL, pp. 4854, Edmonton, Canada. ACL.
Kohomban, U., & Lee, W. (2005). Learning semantic classes word sense disambiguation.
Proc. 43rd Annual Meeting ACL, pp. 3441, Ann Arbor, MI.
Kouylekov, M., & Magnini, B. (2005). Recognizing textual entailment tree edit distance algorithms. Proc. PASCAL Recognising Textual Entailment Challenge.
Kubler, S., McDonald, R., & Nivre, J. (2009). Dependency Parsing. Synthesis Lectures HLT.
Morgan Claypool Publishers.
Lappin, S., & Leass, H. (1994). algorithm pronominal anaphora resolution. Comp. Linguistics, 20(4), 535561.
Leacock, C., Miller, G., & Chodorow, M. (1998). Using corpus statistics WordNet relations
sense identification. Comp. Linguistics, 24(1), 147165.
180

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Lepage, Y., & Denoual, E. (2005). Automatic generation paraphrases used translation
references objective evaluation measures machine translation. Proc. 3rd Int.
Workshop Paraphrasing, pp. 5764, Jesu Island, Korea.
Levenshtein, V. (1966). Binary codes capable correcting deletions, insertions, reversals.
Soviet Physice-Doklady, 10, 707710.
Lin, D. (1994). PRINCIPAR: efficient, broad-coverage, principle-based parser. Proc.
15th Conf. Comp. Linguistics, pp. 482488, Kyoto, Japan. ACL.
Lin, D. (1998a). Automatic retrieval clustering similar words. Proc. 36th Annual
Meeting ACL 17th Int. Conf. Comp. Linguistics, pp. 768774, Montreal, Quebec,
Canada.
Lin, D. (1998b). information-theoretic definition similarity. Proc. 15th Int. Conf.
Machine Learning, pp. 296304, Madison, WI. Morgan Kaufmann, San Francisco, CA.
Lin, D. (1998c). information-theoretic definition similarity. Proc. 15th Int. Conf.
Machine Learning, pp. 296304, Madison, WI.
Lin, D., & Pantel, P. (2001). Discovery inference rules question answering. Nat. Lang.
Engineering, 7, 343360.
Lonneker-Rodman, B., & Baker, C. (2009). FrameNet model applications. Nat. Lang.
Engineering, 15(3), 414453.
MacCartney, B., Galley, M., & Manning, C. (2008). phrase-based alignment model natural
language inference. Proc. Conf. EMNLP, pp. 802811, Honolulu, Hawaii.
MacCartney, B., & Manning, C. (2009). extended model natural logic. Proc. 8th Int.
Conf. Computational Semantics, pp. 140156, Tilburg, Netherlands.
Madnani, N., Ayan, F., Resnik, P., & Dorr, B. J. (2007). Using paraphrases parameter tuning
statistical machine translation. Proc. 2nd Workshop Statistical Machine Translation,
pp. 120127, Prague, Czech Republic.
Malakasiotis, P. (2009). Paraphrase recognition using machine learning combine similarity measures. Proc. 47th Annual Meeting ACL 4th Int. Joint Conf. Nat. Lang.
Processing AFNLP, Singapore.
Malakasiotis, P., & Androutsopoulos, I. (2007). Learning textual entailment using SVMs string
similarity measures. Proc. ACL - PASCAL Workshop Textual Entailment Paraphrasing, pp. 4247, Prague. ACL.
Mani, I. (2001). Automatic Summarization. John Benjamins.
Manning, C. D. (2008). Introduction Information Retrieval. Cambridge University Press.
Manning, C. D., & Schuetze, H. (1999). Foundations Statistical Natural Language Processing.
MIT press.
Marquez, L., Carreras, X., Litkowski, K. C., & Stevenson, S. (2008). Semantic role labeling:
introduction special issue. Comp. Linguistics, 34(2), 145159.
Marton, Y., Callison-Burch, C., & Resnik, P. (2009). Improved statistical machine translation using
monolingually-derived paraphrases. Proc. Conf. EMNLP, pp. 381390, Singapore.
181

fiA NDROUTSOPOULOS & ALAKASIOTIS

McCarthy, D., & Navigli, R. (2009). English lexical substitution task. Lang. Resources &
Evaluation, 43, 139159.
McDonald, R. (2006). Discriminative sentence compression soft syntactic constraints. Proc.
11th Conf. EACL, pp. 297304, Trento, Italy.
McKeown, K. (1983). Paraphrasing questions using given new information. Comp. Linguistics,
9(1).
Mehdad, Y. (2009). Automatic cost estimation tree edit distance using particle swarm optimization. Proc. 47th Annual Meeting ACL 4th Int. Joint Conf. Nat. Lang.
Processing AFNLP, pp. 289292, Singapore.
Melamed, D. (1999). Bitext maps alignment via pattern recognition. Comp. Linguistics, 25(1),
107130.
Melcuk, I. (1987). Dependency Syntax: Theory Practice. State University New York Press.
Meyers, A., Macleod, C., Yangarber, R., Grishman, R., Barrett, L., & Reeves, R. (1998). Using
NOMLEX produce nominalization patterns information extraction. Proc.
COLING - ACL workshop Computational Treatment Nominals, Montreal, Quebec,
Canada.
Mintz, M., Bills, S., Snow, R., & Jurafsky, D. (2009). Distant supervision relation extraction
without labeled data. Proc. 47th Annual Meeting ACL 4th Int. Joint Conf.
Nat. Lang. Processing AFNLP, pp. 10031011, Singapore.
Mirkin, S., Dagan, I., & Shnarch, E. (2009a). Evaluating inferential utility lexical-semantic
resources. Proc. 12th Conf. EACL, pp. 558566, Athens, Greece.
Mirkin, S., Specia, L., Cancedda, N., Dagan, I., Dymetman, M., & Szpektor, I. (2009b). Sourcelanguage entailment modeling translating unknown terms. Proc. 47th Annual
Meeting ACL 4th Int. Joint Conf. Nat. Lang. Processing AFNLP, pp. 791
799, Singapore.
Mitchell, J., & Lapata, M. (2008). Vector-based models semantic composition. Proc.
46th Annual Meeting ACL: HLT, pp. 236244, Columbus, OH.
Mitchell, T. (1997). Machine Learning. Mc-Graw Hill.
Mitkov, R. (2003). Anaphora resolution. Mitkov, R. (Ed.), Oxford Handbook Comp.
Linguistics, chap. 14, pp. 266283. Oxford University Press.
Moens, M. (2006). Information Extraction: Algorithms Prospects Retrieval Context.
Springer.
Moldovan, D., & Rus, V. (2001). Logic form transformation WordNet applicability
question answering. Proc. 39th Annual Meeting ACL, pp. 402409, Toulouse,
France.
Molla, D., Schwitter, R., Rinaldi, F., Dowdall, J., & Hess, M. (2003). Anaphora resolution E X TR NS. Proc. Int. Symposium Reference Resolution Applications
Question Answering Summarization, pp. 2325, Venice, Italy.
Molla, D., & Vicedo, J. (2007). Question answering restricted domains: overview. Comp.
Linguistics, 33(1), 4161.
182

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Moore, R. C. (2001). Towards simple accurate statistical approach learning translation relationships among words. Proc. ACL Workshop Data-Driven Machine Translation,
Toulouse, France.
Moschitti, A. (2009). Syntactic semantic kernels short text pair categorization. Proc.
12th Conf. EACL, pp. 576584, Athens, Greece.
Munteanu, D. S., & Marcu, D. (2006). Improving machine translation performance exploiting
non-parallel corpora. Comp. Linguistics, 31(4), 477504.
Muslea, I. (1999). Extraction patterns information extraction tasks: survey. Proc.
AAAI Workshop Machine Learning Information Extraction, Orlando, FL.
Navigli, R. (2008). structural approach automatic adjudication word sense disagreements. Nat. Lang. Engineering, 14(4), 547573.
Nelken, R., & Shieber, S. M. (2006). Towards robust context-sensitive sentence alignment
monolingual corpora. Proc. 11th Conf. EACL, pp. 161168, Trento, Italy.
Nielsen, R., Ward, W., & Martin, J. (2009). Recognizing entailment intelligent tutoring systems.
Nat. Lang. Engineering, 15(4), 479501.
Nivre, J., Hall, J., Nilsson, J., Chanev, A., Eryigit, G., Kuebler, S., Marinov, S., & Marsi, E. (2007).
ALT PARSER: language-independent system data-driven dependency parsing. Nat.
Lang. Engineering, 13(2), 95135.
Och, F. J., & Ney, H. (2003). systematic comparison various stat. alignment models. Comp.
Ling., 29(1), 1921.
ODonnell, M., Mellish, C., Oberlander, J., & Knott, A. (2001). ILEX: architecture dynamic
hypertext generation system. Nat. Lang. Engineering, 7(3), 225250.
Pado, S., Galley, M., Jurafsky, D., & Manning, C. D. (2009). Robust machine translation evaluation
entailment features. Proc. 47th Annual Meeting ACL 4th Int. Joint
Conf. Nat. Lang. Processing AFNLP, pp. 297305, Singapore.
Pado, S., & Lapata, M. (2007). Dependency-based construction semantic space models. Comp.
Ling., 33(2), 161199.
Palmer, M., Gildea, D., & Kingsbury, P. (2005). Propositional Bank: annotated corpus
semantic roles. Comp. Linguistics, 31(1), 71105.
Pang, B., Knight, K., & Marcu, D. (2003). Syntax-based alignment multiple translations: extracting paraphrases generating new sentences. Proc. Human Lang. Techn. Conf.
NAACL , pp. 102109, Edmonton, Canada.
Pantel, P., Bhagat, R., Coppola, B., Chklovski, T., & Hovy, E. H. (2007). ISP: Learning inferential
selectional preferences. Proc. HLT Conf. NAACL, pp. 564571, Rochester, NY.
Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002). BLEU: method automatic evaluation
machine translation. Proc. 40th Annual Meeting ACL, pp. 311318, Philadelphia,
PA .
Pasca, M. (2003). Open-domain question answering large text collections (2nd edition). Center
Study Language Information.
183

fiA NDROUTSOPOULOS & ALAKASIOTIS

Pasca, M., & Dienes, P. (2005). Aligning needles haystack: Paraphrase acquisition across
Web. Proc. 2nd Int. Joint Conf. Nat. Lang. Processing, pp. 119130, Jeju Island,
Korea.
Perez, D., & Alfonseca, E. (2005). Application BLEU algorithm recognizing textual
entailments. Proc. PASCAL Challenges Worshop Recognising Textual Entailment,
Southampton, UK.
Porter, M. F. (1997). algorithm suffix stripping. Jones, K. S., & Willet, P. (Eds.), Readings
Information Retrieval, pp. 313316. Morgan Kaufmann.
Power, R., & Scott, D. (2005). Automatic generation large-scale paraphrases. Proc. 3rd
Int. Workshop Paraphrasing, pp. 7379, Jesu Island, Korea.
Qiu, L., Kan, M. Y., & Chua, T. (2006). Paraphrase recognition via dissimilarity significance classification. Proc. Conf. EMNLP, pp. 1826, Sydney, Australia.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann.
Quirk, C., Brockett, C., & Dolan, W. B. (2004). Monolingual machine translation paraphrase
generation. Proc. Conf. EMNLP, pp. 142149, Barcelona, Spain.
Ravichandran, D., & Hovy, E. (2002). Learning surface text patterns question answering
system. Proc. 40th Annual Meeting ACL, pp. 4147, Philadelphia, PA.
Ravichandran, D., Ittycheriah, A., & Roukos, S. (2003). Automatic derivation surface text patterns maximum entropy based question answering system. Proc. HLT Conf.
NAACL , pp. 8587, Edmonton, Canada.
Reiter, E., & Dale, R. (2000). Building Natural Language Generation Systems. Cambridge University Press.
Resnik, P. (1999). Semantic similarity taxonomy: information-based measure application problems ambiguity natural language. Journal Artificial Intelligence
Research, 11, 95130.
Riezler, S., Vasserman, A., Tsochantaridis, I., Mittal, V., & Liu, Y. (2007). Statistical machine
translation query expansion answer retrieval. Proc. 45th Annual Meeting
ACL , pp. 464471, Prague, Czech Republic.
Riloff, E. (1996a). Automatically generating extraction patterns untagged text. Proc.
13th National Conf. Artificial Intelligence, pp. 10441049, Portland, OR.
Riloff, E. (1996b). empirical study automated dictionary construction information extraction three domains. Artificial Intelligence, 85(12), 101134.
Riloff, E., & Jones, R. (1999). Learning dictionaries information extraction multi-level bootstrapping. Proc. 16th National Conf. Artificial Intelligence, pp. 474479, Orlando,
FL.
Rinaldi, F., Dowdall, J., Kaljurand, K., Hess, M., & Molla, D. (2003). Exploiting paraphrases
question answering system. Proc. 2nd Int. Workshop Paraphrasing, pp. 2532,
Saporo, Japan.
Sato, S., & Nakagawa, H. (Eds.). (2001). Proc. Workshop Automatic Paraphrasing. Tokyo,
Japan.
184

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Schohn, G., & Cohn, D. (2000). Less more: active learning Support Vector Machines.
Proc. 17th Int. Conf. Machine Learning, pp. 839846, Stanford, CA.
Schuler, K. K. (2005). VerbNet: Broad-Coverage, Comprehensive Verb Lexicon. Ph.D. thesis,
Univ. Pennsylvania.
Sekine, S., Inui, K., Dagan, I., Dolan, B., Giampiccolo, D., & Magnini, B. (Eds.). (2007). Proc.
ACL - PASCAL Workshop Textual Entailment Paraphrasing. Prague, Czech Republic.
Sekine, S., & Ranchhod, E. (Eds.). (2009). Named Entities Recognition, Classification Use.
John Benjamins.
Selkow, S. (1977). tree-to-tree editing problem. Information Processing Letters, 6(6), 184186.
Shinyama, Y., & Sekine, S. (2003). Paraphrase acquisition information extraction. Proc.
ACL Workshop Paraphrasing, Sapporo, Japan.
Siblini, R., & Kosseim, L. (2008). Using ontology alignment TAC RTE challenge. Proc.
Text Analysis Conference, Gaithersburg, MD.
Sleator, D. D., & Temperley, D. (1993). Parsing English link grammar. Proc. 3rd Int.
Workshop Parsing Technologies, pp. 277292, Tilburg, Netherlands Durbuy, Belgium.
Soderland, S. (1999). Learning inf. extraction rules semi-structured free text. Mach. Learning, 34(13), 233272.
Soderland, S., Fisher, D., Aseltine, J., & Lehnert, W. G. (1995). CRYSTAL: Inducing conceptual
dictionary. Proc. 14th Int. Joint Conf. Artificial Intelligence, pp. 13141319,
Montreal, Quebec, Canada.
Stevenson, M., & Wilks, Y. (2003). Word sense disambiguation. Mitkov, R. (Ed.), Oxford
Handbook Comp. Linguistics, chap. 13, pp. 249265. Oxford University Press.
Stolcke, A. (2002). SRILM extensible language modeling toolkit. Proc. 7th Int. Conf.
Spoken Language Processing, pp. 901904, Denver, CO.
Szpektor, I., & Dagan, I. (2007). Learning canonical forms entailment rules. Proc. Recent
Advances Natural Lang. Processing, Borovets, Bulgaria.
Szpektor, I., & Dagan, I. (2008). Learning entailment rules unary templates. Proc.
22nd Int. Conf. Comp. Linguistics, pp. 849856, Manchester, UK.
Szpektor, I., Dagan, I., Bar-Haim, R., & Goldberger, J. (2008). Contextual preferences. Proc.
46th Annual Meeting ACL: HLT, pp. 683691, Columbus, OH.
Szpektor, I., Shnarch, E., & Dagan, I. (2007). Instance-based evaluation entailment rule acquisition. Proc. 45th Annual Meeting ACL, pp. 456463, Prague, Czech Republic.
Szpektor, I., Tanev, H., Dagan, I., & Coppola, B. (2004). Scaling Web-based acquisition entailment relations. Proc. Conf. EMNLP, Barcelona, Spain.
Tai, K.-C. (1979). tree-to-tree correction problem. Journal ACM, 26(3), 422433.
Tatu, M., Iles, B., Slavick, J., Novischi, A., & Moldovan, D. (2006). COGEX second recognizing textual entailment challenge. Proc. 2nd PASCAL Challenges Workshop
Recognising Textual Entailment, Venice, Italy.
185

fiA NDROUTSOPOULOS & ALAKASIOTIS

Tatu, M., & Moldovan, D. (2005). semantic approach recognizing textual entailment. Proc.
Conf. HLT EMNLP, pp. 371378, Vancouver, Canada.
Tatu, M., & Moldovan, D. (2007). COGEX RTE 3. Proc. ACL - PASCAL Workshop
Textual Entailment Paraphrasing, pp. 2227, Prague, Czech Republic.
Tomuro, N. (2003). Interrogative reformulation patterns acquisition question paraphrases.
Proc. 2nd Int. Workshop Paraphrasing, pp. 3340, Sapporo, Japan.
Tong, S., & Koller, D. (2002). Support Vector Machine active learning applications text
classification. Machine Learning Research, 2, 4566.
Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). Feature-rich part-of-speech tagging cyclic dependency network. Proc. HLT Conf. NAACL, pp. 173180,
Edmonton, Canada.
Tsatsaronis, G. (2009). Word Sense Disambiguation Text Relatedness Based Word Thesauri.
Ph.D. thesis, Department Informatics, Athens University Economics Business.
Tsatsaronis, G., Varlamis, I., & Vazirgiannis, M. (2010). Text relatedness based word thesaurus.
Artificial Intelligence Research, 37, 139.
Turney, P., & Pantel, P. (2010). frequency meaning: Vector space models semantics.
Artificial Intelligence Research, 37, 141188.
Vapnik, V. (1998). Statistical learning theory. John Wiley.
Vendler, Z. (1967). Verbs Times. Linguistics Philosophy, chap. 4, pp. 97121. Cornell
University Press.
Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment statistical translation.
Proc. 16th Conf. Comp. Linguistics, pp. 836841, Copenhagen, Denmark.
Voorhees, E. (2001). TREC QA track. Nat. Lang. Engineering, 7(4), 361378.
Voorhees, E. (2008). Contradictions justifications: Extensions textual entailment task.
Proc. 46th Annual Meeting ACL: HLT, pp. 6371, Columbus, OH.
Wan, S., Dras, M., Dale, R., & Paris, C. (2006). Using dependency-based features take parafarce paraphrase. Proc. Australasian Language Technology Workshop, pp.
131138, Sydney, Australia.
Wang, R., & Neumann, G. (2008). divide-and-conquer strategy recognizing textual entailment. Proc. Text Analysis Conference, Gaithersburg, MD.
Wang, X., Lo, D., Jiang, J., Zhang, L., & Mei, H. (2009). Extracting paraphrases technical terms
noisy parallel software corpora. Proc. 47th Annual Meeting ACL 4th
Int. Joint Conf. Nat. Lang. Processing AFNLP, pp. 197200, Singapore.
Witten, I. H., & Frank, E. (2005). Data Mining: Practical Machine Learning Tools Techniques.
Morgan Kaufmann.
Wu, D. (2000). Alignment. Dale, R., Moisl, H., & Somers, H. (Eds.), Handbook Nat. Lang.
Processing, pp. 415458. Marcel Dekker.
Wubben, S., van den Bosch, A., Krahmer, E., & Marsi, E. (2009). Clustering matching headlines
automatic paraphrase acquisition. Proc. 12th European Workshop Nat. Lang.
Generation, pp. 122125, Athens, Greece.
186

fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS

Xu, F., Uszkoreit, H., & Li, H. (2007). seed-driven bottom-up machine learning framework
extracting relations various complexity. Proc. 45th Annual Meeting
Association Comp. Linguistics, pp. 584591, Prague, Czech Republic.
Yang, X., Su, J., & Tan, C. L. (2008). twin-candidate model learning-based anaphora resolution. Comp. Linguistics, 34(3), 327356.
Yarowski, D. (2000). Word-sense disambiguation. Dale, R., Moisl, H., & Somers, H. (Eds.),
Handbook Nat. Lang. Processing, pp. 629654. Marcel Dekker.
Zaenen, A., Karttunen, L., & Crouch, R. (2005). Local textual inference: defined circumscribed?. Proc. ACL workshop Empirical Modeling Semantic Equivalence
Entailment, pp. 3136, Ann Arbor, MI.
Zanzotto, F. M., & Dell Arciprete, L. (2009). Efficient kernels sentence pair classification.
Proc. Conf. EMNLP, pp. 91100, Singapore.
Zanzotto, F. M., Pennacchiotti, M., & Moschitti, A. (2009). machine-learning approach textual
entailment recognition. Nat. Lang. Engineering, 15(4), 551582.
Zhang, K., & Shasha, D. (1989). Simple fast algorithms editing distance trees
related problems. SIAM Journal Computing, 18(6), 12451262.
Zhang, Y., & Patrick, J. (2005). Paraphrase identification text canonicalization. Proc.
Australasian Language Technology Workshop, pp. 160166, Sydney, Australia.
Zhang, Y., & Yamamoto, K. (2005). Paraphrasing spoken Chinese using paraphrase corpus. Nat.
Lang. Engineering, 11(4), 417434.
Zhao, S., Lan, X., Liu, T., & Li, S. (2009). Application-driven statistical paraphrase generation.
Proc. 47th Annual Meeting ACL 4th Int. Joint Conf. Nat. Lang. Processing
AFNLP, pp. 834842, Singapore.
Zhao, S., Wang, H., Liu, T., & Li, S. (2008). Pivot approach extracting paraphrase patterns
bilingual corpora. Proc. 46th Annual Meeting ACL: HLT, pp. 780788, Columbus,
OH .
Zhitomirsky-Geffet, M., & Dagan, I. (2009). Bootstrapping distributional feature vector quality.
Computational Linguistics, 35, 435461.
Zhou, L., Lin, C.-Y., & Hovy, E. (2006a). Re-evaluating machine translation results paraphrase
support. Proc. Conf. EMNLP, pp. 7784.
Zhou, L., Lin, C.-Y., Munteanu, D. S., & Hovy, E. (2006b). PARA E VAL: Using paraphrases
evaluate summaries automatically. Proc. HLT Conf. NAACL, pp. 447454, New
York, NY.

187

fiJournal Artificial Intelligence Research 38 (2010) 49-84

Submitted 11/09; published 05/10

Change Abstract Argumentation Frameworks:
Adding Argument
Claudette Cayrol
Florence Dupin de Saint-Cyr
Marie-Christine Lagasquie-Schiex

ccayrol@irit.fr
bannay@irit.fr
lagasq@irit.fr

IRIT, Universite Paul Sabatier,
118 route de Narbonne, 31062 Toulouse, France

Abstract
paper, address problem change abstract argumentation system.
focus particular change: addition new argument interacts
previous arguments. study impact addition outcome argumentation system, particularly set extensions. Several properties
change operation defined comparing new set extensions initial one,
properties called structural comparisons based set-cardinality setinclusion relations. Several properties proposed comparisons based
status particular arguments: accepted arguments; properties refer
evolution status change, e.g., Monotony Priority Recency.
properties may less desirable according specific applications.
studied two particular semantics: grounded preferred semantics.

1. Introduction
Argumentation become influential approach handle Artificial Intelligence problems
including defeasible reasoning (see e.g., Pollock, 1992; Dung, 1995; Bondarenko, Dung,
Kowalski, & Toni, 1997; Chesnevar, Maguitman, & Loui, 2000; Prakken & Vreeswijk, 2002;
Amgoud & Cayrol, 2002; Nute, 2003), modeling agents interactions (see e.g., Amgoud,
Maudet, & Parsons, 2000; Kakas & Moratis, 2003). Argumentation basically concerned
exchange interacting arguments. set arguments may come either
dialogue several agents also available (and possibly contradictory)
pieces information disposal one unique agent. Usually, interaction
arguments takes form conflict, called attack. example, logical argument
pair hset assumptions, conclusioni, set assumptions entails
conclusion according logical inference schema. conflict occurs, instance,
conclusion argument contradicts assumption another argument.
main issue argumentation system selection acceptable sets arguments, called extensions, based way arguments interact (intuitively, acceptable
set arguments must sense coherent strong enough, e.g., able defend
attacking arguments). So, outcome argumentation system
often defined set extensions but, depending applications, may also
defined set arguments belongs every extension. convenient explore
concept extension argumentation frameworks, especially Dungs (1995)
c
2010
AI Access Foundation. rights reserved.

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

framework, abstracts arguments nature, represents interaction
form binary relation attack set arguments.
Recent works considered dynamics abstract argumentation frameworks
(Cayrol, Dupin de Saint-Cyr, & Lagasquie-Schiex, 2008; Rotstein, Moguillansky, Garca, &
Simari, 2008b; Boella, Kaci, & van der Torre, 2009a, 2009b). problem study
outcome changes set arguments and/or set attacks
changed. paper, focus case new argument interactions
added argumentation system. study impact addition
set initial extensions. leads us identify properties change operation
respect modification induces outcome. study two main
applications, first one concerns computational issues, second one concerns
definition dialogue strategies. one hand, interest computational processing
knowledge properties change may help deduce
modifications extensions. instance, useful know conditions
change modify previous extensions. hand, knowing impact
adding argument may help choosing good one order achieve given goal.
instance, multi-agent setting, i.e., several agents may present several arguments,
results presented paper help one agent determine arguments
present order outcome dialogue satisfies desired properties.
example, wants widen debate, argument must added induce
change producing larger extensions (i.e. contain arguments, see Section 3
Section 5).
paper organized follows. Section 2 recalls basic concepts argumentation.
Section 3 settles definition change argumentation. Many features taken
account order characterize change operation. first propose class properties
based impact change structure resulting set extensions (see
Section 3.2). second step, define several properties regarding arguments
themselves, particularly accepted change (see Section 3.3).
properties defined regardless semantics.
Then, focus particular change: addition new argument may
interact previously introduced arguments. Section 4 dedicated study
properties addition case two particular semantics, grounded
preferred semantics. give conditions given property satisfied. Section 5
discusses related approaches literature. proofs (and two important lemmas) given Appendix A. additional examples presented Appendix B
illustrating change operations.
Note paper generalizes previous work (Cayrol et al., 2008), argument
addition, called revision, restricted one argument one interaction
existing argumentation system. Here, added argument may interact
number previous arguments. Moreover, broader analysis generalized addition
provided considering new properties as, e.g., Monotony, establishing new
connections different properties.
50

fiChange Argumentation Systems

2. Basic Concepts Argumentation Frameworks
present work lies frame general theory abstract argumentation frameworks proposed Dung (1995). abstract framework assumes set arguments given, well different conflicts them, focuses definition
status arguments.
Definition 1 (Argumentation framework) argumentation framework hA, Ri
pair, non-empty set R binary relation A, called attack relation.
Let A, B A, (A, B) R equivalently ARB means attacks B, B attacked
A.
following, hA, Ri argumentation framework, assume set
arguments finite. First, easy extend concept attack sets arguments.
Definition 2 (Attack set) Let A.1
attacks iff X XRA.
attacks iff X ARX.
main issue argumentation system selection acceptable sets arguments. Intuitively, acceptable set arguments must sense coherent
strong enough (e.g., able defend every attacking argument). argumentation semantics defines properties required set arguments acceptable (this
collective acceptability). selected sets arguments given semantics
called extensions semantics. set extensions characterizes outcome
argumentation system. recall basic concepts used defining usual semantics:
Definition 3 (Conflict-free, defense) Let A.
conflict-free iff A, B ARB.
defends iff attacks argument attacks A. set arguments
defends denoted F(S). F called characteristic function hA, Ri.
literature proposes increasing variety semantics, refining Dungs traditional
ones (Baroni, Giacomin, & Guida, 2005; Caminada, 2006; Dung, Mancarella, & Toni, 2006;
Coste-Marquis, Devred, & Marquis, 2005). paper, well-known traditional semantics considered: grounded, preferred stable semantics.
Definition 4 (Acceptability semantics) Let E A.
E admissible iff E conflict-free defends elements (i.e. E F(E)).
E preferred extension iff E maximal (w.r.t. set-inclusion) admissible set.
1. paper, use denote strict inclusion denote classical inclusion.

51

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

E grounded extension iff E least fixed point (w.r.t. set-inclusion)
characteristic function F.
E stable extension iff E conflict-free attacks argument
belong E.
argumentation framework represented directed graph, called attack
graph, nodes arguments edges represent attack relation. Throughout
paper, examples using graph representation.
Example 1
= {A, B, C, D, F } R = {(A, B), (B, A), (B, C), (C, D), (D, F ), (F, C)}.
admissible sets {}, {A}, {B} {B, D}.
B
C

preferred extensions {A} {B, D}.

grounded extension {}.

F
{B, D} unique stable extension.
Using graph-based representation argumentation framework, extend
definition individual attack follows:
Definition 5 (indirect attack defense) Let G denote attack graph associated
hA, Ri. Let A, B A.
indirectly attacks B iff odd-length path B attack graph
G.
indirectly defends B iff even-length path (with non-zero length)
B attack graph G.
Note case attacks B considered particular case indirect attack.
Dung (1995) proved following results.
Proposition 1 Let hA, Ri argumentation framework.
1. least one preferred extension, always unique grounded extension,
may zero, one many stable extensions.
2. admissible set included preferred extension.
3. stable extension preferred extension, converse false.
4. grounded extension included preferred extension.
5. argument attacked belongs grounded extension (hence
preferred stable extension).
6. R finite, grounded extension computed iteratively applying
function F empty set.
52

fiChange Argumentation Systems

presence cycles attack graph often raised problems, namely
stable semantics, may happen extension exists. Note authors
consider attack graphs without odd-length cycles, arguing odd-length cycle
carries counterintuitive information. following results give properties preferred,
grounded stable extensions depending existence cycles attack graph.
Proposition 2 (Dunne & Bench-Capon, 2001, 2002) Let G denote attack graph associated hA, Ri.
1. G contains cycle, hA, Ri unique preferred extension, also
grounded extension unique stable extension.
2. {} unique preferred extension hA, Ri, G contains odd-length cycle.
3. hA, Ri stable extension, G contains odd-length cycle.
4. G contains odd-length cycle, preferred stable extensions coincide.
5. G contains even-length cycle, hA, Ri unique preferred extension.
acceptable sets arguments defined, possible define status
individual argument.
Definition 6 (Argument status) Let hA, Ri argumentation framework
A. Given semantics s:
skeptically accepted iff belongs extension hA, Ri s.
credulously accepted iff belongs least one extension hA, Ri
s.
rejected iff belong extension hA, Ri s.
Obviously, credulous skeptical acceptance coincide grounded semantics.

3. Change Argumentation
introduce formal definition change argumentation enables distinguish
four types change. define properties change argumentation. First,
consider impact change operation structure set extensions,
study structure modified. point view leads definition
structural properties. Then, consider impact change operation set
arguments accepted. Finally, connections classes properties
studied.
Note properties introduce, definition general
sense applied type change. Section 4 (where give conditions
satisfying properties), focus particular case addition
argument interactions.
53

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

3.1 Definition
section, give definition change argumentation. change may concern
set arguments and/or set attacks them. So, least four cases
encountered:
Definition 7 (Change operations) Let hA, Ri argumentation framework.
adding one interaction i0 two existing arguments (i0 = (X, )
X A) change operation defined by:
hA, Rii i0 = hA, R {i0 }i
removing one existing interaction i0 hA, Ri (i0 R) change operation
defined by:
hA, Rii i0 = hA, R \ {i0 }i
adding one argument Z 6 set interactions concerning Z denoted
Iz change operation defined by:


hA, Rii (Z, Iz ) = hA {Z}, R Iz
Here, Iz supposed non-empty set pairs arguments (either form
(X, Z) (Z, X) X A)2
removing one argument Z interacts arguments change
operation defined by:

hA, Rii Z = hA \ {Z}, R \ Iz
Here, Iz denotes set interactions concerning Z, set {(Z, X) |
(Z, X) R} {(X, Z)|(X, Z) R}3
Note case adding new argument (resp. removing existing argument)
interact argument trivial: added (resp.
removed from) extension. Indeed, change interesting concerned
argument interacts previous ones.
recent work dynamics argumentation (Boella et al., 2009a, 2009b),
four types change defined introduced different names, respectively attack refinement, attack abstraction, argument refinement argument abstraction. However, operations attack refinement, attack abstraction argument
abstraction studied restricted context (see Section 5 discussion).
following, identify argumentation framework hA, Ri associated
attack graph G. write X G instead X argument represented node G.
set extensions hA, Ri denoted E (with E1 , . . . , En denoting extensions).
2. Note that, definition, impossible (Z, Z) Iz .
3. Note Z removed, set interactions concerning Z must also removed.

54

fiChange Argumentation Systems

change operation produces new framework hA , R represented graph G ,
new set extensions E (with E1 , . . . , Ep denoting extensions).
explained above, changing argumentation framework may modify set extensions. Given semantics, modifications less important. depends
kinds interactions added removed precisely status
arguments involved interactions.
impact change studied two points view:
first one concerns structure set extensions address either
comparison number extensions change, or,
number remains unchanged, comparison contents extensions
change;
second point view concerns status particular arguments.
So, next sections, propose two classes general properties change
operation, one point view. proposed properties characterize relation
particular framework resulting framework change.
3.2 Structural Properties
Structural properties, presented section, based impact change
structure set extensions. Note property, definition general
sense type change operation specified: consist adding
one interaction, removing one interaction, adding argument set interactions
concerning argument, removing one argument. However, sake clarity,

property illustrated section examples change operation ;
reader find examples change operations Appendix B.
Let hA, Ri argumentation framework E set extensions hA, Ri
(under given semantics s). Various situations may encountered general case.
E may empty (implying stable semantics), may reduced singleton
{E1 } (where E1 may empty), may contain one extension {E1 , . . . , En }.
situation one non-empty extension convenient determination
status argument. contrast, several extensions exist, different choices
available. Table 1 summarizes various definitions presented below.
first consider decisive property change operation, meaning G
unique non-empty extension, case G.
Definition 8 (Decisive change) change G G decisive iff E = , E =
{{}}, E = {E1 , . . . , En }, n 2, E = {E }, E 6= {}.
Example 2
1. stable (resp. grounded preferred) semantics, change
Iz = {(Z, A)} decisive since:


B

Z

C

E = (resp. E = {{}}),
E = {{Z, B}}
55

ai Z



fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

Property change operation
change decisive
change restrictive
change questioning
change destructive
change expansive
change conservative
change altering

Characterization property
E = E = {{}} |E| > 2
|E | = 1 E 6= {{}}
|E| > |E | > 2
|E| < |E |
E 6= E 6= {{}}
E = E = {{}}
|E| = |E |

Ej E , Ei E, Ei Ej
E = E
|E| = |E |
Ei E s.t. Ej E , Ei 6 Ej

Table 1: Structural properties change operation
2. grounded semantics, change
since:
Z



B

C

B

Z

C

F



B

ai

Z Iz = {(Z, A)} decisive

ai

Z Iz = {(Z, A), (B, Z)}

E = {{A}, {B, D}},
E = {{Z, B, D}}

4. preferred semantics, change
decisive since:


Z Iz = {(Z, A)} decisive

E = {{}},
E = {{Z, B}}

3. preferred semantics, change
since:


ai

E = {{A}, {B}},
E = {{B}} (note Z rejected)

Z

weaker requirement decrease number choices. change G
strictly less extensions G, still least two, called restrictive4 . Note
restrictive property make sense grounded semantics, since
always unique grounded extension.
Definition 9 (Restrictive change) change G G restrictive iff E = {E1 ,
. . . , En }, n 2, E = {E1 , . . . , Ep }, n > p 2.
Example 3
1. preferred (or stable) semantics, change
restrictive since:


B

C

Z

F



ai

Z Iz = {(Z, A)}

E = {{A, C, F }, {A, D}, {B, D}, {B, F }},
E = {{Z, C, F }, {Z, B, D}, {Z, B, F }}

4. work Cayrol et al. (2008), kind change called selective.

56

fiChange Argumentation Systems

2. preferred semantics, change
restrictive since:


B

C

Z

ai

Z Iz = {(Z, A), (B, Z)}

E = {{A}, {B}, {C}},
E = {{B}, {C, Z}} (note Z skeptically
accepted)

opposite point view enables consider changes raise ambiguity, increasing number extensions. case instance G least one
non-empty extension G strictly extensions G. slightly different situation occurs G extension empty one, G one extension.
case, change brings information, decisive. changes called
questioning. restrictive property, questioning property make sense
grounded semantics.
Definition 10 (Questioning change) change G G questioning iff E =
{E1 , . . . , Ep }, p 2, either E = , E = {E1 , . . . , En } p > n 1.
Example 4
1. preferred (or stable) semantics, change
questioning since:


B



Z

C

F

B

Z

C



G

F

ai





B

C

Z Iz = {(Z, A)} questioning

E = ,
E = {{Z, B, F }, {Z, B, G}}

3. preferred semantics, change
(Z, B), (B, Z)} questioning since:
Z

Z Iz = {(Z, A)}

E = {{A, D, F }},
E = {{Z, B, C}, {Z, B, F }, {Z, D, C}, {Z, D, F }}

2. stable semantics, change
since:


ai

ai

Z Iz = {(Z, A), (A, Z),

E = {{A, D}, {B, D}},
E = {{A, D}, {B, D}, {Z}} (note Z skeptically accepted)

Pursuing along previous line, consider changes leading kind decisional
dead-end. case G least one non-empty extension G
extension, empty one5 . change called destructive.
Definition 11 (Destructive change) change G G destructive iff E =
{E1 , . . . , En }, n 1, Ei 6= {} E = E = {{}}.
Example 5
5. two different cases impact: possible decision
argument accepted.

57

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

1. stable semantics, change
since:


B



H

Z

C

G

F

ai

Z Iz = {(Z, A)} destructive

E = {{A, D, F }, {A, D, G}},
E =


2. preferred (or grounded) semantics, change Z Iz = {(Z, A),
(B, Z)} destructive since:
B



E = {{A}},
E = {{}}

Z



3. preferred semantics, change Z Iz = {(Z, A), (Z, B), (F, Z)}
destructive since:
B



C

Z

F



E = {{A}, {B, D}},
E = {{}}

far, considered changes impact number extensions. Now,
interested changes may modify content extensions, without modifying
number extensions. interesting situation occurs extension G
strictly includes one extension G, number extensions same. changes
called expansive.
Definition 12 (Expansive change) change G G expansive iff G G
number extensions extension G strictly includes extension
G.
Example 6 preferred (or stable) semantics, change
{(B, Z)} expansive since:


B

C

Z



ai

Z Iz =

E = {{A, C}, {A, D}},
E = {{Z, A, C}, {Z, A, D}}

particular case set extensions remains unchanged, change called
conservative.
Definition 13 (Conservative change) change G G conservative iff G
G exactly extensions, E = E .
Example 7
1. preferred semantics, change
vative since:


B

C

Z

B

Z

Z Iz = {(B, Z)} conser-

ai

Z Iz = {(A, Z)} conser-

E = {{}},
E = {{}}

2. preferred semantics, change
vative since:


ai

C

E = {{A, C}},
E = {{A, C}}

58

fiChange Argumentation Systems

3. preferred semantics, change
vative since:


B

C

Z



ai

Z Iz = {(A, Z)} conser-

E = {{A, C}, {A, D}},
E = {{A, C}, {A, D}}

Otherwise, may happen G G number extensions
extensions (and sometimes them) altered. called altering change.
Definition 14 (Altering change) change G G altering iff G G
number extensions exists least one extension Ei G Ej
extension G , Ei * Ej .
case instance extension G non-empty intersection
(but include) extension G.
Example 8
1. grounded semantics, change
since:


B

Z

C



B

C

Z Iz = {(Z, A)} altering

ai

Z Iz = {(Z, E), (F, Z)}

E = {{A, D},
E = {{Z, B, D}}

2. preferred semantics, change
altering since:


ai



E

F

Z

E = {{A, C, E}},
E = {{A, C}} (note Z rejected)

discussion summarized Table 2. table, checked
cells #i correspond situations cannot occur:
#1 #2 acceptability semantics argumentation framework may
extension stable semantics. However, stable semantics,
argumentation framework cannot empty extension set arguments
empty. And, assumption, cases #1 #2 correspond argumentation
frameworks non-empty sets arguments (because assumption either Iz 6=
exists one interaction = (X, ), least one X G X
eventually Z belong G ). cases occur change operation
acceptability semantics considered paper.
Note structural properties presented Table 2 mutually exclusive (that
change operation cannot satisfy two them).
59

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

E =



E=

{{}}

{{}}

conservative
#2

#1
conservative

{E1 }

{E1 , . . . , Ep }
p2

decisive

questioning

conservative
expansive
altering

{E1 }

destructive
{E1 , . . . , En }
n2

decisive

questioning
n < p:
questioning
n > p:
restrictive
n = p:
conservative
expansive
altering

Ei 6= {} Ei 6= {}. cell table contains name corresponding
property change operation.

Table 2: Structural properties change operation
3.3 Status-Based Properties
section, interested impact change operation status
particular arguments.
First, interested status arguments accepted
change. leads propose property called Monotony, defined
type change.
Another interesting issue concerns status argument added

change. Obviously, concerns change operation ; leads propose
property called Priority Recency makes sense one type change.
3.3.1 Monotony
Inspired done field non-monotonic inference, define property
monotony expressing arguments accepted change remain accepted
change. Since aim define general properties, make assumption
number extensions, consider different cases acceptance argument
(credulously skeptically accepted).
monotony definition straightforward semantics providing one extension
(such grounded semantics, instance). Following Definition 6, argument
accepted (credulously skeptically) hA, Ri iff belongs (unique) extension
G. So, particular case, monotony means extension G included
extension G . several extensions, monotony take different forms.
credulous form corresponds case argument credulously accepted G
60

fiChange Argumentation Systems

also credulously accepted G . skeptical form corresponds case
argument skeptically accepted G also skeptically accepted G . ideas
lead following definition:
Definition 15 (Monotony)
change G G satisfies Monotony iff extension G included
least one extension G .
change G G satisfies Credulous Monotony6 iff union extensions
G included union extensions G .
change G G satisfies Skeptical Monotony iff intersection extensions G included intersection extensions G .


change operation , Examples 2.1, 2.2, 4.3, 6, 7 illustrate case

property Monotony holds; and, change operation , Examples 2.3, 2.4,
3.1, 3.2, 4.1, 4.2, 5, 8.1, 8.2 illustrate case property Monotony
hold7 .
Obviously, Monotony implies Credulous Monotony. However, Monotony imply
Skeptical Monotony (see Example 4. 3) Skeptical Monotony imply Monotony
(see Examples 2.3, 2.4, 3.1, 3.2). semantics providing one extension, three
notions Monotony coincide.
Monotony property defined level extensions. similar notion
defined level arguments:
Definition 16 (Partial Monotony argument) Let X argument.
change G G satisfies Partial Monotony X iff X belongs extension
G, also belongs least one extension G .
easy prove Monotony (resp. Credulous Monotony) implies Partial Monotony
argument G. case property Skeptical Monotony (see
argument Example 2.4).
3.3.2 Priority Recency
next property concerns status argument added change. Inspired done field belief revision (see Alchourron, Gardenfors, &
Makinson, 1985), postulate concerning priority new piece information,
define property expressing new argument accepted change.

property called Priority Recency8 makes sense change operation .
6. Credulous Monotony related well-known decision problem credulous acceptance argumentation (see Definition 6).
7. Appendix B, reader find examples illustrating property Monotony
change operations.
8. property characteristic postulate AGMs sense; inspired Success
postulate proposed Alchourron et al. (1985).

61

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex



Definition 17 (Priority Recency) change G G satisfies Priority
Recency iff G least one extension added argument Z belongs extension
G .
Examples 2.1 2.3, 3.1, 4.1, 4.2, 6, 8.1 examples change satisfying Priority
Recency. Examples 2.4, 3.2, 4.3, 5, 7, 8.2 examples change satisfy Priority
Recency.
3.4 Connections Properties
links structural properties status-based properties established.
following propositions enumerate results hold type change.
Proposition 3
conservative change always satisfies Monotony Skeptical Monotony.
expansive change always satisfies Monotony Skeptical Monotony.
decisive change satisfies Monotony also satisfies Skeptical Monotony.
particular case semantics providing one extension, change satisfies
Monotony (and Skeptical Monotony) iff either decisive, expansive, conservative.
Proposition 4
destructive change never satisfies Monotony.
altering change never satisfies Monotony.
restrictive change never satisfies Monotony.


Moreover, particular case change , connections structural
properties Priority Recency established.
Proposition 5
conservative change
destructive change

ai

ai

never satisfies Priority Recency.

never satisfies Priority Recency.

particular case grounded, stable preferred semantics, have:
Proposition 6 grounded, stable preferred semantics, expansive change
ai always satisfies Priority Recency.
results examples given Sections 3.2 3.3, inclusion links

different changes type synthesized Figure 19 . Table 3 gives
references examples propositions used identifying links.
9. inclusion Expansive changes operations satisfy Priority Recency
shown Figure 1, checked stable, grounded preferred semantics see Proposition 6
(hence, may hold semantics).

62

fiChange Argumentation Systems

Monotony
Destructive
Conservative

Questioning
Expansive
Decisive

Priority recency
Restrictive

Altering

Figure 1: Inclusion links changes type

conservative
decisive
destructive
expansive
altering
questioning
restrictive

Priority Recency
Never satisfied (Conseq. 5)
May hold (Ex. 2.1 2.3)
(Ex. 2.4)
Never satisfied (Conseq. 5)
Hold stable, grounded, preferred sem. (Prop. 6)
May hold (Ex. 8.1)
(Ex. 8.2)
May hold (Ex. 4.1)
(Ex. 4.3)
May hold (Ex. 3.1)
(Ex. 3.2)

ai

Monotony
Always satisfied(Conseq. 3)
May hold (Ex. 2.1)
(Ex. 2.3)
Never satisfied (Conseq. 4)
Always (Conseq. 3)
Never (Conseq. 4)
May hold (Ex. 4.3)
(Ex. 4.1)
Never (Conseq. 4)



Table 3: Synthesis connections structural status-based properties

63

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

4. Characterizing Argument Addition Grounded Preferred
Semantics


section, focus change , i.e., addition exactly one argument Z
interacts least one argument belonging A. Indeed, adding argument
may interact existing ones frequently encountered type change
real-life situations. Besides, type change sufficiently complex provide rich
analysis properties results.

Moreover, consider change grounded preferred semantics.
chosen two semantics well-known traditional
semantics existence extensions guaranteed.
purpose identify conditions given property satisfied

change operation . conditions concern added argument associated
interactions, may depend semantics.
Arguably, properties seem desirable others according context.
instance, decisive change operation reduce ignorance, since change one
one extension remains, enabling determine status argument (which
always case change). expansive change raise number
accepted arguments, interesting achieving goal persuasion instance.
conservative change keeps extensions unchanged, interesting want add
argument without changing state knowledge. properties Monotony
Priority Recency desirable focus particular arguments,
want get resulting extensions.
constrast, questioning destructive operation increase ignorance, seems
less interesting.
altering operation enforces new look problem, since nothing
kept state change (the number extension remains
different previous ones). According discussion, provide:
sufficient conditions (CS) interesting properties hold (e.g., decisive,
expansive, conservative, monotonic, satisfying Priority Recency);
necessary conditions (CN) undesirable properties (e.g., questioning, destructive, altering), order avoid properties.
following subsections, consider change
ment Z interactions Iz , that:

ai addition argu-



hA, Rii (Z, Iz ) = hA {Z}, R Iz
4.1 Argument Addition Grounded Semantics
grounded semantics, E = {E} E = {E }.
following result gives condition given accepted argument X remains

accepted change (hence Partial Monotony holds X).
Proposition 7 grounded semantics, X belongs E, Z indirectly

attack X, satisfies Partial Monotony X (i.e. X belongs E ).
64

fiChange Argumentation Systems

Example 9 grounded semantics:
C

B

Z

E = {{A, B}}, E = {{Z, B}}
Z indirectly attack B B E, B E



ai

following result gives condition change
Recency.

satisfies Priority

Proposition 8 grounded semantics, Z attacked G,
Priority Recency (i.e. Z belongs E ).

ai satisfies

Example 10 grounded semantics:


B

Z



C

E = {{A, C}}, E = {{Z}}

Let us first study particular case E = {}.
Proposition 9 grounded semantics,
E = {} following equivalence holds: E = {} iff Z attacked G;

moreover, E = {} Z attacked G, E = {Z} i1 F ({Z}).
So, case E = {}, have:

ai conservative).

Either Z attacked G E = {} (and change

Z attacked G E contains Z arguments

indirectly defended Z (and change decisive).
consequence Proposition 9, have:
Corollary 1 grounded semantics,
E = {} Z attacked G, change
change

ai

ai

decisive;

decisive, Z attacked G hence Z attacks G.

Example 11 grounded semantics, following change


B



C

Z

ai

decisive:

E = {{}}, E = {{Z, A, D}}

Now, study particular case E =
6 {}.
following result gives condition change

ai satisfies Monotony.

Proposition 10 grounded semantics, E =
6 {} Z attack E,
ai satisfies Monotony (i.e. E E ).
precisely, two conditions (one conservative change

another one expansive change ):
65

ai



fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

Proposition 11 grounded semantics, E =
6 {} Z attack E,
have:
E defend Z, E = E. (The change

ai

conservative).


E defends Z, E = E {Z} i1 F ({Z}). Moreover, case, Z

attack G, E reduces E {Z}. (The change expansive).
Example 12 grounded semantics, following change


B

ai

expansive:

C

E = {{A}}, E = {{Z, A, D}}
Z

F



consequence Proposition 11, another condition change

ai satisfies Priority Recency:

Corollary 2 grounded semantics, E =
6 {}, Z attack E, E defends

Z, satisfies Priority Recency (i.e. Z belongs E ).
Example 13 grounded semantics:


B

C

E = {{A}}, E = {{Z, A}}
Z

F



Note Corollary 2 hold E defend Z.
Example 14 grounded semantics:


B

C

Z

F



E = E = {A}.
So, E = E = {{A}}.

Another interesting point fact properties change
satisfied grounded semantics:
Proposition 12 grounded semantics, change
restrictive.

ai

ai cannot

never questioning,



case destructive change also interesting sufficient add
attack unattacked argument obtaining change:
Proposition 13 grounded semantics, E =
6 {}, Z attacks unattacked

argument Ai G Z attacked G change destructive; converse
also holds.
66

fiChange Argumentation Systems

4.2 Argument Addition Preferred Semantics
preferred semantics, always least one extension. E may reduced
singleton {E1 } (where E1 may empty), may contain one extension
{E1 , . . . , En }. Similarly, E may reduced singleton {E1 } (where E1 may empty),
may contain one extension {E1 , . . . , En }.

following result gives condition change satisfies Priority
Recency.


Proposition 14 preferred semantics, Z attacked G, satisfies
Priority Recency (i.e. Z belongs Ei ).
Example 15


B

Z

C



B

preferred semantics:
E = {{A, C}, {B}},
E = {{Z, B}, {Z, C}}
C

Z

E = {{A, C}, {B}},
E = {{Z, A, C}}

following proposition establishes admissible sets G kept cases

(so, cases change neither altering, restrictive):
Proposition 15 preferred semantics,
Z attack Ei , Ei remains admissible G ;
Z attack Ei Ei defends Z, Ei {Z} admissible G .
Example 16 preferred semantics:
Z



B

C

E = {{}},
{}{Z} admissible G E = {{Z, B}}.

Example 12 (continued) preferred semantics, E = {{A}}, {A} {Z}
admissible G , nevertheless, E = {{Z, A, D}}.
Note preferred extensions may appear G .
Example 17 preferred semantics:


B

C

E = {{A}},
E = {{Z, A}, {Z, C}}

Z

consequence Proposition 15, another condition change

ai satisfies Priority Recency.

Corollary 3 preferred semantics, Z attacks extension G, Ei

defends Z, satisfies Priority Recency (i.e. Z belongs Ei ).
67

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

Example 18 preferred semantics:


B

C

F

Z



E = {{A, C}, {A, D}},
E = {{Z, A, C}, {Z, A, D}}

following result gives condition change

ai decisive.

Proposition 16 preferred semantics, E = {{}} Z attacked G

even-length cycle G E = {E } Z belongs E (so,
decisive).
Example 11 (continued) preferred semantics, E = {{}}, E = {{Z, A, D}}
Note that, even-length cycles exist graph, change
extensions; change would questioning one:


B



Z

C

F

ai

may induce several

E = {{}},
E = {{Z, A, D}, {Z, A, F }}

reason, considered graphs without even-length cycle Proposition 16.

following result gives necessary condition decisive change (and
also condition conservative change).
Proposition 17 preferred semantics, Z attacks argument G E =

{{}}, E = {{}}; equivalently, E = {{}} change Z decisive
Z attacks G.
following result relates case exists non empty extension G

also gives conditions either conservative change, expansive
one.
Proposition 18 preferred semantics, Z attacks argument G, E 6=
{{}}, i:
Ei defends Z, Ei {Z} extension G ;
Ei defend Z, Ei extension G ;
moreover, G G number extensions.
Example 6 (continued) preferred semantics, change
= {{A, C}, {A, D}} E = {{Z, A, C}, {Z, A, D}}

ai

expansive: E

consequence previous results, condition change

ai satisfies Monotony.

Proposition 19 preferred semantics, Z attacks extension G

change satisfies Monotony.
68

fiChange Argumentation Systems

particular case non controversial argumentation framework, obtain cona
dition change satisfies Skeptical Monotony. notion controversial
argument introduced Dung, proved argumentation framework
without controversial argument nice properties. Roughly speaking, argument X
controversial indirectly attacks indirectly defends argument .
Proposition 20 preferred semantics, assume G contains controversial

argument. Z attack i1 Ei , change satisfies Skeptical Monotony,
i1 Ei i1 Ei .
grounded semantics, exists proposition destructive change

ai :

Proposition 21 preferred semantics, E 6= {{}}, even-length
cycle G , unattacked argument Ai G attacked G Z attacked G

change destructive.
4.3 Synthesis Results
Tables 4 5, display summary necessary (CN) sufficient (CS) conditions

property hold change (in cases, several CS resp. CN may given
denoted CS, CS , . . . resp. CN, CN , . . .).
tables, E, E , E, E , Ei , Ej denote respectively set extensions change,
change, grounded extension change, change, preferred extension
change change.

Table 4 concerns structural properties change .

Table 5 concerns status-based properties change .
tables underline fact able identify sufficient conditions
(CS) interesting properties hold (e.g., decisive, expansive, conservative,
monotonic, satisfying Priority Recency). properties changes less
desirable questioning, destructive, altering, focused search necessary
conditions (CN), allowing us enunciate sufficient conditions order avoid them.

5. Discussion Future Works
paper, study change argumentation. propose properties characterize
impact change operation outcome argumentation framework. Then,
focus particular type change: addition new argument may interact
previously introduced arguments10 . establish conditions given
property satisfied.
study change important issue Artificial Intelligence, traditionally
concerns belief change. agent receives new piece information, must
adapt beliefs; adaptation always easy may imply drop
previous knowledge. seminal work Alchourron, Gardenfors Makinson (AGM)
(1985) settled formal framework reasoning belief change introduced
10. consider knowledge arguments interactions could built.

69

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

Properties change

ai

Grounded semantics

Preferred semantics

Decisive
(E = E = {{}} |E| > 2)
|E | = 1 E 6= {{}}

CS CN: E = {} Z
attacked. (Prop.9)

CS: E = {{}} Z attacked even-length cycle G. (Prop.16)
E = {{}} CN: Z attacks G.
(Prop.17)

Restrictive
|E| > |E | > 2

Never (Prop.12)

CN: even-length cycle
G Z attacks least one Ei
(Prop.15)

Questioning
|E| < |E |

Never (Prop.12)

CN: even-length cycle
G Z attacks G (Prop.17,
Prop.18)

CN CS: E =
6 {} Z attacks unattacked argt
G Z attacked (Prop.13)

CS: E 6= {{}} Z attacked even-length cycle G Z attacks
unattacked argt G (Prop.21)
CN: E 6= {{}} Z attacked odd-length cycle G Z attacks
unattacked argt G (Prop.1.5,
Prop.2.2)

CS: E =
6 {} Z
attack E E defends Z
(Prop.11)

CS: E 6= {{}} Z
attack G i, Ei defends Z
(Prop.18)

CS: E = {} Z attacked
G (Prop.9)
CS : E =
6 {} Z
attack E E defend
Z (Prop.11)

CS: E = {{}} Z
attack G (Prop.17)
CS : E 6= {{}} Z
attack G i, Ei defend Z (Prop.18)

CN: E =
6 {} Z attacks E
(Prop.10)

CN: E 6= {{}} Ei s.t. Z
attacks Ei (Prop.15)

Destructive
E 6= E 6= {{}} (E =
E = {{}})

Expansive
|E| = |E | Ej E , Ei
E, s.t. Ei Ej
Conservative
E = E

Altering
|E| = |E | Ei E s.t. Ej
E , Ei 6 Ej

Table 4: Synthesis necessary sufficient conditions (CN CS) structural

properties Case

70

fiChange Argumentation Systems


Properties change
Monotony
Ei E, Ej E , s.t. Ei Ej

Grounded Semantics

Preferred Semantics

CS: E = {}

CS: Z attack Ei
(Prop.19)

CS : E =
6 {} Z
attack E (Prop.10)
Priority Recency
|E | 1 Ej E , Z Ej

Partial Monotony X
Ei E s.t. X Ei ,
Ej E s.t. X Ej
Skeptical Monotony
i1 Ei j1 Ej

CS: Z attacked (Prop.8)
CS : E =
6 {}, Z attack
E E defends Z (Prop.11)

CS: Z attacked (Prop.14),
CS : Ei E, Z
attack Ei Ei defends Z
(Corol.3)

CS: X E Z indirectly attack X (Prop.7)

cf. Monotony (because, X,
Partial Monotony X implied Monotony)

cf. Monotony (because,
grounded semantics, Skeptical
Monotony Monotony)

CS: controversial argt G
Z attack i1 Ei
(Prop.20)

Table 5: Synthesis necessary sufficient conditions (CN CS) status-based

properties Case

concept belief revision together two types belief change, namely
contraction expansion. Expansion consists adding information without
checking consistency previous beliefs. Contraction operation designed
removing information. Revision consists adding information preserving consistency.
last operation interesting one since, belief theory, inconsistency leads
unexploitable information.
Although change operations defined Section 3 could thought related
AGM theory11 , comparison appropriate two main reasons:
basic underlying formalism different: standard belief revision, logical formulae used knowledge representation whereas, paper, argumentation
framework represents current knowledge. first case, outcome new
set logical formulae, whereas, second case, outcome new argumentation framework induces new set extensions, extension set
arguments.
Revision task knowledge representation strongly related concepts
inference consistency. postulates standard belief revision (AGM)
built consistency notion, since revision aims incorporating new piece
11. Note important cognitive tasks linked belief change theory already studied
field argumentation, see instance work merging Coste-Marquis, Devred, Konieczny,
Lagasquie-Schiex, Marquis (2007).

71

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

information preserving consistency. However, framework argumentation, notion consistency clear standard accepted meaning (even
authors propose take account kind degree inconsistency
argumentation context works Matt & Toni, 2008; Besnard & Hunter,
2008).
Moreover, revision also studied framework non-monotonic theories (Witteveen & van der Hoek, 1997) argumentation theory linked nonmonotony, postulates non-monotonic theories also based consistency
inference notions explicitly present abstract argumentation
system. So, postulates suited problem. belief revision postulates restated (this case property called Priority
Recency inspired AGM Success postulate ), principles must proposed (for instance, identified property called Monotony
checks kind preservation existing extensions change process).
work extension previous work (Cayrol et al., 2008) presented
preliminary step towards formal characterization notion change argumentation
frameworks. work Cayrol et al. (2008), change defined addition
one argument one interaction studied structural properties
Priority Recency (called classicity Cayrol et al., 2008). new version
work, proposed current paper, taking account addition
several interactions (so properties given Cayrol et al., 2008 hold here)
defining new properties around notion Monotony. also look
connections proposed properties conditions (necessary
sufficient) obtaining avoiding properties.
many approaches deal adding new pieces information
within argumentation system. point view adopted family works
different status new piece information added.
instance, Wassermann (1999), well Falappa, Garca, Simari (2004) Paglieri
Castelfranchi (2005), define conditions, expressed terms arguments,
unjustified beliefs become accepted. Pollock Gilliess (2000) approach studies
properties knowledge revision argumentation point view, i.e., problem
generate knowledge base piece information justified good
arguments. kind problem studied Amgoud Vesic (2009) context
argument-based decision. Argument-based decision takes input set options, set
arguments defeat relation among them, returns status option together
total preorder set options. authors study conditions
option may change status new argument received conditions
new argument useless.
Recently, Rotstein, Moguillansky, Falappa, Garca, Simari (2008a) proposed
warrant-prioritized revision operation, consists adding argument theory
way argument warranted afterwards. Even underlying ideas
similar, work differs approach least two points:
First, work Rotstein et al. (2008a), arguments given structure
sub-argument relation, properties minimality, consistency atom72

fiChange Argumentation Systems

icity. definition warranted arguments relies upon evaluation argumentation lines. contrast, approach remains abstract level,
sets accepted arguments computed well-known extension-based
semantics.
Secondly, warrant-prioritized argument revision designed order satisfy
AGM Postulate, corresponding property Priority recency, since
added argument must warranted revised theory. work follows another
direction. propose extensive theoretical study impact addition
outcome abstract argumentation framework, enables us define
several properties change operation.
Concerning general question handling dynamics argumentation, proposal related recent works Boella et al. (2009a, 2009b), Rotstein et al.
(2008b):
work Boella et al. (2009a, 2009b) studies extensions argumentation system remain unchanged set arguments attacks
changed.
four types change proposed Definition 7 introduced
different names, respectively attack refinement, attack abstraction, argument refinement argument abstraction. However, operations attack refinement,
attack abstraction argument abstraction studied,
restrictive point view:
Boella et al. (2009a, 2009b) consider case semantics provides
exactly one extension.
principles defined correspond conditions change
conservative, terminology. property considered.
focus addition argument interactions, work Boella
et al. (2009a, 2009b) viewed complementary work.
Rotstein et al. (2008b) introduce notion dynamics considering arguments
built evidence. Evidence used determine whether argument active (i.e.
used draw inferences) inactive. question addressed Rotstein et al.
(2008b) is: variation set evidence affects nature arguments
(active not)?. question cannot handled pure abstract level
concerns internal dynamics. contrast, remain abstract level:
interested impact change abstract framework outcome
framework.
promising application work could design dialogue strategies. Indeed,
dialogue may defined exchange (called move) arguments two more,
human artificial, agents given protocol. protocol program defines
set allowed moves step dialogue. agent aim
73

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

may develop strategy. works dialogue strategies consider
strategy selects exactly one move (the move must done next). instance,
Bench-Capon (1998) proposes selection strategy (for agents) leading cooperative
dialogues. approaches study strategies context persuasion dialogues,
two agents argue order persuade given initial argument true (or
false according agent opinion). case, strategy helps choose argument must defeated order initial argument accepted (or rejected).
Amgoud Maudet (2002) proposed heuristics select less attackable arguments persuasion dialogue. similar way, Riveret, Prakken, Rotolo, Sartor
(2008) proposed optimal strategy order win debate based probability
success argument cost argument agent. Hunter (2004),
global approach, defined strategy builds optimal subtree
arguments maximizing resonance agent goals minimizing cost.
approach takes another point view. define protocol
restrict dialogue type. Given set arguments may interact, interested
outcome argumentation system, set extensions given
semantics. words, study impact addition argument respect
two points view: first, structural modification induced set extensions,
second, impact acceptability arguments. Although concern acceptability
evolution looks similar aim existing dialogue approaches presented above,
proposal general, since work, interested finding strategies
order make accepted precise argument rather interested establishing
general conditions preservation acceptability. instance, grounded
preferred semantics, provide sufficient condition maintaining argument
accepted arrival new one (Monotony property) sufficient condition
new argument accepted (Priority Recency).
structural point view analysis completely original respect
existing literature. Indeed, analyze impact new argument set extensions
amounts consider addition argument operation performed order
modify form change outcome (by expansive change, decisive
change instance). work reported paper enables us choose right way
changing (which argument must affected change, kind interaction)
order obtain new outcome. plan focus strategies
directing dialogue (i.e., integrated protocol) strategies taking part
(i.e., concerning agent). instance, dialogue arbitrator wants debate
open rather force next speaker use arguments appropriate
expansive change. wants debate focused arguments
appropriate restrictive (and even decisive) change accepted.
several directions research:

1. plan study change operations defined paper, corresponding
removal one argument interactions addition removal
interaction (for instance, exploiting properties symmetry
change operations).
74

fiChange Argumentation Systems

2. would like generalize change operations case addition
removal subgraph arguments (which would kind iterated change).
3. think decisive property desirable property change operation.
So, intend investigate question make minimal change12
given argumentation framework unique non-empty extension?.

Acknowledgments
would like thank reviewers help interesting suggestions.

Appendix A. Proofs
Lemma 1
X G s.t. (Z, X) Iz , change operation

ai

introduces new cycle G .

X G s.t. (X, Z) Iz , change operation

ai

introduces new cycle G .

words, Z attack argument G, Z attacked G,

change operation introduces new cycle G .
Proof Lemma 1: follows directly fact one argument added.



Proofs Related Section 3.4 (Connections Properties)
Proof Proposition 3: follows directly definitions properties (Definitions 8,
12, 13, 15).

Proof Proposition 4: follows directly definitions properties (Definitions 11,
9, 14, 15).

Proof Proposition 5: follows directly definitions properties (Definitions 11,
13, 17).

Proof Proposition 6:
Grounded semantics: Let us show E ( E Z E . Assume E ( E
Z 6 E . going prove E E (which contradiction assumption
E ( E ), proving F ({}) F ({}), induction 1.
Basic case (i = 1): Z 6 E Z attacked G. Thus, X F ({}) X
G definition X unattacked G . X also unattacked G. So,
F ({}) F({}).
Induction hypothesis (for 1 p, F ({}) F ({})):
12. terms number edges add remove and/or terms number arguments add
remove.

75

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

Let us first show subset arguments G F (S) G,
F (S) F(S): Let X F (S), means defends X G X G.
exists G attacks X G, also attacks X G .
defends X G , attacks . also defends X G. F (S) F(S).
Let us compute F p+1 ({}) = F (F p ({})). induction hypothesis, F p ({})
F p ({}). F monotonic, F p+1 ({}) F (F p ({})). let denote
set F p ({}), E G. assumed E ( E Z 6 E
E G. Then, F monotonic, F (S) F (E ) = E G
Due previous point, conclude F (S) F(S). Then, obtain
F p+1 ({}) F(F p ({})) = F p+1 ({}).
Preferred semantics: Given expansive change G Z Iz , let us suppose
exists extension Ej G contain Z. extension included G.
change expansive, exists extension Ei G strictly included Ej . Ei
maximal admissible set inclusion. Since inclusion Ei inside Ej strict, therefore
Ej admissible G. Ej extension G , conflict, hence Ej
defend elements G. exists X Ej attacked G (and thus G )
defended Ej G. means Ej attack . But, since Ej
included G attack G . edge element Ej
G, neither edge G . (Note attacked Z Z Ej )
Stable semantics: Assume exists extension Ej G contain Z.
change expansive, exists extension Ei G strictly included Ej . Since
inclusion strict, exists Ej , belong Ei . assumed
Ej contain Z, G. Ei stable extension G, Ei attacks . Then,
Ei included Ej conflict Ej , contradicts fact Ej stable
extension.


Proofs Related Section 4.1 (Under Grounded Semantics)
Proof Proposition 7: E grounded extension G. Due fact R finite,
E = i1 F ({}). prove induction 1 X belongs F ({}) Z
indirectly attack X, X belongs F ({}).
Basic case (i = 1): X F({}) X attacked G. Since Z attack X,
X remains unattacked G belongs F ({}).
Induction hypothesis (for 1 p, proposition holds): Let X F p+1 ({}).
prove X F p+1 ({})(= F (F p ({}))). Assume X attacked G . Z
attack X, G. X F p+1 ({}) = F(F p ({})), F p ({}) defends X attacking
. exists W F p ({}) attacks , turn attacks X. Z
indirectly attack X, sure Z indirectly attack W . Using induction
hypothesis W , W F p ({}). So, proved F p ({}) defends X G
X F p+1 ({}).

Proof Proposition 8: Z attacked G, Z attacked G . So, due
Proposition 1.5, grounded extension G contains Z.

Proof Proposition 9:
76

fiChange Argumentation Systems

E = {} argument G attacked. Z attacked G, argument
G attacked due Proposition 1.5 Proposition 1.6, E = {}. Z attacked
G, Z attacked G , Z belongs E , empty.
E = {} Z attacked G, Z E . F monotonic,
E fixed point




F , F ({Z}) E 1, {Z} i1 F ({Z}) E . Let

denote {Z} i1 F ({Z}). Now, prove E S. E least fixed


point F , sufficient
proveithat fixed point F . Obviously, F (S) = {X

G s.t. X attacked} i1 F ({Z}). Since E = {}, {X G s.t. X attacked } =

{Z}, F (S) = fixed point F . proved E = {Z} i1 F ({Z}).

Proof Corollary 1:
follows directly Proposition 9. Due Definition 8, grounded semantics,
change decisive E = {} E 6= {}.
Z interacts G, Z attacked G, Z must attack G.

Proof Proposition 10: Due fact R finite, E = i1 F ({}) E =
i1 F ({}). prove induction 1 F ({}) F ({}).
Basic case (i = 1): F({}) attacked G due fact Z
attack E, attacked G F ({}).
Induction hypothesis (for 1 p, F ({}) F ({})): let = F p ({}) = F p ({}).
First, prove F(S) F (S). Let F(S). Obviously, F(S) E. E
Z attack since Z attack E. So, attacked G
attacked G. F(S), defends attacking A. defends G ,
F (S).
Using induction hypothesis, . Moreover, definition F monotonic.
F(S) = F p+1 ({}) F (S) F (S ) = F p+1 ({}). So, E E .

Proof Proposition 11: E =
6 {} Z attack E. Let us first notice (1)
F (E) G, F(E) = E. Indeed, F (E) means E defends G . So,
G, E also defends G, i.e., F(E) = E.
Due Proposition 10, E E . So, prove E defend
Z, E E. Indeed, prove F (E) = E. Then, definition E (least fixed
point), follow E E. Let F (E), E defend Z, hence G,
according (1), F(E) = E. Conversely, let E = F(E), let argument
attacks G . Z attack E, 6= Z, G, E defends attacking
A. So, E defends G F (E).
First, prove E defends Z F (E) = E {Z}. Due (1), F (E) G,
F(E) = E. Now, E defends Z, also Z F (E). So, F (E) E {Z}.
Conversely, let F(E) = E. E defends G. Z attack E, Z attack
, E also defends G , F (E). Z F (E), E {Z} F (E).
particular case Z attack G, Z cannot defend argument. So, F (E
{Z}) = F (E) F (E {Z}) = E {Z}. means E {Z} fixed point
77

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

F , definition E , E E {Z}. Due Proposition 10, E E .
So, also E {Z} E . Finally, E reduces E {Z}.

general case, Z attacks G. Let denote E {Z} i1 F ({Z}). prove

E = S. Obviously, E since E {Z} = F (E) E , E contains i1 F (E ),

hence contains i1 F ({Z}), since F monotonic. Conversely, prove
fixed point F definition E (least fixed point), follow E S.
Since F monotonic, F (E) F (S), F ({Z}) F (S) 2
F ({Z}) F (S). So, F (E) = E {Z}, F (S). Conversely, let F (S)
assume
/ E {Z} = F (E). Then, exists
attacker
attacked E. F (S), must attack A. {Z} i1 F ({Z}) attacks A,

means i1 F ({Z}). So, proved F (S), either E {Z}

i1 F ({Z}), S.

Proof Corollary 2: direct consequence Proposition 11.



Proof Proposition 12: direct consequence definitions: restrictive questioning changes need number extensions strictly greater one, exists one
grounded extension.

Proof Proposition 13: E =
6 {}, unattacked arguments denoted Ai G. Ai ,

Ai attacked G Z attacked G . unattacked argument G , 1
F ({}) = {} E = {}. change destructive.
Conversely, change destructive, definition E =
6 {} E = {}. Then, due

Proposition 1.5, unattacked argument G . So, Z attacked Ai (unattacked
argument G) also attacked G .


Proofs Related Section 4.2 (Under Preferred Semantics)
Proof Proposition 14: Z attacked G, Z attacked G . So, due
Proposition 1, preferred extension G contains Z.

Proof Proposition 15:
Ei conflict-free G, also G . Let Ei attacked G . Z attack
Ei , attacked G Ei admissible G, Ei defends A. So, Ei remains admissible
G.
Z attack Ei , Ei defends Z, Ei attack Z Ei {Z} conflictfree G . Let Ei {Z} attacked G . Either Ei proved
first item Ei admissible G , Ei defends A. = Z, assumed
Ei defends Z. case, Ei {Z} admissible G .


Lemma 2 Ei extension G containing Z, Ei admissible G.
Proof Lemma 2:
78

fiChange Argumentation Systems

Ei contain Z, Ei G. Ei conflict-free G Ei also conflict-free G. Let
Ei attacked argument A, G. Ei admissible, defends . So,
argument B Ei attacking A. Ei G, B G. So, proved Ei admissible G.

Proof Corollary 3: Proposition 15, Ei E, Ei {Z} admissible G . So, exists
j 1 Ei {Z} Ej . Lemma 2, Ek extension G containing Z, Ek
admissible G. So, exists 1 Ek Ei . So, Ek Ei Ei {Z} Ej .
consequence, would strict inclusion two extensions G , impossible.
So, cannot exist Ek extension G containing Z, extension G contains Z.

Proof Proposition 16: Z attacked G, Z attacked G Z belongs
preferred extension. Moreover, even-length cycle G, due Lemma 1,
even-length cycle G . So, due Proposition 2.5, G one preferred extension
empty (it contains least Z).


Lemma 3 Z attacks argument G Ei non empty extension G ,
Ei \ {Z} admissible G.
Proof Lemma 3:
Ei conflict-free G Ei \ {Z} also conflict-free G G.
Let Ei \ {Z}. Assume argument attacking . 6= Z since Z
attacks argument G. Ei non-empty preferred extension G , argument
B Ei attacking A, B 6= Z (always Z attacks argument G). So,
B Ei \ {Z}, Ei \ {Z} defends . So, Ei \ {Z} admissible G.

Proof Proposition 17: Suppose Z attacks argument G E = {{}}.
(reductio ad absurdum): Assume exists non-empty extension G denoted E .
exists E . Either = Z, G. cases, attacked,
arguments G attacked (since E = {{}}) Z attacks argument G. E must
defend . = Z, E cannot reduced (because Z attacks argument cannot defend
itself). E \ {Z} 6= {}. 6= Z, E \ {Z}, E \ {Z} =
6 {}. Due Lemma 3, E \ {Z}
admissible G E \ {Z} E E preferred extension G. G non-empty
extension, contradiction assumption.

Proof Proposition 18:
Z attacks argument G, due Proposition 15, i, Ei admissible G .
exists preferred extension Ej G including Ei . E 6= {{}}, i, Ei 6= {} Ej 6= {}.
Z 6 Ei , Ei Ej \ {Z}. Due Lemma 3, Ej \ {Z} admissible G, exists
k 1 Ei Ej \ {Z} Ek . Using definition preferred extension (-maximal
among admissible sets), conclude Ei = Ej \ {Z} = Ek . So, either Ej = Ei (if
Z 6 Ej ), Ej = Ei {Z} (if Z Ej ). first case, Ei extension G . second
case, Ei {Z} extension G . Moreover, Z Ej , Ej defends Z (which attacked
G, since attack G) Z attacks argument, Ei = Ej \ {Z} defends Z. So,
79

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

Ei defend Z, Ei extension G . hand, Ei defends Z, Ei {Z}
conflict-free G . So, Ei {Z} admissible G case Z Ej Ei {Z}
extension G .
Now, prove G G number extensions. first part
proof, know extension G included extension G . Moreover, two
distinct extensions G cannot included extension G . Indeed, union
two non-empty preferred extensions defends elements strictly contains
extensions. union two extensions cannot conflict-free.
So,we know G least many extensions G G least one nonempty extension. So, Ej E , Ej 6= {}. Due Lemma 3, Ej \ {Z} admissible G. So,
Ej , exists Ei , extension G Ej \ {Z} Ei . first part
proof, have:
Either Ei defends Z, Ei {Z} extension G . Ej \ {Z} Ei ,
Ej Ei {Z}, Ej maximal admissible G , Ej = Ei {Z}.
Ei defend Z, Ei extension G . Ej maximal admissible G ,
Z 6 Ej Ej = Ej \ {Z} = Ei .
So, G G number extensions.

Proof Proposition 19:
E = {{}}, obviously change satisfies Monotony.
G non-empty extension, Proposition 15 applied. extension G
remains admissible G included preferred extension G . So, change satisfies
Monotony.

Proof Proposition 20: Let E = i1 Ei E = i1 Ei .
Let Eg (resp. Eg ) denote grounded extension G (resp G ). Due Proposition 1.4, know
Eg E Eg E . Dung (1995) proved controversial argument,
grounded extension exactly intersection preferred extensions. So, G contains
controversial argument, Eg = E.
Now, Z attack i1 Ei , Z attack Eg , due Proposition 10, E =
6 {}
Eg Eg E = {} i1 Ei = {} inclusion trivially holds. So,

E = Eg Eg E , i1 Ei i1 Ei .
Proof Proposition 21: E 6= {{}} even-length cycle G evenlength cycle G; consequence, according Proposition 2.5 one extension E G;
moreover, E =
6 {}. Since even-length cycle G , know one extension


E G . Assume Z unattacked argument Ai G attacked G ;
unattacked argument G .
Assume E 6= {}. Let X E . X attacked G . Let Y1 denote attacker X. E
admissible, E defends X. E contains X2 attacks Y1 . even-length cycle
G , know X2 6= X. X2 unattacked.
able built infinite sequence distinct arguments:
X attacked Y1 attacked X2 . . . Yp attacked Xp+1 attacked Yp+1 . . .
Xi (resp. Yi s) distinct due absence even-length cycles G .
contradicts assumption finite. E = {} change destructive.
80



fiChange Argumentation Systems

Appendix B. Illustration Properties Change Operations
following examples illustrate structural properties property Monotony

change operations distinct (let us recall property Priority Recency
make sense change operations).


ai




First, notice hA, Rii (Z, Iz ) = hA , R hA , R ii Z = hA, Ri.

example Section 3.2, change also illustrated.
Example 4.1 show decisive change
property Monotony.

ai change ai satisfy




Example 5.2 shows decisive change change satisfies property
Monotony .
Example 4.3 shows restrictive change
property Monotony

ai change ai satisfy

Examples 2.3, 3.1, 5.1 show questioning change
satisfy property Monotony

ai

change

ai



Examples 2.1, 2.2, 4.2 show destructive change
satisfy property Monotony

ai

change

ai



Example 8.2 shows expansive change
property Monotony

ai

change

ai

satisfies




Examples 7.1, 7.2, 7.3 show conservative change change satisfies
property Monotony




Examples 6, 8.1 show altering change change satisfy
property Monotony








hA = {A, B, C}, R = {(A, B), (B, C), (C, A)}i, hA, Rii (A, C) decisive
change (before change E = {{}}, change E = {{A}}); inverse
operation hA, R {(A, C)}ii (A, C) destructive.
example,

satisfies property Monotony not.

hA = {A, B, C}, R = {(A, B), (B, C)}i, hA, Rii (C, A) destructive change
(before change E = {{A, C}}, change E = {{}}); inverse
operation hA, R {(C, A)}ii (C, A) decisive.
example,

satisfy property Monotony satisfies it.

hA = {A, B, C}, R = {(A, B), (B, C)}i, hA, Rii (A, C) altering change
(before change E = {{A, C}}, change E = {{A}}); inverse
operation hA, R {(A, C)}ii (A, C) expansive.
81

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

example,

satisfy property Monotony satisfies it.

hA = {A, B, C}, R = {(A, B)}i, hA, Rii (C, B) conservative change (before change E = {{A, C}}, change E = {{A, C}}); inverse
operation hA, R {(A, C)}ii (A, C) conservative.
example,

satisfy property Monotony.

hA = {A, B, C, D}, R = {(A, B), (B, A), (B, C), (D, C)}i, hA, Rii (C, D)
questioning change (before change E = {{A, D}, {B, D}}, change
E = {{A, D}, {B, D}, {A, C}}); inverse operation hA, R{(C, D)}ii (C, D)
restrictive.
example,

satisfies property Monotony not.

hA = {A, B, C, D}, R = {(A, B), (B, A), (B, C), (D, C), (C, D)}i, change
hA, Rii (A, D) restrictive one (before change E = {{A, D}, {B, D}, {A, C}},
change E = {{B, D}, {A, C}}).
inverse operation hA, R {(A, D)}ii (A, D) questioning.
example,

satisfy property Monotony satisfies it.

hA = {A, B, C}, R = {(A, B), (B, C)}i, hA, Rii (A, B) altering change
(before change E = {{A, C}}, change E = {{A, B}}).
example,

satisfy property Monotony.

hA = {A, B, C, D}, R = {(A, B), (B, C), (C, A)}i, hA, Rii (D, A) expansive change (before change E = {{D}}, change E = {{D, B}}).
example,

satisfies property Monotony.

References
Alchourron, C. E., Gardenfors, P., & Makinson, D. (1985). logic theory change:
partial meet contraction revision functions. Journal Symbolic Logic, 50, 510
530.
Amgoud, L., & Cayrol, C. (2002). Inferring inconsistency preference-based argumentation frameworks. Journal Automated Reasoning, 29, 125169.
Amgoud, L., & Maudet, N. (2002). Strategical considerations argumentative agents
(preliminary report). Proc. NMR, pp. 409417.
Amgoud, L., Maudet, N., & Parsons, S. (2000). Modelling dialogues using argumentation.
Proc. ICMAS, pp. 3138.
Amgoud, L., & Vesic, S. (2009). Revising Argumentation-Based Decision Systems.
Proc. ECSQARU, Vol. LNAI 5590, pp. 7182. Springer-Verlag.
Baroni, P., Giacomin, M., & Guida, G. (2005). Scc-recursiveness: general schema
argumentation semantics. Artifical Intelligence, 168, 162210.
Bench-Capon, T. (1998). Specification implementation Toulmin dialogue game.
Proc. JURIX, pp. 520.
82

fiChange Argumentation Systems

Besnard, P., & Hunter, A. (2008). Elements argumentation. MIT Press.
Boella, G., Kaci, S., & van der Torre, L. (2009a). Dynamics argumentation single
extensions: Abstraction principles grounded extension. Proc. ECSQARU
(LNAI 5590), pp. 107118.
Boella, G., Kaci, S., & van der Torre, L. (2009b). Dynamics argumentation single
extensions: Attack refinement grounded extension. Proc. AAMAS, pp.
12131214.
Bondarenko, A., Dung, P., Kowalski, R., & Toni, F. (1997). abstract, argumentationtheoretic approach default reasoning. Artificial Intelligence, 93, 63101.
Caminada, M. (2006). Semi-stable semantics. Proc. COMMA, pp. 121128.
Cayrol, C., Dupin de Saint-Cyr, F., & Lagasquie-Schiex, M. (2008). Revision argumentation system. Proc. KR 2008, pp. 124134. AAAI Press.
Chesnevar, C., Maguitman, A., & Loui, R. (2000). Logical models argument. ACM
Computing surveys, 32 (4), 337383.
Coste-Marquis, S., Devred, C., Konieczny, S., Lagasquie-Schiex, M., & Marquis, P. (2007).
merging Dungs argumentation systems. Artificial Intelligence, Argumentation Artificial Intelligence, 171 (10-15), 730753.
Coste-Marquis, S., Devred, C., & Marquis, P. (2005). Prudent semantics argumentation
frameworks. Proc. ICTAI, pp. 568572.
Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person games. Artificial Intelligence,
77, 321357.
Dung, P. M., Mancarella, P., & Toni, F. (2006). dialectic procedure sceptical
assumption-based argumentation. Proc. COMMA, pp. 145156.
Dunne, P., & Bench-Capon, T. (2001). Complexity combinatorial properties argument systems. Tech. report, U.L.C.S.
Dunne, P., & Bench-Capon, T. (2002). Coherence finite argument system. Artificial
Intelligence, 141 (1-2), 187203.
Falappa, M., Garca, A., & Simari, G. (2004). Belief dynamics defeasible argumentation
rational agents. Proc. NMR, pp. 164170.
Hunter, A. (2004). Making argumentation believable. Proc. AAAI, pp. 269274.
Kakas, A. C., & Moratis, P. (2003). Argumentation based decision making autonomous
agents. Proc. AAMAS, pp. 883890.
Matt, P., & Toni, F. (2008). game-theoretic measure argument strength abstract
argumentation. Proc. JELIA (LNAI 5293), pp. 285297.
Nute, D. (2003). Defeasible logic. Proc. INAP 2001, LNAI 2543, pp. 151169.
Paglieri, F., & Castelfranchi, C. (2005). Revising beliefs arguments: Bridging
gap argumentation belief revision MAS. Argumentation MultiAgent Systems, pp. 7894. Springer.
83

fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex

Pollock, J., & Gillies, A. (2000). Belief revision epistemology. Synthese, 122 (1-2),
6992.
Pollock, J. L. (1992). reason defeasibly. Artificial Intelligence, 57, 142.
Prakken, H., & Vreeswijk, G. (2002). Logics defeasible argumentation. Handbook
Philosophical Logic, Vol. 4, pp. 218319. Kluwer Academic.
Riveret, R., Prakken, H., Rotolo, A., & Sartor, G. (2008). Heuristics argumentation:
game-theoretical investigation. Proc. COMMA, pp. 324335.
Rotstein, N. D., Moguillansky, M. O., Falappa, M. A., Garca, A. J., & Simari, G. R. (2008a).
Argument theory change: revision upon warrant. Proc. COMMA, pp. 336347.
IOS Press.
Rotstein, N. D., Moguillansky, M. O., Garca, A. J., & Simari, G. R. (2008b). abstract
argumentation framework handling dynamics. Proc. NMR, pp. 131139.
Wassermann, R. (1999). Full acceptance argumentation - preliminary report.
Proc. IJCAI Workshop Practical Reasoning Rationality.
Witteveen, C., & van der Hoek, W. (1997). general framework revising nonmonotonic
theories. Proc. LPNMR (LNAI 1265), pp. 258272. Springer.

84

fi
