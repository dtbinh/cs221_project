Journal Artificial Intelligence Research 38 (2010) 535-568Submitted 05/10; published 08/10Logical Foundations RDF(S) DatatypesJos de BruijnStijn Heymansbruijn@kr.tuwien.ac.atheymans@kr.tuwien.ac.atVienna University TechnologyFavoritenstrae 9-11, A-1040 Vienna, AustriaAbstractResource Description Framework (RDF) Semantic Web standard providesdata language, simply called RDF, well lightweight ontology language, calledRDF Schema. investigate embeddings RDF logic show standard logicprogramming description logic technology used reasoning RDF.subsequently consider extensions RDF datatype support, considering entailment,defined RDF semantics specification, D* entailment, semantic weakeningentailment, introduced ter Horst. use embeddings properties logicsestablish novel upper bounds complexity deciding entailment. subsequentlyestablish two novel lower bounds, establishing RDFS entailment PTime-completesimple-D entailment coNP-hard, considering arbitrary datatypes,size entailing graph. results indicate RDFS may lightweightone may expect.1. IntroductionResource Description Framework (RDF) (Klyne & Carroll, 2004), togethervocabulary description language RDF Schema (RDFS) (Brickley & Guha, 2004), constitutesbasic language Semantic Web. Statements RDF triples form hs, p, oi.Sets triples called RDF graphs: intuitively, triple viewed edgenode node label p. Here, s, o, p constant symbols uniform resourceidentifiers (URIs) literals (e.g., strings) anonymous identifiers, called blank nodes.Consider, example, graphs = {ho, rdf:type, Ai, hA, rdfs:subClassOf, Bi}E = {ho, rdf:type, Bi}. Hayes (2004) defines notions RDF RDFS entailment.that, compared RDF entailment, RDFS entailment gives additional meaningrdfs:subClassOf statements: RDFS-entails E, RDF-entail E.RDF semantics specification (Hayes, 2004) defines four increasingly expressive normative entailment relations RDF graphs, namely simple, RDF, RDFS,entailment, latter extends RDFS entailment support datatypes (e.g.,strings integers). Furthermore, defines extensional RDFS (eRDFS) entailmentpossible extension RDFS entailment line description logic-basedlanguages OWL DL (Patel-Schneider, Hayes, & Horrocks, 2004) OWL 2 DL(Motik, Patel-Schneider, & Parsia, 2009b). Intuitively, difference RDFSeRDFS entailment regimes that, latter, whenever ontological relation (e.g.,subclass property domain) implicitly holds interpretation, corresponding RDFstatement (rdfs:subClassOf, rdfs:domain, respectively) must true, whereasc2010AI Access Foundation. rights reserved.fide Bruijn & Heymansalways case RDFS entailment regime. following example illustratesdifference.Example 1. Let graph{hmother, rdfs:subPropertyOf, parenti, hparent, rdfs:domain, P ersoni}says P erson domain parent, property mother subproperty parent. Using eRDFS entailment conclude P ersondomain mother:|=erdfs hmother, rdfs:domain, P ersonisince must case subject mother triple type P erson; thus,P erson implicitly domain mother. cannot draw conclusion usingRDFS entailment; RDFS, explicitly asserted domain constraints derived.also consider D* entailment (ter Horst, 2005), semantic weakening entailment purpose efficient computation consequences. D*entailment extends RDFS entailment, expensive terms computationalcomplexity.several investigations formal properties RDF semantics(Gutierrez, Hurtado, & Mendelzon, 2004; Gutierrez, Hurtado, Mendelzon, & Perez, 2010;de Bruijn, Franconi, & Tessaris, 2005; ter Horst, 2005): Gutierrez et al. (2004, 2010) reconstruct semantics graph database perspective, de Bruijn et al. (2005)reconstruct semantics logical language perspective. investigationRDF semantics ter Horst (2005) stays close RDF specification. Additionally,ter Horst shows entailment rules computing RDFS entailment presentedoriginal specification (Hayes, 2004) complete respect RDFS semantics.reconstructions led number complexity results RDF entailment.particular, simple, RDF, RDFS entailment NP-complete combined sizegraphs. high complexity due presence blank nodes (essentially existentiallyquantified variables): entailed graph known ground, respective problemsturn decidable polynomial time. bounds showntight. show Section 5, bound tight RDFS entailment,simple RDF entailment, decided logarithmic space.investigate relationship RDF logic embed various RDFentailment regimes F-Logic (Kifer, Lausen, & Wu, 1995), syntactic extensionfirst-order logic (FOL) object oriented modeling constructs. F-Logic constructsexplicitly specify attributes, well generalization/specialization instantiationrelationships. Like RDFS, syntax F-Logic seemingly higher-order features,namely, identifier used class, instance, attribute. However,semantics F-Logic strictly first-order (Kifer et al., 1995). turnsattribute value construct F-Logic exactly equivalent triple construct RDF,typing (class membership) construct F-Logic close spirit oneRDF.addition, consider embedding large subset extensional RDFS FOLtractable description logic language DL-LiteR (Calvanese, Giacomo, Lembo, Lenzerini,536fiLogical Foundations RDF(S) Datatypes& Rosati, 2007), thereby showing that, certain restrictions, extensional RDFSseen standard first-order knowledge representation language.contributions paper summarized follows.1. define embeddings simple, RDF, RDFS, extensional RDFS F-Logic,show simple, RDF, RDFS entailment decided using standard logicprogramming techniques, embeddings Horn fragment F-Logic.2. define alternative, direct embedding extensional RDFS Horn fragment F-Logic fragment RDF graphs, namely RDFSvocabulary used standard way. subsequently exploit earlier resultsrelationship F-Logic statements description logic statements(de Bruijn & Heymans, 2008) show extensional RDFS reasoning groundRDF graphs reduced reasoning tractable description logic DL-LiteR(Calvanese et al., 2007).3. extend embeddings mentioned 1. support datatypes, consideringD* entailment. embeddings extensions simple, RDF,RDFS entailment D* datatype support essentially Horn fragmentF-Logic. extensions simple, RDF, RDFS datatype supportembedded Horn fragment F-Logic suitably restricting datatypesmay considered.4. analyze complexity deciding mentioned entailment relations.mentioned embeddings obtain number novel complexity upper bounds, namely,simple RDF entailment, well extensions datatypes (under suitablerestrictions), LogSpace size entailing graph large fragmentextensional RDFS entailment NP combined size graphsPTime size entailing graph. also establish novel PTime lower boundRDFS entailment novel coNP lower bound simple entailment extendeddatatype support, considering arbitrary datatypes, sizeentailing graph. See Table 2 page 553 overview complexity resultsRDF.structure remainder paper follows. Section 2 review logicsconsideration, namely F-Logic DL-LiteR . Section 3 review RDF(S)semantics, define embeddings F-Logic FOL, show faithfulness embeddings,demonstrate relationship DL-LiteR . Section 4 consider extensionsRDF entailment regimes datatype support based D* entailmentembeddings extensions logic. Section 5 extensively investigatecomplexity various RDF entailment regimes. conclude paper outlinefuture work Section 6.paper extends paper published International Semantic Web Conference(de Bruijn & Heymans, 2007) embeddings D* entailment regimesnovel lower bounds complexity deciding RDFS, D* , entailment.537fide Bruijn & Heymansreasons legibility, definitions various RDF-related notions interpretation may found Appendix A, embeddings RDF entailment regimes mayfound Appendix B, proofs Sections 3 4 may found Appendix C.2. Preliminariessection review F-Logic DL-LiteR .2.1 Frame Logicconsider Frame Logic (F-Logic) defined Kifer, Lausen, Wu (1995). simplifymatters, constructs necessary embedding RDF,consider function symbols, parameterized methods, functional (single-valued) methods,inheritable methods, compound molecules, following de Bruijn Heymans (2008).signature F-language L form = hC, Pi C P disjoint setsconstant predicate symbols; predicate symbol associated arity n 0. LetV set variable symbols. Terms atomic formulas constructed usual: x Vc C terms >, , p(t1 , . . . , tn ), t1 = t2 atomic formulas, p Pn-ary predicate symbol, t1 , . . . , tn terms.molecule F-Logic one following statements: (i) is-a assertionform t1 : t2 , states individual t1 type t2 , (ii) data molecule (calledmethod Kifer et al., 1995) form t1 [t2 t3 ], t1 , t2 , t3 terms,states individual t1 attribute t2 value t3 . F-Logic molecule groundcontain variables.Formulas F-language L either atomic formulas, molecules, compound formulas constructed usual way atomic formulas, molecules,logical connectives , , , , quantifiers , auxiliary symbols ( ).denote universal closure, i.e., universal quantification every variable freeoccurrence formula, ().theory set formulas. theory formula called equality-free equalitysymbol = appear it.F-Logic Horn formulas form ()B1 . . . Bn H, B1 ,. . . , Bn , Hatomic formulas molecules. F-Logic Datalog formulas F-Logic Horn formulasevery variable H occurs equality-free Bi . latter condition calledsafeness.F-structure tuple = hU, U , IC , , IP i, U non-empty set Ubinary relation U . constant symbol c C interpreted element domain:IC (c) U . n-ary predicate symbol p P interpreted relation domainU : IP (p) U n . associates binary relation U k U : (k) U U .Variable assignments B defined usual way.Given F-structure I, variable assignment B, term L, tI,B defined as:I,Bx = xB variable symbol x tI,B = IC (t) C.Satisfaction atomic formulas molecules I, given variable assignment B,denoted (I, B) |=f , defined(I, B) |=f >,(I, B)6|=f ,538fiLogical Foundations RDF(S) DatatypesI,B(I, B) |=f p(t1 , . . . , tn ) iff (tI,B1 , . . . , tn ) IP (p),I,BI,B(I, B) |=f t1 = t2 iff t1 = t2 ,(I, B) |=f t1 : t2 iff tI,BU tI,B12 ,I,B I,B(I, B) |=f t1 [t2 t3 ] iff ht1 , t3 (tI,B2 ).extends arbitrary formulas usual way. F-structure satisfies formula, denoted |=f , (I, B) |=f every variable assignment B. satisfies theory Lsatisfies formulas ; case, called model . theory F-entailsformula L, denoted |=f , iff every model , |=f .Herbrand F-structure F-structure = hU, U , IC , , IP Uset constants every constant symbol c C, IC (c) = c. abuse notation,Herbrand structures use denote structure set ground atomicformulas satisfied structure. Finally, Herbrand F-structure minimal Herbrandmodel theory model Herbrand F-structure I0 modelI0 I.Classical first-order logic (FOL) F-Logic without molecules. Contextual first-order logicclassical FOL C P required disjoint, predicate symbolsassociated arity, every structure = hU, U , IC , , IP i, IP assignsrelation IiP (p) U n every p P, every nonnegative integer i. denote satisfactionentailment classical contextual first-order logic using symbols |= |=c ,respectively. Contextual FOL sometimes also referred FOL punning.F-Logic straightforwardly embedded FOL, shown (Kifer et al., 1995,Theorem 18.1).Proposition 1. Let F-Logic theory formula containbinary ternary predicate symbols isa data, respectively, let 0 0FOL theory formula obtained replacing every is-a molecule : bisa(a, b) every data molecule a[b c] data(a, b, c). Then,|=f iff 0 |= 02.2 DL-LiteRDL-LiteR (Calvanese et al., 2007) language consists pairwise disjoint sets concept(NC ), role (NR ), individual (NI ) identifiers. Concepts roles DL-LiteRdefined follows:Cl | RCr | R | | RR, R0 P | PNC P NR , Cl Cr left- (resp., right-)hand side concepts, R R0roles.DL-LiteR knowledge base K = (T , A) consists TBox , set inclusionaxioms formsCl v CrR v R0539fide Bruijn & HeymansDL syntax FOL syntax(A, X)A(X)(P, X, )P (X, )(P , X, ) P (Y, X)(R, X)y((R, X, y))(A, X)(A, X)(R, X)y((R, X, y))new variableDL syntax(Cl v Cr )(R1 v R2 )(A(a))(P (a1 , a2 ))FOL syntaxx((Cl , x) (Cr , x))x, y((R1 , x, y) (R2 , x, y))A(a)P (a1 , a2 )Table 1: Mapping DL-LiteR FOLABox A, set concept role membership assertions formsA(a)P (a1 , a2 )a, a1 , a2 NI .define semantics DL-LiteR translation FOL, formmapping function , defined Table 1.1 mapping extends naturally setsaxioms assertions.Given DL-LiteR knowledge base K = (T , A), FOL equivalent K FOLtheory = (K) = (T ) (A).Contextual DL-LiteR like DL-LiteR , except sets concept (NC ), role (NR ),individual (NI ) identifiers required disjoint. semantics contextualDL-LiteR knowledge base K = (T , A) given mapping (K),yields contextual FOL theory. Note contextual DL-LiteR essentially subsetQL profile OWL 2 (Motik, Grau, Horrocks, Wu, Fokoue, & Lutz, 2009a).3. RDF RDF Schemafirst review definitions RDF syntax semantics. proceedembedding graphs axiomatization entailment regimes F-Logic,finally embedding extensional RDFS FOL DL-LiteR .3.1 RDF(S) Syntax Semanticsproceed review definitions RDF syntax (Klyne & Carroll, 2004)semantics (Hayes, 2004).vocabulary V = hC, PL, Li consists set C RDF URI references (simply referredURIs), set PL plain literals (i.e., Unicode character strings optionallanguage tag), set L typed literals (i.e., pairs (s, u) Unicode stringURI u, denoting datatype); see (Klyne & Carroll, 2004, Sections 6.4, 6.5, 6.6)details specific form symbols. Note C, PL, L mutuallydisjoint. symbols V collectively referred names.Let B set blank nodes disjoint set names V . Termsnames blank nodes. generalized RDF graph set generalized triples hs, p, oi1. Borgida (1996) discusses relationship description logics first-order logic detail.540fiLogical Foundations RDF(S) Datatypessubject, predicate, object s, p, C PL L B. normal RDF graph setnormal triples hs, p, oi, C B, p C, C PL L B.2 ground tripletriple contain blank nodes. ground generalized, respectively normalRDF graph set ground generalized, respectively normal triples. bl(hs, p, oi) B(resp., bl(S) B) denote set blank nodes triple hs, p, oi (resp., graph S).remainder, whenever speaking triples RDF graphs, mean generalizedtriples, respectively generalized RDF graphs, unless stated otherwise.interpretation tuple = hIR, IP, LV, IS, IL, IEXTi, IR non-empty set,called domain, IP set properties, LV IR set literal values PL LV,mapping : C IR IP, IL mapping IL : L IR, IEXT extensionfunction IEXT : IP 2(IRIR) .Given interpretation I, subset blank nodes B 0 B, mapping : B 0IR, used interpret blank nodes, given term define tI,A as:C, tI,A = IS(t),L, tI,A = IL(t),PL, tI,A = t,B 0 , tI,A = A(t).interpretation satisfies triple hs, p, oi respect mapping : B 0 IR,bl(hs, p, oi) B 0 , denoted (I, A) |= hs, p, oi, pI,A IP hsI,A , oI,A IEXT(pI,A ).satisfies graph respect mapping : bl(S) IR, denoted (I, A) |= S,(I, A) |= hs, p, oi every hs, p, oi S.interpretation satisfies RDF graph S, denoted |= S, (I, A) |=mapping : bl(S) IR; case, model S. interpretation sinterpretation (simple interpretation).notions rdf -, rdfs-, erdfs-interpretation defined additional conditions s-interpretation. example, s-interpretation rdf -interpretationevery object k, k IP iff hk, IS(rdf:Property)i IEXT (IS(rdf:type)) satisfiestriple hrdf:nil, rdf:type, rdf:Listi. Triples required satisfied everyx-interpretation called x-axiomatic triples, x {rdf, rdfs, erdfs} simply axiomatictriples entailment regime clear context. precise definitions rdf -,rdfs-, erdfs-interpretation found Appendix A.Entailment Satisfiability Given vocabulary V entailment regime x{s, rdf, rdfs, erdfs}, generalized (resp., normal) RDF graph x-entails generalized (resp.,normal) RDF graph E, denoted |=x E, every x-interpretation V modelalso model E.Given entailment regime x {s, rdf, rdfs, erdfs}, generalized (resp., normal) RDFgraph x-satisfiable model x-interpretation; otherwise xunsatisfiable. following observations made satisfiability variousentailment regimes; observations concerning normal RDF graphs due Hayes(2004).Proposition 2.1. Every generalized every normal RDF graph s-satisfiable.2. Every normal RDF graph rdf-satisfiable.2. Normal RDF graphs correspond RDF graphs defined Hayes (2004). contrast normal RDF,generalized RDF graphs allow blank nodes literals predicate, literals subject positions.541fide Bruijn & Heymans3. generalized RDF graph rdf-unsatisfiable.4. normal (and generalized) RDF graph rdfs- erdfs-unsatisfiable.3.2 Embedding RDF Logictranslate graph conjunction data molecules, URIs literalsconstant symbols blank nodes existentially quantified variables. axiomatizeentailment regimes using sets formulas independent graphs.remainder assume RDF graphs finite.Given vocabulary V = hC, PL, Li, F-language L conforms Vsignature form = hC 0 , Pi, C 0 C PL L.3Definition 1. Let V vocabulary, let RDF graph V , let bl(S) = {b1 , . . . , bn }set blank nodes appearing S, let hs, p, oi triple S, let LF-language conforms V . Then,tr(hs, p, oi) = s[p o]^tr(S) = b1 , . . . , bn{tr(hs, p, oi) | hs, p, oi S}formulas L.axiomatizations entailment regimes theories x , x {s, rdf, rdfs,erdfs}, defined Appendix B.F-Logic formula prenex normal form existential quantifiers,sk() denotes Skolemization , i.e., every existentially quantified variable replacedglobally unique new constant symbol. extends theories natural way.Proposition 3. Let RDF graph vocabulary V let x {s, rdf, rdfs}entailment regime. Then, sk(tr(S)) x equivalently rewritten set F-LogicHorn formulas.erdfs cannot equivalently rewritten set Horn formulas,use universal quantification antecedents implications erdfs .show faithfulness embedding.Theorem 1. Let E RDF graphs vocabulary V , let x {s, rdf, rdfs, erdfs}entailment regime. Then,|=x Ex-satisfiableifftr(S) x |=f tr(E)ifftr(S) x model.following corollary follows immediately Theorem 1 classical resultsSkolemization (see, e.g., Fitting, 1996).Corollary 1. Let E RDF graphs vocabulary V , let x {s, rdf, rdfs,erdfs} entailment regime. Then,|=x E sk(tr(S)) x |=f tr(E).3. Even though typed literals pairs RDF, treat simply constant symbols embedding.542fiLogical Foundations RDF(S) DatatypesObserve rdf , rdf , erdf infinite due infinite set RDF axiomatictriples. However, checking RDF entailment need finite subset x . GivenRDF graph S, let xS obtained x removing formulas originatingaxiomatic triples involving container membership properties (i.e., rdf: 1, rdf: 2, . . . )appearing S, exception axiomatic triples involving rdf: 1.Proposition 4. Let E RDF graphs let x {s, rdf, rdfs, erdfs} entailmentregime. Then,|=x E sk(tr(S)) xSE |=f tr(E).Proposition 3 sk(tr(S)) , tr(S)sk rdf , sk(tr(S)) rdfsequivalent sets Horn formulas. Therefore, Proposition 4 implies simple, RDF,RDFS entailment computed using reasoners compute ground entailmentF-Logic Horn theories, FLORA-2 (Yang, Kifer, & Zhao, 2003). Notice tr(E)seen boolean conjunctive query (i.e., yes/no query), existentiallyquantified variables tr(E) non-distinguished variables.3.3 Direct Embedding Extensional RDFSconsider alternative, direct embedding extensional RDFS entailmentregime. embedding, rather axiomatizing entailment regime, embeds ontological statements, e.g., rdfs:subClassOf statements, directly formulas.first define notion standard use RDF(S) vocabulary, intuitivelycorresponds using vocabulary locations change semanticsRDF(S) ontology vocabulary (e.g., hrdf:type, rdfs:subPropertyOf, ai).Definition 2. Let RDF graph. Then, standard use RDF(S)vocabularyrdf:type, rdfs:subClassOf, rdfs:domain, rdfs:range, rdfs:subPropertyOfappear subject object positions triplerdfs:ContainerMembershipProperty, rdfs:Resource, rdfs:Class, rdfs:Datatype,rdf:Property appear object positions rdf:type-triples S.ready define direct embedding trerdfs extensional RDFS entailment regime graphs standard use RDFS vocabulary. trerdfs dealsimportant part RDF(S) vocabulary, axiomatization eRDFS semanticsremainder RDF(S) vocabulary may found Appendix B, formtheory erdfs-V , V vocabulary.543fide Bruijn & HeymansDefinition 3. Let hs, p, oi RDF triple. Then,trerdfs (hs, type, Datatypei) ==Propertyi)trerdfs (hs, type, oi) =trerdfs (hs, subClassOf, oi) =trerdfs (hs, subPropertyOf, oi) =trerdfs (hs, domain, oi) =trerdfs (hs, range, oi) =trerdfs (hs, p, oi) =trerdfs (hs, type, ContainerMembership-: Datatype x(x : x : Literal),: ContainerMembershipPropertyx, y(x[s y] x[member y]),: o,x(x : x : o),x, y(x[s y] x[o y]),x, y(x[s y] x : o),x, y(x[s y] : o),s[p o], otherwise.Let RDF graph let bl(S) = {b1 , . . . , bn } set blank nodes S. Then,^trerdfs (S) = { b1 , . . . , bn ( {trerdfs (hs, p, oi) | hs, p, oi S})}say term occurs property position occurs predicatetriple, subject object rdfs:subPropertyOf triple, subjectrdfs:domain rdfs:range triple, graph contains ht, rdf:type, rdf:Propertyiht, rdf:type, ContainerMembershipPropertyi. term occurs class position occurs subject object rdfs:subClassOf triple, object rdfs:domain,rdfs:range, rdf:type triple, subject triple ht, rdf:type, rdfs:Classi,subject triple ht, rdf:type, rdfs:Datatypei.Let RDF graph standard use RDF(S) vocabulary. property(resp., class) vocabulary consists names appearing property (resp., class)positions RDF(S) axiomatic triples standard use RDF(S)vocabulary.Given two RDF graphs E standard use RDF(S) vocabulary,write E E property, resp. class vocabularies E subsets property, resp.class vocabularies S, blank nodes class property positions E,4rdfs:Resource, rdfs:Class, rdf:Property appear E.Theorem 2. Let E RDF graphs standard use RDFS vocabularyE E S. Then,|=erdfs E iff trerdfs (S) erdfs-V |=f trerdfs (E)define erdfs-Vanalogously erdfs, i.e., contain statements concerningcontainer membership properties appearing graph S, exception rdf: 1.following proposition follows argument analogous proof Property 4.Proposition 5. Let E RDF graphs standard use RDFS vocabularyE E S. Then,erdfs|=erdfs E iff sk(trerdfs (S)) erdfs-V(E).SE |=f tr4. restriction use blank nodes entailed graph mentioned extendedabstract paper (de Bruijn & Heymans, 2007). error.544fiLogical Foundations RDF(S) Datatypeswhenever E contain terms rdfs:subClassOf, rdfs:subPropertyOf, rdfs:domain, rdfs:range, trerdfs (E) conjunction atomic moleculesprefixed existential quantifiers (i.e., conjunctive query).sk(trerdfs (S)) erdfs-VSE finite set Horn formulas. Therefore,graphs satisfy mentioned conditions, query answering techniques used F-Logicreasoners FLORA-2 (Yang et al., 2003) used checking extensional RDFSentailment.3.4 Embedding Extensional RDFS First-Order Logicconsider embedding extensional RDFS entailment first-order logic (FOL),based direct embedding extensional RDFS F-Logic defined above.say F-Logic theory translatable contextual FOL containunary binary predicates every molecule form t1 [t2 t3 ] t1 : t2 holdst2 constant symbol. F O() contextual FOL theory obtained replacing:every data molecule t1 [t2 t3 ] atomic formula t2 (t1 , t3 )every is-a molecule t1 : t2 atomic formula t2 (t1 ).following proposition follows immediately earlier result (de Bruijn & Heymans,2008, Theorem 3.2).Proposition 6. Let , respectively , equality-free F-Logic theory, respectively formula, translatable contextual FOL. Then,|=f iff F O() |=c F O().say RDF graph non-higher-order graph contain blanknodes class property positions, standard use RDFS vocabulary.Observe non-higher-order RDF graph, trerdfs (S) erdfs-V translatablecontextual FOL. Notice also every ground RDF graph standard useRDFS vocabulary non-higher-order RDF graph.Theorem 3. Let E non-higher-order RDF graphs E E S. Then,|=erdfs E iff F O(trerdfs (S) erdfs-V ) |=c F O(trerdfs (E)).Proof. Follows immediately Theorem 2, fact F O(trerdfs (S))F O(trerdfs (E)) contain equality symbol, Proposition 6.Concerning relationship DL-LiteR , make following observation.Proposition 7. Let ground non-higher-order graph.5 Then, F O(trerdfs (S)erdfs-V )equivalently rewritten FOL equivalent = (K) contextual DL-LiteRknowledge base K.Analogous Proposition 5, one may discard axiomatic triples concerning containermembership properties used, thus one needs reason finiteknowledge base.5. Note that, considering variant DL-LiteR allows existentially quantified variablesABox also allowed OWL DL restriction could relaxed non-ground non-higherorder RDF graph.545fide Bruijn & Heymans4. Extensions Datatypesentailment regimes dealt previous section consider manyuseful datatypes (e.g., strings, integers). fact, rdf:XMLLiteral datatypeconsidered. RDF semantics specification (Hayes, 2004) defines notionentailment (datatype entailment), extends RDFS entailment supportdatatypes. Ter Horst (2005) defines notion D* entailment, also extensionRDFS entailment, semantically weaker entailment. first review D*entailment, review entailment. semantics originally definedextensions RDFS entailment. However, one might extend entailment regimesconsidered datatype support. Therefore, consider extensions simple, RDF,RDFS, extensional RDFS entailment kinds datatype semantics. firstreview datatype semantics, present embeddings semanticsF-Logic. Finally, discuss notion normalization may used remove equalitystatements embeddings speed processing.4.1 Extension RDF Entailment Regimes DatatypesDatatypes define sets concrete data values (e.g., strings integers), alonglexical representations. datatype tuple = hLd , V , L2V consistinglexical space Ld , set character strings (e.g., 0, 1, 01, . . . ,case integer datatype),value space V , set values (e.g., numbers 0, 1, 2, . . . , caseinteger datatype),lexical-to-value mapping L2V , mapping lexical spacevalue space (e.g., {0 7 0, 1 7 1, 01 7 1, . . .}, integer datatype).simple datatype map partial mapping URIs datatypes. simple datatypemap datatype map D(rdf:XMLLiteral) = xml xml built-in XMLliteral datatype defined RDF specification (Klyne & Carroll, 2004). dom(D)ran(D) denote domain range D, respectively.Given simple datatype map D, call typed literal (s, u) L well-typed udom(D) LD(u) ; (s, u) ill-typed u dom(D)/ LD(u) .review notions D* entailment. Similar previous section,definitions D* - D-interpretations found Appendix A.D* entailment Given simple datatype map D, RDF graph s-D* entails RDFgraph E, denoted |=s-D* E, every s-D* -interpretation model modelE.Given datatype map D, RDF graph x-D*-entails RDF graph E, denoted|=x-D* E, every x-D* -interpretation model model E, x{rdf, rdfs, erdfs}.Notice dom(D) = {rdf:XMLLiteral} x {rdf, rdfs, erdfs}, x-D* entailment corresponds x-entailment, exception considering rdf -D* entailment, triple hrdf:XMLLiteral, rdf:type, rdfs:Datatypei additionally entailed.addition, dom(D) = , s-D* -entailment corresponds s-entailment.546fiLogical Foundations RDF(S) Datatypesfollowing example shows equality may introduced D* semantics.Example 2. Consider datatype map contains XML schema string datatype(Peterson, Gao, Malhotra, Sperberg-McQueen, & Thompson, 2009). Certain equalities holdplain literals without language tags typed literals datatype, setplain literals without language tags corresponds value space string datatype.So, equalities = (a, string) xxx = (xxx, string) necessarily hold.Similar equalities datatypes. example, datatype map containsinteger decimal, equalities (1, integer) = (1, decimal)(1, decimal) = (1.0, decimal) necessarily hold.entailment Given simple datatype map D, RDF graph s-D-entails RDFgraph E, denoted |=s-D E, every s-D-interpretation model modelE.Given datatype map D, RDF graph x-D-entails RDF graph E, denoted|=x-D E, every x-D-interpretation model model E, x{rdf, rdfs, erdfs}. RDF graph x-D-entails RDF graph E, denoted |=x-D E,every x-D-interpretation model also model E.two main differences D* entailment entailment: (i) entailment allows easy extension towards languages express equalityURIs denoting datatypes; whenever two URIs denote datatype, typed literalstwo URIs datatypes interpreted way (see Example 3); (ii)entailment directly links class extension datatype value spacedatatype. latter complicates evaluation entailment somewhat, likelymain motivation introduction D* entailment. complication becomes cleardeclaring blank nodes members specific datatypes, illustrated Example 4.Example 3. Consider extension entailment equality imposing followingcondition interpretations:(+) interpretation satisfies triple hx, owl:sameAs, yi respectblank node assignment iff xI,A = I,A .consider datatype map = {bool 7 boolean}, boolean defined follows:Lboolean = {1, 0, t, f },V boolean = {true, f alse},L2V boolean = {1 7 true, 0 7 f alse, 7 true, f 7 f alse},RDF graph = {hmyBool, owl:sameAs, booli, ha, b, (1, myBool)i}. D-interpretations, typed literals datatype URIs interpreted interpreted well. Therefore, entailment extended condition (+)triple ha, b, (t, myBool)i derived S: (1, myBool) (t, myBool)interpreted L2V boolean (1) = L2V boolean (t) = true; hence, (1, myBool)(t, myBool) interpreted way every interpretation. Similarly,shown triples ha, b, (1, bool)i ha, b, (t, bool)i entailed S.547fide Bruijn & HeymansNone derivations valid considering D* entailment extended condition (+). fact, myBool domain D, (1, myBool) interpretedarbitrary (abstract) symbol; treated way URI.Example 4. Consider datatype map includes XML schema datatypes stringinteger (Peterson et al., 2009), disjoint value spaces. Consider alsograph = {h : x, rdf:type, stringi, h : x, rdf:type, integeri}. rdfs-D*-interpretation class extensions string integer necessarilyvalue spaces respective datatypes. Therefore, may object k IRneither integer string, class extensions stringinteger. Consequently, rdfs-D*-interpretation modelrdfs-D*-satisfiable.rdfs-D-interpretation class extensions string integer necessarilyvalue spaces respective datatypes. Since value spaces disjoint,object class extension string class extensioninteger. Therefore, rdfs-D-satisfiable.4.2 Embeddings Datatypes LogicGiven datatype map D, use set formulas L, defined Appendix B, axiomatize semantics entailment regime {x-D*, x-D}, x {s, rdf, rdfs, erdfs}.Analogous Proposition 3, have:Proposition 8. Let RDF graph vocabulary V . Then, sk(tr(S)) ,{s-D*, rdf-D*, rdfs-D*, s-D, rdf-D, rdfs-D}, equivalently rewritten set FLogic Horn formulas.first show faithfulness embedding D* entailment.Theorem 4. Let E RDF graphs vocabulary V , let datatype map,let x {s, rdf, rdfs, erdfs} entailment regime. Then,|=x-D* E tr(S) x-D* |=f tr(E)x-D*-satisfiable iff tr(S) x-D* model.turn x-D-entailment. turns considering datatype mapsarbitrary datatypes, one needs reason case (see Proposition 14 Section 5),complicates matters. therefore restrict definite datatypes,bring complication. example definite datatype map one includesset datatypes OWL 2 EL QL profiles (Motik et al., 2009a).Definition 4. datatype map definitevalue space every datatype ran(D) infinite,n 1 distinct datatypes d1 , . . . , dn ran(D) holds either (a) valuespaces disjoint, i.e., V di V dj = (1 < j n) (b) intersectioninfinite, i.e., V d1 V dn infinite set,548fiLogical Foundations RDF(S) Datatypestwo datatypes d1 , d2 ran(D) holds d1 V d2 .Theorem 5. Let E RDF graphs vocabulary V , let definite datatypemap, let x {s, rdf, rdfs, erdfs} entailment regime. Then,|=x-D E tr(S) x-D |=f tr(E)x-D-satisfiable iff tr(S) x-D model.4.3 Normalization Datatypesset equality statements axiomatizations x-D* x-D potentially largeand, general, polynomial size vocabulary V . addition, requires equalityreasoning, tends deteriorate performance reasoner. discussnormalize embedding graph F-Logic, thereby removing need expressingequality.Given vocabulary V , assume strict (e.g., lexicographical)order < setliterals PL L. given datatype map D, define V = udom(D) V D(u) , i.e.,values D. v V , define literals represent value v as:v = {(s, u) L | L2V D(u) (s) = v} {l PL | l = v}. representation v, denotedr(v), least element v according order <.Given set formulas L L conforms V , datatype normalization, denoted ()n , obtained replacing every plain literal l PL r(l)replacing every well-typed literal (s, u) L r(L2V D(u) (s)).Observe equality statements normalizations (tr(S) x-D )n(tr(S) x-D* )n trivial statements form = t, literal. Therefore,statements may discarded.following proposition follows straightforwardly shape axiomatizations definition normalization.Proposition 9. Let E RDF graphs vocabulary V , let datatype map D,let {s-D*, rdf-D*, rdfs-D*, erdfs-D*, s-D, rdf-D, rdfs-D, erdfs-D}. Then,tr(S) |=f tr(E) iff (tr(S) )n |=f (tr(E))n5. Complexitysection review complexity various RDF entailment relations presentseveral novel results, exploiting embeddings presented Sections 3 4.complexity non-ground simple entailment RDFS entailment, upper boundsground entailment known literature, analogous results RDF entailment follow immediately. Recall that, although set axiomatic triples infinite,finite subset, linear size graphs, needs taken accountchecking entailment (cf. Proposition 4).Proposition 10 (Gutierrez et al., 2004, 2010; ter Horst, 2005; de Bruijn et al., 2005).decision problems |=s E, |=rdf E, |=rdf E, |=rdfs-D* E, given RDF graphs549fide Bruijn & HeymansE, NP-complete combined size E, polynomial size S.E ground, respective problems PTime.addition, problems |=erdf E |=rdfs-D E NP-hard.membership proofs Gutierrez et al. (2004, 2010), ter Horst (2005), de Bruijnet al. (2005) rely fact set (relevant) entailed triples given graphcomputed polynomial time using RDFS entailment rules (ter Horst, 2005);problem reduced subgraph homomorphism. Corollary 1fact problem checking ground entailment Datalog (Dantsin, Eiter, Gottlob,& Voronkov, 2001) polynomial size data (i.e., tr(S)) obtain novelargument membership.NP-hardness non-ground entailment shown reductionknown NP-hard problem (ter Horst, 2005).embedding F-Logic (Theorem 1), obtain following upper boundcomplexity simple RDF entailment.Proposition 11. Let E RDF graphs. E fixed, problems |=s E|=rdf E decidable LogSpace size S. problems |=s E |=rdf Edecidable LogSpace combined size graphs E ground.Proof Sketch. easy see fact could potentially recursively derived rdf rdf:type[rdf:type rdf:Property]; however, rdf:type[rdf:typerdf:Property] rdf . Thus, sk(tr(S)) sk(tr(S)) rdf may treated nonrecursiveDatalog programs.proposition follows straightforwardly Corollary 1 fact groundentailment nonrecursive Datalog LogSpace size data (Abiteboul, Hull,& Vianu, 1995), data input RDF graphs.turns cannot obtain LogSpace upper bound RDFS entailment.fact, turns ground rdfs-, hence ground rdfs-D* - rdfs-D-entailment,PTime-hard.Proposition 12. exist ground RDF graphs E decision problems|=rdf E, |=rdfs-D* E, |=rdfs-D E PTime-hard.Proof. proceed reduction PTime-hard problem path system accessibility(Jones & Laaser, 1974; Gary & Johnson, 1979), defined as:Instance: set X nodes, subsets S, X source terminal nodes, relationR X X X.Question: node x X accessible x exist accessible nodes y, z Xhx, y, zi R. accessible terminal node ?remainder sp short rdfs:subPropertyOf.encode problem RDFS. graph G constructed follows:every source node x include triple hx, sp, spi,every terminal node x include triple ha, sp, xi,every tuple hx, y, zi R include triple hx, y, zi.550fiLogical Foundations RDF(S) Datatypesshow node X accessible iff G |=rdf ht, sp, spi. followsexists accessible node iff G |=rdf ha, sp, spi.() proceed induction. Base case: ht, sp, spi G, clearlyG |=rdf ht, sp, spi.Induction step: consider ht, y, zi R y, z accessible. ht, y, ziincluded G G |=rdf hy, sp, spi G |=rdf hz, sp, spi, since z accessible.Condition 10 Table 5 implies G |=rdf ht, sp, zi. transitivity sp (condition 9Table 5) subsequently conclude G |=rdf ht, sp, spi.() Assume, contrary, X accessible. straightforwardconstruct rdfs-interpretation |=rdf G 6|=rdf ht, sp, spi, contradiction.Using correspondence Proposition 7, results complexity reasoningDL-LiteR (Calvanese et al., 2007), classical results skolemization (Fitting,1996) obtain following result extensional RDFS entailment. Recall notionstandard use RDFS vocabulary Definition 2.Proposition 13. Let E RDF graphs standard use RDFS vocabulary E E S. Then, problem deciding |=erdf E NP-complete,NLogSpace-complete E ground.Proof. Assume E ground. first demonstrate membership.F O(sk(trerdfs (S)) erdfs-V ) theory contextual FOL equivalent contextual DL-LiteR knowledge base (by Proposition 7). E ground, then,straightforward consequence Theorems 2 3,erdfs-V) |=c F O(trerdfs (E)).|=erdf E iff F O(sk(trerdfs (S)) SEcontextual DL-LiteR theory c (resp., formula c ) straightforwardly rewrittencorresponding classical DL-LiteR theory (resp., formula )c |=c c iff |= .Since transformation linear size knowledge base, complexitydeciding satisfiability entailment contextual DL-LiteR knowledge basesDL-LiteR knowledge bases, namely NLogSpace (Calvanese et al., 2007).Hardness shown reduction known NLogSpace-hard problem: Graph reachability (Papadimitriou, 1994) encoded using subclass statements: edgesgraph represented RDF graph rdfs:subClassOf-triples reachableiff |=erdfs {hs, rdfs:subClassOf, ti}.result immediately leads following NP algorithm deciding |=erdf E,case E ground:1. Guess mapping blank nodes E ground terms F O(sk(trerdfs (S))erdfs-VSE ).erdfs-Verdfserdfs2. Check whether F O(sk(tr(S)) SE ) |=c F O(tr(E)).algorithm clearly sound complete, since theory F O(sk(trerdfs (S)) erdfs-VSE )universal.NP-hardness follows NP-hardness simple entailment (Proposition 10),straightforwardly encoded extensional RDFS entailment.551fide Bruijn & Heymansx-D-entailment arbitrary datatype maps obtain following novel lowerbound.Proposition 14. RDF graphs E datatype map deciding|=s-D E coNP-hard size S.Proof. proceed reduction complement graph k-colorability k 3,i.e., nonexistence k-coloring. problem coNP-complete (Gary & Johnson,1979):Instance: graph G = hV, Ei positive integer k |V | k 3.Question: k-coloring assignment nodes colors f : V {1, 2, . . . , k}two adjacent nodes share color, i.e., hu, vi E, f (u) 6= f (v).case k-coloring?Let datatype map includes rdf:XMLLiteral maps URIdatatype D(d) ordered value space cardinality k, let smallest RDFgraph that:every v V , hv, rdf:type, dievery hu, vi E, hu, R, vi S,R URI, let H = {h :x, R, :xi}, :x blank node.show G k-coloring |=s-D H.() Assume, contrary, 6|=s-D H, means s-D-interpretation |= 6|= H. Therefore, (*) IRhs, si IEXT(IS(R)). Consider hu, vi E; (*) IS(u) 6= IS(v). Sincehu, rdf:type, di, hv, rdf:type, di S, IS(u), IS(v) D(d), condition 20 Table 8.let f (v) = IS(v) every v V . f k-coloring, contradiction.() Analogously, exists k-coloring, one construct s-D-interpretationmodel S, H.polynomial (resp., logspace) datatype map datatype map holds0deciding well-typedness literals deciding L2V D(u) (s) = L2V D(u ) (s0 ) l =L2V D(u) (s), l plain literal (s, u), (s0 , u0 ) well-typed literals, donePTime (resp., LogSpace).Considering definite datatype maps, obtain following lower bound Theorem5 data complexity Datalog, exploiting Skolemization, analogous Corollary 1,exploiting fact need take account subset RDF(S)axiomatic triples, analogous Proposition 4.Proposition 15. Let definite polynomial datatype map. Then, decision problems|=s-D E, |=rdf-D E, |=rdfs-D E NP-complete combined size E,polynomial size S. E ground, respective problems PTime.turns that, analogous case without datatypes, refineupper bounds simple- rdf -entailment.Lemma 1. Let theory let logspace datatype map. Then, ()ncomputed LogSpace.552fiLogical Foundations RDF(S) DatatypesEntailment|=s ,|=rdf ,|=rdf|=s ,|=rdf|=rdf|=erdf|=erdfRestrictionsnonenonenonenonestand. RDFS|=erdfstand. RDFSRestrictions Enonegroundgroundnonestand. RDFSstand. RDFS,groundComplexityNP-completeLogSpaceP-completeNP-hardNP-completeNLogSpace-completeTable 2: Complexity Entailment |=x E RDF, measured combined sizeEEntailmentx=sx=rdfx=rdfsLogSpaceLogSpaceP-completeD*LogSpaceLogSpaceP-completedefiniteLogSpaceLogSpaceP-completecoNP-hardcoNP-hardcoNP-hardTable 3: Complexity Entailment |=x-D E |=x-D* E, measured sizeProof. WL denote set plain well-typed literals, < lexicographical ordering WL. l plain literal, define v l = l; (s, u) well-typedliteral, v (s,u) = L2V D(u)(s) . following algorithm returns representation literal00l WL LogSpace: iterate literals l0 < l, least literal l00 v l = v l00found; observe deciding l0 < l deciding v l = v l done LogSpace.lemma obtain following upper bound, considerations analogousProposition 11 fact axioms \rdf introduce recursion.Proposition 16. Let E RDF graphs let logspace datatype map. Then,problems |=s-D* E |=rdf-D* E decidable LogSpace size S,combined size graphs E ground.Furthermore, definite, problems |=s-D E |=rdf-D E decidableLogSpace size S, combined size graphs E ground.Table 2 summarizes complexity reasoning entailment regimes RDF;stand. RDFS stands standard use RDFS vocabulary; EE E S. results first fourth line table, upper boundground rdfs-entailment previously known (Gutierrez et al., 2004; de Bruijn et al.,2005; ter Horst, 2005). best knowledge, results novel.Table 3 summarizes complexity reasoning datatypes, measured sizeentailing graph S. Definite stands entailment restricted definite datatypemaps. LogSpace results require datatype map logspace well, i.e.,must decidable LogSpace whether two literals equal interpretation givenD. suspect many datatype maps interest logspace examplesXML schema datatypes (Peterson et al., 2009). upper bounds rdfs- rdfs-D*553fide Bruijn & Heymansentailment known literature (ter Horst, 2005). best knowledge,results table novel.6. Conclusions Future Workpresented embeddings different RDF entailment regimes F-Logic,shown deductive database description logic technology usedreasoning RDF.Known complexity results fields deductive databases description logicsresulted several novel upper bounds, particular, ground simple- rdf -entailmentLogSpace, respective extensions D* datatype semantics; non-ground(resp., ground) erdfs-entailment graphs standard use RDFS vocabularyNP (resp., NLogSpace). best knowledge first known upperbounds extensional RDFS entailment nontrivial subset RDF graphs.case extensions simple-, rdf -, rdfs-entailment datatype support, upperbounds non-ground ground entailment D* entailmentconsidering definite datatypes, require reasoning case.addition, established several lower bounds reductions knownhard problems. particular, rdfs-entailment turns PTime-hard simpleentailment extended datatype support turns coNP-hard, sizeentailing graph. also found matching lower bound NLogSpace resultground erdfs-entailment graphs standard use RDFS vocabulary.negative result concerning ground rdfs-entailment (i.e., PTime-hardness) mightcome surprise language seems far less expressive PTime-hardlanguages (e.g., variable-free Datalog (Dantsin et al., 2001) DL-LiteR,u , extensionDL-LiteR (Calvanese et al., 2007)). PTime-hardness proof suggests complexity originates possibility use RDFS vocabulary arbitrary places RDFstatements, e.g., rdfs:subPropertyOf object position triple. Indeed, groundentailment minimal RDFS fragment Munoz, Perez, Gutierrez (2009)decided O(nlogn).6 suspect minimal RDFS fragment extendedmany useful features, class property declarations RDFS metadatavocabulary, without compromising O(nlogn) upper bound. topic futurework.negative result concerning entailment, even considering RDFS vocabulary (i.e., coNP-hardness), suggests one restrict oneself weaker datatypesemantics D* one use definite datatype maps, precludesuse finite datatypes bool int (Peterson et al., 2009). latter approachtaken specification tractable fragments (also called profiles) OWL 2 (Motiket al., 2009a), datatype semantics similar semantics.investigation reported paper formed basis specificationcombinations RIF-BLD rules (RIF Working Group, 2010a), essentially Hornlogic formulas, RDF graphs. RIF RDF OWL specification (RIF WorkingGroup, 2010b) gives model-theoretic account semantics RIF-RDF combinations6. minimal RDFS disallows use RDF(S) vocabulary besides properties RDF(S)ontology vocabulary, allows use properties predicate position triples.554fiLogical Foundations RDF(S) Datatypessuggests combinations embedded RIF-BLD rules, basedembedding Section 3.2. particular challenge future work combination RDFgraphs extensions RIF-BLD allow nonmonotonic negation rules,interaction negation blank nodes.Another topic future investigation precise relationship extensionalRDFS OWL. particular, relationship extensional RDFS standard use RDFS vocabulary OWL 2 QL fragment OWL 2 (Motik et al.,2009a), based contextual DL-LiteR . embedding proof Proposition7 provides promising starting point.AcknowledgmentsJos de Bruijn partially supported European Commission projectsKnowledge Web (IST-2004-507482) ONTORULE (FP7 231875). Stijn Heymanspartially supported Austrian Science Fund (FWF) projects P20305 P20840European Commission project ONTORULE (FP7 231875).Appendix A. RDF(S) Semanticsappendix define notions RDF, RDFS, eRDFS, D* , interpretations(Hayes, 2004; ter Horst, 2005). Recall definition interpretation Section 3.1.RDF InterpretationsRDF vocabulary consists following symbols:rdf:type rdf:Property rdf:XMLLiteral rdf:nil rdf:List rdf:Statement rdf:subjectrdf:predicate rdf:object rdf:first rdf:rest rdf:Seq rdf:Bag rdf:value rdf:Altrdf: 1 rdf: 2 . . .RDF ontology vocabulary consists symbols rdf:type rdf:Property. Noterdf: i, positive integer i, part RDF vocabulary. Thus, RDFvocabulary infinite. remainder, omit prefix rdf: using RDFvocabulary.typed literal (s, XMLLiteral) well-typed XML literal lexical spaceXMLLiteral, defined (Klyne & Carroll, 2004, Section 5.1); XML value s,denoted xml (s), one-to-one correspondence s. lexical spaceXMLLiteral, (s, XMLLiteral) ill-typed XML literal.Given interpretation I, class extension object x IR set elementsconnected x via type, i.e., instances x. defined ICEXT(x) = {k | hk, xiIEXT(IS(type))}.interpretation vocabulary V = hC, PL, Li rdf-interpretation V includes RDF vocabulary conditions 14 Table 4 hold I.RDFS InterpretationsRDFS vocabulary consists of:rdfs:domain rdfs:range rdfs:Resource rdfs:Literal rdfs:Datatype rdfs:Classrdfs:subClassOf rdfs:subPropertyOf rdfs:member rdfs:Container rdfs:labelrdfs:ContainerMembershipProperty rdfs:comment rdfs:seeAlso rdfs:isDefinedBy555fide Bruijn & Heymans1234IS(type), IS(subject), IS(predicate), IS(object), IS(first), IS(rest),IS(value), IS( 1), IS( 2), . . . IPIS(nil) ICEXT(IS(List))IP = ICEXT(IS(Property))(s, XMLLiteral) L well-typed XML literal,IL((s, XMLLiteral)) = xml (s), IL((s, XMLLiteral)) LV,IL((s, XMLLiteral)) ICEXT(IS(XMLLiteral))(s, XMLLiteral) L ill-typed XML literal,IL((s, XMLLiteral))/ LV IL((s, XMLLiteral))/ ICEXT(IS(XMLLiteral))Table 4: Conditions RDF interpretationsRDFS ontology vocabulary consists symbols rdfs:subClassOf, rdfs:subPropertyOf, rdfs:domain, rdfs:range, rdfs:Class, rdfs:Datatype. remainderomit prefix rdfs: using RDFS vocabulary.say rdf -interpretation vocabulary V rdfs-interpretation Vincludes RDFS vocabulary conditions 515 depicted Table 5 hold I.shortcut, define IEXTp (o) = {s | hs, IS(o)i IEXT(IS(p))}.RDF (resp, RDFS) axiomatic triple triple satisfied every rdf -(resp,rdfs-) interpretation. Conditions 1 5 correspond RDF(S) axiomatic triplesfollowing way; see also (Hayes, 2004, Sections 3.1 4.1):IS(s) IP corresponds axiomatic triple hs, type, rdf:Propertyi,IS(s) IEXTp (o) corresponds axiomatic triple hs, p, oi,IS(s) ICEXT(IS(c)) corresponds axiomatic triple hs, type, ci.Extensional RDFS Interpretations normative RDFS semantics, reviewed above,also called intensional RDFS semantics. RDF semantics specification (Hayes,2004) also defines extensional RDFS semantics (eRDFS).rdfs-interpretation erdfs-interpretation conditions depicted Table 6hold.D* Interpretations Given vocabulary V simple datatype map D, s-interpretation V s-D*-interpretation V includes dom(D) conditions 1619 Table7 satisfied u dom(D).Given vocabulary V datatype map D, rdf (resp., rdfs, erdfs)-interpretationV rdf -D* (resp., rdfs-D* , erdfs-D* )-interpretation s-D* -interpretation.Interpretations Given vocabulary V simple datatype map D, s-D* -interpretation V s-D-interpretation satisfies conditions 2022 Table 8u dom(D).Given vocabulary V datatype map D, rdf (resp., rdfs, erdfs)-interpretationV rdf -D (resp., rdfs-D, erdfs-D)-interpretation s-D-interpretation.556fiLogical Foundations RDF(S) Datatypes56789101112131415IS(type), IS(member), IS(seeAlso), IS(isDefinedBy), IS(comment),IS(label), IS(value), IS( 1), IS( 2), . . . IEXTdomain (Resource)IS(domain), IS(range), IS(subPropertyOf) IEXTrdfs:domain (Property)IS(subClassOf) IEXTrdfs:domain (Class)IS(subject), IS(predicate), IS(object) IEXTdomain (Statement)IS(first), IS(rest) IEXTdomain (List)IS(subject), IS(predicate), IS(object), IS(member), IS(first), IS(seeAlso),IS(isDefinedBy), IS(value), IS( 1), IS( 2), . . . IEXTrange (Resource)IS(comment), IS(label) IEXTrange (Literal)IS(subPropertyOf) IEXTrange (Property)IS(type), IS(domain), IS(range), IS(subClassOf) IEXTrange (Class)IS(rest) IEXTrange (List)IS(Alt), IS(Bag), IS(Seq) IEXTsubClassOf (Container)IS(ContainerMembershipProperty) IEXTsubClassOf (Property)IS(isDefinedBy) IEXTsubPropertyOf (seeAlso)IS(XMLLiteral) ICEXT(IS(Datatype))IS(XMLLiteral) IEXTsubClassOf (Literal)IS(Datatype) IEXTsubClassOf (Class)IS( 1), IS( 2), . . . ICEXT(IS(ContainerMembershipProperty))IR = ICEXT(IS(Resource))LV = ICEXT(IS(Literal))hx, yi IEXT(IS(domain)) hu, vi IEXT(x), u ICEXT(y)hx, yi IEXT(IS(range)) hu, vi IEXT(x), v ICEXT(y)IEXT(IS(subPropertyOf)) transitive reflexive IPhx, yi IEXT(IS(subPropertyOf)), IEXT(x) IEXT(y)x ICEXT(Class), x IEXTsubClassOf (Resource)hx, yi IEXT(IS(subClassOf)), ICEXT(x) ICEXT(y)IEXT(IS(subClassOf)) transitive reflexive ICEXT(Class)x ICEXT(ContainerMembershipProperty), x IEXTsubPropertyOf (member)x ICEXT(Datatype), x IEXTsubClassOf (Literal)Table 5: Conditions RDFS interpretations7080100120hx, yi IEXT(IS(domain)) (if hu, vi IEXT(x), u ICEXT(y))hx, yi IEXT(IS(range)) (if hu, vi IEXT(x), v ICEXT(y))hx, yi IEXT(IS(subPropertyOf)) x, IP IEXT(x) IEXT(y)hx, yi IEXT(IS(subClassOf))x, ICEXT(Class) ICEXT(x) ICEXT(y)Table 6: Conditions eRDFS interpretations557fide Bruijn & Heymans16 IS(u) = D(u)17 IS(u) ICEXT(IS(Datatype))(s, u) L LD(u) , IL((s, u)) = L2V D(u) (s) LV18IL((s, u)) ICEXT(D(u))(s, u) L/ LD(u) , IL((s, u))/ LV19IL((s, u))/ ICEXT(D(u))Table 7: Conditions D* interpretations20 ICEXT(IS(u)) = V D(u) LV(s, u0 ) L, IS(u0 ) = IS(u) LD(u) ,21IL((s, u0 )) = L2V D(u) (s)22 (s, u0 ) L, IS(u0 ) = IS(u)/ LD(u) , IL((s, u0 ))/ LVTable 8: Conditions D-interpretationsAppendix B. Embeddingsappendix contains axiomatization x entailment regimes x {s, rdf, rdf,erdfs} axiomatization datatype entailment regimes x-D* , x-D , referencedSections 3 4.Following convention Appendix omit prefixes rdf: rdfs: usingRDF RDF vocabularies.B.1 RDF Entailment Regimesaxiomatization s, rdf , rdfs, erdfs entailment regimes, denoted x ,x {s, rdf, rdfs, erdfs}, defined Table 9.B.2 Datatype Entailment Regimesaxiomatization D* entailment regimes, denoted x-D* x-D , respectively, x {s, rdf, rdfs, erdfs}, defined Table 10.Note entailment requires whenever two URIs mappedindividual given interpretation, URIs used interchangeably typed literals.However, since equality URIs cannot stated RDF(S) indeed inferredneed consider case embeddings.B.3 Extensional RDFSLet V = hC, PL, Li vocabulary. mapping function trerdfs , defined Section3.3, deals eRDFS semantics RDF(S) vocabulary directembedding. define theory erdfs-V , deals remainderRDF(S) vocabulary.558fiLogical Foundations RDF(S) Datatypes=rdf = {tr(hs, p, oi) | hs, p, oi RDF axiomatic triple}{t[type XMLLiteral] | L well-typed XML literal}{illD(t) | L ill-typed XML literal}{x(y, z(y[x z]) x[type Property]),x(x[type XMLLiteral] illD(x) )}rdfs = rdf {tr(hs, p, oi) | hs, p, oi RDFS axiomatic triple}{t[type Literal] | PL}{x(x[type Resource]),u, v, x, y(x[domain y] u[x v] u[type y]),u, v, x, y(x[range y] u[x v] v[type y]),x(x[type Property] x[subPropertyOf x]),x, y, z(x[subPropertyOf y] y[subPropertyOf z] x[subPropertyOf z]),x, y(x[subPropertyOf y] z1 , z2 (z1 [x z2 ] z1 [y z2 ])),x(x[type Class] x[subClassOf Resource]),x, y(x[subClassOf y] z(z[type x] z[type y])),x(x[type Class] x[subClassOf x]),x, y, z(x[subClassOf y] y[subClassOf z] x[subClassOf z]),x(x[type ContainerMembershipProperty] x[subPropertyOf member]),x(x[type Datatype] x[subClassOf Literal]),x(x[type Literal] illD(x) )}erdfs = rdfs {x, y(u, v(u[x v] u[type y]) x[domain y]),x, y(u, v(u[x v] v[type y]) x[range y]),x, y(x[type Property] y[type Property] u, v(u[x v]u[y v]) x[subPropertyOf y]),x, y(x[type Class] y[type Class] u(u[type x] u[type y])x[subClassOf y])}Table 9: Axiomatization RDF entailment regimes.erdfs-V = {trerdfs (hs, p, oi) | hs, p, oi RDF(S) axiomatic triplestandard use RDF(S) vocabulary}{t : XMLLiteral | L well-typed XML literal}{t : illxml | L ill-typed XML literal}{t : Literal | PL}{x(x : Literal x : illxml )}Appendix C. Proofsappendix contains proofs propositions theorems Sections 3 4.C.1 Proof Proposition 2Consider generalized RDF graph S, interpretation = hIR, IP, IS, IEXTiholds IP = IR includes every term S, IS(c) = c URI c, IL(l) = ltyped literal l, every triple hs, p, oi S, (s, o) IEXT (p), blank node559fide Bruijn & HeymansV -D*-= = {l = (s, u) | l PL, (s, u) L well-typed literal,l = L2V D(u) (s)}{(s, u) = (s0 , u0 ) | (s, u), (s0 , u0 ) L distinct well-typed literals0L2V D(u) (s) = L2V D(u ) (s0 )}x-D* = x V -D*-={(s, u)[type u] | (s, u) L well-typed literal}{illD(t) | L ill-typed literal}{u[type Datatype] | u dom(D)}{x(illD(x) x[type u] ) | u dom(D)}x-D = x-D*{(s, u0 )[type u] | (s, u0 ) L well-typed literal,0u dom(D), L2V D(u ) (s) V D(u) }{s[type u] | PL, u dom(D), V D(u) }{x(x[type u] dt(x, u)) | u dom(D)}{x(dt(x, u1 ) dt(x, u2 )) | u1 , u2 dom(D).V D(u1 ) V D(u2 ) = }{dt(l, u) | l PL, u dom(D), l 6 V D(u) }0{dt((s, u), u0 ) | (s, u) L, u0 dom(D), L2V D(u) (s) 6 V D(u ) }Table 10: Axiomatization datatype entailment regimes, x {s, rdf, rdfs, erdfs}.assignment : bl(S) IR maps every blank node itself. Clearly, (I, A) |= S, |= S,s-interpretation. Therefore, s-satisfiable.easy see following generalized RDF graph rdf -, hence rdfs-erdfs-unsatisfiable, negation condition 4 Table 4:= {h(<notXML, XMLLiteral), type, XMLLiterali}: (<notXML, XMLLiteral)ill-typed XML literal, condition 4 Table 4, IL((<notXML, XMLLiteral))/ICEXT(IS(XMLLiteral)). However, graph satisfied rdf -interpretation,must case IL((<notXML, XMLLiteral)) ICEXT(IS(XMLLiteral)), contradiction.Hayes (2004) observed one create similar situation normal RDF graphrange constraint; graph rdfs- hence erdfs-unsatisfiable.C.2 Proof Theorem 1first show 6|=x E iff tr(S) x 6|=f tr(E). follows immediately|=x E iff tr(S) x |=f tr(E).() Let V = hC, PL, Li vocabulary E let L F-languageconforms V . Assume 6|=x E. means x-interpretation= hIR, IP, LV, IS, IL, IEXTi |= 6|= E. construct correspondingF-structure = hU, U , IC , , IP following way:(i) U = IR IP,(ii) (t) = IS(t) every URI reference C, (t) = every plain literal PL,(t) = IL(t) every typed literal L,560fiLogical Foundations RDF(S) Datatypes(iii) (k) = IEXT(k) every k IP (k) = every k/ IP,(iv) IP (illD) = {u | L ill-typed XML literal IL(t) = u}.straightforward verify |=f tr(S) x I6|=fx 6|=f tr(E).tr(E).Hence, tr(S)() Assume tr(S) x 6|=f tr(E). means (by (Fitting, 1996, Theorem 5.9.4)Proposition 6) Herbrand F-structure = hU, U , IC , , IP|=f tr(S) x I6|=f tr(E). Since Herbrand F-structure, U includes constantsymbols, IC maps every constant symbol itself. construct correspondinginterpretation = hIR, IP, LV, IS, IL, IEXTi follows:(i) IP = {p | hp, (Property)i (IF (type))} {p | s, o.hs, oi (p)},(ii) LV = PL {xml(s) | ((s, XMLLiteral) L (s, XMLLiteral) well-typed XMLliteral)} {l | hl, (Literal)i (IF (type))},(iii) IR = U LV,(iv) IS(t) = (t) every URI C, IL((s, u)) = xml(s) (s, u) L well-typedXML literal; IL((s, u)) = ((s, u)) (s, u) L (s, u) L well-typedXML literal,(v) p U hs, oi (p): hs0 , o0 IEXT(p), s0 (resp., o0 ) is:(t, XMLLiteral) L (t, XMLLiteral) well-typed XML literal((t, XMLLiteral)) = (resp., = o), s0 = xml(t) (resp., o0 = xml(t));otherwise s0 = (resp., o0 = o).One verify x-interpretation, |= S, 6|= E. Hence, 6|= E.second part theorem shown analogously.C.3 Proof Proposition 4Corollary 1 |=x E iff sk(tr(S)) x |=f tr(E). Therefore, needshow sk(tr(S)) xSE |=f tr(E) iff sk(tr(S)) x |=f tr(E).() Trivial, since sk(tr(S)) xSE sk(tr(S)) x .() Consider case x = erdfs. Let minimal Herbrand model sk(tr(S)) xlet I0 obtained removing triples involving container membership propertiesn appear x \xSE . verify, e.g., case analysis shapetriples S, I0 minimal model sk(tr(S)) xSE . Similarly, one verify|=f tr(E), I0 |=f tr(E).Analogous x {s, rdf, rdfs}.C.4 Proof Theorem 2prove directions contraposition.() Assume trerdfs (S) erdfs-V 6|=f trerdfs (E). means Herbrand Fstructure = hU, U , IC , , IP |=f trerdfs (S) erdfs-V I6|=f trerdfs (E).561fide Bruijn & Heymansdefine xml0 (x) = xml(s) x well-typed XML literal (s, XMLLiteral); otherwisexml0 (x) = x. construct corresponding interpretation = hIR, IP, LV, IS, IL, IEXTifollows:(i) LV = {xml0 (l) | l U (Literal)},(ii) IP = IR = U LV {type, subClassOf, domain, range, subPropertyOf},(iii) IS(t) = every URI reference S, E, RDF(S) vocabulary,(iv) IL(t) = xml0 (t) L,(v) p U hs, oi (p), hxml0 (s), xml0 (o)i IEXT(p),(vi) IEXT(type) smallest relation(a) IEXT(type) {hxml0 (s), xml0 (o)i | U o};(b) ICEXT(Resource) = ICEXT(Class) = IR;(c) ICEXT(Property) = IP,(vii) IEXT(domain) set tuples hx, yi, x, IR, (if hu, vi IEXT(x),u ICEXT(y)); analogous IEXT(subClassOf), IEXT(subPropertyOf),IEXT(range) (see Table 6 precise conditions).One verify |= S, 6|= E, since E standard use RDFSvocabulary, E include occurrences Resource, Class, Property, classproperty vocabularies E subsets respective vocabularies S.clearly satisfies conditions 14 Table 4, conditions 615 Table 5, conditions07 120 Table 6. verify satisfies condition 5 Table 4 one needs keepmind ICEXT(Resource) = ICEXT(Class) = IR ICEXT(Property) = IP. So,erdfs-interpretation thus 6|=erdfs E.() Assume 6|=erdf E. means erdfs-interpretation I0 that,URI t, IS(t) = (making I0 similar Herbrand interpretation) I0 |=I0 6|= E. Let = hIR, IP, LV, IS, IL, IEXTi erdfs-interpretation obtained I0IP = IR ICEXT(IS(Class)) = IR, IEXT minimally extendedsatisfy semantic conditions Tables 4, 5, 6. Clearly, musterdfs-interpretation |= S. also have, restrictions class propertyvocabularies well non-occurrence E Resource, Class, Property,6|= E.construct corresponding F-Logic interpretation = hU, U , IC , , IP follows:(i) U = IR, (ii) (t) = every URI plain literal t, (t) = every L, (iii)(k) = IEXT(k) every k U , (iv) U = IEXT(IS(type)).straightforwardly verified |=f trerdfs (S) erdfs-V I6|=f trerdfs (E).Therefore, must case trerdfs (S) erdfs-V 6|=f trerdfs (E).562fiLogical Foundations RDF(S) DatatypesC.5 Proof Proposition 7obtained F O(trerdfs (S) erdfs-V ) following way:(i) Class membership property value statements forms A(a), P (a1 , a2 )included such,(ii) Subclass subproperty statements included such,(iii) Domain constraints form x, y(P (x, y) A(x)) rewritten role-typingstatements form x(y(P (x, y)) A(x)),(iv) Range constraints form x, y(P (x, y) A(y)) rewritten role-typing statements form x(y(P (y, x)) A(x)),(v) Constraints form x(A(x) B(x) ) rewritten x(A(x) B(x)).F O(trerdfs (S)) obviously equivalent, easy verify FOLequivalent contextual DL-LiteR knowledge base.C.6 Proof Theorem 4first establish second part theorem, i.e., x-D*-satisfiable iff tr(S) x-D*model.() Let V = hC, PL, Li vocabulary let L F-language conformsV . Assume x-D*-satisfiable. means x-D*-interpretation= hIR, IP, LV, IS, IL, IEXTi |= S. construct corresponding F-structure= hU, U , IC , , IP following way (analogous constructiondirection proof Theorem 1):(i) U = IR IP,(ii) (t) = IS(t) every URI reference C, (t) = every plain literal PL,(t) = IL(t) every typed literal L,(iii) (k) = IEXT(k) every k IP,(iv) IP (illD) = {u | L ill-typed literal IL(t) = u}.Clearly, |=f tr(S).literal L ill-typed XML literal, clearly ill-typed literal.Then, ill-typed literal IS(t) LV (by condition 19 Table 7),hence ill-typed literal IS(t) ICEXT(Literal) IS(t)ICEXT(XMLLiteral), condition 4 Table 4 (if x = rdf, x = rdfs, x = erdfs)condition 6 Table 5 (if x = rdfs x = erdfs). Satisfaction x establishedstraightforwardly.Consider well-typed literal (s, u) plain literal l. case l = L2V D(u) (s),IL((s, u)) = l, condition 18 Table 7, thus ((s, u)) = (l) = l |=f l = (s, u),(ii). Analogous case two distinct well-typed literals. Therefore, |=f V -D*-= .563fide Bruijn & HeymansConsider definition x-D* Table 10. established |=f xSatisfaction second, first, third, fourth sets formulas tablefollows immediately from, respectively, (iv), conditions 18, 17, 19 Table 7.Therefore, |=f x-D* .establishes |=f tr(S) x-D* .V -D*-= .() Assume tr(S) x-D* model. Let = tr(S) x-D* .Let obtained replacing every occurrence = addingusual congruence axioms (cf. Fitting, 1996, Chapter 9). known axiomatizationequality preserves satisfiability entailment first-order logic (Fitting, 1996, Theorem9.3.9). also case F-Logic, Proposition 1.extend signature set URI references C 0 , disjoint C,cardinality |bl(S)|; i.e., signature 0 = hC PL L C 0 , P {}i. Sincemodel (as has), exists, classical results, Herbrand F-structure|=f . U = C C 0 PL L.u U , define follows:u C u dom(D), (u) = D(u),(s, u) L well-typed literal u dom(D), ((s, u)) = L2V D(u) (s),otherwise, (u) = u.construct corresponding interpretation = hIR, IP, LV, IS, IL, IEXTi:(i) IP = {(p) | hp, (Property)i (IF (type))} {(p) | s, o.hs, oi (p)},(ii) LV = PL {L2V D(u) (s) | (s, u) L, u dom(D), (s, u) well-typed literal)}{(l) | hl, (Literal)i (IF (type)) & (x = rdfs x = erdfs)},(iii) IR = U LV,(iv) IS(u) = (u) every URI reference u C; IL((s, u)) = ((s, u)) every (s, u)L,(v) p IP, IEXT smallest set hs, oi (p) implies h(s), (o)iIEXT((p)).easy see |= S. Remains verify x-D*-interpretation. Verifyingx-interpretation straightforward. remains verify satisfactionconditions Table 7.Satisfaction condition 16 follows directly definition . condition17, u dom(D) thus u[type Datatype] x-D* . satisfies x-D*hIF (u), (Datatype)i (IF (type)), h(IF (u)), (IF (Datatype))iIEXT((IF (type))). construction IS, yields IS(u) ICEXT(IS(Datatype)).Consider (s, u) L u dom(D) LD(u) . Then, (s, u) welltyped, IL((s, u)) = L2V D(u) (s) LV. definition x-D* , (s, u)[typeu] x-D* ; follows L2V D(u) (s) ICEXT(D(u)). establishes satisfactioncondition 18.564fiLogical Foundations RDF(S) DatatypesCondition 19 satisfied fact LV contain ill-typed literals. Indeed,PL {L2V D(u) (s) | (s, u) L, u dom(D), (s, u) well-typed literal)}contain ill-typed literals x rdfs erdfs, ill-typed literal|=f t[type Literal], last axiom definition rdfs Table 9.easy verify, directions, 6|= E iff I6|=f tr(E). first parttheorem follows.C.7 Proof Theorem 5first show correspondence satisfiability.() Let V = hC, PL, Li vocabulary E, let rdf x-D-interpretationsatisfies let L F-language conforms V . construct Fstructure = hU, U , IC , , IP corresponds I, using steps (i)(iv) ()direction proof Theorem 4, additional step(v) IP (dt) = {hx, ui | x ICEXT(u) u ran(D)}.argument () direction proof Theorem 4 follows |=f tr(S)x-D* . Consider x-D \ x-D* , defined Table 10. Satisfaction first set followsimmediately conditions 20 21 Table 8. Satisfaction second set followsimmediately condition 20 Table 8. Satisfaction third set follows immediately(v).Consider two u1 , u2 dom(D) V D(u1 ) V D(u2 ) = . condition 20Table 8, ICEXT(IS(u1 ))ICEXT(IS(u2 )) = . (v) follows k Uhk, (u1 )i IP (dt) hk, (u2 )i IP (dt). Consequently, I6|=f x(dt(x, u1 )dt(x, u2 )) thus fourth set sentences satisfied.Consider (s, u) L u0 dom(D) IL((s, u)) = L2V D(u) (s)/0)0D(uV. condition 20 Table 8, ICEXT(IS(u0 )) = V D(u ) , thus IL((s, u))/000ICEXT(IS(u )). (v) follows hIF ((s, u)), (u )i/ IP (dt) thus I6|=f dt((s, u), u ),establishing satisfaction sixth set. argument fifth set obtainedreplacing (s, u) L l PL.thus obtain |=f x-D . Therefore, tr(S) x-D model.() Assume = tr(S) x-D model.Let obtained proof Theorem 4 let = hU, U , IC ,, IP Herbrand F-structure model . construct correspondinginterpretation = hIR, IP, LV, IS, IL, IEXTi following way. W.l.o.g. assumevalue space V , ran(D), contains typed literal L.observe (*) two d1 , d2 dom(D) must hold either V D(d1 )D(d2 ) disjoint overlap infinite, since definite. addition, V D(d1 )VV D(d2 ) disjoint, then, satisfaction fourth set definition x-D , (**)I6|=f t[type d1 ] t[type d2 ] C C 0 .given URI u C C 0 define mapping follows:u dom(D), (u) = D(u),hu, u0 (type), u0 dom(D), (u) = v, v565fide Bruijn & Heymansv V D(u1 ) V D(un ) , u1 , . . . , un dom(D) datatypeidentifiers hu, u1 i, . . . , hu, un (type);u0 C v = (u0 );0(s, u0 ) L u0 dom(D) v = L2V D(u ) (s);v must exist, u cannot member two disjoint datatypes, (**),V D(u1 ) V D(un ) infinite set, Definition 4,otherwise, (u) = u.given literal l PL L define as:l = (s, u) L well-typed literal, (s, u) = L2V D(u) (s),otherwise (l) = (l).One verify two distinct t1 , t2 C PL L, either (t1 ) =(t2 ) ht1 , t2 IP () (by definition V -D*-= ) (t1 ) 6= (t2 ).construct RDF interpretation = hIR, IP, LV, IS, IL, IEXTi, similar construction () direction proof Theorem 4. Note respective constructions differ steps (ii) (v).(i) IP = {(p) | hp, (Property)i (IF (type))} {(p) | s, o.hs, oi (p)},(ii) LV = PL {V | ran(D)} {(l) | hl, (Literal)i (IF (type)) & (x =rdfs x = erdfs)},(iii) IR = U LV,(iv) IS(u) = (u) every u C; IL((s, u)) = ((s, u)) every (s, u) L,(v) IEXT smallest setICEXT(IS(u)) = V D(u) every u dom(D),p IP hs, oi (p), h(s), (o)i IEXT((p)).Satisfaction conditions including 19 established analogous ()direction proof Theorem 4. Notice condition 20 satisfied (v).Consider typed literal = (s, u0 ) L datatype identifier u dom(D).IS(u0 ) = IS(u), must case D(u0 ) = D(u), construction I.00LD(u ) , (s, u0 ) well-typed literal, thus IL((s, u0 )) = L2V D(u ) = L2V D(u) ,0(iv)./ LD(u ) , (s, u0 ) ill-typed literal IL((s, u0 )) = (s, u0 )/ LV,LV contain ill-typed literals. Therefore, conditions 21 22 Table 8satisfied.Consequently, x-D-interpretation. |= thus x-Dsatisfiable.second part theorem follows observation that, directions,6|= E iff I6|=f tr(E).566fiLogical Foundations RDF(S) DatatypesReferencesAbiteboul, S., Hull, R., & Vianu, V. (1995). Foundations Databases. Addison-Wesley.Borgida, A. (1996). relative expressiveness description logics predicate logics.Artificial Intelligence, 82 (12), 353367.Brickley, D., & Guha, R. V. (2004). RDF vocabulary description language 1.0: RDF schema.Recommendation 10 February 2004, W3C.Calvanese, D., Giacomo, G. D., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractablereasoning efficient query answering description logics: dl-lite family. JournalAutomated Reasoning, 39, 385429.Dantsin, E., Eiter, T., Gottlob, G., & Voronkov, A. (2001). Complexity expressivepower logic programming. ACM Computing Surveys (CSUR), 33 (3), 374425.de Bruijn, J., Franconi, E., & Tessaris, S. (2005). Logical reconstruction normative RDF.Proceedings Workshop OWL: Experiences Directions (OWLED-2005).de Bruijn, J., & Heymans, S. (2007). Logical foundations (e)RDF(S): Complexityreasoning. Proceedings 6th International Semantic Web Conference(ISWC2007), pp. 8699. Springer.de Bruijn, J., & Heymans, S. (2008). relationship description logic-basedf-logic-based ontologies. Fundamenta Informaticae, 82 (3), 213236.Fitting, M. (1996). First Order Logic Automated Theorem Proving (second edition).Springer.Gary, M. R., & Johnson, D. S. (1979). Computers Intractability GuideTheory NP-Completeness. W.H. Freeman Company, New York, NY, USA.Gutierrez, C., Hurtado, C., & Mendelzon, A. O. (2004). Foundations semantic webdatabases. Proceedings 23rd ACM Symposium Principles DatabaseSystems (PODS2004), pp. 95106. ACM Press.Gutierrez, C., Hurtado, C. A., Mendelzon, A. O., & Perez, J. (2010). Foundationssemantic web databases. Journal Computer System Sciences. Press.Hayes, P. (2004). RDF semantics. Recommendation 10 February 2004, W3C.Jones, N. D., & Laaser, W. T. (1974). Complete problems deterministic polynomialtime. Proceedings 6th Annual ACM Symposium Theory Computing(STOC1974), pp. 4046, Seattle, Washington, USA. ACM Press.Kifer, M., Lausen, G., & Wu, J. (1995). Logical foundations object-oriented framebased languages. Journal ACM, 42 (4), 741843.Klyne, G., & Carroll, J. J. (2004). Resource description framework (RDF): Conceptsabstract syntax. Recommendation 10 February 2004, W3C.Motik, B., Grau, B. C., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2009a). OWL 2 webontology language profiles. Recommendation 27 October 2009, W3C.Motik, B., Patel-Schneider, P. F., & Parsia, B. (2009b). OWL 2 web ontology languagestructural specification functional-style syntax. Recommendation 27 October2009, W3C.567fide Bruijn & HeymansMunoz, S., Perez, J., & Gutierrez, C. (2009). Simple efficient minimal RDFS. JournalWeb Semantics, 7 (3), 220234.Papadimitriou, C. H. (1994). Computational Complexity. Addison Wesley.Patel-Schneider, P. F., Hayes, P., & Horrocks, I. (2004). OWL web ontology languagesemantics abstract syntax. Recommendation 10 February 2004, W3C.Peterson, D., Gao, S., Malhotra, A., Sperberg-McQueen, C. M., & Thompson, H. S. (2009).W3C XML schema definition language (XSD) 1.1 part 2: Datatypes. Working draft3 December 2009, W3C.RIF Working Group (2010a). RIF basic logic dialect. Recommendation 22 June 2010, W3C.RIF Working Group (2010b). RIF RDF OWL compatibility. Recommendation 22 June2010, W3C.ter Horst, H. J. (2005). Completeness, decidability complexity entailment RDFschema semantic extension involving OWL vocabulary. Journal WebSemantics, 3 (23), 79115.Yang, G., Kifer, M., & Zhao, C. (2003). FLORA-2: rule-based knowledge representation inference infrastructure semantic web. Proceedings Second International Conference Ontologies, Databases Applications Semantics(ODBASE2003). Springer.568fiJournal Artificial Intelligence Research 38 (2010) 687-755Submitted 01/10; published 08/10Automatic Induction Bellman-Error FeaturesProbabilistic PlanningJia-Hong WuRobert GivanJW @ ALUMNI . PURDUE . EDUGIVAN @ PURDUE . EDUElectrical Computer EngineeringPurdue University, W. Lafayette, 47907 USAAbstractDomain-specific features important representing problem structure throughout machinelearning decision-theoretic planning. planning, state features provided, domainindependent algorithms approximate value iteration learn weighted combinationsfeatures often perform well heuristic estimates state value (e.g., distancegoal). Successful applications real-world domains often require features crafted human experts. Here, propose automatic processes learning useful domain-specific feature setslittle human intervention. methods select add features describe state-space regions high inconsistency Bellman equation (statewise Bellman error) approximatevalue iteration. method applied using real-valued-feature hypothesis spacecorresponding learning method selecting features training sets state-value pairs.evaluate method hypothesis spaces defined relational propositional featurelanguages, using nine probabilistic planning domains. show approximate value iterationusing relational feature space performs state-of-the-art domain-independent stochasticrelational planning. method provides first domain-independent approach plays Tetrissuccessfully (without human-engineered features).1. Introductionsubstantial gap performance domain-independent planners domainspecific planners. Domain-specific human input able produce effective plannerscompetition planning domains well many game applications backgammon, chess,Tetris. deterministic planning, work TLPLAN (Bacchus & Kabanza, 2000) shownsimple depth-first search domain-specific human input, form temporal logic formulasdescribing acceptable paths, yields effective planner wide variety competition domains.stochastic planning, feature-based value-function representations used humanselected features great success applications backgammon (Sutton & Barto, 1998;Tesauro, 1995) Tetris (Bertsekas & Tsitsiklis, 1996). usage features provided human experts often critical success systems using value-function approximations.Here, consider problem automating transition domain-independent planningdomain-specific performance, replacing human input automatically learned domain properties. thus study style planner learns encountering problem instances improveperformance subsequently encountered problem instances domain.focus stochastic planning using machine-learned value functions represented linearcombinations state-space features. goal augment state-space representationc2010AI Access Foundation. rights reserved.fiW U & G IVANplanning new machine-discovered features facilitate accurate representationvalue function. resulting learned features used representing value functionproblem instances domain, allowing amortization learning costs acrosssolution multiple problem instances. Note property contrast competitionplanners, especially deterministic planning, retain useful information problem instances. Thus, approach solving planning problems regarded automaticallyconstructing domain-specific planners, using domain-independent techniques.learn features correlate well statewise Bellman error value functions encountered planning, using provided feature language corresponding learner selectfeatures space. evaluate approach using relational propositional featurespaces. recent approaches acquiring features stochastic planning substantial differences approach discuss detail Section 5 (Patrascu, Poupart,Schuurmans, Boutilier, & Guestrin, 2002; Gretton & Thiebaux, 2004; Sanner & Boutilier, 2009;Keller, Mannor, & Precup, 2006; Parr, Painter-Wakefield, Li, & Littman, 2007). previous workevaluated selection relational features correlation statewise Bellman error.Recent theoretical results (Parr et al., 2007) uncontrolled Markov processes show exactly capturing statewise Bellman error new features, repeatedly, lead convergenceuncontrolled optimal value value function selected linear-fixed-point methods weighttraining. Unfortunately machine-learning approaches selecting features, resultstransferred approximations statewise Bellman-error features: case, resultswork Parr et al. (2007) weaker imply convergence. Also, none theory transferred controlled case interest here, analysis muchdifficult effective (greedy) policy consideration value-function trainingchanging.consider controlled case, known theoretical properties similar Parret al. (2007) shown. Lacking theory, purpose demonstrate capabilitystatewise Bellman error features empirically, rich representations require machinelearning techniques lack approximation guarantees. Next, give overview approach, introducing Markov decision processes, value functions, Bellman error, feature hypothesislanguages feature learning methods.use Markov decision processes (MDPs) model stochastic planning problems. MDPformal model single agent facing sequence action choices pre-defined action space,transitioning within pre-defined state space. assume underlying stationarystochastic transition model available action state transitions occur accordingagents action choices. agent receives reward action choice according statevisited (and possibly action chosen), objective accumulating much rewardpossible (possibly favoring reward received sooner, using discounting, averaging time,requiring reward received finite horizon).MDP solutions represented state-value functions assigning real numbers states. Informally, MDP solution techniques, desire value function respects action transitionsgood states either large immediate rewards actions available leadgood states; well-known property formalized Bellman equations recursivelycharacterize optimal value function (see Section 2). degree given value functionfails respect action transitions way, formalized next section, referredBellman error value function, computed state.688fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGIntuitively, statewise Bellman error high magnitude regions state spaceappear undervalued (or overvalued) relative action choices available. state highBellman error locally inconsistent value function; example, state inconsistently labeledlow value action available leads high-value states. approachuse machine learning fit new features regions local inconsistency current valuefunction. fit perfect, new features guarantee represent Bellman updatecurrent value function. Repeated Bellman updates, called value iteration, knownconverge optimal value function. add learned features representationtrain improved value function, adding new features available feature set.method learning new features using approximate value functionregarded boosting-style learning approach. linear combination featuresviewed weighted combination ensemble simple hypotheses. new feature learnedviewed simple hypothesis selected match training distribution focused regionsprevious ensemble getting wrong (as reflected high statewise Bellman error throughoutregion). Growth ensemble sequentially adding simple hypotheses selected correcterror ensemble far refer boosting style learning.important note method scores candidate features correlation statewiseBellman error current value function, minimizing statewise Bellman errorvalue function found using new candidate feature. pre-feature-addition scoring muchless expensive scoring involves retraining weights new feature, especiallyrepeated many times different candidates, relative current value function.use pre-feature-addition scoring select features controlled setting enables muchaggressive search new features previously evaluated post-feature-addition approachdiscussed work Patrascu et al. (2002).approach considered selecting features feature-description languagelearning method exists effectively select features match state-value training data.consider two different feature languages empirical evaluation. Human-constructedfeatures typically compactly described using relational language (such English) whereinfeature value determined relations objects domain. Likewise, considerrelational feature language, based domain predicates basic domain description. (Thedomain description may written, example, standard planning language PPDDLYounes, Littman, Weissman, & Asmuth, 2005.) Here, take logical formulas one free variablerepresent features count number true instantiations formula stateevaluated. example, number holes feature used many Tetris experiments(Bertsekas & Tsitsiklis, 1996; Driessens, Ramon, & Gartner, 2006) interpreted countingnumber empty squares board filled squares them.numeric features provide mapping states natural numbers.addition relational feature language, consider using propositional feature representation learning structure. Although propositional representation less expressiverelational one, exist effective off-the-shelf learning packages utilize propositional representations. Indeed, show reformulate feature learning taskrelated classification problem, use standard classification tool, decision-tree learner C4.5(Quinlan, 1993), create binary-valued features. reformulation classification considerssign, magnitude, statewise Bellman error, attempting learn featurescharacterize positive-sign regions state space (or likewise negative-sign regions).689fiW U & G IVANstandard supervised classification problem thus formulated C4.5 applied generatedecision-tree feature, use new feature value-function representation.propositional approach easier implement may attractive relational oneobvious advantage using relational representation, computing exactstatewise Bellman error state significantly expensive estimating sign.experiments, however, find relational approach produces superior resultspropositional learner. relational approach also demonstrates ability generalize featuresproblem sizes domain, asset unavailable propositional representations.present experiments nine domains. experiment starts single, constant feature, mapping states number, forcing also constant value function makesdistinctions states. learn domain-specific features weights automaticallygenerated sampled state trajectories, adjusting weights new feature added.evaluate performance policies select actions greedily relative learned valuefunctions. evaluate learners using stochastic computer-game Tetris seven planning domains two international probabilistic planning competitions (Younes et al., 2005;Bonet & Givan, 2006). method provides first domain-independent approach playingTetris successfully (without human-engineered features). relational learner also demonstratessuperior success ratio probabilistic planning-competition domains comparedpropositional approach probabilistic planners FF-Replan (Yoon, Fern, & Givan, 2007)FOALP (Sanner & Boutilier, 2006, 2009). Additionally, show propositional learneroutperforms work Patrascu et al. (2002) SysAdmin domain evaluated there.2. Backgroundpresent relevant background use Markov Decision Processes planning.2.1 Markov Decision Processesdefine terminology Markov decision processes. thorough discussionMarkov decision processes, see books Bertsekas Tsitsiklis (1996) Sutton Barto(1998). Markov decision process (MDP) tuple (S, A, R, T, s0 ). Here, finite statespace containing initial state s0 , selects non-empty finite available action set A(s)state S. reward function R assigns real reward state-action-state triple (s, a, )action enabled state s, i.e., A(s). transition probability function mapsstate-action pairs (s, a) probability distributions S, P(S), A(s).Given discount factor 0 < 1 policy mapping state action A(s),value function V (s) gives expected discounted reward obtained state selecting action(s) state encountered discounting future rewards factor per time step.least one optimal policy V (s), abbreviated V (s), less V (s)every state s, policy . following Q function evaluates action respectfuture-value function V ,XQ(s, a, V ) =(s, a, )[R(s, a, ) + V (s )].Recursive Bellman equations use Q() describe V V follows. First, V (s) =Q(s, (s), V ). Then, V (s) = maxaA(s) Q(s, a, V ). Also using Q(), select ac690fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGtion greedily relative value function. policy Greedy(V ) selects, state s, actionarg maxaA(s) Q(s, a, V ).Value iteration iterates operationU(V )(s) = maxaA(s)X(s, a, )[R(s, a, ) + V (s )],computing Bellman update U(V ) V , producing sequence value functions convergingsup-norm V , regardless initial V used.define statewise Bellman error B(V, s) value function V stateU(V )(s) V (s). inducing new features based correlation statewiseBellman error, based sign statewise Bellman error. sup-norm distancevalue function V optimal value function V bounded using Bellman error magnitude, defined maxsS |B(V, s)| (e.g., see Williams & Baird, 1993). use termstatewise Bellman error emphasize distinction widely used sup-norm Bellmanerror.note computing U(V ), thus statewise Bellman error, involve summationentire state space, whereas fundamental motivations require avoiding summations.many MDP problems interest, transition matrix sparse way set statesreachable one step non-zero probability small, current state. problems,statewise Bellman error computed effectively using appropriate representation .generally, sparse manner, sum effectively approximately evaluatedsampling next states according distribution represented .2.2 Modeling Goal-oriented ProblemsStochastic planning problems goal-oriented, objective solving problemguide agent toward designated state region (i.e., goal region). model problemsstructuring reward transition functions R action goal state leadspositive reward zero-reward absorbing state, reward zero everywhere else.retain discounting represent preference shorter paths goal. Alternatively,problems modeled stochastic shortest path MDPs without discounting (Bertsekas, 1995).techniques easily generalized formalisms allow varying action costs well,model variation work.formally, define goal-oriented MDP MDP meeting following constraints. Here, use variables states actions A(s). requirecontain zero-reward absorbing state , i.e., R(, a, s) = 0 (, a, ) = 1a. transition function must assign either one zero triples (s, a, ), callregion states (s, a, ) one goal region. reward function constrainedR(s, a, ) zero unless = . constructing goal-oriented MDPs problemrepresentations, may introduce dummy actions carry transitions involving describedhere.2.3 Compactly Represented MDPswork, consider propositional relational state representations.691fiW U & G IVANrelational MDPs, spaces A(s) relationally represented, i.e.,finite set objects O, state predicates P , action names N used define spacesfollows. state fact application p(o1 , . . . , ) n-argument state predicate p objectarguments oi , n1 . state set state facts, representing exactly true factsstate. action instance a(o1 , . . . , oSn ) application n-argument action name n objectsoi , n. action space = sS A(s) set action instances.MDPs compactly represented state action spaces also use compact representationstransition reward functions. One compact representation PPDDL planninglanguage, informally discussed next subsection formally presented work Youneset al. (2005).propositional problems, action space explicitly specified state space compactly specified providing finite sequence basic state properties called state attributes,Boolean, integer, real values. propositional state vector values stateattributes.Given relational MDP, equivalent propositional MDP easily constructed grounding, explicit action space constructed forming action-name applicationsset state attributes computed forming state-predicate applications, thus removing useset objects representation.2.4 Representing PPDDL Planning Problems using MDPsdiscuss represent goal-oriented stochastic planning problems defined standardizedplanning languages PPDDL (Younes et al., 2005) goal-oriented MDPs. limitfocus problems goal regions described (conjunctive) sets state facts.reference follow approach used work Fern, Yoon, Givan (2006) regardingconverting planning problems compactly represented MDPs manner facilitates generalization problem instances. first discuss several difficult representational issuesfinally pull discussion together formal definition MDP analyze representgiven PPDDL problem instance. consider quantified and/or disjunctive goals,handling goals would interesting useful extension work.2.4.1 P LANNING OMAINSP ROBLEMSplanning domain distribution problem instances sharing state predicates PW ,action names N , action definitions. Actions take objects parameters, definedgiving discrete finite probability distributions action outcomes, specifiedusing add delete lists state facts action parameters.Given domain definition, problem instance domain specifies finite object set O,initial state si goal condition G. initial state given set state facts goalcondition given conjunction state facts, constructed predicates PW .1. state predicate associated arity indicating number objects relates. state predicateapplied number objects domain form ground state fact either true falsestate; states different possible ways select true state facts. Likewise, action nameassociated arity natural number indicating number objects action act upon. action nameapplied number objects form grounded action.692fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING2.4.2 PPDDL R EPRESENTATIONPPDDL standard planning language international probabilistic planning competitions.PPDDL, planning domain syntax planning problem syntax defined. completelydefine planning instance, one specify domain definition problem definition usingrespective syntax. Conditional effects quantified preconditions allowed domaindefinition.planning competitions, customary specify planning domains providing problem generators accept size parameters input output PPDDL problem instances.generators thus specify size-parameterized planning domains. important note, however, problem generators provided recent planning competitions specify planningdomains according definition used here. particular, problem generators varyaction set state predicates instances generated. relationshipdifferent problem instances generated generators much looser requireddefinition, domains somewhat like arbitrary collections planningproblems.logical language allows generalization problems problemsshare state action language, limit empirical evaluation Section 7 domainsprovided problem generators specify planning domains defined here,i.e., without varying action definitions instances (or easily codegenerator). refer domains generators planning domains fixed actiondefinitions.2.4.3 G ENERALIZATION B ETWEEN P ROBLEMS VARYING IZEobject set varies size, without bound, across problem instances domain,infinitely many possible states within different instances single domain. MDPanalyze finite state space, model planning domain infinite set MDPsseeking good policy (in form good value function), one MDPproblem instance2 .value function infinite set MDPs mapping disjoint union statespaces MDPs real numbers. value function used greedily policyMDPs set. However, explicit representation value function wouldinfinite size. Here, use knowledge representation techniques compactly representvalue functions infinite set problem instance MDPs given planning domain.compact representation derives generalization across domains, approach fundamentally finding good generalizations MDPs within single planning domain.representation value functions planning domains given Sections 2.5 4.section, discuss represent single finite MDP single planning probleminstance. However, note objective work find good value functionsinfinite collections MDPs represent planning domains. Throughout paper,assume planning domain provided along means sampling example problemsdomain, sampling parameterized difficulty (generally, problem size)2. paper consider two candidate representations features; one these, relational representation,capable generalizing problem sizes. propositional representation, restrict trainingtesting problem instances size.693fiW U & G IVANeasy example problems selected. Although, PPDDL provide problemdistributions, benchmark planning domains often provided problem generators definingdistributions: generators available, use them, otherwise codedistributions problem instances.2.4.4 G ENERALIZING B ETWEEN P ROBLEMSVARYING G OALSfacilitate generalization problem instances different goals, following workMartin Geffner (2004) Fern et al. (2006), translate PPDDL instance descriptionMDP state specifies true state also goal is. Actiontransitions MDP never change goal, presence goal within statedescription allows value functions (that defined conditioning state) dependgoal well. goal region MDP simply MDP states specifiedcurrent state information matches specified goal information.Formally, translating PPDDL problem instances compact MDPs, enrich given setworld-state predicates PW adding copy predicate indicating desired statepredicate. name goal-description copy predicate p prepending word goal-name. set goal-description copies predicates PW denoted PG , takePW PG state predicates MDP corresponding planning instance. Intuitively,presence goal-p(a,b) state indicates goal condition requires fact p(a, b)part world state. use goal predicates constructing compact MDPPPDDL description constructing initial state, goal conditions truegoal predicates.use domain Blocksworld example illustrate reformulation (thedomain also used example Fern et al., 2006). goal condition Blocksworldproblem described conjunction ground on-top-of facts. world-state predicateon-top-of PW . discussed above, implies predicate goal-on-top-of PG .Intuitively, one ground instance predicate, goal-on-top-of(b1,b2), means stategoal region, block b1 directly top block b2.2.4.5 TATESAVAILABLE ACTIONSPPDDL allows definition domains states meet preconditionsaction applied. However, MDP formalism requires least one available action everystate. translating PPDDL problem instance MDP define action transitionsaction taken dead state transitions deterministically absorbing state.consider states undesirable plan trajectories, give added transitionsreward negative one unless source state goal state.2.4.6 R ESULTING MDPpull together elements formally describe MDP = (S, A, R, T, s0 )given PPDDL planning problem instance. discussed Section 2.3, set definedspecifying predicates objects available. PPDDL description specifies sets Naction names objects, well set PW world predicates. construct enrichedset P = PW PG state predicates define state space sets applicationspredicates objects O. set A(s) state set PPDDL action instances built694fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGN satisfies preconditions, except set empty, A(s) setPPDDL action instances built N O. latter case, say state dead.reward function R defined discussed previously Section 2.2; i.e., R(s, a, ) = 1goal condition G true s, R(s, a, ) = 1 non-goal dead state, zero otherwise.define (s, a, ) according semantics PPDDL augmented semanticsSection 2.2T (s, a, ) one satisfies G, dead, = , zero otherwise.3Transiting one state another never changes goal condition description states givenpredicates PG . MDP initial state s0 PPDDL problem initial state si augmentedgoal condition G using goal predicates PG . propositional representationdesired, easily constructed directly relational representation grounding.2.5 Linear Approximation Value Functionsmany previous authors done (Patrascu et al., 2002; Sanner & Boutilier, 2009; Bertsekas &Tsitsiklis, 1996; Tesauro, 1995; Tsitsiklis & Roy, 1997), address large compactly represented and/or implicitly representing value functions terms state-space featuresf : R. features f must select real value state. describe two approachesrepresenting selecting features Section 4.Recall Section 1 goal learn value function family related MDPproblems. assume state-space features defined across union state spacesfamily.representvalue functions using linear combination l features extracted s, i.e.,PV (s) = li=0 wi fi (s), f0 (s) = 1. goal find features fi (each mapping states realvalues) weights wi V closely approximates V . Note single set featuresweight vector defines value function MDPs features defined.Various methods proposed select weights wi linear approximations (see, e.g.,Sutton, 1988 Widrow & Hoff, 1960). Here, review use trajectory-based approximatevalue iteration (AVI) approach. training methods easily substituted. AVI constructs12finite sequence value functionsone. value functionPl V , V , . . . , V , returns lastrepresented V (s) = i=0 wi fi (s). determine weights wi+1 V , draw settraining states s1 , s2 , . . . , sn following policy Greedy(V ) different example problemssampled provided problem distribution current level problem difficulty. (SeeSection 3 discussion control problem difficulty.) number trajectories drawnmaximum length trajectory parameters AVI method. training state s,compute Bellman update U(V )(s) MDP model problem instance.compute wi+1 training states usingwi+1 = wi +1 Xfi (sj )(U(V )(sj ) V (sj )),ni(1)jlearning rate ni number states s1 , s2 , . . . , sn fi (s)non-zero. Weight updates using weight-update formula descend gradient L2 distanceV U(V ) training states, features first rescaled normalize3. Note according definitions Section 2.2, dead states technically goal states,negative rewards.695fiW U & G IVANeffective learning rate correct feature values rare occurrence training set.4 Pseudocode AVI method drawing training sets following policy available OnlineAppendix 1 (available JAIR website), page 2.Here, use greedy policy draw training examples order focus improvementrelevant states. state distributions generated biased currentpolicy; particular, another option worth considering, especially feature learning stuck, wouldlong random walk distribution discussed work Fern, Yoon, Givan (2004).leave detailed exploration issue future work. substantial discussionissues arise selecting training distribution, please see book Sutton Barto (1998).worth noting on-policy training shown converge optimal value functionclosely related reinforcement learning setting using SARSA algorithm (Singh, Jaakkola,Littman, & Szepesvari, 2000).general, AVI often gives excellent practical results, greedy gradient-descentmethod environment convex due maximization operation Bellman errorfunction. such, guarantee quality weight vector found, even caseconvergence. Convergence guaranteed, and, experiments, divergent weighttraining fact problem required handling. note feature-discovery methodsused weight-selection algorithms approximate linear programming,properties AVI undesirable application.implemented small modifications basic weight update rule order use AVIeffectively setting; described Section 5 Online Appendix 1 (available JAIRwebsite).3. Feature-Discovering Value-function Constructionplanning, state features provided, domain-independent algorithms AVI learnweighted combinations features often perform well heuristic estimates state value(e.g., distance goal). describe methods select add features describestate-space regions high inconsistency Bellman equation (statewise Bellman error)approximate value iteration. methods applied using real-valued-feature hypothesisspace corresponding learning method selecting features match real-valued functiontraining set states. Here, use learner select features match statewiseBellman error function.noted above, use boosting style learning approach finding value functions, iteratingselecting weights generating new features focusing Bellman errorcurrent value function. value function representation viewed weighted ensemblesingle-feature hypotheses. start value function trivial feature, constantfeature always returning value one, initial weight zero. iteratively retrainweights select new features matching regions states current weighted ensemblehigh statewise Bellman error.take learning small problems approach learn features first problemsrelatively lower difficulty, increase problem difficulty time, discussed below. Lowerdifficulty problems typically smaller state spaces and/or shorter paths positive4. deriving gradient-descent weight-update formula, feature fi scaled ri =696qn,nigiving fi = ri fi .fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGrInitial feature vectorrInitial weight vector wInitial problem difficultyDifficultytarget leveltime?YesrFinal rwIncrease problemdifficultyr D. Keep.Learn new featurecorrelating Bellmanerror statestrainingr set, add. Keep currentproblem difficulty D.rwrSelect w approximatelyminimizingerrorr BellmanrV = wDoneReweighted valuer rfunction V = wYesPerformancecurrent difficultymeets threshold?Generate featuretraining setFigure 1: Control flow feature learning. Boxes double borders represent assumed subroutines method. assume problem distribution parameterizedproblem difficulty (such problem size).feedback (e.g. goal states). Learning initially difficult problems typically leadinability find positive feedback random-walk behavior; result learning first lowerdifficulty problems found effective (Martin & Geffner, 2004; Yoon, Fern, & Givan,2002). show experimentally Section 7 good value functions high difficulty problemsindeed learned fashion problems lower, increasing difficulties.approach relies two assumed subroutines, instantiated different waysproviding different algorithms subroutines. First, method weight selection assumed;method takes input problem domain fixed set features, selects weight vectorvalue function problem domain using provided features. intend methodheuristically approximately minimize L Bellman error choice weight vector,practice may easier adjust weights approximate L2 Bellman error. Second, featurehypothesis space corresponding learner assumed provided system designer.control flow approach shown Figure 1. iteration fixed problemdistribution selects weights current feature set (using method attempting minimizeL Bellman error) define new value function V , selects training set states featurelearning, learns new feature correlating well statewise Bellman error V , addingfeature feature set. user-provided performance-threshold function detectsincrease problem difficulty. formalization control flow given Figure 2, formpseudo-code.697fiW U & G IVANFeature-discovering Value-function ConstructionInputs:Initial feature vector 0 , initial weight vectorw 0,Sequence problem distributions D1 , D2 , , Dmax increasing difficulty,Performance threshold function .// (D, V ) tests performance value function V distribution D.Outputs:Feature vector , weight vectorw0,ww 0, 11.(d > max time)Selectw approximately minimizing Bellman error V =w Dd(Dd ,w )2.3.4.5.+ 16.elseGenerate sequence training states using Dd7.8.9.10.Learn new feature f correlating Bellman error feature B(w , )states( ; f ),w (w ; 0)return ,wNotes:1. B(, ) statewise-Bellman error function, defined Section 2.1.2. code approximate value iteration AVI, shown Online Appendix 1 (available JAIR website)page 2, example implementation line 3.3. code draw(Greedy(w ), N), shown Online Appendix 1 page 2, example impletrainingmentation line 7. Ntraining number states feature training set. Duplicated states removedspecified Section 3.1.4. beam-search code learning relational features beam-search-learn(score(, T, B(w , )))example implementation line 8, beam-search-learn shown figure 3 Section 3, scoredefined Section 4.2.Figure 2: Pseudo-code learning set features.experiments reported Section 7, evaluate following choices assumedsubroutines. experiments use AVI select weights feature sets. evaluate twochoices feature hypothesis space corresponding learner, one relational one propositional, described Section 4.Separate training sets drawn weight selection feature learning; formerdepend weight selection method, described AVI Section 2.5, latterdescribed section.Problem difficulty increased sampled performance greedy policy currentdifficulty exceeds user-specified performance thresholds. planning-domain experiments,698fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGperformance parameters measured success ratio (percentage trials find goal) average successful plan length (the average number steps goal among successful trials).non-goal-oriented domains Tetris SysAdmin use different performance measures: average total reward Tetris Bellman error SysAdmin (to facilitate comparison Patrascuet al., 2002).also assume user-provided schedule problem difficulty increases problemsdifficulty parameterized one parameter (e.g., size may measured numberobjects type); domain-independent automation increase difficultytopic future research. give difficulty-increase schedules performance thresholdsexperiments section presenting experiments, Section 7.3.1 Training Set Generationtraining set selection new feature set states. training set constructedrepeatedly sampling example problem instance problem distribution current leveldifficulty, applying current greedy policy Greedy(V ) problem instance createtrajectory states encountered. Every state (removing duplicates) encountered addedtraining set. size feature-selection training set maximum length trainingtrajectory specified user parameters algorithm.Retaining duplicate states training set another option considered. preliminary empirical results favored option, certainly worth exploration.note goal finding near-optimal value function necessarily make referencestate distribution: widely used notion near-optimal theory MDPssup-norm distance V . Moreover, state distribution represented duplicatestraining sets typically distribution badly flawed policy; heeding distributionprevent correcting Bellman error critical states visited policy, visitedrarely. (These states may be, instance, rarely visited good exits visited state regionmisunderstood current value function.) point, primary justificationremoving duplicates empirical performance demonstrated Section 7.Similar reasoning would suggest removing duplicate states training sets AVI weighttraining, described Section 2.5. many large AVI training sets generatedexperiments, duplicate removal must carefully handled control runtime; historical reasons,experiments shown include duplicate removal AVI.possible problem occurs current greedy policy cannot reach enough states complete desired training set. 200 consecutive trajectories drawn without visiting new statedesired training set size reached, process modified follows. point,method attempts complete training set drawing trajectories using random walk (againusing sampled example problems current problem distribution). process leads200 consecutive trajectories without new state, method terminates training-set generationuses current training set even though smaller target size.3.2 Applicability MethodFeature-discovering value-function construction described require complete accessunderlying MDP model. AVI updates training set generation basedfollowing computations model:699fiW U & G IVAN1. Given state ability compute action set A(s).2. Given state s, action A(s), value function V , ability compute Q-valueQ(s, a, V ).3. Given state action A(s), ability draw state next state distributiondefined (s, a, ).4. Given state s, ability compute features selected feature languagecomputations state required selected feature learner. examples,(a) Section 4, introduce relational feature language learner require knowledge set domain predicates (and arities) state conjunctiveset predicate facts (see Section 2.3),(b) and, also Section 4, describe propositional feature language learnerrequire knowledge set propositional state attributes state truthassignment attributes.first three items enable computation Bellman update last item enablescomputation estimated value function given weights features defining wellselection new features feature learner. requirements amount substantial accessproblem model; result method must considered model-based technique.consequence requirements algorithm cannot directly appliedstandard reinforcement learning setting model access via acting worldwithout ability reset selected states; setting Bellman error computations particularstates cannot necessarily carried out. would possible construct noisy Bellman errortraining set model-free setting would appropriate future work explore usetraining set feature learning.PPDDL planning domains studied provide information needed performcomputations, method also applies domains natural represent PPDDL.analyzed method computations implemented. instance,Tetris experiments Section 7.2, underlying model represented providing hand-codedroutines computations within domain.3.3 AnalysisMDP value iteration guaranteed converge optimal value function conductedtabular value-function representation presence discounting (Bertsekas, 1995). Althoughweight selection AVI designed mimic value iteration, avoiding tabular representation,general guarantee weight updates track value iteration thus convergeoptimal value function. particular, may weighted combination featuresrepresents optimal value function, likewise none represents Bellman update U(V )value function V produced AVI weight training process. learning system introducesnew features existing feature ensemble response problem: training set usedselect new feature pairs states statewise Bellman error. learned feature exactlycaptures statewise Bellman-error concept (by exactly capturing training set generalizing700fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGsuccessfully) new feature space contain Bellman update value function usedgenerate training data.aim find features approximate Bellman error feature, takefunction mapping states statewise Bellman error. Theoretical properties Bellman errorfeatures uncontrolled Markov processes (i.e., without max operator Bellman equation) recently discussed work Parr et al. (2007), additionfeatures (or close approximations thereof) proven reduce weighted L2 -norm distance best weight setting true (uncontrolled) value V , linear fixed-pointmethods used train weights feature addition. Prior work (in Wu & Givan,2005), parallel it, empirically exploring effects selecting Bellmanerror features complex controlled case, leading results reported here.clear simply add Bellman error feature directly, set corresponding weight one, resulting value function would desired Bellman update U(V )current value function V . Adding features iteration would thus give us wayconduct value iteration exactly, without enumerating states. added feature woulddescribe Bellman error value function defined terms previously added features, posingserious computational cost issue evaluating added features. particular, Bellmanerror feature value function V estimated particular state high confidenceevaluating value function V state polynomial-sized sample next statesaction (based Chernoff bounds).However, value function V based upon previously added Bellman-error feature,evaluation V requires sampling (again, possible action) compute.manner, amount sampling needed high confidence grows exponentially numbersuccessive added features type. levels sampling collapse one expectationintervening choices actions, often case decision-theoretic sampling.feature selection method attempt tractably approximate exact value iteration methodlearning concise efficiently computable descriptions Bellman-error featureiteration.method thus viewed heuristic approximation exact value iteration. Exactvalue iteration instance method obtained using explicit state-value tablefeature representation generating training sets feature learning containing statesobtain exact value iteration would also omit AVI training instead set weight one.feature language learner shown approximate explicit features tightlyenough (so resulting approximate Bellman update contraction L norm),easy prove tightening approximations V result weights set one. However,practical results experiments, use feature representations learnersapproximation bound relative explicit features known.4. Two Candidate Hypothesis Spaces Featuressection describe two hypothesis spaces features, relational feature spacepropositional feature space, along respective feature learning methods.two feature spaces, assume learner provided training set states pairedstatewise Bellman error values.701fiW U & G IVANNote two feature-space-learner pairs lead two instances general methodothers easily defined defining new feature spaces corresponding learners.paper empirically evaluate two instances presented here.4.1 Relational Featuresrelational MDP defined terms set state predicates. state predicates basicelements define feature-representation language. Below, define generalpurpose means enriching basic set state predicates. resulting enriched predicatesused predicate symbols standard first-order predicate logic. considerformula logic one free variable feature, follows5 .state relational MDP first-order interpretation. first-order formula one freevariable function states natural numbers maps state numberobjects state satisfy formula. take first-order formulas real-valuedfeatures normalizing real number zero onethis normalization donedividing feature value maximum value feature take, typicallytotal number objects domain, smaller domains objects (andquantifiers) typed. similar feature representation used work Fawcett (1996).feature representation used relational experiments, learner describenext subsection considers existentially quantified conjunctions literals (with one freevariable) features. space formulas thus effective feature space relationalexperiments.Example 4.1: Take Blocksworld table object example, on(x, y)predicate domain asserts block x top object y,may block table. possible feature domain describedon(x, y), first-order formula x one free variable. formulameans object immediately block object x,essentially excludes table object block held arm (if any)object set described feature. n blocks problems, un-normalized valuefeature n states block held arm, n 1 statesblock held arm.4.1.1 E NRICHED P REDICATE ETinteresting examples possible enriched predicate set define. enrichset state predicates P , add binary predicate p transitive closure formpredicate p+ predicates min-p max-p identifying minimal maximal elementspredicate. goal-based domains, recall problem representation (from Section 2.4)includes, predicate p, goal version predicate called goal-p represent desiredstate predicate p goal. Here, also add means-ends analysis predicate correct-prepresent p facts present current state goal.So, objects x y, correct-p(x,y) true p(x, y) goal-p(x,y)true. p+(x, y) true objects x connected path binary relation p. relationmax-p(x) true object x maximal element respect p, i.e., exists object5. Generalizations allow multiple free variables straightforward unclear utility time.702fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGp(x, y) true. relation min-p(x) true object x minimal element respectp, i.e., exists object p(y, x) true.formally define feature grammar Online Appendix 1 (available JAIR website)page 3.Example 4.1 (cont.): feature correct-on(x, y) means x stacked topobject current state goal state. feature on+(x, y)means current state, x directly object y, i.e., sequencerelations traversing path x y, inclusively. feature max-on+(x)means x table object block-towers placed table, sincetable object object. feature min-on+(x) meansobject top x, i.e., x clear.4.2 Learning Relational Featuresselect first-order formulas candidate features using beam search beam width W .present pseudo-code beam search Figure 3. search starts basic features derivedautomatically domain description repeatedly derives new candidate featuresbest scoring W features found far, adding new features candidates keepingbest scoring W features times. new candidates added fixed depth times,best scoring feature found overall selected added value-function representation.Candidate features scored beam search correlation Bellman error featureformalized below.Specifically, score candidate feature f correlation coefficient Bellmanerror feature B(V, ) estimated training set. correlation coefficient functions(s)}defined corr-coef(, ) = E{(s) (s)}E{(s)}E{. Instead using knowndistribution compute value, use states training set compute sampledversion using following equations approximate true expectation E true standarddeviation random variable X:1 XX(s ),Es {X(s)} =|s |X,s =corr-coef-sampled(, , ) =1 X(X(s ) E{X(s)})2 ,|s |Es {(s) (s)} Es {(s)}Es { (s)}.,s ,sscoring function feature selection regularized version correlation coefficientfeature target functionscore(f, , ) = |corr-coef-sampled(f, , )|(1 depth(f )),depth feature depth beam search first occurs,parameter learner representing degree regularization (bias towards low-depth features).703fiW U & G IVANbeam-search-learnInputs:Feature scoring function fscore : features [0, 1]Outputs:New feature fSystem parameters:W : Beam widthmaxd : Max number beam-search iterations: Degree regularization, defined Section 4.21.2.3.4.5.6.7.8.set basic features, defined Section 4.2.1, F I.repeatSet beam B highest scoring W candidates F .Candidate feature set F B.candidate f1 Bcandidate f2 (B I), f2 6= f1F = F combine(f1 , f2 ).9.10.11.+ 1.(d > maxd ) (highest score far (1 d)).return maximum scoring feature f F .Notes:1. Feature scoring function fscore(f ) used rank candidates lines 4 11. discussion samplescoring function, used relational experiments, given Section 4.2.2. Candidate scores cached calls fscore, candidate scored twice.3. value (1 d) largest score feature depth have.Figure 3: Pseudo-code beam search.value score(f, , B(V, )) score well feature f correlates Bellman error feature. Note features non-negative, still well correlatedBellman error (which negative), presence constant feature representation allows non-negative feature shifted automatically needed.remains specify features hypothesis space considered initial,basic, features beam search, specify means constructing complex featuressimpler ones use extending beam search. first take state predicate set Pdomain enrich P described Section 4.1. enrichment P , take basicfeatures existentially quantified applications (possibly negated) state predicates variableszero one free variable6 . grammar basic features defined follows.6. domain distinguishes objects naming constants, allow constants argumentspredicates well.704fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGDefinition: basic feature existentially quantified hliterali expressionone free variable (see Figure 3 Online Appendix 1, available JAIR website,page 3).feature free variables treated technically one-free-variable featurevariable used; results binary feature value either zero total numberobjects, instantiating free variable different ways always results truth value.assume throughout every existential quantifier automatically renamed away everyvariable system. also take basic features human-provided featuresmay available, add features experiments paper order clearlyevaluate methods ability discover domain structure own.stage beam search add new candidate features (retaining W best scoringfeatures previous stage). new candidate features created follows. featurebeam combined conjunctively other, basic feature. method combination two features described Figure 4. figure shows non-deterministic pseudo-codecombining two input features, way making non-deterministic choices resultsnew candidate feature. pseudo-code refers feature formulas f1 f2 describingtwo features. places, formulas others written free variable exposed,f1 (x) f2 (y). Also substitution variable notated replacing notation,f1 (z).combination conjoining feature formulas, shown line 2 Figure 4; however,additional complexity resulting combining two free variables possibly equatingbound variables two features. two free variables either equated (by substitution) one existentially quantified combination done, line 1. two pairsvariables, chosen one contributing feature, may also equated, resultingquantifier front, described line 3. Every combination feature candidate.beam-search construction lead logically redundant features casessyntactically redundant well. avoid syntactically redundant features end beamsearch selecting highest scoring feature already feature set. Logical redundancy syntactic redundancy difficult detect. avoid redundancyautomatically using ordering beam search reduce generation symmetric expressions . However, testing logical equivalence featureslanguage NP-hard (Chandra & Merlin, 1977), deploy complete equivalence testhere.Example 4.2: Assume two basic features z p(x, z) w q(y, w). setpossible candidates generated combining two features are:line 3 Figure 4 runs zero times,1. (x z p(x, z)) (w q(y, w)), xf1 (x) f2 (y)2. (z p(x, z)) (y w q(y, w)), f1 (x) yf2 (y),3. (z p(x, z)) (w q(x, w)), f1 (x) f2 (x)line 3 runs one time,4. u ((z p(u, z)) (q(y, u))), equating x w item 1 above,5. u (x p(x, u)) (q(y, u)), equating x z item 1 above,705fiW U & G IVANcombineInputs:Features f1 (x), f2 (y)Outputs:Set features {o1 }return set features o1 result from:1.Perform onea. f1 = (x)f1 (x)b. f2 = (y)f2 (y)c. f2 = f2 (x)2.o1 = f1 f23.Perform following variable equating step zero, one, two times:a. Let v variable occurring f1 o1 .Let e1 expression form (v)1 (v) occurs o1b. Let w variable occurring f2 o1 .Let e2 expression form (w)2 (w) occurs o1c. Let u new variable, used o1d. o2 = replace e1 1 (u) replace e2 2 (u) o1e. o1 = (u)o2Notes:1. choice 1a, 1b, 1c, choice number iterations step 3, choices e1 e2steps 3a 3b non-deterministic choices.2. feature produced run non-deterministic algorithm included setfeatures returned combine.3. assumed f1 f2 variables common, renaming necessary operation.Figure 4: non-deterministic algorithm combining two feature formulas.6. u (p(x, u) (w q(u, w))), equating z item 2 above,7. u (p(x, u) (y q(y, u))), equating z w item 2 above,8. u (p(x, u) ( q(x, u))), equating z w item 3 above.first three computed using cases 1a, 1b, 1c, respectively. remainingfive derive first three equating bound variables f1 f2 .Features generated depth k language easily require enumerating k-tuplesdomain objects. Since cost evaluation grows exponentially k, bound706fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGmaximum number quantifiers scope point feature formula q, refuseconsider feature violating bound.values W , , d, q parameters controlling relational learner evaluatepaper. set parameters discussed experimental setup descriptionSection 6.provide brief discussion motivations feature combination method. First,note additive combination features represent disjunctions features7 ; hence,consider conjunction feature combination. Here, chosen conjoin featuresmultiple ways, varying handling/combining free bound variables. believechoice uniquely effective, provide example realization proposed featurediscovery architecture.choice feature representation combination method must trade costevaluation choices potential gain quality selected features. Here,chosen limit individual features conjunction; effectively, limited featuresHorn clauses predicates negations, univariate heads.4.3 Propositional Featuresdiscuss second candidate hypothesis space features, using propositional representation. use decision trees represent propositional features. detailed discussionclassification using decision trees found book Mitchell (1997). decision treebinary tree internal nodes labeled binary tests states, edges labeled yesrepresenting results binary tests, leaves labeled classes (in case, either zeroone). path tree root leaf label l identifies labeling setstateseach state consistent state-test results path viewed labeled l tree.way, decision tree real number labels leaves viewed labeling statesreal numbers, thus feature.learn decision trees training sets labeled states using well known C4.5 algorithm(Quinlan, 1993). algorithm induces tree greedily matching training data rootdown. use C4.5 induce new featuresthe key algorithm construct suitabletraining sets C4.5 induced features useful reducing Bellman error.include possible state tests decision trees induce every grounded predicateapplication8 state predicates, well every previously selected decision-tree feature(each binary test leaf labels zero one).4.4 Learning Propositional Featuresconstruct binary features, use sign Bellman error feature, magnitude. sign statewise Bellman error state serves indication whetherstate undervalued overvalued current approximation, least respect exactlyrepresenting Bellman update current value function. identify collectionundervalued states new feature, assigning appropriate positive weight feature7. Representing disjunction overlapping features using additive combination done third featurerepresenting conjunction, using inclusion/exclusion negative weight conjunction.8. grounded predicate application predicate applied appropriate number objects problem instance.707fiW U & G IVANincrease value. Similarly, identifying overvalued states new feature assigningnegative weight decrease value. note domains interest generallylarge state-space enumeration, need classification learning generalize notionsovervalued undervalued across state space training sets sample states.enable method ignore states approximately converged, discard statesstatewise Bellman error near zero either training set. Specifically, among states negative statewise Bellman error, discard state error closer zero medianwithin set; among states positive statewise Bellman error. sophisticated methods discarding training data near intended boundary consideredfuture research; often introduce additional parameters method. Here, seekinitial simple evaluation overall approach. discarding, define +set remaining training pairs states positive statewise Bellman error,likewise negative statewise Bellman error.use + positive examples negative examples supervisedclassification algorithm; case, C4.5 used. hypothesis space classification spacedecision trees built tests selected primitive attributes defining state spacegoal; case, also use previously learned features decision trees attributes.concept resulting supervised learning treated new feature linear approximation architecture, initial weight zero.intent, ideally, develop approximately optimal value function. value functionexpected Bellman error many states, every state; however, low state-wiseerror states contribute high sup-norm Bellman error. discarding trainingstates low statewise Bellman error reflects tolerance low error thresholdrepresenting degree approximation sought. Note technical motivation selectingfeatures based upon Bellman error focuses reducing sup-norm Bellman error; givenmotivation, interested finding exact boundary positive negativeBellman error identifying states large magnitude Bellman error (solarge-magnitude error addressed feature addition).observe limited need separately learn feature matching duefollowing representability argument. Consider binary feature F complement F ,exactly one F F true state. Given presence constant feature featureset, adding F F feature set yields set representable value functions (assigningweight w F effect assigning weight w F adding w weightconstant feature).4.5 Discussiondiscuss generalization capability, learning time, heuristic elements featurelearning method.4.5.1 G ENERALIZATION ACROSS VARYING OMAIN IZESpropositional feature space described varies size number objects relationaldomain varied. result, features learned one domain size generally meaningful (oreven necessarily defined) domain sizes. relational approach is, contrast, ablegeneralize naturally different domains sizes. experiments report ability708fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGpropositional technique learn within domain size directly, attempt useapproach learning small problems gain performance large problems. majorlimitation producing good results large domains.4.5.2 L EARNING IMEprimary motivation giving generalization domain sizes order employ propositional approach resulting learner use highly efficient, off-the-shelf classificationalgorithms. learning times reported Section 7 show propositional learner learns newfeatures orders magnitude faster relational learner.4.5.3 H EURISTIC E LEMENTSETHODmentioned earlier, algorithm heuristically approximates repeated addition Bellmanerror features linear value-function approximation order carry value iteration. Alsomentioned earlier, value iteration guaranteed converge optimal value function.However, due scale problems target, heuristic approximations required. discussmotivations heuristic approximation employ briefly here.First, compute exact Bellman error features. Instead, use machine learning fittraining set sample states Bellman error values. selection training setdone heuristically, using trajectories drawn current greedy policy. use on-policyselection training data loosely motivated on-policy convergence results reinforcementlearning (Singh et al., 2000), serves focus training relevant states. (See Section 3.1.)Second, relational instance feature framework, beam-search method useselect highest scoring relational feature (with best fit Bellman error) ad-hoc, greedy,severely resource bounded. fit obtained Bellman error purely heuristic. provideheuristic method machine learning problem example, intend futureresearch provide better relational learners resulting better planning performance. Heuristicelements current method discussed Appendix A.3. workviewed providing reduction stochastic planning structured machine learning numericfunctions. (See Section 3.)Third, propositional instance feature framework,, learner C4.5 selects hypotheses greedily. Also, reduction C4.5 classification relies explicit tolerance approximation form threshold used filter training data near-zero Bellman error.motivation approximation tolerance focus learner high Bellman error statesallow method ignore almost converged states. (See Section 4.4.)Fourth, fundamental work use linear approximation value functiongradient-descent-based weight selection (in case AVI). approximation methods keyapproach handling large state spaces create need feature discovery. AVI methodincludes empirically motivated heuristic methods controlling step size sign changesweights. (See Section 5 Online Appendix 1, available JAIR website.)Fifth, rely human input select sequence problem difficulties encounteredfeature discovery well performance thresholds problem difficulty increases.believe aspect algorithm automated future research. (See Section 3.)709fiW U & G IVAN5. Related WorkAutomatic learning relational features approximate value-function representation surprisingly frequently studied quite recently, remains poorly understood. Here,review recent work related one dimensions contribution.5.1 Feature Selection Based Bellman Error MagnitudeFeature selection based Bellman error recently studied uncontrolled (policyevaluation) context work Keller et al. (2006) Parr et al. (2007), attribute-valueexplicit state spaces rather relational feature representations. Feature selection basedBellman error compared feature selection methods uncontrolled contexttheoretically empirically work Parr, Li, Taylor, Painter-Wakefield, Littman(2008).Here, extend work controlled decision-making setting study incorporationrelational learning selection appropriate knowledge representation value functionsgeneralize problems different sizes within domain.main contribution work Parr et al. (2007) formally showing, uncontrolledcase policy evaluation, using (possibly approximate) Bellman-error features provably tightens approximation error bounds, i.e., adding exact Bellman error-feature provably reduces(weighted L2 -norm) distance optimal value function achieved optimizing weights linear combination features. result extended weaker formapproximated Bellman-error features, uncontrolled case. limitation uncontrolled case substantial difference setting work. limited experiments shownuse explicit state-space representations, technique learns completely new set featurespolicy evaluation conducted policy iteration. contrast, method accumulatesfeatures value iteration, point limiting focus single policy. Constructingnew feature set policy evaluation procedure amenable formal analysisretaining learned features throughout value iteration policy implicitly considered value iteration (the greedy policy) potentially changing throughout. However,using relational feature learning, runtime cost feature learning currently high makeconstructing new feature sets repeatedly practically feasible.Parr et al. (2007) builds prior work Keller et al. (2006) also studied uncontrolled setting. work provides theoretical results general framework, providesspecific approach using Bellman error attribute value representations (where state represented real vector) order select new features. approach provides apparent leverageproblems state real vector, structured logical interpretation, typicalplanning benchmarks.5.2 Feature Discovery via Goal Regressionprevious methods (Gretton & Thiebaux, 2004; Sanner & Boutilier, 2009) find useful featuresfirst identifying goal regions (or high reward regions), identifying additional regions regressing action definitions previously identified regions. principle exploitedgiven state feature indicates value state, able achieve featureone step also indicate value state. Regressing feature definition action710fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGdefinitions yields definition states achieve feature one step. Repeated regression identify many regions states possibility transitioningaction sequence high-reward region.exponentially many action sequences relative plan length,exponentially many regions discovered way, well exponential increase sizerepresentation region. exponentials terms number regression stepstaken. control exponential growth number features considered, regressionimplemented pruning optimizations control eliminate overlap regionsdetected inexpensively well dropping unlikely paths. However, without scoringtechnique (such fit Bellman-error used paper) select features, regression stillgenerates large number useless new features. currently effective regression-basedfirst-order MDP planner, described work Sanner Boutilier (2009), effectivedisallowing overlapping features allow optimizations weight computation. Yet clearlyhuman-designed feature sets fact overlapping features.inductive technique avoids issues considering compactly represented features,selecting match sampled statewise Bellman error training data. provide extensiveempirical comparison First-Order Approximate Linear Programming technique (FOALP)work Sanner Boutilier (2009) empirical results. empirical evaluationyields stronger results across wide range probabilistic planning benchmarks goalregression approach implemented FOALP (although aspects approachesgoal-regression candidate generation vary comparison well).Regression-based approaches feature discovery related method fitting Bellmanerror exploit fact states reach valuable states must valuable, i.e. seek local consistency. fact, regression goal viewed specialcase iteratively fitting features Bellman error current value function. Dependingexact problem formulation, k, Bellman error k-step-to-go value functionnon-zero (or otherwise nontrivially structured) region states reach goal firstk + 1 steps. Significant differences Bellman error approach regression-basedfeature selection arise states reach goal different probabilities differenthorizons. approach fits magnitude Bellman error, smoothly considerdegree state reaches goal horizon. approach also immediately generalizes setting useful heuristic value function provided automatic featurelearning, whereas goal-regression approach appears require goal regions begin regression.spite issues, believe approaches appropriate valuableconsidered important sources automatically derived features future work.Effective regression requires compact declarative action model, always available9 .inductive technique present require even PDDL action model, deductive component computation Bellman error individual states. representationstatewise Bellman error computed sufficient technique. empirical results show performance planner Tetris, model representedgiving program that, given state input, returns explicit next state distributionstate. FOALP inapplicable representations due dependence logical deductive rea9. example, Second International Probabilistic Planning Competition, regression-based FOALP plannerrequired human assistance domain providing needed domain information even though standardPDDL model provided competition sufficient planner.711fiW U & G IVANsoning. believe inductive deductive approaches incorporating logical representationimportant complementary.goal regression approach special case general approach generating candidate features transforming currently useful features. Others considered includeabstraction, specialization, decomposition (Fawcett, 1996). Research human-defined concept transformations dates back least landmark AI program (Davis & Lenat, 1982).work uses one means generating candidate features: beam search logical formulasincreasing depth. means candidate generation advantage strongly favoring concise inexpensive features, may miss complex accurate/useful features.approach directly generalizes means generating candidate features.centrally distinguishes approach previous work leveraging feature transformationsuse statewise Bellman error score candidate features. FOALP (Sanner & Boutilier, 2006,2009) uses scoring function, includes non-pruned candidate features linear programused find approximately optimal value function; Zenith system (Fawcett, 1996) usesscoring function provided unspecified critic.5.3 Previous Scoring Functions MDP Feature Selectionmethod, work Patrascu et al. (2002), selects features estimating minimizingL1 error value function results retraining weights candidate featureincluded. L1 error used work instead Bellman error difficulty retrainingweights minimize Bellman error. method focuses fitting Bellman errorcurrent approximation (without retraining new feature), avoids expensiveretraining computation search able search much larger feature space effectively.work Patrascu et al. (2002) contains discussion relational representation, L1scoring method could certainly used features represented predicate logic; work datetried (potentially expensive) approach.5.4 Related Workinclude discussion additional, distantly related research directions Appendix A, divided following subsections:1. relevant feature selection methods (Fahlman & Lebiere, 1990; Utgoff & Precup, 1997,1998; Rivest & Precup, 2003; Mahadevan & Maggioni, 2007; Petrik, 2007);2. Structural model-based model-free solution methods Markov decision processes, including(a) Relational reinforcement learning (RRL) systems (Dzeroski, DeRaedt, & Driessens,2001; Driessens & Dzeroski, 2004; Driessens et al., 2006),(b) Policy learning via boosting (Kersting & Driessens, 2008),(c) Fitted value iteration (Gordon, 1995),(d) Exact value iteration methods first-order MDPs (Boutilier, Reiter, & Price, 2001;Holldobler & Skvortsova, 2004; Kersting, Van Otterlo, & De Raedt, 2004);712fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNING3. Inductive logic programming algorithms (Muggleton, 1991; Quinlan, 1996; Karalic & Bratko,1997);4. Approximate policy iteration relational domains (Fern et al., 2006), discussionrelational decision-list-policy learners (Khardon, 1999; Martin & Geffner, 2004; Yoon et al.,2002);5. Automatic extraction domain knowledge (Veloso, Carbonell, Perez, Borrajo, Fink, &Blythe, 1995; Kambhampati, Katukam, & Qu, 1996; Estlin & Mooney, 1997; Fox & Long,1998; Gerevini & Schubert, 1998).6. Experimental Settingpresent experiments nine stochastic planning domains, including reward-orientedgoal-oriented domains. use Pentium 4 Xeon 2.8GHz machines 3GB memory. section, give general overview experiments giving detailed results discussionindividual domains Section 7. Here, first, briefly discuss selection evaluation domainsSection 6.1. Second, Section 6.2 set evaluation relational feature learnercomparison variants replace key aspects algorithm random choice determineimportance. Additional details, including many experimental parameter settings, foundOnline Appendix 1 (available JAIR website) Section 3.6.1 Domains Consideredevaluation domains below, necessary specify discount factor modelingdomain MDP discounting. discount factor effectively specifies tradeoffgoals reducing expected plan length increasing success rate. parametermethod, domain studied, feature-learning method appliedchoice . Here, simplicity, choose 0.95 throughout experiments. notediscount factor used YS DMIN domain formalization compareprevious work Patrascu et al. (2002).6.1.1 ETRISSection 7.2 evaluate performance relational propositional learners usingstochastic computer-game ETRIS, reward-oriented domain goal playermaximize accumulated reward. compare results performance set handcrafted features, performance randomly selected features.6.1.2 P LANNING C OMPETITION OMAINSSection 7.3, evaluate performance relational learner seven goal-oriented planning domains two international probabilistic planning competitions (IPPCs) (Younes et al.,2005; Bonet & Givan, 2006). comparison purposes, evaluate performance propositional learner two seven domains (B LOCKSWORLD variant B OXWORLD describedbelow). Results two domains illustrate difficulty learning useful propositional features complex planning domains. also compare results relational plannertwo recent competition stochastic planners FF-Replan (Yoon et al., 2007) FOALP (Sanner &713fiW U & G IVANBoutilier, 2006, 2009) performed well planning competitions. Finally,compare results obtained randomly selecting relational features tuning weightsthem. complete description of, PPDDL source for, domains used, please seework Younes et al. (2005) Bonet Givan (2006).Every goal-oriented domain problem generator first second IPPC considered inclusion experiments. inclusion, require planning domain fixedaction definitions, defined Section 2.4, addition ground conjunctive goal regions. Four domains properties directly, adapted three domainsproperties:1. B OXWORLD, modify problem generator goal region always groundconjunctive expression. call resulting domain C ONJUNCTIVE -B OXWORLD.2. F ILEWORLD, construct obvious lifted version, create problem generator restricted three folders domain action definitions vary numberfolders. call resulting domain L IFTED -F ILEWORLD 3.3. OWERS H ANOI, create problem generator.resulting selection provides seven IPPC planning domains empirical study. providedetailed discussions adapted domains Section 2 Online Appendix 1 (available JAIRwebsite), well discuss reasons exclusion domains.6.1.3 YS DMINconclude experiments comparing propositional learner previous method Patrascu et al. (2002), using YS DMIN domain used evaluation there. empiricalcomparison YS DMIN domain shown Section 7.4.6.2 Randomized Variants Methodmajor contribution introduction evaluation feature learning frameworkcontrolled setting based scoring Bellman-error (BE Scoring). empirical work instantiates framework relational feature-learning algorithm design based greedybeam-search. Here, compare performance instance framework variantsreplace key aspects randomized choice, illustrating relative importance features. two random-choice experiments, adapt method one following twoways:1. Labeling training states random scores instead Bellman Error scores. targetvalue feature training set random number -1 1. algorithm calledRandom Scoring.2. Narrowing beam search randomly rather greedily. eliminate scoring beam search, instead using random selection narrow beam; endbeam search scoring used select best resulting candidate. algorithm calledRandom Beam Narrowing.714fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGoriginal algorithm, labels training data Bellman error narrows beam greedily rather randomly, called Greedy Beam Search/BE Scoring plots.comparisons, consider relational feature representation, beamsearch method used. Experiments two variants introduced here, presentedSections 7.2.4 7.3.4, show original method selects features perform much betterrandomly selected features, greediness beam search often (but always)important achieving good performance.7. Experimental Resultspresent experimental results ETRIS, planning competition domains, YS DMINsection, starting introduction structure result presentation.7.1 Read Resultstask evaluating feature-learning planning system subtle complex. particularlyfactor relational case generalization problem sizes learning smallproblems must evaluated. resulting data extensive highly structured, requiringtraining reader understand interpret. introduce reader structureresults.experiments propositional learning (or randomly selected propositional features), problem size never varies within one run learner, propositional representation Section 4.3 cannot generalize sizes. run separate experimentsize considered. experiment two independent trials; trial starts single trivialfeature repeatedly adds features termination condition met. feature addition, AVI used select weights combining features form value function,performance value function measured (by sampling performance greedy policy).compute average (of two trials) performance function numberfeatures used. Since results single line plot performance function numberfeatures, several different fixed-problem-size learners compared one figure, oneline each, done example Figures 7 14. performance measure used variesappropriately domain presented below.study ability relational representation Section 4.1 generalize sizes.study properly understood backdrop flowchart Figure 1.described flowchart, one trial learner learn sequence features encountersequence increasing problem difficulties. One iteration learner either add newfeature increase problem difficulty (depending current performance). either case,weights retrained AVI performance measurement resulting greedy policytaken. different trials may increase size different points, cannot meaningfullyaverage measurements two trials. Instead, present two independent trials separatelytwo tables, Figures 5 12. first trial, also present datasecond time line plot showing performance function number features, problemsize changes annotated along line, plots Figures 6 13. Note successratio generally increases along line features added, falls problem sizeincreased. (In ETRIS, however, measure rows erased rather success ratio, rows715fiW U & G IVANerased generally increases either addition new feature addition new rowsavailable grid.)interpret tables showing trials relational learner, useful focus firsttwo rows, labeled # features Problem difficulty. rows, taken together, showprogress learner adding features increasing problem size. column tablerepresents result indicated problem size using indicated number learned features.one column next, change one rowsif performancepolicy shown column high enough, problem difficulty increases,otherwise number features increases. adding subtlety interpreting tables, note several adjacent columns increase number features,sometimes splice two columns save space. Thus, several featuresadded consecutively one problem size, slowly increasing performance, may showfirst last columns problem size, consequent jump numberfeatures columns. likewise sometimes splice columns several consecutive columns increase problem difficulty. found splicings save spaceincrease readability practice reading tables.Performance numbers shown column (success ratio average plan length, numberrows erased, ETRIS) refer performance weight-tuned policy resultingfeature set problem difficulty. also show column performance valuefunction (without re-tuning weights) target problem size. Thus, show quality measurespolicy found feature learning current problem size pointtarget problem size, illustrate progress learning small problems target sizevia generalization.study problem deciding stop adding features. Instead,propositional relational experiments, trials stopped experimenter judgment additional results expensive value giving evaluating algorithm. However,stop trials still improving unless unacceptable resource consumptionoccurred.Also, trial, accumulated real time trial measured shown pointtrial. use real time rather CPU time reflect non-CPU costs paging duehigh memory usage.7.2 Tetrispresent experimental results ETRIS.7.2.1 OVERVIEWETRISgame ETRIS played rectangular board area, usually size 10 20, initiallyempty. program selects one seven shapes uniformly random player rotatesdrops selected piece entry side board, piles onto remaining fragmentspieces placed previously. implementation, whenever full row squaresoccupied fragments pieces, row removed board fragments topremoved row moved one row; reward also received row removed.process selecting locations rotations randomly drawn pieces continues boardfull new piece cannot placed anywhere board. ETRIS stochastic since716fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGnext piece place always randomly drawn, stochastic elementgame. ETRIS also used experimental domain previous MDP reinforcement learningresearch (Bertsekas & Tsitsiklis, 1996; Driessens et al., 2006). set human-selected featuresdescribed book Bertsekas Tsitsiklis (1996) yields good performanceused weighted linearly approximated value functions. cannot fairly compare performancedomain probabilistic planners requiring PPDDL input found naturalPPDDL definition ETRIS.performance metric ETRIS number rows erased averaged 10,000 trialgames. reward-scaling parameter rscale (defined Section 5 Online Appendix 1 page 8)selected 1.7.2.2 ETRIS R ELATIONAL F EATURE L EARNING R ESULTSrepresent ETRIS grid using rows columns objects. use three primitive predicates:fill(c, r), meaning square column c, row r occupied; below(r1 , r2 ), meaning rowr1 directly row r2 ; beside(c1 , c2 ), meaning column c1 directly leftcolumn c2 . quantifiers used relational ETRIS hypothesis space typed using typesrow column.also state predicates representing piece drop; however, efficiencyreasons planner computes state value function grid, next piece.limitation value-function expressiveness allows significantly cheaper Bellman-backup computation. one-step lookahead greedy policy execution provides implicit reasoningpiece dropped, piece grid next states.conduct relational ETRIS experiments 10-column, n-row board, n initiallyset 5 rows. threshold increasing problem difficulty adding one row scoreleast 15 + 20(n 5) rows erased. target problem size experiments 20 rows.results relational ETRIS experiments given Figures 5 6 discussed below.7.2.3 ETRIS P ROPOSITIONAL F EATURE L EARNING R ESULTSpropositional learner, describe ETRIS state 7 binary attributes represent7 pieces currently dropped, along one additional binary attributegrid square representing whether square occupied. adjacency relationshipsgrid squares represented procedurally coded action dynamics. Notenumber state attributes depends size ETRIS grid, learned featuresapply problems grid size. result, show separate results selected problemsizes.evaluate propositional feature learning 10-column ETRIS grids four different sizes: 5rows, 7 rows, 9 rows, 20 rows. Results four trials shown together Figure 7average accumulated time required reach point Figure 7 shown Figure 8.results discussed below.7.2.4 E VALUATING MPORTANCE B ELLMAN - ERROR CORING G REEDYB EAM - SEARCH ETRISFigure 9 compares original algorithm alternatives vary either training setscoring greediness beam search, discussed Section 6.2. two alternatives, use717fiW U & G IVANTrial #1# featuresProblem difficultyScoreAccumulated time (Hr.)Target size score050.20.00.3150.521.3251.04.21.4353.05.21.811518201781163121238126322426117635391761775542198187564621118880502171891025722118101216522018152341112681820316178317Trial #2# featuresProblem difficultyScoreAccumulated time (Hr.)Target size score050.20.00.3150.62.41.7851615104862815113126362710812753291161475639130141113366192151113676196151215187199161215697206161316710321117131681102112613175211219261419222022527142102362182717238276231281725129523129172403182333317241408231Figure 5: ETRIS performance (averaged 10,000 games). Score shown average rowserased, problem difficulty shown number rows ETRIS board.number columns always 10. Difficulty increases average score greater15+20*(n-5), n number rows ETRIS board. Target problemsize 20 rows. columns omitted discussed Section 7.1.Average Rows ErasedTetris, Relational, Trial 1350300250200150100500102010151061061051050101010724681012141618Number FeaturesFigure 6: Plot average number lines erased 10,000 ETRIS games runAVI training learning relational features (trial 1). Vertical lines indicatedifficulty increases (in number rows), labeled along plot.718fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGAverage Rows ErasedTetris, Propositional141210864200 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50Number Features1051071091020Figure 7: Plot average number lines erased 10,000 ETRIS games iterationAVI training learning propositional features, averaged two trials.Accumulated Time (Hr.)Tetris, Propositional1601401201008060402000 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50Number Features1051071091020Figure 8: Plot accumulated time required reach point Figure 7, averaged twotrials.schedule used original Greedy Beam Search/BE Scoring algorithm ETRISstarting 10 5 problem size. However, performance two alternatives nevergood enough increase problem size.7.2.5 E VALUATING H UMAN - DESIGNED F EATURES ETRISaddition evaluating relational propositional feature learning approach, also evaluatehuman-selected features described book Bertsekas Tsitsiklis (1996) performselected problem sizes. problem size, start weights zero use AVI719fiW U & G IVANAverage Rows ErasedImpact Greedy Beam Search Scoring1816141210864200 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50Number Relational FeaturesGreedy Beam Search/BE Scoring (original algorithm)Random Scoring (variant 1)Random Beam Narrowing (variant 2)Figure 9: Plot average number lines erased 10,000 ETRIS games relational featureslearned original algorithm two alternatives discussed Section 6.2.Random Scoring Random Beam Narrowing, results averages twoindependent trials. Trials two variants terminated fail makeprogress several feature additions. comparison purposes, trial one originalGreedy Beam Search/BE Scoring method shown, reaching threshold difficultyincrease eleven feature additions (trial two even better).Average rows erased, Trial 1Average rows erased, Trial 210 5 10 7 10 9 10 201986267 17,9541986266 18,125Figure 10: average number lines erased 10,000 ETRIS games best weightedcombination human features found two trials AVI four problemsizes.process described Section 2.5 train weights 21 features performance appears3031+k/100human-designed featuresconverge. change learning rate 1+k/100require larger step-size converge rapidly. human-designed features normalizedvalue 0 1 experiments. run two independent trials problem sizereport performance best-performing weight vector found trial, Figure 10.7.2.6 P ERFORMANCE C OMPARISON B ETWEEN IFFERENT PPROACHESETRISSeveral general trends emerge results ETRIS. First all, addition new learnedfeatures almost always increasing performance resulting tuned policy (on currentsize target size), best performance point reached. suggests fact720fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGRelational Prop. 10 5 Prop.10 7 Prop.10 9 Prop.10 20Average feature learningtime (Min.)16744526044Figure 11: Table average feature learning time relational propositional approaches.selecting useful features. also find clear evidence ability relational representationusefully generalize problem sizes: substantial performance developed targetproblem size without ever training directly size.find best performance learned propositional features much lowerlearned relational features problem sizes shown here, even though larger feature training setsize many learned features used propositional approach. suggestsrich relational representation indeed able better capture dynamics ETRISpropositional representation.find performance using random features ETRIS significantly worseusing learned features, demonstrating performance improvements feature learningdue useful feature selection (using Bellman error), simply due increasing numberfeatures.learned relational feature performance 10 20 ETRIS far worse obtainedusing human-selected features AVI size. However, 10 5 ETRISrelational feature performance close human-designed features. human-designedfeatures engineered perform well 10 20 ETRIS hence concepts usefulperforming well smaller problem sizes may exist features.7.2.7 IME L EARN E ACH F EATUREFigure 11 show average time required learn relational feature propositional featureETRIS.time required learn relational feature significantly longer required learnpropositional feature, even though propositional approach larger feature training set sizeused.7.2.8 C OMPARISONP REVIOUS ETRIS - SPECIFIC L EARNERSevaluating domain-independent techniques ETRIS, must first put aside strong performance already shown many times literature domain-dependent techniques domain.Then, must face problem published domain-independent comparison pointsorder define state-of-the-art target surpass. latter problem, provide baselinetwo different approaches random feature selection, show targeted feature selection dramatically improves random selection. former problem, includediscussion domain-specific elements key previous published results ETRIS.many previous domain-specific efforts learning play ETRIS (Bertsekas& Tsitsiklis, 1996; Szita & Lorincz, 2006; Lagoudakis, Parr, & Littman, 2002; Farias & Van Roy,2004; Kakade, 2001). Typically, provide human-crafted domain-dependent features, deploy domain-independent machine learning techniques combine features (often tuning721fiW U & G IVANweights linear combination). example, domain-specific feature counting numbercovered holes board frequently used. feature plausibly derived humanreasoning rules game, realizing holes difficult fill lateraction lead low scores. prior work, selection feature hand,automated feature-selection process (such scoring correlation Bellman error).frequently used domain-specific features include column height difference height adjacent columns, apparently selected relevant human reasoning rulesgame.key research question address, then, whether useful features derived automatically, decision-making situation like ETRIS approached domain-independentsystem without human intervention. method provided domain-state representation using primitive horizontal vertical positional predicates, single constant feature.knowledge, research published evaluation ETRIS relydomain-specific human inputs discussed. expected, performanceETRIS much weaker achieved domain-specific systems cited.7.3 Probabilistic Planning Competition DomainsThroughout evaluations learners planning domains, use lower plan-length cutoff1000 steps evaluating success ratio iterative learning features, speed learning.use longer cutoff 2000 steps final evaluation policies comparisonplanners evaluations target problem size. reward-scaling parameter rscale(defined Section 5 Online Appendix 1 page 8) selected 1 throughout planningdomains.domains multi-dimensional problem sizes, remains open research problemchange problem size different dimensions automatically increase difficulty learning.Here, C ONJUNCTIVE -B OXWORLD Z ENOTRAVEL, hand-design sequence increasing problem sizes.discussed Section 6.1.2, evaluate feature learners total seven probabilistic planning competition domains. following paragraphs, provide full discussionB LOCKSWORLD C ONJUNCTIVE -B OXWORLD, abbreviated results five domains. provide full discussion five domains Appendix B.relational feature learner finds useful value-function features four domains(B LOCKSWORLD, C ONJUNCTIVE -B OXWORLD, IREWORLD, L IFTED -F ILEWORLD 3).three domains (Z ENOTRAVEL, E XPLODING B LOCKSWORLD, OWERS H ANOI),relational feature learner makes progress representing useful fixed-size value functiontraining sizes, fails find features generalize well problems larger sizes.7.3.1 B LOCKSWORLDprobabilistic, non-reward version B LOCKSWORLD first IPPC, actions pickupputdown small probability placing handled block table object insteadselected destination.relational learner, start 3 blocks problems. increase n blocks n + 1blocks whenever success ratio exceeds 0.9 average successful plan length less30(n 2). target problem size 20 blocks. Results shown Figures 12 13.722fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGTrial #1# featuresProblem difficultySuccess ratioPlan lengthAccumulated time (Hr.)Target size SRTarget size Slen.0122333333344510151.00 11 0.95 111 0.9789 45 20 133 1933 173 3950.5 1.0 1.5 2.2 3.3 3.9 10360000 0.98 0.96 0.98 0.97761 724 754 745Trial #2# featuresProblem difficultySuccess ratioPlan lengthAccumulated time (Hr.)Target size SRTarget size Slen.031800.50122333333445101511 0.94 111 0.9648 19 125 1734 167 3861.0 1.4 2.0 3.3 3.8 9.4 33000 0.97 0.98 0.98 0.98768 750 770 741Figure 12: B LOCKSWORLD performance (averaged 600 problems) relational learner.add one feature per column success ratio exceeds 0.9 average successful planlength less 30(n 2), n blocks, increase problem difficultynext column. Plan lengths shown successful trials only. Problem difficultiesmeasured number blocks, target problem size 20 blocks. columnsomitted discussed Section 7.1.propositional learner, results problem sizes 3, 4, 5, 10 blocks shownFigure 14.relational learner consistently finds value functions perfect near-perfect successratio 15 blocks. performance compares favorably recent RRL (Driessenset al., 2006) results deterministic B LOCKSWORLD, goals severely restricted to,instance, single atoms, success ratio performance around 0.9 three ten blocks(for single goal) still lower achieved here. results B LOCKSWORLD showaverage plan length far optimal. observed large plateaus induced valuefunction: state regions states given value greedy policy wanders.problem merits study understand feature-induction breakplateaus. Separately, studied ability local search break plateaus (Wu,Kalyanam, & Givan, 2008).performance target size clearly demonstrates successful generalization sizesrelational representation.propositional results demonstrate limitations propositional learner regarding lackgeneralization sizes. good value functions induced smallproblem sizes (3 4 blocks), slightly larger sizes 5 10 blocks render method ineffective.10 block problems, initial random greedy policy cannot improved never finds723fiW U & G IVANSuccess RatioBlocksworld, Relational, Trial 13 blocks13 blocks3 blocks4, 5, 10 blocks15 blocks0.954 blocks0.90.850.80Successful Plan Length012400315 blocks3002003 blocks1003 blocks4 blocks10 blocks3 blocks5 blocks4 blocks00123Number FeaturesFigure 13: B LOCKSWORLD success ratio average successful plan length (averaged 600problems) first trial Figure 12 using relational learner.goal. addition, results demonstrate learning additional features good policyfound degrade performance, possibly AVI performs worse higher dimensionalweight space results.7.3.2 C ONJUNCTIVE -B OXWORLDprobabilistic, non-reward version B OXWORLD first IPPC similarfamiliar Logistics domain used deterministic planning competitions, except explicit connectivity graph cities defined. Logistics, airports aircraft play important rolesince possible move trucks one airport (and locations adjacent it) another airport (and locations adjacent it). B OXWORLD, possible move boxeswithout using aircraft since cities may connected truck routes. stochasticelement introduced domain truck moved one city another,small chance ending unintended city. described Section 6.1, useC ONJUNCTIVE -B OXWORLD, modified version B OXWORLD, experiments.start 1-box problems relational learner increase n boxes n + 1 boxeswhenever success ratio exceeds 0.9 average successful plan length better 30n.feature-learning problem difficulties use 5 cities. use two target problem sizes: 15 boxes724fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGBlocksworld, PropositionalSuccess Ratio10.80.60.40.2Successful Plan Length450400350300250200150100500Accumulated Time (Hr.)09080706050403020100024681002468100246810Number Features3 blocks4 blocks5 blocks10 blocksFigure 14: B LOCKSWORLD performance success ratio average successful plan length (averaged 600 problems), accumulated run-time propositional learner, averaged two trials.725fiW U & G IVANTrial #1# features012Problem difficulty111Success ratio0.97 11Plan length226 84 23Accumulated time (Hr.) 7.2 10 130.98 11Target size #1 SRTarget size #1 Slen.1056 359 93Target size #2 SR0.16 0.90 0.97Target size #2 Slen.1583 996 23822137141910.9723023144161900.9623325154211920.98244210177421900.96240211180491920.9823821213135713550.901024213187651900.98240215192841910.96239Trial #2# features012Problem difficulty111Success ratio0.97 11Plan length235 85 24Accumulated time (Hr.) 7.3 11 14Target size #1 SR0.96 111019 365 90Target size #1 Slen.Target size #2 SR0.19 0.9 0.97Target size #2 Slen.1574 982 22622134161910.9723023143181910.9823325154231920.9823329172391890.9724221012994513590.921006211180511890.982312121.003106013630.911026213184681900.97240215191861900.96233Figure 15: C ONJUNCTIVE -B OXWORLD performance (averaged 600 problems). add onefeature per column success ratio greater 0.9 average successful planlength less 30n, n boxes, increase problem difficulty nextcolumn. Problem difficulty shown number boxes. Throughout learningprocess number cities 5. Plan lengths shown successful trials only. Twotarget problem sizes used. Target problem size #1 15 boxes 5 cities. Targetproblem size #2 10 boxes 10 cities. columns omitted discussedSection 7.1.5 cities, 10 boxes 10 cities. Relational learning results shown Figures 15 16,results propositional learner 5 cities 1, 2, 3 boxes shown Figures 17.interpreting C ONJUNCTIVE -B OXWORLD results, important focus averagesuccessful plan-length metric. C ONJUNCTIVE -B OXWORLD problems, random walk ablesolve problem nearly always, often long plans10 . learned features enabledirect solutions reflected average plan-length metric.two relational features required significantly improved performance problemstested. Unlike domains evaluate, C ONJUNCTIVE -B OXWORLD domain10. note that, oddly, IPPC competition domain used action preconditions prohibiting moving box awaydestination. preconditions bias random walk automatically towards goal. consistencycompetition results, retain odd preconditions, although preconditions necessary goodperformance algorithm.726fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGSuccess RatioConjuctive-Boxworld, 5 Cities, Relational, Trial 11 box11, 2, 3, 5, 10, 15 boxes1 box0.950.90012250Successful Plan Length1 box20015010015 boxes10 boxes1 box5 boxes3 boxes502 boxes1 box0012Number FeaturesFigure 16: C ONJUNCTIVE -B OXWORLD success ratio average successful plan length (averaged600 problems) first trial using relational learner.learned features straightforwardly describable English. first feature counts manyboxes correctly target city. second feature counts many boxes trucks.note lack features rewarding trucks right place (resultinglonger plan lengths due wandering value-function plateaus). features easily written knowledge representation (e.g. count trucks located cities destinationspackage truck), require quantification cities packages. severelimitation quantification currently method efficiency reasons prevents considerationfeatures point. also worth noting regression-based feature discovery, studied work Gretton Thiebaux (2004) Sanner Boutilier (2009), expectedidentify features regarding trucks regressing goal action unloadingpackage destination. Combining Bellman-error-based method regression-basedmethods promising future direction.Nevertheless, relational learner discovers two concise useful features dramaticallyreduce plan length relative initial policy random walk. significant successautomated domain-independent induction problem features.727fiW U & G IVANConjunctive-Boxworld, PropositionalSuccess Ratio10.80.60.40.2Successful Plan Length0024681002468100246810500450400350300250200150100500Accumulated Time (Hr.)450400350300250200150100500Number Features1 box2 box3 boxFigure 17: C ONJUNCTIVE -B OXWORLD performance (averaged 600 problems) accumulated run-time propositional learner, averaged two trials. Throughout learning process number cities 5.728fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGOne trial relational feature learner C ONJUNCTIVE -B OXWORLD takes several days,even though fixed number cities training problems five cities. New techniques required improving efficiency feature learning provide resultstraining larger numbers cities. results demonstrate current representationlearning methods adequately manage small city graphs even larger larger numbersboxes deliver, resulting value functions successfully generalize 10-city problems.domain, well known weakness AVI apparent. AVI often works practice,theoretical guarantee quality weight vector found AVI training. (Alternatively, approximate linear programming step could replace AVI training provideexpensive perhaps robust weight selection.) C ONJUNCTIVE -B OXWORLD results,AVI training goes astray selecting weights 12 box domain size Trial 1. result,selected weights overemphasize first feature, neglecting second feature. revealeddata shown plan-length performance degrades significantly one columndata. AVI repeated next problem size (13 boxes), good performance restored.similar one-column degradation plan length occurs trial 2 10-box 12-box sizes.propositional experiments C ONJUNCTIVE -B OXWORLD, note that, generally,adding learned propositional features degrades success-rate performance relative initialrandom walk policy introducing ineffective loops greedy policy. resulting greedypolicies find goal fewer steps random walk, generally pay unacceptable dropsuccess ratio so. one exception policy found one-box problems using twopropositional features, significantly reduces plan length preserving success ratio. Still,result much weaker relational feature language.problems get severe problem size increases, 3-box problems suffering severedegradation success rate modest gains successful plan length. Also please noteaccumulated runtime experiments large, especially 3-box problems. AVItraining expensive policies find goal. Computing greedy policystate long trajectory requires considering action, number available actionsquite large domain. reasons, propositional technique evaluate sizeslarger three boxes.7.3.3 UMMARY R ESULTSDDITIONAL OMAINSFigures 18 20, present summary results five additional probabilistic planning domains. detailed results full discussion domains, please see Appendix B.summary results, see feature learning approach successfully finds features perform well across increasing problem sizes two five domains, IREWORLD L IFTED F ILEWORLD 3. three domains (Z ENOTRAVEL, OWERS H ANOI, E XPLODINGB LOCKSWORLD), feature learning able make varying degrees progress fixed small problem sizes, progress (sometimes quite limited) generalize well size increases.7.3.4 E VALUATING R ELATIVE MPORTANCE B ELLMAN - ERROR CORINGG REEDY B EAM - SEARCH G OAL - ORIENTED OMAINSFigure 21 compares original algorithm alternatives vary either training setscoring greediness beam search, discussed Section 6.2. trial variant,generate greedy policy domain using feature selection within relational representation729fiW U & G IVANTireworld, Trial 1Success Ratio10.94 nodes4, 5 nodes6 nodes20, 30 nodes6 nodes9 nodes9, 10 nodes344 nodes0.80.70.64 nodes0.50.40Successful Plan Length0125620, 30 nodes54 nodes44 nodes4 nodes39, 10 nodes6, 9 nodes24, 5, 6 nodes10012345Number FeaturesZenotravel, Trial 1Success Ratio13 cities, 1 person, 1 aircraft0.80.63 cities, 2 people, 2 aircraft0.43 cities, 2 people, 2 aircraft00.2Successful Plan Length01234567895004003 cities, 2 people, 2 aircraft3 cities, 2 people, 2 aircraft3002003 cities, 1 person, 1 aircraft10000123456789Number FeaturesFigure 18: Summary results IREWORLD Z ENOTRAVEL. full discussion detailedresults, please see Appendix B.730fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGExploding Blocksworld, Trial 1Success Ratio10.83 blocks3 blocks3 blocks0.63 blocks4 blocks0.44 blocks0.20Successful Plan Length012345678910654 blocks44 blocks33 blocks3 blocks23 blocks3 blocks10012345678910Number FeaturesTower Hanoi, Trial 1Success Ratio12 discs0.80.64 discs0.43 discs0.25 discs4 discs0Successful Plan Length01234567209838105040303 discs20104 discs2 discs0012345678Number FeaturesFigure 19: Summary results E XPLODING B LOCKSWORLD OWERSdiscussion detailed results, please see Appendix B.731H ANOI. fullfiW U & G IVANSuccess RatioLifted-Fileworld3, Trial 11 file11 file1 file1 2 files14 16 files16 files2 14 files16 20 files0.950.9001234567Successful Plan Length6016 files14 files20 files4014 files15 files13 files12 files10 files11 files16 files16 files201 file1 file1 file4 files2 files3 files2 files1 file001234567Number FeaturesFigure 20: Summary results L IFTED -F ILEWORLD 3. full discussion detailed results,please see Appendix B.(alternating AVI training, difficulty increase, feature generation original algorithm).trial, domain, select best performing policy, running algorithmtarget problem difficulty reached improvement least three feature additions;latter case generating least nine features. evaluate greedy policy acquiredmanner, measuring average target-problem-size performance domain, averageresults two trials. results shown Figure 21.domain alternative Random Scoring perform comparably original GreedyBeam Search/BE Scoring, exception three domain/size combinations learnersperform poorly (Z ENOTRAVEL, 10-block E XPLODING B LOCKSWORLD, 5-disc OWERSH ANOI ). alternative Random Beam Narrowing sometimes adequate replace originalapproach, domains, greedy beam search critical performance.7.3.5 C OMPARISONFF-R EPLANFOALPcompare performance learned policies FF-Replan FOALPPPDDL evaluation domains used above. use problem generators provided planningcompetitions generate 30 problems tested problem size except OWERS H ANOI732fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGDomainSizeGreedy Beam/BE Scoring (orig.) SRGreedy Beam/BE Scoring (orig.) SLen.Random Scoring (var. 1) SRRandom Scoring (var. 1) SLen.Random Beam Narrowing (var. 2) SRRandom Beam Narrowing (var. 2) SLen.Random walk SRRandom walk SLen.BW200.9874800.012580Box Box Tire Zeno EX-BW EX-BW TOH TOH File(15,5) (10,10) 30 (10,2,2)51045 3010.98 0.92 0.110.340.03 0.51 0.00 19023551137623414 650.99 0.21 0.67 0.050.270.01 0.24 0.03 1946 1582691061213 26 21510.99 0.91 0.130.350.02 0.25 0.01 1902426112781938 84 2500.97 0.18 0.18 0.060.1300.09 0.00 11038 15796865414 14 251Figure 21: Target-problem-size performance (averaged 600 problems) relational featureslearned original algorithm two alternatives discussed Section 6.2,random walk, averaged best results two independent trialstarget problem size.L IFTED -F ILEWORLD 3, one fixed problem problem size. evaluateperformance planner 30 times problem, report Fig. 22 success ratioplanner problem size (averaged attempts). policies, learnedtwo independent trials shown above, indicated RFAVI #1 RFAVI #2. planner30-minute time limit attempt. average time required finish successful attemptlargest problem size domain reported Figure 23.two trials learner domain, evaluate policy performed best trial (first) target problem size. (Here, policy set featurescorresponding weight vector learned AVI trial.) Performance measuredsuccess rate, ties broken plan length. remaining ties broken taking laterpolicy trial tied. case, consider policy policylearned trial.results show planners performance incomparable FF-Replan (winning domains, losing others) generally dominates FOALP.RFAVI performs best planners larger B LOCKSWORLD, C ONJUNCTIVE B OXWORLD, IREWORLD problems. RFAVI essentially tied FF-Replan performanceL IFTED -F ILEWORLD 3. RFAVI loses FF-Replan remaining three domains, E XPLODINGB LOCKSWORLD, Z ENOTRAVEL, OWERS H ANOI. Reasons difficulties lastthree domains discussed sections presenting results domains. noteFOALP learned policy Z ENOTRAVEL, E XPLODING B LOCKSWORLD, OWERSH ANOI , L IFTED -F ILEWORLD 3.RFAVI relies random walk explore plateaus states differentiated selectedfeatures. reliance frequently results long plan lengths times results failure.recently reported elsewhere early results ongoing work remedying problemusing search place random walk (Wu et al., 2008).RFAVI learning approach different non-learning online replanning usedFF-Replan, problem determinized, dropping probability parameters.733fiW U & G IVANRFAVI #1RFAVI #2FF-ReplanFOALP15 blocks BW1 (483)1.00 (463)0.93 (52)1 (56)20 blocks BW1 (584)1.00 (578)0.91 (71)0.73 (73)25 blocks BW0.85 (1098)0.85 (1099)0.7 (96)0.2 (96)30 blocks BW0.75 (1243)0.77 (1227)0.23 (118)0.07 (119)RFAVI #1RFAVI #2FF-ReplanFOALP(10BX,5CI)Box1 (76)1 (75)1 (70)1 (35)(10BX,10CI)Box0.97 (225)0.97 (223)0.98 (256)0.70 (257)(10BX,15CI)Box0.93 (459)0.93 (454)0.93 (507)0.28 (395)(15BX,5CI)Box1 (90)1 (90)1 (88)0.99 (56)RFAVI #1RFAVI #2FF-ReplanFOALP20 nodes Tire0.87 (5)0.85 (4)0.76 (2)0.92 (4)30 nodes Tire0.85 (7)0.84 (7)0.73 (3)0.90 (5)40 nodes Tire0.98 (6)0.97 (6)0.83 (3)0.91 (5)(10CI,2PR,2AT)Zeno0.06 (1240)0.07 (1252)1 (99)N/ARFAVI #1RFAVI #2FF-ReplanFOALP5 blocks EX-BW0.25 (8)0.25 (8)0.91 (7)N/A10 blocks EX-BW 4 discs TOH0.02 (30)0.43 (4)0.01 (35)0.47 (4)0.45 (20)0.57 (3)N/AN/A5 discs TOH0 ()0 ()0.37 (7)N/A(20BX,20CI)Box0.82 (959)0.82 (989)0.35 (1069)0.0 (711)30 files Lifted-File1 (65)1 (65)1 (66)N/AFigure 22: Comparison planner (RFAVI) FF-Replan FOALP. Success ratiototal 900 attempts (30 attempts OWERS H ANOI L IFTED -F ILEWORLD 3)problem size reported, followed average successful plan lengthparentheses. two rows RFAVI map two learning trials shown paper.30 BW (20,20) BX 40 Tire (10,2,2) Zeno 10 EX-BW 5 TOH 30 FilesRFAVI #1106s83s1s51s2s1sRFAVI #2105s86s0s51s3s1sFF-Replan 872s739s0s1s8s3s10sFOALP16s173s24sN/AN/AN/AN/AFigure 23: Average runtime successful attempts, results shown Figure 22,largest problem size domain.734fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGimportant topic future research try combine benefits obtained differentplanners across domains.dominance RFAVI FOALP results implies RFAVI stateart among first-order techniques work problem lifted form use liftedgeneralization. Although FOALP uses first-order structure feature representation, learnedfeatures aimed satisfying goal predicates individually, whole. believegoal-decomposition technique sometimes work well small problems scale welllarge problems.comparisons, also noted FOALP read PPDDL domain descriptions directly, requires human-written domain axioms learning, unlike completelyautomatic technique (requiring numeric parameters characterizing domain).requirement human-written domain axioms one reasons FOALP competecompetition domains learned policy domainstested here.C ONJUNCTIVE -B OXWORLD11 , note FF-Replan uses outcomes problem determinization discriminate likely unlikely outcomes truck-movementactions. result, plans frequently selected rely unlikely outcomes (perhaps choosingmove truck undesired location, relying unlikely outcome accidentally movingdesired location). plans usually fail, resulting repeated replanning FF luckily selects high-likelihood outcome plan execution happens get desired low-likelihoodoutcome. behavior effect similar behavior learned value function exhibits because, discussed Section 7.3.2, learner failed find feature rewarding appropriatetruck moves. planners result long plan lengths due many unhelpful truck moves. However, learned policy conducts random walk trucks much efficiently (and thussuccessfully) online replanning FF-Replan, especially larger problem sizes.believe even dramatic improvements available improved knowledge representation features.7.4 SysAdminfull description YS DMIN domain provided work Guestrin, Koller, Parr(2001). Here, summarize description. YS DMIN domain, machines connecteddifferent topologies. machine might fail step, failure probability dependsnumber failed machines connected it. agent works toward minimizing numberfailed machines rebooting machines, one machine rebooted time step. problemn machines fixed topology, dynamic state space sufficiently described npropositional variables, representing on/off status certain machine.test domain purpose direct comparison performance propositional techniques published results work Patrascu et al. (2002). test exactlytopologies evaluated measure performance measure reported there, sup-norm Bellmanerror.evaluate method exact problems (same MDPs) used evaluationwork Patrascu et al. (2002) testing domain. Two different kinds topologies tested:11. hand-convert nested universal quantifiers conditional effects original BOXWORLD domain definitionequivalent form without universal quantifiers conditional effects allow FF-Replan read domain.735fiW U & G IVANCycle Topology3-legs TopologyFigure 24: Illustration two topologies YS DMIN domain (10 nodes). noderepresents machine. label indicates server machine, specified workPatrascu et al. (2002).3-legs cycle. 3-legs topology three three-node legs (each linear sequence threeconnected nodes) connected single central node one end. cycle topology arrangesten nodes one large cycle. 10 nodes topology. two topologiesillustrated Figure 24. target learning domain keep many machinesoperational possible, number operating machines directly determines rewardstep. Since 10 nodes basic features on/off statusesnodes, total 1024 states. reward-scaling parameter rscale (defined Section 5Online Appendix 1, available JAIR website, page 8) selected 10.work Patrascu et al. (2002) uses L (sup norm) Bellman error performancemeasurement YS DMIN. technique, described above, seeks reduce mean Bellmanerror directly L Bellman error. report L Bellman error, averaged twotrials, Figure 25. Also included Figure 25 results shown work Patrascu et al.(2002). select best result shown (from various algorithmic approaches) 3-legscycle topologies shown paper. correspond d-o-s setting cycletopology d-x-n setting 3-legs topology, terminology paper.topologies show algorithm reduces L Bellman error effectively perfeature well effectively overall experiments previously reported workPatrascu et al. (2002). topologies also show Bellman error eventually diverges AVI cannothandle complexity error function dimensionality increases. algorithm stillachieve low Bellman error remembering restoring best-performing weighted feature setweakened performance detected.note superior performance reducing Bellman error could due entirelypart use AVI weight training instead approximate linear programming (ALP),method used Patrascu et al. However, systematic superiority known AVI ALP,results suggest superior performance feature learning itself.736fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGSysAdmin, 3-Legs Topology3310129Bellman Error8765432101 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30Number Features3-legs, Learned3-legs, PatrascuSysAdmin, Cycle Topology25 42109Bellman Error8765432101 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31Number FeaturesCycle, LearnedCycle, PatrascuFigure 25: L Bellman error YS DMIN domain (10 nodes) two topologies. Valuesresults work Patrascu et al. (2002) taken Figure 2 3work Patrascu et al. (2002).7.5 Demonstration Generalization Across Problem Sizesasset relational feature representation presented paper learned relationalfeatures applicable problem size domain. section 2.4, discussed737fiW U & G IVANTarget problem sizes10 20 Tetris 15 blocks BW (15 box, 5 city) BX 30 nodes Tire 30 files Lifted-FileIntermediate problem sizes 10 10 Tetris 10 blocks BW (10 box, 5 city) BX 15 nodes Tire 10 files Lifted-FileGeneralize target sizeLearn intermediate sizeRandom walk551190.11 (171)1 (170)0 ()1 (76)1 (188)0.97 (893)0.88 (4)0.89 (4)0.29 (6)1 (25)1 (25)1 (88)Figure 26: Performance intermediate-sized problems generalization. showperformance value functions learned target problem sizes evaluatedintermediate-sized problems, demonstrate generalization sizes. comparison, also intermediate-sized problems, show performance value functions learned directly intermediate size well performance randomwalk. Generalization results intermediate size learning results averages twotrials. ETRIS, average accumulated rows erased shown. goal-orienteddomains, success ratio successful plan length (in parentheses) showndomain.modeling planning domain infinite set MDPs, one problem instancedomain. infinite set MDPs, feature vector plus weight vector defines singlevalue function well defined every problem instance MDP. discuss question whether framework find single feature/weight vector combination generalizesgood performance across problem sizes, i.e., value function V defined combination,whether Greedy(V ) performs similarly well different problem sizes.Throughout Section 7, demonstrated direct application learned feature/weightvectors target problem sizes, (without retraining weights)these results showntarget-size lines result tables domain. ETRIS, B LOCKSWORLD, C ONJUNCTIVE B OXWORLD, IREWORLD, L IFTED -F ILEWORLD 3, target-size lines demonstrate directsuccessful generalization target sizes even current problem sizes significantly smaller.(In domains, either notion problem size (S YS DMIN), insufficient planning progress significantly increase problem size learning small problems (E XPLOD ING B LOCKSWORLD , Z ENOTRAVEL , OWERS H ANOI ).)subsection, consider generalization (larger) target sizes selected intermediate sizes five domains. Specifically, take weight vectors feature vectorsresulting end trials (i.e. weight vector retrained target sizes), applydirectly selected intermediate problem sizes without weight retraining. trials terminate learning reaches target problem sizes12 , take weights features resultbest performing policy terminating problem sizes. generalization results shownFigure 26; comparison, table also shows performance intermediate-sizedproblems value function learned directly size, well performancerandom walk size.12. Note one trials ETRIS terminates reaching target size due non-improving performance,two trials L IFTED -F ILEWORLD 3 terminate target-size performance already reaches optimalitylearning reaches target size. Still, although value functions learned smaller sizestarget size, value functions evaluated generalization learned significantly larger sizesintermediate evaluation size.738fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGdomain shown random walk result much weaker generalization result,showing presence generalization learned value functions across problem sizes.four goal-oriented planning domains, applying value functions learned target sizes equalsperformance achieved value functions learned directly intermediate sizes (with betterperformance C ONJUNCTIVE -B OXWORLD). ETRIS, however, generalization resultmatch result learning intermediate size. note domains, solutionstrategy invariant respect problem size (e.g. destroying incorrect towers form correctones B LOCKSWORLD). domains best plan/strategy may change dramaticallysize. example, ETRIS, larger number rows board allows strategies temporarystack uncompleted rows, smaller number rows favors strategies complete rows quicklypossible. Thus one necessarily expect generalization domain sizes everydomainthis conclusion expected hold whether considering generalizationvalue functions policies.included discussion policy-based generalization related work section (Appendix A.4), focusing previous work approximate policy iteration. However, notepolicies generalize problems different sizes less well definedvalue functions generalize problems. previous API work, definedpolicies select actions states domain size; work define value functionsassign numeric values states domain size. None work guarantees finding goodoptimal policy value function; far know, problems admit good compact valuefunctions, admit good compact policies, admit both, neither.8. Discussion Future Researchpresented general framework automatically learning state-value functions featurediscovery gradient-based weight training. framework, greedily select featuresprovided hypothesis space (which parameter method) best correlate Bellmanerror features, use AVI find weights associate features.proposed two different candidate hypothesis spaces features. One twospaces relational one features first-order formulas one free-variable, beamsearch process used greedily select hypothesis. hypothesis space considered propositional feature representation features decision trees. hypothesisspace, use standard classification algorithm C4.5 (Quinlan, 1993) build feature bestcorrelates sign statewise Bellman error, instead using sign magnitude.performance feature-learning planners evaluated using reward-orientedgoal-oriented planning domains. demonstrated relational planner representsstate-of-the-art feature-discovering probabilistic planning techniques. propositional plannerperform well relational planner, cannot generalize problem instances,suggesting knowledge representation indeed critical success feature-discoveringplanners.Although present results propositional feature-learning approach relation featurelearning approach, knowledge representation difference differenceapproaches. Historically, propositional approach originally conceived reductionclassification learning, attempt capture magnitude Bellman error739fiW U & G IVANfeature selection, rather focuses sign error. contrast, relational approachcounts objects order match magnitude Bellman error.difference, cannot attribute performance differencesapproaches knowledge representation choice. differences performance could duechoice match sign propositional feature selection. possible future experimentidentify sources performance variation would use propositional representation involvingregression trees (Dzeroski, Todorovski, & Urbancic, 1995) capture magnitude error.representation might possibly perform somewhat better decision-tree representationshown here, course would still enable generalization sizes relationalfeature learner exhibits.Bellman-error reduction course one source guidance might followedfeature discovery. experiments IPPC planning domains, find manydomains successful plan length achieved much longer optimal, discussedSection 7.3.5. possible remedy deploying search previous work (Wu et al.,2008) learn features targeting dynamics inside plateaus, use features decisionmaking plateaus encountered.Acknowledgmentsmaterial based upon work supported part National Science Foundation GrantNo. 0905372.Appendix A. Related WorkA.1 Feature Selection ApproachesA.1.1 F EATURE ELECTIONVIAC ONSTRUCTIVE F UNCTION PPROXIMATIONAutomatic feature extraction sequential decision-making studied work UtgoffPrecup (1997), via constructive function approximation (Utgoff & Precup, 1998). workviewed forerunner general framework, limited propositional representations,binary-valued features, new features single-literal extensions old features conjunction. Also work Rivest Precup (2003) variant Cascade-Correlation (Fahlman& Lebiere, 1990), constructive neural network algorithm, combined TD-learning learnvalue functions reinforcement learning. Cascade-Correlation incrementally adds hidden unitsmulti-layered neural networks, hidden unit essentially feature built upon setnumerically-valued basic features. work provides framework generalizing prior efforts reduction supervised learning, explicit reliance Bellman error signal,feature hypothesis space corresponding learner deployed. particular,demonstrate framework binary propositional features using C4.5 learner richnumeric-valued relational features using greedy beam-search learner. work provides firstevaluation automatic feature extraction benchmark planning domains several planningcompetitions.work Utgoff Precup (1997) implicitly relies Bellman error,explicit construction Bellman error training set discussion selecting features correlate740fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGBellman error. instance, work focuses first refining current feature weightupdates converging poorly (high variance weight updates), whereas work focuses firstfinding feature correlates statewise Bellman error, regardless whether feature refinescurrent feature. addition, work selects features online weights currentfeatures adjusted, stationary target value function Bellmanerror considered selection next new feature. contrast, work separates weighttraining new feature selection completely. (These differences perhaps part duereinforcement learning setting used Utgoff & Precup, 1997, opposed planning settingwork.)selection hidden unit feature Cascade-Correlation (Fahlman & Lebiere, 1990) basedcovariance feature values errors output units. output unitsestimating value function, training data providing Bellman update value function,output unit error Bellman error. Thus, hidden units learned work RivestPrecup (2003) approximations Bellman-error features learned features are, although made explicit work. making goal capturing Bellman error explicithere, provide general reduction facilitates use learning method captureresulting feature-learning training sets. particular, able naturally demonstrate generalization across domain sizes several large domains, using relational feature learner. contrast,single test domain work Rivest Precup (2003) small fixed size. Nonetheless,work important precursor approach.A.1.2 F EATURE C ONSTRUCTIONVIAPECTRAL NALYSISFeature-learning frameworks value functions based upon spectral analysis state-space connectivity presented work Mahadevan Maggioni (2007) Petrik (2007).frameworks, features eigenvectors connectivity matrices constructed random walk (Mahadevan & Maggioni, 2007) eigenvectors probabilistic transition matrices (Petrik, 2007).features capture aspects long-term problem behaviours, opposed short-term behaviourscaptured Bellman-error features. Bellman-error reduction requires iteration capture longterm behaviors.Reward functions considered feature construction work Mahadevan Maggioni (2007); work Petrik (2007), reward functions incorporatedlearning Krylov basis features, variant Bellman error features (Parr et al., 2008), complement eigenvector features. However, even Petriks framework, reward incorporatedfeatures used policy evaluation rather controlled environment consider.Essential work use machine learning factored representations handlelarge statespaces generalize problems different sizes. spectralanalysis frameworks limited respect (at least current state development). approach Petrik (2007) presented explicit statespaces, factorization approachscaling large discrete domains proposed work Mahadevan Maggioni (2007).approach, features learned dimension factorization, independentdimensions. believe assumption independence dimensions inappropriatemany domains, including benchmark planning domains considered work. Mahadevan Maggioni factorization approach also suffers drawbacks propositionalapproach: solution recomputed problems different sizes domain741fiW U & G IVANlacks flexibility generalize problems different sizes provided relationalapproach.A.2 Structural Model-based Model-free Solution Methods Markov DecisionProcessesA.2.1 R ELATIONAL R EINFORCEMENT L EARNINGwork Dzeroski et al. (2001), relational reinforcement learning (RRL) system learnslogical regression trees represent Q-functions target MDPs. work related sinceuse relational representations automatically construct functions capture state value.addition Q-function trees, policy tree learner also introduced work Dzeroskiet al. (2001) finds policy trees based Q-function trees. learn explicit policydescription instead use greedy policies evaluation.logical expressions RRL regression trees used decision points computingvalue function (or policy) rather numerically valued features linear combination,method. Generalization across problem sizes achieved learning policy trees; learned valuefunctions apply training problem sizes. date, empirical results approachfailed demonstrate ability represent value function usefully familiar planningbenchmark domains. good performance shown simplified goals placingparticular block onto particular block B, technique fails capture structure richerproblems constructing particular arrangements Blocksworld towers. RRLentered international planning competitions. difficulties representing complexrelational value functions persist extensions original RRL work (Driessens & Dzeroski,2004; Driessens et al., 2006), limited applicability shown benchmark planningdomains used work.A.2.2 P OLICY L EARNING VIA B OOSTINGwork Kersting Driessens (2008), boosting approach introduced incrementallylearn features represent stochastic policies. policy-iteration variant featurelearning framework, clearly differs work policy representations learned insteadvalue function representations. Using regression tree learner TILDE (Blockeel & De Raedt,1998), feature learner demonstrated advantages previous RRL work task accomplishing on(A,B) 10-block problem. Applicability simple continuous domain (the corridorworld) also demonstrated. line RRL work, limited applicability benchmarkplanning domains shown here. One probable source limited applicability model-freereinforcement-learning setting system model problem dynamics explicitly.A.2.3 F ITTED VALUE TERATIONGordon (1995) presented method value iteration called fitted value iteration suitablelarge state spaces require direct feature selection. Instead, method reliesprovided kernel function measuring similarity states. Selection kernel functionviewed kind feature selection, kernel identifies state aspects significantmeasuring similarity. knowledge, techniques class appliedlarge relational planning problems like evaluated paper. note selection742fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGsingle relational kernel domains would measure state similarity domain-independentmanner thus believe kernel could adapt individual domains waywork does. Thus would expect inferior performance approach; however,remains investigated. Selection domain-specific kernels stochastic planning domains,automatically, also yet explored.A.2.4 E XACT VALUE TERATION F IRST- ORDER MDPPrevious work used lifted techniques exactly solve first-order MDPs reformulating exactsolution techniques explicit MDPs, value iteration. Boutilier et al. (2001) Holldobler Skvortsova (2004) independently used two different first-order languages (situationcalculus fluent calculus, respectively) define first-order MDPs. works, Bellman update procedure value iteration reformulated using respective calculus, resultingtwo first-order dynamic-programming methods: symbolic dynamic programming (SDP), firstorder value iteration (FOVI). simple boxworld example human-assisted computationdemonstrated SDP work, method serves basis FOALP (Sanner & Boutilier,2009), replaces exact techniques heuristic approximation order scale techniquesbenchmark planning domains. Application FOVI planning domains demonstratedcolored blocksworld benchmark, limited 10 blocks (Holldobler, Karabaev, &Skvortsova, 2006).work Kersting et al. (2004), constraint logic programming used define relationalvalue iteration method. MDP components, states, actions, rewards, first abstractedform Markov decision program, lifted version MDP. relational Bellman operation(ReBel) used define updates Q-values state values. Empirical study ReBelapproach limited 10-step backups single-predicate goals blocksworldlogistics domains.Exact techniques suffer difficulty representing full complexity state-valuefunction arbitrary goals even mildly complex domains. previous works serve illustrate central motivation using problem features compactly approximate structurecomplex value function, thus motivate automatic extraction features studiedwork.A.3 Comparison Inductive Logic Programming Algorithmsproblem selecting numeric function relational states match Bellman-error trainingset first-order regression problem available systems describedInductive logic programming (ILP) literature (Quinlan, 1996; Karalic & Bratko, 1997).important note ILP work studied learning classifiers relationaldata (Muggleton, 1991), concerned learning numeric functions relationaldata (such states). latter problem called first-order regression within ILP literature, received less study relational classification. Here, choose designproof-of-concept relational learner experiments rather use one previoussystems. Separate work needed compare utility relational learner previousregression systems; purpose demonstrate utility Bellman-error training datafinding decision-theoretic value-function features. simple learner suffices createstate-of-the-art domain-independent planning via automatic feature selection.743fiW U & G IVANILP classification systems often proceed either general specific, specificgeneral, seeking concept match training data. regression, however,easy ordering numeric functions searched. design instead method searchesbasic logical expression language simple expressions complex expressions, seekinggood matches training data. order control branching factor, still allowingcomplex expressions considered, heuristically build long expressionsshort expressions score best. words, use beam search space expressions.several heuristic aspects method. First, define heuristic set basic expressions search begins. Second, define heuristic method combiningexpressions build complex expressions. two heuristic elements designedlogical formula without disjunction, one free variable, built repeated combination basic expressions. Finally, assumption high-scoring expressions builthigh-scoring parts heuristic (and often true). critical heuristic assumptionmakes likely learner often miss complex features match training data well.known method guarantees tractably finding features.A.4 Approximate Policy Iteration Relational Domainsplanners use greedy policies derived learned value functions. Alternatively, one directly learn representations policies. policy-tree learning work Dzeroski et al.(2001), discussed previously Appendix A.2.1, one example. Recent work uses relational decision-list language learn policies small example problems generalize wellperform large problems (Khardon, 1999; Martin & Geffner, 2004; Yoon et al., 2002). Dueinductive nature line work, however, selected policies occasionally contain severeflaws, mechanism provided policy improvement. policy improvement quitechallenging due astronomically large highly structured state spaces relational policylanguage.work Fern et al. (2006), approximate version policy iteration addressingissues presented. Starting base policy, approximate policy iteration iteratively generatestraining data improved policy (using policy rollout) uses learning algorithmwork Yoon et al. (2002) capture improved policy compact decision-list languageagain. Similar work, learner work Fern et al. (2006) aims take flawedsolution structure improve quality using conventional MDP techniques (in case, findingimproved policy policy rollout) machine learning. Unlike work, work Fernet al. (2006) improved policies learned form logical decision lists. workviewed complementary previous work exploring structured representation valuefunctions work explored structured representation policies. approacheslikely relevant important long-term effort solve structured stochastic decisionmaking problems.note feature-based representation, considered generally MDP literature, used represent value functions rather policies. Compact representation policiesdone via value functions (with greedy execution) directly, example, using decision lists. previous API work discussed uses direct representation policies, neveruses compact representation value functions. Instead, sampling value functions usedpolicy evaluation step policy iteration.744fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGOne imagine different novel approach API compact feature-basedrepresentation used value functions, greedy execution policy representation.approach, feature discovery similar explore value iteration could designed assist policy evaluation phase policy iteration. leave developmentevaluation idea future work. expect two approaches API, wellcurrent approach value iteration, advantages disadvantages vary domainways yet well understood. domains natural compact direct policyrepresentations (run see tarantula), whereas others naturally compactly representedvia value functions (prefer restaurants good review ratings). Research area musteventually develop means combine compact representations effectively.A.5 Automatic Extraction Domain Knowledgesubstantial literature learning plan using methods direct representationvalue function reactive policy, especially deterministic planning literature.techniques related acquire domain specific knowledge via planning experience domain. Much literature targets control knowledge particular search-basedplanners (Estlin & Mooney, 1997; Kambhampati et al., 1996; Veloso et al., 1995), distantapproach focus particular planning technology used limitationdeterministic domains. unclear generalize work value-function constructionprobabilistic domains.However, broader learning-to-plan literature also contains work producing declarativelearned domain knowledge could well exploited feature discovery value function representation. work Fox Long (1998), pre-processing module called TIMable infer useful domain-specific problem-specific structures, typing objectsstate invariants, descriptions domain definition initial states. invariantstargeted work improving planning efficiency Graphplan based planner, suggestfuture work could exploit invariants discovering features value function representation. Similarly, work Gerevini Schubert (1998), DISCOPLAN infers state constraintsdomain definition initial state order improve performance SAT-based planners; again, constraints could incorporated feature search like methoddate.Appendix B. Results Discussions Five Probabilistic Planning CompetitionDomainsSection 7.3, presented results relational propositional feature learnersB LOCKSWORLD C ONJUNCTIVE -B OXWORLD. present results relationalfeature learner following five probabilistic planning competition domains: IREWORLD,Z ENOTRAVEL, E XPLODING B LOCKSWORLD, OWERS H ANOI, L IFTED -F ILEWORLD 3.B.1 Tireworlduse IREWORLD domain second IPPC. agent needs drive vehiclegraph start node goal node. moving one node adjacent node,vehicle certain chance suffering flat tire (while still arriving adjacent node).745fiW U & G IVANTrial #1# features012333445Problem difficulty444456699Success ratio0.52 0.81 0.84 0.86 0.86 0.84 0.88 0.85 0.86Plan length434222334Accumulated time (Hr.) 0.3 3.1 12 17 18 18 19 21 220.17 0.53 0.81 0.83 0.83 0.82 0.90 0.91 0.91Target size SRTarget size Slen.5495446665100.864230.916Trial #2# features012333444Problem difficulty444456610 200.52 0.81 0.85 0.86 0.93 0.81 0.89 0.85 0.86Success ratioPlan length433232344Accumulated time (Hr.) 0.5 3.7 6.9 10 11 11 12 14 18Target size SR0.19 0.49 0.80 0.82 0.91 0.62 0.92 0.91 0.90Target size Slen.7394525564300.885240.8865200.915290.9255300.915360.926Figure 27: IREWORLD performance (averaged 600 problems) relational learner. addone feature per column success ratio exceeds 0.85 average successful planlength less 4n, n nodes, increase problem difficulty nextcolumn. Plan lengths shown successful trials only. Problem difficulties measurednumber nodes, target problem size 30 nodes. columns omitteddiscussed Section 7.1.flat tire replaced spare tire, spare tire present nodecontaining vehicle, vehicle carrying spare tire. vehicle pick sparetire already carrying one one present node containing vehicle.default setting second-IPPC problem generator domain defines problem distributionincludes problems policy achieving goal probability one.problems create tradeoff goal-achievement probability expected number stepsgoal. strongly planner favors goal achievement versus short trajectories goaldetermined choice discount factor made Section 6.1.start 4-node problems relational learner increase n nodes n + 1nodes whenever success ratio exceeds 0.85 average successful plan length better4n steps. target problem size 30 nodes. results shown Figures 18 27.IREWORLD, relational learner able find features generalize well largeproblems. learner achieves success ratio 0.9 30 node problems. unknownwhether policy exceed success ratio problem distribution; however, neithercomparison planner, FOALP FF-Replan, finds higher success-rate policy.note improvements success rate domain necessarily associatedincreases plan length success-rate improvements may due path deviationsacquire spare tires.746fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGTrial #1# featuresProblem difficultySuccess ratioPlan lengthAccumulated time (Hr.)Target size SRTarget size Slen.03,1,10.792530.750.0691613,1,10.82551.70.08102413,2,20.594133.40.09106423,2,20.524407.10.09111433,2,20.54437110.12105043,2,20.55450150.11112553,2,20.54411190.10111163,2,20.52440250.08111573,2,20.56426300.11106183,2,20.53428360.08117493,2,20.55451410.121195Trial #2# featuresProblem difficultySuccess ratioPlan lengthAccumulated time (Hr.)Target size SRTarget size Slen.03,1,10.772621.30.0581413,1,10.792542.30.10100823,1,10.802333.30.10100723,2,20.553915.30.09106733,2,20.554258.90.09108843,2,20.50415130.08101453,2,20.53422170.10107863,2,20.120220.02073,2,20.120290.02083,2,20.120360.02093,2,20.100430.010Figure 28: Z ENOTRAVEL performance (averaged 600 problems) relational learner.problem difficulty shown table lists numbers cities, travelers, aircraft,target problem size 10 cities, 2 travelers, 2 aircraft. add one featureper column success ratio exceeds 0.8, increase problem difficultynext column. Plan lengths shown successful trials only.B.2 Zenotraveluse Z ENOTRAVEL domain second IPPC. goal domain fly travelers original location destination. Planes (finite-range, discrete) fuel levels,need re-fuelled fuel level reaches zero cont inue flying. available activity(boarding, debarking, flying, zooming, refueling) divided two stages, activityX modelled two actions start-X finish-X. finish-X activity (high) probabilitynothing. start action taken, corresponding finish action must taken(repeatedly) succeeds conflicting action started. structure allowsfailure rates finish actions simulate action costs (which used explicitlyproblem representation competition). plane moved locations flyingzooming. Zooming uses fuel flying, higher success probability.start problem difficulty 3 cities, 1 traveler, 1 aircraft using relationalfeature learner. Whenever success ratio exceeds 0.8, increase number n travelersaircraft 1 number cities less 5n 2, increase number cities oneotherwise. target problem size 10 cities, 2 travelers, 2 aircraft. Z ENOTRAVEL resultsrelational learner shown Figures 18 28.747fiW U & G IVANrelational learner unable find features enable AVI achieve threshold successrate (0.8) 3 cities, 2 travelers, 2 aircraft, although 9 relational features learned. trialsstopped improvement performance achieved several iterations featureaddition. Using broader search (W = 160, q = 3, = 3) able find better featuresextend solvable size several cities success rate 0.9 (not shown resultspaper use search parameters, reported Wu & Givan, 2007), runtime alsoincreases dramatically, weeks. believe speed effectiveness relational learningneeds improved excel domain, likely major factor improved knowledgerepresentation features key concepts Z ENOTRAVEL easily represented.Trial two Figure 28 shows striking event adding single new feature useful valuefunction results value function greedy policy cannot find goal all,success ratio degrades dramatically immediately. Note small problem size,ten percent problems trivial, initial state satisfies goal. additionsixth feature trial two, problems policy solve. reflectsunreliability AVI weight-selection technique aspect feature discovery:all, AVI free assign zero weight new feature, not. Additional studycontrol AVI and/or replacement AVI linear programming methods indicatedphenomenon; however, rare event extensive experiments.B.3 Exploding Blocksworldalso use E XPLODING B LOCKSWORLD second IPPC evaluate relational planner.domain differs normal Blocksworld largely due blocks certain probability detonated put down, destroying objects beneath (butdetonating block). Blocks already detonated detonated again. goalstate domain described tower fragments, fragments generally requiredtable. Destroyed objects cannot picked up, blocks cannot put destroyed objects (but destroyed object still part goal necessary relationshipsestablished destroyed).start 3-block problems using relational learner increase n blocks n + 1blocks whenever success ratio exceeds 0.7. target problem sizes 5 10 blocks.E XPLODING B LOCKSWORLD results relational learner shown Figures 19 29.results E XPLODING B LOCKSWORLD good enough planner increasedifficulty beyond 4-block problems, results show limited generalization 5-blockproblems, little generalization 10-block problems.performance domain quite weak. believe due presence manydead-end states reachable high probability. states either tableone blocks needed goal destroyed, object question achievedrequired properties. planner find meaningful relevant features: planner discoversundesirable destroy table, instance. However, resulting partial understanding domain cannot augmented random walk (as domainsB LOCKSWORLD C ONJUNCTIVE -B OXWORLD) enable steady improvement value, leading goal; random walk domain invariably lands agent dead end. shortsuccessful plan length, low probability reaching goal, (not shown here) high unsuccessful plan length (caused wandering dead end region) suggest need new techniques748fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGTrial #1# features0123Problem difficulty3333Success ratio0.56 0.58 0.56 0.63Plan length1212Accumulated time (Hr.) 0.6 1.4 2.2 3.10.12 0.12 0.14 0.22Target size #1 SRTarget size #1 Slen.3335Target size #2 SR000 0.00Target size #2 Slen.10430.5614.20.2040.004Trial #2# features01234Problem difficulty33333Success ratio0.56 0.56 0.55 0.63 0.55Plan length12121Accumulated time (Hr.) 0.6 1.3 2.1 2.9 3.7Target size #1 SR0.14 0.15 0.12 0.18 0.1743464Target size #1 Slen.Target size #2 SR000 0.01 0.00Target size #2 Slen.19 185677893334440.68 0.62 0.71 0.4 0.45 0.431224545.9 8.7 11 12 20 280.31 0.16 0.34 0.33 0.31 0.316966550.03 0 0.02 0.03 0.02 0.0224 19 26 23 22530.7524.60.3360.0226540.4545.30.3160.0127640.455140.3260.0115740.435220.3160.0221840.424310.2850.01151040.445380.2950.0115940.364390.3050.0118Figure 29: E XPLODING B LOCKSWORLD performance (averaged 600 problems) relationallearner. Problem difficulties measured number blocks. add one feature percolumn success ratio exceeds 0.7, increase problem difficulty nextcolumn. Plan lengths shown successful trials only. Target problem size #1 5blocks, target problem size #2 10 blocks.aimed handling dead-end regions handle domain. results demonstrate technique relies random walk (or form search) learned features needcompletely describe desired policy.B.4 Towers Hanoiuse domain OWERS H ANOI first IPPC. probabilistic version wellknown problem, agent move one two discs simultaneously, small probabilitygoing dead-end state move, probability depends whether largest discmoved type disc move (one two time) used. noteone planning problem problem size here.important note 100% success rate generally unachievable domain dueunavoidable dead-end states.749fiW U & G IVANTrial #1# featuresProblem difficultySuccess ratioPlan lengthAccumulated time (Hr.)Target size #1 SRTarget size #1 Slen.Target size #2 SRTarget size #2 Slen.011233456788 20 38223334444445550.70 0.75 0.11 0.44 0.73 00000 0.51 000424326440.0 0.0 0.1 0.2 0.3 0.4 0.5 1.1 1.2 2.1 2.2 2.3 18 530.07 0.15 0.01 0.08 0.03 00000 0.52 0.53 0 0.431399095374440.00 000 0.00 00000000011107Trial #2# featuresProblem difficultySuccess ratioPlan lengthAccumulated time (Hr.)Target size #1 SRTarget size #1 Slen.Target size #2 SRTarget size #2 Slen.00123345678233334444440.71 0.23 0.14 0.42 0.75 00000 0.534123725440.0 0.0 0.2 0.3 0.3 0.4 0.5 1.1 1.9 2.3 2.60.1 0.09 0.0 0.09 0.03 00000 0.491411 105 954140.00 0.100 0.00 00000016291078502.700205060038501600Figure 30: OWERS H ANOI performance (averaged 600 problems) relational learner.add one feature per column success ratio exceeds 0.7n1 n discs,increase problem difficulty next column. Plan lengths shown successful trialsonly. Problem difficulties measured number discs, target problem size #14 discs size #2 5 discs. columns omitted discussed Section 7.1.start 2-disc problem relational learner increase problem difficultyn discs n + 1 discs whenever success ratio exceeds 0.7n1 . target problem sizes4 5 discs. OWERS H ANOI results relational learner shown Figures 19 30.learner clearly able adapt three- four-disc problems, achieving around 50%success rate four disc problem trials. optimal solution four disc problemsuccess rate 75%. policy uses single disc moves large disc moveduses double disc moves. Policies use single disc moves double disc movesachieve success rates 64% 58%, respectively, four disc problem. learned solutionoccasionally moves disc way get closer goal, reducing success.Unfortunately, trials show increasing number new features needed adaptlarger problem size, trials even 38 total features enough adaptfive-disc problem. Thus, know approach extend even five discs. Moreover,results indicate poor generalization problem sizes.believe difficult learner (and humans) represent good value functionacross problem sizes. Humans deal domain formulating good recursive policy,establishing direct idea value state. Finding recursive policy automaticallyinteresting open research question outside scope paper.750fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGB.5 Lifted-Fileworld3described Section 6.1, use domain L IFTED -F ILEWORLD 3, straightforwardlylifted form F ILEWORLD first IPPC, restricted three folders. reach goal filingfiles, action needs taken file randomly determine folder filego into. actions taking folder, putting file folder, returning foldercabinet. goal reached files correctly filed targeted folders.note F ILEWORLD L IFTED -F ILEWORLD 3 benign domains.reachable dead ends non-optimal actions, directly reversible.Random walk solves domain success rate one even thirty files. technical challengeposed minimize unnecessary steps minimize plan length. optimal policysolves n-file problem 2n + 1 2n + 5 steps, depending random file typesgenerated.Rather preset plan-length threshold increasing difficulty (as function n),adopt policy increasing difficulty whenever method fails improve plan length addingfeatures. Specifically, success ratio exceeds 0.9 one feature added without improvingplan length, remove feature increase problem difficulty instead.13start 1 file problems relational learner increase n files n + 1 fileswhenever performance improve upon feature addition. target problem size 30files. L IFTED -F ILEWORLD 3 results relational learner shown Figures 20 31.results show planner acquires optimal policy 30-file target size problemlearning four features, two trials. results domain revealweakness AVI weight-selection method. Although four features enough define optimal policy, problem difficulty increases, AVI often fails find weight assignment producingpolicy. happens, feature addition triggered, trial 1.domain, results show extra features prevent AVI finding good weightssubsequent iterations, optimal policy recovered larger feature set. Nonetheless, another indication improved performance may available via work alternativeweight-selection approaches, orthogonal topic feature selection.ReferencesBacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledgeplanning. Artificial Intelligence, 116, 123191.Bertsekas, D. P. (1995). Dynamic Programming Optimal Control. Athena Scientific.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.Blockeel, H., & De Raedt, L. (1998). Top-down induction first-order logical decision trees.Artificial Intelligence, 101, 285297.Bonet, B., & Givan, R. (2006). Non-deterministic planning track 2006 international planningcompetition. Website. http://www.ldc.usb.ve/ bonet/ipc5/.13. possible specify plan-length threshold function triggering increase difficulty domain,done domains. find domain quite sensitive choice function, endmust chosen trigger difficulty increase feature addition fruitless current difficulty.So, directly implemented automatic method triggering difficulty increase.751fiW U & G IVANTrial #1# features0 1 21 1 1Problem difficultySuccess ratio1 1 114 8 4Plan lengthAccumulated time (Hr.) 0.0 0.0 0.0Target size SR1 1 1Target size Slen.251 134 8731130.0032170.1042160.1043190.10441110.21.00874121295.91934131317.31654141498.919051413710191515135131655161551519161613717165716137191657181413716571914349111172014562165Trial #2# features0 1 2Problem difficulty1 1 1Success ratio1 1 114 8 4Plan lengthAccumulated time (Hr.) 0.0 0.0 0.01 1 1Target size SRTarget size Slen.251 135 8831130.0032170.1042160.1043190.1044 4 4 445 8 9 1011 1 1 112 14 21 23 250.2 0.6 2.5 3.1 3.90.96 1 1 1 185 88 82 82 914141339.01964151351118741616213191417165191934181412719741914330165420149341654231915011074241536618242515574165481212.41.00824101253.81914111304.8188Figure 31: L IFTED -F ILEWORLD 3 performance (averaged 600 problems) relationallearner. add one feature per column success ratio exceeds 0.9 adding oneextra feature improve plan length, increase problem difficultynext column (after removing extra feature). Plan lengths shown successful trialsonly. Problem difficulties measured number files, target problem size30 files. columns omitted discussed Section 7.1.Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming first-order MDPs.Proceedings Seventeenth International Joint Conference Artificial Intelligence,pp. 690700.Chandra, A., & Merlin, P. (1977). Optimal implementation conjunctive queries relational databases. Proceedings Ninth Annual ACM Symposium Theory Computing, pp.7790.Davis, R., & Lenat, D. (1982). Knowledge-Based Systems Artificial Intelligence. McGraw-Hill,New York.Driessens, K., & Dzeroski, S. (2004). Integrating guidance relational reinforcement learning.Machine Learning, 57, 271304.Driessens, K., Ramon, J., & Gartner, T. (2006). Graph kernels gaussian processes relationalreinforcement learning. Machine Learning, 64, 91119.Dzeroski, S., DeRaedt, L., & Driessens, K. (2001). Relational reinforcement learning. MachineLearning, 43, 752.Dzeroski, S., Todorovski, L., & Urbancic, T. (1995). Handling real numbers ILP: step towardsbetter behavioural clones. Proceedings Eighth European Conference MachineLearning, pp. 283286.752fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGEstlin, T. A., & Mooney, R. J. (1997). Learning improve efficiency quality planning.Proceedings Fifteenth International Joint Conference Artificial Intelligence, pp.12271232.Fahlman, S., & Lebiere, C. (1990). cascade-correlation learning architecture. AdvancesNeural Information Processing Systems 2, pp. 524 532.Farias, V. F., & Van Roy, B. (2004). Tetris: study randomized constraint sampling. Probabilistic Randomized Methods Design Uncertainty. Springer-Verlag.Fawcett, T. (1996). Knowledge-based feature discovery evaluation functions. ComputationalIntelligence, 12(1), 4264.Fern, A., Yoon, S., & Givan, R. (2004). Learning domain-specific control knowledge randomwalks. Proceedings Fourteenth International Conference Automated PlanningScheduling, pp. 191199.Fern, A., Yoon, S., & Givan, R. (2006). Approximate policy iteration policy language bias:Solving relational Markov decision processes. Journal Artificial Intelligence Research, 25,75118.Fox, M., & Long, D. (1998). automatic inference state invariants TIM. Journal ArtificialIntelligence Research, 9, 367421.Gerevini, A., & Schubert, L. (1998). Inferring state constraints domain-independent planning.Proceedings Fifteenth National Conference Artificial Intelligence, pp. 905912.Gordon, G. (1995). Stable function approximation dynamic programming. ProceedingsTwelfth International Conference Machine Learning, pp. 261268.Gretton, C., & Thiebaux, S. (2004). Exploiting first-order regression inductive policy selection.Proceedings Twentieth Conference Uncertainty Artificial Intelligence, pp. 217225.Guestrin, C., Koller, D., & Parr, R. (2001). Max-norm projections factored MDPs. Proceedings Seventeenth International Joint Conference Artificial Intelligence, pp. 673680.Holldobler, S., Karabaev, E., & Skvortsova, O. (2006). FluCaP: heuristic search plannerfirst-order MDPs. Journal Artificial Intelligence Research, 27, 419439.Holldobler, S., & Skvortsova, O. (2004). logic-based approach dynamic programming.Proceedings Workshop Learning Planning Markov ProcessesAdvancesChallenges Nineteenth National Conference Artificial Intelligence, pp. 3136.Kakade, S. (2001). natural policy gradient. Advances Neural Information ProcessingSystems 14, pp. 15311538.Kambhampati, S., Katukam, S., & Qu, Y. (1996). Failure driven dynamic search control partialorder planners: explanation based approach. Artificial Intelligence, 88(1-2), 253315.Karalic, A., & Bratko, I. (1997). First order regression. Machine Learning, 26, 147176.Keller, P., Mannor, S., & Precup, D. (2006). Automatic basis function construction approximate dynamic programming reinforcement learning. Proceedings Twenty-ThirdInternational Conference Machine Learning, pp. 449456.753fiW U & G IVANKersting, K., Van Otterlo, M., & De Raedt, L. (2004). Bellman goes relational. ProceedingsTwenty-First International Conference Machine Learning, pp. 465472.Kersting, K., & Driessens, K. (2008). Non-parametric policy gradients: unified treatmentpropositional relational domains. Proceedings Twenty-Fifth International Conference Machine learning, pp. 456463.Khardon, R. (1999). Learning action strategies planning domains. Artificial Intelligence, 113(12), 125148.Lagoudakis, M. G., Parr, R., & Littman, M. L. (2002). Least-squares methods reinforcementlearning control. SETN 02: Proceedings Second Hellenic Conference AI, pp.249260.Mahadevan, S., & Maggioni, M. (2007). Proto-value functions: Laplacian framework learning representation control Markov decision processes. Journal Machine LearningResearch, 8, 21692231.Martin, M., & Geffner, H. (2004). Learning generalized policies planning examples usingconcept languages. Applied Intelligence, 20, 919.Mitchell, T. M. (1997). Machine Learning. McGraw-Hill.Muggleton, S. (1991). Inductive logic programming. New Generation Computing, 8(4), 295318.Parr, R., Li, L., Taylor, G., Painter-Wakefield, C., & Littman, M. (2008). analysis linearmodels, linear value-function approximation, feature selection reinforcement learning.Proceedings Twenty-Fifth International Conference Machine Learning, pp. 752759.Parr, R., Painter-Wakefield, C., Li, L., & Littman, M. (2007). Analyzing feature generationvalue-function approximation. Proceedings Twenty-Fourth International ConferenceMachine Learning, pp. 737744.Patrascu, R., Poupart, P., Schuurmans, D., Boutilier, C., & Guestrin, C. (2002). Greedy linear valueapproximation factored Markov decision processes. Proceedings EighteenthNational Conference Artificial Intelligence, pp. 285291.Petrik, M. (2007). analysis Laplacian methods value function approximation MDPs.Proceedings twentith International Joint Conference Artificial Intelligence, pp.25742579.Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann.Quinlan, J. R. (1996). Learning first-order definitions functions. Journal Artificial IntelligenceResearch, 5, 139161.Rivest, F., & Precup, D. (2003). Combining TD-learning cascade-correlation networks.Proceedings Twentieth International Conference Machine Learning, pp. 632639.Sanner, S., & Boutilier, C. (2006). Practical linear value-approximation techniques first-orderMDPs. Proceedings Twenty-Second Conference Uncertainty Artificial Intelligence, pp. 409417.Sanner, S., & Boutilier, C. (2009). Practical solution techniques first-order MDPs. ArtificialIntelligence, 173(5-6), 748788.754fiAUTOMATIC NDUCTION B ELLMAN -E RROR F EATURES P ROBABILISTIC P LANNINGSingh, S., Jaakkola, T., Littman, M., & Szepesvari, C. (2000). Convergence results single-stepon-policy reinforcement-learning algorithms. Machine Learning, 38(3), 287308.Sutton, R. S. (1988). Learning predict methods temporal differences. Machine Learning,3, 944.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.Szita, I., & Lorincz, A. (2006). Learning tetris using noisy cross-entropy method. NeuralComputation, 18, 29362941.Tesauro, G. (1995). Temporal difference learning TD-Gammon. Communications ACM,38(3), 5868.Tsitsiklis, J., & Roy, B. V. (1997). analysis temporal-difference learning function approximation. IEEE Transactions Automatic Control, 42(5), 674690.Utgoff, P. E., & Precup, D. (1997). Relative value function approximation. Tech. rep., UniversityMassachusetts, Department Computer Science.Utgoff, P. E., & Precup, D. (1998). Constuctive function approximation. Motoda, & Liu (Eds.),Feature Extraction, Construction, Selection: Data-Mining Perspective, pp. 219235.Kluwer.Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating planninglearning: PRODIGY architecture. Journal Experimental Theoretical AI, 7(1),81120.Widrow, B., & Hoff, Jr, M. E. (1960). Adaptive switching circuits. IRE WESCON ConventionRecord, 96104.Williams, R. J., & Baird, L. C. (1993). Tight performance bounds greedy policies basedimperfect value functions. Tech. rep., Northeastern University.Wu, J., & Givan, R. (2007). Discovering relational domain features probabilistic planning.Proceedings Seventeenth International Conference Automated PlanningScheduling, pp. 344351.Wu, J., Kalyanam, R., & Givan, R. (2008). Stochastic enforced hill-climbing. ProceedingsEighteenth International Conference Automated Planning Scheduling, pp. 396403.Wu, J., & Givan, R. (2005). Feature-discovering approximate value iteration methods. Proceedings Symposium Abstraction, Reformulation, Approximation, pp. 321331.Yoon, S., Fern, A., & Givan, R. (2002). Inductive policy selection first-order MDPs. Proceedings Eighteenth Conference Uncertainty Artificial Intelligence, pp. 568576.Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning. Proceedings Seventeenth International Conference Automated Planning Scheduling, pp. 352358.Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic trackinternational planning competition. Journal Artificial Intelligence Research, 24, 851887.755fiJournal Artificial Intelligence Research 38 (2010) 189-221Submitted 10/09; published 05/10Constructing Reference Sets Unstructured,Ungrammatical TextMatthew Michelsonmmichelson@fetch.comFetch Technologies841 Apollo St, Ste 400El Segundo, CA 90245 USACraig A. Knoblockknoblock@isi.eduUniversity Southern CaliforniaInformation Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292 USAAbstractVast amounts text Web unstructured ungrammatical, classified ads, auction listings, forum postings, etc. call text posts. Despiteinconsistent structure lack grammar, posts full useful information. paper presents work semi-automatically building tables relational information, calledreference sets, analyzing posts directly. Reference sets applied number tasks ontology maintenance information extraction. reference-setconstruction method starts small amount background knowledge, constructs tuples representing entities posts form reference set. also describeextension approach special case even small amount background knowledge impossible discover use. evaluate utility machineconstructed reference sets, compare manually constructed reference setscontext reference-set-based information extraction. results show reference setsconstructed method outperform manually constructed reference sets. also compare reference-set-based extraction approach using machine-constructed referenceset supervised extraction approaches using generic features. results demonstrateusing machine-constructed reference sets outperforms supervised methods, eventhough supervised methods require training data.1. Introductionvast amounts unstructured, ungrammatical data Web. Sourcesdata include classified ads, auction listings, bulletin board/forum postings. callunstructured, ungrammatical data posts. Figure 1 shows example posts, caseset classified ads cars Craigslist site. consider posts unstructuredone cannot assume ordering terms consistent postpost. instance, Figure 1 cannot assume car make (e.g., Audi) precedecar model (e.g., A4). Further, consider posts ungrammatical wouldyield useful grammatical parse (it would yield nouns almost exclusively).Although posts unstructured ungrammatical, full useful information.posts Figure 1 contain information cars different varieties carsc2010AI Access Foundation. rights reserved.fiMichelson & KnoblockFigure 1: Example posts carssale, price, etc. Therefore, analyzing posts corpus information yieldnumber insights.paper focus analyzing posts build reference sets, relationaltables entities attributes. instance, reference set cars would includeattributes car make (e.g., Mercury), car model (Sable), car trim (GS).Reference sets used background information number tasks, particular, recent interest using reference sets background knowledgeinformation extraction (Michelson & Knoblock, 2007, 2008; Mansuri & Sarawagi, 2006; Cohen & Sarawagi, 2004). completeness, describe previous work reference-set-basedinformation extraction detail Section 2.goal exploit dense information content posts construct reference setslittle human intervention possible. Posts numerous, freely available,generally large number useful attributes packed short strings. Further, postssometimes cover obscure entities one might find general Web text (anotherpossible corpus mining reference set). instance, many categoriesitems auction sites specific particular. items may mentionedfrequently Web text outside posts. Therefore, posts attractive data sourcebuilding reference sets.contrast approach manually constructing reference sets, poses numberchallenges. importantly, user must discover correct source(s)build reference set. reference sets built extracting informationsemi-structured websites using wrappers (Muslea, Minton, & Knoblock, 2001; Crescenzi,Mecca, & Merialdo, 2001), challenge parsing data, rather choosingcorrect sources. often cases difficult find sources enumeratereference set interest, therefore building reference set becomes challengingproblem finding multiple sources use, aggregating records, taking careduplicates. instance, demonstrate results, difficult find single sourcesenumerates specific attributes model numbers laptops.Dell Inspiron 1720, Inspiron E1405, 2650, name few. happens acrossIBM laptops, Dell laptops, HP laptops, etc. create reference set encompasseslaptop model numbers would require finding scraping multitude websites.Yet, useful attribute extraction since difference Inspiron 1720E1405 important end user. However, posts generally aggregationitems people interested in, using posts reference set one discoverexhaustive list.190fiConstructing Reference Sets Unstructured, Ungrammatical TextFurther, data reference sets constantly changing. example, considering laptop domain, new laptop model numbers released every months newhardware improvements made. Therefore, even comprehensive laptop reference setbuilt multiple sources, become stale months, reference set need updated time sources updated new laptops.creates additional challenge creating reference sets wrapped sourcessources must constantly monitored changes assure referenceset reflects changes.Lastly, stated above, much work motivated using reference setsbackground knowledge aid information extraction (Section 2). However, even userextract reference set Web sources using wrappers, guaranteereference set appropriate given data extraction. Concretely, assume goalextract car information Craigslist classifieds Figure 1, assumeuser built reference set American cars using Web sources. reference setuseful posts cars outside United States. call mismatchreference set posts coverage problem entitiesposts covered records reference set.coverage mismatches also happen data constantly changing,laptops described above. case, websites new laptops used createreference set, might mismatch used laptops generally soldclassified ads (in fact, demonstrate effect results). Therefore,number advantages building reference sets posts instead Web sources,although course could complementary processes.paper elaborates previous work building reference sets posts (Michelson & Knoblock, 2009). First, describe previous method detail. Second,previous method exploits small amount background knowledge build referenceset, paper also significantly extend algorithm handle special casebackground knowledge source known. demonstrate eventotally unknown source still construct reference set useful extraction.rest paper follows. Section 2 describes detail processusing reference sets information extraction. Section 3 describes methodconstructing reference sets posts themselves. Section 4 presents experimentsanalyzes results. Section 5 discusses related work, Section 6 presentsconclusions future work.2. Previous Work using Reference Sets Information Extractionmotivate work constructing reference sets putting context discovering reference sets use information extraction. particular, focustask extracting information posts using reference sets, shownpreviously aid task quite bit (Michelson & Knoblock, 2005, 2007). Informationextraction task parsing desired attributes text (posts case).Using example posts Figure 1, extraction, would like posts Figure 1separated make attribute, model attribute, trim attribute. Specifically, third post could annotated extractions MAKE={Honda} (which191fiMichelson & Knoblockimplied!), MODEL={Accord}, TRIM = {EX}. done, would allowstructured queries integration posts, using extracted attributes insteadfull text post.Given posts conform English grammar, Natural Language Processing approaches extraction would work posts (Ciravegna, 2001). Further, since postsunstructured, wrapper methods would work either (Muslea et al., 2001; Crescenziet al., 2001). Instead, recent work showed extraction posts benefits exploiting reference sets (Michelson & Knoblock, 2005, 2007).Previous work exploiting reference sets extraction uses two step process, shownFigure 2. first step, algorithm discovers best matches posttuples reference set. Then, second step, algorithm performsinformation extraction comparing tokens post attributes matchesreference set. example, token Accord would extracted modelsince would match model attribute matching tuple reference set.key idea without labeled data, system perform information extractionrelying solely information reference set, rather grammaticalstructural patterns. Recent work shows perform reference-set-based extractionautomatically (Michelson & Knoblock, 2007) using techniques machine learning(Michelson & Knoblock, 2008).Figure 2: Reference-set based extractionprevious work reference-set-based extraction assumes user manuallyconstructed reference set supply algorithm. strong assumptionmany potential difficulties stated above. Therefore, helps motivateapproach take paper, building reference sets posts, little (or no) humanintervention. method paper rely labeled data, mayrequire small amount background knowledge produce clean useful referencesets. machine-constructed reference sets applied pluggingreference-set-based extraction framework automatic extraction posts.192fiConstructing Reference Sets Unstructured, Ungrammatical TextWithin context information extraction, emphasize two mainbenefits using posts construct reference set. First, challengediscovering sources manually build reference set overcome sinceposts used. Second, since reference set constructedposts, overlapping coverage definition. show experiments,approach especially useful covering attributes particularly difficultcover manual reference sets, laptop model numbers, constantly changehard enumerate.note although motivate work building reference-sets contextinformation extraction, machine constructed reference sets useful manytasks require background knowledge. use structured entities filltaxonomies, help construct ontologies Semantic Web, simply see tuplesreference set might exist posts, help topic classification queryformulation. emphasize information extraction task described oneapplication reference sets, useful proxy comparing utilityvarious reference sets (as experiments). However, work describedpaper focuses specific task reference set construction, rather extractiondescribed elsewhere.3. Reference Set Constructionintuition constructing reference sets posts reference set tuples oftenform hierarchy-like structures, call entity trees. Consider simple referenceset three cars Figure 3. tuple reference set cars two attributes,make model. model specific version make (i.e., AccordHonda), Accord attribute value child node Honda value.said Civic value, generate entity tree rootedvalue Honda, two children: Civic Accord. argument applies turnFord tuple entity tree. However, entity trees rooted Honda Forddisjoint, since share ancestors. reference set really forestentity trees. So, algorithm constructs set entity trees, traversethem, outputting tuple path root leaf, union tuplescreates reference set. Therefore, construct reference set posts, goal reallybuild forest entity trees posts.general approach building reference sets posts decomposes two highlevel steps, shown Figure 4. first step breaks posts bigrams. example,post, Honda civic cool yields bigrams: {Honda, civic}, {civic, is}, etc.1 Creatingbigrams pre-processing step, since second step algorithm takes full setbigrams input generates reference set.second step algorithm three sub-components. First, algorithm generates initial set entity trees based upon bigrams (shown step 2.1). Next,1. Note algorithm considers ordered bigrams, rather combination token pairs.done efficiency, since measured average post length 8.6 tokens across thousandsposts, would generate 40,320 possible token pairs check, per post, pairsconsidered.193fiMichelson & KnoblockFigure 3: reference set entity treesiteratively adds new attributes entity trees general token attributes,define (step 2.2). Finally, algorithm traverses entity tree rootleaf, outputting path generate reference set (step 2.3). discuss methodscreating entity trees discovering general tokens detail following subsections.PostsStep 1--------------------------------------------------------------------------Construct Bi-GramsStep 2.1:Create Entity TreesStep 2Step 2.2:Discover general tokensStep 2.3:Form Reference SetFigure 4: Constructing reference sets posts194fiConstructing Reference Sets Unstructured, Ungrammatical Text3.1 Creating Entity Treesstated above, first step approach converts set input posts setbigrams. build entity trees bigrams use modified version SandersonCroft (1999) heuristic finding token subsumptions, notion token xsubsumes y, child node x entity tree contains x. definerule subsumption given terms x as:2x subsumes P (x|y) 0.75 P (y|x) P (x|y)example, consider four posts shown Table 1. consider tokenpair Honda Civic see conditional probability Honda given Civic(P (Honda|Civic)) 1.0, P (Civic|Honda) 0.5 (since Honda occurs four postsHonda occurs Civic two). Therefore, subsumption rule fires, Civicbecomes child node Honda. Similarly, Accord becomes child Honda, resultingentity tree Figure 3.Table 1: Four example postsHonda civic coolLook cheap Honda civicHonda accord rulesHonda accord 4 u!Since consider ordered bigrams, building entity trees based SandersonCroft heuristic requires assumption order entity tree reflectedposts. is, users tend order attributes general (e.g., car makes)specific (e.g., car models). Also, ordering needs hold least enoughposts make subsumption rule fire.Yet, approach builds entity trees, constructs useful reference setsused effectively extraction, shown experiments. Therefore, approachleverages little ordering find bigrams build reference set,use extract values posts ordering assumption hold.Further, given approach finds effective entity trees reflects notionusers tend order attributes general specific. case,discovered entity trees would little utility extraction later.Sanderson Croft heuristic defined single tokens x y, yetattribute values unigrams. Therefore, handle bigrams, add constraintx subsumes subsumes x, merge x single node (attribute value).instance, given attribute values Crown Victoria Crown subsumes VictoriaVictoria subsumes Crown merge single value Crown Victoria(which subsumed common parent Ford). note bigram actuallymerged using approach. extend n-grams, one simply checks token pairssubsumption.2. Note, require terms x co-occur least rule considered.195fiMichelson & Knoblockreference sets constructed algorithm experiments, 5.49%attribute values n-grams containing single token, large enoughpercentage validate including merge heuristic approach. Therefore, technique solely applicable case reference set values single tokens. However, cases merging heuristic perform well, discussdetail discussion Section 4.3.directionality imposed Sanderson Croft heuristic importantapproach. Specifically, Sanderson Croft heuristic uses conditional probabilitiesimposes directionality relationship tokens allowsform subsumption relationships. is, x subsumes y, x parent baseddirectionality imposed conditional probability. need directionalityentity trees must relative subsumption ordering align treesreference set. specifically, using example Figure 3, buildingreference set entity trees, know columns reference setaligned based positions entity tree. So, roots entity tree formleftmost column reference set table (Honda, Ford), children (Honda, Accord,Focus) form next right column, etc., leaves entity trees. So,tracing paths root leaf, sure tuples outputted disjointtrees still align correctly columns reference set orderingimposed directionality.contrast probabilistic measures term co-occurrences Pointwise Mutual Information (PMI).3 Specifically, PMI symmetric thereforeprovides strong measure term relationships, unclear order terms basedmeasure, therefore, even one use symmetric relationship findreference set tuples, unclear align disjoint tuples (e.g., Honda Ford tuples)based metric since impose relative ordering attributes.reason, require asymmetric measure.3.2 Discovering General Tokensconstructed initial entity trees, iterate posts discoverpossible terms occur across trees. Specifically, subsumption determinedconditional probabilities tokens, second token much frequentfirst token, conditional probability low yield subsumption.occurs attribute value appears across entity trees (reference set tuples).Since second term occurs frequently first across tuples, callgeneral token effect.example general token effect seen trim attribute cars.instance, consider posts Table 2 show general token effect trimvalue LE. posts show LE trim occurring Corolla model, Camrymodel, Grand model, Pathfinder. Since LE happens across many differentposts many varying bigrams, call general token, conditional probabilitynever high enough subsumption. Thus never inserted entity tree.3. terms x y, PMI defined P I(x, y) = log196p(x,y)p(x)p(y)fiConstructing Reference Sets Unstructured, Ungrammatical TextTable 2: Posts general trim token: LE2001 Nissan Pathfinder LE - $15000Toyota Camry LE 2003 - 20000 $1525098 Corolla LE 145K, Remote entry w/ alarm, $46001995 Pontiac Grand LE (Northern NJ) $700compensate general token peculiarity, iteratively run subsumptionprocess, iteration first, consider conditional probability usingset first tokens bigrams share common second token bigram.Note, however, set contains bigrams whose first token already node entitytree, otherwise algorithm may counting noise conditional probability.reason run first iteration. algorithm iterateslonger generates new attribute values.make clear, consider LE trim. possible cross-tree attribute would occur disjoint subtrees rooted CAMRY, COROLLA,PATHFINDER. iterating, algorithm considers following conditional probabilitysubsumption, assuming models Camry, Corolla Pathfinder alreadydiscovered:P ({CAM RY COROLLA P HF DER}|LE)Now, conditional probability fits heuristic subsumption, LE addedchild nodes CAMRY, COROLLA PATHFINDER respectiveentity trees. Iterating important step since method tests general tokensubsumption terms occurs bigram already entity trees.So, LE occurred tokens, none entity tree already,method ignores noise. approach must iterate since new general tokensconsidered occur attribute entity tree, approach may discovernew general token add entity tree, turn allows approachdiscover another new general token. experiments describe effects iteratingversus not. final step approach Figure 4 turns entity treesreference set tracing paths trees, outputting nodes columnsreference set tuples.However, blindly applying subsumption method lead noisy entity trees.common occurrence auction listings, instance, include term Free ShippingFree Handling. phrases occur frequently enough posts, subsumptionrule fire, creating entity tree rooted Free children Shipping Handling.Clearly noisy tree used would introduce noisy extractions. Therefore,following two subsections describe different approaches handling noise processconstructing entity trees.3.3 Seed-Based Reference Set Constructionfirst approach dealing noise exploits small amount background knowledge,called seeds, focus construction entity trees. Specifically, use methodFigure 4 build entity trees, added constraint entity tree must197fiMichelson & Knoblockrooted given seed value. gave Honda seed, one entity treerooted Honda would constructed. Even entity trees discovered,discarded. easy discover exhaustive list seeds Web includingmany seeds issue algorithm simply removes entity tree consistssolely root constructed reference set (i.e., singleton set).One key intuitions behind approach set root nodes entitytrees generally much easier discover online nodes farther trees.instance, consider laptops, manufacturers laptops (the roots) fairly easydiscover enumerate. However, one traverses farther entity trees, saymodel numbers, becomes hard find information. Yet, small set seedsenough improve process reference set construction substantially, showresults compare reference sets constructed without seed-basedconstraint. Also, importantly, attributes farther tree change time(new model numbers released often), seeds infrequently change (therenew computer manufacturers). So, using reference set information extraction,coverage becomes less issue considering roots versus attributesreference set tuple.manner construct reference set directly posts, using seedsconstrain noise generated final reference set. Table 3 describes fullalgorithm constructing entity trees using seeds, turned referenceset outputting tuple path root leaf tree.3.4 Locking-Based Reference Set Constructionseed-based method handles noise exploiting small amount background knowledge. describe second approach dealing noise caseseeds impossible discover costly find use.approach revolves around locking mechanism. seeds seed-basedmethod constrain possible entity trees limiting attributes become rootsentity trees. This, turn, leads cleaner useful reference sets. Therefore,lacking seeds, goal introduce constraining mechanism preventsnoise introduced entity trees. approach lock levelsentity trees certain points, locking new attribute valuesintroduced level entity trees.Since many attributes discover specifications general attributes(such car models specify makes), point although may discovering new values specific attributes (car models), saturateddiscover parent attribute (car makes). Further, saturate parentattributes, algorithm introduce new values representing new parents,likely noise. So, algorithm lock parent attribute saturation point,allow discovery new attributes level locked attributehierarchies.Consider example shown Figure 5. iteration algorithm discoveredtwo entity trees, one rooted car make Ford one rooted car makeHonda. makes also models associated (their children).198fiConstructing Reference Sets Unstructured, Ungrammatical TextTable 3: Entity tree construction using seedsMineReferenceSet(Posts P , Seeds S)/* First, break posts bigrams */Bigrams B MakeBigrams(P )/* Build entity trees rooted seeds */AddedNodes N {}{x, y} B/* {x, y} bigram */x/* check x seed */x subsumeschild x entity treeN N/*Find childrens children, children, etc.*/N null{s, t} BNN N -ssubsumeschild treeN N/* Iterate discover general token nodes *//* Start unique nodes already entity trees */AllEntityNodes UniqueList(All Entity Trees)/* Keep iterating find new terms */FoundNewTerms trueFoundNewTerms trueFoundNewTerms false/* Consider terms {p0 , . . ., pn } entity treesform bigrams non-entity tree term q */( {p0 , . . ., pn }, q) s.t. {p0 , . . ., pn } AllEntityNodes{p0 , . . ., pn } subsumes q/* consider P ( pi |q) */q becomes child pi treesAllEntityNodes AllEntityNodes qFoundNewTerms truebottom figure shows future time (iteration t+y), point systemdecides lock make attribute, model trim. Therefore, algorithmstill add car models (as Taurus model Ford make) car trims(as LX trim Civic model). However, since make attribute locked,make attributes allowed, therefore hierarchy would rootedmake Brand model New (which noise) allowed.shown right crossed out.manner, locking acts like pre-pruner attribute values similar spiritseeds. intent algorithm lock attributes right timeminimize number noisy attributes may introduced later iterations.works noise often introduced algorithm iterates,199fiMichelson & KnoblockFigure 5: Locking car attributesbeginning. example, instead post-pruning away hierarchy rooted Brand,algorithm instead prevented added locking make attribute.assumption deeper levels tree, posts need examinedattributes represented levels trees rarer. However, higherlevel tree, common attribute value therefore fewer postsneed examined. assumption exploit justify locking topmanner. is, lock roots entity trees childrenassume need see fewer posts discover roots children.assumption carries tree, lock leaves last need seeposts generate leaves. So, locking approach terminates attributes(i.e., levels entity trees) become locked, since point processingposts that.Based assumption, model locking mechanism requesting service.assumption need look fewer posts higher trees,help eliminate noise (justified experiments comparing lockinglocking). rather process posts once, instead algorithmrequest batches posts process them, building entity trees using approachFigure 4. receiving next batch posts, algorithm builds new setentity trees, compares previously discovered ones, algorithm decideswhether lock level. lock, requests posts examine. keepsrequesting posts examine levels entity trees locked. note, however,batch comes processing, combined previously seenposts. way, gradual build number posts system examinesgiven level, sense algorithm iterates examines previousposts time receives new batch.Therefore, leverage notion locking process requires continuous requests posts user locks attributes. Essentially, request,machine compares discover using given posts discover200fiConstructing Reference Sets Unstructured, Ungrammatical Textusing previous set given posts (note newly requested set supersedesprevious set). example, algorithm may start examining 100 posts buildreference set. Then, levels entity trees locked, algorithm requests100 posts analyzes 200 posts build reference set. algorithmcompares discover using first 100 posts discover usingcombined 200 posts. algorithm thinks cannot discover useful attributes200 posts 100 posts, locks certain attributes (Again, note 100posts subset 200 posts).comparison locking, algorithm compares entropies generatinggiven attribute (e.g., member given level entity tree), based upon likelihoodtoken labeled given attribute. So, cars domain would calculateentropy token labeled make, model, trim (note label namesgiven post-hoc, machine simply regards attribute1 , attribute2 , etc.).clarity, define pmake (x) probability arbitrary token x labeledmake attribute (e.g., falling level entity tree associated make),define entropy, H(make) as:4XH(make) =pmake (x) log(pmake (x))xtokensSo, given attribute A, use pA (x) define H(A) as:H(A) =XpA (x) log(pA (x))xtokensentropy labeling particular attribute interpreted uncertaintylabeling tokens given attribute. So, see posts,entropy change seeing 100 posts seeing 200 posts, uncertaintylabeling attribute steady need keep mining attributeposts. However, cannot directly compare entropies across runs, sinceunderlying amounts data different. So, use normalized entropy instead. is,attribute (e.g., make), given N posts, define normalized entropy H(A)N :H(A)N =H(A)logNAlthough entropy provides measure uncertainly token labels,provide sufficient comparison runs varying numbers posts. provideexplicit comparison, analyze percent difference normalized entropiesacross runs. instance, using attribute A, would compare entropies runsacross 100 posts 200 posts (defined H(A)100 H(A)200 respectively), computingpercent difference them:P D(H(A)100 , H(A)200 ) =12|H(A)100 H(A)200 |(H(A)100 + H(A)200 )value minimum (ideally 0), know lock attribute 100 posts,since using 200 posts yield information entropies essentially4. assumes built reference set compute probabilities pmake (x).201fiMichelson & Knoblock(i.e., uncertainty steady). So, algorithm locks attributefinds minimum percent difference entropies across runs attribute.minimum found using greedy search previously calculated PD values. Table 4summarizes technique locking attributes mining reference set.Table 4: Locking attributesLockingAttributes(Attributes A, Posts Pi , Posts Pj ,ReferenceSet RSi , ReferenceSet RSj , LockedAttributes L)/* Pi first set posts *//* Pj next set j posts, Pi Pj *//* RSi RSj reference sets Pi Pjrespectively used posts compute likelihoods pA (x) *//* L set previously locked attributes */attributelocked/* Compute entropies H(a)i H(a)j defined */H(a)i Compute entropy given Pi RSiH(a)j Compute entropy given Pj RSjPD(H(a)i , H(a)j ) minimum previous valuesParent(a) L /* Parent locked */Lock(a)LLareturn Ltwo small items note. First, add heuristic attribute maylock parent attribute already locked, prevent children locking parents.Second, although discussion repeatedly mentions machine requestingposts user, note algorithm automatically request postssources using technology RSS feeds, alleviating human involvement beyondsupplying URL source.Therefore, using technique lock attributes go, evengenerating new children attribute values, parents locked, actsautomatic pruning method. Further, know stop asking posts,stopping criteria number posts need run mining algorithm.stopping criteria important since assumption algorithm exhaustedpossible reference set membership locks levels. Note, assumption couldviolated algorithm supplied enough posts (since would never locklevels).Table 5 ties aspects together describing Iterative Locking Algorithm(ILA) mining reference set tuples posts without seeds. Essentially, approachseed-based method: batch posts, algorithm constructsentity trees scanning data iterating general tokens. key differenceILA constrain roots entity trees seeds, instead useslocking block attributes added trees. Further, locking approachprocesses batches posts time, flow different requests batchposts, builds/refines entity trees, tests trees locking conditions,proceeds next batch posts.202fiConstructing Reference Sets Unstructured, Ungrammatical TextTable 5: ILA method mining reference setsMineReferenceSet(Posts, x, y)# x number posts start# number posts add iterationPosts Px GetPosts(x)ReferenceSet RSx BuildReferenceSet(Px )/* Algorithm Table 3, exceptignore constraint tree roots seeds */finished falseLockedAttributes L {}while(finished false)x x+yPosts Py GetPosts(x)ReferenceSet RSy BuildReferenceSet(Py , L)/* Table 3, exceptadd nodes unlocked levels trees */Attributes GetAttributes(RSx )/* GetAttributes returns columns found reference set */L L LockingAttributes(A, Px , Py , RSx , RSy , L)|L| equals |A| /* size, attributes locked */finished truePx PyRSx RSy4. Experimentsgoal research construct reference sets tasks informationextraction posts. However, directly comparing reference sets constructed variousways number problems. First, unclear directly compare reference setsquantitatively. problem noted elsewhere well context comparinghierarchies (e.g., Bast, Dupret, Majumdar, & Piwowarski, 2006). instance,clear measures define similarities comparing hierarchies. Second, withoutcontext, hard judge reference sets. is, one reference set may hugecomprehensive, high utility task ontology construction, mightlittle use extraction due coverage mismatches. Another reference set may quitenoisy (therefore bad ontology construction), actually preferred extractionsince coverage better.Therefore, instead measuring goodness reference sets directly, instead putcontext information extraction task using reference-set-basedextraction posts. compare extraction results use resultsproxy utility reference set. assumption extraction resultsreflect reference sets utility since noisy reference set lead poor extraction,would reference set poor coverage posts.following subsections test two different approaches constructing reference sets: seed-based approach locking based approach (ILA).4.1 Experiments: Seed-based Approachfirst experiment, test effectiveness using seed-based approachbuilding reference sets. experiment, compare seed-based approachfull, manually constructed reference sets extracted online sources (which call203fiMichelson & Knoblockmanual approach) version seed-based approach constrainentity trees rooted seed values (called seeds). comparing seedbased method manually constructed reference set, test coverage issuesstem collecting reference sets online (versus posts themselves). Further,comparison allows us analyze trade-off high cost building manualreference set (versus low cost finding seeds) gains accuracy usingmanual reference set. Using seeds tests effectiveness constraining entitytree roots seeds. is, expect seeds method generates muchnoisier reference set (leading poor extraction) seed-based method requiresconstraint.Therefore, first experiment, use manual seed approachesbaselines compare seed-based reference set. procedure,experimental data sets, build three different reference sets (one manual, one basedseeds, one without seeds) pass reference sets systemexploit perform automatic extraction (Michelson & Knoblock, 2007).compare extraction results using standard metrics recall, precision, F1 measure. Since difference extraction algorithm reference set provided,extraction results serve proxy quality reference set termswell overlaps posts (the coverage) clean (since noise leadspoor extractions), want test.goal extraction task extract values given attributes. instance, using Figure 1, extract model={Accord} trim={EX}. However,approach constructing reference sets supply attribute names.method discovers attribute values Honda Accord, internally labelsassociated attribute names attribute0 attribute1 , instead Make Model.Therefore, clarify results manually label attribute names given manually constructed reference sets. feel much hindrance method.user find set seeds, user also able find appropriate attributesnames. fact, significantly challenging discover attribute valuesfinding names.4.1.1 Data Seed-based Experimentsused three real-world data sets experimental data. first set contains classified ads used cars sale classified site Craigslist.org. these, labeled 1,000 posts test extraction make (e.g., Honda), model (e.g., Civic),trim (e.g., DX) attributes. second set consists classified ads used laptopsCraigslist.org well. labeled 1,000 posts extracting manufacturer(e.g., IBM), model (e.g., Thinkpad), model number (e.g., T41). last data set contains posts skis sale eBay. labeled 1,000 posts extractionbrand (e.g., Rossignol), model (e.g., Bandit), model specification (e.g., B3,called spec). data summarized Table 6.need full, manually constructed reference sets comparison. Cars domain,collected 27,000 car tuples pulling data Edmunds.com car buying sitecars combining data classic car site, SuperLambAuto.com.204fiConstructing Reference Sets Unstructured, Ungrammatical TextTable 6: Three experimental data setsNameCarsLaptopsSkisSourceCraigslistCraigslisteBayAttributesmake, model, trimmanufacturer, model, model num.brand, model, model spec.Num. Posts2,5682,9214,981Laptops domain, scraped 279 laptops online retailer Overstock.com. Lastly,Skis domain, built 213 ski tuples skis.com website cleanedremove certain stop words.5seeds seed-based method also came freely available sources.car domain, seeds consist 102 car makes, Edmunds. laptop seeds40 manufacturers, culled Wikipedia, ski seeds 18 ski brands pulledSkis.com.4.1.2 Results Seed-based ExperimentsTable 7 shows field-level extraction results attribute domain, comparingthree methods.6 Again, manual method uses full reference set constructedonline sources (shown parentheses table), seed method methodwithout seed-based constraint, full technique called seed-based.Table 8 summarizes results, showing number attributes seed-basedmethod outperformed techniques terms F1 -measure. also shows numberattributes seed-based technique within 5% methods F1 -measure(including attributes seed-based method outperforms method).F1 -measure within 5% competitive result.results show seed-based method builds cleaner reference setfully automatic approach ignores seeds since seed-based approach outperformsseed approach every single attribute. seed-based method builds cleaner,effective reference set, leads effective extraction.results also support notion using posts generate reference set yields reference sets better coverage constructed manuallysingle source. seed-based method outperform manual reference setsmajority attributes (5/9), seed-based methods reference set better representsspecific attributes (ski model, ski model spec., laptop model, laptop modelnum.), attributes likely cause coverage problems. attributes, 53.15% unique attribute values seed-based reference set existmanually constructed reference set. Therefore, coverage quite different, givenseed-based approach performs better attributes, coverage better.example, important note Overstock sells new computers,laptops sale Craigslist generally used, older laptops. So, match5. posts reference sets experiments available www.mmichelson.com.6. Field-level results strict extraction correct tokens labeledare, extra tokens labeled.205fiMichelson & KnoblockTable 7: Extraction results comparing seed-based methodMakeManual (Edmunds)seedSeed-basedModelManual (Edmunds)seedSeed-basedTrimManual (Edmunds)seedSeed-basedCarsRecall92.5179.3189.15Recall79.5064.7773.50Recall38.0123.4531.08Prec.99.5284.3099.50Prec.91.8684.6293.08Prec.63.6954.1050.59F1 -Meas.95.6881.7394.04F1 -Meas.85.2373.3882.14F1 -Meas.47.6132.7138.50BrandManual (Skis.com)seedSeed-basedModelManual (Skis.com)seedSeed-basedModel Spec.Manual (Skis.com)seedSeed-basedSkisRecall83.6260.5980.30Recall28.1251.8662.07Recall18.2842.3750.97Prec.87.0555.0396.02Prec.67.9551.2578.79Prec.59.4463.5564.93F1 -Meas.85.3057.6887.46F1 -Meas.39.7751.5569.44F1 -Meas.27.9650.8457.11LaptopsManufacturerRecallManual (Overstock) 84.41seed51.27Seed-based73.01ModelRecallManual (Overstock) 43.19seed54.47Seed-based70.42Model Num.RecallManual (Overstock) 6.05seed25.58Seed-based34.42Prec.95.5946.2295.12Prec.80.8849.5277.34Prec.78.7977.4686.05F1 -Meas.89.6548.6182.61F1 -Meas.56.3151.8773.72F1 -Meas.11.2338.4649.17Table 8: Summary results seed-based method versus othersOutperformsWithin 5%Seed vs. seed9/99/9Seed vs. Manual5/97/9manufacturers (since laptop manufacturers dont change quickly), evenused laptops six months older new ones sale mismatchmodels many model numbers. coverage mismatch usingmanual reference sets clear laptop model numbers ski modelspecifications. attributes change quite frequently time newmodels come out. contrast ski brands laptop manufacturers (our seeds)change much less frequently enumerated less concern towardcoverage. note chose Wikipedia comprehensive list laptopmanufacturers, Wikipedia enumerates far fewer models model numbersOverstock reference set would worse choice manual reference set.206fiConstructing Reference Sets Unstructured, Ungrammatical TextAlso, note seed-based technique competitive 7/9 attributescompared full, manually constructed reference sets. Yet, number seedsdrastically smaller number tuples manually constructed reference sets.So, even though starting much tinier set knowledge, still retain muchbenefit knowledge leveraging it, rather explicitly enumeratetuple attributes ourselves. important much easier findseeds. Therefore, cost (in manual terms) much lower seed-based approach,give accuracy performance compared manual approach buildingreference sets.one attribute manual reference set drastically outperforms seed-basedmethod trim attribute cars, difference roughly 9% F1 -measure.mostly due fact use field level results, seed-basedtechnique constructs trim attribute sometimes leaves certain attribute tokens.instance, consider example extracted trim 4 Dr DX. Here,seed-based technique includes DX reference set tuples attribute. Meanwhile,manually constructed reference set contains possible tokens since scrapedcomprehensive source (its attribute value 4 Dr DX 4WD). So, although seed-basedtechnique finds DX token labels correctly trim, misses 4 Dr partextraction, whole extraction counted incorrect using field level results.Overall, machine-constructed reference sets yield better extraction results attributes occur higher entity trees. extraction results bestattributes roots entity trees, attributes children roots,leaves entity trees. largely discovery issue. set possibleattribute values generally grows one traverses tree (e.g., valueslaptop models manufacturers, model numbers models, etc.). Therefore,algorithm needs see posts overcome lack evidence discoverattributes farther entity trees. So, seeing many posts generateenough evidence compensate issue.One limitation seed-based technique versus manual construction referencesets inclusion certain attributes. Surprisingly, enoughrepetition posts discovering years cars attributes. duevarious factors including variety year representations (all four digits, two digits,strange spellings, etc.) placement posts years (since considerbigrams subsumptions). However, full manual reference set contain yearsextract attribute, seed-based method cannot. Therefore, sinceseed-based method unable learn fit year attributes entitytree, fails extract it, remove attribute extraction results (asresults essentially 0). Nonetheless, although manual reference set may includeattribute cannot discovered automatically, reference set might terriblecoverage posts, limiting utility. So, feel important deal coverage,seed-based method does.207fiMichelson & Knoblock4.1.3 Results Iterating General Tokensalso tested effect iterating capture general tokens versus simply stoppingfirst pass posts. use extraction results proxy comparingreference sets. case, assumption iterative method capturegeneral tokens therefore construct fuller reference set yields better extractionresults algorithm stops first pass posts. Table 9 showscomparable F1 -measure results extraction comparing Single Pass Iterativeapproach.Table 9: Comparing iterating iterating (seed-based method)CarsMakeModelTrimSingle Pass (F1 )93.2978.4216.44Iterative (F1 )94.0482.1438.50Single Pass (F1 )81.7773.5249.50Iterative (F1 )82.6173.7249.17Single Pass (F1 )87.3067.0342.75Iterative (F1 )87.4669.4457.11LaptopsManufacturerModelModel Num.SkisBrandModelModel Spec.expected, iterative technique yields better results. iterative method outperforms single-pass approach every attribute except one (Laptop Model Numbers,F1 -measure decreases -0.33%). Interestingly, iterating, algorithmimproves attributes deeper levels entity trees. is, comparingextraction results roots entity trees, almost difference. However, second level entity trees slight improvement (around +3.5%F1 -measure Car Models +2.5% Ski Models), comparing leavesentity trees improvement (+22% increase Car Trims, +15% increase Ski Model Specifications). So, seems iterating fact capturegeneral tokens used successful extractions, seems generaltokens seem occur farther trees. note algorithm iteratestimes domain, since almost always helps extraction (sometimes quitedramatically), useful component seed-based approach constructing referencesets.208fiConstructing Reference Sets Unstructured, Ungrammatical Text4.1.4 Entity Tree AnalysisAlthough extraction experiments serve best metric actual utility seedbased reference sets, also ran experiments generated entity trees themselves.examined whether attribute values consistent placement entity trees (thecolumn homogeny). instance, given known car models Civic measuremodel values mostly placed car model attributes (second level tree)misplaced car trims (third level). However, measuring directly without domainexpertise difficult. Instead, compare attribute values seed-based referenceset manually constructed reference sets, values match,measure attribute (i.e., columns match) not. yieldsmeasure column homogeny seed-based reference set, based manualreference set, assumed clean. However, approximate measurevalues seed-based reference set match manual reference set, sincediffer coverage (see previous results).Nonetheless, results approximate measurement indicate good level homogeny amongst seed-based attributes. skis, 1.7% found attribute valueswrong column, cars 2.9% values wrong columns.skis cars common error placing specific attribute (model spec cartrim) one spot higher entity tree been. However, approximation misleading laptops. laptops domain, found perfect column homogenyusing measure, measure column homogenyattributes match seed-based manual reference sets. Yet,obvious column homogeny errors, cpu speeds placed model numbers. Sincematch manual reference set, ignored homogenymeasuring experiment. Given enough domain expertise, manualcalculation set determined 8.09% tuples seed-based setcpu speed variant model number incorrect. However, even 8%good result homogeny.4.1.5 Comparison Supervised MethodsAlthough experiments meant test utility reference set (not extraction algorithm itself), one aspect analyze reducing burden userseed-based approach. is, comparing seed-based reference set (which usesautomatic extractor) supervised machine learning approach extraction,examine amount labeled data needed supervised system garner similarresults. yields insight gain terms labor cost generating setseeds much less costly labeling data train classifier, would likeexamine much labeled data needed get comparable extraction results.analyze user effort, compare seed-based results common machine learning approach extraction: Conditional Random Fields (CRF) (Lafferty, McCallum, & Pereira, 2001). used MALLET (McCallum, 2002) implement twodifferent CRF extractors. One, called CRF-Orth, uses orthographic features tokens extraction, capitalization, number containment, etc. second extractor,CRF-Win, uses orthographic features also considers two-word sliding win209fiMichelson & Knoblockdow around token feature. extractors built reflect common featurestechniques CRF-based extraction. Then, perform 10-fold cross validationextractor (varying amount data training) noting fold independent,compare average field-level extraction results using supervised approachesautomatic approach using seed-based reference set.first experiment compares seed-based method CRF using 10%data training. experiment compares seed-based method supervisedmethod using small enough amount labeled data reflect real-world cost constraints.seed-based method outperforms CRFs majority attributes,effective method extraction also cost effective since outperforms supervisedmethods supplied realistic amount training data. Table 10 showssummary extraction results experiment, similar format Table 8show number times seed-based method outperforms competitiveanother method.Table 10: Summary results comparing seed-based method CRFs (10% training data)OutperformsWithin 5%Seed vs. CRF-Win7/99/9Seed vs. CRF-Orth6/97/9Table 10 shows seed-based method outperforms two CRF extractorsmajority attributes, even though cost creating seed list significantlyless cost labeling data creating features training specific CRFs.Further, table shows technique relies heavily structure, CRF-Win,performs worse extraction posts compared methods.One aspect analyze based results amount training data neededsupervised methods outperform seed-based methods. analysis,trained CRFs 10%, 30%, 50% data, note amounttraining data CRFs outperform seed-based method. certain cases, even50% data used training, CRF outperform seed-based method (wedenote amount >50% table). Table 11 shows amount data neededCRF oupteform seed-based method, broken specific attributedomain.results see quite cases either 50% data (oreven more) needed supervised approaches outperform seed-based method(3/9 CRF-Orth 5/9, majority, CRF-Win). Therefore, large gainterms cost using seeds, much labeled data would neededsupervised systems. fact, attributes extractors never outperformedseed-based approach, even given 50% data training. Further, noteonce, CRF-Orth Skis domain, less 50% data requiredoutperform seed-based method attributes. case, using 30%data training sufficient outperform seed-based method attribute,labeling 30% data domain far costlier generating list 18 ski210fiConstructing Reference Sets Unstructured, Ungrammatical TextTable 11: Amount training data outperform seed-based approachCarsMakeModelTrimCRF-Orth>50%50%10%CRF-Win>50%>50%30%CRF-Orth50%30%10%CRF-Win>50%>50%10%CRF-Orth30%30%10%CRF-Win50%30%30%LaptopsManufacturerModelModel Num.SkisBrandModelModel Spec.brands used seeds. Lastly, domain would 10% data allow CRFsoutperform seed-based method attributes. Therefore, seed-based methodprovides much less costly approach extraction task based amount trainingdata needed.one case CRF methods perform well relatively small amounttraining data, laptop model number. attribute fits well orthographicfeatures (since usually capital letters numbers it), extractorgeneralize well 10% training data extracting it. argues certainattributes may benefit extracted using generalized features (suchCRF-Orth) versus reference-set membership (as method does). Therefore, planinvestigate hybrid methods combine best CRF-based extractorsreference-set based extractors.set experiments demonstrate utility seed-based approach. Comparing seed-based method baseline manually constructed reference set,showed seed-based method outperforms manual reference set majorityattributes (especially coverage difficult), requiring less user effortconstruct. Therefore, reference set constructed using seeds better coveragemanually constructed reference sets used effectively, even thoughcheaper construct. Further, showed constraint seed-based methoduses (constraining roots seeds) indeed strong impact results,versus using constraint. Lastly, compared using seed-based approachsupervised machine learning approach judge comparable amount training dataneeded outperform seed-based method, show indeed, takes quite bittraining data compared small number seeds.211fiMichelson & Knoblock4.2 Experiments: Locking Approachnext set experiments analyze locking-based approach building reference sets.stated above, locking based technique appropriate special case seedscostly impossible find. Therefore, locking based approach alternativeseed method described previous experiments. experimental procedureexperiments exactly above. use data sets comparereference sets constructed different ways (seed-based, seed, locked)passing extraction mechanism comparing extraction resultsproxy reference sets utility.locking algorithm, must specify number posts add lockingiteration. set value 200, large enough limit total possible numberiterations (versus say, 20), also small enough allow algorithm convergeseeing posts (versus, say 1,000, may coarse). Table 12 showstotal number posts (and iterations) required locking algorithm locklevels entity trees, therefore converge, returning constructed reference set.note domains, total number posts required locking algorithmconverge less total number posts domain. Table 12 also showstotal number posts domain.Table 12: Locking convergence resultsDomainCarsLaptopsSkisTotal Posts RequiredLocking2,0002,4004,400Total Possible PostsIterations2,5682,9214,981101222Table 13 shows comparative field-level extraction results different domains,using reference sets generated different methods (seed-based, seed,locked).Based upon results Table 13, see locking good alternative simplylocking (no seeds). cars skis domains, one differenceF1 -measure statistically significant using two-tailed test 95% confidence (theCar Trim attribute). However, laptops domain, locking method outperformsseed attributes, largely due increase precision, direct resultlocking noise entity trees. Therefore, good strategy attemptlocking approach (versus seed approach) since based upon results,worst case, minimal negative effect generated reference set (evidencedCar Trim attribute), yield significantly cleaner reference set bestcase (as shown laptop results). Further, locking algorithm converged (i.e.,able lock levels saw posts) domains, able producereference sets without burden requiring additional posts.212fiConstructing Reference Sets Unstructured, Ungrammatical TextTable 13: Extraction results comparing locking methodMakeLockedseedSeed-basedModelLockedseedSeed-basedTrimLockedseedSeed-basedCarsRecall79.6479.3189.15Recall65.3064.7773.50Recall19.5423.4531.08Prec.84.4684.3099.50Prec.83.2484.6293.08Prec.52.1354.1050.59F1 -Meas.81.8481.7394.04F1 -Meas.72.2273.3882.14F1 -Meas.28.2832.7138.50BrandLockedseedSeed-basedModelLockedseedSeed-basedModel Spec.LockedseedSeed-basedSkisRecall60.8460.5980.30Recall51.3351.8662.07Recall39.1442.3750.97Prec.55.2655.0396.02Prec.48.9351.2578.79Prec.56.3563.5564.93F1 -Meas.57.9157.6887.46F1 -Meas.50.1051.5569.44F1 -Meas.46.2950.8457.11ManufacturerLockedseedSeed-basedModelLockedseedSeed-basedModel Num.LockedseedSeed-basedLaptopsRecall Prec.60.42 74.3551.27 46.2273.01 95.12Recall Prec.61.91 76.1854.47 49.5270.42 77.34Recall Prec.27.91 81.0825.58 77.4634.42 86.05F1 -Meas.66.6748.6182.61F1 -Meas.68.3151.8773.72F1 -Meas.41.5238.4649.174.3 Experiments: Assumptions Constructing Reference Setssection examine assumptions made dataable construct reference sets using seed-based method (or locking method,necessary). First, mentioned previously need assumeconstructed reference set filled single token attributes, roughly 6%attributes constructed reference sets n-grams using seed-based method.note, however, researchers also discussed difficulty discovering n-gramsconcept hierarchies text. example, previous work discards conceptstopic hierarchy consist multiple terms (Bast et al., 2006).Despite fact merging heuristic yield n-gram values attributes,cases heuristic breaks down. Specifically, perform well domainsattribute values multiple tokens, tokens occurvarious frequencies. example, consider users selling items sports teams,San Diego Chargers helmet, San Francisco 49rs t-shirt. case,Diego Francisco tokens subsumed San creating unnecessaryentity tree, rather joining terms together. main failuremerging approach: algorithm force subsumption relationship213fiMichelson & Knoblockmerging rule fails fire. However, note merging heuristic never causessubsumption rule fire, rather fails therefore creates errant entitytrees. Therefore, since never destroys information entity tree (e.g., never causessubsumption fail) consider two approaches improving merge heuristic. First,could make approach aggressive merging. Second, could perform posthoc analysis constructed entity trees fix errors. instance, one could useoutside information, ontology corpus statistics, determine likelihoodFranscisco child San versus merged single term thereforecleaning hierarchy account failed merging. Improving merging methodfuture research challenge.might seem necessary attributes always appear adjacentone another posts (e.g., make model trim tokens them),case. fact, average, across three domains measured 0.115 tokensattribute posts. significantly larger 0, impliesindeed tokens attributes number posts. Further,might seem must always see correct order posts (e.g., never see Cartrim attribute Car make attribute) order successfully construct referencesets. However, again, due unstructured nature posts, seecase. fact, see perfect ordering less half posts threedomains (45.2%), perfect ordering full ordering defined entity tree (e.g.,Car post make attribute model attribute trim attribute, order).fact, cars 0.61% posts Car trim attribute comingattributes, strange random ordering. Therefore, need assumeordering always correct extraneous tokensattributes. need assume attribute single token.enough cases ordering reflect entity tree, wordsseen together, subsumption heuristic fire produce correct entitytree.Yet, certain number assumptions make order construct reference set. First, must assume reasonable hierarchical structureentity trees (e.g., Car makes general Car models). Although constraintholds enormous set categories (e.g., items sale, descriptive categoriesgeographical person data, etc.) categories lack characteristic (e.g., personal ads). see case analyze informationhotels, using Bidding Travel extraction data set previous work (Michelson& Knoblock, 2008). data set, goal extract hotel information, hotelnames local areas posts internet forum users talk dealsreceived hotel accommodations. give seed-based method sethotel names seeds (from data set) try build reference set roughly2,500 posts BiddingForTravel.com, expect construct entity trees localareas children hotel names. However, resulting reference set constructedwell. fact, algorithm finds 20 hotel tuples 132 possible. mostlydue fact even users themselves, created posts, cannot decideconsistent hierarchical structure data. Analyzing posts, users put hotelname immediately local area 40.58% time local area immediately214fiConstructing Reference Sets Unstructured, Ungrammatical Texthotel name 27.17% time. Therefore, even usersleast two intepretations representing data entity trees, ambiguouswhether expect hotel names roots areas roots. noteoften case hotel users flip mentions attributes. So,assumption make posts structured,structure entity trees consistent (and agreed upon) algorithmreconstruct entity trees based users posts. is, case, entitytrees rooted either hotel names, local areas, mixture seereflected users posts. Further, data particularly difficult constructingreference sets terms attributes freely intermixed. is, tokenshotel name local area sometimes interspersed, makes difficultmachine determine terms go together attribute. largely duelimiting bi-grams order (which efficiency), perhapsextend algorithm consider possible combinations bigrams (perhapsextending method distributed approach) could handle issue.5. Related Workfocus research creating reference sets posts. reference setsflattened entity trees, work closely resembles research creatingterm hierarchies (subsumptions) text. alternative methods buildingterm hierarchies. However, methods well suited Sanderson Croftmethod (1999) chose problem. First, since data ungrammatical,cannot use subsumption methods rely Formal Concept Analysis, relateverbs nouns text discover subsumptions (Cimiano, Hotho, & Staab, 2005).plenty nouns posts, almost verbs. Further, since algorithm runsiteratively due general token problem, need method runs efficiently.algorithm using Sanderson Croft method runs O(kn) time nnumber tokens posts, k number iterations general tokens, sinceprocess scans posts create bigrams calculate probabilitiesconsiders high enough probabilities. contrast methodsterm subsumption use Principle Component Analysis (PCA) (Dupret & Piwowarski,2006; Bast et al., 2006) run O(n3 ) time respect token-by-token matrix(which may sparse). Therefore, PCA methods suitable large numbertokens one iteration. also previous work uses outsideinformation sources, links image tags users supplyFlickr, aid building term hierarchies (Schmitz, 2006). explicitlinks terms users. Lastly, previous work uses Google determineterm dependencies (Makrehchi & Kamel, 2007). However, cannot assume termsencounter posts occur across many webpages. fact, method work evenposts place mentions entities entire Web (providedenough posts). However, case, might occur postsobscure items, could leverage Google-based method. Further, althoughalternative approaches building term hierarchies, also one larger,fundamental difference problem previous work ontology creation.215fiMichelson & Knoblockprevious methods build single, monolithic conceptual hierarchy. case,instead aim build number disjoint entity trees, flattenreference set.Along lines discovering term hierarchies text, also work aimsextract features text product reviews. Since entity trees methodconstructs often include product features (e.g., Laptop models), work constructs similaroutput methods. Approaches feature extraction include association rule miningfinding frequent product features (Hu & Liu, 2004) leveraging Web aidfeature extraction (Popescu & Etzioni, 2005). However, methods rely naturallanguage processing, part-of-speech (POS) tagging parse reviews possiblefeatures. However, posts grammatical enough support part-of-speech tagging,cannot use features data.Recently, even large commercial search engines begun constructreference sets Web data. Google built Google Squared,7 allows userstype query category returns square reference set relatedcategory. product provides intuitive interface including/excluding attributes(columns) naming appropriately. However, tested applicationexperimental domains (providing queries cars, laptops, skis) foundcolumns square broken constituent attributes finelyreference sets. instance, laptops skis, single attribute (calleditem name) essentially functions post describing entity. laptops,item name combines manufacturer, model, model number single attribute,skis combines brand, model, model spec. cars, square sometimescombined make model car item name. Yet, encouraginglarge company finds reference sets important useful enough devoteapplication them, therefore feel methods could greatlycomplement technology providing means build even finer grained reference setsinclude squares.stated, goal work build reference sets, used numbertasks, including ontology maintenance, query formulation, information extraction.Given chose information extraction mechanism evaluating referencesets, completeness describe related work information extraction put application constructed reference sets context. also point readers previouswork reference-set-based information extraction, also present comparisonsextraction methods (Michelson & Knoblock, 2005, 2007, 2008, 2009).note information extraction techniques based CRFsdirectly use reference sets form either single columns reference set (dictionaries) (Cohen & Sarawagi, 2004) full, relational databases (Mansuri & Sarawagi, 2006),fact, approaches focus extraction unstructured text, similar posts.Again, work paper complements methods well either constructed reference set split column-wise produce dictionaries, reference-setused relational database.7. www.google.com/squared216fiConstructing Reference Sets Unstructured, Ungrammatical TextSimilarly reference-set-based extraction methods described above, extraction methods use ontologies background information (Embley, Campbell,Jiang, Liddle, Lonsdale, Ng, & Smith, 1999). Later versions work even talkusing ontology-based information extraction means semantically annotate unstructured data car classifieds (Ding, Embley, & Liddle, 2006). Although waysmethods use background information differ (the ontology-based method performs keyword-lookup ontology along structural contextual rules,reference-set-based methods use either machine-learning string-similarity methodsmatch posts reference-set members), reference-set construction method presentedcomplement ontology-based extraction well. One difficulty ontologybased method creating maintaining ontology expensive data engineeringtask. Perhaps reference-set construction methods one ease burdenproviding method discover ontology instances automatically map relations. Along lines methods use informal ontologies, Wikipedia,background information (Wu, Hoffmann, & Weld, 2008; Kazama & Torisawa, 2007).Again, method complementary here, especially unclear whether Wikipediawould cover obscure tuples could generate reference set.fact, showed Laptop domain, Wikipedia source laptops nearlycomprehensive Overstock, appropriately coverposts way generated reference set did.previous approaches use outside information aid extraction (suchontologies reference sets), also quite unsupervised methods extraction. Although use reference sets, include completenessaddressing extraction problem. One set techniques focuses finding relationsWeb. Aggregating relations sometimes yield reference sets, table person X born country (Cafarella, Downey, Soderland, & Etzioni, 2005;Hassan, Hassan, & Emam, 2006; Pasca, Lin, Bigham, Lifchits, & Jain, 2006). However,research differs reference-set-based methods posts extractrelations Web pages allows learn exploit specific extraction patterns. patterns assume similar structures occur make learnedextraction patterns useful, structural assumptions posts cannot madebeyond redundancy bigrams. Again, however, work complements quitewell, methods could perhaps used together build reference setsWeb pages posts.note task extracting information posts may associated reference set (e.g., apartment listings, entity tree would harddefine) received attention past well. So, space extraction postswithout reference sets covered complementing previous workreference-set-based extraction posts work extraction posts.particular, previous work uses information structure ads performextraction (e.g., idea certain types posts attributes often multi-token)(Grenager, Klein, & Manning, 2005). similar work uses prototype learning extraction posts seed examples attributesextract, called prototypes, provided background knowledge (Haghighi & Klein,2006). machine-constructed reference sets could provide prototypes automating217fiMichelson & Knoblockapproach even further. One interesting approach used postsassociated reference set presented Chang, et. al.(2007), extraction algorithm encodes uses various constraints extraction.One supported constraint dictionary membership. described previously,dictionaries built directly reference sets approach constructs.6. Conclusionpaper presents method constructing reference sets unstructured, ungrammatical text Web. discovered, reference sets used tasks including ontology maintenance, query formulation, information extraction. demonstrateutility machine constructed reference-sets comparing manually constructed reference sets information extraction task, show machineconstructed reference sets yield better extraction results.future plan investigate synonym discovery relationship automatically constructing reference sets. instance, may able automaticallymerge branches hierarchy synonyms referring object (suchLenovo IBM laptops). Further, plan investigate topic dynamic dataintegration using automatically mined reference sets. is, system discoversreference set, would want bring related sources data integration.Acknowledgmentsresearch based upon work supported part National Science Foundationaward number CMMI-0753124, part Air Force Office Scientific Researchgrant number FA9550-07-1-0416, part Defense Advanced ResearchProjects Agency (DARPA), Department Interior, NBC, AcquisitionServices Division, Contract No. NBCHD030010.U.S. Government authorized reproduce distribute reports Governmental purposes notwithstanding copyright annotation thereon. views conclusionscontained herein authors interpreted necessarily representing official policies endorsements, either expressed implied,organizations person connected them.ReferencesBast, H., Dupret, G., Majumdar, D., & Piwowarski, B. (2006). Discovering term taxonomyterm similarities using principal component analysis. Semantics, WebMining., LNAI 4289, pp. 103120. Springer.Cafarella, M. J., Downey, D., Soderland, S., & Etzioni, O. (2005). Knowitnow: fast,scalable information extraction web. Proceedings conferenceHuman Language Technology Empirical Methods Natural Language Processing(HLT-EMNLP), pp. 563570. Association Computational Linguistics.218fiConstructing Reference Sets Unstructured, Ungrammatical TextChang, M.-W., Ratinov, L., & Roth, D. (2007). Guiding semi-supervision constraintdriven learning. Proceedings 45th Annual Meeting AssociationComputational Linguistics, pp. 280287. Association Computational Linguistics.Cimiano, P., Hotho, A., & Staab, S. (2005). Learning concept hierarchies text corporausing formal concept analysis. Journal Artificial Intelligence Research, 24, 305339.Ciravegna, F. (2001). Adaptive information extraction text rule inductiongeneralisation.. Proceedings 17th International Joint Conference ArtificialIntelligence, pp. 12511256. Morgan Kaufman.Cohen, W., & Sarawagi, S. (2004). Exploiting dictionaries named entity extraction: combining semi-markov extraction processes data integration methods. Proceedings10th ACM International Conference Knowledge Discovery Data Mining,pp. 8998. ACM Press.Crescenzi, V., Mecca, G., & Merialdo, P. (2001). Roadrunner: Towards automatic dataextraction large web sites. Proceedings 27th International ConferenceLarge Data Bases, pp. 109118. VLDB Endowment.Ding, Y., Embley, D. W., & Liddle, S. W. (2006). Automatic creation simplified querying semantic web content: approach based information-extraction ontologies.ASWC, LNCS 4185, pp. 400414. Springer.Dupret, G., & Piwowarski, B. (2006). Principal components automatic term hierarchybuilding. SPIRE, LNCS 4209, pp. 3748. Springer.Embley, D. W., Campbell, D. M., Jiang, Y. S., Liddle, S. W., Lonsdale, D. W., Ng, Y. K.,& Smith, R. D. (1999). Conceptual-model-based data extraction multiple-recordweb pages. Data Knowl. Eng., 31 (3), 227251.Grenager, T., Klein, D., & Manning, C. D. (2005). Unsupervised learning field segmentation models information extraction. Proceedings 43rd Annual MeetingAssociation Computational Linguistics, pp. 371378. Association Computational Linguistics.Haghighi, A., & Klein, D. (2006). Prototype-driven learning sequence models.Proceedings main conference Human Language Technology ConferenceNorth American Chapter Association Computational Linguistics, pp.320327. Association Computational Linguistics.Hassan, H., Hassan, A., & Emam, O. (2006). Unsupervised information extraction approach using graph mutual reinforcement. Proceedings Conference Empirical Methods Natural Language Processing (EMNLP), pp. 501508. AssociationComputational Linguistics.Hu, M., & Liu, B. (2004). Mining summarizing customer reviews. Proceedings10th ACM International Conference Knowledge Discovery Data Mining,pp. 168177. ACM Press.219fiMichelson & KnoblockKazama, J., & Torisawa, K. (2007). Exploiting wikipedia external knowledgenamed entity recognition. Proceedings Joint Conference Empirical Methods Natural Language Processing Computational Natural Language Learning(EMNLP-CoNLL), pp. 698707. Association Computational Linguistics.Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional random fields: Probabilistic models segmenting labeling sequence data. Proceedings 18thInternational Conference Machine Learning, pp. 282289. Morgan Kaufmann.Makrehchi, M., & Kamel, M. S. (2007). Automatic taxonomy extraction using googleterm dependency.. Proceedings IEEE/WIC/ACM International ConferenceWeb Intelligence, pp. 321325. IEEE Computer Society.Mansuri, I. R., & Sarawagi, S. (2006). Integrating unstructured data relationaldatabases. Proceedings International Conference Data Engineering, p. 29.IEEE Computer Society.McCallum, A. (2002).Mallet:http://mallet.cs.umass.edu.machinelearninglanguagetoolkit.Michelson, M., & Knoblock, C. A. (2005). Semantic annotation unstructured ungrammatical text. Proceedings 19th International Joint Conference ArtificialIntelligence, pp. 10911098. Morgan Kaufmann.Michelson, M., & Knoblock, C. A. (2007). Unsupervised information extraction unstructured, ungrammatical data sources world wide web. International JournalDocument Analysis Recognition (IJDAR), Special Issue Noisy Text Analytics, 10, 211226.Michelson, M., & Knoblock, C. A. (2008). Creating relational data unstructuredungrammatical data sources. Journal Artificial Intelligence Research (JAIR), 31,543590.Michelson, M., & Knoblock, C. A. (2009). Exploiting background knowledge buildreference sets information extraction. Proceedings 21st international jontconference Artifical intelligence, pp. 20762082. Morgan Kaufmann.Muslea, I., Minton, S., & Knoblock, C. A. (2001). Hierarchical wrapper inductionsemistructured information sources. Autonomous Agents Multi-Agent Systems,4 (1/2), 93114.Pasca, M., Lin, D., Bigham, J., Lifchits, A., & Jain, A. (2006). Organizing searchingworld wide web facts - step one: one-million fact extraction challenge.Proceedings 21st National Conference Artificial Intelligence (AAAI), pp.14001405. AAAI Press.Popescu, A.-M., & Etzioni, O. (2005). Extracting product features opinionsreviews. HLT 05: Proceedings conference Human Language TechnologyEmpirical Methods Natural Language Processing, pp. 339346, Morristown,NJ, USA. Association Computational Linguistics.220fiConstructing Reference Sets Unstructured, Ungrammatical TextSanderson, M., & Croft, B. (1999). Deriving concept hierarchies text. Proceedings22nd International ACM Conference Research Development InformationRetrieval, pp. 206213. ACM Press.Schmitz, P. (2006). Inducing ontology flickr tags. Proceedings WorkshopCollaborative Web Tagging.Wu, F., Hoffmann, R., & Weld, D. S. (2008). Information extraction wikipedia:moving long tail. Proceedings 14th ACM international conferenceKnowledge discovery data mining, pp. 731739. ACM Press.221fiJournal Artificial Intelligence Research 38 (2010) 415-473Submitted 01/10; published 07/10Resource-Driven Mission-Phasing Techniques ConstrainedAgents Stochastic EnvironmentsJianhui WuEdmund H. Durfeejianhuiw@umich.edudurfee@umich.eduComputer Science Engineering, University MichiganAnn Arbor, MI 48109 USAAbstractagents resources dictate actions possibly take, planresources holds time carefully, considering inherent limitations (suchpower payload restrictions), competing needs agents resources,stochastic nature environment. agents can, general, achieveobjectives use even create opportunities change resourceshold various times. Driven resource constraints, agents could breakoverall missions optimal series phases, optimally reconfiguring resourcesphase, optimally using assigned resources phase, given knowledgestochastic environment.paper, formally define analyze constrained, sequential optimizationproblem single-agent multi-agent contexts. present family mixedinteger linear programming (MILP) formulations problem optimally createphases (when phases predefined) accounting costs limitations phase creation.formulations simultaneously also find optimal allocations resourcesphase optimal policies using allocated resources phase, exploitstructure across coupled problems. allows find solutions significantly faster(orders magnitude faster larger problems) alternative solution techniques,demonstrate empirically.1. Introductionomnipresent issue realistic application domains autonomous agents agentsresource-limited. Resources enable action. example, agent cameracapture image, agent gripper manipulate objects, agent auxiliarybattery pack take actions must recharge, agent additionalmemory chip solve larger computational problems. Given resources possesses,agent utilize take best sequences actions can, dependingobjectives environment.paper, consider situation agents degree controlresources choose possess, subject inherent (unavoidable) limitationsagents themselves, well contention resources. Agents inherent limitations stemcall capacity constraints. example, mobile robot agent (say, MarsRover) might weight limitations payload carry, cannot carrycamera gripper time. physical configuration resources mightpreclude combinations, gripper arm necessarily obstructs camera view.power drawn across combinations peripherals might exceed agents power supply,c2010AI Access Foundation. rights reserved.fiWu & Durfeecomputational cycles demanded combination time interval might exceedagents processing power. short, number reasons, agent might lackcapacity effectively possess resources might find useful, caseneeds determine subset combination resources will, expectation, allowact effectively time, given uncertainty future evolution environment.multiagent setting, agent might fail possess potentially useful resourcecapacity constraints, also resource scarcity constraints.example, might fewer instruments type, working cameras grippers,robots (Mars Rovers), case cooperative agent get oneresources expects make better use agents would getit. Along similar lines, number licenses running particular piece softwarelimited, cooperative agents allocate best possible waycollective benefit. Or, number satellites remotely control order acquire neededimages restricted, assignments agents done judiciously.Dolgov Durfee (2006) looked kinds problems, studying efficient techniquesagents assess value alternative resource combination (bundle) assignments terms execution policies (and expected utilities policies)resources enable. work focused question finding optimal static resourceallocation agent (or multiple agents) agent(s) make sequential decisionsstochastic environment.significant new contribution work present paper consider sequentiality agents actions also allocation resources.1 singleagent case, agent might plan change, midst execution, utilizes limited capacity. example, might return toolbox base station dropone instrument (e.g., camera) pick another (e.g., gripper). might powerone peripheral power another, terminate one process create another.multiagent case, agents might particular times swap possesses controls differentinstruments, holds licenses various software packages.precisely, paper present formulations defining, algorithms solving, several classes single- multi-agent sequential resource allocation decision problemsagents acting stochastic environments. problems characterized agents operating multiple phases, set resources held agent (and thus actionsperform) constant within phase, change one phase another.challenges tackle paper thus involve deciding resource constraintsdrive agents overall missions best broken planned phases,agents decide resources hold phase. shall see, questionsintertwined other, also questions agents formulatepolicies pursuing objectives phase.1.1 Simple Illustrating Single-Agent Exampledrive home problem simple form, provide running exampleuse illustrate formalisms, notations, algorithms coming sections,present simple schematic example illustrate Single-agent Resource-driven1. paper brings together significantly extends work previously reported conferences (Wu & Durfee,2005, 2007a).416fiResource-Driven Mission-Phasing Techniquesa1 (0.1), noop (0.8)12-5-20a1 (0.9), noop (0.2)a2 (1.0), noop (1.0)3a4 (0.1), noop (0.5)a5 (0.2), noop (0.8)-5a4 (0.1), noop (0.3)), noopa3 (0.9(0.05)a3 (0.1), noop (0.95)4-55a4 (0.8), noop (0.2)-5a5 (0.8), noop (0.2)6200Figure 1: simple single-agent example.Mission Phasing (S-RMP) problem. present simple multiagent example problemlater paper.problem, shown Figure 1, agent begins state S1 moves among statesS1 S5 reaches stops state S6 . Associated state Sireward ri agent receives reaching state, so, example, reaching state S2 bad(incurring reward -20) reaching state S6 good (providing reward +200).agent degree control trajectory among states based actionchooses take state. example, state S1 choice two actions, a1noop (where noop action taking action, passively letting environmentdynamics change agents state). shown figure, takes action a1probability 0.1 reaching state S2 , 0.9 reaching state S3 , whereas noop reachesstates S2 S3 probabilities 0.8 0.2 respectively. So, look agents firstdecision, would appear choose action a1 noop reduce likelihoodhigher negative reward reaching S2 .However, actually take action a1 , agent needs particular resource,call o1 . generally, actions ai agent take, needsresource oi , noop action (which notational convenience sometimesrefer a0 ), require resources. Thus, setting stateS1 agent anticipated taking actions a1 , a3 , a5 , say, would want setresources o1 , o3 , o5 .Unfortunately agent simple example, say capacity limitedsingle resource given time. Now, settingS1 need decide resource would, expectation, allow make actionchoices would maximize total reward time reaches S6 . simple417fiWu & Durfeeinstance type problem solved Dolgov Durfee (2006), showsolution shortly stepping stone algorithm.S-RMP problem, consider generalization Dolgov Durfees problem,agent access instances resources oi state S1 , alsostates. agent sets state S1 resource considersvaluable, traverses states reaches one states, say state Si .state Si , agent reconfigure resources, subject always capacity constraints,thus switch new phase execution, set actions takedifferent. thus refer states like Si (and, degenerate way, S1 ) phase-switchingstates. Referring back earlier examples capacity-limited agents, phase-switchingstate could correspond agent arriving location holding cache instruments (atoolbox), could correspond reaching time, place, situation (e.g., holdingpattern) environment less dynamic agent safely powerperipherals power others. Simple human examples phase-switching statesinclude state enter parking lot, access car,state highway entrance ramp, driver given buffer changedriving behaviors car speed prepare safely merge high-speed traffic.shall see, even problems phase-switching states static predefinedagent, phase-switching opportunities complicate agents decisionsactions take, might choose actions based rewards reachingstates also based benefits future action choices reaching phase-switching states.Further, classes problems, agent might able decompose problemphases deciding states would like phase-switching states. example,could choose would like toolboxes (or entrance ramps) placed environment,circumstances would like buffered environmental dynamicsreconfigures itself. agent would generally face constraints creating phase-switchingstates, bounds number states (e.g., might limited numbertoolboxes distribute), incur cost time creates state buffered(e.g., every holding pattern introduces costly delays).Thus, referring back Figure 1, Single-agent Resource-driven Mission Phasing (SRMP) problem generally involves optimally deciding states (besides start state S1 )designate phase-switching states, optimally allocating resources states,optimally choosing actions enabled resources phase. shallsee later, multiagent extension requires multiple agents agreephase-switching states, since resource reallocation means potentially swapping (controlover) different resources, switch best (re)distribute limited resourcesamongst themselves.1.2 Paper Overviewidea reconfiguring resources improve agent performance fairly straightforward, preceding example suggests challenging problem reconfigureresources optimally. primary goal study paper design computationally efficient algorithms exactly solve class challenging problems. Toward end,develop suite algorithms formulate complex resource-driven mission-phasingproblems compact mathematical formulations. Thereafter, simultaneously solving418fiResource-Driven Mission-Phasing Techniquesproblem decomposition (phase creation), resource (re)configuration, policy formulationproblems, algorithms fruitfully exploit problem structure, often resultssignificant reduction computational cost.paper organized follows. Section 2 introduces background techniques. Section 3starts relatively simple single-agent resource-driven mission-phasing problemphase-switching states known priori. Exploiting fixed phase-switching states,work particular, efficient algorithm. describe solution algorithms solvinggeneral resource-driven mission-phasing problems, agent needs determinereconfigure resources, reconfigure resources, optimalexecutable policies subject (re)configured resources. Section 4 extends resourcedriven mission-phasing techniques presented Section 3 class multiagent systemssequentially allocating resources among group cooperative agents. section followssimilar progression Section 3, terms giving agents increasing latitudedetermining reallocate resources. Then, contrast work related workSection 5, finally, Section 6 concludes paper summary work,discussion questions remain open together possible future research directions.2. Backgroundformulate single- multi-agent resource-driven mission phasing problems usingwell-established formalism Markov Decision Processes (MDPs), extensions constrained MDPs. section summarizes relevant aspects previously-developedformalisms, illustrates using example previously discussed Section 1.1.2.1 Markov Decision Processesgeneral, classical discrete-time, fully-observable Markov Decision Process finitestate space finite action space defined four-tuple hS, A, P, Ri (Puterman,1994), where:finite state space, represented set n states {1, ...i, ...n}.finite action space. state S, Ai represents set actionsexecuted state i.P = {pi,a,j } represents state transition probability pi,a,j probabilityagent reaches state j executes action state i.PPstate action a, j pi,a,j must greater one. j pi,a,j = 1 meansP agent always stay system executing action state i,j pi,a,j < 1 means probability agent system(which equivalently interpreted agent entering sink state agentwould stay forever) executing action state (Kallenberg, 1983).R = {ri,a } (bounded) reward function ri,a reward agentreceive executes action state i.Running Example: MDP Encoding.easily represented MDP:example introduced Section 1.1 (Figure 1)419fiWu & Durfee= {S1 , S2 , ...S6 }.= {a0 = noop, a1 , a2 , ...a5 }.P = {pS1 ,a0 ,S2 = 0.8, pS1 ,a1 ,S2 = 0.1, ...}.R = {rS1 ,a0 = 5, rS1 ,a1 = 5, ...}.Markov decision process extension well-known Markov chain. mainproperty MDP possesses Markov property (Bellman, 1957): currentstate MDP time known, transitions new state time + 1 dependcurrent state action chosen it, independent previous historystates.MDP, decision-making agent chooses actions based upon observationcurrent state world, motivation maximizing aggregate reward.deterministic stationary policy MDP defined mapping states actions: :Ai . objective decision-making agent find optimalpolicy maximizes predefined cumulative function rewards. Let {i0 , i1 , ..., , ...}{a0 , a1 , ..., , ...} represent particular state action sequences generated followingpolicy starting state i0 , let E[ ] denote expectation function. typicalcumulative reward function non-discounted MDP defined as:U () = E[Xrit ,at ]t=0Similarly, cumulative reward function discounted MDP discount factordefined as:2X()t rit ,at ]U () = E[t=0Although general mission-phasing techniques paper also apply discounted MDPs contracting MDPs (Kallenberg, 1983; Puterman, 1994; Sutton &Barto, 1998), illustrate paper using transient, non-discountedMDPs.3 NonPdiscounted MDPs described above. transient MDP (in j pi,a,j < 1states), agent eventually leave corresponding Markov chain, running policyfinite number steps (Kallenberg, 1983). words, given finite state space,assumed agent visits state finite number timesP policy,turn means total expected reward function U () = E[t=0 rit ,at ] bounded evennon-discounted MDP. running example problemSection1.1 examplePkind MDP, state S6 acts sink state ( j p6,a,j = 0).2.2 Linear Programmingvalue iteration policy iteration algorithms widely used solving classical MDPs(Kallenberg, 1983; Puterman, 1994; Sutton & Barto, 1998). However, surprisingly hardextend algorithms incorporate additional constraints without considerably increasing2. paper, (a)b represents exponent, ab represents superscript.3. transient MDP interest work subclass contracting MDPs.420fiResource-Driven Mission-Phasing Techniquessize state space and/or action space MDP model. reason,number researchers proposed utilized alternative solution approach,based upon mathematical programming (Altman, 1998; Feinberg, 2000; Dolgov & Durfee,2006). procedure formulating MDP linear program (whose solution yieldsoptimal policy maximizing total expected reward) described below. work extendsapproach.Let xi,a , often called occupation measure visitation frequency (e.g., Dolgov& Durfee, 2006),denote expected number times action executed state i.P Pfunction xi,a ri,a used represent total expected reward,problem finding optimal policy MDP equivalent solving following linearprogram:XXmaxxi,a ri,a(1)subject to:XXXpi,a,j xi,axj,a = j +: jxi,a 0: i,j probability agentP stateP j, constraint (namedP initiallyprobability conservation constraint) xj,a = j + pi,a,j xi,a guaranteesexpected number times state j visited must equal initial probability distributionstate j plus expected number times state j entered via possible transitions.linear program Eq. 1 solved, trivial derive optimal policyspecifies action(s) take given state. Specifically, policy assigns probabilityxP i,aexecuting action state maximize total expected reward. statea xi,aaction probability value zero one, optimal policy randomized;otherwise deterministic.Running Example: MDP Policy Formulation. consider problem introducedSection 1.1 (Figure 1) ignore agents capacity constraints (such agentevery state resources needed full set actions = {a0 , a1 , ...a5 }),corresponds classical (what refer unconstrained) MDP. Usingpolicy formulation algorithm, agent easily compute optimal policy,[S1 a1 , S2 noop/a2 , S3 a3 , S4 a4 , S5 a5 , S6 noop], total expectedreward 174.65.2.3 Constrained MDPsFormulating unconstrained MDPs linear programs makes straightforward takeaccount additional constraints, including agent capacity constraints resource constraints. Several constrained optimization problems investigated DolgovDurfee (2006). follows, summarize work.constrained MDP models agent capacity limitations represented hM, , Ci,where:classical MDP (Section 2.1), represented hS, A, P, Ri.421fiWu & Durfee= {i } indicates probability distribution initial states.C agent capacity constraints, represented hO, C, U, , i, where:= {o} finite set indivisible non-consumable execution resources, e.g., ={camera, spectrometer, gripper, etc.}.C = {c} finite set capacities agent, e.g., C = {weight, space, etc.}.U = {uo,a,i } represents resource requirements executing actions, uo,a,i{0, 1} indicates whether agent requires resource execute action statei.4 example, uo=camera, a=take picture, i=any state = 1 says prerequisitetaking picture camera.= {o,c } defines resource capacity costs, o,c amount agent capacityc required hold one unit resource o. example, o=camera, c=weight = 2o=camera, c=space = 1 says carrying camera consume two unitscarrying weight one unit carrying space agent.= {c } specifies limits agent capacities, e.g., c=weight = 4 denotesmaximum weight four units agent carry.Running Example: Constraint Formulation.tion 1.1, agent constraint components are:simple running example Sec-= {o1 , o2 , ...o5 }.C = {hold}.U = {uoi ,ai ,si = 1 : 1 5}.= {oi ,chold = 1 : 1 5}.= {chold = 1}.linear programming formulation (Eq. 1) paves way incorporating agent capacity constraints. Namely, capacity limitations modeled adding followingmathematical constraints (shown Eq. 2) occupation measures xi,a linear programEq. 1.XXXo,c (uo,a,i xi,a ) c: c(2)(z) step function, defined(z) =10z>0otherwiseconstraint indicates that, given resource requirement parameter uo,a,i = 1, agentemploy o,c amount capacity c hold resource decides executeaction one states policy.4. simplify presentation, assumed resource requirement binary, impliesagent interested one unit particular resource, results presentedpaper generalized non-binary resource requirement cases without much difficulty.422fiResource-Driven Mission-Phasing TechniquesNote (z) function nonlinear function. general, directly solving nonlinearconstrained optimization problems difficult. Fortunately, simple way transform nonlinear constraint Eq. 2 linear constraints introducing integervariables (Dolgov & Durfee, 2006). reformulation Equation 2 depicted below.P Puo,a,i xi,a:XXo,c c: c{0, 1}:, binary integer set {0, 1}, introduced indicate whetherPthePagent useslimited capacity hold resourceo. X constant less sup xi,a ,P PP Puo,a,i xi,anever exceeds one (because uo,a,i xi,aappliedguaranteeXP PthatPPxi,a X). One way compute X solve unconstrainedxi,a supMDP:XXX = maxxi,a(3)subject to:XXXxj,a = j +pi,a,j xi,a: jxi,a 0: i,summarize, constrained MDP models agents capacity limitationsformulated mathematical program Eq. 4 (i.e., putting Eq. 1 integerlinear constraints together), whose solution yield optimal capacity usage configurationoptimal executable policy.maxXXxi,a ri,asubject to:XXXxj,a = j +pi,a,j xi,aP Puo,a,ixi,aXXo,c c(4): j:: cxi,a 0: i,{0, 1}:Eq. 4, pi,a,j , ri,a , j , uo,a,i , o,c , c , X constants, xi,a continuousvariables binary integer variables, indicates Eq. 4 mixed integerlinear program (MILP).423fiWu & DurfeeMixed integer linear programming discrete version linear programmingadditional requirement particular variables must integers. Although MILPs NPhard number integer variables, solved variety highly optimizedalgorithms tools (Cook, Cunningham, Pulleyblank, & Schrijver, 1998; Wolsey, 1998).Recently, substantial progress using MILPs automated planning (Earl &DAndrea, 2005; Kautz & Walser, 2000; van Beek & Chen, 1999; Vossen, Ball, Lotem, & Nau,1999). automated resource-driven mission-phasing techniques (which also NP-hardshown later) presented paper based upon MILP well.Running Example: Constrained MDP Solution. simple running exampleSection 1.1, constraint permits agent hold one resource (and thus capableexecuting action noop one state). Given MDP constraintparameters problem, computing constant X = 70.24 using Eq. 3, applyMILP solver CPLEX (www.ilog.com) easily derive optimal solutionMILP:[(x1,0 , x1,1 ), (x2,0 , x2,2 ), (x3,0 , x3,3 ), (x4,0 , x4,4 ), (x5,0 , x5,5 ), x6,0 ]=[(3.47, 0), (3.03, 0), (5.21, 0), (4.95, 0), (0, 1.25), 1][1 , 2 , 3 , 4 , 5 ] = [0, 0, 0, 0, 1]is, optimal policy [S1 noop, S2 noop, S3 noop, S4 noop, S5a5 , S6 noop], corresponding total expected reward reduced 65.02 (from 174.65unconstrained case) due limitation agent capacity. optimalpolicy constrained agent uses single policy throughout entire mission.use example go along illustrate degree automated missionphasing techniques improve expected reward.3. Resource Reconfiguration Single-Agent Systemsturn new techniques results build work others summarized previous section. particular, extend representations techniquessolving constrained MDPs resources allocated prior execution, sequential constrained MDPs resource allocations change execution particular statesreached. previously mentioned described example problem (Section 1.1),refer intervals agents resources cannot change phase,states connect phases (representing opportunitybut obligationto changeresource allocation) phase-switching states. assume full complementresources (e.g., full toolbox) available phase-switching state, agentcannot pick discard resource except phase-switching state; relaxing assumption discussed future work (Section 6.2).extreme, every state phase-switching state, agent effectivelyunconstrained (unless exist action whose necessary resources total capacityrequirements alone exceed agents capacity limits). general, however,restrictions states (or should) phase-switching states. considerseveral cases section. range phase-switching states inherentlypredetermined environment (e.g., placement toolboxes, shelters424fiResource-Driven Mission-Phasing Techniquesdomain dynamics, dictated agent), number phase-switching statesbounded environment states designated phase-switching statesdecided agent (e.g., number toolboxes shelters fixed agentchoose placed), number phase-switching states unboundedcreating phase-switching state incurs cost (e.g., toolboxes sheltersbought placed agent wishes) agent want selectivespend creating phase-switching state improvement phase-switchingstate make expected reward.section begins giving formal definition single-agent resource-driven missionphasing (S-RMP) problem Section 3.1, Section 3.2 analyzes discussescomputational complexity S-RMP problem, illustrating standard approachescomputationally intractable solving problem. Section 3.3 Section 3.4 present, analyze, illustrate solution algorithms variations S-RMP problem mentionedabove. present experimental results Section 3.5, effectiveness efficiencyautomated mission-phasing techniques empirically evaluated. Finally, Section 3.6summarizes contributions work described section.3.1 Problem DefinitionFormally, single-agent resource-driven mission-phasing (S-RMP) optimization problemgeneralization constrained MDP optimization problem presented Section 2.3, composed Markov decision process M, initial probability distribution , agent capacityconstraint C, resource reconfiguration constraint5 R, where:classical MDP, described Section 2.1.= {i } probability distribution states, probabilityagent starts state i.C agent capacity constraint, described Section 2.3.R resource reconfiguration constraint (sometimes also called phase-switching constraint) specifies restrictions creating phase-switching states constrained agent reconfigure resources adjust use limited capacities.typical resource reconfiguration constraint R formulated h, (and onegeneralizations discussed Section 3.4.2), where:= {i } indicates phase-switching state creation costs, denotes costmaking state phase-switching state.0 specifies cost limit creating phase-switching states.notational convenience, also define set eligible phase-switchingstates (indicating states potentially become phase-switching state).definition, (not necessarily proper) subset S, , .is, state inherently ineligible phase-switching state cost makephase-switching state exceeds agents cost limit .5. resource reconfiguration comes along phase switching, following discussion, resourcereconfiguration constraints sometimes called phase-switching constraints improve readability.425fiWu & DurfeeRunning Example: Resource Reconfiguration Constraints. Given exampleSection 1.1, many possible specifications Resource ReconfigurationConstraints.1 > : 6= 1, = {S1 } constrained MDPsituation described Section 2.3.= 0 : (so, = S), case described beginning sectionevery state phase-switching state, thus equates unconstrainedMDP unless agent least one action needs resources whose capacity requirements exceed capacity constraint.predefined, = 0 : > : . casephase-switching states dictated agent.= 1 : i, = n 0 < n < |S|, = caseagent select subset n states phase-switching states.> 0 : i, = , = case agentcould turn (and all) states phase-switching states, costs incurredsubtracted agents reward might choose leave (or most!) statesnon-phase-switching states.Given inputs M, , C, R, objective S-RMP optimization problemmaximize total expected utility capacity-restricted agent identifying setphase-switching states 0 = {sk } decompose overall problem collectionphases, and, phase k, determining resource configuration k executablepolicy k adopted agent entry phase (at state sk ).Specifically, constrained optimization perspective, S-RMP optimization problem formulated follows:Objective:maximize utility overall policysubject following constraints:i) set phase-switching states 0 = {sk } satisfy phase-switching constraintR.ii) Within phase k, resource configuration k satisfy agent capacity constraint C.iii) Within phase k, policy k executable respect resource configuration k .iv) overall policy composed phase policies k , i.e., phase policy k adoptedagent encounters phase-switching state sk 0 midstexecution.426fiResource-Driven Mission-Phasing TechniquesClearly, S-RMP optimization problem involves three intertwined components: i) problem decomposition, ii) resource configuration, and, iii) policy formulation. Problem decomposition (which creates phase-switching states) lays foundation resource configurationreconfiguration; resource configuration dictates policies executable phase;policy formulation determines transitions within among phases well rewardsaccrued agent, turn determines utility problem decompositionresource (re)configuration.three component problems combinations investigated number research fields (but none prior approaches computationallytractable S-RMP optimization problem tightly couples problem decomposition,resource configuration, policy formulation). comprehensive discussion contrastswork prior work postponed Section 5 computationally efficient solutionapproach presented.3.2 Computational Complexity Analysisdescribing new solution techniques S-RMP problems, first analyzecomputational complexity S-RMP optimization problem illustrate standardapproaches computationally tractable solving it.Theorem 3.1. S-RMP optimization NP-complete.Proof: proof S-RMP optimization NP-hard trivial, onespecial cases, includes one phase (i.e., agent configure resourcesbeginning mission execution), proven NP-hard reductionwell-known KNAPSACK problem (Dolgov, 2006; Dolgov & Durfee, 2006).presence NP proven following way. MDP n states,clear n phases (i.e., n phases extreme situationevery state phase-switching state). featuring phase id (assuming phaseunique id) state representation, generalized MDP n2 statesconstructed polynomial time phase policies combined overall policygeneralized MDP polynomial time too. Given generalized MDP policy,problem reduced solving Markov chain. Since Markov chain verifiedpolynomial time, S-RMP optimization NP.Given presence NP NP-hard, S-RMP optimization proven NPcomplete.S-RMPs complexity evident considering straightforward solution methodswould perform. previous work (Wu, 2008), compare solution methodbrute-force search algorithm MDP-expansion-based approach. briefly summarizecomparison here. brute-force search algorithm enumerates possible problemdecomposition schemes (legal combinations phase-switching states), and, schemeenumerates possible ways configure reconfigure resources, and, finally, possible problem decomposition resource (re)configuration, derives optimal phase policiesexecutable respect configured resources. quickly becomes intractablenon-trivial S-RMP optimization problems. MDP-expansion-based approach instead427fiWu & Durfeeincorporates resources state representation models resource reconfiguration activities explicit actions, efficient brute-force algorithm, still scalespoorly folding resources states increases state space size exponentially.Neither approaches exploit key problem structure stemming coupledproblems. brute-force approach deals S-RMP component problems isolationsequentially, MDP-based approach combines resource-configurationpolicy-formulation components nave way results exponentially larger policyformulation problem. contrast, see, new solution algorithms take advantage problem structure formulating problem decomposition, resource configuration,policy formulation problems compact mathematical program solving component problems simultaneously, using highly optimized tool. shown Section 3.5,algorithms presented section often find exact solutions complex S-RMPproblem within reasonable time.3.3 Exploiting Fixed Phase-Switching Statesfar, formally defined S-RMP optimization problem theoretically analyzedcomputational complexity. next subsections, present illustratecomputationally efficient automated mission-phasing algorithms solving S-RMP optimization problems.begin first examining simple variation S-RMP optimization problemphase-switching states predetermined; is, phase-switching statesgiven agent, , = 0. variation fits problemsopportunities reconfigure resources switch policies (e.g., placementequipment and/or technicians needed (un)loading refitting) dictated agentsenvironment rather choice agent. Exploiting fact phase-switchingstates fixed, devise particular, efficient algorithm (while generalgenerally slower algorithm presented Section 3.4).Decomposition techniques planning stochastic domains widely used large environments many states (and detailed discussion problem decomposition techniquesgiven Section 5). approaches, states partitioned small regions,policy computed region, local policies pieced togetherobtain overall policy (Parr, 1998; Precup & Sutton, 1998; Lane & Kaelbling, 2001).automated mission-phasing techniques analogous decomposition techniquespartitioning mission multiple phases leads smaller state action spacesphase though motivation mission phasing handle constraints policiesagents execute rather reduce computational cost policy formulation.Nonetheless, exploit ideas.algorithm solving S-RMP optimization problems predefined phase-switchingstates based upon abstract MDPs. abstract MDP composed abstract states,corresponds mission phase. action abstract state policyused corresponding phase (which conceptually similar options, Sutton, Precup, &Singh, 1999). assumed none constraints associatedone phase. discussion general constraints postponed next subsection.Since assumed agent constraints one phase cannot affected policychoices another phase, abstract MDP unconstrained MDP (at abstract level)428fiResource-Driven Mission-Phasing Techniqueseven though internally phase still constrained MDP. algorithm thus uses policyiteration approach abstract level together embedded MILP solver within phases.embedded MILP solver finds possible executable policies expected rewardsphases, different policies may different probabilities reachingvarious phase-switching states edges phase. outer policy iterationalgorithm abstract level iteratively searches combination phase policiesmaximizes reward across whole mission.detailed procedure abstract MDP solver illustrated below:1. Partitioning mission phases.phase-switching states given, partitioning mission multiple phasesstraightforward. Start phase-switching state, keep expandingconnected transitions encountering phase-switching states. resultingstate space phase state space corresponding phase-switching state.62. Policy iteration.following policy iteration algorithm adopted state space partitioned.(a) phase-switching state s, solve MDP corresponding phase beginning state unconstrained MDP, compute state valueV (s). V (s) used initial values phase-switching states sinceprovide informed (as opposed random) estimates experience tendwork well, especially under-constrained problems.(b) abstract MDP, phase treated abstract state policyphase treated abstract action phases abstract state. policyiteration algorithm alternates following two steps:Policy improvement: Rather enumerating possible policies (abstract actions) phase (abstract state), algorithm uses constrained MDP solver(that shown Eq. 4) calculate optimal policy phase, givencurrent values V (s) associated (outgoing) neighboring phase-switchingstates.Policy evaluation: Given abstract actions, calculate V (s) phase-switchingstate s. small state spaces, standard linear algebra methods oftenbest solutions policy evaluation. larger state spaces, simplified valueiteration algorithm might preferable (simplified policyphase fixed) (Puterman, 1994).Unlike much best-response hill-climbing work, abstract MDP fixed statetransition functions fixed reward functions abstract level phase levelagent enters phase always phase-switching state, guaranteespolicy iteration algorithm return optimal solution.Theorem 3.2. abstract MDP policy iteration procedure converge optimalsolution.6. Note exploiting factored state representations lead other, efficient (although generallyapproximate) algorithms partitioning (Kim & Dean, 2001; Guestrin, Koller, Parr, & Venkataraman,2003).429fiWu & DurfeeProof: iteration, new abstract policy strict improvement previousone. Since total expected reward abstract MDP bounded (because total expected reward corresponding unconstrained MDP bounded), iteration procedureeventually converge.convergence point, phase MDPs abstract MDP satisfy Bellmanoptimality equation (because nature linear programming solver policyiteration algorithm), indicating derived policy optimal policy.Running Example: Optimizing Predetermined Phase-Switching States.return running example introduced Section 1.1 illustrate total expectedreward improved agent reconfigure resources states. Let us sayagent told able reconfigure resources switch policies states S1 , S3S4 . three phase-switching states decompose example problem three phases.corresponding abstract MDP constructed shown Figure 2, composedthree abstract states.Using abstract MDP policy-iteration algorithm described using parameters (especially executable policy cannot one actionnoop), state values phase-switching states eventually convergeV (S1 ) = 113.65V (S3 ) = 120.65V (S4 ) = 123.05optimal policy phase [S1 a1 , S2 noop] (with resource o1 ), optimal policyphase II [S2 noop, S3 noop, S5 a5 , S6 noop] (with resource o5 ), optimalpolicy phase III [S2 noop, S4 noop, S5 a5 , S6 noop] (also resource o5 ).total expected reward 113.65, 74.8% higher expected rewardconstrained MDP case (where resource allocation happens state S1 ) thanksadditional phase-switching states.Thanks policy iteration procedure, abstract MDP solver generally convergesquickly. However, noted two limitations inherent abstract MDPsolver. One limitations abstract MDP solver requires phase-switchingstates known priori, restricts applicability (although combinephase-switching-state heuristic search techniques). limitation duepossible existence constraints running across multiple phases. abstract MDP solvercannot cope constraints associated multiple abstract states, restrictionsexpected number visits particular state belongs multiple phases.contrast, general S-RMP solution algorithms present next sectionlimitations.3.4 Determining Optimal Phase-Switching Statesgeneral S-RMP optimization problem, phase-switching states completely predetermined. Instead, given defined set eligible phase-switching states , set costs {i }(where denotes cost making eligible state phase-switching state), cost0limitP , objective agent find optimal phase-switching set subject0 , along optimal resource configurations optimal executable policieswithin phase, maximize expected cumulative reward.430fiResource-Driven Mission-Phasing TechniquesPhaseS1Phase IIS2S2S3S5S4S2S6S5Phase IIIS6Figure 2: abstract MDP three phases.mentioned, abstract MDP solver presented Section 3.3 cannot directly usedgeneral S-RMP optimization problem. section, construct mixed integer linearprogram, solution yields optimal set phase-switching states maximizingtotal expected reward, well optimal resource configurations executable policieswithin phase. make simplifying assumption state positive probabilityj initial state always phase-switching state. assumption makespresentation clearer representation concise, well sidestepping questiondefault agent policy might (since would use couldconfigure resources initial state).Let xki,a expected number times action executed state within phase k.P PPClearly, state reachable phase k, xki,a = 0. Let jk = xkj,a pi,a,jxki,a pi,a,j state transition probability, jk provides way characterizetransitions among phases. state j phase-switching state, jk = 0 k,P) mustsince within phase expected number times visiting state j ( xkj,aPP equalexpected number times entering stateP j possible transitions ( pi,a,jxki,a ). state j phase-switching state, k jk = j . Recall j initial probabilityP kdistribution state j.k j = j guarantees total expected number timesvisiting state j must equal initial probability distribution state j plus total expectednumber times entering state j possible transitions.Now, formulate S-RMP optimization problem mixed integer linearprogram, shown Eq. 5. formulation builds MILP constrainedgiven Eq. 4, incorporates phase information. objective functionP P PMDPk rxi,a MILP represents total expected reward accumulated acrossk i,a431fiWu & Durfeephases, ri,a MDP reward function.maxXXXkxki,a ri,a(5)subject to:probability conservation constraints:XXXpi,a,j xki,axkj,a = jk +Xkkxi,ajk = j: j0: k, i,capacity constraints:P Pkuo,a,i xi,akoXXo,c ko cko: k, j: o, k: c, k{0, 1}: o, kphase-switching constraints:jkjXXj j: k, jjj {0, 1}: jP PPstated above, constraint xkj,a = jk + pi,a,j xki,a models conservationprobability within phase.P k= indicates probability conservation constraint acrossconstraintP PPP PP k k jP Pj kphases, i.e., k j = k ( xj,a pi,a,j xki,a ) = xj,a pi,a,j xi,a =Pj , xi,a = k xki,a total expected number times action executedstate i.P PPuo,a,i xki,acapacity constraints Xko o,c ko c arePa multi-phasePversion capacity constraints discussed Eq. 4, X = max xi,acomputed using Eq. 3.432fiResource-Driven Mission-Phasing Techniqueskj constraint Xj j binary variable, j = 1 state jphase-switching state, j = 0 otherwise. prove X sup jk follows:sup jk = sup(XxkjasupXXXpaij xkia )xkjaXXXxkiak=XkTherefore, constraint constraint j {0, 1} guarantee k : Xj >0 j = 1, implies state must phase-switching statetransition leakage state phase.Pconstraint j j j says cost creating phase-switching statesmust greater cost limit .constraints denote ranges variables. Note range restrictions jk .definition, j ko solution Eq. 5 indicate phase-switching statesresource configuration (within phase), respectively. solved Eq. 5,use resulting values xki,a derive optimal overall policy follows.1. Compute optimal policy phase.k =state i, action executed probability i,axkP i,ak .xi,ak } denote phase policyfollowing discussion, use k = {i,aphase k.2. Determine phase policy adopt phase-switching state.also trivial. agent choose phase policy k probabilityphase-switching state maximizing total expected reward, xki =xkP kP k xikxi,a .Running Example: Selecting Optimal Fixed Number Phase-Switching States.illustrate solution algorithm running example depicted Figure 1. Recallthat, shown Section 3.3, agent allowed reconfigure resourcesswitch policy S1 , S3 S4 , total expected reward 113.65 (higher reward65.02 one-shot constrained MDP case, still much lower optimal reward 174.65unconstrained MDP case). Rather starting predefined phase-switching states,assume 1 = 0, i{2,...,6} = 1, = 2. say, two additional phaseswitching states besides initial state S1 chosen agent statessystem.use transition probability pi,a,j , reward ri,a , initial probability distribution j ,resource requirement cost uo,a,i , capacity cost o,c , capacity limit c , constant value433fiWu & DurfeeX Section 1.1. phase-switching costs cost limit given above.optimal integer solution mixed integer linear program Eq. 5 is:[1 , 2 , 3 , 4 , 5 , 6 ] = [1, 0, 1, 0, 1, 0]fi 1 1 1 1 1 fi fififi 1 , 2 , 3 , 4 , 5 fi fi 1, 0, 0, 0, 0 fifi 2 2 2 2 2 fi fififi , , , , fi = fi 0, 0, 1, 0, 0 fi12345fififi fifi 3 , 3 , 3 , 3 , 3 fi fi 0, 0, 0, 0, 1 fi12345is, optimal set phase-switching states 0 = {S1 , S3 , S5 }. Examiningcontinuous variables xki,a (not shown many them) showstotal expected reward agent 173.80, close optimal unconstrainedreward 174.65. derived solution choose resource o1 adopt policy [S1a1 , S2 noop] S1 , switch resource o3 policy [S3 a3 , S4 noop] S3 , switchresource o5 policy [S2 noop, S5 a5 , S6 noop] S5 .3.4.1 Variation: Maximizing Total Reward, Accounting Costsubsection demonstrates extensibility MILP-based algorithm showingeasily revised work another useful variation S-RMP optimization problemphase-switching states predetermined (Section 3.3) cost creatingphase-switching states bounded (Section 3.4). assume state couldphase-switching state, many states desired could phase-switching states,(similarly Section 3.4) cost associated treating state phaseswitching state. However, instead subject cost limits, costscalibrated rewards associated executing policies. optimization problemmaximize total expected reward, accounting costs creating phase-switchingstates, without predetermining phase-switching states manybe. shown below, designing algorithm problems trivial. simplemathematical reformulation Eq. 5. details presented Eq. 6 (which omitsprobability conservation capacity constraints unchanged Eq. 5).maxXXXkxki,a ri,aX(6)subject to:probability conservation constraints (unchanged)capacity constraints (unchanged)phase-switching constraints:jkjXj {0, 1}: k, j: jcost creating phase-switching state i, objective functionrepresents PP P Pkrepresents total expected reward policy minuskxi,a ri,acost creating phase-switching states.434fiResource-Driven Mission-Phasing TechniquesCaseunconstrained (Section 2.1)one-shot (Section 2.3)3 fixed phases (Section 3.3)2 added chosen phases (Section 3.4)unlimited phases balancing cost (Section 3.4.1)Phase-Switching States{s1 , s2 , s3 , s4 , s5 , s6 }{s1 }{s1 , s3 , s4 }{s1 , s3 , s5 }{s1 , s5 }Expected Utility-75.3565.0213.6573.80102.55Table 1: Comparison solutions example problem, given cost creatingadditional phase-switching state 50.Running Example: Selecting Optimal Phase-Switching States Based Cost.Let us revisit running example illustrate algorithm used solvevariation S-RMP optimization problem. Suppose 1 = 0 (assuming initialstate already phase-switching state) = c state. Using MILPformulation (Eq. 6), find 0 < c 0.85 optimal phase-switching states[S1 , S3 , S4 , S5 ], 0.85 < c 21.25, optimal phase-switching states [S1 , S3 , S5 ],21.25 < c 87.53, optimal phase-switching states [S1 , S5 ], c > 87.53optimal decision create additional phase-switching states besides initial stateS1 . expected, number phase-switching states decreases cost creating phaseswitching states increases.specific example, c = 50, optimal set phase-switching states {S1 , S5 }.optimal resource configuration executable policy phase initiated S1{o3 } [S1 noop, S2 noop, S3 a3 , S4 noop], respectively; optimal resourceconfiguration executable policy phase initiated S5 {o5 } [S2 noop, S3noop, S4 noop, S5 a5 ], respectively. policy utility 152.55 (reward)501 (cost) =102.55.better understand compare solution example solutions derivedprevious sections, Table 1 shows solution utilities (where utility definedexpected reward policy minus cost creating phase-switching states).surprisingly, utility solution presented subsection higher otherssince derived algorithm (Eq. 6) explicitly balances costs expectedbenefits creating phase-switching states.3.4.2 Variation: Cost Associated State Featuresfinal variation briefly describe, similarities multiagent approachdescribed later Section 4, case conditions enable resource reconfiguration (phase switching) associated subset world features, rather fullygrounded state. simple example, consider situation resources (e.g., softwarepackages, control satellite, etc.) licensed/leased particular timesparticular intervals, hourly. is, agent identify, start hour,resources (within capacity constraints) hold next hour. couldnumber states (e.g., physical locations, pending task queue, etc.), resource reconfiguration take place them. Similarly, example robot reconfigures435fiWu & Durfeeresources toolbox, critical feature phase switch state whoselocation feature corresponds toolbox, regardless state features (e.g., directionfacing battery level).generally, let us say MDP state space consists L disjoint subsetsS1 , S2 , ..., Sl , ..., SL , subset contains states identical valuesphase-switching feature(s) (e.g., states Sl clock time t). Thus, state withinSl phase-switching state states Sl phase-switching states well. Letl denote cost making Sl states phase-switching states, i.e., costenable phase switching worlds critical feature(s) take common value(s)Sl , let denote cost limit creating phase-switching states. Clearly,generalization previous phase-switching constraint: every Sl contains exactlyone state, representation equivalent phase-switching constraint R previouslypresented Section 3.1.new mixed integer linear program generalized phase-switching constraintformulated Eq. 7, similar Eq. 5, except minor revisionsportion phase-switching constraints. before, constraints unchanged Eq. 5repeated.XXXmaxxki,a ri,a(7)ksubject to:probability conservation constraints (unchanged)capacity constraints (unchanged)phase-switching constraints:jklXXl l: k, l, jSlll {0, 1}: lbinary variable l denotes whether Sl phase-switching set.Running Example: Selecting Optimal Phase Switching Features. runningexample, suppose state space composed Sl=1 = {S1 }, Sl=2 = {S2 , S3 },Sl=3 = {S4 , S5 }, Sl=4 = {S6 }, l=1 = 0, l6=1 = 1, = 1. solutionEq. 7 yield policy reward 165.68 using phase-switching states {S1 , S4 , S5 },spending one unit cost creates phase-switching state S4 phase-switchingstate S5 .3.5 Experimental Evaluationpoint, described variations single-agent resource-driven mission-phasingproblems techniques solving them, using simple example illustrate ideas.Ultimately, significance techniques hinges computational efficiencysolving problems difficult. section, give empirical evaluationtechniques focusing problems complex state space larger resource436fiResource-Driven Mission-Phasing Techniquesset. experiments implemented simplified Mars rover domain simulationautonomous rover operates stochastic environment. Following much literaturesimilar problems (Bererton, Gordon, & Thrun, 2003; Dolgov & Durfee, 2006), Marsrover domain represented using grid world.3.5.1 Experimental Setupgrid world (see Figure 3c) number wall locations rovercannot move. locations associated execution resource, which,held rover, allows rover move confidence safety locationdesired next location. example, resources could sensors conditionsdifferent locations (dusty, foggy, overgrown, etc.), different kinds wheels (for navigatingsand, rocks, etc.). rover agent also move without holding appropriate resourcelocation, result greater uncertainty action outcomes (it could blunderslip, thus arrive different location desired) possibly cause damagerover, detailed shortly.addition, multiple tasks randomly distributed grid world.rover reaches location task, rover currently carries task-required execution resource, rover choose perform action (that carries task)receive reward. task carried out, mission accomplished roverleave system (the experimental run terminates).experiences running variety experiments indicate trends resultspresented section sensitive exact parameter settings, sakereproducibility, describe detailed parameters below. procedure buildingrandom grid world illustrated Figure 3. n n grid world built, 40%locations randomly chosen wall locations, 10% locations randomly chosentask locations. avoid simple test problems, use grid worlds whose numberreachable locations (from rovers starting location) greater half total numberlocations (i.e., greater n2 /2).task location, task could accomplished rover generatereward. make problem interesting challenging, distinguish tasks settingdifferent rewards them. sort tasks Manhattan distances starting locationrover (the smallest distance first), let ith task reward i. Therefore,always true rover would desire pursue high-reward tasks low-rewardtasks closer rover might easier safer complete.rover always starts (START) location left bottom corner grid(which never assigned wall), objective maximize expected reward.time step, rover chooses action action set {wait, up, left, down, right,safe-up, safe-left, safe-down, safe-right, do}. Actions wait, up, left, down, rightexecuted without requiring rover carry particular resource. contrast, performingsafe-moving action safe-up, safe-left, safe-down, safe-right non-wall location requiresparticular resource (related location), randomly uniformly selectedresource set problem built. Analogously, performing action task locationrequires particular resource also randomly uniformly selected. pointedperforming action needs one resource, resource may (by chance)437fiWu & Durfee40% wallsSTARTlocation(a)10% tasks,closer START,lower reward(b)1non-tasklocation, randomresource movement23task location,random resource movementrandom resource task(c)Figure 3: procedure creating random grid world. (a) 40% locations randomly chosen walls. (b) 10% locations randomly chosen tasks. (c)resource requirements randomly set.438fiResource-Driven Mission-Phasing Techniquesenable agent move safely multiple locations, and/or carry multiple tasks.resource requirement information known rover priori.following lists detailed action parameters used experiments:wait executed non-wall location without requiring resource.execution action, rover stay current location probability 0.95,system probability 0.05 (e.g., running battery).up, down, left, right executed non-wall location without requiring resource. actions achieves intended effect probability 0.4, movesrover three directions (except intended direction)probability 0.1, keeps rover current location probability 0.1, causesdamage rover (and rover system) probability 0.2.Furthermore, rover bumps wall, stay current location.safe-up, safe-down, safe-left, safe-right executed location whose required resource currently held rover. Compared unsafe-moving action,safe-moving action achieves intended effect much higher probability0.95, fails (leaves system) lower probability 0.05. Similarly before,rover bumps wall, stays current location.executed tasks whose required resources currently held rover.action executed, rover receives reward task currentlocation, leaves system (since mission accomplished).capacity rover restricted: capacity limit , carrying resourceincur one unit capacity cost. say, rover carry resources.run experiments Core 2 Duo machine use CPLEX 10.1 MILP solver.experiments, average data point computed 20 randomly generated problems.3.5.2 Improvements Solution Qualitystart evaluation showing improved reward using phasing strategyapproach consider possibility switching resources midstexecution. Let us first consider case five supply stations distributedenvironment (the first station always START location remaining fourstations randomly uniformly distributed non-wall locations problemgenerated). parameters set follows: n = 8, i.e., size grid world 88, |O| = 9, i.e., nine different types resources system. Figure 4gives average rewards experiments, error bars graphedresults throughout paper show standard deviation. Clearly, exploiting resourcereconfiguration opportunities (using abstract MDP solver presented Section 3.3)considerably improve performance rover, e.g., receiving reward average40% higher reward taking advantage supply stations, rovercarry three resources.Figure 4 also compares performance rover case locationssupply stations randomly pre-selected case locationsnumber supply stations (i.e., five phases, given i=ST ART = 0, i6=ST ART = 1,439fiWu & Durfee4.545 optimal phasesaverage reward3.55 fixed phases3nonphasing2.521.510.50123456789number carried resourcesFigure 4: Exploiting fixed phase-switching states increases agents reward, findingoptimal phase-switching states increases reward.4.54average reward3.532.521.510.5011.522.533.544.555.56number phasesFigure 5: reward increases number phases increases.= 4) determined rover itself. expected, finding optimal phase-switchingstates (which done using MILP algorithm presented Section 3.4) valuabletightly constrained environments. example, average, yields reward 46%higher approach randomly selects phase-switching states numbercarried resources limited = 3.Figure 5 examines effectiveness resource-driven mission-phasing approachanother perspective, showing average reward rover function numberphase-switching states built environment (with system parametersn = 8, |O| = 9, = 3). see (as expected) breaking mission multiplephases significantly improve total expected reward constrained rover.440fiResource-Driven Mission-Phasing Techniquesexample, setting two additional supply stations 8 8 grid world environment (andbreaking three phases) almost double average reward rovergain without using phasing.3.5.3 Computational Efficiencymajor objective work presented section design computationallyefficient solution approach S-RMP optimization problem. Section 3.2 giventheoretical analysis computational complexity S-RMP optimization problem;subsection intended empirically evaluate efficiency solution approachpresented section solving complex S-RMP optimization problems. makepresentation concise, runtime performance MILP-based algorithm describedSection 3.4 shown, i.e., focusing standard S-RMP optimization problem definedSection 3.1.7two prior straightforward algorithms described Section 3.2 (the brute-force searchapproach based upon enumeration MDP-based approach incorporating resource features MDP state representation) also used solve S-RMP optimizationproblem. Enumerating decompositions, then, each, enumerating possible resource configurations reconfigurations thought (very slow) brute-forcesearch algorithm formulated MILP. Therefore, report empirical results,since state-of-art MILP solvers (such CPLEX use) usually follow sophisticated branch-and-bound (B&B) strategies, well established mathematicalprogramming literature B&B approach is, general, significantly betterstraightforward brute-force search (in runtime finding optimal solutionanytime performance finding good solution). search Artificial IntelligenceOperations Research literatures indicates MDP-based approachexisting approach (besides brute-force search) directly applicable S-RMPoptimization problem. thus focus comparing MILP-based algorithmMDP-based algorithm following discussion.MDP-based algorithm, new drop-all action |O| new pick-one actionsadded original action space (instead adding 2|O| resource reconfigurationactions). say, rather performing resource reconfiguration one step,agent switches new bundle resources first implementing drop-all actionsequentially performing pick-one actions desired resources.experience revised algorithm computationally efficient versionexponential-size action space.Note MDP resulting incorporating resource features state representation still constrained MDP phase-switching constraints place restrictionsstates resource-reconfiguration-related actions performed in. constrainedMDP solver (Eq. 4) shown efficient solving large constrained MDPs (Dolgov,2006), work uses solving remodeled constrained MDPs.87. experiments (Wu, 2008) also show trends results variations S-RMP optimization problem similar described subsection.8. MILP formulation solving remodeled constrained MDP, number binary variables equalsnumber states specified S-RMP problem definition. is, runtime MDP-basedalgorithm exponential input size doubly exponential.441fiWu & Durfee120runtime (seconds)10080604020012345678910number phasesFigure 6: runtime increases decreases number phases increases.provide better idea computational complexity experimental domainsolution techniques, begin showing hard resource-driven mission-phasingproblem is, particularly along dimension number phases created.use parameters Figure 5, analyze runtime instead. results shownFigure 6, demonstrates running time deriving optimal S-RMP solutionvaries number supply stations created environment increases.figure, solid line shows average, error bars show standard deviation, datapoint, shown , corresponds single run.shown figure, running time low number phases small,gradually increases number phases increases. surprising,number variables (both continuous variables binary variables) MILP formulationlinear number phases. However, interesting observation that,point, runtime starts decrease although size MILP still keeps increasing.believe because, number allowable phases large, severaldifferent ways set phase-switching states achieving maximum reward.words, S-RMP optimization problem large number phase-switching statesbecomes under-constrained, might large number different optimal solutions.MILP-based algorithm presented work effectively exploit property,reduce computational costs. Based upon complexity profile, highlight abilitysolving hard problem instances, following experiments set phase-switching cost limit2 (except case examine running time changes numberphases increases). means three phases system, assumingcreating additional phase-switching state incurs one unit cost.Figure 7 compares average time finding optimal solution MILPbased algorithm standard MDP-based algorithm relative number phases(top-left figure), number carried resources c (top-right figure), number resourcetypes |O| (bottom-left figure), size9 grid world n (bottom-right figure).9. Recall grid world size n n.442fiResource-Driven Mission-Phasing Techniques500MDPbasedMILPbasedruntime (seconds)runtime (seconds)5004003002001000123456MDPbasedMILPbased40030020010007number phases34567500MDPbasedMILPbasedruntime (seconds)runtime (seconds)2number carried resources5004003002001000146810MDPbasedMILPbased400300200100012number resource types5678910size grid worldFigure 7: Runtime comparison MILP-based algorithm MDP-based algorithm. MILP-based algorithm finds exact solution S-RMP optimizationproblem faster standard MDP-based algorithm. Parameters set follows. Top-left figure: n = 8, = 3, |O| = 9, = {0, 1.., 6}. Top-right figure: n = 8,= {1, ..., 7}, |O| = 9, = 2. Bottom-left figure: n = 8, = 3, |O| = {3, 4, ..., 12},= 2. Bottom-right figure: n = {5, 6, ..., 10}, = 3, |O| = 9, = 2.see MILP-based algorithm expectation considerably faster MDP-basedalgorithm, particularly complex problem instances.top-left figure, results MILP-based algorithm shownFigure 6, already discussed. Notably, unlike three figures,curve MDP-based algorithm figure monotonically increase valueinput parameter increases. input parameter figure, numberphases, affect size state space expanded MDP. Furthermore,constrained MDP method (Eq. 4) used solve expanded MDP exploit problemstructure problem becomes under-constrained. explains running timedecreases point (but time still much higher MILP-basedapproach).top-right figure also demonstrates trend running time MILP-basedalgorithm decreasing value input parameter (i.e., number resourcescarried rover) particular threshold. reason443fiWu & Durfeeused explain Figure 6 MILP-based algorithm, MILP solver utilizesbranch-and-bound, effectively discover exploit fact problem becomesunder-constrained. contrast, MDP-based algorithm incorporating resource featuresstate representation leads MDP whose size grows rapidly numberresources carried increases, thus results significant increaserunning time.illustrated bottom-left figure bottom-right figure, average runtimeMILP-based algorithm also increases considerably slowly MDP-basedalgorithm, although, unlike top-left top-right figures, runtime monotonically increases either number resource types size grid world increases.because, general, increases two parameters make problem becomeunder-constrained themselves.reason significant reduction computational cost MILP-basedapproach formulate S-RMP optimization problem compact (as opposed exponential) formulation, paves way taking advantage state-of-the-art MILPsolvers effectively solve coupled problems problem decomposition, resource configuration, policy formulation. important emphasize MILP-based approachuses approximation techniques (and find optimal solutions). compactnessformulation MILP-based approach folds process solving NPcomplete S-RMP problem process solving NP-complete MILP (where MILPsolved efficiently state-of-the-art solvers).Specifically, MDP-based approach models resources MDP representation regardless valuations subsets resources, reasons generalizedMDP determine optimal way configuring reconfiguring resources. contrast,MILP-based solver finds exact S-RMP solution taking advantage embeddedbranch-and-bound MILP method discard subsets fruitless candidate solutions (throughupper lower estimated bounds). Although MILP-based approach MDP-basedapproach similar worst-case runtimes, i.e., requiring exponential time enumeratepossible ways sequentially configuring resources (which reasonable S-RMP NPcomplete), average-case performance MILP-based approach often much betterMDP-based approach effectiveness branch-and-bound algorithmpruning suboptimal solutions. particularly significant cases suboptimaldecompositions detected easily early large number possible resourceconfigurations executable policies discarded without much computationaleffort.3.6 Summarypoint, analyzed several variations single-agent resource-driven missionphasing problem, corresponding several cases phase-switching constraints, presentedsuite computationally efficient algorithms finding using mission phases.shown analysis experiments approach considerably reducecomputational cost finding exact solution complex S-RMP optimization problemcomparison prior approaches. remainder paper, extendtechniques multiagent stochastic systems.444fiResource-Driven Mission-Phasing Techniques4. Resource Reallocation Multiagent SystemsAdditional complications arise agent deciding resources holdpart multiagent system, potential competition scarce, shared resources.example, might satellites remotely control acquire desiredimages, small number licenses simultaneously run software package. individualagent might unable procure desired resources (even capacityrestrict amount resources hold) agents may wantresources well. cooperative agents, optimal allocation distribute resourcesagents maximize agents aggregate reward, meaning shared resource (suchcontrol satellites sensor) given agent use best, givengoals, potential actions, resources possessed.problem general doubly-exponential. could agent need considerexponentially many combinations resources might possess, collectivelyagents could need consider exponentially many joint combinations individualcombinations, filtering exceed shared resource constraints, returningbest remain. Dolgov Durfee (2005, 2006) showed much efficientalgorithm possible exploits problem structure case agents valuationresource bundle based expected value MDP policy utilizesactions made possible holding resources bundle. summarize workSection 4.2, approach similar solution method resource assignmentsingle agent capacity constraints described Section 2.3, like work solvesone-shot allocation problem. Hence, like work consider possibilityagents might able redistribute resources among midst missionexecution.section thus focuses solving sequential resource redistribution (reallocation) problems, along problem optimizing agents policies execution phasesredistribution events, building ideas Dolgov Durfees work well SRMP techniques presented previous section. remainder section thus largelyfollows parallel structure preceding S-RMP presentation. begin (Section 4.1)introducing simple problem use running examples remaindersection. summarize (and using example illustrate) prior workDolgov Durfee (2005, 2006) one-shot allocation Section 4.2, define sequential multiagent resource-driven mission phasing problem Section 4.3. analyzingproblems complexity (Section 4.4), consider sequence variations problem(again paralleling S-RMP description), beginning case phase-switchingstates pre-defined (Section 4.5) chosen (Section 4.6),each, present, analyze, illustrate solution algorithms. efficiency optimalitytechniques empirically evaluated Section 4.7. Finally, Section 4.8 summarizescontributions work presented section.4.1 Multiagent Exampledescribe simple multiagent resource-allocation example problem useillustrate various solution approaches throughout section. example, twocooperative agents attempt maximize total expected reward ten time stepinterval. agent three tasks. time step, agent choose continue445fiWu & DurfeeTask 1----------------------Task 2----------------------Task 3----------------------Reward:RL :DL:Resource:Reward:RL :DL:Resource:Reward:RL :DL:Resource:10141122102285812Task 1----------------------Task 2----------------------Task 3----------------------Reward:RL :DL:Resource:Reward:RL :DL:Resource:Reward:RL :DL:Resource:2617126381126102Figure 8: simple two-agent example.previously started task (if one required resources still assignedagent), start new task (and abort current task one), simply nothing.addition, say task aborted previously (and thus failed)re-tried, task accomplished once.Figure 8 shows detailed information tasks example problem, includingrelease (RL) time (i.e., earliest time task started successfully), deadline (DL)(i.e., latest time task finish successfully), reward task completes successfully,resource prerequisites. example, agent 1 start (or continue) task 1,incur reward 10 accomplished, time step within interval [1, 4) givenone unit resource 1 time. concentrate multiagent issues,problem assume agent sufficient capacity carry resources 12. uncertainty problem amount time required execute task. Here,say that, agent starts task abort execution, agentprobability 0.3, 0.4, 0.3 accomplishing within one, two, three time steps,respectively.10multiple instances resources 1 2, problem degeneratestwo independent unconstrained MDP problems, one agent. illustratedFigure 9, agent hold resources needs throughout full time interval. Usingstandard policy formulation algorithm (e.g., value iteration), easily computeoptimal unconstrained policy agent, yields total expected reward acrosstwo agents 93.64.4.2 Background: Integrated Resource Allocation Policy FormulationStochastic planning multiagent environments typically much challengingsingle-agent environments, particularly agent partial view globalenvironment. Previous complexity analyses shown general decentralized Markovdecision process (Dec-MDP) NEXP complete (Bernstein, Zilberstein, & Immerman, 2000;10. problem representation simplification TAEMS modeling approach (Lesser, Decker, Wagner,Carver, Garvey, Horling, Neiman, Podorozhny, Prasad, Raja, Vincent, Xuan, & Zhang, 2004; Wagner,Raja, & Lesser, 2006) used DARPA COORDINATORS project (Wagner, Phelps, Guralnik, &VanRiper, 2004; Wu & Durfee, 2007b).446fiResource-Driven Mission-Phasing Techniques11111111112222222221111111112222222222345678910Figure 9: Optimal resource allocation resources unlimited.Goldman & Zilberstein, 2004). Fortunately, many application domains, actions takenone agent may impact agents transitions. example, deliveryrobots operate large open environment, interactions may rare easily avoidable.development efficient algorithms loosely-coupled systems gained muchattention among many researchers (e.g., Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling, Dean,& Boutilier, 1998; Becker, Zilberstein, Lesser, & Goldman, 2004; Dolgov & Durfee, 2005).approach specifically draws upon prior approach designed Dolgov Durfee(2005, 2006), extends work summarized Section 2.3 multiagent resourceallocation case. work assumes group cooperative agents coupledsharing resources (i.e., actions selected one agent might restrict actions availableothers), actions executed one agent cannot impact rewards transitionsothers. typical resource-allocation research literature, work also assumesthat, resources distributed, utility agent achievefunction resource assignment depend resources givenagents use resources.multiagent constrained MDP scarce shared resources representedtuple hM, , Ci, next specified. Note specification essentially represents independent instance constrained MDP (Section 2.3) agent, except (the setresources) (the bounds number copies resource) shared acrossagents.= {Mm } set classical MDPs, Mm represents agent ms MDP, modeledway described Section 2.1. is, Mm = hS , , {pmi,a,j }, {ri,a }ifinite state space agent m, finite action space agent m,pmi,a,j probability agent reaches state j executes actionreward agent receives performs action state i.state i, ri,a= {m } specifies initial probability distribution states agent m,im probability agent initially state i.C represents resource constraints agents system, representedhO, C, U, , , where:447fiWu & Durfeefinite set shared, indivisible, non-consumable execution resources.11C = {C } specifies finite set capacities agent m.U = {U } gives resource requirements agents actions,binary parameter umo,a,i {0, 1} indicates whether agent requires resourceexecute action state i.= {m } represents capacity costs agent m.} captures capacity limits agent m.= {m= {o } specifies (shared) resource limitations, maximum numbercopies resource distributed agents system.Running Example: Multiagent Constraint Formulation. simple running example Section 4.1, agents constraint components C summarized below,represents state unspecified values u zero.= {o1 , o2 }.C = {{hold}, {hold}}.U = {{u1o1 ,a1 , = 1, u1o2 ,a2 , = 1, u1o1 ,a3 , = 1, u1o2 ,a3 , = 1}, {u2o1 ,a1 , = 1, u2o2 ,a1 , =1, u2o1 ,a2 , = 1, u2o2 ,a3 , = 1}}.= {{o11 ,chold = 1, o12 ,chold = 1}, {o21 ,chold = 1, o22 ,chold = 1}}.= {{c1hold = 2}, {c2hold = 2}}.= {o1 = 1, o2 = 1}.algorithm devised Dolgov Durfee (2006) presented Eq. 8, clarityleaving capacity constraints focus multiagent constraints. Analogouslysingle-agent case, continuous variable xmi,a represents expected number timesagent executes action state i, binary variablerepresents whether oneunit resource assigned agent prior execution.maxXXXxmi,a ri,a(8)11. simplicity, assume resources shared. agents also draw cacheprivate resources straightforward extension would add unnecessary complicationpresentation.448fiResource-Driven Mission-Phasing Techniquessubject to:probability conservation constraints:XXXxmpmj,a = j +i,a,j xi,axmi,a: m, j0: m, i,resource constraints:P Puo,a,i xi,aXXo,cc: m,: c,X=:{0, 1}: m,P P Pobjective function xmi,a ri,a represents sum cumulative rewardsamong agents, based upon assumption agents coupledresources (i.e., actions taken one agent impact agents rewardstransitions).PP Pconstraint xmj,a = j +pi,a,j xi,a guarantees probability conservationevery state every agent, multiagent version probability conservationconstraint single-agent MDP formulation (Eq. 1).P PX constant equal greater sup xmi,a (where finite horizon MDP,X set finite horizonsinceagentexecute actions withinP Puo,a,i xi,aimplies xmhorizon). constrainti,a must zero (i.e.,X=1(i.e., agent mustaction cannot executed agent state i) umo,a,iresource execute actionPa Pstate i) = 0. xmi,a unrestricteddefinition.xotherwise since X less umi,ao,a,iPconstraint= guarantees total amount resource allocatedacross agents must equal amount available resource (assuming resourcesP bemcompletely assigned). constraint easily relaxed constraintintroducing additional dummy agent keep unallocated resources.optimal joint policy easily derived solution MILPsimilar way discussed Section 2.2. is, maximize total expected rewardxmgroup agents, agent choose probability P i,astatexi,ai.Running Example: Multiagent Constrained MDP Solution. Continuing simplerunning example Section 4.1, apply solution technique find optimalallocation resources 1 2 outset agents assuming onecopy available. Eq. 8 finds optimal one-shot allocation give resourcesagent 1 let agent 2 idle entire execution, shown Figure 10, total449fiWu & Durfee11111111112222222222345678910Figure 10: Optimal one-shot resource allocation resources scarce.expected reward 49.64 case, much lower reward (93.64) unconstrainedcase.4.3 Multiagent Resource-Driven Mission Phasing Problem DefinitionMultiagent Resource-driven Mission Phasing (M-RMP) problem sequential versionDolgov Durfees (one-shot) multiagent resource allocation problem described.general multiagent mission-phasing problem solved exactly using S-RMPsolution approach presented Section 3 joint state action spaces interactingagents (assuming agent full view joint state), solutionmethodology would suffer curse dimensionality since sizes joint stateaction spaces grow exponentially number agents. Thus, exploitloose-coupling assumption: agents interact (now potentially repeated)contention shared resources, otherwise transition reward independent.multiagent case sequential resource (re)allocation, phase correspondsparticular distribution shared resources among agents. say transitionone phase another occurs agents reach state relinquishpossession resources currently hold, acquire resources nextphase.12 However, unlike single-agent case agent knows reachedphase-switching state, multiagent case agent observe local state,detecting joint phase-switching state would require agents communicate stateinformation individually track full joint state. turn means wouldneed policy maps (exponentially larger space of) joint states local actions,effectively introducing transition reward dependencies exploding complexityproblem.work instead agents exploit deterministically-changing feature jointstate observe: (synchronized) clock. Phase switchingredistributingresources software licenses control satellites sensorsoccurs pre-arranged(and preferably carefully chosen) times. already saw Section 3.4.2 (single-agent) RMP12. principle different subsets agents could swap resources among themselves, paperconsider case agents engage swaps, though course since agent acquireresources relinquishes effect could subset agents materially involvedgiven swap.450fiResource-Driven Mission-Phasing Techniquesvariation phase-switching states grouped based value(s) (subset of)feature(s). M-RMP builds variation, effectively partitioning exponentially-sizedjoint state space subsets based states time feature, determining time(s)resource (re)distributions take place, matter detailsagents states whether finished using currently-held resources yet.Phasing based time advantages limitations. One key advantagerequires agents know runtime knowtime (and common knowledge). domains reliable mutual observationcommunication runtime impractical (for example, military operations), synchronizing actions based clock time long norm. second advantagefuture time guaranteed reached. contrast, agents need conditionsmet exchange resources (for example, need location and/oridle), applications might impossible guarantee state everoccur. force cases occur, agents would need know othersstates (where others and/or soon current tasks end) reach hand-offpoint. M-RMP techniques describe principle extended cases,practice greater need agents global state awareness, lesser expectproblems exhibit kinds structure M-RMP exploits.paper, also assume resource redistributions always succeed (resourcessomehow get misplaced transfer); discussion future work (Section 6.2)talk implications relaxing assumption.Based preceding, formally define multiagent resource-driven missionphasing (M-RMP) problem. generalization multiagent constrained MDP described Section 4.2, tuple hM, , C, Ri, components M, , Cdefined Section 4.2, R defined follows.R specifies constraints resource reallocation. capture efforts requiredresource reallocation activities costs h{t }, i:13{t } indicates resource reallocation costs, denotes cost reconfiguring resource assignment time t. Note associated timeregardless resources many reassigned. variationresource reallocation constraints reallocation cost depends amountresources transferred discussed analyzed Section 4.6.1presenting solution algorithm M-RMP optimization problem definedsection.specifies limit amount cost could spent resource reallocation. example, t=any time = 1 = 4 means four resourcereconfiguration events could scheduled particular mission execution.Running Example: M-RMP Formulation. Continuing simple running exampleSection 4.1 building encoding Section 4.2, agents reallocation constraints R summarized below, assuming agents reallocate resources three timesbesides initial time 1.13. different buffer pool research (Lehman & Carey, 1986; Sacco & Schkolnick, 1982), oftenassumes buffer size changed immediately free charge.451fiWu & Durfee= {1 = 0, = 1 : 2 10}.= 3.objective M-RMP optimization problem maximize total expectedreward group agents within finite time horizon judiciously reallocating limited, shared resources among agents time. Although much simpler generaldecentralized MDP problem, automated multiagent mission-phasing problem stillcomputationally challenging needs determine initially allocatelimited shared resources, also reallocate resources, best way reallocating resources times are, best executable policies respectreallocated resources are. S-RMP, three component problems mission decomposition, resource allocation, policy formulation strongly intertwined. utilitydecomposing problem phases utility allocating resources phaseunknown executable policies formulated evaluated, policies cannotformulated phases built resources allocated.4.4 Computational Complexity Analysissection starts theoretically analyzing computational complexity M-RMPoptimization problem.Theorem 4.1. M-RMP optimization NP-complete.Proof: trivial prove M-RMP optimization problem NP-hard. Givenspecial case one-shot resource allocation policy formulation provenNP-complete reduction KNAPSACK problem (Dolgov, 2006), M-RMPoptimization NP-hard.Given solution M-RMP problem, satisfaction resource constraintsresource reallocation constraints verified linear time. that, agent,incorporating policy MDP model, M-RMP optimization problem becomesMarkov chain, solved polynomial time. is, M-RMP optimizationNP.NP NP-hard, M-RMP optimization NP-complete.Given result, surprising prior approaches (summarized below)could applied finding exact solution M-RMP optimization problemcomputationally efficient.Decentralized MDP. Modeling resources MDP state representation formulating resource-reconfiguration activities actions possible (but slow) way solveS-RMP problem (Section 3), generally infeasible M-RMP problem.Since outcome agents resource-reallocation action (e.g., acquiring resource)depends whether another agent takes corresponding action (e.g., releasing resource) time, resulting Decentralized MDP (Dec-MDP)transition independent. general Dec-MDP NEXP-complete (Bernstein et al.,2000), meaning M-RMP involves solving NEXP-complete problem inputexponential number resources.452fiResource-Driven Mission-Phasing TechniquesCombinatorial stochastic optimization. Although phase M-RMP problem one-shot resource-allocation policy-formulation problem, directly usingintegrated combinatorial stochastic optimization approach (Section 4.2) solvephase independently piecing phase policies together is, general,infeasible. Besides enumerate possible decompositions, solving phaseindependently requires knowing initial state probability distribution jm Eq. 8.Unfortunately, jm phase generally depends policy preceding phase,policy preceding phase usually optimized respect alreadyknowing expected utilities attainable current future phases.Auction-based resource allocation. resource allocation approach based using auctions (Pekec & Rothkopf, 2003; De Vries & Vohra, 2003), agent bids set valuations possible sequential resource assignments central auction,decides sequentially allocate resources among agents. Unfortunately,approach scale. example, group = 5 agents wants maximizetotal expected reward within = 10 time steps, (re)distributing = 5 shared resources k = 3 times (twice initial allocation), agent needst1solve Ck1(2)ok = 1, 179, 648 non-trivial problems evaluate possible sequentialresource assignments. Then, auction faces winner determination problem (WDP)5 agents submits 1, 179, 648 bids daunting task.S-RMP problem, solution formulate problem simultaneously solve coupled problems mission decomposition, resource allocation, policyformulation, exploit interactions among reduce computational cost.4.5 Exploiting Fixed Resource Reallocation ScheduleSection 3.3, begin simple variant problem, schedulereallocating resources predetermined, i.e., resource reallocation cost = 0 time stepspecified predefined schedule, > 0 otherwise, cost limit = 0.Section 4.4 explained directly applying (one-shot) integrated combinatorialstochastic optimization approach phase independently piecing phase policiestogether generally infeasible. approach instead links phases together modelingtransition probability conservation. details given following MILP. Note that,highlight M-RMPs emphasis resource (re)allocation, continue throughoutremainder section omit capacity constraints.maxXXX453xmi,a ri,a(9)fiWu & Durfeesubject to:probability conservation constraints:XXXxmpmj,a = j +i,a,j xi,axmi,a0: m, i,resource constraints:PPuo,a,i xi,aiSkm,kXm,k=m,k: m, j{0, 1}: k, m,: o, k: k, m,probability conservation constraints Eq. 8, resourceconstraints associated (superscripted by) phase k.indicate whetheragent assigned onePhase-specific binary variables m,kP= says amountunit resource phase k. constraint m,kresource allocated phase k must equal amount available (again, assumem,klinked constraintdummy agent hold unwanted resources). xmi,aPxmi,aPumo,a,i xi,am,k(where Sk represents set states within phase k). is,0 (i.e., action executable state agent within phase k) umo,a,i = 1 (i.e.,iSkrequires resource o) m,k= 0 (i.e., agent resource phase k)resource o. Otherwise, xi,a restricted since actions executedfinite time horizon .Deriving optimal sequential resource allocation joint policy solutionEq. 9 straightforward. start time phase k, resources redistributedfollowing way: m,k= 1, unit resource assigned agent m. Every agent= Pxi,aadopt policy i,amaximize total expected reward groupxi,aagents.Running Example: Optimizing Predetermined Phase-Switching Schedule.Returning running example (Section 4.1), see whether total expected reward improved resources reallocated execution. Let us saypredetermined schedule says resources redistributed times 1, 3, 6, 8,decomposing example problems time horizon four phases roughly equal duration.Formulating solving M-RMP problem Eq. 9 yields sequential allocation depicted Figure 11. Compared one-shot distribution (Section 4.2, Figure 10), agent 2longer idles entire horizon, total expected reward increases 65.04, 31%higher attained one-shot allocation.4.6 Determining Optimal Resource Reallocation ScheduleWithout predetermined resource reallocation schedule, agents free (within constraints) determine reassign resources achieve remaininggoals better. (Section 4.3), given inputs M, , C, R, M-RMP optimization454fiResource-Driven Mission-Phasing Techniques11111222221112224356781122910Figure 11: Optimal sequential resource allocation four predefined phases.problem find optimal resource reallocation schedule (subject resource reallocation constraints R), find optimal resource allocation among agents (subjectresource constraints C) within phase, well derive optimal executable phasepolicies agent. complexity problem limitations straightforwardapproaches solving described Section 4.4.instead extend MILP Eq. 9 also reason problem decomposition.extension shown Eq. 10, (probability conservation) constraints unchangedEq. 9 omitted. model constraints total resource reallocation costsoccurrences resource-reallocation events, new formulation represents resource constraints time step (instead phase), introduces supplementary constraintsmodel phase transitions.XXXmaxxm(10)i,a ri,asubject to:probability conservation constraints (unchanged)resource constraints:XXm,tumo,a,i xi,aX: t, m,iStm,t=m,t: o,{0, 1}: t, m,reallocation constraints:m,t1m,t: o, > 1,t=1 = 1X{0, 1}:, xm , um , , definitions before. represents setri,ai,ao,a,iindicateswhetherresourcestates associated time t. New binary variable m,t455fiWu & Durfee21111222231112221122145678910Figure 12: Optimal sequential resource allocation four phases without predefined schedule.assigned agent time t, resource constraints guarantee total amountallocated resources must equal total amount available resources time point.model cost constraints resource reallocation, Eq. 10 introduces new binaryvariables represent whether resources redistributed time t. sidestepquestion default resource allocation might be, assumed resourcesalways initially allocated beginning execution, i.e., t=1 = 1. Notem,tom,t1 never greater one since m,tom,t1 binary valuesm,t1m,tthus points must one agent{0, 1} ; constraintprocures different resource time compared time 1. words, resourcereassignmenttime lead = 1, means use constraintPlimit total cost resource reallocation.definition, one-to-one mapping possible sequential resource allocations possible integer solutions. addition, given particular sequential resourceallocation, MILP would reduced linear program whose solution space equivalentexecutable policy space (because resource constraints would prune unexecutable actions). words, MILP solution space includes best way allocating resourcestogether best way utilizing allocated resources, finding optimalsolution MILP equivalent finding optimal way sequentially allocatingutilizing resources.Running Example: Optimizing Fixed Number Phase-Switching Times.Consider happens agents determine set reallocation timesgiven upper bound four size set, i.e., t=1 = 0, t6=1 = 1, = 3.Using Eq. 10, optimal schedule reallocate resources computed {1, 4, 5, 8}. Figure 12depicts detailed allocation. schedule gives high priority allots sufficient timeagents accomplish high-reward tasks (i.e., task 3 agent 1, task 1 agent2). result, total expected reward two agents increases 72.25,11.1% higher fixed set 4 reallocation times evenly spaced(Section 4.5, Figure 11), 45.5% higher one-shot case (Section 4.2, Figure 10).456fiResource-Driven Mission-Phasing Techniques4.6.1 Variation: Maximizing Total Reward, Accounting CostS-RMP problem (Section 3.4.1), consider variation M-RMP problemneither resource-reallocation schedule predefined (Section 4.5) numbertimes reallocating resources restricted (Section 4.6), rather cost incurredtime resources reallocated cost calibrated utility MDPpolicy. Thus optimization problem maximize total expected reward, accountingcosts redistributing resources execution.begin examining binary-cost case where, resource reallocation scheduledtime t, charge group agents constant fee regardless resourcesmany redistributed time. general, coping binaryreallocation costs relatively easy Eq. 10 paved way characterize timesteps resource reassignments.Eq. 11 shows changed components solutionalgorithmproblem,comparedPP PP,rEq. 10. Eq. 11 adopts new objective function xmi,ai,aPremoves constraint longer applicable since agentsreallocate resources frequently desire.XXXXmaxxm(11)i,a ri,asubject to:probability conservation constraints (unchanged)resource constraints (unchanged)reallocation (cost) constraints:m,t1m,t: o, > 1,t=1 = 1{0, 1}:Next consider difficult variation cost incurred redistributingresources based amount resources transferred among agents. Sinceassumed agents cooperative, matter agent involvedexchange pays resource transfer costs. Without loss generality, let us say agentobtains one unit resource time someone else,pays cost cm,tagent releasing resource pays cost.used represent whether resource currently held agent timebefore, m,tt. cost agent pay getting resource time representedm,tm,t1cm,t) function (z) piecewise linear function, defined as:(oz z>0(z) =0 otherwisepiecewise linear constraint equivalently represented using multiple linear constraints introducing continuous variables m,t. new MILP formulation shownEq. 12, groups changed constraints compared Eq. 10 shown.XXXXXXm,txmmaxcm,t(12)i,a ri,a457fiWu & Durfee21111222231111122222145678910Figure 13: Optimal sequential resource allocation, given transfer cost 5 per unit.subject to:probability conservation constraints (unchanged)resource constraints (unchanged)reallocation (cost) constraints:m,t=1= m,t=1: o,m,t1m,tm,tm,t: o, > 1,0: o, t,om,t1 .m,t0 m,tconstrained m,tis, > 1, m,tm,tm,tm,t1m,tm,t1words, 1 >(i.e., = 1,= 0), m,t0Pundercircumstances.NoteobjectivefunctionEq.12maximizeP P P m,t m,tP P P m,t m,tP Pcoco , implying second termxi,a ri,asmall possible optimal solution yields highest expected utility.m,tis, m,t= 1reach lower bound optimal solution Eq. 12, i.e.,m,tm,t1m,t>(i.e., agent acquires resource time t) = 0 otherwise,represent piecewise linear costexactly matches expectation using m,tm,t1function (m,t).Running Example: Optimizing Total Reward Accounting Cost. Consideralgorithm manages transfer resources transfer incurs costrunning example problem Section 4.1. transferring one unit resource costs5, optimal sequential resource allocation, shown Figure 13, transferfour units resources entire execution (two units initial time 1, one unittime 4, one unit time 5). surprisingly, transfer cost increases, amountresources transferred decreases, vice versa.Table 2 compares resulting schedule schedules derived previous sections,incorporating cost 5 resource transfer. expected, algorithmEq. 12 yields reallocation schedule highest utility, 48.72.4.7 Experimental Evaluationanalyzed computational complexity M-RMP problem Section 4.4; here,empirically evaluate effectiveness computational efficiency MILP-based solution458fiResource-Driven Mission-Phasing TechniquesCaseone-shot (Figure 10)4 fixed times (Figure 11)3 added times (Figure 12)unlimited times balancing cost (Figure 13)Total Resource (Re)Assignments2754Utility39.6430.0447.2548.72Table 2: Comparison resource reallocation schedules example problem, giventransfer cost 5 per unit.algorithms developed section, using grid world environment similar usedS-RMP evaluation Section 3.5.144.7.1 Experimental Setuptest problem instance includes cooperative agents agent operatesnn grid world independent others. starting location agent alwayscenter grid world.15 objective group agents maximize totalexpected reward within time steps. Like single-agent test problems (Section 3.5),grid world generated, 40% locations randomly chosen walls, 10%randomly chosen task locations. rewards tasks randomly set, i.e.,ith task (in random order) given reward i.task temporally constrained release time deadline. release timetime step task becomes available, i.e., attempting taskreturn zero reward. deadline task becomes unavailable, i.e., finishingtask also return zero reward. temporal constraints randomly set.tasks release time integer uniformly randomly selected range [1, 2]time horizon, deadline always three time steps later. Thus, tasktime window [ti , ti + 3) ti random integer [1, 2]. task repeatedmultiple times (and time give reward) within time window.action space agent {wait, up, left, down, right, safe-up, safe-left, safe-down,safe-right, do}. actions except action exactly definitions(Section 3.5). resource prerequisite action also before,outcome longer always terminates execution immediately. Instead, terminatesprobability 0.05, otherwise agent stays location (with probability 0.95)repeat task move another task time horizon reached.change makes test problems interesting complex, since agent usesresources throughout experiment rather completing first task.system constrained resource limitations. |O| different resource typessystem. Further, one instance resource type, sharedagents.14. empirical evaluation domain problems similar (but complex than) runningexample used section (Figure 8) found work Wu Durfee (2007a).15. Starting center makes problem interesting challenging starting corner, allowingagent potentially visit larger fraction grid world sooner.459fiWu & Durfee255 optimal phasesaverage reward205 fixed phases15nonphasing10502345678910number agentsFigure 14: Exploiting fixed phases increases reward, finding optimal phasesincreases reward.4.7.2 Improvements Solution QualityFigure 14 demonstrates improvement sequential resource allocation approachesprior one-shot resource allocation approach. x-axis figure representsnumber agents world, y-axis specifies total expected rewardgroup agents.16 parameters set follows: = 10, n = 5, |O| = 5.see that, taking account resource reallocation opportunities execution,agents gain considerably higher reward. example, case five fixedresource (re)allocation times (one initial time step four randomlyuniformly selected test problem defined) available midst execution,mission-phasing approach, using Eq. 9 denoted 5-fixed-phases, average achievesreward 50% higher exploiting resource-reallocation opportunities.also see (as expected) finding using optimal resource-allocation phaseswitching time points improve system performance, e.g., 5-optimal-phasesapproach (using Eq. 10 assuming four additional phase-switching points besidesone initial time step created) achieves average reward 20% higheraforementioned 5-fixed-phases solution.Another interesting observation Figure 14 improvement sequential resource allocation one-shot resource allocation increases number agents increases.because, given number resources fixed 5, agents are,scarcer resources are. Hence, assigning resource right agent righttime becomes increasingly important performance constrainedness systemincreases.Figure 15 uses parameters Figure 14 (i.e., = 10, n = 5, |O| = 5),holds number agents constant = 5, shows much better agentschoose phase-switching times (Eq. 10) number phase-switching times16. section, average data point computed 20 random test problems.460fiResource-Driven Mission-Phasing Techniques25average reward2015105012345678910number phasesFigure 15: reward increases phase-switching cost limit (that determines number phases) increases.allowed rises. However, note that, unlike S-RMP optimization problem, even agentsreallocate resources every time step, usually cannot achieve rewardunconstrained case unlimited resources (which reward 37.2 averagetest problems). because, time step, agents might ableacquire desired resources simply enough resourcesgo around.4.7.3 Computational Efficiencyunderstand impact number phases computational cost choosehard M-RMP test problems computational efficiency evaluation follow,run experiments parameters Figure 15, collect examine resultsaverage runtime finding exact solutions test problems. shown Figure 16,MILP-based solution approach exploit over-constrainedness (when number phasessmall) under-constrainedness (when number phases large) improve efficiency.complexity profile indicates average, parameter settings, problemsdifficult constrained 3 phases (that = 2 usual t=1 = 0).experiments follow, one parameter varied time others retaindefault settings, variations create larger complex instances usedgenerate Figure 16. Hence, phase-switching cost limit default set 3 avoidsimpler over-constrained problems.compare MILP-based algorithm (Eq. 10) WDP-based algorithm (usingauction-based resource allocation strategy), computationally-efficientapproach among three prior related approaches discussed Section 4.4. RecallWDP-based algorithm involves two steps. First, agent submits valuations possible1sequential resource allotments central agent. number bids CK1(2)|O|K (asexplained Section 4.4). Second, central agent solves winner determination problem.461fiWu & Durfee70runtime (seconds)605040302010012345678910number phasesFigure 16: runtime increases decreases number times resourcereallocation increases.Let us assume central agent perfect filtering method (although usuallynot), needs consider evaluate valid combinations bids.11assumption reduces number possible combinations (CK1(2)|O|K )m CK1(m)|O|K base exponentiation (m)|O|K differentways allocate one resource among agents.However, even enhancement, WDP-based algorithm still computationallyintractable moderately complex M-RMP problems (where often cannot find exactsolution within 100 hours cpu time). Note lower bound running time11(2)|O|K tbid +CK1(m)|O|K tevalWDP-based algorithm approximated CK1tbid average runtime evaluating sequential resource allotment (i.e., bid)modeling solving unconstrained finite-horizon MDP, teval average runtimeevaluating feasible combination agents bids. work uses sampling methodestimate runtime, i.e., tbid teval estimated 100,000 random runs.Figure 17 compares average runtime results various parameter settings.17 Notey-axis logarithmic scale. results illustrate emphasizeMILP-based algorithm, formulates simultaneously solves coupled problemsmission decomposition, resource allocation, policy formulation using single compactMILP formulation, effectively fruitfully exploit inter-relationships amongcomponent problems. result, significantly faster WDP-based approachconsiders component problems isolation.4.8 Summarysection, presented, analyzed, empirically evaluated MILP-based approach automates process finding using optimal resource reallocation schedules17. Neither MILP WDP uses parallel computation.462fiResource-Driven Mission-Phasing Techniques151510WDPbasedMILPbasedruntime (seconds)runtime (seconds)101010510010WDPbasedMILPbased1010510024681010number phases158101510WDPbasedMILPbasedruntime (seconds)runtime (seconds)6number resource types1010105100104WDPbasedMILPbased101051006810121014horizon46810number agentsFigure 17: Runtime comparison MILP-based algorithm WDP-based algorithm. Parameters set follows: Top-left figure n = 5, = 10, = 5,|O| = 5, = {1, 2, ..., 9}. Top-right figure n = 5, = 10, = 5,|O| = {4, 5, ..., 10}, = 3. Bottom-left figure n = 5, = {6, 7, ..., 14},= 5, |O| = 5, = 3. Bottom-right figure n = 5, = 10, = {3, 4, ..., 10},|O| = 5, = 3.463fiWu & Durfeegroup agents operating complex environments resource limitationsuncertainties. analytical experimental results shown approachgreatly reduce computational cost compared prior approaches.5. Related Workresource-driven mission phasing (RMP) problem involves three intertwined componentproblems: mission (problem) decomposition, resource configuration, policy formulation.component problems studied wide variety research fields.combinations two also gained much attention recent years. sectiongives overview related work, discusses prior approaches directlyapplicable RMP problem interest paper.presented Section 3.1 Section 4.3, RMP problems defined extending unconstrained MDP model include resource constraints phase-switchingconstraints. organization section follows way definition. beginsdiscussion policy formulation techniques, followed discussion resource configuration techniques. reviews problem decomposition techniques combinationspolicy formulation and/or resource configuration work. section concludesdiscussion mode-transition research related work fit clearlyprevious categories.5.1 Policy Formulation.well-known Markov decision process described Section 2.1. formulatingsequential decision-making problem MDP model, number efficient (polynomialtime) solvers, value iteration policy iteration algorithms, usedcompute optimal policy (Puterman, 1994).However, directly applying algorithms resource-constrained systems,resource-driven mission-phasing problem, typically involves incorporating resource featuresMDP state representation (and actions conditioned resource availability),result exponential increase size state space (Meuleau et al.,1998), i.e., well known curse dimensionality challenge. shown empirical results (Section 3.5.3) exponential-size state space result computationalinefficiency.5.2 Resource Configuration.domains impossible (or expensive) resolve resource constraintsmodifying agents physical architecture (for example, adding another battery robotalready deployed Mars), improving performance constrained agent limited architecture active subject recent years, i.e., class bounded optimality problems (Russell, 2002). Cooperative Intelligent Real-Time Control Architecture(CIRCA) one research effort (Musliner, Durfee, & Shin, 1993, 1995). CIRCA usessimple greedy, myopic approach compute feasible policies. starts buildingoptimal unconstrained policy without worrying real-time requirements,greedily repairs policy executable real-time system.464fiResource-Driven Mission-Phasing Techniquessurprisingly, (fast) greedy approach adopted CIRCA might result suboptimal policies cannot fully utilize agents capacity. Several recent studiesproposed alternative algorithms searching policy executable within agentcapacity constraints optimizes expected (possibly discounted) reward accruedentire agent execution. example, Altman (1998) adopted Lagrangian dualLP approach solve constrained MDPs total cost criteria. Feinberg (2000) analyzedcomplexity constrained discounted MDPs. particular relevance workpaper study strongly-coupled resource allocation policy formulation problemsDolgov Durfee (2006). approach implements simultaneous combinatorial optimization stochastic optimization via reduction mixed integer linear programming,recapped Section 2.2. However, prior studies constrained agentsbased upon assumption agents limited capacity configured resourcesprocures prior execution cannot reconfigured plan execution.5.3 Problem Decomposition.literature stochastic planning, number decomposition algorithmsproposed speed planning process. discovery recurrent classes MDPsone decomposition strategy, find exact state space decompositionenvironment uncertainties (Puterman, 1994; Boutilier, Dean, & Hanks, 1999).recurrent class represents special absorbing subset state space, meansagent enters recurrent class remains forever matter policy adopts.Puterman (1994) suggested variation Fox-Landi algorithm (Fox & Landi, 1968)discover recurrent classes. discovery recurrent classes, MDP solverderive optimal overall policy building optimal policy recurrent classindependently constructing solving reduced MDP consisting transientstates (i.e., removing recurrent classes MDP).course, application problems exactly decomposed independent subproblems. However, many composed multiple weakly-coupled sub-problemsnumber states transitions connecting two neighboring sub-problems relatively small. number heuristic decomposition methods designed exploitweakly-coupled relationships. example, robot navigation domain (Parr, 1998;Precup & Sutton, 1998; Lane & Kaelbling, 2001), doorways (or similar connection structures,bridges) used break large environment blocks states, e.g., one blockroom. Two neighboring blocks connected small number doorwaystates. weakly-coupled state space decomposed several pieces,methods used efficiently build overall policy based upon sub-problem policies. One common method let sub-problem iteratively exchange informationneighboring sub-problems, repeatedly revise sub-policy (if necessary) based uponupdated knowledge utilities values neighbors overall (approximately)optimal solution derived (Dean & Lin, 1995).Besides application stochastic planning, decomposition techniques alsoshown beneficial resource management many realistic application domains. Several resource allocation algorithms developed problem allocating setheterogeneous resources availability constraints maximize given utility function (Wu& Castanon, 2004; Palomar & Chiang, 2006; Reveliotis, 2005). example, Wu Cas465fiWu & Durfeetanon (2004) presented approximate solution algorithm using decomposition combineddynamic programming, experimental results showed algorithm producesnear-optimal results much reduced computational effort.addition Artificial Intelligence (AI) techniques discussed above, decompositiontechniques, often integrated hierarchical control (also called multilevel controlliterature), received much attention recent years Operations Research,Operations Management, Systems Theory, Control Theory, several fields (Sethi,Yan, Zhang, & Zhang, 2002; Antoulas, Sorensen, & Gugercin, 2001; Xiao, Johansson, & Boyd,2004; Phillips, 2002; Teneketzis, Javid, & Sridhar, 1980). Many manufacturing systemslarge complex; management systems requires recognizing reactingwide variety events could deterministic stochastic. Obtaining exact optimalpolicies run systems often difficult theoretically computationally.exploiting fact real-world systems often characterized several decision subsystems, e.g., company consists departments marketing, production, personnel,on, one popular way deal computational complexity challenge developmethods hierarchical decision-making systems. fundamental ideasreduce overall complex problem multiple smaller, manageable sub-problems, solvesub-problems, coordinate solutions sub-problems overall systemobjectives constraints satisfied (Sethi et al., 2002).summarize, well established utilizing decomposition greatly reduce computational costs many situations. However, aforementioned prior decompositiontechniques directly applicable RMP optimization problem. underlyingreason decomposition points good reducing computational effortsnecessarily (and possibly completely unrelated to) optimal points constrained agentsreconfigure resources. worth emphasizing RMP decomposition tackles capacityconstraints instead computation time constraints. Indeed, general, mission decomposition RMP solution reduce computational requirementspolicy one phase usually optimized respect policies plannedpossible subsequent phases.5.4 Mode Transition.Finally, important distinguish resource-driven mission-phasing researchmode-transition research implemented fields Operations Research ControlTheory (Schrage & Vachtsevanos, 1999; Wills, Kannan, Sander, Guler, Heck, Prasad, Schrage,& Vachtsevanos, 2001; Karuppiah, Grupen, Hanson, & Riseman, 2005). first glance,two research fields lot common: work transitions one subproblem another, take account resource reconfigurations. However,pointed emphasize distinct aspects, applicable different applicationdomains.First all, mode-transition approach, operational modes usually tightly associated explicit actions (e.g., hover fly-forward modes helicopter exampledescribed Schrage & Vachtsevanos, 1999), corresponding particular states (e.g.,sleep, search, seed, final modes defined Bojinov, Casal, & Hogg, 2002), characterizedexplicit purposes (e.g., passing narrow tunnel traversing roughterrain requires self-reconfiguring robot adjust shape achieve goal better, Rus466fiResource-Driven Mission-Phasing Techniques& Vona, 2001). contrast explicit definition representation modes modetransition research, phases RMP problem usually much difficult identify.phasing information hidden MDP model, finding optimal phases usuallychallenging task.Second, mode-transition research, mode transition resource reconfigurationoften triggered real-time events, e.g., responding unexpected disastrous eventreconfiguring resources fault toleration (Drozeski, 2005). contrast, resourcedriven mission-phasing study assumes decision-making agent complete informationenvironment prior execution, one main objectives findoptimal points reconfiguring resources capacity usage. is, phase switchingRMP choice agent instead reactive response exogenous event.specifically, RMP techniques presented paper utilize sequential decision-makingidentify optimal resource reconfiguration policy switching states. emphasizereconfigure resources switch policies agent(s) would (or would lesslikely to) enter predicament encountering undesirable events, instead studyingreconfigure resources real-time respond unexpected event.Finally, much prior mode-transition research, particularly Control Theory literature,investigates perform smooth functional transition among modes, workpaper simply assumes aggregate resource (re)configuration actions,sequence primitive actions arranging resources. paperaddress details agents mechanically implement mode-transition resourcereconfiguration actions.6. Conclusionwork paper designed, analyzed, evaluated suite computationally efficientalgorithms automatically identify utilize resource reconfiguration opportunitiesresource-constrained environments. analytical experimental results illustratedemphasized mission phasing approach, incorporating problem decomposition,resource allocation, policy formulation, help constrained agents judiciously effectively exploit resource reconfiguration opportunities improve performance.section concludes paper summary main contributions workdiscussion several promising future research directions.6.1 Summary Contributions. work explicitly took account known opportunities midst executionreconfigure resources switch policies, designed computationally efficient algorithms (including abstract MDP algorithm single-agent resource reconfigurationproblems MILP-based algorithm multiagent resource reallocation problems)optimize use fixed opportunities complex stochastic systems. empirical results (Figure 4 Figure 14) confirmed exploiting phase-switchingopportunities considerably improve performance, particularly tightly constrainedsystems (the reward doubles test cases).. extension utilizing fixed phase-switching opportunities, Section 3.4 (for singleagent systems) Section 4.6 (for multiagent systems) presented MILP-based algo467fiWu & Durfeerithms able automate process finding using mission phasesstochastic, constrained systems, eliminates need phasespredefined, also avoids potential sub-optimality caused phases improperlypredefined.. automated resource-driven mission-phasing algorithms presented workcomputationally efficient. capturing whole mission-phasing problem compact mathematical formulation simultaneously solving coupled problemsmission decomposition, resource allocation, policy formulation, presentedalgorithms effectively exploit problem structure, results significant reduction computational cost comparison approach considers missiondecomposition, resource allocation, policy formulation isolation (e.g., reductionhours seconds shown Figure 17).. Unlike much prior work agents reactively (and often greedily) reconfigure resources exogenous events occur, work, based upon Markov decision processessequential decision-making theory, proactively determine optimally utilize resource reconfiguration opportunities. provides new computationally efficientresource-reconfiguration mechanism resource-constrained environments.6.2 Future WorkAlthough paper presented suite algorithms improve agent performance constrained stochastic systems, still much interesting work remaining. Below, pointpromising research directions overcome limitations workpresented paper.. Resource Constraints Time LimitationsResource-driven mission-phasing problems NP-complete. Although solution approaches designed work exploit problem structure reduce computationalcost, finding exact solution complex RMP problem might still difficult, particularly time-limited environments. One approach handling problemsadopt approximate methods. preliminary investigations developing anytimealgorithms solving problems resource constraints time limitationsshown promise (Wu, 2008) work remains area, including comparingmethods grounded RMP concepts heuristic greedy techniques allocating resources agents.. Flexible Resource Reallocation Optionswork discussed paper assumed clear delineation two kindsstates: states resources (re)allocated way desired (phase-switchingstates) states resource allocations cannot change. generally, mightcase states could exist limited resource reallocations could occur (e.g., partially filled toolbox, subset agents swapresources), leading challenging reasoning problems agents decidestates seek avail of. Further, agent could even potentially468fiResource-Driven Mission-Phasing Techniquescreate state fly dropping resources well-chosen stategainfully retrieved (perhaps another agent) future time. Obviously, problemsget increasingly complicated kinds ways, modeling resources part stateincorporating actions picking dropping resources becomes important,leading MDP-based solution techniques described paper (e.g., Sections 3.23.5.3). Finding methods kind flexibility without incurringcosts MDP-based techniques challenging direction future work.. Resource Reallocation Decentralized MDPslimiting assumption made work that, resource reallocation scheduled, participant agents always able successfully redistribute resources amongscheduled time, regardless state features valuesare. plan relax assumption future consider sequential resourceallocation problems additional constraints agents ableexchange resources. example, physical agents might able exchangeresources location time. Or, another example, task might interruptible started, means mayimpossible reassign resources used task task completed.Decentralized MDPs one possible way solve problems. preliminary work (Wu & Durfee, 2006), included paper, developedMILP-based algorithm solving transition independent Dec-MDPs. work linkedDec-MDP formulation MILP formulation, pointed one waycharacterize resource constraints MILP formulation. future, digdeeper direction.. Application Evaluation Settingswork far focused testing techniques problems small enoughsolve using slower standard approaches (to confirm techniques optimal)generated spaces problems allow us probe efficacy techniquessettings vary controlled ways. Applying techniques extensiverealistic domains important avenue follow identify strengthsweaknesses better. example application particularly interested in,prompted work early stages, intelligent real-time control. SystemsCIRCA (Musliner et al., 1993, 1995) use AI techniques construct real-time controlplans composed set sense-act tasks scheduled frequenciesensure safe operation. Often, desired sense-act tasks cannot fitschedule, important combination tasks must chosen. applicationscontrolling unmanned aircraft (Atkins, Abdelzaher, Shin, & Durfee, 2001),different combinations might better different phases activity (takeoff, cruising,landing, etc.). Similarly, formation aircraft, aircraft responsibledetecting reacting particular event shift time progresses mission(Musliner, Goldman, & Krebsbach, 2005). prior work used heuristic, localsearch techniques find good solutions phasing problems, techniquespaper potential finding optimal mission decompositions.469fiWu & DurfeeAcknowledgmentsmaterial based upon work supported part DARPA/IPTO COORDINATORsprogram Air Force Research Laboratory Contract No. FA875005C0030,Air Force Office Scientific Research Contract No. FA9550-07-1-0262.views conclusions contained document authors,interpreted representing official policies, either expressed implied, DefenseAdvanced Research Projects Agency, Air Force, U.S. Government.authors thank Dmitri Dolgov three anonymous reviewers helpfulsuggestions comments, Stefan Witwicki Jim Boerkoel help proofreading article.ReferencesAltman, E. (1998). Constrained Markov decision processes total cost criteria: Lagrangeapproach dual LP. Methods Models Operations Research, 48, 387417.Antoulas, A. C., Sorensen, D. C., & Gugercin, S. (2001). survey model reduction methodslarge-scale systems. Contemporary Mathematics, 280, 193220.Atkins, E. M., Abdelzaher, T. F., Shin, K. G., & Durfee, E. H. (2001). Planning resourceallocation hard real-time, fault-tolerant plan execution. Autonomous AgentsMulti-Agent Systems, 4 (1-2), 5778.Becker, R., Zilberstein, S., Lesser, V. R., & Goldman, C. V. (2004). Solving transition independent decentralized Markov decision processes. Journal Artificial IntelligenceResearch, 22, 423455.Bellman, R. (1957). Markov decision process. Journal Mathematical Mechanics, 6,679684.Bererton, C. A., Gordon, G. J., & Thrun, S. (2003). Auction mechanism design multi-robotcoordination. Advances Neural Information Processing Systems, pp. 879886.Bernstein, D. S., Zilberstein, S., & Immerman, N. (2000). complexity decentralized control Markov decision processes. Proceedings 16th Conference UncertaintyArtificial Intelligence, pp. 3237.Bojinov, H., Casal, A., & Hogg, T. (2002). Multiagent control self-reconfigurable robots.Artificial Intelligence, 142, 99120.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research, 11, 194.Cook, W., Cunningham, W., Pulleyblank, W., & Schrijver, A. (1998). Combinatorial Optimization. John Wiley & Sons, New York.De Vries, S., & Vohra, R. (2003). Combinatorial auctions: survey. INFORMS JournalComputing, 15 (3), 284309.Dean, T., & Lin, S. H. (1995). Decomposition techniques planning stochastic domains.Proceedings 14th International Joint Conference Artificial Intelligence, pp.304309.470fiResource-Driven Mission-Phasing TechniquesDolgov, D. A. (2006). Integrated Resource Allocation Planning Stochastic MultiagentEnvironments. Ph.D. thesis, Computer Science Department, University Michigan.Dolgov, D. A., & Durfee, E. H. (2005). Computationally-efficient combinatorial auctionsresource allocation weakly-coupled MDPs. Proceedings 4th InternationalJoint Conference Autonomous Agents Multiagent Systems, pp. 657664.Dolgov, D. A., & Durfee, E. H. (2006). Resource allocation among agents MDP-inducedpreferences. Journal Artificial Intelligence Research, 27, 505549.Drozeski, G. R. (2005). Fault-Tolerant Control Architecture Unmanned Aerial Vehicles.Ph.D. thesis, Georgia Institute Technology.Earl, M., & DAndrea, R. (2005). Iterative MILP methods vehicle control problems. IEEETransactions Robotics, 21 (6), 11581167.Feinberg, E. (2000). Constrained discounted Markov decision processes Hamiltoniancycles. Mathematics Operations Research, 25, 130140.Fox, B., & Landi, D. M. (1968). algorithm identifying ergodic subchainstransient states stochastic matrix. Communications ACM, 2, 619621.Goldman, C. V., & Zilberstein, S. (2004). Decentralized control cooperative systems:Categorization complexity analysis. Journal Artificial Intelligence Research, 22,143174.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithmsfactored MDPs. J. Artif. Int. Res., 19 (1), 399468.Kallenberg, L. (1983). Linear Programming Finite Markovian Control Problems. Mathematisch Centrum, Amsterdam.Karuppiah, D., Grupen, R., Hanson, A., & Riseman, E. (2005). Smart resource reconfigurationexploiting dynamics perceptual tasks. IEEE/RSJ International ConferenceIntelligent Robots Systems, pp. 1513 1519.Kautz, H., & Walser, J. (2000). Integer optimization models AI planning problems. Knowledge Engineering Review, 15(1), 101117.Kim, K.-E., & Dean, T. (2001). Solving factored MDPs via non-homogeneous partitioning.IJCAI01: Proceedings 17th international joint conference Artificial intelligence, pp. 683689.Lane, T., & Kaelbling, L. P. (2001). Toward hierarchical decomposition planninguncertain environments. Proceedings 2001 IJCAI Workshop PlanningUncertainty Incomplete Information, pp. 17.Lehman, T. J., & Carey, M. J. (1986). study index structures main memory databasemanagement systems. Proceedings 12th International Conference LargeData Bases, pp. 294303.Lesser, V., Decker, K., Wagner, T., Carver, N., Garvey, A., Horling, B., Neiman, D., Podorozhny, R., Prasad, M. N., Raja, A., Vincent, R., Xuan, P., & Zhang, X. (2004). Evolution GPGP/TAEMS domain-independent coordination framework. AutonomousAgents Multi-Agent Systems, 9 (1), 87143.471fiWu & DurfeeMeuleau, N., Hauskrecht, M., Kim, K.-E., Peshkin, L., Kaelbling, L. P., Dean, T., & Boutilier,C. (1998). Solving large weakly coupled Markov decision processes. Proceedings15th National Conference Artificial Intelligence, pp. 165172.Musliner, D. J., Durfee, E. H., & Shin, K. G. (1993). CIRCA: cooperative intelligent realtime control architecture. IEEE Transactions Systems, Man, Cybernetics, 23 (6),15611574.Musliner, D. J., Durfee, E. H., & Shin, K. G. (1995). World modeling dynamicconstruction real-time control plans. Artificial Intelligence, 74 (1), 83127.Musliner, D. J., Goldman, R. P., & Krebsbach, K. D. (2005). Deliberation scheduling strategiesadaptive mission planning real-time environments. Anderson, M., & Oates, T.(Eds.), Metacognition Computation, Vol. SS-05-04 AAAI Technical Report, pp.98105. AAAI Press.Palomar, D., & Chiang, M. (2006). tutorial decomposition methods network utilitymaximization. IEEE Journal Communications, 24 (8), 1439 1451.Parr, R. (1998). Flexible decomposition algorithms weakly coupled Markov decision problems. Proceedings 14th Conference Uncertainty Artificial Intelligence, pp.422430.Pekec, A., & Rothkopf, M. (2003). Combinatorial auction design. Management Science,49 (11), 14851503.Phillips, A. (2002). Functional decomposition vehicle control system. Proceedings2002 American Control Conference, pp. 37133718.Precup, D., & Sutton, R. (1998). Multi-time models temporally abstract planning. Advances Neural Information Processing Systems, 10, 10501056.Puterman, M. L. (1994). Markov Decision Processes. John Wiley & Sons, New York.Reveliotis, S. A. (2005). Real-Time Management Resource Allocation Systems: DiscreteEvent Systems Approach. Springer-Verlag New York.Rus, D., & Vona, M. (2001). Crystalline robots: Self-reconfiguration compressible unitmodules. Autonomous Robots, 10 (1), 107124.Russell, S. (2002). Rationality intelligence. Elio, R. (Ed.), Common Sense, Reasoning,Rationality. Oxford University Press, USA.Sacco, G., & Schkolnick, M. (1982). mechanism managing buffer pool relationaldatabase system using hot set model. Proceedings 8th International ConferenceLarge Data Bases, 257262.Schrage, D., & Vachtsevanos, G. (1999). Software-enabled control intelligent UAVs. Proceedings 1999 International Symposium Computer Aided Control System Design,pp. 528532.Sethi, S. P., Yan, H., Zhang, H., & Zhang, Q. (2002). Optimal hierarchical controls dynamic stochastic manufacturing systems: survey. Manufacturing & Service OperationsManagement, 4 (2), 133170.472fiResource-Driven Mission-Phasing TechniquesSutton, R., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: frameworktemporal abstraction reinforcement learning. Artificial Intelligence Journal, 112,181211.Sutton, R., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press, Cambridge, MA.Teneketzis, D., Javid, S. H., & Sridhar, B. (1980). Control weakly-coupled Markov chains.Proceedings 1980 19th IEEE Conference Decision Control includingSymposium Adaptive Processes, pp. 137143.van Beek, P., & Chen, X. (1999). CPlan: constraint programming approach planning.Proceedings 16th National Conference Artificial Intelligence, pp. 585590.Vossen, T., Ball, M., Lotem, A., & Nau, D. (1999). use integer programming modelsAI planning. Proceedings 16th International Joint Conference ArtificialIntelligence, pp. 304309.Wagner, T., Phelps, J., Guralnik, V., & VanRiper, R. (2004). application view COORDINATORS: Coordination managers first responders. AAAI, pp. 908915.Wagner, T., Raja, A., & Lesser, V. (2006). Modeling uncertainty implicationssophisticated control TAEMS agents. Autonomous Agents Multi-Agent Systems,13 (3), 235292.Wills, L., Kannan, S., Sander, S., Guler, M., Heck, B., Prasad, J., Schrage, D., & Vachtsevanos,G. (2001). open platform reconfigurable control. Control Systems Magazine,IEEE, 21 (3), 4964.Wolsey, L. A. (1998). Integer Programming. John Wiley & Sons, New York.Wu, C., & Castanon, D. (2004). Decomposition techniques temporal resource allocation.IEEE Conference Decision Control, pp. 3798 3803.Wu, J. (2008). Mission-Phasing Techniques Constrained Agents Stochastic Environments. Ph.D. thesis, University Michigan.Wu, J., & Durfee, E. H. (2005). Automated resource-driven mission phasing techniquesconstrained agents. Proceedings 4th International Joint Conference Autonomous Agents Multiagent Systems, pp. 331338.Wu, J., & Durfee, E. H. (2006). Mixed-integer linear programming transition-independentdecentralized MDPs. Proceedings 5th International Joint Conference Autonomous Agents Multiagent Systems, pp. 10581059.Wu, J., & Durfee, E. H. (2007a). Sequential resource allocation multi-agent systemsuncertainties. Proceedings 6th International Joint Conference AutonomousAgents Multiagent Systems, pp. 760767.Wu, J., & Durfee, E. H. (2007b). Solving large TAEMS problems efficiently selectiveexploration decomposition. Proceedings 6th International Joint ConferenceAutonomous Agents Multiagent Systems, pp. 291298.Xiao, L., Johansson, M., & Boyd, S. P. (2004). Simultaneous routing resource allocationvia dual decomposition. IEEE Transactions Communications, 52 (7), 11361144.473fiJournal Artificial Intelligence Research 38 (2010) 569-631Submitted 12/09; published 08/10Cause Identification Aviation Safety Incident Reportsvia Weakly Supervised Semantic Lexicon ConstructionMuhammad Arshad Ul AbedinVincent NgLatifur Khanarshad@student.utdallas.eduvince@hlt.utdallas.edulkhan@utdallas.eduDepartment Computer ScienceErik Jonsson School Engineering & Computer ScienceUniversity Texas Dallas800 W. Campbell Road; MS EC31Richardson, TX 75080 U.S.A.AbstractAviation Safety Reporting System collects voluntarily submitted reports aviation safety incidents facilitate research work aiming reduce incidents. effectively reduce incidents, vital accurately identify incidents occurred.precisely, given set possible causes, shaping factors, task cause identification involves identifying shaping factors responsibleincidents described report. investigate two approaches cause identification.approaches exploit information provided semantic lexicon, automatically constructed via Thelen Riloffs Basilisk framework augmented linguisticalgorithmic modifications. first approach labels report using simple heuristic, looks words phrases acquired semantic lexicon learningprocess report. second approach recasts cause identification text classification problem, employing supervised transductive text classification algorithmslearn models incident reports labeled shaping factors using modelslabel unseen reports. experiments show heuristic-based approachlearning-based approach (when given sufficient training data) outperform baselinesystem significantly.1. IntroductionSafety paramount importance comes aviation industry. 2007 alone,4659 incidents1 , including 26 fatal accidents 750 casualties2 . improveaviation safety situation, Aviation Safety Reporting System (ASRS) established1976 make safety incident data available researchers. ASRS collects voluntarily submitted reports aviation safety incidents written flight crews, attendants, controllersrelated parties. reports contain number fixed fields free text narrative describing incident. However, data grown quite large yearsgetting increasingly difficult, impossible, analyze reports humanmeans. become necessary reports analyzed automated means.1. http://asrs.arc.nasa.gov/2. http://www.flightsafety.gov/c2010AI Access Foundation. rights reserved.fiAbedin, Ng & Khantake full advantage data reduce safety incidents, necessary extractreports happened why. known, possibleidentify correlations incidents causes, take fruitful measurestoward eliminating causes. However, fixed fields reports devoted variousaspects happened incidents, fixed field indicatesincidents causes. Instead, reporter discusses report narrative thinkscaused incident, along incident description. Thus cause incidentextracted analyzing free text narrative. example, report shown nextillustrate task:Report#424362. descending lit encountered Instrument Meteorological Conditions; rime ice; rain; moderate chop. turnedheading Auto-Pilot direct lit attitude indicator remainedbank. XCHKING; noticed Radio Magnetic IndicatorS 55 degreeheadings. switched #2 corrected course. Auto-Pilot flightdirector kicked off. continued problems altitude selectAuto-Pilot attempted re-engage it. radar vectorsapproach descent 2300 feet noticed altitude 2000 feetMean Sea Level. stopped descent climbed 2300 feet Mean SeaLevel. Air Traffic Control noted altitude deviation time noticed.thankful backup time flight director problemscockpit. occurred end 13 hour crew day; bad weather; instrument problems; lack crew rest. First Officer (Pilot Flying)right seat; 4 hours rest due inability go sleepnight before. tired trip lit-ORL-lit. eaten7 hours.3Posse et al. (2005) identify 14 important cause types, shaping factors,influence occurrence aviation safety incident described ASRS report.shaping factors contextual factors influenced reporters behaviorincident thus contributed occurrence incident. factorsattributed humans (e.g., pilot flight attendant psychological Pressure,overly heavy Taskload, unprofessional Attitude impacts performance),related surrounding environment (e.g., Physical Environment snow,Communication Environment auditory interference). detailed description14 shaping factors found Section 2.1.report, find incident influenced three shaping factors,namely Physical Environment (which concerns bad weather, mentioned above), ResourceDeficiency (which concerns problems equipment), Duty Cycle (which refersphysical exhaustion due long hours duty without adequate rest replenishment).three shaping factors indicated different words phrases report.instance, bad weather condition expressed using phrases rime ice, rainmoderate chop, details equipment problem appear sentence fragments like3. improve readability, report preprocessed original form using steps describedSection 2.2.570fiCause Identification via Weakly Supervised Semantic Lexicon Constructionattitude indicator remained bank, 55 degree headings flight director problems.issue long hours duty illustrated sentence fragments like 13 hourcrew day tired trip. goal cause identification task aviationsafety domain, then, identify 14 shaping factors contributed incidentdescribed report using lexical cues appearing report narrative.However, mentioned earlier, sheer volume data makes prohibitiveanalyze reports manually identify associated shaping factors. Thus,focus research automated cause identification ASRS reports, involvesautomatically analyzing report narrative identifying responsible shaping factors.brings problem domain Natural Language Processing (NLP).Since set texts (i.e., report narratives) set possible labelstexts (i.e., shaping factors), task naturally cast text classificationtask. However, unlike topic-based text classification, cause-based text classificationaddressed extensively NLP community. Previous work causal analysis quitedifferent nature cause-based text classification task. specifically, previouscause analysis works involve text classification, focusing instead determiningexistence causal relation two sentences events. instance,work causal analysis question answering, question may involvecause(s) event (e.g., Kaplan & Berry-Rogghe, 1991; Garcia, 1997; Khoo, Chan, & Niu,2000; Girju, 2003). Here, focus finding causal relationship two sentencecomponents. another example, causal analysis equipment malfunction reportsattempted Grishman Ksiezyk (1990), whose work restricted analysisreports related one specific piece equipment studied. analyze cause-effectrelations events leading malfunction described reports.Cause identification aviation safety reports rather challenging problem,result number factors specific ASRS dataset. First, unlike many NLP problemsunderlying corpus composed set well-edited texts newspaperreports, reviews, legal medical documents4 , ASRS reports mostly writteninformal manner, since edited except removing author-identityinformation, reports tend contain spelling grammatical mistakes. Second,employ large amount domain-specific acronyms, abbreviations terminology. Third,incident described report may caused one shaping factor.Thus reports multiple shaping factor labels, making task challengingbinary classification, even multi-class problems instance onelabel. all, scarcity labeled data task, coupled highly imbalancedclass distributions, makes difficult acquire accurate classifier via supervised learning.Previous work cause identification ASRS reports done primarilyresearchers NASA (see Posse et al., 2005) and, knowledge, involved manualanalysis reports. Specifically, NASA brought together experts aviation safety,human factors, linguistics English language participate series brainstormingsessions, generated collection seed keywords, simple expressions templateexpressions related shaping factor. labeled reports shapingfactors looking related expressions report narrative. However,4. Recently, work started processing blogs, may grammatical either, blogstypically full domain-specific terminology.571fiAbedin, Ng & Khanmajor weakness associated approach: involves large amount human effortidentifying relevant keywords expressions, yet resulting list keywordsexpressions means exhaustive. Moreover, evaluated approach20 manually labeled reports. small-scale evaluation means satisfactoryjudged current standard NLP research. One contributions researchannotation 1333 ASRS reports shaping factors, serve standardevaluation dataset different cause identification methods compared.paper, investigate two alternative approaches cause identification,exploit information provided automatically constructed semantic lexicon.specifically, view large amount human involvement NASAs work,aim replace manual selection seed words bootstrapping approachautomatically constructs semantic lexicon. Specifically, motivated Thelen Riloffs(2002) Basilisk framework, learn semantic lexicon, consists set wordsphrases semantically related shaping factors, follows. Starting smallset seed words phrases, augment seeds iteration automaticallyfinding fixed number words phrases related seeds corpus addingseed list. importantly, however, propose four modificationsBasilisk framework potentially improve quality generated lexicon.first linguistic modification: addition using parse-based features (e.g., subjectverb verb-object features) Basilisk, employ features computedrobustly (e.g., N-grams). remaining three algorithmic modificationsBasilisk framework, involving (1) use probabilistic semantic similarity measure, (2)use common word pool, (3) enforcement minimum support maximumgenerality constraints words extraction patterns, favors additionfrequently-occurring content-bearing words disfavors overly-general extraction patterns.mentioned above, investigate two approaches cause identification exploitautomatically learned semantic lexicon. first approach heuristic approach,which, motivated Posse et al. (2005), labels report shaping factor containsleast word phrase relevant shaping factor. Unlike Posse et al.swork, relevant words phrases employed heuristic proceduremanually identified, automatically acquire words phrases via semisupervised semantic lexicon learning procedure described above. second approachmachine-learning approach somewhat orthogonal NASAs approach: insteadhuman identify seed words phrases relevant shaping factor,humans annotate small subset available incident reports shapingfactors, apply machine learning algorithm train classifier automaticallylabel unseen report, using combinations N-gram features words phrasesautomatically acquired aforementioned semantic lexicon learning procedure.see, acquire cause identifier using Support Vector Machines (SVMs),shown effective topic-based text classification. Since smallnumber labeled reports, also attempt combine labeled unlabeled reports usingtransductive version SVMs.Since approaches rely simple linguistic knowledge sources involve N-gramswords phrases automatically acquired semantic lexicon learning procedure, one may argue use simple features sufficient cause572fiCause Identification via Weakly Supervised Semantic Lexicon Constructionidentification. important point means arguingfeatures sufficient cause identification. However, use simple featuresrelevant task motivated work performed NASA researchers,who, mentioned above, manually identified seed words phrases shapingfactor (Posse et al., 2005). semantic lexicon learning procedure precisely aims learnwords phrases. error analysis reveals simple linguistic featuressufficient learning cause identification (and sophisticated knowledgesources needed improve performance), one first attempts tackle causeidentification task, believe use simple features good starting pointestablishes baseline future studies domain-specific problemcompared.evaluate aforementioned two approaches manually annotated ASRS reports. experiments show number interesting results. First, best performanceachieved using heuristic approach, label report basis presenceautomatically acquired lexicon words phrases report, achieving F-measure50.21%. importantly, method significantly surpasses performancebaseline system, labels report basis presence small set manuallyidentified seed words phrases. results suggest employing automaticallyacquired semantic lexicon relevant useful cause-based text classificationASRS reports. Second, words phrases learned semantic lexicon, usedfeatures training SVMs classification approach, improve performanceSVM classifier trained solely N-gram based features amounttraining data small. However, increase amount training data (by crossvalidation), using lexicon words phrases features addition unigramsbigrams helps improve classifier performance statistically significantly. particular,observed F-measure 53.66% SVM classifiers using combinationunigrams, bigrams lexicon words phrases features. results confirmwords phrases learned semantic lexicon relevant valuablefeatures identifying responsible shaping factors. Nevertheless, magnitudeimprovement indicates still much room improvement, mayachieved using deeper semantic features.summary, believe work automated cause identification makes fiveprimary contributions:show instead manually analyzing incident reports identifyrelevant shaping factors, possible reduce amount human effort requiredtask manually analyzing small subset reports identifyingshaping factors rest reports using automated methods.propose several modifications Thelen Riloffs (2002) semi-supervised lexicon learning framework, show Modified Basilisk framework allows usacquire semantic lexicon yields significantly better performance causeidentification original Basilisk framework. Equally importantly, nonemodifications geared towards cause identification task, henceapplicable generally semantic lexicon learning task. fact, addi573fiAbedin, Ng & Khantional experiments suggest Modified Basilisk yields better accuracy OriginalBasilisk bootstrapping general semantic categories.show semantic lexicon learning useful cause identification ASRSreports. particular, words phrases learned semantic lexiconprofitably used improve heuristic-based approach learning-basedapproach (when given sufficient training data) cause identification. addition,believe similar cause identification task causes describedtext, may useful learn semantic lexicon containing key wordsphrases related different types possible causes use key wordsphrases features machine learning.attempt deduce weaknesses approaches help direct futureresearch, performed analysis errors made best-performingsystem, namely heuristic approach using semantic lexicon learnedmodified Basilisk method randomly chosen subset test reports.manually annotated subset reports relevant shaping factors.set annotated reports, made publicly available, servestandard evaluation set task future research also comparingapproaches cause identification.rest paper organized follows. Section 2, discuss dataset,shaping factors, reports preprocessed annotated. Section 3 definesbaseline, simply looks small set manually extracted seed wordsphrases report narratives. Section 4, describe semantic lexicon learningprocedure, based Basilisk lexicon learning procedure (Thelen & Riloff,2002) augmented modifications. Section 5, discuss heuristic-basedlearning-based approaches cause identification. evaluate two approachesSection 6 discuss related work Section 7. Finally, Section 8, summarizeconclusions discuss future work.2. Datasetdataset used research aviation safety incident reports publicly availablewebsite Aviation Safety Reporting System5 . used 140,599 reports collected period January 1998 December 2007. report containsfree text narrative written reporter several fixed fields incident liketime place incident, environment information, details aircraftsinvolved, reporting persons credentials, details like anomaly, detector, resolutionconsequence incident itself, description situation. words,fixed fields report contain various information happened,physical circumstances, cover incident took place. discussedPosse et al. (2005) Ferryman, Posse, Rosenthal, Srivastava, Statler (2006),narrative report contains information shaping factors incident.5. Available http://asrs.arc.nasa.gov/search/database.html574fiCause Identification via Weakly Supervised Semantic Lexicon Constructionreason, decided analyze free-text narrative report using NLP techniques identify shaping factor(s) incident may be, constructedcorpus task combining narratives 140,599 reports.2.1 Shaping Factorsincidents described ASRS reports happen variety reasons. Posse et al.(2005) focus 14 shaping factors, simply shapers. Following short descriptionshaping factors, taken verbatim work Posse et al..1. Attitude: indication unprofessional antagonistic attitude controllerflight crew member.2. Communication Environment: Interferences communications cockpitnoise, auditory interference, radio frequency congestion, language barrier.3. Duty Cycle: strong indication unusual working period e.g., long day, flyinglate night, exceeding duty time regulations, short inadequate restperiods.4. Familiarity: indication lack factual knowledge, new unfamiliar company, airport, aircraft.5. Illusion: Illusions include bright lights cause something blend in, black hole,white out, sloping terrain.6. Physical Environment: Unusual physical conditions could impair flyingmake things difficult, unusually hot cold temperatures inside cockpit,cluttered workspace, visual interference, bad weather, turbulence.7. Physical Factors: Pilot ailment could impair flying make things difficult, tired, fatigued, drugged, incapacitated, influenced alcohol,suffering vertigo, illness, dizziness, hypoxia, nausea, loss sight, loss hearing.8. Preoccupation: preoccupation, distraction, division attention createsdeficit performance, preoccupied, busy (doing something else),distracted.9. Pressure: Psychological pressure, feeling intimidated, pressured, pressedtime, low fuel.10. Proficiency: general deficit capabilities, inexperience, lack training,qualified, current, lack proficiency.11. Resource Deficiency: Absence, insufficient number, poor quality resource,overworked unavailable controller, insufficient out-of-date chart, equipment malfunction, inoperative, deferred, missing equipment.575fiAbedin, Ng & Khan12. Taskload: Indicators heavy workload many tasks once, shorthanded crew.13. Unexpected: Something sudden surprising expected.14. Other: Anything else could shaper, shift change, passenger discomfort, disorientation.2.2 Preprocessingsemantic lexicon learning approach cause identification, need identify(1) part-of-speech (POS) word text, (2) phrases chunkssentences, (3) grammatical roles words governing words. Ideally,achieve high accuracies three tagging tasks, would manually annotate sectionASRS corpus appropriate annotations (e.g., POS tags, chunks) trainappropriate taggers tag rest corpus. However, laborintensive task, beyond scope paper. Therefore, used publiclyavailable tools trained standard corpora three tasks. inevitableproduce accurate automatic annotations corpus, see,caused problem task.corpus, first identify sentence boundaries using tool MXTERMINATOR6 . Second, run POS tagger CRFTagger (Phan, 2006b), uses PennTreebank tag set (Marcus, Santorini, & Marcinkiewicz, 1993), sentences detectedMXTERMINATOR. Third, run chunker CRFChunker (Phan, 2006a) taggedtext identify different types phrases. Also, Minipar parser (Lin, 1998) runsentences identify grammatical roles words. However, report textpreprocessed applying tools reasons described following paragraphs.reports ASRS data set usually informally written, using various domainspecific abbreviations acronyms. general, observed van Delden Gomez(2004), Posse et al. (2005) Ferryman et al. (2006), narratives tend writtenshort, abbreviated manner, tend contain poor grammar. Also, textconverted upper-case. Following example narrative report:TAXIING RAMP LAF NIGHT. MADE WRONG TURNCROSSED RWY 10/28; ACTIVE TIME.SIGN INDICATE RWY XING. CLRED DIRECTIONS XING. ACFT FIELDTIME. MENTION ATIS SIGNSCONSTRUCTION RAMP AREA. CTLR DIDNT QUESTIONUS; BROUGHT SIT CROSSEDACTIVE RWY. COMMUTER OPS 3 DAYS HVY FLYING;REDUCED REST; RWY SIGNS BUSY LAST MIN COMMUTER PAPER WORK CHANGES; CONTRIBUTED RWYINCURSION. 12 HR DAY 6 HR FLT TIME.6. ftp://ftp.cis.upenn.edu/pub/adwait/jmx/, trained Wall Street Journal corpus576fiCause Identification via Weakly Supervised Semantic Lexicon Constructionreports need preprocessing NLP techniques applied them,since off-the-shelf tools (e.g., POS tagger) trained mixed-case texts.example, running CRFTagger (which trained WSJ corpus correct cases)first two sentences yield following:1. TAXIING/NNP FROM/NNP THE/DT RAMP/NNP AT/IN LAF/NNP AT/INNIGHT/NN ./.2. MADE/NNP A/DT WRONG/NNP TURN/NNP AND/CC CROSSED/VBDRWY/NNP 10/28/CD ;/: THE/DT ACTIVE/NNP AT/IN THE/DT TIME/NN ./.seen, tagger mislabels words TAXIING, FROM, MADE, WRONGACTIVE proper nouns (NNP), instead tagging verb, preposition, verb,adjective adjective respectively. occurs good feature detecting propernouns sentence case first character. Since words begin capitalletter, tagger mistakes significant portion words NNP. Another reasontagger performs poorly corpus lot abbreviations appear text.example, XING HVY short crossing heavy. sincelikely known POS tagger trained standard well-edited corpus, wouldidentified unknown words, likely tagged nouns instead verbadjective respectively. Similar problems observed parsers chunkers.reason, decided preprocess text expanding abbreviationsrestoring cases words.expand acronyms abbreviations, rely official list acronymsabbreviations used ASRS reports7 . small number cases, abbreviationacronym may one expansion. example, ARR may mean either arrivalarrive. cases arbitrarily chose one possibilities8 . Then, restore case,set English word lists, place names person names9 applied textidentify known words. word report text appeared word lists,converted lower case. unknown words left uppercase. resultprocess aforementioned narrative follows:TAXIING ramp LAF night. made wrong turn crossedrunway 10/28; active time. sign indicaterunway crossing. cleared directions crossing.aircraft field time. mention Automatic TerminalInformation Service signs construction ramp area.controller DIDNt question us; brought situationcrossed active runway. commuter operations 3 days heavy flying;7. See http://akama.arc.nasa.gov/ASRSDBOnline/pdf/ASRS_Decode.pdf.8. better option would disambiguate alternative expansions based context (e.g.,method followed Banko & Brill, 2001). However, number ambiguities acronymsabbreviations list small (10, exact), either POS variationsword. Thus effect ambiguities performance NLP tools expectedminimal.9. http://wordlist.sourceforge.net/577fiAbedin, Ng & Khanreduced rest; runway signs busy last minute commuter paper workchanges; contributed runway incursion. 12 hour day 6 hour flight time.ran POS tagger, CRFTagger, processed text observeerrors. example, tagged version aforementioned two sentences are:1. TAXIING/VBG from/IN the/DT ramp/NN at/IN LAF/NNP at/IN night/NN ./.2. made/VBN a/DT wrong/JJ turn/NN and/CC crossed/VBD runway/NN 10/28/CD;/: the/DT active/JJ at/IN the/DT time/NN ./.sentences correctly tagged. However, case restoration methodarguably simplistic. Hence, determine need perform fine-grained caserestoration, sought measure much would gain accurately restoringcase words sentences present heuristic method. check this,randomly picked 100 sentences corpus. first ran POS taggersentences case-restored aforementioned heuristic case restorationmethod. Then, manually corrected capitalization sentences re-ranPOS tagger case-restored sentences. tags thus generated compared,found 99.7% agreement, means likely gain much termsPOS tagging accuracy correctly case restored text heuristically case restoredtext. five differences 2049 words, three NNPs mislabeled NNs,essentially effect outcomes research. Therefore, marginal utilityapplying sophisticated case restoration methods seem enough justifyadditional effort necessary, limit preprocessing step expansion abbreviations acronyms followed heuristic case restoration procedure described above.complete flow preprocessing shown Figure 1.2.3 Human Annotation ProcedureRecall need reports labeled shaping factors training cause identification classifiers testing performance two approaches cause identification.Additionally, order learn semantic lexicon via bootstrapping, need small setseed words phrases related shaping factor starting point. result,performing language normalization, performed two types annotations: (1) labelingset reports shaping factors, (2) identifying set seed words phrasesreports. annotation procedure described detail following sections.2.3.1 Annotating Reports Shaping FactorsNASA previously developed heuristic approach tackle cause identificationtask (Posse et al., 2005), approach evaluated 20 manually annotated reports,far satisfactory far establishing strong baseline method concerned.Thus decided annotate set reports evaluating automatic causeidentification methods.complete set 140,599 reports, chose random set 1333 reportsannotation. subset divided two parts. first part, consisting 233 reports,578fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionFigure 1: Flow chart text preprocessingannotated two persons (one undergraduate student one graduate student).report, asked answer following question:shaping factor(s) responsible incident described report?annotators trained similar way labeled 20 reports usedevaluation NASA researchers (see Posse et al., 2005). Specifically, backgroundreading, annotators referred works Posse et al. Ferryman et al. (2006),describe shaping factors, also give examples wordsphrases indicate influence shaping factors described incidents.definitions shapers repeated Section 2.1. Following Posse et al.s method,annotators explicitly instructed adhere definitions much possibleannotating reports shaping factors. annotations completed,inter-annotator agreement computed using Krippendorffs (2004) statisticsdescribed Artstein Poesio (2008), using Measuring Agreement Set-valuedItems (MASI) scoring metric (Passonneau, 2004). observed inter-annotator agreement,, case found 0.72, indicates reliable agreement. 233reports, completely agreed annotations 80 reports, completely disagreed100 reports partially agreed 53 reports. annotators asked discussdiscrepancies. discussion, found discrepancies could579fiAbedin, Ng & Khanprimarily attributed vagueness descriptions shaping factors Posse etal.s paper, interpreted differently two annotators.annotators agreed descriptions shapers interpreted,resolved differences annotation. discussion, remaining 1100reports annotated one annotators. annotator also askedannotate subset reports (100 reports) cross-verification purpose10 ,inter-annotator agreement, , case observed 0.66. 1333 reportsannotated first annotator divided three sets: training set (233 reports)training cause identification classifiers, held-out development set (100 reports)parameter tuning, test set (1000 reports) evaluating performanceapproaches cause identification. distribution shaping factors training,development test sets shown second, third fourth columns Table 1.2.3.2 Extracting Seed Words Phrasesseparate process, first author went first 233 reports annotatorsworked on, selected words phrases relevant shaping factors.judgment whether word phrase relevant shaping factor based carefulreading description shaping factors works Posse et al. (2005)Ferryman et al. (2006), well example seed words selected NASA expertsshown two papers. specific task case was:report, word phrase indicativeshaping factors? is, identify assign appropriateshaping factor.Note seed words phrases chosen without regard shaping factorannotation document; picked possibility relevantrespective shaping factors. number seed words phrases shapingfactor shown last column Table 1. see, 177 seed words phrasesmanually selected 233 training reports. completeness, also showseed words phrases extracted reports Appendix A. facilitateresearch topic, annotated data used research made availablehttp://www.utdallas.edu/~maa056000/asrs.html.Since gold standard compare list annotatedwords phrases, difficult directly compute precision. However, get roughidea precision, asked one annotators examine list identifywords phrases list believes correct. disagreementone word. yields precision 99.44%, provides suggestive evidenceannotation fairly reliable. manually identified words phrasesused baseline cause identification system (see Section 3) also served seedssemantic lexicon learning procedure (see Section 4).10. fairly standard procedure NLP research cross-annotate subset datacomplexity cost individual annotation high. See works Zaidan, Eisner, Piatko (2007)Kersey, Di Eugenio, Jordan, Katz (2009), instance.580fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionTable 1: Distribution shaping factors training, test development setsShaping factorReports ReportsReportsSeedtraining settest set development wordstest setAttitude173058Communication Environment1190185Duty Cycle926310Familiarity125089Illusion120136217368Physical Environment432654045Physical Factors103538Preoccupation25110109Pressure530310Proficiency432472312Resource Deficiency1125073347Taskload62972Unexpected31013Total23310001001773. Baseline System Cause Identificationdiscussed introduction, goal research label incident reportsshaping factors caused incidents. evaluate performance causeidentification methods, need baseline uses amount training datamethods described paper performs reasonably well test set.Given cause identification relatively new under-investigated task, standardbaseline adopted task. fact, knowledge, related workscause identification aviation safety domain conducted researchersNASA (see Posse et al., 2005; Ferryman et al., 2006). result, construct baselinesystem motivated Posse et al.s work. Specifically, baseline takes input setseed words phrases manually collected shaping factors (see Section 2.3.2),labels report Occurrence Heuristic: seed word phrase foundreport, baseline annotates report shaping factor associatedseed. example, 11 hour duty day seed phrase associated shapingfactor Duty Cycle. Then, Occurrence Heuristic label report containsphrase 11 hour duty daywith Duty Cycle. approach simple attractive(1) need training, (2) evaluated easily, searchingseed words narrative report labeled, (3) report potentiallylabeled one shaping factors. seed words phrases indeedrelevant respective shaping factors, identify reports relatedshaping factors high degree precision.581fiAbedin, Ng & Khan4. Semantic Lexicon Learningdescribed Section 3, baseline uses seed words phrases manually extracted233 reports combination Occurrence Heuristic label reportsshaping factors. However, reports used evaluation may contain exactlywords phrases, may contain different variations, synonyms, wordsphrases semantically similar seed words phrases. Thus baselinemay able label reports correctly looking words phrasesseed words list.address potential problem, propose use semantic lexicon learning algorithms learn words phrases semantically similar seed words phrasesreports corpus containing narratives 140,599 reports. Using weakly supervised bootstrapping algorithm may allow us learn large number useful wordsphrases corpus would required huge amounts human effortdone manually. Below, first describe general bootstrapping approach Section 4.1.Then, Section 4.2, describe Basilisk framework learning semantic lexiconunannotated corpus (Thelen & Riloff, 2002). Finally, Section 4.3, discussmodifications Basilisk framework.4.1 Weakly Supervised Lexicon Learningmentioned earlier, employ weakly supervised bootstrapping approach buildingsemantic lexicon. use manually extracted seed words phrasesshaping factor (described Section 2.3.2) create initial semantic lexicon.select words phrases unannotated reports semantically similarwords already appearing semantic lexicon. reports corpus needlabeled shaping factors. semantic similarity two words measuredusing features extracted corpus word. process repeated iteratively:iteration, certain number words added semantic lexicon,words augmented lexicon used seeds following iteration.process shown Figure 2.Figure 2: Flow chart lexicon learning procedure582fiCause Identification via Weakly Supervised Semantic Lexicon Construction4.2 Basilisk FrameworkBasilisk (Bootstrapping Approach SemantIc Lexicon Induction using Semantic Knowledge)instantiation aforementioned generic semantic lexicon learning framework (Thelen & Riloff, 2002). Basilisk framework works first identifying patternsextracting noun phrases corpus appear one three syntactic roles:subject, direct object, prepositional phrase object. example, discussed Thelen Riloff, sentence John arrested collaborated Smithmurdered Brown, extraction patterns <subject> arrested, extractsJohn, murdered <object> extracts Brown collaborated <pp object>extracts Smith. Then, semantic category Sk , pattern pool constructedpatterns tend extract words Sk . measure tendency pattern Pjextract words Sk , R log F metric used, defined as:R log F (Pj ) =Fjlog (Fj )Nj(1)Here, Fj number (distinct) words Sk pattern Pj extracts, Njtotal number (distinct) words corpus Pj extracts. metric highhigh precision patterns (i.e., patterns extract primarily words Sk ) high recallpatterns (i.e., patterns extract large number words Sk ). iteration i,top (20 + i) patterns (in terms R log F scores) put pattern pool Sk .Depleted patterns (i.e., patterns extracted words already semanticlexicon) considered step. Then, head nouns phrases extractedresulting patterns pattern pool put word pool Sk .Next, subset words word pool selected added seed wordslist. words word pool chosen relevant Sk .specifically, word Wi word pool Sk , first AvgLog score calculated,defined follows:AvgLog (Wi , Sk ) =WPiXlog2 (Fj + 1)j=1W Pi(2)Here, W Pi number patterns extract word Wi , pattern Pjextracts Wi , Fj number words extracted Pj belong Sk . Then,semantic category Sk , five words chosen highest AvgLog scorecategory Sk .multi-category learning, Thelen Riloff (2002) experimented different scoring metrics reported achieved best performance calculating diffscore word. given word word pool semantic category, diffscore takes consideration score word gets categories, returnsscore based words score semantic category relative categories.precisely, diff score defined follows:dif f (Wi , Sk ) = AvgLog (Wi , Sk ) max (AvgLog (Wi , Sl ))l6=k583(3)fiAbedin, Ng & KhanHere, Sk semantic category Wi evaluated. Thus diff scorehigh strong evidence Wi belongs semantic category Sk little evidencebelongs semantic categories. semantic category, diff scorecalculated word categorys word pool, top five wordshighest diff score added lexicon category. Two additional checksmade stage: (1) word word pool added categoryearlier iteration, word discarded, (2) word foundone word pool added category highest score11 .completed semantic categories, iteration ends, next iterationbegins augmented lexicon.4.3 Modifications Basilisk Frameworksee later subsection, analysis framework revealscases words selected Basilisk may relevant ones. reason,propose three algorithmic modifications Basilisk framework: (1) using new semanticsimilarity measure, (2) merging word pools one single pool assigning wordssemantic categories, (3) imposing minimum support maximum generality criteriapatterns words added pattern pools word pools. addition, proposeone linguistic modification, employ type feature computedrobust manner words phrases corpus, namely, N-gram features.rest subsection discusses modifications.4.3.1 Modification 1: New Semantic Similarity Measureseen Section 4.2, Basilisk framework uses AvgLog scoring function measuresemantic similarity words. diff score multi-category learning also usesAvgLog function compute evidence word belonging semantic categoryrelative categories. However, closer examination AvgLog function showsmay able properly predict semantic similarity circumstances.understand reason, let us first make following observations: pattern Pj occurs1000 times, extracts words category Sk 5 times, unlikely Pj stronglyrelated Sk . Similarly, word Wi occurs 1000 times, extracted pattern Pj 5times, Pj small influence classification Wi . However, AvgLog scoreable take factors consideration, precisely considersabsolute number semantic category members extracted patterns extractword frequency extraction. see case, let us considerword Wi extracted three patterns P1 , P2 P3 , frequencies shownTable 2. P1 , P2 P3 extract five distinct seed words, AvgLog scoreword W would 2.32, irrespective fact patterns actually extract wordseed words list tiny fraction occurrence corpus. P1 extractsseed word 5% occurrence, P2 1% time, P3 , pattern extracts Woften, extracts lexicon word 0.5% times appears text. Clearly,11. approach effectively assumes word belong one category. reasonableassumption specific task since shaping factors distinct meanings.584fiCause Identification via Weakly Supervised Semantic Lexicon Constructionpatterns would suggest Wi related semantic category, yet getsgood score.Table 2: Illustration problem AvgLog: unrelated words may highsimilarity score. Wi word appears corpus extractedpatterns P1 , P2 P3Patterns extract WiNumber times Wi extracted pattern PjNumber times pattern Pj occurs textNumber times word category Sk extracted pattern PjNumber category words extracted pattern Pjlog2 (Fj + 1)AvgLog (Wi )P110100552.32P2P32070500 100055552.32 2.322.32Keeping mind, propose probabilistic metric, SemProb, computesprobability word Wi belongs semantic category Sk given extractedpatterns P1 , P2 , . . . , Pn . specifically, SemProb calculated follows:SemP rob (Wi , Sk ) = P rob (Sk |Wi )X=P rob (Sk |Pj ) P rob (Pj |Wi )(4)Pjwords, SemProb assumes semantic category Sk word Wiconditionally independent given Pj , pattern extracts Wi . probabilitiesequation estimated using maximum likelihood estimation corpus. Specifically,compute P rob (Pj |Wi ), divide number times Pj extracts Wi corpustotal number times Wi appears corpus. compute P rob (Sk |Pj ), dividenumber times Pj extracts word semantic category Sk total numbertimes Pj appears corpus. given word Wi given semantic categorySk , sum products two quantities patterns extract Wigives probability category Sk given word Wi . method sufferproblem faced AvgLog since depends probability word extractedpatterns patterns probability extracting words category.example Table 2, SemProb metric word Wi 0.0105, illustratinglow probability Wi belonging semantic category Sk is. details givenTable 3.4.3.2 Modification 2: Common Word PoolSince compute Eqn (4) every word word pool categoriesassign word semantic category probability highest, changeframework one common word pool semantic categories.585fiAbedin, Ng & KhanTable 3: Illustration effectiveness SemProb: unrelated words get low similarityscore.Patterns extract WiNumber times Wi extracted pattern PjNumber times pattern Pj occurs textNumber times word category Sk extracted pattern PjP rob (Wi extracted Pj )P rob (Pj extracts word Sk )P rob (Wi extracted Pj ) P rob (Pj extracts word Sk )SemP rob (Wi , Sk ) = P rob (Wi belongs semantic category Sk )P11010050.10.050.005P2P320705001000550.20.70.010.0050.002 0.00350.0105still separate pattern pools different semantic categories, words relatedpatterns pattern pools put common word pool, allocatedprobable semantic category there. separate word poolssemantic category, add fixed number words categoryiterations. constraint may undesirably cause word added categorylikely. However, since one word pool modification,constraint add fixed number words category,assign word likely category. Thus number words addeddifferent categories may vary iteration.4.3.3 Modification 3: Minimum Support Maximum Generalityscenarios SemProb metric produce undesirable results.example, consider infrequent word Wi occurs entire corpus exactly once.Assume pattern Pj , extracts Wi , extracts words semantic category Sk70% probability. So, according SemProb, probability Wi belongs Sk becomes70%. However, sufficient evidence Wi belongs Sk . casesuncommon, imposed minimum word frequency constraint wordsput word pool, words appear less certain number timesconsidered. pattern appears infrequently corpus also leadproblem. Consider infrequent pattern, Pj , appears exactly twice corpusextracts two words. one words happen seed word,word 50% probability belong category seed word PjR log F value 0.5. However, since Pj infrequent, convey good evidencemembership semantic category, allow Pj put wordsword pool. Therefore, disallow low frequency patterns includedpattern pool adding constraint patterns put pattern pool must alsominimum pattern frequency. Besides two constraints imposed frequencyoccurrence words patterns, employ two additional constraints. first586fiCause Identification via Weakly Supervised Semantic Lexicon Constructionmaximum pattern generality constraint: motivated Rychly Kilgarriff (2007),remove consideration patterns general (i.e., patterns extractmany words), imposing upper limit number distinct words patternadded pattern pool extract. second maximum word frequencyconstraint: since content-bearing words likely lower frequency (see Davidov& Rappoport, 2006), impose upper limit maximum number times wordappears corpus. four thresholds associated four frequency-basedconstraints tuned automatically using held-out development set.4.3.4 Modification 4: N-gram Patternsaddition parse-tree-based subject-verb verb-object patterns already employedBasilisk, also employ N-gram-based extraction patterns, goal robustly capturing context words appear. construct N-gram extractionpatterns follows. noun adjective, X, corpus, create two N-grampatterns extracting X: (a) preceding N words + hXi, (b) hXi + succeedingN words. example, sentence ... solid line thunderstorms detected ...,bigram patterns thunderstorms would be: line hXi hXi detected.complete sentence approaching ATL area solid line thunderstormsdetected vicinity airport, words extracting bigram patternswould be:ATL: approaching hXi, hXi areaarea: ATL hXi, hXi solidsolid: area hXi, hXi lineline: solid hXi, hXi thunderstormsthunderstorms: line hXi, hXi detectedvicinity: hXi, hXiairport: hXiaddition constructing N-gram patterns extracting words, also constructN-gram patterns extracting phrases. so, first remove articles (a, an, the)possessive pronouns adjectives (e.g., my, his) beginning phrasescorpus. noun phrase adjective phrase, X, appears corpus,create two N-gram patterns extracting X: (a) preceding N words + hXi, (b)hXi + succeeding N words. example, sentence last 5 legsapproaching end 8 hour duty day 7 hour hard time flying day, wouldextract following phrases following bigram patterns:5 legs: last hXi, hXi approachingend: approaching hXi, hXi587fiAbedin, Ng & Khan8 hour duty day: end hXi, hXi 77 hour hard time flying day: day hXiThus use three types patterns experiments: bigram patterns extractingwords, bigram patterns extracting phrases, parse-tree-based subject-verb verbobject patterns. patterns generated reports corpus generatedcombining narratives 140,599 unlabeled reports described Section 2.2.see, three types patterns beneficial use far performanceconcerned. Section 6, show automatically select best subsetpatterns use based development set.5. Semantic Lexicon-Based Approaches Cause IdentificationASRS Reportsinvestigate heuristic-based approach learning-based approach cause identification, exploit information provided automatically acquired semanticlexicon. section describes details two approaches.5.1 Heuristic-Based Approachheuristic-based approach operates essentially way baseline causeidentification system described Section 3, Occurrence Heuristic used labelreport shaping factors. difference words phrases usedOccurrence Heuristic baseline manually identified, whereasheuristic-based approach acquired Modified Basilisk procedure.5.2 Learning-Based Approachlearning-based approach cause identification problem recast classification task. Note multi-class multi-labeled classification task: 14classes report labeled one class. number approachesproposed tackle multi-class multi-labeled classification tasks. restsection, describe three existing approaches multi-class multi-labeled text classification explore experiments (Section 5.2.1), provide overviewtheory Support Vector Machines (SVMs), underlying learning algorithm usetrain classifiers employed three approaches (Section 5.2.2).5.2.1 Three Approaches Multi-Class Multi-Labeled Text ClassificationOne-Versus-All. approach, train one binary classifier shaping factorSk determine whether report labeled Sk . specifically, followOne-Versus-All classification scheme: given Sk , reports training setcontains Sk set labels (assigned annotator) positive instancesbinary classifier rest reports training set negative instances.training, apply classifiers report test set independentlyreports, label report Sk corresponding classifier classifies588fiCause Identification via Weakly Supervised Semantic Lexicon Constructionreport positive. Thus convert cause identification multi-class multi-labeleddocument classification task.learning algorithm used principle train classifiers OneVersus-All scheme, use Support Vector Machines12 training testing classifiers,primarily due successes various text classification tasks. classifier trainedtwo types features: (1) unigrams bigrams report narratives, (2)words phrases semantic lexicon. feature values TF*IDF values.shaping factor-labeled data set 1333 reports substantially largerset 20 reports annotated NASA researchers (see Section 1), arguably fairlysmall machine learning perspective. Hence, conceivable performanceSVM classifiers would limited small size training data. result,investigate whether improve One-Versus-All approach using transductiveSVM, version inductive SVM described attempts improveclassifier performance combining labeled unlabeled data (see Section 5.2.2overview transductive learning). cause identification task, unlabeledreports test set serve unlabeled data transductive learning procedure.MetaLabeler. second approach, employ MetaLabeler (Tang, Rajan, & Narayanan,2009) classifying multi-class multi-labeled text data. Here, model first learnedpredicts number labels instance may have. addition, set binary classifier models, one possible label, learned predict likelihood labelinstance. instance classified, first model predicts K, numberpossible labels instance, output second set classifiers, Klabels chosen highest likelihood instance.implementation approach, first model learned using SVMmulticlass ,implementation multi-class SVM described Crammer Singer (2002)13 .second set classifiers set described Section 5.2.2. case,given instance x, decision functions f (x) = w x b classifiersevaluated, positive decision values sorted. top K labels correspondinghighest values decision functions assigned instance.multiclass classifier set binary classifiers trained using typesfeatures One-Versus-All approach, namely unigrams bigrams reports,words phrases semantic lexicon. feature values alsoOne-Versus-All approach, namely TF*IDF values.Ensembles Pruned Sets. Pruned Sets approach (Read, Pfahringer, & Holmes,2008), multi-class multi-label text classification problem transformed multiclass single-label text classification problem selecting subset label combinationsfrequently occurring dataset assigning unique pseudo-label chosenlabel combination.first step algorithm choose label sets training. step,label sets chosen meet minimum frequency requirement trainingset. Using minimum frequency constraint prunes away infrequently occurring label setsfrequency less p, leaving label combinations frequent thus12. implemented SVMlight software package Joachims (1999)13. Available http://svmlight.joachims.org/svm_multiclass.html589fiAbedin, Ng & Khanimportant. training instances labeled pruned label setsalso removed training set. minimum cardinality parameter, b, usedreintroduce pruned instances back training set order minimizeinformation loss pruning process. First label sets rejected instancesbroken smaller subsets least size b. new subsetsfrequency higher p reintroduced, pruned training instances whose labelsets supersets newly accepted label sets reinstated training set.role parameter b case ensure many instances smalllabel sets put back, cause average number labels reduce,resulting smaller number labels per instance classification time.next step learn classifiers selected label sets. First, accepted labelset assigned unique pseudo-label, thus transforming multi-label classification problem single-label classification problem. ensemble classifiers learnedpredict pseudo-labels given instance (using multi-class SVM implementation MetaLabeler), classifier ensemble trained differentrandom sample training data. Since (1) label sets training classifiersrepresent subset label combinations present original training data(2) test data may contain label combinations present trainingdata, ensemble classifiers allows system generate label combinationsobserved training time. example, let label combinations {l1 , l3 } {l2 , l3 }present training data. Then, one classifier ensemble labels test instance{l1 , l3 } another classifier ensemble labels instance {l2 , l3 },instance may labeled {l1 , l2 , l3 } (depending actual voting policyeffect classification time) even combination present training data.classifiers ensemble built using two types features One-VersusAll approach, namely unigrams bigrams reports words phrasessemantic lexicon learned modified Basilisk framework.Finally, classifying instance, classifiers assigns one pseudo-labelinstance. pseudo-labels mapped back original label combinationvote actual label counted normalized dividing numberclassifiers, , order bring prediction possible label range0.0 1.0. threshold used label prediction valuegreater equal assigned instance. scheme used make possibleassign label combinations unseen training time test instances.5.2.2 Overview Support Vector MachinesSVMs shown effective text classification (Joachims, 1999).describe two versions SVMs: (1) inductive SVMs, learn classifier solelylabeled data, (2) transductive SVMs, learn classifier labeledunlabeled data.Inductive SVMs. Given training set consisting data points belonging two classes,inductive SVM aims find separating hyperplane maximizes distanceseparating hyperplane nearest data points. nearest data points actsupport vectors plane.590fiCause Identification via Weakly Supervised Semantic Lexicon Constructionformally, let data set data points= {(xi , ci ) |xi Rn , ci {1, 1} , 1 m}(5)point xi represented n-dimensional vector associated class labelci . inductive SVM classifier attempts find hyperplane w x b = 0maximum distance nearest data points opposite labels. hyperplane wouldmiddle two hyperplanes containing support vectors class.2. Therefore,two hyperplanes wxb = 1 wxb = 1, distance |w|desired separating hyperplane found solving following quadratic programmingoptimization problem:Minimizesubject1|w|22ci (w xi b) 1, 1(6)However, practice many classes linearly separable. handle cases, setslack variables used represent misclassification point xi . problembecomes:X1|w|2 + CMinimize2subjectci (w xi b) 1 , > 0, 1(7)additional variables representing training errors C constant representing trade-off training error margin. details found CortesVapnik (1995). experiments, use radial basis function (RBF)kernel,2every dot product replaced function k (x, x ) = exp |x, x | , > 0.addition, C chosen cross-validation training set.Transductive SVMs. transductive setting, addition set labeled datapoints, also exploit set unlabeled data points, = {xi |xi Rn , 1 k},taken test set. described Joachims (1999), goal minimizeexpected number classification errors test set. expected error ratedefined Vapnik (1998) follows:Z1X(8)(hL (xi ) , ci ) dP (x1 , c1 ) . . . dP (xk , ck )R (L) =kL = , hL hypothesis learned L, (a, b) zero = bone otherwise. labeling ci test data hyperplane maximizesseparations training testing positive negative instances found solvingfollowing quadratic programming optimization problem, modified versionEqn (7):XX1j|w|2 + C+ CMinimize2subjectjci (w xi b) 1 , > 0, 1cj w xj b 1 j , j > 0, 1 j k591(9)fiAbedin, Ng & KhanSimilar inductive SVM Section 5.2.2, use RBF kernel experimentsinvolving transductive SVM.6. Evaluationgoal evaluation study effectiveness two approaches cause identification, namely semantic lexicon learning approach classification approach.testing performance approaches randomly chosen set reportsmanually annotated shaping factors caused incidents described (Section 2.3.1). start describing experimental setup (Section 6.1),followed baseline results (Section 6.2) performance two approaches(Sections 6.3 6.4). describe experiment increase amounttraining data available classification approach investigate impactsperformance (Section 6.5). that, perform analysis errors bestperforming approach (Section 6.6) conduct additional experiments attemptgain better insight cause identification task help direct future research(Section 6.7). Finally, present summary major conclusions drawexperiments (Section 6.8).6.1 Experimental Setupdescribed Section 2.3, 140,599 reports entire corpus, manuallyannotated 1333 incident reports shaping factors. used first 233(1) manually extract initial seed words phrases semantic lexiconlearning procedure, (2) train classifiers identifying shaping factors associatedreport. remaining reports, used 1000 reports test data 100 reportsdevelopment data (for parameter tuning).6.1.1 Evaluation Metricsmentioned Section 2.1, 14 shaping factors, report may labeledone shaping factors. evaluate performance causeidentification approaches based well automatic annotations match humanannotations reports test set. evaluation, use precision, recallF-measure, computed described Sebastiani (2002). Specifically,shaping factor Si , = 1, 2, . . . 14, let ni number reports test sethuman annotator labeled Si , i.e., number true Si -labeled reports testset. Further, let pi number reports automatic labeling scheme Cilabeled Si , let tpi number reports Ci labeled correctly Si .Then, shaping factor Si , following performance metrics:Precisioni fraction reports really caused shaping factor Si amongreports labeled Si labeling scheme.P recisioni =592tpipifiCause Identification via Weakly Supervised Semantic Lexicon ConstructionRecalli percentage reports really caused shaping factor Si labeledlabeling scheme shaping factor Si .Recalli =tpiniThus obtain measure labeling schemes performance shapingfactors. obtain overall performance labeling scheme, sum counts(i.e., ni , pi tpi ) shaping factors compute micro-averaged precision,recall F-measure aggregated counts described Sebastiani repeatedfollows:PtpiP recision = PipiPitpiRecall = Pini2 P recision RecallF -measure =P recision + RecallThus labeling scheme one set overall scores reflecting performanceclasses.6.1.2 Statistical Significance Testsdetermine whether labeling scheme better another, apply two statisticalsignificance tests McNemars test (Everitt, 1977; Dietterich, 1998) stratified approximate randomization test (Noreen, 1989) test whether difference performances really statistically significant. McNemars test compares two labeling schemesbasis errors (i.e., whether labeling schemes making mistakes), stratified approximate randomization test compares labeling schemesF-measure. tests extensively used machine learning NLP literature. particular, stratified approximate randomization standard significance testemployed organizers Message Understanding Conferences determinedifference F-measure scores achieved two information extraction systems significant (see Chinchor, 1992; Chinchor, Hirschman, & Lewis, 1993). Since ultimatelyconcerned difference F-measure scores two labeling schemes causeidentification, discussion statistical significance rest section focused solely stratified approximate randomization test. tests, determinesignificance level p < 0.05.6.2 Baseline SystemRecall use baseline heuristic method described Section 3,Occurrence Heuristic used label report using seed words phrases manuallyextracted 233 training reports. Results, shown Experiment 1 sectionTable 4, reported terms precision (P), recall (R), F-measure (F). lasttwo columns show whether particular automatic labeling scheme significantly better593fiAbedin, Ng & Khanbaseline respect McNemars test (MN) stratified approximate randomization test (AR) [Statistical significance insignificance denoted XX, respectively]. evaluated 1000 reports test set, baseline achievesprecision 56.48%, recall 40.47% F-measure 47.15%.Table 4: Report labeling performance different methods.Approach Feature SetPRF MNARExperiment 1: BaselineHeuristic Seed words56.48 40.47 47.15 N/A N/AExperiment 2: Semantic lexicon approachLexicon modified Basilisk53.15 47.57 50.21XXHeuristicLexicon original Basilisk49.23 42.78 45.78XXExperiment 3: Supervised One-Versus-All classification approachUnigrams37.54 64.50 47.46XXUnigrams bigrams42.19 47.39 44.64XXSVMLexicon words48.72 37.08 42.11XXUnigrams lexicon words37.05 65.96 47.45XXUnigrams, bigrams, lexicon words 51.19 36.59 42.68XXExperiment 4: Transductive One-Versus-All classification approachUnigrams11.84 67.78 20.16XXUnigrams bigrams50.00 33.86 40.38XXSVMLexicon modified Basilisk42.83 30.64 35.73XXUnigrams lexicon words51.30 38.29 43.85XXUnigrams, bigrams, lexicon words 55.90 32.77 41.32XXExperiment 5: MetaLabeler approachUnigrams58.80 16.63 25.92XXUnigrams bigrams66.02 20.51 31.30XXSVMLexicon words63.23 17.11 26.93XXUnigrams lexicon words70.29 20.39 31.61XXUnigrams, bigrams, lexicon words 68.79 24.21 35.82XXExperiment 6: Ensembles pruned sets approachUnigrams22.44 63.05 33.09XXUnigrams bigrams22.22 67.42 33.42XXSVMLexicon modified Basilisk20.72 73.67 32.35XXUnigrams lexicon words23.72 85.25 37.12XXUnigrams, bigrams, lexicon words 16.93 71.42 27.37XXExperiment 7: Additional training data 5-fold cross-validationUnigrams42.21 63.65 50.76XXUnigrams bigrams43.58 58.31 49.88XXSVMLexicon words56.06 40.41 46.97XXUnigrams lexicon words54.75 52.43 53.56XXUnigrams, bigrams, lexicon words 54.81 52.55 53.66XX594fiCause Identification via Weakly Supervised Semantic Lexicon Construction6.3 Experiments Semantic Lexicon ApproachRecall semantic lexicon learning approach, label report test set usingOccurrence Heuristic combination semantic lexicon learned modifiedBasilisk framework described Section 4.3. showing results approach,first describe tune parameters modified Basilisk framework.6.3.1 Parametersmodified Basilisk framework five parameters tune. first four thresholds resulting four frequency-based constraints involving minimum supportmaximum generality (see Modification 3 Section 4.3.3). specifically, fourthreshold parameters (1) minimum frequency word (M inW ), (2) maximum frequency word (M axW ), (3) minimum frequency pattern (M inP ),(4) maximum number words extracted pattern (M axP ). addition, recallSection 4.3.4 three types patterns (namely, subject-verb/verb-object patterns, bigram patterns extracting words, bigram patterns extracting phrases).fifth parameter pattern parameter, determines subsetthree types patterns use. goal tune five parameters jointlydevelopment set. words, want find parameter combination yieldsbest F-measure Occurrence Heuristic used label reports development set. However, maintain computational tractability, need limit numbervalues parameter take. Specifically, limit five different combinations four threshold parameters (see Table 5), combination,find subset three types patterns yields best F-measure development set. Hence total number experiments need run 35 (= 7 (the number(non-empty) subsets three types patterns) 5 (the number combinationsfirst four parameters)). experiment indicates combination 3 Table 5,together bigram patterns extracting phrases, yields best F-measuredevelopment set, therefore chosen best parameter combination involvingfive parameters.new words phrases acquired first two iterations modified Basiliskusing parameter combination shown Appendix B. see newwords acquired first two iterations eight 14 categories. reasons(1) unlike original Basilisk framework, modified Basilisk employs commonword pool, thus longer requiring five words must added categorybootstrapping iteration; (2) application minimum support words ledfiltering infrequently-extracted words. two reasons together ensuremodified Basilisk framework focuses learning high-precision words category.6.3.2 Resultssemantic lexicon learned using best parameter combination (based performance development set) used label reports test set. seerow 1 Experiment 2 Table 4, Modified Basilisk approach achieves precision53.15%, recall 47.57% F-measure 50.21%. comparison baseline,method lower precision higher recall. increased recall shows595fiAbedin, Ng & KhanTable 5: Combinations four threshold parameters modified Basilisk framework.CombinationCombinationCombinationCombinationCombinationCombination12345inW2525101010axW25002500250025005000inP250100250250250axP100100100250100reports covered expanded lexicon. However, learned lexicon also containsgeneral words resulted drop precision. Overall, higher Fmeasure, statistically significantly better baseline accordingsignificance tests. vindicates premise learning words phrasesrelevant shaping factors help us identify shaping factors reports.6.3.3 Results Using Original Basiliskbetter understand whether proposed linguistic algorithmic modificationsBasilisk framework (see Section 4.3) indeed beneficial cause identificationtask, repeated experiment described above, except replaced lexicongenerated using modified Basilisk framework one generated using originalBasilisk framework. specifically, implemented original Basilisk frameworkdescribed Thelen Riloff (2002), one minor difference: casebigram patterns extracting phrases, word pools described Section 4.2 populatedentire phrases instead head words. done seed words listextracted Section 2.3.2 contains words phrases hence would like learnentire phrases.parameter tune original Basilisk framework pattern parameter,which, mentioned above, determines subset three types patterns use.Therefore, construct seven lexicons (corresponding seven non-empty subsetsthree types patterns) using original Basilisk framework, determinelexicon yields best performance development set. experiment indicatesbest development result achieved bigram patterns extractingphrases used. Applying corresponding semantic lexicon combinationOccurrence Heuristic classify reports test set, observe precision 49.23%,recall 42.78% F-measure 45.78% (see row 2 Experiment 2 sectionTable 4). lower precision higher recall indicates lexicon learnedwords general (i.e., words appear many reports littlediscriminative power). new words phrases acquired first two iterationsoriginal Basilisk shown Appendix C. seen, original Basilisk frameworkadds lot words, many relevant shaping factorsadded, semantically similar seed words shaping factor.596fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionHence, although recall improves small amount, precision drops significantly, leadingprecipitation F-measure. results suggest proposed modificationsoriginal Basilisk framework indeed beneficial far cause identification taskconcerned.6.4 Experiments Classification ApproachRecall classification approach cause identification, train SVM classifiershaping factor Sk determine whether report labeled Sk . desired,approach allows report test set potentially receive multiple labels, sinceresulting 14 SVM classifiers applied independently report. investigateeffect different feature sets performance cause identification, employ fivefeature sets experiments: (1) unigrams only; (2) unigrams bigrams; (3) lexiconwords only; (4) unigrams lexicon words; (5) unigrams, bigrams lexicon words.unigrams bigrams generated reports training set firstremoving stop-words ignoring case information, semantic lexiconone constructed modified Basilisk framework. showing resultssupervised transductive experiments, first describe parameters associatedclassification approach.6.4.1 ParametersSVM classifier, two parameters tune. first parameterpercentage features use. Feature selection shown improve performancetext classification tasks (Yang & Pedersen, 1997). result, employ informationgain (IG), one effective methods feature selection according YangPedersens experimental results. Since assume words semantic lexiconrelevant cause identification, apply feature selection lexicon words.Rather, apply feature selection unigrams bigrams. specifically,unigrams used features (as first five feature sets mentionedbeginning subsection), select N % unigrams highest IG,value N tuned using development set. unigrams bigrams usedfeatures (as second fifth feature sets), combine unigrams bigramsone feature set select N % unigrams bigrams highest IG,value N tuned using development set. experiments, tested 10values N : 10, 20, . . ., 100.second parameter associated SVM classifiers classification threshold.default, SVM sets classification threshold 0, meaning every data pointclassification value 0 classified positive, rest classifiednegative. However, since SVM classifier trained optimize classification accuracy,best classification threshold may 0 cause identification task,goal optimize F-measure. result, parameterize classification threshold,allowing take one 21 values: 2.0, 1.8, . . . , 1.8, 2.0.usual, tune two parameters described jointly rather independently.words, possible value combination percentages features597fiAbedin, Ng & Khanclassification threshold, compute F-measure classifiers development setclasses choose value pair yields maximum F-measure.get better idea two parameters impact performance, showFigure 3 F-measure changes development set vary valuestwo parameters, experiment underlying SVM classifiers employunigrams features. see, best F-measure achieved employingtop 50% unigrams classification threshold 0.8. Using default parameter values(no feature selection classification threshold 0) yields F-measure approximately18%. Overall, results provide suggestive evidence parameterslarge impact performance.F-measure Vs. classification thresholddifferent percentages unigram features100Top 10% UnigramsTop 20% UnigramsTop 30% UnigramsTop 40% UnigramsTop 50% UnigramsTop 60% UnigramsTop 70% UnigramsTop 80% UnigramsTop 90% UnigramsTop 100% Unigrams9080F-measure (%)706050403020100-2-1.5-1-0.500.5Classification threshold11.52Figure 3: Variation F-measure different percentages unigram features classification thresholds used SVM classification.6.4.2 Supervised One-Versus-All Classifiers: Results DiscussionsResults supervised One-Versus-All classification approach using five feature setsdescribed shown Experiment 3 section Table 4.14 see,feature sets 1 (unigrams only) 4 (unigrams lexicon words) used, achievebest results F-measure scores 47.46% 47.45%, respectively. However, evenbest results statistically indistinguishable baseline result (accordingapproximate randomization test), significantly worse result produced14. Recall supervised approach, SVM classifiers trained 233 reportstraining set.598fiCause Identification via Weakly Supervised Semantic Lexicon Constructionmodified Basilisk approach (row 1 Experiment 2) [see Appendix D, containsstatistical significance test results obtained applying stratified approximate randomization test pair experiments Table 4].fact, also indicate Occurrence Heuristic made effective uselearned semantic lexicon SVM classifiers: SVM classifiers trainedlexicon words features (row 3 Experiment 3) produced significantly worseF-measure score (42.11%) Occurrence Heuristic (50.21%), due largedrops recall precision. Overall, results suggest supervised approach performs worse heuristic-based semantic lexicon approach task.hypothesize limited amount training data available SVM learner contributed poor performance supervised approach. test hypothesisSection 6.5Two additional observations worth mentioning. First, comparing rows 1 4Experiment 3, see lexicon words useful cause identificationpresence unigrams. Second, comparing rows 1 2 rows 4 5 Experiment3, see using bigrams hurts performance. likely reason attributedfeature selection method: since choose top N % features, bigram featuressignificantly outnumber unigram features, thus potentially diminishing effectlatter. One solution problem employ separate parameters selectingunigrams bigrams, decided choice, would lead explosionsize parameter space.6.4.3 Transductive One-Versus-All Classifiers: Results Discussionsinvestigate whether useful exploit unlabeled data, employ transductive SVMcombine labeled unlabeled data. Essentially, repeated experimentssupervised One-Versus-All classification approach, except trained transductiveSVM classifier using (labeled) reports training set (unlabeled)reports test set described Section 5.2.2. two parameters percentagefeatures used classification threshold tuned jointly maximize F-measuredevelopment set, described supervised approach, except transductiveSVMs used parameter tuning step trained using training set labeled datadevelopment set unlabeled data.Results transductive SVM classifiers shown Experiment 4 sectionTable 4. Overall, transductive results significantly worse correspondingresults Experiment 3. However, conclusions draw transductiveresults slightly different drawn supervised results. First, usingbigrams significantly improves performance lexicon words absent (comparingrows 1 2 Experiment 3) hurts performance lexicon words present(comparing rows 4 5). Second, adding lexicon words unigram-only featureset (comparing rows 1 4) significantly improves performance, suggesting potentialusefulness lexicon features. Nevertheless, Experiments 3 4 indicate (1)using lexicon words features far adequate, (2) best performanceachieved lexicon words added unigrams features.599fiAbedin, Ng & Khan6.4.4 Results Additional Supervised ApproachesNext, present results two additional supervised approaches, namely MetaLabeler ensembles pruned sets (Section 5.2.1). feature sets usedapproaches used One-Versus-All method. OneVersus-All method, approaches use SVM underlying learning algorithmclassifier training.MetaLabeler. parameter needs tuned MetaLabeler approachpercentage features use (N ), selected based classification performance (F-measure) development set.Results MetaLabeler approach shown Experiment 5 section Table 4. interesting points results. First, MetaLabelermethod results much better precision methods. Second, methodshows consistent performance improvement bigram features added, seencomparing first second, fourth fifth rows MetaLabeler results.Third, inclusion lexicon word features also found improve performance,seen comparing first fourth, second fifth, rows MetaLabelerresults. two observations show MetaLabeler approach properly takeadvantage increasingly richer feature sets used experiments, bestperformance occurring types features used (fifth row). Unfortunately,approach suffers poor recall, fact prevents even matching, let alonesurpassing, F-measure scores methods. Since method discards lessprobable labels assigns labels documents, precision much improvedrecall suffers.Ensembles Pruned Set. Among parameters ensembles pruned setsapproach, number classifiers ensemble, , size sampletraining data classifier ensemble trained, chosenones used Read et al. (2008), namely 10 63% respectively. restparameters pruned set approach, namely minimum cardinality (b), minimumsupport (p), percentage features use (N ), threshold label assignment (t)selected jointly based classification performance (F-measure) developmentset. values specific value b chosen 2, 3 5. possiblevalues p tested experiment 3, 5 10. threshold parameter chosenvalues 0.1, 0.2, . . . , 1.0, percentage features, N chosenvalues 10%, 20%, . . . , 100%. Thus 900 parameter combinations feature set,parameter combinations, combination performancedevelopment test set best (in terms F-measure) chosen running systemtest set.Results pruned set approach shown Experiment 6 section Table 4.Here, see best performance combination unigram lexicon word features,better performance using unigrams lexicon words individually. However,performance degraded inclusion bigrams combination. Precisionmuch lower methods, indicates selection labelsets training set 233 reports may adequate.600fiCause Identification via Weakly Supervised Semantic Lexicon Construction6.5 Experiments Using Additional Training Dataresults experiments somewhat surprising: best-performing supervised classification approach One-Versus-All approach performs significantly worsemodified Basilisk approach. hypothesize poor performance attributed scarcity (labeled) training data. test hypothesis, conductedset experiments increased amount training data One-Versus-Allsupervised classification approach applying cross-validation. specifically, taketest set 1000 reports split five disjoint subsets equal size, T1 , T2 , . . . , T5 .Then, construct training set merging Tj , 6= j,original training set 233 reports. that, train SVM classifier mergedtraining set test set Ti . done five folds, computeF-measure entire test set. words, results report setexperiments F-measure scores averaged five folds. experimentedfive set features used supervised experiments Section 6.4. twoparameters, percentage features used classification threshold, tunedexactly way supervised experiments.Results set experiments shown Experiment 7 section Table 4.comparison results Experiment 3, F-measure increases uniformly significantly.provides empirical evidence performance supervised classifiers limitedamount data trained. feature sets 4 (unigramslexicon words) 5 (unigrams, bigrams lexicon words), achieve best resultsF-measure scores 53.56% 53.66% respectively differencestatistically insignificant. two results turn significantly bettermodified Basilisk (row 1 Experiment 2), according approximate randomizationtest. addition, except feature set 3 (lexicon words only), results obtainedexperiment significantly better baseline, according approximaterandomization test. Overall, results suggest difficulty cause identificationtask: comparing rows 4 Experiments 3 5, see F-measure increases6% number training reports increased 233 1033.points deserve mentioning. previous learning-based experiments, using lexicon words features yields worst result set experiments,combining unigrams lexicon words still yields one best results. Nevertheless,comparison Experiment 3, using bigrams still improve performance,hurt performance (from statistical significance point view). Perhapsimportantly, comparing rows 1 4 Experiment 7, see augmenting unigramslexicon words yields significantly better performance. indicates lexiconwords indeed useful features cause identification, usefulness mayrevealed small labeled training set used, seen Experiment 3. Learning algorithms attempt learn features important relevant given classificationtask based training examples see, training examples,better able learn relevance features. results showpoignant illustration phenomenon: SVM learner able use lexicon wordfeatures effectively given large number training instances. seenclearly SVM learning curves Section 6.7.3. indicates lexicon601fiAbedin, Ng & Khanwords useful features sufficiently large training data. However,lexicon words may still used effectively ways linguistic features eventraining set small, see results Experiment 2, useslexicon words combination Occurrence Heuristic achieve performancesstatistically significantly better baseline.6.6 Error Analysis Lessons Learnedorder gain clearer insight cause identification problem help directfuture research, manually analyzed errors made best-performing system (i.e.,heuristic based approach using semantic lexicon learned modified Basiliskframework) randomly chosen 100-report subset test set. specifically,looked false negatives (cases annotator labeled report shapingfactor system not) false positives (cases system labeledreport shaping factor annotator not). false negative, trieddetermine system failed correctly label report, false positive,tried determine system labeled report erroneously. Table 6 showsnumber false positives false negatives along reasons errorsdiscovered analysis. following sections discuss errors reasonsdetail. Note since shaping factor may indicated one keywordsingle report, one reason false negative (positive) error.Thus sum frequencies different types false negative (positive) errors greatertotal number false negatives (positives).Table 6: Error analysis details: different reasons false positive false negativeerrors.False negativesSentence fragments bigger phrasesImplicit causes cannot identified keywordsPhrases learnedFalse positivesKeyword generalKeyword indicates concept appears reportcontribute incidentWrongly learned keywordKeyword used negative contextKeyword used hypothetical context58242314835032Percentage41.38%39.66%24.14%6317.23%3.61%1.20%60.24%38.55%False negatives. false negative error, read report narrative identifyword, phrase sentence fragment may indicate shaping factorsystem missed. analysis, identified three reasons false negativesfollows:602fiCause Identification via Weakly Supervised Semantic Lexicon Construction1. Required sentence fragments larger phrase. identified 24 sentencefragments bigger phrases (i.e., consist two phrases).example, sentence fragment never DCA consists 4phrases: never been, to, DCA before. Together, convey meaningreporter unfamiliar DCA, possible identify singleword phrase conveys meaning. Since framework learnsphrases, possible learn sentence fragments.2. Cause identifiable specific words phrases. 21 instances, specificword, phrase sentence fragment could identified could pinpoint shapingfactors responsible incident. example, number reports, includingreport#566757, describe incidents miscommunicationpilot air traffic controller, miscommunication must understoodfollowing conversation. human reading report easily understandpilot claiming controller said one thing controller claimingsaid something different, detect kind scenario, machine would needgenerate complete model discourse identifies specific topicconversation, participants, claims participant makes topic,fact claims contradictory, also fact contradiction arisesmiscommunication them. preprocessed narrative reportshown Appendix E.3. Missing phrases. 14 cases necessary phrase missing semanticlexicon learned modified Basilisk framework. 14 phrases, sixphrases infrequent considered modified Basilisk framework dueminimum frequency criterion. example, phrase temperature fluxappears entire corpus hence considered system.Two phrases verb phrases, could learned focusedlearning noun phrases adjective phrases. four phrasessemantically similar seed word shaping factors. example,phrase garbled transmission semantically similar seed wordshaping factor Communication Environment, disturbance, static, radiodiscipline, congestion noise. Finally, two phraseslearned system, learned time putword pool, words higher scores selected instead.False positives. case false positives, looked report narrativekeyword found content determine indication shapingfactor incident described report incorrect. different reasonsidentified follows.1. general keywords. observed large number false positives duekeywords general (i.e., keywords extracted learnedshaping factor may appear phrases related shapingfactor). example, keyword failure correct indicator Resource Deficiencyappears text like complete electrical failure, alternator failure, etc.,appears text like failure follow Air Traffic Control instructions,603fiAbedin, Ng & Khanindicate Resource Deficiency shaping factor. identified 50 casescaused keywords general.2. Concept present contributing incident. Another frequently facedproblem sometimes concepts identified keywords presentreport, act shaper incident described report.example, report#324831, reporter mentions flying solo,indication Taskload, incident due Physical Environments, namelysnow foggy weather. fact flying solo merely mentionedpart description overall situation. preprocessed version reportalso given Appendix E. total, observed 32 cases.3. Incorrectly learned words phrases. six cases semantic lexicon learner learned incorrect words phrases relatedshaping factors assigned. example, framework incorrectly learned word shaping factor Resource Deficiency, thusnumber reports mislabeled Resource Deficiency.4. Negative context. three cases keyword appearednegative context, typically signaled contextual valence shifterhardly (Polanyi & Zaenen, 2006). example, keyword aircraft damage, indicator Resource Deficiency, appears report#569901 apparentaircraft damage, results false positive.5. Hypothetical context. one case keyword appearedhypothetical context reporter conjectures possible scenario.keyword single pilot, indicator Taskload, appeared report#534432could happen pilot especially single pilot, resulting false positive.Lessons learned. error analysis provides valuable insight natureproblem well hints one proceed order improve performancesystem. analyzing frequent errors, present following lessonslearned analysis. First all, useful learn high-precision keywordsphrases general ones largest part false positive errors attributedgeneral keywords. However, high-precision keywords phraseslikely low frequencies, hence one would adapt learning methodslearn useful words phrases infrequent ones. Second, one must take accountfact relevant portions text may larger phrases, even goingclause sentences. cannot identified learning words phrases, N-gramsreasonable size. Thus, robust methods needed learn useful sentencefragments useful sentence structures. Finally, cases one cannot hopeidentify using methods look keywords, phrases, sentence fragments even sentencestructures, i.e., cases cause incident understooddiscourse, cases concept present description yet plays partincident. Much deeper analysis simple bag-of-anything models neededavoiding two types errors, represent almost one thirderrors analyzed subset. former needs method distinguish relevant604fiCause Identification via Weakly Supervised Semantic Lexicon Constructionsentences irrelevant ones. example, Patwardhan Riloff (2007) discuss relevantsentence classifier trained small set seed patterns set documentsmarked relevant irrelevant useful context. latter problemrequires discourse analysis method that, discussed earlier, model conversationsidentify relations correctly. shows though possible identify shapingfactors reports using words phrases certain extent, much deeper naturallanguage techniques needed accurately identify full range causes.6.7 Additional Analysessection present outcomes number additional analyses performedcause identification task approaches task. Section 6.7.1 studyrelative difficulties classifying different shaping factors. Sections 6.7.2 6.7.3show learning curves semantic lexicon based approach learning basedapproach respectively, i.e., performances two approaches varyprovided different amounts training data. Finally Section 6.7.4 discussoutcomes experiment conducted determine modifications Basiliskframework useful learning general semantic categories.6.7.1 Per-Class Resultsget insight classes difficult classify, perform analysisper-class performance two labeling schemes: best heuristic-based method (i.e.,Occurrence Heuristic using lexicon learned modified Basilisk framework) [seefirst part Table 7] best learning-based method (i.e., 5-fold SVM classifiersusing unigrams, bigrams lexicon words features) [see second part Table 7].conjunction Table 1, two classes stand prominently difficult classifyIllusion Taskload. classes little representation training,test development sets, small number seed words, result poorperformance approaches. easily identifiable classes PhysicalEnvironment, Physical Factors, Resource Deficiency Preoccupation,labeling schemes F-measures better 40%. general classes betterrepresentation training, testing development sets, also reasonablenumber words phrases semantic lexicon. believe differencecharacteristics classes valuable insight helpful future work.6.7.2 Lexicon Learning Curvementioned Section 2.3.2, used total 177 seed words phrases.first glance, number seeds may seem large far bootstrapping experimentsconcerned. However, considering fact 177 seeds distributed 14shaping factors, average 12.6 words phrases per shaping factor.Nevertheless, would still interesting examine cause identification performanceaffected reduce number seeds shaping factor used ModifiedBasilisk bootstrapping process. result, ran set experiments measurecause identification performance uses semantic lexicon learned Modified Basiliskgiven different number seed words, parameters specific Modified605fiAbedin, Ng & KhanTable 7: Per-class performance results. upper table shows per-class performanceOccurrence Heuristic using lexicon learned modified Basilisk framework.lower table shows per-class performance 5-fold SVM classifiers using unigrams,bigrams lexicon words features.Shaping FactorAttitudeCommunication EnvironmentDuty CycleFamiliarityIllusionPhysical EnvironmentPhysical FactorsPreoccupationPressureProficiencyResource DeficiencyTaskloadUnexpectedOverallTP393310251952278144036004784FN27812319219270133216207147296864TN95788897387299676663895882290272322596597611661FP1322178217977686830268614691Precision18.75%29.03%75.00%28.44%0.00%59.52%66.78%75.86%53.42%17.07%57.14%57.32%0.00%22.22%53.15%Recall10.00%10.00%11.54%62.00%0.00%11.52%73.58%62.86%70.91%46.67%16.19%71.01%0.00%40.00%47.57%F-measure13.04%14.88%20.00%38.99%0.00%19.31%70.02%68.75%60.94%25.00%25.24%63.44%0.00%28.57%50.21%Shaping FactorAttitudeCommunication EnvironmentDuty CycleFamiliarityIllusionPhysical EnvironmentPhysical FactorsPreoccupationPressureProficiencyResource DeficiencyTaskloadUnexpectedOverallTP22010180521822055610239900866FN287016322165831555241451082910782TN96487196292499868562395584896163924797199011638FP63912260981121042911424600714Precision25.00%33.90%45.45%40.91%0.00%34.67%61.90%66.67%56.70%40.00%47.22%61.86%0.00%0.00%54.81%Recall6.67%22.22%38.46%36.00%0.00%23.96%68.68%57.14%50.00%20.00%41.30%78.70%0.00%0.00%52.55%F-measure10.53%26.85%41.67%38.30%0.00%28.34%65.12%61.54%53.14%26.67%44.06%69.27%0.00%0.00%53.66%606fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionBasilisk set described Section 6.3.1. specifically, chose top 3, 4, 5, 6,7, 10, 15 20 seed words phrases shaping factor (in terms frequencyentire corpus), ran modified Basilisk framework ten iterations usingaforementioned parameters.Note, however, shaping factors number manually selectedseed words phrases. example, Illusion, Taskload Unexpected 1, 2 3seed words phrases respectively, whereas Resource Deficiency Physical Environment47 45 respectively (see last column Table 1). Hence, experimentsnumber seeds used shaping factor exceeds number manuallyselected seeds shaper, manually selected seeds used. example, sinceUnexpected three manually selected seeds, used experimentsleast three seeds used shaping factor.Occurrence Heuristic used lexicons thus generated evaluateperformance test set. resulting learning curve, terms F-measuretest set 1000 reports, shown Figure 4. addition, since baselinecompare performance based seed words, baseline learning curvecorresponding reduced seed words set also shown. expected, increasingnumber seed words monotonically improves F-measure. However, improvementbaseline particularly small fewer seven seed words used,highest improvement observed seven seed words phrases. on, addingseeds improves overall performance, improvement baseline slowlydiminishes.Lexicon Learning Curve504846F-measure (%)4442403836BaselinePerformance learned lexicon343230024681012Number Seeds14161820Figure 4: Variation F-measure different number seeds words per category.607fiAbedin, Ng & KhanSVM Learning Curve60F-measure Test Set5856F-measure (%)54525048464442400100200300 400 500 600 700Number Training Instances800900 1000Figure 5: Variation F-measure different number training reports.6.7.3 SVM Learning Curvediscussed Section 6.5, hypothesize failure SVM classifiers perform better baseline due scarcity training instances availablelearner. One may argue SVM shown work well small datasets.So, natural question is: much smaller training set seestatistically significant drop cause identification performance? answer question,plot learning curve One-Versus-All classification approach, using featurescombination unigrams, bigrams, lexicon word features five-fold cross validationsetting, setting yields best performance Table 4. Specifically,generated random subsets training sets sizes 50, 100, . . . , 1000 instances. Parameters, namely percentage features classification threshold, chosenway original experiment described Section 6.5, F-measureevaluated entire test set. curve shown Figure 5, data pointcomputed averaging results five independent runs. see,general trend performance improvement increase number traininginstances. addition, trained 50% training set, see causeidentification system started perform statistically significantly worse systemtrained available instances according stratified approximaterandomization test.608fiCause Identification via Weakly Supervised Semantic Lexicon Construction6.7.4 General Usefulness Modifications Basiliskorder test whether modifications made Basilisk framework usefullexicon learning general, added two general categories shaping factorsbootstrapping experiments, namely People Equipment. two categoriesadded because, firstly, words phrases added categories would easy verify(i.e., whether words phrases representing people equipment), secondly,similar original context Basilisk framework originally evaluated (i.e., learning words categories BUILDING, EVENT, HUMAN, LOCATION,TIME, WEAPON terrorism reports). two additional categories addedseed lexicon described Section 2.3.2, bootstrapped running Original Basilisk Modified Basilisk separately ten iterations, parameters specificBasilisk frameworks set way described Section 6.3.1. seedwords two categories selected manner done ThelenRiloff (2002), i.e., phrases corpus sorted frequency fivefrequent phrases belonging categories manually identified. seedwords used two categories:People: Captain, controller, First Officer, RPTR, passengerEquipment: aircraft, airplane, Collision Avoidance System II, engine, Auto-Pilotorder verify words phrases learned two frameworks correctlybelong assigned category, first author computer science graduate studentaffiliated research went generated lexicons. Appendices F Gshow lexicons generated Original Basilisk Modified Basilisk respectively.facilitate analysis, divide words phrases generated lexicon threecategories: (1) determined correct human judges; (2)determined correct one judge; (3) determined incorrectjudges.lexicon generated Original Basilisk, find category People, 2950 words phrases determined correct judges, 6 determinedexactly one judges correct; category Equipment, 6 50 wordsphrases correct according judges, 22 correct according exactly onejudges. hand, lexicon generated Modified Basilisk, findcategory People, 44 50 words phrases determined correctjudges, 3 determined exactly one judges correct; categoryEquipment, 34 50 words phrases correct according judges, 9correct according exactly one judges. comparison clearly showsmodifications made Basilisk framework specific particulartask; rather, modifications improved lexicon building performance general.6.8 Summary Conclusionsend section providing summary major conclusions drawexperiments.609fiAbedin, Ng & Khanheuristic approach cause identification, labels report using Occurrence Heuristic combination words phrases automatically acquiredusing Modified Basilisk framework, surpasses performance baseline system, applies Occurrence Heuristic combination seed wordsphrases manually identified training documents. difference F-measuretwo systems statistically significant according McNemars teststratified approximate randomization test. suggests wordsphrases semantic lexicon learned via Modified Basilisk relevant effectivecause identification.Adding learned lexicon words N-gram-based feature set training SVMclassifiers beneficial cause identification training set sufficientlylarge, exhibited statistically significant increase F-measure. providessuggestive evidence words phrases semantic lexicon learned viaModified Basilisk relevant useful features cause identification.used combination Occurrence Heuristic, semantic lexicon learnedModified Basilisk framework offers significantly better performancecause identification task one obtained using original Basilisk framework. Additional experiments reveal Modified Basilisk usefulcause identification, also offers performance superior Original Basiliskbootstrapping general semantic categories People Equipment.Among three multi-class multi-labeled text classification approaches experimented with, One-Versus-All works significantly better MetaLabeler PrunedSets cause identification. Transductive learning, used combinationOne-Versus-All approach, significantly hurts performance, suggesting unlabeled data cannot profitably exploited given fairly small amount labeleddata.best system achieves F-measure around 53.7%, indicates causeidentification difficult task, lot room improvement.provide directions future research, performed analysis errors madebest-performing system. particular, found performance currentlylimited part several factors. First, number casesrelevant text indicating responsible shaping factor may larger phrases.Second, indicators shaping factor may mentioned report without influencing incident described report. Finally, casesshaping factors cannot identified simply looking words, phrases evensentence fragments much deeper analysis required cases.Increasing number seed words phrases employed Modified Basilisk improves cause identification performance, marginal performance improvementadded seed diminishes successive additions. words, resultsseem suggest using seed words unlikely improve muchcurrent performance; rather would promising start small numberhigh frequency seeds improve upon bootstrapping process.610fiCause Identification via Weakly Supervised Semantic Lexicon Constructionlearning curve plotted One-Versus-All classification approach showscause identification performance increases number training instances.particular, trained 50% training set, see resulting causeidentification system performs statistically significantly worse one trainedavailable instances.Overall, approaches rely automatically learned lexicon words phrasesadequate cause identification, relevant task. mentioned previously, use motivated labor-intensive procedure NASAresearchers employed manually identifying seed words phrases shaping factor (Posse et al., 2005). work represents one first attempts tackle causeidentification task, believe use simple features good starting pointestablishes baseline future studies problem compared.main take home message research though possible solveproblem set solve, namely automated cause identification, learningrelevant keywords sentence fragments suitable bag-of-words models,remains significant portion data remains unlabeled mislabeledmethods. match performance level achieved topical text classificationtasks, much deeper linguistic analysis like relevant sentence detection discourse analysismethods like identifying disagreements, disputes hostile attitudes needed.lesson cornerstone research area.7. Related Worksection, describe works related research. particular,discussion focuses causal analysis well approaches semantic lexicon construction text classification, organized follows. First, discuss causal analysisappeared different fields. Second, discuss different semantic lexiconlearning algorithms. Third, discuss works deal extraction pattern learning.Fourth, describe different algorithms unsupervised word clustering thesaurusbuilding. Finally, include discussion related work multi-class multi-labeled textclassification.Causal analysis. Major research causality performed mainly fieldsphilosophy psychology. field philosophy, seminal works causalityconducted Hume (1739, 1748), provides one influential definitionscause object followed another, objects, similar first,followed objects similar second. Or, words, where, first objectbeen, second never existed. basis later, much strongerdefinitions causation (e.g., Lewis, 1973; Ganeri, Noordhof, & Ramachandran, 1996).Notable investigations causation field psychology include Cheng (1997),defines causation terms probabilistic contrast model; Griffiths Tenenbaum(2005), discuss learning cause effect relationships using causal graphicalmodels; Halpern Pearl (2005), provide explanations causality meansstructural equations governing random variables representing events. Although611fiAbedin, Ng & Khanworks provide important background definitions contributing understandingcausality, order identify causes naturally written text must turn NLP.field NLP, little work cause identification similar problem.Research causality focuses mainly identifying causal relations two sentencecomponents. instance, Girju (2003) describes method automatically discoveringlexico-semantic patterns refer causation. particular, focuses explicitintra-sentential pattern hN P1 verb N P2 i, verb simple causative. also showspatterns used improve performance system answeringcause-effect type questions. Khoo et al. (2000) use graphical pattern matching identifycausal relations medical article abstracts. use hand-crafted patternsmatched parse trees sentences. subtrees parse tree matchpatterns extracted causes effects. Similarly, Garcia (1997) uses hand-craftedextraction patterns identify causal relations sentences French language.limitation approaches focus identifying causal relationssentence, whereas reports multi-sentence discourses.Grishman Ksiezyk (1990) use domain modeling, discourse analysis causal inference find cause-effect relations events leading equipment malfunctionsshort equipment failure reports. specifically, first apply syntactic analysisproduce parse trees sentences reports using augmented context-freegrammar. apply semantic analysis map (1) verbs syntactic relationsdomain-specific predicates relations (2) noun phrases references componentsdomain model. Finally, apply discourse analysis predicates constructtime-graph showing temporal causal relationships elementary facts.temporal relations derived text structures words (e.g., when, then,etc.) order appearance text, causal relations determined querying simulation model equipment built using domain knowledge. Specifically,possible causal link posed query model test relation holds.Overall, method relies heavily domain model equipment studied,research focuses one specific piece equipment.NASAs research identifying causes incidents report narrativesperformed Posse et al. (2005), describe specific experimentbrought together experts manually analyze report narratives identify words,phrases expressions related shaping factors, mentioned earlier. Laterwork Ferryman et al. (2006) take manually extracted expressions ground truthcompare anomalies described reports shaping factors derivedapplying expressions reports. Specifically, attempt learnexpressions automatically; rather, focus finding possible correlationsshaping factors anomalies.Algorithms semantic lexicon learning. number semantic lexicon learningalgorithms follow iterative bootstrapping approach, starting small numbersemantically labeled seed words. Roark Charniak (1998) propose method constructing semantic lexicons based co-occurrence statistics nouns conjunctions, listsappositives. start small seed nouns list, iteratively add similar wordslist. word similarity measured ratio many times word occur612fiCause Identification via Weakly Supervised Semantic Lexicon Constructiontogether seed word number times word appear corpus.construction, rank words log-likelihood statistic (Dunning, 1993). However,due general brevity reports, co-occurrences lists rathercorpus, useful us use context-based similarities like Thelen Riloff(2002). describe Basilisk framework learning semantic lexicon using extraction patterns features. apply weakly supervised bootstrapping approachstart small manually constructed seed lexicon iteratively add semanticallysimilar words it. This, described detail Section 4.2, basislexicon learning approach.number improvements Basilisk framework, generally bootstrapping approaches, proposed. Basilisk framework, number iterationsparameter chosen arbitrarily. Rather making arbitrary choice,Yangarber (2003) proposes method detecting termination unsupervised semanticpattern learning processes. method requires documents must labeledrelevant irrelevant. Since information available corpus, useful us. Curran, Murphy, Scholz (2007) suggest improvement traditionalbootstrapping methods discarding words contexts appear relatedone category, order minimize semantic drift enforce mutual exclusion.hand, handle cases comparing conditional probabilitiesdifferent categories words belong. Zhang, Zhou, Huang, Wu (2008)present bootstrapping graph mutual reinforcement-based bootstrapping (GMR)(Hassan, Hassan, & Emam, 2006), modification Basilisk method. Similar us,explore using N-grams capture context, use different set patternword scoring formulas. learning multiple categories simultaneously, introducescoring system based entropy pattern. report better results BasiliskMUC-4 dataset (see Sundheim, 1992).Among non-bootstrapping approaches, Ando (2004) presents new method constructing semantic lexicons unannotated corpus using set semantic classes setseed words phrases semantic class. uses spectral analysis improvefeature vectors projecting useful portions vectors subspace removing harmful portions vectors. resultant feature vectors usedcentroid-based classifier using cosine similarity measure label words. Avancini,Lavelli, Sebastiani, Zanoli (2006) take classification approach semantic lexiconconstruction. cast problem term (meaning words phrases) categorization task (dual document categorization task), similar bag-of-wordmodel, represent terms bag-of-documents. use variation adaptiveboosting algorithm, AdaBoost.M H KR , trained small seed lexiconused classify noun terms corpus zero, one semantic categories.Algorithms learning extraction patterns. approach semantic lexicon construction uses extraction patterns features, present methods aimimprove extraction pattern collection process. Riloff (1996) describes AutoSlog-TSsystem learns extraction patterns untagged text. However, needs pre-classifiedcorpus text classified relevant irrelevant; mentioned earlier,access information. Phillips Riloff (2007) present method boot613fiAbedin, Ng & Khanstrapping algorithm learn role-identifying nouns, used learn importantextraction patterns, also role-identifying expressions. However, focus mainlyidentifying roles words events.Patwardhan Riloff (2007) provide another extraction pattern learning approachusing relevant regions. require documents pre-classified relevantirrelevant documents. Using small set seed patterns, classify sentencesdocuments relevant irrelevant sentences. semantically appropriate extraction patterns learned using semantic affinity metric separated primarysecondary patterns. approach also directly usable us due unavailabilitydocuments pre-classified relevant irrelevant categories.Recently, Internet increasingly used natural language research. Patwardhan Riloff (2006) use AutoSlog-TS system (Riloff, 1996) learn domain specificextraction patterns processing documents retrieved querying web selecteddomain-specific words. Using web interesting promising enhancement and,mentioned Section 8, intend extend work using Google corpus (Brants &Franz, 2006).Algorithms thesaurus building unsupervised word clustering. Anotherarea research closely related semantic lexicon learning thesaurus building.Building thesaurus requires discovering groups semantically similar words, thoughstops short assigning semantic class labels words. Thus shares problemmeasuring semantic similarity grouping similar words semantic lexicon buildingtask. discuss several approaches thesaurus building task.Clustering used extensively thesaurus building, mostly unsupervised nature ability handle large volumes data. seminal workdirection Pereira, Tishby, Lee (1993), present unsupervised methodsoft clustering words using distributions words different contexts. approach generates overlapping word clusters, grouping words based contextsappear in. Baker McCallum (1998) use Pereira et al.s distributional clustering technique perform feature space reduction supervised classification nave Bayesusing clusters features. Lin Pantel (2001) present approach generatingcollection sets semantically similar words, concepts, using clustering method,UNICON, dependency relations features. Pantel Lin (2002) present anotherclustering approach, clustering committee, using contextual features point wisemutual information feature values, compare better Lin Pantelsresults. Rohwer Freitag (2004) present clustering-based automatic thesaurus buildingprocess unannotated corpus. propose information theoretic co-clusteringalgorithm groups together highly frequent words clusters similar part-of-speechcategory. pursue additional process, lexicon optimization, grow lexiconassigning less frequent words likely clusters.Among non-cluster-based methods, Davidov Rappoport (2006) present unsupervised method discovering groups words similar meanings. achieve(1) identifying high frequency words content words, (2) identifying symmetriclexical relationship patterns, (3) applying graph clique-set algorithm generate wordcategories co-occurrence information content words symmetric patterns.614fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionConcentrating performance issues plague attempts build thesauruslarge corpus, Rychly Kilgarriff (2007) present two methods improving performancegeneral context-based thesaurus building algorithms. first method compareword pairs context common. second method useheuristic removing contexts general (i.e., contextscertain number distinct words). research, adopted second method(see Section 4.3). also applied partitioned sequential approach constructionprocess. Though thesaurus building usually require annotated corpus setseed words phrases, directly applicable task growing semanticlexicon learn words specific semantic categories.method control words learned classes discoveredword groups belong to. may possible adapt method semantic lexicongrowing classifying word groups semantic classes using seed wordsphrases. However, method extended extract noun adjective phrases.Algorithms multi-class multi-labeled text classification. mentioned previously, cause identification, cast text classification problem, multi-classmulti-labeled text classification problem, since 14 shaping factors totaldocument may labeled one shaping factors. severalpopular approaches solving multi-class multi-labeled text classification problem.first, one approaches followed research, independently train binaryclassifier class, apply classifier test instance isolation.case, underlying learner Support Vector Machines (Joachims, 1998). GodboleSarawagi (2004) suggest number improvements scheme, namely, including classlabels suggested preliminary set classifiers features, removing negative examplesclose classification hyperplane, selectively removing classesone-versus-others classifications scheme. Another notable method, followed TsoumakasVlahavas (2007) Read et al. (2008), treat unique set labelsnew label, thus converting problem multi-class single-labeled one. worksdiffer construction new labels. former, called RAndomk-LabELsets, RAKEL, builds ensemble classifiers randomly sampling label setssize k; whereas latter adopts method filtering observed label sets minimumsupport. Tang et al. (2009), hand, take different approach: train oneclassifier predicts number labels test instance would have, choosemany labels instance based output another classifier ranks labelslikelihood instance. works use SVM underlying learner.addition, approaches make assumption classes correlated highdegree. However, analysis dataset present evidence strongcorrelation. 140 documents multiple labels test set, 68 uniquelabel sets, seven frequency least five. Thus increasing numberlabels would aggravate already imbalanced class distribution.Among approaches, mention two systems use probabilistic generative models. McCallum Nigam (1999) propose system starts small set keywordsunlabeled documents, learns nave Bayes classifier bootstrapping processkeyword-induced labels using hierarchical shrinkage expectation maximization615fiAbedin, Ng & Khanheld-out data set. Ueda Saito (2002) present another generative model called Parametric Mixture Models, treats multi-labeled text parametric mixture wordsrelevant label. work closely related Latent Dirichlet Allocation (Blei,Ng, & Jordan, 2003). generative models usually assume document relatedparticular topic would high frequency words related topic. research,documents mostly devoted description event occurred, causeevent mentioned briefly. makes generative models less suitabletask hand generative models would likely generate models related eventscauses. comprehensive review different approaches multi-classmulti-label text classification found work Tsoumakas Katakis (2007).8. Conclusionsinvestigated two approaches cause identification task, goalunderstand aviation safety incident happened via identification causes,shaping factors, responsible incident. approaches exploit informationprovided semantic lexicon, automatically constructed via Thelen Riloffs(2002) Basilisk framework augmented three algorithmic modifications (namely,use probabilistic similarity measure, use common word pool, enforcement minimum support maximum generality constraints words extractionpatterns) one linguistic modification (the use N-gram-based extraction patterns).heuristic-based approach labels report employing Occurrence Heuristic,simply looks words phrases acquired semantic lexicon learning process report. learning-based approach labels report employing inductivetransductive support vector machines learn models reports labeled shaping factors. experimental results indicate heuristic-based approachsupervised learning approach (when given sufficient training data) significantly outperform baseline, which, motivated NASAs work, labels report simply usingOccurrence Heuristic combination set manually-identified seed wordsphrases. importantly, results heuristic-based approach indicate modifications original Basilisk framework beneficial far cause identificationconcerned, results learning-based approach indicates usefulness lexiconwords used combination unigrams features training SVMclassifier. Overall, set prove possible automate causeidentification task manually analyzing small number reports using information thus generated train machine learning methods identify shaping factorsrest reports. experiments able prove feasibility approach,also usefulness learning semantic lexicon using words features.Nevertheless, best system achieves F-measure around 53.7%, indicatescause identification difficult task, lot room improvement.particular, analysis errors made best system 100 randomly chosen testdocuments provides valuable insights task well directions future research.experience current research, intend extend workfollowing directions. First foremost, plan extend approach handle textfragments bigger phrases. Second, order improve quality labeling,616fiCause Identification via Weakly Supervised Semantic Lexicon Constructionpropose work improving lexicon learning performance using differentsemantic similarity measures. instance, would like study performancesemantic similarities weighting functions suggested Curran Moens (2002)context. Third, plan use thoroughly normalized text better parsingtagging, well relevant region information (Ko, Park, & Seo, 2004; Patwardhan& Riloff, 2007). Fourth, propose augment semantic lexicon, specifically usingGoogle N-grams corpus (Brants & Franz, 2006) extract frequent N-gram patternswords. Fifth, propose explore recent lexicon construction methodslike unsupervised word clustering (Pantel & Ravichandran, 2004), spectral analysis, mutualexclusion bootstrapping, co-clustering exploiting symmetric patterns. Finally, orderhandle shaping factors difficult identify words occurringreports, propose employ much deeper analysis text semantic level.also taken step making annotated incident reports publicly available,hope stimulate research under-investigated problem NLPcommunity.Acknowledgmentsauthors would like thank anonymous reviewers provided us commentsinvaluable improving quality paper. research supportedpart NASA grant NNX08AC35A. opinions, findings, conclusions recommendations expressed paper authors necessarily reflectviews official policies, either expressed implied, NASA.617fiAbedin, Ng & KhanAppendix A: Seed Wordsseed words manually extracted 233 reports training set (seeSection 2.3.2 details).Shaping FactorAttitudeCommunicationEnvironmentDuty CycleFamiliarityIllusionPhysicalEnvironmentPhysical FactorsPreoccupationPressureProficiencyResourceDeficiencyTaskloadUnexpectedSeed wordsget HOMEITIS, attitude, inattentiveness, get THEREITIS, complacency, overconfidence, sarcastic, inattentiondisturbance, static, radio discipline, congestion, noise11 hour duty day, inadequate rest, last 4 legs, heavy flying, reducedrest, all-night flight, 12 hour day, red eye, ten leg day, nightfamiliarization, familiar, new, first departure, unfamiliar, unfamiliarity, familiar, low time, first landingbright lightsnoise abatement policy, disoriented, confused, medical emergency,economic considerations, disorientation, drunk passenger, confusioncold, clouds, dark, setting sun, sun glare, obscured, visibility, hazystratus, birds, fog bank, solid overcast, snow, weather, rime, gust, lowweather, surface winds, jet blast, lightning, sea gulls, high ceilings,hot, tailwind, chop, dark, sea gull, winds, scattered, high tailwinds, extremely dark, bright, icing, turbulence, RPTED wind,terrain, bird strike, crosswind, thunderstorm, glare, reduced visibility, high flying birds, fog, severe winter weather, cloud, icetired, HYPOXIA, tiredness, tired, fatigued, disorientation, fatigue, restdistracted, preoccupied, mental lapse, busy, DISTRS, distraction,attention, inattention, absorbedhurry, running late, pressure, low fuel, fuel considerations, behindschedule, late, peer pressure, pressure, rushingmistakes, mistaken, new hire, inexperience, forgotten, less 100hours, newly rated, training, recent pilot, inadvertently, bad turn,MISINTERPEDloose connection, erratic, blown, overheated, bang, collapse, idea,unavailable, placarded, crack, Service, damage, smoke, inoperative, failure, leak, deferred items, communication failure, loss,unreliable, FDRS problem, bump, shaking, master caution, inadequately lighted, unreadable, disconnected, malfunction, shudder, absence, hazard, inaccurate, UNFLAGGED, fire, broken, fluctuations,compressor stall, deferral, unusable, wrong, intermittently, warning,discrepancies, faulty, deferred, intermittent, missingsingle pilot, solounexpected, suddenly, UNFORECAST618fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionAppendix B: Sample Lexicon Words Learned Modified Basilisksemantic lexicon words learned modified Basilisk frameworkfirst two iterations.Shaping FactorAttitudeCommunicationEnvironmentDuty CycleFamiliarityIllusionPhysicalEnvironmentPhysical FactorsPreoccupationPressureProficiencyResourceDeficiencyTaskloadUnexpectedNew wordsaligned, fairly new, familiarinitial confusion, minimum fuel emergency, misunderstanding,weather emergencyTRWS, conflict message, cumulonimbus, large cells, numerous thunderstorms, occasionally severe, thunderstorm cells, weather buildups,weather cell, weather en routefirst factoradequate attention, much attention, close attention, close enoughattention, crew attention, enough attention, much attention, properattention, strict attention, close attentiondifferent, amiss, awry, obviously wrong, resulting loss, seriouslywrong, slight loss, temporary loss, terribly wrong, wrong619fiAbedin, Ng & KhanAppendix C: Sample Lexicon Words Learned Original Basilisksemantic lexicon words learned original Basilisk framework firsttwo iterations.Shaping FactorAttitudeCommunicationEnvironmentDuty CycleFamiliarityIllusionPhysicalEnvironmentPhysical FactorsPreoccupationNew wordsAir Traffic Control security, aileron yoke displacement, anomalous VFR Omni-Directional Radio Range information, assured TFRavoidance, betrayal, concern urgency, forgetting air carrier X,magnified problem, operational complacency, unseen unknownturbulence9001 noise, BNA runway 31 approach plate, LIGHTSPEED 20Knoise, Non- noise, OVERSPD bell, active noise, clearance deliverytransmission, left engine stall, static Emergency Locator Transmitter, stuck trim elevator movement10 plus 16 layover, 2 different time frames, 3 back-to-back continuous duty trips, 4 hour break, 69 minutes, 8 hour 15 minute flight timeday, Pacific Daylight Time departure, TPA flight, XC15 departure,scheduled 2- leg continuous dutypartial unfamiliarity, perceived familiarity, Command familiarity, Command unfamiliarity, blue panel indication light, dispatchwork desks, generally unfamiliar, inexperience unfamiliarity, neweveryday, past experience familiarity1 1/2 Nautical Mile SSW, 1/2-1/4 point, 10 end, 50 feet side, Elmendorf required use, 1/2 mile downwind, airspace E, foxtrotintersection, lateral boundaries, mile rightmisinformation, Flight Management System/heading anomalies, confusion/conflict, disoriented confused, intense panic, micro sleep,miss numerous times, mistake inconvenience, note closure problem,start terrorMHT class Celsius, STRATO-cumulus, Thur morning, clouds underneath, compacted snow ice, fair weather cumulus, next morningweather, puffy cumulus clouds, thin scattered clouds, well developedcumulus cloudsHYPOXIA/carbon monoxide, Minimum Equipment List 24-32-02,basically tired, cardiac distress, indicating system problem, internalbleeding, interrupted fuel flow, oncoming seizure, stress overload,upper respiratory problemsCaptain First Officer attention, Terminal Radar Approach Control Facility distraction, close enough attention, consequently attention, good enough attention, lip service, mind attention, muchmind, real attention, real close attentionContinued next page620fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionShaping FactorPressureProficiencyResourceDeficiencyTaskloadUnexpectedNew wordsMinimum Equipment List pressure, consistent answer, elevator pressure, intense pressure, part # Coordinated Universal Time, repercussion, right engine pressure, significant pressure, slow gear, wheelpressure& P school, CL65 ground school, basic flight training, hard lesson,initial annual proficiency training, occurrence strive, ratingtraining, several military flying clubs, situation event, time limitedsimulator sessionsAir Traffic Control loss, altitude deviation/loss, apparently inoperative, either inoperative, even reexamining, intermittent inoperative, known traffic conflict loss, observed loss, recently Los,thankfully accurate16500 # turboprop, A320 type aircraft, AVIAT husky A1 two placetail DRAGGER aircraft, Cessna 402 type aircraft, Cessna model421 type aircraft, L1011-250, LGA-MHT flight, McDonnell DouglasMD11, solo cross country FLTS, solo cross country privilegessignificant, 1 jolt, approximately 5-10 sec, choppy aircraft, consistently moderate, contributing workload factor, industry issue,severe, rapid immediate, real cushion621fiAbedin, Ng & KhanAppendix D: Additional Stratified Approximate Randomization TestsMLWOLWSVM-USVM-UBSVM-LSVM-ULSVM-UBLSVMT-USVMT-UBSVMT-LSVMT-ULSVMT-UBLSVM5-USVM5-UBSVM5-LSVM5-ULSVM5-UBLMethodaSWMLWOLWSVM-USVM-UBSVM-LSVM-ULSVM-UBLSVMT-USVMT-UBSVMT-LSVMT-ULSVMT-UBLSVM5-USVM5-UBSVM5-LSVM5-ULSVM5-UBLSWascertain statistical significance difference F-measure scoresdifferent report labeling methods, performed stratified approximate randomizationtest 9,999 shuffles pairs results Experiments 1 5 Table 4.table shows method column statistically significantly bettermethod row level p < 0.05. before, statistical significanceinsignificance denoted X X, respectively.XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-a. Legend: SW = Occurrence Heuristic using seed words, MLW = Occurrence Heuristic using modifiedBasilisk lexicon, OLW = Occurrence Heuristic using original Basilisk lexicon, SVM-U = SVM usingunigrams, SVM-UB = SVM using unigrams bigrams, SVM-L = SVM using lexicon words, SVM-UL= SVM using unigrams lexicon words, SVM-UBL = SVM using unigrams, bigrams lexiconwords, SVMT-U = transductive SVM using unigrams, SVMT-UB = transductive SVM using unigramsbigrams, SVMT-L = transductive SVM using lexicon words, SVMT-UL = transductive SVM usingunigrams lexicons, SVMT-UBL = transductive SVM using unigrams, bigrams lexicon words,SVM5-U = 5-fold SVM using unigrams, SVM5-UB = 5-fold SVM using unigrams bigrams, SVM5-L= 5-fold SVM using lexicon words, SVM5-UL = 5-fold SVM using unigrams lexicon words, SVM5UBL = 5-fold SVM using unigrams, bigrams lexicon words.622fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionAppendix E: Sample Preprocessed ReportsReport ACN#324831RETURNING waukegan regional airport practice area located 5-20 mileW airport; flying solo student pilot; 3000 feet Mean Sea Level VisualFlight Rules. cloud area 5 mile W airport obscured view ahead reducedaltitude proceed Visual Flight Rules returned 3000 feet passing thincloud line. area n; containing fix references airport location; shroudedclouds fog ground level. true lake michigan shorelineE. ground also substantially snow covered. although airspace airportundoubtedly clear; practice area; orientation field lost me.climbed 4500 feet increase overview; without benefit. returning 3000 feet;flew believed n airfield landfall airport. mustS; however; proceeding flew ord class B airspace. coincidinglost; contacted waukegan tower; realizing flown Federal AviationRegulation had. directed contact ord approach frequency given;beginning ord approach vectored back waukegan airport; frequency changedtower control blessedly cleared land. time lost 1 hour 15 minutes1 1/2 hours.Report ACN#566757following event occurred REPOSITIONING; taxi; W sideside isp airport. initially contacted longitude island tower asking permission REPOSW side OPS Base Operations Office tower (the side). controllerreplied start taxi via taxiway W hold short runway 6. read backinstructions stating start taxi via taxiway W holding short runway 6. taxiing;aircraft taxiway W holding short runway 6; performing run-up.controller asked able get around aircraft. replied able.controller said use caution taxiing around aircraft cross runway 6.taxiing across runway 6; noticed aircraft short final runway 6. clearrunway aircraft touched down. controller came frequencysaid instructed hold short runway 6. replied cleared acrossrunway 6. controller said call tower park. replied roger; callpark. called talked controller minutes later saidinstructed hold short runway 6. told cleared acrossrunway. feel pilots controllers need listen deciphersaid acting it.623fiAbedin, Ng & KhanAppendix F: Lexicon Learned Original Basilisk Categories PeopleEquipmentfollowing table shows words phrases learned original Basilisk frameworkcategories people equipment (see Section 6.7.4).CategoryPeopleEquipmentNew wordsAgreed judges correct: ABQ tower procedure specialist, ACN 126721 reporter, AFSFO, AVP tower specialist, Air RouteTraffic Control Center specialist, Air Traffic Control facility reps,BDR tower specialist, BHM control, BUF field operations officer,CAE tower specialist, Chicago quality control, DFW maintenancemanager, Flight Service Station dispatcher, SFOLM Captain,SII program manager, Stearman pilot, TLH supervisor, bur localcontroller, casino manager, cos Air Traffic Control chief, flight testengineers, local balloon repairman, outbound Captain First Officer, repair facility pilot, shift boss, spokesperson, station management individual, technician desk, tower supervisor/managerIdentified one judge correct: Flight Standards DistrictOffice ORL, maintenance supervisor, approach controller verbatim, freighter aircraft approach, tower, passengerfatigueAgreed judges incorrect: ACN 670635, ACN 682482,AT6 aircraft, B737-300/500 SRM, EMB service manual, Non-aircarrier aircraft, RPTR ACN 518698, RPTR ACN 601074, RPTRACN 658075, RPTR ACN 664336, RPTR ACN 676343, RPTR ACN88920, cabin company, aircraft center, reliable research resourcesAgreed judges correct: Collision Avoidance System II 10 Distance Measuring Equipment screen, Collision AvoidanceSystem II B737-200, Collision Avoidance System II EHSI, CollisionAvoidance System II IVSI display, Collision Avoidance System IIMissed Approach Point page, Collision Avoidance System II RR,Continued next page624fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionCategoryNew wordsIdentified one judge correct: Collision Avoidance System II VSI overlay, Resolution Advisory stopped aircraft, Collision Avoidance System II stop climb alert, Collision AvoidanceSystem II traffic ; climb advisory, Collision Avoidance System II traffic ; traffic aural warning, Collision Avoidance SystemII 3 mile circle, Collision Avoidance System II 5 mile scale, Collision Avoidance System II 6 mile scale, Collision Avoidance System II POPUP traffic, Collision Avoidance System II ResolutionAdvisory alerts, Collision Avoidance System II Resolution Advisoryclimb priority, Collision Avoidance System II Resolution Advisoryclimb warning, Collision Avoidance System II Resolution Advisorysignals, Collision Avoidance System II Resolution Advisory zone,Collision Avoidance System II Resolution Advisory/Traffic Advisoryalert, Collision Avoidance System II Resolution Advisory/Traffic Advisory alerts/advisories, Collision Avoidance System II ResolutionAdvisory/altitude deviation, Collision Avoidance System II TrafficAdvisory Resolution Advisory alerts, Collision Avoidance System II WINDSHEAR warning, Collision Avoidance System II advisory alert, Collision Avoidance System II advisory alert warning,Collision Avoidance System II warning aircraftAgreed judges incorrect: Collision Avoidance System II 10 Oclock 2 1/2 3 mile, Collision Avoidance System II Resolution Advisory climb command, Collision AvoidanceSystem II Resolution Advisory area, Collision Avoidance SystemII Resolution Advisory climb descent, Collision Avoidance System II Resolution Advisory data tag, Collision Avoidance SystemII Resolution Advisory descent, Collision Avoidance System II Resolution Advisory green band target, Collision Avoidance System IIResolution Advisory increase climb, Collision Avoidance System IIResolution Advisory maneuvering, Collision Avoidance System IIResolution Advisory messages, Collision Avoidance System II Resolution Advisory recovery procedure, Collision Avoidance SystemII Resolution Advisory requirement, Collision Avoidance System IIResolution Advisory requiring climb, Collision Avoidance SystemII Resolution Advisory resolution, Collision Avoidance System IITraffic Advisory notification, Collision Avoidance System II TrafficAdvisory/Resolution Advisory aircraft, Collision Avoidance SystemII Traffic Advisory/Resolution Advisory event, Collision AvoidanceSystem II action requirements, Collision Avoidance System II advice,Collision Avoidance System II advisories instructions, CollisionAvoidance System II caution, Collision Avoidance System II quit625fiAbedin, Ng & KhanAppendix G: Lexicon Learned Modified Basilisk Categories PeopleEquipmentfollowing table shows words phrases learned modified Basilisk frameworkcategories people equipment (see Section 6.7.4).CategoryPeopleEquipmentNew wordsAgreed judges correct: First Officer, First Officer, ; First Officer, CP, Captain, Captain RPTR, Captain trainee,Co-Captain, Co-pilot, First Officer, First Officer # 2, Initial Operating Experience Captain, PAXS, Pilot Flying First Officer,Potomac controller, RPTING Captain, RPTING First Officer, RPTING pilot, RPTR Captain, RPTR pilot, S/O, ZOA supervisor, aircarrier pilot, aircraft X pilot, aircraft commander, passenger, analyst, First Officer, baron pilot, biplane pilot, controller,facility person, first observer, flight attendant # 3, flight attendantspassenger, flying Captain, forward observer, passenger, passenger crew, passenger flight attendants, right seat pilot, second observer, sic, specialist, student Captain, supervisor/Controller,tower Controller, tower operator, training pilotIdentified one judge correct: RPTR, gate passenger,First OfficerAgreed judges incorrect: departure departure,neither Captain, CLRLYAgreed judges correct: # 1 Auto-Pilot, #2 Auto-Pilot, 3 AUTOPLTS, AUTOFLT, AUTOTHROTTLE,AUTOTHROTTLE Auto-Pilot, AUTOTHROTTLES, AUTOTHROTTLES Auto-Pilot, AUTOTHRUST, Auto-Pilot# 1, Auto-Pilot # 2, Auto-Pilot B, Auto-Pilot AUTOTHRUST, Auto-Pilot PMs, Auto-Pilot throttles, AutoPilot/AUTOTHROTTLES, Cessna 180, Collision Avoidance SystemII system, ENGS # 2 # 3, aircraft ABCD, aircraft Auto-Pilot,aircraft engine, allowed aircraft, automatic pilot, automatic throttle,automatic throttles, autopilot, center Auto-Pilot, craft, emergencyengine, left Auto-Pilot, left hand engine, parked plane, right AutoPilotIdentified one judge correct:problem engine, maintenance aircraft, later aircraft, aircraft aircraft, CollisionAvoidance System II alert, # 1 Constant Speed Drive, Auto-PilotAUTOTHROTTLES, WDB 2, perfAgreed judges incorrect: aircraft beginning, aircraftparallel, normal aircraft, person property, persons property,aircraft, time aircraft626fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionReferencesAndo, R. K. (2004). Semantic lexicon construction: Learning unlabeled data viaspectral analysis. Proceedings 8th Conference Computational NaturalLanguage Learning, pp. 916.Artstein, R., & Poesio, M. (2008). Inter-coder agreement computational linguistics.Computional Linguistics, 34 (4), 555596.Avancini, H., Lavelli, A., Sebastiani, F., & Zanoli, R. (2006). Automatic expansiondomain-specific lexicons term categorization. ACM Transactions SpeechLanguage Processing (TSLP), 3 (1), 130.Baker, L. D., & McCallum, A. K. (1998). Distributional clustering words text classification. Proceedings 21st Annual International ACM SIGIR ConferenceResearch Development Information Retrieval, pp. 96103.Banko, M., & Brill, E. (2001). Mitigating paucity-of-data problem: Exploring effect training corpus size classifier performance natural language processing.Proceedings 1st International Conference Human Language TechnologyResearch.Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. JournalMachine Learning Research, 3, 9931022.Brants, T., & Franz, A. (2006). Web 1T 5-gram Version 1. Linguistic Data Consortium,Philadelphia, USA.Cheng, P. W. (1997). covariation causation: causal power theory. PsychologicalReview, 104 (2), 367405.Chinchor, N. (1992). statistical significance MUC-4 results. Proceedings4th Message Understanding Conference, pp. 3050.Chinchor, N., Hirschman, L., & Lewis, D. D. (1993). Evaluating message understanding systems: analysis Third Message Understanding Conference (MUC-3).Computational Linguistics, 19, 409449.Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine Learning, 20 (3), 273197.Crammer, K., & Singer, Y. (2002). algorithmic implementation multiclass kernelbased vector machines. Journal Machine Learning Research, 2, 265292.Curran, J. R., & Moens, M. (2002). Improvements automatic thesaurus extraction.Proceedings ACL 2002 Workshop Unsupervised Lexical Acquisition, pp.5966.Curran, J. R., Murphy, T., & Scholz, B. (2007). Minimising semantic drift mutualexclusion bootstrapping. Proceedings 10th Conference Pacific Association Computational Linguistics, pp. 172180.627fiAbedin, Ng & KhanDavidov, D., & Rappoport, A. (2006). Efficient unsupervised discovery word categoriesusing symmetric patterns high frequency words. Proceedings 21st International Conference Computational Linguistics 44th Annual MeetingAssociation Computational Linguistics, pp. 297304.Dietterich, T. G. (1998). Approximate statistical tests comparing supervised classification learning algorithms. Neural Computation, 10 (7), 18951923.Dunning, T. (1993). Accurate methods statistics surprise coincidence. Computational Linguistics, 19 (1), 6174.Everitt, B. S. (1977). Analysis Contingency Tables. Chapman Hall.Ferryman, T. A., Posse, C., Rosenthal, L. J., Srivastava, A. N., & Statler, I. C. (2006).happened, why: Toward understanding human error based automatedanalyses incident reports Volume II. Tech. rep. NASA/TP2006-213490, NationalAeronautics Space Administration.Ganeri, J., Noordhof, P., & Ramachandran, M. (1996). Counterfactuals preemptivecausation. Analysis, 56 (4), 219225.Garcia, D. (1997). COATIS, NLP system locate expressions actions connectedcausality links. Proceedings 10th European Workshop KnowledgeAcquisition, Modeling Mangement, pp. 347352.Girju, R. (2003). Automatic detection causal relations question answering. Proceedings ACL 2003 Workshop Multilingual Summarization QuestionAnswering, pp. 7683.Godbole, S., & Sarawagi, S. (2004). Discriminative methods multi-labeled classification.Proceedings 8th Pacific-Asia Conference Knowledge Discovery DataMining, pp. 2230.Griffiths, T. L., & Tenenbaum, J. B. (2005). Structure strength causal induction.Cognitive Psychology, 51, 334384.Grishman, R., & Ksiezyk, T. (1990). Causal temporal text analysis: roledomain model. Proceedings 13th International Conference ComputationalLinguistics, pp. 126131.Halpern, J. Y., & Pearl, J. (2005). Causes explanations: structural-model approach.Part I: Causes. British Journal Philosophy Science, 56, 843887.Hassan, H., Hassan, A., & Emam, O. (2006). Unsupervised information extraction approachusing graph mutual reinforcement. Proceedings 2006 Conference EmpiricalMethods Natural Language Processing, pp. 501508.Hume, D. (1999 (Original work published 1748)). Enquiry Concerning Human Understanding. Oxford University Press, USA.Hume, D. (2000 (Original work published 1739)). Treatise Human Nature. OxfordUniversity Press, USA.Joachims, T. (1999). Advances Kernel Methods - Support Vector Learning, chap. Makinglarge-Scale SVM Learning Practical. MIT-Press.628fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionJoachims, T. (1998). Text categorization suport vector machines: Learning manyrelevant features. Proceedings 10th European Conference Machine Learning, pp. 137142.Joachims, T. (1999). Transductive inference text classification using support vectormachines. Proceedings 16th International Conference Machine Learning,pp. 200209.Kaplan, R., & Berry-Rogghe, G. (1991). Knowledge-based acquisition causal relationshipstext. Knowledge Acquisition, 3 (3), 317337.Kersey, C., Di Eugenio, B., Jordan, P., & Katz, S. (2009). KSC-PaL: peer learning agentencourages students take initiative. Proceedings 4th WorkshopInnovative Use NLP Building Educational Applications, pp. 5563.Khoo, C. S. G., Chan, S., & Niu, Y. (2000). Extracting causal knowledge medicaldatabase using graphical patterns. Proceedings 38th Annual MeetingAssociation Computational Linguistics, pp. 336343.Ko, Y., Park, J., & Seo, J. (2004). Improving text categorization using importancesentences. Information Processing Management, 40 (1), 6579.Krippendorff, K. (2004). Content analysis: introduction methodology. Sage Publications, Inc.Lewis, D. (1973). Causation. Journal Philosophy, 70 (17), 556567.Lin, D. (1998). Dependency-based evaluation MINIPAR. Proceedings LRECWorkshop Evaluation Parsing Systems, pp. 317329.Lin, D., & Pantel, P. (2001). Induction semantic classes natural language text.Proceedings 7th ACM SIGKDD International Conference Knowledge Discovery Data Mining, pp. 317322.Marcus, M. P., Santorini, B., & Marcinkiewicz, M. A. (1993). Building large annotatedcorpus English: Penn Treebank. Computational Linguistics, 19 (2), 313330.Special Issue Using Large Corpora.McCallum, A., & Nigam, K. (1999). Text classification bootstrapping keywords,EM shrinkage. Proceedings ACL Workshop Unsupervised LearningNatural Language Processing, pp. 5258.Noreen, E. W. (1989). Computer-Intensive Methods Testing Hypotheses : Introduction. Wiley.Pantel, P., & Lin, D. (2002). Discovering word senses text. Proceedings 8thACM SIGKDD International Conference Knowledge Discovery Data Mining,pp. 613619.Pantel, P., & Ravichandran, D. (2004). Automatically labeling semantic classes. Proceedings Human Language Technology Conference North American ChapterAssociation Computational Linguistics, pp. 321328.Passonneau, R. (2004). Computing reliability coreference annotation. ProceedingsFourth International Conference Language Resources Evaluation, Vol. 4,pp. 15031506.629fiAbedin, Ng & KhanPatwardhan, S., & Riloff, E. (2006). Learning domain-specific information extraction patterns web. Proceedings COLING/ACL Workshop InformationExtraction Beyond Document, pp. 6673.Patwardhan, S., & Riloff, E. (2007). Effective information extraction semantic affinitypatterns relevant regions. Proceedings 2007 Joint Conference Empirical Methods Natural Language Processing Computational Natural LanguageLearning, pp. 717727.Pereira, F. C. N., Tishby, N., & Lee, L. (1993). Distributional clustering English words.Proceedings 31st Annual Meeting Association Computational Linguistics, pp. 183190.Phan, X.-H. (2006a). CRFChunker: CRF English Phrase Chunker. http://crfchunker.sourceforge.net/.Phan, X.-H. (2006b). CRFTagger: CRF English POS Tagger.sourceforge.net/.http://crftagger.Phillips, W., & Riloff, E. (2007). Exploiting role-identifying nouns expressions information extraction. Proceedings International Conference Recent AdvancesNatural Language Processing.Polanyi, L., & Zaenen, A. (2006). Contextual valence shifters. Computing AttitudeAffect Text: Theory Applications, pp. 110. Springer Verlag.Posse, C., Matzke, B., Anderson, C., Brothers, A., Matzke, M., & Ferryman, T. (2005).Extracting information narratives: application aviation safety reports.Proceedings 2005 IEEE Aerospace Conference, pp. 36783690.Read, J., Pfahringer, B., & Holmes, G. (2008). Multi-label classification using ensemblespruned sets. Proceedings 8th IEEE International Conference DataMining, pp. 9951000.Riloff, E. (1996). Automatically generating extraction patterns untagged text.Proceedings 13th National Conference Artificial Intelligence, pp. 10441049.Roark, B., & Charniak, E. (1998). Noun-phrase co-occurrence statistics semi-automaticsemantic lexicon construction. Proceedings 17th International ConferenceComputational Linguistics, pp. 11101116.Rohwer, R., & Freitag, D. (2004). Towards full automation lexicon construction.Proceedings Computational Lexical Semantics Workshop HLT-NAACL 2004,pp. 916.Rychly, P., & Kilgarriff, A. (2007). efficient algorithm building distributionalthesaurus (and Sketch Engine developments). Proceedings ACL 2007Demo Poster Sessions, pp. 4144.Sebastiani, F. (2002). Machine learning automated text categorization. ACM ComputingSurveys, 34 (1), 147.Sundheim, B. M. (1992). Overview fourth message understanding evaluationconference. Proceedings Fourth Message Understanding Conference, pp. 321.630fiCause Identification via Weakly Supervised Semantic Lexicon ConstructionTang, L., Rajan, S., & Narayanan, V. K. (2009). Large scale multi-label classification viametalabeler. Proceedings International World Wide Web Conference, pp. 211220.Thelen, M., & Riloff, E. (2002). bootstrapping method learning semantic lexiconsusing extraction pattern contexts. Proceedings 2002 Conference EmpiricalMethods Natural Language Processing, pp. 214221.Tsoumakas, G., & Katakis, I. (2007). Multi-label classification: overview. InternationalJournal Data Warehousing Mining, 3 (3), 113.Tsoumakas, G., & Vlahavas, I. P. (2007). Random k -labelsets: ensemble methodmultilabel classification. Proceedings 18th European Conference MachineLearning, Vol. 4701 Lecture Notes Computer Science, pp. 406417.Ueda, N., & Saito, K. (2002). Parametric mixture models multi-labeled text. AdvancesNeural Information Processing Systems 15, pp. 721728.van Delden, S., & Gomez, F. (2004). Retrieving NASA problem reports: case studynatural language information retrieval. Data Knowledge Engineering, 48 (2),231246.Vapnik, V. N. (1998). Statistical Learning Theory. Wiley.Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization. Proceedings 14th International Conference Machine Learning,pp. 412420.Yangarber, R. (2003). Counter-training discovery semantic patterns. Proceedings41st Annual Meeting Association Computational Linguistics, pp.343350.Zaidan, O. F., Eisner, J., & Piatko, C. (2007). Using annotator rationales improve machine learning text categorization. Proceedings Human Language Technology Conference North American Chapter Association ComputationalLinguistics, pp. 260267.Zhang, Q., Zhou, Y., Huang, X., & Wu, L. (2008). Graph mutual reinforcement basedbootstrapping. Information Retrieval Technology, 4993/2008, 203212.631fiJournal Artificial Intelligence Research 38 (2010) 371-413Submitted 2/10; published 7/10Approximate Model-Based DiagnosisUsing Greedy Stochastic SearchAlexander Feldmana.b.feldman@tudelft.nlDelft University TechnologyMekelweg 4, 2628 CD, Delft, NetherlandsGregory Provang.provan@cs.ucc.ieUniversity College CorkCollege Road, Cork, IrelandArjan van Gemunda.j.c.vangemund@tudelft.nlDelft University TechnologyMekelweg 4, 2628 CD, Delft, NetherlandsAbstractpropose StochAstic Fault diagnosis AlgoRIthm, called Safari, tradesguarantees computing minimal diagnoses computational efficiency. empiricallydemonstrate, using 74XXX ISCAS85 suites benchmark combinatorial circuits,Safari achieves several orders-of-magnitude speedup two well-known deterministic algorithms, CDA HA , multiple-fault diagnoses; further, Safari computerange multiple-fault diagnoses CDA HA cannot. also prove Safarioptimal range propositional fault models, widely-used weak-faultmodels (models ignorance abnormal behavior). discuss optimality Safari class strong-fault circuit models stuck-at failure modes. modelingalgorithm Markov chain, provide exact bounds minimality diagnosis computed. Safari also displays strong anytime behavior, return diagnosisnon-trivial inference time.1. IntroductionModel-Based Diagnosis (MBD) area artificial intelligence uses system model,together observations system behavior, isolate sets faulty components (diagnoses) explain observed behavior according minimality criterion.standard MBD formalization (Reiter, 1987) frames diagnostic problem terms setlogical clauses include mode-variables describing nominal fault statussystem components; diagnostic status system computed givenobservation systems sensors. MBD provides sound complete approachenumerating multiple-fault diagnoses, exact algorithms guarantee finding diagnosis optimal respect number faulty components, probabilistic likelihood,etc.biggest challenge (and impediment industrial deployment) computationalcomplexity MBD problem. MBD problem determining exists diagnosis k faults NP-hard arbitrary propositional models considerarticle (Bylander, Allemang, Tanner, & Josephson, 1991; Friedrich, Gottlob, & Nejdl,1990). Computing set diagnoses harder still, since possibly exponenc2010AI Access Foundation. rights reserved.fiFeldman, Provan, & van Gemundtially many diagnoses. Since almost proposed MBD algorithms completeexact, authors proposing possible trade-offs completeness fasterconsistency checking employing methods BCP (Williams & Ragno, 2007),complexity problem still remains major challenge MBD.overcome complexity problem, propose novel approximation approachmultiple-fault diagnosis, based stochastic algorithm. Safari (StochAstic Fault diagnosis AlgoRIthm) sacrifices guarantees optimality, diagnostic systemsfaults described terms arbitrary deviation nominal behavior, Safaricompute diagnoses several orders magnitude faster competing algorithms.contributions follows. (1) paper introduces approximation algorithmcomputing diagnoses within MBD framework, based greedy stochastic algorithm.(2) show compute minimal-cardinality diagnoses weak fault modelspolynomial time (calling incomplete SAT-solver implements Boolean ConstraintPropagation1 (BCP) only), general frameworks (such sub-class strongfault models) also amenable class algorithm. (3) model Safari searchMarkov chain show performance optimality trade-offs algorithm makes.(4) apply algorithm suite benchmark combinatorial circuits, demonstrating order-of-magnitude speedup two state-of-the-art deterministic algorithms, CDAHA , multiple-fault diagnoses. (5) compare performance Safarirange Max-SAT algorithms benchmark problems. results indicate that,whereas search complexity deterministic algorithms tested increases exponentially fault cardinality, search complexity stochastic algorithm appearsindependent fault cardinality. Safari great practical significance,compute large fraction minimal-cardinality diagnoses discrete systems largecomplex diagnosed existing deterministic algorithms.2. Technical Backgrounddiscussion continues formalizing MBD notions. paper uses traditionaldiagnostic definitions (de Kleer & Williams, 1987), except use propositional logicterms (conjunctions literals) instead sets failing components.Central MBD, model artifact represented propositional formulaset variables. Discerning two subsets variables assumable observable 2variables gives us diagnostic system.Definition 1 (Diagnostic System). diagnostic system DS defined triple DS =hSD, COMPS, OBSi, SD propositional theory set variables V , COMPSV , OBS V , COMPS set assumables, OBS set observables.Throughout paper assume OBS COMPS = SD 6|=.propositional theories used system descriptions interest MBD. Diagnostic systems characterized restricted set models, restriction making problem1. formulae Conjunctive Normal Form (CNF), BCP implemented unit resolutionrule.2. MBD literature assumable variables also referred component, failure-mode,health variables. Observable variables also called measurable, control variables.372fiApproximate Model-Based Diagnosis Using Greedy Stochastic Searchcomputing diagnosis amenable algorithms like one presented paper.consider two main classes models.Definition 2 (Weak-Fault Model). diagnostic system DS = hSD, COMPS, OBSi belongsclass WFM iff COMPS = {h1 , h2 , . . . , hn }, SD equivalent (h1 F1 ) (h2F2 ) . . . (hn Fn ) COMPS V = , V set variables appearingpropositional formulae F1 , F2 , . . . , Fn .Note conventional selection sign health variables h1 , h2 , . . . hn . Alternatively, negative literals, e.g., f1 , f2 , . . . , fn used express faults, caseweak-fault model form (f1 F1 ) . . . (fn Fn ). authors use ababnormal ok healthy.Weak-fault models sometimes referred models ignorance abnormalbehavior (de Kleer, Mackworth, & Reiter, 1992), implicit fault systems. Alternatively,model may specify faulty behavior components. following definition,aim simplifying formalism throughout paper, adopt slightly restrictiverepresentation faults, allowing single fault-mode per assumable variable.easily generalized introducing multi-valued logic suitable encodings (Hoos, 1999).Definition 3 (Strong-Fault Model). diagnostic system DS = hSD, COMPS, OBSi belongsclass SFM iff SD equivalent (h1 F1,1 ) (h1 F1,2 ) . . . (hn Fn,1 )(hn Fn,2 ) 1 i, j n, k {1, 2}, {hi } COMPS, F{j,k} propositionalformula, none hi appears Fj,k .Membership testing WFM SFM classes performed efficiently manycases, example, model represented explicitly Def. 2 Def. 3.2.1 Running Exampleuse Boolean circuit shown Fig. 1 running example illustratingnotions algorithms paper. subtractor, shown there, consists sevencomponents: inverter, two or-gates, two xor-gates, two and-gates. expressionh (o i) models normative (healthy) behavior inverter, variables i,o, h represent input, output health respectively. Similarly, and-gate modeledh [o (i1 i2 )] or-gate h [o (i1 i2 )]. Finally, xor-gate specifiedh [o (i1 i2 )].propositional formulae copied gate Fig. 1 variablesrenamed way properly connect circuit disambiguate assumables,thus obtaining propositional formula Boolean subtractor, given by:SDw = {h1 [i (y p)]} {h2 [d (x i)]} [h3 (j p)][h4 (m l j)] [h5 (b k)] [h6 (x l)][h7 (k p)](1)strong-fault model Boolean circuit shown Fig. 1 constructed assigningfault-modes different gate types. assume that, malfunctioning,output xor-gate value one inputs, or-gate stuck-at-one,373fiFeldman, Provan, & van Gemundxph1h3jh2h5bh6lh4h7kFigure 1: subtractor circuitand-gate stuck-at-zero, inverter behaves like buffer. gives usfollowing strong-fault model formula Boolean subtractor circuit:SDs = SDw [h1 (i y)] [h2 (d x)] (h3 j)(h4 m) (h5 b) [h6 (x l)] (h7 k)(2)models (SDs SDw ), set assumable variables COMPS = {h1 , h2 , . . . , h7 }set observable variables OBS = {x, y, p, d, b}.2.2 Diagnosis Minimal Diagnosistraditional query MBD computes terms assumable variables explanations system description observation.Definition 4 (Health Assignment). Given diagnostic system DS = hSD, COMPS, OBSi,assignment variables COMPS defined health assignment.health assignment conjunction propositional literals. cases convenient use set negative positive literals . two sets denotedLit () Lit + (), respectively.example, nominal assignment 1 = h1 h2 . . . h7 . healthassignment 2 = h1 h2 h3 h4 h5 h6 h7 means two and-gates Fig. 1malfunctioning. follows formal definition consistency-based diagnosis.Definition 5 (Diagnosis). Given diagnostic system DS = hSD, COMPS, OBSi, observation , instantiation variables OBS, health assignment ,diagnosis iff SD 6|=.Traditionally, authors (de Kleer & Williams, 1987) arrive minimal diagnosis computing minimal hitting set minimal conflicts (broadly, minimal health assignmentsincompatible system description observation), paper makesuse conflicts, hence equivalent, direct definition above.total 96 possible diagnoses given SDw observation 1 = x pb d. Example diagnoses 3 = h1 h2 . . . h7 4 = h1 h2 h3 . . . h7 .Trivially, given weak-fault model, faulty health assignment (in example374fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search= h1 . . . h7 ) diagnosis instantiation observable variables OBS(cf. Def. 2).analysis algorithm need opposite notion diagnosis, i.e., healthassignments inconsistent model observation. MBD literatureassignments usually called conflicts. Conflicts, however, necessarily instantiatevariables COMPS. paper always use full health instantiations, useterm conflict avoided prevent confusion.MBD literature, range types preferred diagnosis proposed.turns MBD problem optimization problem. following definitionconsider common subset-ordering.Definition 6 (Minimal Diagnosis). diagnosis defined minimal, diagnosisexists Lit ( ) Lit ( ).Consider weak-fault model SDw circuit shown Fig. 1 observation2 = x p b d. example, two minimal diagnoses 5 =h1 h2 h3 h4 h5 h6 h7 6 = h1 h2 . . . h5 h6 h7 . diagnosis7 = h1 h2 h3 h4 h5 h6 h7 non-minimal negative literals 5 formsubset negative literals 7 .Note set minimal diagnoses characterizes diagnoses weak-faultmodel, hold general strong-fault models (de Kleer et al., 1992).latter case, faulty components may exonerate other, resulting healthassignment containing proper superset negative literals another diagnosisdiagnosis. example, given SDs 3 = x p b d, follows8 = h1 h2 h3 h4 . . . h7 diagnosis, 9 = h1 h2 h3 h4 . . . h7diagnosis, despite fact negative literals 9 form supersetnegative literals 8 .Definition 7 (Number Minimal Diagnoses). Let set (SD ) contain minimal diagnoses system description SD observation . number minimaldiagnoses, denoted | (SD )|, defined cardinality (SD ).Continuing running example, | (SDw 2 )| = 8 | (SDs 3 )| = 2. numbernon-minimal diagnoses SDw 2 61.Definition 8 (Cardinality Diagnosis). cardinality diagnosis, denoted ||,defined number negative literals .Diagnosis cardinality gives us another partial ordering: diagnosis defined minimalcardinality iff minimizes number negative literals.Definition 9 (Minimal-Cardinality Diagnosis). diagnosis defined minimalcardinality diagnosis exists | | < | |.cardinality minimal-cardinality diagnosis computed system description SDobservation denoted MinCard (SD ). example model SDwobservation 4 = x p b d, follows MinCard (SDw 4 ) = 2. Notecase minimal diagnoses also minimal-cardinality diagnoses.375fiFeldman, Provan, & van Gemundminimal cardinality diagnosis minimal diagnosis, opposite need hold.general case, minimal diagnoses minimal-cardinality diagnoses. Consider example SDw 2 given earlier section, two resultingminimal diagnoses 5 6 . two, 5 minimal-cardinality diagnosis.Definition 10 (Number Minimal-Cardinality Diagnoses). Let set (SD ) contain minimal-cardinality diagnoses system description SD observation .number minimal-cardinality diagnoses, denoted | (SD )|, definedcardinality (SD ).Computing number minimal-cardinality diagnoses running example results| (SDw 2 )| = 2, | (SDs 3 )| = 2, | (SDw 4 )| = 4.2.3 Converting Propositional Formulae Clausal Formapproach related satisfiability, Safari uses SAT solver. SAT solvers commonly accept input Conjunctive Normal Form (CNF), although exist SATsolvers work directly propositional formulae (Thiffault, Bacchus, & Walsh, 2004).Converting propositional formula CNF done (Tseitin, 1983) without(Forbus & de Kleer, 1993) introduction intermediate variables. cases important structural information lost, may lead performance degradationchecking formula consistent computing solution.Lemma 1. fault-model SD = F1 F2 . . . Fn (SD WFM SD SFM)n = |COMPS| component variables converted CNF time O(|COMPS|)time converting largest subformula Fi (1 n) CNF.Proof (Sketch). conversion SD CNF done (1) converting subformulaFi CNF (2) concatenating resulting CNFs final CNF equivalent SD.complexity (1) O(n) complexity (2) is, worst-case, O(2m ) < ,largest number variables subformula Fi . result, total timeconverting SD dominated linear |COMPS|.Lemma 1 useful cases subformula Fi small. case manypractical situations SD composed small component models. also caseexperimental benchmark (cf. Sec. 6) model combinational circuitconjunction fault models simple logic gates (x-bit and-gates, typically x < 10,xor-gates, etc.). Ideally, Safari would use non-CNF SAT solver, practical reasonsconstrained reasoning diagnostic models concise CNF encodings.Consider, example, formula (x1 y1 ) (x2 y2 ) (xn yn ),Disjunctive Normal Form3 (DNF) and, converted CNF, 2n clauses. Althoughsimilar examples propositional formulae exponentially many clauses CNFrepresentations easy find, artificial rarely encountered MBD.Furthermore, Boolean circuits tested performance Safarishow exponential blow-up converted CNF.3. Note DNF formulae also propositional formulae.376fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search2.4 Complexity Diagnostic Inferencesection discusses complexity problems interested, namelyproblem computing single set minimal diagnoses, using two minimalitycriteria, subset-minimality () cardinality-minimality (). assume input CNFformula defined variable set V , = |COMPS| assumable (or fault)variables. Table 1 introduces notation use define 4 types diagnosis.Table 1: Summary definitions types diagnosis interestSymbolDiagnoses11Preference Criterion(subset-minimality)(cardinality-minimality)(subset-minimality)(cardinality-minimality)complexity computing set diagnoses harder computing singlediagnosis, since number diagnoses is, worst case, exponential input size(number components). problem bounded problem countingnumber diagnoses. problem shown #co-NP -Complete (Hermann& Pichler, 2007).restrict clauses Horn definite Horn, reduce complexityproblems solving, expense decreased model expressiveness.Horn-clause restriction, SD WFM, determining first minimal diagnosis existsP . restriction, SD SFM, deciding first minimal diagnosisexists NP-hard (Friedrich et al., 1990). cases (SD WFM, SFM) decidingnext diagnosis exists NP-hard.diagnosis problems interest article intractable worst-case.complexity closely-related problem, Propositional Abduction Problems (PAPs),studied Eiter Gottlob (1995). show propositional PAP,problem determining solution exists P2 -complete. Computing minimal diagnosissearch problem, hence difficult pose decision question provingcomplexity results. Consequently, one note computing diagnosis minimalrespect / requires O(log |COMPS|) calls NP oracle (Eiter & Gottlob,1995), asking oracle step diagnosis containing k faulty componentsexists.Results abduction problems indicate task approximate diagnosis intractable. Roth (1996) addressed problems abductive inference, approximating inference. Roth focuses counting number satisfying assignmentsrange AI problems, including instances PAPs. addition, Roth showsapproximating number satisfying assignments problems intractable.Abdelbar (2004) studied complexity approximating Horn abduction problems,showing even particular Horn restriction propositional problem interest,approximation problem intractable. particular, abduction problemcosts assigned assumables (which used model preference-ordering ),377fiFeldman, Provan, & van Gemundexamined complexity finding Least Cost Proof (LCP) evidence(OBS), cost proof taken sum costs hypothesesmust assumed order complete proof. problem shownNP -hard approximate LCP within fixed ratio r cost optimal solution,r < 0.Safari approximates intractable problems denoted Table 1. showWFM, Safari efficiently compute single diagnosis minimal usingsatisfiability oracle. SD SFM, Safari generates sound possibly sub-optimaldiagnosis (or set diagnoses). referred papers indicating intractableapproximate, within fixed ratio, minimal diagnosis. following, adoptstochastic approach cannot provide fixed-ratio guarantees. However, Safari tradesoptimality efficiency compute diagnoses high likelihood.3. Stochastic MBD Algorithmsection discuss algorithm computing multiple-fault diagnoses using stochastic search.3.1 Simple Example (Continued)Consider Boolean subtractor shown Fig. 1, weak-fault model SDw given (1),observation 4 preceding section. four minimal diagnoses associatedSDw 4 are: 1 = h1 h2 h3 h4 h5 h6 h7 , 2 = h1 h2 h3 h4 h5 h6 h7 ,3 = h1 h2 . . . h6 h7 , 4 = h1 h2 h3 . . . h6 h7 .nave deterministic algorithm would check consistency 2|COMPS| possible health assignments diagnostic problem, 128 case running example.Furthermore, deterministic algorithms first enumerate health assignments smallcardinality high priori probability, renders algorithms impracticalsituations minimal diagnosis higher cardinality. performancesurprising even using state-of-the art MBD algorithms utilize, example conflict learning, partial compilation, considering bad worst-case complexity findingminimal diagnoses (cf. Sec. 2.4).follows, show two-step diagnostic process requires fewer consistency checks. first step involves finding random non-minimal diagnosis startingpoint (cf. Sec. 3.2 details computing random SAT solutions equal likelihood).second step attempts minimize fault cardinality diagnosis repeatedmodification diagnosis.first step find one random, possibly non-minimal diagnosis SDw 4 .diagnosis obtain classical DPLL solver modifying two ways: (1)determine instance satisfiable also extract satisfying solution(2) find random satisfiable solution every time solver invoked. modificationstrivial, DPLL solvers typically store current variable assignments easychoose variable value randomly (according uniform distribution) insteaddeterministically branching. latter modification may possibly harm DPLLvariable value selection heuristics, later paper see378fiApproximate Model-Based Diagnosis Using Greedy Stochastic Searchconcern type problems considering diagnostic systems typicallyunderconstrained.subtractor example call DPLL solver SDw 4 inputconsider random solution (and obviously diagnosis) 5 = h1 h2 h3 h4 h5h6 h7 (|5 | = 4). second step stochastic algorithm, try minimize5 repetitively choosing random negative literal, flipping value positive (thusobtaining candidate smaller number faults), calling DPLL solver.new candidate diagnosis, try improve newly discovered diagnosis,otherwise mark attempt failure choose another negative literal.constant number failures (two example), terminate searchstore best diagnosis discovered far process.changing sign h7 5 discover new health assignmentconsistent SDw 4 , hence diagnosis discard it. Instead,algorithm attempts changing h6 h6 5 , time successfully obtaining newdiagnosis 6 = h1 h2 h3 h4 h5 h6 h7 cardinality 3. Next algorithmtries find diagnosis even smaller cardinality randomly choosing h1 h76 , respectively, trying change sign, attempts return inconsistency.Hence climb aborted 6 stored current best diagnosis.Repeating process another random initial DPLL solution, gives us new diagnosis 7 = h1 h2 h3 h4 h5 h6 h7 . Changing sign h7 , again, leadsinconsistency, next two flips (of h4 h2 ) lead double-fault diagnosis8 = h1 h2 . . . h6 h7 . diagnosis 8 improvedminimal. Hence next two attempts improve 8 fail 8 stored result.process illustrated Fig. 2, search 6 left 8 right.Gates shown solid black suspected faulty health assignmentparticipate tested consistency, inconsistent candidates crossed-out.Let us consider result. found two diagnoses: 6 8 , 6minimal diagnosis. done price 11 calls DPLL subroutine.suboptimal diagnosis 6 value cardinality near one minimaldiagnosis. Hence demonstrated way find approximation minimaldiagnoses, drastically reducing number consistency checks comparisondeterministic algorithm, sacrificing optimality. Next formalize experiencealgorithm, behavior analyze extensively section follows.Diagnosing strong-fault model known strictly difficult weak-faultmodel (Friedrich et al., 1990). many diagnostic instances problem alleviatedfact exist, although without guarantee, continuities diagnostic searchspace similar one weak-fault models. Let us discuss process findingminimal diagnosis subtractors strong-fault model SDs observation 2 (bothSec. 2.1).six distinct diagnoses 9 , . . . , 14 SDs 2 shown Fig. 3.9 10 minimal |9 | = |10 | = 3. visible Fig. 3 diagnosescomponent variables h2 h5 false, h1 h7 true (healthy). Hence,satisfying assignment SDs 2 would contain h1 h2 h5 h7 . Startingmaximal-cardinality diagnosis 14 , must flip variables h3 , h4 , h6 orderreach two minimal diagnoses. key insight that, shown Fig. 3, always379fiFeldman, Provan, & van GemundFigure 2: example stochastic diagnostic processh291314h291114h5h4h6h3h1h7h5h4h6h3h1h7h2101214h2101314h5h4h6h3h1h7h5h4h6h3h1h7Figure 3: Diagnoses strong-fault modelpossible flipping single literal time health faulty receiving anotherconsistent assignment (diagnosis).follows formalize experience far stochastic algorithmfinding minimal diagnoses.3.2 Greedy Stochastic AlgorithmAlgorithm 1 shows pseudocode Safari.380fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchAlgorithm 1 Safari: greedy stochastic hill climbing algorithm approximatingset minimal diagnoses1: function Safari(DS, , M, N ) returns trieinputs: DS = hSD, COMPS, OBSi, diagnostic system, term, observation, integer, climb restart limitN , integer, number trieslocal variables: SDcnf , CNFm, n, integers, , termsR, set terms, result2:SDcnf WffToCNF(SD)3:n = 1, 2, . . . , N4:RandomDiagnosis(SDcnf , )Get random SAT solution.5:m06:<7:ImproveDiagnosis()Flip unflipped health variable.8:SDcnf 6|=Consistency check.9:10:m011:else12:mm+113:end14:end15:unless IsSubsumed(R, )16:AddToTrie(R, )17:RemoveSubsumed(R, )18:end unless19:end20:return R21: end functionSafari accepts two input parameters: N . N independent searchesstart randomly generated starting points. algorithm tries improvecardinality initial diagnoses (while preserving consistency) randomly flipping fault literals. change sign literal done one direction only: faultyhealthy. attempt find minimal diagnosis terminates unsuccessful attempts improve current diagnosis stored . Thus, increasing leadbetter exploration search space and, possibly, diagnoses lower cardinality,decreasing improve overall speed algorithm.Safari uses number utility functions. WffToCNF converts propositionalformula SD CNF (cf. Sec 2.3). ImproveDiagnosis subroutine takes termargument changes sign random negative literal . negativeliterals, function returns original argument.381fiFeldman, Provan, & van Gemundimplementation RandomDiagnosis uses modified DPLL solver returningrandom SAT solution SD . Consider original DPLL algorithm (Davis, Logemann,& Loveland, 1962) without unit resolution rule. One show if, eventbranching, algorithm chooses unassigned variables polarity equalprobability, DPLL algorithm equally likely compute satisfiable solution (ifexists). Note order variables assigned matter. course,DPLL algorithm may end-up partial assignment, i.e., variablesdont care. problem partial assignment extendedfull satisfiable assignment randomly choosing signs unassigned variablesuniform distribution. Taking consideration unit resolution rule,change likelihood modified DPLL solver finding particular solutionchanges order variables assigned. formal proof modifiedDPLL solver computes SAT assignment equal probability beyond scopepaper, idea build probabilistic model progress DPLL solver.probabilistic model balanced tree nodes iterate branching performingunit resolution (assigning values zero unit clauses). branching probabilityset equal leaf nodes (SAT solutions) equal depth, one showequal likelihood arriving SAT solution. up-to-date SAT solvers basedDPLL, creating randomized DPLL solver computes satisfiable solutionequal probability difficult. course, random polarity decisions may effect negativelybranching heuristics (Marques-Silva, 1999) analysis also beyond scopepaper.Similar deterministic methods MBD, Safari uses SAT-based procedurechecking consistency SD. increase implementation efficiency Safari,combine BCP-based LTMS engine (McAllester, 1990) full-fledged DPLL solvertwo-stage consistency checking. Experimentation shows combining LTMS DPLLway allows order-of-magnitude Safari speed-up compared pure DPLL,soundness completeness properties consistency checking preserved.implemented two-stage consistency checking follows. First, Safari callsBCP-based LTMS (Forbus & de Kleer, 1993) check SD |=. resultUNSAT candidate diagnosis.4 LTMS result UNSAT,means consistency candidate unknown call complete DPLLengine needed. full DPLL checking use POSIT (Freeman, 1995) MiniSat(Een & Sorensson, 2003).Safari benefits two-stage SAT procedure typical MBD instanceinvolves many consistency checks (O(|COMPS|2 ) N = 1, = |COMPS|). SDchange search time small number assumption clausesupdated, incremental nature LTMS greatly improves search efficiency.Even though DPLL running time per instance LTMS (DPLL performsBCP unit propagation), DPLL construction expensive avoidedpossible. DPLL initialization typically slow involves building data structuresclauses variables, counting literals, initializing conflict databases, etc.hand, implementation LTMS incremental (does reinitialized4. shown BCP consistency check SD returns UNSAT, formulaUNSAT (the opposite necessarily true).382fiApproximate Model-Based Diagnosis Using Greedy Stochastic Searchconsistency check) efficient maintains counters clause.counter keeps number unassigned literals. Assigning value variablerequires decrementing clause counters. counter becomes zero,contradiction handler signaled.guarantee two diagnostic searches, starting random diagnoses,would lead minimal diagnosis. prevent this, store generateddiagnoses trie R (Forbus & de Kleer, 1993), straightforward extractresulting diagnoses recursively visiting nodes. diagnosis added trie Rfunction AddToTrie, iff subsuming diagnosis contained R (the IsSubsumedsubroutine checks condition). adding diagnosis resulting trie R,diagnoses contained R subsumed removed call RemoveSubsumed.3.3 Basic Properties Greedy Stochastic Searchcontinue topics completeness optimality, show Safarisound, i.e., returns diagnoses only.Lemma 2 (Soundness). Safari sound.Proof (Sketch). consistency check line 8 Alg. 1 guarantees termsholds SD 6|= added result set R. According Def. 5terms diagnoses.One key factors success proposed algorithm exploitationcontinuity search-space diagnosis models, continuity meanmonotonically reduce cardinality non-minimal diagnosis. exploitation continuity property, Safari configured guarantee finding minimaldiagnosis weak fault models polynomial number calls satisfiability oracle.hypothesis comes next well studied prior work (de Kleer et al., 1992),determines conditions minimal diagnoses represent diagnosesmodel observation. paper interested hypothesis computationalviewpoint: defines class models possible establish theoretical boundoptimality performance Safari.Hypothesis 1 (Minimal Diagnosis Hypothesis). Let DS = hSD, COMPS, OBSi diagnostic system diagnosis arbitrary observation . Minimal Diagnosis Hypothesis (MDH) holds DS iff health assignment Lit () Lit ( ),also diagnosis.easy show MDH holds weak-fault models. theoriesSD 6 WFM MDH holds (e.g., one directly construct theory conjunctionterms MDH holds). Unfortunately, necessary condition known MDHhold arbitrary SD. lemma comes next direct consequence MDHweak-fault models.Lemma 3. Given diagnostic system DS = hSD, COMPS, OBSi, SD WFM,diagnosis observation , follows non-minimal iff another diagnosisobtained changing sign exactly one negative literal .383fiFeldman, Provan, & van GemundProof (Sketch). Def. 2 SD WFM, follows minimal diagnosis,diagnosis obtained flipping one positive literal also diagnosis. Applyingargument direction gives us statement.Safari operates performing subset flips non-minimal diagnoses, attempting compute minimal diagnoses. next formalize notion flips, order characterizeSafari able compute minimal diagnosis.Definition 11 (Subset Flip ). Given diagnostic system DS = hSD, COMPS, OBSihealth assignment non-empty set negative literals (Lit () 6= ), subsetflip turns one negative literals positive literal, i.e., creates healthassignment one positive literal.next characterize flips based whether produce consistent models flip.Definition 12 (Valid Subset Flip). Given diagnostic system DS = hSD, COMPS, OBSi,observation , non-minimal diagnosis , valid flip exists performsubset flip create SD 6|=.Given notions, define continuity diagnosis search space terms literalflipping.Definition 13 (Continuity). system model SD observation satisfy continuityproperty respect set diagnoses (SD), iff diagnosis k (SD)exists sequence = h1 , 2 , , k1 , k , k+1 , , n i, =1, 2, , n 1, possible go i+1 via valid subset flip, (SD ),n (SD ).definition allows trivial continuity cases model observation lead minimal diagnoses (no non-minimal diagnoses). see Sec. 6,models observations diagnoses minimal rare practice (of course,problems created artificially). Note Safari algorithm still workstheoretical properties preserved even case trivial continuity.Given Def. 13, easily show following two lemmata:Lemma 4. SD satisfies MDH, satisfies continuity property.Proof. Follows directly Hypothesis 1 Def 13.Lemma 5. SD WFM satisfies continuity property.Proof (Sketch). straightforward show SD WFM SD satisfies MDH.Lemma 4 follows SD satisfies continuous property.greedy algorithm starts initial diagnosis randomly flips faulty assumable variables. use MDH property show that, starting non-minimaldiagnosis , greedy stochastic diagnosis algorithm monotonically reduce sizeseed diagnosis obtain minimal diagnosis appropriately flipping faultvariable faulty healthy; view flipping search, search continuous diagnosis space.384fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchProposition 1. Given diagnostic system DS = hSD, COMPS, OBSi, observation ,SD WFM, Safari configured = |COMPS| N = 1 returns one minimaldiagnosis.Proof. diagnosis improvement loop starts, worst case, health assignmentconjunction negative literals only. Necessarily, case, diagnosisSD WFM. diagnosis subsumed would foundconsistency checks (provided exists) set equal number literalsrepetitions randomly choosing literal flip next. If,trying negative literals , diagnosis, Lemma 3 followsminimal diagnosis.simple inductive argument, continue process obtainminimal diagnosis.Proposition 1 follows upper bound O(|COMPS|) consistencychecks finding single minimal diagnosis. practical cases, however,interested finding approximation minimal-cardinality diagnoses. resultcomplexity optimally configured Safari algorithm becomes O(|COMPS|2 S),number minimal-cardinality diagnoses given observation. Section 5discusses detail computation multiple minimal-cardinality diagnoses.number assumable variables system practical significance may exceedthousands, rendering optimally configured Safari computationally expensive.Sec 4 see computationally efficient configure < |COMPS|,still possible find minimal diagnosis high probability.simple show flip-based search algorithms complete continuous diagnosis search spaces given weak fault models, i.e., SD WFM, models followMDH, i.e., Lemma 3. formally characterize guarantee finding minimal diagnosis Safari terms continuous diagnosis space. Note sufficient,necessary, condition; example, may configure Safari flip multiple literalstime circumvent problems getting trapped discontinuous diagnosis spaces.Theorem 1. Given diagnostic system DS = hSD, COMPS, OBSi, starting diagnosis, Safari configured = |COMPS| N = 1 guaranteed compute minimaldiagnosis diagnosis space continuous.Proof. Given initial diagnosis , Safari attempts compute minimal diagnosisperforming subset flips. diagnosis space continuous, know existssequence valid flips leading minimal diagnosis. Hence Safari guaranteed findminimal diagnosis .Finally, show Safari provides strong probabilistic guarantee computingminimal diagnoses.Theorem 2. probability Safari, configured = |COMPS|, computingminimal diagnoses diagnostic system DS = hSD, COMPS, OBSi observationdenoted Pr . Given continuous diagnosis space (SD, ), holds Pr 1N .385fiFeldman, Provan, & van GemundProof (Sketch). Since (1) search space continuous, (2) step non-zeroprobability flipping unflipped literal, (3) polynomial upper boundsteps (|COMPS|) computing diagnosis, Safari compute non-minimal diagnosisnon-zero probability. Hence N , Safari compute minimal diagnoses.3.4 Complexity Inference Using Greedy Stochastic Searchnext look complexity Safari, stochastic approach computing soundincomplete diagnoses. show primary determinant inference complexity consistency checking. Safari randomly computes partial assignment ,checks extended create satisfying assignment consistencycheck, i.e., checks consistency SD. solving satisfiability problem (SAT), NP-complete (Cook, 1971). show use incompletesatisfiability checking reduce complexity, cost completeness guarantees.following, call complexity consistency check, assumecomponents fail, i.e., = |COMPS|.Lemma 6. Given diagnostic system DS = hSD, COMPS, OBSi SD WFM,worst-case complexity finding minimal diagnosis O( 2 ), costconsistency check.Proof. upper bound succeeding consistency checks finding singleminimal diagnosis since maximum steps computing healthydiagnosis. Safari performs consistency check flip stepalgorithm must flip literals, total complexity O( 2 ).practical cases, however, interested finding approximation minimal-cardinality diagnoses.result complexity optimally configured Safari||algorithm becomes , || cardinality minimal-cardinalitydiagnoses given observation (cf. Sec. 6.6).complexity BCP well-known, allowing us get precise boundsworst-case complexity computing one minimal-diagnosis Safari. followsassume SD represented CNF (cf. Sec. 2.3).Lemma 7. Given diagnostic system DS = hSD, COMPS, OBSi, SD WFM, SDc clauses n variables, worst-case complexity WFM findingminimal diagnosis O( 2 cn) using BCP consistency checks.5Proof (Sketch). implementation BCP (Forbus & de Kleer, 1993) maintains totalc counters number unsatisfied literals clause. consistency check requiresdecrementing counters n variables SD. gives us upperbound O(cn) execution time BCP. Combining complexity BCPLemma 6 gives us desired result.5. efficient implementations BCP exist (Zhang & Stickel, 1996).386fiApproximate Model-Based Diagnosis Using Greedy Stochastic Search4. Optimality Analysis (Single Diagnosis)contrast deterministic algorithms, Safari algorithm absolute guarantee optimum solution (minimal diagnosis) found. provideintuition behind performance Safari algorithm means approximate,analytical model estimates probability reaching diagnostic solution specificminimality.4.1 Optimality Safari Weak-Fault Modelsstart considering single run algorithm without retriesassume existence one minimal diagnosis. Next, extend modelconsidering retries.4.1.1 Basic ModelConsider diagnostic system DS = hSD, COMPS, OBSi SD WFM,observation manifests one minimal diagnosis . argumentfollows configure Safari = 1, N = 1, assume startingsolution trivial faulty diagnosis.Safari randomly chooses faulty variable flips it, sayingsuccess new candidate diagnosis, failure otherwise. Let k denotenumber steps algorithm successfully traverses direction minimaldiagnosis cardinality ||. Thus k also measures number variables whose valuesflipped faulty healthy process climbing.Let f (k) denote probability distribution function (pdf) k. followingderive probability p(k) successfully making transition k k + 1. diagnosisstep k k positive literals |COMPS| k negative literals. probabilitynext variable flip successful equals probability next negative positiveflip H k negative literals conflict negative literal belongingdiagnosis solution . Consequently, || k literals COMPS| || k literalsallowed flip, therefore success probability equals:p (k) =|||COMPS| || k=1|COMPS| k|COMPS| k(3)search process modeled terms Markov chain depicted Fig. 4,k equals state algorithm. Running inconsistency modeledtransitions state denoted fail.probability exactly attaining step k (and subsequently failing) given by:f (k) = (1 p(k + 1))kp(i)(4)i=0Substituting (3) (4) gives us pdf k:k||||1f (k) =|COMPS| k + 1|COMPS|i=0387(5)fiFeldman, Provan, & van Gemundk=01 p(0)p(0)k=11 p(1)p(1)k=21 p(2)p(i)k=ip(n 1)1 p(i + 1)k=n1failFigure 4: Model Safari run = 1 single diagnosis (n = |COMPS| ||)optimum goal state k = |COMPS| || failure probability term (5) correctequals unity.p independent k, f would geometrically distributed, implieschance reaching goal state k = |COMPS||| slim. However, fact p decreasesk moves probability mass tail distribution, works favorreaching higher-k solutions. instance, single-fault solutions (|| = 1) distributionbecomes uniform. Figure 5 shows pdf problem instances |COMPS| = 100increasing fault cardinality ||. order decrease sampling noise, empirical f (k)values Fig. 5 computed taking average 10 samples k.0.10.1|| = 1|| = 5|| = 100.08|| = 1|| = 5|| = 100.08f(k)0.06f(k)0.060.040.040.020.020020406080100k0020406080100kFigure 5: Empirical (left) analytic (right) f (k) retries single diagnosisnext section show retries move probability mass towardsoptimum, increasing tail distribution, needed (almost always) reachingoptimality.4.1.2 Modeling Retriessection extend model account retries, profound effectresulting pdf f . Again, consider transition step k k + 1,algorithm spend = 1, . . . , retries exiting failure.388fiApproximate Model-Based Diagnosis Using Greedy Stochastic Searchseen algorithm (cf. Alg. 1), variable flip produces inconsistency retryexecuted incremented.elementary combinatorics compute probability diagnosisflipping different negative literals step k. Similar (3), stage k|COMPS| k faulty literals chosen (as variable flips leadinginconsistency recorded attempted again, difference choosingvariables advance one another). probability advancing stagek stage k + 1 becomes:||p (k) = 1|COMPS|k(6)progress Safari modeled values > 1 Markov chain, similarone shown Fig. 4 transition probability p replaced p . resultingpdf number successful steps becomes:#"k||||(7)1 |COMPS|if (k) = |COMPS|k+1i=0seen (5) restricted case (7) = 1.retry effect shape pdf profound. Whereas single-fault solutionsshape = 0 uniform, = 1 probability mass already locatedoptimum k = |COMPS| ||. Fig. 6 plots f number problem instancesincreasing . expected, effect extremely significant. Note casereal system, = |COMPS| pdf would consist single, unit probability spike|COMPS| ||.Although unable find analytic treatment transition model above,graphs immediately show large probability moving k = |COMPS| ||large. Hence, expect pdf considerable probability mass locatedk = |COMPS| ||, depending relative |COMPS|.4.2 Optimality Safari Strong-Fault Modelsanalysis seen WFM easy, starting non-minimaldiagnosis, reach subset minimal diagnosis. discussed detail below,necessarily case strong-fault models. many practical cases, however,strong-fault models exhibit, least partially, behavior similar MDH, thus allowing greedyalgorithms like Safari achieve results close optimal values.4.2.1 Partial Continuity Strong-Fault Stuck-At Modelsfollows restrict attention large subclass SFM, called SFSM(Struss & Dressler, 1992).Definition 14 (Strong-Fault Stuck-At Model). system DS = hSD, COMPS, OBSi belongs class SFSM iff SD equivalent (h1 F1 ) (h1 l1 ) (hnFn ) (hn ln ) 1 i, j n, {hi } COMPS, Fj propositional formula,none hi appears Fj , lj positive negative literal Fj .389fiFeldman, Provan, & van GemundM=2M=20.040.04|| = 5|| = 100.03f(k)f(k)0.030.020.010|| = 5|| = 100.020.01020406080010002040kM=410060801000.12|| = 5|| = 100.1|| = 5|| = 100.10.08f(k)0.08f(k)80M=40.120.060.060.040.040.020.02060k020406080100k002040kFigure 6: Empirical (left) analytic (right) f (k) multiple retries single diagnosisMDH (cf. Hypothesis 1) hold SFSM models. Consider adder whose inputsoutputs zeroes, whose gate models stuck-at-1 faulty.case, nominal assignment diagnosis, but, example, stuck-at-1 output gatediagnosis (there contradiction zero output).Many practical observations involving SFSM models, however, lead partial continuity. means groups diagnoses differ one literal, i.e.,flip based search improve cardinality diagnosis. next formalize notion.Definition 15 (Partial Continuity). system model SD observation satisfypartial continuity property respect set (SD ), iff every diagnosissatisfying Lit () \ Lit (i ) exists finite sequence valid subsetflips .one extreme spectrum, SD satisfy partial continuity propertyrespect set diagnoses extreme, partial continuity390fiApproximate Model-Based Diagnosis Using Greedy Stochastic Searchproperty satisfied respect singleton (consider, example, SD WFMconsists single faulty diagnosis).Note continuous property trivally satisfied respect diagnosisk (SD ), i.e., always exists sequence containing k ( = hk i).interested non-trivial cases, || > 1.Consider system SD observation satisfy partial continuity propertyrespect diagnosis k . say diagnoses flip sequencecontains k form continuous subspace. Alternatively, given diagnostic system SDobservation , continuous diagnostic subspace SD set diagnoses (SD)property that, diagnosis , another diagnosis|Lit ()| |Lit ()| = 1.Unfortunately, general SFSM case, cannot derive bounds sizescontinuous subspaces, hence, optimality Safari. follows,help examples, illustrate fact partial continuity dependsmodel observation express optimality Safari functiontopologically-dependent property. Later, Sec. 6, collect empirical data continuoussubspaces leading near-optimal diagnoses exist class benchmark SFSM circuits.first example illustrates notion discontinuity (lack partial continuityrespect diagnoses). show rare example model observationleading set diagnoses contains diagnoses cardinality + q (q > 1),diagnoses cardinality + 1, + 2, , + q 1.Discontinuity Example Consider, example, Boolean circuit shown Fig. 7modeled propositional formula:[h1 (y x)] [h1 (y x)](8)SDd =[h2 (y x)] [h2 (y x)]observation = x y. Note, SDd 6 SFSM. exactly two diagnosesSDd : 15 = h1 h2 16 = h1 h2 . Note model cannot singlefaults. 15 minimal, |15 | = 0, |16 | = 2, algorithm starts 16possible reach minimal diagnosis 15 performing single flips. Similarlyconstruct models impose arbitrarily bad bound optimality Safari.models, however, common see greedy algorithm performswell wide class strong-fault models.h1xh2Figure 7: two inverters circuitObviously, continuity distribution cardinalities set diagnoses necessary (but sufficient) condition Safari progress. models impose arbitrarydifficulty Safari, leading suboptimal diagnoses cardinality.391fiFeldman, Provan, & van GemundExample Partial Continuity continue running example started Sec. 2.First, create system description SDsa SFSM model. Let SDsa = SDw SDf ,SDw given (1). second part SDsa , strong fault description SDf ,specifies output faulty gate must stuck-at-1:SDf = (h1 i) (h2 d) (h3 j) (h4 m)(h5 b) (h6 l) (h7 k)(9)clear SDsa SFSM. next compute diagnoses SDsa 1 (1 = xp b d). one minimal diagnosis SDsa 1 5 = h1 h2 h3 h7(cf. Fig. 8). choose two literals h3 h4 5 change signs h3h4 , create two new health assignments: 15 = h1 h2 h3 h4 h5 h6 h716 = h1 h2 h3 h4 h5 h6 h7 . checked 15 16diagnoses, i.e., SDsa 1 15 6|= SDsa 1 16 6|=. Note 15 16diagnoses weak-part model, i.e., {15 , 16 } (SDw 1 ). followsMDH fact 5 minimal diagnosis SDw 1 . Furthermore, 15 alsodiagnosis strong-fault stuck-at model (15 (SDsa 1 )) SDw 1 h3lead contradictory value j strong-fault part SDf . similar argumentapplies 16 : SDw 1 h4 contradict SDf . Equivalently, negating h35 , makes j stuck-at-1, results diagnosis, negating h4 5 , makesstuck-at-1, also results diagnosis, negating h3 h4 5 also resultdiagnosis (consider fact fault mode h4 sets only, imposeconstraints j). argument extended similarly h5 , h6 , h7 . Hence,assignment COMPS containing h1 h2 diagnosis SDsa 1 , mattercombination signs take h3 , h4 , h5 , h6 , h7 . Note health assignmentcontaining h4 diagnosis conditioned k = 1.x=1y=1p=1h2d=0h6h1i=1l=0h4h3m=0j=1h5b=1h7k=1Figure 8: Continuous subspace strong-fault, stuck-at-1 model subtractorConsider alternative way computing set ambiguous diagnoses SDsa 1 . GivenSDsa 1 5 , compute consistent assignment internal variables (for examplepropagation). exactly one assignment = j k l m,SDsa 1 5 6|= (cf. Fig. 8). Note components h1 , h3 , h5 , h7 ,change state component (healthy faulty) lead different outputvalue. example output j h3 or-gate 1 gate healthy392fiApproximate Model-Based Diagnosis Using Greedy Stochastic Searchinputs 1 j would also 1 stuck-at-1 or-gate (h3 ). result, diagnosticreasoner determine components dashed region Fig. 8 healthy faulty(stuck-at-1). Equivalently, one change signs h3 , h5 , h7 diagnosis 5resulting assignments still diagnoses. call set components modeledh1 , h3 , h5 , h7 ambiguity group. Clearly, Safari start diagnosis17 = h1 h2 h3 h4 h5 h6 h7 (|17 | = 4) reach 5 (|5 | = 1)performing valid subset flips.make reasoning precise, restrict class SFSM models exclude malformed circuits ones disconnected inputs outputs, etc. Furthermore,assume component exactly one output (the set component output variables denoted COUT). latter big restriction multi-output componentmodels replaced multiple components, single output.6Definition 16 (Well-Formed Diagnostic System (Wfds)). diagnostic system DS =hSD, COMPS, OBSi well-formed (DS Wfds) iff observationdiagnosis (SD ), exactly one assignment component outputsCOUT SD 6|=.Consider SFSM model SD = (h1 F1 ) (h1 l1 ) (hn Fn ) (hn ln ).denote COMPS set hi (1 n) respective li literalsnegative (cf. Def. 14), i.e., COMPS set components whose failure modes stuckat-0. Similarly, use COMPS+ set component variables whose stuck-at li literalspositive (COMPS COMPS+ = COMPS, COMPS COMPS+ = ). Wfds,observation diagnosis force output component either negativepositive value. denote set health variables whose respective componentoutputs forced negative values G (DS, , ). Similarly, G+ (DS, , )components whose outputs positive values. define notioncomponent ambiguity group.Definition 17 (Component Ambiguity Group). Given system DS = hSD, COMPS, OBSi,SD SFSM, SD Wfds, observation , diagnosis (SD), componentambiguity group U(DS, , ), U COMPS, defined U(DS, , ) = {G (DS, , )COMPS } {G+ (DS, , ) COMPS+ }.Finally, show component ambiguity group leads continuous subspace.general case cannot say much size component ambiguity groups.experimentation, noticed difficult assign inputs SFSMvalues generate small continuous subspaces (either SD |=, SD leadslarge component ambiguity groups). course, possible consider adder,multiplier, example, whose inputs zeroes whose gate models stuck-at-1faulty, number inputs/circuit combinations small.Proposition 2. diagnostic system SD, SD SFSM, SD Wfds, observationentail continuous diagnostic subspaces.6. multi-output Boolean function replaced composition single-output Boolean functions.393fiFeldman, Provan, & van GemundProof. Def. 16 fact SD Wfds follows output valuessubset components sign models stuck-at value. denoteset COMPS , COMPS COMPS. health assignment differs signscomponents belonging COMPS also diagnosis. set diagnoses SDcontains possible assignments assumables COMPS diagnoses formcontinuous space (cf. Def. 17).best illustrate Proposition 2, consider or-gate modeled h3 Fig. 8. output1 either gate healthy one gates inputs 1, gatestuck-at-1. situation, possible determine component healthyfaulty.Clearly, |U(DS, , )| lower bound progress Safari stuck-at models.shown Safari starts diagnosis maximum cardinalitygiven subspace, Safari guaranteed (for = |COMPS|) improve cardinalityleast |U(DS, , )|. practice, Safari proceed even stuckat ambiguity groups one factor diagnostic uncertainty. stuck-at componenteffectively disconnects inputs outputs, hence gates fan-in regionconstrained. instance, continuing example, h5 , predecessors coneh5 (components h3 , h4 , h5 , h6 , h7 ) constitute continuous health subspace.Contrary component ambiguity group, set conditional health stateanother component. thorough study stuck-at continuity outside scopepaper shall see Sec. 6, continuous subspaces justify Safari experimentsstuck-at models.4.2.2 Performance Modeling Stuck-At Modelsstudy optimality Safari strong-fault models, first define casealgorithm cannot improve non-minimal diagnosis changing signfaulty literal. Note existence cases sufficient condition Safarisuboptimal, possible reach minimal diagnosis first changing signfaulty literal, thus circumventing missing diagnosis.preceding section know number invalid flips dependk, i.e., determined observation vector fault modes. probabilitySafari progress non-minimal diagnosis becomesp(k) = 1||+|X||COMPS|k(10)|X| number invalid flips. ratio number invalid flips |X||COMPS| call SFM density d. density gives average probability tryinginvalid flip throughout diagnostic search. approximation probabilitysuccess Safari is:p(k) = 1|||COMPS|k394(11)fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchPlugging p (4) allows us predict f (k) SFM models assumptionshold. pdf, measured implementation Safari generated (4)(11) shown Fig. 9 different values density d.= 4, |COMPS| = 100, || = 10= 4, |COMPS| = 100, || = 100.120.12d=0= 0.1= 0.25= 0.50.10.08f(k)f(k)0.080.060.060.040.040.020.0200204060d=0= 0.1= 0.25= 0.50.180100k0020406080100kFigure 9: Empirical (left) analytic (right) f (k) various diagnostic densities, multipleretries single diagnosisFig. 9 visible increasing density leads shift probabilitydensity length walk k left. effect, however, profoundeven large values d, easily compensated increasing , discussedpreceding sections.interesting note bounds computed SD (independent ),bounds used improve performance Safari.4.3 Validationpreceding sections illustrated progress Safari synthetic circuitsexposing specific behavior (diagnoses). remainder section plot pdfgreedy search one small benchmark circuits (for information74181 model cf. Sec. 6).progress Safari weak-fault model 74181 circuit shown Fig. 10.chosen difficult observation leading minimal diagnosis cardinality 7 (left)easy observation leading single fault diagnosis (right). plots showprobability mass shifts right increasing effect profoundsmaller cardinality.effect stuck-at-0 stuck-at-1 fault modes (SFM) probabilitysuccess Safari shown Fig. 11.Obviously, case effect increasing smaller, although still dependingdifficulty observation vector. Last, even small values , absoluteprobability Safari finding minimal diagnosis sizeable, allowing use Safari395fiFeldman, Provan, & van Gemund74181, || = 774181, || = 10.50.5M=1M=1M=20.4M=20.4M=30.3M=30.30.20.20.10.1001020M=4f(k)f(k)M=430k4050030604050k6070Figure 10: Empirical f (k) weak-fault model 74181 circuit observationsleading two different minimal-cardinality diagnoses various74181, || = 6, S-A-074181, || = 6, S-A-10.20.2M=10.15M=40.10.05020M=20.15M=3f(k)f(k)M=1M=2M=3M=40.10.053040k50600102030405060kFigure 11: Empirical f (k) stuck-at-0 stuck-at-1 strong-fault models 74181circuit variouspractical anytime algorithm always returns diagnosis, optimalitydepends time allocated computation.5. Optimality Analysis (Multiple Diagnoses)preceding section described process computing one diagnosis Safari (N =1). section discuss use Safari computing (or counting) minimalcardinality diagnoses (N > 1). rest section assume Safariconfigured = |COMPS|.396fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchConsider system description SD (SD WFM) observation . numberminimal diagnoses | (SD )| exponential |COMPS|. Furthermore, practice, diagnosticians interested sampling set minimal-cardinality diagnoses(SD ) (recall (SD ) (SD )) minimal-cardinality diagnosescover significant part posteriori diagnosis probability space (de Kleer, 1990).follows, see Safari well suited task.Theorem 3. probability Safari configured = |COMPS| computing minimal diagnosis cardinality || system |COMPS| component variables approaches|COMPS||| |COMPS|/|| .Proof (Sketch). Assume minimal diagnosis cardinality || exists. Proposition 1follows Safari configured = |COMPS| guaranteed compute minimaldiagnoses. Starting faulty assignment, consider step k improvingdiagnosis cardinality. state k contains one diagnosis, state k+1, Safarieither (1) flip literal belonging diagnosis (note literal may belongone diagnosis) subsequently prevent Safari reaching diagnosis(2) flip literal belonging diagnosis already invalidated (i.e., oneliterals flipped earlier step).probability solution cardinality || survives flip iteration k (i.e.,invalidated) is:p (k) = 1|COMPS| || k||=|COMPS| k|COMPS| k(12)Similarly basic model (Sec. 4.1.1), probability diagnosis survivesreturned algorithm:|COMPS|||1f (|COMPS| || 1) =|COMPS|||1p(i) =i=0i=0|COMPS| |||COMPS|(13)Rewriting right hand side Eq. (13) gives us:f (|COMPS| || 1) =(|COMPS| ||)!||!(|COMPS| ||)!=(|| + 1)(|| + 2) |COMPS||COMPS|!(14)Since1(|COMPS| ||)!=|COMPS|!(|COMPS| || + 1)(|COMPS| || + 2) |COMPS|(15)holds(|COMPS| ||)!= |COMPS||||COMPS|!|COMPS|/||lim(16)result, small || relative |COMPS|,f (|COMPS| || 1) = ||!|COMPS|||gives us theorem.397(17)fiFeldman, Provan, & van Gemunddistribution hi (||) cardinalities minimal diagnoses (SD ) dependstopology SD ; i.e., create SD hi (||). denotecardinality distribution minimal diagnoses computed Safari h(||).Theorem 3 gives us termination criterion Safari used enumeratingcounting minimal-cardinality diagnoses. Instead running SafariP fixed N ,sufficient compute area output distribution functionh. valuePconverge single value, hence terminate Safari changehdrops fixed threshold. Note Safari efficient enumerating minimalcardinality diagnoses, computed probability exponentially higherprobability computing minimal diagnoses higher-cardinality, shownTheorem 3.Corollary 1. Safari computes diagnoses equal cardinality equal probability.Proof (Sketch). Theorem 3 follows probability success f Safaricomputing diagnosis depends || actual composition .corollary gives us simple termination criterion Safari casesminimal diagnoses also minimal-cardinality diagnoses; provencase minimal-cardinality diagnoses computed probability.see that, given input cardinality distribution hi (||), Safari producesoutput distribution h(||) highly skewed right, due Theorem 3. facilitatestudy Safari transforms hi (||) h(||) use Monte Carlo simulationSafari. advantage Monte Carlo simulation much simpler analysingrun-time behavior Safari studying algorithm itself.Algorithm 2 Monte Carlo simulation Safari1: function SafariSimulate(, N ) returns cardinality distributioninputs: , set minimal diagnosesN , integer, number trieslocal variables: hi , h, vectors, cardinality distributionsb, vector, fault distribution, n, i, c, integers2:hi CardinalityDistribution( )3:n 1, 2, . . . , N4:c 1, 2, . . . , |hi |5:b[c] c hi [c]6:end7:1, 2, . . . , | |8:c DiscreteInverseRandomValue Pb b9:b[c] b[c] c10:end11:h[c] h[c] + 112:end13:return h14: end function398fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchAlgorithm 2 simulates diagnoses input set minimal diagnosesreached Safari N tries. auxiliary subroutine CardinalityDistributioncomputes input distribution hi iterating diagnoses . store inputcardinality distribution hi resulting cardinality distribution h vectors (notevector sums lines 7 8 division vector scalar line 8).outermost loop Alg. 2 (lines 3 12) simulates N runs Safari. donecomputing updating auxiliary vector b, contains distributioncomponent variables according cardinalities diagnoses variablesbelong to. Initially, b initialized number literals single faults position 1,number literals double faults position 2 (for example three doublefaults hi , b[2] = 6), etc. done lines 4 6 Alg. 2. assume diagnosesshare literals. restriction easily dropped counting assumablesinput (the latter assumption change results section).Lines 7 10 simulate process actual bit flipping Safari. stepsimulation draws random literal probability distribution function (pdf ) Pb b ;done DiscreteInverseRandomValue function line 8. bit flipinvalidates diagnosis set , i.e., diagnosis cardinality c cannot reachedSafari. diagnosis invalidated, vector b updated, example,simulation invalidates quadruple fault, b[4] = b[4] 4 (line 9). Note numberiterations loop lines 7 10 equals number diagnoses . resultterminating loop, value integer variable c equal cardinalitylast invalidated diagnosis. latter diagnosis Safari computesrun. remains update resulting pdf right cardinality (line 11).simulation Alg. 2 links distribution actual diagnosesdistribution cardinalities diagnoses returned Safari. arbitrarily set, apply Alg. 2 range typical input distributions. resultssimulation well results running Safari synthetic problemsinput distributions shown Fig. 12.Fig. 12 shows (1) Alg. 2 predicts actual behavior Safari (compare secondthird column plots), (2) Safari computes diagnoses small cardinalityagreement Theorem 3. case output distribution steepexponential cardinalities set input minimal diagnoses grow exponentially. Table 2 summarizes parameters exponential fits input cardinalitydistributions shown Fig. 12 (a initial (zero) cardinality, decay constant,R2 coefficient determination). seen Safari suited computingmultiple diagnoses small probability occurrence. next section providealternative argument leading similar conclusions.6. Experimental Resultssection discusses empirical results measured implementation Safari. order compare optimality performance Safari various diagnostic algorithms,performed million diagnosis computations 64 dual-CPU nodes belonging cluster. node contains two 2.4 GHz AMD Opteron DP 250 processors4 Gb RAM.399fiFeldman, Provan, & van Gemunddegenerate inputprediction (model)0.501h(||)1h(||)h(||)10.50050||10000.5050||1000050||100h(||)h(||)0.20.120exponential input10||0h(||)h(||)20||400prediction (model)0.3510||0.20.10400.3h(||)h(||)h(||)020||SAFARI0.400.500reverse exponential input0.22010.54010||SAFARI020||0.1prediction (model)000.22010.2100000.450||0.3010||0SAFARI0.30.051000.5prediction (model)0.150||SAFARIh(||)h(||)h(||)0.5001normal inputh(||)10010h(||)50||prediction (model)100.50uniform input0SAFARI0.20.105||10005||Figure 12: Predicted actual cardinality distributions40010fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchTable 2: Fit coefficients exponential goodness fit cardinality distributionFig. 12R257642369 4703850.440.344.260.3310.9910.95Input DistributionUniformNormalExponentialReverse Exponentialdefault configuration Safari (when stated otherwise) = 8 N = 4;is, Safari configured maximum number 8 retries givingclimb, total 4 attempts. provide precise average run-time optimalityperformance data, stochastic algorithms (i.e., ones based SLS Max-SAT Safari)repeatedly run 10 times model observation vector.6.1 Implementation Notes Test Set Descriptionimplemented Safari approximately 1 000 lines C code (excluding LTMS,interface, DPLL code) part Lydia package.7Traditionally, MBD algorithms tested diagnostic models digital circuitslike ones included ISCAS85 benchmark suite (Brglez & Fujiwara, 1985).models derived ISCAS85 large (from traditional diagnostic perspective),also considered four medium-sized circuits 74XXX family (Hansen, Yalcin,& Hayes, 1999). order provide weak- strong-fault cases, translatedcircuit weak, stuck-at-0 (S-A-0), stuck-at-1 (S-A-1) model. stuck-atmodels, output faulty gate assumed constant (cf. Def. 14).performance diagnostic algorithms depends various degrees observationvectors (algorithm designers strive produce algorithms, performancedependent observation vectors). Hence, performed experimentationnumber different observations model. implemented algorithm(Alg. 3) generates observations leading diagnoses different minimal-cardinality,varying 1 nearly maximum respective circuits (for 74XXX modelsmaximum). experiments omit nominal scenarios trivialviewpoint MBD.Algorithm 3 uses number auxiliary functions. RandomInputs (line 3) assignsuniformly distributed random values input (note generationobservation vectors partition observable variables OBS inputs outputsuse input/output information comes original 74XXX/ISCAS85circuits simulation). Given healthy health assignment diagnostic system, ComputeNominalOutputs (line 4) performs simulation propagating inputassignment . result assignment contains values output variableOUT.7. Lydia, Safari, diagnostic benchmark downloaded http://fdir.org/lydia/.401fiFeldman, Provan, & van GemundAlgorithm 3 Algorithm generation observation vectors1: function MakeAlphas(DS, N, K) returns set observationsinputs: DS = hSD, COMPS, OBSi, diagnostic systemOBS = OUT, =N , integer, number tries SafariK, integer, maximal number diagnoses per cardinalitylocal variables: , , n , , termsc, integer, best cardinality farA, set terms (observation vectors), result2:k 1, 2, . . . , K3:RandomInputs(IN)4:ComputeNominalOutputs(DS, )5:c06:v7:n Flip(, v)8:SmallestCardinalityDiagnosis(Safari(SD, n , |COMPS|, N ))9:|| > c10:c ||11:n12:end13:end14:end15:return16: end functionloop lines 6 13 increases cardinality greedily flipping valuesoutput variables. new candidate observation n , Alg. 3 uses diagnostic oracleSafari compute minimal diagnosis cardinality c. Safari returnsone diagnosis (up N ), use SmallestCardinalityDiagnosis choose onesmallest cardinality. cardinality c diagnosis increases comparisonprevious iteration, observation added list.running Alg. 3 get K observations leading faults cardinality 1, 2, . . . , m,cardinality MFMC diagnosis (Feldman, Provan, & van Gemund,2008b) respective circuit. Alg. 3 clearly shows bootstrapping problem. ordercreate potentially difficult observations Safari, require Safari solvedifficult observations. Although seen Sec. 5 Safari heavily biasedtowards generating diagnoses small cardinality, guarantee. alleviateproblem, generation observation vectors, configured Safari computesubset-minimal diagnoses = |COMPS| N increased 20.Table 3 provides overview fault diagnosis benchmark used experiments.third fourth columns show number observable assumable variables,characterize size circuits. next three columns show number observationvectors tested weak, S-A-0, S-A-1 models. stuck-atmodels, chosen weak-fault model observations consistent402fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchTable 3: overview 74XXX/ISCAS85 benchmark circuitsNameDescription7418274L8574283741814-bit4-bit4-bit4-bitc432c499c880c1355c1908c2670c3540c5315c6288c755227-channel interrupt controller32-bit SEC circuit8-bit ALU32-bit SEC circuit16-bit SEC/DEC12-bit ALU8-bit ALU9-bit ALU32-bit multiplier32-bit adderVariables|OBS| |COMPS|carry-lookahead generatormagnitude comparatoradderALUObservationsWeak S-A-0 S-A-11414142219333665250150202350150582021438289202213437386735837372301643151602023835468801 1931 6692 3072 4163 5123018351 1828368461 1627562 0384041 557301235217836846134625158274255301835335836846123743228366233respective system descriptions (as strong-fault models often case SD |=,considered scenarios).6.2 Comparison Complete AlgorithmsTable 4 shows results comparing Safari implementations two state-of-the-artcomplete deterministic diagnostic algorithms: modification completeness CDA(Williams & Ragno, 2007) HA (Feldman & van Gemund, 2006). Table 4 shows,model algorithm, percentage tests diagnosis couldcomputed within cut-off time 1 minute.visible three rightmost columns Table 4, Safari could find diagnoses observation vectors, performance two deterministic algorithms(columns two seven) degraded increase model size cardinalityobservation vector. Furthermore, observed degradation performanceCDA HA increased cardinality minimal-cardinality diagnoses,performance Safari remained unaffected.6.3 Comparison Algorithms Based ALLSAT Model Countingcompared performance Safari pure SAT-based approach,uses blocking clauses avoiding duplicate diagnoses (Jin, Han, & Somenzi, 2005).Although SAT encodings worked efficiently variety domains,planning, weak health modeling makes diagnostic problem underconstraineduninformed ALLSAT strategy (i.e., search exploiting continuity imposedweak-fault modeling) quite inefficient, even small models.403fiFeldman, Provan, & van GemundTable 4: Comparison CDA , HA , Safari [% tests solved]NameWeakCDAS-A-07418274L85742837418110010010079.110010010098.610010010097.7c432c499c880c1355c1908c2670c3540c5315c6288c755274.12911.63.800000075.445.544.74.700000073.127.732.25.4000000S-A-1WeakHAS-A-0S-A-1Weak10010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010010071.124.112.410.86.151.11.13.53.994.777.962.210.6664.23.88.25.17.869.125.941.512.26.544.72.25.73.312SafariS-A-0 S-A-1substantiate claim, experimented state-of-the-art satisfiabilitysolver RelSat, version 2.02 (Bayardo & Pehoushek, 2000). Instead enumeratingsolutions filtering minimal diagnoses only, performed model-counting, whoserelation MBD extensively studied (Kumar, 2002). possible solvetwo smallest circuits, solver terminate larger models withinpredetermined time 1 hour. results shown Table 5.second column Table 5 shows model count returned RelSat, sample single-fault observations benchmark. third column reports timemodel counting. slow performance relatively small diagnostic instances leads usconclusion specialized solvers like Safari better suited finding minimaldiagnoses off-the-shelf ALLSAT (model counting) implementations encodeinference properties similar encoded Safari.used state-of-the-art, non-exact model counting method SampleCount(Gomes, Hoffmann, Sabharwal, & Selman, 2007) compute lower bounds modelcounts. results shown third fourth columns Table 5. Configureddefault settings ( = 3.5, = 2, z = 20, cutoff 10 000 flips), SampleCount couldfind lower bounds circuits larger c1355. Although performance SampleCount significantly better RelSAT, fact SampleCount computes lowerbounds scale large circuits prevent us building diagnosis algorithmbased approximate model counting.satisfiability-based method diagnosing optimized version ISCAS85used Smith, Veneris, Viglas (2004). recent paper (Smith, Veneris, Ali, &Viglas, 2005), SAT-based approach replaced Quantified Boolean Formula(QBF) solver computing multiple-fault diagnoses. methods report good absolute404fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchTable 5: Model count time countingRelSatModelsTime [s]NameSampleCountModelsTime [s]7418274L8574283741813.9896 1078.3861 10141.0326 10155.6283 10151340> 3 600> 3 6003.526359 1067.412344 10133.050026 10141.538589 10270.20.30.31.1c432c499c880c1355c1908c2670c3540c5315c6288c75527.2045 10183.6731 10209.4737 10391.4668 10282.1704 10319.0845 10154.8611 10199.3551 10161.0300 10181.0049 1016> 3 600> 3 600> 3 600> 3 600> 3 600> 3 600> 3 600> 3 600> 3 600> 3 6001.496602 10677.549183 10838.332702 101667.488300 102339.913.142.799.8execution time single double-faults (and believe scale well highercardinalities), require modifications initial circuits (i.e., introduce cardinalitytest constraints) suggest specialized heuristics SAT solvers order improvesearch performance. Comparison performance Safari timings reportedpapers would difficult due number reasons like use differentoptimized benchmark sets, trading-off memory speed, rewriting original circuits, etc.6.4 Performance Greedy Stochastic SearchTable 6 shows absolute performance Safari (M = |COMPS|, N = 4). variesmillisecond small models, approx. 30 largest strong-faultmodel. fast absolute times show Safari suitable on-line reasoning tasks,autonomy depends speedy computation diagnoses.model, minimum maximum time computing diagnosiscomputed. values shown columns tmin tmax , respectively. smallrange tmax tmin confirms theoretical results Safari insensitive faultcardinalities diagnoses computes. performance CDA HA ,hand, dependent fault cardinality quickly degrades increasing faultcardinality.6.5 Optimality Greedy Stochastic Searchresults produced complete diagnostic methods (CDA HA ) knowexact cardinalities minimal-cardinality diagnoses observations.considering observations, lead single double faults, evaluated405fiFeldman, Provan, & van GemundTable 6: Performance Safari [ms]WeakNametminS-A-0tmax7418274L8574283741810.410.780.922.041.257.474.846.94c432c499c880c1355c1908c2670c3540c5315c6288c75528.6514.1948.0895.03237.77500.54984.311 950.122 105.284 557.438.9431.7888.87141.59349.96801.121 300.982 635.712 688.346 545.21tmin0.390.720.882.13S-A-1tmax4.411.893.6522.4tmin0.400.690.922.07tmax0.984.775.27.197.5830.597.9638.2711.0330.3210.7931.1137.0880.7438.4781.3476.57150.2983.14135.29196.13300.11217.32442.91646.95 1 776.72463.24931.81 248.52 516.46976.56 2 565.183 346.49 7 845.41 2 034.54 671.172 246.84 3 554.4 1 799.18 2 469.489 975.04 32 210.71 5 338.97 12 101.61average optimality Safari. Table 7 shows optimality results greedysearch. second column Table 7 shows number observation vectors leadingsingle faults weak-fault model. third column shows average cardinalitySafari. second third column repeated S-A-0 S-A-1 models.Table 7 shows that, SD WFM, average cardinality returned Safarinear-optimal single double faults. c1355 model shows worst-caseresults single-fault observations, c499 difficult weak-fault modelcomputing double-fault diagnosis. results improved increasing Ndiscussed Sec. 4.strong-fault models, results close optimal small modelsquality diagnosis deteriorates c3540 bigger. surprising, consideringmodest number retries number flips Safari configured.6.6 Computing Multiple Minimal-Cardinality Diagnosesnext show results experiments supporting claims made Sec. 5. that,first chosen observations could compute | (SD )|deterministic algorithm like CDA HA (mostly observations leading single doublefaults). configured Safari = |COMPS| N = 10| (SD )|.Finally, diagnoses computed Safari filtered minimal-cardinalityones. results summarized Table 8.Table 8 repeats columns weak, S-A-0, S-A-1 models datacolumns interpreted follows. columns marked | | showminimal maximal number minimal-cardinality diagnoses per model computeddeterministic algorithm. columns Mc show percentage minimal-cardinality406fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchTable 7: Optimality Safari [average cardinality]Single FaultsS-A-0S-A-1# Card. # Card.NameWeak# Card.7418274L8574283741815050505011.041.081.193718343611.021.592.8140404646c432c499c880c1355c1908c2670c3540c5315c6288c755258845084522981413271.191.4911.661.051.031.01111.0152533982493923913111.061.491.112.911.772.53.5428.8317.373784408452281612121811.031.882.6Weak# Card.Double FaultsS-A-0S-A-1# Card. # Card.5050505022.122.22.25381745361.04 821.01 1151.05 501.0264.792.06 133.745.4728.68123.38 162.463.272.012.152.122228034347224131422.062.413.611835424322.072.63.162.25 483.01 1152.14 35218332.78 154.93.712718.562.152.032.072.073.173.273.827.53Table 8: % minimal-cardinality diagnoses computed SafariWeakMcName| |7418274L8574283741811 251 781 481 13310099.297.997.4c432c499c880c1355c1908c2670c3540c5315c6288c75521 991 222 6465 2 7702 1 4471 761 3841 2351 1541 49094.278.599.979.496.610081.597.710093.1S-A-0Mc Mf| |023112141 161 1610010093.888.60004.071 201 491 291 5710099.784.996.70046.361 401 151 1602 6482 5791 201 1531 241 734 23689.796.396.995.785.297.188.881.778.190.806001.8507.987.045.113.551 181 161 2102 3472 3741 1811 1711 301 1011 1689794.897.595.282.389.778.293.482.1780000.521.2407.278.241.2212.17.141.5101.022.612.348.521.7413.12.17| |S-A-1Mc MfMfdiagnoses returned Safari (from minimal-cardinality diagnoses)| (SD )| > 1. columns Mf show percentage observations Safaricould compute minimal-cardinality diagnosis.407fiFeldman, Provan, & van Gemundresults shown Table 8 show even moderate values N (N 27 770),Safari capable computing significant portion minimal-cardinality diagnoses.portion varies 78.5% 100% weak-fault models 78% 100%strong-fault models. percentage cases Safari could reach minimalcardinality diagnosis limited (at 13.55%) mainly casesexists one single-fault diagnosis. Note even cases Safari cannotcompute minimal-cardinality diagnoses, result Safari still useful.example, subset-minimal diagnosis small cardinality differing one two literalsnevertheless brings useful diagnostic information (a discussion diagnostic metricsbeyond scope paper).6.7 Experimentation Summaryapplied Safari suite benchmark combinatorial circuits encoded usingweak-fault models stuck-at strong fault models, shown significant performanceimprovements multiple-fault diagnoses, compared two state-of-the-art deterministicalgorithms, CDA HA . results indicate Safari shows least order-ofmagnitude speedup CDA HA multiple-fault diagnoses. Moreover, whereassearch complexity deterministic algorithms tested increases exponentially faultcardinality, search complexity stochastic algorithm appears independentfault cardinality.compared performance Safari algorithm based MaxSAT, Safari shows least order-of-magnitude speedup computing diagnoses.compared optimality Safari algorithm based SLS MaxSAT, Safari consistently computes diagnoses smaller cardinality whereas SLSMax-SAT diagnostic algorithm often fails compute diagnosis.7. Related Workpaper (1) generalizes Feldman, Provan, van Gemund (2008a), (2) introduces important theoretical results strong-fault models, (3) extends experimental resultsthere, (4) provides comprehensive optimality analysis Safari.gross level, one classify types algorithms applied solveMBD based search compilation. search algorithms take input diagnostic model observation, search diagnosis, may minimalrespect minimality criterion. Examples search algorithms include -basedalgorithms, CDA (Williams & Ragno, 2007) hitting set algorithms (Reiter,1987). Compilation algorithms pre-process diagnostic model formefficient on-line diagnostic inference. Examples algorithms include ATMS(de Kleer, 1986) prime-implicant methods (Kean & Tsiknis, 1993), DNNF (Darwiche, 1998), OBDD (Bryant, 1992). knowledge, approaches adoptexact methods compute diagnoses; contrast, Safari adopts stochastic approachcomputing diagnoses.first glance, seems like MBD could efficiently solved using encodingSAT (Jin et al., 2005), constraint satisfaction (Freuder, Dechter, Ginsberg, Selman, &Tsang, 1995) Bayesian network (Kask & Dechter, 1999) problem. However, one needs408fiApproximate Model-Based Diagnosis Using Greedy Stochastic Searchtake account increase formula size (over direct MBD encoding), additionunderconstrained nature MBD problems.Safari close resemblance Max-SAT (Hoos & Stutzle, 2004) conducted extensive experimentation complete (partial weighted) SLS-basedMax-SAT. results experiments long, published separate technical report (Feldman, Provan, & van Gemund, 2009a). results showalthough Max-SAT compute diagnoses many cases, performance MaxSAT degrades increasing circuit size cardinality injected faults.particular, Safari outperforms Max-SAT least order-of-magnitude classdiagnostic problems considered. case SLS-based Max-SAT, optimalityMax-SAT-based inference significantly worse Safari.show Safari exploits particular property MBD problems, called diagnosticcontinuity, improves optimality Safari compared to, example, straightforward ALLSAT encodings (Jin et al., 2005). experimentally confirm favorableperformance optimality Safari. Although Safari close resemblance MaxSAT, Safari exploits specific landscape properties diagnostic problems, allow(1) simple termination criteria (2) optimality bounds. Due hybrid natureSafari (the use LTMS SAT), Safari avoids getting stuck local optima performs better Max-SAT based methods. Incorporating approaches Max-SAT,particular SAPS (Hutter, Tompkins, & Hoos, 2002), future versions Safari mayhelp solving general abduction problems, may expose continuousproperties models considered.Stochastic algorithms discussed framework constraint satisfaction(Freuder et al., 1995) Bayesian network inference (Kask & Dechter, 1999). lattertwo approaches used solving suitably translated MBD problems. oftencase, though, encodings difficult search specialized ones.MBD instance constraint optimization, particular constraints failurevariables. MBD developed algorithms exploit domain properties,proposed approach differs significantly almost MBD algorithms appearliterature. advanced MBD algorithms deterministic, Safari borrowsSLS algorithms that, rather backtracking, may randomly flip variable assignmentsdetermine satisfying assignment. Complete MBD algorithms typically make usepreferences, e.g., fault-mode probabilities, improve search efficiency; Safari usestechnique top stochastic search space diagnoses.closely-related diagnostic approach Fijany, Vatan, Barrett, James, Williams,Mackey (2003), map minimal-hitting set problem problem findingassignment bounded weight satisfying monotone SAT problem, proposeuse efficient SAT algorithms computing diagnoses. approach Fijany et al.shown speedups comparison diagnosis algorithms; main drawbacknumber extra variables clauses must added SAT encoding,even significant strong fault models multi-valued variables. contrast,approach works directly given diagnosis model requires conversion anotherrepresentation.work bears closest resemblance preference-based Cost-Based Abduction(CBA) (Charniak & Shimony, 1994; Santos Jr., 1994). algorithmic work409fiFeldman, Provan, & van Gemundarea, primary paper adopts stochastic local search Abdelbar, Gheita,Amer (2006). paper, present hybrid two-stage method basedIterated Local Search (ILS) Repetitive Simulated Annealing (RSA). ILS stagealgorithm uses simple hill-climbing method (randomly flipping assumables)local search phase, tabu search perturbation phase. RSA repeatedly appliesSimulated Annealing (SA), starting time random initial state. hybridmethod initially starts arbitrary state, greedily-chosen state. appliesILS algorithm; algorithm fails find optimal solution fixed numberhill-climbing steps8 fixed number R repetitions perturbation-localsearch cycle,9 ILS-based search terminated RSA algorithm run optimalsolution found.work differs Abdelbar et al. (2006) several ways. First, initialstate generated using random SAT solution. hill-climbing phase use nextsimilar Abdelbar et al.; however, randomly restart hill-climbingidentify better diagnosis, rather applying tabu search simulated annealing.approach simpler Abdelbar et al., case weak fault modelsguaranteed optimal; future work plan compare approachAbdelbar et al. strong fault models.2009 Safari competed diagnostic algorithms NGDE (de Kleer, 2009)RODON (Bunus, Isaksson, Frey, & Munker, 2009) synthetic track firstdiagnostic competition DXC09 (Kurtoglu, Narasimhan, Poll, Garcia, Kuhn, de Kleer, vanGemund, & Feldman, 2009). conditions DXC09 experimentsconducted similar ones described paper. CPU memory performance Safari order magnitude better competing algorithms despitefact NGDE RODON performed better complete algorithms discussedsection. paper, addition computational metrics, informallyused minimality diagnosis optimality criterion. DXC09 organizers, however, defined utility metric approximates expected repair effort circuit(Feldman, Provan, & van Gemund, 2009b). utility metric, Safari scored slightlyworse two competing algorithms, expected Safari tradesdiagnostic precision computational efficiency. refer reader DXC papersmentioned thorough analysis competition results.8. Conclusion Future Workdescribed greedy stochastic algorithm computing diagnoses within modelbased diagnosis framework. shown subset-minimal diagnoses computedoptimally weak fault models important subset strong fault models,almost minimal-cardinality diagnoses computed general fault models.8. Hill-climbing proceeds follows: given current state cost f (s), neighbouring stategenerated flipping randomly chosen assumable hypothesis. f (s ) better f (s),becomes current state; otherwise, discarded. iterations elapse without changecurrent state, local search exits.9. Perturbation-local search, starting current state cost f (s), randomly choosesassumable variable h, applies tabu search identify better state flipping h based tabustatus.410fiApproximate Model-Based Diagnosis Using Greedy Stochastic Searchargue Safari broad practical significance, compute significant fraction minimal-cardinality diagnoses systems large complexdiagnosed existing deterministic algorithms.future work, plan experiment models combination weak strongfailure-mode descriptions. also plan experimenting wider variety stochasticmethods, simulated annealing genetic search, using larger set benchmarkmodels. Last, plan apply algorithms wider class abduction constraintoptimization problems.ReferencesAbdelbar, A. M. (2004). Approximating cost-based abduction NP-hard. Artificial Intelligence, 159 (1-2), 231239.Abdelbar, A. M., Gheita, S. H., & Amer, H. A. (2006). Exploring fitness landscaperun-time behaviour iterated local search algorithm cost-based abduction.Experimental & Theoretical Artificial Intelligence, 18 (3), 365386.Bayardo, R. J., & Pehoushek, J. D. (2000). Counting models using connected components.Proc. AAAI00, pp. 157162.Brglez, F., & Fujiwara, H. (1985). neutral netlist 10 combinational benchmark circuitstarget translator fortran. Proc. ISCAS85, pp. 695698.Bryant, R. E. (1992). Symbolic Boolean manipulation ordered binary-decision diagrams. ACM Computing Surveys, 24 (3), 293318.Bunus, P., Isaksson, O., Frey, B., & Munker, B. (2009). RODON - model-based diagnosisapproach DX diagnostic competition. Proc. DX09, pp. 423430.Bylander, T., Allemang, D., Tanner, M., & Josephson, J. (1991). computational complexity abduction. Artificial Intelligence, 49, 2560.Charniak, E., & Shimony, S. E. (1994). Cost-based abduction MAP explanation. Artificial Intelligence, 66 (2), 345374.Cook, S. A. (1971). complexity theorem-proving procedures. Proc. STOC71, pp.151158.Darwiche, A. (1998). Model-based diagnosis using structured system descriptions. JournalArtificial Intelligence Research, 8, 165222.Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.Communications ACM, 5 (7), 394397.de Kleer, J. (1986). assumption-based TMS. Artificial Intelligence, 28 (2), 127162.de Kleer, J. (1990). Using crude probability estimates guide diagnosis. Artificial Intelligence, 45 (3), 381291.de Kleer, J. (2009). Minimum cardinality candidate generation. Proc. DX09, pp. 397402.de Kleer, J., Mackworth, A., & Reiter, R. (1992). Characterizing diagnoses systems.Artificial Intelligence, 56 (2-3), 197222.411fiFeldman, Provan, & van Gemundde Kleer, J., & Williams, B. (1987). Diagnosing multiple faults. Artificial Intelligence,32 (1), 97130.Een, N., & Sorensson, N. (2003). extensible SAT-solver. Proc. SAT03, Vol. 2919Lecture Notes Computer Science, pp. 502518. Springer.Eiter, T., & Gottlob, G. (1995). complexity logic-based abduction. JournalACM, 42 (1), 342.Feldman, A., Provan, G., & van Gemund, A. (2008a). Computing minimal diagnosesgreedy stochastic search. Proc. AAAI08, pp. 911918.Feldman, A., Provan, G., & van Gemund, A. (2008b). Computing observation vectorsmax-fault min-cardinality diagnoses. Proc. AAAI08, pp. 911918.Feldman, A., Provan, G., & van Gemund, A. (2009a). family model-based diagnosisalgorithms based Max-SAT. Tech. rep. ES-2009-02, Delft University Technology.Feldman, A., Provan, G., & van Gemund, A. (2009b). Lydia approach combinationalmodel-based diagnosis. Proc. DX09, pp. 403408.Feldman, A., & van Gemund, A. (2006). two-step hierarchical algorithm model-baseddiagnosis. Proc. AAAI06, pp. 827833.Fijany, A., Vatan, F., Barrett, A., James, M., Williams, C., & Mackey, R. (2003). novelmodel-based diagnosis engine: Theory applications. Proc. IEEE Aerospace03,Vol. 2, pp. 901910.Forbus, K., & de Kleer, J. (1993). Building Problem Solvers. MIT Press.Freeman, J. W. (1995). Improvements Propositional Satisfiability Search Algorithms.Ph.D. thesis, University Pennsylvania.Freuder, E. C., Dechter, R., Ginsberg, M. L., Selman, B., & Tsang, E. P. K. (1995). Systematic versus stochastic constraint satisfaction. Proc. IJCAI95, Vol. 2, pp. 20272032.Friedrich, G., Gottlob, G., & Nejdl, W. (1990). Physical impossibility instead faultmodels. Proc. AAAI90, pp. 331336.Gomes, C. P., Hoffmann, J., Sabharwal, A., & Selman, B. (2007). sampling modelcounting. Proc. IJCAI07, pp. 22932299.Hansen, M., Yalcin, H., & Hayes, J. (1999). Unveiling ISCAS-85 benchmarks: casestudy reverse engineering. IEEE Design & Test, 16 (3), 7280.Hermann, M., & Pichler, R. (2007). Counting complexity propositional abduction.Proc. IJCAI07, pp. 417422.Hoos, H. (1999). SAT-encodings, search space structure, local search performance.Proc. IJCAI99, pp. 296303.Hoos, H., & Stutzle, T. (2004). Stochastic Local Search: Foundations Applications.Morgan Kaufmann Publishers Inc.Hutter, F., Tompkins, D. A. D., & Hoos, H. H. (2002). Scaling probabilistic smoothing:Efficient dynamic local search SAT. Proc. CP02, pp. 233248.412fiApproximate Model-Based Diagnosis Using Greedy Stochastic SearchJin, H., Han, H., & Somenzi, F. (2005). Efficient conflict analysis finding satisfyingassignments Boolean circuit. Proc. TACAS05, pp. 287300.Kask, K., & Dechter, R. (1999). Stochastic local search Bayesian networks. Proc.AISTAT99, pp. 113122.Kean, A., & Tsiknis, G. K. (1993). Clause management systems. Computational Intelligence,9, 1140.Kumar, T. K. S. (2002). model counting characterization diagnoses. Proc. DX02,pp. 7076.Kurtoglu, T., Narasimhan, S., Poll, S., Garcia, D., Kuhn, L., de Kleer, J., van Gemund, A.,& Feldman, A. (2009). First international diagnosis competition - DXC09. Proc.DX09, pp. 383396.Marques-Silva, J. P. (1999). impact branching heuristics propositional satisfiabilityalgorithms. Proc. EPIA99, pp. 6274.McAllester, D. A. (1990). Truth maintenance. Proc. AAAI90, Vol. 2, pp. 11091116.Reiter, R. (1987). theory diagnosis first principles. Artificial Intelligence, 32 (1),5795.Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1-2),273302.Santos Jr., E. (1994). linear constraint satisfaction approach cost-based abduction.Artificial Intelligence, 65 (1), 128.Smith, A., Veneris, A., Ali, M. F., & Viglas, A. (2005). Fault diagnosis logic debuggingusing Boolean satisfiability. IEEE Transactions CAD Integrated CircuitsSystems, 24 (10), 16061621.Smith, A., Veneris, A., & Viglas, A. (2004). Design diagnosis using Boolean satisfiability.Proc. ASP-DAC04, pp. 218223.Struss, P., & Dressler, O. (1992). Physical negation - integrating fault models General Diagnostic Engine. Readings Model-Based Diagnosis, pp. 153158. MorganKaufmann Publishers Inc.Thiffault, C., Bacchus, F., & Walsh, T. (2004). Solving non-clausal formulas DPLLsearch. Proc. CP04, pp. 663678.Tseitin, G. (1983). complexity proofs propositional logics. Siekmann, J., &Wrightson, G. (Eds.), Automation Reasoning: Classical Papers ComputationalLogic (19671970), Vol. 2. Springer-Verlag.Williams, B., & Ragno, R. (2007). Conflict-directed A* role model-based embedded systems. Journal Discrete Applied Mathematics, 155 (12), 15621595.Zhang, H., & Stickel, M. E. (1996). efficient algorithm unit propagation. Proc.AI-MATH96, pp. 166169.413fiJournal Artificial Intelligence Research 38 (2010) 271-305Submitted 12/09; published 06/10Developing Approaches Solving TelecommunicationsFeature Subscription ProblemDavid Lesaintdavid.lesaint@bt.comBusiness Modelling Operational Transformation,BT Research,UK.Deepak MehtaBarry OSullivanLuis QuesadaNic Wilsond.mehta@4c.ucc.ieb.osullivan@4c.ucc.iel.quesada@4c.ucc.ien.wilson@4c.ucc.ieCork Constraint Computation Centre,University College Cork,Ireland.AbstractCall control features (e.g., call-divert, voice-mail) primitive options userssubscribe off-line personalise service. configuration feature subscription involves choosing sequencing features catalogue subject constraintsprevent undesirable feature interactions run-time. subscription requesteduser inconsistent, one problem find optimal relaxation, generalisation feedback vertex set problem directed graphs, thus NP-hardtask. present several constraint programming formulations problem. alsopresent formulations using partial weighted maximum Boolean satisfiability mixed integer linear programming. study formulations experimentally comparingvariety randomly generated instances feature subscription problem.1. IntroductionInformation communication services, news feeds internet telephony, playingincreasing, potentially disruptive, role daily lives. result, service providersseek develop personalisation solutions allowing customers control enrichservice. telephony, instance, personalisation relies provisioning call controlfeatures. feature increment functionality which, activated, modifies basicservice behaviour systematic non-systematic ways, e.g., do-not-disturb, multi-mediaring-back tones, call-divert-on-busy, credit-card-calling.Modern service delivery platforms provide ability implement features modularapplications compose demand setting live sessions, is, consistently feature subscriptions preconfigured participants. architectural stylecommonly found platforms based Session Initiation Protocol (Rosenberg,Schulzrinne, Camarillo, Johnston, Peterson, Sparks, Handley, & Schooler, 2002; Sparks,2007) notably, Internet Multimedia Subsystem (Poikselka, Mayer, Khartabil, & Niemi,2006), consists chaining applications end-points. context, personalic2010AI Access Foundation. rights reserved.fiLesaint, Mehta, OSullivan, Quesada, & Wilsonsation approach consists exposing catalogues call-control features subscribersletting select sequence features choice.sequences features acceptable, however, due possible occurrencefeature interactions (Calder, Kolberg, Magill, & Reiff-Marganiec, 2003). feature interaction way feature modifies influences behaviour another featuregenerating systems overall behaviour (Bond, Cheung, Purdy, Zave, & Ramming,2004). instance, do-not-disturb feature block incoming call canceleffect subsequent feature subscribed callee. undesirable interaction:shown Figure 1, call originating caller X never reach call-logging featurecallee Y. However, call-logging placed do-not-disturb featuresplay role.Figure 1: example undesirable feature interaction.Distributed Feature Composition (dfc) provides method formal architectureaddress feature interactions (Jackson & Zave, 1998, 2003; Bond et al., 2004). methodconsists constraining selection sequencing features prescribing constraintsprevent undesirable interactions. feature interaction resolution constraintsrepresented catalogue precedence exclusion constraints. precedence constraint,j, means features j part sequence must precedej. exclusion constraint j means cannot togethersequence. Note exclusion constraint j expressed pairtwo precedence constraints j j i. Undesirable interactions avoidedrejecting sequence satisfy catalogue precedence constraints.Informally, feature subscription defined set features, set precedenceconstraints specified user set precedence constraints prescribed feature catalogue. task find sequence user-selected features subjectcatalogue precedence constraints user-specified precedence constraints. mayalways possible construct sequence, case task find relaxation feature subscription consistent closest initial requirementsuser (Lesaint, Mehta, OSullivan, Quesada, & Wilson, 2008b). paper, showchecking consistency feature subscription polynomial time, findingoptimal relaxation subscription, inconsistent, NP-hard.present several formulations finding optimal relaxation feature subscription using constraint programming. present simple constraint optimisation problemformulation problem investigate impact maintaining three different levelsconsistency decision variables within depth-first branch bound. first onearc consistency (Rossi, van Beek, & Walsh, 2006a), commonly used. secondsingleton arc consistency third restricted singleton arc consistency (rsac).also present formulation problem based soft global constraint, callSoftPrec (Lesaint, Mehta, OSullivan, Quesada, & Wilson, 2009). present272fiApproaches Solving Telecommunications Feature Subscription Problemformulation based weighted constraint satisfaction problem framework (Rossi, vanBeek, & Walsh, 2006b). also consider partial weighted maximum satisfiability (Biere,Heule, van Maaren, & Walsh, 2009), mixed integer linear programming. presentformulations using approaches discuss differences respectconstraint programming formulations.Notice finding optimal relaxation feature subscription generalisationwell-known feedback vertex set problem well feedback arc set problem (Garey& Johnson, 1979). Given directed graph G = hV, Ei set vertices V setedges E, feedback vertex (arc) set problem find smallest V 0 V (E 0E) whose deletion makes graph acyclic. Although paper focusparticular telecommunication problem, techniques studied also applicabledomains feedback vertex/arc set problem encountered, e.g., circuit design,deadlock prevention, vlsi testing, stabilization synchronous systems (Festa, Pardalos,& Resende, 1999, Section 5). also applications chemistry comessorting list samples complex mixtures according compositions presencemissing data, i.e., components measured samples (Fried, Hordijk,Prohaska, Stadler, & Stadler, 2004).remainder paper organised follows. Section 2 presents necessarybackground required paper. introduce notion feature subscriptionSection 3. Section 4 reformulate original problem order relate easilywell-known problems existing literature. Section 5 present algorithmdealing symmetries introduced original subscription reformulated.introduce notion relaxation inconsistent subscription Section 6 provefinding optimal relaxation inconsistent subscription NP-Hard. Section7 model problem finding optimal relaxation constraint optimisationproblem. Section 8, present two constraint programming approaches basednotions global constraints weighted constraint satisfaction problems.Sections 9 10, partial weighted maximum satisfiability mixed integer linearprogramming formulations problem described. empirical evaluationapproaches shown Section 11. Finally conclusions future directionspresented Section 12.2. Backgroundsection present set concepts binary relations constraint programmingused next sections.2.1 Binary Relationsbinary relation finite set X association elements X elements X.Let R binary relation finite set X. relation R set X irreflexivex X hx, xi R. relation R set X transitivex, z X, [hx, yi R][hy, zi R] [hx, zi R]. transitive closurebinary relation R set X smallest transitive relation X contains R.use notation R denote transitive closure R. relation R set Xasymmetric x, X, [hx, yi R] [hy, xi 6 R]. relation R set273fiLesaint, Mehta, OSullivan, Quesada, & WilsonX total x, X, either hx, yi R hy, xi R. strict partialorder binary relation irreflexive transitive. strict total order binarybrelation transitive, asymmetric total. transpose relation R, denoted R,set {hy, xi|hx, yi R}. restriction R set , denoted RY , set{hx, yi R|{x, y} }. binary relation R set X also viewed directedgraph nodes correspond elements X ordered pairs R correspondedges graph.2.2 Constraint ProgrammingConstraint Programming (cp) successfully used many applications planning, scheduling, resource allocation, routing, bio-informatics (Wallace, 1996). Problems primarily stated Constraint Satisfaction Problems (csps), finite setvariables finite domains, together finite set constraints. solutioncsp assignment value variable constraints satisfied simultaneously. basic approach solving csp instance use backtracking searchalgorithm interleaves two processes: constraint propagation labelling. Constraintpropagation helps pruning values cannot lead solution problem. Labellinginvolves assigning values variables may lead solution.binary constraint said arc consistent every value domain everyvariable, exists value domain pair values satisfiesconstraint variables. non-binary constraint generalised arc consistentvalue variable scope, exists value everyvariable scope tuple satisfies constraint (Rossi et al., 2006a).csp said Arc Consistent (ac) constraints (generalised) arc consistent.csp said Singleton Arc Consistent (sac) non-empty domainsassignment variable resulting subproblem made ac (Bessiere, Stergiou,& Walsh, 2008). Mixed consistency means maintaining different levels consistencydifferent variables problem. shown maintaining sac variablesac remaining variables certain problems, job shop schedulingradio link frequency assignment, reduce solution time (Lecoutre & Patrick, 2006).Various generalisations csps developed, objective findsolution optimal respect certain criteria costs, preferences priorities.One significant Constraint Optimisation Problem (cop). goalfind optimal solution either maximises minimises objective functiondepending upon problem. simplest cop formulation retains csp limitationallowing hard constraints adds objective function variables.depth-first branch bound search algorithm generally used find solutioncop optimal value. case maximisation, branch bound searchalgorithm keeps current optimal value solution traversing search tree.value lower bound optimal value objective function. nodesearch tree, search algorithm computes overestimation global value.value upper bound best solution extends current partial solution.lower bound greater equal upper bound, solution greater274fiApproaches Solving Telecommunications Feature Subscription Problemvalue current optimal value cannot found current node, currentbranch pruned algorithm backtracks.3. Configuring Feature SubscriptionsDistributed Feature Composition (dfc) feature implemented onemodules called Feature Box Types (fbt) fbt many run-time instances calledfeature boxes. simplicity, paper assume feature implementedsingle feature box associate features feature boxes.SOURCE REGIONTARGET REGIONfeaturesCATALOGUECLOCSOCSTCS TDR CFUCLCL<TCS<TDR<CL<<<>CFUSUBSCRIPTIONSCONFIGURATIONtarget sub.source sub. XOCSTDRTCStarget sub. ZCLTCSROUTINGzone XZONESfeaturebox typesXsrc=xtrg=yOCSfeatureboxeszonesrc=xtrg=yTDRTCSzone Zsrc=xtrg=zCLsrc=xtrg=zTCSsrc=xtrg=zZFigure 2: DFC: Catalogues, subscriptions sessions.Dfc establishes dialogue endpoints routing set-up request encapsulating source target addresses associated source target feature boxesrespectively. Addresses may change along way dfc routers evolve connectionpath accordingly. Starting feature box initiating call, feature boxes incorporated one terminating box reached. router usedstep locate next box relay set-up request. shown third rowFigure 2, routing method decomposes connection path source targetregion region partitioned zones. source (target) zone sequencefeature boxes execute source (target) address. first source zoneassociated source address encapsulated initial set-up request, i.e, zone275fiLesaint, Mehta, OSullivan, Quesada, & WilsonX Figure 2. change source address source region, caused instanceidentification feature, triggers creation new source zone. change occurszone cannot expanded further, routers switch target region. Likewise,change target address target region, performed Time-Dependent-Routing(tdr) Figure 2, triggers creation new target zone. change occurszone cannot expanded Z Figure 2, request sent finalbox identified encapsulated target address.Dfc routers concerned locating feature boxes assembling zonesregions. make decisions type ordering feature boxes appearingzone. simply fetch information pre-configured feature subscriptionassociated address region zone use construct zone.instance, zone Z Figure 2 results sequence feature box typessubscribed Z target region.Subscriptions pre-configured feature catalogue published serviceprovider. catalogue set features. Features classified source, targetreversible (i.e., subset features source target) based whethersubscribed source region, target region both. instance,catalogue shown first row Figure 2 includes Originating-Call-Screening (ocs)source feature, Terminating-Call-Screening (tcs), Time-Dependent-Routing (tdr),Call-Forwarding-Unconditional (cfu) target features, Call-Logging (cl)reversible feature. source feature activated behalf caller target featureactivated behalf callee.Constraints formulated designers pairs source features pairs targetfeatures prevent undesirable feature interactions (Zave, 2003). precedence constraintimposes routing order two features. order specified respectdirection outgoing call features source (e.g., ocs must precede cl Figure 2)respect direction incoming call features target (e.g., cl mustprecede tcs). exclusion constraint makes two features mutually exclusive,case cl cfu Figure 2. encode exclusion constraint two features fifj pair precedence constraints fi fj fj fi . sake simplicity,treat precedence constraints ordered pairs, i.e., precedence constraint fi fjalso viewed hfi , fj i.Definition 1 (Catalogue). catalogue tuple hFs , Hs , Ft , Ht where:Fs finite set source features,Ft finite set target features,Fs Ft finite set reversible features,Hs set source precedence constraints Fs ,Ht set target precedence constraints Ft .source (target) subscription associated address subset source (target) catalogue features, set catalogue precedence constraints source (target)features, set user precedence constraints source (target) features.276fiApproaches Solving Telecommunications Feature Subscription Probleminstance, target subscription shown second row Figure 2 includestarget features tdr tcs user precedence tdr tcs meaning tdrappear tcs connection path.Definition 2 (Feature Subscription). Given catalogue hFs , Hs , Ft , Ht i, feature subscription defined pair tuples Ss = hFs , Hs , Ps St = hFt , Ht , Pt where:Fs Ft user selected source target features respectively FsFs , Ft Ft Fs Ft = Ft Fs , i.e., reversible feature Fs Ft appearsFs Ft ;Hs set source catalogue precedence constraints Fs given Hs = Hs Fs{(f g) (Fs Ft )2 : g f Ht };Ht set target catalogue precedence constraints Ft given Ht = Ht Ft{(f g) (Fs Ft )2 : g f Hs };Ps set source user precedence constraints Fs , satisfies Ps {(fg) (Fs Ft )2 : g f Pt };Pt set target user precedence constraints Ft , satisfies Pt {(fg) (Fs Ft )2 : g f Ps }.Configuring feature subscription involves selecting, parameterising sequencingfeatures region consistently catalogue constraints integrity rules(Jackson & Zave, 2003). particular, source target regions subscription mustinclude reversible features inverse order, i.e. source target regionsconfigured independently.Definition 3 (Consistency Feature Subscriptions). say feature subscription= hhFs , Hs , Ps i, hFt , Ht , Pt ii consistent exists strict total order TsFs strict total order Tt Ft1. Ts Hs Ps2. Tt Ht Pt3. f, g Fs Ft , f g Ts g f Tt .following configuration services may provided users submitting featuresubscription:(verification) Check consistency subscription.(filtering) feature subscription consistent, compute anti-subscription,i.e., set features precedence constraints would make inconsistentadded.(partial completion) feature subscription consistent, computetransitive closure region, i.e., (Hs Ps ) (Ht Pt ) .277fiLesaint, Mehta, OSullivan, Quesada, & Wilson(completion) feature subscription consistent, compute pair stricttotal orders source target features points 1, 2 3 Definition 3respected.(relaxation) feature subscription inconsistent, suggest consistent subscriptions obtained removing one features user precedences.formalise tasks next section describe time complexitiesreformulating original definition feature subscription.4. Reformulating Original Definition Feature Subscriptiondefinition, catalogue includes two sets features two sets precedence constraints. section, reformulate catalogue merging source targetfeature sets merging source target precedence sets. transform featuresubscriptions accordingly show consistency subscription equivalentacyclicity transformation. new definitions simpler reformulationallows us establish relations well-known problems existing literature.principle reformulation catalogue inverse merge targetprecedences source precedences. Specifically, catalogue hFs , Hs , Ft , Ht rect i, Hct transpose Htformulated hFc , Hc hFs Ft , Hs H2ct . definitions (consistent) feature subscriptionhi, ji Ft : hi, ji Ht hj, ii Hadapted follows.Definition 4 (Feature Subscription). feature subscription catalogue hFc , Hctuple hF, H, P i, F Fc , H = Hc F , P set (user defined) precedenceconstraints F .Definition 5 (Consistency Reformulated Feature Subscription). feature subscription hF, H, P catalogue hFc , Hc defined consistent existstotal order F H P .Definition 6 (Corresponding Subscription). Let hFs , Hs , Ft , Ht original cataloguect reformulation. Given feature subscription =hFc , Hc hFs Ft , Hs HhhFs , Hs , Ps i, hFt , Ht , Pt ii catalogue hFs , Hs , Ft , Ht feature subscription r =hF r , H r , P r catalogue hFc , Hc i, say r corresponds followingco , P r = P Pco .holds: F r = Fso Fto , H r = Hso HDue composition source target catalogues single catalogue,feature subscription consistent source target regions consistentDFC sense.Proposition 1 (Equivalence Subscription Consistency). Let hFs , Hs , Ft , Ht origct reformulation. feature subscriptioninal catalogue hFc , Hc hFs Ft , Hs H= hhFs , Hs , Ps i, hFt , Ht , Pt ii catalogue hFs , Hs , Ft , Ht consistentcorresponding subscription r = hF r , H r , P r catalogue hFc , Hc consistent.278fiApproaches Solving Telecommunications Feature Subscription Problemco , P r = P Pco .Proof. Definition 6 F r = Fso Fto , H r = Hso Hrrrr() consistent exists total order F H r P r .r . total orders F FLet Tso = r Fso let Tto = T\Ftco F F ,respectively. Since, Tso Hso Pso , Tto Hto Pto , Tso equivalentalso consistent.() consistent exist two total orders Tso Tto Fso Fto respectivelyco Fso Fto .Tso Hso Pso , Tto Hto Pto , Tso equivalentrc acyclic. implies consistent (see Definition 5), sinceprove Tsco . Note that,r H r P r , r total order F r extending Tsoco hf, f 0 Tso . provef, f 0 Fso hf, f 0 Tsoco acyclic contradiction. Assume Tsoco acyclic. Thus existsTsocycle, and, particular, cycle minimum cardinality, say, k. Therefore existsco , definef1 , . . . , fk , F r = 0, . . . , k, hfi , fi+1 Tsofk+1 = f1 f0 = fk . Suppose fi Fso \ Fto 1. Then, musthfi1 , fi Tso hfi , fi+1 Tso implies hfi1 , fi+1 Tso transitivity Tso .still cycle omit fi , contradicts minimality cyclelength k. shown, 1, fi Fto hfi , fi+1 Tto . TransitivityTto implies hf1 , fk+1 Tto , i.e., hf1 , f1 Tto , contradicts Tto strict totalorder.Proposition 2 (Complexity Consistency Checking). Determining whether feature subscription hF, H, P consistent checked O(|F | + |H| + |P |).Proof. use Topological Sort (Cormen, Leiserson, & Rivest, 1990). Topological Sortinterested ordering nodes directed graph directed edgehi, ji set edges graph node less node j order.order use Topological Sort detecting whether feature subscription consistent,associate nodes features edges precedence constraints. Then, subscriptionconsistent edges hi, ji graph associated subscription,precedes j order computed Topological Sort. complexity TopologicalSort linear respect size graph (i.e., sum number nodesnumber edges graph) detecting whether feature subscription consistentO(|F | + |H| + |P |).Definition 7 (Anti-subscription). Given catalogue hFc , Hc consistent feature subscription = hF, H, P i, anti-subscription tuple hFa , Pa defined follows. f Fcelement Fa directed graph associated subscription obtained adding feature f , i.e., hF {f }, Hc F {f } P i, cyclic; i, j F , jPa directed graph associated subscription obtained addingprecedence j, i.e., hF {i, j}, Hc F {i,j} P {i j}i, cyclic.definition anti-subscription suggests one way computing anti-subscriptiongiven subscription. order test whether feature/precedence belongs antisubscription check consistency resulting subscription. O(|Fc |)279fiLesaint, Mehta, OSullivan, Quesada, & Wilsonfeatures O(|Fc |2 ) precedences, worst-case time complexity computing antisubscription O(|Fc |2 (|F | + |H| + |P |)).Definition 8 (Partial Order Consistent Subscription). Given consistent subscriptionhF, H, P i, partial order subscription transitive closure (H P )relation H P .worst-case complexity finding transitive closure O(|F |3 ).Definition 9 (Total Order Consistent Subscription). total order consistent subscription topological sort directed graph hF, H P i, i.e., total order extendingrelation H P .worst-case complexity finding total order linear time respectsize corresponding graph.5. Symmetry Inherent ReformulationOne services provided end-user configuring feature subscriptioncomputation compatible pairs total orders source target features.section, show original subscription, defined Section 3, reformulated, described Section 4, symmetries introduced. Two total ordersreformulated subscription symmetric correspond pair total orders (on source target features) original subscription. formally,let = hhFso , Hso , Pso i, hFto , Hto , Pto ii subscription catalogue hFs , Hs , Ft , Ht i,r = hF r , H r , P r corresponding subscription catalogue hFc , Hcct i, i.e., F r = F F , H r = H Hco , P r = P Pco . pairhFs Ft , Hs Htotal orders hTs , Tt compatible Conditions (1), (2) (3) Definition 3hold. many-to-one relation set total orders r (see Definition9) set compatible pairs total orders .Let us consider subscription Fso = {1, 2, 3}, Fto = {2, 3, 4}, Hso = {1 2},Ht = {4 3}, Pso Pto empty. corresponding r would F r = {1, 2, 3, 4},H r = {1 2, 3 4}, P r = . r consistent. set total ordersr , set compatible pairs total orders shown Table 1.cardinality former set six, latter five. last two total ordersr correspond last compatible pair total orders . due factunion total order source features transpose total ordertarget features necessarily total order. example last pair totalorders Table 1, union 3 1 2 3 4 2 result total order,since order 1 4.repetition computation symmetric pairs total orders original subscription total orders reformulated subscription desirable.order compute compatible pair total orders once, use algorithmGetSolutions(S r ), shown Algorithm 1. algorithm two nested loops.first loop selects total order set reversible features extendstotal order generate set total orders source features set total orderstarget features. second loop total order source features total order280fiApproaches Solving Telecommunications Feature Subscription ProblemTable 1: Total orders F r , Fso , Fto .SrrFFsFto1234123 4321324132 4231342132 2433124312 4233142312 2433412target features selected previously generated sets. Due factsource features target features ordered independently GetSolutions(S r ),unnecessary ordering imposed source features target features.Algorithm 1 GetSolutions(S r )Require:r = hF r , H r , P r consistent subscription, F r = Fso Fto , Fso setsource features, Fto set target features, Fro = Fso Fto setreversible features corresponding subscription .GetTotalOrders(hF, Oi) generates set total orders extendgiven acyclic binary relation defined set features F ., R , , set (H r P r ) , Fro , Fso , Fto respectively.Ensure: PTOs set pairs compatible total orders Fso Fto respectively.1: PTOs2: RTOs GetTotalOrders(hFro , R i)3: r RTOs4:STOs GetTotalOrders(hFso , r i)5:TTOs GetTotalOrders(hFto , r i)6:STOs, TTOsct i}7:PTOs PTOs {hs ,8: return PTOsalgorithm computes saves total orders given set reversible featuresRT Os, given total order set reversible features computes savestotal orders source target features ST Os Os respectively. However,presented algorithm purpose clarity. practice, total ordercomputed lazily, i.e., total order computed needed, thus avoiding needkeeping total orders generated memory.amortised time complexity computing total orders extending givenacyclic binary relation linear respect number total orders (Pruesse &Ruskey, 1994). Assuming r total orders Fro , total281fiLesaint, Mehta, OSullivan, Quesada, & Wilsonorders Fso Fto consistent given total order Fro respectively,time complexity GetSolutions O(r ). computation pairscompatible total orders could impractical size resulting set large.Therefore, cases computation number total orders could restrictedpre-specified number, heuristic used select r Line 3,Line 6 Algorithm 1.may pairs total orders Fso Fto desirableothers. instance, would desirable present end-user pairstotal orders easy extend (in terms addition feature userprecedence). One way use notion anti-subscription (see Definition7). pair total orders associated anti-subscription. sizeanti-subscription sum number features precedences involvedit. pairs total orders ordered increasing size correspondinganti-subscriptions. size anti-subscription sense reflects constrainedpair total orders respect future addition number featuresuser precedences end-user may consider his/her subscription future.6. Relaxations Feature Subscriptionsinput feature subscription consistent goal relax dropping onefeatures user precedence constraints generate consistent feature subscriptionclosest initial users requirements. Therefore, introduce function w :F P N assigns weights features user precedence constraints, indicatingimportance user features user precedences. weights couldelicited directly data mining analysis user interactions. restpaper feature subscriptionPis denoted byPS = hF, H, P, wi. value subscriptiondefined Value(S) = f F w(f ) + P w().Definition 10 (Relaxation). relaxation feature subscription hF, H, P, wi catalogue hFc , Hc subscription hF 0 , H 0 , P 0 , w0 F 0 F , H 0 = HF 0 , P 0 P F 0w0 w restricted F 0 P 0 .Definition 11 (Optimal Relaxation). Let RS set consistent relaxationsfeature subscription S. say Si RS optimal relaxation maximumvalue among consistent relaxations, i.e., exist Sj RSValue(Sj ) > Value(Si ).Proposition 3 (Complexity Finding Optimal Relaxation). Finding optimal relaxation feature subscription NP-hard.Proof. Given directed graph G = hV, Ei, Feedback Vertex Set Problem findsmallest V 0 V whose deletion makes graph acyclic. problem known NPhard (Garey & Johnson, 1979). prove finding optimal relaxation NP-hardreduction feedback vertex set problem. feedback vertex set problemreduced problem associating nodes directed graph V featuresF , edges E catalogue precedence constraints H. set P define ww(f ) = 1, f F . Thus, finding optimal relaxation = hF, H, P, wi corresponds282fiApproaches Solving Telecommunications Feature Subscription Problemfinding biggest set nodes V 00 deletion V V 00 G resultsacyclic graph. Therefore, conclude finding optimal relaxation inconsistentsubscription NP-hard.challenging operation feature subscriptions find optimal relaxationsubscription consistent, since NP-Hard. remainder paperfocus particular task.7. Basic COP Model Finding Optimal Relaxationsection model problem finding optimal relaxation feature subscription hF, H, P, wi catalogue hFc , Hc constraint optimisation problem (Lesaint,Mehta, OSullivan, Quesada, & Wilson, 2008c).Variables Domains. associate feature F two variables: Booleanvariable bfi integer variable pfi . Boolean variable bfi instantiated 1 0depending whether feature included subscription not, respectively. domain integer variable pfi {1, . . . , |F |}. Assuming computed subscriptionconsistent, integer variable pfi corresponds position feature sequence, consistent optimal relaxation. associate user precedenceconstraint (i j) P Boolean variable bpij . Boolean variable bpij instantiated1 0 depending whether j respected computed subscription not,respectively. variable v associated value subscription, initial lowerbound 0 initial upper bound sum weights featuresuser precedences.Constraints. catalogue precedence constraint (i j) H featurefeature j expressed follows:bfi bfj (pfi < pfj ).Note constraint activated selection variables bfi bfj instantiated1. user precedence constraint (i j) P placed jsubscription expressed follows:bpij (bfi bfj (pfi < pfj )).Note user precedence constraint holds features j includedsubscription also feature placed j, is, selection variables bfibfj instantiated 1 pfi < pfj true.value subscription equal sum weights included featuresincluded user precedences. constraint expressed following:XXv=bfi w(i) +bpij w(i j).(1)(ij)PEnforcing arc consistency Equation (1), general, exponential (Zhang & Yap, 2000).Therefore, cp solvers perform bounds consistency constraint, equivalent283fiLesaint, Mehta, OSullivan, Quesada, & Wilsonenforcing arc consistency following pair constraints, seendecomposition Equation (1):XXbpij w(i j).(2)vbfi w(i) +vX(ij)Pbfi w(i) +Xbpij w(i j).(3)(ij)Porder reason complexities enforcing different consistency techniquesalways assume two inequality constraints used instead equality constraint.Objective.objective find optimal relaxation feature subscription.investigated impact maintaining three different levels consistencywithin branch bound search. first arc consistency rest mixed consistencies. following sections shall describe consistency techniques presentworst-case time complexities enforced instance feature subscription,formulated described above. results complexities presentedbased assumption Boolean variables associated inclusion/exclusion features user precedences decision variables. remarkproblem arc-consistent instantiating Boolean variables alsoglobally consistent.7.1 Arc ConsistencyLet e sum number user precedences number catalogue precedences,let n sum number features number user precedences,let number features. complexity achieving arc consistency (ac)(catalogue/user) precedence constraint constant respect number variables.catalogue precedence constraint made arc-consistent Boolean variablesinvolved constraint initialised domains position variablesmodified. Thus, catalogue precedence constraint made arc-consistent(1 + 1 + (d 1) + (d 1)) times, effectively 2d times. user precedence constraintmade arc-consistent 2d + 1 times. Since are, total, e precedenceconstraints, worst-case time complexity imposing arc consistency precedenceconstraints O(e d), also optimal. addition, arc consistency also enforcedlinear inequalities (2) (3), complexity linear respectnumber Boolean variables. Whenever Boolean variable instantiated constraintrevised since n Boolean variables, made arc-consistent ntimes. Therefore, worst-case time complexity enforcing arc consistency linearinequalities O(n2 ), optimal. Thus, worst-case time complexity enforcingac instance basic cp model finding optimal relaxation O(e + n2 ).7.2 Singleton Arc ConsistencyMaintaining higher level consistency expensive terms time. However,values removed domains variables, search effort284fiApproaches Solving Telecommunications Feature Subscription Problemreduced may save time. shall investigate effect maintaining SingletonArc Consistency (sac) Boolean variables ac remaining variablesdenote sacb . used sac-1 (Debruyne & Bessiere, 1997) algorithmenforcing sac Boolean variables. Enforcing sac Boolean variables sac-1manner works traversing list 2n variable-value pairs. instantiationBoolean variable x value 0/1, domain wipeout enforcing acvalue removed corresponding domain ac enforced. time valueremoved, list traversed again. Since 2n variable-value pairs, numbercalls underlying arc consistency algorithm 4n2 . Thus worst-casetime complexity sacb O(n2 (e + n2 )).sacb optimal worst-case time complexity. sacb arc consistencyenforced subproblem obtained restricting Boolean variable single value2n times, time arc consistency established scratch. However, onetake incremental property arc consistency account obtain optimal versionsacb . Following work Lecoutre (2009) arc consistency algorithm saidincremental worst-case time complexity appliedgiven network P applied times P twoconsecutive executions, least one value deleted. sum domainsizes variables involved problem P . idea behind optimal versionwant achieve arc consistency scratch subproblem, but,instead, benefit incremental property underlying arc consistency algorithm.results asymptotic complexity O(e + n2 ) enforcing arc consistency 2ntimes. Thus, time complexity optimal version sacb would O(n (e + n2 )).7.3 Restricted Singleton Arc Consistencymain problem sac-1 deleting single value triggers loop again.Restricted Singleton Arc Consistency (rsac) avoids considering variable-valuepair (Prosser, Stergiou, & Walsh, 2000). investigate effect enforcing(rsac) Boolean variables ac remaining variables, denote rsacb .worst-case time complexity rsacb O(n (e + n2 )).8. CP Modelssection present two cp approaches. first approach uses global constraint achieves higher level consistency taking account cyclesprecedence constraints. second approach model problem weighted constraint satisfaction problem.8.1 Global Constraintglobal constraint captures relation several variables. takes accountstructure problem prune values. instance, user selected setfeatures, F = {1, 2, 3, 4} features constrained catalogue precedences1 2, 2 1, 3 4 4 3, three features required includedsubscription one infer problem inconsistent without search.285fiLesaint, Mehta, OSullivan, Quesada, & Wilsonpossible inferring cycles precedence constraints using prunebounds objective function.soft global precedence constraint SoftPrec proposed Lesaint et al. (2008a).holds strict partial order selected features subjectrelevant hard (catalogue) precedence constraints selected soft (user) precedenceconstraints, value subscription within provided bounds. shownLesaint et al. (2008a), achieving ac SoftPrec NP-complete sinceway determine polynomial time whether strict partial order whose valuegiven bounds. Therefore, ac approximated pruning domainsvariables based filtering rules follow definition SoftPrec.time-complexity achieving pruning O(|F |3 ), polynomial. upperbound value subscription pruned based incompatibilitiesinferred pairs features, dependencies user precedencescorresponding features. pruning rules SoftPrec used within branchbound search find optimal relaxation feature subscription.Let hF, H, P, wi subscription. Let bf vector Boolean variables associatedF . say feature included bf(i) = 1, excluded bf(i) = 0.abuse notation using bf(i) mean bf(i) = 1, bf(i) mean bf(i) = 0. similarconvention adopted Boolean variables. Let bp |F |2 matrix Booleanvariables. bp intended represent strict partial order included features F 0compatible catalogue constraints restricted F 0 .Definition 12 (SoftPrec). Let = hF, H, P, wi feature subscription, bf bpvectors Boolean variables, v integer variable, SoftPrec(S, bf, bp, v) holds1. bp strict partial order restricted bf, i.e.,i, j F : bp(i, j) bf(i) bf(j)(restricted),i, j F : bp(i, j) bp(j, i)(asymmetric),i, j, k F : bp(i, j) bp(j, k) bp(i, k) (transitive),2. bp compatible H restricted bf, i.e.,(i j) H : bf(i) bf(j) bp(i, j),3. v =Pbf(i) w(i) +P(ij)Pbp(i, j) w(i j).set constraints cp model contains SoftPrec. decision variablesmodel bf bp. solution SoftPrec consistent relaxationsubscription hF, H, P, wi. Notice feedback vertex set problem (Garey & Johnson,1979) expressed terms SoftPrec associating vertices features arcscatalogue precedence constraints. Therefore, achieving generalised arc consistencySoftPrec NP-hard.286fiApproaches Solving Telecommunications Feature Subscription Problem8.2 Weighted CSP Modelclassical csp framework extended associating weights (or costs)tuples (Larrosa, 2002). Weighted Constraint Satisfaction Problem (wcsp) specificextension relies specific valuation structure S(k) defined follows.Definition 13 (Valuation Structure). S(k) triple ({0, . . . , k}, , ) where: k {1, . . . , }either strictly positive natural number infinity, {0, 1, . . . , k} set naturals lessequal k, sum valuation structure defined as: ab = min{k, a+b},standard order among naturals.wcsp instance defined valuation structure S(k), set variables (asclassical csp instances) set constraints. domain associated variablecost function constraint. precisely, constraint Ctuple built domains associated variables involved C,value {0, 1, . . . , k} assigned t. constraint C assigns cost k tuplet, means C forbids t. Otherwise, permitted C corresponding cost.cost instantiation variables sum (using operator ) constraintsinvolving variables instantiated. instantiation consistent cost strictly lessk. goal wcsp problem find full consistent assignment variablesminimum cost. wcsp formulation finding optimal relaxation inputsubscription hF, H, P, wi, inconsistent, outlined below.maximum acceptable costXXk=w(i) +w().Passociate feature F integer variable pfi . domain integervariable, D(pfi ), {0, . . . , |F |}. pfi instantiated 0, indicates excludedsubscription.unary cost function Ci : D(pfi ) {0, w(i)} assigns costs assignments variablepfi following way:0> 0Ci (a) =w(i) = 0catalogue precedence constraint (i j) H associated binary cost functionHij : D(pfi ) D(pfj ) {0, k} assigns costs assignments variables pfi pfjfollowing way:0 = 0 b = 0 < bHij (a, b) =k otherwiseuser precedence constraint (i j) P associated binary cost function Pij :D(pfi ) D(pfj ) {0, w(i j)} assigns costs assignments variables pfi pfjfollowing way:06= 0 b 6= 0 < bPij (a, b) =w(i j) otherwiseNote user precedence constraint holds features j includedsubscription also feature placed j, is, integer variables pfipfj instantiated value greater 0 pfi < pfj true.287fiLesaint, Mehta, OSullivan, Quesada, & Wilson9. Boolean SatisfiabilityBoolean Satisfiability Problem (sat) decision problem instanceexpression propositional logic. problem decide whether assignmenttrue false values variables make expression true. expressionnormally written conjunctive normal form. Partial Weighted Maximum BooleanSatisfiability Problem (pwmsat) extension sat includes notions hardsoft clauses. solution respect hard clauses. Soft clauses associatedweights. goal find assignment satisfies hard clauses minimisessum weights unsatisfied soft clauses. section present Booleansatisfiability formulations finding optimal relaxation feature subscription.9.1 Atom-based Encodingatom-based encoding, atom, like f g, associated propositional variableasymmetricity transitivity properties precedence relation explicitlyencoded. atom-based encoding finding optimal relaxation feature subscriptionhF, H, P, wi outlined below.Variables. Let PrecDom set possible precedence constraints definedF , i.e., {i j : {i, j} F 6= j}). feature F Booleanvariable bfi , true false depending whether feature includedcomputed subscription. precedence constraint (i j) Boolean variablebpij , true false depending whether precedence constraint holdscomputed subscription. bpij true, then, roughly speaking, means featuresj included, precedes j.Clauses. weighted-clause represented tuple hw, ci, w weightclause c. Note hard clauses associated weight >, representsinfinite penalty satisfying them.catalogue precedence constraint, (i j) H, must satisfied featuresj included computed subscription. modelled adding followinghard clause:h>, (bfi bfj bpij )i.precedence relation transitive asymmetric order ensuresubscription graph acyclic. ensure asymmetricity, following clause addedevery pair {i j, j i} PrecDom:h>, (bpij bpji )i.(4)bpij bpji false. However, one true onefalse.ensure transitivity, every {i j, j k} PrecDom, following clause added:h>, (bpij bpjk bpik )i.(5)Note Rule (5) need applied hi, j, ki 6= k since precedence constraints reflexive Rule (4).288fiApproaches Solving Telecommunications Feature Subscription Problemprecedence constraint (i j) PrecDom satisfied correspondingfeatures j features included. ensured considering following clauses:h>, (bpij bfi )ih>, (bpij bfj )i.need penalise solution include feature F user precedenceconstraint (i j) P . done adding following clauses:hw(i), (bfi )ihw(i j), (bpij )i.cost violating clauses weight feature weight userprecedence constraint j respectively.Reducing Variables Clauses. straightforward realise atombased encoding described previous section requires (n2 ) Boolean variables(n3 ) clauses, n number features1 . describe two techniquesreduce number variables clauses. subscription contains cycletransitive closure H P contains cycle. Therefore, instead associatingBoolean variable possible precedence constraint, sufficient associateBoolean variables precedence constraints transitive closure H P .Reducing Boolean variables also reduce transitive clauses, especiallyinput subscription graph dense. Otherwise, Rule (5) generate |F | (|F | 1)(|F | 2) transitivity clauses Rule (4) generate (|F | (|F | 1))/2 asymmetricityclauses. example, subscription hF, H, P, wi F = {1, 2, 3, 4, 5, 6}, H = {12, 2 1, 3 4, 4 3, 5 6, 6 5}, P = , Rules (4) (5) generate 120transitivity clauses 15 asymmetricity clauses respectively. Since relaxationgiven subscription respecting clauses generated Rule (4) acyclic, 120 transitivityclauses 12 asymmetricity clauses redundant. Thus, PrecDom instead settransitive closure H P , Rules (4) (5) would generate redundantclauses. reduce number transitivity clauses h>, (bpij bpjk bpik )iconsidering none j i, k j, k H, especiallyinput subscription graph sparse. reason transitivity clausesalways entailed due enforcement catalogue precedence constraints.reduction number clauses might reduce memory requirement also mightimpact efficiency unit propagation, turn may reduce runtime.9.2 Symbol-based EncodingAnother sat approach based symbol-based encoding partial order constraintspresented Codish et al. (2009). Partial order constraints (Codish, Lagoon, & Stuckey,2008) basically propositional formulae except propositions also statementspartial order finite set symbols. symbol-based encoding transitivityasymmetricity properties precedence relation enforced implicitly.also Boolean variable bfi associated feature F indicating whetherincluded excluded. Boolean variable bpij associated precedence1. Given function g(n), (g(n)) denotes set functions f (n) exist positive constantsc1 , c2 n0 0 c1 g(n) f (n) c2 g(n) n n0 (Cormen et al., 1990).289fiLesaint, Mehta, OSullivan, Quesada, & Wilsonconstraint (i j) H P . catalogue constraint (i j) H following clauseadded: h>, (bfi bfj bpij )i. precedence constraint j (H P )following clauses added: h>, (bpij bfi )i h>, (bpij bfj )i. precedenceconstraint j (H P ) propositional constraint bpij Ji jK encoded2 .intuitively means bpij true precedes j. Two different ways encodingprecedence constraint Ji jK presented Codish et al. (2009), calledunary encoding binary encoding. brief description presentedSection 9.2.1 Section 9.2.2, provide basis theoretical comparisons.Advanced techniques encoding objective function also proposedCodish et al. (2009). However encoding objective function orthogonalway precedences encoded. purpose compare encodingprecedence constraints, omit details encoding objective functionsymbol-based encoding proposed Codish et al. (2009). Instead, assumeapproach objective function encoded done atom-based case. Therefore,pwmsat setting following soft clauses added features user precedences:hw(i), bfi hw(i j), bpij i.9.2.1 Unary Encodingsymbol-based unary encoding (Codish et al., 2009) feature associatedordered set Boolean variables represents unary encoding position.unary encoding non-negative integer n assignment values sequencen Boolean variables hm1 , . . . , mn m1 m2 mn . integer-valuerepresentation number variables mi taking value 1. example, sequence11100000 represents number = 3 using n = 8 variables. pair consecutivevariables sequence, say mk mk+1 , clause h>, (mk+1 mk )i introducedencoding order enforce mk+1 assigned 1 predecessor sequence,mk , must assigned 1. Let j two non-negative integer variablesassigned values less equal n. Let hi1 , . . . , hj1 , . . . , jn sequencesn Boolean variables represent unary-encodings j respectively. unaryencoding j denoted hi1 , . . . , hj1 , . . . , jn i, means numbervariables assigned values 1 sequence hi1 , . . . , less number variablesassigned values 1 sequence hj1 , . . . , jn i. Notice hi1 , . . . , hj1 , . . . , jn holdsholds, j1 holds, hi1 , . . . , hj2 , . . . , jn , 0i holds. hj2 , . . . , jn , 0iencodes integer 0 n 1, predecessor hj1 , . . . , jn i.inequality hi1 , . . . , hj2 , . . . , jn , 0i encoded follows: 1 k n1, ik jk+1 .resulting weighted clauses bpij Ji jK hbpij i, hbpij j1 i,1 k n 1, h>, (bpij ik jk+1 )i. Overall, symbol-based unary encodingrequires (n2 ) propositional variables (n per feature) involves (k n) clauses (n perprecedence constraint), k = |H P |.9.2.2 Binary Encodingsymbol-based binary encoding feature associated ordered setBoolean variables represents binary log encoding position. binary encod2. Ji jK Boolean formula satisfiable precedes j.290fiApproaches Solving Telecommunications Feature Subscription Probleming non-negative integer n sequence values assignedk variables v1 , . . . , vk ,Pk = dlog2 ne. value representation 1mk 2km vm . example, sequence 101 represents number 5 using 3 variables. precedence constraintencoded using lexicographical comparator (Apt, 2003). Given two numbers binaryencoded form hi1 , . . . , ik hj1 , . . . , jk i, precedence constraint hi1 , . . . , ik < hj1 , . . . , jkholds exists > 0 im < jm l < m, il = jl . resulting encoding conjunctive normal form. Therefore, Tseitin transformation3(Tseitin, 1968) used obtain corresponding formula conjunctive normal form.given precedence constraint, Tseitin transformation introduces (log n) variablesclauses, since log n length formula associated given precedenceconstraint. Overall, symbol-based binary encoding requires (n log n) propositionalvariables involves (k log n) clauses, k = |H P |.9.3 Comparison EncodingsUnit Propagation (up) central component search-based sat solver. Given unitclause l, unit propagation applies following rules: (1) every clause containing l removed, (2) l removed every clause contains literal. rulesapplied fixed-point reached. application two rules leads new setclauses equivalent old one. Unit propagation detects inconsistencyempty clause generated.Let ae, seu , seb denote atom-based encoding, symbol-based unary encoding,symbol-based binary encoding respectively. difference encodingsway encode acyclicity. ae acyclicity encoded explicitly adding transitivityasymmetricity clauses. seu seb acyclicity encoded implicitly associatingfeature set Boolean variables represent position (an integer value)precedence constraint expressed terms positions. Boolean variablesdenoting inclusion (or exclusion) features user precedences called problemvariables. variables common encodings. optimal relaxationexpressed terms problem variables. order show unit propagationone encoding stronger unit propagation another encoding, need mapdecisions one encoding one. Unfortunately, possible mapdecisions atom-based symbol-based encodings. example,assignment position variable symbol-based encodings cannot expressedterms assignments variables ae. Nevertheless, following, proveunit propagation ae stronger unit propagation seb set assignmentsrestricted problem variables.Proposition 4. Given set assignments restricted problem variables, unitpropagation detects inconsistency seb also detects inconsistency ae,converse true.3. Given propositional formula, Tseitin transformation obtains equivalent formula conjunctivenormal form associating new variable every subformula original formula applyingfollowing equivalences: (i) s0 (s1 s2 ) {(s0 s1 s2 ), (s0 s1 ), (s0 s2 )}, (ii) s0 (s1 s2 ){(s0 s1 s2 ), (s0 s1 ), (s0 s2 )}, (iii) s0 s1 {(s0 s1 ), (s0 s1 )}.291fiLesaint, Mehta, OSullivan, Quesada, & WilsonProof. atom-based symbol-based binary encoding differ encoding acyclicity, i.e., encoding transitivity asymmetricity propertiesprecedence relation. symbol-based binary encoding transitivity asymmetricity properties implicitly captured clauses corresponding propositionalconstraints form bpij Ji jK. Therefore, order prove detects inconsistency seb also detects inconsistency ae, sufficient show bpijfalsified due violation Ji jK seb unit propagation, happens ae.clauses corresponding Ji jK defined terms problem variablesnone clauses unary4 . Therefore, falsify bpij seb . triviallyimplies that, set problem variables instantiated, ae detectsinconsistency detected seb .show exists case inconsistency detectedae detected seb . Let F = {i, j, k} set features, H = ,P = {i j, j k, k i} set user precedence constraints. encodingsBoolean variable per user precedence constraint: bpij , bpjk bpki assumebpij , bpjk bpki set true. ae unit resolution bpij bpjktransitive clause bpij bpjk bpik yields bpik , unit-resolution bpikbpki bpik yields bpki , results empty clause resolved bpki .seb , ordered set Boolean variables associated feature. 3features, two Boolean variables required per feature. Therefore feature i, jk associated hi1 , i2 i, hj1 , j2 i, hk1 , k2 respectively used encodeprecedence constraint. precedence constraint, say j, set clausesencode propositional constraint bpij (i1 j1 ) ((i1 j1 ) (i2 j2 )) alsoadded. formulae associated j k k encoded similarly. Althoughbpij bpjk set true, infer bpik , since none clauses obtainedapplying Tseitin transformation unary. Therefore, unlike ae, seb detectinconsistency.Thus, infer unit propagation detects inconsistency seb alsodetects inconsistency ae, converse true.Given set assignments restricted problem variables, unit propagation detectsinconsistency seu also detects inconsistency ae, converse also true.follows directly explanation symbol-based unary encodingatom-based encoding. Notice encodings detect cycles consisting two featuresform j j i. cycles involve two features j, j k, kinfer k result cycle consisting two features k.10. Mixed Integer Linear Programminglinear programming goal optimise objective function subject linear equality inequality constraints. variables forced integer-valued,problem called Mixed Integer Linear Programming (mip) problem. standard way4. 2 features, clauses corresponding Ji jK seb unary, caseinconsistency detected exists. However, inconsistency detectedatom-based encoding.292fiApproaches Solving Telecommunications Feature Subscription Problemexpressing problems presenting function optimised, linear constraints respected domain variables involved. basic copformulation atom-based pwmsat formulation finding optimal relaxationfeature subscription hF, H, P, wi translated mip formulation. translationpwmsat formulation mip straightforward. particular formulationobserved cplex able solve even simple problems within time limit 4hours. paper, present mip formulation corresponds basiccop formulation presented Section 2.2.Variables. F , use binary variable bfi real variable pfi . binaryvariable bfi equal 1 0 depending whether feature included not. realvariable pfi , 1 pfi |F |, bfi set 1, used determine position featurecomputed subscription. user precedence constraint (i j) P , usebinary variable bpij . instantiated 1 0 depending whether precedenceconstraint j holds not.Linear Inequalities. features j included computed subscription(i j) H position feature must less position feature j.effect, need translate underlying implication (bfi bfj (pfi < pfj ))following linear inequality:pfi pfj + n bfi + n bfj 2n 1 .(6)Here, n constant equal number features, |F |, selected user.bfi bfj 1, Inequality (6) force (pfi < pfj ). Noterequired user precedence constraint (i j) P , since violated.user precedence (i j) P equivalent implication bpij (pfi < pfj )bfi bfj ,turn equivalent conjunction three implications (bpij (pfi < pfj )),(bpij bfi ) (bpij bfj ). implications translated followinginequalities:(7)pfi pfj + n bpij n 1bpij bfi 0(8)bpij bfj 0 .(9)Inequality (7) means bpij = 1 forces pfi < pfj true. Also, bpij = 1bfi bfj equal 1 Inequalities (8) (9) respectively.Objective Function. objective find optimal relaxation feature subscription configuration problem hF, H, P, wi maximises sum weightsfeatures user precedence constraints selected:XXMaximisew(i) bfi +w(i j) bpij .(ij)P11. Experimental Resultssection, shall describe empirical evaluation finding optimal relaxationrandomly generated feature subscriptions using constraint programming, partial weightedmaximum Boolean satisfiability integer linear programming.293fiLesaint, Mehta, OSullivan, Quesada, & Wilson11.1 Problem Generation Experimental Settingsorder compare different approaches generated experimented varietyrandom catalogues many classes random feature subscriptions. randomselections performed uniform distributions. random catalogue definedtuple hfc , Bc , Tc i. Here, fc number features, Bc number binaryconstraints Tc {, , } set types constraints. Note j meansgiven subscription features j cannot exist together. randomcatalogue generated selecting Bc pairs features randomly fc (fc 1)/2 pairsfeatures. selected pair features associated type constraintselected randomly Tc . random feature subscription defined tuplehfu , pu , wi. Here, fu number features selected randomly fc features,pu number user precedence constraints pairs featuresselected randomly fu (fu 1)/2 pairs features, w integer greater 0.feature user precedence constraint associated integer weightselected randomly 1 w inclusive.generated catalogues following forms: h50, 250, {, }i, h50, 500, {, , }ih50, 750, {, }i. random catalogue, generated classes feature subscriptions following forms: h10, 5, 4i, h15, 20, 4i, h20, 10, 4i, h25, 40, 4i, h30, 20, 4i, h35, 35, 4i,h40, 40, 4i, h45, 90, 4i h50, 5, 4i. Note h50, 250, {, }i default cataloguevalue w 4 default, unless stated otherwise. catalogue 10 instancesfeature subscriptions generated mean results reported paper5 .remark 4 randomly generated instances consistent 270 generatedinstances. consistent instances instances feature subscription class h10, 5, 4icatalogue h50, 250, {, }i.experiments performed pc pentium 4 (cpu 1.8 ghz 768mbram) processor. performances approaches measured terms searchnodes (#nodes) runtime seconds (time). time reported time spentfinding optimal solution proving optimality. used time limit 14,400seconds (i.e., 4 hours) cut search. initial bounds computedapproaches.11.2 Evaluation Constraint Programming Formulationsbasic constraint optimisation problem model presented Section 7 first investigated effect Maintaining Arc Consistency (mac) within branch bound search.also studied effect maintaining different levels consistency different setsvariables within problem. particular investigated, (1) maintaining singleton arcconsistency Boolean variables mac remaining variables (see Section 7.2),(2) maintaining restricted singleton arc consistency Boolean variables macremaining variables (see Section 7.3); former denoted msacb latter mrsacb . branch bound search algorithms tested two differentvariable ordering heuristics: dom/deg (Bessiere & Regin, 1996) dom/wdeg (Boussemart,Hemery, Lecoutre, & Sais, 2004). dom domain size, deg original degree5. generated instances available http://4c.ucc.ie/~lquesada/FeatureSubscription/page/instances.htm.294fiApproaches Solving Telecommunications Feature Subscription Problemvariable, wdeg weighted degree variable. experimentsbasic constraint optimisation problem formulation done using choco6 (version 2.1)Java library constraint programming systems. results three branchbound search algorithms dom/deg variable ordering heuristic presentedTable 2 dom/wdeg variable ordering heuristic presented Table 3.Table 2: Average results mac, mrsacb msacb dom/deg heuristic.hfu , puh20, 10ih25, 40ih30, 20ih35, 35ih40, 40itime0.29.85.6125.21,716.9MAC#nodes1,69170,23329,076479,6505,307,530MRSACbtime#nodes0.0450.51740.61797.31,26968.89,830MSACbtime#nodes0.0440.61560.71578.11,08375.18,466Table 3: Average results mac, mrsacb msacb dom/wdeg heuristic.hfu , puh20, 10ih25, 40ih30, 20ih35, 35ih40, 40itime0.13.32.476.9889.0MAC#nodes70120,09610,511248,4472,255,713MRSACbtime#nodes0.0420.51640.51615.593245.96,105MSACbtime#nodes0.0410.61450.61426.379852.95,184Tables 2 3 clearly show maintaining (r)sac Boolean variables acinteger variables dominates maintaining ac variables. bestknowledge first time significant improvement observedmaintaining partial form singleton arc consistency search. problemsize increases difference terms number nodes visited mrsacb msacbincreases. Note mrsacb usually visits nodes visited msacb ,difference significant. suggests level consistencyenforced rsac instances feature subscription problem closeenforced sac. Despite visiting nodes, mrsacb usually requires less time msacb .average, three search algorithms perform better dom/wdeg heuristicdom/deg heuristic. Note remainder paper resultscorrespond basic cop model obtained using mrsacb dom/wdeg variableordering heuristic.remark underlying algorithms mac mrsacb enforce acrsacb respectively optimal worst-case time complexity. However, underlyingalgorithm msacb enforces sacb optimal worst-case time complexity.Implementing algorithm enforce sacb optimal worst-case time complexitycumbersome also higher space requirement. works Bessiere et al.(2004, 2005) provide evidence optimal algorithm enforcing sac usedpreprocessor expensive terms running time space. Therefore,6. http://choco.sourceforge.net/295fiLesaint, Mehta, OSullivan, Quesada, & Wilsonmaintaining search, case, could even expensive. Indeedexists sub-optimal efficient algorithms enforcing singleton arc consistencyconstraints networks, proposed Lecoutre et al. (2005) and, remains see whetherefficient algorithms reduce running time msacb .Notice sacb prune values rsacb . However, practice, differencepruning instances feature subscriptions much, evidentbased number nodes time shown Tables 2 3. recall rsacbenforces partial sacb . given node search tree, rsacb enforces arc consistencyone time assignment value Boolean variable, whereas sacbenforce arc consistency n times worst-case. n sumBoolean variables associated features user precedences. Nevertheless, practice,observed much less. example, instance feature subscriptionclass h40, 40i arc consistency enforced 7 times variable-value pair,much less n = 80. also justifies use non-optimal versionalgorithm enforce sacb .wcsp formulation finding optimal relaxation feature subscriptionalso tested. purpose toulbar2 (a generic solver wcsp) used7 . generalresults terms time poor. remark solution wcsp model totalorder features whose position variables assigned values greater 0. Dueholes (when feature excluded) different assignments position variables may leadtotal order. Thus, search effort could spent wcsp formulation.recall basic cop model decision variables Boolean variablesindicate inclusion/exclusion features user precedences positionvariables. Therefore, optimal solution basic cop model may necessarilytotal order included features. Nevertheless, obtained computingtopological sort included user precedences catalogue precedences definedincluded features.order remove symmetries wcsp formulation, described Section 8.2,augmented. One way could associate costs values (greater 0)position variables way unique assignment valuesvariables, optimal given strict partial order. preliminary investigationsuggested number nodes reduced expense increasing time.current setting, wcsp approach used black box. Indeed, certainimprovements made may improve performance terms time.example, stronger soft consistency techniques applied similar singleton arcconsistency cop model, efficient feature subscription problem.also investigated impact using global constraint SoftPrec. globalconstraint implemented choco. results obtained using denotedsp. Five variants SoftPrec investigated Lesaint et al. (2009).results presented paper correspond variant observed bestterms time, Lesaint et al. (2009) denoted sp4 . results Tables 68 show SoftPrec always outperforms mrsacb average. However, Lesaint et al.(2008a) theoretically showed pruning achieved maintaining rsac Boolean7. http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro296fiApproaches Solving Telecommunications Feature Subscription Problemvariables cop model ac remaining variables incomparablepruning achieved using SoftPrec.11.3 Evaluation Boolean Satisfiability Formulationsevaluation atom-based pwmsat encoding feature subscription carriedthree different solvers: (a) sat4j8 (version 2.1.1), efficient library sat solversJava implements minisat specification (Een & Sorensson, 2003); (b) minisat+9(version 1.13+), pseudo-Boolean solver implemented top minisat (Een & Sorensson,2006); (c) clasp10 (version 1.3.0), answer set solver supports Boolean constraintsolving (Gebser, Kaufmann, & Schaub, 2009). two last solvers pseudo-Booleansolvers, pwmsat instances translated linear pseudo-Boolean instancesassociating clause linear pseudo-Boolean constraint, defining objectivefunction weighted sum soft clauses pwmsat model (de Givry, Larrosa,Meseguer, & Schiex, 2003).results evaluation summarized Table 4. remark resultssat4j solver, especially dense catalogues, roughly 10 times faster termstime compared presented Lesaint et al. (2008c). simply dueadvances version sat4j used obtain results. Despite that,sat4j significantly outperformed minisat+ clasp. observed oneorder-of-magnitude gap cases catalogue sparse. clasp minisat+seem incomparable instances. Even though clasp performed bettertoughest category instances h45, 90i, clasp spent 27% time solving whole setinstances. also noticed clasp seems sensitive number featuressparse instances. observed gap one order-of-magnitude categoriesh45, 90i h50, 4i h50, 250, {, }i catalogue sat4j minisat+, gapobserved clasp significant.Table 4: Results atom-based encoding using different SAT solvers.hf, pih30, 20ih35, 35ih40, 40ih45, 90ih50, 4ih50, 250, {, }isat4jclaspminisat+0.60.11.22.70.83.018.26.98.01,156.4 111.1119.690.879.011.9h50, 500, {, , }isat4jclaspminisat+0.50.00.70.70.11.31.20.12.03.60.45.73.70.63.8h50, 750, {, }isat4jclaspminisat+0.80.20.72.50.82.08.03.24.546.713.825.5147.143.812.8compare atom-based encoding symbol-based unary binaryencodings described Section 9.2. order fair comparisonencodings need solve instances feature subscription machineusing solver. access instances feature subscriptionseu seb encodings, use results experiments run Daniel Le Berre11three encodings: ae, seu seb instances feature subscription8.9.10.11.http://www.sat4j.org/http://minisat.se/MiniSat+.htmlhttp://www.cs.uni-potsdam.de/clasp/http://www.cril.univ-artois.fr/~leberre/297fiLesaint, Mehta, OSullivan, Quesada, & Wilsonusing sat4j solver (version 2.1.0) pc pentium 4 (cpu 3 ghz). Codish et al. (2009)also made results public.Table 5 presents results feature subscriptions different sizes different cataloguesthree encodings: ae, seu , seb . experimental results show ae is, general,efficient seb , consistent fact unit propagation aestrictly stronger unit propagation seb . Note ae two orders-ofmagnitude faster seb . Notice seb never outperforms seu aeclass feature subscription.Table 5: Mean results terms time obtained using ae, seu , seb encodings sat4j.subscriptionh10, 5ih15, 20ih20, 10ih25, 40ih30, 20ih35, 35ih40, 40ih45, 90ih50, 4ih50, 250, {, }iaeseuseb0.050.120.170.120.690.320.150.760.360.411.701.870.581.661.221.403.467.129.209.0621.03484.16 161.371,844.0130.727.0911.97h50, 500, {, , }iaeseuseb0.07 0.290.150.13 0.950.300.17 1.240.420.27 1.751.230.31 2.211.490.57 3.153.350.91 3.735.312.34 8.8522.112.39 4.918.77h50, 750, {, }iaeseuseb0.070.310.160.141.120.470.181.320.790.352.445.900.473.589.161.337.1949.653.2215.67153.7524.6464.791205.1261.57 41.87618.66Although results reported Tables 1, 2 3 works Codish et al. (2008,2009) suggest seb much better ae, results shown Table 5 contradictconclusion. results obtained using seb significantly outperformed obtained using ae. apparent conflict could one several reasons. resultsreported Codish et al. (2008) based different instances different encodingsinstances used symbol-based encoding much easier factlarge size instances 50 features already consistent. Also, experimentsdifferent encodings conducted different machines. Codish et al. (2008, 2009)obtained results symbol-based encoding atom-based encodings usingdifferent solvers. experiments seb done using solver, implemented top minisat, ae results obtained using sat4j solver.apparent Table 4 use different solvers make huge differenceterms runtime. fact, observed huge improvement ae testedminisat+ solver. latter fact suggests speed observed Codish et al.(2008, 2009) could mostly use minisat. Also, notice resultsdepicted Table 5 accordance fact unit propagation atom-basedencoding strictly stronger unit propagation symbol-based binary encoding.Although unit propagation ae encoding equivalent unit propagation seuencoding assignments restricted problem variables, empirically alwayspossible observe due exploration search trees different orders. Table 5shows ae seu incomparable terms time. Therefore, possibleconclude superiority two approaches. also informedinstances symbol-based encodings also include computation objectivefunction, comparison value objective function upper bounddescribed Codish et al. (2009). However, needed applying pwmsatsolver sat4j. extra clauses may indeed prevent symbol-based approaches298fiApproaches Solving Telecommunications Feature Subscription Problemperform best. Nevertheless, clauses symbol-based encodingscoming encoding precedence constraints.Finding optimal relaxation feature subscription using sat solver decomposed three tasks: (a) encoding strict partial order, (b) encodingobjective function, (c) underlying search algorithm sat solver. Improving tasks improve whole approach solving problem.paper focused task (a), mainly encoding precedenceconstraints. remark (a), (b) (c) orthogonal tasks, techniquestasks (b) (c) certainly used techniques task (a).different encodings precedence constraints fairly compared (orbest suited) techniques tasks (b) (c) used. Codish et al. (2008, 2009) proposeseveral techniques (b) (c), e.g., encoding sum constraint usedichotomic search optimisation aspect. may possible improve resultsatom-based encoding using techniques.11.4 Comparison CP, SAT MIP-based approachesperformances using constraint programming (cp), partial weighted maximum satisfiability (sat) mixed integer linear programming (mip) approaches presentedTables 6, 7 8. mip model problem solved using ilog cplex12 (version10.1). cp approaches results presented mrsacb global constraintdenoted sp. sat approaches use results obtained using claspminisat+. approaches solved instances within time limit. Since general finding optimal relaxation NP-hard, need investigate approachreasonable time. best approach terms time represented bold lettersclass feature subscription.Table 6: Catalogue h50, 250, {, }i.MIPhfu , puh30, 20ih35, 35ih40, 40ih45, 90ih50, 4i#nodes2089052,6169,8181,754time0.42.09.177.46.1CPMRSACbSP#nodestime#nodestime1610.51150.29325.67442.86,10545.92,70712.3104,789 1,256.1103,065971.326,494218.19,13336.5SATCLASPMINISAT+#nodestime #nodestime5,2580.13,9381.211,5650.89,7573.037,3316.920,3688.0310,595111.1133,303119.6196,68479.026,08711.9results presented Table 6 suggest mip approach performs bettercp sat approaches hardest feature subscription instances sparse catalogueh50, 250, {, }i, particular h45, 90i h50, 4i classes feature subscriptions,remaining classes feature subscription catalogue h50, 250, {, }i, sat approach based clasp solver winner. dense catalogue h50, 750, {, }i,mip approach significantly slower approaches. Notice results mip approach improved significantly compared resultspresented Lesaint et al. (2008c). usage real-valued variablespositions features. results presented Tables 7 8 catalogues12. http://www.ilog.com/products/cplex/299fiLesaint, Mehta, OSullivan, Quesada, & WilsonTable 7: Catalogue h50, 500, {, , }i.MIPhfu , puh30, 20ih35, 35ih40, 40ih45, 90ih50, 4i#nodes48112160573258CPtime0.41.11.818.21.5MRSACb#nodestime660.21581.02291.86879.67686.2SP#nodestime530.11110.41881.06206.19543.6SATCLASPMINISAT+#nodestime #nodestime2,0660.04,2980.72,9990.16,8381.34,0050.18,8972.07,2650.419,7915.78,8870.616,5113.8Table 8: Catalogue h50, 750, {, }i.MIPhfu , puh30, 20ih35, 35ih40, 40ih45, 90ih50, 4i#nodes3,76113,48528,46143,958163,686time9.367.9229.0539.11,644.4CPMRSACbSP#nodestime #nodestime5782.21680.41,99711.43961.95,22936.79935.819,190207.82,90229.731,580253.15,56928.2SATCLASPMINISAT+#nodestime#nodestime4,6330.25,1250.79,2850.812,6112.020,9053.222,2844.560,676 13.860,53125.5130,92043.845,802 12.8h50, 500, {, , }i h50, 750, {, }i, respectively, suggest sat approachesperform significantly better mip cp approaches. particular, sat approach based clasp solver winner classes except h50, 4i classfeature subscription catalogue h50, 750, {, }i, outperformed cpapproach based global constraint sat approach based minisat+.Even though mrsacb SoftPrec outperformed least oneapproaches cases, never worst respect total time requiredsolving instances shown Figure 3. particular cp approach basedSoftPrec competitive cases catalog dense. Figure 3 alsoshows pseudo-Boolean solvers clasp minisat+ perform better termstotal time compared approaches. noted claspminisat+ implemented C++ use restarts, mrsacb SoftPrecimplemented Java-based choco solver use restarts. claspminisat+ perform poorly compared respect number nodes visitedsearch. shows time spent clasp minisat+ nodeconsiderably less time spent remaining approaches. courseopportunity improve per-node speed cp approaches implementingC++ based solver. also remark clasp minisat+ consumememory cp-based approaches mip approach. illustrate this, alsocomputed sum problem sizes instances approaches. Here,problem size instance sum number variables, domain sizesvariables, arity constraints. Figure 4 depicts plottotal problem size approach. total problem size clasp minisat+roughly two orders-of-magnitude approaches. We, therefore, concludeclasp minisat+ offer scalability.300fiApproaches Solving Telecommunications Feature Subscription Problem1e+07search nodes (logscale)CLASPMINISAT+MIPMRSACSP1e+06051015time (seconds)202530Figure 3: Total time nodes required solve instances different approaches.units problem size -- see text (logscale)1e+081e+071e+06100000MIPMRSACSPapproachCLASPMINISAT+Figure 4: Total problem size instances different approaches.301fiLesaint, Mehta, OSullivan, Quesada, & Wilson12. Conclusions Future Workpaper focussed task finding optimal relaxation feature subscription users preferences violate technical constraints defined setdistributed feature composition rules. reformulated problem finding optimalrelaxation, showed generalisation Feedback Vertex Set problem,makes problem NP-hard. developed cpbased methods finding optimal relaxation feature subscription. particular presented three models: basic constraintoptimisation problem model, model based global constraint, weighted cspmodel. basic cop model, studied effect maintaining arc consistencytwo mixed consistencies branch bound search. experimental results suggestmaintaining (restricted) singleton arc consistency Boolean variables arc consistency integer variables outperforms mac significantly. former approachoutperformed empirically cp approach based SoftPrec global constraint.also compared cpbased approaches sat-based approaches mixedinteger linear programming approach. partial weighted maximum satisfiability casepresented atom-based encoding investigated two symbol-based encodings.set assignments restricted problem variables unit propagation atombased encoding strictly stronger unit propagation symbol-based binaryencoding, former equivalent unit propagation symbol-based unaryencoding. Empirically, atom-based encoding better symbol-based binaryencoding, incomparable symbol-based unary encoding. Overall,results suggest catalogue sparse mip better terms runtime hardinstances. catalogue dense sat approach based clasp better termsruntime. sat approach based minisat+ cp approach based globalconstraint also competitive dense catalogues. Overall, pseudo-Booleansolvers clasp minisat+ perform better terms total time comparedapproaches.approaches considered paper mostly one-stage approaches senseexploration started without approximation optimum value.future would like consider two-stage approach where, first stage, heuristicused compute approximation optimal solution, second stage,exploration carried taking approximate value initial lower bound.cp approach based wcsp explored least. may possible improveperformance using different models overcome problem symmetric solutionsstronger consistency techniques similar singleton arc consistency casebasic cop model. current settings performance approaches termstime includes time taken prove optimality solution. future, wouldlike compare presented approaches also local search methods termsanytime profiles (i.e. solution qualities time). would interesting investigateimpact restarts approaches.302fiApproaches Solving Telecommunications Feature Subscription ProblemAcknowledgmentsmaterial based upon work supported Science Foundation Ireland GrantNo. 05/IN/I886, 08/PI/I1912, Embark Post Doctoral Fellowships No. CT1080049908No. CT1080049909. authors would like thank Hadrien Cambazard, Daniel LeBerre Alan Holland support using choco, sat4j cplex respectively.authors would also like thank Simon de Givry help wcsp formulationproblem. Thanks also Michael Codish providing symbol-based encodinginstances Daniel Le Berre. thank reviewers providing valuable commentshelped us improve quality paper.ReferencesApt, K. (2003). Principles Constraint Programming. Cambridge University Press.Bessiere, C., & Debruyne, R. (2004). Optimal suboptimal singleton arc consistencyalgorithms. Proceedings Nineteenth International Joint Conference Artificial Intelligence (IJCAI 2005), pp. 5459.Bessiere, C., & Regin, J.-C. (1996). MAC combined heuristics: Two reasons forsake FC (and cbj?) hard problems. Proceedings Second InternationalConference Principles Practice Constraint Programming (CP 1996), pp.6175.Bessiere, C., Stergiou, K., & Walsh, T. (2008). Domain filtering consistencies non-binaryconstraints. Artificial Intelligence, 172 (6-7), 800822.Biere, A., Heule, M. J. H., van Maaren, H., & Walsh, T. (Eds.). (2009). HandbookSatisfiability, Vol. 185 Frontiers Artificial Intelligence Applications, chap. 19,p. 980. IOS Press.Bond, G. W., Cheung, E., Purdy, H., Zave, P., & Ramming, C. (2004). Open ArchitectureNext-Generation Telecommunication Services. ACM Transactions InternetTechnology, 4 (1), 83123.Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting systematic searchweighting constraints.. de Mantaras, R. L., & Saitta, L. (Eds.), Proceedings16th European Conference Artificial Intelligence (ECAI 2004), pp. 146150. IOSPress.Calder, M., Kolberg, M., Magill, E. H., & Reiff-Marganiec, S. (2003). Feature Interaction:Critical Review Considered Forecast. Computer Networks, 41 (1), 115141.Codish, M., Lagoon, V., & Stuckey, P. J. (2008). Telecommunications feature subscriptionpartial order constraint problem. Proceedings 24th International ConferenceLogic Programming (ICLP 2008), pp. 749753.Codish, M., Genaim, S., & Stuckey, P. (2009). declarative encoding telecommunicationsfeature subscription SAT. Proceedings 11th ACM SIGPLAN conferencePrinciples practice declarative programming (PPDP 2009), pp. 255266, NewYork, NY, USA. ACM.303fiLesaint, Mehta, OSullivan, Quesada, & WilsonCodish, M., Lagoon, V., & Stuckey, P. (2008). Logic programming satisfiability. TheoryPractice Logic Programming, 8 (1), 121128.Cormen, T., Leiserson, C., & Rivest, R. (1990). Introduction Algorithms. MIT Press.de Givry, S., Larrosa, J., Meseguer, P., & Schiex, T. (2003). Solving max-sat weightedcsp.. pp. 363376.Debruyne, R., & Bessiere, C. (1997). practical filtering techniques constraintsatifaction problem. Proceedings 15th International Joint ConferenceArtificial Intelligence (IJCAI 1997), pp. 412417, Nagoya, Japan.Een, N., & Sorensson, N. (2003). extensible SAT-solver. Proceedings SixthInternational Conference Theory Applications Satisfiability Testing (SAT2003), pp. 502518.Een, N., & Sorensson, N. (2006). Translating pseudo-boolean constraints SAT. JournalSatisfiability, Boolean Modeling Computation (JSAT), 2 (1-4), 126.Festa, P., Pardalos, P., & Resende, M. (1999). Feedback set problems. Tech. rep. 99.2.2,AT&T Labs Research.Fried, C., Hordijk, W., Prohaska, S., Stadler, C., & Stadler, P. (2004). footprint sortingproblem. Journal Chemical Information Modeling, 44 (2), 332338.Garey, M., & Johnson, D. (1979). Computers Intractability: Guide TheoryNP-Completeness. W. H. Freeman Company.Gebser, M., Kaufmann, B., & Schaub, T. (2009). conflict-driven answer set solverclasp: Progress report. Proceedings 10th International Conference LogicProgramming Nonmonotonic Reasoning (LPNMR 2009), pp. 509514, Berlin,Heidelberg. Springer-Verlag.Jackson, M., & Zave, P. (1998). Distributed Feature Composition: Virtual ArchitectureTelecommunications Services. IEEE Transactions Software Engineering (TSE),24 (10), 831847.Jackson, M., & Zave, P. (2003). DFC Manual. AT&T.Larrosa, J. (2002). Node arc consistency weighted CSP. ProceedingsEighteenth National Conference Artificial Intelligence (AAAI 2002), pp. 4853,Menlo Park, CA, USA. American Association Artificial Intelligence.Lecoutre, C., & Patrick, P. (2006). Maintaining singleton arc consistency. Proceedings3rd International Workshop Constraint Propagation Implementation(CPAI2006), pp. 4761, Nantes, France.Lecoutre, C. (2009). Constraint Networks: Techniques Algorithms. Wiley Blackwell.Lecoutre, C., & Cardon, S. (2005). greedy approach establish singleton arc consistency. Proceedings Nineteenth International Joint Conference ArtificialIntelligence (IJCAI 2005), pp. 199204.Lesaint, D., Mehta, D., OSullivan, B., Quesada, L., & Wilson, N. (2009). Soft GlobalPrecedence Constraint. Proceedings 21st International Joint ConferenceArtificial Intelligence (IJCAI-09), Pasadena, CA, USA.304fiApproaches Solving Telecommunications Feature Subscription ProblemLesaint, D., Mehta, D., OSullivan, B., Quesada, L., & Wilson, N. (2008a). Consistencytechniques finding optimal relaxation feature subscription. Proceeding20th IEEE International Conference Tools Artificial Intelligence(ICTAI2008), pp. 283290.Lesaint, D., Mehta, D., OSullivan, B., Quesada, L., & Wilson, N. (2008b). PersonalisationTelecommunications Services Combinatorial Optimisation. ProceedingsTwentieth Conference Innovative Applications Artificial Intelligence (IAAI2008), pp. 16931698, Chicago, USA. AAAI Press.Lesaint, D., Mehta, D., OSullivan, B., Quesada, L., & Wilson, N. (2008c). SolvingTelecommunications Feature Subscription Configuration Problem. Proceedings14th International Conference Principles Practice Constraint Programming (CP 2008), pp. 6781.Poikselka, M., Mayer, G., Khartabil, H., & Niemi, A. (2006). IMS: IP MultimediaConcepts Services (2nd edition). John Wiley Sons.Prosser, P., Stergiou, K., & Walsh, T. (2000). Singleton Consistencies. Dechter, R.(Ed.), Proceedings 6th International Conference Principles PracticeConstraint Programming(CP 2000), pp. 353368.Pruesse, G., & Ruskey, F. (1994). Generating linear extensions fast. SIAM JournalComputing, 23 (2), 373386.Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston, A., Peterson, J., Sparks, R., Handley, M., & Schooler, E. (2002). SIP: Session initiation protocol RFC 3261 (proposedstandard updated RFCs 3265, 3853, 4320)..Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006a). Handbook Constraint Programming,chap. 3. Elsevier Science Inc.Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006b). Handbook Constraint Programming,chap. 9. Elsevier Science Inc.Sparks, R. (2007). SIP: Basics Beyond. ACM Queue, 5 (2), 2233.Tseitin, G. S. (1968). complexity derivations propositional calculus. StudiesMathematics Mathematical Logic, Part II, 115125.Wallace, M. (1996). Practical applications constraint programming. Constraints Journal,1 (1), 139168.Zave, P. (2003). Experiment Feature Engineering. McIver, A., & Morgan, C.(Eds.), Programming Methodology, pp. 353377. Springer-Verlag.Zhang, Y., & Yap, R. (2000). Arc consistency n-ary monotonic linear constraints.Proceedings 6th International Conference Principles Practice Constraint Programming (CP 2002), pp. 470483, Sigapore. Springer-Verlag.305fiJournal Artificial Intelligence Research 38 (2010) 513-534Submitted 04/10; published 08/10Algorithms ClosedRational Behavior (CURB) SetsMichael BenischGeorge B. DavisTuomas Sandholmmbenisch@cs.cmu.edugbd@cs.cmu.edusandholm@cs.cmu.eduSchool Computer ScienceCarnegie Mellon University5000 Forbes AvePittsburgh, PA 15213 USAAbstractprovide series algorithms demonstrating solutions according fundamental game-theoretic solution concept closed rational behavior (CURB) setstwo-player, normal-form games computed polynomial time (we also discuss extensions n-player games). First, describe algorithm identifies players bestresponses conditioned belief player play within given subsetstrategy space. algorithm serves subroutine series polynomial-timealgorithms finding minimal CURB sets, one minimal CURB set, smallestminimal CURB set game. show complexity finding Nash equilibrium exponential size games smallest CURB set. Related this,show smallest CURB set arbitrarily small portion game,also arbitrarily larger supports enclosed Nash equilibrium.test algorithms empirically find commonly studied academic gamestend either large small minimal CURB sets.1. Introductionnoncooperative multi-agent settings, game-theoretic solution concepts help players choosestrategies, help modelers predict outcomes, help mechanism designers guarantee properties systems create. Significant attention given algorithms computing solutions according concepts subgame perfect Nash equilibrium (e.g., minimaxsearch --pruning), Nash equilibrium (Lemke & Howson, 1964; Porter, Nudelman,& Shoham, 2004; Sandholm, Gilpin, & Conitzer, 2005), correlated equilibrium (Gilboa &Zemel, 1989), iterative dominance (Knuth, Papadimitriou, & Tsitsiklis, 1988; Conitzer &Sandholm, 2005a), related concepts (Conitzer & Sandholm, 2005b).Nash equilibrium concept, player weakly prefers strategylong players deviate theirs, remains important pointvalued game-theoretic solution concept. However, shown that, even twoplayer games binary utilities, computing single Nash equilibrium PPAD-complete(Chen & Deng, 2006; Abbott, Kane, & Valiant, 2005), suggesting algorithms existcomputing equilibria worst-case polynomial time (Daskalakis, Goldberg, &Papadimitriou, 2009).c2010AI Access Foundation. rights reserved.fiBenisch, Davis, & Sandholmfundamental solution concepts known advantagesNash equilibria, andas showsolutions according conceptsfound polynomial time, even worst case. Specifically, study fundamentalconcept closed rational behavior (CURB) strategy sets two-player, normal-formgames. game multiple Nash equilibria, point, single(potentially mixed) strategy player. contrast, CURB set contain multiplestrategies player, stable long players choose (potentially mixed)strategies within set.CURB sets based notion rationalizability, introduced Pearce(1984) Bernheim (1984). Rationalizability is, now, widely known, robust gametheoretic solution concept used study various applications, first-priceauctions (Battigalli & Siniscalchi, 2003). main insight rationality restricts playersever playing strategies best responses given beliefs holdopponents. Strategies best responses set consistent beliefsopposing strategies said rationalizable. two-player games, processiteratively eliminating strategies dominated, strategies bestresponses opponent strategy, captures concept rationalizability. emulatesplayers assumptions opponent never play strategy bestresponse one players remaining strategies (Pearce, 1984).set players rationalizable strategies property players bestresponse pure mixed strategy inside set lies outside set words,set CURB. However, CURB set may also CURB subsets, demonstratesCURB sets extend notion rationalizability. Basu Weibull (1991) introducednotion minimal CURB set, CURB set contain CURB subsets,proved minimal CURB set guaranteed contain supports leastone Nash equilibrium.minimal CURB set solution concept since motivated several perspectives academic literature, including following:Mixed-strategy Nash equilibria (the type guaranteed exist every game)highly unstable, player may indifferent strategies.Strict Nash equilibria, players strictly prefer strategies equilibrium,stable alternative, guaranteed exist. Minimal CURB setsalways exist referred nearest set-valued generalizationstrict Nash equilibria, since smallest sets strategies includeways choosing among indifferences equilibrium (Basu & Weibull, 1991).CURB set viewed subspace strategies within best-responsedynamic (even best-response dynamic mixed strategies) stay. Thus, CURBsets used solution concept describe strategy subspaceiteratively adapting agents eventually settle (Hurkens, 1995).Voorneveld et.al. enumerated number properties minimal CURB setsillustrate stability set-based solution concepts point-valued concepts,Nash equilibria (Voorneveld, Kets, & Norde, 2005).514fiAlgorithms Closed Rational Behavior (CURB) Setsorder solution concept operational, must also accompanied algorithms applying it. Finding minimal CURB sets previously consideredchallenging (Pruzhansky, 2003), and, prior work CURB sets, little doneproblem computational standpoint. knowledge, workpredate Pruzhansky, studied sequential games perfect information.games relatively simple, contain exactly one minimal CURB set,straightforward algorithm quickly find exploiting sequential representation(Pruzhansky, 2003). paper, present first thorough computational treatmentCURB sets general two-player games. show that, settings, minimal CURBsets actually easy find: time complexity polynomial size game,even worst case.primary source complexity algorithms linear programming-basedsubroutine finding players best responses (i.e., utility-maximizing pure strategies)conditioned belief player play within given subsetstrategy space. problem solved fast two players, case involvessolving simple linear feasibility program, mathematical program usedegree p 1, p number players, p = 3 constraints alreadyquadratic. plus side, CURB set algorithms make polynomial numbercalls subroutine. future research able identify polynomial-time algorithmsfinding players best responses n-player games, CURB set algorithmsalso polynomial time settings. Additionally, algorithms usefultemplates development algorithms compute related solution conceptsn-player games (Brandt, Brill, Fischer, & Harrenstein, 2009; Jordan & Wellman, 2010).rest paper organized follows. begin preliminariesnotations definitions. Next, present analyze algorithm findingconditional best responses, serves main subroutine CURB set findingalgorithms. present analyze family polynomial-time algorithms twoplayer, normal-form games compute games minimal CURB sets, single oneminimal CURB sets, smallest minimal CURB set. Finally, discuss additionalapplications results, including potential CURB set algorithms boundtheoretical complexity finding Nash equilibria.2. Preliminariesdescribe analyze algorithms classic game-theoretic setting two-player,normal-form game represented matrix rows corresponding pure strategies(or actions) one player, player r, columns corresponding pure strategiesother, player c. (For shorthand, often omit term pure refer purestrategy simply strategy.) typical game theory, players assumedfully-rational, utility-maximizing agents.row game matrix corresponds strategy, sr , set player rsstrategies, Sr . Likewise, column corresponds strategy, sc , setplayer cs strategies, Sc . cell corresponding strategies sr sc contains two entries,one indicating real-valued utility row player sr sc played, ur (sr , sc ),indicating column player two strategies played,515fiBenisch, Davis, & Sandholmuc (sr , sc ). Using entities, also refer game, G, tuple, G = hSr , Sc , ur , uc i.size game, refer n, total number strategies contains,n = |Sr | + |Sc |.mixed strategy, mixture, probability distribution pure strategies,function,Pi , maps player pure strategies probability, mi : Si[0, 1] sSi mi (s) = 1. supports mixture pure strategiesmixture non-zero probability. set possible mixtures supportsset strategies, Si , denoted (Si ), thought simplex degree|Si | 1. pure strategy represented point-mass mixture, mixtureprobability mass one strategy.strategy profile set pure mixed strategies, one player.mixed-strategy profile played, players utility assumed expected utility, given summing players utility possible pure-strategy profileweightedPprofiles joint probability according mixtures, e.g., ur (mr , mc ) =P(s)rrsc Sc mc (sc )ur (sr , sc ). occasionally use notation refersr Srplayer players player i. used subscript strategy-relatedentity two players, intend refer one instance entityper player (e.g., mi mixed-strategy profile containing one mixture per playeri).Player best responses mixed strategy player(s), mi , givenfunction (mi ). pure strategies maximize player utilityplayer(s) play mi .set players pure strategies, Si , define (Si ) functionreturns player best responses every mixture supports Si , (Si ) =mM (Si ) (m). Section 3, describe algorithm computing pure strategies(Si ) serves subroutine CURB set algorithms, referstrategies computes conditionally rational. define (S) (without subscript i)union sets (Si ) players.CURB set, S, formally defined set pure strategies (with least one strategyplayer) contains best responses mixture itself: CURBplayers believe strategy outside played positive probabilityopponents, strategies indeed played rational players. Usingnotation above, set, S, CURB (S) S. (The entire game trivially CURBdefinition.) refer number strategies CURB set size.intersection two CURB sets, S1 S2 , set strategies attained takingintersection strategy sets, SI = S1 S2 . Two CURB sets overlap sharestrategy (i.e., intersection non-empty).Nash equilibrium pure- mixed-strategy profile, {mr , mc }, playersstrategy least good best response others, ur (mr , mc ) = ur (sr , mc )uc (mr , mc ) = uc (mr , sc ), sr r (mc ) sc c (mr ). strict Nash equilibriumpure-strategy profile, {sr , sc }, players strategy best responseothers, r (sc ) = {sr } c (sr ) = {sc }. CURB set contains one strategy perplayer also pure-strategy Nash equilibrium.516fiAlgorithms Closed Rational Behavior (CURB) Sets3. Finding Conditional Best ResponsesFinding players best responses conditioned belief playerplay within subset total strategy space, problem interestright, plays central role computation CURB sets. section describespolynomial-time algorithm, conditionally rational, that. algorithm row player; column players variant symmetric. inputsalgorithm set row-player strategies consider, Sr , set column-playerstrategies may played against, Sc , row players utility function, ur .function conditionally rational(Sr , Sc , ur )Srrow strategy, sr Srexists feasible solution following linear feasibility program:find pscXp sc= 1(1)sc ScXXpsc ur (sr , sc )sc Scpsc ur (s0r , sc )s0r Sr \ sr(2)sc Scp sc0 sc Sc(3)Sr Sr srreturn Srrow strategy, sr Sr , linear feasibility program (LFP) (i.e., linear programobjective) constructed find mixture probabilities column-playerstrategies, psc , sr row players best response. constraints LFPensure mixture valid (sums one), row players utility playingsr psc greater equal strategy. LFP feasiblesolution, sr added set best responses returned.computational complexity algorithms described paper dependtotal number strategies game, n, complexity solving LFPnumber variables constraints bounded n, denote LFP(n).LFPs solved low-order polynomial time, even worst case, fastestknown algorithms LFPs better worst-case guarantees fastest known linearprogramming algorithms (Ye, 2006). experiments, solve LFP using simplexalgorithm, exponential worst-case time complexity, known outperformpolynomial-time linear programming algorithms practice.Proposition 1. conditionally rational algorithm returns players best responses every mixture input strategy set, nothing else. worst-case timecomplexity (n) LFP(n).517fiBenisch, Davis, & SandholmProof. Since conditionally rational runs program strategies includesreturn set LFP feasible, must correct. Since LFPexecuted strategy, size bounded n, conditionally rationalcomplexity shown.4. Finding CURB Setsturn attention problem finding CURB sets. algorithmfinds smallest CURB set contains given seed strategy within given subgame.(The returned set necessarily minimally CURB.) algorithm repeatedly alternatesplayers, time calling conditionally rational add strategies necessary maintaining CURB property. iteration passes without strategiesadded, algorithm converged.function min containing CURB(sr , G = hSr , Sc , ur , uc i)Sr {sr }, Scconverged falseconvergedconverged true{r, c},u )Si0 conditionally rational(Si , Si0Si \ Si 6=converged falseSi Si Si0return Sr Scworth noting second-to-last line algorithm (Si Si Si0 )necessary merge old strategies, Si , newly identified strategies, Si0 ,Si0 always superset Si . If, instead, Si replaced Si0 , wouldpossible seed strategy eliminated algorithms first iteration.example, consider following game.sr1sr2sc11,10,1sc20,01,0strategy sr2 used seed, first iteration Sr initialized {sr2 }, Scset {sc1 }, finally Sr set {sr1 }. Thus, without merge algorithmwould output subgame contain seed strategy.Proposition 2. min containing CURB algorithm worst-case runtime (n2 )LFP(n).Proof. Every two calls made conditionally rational must add strategyreturn set, min containing CURB terminate. Since n strategies addedway, complexity min containing CURB (n2 ) LFP(n).518fiAlgorithms Closed Rational Behavior (CURB) SetsTheorem 1. min containing CURB algorithm correct, is, returned set, ,smallest set strategies 1) contains given seed strategy, sr , 2)CURB.Proof. convergence algorithm implies strategies outside bestresponses mixture supports . Therefore, (S ) , CURB.prove smallest CURB set containing sr , use inductionstrategies added.Base Case: Initially, contains sr c (sr ). point, subsetsmallest CURB set containing sr .Inductive Step: time new strategy, , added , necessarily bestresponse mixture, (S ), strategies already contained . Sincestrategies never removed execution, remain valid mixture.Therefore, strategy added necessary maintain CURB property.present three algorithms use min containing CURB determinegames minimal CURB sets. facilitate discussion algorithms, first presentthree results regarding CURB set structure, which, best knowledge,previously known.Theorem 2. two intersecting strategy sets CURB, intersectionalso CURB.Proof. Consider two CURB sets, SA SB , nonempty intersection, SI .mixture strategies SI belonging (without loss generality) row player,exists set pure strategies column players best responses, Sc . SACURB, also contains strategies Sc (i.e., Sc SA ); likewise Sc SB .Therefore, Sc within intersection, SI .Since intersection two CURB sets must CURB contained sets,also following two corollaries.Corollary 1. Distinct minimal CURB sets cannot overlap (i.e., share rows columns).Corollary 2. strategy belongs one minimal CURB set.4.1 Finding Minimal CURB Setsbroadest query one make regarding minimal CURB set structure gameasking minimal CURB sets. useful, example, adaptiveagent context identify regions strategy space learning agents likelysettle (Hurkens, 1995).MC algorithm first checking pair strategies size-twoCURB sets (i.e., pure-strategy Nash equilibria) adding return set minimalCURB sets. Since operation (n2 ), done preprocessing stepwithout affecting algorithms worst-case time complexity, strategies findseliminated future consideration. MC algorithm determinesminimal CURB sets remaining subgame calling min containing CURBrow strategy, turn, seed.519fiBenisch, Davis, & Sandholmfirst, call min containing CURB using entire remaining subgame input.However, accelerate subsequent calls min containing CURB maintaining mapstrategy smallest CURB set discovered far.(The entries added map also stored candidate minimal CURB sets.)new strategy used seed, use smallest known CURB set containing strategysecond input min containing CURB. Whenever smaller CURB set containingnew seed identified, eliminate candidate minimal CURB sets containnewly found one. strategy used seed, MC terminatesreturns remaining candidate minimal CURB sets.Proposition 3. MC algorithm finds games minimal CURB sets,nothing else. worst-case runtime (n3 ) LFP(n). best-case runtime (n2 ).Proof. Corollary 1, minimal CURB set strategy must either equal,contained by, CURB set strategy found. Therefore, restrictingmin containing CURB search smallest CURB set strategyfound far valid, main loop MC discover minimal CURB setsgame. Since CURB set minimal must contained one minimalCURB sets discovered, removed smaller CURB set discovered (or addedsmaller set previously discovered).worst case, MC must call min containing CURB n times, full gameparameter, giving time complexity (n3 ) LFP(n). best-case complexity followsbest-case game strategy part pure-strategy Nash equilibrium.4.2 Finding One Minimal CURB SetRather finding minimal CURB sets game, may desirable find singleminimal CURB set. complete quickly, first choose random seed strategycheck part size-two CURB sets (i.e., part pure-strategy Nash equilibrium),takes O(n) time. fails, use min containing CURB algorithmrandomly-chosen strategy seed full game second input. Sinceresulting CURB set might minimal, recur within choosing, seed,contained strategy yet used. repeat strategiescurrent set used seeds, point terminate return remainingset. constitutes one MC algorithm.game one CURB set, one MC faster MCnever leave CURB set starts. exact speed one MC practicedepend first seed chosen. happens small CURB set, one MCrun fast. worst case, entire game CURB set, one MC executessteps MC.Proposition 4. one MC algorithm returns one games minimal CURB sets.worst-case time complexity (n3 ) LFP(n). best-case time complexity (n).Proof. minimal CURB sets, entire game minimally CURBreturned. minimal CURB sets, onediscovered strategy inside used seed.520fiAlgorithms Closed Rational Behavior (CURB) Setsworst case, whole game minimally CURB, one MC must callmin containing CURB algorithm n times, full game input, giving time complexity (n3 ) LFP(n). best-case complexity follows best-case gamestrategy CURB set size two chosen seed.4.3 Finding Smallest Minimal CURB Setdifferent type query, one may interested finding one games smallestminimal CURB sets. important, example, CURB set used futurecomputations complexity future computations increases sizeCURB set (e.g., Nash equilibrium finding discuss later paper).find one games smallest minimal CURB sets using pseudo-parallelization MC.First, use preprocessor MC checks pair strategiessize-two CURB set returns one, found. fails, construct candidate setrow strategy containing strategy. insert sets priority queue,sets containing fewest strategies given highest priority. repeatedly popsmallest candidate set queue, add necessary best responses keepCURB calling conditionally rational player. new strategiesadded either player, resulting set inserted back queue, prioritizedbased new size. algorithm terminates candidate set removedqueue fails admit new best responses. set returned onegames smallest minimal CURB sets (we denote size set n ). callalgorithm small MC.Proposition 5. small MC algorithm returns one games smallest minimal CURBsets. worst-case runtime (n n2 ) LFP(n). best-case runtime (n2 ).Proof. time small MC terminates, conditionally rational calledrow column strategy set new best responses added.Therefore, returned set CURB. Since candidate sets queue mustlarge, larger returned set (and future exploration add strategiessets), set least small smallest CURB set game,games smallest CURB sets also minimal.Whenever candidate set fathomed, least one new strategy must addedsmall MC terminate. Since n candidate sets, n strategies returnedset, worst case n n sets fathomed termination. Since examination candidate set involves call conditionally rational, complexitysmall MC claimed. Priority queue operations logarithmic sizegame, worst case n n operations. Thus, overall worst-casecomplexity (n n2 + n n log n) LFP(n), (n n2 ) LFP(n). proofbest-case complexity Proposition 3.4.4 Experimental Resultsimplemented algorithms conducted experiments performance using instance generators main benchmark collection solving normal-formgames, GAMUT (Nudelman, Wortman, Shoham, & Leyton-Brown, 2004). GAMUT521fiBenisch, Davis, & Sandholmcollection includes variety commonly studied game types academic gametheory literature. also specifically designed test different aspects scalabilitygame-solving algorithms, example, generators allow one create multiplegame instances given size.1 section show complexity algorithms depends primarily size game size smallest CURB set.proceed explore distribution CURB set sizes different game types.first report runtime algorithms two representative GAMUT gamedistributions: random games, covariant games. Figure 1 (left) showsminimal CURB set finding algorithms scales game size data set 1000random, square normal-form games 20 100 strategies. results showsmall MC faster MC random games, consistent timecomplexities, considering many random games small CURB sets.worst-case time complexity one MC MC same, experimentally one MCfaster needs find one minimal CURB set. also see that, largerandom games, small MC performs slightly better one MC, since games tendcontain small large CURB sets one MC likely start largerones. hand, games large CURB sets, one MC tends faster,show later.observed performance random games, illustrated Figure 1 (left),typical many GAMUT instance distributions. However, show potentiallydiffering performance, also report experiments covariant game class,utilities players drawn distribution specified covariance.(In experiments set covariance parameter 0.5.) class (and setting)shown particularly challenging Nash equilibrium finding algorithms,Lemke-Howson Porter-Nudelman-Shoham algorithms (Lemke & Howson,1964; Porter et al., 2004). Figure 1 (right) shows MC algorithm scales similarlyrandom covariant games, two algorithms lose speed advantagesapplied class.distribution CURB sets random games shown solid dots Figure 2.random games small smallest CURB sets (in fact, often sets size two),not, tend large smallest CURB sets. hand, distributionsmallest CURB set sizes covariant games (shown Figure 2, hollow squares) almostsmall smallest CURB sets many large smallest CURB sets. consistentobserved hardness games support enumeration-based Nash equilibriumfinding algorithms, typically try find equilibria small supports first (Porteret al., 2004). disparity also explains lowered performance covariant gamestwo minimal CURB finding algorithms time complexities dependentsize smallest minimal CURB set, small MC one MC.Figure 3 shows distribution smallest CURB set size 1000 instancestwenty-four distributions emitted GAMUT generators. Using varietygame generators, done here, become primary way testing game-solvingalgorithms (Porter et al., 2004; Sandholm et al., 2005), used parametersettings distributions prior papers. covariant games, suffixes Pos,1. benchmark GAMUT games fixed size, Chicken, PrisonersDilemma, Battle Sexes, trivial solve computational perspective.522fiAlgorithms Closed Rational Behavior (CURB) SetsRandom games500all_MCone_MCsmall_MC400300Runtime (sec)Runtime (sec)500Covariant games2001000all_MCone_MCsmall_MC400300200100020 30 40 50 60 70 80 90 100Game size (n)20 30 40 50 60 70 80 90 100Game size (n)Figure 1: Scalability algorithms game size random (left) covariant (right)games.Small games (n = 20)100CovariantRandom80% games% games100Large games (n = 40)604020080CovariantRandom6040200051015200 5 10 15 20 25 30 35 40Smallest CURB set sizeSmallest CURB set sizeFigure 2: Distribution smallest CURB set size random covariant (r = 0.5) games,n = 20 n = 40 (3,000 games generated distributionvalue n).Rand, Zero refer positive, random, zero covariance parameters, respectively.distributions take graph input, CG, RG, SG refer complete,random, star graphs.distributions, like random covariant games, exhibited mediumsized smallest CURB sets. instances smallest CURB set extreme:either pure strategy equilibrium entire game. generators,instances lie extreme. Interestingly, generators (e.g., Polymatrix)produced significant number games CURB sets one specific, nonextremal sizes. also notable using different graph parameters Local EffectPolymatrix games effect smallest CURB set size distributions, suggesting523fiBenisch, Davis, & SandholmBidirectionalLEG-CG20005101520% games% games% games0010150005101520PolymatrixGame-CG10080604020005101520Smallest CURB set sizeTravelersDilemma1008060402005101520Smallest CURB set size5101520Smallest CURB set size20Smallest CURB set size0UniformLEG-SG5101520Smallest CURB set size15CovariantGame-Zero5101520Smallest CURB set size10080604020010100806040200PolymatrixGame-SW5101520Smallest CURB set size5Smallest CURB set size20100806040200UniformLEG-RG051008060402005101520Smallest CURB set size1008060402000MinimumEffortGame% games020Smallest CURB set size% games% games2010080604020015100806040200PolymatrixGame-Road% games5101520Smallest CURB set size1510CovariantGame-Rand% games% games% games0UniformLEG-CG0105100806040200Smallest CURB set sizeLocationGame5101520Smallest CURB set size1008060402005100806040200PolymatrixGame-RG00Smallest CURB set size5101520Smallest CURB set size10080604020020% games0DispersionGame015100806040200Smallest CURB set size10080604020010CovariantGame-Pos% games% gamesBinaryRandomGame1008060402005Smallest CURB set size% games15% games10Smallest CURB set sizeBidirectionalLEG-SG% games5BidirectionalLEG-RG1008060402005101520Smallest CURB set sizeWarOfAttrition% games0100806040200% games% games% gamesBertrandOligopoly10080604020010080604020005101520Smallest CURB set sizeFigure 3: Distribution smallest CURB set size sets 1000 games n = 20various GAMUT distributions.type graph used may change fundamental structure typesgames.better understand minimal CURB set finding algorithms scale sizesmallest CURB set, bucketed n = 20 random covariant games accordingsize smallest CURB sets. (For n = 40, buckets medium-sized smallestCURB sets nearly empty, making impossible us estimate mean runtimesmeaningful accuracy.) Figure 4 plots average runtime 95% confidence intervalsbucket. games small CURB sets, small MC fastest,outperformed one MC MC size smallest CURB set grows.524fiAlgorithms Closed Rational Behavior (CURB) Setssomewhat surprising runtime performance latter two algorithms dueleveraging information across calls min containing CURB different seeds.small MC performs searches parallel, information unavailable.Random games2all_MCone_MCsmall_MC1.5Runtime (sec)Runtime (sec)2Covariant games10.50all_MCone_MCsmall_MC1.510.5005101520Smallest CURB set size05101520Smallest CURB set sizeFigure 4: Average runtime games n = 20, varying smallest CURB set sizes.5. CURB Sets Nash EquilibriaMinimal CURB sets Nash equilibria model strategy subspaces mutuallyreinforced given rationality agents common knowledge. originalwork minimal CURB sets, Basu Weibull showed every minimal CURB setcontains supports least one Nash equilibrium (Basu & Weibull, 1991). observeresult suggests secondary use finding minimal CURB sets: algorithmsused preprocess game Nash equilibrium finding algorithm restrictattention one games minimal CURB sets, rather running entiregame. show, theoretically yield arbitrarily large reductionsearch space.common prior preprocessing technique Nash equilibrium finding, iteratedremoval dominated strategies, attempts eliminate strategies cannot playedprobability Nash equilibrium (Knuth et al., 1988; Gilboa, Kalai, & Zemel, 1993).true another recent preprocessing technique, generalized eliminabilitymethod (Conitzer & Sandholm, 2005b). One comparative advantage minimal CURBset-based elimination eliminate strategies played equilibria,guaranteeing resulting set still contains supports least one.First, show CURB set-based preprocessor reduce search space sizearbitrary amount even games prior preprocessing techniques cannot eliminateanything.Theorem 3. r,c,r0 , c0 r 2, c 2, 1 < r0 r, 1 < c0 c,exists normal form games size r c, following properties:a) contains minimal CURB set shape r0 c0 ,525fiBenisch, Davis, & Sandholmb) iterated elimination dominated strategies (even domination mixed strategies)cannot eliminate strategies,c) recursive preprocessing technique (that eliminate strategies belongequilibrium long equilibrium remains) (Conitzer & Sandholm, 2006)eliminate one strategy per player,d) general eliminability method (Conitzer & Sandholm, 2005b) cannot eliminatestrategies.Proof. first present family games, . Let r0 c0 denote game familysize r0 c0 . following generator produces game r0 , c0 2. Assignutilities,u(sr1 , sc1 ) = u(sr2 , sc2 ) = (0, 1) u(sr1 , sc2 ) = u(sr2 , sc1 ) = (1, 0).0Then, [2, b r2 c], set0, 1) u(sr2i1 , sc2 ) = ( 2i2u(sr2i1 , sc1 ) = ( r 2i+2r0r 0 , 0),0u(sr2i , sc1 ) = ( r (2i1), 0) u(sr2i , sc2 ) = ( 2i1r0r 0 , 1).r0 odd one remaining row. case, set following utilities,01r0 odd, u(sr0 , sc1 ) = ( r10 , 12 ) u(sr0 , sc2 ) = ( r r10 , 2 ).0Next, j [2, b c2 c], set0u(sr1 , sc2j1 ) = (0, c 2j+2) u(sr2 , sc2j1 ) = (1, 2j2c0c0 ),0u(sr1 , sc2j ) = (1, c (2j1)) u(sr2 , sc2j ) = (0, 2j1c0c0 ).c0 odd one remaining column. case, set following utilities,0c0 odd, u(sr1 , sc0 ) = ( 12 , c10 ) u(sr2 , sc0 ) = ( 21 , c c10 ).example, game 3,4 follows.3,4sr1sr2sr3sc10,11,01 13, 2sc21,00,12 13,2sc30, 121, 12-3,-3sc41, 140, 34-3,-4game generated way Nash equilibrium row player mixesevenly first two strategies, column player mixes evenly amongstrategies. game also equilibrium column player mixes evenlyfirst two strategies, row player mixes evenly among strategies. Thus,every strategy r0 c0 part equilibrium. Additionally, column strategy526fiAlgorithms Closed Rational Behavior (CURB) Setsbest response mixture first two row strategies (and, column strategy,one two best response), vice-versa. Thus, r0 c0 single minimal CURBset includes entire game.construct r c game, minimally CURB r0 c0 subset, puttinggame r0 c0 top left game (rr0 )(cc0 ) bottom right. utilitiesset arbitrary negative values, two exactly same. resultinggame shown Figure 5.Figure 5: r c game arbitrary reduction r0 c0 CURB set, irreducible priortechniques.irreducible (iterated) dominance general eliminability everystrategy participates Nash equilibrium. game irreducible (othersingle strategy per player) recursive preprocessor row players utilitiesdistinct within column, column players utilities distinct withinrow (except last row column game, odd number rowscolumns).Three factors curb promise minimal CURB set algorithms powerful preprocessors Nash equilibrium finding. First, fastest Nash equilibrium finding algorithms,requiring exponential time worst case, tend run faster CURB setfinding algorithms many types games (at least best known implementationsalgorithms). Second, smallest CURB set arbitrarily large (up sizeentire game, case preprocessor eliminate strategiesconsideration). Third, show, even smallest minimal CURB setidentified, remaining search space (CURB set size) arbitrarily largersize supports contained Nash equilibrium.prove this, use following family games contain large minimalCURB sets small-support equilibria. integer k > 0, define game kfollows. previous proof, assign utilities u(sr1 , sc1 ) = u(sr2 , sc2 ) = (0, 1)u(sr1 , sc2 ) = u(sr2 , sc1 ) = (1, 0), let Z arbitrarily large value (essentially ).Then, [3, 2 + k],u(sri , sc1 ) = (Z, ), u(sr1 , sci ) = (, Z),u(sri , sci ) = (0, 0),u(sri , sci1 ) = (1 + , 0), u(sri1 , sci ) = (0, 1 + ),527fiBenisch, Davis, & Sandholmj > + 1 j 2 + n,u(sri , scj ) = (0, Z), u(srj , sci ) = (Z, 0)example, game 2 follows.2sr1sr2sr3sr4sc10,11,0Z,Z,sc21,00,11+,0Z, 0sc3,Z0,1+0,01+,0sc4,Z0,Z0,1 +0,0respect strategic structure games class, followingresults.Lemma 1. > 2, row (column) players strategy sri (sci ) best responsecolumn (row) players strategy sci1 (sri1 ). column (row) players strategy sc1 (sr1 )best response row (column) players strategy srn+2 (scn+2 ).Proposition 6. k single minimal CURB set includes entire game.Proof. Strategies sr1 , sr2 , sc1 , sc2 must included minimal CURB set,best responses subgame containing them, subgameadmits pure-strategy Nash equilibrium. Based Lemma 1, see = 3,row (column) players strategy sr3 (sc3 ) best response column (row) playerssecond strategy. forces third strategy player minimal CURB setcontaining first two strategies player, inductively additional strategyadded way.Proposition 7. k , Nash equilibrium mixed-strategy profilesr1 , sr2 , sc1 , sc2 played probability 21 .Proof. Assume, contradiction, case, is, exists mixture,mr , rows Mr , comprising row players profile Nash equilibrium,sr1/ Mr . Along assumption, definition Nash equilibrium impliesmust exist mixture, mc , columns Mc r (mc ) = Mr c (mr ) = Mc .Since sr1 Mr assumption, exists > 1 sri lowest numberedsupport Mr , definition specifies outcome, u(sri , scj ) = (0, Z),j > + 1.column players Nash equilibrium supports cannot contain scj ,placing positive probability strategy lead highly negative expectedpayoff playing pure strategy sc1 provides guaranteed payout least 0.exclude strategies, sci+1 (the highest-numbered remaining column strategy)remaining strategy, sc1 , provides non-zero utility mixtures rowsi. words, dominates column strategies row players supports Mr ,aside one: sc1 .528fiAlgorithms Closed Rational Behavior (CURB) SetsSince dominated strategies cannot played equilibrium, Mc constrainedsubset {sc1 , sci+1 }. Mc contains sc1 , Mr must include srj j > 2, duehighly negative expected payoff mixture including strategies (as discussedabove). case, remaining possible equilibrium row mixture purestrategy sr2 , best response sc3 . Since, Corollary 2, n pureNash equilibrium, cannot constitute equilibrium, contradicting assumption.Alternatively, Mc include sc1 , mc must pure strategy sci+1 ,Lemma 1 provides pure-strategy best response pure strategy > 2.would, again, form pure strategy Nash equilibrium, shown cannot exist.reasoning also inverted show contradiction causedassumption Mc contain sc1 .shown row players equilibrium mixture must contain r1 r2 ,column players equilibrium mixture must contain c1 c2 strategieseither players supports, since would lead one highly negativeutility.game demonstrates possible construct large CURB setsloose around supports enclosed Nash equilibrium, giving us following generalresult.Theorem 4. Nash equilibrium supports consisting two strategies playerNash equilibrium arbitrarily large minimal CURB set.results imply minimal CURB set algorithms always effectivepreprocessors Nash equilibrium finding. However, game instances smallCURB set relatively tight minimal CURB set,2 algorithms potentialyield significant speed improvement.Furthermore, existence polynomial-time algorithm detecting gamessmallest CURB set (small MC) allows us offer following theoretical result potentialgeneral interest.Theorem 5. complexity finding Nash equilibrium two-player normal-formgame super-polynomial size games smallest CURB set (notsize full game).relationship complexity finding minimal CURB setfinding Nash equilibrium surprising several ways. one, obviousfinding minimal CURB set easier finding Nash equilibrium, since, likeNash equilibria, CURB sets exponential space possible supports chosen maximization processes players. Yet theoretical, worst-caseperspective, Nash equilibrium finding PPAD-complete (which widely believedstrictly harder complexity class P) and, showed earlier paper, minimalCURB set finding polynomial time.worth noting games small support equilibria, include gamessmall CURB sets, already known easily solvable Nash equilibria2. game relatively tight CURB set, Nash equilibrium found quickly enumeratingstrategies CURB left supports.529fiBenisch, Davis, & Sandholmusing techniques support enumeration. particular, games whose smallestCURB set size logarithmic full game size, support enumeration CURBset preprocessing permit guarantee polynomial runtime finding Nash equilibrium.CURB set preprocessing additional advantage also used simplifygames larger equilibrium supports, support enumeration exponential.example, consider Gk game class described Sandholm, Gilpin Conitzer (2005),generates games single equilibrium, equilibrium contains halfstrategies support. also determined games single CURB set,CURB set includes exactly supports equilibrium. Games classpadded, using embedding technique Theorem 3, become arbitrarilylarge games without introducing additional equilibria CURB sets. games,CURB set detection offers polynomial-time method reducing game pointalgorithms based support enumeration applied.complexity two problems (Nash equilibrium finding CURBset finding) practice? Figure 6 shows, average runtimes smallest CURBset finding algorithm Lemke-Howson Nash equilibrium finding algorithm (usingimplementation Gambit, McKelvey, McLennan, & Turocy, 2004) seem scale similarlyinput game size (when one explicitly generate pathological casesproduce exponential behavior latter, Savani & von Stengel, 2004). fact, CURBset algorithms slower (by two orders magnitude) average Lemke-Howson.experimental performance agrees intuition, reverse theoreticalstate knowledge regarding worst-case complexity.1000small_MCLemke Howson1001010.10.01Covariant gamesLogscale runtime (sec)Logscale runtime (sec)Random games20 30 40 50 60 70 80 90 100Game size (n)1000small_MCLemke Howson1001010.10.0120 30 40 50 60 70 80 90 100Game size (n)Figure 6: Average runtime 95% confidence intervals small MC Lemke Howsonfunction game size.worth pointing algorithm builds part work oneCURB set problems (finding minimal CURB sets) presented workingpaper (Klimm, Sandholm, & Weibull, 2010), appears scale favorablyours. However, algorithm directly compared Lemke-HowsonNash equilibrium finding algorithms, relative value related preprocessingremains seen.530fiAlgorithms Closed Rational Behavior (CURB) Setsroot cause complexity Nash equilibrium search proved elusive, twocandidates considered potential culprits shown affect worstcase complexity: games two players binary utilities difficultgeneral case, even restrictions apply simultaneously (Chen & Deng, 2006; Abbottet al., 2005). fact bounding smallest CURB set size serve bounddifficulty Nash equilibrium search suggests isolate causeequilibrium search complexity endemic minimal CURB sets, rather gamesgeneral. regard, observe special two-player game used ChenDeng show PPAD-completeness (Chen & Deng, 2006) single minimal CURBset, remains Abbott et al.s (Abbott et al., 2005) transformation binaryutilities.6. Conclusionspresented thorough computational treatment CURB sets, important set-valued,game-theoretic solution concept, including several algorithms finding CURB setstwo-player, normal-form games. algorithms find minimal CURB sets (all MC),one minimal CURB set (one MC), smallest minimal CURB set (small MC),polynomial time. algorithms based basic properties CURB sets prove,fact minimal CURB sets cannot overlap. algorithms use dovetailingpriority queue, exploiting information across overlapping, non-minimal CURBsets, improve speed.Experiments random games showed that, unsurprisingly, small MC tendsfastest, one MC second, MC slowest. However, covariant games speedadvantage former two disappears. runtime algorithms primarilydetermined size smallest CURB set, covariant games, tendlarger CURB sets, algorithms (especially one MC) suffer.algorithms also enable study CURB set size distributions different gameclasses. showed instance distributions GAMUT mainly extremal,sense given game generator yield mostly games pure-strategy equilibriaand/or games game sole minimal CURB set. However, curiously,generators yield significant number games smallest CURB setsspecific non-extremal sizes.also examined potential using algorithms preprocessors Nash equilibrium finding algorithms. proved technique eliminate arbitrarily largeportion game consideration, guaranteeing remaining subgamecontains least one Nash equilibrium full game. case even gamesprior preprocessing techniques, including iterated removal dominated strategies, powerless.downside, showed smallest CURB set arbitrarily large and/orarbitrarily loose. Furthermore, many distributions, showed current Nash equilibrium finding algorithms run faster, average, CURB set algorithms.surprising theoretical worst-case complexity two problems reverse.demonstrated worst-case complexity finding Nash equilibrium polynomial known aspects game except size smallest CURB set. Taken531fiBenisch, Davis, & Sandholmtogether CURB set finding algorithms polynomial time even worstcase, fact Nash equilibrium finding super-polynomial worst case (unless PPAD=P), observe essence worst-case complexity finding Nashequilibrium complexity finding Nash equilibrium within minimal CURB set.CURB set definition number players, presentedalgorithms two-player setting. larger number players, obstaclefinding minimal CURB sets finding conditional best responses quickly subroutine.showed problem solved fast two playersin settings involvessolving simple linear feasibility program. However, mathematical program usedegree p 1, p number players, three players constraintsalready quadratic. plus side, algorithms make polynomial numbercalls subroutine. Therefore, future research able identify polynomial-timealgorithms finding players conditional best responses n-player games,CURB set algorithms also polynomial time settings.Acknowledgmentsmaterial based upon work supported National Science Foundation ITR grant0205435, IGERT grant 9972762, IIS grants 0121678, 0427858, 0905390, wellOffice Naval Research grant N00014-02-1-0973, Sloan Fellowship. wouldalso like thank anonymous reviewers, Vincent Conitzer, Andrew Gilpinhelpful input advice.ReferencesAbbott, T., Kane, D., & Valiant, P. (2005). complexity two-player win-lose games.Proceedings Symposium Foundations Computer Science (FOCS), pp.113122.Basu, K., & Weibull, J. W. (1991). Strategy subsets closed rational behavior. Economics Letters, 36 (2), 141146.Battigalli, P., & Siniscalchi, M. (2003). Rationalizable bidding first-price auctions. GamesEconomic Behavior, 45 (1), 3872.Bernheim, B. D. (1984). Rationalizable strategic behavior. Econometrica, 52 (4), 100728.Brandt, F., Brill, M., Fischer, F., & Harrenstein, P. (2009). Computational aspectsShapleys saddles. Proceedings International Conference AutonomousAgents Multi-Agent Systems (AAMAS), pp. 209216.Chen, X., & Deng, X. (2006). Settling complexity two-player Nash-equilibrium.Proceedings Symposium Foundations Computer Science (FOCS), pp.261272.Conitzer, V., & Sandholm, T. (2005a). Complexity (iterated) dominance. ProceedingsACM Conference Electronic Commerce (ACM EC), pp. 8897.532fiAlgorithms Closed Rational Behavior (CURB) SetsConitzer, V., & Sandholm, T. (2005b). generalized strategy eliminability criterioncomputational methods applying it.. Proceedings National ConferenceArtificial Intelligence (AAAI), pp. 483488.Conitzer, V., & Sandholm, T. (2006). technique reducing normal form games compute Nash equilibrium. Proceedings International Conference AutomatedAgents Multi-Agent Systems (AAMAS), pp. 537544.Daskalakis, C., Goldberg, P. W., & Papadimitriou, C. H. (2009). complexity computing nash equilibrium. Communications ACM, 52 (2), 8997.Gilboa, I., Kalai, E., & Zemel, E. (1993). compleixty eliminating dominated strategies. Mathematics Operations Research, 18, 553565.Gilboa, I., & Zemel, E. (1989). Nash correlated equilibria: complexity considerations. Games Economic Behavior, 1, 8093.Hurkens, S. (1995). Learning forgetful players. Games Economic Behavior, 11 (1),304329.Jordan, P., & Wellman, M. (2010). Algorithms finding approximate formations games.Proceedings National Conference Artificial Intelligence (AAAI), pp. 798804.Klimm, M., Sandholm, T., & Weibull, J. W. (2010). Finding minimal sCURB setsfinite games. Mimeo, 3/24/2010.Knuth, D. E., Papadimitriou, C. H., & Tsitsiklis, J. N. (1988). note strategy eliminationbimatrix games. Letters, 7 (3), 103107.Lemke, C., & Howson, J. (1964). Equilibrium points bimatrix games. JournalSociety Industrial Applied Mathematics, 12, 413423.McKelvey, R. D., McLennan, A. M., & Turocy, T. L. (2004). Gambit: Software toolsgame theory, version 0.97.1.5. http://econweb.tamu.edu/gambit.Nudelman, E., Wortman, J., Shoham, Y., & Leyton-Brown, K. (2004). Run GAMUT:comprehensive approach evaluating game-theoretic algorithms.. ProceedingsInternational Conference Automated Agents Multi-Agent Systems (AAMAS), pp. 880887.Pearce, D. G. (1984). Rationalizable strategic behavior problem perfection.Econometrica, 52 (4), 102950.Porter, R., Nudelman, E., & Shoham, Y. (2004). Simple search methods findingNash equilibrium. Proceedings National Conference Artificial Intelligence(AAAI), pp. 664669.Pruzhansky, V. (2003). finding CURB sets extensive games. International JournalGame Theory, 32 (2), 205210.Sandholm, T., Gilpin, A., & Conitzer, V. (2005). Mixed-integer programming methodsfinding Nash equilibria. Proceedings National Conference ArtificialIntelligence (AAAI), pp. 495501.533fiBenisch, Davis, & SandholmSavani, R., & von Stengel, B. (2004). Exponentially many steps finding Nash equilibrium bimatrix game. Proceedings Symposium FoundationsComputer Science (FOCS), pp. 258267.Voorneveld, M., Kets, W., & Norde, H. (2005). axiomatization minimal CURB sets.International Journal Game Theory, 33, 479490.Ye, Y. (2006). Improved complexity results solving real-number linear feasibility problems. Mathematical Programming, 106 (2), 339363.534fiJournal Artificial Intelligence Research 38 (2010) 1-48Submitted 11/09; published 05/10Using Local Alignments Relation RecognitionSophia KatrenkoPieter AdriaansMaarten van SomerenS.Katrenko@uva.nlP.W.Adriaans@uva.nlM.W.vanSomeren@uva.nlInformatics Institute, University AmsterdamScience Park 107, 1098XG Amsterdam, NetherlandsAbstractpaper discusses problem marrying structural similarity semantic relatedness Information Extraction text. Aiming accurate recognition relations,introduce local alignment kernels explore various possibilities usingtask. give definition local alignment (LA) kernel based Smith-Watermanscore sequence similarity measure proceed range possibilities computing similarity elements sequences. show distributional similaritymeasures obtained unlabeled data incorporated learning task semantic knowledge. experiments suggest LA kernel yields promising resultsvarious biomedical corpora outperforming two baselines large margin. Additionalseries experiments conducted data sets seven general relation types,performance LA kernel comparable current state-of-the-art results.1. IntroductionDespite fact much work done automatic relation extraction (or recognition) past decades, remains popular research topic. main reasonkeen interest relation recognition lies utility. concepts semantic relationsidentified, used variety applications question answering(QA), ontology construction, hypothesis generation others.ontology construction, relation studied is-a relation (or hypernymy), organizes concepts taxonomy (Snow, Jurafsky, & Ng, 2006). information retrieval, semantic relations used two ways, refine queries actualretrieval, manipulate output returned search engine (e.g. identifyingwhether fragment text contains given relation not). widely used relationsquery expansion hypernymy (or broader terms thesaurus) synonymy.Semantic relations also useful different stages question answering.taken account identifying type question considered actual answer extraction time (van der Plas, 2008). Yet another applicationrelations constructing new scientific hypothesis given evidence found text.type knowledge discovery text often based co-occurrence analysis and, manycases, corroborated via experiments laboratories (Swanson & Smalheiser, 1999).Another reason extraction semantic relations interest lies diversityrelations. Different relations need different extraction methods. Many existing informationextraction systems originally designed work generic data (Grishman & Sundheim, 1996), became evident domain knowledge often necessary successfulc2010AI Access Foundation. rights reserved.fiKatrenko, Adriaans, & van Somerenextraction. instance, relation extraction biomedical domain would requireaccurate recognition named entities gene names (Clegg, 2008), areafood needs information relevant named entities toxic substances.Also generic relations syntactic information often sufficient. Consider,instance, following sentences (with arguments relations written italics):(1)Mary looked back whispered: know every tree forest, every scent.(Part-Whole relation)(2)person infected particular flu virus strain develops antibodiesvirus. (Cause-Effect relation)(3)apples basket. (Content-Container relation)sentences exemplify binary relations, namely Part-Whole (tree partforest), Cause-Effect (virus causes flu) Content-Container (apples containedbasket). easily notice syntactic context (1) (3) same, namely,arguments cases connected preposition in. However,context highly ambiguous even though allows us reduce numberpotential semantic relations, still sufficient able discriminatePart - Whole Content - Container relation. words, world knowledgetrees, forests, apples baskets necessary classify relations correctly.situation changes even drastically consider example (2). Here, explicitindication causation. Nevertheless, knowing flu virus is,able infer Cause - Effect relation holds.examples (1), (2) (3) highlight several difficulties characterize semanticrelation extraction. Generic relations often occur nominal complexes fluvirus (2) lack sentential context boosts approaches paraphrasing (Nakov,2008). However, even noun compounds one combine world knowledgecompounds context arrive correct interpretation.Computational approaches relation recognition problem often rely two-stepprocedure. First, relation arguments identified. Depending relation hand,step often involves named entity recognition arguments relations.second step check whether relation holds. relation arguments provided (e.g.,basket apples (3)), relation extraction reduced second step. Previouswork relation extraction suggests case accuracy relation recognitionmuch higher case discovered automatically (Bunescuet al., 2005). Furthermore, existing solutions relation extraction (including workpresented paper) focus relation examples occur within single sentenceconsider discourse (McDonald, 2005). Recognizing relations wider scopeinteresting enterprise, would require take account anaphora resolutiontypes linguistic analysis.Approaches relation extraction based hand-written patterns timeconsuming many cases need expert formulate test patterns. Althoughpatterns often precise, usually produce poor recall (Thomas et al., 2000).general, hand-written patterns two types. first type sequential based2fiUsing Local Alignments Relation Recognitionfrequently occurring sequences words sentence. Hand-written sequential patternsinitially used extraction Hypernymy (Hearst, 1992), several attemptsextend relations. second type patterns (Khoo, Chan, & Niu, 2000) takesyntactic structure sentence account. dependency structure sentenceusually represented tree patterns become subtrees. patternssometimes referred graphical patterns. identify examples Cause-Effectrelation, Khoo et al. (2000) applied type patterns texts medical domain.study showed graphical patterns sensitive errors made parsers,cover examples test data extract many spurious instances.alternative using hand-written patterns supervised Machine Learning. Then,relations labeled used train classifier recognize relations newtexts. One approach learn generalized extraction patterns patterns expressedcharacters, words syntactic categories words. approaches involve clusteringbased co-occurrence (Davidov & Rappoport, 2008). recent years kernel-based methodsbecome popular handle high-dimensional problems (Zelenko et al.,2003; Bunescu & Mooney, 2006; Airola et al., 2008). methods transform text fragments, complete sentences segments around named entitites verbs, vectors,apply Support Vector Machines classify new fragments.Machine Learning methods use prior knowledge given systemaddition labeled examples (Scholkopf, 1997, p. 17). use prior knowledge oftenmotivated by, example, poor quality data data sparseness. Prior knowledgeused many ways, changing representation existing training examples addingexamples unlabelled data. NLP tasks, prior knowledge exists formmanually (or automatically) constructed ontologies large collections unannotated data.enrich textual data thereby improve recognition relations (Sekimizu,Park, & Tsujii, 1998; Tribble & Fahlman, 2007). Recently, Zhang et al. (2008) showedsemantic correlation words learned unlabelled text collections, transferredamong documents used improve document classification. general,use large collections text allows us derive almost information needed, donevarying accuracy. contrast, existing resources created humans provideprecise information, less likely cover possible areas interest.paper, work Bunescu Mooney (2006), use syntacticstructure sentences, particular, dependency paths. stems observationlinguistic units organized complex structures understanding wordsword senses relate often requires contextual information. Relation extractionviewed supervised classification problem. training set consists examplesgiven relation goal construct model applied new, unseendata set, recognize instances given relation new data set. recognitionrelations use kernel-based classifier applied dependency paths. However,instead vector-based kernel directly use similarity dependency pathsshow information existing ontologies large text corpora employed.paper organized follows. start reviewing existing kernel methodswork sequences (Section 2). Section 3, give definition local alignment kernelbased Smith-Waterman measure. proceed discussing usedcontext natural language processing (NLP) tasks, particularly extracting3fiKatrenko, Adriaans, & van Somerenrelations text (Section 3.2). method described, report two typesdata sets (biomedical generic) used experiments (Section 4) elaborateexperiments (Sections 5 6). Section 7 discusses findings detail.Section 8 concludes paper discussing possible future directions.2. Kernel Methodspast years witnessed boost interest kernel methods, theoretical analysispractical applications various fields (Burges, 1998; Shawe-Taylor & Christianini,2000). idea method works different structures representations,starting simplest representation using limited number attributes complexstructures trees, seems indeed attractive.define kernel function, recall standard setting supervised classification. training set n objects (instances) (x1 , y1 ), . . . , (xn , yn ) x1 , . . . , xn Xinput examples input space X corresponding labels y1 , . . . , yn {0,1},goal infer function h : X {0, 1} approximates target function t.However, h still err data reflected loss function, l(h(xi ), yi ).Several loss functions proposed literature far, best knownzero-one loss. loss function outputs 1 time method errsdata point (h(xi ) 6= yi ), 0 otherwise.key idea kernel methods lies implicit mapping objects highdimensional space (by using mapping function ) considering inner product(similarity) k(xi , xj ) =< (xi ), (xj ) >, rather representing explicitly. Functions used kernel methodssymmetric positive semi-definite,Pben Pnwhereby positive semi-definiteness defined i=1 j=1 ci cj k(xi , xj ) 0 n > 0,objects x1 , . . . , xn X , choice real numbers c1 , . . . , cn R. functionpositive semi-definite, algorithm may find global optimal solution.requirements w.r.t. symmetry positive semi-definiteness met, kernel calledvalid.Using idea kernel mapping, Cortes Vapnik (1995) introduced support vectormachines (SVM) method seeks linear separation two classesinput points function f (x) f (x) = wT (x) + b, wT Rp , b Rh(x) = sign(f (x)). Here, wT stands slope linear function boffset. Often, exist several functions separate data well,equally good. hyperplane separates mapped examples largest possiblemargin would best option (Vapnik, 1982).SVMs solve following optimization problem:nX1k w k2 +Cl(h(xi ), yi )f (x)=wT x+b 2argmin(4)i=1Equation 4, first part equation corresponds margin maximization(by minimizing 12 k w k2 ), second takes account error trainingset minimized (where C penalty term). hyperplane foundmay correspond non-linear boundary original input space. exist number4fiUsing Local Alignments Relation Recognitionstandard kernels linear kernel, Gaussian kernel others. Informationdata problem motivate choice particular kernel.shown Haussler (1999) complex kernel (referred convolution kernel )defined using simpler kernels.forms machine learning representations using prior knowledge definedalong methods exploiting it. Inductive logic programming offers one possiblesolution use explicitly, form additional Horn clauses (Camacho, 1994).Bayesian learning paradigm information hypothesis without seeing data encoded Bayesian prior (Mitchell, 1997) higher level distribution hierarchicalBayesian setting. less obvious though represent use prior knowledgelearning frameworks. case SVMs, three possible ways incorporatingprior knowledge (Lauer & Bloch, 2008). named sampling methods (prior knowledge used generate new data), kernel methods (prior knowledge incorporatedkernel function by, instance, creating new kernel), optimization methods(prior knowledge used reformulate optimization problem by, example, addingadditional constraints). choice kernel based general statistical propertiesdomain, attractive possibility incorporate explicit domain knowledgekernel. improve kernel smoothing space: instancessimilar higher probability belonging class kernel withoutprior knowledge.follows, review number kernels strings proposedresearch community past years. natural domain lookbiomedical field many problems formulated string classification(protein classification amino acid sequences, name few). Sequence representationis, however, applicable biomedical area, also consideredmany natural language processing tasks. introducing kernels usedbiomedicine, move NLP domain present recent work relation extractionemploying kernel methods.2.1 Spectrum KernelLeslie, Eskin, Noble (2002) proposed discriminative approach protein classification.sequence x X , authors define m-spectrum set contiguoussubsequences x whose length equal m. possible m-long subsequences qindexed frequency occurrence (q (x)). Consequently, feature mapsequence x alphabet equals (x) = (q (x))qAm . spectrum kernel twosequences x defined inner product corresponding feature maps:kS (x, y) =< (x), (y) >.Now, even assuming contiguous subsequences small m, feature space considerlarge. authors propose detect subsequences length using suffixtree method guarantees fast computation kernel matrix. spectrum kerneltested task protein homology detection, best results achievedsetting relatively small number (3). novelty Leslie et al.s (2002) methodlies generality low computational complexity.5fiKatrenko, Adriaans, & van Someren2.2 Mismatch Kernelsmismatch kernel introduced later Leslie et al. (2004) essentially extension latter. obvious limitation spectrum kernel consideredsubsequences contiguous match exactly. mismatch kernel contiguity preserved match criterion changed. words, instead lookingpossible subsequences length given subsequence, one searchingpossible subsequences length allowing r mismatches. comparisonresult larger subset subsequences, kernels defined way still calculated rather fast. kernel formulated similarly spectrum kernelmajor difference computing feature mapP sequences. precisely, featuremap sequence x defined m,r (x) = qS m,r (q) m,r (q) = ( (q))Am .(q) binary indicates whether sequence belongs set m-length sequencesdiffer q r elements (1) (0). clear r set0, mismatch kernel reduced spectrum kernel. complexity mismatchkernel computation linear respect sum sequence lengths.authors also show mismatch kernel yields state-of-the-art performance protein classification task also outputs subsequences informativebiological point view.2.3 Kernel Methods NLPOne merits kernel methods possibility designing kernels different structures, strings trees. NLP field (and relation extraction, particular)work roughly falls two categories. first, kernels defined plaintext using sequences words. second uses linguistic structures dependencypaths trees output shallow parsing. short review takechronological perspective rather start methods based sequencesproceed approaches make use syntactic information.year spectrum kernel designed, Lodhi et al. (2002) introduced string subsequence kernels provide flexible means work text data.particular, subsequences necessarily contiguous weighted accordinglength (using decay factor ). length subsequences fixed advance.authors claim even without use linguistic information kernelsable capture semantic information. reflected better performancetext classification task compared bag-of-words approach. Lodhi et al.s (2002)kernel works sequences characters, kernel proposed Cancedda et al. (2003)applied word sequences. String kernels also extended syllable kernelsproved well text categorization (Saunders, Tschach, & Shawe-Taylor, 2002).kernels defined recursively, computation efficient.instance, time complexity Lodhi et al.s (2002) kernel O(n|s||t|), nlength subsequence, documents.2.3.1 Subsequence Kernelsrecognition binary relations, natural way consider words locatedaround relation arguments. approach taken Bunescu Mooney6fiUsing Local Alignments Relation Recognition(2005b) whose choice sequences motivated textual patterns found corpora.instance, observed relations expressed subject-verb-object constructions others part noun prepositional phrases. result, three typessequences considered: fore-between (words two named entities),(words two entities) between-after (words twoentities). length sequences restricted. handle data sparseness, authorsgeneralize existing sequences using PoS tags, entity types WordNet synsets.generalized subsequence kernel recursively defined number weighted sparse subsequences two sequences share. absence syntactic information, assumptionmade long subsequences likely represent positive examplespenalized. subsequence kernel computed three types sequencesresulting relation kernel defined sum three subkernels. Experimental resultsbiomedical corpus encouraging, showing relation kernel performs bettermanually written patterns approach based longest common subsequences.method proposed Giuliano et al. (2006) largely inspired work BunescuMooney (2005b). However, instead looking subsequences three types sequences, authors treat bag-of-words define called global kernelfollows. First, sequence type (pattern) P represented vector whose elementscounts many times token used P . local kernel defined similarlyusing words surrounding named entities (left right context). final shallowlinguistic kernel defined combination global local kernels. Experiments biomedical corpora suggest kernel outperforms subsequence kernelBunescu Mooney.2.3.2 Distributional KernelsRecently, Seaghdha Copestake (2008) introduced distributional kernels co- occurrence probability distributions. co-occurrence statistics use formeither syntactic relations n-grams. show possible derive kernelsdistances Jensen-Shannon divergence (JSD) Euclidean distance (L2 ) (Lee, 1999).JSD smoothed version Kullback-Leibler divergence, information-theoretic measure dissimilarity two probability distributions. main motivation behindapproach lies fact distributional similarity measures proved usefulNLP tasks. extract co-occurrence information, authors use two corpora, BritishNational Corpus (BNC) Web 1T 5-Gram Corpus (which contains 5-gramsobserved frequency counts collected Web). Distributional kernelsproved successful number tasks compound interpretation, relationextraction verb classification. them, JSD kernel clearly outperformsGaussian linear kernels. Moreover, estimating distributional similarity BNCcorpus yields performance similar results obtained Web 1T 5-Gram Corpus.interesting finding BNC corpus used estimate similaritysyntactic relations whereas latter corpus contains n-grams only. importantly,method Seaghdha Copestake provides empirical support claim usingdistributional similarity beneficial relation extraction.7fiKatrenko, Adriaans, & van Someren2.3.3 Kernels Syntactic StructuresKernels defined unpreprocessed text data seem attractive applieddirectly text language. However, general are, lose precision compared methods use syntactic analysis. Re-ranking parsingtrees (Collins & Duffy, 2001) one first applications kernel methods NLPproblems. accomplish goal, authors rely subtrees pair treescommon. Later on, Moschitti (2006) explored convolution kernels dependencyconstituency structures semantic role labeling question classification. workintroduces novel kernel called partial tree kernel (PT). essentially builttwo kernels proposed before, subtree kernel (ST) contains descendant nodestarget root (including leaves) subset tree kernel (SST) flexibleallows internal subtrees necessarily encompass leaves. partial treegeneralization subset tree whereby partial structures grammar allowed (i.e.,parts production rules [VP [V]] form valid PT). Moschitti demonstratedPTs obtain better performance dependency structures SSTs, latteryield better results constituent trees.2.3.4 Kernel Shallow Parsing OutputZelenko et al. (2003) use shallow parsing designed kernels extract relations text.contrast full parsing, shallow parsing produces partial interpretations sentences.node tree enriched information roles (that correspondarguments relation). similarity two trees determined similaritynodes. Depending similarity computed, Zelenko et al. define two typeskernels, contiguous subtree kernels sparse kernels. types tested two typesrelations, person-affiliation organization-location exhibiting good performance.particular, sparse kernels outperform contiguous subtree kernels leading conclusionpartial matching important dealing typically sparse natural languagedata. However, computation sparse kernel takes O(mn3 ) time (where nnumber children two relation examples, i.e. shallow trees, consideration,n), algorithm contiguous subtree kernel runs time O(mn).2.3.5 Shortest Path KernelBunescu Mooneys (2005a) shortest path kernel represents yet another approachrelation extraction kernel-based relies information found dependency trees.main assumption entire dependency structure relevant, onefocus path connecting two relation arguments instead. similarpaths are, likely two relation examples belong category. spiritprevious work, Bunescu Mooney seek generalizations existing pathsadding information sources like part speech (PoS) categories named entity types.shortest path relation arguments extracted kernel twosequences (paths) x = {x1 , . . . , xn } x0 = {x01 , . . . , x0m } computed follows:8fiUsing Local Alignments Relation Recognition0kB (x, x ) =0Qn0i=1 f (xi , xi )6= nm=n(5)Equation 5, f (xi , x0i ) number features shared xi x0i . BunescuMooney (2005a) use several features word (e.g., protesters), part speech tag (e.g.,N N S), generalized part speech tag (e.g., N oun), entity type (e.g., P ERSON )applicable. addition, direction feature ( ) employed. reproduceexample paper.Example 1 Given two dependency paths exemplify relation Locatedactions Brcko arrival Beijing, paths expandedadditional features mentioned above. easy see comparing path (6)path (7) gives us score 18 (3111213 = 18).BrckoactionsNNPP RP[] N N [][]N ounP ERSONN ounLOCAT ION(6)BeijingNNP[]N ounLOCAT ION(7)arrival[] N N[]P RPN ounP ERSONtime complexity shortest path kernel O(n), n stands lengthdependency path.Dependency paths also considered recent work relation recognition (Erkan,Ozgur, & Radev, 2007). Here, Erkan et al. (2007) use dependency paths inputcompare means cosine similarity edit distance. authors motivatechoice need compare dependency paths different length. Further, various machine learning methods used classification, including SVM transuctive SVM(TSVM), extension SVM (Joachims, 1999). particular, TSVM makes uselabeled unlabeled data first classifying unlabeled examples searchingmaximum margin separates positive negative instances sets.authors conclude edit distance performs better cosine similarity measure,TSVM slightly outperforms SVM.Airola et al. (2008) propose graph kernel makes use entire dependencystructure. work, sentence represented two subgraphs, onebuilt dependency analysis, corresponds linear structuresentence. Further, kernel defined paths two vertices graph.method Airola et al. (2008) achieves state-of-the-art performance biomedicaldata sets, discussed, together shortest path kernel work9fiKatrenko, Adriaans, & van SomerenErkan et al. (2007), Section 5 relation extraction biomedical domainpaper.Finally, kernels defined graphs syntactic structures, alsographs semantic network. illustrated Seaghdha (2009), uses graphkernels graph built hyponymy relations WordNet. Even thoughsyntactic information utilized, kernels proved perform well extractionvarious generic relations.kernels reviewed section deal sequences trees albeit different ways. empirical findings suggest kernels allow partial matching usuallyperform better compared methods similarity defined exact match.alleviate problem exact matching, researchers suggested generalizingelements existing structures (Bunescu & Mooney, 2005a) others opted flexiblecomparison. view, types methods complement (Saunderset al., 2002). flexible partial matching methods are, may suffer low precision penalization mismatch low. holds approaches usegeneralization strategies may easily overgeneralize. possible solution wouldcombine both, provided mismatches penalized well generalizationssemantically plausible rather based part speech categories. ideaexplored present paper evaluated relation recognition task.nutshell, goals paper following: (i) study possibilitiesusing local alignment kernel relation extraction text, (ii) explorationuse prior knowledge alignment kernel (iii) extensive evaluationautomatic recognition two types relations, biomedical generic.3. Local Alignment KernelOne note short overview kernels designed NLP manyresearchers use partial structures propose variants subsequence kernels (Bunescu& Mooney, 2005b), partial tree kernel (Moschitti, 2006), kernel shallow parsingoutput (Zelenko et al., 2003) relation extraction. paper focus dependencypaths input formulate following requirements kernel function:allow partial matching similarity measured pathsdifferent lengthpossible incorporate prior knowledgeRecall prior knowledge mean information comes either larger corpora existing resources ontologies. instance, knowing developmentsynonymous evolution contexts help recognize two different wordsclose semantically. information especially useful meaning relevantdetecting relations may differ form.following subsection define local alignment kernel satisfiesrequirements show incorporate prior knowledge.10fiUsing Local Alignments Relation Recognition3.1 Smith-Waterman Measure Local Alignmentswork motivated recent advances biomedical field. shownpossible design valid kernels based similarity measure strings (Saigo,Vert, & Akutsu, 2006). example, Saigo, Vert, Ueda, Akutsu (2004) considerSmith-Waterman (SW) similarity measure (Smith & Waterman, 1981) (see below) measure similarity two sequences amino acids.String distance measures divided measures based terms, edit-distanceHidden Markov models (HMM) (Cohen, Ravikumar, & Fienberg, 2003). Term-baseddistances measures based TF-IDF score, consider pair word sequencestwo sets words ignoring order. contrast, string edit distances (or string similaritymeasures) treat entire sequences compare using transformation operations,convert sequence x sequence x0 . Examples Levenshtein distance,Needleman-Wunsch (Needleman & Wunsch, 1970) Smith-Waterman (Smith& Waterman, 1981) measures. Levenshtein distance used naturallanguage processing field component variety tasks, including semantic rolelabeling (Sang et al., 2005), construction paraphrase corpora (Dolan, Quirk, & Brockett,2004), evaluation machine translation output (Leusch, Ueffing, & Ney, 2003), others.Smith-Waterman measure mostly used biological domain, are, however,applications modified Smith-Waterman measure text data well (Monge &Elkan, 1996; Cohen et al., 2003). HMM-based measures present probabilistic extensionsedit distances (Smith, Yeganova, & Wilbur, 2003).hypothesis string similarity measures best basis kernelrelation extraction. case, order words appear likely relevantsparse data usually prevents estimation probabilities (as work Smith et al.,2003). general, two sequences aligned several possible ways. possiblesearch either alignment spans entire sequences (global alignment),alignment based similar subsequences (local alignment). casesequences amino acids relation extraction, local patterns likelyimportant factor determines similarity. Therefore need similarity measureemphasizes local alignments.Formally, define pairwise alignment L elements two sequencesx = x1 x2 . . . xn x0 = x01 x02 . . . x0m , pairing = {l (i, j)}, l = 1, . . . , L, 1 n,1 j m, 1 l n, 1 l m. Example 2 (ii), third element first sequencealigned first element second one, denoted 1 (3, 1).Example 2 Given sequences x=abacde x0 =ace, two possible alignments (with gapsindicated -) follows.(i) global alignmentb--cc-eeAlignment:= {1 (1, 1), 2 (4, 2), 3 (6, 3)}cc-eeAlignment:= {1 (3, 1), 2 (4, 2), 3 (6, 3)}(ii) local alignment-b-11fiKatrenko, Adriaans, & van Somerenexample, number gaps inserted x0 align x numberelements match cases. Yet, biologicallinguistic context may prefer alignment (ii), closely matching substrings,local alignments, better indicator similarity shared items far apart.is, therefore, better use measure puts less weight gapsstart end strings (as Example 2 (ii)). done using localalignment mechanism searches similar subsequences two sequences.Local alignments employed sequences dissimilar different length,global alignments considered sequences roughly length.measures mentioned above, Smith-Waterman measure local alignmentmeasure, Needleman-Wunsch measure compares two sequences based globalalignments.Definition 1 (Global alignment) Given two sequences x = x1 . . . xn x0 = x01 . . . x0m ,global alignment pair sequences y0 length,obtained inserting zero gaps first element either x x0 ,element x x0 .Definition 2 (Local alignment) Given two sequences x = x1 . . . xn x0 = x01 . . . x0m ,local alignment pair subsequences x x0 , whose similaritymaximal.clarify mean local global alignments, give definitionSmith-Waterman Needleman-Wunsch measures. Given two sequences x = x1 x2 . . . xnx0 = x01 x02 . . . x0m length n respectively, Smith-Waterman measure definedsimilarity score best local alignment:sw(x, x0 ) =maxA(x,x0 )s(x, x0 , )(8)equation above, s(x, x0 , ) score local alignment sequence x x0denotes set possible alignments. best local alignment efficientlyfound using dynamic programming. this, one fills matrix SW partialalignments follows:0SW(i 1, j 1) + d(xi , x0j )SW (i, j) = max1in,SW(i 1, j) G1jmSW(i, j 1) G(9)Equation 9, d(xi , x0j ) denotes substitution score two elements xi x0jG stands gap penalty. Using equation possible find partial alignments,stored matrix cell (i, j) reflects score alignment x1 . . . xi12fiUsing Local Alignments Relation Recognitionce00000210b01100210c01430033e0025ce(a) Smith-Waterman measure00000210b01100000c0-1210-111e0-103(b) Needleman-Wunsch measureTable 1: Matrices computing Smith-Waterman Needleman-Wunsch scores sequences x=abacde x0 =ace, gap G = 1, substitution score d(xi , x0j ) = 2xi = x0j , d(xi , x0j ) = 1 xi 6= x0j .x01 . . . x0j . cell largest value matrix contains Smith-Watermanscore.Needleman-Wunsch measure, searches global alignments, defined similarly, except fact cells matrix contain negative scores:NW(i 1, j 1) + d(xi , x0j )NW (i, j) = maxNW(i 1, j) G1in,NW(i, j 1) G1jm(10)Smith-Waterman measure seen modification Needleman-Wunschmethod. disallowing negative scores matrix, regions high dissimilarityavoided and, result, local alignments preferred. Moreover, NeedlemanWunsch score equals largest value last column last row, Smith-Watermansimilarity score corresponds largest value matrix.Let us reconsider Example 2 show global local alignments alignmentstwo sequences x=abacde x0 =ace obtained. arrive actual alignments, oneset gap parameter G substitution scores. Assume use followingsettings: gap G = 1, substitution score d(xi , x0j ) = 2 xi = x0j , d(xi , x0j ) = 1xi 6= x0j . values chosen illustrative purpose only, realisticcase, e.g., alignment protein sequences, choice substitution scores usuallymotivated biological evidence. gapping, Smith Waterman (1981) suggesteduse gap value least equal difference match (d(xi , x0j ),xi = x0j ) mismatch (d(xi , x0j ), xi 6= x0j ). Then, Smith-Waterman NeedlemanWunsch similarity scores x x0 calculated according Equation 9Equation 10 given Table 1.First, first row first column matrix initialized 0. Then,matrix filled computing maximum score cell defined Equation 9Equation 10. score best local alignment equal largest element13fiKatrenko, Adriaans, & van Somerenmatrix (5), Needleman-Wunsch score 3. Note possible trace backsteps taken arrive final alignment (the cells boldface). left-rightstep corresponds insertion, top-down step deletion (these lead gaps),diagonal step implies alignment two sequences elements.Since prefer use local alignments dependency paths, natural choice woulduse Smith-Waterman measure kernel function. However, Saigo et al. (2004)observed Smith-Waterman measure may result valid kernelmay positive semi-definite. give definition LA kernel, statestwo sequences similar many local alignments high scores,Equation 11.kL (x, x0 ) =X0es(x,x ,)(11)A(x,x0 )Here, s(x, x0 , ) local alignment score ( 0) scaling parameter.define LA kernel kL (as Equation 11) two sequences x x0 , neededtake account transformation operations used local alignments. First, onedefine kernel elements corresponds individual alignments, ka . Second,since type alignment allows gaps, another kernel gapping, kg . Lastleast, recall local alignments parts sequences may aligned,elements x x0 may left out. elements influence alignmentscore kernel used cases, k0 , set constant, k0 (x, x0 ) = 1. Finally,LA kernel composition several kernels (k0 , ka , kg ), spiritconvolution kernels (Haussler, 1999).According Saigo et al. (2004), similarity aligned sequences elements (ka kernel)defined follows:0|x| =6 1 |x0 | =6 10ka (x, x ) =(12)0)d(x,xeotherwiseeither x, x0 one element, kernel would result 0. Otherwise,calculated using substitution score d(x, x0 ) x x0 . score reflectssimilar two sequences elements and, depending domain, computed usingprior knowledge given domain.gapping kernel defined similarly alignment kernel Equation 12, wherebyscaling parameter preserved, gap penalties used instead similarityfunction two elements:0kg (x, x0 ) = e(g(|x|)+g(|x |))(13)Here, g stands gap function. Naturally, gap length 0 function returnszero. gaps length n, reasonable define gap terms gap openinggap extension e, g(n) = + e (n 1). case possible decide whether longergaps penalized shorter ones, much. instance,14fiUsing Local Alignments Relation Recognitionthree consecutive gaps alignment, first gap counted gap opening,two gap extension. consecutive gaps (i.e., gaps length n > 1) gapequal importance, gap opening equal gap extension. If, however,length gaps matter, one would prefer penalize gap opening more,give little weight gap extension.kernels combined follows:k(r) (x, x0 ) = k0 (ka kg )r1 ka k0(14)Equation 14, k(r) (x, x0 ) stands alignment r elements x x0 possiblyr 1 gaps. Similarity aligned elements calculated ka , gapping kg . Sincecould r 1 gaps, corresponds following part equation:(ka kg )r1 . Further, rth aligned element, one ka added. Givendiscussion above, k0 added initial final part. follows Equation 14,elements x x0 aligned, k(r) equals k0 , 1. elements xx0 aligned gaps, value k(r) (ka )r .Finally, LA kernel equal sum taken possible local alignmentssequences x x0 :0kL (x, x ) =Xk(i) (x, x0 )(15)i=0results biological domain suggest kernels based Smith-Watermandistance relevant comparison amino acids string kernels (Saigo et al.,2006). clear whether holds applied natural language processing tasks.view, could depend parameters used, substitutionmatrix penalty gaps.3.1.1 Computational complexityLA kernel, many kernels discussed Section 2, efficiently calculated using dynamic programming. two sequences x x0 , length n respectively,complexity proportional n m. Additional costs may come substitution matrix, which, unlike biomedical domain, become large. However,look-up substitution scores done efficient manner well, leadsfast kernel computation. instance, calculating kernel matrix largest dataset used paper, AImed (3,763 instances), takes 805 seconds 2.93 GHz Intel(R)Core(TM)2 machine.3.2 Designing Local Alignment Kernel Relation ExtractionSmith-Waterman measure based transformations, particular deletions elements different strings. However, elements different may stillsimilar degree. similarities used part similarity measure.example, two elements words different synonyms,count less different completely unrelated. call15fiKatrenko, Adriaans, & van Somerensimilarities substitution scores (Equation 12) define two different ways:basis distributional similarity basis semantic relatedness ontology.Example 1 would like able infer Brcko similar Beijing, eventhough two words match exactly. Furthermore, phrases arrivalBeijing arrival January, would like kernel say Brckosimilar Beijing January. use information prior knowledgemakes possible measure similarity two words, one test settraining set, even match exactly. review two typesmeasures based statistical distributions relatedness WordNet.3.2.1 Distributional Similarity Measuresnumber distributional similarity measures proposed years, includingCosine, Dice Jaccard coefficients. Distributional similarity measures extensively studied (Lee, 1999; Weeds, Weir, & McCarthy, 2004). main hypothesisbehind distributional measures words occurring contextsimilar meaning (Firth, 1957). Context defined either using proximity text,employing grammatical relations. paper, use first option contextsequence words text length set advance.MeasureFormulaCosined(xi , x0j ) = PDiced(xi , x0j ) =L2d(xi , x0j ) =P (c|xi )P (c|x0j )P0 22c P (c|xi )c P (c|xj )Pc2F (xi )F (x0j )F (xi )F (x0j )qPc (P (c|xi )P (c|x0j ))2Table 2: list functions used estimate distributional similarity measures.chosen following measures: Dice, Cosine L2 (Euclidean) whose definitions given Table 2. definition Cosine L2, possible use eitherfrequency counts probability estimates derived unsmoothed relative frequencies.Here, adopt definitions given Lee (1999), based probability estimates P . Recall x x0 two sequences would wish compare,corresponding elements xi x0j . Further, c stands context. definitionDice coefficient, F (xi ) = {c : P (c|xi ) > 0}. mainly interested symmetric measures(d(xi , x0j ) = d(x0j , xi )) symmetric positive semi-definite matrix required kernel methods. Euclidean measure defined Table 2 necessarily vary 01. reason, given list pairs words (xi , x0j ) xi fixed j = 1, . . . ,corresponding L2 score, maximum value maxj d(xi , x0j ) detected usednormalize scores list. Furthermore, unlike Dice Cosine, return 1case two words equal, Euclidean score equals 0. next step, substractobtained normalized value 1 ascertain scores within interval [0, 1]16fiUsing Local Alignments Relation Recognitionlargest value (1) assigned identical words. view, proceduremake comparison selected distributional similarity measures respectinfluence LA kernel transparent.Distributional similarity measures suitable information available.case data annotated means taxonomy (e.g., WordNet),possible consider measures defined taxonomy. Availability hand-craftedresources, WordNet, comprise various relations concepts, enablesmaking distinctions different concepts subtle way.3.2.2 WordNet Relatedness Measuresgeneric relations, commonly used resource WordNet (Fellbaum, 1998),lexical database English. WordNet, words grouped together synsetssynset consists list synonymous words collocations (e.g., fountain pen),pointers describe relations synset synsets (Fellbaum, 1998).WordNet employed different purposes studying semantic constraintscertain relation types (Girju, Badulescu, & Moldovan, 2006; Katrenko & Adriaans, 2008),enriching training set (Giuliano et al., 2007; Nulty, 2007).compare two concepts given synsets c1 c2 use five different measuresproposed past years. rely notions lengthshortest path two concepts c1 c2 , len(c1 , c2 ), depth nodeWordNet hierarchy (which equal length path root givensynset ci ), dep(ci ), least common subsumer (or lowest super-ordinate) c1c2 , lcs(c1 , c2 ), turn synset. measures exclusively basednotions belong conceptual similarity proposed Palmer Wu (1995) (simwupEquation 16) formula scaled semantic similarity introduced LeacockChodorow (1998) (simlch Equation 17). 1 major difference liesfact simlch consider least common subsumer c1 c2 usesmaximum depth WordNet hierarchy instead. Conceptual similarity ignoresfocuses subhierarchy includes synsets.simwup (c1 , c2 ) =2 dep(lcs(c1 , c2 ))len(c1 , lcs(c1 , c2 )) + len(c2 , lcs(c1 , c2 )) + 2 dep(lcs(c1 , c2 ))simlch (c1 , c2 ) = loglen(c1 , c2 )2 maxcW ordN et dep(c)(16)(17)Aiming combining information several sources, Resnik (1995) introduced yet another measure grounded information content (simres Equation 18). Intuitively,two synsets c1 c2 located deeper hierarchy path one synsetanother short, similar. path two synsets longleast common subsumer placed relatively close root, indicates synsets1. equations similarity measures defined WordNet, subscripts refer similarity measure(e.g., lch, wup simlch simwup , respectively)17fiKatrenko, Adriaans, & van Somerenc1 c2 much common. quantify intuition, necessary deriveprobability estimate lcs(c1 , c2 ) done employing existing corpora.precisely, p(lcs(c1 , c2 )) stands probability encountering instance conceptlcs(c1 , c2 ).simres (c1 , c2 ) = log p(lcs(c1 , c2 ))(18)One biggest shortcomings Resniks method fact leastcommon subsumer appears Equation 18. One easily imagine full-blown hierarchyrelatedness concepts subsumed lcs(ci , cj ) heavily vary.words, using lcs only, one able make subtle distinctions twopairs concepts share least common subsumer. overcome this, JiangConrath (1997) proposed solution takes account information synsetscompared (simjcn Equation 19). comparing Equation 19 Equation 18,notice equation incorporates probability encounteringlcs(c1 , c2 ), also probability estimates c1 c2 .simjcn (c1 , c2 ) = 2 log p(lcs(c1 , c2 )) (log p(c1 ) + log p(c2 ))(19)Lin (1998) defined similarity two concepts using much commonalitydifferences involved. Similarly two previous approaches, usesinformation theoretic notions derives similarity measure simlin given Equation 20.simlin (c1 , c2 ) =2 log p(lcs(c1 , c2 ))log p(c1 ) + log p(c2 )(20)past, semantic relatedness measures evaluated different NLP tasks (Budanitsky & Hirst, 2006; Ponzetto & Strube, 2007) concluded measureperforms best problems. evaluation, use semantic relatednessvalidation generic relations study depth contribute final results.3.2.3 Substitution Matrix Relation Extractionnow, discussed two possible ways calculating substitution score d(, ),using either distributional similarity measures, measures defined WordNet. However,dependency paths generated parsers may contain words (or lemmata),also syntactic functions subjects, objects, modifiers, others. takeaccount, revise definition d(, ). assume sequences x = x1 x2 . . . xnx0 = x01 x02 . . . x0m contain words (xi W W refers set words) syntacticfunctions accompanied direction (xi/ W ). elements W unique words (orlemmata) found dependency paths, instance, pathsactions Brcko arrival Beijing Example (1) Section 2.3.5,W = {his, actions, in, Brcko, arrival, Beijing}. dependency paths use presentwork include information syntactic functions, instance awarenessjoy. case, W = {awareness, come, joy} W = {18prep f romprep f rom nsubj, }.nsubjcomefiUsing Local Alignments Relation RecognitionThen,d(xi , x0j )10d0 (xi , x0j ) =00xi , x0j Wxi , x0j/ W & xi = x0j0xi , xj/ W & xi 6= x0jxi W & x0j/Wxi/ W & x0j W(21)Equation (21) states whenever element xi sequence x comparedelement x0j sequence x0 , substitution score equal either (i) similarityscore case elements words (lemmata), (ii) 1, elementssyntactic function, (iii) 0, case.follows discussion similarity measures above, two ways defined(xi , x0j ), using either distributional similarity xi x0j (Section 3.2.1),WordNet similarity, provided annotated WordNet synsets (Section 3.2.2).4. Experimental Set-upsection, describe data sets used experiments provideinformation data collections used estimating distributional similarity.4.1 Dataevaluate performance LA kernel, consider two types text data, domainspecific data, comes biomedical domain generic domain-independentdata represents variety well-known widely used relations PartWhole Cause-Effect.Like work, extract dependency path two nodes correspondingarguments binary relation. also assume analysis results tree sinceacyclic graph, exists unique path pair nodes.consider, however, structures might derived full syntactic analysisin, example, subtrees (Moschitti, 2006).4.1.1 Biomedical RelationsCorpora use three corpora come biomedical field contain annotations either interacting proteins - BC-PPI2 (1,000 sentences), AImed (Bunescu & Mooney,2005b) interactions among proteins genes LLL (77 sentences training set87 test set, Nedellec, 2005). BC-PPI corpus created sampling sentences BioCreAtive challenge, AImed corpus sampled Medlinecollection. LLL corpus composed querying Medline term Bacillus subtilis. difference among three corpora lies directionality interactions.Table 3 shows, relations AImed corpus strictly symmetric, LLL asymmetric BC-PPI contains types. differences number training instancesAImed corpus explained fact correspond dependency2. Available http://www2.informatik.hu-berlin.de/~hakenber/.19fiKatrenko, Adriaans, & van Somerenpaths named entities. parsing fails produces several disconnected graphs persentence, dependency path extracted.ParserLinkParserLinkParserStanfordStanfordEnjuData setLLL (train)LLL (test)BC-PPIAImedAImed#examples61847666437635272#pos15383250922918directionasymmetricasymmetricmixedsymmetricsymmetrica. Even though actual annotations test data given, number interactionstest data set provided LLL organizers.Table 3: Statistics biomedical data sets LLL, BC-PPI, AImedd. table, #posstands number positive examples per data set #examples indicatesnumber examples total.goal relation extraction three cases output correct interactionsbiomedical entities (genes proteins) found input data.biomedical entities already provided, need named entity recognition.discrepancy training test sets used LLL challenge.Unlike training set, sentence example least one interaction,test set contains sentences interaction. organizers LLL challenge distinguish sentences without coreferences. Sentences coreferencesusually appositions, shown one examples below. first sentence (4.1.1)example sentence without coreferences (with interaction ykuD SigK),whereas second one sentence coreference (with interaction spoIVAsigmaE). precisely, spoIVA refers phrase one genesknown interact sigmaE. therefore infer spoIVA interacts sigmaE. Sentences without coreferences form subset, refer LLL-nocoref,sentences coreferences part separate subset LLL-coref.(22) ykuD transcribed SigK RNA polymerase T4 sporulation.(23) Finally, show proper localization SpoIVA required expression onegenes which, like spoIVA, control mother celltranscription factor sigmaE.assumed relations sentences coreferences harder recognize. show LA kernel performs subsets, report experimental results full set test data (LLL-all), subsets (LLL-coref LLL-nocoref).Syntactic analysis analyzed BC-PPI corpus Stanford parser. LLLcorpus already preprocessed LinkParser output checkedexperts. enable comparison previous work, used AImed corpus parsed20fiUsing Local Alignments Relation RecognitionStanford parser 3 Enju parser 4 (which exactly correspond inputexperiments Erkan et al., 2007 Stre et al., 2008). Unlike Stanford parser,Enju based Head-driven Phrase Structure Grammar (HPSG). outputEnju parser presented two ways, either predicate argument structurephrase structure tree. Predicate argument structures describe relations wordssentence, phrase structure presents sentence structure form clausesphrases. addition, Enju trained GENIA corpus includes modelparsing biomedical texts.(24) Cbf3 contains three proteins, Cbf3a, Cbf3b Cbf3c.containsdobjnsubjproteinsCbf3numconjconj conjthreeCbf3ansubjCbf3bdobjCbf3 contains proteinsnsubjdobjCbf3 contains proteinsnsubjdobjCbf3 contains proteinsCbf3bconjCbf3aCbf3bconjCbf3cconjFigure 1: Stanford parser output representation Example (24).Figure 1 shows dependency tree obtained Stanford parser sentence(24). sentence mentions three interactions among proteins, precisely,Cbf3 Cbf3a, Cbf3 Cbf3b, Cbf3 Cbf3c. three dependencypaths contain words (lemmata) syntactic functions (such subj subject) plusdirection traversing tree. Figure 2 presents output sentence providedEnju parser. upper part refers phrase structure tree lower partshows paths extracted predicate argument structure. two parsers clearlydiffer output. First, Stanford parser conveniently generates pathsthree interaction pairs Enju analyzer not. Second, outputStanford parser excludes prepositions conjunctions attached syntacticfunctions whereas Enju analyzer lists parsing results. differences3. Available http://nlp.stanford.edu/software/lex-parser.shtml.4. Available http://www-tsujii.is.s.u-tokyo.ac.jp/enju/.21fiKatrenko, Adriaans, & van Somerenlead different input sequences later fed LA kernel. Consequently,variations input may translate differences final performance.Cbf3Cbf3Cbf3ARG1/verbARG1/verbARG1/verbcontaincontaincontainARG2/verbARG2/verbARG2/verbproteinproteinproteinARG1/appARG1/appARG1/app,,,ARG2/appARG2/appARG2/appCbf3aCbf3aCbf3aARG1/coordARG1/coord,ARG2/coordCbf3bARG2/coordCbf3cFigure 2: Enjus output representation Example (24).addition, work employing AImed, dependency pathsFigure 1 Figure 2 preprocessed following way. actual named entitiesarguments relation replaced label, e.g. PROTEIN. Consequently,nsubjdobjconjfirst path Figure 1 becomes PROTEIN contains proteins PROTEIN.able compare results AImed performance reported workErkan et al. (2007) Stre et al. (2008), use exactly dependency pathsargument labels. However, study whether using labels instead actual named entitiesimpact final results LLL data set, carry two experiments.first one, dependency paths contain named entities, whereas second containlabels. second experiment referred adding word LABEL name (asLLL-all-LABEL Table 7).4.1.2 Generic Relationssecond type relations consider generic relations. argumentssometimes annotated using external resources WordNet, makes possibleuse semantic relatedness measures defined them. example approach22fiUsing Local Alignments Relation Recognitiondata used SemEval-2007 challenge, Task 04: Classification Semantic RelationsNominals (Girju et al., 2009).goal Task 4 classify seven semantic relations (Cause - Effect, Instrument - Agency, Product - Producer, Origin - Entity, Theme - Tool, Part Whole Content - Container), whose examples collected Web usingpredefined queries. words, given set examples relation, expected output would binary classification whether example belongs givenrelation not. arguments relation annotated synsets WordNethierarchy, Figure 3. Given sentence pair (spiritual awareness, joy)corresponding synsets joy%1:12:00 awareness%1:09:00, would mean classifier decide whether pair example Cause-Effect relation.particular sentence retrieved quering Web phrase joy comes *.synsets manually selected WordNet hierarchy. seven semanticrelations used challenge, gives seven binary classification problems.Genuine <e1>joy</e1> comes <e2>spiritual awareness</e2> life absolute clarity direction, living purpose.WordNet(e1) = joy%1:12:00, WordNet(e2) = awareness%1:09:00,Query: joy comes *, Cause-Effect(e2, e1) = trueFigure 3: annotated example Cause - Effect SemEval-2007, Task 4training data set.relation typeOrigin - EntityProduct - ProducerTheme - ToolInstrument - AgencyPart - WholeContent - ContainerCause - Effect#examples (train)140140140140140140140#pos (train)54855871656573#examples (test)81937178727480directionasymmetricasymmetricasymmetricasymmetricasymmetricasymmetricasymmetricTable 4: Distribution SemEval-2007, Task 4 examples (training test data),#pos stands number positive examples per data set #examplesindicates number examples total.Syntactic analysis generate dependency paths, seven data sets used SemEval 2007, Task 4, analyzed Stanford parser. dependency path sentenceFigure 3 given (25).23fiKatrenko, Adriaans, & van Someren(25) awareness#n#1prep f romnsubjcome joy#n#1Here, words annotated WordNet PoS tag attached, followed sense.instance, awareness noun current context first sense used,corresponds awareness#n#1.4.2 Substitution Matrixbuild substitution matrix LA kernel, use either distributional similarityWordNet semantic relatedness measures. data set dependency paths,contains unique elements (words syntactic functions), size matrix t.k elements words, number substitution scores computeddistributional similarity (or semantic relatedness) measures equals k(k + 1)/2. duefact measures use symmetric. substitution matrix builtcorpus used experiments, results three substitution matricesbiomedical domain (for BC-PPI, LLL, AImed) seven substitution matricesgeneric relations. follows, discuss settings used calculatingsubstitution matrix detail.Distributional similarity estimated either using contextual information (OSeaghdha & Copestake, 2008), exploring grammatical relations words (Lee,1999). work opt contextual information. motivated presencewords belonging different parts speech dependency paths. instance,even though, according dependency grammar theory (Melcuk, 1988), adjectivesgovern words, may still occur dependency paths. words, evenparsing fail, may produce unreliable syntactic structures. able comparewords part speech, decided estimate distributional similarity basedcontextual information, rather grammatical relations.computing distributional similarity, may happen given word xioccur corpus. handle cases, always set d(xi , xi ) = 1 (the largest possiblesimilarity score), d(xi , x0j ) = 0 xi 6= x0j (the lowest possible similarity score).4.2.1 Biomedical domainestimate distributional similarity biomedical domain, use TREC 2006Genomics collection (Hersch, Cohen, Roberts, & Rakapalli, 2006) contains 162,259documents 49 journals. documents preprocessed removing HTMLtags, citations text reference sections stemmed Porter stemmer (vanRijsbergen, Robertson, & Porter, 1980). Furthermore, query-likelihood approachDirichlet smoothing (Chen & Goodman, 1996) used retrieve document passages givenquery. passages ranked according likelihood generating query. Dirichlet smoothing used avoid zero probabilities poor probability estimates (which mayhappen words occur documents). k unique words occurring setdependency paths sequences fed queries collect corpus estimating similarity.Immediate context surrounding pair words used calculate distributionalsimilarity words. set context window 2 (2 tokens right 224fiUsing Local Alignments Relation Recognitiontokens left word focus) perform kind preprocessingPoS tagging.4.2.2 Generic relationsgeneric relations, use WordNet relatedness measures described Section 3.2.2.already shown WordNet relatedness measures work synsets,assumes words manually annotated information WordNet.Since done relations arguments (see example Figure 3),words sentences (and, correspondingly, dependency paths), buildsubstitution matrix follows. two words annotated WordNet, substitution score equals value returned relatedness measure used. wordpair, equals 1 whenever words identical, 0 otherwise. 5 example,consider words dependency path (25) Wu-Palmer (wup) relatednessmeasure, substitution scores obtain follows:d(awareness#n#1, awareness#n#1) = 1d(awareness#n#1, come) = 0d(awareness#n#1, joy#n#1) = 0.35d(prep from, come) = 0d(prep from, joy#n#1) = 0d(come, nsubj) = 0d(nsubj, nsubj) = 1d(joy#n#1, joy#n#1) = 1d(awareness#n#1, prep from) = 0d(awareness#n#1, nsubj) = 0d(prep from, prep from) = 1d(prep from, nsubj) = 0d(come, come) = 1d(come, joy#n#1) = 0d(nsubj, joy#n#1) = 0Figure 4: substitution scores dependency path (25) using wup measure.Syntactic relations (prep from, subj) accompanied directiondependency tree traversal (either ).dependency path (25), 5 unique elements (t), 2 annotatedWordNet synsets (k). Consequently, 5*6/2 = 15 substitution scores total,3 computed using WordNet relatedness.compute WordNet relatedness, use WordNet::Similarity package WordNet 3.0 (Pedersen, Patwardhan, & Michelizzi, 2004).4.3 Baselines Kernel Settingssection, discuss two baselines kernel settings.4.3.1 Baselinestest well local alignment kernels perform compared kernels proposed past,implemented shortest path kernel described work Bunescu Mooney5. also applies cases relation arguments could annotated WordNetinformation.25fiKatrenko, Adriaans, & van Someren(2005a) (Section 2.3.5) one baselines (Baseline I). method seemsnatural choice operates data structures (dependency paths).Similarly Bunescu Mooneys (2005a) work, experiments use lemma, partspeech tag direction, consider entity type negative polarity items.choice LA kernel paper motivated abilitycompare sequences flexible way, also possibility explore additionalinformation (not present training set) via substitution matrix. baseline,Baseline II, used test whether choice similarity measures affects results.case, substitution scores d(, ) calculated using distributional similarityWordNet relatedness, generated randomly within interval [0, 1].4.3.2 Kernel settingskernels compute used together support vector machine tool LibSVM(Chang & Lin, 2001) detect hyperplanes separating positive examples negativeones. plugging kernel matrices 10-fold cross-validation LibSVM,normalized Equation 26.00k(x, y)k(x , ) = pk(x, x)k(y, y)(26)handle imbalanced data sets (most notably AImed BC-PPI), examplesweighted using inverse-class probability (i.e. training examples class weighted1/prob(A) prob(A) fraction training examples class A). significancetests done using two-tailed paired t-test confidence level 95% ( = 0.05).addition, experiments tuned penalty parameter C (Equation 4)range (26 , 24 , . . . , 212 ).use LA kernel, one set following parameters: gap opening cost,gap extension cost, scaling parameter . cross-validation experiments,gap opening cost set 1.2, extension cost 0.2 scaling parameter1. choice scaling value motivated experiments amino acidsbiological domain (Saigo et al., 2004). initial experiments, presentstudy parameter values varied.5. Experiment I: Domain-Specific Relationsgoal evaluation study behavior LA kernel domain-specificrelations biomedical domain. section, report experiments conductedthree biomedical corpora using LA kernel based distributional similarity measures, two baselines results published previously (e.g., using graph kernel Airolaet al., 2008 tree kernel Stre et al., 2008). best knowledge, stringkernels applied dependency paths yet. However, gap-weighted stringkernel (described Section 2) also allows gapping thus compared LAkernel. test Lodhi et al.s (2002) kernel performs dependency paths, use26fiUsing Local Alignments Relation Recognitionthree corpora. tuned parameters string kernel set lengthsubsequences 4 decay factor 0.5. 65.1 LLL BC-PPI Data Setssubsection presents results two biomedical data sets, BC-PPI LLL. Wheneverpossible, also discuss performance previously reported literature.10-fold cross-validation results BC-PPI corpus presented Table 5LLL training data set Table 6. LA kernel based distributional similaritymeasures (LA-Dice, LA-Cosine LA-L2) performs significantly better two baselines. Recall Baseline corresponds shortest path approach (Section 2.3.5)Baseline II LA kernel randomly generated substitution scores. contrastBaseline I, able handle sequences different lengths including gaps. AccordingEquation 5, comparison two sequences different lengths results 0-score.Nevertheless, still yields high recall, precision much lower. explainedfact shortest path uses PoS tags. Even though two sequenceslength different, comparison may still result non-zero score, providedpart speech tags match. Furthermore, Baseline II suggests accurate estimation substitution scores important achieving good performance. Baseline II mayyield better results Baseline I, randomly generated substitution scores degradeperformance.MethodLA-DiceLA-CosineLA-L2BaselineBaseline IIGap-weighted string kernel (Lodhi et al., 2002)Precision75.5676.4077.5632.0466.3672.00Recall79.7280.6679.3175.6354.4875.31F-score77.5678.1378.4245.0059.8073.62Table 5: 10-fold cross-validation BC-PPI data set.first glance, choice distributional similarity measures affectoverall performance yielded LA kernel. BC-PPI data, method basedL2 measure outperforms methods based Dice (p.07) Cosine,differences latter case significant. statistically significant differencesobserved method based Dice Cosine.contrast BC-PPI data set, kernels use Dice Cosine measuresLLL data set significantly outperform one based L2 (at p1.22107p1.33106 , respectively).data sets, LA method using distributional similarity measures significantlyoutperforms baselines. Interestingly, gap-weighted string kernel Lodhi et al.(2002) yields good performance seems better choice subsequence6. Lodhi et al. (2002) mentioned paper F1 numbers (with respect SSK) seempeak subsequence length 4 7.27fiKatrenko, Adriaans, & van Somerenkernel based shallow linguistic information (Giuliano et al., 2006). Recent workLLL (Fundel, Kueffner, & Zimmer, 2007) employs dependency information but, contrastmethod, serves representation extraction rules defined. Airolaet al. (2008) apply graph kernel-based approach extract interactions use, amongothers, LLL AImed data sets. seen Table 6, method yields resultscomparable gap-weighted string kernel dependency paths.best knowledge, performance achieved LA kernel LLL training sethighest (in terms F-score) among results reportedliterature.MethodLA-DiceLA-CosineLA-L2BaselineBaseline IIGraph kernel (Airola et al., 2008)Gap-weighted string kernel (Lodhi et al., 2002)Shallow linguistic kernel (Giuliano et al., 2006)Rule-based method (Fundel et al., 2007)Precision88.7688.6386.8039.0265.8272.583.6662.1068Recall81.6282.0975.04100.0041.3287.271.1161.3083F-score85.0385.2380.4956.1350.7676.876.8861.7075Table 6: 10-fold cross-validation LLL-all training data set.also apply method LLL test data (Table 7). 7 Even though performance test set poorer, LA-Dice outperforms baselines. addition,gap-weighted string kernel (Lodhi et al., 2002) seems perform much worse testset. LA kernel, precision high, recall decreases (and drasticallydata subset includes co-references). might due factsentences incomplete parses generated and, consequently, dependency pathsentities found. 91 567 possible interaction pairs generatedtest data, dependency path extracted. contrast, approach reportedGiuliano et al. (2006) make use syntactic information, data subsetwithout coreferences achieves higher recall.hand, lower recall also caused using actual names proteinsgenes arguments. work reported before, relation argumentsnamed entities often replaced types (e.g., PROTEIN) usedinput learning algorithm. conducted additional experiments using named entitytypes dependency paths, led great improvement terms recallF-score (Table 7, LLL-coref-LABEL, LLL-nocoref-LABEL, LLL-coref-LABEL). methodclearly outperforms shallow linguistic kernel also achieves better resultsbest-performing system LLL competition (Sbest ), which, according Nedellec (2005),applied Markov logic syntactic paths.7. Airola et al. (2008) report performance LLL data set and, reason, informationgraph all-paths kernel included Table 7.28fiUsing Local Alignments Relation RecognitionData setLLL-corefLLL-nocorefLLL-allLLL-allLLL-allLLL-coref-LABELLLL-nocoref-LABELLLL-all-LABELLLL-corefLLL-nocorefLLL-allLLL-allLLL-allMethodLA-DiceLA-DiceLA-DiceBaselineBaseline IILA-DiceLA-DiceLA-DiceShallow linguistic kernel (GiulianoShallow linguistic kernel (GiulianoShallow linguistic kernel (GiulianoGap-weighted string kernel (LodhiSbest (Nedellec, 2005)etetetetal.,al.,al.,al.,2006)2006)2006)2002)Precision52.370.772.748.612.960.069.074.529.054.856.056.060.9Recall37.953.748.143.345.751.753.753.031.062.961.416.846.2F-score44.061.057.945.820.155.560.461.930.058.658.625.952.6Table 7: Results LLL test data set.5.2 AImed Data SetYet another data set consider AImed. data set often usedexperiments relation extraction biomedical domain, enables comparisonmethods. noted, however, particular case, corpuscollection documents (abstracts). may lead two ways performing 10-foldcross-validation. One possibility lies randomly splitting data 10 parts,cross-validation level documents. experiments reportdone using first setting directly compared methods describedwork Stre et al. (2008), Erkan et al. (2007) Giuliano et al. (2006). addition,use dependency paths LA kernel ones employed Stre et al.Erkan et al.. results Airola et al. (2008) Bunescu (2007) obtainedcross-validating level documents.conducted experiments setting distributional measure Dice, referredLA-Dice Table 8. upper part table used dependency paths generatedStanford parser lower part obtained Enju. discussedSection 2, Erkan et al. (2007) use similarity measures compare dependency paths,consider additional sources whose information incorporatedlearning procedure. They, however, experiment supervised (SVM) semi-supervisedlearning (TSVM), number training instances varied. Table 8 shows bestperformance achieved Erkan et al.s (2007) method. Among models basedSVM, one Cosine distance, SVM-Cos, yields best results. TSVMsetting, one Edit measure performs best. observe LA-Dice slightlyoutperforms has, particular, high precision.work, Stre et al. (2008) explore several parsers combinations features.features include paths Enju, also word dependencies generateddata-driven KSDEP parser, word features. KSDEP parser based probabilistic29fiKatrenko, Adriaans, & van Somerenshift-reduce algorithm (Sagae & Tsujii, 2007). general, method Stre et al. alsouses SVM, case focuses tree kernels (discussed Section 2.3.3). makefair comparison, conducted experiments paths obtained deep syntactic analysis(Enju parser) compared scores Stre et al.s (2008) results. contrastprevious experiments, achieve higher recall lower precision. Overall, LAkernel yields better performance one reported Stre et al. However,different sets features combined (parses Enju KSDEP plus word features Enju+KSDEP+W Table 8), overall performance improved.MethodLA-DiceBaseline (Bunescu, 2007)Baseline IISVM-Cos (Erkan et al., 2007)TSVM-Edit (Erkan et al., 2007)Gap-weighted string kernel (Lodhi et al., 2002)LA-DiceTree kernel (Stre et al., 2008)Tree kernel (Stre et al., 2008)Graph kernel (Airola et al., 2008)Shallow linguistic kernel (Giuliano et al., 2006)ParserStanfordCollinsStanfordStanfordStanfordStanfordEnjuEnjuEnju+KSDEP+WCharniak-LeasenonePrecision69.0969.0848.8961.9959.5967.2571.1676.078.152.960.9Recall54.6335.0025.0654.9960.6854.6746.7139.762.761.857.2F-score61.0246.4633.0758.0959.9660.3156.4052.069.556.459.0Table 8: 10-fold cross-validation AImed data set.Bunescu (2007) reports evaluation results AImed corpus formprecision-recall curve. consider highest precision obtained experiments (69.09 71.16, depending input), roughly corresponds recall35% plot (referred Baseline Table 8). sum, shortest path approachnever approaches performance LA kernel biomedical data setsstudied here. baseline, Baseline II, achieves lowest scoresmethods presented here.Table 8 illustrates various methods trained AImed corpus,also many different parsers used. noted graph kerneltrained tested syntactic representation generated Charniak-Leaseparser, shortest path kernel explored dependency paths obtainedCollins parser. Charniak-Lease parser statistical parser trained biomedicaldata (Lease & Charniak, 2005), whose phrase structures transformed dependencies. Likewise, Collins parser statistical parser (Collins, 1999). leadsquestion whether choice syntactic parser significant impact extractionresults. compare impact syntactic parsers relation extraction AImed,Miyao et al. (2008) conducted complex study eight parsers (including Stanford analyzer) five parse representations 8 . consider two cases. first one,parsers trained biomedical data. Regardless parser usedexperiments, accuracy extraction task similar. second experiment,8. either various dependency tree formats (e. g., Stanford dependency format), phrasestructures, predicate-arguments structures.30fiUsing Local Alignments Relation Recognitionparsers re-trained domain-specific data. case, shownrelation extraction results improved. actual gain, however, varyone parser another.AImed data, LA kernel Dice measure gives state-of-the-art results.outperformed approaches use information dependencypaths.5.3 LA Kernel ParametersSaigo et al. (2004) already shown scaling parameter (Equation 11)significant impact accuracy. also carried additional experiments varyinggap values value . Results visualized Figure 5. opening extensiongap values separated slash symbol values X-axis form a/bread opening gap set extension gap equal b.kernel matrices normalized examples weighted. According previousexperiments, results yielded Dice measure significantly differones achieved Cosine measure selected Dice measure conductexperiments. performance BC-PPI data set shown Figure 5.F-score767472706866646260587674727068666462605812/212/12gaps24/224/120.10.30.50.815scalingFigure 5: Varying gaps scaling () parameter BC-PPI data set (10-foldcross-validation): F-score.31fiKatrenko, Adriaans, & van Someren8079787776757473727170Precision908580757065560112/20.812/12gapsscaling0.524/20.324/120.1Figure 6: Varying gaps scaling () parameter BC-PPI data set (10-foldcross-validation): Precision.7570Recall65906080557050604550540112/20.812/12gaps0.524/2scaling0.324/120.1Figure 7: Varying gaps scaling () parameter BC-PPI data set (10-foldcross-validation): Recall.32fiUsing Local Alignments Relation Recognitionresults Figure 5 indicate decreasing leads decrease overall performance. Moreover, varying gap values causes subtle changes F-score,changes drastic changes due lower .Changes F-score likely explained variances precisionrecall. investigate matter, look measures depend parameterchanges. set low value, one expect nearly diminish impactsubstitution matrix, i.e. similarity among elements. reason hypothesizelarger values scaling parameter result higher recall. Indeed, Figure 7supports hypothesis recall plot resembles one F-score. Varyingparameter values much lower impact precision (Figure 6) nonetheless precisiondecrease parameter becomes larger.Overall, seems influence final results most, although gap values makecontribution well. According results obtained, setting extension gap elarge value (or equal opening gap o) undesirable. Since scaling parameterapplied substitution matrix gap values well, setting0.5 decreases effects gap penalization similarity elements. Consequently,best performance achieved setting 1. suggests final performanceLA kernel influenced combination parameters choice crucialobtaining good performance.6. Experiment II: Generic RelationsAnother series experiments carried seven generic relations SemEval- 2007 challenge, Task 4. choice data sets case motivated twofactors. First, semantic relations used differ relations biomedicaldomain. Second, since arguments relations annotated WordNet, becomespossible explore information WordNet use prior knowledge LAkernel.Many participants challenge considered WordNet either explicitly (Tribble &Fahlman, 2007; Kim & Baldwin, 2007), part complex system (Giuliano et al.,2007). Since always obvious use WordNet yields best performance, many researchers made additional decisions use supersenses (Hendrickx et al., 2007), selection predefined number high-level concepts (Nulty, 2007),cutting WordNet hierarchy certain level (Bedmar et al., 2007). systemsone Nakov (2007) based solely information collected Web.Even though became evident best performing systems used WordNet, variance results remarkable clear whether difference performanceexplained machine learning methods used, combination features,factors.SemEval-2007 Task-4 data set includes relation examples nominalcompounds (like coffee maker), greatly reduces availability informationtwo arguments dependency paths. relation arguments case linkedone grammatical relation (e.g., coffee maker linked grammatical relationnn, corresponds noun compound). assume, therefore, information comingWordNet especially helpful dependency paths short.33fiKatrenko, Adriaans, & van Somerenexperiments used 5 relatedness measures defined earlier Section 3.2 plus one additionalmeasure called random. random measure indicates relatedness valuestwo relation arguments generated randomly (within [0, 1]) thussuitable baseline (Baseline II). Similarly experiments biomedical domain,another baseline shortest path kernel (Baseline I). Note Task 4 overviewpaper, Girju et al. (2007) reported three baselines, which, case, (i) guessingtrue false examples, depending class majority class testset (Baseline III), (ii) always guessing true (Baseline IV), (iii) guessing true falseprobability corresponds class distribution test set (Baseline V).first question interest implications choice semantic relatednessmeasure performance LA kernel. answer question, perform10-fold cross-validation training set (Figure 9, Figure 10 Figure 11). Among5 measures jcn resnik fail perform better random score.cases, Resnik score outperformed measures. behaviour LeacockChodorow score (lch) jcn varies one semantic relation another. instance, usejcn seems boost precision Cause-Effect, Part-Whole, Product - Producer,Theme - Tool. remaining three relations clearly best-performingmeasure.check whether differences relatedness measures, carriedsignificance tests comparing measures relations. findings summarizedTable 9. Here, symbol two relatedness measures stands measureequivalence, or, words, indicates significant difference. Similarlyexperiments biomedical field, significance tests conducted usingtwo-tailed paired t-test confidence level 95%. addition, two measuresb, > b means performs significantly better b. instance, rankingCause - Effect Table 9 read follows. two best performing measureswup lch, significantly outperform lin, followed random res, which,turn, yield significantly better results jcn. seen table wuplch clearly best performing measures seven relations (each bestmeasure six seven relations).Relation typeCause - EffectInstrument - AgencyProduct - ProducerOrigin - EntityTheme - ToolPart - WholeContent - ContainerRankingwup lch > linwup lch > linwup lch > linwup lch > linlch > lin wupwup lin lchwup > lch > lin>>>>>res random > jcnres > jcn randomjcn res > randomres jcn > randomres > jcn > randomres > jcn randomres > jcn randomTable 9: Ranking relatedness measures respect accuracy training sets ( stands measure equivalence, > b indicates measuresignificantly outperforms b).34fiUsing Local Alignments Relation Recognitionrelation, applied best performing measure training setparticular relation test data. results reported Table 10. average, LAkernel employing WordNet relatedness measures significantly outperforms two baselines.Moreover, compared best results SemEval-2007 competition (Beameret al., 2007), method approaches performance yielded best system (bestSV ).system used various lexical, syntactic, semantic feature sets, alsoexpanded training set adding examples many different sources. alreadymentioned Section 2 recent work Seaghdha (2009) explores WordNetstructure graph kernels classify semantic relations. overall performanceachieved method (Table 10) comparable one LA kernel,unclear whether semantic relations one approaches performsbetter.Relation typeCause - EffectInstrument - AgencyProduct - ProducerOrigin - EntityTheme - ToolPart - WholeContent - ContainerAverageBaselineBaseline IIBaseline IIIBaseline IVBaseline VbestSVGap-weighted string kernel (Lodhi et al., 2002)WordNet kernels (O Seaghdha, 2009)Accuracy61.2575.6475.2774.0773.2480.5671.6273.0958.2355.8357.048.548.576.361.1974.1Precision62.5073.1776.7175.8667.8670.0074.2971.4852.5061.6181.348.548.579.766.2-Recall60.9878.9590.3261.1165.5280.7768.4272.3054.3055.5042.9100.057.169.847.52-F-score61.7375.9582.9667.6966.6775.0071.2371.6049.1953.9330.864.848.572.443.0271.0measurelchwuplchwuplchwupwupTable 10: Results SemEval-2007, Task 4 test data set (selecting best performingmeasure training set relation).addition, report results SemEval Task 4 test set per relatedness measure(Table 11), averages seven relations. Similarly findingstraining set, wup lch best performing measures test data well.One would expect optimal use prior knowledge allow us reducenumber training instances without significant changes performance. study(and whether) amount training data influences results test set, splittraining set several subsets, creating model subset applyingSemEval-2007, Task 4 test data. split corresponds split used challengeorganizers. Figure 8 9 suggests, relations recognized well even relativelysmall data sample used. exception Theme-Tool relation increasing9. model trained 35 Origin-Entity examples classifies none test examples positive,reason point Figure 8 relation given 35 training examples.35fiKatrenko, Adriaans, & van Somerentraining data clearly helps. finding line results Giuliano et al. (2007)whose system combination kernels data. results also indicaterelations one (Theme-Tool) extracted well, even quartertraining set used.Relatedness measurewuplchlinresjcnrandomAccuracy72.9172.9665.2762.9455.5556.57Precision71.2072.3162.0162.5152.2553.10Recall72.5670.9367.0759.6669.2852.94F-score71.6271.0263.6560.4657.0752.83Table 11: Results SemEval-2007, Task 4 test data set, averages 7 relationsper WordNet relatedness measure.Learning curve100908070F-score6050Cause-EffectInstrument-AgencyProduct-ProducerOrigin-EntityTheme-ToolPart-WholeContent-Container4030201003570105training examples140Figure 8: Learning curve SemEval-2007, Task 4 test data set.recent work SemEval Task 4 data set includes investigation distributional kernels (O Seaghdha & Copestake, 2008), pattern clusters (Davidov & Rappoport,2008), relational similarity (Nakov & Hearst, 2008), WordNet kernels. Unlike WordNetkernels, first three approaches use WordNet. Seaghdha Copestake (2008)report accuracy 70.7 F-score 67.5 best results yielded distributional kernels best performance Davidov Rappoports (2008) methodaccuracy 70.1, F-score 70.6. WordNet kernels, similarly findingsLA kernel, yield better accuracy methods using WordNet (74.1),36fiUsing Local Alignments Relation RecognitionCause-Effect100precisionrecallF-score9080706050403020100wuplinlchressimilarity measurejcnrandomInstrument-Agency100precisionrecallF-score9080706050403020100wuplinlchressimilarity measurejcnrandomProduct-Producer100precisionrecallF-score9080706050403020100wuplinlchressimilarity measurejcnrandomFigure 9: 10-fold cross-validation training set (Cause - Effect, Instrument Agency Product - Producer relations).37fiKatrenko, Adriaans, & van SomerenOrigin-Entity100precisionrecallF-score9080706050403020100wuplinlchressimilarity measurejcnrandomTheme-Tool100precisionrecallF-score9080706050403020100wuplinlchressimilarity measurejcnrandomPart-Whole100precisionrecallF-score9080706050403020100wuplinlchressimilarity measurejcnrandomFigure 10: 10-fold cross-validation training set (Origin - Entity, Theme - ToolPart - Whole relations).38fiUsing Local Alignments Relation RecognitionContent-Container100precisionrecallF-score9080706050403020100wuplinlchressimilarity measurejcnrandomFigure 11: 10-fold cross-validation training set (Content - Container relation).F-score comparable performance reported Seaghdha Copestake (2008)Davidov Rappoport (2008).7. Discussionsection revisit goals stated end Section 2 discussfindings detail.7.1 LA Kernel Relation Extractionintroduced LA kernel, proven effective biomedical problems,NLP domain showed well suited relation extraction. particular, experiments two different domains either outperform existing methods yieldperformance par existing state-of-the-art kernels.One motivations using LA kernel relation extraction taskexploit prior knowledge. Here, explore two possibilities, distributional similarityinformation provided WordNet.7.1.1 Distributional Similarity Measuressetting, consider three distributional measures already studiedbefore. instance, Lee (1999) uses detect similar nouns based verb-objectco-occurrence pairs. results suggest Jaccard coefficient (which relatedDice measure) one best performing measures followed others includingCosine. Euclidean distance fell group largest error rates. Given previouswork Lee (1999), one would expect Euclidean distance achieve worse results39fiKatrenko, Adriaans, & van Somerentwo measures. Indeed, LLL corpus, LA kernel employing L2 showssignificant decrease performance. measures, method using Dicesignificantly outperforms one based L2 measure LLL corpussignificant improvement BC-PPI data set. Based experimentsconducted, conclude LA kernel using Dice Cosine measures performssimilarly LLL data set BC-PPI corpus. Given results various biomedical corpora (and different settings experimented with), obtained experimentalsupport choosing Dice Cosine measure Euclidean distance.7.1.2 WordNet Similarity Measuresgeneric relations, semantic relatedness plays significant role. differenceF-score models use semantic relatedness kernel relatednessvalues generated randomly (Baseline II) amounts nearly 20%. measures exhibitdifferent performance seven generic relations considered.observe, instance, wup, lch, lin almost always yield best results, matterrelation considered. found Resnik score Jiang Conraths measureyield lower results measures. Even though F-scores per relation varyquite substantially (by placing Cause-Effect, Theme-Tool, Origin-Entity amongdifficult relations extract), two measures, wup lch, top-performingmeasures seven relations. two measures explore WordNet taxonomy usinglength paths two concepts, depth WordNet hierarchy and,consequently, belong path-based measures. three measures, res, linjcn information content based measures, relatedness two conceptsdefined amount information share. experiments LAkernel generic relation recognition suggest that, particular case, path-basedmeasures preferred information content based measures.stress, however, evaluation semantic relatedness measures context relation recognition, one means draw conclusiontop measures NLP tasks stay same. example, BudanitskyHirst (2006) use semantic relatedness measures detect malapropism showJiang Conraths measure (jcn) yields best results, followed Lins measure (lin),one Leacock Chodorow (lch), Resniks measure (res).results quite similar findings consider res measure, jcntop accuracy ranking list seven semantic relationsstudied.7.2 Factors Parameters Influence LA Kernel Performanceexperiments two domains shown LA kernel either outperforms existingmethods corpora, yields performance par existing state-of-the-artkernels.7.2.1 Baselinesadvantage LA kernel Bunescu shortest path method (Baseline I)capable handling paths different lengths. allowing gaps penalizing them,40fiUsing Local Alignments Relation Recognitionfinal kernel matrix becomes less sparse. shortest path approach also attemptsgeneralize dependency paths, usually overgeneralizes leads highrecall scores (Table 5 Table 6) poor overall performance. One explanationovergeneralization may method accounts well structural similarity (providedsequences length) fails provide finer distinctions among dependencypaths. Consider, example, two sequences trip makes tram coffee makesguy, whereby first path represents negative instance Product-Producerrelation second path corresponds positive one. Even though matchexactly, elements match nouns singular. Consequently, comparisonaccording shortest path method result relatively high similarity score.contrast, LA kernel consider similarity elements pairs trip-coffeetram-guy obtain low scores.addition, Baseline II, based randomly generated substitution scores,performs poor data sets (or comparable Baseline I). leads us conclusionaccurate estimation similarities another reason LA kernel performs wellrelation extraction.7.2.2 Comparison Methodsalready pointed out, obvious shortcoming Baseline inabilityhandle dependency paths different length. reason, also appliedgap-weighted string kernel (Lodhi et al., 2002) data sets. case, dependencypaths compared flexible way gapping allowed, additionalinformation used. kernel outperforms Baseline increasing precision relationextraction preserving relatively high recall. data set fails yieldgood results LLL test data, believe due differences LLLtraining test data. data sets, LA kernel achieves better performancegap-weighted string kernel. margin, however, different different data sets.biomedical domain, differences two methods clearly seenBC-PPI LLL data sets, results AImed corpus comparable.However, methods tested AImed get higher scores unless usefeatures dependency paths. holds types cross-validation usedcorpus. generic relations, difference LA kernel gapweighted string kernel much larger. particular, case gap-weighted kernel,precision high, recall much lower. explained fact genericrelations benefit knowledge found WordNet recall achieved LA kernelis, therefore, high. gap-weighted kernel access information founddependency paths and, reason, fails find relations.LA kernel also achieves best performance LLL training set, outperforminggraph kernel (Airola et al., 2008), shallow linguistic kernel (Giuliano et al., 2006)rule-based system Fundel et al. (2007). three used different inputmethods, varying plain text dependency structures. reason, directcomparison unfortunately possible, conclude methods employingdependency information always among best performing approaches.41fiKatrenko, Adriaans, & van SomerenTwo approaches whose performance reported AImed data set include tree kernel (Stre et al., 2008) TSVM (Erkan et al., 2007).explore syntactic information different ways. Stre et al. consider subtrees,method Erkan et al. similarities approach reliesdependency path comparison. comparison, use information alreadyavailable dependency paths (SVM setting), dependency paths (TSVM setting). According Lauer Bloch (2008), TSVMs fall category using priorknowledge sampling methods, explores prior knowledge generating newexamples. contrast, employ information large unlabeled text sources orderenable finer comparison dependency paths always work supervised learningsetting. Using evaluation procedure work Stre et al. Erkan et al.show LA kernel outperforms methods, differences data setmuch smaller data sets used.7.2.3 LA Parametersdemonstrated choice LA parameters crucial achieving good performance. experiments, scaling parameter contributes overall performancemost, parameters gap values taken account well.approaches infinity, LA kernel approximates Smith-Waterman distance,increasing necessarily positive impact final performance.finding line results reported Saigo et al. (2004) homology detectiontask. best performance yielded setting scaling parameter 1 bit higher,penalizing gap extension less gap opening.8. Conclusions Future Workpresented novel approach relation extraction based local alignments sequences. Using LA kernel provides us opportunity explore varioussources information study role relation recognition. Possible future directions include, therefore, examination distributional similarity measures, studyingimpact extraction generic relations, looking sources information could helpful relation recognition. may interesting considerrelational similarity (Turney, 2006), looks correspondence relationinstances. case, one able infer doctor corresponds scalpelsimilar way fisherman net (where (scalpel, doctor) (net, fisherman)examples Instrument - Agency).Despite sparseness problem might occur WordNet-based measuresused, measures advantage distributional measures treating elements compared concepts rather words. NLP community, stepsalready taken solve problem clustering words large corpora aimingword sense discovery (Pennacchiotti & Pantel, 2006). Recently, Mohammad (2008)thesis investigated compatibility distributional measures ontological ones.using corpus statistics thesaurus, author introduced distributional profilessenses defined distance measures them. Even though new approach calculat-42fiUsing Local Alignments Relation Recognitioning similarity tested generic corpora, would certain interest applydomain-specific data.Overall, local alignment kernels provide flexible means work data sequences.First, allow partial match sequences particularly importantdealing text. Second, possible incorporate prior knowledge learningprocess preserving kernel validity. general, LA kernels appliedNLP problems long input data form sequences.Acknowledgmentsauthors wish thank Simon Carter Gerben de Vries commentsproofreading, three anonymous reviewers highly valuable feedback.also acknowledge input Adaptive Information Management (AIM) groupUniversity Amsterdam. preliminary version work dicussed22nd International Conference Computational Linguistics (CoLing 2008)Seventh International Tbilisi Symposium Language, Logic Computation (2007).work carried context Virtual Laboratory e-Science project(www.vl-e.nl). project supported BSIK grant Dutch MinistryEducation, Culture Science (OC&W) part ICT innovation programMinistry Economic Affairs (EZ).ReferencesAirola, A., Pyysalo, S., Bjorne, J., Pahikkala, T., Ginter, F., & Salakoski, T. (2008). Allpaths graph kernel protein-protein interaction extraction evaluation crosscorpus learning. BMC Bioinformatics, 9 (Suppl II).Beamer, B., Bhat, S., Chee, B., Fister, A., Rozovskaya, A., & Girju, R. (2007). UIUC:Knowledge-rich Approach Identifying Semantic Relations Nominals.Proceedings Workshop Semantic Evaluations (SemEval), Prague, CzechRepublic.Bedmar, I. S., Samy, D., & Martinez, J. L. (2007). UC3M: Classification semantic relationsnominals using sequential minimal optimization. SemEval-2007.Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures lexical semanticrelatedness. Computational Linguistics, 32 (1), 1347.Bunescu, R. C. (2007). Learning Information Extraction. Ph.D. thesis, DepartmentComputer Sciences, University Texas Austin.Bunescu, R. C., Ge, R., Kate, R. J., Marcotte, E. M., Mooney, R. J., Ramani, A. K., &Wong, Y. W. (2005). Comparative experiments learning information extractorsproteins interactions. Artificial Intelligence Medicine, 33, 139155.Bunescu, R. C., & Mooney, R. J. (2005a). shortest path dependency kernel relationextraction. Joint Conference Human Language Technology / Empirical MethodsNatural Language Processing (HLT/EMNLP), Vancouver, BC.43fiKatrenko, Adriaans, & van SomerenBunescu, R. C., & Mooney, R. J. (2005b). Subsequence kernels relation extraction.Proceedings 19th Conference Neural Information Processing Systems,Vancouver, BC.Bunescu, R. C., & Mooney, R. J. (2006). Text Mining Natural Language Processing,chap. Extracting Relations Text. Word Sequences Dependency Paths.Springer.Burges, C. J. C. (1998). tutorial support vector machines pattern recognition.Data Mining Knowledge Discovery, 2 (2), 121167.Camacho, R. (1994). use background knowledge inductive logic programming.Report.Cancedda, N., Gaussier, E., Goutte, C., & Renders, J.-M. (2003). Word-sequence kernels.Journal Machine Learning Research, 3, 10591082.Chang, C.-C., & Lin, C.-J. (2001). LIBSVM: library support vector machines. Softwareavailable http://www.csie.ntu.edu.tw/~cjlin/libsvm.Chen, S. F., & Goodman, J. (1996). empirical study smoothing techniques languagemodeling. ACL96.Clegg, A. B. (2008). Computational-Linguistic Approaches Biological Text Mining. Ph.D.thesis, University London.Cohen, W. W., Ravikumar, P., & Fienberg, S. (2003). comparison string distancemetrics name-matching tasks. IIWeb 2003, pp. 7378.Collins, M. (1999). Head-Driven Statistical Models Natural Language Parsing. Ph.D.thesis, University Pennsylvania.Collins, M., & Duffy, N. (2001). Convolution kernels natural language. AdvancesNeural Information Processing Systems 14, pp. 625632. MIT Press.Cortes, C., & Vapnik, V. (1995). Support vector networks. Machine Learning, 20 (3),273297.Davidov, D., & Rappoport, A. (2008). Classification semantic relationshipsnominals using pattern clusters. Proceedings ACL-08:HLT, pp. 227235.Dolan, W. B., Quirk, C., & Brockett, C. (2004). Unsupervised construction large paraphrase corpora: Exploiting massively parallel news sources. COLING 2004, Geneva,Switzerland.Erkan, G., Ozgur, A., & Radev, D. R. (2007). Semi-supervised classification extractingprotein interaction sentences using dependency parsing. 2007 Joint ConferenceEmpirical Methods Natural Language Processing Computational NaturalLanguage Learning, pp. 228237.Fellbaum, C. (1998). WordNet: Electronic Lexical Database. MIT Press.Firth, J. R. (1957). synopsis linguistic theory 19301955. Studies Linguistic Analysis.Philological Society, Oxford. Reprinted Palmer, F. (ed.), 1968.Fundel, K., Kueffner, R., & Zimmer, R. (2007). RelEx - relation extraction using dependencyparse trees. Bioinformatics, 23 (3).44fiUsing Local Alignments Relation RecognitionGirju, R., Badulescu, A., & Moldovan, D. (2006). Automatic discovery part-whole relations. Computational Linguistics, 32 (1), 83135.Girju, R., Nakov, P., Nastase, V., Szpakowicz, S., Turney, P., & Yuret, D. (2007). SemEval2007 Task 04: Classification semantic relations nominals. ACL 2007.Girju, R., Nakov, P., Nastase, V., Szpakowicz, S., Turney, P., & Yuret, D. (2009). Classification semantic relations nominals. Language Resources Evaluation,43 (2), 105121.Giuliano, C., Lavelli, A., Pighin, D., & Romano, L. (2007). FBK-IRST: Kernel methodssemantic relation extraction. SemEval-2007.Giuliano, C., Lavelli, A., & Romano, L. (2006). Exploiting shallow linguistic informationrelation extraction biomedical literature. EACL 2006.Grishman, R., & Sundheim, B. (1996). Message Understanding Conference - 6: briefhistory. Proceedings 16th International Conference Computational Linguistics.Haussler, D. (1999). Convolution kernels discrete structures. Tech. rep. UCS-CRL-99-10,UC Santa Cruz.Hearst, M. (1992). Automatic acquisition hyponyms large text data. ProceedingsCOLING-92, pp. 539545.Hendrickx, I., Morante, R., Sporleder, C., & van den Bosch, A. (2007). ILK: Machinelearning semantic relations shallow features almost data. SemEval2007.Hersch, W., Cohen, A. M., Roberts, P., & Rakapalli, H. K. (2006). TREC 2006 genomicstrack overview. Proceedings 15th Text Retrieval Conference.Jiang, J. J., & Conrath, D. W. (1997). Semantic similarity based corpus statisticslexical taxonomy. Proceedings International Conference ResearchComputational Linguistics (ROCLING X), pp. 1933.Joachims, T. (1999). Transductive inference text classification using Support VectorMachines. Proceedings ICML.Katrenko, S., & Adriaans, P. (2008). Semantic types generic relation arguments:Detection evaluation. Proceedings 46th Annual Meeting Association Computational Linguistics: Human Language Technologies (ACL/HLT),Columbus, USA.Khoo, C. S. G., Chan, S., & Niu, Y. (2000). Extracting causal knowledge medical database using graphical patterns. Proceedings 38th Annual MeetingAssociation Computational Linguistics, pp. 336343, Morristown, NJ, USA.Association Computational Linguistics.Kim, S. N., & Baldwin, T. (2007). MELB-KB: Nominal classifications noun compoundinterpretation. SemEval-2007.Lauer, F., & Bloch, G. (2008). Incorporating Prior Knowledge Support Vector MachinesClassification: Review. Neurocomputing, 71, 15781594.45fiKatrenko, Adriaans, & van SomerenLeacock, C., & Chodorow, M. (1998). Combining local context WordNet similarityword sense identification. MIT Press, Cambridge, MA.Lease, M., & Charniak, E. (2005). Parsing biomedical literature. Proceedings IJCNLP.Lee, L. (1999). Measures distributional similarity. Proceedings 37th annual meeting Association Computational Linguistics Computational Linguistics,pp. 2532.Leslie, C., Eskin, E., Cohen, A., Weston, J., & Noble, W. S. (2004). Mismatch string kernelsdiscriminative protein classification. Bioinformatics, 20 (4), 467476.Leslie, C., Eskin, E., & Noble, W. S. (2002). spectrum kernel: string kernel SVMprotein classification. Pacific Symposium Biocomputing 7, pp. 566575.Leusch, G., Ueffing, N., & Ney, H. (2003). novel string-to-string distance measureapplications machine translation evaluation. Machine Translation Summit IX,pp. 240247, New Orleans, LO.Lin, D. (1998). information-theoretic definition similarity. Proceedings 15thInternational Conference Machine Learning, pp. 296304.Lodhi, H., Saunders, C., Shawe-Taylor, J., Christianini, N., & Watkins, C. (2002). Textclassification using string kernels. Journal Machine Learning Research, 2, 419444.McDonald, R. (2005). Extracting relations unstructured text. Tech. rep. MS-CIS-0506, UPenn.Melcuk, I. (1988). Dpendency syntax: theory practice. SUNY Press.Mitchell, T. (1997). Machine Learning. McGraw Hill.Miyao, Y., Stre, R., Sagae, K., Matsuzaki, T., & Tsuji, J. (2008). Task-oriented evaluationsyntactic parsers representations. Proceedings ACL-08:HLT, pp. 4654.Mohammad, S. (2008). Measuring Semantic Distance using distributional profiles concepts. Ph.D. thesis, Graduate Department Computer Science UniversityToronto.Monge, A. E., & Elkan, C. (1996). field matching problem: Algorithms applications.KDD 1996, pp. 267270.Moschitti, A. (2006). Efficient convolution kernels dependency constituent syntactictrees. ECML 2006, pp. 318329.Nakov, P. (2007). UCB: System description SemEval task #4. SemEval-2007.Nakov, P. (2008). Paraphrasing verbs noun compound interpretation. ProceedingsWorkshop Multiword Expressions (MWE08), conjunction LanguageResources Evaluation conference, Marrakech, Morocco, 2008.Nakov, P., & Hearst, M. A. (2008). Solving relational similarity problems using webcorpus. Proceedings ACL-08:HLT.Nedellec, C. (2005). Learning Language Logic - Genic Interaction Extraction Challenge.Proceedings Learning Language Logic workshop.46fiUsing Local Alignments Relation RecognitionNeedleman, S. B., & Wunsch, C. D. (1970). general method applicable searchsimilarities amino acid sequence two proteins. Journal Molecular Biology,48 (3), 443453.Nulty, P. (2007). UCD-PN: Classification semantic relations nominals usingWordNet web counts. SemEval-2007.Seaghdha, D. (2009). Semantic classification WordNet kernels. ProceedingsNorth American Chapter Association Computational Linguistics - HumanLanguage Technologies Conference (NAACL-HLT), Boulder, CO.Seaghdha, D., & Copestake, A. (2008). Semantic classification distributional kernels.Proceedings CoLing 2008, Manchester, UK.Palmer, M., & Wu, Z. (1995). Verb semantics English-Chinese translation. Tech. rep.,Technical Report No. MS-CIS-95-39, Department Computer & Information Science,University Pennsylvania.Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet::Similarity - MeasuringRelatedness Concepts. Proceedings Nineteenth National ConferenceArtificial Intelligence (AAAI-04), pp. 10241025, San Jose, CA.Pennacchiotti, M., & Pantel, P. (2006). Ontologizing semantic relations. ACL-44: Proceedings 21st International Conference Computational Linguistics44th annual meeting Association Computational Linguistics, pp. 793800,Morristown, NJ, USA. Association Computational Linguistics.Ponzetto, S. P., & Strube, M. (2007). Knowledge Derived Wikipedia ComputingSemantic Relatedness. Journal Artificial Intelligence Research, 30, 181212.Resnik, P. (1995). Using information content evaluate semantic similarity. Proceedings14th International Joint Conference Artificial Intelligence, pp. 448453.Stre, R., Sagae, K., & Tsuji, J. (2008). Syntactic features protein-protein interactionextraction. 2nd International Symposium Languages Biology Medicine,pp. 6.16.14.Sagae, K., & Tsujii, J. (2007). Dependency parsing domain adaptation LR modelsparser ensembles. Proceedings EMNLP-CoNLL.Saigo, H., Vert, J.-P., & Akutsu, T. (2006). Optimizing amino acid substitution matriceslocal alignment kernel. BMC Bioinformatics, 7:246.Saigo, H., Vert, J.-P., Ueda, N., & Akutsu, T. (2004). Protein homology detection usingstring alignment kernels. Bioinformatics, 20 (11), 16821689.Sang, E. F. T. K., Canisius, S., van den Bosch, A., & Bogers, T. (2005). Applying spellingerror correction techniques improving semantic role labeling. ProceedingsNinth Conference Natural Language Learning, CoNLL-2005, Ann Arbor, MI.Saunders, C., Tschach, H., & Shawe-Taylor, J. (2002). Syllables string kernelextensions. ICML 2002.Scholkopf, B. (1997). Support vector learning. Ph.D. thesis, Berlin Technical University.47fiKatrenko, Adriaans, & van SomerenSekimizu, T., Park, H. S., & Tsujii, J. (1998). Identifying interaction genesgene products based frequently seen verbs Medline abstracts. GenomeInformatics, 9, 6271.Shawe-Taylor, J., & Christianini, N. (2000). Support Vector Machines KernelBased Learning Methods. Cambridge University Press.Smith, L. H., Yeganova, L., & Wilbur, W. J. (2003). Hidden Markov models optimizedsequence alignment. Computational Biology Chemistry, 27 (1), 77 84.Smith, T. F., & Waterman, M. S. (1981). Identification common molecular subsequences.Journal Molecular Biology, 147, 195197.Snow, R., Jurafsky, D., & Ng, A. Y. (2006). Learning named entity hyponyms questionanswering. Proceedings COLING/ACL.Swanson, D. R., & Smalheiser, N. R. (1999). Implicit text linkages Medline records:Using Arrowsmith aid scientific discovery. Library Trends, 48 (1).Thomas, J., Milward, D., Ouzounis, C., & Pulman, S. (2000). Automatic extractionprotein interactions scientific abstracts. Proceedings Pacific SymposiumBiocomputing.Tribble, A., & Fahlman, S. E. (2007). CMU-AT: Semantic distance background knowledge identifying semantic relations. SemEval-2007.Turney, P. D. (2006). Similarity semantic relations. Computational Linguistics, 32 (3),379416.van der Plas, L. (2008). Automatic Lexico-Semantic Acquisition Question Answering.Ph.D. thesis, University Groningen.van Rijsbergen, C. J., Robertson, S. E., & Porter, M. F. (1980). New models probabilisticinformation retrieval. Tech. rep. 5587, British Library Research DevelopmentReport.Vapnik, V. (1982). Estimation Dependences Based Empirical Data. New York:SPringer Verlag.Weeds, J., Weir, D., & McCarthy, D. (2004). Characterising measures lexical distributional similarity. Proceedings CoLing 2004.Zelenko, D., Aone, C., & Richardella, A. (2003). Kernel methods relation extraction.Journal Machine Learning Research, 3, 10831106.Zhang, Y., Schneider, J., & Dubrawski, A. (2008). Learning semantic correlation:alternative way gain unlabeled text. Proceedings 22nd ConferenceNeural Information Processing Systems, Vancouver, BC.48fiJournal Artificial Intelligence Research 38 (2010) 633-685Submitted 03/10; published 08/10Non-Transferable Utility Coalitional Gamesvia Mixed-Integer Linear ConstraintsGianluigi Grecoggreco@mat.unical.itDipartimento di MatematicaUniversita della CalabriaI-87036 Rende, ItalyEnrico MaliziaLuigi PalopoliFrancesco Scarcelloemalizia@deis.unical.itpalopoli@deis.unical.itscarcello@deis.unical.itDEISUniversita della CalabriaI-87036 Rende, ItalyAbstractCoalitional games serve purpose modeling payoff distribution problems scenarios agents collaborate forming coalitions order obtain higher worthsacting isolation. classical Transferable Utility (TU) setting, coalition worthsfreely distributed amongst agents. However, several application scenarios,case Non-Transferable Utility setting (NTU) must considered,additional application-oriented constraints imposed possible worth distributions.paper, approach define NTU games proposed based describing allowed distributions via set mixed-integer linear constraints appliedunderlying TU game. shown games allow non-transferable conditionsworth distributions specified natural succinct way. propertiesrelationships among prominent solution concepts NTU games holdapplied (mixed-integer) constrained games investigated. Finally, thorough analysis carried assess impact issuing constraints computationalcomplexity solution concepts.1. IntroductionCooperative game theory providesunder concept coalitional gamesan elegantframework modeling multi-agent systems agents might collaborateagents, forming coalitions order guarantee advantage. Withinframework, coalition N (where N set players, also calledgrand-coalition), assigned certain worth v(S) R, outcome gamevector real payoffs (xi )iN meant specify distribution worth grantedplayers result game.Coalitional games often classified according mechanisms underlying payoffdistributions. best known widely studied class therein coalitionalgames transferable utility (or TU games) (Osborne & Rubinstein, 1994),constraints whatsoever imposed way coalitional worths distributedamongst coalition members. context, several outcomes might associatedc2010AI Access Foundation. rights reserved.fiGreco, Malizia, Palopoli, & Scarcellogiven game, hence relevant question understand outcomes properlycapture rational behavior players. matter extensively studiedeconomics social sciences (Aumann & Hart, 2002). fact, various solution conceptsproposed literature identify worth distributions embodyrational concept stability, i.e., somehow immune deviations causedgroups players may decide leave grand-coalition form sub-coalitionsorder claim higher worths.cases, however, players cannot freely distribute coalition worthpure TU framework appropriate modeling purposes (Aumann & Peleg,1960). deal scenarios, coalitional games without transferable utility (or NTUgames) introduced literature, worth function definedreturn allowed worth distributions (called consequences, setting) associatedgiven coalition, rather associating one real value it. fact,easily understood NTU games general TU ones, since gamelatter kind expressed NTU game possible worth distribution amongmembers coalition consequence S.1.1 Modeling NTU Specifications via Mixed-Integer Linear ConstraintsTU GamesEnhancing TU games application-oriented constraints set possible outcomes approach exploited literature order model nontransferable scenarios. first occurrence name constrained games goes backseventies, due Aumann Dreze (1974), considered games coalition structures, players partitioned groups S1 , . . . , Sk , outcome(xi )iN must allocate total payoff v(SP j ) exactly amongst members group Sj ,is, satisfy equalities iSj xi = v(Sj ), 1 j k. However, AumannDreze noticed turn considering constraints TU games novelidea, since core nucleolus (which two prominent solution concepts TUgames) indeed defined Gillies (1959) Schmeidler (1969), respectively, gamesoutcomes restricted subsets R|N | .Recently, constrained games reconsidered pragmatic perspectivemodeling relevant application scenarios, price formation (Byford, 2007)autonomic wireless networks (Jiang & Baras, 2007). matter fact, however,received considerably little attention years. particular, general framework proposed literature systematic study (analytical, wellcomputational) properties kind approaches conducted far.paper, embark systematic formalization constrained games,investigate framework allowing succinctly specify non-transferable conditionsoutcomes underlying TU game, via set constraints expressed mixed-integerlinear (in)equalities.1 Note constrained games defined top underlyingTU specification, hence expected retain nice propertiestransferable setting. However, ability restricting set possible outcomes makes1. good source basic notions results mixed-integer linear programming bookNemhauser Wolsey (1988).634fiMixed-Integer Constrained Coalitional Gamesfit general framework NTU games, smoothly inheritsolution concepts shall use.allowing integer variables, constrained games studied paper improveexpressiveness classical NTU formalizations, admissible outcomes mightpossibly restricted non-convex non-comprehensive regions (definitionsproperties recalled Section 3.2). Indeed, NTU games attracted much attention earlier literature allow specify arbitrary consequences (Aumann & Hart,2002). Rather, according classical definition due Aumann Peleg (1960),NTU game actually game must satisfy additional conditions as, particular, convexity comprehensiveness. view features several nice propertiesmathematical perspective (Weber, 1994; McLean, 2002), influenced several proposals defining NTU games appeared literature, additionalconditions often considered. However, view appropriate model applicationscenarios required properties naturally hold.fact, framework constrained games proposed paper viewedframework (succinctly) define NTU games convexity comprehensivenessnecessarily hold. important peculiarity approach knowledge representation perspective. intuitive exemplification scenarios peculiaritymight useful illustrated below.Example 1.1. Three brothers, Tim, John Jim, aged 10, 8 5, resp., collectedpiggy money-box small Euro coins (values 1, 2, 5, 10 cents) Momevery week given since age four. Now, time comebreak money-box divide content. order avoid quarrels among kids,Mom decides distribution go ages, Tim deserveleast 10/8 money John get John, turn, receive least 8/5 Jimsmoney share. (Jim happy that, agrees comply Moms rule).money-box gets broken little treasure seven Euros ninety Euro cents,resulting available coin set including one-hundred 1-cent coins, seventy 2-centcoins, fifty 5-cents coins, thirty 10-cent coins, divided amongst kids.Note scenario based non-transferable condition treasurecannot freely distributed amongst brothers. specific distribution rule, however,fit classical NTU formalization Aumann Peleg (1960).hand, easily seen scenario modeled meansset linear (in)equalities, variables taking values set Z integernumbers. example, admissible outcomes indeed identified solutionsfollowing set mixed-integer linear (in)equalities (the three brothers Tim, JohnJim denoted using indexes 1, 2 3, respectively):635fiGreco, Malizia, Palopoli, & Scarcelloxi = 1 i1 + 2 i2 + 5 i5 + 10 i10 , 1 311 + 21 + 31 = 10012 + 22 + 32 = 7015 + 25 + 35 = 50110 + 210 + 310 = 30x1 10/8 x2x2 8/5 x3i1 , i2 , i5 , i10 0, 1 3xi R, i1 , i2 , i5 , i10 Z, 1 3Note auxiliary variables ij denote number coins value j takenplayer i, first five equalities encode restrictions domains variables definedavailable coin set, subsequent two inequalities encode Moms rule (whichseen, instance, playing role central market regulation authority).1.2 Contribution OrganizationDespite intuitiveness modeling approach adopted Example 1.1,reference framework literature accounting it, specificityMoms rule money distribution constrained available coin set,allowed outcomes form convex set.Proposing investigating framework may serve model kinds scenariosmain contribution paper. detail:define formal framework NTU games based mixed-integer linear constraints applied underlying TU game, discuss modeling capabilities,show main solution concepts NTU gamesin particular, core, bargainingset, kernel, nucleolus, Shapley valuespecialize within novel framework.analyze impact constraints basic properties solution concepts.Moreover, highlight similarities differences featured constrained gamesopposed TU games, investigating particular whether outcome stable(under concepts) TU game remains stable constraints issued.assess impact adding constraints computational complexity underlying concepts. particular, consider games characteristic functionform (von Neumann & Morgenstern, 1944) within setting worths givenoracles. context, discuss intrinsic difficulty checking whethergiven worth distribution core bargaining set, decidingnon-emptiness solutions. Complexity results constrained games alsocompared characterizing TU games.rest paper organized follows. Section 2, overview basicnotions cooperative game theory. formal framework constrained games definedSection 3. properties novel framework illustrated Section 4,analysis computational viewpoint carried Section 5. discussionconcluding remarks reported Section 6.636fiMixed-Integer Constrained Coalitional Games2. Coalitional Gamesimportant issue cooperative game theory determine payoff distributionsagents scenarios collaborate forming coalitions, order obtainhigher worths acting isolation. context, one usually take carerelevant problems emerging coalition formation process, coalitionvalue calculation coalition structure generation problemsan excellent overviewproblems state-of-the-art algorithm facing latter one foundwork Rahwan, Ramchurn, Jennings, Giovannucci (2009).Coalitional games introduced von Neumann Morgenstern (1944)order model payoff distributions problems scenarios utility freely transferred among players. cases, coalitional games described associatingpayoff possible coalition. Thus, coalitional game transferable utility (TU)pair hN, vi, N finite set players, v function (v : 2N 7 R)associates every coalition N real number v(S), called worth S.Scenarios utility cannot freely transferred among players first formalizedAumann Peleg (1960). scenarios, games described specifyingpossible payoff distributions players coalition, rather one(global) payoff. coalition N , let |S| denote cardinality S, let RS|S|-dimensional real coordinate space, whose coordinates labeled membersS; particular, given payoff vector x RS , xi denotes component associatedplayer S. Then, coalitional game without transferable utility (NTU)pair hN, V i, N finite set players, V function associating everycoalition N set payoff vectors V (S) RS , also called consequences.Note NTU games generalizations TU games. particular, accordingstandard encoding2 discussed, e.g., handbook edited Aumann Hart (2002)book Peleg Sudholter (2007), TU game hN, vi viewed throughoutpaper NTU game hN, Vv i, where:fiXSfiVv (S) = x R fixi v(S) , N.(1)Let G = hN, V NTU game. consequence x V (N ) imputation Gfollowing two properties hold (see, e.g., Peleg, 1963; Peleg & Sudholter, 2007):(1) Efficiency: V (N ), player N xi yi propertyalso known weak Pareto optimality;(2) Individual Rationality: player N , xi max{ yi | yi V ({i}) }.set imputations NTU game G denoted X(G). G actually TUgame, i.e., G = hN, vi (or, equivalently, G = hN, Vv i), immediate check that:fiXNfiX(G) = x R fixi = v(N ) xj v({j}), j N .2. Indeed, encoding allows solution concepts originally defined TU games smoothlygeneralized NTU frameworkas shall discuss later section.637fiGreco, Malizia, Palopoli, & Scarcelloparticular, note xj v({j}) encodes individual rationality player j x.outcome G imputation taken X(G) specifying payoff distributionplayers game. outcome represent kind agreement amongstplayers, stable respect possibility subsets players getincentive deviate it, forming coalitions own. Depending criterium adopted define concept stability, various (solution) concepts coalitionalgames defined. relevant solution concepts coalitional gamessuchcore, bargaining set, nucleolus, kernel, Shapley valuehaveoriginally defined within TU framework (see, e.g., Osborne & Rubinstein, 1994). Severalefforts subsequently paid apply concepts within general NTUframework (see, e.g., Aumann & Hart, 2002). Natural extensions definedcases, natural counterparts still missing looked others.following, shall provide overview definitions basic solutionconcepts TU games canonical extensions NTU games.2.1 Coreconcept core goes back work Edgeworth (1881). TU framework,formalized Gillies (1959), first extended NTU frameworkAumann (1961). fact, solution concept enjoys canonicalextension NTU case, one presented next.Let G = hN, V NTU game. coalition N , vector RSreal numbers called S-feasible V (S). Let x consequence RN . Then,pair (y, S) objection x S-feasible payoff vector yk > xkk Sin case, coalition also said block x via y.Definition 2.1. core C (G) NTU game G = hN, V set imputationsx objection; is,C (G) = {x X(G) |S N, V (S) yk > xk , k } .Thus, imputation x core stable coalition whose members receive higher payoff x leaving grand-coalition.application Definition 2.1 TU games exactly coincides originalformulation Gillies (1959). Moreover, easily seen that, applied TUgames, Definition 2.1 equivalently restated illustrated next (see, e.g., Osborne &Rubinstein, 1994). coalitionN payoff vector x RN , define x(S)Pvalue expression xi .Definition 2.2. core C (G) TU game G = hN, vi set imputationsx X(hN, Vv i) that, coalition N , x(S) v(S).Thus, core coalitional game transferable utility |N | players definedset inequalities |N | variables and, fact, polytope RN .638fiMixed-Integer Constrained Coalitional Games2.2 Bargaining Setconcept bargaining set defined Aumann Maschler (1964), manyvariants even within TU context (see, e.g., Maschler, 1992). natural extensionNTU framework given Peleg (1963), discussed next.Let G = hN, V NTU game, x consequence V (N ). Let Ncoalition, S-feasible payoff vector (i.e., V (S)). pair (y, S)objection player player j x S, j/ S, yk > xk k S.counterobjection objection (y, S) j x pair (z, ) j ,/ , z -feasible payoff vector zk xk k \ zk ykk S. exist counterobjection (y, S), say (y, S)justified objection.Definition 2.3. bargaining set B(G) NTU game G set imputationsx justified objection.Note definitions straightforwardly apply TU games, coincideone originally proposed Aumann Maschler (1964). sakecompleteness, recall (resp., z) S-feasible (resp., -feasible) payoffvector TU game hN, vi Vv (S)P(resp., z Vv (T )) holds;P is, y(S) v(S)(resp., z(T ) v(T ))recall y(S) = yi (resp., z(T ) = zi ).2.3 Nucleolusnucleolus solution concept introduced Schmeidler (1969). definition basednotion excess e(S, x, V ) coalition imputation x, measuredissatisfaction x.case TU games (where v denotes worth function), widely acceptedcanonical definition excess e(S, x, Vv ) = v(S) x(S). Then, vectorx RN , let us define (x) vector excesses associated coalitions(but empty one) arranged non-increasing order:(x) = (e(S1 , x, V ), e(S2 , x, V ), . . . , e(S2|N| 1 , x, V )).Let (x)[i] denote i-th element (x). pair imputations x y, say(x) lexicographically smaller (y), denoted (x) (y), existspositive integer q (x)[i] = (y)[i] < q (x)[q] < (y)[q].Since excess measure dissatisfaction, imputations lexicographically minimizing vector excesses natural candidates stable outcomesgame. indeed idea underlying definition nucleolus,defined Schmeidler (1969) TU games.Definition 2.4. nucleolus N (G) TU game G = hN, vi setN (G) = {x X(hN, Vv i) | X(G) (y) (x)}.games fit TU framework, definition still usedprovided suitable generalization concept excess conceived.639fiGreco, Malizia, Palopoli, & Scarcelloinfluential approach define excess functions NTU games proposed Kalai (1975),axiomatized properties functions satisfy retainnice features underlying TU specifications. properties follows:1. Let x, RN . xi = yi players S, e(S, x, V ) = e(S, y, V ) holds,function V ;2. Let x, RN . xi < yi players S, e(S, x, V ) > e(S, y, V ) holds,function V ;3. Let x RS . vector V (S) that, S, yi > xi ,e(S, x, V ) = 0 holds, function V ;4. e(S, x, V ) continuous jointly x V .example, prototypical excess function discussed Kalai following:, .eK (S, x, V ) = sup R | V (S) yi = xi +|S|(2)function coincides canonical excess function v(S)x(S) whenever appliedTU games (Kalai, 1975).2.4 Kernelkernel solution concept originally introduced TU framework DavisMaschler (1965) help understand properties bargaining set.TU game hN, vi, define surplus si,j (x) player player jimputation x value si,j (x) = maxS|iS,j / e(S, x, Vv ) = maxS|iS,j / (v(S) x(S)).Definition 2.5. kernel K (G) TU game G = hN, vi set:K (G) = {x X(hN, Vv i) | si,j (x) > sj,i(x) xj = v({j}), i, j N, 6= j}.Note definition TU games based notion excess.Intuitively, surplus player j x highest payoff playergain (or minimal amount lose, negative value) without cooperationj, forming coalitions players satisfied x; thus, si,j (x)weight possible threat j. particular, player bargainingpower j x si,j (x) > sj,i (x); however, player j immune threat wheneverxj = v({j}), since case j obtain v({j}) even operating alone. sayplayer outweighs player j x si,j (x) > sj,i(x) xj > v({j}). kernelset imputations player outweighs another one.Generalizing kernel NTU games based considering generalizationsexcess function, nucleolus. Again, influential approach, recalled next,due Kalai. However, worthwhile noticing approaches alsoproposed literature (see, e.g., Orshan & Zarzuelo, 2000; Peleg & Sudholter, 2007).Indeed, differently solution concepts discussed far, variations kernel (and640fiMixed-Integer Constrained Coalitional Gamesrelated concepts, prekernel, focus extensions cited above)NTU games still subject research debate (cf. Serrano, 1997).Let G = hN, V NTU game. say payoff vector RN transferplayer j player tj 0, ti 0, tk = 0, player k N \ {i, j}. transferjustified imputation x, every real number , 0 < < 1, vector = x +(such yk = xk + tk , k N ) individually rational vector V (N )(x + t) (x)of course, excess function G satisfying Kalais axiomatization mustused order define excess vectors. kernel K (G) G set: K (G) ={x X(G) | justified transfer player j player x, i, j N, 6= j}.2.5 Shapley ValueShapley value solution concept introduced TU framework Shapley (1953).concept associates every TU game G = hN, vi unique payoff vector (G) RN ,component (G)i , called Shapley value player i, indicatesworth assigned player i, based upon ability cooperation measuredexpected marginal contribution player forming coalitions (as formalized below).Let permutation set N players. player i, denote piset players preceding . marginal contribution player coalition piv(pi {i}) v(pi ). permutations chosen uniformly random setpossible permutations,P expected marginal contribution player game Gvalue (G)i = |N1 |! v(pi {i}) v(pi ) or, equivalently:(G)i =XSN \{i}|S|!(|N | |S| 1)!(v(S {i}) v(S)) .|N |!Shapley value unique payoff vector satisfying following properties,constitute axiomatic characterization3 :P(1) Efficiency:(G)i = v(N ).(2) Symmetry: Two players j symmetric if, N i, j/ S,v(S {i}) = v(S {j}). players players j symmetric, (G)i = (G)j .(3) Dummy: player dummy if, N \ {i}, v(S {i}) v(S) = v({i}).player dummy player, (G)i = v({i}).(4) Additivity: Let G = hN, wi TU game, G = hN, v + wi TU game(v+w)(S) = v(S)+w(S) coalition N . Then, (G )i = (G)i +(G )i .Note Shapley value might satisfy individual rationality, thusnecessarily imputation. Payoff distributions efficient, necessarilyindividually rational, called pre-imputations literature.Generalizing Shapley value NTU framework straightforward. Differentextensions Shapley value NTU games proposed. them,3. characterization reported one found often literature. However,original axiomatic formulation Shapley requires carrier axiom instead efficiencydummy axioms; two axiomatizations equivalent (Shapley, 1953; Winter, 2002).641fiGreco, Malizia, Palopoli, & Scarcelloevaluated NTU version TU game, coincides standard Shapley valueTU games. discuss generalization proposed Shapley (1969)formulation reported McLean (2002), refer interested reader latterwork extended treatment subject values NTU games, paperHart (2004) comparison notable three them.Let G = hN, V NTU game. vector RN strictly positive real numbers,let G game hN, v()Xv (S) = supzi | z V (S) .TU game G said defined G v (S) finite S.Definition 2.6. Let G = hN, V NTU game. vector x RN Shapley NTUvalue payoff G exists vector RN strictly positive real numbersthat: x V (N ); G defined G; xi = (G )i player N . setShapley NTU values G denoted (G).Shapley NTU values fulfill, adaptations, axioms characterizingstandard TU Shapley values. Actually, axioms suffice uniquely characterizeNTU counterpart, axioms issued order define unambiguouslyNTU Shapley value. axiomatization NTU case given Aumann (1985).interested reader referred work McLean (2002), issue.2.6 Properties Solution Concepts TU Gamesconclude recalling well-known properties solution concepts discussedabove, applied TU games.Proposition 2.7 (see, e.g., Osborne & Rubinstein, 1994). Let G = hN, vi TU gameX(G) 6= . Then:(1) |N (G)| = 1;(2) N (G) K (G) (hence, K (G) 6= );(3) K (G) B(G) (hence, B(G) 6= );(4) C (G) B(G); and,(5) C (G) 6= implies N (G) C (G).Note relationship Shapley value solutionconcepts (just recall Shapley value necessarily imputation).3. Constrained Games via Mixed-Integer Linear (In)EqualitiesAssume TU game G = hN, vi given consider problem modelingdealing constraints imposed feasible worth distributions amongst players G.642fiMixed-Integer Constrained Coalitional Gamesconstraints might implied nature domain hand (e.g.,worth arbitrarily divisible), reflect hard preferences expressedplayers regulation authorityrecall Example 1.1. approachencode application-oriented constraints within classical coalitional TU game settingdefining set mixed-integer linear (in)equalities, satisfiedimputations game G. approach first formalized below; subsequently, shallillustrate modeling capabilities discuss relationships TU framework.start recalling mixed-integer linear (in)equality linear (in)equalityvariables might constrained take values set Z integers.set LC mixed-integer linear (in)equalities, denote real (LC) int(LC) setsvariables LC defined R Z, respectively. Moreover, assume worthdistributions constrained defining inequalities via player auxiliary variables.player variable form xi , N player underlying TU game,meant encode worth assigned player outcomesgame. (possibly empty) set auxiliary variables LC setreal (LC) int(LC) \ {xi | N }. Auxiliary variables sometimes useful modelingpurposes, illustrated Example 1.1.Let us proceed formalization. Let G = hN, vi TU game, recallSection 2 G viewed NTU game hN, Vv i. Let LC set mixedinteger linear (in)equalities. Define (LC) set solutions LC. Moreover,coalition N , let (LC)[S] denote projection (LC) onto subspace associatedpayoff domains players S; is, vector index set belongs (LC)[S]vector x (LC) xi = yi holds, S.Intuitively, constrained game LC defined restricting consequencesunderlying TU game G belonging solution space set LC mixed-integerlinear (in)equalities projected onto subspace associated player variablesrecallauxiliary variables may occur LC. formalized below.Definition 3.1 (Mixed-Integer Constrained Games). Let G = hN, vi TU gamelet LC set mixed-integer linear (in)equalities. Then, (mixed-integer) constrainedgame G|LC NTU game hN, VLC VLC (S) = Vv (S) (LC)[S]. is,fiXSfiVLC (S) = x R fixi v(S) x (LC)[S] , N.3.1 Modeling Capabilities Constrained GamesConstraining TU game G via set LC (in)equalities involve integer variables(i.e., int(LC) = ) abstraction approaches literature considerspecific sets (in)equalities real variables (such Aumann & Dreze, 1974; Byford,2007; Jiang & Baras, 2007). particular, capability might exploited to:(1) State hard preferences worth distributions.example, consider game G = hN, vi set players N = {1, 2, 3, 4},v(N ) = 10. Assume players 3 4 together require get least643fiGreco, Malizia, Palopoli, & Scarcellohalf worth. Then, requirement modeled as:x3 + x4 5x1 , x2 , x3 , x4 RMoreover, allowing integer variables, completely novel modeling capabilities emergesetting w.r.t. earlier approaches. Indeed, integer variables used isolatenon-convex regions, might needed model specific application requirementsNTU nature, exemplified below.(2) Consider alternative scenarios.allowing integer variables, may model alternative preferences players, i.e.,may enforce disjunctions preferences. instance, consider scenarioeither players 1 2 must get together 3, players 2 3 must gettogether 5. case, two constraints (i.e., x1 + x2 3x2 + x3 5) goal define set (in)equalities prescribing leastone satisfied. end, auxiliary integer variable used:x1 + x2 3 + Ux2 + x3 5 + U (1 y)0y1x ,x ,x R1 2 3yZconstant value U upper bound worth coalition. Indeed,case = 1, constraint x1 + x2 3 + U trivially satisfied (because Usufficiently large), thus, enforce x2 +x3 5. Symmetrically, = 0,constraint x2 + x3 5 + U trivially satisfied, thus, enforce x1 + x2 3.course, simple manipulations, one may easily specify kinds alternatives, e.g., fact least (or most) k given constraints satisfied.(3) Restrict worth functions specific domains.domains required integer intervals, rather obvious. instance,assume x3 take values domain {4, 5, 6, 7, 8, 9, 10}. Then, maysimply consider following constraints:4 x3 10x ,x ,x R1 2 4x3 Zorder model general scenarios, (as point (2) above) mixedinteger linear (in)equalities defined auxiliary variables. instance, assumeplayer 2 wants either take whole worth (even formingcoalitions players) or, whenever possible, get nothing.modeled constraints, additional variable win fact, notice644fiMixed-Integer Constrained Coalitional Gamesv(N ) constant value game given hand:x2 = v(N ) w0w1x ,x ,x ,x R1 2 3 4wZNote Example 1.1 basically presents realistic case, several auxiliaryvariables used restrict money distributions available coin set.basic modeling capabilities constrained games discussed,order illustrate possible applications resulting framework, convenientpreliminarily observe two properties (which related use integer variables).First, easy check that, constrained games, may deal imputationsets arbitrary sizes.4Proposition 3.2. Let G = hN, vi TU game let X X(G) arbitrary finiteset imputations. Then, finite set constraints LC X(G|LC ) = X .addition, integer variables might used succinctly specify exponentially manyimputations via polynomially many (in)equalities.Proposition 3.3. exists class C = {G|nLC }n>0 constrained gamesgame G|nLC n + 1 players, LC consists 2 n + 1 inequalities, |X(G|LC )| = 2n .believe setting emerging properties rather appealingknowledge representation perspective. Indeed, one may exploit constrained gamesnaturally model scenarios non-transferable conditions emerge, devisingcompact specifications desired restrictions utilities may transferred amongcoalition members. fact, various circumstances envisaged usageconstrained games natural choice; instance, whenever worth distributedamong agents comes set indivisible goods, exemplified below.Example 3.4 (Distributing indivisible goods). certain region countryfamous hosting several producers two kinds goods, named .producer {1, . . . , n}, let denote quantity pieces produced i,respectively. assembling together one piece one piece , novel kind indivisiblegood obtained and, fact, commercializing assembled product muchadvantageous business selling separately. Therefore, agreement foundamongst producers area order assemble pieces overallavailable, provided resulting units assembled product (fairly) distributedamongst involved producers, would like independently commercialize them.scenario easily modeled within framework follows. First, associateevery coalition {1, . . . , n}, number pieces assembled productproduce. Thus, define:XXv(S) = min(,).4. sake exposition, proofs propositions stated section reported Appendix.645fiGreco, Malizia, Palopoli, & ScarcelloThen, since assembled product indivisible, possible worth distributionvector non-negative integers, immediately modeled via following setconstraints LC = {xi 0, xi Z, 1 n}. particular, (LC) convex region,earlier modeling perspectives NTU games, present handbookedited Aumann Hart (2002), apply here.cases, however, worth might practically assumed divisible,specific constraints regulate actual distribution. Notably, even cases, integervariables may play crucial role illustrated next.Example 3.5 (Service composition). Assume service acquired 100Eurosfor sake simplicity, assume money divisible, otherwise worthdistributions might simply restricted discrete domain Example 3.4Example 1.1. Supplying service implies executing tasks, named t1 , . . . , tm .Assume also set {1, . . . , n} agents, one capable carryingtasks, let sij denote ability agent perform task tj (sij = 1means agent able perform tj , whereas sij = 0 means capableso).PThus, coalition {1, . . . , n} capable supporting service casesij 1, j {1, . . . , m}.Assume, moreover, order complete , tasks must completed, agents contributing must able exchange partial results returnedperforming required tasks. Establishing communication infrastructure guaranteeingneeded result-transfers take place specific cost coalition S,denote com(S) < 100. Hence, amount money might finally distributedamongst players described following worth function:P100 com(S)sj 1, j {1, . . . , m}v(S) =0otherwise.Note scenario defines classical TU game G = h{1, . . . , n}, vi. However,things may significantly different assume agent sustain internalcost, say cij , whenever actually performing task tj , that, hence, may decideperform task all, convenient. Indeed, case, letting ji {0, 1}variable denoting whether actually performing tj , Pnatural statetotal internal cost agent (which given expressionj=1 j cj )exceed agent gets worth distribution. Hence, utilities cannot freelydistributed and, proper modeling realistic scenario, gameenriched following set constraints:Xji = 1, j {1, . . . , m}Xji cij , {1, . . . , n}xij=1LC =0 ji sij , {1, . . . , n}, j {1, . . . , m}x1 , . . . , xn Rj Z, {1, . . . , n}, j {1, . . . , m}646fiMixed-Integer Constrained Coalitional Gamesrespect formalization, worthwhile noting (LC) emptyservice cannot provided all, indeed X(G|LC ) would empty turn. Otherwise,i.e., (LC) 6= , imputations G|LC correspond worth distributions associatedlegal staffing tasks, rather arbitrary possible worth distributions(as would plain TU case).worthwhile contrasting formulation alternative TU one,constraints LC directly encoded definition worth function, insteadusing separate component thereof, done NTU framework proposing here.instance, one may add condition v(S) = 100 com(S) requirementexists element x (LC) task tj , playerji 6= 0 (in x). way, ensure payoff 100 com(S) assignedcoalition formed players perform task conformingcost constraints, jointly complete refined modeling perspectiveexactly one underlying class linear programming games (see, e.g., Owen, 1975).However, approach would prescribe payoff 100 com(S) actuallydistributed amongst players S. fact, focusing accurately modelingworth function, cannot guarantee outcome game (according chosensolution concept) fulfils desired constraints distribution payoffs singleplayers. words, using constraints definition worth function mayuseful certain cases careful modeling purposes, cannot general replaceuse external constraints actually constrain allowed worth distributions.important remark, note structure example maywell used guideline formalization application scenarios. Indeed,basic idea use mixed-integer linear constraints define solutions combinatorial problems associated feasible worth distributions (reflecting, e.g., costssolutions). Thus, contextualized approach case staffingproblem, similar encodings used define constrained games suited dealscheduling planning problems, cite few.3.2 Closer Look Constrained Gamesresort presentation framework constrained games analyzing structure consequences, role played individual rationalityrequirement context. analysis provide important bases subsequenttreatment analytical computational properties NTU solution conceptsapplied constrained games.3.2.1 Consequences Constrained Gamesorder understand nature constrained games, convenient take closerlook structure function VLC . fact, principle NTU game hN, Vimpose requirement function associating set consequence V (S)coalition N , NTU games attracted much attention literatureactually allow arbitrary consequences specified (Aumann & Hart, 2002). Indeed,sets consequences usually required satisfy additional conditions,(de facto) conceived guarantee nice properties hold solution concepts647fiGreco, Malizia, Palopoli, & Scarcellointerest. assumptions often considered literature(not necessarily required simultaneously hold) recalled next. N , V (S)might required be:(1) (Upper) Bounded: real number R x V (S),S, xi holds;(2) Closed: V (S) contains boundaries;(3) Compact: V (S) closed bounded;(4) Comprehensive: x V (S), RN (i S)(yi xi ), V (S);(5) Convex: pair x, V (S), real number t, 0 < < 1, vector(1 t)x + ty belongs V (S).(6) Non-empty: |V (S)| > 0.case constrained games, explicitly ask requirementssatisfied, thereby giving rise setting powerful modeling capabilities (asdiscussed Section 3.1). differences constrained games classical NTUgames illustrated next.Consider function VLC associated constrained game G|LC . first differenceconcerns property (1), VLC (S) required bounded (as TU case,individual payoffs players bounded general, since requirement sum exceed worth v(S) associated Ssee Equation (1)Section 2). Actually, substantial difference given that, possible worthdistribution G|LC corresponding solution concept illustrated Section 2,payoff player bounded.Similarly, easy see might cases property (2) holdcontext constrained games. Indeed, VLC (S) might closed whenever LCcontains strict inequality excludes boundary VLC (S). However, knowncases undesirable solution concepts, hence shall considerconstraints based non-strict inequalities only. Property (3) combinationfirst two properties, thus lines reasoning still apply.differences remaining three properties, instead, characterize frameworkconstrained games basis modeling capabilities. fact, abilityhandle sets consequences comprehensive convex, possiblyempty coalition, important peculiarity constrained games knowledgerepresentation perspective. Indeed, may lose comprehensiveness time constraintpayoff distribution given states players required get leastcertain worth; may lose convexity (as well comprehensiveness) time integralityconstraints involved. Moreover, may deal empty set consequencescoalition whenever feasible way distribute worth associatedaccording constraints players must satisfy.Example 3.6. Consider TU game G = hN, vi N = {1, 2, 3}, v({1, 2, 3}) = 3,v(S) = 0 {1, 2, 3}. Consider scenario worth G restricted648fiMixed-Integer Constrained Coalitional Gamesinteger value (i.e., payoff distributions taken Z{1,2,3} ), players1 2 require get least 2. constraints modeled follows:x1 + x2 2LC =x1 , x2 , x3 ZNote (LC)[{1, 2, 3}] = {x Z{1,2,3} | x1 + x2 2}, (LC)[{1, 2}] = {x Z{1,2} |x1 +x2 2}, (LC)[{1, 3}] = Z{1,3} , (LC)[{2, 3}] = Z{2,3} , (LC)[{1}] = Z{1} , (LC)[{2}] =Z{2} , (LC)[{3}] = Z{3} . Then, constrained game G|LC = hN, VLC that:VLC ({1, 2, 3}) ==VLC ({1, 2})=VLC ({1, 3})==VLC ({2, 3})VLC ({i})={x R{1,2,3} | x1 + x2 + x3 3} (LC)[{1, 2, 3}] ={x Z{1,2,3} | x1 + x2 + x3 3, x1 + x2 2};{x R{1,2} | x1 + x2 0} (LC)[{1, 2}] = ;{x R{1,3} | x1 + x3 0} (LC)[{1, 3}] = {x Z{1,3} | x1 + x3 0};{x R{2,3} | x2 + x3 0} (LC)[{2, 3}] = {x Z{2,3} | x2 + x3 0};{x R{i} | xi 0} (LC)[{i}] = {x Z{i} | xi 0}; (i {1, 2, 3})Despite simple constraints considered G, immediate check (e.g.)VLC (N ) comprehensive convex, VLC ({1, 2}) empty. Indeed,integrality constraints immediately lead loose comprehensiveness convexity. Moreover, fact players 1 2 require get least 2 implies coalition {1, 2}never form deviate grand-coalition, given two players cannotguarantee worth acting without player 3 (indeed, v({1, 2}) = 0).3.2.2 Individual Rationality Constrained Gamesimportant issue pointed constrained games related individualrationality requirement set imputations. Let G = hN, V NTU game,recall Section 2 imputation x X(G) must playerN , xi max{ yi | yi V ({i}) }.Consider constrained game G|LC G = hN, Vv underlying TU game.Definition 3.1, set VLC ({i}) coincides Vv ({i}) (LC)[{i}]. Then, individual rationality requirement, player i, xi max{ yi | yi Vv ({i})(LC)[{i}] }.Note special case occurs VLC ({i}) = Vv ({i}) (LC)[{i}] = . case,indeed, max{ yi | yi VLC ({i}) } defined (as real value). approach mighttherefore observe game over-constrained, stop analysis.approach is, fact, consistent several NTU formalizations requiring setconsequences non-empty, possible coalition (see Section 3.2.1).However, Example 3.6 already pointed empty sets consequencesmay naturally emerge constrained games, VLC (S) = reflects factcoalition cannot form deviate grand-coalition, worth distributionprinciple granted members alone (according underlying TUgame), satisfies constraints hand. Consequently, finer-grained perspectiveconsidered deal individual rationality requirement, special caseVLC ({i}) = , player N .basic observation VLC ({i}) = necessarily implies xi > v({i}) holds,imputation x VLC (N ). Thus, extreme scenarios, individual rationality649fiGreco, Malizia, Palopoli, & Scarcelloconstraint conceptually satisfied (though formally undefined) possible imputationx, since constraints LC require xi larger v({i}). Technically, stressconclusion implied defining max{} = , standard extensionmax empty sets.light perspective, show individual rationality preserved constraints added given TU game.Proposition 3.7. Let G = hN, vi TU game let x payoff vectorindividually rational w.r.t. G (i.e., xi v({i}), player N ). Then, setLC constraints, x individually rational w.r.t. constrained game G|LC .4. Solution Concepts Constrained GamesConstrained coalitional games special cases NTU games, therefore inheritvarious solution concepts discussed Section 2. Thus, constrained (and, such, NTU) game G|LC , interest compute core, bargainingset, nucleolus, kernel, Shapley value. section, study properties concepts, highlighting similarities differences featured constrainedgames opposed TU games.nutshell, show properties TU games stated Proposition 2.7still hold constrained games solution concepts, bargaining setmight empty games. Moreover, portion core TU game Gsatisfies constraints preserved, sense subset coreconstrained game G|LC built top G. hand, solutionsconcepts, preservation property holds special cases only.illustrating results, useful state property relating imputationset constrained game imputation set underlying TU game.Proposition 4.1. Let G|LC constrained game G = hN, vi.(LC)[N ] X(G|LC ).Then, X(G)Proof. Let x payoff vector X(G) (LC)[N ]. Since x X(G) x Vv (N ).also assuming x (LC)[N ] hence x VLC (N )recall,Definition 3.1, VLC (N ) = Vv (N ) (LC)[N ]. x X(G), x also efficient w.r.t.G, meaning Vv (N ), player N xi yi . Moreover, sinceVLC (N ) Vv (N ), x also efficient w.r.t. G|LC . Finally, Proposition 3.7, know xindividually rational w.r.t. G|LC . Thus, x X(G|LC ).Based result, show imputation x X(G) also belongs X(G|LC ),following shall show x satisfies constraints LC, thereby avoidingexplicitly reason efficiency individual rationality x.4.1 Relationships Among Solution Conceptsstart analysis investigating whether properties basic solution concepts(as appear Proposition 2.7) preserved setting constrained games.650fiMixed-Integer Constrained Coalitional Games4.1.1 Counterparts Proposition 2.7.(1) Proposition 2.7.(2)Let us begin focusing first two properties Proposition 2.7, pertainnucleolus. TU framework, nucleolus always consists exactly one imputation.constrained framework, properties solution concept intimately relatedcloseness (LC) (and, turn, X(G|LC )), i.e., whether (LC) containsboundaries. Recall Section 3 (LC) might closed dueoccurrence strict inequalities LC.Proposition 4.2. exists constrained game G|LC (with int(LC) = )X(G|LC ) 6= N (G|LC ) = (for excess function eK Equation (2)page 640).Proof. Consider game G players {1, 2}, v({1, 2}) = 1 v({1}) = v({2}) =0. Given constraint LC = {x1 < 12 , x1 R}, one may note X(G|LC ) 6= . Indeed,observe max{x1 | x1 VLC ({1})} = max{x2 | x2 VLC ({2})} = 0, since VLC ({i}) =Vv ({i}) (LC)[{i}] = {xi R{i} | xi 0} (LC)[{i}] = {xi R{i} | xi 0},{1, 2}. Thus, payoff vector x X(G|LC ) required satisfy x1 0x2 0, order individually rational. particular, claim X(G|LC ) = {xR{1,2} | x1 + x2 = 1, x1 < 12 , x1 0, x2 0}. Indeed, vector x VLC (N ) = {x RN |x1 + x2 1, x1 < 12 } x1 < 12 x2 < 12 efficient, givenvector VLC (N ) x1 < y1 < 12 x2 < y2 < 12 , y1 + y2 < 1. Moreover,vector x VLC (N ) x1 < 12 , x2 > 12 , x1 + x2 < 1 also efficient,given existence vector VLC (N ) x1 < y1 = x1 + 1x22 x1 < 12x2 < y2 = x2 + 1x22 x1 , (therefore) y1 + y2 = 1.Consider imputation x x1 + x2 = 1 x1 < 12 (and hence x2 > 12 ).Then, always build imputation 6= x y1 = x1 + ( 12 x1 )/2 > x1y2 = 1 y1 < x2 ; notice y1 < 12 holds. new imputation, case(y) (x) holds w.r.t. excess function eK Equation (2). Indeed, recallingVLC ({i}) = {xi R{i} | xi 0} xi 0 yi 0 hold, {1, 2},(x) = (0, x1 , x2 ) (y) = (0, y1 , y2 ). Thus, imputation xbelongs N (G|LC ), i.e., N (G|LC ) = . Note (LC) closed.practical applications linear programming, one may deal non-strict inequalities(see, e.g., Papadimitriou & Steiglitz, 1998); cases (i.e., whenever X(G|LC )closed hence compact, since always bounded), nucleolus empty.property observed hold Kalai (1975) along relationship nucleoluskernel. properties restated context follows.Proposition 4.3 (cf. Kalai, 1975). Let G|LC constrained game X(G|LC ) 6= .Then,(1) X(G|LC ) compact, |N (G|LC )| 1;(2) N (G|LC ) K (G|LC ) (hence, K (G|LC ) 6= whenever X(G|LC ) compact).following, examples counterexamples built avoiding use strictinequalities.651fiGreco, Malizia, Palopoli, & Scarcello4.1.2 Counterparts Propositions 2.7.(3), (4), (5)Let us move analyze counterpart Proposition 2.7.(3). end, firstnotice that, unlike TU case, bargaining set sometimes empty.Proposition 4.4. exists constrained game G|LC (with int(LC) = )X(G|LC ) 6= B(G|LC ) = .Proof. Consider TU game G players {1, 2, 3, 4}, whose worths follows:v({1, 2, 3, 4}) = 3, v({1, 2}) = 2, v({2, 3, 4}) = 3, v({1, 3, 4}) = 3, v({2}) = 1, v(S) = 0coalition {1, 2, 3, 4}. Consider moreover following set constraints:x1 + x2 + x3 + x4 = 3x2 + x3 + x4 = 3x1 + x3 = 1LC =x + x4 = 11x1 , x2 , x3 , x4 RLet x payoff vector x1 = 0 x2 = x3 = x4 = 1. Observe x satisfiesconstraints LC. Moreover, x imputation X(G); thus, Proposition 4.1, xbelongs X(G|LC ). fact, x vector (LC) and, therefore,imputation X(G|LC ). Thus, prove B(G|LC ) = , show xcontained B(G|LC ). end, consider objection (y, {1, 2}) player 1player 3, y1 = 13 y2 = 53 . Note y1 + y2 = v({1, 2}) = 2, y2 > 1 y1 > 0,thus {1, 2}-feasible. Moreover, recall v({3}) = v({3, 4}) = v({2, 3}) = 0.follows counterobjections 3 1 (y, {1, 2}) may constructedcoalition {2, 3, 4}. Assume (z, {2, 3, 4}) one counterobjection. player2, belongs intersection two coalitions {1, 2} {2, 3, 4}, z2 y2 > 1holds. constraint z2 + z3 + z4 = 3, entails z3 + z4 < 2. However,impossible since also z3 x3 = 1 z4 x4 = 1. Thus,possible counterobjections objection (y, {1, 2}) x. follows xbelong B(G|LC ) and, hence, B(G|LC ) = , even though X(G|LC ) 6= .consequence, derive counterpart Proposition 2.7.(3) holdconstrained games. Indeed, may consider game G|LC defined proofProposition 4.4 observe that, since X(G|LC ) 6= , Proposition 4.3, knowK (G|LC ) 6= .Corollary 4.5. constrained game G|LC (with int(LC) = ) B(G|LC ) =K (G|LC ) 6= (and thus K (G|LC ) 6 B(G|LC )).complete picture pertaining bargaining set, showingcore always included it. provides counterpart Proposition 2.7.(4).Proposition 4.6. Let G|LC constrained game. Then, C (G|LC ) B(G|LC ).Proof. Consider imputation x C (G|LC ) assume contradiction x/ B(G|LC ).this, must exist objection (y, S) x. Therefore, must caseS-feasible payoff vector G|LC yk > xk , k S. implies x/ C (G|LC ):contradiction. Thus, x B(G|LC ).652fiMixed-Integer Constrained Coalitional GamesFigure 1: Illustration Solution Concepts Example 4.8.finally stress counterpart Proposition 2.7.(5) already knownwork Kalai (1975), restated settings constrained games follows.Proposition 4.7 (cf. Kalai, 1975). Let G|LC constrained game. Then, C (G|LC ) 6=implies N (G|LC ) C (G|LC ).4.2 Preservation Solution Conceptscontinue investigation turning problem assessing whether outcomestable (under solution concept) TU game remains stable constraintsissued. crucial issue extent imputation set affectedconstraints imposed game. issue illustrated next.Example 4.8. Consider TU game G = hN, vi N = {1, 2}, v({1, 2}) = 2,v({1}) = v({2}) = 0. immediate check X(G) = {x R{1,2} | x1 + x2 = 2 x10 x2 0}. solution concepts G follows (see Figure 1 illustration):Core. imputation x X(G) coalition {1, 2}, casex(S) v(S). Thus, C (G) = X(G).Bargaining Set. Since C (G) B(G) (recall Proposition 2.7) since B(G) X(G),immediately B(G) = C (G) = X(G).Nucleolus. Let x X(G) imputation. Considering standard excess functionTU games, either (x) = (0, x2 , x1 ) (x) = (0, x1 , x2 ),depending whether x1 x2 x2 > x1 . Indeed, recall v({1, 2}) =x({1, 2}) = 2 v({1}) = v({2}) = 0. Thus, lexicographically minimum excessvector obtained imputation x x1 = x2 = 1, i.e., N (G) = {x}.Kernel. Since N (G) K (G) (recall Proposition 2.7), x K (G). Considerimputation x X(G) x 6= x. Assume x1 > 1 (the linereasoning applies case x2 > 1), thus x2 < 1. standardexcess function TU games, s1,2 (x) = x1 s2,1 (x) = x2 surpluses x,653fiGreco, Malizia, Palopoli, & Scarcellov({1}) = v({2}) = 0. Then, s2,1 > s1,2 holds, order x K (G),x1 = v({1}) = 0, case, x1 > 1. followsK (G) = {x}.Shapley Value. Note two players G symmetric hence Shapleyvalue must same. Thus, (G) = (1, 1).Now, consider constraints LC = {x1 +x2 1, x1 , x2 R}. Then, easily checkedX(G|LC ) = {x R{1,2} | x1 + x2 = 1 x1 0 x2 0}, hence X(G) X(G|LC ) = .applying line reasoning (and considering Kalais excess functionEquation (2) nucleolus kernel), derive C (G|LC ) = B(G|LC ) = X(G|LC )N (G|LC ) = K (G|LC ) = {y}, y1 = y2 = 12 (see, again, Figure 1).Moreover, Shapley NTU values G|LC , note vectors = (1 , 2 )1 = 2 = > 0 G|LC definedforevery vectorP G|LC . fact,= (1 , 2 ) 1 6= 2 value v|LC (N ) = supzi | z V (N ) infinite.Indeed, pre-imputations players necessarily individually rational, hencegame one player may get unbounded negative value, long one getsunbounded positive value sum 2. Now, every = (, ), worthfunction TU game G|LC v|LC ({1}) = v|LC ({2}) = 0, v|LC (N ) = . Sincetwo players symmetric, Shapley values family games form(G|LC ) = ( 2 , 2 ). Therefore, consequence x V |LC (N ) different ( 12 , 12 ) admitsvector = (1 , 2 ), 1 = 2 , xi = (G|LC )i players 1 2.conclude singleton {y} also set Shapley NTU values G|LC .Thus, solutions concepts constrained game G|LC completely unrelatedG.Note that, example, fact solution concept preservedchance. Indeed, recall core, bargaining set, nucleolus, kernel definedrefinements set possible imputations. Therefore, extreme scenarioX(G) X(G|LC ) = holds (for constrained game G|LC built top TU game G),none solution concepts preserved.Fact 4.9. Let G|LC constrained game X(G) X(G|LC ) = . Then,(1) C (G) C (G|LC ) = ;(2) B(G) B(G|LC ) = ;(3) N (G) N (G|LC ) = ; and,(4) K (G) K (G|LC ) = .Moreover, recall Shapely NTU values refinements set possible payoffdistributions associated grand-coalition (and, particular, pre-imputationsTU games). Thus, (G) 6 VLC (N ) (as Example 4.8), solution concept cannotpreserved. general, since (G) pre-imputation, following holds.Fact 4.10. Let G|LC constrained game, G = hN, vi. Assume VLC (N ) {xVv (N ) | x efficient } = . Then, (G) 6 (G|LC ).654fiMixed-Integer Constrained Coalitional Gameslight observations, however interest analyze whetherpreservation properties hold respect (pre)imputations G G|LC .example, interest establish relationship payoff vectorsC (G) X(G|LC ) (i.e., vectors core TU gameand thus imputationsgameand also imputations constrained game) payoff vectorsC (G|LC ) X(G) (i.e., vectors core constrained gameand thusimputations gameand also imputations TU game). Exploringrelationships, solution concept, addressed rest section.4.2.1 Corefirst result concerns core, shows imputations coreTU game satisfy constraints also core resulting constrained game.Proposition 4.11. Let G|LC constrained game. Then, C (G) X(G|LC ) C (G|LC )X(G).Proof. Let G = hN, vi TU game, recall Section 2 G equivalentlyviewed NTU game hN, Vv i. Assume x payoff vector C (G), henceX(G). Then, coalition N vector Vv (S) yi > xi , S.Definition 3.1, NTU game G|LC = hN, VLC i, case VLC (S) Vv (S),N . Therefore, coalition N vector VLC (S)yi > xi , S. is, x X(G|LC ), x belongs C (G|LC ).However, inclusion strict cases, even imputation affectedconstraints, i.e., even X(G) = X(G|LC ).Proposition 4.12. exists constrained game G|LC (with int(LC) = )X(G) = X(G|LC ), C (G) = C (G|LC ) 6= . Thus, C (G) X(G|LC ) C (G|LC ) X(G).Proof. Consider TU game G = hN, vi N = {1, 2, 3}, v({1}) = 1, v({2}) = 1,v({3}) = 2, v({1, 2}) = 3, v({1, 3}) = 0, v({2, 3}) = 0, v({1, 2, 3}) = 4. NoticeX(G) = {x} x1 = 1, x2 = 1, x3 = 2; C (G) = . particular,latter equality, consider pair (y, {1, 2}) y1 = y2 = 32 . Since y({1, 2}) =v({1, 2}), y1 > x1 y2 > x2 , (y, {1, 2}) objection x, thereforebelong C (G).Consider following set constraints:x1 + x2 2LC =x1 , x2 Reasily seen x satisfies LC. Thus, x X(G|LC ) holds Proposition 4.1. Moreover,since (LC)[{i}] = R{i} holds player N , constraintworths singleton coalitions, individual rationality constraint G|LC prescribesx X(G|LC ): x1 v({1}) = 1, x2 v({2}) = 1, x3 v({3}) = 2. Sincev({1, 2, 3}) = 4, x fact imputation X(G|LC ). Thus, X(G) = X(G|LC ).conclude proof, let us observe that, constrained game G|LC ,{1, 2}-feasible vector z z1 > x1 z2 > x2 ; indeed, observe z1 + z2 2holds constraints, x1 + x2 = 2. is, objection x,therefore imputation C (G|LC ).655fiGreco, Malizia, Palopoli, & Scarcello4.2.2 Bargaining Setfar bargaining set concerned, show constrained gameswhose bargaining set completely unrelated underlying TU games.objections counterobjections necessarily restricted setpossible imputations. Thus, constraints may radically alter feasibility propertiescertain payoff vectors, yet without affecting imputation set. shownfollowing two propositions.Proposition 4.13. exists constrained game G|LC (with int(LC) = )X(G) = X(G|LC ), B(G) X(G|LC ) 6 B(G|LC ) X(G).Proof. Consider TU game G = hN, vi N = {1, 2, 3, 4, 5}, v({1, 2, 3, 4, 5}) = 8,v({2, 3, 4}) = 8, v({1, 3, 4}) = 7, v({1, 2}) = 2, v({5}) = 1, v(S) = 0coalition N . Consider imputation x x1 = 0, x2 = 1, x3 = 3, x4 = 3,x5 = 1. claim x B(G). Indeed, let (y, S) objection x. objectioncarried three different coalitions, counterobjection:First, = {2, 3, 4}, y2 > x2 = 1, y3 > x3 = 3, y4 > x4 = 3, y2 + y3 +y4 v({2, 3, 4}) = 8. case (y, S) objection player 1player 5. former case, (z, {1}) z1 = x1 = 0 trivial counterobjection(y, S); latter case, (z, {5}) z5 = x5 = 1 counterobjection (y, S).Second, = {1, 3, 4}, y1 > x1 = 0, y3 > x3 = 3, y4 > x4 = 3,y1 + y3 + y4 v({1, 3, 4}) = 7. case, (y, S) objection playerplayer 2 player 5. observed above, (z, {5}) z5 = x5 = 1trivial counterobjection objection 5. Thus, let us assume(y, S) objection player 2. (y, S) objection player 3 4,may consider pair (z, {1, 2}) z1 = y1 z2 = x2 . Indeed, notey1 < 1 holds and, thus, z1 + z2 < 1 + x2 = 2 = v({1, 2}). Therefore, z{1, 2}-feasible, (z, {1, 2}) counterobjection (y, S). hand,(y, S) objection player 1 player 2 x, may consider pair(w, {2, 3, 4}) w2 = x2 , w3 = y3 , w4 = y4 . Note y3 + y4 < 7 and,thus, w2 + w3 + w4 < x2 + 7 = 1 + 7 = v({2, 3, 4}). Then, w {2, 3, 4}-feasible,(w, {2, 3, 4}) counterobjection (y, S).Finally, = {1, 2}, y1 > x1 = 0, y2 > x2 = 1, y1 +y2 v({1, 2}) = 2.case, (y, S) objection player 3, 4, 5. Let us considerfirst two cases, since (z, {5}) z5 = x5 = 1 trivial counterobjectionobjections 5. (y, S) objection player 1 (against player 3 4),may consider pair (z, {2, 3, 4}) z2 = y2 , z3 = x3 , z4 = x4 . Notey2 < 2 and, thus, z2 +z3 +z4 < 2+x3 +x4 = 2+6 = v({2, 3, 4}) = 8. Hence, (z, {2, 3, 4})counterobjection (y, S). (y, S) objection player 2 (against player 34), may consider pair (w, {1, 3, 4}) w1 = y1 , w3 = x3 , w4 = x4 .Note y1 < 1 and, thus, w1 + w3 + w4 < 1 + x3 + x4 = 1 + 6 = v({1, 3, 4}) = 7.Hence, (w, {1, 3, 4}) counterobjection (y, S).656fiMixed-Integer Constrained Coalitional GamesConsider following set constraints:x2 + x3 + x4 7LC =x2 , x3 , x4 Rimmediate check X(G) = X(G|LC ); indeed, individual rationalityplayer 5 forces x5 1; given v({1, 2, 3, 4, 5}) = 8, constraint thereforelogically implied individually rational vectors VLC (N ). However, LC plays crucialrole concerning formation coalition {2, 3, 4}. Indeed, consider objection(y, {1, 2}) player 1 player 3 x, y1 = 12 y2 = 32 . counterobjection(z, ) (y, {1, 2}) must = {2, 3, 4}. Thus, z2 y2 = 32 , z3 x3 = 3,z4 x4 = 3 must hold. follows z2 + z3 + z4 > 7 and, hence, z 6 VLC (T ). Since (y, S)justified objection, x 6 B(G|LC ).Proposition 4.14. exists constrained game G|LC (with int(LC) = )X(G) = X(G|LC ), B(G|LC ) X(G) 6 B(G) X(G|LC ).Proof. Consider TU game G = hN, vi N = {1, 2, 3}, v({1}) = v({2}) = 1,v({3}) = 0, v({1, 3}) = v({2, 3}) = 4, v({1, 2}) = 5, v({1, 2, 3}) = 3. Considerimputation x x1 = x2 = x3 = 1. observe x/ B(G). Indeed, considerobjection (y, {1, 2}) player 1 player 3 y1 = 1 + 12 y2 = 3 + 12(observe y({1, 2}) = v({1, 2}). Player 3 cannot counterobject either singleton,since v({3}) < x3 , coalition {2, 3}, since vector z R{2,3}z2 y2 > 3 z3 x1 = 1, z({2, 3}) > 4 = v({2, 3}). follows x 6 B(G).Consider following set constraints:x1 + x2 4LC =x1 , x2 Rimmediate check X(G) = X(G|LC ). Moreover, let us notice playerjustified objection player 1 2 x, since counterobject singletons;indeed, observe v({i}) = 1 = xi , {1, 2}. Consider, then, objection(y, {1, 2}) player 1 player 3, y1 x1 = 1 y2 x2 = 1. Since, mustbelong VLC ({1, 2}), y2 3 holds. Thus, pair (z, {2, 3}) z2 = 3 y2z3 = x3 = 1 counterobjection (y, {1, 2}), z({2, 3}) = 4 = v({2, 3}).symmetry game definition, line reasoning applies showalso player 2 justified objections player 3. Therefore, x B(G|LC ).4.2.3 Nucleolus KernelLet us move analyze nucleolus kernel. case bargaining set,preservation property holds, demonstrated next.Proposition 4.15. exists constrained game G|LC (with int(LC) = )X(G) = X(G|LC ) 6= , K (G) K (G|LC ) = , N (G) N (G|LC ) = (for Kalais excessfunction Equation (2) page 640).657fiGreco, Malizia, Palopoli, & ScarcelloProof. Consider TU game G = hN, vi N = {1, 2, 3}, v({1, 2, 3}) = 3,v({1, 2}) = 5, v({1, 3}) = 4, v({2, 3}) = 3, v(S) = 0, coalition N .Consider imputation x belongs K (G), consider expressions: s1,3 (x)s3,1 (x) = (5 x1 x2 ) (3 x2 x3 ) = 2 x1 + x3 s1,2 (x) s2,1 (x) = (4 x1 x3 )(3 x2 x3 ) = 1 x1 + x2 . Definition 2.5, get 2 x1 + x3 > 0 impliesx3 = 0, 2 x1 + x3 < 0 implies x1 = 0, 1 x1 + x2 > 0 implies x2 = 0,1 x1 + x2 < 0 implies x1 = 0. simple algebraic calculations, relationshipstogether individual rationality x (i.e., x1 0, x2 0, x3 0) entailx1 x2 = 1 x1 x3 = 2 must hold. turn, since x1 + x2 + x3 = 3, latter twoequations uniquely determine value x. particular, K (G) singleton {x}x1 = 2, x2 = 1 x3 = 0. Moreover, since N (G) K (G) |N (G)| = 1 (seeProposition 2.7), N (G) = K (G).Consider following set constraints:x1 + x2 3x1 + x3 3LC =x + x3 32x1 , x2 , x3 RNotice constraints modify imputation set, is, X(G) =X(G|LC ) 6= . Moreover, observe V |LC = Vv , v worth function gameG = hN, v v ({1, 2, 3}) = v ({1, 2}) = v ({1, 3}) = v ({2, 3}) = 3, v (S) = 0coalitions N . this, excess function eK reported Equation (2) coincides canonical TU excess, definitions kernel NTU nucleolus NTUcoincide TU games (cf. Kalai, 1975). kernel nucleolus G|LCG . Finally, easily checked K (G ) singleton {x } x1 = 1,x2 = 1 x3 = 1 (and, thus, K (G ) = N (G )). follows K (G) K (G|LC ) =N (G) N (G|LC ) = .4.2.4 Shapley ValueLet us conclude analysis Shapley value. Below, show solution concept preserved whenever set pre-imputations modified constraints.Proposition 4.16. Let G|LC constrained game. sets pre-imputations GG|LC coincide, (G|LC ) = {(G)}.Proof. Let pX(G) = {x RN | x(N ) = v(N )} set pre-imputations TUG = hN, vi; fact, recall pX(G) contains efficient payoff vectors Vv (N ) = {xRN | x(N ) v(N )}. Let pX(G|LC ) = {x Rn | x(N ) v(N )x (LC)[N ]x efficient}set pre-imputations G|LC . Since pX(G) = pX(G|LC ), must case(LC)[N ] Vv (N ) = {x Rn | x(N ) v(N )}. Therefore, VLC (N ) = Vv (N ) (LC)[N ] =Vv (N ). coalition vector RS , consider vector x RNxi = yi , S, xi = (v(N ) y(S))/|N \ S|, (N \ S). Notex(N ) = v(N ) and, hence, x Vv (N ) x (LC)[N ]. Therefore, belongs (LC)[S].Thus, (LC)[S] = RS and, hence, VLC (S) = Vv (S) (LC)[S] = Vv (S), N .Finally, since VLC (N ) = Vv (N ) also holds (and thus VLC (S) = Vv (S), N ),follows (G|LC ) = {(G)} (see, e.g., McLean, 2002).658fiMixed-Integer Constrained Coalitional GamesHowever, Shapley value (G) preserved general, even (G) imputation, imputation sets affected constraints.Proposition 4.17. exists constrained game G|LC (with int(LC) = )(G) X(G), X(G) = X(G|LC ), (G)/ (G|LC ).Proof. Consider TU game G = hN, vi N = {1, 2, 3}, v({1, 2, 3}) = 3,v({1, 2}) = 4, v({1, 3}) = 3, v({2, 3}) = 3, v(S) = 0, coalition N .simple calculations, one may compute Shapley value (G), notice (G)1 = 7/6,(G)2 = 7/6, (G)3 = 4/6. Thus, (G) X(G).Consider following set constraints:x1 + x2 3LC =x1 , x2 Rnotice modify imputation set, is, X(G) = X(G|LC ) 6= .Indeed, inequality x1 + x2 3 logically implied worth grand-coalition(which forces x1 + x2 + x3 3) individual rationality players (i.e., x1 0,x2 0, x3 0). sake completeness, note constrained game Gfit hypothesis Proposition 4.16 since pX(G) 6= pX(G|LC ) (indeed, payoffvector x x1 + x2 > 3 x(N ) v(N ) = 3 pre-imputation G G|LC ,x1 + x2 3 satisfied).Moreover, observe V |LC = Vv , v worth function game G =hN, v v ({1, 2, 3}) = v ({1, 2}) = v ({1, 3}) = v ({2, 3}) = 3, v (S) = 0coalitions N . suffices conclude (G|LC ) = {(G )} (see, e.g., McLean,2002). However, easily checked (G ) (G )1 = (G )2 = (G )3 = 1.Thus, (G)/ (G|LC ).5. Complexity Analysissection, shall look core bargaining set (constrained) coalitionalgames computational viewpoint. particular, aim shed light impactissuing constraints w.r.t. intrinsic complexity notions, assess whetherprice paid increased expressiveness constrained gamesfor sakecompleteness, background notions complexity theory reported Appendix.argue fact sensible analyze computational properties,corresponds analyzing feasibility using concepts thesis boundedrationality, is, decisions taken realistic agents cannot involve unbounded resources support reasoning (Simon, 1972). Moreover, worthwhile noting studyingmatters might hopefully guide design effective computation algorithms.leave future work complexity analysis solution concepts,would interesting consider various kinds Kalais excess functions differentcomputational properties.5.1 Setup Problems Analyzedanalysis follows, assume games provided characteristic function form,i.e., deal scenarios coalition worths returned given function (von659fiGreco, Malizia, Palopoli, & ScarcelloNeumann & Morgenstern, 1944). instance, games discussed Example 3.4Example 3.5 characteristic function form. Moreover, following generalframework proposed Bilbao (2000), assume input reasoning problemconsists constrained game G|LC worth function v given oracle.particular, shall consider two types oracles:(1) Oracles computable polynomial time size ||G|LC || game representation.5 instance, game Example 3.4 fits framework, well gameExample 3.5, provided cost function com(S) (of establishing communicationinfrastructure agents S) comes oracle computable polynomial time.(2) Oracles computable non-deterministic polynomial time size ||G|LC ||game representation. instance, game Example 3.5 may fit settingcautious perspective require that, coalition S, valuev(S) = 100 com(S) actually obtained imputation. is,add condition element x (LC) task tj ,player ji 6= 0 (in x), i.e., task actuallyperformed coalition conforming costs constraints. Here,also require course com(S) computable non-deterministic polynomialtime. Note powerful worth-functions used encode NP-completeproblems reflecting results complex algorithmic procedures, arisingallocation, scheduling routing scenarios, name few.Let us remark framework worth function oracle computablepolynomial time encompasses settings games (implicitly) describedkind compact structures, simple calculations encodingsperformed compute worth given coalitionnoticeable influentialsettings type graph hypergraph games (Deng & Papadimitriou, 1994),marginal contribution nets (Ieong & Shoham, 2005), games multi-issue domains(Conitzer & Sandholm, 2004), weighted voting games (Elkind & Pasechnik, 2009;Elkind, Goldberg, Goldberg, & Wooldridge, 2009). Therefore, membership resultsimmediately carry various classes games cited above, whereas hardness resultsspecific oracle setting, hold general (sub)settings.Within setting discussed above, shall next focus checking whether givenimputation satisfies conditions needed core bargaining set. Thus,given constrained game G|LC vector x, following problems considered:Core-Check: x C (G|LC )?BargainingSet-Check: x B(G|LC )?addition, recall Section 4 core bargaining set might emptyconstrained games. Thus, sensible well study following problems:5. usual, implicitly assumed game representation includes list players, that,every coalition S, ||S|| ||G|LC ||. Otherwise, one formally say, e.g., oraclescomputable polynomial time combined size G|LC S.660fiMixed-Integer Constrained Coalitional GamesProblemConstrainedConstrained(int(LC) {xi |i N })Constrained(int(LC) = )TUCore-CheckBargainingSet-CheckCore-NonEmptinessBargainingSet-NonEmptinessDP -completeP2 -completeP2 -completeP3 -completeco-NP-completeP2 -completeP2 -completeP3 -completeco-NP-completeP2 -completeP2 -completeP3 -completeco-NP-completeP2 -completeco-NP-completetrivialFigure 2: Complexity Results Constrained Games. Hardness results hold even cohesive games worth functions given polynomial-time oracles. Membershipresults hold non-deterministic polynomial-time worth-function oracles, without assumption representation real numbers.Core-NonEmptiness: C (G|LC ) 6= ?BargainingSet-NonEmptiness: B(G|LC ) 6= ?Overview Results. summary results reported Figure 2. Notefour settings emerge analysis: TU games, constrained games without integervariables (i.e., int(LC) = ), constrained games without auxiliary integer variables (i.e.,int(LC) {xi | N }), arbitrary constrained games. fact, stress hardnessresults established without use auxiliary real variables, membership results(for constrained games) hold even variables kind actually occur. Thus, auxiliaryreal variables play computational role setting constrained games.Concerning checking problems, Figure 2 evidences Core-Check co-NPhard TU games, co-NP constrained games auxiliary integer variablesallowedas said above, bound membership result numberconsidered auxiliary real variables. allowing use auxiliary integer variables,Core-Check becomes DP -hard, fact complete class. Thus, auxiliary integervariables cause slight increase complexity solution concept. hand,emerged occurrence real variableseither player variables auxiliary onesinteger player variables completely immaterial computational perspective.far BargainingSet-Check concerned, deliver good newsadding constraints alter complexity w.r.t. TU case. Indeed, problemPP2 -hard TU games, 2 whichever constraints considered.Concerning non-emptiness problems, show instead constraints may radicallyalter computational properties. Indeed, CoreNonEmptiness raises one levelpolynomial hierarchy, co-NP absence constraints (Malizia, Palopoli, &Scarcello, 2007) P2 , BargainingSet-NonEmptiness trivial TU games(since concept always non-empty there), becomes P3 -complete constrainedgames. Interestingly, cases, auxiliary integer variables play role.Indeed, hardness results established basic case int(LC) = (and withoutauxiliary variables), membership results hold arbitrary constraints.following, hardness results shown hold simplest case(deterministic) polynomial-time worth-function oracles. Moreover, membership resultsassume a-priori bound representation size real numbers. end,661fiGreco, Malizia, Palopoli, & Scarcellonon-trivial technical matters faced next, show algorithms safely workpolynomially many bits, solution concept considered paper.5.2 Hardness Results (on Cohesive Games Polynomial-Time Oracles)section, shall establish hardness results. particular, order highlightintrinsic difficulty associated solution concepts, constructions reportedkinds worth functions simple computational viewpoint,given via oracles computable polynomial time, also algebraicviewpoint, induce cohesive games.recall (TU) game cohesiveworth function v that,Ppartition players N , v(N ) SS v(S) holds (Osborne & Rubinstein, 1994)acondition often imposed order guarantee grand-coalition actually forms. Noteearlier proofs complexity results compactly specified games (see, e.g., Deng &Papadimitriou, 1994; Greco, Malizia, Palopoli, & Scarcello, 2009b; Ieong & Shoham, 2005)generally exploit constructions games cohesive and, hence,entail hardness results stated paper. fact, results interestingly showcohesivity simplify reasoning solution concepts coalitional games.order establish hardness results, exploit number reductions referBoolean formulae. Let Boolean formula, let vars() = {W1 , . . . , Wn } setBoolean variables occurring . Recall literal either Boolean variable Winegation Wi . former called positive literal, latter called negativeliteral. denote vars() = {Wi | Wi vars()} set negative literalsvariables occurring . Literals associated game players proofs.set players S, define (S) truth assignment Wi vars() true Wioccurs S, false, otherwise. fact (S) satisfies denoted (S) |= .Moreover, say coalition vars()vars() consistent w.r.t. set variablesvars() if, Wi , |{Wi , Wi } S| = 1 holds. case = vars(),simply say consistent.start demonstrating hardness results various membership-checking problems. first result co-NP-hardness Core-Check, establishedbasis rather standard arguments reported sake completeness.particular, reader may find useful check reduction exploited proofbased games cohesive, makes different earlier complexity resultsgiven literature specific kinds compactly specified games.Theorem 5.1. Core-Check co-NP-hard, even cohesive TU games polynomialtime oracles input vector imputation.Proof. Recall deciding whether Boolean formula variables X1 , . . . , Xnsatisfiable, i.e., deciding whether exists truth assignment variablesmaking true, co-NP-complete problem (Johnson, 1990).Given formula , build polynomial time TU game G() = hN, vi,N = vars() {w, e} where, set players S, v that:1 = N,v(S) =1 e/ w (S) |= ,0 otherwise.662fiMixed-Integer Constrained Coalitional GamesConsider, now, vector x xe = 1 xp = 0 player p, notex imputation. claim that: x C (G()) satisfiable.() x C (G()) implies coalition S-feasible payoff vectoryi > xi , S. Consider coalition/assignment e/w S, observe x(S) = 0. Since x C (G()), must v(S) = 0,entails (S) satisfy , definition worth function. Givenone-to-one correspondence coalitions (with e/ w S)truth assignments , conclude satisfiable.() x/ C (G()), must exist coalition N x(S) < v(S),possible x(S) = 0 v(S) = 1. construction worth function,follows N , e/ S, w (S) |= . is, satisfiable.Finally, observe role player w guarantee game cohesive.Indeed, partition N , one set contains w, hencemay get 1 coalition worth.considering constrained games arbitrary input vectors (i.e., necessarilyimputations), Core-Check turns slightly difficult previouscase. fact, stress use auxiliary integer variables crucial orderestablish result illustrated next.Theorem 5.2. Core-Check DP -hard, even cohesive constrained games polynomial-time oracles.Proof. Given pair Boolean formulae (, ), deciding whether satisfiablesatisfiable prototypical DP -complete problem (Johnson, 1990). Assume, w.l.o.g.,= c1 . . .cm , ci = ti,1 ti,2 ti,3 , {1, . . . , m}. is, conjunctivenormal form every clause contains exactly three literals. Moreover, let vars( ) ={Y1 , . . . , } vars() = {X1 , . . . , Xn }, assume w.l.o.g. vars() vars( ) = .Consider TU game G() = hN, vi built proof Theorem 5.1, recallN = vars() {w, e} vector x (where xe = 1 xp = 0, playerp N p 6= e) belongs C (G()) satisfiable.Consider following set constraints:1 TYj 0, j {1, . . . , }(ti,1 ) + (ti,2 ) + (ti,3 ) 1, {1, . . . , m}LC =x R, p NpTYj Z, j {1, . . . , }(ti,h ) denotes expression 1 Tti,h ti,h negative literal, expressionTti,h ti,h positive literal. Note players N actually constrained LC.Therefore, (LC) = , (LC)[N ] = trivially holds (since (LC)[N ] restrictionempty set RN ). Otherwise, i.e., (LC) 6= , (LC)[N ] = RN thereforeconstraints immaterial. course, (LC) = , imputationG()|LC ; otherwise, solution concepts G() preserved G()|LC , sinceconstraints play role case.663fiGreco, Malizia, Palopoli, & ScarcelloObserve that, j {1, . . . , }, TYj constrained domain {0, 1}encode truth value Boolean variable Yj . Clearly, LC computedpolynomial time , immediate check (LC) 6=satisfiable. follows vector x core G()|LC x belongscore G() (i.e., satisfiable) (LC) 6= (i.e., satisfiable).turn study bargaining set. Notice class graph games(which instance general framework considering here) completenessBargainingSet-Check P2 recently established Greco et al. (2009b).Clearly enough, result already implies BargainingSet-Check P2 -hardTU games polynomial-time oracles. Below, show hardness result stillholds games polynomial-time oracles moreover cohesive.Theorem 5.3. BargainingSet-Check P2 -hard, even cohesive TU gamespolynomial-time oracles input vector imputation.Proof. show polynomial-time reduction problem deciding whether quantified Boolean formula H = Y1 , . . . , Yn Z1 , . . . , Zq valid, well-known P2complete problem (Johnson, 1990). Let = {Y1 , . . . , Yn } Z = {Z1 , . . . , Zq } denotesets universally existentially quantified variables, respectively.Based H, build game G(H) = hN, vi, N = vars() vars() {a, }where, set players S, v that:2 = N,1 |S| = n consistent w.r.t. {Y1 , . . . , Yn },v(S) =1 consistent, |{a, } S| = 1, (S) |= ,0 otherwise.Let x imputation xa = xa = 1 xp = 0, player p.construction G(H) x defined guarantee two basic properties,intuitively illustrated next:(1) Recall objection (y, S) player player j x S,j/ S, y(S) v(S) yk > xk , k S. Since v(S) > x(S) must holdobjection (y, S), case objections one-to-one associated truthassignments variables Y; indeed, v(S) = 1 (and x(S) = 0).Let (Y \ S) truth assignment associated coalition S.(2) Recall counterobjection (z, ) objection (y, S) player player jx/ , j , z(T ) v(T ), zk yk , k S, zk xk ,k \ S. (y, S) objection player j/ {a, }, (z, {j})zj = 0 trivial counterobjection. hand, counterobjections (z, )objections (y, S) necessarily = , z(T )1 xa = xa = 1. particular, z(T ) = 1 must hold. Thus, counterobjectionsone-to-one associated possible satisfying truth assignmentsvariables H, moreover obtained extensions assignment (Y \ S).664fiMixed-Integer Constrained Coalitional GamesDefinition 2.3, x bargaining set G(H) objection(i.e., assignment (Y \ S) variables Y), counterobjection (i.e., satisfyingassignment obtained extending (Y \ S)). Therefore, following claim holds, whoseformal proof reported Appendix:Claim A. x B(G(H)) H valid.conclude proof, note game cohesive. Indeed, coalitionv(S) = 1, case |S {Y1 , . . . , Yn , Y1 , . . . , Yn }| = n. Thus, given threecoalitions S1 , S2 S3 v(S1 ) = v(S2 ) = v(S3 ) = 1, must case twooverlap players. Therefore, partition N contains twocoalitions getting worth greater 0, result follows since v(N ) = 2.remainder section prove hardness results non-emptiness problems.start showing adding constraints game causes complexity nonemptiness problem core raise one level polynomial hierarchyfromco-NP absence constraints (Malizia et al., 2007) P2 . Note proofbelow, integer auxiliary variables play role.Theorem 5.4. Core-NonEmptiness P2 -hard, even cohesive constrained gamespolynomial-time oracles, integer auxiliary variables allowed.Proof. Deciding whether quantified Boolean formula F = X1 , . . . , Xn Y1 , . . . , Yqvalid well-known P2 -complete problem (Johnson, 1990).Based F , build polynomial time game G(F ) = hN, vi, N = vars()vars() {a} where, set players S, v that:3 n = N,v(S) =nconsistent (S) 6|= ,0otherwise.addition, build polynomial time set LC that, 1 n, containsfollowing constraints:xXi + xXi = 1x Xi 0xXi 0LC =xa = 2 n,x RxXi Xixa RFirst, note LC forces xXi + xXi = 1, forces xa take value 2 n. Thus, sincev(N ) = 3 n, imputation x constrained game G(F )|LC distributeworth players associated variables {Y1 , . . . , Yq }. imputation xassociated assignment (x) variables {X1 , . . . , Xn } Xi true(x) xXi < 1note associating 1 false, here.understand salient features reduction, recall objection (y, S)imputation x VLC (S) yk > xk k S. Since y(S) > x(S)holds, take care coalitions N consistent (S)satisfying truth assignment. Recall VLC (S) = {x RS | x(S) v(S)} (LC)[S];665fiGreco, Malizia, Palopoli, & Scarcellothus, objection (y, S) Xi (resp., Xi S), yXi 1 (resp.,yXi 1). Therefore, cannot include players {X1 , X1 , ..., Xn , Xn } getting worth 1x. follows set possible objections (y, S) imputation x correspondssuperset truth assignments (S) satisfying extensions(x). correspondence allows us establish following result (whose formal proofdeferred Appendix).Claim B. C (G(F )|LC ) 6= F valid.conclude proof, notice G(F )|LC cohesive. Indeed, coalitionv(S) = n must consistent, thus |S (vars() vars())| = n + q. Therefore, giventhree coalitions S1 , S2 S3 v(S1 ) = v(S2 ) = v(S3 ) = n, must casetwo overlap players. follows partition N containstwo coalitions getting worth n.non-emptiness problems bargaining set trivial TU games, sinceconcept always non-empty there. longer case constrained games,problem turns quite difficult. proof Theorem 5.4, integerauxiliary variables play role result shown below.Theorem 5.5. BargainingSet-NonEmptiness P3 -hard,even cohesive constrainedgames polynomial-time oracles,and integer auxiliary variables allowed.Proof. Deciding validity formula P = X1 , . . . , Xm Y1 , . . . , Yn Z1 , . . . , Zqwell-known P3 -complete problem (Johnson, 1990).Based P , build polynomial time game G(P ) = hN, vi, N = vars()vars() {a, w} where, set players S, v that:+ 1 = N1w |S| = n + 1consistent w.r.t. {Y1 , . . . , Yn },v(S) =1= {Xi , Xi },1\ {a} consistent(S) |= ,0otherwise.also build polynomial time set LC that, 1 m, contains followingconstraints:xXi + xXi = 1x Xi 0xXi 0xa = 1xXi , xXi Rxa RFirst, observe that, constraints fact v(N ) =m+1, imputation game players Yj , 1 j n, players Zr , 1 r q,get payoff 0. Moreover, imputation x index i, 1 m,xXi > 0 xXi > 0 cannot belong bargaining set G(P )|LC , objection666fiMixed-Integer Constrained Coalitional Games1(y, {w, Y1 , ..., Yn }) player yYj = n+1justified. Indeed, (z, )counterobjection , would za xa = 1 (indeed, xa = 1 prescribedLC). Moreover, definition worth function, would\ {a} consistent, i.e., {1..., m}, |T {Xi , Xi }| = 1. Assume Xi(the line reasoning applies Xi ). Then, zXi xXi > 0 must holdwould z(T ) > 1, impossible since v(T ) 1 since v(T ) z(T ) holdscounterobjection. Thus, set imputations x might possibly belongbargaining set restricted variables xXi xXi take distinct valuesset {0, 1}. result, associate imputation x constrained gameG(P )|LC assignment (x) variables {X1 , . . . , Xm } Xi true(x) xXi = 0. Note associating 0 true here.fact, order show correctness reduction, may basically followspirit proof Theorem 5.4. imputation x (with properties illustratedabove), set possible objections (y, S) corresponds set possible truthassignments (Y \ S) variables = {Y1 , ..., Yn }. Objections mightpossibly justified restricted player a, counterobjectionscorrespond satisfying assignments extending (x) (Y \ S). Thus, followingshown, whose detailed proof reported Appendix.Claim C. B(G(P )|LC ) 6= P valid.Finally, note game cohesive. Indeed, consider partition playersN , coalition v(S) = 1. case consistentw.r.t. vars(), cannot exist coalition v(S ) = 1= {Xi , Xi } i. addition, exist one coalitionSPv(S ) = 1 (for |S | = n + 1, w , consistent w.r.t. {Y1 , . . . , Yn }).Thus, SS v(S) 2. Similarly,P coalitionconsistent w.r.t. vars(), SS v(S) + 1. Indeed, might contain coalitions{X1 , X1 }, . . . , {Xm , Xm }, plus one coalition consistent w.r.t. {Y1 , . . . , Yn }gets worth 1. particular, cannot contain two coalitions consistentw.r.t. {Y1 , . . . , Yn } v(S ) = v(S ) = 1, w contained both.5.3 Membership Resultscomplete picture complexity arising context constrained gamesproving membership results that, together proofs previous section, providecompleteness results reported Figure 2. particular, shall consider caseworth function v oracle computed deterministic polynomial timesize ||G|LC || constrained game, deferring discussionresults extended case v oracle computable non-deterministicpolynomial time Section 5.3.1.start analysis stating complexity checking whether vectorimputation.Lemma 5.6. Deciding whether vector imputation DP constrained games.particular, problem co-NP constrained games without auxiliary integervariables, P constrained games without integer variables.667fiGreco, Malizia, Palopoli, & ScarcelloProof. Let G = hN, vi TU game let LC set constraints. Let x vectorassigning payoff value player N . Recall x imputation X(G|LC )if: (1) x VLC (N ) = {x RN | x(N ) v(N )} (LC)[N ]; (2) x efficient; (3) xindividually rational.(1) Checking whether x(N ) v(N ) feasible polynomial time. Moreover, checkingwhether x (LC)[N ] feasible NP. Indeed, consider set linearinequalities LC derived LC replacing player variables values according x. Note LC mixed integer linear program defined variables(if any) real (LC) int(LC) \ {xi | N }, x (LC)[N ] LCsatisfiable. well-known results mixed integer linear programming (see, e.g.,Nemhauser & Wolsey, 1988), LC admits solution admits solutionrepresented polynomially many bits (in size LC ). Thus,problem solved first guessing NP vector x assigning valuevariable real (LC) int(LC) \ {xi | N }, subsequently checking whether xsatisfies constraints LC (which feasible polynomial time). course,int(LC) {xi | N }, LC linear program without integer variables.special case, satisfiability LC checked P (see, e.g., Papadimitriou &Steiglitz, 1998).(2) Recall x efficient x VLC (N ), player Nxi xi . Consider set linear inequalities LC derived LC adding|N | + 1 inequalities: x(N ) v(N ), xi > xi N . Then, x efficientLC satisfiable. latter task feasible co-NP, since LCmixed integer linear program whose satisfiability checked NPsee (1).special case int(LC) = , LC contain integer variables and, hence,(un)satisfiability checked polynomial time.(3) Recall x individually rational player N , xi max{ xi | xiVLC ({i}) }. Consider set linear inequalities LCderived LC addingtwo inequalities xi v({i}) xi > xi . individual rationality holdsLCsatisfiable, N . point (2) above, task feasibleco-NP general, polynomial time whenever int(LC) = .conclude deciding whether x imputation conjunctionproblem (1), feasible NP, problems (2) (3), feasibleco-NP. Thus, problem DP .case int(LC) {xi | N } holds, (1) feasible polynomial time and,hence, deciding whether x imputation co-NP.Finally, int(LC) = , problems (1), (2), (3) feasible polynomial time.Let us consider membership Core-Check. proof routinereported sake completeness only.Theorem 5.7. Core-Check DP . particular, co-NP constrainedgames without auxiliary integer variables.668fiMixed-Integer Constrained Coalitional GamesProof. Let x input vector game G|LC , G = hN, vi. checkx satisfies conditions core x indeed imputation.Concerning former task, recall complementary problem deciding whetherx core amounts finding coalition vector x VLC (S)xi > xi , S. Consider set linear inequalities LCS derived LC adding|S| + 1 inequalities x(S) v(S), xi > xi S. Then, x corecoalition LCS satisfiable. task therefore solved guessingNP coalition together vector x assigning value variable LCS ,subsequently checking x indeed satisfy constraints LCS . followsdeciding whether x satisfies conditions core feasible co-NP.Concerning task checking whether x imputation, use resultsLemma 5.6. Thus, general games, Core-Check solved conjunctionproblem co-NP problem DP . course, problem feasible DP .Moreover, int(LC) {xi | N } holds, Core-Check feasible co-NP.Deriving membership result BargainingSet-Check constrained games requires sophisticated line reasoning. start recalling that, TU games,shown BargainingSet-Check P2 (Greco et al., 2009b). fact,result established exploiting characterization bargaining sethold presence constraints. Below, exploiting completely differentproof technique, shall show that, surprisingly, presence constraintsalter computational properties problem.following proofs, recall given set LC linear (in)equalities nreal variables, set (LC) polyhedron Rn , whose faces given halfspacesassociated (in)equalities LC, whose vertices given intersection ninequalities LC, hence represented polynomially many bits sizeLC (see, e.g., Papadimitriou & Steiglitz, 1998; Nemhauser & Wolsey, 1988). boundedpolyhedron called polytope. Moreover, use following notation. Let Nset players let yS set variables {yk | k S}. denote LCyS copysystem mixed-integer linear inequalities LC every player variable xi ,S, renamed yi , every variable v LC renamed vyS .Lemma 5.8. Let G = hN, vi TU game, LC set constraints, ximputation G|LC belong B(G|LC ). Then, exists justified objectionx representable polynomially many bits./ S,Proof. Since x/ B(G|LC ), two players j, coalition jS-feasible vector (y, S) justified objection j x. LetLCi,j,S system consisting (in)equalities LCyS plus |S| + 1 inequalities:y(S) v(S) yk > xk , k S. Then, set (LCi,j,S )[yS ] consists S-feasiblevectors (y, S) objection j x.Let us consider possible candidate counterobjections. N j/ , let LCi,j,S,T system including (in)equalities LCyS LCzT , plusinequalities y(S) v(S), yk > xk , k S, z(T ) v(T ), zk yk , k S,zk xk , k \ S. Note (LCi,j,S,T )[yS ] contains vectors index setexists counterobjection , hence form (z, ),669fiGreco, Malizia, Palopoli, & ScarcelloFigure 3: Illustration Claim D, coalitions T1 , T2 , T3 .objection (y, S) j x. follows set vectors (y, S)justified objection j x set:[(LCi,j,S )[yS ] \(LCi,j,S,T )[yS ].|iT/ jTconclude proof claim following.i,j,S,T )[y ] contains point (i.e., justified obClaim D. (LCi,j,S )[yS ] \ |iT/ jT (LCjection x) represented polynomially many bits.prove claim, let us consider following geometrical arguments: Consider firstcase LCi,j,S LCi,j,S,T (for |/ j ST ) contain integer variables,i,j,S,T )[y ].let P maximal convex subset (LCi,j,S )[yS ] \ |iT/ jT (LCvertices P , points R , given intersection |S| (independent) halfspaces facets (LCi,j,S )[yS ] (LCi,j,S,T )[yS ], thusrepresented polynomially many bits. fact, P might containboundaries. Thus, vertices actually belongs P , result straightforwardly holds. hand, P possibly open segment endpoints b(representable polynomially many bits), middle point ym necessarily belongsP (since P convex) represented polynomially many bits. Finally,polytope P two vertices (as shown Figure 3), mustleast three vertices , b , c belong face P . Therefore,barycenter triangle vertices , b , c belongs P ,represented polynomially many bits, case , b , c .670fiMixed-Integer Constrained Coalitional Gamesconclude proof, observe integer variables LCi,j,S LCi,j,S,T (for|/ j ) easily preprocessed. Roughlythe technical detailsreported Appendix, since (LCi,j,S )[yS ] polytope construction LCi,j,Ssince, therefore, vertices represented polynomially many bits, integercomponents interest (basically falling within (LCi,j,S )[yS ]) representedpolynomially many bits, well. Thus, find point polynomially many bitsasked Claim D, iterate possible combinationsinteger valuesi,j,Si,j,S,T )[y ]and, step, evaluate expression (LC)[yS ] \ |iT/ jT (LCreplacing integer values combination values hand. course, resultingexpression involve integer variables, inequalities still representablepolynomially many bits, therefore line reasoning applies.Armed lemma, state complexity BargainingSet-Check.Theorem 5.9. BargainingSet-Check P2.Proof. show complementary problem deciding whether vector xbargaining set given constrained game G|LC P2 . start checking whetherx imputation DP (cf. Lemma 5.6)recall DP contained P2 .case, Lemma 5.8 guess non-deterministic polynomial time justified objectionx, is, coalition S, two players j/ S, vector (y, S)objection j x. Consider system LC (in)equalities obtainedLCi,j,S (recall definition proof Lemma 5.8) replacing player variablesassociated coalition respective values y. course, (y, S) objectionLC satisfiable. well-known results mixed integer linear programming(see, e.g., Nemhauser & Wolsey, 1988), LC admits solution admitssolution represented polynomially many bits. Therefore, withinnon-deterministic step, also guess assignment (call w ) variablesLC , check polynomial time w actually satisfies constraints (i.e.,actually objection).conclude algorithm solving BargainingSet-Check, checkcounterobjection (z, ) objection (y, S) j x. taskrequires co-NP oracle call. particular, oracle works checking complementarycondition NP. end, non-deterministic step, first guesses coalitionj/ . Consider system LC including (in)equalities LCzT , plusinequalities z(T ) v(T ), zk yk , k S, zk xk , k \ S. Then,counterobjection (z, ) (y, S) vector z LC satisfiable.case above, solution LC guaranteed exist representedpolynomially many bits, solution (call w ) guessed withinnon-deterministic step oracle. fact, check w actually satisfies LCtrivially feasible polynomial time.turn analyze non-emptiness problems. start non-emptinesscore, co-NP-complete problem TU games (Malizia et al., 2007).Constraints play role here, since shown Core-NonEmptiness P2hard (cf. Theorem 5.4). Below, confirm exact complexity problem.671fiGreco, Malizia, Palopoli, & ScarcelloTheorem 5.10. Core-NonEmptiness P2.Proof. Let us adopt notation used proof Lemma 5.8. Let Ncoalition, LCS set mixed-integer linear (in)equalities including (in)equalitiesLCxN LCyS , plus inequalities y(S) v(S) yi > xi , S. get:[C (G|LC ) = X(G|LC ) \(LCS )[xN ].SNLet LCX set (in)equalities LCxN plus inequality x(N ) v(N ). Moreover,player i, let LCi set (in)equalities LCxN LCy , plus inequalities{i}x(N ) v(N ) xi < yi v({i}). Then, set (LCi )[xN ] consists vectorsindividually rational (w.r.t. player i). Thus,C (G|LC ) =X(LC )[xN ] \[!(LC )[xN ]\[(LCS )[xN ].SNparticular, note efficiency condition imputations guaranteed. Indeed,points efficient removed, belong set (LCN )[xN ],considered = N .applying line reasoning Claim (in Lemma 5.8)expressions, that, C (G|LC ) empty, contains imputationrepresentable polynomially many bits. Thus, decide non-emptinesscore first guessing NP vector x. Then, may call DP oracle (correspondinginvocation NP co-NP oracle) check x imputation (cf.Lemma 5.6), finally verify x core call co-NPoracle. particular, latter oracle works checking complementary conditionNP, i.e., checks whether x core. end, oracle guesses nondeterministic step coalition S. Consider system LC formed (in)equalitiesLCyS plus |S| + 1 inequalities: y(S) v(S) yk > xk , k S. Then,objection (y, S) x vector LC satisfiable. Again, LC admitssolution admits solution represented polynomially manybits. Therefore, within non-deterministic step, also guess assignment(call w ) variables LC , check polynomial time w actuallysatisfies constraints.Now, complete picture bargaining set.Theorem 5.11. BargainingSet-NonEmptiness P3.Proof. Consider setting proof Lemma 5.8. Let j two playersN . coalition j 6 S, let LCi,j,S system consisting(in)equalities LCxN LCyS plus |S| + 1 inequalities: y(S) v(S) yk > xk ,k S. Moreover, pair sets players \ j \ S,let LCi,j,S,T system mixed integer inequalities including inequalitiessystems LCxN , LCyS , LCzT , plus inequalities y(S) v(S), yk > xk k S,672fiMixed-Integer Constrained Coalitional Gamesz(T ) v(T ), zk yk k S, zk xk k \ S. is,proceed way proof Lemma 5.8, components vectorx variables linear program, previous lemma fixed values.Observe (LCi,j,S,T )[xN yS ] contains pairs hx, yi existscounterobjection (z, ) objection (y, S) j x, (LCi,j,S )[xN yS ]consists pairs hx, yi S-feasible vector j 6(y, S) objection x. Then, set[(i, j, S) = (LCi,j,S )[xN yS ] \(LCi,j,S,T )[xN yS ]|iT/ jTset pairs hx, yi (y, S) justified objection j x.Therefore,[B(G|LC ) = X(G|LC ) \(i, j, S)[xN ],SN iSj/where, considering efficiency individual rationality (see notation proofTheorem 5.10),[(LCi )[xN ].X(G|LC ) = (LCX )[xN ] \ (LCN )[xN ] \slightly adapting proof Claim (in Lemma 5.8), one may showbargaining set empty, exists vector x B(G|LC ) representedpolynomially many bits. Therefore, BargainingSet-NonEmptiness solvedfirst guessing non-deterministic polynomial time vector x. Then, may callDP oracle check x imputation (cf. Lemma 5.6), finally verifyx indeed bargaining set call P2 oracle, order solveBargainingSet-Check input x (cf. Theorem 5.9).5.3.1 Extension General Worth Functionsmembership results above, assumed worth functions polynomial-time computable and, within setting, shown various hardness resultsindeed tight. Thus, reader might inclined believe that, consideringpowerful worth functions, complexity problems may consistently increase. Surprisingly, case. Indeed, show nothing paidpowerful worth functions encode NP-complete problems considered.end, let vG|LC denote worth function game G|LC , define worthfunction graph class C constrained games set tuples WC = {h(G|LC , S), wi |G|LC C vG|LC (S) = w}. Recall, e.g., work Johnson (1990),function computable non-deterministic polynomial time integer kWC (i) k-balanced, i.e., ||w|| (||G|LC || + ||S||)k , (ii) k-decidable, i.e.,non-deterministic Turing machine decides whether given tuple belongs WCO(||t||k ) time. precisely, since vG|LC partial (standard) single-valued function(multi-valued functions also considered literature), class functionsconsider called NPSV (see, e.g., Selman, 1994).673fiGreco, Malizia, Palopoli, & Scarcellocomplexity various solution concepts TU games within setting worthfunctions given oracles computable NPSV analyzed extendedversion work Greco et al. (2009b). There, emerged membershipresults Figure 2 hold class C games worth functions. roughly,basic observation consider NPSV worth-functions, non-deterministicalgorithm guesses polynomial-time coalition game G|LC C,time (with polynomial-time delay) guess worth w additionalstring c (of polynomial size w.r.t. ||G|LC || + ||S||), acts certificate decidewhether tuple h(G|LC , S), wi belongs NP set WC . Thus, complexity(non-deterministic) algorithm uses value vG|LC (S) guess coalitionaffected replacing polynomial-time worth-functions NPSV worth-functions.exploiting line reasoning, easy adapt proofs membership results orderdeal general worth functions.Theorem 5.12. membership results Figure 2 hold class C games whoseworth functions NPSV.6. Discussion ConclusionImposing linear constraints outcomes games approach exploredseveral authors context non-cooperative strategic games (e.g., Charnes, 1953;Semple, 1997; Ryan, 1998). However, context cooperative games approachreceived considerably less attention and, indeed, general framework proposedliterature analysis properties conducted far.paper, faced issue conducting systematic study constrainedgames within framework constraints defined mixed-integer linear (in)equalities imposed underlying TU game. Seemingly close class constrainedgames class linear programming games (see, e.g., Owen, 1975), worthv(S) coalition implicitly given linear program (e.g., maximumgiven objective function feasible region (LC) defined terms set linear(in)equalities LC). course, approach differs setting constrained gamesrole LC is, instead, govern distribution worths within NTUperspective. Moreover, differently classical NTU formalizations, constrained gamesallow define non-convex non-comprehensive sets worth distributions,appealing modeling capability emerged useful several application domains.Finally, resulting game framework analyzed respect preservationcomputational properties relevant solution concepts.worthwhile noticing framework discussed paper sharesspirit recent arguments Shoham (2008), advocated use broader vocabulary fairly terse one characterizing early foundations game theory. Alsorelevant proposals reconsidered basic concepts cooperative gameslight modeling perspective closer requirements computer science applications: seminal influential directions type give rise, particular, coalitionalskill games (Bachrach & Rosenschein, 2008), qualitative coalitional games (Wooldridge &Dunne, 2004), coalitional resource games (Wooldridge & Dunne, 2006), Bayesian coalitionalgames (Ieong & Shoham, 2008), multi-attribute coalitional games (Ieong & Shoham, 2006),674fiMixed-Integer Constrained Coalitional Gamestemporal qualitative coalitional games (Agotnes, van der Hoek, & Wooldridge, 2006),cooperative Boolean games (Dunne, van der Hoek, Kraus, & Wooldridge, 2008).light approaches, interesting avenue research may considerexpressive kinds constraints, formulated instance via logic-based languages,preference criteria adopted place hard constraints.avenues research related technical questions exploredpaper. First, complexity analysis focused notions corebargaining set, founded concepts objections counterobjections.course, would interesting complement results analysis kernel,nucleolus, Shapely value. Actually, hardness results kernel nucleolusTU (graphical) games recently illustrated Greco et al. (2009b), indeedtrivially provide lower bounds complexity solution conceptssetting constrained games. However, providing tighter computational bounds requiresdeeper understanding computational aspects underlying Kalais axiomatization,outside scope paper. Furthermore, Shapley value, intereststudy extensions provided literature NTU gamesassess behavior applied constrained games.Moreover, hardness results shown hold even restricting underlying TU games use cohesive worth functions only. might interest studycomplexity different specific kinds functions considered (for instance, monotone,superadditive, weakly superadditive, convex ones6 ). Similarly, assessing extentconsidering specific kinds worth functions affects analytical properties studiedSection 4 interesting question leave research.Finally, modeling viewpoint, recall framework proposed paperexploits one set linear (in)equalities constrain outcomes coalitions. Thus,light adding modeling power framework, might interest study natural generalization coalition equipped specific set linear (in)equalities.particular, setting would call conceiving suitable mechanisms compactly represent (exponentially many) different sets constraints, defining formal measuresexpressivity compact representations constraint-based NTU games.Acknowledgmentscoalitional game framework dealing linear constraints imposed TU gamesfirst illustrated authors extended abstract published proceedings8th International Conference Autonomous Agents Multiagent Systems (Greco,Malizia, Palopoli, & Scarcello, 2009a). There, solution concepts definedstudied, based proposing ad-hoc adaptations solution conceptsTU games. Following suggestions anonymous referees, constrained gameframework proposed present paper fits instead framework NTU games,general form. Thus, solution concepts studied paper givensuitable specializations standard solution concepts defined NTU games.6. worth function v : 2N 7 R monotone v(S) v(T ) holds, pair coalitions S, N; v superadditive v(S ) v(S) + v(T ) holds, pair coalitions S, N= ; v weakly superadditive v(S {i}) v(S) + v({i}), N N \ S; vconvex v(S ) + v(S ) v(S) + v(T ), S, N (see, e.g., Peleg & Sudholter, 2007).675fiGreco, Malizia, Palopoli, & ScarcelloAppendix A. Computational Complexityappendix recall basic definitions complexity theory, referringreader work Johnson (1990) topic.A.1 Complexity Decision Problems: P, NP, co-NPDecision problems maps strings (encoding input instance fixed alphabet,e.g., binary alphabet {0, 1}) set {yes, no}. class P set decisionproblems solved deterministic Turing machine polynomial timerespect input size, is, respect length string encodesinput instance. given input x, size usually denoted ||x||.Throughout paper, often refer computations carried non-deterministicTuring machines, too. Recall Turing machines that, pointscomputation, may one single next action perform, choice severalpossible next actions. non-deterministic Turing machine answers decision problemgiven input x: (i ) least one sequence choices leading haltaccepting state x yes instance; (ii ) possible sequences choices leadrejecting state x instance.class decision problems solved non-deterministic Turing machinespolynomial time denoted NP. Problems NP enjoy remarkable property:yes instance x certificate yes instance, polynomial lengthchecked polynomial time (in size ||x||). example, problemdeciding whether Boolean formula variables X1 , . . . , Xn satisfiable, i.e.,deciding whether exists truth assignment variables making true,well-known problem NP; fact, satisfying truth assignment obviouslycertificate yes instance, i.e., satisfiable.class problems whose complementary problems NP denoted co-NP.example, problem deciding whether Boolean formula satisfiableco-NP. course, class P contained NP co-NP.class DP class problems defined conjunction twoproblems, one NP one co-NP, respectively. instance, DPdecide whether, given pair Boolean formulae (, ), satisfiable not.A.2 Complexity Classes: Polynomial HierarchyThroughout paper, also refer particular type computation called computationoracles. Intuitively, oracles subroutines unary cost.PPclasses Pk , k , k , forming polynomial hierarchy, defined follows:PPPPk1 , P = Pk1 , P = co-PP0 = 0 = P k 1, k = NPkkkco-PdenotesclassproblemswhosecomplementaryproblemsolvablePkk.PPHere, k (resp., k ) models computability non-deterministic (resp., deterministic)Ppolynomial-time Turing machine may use oracle Pk1 . Note 1 coincidesNP, P1 coincides co-NP.well-known problem k-th level polynomial hierarchy decidingvalidity quantified Boolean formula k quantifier alternations. quantified Boolean676fiMixed-Integer Constrained Coalitional Gamesformula (short: QBF) k quantifier alternations form Q1 X1 Q2 X2 ...Qk Xk ,k 1, Xi (1 k) set variables, Qi {, } (1Sk k), Qi 6= Qi+1(1 < k), Boolean formula variables i=1 Xi . setquantified Boolean formulae k quantifier alternations Q1 = (resp., Q1 = )denoted QBFk, (resp., QBFk, ). Deciding validity quantified Boolean formulaPQBFk, (resp., QBFk, ) well-known problem Pk (resp., k ). Notek = 1, problem coincides problem deciding whether Boolean formulasatisfiable (resp., satisfiable), indeed NP (resp., co-NP).A.3 Reductions Among Decision Problemsdecision problem A1 polynomially reducible decision problem A2 , denotedA1 p A2 , polynomial time computable function h that, every x, h(x)defined x yes instance A1 h(x) yes instance A2 .decision problem complete class C polynomial hierarchy (beyond P)belongs C every problem C polynomially reducible A. Thus, problemscomplete class C difficult problems C.worthwhile observing problems discussed section knowncomplete classes membership pointed out. particular,deciding validity QBFk, (resp., QBFk, ) formula prototypical Pk -complete(resp., P-complete)problem.kAppendix B. Proofs Section 3Proposition 3.2 Let G = hN, vi TU game let X X(G) arbitrary finiteset imputations. Then, finite set constraints LC X(G|LC ) = X .Proof. Consider game G = hN, vi, set X = {x1 , . . . , xk } imputations G,set constraints:xi = x1i 1 + + xki k , 1 |N |0 yj 1, 1 j kLC =y1 + + yk = 1x , . . . , xn R11, . . . , yk Zx1i , . . . , xki (for 1 |N |) constants.immediate check VLC (N ) = X . Moreover, observe vectorxj VLC (N ) (1 j k) efficient, since cannot dominated vectorX (just notice X set imputations G). Finally, notice imputationx X individually rational w.r.t. G. Thus, Proposition 3.7, x individually rationalw.r.t. constrained game too. follows VLC (N ) = X(G|LC ).Proposition 3.3 exists class C = {G|nLC }n>0 constrained gamesgame G|nLC n + 1 players, LC consists 2 n + 1 inequalities, |X(G|LC )| = 2n .677fiGreco, Malizia, Palopoli, & ScarcelloProof. Consider class C = {G|nLC }n>0 game G n = hN, vi N ={1, . . . , n, n + 1}, v(N ) = n, v(S)Pn= 0, coalition N , LC = {0n xi n1, xiZ, 1 n} {xn+1 n i=1 xi }. easily checked |X(G|LC )| = 2 .Proposition 3.7 Let G = hN, vi TU game let x payoff vector individually rational w.r.t. G (i.e., xi v({i}), player N ). Then, set LCconstraints, x individually rational w.r.t. constrained game G|LC .Proof. Let x payoff vector xi v({i}), player N . Considerconstrained game G|LC player N . VLC ({i}) = Vv ({i}) (LC)[{i}] = ,trivially xi > . Otherwise, i.e., VLC ({i}) 6= , noticemax{ yi | yi VLC ({i}) } v({i}). Thus, xi max{ yi | yi VLC ({i}) }.Appendix C. Proofs Claims Section 5Claim A. x B(G(H)) H valid.Proof. Let us study structure possible objection x. Recall (y, S)objection player player j x if: S, j/ S, y(S) v(S)yk > xk , k S. Thus, observe v(S) = 1 must hold, order improvepayoffs members, worth value equal 2 obtainedgrand-coalition. addition, since xa = xa = 1 since y(S) v(S) = 1, must alsocase {a, } = , players get 1 current imputation x. Duedefinition worth function, entails consistent variables Y,i.e., set n players corresponding literals universally quantified variables.thus associate possible objection (y, S) x (where y(S) 1 yk > 0,k S) truth-value assignment variables that, 1 n, Yi assignedfalse Yi (and true Yi S). According notation, meansobjection associated truth-value assignment (Y \ S). defineconverse, well. truth-value assignment universally quantified variables,associated objection pair (y, S) = {Yk | (Yk ) = false} {Yk |1Yk Y, (Yk ) = true}, yp = |S|, p S. Note (y, S) objectionplayer player x, (Y \ S) = .Indeed, (y, S) objection player j/ {a, }, (z, {j}) zj = 0trivial counterobjection, since v({j}) = xj = 0 j/ S. follows setobjections possibly justified restricted player player. Next, consider case objection a, exactly argumentshold objections . Let (y, S) objection player x.counterobjection (z, ) must (and/ ). Thus, orderza xa = 1, must case v(T ) 1 and, actually, v(T ) = 1, duedefinition worth function. particular, latter (with fact za = 1) entailsthat, player p 6= p , holds zp = 0. Thus, must empty,members get something according y, \{a} consistent, (T ) |= .particular, since = , according satisfying assignment, Yi true (T )Yi/ S. follows (T ) coincides (Y \ S) universallyquantified variables, thus fact extension truth-value assignment678fiMixed-Integer Constrained Coalitional Gamesset variables occurring formula . Conversely, note every satisfyingassignment extends (Y \ S) corresponds counterobjection (y, S).Given observations, show claim: x B(G(H)) H valid.() Assume x B(G(H)). Let truth-value assignment universallyquantified variables, let (y, S) objection x associated .particular, (Y \ S) = , construction. Since x B(G(H)), exists validcounterobjection (z, ) (y, S), seen corresponding truthvalue assignment (T ) extension (Y \ S) set variables vars(),(T ) |= . follows H valid.() Assume x/ B(G(H)). Then, justified objection (y, S) (or) x. follows discussion truth-value assignmentable extend assignment (Y \ S) variables vars(),satisfy . Indeed, extension would associated counterobjection(y, S). follows H valid.Claim B. C (G(F )|LC ) 6= F valid.Proof.() Assume x C (G(F )|LC ), i.e., N , S-feasible payoff vectoryi > xi S. claim (x) truth assignmentvariables {X1 , . . . , Xn } witnessing validity F . Indeed, assume, sakecontradiction, truth assignment variables {Y1 , . . . , Yq }(x) 6|= . Consider coalition consistent(S) = (x) . definition worth function, v(S) = n. Moreover, observex(S) < n holds, definition assignment (x) given xYj = 0xYj = 0, imputation x variable Yj (1 j q). Note, fact,Xi Xi true (x) xXi < 1, Xi Xi falseminiS (1xi )(x) xXi = 0 (because case xXi = 1 holds). Now, let =n+qnotice > 0, since xi < 1 is, particular, prescribed definition(x). Consider vector RS yi = xi + S. Notey(S) n |S| = n + q; moreover, VLC (S) holds v(S) = nconstraints satisfied (just notice contains exactly one player{Xi , Xi }, variable Xi , associated payoff less equal1 constraints xXi + xXi = 1 play roleone player Xi Xi hence given variable yXi (resp., yXi ) yXi 1(resp., yXi 1) always exists non negative value yXi (resp., yXi )yXi + yXi = 1). Since yi > xi , S, conclude x/ C (G(F )|LC ),impossible.() Assume truth assignment variables {X1 , . . . , Xn } witnessingvalidity F , let x imputation (x) coincides ,particular xXi = 1 (resp., xXi = 0) Xi false (resp., true) . claimx C (G(F )|LC ). Indeed, assume sake contradiction,coalition S-feasible payoff vector yi > xi S. Since679fiGreco, Malizia, Palopoli, & Scarcellov(S) y(S) > x(S) since x(S) 0, given definition worth function,actually case consistent (and, thus, (S) truth assignment)(S) satisfying. particular, recall VLC (S) = {x RS | x(S)v(S)} (LC)[S]; thus, player Xi (resp., Xi S), yXi 1 (resp.,yXi 1). Therefore, cannot include player {X1 , X1 , ..., Xn , Xn } gettingworth 1 x. follows (S) extension (x), moreoversatisfying. Thus, (x) would witness validity F , impossible.Claim C. B(G(P )|LC ) 6= P valid.Proof. Consider imputation x xa = 1, xXi xXi take distinct valuesset {0, 1}, variable Xi {X1 , ..., Xm }. objection (y, S) x mustv(S) = 1 (which indeed maximum available worth coalitionN ) player xi = 1. follows objections necessarilyform (y, S) w S, |S| = n+1, consistent w.r.t. {Y1 , . . . , Yn }. words,objection (y, S) x contains w plus one universal player per universallyquantified variable, thus uniquely associated truth-value assignmentuniversally quantified variables = {Y1 , . . . , Yn }. Let (Y \ S) denote assignment,set Yj = true Yj/ S, 1 j n. define also converse:given truth value assignment universally quantified variables, associatedobjection pair (y, S) = {Yj | (Yj ) = false}{Yj | (Yj ) = true}{w},1, every k S.yk = |S|Now, (y, S) objection player j/ {a, X1 , . . . , Xm , X1 , . . . , Xm },(z, {j}) zj = 0 trivial counterobjection. Indeed, player j belongmay either element {Y1 , . . . , Yn } element {Z1 , . . . , Zq }. eithercases, v({j}) = xj = 0. hand, (y, S) objection player Xi (or,Xi ), (z, {Xi , Xi }) zXi = xXi zXi = xXi counterobjection,v({Xi , Xi }) = z({Xi , Xi }) = 1 {Xi , Xi } = . follows set objectionspossibly justified restricted objections player a. Let (y, S)objection player x. counterobjection (z, ) must. Thus, order za xa = 1, must case v(T ) 1 and, actually,v(T ) = 1, due definition worth function. particular, latter entailsplayer p 6= p , holds zp = 0. Thus, must emptyand, particular, possibility \ {a} consistent, (T ) |= . Finally,since = x(p) = 0 p p 6= a, (T ) satisfyingassignment where: Xi true (T ) Xi true (x); Yi true(T ) Yi/ S, thus Yi true (Y \ S). is, (T ) completeassignment extends partial assignments (x) (Y \ S).exploiting observations, prove claim.() Assume exists x B(G(P )|LC ). seen imputation xassociated truth-value assignment (x) variables {X1 , . . . , Xm }recall imputation x index i, 1 m, xXi > 0xXi > 0 cannot belong bargaining set G(P )|LC . Moreover, seenevery assignment universally quantified variables corresponds680fiMixed-Integer Constrained Coalitional Gamespossible objection (y, S) x, since x belongs bargaining set mustexist valid counterobjection (z, ) (y, S) associated satisfying truth-valueassignment extends partial assignments (x) . meansx witness validity P .() P valid assignment X variables {X1 , . . . , Xm }witnesses validity. Consider imputation x that, 1 m, xXi = 0xXi = 1 X (Xi ) = true, xXi = 1 xXi = 0 otherwise. Moreover,xa = 1 players get 0. Since, every extension X universallyquantified variables (corresponding possible objection (y, S) x), existsextension variables satisfies (corresponding counterobjection(y, S)), follows x B(G(P )|LC ).i,j,S,T )[y ] contains point (i.e., justified obClaim D. (LCi,j,S )[yS ] \ |iT/ jT (LCjection x) represented polynomially many bits.Proof. case (LCi,j,S )[yS ] (LCi,j,S,T )[yS ] (for |/ j )contain integer variables already addressed proof Lemma 5.8. nextshow preprocess integer variables, occur programs hand.Recall first (LCi,j,S )[yS ] bounded, since LCi,j,S contains |S| + 1 inequalities:y(S) v(S) yk > xk , k S. implies assume, w.l.o.g., (LCi,j,S )bounded turn. Indeed, standard arguments linear programming followspoint (LCi,j,S )[yS ] obtained projection point (LCi,j,S ) whoseauxiliary components (i.e., associated variables yS ) boundedpolynomial size LCi,j,S . Thus, bound made explicit definitionLCi,j,S , without altering projection (LCi,j,S )[yS ].Second, observe also assume, w.l.o.g, (LCi,j,S,T ) bounded too,/ j . Indeed, definition LCi,j,S,T , may constrainvariable yS range within minimum maximum values may assume(LCi,j,S )[yS ]note extreme values represented polynomially manybits, since achievedvertices (LCi,j,S )[yS ]. modificationi,j,Si,j,S,T )[y ]. Thus, (LCi,j,S,T )[y ] bounded,alter set (LC)[yS ] \ |iT/ jT (LC(LCi,j,S,T ) assumed bounded, toosee above.resume main proof show integer variables easily prefC denoteprocessed. Let LC program {LCi,j,S } {LCi,j,S,T |/ j }, let LfC) representedlinear relaxation LC, recall vertex polytope (Lfpolynomially many bits. Since (LC) contained (LC), values components vertices bounds every integer component vector (LC),thus represented polynomially many bits. Let U set admissiblevalues integer components. Let I(LC) denote set possible assignments values integer variables LC U , assignment z I(LC),let LChzi denote linear program integer variable int(LC) replacedcorresponding value z. Now, pair assignments z w belonging I(LCi,j,S )I(LCi,j,S,T ), respectively, let us say w matches z (w.r.t. yS ) z wcoincide restrictions yS int(LCi,j,S )int(LCi,j,S,T ).Furthermore, let Wi,j,S,T )).set non-integer variables yS , is, yS \ (int(LCi,j,S ) |iT/ jT int(LC681fiGreco, Malizia, Palopoli, & Scarcelloi,j,S,T )[y ] contains pointThen, set (LCi,j,S )[yS ] \ |iT/ jT (LCrepresented polynomially many bits (resp., empty) elementz I(LCi,j,S ) (resp., element z I(LCi,j,S )):[[(LCi,j,S hzi)[W] \(LCi,j,S,T hwi)[W]|iT/ jTwI(LCi,j,S,T ) | w matches zcontains element represented polynomially many bits (resp., empty).Note expression form original one, integervariable occurs it. conclude, observe LCi,j,S hzi LCi,j,S,T hwi (T |/j ) represented polynomially many bits (w.r.t. size originalmixed-integer linear programs), since obtained mapping integer variablesvalues representable polynomially many bits.ReferencesAgotnes, T., van der Hoek, W., & Wooldridge, M. (2006). Temporal qualitative coalitionalgames. Nakashima, H., Wellman, M. P., Weiss, G., & Stone, P. (Eds.), Proceedings5th International Conference Autonomous Agents Multiagent Systems(AAMAS 2006), pp. 177184, Hakodate, Japan.Aumann, R. J. (1961). core cooperative game without side payments. TransactionsAmerican Mathematical Society, 98, 539552.Aumann, R. J. (1985). axiomatization non-transferable utility value. Econometrica, 53 (3), 599612.Aumann, R. J., & Dreze, J. H. (1974). Cooperative games coalition structures. International Journal Game Theory, 3 (4), 217237.Aumann, R. J., & Hart, S. (Eds.). (1992, 1994, 2002). Handbook Game TheoryEconomic Applications, Volume 1,2 3, Vol. 11 Handbooks Economics.North-Holland, Amsterdam, Netherlands.Aumann, R. J., & Maschler, M. (1964). bargaining set cooperative games.Advances Game Theory, pp. 443476. Princeton University Press, Princeton, NJ,USA.Aumann, R. J., & Peleg, B. (1960). Von Neumann-Morgenstern solutions cooperativegames without side payments. Bulletin American Mathematical Society, 66 (3),173179.Bachrach, Y., & Rosenschein, J. S. (2008). Coalitional skill games. Padgham, L., Parkes,D. C., Muller, J., & Parsons, S. (Eds.), Proceedings 7th International Conference Autonomous Agents Multiagent Systems (AAMAS 2008), pp. 10231030,Estoril, Portugal.Bilbao, J. M. (2000). Cooperative Games Combinatorial Structures, Vol. 26 TheoryDecision Library C. Kluwer Academinc Publishers, Reading, MA, USA.Byford, M. C. (2007). constrained coalitional approach price formation. NorthAmerican Summer Meetings Econometric Society, Durham, NC, USA.682fiMixed-Integer Constrained Coalitional GamesCharnes, A. (1953). Constrained games linear programming. Proceedings NationalAcademy Sciences United States America, 39 (7), 639641.Conitzer, V., & Sandholm, T. (2004). Computing shapley values, manipulating value division schemes, checking core membership multi-issue domains. McGuinness,D. L., & Ferguson, G. (Eds.), Proceedings 19th National Conference ArtificialIntelligence (AAAI-04), pp. 219225, San Jose, CA, USA.Davis, M., & Maschler, M. (1965). kernel cooperative game.. Naval ResearchLogistics Quarterly, 12, 223259.Deng, X., & Papadimitriou, C. H. (1994). complexity cooperative solution concepts. Mathematics Operations Research, 19 (2), 257266.Dunne, P. E., van der Hoek, W., Kraus, S., & Wooldridge, M. (2008). Cooperative booleangames. Padgham, L., Parkes, D. C., Muller, J., & Parsons, S. (Eds.), Proceedings7th International Conference Autonomous Agents Multiagent Systems(AAMAS 2008), pp. 10151022, Estoril, Portugal.Edgeworth, F. Y. (1881). Mathematical Psychics: essay mathematics moralsciences. C. Kegan Paul & Co., London.Elkind, E., Goldberg, L. A., Goldberg, P. W., & Wooldridge, M. (2009). computational complexity weighted voting games. Annals Mathematics ArtificialIntelligence, 56 (2), 109131.Elkind, E., & Pasechnik, D. (2009). Computing nucleolus weighted voting games.Mathieu, C. (Ed.), Proceedings 20th Annual ACM-SIAM SymposiumDiscrete Algorithms (SODA09), pp. 327335, New York, NY, USA.Gillies, D. B. (1959). Solutions general non-zero-sum games. Tucker, A. W., & Luce,R. D. (Eds.), Contributions Theory Games, Volume IV, Vol. 40 AnnalsMathematics Studies, pp. 4785. Princeton University Press, Princeton, NJ, USA.Greco, G., Malizia, E., Palopoli, L., & Scarcello, F. (2009a). Constrained coalitional games:formal framework, properties, complexity results (extended abstract). Sierra,C., Castelfranchi, C., Decker, K. S., & Sichman, J. S. (Eds.), Proceedings8th International Conference Autonomous Agents Multiagent Systems (AAMAS 2009), pp. 12951296, Budapest, Hungary.Greco, G., Malizia, E., Palopoli, L., & Scarcello, F. (2009b). complexity compact coalitional games. Boutilier, C. (Ed.), Proceedings 21th International Joint Conference Artificial Intelligence (IJCAI-09), pp. 147152, Pasadena,CA, USA. extended version available technical report arXiv:0810.3136(http://arxiv.org/abs/0810.3136).Hart, S. (2004). comparison non-transferable utility values. Theory Decision,56 (12), 3546.Ieong, S., & Shoham, Y. (2005). Marginal contribution nets: compact representationscheme coalitional games. Riedl, J., Kearns, M. J., & Reiter, M. K. (Eds.), Proceedings 6th ACM Conference Electronic Commerce (EC05), pp. 193202,Vancouver, BC, Canada.683fiGreco, Malizia, Palopoli, & ScarcelloIeong, S., & Shoham, Y. (2006). Multi-attribute coalitional games. Feigenbaum, J.,Chuang, J., & Pennock, D. M. (Eds.), Proceedings 7th ACM ConferenceElectronic Commerce (EC06), pp. 170179, Ann Arbor, MI, USA.Ieong, S., & Shoham, Y. (2008). Bayesian coalitional games. Fox, D., & Gomes, C. P.(Eds.), Proceedings 23rd National Conference Artificial Intelligence (AAAI08), pp. 95100, Chicago, IL, USA.Jiang, T., & Baras, J. S. (2007). Fundamental tradeoffs constrained coalitional gamesautonomic wireless networks. Proceedings 5th International SymposiumModeling Optimization Mobile, Ad Hoc, Wireless Networks (WiOpt07),pp. 18, Limassol, Cyprus.Johnson, D. S. (1990). catalog complexity classes. van Leeuwen, J. (Ed.), HandbookTheoretical Computer Science, Volume A: Algorithms Complexity, pp. 67161.MIT Press, Cambridge, MA, USA.Kalai, E. (1975). Excess functions cooperative games without sidepayments. SIAMJournal Applied Mathematics, 29 (1), 6071.Malizia, E., Palopoli, L., & Scarcello, F. (2007). Infeasibility certificates complexitycore coalitional games. Veloso, M. M. (Ed.), Proceedings 20thInternational Joint Conference Artificial Intelligence (IJCAI-07), pp. 14021407,Hyderabad, India.Maschler, M. (1992). bargaining set, kernel, nucleolus. Aumann, R. J., & Hart,S. (Eds.), Handbook Game Theory, Volume 1, Vol. 11 Handbooks Economics,chap. 18. North-Holland, Amsterdam, Netherlands.McLean, R. P. (2002). Values non-transferable utility games. Aumann, R. J., & Hart,S. (Eds.), Handbook Game Theory, Volume 3, Vol. 11 Handbooks Economics,chap. 55. North-Holland, Amsterdam, Netherlands.Nemhauser, G. L., & Wolsey, L. A. (1988). Integer combinatorial optimization. WileyInterscience Series Discrete Mathematics Optimization. Wiley-Interscience,New York, NY, USA.Orshan, G., & Zarzuelo, J. M. (2000). bilateral consistent prekernel ntu games.Games Economic Behavior, 32 (1), 6784.Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press,Cambridge, MA, USA.Owen, G. (1975). core linear production games. Mathematical Programming,9 (1), 358370.Papadimitriou, C., & Steiglitz, K. (1998). Combinatorial Optimization: AlgorithmsComplexity (2nd edition). Dover Publications.Peleg, B. (1963). Bargaining sets cooperative games without side payments. Israel JournalMathematics, 1 (4), 197200.Peleg, B., & Sudholter, P. (2007). Introduction Theory Cooperative Games (2ndedition). Theory Decision Library. Springer, Berlin, Germany.684fiMixed-Integer Constrained Coalitional GamesRahwan, T., Ramchurn, S. D., Jennings, N. R., & Giovannucci, A. (2009). Anytime algorithm optimal coalition structure generation. Journal Artificial IntelligenceResearch, 34, 521567.Ryan, M. J. (1998). Constrained games, intervening duality experimenter-experimentinteractions. European Journal Operational Research, 110 (2), 326341.Schmeidler, D. (1969). nucleolus characteristic function game. SIAM JournalApplied Mathematics, 17 (6), 11631170.Selman, A. L. (1994). taxonomy complexity classes functions. Journal ComputerSystem Sciences, 48 (2), 357381.Semple, J. (1997). Constrained games evaluating organizational performance. EuropeanJournal Operational Research, 96 (1), 103112.Serrano, R. (1997). Reinterpreting kernel. Journal Economic Theory, 77 (1), 5880.Shapley, L. S. (1953). value n-person games. Kuhn, H. W., & Tucker, A. W. (Eds.),Contributions Theory Games, Volume II, Vol. 28 Annals MathematicsStudies, pp. 307317. Princeton University Press, Princeton, NJ, USA.Shapley, L. S. (1969). Utility comparison theory games. La Decision, pp.251263. Editions du Centre National de le Recherche Scientifique, Paris.Shoham, Y. (2008). Computer science game theory. Communications ACM,51 (8), 7479.Simon, H. A. (1972). Theories bounded rationality. McGuire, C. B., & Radner, R.(Eds.), Decision Organization, Vol. 12 Studies Mathematical ManagerialEconomics, pp. 161176. North-Holland, Amsterdam, Netherlands.von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior(1st edition). Princeton University Press, Princeton, NJ, USA.Weber, R. J. (1994). Games coalitional form. Aumann, R. J., & Hart, S. (Eds.),Handbook Game Theory, Volume 2, Vol. 11 Handbooks Economics, chap. 36.North-Holland, Amsterdam, Netherlands.Winter, E. (2002). shapley value. Aumann, R. J., & Hart, S. (Eds.), HandbookGame Theory, Volume 3, Vol. 11 Handbooks Economics, chap. 53. North-Holland,Amsterdam, Netherlands.Wooldridge, M., & Dunne, P. E. (2004). computational complexity qualitativecoalitional games. Artificial Intelligence, 158 (1), 2773.Wooldridge, M., & Dunne, P. E. (2006). computational complexity coalitionalresource games. Artificial Intelligence, 170 (10), 835871.685fiJournal Articial Intelligence Research 38 (2010) 339-369Submitted 11/09; published 07/10Mixed Strategies Combinatorial AgencyMoshe Babaiomoshe@microsoft.comMicrosoft Research - Silicon ValleyMountain View, CA 94043 USAMichal Feldmanmfeldman@huji.ac.ilSchool Business AdministrationCenter Study Rationality,Hebrew University Jerusalem,Jerusalem, IsraelNoam Nisannoam@cs.huji.ac.ilSchool Computer Science,Hebrew University Jerusalem,Jerusalem, IsraelAbstractmany multiagent domains set agents exert eort towards joint outcome, yetindividual eort levels cannot easily observed. typical example scenariorouting communication networks, sender observe whether packetreached destination, often information actions intermediaterouters, inuences nal outcome. study setting principal needsmotivate team agents whose combination hidden eorts stochastically determinesoutcome. companion paper devise study basic combinatorial agency modelsetting, principal restricted inducing pure Nash equilibrium.study various implications restriction. First, show that, contrastcase observable eorts, inducing mixed-strategies equilibrium may benecialprincipal. Second, present sucient condition technologies gaingenerated. Third, bound principals gain various families technologies. Finally,study robustness mixed equilibria coalitional deviations computationalhardness optimal mixed equilibria.1. Introductionpaper study Combinatorial Agency Mixed Strategies, section reviewsbackground Combinatorial Agency pure strategies present resultsmixed strategies.1.1 Background: Combinatorial Agencywell studied principal-agent problem deals principal motivaterational agent exert costly eort towards welfare principal. dicultymodel agents action (i.e. whether exerts eort not) invisibleprincipal nal outcome, probabilistic also inuencedc2010AI Access Foundation. rights reserved.fiBabaioff, Feldman & Nisanfactors, visible1 . problem well studied many contexts classicaleconomic theory refer readers introductory texts economic theorywork Mass-Colell, Whinston, Green (1995), Chapter 14. settings,properly designed contract, payments contingent upon nal outcome,inuence rational agent exert required eort.many multiagent settings, however, set agents work together towards jointoutcome. Handling combinations agents rather single agent focuswork Babaio, Feldman, Nisan (2006a). much work previously donemotivating teams agents (e.g., Holmstrom, 1982; Strausz, 1996), emphasisdealing complex combinatorial structure dependencies agents actions.general case, combination eorts exerted n dierent agents may resultdierent expected gain principal. general question asks, given exactspecication expected utility principal combination agents actions,conditional payments principal oer agents maximizenet utility?view problem hidden actions computational settings complementaryproblem problem hidden information heart eld AlgorithmicMechanism Design (Nisan, Roughgarden, Tardos, & Vazirani, 2007; Nisan & Ronen, 2001).recent years, computer science articial intelligence showed lot interestalgorithmic mechanism design. particular, imported concepts game theorymechanism design solving problems arise articial intelligence applicationdomains, computer networks routers autonomous software agents.Communication networks serve typical application setting. Since many computer networks (such Internet mobile ad-hoc networks) used administeredmultiple entities dierent economic interests, performance determinedactions among various interacting self-interested parties. Thus, taking accounteconomic strategic considerations together technical ones may crucialsettings. Indeed, recent years seen urry research employing game theoretic models analysis better understanding eect strategic considerationsnetwork design performance.example discussed work Feldman, Chuang, Stoica, Shenker(2007) Quality Service routing network: every intermediate link router mayexert dierent amount eort (priority, bandwidth, etc.) attempting forwardpacket information. nal outcome whether packet reached destinationclearly visible, rarely feasible monitor exact amount eort exertedintermediate link ensure really exert appropriate amounteort? example, Internet routing, IP routers may delay drop packets,mobile ad hoc networks, devices may strategically drop packets conserve constrainedenergy resources. Aside forwarding decisions, done sequential manner,eort decisions take place prior actual packet transmission, donesimultaneous manner. many examples decisions, amongquality hardware, appropriate tuning routers, more. focus1. Invisible meant wide sense includes precisely measurable, costly determine,non-contractible (meaning upheld court law).340fiMixed Strategies Combinatorial Agencya-priori eort decisions, since crucial quality transmission,harder detect agents shirk respect matters.general model presented work Babaio et al. (2006a), n agentsset possible actions, combination actions players resultsoutcome, happens probabilistically. main part specicationproblem model function (the technology) species distributionn-tuple agents actions. Additionally, problem species principals utilitypossible outcome, agent, agents cost possible action.principal motivates agents oering contract speciespayment possible outcome whole project. Key actionsplayers non-observable (hidden-actions) thus contract cannot makepayments directly contingent actions players, rather outcomewhole project.Given set contracts, agent optimizes utility; i.e., chooses actionmaximizes expected payment minus cost action. Since outcome dependsactions players together, agents put game assumedreach Nash Equilibrium (NE). principals problem designing optimalcontract: i.e. vector contracts dierent agents induce equilibriumoptimize expected utility outcome minus expected total payment.main diculty determining required Nash equilibrium point.interest paper, work Babaio et al. (2006a), focusedbinary case: agent two possible actions exert eort shirktwo possible outcomes success failure. motivating examples comefollowing restricted concrete structured subclass problem instances:Every agent performs subtask succeeds low probability agentexert eort higher probability > , agent exert eort.whole project succeeds deterministic Boolean function success subtasks.example, Boolean functions represent respective casesagents complementary (i.e., project succeeds agentssucceed) substitutive (i.e., project succeeds least oneagents succeeds). Yet, restricted subclass problem instances technologiesrepresented read-once networks two specied source sink nodes,every edge labeled single agent, project succeeds (e.g., packetinformation reaches destination) successful path sourcesink nodes.1.2 Paper: Mixed Equilibriafocus work Babaio et al. (2006a) notion Nash-equilibriumpure strategies: allow principal attempt inducing equilibriumagents mixed strategies actions. observable-actions case (whereprincipal condition payments agents individual actions) restrictionpure strategies without loss generality: mixed actions never help since simplyprovide convex combination would obtained pure actions.341fiBabaioff, Feldman & NisanYet, surprisingly, show case hidden-actions casestudying: cases, Mixed-Nash equilibrium provide better expected utilityprincipal obtain equilibrium pure strategies. particular,already happens case two substitutive agents certain (quite restricted) rangeparameters (see Section 3).inducing mixed strategy equilibria might benecial principal, mixedNash equilibrium much weaker solution concept pure Nash equilibrium,already observed Harsanyi (1973). opposed Nash equilibria pure strategies,guarantees one obtains expectation. addition, player deviateequilibrium strategy without lowering expected payo even expectsplayers stick equilibrium strategies. Moreover, best-response dynamics convergepure proles, natural dynamics leading mixed Nash equilibrium.result, principal cannot gain much inducing Nash equilibrium mixedstrategies, might willing tolerate instability notion. main goalquantify principals gain inducing mixed equilibrium, rather pure.that, analyze worst ratio (over principals values) principals optimalutility mixed equilibrium, optimal utility pure equilibrium. termratio price purity (POP) instance study.price purity least 1 denition, larger is, principalgain inducing mixed equilibrium compared pure one. provesuper-modular technologies (e.g. technologies increasing returns scale)contains particular Boolean function, price purity trivial (i.e., P OP =1). Moreover, show Boolean function, assignmentparameters (agents individual success probabilities) obtained structuredtechnology non trivial POP (i.e., P OP > 1). (Section 4).price purity may strictly greater 1, obtain quite large numberresults bounding ratio (Section 5). bounds range linear boundgeneral families technologies (e.g., P OP n anonymous sub-modulartechnology) constant bounds restricted cases (e.g., P OP 1.154... familyanonymous technologies, P OP 2 technology 2 agents).Additionally, study properties mixed equilibrium. show mixedNash equilibria delicate pure ones. particular, show unlikepure case, optimal contract also strong equilibrium (Aumann, 1959)(i.e., resilient deviations coalitions), optimal mixed contract (in least twoagents truly mix) never satises requirements strong equilibrium (Section 6).Finally, study computational hardness optimal mixed Nash equilibrium,show hardness results pure case hold mixed case well(Section 7).2. Model Preliminariesfocus simple binary action, binary outcome scenario agent twopossible actions (exert eort shirk) two possible outcomes (failure,success). begin presenting model pure actions (which generalizationmodel Winter, 2004), move mixed case. principal employs set342fiMixed Strategies Combinatorial Agencyagents N size n. agent N set two possible actions Ai = {0, 1} (binaryaction), low eort action (0) cost 0 (ci (0) = 0), high eort action (1)cost ci > 0 (ci (1) = ci ). played prole actions determine, probabilistic way,contractible outcome, {0, 1}, outcomes 0 1 denote project failuresuccess, respectively (binary-outcome). outcome determined according successfunction : A1 . . . [0, 1], t(a1 , . . . , ) denotes probability projectsuccess players play action prole = (a1 , . . . , ) A1 . . . = A.use notation (t, c) denote technology (a success function vector costs,one agent). assume everything eort agents commonknowledge.principals value successful project given scalar v > 0, gainsvalue project failure. hidden-actions model actions playersinvisible, nal outcome visible others, may design enforceablecontracts based outcome. assume principal pay agentsne (known limited liability constraint). contract agent thus givenscalar value pi 0 denotes payment gets case project success.project fails, agent gets money (this contrast observable-actionsmodel payment agent contingent action). contractsagents public, agents know making eort decisions.Given setting, agents put game, utility agentprole actions = (a1 , . . . , ) given ui (a) = pi t(a) ci (ai ).usual, denote ai Ai (n 1)-dimensional vector actions agentsexcluding agent i. i.e., ai = (a1 , . . . , ai1 , ai+1 , . . . , ). agents assumedreach Nash equilibrium, equilibrium exists. principals problem (whichproblem paper)design contracts pi maximize expectedutility u(a, v) = t(a) (v pi ), actions a1 , . . . , Nash-equilibrium.case multiple Nash equilibria, model let principal choose desiredone, suggest agents, thus focusing best Nash equilibrium.2wish concentrate motivating agents, rather coordinationagents, assume eort agent always leads better probabilitysuccess. Formally, N, ai Ai t(1, ai ) > t(0, ai ). also assumet(a) > 0 A.next consider extended game agent mix exerting eortshirking (randomize two possible pure actions). Let qi denote probabilityagent exerts eort, let qi denote (n 1)-dimensional vector investmentprobabilities agents except agent i. extend denition successfunction range mixed strategies, taking expectation.t(q1 , . . . , qn ) =n( qiai (1 qi )(1ai ) )t(a1 , . . . , )a{0,1}n i=12. pure case (Babaio, Feldman, & Nisan, 2006b), best Nash equilibrium also strongequilibrium, case delicate mixed case (see Section 6). variants NEexist. One variant, similar spirit strong implementation mechanism design, wouldtake worst Nash equilibrium, even, stronger yet, require single equilibrium exists(as work Winter, 2004).343fiBabaioff, Feldman & NisanNote agent (qi , qi ) holds t(qi , qi ) = qi t(1, qi ) + (1 qi )t(0, qi ). mixed equilibrium prole least one agent mixes probabilitypi [0, 1] called non-degenerate mixed equilibrium.pure strategies, marginal contribution agent i, given ai Ai , denedbe: (ai ) = t(1, ai ) t(0, ai ). mixed case dene marginal contributionagent i, given qi be: (qi ) = t(1, qi ) t(0, qi ). Since monotone,positive function.next characterize payment result agent mixing exertingeort shirking.Claim 2.1 Agent best response mix exerting eort shirking probability qi (0, 1) indierent ai = 1 ai = 0. Thus, given prolestrategies qi , agent mixes if:pi =cici=(qi )t(1, qi ) t(0, qi )payment makes indierent exerting eort and(shirking.)q.expected utility agent i, exerts eort probability qi is: ui (q) = ci it(q)(qi )Proof: Recall ui (q) = t(q) pi qi ci , thus ui (q) = qi ui (1, qi ) + (1 qi ) ui (0, qi ).Since maximizes utility, qi (0, 1), must case ui (1, qi ) = ui (0, qi ).ci.2Solving pi get pi = (q)prole mixed strategies q = (q1 , . . . , qn ) Mixed Nash equilibrium agenti, qi agent best response, given qi .principals expected utility mixed Nash prole q given=u(q, v)ci(v P ) t(q), P total payment case success, given P = i|qi >0 (q.)optimal mixed contract principal equilibrium mixed strategy prole q (v)maximizes principals utility value v. Babaio et al. (2006a) showsimilar characterization optimal pure contract A. agent exerts eort paidci(ai ) , utilities above, given pure prole.pure Nash case, given value v, optimal pure contract principal set agents(v) exert eort equilibrium, set maximizes principals utilityvalue v.simple crucial observation, generalizing similar one work Babaioet al. (2006a) pure Nash case, shows optimal mixed contract exhibitsmonotonicity properties value.Lemma 2.2 (Monotonicity lemma): technology (t, c) expected utilityprincipal optimal mixed contract, success probability optimal mixedcontract, expected payment optimal mixed contract, monotonicallynon-decreasing value.proof postponed Appendix A, also shows monotonicityalso holds observable-actions case. Additionally, lemma holds generalsettings, agent arbitrary action set (not restricted binary-actionsmodel considered here).344fiMixed Strategies Combinatorial Agencywish quantify gain inducing mixed Nash equilibrium, inducing pureNash. dene price purity worse ratio (over v) maximumutilities obtained mixed pure strategies.Denition 2.3 price purity P OP (t, c) technology (t, c) dened worseratio, v, principals optimal utility mixed case optimal utilitypure case. Formally,)(t(q (v)) v i|q (v)>0 (qci (v))()P OP (t, c) = Supv>0cit(S (v)) v (v) (ai )(v) denotes optimal pure contract q (v) denotes optimal mixed contract,value v.price purity least 1, may greater 1, later show. Additionally, obtained value transition point pure case (a pointprincipal indierent two optimal pure contracts).Lemma 2.4 technology (t, c), price purity obtained nite vtransition point two optimal pure contracts.2.1 Structured Technology Functionsorder concrete, next present technology functions whose structuredescribed easily derived independent agent tasks call structuredtechnology functions. subclass gives us natural examples technology functions,also provides succinct natural way represent technology success functions.structured technology function, individual succeeds fails taskindependently. projects success failure deterministically depends, maybe complex way, set successful sub-tasks. Thus assume monotone Booleanfunction f : {0, 1}n {0, 1} indicates whether project succeeds functionsuccess n agents tasks.structured technology function dened t(a1 , . . . , ) probabilityf (x1 , . . . , xn ) = 1 bits x1 , . . . , xn chosen according followingdistribution: ai = 0 xi = 1 probability [0, 1) (and xi = 0 probability1 ); otherwise, i.e. ai = 1, xi = 1 probability > (and xi = 0probability 1 ). Thus, structured technology dened n, f parameters{i , }iN .Let us consider two simple structured technology functions, OR. Firstconsidertechnology: f (x1 , . . . , xn ) logical conjunction xi (f (x) =x).Thus project succeeds agents succeed tasks. showngraphically read-once network Figure 1(a). technology, probabilitysuccess product individualsuccess probabilities. Agent succeedsprobability iai i1ai , thus t(a) = iai i1ai .Next,consider technology: f (x1 , . . . , xn ) logical disjunction xi(f (x) = xi ). Thus project succeeds least one agents succeed345fiBabaioff, Feldman & Nisanx1 x2xnx1x2xn(b) technology(a) technologyFigure 1: technologies. (a), project successful packet routedalong linear path (where agent controls edge), (b), projectsuccessful packet routed least along one edge.tasks. shown graphically read-once network Figure 1(b). technology,probability success 1 minus probabilityfail. Agent failsprobability (1 )ai (1 )1ai , thus t(a) = 1 (1 )ai (1 )1ai .two simple examples. One consider interesting examplesMajority function (the project succeed majority agents successful),OR-Of-ANDs technology, disjunction conjunctions (several teams,project succeed agents one teams successful). additionalexamples see work Babaio et al. (2006a).success function called anonymoussymmetric respect players.I.e. t(a1 , . . . , ) depends ai . example, anonymous technologyparameters 1 > > > 0 agent succeed probabilityeort, probability > eort. agents exert eort, successprobability 1 (1 )m (1 )nm .technology identical costs exists c agent i, ci = c.case identical costs POP independent c, use P OP (t) denotePOP technology identical costs. abuse notation denote technologyidentical costs success function t. Throughout paper, unless explicitly statedotherwise, assume identical costs. technology identical costs anonymousanonymous.3. Example: Mixed Nash Outperforms Pure Nash!actions observable (henceforth, observable-actions case), agentexerts eort paid exactly cost, principals utility equals social welfare.case, social welfare mixed strategies convex combination socialwelfare pure strategies; thus, clear optimal utility always obtained purestrategies. However, surprisingly enough, hidden-actions case, principal mightgain higher utility mixed strategies allowed. demonstrated followingexample:346fiMixed Strategies Combinatorial AgencyFigure 2: Optimal mixed contracts technologies 2 agents. areas indicated 0,1, 2 correspond areas optimal 0, 1, 2 agents, respectively,exert eort probability 1. white area corresponds agents exert eortnon-trivial probability, q. xed , q increases v.Example 3.1 Consider anonymous technology two agents, c = 1, =1 = 2 = 1 1 = 1 2 = 0.09 v = 348. holds t(0, 0) = 1 (1 )2 =0.172, t(0, 1) = t(1, 0) = 1 (1 )(1 ) = 0.9181, t(1, 1) = 1 (1 )2 = 0.992.Consider mixed strategy q1 = q2 = 0.92. holds that: t(0, 0.92) = 0.08 t(0, 0) +0.92 t(0, 1) = 0.858, t(1, 0.92) = 0.92 t(1, 1) + 0.08 t(1, 0) = 0.986, t(0.92, 0.92) =0.082 t(0, 0) + 0.08 0.92 t(0, 1) 2 + 0.922 t(1, 1) = 0.976. payment player1= 7.837, thus principalssuccessful project pi (0.92, 0.92) = t(1,0.92)t(0,0.92)utility mixed strategies q1 = q2 = 0.92 v = 348 u((0.92, 0.92), 348) =t(0.92, 0.92) (348 2 7.837) = 324.279.principals utility mixed prole q1 = q2 = 0.92 324.279,optimal contract pure strategies obtained agents exert eort achievesutility 318.3. implies moving pure strategies mix strategies, onegains least 324.27/318.3 > 1.0187 factor improvement (which approximately 1.8%).worse ratio exists general case (in necessarily hold= 1 ) = 0.0001, = 0.9 v = 233. case get optimal purecontract one agent, gives utility 208.7, mixed contract q1 = q2 = 0.92gives utility 213.569, ratio least 1.0233 (approximately 2.3%).complete example, Diagram 2 presents optimal contract 2 agents,function (when = 1 ) v. shows parameters v,optimal contract obtained agents exert eort equal probabilities.following lemma (proved Appendix A.1) shows optimal mixed contractsanonymous technology (with n agents) specic structure. is,agents shirk, mix exactly probability.347fiBabaioff, Feldman & NisanLemma 3.2 anonymous technology (any > , c, n) value v, eitheroptimal mixed contract pure contract, or, optimal mixed contract k {2, . . . n}agents exert eort equal probabilities q1 = . . . = qk (0, 1), rest agentsexert eort.4. Pure Nash Good Enough?Next, identify class technologies price purity 1; is,principal cannot improve utility moving pure Nash equilibrium mixed Nashequilibrium. technologies marginal contribution agent nondecreasing eort agents. Formally, two pure action proles a, bdenote b j, bj j aj (eort bj least high eort aj ).Denition 4.1 technology success function exhibits (weakly) increasing returnsscale (IRS)3 every i, every pure proles bt(bi , bi ) t(ai , bi ) t(bi , ai ) t(ai , ai )technology exhibits IRS (Winter, 2004; Babaio et al., 2006a). IRStechnologies show P OP = 1.Theorem 4.2 Assume super-modular. cost vector c, P OP (t, c) = 1.Moreover, non-degenerate mixed contract never optimal.Proof: mixed prole q = (q1 , q2 , . . . , qn ), let S(q) support q, is, S(q)qi > 0, agent S(q) let Si = S(q) \ {i} support qexcluding i. Similarly, pure prole = (a1 , a2 , . . . , ) let S(a) support a.ci. Similarly,mixed prole q, agent S(q) paid pi (qi ) = t(1,qi )t(0,q)cipure prole a, agent S(a) paid pi (S(a) \ {i}) = pi (ai ) = t(S(a))t(S(a)\{i}),t(T ) success probability aj = 1 j , aj = 0 j/ . alsodenote (T ) = t(T ) t(T \ {i}).show q non-degenerate mixed prole (i.e., least one agent q exertseort probability qi (0, 1)), prole agent S(q) exerts eortprobability 1 yields higher utility principal.Lemma 5.3 (see Section 5), holds pi (qi ) minT Si pi (T ), pi (T ) =ci(T ) . exhibits IRS, (T ) increasing function denition (see Section 4), therefore minT Si pi (T ) = pi (Si ). Therefore holds S(q),pi (qi ) pi (Si ), thus:pi (qi )pi (Si )iS(q)iS(q)3. Note exhibits IRS super-modular.348fiMixed Strategies Combinatorial Agencyaddition, due monotonicity t, holds t(q) < t(S(q)). Therefore,u(q, v) = t(q) vpi (qi )iS(q)< t(S(q)) vt(S(q)) viS(q)pi (qi )pi (Si )iS(q)= u(S(q), v)u(S(q), v) principals utility pure prole agentsS(q) exert eort probability 1, rest exert eort.2show (on subset bits) function structuredtechnology based function exhibits IRS, is, functionchoices parameters (any n {i , }iN ), structured technology exhibitsIRS. Boolean function, assignment parameterscreated structured technology essentially 2 inputs (Lemma B.1 Appendix B),thus non-trivial POP (recall Example 3.1). proof following theoremsee Appendix B.Theorem 4.3 Let f monotone Boolean function n 2 inputs,constant conjunction subset input bits. exist parameters{i , }ni=1 POP structured technology parameters (andidentical cost c = 1) greater 1.0233.Thus, goal give upper bounds POP various technologies.5. Quantifying Gain Mixingsection present bounds price purity general technologies, followingbounds special case technology.5.1 POP General Technologiesrst show POP bounded principals price unaccountability (Babaio et al., 2006b), whose denition follows.Denition 5.1 principals price unaccountability P OUP (t, c) technology (t, c)dened worst ratio (over v) principals utility observable-actionscase hidden-actions case:(v)) vt(Soa(v) ciiSoaP OUP (t, c) = Supv>0cit(S (v)) v (v) (a)(v) optimal pure contract observable-actions case, (v)Soaoptimal pure contract hidden-actions case.349fiBabaioff, Feldman & NisanTheorem 5.2 technology holds P OUP (t) P OP (t).Proof: P OUP (t) P OP (t) dened supremum utilities ratio givenvalue v. present bound v, thus holds supremum. denominatorcase same: optimal utility principal hidden-actions casepure strategies. numerator POP optimal principal utility hiddenactions case mixed strategies. Obviously, optimal principal utilityobservable-actions case mixed strategies. already observedobservable-actions case mixed strategies cannot help principal (see Section 3), i.e.,principal utility mixed strategies equals principal utility pure strategies.assertion theorem follows observing optimal principal utilitypure strategies observable-action case numerator P OUP .2However, bound rather weak. best see this, note principals priceunaccountability might unbounded (e.g., Babaio et al., 2006b). Yet, shownSection 4.2, P OP (AN D) = 1.section provide better bounds technologies identical costs. begincharacterizing payments mixed contract. show mixed prole,agent support contract paid least minimal payment singleagent pure prole support, maximal payment.mixed prole q = (q1 , q2 , . . . , qn ), let S(q) support q, is, S(q)qi > 0. Similarly, pure prole = (a1 , a2 , . . . , ) let S(a)cisupport a. mixed prole q, agent S(q) paid pi (qi ) = t(1,qi )t(0,q.)Similarly, pure prole a, agent S(a) paid pi (S(a) \ {i}) = pi (ai ) =cit(S(a))t(S(a)\{i}) , t(T ) success probability aj = 1 j , aj = 0j/ T.Lemma 5.3 mixed prole q = (q1 , q2 , . . . , qn ), agent S(q) let Si =S(q) \ {i} support q excluding i. holdsmaxT Si pi (T ) pi (qi ) minT Si pi (T )Proof: show agent S(q), increase success probabilityexerting eort players play mixed strategies, convex combinationincreases success probabilitysupport play pure strategies.nthe aagentsRecall that: t(q1 , . . . , qn ) = a{0,1}n ( i=1 qi (1 qi )(1ai ) )t(a1 , . . . , ).Let technology restricted support = S(q), is, i1 , . . . ,agents (ai1 , ai2 , . . . , aiS ) dened value a, aj = 0agent j/ S, aj = aik j = ik S. dened mixed strategiesexpected way. Thus,(qi ) = t(1, qi ) t(0, qi )= (1, qSi ) (0, qSi )aj=(qj (1 qj )(1aj ) ) (1, a)a{0,1}|S|1 jSi=((a{0,1}|S|1 jSiqj j(1 qj )(1aj ) )(t (1, a) (0, a))a{0,1}|S|1 jSi350qj j (1 qj )(1aj ) )t (0, a)fiMixed Strategies Combinatorial Agencyconclude (qi ) convex combination (bi ) b support S(b)Si . Therefore, minT Si (t({i} ) t(T )) (qi ) maxT Si (t({i} ) t(T )).Thus,maxT Si 1/(t({i} ) t(T )) = 1/minT Si (t({i} ) t(T ))1/i (qi ) = pi (qi )1/maxT Si (t({i} ) t(T ))= minT Si 1/(t({i} ) t(T ))2follows, consider two general families technologies n agents: anonymous technologies technologies exhibit decreasing returns scale (DRS). DRStechnologies technologies decreasing marginal contribution (more eort othersdecrease contribution agent). families present bound nPOP.begin formal denition DRS technologies.Denition 5.4 technology success function exhibits (weakly) decreasing returnsscale (DRS)4 every i, every bt(bi , bi ) t(ai , bi ) t(bi , ai ) t(ai , ai )Theorem 5.5 anonymous technology (non-anonymous) technology exhibits DRS, holds P OP (t) n.proof theorem well proofs claims appear latersection, see Appendix C. also prove bound POP technology 2agents (even anonymous), improved bound anonymous case.Theorem 5.6 technology (even non-anonymous) 2 agents, holdsP OP (t) 2. anonymous P OP (t) 3/2.provide bounds non-anonymous technologies, left openproblem future research. believe linear bound anonymous DRStechnologies tight conjecture exists universal constant Cbounds POP technology. Moreover, simulations seem indicate nonanonymous technology 2 agents yields highest possible POP. motivatesus explore POP technology detail.5.2 POP Technologytechnology (even non-anonymous) exhibits DRS (see Appendix A.1), impliesbound n POP technology. Yet, anonymous technologypresent improved bounds POP. particular, = 1 < 1/2 boundPOP 1.154....4. Note exhibits DRS submodular.351fiBabaioff, Feldman & NisanTheorem 5.7 anonymous technology n agents:nn (n 1). (b) POP goes 1 n goes1. 1 > > > 0: (a) P OP 1(1)(for xed ) goes 1 (for xed n 2).2.12> = 1 > 0: (a) P OP0 goes122(32 3)(=3( 32)1.154..). (b) POP goes 1 goes(for xed n 2).bounds anonymous technologies case = 1much better general bounds, still tight. highest POP ableobtain simulations 1.0233 > , 1.0187 = 1 (see Section 3),deriving exact bound analytically left open problem.6. Robustness Mixed Nash Equilibriaorder induce agent truly mix exerting eort shirking, pi mustequal exactly ci /i (qi ) (see claim 2.1). Even increase pi , agentlonger indierent ai = 0 ai = 1, equilibrium falls apart.cicontrast pure case, pi (amaintain required)equilibrium. delicacy exhibits robustness obtained equilibriumdeviations coalitions (as opposed unilateral deviations Nash). strongequilibrium (Aumann, 1959) requires subgroup players (henceforth coalition)coordinate joint deviation every member coalition strictly improvesutility.Denition 6.1 mixed strategy prole q [0, 1]n strong equilibrium (SE)exist coalition N strategy prole q [0, 1], q ) > u (q)., ui (qwork Babaio et al. (2006b) show payments inducepure strategy prole best pure Nash equilibrium (i.e., pure Nash equilibriummaximizes principals utility), also strong equilibrium. contrastpure case, next show non-degenerate mixed Nash equilibrium qexist least two agents truly mix (i.e., = j s.t. qi , qj (0, 1)), never strongequilibrium. coalition = {i|qi (0, 1)} deviate qexerts eort probability 1, agent strictly improves utility (seeproof Appendix D).Theorem 6.2 mixed optimal contract q includes least two agents truly mix(i = j s.t. qi , qj (0, 1)), q strong equilibrium.technology, example, holds non-degenerate mixed equilibrium least two agents truly mix (see lemma 3.2). Therefore, non-degenerate contracttechnology strong equilibrium.generically mixed Nash contract strong equilibrium pure Nashcontract always is, pricipal wishes induce strong Nash equilibrium (e.g.,agents coordinate moves), restrict inducing pure Nashequilibrium, loss bounded POP (see Section 5).352fiMixed Strategies Combinatorial Agency7. Algorithmic Aspectscomputational hardness nding optimal mixed contract depends representation technology accessed. black-box accessspecial case read-once networks, generalize hardness results pure case(Babaio et al., 2006b) mixed case. main open question whether possiblend optimal mixed contract polynomial time, given table representationtechnology (the optimal pure contract found polynomial time case).generalization theorems follow (see proofs Appendix E).Theorem 7.1 Given input black box success function (when costsidentical), value v, number queries needed, worst case, ndoptimal mixed contract exponential n.Even technology structured technology restricted sourcepair reliability read-once network (see (Babaio et al., 2006b)), computing optimalmixed contract hard.Theorem 7.2 optimal mixed contract problem read networks #P -hard(under Turing reductions).8. Conclusions Open Problemspaper studies model principal induces set agents exert eortindividual contracts based nal outcome project. focuspaper question much principal benet inducing Nash equilibriummixed strategies instead restricted pure Nash equilibrium (as assumedoriginal model). nd case observable actions mixed equilibriacannot yield principal higher utility level pure ones, indeed happenhidden actions. Yet, whether mixed equilibria improve principals utilitydepends technology project. give sucient conditions technologiesmixed strategies yield gain principal. Moreover, provide boundsprincipals gain various families technologies. Finally, show optimalcontract non-degenerated mixed Nash equilibrium strong equilibrium (in contrastpure one) nding optimal contract computationally challenging.model results raise several open problems directions future work.would interesting study principals gain (from mixed strategies) dierentfamilies technologies, series-parallel technologies. Additionally, modelextended beyond binary eort level used here. Moreover, focus inducingmixed Nash equilibrium, equilibrium might unique. One considersolution concepts unique Nash equilibrium iterative elimination dominatedstrategies. Finally, might interest study performance gap puremixed Nash equilibria domains beyond combinatorial agency.353fiBabaioff, Feldman & Nisan9. AcknowledgmentsMichal Feldman partially supported Israel Science Foundation (grant number1219/09) Leon Recanati Fund Jerusalem school business administration.Appendix A. GeneralLemma 2.2 ( Monotonicity lemma) technology (t, c) expected utilityprincipal optimal mixed contract, success probability optimal mixedcontract, expected payment optimal mixed contract, monotonicallynon-decreasing value.Proof: Suppose proles mixed actions q 1 q 2 optimal v1 v2 < v1 ,respectively. Let P 1 P 2 total payment case successful project, correspondingminimal payments induce q 1 q 2 Nash equilibria, respectively. utilitylinear function value, u(a, v) = t(a) (v P ) (P total payments casesuccessful project). q 1 optimal v1 , u(q 1 , v1 ) u(q 2 , v1 ), t(a) 0v1 > v2 , u(q 2 , v1 ) u(q 2 , v2 ). conclude u(q 1 , v1 ) u(q 2 , v2 ), thus utilitymonotonic non-decreasing value.Next show success probability monotonic non-decreasing value. q 1optimal v1 , thus:t(q 1 ) (v1 P 1 ) t(q 2 ) (v1 P 2 )q 2 optimal v2 , thus:t(q 2 ) (v2 P 2 ) t(q 1 ) (v2 P 1 )Summing two equations, get (t(q 1 ) t(q 2 )) (v1 v2 ) 0, impliesv1 > v2 t(q 1 ) t(q 2 ).Finally show expected payment monotonic non-decreasing value.q 2 optimal v2 t(q 1 ) t(q 2 ), observe that:t(q 2 ) (v2 P 2 ) t(q 1 ) (v2 P 1 ) t(q 2 ) (v2 P 1 )equivalently, P 2 P 1 , wanted show.2note lemma also holds case proles pure actions,observable-actions case (by exactly arguments).Lemma 2.4 technology (t, c), price purity obtained nite vtransition point two optimal pure contracts.Proof: Clearly large enough value v , ratio 1, cases agents exertmaximal eort. small enough values principal choose contractagent cases (and ratio 1). true value smalleragents cost, optimal contract contract agent cases. Let vsupremum values principal choose contract agentcases. Now, ratio continuous function compact range [v, v ], thussupremum obtained, value v .354fiMixed Strategies Combinatorial Agencyseen POP obtained value v, next prove obtainedtransition point pure case. P OP = 1 claim clearly holds, thusconsider case P OP > 1. Let v maximal value POPobtained. Assume contradiction v transition point two optimalpure contracts, q optimal pure mixed cases, respectively.P OP > 1, q non-degenerate u(q, v) > u(a, v). Let P (a) P (q) denote totalpayment case success q, respectively. next consider two options.rst consider case t(a) t(q). show case, utilities ratiov , > 0 worse utilities ratio v, get contradiction.> 0 small enough, optimal pure contract still a, u(q, v ) > 0. Let qoptimal mixed contract v . holdsP OPu(q , v )u(q, v )u(q, v) t(q)u(q, v)=>u(a, v )u(a, v )u(a, v) t(a)u(a, v)last strict inequality following argument.u(q, v) t(q)u(q, v)>u(a, v) t(a)u(a, v)t(q) u(a, v) < t(a) u(q, v)P (q) < P (a)P (q) < P (a) u(q, v) = t(q)(v P (q)) > t(a)(v P (a)) = u(a, v) t(a) t(q).Next consider case t(q) > t(a). P (q) < P (a), argumentpresented shows utilities ratio v , > 0, worseutilities ratio v, get contradiction. hand, P (q) P (a) showutilities ratio v + , > 0, least large utilities ratiov, contradiction v maximal value POP obtained. > 0small enough, optimal pure contract still (as v transition pointpure contracts). Let q optimal mixed contract v + . holdsP OPu(q, v + )u(q, v) + t(q)u(q, v)u(q , v + )=u(a, v + )u(a, v + )u(a, v) + t(a)u(a, v)last inequality following argument.u(q, v) + t(q)u(q, v)u(a, v) + t(a)u(a, v)t(q) u(a, v) t(a) u(q, v)P (q) P (a)holds assumption.2following corollary Lemma 2.4 helpful nding POP technologies2 agents.Corollary A.1 Assume technology 2 agents identical costs exhibitsDRS, POP obtained transition point pure case, contractagents.Proof: Lemma 2.4 POP obtained transition point pure case.single transition point, 0 agents 2 agents, claim holds. contractingsingle agent sometimes optimal, must case single agentcontracted agent (possibly weakly) highest success probability (agent355fiBabaioff, Feldman & Nisant({i}) t({j}) j = i, implies = t({i})t() t({j})t() = j ).Thus need show POP obtained transition point v0 agents contract agent i. Assume q optimal mixed contractv, P (q) total payment case success. q gives utilitycontract {i}, done.Otherwise, u(q, v) > u({i}, v) , Corollary C.9 holds P (q) c1 , thust(q) > t({i}). implies utilities ratio value v + > 0 small enoughworse ratio v (by argument presented Lemma 2.4 caset(q) > t(a)).2A.1 Analysis TechnologyLemma 3.2 anonymous technology (any > , c, n) value v, eitheroptimal mixed contract pure contract, or, optimal mixed contract k {2, . . . n}agents exert eort equal probabilities q1 = . . . = qk (0, 1), rest agentsexert eort.Proof: First, observe cannot case agents one exert eort,single agent mix probability 0 < qi < 1. principal would ratherchange prole qi = 1 (pays same, gets higher success probability). Supposecontradiction contract induces prole (qi , qj , qij ) qi , qj (0, 1]qi = qj (qi > qj without loss generality) optimal. agent k, denoteprobability failure agent k task (qk ). is, (qk ) = 1 (qk + (1 qk )) =1 + ( )qk = + qk = .show suciently small > 0, mixed prole q = (qi , qj + (qji ) , qij )(q )(qi )}, ) obtains better contract,(for q [0, 1]. i.e., < min{qi , (1 qi ) (qj)contradiction optimality original contract.technology,t(q) = 1 kN (qk ) = 1 (q), (q) = kN (qk ).also denote ij (q) = k=i,j (qk ). change success probability related()new product (qi ) qj + ji :(qi )(qj )()(qj )= (qi ) qj +(qi ))((qj )= ((qi ) ) (qj ) +(qi )(qj )(qj )= (qi )(qj ) (qj ) +(qi ) 2 2(qi )(qi )(qj )= (qi )(qj ) 2 2(qi )356fiMixed Strategies Combinatorial AgencyTherefore new success probability t(q ) increased change:j, qij )()(qj )= 1 (qi ) qj +ij (q)(qi ))((qj )= 1 (qi )(qj ) 2 2ij (q)(qi )()2 2 (q)2 2 (q)= t(q) += t(q) 1 +((qi ))2t(q) ((qi ))2t(q ) = t(qi , qj +2 2(q)denote z() = t(q)((q2 , thus t(q ) = t(q) (1 + z()), z() > 0 .))showing success probability increases, left show suciently small , total payment decreases. payment agent l given by:pl =cc (ql )c==t(1, ql ) t(0, ql )( ) m=l (qm )( ) t(q)change payment agent kc (qk )c (qk )( ) t(q) ( ) t(q )()(qk )c=(qk )t(q) ( )(1 + z())()c=(qk ) (qk ) + (qk ) z()t(q) ( ) (1 + z())()= W () (qk ) (qk ) + (qk ) z()pk pk =cW () = t(q)()(1+z())agent k = i, j, (qk ) = (qk ) get pk pk = W () (qk ) z(). agent i,(qi ) (qi ) = get pi pi = W () ( + (qi ) z()). agent j, (qj ) (qj ) =(qji ) get pj pj = W () ( (qji ) + (qj ) z()).summing agents get(q )(q )kNpkkNpk =(pk pk )kN= (pi pi ) + (pj pj ) +(pk pk )k=i,j)(qj )+ z()(qk )= W ()(qi )kN( ())(qj )= W () 1+ z()(qk )(qi )(kN357fiBabaioff, Feldman & Nisanpositive following observations. W () > 0 z() > 0 , clearly(qj )kN (qk ) > 0. Additionally, (1 (qi ) ) > 0 = < 0, (qi ) < (qj )pi > p j .conclude, show success probability q greater successprobability q, payments lower, thus utility principal increasesmoves q q , contradiction optimality q.2Observation A.2 technology exhibits DRS.Proof: Let ra , rb [0, 1]n two proles actions, rb ra (for i, rib ria ).b ) (r , r b ) (r b , r ) (r , r ). Indeed,need show every i, ti (rib , ribbti (rib , ri) ti (ria , ri) = 1 (1 rib ) (1 rjb ) (1 (1 ria ) (1 rjb ))j=i= (rib ria ) (1 rjb )j=ij=i(ribria )(1 rja )j=i= 1 (1 rib )(1 rja ) (1 (1 ria ) (1 rja ))j=i=ti (rib , ri)j=iti (ria , ri)2Appendix B. Pure Nash Good Enough?Lemma B.1 Let f : {0, 1}n {0, 1} n 2 monotone Boolean functionconstant conjunction subset input bits. existassignment two bits restricted function disjunctiontwo bits.Proof: induction number bits function depends on. base case n = 2,monotone function constant conjunction subsetinput bits disjunction two input bits.Let xi variable f depends (which must exist since f constant). Let|x=af= f (a, xi ) denote function f restricted xi = a. denote h = f |xi =0|xg = f =1 . f monotone, f = x f |xi =1 + f |xi =0 = g x + h, f |xi =1 f |xi =0 (thatis, xi , f (0, xi ) = 1 f (1, xi ) = 1, f (1, xi ) = 0 f (0, xi ) = 0).h constant conjunction subset input bits, continueinduction using h setting x = 0. Similarly g constant conjunctionsubset input bits, continue induction using g setting x = 1.left case h g conjunctions subsetvariables (where constant 1 considered conjunction empty setvariables, easy verify h g cannot constant 0). Since f dependsxi , h = g, since h g, exists variable xj (j = i)358fiMixed Strategies Combinatorial Agencyset variables whose conjunction h g. set variablesxi xj 1, left xi + xj .2Theorem B.2 Let f monotone Boolean function n 2 inputs,constant conjunction subset input bits. exist parameters{i , }ni=1 POP structured technology parameters (andidentical cost c = 1) greater 1.0233.Proof: Lemma B.1 assignment two variables restrictedfunction two variables function. two variables chooseparameters according worst POP know technology (see Section 3).rest variables choose parameters valueworst utilities ratio achieved, rest agents exert eort provide successprobabilities (almost) success probabilities dictated assignment. Nextmake argument formal.Recall Lemma B.1 assignment two variablesrestricted function two variables function. Let i1 i2 indicestwo variables. Section 3 observed technology two agentsvalues v = 233, 1 = 2 = 0.0001 1 = 2 = 0.9, POP least 1.0233.embed instance technology n agents considering valuev = 233 success probabilities follows: agents i1 i1 , let i1 = i2 = 0.0001i1 = i2 = 0.9. rest agents, x suciently small > 0. set = 1= 1 2 set 1 assignment, set = 2 = set0 assignment.> 0 small enough payment needed induce every agent = i1 , i2exert eort (for prole eorts others) greater v inverselyproportional increase success probability due eort, goeszero . Thus, small enough agents = i1 , i2 exert eortoptimal contract, agent provide almost sure success caseassignment variable 1, almost sure failure case assignmentvariable zero. created technology essentially technologyagents i1 i2 i1 = i2 = 0.0001, i1 = i2 = 0.9, value v = 233POP least 1.0233.2Appendix C. Quantifying Gain MixingC.1 POP n Agentsobserve technology, POP bounded ratio successprobability agents exert eort, success probability none agentsexert eort. simple bound shows success probability none agentsexert eort least positive constant, POP bounded constant.Observation C.1 technology (t, c) set agents N , P OP (t)359t(N )t() .fiBabaioff, Feldman & NisanProof: given value v, utility principal optimal mixed Nashv t(N ), utility principal optimal pure Nash least)t(N )v t(), thus POP bounded vt(N2vt() = t() .point consider technologies identical costs. following lemmashows anonymous technologies well technology exhibits DRS POPn.Lemma C.2 Assume technology n agents following holds:optimal mixed contract q support S, pure prole supportt(a)t(S)|S|agent , pure prole b support R holds t(1, ai )t(0, ai ) t(1, bi ) t(0, bi ).P OP (t) n.Proof: rst observe P (a), total payment prole casesuccess, P (q), total payment prole q. S, set agentspaid subset set agents paid q. agentpaid least much q, paid (by second condition,increase success probability q convex combination increase successprobability pure proles support R S). Thus, P (a) P (q), U (a) > 0.concludet(q)(v P (q))t(q)t(S)u(q, v)|S|u(a, v)t(a)(v P (a))t(a)t(a)last inequality derived rst condition. implies POPbounded n.2Corollary C.3 anonymous technology n agents, P OP (t) n.Proof: Assume value v mixed prole q optimal, support sizek. Let tm success probability agents exert eort, let = tm tm1 . Let= argmaxmk .denition second condition holds. rst condition holds as:ktm k(t0 +tm t0 ) t0 +k(tm t0 ) t0 +k(tm tm1 ) = t0 +km t0 +(tk t0 ) = tk2Corollary C.4 technology n agents exhibits DRS identicalcosts, P OP (t) n.Proof: Let agent agent maximal individual contribution S, supportq (t({i}) t({j}) j S). DRS ensures two conditions Lemma C.2hold.2following holds technology n agents (even non-anonymous), exhibits DRS. particular, even single agent > 1/2 get bound 2POP.360fiMixed Strategies Combinatorial AgencyObservation C.5 Assume technology n agents (with identical costs) exhibitst(N )DRS, P OP (t) t({i}), agent maximal individual contribution (t({i})t({j}) j N ).Proof: Let agent j agent maximal individual contribution S, supportq. Following proof Lemma C.2, t({i}) t({j}) P (q) P ({j}) P ({i}),u(q, v) > 0 ,this implies u({i}, v) u({j}, v) > 0. Thus optimal pure contractgives utility least u({i}, v) > 0, therefore v boundu(q, v)u(q, v)t(q)(v P (q))t(S)t(N )=u(a , v)u({i}, v)t({i})(v P ({i}))t({i})t({i})implies POP boundedt(N )t({i}) .2Corollary C.6 anonymous technology n agents exhibits DRS, holdsP OP (t) ttn1 .C.2 POP Anonymousexhibits DRS, following direct corollary Observation C.5.Corollary C.7 anonymous technology n agents, holds P OP (OR)tnt1 .Theorem 5.7 anonymous technology n agents:n1. 1 > > > 0: (a) P OP 1(1)n (n 1). (b) POP goes 1 n goes(for xed ) goes 1 (for xed n 2).2.12> = 1 > 0: (a) P OP0 goes122(32 3)(=3( 32)1.154..). (b) POP goes 1 goes(for xed n 2).Proof: Based Corollary C.7, P OPt(1n ),t(1,0n1 )results based bound.1. Proof part 1(a):t(1n )1 (1 )n1 (1 )n1 (1 )n==t(1, 0n1 )1 (1 )(1 )n11 (1 )Additionally,1 (1 )n=(1 )j = 1 +(1 )j 1 +(1 ) = n (n 1)1 (1 )n1n1n1j=0j=1j=1concludes proof.361fiBabaioff, Feldman & Nisan2. Proof part 1(b):t(1n )1 (1 )n=t(1, 0n1 )1 (1 )(1 )n1expression goes 1 xed > > 0, n goes , (1 )n(1 )n1 goes zero.1(1)n,Additionally, saw P OPgoes 1, POP goes 1.thus clear n xed3. Proof part 2(a): rst bound POP case anonymous 2agents = 1 < 1/2. case POP boundedt(1, 1)(2 )= 2t(0, 1)+12derivative ratio (223 1.2 +1)2 , equals zero =maximum point since second derivative negative, ratio pointequals 1.154... Therefore, t(1,1)t(1,0) 1.154... Observation C.8 showsn 2 holdst(1n )t(1,0n1 )t(1,1)t(0,1)4. Proof part 2(b): expressionthus bound holds n.t(1n )t(1,0n1 )=1 n1(1)n1goes 1 goes 012.2anonymous technology n agents = 1 < 1/2 boundPOP 1.154...Observation C.8 Let ORn, denote anonymous technology n agents =1 < 1/2. k 3 holdsP OP (ORk, )ORk, (1k )ORk1, (1k1 )ORk, (1, 0k1 )ORk1, (1, 0k2 )thus k 3 holdsP OP (ORk, )ORk, (1k )OR2, (1, 1)1.154...k1ORk, (1, 0 )OR2, (1, 0)Proof: technology ORk, holdsORk, (1k )1 k=ORk, (1, 0k1 )1 (1 )k1Thus need show k 31 k1 k11 (1 )k11 (1 )k2362fiMixed Strategies Combinatorial Agencyholds1 k (1 )k2 + k+1 (1 )k2 1 k1 (1 )k1 + k (1 )k1holdsk1 (1 ) + (1 )k2 (1 (1 )) + k (1 )k2 ((1 ) ) 0dividing 2 (1 ), holdsk3 + (1 )k3 + k2 (1 )k3 (1 2 ) 0holds 1 thus (1 )k3 k3 k2 (1 )k3 (1 2 ) 0.2C.3 POP 2 AgentsLet us consider case n = 2, prove better bound POP.shown POP IRS technology 1. Since anonymous technology 2 agentsexhibits either IRS DRS, need handle DRS case. Let 1 = t1 t02 = t2 t1 . Assume 1 = 2 1 (DRS).following corollary Lemma 5.3.Corollary C.9 DRS technology 2 agents, assume w.l.o.g. t({1}) t({2})denote 1 = t({1}) t(). mixed prole q = (q1 , q2 ) holds agentpaid least c1 .Proof: t({1}) t({2}) implies 1 = t({1}) t() t({2}) t(), DRSimplies 1 = t({1}) t() t({1, 2}) t({1}) t({2}) t() t({1, 2}) t({2}),2thus Lemma 5.3 implies agent paid least c1 .Theorem C.10 anonymous technology 2 agents, holds P OP (t)3/2.Proof: Let u((q1 , q2 ), v) utility principal mixed prole (q1 , q2 ) valueproject v. Let P (q1 , q2 ) denote total payment agents projectsuccessful. Similarly, let u((a1 , a2 ), v) utility principal pure prole (a1 , a2 )value v.given value v, let (q1 , q2 ) optimal mixed contract, let (a1 , a2 )u((q1 ,q2 ),v)optimal pure contract. show value v holds u((a3/2,1 ,a2 ),v)sucient prove theorem.optimal mixed prole pure prole, ratio 1, thus need handlecase prole (q1 , q2 ) pure (a non-degenerate mixed contract). case,u((q1 , q2 ), v) = t(q1 , q2 )(vP (q1 , q2 )) > 0, holds vP (q1 , q2 ) > 0. corollary C.9implies u((1, 0), v) > 0 P (q1 , q2 ) c1 . Thus u((a1 , a2 ), v) u((1, 0), v) > 0,u((q1 , q2 ), v)u((q1 , q2 ), v)t(q1 , q2 )(v P (q1 , q2 ))t(q1 , q2 )t(1, 1)t2=cu((a1 , a2 ), v)u((1, 0), v)t(1, 0)(v 1 )t(1, 0)t(1, 0)t1363fiBabaioff, Feldman & Nisanconsider two cases. First consider case t0 2 . caset2t0 + 1 + 22 + 2 + 22+13u((q1 , q2 ), v)===1+u((a1 , a2 ), v)t1t0 + 12 + 21+1+2replace t0 2 use Lemma C.13.Next consider case t0 < 2 . case look value vprincipal independent contracting 1 2 agents. v = v holdsct(1, 0) (v c1 ) = t(1, 1) (v 2c2 ), thus v 2 = v (t2 t1 ) = t2 2c2 t1, thus2cholds v = (2 )2 (2 t2 t1 ). value v v enough bound ratio1 ,q2 ),v)value v v enough bound ratio u((qu((1,1),v) . boundratios separately.21 +2Lemma C.13, case 0 t0 < 2 , tt21 = t0 +(1+)= 1 + 1 .t0 +12value v v)(v 2c1u((q1 , q2 ), v)t(q1 , q2 )(v P (q1 , q2 ))t2 v P (q1 , q2 )11+u((1, 0), v)t(1, 0)(v c1 )t1v c1v c1)) ((111 v1+c 1 1u((q1 ,q2 ),v)u((1,0),v) ,Now,2t2vc=2t0 +(1+)21=1 122 +(1+)21(2(2 )2=12+ ,conclude122==2 t2 t1 2(2 1) t2t2 t1 ) 11(2 1)(2 + )Thusu((q1 , q2 ), v)u((1, 0), v)(11+) (1vc11 1)(11+) (11(2 1)(2 + ))Lemma C.11 shows function RHS bounded 3/2 1.1 ,q2 ),v)Finally, value v v , enough bound ratio u((qu((1,1),v) .vu((q1 , q2 ), v)t(q1 , q2 )(v P (q1 , q2 ))=2cu((1, 1), v)t(1, 1)(v 2 )v2c12c2=vv2c22c2Intuitively, fraction goes 1 goes 1, implies suciently smallfraction less 3/2. Formally,v2c22c2=1+v)(11+22c2v2(2(2 )22c22c22(1 1 )1+2=1+ vc 2 2(1)vc12 212( 1)22( 1)21+=1+22(2 1)t1t2 t1 ) 2212364fiMixed Strategies Combinatorial Agency1+2( 1)(2 1)2(1)nd maximum RHS. derivative 1 + (21)maximum obtained = 1 += 1 +22 ),222(22 4+1).(21)2 2(it maximum second derivative negativemaximum 1 +2(1+ 2)(1+ 22 )2< 1.35.Lemma C.11 1 holds() ()111+13/2(2 1)(2 + )Proof:(f () =Let h() =3+ 34 ,11+22 +33(21) .) (11(2 1)(2 + ))(=derivative h()11+2)82 +123,2 (21)222 + 3 3(2 1)maximumvalue maximum lower 2.072.1look = 8/5. function 1 +2increasing function (for 1),()1get , f () 1 +2 2.072 = 1318 2.072 < 3/2 concludeproof show f () decreasing function , = 8/5. derivativef ()2(24 + 43 42 9 + 3)2 (2 1)2 (2 + )2Thus need show 24 + 43 42 9 + 3 > 0 = 8/5.holds 43 42 = 42 (1) > 0 > 1, 24 9+3 24 9+3 = 1067625 > 043(as function 2 9 + 3 derivative 8 9 positive91/3 /2, thus monotonically increasing function = 8/5 > 1.05 > 91/3 /2).2Theorem C.12 technology (even non-anonymous) 2 agents identicalcosts, holds P OP (t) 2.Proof: technology anonymous, already proved stronger claim. Assumenot, w.l.o.g. assume t(1, 0) t(0, 1). shown prole(0, 1) never optimal, implies (by argument seen casetechnology anonymous),P OPu((q1 , q2 ), v)u((q1 , q2 ), v)t(1, 1)u((a1 , a2 ), v)u((1, 0), v)t(1, 0)technology exhibits IRS, know POP=1. conclude proof showt(1,1)technology exhibits IRS t(1,1)t(1,0) 2. Assume t(1,0) > 2,show technology exhibits IRS. true sincet(1,1)t(1,0)> 2 implies:t(1, 1) t(1, 0) > t(1, 0) t(1, 0) t(0, 0)365fiBabaioff, Feldman & Nisant(1, 0 > t(0, 1) also holdst(1, 1) t(0, 1) > t(1, 1) t(1, 0) t(1, 0) t(0, 1) t(0, 1) t(0, 0)2implies IRS.Lemma C.13 b 0 x > 0a+xa+yb+xb+y .Appendix D. Robustness Mixed Nash EquilibriaTheorem 6.2 mixed optimal contract q includes least two agents truly mix(i, j s.t. qi , qj (0, 1)), q strong equilibrium.Proof: Let Q support q (i.e., Q = {i|qi > 0}), let k = |Q|. Recallcioptimal payments induce strategy prole q pi = (q(where (qi ) =)t(1, qi ) t(0, qi )) Q, pi = 0 N \ Q. Let = {i|qi (0, 1)}(|| 2 assumption), consider deviation coalition pure strategyprole q , , qi = 1. q denote new prole (i.e., q = (q , q )).next show , ui (q) < ui (q ), thus q resilient deviation. Since qi (0, 1), must indierent ai = 0 ai = 1 (see claim 2.1);therefore, utility q is:ui (q) = ui (0, qi ) = cit(0, qi )(qi )utility q is:ciui (q ) = t(q )pi ci = t(q )ci = ci(qi )(t(q )1(qi ))(= cit(q ) t(1, qi ) + t(0, qi )(qi ))Therefore, ui (q ) > ui (q) t(q ) t(1, qi ) > 0, holds assumption|| 2 monotonicity t.2Appendix E. Algorithmic AspectsE.1 Results Mixed Casenext show black box model, exponential number queries neededdetermine optimal mixed contract. proved optimal pure contract(for completeness present claim Theorem E.2, taken (Babaio et al., 2006a)),show also holds mixed case.Theorem 7.1 Given input black box success function (when costsidentical), value v, number queries needed, worst case, ndoptimal mixed contract exponential n.Proof: show optimal mixed contract technology presented Theorem E.2 value c(k + 1/2) support exactly , thus claim direct resultTheorem E.2.366fiMixed Strategies Combinatorial AgencyAssume q optimal mixed contract value c(k + 1/2). support q mustsize k, otherwise payment case success least c(k +1) > c(k +1/2)(as agent support must paid least c), implies negative utility.support size k exactly , least one agentpaid c/ > c(k + 1/2) suciently small > 0. Thus case utilitynegative.2Next show read-one network optimal mixed contract #P -hard.based theorem work Babaio et al. (2006a) cited Theorem E.3 below.Theorem 7.2 Optimal Mixed Contract Problem Read Networks #P -hard(under Turing reductions).Proof: use reduction presented Theorem E.3. prove x close enough1/2, transition point E E {x} pure case, optimal mixedcontract pure (also E E {x}). implies use argumentTheorem E.3 calculate network reliability (which #P -hard) using algorithmoptimal mixed contract.Lemma E.1 presents generalization lemma work Babaio et al.(2006a) mixed case. lemma implies value v x rst enteredsupport optimal mixed contract q, contract x optimal valuev t(E). single edge, optimal mixed contracts pure, thus x exertseort probability 1. Additionally, contract original graph (with edges E)optimal value v (1 x ), thus x close enough 1/2, v large enoughoptimal mixed contract agents exerting eort probability 1 (pure).2Let g h two Boolean functions disjoint inputs let f = g h (i.e., takenetworks series). optimal mixed contract f v, denoted qS ,composed h-part g-part, call mixed prole parts qT qRrespectively.Lemma E.1 Let qS optimal mixed contract f = g h v. Then, qToptimal mixed contract h v tg (qR ), qR optimal mixed contract gv th (qT ).proof proof pure case, presented work Babaio et al.(2006b).E.2 Results work Babaio et al. (2006b) Pure Casefollowing results cited work Babaio et al. (2006b), completeness.Theorem E.2 Given input black box success function (when costsidentical), value v, number queries needed, worst case, ndoptimal contract exponential n.Proof: Consider following family technologies. small > 0 k = n/2dene success probability given set follows. |T | < k, t(T ) = |T | .|T | > k, t(T ) = 1 (n |T |) . set agents size k, technologytT dened t(T ) = 1 (n |T |) t(T ) = |T | = size k.367fiBabaioff, Feldman & Nisanvalue v = c (k + 1/2), optimal contract tT (for contractutility principal v c k = 1/2 c > 0, contract utilitynegative).( n )2 sets size k, cannot alwaysalgorithm queries n/2determine optimal contract (as( n of) sets queried mightoptimal one). conclude n/21 queries needed determine optimalcontract, exponential n.2Let t(E) denote probability success edge succeeds probabilitye . rst notice even computing value t(E) hard problem: callednetwork reliability problem known #P hard (Provan & Ball, 1983).little eort reveal problem easier:Theorem E.3 Optimal Contract Problem Read Networks #P -hard (underTuring reductions).Proof: show algorithm problem used solve networkreliability problem. Given instance network reliability problem < G, {e }eE >(where e denotes es probability success), dene instance optimal contractproblem follows: rst dene new graph G obtained Anding Gnew player x, x close 12 x = 1 x . edges, let e = ee = e /2. choosing x close enough 12 , make sure player x enteroptimal contract large values v, agents contracted (ifnd optimal contract value, easy nd valueoriginal network optimal contract E, keep doubling value askingclargeroptimal contract. nd value, choose x s.t. 12xvalue). Let us denote x = 1 2x .critical value v player x enters optimal contract G , foundusing binary search algorithm supposedly nds optimal contractnetwork value. Note critical value v, principal indierentset E E {x}. write expression indierence, termst(E) ti (E) , observe following.(t(E)x viEcx ti (E \ i))(= t(E)(1x ) viEcc(1 x ) ti (E \ i) t(E) x)(1 x ) c(x )2 vthus, always nd optimal contract also able compute valuet(E).2t(E) =ReferencesAumann, R. (1959). Acceptable Points General Cooperative n-Person Games. Contributions Theory Games, Vol. 4.368fiMixed Strategies Combinatorial AgencyBabaio, M., Feldman, M., & Nisan, N. (2006a). Combinatorial agency. ACM EC06,pp. 1828.Babaio, M., Feldman, M., & Nisan, N. (2006b). Combinatorial agency. Full version.Feldman, M., Chuang, J., Stoica, I., & Shenker, S. (2007). Hidden-Action Multi-HopRouting.. IEEE JSAC Special Issue Non-Cooperative Behavior Networking.Harsanyi, J. C. (1973). Games randomly disturbed payos: new rationale mixedstrategy equilibrium points. International Journal Game Theory, 2 (1), 123.Holmstrom, B. (1982). Moral Hazard Teams. Bell Journal Economics, 13, 324340.Mass-Colell, A., Whinston, M., & Green, J. (1995). Microeconomic Theory. Oxford University Press.Nisan, N., & Ronen, A. (2001). Algorithmic mechanism design. Games EconomicBehaviour, 35, 166 196. preliminary version appeared STOC 1999.Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. V. (2007). Algorithmic GameTheory. Cambridge University Press.Provan, J. S., & Ball, M. O. (1983). complexity counting cuts computingprobability graph connected. SIAM J. Comput., 12 (4), 777788.Strausz, R. (1996). Moral hazard sequential teams. Departmental Working Paper. FreeUniversity Berlin.Winter, E. (2004). Incentives Discrimination. American Economic Review, 94, 764773.369fiJournal Articial Intelligence Research 38 (2010) 85-133Submitted 05/09; published 05/10BnB-ADOPT:Asynchronous Branch-and-Bound DCOP AlgorithmWilliam Yeohwyeoh@usc.eduComputer Science Department,University Southern California,Los Angeles, CA 90089, USAAriel Felnerfelner@bgu.ac.ilInformation Systems Engineering,Deutsche Telekom Labs,Ben-Gurion University Negev,Beer-Sheva, 85104, IsraelSven Koenigskoenig@usc.eduComputer Science Department,University Southern California,Los Angeles, CA 90089, USAAbstractDistributed constraint optimization (DCOP) problems popular way formulatingsolving agent-coordination problems. DCOP problem problem several agents coordinate values sum resulting constraint costs minimal. oftendesirable solve DCOP problems memory-bounded asynchronous algorithms. introduce Branch-and-Bound ADOPT (BnB-ADOPT), memory-bounded asynchronous DCOP searchalgorithm uses message-passing communication framework ADOPT (Modi, Shen,Tambe, & Yokoo, 2005), well known memory-bounded asynchronous DCOP search algorithm,changes search strategy ADOPT best-first search depth-first branch-and-boundsearch. experimental results show BnB-ADOPT finds cost-minimal solutions oneorder magnitude faster ADOPT variety large DCOP problems fastNCBB, memory-bounded synchronous DCOP search algorithm, DCOPproblems. Additionally, often desirable find bounded-error solutions DCOP problemswithin reasonable amount time since finding cost-minimal solutions NP-hard. existing bounded-error approximation mechanism allows users specify absolute error boundsolution cost relative error bound often intuitive. Thus, present twonew bounded-error approximation mechanisms allow relative error bounds implementtop BnB-ADOPT.1. Introductiondistributed constraint optimization (DCOP) problem consists agents, responsible taking(= assigning itself) value nite domain values. agents coordinate values,subject constraints. Two agents constrained share constraint.constraint associated constraint cost, depends values constrained agents.(complete) solution assignment values agents, partial solution assignmentvalues subset agents. solution cost (partial complete) solution sumconstraint costs constraints resulting given assignment values agents. SolvingDCOP problem optimally means nding solution minimal solution cost NP-hard (Modiet al., 2005).Formulating agent-coordination problems constraint optimization (COP) problems, specictype weighted constraint satisfaction problems (Schiex, Fargier, & Verfaillie, 1995; Bistarelli,c2010AI Access Foundation. rights reserved.fiYeoh, Felner & Koeniga1a2a3a1a4a2a3(a)a4a10011a20011a20101a30101Constraint Cost58203Constraint Cost5433(b)a10011a20011a30101a40101Constraint Cost510203Constraint Cost38103(c)Figure 1: Example DCOP ProblemMontanari, Rossi, Schiex, Verfaillie, & Fargier, 1999), general formulatingcommon constraint satisfaction problems (Dechter, 2003). Constraint satisfaction problemsconstraints either satised unsatised. Solving constraint satisfaction problemmeans nding solution constraints satised. example applicationscheduling jobs job-shop, constraints express jobs performedcertain machines jobs performed jobs. couldpotentially multiple solutions satisfy constraints. However, solutions mightdesirable others. example, one might prefer solution shortest completion time.Unfortunately, constraint satisfaction problems cannot capture preferences. However, COPproblems able using constraint costs represent preferences.DCOP algorithms better suited compared COP algorithms problems naturally distributed. result, DCOP algorithms applied coordinating unmannedaerial vehicles (Schurr, Okamoto, Maheswaran, Scerri, & Tambe, 2005), scheduling meetings (Maheswaran, Tambe, Bowring, Pearce, & Varakantham, 2004b; Petcu & Faltings, 2005b; Greenstadt,Grosz, & Smith, 2007; Zivan, 2008; Yeoh, Varakantham, & Koenig, 2009), coordinating sensor networks (Lesser, Ortiz, & Tambe, 2003; Zhang, Xing, Wang, & Wittenburg, 2003; Modi et al., 2005;Jain, Taylor, Tambe, & Yokoo, 2009; Stranders, Farinelli, Rogers, & Jennings, 2009; Zivan, Glinton,& Sycara, 2009), synchronizing trac lights (Junges & Bazzan, 2008), planning truck routes (Ottens& Faltings, 2008) managing power distribution networks (Kumar, Faltings, & Petcu, 2009).common visualize DCOP problem constraint graph verticesagents edges constraints. DCOP algorithms operate pseudo-tree,spanning tree (completely connected) constraint graph property edgesconstraint graph connect vertex one ancestor descendant verticesconstraint tree (Freuder & Quinn, 1985; Bayardo & Miranker, 1995). edge constraintgraph part pseudo-tree backedge. agent c pseudo-child agentagent p agent c descendant agent agent p pseudo-tree constrainedvia backedge. Similarly, agent p pseudo-parent agent agent c. Sibling subtrees representindependent DCOP subproblems (since two agents dierent sibling subtrees share constraint).Figure 1(a) shows constraint graph example DCOP problem four agentstake value 0 value 1, Figure 1(b) shows one possible pseudo-tree assignmentsvalues agents a3 a4 independent DCOP subproblems (the dotted line backedge),Figure 1(c) shows constraint costs. example DCOP problem, cost-minimal solutionresults agents take value 1. minimal solution cost 12.1.1 DCOP Algorithmsprovide taxonomy DCOP algorithms. Figure 2 shows taxonomy. DCOP algorithmsdivided two groups: complete incomplete DCOP algorithms. Complete DCOP algorithms nd cost-minimal solutions incomplete DCOP algorithms often faster typicallynd suboptimal solutions.86fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmDCOP AlgorithmsIncomplete Algorithmse.g., DBA, DSA, MGM,k-optimal algorithmsComplete AlgorithmsPartially Centralized Algorithmse.g., OptAPOFully DecentralizedAlgorithmsSearch Algorithmse.g., SBB, ADOPT,NCBB, AFBInference Algorithmse.g., DPOPFigure 2: Taxonomy DCOP Algorithms1.1.1 Incomplete DCOP AlgorithmsIncomplete DCOP algorithms typically use local search nd locally optimal solutionsthus potentially get trapped local minima. Nevertheless, since solving DCOP problems optimallyNP-hard, DCOP algorithms desirable large DCOP problems nding costminimal solutions might slow. DBA (Yokoo & Hirayama, 1996), DSA (Fitzpatrick & Meertens,2003), MGM (Maheswaran, Pearce, & Tambe, 2004a) recent class k-optimal DCOPalgorithms (Pearce & Tambe, 2007; Bowring, Pearce, Portway, Jain, & Tambe, 2008; Greenstadt,2009) examples incomplete DCOP algorithms.1.1.2 Complete DCOP AlgorithmsComplete DCOP algorithms generally divided two groups, namely partially centralizedfully decentralized DCOP algorithms.Partially Centralized DCOP AlgorithmsPartially centralized DCOP algorithms allow agents transfer constraint information(= information regarding constraints involved in) central agent processing. OptAPO (Mailler & Lesser, 2004) example partially centralized DCOP algorithmuses cooperative mediation, certain agents act mediators solve overlapping DCOPsubproblems centrally.Fully Decentralized DCOP AlgorithmsFully decentralized DCOP algorithms central agents collect constraint information agents constrained them. Rather, every agent accessconstraint information. Fully decentralized DCOP algorithms generally divided twogroups, namely DCOP inference search algorithms.DCOP inference algorithms: DCOP inference algorithms typically use dynamic programming propagate aggregated constraint costs one agent another agent thus reduce87fiYeoh, Felner & KoenigDCOPAlgorithmSBBADOPTNCBBAFBBnB-ADOPTSearchStrategyDFBnBbest-firstDFBnBDFBnBDFBnBAgentOperationsequential & synchronousconcurrent & asynchronoussequential & synchronousconcurrent & asynchronousconcurrent & asynchronousCommunicationpoint-to-point neighborspoint-to-point neighborspoint-to-point neighborsbroadcast agentspoint-to-point neighborsAgentOrderingchaintreetreechaintreeTable 1: Properties DCOP Search AlgorithmsDCOP problem size one agent step. repeat procedure DCOPproblem size reduced one agent solution space (= space possible partial solutions) thus cannot reduced anymore. sole remaining agent sucientknowledge nd cost-minimal solution. DPOP (Petcu & Faltings, 2005b) exampleDCOP inference algorithm. number messages sent agents linearnumber agents. However, memory requirements exponential inducedwidth DCOP problem. induced width depends number backedgespseudo-tree. large number agents minus one constraint graphfully connected every agent thus constrained every agent.DCOP search algorithms: DCOP search algorithms use search strategies searchsolution space nd cost-minimal solution. ADOPT (Modi et al., 2005) uses best-rstsearch, SBB (Hirayama & Yokoo, 1997), NCBB (Chechetka & Sycara, 2006), AFB (Gershman, Meisels, & Zivan, 2009) new DCOP search algorithm, BnB-ADOPT, usedepth-rst branch-and-bound search. memory requirements polynomialnumber agents. However, number messages sent agents exponentialnumber agents.Therefore, groups fully decentralized DCOP algorithms desirable dierentconditions tradeo space (memory requirements) time (number messagessent).1.2 Motivationdescribe motivation behind work.1.2.1 BnB-ADOPTstudy DCOP search algorithms memory-bounded. property important applications, sensor networks, every agent/sensor xed amountmemory available. result, several DCOP search algorithms, SBB, ADOPT, NCBBAFB, developed limitation mind. described earlier, memory requirementspolynomial number agents. Table 1 shows properties DCOP search algorithms well properties new DCOP search algorithm, BnB-ADOPT. describeproperty detail justify properties BnB-ADOPT.Search strategy: ADOPT uses best-rst search search solution space, SBB,NCBB AFB use depth-rst branch-and-bound (DFBnB) search. Best-rst search repeatedly searches next best partial solution nds cost-minimal solution. nextbest partial solution cost-minimal partial solution among partial solutionsyet found. Depth-rst branch-and-bound search starts nding complete (but88fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithmoften suboptimal) solution stores solution cost upper bound. continuessearch solution whose solution cost less upper bound. stores solutioncost solution upper bound, search proceeds longer ndsolution whose solution cost less upper bound.centralized search, known search problems depth-bounded search treesoften solved faster depth-rst branch-and-bound search memory-boundedbest-rst search memory-bounded best-rst search algorithms, RBFS (Korf,1993), need repeatedly reconstruct partial solutions purged memory. Depthrst branch-and-bound search algorithms memory-bounded suerproblem (Zhang & Korf, 1995). Since DCOP problems search problems depthbounded search trees, hypothesize depth-rst branch-and-bound search might fasterbest-rst search. Therefore, decided BnB-ADOPT use depth-rst branchand-bound search.Agent operation: Agents SBB NCBB operate sequentially. agents tokensactive agents remain idle. token-holding agents done, passtokens remain idle. hand, agents ADOPT AFB operateconcurrently (= times). Agents operate concurrently might able solve DCOPproblems faster agents operate sequentially since former agents performpotentially useful computation instead wait agents. Therefore,decided agents BnB-ADOPT operate concurrently. Agents SBB NCBBalso operate synchronously. Communication agents often form messages.Synchronous agents operate cycles (Modi et al., 2005). cycle time requiredagent process incoming messages queue send outgoing messages,processed receiving agents next cycle (see Section 6.1 details).Therefore, agents wait last agent done sending messages startnew cycle. hand, asynchronous agents, agents ADOPT AFB,able operate independently other, often increases robustness (Silaghi,Landwehr, & Larrosa, 2004). example, synchronous agents aected singlecommunication link suers congestion small number asynchronous agentsaected. therefore decided agents BnB-ADOPT operate asynchronously.Communication:DCOP search algorithms SBB, ADOPT NCBB restrictcommunication agents share constraints. restriction motivated applicationssensor networks communication restricted neighboring agents/sensors duelimited communication radius. Neighboring sensors share constraints since needcoordinate sense areas near them. DCOP search algorithms AFBrestriction allow agents broadcast messages agents. decidedagents BnB-ADOPT obey restrictions applications sensor networksthus communicate neighboring agents.Agent ordering: DCOP search algorithms mentioned start pre-processingstep arranges agents pseudo-tree. DCOP search algorithms SBBAFB arrange agents chain, ADOPT NCBB arrange agents tree.tree ordering capture independent DCOP subproblems (represented sibling subtrees)chain ordering not. DCOP search algorithms operate trees thusoperate independent DCOP subproblems independently, DCOP search algorithmsoperate chains not. Therefore, decided BnB-ADOPT arrangeagents tree.ADOPT preferred properties mentioned except uses best-rst search.therefore introduce BnB-ADOPT, memory-bounded asynchronous DCOP search algorithm89fiYeoh, Felner & Koeniguses message passing communication framework ADOPT changes search strategyADOPT best-rst search depth-rst branch-and-bound search.1.2.2 Bounded-Error ApproximationsSolving DCOP problems optimally NP-hard, makes advantageous allow users tradesolution cost smaller runtime. also desirable error resulting solutioncost bounded provide guarantees solution cost. ADOPT is, best knowledge,DCOP search algorithm property. Absolute Error Mechanism allows usersspecify absolute error bound solution cost, example, solution cost10 larger minimal solution cost. However, often much desirablespecify relative error bound solution cost, example, solution cost10 percent larger minimal solution cost or, equivalently, 1.1 times largerminimal solution cost. cannot done Absolute Error Mechanism without knowingminimal solution cost priori. Thus, propose two approximation mechanisms allow usersspecify relative error bound solution cost, namely Relative Error MechanismWeighted Heuristics Mechanism, implement top BnB-ADOPT. approximationmechanisms allow BnB-ADOPT nd solutions bounded errors faster cost-minimalsolutions.1.3 Experimental Resultsexperimentally compare ADOPT, BnB-ADOPT NCBB three dierent DCOP problemtypes, namely graph coloring problems, sensor network problems meeting scheduling problems.results show BnB-ADOPT one order magnitude faster (measured numbernon-concurrent constraint checks number cycles) ADOPT variety largeDCOP problems. BnB-ADOPT also inferred faster SBB since ADOPT fasterSBB (Modi et al., 2005). BnB-ADOPT also fast NCBB DCOPproblems. results suboptimal variants BnB-ADOPT show Weighted HeuristicsMechanism dominates Absolute Error Mechanism Relative Error Mechanism.1.4 Article Structurearticle organized follows: formalize DCOP problems Section 2 describeDCOP search algorithm, BnB-ADOPT, Section 3. describe approximation mechanismsallow BnB-ADOPT nd solutions bounded error Section 4. outline correctnesscompleteness proofs BnB-ADOPT Section 5. Lastly, present experimental evaluationsSection 6 conclusions Section 7.2. DCOP Problemssection, formally dene distributed constraint optimization (DCOP) problems describesolution space.2.1 Definition DCOP ProblemsDCOP problem dened following elements:nite set agents = {a1 , a2 , ..., };set nite domains = {Dom(a1 ), Dom(a2 ), ..., Dom(an )}, Dom(ai ) domainpossible oating point values agent ai A;90fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithma100ba2a2BC58a310 14a4320a38813a3a4103325a473a3823a46c103gEheFjk(a)GlfHnpqJrKuv(b)Figure 3: AND/OR Search Treeset binary constraints F = {f1 , f2 , ..., fm }, constraint fi : Dom(ai1 )Dom(ai2 ) R+ , species non-negative constraint cost function valuesdistinct agents ai1 ai2 share constraint.denition assumes agent takes one value rather multiple values,example, dierent value constraint involved in. DCOP problemscommonly formulated agent responsible assignments valuesmultiple variables. However, exist techniques reduce DCOP problems DCOPproblems (Burke & Brown, 2006). Thus, use terms agent variable interchangeably.denition also assumes constraints binary (= two agents) rather n-ary(= n agents). One able extend BnB-ADOPT solve DCOP problems nary constraints using techniques proposed extend ADOPT solve DCOPproblems n-ary constraints (Modi et al., 2005). Additionally, assume messages sentagents delayed nite amount time never lost.2.2 Search Treessolution space DCOP problems visualized search trees. Traditional search treesor, synonymously, search trees (Marinescu & Dechter, 2009) assign values agents sequentially.utilize fact values agents belong independent DCOP subproblemsassigned sequentially. AND/OR search trees based pseudo-trees remedyissue (Marinescu & Dechter, 2009). Thus, use AND/OR search trees refersearch trees article. depth bounded (twice) number agents.Figure 3(a) shows search tree based pseudo-tree Figure 1(b). Figure 3(b)labels node search tree identier allow us refer nodes easily. Circularnodes nodes (labeled upper-case letters) correspond agents. example,agent node C agent a2 . Left branches nodes correspond agents taking value0 right branches correspond agents taking value 1. Square nodes nodes(labeled lower-case letters) correspond partial solutions root nodenodes. example, partial solution node f {(a1 , 1), (a2 , 1)}. subtree rootednode represents DCOP subproblem assumes partial solution node.example, subtree rooted node f represents DCOP subproblem assigning valuesagents a3 a4 given {(a1 , 1), (a2 , 1)}. number independent DCOP subproblemswithin DCOP subproblem indicated number branches exiting node.example, two branches exiting node f , indicating two independent DCOPsubproblems, namely assigning values agents a3 a4 . numbers nodesdelta costs nodes. delta cost node dened sumconstraint costs constraints partial solution involve agent parent node.91fiYeoh, Felner & Koenigexample, partial solution node v {(a1 , 1), (a2 , 1), (a4 , 1)}. two constraintspartial solution, namely constraint agents a1 a2 , constraint cost 3,constraint agents a2 a4 , also constraint cost 3. Since parentnode node v node K agent a4 , delta cost node v 3, namely constraint costlatter constraint. former constraint included since involve agent a4 .solution cost partial solution node sum delta costs nodesalong branch root node node. example, solution cost partialsolution node v (= 6) sum delta costs nodes b, f v. example DCOPproblem, cost-minimal solution union partial solutions nodes v (all agentstake value 1). Thus, minimal solution cost (= 12) sum delta costs nodes b, f ,v.3. BnB-ADOPTsection, present Branch-and-Bound ADOPT (BnB-ADOPT). describe BnBADOPT modication ADOPT since approach requires readers in-depthunderstanding ADOPT. Instead, give stand-alone description BnB-ADOPT requiresknowledge ADOPT, intention creating self-contained hopefully easy-to-readdescription.3.1 Search Strategies ADOPT BnB-ADOPTrst describe centralized versions search strategies ADOPT BnB-ADOPT omittechnical details since described detail later sections.3.1.1 Search Strategy ADOPTADOPT (Modi et al., 2005) popular DCOP search algorithm (Modi & Ali, 2004; Ali, Koenig,& Tambe, 2005; Bowring, Tambe, & Yokoo, 2006; Davin & Modi, 2006; Pecora, Modi, & Scerri,2006; Choxi & Modi, 2007; Silaghi & Yokoo, 2009; Matsui, Silaghi, Hirayama, Yokoo, & Matsuo,2009) traverses search tree best-rst search order. describe simplied versionbest-rst search. complete version found (Marinescu & Dechter, 2007). Bestrst search maintains list initially contains child nodes root node.repeatedly performs following operations: expands node smallest solutioncost list removing node list adding grandchild nodesnode list. example DCOP problem, best-rst search expands nodessearch tree Figure 3 rst time following order, numbers parenthesesindicate solution costs partial solutions expanded nodes: (0), b (0), f (3), c (5),v (6), (8), (8) (9).Figure 4 shows simplied trace ADOPT example DCOP problem. ADOPT terminatesfteen steps minimal solution cost 12. numbers nodes delta costsrnodes. lower bound LBXr optimistic estimate minimal solution cost.smallest underestimated solution cost, solutions. underestimated solution costsolution sum delta costs nodes solution whose parent noderoot node whose grandparent node expanded. example, underestimatedsolution cost solution {(a1 , 1), (a2 , 1), (a3 , 1), (a4 , 1)} 3 node b expanded nodes f ,rv expanded. upper bound U BXr pessimistic estimate minimal solutioncost. solution cost solution smallest solution cost found far. ADOPTrrterminates upper bound U BXr larger lower bound LBX r . ordermemory-bounded, ADOPT maintains one branch search tree (shaded grey gure)root node currently expanded node thus needs repeatedly reconstruct nodes92fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmLBrXr = 0bBCcgEheFjkGlfHnpqrKuv00a2a25Ja38a410 14 3a38a18 13 10 3 25 7a30a2810 14 3=5= infinity0a4a383a48 13 10 3 25 73a120a3a4a38 23 6 10 3a300a28a410 14 3a3a308a410 14 3a3883a3a18 23 6 10 3a3a30a2810 14 3=8= infinity0a4a30810 14 3883a3a310 14 38= 12= infinity00a2a3a388 13 10 3 25 710 14 38a30a2810 14 3a38a38 13 10 3 25 73a43a38 23 6 10 3a338 13 10 3 25 7a300a28a410 14 3a3810 14 38a13a38 13 10 3 25 7a30a210 14 3820a4a38 13 10 3 25 700a2a310 14 38a4a3820a4a38 13 10 3 25 73a43a33a43a3a48 23 6 10 3Step 15Figure 4: Trace Simplied Memory-Bounded Best-First Search (Centralized ADOPT)93a48 23 6 10 3= 12= 120a3a48 23 6 10 3Step 14LBrXrUBrXr8a43a3a25a48 23 6 10 3a253a4a1 UBrXr = infinityStep 13a3LBrXr = 123a48 13 10 3 25 7Step 1220a420a3a4a48 23 6 10 3a25a4= 12= infinity083a3Step 11LBrXrUBrXra2a33a4a1 UBrXr = infinity8 23 6 10 30a4a3LBrXr = 8a3a25a420a43a48 13 10 3 25 7a1a48 23 6 10 30a4203a3a25a4=8= infinitya3a43a4Step 8LBrXrUBrXr0a3a3a1 UBrXr = infinity8 23 6 10 3a2a420a4820a4Step 10LBrXrUBrXr8a4305a48 23 6 10 3a2510 14 3a3LBrXr = 8a3a2Step 9a18a43a48 13 10 3 25 7a13a48 13 10 3 25 7a320a3a420a3a40a2Step 5a2a3a48 23 6 10 305a48 23 6 10 30a43a3a2Step 7a253a3a25a43a4a1 UBrXr = infinitya1 UBrXr = infinitya38 13 10 3 25 73a48 13 10 3 25 7Step 6LBrXrUBrXr20a4LBrXr = 83a48 13 10 3 25 7820a3a420a3a410 14 3a3Step 4a258a4LBrXr = 8=5= infinitya2LBrXr = 8a3Step 2LBrXrUBrXr05a4a1 UBrXr = infinity0a25a48 23 6 10 3a2Step 33a30a2Step 1a253a4a1 UBrXr = infinity20a3a4IdentifiersLBrXrUBrXrLBrXr = 3a1 UBrXr = infinityfiYeoh, Felner & KoenigLBrXr = 0bBCcgEheFjkGlfHnpqrKuv00a2a25Ja38a410 14 3a38a1a30a2810 14 3=0= infinity0a4a38 13 10 3 25 783a48 13 10 3 25 73a120a3a4a1a3a3a388 13 10 3 25 7810 14 3a3a18a33a38 23 6 10 3a310 14 380a210 14 38a30a28a410 14 3a38a38 13 10 3 25 73a43a3a48 13 10 3 25 73a38 23 6 10 3a3810 14 3800a2a38a410 14 3a3820a43a3a48 13 10 3 25 73a3a48 23 6 10 33a43a1 UBrXr = 1820a38 13 10 3 25 7Step 9a48 23 6 10 3LBrXr = 120a43a3a2a2a3a4Step 8LBrXr = 12UBrXr = 180a43a38 13 10 3 25 75a48 23 6 10 3a25a420a4a1 UBrXr = 183a3a120a4020a48 23 6 10 3LBrXr = 0=0= 180a43a3Step 5LBrXrUBrXr8a4a25a48 23 6 10 3a2a33a38 13 10 3 25 7Step 70a330a420a4a1 UBrXr = 18a3a25a4LBrXr = 3UBrXr = 188a483a48 13 10 3 25 7a13a4a2510 14 3a320a3a4Step 68a4LBrXr = 0=0= infinity0a420a3a4a3Step 2LBrXrUBrXra20810 14 3=0= 18a2a30a2Step 4LBrXrUBrXr0a40a25a48 23 6 10 305a48 23 6 10 3a253a3a2Step 3Step 1a253a4a1 UBrXr = infinity20a3a4IdentifiersLBrXrUBrXrLBrXr = 0a1 UBrXr = infinitya38 23 6 10 3Step 100a25a40a2a310 14 38a4a3820a4a38 13 10 3 25 73a43a3a48 23 6 10 3Step 11LBrXr = 12a1 UBrXr = 120a250a2a310 14 38a4a3820a4a38 13 10 3 25 73a43a3a48 23 6 10 3Step 12Figure 5: Trace Simplied Depth-First Branch-and-Bound Search (Centralized BnB-ADOPT)purged memory. example, Step 3, ADOPT branch node f memory.next node best-rst search expands node c, ADOPT discards branch node fStep 4. Steps 6 7, needs reconstruct discarded branch node f orderexpand node v Step 8.3.1.2 Search Strategy BnB-ADOPTdescribe simplied version depth-rst branch-and-bound search. complete versionrrfound (Marinescu & Dechter, 2009). use denitions LBXr U BX rdescribed earlier Figure 4. Depth-rst branch-and-bound search maintains stack initiallycontains child nodes root node. expands node top94fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithmstack removing node stack performing following check. solutionrcost node smaller upper bound U BXr , prunes node repeatsoperation. Otherwise, adds grandchild nodes node top stackrrepeats operation. terminates upper bound U BXr larger lower boundrLBX r . Depth-rst branch-and-bound search add grandchild nodes expandednode (and child nodes root node) decreasing order solution costsinstead random order top stack. ordering ensures depth-rst branchand-bound search expands grandchild node smallest solution cost rst. useimprovement throughout article. example DCOP problem, depth-rst branch-andbound search expands nodes search tree following order, prunesnodes brackets: (0), c (5), (8), j (13), g (15), [h (19)], (8), n (11), k (16), [m (18)], [l (21)],b (0), f (3), v (6) (9). Figure 5 shows trace depth-rst branch-and-bound searchexample DCOP problem. memory-bounded without repeatedly reconstruct nodespurged memory expands nodes best-rst search expand,node j Step 4. depth-rst branch-and-bound search terminates twelve stepsminimal solution cost 12, three steps fewer ADOPT.3.2 Description BnB-ADOPTprovide incremental description BnB-ADOPT. First, provide notations keyterms BnB-ADOPT. Then, describe BnB-ADOPT updates bounds, adheres memorylimitations, performs depth-rst search performs branch-and-bound. Finally, introduceenhanced nal version BnB-ADOPT show pseudocode trace exampleDCOP problem.3.2.1 Notation Key Termsadopt following notation ADOPT describe BnB-ADOPT:V alInit(a) Dom(a) initial value agent A;CD(a) set child pseudo-child agents agent A;C(a) CD(a) set child agents agent A;pa(a) parent agent agent except root agent;P (a) set ancestor agents (including parent agent) agent A;SCP (a) P (a) set ancestor agents (including parent agent) agentparent pseudo-parent agents agent one (or more) descendant agents;CP (a) SCP (a) set ancestor agents (including parent agent) agentparent pseudo-parent agents agent a.adopt following key terms ADOPT describe BnB-ADOPT:Context (X): context X agent set values ancestor agents agenta. context X r root agent r always equal {}.Delta cost (): delta cost X(d) sum constraint costs constraintsinvolve agent one ancestor agents, assumption agenttakes value ancestor agents take values context X . search tree,X(a, d). example,(d) delta cost node partial solution Xa2{(a1 ,1)} (1) delta cost node f Figure 3.95fiYeoh, Felner & KoenigGamma cost (): gamma costs X(d) X dened follows:X(d) := X (d) +cX(a,d)(1)cC(a)X:=min{X(d)}dDom(a)(2)agents a, values contexts X . Thus, gamma cost X(d) sumconstraint costs constraints involve agent one descendant agents (thatis, either agent one ancestor agents, agent one descendantagents, descendant agent ancestor agent agent two descendant agentsagent a) minimized possible values descendant agents, assumptionagent takes value ancestor agents take values context X . search(a, d).tree, X(d) gamma cost node partial solution Xa2example, {(a1 ,1)} (1) gamma cost node f Figure 3. gamma cost Xsumconstraint costs constraints involve agent one descendant agentsminimized possible values agent descendant agents, assumptionancestor agents agent take values context X . search tree,gamma cost Xgamma cost node whose agent agent whose parenta2gamma cost node Cnode partial solution X . example, {(a1 ,1)}Figure 3. Therefore, gamma cost node sum delta costgamma costs child nodes, gamma cost node minimumgamma costs child nodes. example, gamma cost node f Figure 3sum delta cost gamma costs nodes J K, gamma costnode C Figure 3 minimum gamma costs nodes e f .rSolving DCOP problem optimally means determine Xr root agent r or, equivalently,rgamma cost root node since X r minimal solution cost. dicultagents cache information allows determine cost-minimal solution.3.2.2 Updating BoundsEvery agent BnB-ADOPT stores updates several bounds gamma costs, namelya,clba,cX (d), LBX (d), LBX , ubX (d), U BX (d) U BX values d, child agents ccontexts X , maintaining following bound property:LBXLBX(d)a,clbX (d)XX(d)cX(a,d)U BX(3)(4)(5)U BX(d)a,cubX (d)search tree,LBXU BX lower upper bounds, respectively, (on gamma cost)node whose agent agent whose parent node partial solution X ;LBX(d) U BX (d) lower upper bounds, respectively, (on gamma cost)node partial solution X (a, d);a,clba,cX (d) ubX (d) lower upper bounds, respectively, (on gamma cost)node whose agent agent c whose parent node partial solution X (a, d).96fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithma2a2a2example, LB{(aU B{(abounds node C Figure 3, LB{(a(1)1 ,1)}1 ,1)}1 ,1)}a2 ,a3a2 ,a3a2U B{(a1 ,1)} (1) bounds node f , lb{(a1 ,1)} (1) ub{(a1 ,1)} (1) bounds node J.a3a32 ,a32 ,a3lba{(a(1), uba{(a(1), LB{(aU B{(abounds node J, agent1 ,1)}1 ,1)}1 ,1),(a2 ,1)}1 ,1),(a2 ,1)}a2 maintains rst two bounds agent a3 maintains last two bounds.agent uses following update equations values d, child agents ca,ca,ccontexts X initialize bounds lba,cX (d) ubX (d), heuristic values hX (d)a,ccoating point numbers admissible thus satisfy 0 hX (d) X (a,d) :a,clba,cX (d) := hX (d)uba,cX (d):=(6)(7)Agent uses repeatedly following update equations values d, child agents c,contexts X contexts X c (= X (a, d)) tighten bounds:a,cclba,cX (d) := max{lbX (d), LBX c }a,cLBXlbX (d)(d) := X (d) +(8)(9)cC(a)LBX:=uba,cX (d) :=U BX(d):=U BX:=min {LBX(d)}dDom(a)cmin{uba,cX (d), U BX c }Xuba,c(d) +X (d)cC(a)min{U BX(d)}dDom(a)(10)(11)(12)(13)updates maintain bound property improve bounds monotonically, is,lower bounds monotonically non-decreasing upper bounds monotonically nonaincreasing.1 nite amount time, U BXLBX agents contexts X .rrBnB-ADOPT terminates termination condition U BX r LBX r root agent rrrrrsatised. Then, U BXr LBX r bound property U BX r LBX r together implyrrrU BX r = X r = LBX r , DCOP problem solved optimally.Figure 6 shows simplied trace updates (lower upper) bounds exampleDCOP problem. assume updates proceed sequentially leaf agents rootagent. Due simplication, lower upper bounds node identicalgamma cost independent heuristic values. numbers nodes bounds.Two agents maintain bounds nodes except root node. gure shows boundsparent agent maintains rather bounds child agent maintains. example,number node B bounds agent a1 rather agent a2 maintains. boundschild agent maintains computed taking minimum bounds childnodes node. Agents update bound node sum delta costbounds child nodes according update equations 9 12. updatebound node minimum bounds child nodes according updateequations 10 13. detailed description trace follows:Step 1: Leaf agent a3 updates bounds nodes g, h, k, l, o, p,delta costs according update equations 9 12 bounds nodes D, F , H1. Leaf agents use update equations. Since child agents, sums child agents(d) = U B (d) = (d) leaf agents a, values contexts X .evaluate 0. example, LBXXaXa97fiYeoh, Felner & Koenig00b000BC000cgEheFjkGlfHnpqJrK0uv00010 14 3080008 13 10 3 25 7Identifiers00308 23 6 10 3Step 1181810 14 338830378 13 10 3 25 71233638 23 6 10 3Step 2121218101912018001010 14 31938830378 13 10 3 25 71233638 23 6 10 3Step 3Figure 6: Simplied Trace Updates (Lower Upper) BoundsJ minimum bounds child nodes according update equations 1013. Similarly, leaf agent a4 updates bounds nodes i, j, m, n, q, r, uv delta costs according update equations 9 12 bounds nodesE, G, K minimum bounds child nodes according updateequations 10 13. bounds nodes K shown gure since(yet) maintained agent a2 .Step 2: Agent a2 updates bounds nodes K maintains boundsnodes leaf agents a3 a4 maintain according update equations 811, bounds nodes c f sum delta costs boundschild nodes according update equations 9 12 bounds nodes BC minimum bounds child nodes according update equations 1013. bounds nodes B C shown gure since (yet)maintained agent a1 .Step 3: Agent a1 updates bounds nodes B C maintains boundsnodes agent a2 maintains according update equations 8 11,bounds nodes b sum delta costs bounds childnodes according update equations 9 12 bounds node minimumbounds child nodes according update equations 10 13. Sincelower upper bounds node equal gamma cost, lower upper boundsroot node equal gamma cost, turn equal minimal solutioncost. propagation terminates three steps minimal solution cost 12.3.2.3 Adhering Memory Limitationsdescription BnB-ADOPT far assumes memory limitations. However, BnB-ADOPTmemory-bounded DCOP search algorithm memory requirements per agent linearnumber agents. describe BnB-ADOPT adheres memory limitationsusing techniques introduced ADOPT apply BnB-ADOPT well.simplied trace Figure 6 assumes every agent maintains bounds values d,child agents c contexts X . number contexts exponential depthagent pseudo-tree. example DCOP problem, agent a3 four dierent contextsfour dierent combinations values ancestor agents a1 a2 . agent cannot maintain98fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithmexponential number bounds due memory limitations. Therefore, every agent maintainsbounds one context given time. context stored variable Xagent a. size context linear number agents. number boundsagent linear product domain cardinality number child agents.Thus, memory requirements per agent linear number agents domaincardinality magnitude bounds (and variables) constant agent.3.2.4 Performing Depth-First Searchdescription BnB-ADOPT far applies ADOPT well. However, BnB-ADOPT usesdepth-rst branch-and-bound search ADOPT uses best-rst search. describeBnB-ADOPT implements depth-rst search.Agents BnB-ADOPT send messages similar ADOPT processesdierently. send messages three dierent types, namely VALUE, COST TERMINATEmessages. start, every agent initializes context X , uses update equations 6, 9, 10, 7, 1213 initialize bounds takes best value da := arg mindDom(a) {LBX(d)}. sendsVALUE messages child agents COST message parent agent. repeatedlywaits incoming messages, processes them, possibly takes dierent value sendsVALUE messages child agents COST message parent agent. descriptionthree message types agents process follows:VALUE messages: agent context X value da sends VALUE messageschild agents desired context X (a, da ), context augmentedvalue. Leaf agents child agents thus send VALUE messages. VALUEmessages thus propagate contexts pseudo-tree.agent receives VALUE message, checks whether context identicaldesired context VALUE message. not, agent changes contextdesired context VALUE message. either case, executes common program(see below).COST messages: agent sends COST messages parent agent identitya, context X bounds LBXU BX . root agent parentagent thus send COST messages. COST messages thus propagate boundspseudo-tree.agent receives COST message, checks whether context contextCOST message compatible. Two contexts compatible agent takes dierentvalues two contexts. are, agent uses update equations 8 13bounds COST message improve bounds value message. eithercase, executes common program (see below).rrTERMINATE messages: termination condition U BXr LBX r satised,root agent r sends TERMINATE messages (without parameters) child agentsinform search complete terminates. agent receivesTERMINATE message, sends TERMINATE messages child agents terminateswell. Leaf agents child agents thus send TERMINATE messages.TERMINATE messages thus propagate pseudo-tree agents terminate.common program follows:Context change: agent changed context X , executes following statements:uses update equations 6, 9, 10, 7, 12 13 initialize bounds takes bestvalue da := arg mindDom(a) {LBX(d)}. sends VALUE messages child agentsCOST message parent agent.99fiYeoh, Felner & Koenig00b005BC005cgEheFjkGlfHnpqJrK5uv80010 14 38X0XXXXX XX XX XX XX XX X0180Identifiers108310 14 38XXXXX XX XX XX XX XX X0808018808018188103X XX X0X08 13 10 3X18XXXXX XX XX XX X19103X XX X88 13 10 3Cycle 3XXXXX XX XX XX X1019310 14 38XXXXX XX XX XX XX XX X31801831818018318X1010 14 3X38203XXX0000X XX XX XX XX XX XX20XXXX0X XX XX XX XX XCycle 63000X X 23 6 10 33X20XXXX0X XX XX XX XX X12063X X 23 6 10 3Cycle 81218181212X3XCycle 7X3Cycle 53X8018X0Cycle 40X3X0Cycle 20X0Cycle 10X0X20XXXX0X XX XX XX XX X12063X X 23 6 10 3Cycle 9Figure 7: Trace Updates Lower Boundscontext change: agent change context X , executes followingstatements: U BXLBX (d ) value , context agent augmentedvalue cannot completed solution whose solution cost smaller solutioncost best solution found far context X (= U BX) agent thus takesbest value := arg mindDom(a) {LBX (d)}. sends VALUE messages childagents COST message parent agent.Assume context X agent change. nite amount time,U BXagent takes best value repeatsLBX (d ) value .procedure. nite amount time, U BXLBX (d) values d, impliesU BX LBX . agent takes every value U BXLBX since LBX (d)remains unchanged U BX monotonically non-increasing agent changes valuedierent value, prevents agent changing value backU BXLBX . BnB-ADOPT thus performs depth-rst search. Then, nite amount time,rrrrrrrU BX r LBX r bound property U BXr LBX r together imply U BX r = X r = LBX rroot agent r, DCOP problem solved optimally.Figures 7 8 show traces updates lower upper bounds, respectively,example DCOP problem. BnB-ADOPT uses zero heuristic values. initial context every100fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithminfinfbinfinfinfBCinfinfinfcgEheFjkGlfHnpqJrinfKuvinfinfinf10 14 38XinfXXXXX XX XX XX XX XX X10inf310 14 38XXXXX XX XX XX XX XX XCycle 2181818inf18inf1818inf18inf1818inf103X XX XinfXinf8 13 10 3X18XXXXX XX XX XX X19103X XX X88 13 10 3Cycle 3XXXXX XX XX XX X1019310 14 38XXXXX XX XX XX XX XX X1818inf18inf1818inf18inf18X1010 14 3X38infinfXXXinfinfinfinfX XX XX XX XX XX XXinfXXXXinfX XX XX XX XX XCycle 6infinfinfinfX X 23 6 10 3infXinfXXXXinfX XX XX XX XX X12inf63X X 23 6 10 3Cycle 81218181212XinfXCycle 7X3Cycle 518X8inf18XinfCycle 418X3XinfCycle 118Xinf018infIdentifiersXinfXinfXXXXinfX XX XX XX XX X12inf63X X 23 6 10 3Cycle 9Figure 8: Trace Updates Upper Boundsagent assigns value 0 ancestor agents agent. partition time cycles. Agentsmaintain bounds one context given time. Nodes gures crossedagent maintain bounds. nodes shaded partial solution equalcontext agent parent node augmented value. example, agentsa1 , a3 a4 take value 0 Cycle 2, agent a2 takes value 1. context agent a1{}, context agent a2 {(a1 , 0)} contexts agents a3 a4 {(a1 , 0), (a2 , 0)}.description trace follows:Cycle 1: Root agent a1 initializes context X a1 {}. initializes lower boundsnodes B (= lbaX1a,a1 2 (0)) C (= lbaX1a,a1 2 (1)) 0 since uses zero heuristic values.a1updates lower bound node (= LBXa1 (0)) sum delta cost (= 0)lower bound node B (= 0) according update equations. updates lower bounda1node b (= LBXa1 (1)) sum delta cost (= 0) lower bound node C (= 0)a1according update equations. updates lower bound node (= LBXa1 )minimum lower bound node (= 0) lower bound node b (= 0) accordingupdate equations. initializes upper bounds nodes B C innity. updatesupper bounds nodes a, b innity according update equations. takes101fiYeoh, Felner & Koenigbest value. take either value 0 value 1 since lower bounds nodesb 0. takes value 0 sends VALUE message child agent a2 .Agent a2 initializes context X a2 {(a1 , 0)}. initializes lower bounds nodes D, E,F G 0. updates lower bounds nodes c, B 5, 8 5, respectively.initializes upper bounds nodes D, E, F G innity. updates upper boundsnodes c, B innity. bounds node B agent a2 maintains showngures. takes best value 0, sends VALUE messages child agents a3a4 sends COST message parent agent a1 .Leaf agent a3 initializes context X a3 {(a1 , 0), (a2 , 0)}. updates lower boundsnodes g h delta costs 10 14, respectively, since leaf agents childagents. updates lower bound node 10. updates upper bounds nodes gh delta costs 10 14, respectively, since leaf agents child agents.updates upper bound node 10. bounds node leaf agent a3 maintainsshown gures. takes best value 0 sends COST messageparent agent a2 .Leaf agent a4 initializes context X a4 {(a1 , 0), (a2 , 0)}. updates lower boundsnodes j delta costs 3 8, respectively. updates lower bound node E3. updates upper bounds nodes j delta costs 3 8, respectively.updates upper bound node E 3. bounds node E leaf agent a4 maintainsshown gures. takes best value 0 sends COST messageparent agent a2 .summary, following messages sent Cycle 1:message (VALUE, {(a1 , 0)}) agent a1 agent a2 ;message (VALUE, {(a1 , 0), (a2 , 0)}) agent a2 agent a3 ;message (VALUE, {(a1 , 0), (a2 , 0)}) agent a2 agent a4 ;message (COST, a2 , {(a1 , 0)}, 5, ) agent a2 agent a1 ;message (COST, a3 , {(a1 , 0), (a2 , 0)}, 10, 10) agent a3 agent a2 ;message (COST, a4 , {(a1 , 0), (a2 , 0)}, 3, 3) agent a4 agent a2 .Cycle 2: Root agent a1 receives COST message sent child agent a2 Cycle 1. Sincecontext agent a1 (= {}) compatible context message (= {(a1 , 0)}),improves bounds. updates bounds node B bounds message (= 5innity, respectively). updates bounds nodes a, b A. change valuea1a1) = 5 value da1 = 0) still smallersince lower bound node (= LBXa1 (da1upper bound node (= U BX a1 = ). sends VALUE message child agenta2 .Agent a2 receives VALUE message sent parent agent a1 Cycle 1. context(= {(a1 , 0)}) remains unchanged since desired context message(= {(a1 , 0)}). Agent a2 also receives COST messages sent child agents a3 a4Cycle 1. Since context agent a2 (= {(a1 , 0)}) compatible contextsmessages (= {(a1 , 0), (a2 , 0)}), improves bounds. updates bounds nodebounds rst message (= 10 10, respectively) bounds node Ebounds second message (= 3 3, respectively). updates bounds nodes c,a2a2) = 18 valueB. changes value since lower bound node c (= LBXa2 (da2a2= 0) longer smaller upper bound node B (= U BX a2 = 18). takesbest value 1, sends VALUE messages child agents a3 a4 sends COST messageparent agent a1 .102fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmLeaf agents a3 a4 receive VALUE messages sent parent agent a2 Cycle 1.contexts (= {(a1 , 0), (a2 , 0)}) remain unchanged since desiredcontext message (= {(a1 , 0), (a2 , 0)}). send COST messagesparent agent a2 .summary, messages sent Cycle 2 identical ones sent Cycle 1,except messages sent agent a2 , follows:message (VALUE, {(a1 , 0), (a2 , 1)}) agent a2 agent a3 ;message (VALUE, {(a1 , 0), (a2 , 1)}) agent a2 agent a4 ;message (COST, a2 , {(a1 , 0)}, 8, 18) agent a2 agent a1 .VALUE messages dierent agent a2 changed value 0 1. COSTmessage dierent agent a2 changed bounds.Cycles 3-9: messages sent Cycle 3 identical ones sent Cycle 2,except messages sent agents a3 a4 , follows:message (COST, a3 , {(a1 , 0), (a2 , 1)}, 8, 8) agent a3 agent a2 ;message (COST, a4 , {(a1 , 0), (a2 , 1)}, 3, 3) agent a4 agent a2 .COST messages dierent agents a3 a4 changed contexts.termination condition holds nite amount time upper bound nodea1a1(= U BXa1 = 12) larger lower bound node (= LBX a1 = 12). Root agent a1sends TERMINATE messages child agents, TERMINATE messages propagatepseudo-tree agents terminate. BnB-ADOPT terminates nine cyclesminimal solution cost 12.3.2.5 Performing Branch-and-Boundrene description BnB-ADOPT explaining agents implement branchand-bound search make BnB-ADOPT faster. Every agent BnB-ADOPT also maintainsvariable threshold HX, initializes innity. threshold root agent alwaysremains innity. Every agent uses threshold pruning, meaning changevalue earlier previously.First change: agent change context X , previously executed followingstatements: U BXLBX (d ) value , agent took best value.sent VALUE messages child agents COST message parent agent. Now,HXLBX (d ), agent also takes best value. Thus, min{T HX , U BX }LBX(d),agenttakesbestvaluethuspotentiallychangesvalue,earlier previously. min{T HX,UB}pruningquantity.XaSecond change: agent context X value da sends VALUE messageschild agents, previously contained desired context X (a, da ).VALUE messages also contain desired threshold min{T HX, U BX } X (d )a,cc C(a)\c lbX (d ) child agent c. agent c receives VALUE message, setsthreshold desired threshold proceeds described earlier. desiredreachesthreshold set lower bound LBX(d ) agent valuecpruning quantity (and agent thus potentially changes value) lower bound LBXcagent c reaches desired threshold. property veried follows:103fiYeoh, Felner & KoenigcLBXc min{T HX , U BX } X (d )lba,cX (d )(14)c C(a)\clba,cX (d ) min{T HX , U BX } X (d )a,cmin{T HX, U BX } X (d ) lb (d )Xlba,cX (d )(15)c C(a)\clba,cX (d )(16)c C(a)\ca,cmin{T HX, U BX } X (d ) + lb (d ) +Xmin{T HX, U BX } X (d ) +lba,cX (d )(17)c C(a)\clba,cX (d )(18)c C(a)min{T HX, U BX } LBX (d )(19)3.2.6 Enhancementscontinue rene description BnB-ADOPT explaining number additional enhancements, introduced ADOPT.Reduced contexts: agents use reduced contexts, subsets contextsdescribed previously. reduced context X1a agent contains values ancestoragents p SCP (a), context X2a described previously contains valuesancestor agents p P (a). agents use reduced contexts since X= X X (d) =121X2a (d) values d. Agents use reduced contexts need changecontexts thus initialize bounds less often receive VALUE messages sincecontexts often identical desired contexts VALUE messages.example DCOP problem, reduced context agent a4 contains valuesagent a2 rather values agents a1 a2 . Therefore, following pairs nodessearch tree actually node: nodes q, nodes j r, nodes u,nodes n v.VALUE COST messages: agent sends VALUE messages child agents,previously contained desired context desired threshold. desired contextcontext agent augmented value. agent receives VALUE message,previously checked whether context identical desired context VALUEmessage. not, agent changed context desired contextVALUE message. Agents update contexts dierently reduce sizeVALUE messages. agent sends VALUE messages child pseudo-child agentsidentity, value desired threshold, innity pseudo-child agents.agent receives VALUE message, sets threshold desired threshold messageparent agent. also checks whether value ancestor agent VALUEmessage recent value ancestor agent context. is,agent changes value ancestor agent context value ancestor agentVALUE message. However, context agent contain valuesparent pseudo-parent agents also values ancestor agents parentpseudo-parent agents one (or more) descendant agents, ancestor agentsconstrained agent cannot send VALUE messages agent. However,send VALUE messages pseudo-child agents, least one descendant agentagent, information propagates pseudo-tree COST messagesreaches agent. agent receives COST message, checks whether104fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithmvalue ancestor agent context COST message recentvalue ancestor agent context. is, agent changes valueancestor agent context value ancestor agent context COSTmessage. example DCOP problem simple allow us illustrate propagationinformation pseudo-tree. However, imagine new agent a5 child agentagent a4 constrained agents a1 a4 . context agent a4 containsvalue agent a1 agent a1 cannot send VALUE messages agent a4 . However, agenta1 sends VALUE messages agent a5 . Agent a5 changes value agent a1 contextsends COST messages context agent a4 , changes value agenta1 context well.agents need determine whether value agent VALUE messagescontexts COST messages recent value agent contexts. Everyagent therefore also maintains counter IDa increments whenever changesvalue. Therefore, larger ID indicates recent value. values agents contextslabeled IDs, VALUE messages contain identity sending agent,value, ID desired threshold.Bounds: Whenever agent changes context X , previously initialized boundstook best value. (reduced) context child agent agent strictsubset (reduced) context agent since parent pseudo-parent agentsagent might (parent or) pseudo-parent agents child agent descendantagents. context child agent c contain values agents whose valueschanged context agent a, agent initialize lower bounds lba,cX (d)upper bounds uba,c(d)agentcvaluestakesbestvalue.AgentsXause optimization need initialize bounds less often way.example DCOP problem, agent a2 changes context {(a1 , 0)} {(a1 , 1)} (whereIDs omitted simplicity), initialize lower bounds lbaX2a,a2 4 (d) upperbounds ubaX2a,a2 4 (d) child agent a4 values since context agent a4contain value agent a1 .Additionally, agent changes context due COST message child agent cnew context X compatible context COST message, agenta,cset lower bound lba,cX (d) upper bound ubX (d) agent c value agentCOST message bounds COST message takes best value.Agents use optimization bounds COST message informedinitialized bounds. example DCOP problem simple allow us illustrateoptimization. However, imagine new agent a5 child agent agent a4constrained agents a1 a4 . Assume context agent a4 {(a1 , 0), (a2 , 0)}(where IDs omitted simplicity) receives COST message agenta5 context {(a1 , 1), (a4 , 0)}. Agent a4 changes context {(a1 , 1), (a2 , 0)}, sets4 ,a54 ,a5lower bound lba{(a(0) upper bound uba{(a(0) bounds1 ,1),(a2 ,0)}1 ,1),(a2 ,0)}COST message initializes bounds takes best value.3.2.7 PseudocodeFigure 9 shows BnB-ADOPT pseudocode every agent. pseudocode indexvariables context since context implicitly given variable X . usespredicate Compatible(X, X ) = (a,d,ID)X,(a ,d ,ID )X (a == ) determines twocontexts X X compatible, is, agent takes two dierent values two contexts[Lines 35, 44, 46, 48 51]. pseudocode also uses procedure PriorityMerge(X, X )executes X := {(a , , ID ) X | (a,d,ID)X (a = )} {(a , , ID ) X | (a,d,ID)X (a =105fiYeoh, Felner & Koenigprocedure Start()[01]X := {(p, ValInit(p), 0) | p SCP (a)};[02]IDa := 0;[03]forall c C(a), Dom(a)[04]InitChild(c, d);[05]InitSelf ();[06]Backtrack();[07]loop forever[08](message queue empty)[09]while(message queue empty)[10]pop msg message queue;[11]Received(msg);[12]Backtrack();procedure InitChild(c, d)[13]lba,c (d) := ha,c (d);[14]uba,c (d) := ;procedure InitSelf ()[15]da := arg mindDom(a) { (d) + cC(a) lba,c (d)};[16]ID := ID + 1;[17]H := ;procedure Backtrack()[18]forall Dom(a)[19]LB (d) := (d) + cC(a) lba,c (d);[20]UB (d) := (d) + cC(a) uba,c (d);[21]LB := mindDom(a) {LB (d)};[22]UB := mindDom(a) {UB (d)};[23](LB (da ) min{T H , UB })[24]da := arg mindDom(a) {LB (d)} (choose previous da possible);[25]new da chosen[26]IDa := IDa + 1;[27]((a root UB LB ) termination message received)[28]Send(TERMINATE) c C(a);[29]terminate execution;[30]Send(VALUE, a, da , IDa , min{T H , UB } (da ) c C(a)\c lba,c (da )) c C(a);[31]Send(VALUE, a, , ID , ) c CD(a) \ C(a);[32]Send(COST, a, X , LB , UB ) pa(a) root;procedure Received(VALUE, p, dp , IDp , H p )[33]X := X ;[34]PriorityMerge((p, dp , ID p ), X );[35](!Compatible(X , X ))[36]forall c C(a), Dom(a)[37](p SCP (c))[38]InitChild(c, d);[39]InitSelf ();[40](p = pa(a))[41]H := H p ;procedure Received(COST, c, X c , LB c , UB c )[42]X := X ;[43]PriorityMerge(X c , X );[44](!Compatible(X , X ))[45]forall c C(a), Dom(a)[46](!Compatible({(p, dp , ID p ) X | p SCP (c)},X ))[47]InitChild(c,d);[48](Compatible(X c , X ))[49]lba,c (d) := max{lba,c (d), LB c } unique (a , d, ID) X c = a;[50]uba,c (d) := min{uba,c (d), UB c } unique (a , d, ID) X c = a;[51](!Compatible(X , X ))[52]InitSelf ();procedure Received(TERMINATE)[53]record termination message received;Figure 9: Pseudocode BnB-ADOPTID ID )} {(a, d, ID) X | (a ,d ,ID )X (a = ID > ID )} thus replaces values106fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithmagents context X recent values, available, agents context X [Lines34 43].code identical every agent except variable self variable pointsagent itself. start, BnB-ADOPT calls Start() every agent. agent receivesVALUE message ancestor agent, Received handler VALUE messagescalled p ancestor agent, dp value ancestor agent, IDpID ancestor agent H p desired threshold agent ancestor agentparent agent (and innity otherwise) [Line 11]. agent receives COST messagechild agent, Received handler COST messages called c childcagent, X c context child agent, LB c lower bound LBXc child agentccU B upper bound U BX c child agent [Line 11]. Finally, agent receivesTERMINATE message parent agent, Received handler TERMINATEmessages called without arguments [Line 11].BnB-ADOPT uses message passing communication framework ADOPTmemory requirements. uses similar VALUE, COST TERMINATE messages,similar strategy update context agent based VALUE messages ancestoragents COST messages child agents, semantics boundsupdate equations update bounds. BnB-ADOPT ADOPT use thresholds BnBADOPT uses thresholds pruning ADOPT uses reconstruct partial solutionspurged memory. Thus, BnB-ADOPT uses dierent threshold initialization [Line17], dierent desired threshold calculation [Line 30] dierent termination condition [Line 27].BnB-ADOPT also diers ADOPT maintains IDs agents use indicaterecency values labels values agents contexts IDs.3.2.8 TraceFigures 10 11 show traces updates lower upper bounds, respectively,example DCOP problem, Table 2 shows trace update variables. BnB-ADOPTuses heuristic values haX1a,a1 2 (0) := 3, haX1a,a1 2 (1) := 6, haX2a,a2 3 (0) := 2, haX2a,a2 3 (1) := 2, haX2a,a2 4 (0) := 2haX2a,a2 4 (1) := 2 contexts X a1 X a2 . heuristic values chosen hand. Everyagent assigns value ancestor agents initial context 0. partition timecycles Figures 7 8 continue use conventions made context gures.Cycle 1: Root agent a1 initializes context X a1 {} [Line 1]. initializes lower boundsnodes B (= lbaX1a,a1 2 (0)) C (= lbaX1a,a1 2 (1)) heuristic values 3 6, respectivelya1[Line 13]. updates lower bound node (= LBXa1 (0)) sum delta cost(= 0) lower bound node B (= 3) according update equations [Line 19].a1updates lower bound node b (= LBXa1 (1)) sum delta cost (= 0)lower bound node C (= 6) according update equations [Line 19]. updatesa1lower bound node (= LBXa1 ) minimum lower bound node (= 3)lower bound node b (= 6) according update equations [Line 21]. initializesupper bounds nodes B C innity [Line 14]. updates upper bounds nodes a,b innity according update equations [Lines 20 22]. takes bestvalue 0 since lower bound node (= 3) smaller lower bound node b (= 6)[Line 15], initializes ID IDa1 1 [Lines 2 16], initializes threshold H a1 innity[Line 17] sends VALUE messages child agent a2 pseudo-child agent a3 [Lines 3031].Agent a2 initializes context X a2 {(a1 , 0, 0)} [Line 1]. initializes lower boundsnodes D, E, F G heuristic value 2 [Line 13]. updates lower bounds nodesc, B 9, 12 9, respectively [Lines 19 21]. initializes upper boundsnodes D, E, F G innity [Line 14]. updates upper bounds nodes c, Binnity [Lines 20 22]. bounds node B agent a2 maintains shown107fiYeoh, Felner & KoenigCycleX a1da1ID a1H a1LB a1 (0)LB a1 (1)LB a1U B a1 (0)U B a1 (1)U B a1lba1 ,a2 (0)lba1 ,a2 (1)uba1 ,a2 (0)uba1 ,a2 (1)X a2da2ID a2H a2LB a2 (0)LB a2 (1)LB a2U B a2 (0)U B a2 (1)U B a2lba2 ,a3 (0)lba2 ,a3 (1)uba2 ,a3 (0)uba2 ,a3 (1)lba2 ,a4 (0)lba2 ,a4 (1)uba2 ,a4 (0)uba2 ,a4 (1)X a3da3ID a3H a3LB a3 (0)LB a3 (1)LB a3U B a3 (0)U B a3 (1)U B a3X a4da4ID a4H a4LB a4 (0)LB a4 (1)LB a4U B a4 (0)U B a4 (1)U B a41234567890136336(a1 , 0, 0)0191292222(a1 , 0, 0)(a2 , 0, 0)01101410101410(a2 , 0, 0)013833830196696(a1 , 0, 1)12181212181810210323(a1 , 0, 1)(a2 , 0, 1)01101410101410(a2 , 0, 1)01383383011266181812618(a1 , 0, 1)12181212181810210323(a1 , 0, 1)(a2 , 1, 2)02881388138(a2 , 1, 2)12810331033011266181812618(a1 , 0, 1)03181819181819181081083333(a1 , 0, 1)(a2 , 1, 2)02881388138(a2 , 1, 2)12810331033121866181818618(a1 , 0, 1)03181819181819181081083333(a1 , 0, 1)(a2 , 0, 3)0310101410101410(a2 , 0, 3)033383383121866181818618(a1 , 1, 2)14182588223333(a1 , 1, 2)(a2 , 0, 3)141025772577(a2 , 0, 3)033383383121888181818818(a1 , 1, 2)1418308830307273333(a1 , 1, 2)(a2 , 1, 4)151223662366(a2 , 1, 4)1413103310331218881830181881830(a1 , 1, 2)141830121230121276763333(a1 , 1, 2)(a2 , 1, 4)151223662366(a2 , 1, 4)1413103310331218121218121218121812(a1 , 1, 2)141830121230121276763333(a1 , 1, 2)(a2 , 1, 4)15623662366(a2 , 1, 4)14310331033Table 2: Trace Update Variables BnB-ADOPT108fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm36b369BC369cgEheFjkGlfHnpqJrK9uv122210 14 38X2XXXXX XX XX XX XX XX X6182Identifiers1012310 14 38XXXXX XX XX XX XX XX X612612618126126181812103X XX X2X28 13 10 3X18XXXXX XX XX XX X19103X XX X88 13 10 3Cycle 3XXXXX XX XX XX X1019310 14 38XXXXX XX XX XX XX XX X81861881818618818XXXXXX XX XX X25X2X X 25 78338X23X XX XX30XXXX7X XX XX XX XX XCycle 68323X X 23 6 10 38X30XXXX7X XX XX XX XX X12363X X 23 6 10 3Cycle 81218181212X8XCycle 7X3Cycle 58X8618X6Cycle 46X3X2Cycle 26X2Cycle 16X6X30XXXX7X XX XX XX XX X12363X X 23 6 10 3Cycle 9Figure 10: Trace Update Lower Bounds BnB-ADOPTgure. takes best value 0 [Line 15], initializes ID 1 [Lines 2 16],initializes threshold innity [Line 17] sends VALUE messages child agents a3a4 COST message parent agent a1 [Lines 30-32].Leaf agent a3 initializes context X a3 {(a1 , 0, 0), (a2 , 0, 0)} [Line 1]. updates lowerbounds nodes g h delta costs 10 14, respectively, since leaf agentschild agents [Line 19]. updates lower bound node 10 [Line 21]. updatesupper bounds nodes g h delta costs 10 14, respectively, since leaf agentschild agents [Line 20]. updates upper bound node 10 [Line 22].bounds node leaf agent a3 maintains shown gure. takesbest value 0 [Line 15], initializes ID 1 [Lines 2 16], initializes threshold innity[Line 17] sends COST message parent agent a2 [Line 32].Leaf agent a4 initializes (reduced) context X a4 {(a2 , 0, 0)} [Line 1]. updates lowerbounds nodes j delta costs 3 8, respectively [Line 19]. updateslower bound node E 3 [Line 21]. updates upper bounds nodes jdelta costs 3 8, respectively [Line 20]. updates upper bound node E 3 [Line22]. bounds node E leaf agent a4 maintains shown gure. takes109fiYeoh, Felner & KoeniginfinfbinfinfinfBCinfinfinfcgEheFjkGlfHnpqJrinfKuvinfinfinf10 14 38XinfXXXXX XX XX XX XX XX X10inf310 14 38XXXXX XX XX XX XX XX XCycle 2181818inf18inf1818inf18inf1818inf103X XX XinfXinf8 13 10 3X18XXXXX XX XX XX X19103X XX X88 13 10 3Cycle 3XXXXX XX XX XX X1019310 14 38XXXXX XX XX XX XX XX X1818inf18inf1818inf18inf18XXXXXX XX XX XinfXinfX X 25 7inf338Xinf3X XX XX30XXXX7X XX XX XX XX XCycle 6inf3inf3X X 23 6 10 330XXX7X XX XX XX XX X12363X X 23 6 10 3Cycle 81218181212X30XX30XCycle 7X3Cycle 518X8inf18XinfCycle 418X3XinfCycle 118Xinfinf18infIdentifiersXinfX30XXXX7X XX XX XX XX X12363X X 23 6 10 3Cycle 9Figure 11: Trace Update Upper Bounds BnB-ADOPTbest value 0 [Line 15], initializes ID 1 [Lines 2 16], initializes thresholdinnity [Line 17] sends COST message parent agent a2 [Line 32].summary, following messages sent Cycle 1:message (VALUE, a1 , 0, 1, ) agent a1 agent a2 ;message (VALUE, a1 , 0, 1, ) agent a1 agent a3 ;message (VALUE, a2 , 0, 1, ) agent a2 agent a3 ;message (VALUE, a2 , 0, 1, ) agent a2 agent a4 ;message (COST, a2 , {(a1 , 0, 0)}, 9, ) agent a2 agent a1 ;message (COST, a3 , {(a1 , 0, 0), (a2 , 0, 0)}, 10, 10) agent a3 agent a2 ;message (COST, a4 , {(a2 , 0, 0)}, 3, 3) agent a4 agent a2 .Cycle 2: Root agent a1 receives COST message sent child agent a2 Cycle 1. Sincecontext agent a1 (= {}) compatible context message (= {(a1 , 0, 0)}),improves bounds. updates bounds node B bounds message (= 9innity, respectively) [Lines 48-50]. updates bounds nodes a, b [Lines 18-22].110fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithma1a1change value since lower bound node (= LBX) = 9 valuea1 (da1a1a1= 0) still smaller pruning quantity (= min{T HX a1 , U BX a1 } = min(, ) =). sends VALUE messages child agent a2 pseudo-child agent a3 [Lines 30-31].Agent a2 receives VALUE message sent parent agent a1 Cycle 1. updatescontext {(a1 , 0, 0)} {(a1 , 0, 1)} since ID agent a1 context (= 0) smallerID message (= 1) [Line 34]. threshold (= ) remains unchanged sincedesired threshold (= ) message. Agent a2 also receives COSTmessages sent child agents a3 a4 Cycle 1. Since context (= {(a1 , 0, 1)}) compatible contexts messages (= {(a1 , 0, 0), (a2 , 0, 0)} {(a2 , 0, 0)}, respectively),improves bounds. updates bounds node bounds rst message(= 10 10, respectively) bounds node E bounds second message (= 33, respectively) [Lines 48-50]. updates bounds nodes c, B [Lines 18-22].a2a2) = 18 value da2 = 0)changes value since lower bound node c (= LBXa2 (da2a2longer smaller pruning quantity (= min{T HX a2 , U BXa2 } = min(, 18) = 18).takes best value 1 [Line 24], increments ID 2 [Lines 25-26], sends VALUE messageschild agents a3 a4 [Lines 30-31] sends COST message parent agent a1[Line 32].Leaf agent a3 receives VALUE messages sent parent agent a2 pseudo-parentagent a1 Cycle 1. updates context {(a1 , 0, 0), (a2 , 0, 0)} {(a1 , 0, 1), (a2 , 0, 1)}since IDs agents a1 a2 context (= 0 0, respectively) smallerIDs messages (= 1 1, respectively) [Line 34]. threshold (= ) remainsunchanged since desired threshold (= ) message. boundsreinitialized since context compatible previous context [Line 35]. sendsCOST message parent agent a2 [Line 32].Leaf agent a4 receives VALUE message sent parent agent a2 Cycle 1. updatescontexts {(a2 , 0, 0)} {(a2 , 0, 1)} since ID agent a2 context (= 0) smallerID message (= 1) [Line 34]. threshold (= ) remains unchanged sincedesired threshold (= ) message. bounds reinitialized sincecontext compatible previous context [Line 35]. sends COST messageparent agent a2 [Line 32].summary, messages sent Cycle 2 identical ones sent Cycle 1,except messages sent agents a2 , a3 a4 , follows:message (VALUE, a2 , 1, 2, 8) agent a2 agent a3 ;message (VALUE, a2 , 1, 2, 8) agent a2 agent a4 ;message (COST, a2 , {(a1 , 0, 1)}, 12, 18) agent a2 agent a1 .message (COST, a3 , {(a1 , 0, 1), (a2 , 0, 1)}, 10, 10) agent a3 agent a2 ;message (COST, a4 , {(a2 , 0, 1)}, 3, 3) agent a4 agent a2 .VALUE messages dierent agent a2 changed value 0 1. COSTmessages dierent agent a2 changed bounds context agents a3a4 changed contexts.Cycles 3-9: messages sent Cycle 3 identical ones sent Cycle 2,except messages sent agents a3 a4 , follows:message (COST, a3 , {(a1 , 0, 1), (a2 , 1, 2)}, 8, 8) agent a3 agent a2 ;message (COST, a4 , {(a2 , 1, 2)}, 3, 3) agent a4 agent a2 .111fiYeoh, Felner & KoenigCOST messages dierent agents a3 a4 changed contexts.termination conditions holds nite amount time upper bound nodea1a1(= U BXa1 = 12) larger lower bound node (= LBX a1 = 12) [Line 27]. Rootagent a1 sends TERMINATE messages child agents [Line 28], TERMINATEmessages propagate pseudo-tree [Line 28] agents terminate. BnB-ADOPTterminates nine cycles minimal solution cost 12.4. Bounded-Error Approximationssection, present three approximation mechanisms allow BnB-ADOPT tradesolution cost smaller runtime. bound error solution cost user-denederror bound. First, modify Absolute Error Mechanism ADOPT (Modi et al., 2005)work BnB-ADOPT. approximation mechanism allows users specify absolute errorbound solution cost (for example, solution cost 10 largerminimal solution cost). However, often much desirable specify relative error boundsolution cost (for example, solution cost 10 percent largerminimal solution cost or, equivalently, 1.1 times larger minimal solution cost). cannotdone Absolute Error Mechanism without knowing minimal solution cost priori.Thus, introduce two approximation mechanisms allow users specify relative error boundsolution cost, namely Relative Error Mechanism Weighted Heuristics Mechanism.approximation mechanisms let root agent r (and root agent) maintainlimit limr . root agent uses limit way termination conditionrrapproximation mechanisms updates dierently. termination condition U BXr LBX rrrLine 27 pseudocode BnB-ADOPT replaced U BX r lim . root agent updateslimit Lines 26 27 pseudocode, outside preceding statement.4.1 Absolute Error MechanismAbsolute Error Mechanism ADOPT requires user-dened absolute error bound 0 b <species solution cost b larger minimal solution cost.approximation mechanism easily modied BnB-ADOPT setting limit follows:limr:=rb + LBXr(20)BnB-ADOPTAEM resulting variant BnB-ADOPT Absolute Error Mechanism.BnB-ADOPTAEM terminates upper bound root node (which equal solutioncost solution smallest solution cost found far) larger limit (whichequal absolute error bound b plus lower bound root node, lowerbound minimal solution cost). BnB-ADOPTAEM terminates solution costequal upper bound root node although minimal solution cost could smalllower bound root node. thus terminates solution cost b largerminimal solution cost. Figure 12 shows trace BnB-ADOPTAEM absolute errorbound b = 24 example DCOP problem. BnB-ADOPTAEM terminates three cyclessuboptimal solution cost 18, six cycles faster BnB-ADOPT.4.2 Relative Error Mechanismoften much desirable specify relative error bound solution cost ratherabsolute error bound. Fortunately, Absolute Error Mechanism BnB-ADOPT easilychanged Relative Error Mechanism setting limit follows. Relative Error112fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm3lim 1 = 27UB 1 = infinitylim 1 = 30UB 1 = infinity663696123696129212210 14 38XX1822XXXXX XX XX XX XX XX X1012310 14 38XX22XXXXX XX XX XX XX XX XCycle 16618lim 1 = 30UB 1 = 1812103X XX X2X28 13 10 3Cycle 2XXXXXX XX XX XX XCycle 3Figure 12: Trace Update Lower Bounds BnB-ADOPTAEM b = 243lim 1 = 9UB 1 = infinitylim 1 = 18UB 1 = infinity663696123696129212210 14 38XX1822XXXXX XX XX XX XX XX X1012310 14 38XX22XXXXX XX XX XX XX XX XCycle 1Cycle 26618lim 1 = 18UB 1 = 1812103X XX X2X28 13 10 3XXXXXX XX XX XX XCycle 3Figure 13: Trace Update Lower Bounds BnB-ADOPTREM p = 3Mechanism requires user-dened relative error bound 1 p < species solutioncost p times larger minimal solution cost:limrr:= p LBXr(21)BnB-ADOPTREM resulting variant BnB-ADOPT Relative Error Mechanism.BnB-ADOPTREM terminates upper bound root node (which equal solutioncost solution smallest solution cost found far) larger limit (whichequal relative error bound p times lower bound root node, lowerbound minimal solution cost). BnB-ADOPTREM terminates solution costequal upper bound root node although minimal solution cost could smalllower bound root node. thus terminates solution cost p timeslarger minimal solution cost. Figure 13 shows trace BnB-ADOPTREM relativeerror bound p = 3 example DCOP problem. BnB-ADOPTREM terminates three cyclessuboptimal solution cost 18, six cycles faster BnB-ADOPT.4.3 Weighted Heuristics Mechanismsecond way implementing relative error bound BnB-ADOPT since BnB-ADOPTuses admissible heuristic values. common practice context A* trade solutioncost smaller runtime using weighted heuristic values (Pohl, 1973), derivedadmissible heuristic values multiplying user-dened weight 1 w < .resulting heuristic values inadmissible. A* longer guaranteed nd cost-minimalsolutions guaranteed terminate solution cost w times largerminimal solution cost (Pohl, 1970). approximation mechanism easily modiedBnB-ADOPT setting limit follows:limr:=113rLBXr(22)fiYeoh, Felner & Koenig9lim 1 = 9UB 1 = infinitylim 1 = 17lim 1 = 1817 UBa1 = infinity18 UBa1 = 1891817182091817182017620610 14 38XX2166XXXXX XX XX XX XX XX X1020610 14 38XX6XXXXX XX XX XX XX XX XCycle 1Cycle 2182161820106X XX X6X68 13 10 3XXXXXX XX XX XX XCycle 3Figure 14: Trace Update Lower Bounds BnB-ADOPTW HM w = 3initializing lower bounds lba,cX (d) follows:lba,cX (d):= w ha,cX (d)(23)agents a, values d, child agents c contexts X . BnB-ADOPTW HMresulting variant BnB-ADOPT Weighted Heuristics Mechanism. BnB-ADOPTW HMterminates upper bound root node (which equal solution cost solutionsmallest solution cost found far) larger limit (which equal lowerbound root node, lower bound w times minimal solution cost). BnBADOPTW HM terminates solution cost equal upper bound root nodealthough minimal solution cost could small lower bound root node dividedw. thus terminates solution cost w times larger minimalsolution cost. Figure 14 shows trace BnB-ADOPTW HM w = 3 example DCOPproblem. BnB-ADOPTW HM terminates three cycles suboptimal solution cost 18,six cycles faster BnB-ADOPT.5. Correctness Completenesssection, prove correctness completeness BnB-ADOPT suboptimalvariants. denitions, lemmata, theorems corollaries hold BnB-ADOPT suboptimal variants except mentioned otherwise. Therefore, agent uses following updateequation values d, child agents c contexts X initialize bounds lba,cX (d):a,clba,cX (d) := w hX (d)(24)weight w oating point number satises 1 w < heuristic valuesha,cX (d) oating point numbers satisfyc0 ha,cX (d) X (a,d)(25)Messages sent end cycle received beginning cycle. largestduration time message sent time processed, largest durationcycle.Lemma 1. two contexts X X arbitrary agent agree values ancestor= Xagents p SCP (a) agent a, X.Proof. denition, X X (reduced) context contains values ancestor agentssum constraint costs constraintsp SCP (a) agent a. gamma cost X114fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithminvolve agent one descendant agents minimized possible values agentdescendant agents, assumption ancestor agents agent take valuesthus depends values ancestor agents (includingcontext X. gamma cost Xparent agent) agent parent pseudo-parent agents agent one (or more)descendant agents, is, values ancestor agents p SCP (a) agent a. Therefore,= XX. Similarly, X = X .Definition 1. Contexts correct IDs values agents contexts equalIDs agents, implies values agents contexts equalvalues agents.Lemma 2. context X arbitrary agent change period time,lower bounds lba,cX (d), LBX (d) LBX monotonically non-decreasing uppera,cbounds ubX (d), U BX (d) U BX monotonically non-increasing period timevalues Dom(a) child agents c C(a).Proof. Since context X change, delta values X(d) constant bounds(once initialized) updated according update equations 8 13. Thus, lower boundsmonotonically non-decreasing upper bounds monotonically non-increasing.Lemma 3. value arbitrary ancestor agent p SCP (a) arbitrary agentchange current time future time + |A| ( + ) + ,value agent p ID context agent equal value agent p ID,respectively, time time t.Proof. Assume value arbitrary ancestor agent p SCP (a) arbitrary agentchange current time future time + |A| ( + ) + .following two cases.Case 1: agent p parent pseudo-parent agent agent a, sent VALUE messageagent value ID time + , is, cycle tookvalue time since duration cycle larger . (Theagents send VALUE messages end every cycle.) Agent receives VALUE messagetime + since messages delivered nite delay . updates valueagent p ID context time + + since update done cycleduration cycle larger . Thus, value agent p IDcontext agent equal value agent p ID, respectively,time time + + + + 2 since agent p changevalue time time t.Case 2: agent p parent pseudo-parent agent agent a, one pseudo-childagents c descendant agent agent a. Agent p sent VALUE message agent cvalue ID time + . Agent c receives VALUE message time + .updates value agent p ID context sends COST message parentagent pa(c) updated context time + + . (The agents send COST messagesend every cycle.) Agent pa(c) receives COST message time + 2 + .updates value agent p ID context sends COST message parentagent pa(pa(c)) updated context time + 2 ( + ). process continuesagent updates value agent p ID context time + n ( + ),n |A| number messages chain messages. Thus, value agent pID context agent equal value agent p ID, respectively,time time + n ( + ) + |A| ( + ) + since agentp change value time time t.115fiYeoh, Felner & KoenigCorollary 1. values ancestor agents p SCP (a) arbitrary agentchange current time future time + |A| ( + ) + , contextagent correct time time t.cccLemma 4. LBXc w X c w U BX c times child agents c C(a) arbitrarya,ca,cccagent contexts X , lbX (d) w X(a,d) w ubX (d) times contextX agent a, values Dom(a) child agents c C(a).Proof. prove lemma induction number times agent changes contexta,cupdates bounds lba,cX (d) ubX (d) arbitrary value arbitrary child agent cagent initializes bounds. conclusion lemma holds agent contextX initializes bounds sincea,clba,cX (d) = w hX (d)(Eq. 24)w(Eq. 25)cX(a,d)= w uba,cX (d)(Eq. 7)(unchanged new) context X agent (induction basis). assume lemmaholds agent changed context updated bounds number times (induction assumption). show also holds agent changes context updates bounds onetime (induction step). following two cases (where split operationsreceiving COST message two parts).Case 1: conclusion lemma holds agent changes context X Xreceiving VALUE COST message two contexts agree valuesancestor agents p SCP (c) since agent change bounds thus(d) = lba,clba,cX (d)Xcw X(a,d)(induction assumption)cw X(a,d)a,cubX (d)cX(a,d)cX (a,d)(Lemma 1)=uba,c(d)X(premise case)==(premise case)(induction assumption)(Lemma 1)receiving VALUE COST message (since contexts X X agree valuesancestor agents p SCP (c)).Case 2: conclusion lemma holds agent updates bounds lba,cX (d)a,ca,ca,cubX (d) lbX (d) ubX (d), respectively, receiving COST message childcccagent c bounds LBXcompatible context Xc U BX c context Xagent value since116fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithma,ca (d) = max{lba,ca (d), LB c c }lbXXXccmax{w X(a,d) , w X c }(Eq. 8)(induction assumption premise lemma)cc= max{w X(a,d) , w X (a,d) }=wa,ca (d)ubX(Lemma 1)cX(a,d)c= min{uba,cX (d), U BX c }ccmin{X(a,d) , X c }(Eq. 11)(induction assumption premise lemma)cc= min{X(a,d) , X (a,d) }=(Lemma 1)cX(a,d)receiving COST message (since contexts X (a, d) X c agree valuesancestor agents p SCP (c)).a,ccThus, lba,cX (d) w X (a,d) w ubX (d) times values Dom(a) childagents c C(a).Lemma 5. LBX(d) w X (d) w U BX (d) LBX w X w U BX timesvalues Dom(a) context X arbitrary agent A.Proof. prove lemma induction depth agent pseudo-tree. lemmaholds leaf agent pseudo-tree context X sinceLBX(d) = X (d)(Eq. 9)X(d)X (d)X(d)(Eq. 1)(Eq. 12)=U BX(d) ==(Eq. 1)values times. Thus, LBX(d) = X (d) w X (d) = w U BX (d) valuestimes. Furthermore,LBX==U BXmin{LBX(d)}(Eq. 10)dDom(a)min{X(d)}(see above)dDom(a)= X= min(Eq. 2)(Eq. 13){U BX(d)}dDom(a)=min{X(d)}(see above)dDom(a)= X(Eq. 2)times. Thus, LBX= X w X = w U BX times (induction basis). assumelemma holds agents depth pseudo-tree (induction assumption). showalso holds agents depth 1 pseudo-tree time updatebounds (induction step). lemma holds agent context X since117fiYeoh, Felner & KoenigLBX(d) = X (d) +lba,cX (d)(Eq. 9)cC(a)X(d) +cw X(a,d)(induction assumption Lemma 4)cC(a)w X(d)U BX(d) = X (d) +(Eq. 1)uba,cX (d)(Eq. 12)cC(a)X(d) +cX(a,d)(induction assumption Lemma 4)cC(a)= X(d)(Eq. 1)Thus, LBX(d) w X (d) w U BX (d) times values Dom(a). Furthermore,LBX=min{LBX(d)}(Eq. 10)dDom(a)min{w X(d)}(see above)dDom(a)=wmin{X(d)}dDom(a)= w XU BX=(Eq. 2)min {U BX(d)}dDom(a)min(Eq. 13){X(d)}(see above)dDom(a)= X(Eq. 2)Thus, LBXw X w U BX times.Definition 2. potential agent context XLBX(d)}.dDom(a) {wU BX(d)Lemma 6. context X arbitrary agent longer changes, potentialagent monotonically non-increasing decreases positive constant every timeagent changes value.Proof. lower bounds LBX(d) monotonically non-decreasing upper bounds U BX (d)monotonically non-increasing values according Lemma 2 since context Xagent longer changes. Therefore, potential agent monotonically non-increasing.Furthermore, agent changes value new value mindDom(a) {LBX(d)} < LBX (d)[Line 24]. Thus, lower bound LBX (d) must strictly increased timeagent changed value time changes value new value. Thus,potential decreased positive constant, namely smallest possible increaselower bound LBX(d). Assume constraint costs, weights heuristic values integers.Then, smallest possible increase bounded one possible valuesLBX(d) combinations constraint costs weighted heuristic values. similar statementholds constraint costs, weights heuristic values oating point numbers sincetransformed integers multiplying suciently large integer.Lemma 7. agents change values nite number times.118fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmProof. Assume lemma hold choose agent changes valueinnite number times whose ancestor agents p SCP (a) change values nitenumber times. Then, exists time ancestor agents change valueslonger. exists (later) time agent longer changes context X accordingCorollary 1. Every time agent changes value afterwards, potential decreasespositive constant according Lemma 6, towards minus innity. However, potential cannotbecome negative since LBX(d) w U BX (d) values according Lemma 5,contradiction. Thus, agents change values nite number times.Lemma 8. BnB-ADOPT suboptimal variants terminate earlier, U BXLBX nite amount time agents contexts X .Proof. prove lemma induction depth agent pseudo-tree. existstime agent changes value longer according Lemma 7. exists (later)time contexts agents correct longer change according Corollary 1. LetX context agent point time agents a. exists (even later)a,ctime bounds lba,cX (d), LBX (d), LBX , ubX (d), U BX (d) U BX longer changeagents a, values child agents c since (1) lower bounds lba,cX (d), LBX (d)a,cLBX monotonically non-decreasing upper bounds lbX (d), U BX (d) U BXmonotonically non-increasing agents a, values child agents c according Lemma2, (2) LBX(d) w X (d) w U BX (d) LBX w X w U BX agentsa,ca,cvalues according Lemma 5, (3) lbX (d) w ubX (d) agents a, valueschild agents c according Lemma 4 (4) smallest possible increases lower boundssmallest possible decreases upper bounds larger positive constant sincepossible values bounds combinations constraint costs heuristic values,explained detail proof Lemma 6. Consider rst COST message agentsends time earliest time COST messages processedreceiving agents. lemma holds leaf agent pseudo-tree context X sinceLBX(d) = X (d)= X(d)(Eq. 9)(Eq. 1)U BX(d) = X (d)= X(d)(Eq. 12)(Eq. 1)values considered time. Furthermore,LBX==U BXmin{LBX(d)}min{X(d)}(Eq. 10)dDom(a)(see above)dDom(a)= X= min(Eq. 2)(Eq. 13){U BX(d)}dDom(a)=min{X(d)}(see above)dDom(a)= X(Eq. 2)considered time. Thus, U BX= LBX considered time (induction basis).assume lemma holds agents depth pseudo-tree considered time(induction assumption). show also holds agents depth 1 pseudotree considered time (induction step). agent context X119fiYeoh, Felner & KoenigLBX(d) = X (d) +lba,cX (d)(Eq. 9)cmax{lba,cX (d), LBX c }(Eq. 8)cC(a)= X(d) +cC(a)X(d) +cLBXccC(a)X(d)+cU BXc(induction assumption)cC(a)X(d) +cmin{uba,cX (d), U BX c }cC(a)=X(d)+uba,cX (d)(Eq. 11)cC(a)= U BX(d)(Eq. 12)value considered time since bounds longer change. Thus, U BX(d)(d)valueconsideredtime.SinceagentchangevalueLBXconsidered time, must hold LBX(d)<min{TH,UB}[Line23]LBXaXaX (d) =mindDom(a) {LBX(d)}[Line24].rstdisjunctimpliesmin{T HX, U BX } U BXU BX(d)LBX (d)(Eq. 13)(see above)< min{T HX, U BX }(rst disjunct)value d, contradiction. second disjunct impliesU BXU BX (d)LBX(d)=min(Eq. 13)(see above){LBX(d)}(second disjunct)dDom(a)= LBX(Eq. 10)value thus U BXLBX .Theorem 1. BnB-ADOPT suboptimal variants terminate nite amount time.Proof. BnB-ADOPT suboptimal variants terminate earlier, U BXLBXnite amount time agents contexts X according Lemma 8.rrrrparticular, U BXroot agent r, limr = LBXr LBX r limr BnB-ADOPTrrb0BnB-ADOPTlimr = p LBXBnB-ADOPTW HM , limr = b + LBXrrAEMp 1 BnB-ADOPTREM according Section 4. Thus, termination conditionrrrrU BXsuboptimalr LBX r BnB-ADOPT termination condition U BX r limvariants satised.rTheorem 2. BnB-ADOPT terminates minimal solution cost Xr.120fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmProof. BnB-ADOPT terminates nite amount time according Theorem 1. solutionrrrcost BnB-ADOPT upper bound U BXr root agent r. U BX r LBX r upon terminationrrraccording termination condition. w U BX r w X r LBX r according Lemma 5.rrrTherefore, U BXr = X r = LBX r since w = 1.Theorem 3. BnB-ADOPTAEM terminates solution cost boundedruser-dened absolute error bound b plus minimal solution cost Xr.Proof. BnB-ADOPTAEM terminates nite amount time according Theorem 1.rrrsolution cost BnB-ADOPTAEM upper bound U BXr root agent r. U BX r lim =rrrb + LBX r upon termination according termination condition. LBX r w X r accordingrrLemma 5. Therefore, U BXr b + X r since w = 1.Theorem 4. BnB-ADOPTREM terminates solution cost boundedruser-dened relative error bound p times minimal solution cost Xr.Proof. BnB-ADOPTREM terminates nite amount time according Theorem 1.rrrsolution cost BnB-ADOPTREM upper bound U BXr root agent r. U BX r lim =rrrp LBX r upon termination according termination condition. LBX r w X r accordingrrLemma 5. Therefore, U BXr p X r since w = 1.Theorem 5. BnB-ADOPTW HM terminates solution cost boundedruser-dened weight w times minimal solution cost Xr.Proof. BnB-ADOPTW HM terminates nite amount time according Theorem 1.rrrsolution cost BnB-ADOPTW HM upper bound U BXr root agent r. U BX r lim =rrruponterminationaccordingterminationcondition.LBwaccordingLBXrXrXrrrLemma 5. Therefore, U BXw.rXr6. Experimental Evaluationssection, compare BnB-ADOPT two memory-bounded DCOP search algorithmsalso restrict communication agents share constraints, namely ADOPT NCBB.also compare three suboptimal variants BnB-ADOPT other. use distributedDFS algorithm max-degree heuristic (Hamadi, Bessiere, & Quinqueton, 1998) usedADOPT construct pseudo-trees. use DP2 (Ali et al., 2005) used ADOPTpre-calculate heuristic values ADOPT BnB-ADOPT. DP2 solves relaxed versiongiven DCOP problem (where backedges ignored) dynamic programming based approach.NCBB calculates heuristic values search rather pre-processing step.6.1 Runtime Metricsuse two common runtime metrics, namely non-concurrent constraint checks (Meisels, Kaplansky,Razgon, & Zivan, 2002) cycles (Modi et al., 2005).Non-concurrent constraint checks (NCCCs): NCCCs weighted sum processingcommunication time. Every agent maintains counter N CCC , initialized0. agent assigns N CCC := N CCC + 1 every time performs constraint checkaccount time takes perform constraint check. assigns N CCC :=max{N CCC , N CCC + t} every time receives message agent accounttime takes wait agent send message (N CCC ) transmission timemessage (t). use = 0 simulate fast communication = 1000 simulateslow communication. number NCCCs largest counter value agent.121fiYeoh, Felner & KoenigSensors132Targets56789410111213ConstraintsunitFigure 15: Example: Allocating TargetsFigure 16: Example: Scheduling MeetingsNCCCs good runtime metric ratio processing communication timeestimated reliably.Cycles: Cycles time slices. cycle time required agent process incomingmessages queue send outgoing messages, processed receivingagents next cycle. Thus, number cycles indicates length longest chainmessages agents. Cycles good runtime metric communication timemuch larger processing time. Cycles become better better runtime metricfuture since communication time expected remain relatively stableprocessing time expected decrease (Silaghi, Lass, Sultanik, Regli, Matsui, & Yokoo, 2008).6.2 DCOP Problem Typesuse three DCOP problem types experiments, namely graph coloring problems, sensornetwork problems meeting scheduling problems.Graph coloring: Graph coloring problems involve coloring vertices graph, takingrestrictions colors adjacent vertices account. agents vertices,domains colors, constraints adjacent vertices. varynumber vertices 5 15, constraint density (= ratio numberconstraints number agents) 2 (sparse graphs) 3 (dense graphs)range constraint costs range 0 1 (small range) range 0 10,000 (largerange). agent always three possible values. average experimental results50 DCOP problem instances randomly generated constraints randomly generatedinteger constraint costs.Sensor network: Sensor network problems involve assigning targets sensors sensornetwork, taking restrictions availability sensors, restrictions numbersensors need track target priorities targets account.agents targets, domains time slots tracked,constraints adjacent targets (Maheswaran et al., 2004b). Figure 15 shows sensornetwork targets located grid target surrounded four sensors,needed track target. vary number targets 4 15.always use 8 time slots. cost assigning time slot target also assignedadjacent target innity (to precise: 1,000,000) since sensor cannot tracktargets time slot. cost targets tracked timeslot 100. costs range 0 100. average experimental results50 DCOP problem instances randomly generated integer constraint costs.Meeting scheduling: Meeting scheduling problems involve scheduling meetingsemployees company, taking restrictions availability well prioritiesaccount. agents meetings, domains time slotsheld, constraints meetings share participants (Maheswaran et al.,122fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmGraph Coloring, Density = 2Communication Cost = 0Graph Coloring, Density = 2Communication Cost = 10001.E+08ADOPTBnB-ADOPTNCBB1.E+04NCCCNCCC1.E+051.E+031.E+02ADOPTBnB-ADOPTNCBB1.E+071.E+061.E+05567891011121314567Number Vertices89(a)Graph Coloring, Density = 2121314Graph Coloring, Density = 3Communication Cost = 01.E+06ADOPTBnB-ADOPTNCBBNCCC1.E+05Cycles11(b)1.E+041.E+03ADOPTBnB-ADOPTNCBB1.E+041.E+031.E+021.E+025678910 11Number Vertices12137148911121314(d)Graph Coloring, Density = 3Communication Cost = 10001.E+0910Number Vertices(c)Graph Coloring, Density = 31.E+05CyclesADOPTBnB-ADOPTNCBB1.E+08NCCC10Number Vertices1.E+071.E+061.E+051.E+04ADOPTBnB-ADOPTNCBB1.E+031.E+0278910111213147891011121314Number VerticesNumber Vertices(e)(f)Figure 17: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Graph ColoringProblems Constraint Costs Ranging 0 10,0002004b). Figure 16 shows hierarchical organization 4 units supervisor threesubordinates. example, supervisor 2 three subordinates 5, 6 7. unit,assume possible meetings: one entire unit (e.g., 2, 5, 6, 7), two parent-child meetings(e.g., 2, 5 2, 7) two sibling-sibling meetings (e.g., 5, 6 6, 7). vary numbermeetings 5 (1 unit) 20 (4 units). always use 8 time slots. cost assigningtime slot meeting least one participant another meetingtime slot innity (to precise: 1,000,000) since person cannot attendone meeting time. cost non-scheduled meeting 100. costsrange 0 100. average experimental results 50 DCOP problem instancesrandomly generated integer constraint costs.123fiYeoh, Felner & Koenig1.E+05Graph Coloring, Density = 2Communication Cost = 01.E+081.E+07NCCCNCCC1.E+04Graph Coloring, Density = 2Communication Cost = 10001.E+03ADOPTBnB-ADOPTNCBB1.E+021.E+06ADOPTBnB-ADOPTNCBB1.E+051.E+011.E+040-10-100-1000-1,000 0-10,0000-1Range Constraint Costs0-100-1000-1,000 0-10,000Range Constraint Costs(a)(b)Graph Coloring, Density = 21.E+061.E+04Graph Coloring, Density = 3Communication Cost = 0NCCCCycles1.E+051.E+03ADOPTBnB-ADOPTNCBB1.E+021.E+041.E+03ADOPTBnB-ADOPTNCBB1.E+021.E+011.E+010-10-100-1000-1,000 0-10,0000-1Range Constraint Costs(c)1.E+090-1000-1,000 0-10,000(d)Graph Coloring, Density = 3Communication Cost = 1000Graph Coloring, Density = 31.E+051.E+081.E+04CyclesNCCC0-10Range Constraint Costs1.E+071.E+06ADOPTBnB-ADOPTNCBB1.E+051.E+03ADOPTBnB-ADOPTNCBB1.E+021.E+041.E+010-10-100-1000-1,000 0-10,000Range Constraint Costs0-10-100-1000-1,000 0-10,000Range Constraint Costs(e)(f)Figure 18: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Graph ColoringProblems 10 Vertices6.3 Experimental Results: Optimal DCOP Search Algorithmsrst compare BnB-ADOPT ADOPT NCBB. Figure 17 shows experimental resultsgraph coloring problems constraint costs ranging 0 10,000, variednumber vertices, Figure 18 shows experimental results graph coloring problems10 vertices, varied range constraint costs. Figures 17(a-c) 18(a-c) showresults coloring sparse graphs, Figures 17(d-f) 18(d-f) show results coloringdense graphs. y-axes log scale show runtimes NCCCs cycles. DCOP searchalgorithms sparse graphs faster dense graphs because, example, largerlikelihood independent DCOP subproblems sparse graphs. BnB-ADOPT generally fasterNCBB sparse graphs dense graphs BnB-ADOPT allows agents sendmessages parent agents pseudo-tree (along edges pseudo-tree) NCBB124fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmSensor NetworkCommunication Cost = 10001.E+061.E+091.E+051.E+08NCCCNCCCSensor NetworkCommunication Cost = 01.E+041.E+03ADOPTBnB-ADOPTNCBB1.E+02ADOPTBnB-ADOPTNCBB1.E+071.E+061.E+051.E+011.E+0445647 8 9 10 11 12 13 14 15Number Targets56(a)(b)Sensor NetworkMeeting SchedulingCommunication Cost = 01.E+051.E+06ADOPTBnB-ADOPTNCBB1.E+05NCCCCycles1.E+041.E+031.E+021.E+04ADOPTBnB-ADOPTNCBB1.E+031.E+011.E+0245657 8 9 10 11 12 13 14 15Number Targets67(c)131415Meeting Scheduling1.E+051.E+071.E+04Cycles1.E+081.E+06ADOPTBnB-ADOPTNCBB1.E+0589 10 11 12Number Meetings(d)Meeting SchedulingCommunication Cost = 1000NCCC7 8 9 10 11 12 13 14 15Number Targets1.E+03ADOPTBnB-ADOPTNCBB1.E+021.E+041.E+0156789 10 11 12Number Meetings131415(e)56789 10 11 12Number Meetings131415(f)Figure 19: Experimental Results Comparing ADOPT, BnB-ADOPT NCBB Sensor NetworkMeeting Scheduling Problemsallows agents also send messages pseudo-parent agents (along backedges pseudotree). Thus, agents NCBB receive updates faster agents BnB-ADOPT. eectprevalent dense graphs since backedges dense graphs. However, dierenceBnB-ADOPT NCBB becomes negligible communication slow.Figure 17 shows BnB-ADOPT least half order magnitude faster ADOPTnumber vertices small. speedup ADOPT increases number verticesgets larger DCOP problems thus become complex. Similarly, Figure 18 showsspeedup ADOPT increases range constant costs increases DCOP problemsthus become complex. However, ADOPT faster BnB-ADOPT simple DCOPproblems. example, ADOPT requires fewer cycles BnB-ADOPT DCOP problemsconstraint costs ranging 0 1. Figure 19 shows trend sensor network meetingscheduling problems. reason behavior follows. ADOPT uses memory-bounded best125fiYeoh, Felner & KoenigSensor NetworkCommunication Cost = 01.E+05Sensor NetworkCommunication Cost = 10001.E+06NCCCNCCC1.E+041.E+03ADOPT1.E+021.E+05ADOPTBnB-ADOPTBnB-ADOPT1.E+011.E+040.50.60.70.8Weight0.910.50.6(a)0.910.91(b)Sensor Network1.E+03Sensor NetworkUnique Contexts Explored1.E+02No.ContextsCycles0.70.8Weight1.E+02ADOPTADOPTBnB-ADOPTBnB-ADOPT1.E+011.E+010.50.60.70.8Weight0.910.50.6(c)0.70.8Weight(d)Sensor NetworkRepeated Contexts ExploredNo.Contexts1.E+031.E+02ADOPTBnB-ADOPT1.E+011.E+000.50.60.70.8Weight0.91(e)Figure 20: Experimental Results Cause Speedup ADOPT BnB-ADOPTrst search thus exploits heuristic values well needs repeatedly reconstruct partialsolutions purged memory, especially heuristic values poorly informed. BnBADOPT uses depth-rst branch-and-bound search thus exploit heuristic valuesquite well repeatedly reconstruct partial solutions. ADOPT thusfaster BnB-ADOPT DCOP problems well informed heuristic values, simpleDCOP problems.conrm intuition additional experiment sensor network problems fourtargets dierent informedness heuristic values. use heuristic values cha,cX (d) 0.5c 1, ha,cX (d) heuristic values calculated DP2, used now. Figures 20(a-c)show number NCCCs dierent weights c. heuristic values well informed (largeweights), ADOPT indeed faster BnB-ADOPT. Since ADOPT relies heuristicvalues BnB-ADOPT, speedup ADOPT much larger BnB-ADOPTheuristic values get informed. Figures 20(d) 20(e) show number unique126fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithm(= dierent) repeated contexts per agent dierent weights c. heuristic valueswell informed (large weights), agents ADOPT explore fewer unique contexts agents BnBADOPT since focused search. However, heuristic values poorlyinformed (small weights), explore unique contexts. Agents ADOPT explore manyrepeated contexts agents BnB-ADOPT since need reconstruct partial solutionspurged memory. Agents BnB-ADOPT explore repeated contexts even thoughreconstruct partial solutions. reason behavior distributed natureBnB-ADOPT. example, assume context agent {(a1 , 0), (a2 , 0)} nextcontext centralized variant BnB-ADOPT would {(a1 , 1), (a2 , 1)} (where IDs omittedsimplicity). agent updates context {(a1 , 1), (a2 , 0)} receives messageagent a1 takes value 1. agent updates context {(a1 , 1), (a2 , 1)}receives message agent a2 takes value 1. Thus, agent explores intermediatecontext {(a1 , 1), (a2 , 0)} centralized variant BnB-ADOPT would explore. countsrepeated context agent explores context intentionally future. Overall, BnB-ADOPTtends faster ADOPT heuristic values poorly informed (small weights). Thus,BnB-ADOPT great potential DCOP search algorithm since heuristic values often poorlyinformed complex DCOP problems, DCOP problems large numbers agents, largedomains, large numbers constraints large ranges constraint costs.6.4 Experimental Results: Suboptimal Variants BnB-ADOPTcompare three suboptimal variants BnB-ADOPT other. experimentalsetup identical one optimal DCOP search algorithms, except follows: graphcoloring problems, number vertices 10, range constraint costs 0 10,000constraint density 2; sensor network problems, number targets 9; meetingscheduling problems, number meetings 10. measure runtimes cycles. (The resultsNCCCs similar.) However, report normalized runtimes, is, runtimes dividedruntime nding cost-minimal solution BnB-ADOPT. Thus, normalized runtime0.25 refers one quarter number cycles takes nd cost-minimal solutionBnB-ADOPT. Similarly, report normalized solution costs, is, solution costs dividedminimal solution costs. Thus, normalized solution cost 2.5 refers solution costtwo half times larger minimal solution cost. vary relative error bound (whichworst acceptable normalized solution cost) 1.0 4.0. relative error bound pBnB-ADOPTREM w BnB-ADOPTW HM . pre-calculate minimal solution costsset correct value b BnB-ADOPTAEM . example, minimal solution cost 100relative error bound 2.5, p = 2.5 BnB-ADOPTREM , w = 2.5 BnB-ADOPTW HMb = (2.5 1) 100 = 150 BnB-ADOPTAEM .Figure 21(a-c) shows experimental results graph coloring problems. Figure 21(a) showsnormalized solution costs three suboptimal variants increase relative errorbound increases. However, solution costs remain much smaller error bound.example, normalized solution costs three suboptimal variants less 1.3 (rather3) relative error bound 3. normalized solution costs BnB-ADOPTAEMusually larger normalized solution costs BnB-ADOPTREM relative errorrrbound. reason behavior BnB-ADOPTAEM terminates U BX=r limrrrrb + LBX r = (p 1) X r + LBX r , X r minimal solution cost. Thus, solution costrrrBnB-ADOPTAEM U BXr LBX r (p 1) X r larger minimal solutionrrrcost. hand, BnB-ADOPTREM terminates U BXr lim = p LBX r . Thus,rrrsolution cost BnB-ADOPTREM U BX r LBX r (p 1) LBX r largerminimal solution cost. absolute error bound BnB-ADOPTAEM thus smallerrrabsolute error bound BnB-ADOPTREM since Xr LBX r initially strictly greaterrrabsolute error bound BnB-ADOPTREM since X r > LBXr search.127fiYeoh, Felner & KoenigGraph ColoringSolution Cost BnB-ADOPT VariantsGraph ColoringComputation Time BnB-ADOPT Variants1.00Normalized Runtimes(Cycles)Normalized Costs1.351.301.251.201.15Weighted Heuristics (WHM)Absolute Error (AEM)Relative Error (REM)1.101.051.001.001.502.002.503.00Relative Error Bound3.500.800.400.200.001.004.00Weighted Heuristics (WHM)Absolute Error (AEM)Relative Error (REM)0.601.502.002.503.00Relative Error Bound(a)Graph ColoringPerformance BnB-ADOPT VariantsSensor NetworkPerformance BnB-ADOPT Variants1.000.80Normalized Runtimes(Cycles)Normalized Runtimes(Cycles)4.00(b)1.00Weighted Heuristics (WHM)Absolute Error (AEM)Relative Error (REM)0.600.400.200.001.003.501.051.101.151.20Normalized Costs1.251.300.80Weighted Heuristics (WHM)Absolute Error (AEM)Relative Error (REM)0.600.400.200.001.001.021.04(c)1.061.081.10Normalized Costs1.121.14(d)Meeting SchedulingPerformance BnB-ADOPT VariantsNormalized Runtimes(Cycles)1.000.80Weighted Heuristics (WHM)Absolute Error (AEM)Relative Error (REM)0.600.400.200.001.001.051.101.15Normalized Costs1.201.25(e)Figure 21: Experimental Results Comparing Suboptimal Variants BnB-ADOPTFigure 21(b) shows normalized runtimes three suboptimal variants decreaserelative error bound increases. decrease almost 0 relative error bound 2.0.Therefore, three suboptimal variants terminate almost immediately nding rst solution.normalized runtimes BnB-ADOPTAEM usually smaller normalized runtimesBnB-ADOPTREM relative error bound since BnB-ADOPTAEM terminatesuboptimal solution cost within absolute error bound yet within absolute errorbound BnB-ADOPTREM absolute error bound BnB-ADOPTAEM strictly greaterabsolute error bound BnB-ADOPTREM . words, BnB-ADOPTAEM terminaterrrsuboptimal solution cost (p 1) LBXr < U BX r (p 1) X r BnB-ADOPTREMnot.Figure 21(c) shows normalized runtimes needed achieve given normalized solution cost.BnB-ADOPTW HM terminates faster BnB-ADOPTAEM , turn terminates fasterBnB-ADOPTREM . example, normalized runtime needed achieve normalized solu-128fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP Algorithmtion cost 1.05 0.18 BnB-ADOPTW HM , 0.30 BnB-ADOPTAEM 0.35 BnBADOPTREM . Thus, BnB-ADOPTW HM suboptimal variant BnB-ADOPT bestperformance. Figures 21(d-e) show trend sensor network meeting scheduling problems.7. Conclusionsarticle, introduced Branch-and-Bound ADOPT (BnB-ADOPT), memory-boundedDCOP search algorithm. BnB-ADOPT uses message passing communication frameworkADOPT changes search strategy ADOPT best-rst search depth-rst branchand-bound search make ADOPT faster taking advantage fact DCOP problemsdepth-bounded search trees. properties BnB-ADOPT similar ADOPT.BnB-ADOPT allows agents operate concurrently (in order decrease runtime) asynchronously (in order increase robustness). BnB-ADOPT restricts communication agentsshare constraints (in order restrictions applications sensor networks). Finally,BnB-ADOPT orders agents pseudo-tree (in order take advantage independent DCOPsubproblems). experimental results showed BnB-ADOPT nds cost-minimal solutionsone order magnitude faster ADOPT variety large DCOP problems fastNCBB DCOP problems. reason behavior following: AgentsNCBB operate sequentially thus often idle. ADOPT construct fewer partial solutionsBnB-ADOPT reconstruct partial solutions purged memory.advantage ADOPT respect number constructed partial solutions decreasesdisadvantage respect number reconstructed partial solutions increases heuristicvalues become poorly informed. Thus, BnB-ADOPT great potential DCOP searchalgorithm since heuristic values often poorly informed complex DCOP problemsDCOP problems large numbers agents, large domains, large numbers constraints largeranges constraint costs.also investigated three approximation mechanisms trade solution cost BnBADOPT smaller runtime, namely Absolute Error Mechanism ADOPT (resultingBnB-ADOPTAEM ), new Relative Error Mechanism (resulting BnB-ADOPTREM )new Weighted Heuristics Mechanism (resulting BnB-ADOPTW HM ). two new approximation mechanisms allow users specify relative error bound, often meaningfulabsolute error bound. Weighted Heuristics Mechanism dominated Absolute Error Mechanism Relative Error Mechanism experiments applyDCOP search algorithms well since benet using heuristic values focussearches (Yeoh, Koenig, & Sun, 2008b).future, plan improve BnB-ADOPT following ways: First, would likereduce number sent messages handle lost messages. Second, would like studydierent pseudo-tree arrangements (Atlas & Decker, 2007; Sultanik, Lass, & Regli, 2009)pre-processing techniques (Matsui et al., 2009) aect eciency BnB-ADOPT. Finally,would like compare BnB-ADOPT approximation mechanisms DCOP algorithms,including OptAPO, DPOP variants (Petcu & Faltings, 2005a, 2006).Acknowledgmentsarticle extension two earlier publications (Yeoh, Felner, & Koenig, 2008a; Yeoh et al.,2008b) contains additional expositions, examples proofs. thank Anton Chechetkaproviding us implementation NCBB anonymous reviewers helpfulcomments. research done Ariel Felner spent sabbatical UniversitySouthern California, visiting Sven Koenig. research partly supported U.S. Army129fiYeoh, Felner & KoenigResearch Laboratory (ARL) U.S. Army Research Oce (ARO) award Sven Koeniggrant W911NF-08-1-0468, Oce Naval Research (ONR) award Sven Koenig grantN00014-09-1-1031, National Science Foundation (NSF) award Sven Koenig grant0413196 Israeli Science Foundation (ISF) award Ariel Felner grants 728/06305/09. views conclusions contained document authorsinterpreted representing ocial policies, either expressed implied, sponsoringorganizations, agencies, companies U.S. government.ReferencesAli, S., Koenig, S., & Tambe, M. (2005). Preprocessing techniques accelerating DCOPalgorithm ADOPT. Proceedings International Joint Conference AutonomousAgents Multiagent Systems (AAMAS), pp. 10411048.Atlas, J., & Decker, K. (2007). complete distributed constraint optimization method nontraditional pseudotree arrangements. Proceedings International Joint ConferenceAutonomous Agents Multiagent Systems (AAMAS), pp. 736743.Bayardo, R., & Miranker, D. (1995). space-time trade-o solving constraint satisfaction problems. Proceedings International Joint Conference Articial Intelligence(IJCAI), pp. 558562.Bistarelli, S., Montanari, U., Rossi, F., Schiex, T., Verfaillie, G., & Fargier, H. (1999). Semiring-basedCSPs valued CSPs: Basic properties comparison. Constraints, 4 (3), 199240.Bowring, E., Pearce, J., Portway, C., Jain, M., & Tambe, M. (2008). k-optimal distributedconstraint optimization algorithms: New bounds algorithms. Proceedings International Joint Conference Autonomous Agents Multiagent Systems (AAMAS), pp.607614.Bowring, E., Tambe, M., & Yokoo, M. (2006). Multiply-constrained distributed constraint optimization. Proceedings International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 14131420.Burke, D., & Brown, K. (2006). Eciently handling complex local problems distributed constraintoptimisation. Proceedings European Conference Articial Intelligence (ECAI), pp.701702.Chechetka, A., & Sycara, K. (2006). No-commitment branch bound search distributedconstraint optimization. Proceedings International Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 14271429.Choxi, H., & Modi, P. (2007). distributed constraint optimization approach wireless networkoptimization. Proceedings AAAI-07 Workshop Conguration, pp. 18.Davin, J., & Modi, P. (2006). Hierarchical variable ordering multiagent agreement problems.Proceedings International Joint Conference Autonomous Agents MultiagentSystems (AAMAS), pp. 14331435.Dechter, R. (Ed.). (2003). Constraint Processing. Morgan Kaufmann.Fitzpatrick, S., & Meertens, L. (2003). Distributed coordination anarchic optimization.Lesser, V., Ortiz, C., & Tambe, M. (Eds.), Distributed Sensor Networks: MultiagentPerspective, pp. 257295. Kluwer.Freuder, E., & Quinn, M. (1985). Taking advantage stable sets variables constraint satisfaction problems. Proceedings International Joint Conference Articial Intelligence(IJCAI), pp. 10761078.130fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmGershman, A., Meisels, A., & Zivan, R. (2009). Asynchronous Forward-Bounding distributedCOPs. Journal Articial Intelligence Research, 34, 6188.Greenstadt, R. (2009). overview privacy improvements k-optimal DCOP algorithms (extended abstract). Proceedings International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 12791280.Greenstadt, R., Grosz, B., & Smith, M. (2007). SSDPOP: Improving privacy DCOPsecret sharing. Proceedings International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 10981100.Hamadi, Y., Bessiere, C., & Quinqueton, J. (1998). Distributed intelligent backtracking. Proceedings European Conference Articial Intelligence (ECAI), pp. 219223.Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem. Proceedings International Conference Principles Practice Constraint Programming(CP), pp. 222236.Jain, M., Taylor, M., Tambe, M., & Yokoo, M. (2009). DCOPs meet real world: Exploringunknown reward matrices applications mobile sensor networks. ProceedingsInternational Joint Conference Articial Intelligence (IJCAI), pp. 181186.Junges, R., & Bazzan, A. (2008). Evaluating performance DCOP algorithms real world,dynamic problem. Proceedings International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 599606.Korf, R. (1993). Linear-space best-rst search. Articial Intelligence, 62 (1), 4178.Kumar, A., Faltings, B., & Petcu, A. (2009). Distributed constraint optimization structuredresource constraints. Proceedings International Joint Conference AutonomousAgents Multiagent Systems (AAMAS), pp. 923930.Lesser, V., Ortiz, C., & Tambe, M. (Eds.). (2003). Distributed Sensor Networks: MultiagentPerspective. Kluwer.Maheswaran, R., Pearce, J., & Tambe, M. (2004a). Distributed algorithms DCOP: graphical game-based approach. Proceedings International Conference ParallelDistributed Computing Systems (PDCS), pp. 432439.Maheswaran, R., Tambe, M., Bowring, E., Pearce, J., & Varakantham, P. (2004b). Taking DCOPreal world: Ecient complete solutions distributed event scheduling. ProceedingsInternational Joint Conference Autonomous Agents Multiagent Systems (AAMAS),pp. 310317.Mailler, R., & Lesser, V. (2004). Solving distributed constraint optimization problems using cooperative mediation. Proceedings International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 438445.Marinescu, R., & Dechter, R. (2007). Best-rst AND/OR search graphical models. ProceedingsAAAI Conference Articial Intelligence (AAAI), pp. 11711176.Marinescu, R., & Dechter, R. (2009). AND/OR branch-and-bound search combinatorial optimization graphical models. Articial Intelligence, 173 (16-17), 14571491.Matsui, T., Silaghi, M., Hirayama, K., Yokoo, M., & Matsuo, H. (2009). Directed soft arc consistencypseudo trees. Proceedings International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 10651072.Meisels, A., Kaplansky, E., Razgon, I., & Zivan, R. (2002). Comparing performance distributedconstraints processing algorithms. Proceedings Distributed Constraint ReasoningWorkshop, pp. 8693.131fiYeoh, Felner & KoenigModi, P., & Ali, S. (2004). Distributed constraint reasoning unreliable communication.Zhang, W., & Sorge, V. (Eds.), Frontiers Articial Intelligence Applications, Vol. 112,pp. 141150. IOS Press.Modi, P., Shen, W.-M., Tambe, M., & Yokoo, M. (2005). ADOPT: Asynchronous distributed constraint optimization quality guarantees. Articial Intelligence, 161 (1-2), 149180.Ottens, B., & Faltings, B. (2008). Coordinating agent plans distributed constraint optimization. Proceedings ICAPS-08 Workshop Multiagent Planning.Pearce, J., & Tambe, M. (2007). Quality guarantees k-optimal solutions distributed constraintoptimization problems. Proceedings International Joint Conference ArticialIntelligence (IJCAI), pp. 14461451.Pecora, F., Modi, P., & Scerri, P. (2006). Reasoning dynamically posting n-ary constraintsADOPT. Proceedings Distributed Constraint Reasoning Workshop, pp. 5771.Petcu, A., & Faltings, B. (2005a). Approximations distributed optimization. ProceedingsInternational Conference Principles Practice Constraint Programming (CP), pp.802806.Petcu, A., & Faltings, B. (2005b). scalable method multiagent constraint optimization.Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 14131420.Petcu, A., & Faltings, B. (2006). ODPOP: algorithm open/distributed constraint optimization. Proceedings National Conference Articial Intelligence (AAAI), pp. 703708.Pohl, I. (1970). First results eect error heuristic search. Machine Intelligence, 5,219236.Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamicweighting computational issues heuristic problem solving. Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 1217.Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued constraint satisfaction problems: Hardeasy problems. Proceedings International Joint Conference Articial Intelligence(IJCAI), pp. 631637.Schurr, N., Okamoto, S., Maheswaran, R., Scerri, P., & Tambe, M. (2005). Evolution teamworkmodel. Sun, R. (Ed.), Cognition Multi-Agent Interaction: Cognitive ModelingSocial Simulation, pp. 307327. Cambridge University Press.Silaghi, M., Landwehr, J., & Larrosa, J. (2004). Asynchronous branch & bound A* disWCSPsheuristic function based consistency-maintenance. Zhang, W., & Sorge, V. (Eds.),Frontiers Articial Intelligence Applications, Vol. 112, pp. 4962. IOS Press.Silaghi, M., Lass, R., Sultanik, E., Regli, W., Matsui, T., & Yokoo, M. (2008). operation pointunits distributed constraint solvers. Proceedings Distributed Constraint ReasoningWorkshop, pp. 116.Silaghi, M., & Yokoo, M. (2009). ADOPT-ing: Unifying asynchronous distributed optimizationasynchronous backtracking. Autonomous Agents Multi-Agent Systems, 19 (2), 89123.Stranders, R., Farinelli, A., Rogers, A., & Jennings, N. (2009). Decentralised coordination mobilesensors using Max-Sum algorithm. Proceedings International Joint ConferenceArticial Intelligence (IJCAI), pp. 299304.Sultanik, E., Lass, R., & Regli, W. (2009). Dynamic conguration agent organizations.Proceedings International Joint Conference Articial Intelligence (IJCAI), pp. 305311.132fiBnB-ADOPT: Asynchronous Branch-and-Bound DCOP AlgorithmYeoh, W., Felner, A., & Koenig, S. (2008a). BnB-ADOPT: asynchronous branch-and-boundDCOP algorithm. Proceedings International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 591598.Yeoh, W., Koenig, S., & Sun, X. (2008b). Trading solution cost smaller runtime DCOPsearch algorithms (short paper). Proceedings International Joint ConferenceAutonomous Agents Multiagent Systems (AAMAS), pp. 14451448.Yeoh, W., Varakantham, P., & Koenig, S. (2009). Caching schemes DCOP search algorithms.Proceedings International Joint Conference Autonomous Agents MultiagentSystems (AAMAS), pp. 609616.Yokoo, M., & Hirayama, K. (1996). Distributed breakout algorithm solving distributed constraintsatisfaction problems. Proceedings International Conference Multiagent Systems(ICMAS), pp. 401408.Zhang, W., & Korf, R. (1995). Performance linear-space search algorithms. Articial Intelligence,79 (2), 241292.Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2003). analysis application distributedconstraint satisfaction optimization algorithms sensor networks. ProceedingsInternational Joint Conference Autonomous Agents Multiagent Systems (AAMAS),pp. 185192.Zivan, R. (2008). Anytime local search distributed constraint optimization. ProceedingsAAAI Conference Articial Intelligence (AAAI), pp. 393398.Zivan, R., Glinton, R., & Sycara, K. (2009). Distributed constraint optimization large teamsmobile sensing agents. Proceedings International Conference Intelligent AgentTechnology (IAT), pp. 347354.133fiJournal Artificial Intelligence Research 38 (2010) 223-269Submitted 11/09; published 05/10Grounding FO FO(ID) BoundsJohan WittocxMaarten MarienMarc Deneckerjohan.wittocx@cs.kuleuven.bemaarten.marien@cs.kuleuven.bemarc.denecker@cs.kuleuven.beKatholieke Universiteit LeuvenDepartment Computer ScienceCelestijnenlaan 200A, 3001 Heverlee, BelgiumAbstractGrounding task reducing first-order theory finite domain equivalentpropositional theory. used preprocessing phase many logic-based reasoning systems.systems provide rich first-order input language user rely efficient propositionalsolvers perform actual reasoning.Besides first-order theory finite domain, input grounders contains many applications also additional data. exploiting data, size grounders output oftenreduced significantly. common practice improve efficiency grounder contextmanually adding semantically redundant information input theory, indicatinggrounder exploit data. paper present method computeadd redundant information automatically. method therefore simplifies taskwriting input theories grounded efficiently current systems.first present method classical first-order logic (FO) theories. extendFO(ID), extension FO inductive definitions, allows concisecomprehensive input theories. discuss implementation issues experimentally validatepractical applicability method.1. IntroductionGrounding, propositionalization, task reducing first-order theory finite domainequivalent propositional theory, called grounding. Grounding used preprocessing phasemany logic-based reasoning systems. serves provide user rich input language,enabling system rely efficient propositional solvers perform actual reasoning.Examples systems rely grounding found area finite first-order modelgeneration (Claessen & Sorensson, 2003; McCune, 2003; East, Iakhiaev, Mikitiuk, & Truszczynski,2006; Mitchell, Ternovska, Hach, & Mohebali, 2006; Torlak & Jackson, 2007; Wittocx, Marien, &Denecker, 2008d). systems turn used part theorem provers (Claessen & Sorensson,2003) lightweight software verification (Jackson, 2006). Currently, almost Answer SetProgramming (ASP) systems rely grounding preprocessing phase (Gebser, Schaub, & Thiele,2007; Perri, Scarcello, Catalano, & Leone, 2007; Syrjanen, 2000; Syrjanen, 2009). Also planningsystems (Kautz & Selman, 1996) relational data mining (Krogel, Rawles, Zelezny, Flach, Lavrac,& Wrobel, 2003) grounding frequently used. large number applications indicatesimportance grounding logic-based reasoning systems need develop efficient grounders.basic (naive) grounding method instantiating variables input theorypossible combinations domain elements. Grounding way polynomial sizedomain exponential maximum width formula input theory, may easilyproduce groundings unwieldy size. Several techniques developed efficiently producesmaller groundings. two main categories techniques. first, input theoryrewritten maximum width formulas decreases. Methods like clause splitting(Schulz, 2002) partitioning (Ramachandran & Amir, 2005) belong category.c2010AI Access Foundation. rights reserved.fiWittocx, Marien, & Deneckersecond type techniques applicable besides finite domain, additional dataavailable. often case practical model generation problems, onestypical ASP. graph problem data could encoding input graph; contextplanning, could description initial goal state, etc. Sometimes data explicitlyavailable, e.g., form database, sometimes implicit, e.g., set ground factsinput theory. second type techniques aims efficiently computing small groundingstaking data account.Observe types techniques combined grounder. paper mainlyfocus technique second category. explain intuition underlying method, considerfollowing model generation problem.Example 1. Let T1 first-order logic theory vocabulary {Edge, Sub}, consistingtwo sentencesuv (Sub(u, v) Edge(u, v))(1)xyz (Sub(x, y) Sub(x, z) = z),(2)T1 expresses Sub subgraph Edge one outgoing edge vertex. Computing subgraph given graph G = hV, Ei cast model generation probleminput theory T1 data G. data represented structure subvocabulary1 = {Edge} domain V EdgeI = E. solution obtained generating modelT1 expands interpretation Sub.Applying naive grounding algorithm produces |V |2 instantiations (1) |V |3 instantiations (2). taking data account, atoms Edge = substitutedtruth value . Simplifying resulting grounding eliminates |E| instantiations (1)|V | instantiations (2). Smart grounding algorithms interleave substitution simplificationgrounding process order avoid creating unnecessary parts grounding.Observe substituting atoms 1 simplifying still produces grounding sizeO(|V |3 ). Indeed, simplified grounding (2) set binary clauses Sub(i, j) Sub(i, k)i, j, k V 6= j. set size |V |3 |V |.grounders apply reasoning ground theory reduce even further. example,simplified grounding (1) consists clauses Sub(i, j) (i, j) 6 E. Sinceunit clauses, certainly true every model ground theory. followsbinary clauses Sub(i, j) Sub(i, k) either Sub(i, j) Sub(i, k) belongssimplified grounding (1) certainly true every model ground theory thusomitted simplified grounding (2). result grounding size |E ./1=1 E|,./1=1 denotes natural join matching first columns. sparse graph, |E ./1=1 E|much smaller |V |3 . However, since reasoning ground theory avoid creatinginstantiations formula, significantly speed grounding process.One way avoid large grounding without relying reasoning ground theoryadding redundant information formulas. method frequently used ASP. example,xyz(Edge(x, y) Sub(x, y) Edge(x, z) Sub(x, z) = z)(3)equivalent (2) given (1), grounding (without reasoning ground theory) equalone obtained kind reasoning ground theory illustrated above. illustratesadding redundant information may sometimes dramatically reduce size grounding.Since current grounders optimized ground formulas like (3) without trying instances,grounding may also speed lot.However, manually adding redundancy formulas disadvantages: leads complex hence, less readable theories. Worse, might introduce errors. requires good understanding used grounder, since depends grounder information beneficialadd where. Also, human developer could easily miss useful information.224fiGrounding FO FO(ID) Boundsmotivates study automated methods deriving redundant informationprincipled ways adding formulas. develop algorithm that, given model generationproblem input theory input data , derives redundant information, formpair symbolic upper lower bound subformula . boundsformula vocabulary . instance, Example 1, algorithm computeEdge(x, y) upper bound Sub(x, y), meaning Edge(x, y) true, Sub(x, y)true either. also show insert bounds formulas . example, insertingupperbound Edge(x, y) Sub(x, y) upperbound Edge(x, z) Sub(x, z) transforms (2)(3).rest paper organized follows. next section recall notionsfirst-order logic (FO) introduce notations used throughout paper. Section 3formally define grounding model generation additional data. Section 4 introduceupper- lowerbounds formulas. present any-time algorithm computecontext FO input theories. show bounds used rewrite input theoryequivalent theory smaller grounding.Although many search problems cast concisely naturally FO model generationproblems, problems require richer logics FO. One logic FO(ID), extensionFO inductive definitions. definitions used represent, e.g., conceptreachability graph. Section 5 extend rewriting method FO(ID).Section 6 discuss implement algorithm compute bounds. case study,show one particular grounding algorithm adapted exploit bounds directly.also present experimental results indicate impact method grounding sizetime. end related work conclusions.current paper extends previous work (Wittocx, Marien, & Denecker, 2008c). Besidesproofs main propositions thorough experimental validation, also followingparts added:theoretical result stating rewriting method certainly yields smaller groundings(Proposition 23);extension rewriting method FO(ID) (Section 5);section implementation issues (Section 6).2. Preliminariessection, introduce conventions notations used paper. assume readerfamiliar FO.2.1 First-Order Logicvocabulary tuple hP , F , V P , F V respectively sets predicatesymbols, function symbols variables. identify constants zero-arity function symbols.Abusing notation, often leave V simply write hP , F represent . vocabularysubvocabulary , denoted , P P , F F V V .Throughout paper variables denoted lowercase letters, predicate function symbolsuppercase letters. predicate function symbol associated arity n N. oftendenote predicate symbol P P/n function symbol F F/n indicate arities.Tuples sets variables denoted x, y, z. term inductively definedvariable x term;F/n function symbol t1 , . . . , tn terms , F (t1 , . . . , tn ) term.225fiWittocx, Marien, & DeneckerTuples terms denoted t, t1 , t2 , . . . . first-order logic formula inductively definedP/n predicate symbol t1 , . . . , tn terms, P (t1 , . . . , tn ) formula.t1 t2 two terms, t1 = t2 formula.formulas x variable, , , , x x formulas.use , t1 6= t2 shorthands respectively , ( ) ( )(t1 = t2 ). atom formula form P (t) t1 = t2 . literal atom negationatom.occurrence formula subformula formula positive, respectively negative,occurs scope even, respectively odd, number negations.formula , often write [x] indicate x free variables. is, x,occurs , scope quantifier . variable x term t,formula [x/t] denotes result replacing free occurrences x t. notationextended tuples variables terms length. sentence formula withoutfree variables. theory finite set sentences.-interpretation consists domaindomain element xI variable x V ;relation P Dn predicate symbol P/n P ;function F : Dn function symbol F/n F .-structure interpretation relation function symbols . restriction-interpretation vocabulary denoted I| . Vice versa, called expansionI| . variable x domain element d, I[x/d] interpretation assignsx corresponds symbols. notation extended tuples variablesdomain elements length. interpretation called finite domain finite.value tI term interpretation I, satisfaction relation |= definedusual (e.g., Enderton, 2001). called model formula |= . denote T1 |= T2every model theory T1 also model theory T2 .query expression form {x | }, free variables among x. tupledomain elements answer {x | } structure I[x/d] |= . set answers{x | } denoted {x | }I .2.2 Rewriting Term Normal Formpaper use following well-known equivalences rewrite formulas logicallyequivalent formulas.1. Moving quantifiersxyxyyx(4)yx(5)x ( )(x ) (x )(6)x ( )(x ) (x )(7)x ( )(x )x occur free(8)x ( )(x )x occur free(9)226fiGrounding FO FO(ID) Bounds2. Moving negations( )() ()(10)( )() ()(11)(x )x ()(12)(x )x ()(13)3. Flattening termsP (t1 , . . . , ti , . . . , tn ) x (x = ti P (t1 , . . . , ti1 , x, ti+1 , . . . , tn ))(14)x occur P (t1 , . . . , tn ).facilitate presentation, sometimes require formulas term normal form(TNF). say formula TNF, every atomic subformula form P (x),F (x) = x = y, negations occur directly front atoms. Using (10)(14), everyformula transformed equivalent formula TNF. say theory TNFsentences are.2.3 SATvocabulary propositional F = every predicate symbol P arity zero.propositional theory (PC theory) theory propositional vocabulary. propositional clausedisjunction propositional literals. PC theory conjunctive normal form (CNF)sentences clauses. Boolean satisfiability problem (SAT) NP-complete problemdeciding PC theory whether satisfiable. NP search problem corresponding SATproblem problem computing witness decision problem form modeltheory. SAT solvers typically operate constructing model.Contemporary SAT solvers exhibit impressive performance. such, many NP problemssolved efficiently translating SAT. instance, done areas modelgeneration (Claessen & Sorensson, 2003; McCune, 2003), planning (Kautz & Selman, 1996)relational data mining (Krogel et al., 2003). modern SAT solvers expect CNF theoryinput, instead general PC theory. input satisfiable theory, return modelwitness answer.3. Model Generation GroundingModel generation problem computing model logic theory , usually contextgiven finite domain, typically Herbrand Universe. model generator allows decidesatisfiability theory context fixed domain. useful, e.g., contextlightweight verification (Jackson, 2006). Beyond determining satisfiability, broad classproblems answers naturally given models declarative domain theory.example, model theory specifying scheduling domain typically contains (correct)schedule. Thus, model generator applied theory solve scheduling problemdomain.1 idea model generation declarative problem solving paradigmpioneered area ASP (Marek & Truszczynski, 1999; Niemela, 1999). area, answersproblem given models ASP theory.mentioned introduction, many practical model generation problems contain additionaldata besides input theory finite domain. data implicit input theory.1. set problems kind, see, e.g., benchmarks ASP-competition (http://dtai.cs.kuleuven.be/events/ASP-competition).227fiWittocx, Marien, & Deneckerexample, ASP problems split two parts: non-ground theory list ground facts.latter part essentially represents given data. contexts (Mitchell & Ternovska, 2005;Torlak & Jackson, 2007; Wittocx et al., 2008d), data given (partial) structure interpretingpart vocabulary input theory. paper assume without loss generalitydata represented structure. practice, often case preprocessing,e.g., materializing view database, needs done data format (see alsoSection 5.3.2).3.1 Model Expansion Search ProblemModel generation input theory input structure called model expansion. Model expansion logic L, denoted MX(L), defined follows.Definition 1. Let L-theory vocabulary , subvocabulary finite-structure. model expansion search problem input hT, problem computing-structure |= | = .vocabulary called input vocabulary problem, vocabulary \ expansionvocabulary. called input structure. denote |=I solutionmodel expansion search problem input hT, i. Similarly, formula denote|=I expands satisfies .Observe = , model expansion reduces model checking, = h, i, reducesmodel generation given finite size. Also, theory vocabularycontaining function symbols arity greater zero, Herbrand model generationsimulated model expansion. Indeed, let = h, F i, structure Herbranduniverse C = C every constant C F .illustrate model expansion two examples. examples paper, often usemany-sorted FO, since leads concise readable sentences. many-sorted FO,domain interpretation partitioned sorts (or types), variable associated sort,n-ary predicate symbol n-tuple associated sorts n-ary function symbolassociated (n + 1)-tuple sorts. interpretation variable x associated sorts, xI sI , sI denotes set domain elements sort s. Similarly, P/nassociated sorts (s1 , . . . , sn ), P sI1 sIn , F/n associated sorts (s1 , . . . , sn+1 ),F : sI1 sIn sIn+1 . often denote P P (s1 , . . . , sn ) F F (s1 , . . . , sn ) : sn+1indicate associated sorts.Example 2 (Graph Colouring). graph colouring problem problem colouring givengraph given set colours adjacent vertices different colours. expressproblem MX(FO), let V tx Col sorts let = h{Edge(V tx, V tx)}, i. sort Coldenotes given set colours, given graph represented V tx Edge. Letvocabulary hP , {Colour(V tx) : Col}i theory consists sentencev1 v2 (Edge(v1 , v2 ) Colour(v1 ) 6= Colour(v2 )).model expansion input theory input vocabulary expresses graph colouringproblem. Indeed, |=I , ColourM proper colouring graph represented .Example 3 (SAT). represent SAT problem MX(FO), let vocabulary containingtwo sorts Atom Clause, representing atoms clause input CNF theory,two predicates P osIn(Atom, Clause) N egIn(Atom, Clause), represent positive,respectively negative, occurrences atoms clauses. theory givenc ((P osIn(a, c) rue(a)) (N egIn(a, c) rue(a)))228fiGrounding FO FO(ID) Bounds= hP {T rue(Atom)}, expresses SAT problem: |=I , propositionalstructure represented rueM model CNF theory represented . Indeed, theoryforces every clause contains least one true literal.shown Mitchell Ternovska (2005), follows Fagins (1974) theorem modelexpansion FO captures NP, following sense:fixed problem deciding whether exists model expandinginput structure NP.Vice versa, NP decision problem X class finite -structuresvocabulary first-order -theory model expansion input theoryexpresses X, i.e., belongs X iff exists -structure |=I .result proves NP problem X expressed MX(FO) problem, henceshows broad applicability MX(FO) solvers solve NP problems.illustrated examples above, intention theory intuitive representation problem X. NP problems represented natural manner MX(FO).instance, problem deciding whether graph connected expressed MX(FO),requires non-trivial encoding fixpoint operator FO. Model expansion richerlogics FO better suited problems. Section 5 consider MX FO(ID),extension FO inductive definitions.3.2 Reducing MX(FO) SATrest paper, let theory vocabulary , subvocabularyfinite -structure domain D.Since every FO theory , deciding whether model expanding NP,problem reduced SAT problem Tprop polynomial time. However, want findmodels expanding using SAT solver, need method translate models Tpropmodels . Moreover, interested finding models expanding , oneto-one correspondence models models Tprop needed. paperfocus reductions preserve models, setting ASP paradigm (Marek &Truszczynski, 1999; Niemela, 1999).Let vocabulary Tprop . one-to-one correspondence modelsexpanding models Tprop , possible represent -structures expanding-structures. natural way accomplish choosing containssymbol Pd every P/n P Dn , symbol Fd,d0 every F/n F(d, d0 ) Dn+1 . -structure making Pd , respectively Fd,d0 true corresponds structureP , respectively F (d) = d0 . manner, every -structure expandingcorresponding -structure. Vice versa, every -structure satisfying requirementevery function symbol F/n Dn , exactly one d0 Fd,d0 trueA, corresponds -structure domains . is, one-to-onecorrespondence -structures satisfying every function symbol F/n Dnformula!_^^Fd,d0(15)Fd,d0 Fd,d0d0d01d02 D\d0112-structures domain D.Denote dom(I ) vocabulary extended new constant symbol every D.call new constants domain constants. Abusing notation, denote domainelements corresponding domain constants d. formula [x] tuple229fiWittocx, Marien, & Deneckerdomain constants, call [x/d] instance . -interpretation expandingformula containing domain constants, denote |= expansion dom(I )defined interpreting every domain constant corresponding domain element, satisfies .Definition 2. Two formulas 1 2 dom(I ) -equivalent |=I 1 iff |=I 2 ,every -interpretation .following straightforward results -equivalence.Lemma 3.1. Two logically equivalent formulas -equivalent.V2. dD [x/d] -equivalent x [x].W3. dD [x/d] -equivalent x [x].4. 0 0 -equivalent respectively , 0 , 0 0 , 0 0 , x 0x 0 -equivalent respectively , , , x x .5. subformula -equivalent 0 , result replacing 0-equivalent .formula ground normal form (GNF) contains quantifiers atomicsubformulas form P (d1 , . . . , dn ), F (d1 , . . . , dn ) = d1 = d2 , d1 , . . . , dn ,domain constants. theory GNF sentences GNF. GNF theory essentiallypropositional: replacing GNF theory every atom P (d) Pd , F (d) = d0 Fd,d0 , di = dj> if, respectively, = j 6= j, adding formula (15) every function symbol F/nDn , obtain propositional theory Tprop models Tprop correspond.Also note similarity GNF TNF theories.Definition 4. grounding respect GNF theory Tg dom(I )Tg -equivalent. Tg called reduced contain symbols .3.2.1 Grounding Algorithmsrest section, assume theory TNF. explained Section 2.2,make assumption without loss generality. introduce, reference, groundingrespect obtained naive grounding algorithm mentioned introduction.call grounding full grounding define formally induction.Definition 5. full grounding Grfull (, ) TNF sentence respect definedliteralGr()Gr()equal 1 2full2full 1Grfull () = Grfull (1 ) Grfull (2 ) equal 1 2(16)Vequal x [x]dD Grfull ([x/d])WGr([x/d])equal x [x]fulldDfull grounding respect theory consisting full groundingssentences respect .denote full grounding Grfull (T, ), Grfull (T ) clear context.follows directly Lemma 3 Grfull (T, ) indeed grounding respect .size full grounding exponential maximal nesting depth quantifiers sentences, polynomial domain size .230fiGrounding FO FO(ID) Boundsinductive definition like (16) evaluated top-down bottom-up way. approaches applied current grounders. one hand, grounders go top-downsyntax trees sentences . subformula form x [x], respectively x [x] reached, grounding [x/d] constructed every domain constant d,replaced conjunction, respectively disjunction, groundings.grounder dlv system (Perri et al., 2007) grounders gringo (Gebser et al., 2007)GidL (Wittocx, Marien, & Denecker, 2008b) take approach.grounders go bottom-up syntax trees. subformula [x] tablecomputed consisting tuples corresponding groundings [x/d]. tables computedfirst atomic formulas subsequently compound formulas. example, let [x, y, z]formula [x, y] [y, z] assume tables computed.table computed taking natural join tables value y,constructing grounding [x/dx , y/dy , z/dz ] (possibly simplified) conjunctiongroundings [x/dx , y/dy ] [y/dy , z/dz ]. Examples grounders bottom-up approachlparse (Syrjanen, 2000; Syrjanen, 2009), kodkod (Torlak & Jackson, 2007) mxg (Mitchellet al., 2006).obtain reduced grounding respect one could first construct full groundingreplace every subformula dom(I ) > |= otherwise.result simplified recursively replacing , > , etc. resultinggrounding one computed current grounding algorithms often lot smallerfull grounding. denote Grred (T, ), Grred (T ) clear context.Smart grounding algorithms use approach outlined above, try avoid creatingfull grounding substituting ground formulas input vocabulary soon possible.example, grounder top-down approach constructs grounding x [x], groundinginstances [x/d] one one making conjunction. process, instances[x/d] detected certainly true omitted. soon instance [x/d] detectedcertainly false, returned grounding x [x].grounder using bottom-up approach reduce size tables computesstoring tuples default value, e.g., >, corresponding grounding. particular,[x] formula , stores tuples 6|= [x/d]. reducing sizetables way, reduced grounding obtained much efficiently.4. Grounding Boundssection present method reducing grounding size. mentioned introduction,based computing bounds subformulas input theory . bound subformula[x] formula input vocabulary . describes set tuples [x/d]certainly true (false) every model expanding . larger set describedbound, precise bound is. Observe fact bounds formulas meansevaluated using given structure .Section 4.1, formally define bounds. indicate bounds insertedobtain new theory 0 . reduced grounding 0 often lot smaller reducedgrounding . precise inserted bounds are, smaller grounding 0 becomes.However, see 0 general weaker additional axiomsadded 0 obtain equivalence . additional axioms need grounded wellthat, careful, total size grounded theory decrease all.Section 4.3, search sufficient conditions bounds guarantee smaller grounding.Section 4.4, show derive bounds. method works two stages. First, boundssubformulas computed using any-time algorithm. longer algorithm runs,precise bounds derived. Often, bounds derived stage lead smallergroundings, reason explained previous paragraph. second stage, bounds231fiWittocx, Marien, & Deneckersatisfy conditions guarantee smaller groundings derived ones computedfirst stage.4.1 Boundsdistinguish two kinds bounds.Definition 6. certainly true bound (ct-bound) respect formula [x]formula ct [y] x |= x (ct [y] [x]). Vice versa, certainly falsebound (cf-bound) respect [x] formula cf [z] z x|= x (cf [z] [x]).mention clear context.Intuitively, ct-bound ct [x] provides every structure lower bound settuples true every model expanding . Indeed, every |=I{x | ct }I {x | }M . Vice versa, cf-bound cf provides lower bound set tuplesfalse: {x | cf }I {x | }M every |=I . Observe negationct-bound, respectively cf-bound, gives upper bound set tuples false,respectively true, least one model expanding .Example 4 (Example 1 ctd.). Let 1 subformula Sub(x, y) Sub(x, z) T1 .Edge(x, y) Edge(x, z) cf-bound 1 respect T1 1 . Indeed, one derive (1) T1 entailsxyz ((Edge(x, y) Edge(x, z)) 1 ) .Observe > ct-bound every sentence . Indeed, every sentence , |=therefore |= > . Also, ct-bound well cf-bound every formula. calltrivial bound. Intuitively, trivial bound contains information all: {x | }I =every x. According following definition, least precise bound.Definition 7. Let [y] [z] two (ct- cf-) bounds [x]. say [y] precise[z] x ([z] [y]) valid.precise bound [x] , provides larger lower bound {x | }I{x | }I every .Definition 8. c-map C mapping subformulas tuples(C ct (), C cf ()), C ct () C cf () respectively ct- cf-boundrespect .notion precision pointwise extends c-maps. is, C1 C2 two c-maps ,C1 precise C2 iff every subformula , C1ct () precise C2ct ()C1cf () precise C2cf ().Let model C c-map . definition ct- cf-boundsfollows immediately every subformula [x] , |= x (C ct () ) |=x (C cf () ) hold. say structure satisfies C precisely property.Definition 9. Let C c-map . theory C definedC ={x (C ct () ) | [x] subformula }{x (C cf () ) | [x] subformula }.structure satisfies C |= C.232fiGrounding FO FO(ID) BoundsClearly, C c-map |=I , |= C. call two formulas [x][x] C-equivalent {x | }I = {x | }I structure satisfies C. Equivalently,C-equivalent C |= x ( ).c-map inconsistent formula certainly true false tuple, accordingc-map:Definition 10. c-map C inconsistent x (C ct () C cf ()) validsubformula [x] . c-map C -inconsistent |= x (C ct () C cf ()) subformula.Proposition 11. exists -inconsistent c-map , 6|=I every. exists inconsistent c-map , 6|=I every .Proof. Let C -inconsistent c-map [x] subformula |=x (C ct () C cf ()). exists tuple domain elements [x/d] |= C ct ()[x/d] |= C cf (). Assume towards contradiction |=I . |= C, hence[x/d] |= C ct () [x/d] |= C cf () . Since | = , follows [x/d] |=[x/d] |= . contradiction.prove second statement, let C inconsistent c-map . C also-inconsistent c-map every -structure . such, model expanding.4.2 C-Transformationrest section, fix c-map C . show insert bounds Csentences . insertion based following lemma.Lemma 12. Let [x] subformula . C-equivalent C ct () C cf ().Proof. prove C |= x ( ( C ct ())) C |= x ( ( C cf ())).former immediately follows fact C |= x (C ct () ), latter factC |= x (C cf () ) .corollary lemma 12 following lemma.Lemma 13. Let sentence subformula . 0 result replacingsubformula C ct (), C cf () ( C cf ()) C ct (), |= iff|= 0 every satisfies C.Observe C ct () = C cf () = , C ct () C cf () logically equivalent. Hence, case sentence 0 Lemma 13 essentially sentence . Intuitively,adding trivial bounds sentence change sentence all.bounds assigned C inserted applying transformation Lemma 13subformulas . result called c-transformation , formally definedfollows.Definition 14 (c-transformation). c-transformation subformula respect C,denoted Chi, formula (0 C cf ()) C ct () 0 definedatomChiequalChi Chi equal0 :=Chi Chi equalx Chiequal xx Chiequal x233fiWittocx, Marien, & Deneckerc-transformation ChT respect C consists c-transformation respect Cevery sentence .Lemma 13, derive following.Lemma 15. ChT C-equivalent.general ChT logically equivalent. ChT may models satisfy C,therefore cannot models . example, let C c-map assigns (>, ) everysentence (, ) every subformula . sentences ChT form> hence ChT simplifies >, general equivalent . obtain ChTtheory equivalent , must add C.Theorem 16. C c-map C theory defined Definition 9, ChT Cequivalent .Proof. Let model . |= C, Lemma 13, |= ChT C.hand, |= ChT C, Lemma 13, |= .Corollary 17. C c-map , ChT C -equivalent structure .4.3 Atom-Based Atom-Equal C-MapsCorollary 17 implies compute grounding respect first computingc-map C grounding ChT C. approach beneficial reducedgrounding ChT C smaller reduced grounding , constructed leastfast. general conditions satisfied. precise c-map C is, smallerreduced grounding ChT becomes, larger reduced grounding C is:Proposition 18. C1 precise C2 , Grred (C1 hT i) smaller Grred (C2 hT i).Moreover, every subformula occurs Grred (C1 hT i) also occurs Grred (C2 hT i).Proof. (Sketch) Let [x] subformula tuple domain elements. sufficesshow C2 hi[x/d] replaced >, respectively , grounding, also caseC1 hi[x/d]. proven induction. base case, assume atom.C2 hi[x/d] formula (( C2cf ()) C2ct ())[x/d]. formula replaced >grounding, three possibilities: formula , [x/d] |= C2ct () [x/d] |= C2cf ().Since C1 precise C2 , [x/d] |= C2ct () implies [x/d] |= C1ct () [x/d] |= C2cf ()implies [x/d] |= C1cf (). conclude C2 hi[x/d] replaced > grounding,also case C1 hi[x/d]. inductive case similar.Proposition 19. C1 precise C2 , Grred (C1 ) larger Grred (C2 ).Proof. (Sketch) Every sentence C1 form x (C1ct () ) x (C1cf () ).number instances C1ct () reduced grounding C1 equal number[x/d] |= C1ct (). Similarly C1cf () . Since C2 less precise C1 , numberinstances Grred (C2 ) corresponding sentences x (C2ct () ) x (C2cf () )smaller.c-map useful reduce grounding size therefore precise, orderavoid large theory Grred (C), still precise enough decrease size Grred (ChT i).section, present sufficient conditions ensure properties. first define classc-maps avoid blow-up Grred (C) ensuring C replaced equivalent, smallereasy-to-find theory C . such, Grred (C) replaced smaller theory Grred (C ).class present, C subset C, namely set sentences C stem atomicsubformulas :234fiGrounding FO FO(ID) BoundsDefinition 20. Define theory CC ={x (C ct () ) | [x] atomic subformula }{x (C cf () ) | [x] atomic subformula }.call C atom-based C |= C.Example 5 (Example 1 ctd.). Let C2 c-map assigns (, (Edge(x, y) Edge(x, z)))Sub(x, y) Sub(x, z) (, ) every subformula. C2 atom-based, since (C 2 )Aequivalent >, C 2 contains sentencexyz ((Edge(x, y) Edge(x, z)) (Sub(x, y) Sub(x, z))).(17)Let C3 c-map assigns (, Edge(x, y)) Sub(x, y), (, Edge(x, z)) Sub(x, z)corresponds C2 subformulas T1 . C3 atom-based. Indeed, (C 3 )A consists(equivalent) sentencesxy (Edge(x, y) Sub(x, y))(18)xz (Edge(x, z) Sub(x, z))(19)C 3 consists sentences (17), (18) (19). (18) (19) imply (17), therefore,(C 3 )A |= C 3 .Clearly, c-map assigning (, ) every non-atomic subformula example atombased c-map. such, c-map transformed atom-based one replacing everybound assigned non-atomic subformula . next section, show computeinteresting atom-based c-maps.Observe Grred (C ) contains unit clauses. Combining definition atom-basedc-map Theorem 16 immediately gives following result.Proposition 21. Let C atom-based c-map . ChT iC equivalent,hence -equivalent every -structure .obtain small groundings using bounds, important information boundsexploited wherever possible. particular, ct- cf-bound assigned atom P (x),similar bound assigned every atom form P (y). call c-map atom-equalexactly property atomic subformulas . is, C atom-equal assignsessentially bounds atomic subformulas predicate function symbol:Definition 22. c-map C TNF theory atom-equal every predicate symbolcfP/n exist formulas ctP [x1 , . . . , xn ] P [x1 , . . . , xn ] every atom P (y1 , . . . , yn )ctcfoccurs , C (P (y1 , . . . , yn )) equal ctP [x1 /y1 , . . . , xn /yn ] C (P (y1 , . . . , yn )) equalcfP [x1 /y1 , . . . , xn /yn ], similarly function symbols.Note predicate function symbol occurs theory , everyc-map atom-equal.Example 6 (Example 1 ctd.). Let T2 theory obtained adding sentence w Sub(w, w)T1 . predicate occurs T2 predicate Sub. Let C4 c-mapT2 assigns following bounds atomic subformulas T2 Sub: (, Edge(u, v))Sub(u, v), (, Edge(x, y)) Sub(x, y), (, Edge(x, z)) Sub(x, z) (, Edge(w, w))cfSub(w, w). C4 atom-equal. Indeed, take ctSub = Sub = Edge(x1 , x2 ),conditions Definition 22 satisfied predicate Sub.235fiWittocx, Marien, & Deneckeratom-equal c-map C, C general contains many equivalent sentences. example,c-map C4 Example 6, (C 4 )A contains amongst others, equivalent sentences (18)(19). also contains w Edge(w, w) Sub(w, w), implied (18). result,C atom-equal c-map, grounding C naive way yields grounding contains severalformulas once. following proposition, assume redundancy removed.words, assume grounding algorithm C never adds GNF formulagrounding. accomplished grounding instead C sentencescfbctbcfbx (ctbP P (x)) x (P P (x)) every predicate symbol P , P PDefinition 22, similarly function symbols.Proposition 23. Let C atom-based, atom-equal c-map TNF theory . modelexpanding , Grred (ChT C ) large Grred (T ).proof, denote size theory Tg |Tg |.Proof. outline proof follows. First, show every subformula occursGrred (ChT i), occurs Grred (T ). Then, prove atom occurring Grred (C ) occursGrred (ChT i). Next, show every atom occurring Grred (C ) occurs leastGrred (T ). Since assumed Grred (C ) contain formula once, follows|Grred (ChT i)| |Grred (T )| |Grred (C )|, concludes proof.directly apply Proposition 18 show every subformula Grred (ChT i) occursGrred (T ): C 0 trivial c-map, Grred (T ) equal Grred (C 0 hT i), clearly Cprecise C 0 .show none atoms occurring Grred (C ) occur Grred (ChT i). Let P (d)atom occurring Grred (ChT i). atomic subformula P (x)6 {x | C ct (P (x))}I 6 {x | C cf (P (x))}I . C atom-equal, followssubformula P (y) occurring , neither {y | C ct (P (y))}I {y | C cf (P (y))}I . ThereforeP (d) occur Grred (C ).remains show every atom occurs Grred (C ) also occurs Grred (T ). Letmodel Grred (T ). model exists assumed model expanding . LetP (d) atom occur Grred (T ). P predicate input vocabulary,P (d) occur Grred (C ) either. hand, P expansion vocabulary,structure 0 obtained swapping truth value P (d) also model Grred (T ).Since Grred (ChT C ) -equivalent Grred (T ) P 6 , follows |= Grred (C )0 |= Grred (C ). Grred (C ) contains unit clauses, conclude P (d)occur Grred (C ).following algorithm create small grounding respect : firstcompute atom-based, atom-equal c-map C (We present algorithmSection 4.4). C -inconsistent, output stop. Else, output Grred (ChT C ).follows Propositions 11 21 result algorithm indeed groundingrespect . Observe first step algorithm independent . onesolve several model expansion problems fixed input theory input vocabulary ,varying , suffices compute C once.perform last step algorithm, one could apply off-the-shelf grounder inputChT C .4.4 Computing Boundspresent algorithm compute (non-trivial) c-map C. based workapproximate reasoning FO (Wittocx, Marien, & Denecker, 2008a). general resulting cmap neither atom-based atom-equal, atom-based, atom-equal c-map derivedit.236fiGrounding FO FO(ID) Bounds4.4.1 Refining C-MapsConstructing non-trivial c-map done starting least precise c-map, i.e., oneassigns (, ) every subformula , gradually refining it. refinement stepconsists three operations:1. Choose subformula .2. Compute current c-map C new ct-bound rct cf-bound rcf . Below,elaborate step: present six different ways obtain new ct- cf-bounds, calledrefinement bounds, C. sentences represented syntax trees,node corresponds subformula . Bottom-up refinement bounds boundsnode computed considering bounds assigned C children. Vice versa, top-downrefinement bounds computed looking parents siblings node. Axiomrefinement bounds bounds roots, i.e., sentences , input, copyfunctional refinement bounds practice mainly bounds atomic subformulas .3. Substitute C ct () C ct () rct , respectively C cf () C cf () rcf .According following lemma, refinement step yields new bound preciseone assigned C.Lemma 24. two ct-bounds respect , also ct-bound. Moreover, precise precise . holds cf-bounds.Proof. Let two ct-bounds [x]. definition, |= x ( ) |= x ( ).Therefore |= x (( ) ), proves ct-bound . Since |= ( )|= ( ), precise bound . proof cf-boundssimilar.conclude repeatedly applying refinement steps leads precise c-map.resulting algorithm any-time algorithm. Section 6 discuss stop criterionalgorithm. also give examples reach fixpoint, examplescannot.present different ways obtain refinement bounds.Input Refinement Let [x] formula input vocabulary . Since |= x ([x] [x])|= x ([x] [x]), clear [x] ct-bound [x] cf-bound [x].call input refinement ct- cf-bounds.Axiom Refinement sentence , > axiom refinement ct-bound .refinement bound states sentence true every model .Bottom-Up Refinement compound subformula , depending structure, Table 1gives bottom-up refinement ct-bound rct cf-bound rcf respect C. ratherstraightforward obtain formulas. instance, formula bottom-right tableindicates formula , certainly false tuplescertainly false. Or, formally, |= C cf () |= C cf () ,|= C cf () C cf () ( ).Top-Down Refinement case top-down refinements, bounds formula usedconstruct refinement bounds one direct subformulas (i.e., one childrensyntax tree). top-down refinement ct-bounds rct cf-bounds rcf givenTable 2. table, tuple denotes free variables occur x0denotes new variable. illustrate refinement bounds. explanation237fiWittocx, Marien, & DeneckerrctrcfcfctC ()C ()ctxx C ()x C cf ()xx C ct ()x C cf ()C ct () C ct ()C cf () C cf ()ctctC cf () C cf ()C () C ()Table 1: Bottom-up refinement boundsrctxC cf ()C ct ()xC ct () x0 (x 6= x0 C cf ()[x/x0 ])C ct ()(C ct () C cf ())rcfC ct ()xC () x (x 6= x0 C ct ()[x/x0 ])xC cf ()(C cf () C ct ())C cf ()0cfTable 2: Top-down refinement bounds238fiGrounding FO FO(ID) Boundsbounds certain sense precise ones obtained, refer workapproximate reasoning (Wittocx et al., 2008a).Let formula x P (x, y). Recall intuitively, ct-bound C ct () indicatesdomain elements d, x P (x, d) certainly true. arbitrary d0 D, P (d0 , d)must true. Hence, C ct () ct-bound . Indeed, since x occur free C ct (),|= xy (C ct () P (x, y)) follows |= (C ct () x P (x, y)).let formula P (x) Q(x, y). know P (d1 ) Q(d1 , d2 ) certainly false,Q(d1 , d2 ) certainly true, P (d1 ) must certainly false. Hence, C cf () C ct ()cf-bound P (x).Let formula x P (x, y) assume x P (x, dy ) certainly true, d0x ,except dx , P (d0x , dy ) certainly false. conclude P (dx , dy ) must true.precisely expressed formula C ct () x0 (x 6= x0 C cf ()[x/x0 ]).Functional Refinement [x, y] formula F (x) = y, functional refinement boundstake account F function. functional refinement ct-bound rct cf-bound rcfgiven by:rct := 0 (y 0 6= C cf ()[y/y 0 ])rcf := 0 (C ct ()[y/y 0 ] 6= 0 )0 new variable. Informally, first formulas indicates F (x) certainlyequal every 0 6= y, F (x) certainly equal 0 . second one says F (x)certainly equal F (x) certainly equal 0 0 6= y.Copy Refinement Let [x1 , . . . , xn ] [y1 , . . . , ym ] two formulas [x1 /z, . . . , xn /z][y1 /z, . . . , ym /z] same, modulo renaming non-free variables. is,exactly syntax tree, variables may differ. Denote E(, ) setequalities xi = yj occurrenceV xi , yj occurs corresponding positionct. formula y1 . . . yV(C()E(, )) copy refinement ct-boundformula y1 . . . ym (C cf () E(, )) copy refinement cf-bound . also saycopy-refinement bounds .Example 7. Let formula P (x1 , x1 ) Q(x2 , s) formula P (y1 , y2 ) Q(y2 , t).[x1 /z, x2 /z] equal [y1 /z, y2 /z] modulo renaming t, formulas satisfyrequirement copy refinement. set E(, ) given {x1 = y1 , x1 = y2 , x2 = y2 }hence,y1 y2 (C ct () x1 = y1 x1 = y2 x2 = y2 )copy refinement ct-bound . Observe C ct () contain bounded occurrencesx1 x2 , formula equivalent simpler formula C ct ()[y1 /x1 , y2 /x1 ] x1 = x2 .One-Step Refinements call rct (rcf ) refinement ct-bound (cf-bound) respectC input, axiom, bottom-up, top-down, functional copy refinement ct-bound (cf-bound)respect C. Lemma 25 states refinement ct-bound (cf-bound) indeed ct-bound(cf-bound).Lemma 25. rct refinement ct-bound respect C, ct-bound .Similarly cf-bounds.Proof. proof consists simple analysis cases. proved casesintroduced input, bottom-up top-down refinement. proof cases similar.Definition 26. Let C c-map , subformula , rct refinement ct-boundrcf refinement cf-bound respect C. assignment C r corresponds C, exceptassigns C r () = (C ct () rct , C cf ()) C r () = (C ct (), C cf () rcf ) called one-steprefinement C.239fiWittocx, Marien, & DeneckerLemma 24 25 obtain following result.Proposition 27. Every one-step refinement c-map c-map .already mentioned beginning section, one compute c-mapfirst assigning (, ) every subformula repeatedly applying one-step refinements.call nondeterministic any-time algorithm refinement algorithm.Example 8 (Example 1 ctd.). Figure 1 shows possible run refinement algorithm input. Here, sentences T1 represented syntax trees. numbers indicatestep bounds refined. trivial bounds shown.step (1), ct-bound first sentence replaced > using axiom refinement.course, new bound simplified >. following steps, figure shows simplifiedbounds. step (2) (3) bounds subformula Edge(u, v) refined input refinement.Then, top-down refinement used set ct-bound Sub(u, v) Edge(u, v) >. Next,top-down refinement, Edge(u, v) becomes ct-bound Sub(u, v) cf-boundSub(u, v).similar way, cf-bound 6= z derived subformula Sub(x, y) Sub(x, z) (step (7)(12)). Then, copy refinement, cf-bounds Sub(x, y) becomes uv (Edge(u, v) u =x v = y), wich simplifies Edge(x, y). Likewise, simplification, Edge(x, z) copyrefinement cf-bound Sub(x, z). Finally, two steps bottom-up refinement used setct-bound (Sub(x, y) Sub(x, z)) 6= z Edge(x, y) Edge(x, z).step, fixpoint reached: every one-step refinement performed yieldsbound logically equivalent one tries refine.Example 9. Consider simplified planning problem, actions scheduledaction ap precondition action a0 , ap performed earlier time pointa0 . problem described theory T3 , consisting sentencea0 ap t0 P rec(ap , a0 ) Do(a0 , t0 ) (tp tp < t0 Do(ap , tp )).sentence, follows chain actions must executed a0 executed,a0 cannot executed ith timepoint. Therefore, > 0, following formulacf-bound Do(a0 , t0 ) 2 = {P rec, <}:a1 ai (P rec(a1 , a0 ) . . . P rec(ai , ai1 )) t1 ti (t1 < t0 . . . ti < ti1 ).Denote formula . n > 0 sufficient number steps, refinement algorithmderive n := 1 . . . n cf-bound Do(a0 , t0 ). Clearly, n1 6= n2 , n1logically equivalent n2 . indicates refinement algorithm reach fixpointinput T3 2 .shown examples, several issues concerning practical implementationrefinement algorithm.1. Due non-deterministic nature algorithm, heuristic needed choosebounds refine kind refinement apply. reasonable choice first applypossible axiom input refinements. Then, top-down refinement formula appliedbound parent one siblings syntax tree recently refined.Similarly, bottom-up refinement applied bound one children refined.strategy used Example 1.2. bounds simplified regular time points, i.e., replaced equivalent smaller formulas. bounds simplified, grow size, rapidlyleading formulas unwieldy size. simplification algorithm discussed Section 6.240fiGrounding FO FO(ID) Boundsu, v(5) ct: Edge(u, v)(1) ct: >(4) ct: >Edge(u, v)(2) ct: Edge(u, v)(3) cf: Edge(u, v)(6) cf: Edge(u, v)Sub(u, v)x, y, z(11) ct: 6= z(7) ct: >(10) ct: >y=z(16) ct: 6= zEdge(x, y) Edge(x, z)(8) ct: = z(9) cf: 6= z(12) cf: 6= z(15) cf: 6= zEdge(x, y) Edge(x, z)(13) cf: Edge(x, y)Sub(x, y)Sub(x, z)(14) cf: Edge(x, z)Figure 1: Refining c-map241fiWittocx, Marien, & Denecker3. able detect fixpoint reached, one needs find two boundsequivalent. general undecidable. detect fixpoint least cases, onecould use FO theorem prover (and restrict running time).case fixpoint cannot reached detected, another stop criterion needed. example,one could restrict number one-step refinements, total time refinement algorithm use. Another stop criterion, simple fixpoint check discussed Section 6.4.4.2 Extracting Atom-Based Atom-Equal C-Mapc-maps obtained refinement algorithm general neither atom-based atom-equal.derive arbitrary c-map C atom-equal c-map least precise C, firstcollect predicate P bounds assigned occurrences P theory.disjunction bounds assigned new bound occurrence P . boundsassigned atoms P essentially same, atom-equal c-map.present method formally:Definition 28. Let C c-map TNF theory P/n predicate. Let P (x11 , . . . , x1n ),. . . , P (xm1 , . . . , xmn ) occurrences P let y1 , . . . , yn n new variables. Denoteict , respectively icf , formulasx0i1 x0in (C ct (P (xi1 , . . . , xin ))[xi1 /x0i1 , . . . , xin /x0in ] y1 = x0i1 . . . yn = x0in )x0i1 x0in (C cf (P (xi1 , . . . , xin ))[xi1 /x0i1 , . . . , xin /x0in ] y1 = x0i1 . . . yn = x0in ),variables x0ij new variables. ct-copy closure P (xk1 , . . . , xkn ) respectWC disjunction 1im ict [y1 /xk1 , . . . , yn /xkn ]. cf-copy closure P (xk1 , . . . , xkn )Wformula 1in icf [y1 /xk1 , . . . , yn /xkn ]. copy-closure atoms form F (x) = definedsimilarly.denote ct-copy closure atom copyCct (), cf-copy closure copyCcf ().Definition 29. copy-closure C c-map assigns (copyCct (), copyCcf ()) everyatomic subformula , corresponds C subformulas.Example 10. Let T4 theory consisting sentences x (P (x) R(x)) (Q(y)R(y)) let C5 c-map 3 = {P, R} assigns (P (x), ) R(x) (Q(y), ) R(y).copy-closure C5 assigns((x0 (P (x0 ) x0 = x)) (x0 (Q(x0 ) x0 = x)), (x0 ( x0 = x)) (x0 ( x0 = x)))R(x). bounds simplify (P (x) Q(x), ). Likewise, copy-closure C5 assignsR(y) bounds simplify (P (y) Q(y), ).Proposition 30. copy-closure c-map atom-equal c-map.Proof. follows immediately definition atom-equal c-mapW since everyWpredicatesymbol P (or function symbol F ), bounds, namely formulas 1in ict 1in icfmentioned definition 28, assigned every atom P (respectively F ).Recall c-map C atom-based C implied C , i.e., sentences C stembounds atomic subformulas . method derive atom-based c-map arbitraryc-map based following observation. Let C c-map let [x]subformula . C ct () formula C ct () C ct (), i.e., bottom-up refinementct-bound respect C, |= x (C ct () ) implied |= x (C ct () )|= x (C ct () ). easy check property holds bottom-uprefinement bounds:242fiGrounding FO FO(ID) BoundsLemma 31. Let C c-map [x] subformula , let rct rcfbottom-up refinement bounds respect C. set direct subformulas , i.e.,children syntax tree, 0 theory given0 := {y C ct () | [y] S} {y C cf () | [y] S},0 |= x rct 0 |= x rcf .Definition 32. c-map C called bottom-up c-map every non-atomic subformula, C ct () bottom-up ct-refinement bound respect C, C cf ()bottom-up cf-refinement bound respect C.next proposition follows directly Lemma 31.Proposition 33. bottom-up c-map C atom-based.Observe bottom-up c-map C completely determined bounds assignsatomic subformulas . Hence, given c-map, one derive bottom-up c-mapretaining bounds atomic subformulas computing corresponding bottom-upc-map. conclude derive atom-based, atom-equal c-map arbitrary c-mapderiving atom-based c-map copy-closure.Example 11 (Example 1 ctd.). Let C6 fixpoint shown Figure 1. c-map atom-equal(and equivalent copy-closure). bottom-up c-map derived C6 shown Figure 2.Observe c-map less precise C6 . instance, cf-bound assigned C6conjunction Sub(x, y) Sub(x, z) disjunction two bounds, namely bound 6= z, obtainedtop-down refinement, bound Edge(x, y) Edge(x, z), obtained bottom-up refinement.c-map Figure 2, latter bound present.c-map Figure 2, c-transformation Sub(x, y) Sub(x, z) given((Sub(x, y) Edge(x, y)) (Sub(x, z) Edge(x, z))) (Edge(x, y) Edge(x, z)).formula contains repeated constraints Edge(x, y) Edge(x, z) variables x, z.general bottom-up c-maps produce many repetitions. could easily eliminatedspeed grounding process, depends used grounding algorithm onesbest deleted.5. Inductive DefinitionsAlthough NP problems cast MX(FO) problems, modelling problems using pureFO extremely complex. practice, modelling often enhanced considerably usingextensions FO constructs inductive definitions, subsorts, aggregates, partial functionsarithmetic. enriched language implemented model generator idp (Wittocxet al., 2008b; Wittocx & Marien, 2008).2paper focus grounding extension FO inductive definitions.well-known arbitrary domains, inductively definable concepts reachabilityFO-expressible. finite domains however, encoded (e.g., encoding fixpointconstruction), process tedious leads large theories. section extendrefinement algorithm FO(ID) (Denecker, 2000; Denecker & Ternovska, 2008). languageextends FO construct representing common types inductive definitions: monotone induction non-monotone induction induction well-founded orderiterated inductive definitions. definitions many applications real-life computational problems, e.g., planning problems problems involving reachability dynamic systems(Denecker & Ternovska, 2008, 2007). time, FO(ID) also integration FOlogic programming.2. idp downloaded http://dtai.cs.kuleuven.be/krr/software.html243fiWittocx, Marien, & Deneckeru, vct: Edge(u, v)ct: >ct: >Edge(u, v)ct: Edge(u, v)cf: Edge(u, v)cf: Edge(u, v)Sub(u, v)ct: xyz (y = z Edge(x, y) Edge(x, z))x, y, zct: = z Edge(x, y) Edge(x, z)ct: Edge(x, y) Edge(x, z)y=zct: = zcf: 6= zcf: Edge(x, y) Edge(x, z)cf: Edge(x, y)Sub(x, y)Sub(x, z)cf: Edge(x, z)Figure 2: bottom-up c-map244fiGrounding FO FO(ID) Bounds5.1 Three-Valued StructuresFO(ID) standard two-valued semantics, three-valued structures used formalsemantics definitions. Indeed, inductive definition defines set describing constructit. semantics, intermediate stages construction recorded three-valued sets,representing object whether belongs set not, whether yetderived. therefore recall basic concepts three-valued logic.denote truth values true, false unknown respectively t, f u. three-valued-interpretation consists domaindomain element xI variable x;function P : Dn {t, f, u} predicate symbol P/n;function F : Dn function symbol F/n.P (d) 6= u every tuple domain elements predicate symbol P , two-valued:corresponds interpretation assigns P iff P (d) = every predicate Pcorresponds symbols.truth order set truth values induced f < u < t, precision order pinduced u <p f u <p t. orders extended three-valued -structures: Jcorrespond F , defineJ iff P (d) P J (d) every P ;p J iff P (d) p P J (d) every d, P .Observe two-valued structures maximally precise three-valued structures.hand, least precise three-valued structure assigns P (d) = u every P .define truth value I()formula three-valued interpretation domainstandard Kleene semantics:(t1 , . . . , tn )) := P I(tI, . . . , tI );I(Pn11 2 ) := lub {I(1 ), I(2 )};I(1 2 ) := glb {I1 , I(2 )};I(I(x) := lub {I[x/d]()| D};I(x) := glb {I[x/d]()| D}.atom form P (d), tuple domain constants, called domain atom.(d)/v] interpretation assignstruth value v domain atom P (d), denote I[Pv P (d) corresponds symbols. notation extended sets domainatoms.5.2 Inductive DefinitionsFO(ID) theory set FO sentences definitions. definition finite set rulesform3x (P (x) ),3. Usually, nested terms allowed arguments P , facilitate presentation, allow variablesarguments paper.245fiWittocx, Marien, & DeneckerP predicate FO formula. free variables among x. P (x)called head rule, body. Predicates occur head rule calleddefined predicates . set defined predicates denoted Def(). symbolscalled open respect . set open symbols denoted Open().Observe FO(ID) theory appearance FO theory augmented collectionlogic programs. illustrated Denecker Ternovska (2008), entails FO(ID)sdefinitions used represent mathematical concepts, also sort commonsense knowledge often represented logic programs, (local forms of) closed worldassumption, inheritance, exceptions, defaults, causality, etc.semantics definitions given well-founded model (Van Gelder, Ross, & Schlipf,1991). argued Denecker Ternovska (2008), well-founded semantics correctly formalizessemantics mentioned types inductive definitions mathematics. borrowpresentation semantics Denecker Vennekens (2007).Definition 34. Let definition three-valued structure. well-founded inductionsequence hJ i0 three-valued structures1. J0 assigns P J0 (d) = u, P defined predicate corresponds open symbols;2. limit ordinal , J = lubp {J | < };3. every ordinal , J+1 relates J one following ways:(a) J+1 = J [P (d)/t] domain atom P (d) P J (d) = u rulex (P (x) ) , J [x/d]() = t.(b) J+1 = J [U/f], U set domain atoms, P (d) U , P J (d) =u rules x (P (x) ) , J+1 [x/d]() = f.Intuitively, (a) says domain atom P (d) made true rule P (x)head body [x/d] already true. hand (b) explains P (d)made false possibility making corresponding body true, except circularreasoning. set U , commonly called unfounded set, witness this: making atomsU false also makes corresponding bodies false.well-founded induction called terminal cannot extended anymore. limitterminal well-founded induction last element. Denecker Vennekens (2007) showterminal well-founded induction limit, corresponds well Open() , denoted wfm (I).well-founded modelfounded model extending I|three-valued general.two-valued structure satisfies definition = wfm (I). FO(ID) theoryfinite set FO sentences definitions. satisfies satisfies definitions sentences. definition J |Open() -structure, exists one expansionJ |= . definition called total |Open() -structure Jprecisely one expansion J satisfies . Intuitively, total definitions correspondwell-formed definitions: every defined predicate P , define tuple domain elementswhether belongs relation denoted P not. definition total, typicallyindicates error. Hence practice, definitions occur MX(FO(ID)) specificationstotal. example, case MX(FO(ID)) specifications used second ASPcompetition (Denecker, Vennekens, Bond, Gebser, & Truszczynski, 2009). general, checkingwhether definition total undecidable. However, several broad easily recognizableclasses total definitions. example, monotone stratified definitions total.give examples definitions MX(FO(ID)) problems.246fiGrounding FO FO(ID) BoundsExample 12. Definition 1 defines relation C transitive closure relation R.xy (T C(x, y) R(x, y)).1 =xy (T C(x, y) z (T C(x, z) C(z, y))).Example 13. cast problem finding Hamiltonian path given graph MX(FO(ID))problem, let= h{Edge/2},= {P {Ham/2, Reached/1}, {Start/0}i.Predicate Ham represents edges form path Reached verticespath. constant Start represents first vertex path. Let theoryv1 v2 (Ham(v1 , v2 ) Edge(v1 , v2 )).v1 v2 v3 (Ham(v1 , v2 ) Ham(v1 , v3 ) v2 = v3 ).v1 v2 v3 (Ham(v1 , v3 ) Ham(v2 , v3 ) v1 = v2 ).v Ham(v, Start).v Reached(v).v (Reached(v) v = Start)..v (Reached(v) w (Reached(w) Ham(w, v))).model expansion input structure input vocabulary expresses Hamiltonian pathproblem: every model |=I , collection edges (v1 , v2 ) HamM forms Hamiltonianpath graph represented EdgeI .well-known concept use later section completion definition.completion definition FO theory weaker , defined follows.Definition 35. completion definition FO theory contains every P Def()sentencex (P (x) ((x = 1 1 ) . . . (x = n n ))),1 (P (y 1 ) 1 ), . . . , n (P (y n ) n ) rules P head.denote completion Comp(). Clearly, every body rule occursComp(). theory denote Comp(T ) result replacing definitionscompletion. following result states completion weaker .Theorem 36 (Denecker & Ternovska, 2008). |= Comp() |= Comp(T ) every definitionFO(ID) theory .SAT(ID) problem problem deciding whether given propositional FO(ID) theorysatisfiable. Currently exist three SAT(ID) solvers. IDsat (Pelov & Ternovska, 2005) workstranslating SAT(ID) problem equivalent SAT problem calls SAT solver.MidL (Marien, Wittocx, & Denecker, 2007) MiniSAT(ID) (Marien, Wittocx, Denecker, &Bruynooghe, 2008) take native approach. Marien (2009) provides details specific formpropositional FO(ID) theories accepted solvers, method transform arbitrarypropositional FO(ID) theories form.5.3 Grounding Inductive DefinitionsLike MX(FO) problems, MX(FO(ID)) problems reduced SAT(ID) problems grounding.section extend grounding refinement algorithm Section 4 FO(ID). Withoutloss generality (Marien, Gilis, & Denecker, 2004), assume none predicatesinput vocabulary defined definition , predicate defined onedefinition. Moreover, assume every rule body TNF.247fiWittocx, Marien, & Denecker5.3.1 Full Reduced GroundingLet FO(ID) theory. FO, grounding Tg respect propositionalFO(ID) theory -equivalent . extend notion full reduced groundingdefinitions.Definition 37. full grounding rule x P (x) respect set {P (d)Grfull ([x/d]) | Dn }, n number variables x. Similarly, reduced groundingx (P (x) ) set {P (d) Grred ([x/d]) | Dn }. full (reduced) groundingdefinition union full (reduced) groundings rules .full (reduced) grounding FO(ID) theory set full (reduced) groundingssentences definitions .5.3.2 Definitions Dependingsay definition depends expansion symbols Open() 6 . dependexpansion symbols, interpretation every predicate Def() every modelexpanding . Indeed, definition |=I , |Open() completelydetermined . Therefore also wfm (M ) depends .deductive database literature describes several algorithms compute wfm (M ) definition depend expansion symbols. defined definitionsevery rule body conjunction atoms. them, Rete algorithm(Forgy, 1982) semi-naive evaluation technique (Ullman, 1988), easily adaptedhandle full FO bodies.Assume definition depend expansion symbols. Let vocabularyhP Def(), F -structure | = |= . clearly, |=Iiff |=I structure . However, grounding \ respect obtainedefficiently, since Grred (T \ , ) necessarily smaller Grred (T, ). Indeed, \subtheory , Grred (T \ , ) contain symbols Def(), Grred (T, ) does.Observe also set c-maps superset set c-maps ,since bounds assigned former c-maps formulas , instead . such,c-maps computed refinement algorithm might yield efficient groundingcompared c-maps computed .5.3.3 Bounds Definitionsextend refinement algorithm FO(ID).Definition 38. formula subformula FO(ID) theory subformula sentencesubformula rule body definition . c-map assignmentct- cf-bound every subformula .Note c-map assign bounds heads rules definition.strategy compute c-map FO(ID) theory simple: construct completionapply refinement algorithm Comp(T ) obtain c-map C Comp(T ). restrictionC subformulas c-map . Indeed, every subformula occurs Comp(T )since |= Comp(T ), Comp(T ) |= x (C ct () ) Comp(T ) |= x (C cf () ), also|= x (C ct () ) |= x (C cf () ).order use c-map grounding, lift definition c-transformation FO(ID)theories.Definition 39. Let C c-map theory definition . c-transformationrule x (P (t) ) given x (P (t) Chi). c-transformation Chi248fiGrounding FO FO(ID) Boundsdefinition set c-transformations rules . c-transformation setc-transformations formulas definitions .also lift notion C-equivalence definitions.Definition 40. Two definitions 1 2 C-equivalent every structure satisfies C,|= 1 iff |= 2 .However, Lemma 15 hold FO(ID) theories: definition , Chi necessarilyC-equivalent .Example 14. Let empty vocabulary theoryP{P P }.theory unsatisfiable definition {P P } one model, P false.contradicts sentence . Clearly, > ct-bound P . C c-mapassigning (>, ) P , Ch{P P }i = {P (P ) >}, equivalent {P >}.definition model assigns true P . Since model also satisfies C, conclude{P P } Ch{P P }i C-equivalent.Definition 41. Let definition . call c-map C -tolerant ChiC-equivalent. call C -tolerant -tolerant every definition .following, say formula occurs positively (negatively) definition occurspositively (negatively) body rule .Proposition 42. Let definition theory . c-map C -tolerantevery subformula contains predicate P Def(), following hold:1. total, C ct () = C cf () = .2. occurs positively P occurs positively , C ct () = .3. occurs negatively P occurs negatively , C cf () = .Note c-map Example 14 violates second condition. prove Proposition 42inductively constructing structure satisfies C, sequence three-valued structureswell-founded induction Chi. |= , show terminalsequence property constructed, proving also satisfies Chi. 6|= ,sequence property constructed last element less precise I.shows satisfy Chi either. construct well-founded inductionChi, prove step extends well-founded induction also valid stepextend Chi. Step (3a) Definition 34 covered Lemma 43, step (3b) Lemma 44.Lemma 43. Let structure satisfies c-map C let J p three two-valued. J()valued interpretation J|p J(Chi)every subformulaT.Proof. prove lemma induction. First assume [x] atom. Chi formulact ()) must( C cf ()) C ct (). J()= u, clearly J(Chi)p J().J()= f, J(Ccf ()) = ffalse, since |= C. Therefore J(Chi)= f. hand, J()= t, J(Chence, J(Chi)= t.inductive cases similar base case. prove one them. Assumeformula . Chi formula ((Chi Chi) C cf ()) C ct (). J()= f,ct ()) = f, concludeJ()= J()= f, induction J(Chi)= J(Chi)= f. Since also J(Ccf ()) = f. Also J()J(Chi)= f. hand J()= t, J(C= J()= t,therefore J(Chi)= J(Chi)= t. Hence J(Chi)= t.249fiWittocx, Marien, & DeneckerLemma 44. Let definition C c-map satisfies three conditionsProposition 42. Let structure satisfies C J p three-valued interpretationtwo-valued. U set domain atoms defined unknown J,everyJ|subformula J[U/f]() 6= u, following hold:J[U/f]()J[U/f](Chi)occurs negatively ;J[U/f]()J[U/f](Chi)occurs positively ;Proof. Denote H := J[U/f].J()6= u, result follows immediately Lemma 43.=uprove case J()= u induction. Assume atom P (x). Since J()JcfH() 6= u, know P (x ) U H() = f. Therefore H(Chi) = H(( C ())C ct ()) = H(C ct ()). occurs negatively , prove H() H(Chi).Since H() = f, inequality holds regardless value C ct () C cf () H.hand, occurs positively, prove H() H(Chi). Since H() = fH(Chi) = H(C ct ()), inequality hold H(C ct ()) = f. conditions Censure C ct () = , conclude indeed H(C ct ()) = f.omit inductive cases, since similar base case.Proof Proposition 42. Let structure satisfies C. prove |= iff|= Chi. total, proof trivial, since Chi equivalent.assume total let hJ i0 well-founded induction ChiI. prove J two-valued, J <p I, exists J+1hJ i0+1 well-founded induction Chi. Also observe limitordinal hJ i0< well-founded induction Chi, holdshJ i0 .sufficient conclude proof. Indeed, |= , keep extending sequenceend I, derive |= Chi. 6|= , eventually extendwell-founded induction structure J+1 6p I. then, well-founded model Chialso precise J+1 , shows 6|= Chi.Assume J two-valued J <p I. total, exists J+1hJ i0+1 well-founded induction . prove also well-foundedinduction Chi. two possibilities:J+1 = J [P (d)/t] domain atom P (d) rule x (P (x) )J [x/d]() = t. Lemma 43, also J [x/d](Chi) = t. Hence, hJ i0+1well-founded induction Chi.J+1 = J [U/f] every P (d) U rule x (P (x) ) , J+1 [x/d]() = f.Lemma 44, conclude also J+1 [x/d](Chi) = f. Therefore, hJ i0+1 wellfounded induction Chi.Proposition 42 derive following procedure compute -tolerant c-maptheory . First compute c-map C necessarily -tolerant. Then, everydefinition every subformula , replace C ct () C cf () , requiredsatisfy conditions Proposition 42.conclude following algorithm produces correct grounding FO(ID) theory :1. Compute c-map C .2. C inconsistent respect , output stop.3. Else, derive atom-based, T-tolerant c-map C 0 C.4. Output Grred (C 0 hT C 0 ), using off-the-shelf grounder FO(ID).250fiGrounding FO FO(ID) Bounds6. Implementation Experimentsfar focussed mostly grounding size. Proposition 23 guaranteed groundingbounds produces smaller groundings. section concerned efficiencypractical implementation grounding bounds. first issue mentioned endSection 4.4.2: atom-based c-map C computed refinement algorithm contains many repeatedconstraints variables. ground ChT efficiently, repetitions avoided muchpossible. Secondly, efficient grounder consults bounds soon possible. particular,use bounds avoid unnecessary instantiations variables, rather removeinstantiations afterwards. case study, show detail adapt basic top-downstyle grounding algorithm efficiently exploit bounds. sketch principlesapplied bottom-up style grounder.second part section discuss aspects implementing refinement algorithm. mentioned Section 4.4.1, several issues concerning practical implementation algorithm. particular, method simplify bounds needed, well goodstop criterion. show issues addressed representing bounds first-orderbinary decision diagrams.Finally, report implementation, called GidL, refinement grounding algorithm. present experimental results show impact using bounds grounding sizetime.6.1 Case Study: Top-Down Grounding Boundsrest section, assume TNF fix -consistent, atom-based c-map C. call formula form x disjunctive formula. Vice versa, conjunctiveformula formula form x .present simple top-down style grounding algorithm exploits bounds withoutconstructing ChT C explicitly. algorithm shown Algorithm 1. Basically, consultsbounds assigned C whenever substitutes free variables formula [x] domainconstants d. according bounds, [x/d] certainly true, i.e., [x/d] |= C ct (),grounding [x/d] computed. Instead, algorithm proceeds [x/d] equal>. Similarly [x/d] certainly false. way, algorithm avoids creating unnecessaryinstantiations. One check C trivial c-map, Algorithm 1 reduces straightforwardtop-down style grounding algorithm produces Grfull (T ).Line 1 Algorithm 1 checks whether one sentences certainly false.case, clearly unsatisfiable (cf. Definition 10), reported immediately.sentence grounded, line 4 checks whether sentence certainly true according C.sentences certainly true grounded. Observe checks simple syntacticchecks executed constant time.Function groundConj gets input formula [x] returns grounding x [x].particular, sentence, result applying groundConj grounding .groundConj, universal quantifiers implicitly pushed inside conjunctions. is, [x]conjunction 1 . . . n , every [1, n], grounding x computedapplying groundConj . conjunction groundings returned grounding x .According equivalence (6) Section 2.2, transformation yields equivalent formula.Function groundConj consults c-map variables substituted domain constants input formula atom. such, groundConj ignores (eliminates) boundsassigned conjunctive formulas. mentioned end Section 4.4.2, importantavoid repeated constraints variable.groundConj([x]), substitutions [x/d] [x/d] 6|= C ct () grounded(see, e.g., line 12). Indeed, substitutions yield formula certainly true modelsexpanding , therefore omitted ground conjunction C computed.251fiWittocx, Marien, & DeneckerAlgorithm 1: Ground BoundsInput: , , COutput: grounding Tg respect123456789101112C cf () = > sentence return ;Tg := ;// Ground sentencesevery sentenceC ct () 6= > Add groundConj() Tg ;// Ground definitionsevery definitionAdd groundDef() Tg ;// Add grounding Cevery atomic subformula [x]every [x/d] |= C ct ()Add [x/d] Tg ;every [x/d] |= C cf ()Add [x/d] Tg ;return Tg ;Function groundConj([x])123456789101112131415C := ;switch [x]case literal6|= C ct ()[x/d]|= C cf ()[x/d] return ;else Add [x/d] C;case = [x, y]return groundConj([x, y]);Vcase =SC := groundConj(i );case disjunctive formula6|= C ct ()[x/d]|= C cf ()[x/d] return ;else Add groundDisj([x/d]) C;returnVC;252fiGrounding FO FO(ID) BoundsFunction groundDisj([x])123456789101112131415:= ;switch [x]case literal6|= C cf ()[x/d]|= C ct ()[x/d] return >;else Add [x/d] D;case = [x, y]return groundDisj([x, y]);Wcase =S:= groundDisj(i );case conjunctive formula6|= C cf ()[x/d]|= C ct ()[x/d] return >;else Add groundConj([x/d]) D;returnWD;Function groundDef()8g := ;every rule x (P (x) [y])z := x \ y;every 6|= C cf ([y/d])|= C ct ([y/d]) g := >;else g := groundConj([y/d]);n := number variables z;00Add P (x)[y/d, z/d ] g g every Dn ;9return g ;1234567253fiWittocx, Marien, & Denecker[x/d] grounded, checked whether substitution yields formula certainlyfalse (see, e.g., line 13). case, whole conjunction C certainly false,therefore returned immediately. Observe implicitly formula C ct () (C cf () )grounded. Hence correctness groundConj follows Lemma 13.Function groundDisj dual groundConj. input [x], returns grounding x [x].implicitly pushes existential quantifiers disjunctions eliminates bounds assigneddisjunctive formulas.Function groundDef returns grounding input definition . grounds rulesone-by-one. rule x (P (x) [y]), substitutions [y/d] possibly truetried (line 4). [y/d] certainly true, replaced > (line 5).lines 7-11 Algorithm 1, theory C grounded. Recall necessary obtaingrounding -equivalent (see Proposition 21). Observe C trivial c-map,output produced lines 7-11 executed.computationally expensive steps Algorithm 1 steps truth values(some the) bounds assigned C computed. large bounds, steps becomeinfeasible. Indeed, expression complexity FO PSPACE-complete (Stockmeyer, 1974).such, grounding complex bounds may take time space constructingfull grounding simplifying afterwards. stop criterion Section 6.2.3 refinementalgorithm designed avoid complex bounds. experiments Section 6.3 showcarefully restricting complexity bounds leads faster grounding.stress Algorithm 1 one example grounding algorithm exploits bounds.4principle consulting bounds soon possible applied adapt groundingalgorithms well. example, recall bottom-up style grounder starts storing instancesatomic subformulas table. exploit bounds efficiently, bottom-up grounderconsult bounds constructing tables leave out, e.g., instances certainlyfalse. such, avoids unnecessary large tables, turn improves speed subsequentgrounding steps.6.2 Implementing Refinement Algorithm Querying Boundssection discuss aspects implementing refinement algorithm. mentionedabove, applying simplification method first-order formulas simplify bounds regulartime points essential good implementation. One use Goubaults (1995) methodpurpose. end, bounds need represented first-order binary decision diagrams.show section representation applied without much overheadapplying one-step refinements. Moreover, using binary decision diagrams leads extra benefits:obtain cheap equivalence check bounds elegant algorithm query bounds,needed implement Algorithm 1. end section discuss stop criterionrefinement algorithm discuss implementation.6.2.1 First-Order Binary Decision Trees Diagramsborrow definition first-order BDDs Goubault (1995). Let , 1 2 threeformulas. ternary if-then-else operator denoted _, defined _ 1 ; 2 :=( 1 ) ( 2 ). formula _ 1 ; 2 also represented graph shown Figure 3.Definition 45 (Goubault, 1995). FO binary decision trees (BDTs) kernels definedsimultaneous induction:atom kernel;4. question whether top-down grounders made efficient bottom-up grounders outsidescope paper, still undecided.254fiGrounding FO FO(ID) BoundsyEEEEEEEE"|y21Figure 3: Graph representation formula _ 1 ; 2BDT x variable, x kernel;> BDTs;kernel 1 2 BDTs, _ 1 ; 2 BDT.Observe graph representation BDT tree whose nodes atoms existentiallyquantified BDTs.Goubault (1995) showed every FO formula exists BDT 0 0equivalent. actual implementation, sharing, reducing ordering applied obtainsimplified compact representation BDTs. representations called reduced orderedbinary decision diagrams (BDDs). Sharing means isomorphic subtrees storedaddress memory. Reducing involves exhaustively replacing subtrees form _ ; .BDT ordered kernels appear fixed order every path graph representation.mentioned above, several important benefits using BDDs represent boundsformula:implementation refinement algorithm using BDDs allows us use simplificationalgorithm BDDs Goubault (1995).explained Section 4.4, detect refinement algorithm reached fixpoint,one needs check equivalence bounds. Often, BDDs representing two equivalentformulas equal.5 Hence, cheap (but necessarily incomplete) equivalence check twobounds consists checking syntactic equality two BDDs representing them. Sinceequal BDDs stored address, check done constant time.show Section 6.2.2, querying bound [x], i.e., finding tuples[x/d] |= , easily implemented directly BDD representation . Queryingbound one main operations performed grounding algorithm exploits boundsdirectly (such Algorithm 1).hand, using BDDs result much overhead computing c-map., [x, y] represented BDDs, BDD representing , x , x , ,[x/x0 , y] computed efficiently (Bryant, 1986; Goubault, 1995). implies everyone-step refinement c-map C implemented efficiently, even bounds assigned CBDDs.6.2.2 Querying BoundAlgorithm 1, main operation performed bound [x] querying: finding tuplesdomain constants |= [x/d]. Finding tuple 6|= [x/d] correspondsquerying . show querying bound [x] done directly BDDrepresentation simple backtracking algorithm.5. propositional BDDs, always case.255fiWittocx, Marien, & DeneckerP (x)yEEEEEEEE"|yQ(x,y)R(x)RRRlRlRRllRRl l RRRRR)ul>Figure 4: BDD representing formula (P (x) Q(x, y)) (P (x) R(x))idea traverse BDD, starting root, trying end leaf >.inner node [y] _ 1 ; 2 , free variables node replaced domain constants dy .|= [y/dy ], algorithm continues via 1 , otherwise via 2 . ends , backtracks.hand, ends >, performed substitutions constitute answer .Function query implements sketched query algorithm. gets bound [x] inputreturns substitution [x/d] |= [x/d]. substitution exists, returns FAIL.algorithm easily adapted return answers [x] instead one.Function query([x])123456789= > return empty substitution;else = [y] _ 1 ;every tuple |= [y/d]:= query(1 [y/d]);6= FAIL return [y/d]else = [y] _ ; 2every tuple 6|= [y/d]:= query(2 [y/d]);6= FAIL return [y/d]14else form [y] _ 1 ; 2every tuple D|y||= [y/d] := query(1 [y/d]);else := query(2 [y/d]);6= FAIL return [y/d]15return FAIL;10111213lines 3 7, algorithm needs find tuples respectively |= [y/d]6|= [y/d]. [y] atom P (y), implemented consulting table P .kernel x [x, y], function query applied recursively find tuples. Indeed, answer(d0 , d) [x, y] provides tuple |= [y/d]. Vice versa, 6|= [y/d] [x, y/d]answer.illustrate query algorithm example.Example 15. Let [x, y] BDD shown figure 4, let {a, b} domain ,P = {b}, RI = {} QI = {(b, b)}. find answer [x, y], query algorithm startsroot P (x). Since none children equal , every domain constant tried. Assumedomain constant tried first. 6 P , algorithm continues node R(a) _ >; .else child node 6 RI , algorithm returns root tries256fiGrounding FO FO(ID) Boundsdomain element b. Since b P , goes node Q(b, y) _ >; . Since else child node, algorithm tries substitutions (b, y/d) QI . Thus, substitutedb. Finally, answer [x/b, y/b] returned.6.2.3 Stop Criterion Refinement Algorithmshown Section 4.4, c-map refinement algorithm reach fixpoint certain inputs.Also, even case fixpoint found, computing may take long time, boundsassigned fixpoint complex querying becomes inefficient. Usingbounds may severely slow grounding. indicates need good stop criterion.Simple Stop Criteria simple stop criterion limits number one-step refinementsmay performed given maximum number m. may depend theory .instance, set C (number subformulas ), C fixed constant.slightly less naive technique, combined previous, limits complexitybounds putting fixed upper bound N number nodes BDD representationbound may have. one-step refinement would lead new bound nodes N ,refinement performed. limits number applicable one-step refinements,probability reaching fixpoint increases.Stop Criteria via Estimators experiments present Section 6.3 indicateexist appropriate values C N produce positive results examples. Still,problems, grounding slows severely, size produced groundingdecrease. One problems following clique problem (entry 6 Table 4).Example 16. Recall clique maximally connected graph. Let= h{Edge/2}, i,= hP {Clique/1},theoryxy (Clique(x) Clique(y) (x = Edge(x, y))).x ((y (Clique(y) x 6= Edge(x, y))) Clique(x)).EdgeI symmetric, i.e., represents undirected graph, model expanding cliquecontained strictly larger clique . Within small number iterations,refinement algorithm finds Clique(x) ct-bound x0 x 6= x0 Edge(x, x0 ). formulaexpresses Clique(x) certainly true every solution x directly connected everyvertex input graph. Clearly, graphs, vertex satisfies condition. So,graphs, would equally precise ct-bound, would allow much faster querying.situation worse cf-bound Clique(x). Since undirected graph, everysingle vertex clique, thus occurs least one solutions, cf-bound necessarilyunsatisfiable respect . Yet, implementation refinement algorithm camex0 (Edge(x, x0 ) x 6= x0 (x00 (x0 6= x00 Edge(x0 , x00 )))) cf-bound. query algorithmoutlined takes cubic time number vertices find x satisfies formula.avoid problems illustrated example above, one could estimate rewardbound versus cost evaluating it. Recall precise bounds yield smaller groundingsizes. Therefore, reward bound dictated precision. Given , possiblefind good estimate number answers (Demolombe, 1980), turnmeasure precision . fixed query algorithm, one also estimate cost cost()computing answer query . following, assume reward boundpositive real number, cost strictly positive real number.257fiWittocx, Marien, & DeneckerGiven reward cost bounds, complexity bound limitedrestricting ratiocost()r() :=.reward() + 1one-step refinement would replace bound 1 2 , r(1 ) < r(2 ), refinementperformed. Clearly, bounds assigned c-map C computed accordingrestriction, r() r() holds. Observe apply restriction, input structureneeded. However, obtained bounds independent .beyond scope paper describe detail estimators reward costbounds. fairly naive estimator used experiments next section assigns ratiosorder O(|DI |), respectively O(|DI |3 ), ct-bound, respectively cf-bound, mentionedExample 16. such, |DI | large enough, bounds avoided.6.2.4 Implementation Refinement Algorithmimplementation refinement algorithm, including heuristic choosing refinementbounds (Section 4.4.1) stop criterion, presented Algorithm 6. algorithm maintainsqueue Q one-step refinements applied. represented tuple hr, i,r type refinement, e.g., axiom refinement, formula rapplied.Algorithm 6: Refinement Algorithm12345678910111213Q := ; C := trivial c-map ;sentences Q.push(haxiom, i);subformulasQ.push(hct-input, i); Q.push(hcf-input, i);Q 6= maximum number refinements reachedhr, := Q.pop();r ct-refinement:= r-refinement bound respect C;:= simplify(C ct () );6= C ct () complexC ct () := ;hr, r-refinement bound contains C ct ()Q.push(hr, i);15else...16return C;14// Similar code cf-refinementsexplained Section 4.4.1, implementation starts scheduling possible axiom-input-refinements. later stage bound changed (line 11), refinement boundscontain bound scheduled applied (line 13). example, assume containsformula ct-bound refined. bottom-up ct-refinementscheduled since bottom-up ct-refinement bound formula given C ct () C ct (),contains C ct (). reason also top-down cf-refinement scheduled.algorithm applies scheduled refinements, unless maximum number refinement stepsreached (line 5). part discussed stop criterion applied line 10. newly258fiGrounding FO FO(ID) Boundscomputed bound complex, i.e., BDD representation contains many nodes ratior() certain threshold, used.BDDs used represent bounds assigned C, line 8 implemented linear timesize C. use Goubaults simplification algorithm BDDs implementing line 9,worst case complexity step non-elementary size C ct () (Goubault, 1995).estimators used implement line 10 take linear time size . may seemcomplexity simplification method limits practical applicability Algorithm 6. However,since large BDDs usually pass test line 10, simplification method rarely appliedlarge BDDs. experiments next section, running time refinement algorithmnegligible compared running time grounding algorithm.6.3 Experimentsimplemented Algorithm 1 Algorithm 6, using BDDs represent bounds. resultinggrounder called GidL. section, present experiments, obtained GidL, showimpact using bounds grounding size time.input GidL, used 37 benchmark problems, mainly taken Asparagus.6 detailsexperiments available http://dtai.cs.kuleuven.be/krr/software.html.used four different versions GidL:GidLnb : Assigns h, bound every atomic subformula input vocabulary,h, every subformula. such, creates reduced grounding inputtheory.GidLbu : Assigns h, bound every atomic subformula input vocabularyapplies bottom-up refinements obtain bottom-up c-map.GidLmn : Limits refinement algorithm 4 (number subformulas ) one-step refinementsallows maximum 4 internal nodes BDD used represent bounds. According previous experiments (Wittocx et al., 2008b), best setting limitingnumber nodes.GidLr : Limits refinement algorithm 4 (number subformulas ) one-step refinements.limits complexity derived bounds estimating number answerscost, described previous section.Table 3, influence bounds grounding size shown. second third columnshow ratio grounding size obtained GidLmn GidLr compared Grred (T ).GidLnb GidLbu , ratio always equal 1. interpreting Table 3, importantnote small reductions grounding size important. reason reductionsobtained refinement algorithm also obtained applying unit propagationgrounding (see Section 7 discussion). Since exist efficient implementationsunit propagation, beneficial let refinement algorithm find small reductionsrelatively high cost. see GidLmn GidLr reduce grounding size50% around 30% benchmarks. 7, respectively 6, benchmarks spectacularreduction 95%.important reductions size reductions grounding time. Table 4 showsrunning times different versions GidL, (between brackets) ratio runningtime running time GidLnb . running time refinement algorithm included (itnever took 0.02 seconds). time-out (###) 600 seconds used.many benchmarks, reduction grounding time respect GidLnb duereduction grounding size. Yet also several benchmarks time decreases lot,6. http://asp.haiti.cs.uni-potsdam.de/259fiWittocx, Marien, & Deneckeralmost reduction size. mostly due creation bottom-up c-map,seen running times GidLbu . Applying bottom-up refinements leads assignmentnon-trivial bounds non-atomic subformulas. allows earlier pruning top-down stylegrounder, hence faster grounding.Table 4, see GidLmn performs quite well. half benchmarks,44% faster GidLnb . also 20% faster GidLbu halfbenchmarks. outliers however. benchmarks 6 11, far slower GidLbu ,producing significantly smaller grounding. indicates use complex boundrelatively small reward. Compared GidLmn , GidLr faster robust, indicatingusing estimators reward cost bounds pays cases. twobenchmarks, naive estimator makes wrong guess. benchmark 1, bound high costreward allowed, benchmark 7, bound low cost high reward allowedGidLr . part future work implement improved estimators.conclude experiments grounding bounds applicable practice. oftenleads smaller grounding sizes standard benchmark problems, bounds carefullyrestricted, yields significant speed up. Since time compute bounds small comparedoverall grounding time, computing essentially free.general, smaller grounding necessarily lead faster propositional model generation.example, grounding size (and time) increases symmetry breaking formulas added,formulas may drastically improve overall solving time (Torlak & Jackson, 2007). Anotherexample clause-learning SAT solvers: clauses learnt solvers redundant,may improve solving time orders magnitude. question arises whether methodgrounding bounds may lead slower overall model generation time compared groundingwithout bounds. case. experiments show general, groundingbounds faster grounding without bounds. Since grounding bounds also produces smallergroundings, subsequent initialization phase SAT solver executed faster. T1 T2two groundings obtained grounding input theory structure with, respectivelywithout bounds, shown7 typical simplification steps applied initializationphase transform T1 T2 exactly simplified theory T3 . Thus, initialization,SAT solver applied exactly theory, whether grounder used bounds.follows general, overall model generation time increase bounds appliedgrounding.7. Related Workprevious sections described method obtain fast compact grounding. Severalmethods described literature. like preprocessingtechniques rewrite input theory. techniques involve reasoning propositionallevel. section provide overview. indicate ones applied improveGidL. also give overview existing grounders.7.1 Methods Optimize GroundingDerivation Bounds knowledge, methods proposed literature derive boundsless general one presented paper. illustrated Table 5, showseveral grounders impact manually adding redundant information. grounderstable except GidL, manually adding redundancy may serious impact.grounders, need add redundancy sometimes avoided writing input theoryspecific format. example, grounder gringo (Gebser et al., 2007) uses syntactic checkderive bounds: derives predicate q input vocabulary bound predicate p p7. exact formulation proof property beyond scope paper.260fiGrounding FO FO(ID) BoundsNr12345678910111213141516171819202122232425262728293031323334353637Benchmark name15puzzleBattleshipBlocked N-queensBlocksworldBounded spanningtreeCliqueHierarchical clusteringGraph colouringDebuggingFastfoodFO-hamcircuitGolomb rulerGraph partitioningAlgebraic groupsHamiltonian circuitTower HanoiKnighttourLabyrinthMagic seriesMaze generationMirror puzzleMissionariesN-queensPigeonholeDisjunctive schedulingSlitherlinkSocial golferSokobanSolitaireSpanningtreeSudokuTarskiToughnutTrain schedulingWaterbucketWeight bounded dominating setWire routingAverage# < 1.00# < 0.50# < 0.05GidLmn1.000.890.020.330.121.000.031.000.861.000.940.540.940.990.011.000.000.991.000.901.000.031.001.000.830.041.000.591.000.060.751.000.000.250.361.000.920.6624127GidLr1.001.000.020.330.121.000.721.001.001.000.991.001.001.000.011.000.000.991.000.901.000.031.001.000.830.041.000.590.730.060.751.000.000.250.361.000.990.7020116Table 3: Impact bounds grounding size261fiWittocx, Marien, & DeneckerNr12345678910111213141516171819202122232425262728293031323334353637TotalAvg. gainMedian gainGidLnb6.130.199.6622.338.523.130.322.570.30######14.050.039.6870.752.3212.228.801.832.770.1217.44.624.92151.150.255.472.780.436.86###4.424.234.063.161.450.062186.98GidLbu2.00 (0.33)0.18 (0.95)10.83 (1.12)16.76 (0.75)8.52 (1.00)3.73 (1.19)0.34 (1.06)2.71 (1.05)0.30 (1.00)### (1.00)5.87 (0.01)3.54 (0.25)0.04 (1.33)9.58 (0.99)71.50 (1.01)1.83 (0.79)10.35 (0.85)8.83 (1.00)1.76 (0.96)2.80 (1.01)0.11 (0.92)18.08 (1.04)4.60 (1.00)5.01 (1.02)151.66 (1.00)0.13 (0.52)5.47 (1.00)2.66 (0.96)0.43 (1.00)6.79 (0.99)2.34 (0.00)4.53 (1.02)4.23 (1.00)2.14 (0.53)3.07 (0.97)1.42 (0.98)0.06 (1.00)974.20 (0.45)12 %0%GidLmn2.07(0.34)0.16(0.84)2.22(0.23)5.80(0.26)3.01(0.35)51.77 (16.54)0.05(0.16)2.69(1.05)0.48(1.60)17.59(0.03)37.86(0.06)4.13(0.29)0.03(1.00)11.20(1.16)2.56(0.04)1.96(0.84)0.06(0.00)8.83(1.00)1.79(0.98)0.51(0.18)0.12(1.00)2.29(0.13)4.62(1.00)4.90(1.00)172.50(1.14)0.02(0.08)5.37(0.98)1.57(0.56)0.46(1.07)0.59(0.09)1.07(0.00)3.67(0.83)0.53(0.13)0.65(0.16)1.76(0.56)0.03(0.02)0.08(1.33)355.00(0.16)0%44 %GidLr5.73 (0.93)0.17 (0.89)2.67 (0.28)5.80 (0.26)1.16 (0.14)3.73 (1.19)0.31 (0.97)2.72 (1.06)0.47 (1.57)16.52 (0.03)6.06 (0.01)3.40 (0.24)0.02 (0.67)9.60 (0.99)1.81 (0.03)1.83 (0.79)0.10 (0.01)8.73 (0.99)1.81 (0.99)0.17 (0.06)0.10 (0.83)2.68 (0.15)4.64 (1.00)4.90 (1.00)171.54 (1.13)0.02 (0.08)5.41 (0.99)1.54 (0.55)0.49 (1.14)0.57 (0.08)1.06 (0.00)3.64 (0.82)0.53 (0.13)0.47 (0.12)2.04 (0.65)0.03 (0.02)0.08 (1.33)272.55 (0.12)40%33%(For GidLmn GidLr , time compute bounds included.)Table 4: Impact bounds grounding time262fiGrounding FO FO(ID) Boundsgringodlvlparsepsgrndgidlconstr76.33339.3763.2544.790.26redun1.594.230.780.720.42defin0.602.8163.58n/an/aTable 5: Grounding times (in seconds) Hamiltonian circuit problem input graph200 nodes 1800 edges. Encoding constr uses constraint state edgecycle edge graph. Encoding redun adds redundancy includebound rules constraints. Encoding defin contains redundancy, limitspossible edges cycle edges graph defining search spacecycle.defined choice rule form, e.g., {p(X)} :- q(X). However, rule replaced{p(X)} :- dom(X), dom denotes domain, constraint :- p(X),not q(X),dom(X)added, q still bound p, detected gringo, seen Table 5.grounder dlv system (Perri et al., 2007) may derive bounds reasoningpropositional level. explain below, order rules constraints groundedcrucial importance method pay off. Since dlv grounds rules constraints, usingconstraint state q bound p improve grounding time.Propagation Propositional Level One techniques produce smaller groundingsconsists applying constraint propagation method ground theory Tg replacing>, respectively , every ground literal derived true, respectively false. resultingtheory simplified. technique applied grounder psgrnd (East et al., 2006),uses unit propagation (Davis & Putnam, 1960) complete one-atom lookahead (Li & Anbulagan,1997) propagation methods. latter performed grounding finished, formertriggered time unit clause added grounding. inconsistency detectedunit propagation, grounding process terminated immediately. Observe techniqueyields small groundings improve grounding speed, except (rare) casepropagation method detects inconsistency grounding. Indeed, avoid computingground instances formulas input theory.propositional constraint propagation method applied grounding constructed, derived information could used refine bounds. instance, unit-propagationderives domain atom P (d1 , . . . , dn ) true, x1 = d1 . . . xn = dn ct-boundP (x1 , . . . , xn ). bounds could used speed construction rest grounding.method effective, however, careful fine-tuning order sentencesgrounded required. may even necessary alternatingly compute partial groundingsdifferent sentences. best knowledge, process worked implemented unit-propagation one-atom lookahead underlying propagation method.hand, ASP grounders apply following limited propagation method: rulesdefining predicate P grounded, concluded domain atom P (d) certainly trueoccurs ground rule form P (d) >, certainly false occurhead ground rule. case, good grounding order derived dependencygraph input theory (e.g., Cadoli & Schaerf, 2005; Perri et al., 2007). GidL, strategyimplemented grounding definitions.Sharing second technique called sharing consists detecting subformulas groundtheory Tg occur once. subformula detected, occurrences Tgreplaced new atom P , sentence P added. large formula occurs263fiWittocx, Marien, & Deneckeroften Tg , may result significant grounding size reduction. Also, sharing improvespropagation SAT solvers.Shlyakhter, Sridharan, Seater, Jackson (2003) present algorithm detect identical subformulas first-order level, Torlak Jackson (2007) propositional level. GidL,implemented simple sharing technique using dynamicV programming. adapted functiongroundConj soVthat instead returning conjunction C, creates new atom P , addssentence P C grounding, returns P . groundConj appliedmultiple timesVinput , predicate P returned time, P C added once.Function groundDisj adapted similar fashion.Clause splitting Clause splitting well-known rewriting technique applied MACE stylemodel generation (McCune, 2003). consists splitting first-order clausexyz (1 [x, z 1 ] 2 [y, z 2 ])(20)x 6 z 2 , 6 z 1 z = z 1 z 2 two new clausesxz 1 (1 [x, z 1 ] S(z 1 z 2 ))(21)yz 2 (S(z 1 z 2 ) 2 [y, z 2 ]).(22)Here, new predicate symbol. full grounding (20) size O(|D|3 ), fullgrounding (21) (22) size O(|D|2 ).sharing implemented adapting functions groundConj groundDisj explainedabove, effect clause splitting obtained moving quantifiers according equivalences (4), (5), (8) (9) Section 2.2. instance, apply equivalences (4) (8)replace (20) xz (1 (y 2 )). Grounding latter applying sharing effectclause splitting. Similarly, grounding size xyz (1 [x, z 1 ] 2 [y, z 2 ]) reducedreplacing formula xz (1 (y 2 )).simple heuristic guide clause splitting described Claessen Sorensson (2003)directly applied choose quantifiers move inside. conclude clause splittingcould easily incorporated GidL.Database Techniques Several techniques optimizing querying databases usedoptimize grounding. Examples join-ordering strategies, backjumping indexing techniques.One basic techniques improve grounding speed consists reordering (long) conjunctions disjunctions literals speed grounding. order best dependsgrounding algorithm. Different strategies described by, e.g, Leone, Perri, Scarcello (2001),Syrjanen (1998, 2009) database literature (Garcia-Molina, Ullman, & Widom, 2000).problem implementing similar technique GidL. Also, reordering nodesBDD representation bounds could optimize querying. part future work investigatereordering strategies BDDs.One important methods dlv grounder use backjumping technique (Perriet al., 2007) efficiently find instances conjunction 1 . . . n possibly true,given (an overestimation of) possibly true instances conjuncts . GidL,backjumping technique applied implement line 12 function groundDisj. Indeed,formula 1 . . . n , line 12 amounts finding possible instances ,cf-bounds 1 , . . . , n provide overestimation possibly true instances conjuncts.Similarly, backjumping technique applied improve line 12 groundConj, possiblyfalse instances disjunction calculated.Catalano, Leone, Perri (2008) present adaptation indexing strategies grounding.Partition-Based Reasoning Ramachandran Amir (2005) describe sophisticated groundingtechnique reduce grounding size FO theories, depending availability264fiGrounding FO FO(ID) Boundsgraphical structure theories. technique directly applicable case, sinceproduces groundings necessarily -equivalent input theory. guaranteeground theory satisfiable iff input problem satisfiable.7.2 Groundersnon-native approach ground MX(FO(ID)) problem consists first translatingequivalent normal logic program well-founded semantics. translation describedMarien et al. (2004). Next, (slightly adapted) grounder ASP used ground logicprogram. approach taken MXidL (Marien, Wittocx, & Denecker, 2006).first native grounding algorithm MX(FO) MX(FO(ID)) described Patterson, Liu, Ternovska, Gupta (2007). based relational algebra takes bottom-upapproach (see Section 3.2.1). construct grounding sentence , first creates possiblegroundings atomic subformulas. combines groundings using relational algebraoperations, working way syntax tree. Finally, grounding obtained. Mitchellet al. (2006) report implementation, called mxg, algorithm.kodkod (Torlak & Jackson, 2007) MX grounder syntactic variant FO. Like mxg,works bottom-up way. represents intermediate groundings (sparse) matrices. Onefeatures kodkod allows user give part solution MX problemthree-valued structure. Specifically, user force atoms P (d), Pexpansion predicate, certainly true (or certainly false). kodkod takes advantageinformation produce smaller groundings. GidL also allows three-valued structure input.applying refinement algorithm, set tuples user indicates Ptrue used initial ct-bound P instead . Similarly cf-bound.leads efficient compact groundings.mace (McCune, 2003) paradox (Claessen & Sorensson, 2003) finite model generatorsFO. work choosing domain grounding input theory SAT. resultinggrounding unsatisfiable, domain size increased process repeated. groundingalgorithm mace paradox basically constructs full grounding simplifies afterwards.Small groundings obtained first rewriting input theory using, e.g., clause splitting. Alsomethods build grounding incrementally applied systems avoid recomputingevery grounding scratch.East et al. (2006) developed grounder psgrnd X(P pb ). P pb fragment FO(ID),extended pseudo-boolean constraints. explained above, psgrnd performs reasoningground theory reduce memory usage grounding size. experiments performed Eastet al. (2006) show carefully designed data structures key importance build efficientgrounder.ASP grounders take input normal logic program transform equivalent groundnormal logic program. such, grounders deal (deeply) nested formulas. Currently, three ASP grounders: lparse (Syrjanen, 2000; Syrjanen, 2009), gringo (Gebseret al., 2007) grounding component dlv (Perri et al., 2007). use techniquesdatabase theory perform grounding efficiently.Finally, mention grounder spec2SAT (Cadoli & Schaerf, 2005). input theoriesnp-spec language, language Datalog-like syntax semantics based model minimality. grounding algorithm implemented spec2SAT basically simplified versiongrounding algorithm dlv.would interesting compare efficiency mentioned grounders experimentally. However, currently possible conduct experiment scientifically fair way.several reasons this. First, grounders different input language, makingimpossible run input. Also, several output languages grounders.richer output language leads compact fast grounding. instance, prob-265fiWittocx, Marien, & Deneckerlems, lparses output size necessarily cubic input domain size, GidLs output formatallows quadratic size. Thirdly, even input output languages grounderssame, expert could easily manipulate experiments carefully choosing modelling style.example, manually add bounds input theories, GidL advantage.bodies rules ordered, dlv likely produce good results. Etc. Finally,large amount data processed grounders, carefully designed data structures optimized implementation core grounding algorithm important achieve fast grounding(East et al., 2006). However, several mentioned grounders yet optimizedsense. such, difficult derive conclusions grounding algorithms experimentallycomparing efficiency current implementations algorithms.8. Conclusionspresented method compute given theory, upper lower bounds subformulastheory. showed bounds used efficiently creating small groundingscontext Model Expansion FO FO(ID). method frees user manuallydiscovering bounds adding theory.presented top-down style grounding algorithm incorporates bounds. discussedimplementation issues showed experiments method works practice: manybenchmark problems, leads significant reductions grounding size time.Future work includes extension algorithm compute bounds richer logics, as,e.g., extensions FO aggregates arithmetic. implementation side, plan usesophisticated estimators evaluate whether computed bound beneficial grounding.AcknowledgmentsResearch supported Research Foundation-Flanders (FWO-Vlaanderen) GOA 2003/08Inductive Knowledge Bases. Johan Wittocx research assistant Research FoundationFlanders (FWO-Vlaanderen).ReferencesBaral, C., Brewka, G., & Schlipf, J. S. (Eds.). (2007). Logic Programming NonmonotonicReasoning, 9th International Conference, LPNMR 2007, Tempe, AZ, USA, May 15-17, 2007,Proceedings, Vol. 4483 Lecture Notes Computer Science. Springer.Bryant, R. E. (1986). Graph-based algorithms boolean function manipulation. IEEE TransactionsComputers, 35, 677691.Cadoli, M., & Schaerf, A. (2005). Compiling problem specifications SAT. Artificial Intelligence,162 (1-2), 89120.Catalano, G., Leone, N., & Perri, S. (2008). demand indexing DLV instantiator.Faber, W., & Lee, J. (Eds.), Workshop Answer Set Programming ComputingParadigms (ASPOCP).Claessen, K., & Sorensson, N. (2003). New techniques improve MACE-style model finding.Workshop Model Computation (MODEL).Davis, M., & Putnam, H. (1960). computing procedure quantification theory. JournalACM, 7 (3), 201215.266fiGrounding FO FO(ID) BoundsDemolombe, R. (1980). Estimation number tuples satisfying query expressed predicatecalculus language. International Conference Large Data Bases (VLDB), pp. 5563.IEEE Computer Society.Denecker, M. (2000). Extending classical logic inductive definitions. Lloyd, J. W., Dahl, V.,Furbach, U., Kerber, M., Lau, K.-K., Palamidessi, C., Pereira, L. M., Sagiv, Y., & Stuckey,P. J. (Eds.), International Conference Computational Logic (CL), Vol. 1861 Lecture NotesComputer Science, pp. 703717. Springer.Denecker, M., & Ternovska, E. (2007). Inductive situation calculus. Artificial Intelligence, 171 (5-6),332360.Denecker, M., & Ternovska, E. (2008). logic nonmonotone inductive definitions. ACM Transactions Computational Logic (TOCL), 9 (2), Article 14.Denecker, M., & Vennekens, J. (2007). Well-founded semantics algebraic theory nonmonotone inductive definitions.. Baral et al. (Baral, Brewka, & Schlipf, 2007), pp. 8496.Denecker, M., Vennekens, J., Bond, S., Gebser, M., & Truszczynski, M. (2009). second answerset programming competition. Erdem, E., Lin, F., & Schaub, T. (Eds.), International Conference Logic Programming Nonmonotonic Reasoning (LPNMR), Vol. 5753 LectureNotes Computer Science, pp. 637654. Springer.East, D., Iakhiaev, M., Mikitiuk, A., & Truszczynski, M. (2006). Tools modeling solvingsearch problems. AI Communications, 19 (4), 301312.Enderton, H. B. (2001). Mathematical Introduction Logic (Second edition). Academic Press.Fagin, R. (1974). Generalized first-order spectra polynomial-time recognizable sets. ComplexityComputation, 7, 4374.Forgy, C. (1982). Rete: fast algorithm many patterns/many objects match problem.Artificial Intelligence, 19 (1), 1737.Garcia-Molina, H., Ullman, J. D., & Widom, J. (2000). Database System Implementation. PrenticeHall.Gebser, M., Schaub, T., & Thiele, S. (2007). GrinGo : new grounder answer set programming..Baral et al. (Baral et al., 2007), pp. 266271.Goubault, J. (1995). BDD-based simplification skolemization procedure. Logic JournalIGPL, 3 (6), 827855.Jackson, D. (2006). Software Abstractions: Logic, Language, Analysis. MIT Press, Cambridge,MA.Kautz, H. A., & Selman, B. (1996). Pushing envelope: Planning, propositional logic stochastic search. National Conference Artificial Intelligence Innovative ApplicationsArtificial Intelligence (AAAI/IAAI), pp. 11941201. AAAI Press.Krogel, M.-A., Rawles, S., Zelezny, F., Flach, P. A., Lavrac, N., & Wrobel, S. (2003). Comparativeevaluation approaches propositionalization. Horvath, T. (Ed.), International Conference Inductive Logic Programming (ILP), Vol. 2835 Lecture Notes Computer Science,pp. 197214. Springer.Leone, N., Perri, S., & Scarcello, F. (2001). Improving ASP instantiators join-ordering methods.Eiter, T., Faber, W., & Truszczynski, M. (Eds.), International Conference Logic Programming Nonmonotonic Reasoning (LPNMR), Vol. 2173 Lecture Notes ComputerScience, pp. 280294. Springer.Li, C. M., & Anbulagan (1997). Heuristics based unit propagation satisfiability problems.International Joint Conference Artificial Intelligence (IJCAI), pp. 366371. MorganKaufman.267fiWittocx, Marien, & DeneckerMarek, V. W., & Truszczynski, M. (1999). Stable models alternative logic programmingparadigm. Apt, K. R., Marek, V. W., Truszczynski, M., & Warren, D. S. (Eds.), LogicProgramming Paradigm: 25-Year Perspective, pp. 375398. Springer-Verlag.Marien, M. (2009). Model Generation ID-Logic. Ph.D. thesis, Department Computer Science,K.U.Leuven, Leuven, Belgium.Marien, M., Gilis, D., & Denecker, M. (2004). relation ID-Logic Answer SetProgramming.. Alferes, J. J., & Leite, J. A. (Eds.), European Conference LogicsArtificial Intelligence (JELIA), Vol. 3229 Lecture Notes Computer Science, pp. 108120.Springer.Marien, M., Wittocx, J., & Denecker, M. (2006). IDP framework declarative problem solving.Search Logic: Answer Set Programming SAT, pp. 1934.Marien, M., Wittocx, J., & Denecker, M. (2007). MidL: SAT(ID) solver. 4th WorkshopAnswer Set Programming: Advances Theory Implementation, pp. 303308.Marien, M., Wittocx, J., Denecker, M., & Bruynooghe, M. (2008). SAT(ID): Satisfiability propositional logic extended inductive definitions. Kleine Buning, H., & Zhao, X. (Eds.),International Conference Theory Applications Satisfiability Testing (SAT), Vol. 4996Lecture Notes Computer Science, pp. 211224. Springer.McCune, W. (2003). Mace4 reference manual guide. CoRR, cs.SC/0310055.Mitchell, D. G., & Ternovska, E. (2005). framework representing solving NP searchproblems.. Veloso, & Kambhampati (Veloso & Kambhampati, 2005), pp. 430435.Mitchell, D. G., Ternovska, E., Hach, F., & Mohebali, R. (2006). Model expansion frameworkmodelling solving search problems. Tech. rep. TR 2006-24, Simon Fraser University,Canada.Niemela, I. (1999). Logic programs stable model semantics constraint programmingparadigm. Annals Mathematics Artificial Intelligence, 25 (3-4), 241273.Patterson, M., Liu, Y., Ternovska, E., & Gupta, A. (2007). Grounding model expansionk-guarded formulas inductive definitions. Veloso, M. M. (Ed.), International JointConference Artificial Intelligence (IJCAI), pp. 161166.Pelov, N., & Ternovska, E. (2005). Reducing inductive definitions propositional satisfiability.Gabbrielli, M., & Gupta, G. (Eds.), International Conference Logic Programming (ICLP),Vol. 3668 Lecture Notes Computer Science, pp. 221234. Springer.Perri, S., Scarcello, F., Catalano, G., & Leone, N. (2007). Enhancing DLV instantiator backjumping techniques. Annals Mathematics Artificial Intelligence, 51 (2-4), 195228.Ramachandran, D., & Amir, E. (2005). Compact propositional encodings first-order theories..Veloso, & Kambhampati (Veloso & Kambhampati, 2005), pp. 340345.Schulz, S. (2002). comparison different techniques grounding near-propositional cnf formulae.Haller, S. M., & Simmons, G. (Eds.), International Florida Artificial Intelligence ResearchSociety Conference (FLAIRS), pp. 7276. AAAI Press.Shlyakhter, I., Sridharan, M., Seater, R., & Jackson, D. (2003). Exploiting subformula sharingautomatic analysis quantified formulas. Poster presented Theory ApplicationsSatisfiability Testing (SAT), 6th International Conference.Stockmeyer, L. J. (1974). complexity decision problems automata logic. Ph.D. thesis,Massachusetts Institute Technology.Syrjanen, T. (1998). Implementation local grounding logic programs stable model semantics. Tech. rep. B18, Helsinki University Technology, Finland.268fiGrounding FO FO(ID) BoundsSyrjanen, T. (2000).lparse.ps.gz.Lparse 1.0 users manual. http://www.tcs.hut.fi/Software/smodels/Syrjanen, T. (2009). Logic Programs Cardinality Constraints: Theory Practice. Doctoraldissertation, TKK Dissertations Information Computer Science TKK-ICS-D12, HelsinkiUniversity Technology, Faculty Information Natural Sciences, Department Information Computer Science, Espoo, Finland.Torlak, E., & Jackson, D. (2007). Kodkod: relational model finder. Grumberg, O., & Huth, M.(Eds.), International Conference Tools Algorithms Construction AnalysisSystems (TACAS), Vol. 4424 Lecture Notes Computer Science, pp. 632647. Springer.Ullman, J. D. (1988). Principles database knowledge-base systems, Vol. I. Computer SciencePress, Inc., New York, NY, USA.Van Gelder, A., Ross, K. A., & Schlipf, J. S. (1991). well-founded semantics general logicprograms. Journal ACM, 38 (3), 620650.Veloso, M. M., & Kambhampati, S. (Eds.). (2005). Proceedings, Twentieth National ConferenceArtificial Intelligence Seventeenth Innovative Applications Artificial IntelligenceConference, July 9-13, 2005, Pittsburgh, Pennsylvania, USA. AAAI Press / MIT Press.Wittocx, J., & Marien, M. (2008). idp system. http://www.cs.kuleuven.be/~dtai/krr/software/idpmanual.pdf.Wittocx, J., Marien, M., & Denecker, M. (2008a). Approximate reasoning first-order logic theories.Brewka, G., & Lang, J. (Eds.), International Conference Knowledge RepresentationReasoning (KR), pp. 103112. AAAI Press.Wittocx, J., Marien, M., & Denecker, M. (2008b). GidL: grounder FO+ . Pagnucco, M., &Thielscher, M. (Eds.), Workshop Nonmonotonic Reasoning (NMR), pp. 189198. UniversityNew South Wales.Wittocx, J., Marien, M., & Denecker, M. (2008c). Grounding bounds. Fox, D., & Gomes,C. P. (Eds.), AAAI Conference Artificial Intelligence, pp. 572577. AAAI Press.Wittocx, J., Marien, M., & Denecker, M. (2008d). idp system: model expansion systemextension classical logic. Workshop Logic Search (LaSh), pp. 153165.269fiJournal Artificial Intelligence Research 38 (2010) 475-511Submitted 04/10; published 08/10Minimum Relative Entropy PrincipleLearning ActingPedro A. OrtegaDaniel A. Braunpeortega@dcc.uchile.cldab54@cam.ac.ukDepartment EngineeringUniversity CambridgeCambridge CB2 1PZ, UKAbstractpaper proposes method construct adaptive agent universalrespect given class experts, expert designed specifically particularenvironment. adaptive control problem formalized problem minimizingrelative entropy adaptive agent expert suitableunknown environment. agent passive observer, optimal solutionwell-known Bayesian predictor. However, agent active, past actions needtreated causal interventions I/O stream rather normal probabilityconditions. shown solution new variational problem givenstochastic controller called Bayesian control rule, implements adaptivebehavior mixture experts. Furthermore, shown mild assumptions,Bayesian control rule converges control law suitable expert.1. Introductionbehavior environment control signal fully known,designer choose agent produces desired dynamics. Instances problem include hitting target cannon known weather conditions, solving mazemap controlling robotic arm manufacturing plant. However,environment unknown, designer faces problem adaptive control.example, shooting cannon lacking appropriate measurement equipment, findingway unknown maze designing autonomous robot Martian exploration.Adaptive control turns far difficult non-adaptive counterpart.good policy carefully trade explorative versus exploitative actions,i.e. actions identification environments dynamics versus actions controldesired way. Even environments dynamics known belong particular class optimal agents available, constructing corresponding optimaladaptive agent general computationally intractable even simple toy problems (Duff,2002). Thus, finding tractable approximations major focus research.Recently, proposed reformulate problem statement classescontrol problems based minimization relative entropy criterion. example,large class optimal control problems solved efficiently problem statementreformulated minimization deviation dynamics controlled systemuncontrolled system (Todorov, 2006, 2009; Kappen, Gomez, & Opper, 2010).work, similar approach introduced adaptive control. class agentsc2010AI Access Foundation. rights reserved.fiOrtega & Braungiven, agent tailored different environment, adaptive controllersderived minimum relative entropy principle. particular, one constructadaptive agent universal respect class minimizing average relativeentropy environment-specific agent.However, extension straightforward. syntactical differenceactions observations taken account formulating variationalproblem. specifically, actions treated interventions obeying rulescausality (Pearl, 2000; Spirtes, Glymour, & Scheines, 2000; Dawid, 2010). distinctionmade, variational problem unique solution given stochastic control rulecalled Bayesian control rule. control rule particularly interestingtranslates adaptive control problem on-line inference problem appliedforward time. Furthermore, work shows mild assumptions, adaptiveagent converges environment-specific agent.paper organized follows. Section 2 introduces notation sets adaptivecontrol problem. Section 3 formulates adaptive control minimum relative entropyproblem. initial, nave approach, need causal considerations motivated.Then, Bayesian control rule derived revised relative entropy criterion.Section 4, conditions convergence examined proof given. Section 5illustrates usage Bayesian control rule multi-armed bandit problemundiscounted Markov decision processes. Section 6 discusses properties Bayesiancontrol rule relates previous work literature. Section 7 concludes.2. Preliminariesfollowing agent environment formalized causal models I/Osequences. Agent environment coupled exchange symbols following standardinteraction protocol discrete time, observation control signals. treatmentdynamics fully probabilistic, particular, actions observationsrandom variables, contrast typical decision-theoretic agent formulationtreating observations random variables (Russell & Norvig, 2010). proofsprovided appendix.Notation. set denoted calligraphic letter like A. words set & alphabetelement & symbol used mean thing respectively. Strings finiteconcatenations symbols sequences infiniteconcatenations. denotes setstrings length n based A, := n0 set finite strings. Furthermore, := {a1 a2 . . . |ai = 1, 2, . . .} defined set one-wayinfinite sequences based alphabet A. Tuples written parentheses (a1 , a2 , a3 )strings a1 a2 a3 . notation ai := a1 a2 . . . ai shorthand string starting first index. Also, symbols underlined glue together like aoaoi := a1 o1 a2 o2 . . . ai oi . function log(x) meant taken w.r.t. base 2, unlessindicated otherwise.Interactions. possible I/O symbols drawn two finite sets. Let denoteset inputs (observations) let denote set outputs (actions). set Z := AOinteraction set. string aot ao<t interaction string (optionally ending476fiA Minimum Relative Entropy Principle Learning Actingot ) ak ok O. Similarly, one-sided infinite sequence a1 o1 a2 o2 . . .interaction sequence. set interaction strings length denoted Z .sets (finite) interaction strings sequences denoted Z Z respectively.interaction string length 0 denoted .I/O System. Agents environments formalized I/O systems. I/O systemprobability distribution Pr interaction sequences Z . Pr uniquely determinedconditional probabilitiesPr(at |ao<t ),Pr(ot |ao<t )(1)aot Z . conditional probabilities either represent generative law(propensity) case issuing symbol evidential probability (plausibility)case observing symbol. two interpretations applies particular casebecomes apparent I/O system coupled another I/O system.AgentPa1 o1 a2 o2 a3 o3 a4 o4 a5 o5EnvironmentQFigure 1: model interactions. agent P environment Q define probability distribution interaction sequences.Interaction System. Let P, Q two I/O systems. interaction system (P, Q)coupling two systems giving rise generative distribution G describesprobabilities actually govern I/O stream two systems coupled. Gspecified equationsG(at |ao<t ) := P(at |ao<t )G(ot |ao<t ) := Q(ot |ao<t )valid aot Z . Here, G models true probability distribution interactionsequences arises coupling two systems I/O streams. specifically,system P, P(at |ao<t ) probability producing action given historyao<t P(ot |ao<t ) predicted probability observation ot given history477fiOrtega & Braunao<t . Hence, P, sequence o1 o2 . . . input stream sequence a1 a2 . . .output stream. contrast, roles actions observations reversedcase system Q. Thus, sequence o1 o2 . . . output stream sequencea1 a2 . . . input stream. previous model interaction fairly general, manyinteraction protocols translated scheme. convention, giveninteraction system (P, Q), P agent constructed designer, Qenvironment controlled agent. Figure 1 illustrates setup.Control Problem. environment Q said known iff agent P propertyaot Z ,P(ot |ao<t ) = Q(ot |ao<t ).Intuitively, means agent knows statistics environments futurebehavior past, particular, knows effects given controls.environment known, designer agent build custom-made policyP resulting generative distribution G produces interaction sequencesdesirable. done multiple ways. instance, controls chosenresulting policy maximizes given utility criterion; resultingtrajectory interaction system stays close enough prescribed trajectory. Formally,Q known, conditional probabilities P(at |ao<t ) aot Zchosen resulting generative distribution G interaction sequences givenG(at |ao<t ) = P(at |ao<t )G(ot |ao<t ) = Q(ot |ao<t ) = P(ot |ao<t )desirable, P said tailored Q.Adaptive Control Problem. environment Q unknown, task designing appropriate agent P constitutes adaptive control problem. Specifically,work deals case designer already class agents tailoredclass possible environments. Formally, assumed Q going drawnprobability P (m) set Q := {Qm }mM possible systems interaction starts, countable set. Furthermore, one set P := {Pm }mMsystems M, Pm tailored Qm interaction system(Pm , Qm ) generative distribution Gm produces desirable interaction sequences.designer construct system P behavior close possiblecustom-made system Pm realization Qm Q?3. Adaptive Systemsmain goal paper show problem adaptive control outlinedprevious section reformulated universal compression problem.informally motivated follows. Suppose agent P implemented machineinterfaced environment Q. Whenever agent interacts environment,agents state changes necessary consequence interaction. changestate take place many possible ways: updating internal memory; consulting478fiA Minimum Relative Entropy Principle Learning Actingrandom number generator; changing physical location orientation; forth.Naturally, design agent facilitates interactions complicates others.instance, agent designed explore natural environment, mightincur low memory footprint recording natural images,memory-inefficient recording artificially created images. one abstracts awayinner workings machine decides encode state transitions binarystrings, minimal amount resources bits required implementstate changes derived directly associated probability distribution P.context adaptive control, agent constructed minimizesexpected amount changes necessary implement state transitions, equivalently,maximally compresses experience. Thereby, compression takenstand-alone principle design adaptive agents.3.1 Universal Compression Nave Construction Adaptive Agentscoding theory, problem compressing sequence observations unknownsource known adaptive coding problem. solved constructing universal compressors, i.e. codes adapt on-the-fly source within predefined class(MacKay, 2003). codes obtained minimizing average deviation predictor true source, constructing codewords using predictor.subsection, procedure used derive adaptive agent (Ortega & Braun, 2010).Formally, deviation predictor P true distribution Pm measuredrelative entropy 1 . first approach would construct agent Bminimize total expected relative entropy Pm . constructed follows. Definehistory-dependent relative entropies action observation otXPm (at |ao<t )(ao<t ) :=DmPm (at |ao<t ) logPr(at |ao<t )ot(ao<t ) :=DmXotPm (ot |ao<t ) logPm (ot |ao<t ),Pr(ot |ao<t )Pm (ot |ao<t ) = Qm (ot |ao<t ) Qm known Prargument variational problem. Then, one removes dependency pastaveraging possible histories:X:=(ao<t )Pm (ao<t )DmDmao<totDm:=Xot(ao<t ).Pm (ao<t )Dmao<tFinally, total expected relative entropy Pr Pm obtained summingtime steps averaging choices true environment::= lim supXP (m)X=1.+ DmDm(2)1. relative entropy also known KL-divergence measures average amount extrabits necessary encode symbols due usage (wrong) predictor.479fiOrtega & BraunUsing (2), one define variational problem respect Pr. agent B onelooking system Pr minimizes total expected relative entropy (2), i.e.B := arg min D(Pr).Prsolution Equation 3 system B defined set equationsXB(at |ao<t ) =Pm (at |ao<t )wm (ao<t )B(ot |ao<t ) =XPm (ot |ao<t )wm (ao<t )(3)(4)valid aot Z , mixture weightsP (m)Pm (ao<t )P (m )Pm (ao<t )P (m)Pm (ao<t ).wm (ao<t ) := PP (m )Pm (ao<t )wm (ao<t ) := P(5)reference, see work Haussler Opper (1997) Opper (1998). clearB Bayesian mixture agents Pm . one defines conditionalprobabilitiesP (at |m, ao<t ) := Pm (at |ao<t )(6)P (ot |m, ao<t ) := Pm (at |ao<t )aot Z , Equation 4 rewrittenB(at |ao<t ) =B(ot |ao<t ) =XXP (at |m, ao<t )P (m|ao<t ) = P (at |ao<t )P (ot |m, ao<t )P (m|ao<t ) = P (ot |ao<t )(7)P (m|ao<t ) = wm (ao<t ) P (m|ao<t ) = wm (ao<t ) posteriorprobabilities elements given past interactions. Hence, conditionalprobabilities (4) minimize total expected divergence predictivedistributions P (at |ao<t ) P (ot |ao<t ) one obtains standard probability theory,particular, Bayes rule. interesting, provides teleological interpretationBayes rule.behavior B described follows. given time t, B maintainsmixture systems Pm . weighting given mixture coefficientswm . Whenever new action new observation ot produced (by agentenvironment respectively), weights wm updated according Bayes rule.addition, B issues action suggested system Pm drawn randomly accordingweights wt .However, important problem B arises due factsystem passively observing symbols, also actively generating them.subjective interpretation probability theory, conditionals play role observations480fiA Minimum Relative Entropy Principle Learning Actingmade agent generated external source. interpretation suitssymbols o1 , o2 , o3 , . . . issued environment. However, symbols generated system require fundamentally different belief update.Intuitively, difference explained follows. Observations provide informationallows agent inferring properties environment. contrast, actionscarry information environment, thus incorporated differentlybelief agent. following section illustrate problem simplestatistical example.3.2 CausalityCausality study functional dependencies events. stands contraststatistics, which, abstract level, said study equivalence dependencies(i.e. co-occurrence correlation) amongst events. Causal statements differ fundamentallystatistical statements. Examples highlight differences many,smokers get lung cancer? opposed smokers lung cancer?; assignf (x) opposed compare = f (x) programming languages; F/mopposed F = Newtonian physics. study causality recently enjoyedconsiderable attention researchers fields statistics machine learning.Especially last decade, significant progress made towards formalunderstanding causation (Shafer, 1996; Pearl, 2000; Spirtes et al., 2000; Dawid, 2010).subsection, aim provide essential tools required understand causalinterventions. in-depth exposition causality, reader referredspecialized literature.illustrate need causal considerations case generated symbols, considerfollowing thought experiment. Suppose statistician asked design modelsimple time series X1 , X2 , X3 , . . . decides use Bayesian method. Assumecollects first observation X1 = x1 . computes posterior probability density function(pdf) parameters model given data using Bayes rule:p(|X1 = x1 ) = Rp(X1 = x1 |)p(),p(X1 = x1 | )p( )p(X1 = x1 |) likelihood x1 given p() prior pdf .use model predict next observation drawing sample x2 predictivepdfZp(X2 = x2 |X1 = x1 ) = p(X2 = x2 |X1 = x1 , ) p(|X1 = x1 ) d,p(X2 = x2 |X1 = x1 , ) likelihood x2 given x1 . Note x2drawn p(X2 = x2 |X1 = x1 , ). understands nature x2 differentx1 : x1 informative change belief state Bayesian model,x2 non-informative thus reflection models belief state. Hence, wouldnever use x2 condition Bayesian model. Mathematically, seems implyp(|X1 = x1 , X2 = x2 ) = p(|X1 = x1 )481fiOrtega & Braunx2 generated p(X2 |X1 = x1 ) itself. simple independence assumption correct following elaboration example show.statistician told source waiting simulated data point x2order produce next observation X3 = x3 depend x2 . hands x2obtains new observation x3 . Using Bayes rule, posterior pdf parametersp(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X1 = x1 |) p()R(8)p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X1 = x1 | ) p( )p(X3 = x3 |X1 = x1 , X2 = x2 , ) likelihood new data x3 given olddata x1 , parameters simulated data x2 . Notice looks almost likeposterior pdf p(|X1 = x1 , X2 = x2 , X3 = x3 ) givenRp(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X2 = x2 |X1 = x1 , ) p(X1 = x1 |) p()p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X2 = x2 |X1 = x1 , ) p(X1 = x1 | ) p( )exception latter case, Bayesian update contains likelihoodssimulated data p(X2 = x2 |X1 = x1 , ). suggests Equation 8 variantposterior pdf p(|X1 = x1 , X2 = x2 , X3 = x3 ) simulated data x2 treateddifferent way data x1 x3 .Define pdf p pdfs p (), p (X1 |), p (X3 |X1 , X2 , ) identicalp(), p(X1 |) p(X3 |X2 , X1 , ) respectively, differ p (X2 |X1 , ):p (X2 |X1 , ) = (X2 x2 ).Dirac delta function. is, p identical p assumesvalue X2 fixed x2 given X1 . p , simulated data x2 non-informative:log2 p (X2 = x2 |X1 , ) = 0.one computes posterior pdf p (|X1 = x1 , X2 = x2 , X3 = x3 ), one obtains resultEquation 8:Rp (X3 = x3 |X1 = x1 , X2 = x2 , ) p (X2 = x2 |X1 = x1 , ) p (X1 = x1 |) p ()p (X3 = x3 |X1 = x1 , X2 = x2 , )p (X2 = x2 |X1 = x1 , ) p (X1 = x1 | ) p ( )p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X1 = x1 |) p()=R.p(X3 = x3 |X1 = x1 , X2 = x2 , ) p(X1 = x1 | ) p( )Thus, order explain Equation 8 posterior pdf given observed data x1 x3generated data x2 , one intervene p order account fact x2non-informative given x1 . words, statistician, defining valueX2 herself2 , changed (natural) regime brings series X1 , X2 , X3 , . . .,mathematically expressed redefining pdf.Two essential ingredients needed carry interventions. First, one needsknow functional dependencies amongst random variables probabilistic model.provided causal model, i.e. unique factorization joint probability2. Note conceptually broken two steps: first, samples x2 p(X2 |X1 = x1 );second, imposes value X2 = x2 setting p (X2 |X1 , ) = (X2 x2 ).482fiA Minimum Relative Entropy Principle Learning Actingdistribution random variables encoding causal dependencies. generalcase, defines partial order random variables. previous thought experiment, causal model joint pdf p(, X1 , X2 , X3 ) given set conditionalpdfsp(), p(X1 |), p(X2 |X1 , ), p(X3 |X1 , X2 , ).Second, one defines intervention sets X value x, denoted X x,operation causal model replacing conditional probability X Diracdelta function (X x) Kronecker delta xX continuous discrete variable Xrespectively. thought experiment, easily seenp (, X1 = x1 , X2 = x2 , X3 = x3 ) = p(, X1 = x1 , X2 x2 , X3 = x3 )thereby,p (|X1 = x1 , X2 = x2 , X3 = x3 ) = p(|X1 = x1 , X2 x2 , X3 = x3 ).Causal models contain additional information available joint probabilitydistribution alone. appropriate model given situation depends storytold. Note intervention lead different results respective causalmodels differ. Thus, causal modelp(X3 ), p(X2 |X3 ), p(X1 |X2 , X3 ), p(|X1 , X2 , X3 )intervention X2 x2 would differ p , i.e.p (, X1 = x1 , X2 = x2 , X3 = x3 ) 6= p(, X1 = x1 , X2 x2 , X3 = x3 ),even though causal models represent joint probability distribution.following, paper use shorthand notation x := X x random variableobvious context.3.3 Causal Construction Adaptive AgentsFollowing discussion previous section, adaptive agent P going constructed minimizing expected relative entropy expected Pm , timetreating actions interventions. Based definition conditional probabilitiesEquation 6, total expected relative entropy characterize P using interventions going defined. Assuming environment chosen first, symbol dependsfunctionally environment previously generated symbols, causal modelgivenP (m), P (a1 |m), P (o1 |m, a1 ), P (a2 |m, a1 , o1 ), P (o2 |m, a1 , o1 , a2 ), . . .Importantly, interventions index set intervened probability distributions derivedbase probability distribution. Hence, set fixed intervention sequences forma1 , a2 , . . . indexes probability distributions observation sequences o1 , o2 , . . ..this, one defines set criteria indexed intervention sequences,483fiOrtega & Braunclear solution. Define history-dependent intervened relativeentropies action observation ot(ao<t ) :=CmXot(ao<t ) :=CmXotP (at |m, ao<t ) log2P (at |m, ao<t )Pr(at |ao<t )P (ot |m, ao<t ) log2P (ot |m, ao<t ),Pr(ot |ao<t )Pr given arbitrary agent. Note past actions treated interventions.particular, P (at |m, ao<t ) represents knowledge state past actions alreadyissued next action known yet. Then, averaging previous relativeentropies pasts yields=CmXao<tot=Cm(ao<t )P (ao<t |m)CmXao<tot(ao<t ).P (ao<t |m)Cm(ao ) C ot (ao ),again, knowledge state time represented Cm<t<taverages taken treating past actions interventions. Finally, define total exat + C ot ) time, averagedpected relative entropy Pr Pm sum (Cmpossible draws environment:C := lim supXP (m)X=1+ CmCm.(9)variational problem consists choosing agent P system Pr minimizingC = C(Pr), i.e.P := arg min C(Pr).(10)Prfollowing theorem shows variational problem unique solution,central theme paper.Theorem 1. solution Equation 10 system P defined set equationsXP(at |ao<t ) = P (at |ao<t ) =P(ot |ao<t ) = P (ot |ao<t ) =P (at |m, ao<t )vm (ao<t )XP (ot |m, ao<t )vm (ao<t )(11)valid aot Z , mixture weightsQt1=1 P (o |m, ao< ).Qt1=1 P (o |m , ao< )P (m )vm (ao<t ) = vm (ao<t ) := PP (m)484(12)fiA Minimum Relative Entropy Principle Learning ActingBayesian Control Rule: Given set operation modes {P (|m, )}mMinteraction sequences Z prior distribution P (m)parameters M, probability action at+1 givenXP (at+1 |m, aot )P (m|aot ),(13)P (at+1 |aot ) =posterior probability operation modes given recursionP (ot |m, ao<t )P (m|ao<t ).P (ot |m , ao<t )P (m |ao<t )P (m|aot ) = PTable 1: Summary Bayesian control rule.theorem says optimal solution variational problem (10) preciselypredictive distribution actions observations treating actions interventionsobservations conditionals, i.e. solution one would obtain applyingstandard probability causal calculus. provides teleological interpretationagent P akin nave agent B constructed Section 3.1. behavior P differsimportant aspect B. given time t, P maintains mixture systemsPm . weighting systems given mixture coefficients vm . contrastB, P updates weights vm whenever new observation ot producedenvironment. update follows Bayes rule treats past actions interventionsdropping evidence provide. addition, P issues action suggestedsystem drawn randomly according weights vm .3.4 SummaryAdaptive control formalized problem designing agent unknown environment chosen class possible environments. environment-specific agentsknown, Bayesian control rule allows constructing adaptive agent combiningagents. resulting adaptive agent universal respect environmentclass. context, constituent agents called operation modes adaptiveagent. represented causal models interaction sequences, i.e. conditionalprobabilities P (at |m, ao<t ) P (ot |m, ao<t ) aot Z ,index parameter characterizing operation mode. probability distributioninput stream (output stream) called hypothesis (policy) operation mode.Table 1 collects essential equations Bayesian control rule. particular,rule stated using recursive belief update.4. Convergenceaim section develop set sufficient conditions convergenceprovide proof convergence. simplify exposition, analysis limited485fiOrtega & Brauncase controllers finite number input-output models.4.1 Policy Diagramsfollowing use policy diagrams useful informal tool analyze effectpolicies environments. Figure 2 illustrates example.state spaceaopolicyFigure 2: policy diagram. One imagine environment collection statesconnected transitions labeled I/O symbols. zoom highlights statetaking action collecting observation leads state .Sets states transitions represented enclosed areas similar Venndiagram. Choosing particular policy environment amounts partiallycontrolling transitions taken state space, thereby choosing probabilitydistribution state transitions (e.g. Markov chain given environmentaldynamics). probability mass concentrates certain areas state space,choosing policy thought choosing subset environmentsdynamics. following, policy represented subset state space(enclosed directed curve) illustrated above.Policy diagrams especially useful analyze effect policies different hypotheses environments dynamics. agent endowed set operationmodes seen hypotheses environments underlying dynamics,given observation models P (ot |m, ao<t ), associated policies, given action models P (at |m, ao<t ), M. sake simplifying interpretationpolicy diagrams, assume existence state space : (A O) mappingI/O histories states. Note however assumptions made obtainresults section.4.2 Divergence Processescentral question section investigate whether Bayesian control rule converges correct control law not. is, whether P (at |aot ) P (at |m , ao<t )true operation mode, i.e. operation mode P (ot |m , ao<t ) =Q(ot |ao<t ). obvious discussion rest section,general true.easily seen Equation 13, showing convergence amounts showposterior distribution P (m|ao<t ) concentrates probability mass subset operation486fiA Minimum Relative Entropy Principle Learning Actingmodes essentially output stream ,XXP (at |m, ao<t )P (m|ao<t )P (at |m , ao<t )P (m|ao<t ) P (at |m , ao<t ).mMmMHence, understanding asymptotic behavior posterior probabilitiesP (m|aot )crucial here. particular, need understand conditions quantitiesconverge zero. posterior rewrittenQP (aot |m)P (m)P (m) =1 P (o |m, ao< ).=PP (m|aot ) = PQtP (aot |m )P (m )P (m )=1 P (o |m , ao< )summands one index dropped denominator, oneobtains boundP (m|aot )P (m) P (o |m, ao< ),P (m )P (o |m , ao< )=1valid M. inequality, seen convenientanalyze behavior stochastic processdt (m km) :=X=1lnP (o |m , ao< )P (o |m, ao< )divergence process reference . Indeed, dt (m km),P (m)P (m) P (o |m, ao< )= limedt (m km) = 0,P (m )P (o |m , ao< ) P (m )lim=1thus clearly P (m|aot ) 0. Figure 3 illustrates simultaneous realizationsdivergence processes controller. Intuitively speaking, processes provide lowerbounds accumulators surprise value measured information units.divergence process random walk whose value time depends wholehistory time t1. makes divergence processes cumbersome characterizefact statistical properties depend particular policy applied;hence, given divergence process different growth rates depending policy(Figure 4). Indeed, behavior divergence process might depend criticallydistribution actions used. example, happen divergence processstays stable one policy, diverges another. context Bayesiancontrol rule problem aggravated, time step, policyapplied determined stochastically. specifically, true operation mode,dt (m km) random variable depends realization aot drawn=1P (a |m , ao )P (o |m , ao ),487fiOrtega & Braundt12340Figure 3: Realization divergence processes 1 4 associated controlleroperation modes m1 m4 . divergence processes 1 2 diverge, whereas 34 stay dotted bound. Hence, posterior probabilities m1m2 vanish.dt1232103Figure 4: application different policies lead different statistical propertiesdivergence process.488fiA Minimum Relative Entropy Principle Learning Actingm1 , m2 , . . . , mt drawn P (m1 ), P (m2 |ao1 ), . . . , P (mt |ao<t ).deal heterogeneous nature divergence processes, one introducetemporal decomposition demultiplexes original process many sub-processesbelonging unique policies. Let Nt := {1, 2, . . . , t} set time steps time t.Let Nt , let m, M. Define sub-divergence dt (m km) random variableX P (o |m , ao )<gm (m; ) :=lnP (o |m, ao< )drawnPm ({ao } |{ao } ) :=P (a |m , ao< )P (o |m , ao< ) ,:= Nt \ {ao } given conditions kept constant.definition, plays role policy used sample actions timesteps . Clearly, realization divergence process dt (m km) decomposedsum sub-divergences, i.e.Xgm (m; Tm ),dt (m km) =(14){Tm }mM forms partition Nt . Figure 5 shows example decomposition.dt1230Figure 5: Decomposition divergence process (1) sub-divergences (2 & 3).averages sub-divergences play important role analysis. Defineaverage realizations gm (m; )XPm ({ao } |{ao } )gm (m; ).Gm (m; ) :=(ao )Notice Nt ,XP (o |m , ao< )P (a |m , ao< )P (o |m , ao< ) ln0,Gm (m; { }) =P (o |m, ao< )aoGibbs inequality. particular,Gm (m ; { }) = 0.Clearly, holds well Nt :Gm (m; ) 0,Gm (m ; ) = 0.489(15)fiOrtega & Braun4.3 Boundednessgeneral, divergence process complex: virtually classes distributionsinterest control go well beyond assumptions i.i.d. stationarity.increased complexity jeopardize analytic tractability divergence process,predictions asymptotic behavior made anymore. specifically,growth rates divergence processes vary much realization realization, posterior distribution operation modes vary qualitativelyrealizations. Hence, one needs impose stability requirement akin ergodicity limitclass possible divergence-processes class analytically tractable.purpose following property introduced.divergence process dt (m km) said bounded variation iff > 0,C 0, M, Ntfififififigm (m; ) Gm (m; )fi Cprobability 1 .dt1230Figure 6: divergence process bounded variation, realizations (curves 2 &3) sub-divergence stay within band around mean (curve 1).Figure 6 illustrates property. Boundedness key property goingused construct results section. first important result posteriorprobability true input-output model bounded below.Theorem 2. Let set operation modes controllerdivergence process dt (m km) bounded variation. Then, > 0, > 0,N,P (m |aot )|M|probability 1 .4.4 Coreone wants identify operation modes whose posterior probabilities vanish,enough characterize modes whose hypothesis matchtrue hypothesis. Figure 7 illustrates problem. Here, three hypotheses alongassociated policies shown. H1 H2 share prediction made region differ490fiA Minimum Relative Entropy Principle Learning Actingregion B. Hypothesis H3 differs everywhere others. Assume H1 true. longapply policy P2 , hypothesis H3 make wrong predictions thus divergenceprocess diverge expected. However, evidence H2 accumulated.one applies policy P1 long enough time controller eventuallyenter region B hence accumulate counter-evidence H2 .H1H2BH3BP3P1P2Figure 7: hypothesis H1 true agrees H2 region A, policy P2 cannotdisambiguate three hypotheses.long enough mean? P1 executed short period,controller risks visiting disambiguating region. unfortunately, neither rightpolicy right length period run known beforehand. Hence, agentneeds clever time-allocating strategy test policies finite time intervals.motivates following definition.core operation mode , denoted [m ], subset containingoperation modes behaving like policy. formally, operation mode/ [m ] (i.e. core) iff C 0, > 0, > 0 t0 N,t0 ,Gm (m; ) Cprobability 1 , Gm (m; ) sub-divergence dt (m km), Pr{} Nt .words, agent apply policy time step probabilityleast , strategy expected sub-divergence Gm (m; ) dt (m km) growsunboundedly, core . Note demanding strictly positiveprobability execution time step guarantees agent runpossible finite time-intervals. following theorem shows, posterior probabilitiesoperation modes core vanish almost surely.Theorem 3. Let set operation modes agentdivergence process dt (m km) bounded variation./ [m ], P (m|aot ) 0almost surely.4.5 ConsistencyEven operation mode core , i.e. given essentially indistinguishable control, still happen differentpolicies. Figure 8 shows example this. hypotheses H1 H2 share region491fiOrtega & Braundiffer region B. addition, operation modes policies P1 P2 respectively confined region A. Note operation modes core other.However, policies different. means unclear whether multiplexingpolicies time ever disambiguate two hypotheses. undesirable, couldimpede convergence right control law.H2H1BBP2P1Figure 8: example inconsistent policies. operation modes coreother, different policies.Thus, clear one needs impose restrictions mapping hypotheses policies. respect Figure 8, one make following observations:1. operation modes policies select subsets region A. Therefore,dynamics preferred dynamics B.2. Knowing dynamics preferred dynamics B allows usdrop region B analysis choosing policy.3. Since hypotheses agree region A, choose policy orderconsistent selection criterion.motivates following definition. operation mode said consistentiff [m ] implies < 0, t0 , t0ao<t ,fififififiP (at |m, aot ) P (at |m , aot )fi < .words, core , ms policy converge policy.following theorem shows consistency sufficient condition convergenceright control law.Theorem 4. Let set operation modes agent that:divergence process dt (m km) bounded variation; m, M, consistent. Then,P (at |ao<t ) P (at |m , ao<t )almost surely .492fiA Minimum Relative Entropy Principle Learning Acting4.6 Summarysection, proof convergence Bayesian control rule true operationmode provided finite set operation modes. convergence resulthold, two necessary conditions assumed: boundedness consistency. first one,boundedness, imposes stability divergence processes partial influencepolicies contained within set operation modes. condition regardedergodicity assumption. second one, consistency, requires hypothesis makespredictions another hypothesis within relevant subset dynamics,hypotheses share policy. relevance formalized coreoperation mode. concepts proof strategies strengthen intuition potentialpitfalls arise context controller design. particular could showasymptotic analysis recast study concurrent divergence processesdetermine evolution posterior probabilities operation modes, thus abstractingaway details classes I/O distributions. extension resultsinfinite sets operation modes left future work. example, one could thinkpartitioning continuous space operation modes essentially different regionsrepresentative operation modes subsume neighborhoods (Grunwald, 2007).5. Examplessection illustrate usage Bayesian control rule two examplescommon reinforcement learning literature: multi-armed bandits Markovdecision processes.5.1 Bandit ProblemsConsider multi-armed bandit problem (Robbins, 1952). problem stated follows.Suppose N -armed bandit, i.e. slot-machine N levers. pulled, leverprovides reward drawn Bernoulli distribution bias hi specific lever.is, reward r = 1 obtained probability hi reward r = 0 probability1hi . objective game maximize time-averaged reward iterativepulls. continuum range stationary strategies, one parameterized Nprobabilities {si }Ni=1 indicating probabilities pulling lever. difficulty arisingbandit problem balance reward maximization based knowledge alreadyacquired attempting new actions improve knowledge. dilemma knownexploration versus exploitation tradeoff (Sutton & Barto, 1998).ideal task Bayesian control rule, possible banditknown optimal agent. Indeed, bandit represented N -dimensional bias vector= [m1 , . . . , mN ] = [0; 1]N . Given bandit, optimal policy consistspulling lever highest bias. is, operation mode given by:hi = P (ot = 1|m, = i) = misi = P (at = i|m) =493(1 = maxj {mj },0 else.fiOrtega & Braunm20a)1b)m1 m2m211m2 m1 , 3m30m100m111Figure 9: space bandit configurations partitioned N regions accordingoptimal lever. Panel b show 2-armed 3-armed bandit casesrespectively.apply Bayesian control rule, necessary fix prior distributionbandit configurations. Assuming uniform distribution, Bayesian control ruleZ(16)P (at+1 = i|m)P (m|aot )P (at+1 = i|aot ) =update rule givenQrNmj j (1 mj )fjP (m) =1 P (o |m, )=P (m|aot ) = RQtB(rj + 1, fj + 1)=1 P (o |m , ) dmP (m )j=1(17)rj fj counts number times reward obtainedpulling lever j number times reward obtained respectively. Observesummation discrete operation modes replaced integralcontinuous space configurations. last expression see posteriordistribution lever biases given product N Beta distributions. Thus,sampling action amounts first sample operation mode obtaining biasmi Beta distribution parameters ri + 1 fi + 1, choosingaction corresponding highest bias = arg maxi mi . pseudo-code seenAlgorithm 1.Simulation: Bayesian control rule described compared twoagents: -greedy strategy decay (on-line) Gittins indices (off-line).test bed consisted bandits N = 10 levers whose biases drawn uniformlybeginning run. Every agent play 1000 runs 1000 time steps each.Then, performance curves individual runs averaged. -greedy strategyselects random action small probability given otherwise playslever highest expected reward. parameters determined empiricallyvalues = 0.1, = 0.99 several test runs. adjusted waymaximize average performance last trials simulations. Gittinsmethod, indices computed horizon 1300 using geometric discounting= 0.999, i.e. close one approximate time-averaged reward. resultsshown Figure 10.494fiA Minimum Relative Entropy Principle Learning ActingAlgorithm 1 BCR bandit.= 1, . . . , NInitialize ri fi zero.end= 1, 2, 3, . . .Sample using (17).{ Interaction }Set arg maxi mi issue a.Obtain environment.Avg. Reward{Update belief}= 1ra = ra + 1elsefa = fa + 1endend0.850.80Bayesian control rule-greedyGittins indices0.750.700200400600800100002004006008001000% Best Lever100806040200Figure 10: Comparison N -armed bandit problem Bayesian control rule (solidline), -greedy agent (dashed line) using Gittins indices (dotted line).1,000 runs averaged. top panel shows evolution averagereward. bottom panel shows evolution percentage timesbest lever pulled.495fiOrtega & Braunseen -greedy strategy quickly reaches acceptable level performance,seems stall significantly suboptimal level, pulling optimal lever 60%time. contrast, Gittins strategy Bayesian control rule show essentially asymptotic performance, differ initial transient phaseGittins strategy significantly outperforms Bayesian control rule. least threeobservations worth making here. First, Gittins indices pre-computedoff-line. time complexity scales quadratically horizon, computationshorizon 1300 steps took several hours machines. contrast, Bayesiancontrol rule could applied without pre-computation. Second, even though Gittinsmethod actively issues optimal information gathering actions Bayesian controlrule passively samples actions posterior distribution operation modes,end methods rely convergence underlying Bayesian estimator.implies methods information bottleneck, since Bayesian estimator requires amount information converge. Thus, active information gatheringactions affect utility transient phase, permanent state. efficient algorithms bandit problems found literature (Auer, CesaBianchi, &Fischer, 2002).5.2 Markov Decision ProcessesMarkov Decision Process (MDP ) defined tuple (X , A, T, r): X state space;action space; Ta (x; x ) = Pr(x |a, x) probability actiontaken state x X lead state x X ; r(x, a) R := R immediatereward obtained state x X action A. interaction proceeds time steps= 1, 2, . . . time t, action issued state xt1 X , leading rewardrt = r(xt1 , ) new state xt starts next time step + 1. stationary closedloop control policy : X assigns action state. MDPs alwaysexists optimal stationary deterministic policy thus one needs considerpolicies. undiscounted MDPs average rewardPper time step fixed policyinitial state x defined (x) = limt E [ 1t =0 r ]. shown (Bertsekas,1987) (x) = (x ) x, x X assumption Markov chainpolicy ergodic. Here, assume MDPs ergodic stationary policies.order keep intervention model particularly simple3 , follow Q-notationWatkins (1989). optimal policy characterized terms optimalaverage reward optimal relative Q-values Q(x, a) state-action pair (x, a)solutions following system non-linear equations (Singh, 1994):3. brute-force adaptive agent problem would roughly look follows. First, agentstarts prior distribution MDPs, e.g. product Dirichlet distributions transitionprobabilities. Then, cycle, agent samples full transition matrix distributionsolves using dynamic programming. computed optimal policy, uses issuenext action, discards policy. Subsequently, updates distribution MDPs usingnext observed state. However, main text follow different approach avoids solvingMDP every time step.496fiA Minimum Relative Entropy Principle Learning Actingstate x X action A,Q(x, a) + = r(x, a) +Xx XhQ(x,)Pr(x |x, a) maxfihfi= r(x, a) + Ex maxx,.Q(x,)fi(18)optimal policy defined (x) := arg maxa Q(x, a) state x X .setup allows straightforward solution Bayesian control rule,learnable MDP (characterized Q-values average reward)known solution . Accordingly, operation mode given = [Q, ] =R|A||O|+1 . obtain likelihood model inference m, realize Equation 18rewritten predicts instantaneous reward r(x, a) sum meaninstantaneous reward plus noise term given Q-values average rewardMDP labeledr(x, a) = Q(x, a) + maxQ(x , ) + maxQ(x , ) E[maxQ(x , )|x, a]|{z}{z}|noisemean instantaneous reward (x,a,x )Assuming reasonably approximated normal distribution N(0, 1/p)precision p, write likelihood model immediate reward r usingQ-values average reward, i.e.rn pp2P (r|m, x, a, x ) =(19)exp (r (x, a, x )) .22order determine intervention model operation mode, simply exploitproperties Q-values, gives(1 = arg maxa Q(x, )P (a|m, x) =(20)0 else.apply Bayesian control rule, posterior distribution P (m|at , xt ) needscomputed. Fortunately, due simplicity likelihood model, one easily deviseconjugate prior distribution apply standard inference methods (see Appendix A.5). Actions determined sampling operation modes posterior executingaction suggested corresponding intervention models. resulting algorithmsimilar Bayesian Q-learning (Dearden, Friedman, & Russell, 1998; Dearden, Friedman, & Andre, 1999), differs way actions selected. pseudo-code listedAlgorithm 2.Simulation: tested MDP-agent grid-world example. give intuitionachieved performance, results contrasted achieved R-learning.used R-learning variant presented work Singh (1994, Algorithm 3)together uncertainty exploration strategy (Mahadevan, 1996). correspondingupdate equationsQ(x, a) (1 )Q(x, a) + r + maxQ(x , )(21)(1 ) + r + maxQ(x,)Q(x,a),497fiOrtega & BraunAlgorithm 2 BCR-MDP Gibbs sampler.Initialize entries zero.Set initial state x x0 .= 1, 2, 3, . . .{Gibbs sweep}Sample using (30).Q(y, b) visited statesSample Q(y, b) using (31).end{ Interaction }Set arg maxa Q(x, ) issue a.Obtain = (r, x ) environment.{Update hyperparameters})(x,a,x )+p r(x, a, x ) (x,a,x(x,a,x )+p(x, a, x ) (x, a, x ) + pSet x x .endgoalmembranesb) Bayesian control rulec) R-learning, C=5d) R-learning, C=30initial 5,000 stepsa) 7x7 Mazee) R-learning, C=200f) Average Reward0.40.3C=30C=50.2lowprobabilityC=2000.1last 5,000 stepshighprobabilityBayesian control rule0.00125250375500x1000 time stepsFigure 11: Results 77 grid-world domain. Panel (a) illustrates setup. Columns(b)-(e) illustrate behavioral statistics algorithms. upper lowerrow calculated first last 5,000 time steps randomlychosen runs. probability state color-encoded, arrowsrepresent frequent actions taken agents. Panel (f) presentscurves obtained averaging ten runs.498fiA Minimum Relative Entropy Principle Learning ActingAverage RewardBCRR-learning, C = 200R-learning, C = 30R-learning, C = 50.3582 0.00380.2314 0.00240.3056 0.00630.2049 0.0012Table 2: Average reward attained different algorithms end run.mean standard deviation calculated based 10 runs., > 0 learning rates. exploration strategy chooses fixed probabilityCpexp > 0 action maximizes Q(x, a) + F (x,a), C constant, F (x, a)represents number times action tried state x. Thus, higher valuesC enforce increased exploration.study (Mahadevan, 1996), grid-world described especially usefultest bed analysis RL algorithms. purposes, particular interesteasy design experiments containing suboptimal limit-cycles. Figure 11, panel(a), illustrates 7 7 grid-world. controller learn policy leadsinitial location goal state. step, agent move adjacentspace (up, down, left right). agent reaches goal state next positionrandomly set square grid (with uniform probability) start another trial.also one-way membranes allow agent move one directionother. experiments, membranes form inverted cupsagent enter side leave bottom, playing rolelocal maximum. Transitions stochastic: agent moves correct square9probability p = 10free adjacent spaces (uniform distribution)1probability 1 p = 10 . Rewards assigned follows. default reward r = 0.agent traverses membrane obtains reward r = 1. Reaching goal stateassigns r = 2.5. parameters chosen simulation following.MDP-agent, chosen hyperparameters 0 = 1 0 = 1 precision p = 1.R-learning, chosen learning rates = 0.5 = 0.001, explorationconstant set C = 5, C = 30 C = 200. total 10 runs carriedalgorithm. results presented Figure 11 Table 2. R-learninglearns optimal policy given sufficient exploration (panels & e, bottom row), whereasBayesian control rule learns policy successfully. Figure 11f, learning curveR-learning C = 5 C = 30 initially steeper Bayesian controller. However,latter attains higher average reward around time step 125,000 onwards. attributeshallow initial transient phase distribution operation modesflat, also reflected initially random exploratory behavior.6. Discussionkey idea work extend minimum relative entropy principle, i.e.variational principle underlying Bayesian estimation, problem adaptive control.499fiOrtega & Brauncoding point view, work extends idea maximal compressionobservation stream whole experience agent containing agents actionsobservations. minimizes amount bits write saving/encodingI/O stream, also minimizes amount bits required produce/decodeaction (MacKay, 2003, Ch. 6).extension non-trivial, important caveat coding I/O sequences: unlike observations, actions carry information could usedinference adaptive coding actions issued decoder itself. probleminference ones actions logically inconsistent leads paradoxes(Nozick, 1969). seemingly innocuous issue turned intricateinvestigated intensely recent past researchers focusing issuecausality (Pearl, 2000; Spirtes et al., 2000; Dawid, 2010). work contributes bodyresearch providing evidence actions cannot treated using probabilitycalculus alone.causal dependencies carefully taken account, minimizing relativeentropy leads rule adaptive control called Bayesian control rule.rule allows combining class task-specific agents agent universalrespect class. resulting control law simple stochastic control rulecompletely general parameter-free. analysis paper shows, controlrule converges true control law mild assumptions.6.1 Critical IssuesCausality. Virtually every adaptive control method literature successfully treatsactions conditionals observation streams never worries causality.Thus, bother interventions? decision-theoretic setup, decisionmaker chooses policy maximizingP expected utility U outcomes, i.e. := arg max E[U |] = Pr(|)U (). Choosing formallyequivalent choosing Kronecker delta function probability distributionpolicies. case, conditional probabilities Pr(|) Pr(|) coincide,sincePr(, ) = Pr()Pr(|) = Pr(|) = Pr(, ).sense, choice policy causally precedes interactions.discussed Section 3 however, uncertainty policy (i.e. Pr() 6=), causal belief updates crucial. Essentially, problem arisesuncertainty policy resolved interactions. Hence, treatingactions interventions seamlessly extends status random variables.prior probabilities/likelihood models/policies come from? predictorBayesian control rule essentially Bayesian predictor thereby entails (almost) modeling paradigm. designer define class hypothesesenvironments, construct appropriate likelihood models, choose suitableprior probability distribution capture models uncertainty. Similarly, sufficient domain knowledge, analogous procedure applied construct suitableoperation modes. However, many situations difficult even500fiA Minimum Relative Entropy Principle Learning Actingintractable problem itself. example, one design class operation modespre-computing optimal policies given class environments. Formally, letclass hypotheses modeling environments let class policies. Givenutility criterion U , define set operation modes := {m } constructing operation mode := (, ), , := arg max E[U |, ].However, computing optimal policy many cases intractable.cases, remedied characterizing operation modes optimalityequations solved probabilistic inference example MDPagent Section 5.2. Recently, applied similar approach adaptive controlproblems linear quadratic regulators (Braun & Ortega, 2010).Problems Bayesian methods. Bayesian control rule treats adaptive controlproblem Bayesian inference problem. Hence, problems typically associatedBayesian methods carry agents constructed Bayesian controlrule. problems analytical computational nature. example,many probabilistic models posterior distributionclosed-form solution. Also, exact probabilistic inference general computationallyintensive. Even though large literature efficient/approximate inference algorithms particular problem classes (Bishop, 2006), manysuitable on-line probabilistic inference realistic environment classes.Bayesian control rule versus Bayes-optimal control. Directly maximizing (subjective) expected utility given environment class minimizingexpected relative entropy given class operation modes. two methodsbased different assumptions optimality principles. such, Bayesiancontrol rule Bayes-optimal controller. Indeed, easy design experimentsBayesian control rule converges exponentially slower (or convergeall) Bayes-optimal controller maximum utility. Consider followingsimple example: Environment 1 k-state MDP k consecutive actionsreach state reward +1. interception B-action leads backinitial state. Consider second environment like first actionsB interchanged. Bayes-optimal controller figures true environment kactions (either k consecutive Bs). Consider Bayesian control rule:optimal action Environment 1 A, Environment 2 B. uniform ( 21 , 21 ) prioroperation modes stays uniform posterior long rewardobserved. Hence Bayesian control rule chooses time-step Bequal probability. policy takes 2k actions accidentally chooserow (or Bs) length k. Bayesian control rule optimaltoo. Bayes-optimal controller converges time k, Bayesian controlrule needs exponentially longer. One way remedy problem might allowBayesian control rule sample actions operation mode severaltime steps row rather randomizing controllers every cycle. However,one considers non-stationary environments strategyalso break down. Consider, example, increasing MDP k = 10 , Bayes-optimalcontroller converges 100 steps, Bayesian control rule convergerealizations, boundedness assumption violated.501fiOrtega & Braun6.2 Relation Existing Approachesideas underlying work unique Bayesian control rule.following selection previously published work recent Bayesian reinforcementlearning literature related ideas found.Compression principles. literature, important amount workrelating compression intelligence (MacKay, 2003; Hutter, 2004b). particular,even proposed compression ratio objective quantitative measureintelligence (Mahoney, 1999). Compression also used basis theorycuriosity, creativity beauty (Schmidhuber, 2009).Mixture experts. Passive sequence prediction mixing experts studiedextensively literature (Cesa-Bianchi & Lugosi, 2006). study onlinepredictors (Hutter, 2004a), Bayes-optimal predictors mixed. Bayes-mixturesalso used universal prediction (Hutter, 2003). control case, ideausing mixtures expert-controllers previously evoked models likeMOSAIC-architecture (Haruno, Wolpert, & Kawato, 2001). Universal learningBayes mixtures experts reactive environments studied workPoland Hutter (2005) Hutter (2002).Stochastic action selection. idea using actions random variables,problems entails, expressed work Hutter (2004b, Problem5.1). study Section 3 regarded thorough investigation openproblem. stochastic action selection approaches found thesis Wyatt (1997) examines exploration strategies (PO)MDPs, learning automata(Narendra & Thathachar, 1974) probability matching (Duda, Hart, & Stork,2001) amongst others. particular, thesis discusses theoretical propertiesextension probability matching context multi-armed bandit problems.There, proposed choose lever according likely optimalshown strategy converges, thus providing simple method guidingexploration.Relative entropy criterion. usage minimum relative entropy criterionderive control laws underlies KL-control methods developed work Todorov(2006, 2009) Kappen et al. (2010). There, shown large classoptimal control problems solved efficiently problem statementreformulated minimization deviation dynamics controlledsystem uncontrolled system. related idea conceptualize planninginference problem (Toussaint, Harmeling, & Storkey, 2006). approach basedequivalence maximization expected future return likelihoodmaximization applicable MDPs POMDPs. Algorithms basedduality become active field current research. See example workRasmussen Deisenroth (2008), fast model-based RL techniquesused control continuous state action spaces.502fiA Minimum Relative Entropy Principle Learning Acting7. Conclusionswork introduces Bayesian control rule, Bayesian rule adaptive control.key feature rule special treatment actions based causal calculusdecomposition adaptive agent mixture operation modes, i.e. environmentspecific agents. rule derived minimizing expected relative entropytrue operation mode carefully distinguishing actions observations. Furthermore, Bayesian control rule turns exactly predictive distributionnext action given past interactions one would obtain using probabilitycausal calculus. Furthermore, shown agents constructed Bayesiancontrol rule converge true operation mode mild assumptions: boundedness,related ergodicity; consistency, demanding two indistinguishable hypotheses share policy.presented Bayesian control rule way solve adaptive control problemsbased minimum relative entropy principle. Thus, Bayesian control rule eitherregarded new principled approach adaptive control novel optimalitycriterion heuristic approximation traditional Bayes-optimal control. Sincetakes similar form Bayes rule, adaptive control problem could translatedon-line inference problem actions sampled stochastically posteriordistribution. important note, however, problem statement formulatedusual Bayes-optimal approach adaptive control same.future relationship two problem statements deserves investigation.Acknowledgmentsthank Marcus Hutter, David Wingate, Zoubin Ghahramani, Jose Aliste, Jose Donoso,Humberto Maturana anonymous reviewers comments earlier versionsmanuscript and/or inspiring discussions. thank Ministerio de Planificacion de Chile(MIDEPLAN) Bohringer-Ingelheim-Fonds (BIF) funding.Appendix A. ProofsA.1 Proof Theorem 1Proof. proof follows line argument solution Equation 3crucial differencetreated interventions. Consider without lossP actionsEquation 9. Note relative entropygenerality summand P (m)Cmwritten difference two logarithms, one term depends Pr varied.Therefore, one pull term write constant c. yieldscXP (m)Xao<tP (ao<t |m)X503P (at |m, ao<t ) ln Pr(at |ao<t ).fiOrtega & BraunSubstituting P (ao<t |m) P (m|ao<t )P (ao<t )/P (m) using Bayes rule rearrangement terms leadsXXX=cP (m|ao<t )P (ao<t )P (at |m, ao<t ) ln Pr(at |ao<t )ao<t=cXP (ao<t )Xao<tP (at |ao<t ) ln Pr(at |ao<t ).Pinner sum form x p(x) ln q(x), i.e. cross-entropy q(x) p(x),minimized q(x) = p(x) x. Let P denote optimum distributionPr. choosing optimum one obtains P(at |ao<t ) = P (at |ao<t ) . Notesolution variational problem Pindependent Pweighting P (ao<t ). Sinceargument applies summand P (m)CmP (m)Cm Equation 9,variational problems mutually independent. Hence,P(at |ao<t ) = P (at |ao<t )P(ot |ao<t ) = P (ot |ao<t )aot Z . P (at |ao<t ), introduce variable via marginalizationapply chain rule:XP (at |ao<t ) =P (at+1 |m, ao<t )P (m|ao<t ).term P (m|aot ) developedP (ao<t |m)P (m)P (ao<t |m )P (m )Qt1P (m) =1 P (a |m, ao< )P (o |m, ao< )=PQt1P (m )=1 P (a |m , ao< )P (o |m , ao< )Qt1P (m) =1 P (o |m, ao< ).=PQt1P (m )=1 P (o |m , ao< )P (m|ao<t ) = Pfirst equality obtained applying Bayes rule second using chainrule probabilities. get last equality, one applies interventions causalfactorization. Thus, P (a |m, ao< ) = 1 P (o |m, ao< ) = P (o |m, ao< ).equations characterizing P (ot |ao<t ) obtained similarly.A.2 Proof Theorem 2Proof. pointed (14), particular realization divergence processdt (m km) decomposedXdt (m km) =gm (m ; Tm ),gm (m ; Tm ) sub-divergences dt (m km) Tm form partition Nt .However, since dt (m km) bounded variation M, one > 0,C(m) 0, M, Nt Nt , inequalityfififififigm (m ; Tm ) Gm (m ; Tm )fi C(m)504fiA Minimum Relative Entropy Principle Learning Actingholds probability 1 . However, due (15),Gm (m ; Tm ) 0M. Thus,gm (m ; Tm ) C(m).previous inequalities hold simultaneously divergence processbounded well. is, inequalitydt (m km) C(m)(22)holds probability (1 )M := |M|. Choose(m)(m) := max{0, ln PP(m) }.(m)Since 0 ln PP(mUsing) (m), added right hand side (22).definition dt (m km), taking exponential rearranging terms one obtainsP (m )=1(m)P (o |m , ao< ) eP (m)=1P (o |m, ao< )(m) := C(m) + (m) 0. Identifying posterior probabilitiesdividing sides normalizing constant yields inequalityP (m |aot ) e(m) P (m|aot ).2inequality holds simultaneously probability (1 )Mparticular := minm {e(m) }, is,P (m |aot ) P (m|aot ).since valid M, maxm {P (m|aot )}P (m |aot )1M,one gets,probability1 arbitrary > 0 related equation :=M211 .A.3 Proof Theorem 3Proof. divergence process dt (m km) decomposed sum sub-divergences(see Equation 14)Xgm (m; Tm ).(23)dt (m km) =Furthermore, everyM, one > 0, C 0,N Ntfififififigm (m; ) Gm (m; )fi C(m)505fiOrtega & Braunprobability 1 . Applying bound summands (23) yields lowerboundXXgm (m; Tm )Gm (m; Tm ) C(m)(1 )M ,holds probability:= |M|. Due Inequality 15, one6= , Gm (m; Tm ) 0. Hence,XGm (m; Tm ) C(m) Gm (m; Tm ) CC := maxm {C(m)}. members set Tm determined stochastically;specifically, ith member included Tm probability P (m |aoi ) /M> 0 Theorem 2. since/ [m ], one Gm (m; Tm )probability 1 arbitrarily chosen > 0. implieslim dt (m km) lim Gm (m; Tm ) Cprobability 1 , > 0 arbitrary related = 1 (1 )M +1 .Using result upper bound posterior probabilities yields final resultP (m) dt (m km)e= 0.P (m )0 lim P (m|aot ) limA.4 Proof Theorem 4Proof. use abbreviations pm (t) := P (at |m, ao<t ) wm (t) := P (m|ao<t ).Decompose P (at |ao<t )XXpm (t)wm (t) +pm (t)wm (t).(24)P (at |ao<t ) =m[m/ ]m[m ]first sum right-hand side lower-bounded zero upper-boundedXXpm (t)wm (t)wm (t)m[m/ ]m[m/ ]pm (t) 1. Due Theorem 3, wm (t) 0 almost surely. Given > 0> 0, let t0 (m) time t0 (m), wm (t) < . Choosingt0 := maxm {t0 (m)}, previous inequality holds t0 simultaneouslyprobability (1 )M . Hence,XXpm (t)wm (t)wm (t) < .(25)m[m/ ]m[m/ ]bound second sum (24) one proceeds follows. every member [m ],one pm (t) pm (t) . Hence, following similar construction above,one choose t0 t0 [m ], inequalitiesfififififipm (t) pm (t)fi <506fiA Minimum Relative Entropy Principle Learning Actinghold simultaneously precision > 0. Applying second sum Equation 24yields boundsXXXpm (t) + wm (t).pm (t)wm (t)pm (t) wm (t)m[m ]m[m ]pm (t)m[m ]multiplicative constants placed front sum. Note1Xm[m ]wm (t) = 1Xm[m/ ]wm (t) > 1 .Use inequalities allows simplifying lower upper bounds respectively:Xpm (t)wm (t) > pm (t)(1 ) pm (t) 2 ,m[m ]pm (t) +Xm[m ](26)wm (t) pm (t) + < pm (t) + 2 .Combining inequalities (25) (26) (24) yields final result:fifififiP(a|ao(t))pfifi < (2 + ) = ,<tholds probability 1 arbitrary > 0 related = 1arbitrary precision .1A.5 Gibbs Sampling Implementation MDP AgentInserting likelihood given Equation 19 Equation 13 Bayesian control rule,one obtains following expression posteriorP (m|at , ot ) ==P (x |m, x, a)P (r|m, x, a, x )P (m|a<t , o<t )P (x |m , x, a)P (r|m , x, a, x )P (m |a<t , o<t ) dmP (r|m, x, a, x )P (m|a<t , o<t )R,P (r|m , x, a, x )P (m |a<t , o<t ) dmR(27)replaced sum integration , finite-dimensional real spacecontaining average reward Q-values observed states,simplified term P (x |m, x, a) constant M.likelihood model P (r|m , x, a, x ) Equation 27 encodes set independent normal distributions immediate reward means (x, a, x ) indexed triples(x, a, x ) X X . words, given (x, a, x ), rewards drawnnormal distribution unknown mean (x, a, x ) known variance 2 . sufficient statistics given n(x, a, x ), number times transition x xaction a, r(x, a, x ), mean rewards obtained transition.conjugate prior distribution well known given normal distributionhyperparameters 0 0 :rn200.(28)exp 2 (x, a, x ) 0P (m (x, a, x )) = N(0 , 1/0 ) =2507fiOrtega & Braunposterior distribution givenP (m (x, a, x )|at , ot ) = N((x, a, x ), 1/(x, a, x ))posterior hyperparameters computed0 0 + p n(x, a, x ) r(x, a, x )0 + p n(x, a, x )(x, a, x ) = 0 + p n(x, a, x ).(x, a, x ) =(29)introducing shorthand V (x) := maxa Q(x, a), write posterior distributionP (|at , ot ) = N(, 1/S)(30)=1 X(x, a, x )((x, a, x ) Q(x, a) + V (x )),x,a,xXS=(x, a, x ).x,a,xposterior distribution Q-values difficult obtain,Q(x, a) enters posterior distribution linearly non-linearly . However,fix Q(x, a) within max operations, amounts treating V (x)constant within single Gibbs step, conditional distribution approximatedP (Q(x, a)|at , ot ) N Q(x, a), 1/S(x, a)(31)Q(x, a) =X1(x, a, x )((x, a, x ) + V (x )),S(x, a)xX(x, a, x ).S(x, a) =xexpect approximation hold resulting update rule constitutes contraction operation forms basis stochastic approximation algorithms (Mahadevan, 1996). result, Gibbs sampler draws values normal distributions. cycle adaptive controller, one carry several Gibbs sweepsobtain sample improve mixing Markov chain. However, experimentalresults shown single Gibbs sweep per state transition performs reasonably well.new parameter vector drawn, Bayesian control rule proceeds takingoptimal action given Equation 20. Note entries transitionsoccurred need represented explicitly; similarly, Q-values visitedstates need represented explicitly.508fiA Minimum Relative Entropy Principle Learning ActingReferencesAuer, P., CesaBianchi, N., & Fischer, P. (2002). Finite-time analysis multiarmedbandit problem. Machine Learning, 47, 235256.Bertsekas, D. (1987). Dynamic Programming: Deterministic Stochastic Models.Prentice-Hall, Upper Saddle River, NJ.Bishop, C. M. (2006). Pattern Recognition Machine Learning. Springer.Braun, D. A., & Ortega, P. A. (2010). minimum relative entropy principle adaptivecontrol linear quadratic regulators. 7th conference informatics control,automation robotics, Vol. 3, pp. 103108.Cesa-Bianchi, N., & Lugosi, G. (2006). Prediction, Learning Games. Cambridge University Press.Dawid, A. P. (2010). Beware DAG!. Journal Machine Learning Research, (toappear).Dearden, R., Friedman, N., & Andre, D. (1999). Model based bayesian exploration.Proceedings Fifteenth Conference Uncertainty Artificial Intelligence, pp.150159.Dearden, R., Friedman, N., & Russell, S. (1998). Bayesian q-learning. AAAI98/IAAI 98: Proceedings fifteenth national/tenth conference Artificial intelligence/Innovative applications artificial intelligence, pp. 761768. American Association Artificial Intelligence.Duda, R. O., Hart, P. E., & Stork, D. G. (2001). Pattern Classification (Second edition).Wiley & Sons, Inc.Duff, M. O. (2002). Optimal learning: computational procedures bayes-adaptive markovdecision processes. Ph.D. thesis. Director-Andrew Barto.Grunwald, P. (2007). Minimum Description Length Principle. MIT Press.Haruno, M., Wolpert, D., & Kawato, M. (2001). Mosaic model sensorimotor learningcontrol. Neural Computation, 13, 22012220.Haussler, D., & Opper, M. (1997). Mutual information, metric entropy cumulativerelative entropy risk. Annals Statistics, 25, 24512492.Hutter, M. (2002). Self-optimizing pareto-optimal policies general environmentsbased bayes-mixtures. COLT.Hutter, M. (2003). Optimality universal Bayesian prediction general loss alphabet.Journal Machine Learning Research, 4, 971997.Hutter, M. (2004a). Online prediction bayes versus experts. Tech. rep.. PresentedEU PASCAL Workshop Learning Theoretic Bayesian Inductive Principles(LTBIP-2004).Hutter, M. (2004b). Universal Artificial Intelligence: Sequential Decisions based Algorithmic Probability. Springer, Berlin.509fiOrtega & BraunKappen, B., Gomez, V., & Opper, M. (2010). Optimal control graphical model inferenceproblem. JMLR (to appear).MacKay, D. J. C. (2003). Information Theory, Inference, Learning Algorithms. Cambridge University Press.Mahadevan, S. (1996). Average reward reinforcement learning: Foundations, algorithms,empirical results. Machine Learning, 22 (1-3), 159195.Mahoney, M. V. (1999). Text compression test artificial intelligence. AAAI/IAAI,pp. 486502.Narendra, K., & Thathachar, M. A. L. (1974). Learning automata - survey. IEEETransactions Systems, Man, Cybernetics, SMC-4 (4), 323334.Nozick, R. (1969). Newcombs problem two principles choice. Rescher, N. (Ed.),Essays Honor Carl G. Hempel, pp. 114146. Reidel.Opper, M. (1998). bayesian approach online learning. Online Learning NeuralNetworks, 363378.Ortega, P. A., & Braun, D. A. (2010). bayesian rule adaptive control based causalinterventions. third conference artificial general intelligence, pp. 121126.Pearl, J. (2000). Causality: Models, Reasoning, Inference. Cambridge University Press,Cambridge, UK.Poland, J., & Hutter, M. (2005). Defensive universal learning experts. ALT.Rasmussen, C. E., & Deisenroth, M. P. (2008). Recent Advances Reinforcement Learning,Vol. 5323 Lecture Notes Computer Science, LNAI, chap. Probabilistic InferenceFast Learning Control, pp. 229242. Springer-Verlag.Robbins, H. (1952). aspects sequential design experiments. Bulletin AmericanMathematical Socierty, 58, 527535.Russell, S., & Norvig, P. (2010). Artificial Intelligence: Modern Approach (3rd edition).Prentice-Hall.Schmidhuber, J. (2009). Simple algorithmic theory subjective beauty, novelty, surprise,interestingness, attention, curiosity, creativity, art, science, music, jokes. JournalSICE, 48 (1), 2132.Shafer, G. (1996). art causal conjecture. MIT Press.Singh, S. P. (1994). Reinforcement learning algorithms average-payoff markovian decisionprocesses. National Conference Artificial Intelligence, pp. 700705.Spirtes, P., Glymour, C., & Scheines, R. (2000). Causation, Prediction Search (2ndedition). Springer-Verlag, New York.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, MA.Todorov, E. (2006). Linearly solvable markov decision problems. Advances NeuralInformation Processing Systems, Vol. 19, pp. 13691376.510fiA Minimum Relative Entropy Principle Learning ActingTodorov, E. (2009). Efficient computation optimal actions. Proceedings NationalAcademy Sciences U.S.A., 106, 1147811483.Toussaint, M., Harmeling, S., & Storkey, A. (2006). Probabilistic inference solving(po)mdps. Tech. rep. EDI-INF-RR-0934, University Edinburgh.Watkins, C. (1989). Learning Delayed Rewards. Ph.D. thesis, University Cambridge,Cambridge, England.Wyatt, J. (1997). Exploration Inference Learning Reinforcement. Ph.D. thesis,Department Artificial Intelligence, University Edinburgh.511fiJournal Artificial Intelligence Research 38 (2010) 307-338Submitted 01/10; published 06/10Fast Set Bounds Propagation Using BDD-SAT HybridGraeme GangePeter J. Stuckeyggange@csse.unimelb.edu.aupjs@csse.unimelb.edu.auNational ICT Australia, Victoria LaboratoryDepartment Computer Science Software EngineeringUniversity Melbourne, Vic. 3010, AustraliaVitaly Lagoonlagoon@cadence.comCadence Design Systems270 Billerica Rd, Chelmsford, 01824, USAAbstractBinary Decision Diagram (BDD) based set bounds propagation powerful approachsolving set-constraint satisfaction problems. However, prior BDD based techniques incur significant overhead constructing manipulating graphs search.present set-constraint solver combines BDD-based set-bounds propagatorslearning abilities modern SAT solver. Together number improvementsbeyond basic algorithm, solver highly competitive existing propagationbased set constraint solvers.1. Introductionoften convenient model constraint satisfaction problem (CSP) using finite setvariables set relationships them. common approach solving finite domainCSPs using combination backtracking search constraint propagation algorithm.propagation algorithm attempts enforce consistency values domainsconstraint variables removing values domains variables cannotform part complete solution system constraints. common levelconsistency set bounds consistency (Gervet, 1997) solver keeps trackset elements definitely set. Many solvers use set boundsconsistency including ECLiPSe (IC-PARC, 2003), Gecode (GECODE, 2008), ILOGSOLVER (ILOG, 2004).Set bounds propagation supported solvers since stronger notions propagationdomain propagation require representing exponentially large domains possiblevalues. However, Lagoon Stuckey (2004) demonstrated possible use reducedordered binary decision diagrams (BDDs) compact representation set domainsset constraints, thus permitting set domain propagation. domain propagatorensures every value domain set variable extended completeassignment variables constraint. use BDD representation comesseveral additional benefits. ability easily conjoin existentially quantifyBDDs allows removal intermediate variables, thus strengthening propagation,also makes construction propagators global constraints straightforward.Given natural way BDDs used model set constraint problems,therefore worthwhile utilising BDDs construct types set solver. Indeedc2010AI Access Foundation. rights reserved.fiGange, Stuckey, & Lagoonpreviously demonstrated (Hawkins, Lagoon, & Stuckey, 2004, 2005) setbounds propagation efficiently implemented using BDDs represent constraintsdomains variables. major benefit BDD-based approach freesus need laboriously construct set bounds propagators new constrainthand. Moreover, correctness optimality BDD-based propagators followconstruction. advantages BDD-based representation identified stillapply, resulting solver performs favourably compared existing setbounds solvers.set bounds propagation using BDDs still constructs BDDs propagation,considerable overhead. paper show perform BDD-basedset bounds propagation using marking algorithm perform linear scans BDDrepresentation constraint without constructing new BDDs. resulting set boundspropagators substantially faster using BDDs.contributions paper are:Efficient set bounds propagators: new BDDs constructed propagation, fast.Graph reuse: reuse single BDD multiple copies constraint,hence handle larger problems.Ordering flexibility: restricted single global ordering Booleansconstructing BDDs.Filtering: keep track parts set variable really makedifference, reduce amount propagation.Pure set-bounds propagation tends perform badly, however, problems largenumber similar regions search space must explored. therefore embedset-bounds propagators MiniSAT (Een & Sorensson, 2003), provide SAT-style clauselearning.next section, introduce propagation-based solving set problems, brieflydiscuss SAT solving. Section 3 discuss binary decision diagrams (BDDs)implement set bounds propagation using BDDs. Section 4, presentpropagation algorithm used hybrid solver, together number variationsupon standard algorithm. Section 5, show incorporate reason generationBDD propagation build hybrid solver Section 6 test performancesolver variety set-constraint problems, compare set-constraintsolvers. Section 7 discuss related work, concluding Section 8.2. Propagation-based SolvingPropagation based approaches solving set constraint problems represent problemusing domain storing possible values set variable, propagatorsconstraint, remove values domain variable inconsistent values variables. Propagation combined backtracking search find solutions.308fiFast Set Bounds Propagation Using BDD-Sat Hybriddomain complete mapping fixed finite set variables V finitecollections finite sets integers. domain variable v set D(v). domainD1 said stronger domain D2 , written D1 D2 , D1 (v) D2 (v)v V. domain D1 equal domain D2 , written D1 = D2 ,V D1 (v) = D2 (v)variables v V. domain interpreted constraint vV v D(v).set constraints often interested restricting variables take convexdomains. set sets K convex a, b K c b implies c K. useinterval notation [a, b] b represent (minimal) convex set K includingb. finite collection sets K = {a1 , a2 , . . . , }, define convex closureK: conv (K) = [aK a, aK a]. extend concept convex closure domainsdefining ran(D) domain ran(D)(v) = conv (D(v)) v V.valuation set mappings set variables V sets integer values,written {v1 7 d1 , . . . , vn 7 dn }. valuation extended apply constraintsinvolving variables obvious way. Let vars function returns setvariables appearing expression, constraint valuation. abuse notation,say valuation element domain D, written D, (vi ) D(vi )vi vars().2.1 Constraints, Propagators Propagationconstraint restriction placed allowable values set variables. shalluse primitive set constraints (membership) k v, (equality) u = v, (subset) u w,(union) u = v w, (intersection) u = v w, (cardinality) |v| = k, (upper cardinality bound)|v| k, (lexicographic order) u < v, u, v, w set variables, k integer.also construct complicated constraints (possibly existentially quantified)conjunctions primitive set constraints. define solutions constraint cset valuations vars(c) make constraint true.associate propagator every constraint. propagator f monotonicallydecreasing function domains domains, D1 D2 implies f (D1 ) f (D2 ),f (D) D. propagator f correct constraint c domainsD: { | D} solns(c) = { | f (D)} solns(c)propagation solver solv (F, D) set propagators F domain repeatedly applies propagators F starting domain fixpoint reached.solv (F, D) weakest domain f (D ) = f F .Example 1 small example set-constraint problem would to, given universeconsisting elements {1, 2, 3, 4}, find values variables x, y, z z = x y,|x| = 3, |y| = 3, |z| = 2, 3/ z, 1 z 2/ y.unique solution problem = {x 7 {1, 2, 4}, 7 {1, 3, 4}, z 7 {1, 4}}.2.2 Set Bounds Consistencydomain (set) bounds consistent constraint c every variable v vars(c)upper bound D(v) union values v solutions c D,lower bound D(v) intersection values v solutions c D.309fiGange, Stuckey, & Lagoondefine set bounds propagator constraint c({i | solns(D c) (v)} v vars(c)ub(c)(D)(v) =ub(v)otherwiselb(c)(D)(v) =({i | solns(D c) (v)}lb(v)v vars(c)otherwisesb(c)(D)(v) = [lb(c)(D)(v), ub(c)(D)(v)]sb(c)(D) always bounds consistent c.Example 2 Continuing example previous section, initial boundsvariables x, y, z D(x) = D(y) = D(z) = [, {1, 2, 3, 4}], values explicitlyincluded excluded domains. first 3/ z added, 1 z finally2/ y, bounds reduced, consequences changes propagatedamong variables follows:PropagatorD(x)D(y)D(z)[, {1, 2, 3, 4}][, {1, 2, 3, 4}][, {1, 2, 3, 4}]3/z[, {1, 2, 3, 4}][, {1, 2, 3, 4}][, {1, 2, 4}]1z[, {1, 2, 3, 4}][, {1, 2, 3, 4}][{1}, {1, 2, 4}]z =xy[{1}, {1, 2, 3, 4}][{1}, {1, 2, 3, 4}][{1}, {1, 2, 4}]2/y[{1}, {1, 2, 3, 4}][{1}, {1, 3, 4}][{1}, {1, 2, 4}]|y| = 3[{1}, {1, 2, 3, 4}][{1, 3, 4}, {1, 3, 4}] [{1}, {1, 2, 4}]z =xy[{1}, {1, 2, 4}][{1, 3, 4}, {1, 3, 4}][{1}, {1, 4}]|z| = 2[{1}, {1, 2, 4}][{1, 3, 4}, {1, 3, 4}] [{1, 4}, {1, 4}]|x| = 3[{1, 2, 4}, {1, 2, 4}] [{1, 3, 4}, {1, 3, 4}] [{1, 4}, {1, 4}]1 z fixed, 1 added lb(z). Since z = x y, element lb(z) mustalso lb(x) lb(y). 2/ set, |ub(y)| = 3 since |ub(y)| |y| = 3means = ub(y) = {1, 3, 4}. means 2/ z since z = x y. Since 3/ ub(z),least one x must contain 3. 3 lb(y) set, determined3/ ub(x). Since |ub(z)| = 2 forces z = ub(z) = {1, 4}. Finally constraint|x| = 3 results value x becoming fixed. corresponding valuation= {x 7 {1, 2, 4}, 7 {1, 3, 4}, z 7 {1, 4}}, solution provided Example 1.2.3 Boolean Satisfiability (SAT)Boolean Satisfiability SAT solvers special case propagation-based solvers, restricted Boolean variables clause constraints.Davis-Putnam-Logemann-Loveland (DPLL) algorithm (Davis, Logemann, & Loveland, 1962), modern SAT solvers based, also propagation-basedapproach solving SAT problems. interleaves two phases search, unfixedvariable assigned value, propagation (so called unit propagation).Modern SAT solvers incorporate sophisticated engineering propagate constraintsfast, record nogoods part search lead failure, automate search310fiFast Set Bounds Propagation Using BDD-Sat HybridSAT EngineSearchconflictanalysisunit propagationClause DatabaseFigure 1: Architecture SAT solver.keeping track often variable part reason causing failure (activity)concentrating search variables high activity. Modern SAT solvers also frequentlyrestart search scratch relying nogoods recording prevent repeated search,activity drive search profitable areas. See e.g., report EenSorensson (2003) good introduction modern SAT solving.rough architecture modern SAT solver illustrated Figure 1. Search startsunit propagation process interacts clause database may detect failure,initiates conflict analysis. Unit propagation records literal madetrue, clause explains literal become true. Conflict analysis uses graphexplanations construct nogood resolvent clauses causing failureadds strength unit propagation. stored clause databasecauses search backjump. prevents search revisiting set decisions.detailed activity counters record variables responsiblefailure, variables chosen labelling search.3. Binary Decision Diagramsassume set B Boolean variables total ordering . Boolean variabletake value 0 (false) 1 (true). make use following Boolean operations:(conjunction), (disjunction), (negation), (implication), (bi-implication)(existential quantification). denote V F formula x1 xn F V =V F mean V F V = vars(F ) \ V .{x1 , . . . , xn },Reduced Ordered Binary Decision Diagrams well-known method representingBoolean functions Boolean variables using directed acyclic graphs single root.Every internal node n(v, f, t) BDD r labelled Boolean variable v B,two outgoing arcs false arc (to BDD f ) true arc (to BDD t). Leafnodes either F (false) (true). node represents single test labelledvariable; traversing tree appropriate arc followed depending value311fiGange, Stuckey, & Lagoon76540123v3 EEE"76540123v4|76540123v5|76540123v6 EEE"76540123v7 DDD!" }rF76540123x1 FFF|"7654012376540123x2 Fx2 FFFFF" |"|765401237654012376540123x3 Fx3x3 FFFFF"7654"||012376540123x4 Fx4FF"7654|0123x5 EEE"}" |(a)F(b)Figure 2: BDDs (a) v3 v4 v5 v6 v7 . (b) x1 + x2 + x3 + x4 + x5 2. noden(v, f, t) shown circle labelled v dotted arc f BDD, solid arcBDD.variable. Define size |r| number internal nodes BDD r, VAR(r)set variables v B appearing internal node r.Reduced Ordered Binary Decision Diagrams (BDDs) (Bryant, 1986) requireBDD is: reduced, contains identical nodes (nodes variable labelidentical true false arcs) redundant tests (no node truefalse arcs leading node); ordered, arc node labelledv1 node labelled v2 v1 v2 . BDD nice property functionrepresentation canonical variable reordering. permits efficient implementationsmany Boolean operations.Boolean variable v said fixed BDD r either every node n(v, f, t) rconstant F node, every node n(v, f, t) f constant F node. variablesidentified linear time scan domain BDD (see e.g., Hawkins et al.,2005). convenience, BDD, write JK denote BDD representingconjunction fixed variables .Example 3 Figure 2(a) gives example BDD representing formula v3 v4v5 v6 v7 . Figure 2(b) gives example complex BDD representing formulax1 + x2 + x3 + x4 + x5 2 interpret Booleans 0-1 integers. One verifyvaluation {x1 7 1, x2 7 0, x3 7 1, x4 7 0, x5 7 0} makes formula truefollowing path right, left, right, left, left root.3.1 Set Propagation using BDDskey step building set propagation using BDDs realize representfinite set domain using BDD.3.1.1 Representing domainsv set variable ranging subsets {1, . . . , N }, represent v usingBoolean variables V (v) = {v1 , . . . , vN } B, vi true iff v. order312fiFast Set Bounds Propagation Using BDD-Sat Hybridvariables v1 v2 vN . represent valuation using formulaR() =^vvars()^^vii(v)i{1,...,N }(v)vi .Wdomain variable v, D(v) represented = aD(v) R({v 7 a}).formula represented BDD. set bounds v obtained extractingfixed variables BDD, JK.example valuation Example 1 represented formula R():x1 x2 x3 x4 y1 y2 y3 y4 z1 z2 z3 z4 .domain D(v) = [{3, 6, 7}, {1, 2, 3, 6, 7, 8, 9}] represented BDD Figure 2(a) since v3 , v6 v7 true 3, 6, 7 definitely set, v4 v5false 4 5 definitely set.3.1.2 Representing constraintssimilarly model set constraint c BDD B(c) using Boolean variablerepresentation V (v) set variables v. ordering variables BDD carefullybuild small representations formulae. pointwise order Boolean variablesdefined follows. Given set variables u v w ranging sets {1, . . . , N }order Boolean variables u1 v1 w1 u2 v2 w2 uN vN wN .representation B(c) simply solns(c) R(). primitive set constraints (usingpointwise order) size linear N . details see work Hawkins et al.(2005). BDD representation |x| 2 shown Figure 2(b), N = 5.3.1.3 BDD-based Set Bounds Propagationbuild set bounds propagator, less definition, since BDDsrepresent domains constraints.= B(c)^D(v )v vars(c)sb(c)(D)(v) = V (v) JKsimply conjoin domains constraint obtaining , extract fixed variablesresult, project relevant part variable v. set boundspropagation improved removing fixed variables soon possible.improved definition given Hawkins et al. (2004). Overall complexity madeO(|B(c)|).updated set bounds used simplify BDD representing propagator.Since fixed variables never interact propagation projectedB(c), replace B(c) VAR(JK) .313fiGange, Stuckey, & Lagoonbdd2sat(node) {switch node {F: return (0, {}) ;: return (1, {});n(v, f, t):(visit[node] 6= ) return(visit[node],{});let n new Boolean variable;visit[node] = n ;(f , Cf ) = bdd2sat(f );(t , Ct ) = bdd2sat(t);return (n , {v n , v f n , v n , v f n ,f n , f n } Cf Ct );}}Figure 3: Pseudo-code Tseitin transformation BDD rooted node nBoolean variable encoding truth value node.3.2 Tseitin Transformationpossible convert Boolean circuit pure SAT representation; methodgenerally attributed Tseitin (1968). Figure 3 gives pseudo codetranslation BDD rooted node, returning pair (Boolean variable, set clauses).clauses enforce Boolean variable takes truth value BDD. LikeBDD algorithms relies marking visited nodes ensure node visitedonce. assumes array visit[] initially bottom , first visiting nodestores corresponding Boolean variable visit[]. comprehensive discussionTseitin transformation presented Een Sorensson (2006).constraint enforced fixing variable corresponding root nodetrue. advantage replacing BDD Tseitin representation useunmodified SAT solver tackle BDD-based set constraint problems. shall seeSection 6 approach cannot compete handling BDDs directly.4. Faster Set-bounds Propagationset bounds propagation using BDDs much faster set domain propagationoften better set domain propagation (or variations propagation sets)still creates new BDDs. necessary long prepared givesimplifying BDDs possible set bounds propagation.represent domains variables BDDs, rather arrays Booleandomains. domain array where, variable v ranging subsets {1, . . . , N }:0/ D[vi ] indicates v, 1/ D[vi ] indicates/ v. D[vi ] = {0, 1}, dont knowwhether v. Hence D(v) = [{i|0/ D[vi ]}, {i|1 D[vi ]}].BDD representation constraint B(c) built before. significant differencesince constraints communicate set bounds variables314fiFast Set Bounds Propagation Using BDD-Sat Hybridneed share global variable order hence necessary modify variableorder used construct B(c) c, use automatic variable reordering (whichavailable BDD packages) construct B(c). Another advantagereuse BDD constraint c(x) variables x constraint c(y) variables(as long range initial sets), is, constraint differentvariables. Hence build one BDD, rather one instanceconstraint.set bounds propagator sb(c(x)) constraint c(x) implemented follows.generic BDD representation r constraint c(y) constructed. propagator copiesdomain description actual parameters x1 , . . . , xn onto domain description Eformal parameters 1 , . . . , n . constructs array E E[yij ] = D[xji ]. LetV = {yij | 1 j n, 1 N } set Boolean variables occurringconstraint c(y). propagator executes code bddprop(r, V, E) shown Figures 45 returns (r , V , E ). r = F propagator returns false domain, otherwisepropagator copies back domains formal parameters actual parametersD[xji ] = E[yij ]. come back V argument next subsection.procedure bddprop(r, V, E) traverses BDD r follows. visit noden(v, f, t) BDD top-down memoing manner. record if, currentdomain, node reach F node, reach node. f childreach node add support variable v taking value 0. Similarlychild reach add support variable v taking 1. node reachF record variable v matters computation BDD.visit reduce variable set propagator matter, remove valuessupport domain. procedure assumes global time variableincremented propagation, used memo marking phase.top(n, V ) function returns variable root node n largest variable (under) V n = n = F.presented bddprop time complexity O(|r| |V |) |r| number nodesappearing BDD r. practice complexity O(|r| + |V |) since |V | factor ariseshandling long arcs, node n(v, f, t) child node (f t) labelledBoolean different next order v. set constraints lengthlong arc typically bounded arity set constraint. possible createversion bddprop strictly O(|r|) careful handling long arcs. so,practice slower form presented here. bddprop space complexityO(|V | + |r|) first component maintaining domains variables secondmemoing BDD nodes.Example 4 Consider BDD constraint x = z N = 2 shown Figure 6(a). Assuming domain E E[y1 ] = {1} (1 y) E[z2 ] = {1} (2 z),remaining variables take value {0, 1}, algorithm traverses edges showndouble lines Figure 6(b). path x1 , x2 following f arc reaches hence 0added E [x1 ] E [x2 ]. result E[x1 ] E[x2 ] set {1}. Hencedetermined 1 x 2 x.Also, nodes z1 actually visited, left node y2 reaches Fright node reaches . Hence matters[z1 ] matters[y2 ] marked315fiGange, Stuckey, & Lagoonbddprop(r,V ,E) {(v V ) {E [v] = {};}(reachf , reacht ) = bddp(r, V, E);(reacht ) return (F, , E);vars = ;(v V ) {(E [v] 6= E[v]) {E[v] = E [v];}(E[v] = {0, 1} matters[v] time) vars = vars {v};}return (r, vars , E);}Figure 4: Pseudo-code BDD-propagation.current time. set vars collected bddprop empty, since remaining variablesfixed.4.1 Waking Less Oftenpractice bounds propagation solver blindly apply propagator fixpoint, keeps track propagators must still fixpoint, executesmay be. set bounds usually managed follows. setvariable v attached list propagators c involve v. Whenever v changes,propagators rescheduled execution.better BDD based propagators. algorithm bddpropcollects set Boolean variables matter BDD, change result.variable matter becomes fixed, set bounds propagation cannot learnnew information. modify wakeup process follows. propagator storeslist vars Boolean variables matter given current domain. Booleanvariable xji becomes fixed traverse list propagators involving xji wakepropagators xji occurs vars. executing propagator revise set varsstored propagator. Note optimization could applied standardapproach, requires overhead computing vars folded bddprop.possible instead propagator wake-up literals, rather variables.case, observe fixing variable v true matters node n(v, f, t) iff reachablef F reachable converse holds v. terms pseudo-codeFigure 5, line(reachf reacht ) matters[v] = time;may therefore replaced316fiFast Set Bounds Propagation Using BDD-Sat Hybridbddp(node,V ,E) {(in set(fset, node)) { return (1, 0)};switch node {F: return (1,0);: return (0,1);n(v, f, t):(visit[node] time) return save[node];reachf = 0; reacht = 0;(0 E[v]) {(rf0 , rt0 ) = bddp(f, V, E);reachf = reachf rf0 ;reacht = reacht rt0 ;(rt0 ) {(v V, v v top(f, V ))E [v ] = E[v ];E [v] = E [v] 0;}}(1 E[v]) {(rf1 , rt1 ) = bddp(t, V, E);reachf = reachf rf1 ;reacht = reacht rt1 ;(rt1 ) {(v V, v v top(t, V ))E [v ] = E[v ];E [v] = E [v] 1;}}(reachf reacht ) matters[v] = time;save[node] = (reachf , reacht ); (reacht) { insert(fset, node) };visit[node] = time;return (reachf , reacht );}}Figure 5: Pseudo-code processing constraint graph propagation. Modifications necessary using dead-subgraph memoization shown right.(rt0 rf 1) matters[v] = time;(rt1 rf 0) matters[v] = time;allows propagators wake less frequently, propagator execution slowerdue keeping track additional reachability information.317fiGange, Stuckey, & Lagoon76540123x1 CCCCCC!76540123y10123z7654{ 1{{{! }{{76540123x2 CCCCCC!76540123y276540123z2{{{{! }{{}76540123y176540123z1}76540123276540123z|| 2|ff ~|vt |F(a)76540123x1CCCCCCCCCCCC %76540123y17654z10123{{{{!}{{76540123x2CCCCCCCCCCCC %76540123y2ff76540123{{{z2{{{{!{{{76540123y176540123z1765401232ff76540123z|||| 2|||ffzvt |||F(b)Figure 6: (a) BDD representing x = z N = 2. (b) edges traversedbddprop, E[y1 ] = {1} E[z2 ] = {1} E[v] = {0, 1} otherwise, showndoubled.4.2 Dead Subgraph Memoization Shortcuttingalgorithm presented always explores reachable parts graph orderdetermine set supported values. However, number improvements MultiDecision Diagrams (MDDs) presented Cheng Yap (2008) reduceportion graph must traversed order enforce consistency. deadsubgraph memoization, avoids traversal subgraphs cannot provide supportvalues, shortcutting, recognizes situations necessaryfind one path ensure consistency. readily adapted BDD-basedset constraint solver.4.2.1 Dead Subgraph Memoizationkey observation dead subgraph memoization that, search progresses, pathsalong graph ever removed. such, becomes unreachablenode n, subgraph incident n need never explored solverbacktracks. Thus, set dead nodes maintained, possible progressivelyeliminate subgraphs propagation.keep instance constraint c(x) failure set, fset recordsnodes reach (and hence equivalent F). propagation, node nshown path , added failure set fset. node processed,first check fsetif so, terminate early, otherwise proceed normal.modifications necessary shown right Figure 5. simplicitypseudo-code treats fset global.method efficiently maintaining failure sets presented Cheng Yap(2008), uses sparse-set data structures provide efficient lookup, insertion backtracking. set fset maintained pair arrays: sparse dense counter318fiFast Set Bounds Propagation Using BDD-Sat Hybridinsert(S, n) {S.sparse[n] = S.membersS.dense[S.members] = nS.members++}set(S, n) {index = S.sparse[n]return index < S.membersS.dense[index] == n}(a) Sparse set operationsinsert(S, n) {old index = S.sparse[n]swap value = S.dense[S.members]S.sparse[n] = S.membersS.dense[S.members] = nS.sparse[swap value] = old indexS.dense[old index] = swap valueS.members++}set(S, n) {return S.sparse[n] < S.members}(b) Modified sparse-set operationsFigure 7: Pseudo-code conventional sparse-set operations, corresponding modified versions.members. n fset sparse[n] < members dense[sparse[n]] = n. operationsinsertion testing shown Figure 7(a). Crucially backtrack earlier formsset simply resetting members value time.structures improved slightly observation checking membershipoccur significantly often insertion. Pseudo-code modified sparse-setoperations given Figure 7(b). insertion operations become expensive,overall computation time reduced.Example 5 Consider set illustrated Figure 8(a). elements set {1, 7}.determine element 4 set S0 , sparse[4] strictly lessmembers, indicated arrow Figure 8(a).insert element v using standard sparse-set operations, merely overwritedense[members] v, set value sparse[v] members. shownFigure 8(b), inserting 3 S0 . point, sparse[3] sparse[4] value2. test 4 S0 , sufficient determine sparse[4] < members. One must alsocheck dense[sparse [4]] = 4.inserting v using modified operations, illustrated Figure 8(c), swapvalues sparse[v] sparse [dense[members]], likewise switch valuesdense[members] dense[sparse [v]]. maintains property v sparse[v] <members.319fiGange, Stuckey, & Lagoon0sparsedense1201734625607sparse1410dense3217342232567133(a) S0 = {1, 7}(b) S0 {3}0sparsedense1201734263567143(c) S0 {3} using modified operationsFigure 8: sparse representation sets. (a) possible state data structure representing S0 = {1, 7}. (b) Inserting 3 data structure using standard operations.sparse [3] updated point next element dense, corresponding entrydense points back 3. Notably, sparse [3] sparse [4] point dense[2]. (c)Inserting 3 data structure using modified operations. operation,sparse dense arrays maintained v dense[sparse[v]] = v.Dead subgraph memoization comes space cost O(|r|) store failure setf set. reduces time complexity bddprop O((|r||f set|)|V |) O(|r||f set|+|V |) practice.4.2.2 ShortcuttingShortcutting optimization propagation BDD notices valuescurrent domains variables vi , vi+1 , , vN fully supported,need examine rest nodes involving variables. keep high water markhwater shows least variable whose values supported. ever reachnode numbered high water mark need prove reaches ,need fully explore sub-graph it.modified propagation algorithm taking account shortcutting (and dead subgraphminimization) given Figures 9 10. high water mark hwater originally largergreatest variable appearing BDD.principle difference imp bddp reach node variablehigh water mark use simplified form shortcut bddp checks whethernode reach . complexity update high water mark hwaterfind values v supported (E[v] = E [v]). shortcut bddp carefulmark variables nodes visited reach mattering propagator.320fiFast Set Bounds Propagation Using BDD-Sat Hybridimp bddp(node,V ,E) {(in set(fset, node)) return (1, 0);switch node {F : return (1,0);: return (0,1);n(v, f, t):(visit[node] time) return save[node];(v hwater) return shortcut bddp(node, V, E);reachf = 0; reacht = 0; maxvar = v;(0 E[v]) {(rf0 , rt0 ) = imp bddp(f, V, E);reachf = rf0 ; reacht = rt0 ;(rt0 ) {maxvar = top(f, V );E [v] = E [v] 0;(hwater top(f, V ) E [v] == E[v]) {hwater = v;reachf = 1;goto cleanup;}}}(1 E[v]) {(rf1 , rt1 ) = imp bddp(t, V, E);reachf = reachf rf1 ; reacht = reacht rt1 ;(rt1 ) {maxvar = max(maxvar, top(t, V );E [v] = E [v] 1;(hwater top(t, V ) E [v] == E[v]) {hwater = v;}}}(reacht ):insert(fset, node);cleanup:(v V, v v maxvar)E [v] = E[v];(reachf reacht ) matters[v] = time;save[node] = (reachf , reacht );visit[node] = time;return (reachf , reacht );}}Figure 9: Pseudo-code processing constraint graph propagation, using deadsubgraph memoization shortcutting.Example 6 Consider BDD constraint |y z| = 1 N = 3 shownFigure 11(a). variables fixed, first explore false paths, findnode. provides complete support y2 , x3 , y3 , high-water mark updatedy2 . searching support x2 false, longer need find support anythingbeneath high-water mark need find single path true nodelabelled y2 . high water mark increases y1 . Likewise, finding supportx1 , everything point already supported, explore first path. edges explored shown doubled 11(b).Example 6 also illustrates impact shortcutting highly dependentorder branches searched, structure constraint321fiGange, Stuckey, & Lagoonshortcut bddp(node,V ,E) {(in set(fset, node)) return (1,0);switch node {: return (0,1);n(v, f, t):rf0 = 0;(visit[node] time) return save[node];(0 E[v]) {(rf0 , rt0 ) = shortcut bddp(f, V, E);(rt0 ) {(1 E[v]) { matters[v] = time; rf0 = 1; }visit[node] = time; save[node] = (rf0 , 1);return save[node];}}(1 E[v]) {(rf1 , rt1 ) = shortcut bddp(t, V, E);(rt1 ) {(rf0 ) { matters[v] = time; rf1 = 1; }visit[node] = time; save[node] = (rf1 , 1);return save[node];}}insert(fset, node);return (1, 0);}}Figure 10: Pseudo-code shortcut phase.explore true branches first, rather false branches, would need explorenodes find support variables. Clearly shortcutting change asymptotictime space complexity algorithm. Note shortcutting BDDs complexapproach used Cheng Yap (2008) since treat long arcsMDDs.5. Hybrid SAT SolverDespite fast propagation, pure set bounds-based solver nevertheless suffersinability analyze reasons failure, results repeated exploration similardead subtrees. limits performance solver many hard problem instances.order address this, construct hybrid solver embeds BDD-based setbounds propagators within efficient SAT solver. Search conflict analysis per322fiFast Set Bounds Propagation Using BDD-Sat Hybrid76540123x1 CCCCCC!76540123y1 CCCCCC!}7654012376540123x2 Cx2 CCCCCCCCCC!C!7654012376540123y2 Cy2CCCCC! }76540123x3 CCCCCC!76540123y3}tff }t76540123x1CCCCCCCCCCCC %76540123y1 CCCCCC!ff7654012376540123x2 Cx2CCCCCCCCCCCCCCCC %C!7654012376540123y2 Cy2CCCCC! }76540123x3 CCCCCC!76540123y3F(a)F(b)Figure 11: (a) BDD representing |x y| 1 N = 3. node n(v, f, t) showncircle around v dotted arrow f full arrow t. (b) edges traversedimp bddp, E[v] = {0, 1} v, shown doubled.formed SAT solver, BDD propagators used generate inferencesclauses SAT solver use propagation.5.1 Efficient Reason GenerationKey successful SAT solver recording nogoods, small subsets currentvariable assignments independently result failure. allows similar subtreeseliminated consideration, hence significantly reducing search space.order construct nogoods, necessary explain reason literalset. order determine chain reasoning resulted contradiction.pure SAT solver easy, variable either decision variable, associatedclause caused propagation.BDD-based propagation methods, however, automatically provide explanationsinference. naive approach generating reason clause BDD inferenceenumerate fixed variables occur propagator, construct clausenegations:^_li l llili f ix(B)li f ix(B)Unfortunately, often results large reason clauses, particularly casemerged propagators global constraints. smaller clauses result stronger nogoodsgenerated SAT solver, preferable determine minimal set variablesrequired cause propagation, include variables clause.method constructing minimal clauses demonstrated HawkinsStuckey (2006), method involves constructing new BDDs, eliminating redundantvariables minimal BDD constructed, reading variables remaining323fiGange, Stuckey, & LagoonBDD. Given propagation algorithm herein avoids expensive BDD operations,wish use explanation.Given set assignments {l0 , . . . , lk } entail literal l respect constraintC, also true^liC li{0...k}result, problem finding minimal reason given inference BDDequivalent fixing l unfixing many variables possible without renderingreachable.algorithm presented Subbarayan (2008) provides method traversing static graph, avoiding need construct intermediate BDDs. algorithm,given Figure 12, traverses node n(v, f, t) top-down memoing manner.node, records if, given current domain, node reachable. variablev assigned value, also records reachable conflicting edge;edges must become relaxed, otherwise partial assignment longerconflict.graph traversed second time, time breadth-first manner.variable v, nodes reached corresponding v variable may relaxedwithout opening path , v unfixed. v remains fixed, v marked partreason, node corresponding value v marked reachable.Otherwise, v minimal reason, f nodes markedreached. procedure returns reason clause. procedure O(|r|) timespace complexity, note O(|r|) per new propagation explained!Example 7 Consider constraint assignments obtained Example 4. determined E[y1 ] = {1}E[z2 ] = {1} E[x2 ] = {1} (or equivalently, 1 y2 z 2 x).such, naive reason clause explain 2 x would y1 z2 x2 ; however,possible construct smaller clause this.order construct minimal reason E[x2 ] = {1}, first set E[x2 ] = {0}.corresponding graph shown Figure 13(a), nodes consistentpartial assignment shown doubled. Note solid edge x2 consistentassignment, reachable along doubled path root node.algorithm determines set nodes reachablenodes shown doubled Figure 13(b). nodes must remain unreachable alongfinal reason; such, nodes must remain fixed x2 node leftmostz2 node.Finally, algorithm progressively unfixes variables would providepath (in case, y1 ). final path shown Figure 13(c), resulting inferenceE[z2 ] = {1} E[x2 ] = {1}; corresponding reason clause x2 z2 .5.2 Lazy Reason Generationsimplest way use reason generation called eager generation, wheneverBDD propagator makes new inference, minimal reason clause generated added324fiFast Set Bounds Propagation Using BDD-Sat Hybridconstruct reason(r,V ,D,var,sign) {Let r = n(v, t, f )Dold = D[var];D[var] = {1 sign};forall (nodes n r) visit[n] :=mark reason(r,V,D);reached [v] = {r};(sign)mark reason(node,V ,D) {reason = var;(visit[node] 6= ) return visit[node];elseLet node = n(v, t, f )reason = var;reachhi = mark reason(t, V, D);(v V ) {reachlow = mark reason(f, V, D);fixedvar = false;reacht = false;(n reached[v ]) {(0 D[v])fixedvar = fixedvar fixed [n];reacht = reacht reachlow ;}else(fixedvar v 6= var) {fixed[node] = reachlow ;(0 D[v])(1 D[v])reason = reason v;reacht = reacht reachhi ;elseelsereason = reason v;fixed[node] = reachhi ;}visit[node]= reacht;(n(vn , fn , tn ) reached[v ]) {return reacht ;(fixedvar 1 D[v ])}reached[vn ] = reached[vn ] tn ;(fixedvar 0 D[v ])reached[vn ] = reached[vn ] fn ;}}D[var] = Dold ;return reason;}Figure 12: Pseudo-code reason generation algorithm Subbarayan (2008). Constructs minimal set variables required cause inference var = sign.SAT solver. clauses, however, cannot make meaningful contribution searchconflict detected cannot cause propagation solver backtracksbeyond fixed variable, conflict clauses constructed conflict.degree overhead adding maintaining large set clausessolver, may better delay constructing reasons actually requiredexplain conflict.instead apply reason generation SAT conflict analysis asksexplanation literal set BDD solver. call lazy generation.325fiGange, Stuckey, & Lagoon76540123x1CCCCCCCCCCCC %76540123y17654z10123{{{{{{{{%{{{{76540123x2 CCCCCC!76540123y2ff76540123{{{z2{{{{!{{{76540123y176540123z10123y27654ff76540123z2|||||||||zrzt |F76540123x1EEEEEEEEEEEE &76540123y1ffffffffffffffffffff 7654z1ffff 0123ffffffffxxxxxxxffffx% ffffx xxxx76540123x2 CCCCCC!@ABCGFED?>=<89:;y2ff@ABC?>=<89:;GFEDz2||||||||||76540123y176540123z1{76540123y2ff76540123z2ff{ s{tF(a)(b)w76540123y1ff76540123z1x7654y20123ffGFED?>=<89:;z2@ABC}}}}}}}zrzt }}}F76540123x1EEEEEEEEEEEE &76540123y1fifififififi fffifififi 7654z1fifi 0123fifififi{{{{{{{fifi{{& fifiy {{{@ABCGFED?>=<89:;x2 CCCCCC!76540123y201237654z|| 2||" }||(c)Figure 13: (a) BDD representing x = z N = 2, E[y1 ] = {1}, E[z2 ] = {1}E[x2 ] = {0}. Edges consistent partial assignment shown doubled. (b)Nodes must remain unreachable reason shown doubled. (c) Edges reachablealong minimal reason shown doubled, nodes remain fixed.order so, must determine state propagator caused inference.implement recording order literals become fixed propagator.generating reason variable v becoming fixed, look variablepropagator, unfix variable v time(v) time(v ), restorereason constructed.5.3 Hybrid Architecturehybrid SAT solver embeds BDD propagators inside SAT engine. architectureillustrated Figure 14. usual SAT engine architecture shown left. BDDpropagation added shown right. Unit propagation causes Boolean literalsfixed may require BDD propagators need awoken. attachBoolean variable representing part set variable x BDD propagators involvingset variable. unit propagation reaches fixpoint, trail fixed literals traversedBDD propagator includes one literals scheduled execution.using filtering, scheduled literal one matters propagator.execute scheduled BDD propagators using imp bddp. BDD propagatorfixes literals added trail unit propagation engine.using eager reason generation also immediately build clause explainingpropagation add clause database record clause reasonpropagation literal.using lazy reason generation, instead record reason simply pointerBDD propagator causes literal fixed. conflict analysis demandsexplanation literal, call reason generation BDD propagator, using326fiFast Set Bounds Propagation Using BDD-Sat HybridSAT EngineSearchBDD PropagatorFilteringconflictanalysisunitpropagationimp_bddpreasongenerationClause DatabaseFigure 14: Architecture hybrid BDD-SAT solver.state time literal fixed, build explaining clause.used conflict analysis. replace reason literal trail generatedexplanation clause also add explanation clause database.implementation inherits almost features underlying SAT solver. Eagerreason clauses added nogoods, deleted SAT solver decides eliminatenogoods, lazy reason clauses generated demand conflict analysis.added clause database even though necessary, since makes memoingexplanations already performed simpler. hybrid solver make userestarting activity based search, restarts, although also extend search capabilitiesallow simple static searches preferable set problems tackle.6. Experimental Resultsbuilt hybrid SAT solver implementing algorithms described above. solverbased MiniSAT 2.0 (dated 070721) (Een & Sorensson, 2003), modifiedinclude BDD-based propagation engine. BDDs constructed using BuDDyBDD package (http://sourceforge.net/projects/buddy/) BDDs constructedbeginning execution, converted static graph used propagation. Indeed,many smaller problems solved Section 6, majority solution timeused constructing BDDs.BDD propagators executed lower priority level unit propagation,order detect conflict early possible. Reason clauses generated setbounds propagator added SAT solver learnt clauses, otherwise numberclauses added solver propagation hard problems overwhelm solver.Experiments conducted 3.00GHz Core2 Duo 2 Gb RAM runningUbuntu GNU/Linux 8.10. problems terminated completed within 10 minutes.327fiGange, Stuckey, & Lagoonexperimented 3 classes set benchmarks: social golfers, Steiner systems,Hamming codes. Unless otherwise specified, hybrid solver always executed using lazyreason generation.compare Gecode 3.1.0 set bounds propagation solver since acknowledged one fastest solvers available, well ECLiPSE 6.0 #100. also compare published results Cardinal (Azevedo, 2007) Length-Lex (Yip &Van Hentenryck, 2009) solvers problems.6.1 Social Golferscommon set benchmark Social Golfers problem, consists arrangingN = g golfers g groups players w weeks, two playersplay together once. Again, use model used LagoonStuckey (2004), using w g matrix set variables vij 1 w 1 j g.V Vgw< (v , . . . , v ))partition|v|=i1igiji=1Vi=1V j=1VVw1 w|vv|1vvj1jli,j{1...w}, i6=jk,l{1...g} iki=1j=i+1 i1(Vwglobal constraint partition< ensures arguments pairwise disjoint imposeslexicographic order arguments, i.e. vi1 < < vig . corresponding propagatorbased single BDD. construct BDD propagators constraint forms|v v | 1, v v |v| = s. Note first form would typically decomposedu = v v |u| 1 normal set bounds propagator.hybrid solver constructs one BDD 4 terms equation,instantiating constraints accordingly.Table 1 shows results using static search strategy easy problems. searchfixes elements sets vij order v11 , v12 , . . . , v1g , v21 , . . . , vwg , always trying firstplace least element set excluding set. comparereported results original BDD-SAT hybrid solver Hawkins Stuckey (2006)versus number variations hybrid. base base solver Figures 4 5,+f indicates filtering Section 4.1 added, +s indicates dead subgraphmemoization shortcutting added (Section 4.2) using original sparse set code, +ioptimizations improved sparse set code. also combine filteringoptimizations. table shows time number fails variant,solvers identical failure behaviour grouped together. Note filteringchange search reordering propagations hence changing nogoodsgenerated, optimizations cannot except shortcutting changeresults filtering (and hence change search). filtering improves base line,dead subgraph memoization shortcutting not, although see benefitimproved sparse set operations. Comparing solver Hawkins Stuckey(2006), run () 2.4GHz Pentium 4, find that, slightly different numberbacktracks slightly faster machine withstanding, solver presentedroughly order magnitude faster.Table 2 shows results using VSIDS search easy problems. comparessolver Hawkins Stuckey (2006) Tseitin decomposition. results328fiFast Set Bounds Propagation Using BDD-Sat HybridProblem2,5,42,6,42,7,42,8,53,5,43,6,43,7,44,5,44,6,54,7,44,9,45,4,35,5,45,7,45,8,36,4,36,5,36,6,37,5,37,5,5TotalHawkinstimefails0.10110.10450.20900.804720.10110.20480.70810.20110.70810.801051.903212.0095682.3011671.501590.90122.109080.902820.40518.2061520.8010044.9019340base0.030.040.062.840.020.040.120.030.250.110.182.580.420.180.060.510.130.053.790.2011.64+s0.020.040.073.150.020.050.080.030.270.140.183.000.480.250.100.600.140.044.670.2013.53Static SearchHybrid+ifails+f0.02190.020.051260.050.071480.073.1388560.470.04190.020.071290.050.111650.100.04190.020.265590.070.151710.180.18400.142.92102942.350.4613280.330.212170.240.07100.080.5716990.330.162780.090.0550.034.4576162.100.181210.1813.19318196.92fails191532651119191562821977288401020912933351010792615570212121452+fs0.020.050.070.500.030.060.140.020.100.170.142.690.400.250.060.320.110.033.080.218.45+fi0.020.040.070.500.020.060.120.030.090.170.142.690.360.240.100.330.140.042.970.208.33fails19153265111919156282197728840101881297335109222575630212121874Table 1: First-solution performance results Social Golfers problem using static,first-element set ordering. Instances marked () unsatisfiable, entries markedcomplete within 10 minutes.Table 1, overall VSIDS better static search. table illustratesdifficulty comparing systems using VSIDS search, since small differencesdrastically change search space. solver +f best except bad-performance7,5,3. base solver around 5 times faster per failure solver HawkinsStuckey (2006). Tseitin decomposition competitive, even discountresults 7,5,3.social golfers, dead-subset memoization shortcutting provide advantage(when discount drastically different search 7,5,3 using VSIDS). numbernodes processed reduced slightly, enough repay additional costcomputation node.Table 3 compares reason generation strategies: eager reasoning constructs reasons soon inference detected; lazy reasoning reasons necessarydetermine first UIP perform conflict clause minimization.Table 3 compares base solver without filtering (since dead subgraph memoization shortcutting help here) harder social golfer problems using staticsearch. shows time (base) well number reasons generated fails orderfind first solution. harder examples filtering highly beneficial.see number reasons generated lazy reasoning half requiredeager reasoning, doesnt make much difference computation time, sincepropagation dominates time spent solver. Interestingly adding reasons eagerly also seems generate slightly better nogoods search usually smaller. Table 4shows results using VSIDS search harder instances. appears advantages329fiGange, Stuckey, & LagoonProblem2,5,42,6,42,7,42,8,53,5,43,6,43,7,44,5,44,6,54,7,44,9,45,4,35,5,45,7,45,8,36,4,36,5,36,6,37,5,37,5,5TotalHawkinstimefails0.10220.10640.201191.306220.10240.30580.60920.401221.303041.00982.00595.6058761.905811.501041.704250.20714.3028011.0027518.0070182.0013943.6018874base0.040.020.030.100.040.050.060.050.260.090.161.234.140.160.080.180.250.078.810.1415.96+s0.030.030.030.120.040.040.060.060.260.110.181.425.160.130.100.170.270.0611.080.1119.46+i0.030.020.030.110.020.040.060.060.260.100.181.354.800.130.100.170.290.0710.720.1218.66VSIDS SearchHybridfails+ffails40.024200.0320130.04131090.10109510.0351800.0680780.07791080.041163090.131581020.10103360.143658690.56313998460.912487770.1184290.10294250.144793690.18409360.07701894939.3593789470.10473655742.28101302+fs0.020.020.050.100.030.040.060.060.140.090.180.690.770.130.100.300.170.082.470.135.63+fi0.030.020.040.100.040.040.100.060.150.080.150.670.740.120.100.280.160.092.380.105.45fails420131095180791162051033631841754842910133977045544711948Tseitintimefails0.0370.04370.06550.09780.051700.072680.124690.1411430.4931560.2510200.6310374.74267690.5834751.1635960.529182.83175951.8586751.09354745.54777860.93197761.21151778Table 2: First-solution performance results Social Golfers problem using VSIDSsearch strategy.Social GolfersProblem7,5,32,6,54,6,56,10,39,10,310,10,3Totalbase6.340.140.460.9016.91109.43134.18Lazy Reason Generationreasonsfails+freasons62630130715.496544716735810.03317705810670.38702666758710.72697315522385715.74151032811011462130.043258012166830909152.40127446fails1307966103794637081312831964base8.760.170.551.0427.88198.90237.30Eager Reasonreasonsfails1173231327330265811183310669942820341814039812701275525757532534Generation+freasons7.381176570.047400.48119670.871010125.7732945187.1179461221.65252871Table 3: First-solution performance results harder Social Golfers problems, using staticleast-element set search method. Results given comparing eager lazy reasongeneration.lazy reasoning increased use VSIDS, presumably better nogoodsuseful driving search.Finally Table 5 compares number different systems. use modelsocial-golfers described work Yip Van Hentenryck (2009), additionfixes first week, first group second week eliminate symmetric solutions.use instances reported Yip Van Hentenryck (2009). show resultsbase solver without filtering. compare Gecode 3.1.0 Eclipse 6.0#100, implement set bounds propagation combined limited cardinalityreasoning, identical MiniZinc model social-golfers running 3GHz Core2Duo.Gecode arguably represents state art set bounds propagation solving. alsocompare published results Cardinal solver (Azevedo, 2007), uses330fails1259866102884938531233830732fiFast Set Bounds Propagation Using BDD-Sat HybridSocial GolfersProblem7,5,32,6,54,6,56,10,39,10,310,10,3Totalbase0.200.020.060.220.921.512.93Lazyreasons209638176188174319176158Reasonfails2174187110139495Generation+freasons1.03126380.02380.061760.181880.456660.646412.3814347fails2608418768462751base0.220.031.280.341.592.065.52Eager Reasonreasonsfails432821235042802615651824766851347707200489202122Generation+freasons2.18637800.043500.0816040.3418231.2063101.0843104.9278177fails49114407107575126Table 4: First-solution performance results harder Social Golfers problems, usingVSIDS search method. Results given comparing eager lazy reason generation.complex cardinality reasoning set solving, using () Pentium 4 2.4GHz machine,recently published results Length-Lex solver Yip Van Hentenryck(2009), maintains bounds sets variables terms length-lex order (see Gervet& Van Hentenryck, 2006; Yip & Van Hentenryck, 2009 details) running () C2DM 2.53GHz machine. pure set bounds solvers cannot compete approachsince search space without using nogood recording big. Nonesystems except Length-lex solve instances. One see drasticdifference number failures Gecode, uses set bounds propagationwithout learning, versus base solver. Gecode sometimes require less failureseasy problems since combines cardinality reasoning bounds reasoning, hardproblems advantages learning prune similar searches parts treedominates completely. stronger pruning Length-lex compared set boundsmeans often improve fails compared base learning robust.hybrid solver overall around order magnitude faster Length-Lex.6.2 Steiner SystemsAnother commonly used benchmark set constraint solvers calculation smallSteiner systems. Steiner system S(t, k, N ) set X cardinality N collectionC subsets X cardinality k (called blocks), elementsXexactly one block. Steiner system must exactly = Nt / kt blocks (Theorem19.2 van Lint & Wilson, 2001).model Steiner problem similarly Lagoon Stuckey (2004) extendedcase general Steiner Systems. model block set variable s1 , . . . , sm ,constraints:^(|si | = k)i=1m1^^(|si sj | 1 si < sj )i=1 j=i+1comparison results Azevedo (2007) Yip Van Hentenryck (2009),construct dual model additional variables d1 , . . . , dN , additional constraints331fiGange, Stuckey, & LagoonProblem4,4,25,4,26,4,27,4,24,4,35,4,36,4,34,4,45,4,43,5,24,5,25,5,26,5,27,5,28,5,29,5,23,5,34,5,35,5,36,5,37,5,32,5,43,5,44,5,45,5,43,5,54,5,55,5,56,5,57,5,52,6,33,6,34,6,35,6,36,6,32,6,43,6,42,6,53,6,54,6,55,6,53,6,62,7,22,7,32,7,43,7,44,7,45,7,42,7,52,7,62,7,75,8,34,8,42,8,54,9,46,10,39,10,310,10,34,10,45,10,4TotalGecode0.0000.0000.0000.0000.0061.7257810.01450.0000.0000.0010.0020.0020.0060.01170.01220.01170.01490.03730.03105110.333355310.0910900.116050.092980.194100.0010.01130.04450.03308.11122740.0000.01300.01230.093110.153881.91166083.6815948547.911893577275.3858453296.891453710.0180.0010.00105.643983313.404662110.542421611.32187850.01026.92568448.931185417.331634534.6236294Eclipse0.560.540.550.620.5611.210.660.570.610.540.570.610.660.710.810.860.580.650.761.261.100.981.400.650.740.840.96161.120.560.690.711.081.328.1210.16265.400.820.600.6417.4327.2319.3817.170.8646.0312.1817.1046.58Cardinal165.6394.671.893.1328.651.201.754.622.826.3712.4617.181.0142.45length-lex0.0100.0100.0100.0100.0100.407320.02290.061110.05570.0100.0100.0100.0100.0210.0210.0210.0110.0110.0250.4131674.59461170.01110.02240.141941.8719470.06934.72687654.275062329.21157690.0110.0000.0110.0110.0260.04100.01140.03420.051182.54335132.603127028.7667580.826610.0100.0110.0100.03210.05260.361520.315740.7812710.28034.52454770.06180.253070.21945.862941233.8045437210.80252460.271040.58149719.11286960base0.010.020.020.020.010.460.030.020.020.020.010.020.010.040.060.120.020.030.030.806.320.020.030.070.980.020.050.070.153.280.020.030.040.040.390.040.060.130.150.4515.240.040.030.020.020.070.080.220.451.440.060.090.120.560.190.9116.66110.800.520.76162.39+f3481391877573813581424401018302516130712136191259202964167472844111593258975815321067264950001969622431944603107167214590871385711462409576832620.010.020.020.040.020.350.040.020.030.020.030.020.030.040.050.140.020.010.030.565.500.020.020.080.740.020.040.060.158.170.020.010.020.040.270.020.050.050.080.352.850.030.030.030.050.070.080.160.070.180.050.110.100.230.190.7315.64129.660.460.65168.58348139179957381358142440101630234513079213618923560276422111736441115959589766178103772950001972632341335660706729110094637081312841959662265Table 5: Comparison solvers using different propagation mechanisms, usingmodel instances described Yip Van Hentenryck (2009). denotes failurecomplete test-case 10 minutes (or 15 minutes Cardinal). blank entry meanspublished result compare.shown:^N^(j si dj )i=1 j=1N^(|dj | =j=1332mk)NfiFast Set Bounds Propagation Using BDD-Sat HybridProblem2,3,72,3,92,3,132,3,152,3,192,3,212,3,252,3,272,3,312,3,33Gecodetimefails0.0000.0030.03180.0400.651442.61413Eclipsetime0.530.561.202.158.09Cardtime0.010.050.610.917.9439.0748.52Length-lextimefails0.0000.0110.05100.0900.461641.0444814.07510023.5570665.290Static Hybridbasefails0.0100.0210.0690.0700.37780.822257.10247412.8834015.380443.07111923VSIDS Hybridbasefails0.0350.02170.02240.322950.0710639.1942688229.5911337319.308228Tseitintimefails0.04590.8138041.937879143.8112420514.0134089Table 6: First-solution performance results alternate Steiner Systems instances usingdual model. Gecode sequential hybrid use sequential least-element set searchstrategy dual variables. VSIDS hybrid Tseitin decomposition use VSIDSsearch. denotes failure complete test-case 10 minutes due either timeoutmemory error. blank entry means published result compare.create BDD propagators constraint forms |v| = mkN |v v |1 v < v |v| = k |v | = k. note non-BDD based set bounds solvers lastform would typically five separate constraints. channelling component j v vexplicitly represented. Instead, underlying Boolean variables re-used.Table 6, use model search strategy used Azevedo (2007), restrictingnumber times given element occur sets s1 , . . . , sm . compareGecode Eclipse using MiniZinc model, well published resultsCardinal Length-Lex. model used hybrid solver constructs oneconstraint pair set variables, conjoining cardinality, intersection orderingconstraints. instances significant amount search occurs, seemassive improvement beyond performance pure set bounds propagationsolvers. hybrid solver Length-Lex robust. see hybridrequires least search somewhat faster Length-Lex. also compareversus VSIDS search. Steiner problems illustrate specialized search strategybetter generic VSIDS approach. see Tseitin decompositioncompetitive problems6.3 Fixed-weight Hamming Codesproblem finding maximal Hamming codes also expressed set-constraintproblem. Hamming code distance length l set l-bit codewordspair codewords must least bits differ. variation problemfind maximal codes codewords exactly w bits set.333fiGange, Stuckey, & LagoonProblem8,4,49,4,39,4,49,4,59,4,610,4,310,4,410,4,510,4,610,4,710,6,5Fixed-weight Hamming CodesLength-lexStatic Hybridtimefails+f+fs+fi0.071100.160.170.162.0546177.137.477.250.409081.671.661.61359.306298221.9944150.0315878.9978.1478.92Gecodetimefails280.972175542fails897299851054192349Table 7: Results hard Hamming instances static least-element set search order,additional symmetry breaking.Problem8,4,49,4,39,4,49,4,59,4,610,4,310,4,410,4,510,4,610,4,710,6,5+f0.080.3056.5569.280.43102.6453.72509.13110.650.71Fixed-weight Hamming CodesVSIDS HybridTseitin+fs+fifailstimefails0.080.1028211.15505300.260.24162716.186787645.9543.39 21018359.5656.65 3077860.390.36258914.845529290.3786.09 63821438.7237.0491781404.65385.48 987682101.37103.207274650.570.545057157.86693148Table 8: Results hard Hamming instances VSIDS, additional symmetrybreaking.formulation problem is:^(|si | = w)i=1m1^^(|si sj | si < sj )i=1 j=i+1= (s ) (s s) symmetric difference. similar structureformulation Steiner Systems; however, rather fixed numbersets, find maximal code repeatedly adding new sets correspondingconstraints solution found. unsatisfiability n codewords provesmaximal code n 1 codewords. create BDD propagators constraint form|v v | v < v |v| = w |v | = w.compare two different models fixed-weight Hamming code problems, oneusing description above, another first two sets fixed removesymmetries. compare Gecode, published results Length-Lex334fiFast Set Bounds Propagation Using BDD-Sat HybridProblem8,4,49,4,39,4,49,4,59,4,610,4,310,4,410,4,510,4,610,4,710,6,5Gecodetimefails15.292986966.7221659847.721018320.07546Fixed-weight Hamming CodesLength-lexStatic Hybridtimefails+f+fs+fi0.071100.040.040.042.0546170.280.290.2818.0917.9517.9955.9056.5257.140.409080.040.040.04359.306298221.9944156.166.246.290.031580.020.020.02fails51213043318717772082285770Table 9: Results hard Hamming instances sequential least-element set searchorder, fixed first second sets.Problem8,4,49,4,39,4,49,4,59,4,610,4,310,4,410,4,510,4,610,4,710,6,5+f0.030.081.284.820.062.7620.53143.5064.102.210.03Fixed-weight Hamming CodesVSIDS HybridTseitin+fs+fifailstimefails0.050.03611.0661940.060.063003.19199521.101.044466319.054077624.204.0321651186.642444740.050.062561.3183282.562.3716755120.2222638015.4514.6634503104.29 104.3918405151.7648.96 1313792.051.961353358.061122690.040.031450.101044Table 10: Results hard Hamming instances VSIDS search strategy, fixedfirst second sets.hybrid using static search strategy (the least element set strategy used SocialGolfers), well hybrid solver Tseitin decomposition using VSIDS search.systems compare without shortcutting optimized implementation.Since sure model used Length-Lex report resultsmodels.Tables 7 10 show results 11 hard instances reported Hawkins et al.(2005). Clearly problems VSIDS hybrid robust. solveone instance basic model, additional symmetry breaking.example also clearly shows potential advantages shortcutting improveddata structures: change search improve time 18% 21%respectively base model, 24% 26% respectively improved model.Tseitin decomposition competitive.7. Related WorkSet-constraint problems active area research past decade. Manyearlier solvers, beginning PECOS (Puget, 1992), used set-bounds repre335fiGange, Stuckey, & Lagoonsentation combined fixed set propagation rules constraint. generalapproach also used Conjunto (Gervet, 1997), ECLi PSe (IC-PARC, 2003), ILOGSolver (ILOG, 2004) Mozart (Muller, 2001). However, set-bounds relativelyweak approximation domain set variable, variety variations developed improve propagation strength set-constraint solvers. include solverscombine set-bounds representation either cardinality information,proposed Azevedo (2002, 2007), lexicographic bounds information (Sadler & Gervet,2004) (Gervet & Van Hentenryck, 2006; Yip & Van Hentenryck, 2009).BDD-based approaches set-constraint solving, presented Hawkinset al. (2005) differs greatly approaches, possible perform propagationarbitrary constraints; Lagoon Stuckey (2004) also demonstrated feasibilityBDD-based solver maintains complete domain representation set variables.directly BDD-based algorithms used construct earlier hybrid solverpresented Hawkins Stuckey (2006), conceptually similar solver presented paper. solver presented much efficient, includes improvements filtering shortcutting present solver Hawkins Stuckey(2006). solver Damiano Kukula (2003) also combines BDD solving SATsolving, rather building BDDs high-level problem description lazilyconstructing SAT representation, instead takes CNF SAT representation constructsBDD collection clauses primary goal variable elimination.essentially equivalent base solver.underlying BDD propagation algorithm similar propagation case constraint SICStus PRolog (SICS, 2009) Multi-valued Decision Diagrams (MDDs) (seee.g., Cheng & Yap, 2008). Indeed adapted dead subgraph memoizationshortcutting devices Cheng Yap (2008) BDD propagation. Propagators caseMDDs presently use filtering generate reasons.Finally hybrid set solver present paper example lazy clausegeneration solver (Ohrimenko, Stuckey, & Codish, 2007, 2009). BDD propagatorsunderstood lazily creating clausal representation set constraints encodedBDD, search progresses.8. Concluding Remarkspaper improved BDD-based techniques set-bounds propagation,demonstrated approach avoids need expensive BDD constructionmanipulation operations. traversal-based method, combined filteringreduce number redundant propagator executions dead subgraph memoizationshortcutting, least order magnitude faster previous techniquesconstruct BDDs runtime (Hawkins et al., 2005).Furthermore, integrated modern SAT solver clause learning augmented method generating nogoods, new hybrid solver capable solvinghard problem instances several orders magnitude faster pure bounds set solvers.Overall hybrid solver robust highly competitive propagationbased set-solvers aware of.336fiFast Set Bounds Propagation Using BDD-Sat Hybridmany set problems significant numbers symmetries largebody work solving set problems symmetry breaking techniques (see e.g., Puget,2005). would interesting combine symmetry breaking hybrid solver.9. AcknowledgmentsPart work published previously (Gange, Lagoon, & Stuckey, 2008). NICTAfunded Australian Government represented Department Broadband,Communications Digital Economy Australian Research Council.ReferencesAzevedo, F. (2002). Constraint Solving Multi-valued Logics. Ph.D. thesis, Faculdadede Ciencias e Tecnologia, Universidade Nova de Lisboa.Azevedo, F. (2007). Cardinal: finite sets constraint solver. Constraints, 12 (1), 93129.Bryant, R. (1986). Graph-based algorithms Boolean function manipulation. IEEE Trans.Comput., 35 (8), 677691.Cheng, K., & Yap, R. (2008). Maintaining generalized arc consistency ad hoc r-aryconstraints. 14th International Conference Principles Process ConstraintProgramming, pp. 509523.Damiano, R., & Kukula, J. (2003). Checking satisfiability conjunction BDDs.Proceedings Design Automation Conference, pp. 818823.Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.Communications ACM, 5, 394397.Een, N., & Sorensson, N. (2003). extensible SAT-solver. Giunchiglia, E., & Tacchella,A. (Eds.), Proceedings SAT 2003, Vol. 2919 LNCS, pp. 502518.Een, N., & Sorensson, N. (2006). Translating pseudo-boolean constraints SAT. JournalSatisfiability, Boolean Modeling Computation, 2, 126.Gange, G., Lagoon, V., & Stuckey, P. (2008). Fast set bounds propagation using BDDs.18th European Conference Artificial Intelligence, pp. 505509.GECODE (2008). Gecode. www.gecode.org. Accessed Jan 2008.Gervet, C. (1997). Interval propagation reason sets: Definition implementationpractical language. Constraints, 1 (3), 191246.Gervet, C., & Van Hentenryck, P. (2006). Length-lex ordering set CSPs. ProceedingsNational Conference Artificial Intelligence, pp. 4853.Hawkins, P., Lagoon, V., & Stuckey, P. (2004). Set bounds (split) set domain propagation using ROBDDs. 17th Australian Joint Conference Artificial Intelligence,Vol. 3339 LNCS, pp. 706717.Hawkins, P., Lagoon, V., & Stuckey, P. (2005). Solving set constraint satisfaction problemsusing ROBDDs. Journal Artificial Intelligence Research, 24, 106156.337fiGange, Stuckey, & LagoonHawkins, P., & Stuckey, P. (2006). hybrid BDD SAT finite domain constraint solver.Proceedings 8th International Symposium Practical Aspects DeclarativeLanguages, Vol. 3819 LNCS, pp. 103117.IC-PARC (2003). ECLiPSe constraint logic programming system. [Online, accessedOct 2008]. http://www.eclipse-clp.org/.ILOG (2004). ILOG Solver. [Online, accessed Oct 2008]. http://www.ilog.com/.Lagoon, V., & Stuckey, P. (2004). Set domain propagation using ROBDDs. Proceedings 10th International Conference Principles Practice ConstraintProgramming, Vol. 3258 LNCS, pp. 347361.van Lint, J. H., & Wilson, R. M. (2001). Course Combinatorics (2nd edition). Cambridge University Press.Muller, T. (2001). Constraint Propagation Mozart. Doctoral dissertation, Universitat desSaarlandes, Naturwissenschaftlich-Technische Fakultat I, Fachrichtung Informatik,Saarbrucken, Germany.Ohrimenko, O., Stuckey, P., & Codish, M. (2007). Propagation = lazy clause generation.Bessiere, C. (Ed.), Proceedings 13th International Conference PrinciplesPractice Constraint Programming, Vol. 4741 LNCS, pp. 544558. SpringerVerlag.Ohrimenko, O., Stuckey, P., & Codish, M. (2009). Propagation via lazy clause generation.Constraints, 14 (3), 357391.Puget, J.-F. (1992). PECOS: high level constraint programming language. ProceedingsSPICIS92, Singapore.Puget, J.-F. (2005). Symmetry breaking revisited. Constraints, 10 (1), 2346.Sadler, A., & Gervet, C. (2004). Hybrid set domains strengthen constraint propagationreduce symmetries. Wallace, M. (Ed.), Proceedings 10th InternationalConference Principles Practice Constraint Programming (CP04), No. 3258LNCS. Springer-Verlag.SICS (2009). Sicstus prolog. www.sics.se/sicstus.Subbarayan, S. (2008). Efficent reasoning nogoods constraint solvers BDDs.Proceedings Tenth International Symposium Practical Aspects DeclarativeLanguages, Vol. 4902 LNCS, pp. 5357.Tseitin, G. (1968). complexity derivation propositional calculus. StudiesConstructive Mathematics Mathematical Logic, Part 2, 115125.Yip, J., & Van Hentenryck, P. (2009). Evaluation length-lex set variables. Proceedings 15th International Conference Principles Practice ConstraintProgramming, pp. 817832.338fiJournal Artificial Intelligence Research 38 (2010) 135-187Submitted 12/09; published 05/10Survey Paraphrasing Textual Entailment MethodsIon AndroutsopoulosProdromos MalakasiotisION @ AUEB . GRRULLLER @ AUEB . GRDepartment InformaticsAthens University Economics BusinessPatission 76, GR-104 34 Athens, GreeceAbstractParaphrasing methods recognize, generate, extract phrases, sentences, longer natural language expressions convey almost information. Textual entailment methods,hand, recognize, generate, extract pairs natural language expressions, humanreads (and trusts) first element pair would likely infer elementalso true. Paraphrasing seen bidirectional textual entailment methods twoareas often similar. kinds methods useful, least principle, wide rangenatural language processing applications, including question answering, summarization, text generation, machine translation. summarize key ideas two areas considering turnrecognition, generation, extraction methods, also pointing prominent articles resources.1. Introductionarticle survey computational methods paraphrasing textual entailment. Paraphrasing methods recognize, generate, extract (e.g., corpora) paraphrases, meaning phrases,sentences, longer texts convey same, almost information. example, (1)(2) paraphrases. people would also accept (3) paraphrase (1) (2), thoughcould argued (3) construction bridge necessarily completed,unlike (1) (2).1 fine distinctions, however, usually ignored paraphrasing textualentailment work, say paraphrases may convey almost information.(1)(2)(3)Wonderworks Ltd. constructed new bridge.new bridge constructed Wonderworks Ltd.Wonderworks Ltd. constructor new bridge.Paraphrasing methods may also operate templates natural language expressions, like (4)(6); slots X filled arbitrary noun phrases. Templates specifiedsyntactic semantic level may also used, slot fillers may requiredparticular syntactic relations (e.g., verb-object) words constituents, satisfy semanticconstraints (e.g., requiring denote book).(4)(5)(6)X wrote .written X.X writer .1 Readers familiar tense aspect theories recognized (1)(3) involve accomplishmentVendlers (1967) taxonomy. accomplishments completion point necessarily reached (3), unlike (1)(2).c2010AI Access Foundation. rights reserved.fiA NDROUTSOPOULOS & ALAKASIOTISTextual entailment methods, hand, recognize, generate, extract pairs hT, Hinatural language expressions, human reads (and trusts) would infer Hlikely also true (Dagan, Glickman, & Magnini, 2006). example, (7) textually entails (8), (9)textually entail (10).2(7)(8)(9)(10)drugs slow Alzheimers disease work best earlier administer them.Alzheimers disease slowed using drugs.Drew Walker, Taysides public health director, said: important stress confirmedcase rabies.case rabies confirmed.paraphrasing, textual entailment methods may operate templates. example,discourse painters, composers, work, (11) textually entails (12), noun phrasesX . However, (12) textually entail (11), denotes symphony composedX. require textual entailment templates hold possible slot fillers, (11)textually entails (12) examples discourse, reverse hold.(11)(12)X painted .work X.general, cannot judge two natural language expressions paraphrases correcttextual entailment pair without selecting particular readings expressions, amongmay possible due multiple word senses, syntactic ambiguities etc. example, (13) textuallyentails (14) financial sense bank, (13) refers bank river.(13)(14)bomb exploded near French bank.bomb exploded near building.One possibility, then, examine language expressions (or templates) particularcontexts make intended readings clear. Alternatively, may want treat correcttextual entailment pair hT, Hi possible readings H, humanreads would infer H likely also true; then, system reports (13) textuallyentails (14), response counted correct, regardless intended sense bank.Similarly, paraphrases would possible readings conveying almost information.lexical substitution task SEMEVAL (McCarthy & Navigli, 2009), systems required find appropriate substitute particular word context given sentence,seen special case paraphrasing textual entailment, restricted pairs words.SEMEVAL task, however, includes requirement must possible use two words(original replacement) exactly context. similar manner, one could adoptstricter definition paraphrases, would require (or almostsame) meaning, also expressions used interchangeably grammatical sentences. case, although (15) (16) paraphrases, underlined parts not,cannot swapped two sentences; resulting sentences would ungrammatical.(15)(16)Edison invented light bulb 1879, providing long lasting source light.Edisons invention light bulb 1879 provided long lasting source light.similar stricter definition textual entailment would impose additional requirement Hreplace grammatical sentences.2 Simplifiedexamples RTE-2 (Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, & Szpektor, 2006).136fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS1.1 Possible Applications Paraphrasing Textual Entailment Methodsnatural language expressions paraphrasing textual entailment methods consideralways statements. fact, many methods developed question answering(QA) systems mind. QA systems document collections (Voorhees, 2001; Pasca, 2003;Harabagiu & Moldovan, 2003; Molla & Vicedo, 2007), question may phrased differentlydocument contains answer, taking variations account improve systemperformance significantly (Harabagiu, Maiorano, & Pasca, 2003; Duboue & Chu-Carroll, 2006;Harabagiu & Hickl, 2006; Riezler, Vasserman, Tsochantaridis, Mittal, & Liu, 2007). example,QA system may retrieve relevant documents passages, using input question queryinformation retrieval Web search engine (Baeza-Yates & Ribeiro-Neto, 1999; Manning, 2008),check retrieved texts textually entails candidate answer (Moldovan & Rus,2001; Duclaye, Yvon, & Collin, 2003).3 input question (17) search engine returnspassage (18), system may check (18) textually entails candidate answers (19),replaced interrogative (17) expressions (18) namedentity recognizer (Bikel, Schwartz, & Weischedel, 1999; Sekine & Ranchhod, 2009) would ideallyrecognized person names.4(17)(18)(19)sculpted Doryphoros?Doryphoros one best known Greek sculptures classical era Western Art.Greek sculptor Polykleitos designed work example canon rule, showingperfectly harmonious balanced proportions human body sculpted form. sculptureknown Roman marble replica found Herculaneum conserved NaplesNational Archaeological Museum, but, according Francis Haskell Nicholas Penny, early connoisseurs passed royal Bourbon collection Naples without notable comment.Polykleitos/Francis Haskell/Nicholas Penny sculpted Doryphoros.input question may also paraphrased, allow more, potentially relevant passagesobtained. Question paraphrasing also useful mapping user questions lists frequentlyasked questions (FAQs) accompanied answers (Tomuro, 2003); natural languageinterfaces databases often generate question paraphrases allow users understandqueries understood (McKeown, 1983; Androutsopoulos, Ritchie, & Thanisch, 1995).Paraphrasing textual entailment methods also useful several natural languageprocessing applications. text summarization (Mani, 2001; Hovy, 2003), example, important processing stage typically sentence extraction, identifies important sentencestexts summarized. stage, especially generating single summaryseveral documents (Barzilay & McKeown, 2005), important avoid selecting sentences (e.g.,different news articles event) convey information (paraphrases)sentences already selected, sentences whose information followsalready selected sentences (textual entailment).Sentence compression (Knight & Marcu, 2002; McDonald, 2006; Cohn & Lapata, 2008; Clarke& Lapata, 2008; Cohn & Lapata, 2009; Galanis & Androutsopoulos, 2010), often also processingstage text summarization, seen special case sentence paraphrasing, suggested3 Culicover(1968) discussed different types paraphrasing entailment, proposed earliest computationaltreatment paraphrasing textual entailment aware of, goal retrieving passages textsanswer natural language queries. thank one anonymous reviewers pointing us Culicovers work.4 Passage (18) based Wikipedias page Doryphoros.137fiA NDROUTSOPOULOS & ALAKASIOTISZhao et al. (2009), additional constraint resulting sentence must shorteroriginal one still grammatical; example, sentence matching (5) (6) could shortenedconverting paraphrase form (4). sentence compression work, however, allowsless important information original sentence discarded. Hence, resulting sentenceentailed by, necessarily paraphrase original one. following example, (21)compressed form (20) produced human.5(20)(21)Mother Catherine, 82, mother superior, attend hearing Friday, said.Mother Catherine, 82, mother superior, attend.compressed sentence necessarily paraphrase original one, may firstproduce (grammatical) candidate compressions textually entailed original sentence;hence, mechanism generate textually entailed sentences useful. Additional mechanismsneeded, however, rank candidates depending space save degreemaintain important information; discuss additional mechanisms kind.Information extraction systems (Grishman, 2003; Moens, 2006) often rely manually automatically crafted patterns (Muslea, 1999) locate text snippets report particular typesevents identify entities involved; example, patterns like (22)(24), similar patternsoperating syntax trees, possibly additional semantic constraints, might used locatesnippets referring bombing incidents identify targets. Paraphrasing textual entailment methods used generate additional semantically equivalent extraction patterns (incase paraphrasing) patterns textually entail original ones (Shinyama & Sekine, 2003).(22)(23)(24)X bombedbomb exploded near Xexplosion destroyed Xmachine translation (Koehn, 2009), ideas paraphrasing textual entailment researchembedded measures processes automatically evaluate machine-generatedtranslations human-authored ones may use different phrasings (Lepage & Denoual,2005; Zhou, Lin, & Hovy, 2006a; Kauchak & Barzilay, 2006; Pado, Galley, Jurafsky, & Manning,2009); return issue following sections. Paraphrasing methods also usedautomatically generate additional reference translations human-authored ones training machine translation systems (Madnani, Ayan, Resnik, & Dorr, 2007). Finally, paraphrasingtextual entailment methods employed allow machine translation systems copesource language words longer phrases encountered training corpora(Zhang & Yamamoto, 2005; Callison-Burch, Koehn, & Osborne, 2006a; Marton, Callison-Burch, &Resnik, 2009; Mirkin, Specia, Cancedda, Dagan, Dymetman, & Szpektor, 2009b). use example Mirkin et al. (2009b), phrase-based machine translation system never encounteredexpression file lawsuit training, knows pattern (25) textually entails(26), may able produce acceptable translation converting (27) (28),translating (28). information would lost translation, (28) paraphrase(27), translation may still preferable outcome translating directly (27).(25)X filed lawsuit Z.5 ExampleClarke et al.s paper, Written News Compression Corpus (Clarke & Lapata, 2008); see Appendix A.138fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS(26)(27)(28)X accused Z.Cisco filed lawsuit Apple patent violation.Cisco accused Apple patent violation.natural language generation (Reiter & Dale, 2000; Bateman & Zock, 2003), exampleproducing texts describing entities formal ontology (ODonnell, Mellish, Oberlander, & Knott, 2001; Androutsopoulos, Oberlander, & Karkaletsis, 2007), paraphrasing usedavoid repeating phrasings (e.g., expressing properties similar entities),produce alternative expressions improve text coherence, adhere writing style (e.g., avoidpassives), satisfy constraints (Power & Scott, 2005). Among possible applications,paraphrasing textual entailment methods employed simplify texts, example replacing specialized (e.g., medical) terms expressions non-experts understand (Elhadad &Sutaria, 2007; Deleger & Zweigenbaum, 2009), automatically score student answersreference answers (Nielsen, Ward, & Martin, 2009).1.2 Relation Paraphrasing Textual Entailment Logical Entailmentrepresent meanings natural language expressions logical formulae, examplefirst-order predicate logic, may think textual entailment paraphrasing terms logicalentailment (|=). logical meaning representations H H , hT, Hicorrect textual entailment pair (T B) |= H ; B knowledge base, simplicityassumed form single conjunctive formula, contains meaning postulates(Carnap, 1952) knowledge assumed shared language users.6 Let us considerexample below, logical terms starting capital letters constants; assumedifferent word senses would give rise different predicate symbols. Let us also assume Bcontains . (T ) |= H holds, i.e., H true interpretation (e.g., modeltheoretic) constants, predicate names domain-dependent atomic symbols,hold. sound complete automated reasoner (e.g., based resolution, casefirst-order predicate logic) could used confirm logical entailment holds. Hence,textually entails H, assuming meaning postulate available. reverse, however,hold, i.e., (H ) 6|= ; implication () would made bidirectional() reverse hold.:Leonardo da Vinci painted Mona Lisa.: isPainterOf(DaVinci, MonaLisa)H:HMona Lisa work Leonardo da Vinci.: isWorkOf(MonaLisa, DaVinci): x isPainterOf(x, y) isWorkOf(y, x)Similarly, logical meaning representations T1 T2 1 2 , T1 paraphrase T2 iff (1 B) |= 2 (2 B) |= 1 , B contains meaning postulatescommon sense knowledge. Ideally, sentences like (1)(3) would represented formula, making clear paraphrases, regardless contents B. Otherwise, may6 Zaenenet al. (2005) provide examples showing linguistic world knowledge cannot often separated.139fiA NDROUTSOPOULOS & ALAKASIOTISsometimes unclear T1 T2 considered paraphrases, may unclearknowledge considered part B.Since natural language expressions often ambiguous, especially context, maywant adopt looser definitions, textually entails H iff possible readingsH, represented H , (T B) |= H , similarly paraphrases. Thinkingtextual entailment paraphrasing terms logical entailment allows us borrow notionsmethods logic. Indeed, paraphrasing textual entailment recognition methods mapnatural language expressions logical formulae, examine logical entailments hold.not, however, possible approach. Many other, most, methods currently operatesurface strings syntactic representations, without mapping natural language expressions formalmeaning representations. Note, also, methods map natural language logical formulae,important work form logic provides adequate support logical entailmentchecks; full first-order predicate logic may inappropriate, semi-decidable.apply logic-based definition textual entailment, formulated statements,questions, let us use identical fresh constants (in effect, Skolem constants) across questionsrepresent unknown entities questions ask for; mark constants question markssubscripts, logical entailment checks treated ordinary constants. following example, user asks H, system generates . Assuming meaning postulateavailable B, (T B) |= H , i.e., interpretation predicate symbols constants,(T B) true, H necessarily also true. Hence, textually entails H. practice,means system manages find answer , perhaps phrasing closersentence document collection, answer used respond H.(generated) :painted Mona Lisa?: isAgent(W? ) isPainterOf(W? , MonaLisa)H(asked) :Whose work Mona Lisa?H: isAgent(W? ) isWorkOf(MonaLisa,W? ): x isPainterOf(x, y) isWorkOf(y, x)logic-based definition question paraphrases formulated similar manner,bidirectional logical entailment. Note also logic-based paraphrasing textual entailmentmethods may actually represent interrogatives free variables, instead fresh constants,may rely unification obtain values (Moldovan & Rus, 2001; Rinaldi, Dowdall, Kaljurand,Hess, & Molla, 2003).1.3 Classification Paraphrasing Textual Entailment Methodssix workshops paraphrasing and/or textual entailment (Sato & Nakagawa, 2001;Inui & Hermjakob, 2003; Dolan & Dagan, 2005; Drass & Yamamoto, 2005; Sekine, Inui, Dagan,Dolan, Giampiccolo, & Magnini, 2007; Callison-Burch, Dagan, Manning, Pennacchiotti, & Zanzotto, 2009) recent years.7 Recognizing Textual Entailment (RTE) challenges (Dagan et al.,2006; Bar-Haim et al., 2006; Giampiccolo, Magnini, Dagan, & Dolan, 2007; Giampiccolo, Dang,7proceedings five recent workshops available ACL Anthology.140fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSMagnini, Dagan, & Dolan, 2008), currently fifth year, provide additional significant thrust.8Consequently, large number published articles, proposed methods, resources related paraphrasing textual entailment.9 special issue textual entailment also recentlypublished, editorial provides brief overview textual entailment methods (Dagan, Dolan,Magnini, & Roth, 2009).10 best knowledge, however, present article firstextensive survey paraphrasing textual entailment.provide clearer view different goals assumptions methodsproposed, classify along two dimensions: whether paraphrasing textual entailment methods; whether perform recognition, generation, extraction paraphrasestextual entailment pairs. distinctions always clear literature, especiallydistinctions along second dimension, explain below. also possible classifymethods along dimensions, example depending whether operate language expressions templates; whether operate phrases, sentences longer texts.main input paraphrase textual entailment recognizer pair language expressions(or templates), possibly particular contexts. output judgement, possibly probabilistic, indicating whether members input pair paraphrases correct textual entailmentpair; judgements must agree much possible humans. hand,main input paraphrase textual entailment generator single language expression (or template) time, possibly particular context. output set paraphrases input,set language expressions entail entailed input; output set must largepossible, including errors possible. contrast, particular language expressionstemplates provided paraphrase textual entailment extractor. main inputcase corpus, example monolingual corpus parallel comparable texts, differentEnglish translations French novel, clusters multiple monolingual news articles,articles cluster reporting event. system outputs pairs paraphrases(possibly templates), pairs language expressions (or templates) constitute correct textualentailment pairs, based evidence corpus; goal produce many outputpairs possible, errors possible. Note boundaries recognizers, generators, extractors may always clear. example, paraphrase generator may invokeparaphrase recognizer filter erroneous candidate paraphrases; recognizer generatormay consult collection template pairs produced extractor.note articles reporting actual applications paraphrasing textual entailment methods larger systems (e.g., QA, information extraction, machine translation, discussedSection 1.1) currently relatively few, compared number articles propose new paraphrasing textual entailment methods test vitro, despite fact articlessecond kind often point possible applications methods propose. relativelysmall number application articles may indicator paraphrasing textual entailmentmethods used extensively larger systems yet. believe may due leasttwo reasons. First, efficiency methods needs improved, may require combining recognition, generation, extraction methods, example iteratively producetraining data; return point following sections. Second, literature paraphrasing8 RTEchallenges initially organized European PASCAL Network Excellence, subsequentlypart NISTs Text Analysis Conference.9 textual entailment portal established, part ACL wiki, help organize relevant material.10 slides Dagan, Roth, Zazottos ACL 2007 tutorial textual entailment also publicly available.141fiA NDROUTSOPOULOS & ALAKASIOTIStextual entailment vast, makes difficult researchers working larger systemsassimilate key concepts identify suitable methods. hope article help addresssecond problem, also acting introduction may help new researchers improveparaphrasing textual entailment methods further.Sections 2, 3, 4 consider turn recognition, generation, extraction methodsparaphrasing textual entailment. three sections, attempt identifyexplain prominent ideas, pointing also relevant articles resources. Section 5,conclude discuss possible directions future research. URLs publicly availableresources mention listed appendix A.2. Paraphrase Textual Entailment RecognitionParaphrase textual entailment recognizers judge whether two given language expressions(or templates) constitute paraphrases correct textual entailment pair. Different methods mayoperate different levels representation input expressions; example, may treatinput expressions simply surface strings, may operate syntactic semantic representations input expressions, representations combining information different levels.2.1 Logic-based Approaches RecognitionOne possibility map language expressions logical meaning representations,rely logical entailment checks, possibly invoking theorem provers (Rinaldi et al., 2003; Bos& Markert, 2005; Tatu & Moldovan, 2005, 2007). case textual entailment, involvesgenerating pairs formulae hT , H H (or possible readings), checking(T B) |= H , B contains meaning postulates common sense knowledge, alreadydiscussed. practice, however, may difficult formulate reasonably complete B.partial solution problem obtain common sense knowledge resources like WordNet(Fellbaum, 1998) Extended WordNet (Moldovan & Rus, 2001). latter also includes logicalmeaning representations extracted WordNets glosses. example, since assassinatehyponym (more specific sense) kill WordNet, axiom like following added B(Moldovan & Rus, 2001; Bos & Markert, 2005; Tatu & Moldovan, 2007).x assassinate(x, y) kill(x, y)Additional axioms obtained FrameNets frames (Baker, Fillmore, & Lowe, 1998;Lonneker-Rodman & Baker, 2009), discussed example Tatu et al. (2005), similar resources. Roughly speaking, frame representation prototypical situation (e.g., purchase), also identifies situations main roles (e.g., buyer, entity bought), typesentities (e.g., person) play roles, possibly relations (e.g., causation, inheritance)prototypical situations (other frames). VerbNet (Schuler, 2005) also specifies, amonginformation, semantic frames English verbs. On-line encyclopedias also used obtain background knowledge extracting particular types information (e.g., is-a relationships)articles (Iftene & Balahur-Dobrescu, 2007).Another approach use particular B (meaning postulates common sense knowledge),measure difficult satisfy H , case textual entailment recognition, compared satisfying own. possible measure difference size142fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSminimum model satisfies H , compared size minimum modelsatisfies (Bos & Markert, 2005); intuitively, model assignment entities,relations etc. terms, predicate names, domain-dependent atomic symbols. greaterdifference knowledge required B (T B) |= H hold, difficultbecomes speakers accept textually entails H. Similar bidirectional logical entailmentchecks used recognize paraphrases (Rinaldi et al., 2003).2.2 Recognition Approaches Use Vector Space Models Semanticsalternative using logical meaning representations start mapping wordinput language expressions vector shows strongly word cooccurs particularwords corpora (Lin, 1998b), possibly also taking account syntactic information,example requiring cooccurring words participate particular syntactic dependencies (Pado& Lapata, 2007). compositional vector-based meaning representation theory usedcombine vectors single words, eventually mapping one two input expressionssingle vector attempts capture meaning; simplest case, vector expressioncould sum product vectors words, elaborate approaches alsoproposed (Mitchell & Lapata, 2008; Erk & Pado, 2009; Clarke, 2009). Paraphrasesdetected measuring distance vectors two input expressions, examplecomputing cosine similarity. See also work Turney Pantel (2010) surveyvector space models semantics.Recognition approaches based vector space models semantics appear explored much less approaches discussed article, mostly paraphrase recognition (Erk & Pado, 2009). could also used textual entailment recognition, however,checking vector H particularly close part (e.g., phrase sentence) . Intuitively, would check H says included says, though must carefulnegations expressions preserve truth values (Zaenen et al., 2005; MacCartney& Manning, 2009), (29)(30). return idea matching H part below.(29)(30): denied BigCo bought SmallCo.H: BigCo bought SmallCo.2.3 Recognition Approaches Based Surface String SimilaritySeveral paraphrase recognition methods operate directly input surface strings, possiblyapplying pre-processing, part-of-speech (POS) tagging named-entity recognition,without computing elaborate syntactic semantic representations. example,may compute string edit distance (Levenshtein, 1966) two input strings, numbercommon words, combinations several string similarity measures (Malakasiotis & Androutsopoulos, 2007), including measures originating machine translation evaluation (Finch,Hwang, & Sumita, 2005; Perez & Alfonseca, 2005; Zhang & Patrick, 2005; Wan, Dras, Dale, &Paris, 2006). latter developed automatically compare machine-generated translations human-authored reference translations. well known measure BLEU (Papineni,Roukos, Ward, & Zhu, 2002; Zhou et al., 2006a), roughly speaking examines percentageword n-grams (sequences consecutive words) machine-generated translations alsooccur reference translations, takes geometric average percentages obtaineddifferent values n. Although n-gram based measures criticised machine transla143fiA NDROUTSOPOULOS & ALAKASIOTIStion evaluation (Callison-Burch, Osborne, & Koehn, 2006b), example unawaresynonyms longer paraphrases, combined measures build paraphrase (and textual entailment) recognizers (Zhou et al., 2006a; Kauchak & Barzilay, 2006; Padoet al., 2009), may help address problems automated machine translation evaluation.textual entailment recognition, one input language expressions (T ) often much longerone (H). part surface string similar Hs, indicationH may entailed . illustrated (31)(32), H included verbatim .11Note, however, surface string similarity (e.g., measured string edit distance) Hentire example low, different lengths H.(31)(32): Charles de Gaulle died 1970 age eighty. thus fifty years old when, unknown officer recently promoted rank brigadier general, made famous broadcastLondon rejecting capitulation France Nazis debacle May-June 1940.H: Charles de Gaulle died 1970.Comparing H sliding window surface string size H (in example, sixconsecutive words ) keeping largest similarity score sliding windowH may provide better indication whether entails H (Malakasiotis, 2009). manycorrect textual entailment pairs, however, using single sliding window fixed length may stillinadequate, H may correspond several non-continuous parts ; (33)(34),example, H corresponds three underlined parts .12(33)(34): Gaspe, also known la Gaspesie French, North American peninsula south shoreSaint Lawrence River, Quebec.H: Gaspe peninsula Quebec.One possible solution attempt align words (or phrases) H ,consider H correct textual entailment pair sufficiently good alignment found,simplest case large percentage words aligned words H. Another approach woulduse window variable length; window could be, example, shortest spancontains words aligned words H (Burchardt, Pennacchiotti, Thater, &Pinkal, 2009). case, need careful negations expressionspreserve truth values, already mentioned. Note, also, although effective word alignmentmethods developed statistical machine translation (Brown, Della Pietra, Della Pietra,& Mercer, 1993; Vogel, Ney, & Tillmann, 1996; Och & Ney, 2003), often perform poorlytextual entailment pairs, H often different lengths, necessarilyconvey information, textual entailment training datasets much smallerused machine translation; see MacCartney et al.s (2008) work related discussionword alignment method developed especially textual entailment pairs.132.4 Recognition Approaches Based Syntactic SimilarityAnother common approach work syntax level. Dependency grammar parsers (Melcuk,1987; Kubler, McDonald, & Nivre, 2009) popular paraphrasing textual entailment re11 Exampledataset RTE-3 (Giampiccolo et al., 2007).example dataset RTE-3 (Giampiccolo et al., 2007).13 Cohn et al. (2008) discuss publicly available corpus manually word-aligned paraphrases constructed.word-aligned paraphrasing textual entailment datasets found ACL Textual Entailment Portal.12 Modified144fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSmathematician solved problem problem solved young mathematiciansolvedsubjsolvedobjobj auxmathematicianproblemproblemdetdetdetmathematiciandetmodyoungFigure 1: Two sentences similar viewed level dependency trees.search, natural language processing areas recently. Instead showing hierarchicallysyntactic constituents (e.g., noun phrases, verb phrases) sentence, output dependencygrammar parser graph (usually tree) whose nodes words sentence whose(labeled) edges correspond syntactic dependencies words, example dependencyverb head noun subject noun phrase, dependency nounadjective modifies it. Figure 1 shows dependency trees two sentences. exactform trees edge labels would differ, depending parser; simplicity, showprepositions edges. ignore word order auxiliary passive (right) sentence, take account edge passive sentence corresponds subjedge active (left) one, difference extra adjective passive sentence. Hence,easy figure dependency trees two sentences similar meanings,despite differences word order. Strictly speaking, right sentence textually entails leftone, reverse, word young right sentence.paraphrase recognizers simply count common edges dependency treesinput expressions (Wan et al., 2006; Malakasiotis, 2009) use tree similarity measures.large similarity score (e.g., threshold) indicates input expressions may paraphrases. Tree edit distance (Selkow, 1977; Tai, 1979; Zhang & Shasha, 1989) another examplesimilarity measure applied dependency parse trees; computes sequence operator applications (e.g., add, replace, remove node edge) minimumcost turns one tree other.14 obtain accurate predictions, important deviseappropriate inventory operators assign appropriate costs operators trainingstage (Kouylekov & Magnini, 2005; Mehdad, 2009; Harmeling, 2009). example, replacingnoun one synonyms less costly replacing unrelated word;removing dependency verb adverb perhaps less costly removingdependency verb head noun subject object.textual entailment recognition, one may compare Hs parse tree subtrees parsetree (Iftene & Balahur-Dobrescu, 2007; Zanzotto, Pennacchiotti, & Moschitti, 2009). maypossible match Hs tree single subtree , effect single syntactic window ,illustrated Figure 2, shows dependency trees (33)(34); recall (34)match single window (33) surface string level.15 also exampleoperating higher level surface strings may reveal similarities may less clear lower14 EDITS ,15 Figuresuite recognize textual entailment computing edit distances, publicly available.2 based output Stanfords parser. One might argue North modify American.145fiA NDROUTSOPOULOS & ALAKASIOTISpeninsulasubjGaspedetauxdetmodmodNorthmodAmericanmodknownmodmodalsoobjobjNorthQuebecdet mod modsouthobjobjGaspesieRivermodlamoddet mod modmodSaintLawrenceobjFrenchFigure 2: example dependency treespeninsulamay make easier match short sentence (subsubjauxmod one.tree inside dashed line) part detlongerGaspeobjdetlevels. Another example (35)(36);although (35) includesQuebecverbatim (36), textuallyentail (36).16 clear one compares syntactic representations two sentences:Israel subject established (36), (35). difference, however,evident surface string level, sliding window (35) would match exactly (36), wronglysuggesting textual entailment.(35)(36): National Institute Psychobiology Israel established 1979.H: Israel established 1979.Similar arguments made favour computing similarities semantic level (Qiu,Kan, & Chua, 2006); example, active passive forms sentence may mappedlogical formula, making similarity clearer surface syntax level.syntactic semantic representations input expressions, however, cannot always computedaccurately (e.g., due parser errors), may introduce noise; and, possiblynoise, methods operate syntactic semantic level necessarily outperformpractice methods operate surface strings (Wan et al., 2006; Burchardt, Reiter, Thater, &Frank, 2007; Burchardt et al., 2009).2.5 Recognition via Similarity Measures Operating Symbolic Meaning RepresentationsParaphrases may also recognized computing similarity measures graphs whose edgescorrespond syntactic dependencies, reflect semantic relations mentioned input expressions (Haghighi, 2005), example relation buyer entity bought. Relations kind may identified applying semantic role labeling methods (Marquez, Carreras,16 Modifiedexample Haghighi et al.s (2005) work.146fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSLitkowski, & Stevenson, 2008) input language expressions. also possible computesimilarities meaning representations based FrameNets frames (Burchardt et al.,2007). latter approach advantage semantically related expressions may invokeframe (as announcement, announce, acknowledge) interconnected frames (e.g.,FrameNet links frame invoked arrest frame invoked trial via path temporal precedence relations), making similarities implications easier capture (Burchardt et al.,2009).17 prototypical semantic roles PropBank (Palmer, Gildea, & Kingsbury, 2005) associates verb may also used similar manner, instead FrameNets frames. Similarly,case textual entailment recognition, one may compare Hs semantic representation (e.g.,semantic graph frame) parts representation.WordNet (Fellbaum, 1998), automatically constructed collections near synonyms (Lin, 1998a;Moore, 2001; Brockett & Dolan, 2005), resources like NOMLEX (Meyers, Macleod, Yangarber,Grishman, Barrett, & Reeves, 1998) C VAR (Habash & Dorr, 2003) provide nominalizations verbs derivationally related words across different POS categories (e.g., inventinvention), used match synonyms, hypernymshyponyms, or, generally, semantically related words across two input expressions. According WordNet, (37)(38)shares direct hyponym (more specific meaning) stock, slumped direct hyponymdropped, company indirect hyponym (two levels down) organization.18treating semantically similar words (e.g., synonyms, hypernyms-hyponyms small hierarchical distance) identical (Rinaldi et al., 2003; Finch et al., 2005; Tatu, Iles, Slavick, Novischi, &Moldovan, 2006; Iftene & Balahur-Dobrescu, 2007; Malakasiotis, 2009; Harmeling, 2009),considering (e.g., counting) semantically similar words across two input language expressions(Brockett & Dolan, 2005; Bos & Markert, 2005), paraphrase recognizers may able copeparaphrases similar meanings, common words.(37)(38)shares company dropped.organizations stock slumped.textual entailment recognition, may desirable allow words distanthyponyms words H, compared paraphrase recognition. example, X computertextually entails X artifact, computer hyponym artifact four levels down.Measures exploit WordNet (or similar resources) compute semantic similaritytwo words or, generally, two texts also proposed (Leacock, Miller, &Chodorow, 1998; Lin, 1998c; Resnik, 1999; Budanitsky & Hirst, 2006; Tsatsaronis, Varlamis, &Vazirgiannis, 2010).19 directional, making suitable textual entailment recognition (Corley & Mihalcea, 2005). Roughly speaking, measures kind consider(e.g., sum lengths of) paths WordNets hierarchies (or similar resources) connectsenses corresponding (e.g., similar) words across two texts. may also takeaccount information frequencies words two texts rarelyencountered documents large collection (inverse document frequency). rationalefrequent words input texts rarely used general corpus important,17 Consult,example, work Erk Pado (2006) description system annotate textsFrameNet frames. FATE corpus (Burchardt & Pennacchiotti, 2008), version RTE 2 test set (Bar-Haim et al.,2006) FrameNet annotations, publicly available.18 Modified example work Tsatsaronis (2009)19 Pedersens WordNet::Similarity package implements many measures.147fiA NDROUTSOPOULOS & ALAKASIOTISTraining stage(P1,1, P2,1) X(P1,2, P2,2)(P1,n, P2,n)<f1,1, , fm,1> X<f1,2, , fm,2><f1,n, , fm,n>Vector creationPreprocessingLearningAlgorithmTrainedClassifierClassification stage(P1, P2) ?<f1, , fm> ?Vector creationTrainedClassifierPreprocessingDecision:Figure 3: Paraphrase textual entailment recognition via supervised machine learning.information retrieval; hence, paths connect assigned greater weights. Sinceoften consider paths word senses, many measures would ideally combinedword sense disambiguation (Yarowski, 2000; Stevenson & Wilks, 2003; Kohomban & Lee,2005; Navigli, 2008), not, however, always accurate enough practical purposes.2.6 Recognition Approaches Employ Machine LearningMultiple similarity measures, possibly computed different levels (surface strings, syntacticsemantic representations) may combined using machine learning (Mitchell, 1997; Alpaydin, 2004), illustrated Figure 3.20 pair input language expressions hP1 , P2 i, i.e.,pair expressions wish check paraphrases correct textual entailment pair,represented feature vector h f1 , . . . , fm i. vector contains scores multiple similarity measures applied pair, possibly features. example, many systems alsoinclude features check polarity differences across two input expressions,confirmed case rabies vs. case rabies confirmed, modality differences,case may confirmed vs. case confirmed (Haghighi, 2005; Iftene &Balahur-Dobrescu, 2007; Tatu & Moldovan, 2007). Bos Markert (2005) also include featuresindicating theorem prover managed prove logical representation oneinput expressions entails contradicts it. supervised machine learning algorithm trainsclassifier manually classified (as correct incorrect) vectors corresponding training inputpairs. trained, classifier classify unseen pairs correct incorrect paraphrasestextual entailment pairs examining features (Bos & Markert, 2005; Brockett & Dolan, 2005;Zhang & Patrick, 2005; Finch et al., 2005; Wan et al., 2006; Burchardt et al., 2007; Hickl, 2008;Malakasiotis, 2009; Nielsen et al., 2009).preprocessing stage commonly applied input pair language expressions,converting feature vector (Zhang & Patrick, 2005). Part preprocessing may provide20 WEKA (Witten & Frank, 2005) provides implementations several well known machine learning algorithms, including C 4.5 (Quinlan, 1993), Naive Bayes (Mitchell, 1997), SVMs (Vapnik, 1998; Cristianini & Shawe-Taylor, 2000;Joachims, 2002), AdaBoost (Freund & Schapire, 1995; Friedman, Hastie, & Tibshirani, 2000). efficient implementations SVMs, LIBSVM SVM - LIGHT, also available. Maximum Entropy classifiers alsoeffective; see chapter 6 book Speech Language Processing (Jurafsky & Martin, 2008) introduction;Stanfords implementation frequently used.148fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSinformation required compute features; example, POS taggerparser would applied.21 preprocessing may also normalize input pairs; example,stemmer may applied; dates may converted consistent format; names persons, organizations, locations etc. may tagged semantic categories using named entity recognizer;pronouns or, generally, referring expressions, may replaced expressions refer(Hobbs, 1986; Lappin & Leass, 1994; Mitkov, 2003; Molla, Schwitter, Rinaldi, Dowdall, & Hess,2003; Yang, Su, & Tan, 2008); morphosyntactic variations may normalized (e.g., passivesentences may converted active ones).22Instead mapping hP1 , P2 pair feature vector contains mostly scores measuring similarity P1 P2 , possible use vectors encode directly parts P1P2 , parts syntactic semantic representations. Zanzotto et al. (2009) projecthP1 , P2 pair vector that, roughly speaking, contains features fragments P1 P2parse trees. Leaf nodes corresponding identical similar words (according WordNetbased similarity measure) across P1 P2 replaced co-indexed slots, allow featuresgeneral. Zanzotto et al. define measure (actually, different versions it) that, effect, computes similarity two pairs hP1 , P2 hP10 , P20 counting parse tree fragments(features) shared P1 P10 , shared P2 P20 . measure usedkernel Support Vector Machine (SVM) learns separate positive textual entailment pairshP1 , P2 = hT, Hi negative ones. (valid) kernel thought similarity measureprojects two objects highly dimensional vector space, computes inner productprojected objects; efficient kernels compute inner product directly original objects,without computing projections highly dimensional vector space (Vapnik, 1998; Cristianini & Shawe-Taylor, 2000; Joachims, 2002). Zanzotto et al.s work, object hT, Hipair, projection vector contains parse tree fragments H features.Consult, example, work Zanzotto Dell Arciprete (2009) Moschitti (2009)discussion kernels used paraphrase textual entailment recognition.2.7 Recognition Approaches Based DecodingPairs paraphrasing textual entailment expressions (or templates) like (39), often called rules,may produced extraction mechanisms (to discussed Section 4) usedrecognizers much as, often addition synonyms hypernyms-hyponyms.(39)X fond X likesGiven paraphrasing rule (39) information child synonym kidcandy hyponym sweet, recognizer could figure (40) textually entails (43)gradually transforming (40) (43) shown below.23(40)Children fond sweets.21 Brills (1992) POS tagger well-known publicly available. Stanfords tagger (Toutanova, Klein, Manning, &Singer, 2003) another example publicly available POS tagger. Commonly used parsers include Charniaks (2000),Collins (2003), Link Grammar Parser (Sleator & Temperley, 1993), MINIPAR, principle-based parser (Berwick,1991) similar PRINCIPAR (Lin, 1994), MaltParser (Nivre, Hall, Nilsson, Chanev, Eryigit, Kuebler, Marinov, &Marsi, 2007), Stanfords parser (Klein & Manning, 2003).22 Porters stemmer (1997) well-known. example publicly available named-entity recognizer Stanfords.23 Modified example Bar-Haim et al.s (2009) work.149fiA NDROUTSOPOULOS & ALAKASIOTIS(41)(42)(43)Kids fond sweets.Kids like sweets.Kids like candies.Another recognition approach, then, search sequence rule applicationstransformations (e.g., replacing synonyms, hypernyms-hyponyms) turns one inputexpressions (or syntactic semantic representation) other. call search decoding,similar decoding stage machine translation (to discussed Section 3),sequence transformations turns source-language expression target-languageexpression sought. case, sequence found, two input expressions constitutepositive paraphrasing textual entailment pair, depending rules used; otherwise, pairnegative. rule associated confidence score (possibly learnt training dataset)reflects degree rule preserves original meaning paraphrase recognition,degree confident produces entailed expression, may searchsequence transformations maximum score (or minimum cost), much approachescompute minimum (string tree) edit distance two input expressions. pairinput expressions classified positive maximum-score sequence exceedsconfidence threshold (Harmeling, 2009). One would also consider contexts rulesapplied, rule may valid contexts, instance differentpossible senses words involves. possible solution associate rule vectorrepresents contexts used (e.g., vector frequently occurring wordstraining contexts rule applies), use rule contexts similarassociated context vector; slotted rules, one also model types slot values (e.g., typesnamed entities) rule used work Pantel, Bhagat, Coppola, Chklovski,Hovy (2007), Szpektor, Dagan, Bar-Haim, Goldberger (2008).Resouces like WordNet extraction methods, however, provide thousands millions rules,giving rise exponentially large number transformation sequences consider.24operating level semantic representations, sequence sought effect prooftwo input expressions paraphrases valid textual entailment pair, may obtainedexploiting theorem provers, discussed earlier. Bar-Haim et al. (2007) discuss searchsequences transformations, seen proofs syntactic level, input languageexpressions reformulations represented dependency trees. subsequent work (BarHaim et al., 2009), introduce compact forests, data structure allows dependency treesmultiple intermediate reformulations represented single graph, make searchefficient. also combine approach SVM-based recognizer; sequencestransformations used bring closer H, SVM recognizer employed judgetransformed H consitute positive textual entailment pair not.2.8 Evaluating Recognition MethodsExperimenting paraphase textual entailment recognizers requires datasets containingpositive negative input pairs. using discriminative classifiers (e.g., SVMs), negativetraining pairs must ideally near misses, otherwise may little use (Schohn & Cohn,2000; Tong & Koller, 2002). Near misses also make test data challenging.24 Collections transformation rules resources used obtain rules listed ACL TextualEntailment Portal. Mirkin et al. (2009a) discuss evaluate collections textual entailment rules.150fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSmethodCorley & Mihalcea (2005)Das & Smith (2009)Finch et al. (2005)Malakasiotis (2009)Qiu et al. (2006)Wan et al. (2006)Zhang & Patrick (2005)BASE 1BASE 2accuracy (%)71.576.175.076.272.075.671.966.569.0precision (%)72.379.676.679.472.577.074.366.572.4recall (%)92.586.189.886.893.490.088.2100.086.3F-measure (%)81.282.982.782.981.683.080.779.978.8Table 1: Paraphrase recognition results MSR corpus.widely used benchmark dataset paraphrase recognition Microsoft Research(MSR) Paraphrase Corpus. contains 5,801 pairs sentences obtained clusters online newsarticles referring events (Dolan, Quirk, & Brockett, 2004; Dolan & Brockett, 2005).pairs initially filtered heuristics, require, example, word edit distancetwo sentences pair neither small (to avoid nearly identical sentences)large (to avoid many negative pairs); sentences among first threearticles cluster (articles referring event), rationale initialsentences often summarize events. candidate paraphrase pairs filteredSVM -based paraphrase recognizer (Brockett & Dolan, 2005), trained separate manually classifiedpairs obtained similar manner, biased overidentify paraphrases. Finally, humanjudges annotated remaining sentence pairs paraphrases not. resolving disagreements,approximately 67% 5,801 pairs judged paraphrases. dataset dividedtwo non-overlapping parts, training (30% pairs) testing (70%). Zhang Patrick(2005) others pointed heuristics used construct corpus maybiased towards particular types paraphrases, excluding example paraphrasesshare common words.Table 1 lists published results paraphrase recognition experiments MSR corpusaware of. include two baselines used: BASE1 classifies pairs paraphrases;BASE 2 classifies two sentences paraphrases surface word edit distancethreshold, tuned training part corpus. Four commonly used evaluation measuresused: accuracy, precision, recall, F-measure equal weight precision recall.measures defined below. TP (true positives) FP (false positives) numbers pairscorrectly incorrectly, respectively, classified positive (paraphrases). TN (truenegatives) FN (false negatives) numbers pairs correctly incorrectly,respectively, classified negative (not paraphrases).precision =accuracy =TPTP+FP ,recall =TP+TNTP+TN+FP+FN ,F-measure =TPTP+FN ,2precisionrecallprecision+recallsystems Table 1 better recall precision, implies tend over-classifypairs paraphrases, possibly sentences pair least common wordsrefer event. Systems higher recall tend lower precision, vice versa,one would expect. high F-measure BASE1 largely due perfect recall; precision151fiA NDROUTSOPOULOS & ALAKASIOTISmethodBensley & Hickl (2008)Iftene (2008)Siblini & Kosseim (2008)Wang & Neumann (2008)BASE 1BASE 2accuracy (%)74.672.168.870.650.054.9precision (%)65.550.053.6recall (%)93.2100.073.6F-measure (%)76.966.762.0Table 2: Textual entailment recognition results (for two classes) RTE-4 corpus.significantly lower, compared systems. BASE2 , uses string edit distance,competitive baseline corpus. Space permit listing published evaluation resultsparaphrase recognition methods discussed. Furthermore, comparing resultsobtained different datasets always meaningful.textual entailment recognition, widely used benchmarks RTE challenges. example, RTE-3 corpus contains 1,600 hT, Hi pairs (positive negative). Fourapplication scenarios textual entailment recognition might useful considered: information extraction, information retrieval, question answering, summarization. 200training 200 testing pairs scenario; Dagan et al. (2009) explain constructed. RTE-4 corpus constructed similar way, contains test pairs, 250four scenarios. difference RTE-4 judges classified pairsthree classes: true entailment pairs, false entailment pairs H contradicts (Harabagiu, Hickl,& Lacatusu, 2006; de Marneffe, Rafferty, & Manning, 2008), false pairs readinglead conclusion H; similar pilot task included RTE-3 (Voorhees, 2008).pairs latter two classes merged, two classes (true false) desirable.also note RTE-3 included pilot task requiring systems justify answers. Manyparticipants, however, used technical mathematical terminology explanations,always appreciated human judges; also, entailments often obviousjudges, extent justification considered necessary (Voorhees, 2008). Table 2 listsbest accuracy results RTE-4 participants (for two classes only), along results twobaselines described previously; precision, recall, F-measure scores also shown, available. four measures defined paraphrase recognition, positives negativestextual entailment pairs.25 Again, space permit listing published evaluation resultstextual entailment recognition methods discussed, comparing results obtaineddifferent datasets always meaningful.also possible evaluate recognition methods indirectly, measuring impactperformance larger natural language processing systems (Section 1.1). instance, one couldmeasure difference performance QA system, degree redundancygenerated summary reduced using paraphrase and/or textual entailment recognizers.25 Average precision, borrowed information retrieval evaluation, also used RTE challenges.Bergmair (2009), however, argues using RTE challenges proposes alternative measures.152fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS3. Paraphrase Textual Entailment GenerationUnlike recognizers, paraphrase textual entailment generators given single language expression (or template) input, required produce many output language expressions(or templates) possible, output expressions paraphrases constitute, alonginput, correct textual entailment pairs. generators assume input singlesentence (or sentence template), adopt assumption remainder section.3.1 Generation Methods Inspired Statistical Machine TranslationMany generation methods borrow ideas statistical machine translation (SMT).26 Let us first introduce central ideas SMT, benefit readers unfamiliar them. SMT methodsrely large bilingual multilingual parallel corpora, example proceedings European parliament, without constructing meaning representations often, least recently,without even constructing syntactic representations.27 Let us assume wish translatesentence F, whose words f1 , f2 , . . . , f|F| order, foreign language native language. Let us also denote N candidate translation, whose words a1 , a2 , . . . , a|N| . besttranslation, denoted N , N maximum probability translation F, i.e:N = arg max P(N|F) = arg maxNNP(N)P(F|N)= arg max P(N)P(F|N)NP(F)(44)Since F fixed, denominator P(F) constant ignored searchingN . P(N) called language model P(F|N) translation model.modeling purposes, common assume F fact originally written nativelanguage transmitted us via noisy channel, introduced various deformations.possible deformations may include, example, replacing native word oneforeign ones, removing inserting words, moving words left right etc. commonlyused IBM models 1 5 (Brown et al., 1993) provide increasingly richer inventory worddeformations; recent phrase-based SMT systems (Koehn, Och, & Marcu, 2003) also allowdirectly replacing entire phrases phrases.foreign sentenceff F thus seenresult applying sequence transformations = d1 , d2 , . . . , d|D| N, commonsearch N maximizes (45); search called decoding.N = arg max P(N) max P(F, D|N)N(45)exhaustive search usually intractable. Hence, heuristic search algorithms (e.g., based beamsearch) usually employed (Germann, Jahr, Knight, Marcu, & Yamada, 2001; Koehn, 2004).28Assuming simplicity individual deformations di () mutually independent,P(F, D|N) computed product probabilities Ds individual deformations. Givenbilingual parallel corpus words aligned across languages, estimate probabilities26introduction SMT, see chapter 25 book Speech Language Processing (Jurafsky & Martin,2008), chapter 13 book Foundations Statistical Natural Language Processing (Manning & Schuetze,1999). extensive discussion, consult work Koehn (2009).27 See Koehns Statistical Machine Translation site commonly used SMT corpora tools.28 frequently used SMT system includes decoding facilities Moses.153fiA NDROUTSOPOULOS & ALAKASIOTISpossible deformations di (). practice, however, parallel corpora indicate word alignment. Hence, common find probable word alignment corpus given initialestimates individual deformation probabilities, re-estimate deformation probabilitiesgiven resulting alignment, iterate (Brown et al., 1993; Och & Ney, 2003).29translation model P(F, D|N) estimates probability obtaining F N via D;interested Ns high probabilities leading F. also want, however, N grammatical, use language model P(N) check grammaticality. P(N) probabilityencountering N native language; estimated large monolingual corpuslanguage, typically assuming probability encountering word ai depends preceding n 1 words. n = 3, P(N) becomes:P(N) = P(a1 ) P(a2 |a1 ) P(a3 |a1 , a2 ) P(a4 |a2 , a3 ) P(a|N| |a|N|2 , a|N|1 )(46)language model typically also includes smoothening mechanisms, cope n-gramsrare present monolingual corpus, would lead P(N) = 0.30principle, SMT system could used generate paraphrases, could trainedsufficiently large monolingual corpus parallel texts. N F sentenceslanguage, N different given F, convey (or almostsame) information. main problem readily available monolingual parallelcorpora sizes used SMT, train language model them. One possibilityuse multiple translations source texts; example, different English translationsnovels originally written languages (Barzilay & McKeown, 2001), multiple Englishtranslations Chinese news articles, Multiple-Translation Chinese Corpus. Corporakind, however, still orders magnitude smaller used SMT.bypass lack large monolingual parallel corpora, Quirk et al. (2004) use clustersnews articles referring event. articles cluster always reportinformation and, hence, parallel texts. Since talk event, however,often contain phrases, sentences, even longer fragments similar meanings; corporakind often called comparable. cluster, Quirk et al. select pairs similarsentences (e.g., small word edit distance, identical sentences) using methods likeemployed create MSR corpus (Section 2.8).31 sentence pairs word alignedmachine translation, resulting alignments used create table phrase pairsphrase-based SMT systems (Koehn et al., 2003). phrase pair hP1 , P2 consists contiguouswords (taken phrase, though necessarily syntactic constituent) P1 one sentencealigned different contiguous words P2 another sentence. Quirk et al. provide followingexamples discovered pairs.29 GIZA ++often used train IBM models align words.chapter 4 book Speech Language Processing (Jurafsky & Martin, 2008) chapter 6 bookFoundations Statistical Natural Language Processing (Manning & Schuetze, 1999) introduction languagemodels. SRILM (Stolcke, 2002) commonly used tool create language models.31 Wubben et al. (2009) discuss similar methods pair news titles. Barzilay & Elhadad (2003) Nelken & Shieber(2006) discuss general methods align sentences monolingual comparable corpora. Sentence alignment methodsbilingual parallel comparable corpora discussed, example, Gale Church (1993), Melamed (1999),Fung Cheung (2004), Munteanu Marcu (2006); see also work Wu (2000). Sentence alignment methodsparallel corpora may perform poorly comparable corpora (Nelken & Shieber, 2006).30 See154fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSP1P2injuredBush administrationmargin error...woundedWhite Houseerror margin...Phrase pairs occur frequently aligned sentences may assigned higher probabilities; Quirk et al. use probabilities returned IBM model 1. decoder first constructs latticerepresents possible paraphrases input sentence produced replacingphrases counterparts phrase table; i.e., possible deformations di () phrasereplacements licensed phrase table.32 Unlike machine translation, wordsphrases need replaced, Quirk et al. also allow degenerate identity deformation ( ) = ; assigning high probability identity deformation leads conservativeparaphrases, fewer phrase replacements. decoder uses probabilities di () compute P(F, D|N) equation (45), language model compute P(N). best scored Nreturned paraphrase F; n highly scored Ns could also returned. generally,table phrase pairs may also include synonyms obtained WordNet similar resources,pairs paraphrases (or templates) discovered paraphrase extraction methods; effect, Quirket al.s construction monolingual phrase table paraphrase extraction method. languagemodel may also applied locally replacement words deformation contextassess whether new words fit original context (Mirkin et al., 2009b).Zhao et al. (2008, 2009) demonstrated combining phrase tables derived multiple resources improves paraphrase generation. also proposed scoring candidate paraphrasesusing additional, application-dependent model, called usability model; example,sentence compression (Section 1.1) usability model rewards Ns fewer words F.Equation (45) becomes (47), U(F, N) usability model weights assignedthree models; similar weights used (45).N = arg max U(F, N)1 P(N)2 max P(F, D|N)3N(47)Zhao et al. actually use log-linear formulation (47); select weights maximize objective function rewards many correct (as judged human evaluators) phrasalreplacements.33 One may replace translation model paraphrase recognizer (Section 2)returns confidence score; log-linear formulation, (47) becomes (48), R(F, N)confidence score recognizer.N = arg max[1 logU(F, N) + 2 log P(N) + 3 logR(F, N)]N(48)Including hyponyms-hypernyms textual entailment rules (Section 2.7) phrase tablewould generate sentences N textually entail entailed (depending direction32 Cheveluet al. (2009) discuss decoders could developed especially paraphrase generation.reluctant paraphrasing setting (Dras, 1998), example revising document satisfy length requirements, readability measures, externally imposed constraints, may desirable use objective functionrewards making changes possible, provided constraints satisfied. Dras (1998) discusses formulationproblem terms integer programming.33155fiA NDROUTSOPOULOS & ALAKASIOTISrules whether replace hyponyms hypernyms reverse) F. SMT-inspired methods,however, used mostly paraphrase generation, textual entailment generation.Paraphrases also generated using pairs machine translation systems translateinput expression new language, often called pivot language, back originallanguage. resulting expression often different input one, especially twotranslation systems employ different methods. using different pairs machine translation systems different pivot languages, multiple paraphrases may obtained. Duboue Chu-Carroll(2006) demonstrated benefit using approach paraphrase questions, additionalmachine learning classifier filter generated paraphrases; classifier uses featurescosine similarity candidate generated paraphrase original question, lengthscandidate paraphrase original question, features showing whether questions type (e.g., asking person name), etc. advantage approachmachine translation systems treated black boxes, trainedreadily available parallel corpora different languages. disadvantage translation errorsdirections may lead poor paraphrases. return pivot languages Section 4.principle, output generator may produced mapping input representationmeaning, process usually presupposes parsing, passing meaning representation, new meaning representations logically entailed original one, naturallanguage generation system (Reiter & Dale, 2000; Bateman & Zock, 2003) produce paraphrasesentailed language expressions. approach would similar using language-independentmeaning representations (an interlingua) machine translation, meaning representations would need language-independent, since one language involved. approachsimilar syntactic transfer machine translation may also adopted (McKeown, 1983).case, input language expression (assumed sentence) first parsed. resulting syntactic representation modified ways preserve, affect slightly, original meaning(e.g., turning sentence active passive), ways produce syntactic representationsentailed language expressions (e.g., pruning certain modifiers subordinate clauses). New language expressions generated new syntactic representations, possibly invokingsurface realization components natural language generation system. Parsing, however,input expression may introduce errors, producing correct meaning representation input,required, may far trivial. Furthermore, natural language generator maycapable producing language expressions limited variety, missing possible paraphrasesentailed language expressions. perhaps meaning representation syntactic transferseem currently popular paraphrase textual entailment generation.3.2 Generation Methods Use Bootstrappinginput output expressions slotted templates, possible apply bootstrappinglarge monolingual corpus (e.g., entire Web), instead using machine translation methods.Let us assume, example, wish generate paraphrases (49), givenpairs seed values X , (50) (51).(49)(50)(51)X author .hX = Jack Kerouac,Y = RoadihX = Jules Verne,Y = Mysterious Islandiretrieve corpus sentences contain seed pairs:156fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS(52)(53)(54)Jack Kerouac wrote Road.Mysterious Island written Jules Verne.Jack Kerouac known novel Road.replacing known seeds corresponding slot names, obtain new templates:(55)(56)(57)X wrote .written X.X known novel .example, (55) (56) paraphrases (49); however, (57) textually entails (49),paraphrase (49). want generate paraphrases, must keep (55) (56) only;want generate templates entail (49), must keep (57) too. generated candidatetemplates may neither paraphrases of, entail (or entailed by) original template. goodparaphrase textual entailment recognizer (Section 2) human loop would able filterbad candidate templates; see also Duclaye et al.s (2003) work, Expectation Maximization(Mitchell, 1997) used filter candidate templates. Simpler filtering techniques may alsoused. example, Ravichandran et al. (2002, 2003) assign candidate template pseudoprecision score; roughly speaking, score computed number retrieved sentencesmatch candidate template X values seed pair, dividednumber retrieved sentences match template X seed value value,necessarily corresponding seed value.obtained new templates, search corpus new sentences match them;example, sentence (58) matches generated template (56). new sentences, seedvalues obtained, slot values correspond types expressions (e.g., person names)recognized reasonably well, example using named entity recognizer gazetteer(e.g., large list book titles); (58) would obtain new seed pair (59). iterationsmay used generate templates seeds, templates seedsdiscovered maximum number iterations reached.(58)(59)Frankenstein written Mary Shelley.hX = Mary Shelley,Y = FrankensteiniFigure 4 illustrates bootstrapping paraphrase generator works. Templates textually entailtextually entailed initial template, seed slot values provided,generated similarly, paraphrase recognizer replaced textual entailment recognizer.slot values recognized reliably, also obtain initial seed slot values automatically retrieving directly sentences match original templates identifyingslot values retrieved sentences.34 also given mechanism identify sentencesinterest corpus (e.g., sentences involving particular terms, names known diseasesmedicines), also obtain initial templates automatically, identifying sentencesinterest, identifying slot values (e.g., named entities particular categories) sentences,using contexts slot values initial templates. effect, generation task becomesextraction one, since given corpus, neither initial templates seed slot values.TEASE (Szpektor, Tanev, Dagan, & Coppola, 2004) well-known bootstrapping method34 Seedslot values per semantic relation also obtained databases (Mintz, Bills, Snow, & Jurafsky, 2009).157fiA NDROUTSOPOULOS & ALAKASIOTISkind, produces textual entailment pairs, example pairs like (60)(61), given monolingual (non-parallel) corpus dictionary terms. (60) textually implies (61), examplecontexts like (62)(63), reverse.35(60)(61)(62)(63)X preventsX reduces riskAspirin prevents heart attack.Aspirin reduces heart attack risk.specify directionality produced template pairs, example whether (60)textually entails (61) vice versa, additional mechanisms proposed attemptguess directionality; discuss one mechanism, LEDIR (Bhagat, Pantel, & Hovy, 2007),Section 4.1 below. Although TEASE also used generator, particular input templatesprovided, discuss Section 4.2, along bootstrapping extraction methods,since full form requires initial templates (nor seed slot values). reader remindedboundaries recognizers, generators, extractors always clear.Similar bootstrapping methods used generate information extraction patterns (Riloff& Jones, 1999; Xu, Uszkoreit, & Li, 2007). methods, however, require corpora annotated instances particular types events extracted (Huffman, 1995; Riloff, 1996b;Soderland, Fisher, Aseltine, & Lehnert, 1995; Soderland, 1999; Muslea, 1999; Califf & Mooney,2003), texts mention target events near-miss texts (Riloff, 1996a).Marton et al. (2009) used similar approach, without iterations, generate paraphrasesunknown source language phrases phrase-based SMT system (Section 1.1). unknownphrase, collected contexts phrase occurred monolingual corpus sourcelanguage, searched phrases (candidate paraphrases) corpus occurredcontexts. subsequently produced feature vectors unknown phrasecandidate paraphrases, vector showing often corresponding phrase cooccurredwords. candidate paraphrases ranked similarity vectorsvector unknown phrase. unknown phrases effect replaced bestparaphrases SMT system knew map target language phrases, improvedSMT systems performance.TEASE3.3 Evaluating Generation Methodsgeneration applications, example rephrasing queries QA system (Section 1.1),desirable produce correct outputs (correct paraphrases, expressions constitutecorrect textual entailment pairs along input), also produce many correct outputspossible. two goals correspond high precision recall, respectively. particular inputsi , precision pi recall ri generator defined follows (cf. Section 2.8). TPinumber correct outputs input si , FPi number wrong outputs si , FNinumber outputs si incorrectly generated (missed).pi =TPiTPi +FPi ,ri =TPiTPi +FNiprecision recall scores method set inputs {si } defined usingmicro-averaging macro-averaging:35 Examplework Szpektor et al. (2004).158fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODS<X=Jack Kerouac, Y=On road><X=Jules Verne, Y=The Mysterious Island>Search engine<X=Virginia Wolf, Y=Mrs. Dalloway><X=Mary Shelley, Y=Frankestein>Jack Kerouac wrote roadMysterious Island written Jules VerneJack Kerouac known novel roadIdentify new seedsKnown seeds slotsX wrotewritten XX known novelVirginia Wolf wrote Mrs. DallowayFrankestein written Mary ShelleyX wrotewritten XSearch engineParaphrase RecognizerFigure 4: Generating paraphrases X wrote bootstrapping.macro-precision = pi , macro-recall = rimicro-precision =TPi,(TPi +FPi )micro-recall =TPi(TPi +FNi )case, however, recall cannot computed generation, FNi unknown;numerous correct paraphrases input si may missed, even (ifinfinite) language expressions entail entailed si .36Instead reporting recall, common report (along precision) average numberoutputs, sometimes called yield, defined below, assume n test inputs.better option report yield different precision levels, since usually tradeofftwo figures, controlled parameter tuning (e.g., selecting different valuesthresholds involved methods).yield =1 n(TPi + FPi )n i=1Note use fixed set test inputs {si }, store sets Orefcorrectoutputs reference generation method produces si , treat Orefsetpossible correct outputs may generated si , precision recallcomputed, without human effort new generation method, say M, evaluated.FNi number outputs Orefproduced si M; FPi numberMs outputs si Oref; TPi number Ms outputs si includedrefOi . Callison-Burch et al. (2008) propose evaluation approach kind callparaphrase generation. use phrase alignment heuristics (Och & Ney, 2003; Cohn et al., 2008)36 Accuracy (Section 2.8) also impossible compute case; apart knowing FN , numberoutputs correctly generated (TNi ) infinite.159fiA NDROUTSOPOULOS & ALAKASIOTISobtain aligned phrases (e.g., resign, tender resignation, leave office voluntarily)manually word-aligned sentences meanings (from Multiple-Translation ChineseCorpus). Roughly speaking, use {si } phrases alignments found;refsi , Orefcontains phrases si aligned to. Since Oi , however, contains much fewerphrases possible correct paraphrases si , resulting precision score (possiblypessimistic) lower bound, resulting recall scores measure extent manageddiscover (relatively few) paraphrases Oref, pointed Callison-Burch et al.best knowledge, widely adopted benchmark datasets paraphrasetextual entailment generation, unlike recognition, comparing results obtained differentdatasets always meaningful. lack generation benchmarks probably due factalthough possible assemble large collection input language expressions, practically impossible specify advance numerous (if infinite) correct outputs generatormay produce, already discussed. principle, one could use paraphrase textual entailmentrecognizer automatically judge output generator paraphrase of, forms correctentailment pair corresponding input expression. Current recognizers, however, yetaccurate enough, automatic evaluation measures machine translation (e.g., BLEU, Section2.3) cannot employed, exactly weakness cannot detect paraphrasestextual entailment. alternative, costly solution use human judges, also allowsevaluating aspects outputs, fluency (Zhao et al., 2009), machine translation. One also evaluate performance generator indirectly, measuring impactperformance larger natural language processing systems (Section 1.1).4. Paraphrase Textual Entailment ExtractionUnlike recognition generation methods, extraction methods given particular input language expressions. typically process large corpora extract pairs language expressions(or templates) constitute paraphrases textual entailment pairs. generated pairs storedused subsequently recognizers generators applications (e.g., additional entries phrase tables SMT systems). extraction methods produce pairs sentences (orsentence templates) pairs shorter expressions. Methods discover synonyms, hypernymhyponym pairs or, generally, entailment relations words (Lin, 1998a; Hearst, 1998;Moore, 2001; Glickman & Dagan, 2004; Brockett & Dolan, 2005; Hashimoto, Torisawa, Kuroda,De Saeger, Murata, & Kazama, 2009; Herbelot, 2009) seen performing paraphrasetextual entailment extraction restricted pairs single words.4.1 Extraction Methods Based Distributional Hypothesispossible paraphrase extraction approach store word n-grams occur largemonolingual corpus (e.g., n 5), along left right contexts, consider paraphrases n-grams occur frequently similar contexts. example, n-gram represented vector showing words typically precede follow n-gram, valuesvector indicating strongly word co-occurs n-gram; example, pointwisemutual information values (Manning & Schuetze, 1999) may used. Vector similarity measures,example cosine similarity Lins measure (1998a), employed identify n-grams160fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSoccur similar contexts comparing vectors.37 approach shownviable large monolingual corpora; Pasca Dienes (2005) used Web snapshot approximately billion Web pages; Bhagat Ravichandran (2008) used 150 GB news articlesreported results deteriorate rapidly smaller corpora. Even lightweight linguisticprocessing (e.g., POS tagging, without parsing) performed, processing large datasets requiressignificant processing power, although linear computational complexity possible appropriate hashing context vectors (Bhagat & Ravichandran, 2008). Paraphrasing approacheskind based Harriss Distributional Hypothesis (1964), states words similarcontexts tend similar meanings. bootstrapping methods Section 3.2 basedsimilar hypothesis phrases (or templates) occurring similar contexts (or similar slotvalues) tend similar meanings, hypothesis seen extension Harriss.Lin Pantels (2001) well-known extraction method, called DIRT, also based extended Distributional Hypothesis, operates syntax level. DIRT first applies dependencygrammar parser monolingual corpus. Parsing corpus generally time-consuming and,hence, smaller corpora used, compared methods require parsing; LinPanel used 1 GB news texts experiments. Dependency paths extracteddependency trees corpus. Let us consider, example, sentences (64) (67). dependency trees shown Figure 5; similarity two sentences less obviousFigure 1, different verbs involved. Two dependency pathsextracted trees Figure 5 shown (65) (68). labels edgesaugmented POS-tags words connect (e.g., N:subj:V instead simply subj).38first last words extracted paths replaced slots, shown boxed numberedPOS -tags. Roughly speaking, paths (65) (68) correspond surface templates (66)(69), respectively, paths actually templates specified syntactic level.(64)(65)(66)(67)(68)(69)mathematician found solution problem.N1 :subj:V found V :obj:N solution N:to: N2N1 found [a] solution N2problem solved young mathematician.N3 :obj:V solved V :by: N4N3 solved N4 .DIRT imposes restrictions paths extracted dependency trees;example, start end noun slots. paths extracted, lookspairs paths occur frequently slot fillers. (65) (68) occur frequentlyfillers (e.g., N1 = N4 = mathematician, N2 = N3 = problem), includedpair DIRTs output (with N1 = N4 N2 = N3). measure based mutual information(Manning & Schuetze, 1999; Lin & Pantel, 2001) used detect paths common fillers.Lin Pantel call pairs templates DIRT produces inference rules,directionality templates pair; intention seems produce pairsnear paraphrases. resulting pairs actually often textual entailment pairs, paraphrases,37 Zhitomirsky-GeffetDagan (2009) discuss bootstrapping approach, whereby vector similarity scores (initially computed using pointwise mutual information values vectors) used improve values vectors;vector similarity scores re-computed.38 consistency previous examples, show slightly different labels used Lin Pantel.161fiA NDROUTSOPOULOS & ALAKASIOTISfoundsubjsolvedobjmathematiciansolutiondetobj auxdetproblemmathematiciandetproblemdetmodyoungdetFigure 5: Dependency trees sentences (64) (67).directionality entailment unspecified.39 Bhagat et al. (2007) developed method,called LEDIR, classify template pairs hP1 , P2 DIRT similar methods produce threeclasses: (i) paraphrases, (ii) P1 textually entails P2 reverse, (iii) P2 textually entailsP1 reverse; addition LEDIR, DIRT becomes method extracts separatelypairs paraphrase templates pairs directional textual entailment templates. Roughly speaking, LEDIR examines semantic categories (e.g., person, location etc.) words fill P1P2 slots corpus; categories obtained following WordNets hypernym-hyponymhierarchies filler words certain level, applying clustering wordscorpus using clusters filler words categories.40 P1 occurs fillerssubstantially larger number categories P2 , LEDIR assumes P1 generalmeaning P2 and, hence, P2 textually entails P1 ; similarly reverse direction.substantial difference number categories, P1 P2 taken paraphrases. SzpektorDagan (2008) describe method similar DIRT produces textual entailment pairs unary(single slot) templates (e.g., X takes nap X sleeps) using directional similarity measureunary templates.Extraction methods based (extended) Distributional Hypothesis often produce pairstemplates correct paraphrasing textual entailment pairs, although share manycommon fillers. fact, pairs involving antonyms frequent; according Lin Pantel (2001),DIRT finds X solves similar X worsens ; problemreported experiments LEDIR (Bhagat et al., 2007) distributional approaches operatesurface level (Bhagat & Ravichandran, 2008).Ibrahim et al.s (2003) method similar DIRT, assumes monolingual parallelcorpus available (e.g., multiple English translations novels), whereas DIRT requireparallel corpora. Ibrahim et al.s method extracts pairs dependency paths alignedsentences share matching anchors. Anchors allowed nouns pronouns,match identical, noun compatible pronoun,semantic category etc. (70)(71), square brackets subscripts indicate matching anchors.41pair templates (72)(73) would extracted (70)(71); simplicity, showsentences templates surface strings, although method operates dependency trees39 Templatepairs produced DIRT available on-line.introduction clustering methods, consult chapter 14 Foundations Statistical Natural Language Processing (Manning & Schuetze, 1999).41 Simplified example Ibrahim et al.s work (2003).40162fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSpaths. Matching anchors become matched slots. Heuristic functions used score anchormatches (e.g., identical anchors preferred matching nouns pronouns) resultingtemplate pairs; roughly speaking frequently rediscovered template pairs rewarded, especiallyoccur many different anchors.(70)(71)(72)(73)[clerk]1 liked [Bovary]2 .[He]1 fond [Bovary]2 .X liked .X fond .operating aligned sentences monolingual parallel corpora, Ibrahim et al.s method mayavoid, extent, producing pairs unrelated templates simply happen share commonslot fillers; resulting pairs templates also likely paraphrases, rather simplytextual entailment pairs, since obtained aligned sentences monolingual parallelcorpus. Large monolingual parallel corpora, however, difficult obtain non-parallelcorpora, already discussed. alternative identify anchors related sentences comparable corpora (Section 3.1), easier obtain. Shinyama Sekine (2003) find pairssentences share anchors within clusters news articles reporting event.method, anchors named entities (e.g., person names) identified using named entityrecognizer, pronouns noun phrases refer named entities; heuristics employedidentify likely referents. Dependency trees constructed pair sentences,pairs dependency paths extracted trees treating anchors slots.4.2 Extraction Methods Use BootstrappingBootstrapping approaches also used extraction, generation (Section 3.2),additional complication particular input template seed values slots startfrom. address complication, TEASE (Szpektor et al., 2004) starts lexicon termsknowledge domain, example names diseases, symptoms etc. case medical domain;extent, lexicons constructed automatically domain-specific corpus (e.g.,medical articles) via term acquisition techniques (Jacquemin & Bourigault, 2003). TEASEextracts (non-parallel) monolingual corpus pairs textual entailment templatesused lexicons terms slot fillers. already shown resulting pair templates,(60)(61), Section 3.2; repeat (74)(75) below. Recall TEASE indicatedirectionality resulting template pairs, example whether (74) textually entails (75) viceversa, mechanisms like LEDIR (Section 4.1) could used guess directionality.(74)(75)X preventsX reduces riskRoughly speaking, TEASE first identifies noun phrases cooccur frequently termlexicon, excluding common noun phrases. uses terms cooccurringnoun phrases seed slot values obtain templates, new templates obtainslot values, much Figure 4. TEASE, however, templates actually slotted dependencypaths, method includes stage merges compatible templates form generalones.42 particular input templates provided, TEASE used generator (Section 3.2).42 Templatepairs produced TEASE available on-line.163fiA NDROUTSOPOULOS & ALAKASIOTISBarzilay McKeown (2001) also used bootstrapping method, extract paraphrasesparallel monolingual corpus; used multiple English translations novels. Unlikepreviously discussed bootstrapping approaches, method involves two classifiers (in effect, twosets rules). One classifier examines words candidate paraphrases consist of, secondone examines contexts. two classifiers use different feature sets (different viewsdata), output classifier used improve performance oneiterative manner; case co-training (Blum & Mitchell, 1998). specifically,POS tagger, shallow parser, stemmer first applied corpus, sentencesaligned across different translations. Words occur sentences aligned pairtreated seed positive lexical examples; pairs words two sentencesbecome seed negative lexical examples. aligned sentences (76)(77), obtain three seedpositive lexical examples, shown (78)(80), many seed negative lexical examples, twoshown (81)(82).43 Although seed positive lexical examples pairs identicalwords, algorithm iterates new positive lexical examples produced, maysynonyms (e.g., comfort console) pairs longer paraphrases, explainedbelow.(76)(77)(78)(79)(80)(81)(82)tried comfort her.tried console Mary.hexpression1 = he, expression2 = he, +ihexpression1 = tried, expression2 = tried, +ihexpression1 = to, expression2 = to, +ihexpression1 = he, expression2 = tried,hexpression1 = he, expression2 = to,contexts positive (similarly, negative) lexical examples corresponding sentences used construct positive (or negative) context rules, i.e., rules usedobtain new pairs positive (or negative) lexical examples. Barzilay McKeown (2001) usePOS tags l words lexical examples contexts, experimentsset l = 3. simplicity, however, let us assume l = 2; then, instance, (76)(77)positive lexical example (79), obtain positive context rule (83). rule saystwo aligned sentences contain two sequences words, say 1 2 , one sentence,1 2 preceded pronoun, followed (possibly different) verb, 1 2 positive lexical examples. Identical subscripts POStags denote identical words; example, (83) requires 1 2 precededpronoun, verbs follow may different.(83)hleft1 = (pronoun1 ), right1 = (to1 , verb), left2 = (pronoun1 ), right1 = (to1 , verb), +iiteration, k strongest positive negative context rules retained.strength context rule precision, i.e., positive context rules, number positivelexical examples whose contexts matched rule divided number positivenegative lexical examples matched, similarly negative context rules. Barzilay McKeown(2001) used k = 10, also discarded context rules whose strength 95%.resulting (positive negative) context rules used identify new (positive negative)43 Simplifiedexample work Barzilay McKeown (2001).164fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSSlot 1planesbombersstartBaghdadbombedforcesIraqiSlot 2BaghdadstartIraqiIraqiSlot 3planescapitalmilitaryendcapitalbombedbasearmySlot 4endforcesFigure 6: Word lattices obtained sentence clusters Barzilay Lees method.lexical examples. aligned (84)(85), rule (83) would figure triedsynonym attempted; two words would treated new positive lexical example, shown(86).(84)(85)(86)tried run away.attempted escape.hexpression1 = tried, expression2 = attempted, +icontext rules may also produce multi-word lexical examples, like one shown (87).obtained lexical examples generalized replacing words POS tags, givingrise paraphrasing rules. (87) obtain positive paraphrasing rule (88); again, POSsubscripts denote identical words, whereas superscripts denote identical stems. rule (88)says sequence words consisting verb, to, another verb paraphrasesequence consisting initial verb, to, another verb stemsecond verb first sequence, provided two sequences occur aligned sentences.(87)(88)hexpression1 = start talk, expression2 = start talking, +iffgeneralized expression1 = (verb0 , to, verb1 ), generalized expression2 = (verb0 , verb1 ), +paraphrasing rules also filtered strength, precisionpredict paraphrasing contexts. remaining paraphrasing rules used obtain lexicalexamples, also filtered precision predict paraphrasing contexts.new positive negative lexical examples added existing ones,used obtain, score, filter new positive negative context rules, well rescorefilter existing ones. resulting context rules employed obtain lexical examples, paraphrasing rules, on, new positive lexical examples obtainedcorpus, maximum number iterations exceeded. Wang et al. (2009) addedscoring measures Barzilay McKeowns (2001) method filter rank paraphrase pairsproduces, used extended method extract paraphrases technical terms clustersbug reports.4.3 Extraction Methods Based AlignmentBarzilay Lee (2003) used two corpora genre, different sources (newsarticles two press agencies). call two corpora comparable, use term165fiA NDROUTSOPOULOS & ALAKASIOTISslightly different meaning previously discussed methods; sentences corpusclustered separately, cluster intended contain sentences (from single corpus)referring events type (e.g., bomb attacks), sentences (or documents) referringevents (e.g., particular bombing). cluster, word lattice producedaligning clusters sentences Multiple Sequence Alignment (Durbin, Eddy, Krogh, &Mitchison, 1998; Barzilay & Lee, 2002). solid lines Figure 6 illustrate two possible resultinglattices, two different clusters; omit stop-words. sentence cluster correspondspath clusters lattice. lattice, nodes shared high percentage (50%Barzilay Lees experiments) clusters sentences considered backbone nodes. Partslattice connect otherwise consecutive backbone nodes replaced slots, illustratedFigure 6. two lattices example correspond surface templates (89)(90).(89)(90)X bombed .bombed X.encountered fillers slot also recorded. two slotted lattices (templates) different corpora share many fillers, taken pair paraphrases (Figure 6). Hence,method also uses extended Distributional Hypothesis (Section 4.1).Pang et al.s method (2003) produces finite state automata similar Barzilay Lees(2003) lattices, requires parallel monolingual corpus; Pang et al. used Multiple-TranslationChinese Corpus (Section 3.1) experiments. parse trees aligned sentences constructed merged illustrated Figure 7; vertical lines inside nodes indicate sequencesnecessary constituents, whereas horizontal lines correspond disjunctions.44 exampleFigure 7, sentences consist noun phrase (NP) followed verb phrase (VP); reflected root node merged tree. sentences, noun phrase cardinal number(CD) followed noun (NN); however, particular cardinal numbers nouns differentacross two sentences, leading leaf nodes disjunctions. rest merged treeconstructed similarly; consult Pang al. details. Presumably one could also generalizecardinal numbers, types named entities etc.merged tree converted finite state automaton traversing tree depthfirst manner introducing ramification node disjunction encountered. Figure 8shows automaton corresponds merged tree Figure 7. language expressionsproduced automaton (all paths start end node) paraphrases.Hence, unlike extraction methods, Pang et al.s (2003) method produces automata, ratherpairs templates, automata used similar manner. recognition, example,two strings accepted automaton, paraphrases; generation, couldlook automaton accepts input expression, output expressionsgenerated automaton. Barzilay Lees (2003) method, however, Pang etal.s (2003) method intended extract mostly paraphrase, simply textual entailment pairs.Bannard Callison-Burch (2005) point bilingual parallel corpora much easierobtain, much larger sizes, monolingual parallel comparable corporaextraction methods employ. Hence, set extract paraphrases bilingual parallel corpora commonly used statistical machine translation (SMT). already discussed Section 3.1,phrase-based SMT systems employ tables whose entries show phrases one language may44 ExamplePang et al.s work (2003).166fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSParse treesaligned sentencesCDtwelveNPVPNNpeopleVBdiedNPCD12VPNNpersonsAUXVBkilledmergetreesNP VPAUXCD NN12personstwelvepeopleVBVBkilleddiedFigure 7: Merging parse trees aligned sentences Pang et al.s method.12diedpersonsstartendpeopletwelvekilledFigure 8: Finite state automaton produced Pang et al.s method.replaced phrases another language; phrase tables kind may produced applyingphrase alignment heuristics (Och & Ney, 2003; Cohn et al., 2008) word alignments producedcommonly used IBM models. case English-German parallel corpus, phrasetable may contain entries like following, show control alignedunter kontrolle corpus, unter kontrolle also aligned check; hence,control check candidate paraphrase pair.45English phraseGerman phrase...control...check......unter kontrolle...unter kontrolle...precisely, paraphrase English phrases, Bannard Callison-Burch (2005) employpivot language (German, example above) bilingual parallel corpus Englishpivot language. construct phrase table parallel corpus, tableestimate probabilities P(e| f ) P( f |e), e f range English pivotlanguage phrases table. example, P(e| f ) may estimated number entries (rows)contain e f , divided number entries contain f , multiple rowsmultiple alignments e f corpus, similarly P( f |e). best paraphrase e2English phrase e1 table computed equation (91), f rangespivot language phrases phrase table .e2 = arg max P(e2 |e1 ) = arg maxe2 6=e145 ExampleP( f |e1 )P(e2 | f , e1 ) arg emaxP( f |e1 )P(e2 | f )2 6=e1e2 6=e1 ffwork Bannard Callison-Burch (2005).167(91)fiA NDROUTSOPOULOS & ALAKASIOTISMultiple bilingual corpora, different pivot languages, used; (91) becomes (92), Cranges corpora, f ranges pivot language phrases Cs phrase table.e2 = arg maxe2 6=e1 Cf (C)P( f |e1 )P(e2 | f )(92)Bannard Callison-Burch (2005) also considered adding language model (Section 3.1)method favour paraphrase pairs used interchangeably sentences; roughlyspeaking, language model assesses well one element pair replace sentences latter occurs, scoring grammaticality sentences replacement.subsequent work, Callison-Burch (2008) extended method require paraphrasessyntactic types, since replacing phrase one different syntactic type generally leadsungrammatical sentence.46 Zhou et al. (2006b) employed method similar BannardCallison-Burchs extract paraphrase pairs corpus, used resulting pairs SMTevaluation, comparing machine-generated translations human-authored ones. Riezleret al. (2007) adopted similar pivot approach obtain paraphrase pairs bilingual phrase tables, used resulting pairs paraphrasing rules obtain paraphrases (longer) questionssubmitted QA system; also used log-linear model (Section 3.1) rank resultingquestion paraphrases combining probabilities invoked paraphrasing rules, languagemodel score resulting question paraphrase, features.47pivot language approaches discussed shown produce millions paraphrase pairs large bilingual parallel corpora. paraphrases, however, typically short(e.g., four five words), since longer phrases rare phrase tables. methods alsosignificantly affected errors automatic word phrase alignment (Bannard & CallisonBurch, 2005). take consideration word alignment errors, Zhao et al. (2008) use log-linearclassifier score candidate paraphrase pairs share common pivot phrase, instead usingequations (91) (92). effect, classifier uses probabilities P( f |e1 ) P(e2 | f ) (91)(92) features, also uses additional features assess quality word alignmente1 f , well f e2 . subsequent work, Zhao et al. (2009) also considerEnglish phrases e1 e2 paraphrases, aligned different pivot phrasesf1 f2 , provided f1 f2 paraphrase pair pivot language. Figure 9illustrates original extended pivot approaches Zhao et al. paraphrase pairs h f1 , f2pivot language extracted scored bilingual parallel corpus original approach, reversing roles two languages. scores h f1 , f2 pairs, roughlyspeaking correspond P( f2 | f1 ), included additional features classifier scoresresulting English paraphrases, along scores corresponding P( f1 |e1 ), P(e2 | f2 ), featuresassess word alignments phrases involved.Zhao et al.s (2008, 2009) method also extends Bannard Callison-Burchs (2005) producing pairs slotted templates, whose slots filled words particular parts speech(e.g., Noun1 considered Noun2 Noun2 considers Noun1 ).48 Hence, Zhao et al.s patternsgeneral, reliable parser language paraphrase required; let us assumeparaphrase English. Roughly speaking, slots formed removing subtrees46implementation Callison-Burchs (2008) method paraphrase rules produced available on-line.et al. (2007) also employ paraphrasing method based SMT system trained question-answer pairs.48 collection template pairs produced Zhao et al.s method available on-line.47 Riezler168fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSe1paraphrasee2e1paraphrasef1alignalignfe2paraphrasef2Figure 9: Illustration Zhao et al.s pivot approaches paraphrase extraction.dependency trees English sentences replacing removed subtrees POStags roots; words pivot language sentences aligned removed wordscorresponding English sentences also replaced slots. language model also used,paraphrases replaced longer sentences. Zhao et al.s experiments show method outperforms DIRT, able output many paraphrase pairs method BannardCallison-Burch, better precision, i.e., fewer wrongly produced pairs. generatedparaphrases (93%), however, contain one slot, method still sensitive wordalignment errors (Zhao et al., 2009), although features check word alignment qualityalleviate problem.Madnani et al. (2007) used pivot approach similar Bannard Callison-Burchs (2005)obtain synchronous (normally bilingual) English-to-English context-free grammar rulesbilingual parallel corpora. Parsing English text English-to-English synchronous rulesautomatically paraphrases it; hence resulting synchronous rules used paraphrase generation (Section 3). rules associated probabilities, estimated bilingualcorpora. log-linear combination probabilities features invoked rulesused guide parsing. Madnani et al. employed English-to-English rules parse and, thus,paraphrase human-authored English reference translations Chinese texts. showed using additional automatically generated reference translations tuning Chinese-to-EnglishSMT system improves performance, compared using human-authored references.note alignment-based methods section appear used extractparaphrase pairs, (unidirectional) textual entailment pairs.4.4 Evaluating Extraction Methodsevaluating extraction methods, would ideally measure precision (what percentage extracted pairs correct paraphrase textual entailment pairs) recall (whatpercentage correct pairs could extracted actually extracted).generation, however, recall cannot computed, number correct pairscould extracted large corpus (by ideal method) unknown. Instead, one maycount number extracted pairs (the total yield method), possibly different precision levels. Different extraction methods, however, produce pairs different kinds (e.g., surfacestrings, slotted surface templates, slotted dependency paths) different kinds corpora (e.g.,monolingual multilingual parallel comparable corpora); hence, direct comparisons extraction methods may impossible. Furthermore, different scores obtained, depending whetherextracted pairs considered particular contexts not, whether requiredinterchangeable grammatical sentences (Bannard & Callison-Burch, 2005; Barzilay & Lee, 2003;169fiA NDROUTSOPOULOS & ALAKASIOTISCallison-Burch, 2008; Zhao et al., 2008). output extraction method may also include pairsrelatively minor variations (e.g., active vs. passive, verbs vs. nominalizations, variantsX company bought vs. X bought ), may cause methods produce large numbers minor variants appear better really are; points also apply evaluationgeneration methods (Section 3.3), though discussed mostly extraction literature. Detecting grouping variants (e.g., turning passives nominalizations activeforms) may help avoid bias may also improve quality extracted pairs makingoccurrences (grouped) expressions less sparse (Szpektor & Dagan, 2007).generation, principle one could use paraphrase textual entailment recognizerautomatically score extracted pairs. However, recognizers yet accurate enough; hence,human judges usually employed. extracting slotted textual entailment rules (e.g., Xpainted textually entails work X), Szpektor et al. (2007) report human judgesfind easier agree whether particular instantiations rules (in particular contexts)correct incorrect, opposed asking assess directly correctness rules.better evaluation strategy, then, show judges multiple sentences match lefthand side rule, along corresponding transformed sentences producedapplying rule, measure percentage sentence pairs judges consider correcttextual entailment pairs; measure thought precision individual rule.Rules whose precision exceeds (high) threshold considered correct (Szpektor et al., 2007).Again, one may also evaluate extraction methods indirectly, example measuringmuch extracted pairs help information extraction (Bhagat & Ravichandran, 2008; Szpektor& Dagan, 2007, 2008) expanding queries (Pasca & Dienes, 2005), measuringwell extracted pairs, seen paraphrasing rules, perform phrase alignment monolingualparallel corpora (Callison-Burch et al., 2008), measuring extent SMT summarizationevaluation measures improved taking consideration extracted pairs (CallisonBurch et al., 2006a; Kauchak & Barzilay, 2006; Zhou et al., 2006b).5. ConclusionsParaphrasing textual entailment currently popular research topic. Paraphrasing seenbidirectional textual entailment and, hence, similar methods often used both. Althoughkinds methods described terms logical entailment, usually intendedcapture human intuitions may strict logical entailment; although logic-basedmethods developed, methods operate surface, syntactic, shallow semanticlevel, dependency trees particularly popular representation.Recognition methods, classify input pairs natural language expressions (or templates)correct incorrect paraphrases textual entailment pairs, often rely supervised machinelearning combine similarity measures possibly operating different representation levels (surface, syntactic, semantic). recently, approaches search sequences transformationsconnect two input expressions also gaining popularity, exploit paraphrasingtextual entailment rules extracted large corpora. RTE challenges provide significantthrust recognition work, helped establish benchmarks attract researchers.Generation methods, meaning methods generate paraphrases input natural languageexpression (or template), expressions entail entailed input expression, currently based mostly bootstrapping ideas statistical machine translation. fewer170fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSMain ideas discussedLogic-based inferencingVector space semantic modelsSurface string similarity measuresSyntactic similarity measuresSimilarity measures symbolic meaning representationsMachine learning algorithmsDecoding (transformation sequences)Word/sentence alignmentPivot language(s)BootstrappingDistributional hypothesisSynchronous grammar rulesR-TEXXXXXXXR-PXXXXXXXG-TEXXG-PXXXXXXXE-TEE-PXXXXXXXXTable 3: Main ideas discussed tasks mostly used in. R: recognition; G: generation, E: extraction; TE: textual entailment, P: paraphrasing.publications generation, compared recognition (and extraction), focusparaphrasing; furthermore, established challenges benchmarks, unlike recognition.Nevertheless, generation may provide opportunities novel research, especially researchersexperience statistical machine translation, may example wish develop alignmentdecoding techniques especially paraphrasing textual entailment generation.Extraction methods extract paraphrases textual entailment pairs (also called rules)corpora, usually off-line. used construct resources (e.g., phrase tables collections rules) exploited recognition generation methods, tasks (e.g.,statistical machine translation, information extraction). Many extraction methods basedDistributional Hypothesis, though often operate different representation levels. Alignmenttechniques originating statistical machine translation recently also popular allowexisting large bilingual parallel corpora exploited. Extraction methods also differ dependingwhether require parallel, comparable, simply large corpora, monolingual bilingual.generation, extraction research focused paraphrasing, establishedchallenges benchmarks.Table 3 summarizes main ideas discussed per task, Table 4 lists corresponding main resources typically required. underlying ideas generation extractionmethods effect same, shown Table 3, even methods perform different tasks;recognition work relied rather different ideas. Generation extraction mostly focusedparaphrasing, already noted, fewer ideas explored generationextraction (unidirectional) textual entailment.expect see interplay among recognition, generation, extraction methodsnear future. example, recognizers generators may use extracted rules larger extent;recognizers may used filter candidate paraphrases textual entailment pairs extractiongeneration approaches; generators may help produce monolingual parallel corporarecognition benchmarks. also expect see paraphrasing textual entailment methodsused often larger natural language processing tasks, including question answering,information extraction, text summarization, natural language generation, machine translation.171fiA NDROUTSOPOULOS & ALAKASIOTISMain ideas discussedLogical-based inferencingVector space semantic modelsSurface string similarity measuresSyntactic similarity measuresSimilarity measures operatingsymbolic meaning representationsMachine learning algorithmsDecoding (transformation sequences)Word/sentence alignmentPivot language(s)BootstrappingDistributional hypothesisSynchronous grammar rulesMain typically required resourcesParser producing logical meaning representations, inferencing engine,resources extract meaning postulates common sense knowledge from.Large monolingual corpus, possibly parser.preprocessing tools, e.g., POS tagger, named-entity recognizer,also required methods.Parser.Lexical semantic resources, possibly parser and/or semantic role labelingproduce semantic representations.Training/testing datasets, components/resources needed compute features.Synonyms, hypernyms-hyponyms, paraphrasing/TE rules.Large parallel comparable corpora (monolingual multilingual), possiblyparser.Multilingual parallel corpora.Large monolingual corpus, recognizer.Monolingual corpus (possibly parallel comparable).Monolingual parallel corpus.Table 4: Main ideas discussed main resources typically require.Acknowledgmentsthank three anonymous reviewers valuable comments. work fundedGreek PENED project Combined research areas information retrieval, natural languageprocessing, user modeling aiming development advanced search engines documentcollections, co-funded European Union (80%) Greek General SecretariatResearch Technology (20%).Appendix A. On-line Resources MentionedA.1 Bibliographic Resources, Portals, TutorialsACL 2007 tutorial textual entailment: http://www.cs.biu.ac.il/dagan/TE-Tutorial-ACL07.ppt.ACL Anthology: http://www.aclweb.org/anthology/.Textual Entailment Portal: http://www.aclweb.org/aclwiki/index.php?title=Textual Entailment Portal.A.2 Corpora, Challenges, DatasetsCohn et al.s paraphrase corpus: Word-aligned paraphrases;http://www.dcs.shef.ac.uk/tcohn/paraphrase corpus.html.FATE: RTE-2 dataset FrameNet annotations;http://www.coli.uni-saarland.de/projects/salsa/fate/.MSR Paraphrase Corpus: Paraphrase recognition benchmark dataset;http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/.172fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSMultiple-Translation Chinese Corpus: Multiple English translations Chinese news articles;http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2002T01.RTE challenges, PASCAL Network Excellence: Textual entailment recognition challengesdatasets; http://pascallin.ecs.soton.ac.uk/Challenges/.RTE track NISTs Text Analysis Conference: Continuation PASCALs RTE;http://www.nist.gov/tac/tracks/.Written News Compression Corpus: Sentence compression corpus;http://jamesclarke.net/research/.A.3 Implementations Machine Learning AlgorithmsLIBSVM: SVM implementation; http://www.csie.ntu.edu.tw/cjlin/libsvm/.Stanfords Maximum Entropy classifier: http://nlp.stanford.edu/software/index.shtml.SVM-Light: SVM implementation; http://svmlight.joachims.org/.Weka: Includes implementations many machine learning algorithms;http://www.cs.waikato.ac.nz/ml/weka/.A.4 Implementations Similarity MeasuresEDITS: Suite recognize textual entailment computing edit distances; http://edits.fbk.eu/.WordNet::Similarity: Implementations WordNet-based similarity measures;http://wn-similarity.sourceforge.net/.A.5 Parsers, POS Taggers, Named Entity Recognizers, StemmersBrills POS tagger: http://en.wikipedia.org/wiki/Brill tagger.Charniaks parser: http://flake.cs.uiuc.edu/cogcomp/srl/CharniakServer.tgz.Collins parser: http://people.csail.mit.edu/mcollins/code.html.Link Grammar Parser: http://www.abisource.com/projects/link-grammar/.MaltParser: http://w3.msi.vxu. se/nivre/research/MaltParser.html.MINIPAR: http://www.cs.ualberta.ca/lindek/minipar.htm.Porters stemmer: http://tartarus.org/martin/PorterStemmer/.Stanfords named-entity recognizer, parser, tagger: http://nlp.stanford.edu/software/index.shtml.173fiA NDROUTSOPOULOS & ALAKASIOTISA.6 Statistical Machine Translation Tools ResourcesGiza++: Often used train IBM models align words; http://www.fjoch.com/GIZA++.html.Koehns Statistical Machine Translation site: Pointers commonly used SMT tools, resources;http://www.statmt.org/.Moses: Frequently used SMT system includes decoding facilities;http://www.statmt.org/moses/.SRILM: Commonly used create language models;http://www.speech.sri.com/projects/srilm/.A.7 Lexical Resources, Paraphrasing Textual Entailment RulesCallison-Burchs paraphrase rules: Paraphrase rules extracted multilingual parallel corporavia pivot language(s); implementation method used also available;http://cs.jhu.edu/ccb/.DIRT rules: Template pairs produced DIRT; http://demo.patrickpantel.com/.Extended WordNet: Includes meaning representations extracted WordNets glosses;http://wordnet.princeton.edu/.FrameNet: http://framenet.icsi.berkeley.edu/.Nomlex: English nominalizations verbs; http://nlp.cs.nyu.edu/nomlex/TEASE rules: Textual entailment rules produced TEASE;http://www.cs.biu.ac.il/szpekti/TEASE collection.zip.VerbNet: http://verbs.colorado.edu/mpalmer/projects/verbnet.html.WordNet: http://xwn.hlt.utdallas.edu/.Zhao et al.s paraphrase rules: Paraphrase rules slots corresponding POS tags, extractedmultilingual parallel corpora via pivot language(s);http://ir.hit.edu.cn/phpwebsite/index.php?module=documents&JAS DocumentManager op=viewDocument&JAS Document id=268.ReferencesAlpaydin, E. (2004). Introduction Machine Learning. MIT Press.Androutsopoulos, I., Oberlander, J., & Karkaletsis, V. (2007). Source authoring multilingualgeneration personalised object descriptions. Nat. Lang. Engineering, 13(3), 191233.Androutsopoulos, I., Ritchie, G. D., & Thanisch, P. (1995). Natural language interfaces databasesintroduction. Nat. Lang. Engineering, 1(1), 2981.Baeza-Yates, R., & Ribeiro-Neto, B. (1999). Modern Information Retrieval. Addison Wesley.174fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSBaker, C. F., Fillmore, C. J., & Lowe, J. B. (1998). Berkeley FrameNet project. Proc.17th Int. Conf. Comp. Linguistics, pp. 8690, Montreal, Quebec, Canada.Bannard, C., & Callison-Burch, C. (2005). Paraphrasing bilingual parallel corpora. Proc.43rd Annual Meeting ACL, pp. 597604, Ann Arbor, MI.Bar-Haim, R., Berant, J., & Dagan, I. (2009). compact forest scalable inference entailment paraphrase rules. Proc. Conf. EMNLP, pp. 10561065, Singapore.Bar-Haim, R., Dagan, I., Dolan, B., Ferro, L., Giampiccolo, D., Magnini, B., & Szpektor, I. (2006).2nd PASCAL recognising textual entailment challenge. Proc. 2nd PASCAL Challenges Workshop Recognising Textual Entailment, Venice, Italy.Bar-Haim, R., Dagan, I., Greental, I., & Shnarch, E. (2007). Semantic inference lexicalsyntactic level. Proc. 22nd Conf. Artificial Intelligence, pp. 871876, Vancouver,BC , Canada.Barzilay, R., & Elhadad, N. (2003). Sentence alignment monolingual comparable corpora.Proc. Conf. EMNLP, pp. 2532, Sapporo, Japan.Barzilay, R., & Lee, L. (2002). Bootstrapping lexical choice via multiple-sequence alignment.Proc. Conf. EMNLP, pp. 164171, Philadelphia, PA.Barzilay, R., & Lee, L. (2003). Learning paraphrase: unsupervised approach using multiplesequence alignment. Proc. HLT Conf. NAACL, pp. 1623, Edmonton, Canada.Barzilay, R., & McKeown, K. (2001). Extracting paraphrases parallel corpus. Proc.39th Annual Meeting ACL, pp. 5057, Toulouse, France.Barzilay, R., & McKeown, K. R. (2005). Sentence fusion multidocument news summarization.Comp. Linguistics, 31(3), 297327.Bateman, J., & Zock, M. (2003). Natural language generation. Mitkov, R. (Ed.), OxfordHandbook Comp. Linguistics, chap. 15, pp. 284304. Oxford University Press.Bensley, J., & Hickl, A. (2008). Workshop: Application LCCs GROUNGHOG system RTE -4.Proc. Text Analysis Conference, Gaithersburg, MD.Bergmair, R. (2009). proposal evaluation measures RTE. Proc. ACL WorkshopApplied Textual Inference, pp. 1017, Singapore.Berwick, R. C. (1991). Principles principle-based parsing. Berwick, R. C., Abney, S. P.,& Tenny, C. (Eds.), Principle-Based Parsing: Computation Psycholinguistics, pp. 137.Kluwer, Dordrecht, Netherlands.Bhagat, R., Pantel, P., & Hovy, E. (2007). LEDIR: unsupervised algorithm learning directionality inference rules. Proc. Conf. EMNLP Conf. ComputationalNat. Lang. Learning, pp. 161170, Prague, Czech Republic.Bhagat, R., & Ravichandran, D. (2008). Large scale acquisition paraphrases learning surfacepatterns. Proc. 46th Annual Meeting ACL: HLT, pp. 674682, Columbus, OH.Bikel, D. M., Schwartz, R. L., & Weischedel, R. M. (1999). algorithm learns whatsname. Machine Learning, 34(1-3), 211231.Blum, A., & Mitchell, T. (1998). Combining labeled unlabeled data co-training. Proc.11th Annual Conf. Computational Learning Theory, pp. 92100, Madison, WI.175fiA NDROUTSOPOULOS & ALAKASIOTISBos, J., & Markert, K. (2005). Recognising textual entailment logical inference. Proc.Conf. HLT EMNLP, pp. 628635, Vancouver, BC, Canada.Brill, E. (1992). simple rule-based part speech tagger. Proc. 3rd Conf. AppliedNat. Lang. Processing, pp. 152155, Trento, Italy.Brockett, C., & Dolan, W. (2005). Support Vector Machines paraphrase identification corpusconstruction. Proc. 3rd Int. Workshop Paraphrasing, pp. 18, Jeju island, Korea.Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., & Mercer, R. L. (1993). mathematicsstatistical machine translation: Parameter estimation. Comp. Linguistics, 19(2), 263311.Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures lexical semantic relatedness. Comp. Linguistics, 32(1), 1347.Burchardt, A., & Pennacchiotti, M. (2008). FATE: FrameNet-annotated corpus textual entailment. Proc. 6th Language Resources Evaluation Conference, Marrakech,Marocco.Burchardt, A., Pennacchiotti, M., Thater, S., & Pinkal, M. (2009). Assessing impact framesemantics textual entailment. Nat. Lang. Engineering, 15(4).Burchardt, A., Reiter, N., Thater, S., & Frank, A. (2007). semantic approach textual entailment: System evaluation task analysis. Proc. ACL - PASCAL Workshop TextualEntailment Paraphrasing, pp. 1015, Prague, Czech Republic. ACL.Califf, M., & Mooney, R. (2003). Bottom-up relational learning pattern matching rules information extraction. Journal Machine Learning Research, 4, 177210.Callison-Burch, C. (2008). Syntactic constraints paraphrases extracted parallel corpora.Proc. Conf. EMNLP, pp. 196205, Honolulu, HI.Callison-Burch, C., Cohn, T., & Lapata, M. (2008). ParaMetric: automatic evaluation metricparaphrasing. Proc. 22nd Int. Conf. Comp. Linguistics, pp. 97104, Manchester,UK .Callison-Burch, C., Dagan, I., Manning, C., Pennacchiotti, M., & Zanzotto, F. M. (Eds.). (2009).Proc. ACL - IJCNLP Workshop Applied Textual Inference. Singapore.Callison-Burch, C., Koehn, P., & Osborne, M. (2006a). Improved statistical machine translationusing paraphrases. Proc. HLT Conf. NAACL, pp. 1724, New York, NY.Callison-Burch, C., Osborne, M., & Koehn, P. (2006b). Re-evaluating role BLEU machinetranslation research. Proc. 11th Conf. EACL, pp. 249256, Trento, Italy.Carnap, R. (1952). Meaning postulates. Philosophical Studies, 3(5).Charniak, E. (2000). maximum-entropy-inspired parser. Proc. 1st Conf. NAACL, pp.132139, Seattle, WA.Chevelu, J., Lavergne, T., Lepage, Y., & Moudenc, T. (2009). Introduction new paraphrasegeneration tool based Monte-Carlo sampling. Proc. 47th Annual Meeting ACL4th Int. Joint Conf. Nat. Lang. Processing AFNLP, pp. 249252, Singapore.Clarke, D. (2009). Context-theoretic semantics natural language: overview. Proc.EACL workshop Geometrical Models Nat. Lang. Semantics, pp. 112119, Athens,Greece.176fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSClarke, J., & Lapata, M. (2008). Global inference sentence compression: integer linearprogramming approach. Journal Artificial Intelligence Research,, 31(1), 399429.Cohn, T., Callison-Burch, C., & Lapata, M. (2008). Constructing corpora developmentevaluation paraphrase systems. Comp. Linguistics, 34(4), 597614.Cohn, T., & Lapata, M. (2008). Sentence compression beyond word deletion. Proc. 22ndInt. Conf. Comp. Linguistics, Manchester, UK.Cohn, T., & Lapata, M. (2009). Sentence compression tree transduction. Journal ArtificialIntelligence Research, 34(1), 637674.Collins, M. (2003). Head-driven statistical models natural language parsing. Comput. Linguistics, 29(4), 589637.Corley, C., & Mihalcea, R. (2005). Measuring semantic similarity texts. Proc. ACLWorkshop Empirical Modeling Semantic Equivalence Entailment, pp. 1318, AnnArbor, MI.Cristianini, N., & Shawe-Taylor, J. (2000). Introduction Support Vector MachinesKernel-based Learning Methods. Cambridge University Press.Culicover, P. (1968). Paraphrase generation information retrieval stored text. MechanicalTranslation Computational Linguistics, 11(12), 7888.Dagan, I., Dolan, B., Magnini, B., & Roth, D. (2009). Recognizing textual entailment: Rational,evaluation approaches. Nat. Lang. Engineering, 15(4), ixvii. Editorial specialissue Textual Entailment.Dagan, I., Glickman, O., & Magnini, B. (2006). PASCAL recognising textual entailment challenge. Quinonero-Candela, J., Dagan, I., Magnini, B., & dAlche Buc, F. (Eds.), MachineLearning Challenges. Lecture Notes Computer Science, Vol. 3944, pp. 177190. SpringerVerlag.Das, D., & Smith, N. A. (2009). Paraphrase identification probabilistic quasi-synchronous recognition. Proc. 47th Annual Meeting ACL 4th Int. Joint Conf. Nat. Lang.Processing AFNLP, pp. 468476, Singapore.de Marneffe, M., Rafferty, A., & Manning, C. (2008). Finding contradictions text. Proc.46th Annual Meeting ACL: HLT, pp. 10391047, Columbus, OH.Deleger, L., & Zweigenbaum, P. (2009). Extracting lay paraphrases specialized expressionsmonolingual comparable medical corpora. Proc. 2nd Workshop BuildingUsing Comparable Corpora: Parallel Non-parallel Corpora, pp. 210, Singapore.Dolan, B., & Dagan, I. (Eds.). (2005). Proc. ACL workshop Empirical Modeling Semantic Equivalence Entailment. Ann Arbor, MI.Dolan, B., Quirk, C., & Brockett, C. (2004). Unsupervised construction large paraphrase corpora: Eploiting massively parallel news sources. Proc. 20th Int. Conf. Comp.Linguistics, pp. 350356, Geneva, Switzerland.Dolan, W. B., & Brockett, C. (2005). Automatically constructing corpus sentential paraphrases.Proc. 3rd Int. Workshop Paraphrasing, pp. 916, Jeju island, Korea.177fiA NDROUTSOPOULOS & ALAKASIOTISDras, M. (1998). Search constraint-based paraphrasing. Proc. 2nd Int. Conf. NaturalLang. Processing Industrial Applications, pp. 213219, Moncton, Canada.Drass, M., & Yamamoto, K. (Eds.). (2005). Proc. 3rd Int. Workshop Paraphrasing. Jejuisland, Korea.Duboue, P. A., & Chu-Carroll, J. (2006). Answering question wish asked:impact paraphrasing question answering. Proc. HLT Conf. NAACL, pp.3336, New York, NY.Duclaye, F., Yvon, F., & Collin, O. (2003). Learning paraphrases improve question-answeringsystem. Proc. EACL Workshop Nat. Lang. Processing Question Answering,pp. 3541, Budapest, Hungary.Durbin, R., Eddy, S., Krogh, A., & Mitchison, G. (1998). Biological Sequence Analysis. CambridgeUniversity Press.Elhadad, N., & Sutaria, K. (2007). Mining lexicon technical terms lay equivalents. Proc.Workshop BioNLP, pp. 4956, Prague, Czech Republic.Erk, K., & Pado, S. (2006). Shalmaneser toolchain shallow semantic parsing. Proc.5th Language Resources Evaluation Conference, Genoa, Italy.Erk, K., & Pado, S. (2009). Paraphrase assessment structured vector space: Exploring parametersdatasets. Proc. EACL Workshop Geometrical Models Nat. Lang. Semantics,pp. 5765, Athens, Greece.Fellbaum, C. (1998). WordNet: Electronic Lexical Database. MIT Press.Finch, A., Hwang, Y. S., & Sumita, E. (2005). Using machine translation evaluation techniquesdetermine sentence-level semantic equivalence. Proc. 3rd Int. Workshop Paraphrasing, pp. 1724, Jeju Island, Korea.Freund, Y., & Schapire, R. E. (1995). decision-theoretic generalization on-line learningapplication boosting. Proc. 2nd European Conf. Computational LearningTheory, pp. 2337, Barcelona, Spain.Friedman, J., Hastie, T., & Tibshirani, R. (2000). Additive logistic regression: statistical viewboosting. Annals Statistics, 28(2), 337374.Fung, P., & Cheung, P. (2004). Multi-level bootstrapping extracting parallel sentencesquasi-comparable corpus. Proc. 20th Int. Conf. Comp. Linguistics, pp. 10511057, Geneva, Switzerland.Galanis, D., & Androutsopoulos, I. (2010). extractive supervised two-stage method sentencecompression. Proc. HLT Conf. NAACL, Los Angeles, CA.Gale, W., & Church, K. (1993). program aligning sentences bilingual corpora. Comp.Linguistics, 19(1), 75102.Germann, U., Jahr, M., Knight, K., Marcu, D., & Yamada, K. (2001). Fast decoding optimaldecoding machine translation. Proc. 39th Annual Meeting ACL, pp. 228235,Toulouse, France.Giampiccolo, D., Dang, H., Magnini, B., Dagan, I., & Dolan, B. (2008). fourth PASCAL recognizing textual entailment challenge. Proc. Text Analysis Conference, pp. 19,Gaithersburg, MD.178fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSGiampiccolo, D., Magnini, B., Dagan, I., & Dolan, B. (2007). third PASCAL recognizing textual entailment challenge. Proc. ACL-Pascal Workshop Textual EntailmentParaphrasing, pp. 19, Prague, Czech Republic.Glickman, O., & Dagan, I. (2004). Acquiring lexical paraphrases single corpus. Nicolov, N., Bontcheva, K., Angelova, G., & Mitkov, R. (Eds.), Recent Advances Nat. Lang.Processing III, pp. 8190. John Benjamins.Grishman, R. (2003). Information extraction. Mitkov, R. (Ed.), Oxford Handbook Comp.Linguistics, chap. 30, pp. 545559. Oxford University Press.Habash, N., & Dorr, B. (2003). categorial variation database english. Proc. HLTConf. NAACL, pp. 1723, Edmonton, Canada.Haghighi, A. D. (2005). Robust textual inference via graph matching. Proc. Conf.EMNLP , pp. 387394, Vancouver, BC , Canada.Harabagiu, S., & Hickl, A. (2006). Methods using textual entailment open-domain questionanswering. Proc. 21st Int. Conf. Comp. Linguistics 44th Annual MeetingACL, pp. 905912, Sydney, Australia.Harabagiu, S., Hickl, A., & Lacatusu, F. (2006). Negation, contrast contradiction text processing. Proc. 21st National Conf. Artificial Intelligence, pp. 755762, Boston,.Harabagiu, S., & Moldovan, D. (2003). Question answering. Mitkov, R. (Ed.), OxfordHandbook Comp. Linguistics, chap. 31, pp. 560582. Oxford University Press.Harabagiu, S. M., Maiorano, S. J., & Pasca, M. A. (2003). Open-domain textual question answeringtechniques. Nat. Lang. Engineering, 9(3), 231267.Harmeling, S. (2009). Inferring textual entailment probabilistically sound calculus. Nat.Lang. Engineering, 15(4), 459477.Harris, Z. (1964). Distributional Structure. Katz, J., & Fodor, J. (Eds.), Philosphy Linguistics, pp. 3349. Oxford University Press.Hashimoto, C., Torisawa, K., Kuroda, K., De Saeger, S., Murata, M., & Kazama, J. (2009). Largescale verb entailment acquisition Web. Proc. Conf. EMNLP, pp. 11721181, Singapore.Hearst, M. (1998). Automated discovery Wordnet relations. Fellbaum, C. (Ed.), WordNet:Electronic Lexical Database. MIT Press.Herbelot, A. (2009). Finding word substitutions using distributional similarity baseline immediate context overlap. Proc. Student Research Workshop 12th Conf. EACL,pp. 2836, Athens, Greece.Hickl, A. (2008). Using discourse commitments recognize textual entailment. Proc.22nd Int. Conf. Comp. Linguistics, pp. 337344, Manchester, UK.Hobbs, J. (1986). Resolving pronoun references. Readings Nat. Lang. Processing, pp. 339352. Morgan Kaufmann.Hovy, E. (2003). Text summarization. Mitkov, R. (Ed.), Oxford Handbook Comp. Linguistics, chap. 32, pp. 583598. Oxford University Press.179fiA NDROUTSOPOULOS & ALAKASIOTISHuffman, S. (1995). Learning information extraction patterns examples. Proc. IJCAIWorkshop New Approaches Learning Nat. Lang. Processing, pp. 127142, Montreal,Quebec, Canada.Ibrahim, A., Katz, B., & Lin, J. (2003). Extracting structural paraphrases aligned monolingualcorpora. Proc. ACL Workshop Paraphrasing, pp. 5764, Sapporo, Japan.Iftene, A. (2008). UAIC participation RTE 4. Proc. Text Analysis Conference, Gaithersburg, MD.Iftene, A., & Balahur-Dobrescu, A. (2007). Hypothesis transformation semantic variability rulesused recognizing textual entailment. Proc. ACL - PASCAL Workshop TextualEntailment Paraphrasing, pp. 125130, Prague, Czech Republic.Inui, K., & Hermjakob, U. (Eds.). (2003). Proc. 2nd Int. Workshop Paraphrasing: Paraphrase Acquisition Applications. Sapporo, Japan.Jacquemin, C., & Bourigault, D. (2003). Term extraction automatic indexing. Mitkov, R.(Ed.), Oxford Handbook Comp. Linguistics, chap. 33, pp. 599615. Oxford UniversityPress.Joachims, T. (2002). Learning Classify Text Using Support Vector Machines: Methods, Theory,Algorithms. Kluwer.Jurafsky, D., & Martin, J. H. (2008). Speech Language Processing (2nd edition). Prentice Hall.Kauchak, D., & Barzilay, R. (2006). Paraphrasing automatic evaluation. Proc. HLTConf. NAACL, pp. 455462, New York, NY.Klein, D., & Manning, C. D. (2003). Accurate unlexicalized parsing. Proc. 41st AnnualMeeting ACL, pp. 423430, Sapporo, Japan.Knight, K., & Marcu, D. (2002). Summarization beyond sentence extraction: probalistic approachsentence compression. Artificial Intelligence, 139(1), 91107.Koehn, P. (2004). Pharaoh: beam search decoder phrase-based statistical machine translationmodels. Proc. 6th Conf. Association Machine Translation Americas,pp. 115124, Washington, DC.Koehn, P. (2009). Statistical Machine Translation. Cambridge University Press.Koehn, P., Och, F. J., & Marcu, D. (2003). Statistical phrase-based translation. Proc. HLTConf. NAACL, pp. 4854, Edmonton, Canada. ACL.Kohomban, U., & Lee, W. (2005). Learning semantic classes word sense disambiguation.Proc. 43rd Annual Meeting ACL, pp. 3441, Ann Arbor, MI.Kouylekov, M., & Magnini, B. (2005). Recognizing textual entailment tree edit distance algorithms. Proc. PASCAL Recognising Textual Entailment Challenge.Kubler, S., McDonald, R., & Nivre, J. (2009). Dependency Parsing. Synthesis Lectures HLT.Morgan Claypool Publishers.Lappin, S., & Leass, H. (1994). algorithm pronominal anaphora resolution. Comp. Linguistics, 20(4), 535561.Leacock, C., Miller, G., & Chodorow, M. (1998). Using corpus statistics WordNet relationssense identification. Comp. Linguistics, 24(1), 147165.180fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSLepage, Y., & Denoual, E. (2005). Automatic generation paraphrases used translationreferences objective evaluation measures machine translation. Proc. 3rd Int.Workshop Paraphrasing, pp. 5764, Jesu Island, Korea.Levenshtein, V. (1966). Binary codes capable correcting deletions, insertions, reversals.Soviet Physice-Doklady, 10, 707710.Lin, D. (1994). PRINCIPAR: efficient, broad-coverage, principle-based parser. Proc.15th Conf. Comp. Linguistics, pp. 482488, Kyoto, Japan. ACL.Lin, D. (1998a). Automatic retrieval clustering similar words. Proc. 36th AnnualMeeting ACL 17th Int. Conf. Comp. Linguistics, pp. 768774, Montreal, Quebec,Canada.Lin, D. (1998b). information-theoretic definition similarity. Proc. 15th Int. Conf.Machine Learning, pp. 296304, Madison, WI. Morgan Kaufmann, San Francisco, CA.Lin, D. (1998c). information-theoretic definition similarity. Proc. 15th Int. Conf.Machine Learning, pp. 296304, Madison, WI.Lin, D., & Pantel, P. (2001). Discovery inference rules question answering. Nat. Lang.Engineering, 7, 343360.Lonneker-Rodman, B., & Baker, C. (2009). FrameNet model applications. Nat. Lang.Engineering, 15(3), 414453.MacCartney, B., Galley, M., & Manning, C. (2008). phrase-based alignment model naturallanguage inference. Proc. Conf. EMNLP, pp. 802811, Honolulu, Hawaii.MacCartney, B., & Manning, C. (2009). extended model natural logic. Proc. 8th Int.Conf. Computational Semantics, pp. 140156, Tilburg, Netherlands.Madnani, N., Ayan, F., Resnik, P., & Dorr, B. J. (2007). Using paraphrases parameter tuningstatistical machine translation. Proc. 2nd Workshop Statistical Machine Translation,pp. 120127, Prague, Czech Republic.Malakasiotis, P. (2009). Paraphrase recognition using machine learning combine similarity measures. Proc. 47th Annual Meeting ACL 4th Int. Joint Conf. Nat. Lang.Processing AFNLP, Singapore.Malakasiotis, P., & Androutsopoulos, I. (2007). Learning textual entailment using SVMs stringsimilarity measures. Proc. ACL - PASCAL Workshop Textual Entailment Paraphrasing, pp. 4247, Prague. ACL.Mani, I. (2001). Automatic Summarization. John Benjamins.Manning, C. D. (2008). Introduction Information Retrieval. Cambridge University Press.Manning, C. D., & Schuetze, H. (1999). Foundations Statistical Natural Language Processing.MIT press.Marquez, L., Carreras, X., Litkowski, K. C., & Stevenson, S. (2008). Semantic role labeling:introduction special issue. Comp. Linguistics, 34(2), 145159.Marton, Y., Callison-Burch, C., & Resnik, P. (2009). Improved statistical machine translation usingmonolingually-derived paraphrases. Proc. Conf. EMNLP, pp. 381390, Singapore.181fiA NDROUTSOPOULOS & ALAKASIOTISMcCarthy, D., & Navigli, R. (2009). English lexical substitution task. Lang. Resources &Evaluation, 43, 139159.McDonald, R. (2006). Discriminative sentence compression soft syntactic constraints. Proc.11th Conf. EACL, pp. 297304, Trento, Italy.McKeown, K. (1983). Paraphrasing questions using given new information. Comp. Linguistics,9(1).Mehdad, Y. (2009). Automatic cost estimation tree edit distance using particle swarm optimization. Proc. 47th Annual Meeting ACL 4th Int. Joint Conf. Nat. Lang.Processing AFNLP, pp. 289292, Singapore.Melamed, D. (1999). Bitext maps alignment via pattern recognition. Comp. Linguistics, 25(1),107130.Melcuk, I. (1987). Dependency Syntax: Theory Practice. State University New York Press.Meyers, A., Macleod, C., Yangarber, R., Grishman, R., Barrett, L., & Reeves, R. (1998). UsingNOMLEX produce nominalization patterns information extraction. Proc.COLING - ACL workshop Computational Treatment Nominals, Montreal, Quebec,Canada.Mintz, M., Bills, S., Snow, R., & Jurafsky, D. (2009). Distant supervision relation extractionwithout labeled data. Proc. 47th Annual Meeting ACL 4th Int. Joint Conf.Nat. Lang. Processing AFNLP, pp. 10031011, Singapore.Mirkin, S., Dagan, I., & Shnarch, E. (2009a). Evaluating inferential utility lexical-semanticresources. Proc. 12th Conf. EACL, pp. 558566, Athens, Greece.Mirkin, S., Specia, L., Cancedda, N., Dagan, I., Dymetman, M., & Szpektor, I. (2009b). Sourcelanguage entailment modeling translating unknown terms. Proc. 47th AnnualMeeting ACL 4th Int. Joint Conf. Nat. Lang. Processing AFNLP, pp. 791799, Singapore.Mitchell, J., & Lapata, M. (2008). Vector-based models semantic composition. Proc.46th Annual Meeting ACL: HLT, pp. 236244, Columbus, OH.Mitchell, T. (1997). Machine Learning. Mc-Graw Hill.Mitkov, R. (2003). Anaphora resolution. Mitkov, R. (Ed.), Oxford Handbook Comp.Linguistics, chap. 14, pp. 266283. Oxford University Press.Moens, M. (2006). Information Extraction: Algorithms Prospects Retrieval Context.Springer.Moldovan, D., & Rus, V. (2001). Logic form transformation WordNet applicabilityquestion answering. Proc. 39th Annual Meeting ACL, pp. 402409, Toulouse,France.Molla, D., Schwitter, R., Rinaldi, F., Dowdall, J., & Hess, M. (2003). Anaphora resolution E X TR NS. Proc. Int. Symposium Reference Resolution ApplicationsQuestion Answering Summarization, pp. 2325, Venice, Italy.Molla, D., & Vicedo, J. (2007). Question answering restricted domains: overview. Comp.Linguistics, 33(1), 4161.182fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSMoore, R. C. (2001). Towards simple accurate statistical approach learning translation relationships among words. Proc. ACL Workshop Data-Driven Machine Translation,Toulouse, France.Moschitti, A. (2009). Syntactic semantic kernels short text pair categorization. Proc.12th Conf. EACL, pp. 576584, Athens, Greece.Munteanu, D. S., & Marcu, D. (2006). Improving machine translation performance exploitingnon-parallel corpora. Comp. Linguistics, 31(4), 477504.Muslea, I. (1999). Extraction patterns information extraction tasks: survey. Proc.AAAI Workshop Machine Learning Information Extraction, Orlando, FL.Navigli, R. (2008). structural approach automatic adjudication word sense disagreements. Nat. Lang. Engineering, 14(4), 547573.Nelken, R., & Shieber, S. M. (2006). Towards robust context-sensitive sentence alignmentmonolingual corpora. Proc. 11th Conf. EACL, pp. 161168, Trento, Italy.Nielsen, R., Ward, W., & Martin, J. (2009). Recognizing entailment intelligent tutoring systems.Nat. Lang. Engineering, 15(4), 479501.Nivre, J., Hall, J., Nilsson, J., Chanev, A., Eryigit, G., Kuebler, S., Marinov, S., & Marsi, E. (2007).ALT PARSER: language-independent system data-driven dependency parsing. Nat.Lang. Engineering, 13(2), 95135.Och, F. J., & Ney, H. (2003). systematic comparison various stat. alignment models. Comp.Ling., 29(1), 1921.ODonnell, M., Mellish, C., Oberlander, J., & Knott, A. (2001). ILEX: architecture dynamichypertext generation system. Nat. Lang. Engineering, 7(3), 225250.Pado, S., Galley, M., Jurafsky, D., & Manning, C. D. (2009). Robust machine translation evaluationentailment features. Proc. 47th Annual Meeting ACL 4th Int. JointConf. Nat. Lang. Processing AFNLP, pp. 297305, Singapore.Pado, S., & Lapata, M. (2007). Dependency-based construction semantic space models. Comp.Ling., 33(2), 161199.Palmer, M., Gildea, D., & Kingsbury, P. (2005). Propositional Bank: annotated corpussemantic roles. Comp. Linguistics, 31(1), 71105.Pang, B., Knight, K., & Marcu, D. (2003). Syntax-based alignment multiple translations: extracting paraphrases generating new sentences. Proc. Human Lang. Techn. Conf.NAACL , pp. 102109, Edmonton, Canada.Pantel, P., Bhagat, R., Coppola, B., Chklovski, T., & Hovy, E. H. (2007). ISP: Learning inferentialselectional preferences. Proc. HLT Conf. NAACL, pp. 564571, Rochester, NY.Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002). BLEU: method automatic evaluationmachine translation. Proc. 40th Annual Meeting ACL, pp. 311318, Philadelphia,PA .Pasca, M. (2003). Open-domain question answering large text collections (2nd edition). CenterStudy Language Information.183fiA NDROUTSOPOULOS & ALAKASIOTISPasca, M., & Dienes, P. (2005). Aligning needles haystack: Paraphrase acquisition acrossWeb. Proc. 2nd Int. Joint Conf. Nat. Lang. Processing, pp. 119130, Jeju Island,Korea.Perez, D., & Alfonseca, E. (2005). Application BLEU algorithm recognizing textualentailments. Proc. PASCAL Challenges Worshop Recognising Textual Entailment,Southampton, UK.Porter, M. F. (1997). algorithm suffix stripping. Jones, K. S., & Willet, P. (Eds.), ReadingsInformation Retrieval, pp. 313316. Morgan Kaufmann.Power, R., & Scott, D. (2005). Automatic generation large-scale paraphrases. Proc. 3rdInt. Workshop Paraphrasing, pp. 7379, Jesu Island, Korea.Qiu, L., Kan, M. Y., & Chua, T. (2006). Paraphrase recognition via dissimilarity significance classification. Proc. Conf. EMNLP, pp. 1826, Sydney, Australia.Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann.Quirk, C., Brockett, C., & Dolan, W. B. (2004). Monolingual machine translation paraphrasegeneration. Proc. Conf. EMNLP, pp. 142149, Barcelona, Spain.Ravichandran, D., & Hovy, E. (2002). Learning surface text patterns question answeringsystem. Proc. 40th Annual Meeting ACL, pp. 4147, Philadelphia, PA.Ravichandran, D., Ittycheriah, A., & Roukos, S. (2003). Automatic derivation surface text patterns maximum entropy based question answering system. Proc. HLT Conf.NAACL , pp. 8587, Edmonton, Canada.Reiter, E., & Dale, R. (2000). Building Natural Language Generation Systems. Cambridge University Press.Resnik, P. (1999). Semantic similarity taxonomy: information-based measure application problems ambiguity natural language. Journal Artificial IntelligenceResearch, 11, 95130.Riezler, S., Vasserman, A., Tsochantaridis, I., Mittal, V., & Liu, Y. (2007). Statistical machinetranslation query expansion answer retrieval. Proc. 45th Annual MeetingACL , pp. 464471, Prague, Czech Republic.Riloff, E. (1996a). Automatically generating extraction patterns untagged text. Proc.13th National Conf. Artificial Intelligence, pp. 10441049, Portland, OR.Riloff, E. (1996b). empirical study automated dictionary construction information extraction three domains. Artificial Intelligence, 85(12), 101134.Riloff, E., & Jones, R. (1999). Learning dictionaries information extraction multi-level bootstrapping. Proc. 16th National Conf. Artificial Intelligence, pp. 474479, Orlando,FL.Rinaldi, F., Dowdall, J., Kaljurand, K., Hess, M., & Molla, D. (2003). Exploiting paraphrasesquestion answering system. Proc. 2nd Int. Workshop Paraphrasing, pp. 2532,Saporo, Japan.Sato, S., & Nakagawa, H. (Eds.). (2001). Proc. Workshop Automatic Paraphrasing. Tokyo,Japan.184fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSSchohn, G., & Cohn, D. (2000). Less more: active learning Support Vector Machines.Proc. 17th Int. Conf. Machine Learning, pp. 839846, Stanford, CA.Schuler, K. K. (2005). VerbNet: Broad-Coverage, Comprehensive Verb Lexicon. Ph.D. thesis,Univ. Pennsylvania.Sekine, S., Inui, K., Dagan, I., Dolan, B., Giampiccolo, D., & Magnini, B. (Eds.). (2007). Proc.ACL - PASCAL Workshop Textual Entailment Paraphrasing. Prague, Czech Republic.Sekine, S., & Ranchhod, E. (Eds.). (2009). Named Entities Recognition, Classification Use.John Benjamins.Selkow, S. (1977). tree-to-tree editing problem. Information Processing Letters, 6(6), 184186.Shinyama, Y., & Sekine, S. (2003). Paraphrase acquisition information extraction. Proc.ACL Workshop Paraphrasing, Sapporo, Japan.Siblini, R., & Kosseim, L. (2008). Using ontology alignment TAC RTE challenge. Proc.Text Analysis Conference, Gaithersburg, MD.Sleator, D. D., & Temperley, D. (1993). Parsing English link grammar. Proc. 3rd Int.Workshop Parsing Technologies, pp. 277292, Tilburg, Netherlands Durbuy, Belgium.Soderland, S. (1999). Learning inf. extraction rules semi-structured free text. Mach. Learning, 34(13), 233272.Soderland, S., Fisher, D., Aseltine, J., & Lehnert, W. G. (1995). CRYSTAL: Inducing conceptualdictionary. Proc. 14th Int. Joint Conf. Artificial Intelligence, pp. 13141319,Montreal, Quebec, Canada.Stevenson, M., & Wilks, Y. (2003). Word sense disambiguation. Mitkov, R. (Ed.), OxfordHandbook Comp. Linguistics, chap. 13, pp. 249265. Oxford University Press.Stolcke, A. (2002). SRILM extensible language modeling toolkit. Proc. 7th Int. Conf.Spoken Language Processing, pp. 901904, Denver, CO.Szpektor, I., & Dagan, I. (2007). Learning canonical forms entailment rules. Proc. RecentAdvances Natural Lang. Processing, Borovets, Bulgaria.Szpektor, I., & Dagan, I. (2008). Learning entailment rules unary templates. Proc.22nd Int. Conf. Comp. Linguistics, pp. 849856, Manchester, UK.Szpektor, I., Dagan, I., Bar-Haim, R., & Goldberger, J. (2008). Contextual preferences. Proc.46th Annual Meeting ACL: HLT, pp. 683691, Columbus, OH.Szpektor, I., Shnarch, E., & Dagan, I. (2007). Instance-based evaluation entailment rule acquisition. Proc. 45th Annual Meeting ACL, pp. 456463, Prague, Czech Republic.Szpektor, I., Tanev, H., Dagan, I., & Coppola, B. (2004). Scaling Web-based acquisition entailment relations. Proc. Conf. EMNLP, Barcelona, Spain.Tai, K.-C. (1979). tree-to-tree correction problem. Journal ACM, 26(3), 422433.Tatu, M., Iles, B., Slavick, J., Novischi, A., & Moldovan, D. (2006). COGEX second recognizing textual entailment challenge. Proc. 2nd PASCAL Challenges WorkshopRecognising Textual Entailment, Venice, Italy.185fiA NDROUTSOPOULOS & ALAKASIOTISTatu, M., & Moldovan, D. (2005). semantic approach recognizing textual entailment. Proc.Conf. HLT EMNLP, pp. 371378, Vancouver, Canada.Tatu, M., & Moldovan, D. (2007). COGEX RTE 3. Proc. ACL - PASCAL WorkshopTextual Entailment Paraphrasing, pp. 2227, Prague, Czech Republic.Tomuro, N. (2003). Interrogative reformulation patterns acquisition question paraphrases.Proc. 2nd Int. Workshop Paraphrasing, pp. 3340, Sapporo, Japan.Tong, S., & Koller, D. (2002). Support Vector Machine active learning applications textclassification. Machine Learning Research, 2, 4566.Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). Feature-rich part-of-speech tagging cyclic dependency network. Proc. HLT Conf. NAACL, pp. 173180,Edmonton, Canada.Tsatsaronis, G. (2009). Word Sense Disambiguation Text Relatedness Based Word Thesauri.Ph.D. thesis, Department Informatics, Athens University Economics Business.Tsatsaronis, G., Varlamis, I., & Vazirgiannis, M. (2010). Text relatedness based word thesaurus.Artificial Intelligence Research, 37, 139.Turney, P., & Pantel, P. (2010). frequency meaning: Vector space models semantics.Artificial Intelligence Research, 37, 141188.Vapnik, V. (1998). Statistical learning theory. John Wiley.Vendler, Z. (1967). Verbs Times. Linguistics Philosophy, chap. 4, pp. 97121. CornellUniversity Press.Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment statistical translation.Proc. 16th Conf. Comp. Linguistics, pp. 836841, Copenhagen, Denmark.Voorhees, E. (2001). TREC QA track. Nat. Lang. Engineering, 7(4), 361378.Voorhees, E. (2008). Contradictions justifications: Extensions textual entailment task.Proc. 46th Annual Meeting ACL: HLT, pp. 6371, Columbus, OH.Wan, S., Dras, M., Dale, R., & Paris, C. (2006). Using dependency-based features take parafarce paraphrase. Proc. Australasian Language Technology Workshop, pp.131138, Sydney, Australia.Wang, R., & Neumann, G. (2008). divide-and-conquer strategy recognizing textual entailment. Proc. Text Analysis Conference, Gaithersburg, MD.Wang, X., Lo, D., Jiang, J., Zhang, L., & Mei, H. (2009). Extracting paraphrases technical termsnoisy parallel software corpora. Proc. 47th Annual Meeting ACL 4thInt. Joint Conf. Nat. Lang. Processing AFNLP, pp. 197200, Singapore.Witten, I. H., & Frank, E. (2005). Data Mining: Practical Machine Learning Tools Techniques.Morgan Kaufmann.Wu, D. (2000). Alignment. Dale, R., Moisl, H., & Somers, H. (Eds.), Handbook Nat. Lang.Processing, pp. 415458. Marcel Dekker.Wubben, S., van den Bosch, A., Krahmer, E., & Marsi, E. (2009). Clustering matching headlinesautomatic paraphrase acquisition. Proc. 12th European Workshop Nat. Lang.Generation, pp. 122125, Athens, Greece.186fiA URVEY PARAPHRASING EXTUAL E NTAILMENT ETHODSXu, F., Uszkoreit, H., & Li, H. (2007). seed-driven bottom-up machine learning frameworkextracting relations various complexity. Proc. 45th Annual MeetingAssociation Comp. Linguistics, pp. 584591, Prague, Czech Republic.Yang, X., Su, J., & Tan, C. L. (2008). twin-candidate model learning-based anaphora resolution. Comp. Linguistics, 34(3), 327356.Yarowski, D. (2000). Word-sense disambiguation. Dale, R., Moisl, H., & Somers, H. (Eds.),Handbook Nat. Lang. Processing, pp. 629654. Marcel Dekker.Zaenen, A., Karttunen, L., & Crouch, R. (2005). Local textual inference: defined circumscribed?. Proc. ACL workshop Empirical Modeling Semantic EquivalenceEntailment, pp. 3136, Ann Arbor, MI.Zanzotto, F. M., & Dell Arciprete, L. (2009). Efficient kernels sentence pair classification.Proc. Conf. EMNLP, pp. 91100, Singapore.Zanzotto, F. M., Pennacchiotti, M., & Moschitti, A. (2009). machine-learning approach textualentailment recognition. Nat. Lang. Engineering, 15(4), 551582.Zhang, K., & Shasha, D. (1989). Simple fast algorithms editing distance treesrelated problems. SIAM Journal Computing, 18(6), 12451262.Zhang, Y., & Patrick, J. (2005). Paraphrase identification text canonicalization. Proc.Australasian Language Technology Workshop, pp. 160166, Sydney, Australia.Zhang, Y., & Yamamoto, K. (2005). Paraphrasing spoken Chinese using paraphrase corpus. Nat.Lang. Engineering, 11(4), 417434.Zhao, S., Lan, X., Liu, T., & Li, S. (2009). Application-driven statistical paraphrase generation.Proc. 47th Annual Meeting ACL 4th Int. Joint Conf. Nat. Lang. ProcessingAFNLP, pp. 834842, Singapore.Zhao, S., Wang, H., Liu, T., & Li, S. (2008). Pivot approach extracting paraphrase patternsbilingual corpora. Proc. 46th Annual Meeting ACL: HLT, pp. 780788, Columbus,OH .Zhitomirsky-Geffet, M., & Dagan, I. (2009). Bootstrapping distributional feature vector quality.Computational Linguistics, 35, 435461.Zhou, L., Lin, C.-Y., & Hovy, E. (2006a). Re-evaluating machine translation results paraphrasesupport. Proc. Conf. EMNLP, pp. 7784.Zhou, L., Lin, C.-Y., Munteanu, D. S., & Hovy, E. (2006b). PARA E VAL: Using paraphrasesevaluate summaries automatically. Proc. HLT Conf. NAACL, pp. 447454, NewYork, NY.187fiJournal Artificial Intelligence Research 38 (2010) 49-84Submitted 11/09; published 05/10Change Abstract Argumentation Frameworks:Adding ArgumentClaudette CayrolFlorence Dupin de Saint-CyrMarie-Christine Lagasquie-Schiexccayrol@irit.frbannay@irit.frlagasq@irit.frIRIT, Universite Paul Sabatier,118 route de Narbonne, 31062 Toulouse, FranceAbstractpaper, address problem change abstract argumentation system.focus particular change: addition new argument interactsprevious arguments. study impact addition outcome argumentation system, particularly set extensions. Several propertieschange operation defined comparing new set extensions initial one,properties called structural comparisons based set-cardinality setinclusion relations. Several properties proposed comparisons basedstatus particular arguments: accepted arguments; properties referevolution status change, e.g., Monotony Priority Recency.properties may less desirable according specific applications.studied two particular semantics: grounded preferred semantics.1. IntroductionArgumentation become influential approach handle Artificial Intelligence problemsincluding defeasible reasoning (see e.g., Pollock, 1992; Dung, 1995; Bondarenko, Dung,Kowalski, & Toni, 1997; Chesnevar, Maguitman, & Loui, 2000; Prakken & Vreeswijk, 2002;Amgoud & Cayrol, 2002; Nute, 2003), modeling agents interactions (see e.g., Amgoud,Maudet, & Parsons, 2000; Kakas & Moratis, 2003). Argumentation basically concernedexchange interacting arguments. set arguments may come eitherdialogue several agents also available (and possibly contradictory)pieces information disposal one unique agent. Usually, interactionarguments takes form conflict, called attack. example, logical argumentpair hset assumptions, conclusioni, set assumptions entailsconclusion according logical inference schema. conflict occurs, instance,conclusion argument contradicts assumption another argument.main issue argumentation system selection acceptable sets arguments, called extensions, based way arguments interact (intuitively, acceptableset arguments must sense coherent strong enough, e.g., able defendattacking arguments). So, outcome argumentation systemoften defined set extensions but, depending applications, may alsodefined set arguments belongs every extension. convenient exploreconcept extension argumentation frameworks, especially Dungs (1995)c2010AI Access Foundation. rights reserved.fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiexframework, abstracts arguments nature, represents interactionform binary relation attack set arguments.Recent works considered dynamics abstract argumentation frameworks(Cayrol, Dupin de Saint-Cyr, & Lagasquie-Schiex, 2008; Rotstein, Moguillansky, Garca, &Simari, 2008b; Boella, Kaci, & van der Torre, 2009a, 2009b). problem studyoutcome changes set arguments and/or set attackschanged. paper, focus case new argument interactionsadded argumentation system. study impact additionset initial extensions. leads us identify properties change operationrespect modification induces outcome. study two mainapplications, first one concerns computational issues, second one concernsdefinition dialogue strategies. one hand, interest computational processingknowledge properties change may help deducemodifications extensions. instance, useful know conditionschange modify previous extensions. hand, knowing impactadding argument may help choosing good one order achieve given goal.instance, multi-agent setting, i.e., several agents may present several arguments,results presented paper help one agent determine argumentspresent order outcome dialogue satisfies desired properties.example, wants widen debate, argument must added inducechange producing larger extensions (i.e. contain arguments, see Section 3Section 5).paper organized follows. Section 2 recalls basic concepts argumentation.Section 3 settles definition change argumentation. Many features takenaccount order characterize change operation. first propose class propertiesbased impact change structure resulting set extensions (seeSection 3.2). second step, define several properties regarding argumentsthemselves, particularly accepted change (see Section 3.3).properties defined regardless semantics.Then, focus particular change: addition new argument mayinteract previously introduced arguments. Section 4 dedicated studyproperties addition case two particular semantics, groundedpreferred semantics. give conditions given property satisfied. Section 5discusses related approaches literature. proofs (and two important lemmas) given Appendix A. additional examples presented Appendix Billustrating change operations.Note paper generalizes previous work (Cayrol et al., 2008), argumentaddition, called revision, restricted one argument one interactionexisting argumentation system. Here, added argument may interactnumber previous arguments. Moreover, broader analysis generalized additionprovided considering new properties as, e.g., Monotony, establishing newconnections different properties.50fiChange Argumentation Systems2. Basic Concepts Argumentation Frameworkspresent work lies frame general theory abstract argumentation frameworks proposed Dung (1995). abstract framework assumes set arguments given, well different conflicts them, focuses definitionstatus arguments.Definition 1 (Argumentation framework) argumentation framework hA, Ripair, non-empty set R binary relation A, called attack relation.Let A, B A, (A, B) R equivalently ARB means attacks B, B attackedA.following, hA, Ri argumentation framework, assume setarguments finite. First, easy extend concept attack sets arguments.Definition 2 (Attack set) Let A.1attacks iff X XRA.attacks iff X ARX.main issue argumentation system selection acceptable sets arguments. Intuitively, acceptable set arguments must sense coherentstrong enough (e.g., able defend every attacking argument). argumentation semantics defines properties required set arguments acceptable (thiscollective acceptability). selected sets arguments given semanticscalled extensions semantics. set extensions characterizes outcomeargumentation system. recall basic concepts used defining usual semantics:Definition 3 (Conflict-free, defense) Let A.conflict-free iff A, B ARB.defends iff attacks argument attacks A. set argumentsdefends denoted F(S). F called characteristic function hA, Ri.literature proposes increasing variety semantics, refining Dungs traditionalones (Baroni, Giacomin, & Guida, 2005; Caminada, 2006; Dung, Mancarella, & Toni, 2006;Coste-Marquis, Devred, & Marquis, 2005). paper, well-known traditional semantics considered: grounded, preferred stable semantics.Definition 4 (Acceptability semantics) Let E A.E admissible iff E conflict-free defends elements (i.e. E F(E)).E preferred extension iff E maximal (w.r.t. set-inclusion) admissible set.1. paper, use denote strict inclusion denote classical inclusion.51fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexE grounded extension iff E least fixed point (w.r.t. set-inclusion)characteristic function F.E stable extension iff E conflict-free attacks argumentbelong E.argumentation framework represented directed graph, called attackgraph, nodes arguments edges represent attack relation. Throughoutpaper, examples using graph representation.Example 1= {A, B, C, D, F } R = {(A, B), (B, A), (B, C), (C, D), (D, F ), (F, C)}.admissible sets {}, {A}, {B} {B, D}.BCpreferred extensions {A} {B, D}.grounded extension {}.F{B, D} unique stable extension.Using graph-based representation argumentation framework, extenddefinition individual attack follows:Definition 5 (indirect attack defense) Let G denote attack graph associatedhA, Ri. Let A, B A.indirectly attacks B iff odd-length path B attack graphG.indirectly defends B iff even-length path (with non-zero length)B attack graph G.Note case attacks B considered particular case indirect attack.Dung (1995) proved following results.Proposition 1 Let hA, Ri argumentation framework.1. least one preferred extension, always unique grounded extension,may zero, one many stable extensions.2. admissible set included preferred extension.3. stable extension preferred extension, converse false.4. grounded extension included preferred extension.5. argument attacked belongs grounded extension (hencepreferred stable extension).6. R finite, grounded extension computed iteratively applyingfunction F empty set.52fiChange Argumentation Systemspresence cycles attack graph often raised problems, namelystable semantics, may happen extension exists. Note authorsconsider attack graphs without odd-length cycles, arguing odd-length cyclecarries counterintuitive information. following results give properties preferred,grounded stable extensions depending existence cycles attack graph.Proposition 2 (Dunne & Bench-Capon, 2001, 2002) Let G denote attack graph associated hA, Ri.1. G contains cycle, hA, Ri unique preferred extension, alsogrounded extension unique stable extension.2. {} unique preferred extension hA, Ri, G contains odd-length cycle.3. hA, Ri stable extension, G contains odd-length cycle.4. G contains odd-length cycle, preferred stable extensions coincide.5. G contains even-length cycle, hA, Ri unique preferred extension.acceptable sets arguments defined, possible define statusindividual argument.Definition 6 (Argument status) Let hA, Ri argumentation frameworkA. Given semantics s:skeptically accepted iff belongs extension hA, Ri s.credulously accepted iff belongs least one extension hA, Ris.rejected iff belong extension hA, Ri s.Obviously, credulous skeptical acceptance coincide grounded semantics.3. Change Argumentationintroduce formal definition change argumentation enables distinguishfour types change. define properties change argumentation. First,consider impact change operation structure set extensions,study structure modified. point view leads definitionstructural properties. Then, consider impact change operation setarguments accepted. Finally, connections classes propertiesstudied.Note properties introduce, definition generalsense applied type change. Section 4 (where give conditionssatisfying properties), focus particular case additionargument interactions.53fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex3.1 Definitionsection, give definition change argumentation. change may concernset arguments and/or set attacks them. So, least four casesencountered:Definition 7 (Change operations) Let hA, Ri argumentation framework.adding one interaction i0 two existing arguments (i0 = (X, )X A) change operation defined by:hA, Rii i0 = hA, R {i0 }iremoving one existing interaction i0 hA, Ri (i0 R) change operationdefined by:hA, Rii i0 = hA, R \ {i0 }iadding one argument Z 6 set interactions concerning Z denotedIz change operation defined by:hA, Rii (Z, Iz ) = hA {Z}, R IzHere, Iz supposed non-empty set pairs arguments (either form(X, Z) (Z, X) X A)2removing one argument Z interacts arguments changeoperation defined by:hA, Rii Z = hA \ {Z}, R \ IzHere, Iz denotes set interactions concerning Z, set {(Z, X) |(Z, X) R} {(X, Z)|(X, Z) R}3Note case adding new argument (resp. removing existing argument)interact argument trivial: added (resp.removed from) extension. Indeed, change interesting concernedargument interacts previous ones.recent work dynamics argumentation (Boella et al., 2009a, 2009b),four types change defined introduced different names, respectively attack refinement, attack abstraction, argument refinement argument abstraction. However, operations attack refinement, attack abstraction argumentabstraction studied restricted context (see Section 5 discussion).following, identify argumentation framework hA, Ri associatedattack graph G. write X G instead X argument represented node G.set extensions hA, Ri denoted E (with E1 , . . . , En denoting extensions).2. Note that, definition, impossible (Z, Z) Iz .3. Note Z removed, set interactions concerning Z must also removed.54fiChange Argumentation Systemschange operation produces new framework hA , R represented graph G ,new set extensions E (with E1 , . . . , Ep denoting extensions).explained above, changing argumentation framework may modify set extensions. Given semantics, modifications less important. dependskinds interactions added removed precisely statusarguments involved interactions.impact change studied two points view:first one concerns structure set extensions address eithercomparison number extensions change, or,number remains unchanged, comparison contents extensionschange;second point view concerns status particular arguments.So, next sections, propose two classes general properties changeoperation, one point view. proposed properties characterize relationparticular framework resulting framework change.3.2 Structural PropertiesStructural properties, presented section, based impact changestructure set extensions. Note property, definition generalsense type change operation specified: consist addingone interaction, removing one interaction, adding argument set interactionsconcerning argument, removing one argument. However, sake clarity,property illustrated section examples change operation ;reader find examples change operations Appendix B.Let hA, Ri argumentation framework E set extensions hA, Ri(under given semantics s). Various situations may encountered general case.E may empty (implying stable semantics), may reduced singleton{E1 } (where E1 may empty), may contain one extension {E1 , . . . , En }.situation one non-empty extension convenient determinationstatus argument. contrast, several extensions exist, different choicesavailable. Table 1 summarizes various definitions presented below.first consider decisive property change operation, meaning Gunique non-empty extension, case G.Definition 8 (Decisive change) change G G decisive iff E = , E ={{}}, E = {E1 , . . . , En }, n 2, E = {E }, E 6= {}.Example 21. stable (resp. grounded preferred) semantics, changeIz = {(Z, A)} decisive since:BZCE = (resp. E = {{}}),E = {{Z, B}}55ai ZfiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexProperty change operationchange decisivechange restrictivechange questioningchange destructivechange expansivechange conservativechange alteringCharacterization propertyE = E = {{}} |E| > 2|E | = 1 E 6= {{}}|E| > |E | > 2|E| < |E |E 6= E 6= {{}}E = E = {{}}|E| = |E |Ej E , Ei E, Ei EjE = E|E| = |E |Ei E s.t. Ej E , Ei 6 EjTable 1: Structural properties change operation2. grounded semantics, changesince:ZBCBZCFBaiZ Iz = {(Z, A)} decisiveaiZ Iz = {(Z, A), (B, Z)}E = {{A}, {B, D}},E = {{Z, B, D}}4. preferred semantics, changedecisive since:Z Iz = {(Z, A)} decisiveE = {{}},E = {{Z, B}}3. preferred semantics, changesince:aiE = {{A}, {B}},E = {{B}} (note Z rejected)Zweaker requirement decrease number choices. change Gstrictly less extensions G, still least two, called restrictive4 . Noterestrictive property make sense grounded semantics, sincealways unique grounded extension.Definition 9 (Restrictive change) change G G restrictive iff E = {E1 ,. . . , En }, n 2, E = {E1 , . . . , Ep }, n > p 2.Example 31. preferred (or stable) semantics, changerestrictive since:BCZFaiZ Iz = {(Z, A)}E = {{A, C, F }, {A, D}, {B, D}, {B, F }},E = {{Z, C, F }, {Z, B, D}, {Z, B, F }}4. work Cayrol et al. (2008), kind change called selective.56fiChange Argumentation Systems2. preferred semantics, changerestrictive since:BCZaiZ Iz = {(Z, A), (B, Z)}E = {{A}, {B}, {C}},E = {{B}, {C, Z}} (note Z skepticallyaccepted)opposite point view enables consider changes raise ambiguity, increasing number extensions. case instance G least onenon-empty extension G strictly extensions G. slightly different situation occurs G extension empty one, G one extension.case, change brings information, decisive. changes calledquestioning. restrictive property, questioning property make sensegrounded semantics.Definition 10 (Questioning change) change G G questioning iff E ={E1 , . . . , Ep }, p 2, either E = , E = {E1 , . . . , En } p > n 1.Example 41. preferred (or stable) semantics, changequestioning since:BZCFBZCGFaiBCZ Iz = {(Z, A)} questioningE = ,E = {{Z, B, F }, {Z, B, G}}3. preferred semantics, change(Z, B), (B, Z)} questioning since:ZZ Iz = {(Z, A)}E = {{A, D, F }},E = {{Z, B, C}, {Z, B, F }, {Z, D, C}, {Z, D, F }}2. stable semantics, changesince:aiaiZ Iz = {(Z, A), (A, Z),E = {{A, D}, {B, D}},E = {{A, D}, {B, D}, {Z}} (note Z skeptically accepted)Pursuing along previous line, consider changes leading kind decisionaldead-end. case G least one non-empty extension Gextension, empty one5 . change called destructive.Definition 11 (Destructive change) change G G destructive iff E ={E1 , . . . , En }, n 1, Ei 6= {} E = E = {{}}.Example 55. two different cases impact: possible decisionargument accepted.57fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex1. stable semantics, changesince:BHZCGFaiZ Iz = {(Z, A)} destructiveE = {{A, D, F }, {A, D, G}},E =2. preferred (or grounded) semantics, change Z Iz = {(Z, A),(B, Z)} destructive since:BE = {{A}},E = {{}}Z3. preferred semantics, change Z Iz = {(Z, A), (Z, B), (F, Z)}destructive since:BCZFE = {{A}, {B, D}},E = {{}}far, considered changes impact number extensions. Now,interested changes may modify content extensions, without modifyingnumber extensions. interesting situation occurs extension Gstrictly includes one extension G, number extensions same. changescalled expansive.Definition 12 (Expansive change) change G G expansive iff G Gnumber extensions extension G strictly includes extensionG.Example 6 preferred (or stable) semantics, change{(B, Z)} expansive since:BCZaiZ Iz =E = {{A, C}, {A, D}},E = {{Z, A, C}, {Z, A, D}}particular case set extensions remains unchanged, change calledconservative.Definition 13 (Conservative change) change G G conservative iff GG exactly extensions, E = E .Example 71. preferred semantics, changevative since:BCZBZZ Iz = {(B, Z)} conser-aiZ Iz = {(A, Z)} conser-E = {{}},E = {{}}2. preferred semantics, changevative since:aiCE = {{A, C}},E = {{A, C}}58fiChange Argumentation Systems3. preferred semantics, changevative since:BCZaiZ Iz = {(A, Z)} conser-E = {{A, C}, {A, D}},E = {{A, C}, {A, D}}Otherwise, may happen G G number extensionsextensions (and sometimes them) altered. called altering change.Definition 14 (Altering change) change G G altering iff G Gnumber extensions exists least one extension Ei G Ejextension G , Ei * Ej .case instance extension G non-empty intersection(but include) extension G.Example 81. grounded semantics, changesince:BZCBCZ Iz = {(Z, A)} alteringaiZ Iz = {(Z, E), (F, Z)}E = {{A, D},E = {{Z, B, D}}2. preferred semantics, changealtering since:aiEFZE = {{A, C, E}},E = {{A, C}} (note Z rejected)discussion summarized Table 2. table, checkedcells #i correspond situations cannot occur:#1 #2 acceptability semantics argumentation framework mayextension stable semantics. However, stable semantics,argumentation framework cannot empty extension set argumentsempty. And, assumption, cases #1 #2 correspond argumentationframeworks non-empty sets arguments (because assumption either Iz 6=exists one interaction = (X, ), least one X G Xeventually Z belong G ). cases occur change operationacceptability semantics considered paper.Note structural properties presented Table 2 mutually exclusive (thatchange operation cannot satisfy two them).59fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexE =E={{}}{{}}conservative#2#1conservative{E1 }{E1 , . . . , Ep }p2decisivequestioningconservativeexpansivealtering{E1 }destructive{E1 , . . . , En }n2decisivequestioningn < p:questioningn > p:restrictiven = p:conservativeexpansivealteringEi 6= {} Ei 6= {}. cell table contains name correspondingproperty change operation.Table 2: Structural properties change operation3.3 Status-Based Propertiessection, interested impact change operation statusparticular arguments.First, interested status arguments acceptedchange. leads propose property called Monotony, definedtype change.Another interesting issue concerns status argument addedchange. Obviously, concerns change operation ; leads proposeproperty called Priority Recency makes sense one type change.3.3.1 MonotonyInspired done field non-monotonic inference, define propertymonotony expressing arguments accepted change remain acceptedchange. Since aim define general properties, make assumptionnumber extensions, consider different cases acceptance argument(credulously skeptically accepted).monotony definition straightforward semantics providing one extension(such grounded semantics, instance). Following Definition 6, argumentaccepted (credulously skeptically) hA, Ri iff belongs (unique) extensionG. So, particular case, monotony means extension G includedextension G . several extensions, monotony take different forms.credulous form corresponds case argument credulously accepted G60fiChange Argumentation Systemsalso credulously accepted G . skeptical form corresponds caseargument skeptically accepted G also skeptically accepted G . ideaslead following definition:Definition 15 (Monotony)change G G satisfies Monotony iff extension G includedleast one extension G .change G G satisfies Credulous Monotony6 iff union extensionsG included union extensions G .change G G satisfies Skeptical Monotony iff intersection extensions G included intersection extensions G .change operation , Examples 2.1, 2.2, 4.3, 6, 7 illustrate caseproperty Monotony holds; and, change operation , Examples 2.3, 2.4,3.1, 3.2, 4.1, 4.2, 5, 8.1, 8.2 illustrate case property Monotonyhold7 .Obviously, Monotony implies Credulous Monotony. However, Monotony implySkeptical Monotony (see Example 4. 3) Skeptical Monotony imply Monotony(see Examples 2.3, 2.4, 3.1, 3.2). semantics providing one extension, threenotions Monotony coincide.Monotony property defined level extensions. similar notiondefined level arguments:Definition 16 (Partial Monotony argument) Let X argument.change G G satisfies Partial Monotony X iff X belongs extensionG, also belongs least one extension G .easy prove Monotony (resp. Credulous Monotony) implies Partial Monotonyargument G. case property Skeptical Monotony (seeargument Example 2.4).3.3.2 Priority Recencynext property concerns status argument added change. Inspired done field belief revision (see Alchourron, Gardenfors, &Makinson, 1985), postulate concerning priority new piece information,define property expressing new argument accepted change.property called Priority Recency8 makes sense change operation .6. Credulous Monotony related well-known decision problem credulous acceptance argumentation (see Definition 6).7. Appendix B, reader find examples illustrating property Monotonychange operations.8. property characteristic postulate AGMs sense; inspired Successpostulate proposed Alchourron et al. (1985).61fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexDefinition 17 (Priority Recency) change G G satisfies PriorityRecency iff G least one extension added argument Z belongs extensionG .Examples 2.1 2.3, 3.1, 4.1, 4.2, 6, 8.1 examples change satisfying PriorityRecency. Examples 2.4, 3.2, 4.3, 5, 7, 8.2 examples change satisfy PriorityRecency.3.4 Connections Propertieslinks structural properties status-based properties established.following propositions enumerate results hold type change.Proposition 3conservative change always satisfies Monotony Skeptical Monotony.expansive change always satisfies Monotony Skeptical Monotony.decisive change satisfies Monotony also satisfies Skeptical Monotony.particular case semantics providing one extension, change satisfiesMonotony (and Skeptical Monotony) iff either decisive, expansive, conservative.Proposition 4destructive change never satisfies Monotony.altering change never satisfies Monotony.restrictive change never satisfies Monotony.Moreover, particular case change , connections structuralproperties Priority Recency established.Proposition 5conservative changedestructive changeaiainever satisfies Priority Recency.never satisfies Priority Recency.particular case grounded, stable preferred semantics, have:Proposition 6 grounded, stable preferred semantics, expansive changeai always satisfies Priority Recency.results examples given Sections 3.2 3.3, inclusion linksdifferent changes type synthesized Figure 19 . Table 3 givesreferences examples propositions used identifying links.9. inclusion Expansive changes operations satisfy Priority Recencyshown Figure 1, checked stable, grounded preferred semantics see Proposition 6(hence, may hold semantics).62fiChange Argumentation SystemsMonotonyDestructiveConservativeQuestioningExpansiveDecisivePriority recencyRestrictiveAlteringFigure 1: Inclusion links changes typeconservativedecisivedestructiveexpansivealteringquestioningrestrictivePriority RecencyNever satisfied (Conseq. 5)May hold (Ex. 2.1 2.3)(Ex. 2.4)Never satisfied (Conseq. 5)Hold stable, grounded, preferred sem. (Prop. 6)May hold (Ex. 8.1)(Ex. 8.2)May hold (Ex. 4.1)(Ex. 4.3)May hold (Ex. 3.1)(Ex. 3.2)aiMonotonyAlways satisfied(Conseq. 3)May hold (Ex. 2.1)(Ex. 2.3)Never satisfied (Conseq. 4)Always (Conseq. 3)Never (Conseq. 4)May hold (Ex. 4.3)(Ex. 4.1)Never (Conseq. 4)Table 3: Synthesis connections structural status-based properties63fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiex4. Characterizing Argument Addition Grounded PreferredSemanticssection, focus change , i.e., addition exactly one argument Zinteracts least one argument belonging A. Indeed, adding argumentmay interact existing ones frequently encountered type changereal-life situations. Besides, type change sufficiently complex provide richanalysis properties results.Moreover, consider change grounded preferred semantics.chosen two semantics well-known traditionalsemantics existence extensions guaranteed.purpose identify conditions given property satisfiedchange operation . conditions concern added argument associatedinteractions, may depend semantics.Arguably, properties seem desirable others according context.instance, decisive change operation reduce ignorance, since change oneone extension remains, enabling determine status argument (whichalways case change). expansive change raise numberaccepted arguments, interesting achieving goal persuasion instance.conservative change keeps extensions unchanged, interesting want addargument without changing state knowledge. properties MonotonyPriority Recency desirable focus particular arguments,want get resulting extensions.constrast, questioning destructive operation increase ignorance, seemsless interesting.altering operation enforces new look problem, since nothingkept state change (the number extension remainsdifferent previous ones). According discussion, provide:sufficient conditions (CS) interesting properties hold (e.g., decisive,expansive, conservative, monotonic, satisfying Priority Recency);necessary conditions (CN) undesirable properties (e.g., questioning, destructive, altering), order avoid properties.following subsections, consider changement Z interactions Iz , that:ai addition argu-hA, Rii (Z, Iz ) = hA {Z}, R Iz4.1 Argument Addition Grounded Semanticsgrounded semantics, E = {E} E = {E }.following result gives condition given accepted argument X remainsaccepted change (hence Partial Monotony holds X).Proposition 7 grounded semantics, X belongs E, Z indirectlyattack X, satisfies Partial Monotony X (i.e. X belongs E ).64fiChange Argumentation SystemsExample 9 grounded semantics:CBZE = {{A, B}}, E = {{Z, B}}Z indirectly attack B B E, B Eaifollowing result gives condition changeRecency.satisfies PriorityProposition 8 grounded semantics, Z attacked G,Priority Recency (i.e. Z belongs E ).ai satisfiesExample 10 grounded semantics:BZCE = {{A, C}}, E = {{Z}}Let us first study particular case E = {}.Proposition 9 grounded semantics,E = {} following equivalence holds: E = {} iff Z attacked G;moreover, E = {} Z attacked G, E = {Z} i1 F ({Z}).So, case E = {}, have:ai conservative).Either Z attacked G E = {} (and changeZ attacked G E contains Z argumentsindirectly defended Z (and change decisive).consequence Proposition 9, have:Corollary 1 grounded semantics,E = {} Z attacked G, changechangeaiaidecisive;decisive, Z attacked G hence Z attacks G.Example 11 grounded semantics, following changeBCZaidecisive:E = {{}}, E = {{Z, A, D}}Now, study particular case E =6 {}.following result gives condition changeai satisfies Monotony.Proposition 10 grounded semantics, E =6 {} Z attack E,ai satisfies Monotony (i.e. E E ).precisely, two conditions (one conservative changeanother one expansive change ):65aifiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexProposition 11 grounded semantics, E =6 {} Z attack E,have:E defend Z, E = E. (The changeaiconservative).E defends Z, E = E {Z} i1 F ({Z}). Moreover, case, Zattack G, E reduces E {Z}. (The change expansive).Example 12 grounded semantics, following changeBaiexpansive:CE = {{A}}, E = {{Z, A, D}}ZFconsequence Proposition 11, another condition changeai satisfies Priority Recency:Corollary 2 grounded semantics, E =6 {}, Z attack E, E defendsZ, satisfies Priority Recency (i.e. Z belongs E ).Example 13 grounded semantics:BCE = {{A}}, E = {{Z, A}}ZFNote Corollary 2 hold E defend Z.Example 14 grounded semantics:BCZFE = E = {A}.So, E = E = {{A}}.Another interesting point fact properties changesatisfied grounded semantics:Proposition 12 grounded semantics, changerestrictive.aiai cannotnever questioning,case destructive change also interesting sufficient addattack unattacked argument obtaining change:Proposition 13 grounded semantics, E =6 {}, Z attacks unattackedargument Ai G Z attacked G change destructive; conversealso holds.66fiChange Argumentation Systems4.2 Argument Addition Preferred Semanticspreferred semantics, always least one extension. E may reducedsingleton {E1 } (where E1 may empty), may contain one extension{E1 , . . . , En }. Similarly, E may reduced singleton {E1 } (where E1 may empty),may contain one extension {E1 , . . . , En }.following result gives condition change satisfies PriorityRecency.Proposition 14 preferred semantics, Z attacked G, satisfiesPriority Recency (i.e. Z belongs Ei ).Example 15BZCBpreferred semantics:E = {{A, C}, {B}},E = {{Z, B}, {Z, C}}CZE = {{A, C}, {B}},E = {{Z, A, C}}following proposition establishes admissible sets G kept cases(so, cases change neither altering, restrictive):Proposition 15 preferred semantics,Z attack Ei , Ei remains admissible G ;Z attack Ei Ei defends Z, Ei {Z} admissible G .Example 16 preferred semantics:ZBCE = {{}},{}{Z} admissible G E = {{Z, B}}.Example 12 (continued) preferred semantics, E = {{A}}, {A} {Z}admissible G , nevertheless, E = {{Z, A, D}}.Note preferred extensions may appear G .Example 17 preferred semantics:BCE = {{A}},E = {{Z, A}, {Z, C}}Zconsequence Proposition 15, another condition changeai satisfies Priority Recency.Corollary 3 preferred semantics, Z attacks extension G, Eidefends Z, satisfies Priority Recency (i.e. Z belongs Ei ).67fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexExample 18 preferred semantics:BCFZE = {{A, C}, {A, D}},E = {{Z, A, C}, {Z, A, D}}following result gives condition changeai decisive.Proposition 16 preferred semantics, E = {{}} Z attacked Geven-length cycle G E = {E } Z belongs E (so,decisive).Example 11 (continued) preferred semantics, E = {{}}, E = {{Z, A, D}}Note that, even-length cycles exist graph, changeextensions; change would questioning one:BZCFaimay induce severalE = {{}},E = {{Z, A, D}, {Z, A, F }}reason, considered graphs without even-length cycle Proposition 16.following result gives necessary condition decisive change (andalso condition conservative change).Proposition 17 preferred semantics, Z attacks argument G E ={{}}, E = {{}}; equivalently, E = {{}} change Z decisiveZ attacks G.following result relates case exists non empty extension Galso gives conditions either conservative change, expansiveone.Proposition 18 preferred semantics, Z attacks argument G, E 6={{}}, i:Ei defends Z, Ei {Z} extension G ;Ei defend Z, Ei extension G ;moreover, G G number extensions.Example 6 (continued) preferred semantics, change= {{A, C}, {A, D}} E = {{Z, A, C}, {Z, A, D}}aiexpansive: Econsequence previous results, condition changeai satisfies Monotony.Proposition 19 preferred semantics, Z attacks extension Gchange satisfies Monotony.68fiChange Argumentation Systemsparticular case non controversial argumentation framework, obtain conadition change satisfies Skeptical Monotony. notion controversialargument introduced Dung, proved argumentation frameworkwithout controversial argument nice properties. Roughly speaking, argument Xcontroversial indirectly attacks indirectly defends argument .Proposition 20 preferred semantics, assume G contains controversialargument. Z attack i1 Ei , change satisfies Skeptical Monotony,i1 Ei i1 Ei .grounded semantics, exists proposition destructive changeai :Proposition 21 preferred semantics, E 6= {{}}, even-lengthcycle G , unattacked argument Ai G attacked G Z attacked Gchange destructive.4.3 Synthesis ResultsTables 4 5, display summary necessary (CN) sufficient (CS) conditionsproperty hold change (in cases, several CS resp. CN may givendenoted CS, CS , . . . resp. CN, CN , . . .).tables, E, E , E, E , Ei , Ej denote respectively set extensions change,change, grounded extension change, change, preferred extensionchange change.Table 4 concerns structural properties change .Table 5 concerns status-based properties change .tables underline fact able identify sufficient conditions(CS) interesting properties hold (e.g., decisive, expansive, conservative,monotonic, satisfying Priority Recency). properties changes lessdesirable questioning, destructive, altering, focused search necessaryconditions (CN), allowing us enunciate sufficient conditions order avoid them.5. Discussion Future Workspaper, study change argumentation. propose properties characterizeimpact change operation outcome argumentation framework. Then,focus particular type change: addition new argument may interactpreviously introduced arguments10 . establish conditions givenproperty satisfied.study change important issue Artificial Intelligence, traditionallyconcerns belief change. agent receives new piece information, mustadapt beliefs; adaptation always easy may imply dropprevious knowledge. seminal work Alchourron, Gardenfors Makinson (AGM)(1985) settled formal framework reasoning belief change introduced10. consider knowledge arguments interactions could built.69fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexProperties changeaiGrounded semanticsPreferred semanticsDecisive(E = E = {{}} |E| > 2)|E | = 1 E 6= {{}}CS CN: E = {} Zattacked. (Prop.9)CS: E = {{}} Z attacked even-length cycle G. (Prop.16)E = {{}} CN: Z attacks G.(Prop.17)Restrictive|E| > |E | > 2Never (Prop.12)CN: even-length cycleG Z attacks least one Ei(Prop.15)Questioning|E| < |E |Never (Prop.12)CN: even-length cycleG Z attacks G (Prop.17,Prop.18)CN CS: E =6 {} Z attacks unattacked argtG Z attacked (Prop.13)CS: E 6= {{}} Z attacked even-length cycle G Z attacksunattacked argt G (Prop.21)CN: E 6= {{}} Z attacked odd-length cycle G Z attacksunattacked argt G (Prop.1.5,Prop.2.2)CS: E =6 {} Zattack E E defends Z(Prop.11)CS: E 6= {{}} Zattack G i, Ei defends Z(Prop.18)CS: E = {} Z attackedG (Prop.9)CS : E =6 {} Zattack E E defendZ (Prop.11)CS: E = {{}} Zattack G (Prop.17)CS : E 6= {{}} Zattack G i, Ei defend Z (Prop.18)CN: E =6 {} Z attacks E(Prop.10)CN: E 6= {{}} Ei s.t. Zattacks Ei (Prop.15)DestructiveE 6= E 6= {{}} (E =E = {{}})Expansive|E| = |E | Ej E , EiE, s.t. Ei EjConservativeE = EAltering|E| = |E | Ei E s.t. EjE , Ei 6 EjTable 4: Synthesis necessary sufficient conditions (CN CS) structuralproperties Case70fiChange Argumentation SystemsProperties changeMonotonyEi E, Ej E , s.t. Ei EjGrounded SemanticsPreferred SemanticsCS: E = {}CS: Z attack Ei(Prop.19)CS : E =6 {} Zattack E (Prop.10)Priority Recency|E | 1 Ej E , Z EjPartial Monotony XEi E s.t. X Ei ,Ej E s.t. X EjSkeptical Monotonyi1 Ei j1 EjCS: Z attacked (Prop.8)CS : E =6 {}, Z attackE E defends Z (Prop.11)CS: Z attacked (Prop.14),CS : Ei E, Zattack Ei Ei defends Z(Corol.3)CS: X E Z indirectly attack X (Prop.7)cf. Monotony (because, X,Partial Monotony X implied Monotony)cf. Monotony (because,grounded semantics, SkepticalMonotony Monotony)CS: controversial argt GZ attack i1 Ei(Prop.20)Table 5: Synthesis necessary sufficient conditions (CN CS) status-basedproperties Caseconcept belief revision together two types belief change, namelycontraction expansion. Expansion consists adding information withoutchecking consistency previous beliefs. Contraction operation designedremoving information. Revision consists adding information preserving consistency.last operation interesting one since, belief theory, inconsistency leadsunexploitable information.Although change operations defined Section 3 could thought relatedAGM theory11 , comparison appropriate two main reasons:basic underlying formalism different: standard belief revision, logical formulae used knowledge representation whereas, paper, argumentationframework represents current knowledge. first case, outcome newset logical formulae, whereas, second case, outcome new argumentation framework induces new set extensions, extension setarguments.Revision task knowledge representation strongly related conceptsinference consistency. postulates standard belief revision (AGM)built consistency notion, since revision aims incorporating new piece11. Note important cognitive tasks linked belief change theory already studiedfield argumentation, see instance work merging Coste-Marquis, Devred, Konieczny,Lagasquie-Schiex, Marquis (2007).71fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiexinformation preserving consistency. However, framework argumentation, notion consistency clear standard accepted meaning (evenauthors propose take account kind degree inconsistencyargumentation context works Matt & Toni, 2008; Besnard & Hunter,2008).Moreover, revision also studied framework non-monotonic theories (Witteveen & van der Hoek, 1997) argumentation theory linked nonmonotony, postulates non-monotonic theories also based consistencyinference notions explicitly present abstract argumentationsystem. So, postulates suited problem. belief revision postulates restated (this case property called PriorityRecency inspired AGM Success postulate ), principles must proposed (for instance, identified property called Monotonychecks kind preservation existing extensions change process).work extension previous work (Cayrol et al., 2008) presentedpreliminary step towards formal characterization notion change argumentationframeworks. work Cayrol et al. (2008), change defined additionone argument one interaction studied structural propertiesPriority Recency (called classicity Cayrol et al., 2008). new versionwork, proposed current paper, taking account additionseveral interactions (so properties given Cayrol et al., 2008 hold here)defining new properties around notion Monotony. also lookconnections proposed properties conditions (necessarysufficient) obtaining avoiding properties.many approaches deal adding new pieces informationwithin argumentation system. point view adopted family worksdifferent status new piece information added.instance, Wassermann (1999), well Falappa, Garca, Simari (2004) PaglieriCastelfranchi (2005), define conditions, expressed terms arguments,unjustified beliefs become accepted. Pollock Gilliess (2000) approach studiesproperties knowledge revision argumentation point view, i.e., problemgenerate knowledge base piece information justified goodarguments. kind problem studied Amgoud Vesic (2009) contextargument-based decision. Argument-based decision takes input set options, setarguments defeat relation among them, returns status option togethertotal preorder set options. authors study conditionsoption may change status new argument received conditionsnew argument useless.Recently, Rotstein, Moguillansky, Falappa, Garca, Simari (2008a) proposedwarrant-prioritized revision operation, consists adding argument theoryway argument warranted afterwards. Even underlying ideassimilar, work differs approach least two points:First, work Rotstein et al. (2008a), arguments given structuresub-argument relation, properties minimality, consistency atom72fiChange Argumentation Systemsicity. definition warranted arguments relies upon evaluation argumentation lines. contrast, approach remains abstract level,sets accepted arguments computed well-known extension-basedsemantics.Secondly, warrant-prioritized argument revision designed order satisfyAGM Postulate, corresponding property Priority recency, sinceadded argument must warranted revised theory. work follows anotherdirection. propose extensive theoretical study impact additionoutcome abstract argumentation framework, enables us defineseveral properties change operation.Concerning general question handling dynamics argumentation, proposal related recent works Boella et al. (2009a, 2009b), Rotstein et al.(2008b):work Boella et al. (2009a, 2009b) studies extensions argumentation system remain unchanged set arguments attackschanged.four types change proposed Definition 7 introduceddifferent names, respectively attack refinement, attack abstraction, argument refinement argument abstraction. However, operations attack refinement,attack abstraction argument abstraction studied,restrictive point view:Boella et al. (2009a, 2009b) consider case semantics providesexactly one extension.principles defined correspond conditions changeconservative, terminology. property considered.focus addition argument interactions, work Boellaet al. (2009a, 2009b) viewed complementary work.Rotstein et al. (2008b) introduce notion dynamics considering argumentsbuilt evidence. Evidence used determine whether argument active (i.e.used draw inferences) inactive. question addressed Rotstein et al.(2008b) is: variation set evidence affects nature arguments(active not)?. question cannot handled pure abstract levelconcerns internal dynamics. contrast, remain abstract level:interested impact change abstract framework outcomeframework.promising application work could design dialogue strategies. Indeed,dialogue may defined exchange (called move) arguments two more,human artificial, agents given protocol. protocol program definesset allowed moves step dialogue. agent aim73fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiexmay develop strategy. works dialogue strategies considerstrategy selects exactly one move (the move must done next). instance,Bench-Capon (1998) proposes selection strategy (for agents) leading cooperativedialogues. approaches study strategies context persuasion dialogues,two agents argue order persuade given initial argument true (orfalse according agent opinion). case, strategy helps choose argument must defeated order initial argument accepted (or rejected).Amgoud Maudet (2002) proposed heuristics select less attackable arguments persuasion dialogue. similar way, Riveret, Prakken, Rotolo, Sartor(2008) proposed optimal strategy order win debate based probabilitysuccess argument cost argument agent. Hunter (2004),global approach, defined strategy builds optimal subtreearguments maximizing resonance agent goals minimizing cost.approach takes another point view. define protocolrestrict dialogue type. Given set arguments may interact, interestedoutcome argumentation system, set extensions givensemantics. words, study impact addition argument respecttwo points view: first, structural modification induced set extensions,second, impact acceptability arguments. Although concern acceptabilityevolution looks similar aim existing dialogue approaches presented above,proposal general, since work, interested finding strategiesorder make accepted precise argument rather interested establishinggeneral conditions preservation acceptability. instance, groundedpreferred semantics, provide sufficient condition maintaining argumentaccepted arrival new one (Monotony property) sufficient conditionnew argument accepted (Priority Recency).structural point view analysis completely original respectexisting literature. Indeed, analyze impact new argument set extensionsamounts consider addition argument operation performed ordermodify form change outcome (by expansive change, decisivechange instance). work reported paper enables us choose right waychanging (which argument must affected change, kind interaction)order obtain new outcome. plan focus strategiesdirecting dialogue (i.e., integrated protocol) strategies taking part(i.e., concerning agent). instance, dialogue arbitrator wants debateopen rather force next speaker use arguments appropriateexpansive change. wants debate focused argumentsappropriate restrictive (and even decisive) change accepted.several directions research:1. plan study change operations defined paper, correspondingremoval one argument interactions addition removalinteraction (for instance, exploiting properties symmetrychange operations).74fiChange Argumentation Systems2. would like generalize change operations case additionremoval subgraph arguments (which would kind iterated change).3. think decisive property desirable property change operation.So, intend investigate question make minimal change12given argumentation framework unique non-empty extension?.Acknowledgmentswould like thank reviewers help interesting suggestions.Appendix A. ProofsLemma 1X G s.t. (Z, X) Iz , change operationaiintroduces new cycle G .X G s.t. (X, Z) Iz , change operationaiintroduces new cycle G .words, Z attack argument G, Z attacked G,change operation introduces new cycle G .Proof Lemma 1: follows directly fact one argument added.Proofs Related Section 3.4 (Connections Properties)Proof Proposition 3: follows directly definitions properties (Definitions 8,12, 13, 15).Proof Proposition 4: follows directly definitions properties (Definitions 11,9, 14, 15).Proof Proposition 5: follows directly definitions properties (Definitions 11,13, 17).Proof Proposition 6:Grounded semantics: Let us show E ( E Z E . Assume E ( EZ 6 E . going prove E E (which contradiction assumptionE ( E ), proving F ({}) F ({}), induction 1.Basic case (i = 1): Z 6 E Z attacked G. Thus, X F ({}) XG definition X unattacked G . X also unattacked G. So,F ({}) F({}).Induction hypothesis (for 1 p, F ({}) F ({})):12. terms number edges add remove and/or terms number arguments addremove.75fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexLet us first show subset arguments G F (S) G,F (S) F(S): Let X F (S), means defends X G X G.exists G attacks X G, also attacks X G .defends X G , attacks . also defends X G. F (S) F(S).Let us compute F p+1 ({}) = F (F p ({})). induction hypothesis, F p ({})F p ({}). F monotonic, F p+1 ({}) F (F p ({})). let denoteset F p ({}), E G. assumed E ( E Z 6 EE G. Then, F monotonic, F (S) F (E ) = E GDue previous point, conclude F (S) F(S). Then, obtainF p+1 ({}) F(F p ({})) = F p+1 ({}).Preferred semantics: Given expansive change G Z Iz , let us supposeexists extension Ej G contain Z. extension included G.change expansive, exists extension Ei G strictly included Ej . Eimaximal admissible set inclusion. Since inclusion Ei inside Ej strict, thereforeEj admissible G. Ej extension G , conflict, hence Ejdefend elements G. exists X Ej attacked G (and thus G )defended Ej G. means Ej attack . But, since Ejincluded G attack G . edge element EjG, neither edge G . (Note attacked Z Z Ej )Stable semantics: Assume exists extension Ej G contain Z.change expansive, exists extension Ei G strictly included Ej . Sinceinclusion strict, exists Ej , belong Ei . assumedEj contain Z, G. Ei stable extension G, Ei attacks . Then,Ei included Ej conflict Ej , contradicts fact Ej stableextension.Proofs Related Section 4.1 (Under Grounded Semantics)Proof Proposition 7: E grounded extension G. Due fact R finite,E = i1 F ({}). prove induction 1 X belongs F ({}) Zindirectly attack X, X belongs F ({}).Basic case (i = 1): X F({}) X attacked G. Since Z attack X,X remains unattacked G belongs F ({}).Induction hypothesis (for 1 p, proposition holds): Let X F p+1 ({}).prove X F p+1 ({})(= F (F p ({}))). Assume X attacked G . Zattack X, G. X F p+1 ({}) = F(F p ({})), F p ({}) defends X attacking. exists W F p ({}) attacks , turn attacks X. Zindirectly attack X, sure Z indirectly attack W . Using inductionhypothesis W , W F p ({}). So, proved F p ({}) defends X GX F p+1 ({}).Proof Proposition 8: Z attacked G, Z attacked G . So, dueProposition 1.5, grounded extension G contains Z.Proof Proposition 9:76fiChange Argumentation SystemsE = {} argument G attacked. Z attacked G, argumentG attacked due Proposition 1.5 Proposition 1.6, E = {}. Z attackedG, Z attacked G , Z belongs E , empty.E = {} Z attacked G, Z E . F monotonic,E fixed pointF , F ({Z}) E 1, {Z} i1 F ({Z}) E . Letdenote {Z} i1 F ({Z}). Now, prove E S. E least fixedpoint F , sufficientproveithat fixed point F . Obviously, F (S) = {XG s.t. X attacked} i1 F ({Z}). Since E = {}, {X G s.t. X attacked } ={Z}, F (S) = fixed point F . proved E = {Z} i1 F ({Z}).Proof Corollary 1:follows directly Proposition 9. Due Definition 8, grounded semantics,change decisive E = {} E 6= {}.Z interacts G, Z attacked G, Z must attack G.Proof Proposition 10: Due fact R finite, E = i1 F ({}) E =i1 F ({}). prove induction 1 F ({}) F ({}).Basic case (i = 1): F({}) attacked G due fact Zattack E, attacked G F ({}).Induction hypothesis (for 1 p, F ({}) F ({})): let = F p ({}) = F p ({}).First, prove F(S) F (S). Let F(S). Obviously, F(S) E. EZ attack since Z attack E. So, attacked Gattacked G. F(S), defends attacking A. defends G ,F (S).Using induction hypothesis, . Moreover, definition F monotonic.F(S) = F p+1 ({}) F (S) F (S ) = F p+1 ({}). So, E E .Proof Proposition 11: E =6 {} Z attack E. Let us first notice (1)F (E) G, F(E) = E. Indeed, F (E) means E defends G . So,G, E also defends G, i.e., F(E) = E.Due Proposition 10, E E . So, prove E defendZ, E E. Indeed, prove F (E) = E. Then, definition E (least fixedpoint), follow E E. Let F (E), E defend Z, hence G,according (1), F(E) = E. Conversely, let E = F(E), let argumentattacks G . Z attack E, 6= Z, G, E defends attackingA. So, E defends G F (E).First, prove E defends Z F (E) = E {Z}. Due (1), F (E) G,F(E) = E. Now, E defends Z, also Z F (E). So, F (E) E {Z}.Conversely, let F(E) = E. E defends G. Z attack E, Z attack, E also defends G , F (E). Z F (E), E {Z} F (E).particular case Z attack G, Z cannot defend argument. So, F (E{Z}) = F (E) F (E {Z}) = E {Z}. means E {Z} fixed point77fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexF , definition E , E E {Z}. Due Proposition 10, E E .So, also E {Z} E . Finally, E reduces E {Z}.general case, Z attacks G. Let denote E {Z} i1 F ({Z}). proveE = S. Obviously, E since E {Z} = F (E) E , E contains i1 F (E ),hence contains i1 F ({Z}), since F monotonic. Conversely, provefixed point F definition E (least fixed point), follow E S.Since F monotonic, F (E) F (S), F ({Z}) F (S) 2F ({Z}) F (S). So, F (E) = E {Z}, F (S). Conversely, let F (S)assume/ E {Z} = F (E). Then, existsattackerattacked E. F (S), must attack A. {Z} i1 F ({Z}) attacks A,means i1 F ({Z}). So, proved F (S), either E {Z}i1 F ({Z}), S.Proof Corollary 2: direct consequence Proposition 11.Proof Proposition 12: direct consequence definitions: restrictive questioning changes need number extensions strictly greater one, exists onegrounded extension.Proof Proposition 13: E =6 {}, unattacked arguments denoted Ai G. Ai ,Ai attacked G Z attacked G . unattacked argument G , 1F ({}) = {} E = {}. change destructive.Conversely, change destructive, definition E =6 {} E = {}. Then, dueProposition 1.5, unattacked argument G . So, Z attacked Ai (unattackedargument G) also attacked G .Proofs Related Section 4.2 (Under Preferred Semantics)Proof Proposition 14: Z attacked G, Z attacked G . So, dueProposition 1, preferred extension G contains Z.Proof Proposition 15:Ei conflict-free G, also G . Let Ei attacked G . Z attackEi , attacked G Ei admissible G, Ei defends A. So, Ei remains admissibleG.Z attack Ei , Ei defends Z, Ei attack Z Ei {Z} conflictfree G . Let Ei {Z} attacked G . Either Ei provedfirst item Ei admissible G , Ei defends A. = Z, assumedEi defends Z. case, Ei {Z} admissible G .Lemma 2 Ei extension G containing Z, Ei admissible G.Proof Lemma 2:78fiChange Argumentation SystemsEi contain Z, Ei G. Ei conflict-free G Ei also conflict-free G. LetEi attacked argument A, G. Ei admissible, defends . So,argument B Ei attacking A. Ei G, B G. So, proved Ei admissible G.Proof Corollary 3: Proposition 15, Ei E, Ei {Z} admissible G . So, existsj 1 Ei {Z} Ej . Lemma 2, Ek extension G containing Z, Ekadmissible G. So, exists 1 Ek Ei . So, Ek Ei Ei {Z} Ej .consequence, would strict inclusion two extensions G , impossible.So, cannot exist Ek extension G containing Z, extension G contains Z.Proof Proposition 16: Z attacked G, Z attacked G Z belongspreferred extension. Moreover, even-length cycle G, due Lemma 1,even-length cycle G . So, due Proposition 2.5, G one preferred extensionempty (it contains least Z).Lemma 3 Z attacks argument G Ei non empty extension G ,Ei \ {Z} admissible G.Proof Lemma 3:Ei conflict-free G Ei \ {Z} also conflict-free G G.Let Ei \ {Z}. Assume argument attacking . 6= Z since Zattacks argument G. Ei non-empty preferred extension G , argumentB Ei attacking A, B 6= Z (always Z attacks argument G). So,B Ei \ {Z}, Ei \ {Z} defends . So, Ei \ {Z} admissible G.Proof Proposition 17: Suppose Z attacks argument G E = {{}}.(reductio ad absurdum): Assume exists non-empty extension G denoted E .exists E . Either = Z, G. cases, attacked,arguments G attacked (since E = {{}}) Z attacks argument G. E mustdefend . = Z, E cannot reduced (because Z attacks argument cannot defenditself). E \ {Z} 6= {}. 6= Z, E \ {Z}, E \ {Z} =6 {}. Due Lemma 3, E \ {Z}admissible G E \ {Z} E E preferred extension G. G non-emptyextension, contradiction assumption.Proof Proposition 18:Z attacks argument G, due Proposition 15, i, Ei admissible G .exists preferred extension Ej G including Ei . E 6= {{}}, i, Ei 6= {} Ej 6= {}.Z 6 Ei , Ei Ej \ {Z}. Due Lemma 3, Ej \ {Z} admissible G, existsk 1 Ei Ej \ {Z} Ek . Using definition preferred extension (-maximalamong admissible sets), conclude Ei = Ej \ {Z} = Ek . So, either Ej = Ei (ifZ 6 Ej ), Ej = Ei {Z} (if Z Ej ). first case, Ei extension G . secondcase, Ei {Z} extension G . Moreover, Z Ej , Ej defends Z (which attackedG, since attack G) Z attacks argument, Ei = Ej \ {Z} defends Z. So,79fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexEi defend Z, Ei extension G . hand, Ei defends Z, Ei {Z}conflict-free G . So, Ei {Z} admissible G case Z Ej Ei {Z}extension G .Now, prove G G number extensions. first partproof, know extension G included extension G . Moreover, twodistinct extensions G cannot included extension G . Indeed, uniontwo non-empty preferred extensions defends elements strictly containsextensions. union two extensions cannot conflict-free.So,we know G least many extensions G G least one nonempty extension. So, Ej E , Ej 6= {}. Due Lemma 3, Ej \ {Z} admissible G. So,Ej , exists Ei , extension G Ej \ {Z} Ei . first partproof, have:Either Ei defends Z, Ei {Z} extension G . Ej \ {Z} Ei ,Ej Ei {Z}, Ej maximal admissible G , Ej = Ei {Z}.Ei defend Z, Ei extension G . Ej maximal admissible G ,Z 6 Ej Ej = Ej \ {Z} = Ei .So, G G number extensions.Proof Proposition 19:E = {{}}, obviously change satisfies Monotony.G non-empty extension, Proposition 15 applied. extension Gremains admissible G included preferred extension G . So, change satisfiesMonotony.Proof Proposition 20: Let E = i1 Ei E = i1 Ei .Let Eg (resp. Eg ) denote grounded extension G (resp G ). Due Proposition 1.4, knowEg E Eg E . Dung (1995) proved controversial argument,grounded extension exactly intersection preferred extensions. So, G containscontroversial argument, Eg = E.Now, Z attack i1 Ei , Z attack Eg , due Proposition 10, E =6 {}Eg Eg E = {} i1 Ei = {} inclusion trivially holds. So,E = Eg Eg E , i1 Ei i1 Ei .Proof Proposition 21: E 6= {{}} even-length cycle G evenlength cycle G; consequence, according Proposition 2.5 one extension E G;moreover, E =6 {}. Since even-length cycle G , know one extensionE G . Assume Z unattacked argument Ai G attacked G ;unattacked argument G .Assume E 6= {}. Let X E . X attacked G . Let Y1 denote attacker X. Eadmissible, E defends X. E contains X2 attacks Y1 . even-length cycleG , know X2 6= X. X2 unattacked.able built infinite sequence distinct arguments:X attacked Y1 attacked X2 . . . Yp attacked Xp+1 attacked Yp+1 . . .Xi (resp. Yi s) distinct due absence even-length cycles G .contradicts assumption finite. E = {} change destructive.80fiChange Argumentation SystemsAppendix B. Illustration Properties Change Operationsfollowing examples illustrate structural properties property Monotonychange operations distinct (let us recall property Priority Recencymake sense change operations).aiFirst, notice hA, Rii (Z, Iz ) = hA , R hA , R ii Z = hA, Ri.example Section 3.2, change also illustrated.Example 4.1 show decisive changeproperty Monotony.ai change ai satisfyExample 5.2 shows decisive change change satisfies propertyMonotony .Example 4.3 shows restrictive changeproperty Monotonyai change ai satisfyExamples 2.3, 3.1, 5.1 show questioning changesatisfy property MonotonyaichangeaiExamples 2.1, 2.2, 4.2 show destructive changesatisfy property MonotonyaichangeaiExample 8.2 shows expansive changeproperty MonotonyaichangeaisatisfiesExamples 7.1, 7.2, 7.3 show conservative change change satisfiesproperty MonotonyExamples 6, 8.1 show altering change change satisfyproperty MonotonyhA = {A, B, C}, R = {(A, B), (B, C), (C, A)}i, hA, Rii (A, C) decisivechange (before change E = {{}}, change E = {{A}}); inverseoperation hA, R {(A, C)}ii (A, C) destructive.example,satisfies property Monotony not.hA = {A, B, C}, R = {(A, B), (B, C)}i, hA, Rii (C, A) destructive change(before change E = {{A, C}}, change E = {{}}); inverseoperation hA, R {(C, A)}ii (C, A) decisive.example,satisfy property Monotony satisfies it.hA = {A, B, C}, R = {(A, B), (B, C)}i, hA, Rii (A, C) altering change(before change E = {{A, C}}, change E = {{A}}); inverseoperation hA, R {(A, C)}ii (A, C) expansive.81fiCayrol, Dupin de Saint-Cyr & Lagasquie-Schiexexample,satisfy property Monotony satisfies it.hA = {A, B, C}, R = {(A, B)}i, hA, Rii (C, B) conservative change (before change E = {{A, C}}, change E = {{A, C}}); inverseoperation hA, R {(A, C)}ii (A, C) conservative.example,satisfy property Monotony.hA = {A, B, C, D}, R = {(A, B), (B, A), (B, C), (D, C)}i, hA, Rii (C, D)questioning change (before change E = {{A, D}, {B, D}}, changeE = {{A, D}, {B, D}, {A, C}}); inverse operation hA, R{(C, D)}ii (C, D)restrictive.example,satisfies property Monotony not.hA = {A, B, C, D}, R = {(A, B), (B, A), (B, C), (D, C), (C, D)}i, changehA, Rii (A, D) restrictive one (before change E = {{A, D}, {B, D}, {A, C}},change E = {{B, D}, {A, C}}).inverse operation hA, R {(A, D)}ii (A, D) questioning.example,satisfy property Monotony satisfies it.hA = {A, B, C}, R = {(A, B), (B, C)}i, hA, Rii (A, B) altering change(before change E = {{A, C}}, change E = {{A, B}}).example,satisfy property Monotony.hA = {A, B, C, D}, R = {(A, B), (B, C), (C, A)}i, hA, Rii (D, A) expansive change (before change E = {{D}}, change E = {{D, B}}).example,satisfies property Monotony.ReferencesAlchourron, C. E., Gardenfors, P., & Makinson, D. (1985). logic theory change:partial meet contraction revision functions. Journal Symbolic Logic, 50, 510530.Amgoud, L., & Cayrol, C. (2002). Inferring inconsistency preference-based argumentation frameworks. Journal Automated Reasoning, 29, 125169.Amgoud, L., & Maudet, N. (2002). Strategical considerations argumentative agents(preliminary report). Proc. NMR, pp. 409417.Amgoud, L., Maudet, N., & Parsons, S. (2000). Modelling dialogues using argumentation.Proc. ICMAS, pp. 3138.Amgoud, L., & Vesic, S. (2009). Revising Argumentation-Based Decision Systems.Proc. ECSQARU, Vol. LNAI 5590, pp. 7182. Springer-Verlag.Baroni, P., Giacomin, M., & Guida, G. (2005). Scc-recursiveness: general schemaargumentation semantics. Artifical Intelligence, 168, 162210.Bench-Capon, T. (1998). Specification implementation Toulmin dialogue game.Proc. JURIX, pp. 520.82fiChange Argumentation SystemsBesnard, P., & Hunter, A. (2008). Elements argumentation. MIT Press.Boella, G., Kaci, S., & van der Torre, L. (2009a). Dynamics argumentation singleextensions: Abstraction principles grounded extension. Proc. ECSQARU(LNAI 5590), pp. 107118.Boella, G., Kaci, S., & van der Torre, L. (2009b). Dynamics argumentation singleextensions: Attack refinement grounded extension. Proc. AAMAS, pp.12131214.Bondarenko, A., Dung, P., Kowalski, R., & Toni, F. (1997). abstract, argumentationtheoretic approach default reasoning. Artificial Intelligence, 93, 63101.Caminada, M. (2006). Semi-stable semantics. Proc. COMMA, pp. 121128.Cayrol, C., Dupin de Saint-Cyr, F., & Lagasquie-Schiex, M. (2008). Revision argumentation system. Proc. KR 2008, pp. 124134. AAAI Press.Chesnevar, C., Maguitman, A., & Loui, R. (2000). Logical models argument. ACMComputing surveys, 32 (4), 337383.Coste-Marquis, S., Devred, C., Konieczny, S., Lagasquie-Schiex, M., & Marquis, P. (2007).merging Dungs argumentation systems. Artificial Intelligence, Argumentation Artificial Intelligence, 171 (10-15), 730753.Coste-Marquis, S., Devred, C., & Marquis, P. (2005). Prudent semantics argumentationframeworks. Proc. ICTAI, pp. 568572.Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person games. Artificial Intelligence,77, 321357.Dung, P. M., Mancarella, P., & Toni, F. (2006). dialectic procedure scepticalassumption-based argumentation. Proc. COMMA, pp. 145156.Dunne, P., & Bench-Capon, T. (2001). Complexity combinatorial properties argument systems. Tech. report, U.L.C.S.Dunne, P., & Bench-Capon, T. (2002). Coherence finite argument system. ArtificialIntelligence, 141 (1-2), 187203.Falappa, M., Garca, A., & Simari, G. (2004). Belief dynamics defeasible argumentationrational agents. Proc. NMR, pp. 164170.Hunter, A. (2004). Making argumentation believable. Proc. AAAI, pp. 269274.Kakas, A. C., & Moratis, P. (2003). Argumentation based decision making autonomousagents. Proc. AAMAS, pp. 883890.Matt, P., & Toni, F. (2008). game-theoretic measure argument strength abstractargumentation. Proc. JELIA (LNAI 5293), pp. 285297.Nute, D. (2003). Defeasible logic. Proc. INAP 2001, LNAI 2543, pp. 151169.Paglieri, F., & Castelfranchi, C. (2005). Revising beliefs arguments: Bridginggap argumentation belief revision MAS. Argumentation MultiAgent Systems, pp. 7894. Springer.83fiCayrol, Dupin de Saint-Cyr & Lagasquie-SchiexPollock, J., & Gillies, A. (2000). Belief revision epistemology. Synthese, 122 (1-2),6992.Pollock, J. L. (1992). reason defeasibly. Artificial Intelligence, 57, 142.Prakken, H., & Vreeswijk, G. (2002). Logics defeasible argumentation. HandbookPhilosophical Logic, Vol. 4, pp. 218319. Kluwer Academic.Riveret, R., Prakken, H., Rotolo, A., & Sartor, G. (2008). Heuristics argumentation:game-theoretical investigation. Proc. COMMA, pp. 324335.Rotstein, N. D., Moguillansky, M. O., Falappa, M. A., Garca, A. J., & Simari, G. R. (2008a).Argument theory change: revision upon warrant. Proc. COMMA, pp. 336347.IOS Press.Rotstein, N. D., Moguillansky, M. O., Garca, A. J., & Simari, G. R. (2008b). abstractargumentation framework handling dynamics. Proc. NMR, pp. 131139.Wassermann, R. (1999). Full acceptance argumentation - preliminary report.Proc. IJCAI Workshop Practical Reasoning Rationality.Witteveen, C., & van der Hoek, W. (1997). general framework revising nonmonotonictheories. Proc. LPNMR (LNAI 1265), pp. 258272. Springer.84fi