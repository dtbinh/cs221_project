Journal Artificial Intelligence Research 47 (2013) 521-573

Submitted 01/13; published 07/13

Topic Segmentation Labeling
Asynchronous Conversations
Shafiq Joty

sjoty@qf.org.qa

Qatar Computing Research Institute
Qatar Foundation
Doha, Qatar

Giuseppe Carenini
Raymond T. Ng

carenini@cs.ubc.ca
rng@cs.ubc.ca

University British Columbia
Vancouver, BC, Canada, V6T 1Z4

Abstract
Topic segmentation labeling often considered prerequisite higher-level conversation analysis shown useful many Natural Language Processing
(NLP) applications. present two new corpora email blog conversations annotated
topics, evaluate annotator reliability segmentation labeling tasks
asynchronous conversations. propose complete computational framework
topic segmentation labeling asynchronous conversations. approach extends
state-of-the-art methods considering fine-grained structure asynchronous conversation, along conversational features applying recent graph-based methods
NLP. topic segmentation, propose two novel unsupervised models exploit
fine-grained conversational structure, novel graph-theoretic supervised model
combines lexical, conversational topic features. topic labeling, propose two novel
(unsupervised) random walk models respectively capture conversation specific clues
two different sources: leading sentences fine-grained conversational structure. Empirical evaluation shows segmentation labeling performed
best models beat state-of-the-art, highly correlated human annotations.

1. Introduction
ever increasing popularity Internet technologies, common nowadays
people discuss events, issues, tasks personal experiences social media (e.g.,
Facebook, Twitter, blogs, fora) email (Verna, 2010; Baron, 2008). examples asynchronous conversations participants communicate
different times. huge amount textual data generated everyday conversations calls automated methods conversational text analysis. Effective processing
conversational texts great strategic value organizations individuals (Carenini, Murray, & Ng, 2011). instance, managers find information
exchanged email conversations within company extremely valuable decision
auditing. decision turns ill-advised, mining relevant conversations may
help determining responsibility accountability. Similarly, conversations led
favorable decisions could mined identify effective communication patterns sources
within company. public blogging services (e.g., Twitter, Slashdot), conversations ofc
2013
AI Access Foundation. rights reserved.

fiJoty, Carenini, & Ng

ten get large involving hundreds bloggers making potentially thousands comments.
major event political uprising Egypt, relevant messages posted
thousands millions. simply feasible read messages relevant
event, mining summarization technologies help providing overview
people saying positive negative opinions expressed. Mining
summarizing conversations also aid improved indexing searching.
personal level, informative summary conversation could greatly support new participant get speed join already existing conversation. could also help
someone quickly prepare follow-up discussion conversation already part
of, occurred long ago remember details.
Topic segmentation labeling often considered prerequisite higher-level
conversation analysis (Bangalore, Di Fabbrizio, & Stent, 2006) shown
useful many Natural Language Processing (NLP) applications including automatic summarization (Harabagiu & Lacatusu, 2005; Kleinbauer, Becker, & Becker, 2007; Dias, Alves,
& Lopes, 2007), text generation (Barzilay & Lee, 2004), information extraction (Allan,
2002), conversation visualization (Liu, Zhou, Pan, Song, Qian, Cai, & Lian, 2012).
Adapting standard definition topic (Galley, McKeown, Fosler-Lussier, & Jing,
2003) asynchronous conversations, consider topic something
participants discuss argue express opinions. Multiple topics seem occur
naturally social interactions, whether synchronous (e.g., meetings, chats) asynchronous
(e.g., emails, blogs). naturally occurring ICSI multi-party meetings (Janin et al.
2003), Galley et al. (2003) report average 7.5 topical segments per conversation.
multi-party chat, Elsner Charniak (2010) report average 2.75 discussions active
time. email blog corpora, present article, annotators found
average 2.5 10.77 topics per email blog conversation, respectively.
Topic segmentation refers task grouping sentences asynchronous
conversation set coherent topical clusters (or segments)1 , topic labeling
task assigning short description topical clusters facilitate interpretations topics (Purver, 2011). example, sample truncated email conversation
corpora shown Figure 1, majority three annotators found three different topics (or clusters). Likewise, truncated blog conversation shown Figure 2,
annotators found six different topics. right column figure specifies
particular segmentation assigning topic ID (or cluster ID) sentences belonging topic. topics figure also differentiated using different
colors. topic labels assigned annotators listed conversation (e.g.,
Telecon cancellation, Tag document, Responding I18N Figure 1).
extensive research conducted topic segmentation monolog (e.g.,
news articles) synchronous dialog (e.g., meetings), none studied problem
segmenting labeling asynchronous conversations (e.g., email, blog). Therefore,
reliable annotation scheme, standard corpus, agreed-upon metrics available.
Also, key observation that, asynchronous nature, use
quotation (Crystal, 2001), topics conversations often interleaved
change sequential way. is, look temporal order sentences
1. article, use terms topical cluster topical segment interchangeably.

522

fiTopic Segmentation Labeling Asynchronous Conversations

From: Brian To: rdf core Subject: 20030220 telecon Date: Tue Feb 17 13:52:15
propose cancel weeks telecon schedule another 12 Mar 2004, needed.
would like get moving comments TAG architecture document.
Jan still reviewing?
aim get comments end week agreement email next week?

Topic
[1]
[2]
[2]
[2]

From: Jeremy To: Brian Subject: Re: 20030220 telecon Date: Wed Feb 18 05:18:10
> propose cancel weeks telecon schedule another 12 Mar 2004, needed.
> .. agreement email next week?
think means formally respond I18N charmod comments, shall tell
intend to, e-mail discussion shown disagreement.
e.g. informed RDF Core WG decisions, one indicated unhappiness - however
formally discussed issues; likely to.

[3]
[3]

From: Brian To: Jeremy Subject: Re: 20030220 telecon Date: Wed Feb 18 13:16:21
> think means formally respond I18N charmod comments, shall
> tell intend to, e-mail discussion shown disagreement.
Ah, problem. understood correctly going last call anyway.
> e.g. informed RDF Core WG decisions, one indicated unhappiness
> - however formally discussed issues; likely to.
deadline?
I'm prepared decide email formally respond email.

[3]

[3]
[3]

From: Pat To: Brian Subject: Re: 20030220 telecon Date: Wed Feb 18 16:56:26
> propose cancel weeks telecon schedule another 12 Mar 2004, needed.
Im assuming cancelled unless hear otherwise.
Maybe default?
> would like get moving comments TAG architecture document.
still plan write rather long diatribe find time.
doubt rest WG endorse send along asap, hopefully time next week.

[1]
[1]
[2]
[2]

From: Jeremy To: Brian Subject: Re: 20030220 telecon Date: Thu Feb 19 05:42:21
> Ah. problem. understood correctly going last call anyway.
Yes could change draft informal response indicate formal response
included LC review comments new documents.
> deadline?
> I'm prepared decide email formally respond email.
Two weeks received message ....i.e. Cannes
-I suspect also real deadline, imagine want make final decisions Cannes.
happy draft formal response pretty vacuous, e-mail vote. pretty vacuous, e-mail vote.

[3]

[3]
[3]
[3]

Topic Labels
Topic 1 (green): Telecon cancellation, Topic 2 (magenta): TAG document, Topic 3 (blue): Responding I18N.

Figure 1: Sample truncated email conversation email corpus. color indicates
different topic. right column specifies topic assignments sentences.

523

fiJoty, Carenini, & Ng

Author: Soulskill Title: Bethesda Releases Daggerfall Free Type: Article
Thursday, Bethesda announced 15th anniversary Elder Scrolls series, releasing
Elder Scrolls II: Daggerfall free.
aren't providing support game anymore, posted detailed description get
game running DOSBox.
Fans series easily relive experience getting completely lost enormous dungeons.
Save often.

Fragment
(a)

Topic
[1]
[1]

(b)

[2]
[2]

(c)

[2]
[2]
[2]
[2]

Author: Datamonstar Title: Nice nice nice nice... Comment id: 1 Parent id: None Type: Comment
>Fans series easily relive experience getting completely lost enormous dungeons.
>Save often.
... well really, since game soooo old, still huge HUGE gameworld.
Really, It's big.
Can't wait play it.
makes Oblivion look like Sesame Street.
Author: Freetardo Title: Re: Nice nice nice nice... Comment id: 2 Parent id: 1 Type: Comment
Yes big, thing again.
quite monotonous times, really.

[3]
(d)

[3]

(e)

[4]

Author: gbarules2999 Title: Re: Nice nice nice nice... Comment id: 3 Parent id: 1 Type: Comment
Randomly generated HUGE isn't nearly good designed small.
Back Morrowind, folks.

(f)

[5]

Author: drinkypoo Title: Re: Nice nice nice nice... Comment id: 4 Parent id: 3 Type: Comment
>Randomly generated HUGE isn't nearly good designed small.
solution obviously combine approaches.
way single game satisfy types players.

(g)

[4]
[4]

(h)

[1]

(i)

[1]

(j)

[3]
[3]

Author: ElrondHubbard Title: Rest well night -- Comment id: 5 Parent id: None Type: Comment
-- tomorrow, sail kingdom... Daggerfall.
Many, many enjoyable hours spent playing game could (should) working thesis.
Chief complaint: repetitive dungeons, stitched together seemingly near-randomly prefabbed bits
pieces repeated endlessly.
Still, great game.

[1]

Author: Anonymous Title: Re:Rest well night -- Comment id: 6 Parent id: 5 Type: Comment
>Many, many enjoyable hours spent playing game could (should) working thesis
So, thesis go?
>Chief complaint: repetitive dungeons, stitched together seemingly near-randomly great game
also think great game.

(k)

[0]

(l)

[1]

Topic Labels
Topic 1 (green): Free release Daggerfall reaction, Topic 2 (purple): Game contents size, Topic 3 (orange): Bugs
faults, Topic 4 (magenta): Game design, Topic 5 (blue): gaming options, Topic 0 (red): `OFF-TOPIC'.

Figure 2: Sample truncated blog conversation blog corpus. color indicates different
topic. right column (i.e., Topic) specifies topic assignments sentences.
Fragment column specifies fragments FQG (see Section 3.1.3).

524

fiTopic Segmentation Labeling Asynchronous Conversations

conversation, discussion topic may appear intersect discussion
others. seen Figure 1, discussion topic 3 second third
email, topics 1 2 revisited fourth email, topic 3 brought back
fifth email. Therefore, sequentiality constraint topic segmentation monolog
synchronous dialog hold asynchronous conversation. result,
expect models proved successful monolog synchronous dialog
effective, directly applied asynchronous conversation.
contributions article aim remedy problems. First, present two
new corpora email blog conversations annotated topics, evaluate annotator
reliability topic segmentation labeling tasks using new set metrics,
also used evaluate computational models. knowledge,
first corpora made publicly available. Second, present complete
topic segmentation labeling framework asynchronous conversations. approach
extends state-of-the-art methods (for monologs synchronous dialogs) considering
fine-grained structure asynchronous conversation along conversational
features. so, apply recent graph-based methods NLP (Mihalcea & Radev,
2011) min-cut random walk paragraph, sentence word graphs.
topic segmentation, propose two novel unsupervised models exploit,
principled way, fine-grained conversational structure beyond lexical information.
also propose novel graph-theoretic supervised topic segmentation model combines
lexical, conversational, topic features. topic labeling, propose generate labels
using unsupervised extractive approach identifies representative phrases
text. Specifically, propose two novel random walk models respectively captures
two forms conversation specific information: (i) fact leading sentences
topical cluster often carry informative clues, (ii) fine-grained conversational
structure. best knowledge, also first comprehensive study address
problem topic segmentation labeling asynchronous conversation.
framework tested series experiments. Experimental results topic
segmentation task show unsupervised segmentation models benefit consider finer conversational structure asynchronous conversations. comparison
supervised segmentation model unsupervised models reveals supervised
method, optimizing relative weights features, outperforms unsupervised
ones even using labeled conversations. Remarkably, segmentation decisions
best unsupervised supervised models also highly correlated human
annotations. experiments topic labeling task, show random
walk model performs better exploits conversation specific clues leading
sentences conversational structure. evaluation end-to-end system also
shows promising results corpora, compared human annotations.
rest article, discussing related work Section 2, present
segmentation labeling models Section 3. describe corpora evaluation metrics Section 4. experiments analysis presented Section 5.
summarize contributions consider directions future work Section 6.
525

fiJoty, Carenini, & Ng

2. Related Work
Three research areas directly related study: topic segmentation, topic labeling,
extracting conversation structure asynchronous conversations.
2.1 Topic Segmentation
Topic segmentation extensively studied monologs synchronous dialogs
task divide discourse topically coherent sequential segments (for
detailed overview see Purver, 2011). unsupervised models rely discourse cohesion
phenomenon, intuition sentences segment lexically similar
sentences preceding following segment. approaches
mainly differ measure lexical similarity sentences.
One early approach TextTiling (Hearst, 1997), still forms baseline
many recent advancements. operates three steps: tokenization, lexical score determination, depth score computation. tokenization step, forms fixed
length pseudo-sentences, containing n stemmed words. considers blocks k
pseudo-sentences, gap two consecutive pseudo-sentences measures
cosine-based lexical similarity adjacent blocks representing vectors term frequencies. Finally, measures depth similarity valley gap,
assigns topic boundaries appropriate sentence gaps based threshold.
similarity computed basis raw term frequency (TF) vectors,
cause problems sparseness, treats terms independently. Choi,
Hastings, Moore (2001) use Latent Semantic Analysis (LSA) measure similarity
show LSA-based similarity performs better raw TF-based similarity.
Unlike TextTiling, uses threshold decide topic boundaries, Choi et al. use
divisive clustering find topical segments. use similarity measures based
TF LSA features supervised segmentation model.
Another variation cohesion-based approach LCSeg (Galley et al., 2003),
uses lexical chains (Morris & Hirst, 1991). LCSeg first finds chains based term
repetitions, weights based term frequency chain length. cosine similarity two adjacent blocks lexical chain vectors used measure lexical
cohesion TextTiling-like algorithm find segments. LCSeg achieves results comparable previous approaches (e.g., Choi et al., 2001) monolog (i.e., newspaper)
synchronous dialog (i.e., meeting). Galley et al. also propose supervised model
segmenting meeting transcripts. use C4.5 probabilistic classifier lexical
conversational features show outperforms unsupervised method (LCSeg).
Hsueh, Moore, Renals (2006) apply models Galley et al. (2003)
manual transcripts ASR (automatic speech recognizer) output meetings.
perform segmentation coarse (topic) fine (subtopic) levels. topic level,
get similar results Galley et al. supervised model outperforming LCSeg. However, subtopic level, LCSeg surprisingly outperforms supervised model indicating
finer topic shifts better characterized lexical similarity alone.
work, initially show LCSeg performs poorly, applied temporal
ordering asynchronous conversation. because, mentioned earlier, topics
asynchronous conversations interleaved change sequentially following
526

fiTopic Segmentation Labeling Asynchronous Conversations

temporal order sentences. address this, propose novel extension LCSeg
leverages fine conversational structure asynchronous conversations. also propose
novel supervised segmentation model asynchronous conversation achieves even
higher segmentation accuracy combining lexical, conversational, topic features.
Malioutov Barzilay (2006) use minimum cut clustering model segment spoken
lectures (i.e., spoken monolog). form weighted undirected graph nodes
represent sentences weighted edges represent TF.IDF-based cosine similarity
sentences. segmentation solved graph partitioning problem
assumption sentences segment similar, sentences
different segments dissimilar. optimize normalized cut criterion (Shi &
Malik, 2000) extract segments. general, minimization normalized cut
NP-complete. However, sequentiality constraint topic segmentation monolog allows
find exact solution polynomial time. approach performs better
approach Choi et al. (2001) corpus spoken lectures. Since sequentiality
constraint hold asynchronous conversation, implement model without
constraint approximating solution, compare models.
Probabilistic generative models, variants Latent Dirichlet Allocation (LDA)
(Blei, Ng, & Jordan, 2003) also proven successful topic segmentation
monolog synchronous dialog. Blei Moreno (2001) propose aspect Hidden Markov
Model (AHMM) perform topic segmentation written spoken (i.e., transcribed)
monologs, show AHMM model outperforms HMM task. Purver
et al. (2006) propose variant LDA segmenting meeting transcripts, use top
words topic-word distributions topic labels. However, approach outperform LCSeg. Eisenstein Barzilay (2008) propose another variant incorporating
cue words (sequential) segmentation model. follow-up work, Eisenstein (2009)
proposes constrained LDA model uses multi-scale lexical cohesion perform hierarchical topic segmentation. Nguyen, Boyd-Graber, Resnik (2012) successfully incorporate speaker identity hierarchical nonparametric model segmenting synchronous
conversations (e.g., meeting, debate). work, demonstrate general LDA
model performs topic segmentation asynchronous conversation propose novel
extension LDA exploits fine conversational structure.
2.2 Topic Labeling
first comprehensive approach topic labeling, Mei, Shen, Zhai (2007) propose
methods label multinomial topic models (e.g., topic-word distributions returned
LDA). Crucial approach measure semantic similarity
topic-word distribution candidate topic label extracted corpus.
perform task assuming another word distribution label deriving
Kullback-Leibler divergence two distributions. turns measure
equivalent weighted point-wise mutual information (PMI) topic-words
candidate label, weights actually probabilities topic-word
distribution. use Maximum Marginal Relevance (MMR) (Carbonell & Goldstein,
1998) select labels relevant, redundant. labeling multiple
topic-word distributions, find discriminative labels, adjust semantic similarity
527

fiJoty, Carenini, & Ng

scoring function candidate label also similar topics gets lower
score. work, also use MMR promote diversity labels topic. However,
get distinguishable labels different topical segments conversation, rank
words high scoring word one topic high scores topics.
Recently, Lau, Grieser, Newman, Baldwin (2011) propose methods learn topic
labels Wikipedia titles. use top-10 words topic-word distribution
extract candidate labels Wikipedia. extract number features
represent candidate label. features actually different metrics used
literature measure association topic words candidate label (e.g.,
PMI, t-test, chi-square test). use Amazon Mechanical Turk get humans rank
top-10 candidate labels use average scores learn regression model.
Zhao, Jiang, He, Song, Achananuparp, Lim, Li (2011a) addresses problem
topical keyphrase extraction Twitter. Initially use modified Twitter-LDA model
(Zhao, Jiang, Weng, He, Lim, Yan, & Li, 2011b), assumes single topic assignment
tweet, discover topics corpus. Then, use PageRank (Page, Brin,
Motwani, & Winograd, 1999) rank words topic-word distribution. Finally,
perform bi-gram test generate keyphrases top ranked words topic.
studies try mine topics whole corpus, problem
find topical segments label given conversation, topics
closely related distributional variations subtle (e.g., Game contents size, Game
design Figure 2). Therefore, statistical association metrics like PMI, t-test, chi-square
test may reliable case data scarcity. Also conversation-level,
topics specific particular discussion (e.g., Telecon cancellation, TAG
document, Responding I18N Figure 1) exploiting external knowledge bases
like Wikipedia source candidate labels reasonable option us. fact,
none human-authored labels developement set appears Wikipedia title.
Therefore, propose generate topic labels using keyphrase extraction method
finds representative phrase(s) given text.
Several supervised unsupervised methods proposed keyphrase extraction (for comprehensive overview see Medelyan, 2009). supervised models (e.g.,
Hulth, 2003; Medelyan, Frnak, & Witten, 2009) follow two-stage framework. First,
candidate keyphrases extracted using n-gram sequences shallow parser (chunker).
Second, classifier filters candidates. strategy quite successful,
domain specific labor intensive. Every new domain may require new annotations,
times becomes expensive unrealistic. contrast, approach adopt
unsupervised paradigm, robust across new domains, still capable
achieving comparable performance supervised methods.
Mihalcea Tarau (2004) use graph-based (unsupervised) random walk model
extract keyphrases journal abstracts achieve state-of-the-art performance
(Mihalcea & Radev, 2011).2 However, model generic designed exploit
properties asynchronous conversations. propose two novel random walk models
incorporate conversation specific information. Specifically, models exploit information
2. original work published Mihalcea Tarau (2004).

528

fiTopic Segmentation Labeling Asynchronous Conversations

two different sources: (i) leading sentences topical segments, (ii)
fine conversational structure conversation.
2.3 Conversational Structure Extraction
Several approaches proposed capture underlying conversational structure
conversation. Recent work synchronous conversations focusing disentangling multi-party chats, linear structure. example, several studies propose
models disentangle multi-party chat (Elsner & Charniak, 2010, 2011; Wang & Oard,
2009; Mayfield, Adamson, & Rose, 2012). hand, asynchronous conversations
like email social media services (e.g., Gmail, Twitter) generally organize comments
tree-structured threads using headers. Automatic methods uncover complex
structures also proposed (e.g., Wang, Wang, Zhai, & Han, 2011; Aumayr, Chan,
& Hayes, 2011). However, use quotation asynchronous conversations express
conversational structure finer grained informative one
revealed reply-to relations comments (Carenini et al., 2011). example,
Figures 1 2, proximity quoted paragraph unquoted one represent informative conversational link two (i.e., talk
topic) would appear looking reply-to relations.
previously presented novel method capture email conversation finer
level analyzing embedded quotations emails (Carenini, Ng, & Zhou, 2007).
Fragment Quotation Graph (FQG) formed, shown beneficial email
summarization (Carenini, Ng, & Zhou, 2008) dialog act modeling (Joty, Carenini,
& Lin, 2011). work, generalize FQG asynchronous conversation
demonstrate topic segmentation labeling models also benefit significantly
fine conversational structure asynchronous conversation.

3. Topic Models Asynchronous Conversations
Developing topic segmentation labeling models asynchronous conversations challenging partly specific characteristics media. mentioned earlier,
unlike monolog (e.g., news article) synchronous dialog (e.g., meeting), topics
asynchronous conversations may change sequential way, topics interleaved. Furthermore, noticed Figures 1 2, writing style varies among
participants, many people tend use informal, short ungrammatical sentences,
thus making discourse much less structured. One aspect asynchronous conversation
first glance may appear help topic modeling message comes
header. However, often headers convey much topical information sometimes
even misleading. example, blog conversation (Figure 2), participants
keep talking different topics using title (i.e., nice nice nice),
convey topic information. Arguably, unique properties asynchronous
conversations limit application state-of-the-art techniques successful
monolog synchronous dialog. Below, first describe techniques
present extended effectively deal asynchronous conversations.
529

fiJoty, Carenini, & Ng

3.1 Topic Segmentation Models
first study problem topic segmentation asynchronous conversation. Therefore, first show existing models, originally developed
monolog synchronous dialog, naively applied asynchronous conversations.
Then, pointing limitations, propose novel topic segmentation models
asynchronous conversations.
3.1.1 Existing Models
LCSeg (Galley et al., 2003) LDA (Blei et al., 2003) two state-of-the-art unsupervised models topic segmentation monolog synchronous dialog (Purver, 2011).
following, briefly describe models directly applied
asynchronous conversations.
Lexical Cohesion-based Segmenter (LCSeg)
LCSeg sequential segmentation model originally developed segmenting meeting transcripts. exploits linguistic property called lexical cohesion, assumes topic
changes likely occur strong word repetitions start end. first computes
lexical chains (Morris & Hirst, 1991) non-stop word based word repetitions.3
chains weighted according term frequency chain length.
populated compact chains get higher scores. algorithm works two
adjacent analysis windows, fixed size k, empirically determined.
sentence boundary, computes cosine similarity (or lexical cohesion function)
two windows representing window vector chain-scores words.
Specifically, lexical cohesion windows (X ) computed with:
PN

wi,X .wi,Y
LexCoh(X, ) = cos sim(X, ) = qP i=1
PN
N
2
2
i=1 wi,Y
i=1 wi,X .

(1)

N number chains

rank(Ci ) chain Ci overlaps {X, }
wi, =
0
otherwise
sharp change local minima resulting similarity curve signals high probability
topic boundary. curve smoothed, local minimum computes
segmentation probability based relative depth nearest peaks either side.
Points highest segmentation probability selected hypothesized topic
boundaries. method similar TextTiling (Hearst, 1997) except similarity
computed based scores chains instead term frequencies.
LCSeg directly applied asynchronous conversation arranging comments based arrival time (i.e., temporal order) running algorithm get
topic boundaries.
3. One also consider lexical semantic relations (e.g., synonym, hypernym) lexical chaining
best results account repetition.

530

fiTopic Segmentation Labeling Asynchronous Conversations

Latent Dirichlet Allocation (LDA)
LDA generative model relies fundamental idea documents admixtures topics, topic multinomial distribution words. specifies
following distribution words within document:
P (xij ) =

K
X

P (xij |zij = k, bk )P (zij = k|i )

(2)

k=1

K number topics, P (xij |zij = k, bk ) probability word xij document
topic k, P (zij = k|i ) probability k th topic sampled word
token xij . refer multinomial distributions bk topic-word documenttopic distributions, respectively. Figure 3 shows resultant graphical model plate
notation N documents, K topics Mi tokens document i. Note that,
standard Dirichlet priors bk , respectively. Variational EM used
estimate b (Blei et al., 2003). One also use Gibbs sampling directly estimate
posterior distribution z, i.e., P (zij = k|xij ); namely, topic assignments word
tokens (Steyvers & Griffiths, 2007).





zi,j
bk
xi,j

K
Mi
N

Figure 3: Graphical model LDA plate notation.
framework directly applied asynchronous conversation considering
comment document. assuming words sentence occur independently
estimate topic assignments sentence follows:
P (zm = k|s) =



P (zm = k|xm )

(3)

xm

Finally, topic assigned by:
k = argmaxk P (zm = k|s)

(4)

3.1.2 Limitations Existing Models
main limitation two models discussed make bag-of-words
(BOW) assumption ignoring facts specific multi-party, asynchronous conversation. LCSeg considers term frequency closely terms occur
531

fiJoty, Carenini, & Ng

temporal order sentences. topics interleaved change sequentially
temporal order, often case asynchronous conversation, LCSeg would
fail find topical segments correctly.
hand, information relevant LDA term frequency. Several extensions LDA BOW approach proposed. example, Wallach (2006)
extends model beyond BOW considering n-gram sequences. Griffiths, Steyvers, Blei,
Tenenbaum (2005) present extension sensitive word-order automatically learns syntactic well semantic factors guide word choice. Boyd-Graber
Blei (2008) describe another extension consider syntax sentences.
argue models still inadequate finding topical segments correctly
asynchronous conversations especially topics closely related distributional variations subtle (e.g., Game contents size Game design). better
identify topics one needs consider features specific asynchronous conversations
(e.g., conversation structure, speaker, recipient). following, propose novel
unsupervised supervised topic segmentation models incorporate features.
3.1.3 Proposed Unsupervised Models
One important indicators topic segmentation asynchronous conversation
conversation structure. seen examples (Figures 1 2), participants
often reply post and/or use quotations talk topic. Notice also
use quotations express conversational structure finer level
granularity one revealed reply-to relations. corpora, found average
quotation usage 9.85 per blog conversation 6.44 per email conversation. Therefore,
need leverage key information get best models. Specifically,
need capture conversation structure quotation (i.e., text fragment) level,
incorporate structure segmentation models principled way.
following, first describe capture conversation structure
fragment level. show unsupervised models LCSeg LDA extended take conversation structure account, generating two novel unsupervised
models topic segmentation asynchronous conversation.
Extracting Finer-level Conversation Structure
Since consecutive turns asynchronous conversations far apart time, participants reply post comment, quoted version original message often
included (specially email) default draft reply order preserve context.
Furthermore, people tend break quoted message different questions,
requests claims dealt separately. result, message, unless
beginning, contain mix quoted novel paragraphs (or fragments) may well
reflect reply-to relationship paragraphs finer level granularity
one explicitly recorded comments. proposed novel approach capture
finer level conversation structure form graph called Fragment Quotation
Graph (FQG) (Carenini et al., 2007). following, demonstrate build
FQG sample blog conversation shown Figure 2. Figure 4(a) shows
blog conversation, sake illustration, instead showing real content,
532

fiTopic Segmentation Labeling Asynchronous Conversations

abbreviate sequence labels (e.g., a, b), label corresponding text fragment
(see Fragment column Figure 2). Building FQG two-step process.

Figure 4: (a) main Article C omments fragments example
Figure 2. Arrows indicate reply-to relations. (b) corresponding FQG.
Node creation: Initially, processing whole conversation, identify new
quoted fragments different depth levels. depth level quoted fragment
determined number quotation marks (e.g., >, >>, >>>). instance,
comment C1 contains new fragment c quoted fragment b depth level 1. C6
contains two new fragments k l, two quoted fragments j depth level
1, on. second step, compare fragments
based lexical overlap find distinct fragments. necessary, split
fragments step. example, ef C3 divided e f distinct
fragments compared fragments C4 . process gives 12 distinct
fragments constitute nodes FQG shown Figure 4(b).
Edge creation: create edges represent likely replying relationship fragments assuming new fragment potential reply neighboring quotations depth level 1. example, fragments C6 Figure 4(a), create
two edges k (i.e., (k,i),(k,j)) one edge l (i.e., (l,j)) Figure 4(b).
comment contain quotation, fragments linked new
fragments comment replies, capturing original reply-to relation.
Note FQG approximation reply relations fragments.
cases, proximity may indicate connection cases connection exist fragments never adjacent comment. Furthermore,
process could lead less accurate conversational structure quotation marks (or
cues) present. Nonetheless, previously showed considering FQG
beneficial dialog act modeling (Joty et al., 2011) email summarization (Carenini
et al., 2008). study, show topic segmentation (this Section) labeling
533

fiJoty, Carenini, & Ng

(Section 3.2) models also benefit significantly fine conversational structure
asynchronous conversation. Minimizing noise FQGs left future work.
LCSeg FQG (LCSeg+FQG)
examine FQG carefully, paths (considering fragments first comment
root nodes) interpreted subconversations, topic shifts likely occur
along pathway walk path. incorporate FQG LCSeg three steps.
Path extraction: First, extract paths FQG. example, FQG
Figure 4(b), extract paths < a, j, l >, < b, c, e, g >, < b, c, >, on.
LCSeg application: run LCSeg algorithm extracted paths
separately collect segmentations. example, applied LCSeg <
b, c, e, g > < b, c, > paths separately, may get following segmentations< b, c | e, g > < b, c | >, | denotes segment boundary.4 Notice
fragment multiple paths (e.g., b, c) eventually cause sentences
multiple segments. So, final step, need consolidation method.
Consolidation: intuition sentences consolidated segment appear
together segment often LCSeg applied step 2,
appear together segment, least similar. achieve this,
construct weighted undirected graph G(V, E), nodes V represent
sentences edge weights w(x, y) represent number segments
sentences x appear together; x appear together segment,
cosine similarity used edge weights. formally,

(
n,
w(x, y) =
cos sim(x, y),

x appear together n segments n > 0
n = 0

measure cosine similarity sentences x follows:
P

cos sim(x, y) = qP

tfw,x .tfw,y
qP
2 .
2
tf
x
,x
xi x
yi tfyi ,y

wx,y

(5)

tfa,s denotes term frequency term sentence s. cosine similarity
(0 cos sim(x, y) 1) provides informative edge weights sentence pairs
directly connected LCSeg segmentation decisions.5 Now, consolidation
problem formulated k-way-mincut graph partitioning problem
normalized cut (Ncut) criterion (Shi & Malik, 2000):
4. convenience, showing segmentations fragment level, segmentations
actually sentence level.
5. earlier work (Joty, Carenini, Murray, & Ng, 2010), consider cosine similarity
two sentences appear together segments. However, later found including
cosine similarity offers 2% absolute gain segmentation performance.

534

fiTopic Segmentation Labeling Asynchronous Conversations

N cutk (V ) =

cut(A1 , V A1 ) cut(A2 , V A2 )
cut(Ak , V Ak )
+
+ +
assoc(A1 , V )
assoc(A2 , V )
assoc(Ak , V )

(6)

A1 , A2 Ak form partition (i.e., disjoint sets nodes) graph,
V Ak set difference V (i.e., set nodes) Ak . cut(A, B)
measures total edge weight nodes set nodes set B,
assoc(A, V ) measures total edge weight nodes set nodes
graph. formally:

cut(A, B) =

X

w(u, v)

(7)

w(u, t)

(8)

uA,vB

assoc(A, V ) =

X
uA,tV

Note partitioning problem solved using correlation clustering
method (e.g., Bansal, Blum, & Chawla, 2002). Previous work graph-based topic
segmentation (Malioutov & Barzilay, 2006) shown Ncut criterion
appropriate cut criterion, accounts total edge weight
connecting B, therefore, favors cutting small sets isolated nodes
graph. However, solving Ncut NP-complete. Hence, approximate solution
following method proposed Shi Malik, (2000), time efficient
successfully applied image segmentation computer vision.
Notice approach makes difference FQG conversation contains one path. fact, corpora found average number paths
7.12 16.43 per email blog conversations, respectively.
LDA FQG (LDA+FQG)
key advantage probabilistic Bayesian models, LDA, allow us
incorporate multiple knowledge sources coherent way form priors (or
regularizer). incorporate FQG LDA, propose regularize LDA two
sentences adjacent fragments likely appear topical cluster.
first step towards aim regularize topic-word distributions (i.e., b Figure
3) word network two connected words get similar topic distributions.
now, assume given word network undirected graph G(V, E),
nodes V representing words edges (u, v)E representing links words
u v. want regularize topic-word distributions LDA two connected
words u v word network similar topic distributions (i.e., bk (u) bk (v)
k = 1 . . . K). standard conjugate Dirichlet prior Dir(bk |), however allow us
that, words share common variance parameter, mutually
independent except normalization constraint (Minka, 1999). Recently, Andrzejewski, Zhu,
Craven (2009) describe method encode must-links cannot-links
535

fiJoty, Carenini, & Ng

words using Dirichlet Forest prior. goal encode must-links. Therefore,
reimplemented model capability encoding (must-)links.
Must-links words (a, b), (b, c), (x, y) Figure 5(a) encoded
LDA using Dirichlet Tree (DT) prior. Like traditional Dirichlet, DT prior
also conjugate multinomial, different parameterization. Instead
representing multinomial sample outcome K-sided die, tree representation
(e.g., Figure 5(b)), sample (i.e., leaf tree) represented outcome finite
stochastic process. probability leaf (i.e., word case) product branch
probabilities leading leaf. DT prior distribution leaf probabilities.
Let n edge weight leading node n, C(n) children node n, L
leaves tree, internal nodes, L(n) leaves subtree node
n. generate sample bk DT() drawing multinomial internal node
Dir( C(i) ) (i.e., edge weights node children). probability
density function DT(bk |) given by:

(i)
!
l 1 X

DT (bk |)
blk
bkj
(9)


iI



jL(i)

P
(i) = jC(i) j , difference in-degree out-degree
internal node i. Notice (i) = 0 I, DT reduces standard Dirichlet.
Suppose given word network shown Figure 5(a). network
decomposed collection chains (e.g., (a, b, c), (p), (x, y)). chain
containing multiple elements (e.g., (a, b, c), (x, y)), subtree DT (Figure 5(b)),
one internal node (blank Figure) words chain leaves. weight
internal node leaves , regularization strength
parameter standard symmetric Dirichlet prior bk . root node
DT connects internal nodes |L(i)| weight. leaves (words)
single element chains (e.g, (p)) connected root DT directly
weight . Notice = 1, (i) = 0, reduces standard LDA (i.e.,
regularization). tuning control strength regularization.

3

x
b



p

p





c

2



b



c





x



(b)

(a)

Figure 5: (a) Sample word network, (b) Dirichlet Tree (DT) built word network.
point left explained construct word network.
regularize LDA FQG, construct word network word linked
words adjacent fragments FQG. Specifically, word wi f ragx
536

fiTopic Segmentation Labeling Asynchronous Conversations

word wj f ragy wi 6=wj , create link (wi , wj ) x = (x, y)Ef qg , Ef qg
set edges FQG. implicitly compels two sentences adjacent
fragments similar topic distributions, appear topical segment.
3.1.4 Proposed Supervised Model
Although unsupervised models discussed previous section key advantage
requiring labeled data, limited ability learn domain-specific
knowledge possible large diverse set features (Eisenstein & Barzilay, 2008).
Beside discourse cohesion, captures changes content, important domain-specific distinctive features signal topic change. example, discourse
markers (or cue phrases) (e.g., okay, anyway, now, so) prosodic cues (e.g., longer pause)
directly provide clues topic change, shown useful features
topic segmentation monolog synchronous dialog (Passonneau & Litman, 1997; Galley
et al., 2003). hypothesize asynchronous conversations also feature
distinctive characteristics topic shifts. example, features like sender recipient
arguably useful segmenting asynchronous conversations, different participants
less active discussion different topics. Therefore, next step
build even accurate topic segmentation model asynchronous conversations,
propose combine different sources possibly useful information principled way.
supervised framework serves viable option combine large number features optimize relative weights decision making, relies labeled data
training. amount labeled data required achieve acceptable performance
always important factor consider choosing supervised vs. unsupervised.
work, propose supervised segmentation model outperforms unsupervised
models, even trained small number labelled conversations.
supervised model built graph-theoretic framework used
many NLP tasks, including coreference resolution (Soon, Ng, & Lim, 2001) chat
disentanglement (Elsner & Charniak, 2010). method works two steps.
Classification: binary classifier trained labeled dataset, marks
pair sentences given conversation different topics.
Graph partitioning: weighted undirected graph G = (V, E) formed,
nodes V represent sentences conversation edge-weights w(x, y)
denote probability (given classifier) two sentences x appear
topic. optimal partition extracted.
Sentence pair classification
classifiers accuracy deciding whether pair sentences x
different topics crucial models performance. Note since sentence
pair conversation defines data point, conversation containing n sentences gives
1+2+. . .+(n-1)= n(n1)
= O(n2 ) training examples. Therefore, training dataset containing
2
Pm ni (ni 1)
conversations gives i=1
training examples, ni number sentences
2
th
conversation. quadratic expansion training examples enables classifier
achieve best classification accuracy labeled conversations.
537

fiJoty, Carenini, & Ng

pairing sentences email conversation email corpus, got
total 14, 528 data points 58.8% class (i.e.,
likely email), pairing sentences blog conversation blog
corpus, got total 572, 772 data points 86.3% different class (i.e.,
different likely blog).6 select best classifier, experimented
variety classifiers full feature set (Table 2). Table 1 shows performance
classifiers averaged leave-one-out procedure, i.e., corpus containing
conversations, train 1 conversations test rest.
Classifier
KNN
LR
LR
RMLR (rbf)
SVM (lin)
SVM (rbf)
Majority class

Type

Regularizer

non-parametric
parametric
parametric
non-parametric
parametric
non-parametric
-

l2
l1
l2
-

Accuracy (Blog)
Train
Test
62.7%
61.4 %
90.8% 91.9%
86.8%
87.6%
91.7%
82.0%
76.6%
78.7 %
80.5%
77.9%
86.3% (different)

Accuracy (Email)
Train
Test
54.6%
55.2%
71.7%
72.5%
69.9%
67.7%
91.1%
62.1%
68.3%
69.6%
75.9%
67.7%
58.8% (same)

Table 1: Performance classifiers using full feature set (Table 2). training
set, regularizer strength (or C SVMs) learned 10-fold cross validation.

K-Nearest Neighbor (KNN) performs poorly. Logistic Regression (LR) l2
regularizer delivers highest accuracy datasets. Support Vector Machines (SVMs)
(Cortes & Vapnik, 1995) linear rbf kernels perform reasonably well,
well LR. Ridged Multinomial Logistic Regression (RMLR) (Krishnapuram et al.
2005), kernelized LR, extremely overfits data. opted LR l2 regularizer
delivers best performance term accuracy, also
efficient. limited memory BFGS (L-BFGS) fitting algorithm used LR efficient
terms time (quadratic convergence rate; fastest among listed models) space
(O(mD), memory parameter L-BFGS number features).
Table 2 summarizes full feature set mean test set accuracy (using leave-oneout procedure) achieved different types features LR classifier.
Lexical features encode similarity two sentences x based raw
content. Term frequency-based similarity widely used feature previous work, e.g.,
TextTiling (Hearst, 1997). compute feature considering two analysis windows,
fixed size k. Let X window including sentence x preceding k 1
sentences, window including sentence following k 1 sentences.
measure cosine similarity two windows representing vectors
TF.IDF (Salton & McGill, 1986) values words. Another important domain specific
feature proved useful previous research (e.g., Galley et al., 2003) cue words
(or discourse markers) sign presence topic boundary (e.g., coming up, joining
us news). Since work concerns conversations (not monologs), adopt cue word
6. See Section 4 detailed description corpora. class labels produced taking
maximum vote three annotators.

538

fiTopic Segmentation Labeling Asynchronous Conversations

Lexical

Accuracy: 86.8 Precision: 62.4 Recall: 4.6 (Blog)
Accuracy: 59.6 Precision: 59.7 Recall: 99.8 (Email)

F IDF1
F IDF2
Cue Words
QA

TF.IDF-based similarity x window size k=1.
TF.IDF-based similarity x window size k=2.
Either x contains cue word.
x asks question explicitly using ? answers using
(yes, yeah, okay, ok, no, nope).
Either x greeting word (hi, hello, thanks, thx, tnx, thank.)

Greet
Conversation

Accuracy: 88.2 Precision: 81.6 Recall: 20.5 (Blog)
Accuracy: 65.3 Precision: 66.7 Recall: 85.1 (Email)

Gap
Speaker
F QG1

gap x number sentence(s).
x sender (yes no).
Distance x FQG terms fragment id.
(i.e., |f rag id(y) f rag id(x)|).
Distance x FQG terms number edges.
Distance x FQG number edges
time considering undirected graph.
whether x comment one reply
other.
x mentions ys speaker vice versa.

F QG2
F QG3
Same/Reply
Name
Topic

Accuracy: 89.3 Precision: 86.4 Recall: 17.3 (Blog)
Accuracy: 67.5 Precision: 68.9 Recall: 76.8 (Email)

LSA1
LSA2
LDA
LDA+FQG
LCSeg
LCSeg+FQG
LexCoh

LSA-based similarity x window size k=1.
LSA-based similarity x window size k=2.
LDA segmentation decision x (same different).
LDA+FQG segmentation decision x (same different).
LCSeg segmentation decision x (same different).
LCSeg+FQG segmentation decision x (same different).
Lexical cohesion x y.

Combined

Accuracy: 91.9 Precision: 78.8 Recall: 25.8 (Blog)
Accuracy: 72.5 Precision: 70.4 Recall: 81.5 (Email)

Table 2: Features average performance testsets (using leave-one-out).

539

fiJoty, Carenini, & Ng

list derived automatically meeting corpus Galley et al. (2003). answers
greets x likely topic. Therefore, use Question
Answer (QA) pairs greeting words two lexical features.
Conversational features capture conversational properties asynchronous conversation. Time gap speaker commonly used features segmenting synchronous
conversations (e.g., Galley et al. 2003). encode similar information asynchronous media counting number sentences x (in temporal order)
gap, senders speakers. strongest baseline Speaker (see Section 5.1)
also proves effectiveness asynchronous domains. results Section 5.1 also suggest
fine conversational structure form FQG beneficial incorporated unsupervised segmentation models. encode valuable information
supervised segmentation model computing three distance features FQG:
F QG1 , F QG2 , F QG3 . State-of-the-art email blog systems use reply-to relation
group comments threads. ys comment reply xs comment,
likely two sentences talk topic. Participants sometimes mention others name multi-party conversations make disentanglement easier (Elsner
& Charniak, 2010). also use feature supervised segmentation model.
Topic features complex encode topic information existing segmentation
models. Choi et al. (2001) used Latent Semantic Analysis (LSA) measure similarity
two sentences showed LSA-based similarity yields better results
direct TF.IDF-based similarity since surmounts problems synonymy (e.g., car,
auto) polysemy (e.g., money bank, river bank). compute LSA, first construct
word-document matrix W conversation, Wi,j = frequency word
comment j IDF score word i. perform truncated Singular Value Decomposition
(SVD) W : W Uk k VkT , represent word k dimensional7 vector ki .
sentence represented weighted
sum word vectors. Formally, LSA
P
k


representation sentence =
tf
.i , tfi = term frequency
word sentence s. like TF.IDF-based similarity, compute LSAbased similarity sentences x y, time representing corresponding
windows (i.e., X ) LSA vectors.
segmentation decisions LDA, LDA+FQG, LCSeg LCSeg+FQG models
described previous section also encoded topic features.8 described Section 3.1.1, LCSeg computes lexical cohesion (LexCoh) function two consecutive
windows based scores lexical chains. Galley et al. (2003) shows significant
improvement function used feature supervised (sequential) topic
segmentation model meetings. However, since problem topic segmentation
sequential, want compute function two given windows X (not
necessary consecutive). that, first extract lexical chains scores
spans (i.e., beginning end sentence numbers) conversation. lexical cohesion
function computed method described Equation 1.
7. study, k empirically set 14 number comments based held-out development set.
8. earlier work (Joty, Carenini, Murray, & Ng, 2011) include segmentation decisions
LDA+FQG LCSeg+FQG models features. However, including features improves
classification accuracy segmentation accuracy.

540

fiTopic Segmentation Labeling Asynchronous Conversations

0.35
0.3
0.25
0.2
0.15
0.1

Email
Blog

LCSeg

LCSeg+FQG

LexCoh

LDA+FQG

LDA

LSA2

LSA1

Name

Same/Reply

F QG2

F QG3

F QG1

Gap

Speaker

QA

Greet

Cue

F.IDF2

F.IDF1

5 102
0

Figure 6: Relative importance features averaged leave-one-out.

describe classifiers performance terms raw accuracy (correct decisions/total),
precision recall class different types features averaged leaveone-out procedure (Table 2). Among feature types, topic features yield highest
accuracy same-class precision corpora (p < 0.01).9 Conversational features also
proved important achieve higher accuracy lexical features (p < 0.01).
Lexical features poor accuracy, slightly higher majority baseline
always picks likely class. However, combine features, get
best performance (p < 0.005). results demonstrate importance topical
conversational features beyond lexical features used existing segmentation
models. compare performance two corpora, notice
blog accuracy same-class precision higher email, same-class
recall much lower. Although reasonable given class distributions two
corpora (i.e., 13.7% 58.8% examples same-class blog email, respectively), surprisingly, tried deal problem applying bagging
technique (Breiman, 1996), performance improve significantly. Note
classification errors occurred sentence-pair classification phase recovered
graph partitioning step (see below). reason incorrect decisions
outvoted nearby sentences clustered correctly.
analyze contribution individual features. Figure 6 shows relative
importance features based absolute values coefficients LR
classifier. segmentation decision LCSeg+FQG important feature
domains. Same/Reply also effective feature, especially blog. blog,
Speaker feature also plays important role. F QG2 (distance number edges
directed FQG) also effective domains, especially email. two
features FQG (F QG1 , F QG3 ) also relevant email.
Finally, order determine many annotated conversations need achieve
best segmentation performance, Figure 7 shows classification error rate (incorrect
decisions/total), tested 5 randomly selected conversations trained increasing
9. tests statistical significance performed using paired t-test.

541

fiJoty, Carenini, & Ng

Classification error rate

number randomly added conversations. classifier appears achieve best performance small number labeled conversations. blog, error rate flattens
8 conversations, email, happens 15. surprising
since blog conversations much longer (an average 220.55 sentences) email conversations (an average 26.3 sentences), generating similar number training examples
conversations (recall, n sentences get O(n2 ) training examples).

50
45
40
35
30
25
20
15
10
5

Email
Blog

2

4

6

8

10

12

14

16

18

20

22

24

26

28

30

32

34

Number training conversations

Figure 7: Error rate vs. number training conversations.
Graph partitioning
Given weighted undirected graph G = (V, E), nodes V represent sentences
edge-weights w(x, y) denote probability (given classifier) two
sentences x appear topic, formulate segmentation task
k-way-mincut graph partitioning problem intuition sentences segment
discuss topic, sentences different segments discuss different
topics. optimize normalized cut criterion (i.e., equation 6) extract optimal
partition done consolidating various segments LCSeg+FQG.
3.2 Topic Labeling Models
methods automatically identify topical segments asynchronous conversation, next step pipeline generate one informative
descriptions topic labels segment facilitate interpretations topics.
first address problem asynchronous conversation.
Ideally, topic label meaningful, semantically similar underlying topic,
general discriminative (when multiple topics) (Mei et al., 2007). Traditionally,
top k words multinomial topic model like LDA used describe topic. However,
pointed Mei et al., word-level, topic labels may become generic
impose cognitive difficulties user interpret meaning topic associating
words together. example, Figure 2, without reading text, words
{release, free, reaction, Daggerfall}, may difficult user understand
topic Daggerfalls free release peoples reaction it. hand,
labels expressed sentence-level, may become specific cover
542

fiTopic Segmentation Labeling Asynchronous Conversations

whole theme topic (Mei et al., 2007). Based observations, recent studies
(e.g., Mei et al., 2007; Lau et al., 2011) advocate phrase-level topic labels,
also consistent monolog corpora built part Topic Detection
Tracking (TDT) project10 . Note also observe preference phrase-level labels
within asynchronous conversational corpora human annotators without
specific instructions spontaneously generated topic labels phrase-level. Considering
this, treat phrase-level target level granularity topic label.
problem different problem keyphrase indexing (Medelyan,
2009) task find set keyphrases either given text
controlled vocabulary (i.e., domain-specific terminologies) describe topics covered
text. setting, controlled vocabulary. Furthermore,
exploiting generic knowledge bases like Wikipedia source devising controlled
vocabulary (Medelyan, 2009) viable option case since topics specific particular discussion (e.g., Free release Daggerfall reaction, Game contents
size Figure 2). fact, none human-authored labels developement set
appears verbatim Wikipedia. propose generate topic labels using keyphrase
extraction approach identifies representative phrase(s) given text.
adapt graph-based unsupervised ranking framework, domain independent,
without relying labeled data achieves state-of-the-art performance keyphrase
extraction (Mihalcea & Radev, 2011). Figure 8 shows topic labeling framework. Given
(topically) segmented conversation, system generates k keyphrases describe
topic conversation. discuss different components system.
Word Ranking

words

Segmented
input conversation

Segment-level
Ranking

top words
Phrase
Generation

Preprocessor
Conversation-level
Ranking

top words
conversationlevel phrases

Segment-level
phrases

k output phrases

Redundancy
Checking

relevant
phrases

Conversation-level
Phrase Reranking

Figure 8: Topic labeling framework asynchronous conversation.

3.2.1 Preprocessing
preprocessing step, tokenize text apply syntactic filter select
words certain part-of-speech (POS). use state-of-the-art tagger11 tokenize
10. http://projects.ldc.upenn.edu/TDT/
11. Available http://cogcomp.cs.illinois.edu/page/software

543

fiJoty, Carenini, & Ng

text annotate tokens POS tags. experimented five different
syntactic filters. select (i) nouns, (ii) nouns adjectives, (iii) nouns, adjectives
verbs, (iv) nouns, adjectives, verbs adverbs, (v) words, respectively.
filters also exclude stopwords. second filter, selects nouns adjectives,
achieves best performance development set, also consistent
finding Mihalcea Tarau (2004). Therefore, syntactic filter used system.
3.2.2 Word Ranking
words selected preprocessing step correspond nodes graph. direct
application ranking method described Mihalcea Tarau (2004) would define
edges based co-occurrence relation respective words, apply
PageRank (Page et al., 1999) algorithm rank nodes. argue co-occurrence
relations may insufficient finding topic labels asynchronous conversation.
better identify labels one needs consider aspects specific asynchronous
conversation. particular, propose exploit two different forms conversation specific
information graph-based ranking model: (1) informative clues leading
sentences topical segment, (2) fine-grained conversational structure (i.e.,
Fragment Quotation Graph (FQG)) asynchronous conversation. following,
describe two novel extensions turn.
Incorporating Information Leading Sentences
general, leading sentences topic segment carry informative clues topic
labels, since speakers likely try signal topic shift
introduce new topic. key observation especially true asynchronous
conversations, topics interleaved less structured. example, Figure 2,
notice almost every case, leading sentences topical segments covers
information conveyed labels. property confirmed Figure 9,
shows percentage non-stopwords human-authored labels appear leading
sentences segments development set. first sentence covers 29%
38% words gold labels blog email corpora, respectively. first
two sentences cover around 35% 45% words gold labels blog email,
respectively. consider first three sentences, coverage raises 39%
49% blog email, respectively. increment less add sentences.
leverage useful information ranking model, propose following
biased random walk model, P (w|Uk ), score word w given set leading
sentences Uk topic segment k, expressed convex combination relevance
leading sentences Uk (i.e., (w|Uk )) relatedness words segment:
P (w|Uk ) = P

X
(w|Uk )
e(y, w)
P
+ (1 )
P (y|Uk )
zCk (z|Uk )
zCk e(y, z)

(10)

yCk

value (0 1), call bias, trade-off two
components set empirically. higher values , give weight
words relevance leading sentences compared relatedness words
544

fiTopic Segmentation Labeling Asynchronous Conversations

55
50

Email
Blog

44.86

45
40

25

42.01

52.94
44.57

38.98

38.08
34.73

35
30

50.65

48.95

28.74
One

Two

Four

Three

Five

Figure 9: Percentage words human-authored labels appearing leading sentences
topical segments.
segment. Here, Ck set words segment k, represents nodes
graph. denominators components normalization. define (w|Uk ) as:
(w|Uk ) = log(tfwUk + 1).log(tfwk + 1)

(11)

tfwUk tfwk number times word w appears Uk segment k, respectively. similar model proven successful measuring relevance sentence
query query-based sentence retrieval (Allan, Wade, & Bolivar, 2003).
Recall multiple topics conversation, requirement topic
labels labels different topics discriminative (or distinguishable) (Mei
et al., 2007). implicitly indicates high scoring word one segment
high scores segments conversation. Keeping criterion mind,
define (undirected) edge weights e(y, w) equation 10 follows:
k
e(y, w) = tfw,y
log

K
k0
0.5 + tfw,y

(12)

k
K denotes number topics (or topic segments) conversation, tfw,y
0
k
tfw,y number times words w co-occur window size segment
k segments except k conversation, respectively. Notice measure
similar spirit TF.IDF metric (Salton & McGill, 1986), co-occurrence
level. co-occurrence relationship words captures syntactic dependencies
lexical cohesion text, also used Mihalcea Tarau (2004).12
Equation 10 written matrix notation as:

= [Q + (1 )R]T = ,
Q R square matrices Qi,j =

(13)

P (j|Uk )
zC (z|Uk )

i, Ri,j =

k

P e(i,j)
,
jC e(i,j)

respectively. Notice stochastic matrix (i.e., rows add 1),

k

therefore, treated transition matrix Markov chain. assume
12. Mihalcea Tarau (2004) use unweighted graph key phrase extraction. However, experiments, get better results weighted graph.

545

fiJoty, Carenini, & Ng

word state Markov chain, Ai,j specifies transition probability state
state j corresponding Markov chain. Another interpretation given
biased random walk graph. Imagine performing random walk graph,
every time step, probability , transition made words
relevant leading sentences probability 1 , transition made
related words segment. Every transition weighted according corresponding
elements Q R. vector looking stationary distribution
Markov chain also (normalized) eigenvector eigenvalue 1. Markov
chain unique stationary distribution ergodic (Seneta, 1981).
ensure Markov chain property reserving small probability jumping
state current state (Page et al., 1999).13 larger matrices,
efficiently computed iterative method called power method.
Incorporating Conversational Structure
Section 3.1, described fine conversation structure form Fragment
Quotation Graph (FQG) effectively exploited topic segmentation models.
hypothesize topic labeling model also benefit FQG. previous
work email summarization (Carenini et al., 2008), applied PageRank FQG
measure importance sentence demonstrated benefits using FQG.
finding implies important node FQG likely cover important aspect
topics discussed conversation. intuition that, topic label,
keyword co-occur keywords, also come
important fragment FQG. believe mutually reinforcing relationship
FQG Word Co-occurrence Graph (WCG) reflected
rankings. proposal implement idea process co-ranking (Zhou et
al., 2007) heterogeneous graph, three random walks combined together.
Let G = (V, E) = (VF VW , EF EW EF W ) heterogeneous graph fragments
words. shown Figure 10, contains three sub-graphs. First, GF = (VF , EF )
unweighted directed FQG, VF denoting set fragments EF denoting set
directed links fragments. Second, GW = (VW , EW ) weighted undirected
WCG, VW set words segment EW set edge-weights
defined equation 12. Third, GF W = (VF W , EF W ) weighted bipartite graph
ties GF GW together representing occurrence relations words
fragments. Here, VF W = VF VW , weighted undirected edges EF W connect
fragment vf VF word vw VW , weight representing number times
word vw occurs fragment vf .
co-ranking framework combines three random walks, one GF , one GW
one GF W . Let F W denote transition matrices (intra-class) random walks
GF GW , respectively, f w denote respective stationary distributions.
Since, GF W bipartite graph, (inter-class) random walk GF W described
two transition matrices, F W|VF ||VW | W F|VW ||VF | . One intra-class step changes
probability distribution (f, 0) (F f, 0) (0, w) (0, W w), one inter13. simplicity, make random jump component explicit equations. But, readers
keep mind transition matrices described article contain component.

546

fiTopic Segmentation Labeling Asynchronous Conversations

GW
GF

Figure 10: Three sub-graphs used co-ranking: fragment quotation graph GF ,
word co-occurrence graph GW , bipartite graph GF W ties two together.
Blue nodes represent fragments, red nodes represent words.
class step changes distribution (f, w) (W F w, F W f ) (for details see Zhou,
Orshanskiy, Zha, & Giles, 2007). coupling regulated parameter (0 1)
determines extent ranking words fragments depend
other. Specifically, two update steps power method are:

f t+1 = (1 ) (F f ) + W F (F W W F )wt
w

t+1











= (1 ) (W w ) + F W (W F F W )f

(14)


(15)

described co-ranking framework assuming WCG
corresponding FQG. However, recall WCG built topic segment,
FQG described far (Figure 4) based whole conversation. order construct
FQG topic segment conversation, take fragments (and edges)
conversation-level FQG include sentences segment.
operation two consequences. One, conversation-level fragments may pruned.
Two, sentences conversation-level fragment may discarded. example,
FQG topic (segment) ID 1 Figure 2 includes fragments a, h, i, j, l,
edges them. Fragment j, contains three sentences conversation-level
FQG, contains one sentence FQG topic ID 1.
3.2.3 Phrase Generation
ranked list words describing topical segment, select top
keywords constructing keyphrases (labels) keywords. take similar
approach Mihalcea Tarau (2004). Specifically, mark selected keywords
text, collapse sequences adjacent keywords keyphrases. example,
consider first sentence, .. 15th anniversary Elder Scrolls series .. Figure 2.
Elder, Scrolls series selected keywords, since appear adjacent text,
547

fiJoty, Carenini, & Ng

collapsed one single keyphrase Elder Scrolls series. score keyphrase
determined taking maximum score constituents (i.e., keywords).
Rather constructing keyphrases post-processing phase, do,
alternative approach first extract candidate phrases using either n-gram sequences
chunker preprocessing, rank candidates (e.g., Medelyan, 2009;
Hulth, 2003). However, determining optimal value n n-gram sequence
issue, including possible n-gram sequences ranking excessively increases
problem size. Mei et al. (2007) also show using chunker leads poor results due
inaccuracies chunker, especially applied new domain like ours.
3.2.4 Conversation-Level Phrase Re-ranking
far, extracted phrases topic segment ignoring rest
conversation. method fails find label constituents appear outside
segment. example, Blog corpus, phrase server security humanauthored label server security firewall appear topical segment,
appears whole conversation. fact, development set, 14% 8%
words blog email labels, respectively, come part conversation
outside topic segment. Thus, propose extract informative phrases
whole conversation, re-rank respect individual topics (or segments)
combine relevant conversation-level phrases segment-level ones.
rank words whole conversation applying ranking models described
Section 3.2.2 extract phrases using method described Section 3.2.3. Note
apply biased random walk model whole conversation,
concept leading sentences distinction topics. Therefore, apply
whole conversation, adjust biased random walk model (Equation 10) follows:
P (w) =

X

e(y, w)
P (y)
zCk e(y, z)

P
yCk

(16)

e(y, w) = tfw,y , number times words w co-occur window size
conversation. hand, co-ranking framework, applied whole
conversation, combines two conversation-level graphs: FQG, WCG.
re-rank phrases extracted whole conversation respect particular
topic conversation, reuse score words topic segment (given
ranking models Section 3.2.2). before, score (conversation-level) phrase
determined taking maximum (segment-level) score constituents (words).
word occur topic segment, score assumed 0.
3.2.5 Redundancy Checking
ranked list labels (keyphrases), last step produce final
k labels output. selecting multiple labels topic, expect new labels
diverse without redundant information achieve broad coverage topic.
use Maximum Marginal Relevance (MMR) (Carbonell & Goldstein, 1998) criterion
select labels relevant, redundant. Specifically, select labels one
one, maximizing following MMR criterion time:
548

fiTopic Segmentation Labeling Asynchronous Conversations

l = argmaxlW [ Score(l) (1 ) max

lS Sim(l, l)]

(17)

W set labels set labels already selected output.
define similarity two labels l l as: Sim(l, l) = /nl ,
number overlapping (modulo stemming) words l l, nl number
words l. parameter (0 1) quantifies amount redundancy allowed.

4. Corpora Metrics
Due lack publicly available corpora asynchronous conversations annotated
topics, developed first corpora annotated topic information.
4.1 Data Collection
email, selected publicly available BC3 email corpus (Ulrich, Murray, & Carenini,
2008) contains 40 email conversations World Wide Web Consortium (W3C)
mailing list14 . BC3 corpus, previously annotated sentence-level speech acts, subjectivity, extractive abstractive summaries, one growing number corpora
used email research (Carenini et al., 2011). average 5 emails per conversation total 1024 sentences excluding quoted sentences. conversation
also provides thread structure based reply-to relations emails.
blog, manually selected 20 conversations various lengths, short enough
still feasible humans annotate, popular technology-related news website
Slashdot15 . Slashdot selected provides reply-to links comments,
allowing accurate thread reconstruction, since comments moderated users
site, expected decent standard. conversation Slashdot begins
article (i.e., short synopsis paragraph possibly link original story),
followed lengthy discussion section containing multiple threads comments
single comments. unlike email conversation contains single thread
emails. main article assumed root conversation tree (based
reply-to), threads single comments form sub-trees tree.
blog corpus, total 4, 411 sentences. total number comments per
blog conversation varies 30 101 average 60.3, number threads per
conversation varies 3 16 average 8.35 number single comments
varies 5 50 average 20.25.
4.2 Topic Annotation
Topic segmentation labeling general nontrivial subjective task even
humans, particularly text unedited less organized (Purver, 2011).
conversation phenomenon called Schism makes even challenging conversations.
schism, new conversation takes birth existing one, necessarily
topic shift participants refocus attention onto other,
14. http://research.microsoft.com/en-us/um/people/nickcr/w3c-summary.html
15. http://slashdot.org/

549

fiJoty, Carenini, & Ng

away whoever held floor parent conversation (Sacks, Schegloff, & Jefferson,
1974). example email conversation shown Figure 1, schism takes place
participants discuss topic responding I18N. annotators agree fact
topic responding I18N swerves topic TAG document.
properly design effective annotation manual procedure, performed twophase pilot study carrying actual annotation. initial annotation manual
inspired AMI annotation manual used topic segmentation ICSI meeting
transcripts16 . pilot study, selected two blog conversations Slashdot five
email conversations W3C corpus. Note conversations picked
corpora. Later experiments use conversations development
set tuning different parameters computational models. first phase
pilot study five computer science graduate students volunteered annotation,
generating five different annotations conversation. revised annotation
manual based feedback detailed analysis possible sources disagreement.
second phase, tested procedure university postdoc annotation.
prepared two different annotation manuals one email one blog. chose
mainly two reasons. (i) discussed earlier, email blog conversations
structurally different specific characteristics. (ii) email corpus
already annotations (e.g., abstract summaries) could reuse topic
annotation, whereas blog corpus brand new without existing annotation.
actual annotation recruited paid three cognitive science fourth year
under-graduates, native speakers English also Slashdot bloggers. average,
took 7 28.5 hours annotate 40 email 20 blog conversations,
respectively. all, three different annotations conversation corpora.
blog conversations, task finding topics carried four steps:
1. annotators read conversation (i.e., article, threads comments single
comments) wrote short summary ( 3 sentences) threads.
2. provided short high-level descriptions topics discussed conversation
(e.g., Game contents size, Bugs faults). descriptions serve reference
topic labels work. target number topics labels given
advance instructed find many topics needed
convey overall content conversation.
3. assigned appropriate topic sentence. However, sentence
covered one topic, labeled relevant topics according
order relevance. used predefined topic OFF-TOPIC sentence
fit topic. Wherever appropriate also used two predefined
topics: INTRO (e.g., hi X) END (e.g., Best, X).
4. annotators authored single high-level 250 words summary whole conversation. step intended help remember anything may
forgotten revise annotations previous three steps.
16. http://mmm.idiap.ch/private/ami/annotation/TopicSegmentationGuidelinesNonScenario.pdf

550

fiTopic Segmentation Labeling Asynchronous Conversations

email conversation BC3, already three human-authored summaries.
So, along actual conversations, provided annotators summaries
give brief overview discussion. reading conversation associated
summaries, performed tasks 2 3 procedure follow annotating
blogs. annotators carried tasks paper. created hierarchical thread
view conversation based reply-to relations comments (or emails)
using indentations printed participants information different color Gmail.
email corpus, three annotators found 100, 77 92 topics respectively (269
total), blog corpus, found 251, 119 192 topics respectively (562
total). Table 3 shows basic statistics computed three annotations
conversations.17 average, 26.3 sentences 2.5 topics per email conversation,
220.55 sentences 10.77 topics per blog conversation. average, topic email
conversations contains 12.6 sentences, topic blog conversations contains 27.16
sentences. average number topics active time 1.4 5.81 email
blog conversations, respectively. average entropy corresponds granularity
annotation (as described next Section) 0.94 email conversations 2.62
blog conversations. statistics (i.e., number topics topic density)
indicate substantial amount segmentation (and labeling) do.

Number
Number
Average
Average
Entropy

sentences
topics
topic length
topic density

Mean
Email Blog
26.3
220.55
2.5
10.77
12.6
27.16
1.4
5.81
0.94
2.62

Max
Email Blog
55
430
7
23
35
61.17
3.1
10.12
2.7
3.42

Min
Email Blog
13
105
1
5
3
11.67
1
2.75
0
1.58

Table 3: Statistics three human annotations per conversation.

4.3 Evaluation (and Agreement) Metrics
section describe metrics used compare different annotations. metrics
measure much annotators agree other, well models
various baselines perform. given conversation, different annotations
different numbers topics, different topic assignments sentences (i.e., clustering)
different topic labels. describe metrics used measure segmentation
performance followed metrics used measure labeling performance.
4.3.1 Metrics Topic Segmentation
different annotations group sentences different numbers clusters, agreement
metrics widely used supervised classification, statistic F1 score,
applicable. Again, problem topic segmentation asynchronous conversation
17. got 100% agreement two predefined topics INTRO END. Therefore, computations excluded sentences marked either INTRO END.

551

fiJoty, Carenini, & Ng

sequential nature. Therefore, standard metrics widely used sequential topic
segmentation monolog synchronous dialog, Pk (Beeferman, Berger, &
Lafferty, 1999) W indowDif f (W D) (Pevzner & Hearst, 2002), also applicable.
Rather, one-to-one local agreement metrics described Elsner Charniak
(2010) appropriate segmentation task.
one-to-one metric measures global agreement two annotations pairing
topical segments two annotations way (i.e., computing optimal
max-weight bipartite matching) maximizes total overlap, reports
percentage overlap. local agreement metric lock measures agreement within context
k sentences. compute loc3 score m-th sentence two annotations,
consider previous 3 sentences: m-1, m-2 m-3, mark either
different depending topic assignment. loc3 score two annotations
mean agreement different judgments, averaged sentences.
See Appendix detailed description metrics concrete examples.
report annotators agreement found one-to-one loc3 metrics Table 4.
human annotation, measure agreement two human annotations
separately, report mean agreements. email, get high agreement
metrics, though local agreement (average 83%) little higher global one
(average 80%). blog, annotators high agreement loc3 (average 80%),
disagree one-to-one (average 54%). low one-to-one agreement
blog quite acceptable since blog conversations much longer less focused
email conversations (see Table 3). analyzing two corpora also noticed
blogs, people informal often make implicit jokes (see Figure 2). result,
segmentation task blogs challenging humans well models.
Note similar annotation task chat disentanglement, Elsner Charniak (2010)
report average one-to-one score 53%. Since one-to-one score naive baselines (see
Section 5.1) much lower human agreement, metric differentiates human-like
performance baseline. Therefore, computing one-to-one correlation human
annotations legitimate evaluation models.

one-to-one
loc3

Mean
Email Blog
80.4
54.2
83.2
80.1

Max
Email Blog
100.0
84.1
100.0
94.0

Min
Email Blog
31.3
25.3
43.7
63.3

Table 4: Annotator agreement one-to-one loc3 two corpora.

analyze source disagreement annotation, find far
frequent reason one observed Elsner Charniak (2010)
chat disentanglement task; namely, annotators specific (i.e., fine) others
(i.e., coarse). determine level specificity annotation, similarly Elsner
Charniak, use information-theoretic concept entropy. consider topic
randomly picked sentence conversation random variable X, entropy H(X)
measures level details annotation. topics k length nk
conversation length N , compute H(X) follows:
552

fiTopic Segmentation Labeling Asynchronous Conversations

H(X) =

K
X
nk
k=1

N

log2

nk
N

(18)

K total number topics (or topical segments) conversation.
entropy gets higher number topics increases topics evenly distributed
conversation. corpora, varies 0 2.7 email conversations
1.58 3.42 blog conversations (Table 3). variations demonstrate differences
specificity different annotators, determine agreement general
structure. quantify this, use many-to-one metric proposed Elsner
Charniak (2010). maps source clusters single target cluster
gets highest overlap, computes total percentage overlap.
metric asymmetrical, used performance evaluation.18 However,
provides insights annotation specificity. example, one splits cluster
another annotator multiple sub-clusters then, many-to-one score fine
coarse annotation 100%. corpora, mapping fine (high-entropy) coarse
(low-entropy) annotation get high many-to-one score, average 95% email
conversations average 72% blog conversations (Table 5). suggests
finer annotations mostly scopic boundaries coarser ones.

many-to-one

Mean
Email Blog
94.9
72.3

Max
Email Blog
100
98.2

Min
Email Blog
61.1
51.4

Table 5: Annotator agreement many-to-one two corpora.

4.3.2 Metrics Topic Labeling
Recall extract keyphrases text topic labels. Traditionally keyphrase extraction evaluated using precision, recall F-measure based exact matches
extracted keyphrases human-assigned keyphrases (e.g., Mihalcea Tarau,
2004; Medelyan et al., 2009). However, noted approach based exact
matches underestimates performance (Turney, 2000). example, compared
reference keyphrase Game contents size, credible candidate keyphrase Game contents gets evaluated wrong metric. Therefore, recent studies (Zesch & Gurevych,
2009; Kim, Baldwin, & Kan, 2010a) suggest use n-gram-based metrics account
near-misses, similar ones used text summarization, e.g., ROUGE (Lin, 2004),
machine translation, e.g., BLEU (Papineni, Roukos, Ward, & Zhu, 2002).
Kim et al. (2010a) evaluated utility different n-gram-based metrics keyphrase
extraction showed metric call mutual-overlap (m-o), correlates
human judgments.19 Therefore, one metrics use evaluating topic
18. One easily optimize assigning different topic source sentences.
19. Kim et al. (2010a) call metric R-precision (R-p), different actual definition
R-p keyphrase evaluation given Zesch Gurevych (2009). Originally, R-p precision
measured number candidate keyphrases equals number gold keyphrases.

553

fiJoty, Carenini, & Ng

labeling models m-o. Given reference keyphrase pr length (in words) nr , candidate
keyphrase pc length nc , number overlapping (modulo stemming)
words pr pc , mutual-overlap formally defined as:
mutualoverlap(pr , pc ) =


max(nr , nc )

(19)

metric gives full credit exact matches morphological variants, partial credit two cases overlapping phrases: (i) candidate keyphrase includes
reference keyphrase, (ii) candidate keyphrase part reference
keyphrase. Notice m-o defined evaluates single candidate keyphrase
reference keyphrase. setting, single reference keyphrase (i.e., topic label)
topical cluster, mentioned before, may want models extract
top k keyphrases. Therefore, modify m-o evaluate set k candidate keyphrases Pc
reference keyphrase pr follows, calling weighted-mutual-overlap (w-m-o):
weightedmutualoverlap(pr , Pc ) =

k
X
i=1


S(pic )
max(nr , nic )

(20)

P
S(pic ) normalized score (i.e., S(pic ) satisfies 0 S(pic ) 1 ki=1 S(pic ) = 1)
i-th candidate phrase pic Pc . k = 1, metric equivalent m-o,
higher values k, takes sum k m-o scores, weighted normalized score.
w-m-o metric described considers word overlap ignores semantic relations (e.g., synonymy, hypernymy) words. However, annotators
writing topic descriptions, may use words directly conversation,
semantically related. example, given reference keyphrase meeting agenda,
lexical semantic variants like meeting schedule meeting plan treated
correct. Therefore, also consider generalization w-m-o incorporates lexical
semantics. define weighted-semantic-mutual-overlap (w-s-m-o) follows:

weightedsemanticmutualoverlap(pr , Pc ) =

k
X
i=1

P

tr pr

P

tc pic

(tr , tc )

max(nr , nic )

S(pic )

(21)

(tr , tc ) semantic similarity nouns tr tc . value (tr , tc )
0 1, 1 denotes notably high similarity 0 denotes little-to-none. Notice
that, since metric considers semantic similarity possible pairs nouns,
value measure greater 100% (when presented percentage). use
metrics (e.g., lin similarity, wup similarity) provided WordNet::Similarity package
(Pedersen, Patwardhan, & Michelizzi, 2004) computing WordNet-based similarity,
always choose frequent sense noun. results get similar across
similarity metrics. brevity, mention lin similarity article.
4.3.3 Metrics End-to-End Evaluation
like human annotators, end-to-end system takes asynchronous conversation
input, finds topical segments conversation, assigns short descriptions
554

fiTopic Segmentation Labeling Asynchronous Conversations

(topic labels) topical segments. would fairly easy compute agreement
topic labels based mutual overlaps, number topics topical segments
fixed across annotations given conversation. However, since different annotators
(system human) identify different number topics different clustering
sentences, measuring annotator (model human) agreement topic labels
trivial task. solve this, first map clusters one annotation (say A1 )
clusters another (say A2 ) optimal one-to-one mapping described previous
section. that, compute w-m-o w-s-m-o scores labels mapped
(or paired) clusters. Formally, li1 label cluster c1i A1 mapped
cluster c2j label lj2 A2 , compute w-m-o(li1 , lj2 ) w-s-m-o(li1 , lj2 ).
Table 6 reports human agreement w-m-o w-s-m-o two corpora. Similar
segmentation, get higher agreement labeling metrics email. Plausibly,
reasons remain same; length characteristics (e.g., informal, less focused)
blog conversations make annotators disagree more. However, note measures
computed based one-to-one mappings clusters may reflect
agreement one would get annotators asked label segments.

w-m-o
w-s-m-o

Mean
Email Blog
36.8
19.9
42.5
28.2

Max
Email Blog
100.0
54.2
107.3
60.8

Min
Email Blog
0.0
0.0
0.0
5.2

Table 6: Annotator agreement w-m-o w-s-m-o two corpora.

5. Experiments
section present experimental results. First, show performance
segmentation models. show performance topic labeling models based
manual segmentation. Finally, present performance end-to-end system.
5.1 Topic Segmentation Evaluation
section present experimental setup results segmentation task.
5.1.1 Experimental Setup Segmentation
ran six different topic segmentation models corpora presented Section 4.
first model graph-based unsupervised segmentation model presented Malioutov
Barzilay (2006). Since sequentiality constraint topic segmentation monolog
synchronous dialog hold asynchronous conversation, implement
model without constraint. Specifically, model (call M&B) constructs weighted
undirected graph G(V, E), nodes V represent sentences edge weights
w(x, y) represent cosine similarity (Equation 5) sentences x y.
finds topical segments optimizing normalized cut criterion (Equation 6). Thus,
M&B considers conversation globally, models lexical similarity.
555

fiJoty, Carenini, & Ng

five models LDA, LDA+FQG, LCSeg, LCSeg+FQG Supervised
model (SUP) described Section 3. tunable parameters different models
set based performance developement set. hyperparameters
LDA set default values (=50/K, =0.01) suggested Steyvers
Griffiths (2007).20 regularization strength LDA+FQG set 20.
parameters LCSeg set default values since setting delivers best
performance development set. fair comparison, set number
topics per conversation models. least two three annotators agree
topic number, set number, otherwise set floor value average topic
number. mean statistics six model annotations shown Table 7. Comparing
statistics human annotations Table 3, notice numbers
within bounds human annotations.21

Email

Blog

Topic number
Topic length
Topic density
Entropy
Topic number
Topic length
Topic density
Entropy

M&B
2.41
12.41
1.90
0.99
10.65
20.32
7.38
2.54

LDA
2.10
13.3
1.83
0.98
10.65
20.32
9.39
3.33

LDA+FQG
1.90
15.50
1.60
0.75
10.65
20.32
8.32
2.37

LCSeg
2.41
12.41
1.01
0.81
10.65
20.32
1.00
2.85

LCSeg+FQG
2.41
12.41
1.39
0.93
10.65
20.32
5.21
2.81

SUP
2.41
12.41
1.42
0.98
10.65
20.32
5.30
2.85

Table 7: Mean statistics different models annotation

also evaluate following baselines, useful model outperform.
different sentence conversation constitutes separate topic.
whole conversation constitutes single topic.
Speaker sentences participant constitute separate topic.
Blocks k (= 5, 10, 15, 20, 25, 30): consecutive group k sentences
temporal order conversation constitutes separate topic.
5.1.2 Results Segmentation
Table 8 presents human agreement agreement models human
annotators corpora. model annotation, measure agreement
three human annotations separately using metrics described Section 4.3.1, report
mean agreements. table, also show performance two best baselines
Speaker Blocks k.
20. performance LDA seem sensitive values .
21. Although topic numbers per conversation fixed different models, LDA LDA+FQG may
find less number topics (see Equation 3 4).

556

fiTopic Segmentation Labeling Asynchronous Conversations

Email

Blog

Mean 1-to-1
Max 1-to-1
Min 1-to-1
Mean loc3
Max loc3
Min loc3
Mean 1-to-1
Max 1-to-1
Min 1-to-1
Mean loc3
Max loc3
Min loc3

Baselines
Speaker Blocks M&B LDA
k
51.8
38.3
62.8
57.3
94.3
77.1 100.0 100.0
23.4
14.6
36.3
24.3
64.1
57.4
62.4
54.1
97.0
73.1 100.0 100.0
27.4
42.6
36.3
38.1
33.5
32.0
30.0
25.2
61.1
46.0
45.3
42.1
13.0
15.6
18.2
15.3
67.0
52.8
54.1
53.0
87.1
68.4
64.3
65.6
53.4
42.3
45.1
38.6

Models
LDA+ LCSeg LCSeg SUP
FQG
+FQG
61.5
62.2
69.3
72.3
100.0 100.0 100.0 100.0
24.0
33.1
38.0
42.4
60.6
72.0
72.7
75.8
100.0 100.0 100.0 100.0
38.4
40.7
40.6
40.4
28.0
36.6
46.7
48.5
56.3
53.6
67.4
66.1
16.1
23.7
26.6
28.4
55.4
56.5
75.1
77.2
67.1
76.0
89.0
96.4
46.3
43.1
56.7
63.2

Human

80.4
100.0
31.3
83.2
100.0
43.7
54.2
84.1
25.3
80.1
94.0
63.3

Table 8: Topic segmentation performance two best Baselines, Human Models.
Blocks k column, k = 5 email k = 20 blog.

baselines perform rather poorly. different worst baseline
mean one-to-one scores 0.05 0.10, mean loc3 scores 0.47 0.25
blog email corpus, respectively. Blocks 5 one best baselines email,
performs poorly blog mean one-to-one 0.19 mean loc3 0.54.
contrary, Blocks 20 one best baselines blog, performs poorly email.
intuitive since average number topics topic length blog conversations
(10.77 27.16) much higher email (2.5 12.6). optimal
conversations containing one topic, performance rapidly degrades
number topics increases. mean one-to-one scores 0.29 0.28 mean loc3
scores 0.53 0.54 blog email corpora, respectively. Speaker strongest
baseline domains.22 several cases beats under-performing models.
email corpus, one-to-one, generally models agree annotators
baselines do, less annotators agree other. observe
similar trend local metric loc3 , however metric, models fail beat
best baselines. Notice human agreement annotations quite low (see
Min scores), even lower mean agreement baselines. explained before,
due fact human annotations much fine-grained others.
blog corpus, agreement global metric (one-to-one) much lower
email corpus. reasons already explained Section 4.3.1. notice
similar trend metrics under-performing models fail beat baselines,
others perform better baselines, worse human annotators.
comparison among models reveals general pattern. probabilistic generative models LDA LDA+FQG perform disappointingly corpora. likely
explanation independence assumption made models computing
distribution topics sentence distributions words causes nearby
22. many anonymous authors blog corpus. treated separate author.

557

fiJoty, Carenini, & Ng

sentences (i.e., local context) excessively distributed topics. Another reason
could limited amount data available training. corpora, average
number sentences per blog conversation 220.55 per email conversation 26.3,
might sufficient LDA models (Murphy, 2012). compare performance LDA+FQG performance LDA, get significant improvement
LDA+FQG metrics corpora (p<0.01). regularization
FQG prevents local context excessively distributed topics.
unsupervised graph-based model M&B performs better LDA models
cases (i.e., except loc3 blog) (p < 0.001). However, performance still far
performance top performing models like LCSeg+FQG supervised model.
reason even though, constructing complete graph, method considers
conversation globally, models lexical similarity disregards important
features asynchronous conversation like fine conversation structure speaker.
Comparison LCSeg LDAs M&B reveals LCSeg general better
model. LCSeg outperforms LDA wide margin one-to-one two datasets
loc3 email (p < 0.001). difference LCSeg LDA loc3 blog also
significant p < 0.01. LCSeg also outperforms M&B cases (p < 0.01) except
one-to-one email. Since LCSeg sequential model extracts topics keeping
context intact. helps achieve high loc3 agreement shorter conversations like
email conversations. But, longer conversations like blog conversations, overdoes
(i.e., extracts larger chunks sentences topic segment) gets low loc3 agreement.
unsurprising look topic density Table 7 two datasets density
low blog corpus compared annotators well performing models.
Another reason superior performance LDAs M&B could term weighting
scheme. Unlike LDAs M&B, consider repetition, LCSeg also considers
tightly repetition happens. However, still large gap performance
LCSeg top performing models (LCSeg+FQG, supervised). explained
earlier, topics asynchronous conversation may change sequentially temporal
order sentences. topics interleaved LCSeg fails identify correctly.
Furthermore, LCSeg consider important features beyond lexical cohesion.
incorporate FQG LCSeg, get significant improvement one-to-one
corpora loc3 blog (p<0.0001). Even though improvement loc3
email significant, agreement quite high compared unsupervised
models. Overall, LCSeg+FQG best unsupervised model. supports claim
sentences connected reply-to relations FQG usually refer topic.
Finally, combine features graph-based supervised model (SUP
Table 8), get significant improvement LCSeg+FQG metrics across
domains (p<0.01). agreements achieved supervised model also much closer
human annotators. Beside features, improvement might also due
fact that, constructing complete graph, model considers relations
possible sentence pairs conversation, believe key requirement topic
segmentation asynchronous conversations.
558

fiTopic Segmentation Labeling Asynchronous Conversations

5.2 Topic Labeling Evaluation
section present experimental evaluation topic labeling models
models provided manual (or gold) segmentation. allows us judge
performance independently topic segmentation task.
5.2.1 Experimental Setup Topic Labeling
mentioned Section 4, email corpus, three annotators found 100, 77
92 topics (or topical segments) respectively (269 total), blog corpus,
found 251, 119 192 topics respectively (562 total). annotators wrote short
high-level description topic. descriptions serve reference topic labels
evaluation.23 goal topic labeling models automatically generate
informative descriptions topical segment. compare approach
two baselines. first baseline FreqBL ranks words according frequencies.
second baseline LeadBL, expressed equation 11, ranks words based
relevance leading sentences topical segment.
also compare model two state-of-the-art keyphrase extraction methods.
first one unsupervised general TextRank model proposed Mihalcea Tarau
(2004) (call M&T) incorporate conversation specific information.
second one supervised model Maui proposed Medelyan et al. (2009). Briefly, Maui
first extracts n-grams maximum length 3 candidate keyphrases.
bagged decision tree classifier filters candidates using nine different features. Due
lack labeled training data asynchronous conversations, train Maui humanannotated dataset released part SemEval-2010 task 5 automatic keyphrase
extraction scientific articles (Kim, Medelyan, Kan, & Baldwin, 2010b). dataset
contains 244 scientific papers ACM digital library, comes set authorassigned reader-assigned keyphrases. total number keyphrases assigned
244 articles authors readers 3705.
experimented two different versions biased random walk model
incorporates informative clues leading sentences. One, BiasRW, include
conversation-level phrase (Section 3.2.4), one BiasRW+, does.
parameter Uk , set leading sentences, empirically set first two sentences
bias parameter set 0.85 based development set.
experimented four different versions co-ranking framework depending
type random walk performed word co-occurrence graph (WCG)
whether model includes conversation-level phrases. Let CorGen denote
co-ranking model general random walk WCG, CorBias denote coranking model biased random walk WCG. two models include
conversation-level phrase CorGen+ CorBias+ do. coupling strength
co-occurrence window size empirically set 0.4 2, respectively, based
development set. dumping factor set default value 0.85.
Note models (except Maui) baselines follow preprocessing
post-processing (i.e., phrase generation redundancy checking) steps. value
23. Notice setting, topic segment one reference label compare with.
Therefore, show human agreement topic labeling task Table 9 10.

559

fiJoty, Carenini, & Ng

phrase generation set 25% total number words cluster,
redundancy checking set 0.35 based development set.
5.2.2 Results Topic Labeling
evaluate performance different models using metrics described Section
4.3.2. Table 9 10, respectively, show mean weighted-mutual-overlap (w-m-o)
weighted-semantic-mutual-overlap (w-s-m-o) scores percentage different models
different values k (i.e., number output labels) two corpora.
baselines proved strong, beating existing models almost every
case. tells us frequency words topic segment occurrence
leading sentences carry important information topic labeling. Generally speaking,
LeadBL better baseline email, blog FreqBL better LeadBL.
supervised model Maui worst performer metrics two corpora.
performance also consistently low across corpora particular value k.
possible explanation Maui trained domain (scientific articles),
rather different asynchronous conversations. Another reason may Maui
consider conversational features.
general random walk model M&T also delivers poor performance corpora,
failing beat baselines measures. indicates random walk model
based co-occurrence relations words sufficient finding topic
labels asynchronous conversations. needs consider conversation specific information.
incorporating clues leading sentences, biased random walk model
BiasRW improves performance significantly baselines metrics
values k two corpora (p<0.05). demonstrates usefulness considering
leading sentences information source topic labeling asynchronous conversation.

Baselines

Models

FreqBL
LeadBL
M&T
Maui
BiasRW
BiasRW+
CorGen
CorGen+
CorBias
CorBias+

k=1
Email Blog
22.86 19.05
22.41 18.17
15.87 18.23
10.48 10.03
24.77 20.83
24.91 23.65
17.60 20.76
18.32 22.44
24.84 20.96
25.13 23.83

k=2
Email Blog
17.47 16.17
18.94 15.95
12.68 14.31
9.86
9.56
19.78 17.28
20.36 19.69
15.32 17.64
15.86 19.65
19.88 17.73
20.20 19.97

k=3
Email Blog
14.96 13.83
15.92 13.75
10.33 12.15
9.03
9.23
17.38 15.06
18.09 17.76
15.14 15.78
15.46 18.01
17.61 16.22
18.21 18.33

k=4
Email Blog
13.17 13.45
14.36 12.61
9.63
11.38
8.71
8.90
16.24 14.53
16.20 16.78
14.23 15.03
14.89 16.90
16.99 15.64
17.15 17.28

k=5
Email Blog
12.06 12.59
13.76 11.93
9.07
11.03
8.50
8.53
15.80 14.26
15.78 15.86
14.08 14.75
14.45 16.13
16.81 15.38
16.90 16.55

Table 9: Mean weighted-mutual-overlap (w-m-o) scores different values k two corpora.

general co-ranking model CorGen, incorporating conversation structure,
outperforms baselines metrics k blog (p<0.05), fails
many cases email. blog, also significant difference BiasRW
CorGen w-m-o k (Table 9), CorGen outperforms BiasRW w-s-m-o (Table
10) higher values k (2,3,4,5) (p<0.05). hand, email, BiasRW always
outperforms CorGen metrics k (p<0.05). conclude that, blog,
560

fiTopic Segmentation Labeling Asynchronous Conversations

exploiting conversation structure seems beneficial leading sentences,
whereas email, observe opposite. reason could topic segments
blog much longer email (average length 27.16 vs. 12.6). Therefore,
FQGs blog segments generally larger capture information
FQGs email segments. Besides, email discussions focused blog discussions.
leading sentences email segments carry informative clues blog
segments. also confirmed Figure 9, leading sentences email cover
human-authored words blog.

Baselines

Models

FreqBL
Lead-BL
M&T
Maui
BiasRW
BiasRW+
CorGen
CorGen+
CorBias
CorBias+

k=1
Email Blog
23.36 23.52
24.99 21.19
18.71 22.08
14.79 14.14
28.87 24.63
27.96 24.51
23.66 24.69
23.50 24.30
28.44 25.66
27.97 25.26

k=2
Email Blog
20.50 21.03
21.69 20.61
16.25 19.59
13.76 13.67
24.76 22.51
24.71 23.05
21.97 23.83
22.09 24.35
26.39 24.15
26.34 24.19

k=3
Email Blog
19.82 20.18
20.40 19.49
14.62 17.91
13.03 12.87
22.48 21.36
22.56 22.88
21.51 22.86
21.96 23.89
24.47 23.18
24.69 23.60

k=4
Email Blog
18.47 19.58
19.57 18.98
14.29 17.27
12.69 12.10
21.67 20.95
21.19 22.08
20.98 22.37
21.36 23.42
23.70 22.76
23.65 23.44

k=5
Email Blog
17.81 19.27
19.17 18.71
14.06 16.92
11.73 11.52
21.28 20.78
20.82 21.73
20.44 22.22
20.90 23.00
23.56 22.67
23.23 23.20

Table 10: Mean weighted-semantic-mutual-overlap scores different values k two corpora.

combining two forms conversation specific information single model,
CorBias delivers improved performance CorGen BiasRW metrics.
email, CorBias significantly better CorGen k metrics (p<0.01).
blog, CorBias gets significant improvement BiasRW higher values k (3, 4, 5)
metrics (p<0.05). two sources information complementary help
overcome domain-specific limitations respective models. Therefore, one
exploit information sources build generic domain-independent system.
include conversation-level phrases (+ versions), get significant improvement w-m-o blog (p<0.01), email. may blog conversations many topical segments email conversations (average topic number
10.77 vs. 2.5). Thus, little information label topical segment outside segment email conversations. However, note including conversation-level
phrases hurt performance significantly case.
analyze performance, Table 11 shows mean w-m-o scores
best k output labels considered. allows us judge models ability
generate best label top k list. results much clearer here. Generally
speaking, among models include conversation-level phrases, CorBias
best model, including conversation-level phrases improves performance further.
Table 12 shows examples test set system-generated (i.e.,
CorBias+) labels similar human-authored ones. also many cases
like ones Table 13, system-generated labels reasonable, although
get low w-m-o w-s-m-o scores compared human-authored labels.
561

fiJoty, Carenini, & Ng

Baselines

Models

FreqBL
LeadBL
M&T
Maui
BiasRW
BiasRW+
CorGen
CorGen+
CorBias
CorBias+

k=2
Email Blog
27.02 23.69
28.72 21.69
21.45 21.70
14.00 14.85
29.34 24.92
29.47 25.88
23.45 25.05
24.56 25.87
28.98 25.27
29.76 25.96

k=3
Email Blog
29.79 24.29
30.86 23.14
23.12 23.18
15.57 17.33
31.42 25.18
31.43 27.38
28.44 25.72
28.46 26.61
30.90 26.41
31.04 27.65

k=4
Email Blog
31.12 24.88
31.99 24.19
25.23 23.82
17.15 19.23
32.58 25.89
32.96 28.47
30.10 26.40
31.14 27.63
32.24 27.14
33.61 28.63

k=5
Email Blog
31.25 25.58
31.99 25.33
25.45 24.07
18.40 20.03
32.97 26.64
33.87 29.17
30.33 27.10
32.91 28.50
33.25 27.65
35.35 29.58

Table 11: Mean weighted-mutual-overlap (w-m-o) scores best k labels considered.

Email

Blog

Human-authored
Details Bristol meeting
Nashville conference
Meeting agenda
Design guidelines
Contact Steven
faster light (FTL) travel
Dr. Paul Laviolette
Vietnam Iraq warfare
Pulsars
Linux distributions

System-generated (top 5)
Bristol, face2face meeting, England, October
Nashville conference, Courseware developers, mid October, event
detailed agenda, main point, meetings, revision, wcag meetings
general rule, design guidelines, accessible design, absolutes, forbid
Steven Pemberton, contact, charter, status, schedule w3c
FTL travel, need FTL, limited FTL, FTL drives, long FTL
Dr. Paul Laviolette, bang theory, systems theory, extraterrestial beacons, laugh
Vietnam war, incapable guerrilla war, war information, war ii, vietnamese war
mean pulsars, pulsars slow time, long pulsars, relative pulsars, set pulsars
linux distro, linux support, major linux, viable linux

Table 12: Examples Human-authored labels System-generated labels.

Human-authored
Meeting time place
Archaeology
Bio Al
Budget Constraints
Food choice

System-generated
October, mid October, timing, w3c timing issues, Ottawa
religious site, burial site, ritual site, barrows tomb
Al Gilman, standards reformer, repair interest group, ER IG, ER teams
budget, notice, costs, smaller companies, travel
roast turkey breast, default choices, small number, vegetable rataouille, lunch

Table 13: Examples System-generated labels reasonable get low scores.

562

fiTopic Segmentation Labeling Asynchronous Conversations

human-authored labels corpora abstractive
nature. Annotators often write labels rather simply copying keyphrases
text. so, rely expertise general world knowledge
may go beyond contents conversation. fact, although annotators reuse many
words conversation, 9.81% human-authored labels blog 12.74%
human-authored labels email appear verbatim respective conversations.
Generating human-like labels require deeper understanding text robust
textual inference, extractive approach provide useful input.
5.3 Full System Evaluation
section present performance end-to-end system. first segment
given asynchronous conversation using best topic segmenter (the supervised model),
feed output best topic labeler (the CorBias+ model). Table 14 presents
human agreement agreement system human annotators based
best k outputs. system annotation measure agreement w-m-o
w-s-m-o three human annotations using method described Section 4.3.3.

Email

Blog

Mean w-m-o
Max w-m-o
Mean w-s-m-o
Max w-s-m-o
Mean w-m-o
Max w-m-o
Mean w-s-m-o
Max w-s-m-o

k=1
19.19
100.0
24.98
108.43
9.71
26.67
15.46
47.10

k=2
23.62
100.0
32.08
108.43
11.71
26.67
19.77
47.28

System
k=3
k=4
26.19
27.06
100.0
100.0
34.63
36.92
108.43 108.43
14.55
15.83
35.00
35.00
23.35
25.57
47.28
48.54

Human
k=5
28.06
100.0
38.95
108.43
16.72
35.00
26.23
48.54

36.84
100.0
42.54
107.31
19.97
54.17
28.22
60.76

Table 14: Performance end-to-end system human agreement.

Notice email, system gets 100% agreement w-m-o metric conversations. However, substantial gap mean max w-m-o scores.
Similarly, w-s-m-o, system achieves maximum 108% agreement, mean
varies 25% 39% depending different values k. blog, w-m-o w-s-m-o
scores much lower. maximum scores achieved w-m-o w-s-m-o metrics blog
35% 49% (for k = 5), respectively. mean w-m-o score varies 10%
17%, mean w-s-m-o score varies 15% 28% different values k.
demonstrates difficulties topic segmentation labeling tasks blog conversations.
Comparing Table 11, notice inaccuracies topic segmenter affects
overall performance. However, results encouraging. Even though lower
values k substantial gap results human agreement,
value k increases, results get closer human agreement, especially w-s-m-o.
563

fiJoty, Carenini, & Ng

6. Conclusion Future Direction
work presents two new corpora email blog conversations annotated topics,
which, along proposed metrics, allow researchers evaluate work quantitatively. also present complete computational framework topic segmentation
labeling asynchronous conversation.24 approach extends state-of-the-art methods
considering fine-grained structure asynchronous conversation, along
conversational features. applying recent graph-based methods NLP
min-cut random walk paragraph, sentence word graphs.
topic segmentation, extend LDA LCSeg unsupervised models incorporate fine-grained conversational structure (the Fragment Quotation Graph (FQG)),
generating two novel unsupervised models LDA+FQG LCSeg+FQG. addition
that, also present novel graph-theoretic supervised segmentation model combines
lexical, conversational topic features. topic labeling, propose two novel random
walk models extract representative keyphrases text, respectively
capturing conversation specific clues two different sources: leading sentences
fine conversational structure (i.e., FQG).
Experimental results topic segmentation task demonstrate LDA
LCSeg benefit significantly extended consider FQG, LCSeg+FQG
best unsupervised model. comparison supervised segmentation model
unsupervised models shows supervised method outperforms unsupervised ones even using labeled conversations, best segmentation model
overall. outputs LCSeg+FQG supervised model also highly correlated
human annotations local global metrics. experiment topic
labeling task reveals random walk models perform better exploit
conversation specific clues best results achieved sources clues
exploited. evaluation complete end-to-end system also shows promising results
compared human performance.
work extended many ways. Given human-authored
labels abstractive nature, plan extend labeling framework generate
abstract human-like labels could better synthesize information expressed
topic segment. promising approach would rely sophisticated methods
information extraction, combined semantics (e.g., phrase entailment) datato-text generation techniques. Another interesting venue future work perform
extrinsic evaluation methods. Instead testing respect human
gold standard, would extremely interesting see effective used
support NLP tasks, summarization conversation visualization.
also interested future transfer approach similar domains domain
adaptation methods. plan work synchronous asynchronous domains.

24. annotated corpora, annotation manual source code made publicly available
www.cs.ubc.ca/labs/lci/bc3.html

564

fiTopic Segmentation Labeling Asynchronous Conversations

Bibliographic Note
Portions work previously published two conference proceedings (Joty et al.,
2010, 2011). article significantly extends previous work several ways,
notably: (i) complete topic modeling pipeline presenting novel topic labeling
framework (Section 3.2), (ii) propose new set metrics topic labeling task
(Section 5.2), (iii) present new annotated corpus blog conversations, show
topic segmentation labeling models perform new dataset (Section 4 5),
(iv) demonstrate performance end-to-end system (Section 5.3).

Acknowledgments
work conducted University British Columbia. acknowledge
funding support NSERC Canada Graduate Scholarship (CGS-D), NSERC BIN Strategic
Network NSERC discovery grant. grateful annotators great
effort. Many thanks Gabriel Murray, Jackie Cheung, Yashar Mehdad, Shima Gerani,
Kelsey Allen anonymous reviewers thoughtful suggestions comments.

Appendix A. Metrics Topic Segmentation
A.1 One-to-One Metric
Consider two different annotations conversation 10 sentences (denoted colored boxes) Figure 11(a). annotation, topics distinguished
different colors. example, model output four topics, whereas human annotation three topics. compute one-to-one accuracy, take model output
map segments optimally (by computing optimal max-weight bipartite matching)
segments gold-standard human annotation. example, red segment
model output mapped green segment human annotation. transform
model output based mapping compute percentage overlap one-toone accuracy. example, seven ten sentences overlap, therefore, one-to-one
accuracy 70%.
A.2 Lock Metric
Consider model output (at left column) human annotation (at
right column) conversation 5 sentences (denoted colored boxes)
Figure 12. Similar Figure 11, topics annotation distinguished using
different colors. Suppose want measure loc3 score fifth sentence (marked
yellow arrows bottom two annotations). annotation, look
previous 3 sentences transform based whether different
topics. example, model output one previous three sentences (red),
human annotation two previous three sentences (green),
compared sentence consideration. transformed annotations,
topics denoted gray boxes different topics denoted black boxes.
565

fiJoty, Carenini, & Ng

One-to-One
accuracy

Model Human
output annotation

Transform model
output according
optimal mapping

70%

Transformed Human
model output annotation

Model
output
(b)

(a)

Figure 11: Computing one-to-one accuracy.

566

fiTopic Segmentation Labeling Asynchronous Conversations

compute loc3 measuring overlap different judgments 3-sentence
window. example, two three overlap, therefore, loc3 agreement 66.6%.

Loc3 accuracy

66.6%

different?

Model
Output


different?

Transformed
human annotation

Transformed
model output

Human
annotation

Figure 12: Computing loc3 accuracy.

References
Allan, J. (2002). Topic Detection Tracking: Event-based Information Organization, pp.
116. Kluwer Academic Publishers, Norwell, MA, USA.
Allan, J., Wade, C., & Bolivar, A. (2003). Retrieval Novelty Detection Sentence
Level. Proceedings 26th annual international ACM SIGIR conference
Research development informaion retrieval, SIGIR 03, pp. 314321, Toronto,
Canada. ACM.
Andrzejewski, D., Zhu, X., & Craven, M. (2009). Incorporating domain knowledge topic
modeling via dirichlet forest priors. Proceedings 26th Annual International
567

fiJoty, Carenini, & Ng

Conference Machine Learning, ICML 09, pp. 2532, Montreal, Quebec, Canada.
ACM.
Aumayr, E., Chan, J., & Hayes, C. (2011). Reconstruction threaded conversations
online discussion forums. Proceedings Fifth International AAAI Conference
Weblogs Social Media (ICWSM-11), pp. 2633.
Bangalore, S., Di Fabbrizio, G., & Stent, A. (2006). Learning Structure Task-Driven
Human-Human Dialogs. Proceedings 21st International Conference Computational Linguistics 44th annual meeting Association Computational Linguistics, pp. 201208. ACL.
Bansal, N., Blum, A., & Chawla, S. (2002). Correlation clustering. Proceedings 43rd
Symposium Foundations Computer Science, FOCS 02, pp. 238, Washington,
DC, USA. IEEE Computer Society.
Baron, N. S. (2008). Always on: Language online mobile world. Oxford ; New
York : Oxford University Press.
Barzilay, R., & Lee, L. (2004). Catching drift: Probabilistic content models, applications generation summarization. HLT-NAACL.
Beeferman, D., Berger, A., & Lafferty, J. (1999). Statistical models text segmentation.
Machine Learning, Vol. 34, pp. 177210, Hingham, MA, USA. Kluwer Academic
Publishers.
Blei, D., Ng, A., & Jordan, M. (2003). Latent Dirichlet Allocation. Journal Machine
Learning Research, 3, 9931022.
Blei, D. M., & Moreno, P. J. (2001). Topic segmentation aspect hidden markov
model. Proceedings 24th annual international ACM SIGIR conference
Research development information retrieval, SIGIR 01, pp. 343348, New York,
NY, USA. ACM.
Boyd-Graber, J., & Blei, D. M. (2008). Syntactic topic models. Neural Information
Processing Systems.
Breiman, L. (1996). Bagging predictors. Machine Learning, 24 (2), 123140.
Carbonell, J., & Goldstein, J. (1998). use MMR, diversity-based reranking
reordering documents producing summaries. Proceedings 21st annual
international ACM SIGIR conference Research development information
retrieval, pp. 335336, Melbourne, Australia. ACM.
Carenini, G., Murray, G., & Ng, R. (2011). Methods mining summarizing text
conversations, Vol. 3. Morgan Claypool.
Carenini, G., Ng, R. T., & Zhou, X. (2007). Summarizing Email Conversations Clue
Words. Proceedings 16th international conference World Wide Web, pp.
91100, Banff, Canada. ACM.
Carenini, G., Ng, R. T., & Zhou, X. (2008). Summarizing Emails Conversational
Cohesion Subjectivity. Proceedings 46th Annual Meeting Association Computational Linguistics: Human Language Technologies, pp. 353361,
OH. ACL.
568

fiTopic Segmentation Labeling Asynchronous Conversations

Choi, F. Y. Y., Hastings, P. W., & Moore, J. (2001). Latent semantic analysis text
segmentation. Proceedings 2001 Conference Empirical Methods Natural
Language Processing, EMNLP01, pp. 109117, Pittsburgh, USA. ACL.
Cortes, C., & Vapnik, V. N. (1995). Support Vector Networks. Machine Learning, 20,
273297.
Crystal, D. (2001). Language Internet. Cambridge University Press.
Dias, G., Alves, E., & Lopes, J. G. P. (2007). Topic Segmentation Algorithms Text
Summarization Passage Retrieval: Exhaustive Evaluation. Proceedings
22nd national conference Artificial intelligence - Volume 2, pp. 13341339,
Vancouver, BC, Canada. AAAI.
Eisenstein, J. (2009). Hierarchical text segmentation multi-scale lexical cohesion.
Proceedings Human Language Technologies: 2009 Annual Conference
North American Chapter Association Computational Linguistics, NAACL
09, pp. 353361, Stroudsburg, PA, USA. Association Computational Linguistics.
Eisenstein, J., & Barzilay, R. (2008). Bayesian unsupervised topic segmentation. Proceedings Conference Empirical Methods Natural Language Processing, EMNLP
08, pp. 334343, Honolulu, Hawaii. Association Computational Linguistics.
Elsner, M., & Charniak, E. (2010). Disentangling chat. Computational Linguistics, 36,
389409.
Elsner, M., & Charniak, E. (2011). Disentangling chat local coherence models. Proceedings 49th Annual Meeting Association Computational Linguistics:
Human Language Technologies - Volume 1, HLT 11, pp. 11791189, Stroudsburg, PA,
USA. Association Computational Linguistics.
Galley, M., McKeown, K., Fosler-Lussier, E., & Jing, H. (2003). Discourse segmentation
multi-party conversation. Proceedings 41st Annual Meeting Association
Computational Linguistics - Volume 1, ACL 03, pp. 562569, Sapporo, Japan.
ACL.
Griffiths, T. L., Steyvers, M., Blei, D. M., & Tenenbaum, J. B. (2005). Integrating topics
syntax. Advances Neural Information Processing Systems, pp. 537544. MIT
Press.
Harabagiu, S., & Lacatusu, F. (2005). Topic Themes Multi-document Summarization.
Proceedings 28th annual international ACM SIGIR conference Research
development information retrieval, pp. 202209, Salvador, Brazil. ACM.
Hearst, M. A. (1997). TextTiling: segmenting text multi-paragraph subtopic passages.
Computational Linguistics, 23 (1), 3364.
Hsueh, P., Moore, J. D., & Renals, S. (2006). Automatic segmentation multiparty dialogue. Proceedings 11th Conference European Chapter
Association Computational Linguistics, EACL06, Trento, Italy. ACL.
Hulth, A. (2003). Improved automatic keyword extraction given linguistic knowledge. Proceedings 2003 conference Empirical methods natural language
processing, EMNLP 03, pp. 216223. Association Computational Linguistics.
569

fiJoty, Carenini, & Ng

Janin, A., Baron, D., Edwards, J., Ellis, D., Gelbart, D., Morgan, N., Peskin, B., Pfau, T.,
Shriberg, E., Stolcke, A., & Wooters, C. (2003). ICSI Meeting Corpus. Proceedings IEEE International Conference Acoustics, Speech, Signal Processing
(ICASSP-03), pp. 364367.
Joty, S., Carenini, G., & Lin, C. (2011). Unsupervised modeling dialog acts asynchronous conversations. Proceedings twenty second International Joint Conference Artificial Intelligence (IJCAI), Barcelona.
Joty, S., Carenini, G., Murray, G., & Ng, R. (2010). Exploiting conversation structure
unsupervised topic segmentation Emails. Proceedings conference
Empirical Methods Natural Language Processing, EMNLP10, pp. 388398, Massachusetts, USA. ACL.
Joty, S., Carenini, G., Murray, G., & Ng, R. (2011). Supervised topic segmentation Email
conversations. Proceedings Fifth International AAAI Conference Weblogs
Social Media, ICWSM11, pp. 530533, Barcelona, Spain. AAAI.
Kim, S., Baldwin, T., & Kan, M. (2010a). Evaluating n-gram based evaluation metrics
automatic keyphrase extraction. Proceedings 23rd International Conference
Computational Linguistics, COLING10, pp. 572580, Beijing, China. ACL.
Kim, S. N., Medelyan, O., Kan, M.-Y., & Baldwin, T. (2010b). Semeval-2010 task 5 :
Automatic keyphrase extraction scientific articles. Proceedings 5th
International Workshop Semantic Evaluation, pp. 2126, Uppsala, Sweden. Association Computational Linguistics.
Kleinbauer, T., Becker, S., & Becker, T. (2007). Combining Multiple Information Layers
Automatic Generation Indicative Meeting Abstracts. Proceedings
Eleventh European Workshop Natural Language Generation, ENLG07, pp. 151
154, Stroudsburg, PA, USA. Association Computational Linguistics.
Lau, J., Grieser, K., Newman, D., & Baldwin, T. (2011). Automatic Labelling Topic
Models. Proceedings 49th annual meeting Association Computational
Linguistics, pp. 15361545, Portland, USA. ACL.
Lin, C.-Y. (2004). ROUGE: package automatic evaluation summaries. Proceedings
Workshop Text Summarization Branches Out, pp. 7481, Barcelona.
Liu, S., Zhou, M. X., Pan, S., Song, Y., Qian, W., Cai, W., & Lian, X. (2012). TIARA:
interactive, topic-based visual text summarization analysis. ACM Trans. Intell.
Syst. Technol., 3 (2), 25:125:28.
Malioutov, I., & Barzilay, R. (2006). Minimum cut model spoken lecture segmentation.
Proceedings 21st International Conference Computational Linguistics
44th annual meeting Association Computational Linguistics, ACL-44,
pp. 2532, Sydney, Australia. Association Computational Linguistics.
Mayfield, E., Adamson, D., & Rose, C. P. (2012). Hierarchical conversation structure prediction multi-party chat. Proceedings 13th Annual Meeting Special
Interest Group Discourse Dialogue, SIGDIAL 12, pp. 6069, Stroudsburg, PA,
USA. Association Computational Linguistics.
570

fiTopic Segmentation Labeling Asynchronous Conversations

Medelyan, O. (2009). Human-competitive automatic topic indexing. Ph.D. thesis,
University Waikato, Hamilton, New Zealand.
Medelyan, O., Frank, E., & Witten, I. H. (2009). Human-competitive tagging using automatic keyphrase extraction. Proceedings 2009 Conference Empirical
Methods Natural Language Processing, EMNLP09, pp. 13181327, Singapore. Association Computational Linguistics.
Mei, Q., Shen, X., & Zhai, C. (2007). Automatic labeling Multinomial topic models.
Proceedings 13th ACM SIGKDD international conference Knowledge
discovery data mining, pp. 490499, California, USA. ACM.
Mihalcea, R., & Radev, D. (2011). Graph-based natural language processing information
retrieval. Cambridge University Press.
Mihalcea, R., & Tarau, P. (2004). Textrank: Bringing order text. Proceedings
2004 Conference Empirical Methods Natural Language Processing, EMNLP04,
pp. 404411, Barcelona, Spain.
Minka, T. (1999). dirichlet-tree distribution. Tech. rep., Justsystem Pittsburgh Research Center.
Morris, J., & Hirst, G. (1991). Lexical cohesion computed thesaural relations
indicator structure text. Computational Linguistics, 17 (1), 2148.
Murphy, K. (2012). Machine Learning Probabilistic Perspective. MIT Press.
Nguyen, V.-A., Boyd-Graber, J., & Resnik, P. (2012). Sits: hierarchical nonparametric
model using speaker identity topic segmentation multiparty conversations.
Proceedings 50th Annual Meeting Association Computational Linguistics: Long Papers - Volume 1, ACL 12, pp. 7887, Stroudsburg, PA, USA. Association
Computational Linguistics.
Page, L., Brin, S., Motwani, R., & Winograd, T. (1999). pagerank citation ranking:
Bringing order web.. Technical report 1999-66.
Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: method automatic
evaluation machine translation. Proceedings 40th Annual Meeting
Association Computational Linguistics, ACL02, pp. 311318, Philadelphia, Pennsylvania. Association Computational Linguistics.
Passonneau, R. J., & Litman, D. J. (1997). Discourse segmentation human automated means. Computational Linguistics, 23 (1), 103139.
Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet::Similarity - Measuring
Relatedness Concepts. Proceedings Fifth Annual Meeting North
American Chapter Association Computational Linguistics (NAACL-04),
pp. 3841, Boston, MA.
Pevzner, L., & Hearst, M. A. (2002). critique improvement evaluation metric
text segmentation. Computational Linguistics, 28 (1), 1936.
Purver, M. (2011). Topic segmentation. Tur, G., & de Mori, R. (Eds.), Spoken Language
Understanding: Systems Extracting Semantic Information Speech, pp. 291
317. Wiley.
571

fiJoty, Carenini, & Ng

Purver, M., Kording, K. P., Griffiths, T. L., & Tenenbaum, J. B. (2006). Unsupervised
topic modelling multi-party spoken discourse. Proceedings ACL06, pp.
1724, Sydney, Australia. ACL.
Sacks, H., Schegloff, A., & Jefferson, G. (1974). simplest systematics organization
turn-taking conversation. Language, 50, 696735.
Salton, G., & McGill, M. J. (1986). Introduction Modern Information Retrieval. McGrawHill, Inc., New York, NY, USA.
Seneta, E. (1981). Non-negative Matrices Markov Chains. Springer-Verlag.
Shi, J., & Malik, J. (2000). Normalized cuts image segmentation. IEEE Trans. Pattern
Anal. Mach. Intell., 22 (8), 888905.
Soon, W. M., Ng, H. T., & Lim, D. C. Y. (2001). machine learning approach coreference
resolution noun phrases. Computational Linguistics, 27 (4), 521544.
Steyvers, M., & Griffiths, T. (2007). Latent Semantic Analysis: Road Meaning, chap.
Probabilistic topic models. Laurence Erlbaum.
Turney, P. D. (2000). Learning algorithms keyphrase extraction. Information Retrieval,
2 (4), 303336.
Ulrich, J., Murray, G., & Carenini, G. (2008). publicly available annotated corpus
supervised email summarization. EMAIL-2008 Workshop, pp. 428435. AAAI.
Verna, P. (2010). blogosphere: Colliding social mainstream media. eMarketer.
Wallach, H. M. (2006). Topic modeling: beyond bag-of-words. Proceedings 23rd
international conference Machine learning, ICML 06, pp. 977984, Pittsburgh,
Pennsylvania. ACM.
Wang, H., Wang, C., Zhai, C., & Han, J. (2011). Learning online discussion structures
conditional random fields. Proceedings 34th international ACM SIGIR
conference Research development Information Retrieval, SIGIR 11, pp.
435444, Beijing, China. ACM.
Wang, L., & Oard, D. W. (2009). Context-based message expansion disentanglement
interleaved text conversations. Proceedings Human Language Technologies:
2009 Annual Conference North American Chapter Association Computational Linguistics, NAACL 09, pp. 200208, Stroudsburg, PA, USA. Association
Computational Linguistics.
Zesch, T., & Gurevych, I. (2009). Approximate matching evaluating keyphrase extraction. Proceedings 7th International Conference Recent Advances
Natural Language Processing, RANLP09, pp. 484489, Borovets, Bulgaria.
Zhao, W. X., Jiang, J., He, J., Song, Y., Achananuparp, P., Lim, E.-P., & Li, X. (2011a).
Topical keyphrase extraction twitter. Proceedings 49th Annual Meeting Association Computational Linguistics: Human Language Technologies
- Volume 1, HLT 11, pp. 379388, Stroudsburg, PA, USA. Association Computational Linguistics.
572

fiTopic Segmentation Labeling Asynchronous Conversations

Zhao, W. X., Jiang, J., Weng, J., He, J., Lim, E.-P., Yan, H., & Li, X. (2011b). Comparing
twitter traditional media using topic models. Proceedings 33rd European conference Advances information retrieval, ECIR11, pp. 338349, Berlin,
Heidelberg. Springer-Verlag.
Zhou, D., Orshanskiy, S. A., Zha, H., & Giles, C. L. (2007). Co-ranking authors
documents heterogeneous network. Proceedings 2007 Seventh IEEE
International Conference Data Mining, ICDM 07, pp. 739744, Washington, DC,
USA. IEEE Computer Society.

573

fiJournal Artificial Intelligence Research 47 (2013) 649-695

Submitted 02/13; published 08/13

Protecting Privacy Distributed Computation
Multi-agent Decision Making
Thomas Leaute
Boi Faltings

thomas.leaute@a3.epfl.ch
boi.faltings@epfl.ch

Ecole Polytechnique Federale de Lausanne (EPFL)
Artificial Intelligence Laboratory (LIA)
Station 14
CH-1015 Lausanne, Switzerland

Abstract
large-scale theft data corporate servers becoming increasingly common,
becomes interesting examine alternatives paradigm centralizing sensitive data
large databases. Instead, one could use cryptography distributed computation
sensitive data supplied processed encrypted form, final
result made known. paper, examine paradigm used
implement constraint satisfaction, technique solve broad class AI problems
resource allocation, planning, scheduling, diagnosis. previous work
privacy constraint satisfaction attempted protect specific types information,
particular feasibility particular combinations decisions. formalize
extend restricted notions privacy introducing four types private information,
including feasibility decisions final decisions made, also identities
participants topology problem. present distributed algorithms
allow computing solutions constraint satisfaction problems maintaining four
types privacy. formally prove privacy properties algorithms, show
experiments compare respective performance benchmark problems.

1. Introduction
Protecting privacy information becoming crucial concern many users
increasingly ubiquitous Information Communication Technologies. Companies invest
lot effort keeping secret internal costs future development strategies
actors market, importantly competitors. Individuals also
need privacy personal information: instance, carelessly disclosing ones
activity schedule location might reveal burglars opportunities break ones home.
hand, accessing using private information often necessary solve
problems depend data. context supply chain management, companies
need exchange information contractors subcontractors quantities
goods must produced, price. scheduling meetings various
events friends co-workers, individuals confronted challenge taking
coordinated scheduling decisions, protecting respective availability schedules.
Artificial Intelligence crucial tool help people make better decisions
privacy concerns, delegating part decision problem personal intelligent
agents executing carefully chosen algorithms far complex performed
2013 AI Access Foundation. rights reserved.

fiLeaute & Faltings

human alone. particular, framework Constraint Satisfaction Problems
(CSPs) core AI technology successfully applied many decision-making
problems, configuration scheduling, solving strategic games. show
distributed AI algorithms used solve CSPs, providing strong guarantees
privacy problem knowledge, use techniques borrowed
cryptography. makes possible solve coordination problems depend secret
data, without reveal data parties. hand, distributed,
encrypted computation involving message exchange cost terms performance,
suitable tradeoff privacy scalability must found.
1.1 Motivating Examples
paper, present set novel, privacy-protecting algorithms Distributed Constraint Satisfaction Problems (DisCSPs), wide class multi-agent decision-making problems applications many problems configuration, scheduling, planning, design
diagnosis. consider three examples illustrate privacy requirements might
arise: meeting scheduling, airport slot allocation, computing game equilibria.
meeting scheduling problem (Maheswaran, Tambe, Bowring, Pearce, & Varakantham, 2004), number meetings need scheduled, involving possibly overlapping sets
participants. Taking account respective availability constraints, participants
given meeting must agree time meeting. One given participant
involved multiple meetings, creates constraints meetings. problem class, participants usually want protect privacy respective availability
schedules, well lists meetings involved in.
Another problem class airport slot allocation (Rassenti, Smith, & Bulfin, 1982),
airlines express interests combinations takeoff landing time slots airports, corresponding possible travel routes aircraft. end goal airports
efficiently allocate slots airlines, point view airlines crucial
combinations slots interested remain private, indicate
routes intend fly, sensitive strategic information want hide
competitors.
Finally, consider general class one-shot strategic games, party game
(Singh, Soni, & Wellman, 2004): players invited party, must decide whether
attend, based respective intrinsic costs attendance, whether people
like dislike also choose attend. Players would best play strategies form
Nash equilibrium, single player better deviating chosen
strategy. problem computing equilibrium typical example multiagent decision-making problem, privacy issue: players necessarily want
reveal attendance costs, whether like dislike another invitee.
1.2 Four Types Private Information
seen previous examples, information participants would like
keep private differ nature; propose classify four privacy types.
briefly introduce illustrate here; formal definitions given Section 2.2.1.
650

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

1. Agent privacy relates identities participants. Consider instance
CEO wants schedule two meetings respectively journalist
another companys CEO. Revealing journalist CEOs involvement
decision-making problem could leak companies plans merge.
case agent privacy considered critical.
2. Topology privacy covers information presence constraints.
type critical information airline companies want keep secret airport
slot allocation problem: presence constraint airline specific
airport reveals airlines strategic plans offer flights airport.
3. Constraint privacy nature constraints. covers instance
participants availability schedules meeting scheduling problem, and,
party game, whether player likes dislikes invitees.
4. Decision privacy solution eventually chosen problem.
Depending problem class, type privacy may may relevant.
meeting scheduling problem, time chosen meeting necessarily
revealed participants meeting; however desirable hide
information non-attendees.
Like previous work privacy DisCSP, assume participants honest,
curious (Goldreich, 2009), honestly follow algorithm, interested
learning much possible agents private information based messages exchanged. Note honesty assumption mean agents
assumed faithfully report true constraints algorithm; may tempted
strategize reporting slightly different constraints, hoping would lead algorithm select solution problem deem preferable them. issue
incentive-compatibility addressed related work Petcu, Faltings,
Parkes (2008), orthogonal issue privacy addressed paper. Furthermore, agent would take risk reporting constraints different true constraints:
reporting relaxed constraints could yield solution violates true constraints
would therefore viable, reporting tighter constraints could make overall
problem infeasible algorithm fail find solution all.
hand, algorithms depart previous work two respects. First,
previous work almost exclusively focused constraint privacy, often ignoring agent,
topology decision privacy. show address four types, algorithms
propose correspond various points tradeoff different levels privacy
efficiency. Second, literature focuses quantitatively measuring
reducing amount privacy loss various DisCSP algorithms, developed
algorithms give strong guarantees certain pieces private information
leaked. contrast, previous privacy-protecting algorithms, typically case
piece private information may leaked (small) probability.
rest paper organized follows. Section 2 first formally defines DisCSP
framework four aforementioned types privacy. Section 3 presents first
algorithm, called P-DPOP+. Section 4 describes P3/2 -DPOP+ algorithm,
651

fiLeaute & Faltings

variant achieves higher level decision privacy, expense additional
computational overhead. Another variant, called P2 -DPOP+, introduced Section 5
order improve constraint privacy. Finally, Section 6 compares performance
algorithms previous state art, several classes benchmarks.

2. Preliminaries
section first formally defines DisCSP framework (Section 2.1), introduces
four types privacy (Section 2.2).
2.1 Distributed Constraint Satisfaction
providing formal definition Distributed Constraint Satisfaction (Section 2.1.1),
recall existing algorithms DisCSP optimization variant (Section 2.1.2).
2.1.1 Definition
Distributed Constraint Satisfaction Problem formally defined follows.
Definition 1 (DisCSP). discrete DisCSP tuple < A, X , a, D, C >:
= {a1 , ..., ak } set agents;
X = {x1 , ..., xn } set variables;
: X mapping assigns control variable xi agent a(xi );
= {D1 , ..., Dn } set finite variable domains; variable xi takes values Di ;
C = {c1 , ..., cm } set constraints, ci s(ci )-ary function scope
(xi1 , , xis(ci ) ), ci : Di1 .. Dis(ci ) {false, true}, assigning false infeasible
tuples, true feasible ones.
V
solution complete assignment conjunction ci C ci = true,
case exactly assignment consistent constraints.
important assumptions DisCSP framework following. First,
assume details given constraint ci known agents involved;
agent wants keep constraints private, formulate way
involve variables controls. Furthermore, assume two neighboring agents
(i.e. agents share least one constraint) able communicate
securely, messages delivered FIFO order finite time.
hand, assume two non-neighboring agents initially ignore everything
other, even including involvement problem. particular, DisCSP algorithm
protects agent privacy require communicate directly,
even allow discover others presence. Finally, assume agent honestly
follows protocol, focus preventing private information leaks agents.
Figure 1 introduces simple graph coloring problem instance used illustrate algorithms throughout rest paper. assume five nodes
652

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

R 6= x1

6=

6=
x2

x4 6= B
6=

6=

x3

6=

x5 6 {B, R}

Figure 1: DisCSP constraint graph simple graph coloring problem instance.

graph correspond five different agents, must choose color among red,
blue green. decisions modeled five variables x1 , . . . , x5 domains
{R, B, G}. agent may express secret, unary constraint variable; instance,
x1 want assigned color red. Binary, inequality constraints imposed
pair neighboring nodes, known two agents involved.
Distributed Constraint Optimization (DCOP) extension DisCSP formalism,
constraints specify variable assignments feasible infeasible,
also assign costs (or utilities) assignments. (optimal) solution
DCOP one minimizes sum costs (or maximizes sum utilities).
algorithms paper easily generalized solve DCOPs, complexity
increase linear upper bound (assumed integer) cost
optimal solution. generalization left outside scope paper sake
conciseness, addressed Leaute Faltings (2011) Leaute (2011).
2.1.2 Complete Algorithms DisCSPs
range distributed algorithms exist literature solve DisCSPs DCOPs.
seen belonging two classes, depending order variables.
largest class consists algorithms order variables along linear order,
ABT (Yokoo, Durfee, Ishida, & Kuwabara, 1992), AWC (Yokoo, 1995), SynchBB (Hirayama & Yokoo, 1997), AAS (Silaghi, Sam-Haroud, & Faltings, 2000), AFC (Meisels &
Zivan, 2003), DisFC (Brito & Meseguer, 2003), (Comp)APO (Mailler & Lesser, 2003; Grinshpoun & Meisels, 2008), ConcDB (Zivan & Meisels, 2004), AFB (Gershman, Meisels, &
Zivan, 2006) ConcFB (Netzer, Meisels, & Grubshtein, 2010). linear order may
chosen fixed initially algorithm run, dynamically revised online.
second class, variables ordered along tree-based partial order. includes
ADOPT (Modi, Shen, Tambe, & Yokoo, 2005) variants BnB-ADOPT (Yeoh,
Felner, & Koenig, 2010) BnB-ADOPT+ (Gutierrez & Meseguer, 2010), DPOP (Petcu
& Faltings, 2005) countless variants, NCBB (Chechetka & Sycara, 2006),
order variables following pseudo-tree (Definition 2). Among aforementioned
pseudo-tree-based algorithms, DPOP one using Dynamic Programming (DP),
others based search. algorithms proposed perform DP
different partial variable orders: Action-GDL uses junction trees (Vinyals, RodrguezAguilar, & Cerquides, 2010), DCTE cluster trees (Brito & Meseguer, 2010).
653

fiLeaute & Faltings

2.1.3 DPOP Algorithm
DPOP algorithm originally designed solve optimization problems (DCOPs)
described terms utility maximization. One way apply pure satisfaction problems
(DisCSPs) first reformulate DisCSP Max-DisCSP, constraints
longer boolean rather take values {0, 1}, 0 stands feasibility
1 infeasibility. cost-minimizing variant DPOP (described below)
applied find solution minimal cost, cost (hereafter called feasibility
value) corresponds number constraint violations (which want equal 0).
Overview Algorithm DPOP instance general bucket elimination
scheme Dechter (2003), performed distributedly (Algorithm 1). requires first arranging
constraint graph pseudo-tree, formally defined follows.
Definition 2 (Pseudo-tree). pseudo-tree generalization tree, node
allowed links (back-edges) remote ancestors (pseudo-parents) remote
descendants (pseudo-children), never nodes branches tree.
pseudo-tree arrangement constraint graph Figure 1 illustrated Figure 2.
pseudo-tree naturally decomposes original problem two, loosely coupled subproblems, corresponding two branches, perform rest algorithm
parallel. Figure 2 also shows FEAS messages (originally called UTIL messages
context utility maximization) exchanged propagation feasibility
values, following multi-party dynamic programming computation (lines 1 12).
Algorithm 1 Overal DPOP algorithm, variable x
Require: pseudo-tree ordering variables; px denotes xs parent
1: // (UTIL propagation) Propagate feasibility values pseudo-tree:
2: m(x, px , ) c{c C | xscope(c) scope(c )(childrenx pseudo childrenx )=} c(x, )
// Join received messages:
yi childrenx
5:
Wait message (FEAS, mi (x, )) yi
6:
sepyi scope(mi )
7:
m(x, px , ) m(x, px , ) + mi (x, )
3:
4:

// Project x:
x root variable
10:
x (px , ) arg minx {m(x, px , )}
11:
Send message (FEAS, m(x (px , ), px , )) px
12: else x arg minx {m(x)} // m(x, px , ) actually depends x
8:

9:

13:
14:
15:
16:
17:

// (VALUE propagation) Propagate decisions top-down along pseudo-tree:
x root
Wait message (DECISION, px , ) parent px
x x (px = px , )
yi childrenx send message (DECISION, sepyi ) yi
654

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

x2

x3 x2
R B G
0 1 0
x5 x3
x3
R
0
B
0
G
1

x4 x3
x2
x3 R B G
R
0 1 0
B
0 0 0
G
0 0 0

x2

x3

x5

x4

x1

x1 x4
x2
x4 R B G
R
0 0 0
B
0 0 1
G
0 1 0

Figure 2: Multiparty dynamic programming computation feasible value x2 , based
pseudo-tree arrangement constraint graph Figure 1. dashed
edge represents back-edge pseudo-parent pseudo-tree.

part algorithm, messages travel bottom-up along tree edges. Consider instance
message sent agent a(x5 ) parent agent a(x3 ). message result
projection (lines 10 11) variable x5 conjunction (line 2) x5 two
constraints x5 6= x3 x5 6= B, summarizes minimal number constraint violations a(x5 ) achieve, function ancestor variable x3 . generally,
message sent variable x summarizes minimal number constraint violations
achievable aggregate subproblem owned entire subtree rooted x,
function whose scope called separator x (line 6). DPOP, separator x necessarily includes xs parent px , potentially ancestor variables; indicated
notation m(px , ). instance, message x4 x3 summarizes minimal number
constraint violations achievable entire subtree rooted x4 , function x4
separator {px4 = x3 , x2 }. Notice separator variable x contain variables
neighbors x; example, x2 x4 separator descendent x4
constraint x2 . privacy-aware algorithms presented later paper,
notion separator extended allow separators necessarily include
parent variable, may include multiple codenames referring variables,
might necessarily ancestors pseudo-tree.
Upon receiving messages x5 x3 x4 x3 (line 5), agent a(x3 ) joins
(line 7) constraint x3 6= x2 . Variable x3 projected resulting joint
table, produces message x3 x2 (lines 10 11). end feasibility
propagation (line 12), root variable x2 chooses value x2 minimizes
number constraint violations entire problem (e.g. x2 = R). decision
propagated downwards along tree-edges via DECISION messages (originally called
VALUE messages) variables assigned optimal values (lines 13 17).
655

fiLeaute & Faltings

Complexity Given pseudo-tree ordering n variables, DPOPs bottom-up
top-down phases exchange exactly (n 1) messages (one tree edge).
However, DECISION message contains (n 1) variable assignments,
FEAS message sent given variable x contain exponentially many feasibility values,
contains table representation function |sepx | variables. size
sepmax
largest FEAS message therefore O(Dmax
), Dmax size largest
variable domain, sepmax = maxx |sepx | < n 1 width pseudo-tree.
best case, width equal treewidth constraint graph; however finding
pseudo-tree achieves minimal width NP-hard. practice, pseudo-tree
generated heuristic, distributed, depth-first traversal constraint graph (Online
Appendix 1), producing so-called DFS tree pseudo-tree parentchild relationships neighbors constraint graph. Since DPOP exchanges
(n 1) FEAS messages, overall complexity terms runtime (measured number
sepmax
constraint checks), memory, information exchange O(n Dmax
).
Privacy Properties privacy-aware algorithms Section 3 based DPOP,
two desirable properties allow higher levels privacy. First, DPOP
requires message exchanges neighboring agents, provided pseudotree used DFS tree; necessary protect agent privacy. Greenstadt, Pearce,
Tambe (2006) made opposite claim pseudo-trees detrimental privacy
compared linear orderings; however claim valid type privacy
considered constraint privacy, hold agent privacy topology privacy
guaranteed, i.e. pseudo-tree publicly known agents. second, DPinherited property DPOPs performance depend constraint tightness,
i.e. easy hard satisfy constraint. other, search-based algorithms,
inferences constraint tightness made observing runtime amount
information exchanged (Silaghi & Mitra, 2004). case meeting scheduling problems,
constraint tightness maps directly participants levels availability, private
information. application domains leak constraint tightness tolerable,
algorithms based search rather DP used, many privacy-enhancing
techniques presented paper DPOP also applicable search-based algorithms.
2.2 Privacy DisCSPs
Section 2.2.1 formally defines four types privacy considered paper. Section 2.2.2
recalls previous work attempted address various subsets privacy types.
2.2.1 Privacy Definitions
Definition 3 introduces concept semi-private information (Faltings, Leaute, & Petcu,
2008), may inevitably leaked DisCSP algorithm.
Definition 3 (Semi-private information). Semi-private information refers information
problem and/or solution agent might consider private,
inevitably leaked agents views chosen solution DisCSP.
words, semi-private information covers everything given agent discover
agents making inferences simply based initial knowledge problem
656

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

values variables take solution. instance, graph coloring problem
involving two colors, node infer color neighbors
color assigned chosen solution, provided solution correct. Excluding
semi-private information, distinguish four types private information agents
may desire protect (Faltings et al., 2008).
Definition 4 (Agent privacy). agent able discover identity, even
existence non-neighboring agents. particular consequence type privacy
two agents allowed communicate directly share constraint.
Figure 1, means instance agent a(x1 ) able discover
existence identities agents a(x3 ) a(x5 ). Even two non-neighboring agents
communicate directly, agent privacy might still leaked contents messages;
paper propose method based codenames fully protect agent privacy.
Definition 5 (Topology privacy). agent able discover existence
topological constructs constraint graph, nodes (i.e. variables), edges (i.e.
constraints), cycles, unless owns variable involved construct.
Figure 1, topology privacy means instance agent a(x1 ) discover
many neighbors x2 besides itself. However, a(x1 ) might discover existence
cycle involving x1 , x2 x4 . tolerated x1 involved cycle,
a(x1 ) discover length cycle (i.e. x2 x4 share neighbor).
Definition 6 (Constraint privacy). agent able discover nature
constraint involve variable owns.
Figure 1, example breach constraint privacy would agent a(x1 )
able discover agent a(x4 ) want assigned color blue.
type privacy DisCSP literature mostly focuses on.
Definition 7 (Decision privacy). agent able discover value another
agents variable takes chosen solution (modulo semi-private information).
distributed graph coloring problem, means agent discover color
neighbor (let alone non-neighboring agent) solution chosen problem.
2.2.2 Previous Work Privacy DisCSP
discussing information may leaked given algorithm, prevent
it, important clarify information assumed initially known agent.
Initial Knowledge Assumptions paper, use following three assumptions,
currently widely used DisCSP literature.
1. agent knows agents variables neighbors variables,
know agents (not even existence);
2. variable domain known owner agent agents owning
neighboring variables, agents ignore existence variable;
657

fiLeaute & Faltings

3. constraint fully known agents owning variables scope,
agent knows anything constraint (not even existence).
Brito Meseguer (2003) introduced Partially Known Constraints (PKCs), whose
scopes known agents involved, knowledge whose nature (which assignments allowed disallowed) distributed among agents. relaxation
Assumption 3; however worth noting algorithms presented paper
still support PKCs without introducing privacy leaks enforcing assumption,
PKC decomposed number constraints copy variables
Assumption 3 holds. instance, agents a1 . . . share knowledge unary PKC
variable x, constraint decomposed n unary constraints,
constraint ci known fully agent ai expressed copy
variable xi owned ai . Equality constraints added problem enforce equality
copy variables. However, introduction copy variables detrimental
decision privacy. Grubshtein, Grinshpoun, Meisels, Zivan (2009) later proposed
similar concept asymmetric constraints, also reformulated symmetric
constraints copy variables purpose applying algorithms.
previous work adopted dual approach, assuming variables public
known agents, constraint known one agent (Silaghi et al., 2000;
Yokoo, Suzuki, & Hirayama, 2002; Silaghi, 2005a). Silaghi (2005b) even proposed framework constraints secret everyone. dual approach disadvantage necessarily violating topology privacy, since variables public.
Measuring Constraint Privacy Loss literature privacy DisCSPs
focuses constraint privacy. Metrics proposed evaluate constraint privacy
loss algorithms, particular distributed meeting scheduling (Franzin, Freuder, Rossi,
& Wallace, 2004; Wallace & Freuder, 2005). Maheswaran, Pearce, Bowring, Varakantham,
Tambe (2006) designed framework called Valuation Possible States (VPS)
used measure constraint privacy loss OptAPO SynchBB algorithms,
considered impact whether problem topology public partially
known agents. Greenstadt et al. (2006) also applied VPS evaluate DPOP
ADOPT meeting scheduling problems, assumption problem topology
public. Doshi, Matsui, Silaghi, Yokoo, Zanker (2008) proposed consider cost
privacy loss optimization problems, order elegantly balance privacy optimality.
Preventing Constraint Privacy Loss previous work also proposed approaches
partially reduce constraint privacy loss. instance, Brito Meseguer (2007) described
modification Distributed Forward Checking (DisFC) algorithm DisCSPs
agents allowed lie finite time order achieve higher levels privacy. However, performance search-based algorithms like DisFC leaks information
constraint tightness, explained end Section 2.1.3. avoid subtle privacy
leak, one must either perform full exhaustive search, option chosen Silaghi,
resort Dynamic Programming, option chosen paper.
cryptographic technique secret sharing (Shamir, 1979; Ben-Or, Goldwasser, &
Wigderson, 1988) also applied Silaghi, Faltings, Petcu (2006) Greenstadt,
Grosz, Smith (2007) lower constraint privacy DPOP, assuming constraint
graph topology public knowledge. Cryptography also applied provide strong
658

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

guarantees constraint privacy preservation multi-agent decision making. instance,
Yokoo Suzuki (2002), Yokoo et al. (2002) Yokoo, Suzuki, Hirayama (2005)
showed public key encryption scheme used solve DisCSPs using multiple
servers, protecting constraint privacy decision privacy. Bilogrevic, Jadliwala,
Hubaux, Aad, Niemi (2011) solved single-meeting scheduling problems using similar
techniques, one semi-trusted server. paper however, consider algorithms
make use third parties, third parties might available. Herlea,
Claessens, Preneel, Neven, Piessens, Decker (2001) showed use Secure Multiparty
Computation (SMC) 1 securely schedule single meeting, without relying servers.
SMC, agents collaboratively compute value given, publicly known function
private inputs, without revealing inputs. Herlea et al. (2001), inputs
participants availability given time, function outputs whether
available.
MPC-DisCSP4 Algorithm Silaghi (2005a) also applied SMC solve general
DisCSPs, private inputs agents constraint valuations, function
returns randomly chosen solution. algorithm proceeds follows (Leaute, 2011).
agent ai first creates vector Fi one entry per candidate solution DisCSP, equal
1 candidate solution satisfies ai private constraints, 0 otherwise. reduce
size Fi , candidate solutions may filtered publicly known constraints,
exists any. Using Shamirs polynomial secret sharing technique (Shamir, 1979; BenOr et al., 1988), agent ai sends one secret share Fij vector Fi
agent aj , receives corresponding secret shares Fji respective vectors. Agent ai
multiplies together secret shares received. multiplication Shamir secret
shares non-trivial operation, secret share value polynomial,
multiplying two polynomials increases degree output, must always remain
lower number |A| agents resolvable. Therefore, multiplication
two secret shares, agent ai must perform complex sequence operations involving
exchange messages order reduce degree output.
performing (|A| 1) pairwise multiplications secret shares, agent ai vector Fi contains secret shares 1 entries corresponding globally feasible solutions.
Agent ai performs transformation Fi one secret share 1
remains, identifying one particular feasible solution (if exists one). selecting
first entry would posteriori reveal previous entries correspond infeasible
solutions DisCSP; prevent privacy leak, vector Fi first collaboratively,
randomly permuted using mix-net. Agent ai performs sequence iterative operations Fi (including communication-intensive multiplications) set entries
secret shares 0, except one secret share 1 corresponding chosen solution
DisCSP (if any). vector Fi un-shuffled re-traversing mix-net
reverse. Finally, agent ai compute secret shares domain index variables
chosen assignment, reveal secret shares owners variables.
algorithm numerous drawbacks. First, agent must know variables
domains construct initial vector Fi , immediately violates agent privacy
topology privacy (Table 3.3, page 664). Second, Shamirs secret sharing scheme
1. Silaghi uses different acronym MPC concept.

659

fiLeaute & Faltings

majority threshold scheme, means least half agents collude,
discover everyones private information. Even though, paper, assuming
agents honest collude, consequence threshold
scheme provide privacy guarantee problem involves two agents.
Third, algorithm often practical small problems, performs
full exhaustive search; demonstrated experimental results Section 6.

3. P-DPOP+ : Full Agent Privacy Partial Topology, Constraint
Decision Privacy
section describes variant DPOP algorithm guarantees full agent privacy.
also partially protects topology, constraint, decision privacy. Algorithm 2
improvement P-DPOP algorithm originally proposed (Faltings et al., 2008).
Like DPOP, algorithm performs dynamic programming DFS-tree ordering
variables (Figure 2). Algorithms first elect one variable, generate DFS tree
rooted variable given Online Appendices 1 2. algorithms
reveal pseudo-tree entirety agent; instead, agent discovers
(pseudo-)parents (pseudo-)children variables. sake simplicity,
hereafter assume without loss generality constraint graph consists single
component. problem actually consisted two fully decoupled subproblems,
subproblem would solved parallel, independently others.
Algorithm 2 Overal P-DPOP+ algorithm, variable x
Require: DFS-tree ordering variables
1: // Choose exchange codenames x domain Dx :
2: Wait message (CODES, yix , Dyxi , yxi ) yi {parentx } pseudo parentsx
3: yi childrenx pseudo childrenx
4:
xyi large random number
5:
Dxyi list |Dx | random, unique identifiers
6:
xyi random permutation [1, . . . , |Dx |]
7:
Send message (CODES, xyi , Dxyi , xyi ) yi

12:

// Choose exchange obfuscation key x:
Wait record message (KEY, keyyxi ) yi pseudo parentsx (if any)
yi pseudo childrenx
keyxyi vector large random numbers B bits, indexed Dx
Send message (KEY, keyxyi ) yi

13:

Propagate feasibility values pseudo-tree (Algorithm 3, Section 3.1)

14:

// Propagate decisions top-down along pseudo-tree (Section 3.2):
x root
Wait message (DECISION, px , ) parent px
x x (px = px , ) // x () computed Algorithm 3, line 21
yi childrenx
) yi , sepyi Algorithm 3, line 12
Send message (DECISION, sep


8:
9:
10:
11:

15:
16:
17:
18:
19:

660

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

3.1 Finding Feasible Value Root Variable
already illustrated DPOP Section 2.1.3, agents perform bottom-up propagation feasibility values along pseudo-tree. done Algorithm 3,
extension DPOPs UTIL propagation phase (the extensions indicated comments
bold), improves algorithm originally proposed (Faltings et al., 2008)
patching important constraint privacy leak single-variable FEAS messages
sent variables singleton separators. following sections describe obfuscation
techniques used protect private information could leaked feasibility
messages, using codenames (Section 3.1.1) addition random numbers (Section 3.1.2).
Algorithm 3 Algorithm find feasible value root DFS tree, variable x
Require: DFS-tree ordering variables; px denotes xs parent
1: // Join local constraints:
2: m(x, px , ) c{c C | xscope(c) scope(c )(childrenx pseudo childrenx )=} c(x, )
3:
4:
5:

// Apply codenames:
yi {px } pseudo parentsx
m(x, px , ) replace (yi , Dyi ) m(x, px , ) (yix , Dyxi ) Algorithm 2, line 2,
apply permutation yxi Dyxi

// Obfuscate infeasible entries:
r large, positive,
random number B bits

m(x, px , )
m(x, px , ) = 0
8: m(x, px , )
m(x, px , ) + r m(x, px , ) > 0
6:
7:

9:
10:
11:
12:
13:
14:
15:

// Join received messages:
yi childrenx
Wait message (FEAS, mi (x, )) yi
sepyi scope(mi )
z childrenx pseudo childrenx // resolve codenames
mi (x, ) identify (xz , Dxz ) (x, Dx ) mi (x, ) (if xz present)
m(x, px , ) m(x, px , ) + mi (x, )

// De-obfuscate feasibility values respect x:
17: yi pseudo childrenx
18:
m(x, px , ) m(x, px , ) keyxyi (x) // keyxyi Algorithm 2, line 11
16:

// Project x:
x root variable
21:
x (px , ) arg minx {m(x, px , )}
22:
m(px , ) minx {m(x, px , )}
19:

20:

23:
24:
25:
26:
27:

// Obfuscate feasibility values:
yi pseudo parentsx
m(px , ) m(px , ) + keyyxi (yix ) // keyyxi Algorithm 2, line 9
Send message (FEAS, m(px , )) px
else x arg minx {m(x)} // m(x, px , ) actually depends x
661

fiLeaute & Faltings

3.1.1 Hiding Variable Names Values Using Codenames
Consider feasibility message x1 x4 sent agent a(x1 ) parent variable x4
Figure 2. message recalled Figure 3(a), reformulated terms minimizing
number constraint violations. message actually received cleartext, would
breach agent privacy topology privacy: agent a(x4 ) would able infer
dependency message variable x2 existence agent a(x2 ) (which violates
agent privacy) fact x2 neighbor one unknown nodes x1 .
x1 x4
x2
x4 R B G
R
0 0 0
B
0 0 1
G
0 1 0
(a) cleartext

x4
R
B
G

x1 x4
928372

0 0 0
0 0 1
0 1 0

(b) partly obfuscated

x4
R
B
G

x1 x4
928372


620961 983655
620961 983655
620961 983656


534687
534688
534687

(c) fully obfuscated

Figure 3: message sent agent a(x1 ) parent variable x4 Figure 2.

order patch privacy leaks, variable x2 domain D2 = {R, B, G} replaced random codenames xx2 1 = 928372 D2x1 = {, , } (Figure 3b) preliminarily
generated a(x2 ) communicated directly leaf back-edge (Algorithm 2,
lines 2 7). leaf applies codenames output message (Algorithm 3, line 5),
resolved propagation reaches root back-edge (Algorithm 3, line 14). knowing codenames, agents between, a(x4 ),
infer existence cycle constraint graph involving unknown ancestor descendent. tolerated definition topology privacy (Definition 5)
since also involved cycle. secret, random permutation 2x1 also applied
D2x1 ; useful problem classes variable domains public. Notice
x4 also constraint x2 , reasoning would still hold, x2 would
sent different codename xx2 4 x4 , would able resolve
unknown codename xx2 1 x2 . case, x4 separator would {x3 , xx2 1 , xx2 4 },
message sent x3 would three-dimensional instead two-dimensional.
3.1.2 Obfuscating Feasibility Values
Hiding variable names values using codenames addresses leaks agent topology
privacy. However, address fact feasibility values message
x1 x4 Figure 3(b) violate constraint privacy, reveal x4 subtree
always find feasible solution subproblem x4 = R, regardless value
obfuscated variable 928372. patch privacy leak, feasibility values obfuscated
adding large, random numbers generated root back-edge (x2 )
sent secure channel leaf back-edge (Algorithm 2, lines 9 12).
number bits B random numbers problem-independent parameter
algorithm. obfuscation performed way different random number
662

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

added feasibility values associated value x2 , Figure 3(c), using
obfuscation key [620961, 983655, 534687]. random numbers added leaf
back-edge outgoing message (Algorithm 3, line 25), eventually
subtracted propagation reaches root back-edge (Algorithm 3, line 18).
Notice obfuscation scheme achieves two objectives: 1) hides x4
absolute feasibility values subtree, 2) hides relative dependencies
values obfuscated variable 928372, different random numbers used
value obfuscated domain {, , }. Agent a(x4 ) still able infer relative
dependencies variable x4 , necessary perform projection
variable, unable tell, value (obfuscated) variable, whether
subtrees problem feasible, not, many constraints violated. Notice
particular that, given value obfuscated variable (i.e. column), agent a(x4 )
know whether assignments x4 feasible, therefore would
incorrect simply assume lowest obfuscated feasibility entries decrypts 0.
Similarly, equal entries column correspond high probability entries
number constraint violations, number necessarily 0,
would incorrect infer correspond feasible entries.
Notice also obfuscation scheme applicable presence backedge, i.e. message contains parent variable. Consider
instance single-variable message x5 x3 , recalled Figure 4(a). agent a(x3 ) knew
x5 leaf pseudo-tree, cleartext message would reveal agent a(x5 )s private
local constraint x5 6 {B, R} agent a(x3 ), previous obfuscation scheme
apply absence back-edges. Notice threat constraint privacy
tempered fact P-DPOP+ guarantees terms topology privacy prevent
agent a(x3 ) discovering x5 indeed leaf. a(x3 )s point view, larger
subproblem might hanging variable x5 Figure 2, message could actually
aggregation multiple agents subproblems.

x3
R
B
G

x5 x3
# conflicts
0
0
1

(a) cleartext

x3

x5 x3
# conflicts

R
B
G

0
0
730957

(b) obfuscated

Figure 4: message received agent a(x3 ) Figure 2.

reduce privacy leak present original algorithm (Faltings et al., 2008),
propose new additional obfuscation scheme consists adding large (B-bit), positive,
random numbers positive entries single-variable messages, order obfuscate
true numbers constraint violations (Algorithm 3, line 8 Figure 4(b)).
random numbers never subtracted back, must added zero entries, otherwise algorithm would fail find solution violation. Feasible entries still
revealed, numbers constraint violations infeasible entries remain obfuscated.
663

fiLeaute & Faltings

3.2 Propagating Final Decisions
feasibility values propagated way root pseudotree, feasible assignment root variable found (if exists one),
assignment propagated pseudo-tree (Algorithm 2, lines 14 19).
variable uses assignments contained message parent, order look
corresponding assignment (line 17). sends child assignments
variables separator (line 19), using codenames
protect agent topology privacy. Decision privacy partially guaranteed,
variable learns values chosen parent pseudo-parents other,
non-neighboring variables separator hidden unknown codenames.
3.3 Algorithm Properties
section first formally proves algorithm complete, analyses complexity.
present algorithm variant lower complexity. Finally, privacy guarantees
provided algorithms (summarized Table 3.3) formally described.
privacy type:

agent

topology

constraint

decision

P-DPOP(+)

full
full
full
-

partial
partial
partial
partial

partial
partial
full
partial

partial
full
full
partial

3/2

-DPOP(+)

P
P2 -DPOP(+)
MPC-DisCSP4

Table 1: Privacy guarantees various algorithms.

3.3.1 Completeness Complexity
Theorem 1. Provided codename clashes, P-DPOP+ (Algorithm 2) terminates returns feasible solution DisCSP, exists one.
Proof. exchanging codenames obfuscation keys, guaranteed require
number messages quadratic number n variables, bottom-up
propagation feasibility values (Algorithm 3) terminates sending exactly (n 1)
messages (one tree-edge). One prove induction (left reader)
multi-party dynamic programming computation almost surely correctly reveals
variable x (obfuscated) feasibility subtrees subproblem, function x
possibly ancestor variables pseudo-tree. process may fail case
collisions codenames, roots two overlapping back-edges choose
codenames. codename clashes inherent privacy-protecting algorithms,
made improbable desired augmenting size codename space.
Finally, top-down decision propagation phase (Algorithm 2, lines 14 19) guaranteed yield feasible assignment variable (if exists one), exchange
exactly (n 1) messages (one tree-edge).
664

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

comes complexity algorithm terms number messages
exchanged, bottleneck election root variable (Online Appendix 1),
requires O( n2 ) messages, diameter constraint graph, degree,
n number variables. However, (n 1) messages containing feasibility
values exponentially large: message sent variable x expressed |sepx |
|sep |
variable codenames (Algorithm 3, line 12), therefore contains O(Dmaxx ) feasibility
values, Dmax size largest variable domain. overall complexity
terms information exchange, memory runtime (measured number constraint
sepmax
checks) therefore O(n Dmax
), sepmax = maxx |sepx |. DPOP,
except P-DPOP+ variable may appear multiple times different codenames
separator, hereby increasing value sepmax . However, increase
multiplicative factor upper bounded degree constraint graph, since
number codenames given variable equal number neighbors.
Empirically, experimental results Section 6 suggest that, almost problem
classes considered, median value sepmax tends grow rather linearly n.
3.3.2 P-DPOP: Trading Topology Privacy Performance
possible reduce sizes |sepxi | separators, enforcing agent a(x)
send codename x x xs (pseudo-)children, unlike Algorithm 2 (lines
2 7). variant identified absence plus sign exponent; P-DPOP
version algorithm initially proposed Faltings et al. (2008).
result change, variables previously may occurred multiple times
feasibility message different codenames appear
once, sepmax < n. worst-case complexity P-DPOP
becomes DPOP (Petcu & Faltings, 2005), sepmax equal
width pseudo-tree, bounded treewidth constraint graph.
However, privacy considerations prevents use P-DPOP DPOPs efficient,
less privacy-aware pseudo-tree generation heuristics, resulting higher-width pseudo-trees.
complexity P-DPOP hereby decreased compared P-DPOP+ , sending
codename x variable x (pseudo-)children drawbacks terms
topology privacy, analyzed below.
3.3.3 Full Agent Privacy
two ways identity agent could leaked non-neighbor B:
1) algorithm require B exchange messages other, 2) Agent
receive message whose content refers identifiably B. Case 1 never happen
algorithms, ever involve exchanging messages neighboring
agents. Case 2 addressed mainly use codenames.
Theorem 2. P-DPOP(+) algorithms guarantee full agent privacy.
Proof. P-DPOP(+) algorithms proceed following sequential phases (the preliminary phases root election pseudo-tree generation addressed online appendices):
Bottom-up feasibility propagation (Algorithm 3) feasibility message contains
function (line 11) set variables, whose names, transmitted clear
665

fiLeaute & Faltings

text, could identify owner agent. prevent agent privacy leak, P-DPOP(+)
replaces variable names secret, random codenames, follows.
Consider variable x pseudo-tree. Note feasibility message sent x
ancestor x function x. message sent x function
x, x projected message sent (line 22). Variable x cannot
re-appear feasibility message higher pseudo-tree, agents local
problem involve variable lower pseudo-tree (line 2).
Similarly, consider feasibility message sent descendant x
pseudo-tree, assume first leaf pseudo-tree. Since
children, feasibility message sends function variables
local problem. local problem involves x, replace x codename xy
(line 5) sends feasibility message. One prove inference
feasibility message sent variable x contain x either;
(and necessarily) contain one several codenames xyi .
Since codenames xyi random numbers chosen x (Algorithm 2, line 4),
communicated (through channels assumed secure) respective
neighbors yi x (Algorithm 2, line 7), non-neighbor x receiving message
involving xyi discover identity owner agent.
domain Dx variable x could also contain values might identify owner
agent. fix privacy risk, xs domain also replaced obfuscated domains Dxyi
random numbers, similarly way variable names obfuscated.
paper, make simplifying assumption variables domain
size (which naturally holds many problem classes), one variables domain
size give information owner agent. Otherwise, variable domains
padded fake values order make size.
Top-down decision propagation (Section 3.2) messages contain assignments
variables (Algorithm 2, line 19), also obfuscated using codenames.
concludes proof that, P-DPOP(+) algorithms, agent receive
message infer identity non-neighboring agent.
3.3.4 Partial Topology Privacy
Theorem 3. P-DPOP guarantees partial topology privacy. minor leaks topology
privacy lie fact variable might able discover lower bound neighbor
variables degree constraint graph, lower bound total number variables.
Proof. Root election pseudo-tree generation left online appendices.
Bottom-up feasibility propagation (Algorithm 3) variable x receives FEAS
message child, containing function whose scope might reveal topological
information. variable scope represented secret codename y,
however x may able decrypt codename y, neighbor x
(or x itself), sent codename neighbors.
results leak topology privacy: x discovers, neighboring ancestor y,
666

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

whether least one neighbor given child x. cannot
discover exactly many neighbors are.
Furthermore, case x neighbors, x cannot decrypt y,
still infer exists another, non-neighboring ancestor corresponding
codename. another breach topology privacy. sent
codename neighbors, x also discover whether ancestor
least one neighbor xs children. Moreover, since codenames
large random numbers almost surely unique, x may discover existence
several, distinct non-neighboring ancestors.
Top-down decision propagation (Section 3.2) variable receives message
parent, contain codenames variables variable values
already present FEAS message received previous phase.
concludes proof P-DPOP partially protects topology privacy. limited
topology information leaked variable concerns branch pseudo-tree;
information leaked branch, even existence.
Theorem 4. use different codenames (pseudo-)child improves topology
privacy P-DPOP+ compared P-DPOP, bounds still leaked.
Proof. Consider variable x receives FEAS message including secret codename
corresponding variable (6= x). sent different codename
neighbors, x longer able decrypt y, even neighbor x. consequence,
x longer able infer whether refers known neighbor x, unknown,
non-neighboring variable. However, since codename corresponds unique backedge pseudo-tree, pair (, ) unknown codenames xs received FEAS
message (if pair exists), least one following statements must hold:
refer two different ancestors x, therefore x discovers least
two ancestors (which might known, pseudo-parent); and/or
sent two different descendants x (and possibly including)
sender child y, therefore x discovers least two descendants
(and including) (which might known, pseudo-child y).
Therefore x might able refine lower bound total number variables.
3.3.5 Partial Constraint Privacy
Theorem 5. P-DPOP(+) algorithms guarantee partial constraint privacy. local
feasibility subproblem partial variable assignment X may leaked, even X
cannot extended overall feasible solution (i.e. semi-private information).
Proof. Information constraints transmitted feasibility propagation (Algorithm 3). Based knowledge optimal variable assignments transmitted
last phase (Section 3.2), feasibility information may decrypted.
667

fiLeaute & Faltings

Single-variable feasibility messages variable px receives feasibility message
involving px , message obfuscated adding secret random
numbers infeasible entries (line 8). Feasible entries remain equal 0, px
identify entries refer respectively feasible infeasible assignments px .
However, addition secret, positive, random number infeasible entry
ensures upper bound number constraint violations leaked,
made loose desired choosing random numbers large necessary.
Multi-variable feasibility messages FEAS message involves least one
variable yi , message entries obfuscated adding large random
numbers keyyxi (yix ) B bits (line 25). Furthermore, keyyxi (yix ) known
sender x message pseudo-parent yi , recipient px ,
therefore cannot subtract de-obfuscate entries.
Assume, simplicity, message m(px , yix ) involves two variables
px yix ; argument extends easily variables. recipient px might
able make inferences: 1) fixing yix comparing obfuscated entries
corresponding different values px ; 2) fixing px varying yix instead.
1. given value yix , entries obfuscated adding
random number keyyxi (yix ) (line 25), px compute relative differences
feasibility values various assignments px . However, cannot decrypt
absolute values without knowing keyyxi (yix ). particular, lowest obfuscated
value necessarily equal keyyxi (yix ), necessarily decrypt
0: values px may infeasible particular value yix .
one exception: feasible solution found problem


yix = yix px = px , m(px , yix ) necessarily decrypts 0, therefore


px able infer keyyxi (yix ). fixing yix = yix message

subtracting keyyxi (yix ), reasoning made single-variable
case, feasible infeasible entries identifiable, numbers
constraint violations infeasible entries remain obfuscated.
2. given value px , feasibility value m(px , yix ) obfuscated
adding different, secret random number keyyxi (yix ). Choosing number
bits B sufficiently large makes sure useful information (relative,
absolute) obtained comparing obfuscated feasibility values.
concludes proof P-DPOP(+) guarantees partial constraint privacy.
3.3.6 Partial Decision Privacy
Theorem 6. P-DPOP(+) algorithms guarantee partial decision privacy. leak lies
fact variable might discover values chosen neighbors.
Proof. First notice algorithm cannot leak information chosen values
variables lower pseudo-tree, since variables projected
feasibility messages received. However, decision propagation phase,
variable receives message parent contains chosen values parent
668

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

pseudo-parents. message may also contain codenames assignments other, nonneighboring variables, recipient able decode. Furthermore, domains
shuffled using secret permutations, making impossible decode codename
value non-neighboring variable index variables domain.

4. P3/2 -DPOP+ : Adding Full Decision Privacy
section presents another variant P-DPOP+ algorithm achieves full decision
privacy. results novel algorithm, seen hybrid
P-DPOP+ P2 -DPOP (Leaute & Faltings, 2009) algorithms, called P3/2 -DPOP+.
4.1 Overview Algorithm
Algorithm 4 patches decision privacy leak P-DPOP+ removing decision propagation phase. root variable assigned value, order variables
assigned values, variable made root turn (unless first feasibility propagation
revealed problem infeasible, case algorithm terminate early).
3
intuition behind P /2 -DPOP+ algorithm therefore P-DPOP+ bottom-up
feasibility propagation phase repeated multiple times, time different variable x
root pseudo-tree (lines 10 15). end iteration, constraint
x = x added problem enforce consistency across iterations (line 16).
Algorithm 4 Overall P3/2 -DPOP+ algorithm full decision privacy, variable x
Require: first temporary DFS tree, unique ID idx , tight strict lower bound
+
next unique ID id+
x , upper bound n total number variables
idx

id+
x idx

z }| { z }| {
1: vectorx [1, . . . , 1, 0, 1, . . . , 1, 1, . . . , 1]
|
{z
}
n+

2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:

// Exchange public key shares:
privatex generate private ElGamal key x
publicx generate set (id+
x idx + 1) public key shares corresponding privatex
share publicx ToPrevious((SHARE, share)) Algorithm 9
= 1 . . . n+
Wait record one message (SHARE, share)
share 6 publicx ToPrevious((SHARE, share)) Algorithm 9
Generate compound ElGamal public key based public key shares
vectorx 6=
Choose new root (Algorithm 5, Section 4.2)
Construct new pseudo-tree rooted new root (Online Appendix 2)
Exchange codenames x domain Dx (Algorithm 2, lines 2 7)
Choose exchange obfuscation key x (Algorithm 2, lines 9 12)
Propagate feasibility values pseudo-tree (Algorithm 3, except line 21)
x root Add local constraint x = x , x Algorithm 3, line 27
669

fiLeaute & Faltings

4.2 Choosing New Root Variable
iteratively reroot pseudo-tree, propose use improved version rerooting
procedure initially introduced P2 -DPOP algorithm (Leaute & Faltings, 2009).
procedure requires n variables assigned unique ID; algorithm
achieve presented Online Appendix 3. algorithm reveals variable x
unique ID idx , well tight strict lower bound next unique ID id+
x (i.e.
+ total number variables.
+
1),


upper
bound
n
next unique ID equals id+
x
variable x creates Boolean vector vectorx single zero entry index
corresponding unique ID idx (Algorithm 4, line 1); vector shuffled using
random permutation used hide sequence variables become roots.
keep permutation secret, vector first encrypted using ElGamal encryption
(Appendix A), based compound public key jointly produced agents (Algorithm 4,
lines 2 9). asymmetric encryption scheme enables agent (re-)encrypt
entries vectors using common public key, decryption
performed collaboratively agents, using respective private keys.
Algorithm 5 Algorithm choose new root, variable x
Procedure: ShuffleVectors() variable x
1: myID large random number
2: px random permutation [1 . . . n+ ]
// Propagate xs encrypted vector backwards along circular ordering
vectorx E(vectorx ) // encrypts vector using compound public key
5: ToPrevious((VECT, myID, vectorx , 1)) Algorithm 9 Appendix B
3:

4:

// Process received vectors
7: true
8:
Wait message (VECT, id, vector, round) next variable
6:

9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:

round = 1
id 6= myID j = (idx + 1) . . . id+
x vector[j] 1
else round round + 1 // xs vector; move next round
round > 1 x current root
round round + 1 // root starts round except first
round = 3 vector px (vector) // shuffle vector
round = 4 id = myID // done processing vectorx
vectorx vector
continue
// Pass vector backwards along circular ordering
vector E(vector) // re-encrypts vector using compound public key
ToPrevious((VECT, id, vector, round)) Algorithm 9 Appendix B

Procedure: Reroot() variable x
21: repeat entry Decrypt(pop(vectorx )) entry 6= 1 // Algorithm 6
22: entry = 0 x new root
670

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

agents proceed Algorithm 5. variable x first starts procedure
ShuffleVectors(), run performance improvement
previous work (Leaute & Faltings, 2009), performed iteration.
vectors passed variable variable round-robin fashion, using circular message
routing algorithm presented Appendix B. agent applies secret permutation
vector shuffle it. ShuffleVectors() proceeds four rounds. round 1
(started line 5, Algorithm 5), vector makes full round along circular ordering,
variable x overwrites entries 1 (line 10),
positions vectorx (Algorithm 4, line 1). 1 entries account
IDs [idx + 1, id+
x ] assigned variable (Online Appendix 3).
x received back vectorx , enters incomplete round 2 (line 11)
vectorx passed reaches current root (line 12). root starts round 3
(line 13), variable x shuffles vector using secret permutation px
(line 14). incomplete round 4 returns fully shuffled vector owner (line 16).
reroot variable ordering beginning iteration P3/2 -DPOP+ ,
variable x calls procedure Reroot(), removes decrypts first element
vectorx . Entries decrypt 1 correspond unassigned IDs skipped.
single entry decrypts 0 identifies new root. decryption process (Algorithm 6)
collaborative effort involves variable using private ElGamal key partially
decrypt cyphertext, travels around circular variable ordering way
vectors, gets back sender variable, finally fully decrypt it.
Algorithm 6 Collaborative decryption multiply-encrypted cyphertext e
Procedure: Decrypt(e) variable x
1: codename large random number used secret codename x
2: codenamesx codenamesx {codename}
3: ToPrevious((DECR, codename, e)) Algorithm 9
4: Wait message (DECR, codename, e ) next variable ordering
5: return decryption e using xs private key
Procedure: CollaborativeDecryption() variable x
6: loop
7:
Wait message (DECR, c, e) next variable ordering
8:
c 6 codenamesx
9:
e partial decryption e using xs private key
10:
ToPrevious((DECR, c, e )) Algorithm 9

4.3 Algorithm Properties
3

first analyze completeness complexity properties P /2 -DPOP(+) algorithms, move privacy properties.
4.3.1 Completeness Complexity
Theorem 7. Provided codename clashes, P3/2 -DPOP+ algorithm
terminates returns feasible solution DisCSP, exists one.
671

fiLeaute & Faltings

Proof. basis Theorem 1, remains prove rerooting Algorithm 5
terminates correct, overall algorithm remains correct. latter easy
prove: iteration, feasible value found root variable (if exists
one), value necessarily consistent chosen assignments previous roots
since assignments enforced new, additional constraints (Algorithm 4, line 16).
comes rerooting procedure, unique ID assignment algorithm (Online
Appendix 3) ensures n variables gets unique ID 0 . . . (n+ 1). Therefore,
variable 0 entry unique position vector (Algorithm 4, line 1). Round 1
Algorithm 5 also makes sure vectors 1 entries positions.
ensures exactly one variable become new root iteration, since vectors
applied sequence permutations, variable root twice.
3

terms complexity, P /2 -DPOP+ proceeds similar way P-DPOP+ (Section 3.3), except bottom-up feasibility propagation phase repeated n times (each
time different root variable). overall complexity information exchange theresep
fore becomes O(n2 Dmaxmax ), sepmax maximum separator size variables,
iterations, therefore likely higher exponent PDPOP+ . information exchanged rerooting protocol negligible comparison.
sep
runtime complexity (measured number constraint checks) also O(n2 Dmaxmax ),
sep
memory complexity O(n Dmaxmax ), removing decision propagation phase makes become unnecessary compute record x (px , ) (Algorithm 3,
line 21). experimental results graph coloring benchmarks (Section 6.1) suggest
median value sepmax may greater median value sepmax PDPOP+ small multiplicative factor. terms number ElGamal cryptographic
operations, rerooting procedure requires total n(3n 1)n+ O(n3 ) encryptions:
n variables (re-)encrypts (3n 1) vectors size n+ (each variables vector
performs 3 full rounds, except roots vector, performs 2 full rounds),
n+ n + n 2incrmin , incrmin constant input parameter algorithm.
procedure also requires total n2 n+ O(n3 ) collaborative decryptions:
n variables (partially) decrypts n vectors size n+ .
4.3.2 Full Agent Privacy
Theorem 8. P3/2 -DPOP(+) algorithms guarantee full agent privacy.
Proof. unique ID assignment circular routing algorithms guarantee full agent privacy, demonstrated respectively Online Appendix 3 Appendix B.
Pseudo-tree rerooting (Algorithm 5) messages sent ShuffleVectors() contain variable ID, vector ElGamal cyphertexts, round number. ID
used recipient detect whether vector vector; large
random number chosen owner agent (Algorithm 5, line 1), therefore
cannot linked identity owner agent agent. ElGamal
vector round number also contain information could used
identify agent. Also note procedure used exchange ElGamal public
key shares (Algorithm 4, lines 2 9) leak information agents
672

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

identities. Reroot() procedure makes use collaborative decryption
algorithm, whose properties terms agent privacy discussed below.
Collaborative decryption (Algorithm 6) procedure exchanges messages contain ElGamal cyphertext, codename used like variable ID Algorithm 5.
codename similarly set large random number chosen current agent,
cannot linked identity agent agent.
3

concludes proof P /2 -DPOP(+) algorithms guarantee agent privacy.
4.3.3 Partial Topology Privacy
3

topology privacy P /2 -DPOP(+) slightly worse P-DPOP(+) .
Theorem 9. P3/2 -DPOP(+) algorithms guarantee partial topology privacy. variable unavoidably discovers total number variables problem, might also
discover lower bound neighbor variables degree constraint graph. advan3
3
tages P /2 -DPOP+ P /2 -DPOP P-DPOP+ P-DPOP.
Proof. Since one feasibility propagation phase per variable problem, total
number variables inevitably becomes public. following analyzes topology privacy
properties phase P3/2 -DPOP(+) already present P-DPOP(+) , except
unique ID assignment (Online Appendix 3) secure message routing (Appendix B).
Exchange ElGamal key shares (Algorithm 4, lines 29) messages containing ElGamal key shares contain information could used make
inferences topology constraint graph.
Pseudo-tree rerooting (Algorithm 5) message travels along circular variable
ordering using message routing algorithm Appendix B, contains:
vector encrypted (and re-encrypted operation) therefore cannot provide topological information;
id identifies owner vector; secret, large random number,
owner vector identify itself;
round number take following values:
round = 1 indicates vector modified, variable
setting turn values 1;
round = 2 indicates vector sent root
pseudo-tree. happen vector (unknown) root;
round = 3 indicates vector shuffled variable;
round = 4 indicates vector way back owner.
happen vector belonging (unknown) root.
Reroot() uses decryption algorithm whose properties described below.
673

fiLeaute & Faltings

Collaborative decryption (Algorithm 6) DECR messages passed along circular variable ordering, containing secret codename original sender variable,
variable capable deciphering codename. last part
message payload ElGamal cyphertext, remains encrypted reaches
back original sender, therefore leak topological information.
3

concludes proof P /2 -DPOP(+) guarantees partial topology privacy.
4.3.4 Partial Constraint Privacy
3

constraint privacy properties P /2 -DPOP(+) algorithms differ PDPOP(+) , former protect decision privacy (which benefits constraint privacy),
also reveal total number variables problem (which hurts constraint privacy).
Theorem 10. P3/2 -DPOP(+) algorithms guarantee partial constraint privacy.
leaks P-DPOP(+) (Section 3.3.5), happen less frequently.
Proof. Single-variable feasibility messages leak amount constraint privacy
P-DPOP(+) ; notice however that, since P3/2 -DPOP(+) algorithms reveal total
number variables, circumstances may possible variable discover
child leaf, feasibility message sends therefore contains information
local subproblem only. However, multi-variable feasibility messages leak potentially much
less information P-DPOP(+) : consider simpler non-restrictive case
3
two-variable message m(px , yix ) received px . P /2 -DPOP(+) protects

decision privacy, px longer discovers value yix chosen yix , therefore
longer able infer entries corresponding px = px decrypts 0.
One exception following three conditions simultaneously hold: 1) P3/2 -DPOP

used, 2) codename yix refers variable yix neighbor px , 3) yix

semi-private information px ; px still discover yix , able make
3
inferences P-DPOP(+) . first condition satisfied, i.e. P /2 -DPOP+
3
used instead P /2 -DPOP, px able link codename yix known
3
variable. also case P /2 -DPOP used, second condition

hold. Finally, first two conditions hold, px able discover yix
semi-private information, i.e. infer knowledge problem,
chosen value px .
4.3.5 Full Decision Privacy
Theorem 11. P3/2 -DPOP(+) algorithms guarantee full decision privacy.
Proof. leak decision privacy P-DPOP(+) fixed removing decision propagation phase. Instead, variable ordering rerooted, feasibility propagation
phase restarted. possible compare feasibility messages received one
iteration next infer decision made previous iteration:
messages comparable, since different codenames obfuscation keys used.
674

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

5. P2 -DPOP+ : Adding Full Constraint Privacy
describe previous, non-fully secure obfuscation scheme replaced
ElGamal homomorphic encryption (Appendix A) achieve full constraint privacy,
corresponds original P2 -DPOP algorithm (Leaute & Faltings, 2009), improved
use multiple codenames. important limitation ElGamal scheme
fully homomorphic: possible compute two encrypted Booleans,
possible compute encrypted Boolean cleartext
Boolean. consequence, bottom-up feasibility propagation performed
variable ordering variable one child, i.e. linear variable
ordering (Figure 5), using message routing algorithm Appendix B. Otherwise,
pseudo-tree variable ordering, variable two children would able join
two encrypted feasibility messages sent children. could addressed using
fully homomorphic encryption scheme Gentry (2009), however unclear whether
scheme would practically applicable would sufficient performance.
x2
x3

x1

x5

x4

Figure 5: (counter-clock-wise) circular variable ordering corresponding Figure 2.

5.1 Propagating Encrypted Feasibility Values along Linear Variable Order
contrast Figure 2, illustrates multi-party dynamic programming pseudotree variable ordering (counting constraint violations), Figure 6 shows (in cleartext)
carried linear ordering (in Boolean domain). assumes
circular communication structure preliminarily set described Appendix B.
Algorithm 7 gives detailed pseudocode procedure, intended
replacement line 15 Algorithm 4. differences pseudo-tree-based Algorithm 3 following. First, Algorithm 3 initially reformulated DisCSP
Max-DisCSP minimize number constraint violations, Algorithm 7 works
directly original DisCSP problem. means conjunction operator
replaces sum operator (lines 2 10), disjunction operator replaces
operator min (line 13). Notice also that, case linear ordering, variables local
subproblem longer necessarily involves parent variable ordering (line 2),
like x4 shares constraint x5 Figures 5 6.
next difference variable x longer partially de-obfuscates feasibility
matrix projecting (Algorithm 3, line 18). reason ElGamal
scheme homomorphic, therefore longer necessary first (partially) decrypt
675

fiLeaute & Faltings

x2

x3 x2
R
B
true false

G
true

x2

x3

x3
R
B
G

x5 x3
x2
R
B
true false
true
true
false false

x4 x5
x2
R
B
true false
true true
true true

x3
R
B
G
x5

G
true
true
false

x4

x4
R
B
G

G
true
true
true
x1
x1 x4
x2
R
B
true true
true true
true false

G
true
false
true

Figure 6: Multiparty dynamic programming computation (in cleartext) feasible value
variable x2 , using linear variable ordering based Figure 5.

Algorithm 7 Propagating feasibility values along linear ordering, variable x
1: // Join local constraints:
V
2: m(x, ) c{c C | xscope(c ) scope(c )(childrenx pseudo childrenx )=} c(x, )

// Apply codenames:
4: yi {parentx } pseudo parentsx
5:
m(x, ) replace (yi , Dyi ) m(x, ) (yix , Dyxi ) Algorithm 2, line 2,
apply permutation yxi Dyxi
3:

6:
7:
8:
9:
10:

// Join received message:
Wait message (FEAS, ()) next variable ordering
z childrenx pseudo childrenx
() identify (xz , Dxz ) (x, Dx ) () (if xz present)
m(x, ) m(x, ) ()

// Project x:
x root
W variable
13:
m() E ( x m(x, )) // re-encrypts using compound public key
14:
ToPrevious((FEAS, m())) Algorithm 9
15: else x FeasibleValue(m(x, )) Algorithm 8
11:

12:

676

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

feasibility values project x using operator x . root variable requires
decryption (Algorithm 7, line 15) find value x variable x whose encrypted
feasibility value decrypts true (if any). described following section.
5.2 Decrypting Feasible Value Root Variable
decryption feasibility values root collaborative process variable partially decrypts cyphertext using private key (Algorithm 6). dichotomy
procedure Algorithm 8 uses least log2 |Dx | log2 |Dx | + 1 decryptions
find feasible assignment root variable, detect infeasibility.
Algorithm 8 Finding feasible value encrypted feasibility matrix m(x)
Procedure: FeasibleValue(m (x = xil . . . xir ))
1: il < ir hthen
ki half remaining subdomain:
j // cut
il +ir
2:
il ,
2

W
3:
f easible Decrypt iI (x = xi ) Algorithm 6
4:
f easible = true return FeasibleValue(m
(x = xiI ))
5:
else return FeasibleValue x = xi[il ,ir ]I
else // one value remains x
7:
f easible Decrypt(m (x = xil )) Algorithm 6
8:
f easible = true return xil else return null
6:

5.3 Algorithm Properties
first analyze completeness complexity properties P2 -DPOP(+) algorithms,
move privacy properties.
5.3.1 Completeness Complexity
Theorem 12. Provided codename clashes, P2 -DPOP+ algorithm
terminates returns feasible solution DisCSP, exists one.
Proof. Termination follows Theorem 7, fact message routing
procedure Appendix B guarantees feasibility messages eventually reach destinations. comes completeness, homomorphic property ElGamal scheme
ensures projection variable x encrypted feasibility matrix correct,
feasibility message received variable linear ordering summarizes
(encrypted) feasibility lower agents aggregated subproblems, function higher
variables. particular, feasibility message received root allows find value
variable satisfies overall problem, exists one.
analysis complexity algorithm remains similar analysis Secsep
tion 4.3: O(n2 Dmaxmax ) information exchange number constraint checks,
sep
O(n Dmaxmax ) memory, sepmax maximum separator size along
successive linear variable orderings, instead along pseudo-trees. requirement
677

fiLeaute & Faltings

variable may one child tends make exponent increase significantly,
illustrated empirically Section 6. terms number ElGamal cryptographic operations, addition cost rerooting variable ordering (Section 4.3), algorithm
sep
also requires O(n2 Dmaxmax ) encryptions, O(n log Dmax ) collaborative decryptions.
5.3.2 Full Agent Privacy
Theorem 13. P2 -DPOP(+) algorithms guarantee full agent privacy.
3

Proof. changes introduced P2 -DPOP(+) respect P /2 -DPOP(+)
feasibility propagation, finding feasible value root variable.
ElGamal feasibility propagation (Algorithm 7) point view agent privacy, procedure Algorithm 3, using Algorithm 9 message
routing, algorithms guarantee agent privacy.
Root variable assignment (Algorithm 8) consists iteratively calling procedure Algorithm 6, already shown guarantee agent privacy.
concludes proof P2 -DPOP(+) algorithms guarantee agent privacy.
5.3.3 Partial Topology Privacy
Theorem 14. P2 -DPOP(+) algorithms guarantee partial topology privacy. addition
limited leaks topology privacy P3/2 -DPOP(+) , agent might also able
discover exists another branch constraint graph involved in.
3

Proof. two relevant differences P /2 -DPOP(+) : linear variable ordering, choice value root variable requires collaborative decryption.
ElGamal feasibility propagation (Algorithm 7) exchange FEAS messages along
linear variable ordering, algorithm makes use circular message routing
procedure, shown Appendix B guarantee full topology privacy. However,
last variable linear ordering needs know last order initiate
feasibility propagation; therefore, contraposition, non-last variables know
last, and, particular, non-last leaves pseudo-tree discover
existence another branch. minor leak topology privacy already present
unique variable ID assignment algorithm (Online Appendix 3). Besides this,
topology privacy properties feasibility propagation phases P2 -DPOP
P2 -DPOP+ P-DPOP P-DPOP+ , respectively.
Root variable assignment (Algorithm 8) algorithm involves recursively calling
collaborative decryption procedure, shown guarantee full topology privacy.
concludes proof P2 -DPOP(+) guarantees partial topology privacy.
678

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

5.3.4 Full Constraint Privacy
Theorem 15. P2 -DPOP(+) algorithms guarantee full constraint privacy.
Proof. P2 -DPOP(+) algorithms fix leaks constraint privacy P<2 -DPOP(+) ,
replacing cryptographically insecure obfuscation addition random numbers, cryptographically secure ElGamal encryption (Appendix A). makes
longer possible compare two encrypted feasibility values without decrypting them,
would require collaboration agents (or amount computation break
encryption made arbitrarily high worst case increasing ElGamal
key size). particular, possible compute logical two cyphertexts
without decrypting them, result remains encrypted, cannot compared two
inputs decide one true, any.
5.3.5 Full Decision Privacy
Theorem 16. P2 -DPOP(+) algorithms guarantee full decision privacy.
Proof. proof applies Theorem 11.

6. Experimental Results
report empirical performance algorithms state-of-the-art MPCDisCSP4 algorithm, four classes benchmarks: graph coloring, meeting scheduling,
resource allocation, game equilibrium. compare MPC-DisCSP4,
knowledge general DisCSP algorithm provides strong privacy
guarantees. problem class, choice DisCSP formulation crucial,
dictates four types privacy defined based DisCSP constraint graph
relate actual privacy original problem. particular, P -DPOP(+) algorithms use standard DisCSP assumption constraint known agents
owning variable scope (Section 2.2.2). Therefore, agent wants hide
constraint neighboring agents, must express constraint copies neighbors variables. Additional equality constraints must introduced make copy variables
equal respective original variables. contrast, MPC-DisCSP4 make use
DisCSP assumption, therefore need introduction copy variables.
first performance metric simulated time (Sultanik, Lass, & Regli, 2007),
used, agents simulated single machine, estimate time would
taken solve problem run parallel dedicated machines (ignoring
communication delays). two metrics number messages amount
information exchanged. metric, report median least 100 problem
instances, 95% confidence intervals. obfuscation P<2 -DPOP(+) , used
random numbers B = 128 bits, P2 -DPOP(+) used 512-bit ElGamal encryption.
MPC-DisCSP4 also used 512 bits Paillier encryption. unique variable ID
generation procedure P>1 -DPOP(+) , parameter incrmin set 10. algorithms
implemented inside Java-based FRODO platform DisCSP (Leaute, Ottens, &
Szymanek, 2009), coupled CSP solver JaCoP (Kuchcinski & Szymanek, 2011).
experiments run 2.2-GHz, dual-core computer, Java 1.6 Java
heap space 2 GB. timeout set 10 min (wall-clock time).
679

fiLeaute & Faltings

6.1 Graph Coloring
first report performance algorithms distributed, 3-color graph coloring
problems. graphs randomly generated varying numbers nodes,
edge density fixed 0.4. Notice that, fixed number colors fixed edge
density, increasing number nodes increases degree graph, therefore
reduces number feasible solutions; explains trends following
graphs. DisCSP formulation involves one decision variable per node, assumes
variable controlled single-variable agent. Notice inter-agent constraints
binary inequality constraints, therefore decision privacy relevant problem class:
knowing ones chosen color insufficient infer respective colors ones neighbors.
study tradeoff privacy performance MPC-DisCSP4, considered
variant denoted MPC-DisCSP4 , assumes inter-agent inequality constraints (i.e.
node neighborhoods) public, final choice colors protected. agent

Simulated time (in ms)

106

Induced width

10
MPC

5

MPC

10

8

P2 -DPOP+
P2 -DPOP

104
3

10

3
P2

-DPOP

3
P2

-DPOP

6
+

4

P-DPOP+

102

P-DPOP

2

DPOP

101

0
3

4

5
6
7
8
Number nodes

9

10

3

Number messages

106

4

5
6
7
8
Number nodes

9

10

Information exchanged (in bytes)

108

105

107

MPC
MPC

104



P>1 -DPOP+
3

106

P>1 -DPOP

10

P-DPOP+

102

105

P-DPOP

101
100

DPOP

3

4

5
6
7
8
Number nodes

9

104
103

10

3

4

5
6
7
8
Number nodes

Figure 7: Performance graph coloring problems.

680

9

10

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

first enumerates feasible solutions overall problem (Section 2.2.2), uses
cryptographic techniques securely randomly choose one feasible solutions.
exists none, algorithm therefore terminates without cryptographic operations
exchanging messages. explains phase transition MPC-DisCSP4
following graphs, since probability infeasibility increases problem size.
Figure 7 shows MPC-DisCSP4 (denoted MPC subsequent figures)
scales poorly, timing problems 6 nodes. MPC-DisCSP4
performs better; however, mentioned before, protects final choices colors.
small numbers nodes, total state space small, MPC-DisCSP4 performs
relatively well; numbers nodes 9, problem instances mostly infeasible,
MPC-DisCSP4 quickly detects infeasibility without exchange message.
efficient algorithms far P-DPOP(+) , whose performance curves
least one order magnitude algorithms. particular, P-DPOPs runtime
sensibly DPOP (the communication overhead almost solely due root
Simulated time (in ms)

105

Induced width
14
12

104
P-DPOP+

10
P-DPOP
DPOP

103

8
6

102

4
12

14

16
18
20
Number nodes

22

12

Number messages

105

14

16
18
20
Number nodes

22

Information exchanged (in bytes)

109
108

104
107
106
103
105
102

12

14

16
18
20
Number nodes

104

22

12

14

16
18
20
Number nodes

Figure 8: Performance larger graph coloring problems.

681

22

fiLeaute & Faltings

election algorithm). cost improved topology privacy P-DPOP+ vs. P-DPOP
starts show problem sizes 7, induced widths P-DPOP+ pseudotrees start deviate P-DPOP DPOP. Full decision privacy comes much higher
costs: P3/2 -DPOP(+) curve 1 3 orders magnitude P-DPOP(+) s,
even though induced widths remain sensibly same. suggests rerooting
pseudo-tree (which involves expensive cryptographic operations) far complexity
bottleneck, even full constraint privacy additionally guaranteed P2 -DPOP(+) ,
whose linear variable orderings nevertheless significantly higher induced widths
P<2 -DPOP(+) pseudo-tree orderings. Notice slope runtime curve decreases
problem size increases; due fact problems become
infeasible, P>1 -DPOP(+) algorithms able terminate first iteration
infeasible problems. Similarly P-DPOP+ vs. P-DPOP, cost improved topology
privacy visible 7 nodes; P2 -DPOP+ even timed problems size 10.
Finally, Figure 7 illustrates fact MPC-DisCSP4 tends send large numbers
small messages, P>1 -DPOP(+) algorithms send lower numbers larger messages.
Figure 8 compares performance P-DPOP(+) DPOP larger graph coloring problem instances. larger problems, improved topology privacy PDPOP+ comes complexity price high scale 12 nodes.
hand, P-DPOPs curves one two orders magnitude DPOP,
P-DPOPs median runtime problem instances size 22 30 s.
6.2 Meeting Scheduling
report experimental results random meeting scheduling benchmarks. varied
number meetings, keeping number participants per meeting 2.
meeting, participants randomly drawn common pool 3 agents. goal
assign time meeting among 8 available time slots, agent required
attend simultaneous meetings. pool agents deliberately chosen small increase
complexity problems, increasing probability agent take part
multiple meetings. Note fixing pool size number participants per
meeting still generates unbounded number different problem instances increase
number meetings, since state space (the Cartesian product domains
decision variables) keeps increasing number meetings/decisions made.
DisCSP formulation problem class following. agent owns
one variable domain size 8 meeting participates in. allDifferent
constraint variables enforce meetings scheduled different
times. meeting, binary equality constraint expressed corresponding
variables owned two participants enforces participants agree time
meeting. Notice inter-agent constraints binary equality constraints,
3
therefore P /2 -DPOP(+) bring additional privacy compared P-DPOP(+) ,
since values neighboring variables semi-private information; therefore,
report performance P3/2 -DPOP(+) . MPC-DisCSP4, simplified formulation
introducing one variable per meeting, owned initiator. way,
meeting, initiator made public, exact list participants remains secret
(it revealed posteriori participants meeting attend it).
682

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

Simulated time (in ms)

106

5

105

P2 -DPOP+
P2 -DPOP

104

MPC

4
3

P-DPOP+

103

P-DPOP

2

DPOP

102
101

Induced width

6

1
0
1

2
3
4
5
Number meetings

6

1

Number messages

106

2
3
4
5
Number meetings

6

Information exchanged (in bytes)

108

105

107

104
106
3

10

105
102
104

101
100

1

2
3
4
5
Number meetings

103

6

1

2
3
4
5
Number meetings

6

Figure 9: Performance meeting scheduling problems.

seen Figure 9, P2 -DPOPs performance comparable MPCDisCSP4 (but much stronger privacy guarantees), although former sends significantly information smallest problems, significantly fewer messages
largest problems could solve within timeout limit. hand,
majority threshold scheme, MPC-DisCSP4 actually could provide privacy
guarantees problems size 1, since involved 2 agents. algorithms could
scale problems size 4, timed larger problems. P2 -DPOP+ increased topology privacy comes price made time earlier P2 -DPOP;
complexity increase due P2 -DPOP+ steeper induced width curve.
P-DPOP(+) algorithms remain efficient far: perform 1
2 orders magnitude better others, terms runtime information
exchanged. like graph coloring, improved topology privacy P-DPOP+ comes
price negligible small problems, grow one order magnitude
problems size 6, even induced width remains close P-DPOP. terms
683

fiLeaute & Faltings

runtime information exchange, P-DPOP worse DPOP small factor
(since median induced width); however sends approximately one order
magnitude messages (which mostly due pseudo-tree root election mechanism).
6.3 Resource Allocation
Next, performed experiments distributed resource allocation benchmarks. Problem
instances produced using combinatorial auction problem generator CATS (LeytonBrown, Pearson, & Shoham, 2000), ignoring bid prices. used temporal matching
distribution modeling allocation airport takeoff/landing slots, fixing total number
slots (i.e. resources) 8, varying numbers bids. bid request
bundle 2 resources (a takeoff slot corresponding landing slot). Multiple requests
may placed airline company; airline exactly one fulfilled.

Simulated time (in ms)

106

Induced width

5

105

4
MPC

104

3

P2 -DPOP(+)
P-DPOP(+)

103

2

DPOP

102
101

1
0
1

2

3
4
5
6
Number bids

7

8

1

3
4
5
6
Number bids

7

8

Information exchanged (in bytes)

Number messages

106

2

109
108

105

107
104
106
103
105
102
101

104

1

2

3
4
5
6
Number bids

7

103

8

1

2

3
4
5
6
Number bids

Figure 10: Performance resource allocation problems.

684

7

8

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

problem modeled DisCSP follows (Leaute & Faltings, 2009). One
agent introduced bidder/airline resource/slot, assuming
resource controller different resource provider/airport2 . resource X,
bidder B requests resource, one binary variable xb controlled
resource provider, models whether B allocated
P resource (xb = 1)
(xb = 0). resource provider also expresses one constraint
1 variables
enforce resource allocated one interested bidders.
variable xb , also introduce one copy variable bx owned bidder B,
constraint xb = bx . bidder B expresses constraint variables,
enforcing allocated two resources correspond exactly one
requests. introduction copy variables motivated DisCSP assumption
agent knows constraints involving variables, serves two privacy-related
purposes: 1) full list agents placing requests given resource known
resource provider, 2) full list resources requested given agent (and
bundles) known agent itself. Like meeting scheduling problem class,
inter-agent constraints equality constraints, therefore report performance
P3/2 -DPOP(+) , whose privacy guarantees P-DPOP(+) .
MPC-DisCSP4, DisCSP formulation simplified introducing copy
variables hold bidders, since necessary protect constraint privacy: bidders
request resources expressing constraints directly variables owned
resource providers. However, since MPC-DisCSP4 assumes variables public,
order increase topology privacy introduced, resource, many variables
bidders, regardless whether actually interested resource. reduce
size search space, assumed 1 constraints public.
Figure 10 shows performance MPC-DisCSP4 decreases fast
number requests, algorithm able scale beyond problems
size 4. P2 -DPOP(+) algorithms seem scale better, able solve problems
involving 5 requests. three metrics, algorithms largely outperformed
P-DPOP(+) , whose runtime curve remarkably flat, almost overlaps runtime
curve DPOP, consistent undistinguishable induced width curves.
overhead P-DPOP(+) compared DPOP slightly larger terms information
exchanged, goes one order magnitude terms number messages. PDPOP+ P2 -DPOP+ performed respective non-plus variants.
6.4 Strategic Game Equilibria
Finally, report experimental results one last class problem benchmarks,
corresponds distributed computation pure Nash equilibria strategic games.
used particular example party game introduced Singh et al. (2004),
one-shot, simultaneous-move, graphical game (Kearns, Littman, & Singh, 2001)
players invited common party, players possible strategies whether
attend party not. Players arranged undirected social graph,
defines invitees player knows. players reward attending
2. CATS assumes single auctioneer, specify slot airport;
assumed resource provided separate resource provider.

685

fiLeaute & Faltings

party depends whether acquaintances also decide attend, whether
likes not. reward 1 per attendee likes, minus 1 per attendee dislikes,
minus constant cost attendance [0, 1]. reward attending 0.
problem computing Nash equilibrium game formulated
DisCSP follows. player agent, owns one binary variable
strategy, one copy variable strategy acquaintances. variable
constrained equal copy variables, using binary equality constraints like
resource allocation problems (Section 6.3). agent also expresses one constraint
variables, allows particular strategy agent best response
neighbors joint strategies. Notice resulting constraint graph
game graph, due presence copy variables. solution DisCSP therefore
yields joint strategy profile players pure Nash equilibrium, since
player plays best-response neighbors. Notice also that, since player holds copy

Simulated time (in ms)

106

Induced width

10
9

105

8

104

P2 -DPOP(+)

7

MPC

6

P-DPOP

103

(+)

5
4

DPOP

3

2

10

2
1

10

1
2

3

4
5
6
Number players

7

2

Number messages

105

3

4
5
6
Number players

7

Information exchanged (in bytes)

108
107

104

106
3

10

105
102

101

104

2

3

4
5
6
Number players

103

7

2

3

4
5
6
Number players

Figure 11: Performance party games.

686

7

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

variable neighbors strategy, strategies semi-private information
cannot protected, report performance P3/2 -DPOP(+) .
MPC-DisCSP4, DisCSP formulation simplified introducing copy
variables (Vickrey & Koller, 2002). interesting consequence difference that,
contrary P1 -DPOP(+) , MPC-DisCSP4 able hide players chosen strategy
neighbors. context party game, useful players
decide attend party, since necessarily eventually discover whether
acquaintances also decided attend not. hand, player declines
invitation directly discover anything list attendees. might still
able make indirect inferences decisions acquaintances, based
fact decision decline best response respective chosen strategies.
Figure 11 reports performance algorithms random acyclic game graphs
degree 2 (i.e. trees node 2 children), varying numbers
players. P2 -DPOP(+) algorithms able scale problems size 5
due rapidly increasing induced width, outperformed MPC-DisCSP4
least one order magnitude across three metrics. algorithms still performed
largely worse P-DPOP(+) algorithms, capable scaling much larger
problems. because, setting, induced width remains bounded: since
game graphs acyclic, DPOPs induced width constantly equal 2,
FEAS message sent agent ax parent agent ay expressed ay strategy
variable copy ax strategy variable held ay . P-DPOP(+) induced width
increased 2 agent ay 2 children pseudo-tree, using
different codename ay strategy variable. result, performance overhead
P-DPOP(+) compared DPOP minimal terms runtime; slightly larger
information exchanged, reaches one order magnitude number messages.

7. Conclusion
paper, addressed issue providing strong privacy guarantees Distributed Constraint Satisfaction Problems (DisCSPs). defined four types information problem agents might want hide other: agent privacy
(hiding agents identity non-neighbors), topology privacy (keeping topology
constraint graph private), constraint privacy (protecting knowledge constraints), decision privacy (the final value variable known
owner agent). Departing previous work literature, addressed
subsets privacy types, often focused quantifying privacy loss various algorithms, proposed set algorithms strong guarantees
information provably leaked.
carried performance experiments four different classes benchmarks:
graph coloring, meeting scheduling, resource allocation, game equilibrium computation.
results show algorithms provide stronger privacy guarantees, also
scale better previous state art. explored tradeoff
privacy performance: P-DPOP+ variant shown scale much better
others, guarantee partial constraint decision privacy, may still
considered sufficient many problem classes. Full decision privacy (P3/2 -DPOP+ ) full
687

fiLeaute & Faltings

constraint privacy (P2 -DPOP+ ) come significantly higher prices computation time
information exchange, which, todays hardware, limits applicability smaller
problem instances. compared performance algorithms MPCDisCSP4 algorithm, considered previous state art DisCSP
strong privacy guarantees. first three classes benchmarks, algorithms
almost systematically outperformed MPC-DisCSP4 terms runtime number
messages exchanged; however, MPC-DisCSP4 proved exchange less information
P>1 -DPOP+ . game equilibrium computation, MPC-DisCSP4 scaled much better
P2 -DPOP+ along three metrics, still largely outperformed P-DPOP+ .
terms practical applicability, shown algorithms scale mediumsize problems beyond reach previous state art general DisCSP
strong privacy guarantees. also investigated application algorithms
real-life meeting scheduling, collaboration Nokia Research Center Lausanne.
Future work could extend techniques paper along several directions. First,
restricted pure satisfaction problems sake simplicity,
algorithms easily extended solve Distributed Constraint Optimization Problems (DCOPs). fact, P<2 -DPOP+ algorithms already optimization algorithms;
P2 -DPOP+ requires changes applied DCOPs. changes involve
replacing ElGamal-encrypted Boolean feasibility values ElGamal-encrypted, bit-wise
vector representations integer cost values, described Yokoo Suzuki (2002).
would incur increase complexity linear upper bound cost
optimal solution. optimization variant MPC-DisCSP4, called MPC-DisWCSP4,
also already proposed Silaghi Mitra (2004); report performance comparisons
algorithms publications (Leaute & Faltings, 2011; Leaute, 2011).
avenues future research could result relaxing assumption agents
honest, curious. number challenging issues arise attempting apply
techniques paper self-interested agents manipulate protocol
order achieve solutions better suit selfish preferences. One issue
verifiability, involves making possible check whether protocols executed
designed, without need decrypt messages exchanged. Another interesting issue
whether possible modify algorithms make incentive-compatible,
agents best interest honestly follow protocol.

Appendix A. Cooperative ElGamal Homomorphic Encryption
Homomorphic encryption crucial building block privacy-preserving algorithms
introduced paper. Encryption process message appendix,
Boolean turned cyphertext, way decrypting cyphertext
retrieve initial cleartext message impossible (or, case, computationally
hard worst case) without knowledge secret encryption key used
produce cyphertext. encryption scheme said homomorphic possible
perform operations cyphertexts translate operations initial cleartext
messages, without need know encryption key. ElGamal encryption (Elgamal,
1985) one encryption scheme possesses homomorphic property.
688

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

A.1 Basic ElGamal Encryption Booleans
ElGamal encryption used encrypt Booleans performing following
operations encrypted Booleans possible without knowledge decryption key:
encrypted cleartext Boolean;
two encrypted Booleans.
ElGamal encryption homomorphic, public key cryptography system based
intractability Diffie-Hellman problem (Tsiounis & Yung, 1998), proceeds
follows. Let p safe prime form 2rt + 1, r large random number,
large prime. numbers computations modulo p. Let g generator
Zp , i.e. g powers cover [1, p 1]. p g assumed public knowledge,
ElGamal private key chosen random number x [1, p 2], associated public
key = gx . cleartext number encrypted follows:
E(m) = (, ) = (my r , gr )

(1)

r random number chosen encryptor. Decryption proceeds follows:
r

=
=m.
x
(gr )x
useful feature ElGamal encryption allows randomize encrypted value
generate new encryption bearing similarity original value. Randomizing
E(m) Eq. (1) yields:








E 2 (m) = (y r , g r ) = (my r+r , gr+r )
still decodes m. encrypt Booleans, represent false 1, true
value z 6= 1, allows us compute operations:
E(m) true = E 2 (m) ;

E(m) false = E(1)

E(m1 ) E(m2 ) = (1 2 , 1 2 ) = E(m1 m2 ) .
A.2 Cooperative ElGamal Encryption
previous ElGamal encryption scheme, decryption performed single step,
using private key, secret agent originally encrypted message.
However, also possible perform ElGamal encryption way agents
need cooperate order perform decryption. possible use
compound ElGamal key (x, y) generated cooperatively agents (Pedersen, 1991):
Distributed Key Generation ElGamal key pairs (xi , yi ) n agents combined following fashion obtain compound key pair (x, y):
x = ni=1 xi

= ni=1 yi .

Distributed Decryption agent publishes decryption share xi , message
decrypted follows:


= x =m.
ni=1 xi

689

fiLeaute & Faltings

Appendix B. Routing Messages along Circular Variable Ordering
order implement round-robin exchange vectors briefly presented Section 4.1,
variables ordered along circular ordering mapped chosen pseudo-tree,
illustrated Figure 5 (page 675) . variable needs able send message
previous variable (i.e. clock-wise) ordering, challenge
neighboring variables communicate directly. Furthermore, protect agent
topology privacy, agent know overall circular ordering. solve issue,
Algorithm 9 algorithm used P2 -DPOP (Leaute & Faltings, 2009) route messages.
Algorithm 9 Sending message clock-wise circular variable ordering.
Procedure: ToPrevious(M ) variable x
1: x root pseudo-tree Send message (LAST, ) xs last child
2: else Send message (PREV, ) xs parent
Procedure: RouteMessages() variable x
3: loop
4:
Wait incoming message (type, ) neighbor yi
5:
type = LAST
6:
x leaf Deliver message x
7:
else Send message (LAST, ) xs last child
8:
else type = PREV
9:
yi xs first child Deliver message x
10:
else Send message (LAST, ) child yi xs list children
Consider instance message agent a(x1 ) wants send previous
variable x4 , a(x1 ) know it. Agent a(x1 ) wraps PREV
message sends parent variable x4 (line 2). sender variable x1
x4 first (and only) child, a(x4 ) infers deliver (line 9). Consider
a(x4 ) wants forward previous variable x5 , a(x4 )
know. Like before, a(x4 ) sends message (PREV, ) parent variable x3 ,
reacts sending message (LAST, ) last child preceding x4 list children,
x5 (line 10). LAST messages indicate payload delivered
last leaf current subtree (line 7); therefore, a(x5 ) delivers (line 6) since
children. root wants send message previous variable, also uses
LAST message forward last leaf overall pseudo-tree (line 1).
Theorem 17. Algorithm 9 guarantees full agent privacy.
Proof. goal algorithm precisely address agent privacy issues pseudotree rerooting procedure, involves variable sending message previous
variable circular ordering variables. guarantee exist
circular ordering two consecutive variables owned neighboring agents,
necessary protect agent privacy. Therefore, Algorithm 9 responsible routing
messages paths involve communication neighboring agents.
routing procedure involves encapsulating routed messages inside
PREV LAST messages, contain payload. Therefore, long
690

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

routed messages contain information used identify nonneighboring agent, routing procedure guarantees agent privacy.
Theorem 18. Algorithm 9 guarantees full topology privacy.
Proof. purpose algorithm enable variables propagate messages along
circular variable ordering, without need know topological information
constraint graph, knowledge respective (pseudo-)parents
(pseudo-)children pseudo-tree. ToPrevious() makes possible send message
previous variable circular ordering, without knowing variable is.
reception (PREV, ) message indicates sender child wants
included message delivered previous variable, either
recipient PREV message, unknown descendant thereof.
reception (LAST, ) message ones parent indicates unknown
variable (either unknown root pseudo-tree, unknown child
unknown ancestor, another branch) wants delivered previous variable,
ones descendant pseudo-tree.

References
Ben-Or, M., Goldwasser, S., & Wigderson, A. (1988). Completeness theorems noncryptographic fault-tolerant distributed computation (extended abstract). Proceedings Twentieth Annual ACM Symposium Theory Computing (STOC88),
pp. 110.
Bilogrevic, I., Jadliwala, M., Hubaux, J.-P., Aad, I., & Niemi, V. (2011). Privacy-preserving
activity scheduling mobile devices. Proceedings First ACM COnference
Data Application Security PrivacY (CODASPY11), pp. 261272.
Brito, I., & Meseguer, P. (2003). Distributed forward checking. Proceedings
Ninth International Conference Principles Practice Constraint Programming
(CP03), Vol. 2833 Lecture Notes Computer Science, pp. 801806.
Brito, I., & Meseguer, P. (2007). Distributed forward checking may lie privacy.
Proceedings Ninth International Workshop Distributed Constraint Reasoning
(CP-DCR07).
Brito, I., & Meseguer, P. (2010). Cluster tree elimination distributed constraint optimization quality guarantees. Fundamenta Informaticae, 102, 263286.
Chechetka, A., & Sycara, K. (2006). No-commitment branch bound search distributed constraint optimization. Proceedings Fifth International Joint Conference Autonomous Agents Multiagent Systems (AAMAS06), pp. 1427
1429.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
691

fiLeaute & Faltings

Doshi, P., Matsui, T., Silaghi, M.-C., Yokoo, M., & Zanker, M. (2008). Distributed private
constraint optimization. Proceedings 2008 IEEE/WIC/ACM International
Conference Intelligent Agent Technology (IAT08), pp. 277281.
Elgamal, T. (1985). public key cryptosystem signature scheme based discrete
logarithms. IEEE Transactions Information Theory, 31 (4), 469472.
Faltings, B., Leaute, T., & Petcu, A. (2008). Privacy guarantees distributed constraint satisfaction. Proceedings 2008 IEEE/WIC/ACM International Conference Intelligent Agent Technology (IAT08), pp. 350358.
Franzin, M. S., Freuder, E. C., Rossi, F., & Wallace, R. J. (2004). Multi-agent constraint
systems preferences: Efficiency, solution quality, privacy loss. Computational
Intelligence, 20 (2), 264286.
Gentry, C. (2009). Fully homomorphic encryption using ideal lattices. Proceedings
Forty-first Annual ACM Symposium Theory Computing (STOC09), pp. 169
178. ACM Special Interest Group Algorithms Computation Theory (SIGACT).
Gershman, A., Meisels, A., & Zivan, R. (2006). Asynchronous forward-bounding distributed constraints optimization. Proceedings Seventeenth European Conference Artificial Intelligence (ECAI06), pp. 103107.
Goldreich, O. (2009). Foundations Cryptography, Vol. 2, Basic Applications. Cambridge
University Press.
Greenstadt, R., Grosz, B., & Smith, M. D. (2007). SSDPOP: Using secret sharing
improve privacy DCOP. Proceedings Ninth International Workshop
Distributed Constraint Reasoning (CP-DCR07).
Greenstadt, R., Pearce, J. P., & Tambe, M. (2006). Analysis privacy loss distributed
constraint optimization. Proceedings Twenty-First National Conference
Artificial Intelligence (AAAI06), pp. 647653.
Grinshpoun, T., & Meisels, A. (2008). Completeness performance APO algorithm.
Journal Artificial Intelligence Research (JAIR), 33, 223258.
Grubshtein, A., Grinshpoun, T., Meisels, A., & Zivan, R. (2009). Asymmetric distributed
constraint optimization. Proceedings IJCAI09 Distributed Constraint Reasoning Workshop (DCR09), pp. 6074.
Gutierrez, P., & Meseguer, P. (2010). BnB-ADOPT+ several soft arc consistency
levels. Proceedings Nineteenth European Conference Artificial Intelligence
(ECAI10), No. 215 Frontiers Artificial Intelligence Applications, pp. 6772.
Herlea, T., Claessens, J., Preneel, B., Neven, G., Piessens, F., & Decker, B. D. (2001). securely scheduling meeting. Proceedings Sixteenth International Conference
Information Security Trusted information: new decade challenge (SEC01),
International Federation Information Processing (IFIP) Series, pp. 183198.
Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem.
Proceedings Third International Conference Principles Practice
Constraint Programming (CP97), Vol. 1330 Lecture Notes Computer Science,
pp. 222236.
692

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

Kearns, M. J., Littman, M. L., & Singh, S. P. (2001). Graphical models game theory.
Proceedings Seventeenth Conference Uncertainty Artificial Intelligence
(UAI01), pp. 253260.
Kuchcinski, K., & Szymanek, R. (2011). Java library: JaCoP Java constraint programming
solver. http://jacop.osolpro.com/.
Leaute, T. (2011). Distributed Constraint Optimization: Privacy Guarantees Stochastic
Uncertainty. PhD thesis, Ecole Polytechnique Federale de Lausanne (EPFL).
Leaute, T., & Faltings, B. (2009). Privacy-preserving multi-agent constraint satisfaction.
Proceedings 2009 IEEE International Conference PrivAcy, Security, riSk
Trust (PASSAT09), pp. 1725.
Leaute, T., & Faltings, B. (2011). Coordinating logistics operations privacy guarantees. Proceedings Twenty-Second International Joint Conference Artificial
Intelligence (IJCAI11), pp. 24822487.
Leaute, T., Ottens, B., & Szymanek, R. (2009). FRODO 2.0: open-source framework
distributed constraint optimization. Proc. IJCAI09 Distributed Constraint
Reasoning Workshop (DCR09), pp. 160164. http://frodo2.sourceforge.net.
Leyton-Brown, K., Pearson, M., & Shoham, Y. (2000). Towards universal test suite
combinatorial auction algorithms. Proceedings Second ACM Conference
Electronic Commerce (EC00), pp. 6676. ACM Special Interest Group Electronic
Commerce (SIGEcom). http://www.cs.ubc.ca/~kevinlb/CATS.
Maheswaran, R. T., Pearce, J. P., Bowring, E., Varakantham, P., & Tambe, M. (2006).
Privacy loss distributed constraint reasoning: quantitative framework analysis
applications. Autonomous Agents Multi-Agent Systems (JAAMAS), 13 (1),
2760.
Maheswaran, R. T., Tambe, M., Bowring, E., Pearce, J. P., & Varakantham, P. (2004).
Taking DCOP real world: Efficient complete solutions distributed multievent scheduling. Proceedings Third International Joint Conference Autonomous Agents Multiagent Systems (AAMAS04), Vol. 1, pp. 310317. ACM
Special Interest Group Artificial Intelligence (SIGART).
Mailler, R., & Lesser, V. R. (2003). mediation based protocol distributed constraint
satisfaction. Proceedings Fourth International Workshop Distributed Constraint Reasoning (DCR03).
Meisels, A., & Zivan, R. (2003). Asynchronous forward-checking DisCSPs. Proceedings
Fourth International Workshop Distributed Constraint Reasoning (DCR03).
Modi, P. J., Shen, W.-M., Tambe, M., & Yokoo, M. (2005). ADOPT: Asynchronous distributed constraint optimization quality guarantees. Artificial Intelligence, 161,
149180.
Netzer, A., Meisels, A., & Grubshtein, A. (2010). Concurrent forward bounding DCOPs.
Proceedings Twelfth International Workshop Distributed Constraint Reasoning (DCR10), pp. 6579.
693

fiLeaute & Faltings

Pedersen, T. P. (1991). threshold cryptosystem without trusted party (extended abstract). Advances Cryptology EUROCRYPT91, Workshop Theory
Application Cryptographic Techniques, Proceedings, Vol. 547 Lecture Notes
Computer Science, pp. 522526.
Petcu, A., & Faltings, B. (2005). DPOP: Scalable Method Multiagent Constraint
Optimization. Proceedings Nineteenth International Joint Conference
Artificial Intelligence (IJCAI05), pp. 266271.
Petcu, A., Faltings, B., & Parkes, D. C. (2008). M-DPOP: Faithful distributed implementation efficient social choice problems. Journal Artificial Intelligence Research
(JAIR), 32, 705755.
Rassenti, S. J., Smith, V. L., & Bulfin, R. L. (1982). combinatorial auction mechanism
airport time slot allocation. Bell Journal Economics, 13 (2), 402417.
Shamir, A. (1979). share secret. Communications ACM, 22 (11), 612613.
Silaghi, M.-C. (2005a). Hiding absence solution distributed constraint satisfaction
problem (poster). Proceedings Eighteenth International Florida Artificial
Intelligence Research Society Conference (FLAIRS05), pp. 854855.
Silaghi, M.-C. (2005b). Using secure DisCSP solvers generalized Vickrey auctions
complete stochastic techniques. Proceedings IJCAI05 Distributed Constraint Reasoning Workshop.
Silaghi, M.-C., Faltings, B., & Petcu, A. (2006). Secure combinatorial optimization simulating DFS tree-based variable elimination. Proceedings Ninth International
Symposium Artificial Intelligence Mathematics.
Silaghi, M.-C., & Mitra, D. (2004). Distributed constraint satisfaction optimization
privacy enforcement. Proceedings 2004 IEEE/WIC/ACM International
Conference Intelligent Agent Technology (IAT04), pp. 531535.
Silaghi, M.-C., Sam-Haroud, D., & Faltings, B. (2000). Asynchronous search aggregations. Proceedings Seventeenth National Conference Artificial Intelligence Twelfth Conference Innovative Applications Artificial Intelligence
(AAAI/IAAI00), pp. 917922.
Singh, S., Soni, V., & Wellman, M. P. (2004). Computing approximate Bayes-Nash equilibria
tree-games incomplete information. Proceedings Fifth ACM Conference
Electronic Commerce (EC04), pp. 8190.
Sultanik, E. A., Lass, R. N., & Regli, W. C. (2007). DCOPolis: framework simulating
deploying distributed constraint optimization algorithms. Proceedings
Ninth International Workshop Distributed Constraint Reasoning (CP-DCR07).
Tsiounis, Y., & Yung, M. (1998). security Elgamal-based encryption. Proceedings First International Workshop Practice Theory Public Key
Cryptography (PKC98), Vol. 1431 Lecture Notes Computer Science, pp. 117134.
Vickrey, D., & Koller, D. (2002). Multi-agent algorithms solving graphical games. Proceedings Eighteenth National Conference Artificial Intelligence (AAAI02),
pp. 345351.
694

fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making

Vinyals, M., Rodrguez-Aguilar, J. A., & Cerquides, J. (2010). Constructing unifying
theory dynamic programming DCOP algorithms via generalized distributive
law. Autonomous Agents Multi-Agent Systems (JAAMAS), 22 (3), 439464.
Wallace, R. J., & Freuder, E. C. (2005). Constraint-based reasoning privacy/efficiency
tradeoffs multi-agent problem solving. Artificial Intelligence, 161 (12), 209227.
Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: asynchronous branch-andbound DCOP algorithm. Journal Artificial Intelligence Research (JAIR), 38, 85
133.
Yokoo, M. (1995). Asynchronous weak-commitment search solving distributed constraint
satisfaction problems. Proceedings First International Conference Principles Practice Constraint Programming (CP95), No. 976 Lecture Notes
Computer Science, pp. 88102.
Yokoo, M., Durfee, E. H., Ishida, T., & Kuwabara, K. (1992). Distributed constraint satisfaction formalizing distributed problem solving. Proceedings Twelfth
International Conference Distributed Computing Systems (ICDCS92), pp. 614
621.
Yokoo, M., & Suzuki, K. (2002). Secure multi-agent dynamic programming based homomorphic encryption application combinatorial auctions. Proceedings
First International Joint Conference Autonomous Agents Multi-Agent
Systems (AAMAS02), pp. 112119.
Yokoo, M., Suzuki, K., & Hirayama, K. (2002). Secure distributed constraint satisfaction:
Reaching agreement without revealing private information. Proc. 8th Intl. Conf.
Principles Practice Constraint Prog. (CP02), Vol. 2470 LNCS, pp. 387401.
Yokoo, M., Suzuki, K., & Hirayama, K. (2005). Secure distributed constraint satisfaction:
Reaching agreement without revealing private information. Artificial Intelligence,
161 (12, Distributed Constraint Satisfaction), 229245.
Zivan, R., & Meisels, A. (2004). Concurrent dynamic backtracking distributed CSPs.
Proceedings Tenth International Conference Principles Practice
Constraint Programming (CP04), Vol. 3258 Lecture Notes Computer Science,
pp. 782787.

695

fiJournal Artificial Intelligence Research 47 (2013) 157-203

Submitted 11/12; published 05/13

Survey Latent Tree Models Applications
Raphael Mourad

raphael.mourad@aliceadsl.fr

LINA, UMR CNRS 6241,
Ecole Polytechnique de lUniversite de Nantes
Nantes, Cedex 3, 44306 France

Christine Sinoquet

christine.sinoquet@univ-nantes.fr

LINA, UMR CNRS 6241, Universite de Nantes
Nantes, Cedex, 44322 France

Nevin L. Zhang
Tengfei Liu

lzhang@cse.ust.hk
liutf@cse.ust.hk

Department Computer Science & Engineering, HKUST
Clear Water Bay Road, Kowloon, Hong Kong

Philippe Leray

philippe.leray@univ-nantes.fr

LINA, UMR CNRS 6241,
Ecole Polytechnique de lUniversite de Nantes
Nantes, Cedex 3, 44306 France

Abstract
data analysis, latent variables play central role help provide powerful
insights wide variety phenomena, ranging biological human sciences.
latent tree model, particular type probabilistic graphical models, deserves attention.
simple structure - tree - allows simple efficient inference, latent variables
capture complex relationships. past decade, latent tree model subject
significant theoretical methodological developments. review, propose
comprehensive study model. First summarize key ideas underlying model.
Second explain efficiently learned data. Third illustrate use
within three types applications: latent structure discovery, multidimensional clustering,
probabilistic inference. Finally, conclude give promising directions future
researches field.

1. Introduction
statistics, latent variables (LVs), opposed observed variables (OVs), random
variables directly measured. wide range statistical models, called latent
variable models, relate set OVs set LVs. models, LVs explain
dependences among OVs hence offer compact intelligible insights data. Moreover
LVs allow reduce data dimensionality generate conditionally independent variables,
considerably simplifies downstream analysis. Applications numerous cover
many scientific fields. typically case domains psychology, sociology,
economics, also biological sciences artificial intelligence, cite examples.
fields may need complex constructs cannot observed directly. instance,
human personality psychology social class socio-economics refer higher level
abstractions observed reality.
c
2013
AI Access Foundation. rights reserved.

fiMourad, Sinoquet, Zhang, Liu, & Leray

1.1 Context
Latent tree model (LTM)1 class latent variable models received considerable attention. LTM probabilistic tree-structured graphical model leaf nodes
observed internal nodes either observed latent. model appealing
since simple structure - tree - allows simple efficient inference, latent
variables capture complex relationships.
subclass LTMs first developed phylogenetic community (Felsenstein,
2003). context, leaf nodes observed taxa internal nodes represent unobserved taxum ancestors. instance, molecular genetic evolution, process
evolution DNA scale, obviously hopeless study DNA sequences dead
species collecting DNA. Nevertheless, evolutionary latent models used
infer probable ancestral sequences knowing contemporary living species sequences.
Neighbor joining represents one first algorithms developed LTM learning
phylogenetic context (Saitou & Nei, 1987; Gascuel & Steel, 2006). still popular
quick compute allows find optimal model polynomial time
certain assumptions.
past decade, LTMs general form extensive investigation applied many fields. instance applied human
interaction recognition. Human interaction recognition challenging task,
multiple body parts concomitant inclusions (Aggarwal & Cai, 1999). purpose,
use LTM allows segment interaction multi-level fashion (Park & Aggarwal,
2003): body part positions estimated low-level LVs, overall body position
estimated high-level LV. LTMs also used medical diagnosis (Zhang,
Yuan, Chen, & Wang, 2008). context, LTMs provide way identify,
LVs, different syndrome factors cannot directly observed physician.
1.2 Contributions
paper, present comprehensive study LTM broad-brush view recent
theoretical methodological developments. LTM must paid attention (i)
offers deep insights latent structure discovery (Saitou & Nei, 1987), (ii) applied
multidimensional clustering (Chen, Zhang, Liu, Poon, & Wang, 2012) (iii) allows
efficient probabilistic inference (Wang, Zhang, & Chen, 2008). Somewhat surprisingly,
extensive review research area published.
addition reviewing LTM research area, also contribute analysis
perspective advance understanding subject. establish categorization
learning methods. present generic learning algorithms implementing fundamental
principles. generic algorithms partly different literature
adapted broader context. Besides, performances algorithms
literature compared context small, large large simulated
real datasets. Finally, discuss future directions, adaptation LTM
continuous data.
1. LTM previously called hierarchical latent class model (Zhang, 2004), name
discarded model inherently reveal hierarchy.

158

fiLatent Tree Models

Figure 1: Illustration graph theory terminology.

1.3 Paper Organization
paper organized follows. Section 2 presents latent tree model related
theoretical developments. Section 3, review methods developed learn latent tree
models two main situations: learning structure known learning
case. Then, Section 4 presents details three types applications latent tree
models: latent structure discovery, multidimensional clustering probabilistic inference.
applications classification also discussed. Finally, last two sections 5
6 conclude point future directions.

2. Theory
section, first introduce graph terminology present LTM. Latent classes
probabilistic inference clustering next presented. Scoring LTMs discussed.
also present concepts marginal equivalence, equivalence model parsimony, useful
LTM learning. Then, explain necessity trade-off latent variable
complexity partial structure complexity.
Variables denoted capital letters, e.g. A, B C, whereas lower-case letters
refer values variables take, e.g. a, b c. Bold-face letters represent sets
objects, A, B C sets variables a, b c value sets.
observed variable denoted X whereas latent variable denoted H. variable
know observed latent denoted V .
2.1 Graph Theory Terminology
presenting LTM, first need define graph-related terms, illustrated
Figure 1. graph G(V, E) composed set nodes V set edges E V V.
edge pair nodes (Va , Vb ) E. edge undirected (noted Va Vb ) (Vb , Va ) E
directed (noted Va Vb ) not.
159

fiMourad, Sinoquet, Zhang, Liu, & Leray

Figure 2: (a) Directed tree. (b) Undirected tree. light shade (blue) indicates
observed variables whereas dark shade (red) points latent variables.

directed graph graph whose edges directed. directed graph, node
Va parent node Vb exists edge Va Vb . node Vb
called child node Va . Nodes siblings share parent. node
Vc root parent. directed path node Vd node Va sequence
nodes node except last one, edge next node
sequence. node Va descendant node Vd directed path
Vd Va . node Vd called ancestor node Va .
undirected graph contains undirected edges. undirected graph, node Va
neighbor another node Vb edge them. leaf
node one neighbor. internal node node least two neighbors.
undirected path path edges oriented direction.
clique set pairwise connected nodes (in tree, clique simply edge).
separator set nodes whose removal disconnect two cliques (in tree,
separator simply internal node). tree graph two nodes
connected exactly one path.
2.2 Latent Tree Model
LTM tree-structured graphical model latent variables. composed tree structure - (V, E), set parameters, . tree either directed (i.e.
Bayesian network; Zhang, 2004) undirected (i.e. Markov random field; Choi, Tan,
Anandkumar, Willsky, 2011). representations described Figure 2. set
nodes V = {V1 , ..., Vn+m } represents n + observed latent variables. X = {X1 , ..., Xn }
set observed variables H = {H1 , ..., Hm } set latent variables. Leaf
nodes OVs internal nodes either observed latent. Variables either
discrete continuous. set k edges E = {E1 , ..., Ek } captures direct dependences
variables.
directed setting (Figure 2a), set parameters consists probability distributions, one variable. Given variable Vi parents P aVi , conditional
distribution P (Vi |P aVi ) defined. variable Vi parent, marginal distribution P (Vi ) defined instead. joint probability distribution (JPD) model
160

fiLatent Tree Models

formulated as:
n+m
P (V) = i=1
P (Vi |P aVi ).

(1)

illustrate model, let us take example Figure 2a. composed set
OVs {X1 , ..., X7 } set LVs {H1 , H2 }. JPD writes as:
P (X1 , ..., X7 , H1 , H2 ) = P (X1 |H1 ) P (X2 |H1 ) P (X3 |H1 ) P (H1 |X7 ) P (X7 )
P (X4 |X7 ) P (H2 |X7 ) P (X5 |H2 ) P (X6 |H2 ).

(2)

undirected setting (Figure 2b), set parameters consists probability
distributions, one clique separator. LTM, cliques edges separators
internal nodes. Let {I1 , ..., Ij } separators. JPD model formulated
as:
(V ,V )E P (Va , Vb )
,
(3)
P (V) = b
j=1 P (Ij )(d(Ij )1)
d(Ij ) degree internal node Ij . JPD undirected model Figure
2b writes as:
P (X1 , H1 ) P (X2 , H1 ) P (X3 , H1 ) P (H1 , X7 ) P (X4 , X7 )
P (H1 ) P (H1 ) P (H1 ) P (X7 )
P (X7 , H2 ) P (X5 , H2 ) P (X6 , H2 )

.
P (X7 ) P (H2 ) P (H2 )

P (X1 , ..., X7 , H1 , H2 ) =

(4)

following, seek simplicity, restrain study categorical variables,
i.e. random variables finite number states. also mainly focus LTM
whose internal nodes LVs. works LTM developed two
model settings.
2.3 Latent Classes Clustering
LV number states, representing latent class. latent classes
together represent soft partition data define finite mixture model (FMM).
LTM seen multiple FMMs connected form tree. Given data point,
probability belonging particular class computed using Bayes formula.
computation called class assignment.
LTM, LV Hj represents partition data. observation `
vector values x` = {x`1 , ..., x`n } set OVs X, probability membership
class c LV Hj computed follows:
P (x` |Hj = c) P (Hj = c)
P (x` )
P
0
`
0 P (x , H |Hj = c) P (Hj = c)
= Pk HP
0
`
c=1
H0 P (x , H |Hj = c) P (Hj = c)

P (Hj = c|x` ) =

(5)

H0 = H\{Hj } k cardinality Hj . last formula, reader might get
impression complexity class assignment exponential. However, trees,
161

fiMourad, Sinoquet, Zhang, Liu, & Leray

linear2 - thus efficient - probabilistic inference, using message passing (Kim & Pearl, 1983),
used compute P (Hj = c|x` ).
Probabilistic inference LV values two applications: clustering latent data
imputation. Clustering using LTMs illustrated seen detail Section 4.2.
Latent data imputation process inferring, observation `, values
LVs. variables called imputed LVs. Section 3.2.2, see latent data
imputation basis fast variable clustering-based LTM learning methods.
2.4 Scoring Latent Tree Models
theory, every score, Akaike information criterion (AIC) (Akaike, 1970)
Bayesian information criterion (BIC) (Schwartz, 1978), could used scoring
LTMs. practice, BIC score often used LTMs. Let consider set n OVs
X = {X1 , ..., Xn } collection N identical independently distributed (i.i.d.)
observations Dx = {x1 , ..., xN }. BIC composed two terms:
1
BIC(T, Dx ) = log P (Dx | L , ) dim(T ) log N,
2

(6)

L maximum likelihood parameters, dim(T ) model dimension N
number observations. first term evaluates fit model data.
computed probabilistic inference P (x` ) observation `. second term
score penalizes model according dimension, prevent overfitting.
models without latent variables, dimension simply calculated number
free parameters. sometimes called standard dimension. LVs present,
standard dimension longer appropriate measure model complexity, effective
dimension used instead (Geiger, Heckerman, & Meek, 1996). Effective dimension
computed rank Jacobian matrix mapping model parameters
OV joint distribution.
2.5 Model Parsimony
Let us consider two LTMs, = (T, ) M0 = (T 0 , 0 ), built set n
OVs, X = {X1 , ..., Xn }. say M0 marginally equivalent joint
distributions OVs equal:
P (X1 , ..., Xn |T, ) = P (X1 , ..., Xn |T 0 , 0 ).

(7)

two marginally equivalent models dimension, equivalent models.
model parsimonious3 exist another model M0
marginally equivalent smaller dimension. parsimonious model best
possible score. contain redundant LVs redundant latent classes.
represents model infer data. Two conditions ensure LTM
include redundant LVs (Pearl, 1988):
2. Actually, trees, inference linear number edges |E|, thus also linear number
n + observed latent variables, |E| n + 1.
3. notion parsimony also called minimality Pearl (1988).

162

fiLatent Tree Models

Figure 3: Illustration trade-off latent variable complexity partial structure complexity latent tree models. Superscript represents LV cardinality. See
Figure 2 node color code.

LV must least three (observed latent) neighbors. two
neighbors, simply replaced direct link two.
two variables connected edge LTM neither perfectly dependent
independent.
also condition ensuring LTM include redundant latent
classes. Let H LV LTM. set k variables Z = {Z1 , ..., Zk }
neighbors H. LTM regular (Zhang, 2004) LV H:
|H|

ki=1 |Zi |
.
maxki=1 |Zi |

(8)

Zhang (2004) showed parsimonious models necessarily regular. Thus
model search restricted space regular models. Zhang also demonstrated
2
space regular models upper bounded 23n , n number OVs.
2.6 Trade-off Latent Variable Complexity Partial Structure
Complexity
Zhang Kocka (2004b) distinguished two kinds model complexity LTM: latent
variable complexity refers LV cardinalities partial structure complexity4
4. paper, Zhang Kocka (2004b) called structure complexity. better understanding,
prefer make distinction (complete) structure includes LV cardinalities partial
structure not.

163

fiMourad, Sinoquet, Zhang, Liu, & Leray

edges number LVs graph. trade-off two complexities
important role play one wants choose model. trade-off illustrated
Figure 3. instance, let us consider latent class model (i.e. model one
LV, abbreviated LCM) versus LTM marginal likelihood (marginally
equivalent models). LCM model showing highest LV complexity
lowest partial structure complexity. might low score local dependences
present OVs. opposite, model low LV complexity high
partial structure complexity, binary tree binary LVs, would also low score,
LVs would unnecessary. Depending application, model showing
good trade-off two complexities preferred, would present
better score might easier interpret.

3. Statistical Learning
section, present generic algorithms implementing fundamental principles learning LTMs. algorithms partly different proposed literature,
adapted broader context. Moreover provide unified presentation algorithms, context survey. learning model data,
two main situations distinguished: structure known parameters
learned, complicated situation unknown.
3.1 Known Structure
simplest situation, structure known, i.e. dependences variables also number LVs respective cardinalities (i.e. numbers
latent classes). problem estimate probability parameters. solve problem,
one use expectation-maximization (EM), popular algorithm learning parameters face LVs (Dempster, Laird, & Rubin, 1977; Lauritzen, 1995).
EM leads computational burden large LTMs, efficient procedure,
call LCM-based EM, used. methods different EM, spectral
techniques, also developed.
3.1.1 Expectation-maximization
Ideally, learning parameters, would like maximize log-likelihood set
N i.i.d. observed data Dx = {x1 , ..., xN }:
X
L(; Dx ) = log P (Dx |) = log
P (Dx , H|).
(9)
H

However, directly maximizing L(; Dx ) Equation (9) often intractable involves logarithm (large) sum. overcome difficulty, EM implements iterative approach. iteration, optimizes instead following expected log-likelihood
conditional current parameters :
Q(; ) = EDh |Dx ,t [log P (Dx , Dh |)]

(10)

Dx completed missing data Dh = {h1 , ..., hN } inferred using . Note
completing missing data, EM easily deal partially observed variables.
164

fiLatent Tree Models

Algorithm 1 LCM-based EM parameter learning (LCMB-EM, adapted Harmeling
Williams, 2011)
INPUT:
, tree structure LTM.
OUTPUT:
, parameters LTM.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:

0 graph rooting(T ) /* choose LV root */
Ho /* initialization set imputed latent variables */
0
loop
TLCM = {TLCM1 , ..., TLCMk } identif LCM graph(T 0 , Ho )
LCM = {LCM1 , ..., LCMk } EM (TLCM )
|TLCM | > 1
0 0 children parameters(LCM )
else
0 0 children parent parameters(LCM)
break
end
Ho Ho impute LV data(LCM ) /* parents observed */
end loop
EM ( 0 ) /* global EM using 0 starting point */

important drawback EM guarantee reach global optimum.
reduce probability getting trapped local maximum, random restarts (multiple
starts different random initial parameters) simulated annealing represent well-used
solutions. Wang Zhang (2006) showed random restarts suffice LTM
small variables strongly dependent other. Supplemental material
B.1, also present experiments random restarts EM. appears
possible give simple answer many restarts used depends
model. Besides, convergence sometimes reached even large number
restarts.
3.1.2 LCM-based EM
Although inference linear LTMs, running EM might prohibitive. One solution
speed EM computations consists chaining two steps: first step divide-andconquer strategy local - LCM - learning, followed final step carrying global
learning. LCM-based EM (LCMB-EM) parameter learning method5 presented
Algorithm 1 illustrated Figure 4. first step, parameters locally learned
bottom-up LCM-based learning procedure explained follows. LV first
5. learning procedure similar one proposed binary trees Harmeling Williams
(2011).

165

fiMourad, Sinoquet, Zhang, Liu, & Leray

Figure 4: Illustration LCM-based EM parameter learning algorithm (adapted
Harmeling Williams, 2011). See Figure 2 node color code.

chosen root LTM (line 1; note point discussed detail
Section 3.2.5). rooted LTM, every LCM {X, H} identified (line 5), i.e. every LV
H whose children OVs X. Then, LCM parameters quickly learned
EM (line 6) used update current LTM parameters (lines 7 12). parameters
learned LCM, distributions unknown values LV H
probabilistically inferred observation6 (line 13; details, see Section 2.3,
paragraph 2). distributions used weighted observations. turn,
weighted observations seed learning processes LCMs (now
observed) LVs Ho remaining OVs used LCM learning yet.
Iterating two operations (LCM learning latent data imputation) leads bottomup LCM-based EM procedure enabling local fast parameter learning LTMs. Finally,
LTM parameters refined global EM using starting point locally learned
parameters (line 15). EM, also provide results experiments evaluating
efficiency random restarts (see Supplemental material B.1). results show
LCMB-EM converges better EM. However convergence achieved largest
dataset studied.
3.1.3 Spectral Methods
Recently, Parikh et al. (2011) applied spectral techniques LTM parameter learning.
method directly estimates joint distribution OVs without explicitly recovering
6. recall process named latent data imputation.

166

fiLatent Tree Models

LTM parameters. algorithm useful LTM parameters required,
instance, probabilistic inference OVs only. work Parikh et al. alleviates
restriction approach Mossel et al. (2006) requiring conditional probability
tables invertible, generalizes method Hsu et al. (2009) specific
hidden Markov models.
Parikh et al. (2011) reformulated message passing algorithm using algebraic
formulation:
X
n+m
P (x) =
i=1
P (vi |P avi )
H
>

= r (Mj1 Mj2 ... MjJ 1r ),

(11)

x = {x1 , ..., xn } observation, Xr root, r marginal probability vector
root Mj1 , Mj2 , ..., MjJ incoming message matrices roots children.
Children message matrices calculated similar manner:
1 (Mj1 Mj2 ... MjJ 1i ),
Mi = Ti

(12)

Xi root child, Mi outgoing message matrix Xi , Ti third order tensor related conditional probability matrix Xi P aXi (i.e. Xr ),
1 mode-1 vector
Mj1 , Mj2 , ..., MjJ Xi children incoming messages
product. original message passing algorithm, messages recursively
calculated starting leaves going root.
drawback previous representation message passing still needs model
parameters. tackle issue, key recover P (x) using invertible transformations.
Message matrices calculated transforming message Mj two invertible
matrices Lj Rj (Lj R1
j = I):
1
1
1
1 (Lj1 L1
Mi = Ti
j1 Mj1 Rj1 Lj2 Mj2 Rj2 ... LjJ MjJ RjJ RjJ 1i ).

(13)

matrices Lj , Mj Rj recovered singular vectors Uj empirical
probability matrices P (Xj , Xj ) OVs Xj left neighbor OV Xj . leads
efficient computation message passing involving sequence singular value
decompositions empirical pairwise joint probability matrices. refer work
Parikh et al. (2011) details singular value decomposition spectral
algorithm. Compared EM, spectral method entail problem getting
trapped local maxima. Moreover, performs comparable better EM
orders magnitude faster.
3.1.4 Methods
methods exist parameter learning. Gradient descent (Kwoh & Gillies, 1996;
Binder, Koller, Russel, & Kanazawa, 1997) variations Gauss-Newton method
(Xu & Jordan, 1996) help accelerate sometimes slow convergence EM. However,
require evaluation first and/or second derivatives likelihood function.
Bayesian learning, variational Bayes (Attias, 1999) offers counterpart EM.
167

fiMourad, Sinoquet, Zhang, Liu, & Leray

3.2 Unknown Structure
Regrettably, time, priori information LTM structure.
compels learn every part model, i.e. number LVs, cardinalities,
dependences parameters. learning task represents challenging issue,
various methods conceived. section, provide survey
algorithms. determination LV cardinalities, well time complexity
scalability algorithms also discussed. end establishing summary relative
learning methods.
Structure learning approaches fall three categories. first one comprised
search-based methods, inspired standard Bayesian network learning. second one
based variable clustering related hierarchical procedures. last category
relies notion distances comes phylogenetics.
3.2.1 Search-based Methods
Search-based methods aim finding model optimal according scoring
metric. BNs without LVs, BIC score often used. context LTM, BIC
suffers theoretical shortcoming pointed Section 2.4. However, empirical
results indicate shortcoming seem compromise model quality practice (Zhang & Kocka, 2004a). So, researchers still use BIC comes learning LTM.
Many search procedures proposed. explore space regular LTMs.
focus on: (i) naive one conceptually simple computationally expensive (ii) advanced one reduces search space
implements fast parameter learning local EM.

Naive Greedy Search
Naive greedy search (NGS) consists starting LCM visiting space
regular LTM partial structures. neighborhood current model explored
greedy search operations addition removal latent node, node
relocation7 . partial structure neighbor, cardinalities LVs optimized
addition dismissal state relative LV. model search (partial
structure LV cardinality), candidate models learned EM evaluated
score. best candidate model shows score superior current model score,
former used seed next step. Otherwise, NGS stops current model
considered best model. Therefore, step search, learning approach
necessitates evaluate score large number candidate models. leads
huge computational burden because, candidate model evaluation, likelihood
computed EM.

7. Node relocation picks child LV grafts child another LV connected
former LV.

168

fiLatent Tree Models

Advanced Greedy Search
Advanced greedy search (AGS) relies three strategies reduce complexity.
Advanced greedy search presented Algorithm 2. First, AGS focuses smaller
space models explore NGS (Zhang & Kocka, 2004b). algorithm performs
partial structure search LV cardinality exploration simultaneously. purpose,
two additional operators used: addition removal latent state LV.
Second, AGS follows grow-restructure-thin strategy reduce complexity
search space (Chen, Zhang, & Wang, 2008; Chen et al., 2012). strategy consists
dividing five operators three groups. group applied given step
model search. First, latent node latent state introduction (NI SI, respectively)
used make current model complex8 (grow, line 3). Then, node relocation
(NR) rearranges connections variables (restructure, line 4). Finally, latent node
latent state deletion (ND SD, respectively) make current model simpler (thin,
line 5).
Third, one needs assess BIC score candidate models. Learning parameters
new models thus required. achieve fast learning, Chen et al. (2008, 2012)
compute likelihood instead so-called restricted likelihood local EM
procedure (line 12). principle relies optimizing parameters variables whose
connection cardinality changed candidate model. Parameters remaining
variables kept identical current model.
Operation Granularity
starting simplest solution (an LCM), Zhang Kocka (2004b) observed
comparison BIC scores candidate model 0 current one
might relevant criterion. problem strategy always leads
increase cardinality LCM, without introducing LVs model (see trade-off
LV complexity partial structure complexity Section 2.6). tackle
issue, propose instead assess so-called improvement ratio grow step:
IRBIC (T 0 , |DX ) =

BIC(T 0 , DX ) BIC(T, DX )
,
dim(T 0 ) dim(T )

(14)

difference BIC scores candidate model 0 current model
divided difference respective dimensions.
3.2.2 Methods Based Variable Clustering
major drawback search-based methods evaluation maximum likelihood
presence LVs, well large space explore local search, still entails
computational burden. Approaches relying variable clustering represent efficient
much faster alternatives. rely two key points: grouping variables identify
LVs constructing model bottom-up strategy. Three main categories
developed, depending structures learned: binary trees, non-binary trees
8. Note node relocation used locally NI increase number children.

169

fiMourad, Sinoquet, Zhang, Liu, & Leray

Algorithm 2 Advanced greedy search LTM learning (AGS, adapted EAST, Chen
et al., 2012)
INPUT:
X, set n observed variables {X1 , ..., Xn }.
OUTPUT:
, respectively tree structure parameters LTM constructed.
1:
2:
3:
4:
5:
6:

(T 0 , 0 ) latent class model(X) /* LCM learning using EM */
loop = 0, 1,... convergence
0
0
(T , ) local search(N SI, , ) /* grow */
0
0
00
00
(T , ) local search(N R, , ) /* restructure */
00
00
(T i+1 , i+1 ) local search(N SD, , ) /* thin */
end loop

7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:

/* description function local search(operators, T, ) */
(T 0 , 0 ) (T, )
loop j = 0, 1,... convergence

= {T1 , ..., T` } neighborhood(operators, j ) j
= {1 , ..., ` }
local EM (T, j ) /* except j */
BIC(T, )/dim(T, ) operators = N SI
j+1 arg maxT
BIC(T, )
otherwise
j+1 EM (T j+1 )
j+1 neighborhood(N I, j )
(T j+1 , j+1 ) local search(N R, j+1 , j+1 )
end
end loop

forests.
Binary Trees
Binary tree learning represents simple situation. instance, one simply compute agglomerative hierarchical clustering (Xu & Wunsch, 2005) learn
LTM structure. algorithm called agglomerative hierarchical cluster-based learning (AHCB). purpose clustering, pairwise mutual information (MI) represents
well-suited similarity measure variables (Cover & Thomas, 1991; Kraskov &
Grassberger, 2009). MI two variables Vi Vj defined follows:
I(Vi ; Vj ) =

X X

p(vi , vj ) log

vi Vi vj Vj

p(vi , vj )
.
p(vi ) p(vj )

(15)

Single, complete average linkage used, depending cluster compactness required.
inferred hierarchy provides binary tree (the partial structure) leaf nodes
170

fiLatent Tree Models

Figure 5: Illustration LCM-based LTM learning procedure set 4 variables
{X1 , X2 , X3 , X4 }.

OVs internal nodes LVs (Wang et al., 2008; Harmeling & Williams, 2011). Then,
LV cardinalities parameters learned (for details, see Section 3.2.4 Section 3.1,
respectively).
AHCB, cluster hierarchy represents LV. MI LV
variables (observed latent) approximated linkage criterion. Instead
approximation, another solution consists directly computing MI variables, whatever status, i.e. observed latent (Hwang, Kim, & Zhang, 2006; Harmeling & Williams, 2011). compute MI, values LVs imputed LCM-based
learning. Algorithm 3 presents LCM-based LTM learning (LCMB-LTM) algorithm9
implementing solution. First, working node set W initialized set OVs
X = {X1 , ..., Xn } (line 1). empty graph created W (line 2). pair
variables showing highest MI, {Wi , Wj }, selected (line 5). LCM ({Wi , Wj }, H)
learned (line 6), allowing locally estimate LV cardinality (through greedy search)
parameters, impute values H (line 7). values H known,
used observed variable (line 8). new step clustering, followed LCM learning
LV value imputation, performed. Iterating step loop allows
construct LTM bottom-up recursive procedure. step procedure,
parameters lcm current LCM used update current parameters 0
LTM (line 10). two nodes remaining, two nodes connected10 (line
12), corresponding parameters learned using maximum likelihood (line 13)
loop broken. constructing LTM, final step globally learns LTM parameters
using 0 starting point (line 17). LCMB-LTM yields slightly better BIC results
AHCB large datasets (Harmeling & Williams, 2011). LCMB-LTM illustrated
set 4 variables {X1 , X2 , X3 , X4 } Figure 5.
Harmeling Williams (2011) justified selecting pair variables showing
highest MI step LCMB-LTM. Let us consider working node set (observed
imputed latent) variables W = {W1 , ..., W` }. step LCMB-LTM, unknown
9. algorithm called LCMB-LTM distinguish LCMB-EM parameter learning (Algorithm
1). algorithms similar rely LCM-based learning.
10. prevents introduction redundant LV, see Section 2.5, second paragraph.

171

fiMourad, Sinoquet, Zhang, Liu, & Leray

Algorithm 3 LCM-based LTM learning (LCMB-LTM, adapted BIN-T, Harmeling
Williams, 2011)
INPUT:
X, set n observed variables {X1 , ..., Xn }.
OUTPUT:
(V, E) , respectively tree structure parameters LTM constructed.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:

W X /* Initialization working set variables */
(V, E) empty tree(W) /* tree W edges */
0
loop
{Wi , Wj } pair highest I(W)
lcm latent class model({Wi , Wj })
H impute LV data(lcm)
W W\{Wi , Wj } H /* remove children add imputed parent */
E E edges(lcm); V V H
0 0 children parameters(lcm)
|W| = 2
E E edge two remaining nodes(W)
0 0 learn remaining parameters(W) /* max likelihood estimation */
break
end
end loop
EM ( 0 ) /* global EM using 0 starting point */

JPD P (W) approximated JPD Q(W):
Q(W) = P (Wi , Wj ) Wk W\{Wi ,Wj } P (Wk )
=

P (Wi , Wj )
Wk W P (Wk ),
P (Wi ) P (Wj )

(16)

Wi Wj dependent. proper measure assess divergence
P (W) Q(W) Kullback-Leibler (KL) divergence, easy calculate
situation:
X
X
KL(P ||Q) =
P (W) log P (W)
P (W) log Q(W)
W

= I(Wi ; Wj ) +

W

X
W

P (W) log

P (W)
,
Wk W P (Wk )

(17)

I(Wi ; Wj ) mutual information Wi Wj . last term constant, maximization KL P Q simply consists selecting pair
variables highest MI introducing LV model construction.

172

fiLatent Tree Models

Non-binary Trees
Although modeling binary trees performs well practice (Harmeling & Williams,
2011), would worth alleviating binarity restriction. Indeed might provide better
model faithfulness interpretation less LVs would required. several
ways learn non-binary trees without necessitating much additional computational
cost. instance, Wang et al. (2008) first learn binary tree. Then, check pair
neighbor LVs tree. information redundant two LVs (i.e.
model parsimonious), LV node child LV node
removed remaining node connected every child removed node. Although
approach Wang et al. rigorous, lead practice find trees
close binary trees.
Another solution consists identifying cliques pairwise dependent variables detect
presence LVs (Martin & Vanlehn, 1995; Mourad, Sinoquet, & Leray, 2011).
purpose, Mourad et al. propose alternate two main steps: (i) agglomerative step,
clique partitioning method used identify disjoint cliques variables; (ii)
clique, containing least two nodes, connected LV LCM.
LCM, parameters learned using EM LV data imputed probabilistic inference. Algorithm 3 (line 5), possible replace selection pair variables
highest MI clique partitioning step clique leads construct
LCM impute corresponding LV values.
Flat Trees
algorithms discussed far section based idea hierarchical
variable clustering. Bridged Island (BI) algorithm Liu et al. (2012) takes slightly
different approach. first partitions set observed variables subsets
called sibling clusters. creates LCM sibling cluster introducing
latent variable optimizing cardinality well model parameters. that,
imputes values latent variables links latent variables form
tree structure using Chow-Lius algorithm. EM algorithm run end
optimize parameters whole model. highlight difference BI
variable clustering algorithms, call models produces flat LTMs. Sibling
cluster determination key step BI. BI determines sibling clusters one one.
determine first sibling cluster, starts pair variables maximum
empirical MI. cluster expanded adding variables one another.
step, variable dependent variables already cluster
added cluster. that, unidimensionality test (UD test) determines whether
dependences among variables cluster properly modeled one latent
variable. test fails, expansion process terminated first sibling cluster
determined. Thereafter, process repeats remaining observed variables
grouped sibling clusters.

173

fiMourad, Sinoquet, Zhang, Liu, & Leray

Figure 6: Latent forest models. See Figure 2 node color code.

Forests
number variables analyze large (e.g. 1000 variables), might
reasonable learn forest instead tree many variables might
significantly dependent (see Figure 6). call model latent forest
model (LFM). many advantages LTM, reducing complexity
probabilistic inference (which depends number edges). learn LFM, exists
multiple approaches. instance, AHCB, one use cluster validation criterion
decide cut hierarchy. Regarding LCMB-LTM (Algorithm 3), two
options. one hand, Harmeling Williams (2011) check optimal cardinality
current LV H (additional step line 6). optimal cardinality equals 1,
means LV useful model construction algorithm stops.
hand, partitioning variables cliques (which replaces step line
5), algorithm Mourad et al. (2011) terminates single-node cliques
discovered.
build LFM, one also first construct LTM use independence
testing method Tan et al. (2011) pruning non-significant edges. method provides
guarantees satisfy structural risk consistencies. Similar works non-parametric
analysis also developed Liu et al. (2011). worth mentioning that,
ensure model parsimony, pruning non-significant edges LTM followed
removal latent nodes longer connected minimum three nodes.
3.2.3 Distance-based Methods
class methods originally developed phylogenetics (Felsenstein, 2003).
phylogenetic tree binary LTM showing evolutionary relations among set taxa.
Compared LTM learning methods, distance-based ones provide strong guarantees inference optimal model. section, first define distances
present learning algorithms: neighbor joining (phylogenetic tree inference), distance-based
174

fiLatent Tree Models

Figure 7: Illustration ascertaining child-parent (a b) sibling relations (c).
dotted edge two nodes means two nodes linked path
unknown length. figure, nodes colored white
either observed latent.

method dedicated general LTM learning recent spectral methods.
Distances Variables
Distances restricted LTMs whose variables share state space X ,
e.g. binary variables (Lake, 1994). Distances functions pairwise distributions.
discrete tree model G(V, E) (e.g. LTM), distance two variables Vi Vj
is:
| det(Jij )|
dij = log q
,
(18)
det(Mi ) det(Mj )
ij
Jij joint probability matrix Vi Vj (i.e. Jab
= p(Vi = a, Vj = b), a, b

= p(V = a)).
X ), diagonal marginal probability matrix Vi (i.e. Maa

special case discrete tree models, called symmetric discrete tree models (Choi
et al., 2011), distance simpler form. Symmetric discrete tree models characterized
fact every variable uniform marginal distribution pair
variables Vi Vj connected edge E verifies following property:

1 (K 1) ij vi = vj
p(vi |vj ) =
ij
otherwise,

K cardinality common Vi Vj , ij (0, 1/K), known crossover
probability. symmetric discrete tree models, distance two variables Vi
Vj then:
dij = (K 1) log (1 Kij ).
(19)
Note one-to-one correspondence distances model parameters
symmetric discrete tree models (for details, see Choi et al., 2011).
175

fiMourad, Sinoquet, Zhang, Liu, & Leray

aforementioned distances additive tree metrics (Erdos, Szekely, Steel, & Warnow,
1999):
X
dk` =
dij , k, ` V.
(20)
(Vi ,Vj )P ath((k,`);E)

Choi et al. (2011) showed additive tree distances allow ascertain child-parent
sibling relationships variables parsimonious LTM. Let us consider
three variables Vi , Vj , Vk V. Choi et al. define ijk difference distances
dik djk (ijk = dik djk ). distance dij Vi Vj , following two
properties ijk hold:
ijk = dij , Vk V\{Vi , Vj }, Vi leaf node Vj parent node;
ijk = dij , Vk V\{Vi , Vj }, Vj leaf node Vi parent
node;
dij < ijk = ijk0 < dij , Vk , Vk0 V\{Vi , Vj }, Vi Vj leaf nodes
share parent node, i.e. belong sibling group.
Neighbor Joining
principle neighbor joining (NJ) quite simple (Saitou & Nei, 1987; Gascuel &
Steel, 2006). NJ starts star-shaped tree. iteratively selects two taxa
j, creates new taxum u connect them. selection pair seeks optimize
following Q criterion:
Q(i, j) = (n 2) dij

n
X
k=1

dik

n
X

djk ,

(21)

k=1

n number taxa dij additive tree distance j.
distance new taxum u estimated follows:
!
n
n
X
X
1
1
diu = dij +
dik
djk ,
(22)
2
2(n 2)
k=1

k=1

dju calculated symmetry. distances new taxum u
taxa tree computed as:
duk =

1
1
(dik diu ) + (djk dju ) .
2
2

(23)

success distance methods NJ comes fact
proved efficient terms sample complexity. Cavender-Farris model
evolution (Cavender, 1978; Farris, 1973), Atteson (1999) showed possible
guarantee maxi,j |dij dij | < probability least if:



2
2 ln 2n

exp max dij
,
(24)
N
i,j
(1 exp())2
176

fiLatent Tree Models

N number mutation sites (i.e. number observations) n number
taxa (i.e. number OVs). Erdos et al. (1999) demonstrated
evolutionary model reconstruction method, N grows least fast log n,
model assuming i.i.d. observations, grows least n log n. Erdos et al.
also proposed new algorithm, called Dyadic Closure Method, sample complexity
power log n, mutation probabilities lie fixed interval. Daskalakis et
al. (2009) proved Steels conjecture (Steel, 2001)
states mutation


probabilities edges tree less p = ( 2 1)/23/2 discretized,
tree recovered log n. Recently, Mossel et al. (2011) proved log2 n
suffices discretization assumed.
phylogenetics, scientist often faced set different trees11
construction consensus tree thus required. computational complexity
construction studied polynomial algorithm proposed Steel et
al. (1992).
Learning Dedicated General LTM
subsection, present latest developments Choi et al. (2011) general
LTM learning, i.e. learning restricted phylogenetic trees. restricted
analysis data whose variables share state space, instance binary data.
Assuming data generated parsimonious LTM, additive tree metric property allows
exactly recover child-parent sibling relations distances (see Subsection Distances
Variables, last paragraph). Another advantage OVs necessarily
constrained leaf nodes (this seen next paragraph).
distance-based general LTM learning (DBG) implemented Algorithm 4, detailed follows. First, working node set W initialized set observed
variables X = {X1 , ..., Xn } (line 1). Distances computed three variables W
(line 2). empty tree created W (line 3). following steps successively
iterated (lines 4 16):
procedure (based properties described Subsection Distances Variables, last paragraph) allows identify nodes parent-child relation
nodes siblings (line 5). procedure generates three different sets node
groups: set parent-child groups, PC = {P C1 , ..., P Cp }, set sibling groups,
= {S1 , ..., Sq } set remaining single nodes, R = {R1 , ..., Rr };
content working node set W replaced parent nodes belonging
parents(PC) remaining single nodes belonging R (line 6);
group sibling nodes S, new parent LV H created added W
(lines 7 8);
update distances working node set (line 9), distances
new LVs remaining variables W calculated (the calculation easily
derived previously computed distances; details, see Choi et al., 2011);
11. instance different genes used infer trees.

177

fiMourad, Sinoquet, Zhang, Liu, & Leray

Algorithm 4 Distance-based general LTM learning (DBG, adapted RG, Choi et al.,
2011)
INPUT:
X, set n observed variables {X1 , ..., Xn }.
OUTPUT:
, respectively tree structure parameters LTM constructed.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:

W X /* Initialization working set variables */
inf dist computation(W) /* three variables W */
(V, E) empty tree(W) /* tree W edges */
loop
(PC,S,R) test relations(D,W) /* see paragraph 3 section */
W (parents(PC), R) /* parents singles */
LCMT LCM trees(S) /* LCM tree sibling group */
W W latent variables(LCMT)
inf dist computation(W) /* LVs W */
E E edges(PC) edges(LCMT)
V V latent variables(LCMT)
|W| = 2
E E edge two remaining nodes(W)
break
else |W| = 1 break end
end loop
EM (T ) /* See Section 3.1 */
working node set W contains strictly two nodes, new step
started. Otherwise, two possible situations: working node set W
contains two nodes, nodes connected12 procedure completed
(lines 12 14); working node set W contains one node, iteration
stops (line 15).

learning partial structure, model parameters (line 17) learned (see Section
3.1).
practice, Choi et al. (2011) restricted learning symmetric discrete distributions13 (see definition Subsection Distances Variables). restriction presents
major advantage: allows derive model parameters use distances previously learned structure recovery. words, learning structure,
need recover parameters EM. due one-to-one correspondence
distance model parameters (for details, see Choi et al., 2011).
12. prevents introduction redundant LV, see Section 2.5, second paragraph.
13. Nevertheless, algorithm applied non-symmetric discrete distributions. requirement
variables share state space.

178

fiLatent Tree Models

diminish computational complexity DBG, Choi et al. (2011) propose first
learn minimum spanning tree (MST) based distances OVs. Then, tree,
identify set internal nodes. internal node Vi neighbor nodes
nbd(Vi ), apply DBG outputs latent tree. global model, subtree
{Vi , nbd(Vi )} replaced corresponding latent tree. strategy allows
reduce computational complexity latent tree construction MST fast
compute DBG applied restricted number variables. term sample
complexity, DBG derived algorithms require log n observations recovering
model high probability. sample complexity equal one Chow-Liu
algorithm (Tan et al., 2011).
Another version DBG algorithm developed assumed observations generated genuine LTM. prevent incorporation irrelevant
LVs, applying DBG subtrees {Vi , nbd(Vi )}, integrated model
latent trees increase BIC score.
Spectral Methods
Recent works extended previous distance methods following spectral approach.
one hand, Anandkumar et al. (2011) addressed multivariate setting observed
latent nodes random vectors rather scalars. approach deal
general linear models containing categorical continuous variables. Another important improvement method sample complexity bound given terms
natural correlation conditions generalize restrictive effective depth conditions previous works (Erdos et al., 1999; Choi et al., 2011). proposed extension
consists replacing step line 5 Algorithm 4 quartet test14 relying spectral techniques (more specifically, canonical correlation analysis; Hair, Black, Babin,
Anderson, 2009). Given four observed variables {X1 , X2 , X3 , X4 }, spectral quartet test
distinguishes four possible tree topologies (see Figure 8). correct topology
{{Xi , Xj }, {Xi0 , Xj 0 }} if:
|E[Xi Xj> ]| |E[Xi0 Xj>0 ]| > |E[Xi0 Xj> ]| |E[Xi Xj>0 ]| ,

(25)

|M | := k`=1 ` (M ) product k largest singular values matrix
E[M ] expectation (estimated using covariance matrix).
hand, Song et al. (2011) proposed non-parametric learning based
kernel density estimation (KDE) (Rosenblatt, 1956; Parzen, 1962). KDE particularly
relevant model learning, case non-Gaussian continuous variables showing multimodality skewness. Given set N i.i.d. observed data Dx = {x1 , ..., xN }, joint
distribution modeled :
N n
1 XY
k(xj , xij ),
P (x) =
N

(26)

i=1 j=1

x = {x1 , ..., xn } observation, k(x, x0 ) Gaussian radial basis function N
number observations. Kernels k(x, x0 ) represented inner products h(x), (x0 )iF
14. Quartet tests widely used phylogenetic tree inference. first authors adapt LTM
learning Chen Zhang (2006).

179

fiMourad, Sinoquet, Zhang, Liu, & Leray

Figure 8: four possible tree topologies quartet test. See Figure 2 node color
code.

feature map : R F. products kernels also kernels, product
nj=1 k(xj , x0j ) written single inner product hnj=1 (xj ), nj=1 (x0j )iF n ,
tensor product. Let CX := EX [nj=1 (Xj )] Hilbert space embedding KDE
distribution P (X). expectation P (X) formulated hCX , nj=1 (xj )iF n .
exploiting given latent tree structure, key Hilbert space embedding allows
decompose CX simpler tensors. Similarly work Parikh et al. (2011), message
passing parameter estimation reformulated tensor notation (see work
Song et al., 2011, details). learn structure, non-parametric additive
tree metric used. two variables Vi Vj , distance is:
1
1
1
>
>
dij = log |Cij Cij
|? + log |Cii Cii> |? + log |Cjj Cjj
|? .
2
4
4

(27)

Then, given distances variables, NJ DBG used learn structure.
3.2.4 Determination Latent Variable Cardinalities
LCM learning, LV cardinality determined examination possible values (up maximum) choosing one maximizes criterion,
BIC (Raftery, 1986). cardinality value, parameters required calculate
likelihood appearing optimization criterion. purpose, random restarts
EM generally used learn parameters low probability getting trapped
local maxima. drawback method cannot applied LTM learning, EM becomes time-consuming several LVs. better solution consists
using greedy search approach, starting preset value LV cardinality (generally
equal 2) incrementing meet optimal criterion. However, solution still
remains computationally demanding (Zhang, 2004).
tackle issue computational burden, several strategies proposed.
instance, one simply set small value LV cardinalities. Following idea,
Hwang collaborators (2006) constrain LVs binary variables. worked
binary trees whose OVs also binary, restriction severe practice. Nevertheless, case non-binary OVs and/or non-binary trees, fast method presents
several drawbacks: one hand, small cardinality lead important loss
180

fiLatent Tree Models

information; hand, large cardinality entail model overfitting
unnecessary computational burden.
rigorous, Wang et al.s approach (2008) relies regularity (see Section 2.5). Knowing cardinality neighbor variables Zi , cardinality LV H determined
follows:
ki=1 |Zi |
.
(28)
|H| =
maxki=1 |Zi |
fast approach efficient LVs owning number neighbors. Thus
practicable binary trees trees whose LV degrees small (close 3).
context large scale data analysis (several thousands variables), Mourad et al. (2011)
proposed estimate cardinality LV given number children. rationale
underlying approach following: child nodes LV has, larger
number combinations values child variables. Therefore, cardinality
latent variable depend number child nodes. Nonetheless, keep
model complexity within reasonable limits, maximum cardinality fixed.
Two additional methods proposed offer better trade-off accuracy
computational cost. first one uses search-based agglomerative state-clustering
procedure (Elidan & Friedman, 2001). idea relies Markov blanket LV.
LTMs, Markov blanket LV H, noted MBH , composed parent
children. Markov blanket represents set variables directly interact H.
Elidan Friedmans method sets initial cardinality H based empirical joint
distribution MBH , noted P (MBH ). H initialized state configuration
found P (MBH ). cardinality repeatedly decreased successive merging
operations: states hi hj , whose merging entails best optimization given score,
merged. repeating operations till H one state, cardinality value
leading best score selected. second method relies local fast parameter
estimation LCM learning (Harmeling & Williams, 2011). presented first
paragraph section, greedy search approach used. starts preset
value increments meet optimal criterion. greedy search becomes efficient
because, cardinality value test, parameters quickly learned constant time.
3.2.5 Choosing Root
LTM root cannot learned data. However sometimes need determine
root. instance, LCM-based parameter learning (see Algorithm 1) easily
performed root chosen.
root determined priori knowledge data. instance,
consider latent structure LTM represents hierarchy concepts (i.e. taxonomy
ontology). Thus, LV root corresponds highest abstract level, whereas LV
node OVs children interpreted lowest abstract level. Actually,
variable clustering-based algorithms implicitly implement priori knowledge.
3.2.6 Time Complexity Scalability
time complexity generic LTM learning algorithms summarized Table 1.
table, compare algorithms, approaches, models time complexities. also
181

fiMourad, Sinoquet, Zhang, Liu, & Leray

Algorithm
CL

Approach
-

Model
Tree

Complexity
O(n2 N )

Instantiation
(Chow & Liu, 1968)

NGS

Score

Tree

O(sn5 N )

DHC (Zhang, 2004)

AGS, Alg. 2

Score

Tree

O(sn2 N )

AHCB

Variable
clustering

Forest

O(n2 N )

LCMB-LTM, Alg. 3

Variable
clustering

Forest

O(n2 N )

HSHC (Zhang & Kocka, 2004b)
EAST (Chen et al., 2012)
LTAB (Wang et al., 2008)
BIN-A (Harmeling & Williams, 2011)
BIN-G (Harmeling & Williams, 2011)
CFHLC (Mourad et al., 2011)
BI (Liu et al., 2012)

NJ

Information
distance

Tree

O(n3 N )

DBG, Alg. 4

Information
distance

O(n3 N
Tree

O(n2 N

+

n4 )

+

n4 )

NINJA (Saitou & Nei, 1987; Wheeler, 2009)
RG (Choi et al., 2011)
CLRG (Choi et al., 2011)
regCLRG (Choi et al., 2011)

Table 1: Computational time complexities generic algorithms dedicated latent tree
model (LTM) learning. number observed variables, number observations number steps (in search-based algorithms) denoted n, N
s, respectively. CL: Chow-Lius algorithm; NGS: naive greedy search (Section
3.2.1); AGS: advanced greedy search (Section 3.2.1); LCMB-LTM: latent class
model-based LTM learning (Section 3.2.2); NJ: neighbor joining (Section 3.2.3);
DBG: distance-based general LTM learning (Section 3.2.3).

give examples instantiations generic algorithms. Online resources summarized
Appendix A. order simplify comparison time complexities, consider
number n variables (input data), number N observations number
steps (for search-based algorithms). LTM learning algorithms compared
Chow-Liu algorithm learning tree without LVs. Details complexity
calculation LTM learning algorithms provided Supplemental material B.2.
tree contain LV, learning model done efficiently
O(n2 N ) using Prims algorithm (1957). situation complicated
tree contains LVs. complexity finding regular LTM lowest score
2
O(23n ). Search-based methods implement heuristics reduce large complexity.
overall complexity decomposed product three main terms: number
steps, structure learning complexity parameter learning complexity. opposite,
variable clustering- distance-based methods, overall complexity decomposed
sum. Nevertheless, development new operators greedy search
application local EM led significant improvements (from O(sn5 N ) O(sn2 N )).
Variable clustering-based methods computationally efficient multiple reasons.
rely pairwise dependence computation identify LVs connections,
LCM-based learning determine LV cardinality. Regarding distance-based methods,
NJ provides reasonable complexity O(n3 N ), whereas DBG presents high complexity
O(n3 N + n4 ). However, last complexity corresponds worst case, tree
learn hidden Markov model. Besides, Choi et al. provide modified DBG
reduces complexity O(n2 N + n4 ).
182

fiLatent Tree Models

Algorithm
Number variables
Number observations
Type data

CL1
LCM
DHC
SHC
HSHC
EAST
LTAB
BIN-A
BIN-G
CFHLC
BI
NJ
RG2
CLRG2
regCLRG2
Algorithm
Number variables
Number observations
Type data

CL1
LCM
DHC
SHC
HSHC
EAST
LTAB
BIN-A
BIN-G
CFHLC
BI
NJ
RG2
CLRG2
regCLRG2

BinTree

BinForest
5
500
simu
0.01
5.83
123.83
43.86
15.14
20.17
5.97
2.68
2.61
1.3
37.66
non-bin
non-bin
non-bin
non-bin
Alarm
37
1000
simu
0.15
34.32
time
time
3729.78
158.64
4366.93
277.01
6388.69
83.31
574.57
2.03
86.12
1.28
99.93
5.4
21
223.19
319.62
non-bin
non-bin
non-bin
non-bin
non-bin
non-bin
non-bin
non-bin

4
500
simu
0.01
1.43
18.79
27.07
13.85
12.56
2.8
3.00
3.06
1
19.38
non-bin
non-bin
non-bin
non-bin
Forest
20
500
simu
0.04
0.97
time

Asia

Hannover
8
5
100
3589
simu
real
0.01
0.00
1.02
58.58
16.23
9.86
4.55
5.39
1.5
1.9
3.79
5.02
0.97
1
0.22
16.70
0.23
17.87
0.6
18.6
7.87
7.65
0.15
4.75
0.16
3.49
0.06
3.63
0.04
6.54
Coil-42 NewsGroup
42
100
4000
8121
real
real
0.45
2.17
678.19
1467.10
time
time
time
time
time
time
time
751683
time
2197.69
387.21
1152.70
436.41
1302.10
560.9
1291.4
1193.25
6311.99
non-bin
1325.38
non-bin
274.37
non-bin
927.22
non-bin
345.09

Car
7
869
real
0.01
2.54
1609.72
150.23
18.79
63.55
35.36
3.72
3.72
2.7
69.26
non-bin
non-bin
non-bin
non-bin
HapGen
1000
1000
simu
121.36
bug
time
time
time
time
time
3573.20
7671.20
787.2
18977.02
non-bin
non-bin
non-bin
non-bin

Tree
19
500
simu
0.04
1.61
time
4258.06
87.04
309.47
86.52
0.63
0.29
6.6
183.34
non-bin
non-bin
non-bin
non-bin
HapMap
10000
116
real
memory
memory
time
time
time
time
time
memory
memory
2852.6
time
memory
memory
memory
memory

Long running time

Short running time

Table 2: Comparison running times algorithms literature small,
large large simulated real datasets. 1: CL learns tree without LVs;
2: RG, CLRG regCLRG learn tree whose internal nodes observed
latent. time: long running time; memory: out-of-memory; non-binary:
impossible process non-binary data. 3: results work Chen (2008).

183

fiMourad, Sinoquet, Zhang, Liu, & Leray

Algorithm
Number variables
Number observations
Type data

BinTree

BinForest

4
500
simu

Asia

5
500
simu

Hannover

8
100
simu

5
3589
real

Car

Tree
7
869
real

19
500
simu

CL1

-3222.80

-3350.20

-281.430

-7859.60

-7161.20

-106280

LCM

-3361.830

-3646.98

-346.2310

-7754.63

-7127.818

-100100

DHC

-2825.110

-3038.660

-269.326

-7710.961

-7049.9822

time

SHC

-2825.110

-3056.770

-268.044

-7709.710

-7056.184

-10095.9217

HSHC

-2825.10

-3056.770

-270.590

-7709.710

-7057.493

-10087.548

EAST

-2825.110

-3056.760

-283.826

-7709.690

-7051.977

-10092.455

LTAB

-3332.948

-379147

-727.323

-7876.480

-8084.8857 -13410.27390

BIN-A

-29910

-31460

-296.010

-77560

-7137.741

-100100

BIN-G

-29910

-31460

-296.010

-77560

-7133.843

-100100

CFHLC

-3682.860

-3302.560

-280.862

-8032.390

-7200.7626

-10070.4310

BI

-28500

-30740

-2830

-77111

-706317

-100732

NJ

non-bin

non-bin

-288.391

-77143

non-bin

non-bin

RG2

non-bin

non-bin

-287.132

-7711.44

non-bin

non-bin

CLRG2

non-bin

non-bin

-271.810

-7710.12

non-bin

non-bin

regCLRG2

non-bin

non-bin

-266.140

-7742.423

non-bin

non-bin

Algorithm

Forest

Alarm

Coil-42

NewsGroup

HapGen

HapMap

20

37

42

100

1000

10000

Number observations

500

1000

4000

8121

1000

116

Type data

simu

simu

real

real

simu

real

CL1

-113300

-112810

-364440

-1214000

-1912500

memory

Number variables

LCM

-107090

-218593489

-49581491

-124390768

bug

memory

DHC

time

time

time

time

time

time

SHC

-10777.811

time

time

time

time

time

HSHC

-10775.250

-11322.8384

time

time

time

time

-10777.085 -12315.66589

-35982.43

time

time

time

-14207.87392 -17733.87239 -43655.3746

time

bug

time

EAST
LTAB
BIN-A

-107080

-17640551

-37380104

-11906033

-3010103962

memory

BIN-G

-107080

-17600589

-3740478

-120230231

-3017903006

memory

-17856.0418 -51878.73151 -129101.4488 -367875.31706

-373523876

CFHLC

-10762.38

BI

-107616

-12296125

-36682152

NJ

non-bin

non-bin

RG2

non-bin

CLRG2
regCLRG2

-117278134

-2678811347

time

non-bin

-11761039

non-bin

memory

non-bin

non-bin

-120274380

non-bin

memory

non-bin

non-bin

non-bin

-11758046

non-bin

memory

non-bin

non-bin

non-bin

-118938161

non-bin

memory

High BIC

Low BIC

Table 3: Comparison BIC scores algorithms literature small, large
large simulated real datasets. 1: CL learns tree without LVs;
2: RG, CLRG regCLRG learn tree whose internal nodes observed
latent. time: long running time; memory: out-of-memory; non-binary:
impossible process non-binary data. 3: results work Chen (2008).

184

fiLatent Tree Models

algorithms proposed literature differ generic algorithms
presented. Tables 2 3, compare algorithms literature small, large
large simulated real datasets15 . Moreover provide results standard
algorithms: CL model-based LCM-based approaches. dataset, learned
model training data evaluated BIC score test data. repeated
experiments 10 times. programs allowed run maximum 6 hours. Datasets
described Supplemental material B.316 . report BIC score standard
deviation running time.
small datasets (n 10 variables), search-based methods lead best BIC values,
except Asia dataset distance-based method, regCLRG, best one.
surprising since search-based methods evaluate large number models find
optimal one. Nevertheless, large datasets (10 n 100), search-based methods
require long running times thus cannot used datasets Coil-42
NewsGroup ones. context, variable clustering-based distance-based methods
much efficient yielding accurate results. Regarding large dataset
context (n > 100), variable clustering-based distance-based methods learn
LTMs17 . CFHLC18 approach able process HapMap data containing 117
observations 10k variables. datasets, observe using CL model LCM
predominantly leads lower BIC scores using LTM, except large
large datasets.
3.2.7 Summary
LTM learning subject many methodological developments. structure
known, EM often preferred. Nevertheless, large LTMs, EM leads considerable
running times local maxima. address problem, LCM-based EM allows
quickly learn parameters, spectral methods help find optimal solution
LTM parameters required. structure unknown, search-based approaches
represent standard methods Bayesian network learning. However suitable
learning small LTMs. tackle issue, variable clustering-based methods represent
efficient alternatives. methods based idea grouping variables identify
LVs bottom-up manner. Recently, phylogenetic algorithms adapted
general LTM learning. Compared methods, guarantee exactly recover
generative LTM structure conditions.

15. fair comparison, used implementation NJ provided Choi et al. (2011).
16. Although algorithms NJ, RG, CLRG regCLRG process kind data shared state space
(binary data, ternary data, ...), implementation provided Choi et al. (2011) process
binary data. Hence algorithms applied datasets. recall RG, CLRG
regCLRG exactly learn LTM instead tree whose internal nodes compelled
latent.
17. Although shown Tables 2 3, NJ, RG, CLRG regCLRG able process 1000
binary variables experiments.
18. work Mourad et al. (2011), CFHLC implements window-based approach scale large
datasets (n 100k variables). fair comparison, window-based approach
used.

185

fiMourad, Sinoquet, Zhang, Liu, & Leray

Figure 9: Illustration phylogenetic tree reconstruction.

4. Applications
section, discuss illustrate three types applications LTMs: latent structure
discovery, multidimensional clustering probabilistic inference. end section,
also briefly present applications classification.
4.1 Latent Structure Discovery
Latent structure discovery aims revealing: (i) latent information underlying data, i.e.
unobservable variables abstract concepts role play data analysis,
(ii) latent relationships, i.e. relationships existing observed latent information,
also pieces latent information themselves. purpose, LTM analysis
represents powerful tool latent information latent relationships modeled
LVs graph edges, respectively. Thanks LTMs, latent structure discovery
applied several fields: marketing (Zhang, Wang, & Chen, 2008), medicine (Zhang,
Nielsen, & Jensen, 2004; Zhang et al., 2008), genetics (Hwang et al., 2006; Mourad et al.,
2011) phylogenetics (Felsenstein, 2003; Friedman, Ninio, Peer, & Pupko, 2002). Let
us take example phylogenetics major application LTMs structure
discovery.
phylogenetics, purpose infer tree representing evolutionary connections observed species. Let us consider human closest living relatives:
orangutan, gorilla, bonobo chimpanzee. DNA sequences, possible
reconstruct phylogenetic tree. DNA sequences sequences letters A, , G C.
evolution species, DNA sequences modified mutational processes.
186

fiLatent Tree Models

Figure 10: Latent tree model learned dataset Danish beer consumption. Edge
widths proportional mutual information nodes. latent
variable, number latent classes indicated brackets. See Figure 2
node color code. Lantern software.

species characterized DNA sequence. One popular algorithms
phylogenetic tree reconstruction NJ (described Section 3.2.3, Neighbor Joining).
starts considering tree star linking species (see illustration Figure 9).
distances species calculated based DNA sequences. Chimpanzee
bonobo present shortest distance thus regrouped new latent node.
distances updated last previous step reiterated construction
final phylogenetic tree. tree first links chimpanzee bonobo, human,
gorilla orangutan. success NJ comes fact that, compared previous
hierarchical clustering methods UPGMA (Unweighted Pair Group Method
Arithmetic Mean), assume species evolve rate. length
edge represents time separating two species. Moreover, assuming distances
correct, NJ outputs correct tree.
4.2 Multidimensional Clustering
Cluster analysis, also called clustering, aims assigning set observations several
groups (called clusters) observations belonging cluster similar
sense (Xu & Wunsch, 2008). LTMs particular tools produce multiple
clusterings: LV represents partition data, related specific subset
variables. application called multidimensional clustering mainly
explored Chen et al. (2012).
Let us illustrate LTM-based multidimensional clustering using dataset survey
Danish beer market consumption. purpose, use user-friendly software
Lantern. dataset consists 11 variables 463 consumers. variable represents
beer brand evaluated four possible answers survey questionnaire:
never seen brand (s0); seen before, never tasted (s1); tasted,
drink regularly (s2) drink regularly (s3).
187

fiMourad, Sinoquet, Zhang, Liu, & Leray

Figure 11: Information curves latent variable H1. Lantern software.

learned model presented Figure 10. BIC score 4851.99. model
contains 3 LVs: H0 , H1 H2 . LVs 2, 3 2 latent classes, respectively. Let
us start H1 simplest interpretable LV. Let X1 , X2 , ..., Xn OVs sorted
decreasing values pairwise MI H1 OV Xi . Two different information
curves analyzed Figure 11: (i) curve pairwise mutual information I(H1 ; Xi )
H1 OV Xi , (ii) curve cumulative information I(H1 ; X1 , ..., Xi )
representing MI H1 first OVs X1 , ..., Xi . curve pairwise mutual
information shows TuborgClas, followed CarlSpec Heineken, beers
related H1 . curve cumulative information presents complementary information.
cumulative information curve increases monotonically reaches maximum
n. ratio I(H1 ; X1 , ..., Xi )/I(H1 ; X1 , ..., Xn ) information coverage first
OVs. ratio equal 1, means H1 conditionally independent Xi+1 , ..., Xn
given first OVs. practice first OVs whose information coverage less
95% considered relevant. Using cumulative information curve, observe H1
related TuborgClas, CarlSpec Heineken, represent group beers
different others. TuborgClas CarlSpec frequent beers, bit darker
color different taste two main mass-market beers, GronTuborg
Carlsberg. Although Danish, Heineken one largest brand world
Danes would tasted sometimes travels abroad. Results
LVs discussed shown (interpretation remains H1 ). H0
related CeresTop, CeresRoyal, Pokal, Fuglsang, CarlsSpec FaxeFad (i.e. minor local
beers), whereas H2 connected GronTuborg Carlsberg (i.e., two main
mass-market beers).
188

fiLatent Tree Models

s0
s1
s2
s3

Class1, prior
Tub Carl
0.03
0
0.07 0.12
0.89 0.81
0.02 0.07

= 0.36
Hein
0.08
0.3
0.57
0.05

Class2, prior
Tub Carl
0.06 0.15
0.56 0.74
0.32 0.11
0.06
0

= 0.27
Hein
0.36
0.4
0.23
0.01

Class3, prior
Tub Carl
0
0
0
0.01
0.14 0.39
0.86 0.61

= 0.37
Hein
0.02
0.17
0.66
0.16

Table 4: Class conditional probability tables latent variable H1. Tub: TuborgClas;
Carl: CarlsSpec; Hein: Heineken.

H2

Class1
Class2

Class1
0.55
0.45

H1
Class2
0.71
0.29

Class3
0.11
0.89

Table 5: Conditional probability distributions latent variable H2 given H1 .
Class conditional probability distributions (CCPDs) H1 presented Table 4.
Using table, easy interpret latent classes. instance, first class (Class1)
represents 36% consumers (prior = 0.36). class, conditional probabilities
s2 higher 0.5. means consumers tasted beers,
drink regularly. second class (Class2) contains 27% consumers
represents people saw beers tasted them. last class (Class3)
includes 37% consumers represents people tasted beers drink
regularly. Results LVs discussed shown. CCPDs relative
H0 show division group consumers tasted beers (Class1)
complicated group consumers never saw brands, saw tasted
(Class2). Regarding H2 , CCPDs report consumers tasted beers
(Class1) consumers drink regularly (Class2). Using LTM, also
analyze relations different partitions. conditional probability distribution
P (H2 |H1 ) given Table 5. observe consumer behaviors similar two
groups beers. instance, consumers tasted regularly drink H1 group
beers (Class3 H1 ) generally also drink regularly H2 group beers (Class2 H2 ).
example, able find consumer profiles specific beer brands. Multidimensional clustering thanks LTMs helps discover multiple facets data (i.e. LVs)
partition data along facet (i.e. latent class). Moreover, general relations
multiple facets highlighted connections LVs.
4.3 Probabilistic Inference
Probabilistic inference process answering probabilistic queries form p(x|y),
event x given knowledge (Koller & Friedman, 2009), using Bayes formula:
p(x|y) =

p(y|x)p(x)
.
p(y)
189

(29)

fiMourad, Sinoquet, Zhang, Liu, & Leray

10
10
10
10
10

2

N=1k
N=10k
N=100k

1

10
Time (hour)

10

0

1

10

10

2

3

1

2

4

10

8

2

0

2

4

1

4

16

64

4

16

64

4

16

64

C

10

10

10

0

0

10

1

1

2

10
LTM (1k)
LTM (10k)
LTM (100k)
LBP
CL (100k)
LCM (100k)

1

2

2

4

10

8

1

6

1

10

10

LTM (1k)
LTM (10k)
LTM (100k)
CTP
LBP
CL (100k)
LCM (100k)

0

10

4

10

2

10

0

10
1

10

2

1

2

4

10

8

1

Figure 12: Experiments ALARM BARLEY networks: a) running times LTM
learning using LTAB algorithm (Wang et al., 2008), b) approximation accuracy probabilistic inference c) running time inference. Approximation
accuracy measured Kullback-Leibler divergence approximate
inferred distributions exact inferred distributions obtained clique tree
propagation original BN. N C designate sample size
maximal cardinality latent variables, respectively. results come
work Wang et al. (2008).

Probabilistic inference used many circumstances, credit card fraud detection
(Ezawa & Norton, 1996) disease diagnostic (McKendrick, Gettinbya, Gua, Reidb, &
Revie, 2000).
190

fiLatent Tree Models

Probabilistic inference general BN known NP-hard task (Cooper, 1990).
tackle issue, one approximate original BN using maximum weight spanning
tree learned relying Chow Lius algorithm (1968). drawback risk
inaccuracy inference results. context, LTM provides efficient simple
solution, because: (i) thanks tree structure, model allows linear computations
respect number OVs, time, (ii) represent complex relations
OVs multiple LVs. learning LTM performing inference
time-consuming Wang et al. (2008) propose following strategy: first, offline model
learning performed, answers probabilistic queries quickly computed online.
However, recent spectral methods (Parikh et al., 2011) considerably reduced model learning
phase, require learn model structure. makes inference
large LTMs possible (around several hundred OVs) thus renders even
attractive.
Inferential complexity depend number OVs, also LV
cardinalities: higher cardinality, higher complexity. Hence Wang et al.
(2008) propose tradeoff inferential complexity model approximation accuracy
fixing maximal cardinality C LVs.
Wang et al. (2008) empirically demonstrated high performance LTM-based inference 8 well-known Bayesian networks literature. principle consists
learning LTM provide best approximation original BN.
purpose, data sampled original BN LTM learned data.
illustrate inference, let us consider two examples, ALARM BARLEY
networks show lowest highest inferential complexities among aforementioned networks, respectively. ALARM network contains 37 nodes, characterized
average indegree 1.24 (max: 4) average cardinality 2.84 (max: 4).
BARLEY network contains 48 nodes; average indegree 1.75 (max: 4) average
cardinality 8.77 (max: 67). Two parameters central user: (i) N , sample
size entails long model learning running times leads better model accuracies,
(ii) C, maximal cardinality LVs entails long model learning inference
running times leads higher model accuracies.
Figure 12, LTM-based method compared standard inference approaches: LCM-based approach, Chow-Liu (CL) model-based approach loopy
belief propagation (LBP) (Pearl, 1988). Exact inference clique tree propagation
(CTP) (Lauritzen & Spiegelhalter, 1988) original BN considered reference.
Figure 12a reports running times LTM learning using LTAB algorithm (Wang et al.,
2008). Running times almost linearly increase N C. Regarding inference accuracy (Figure 12b), LTM-based method outperforms methods N C
high, e.g. N = 100k C = 8 ALARM network. regards inference running
times (Figure 12c), benefits using LTM-based method high ALARM
network, high inferential complexity network. experiments, note CL
also interesting, choice latter LTM depend
online inference time allowed. time limited, CL would preferred.
case, LTM would chosen.
191

fiMourad, Sinoquet, Zhang, Liu, & Leray

4.4 Applications
Beside latent structure discovery, multidimensional clustering probabilistic inference,
interesting applications LTMs.
simple efficient classifier naive Bayes. model assumes OVs independent conditional class variable. assumption often violated data
hence numerous adaptations developed improve classifier performance.
Naive Bayes generalized introducing latent nodes internal discrete nodes
(Zhang et al., 2004) continuous nodes (Langseth & Nielsen, 2009), mediating relation leaves class variable. model identical LTM except
root observed. Recently, Wang et al. (2011) proposed classifier based LTM.
class, specific LTM learned latent tree classifier built aggregating
LTMs. classifier outperforms naive Bayes many successful classifiers
tree augmented naive Bayes (Friedman, Geiger, & Goldszmidt, 1997) averaged
one-dependence estimator (Webb, Boughton, & Wang, 2005).
specifically research fields, LTM used human interaction
recognition, haplotype inference genetics diagnosis traditional medicine. Human
interaction recognition challenging task, multiple body parts concomitant
inclusions (Aggarwal & Cai, 1999). purpose, use LTM allows segment
interaction multi-level fashion (Park & Aggarwal, 2003): body part positions
estimated low-level LVs, overall body position estimated highlevel LV. genetics, need inferring haplotypic data (i.e. latent genetic
DNA sequences) genotypic data (observed data). Kimmel Shamir (2005) perform
efficient haplotypic inference using two-layer LFM. Finally, Zhang et al. (2008) applied
LTMs traditional Chinese medicine (TCM). discovered latent structure
obtained matches TCM theories. model provides objective justification
ancient theories.

5. Discussion
data analysis, LTM represents emerging popular topic offers several advantages:
model allows discover interpretable latent structure.
latent variable intended represent way cluster categorical data, connections latent variables meant express relations multiple
clustering ways.
Multiple latent variables organized tree greatly improve flexibility probabilistic modeling while, time, ensuring linear - thus fast - probabilistic
inference.
Applications LTMs summarized Table 6, recapitulates three types applications details, examples, references generic algorithms, scalability large datasets,
software bibliographical references.
past decade, extensive research efforts done LTM learning.
structure known, standard EM LCM-based EM spectral methods used.
192

fiLatent Tree Models

Table 6: Summary main applications latent tree model.
structure unknown, three classes methods proposed: search-based,
variable clustering-based distance-based methods. first one slow leads
accurate models. second one drastically decreases running times. Finally, last class
guarantees exactly recover generative LTM structure assumption
LVs number states number known.
spite aforementioned advances, use LTM presents drawbacks.
example, data dimension large large, model learning still remains prohibitive. Regarding probabilistic inference, LTM provides better results standard
Chow-Lius approach, leads computational burden.

6. Future Directions
Progress LTM made, still much done. multiple
promising directions. instance, recent work developed LTM continuous data analysis (Poon, Zhang, Chen, & Wang, 2010; Choi et al., 2011). authors investigated
relationships LTM ontology (Hwang et al., 2006), LTM-based dependence
visualization (Mourad, Sinoquet, Dina, & Leray, 2011). Although research
carried application causal discovery latent trait analysis, argue
LTM might represent interesting avenues research.
LTM Continuous Data: Recently, LTM modeling applied continuous
data analysis (Poon et al., 2010; Choi et al., 2011; Song et al., 2011; Kirshner, 2012).
instance, Poon et al. (2010) proposed new model, called pouch latent tree model
(PLTM). PLTM identical LTM, except observed node LTM replaced
pouch node representing aggregation multiple continuous OVs. PLTM
represents generalization Gaussian mixture model (GMM) one LV
allowed. proposal Poon et al. originates fact model-based clustering
continuous data sensitive selected variables. Similarly categorical clustering
(Section 4.2), high-dimensional continuous data, multiple ways partition
data, multiple LVs PLTM able take account. Poon et al.
193

fiMourad, Sinoquet, Zhang, Liu, & Leray

developed search-based algorithm PLTM learning. latter algorithm closely
related EAST algorithm (Zhang & Kocka, 2004b) dedicated LTM learning
thus quite slow. Hence, development new methods dedicated efficient PLTM
learning certainly represents interesting perspectives research. Besides, next step would
also development LTM dedicated mixed data analysis, i.e. combining categorical
continuous data.
LTM Structure Ontology: possible relate LTM ontology, particular
taxonomy (tree-structured ontology). instance, applying LTM microarray
dataset yeast cell-cycle, Hwang et al. (2006) showed LVs significantly related specific gene ontology terms, organelle organization cellular physiological
process. Thus taxonomy could help interpret LVs. Moreover taxonomy structure could
used priori structure.
Dependence Visualization: LTM provide compact interpretable view dependences variables, thanks graphical nature latent variables (Mourad
et al., 2011). Compared heat map (Barrett, Fry, Maller, & Daly, 2005)
display pairwise dependences variables, LTM helps visualize pairwise
higher-order dependences. Pairwise dependence represented chain length
linking two leaf variables, whereas higher-order dependences simply represented
set leaf variables connected common LV.
Causal Discovery: argue LTM represents simple efficient model causal
discovery, following reasons:
LTM root known, model interpreted hierarchy.
hierarchy, LVs distributed multiple layers. multiple LV layers represent different degrees information compactness (i.e. data dimension reduction),
since LV captures patterns child variables. connexion variables
parent-child relationships allows easy natural moves general (top
layers) specific (bottom layers) causes, vice-versa. Thus, causal discovery
guided hierarchical model feature.
constructing model variables X = {X1 , ..., Xn }, one wants test
direct dependence Xi another variable present network,
easily computed test independence Xi conditional
parent Xi . practical advantage conditional test meant assess
direct dependence number degrees freedom required low (because
parent Xi used condition test), ensures good power.
Latent Trait Analysis: Similarly generalization LCM LTM, would
worth developing extension latent trait model tree-structured model
internal nodes continuous LVs. instance, would alleviate drawbacks local
independence latent trait model would provide multiple facets thanks LVs
dealing high-dimensional data.

194

fiLatent Tree Models

Acknowledgments
authors deeply indebted four anonymous reviewers invaluable comments helping improve manuscript. work supported BIL
Bioinformatics Research Project Pays de la Loire Region, France. authors also
grateful Carsten Poulsen (Aalborg University, Denmark) providing Danish beer
data, Yi Wang (National University Singapore) LTAB algorithm, Tao Chen (EMC
Corporation, Beijing, China) EAST algorithm, Stefan Harmeling (Max Planck Institute, Germany) BIN-A BIN-G algorithms, Myung Jin Choi (Two Sigma
Investments, USA) Vincent Tan (University Wisconsin-Madison, USA) RG,
CLRG regCLRG algorithms.

Appendix A. Online Resources Mentioned
Software:
BIN-A, BIN-G, CL LCM:
http://people.kyb.tuebingen.mpg.de/harmeling/code/ltt-1.4.tar
CFHLC:
https://sites.google.com/site/raphaelmouradeng/home/programs
DHC, SHC HSHC:
http://www.cse.ust.hk/faculty/lzhang/ltm/index.htm (hlcm-distribute.zip)
http://www.cse.ust.hk/faculty/lzhang/ltm/index.htm (toolBox.zip)
EAST:
http://www.cse.ust.hk/faculty/lzhang/ltm/index.htm (EAST.zip)
Lantern:
http://www.cse.ust.hk/faculty/lzhang/ltm/index.htm (Lantern2.0-beta.exe)
NJ, RG, CLRG regCLRG:
http://people.csail.mit.edu/myungjin/latentTree.html
NJ (fast implementation):
http://nimbletwist.com/software/ninja
datasets used algorithm comparison available :
https://sites.google.com/site/raphaelmouradeng/home/programs

Appendix B. Supplemental Material
B.1 Experiments Parameter Learning EM
studied number random restarts required, practice, obtain convergence
EM (Section 3.1.1) LCMB-EM (Section 3.1.2) optimal solution. BIC scores
presented Figure 13. EM, used method Chickering Heckerman
(1997) implemented software LTAB (Wang et al., 2008). analyzed three
195

fiMourad, Sinoquet, Zhang, Liu, & Leray

Figure 13: impact number random restarts convergence expectationmaximization (EM). a) EM. b) LCMB-EM. number restarts reported
x-axis y-axis indicates BIC scores.

datasets: two small ones (BinTree Asia) large one (Tree). first two,
convergence achieved 20 2000 restarts, respectively. large dataset,
convergence never achieved, even 5000 restarts. LCMB-EM, used software
BIN-A (Harmeling & Williams, 2011). analyzed three datasets: one small one (Asia)
two large ones (Tree, Alarm). Convergence achieved first two datasets
one parameter initialization, whereas later largest, convergence
never achieved (we able assess 1000 restarts
prohibitive running time).
B.2 Time Complexity
recall reader n number variables (input data), N number
observations number steps (for search-based algorithms). time complexities
generic algorithms LTM learning detailed follows:
Naive greedy search (NGS). O(s) steps needed convergence
search-based methods. step, O(n2 ) new models generated
use 3 operators: addition/removal LV node relocation (Zhang, 2004).
model, cardinality optimized LV, O(n2 ) new models
generated (Zhang, 2004). model, parameters learned using EM,
196

fiLatent Tree Models

achieved O(nN ). Thus, overall complexity : O(s) O(n2 ) O(n2 ) O(nN ) =
O(sn5 N ).
Advanced greedy search (AGS), Algorithm 2. O(s) steps needed
convergence search-based methods. step, O(n2 ) new models
generated use 5 operators: addition/removal LV, node relocation
addition/dismissal state relative LV (Zhang & Kocka, 2004b).
model, model evaluation realized local EM O(N ). choosing
best model step, parameters learned using EM, achieved
O(nN ). Thus, overall complexity : O(s) (O(n2 ) O(N ) + O(nN )) = O(sn2 N ).
Agglomerative hierarchical clustering-based learning (AHCB). agglomerative hierarchical clustering achieved O(n2 N )19 . LV cardinality parameters
learned O(N ) thanks LCM parameter learning. O(n) LVs, thus
complexity (O(N ) O(n)). final global EM parameter learning done
O(nN ). Thus, overall complexity : O(n2 N )+(O(N )O(n))+O(nN ) = O(n2 N ).
Latent class model-based LTM learning (LCMB-LTM), Algorithm 3. Pairwise mutual information values computed O(n2 N ). LCM learned O(N ).
LCM learning called O(n) times, i.e. new LV added model. LV
cardinality parameters learned LCM learning. final global EM parameter learning done O(nN ). Thus, overall complexity : O(n2 N ) +
(O(N ) O(n)) + O(nN ) = O(n2 N ).
Neighbor joining (NJ). learn structure, O(n) steps. step,
pairwise distances computed O(n2 N ). Structure learning thus requires O(n3 N )
computations. learning structure, parameters learned EM
LCMB-EM O(nN ). Thus, overall complexity : O(n3 N ) + O(nN ) = O(n3 N ).
Distance-based general LTM learning (DBG), Algorithm 4. First distances computed O(n3 N ). minimum spanning tree learned before,
complexity reduced O(n2 N ). Then, learn structure, testing child-parent
sibling relations necessitates O(n4 ) operations worst case, i.e.
tree hidden Markov model. Parameters learned EM LCMB-EM
O(nN ). Thus, overall complexity : O(n3 N ) + O(n4 ) + O(nN ) = O(n3 N + n4 )
O(n2 N ) + O(n4 ) + O(nN ) = O(n2 N + n4 ).
B.3 Description Datasets Used Literature Algorithm Comparison
Small datasets (n 10 variables):
BinTree. Datasets generated using binary tree 7 variables (4 leaves 3
internal nodes), eight states. leaf data used. train
test datasets consist 500 observations. model comes work
Harmeling Williams (2011).
19. complexity agglomerative hierarchical clustering O(n2 N ) using single linkage criterion.
complexity higher criteria.

197

fiMourad, Sinoquet, Zhang, Liu, & Leray

BinForest. Datasets generated binary forest composed two trees. One
tree 3 variables (2 leaves 1 internal node), one 5 variables (3
leaves 2 internal nodes). leaf data used. train test datasets
consist 500 observations. model comes work Harmeling
Williams (2011).
Asia. Datasets generated using well-known Asia network containing 8 binary
OVs. train test datasets consist 100 observations.
Hannover. Real dataset containing 5 binary variables. dataset split
train dataset test dataset. consist 3573 3589 observations,
respectively. dataset comes work Zhang (2004).
Car. Real dataset containing 7 variables. dataset split train
dataset test dataset. consist 859 869 observations, respectively.
dataset available :
http://archive.ics.uci.edu/ml/.
Large datasets (10 n 100 variables):

Tree. Datasets generated using tree 50 variables (19 leaves 31 internal
nodes). leaf data used. train test datasets consist 500
observations.
Forest. Datasets generated using tree 50 variables (20 leaves 30 internal
nodes). leaf data used. train test datasets consist 500
observations.
Alarm. Datasets generated using well-known Alarm network containing 37 OVs.
train test datasets consist 1000 observations.
Coil-42. Real dataset containing 42 variables. dataset split train
dataset test dataset. consist 5822 4000 observations, respectively.
dataset comes work Zhang Kocka (2004b).
NewsGroup. Real dataset containing 100 binary variables. dataset
split train dataset test dataset. consist 8121 observations.
dataset available :
http://cs.nyu.edu/roweis/data/20news w100.mat.

large datasets (n > 100 variables):
HapGen. Datasets generated 1000 genetic variables using HAPGEN software (Spencer, Su, Donnelly, & Marchini, 2009). train test datasets
consist 1000 observations.
HapMap. Real dataset containing 10000 binary variables. dataset
split train dataset test dataset. consist 118 116 observations,
respectively. dataset comes HapMap phase III (The International HapMap
Consortium, 2007) concerns Utah residents Northern Western European
ancestry (CEU).

198

fiLatent Tree Models

References
Aggarwal, J., & Cai, Q. (1999). Human motion analysis: review. Computer Vision
Image Understanding, 73 (3), 428440.
Akaike, H. (1970). Statistical predictor identification. Annals Institute Statistical
Mathematics, 22 (1), 203217.
Anandkumar, A., Chaudhuri, K., Hsu, D., Kakade, S. M., Song, L., & Zhang, T. (2011).
Spectral methods learning multivariate latent tree structure. Twenty-Fifth
Conference Neural Information Processing Systems (NIPS-11).
Atteson, K. (1999). performance neighbor-joining methods phylogenetic reconstruction. Algorithmica, 25 (2), 251278.
Attias, H. (1999). Inferring parameters structure latent variable models variational
Bayes. Proceedings 15th Conference Uncertainty Artificial Intelligence
(UAI-99), pp. 2130.
Barrett, J. C., Fry, B., Maller, J., & Daly, M. J. (2005). Haploview: analysis visualization
LD haplotype maps. Bioinformatics, 21 (2), 263265.
Binder, J., Koller, D., Russel, S., & Kanazawa, K. (1997). Adaptive probabilistic networks
hidden variables. Machine Learning, 29 (2-3), 213244.
Cavender, J. A. (1978). Taxonomy confidence. Mathematical Biosciences, 40 (3-4),
271280.
Chen, T., & Zhang, N. L. (2006). Quartet-based learning hierarchical latent class models:
Discovery shallow latent variables. Proceedings 9th International Symposium
Artificial Intelligence Mathematics.
Chen, T. (2008). Search-based learning latent tree models. Ph.D. thesis, Hong Kong
University Science Technology.
Chen, T., Zhang, N. L., Liu, T., Poon, K. M., & Wang, Y. (2012). Model-based multidimensional clustering categorical data. Artificial Intelligence, 176 (1), 22462269.
Chen, T., Zhang, N. L., & Wang, Y. (2008). Efficient model evaluation searchbased approach latent structure discovery. Proceedings Fourth European
Workshop Probabilistic Graphical Models (PGM-08), pp. 5764.
Chickering, D. M., & Heckerman, D. (1997). Efficient approximations marginal
likelihood Bayesian networks hidden variables. Machine Learning, 29 (2-3),
181212.
Choi, M. J., Tan, V. Y., Anandkumar, A., & Willsky, A. S. (2011). Learning latent tree
graphical models. Journal Machine Learning Research, 12, 17711812.
Chow, C. K., & Liu, C. N. (1968). Approximating discrete probability distributions
dependence trees. IEEE Transactions Information Theory, 14 (3), 462467.
Cooper, G. F. (1990). computational complexity probabilistic inference using
Bayesian belief networks. Artificial Intelligence, 42 (2-3), 393405.
Cover, T. M., & Thomas, J. A. (1991). Elements information theory. Wiley-Interscience.
199

fiMourad, Sinoquet, Zhang, Liu, & Leray

Daskalakis, C., Mossel, E., & Roch, S. (2009). Evolutionary trees Ising model
Bethe lattice: proof Steels conjecture. Probability Theory Related Fields,
149 (1-2), 149189.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete data via
EM algorithm. Journal Royal Statistical Society. Series B (Methodological),
39, 138.
Elidan, G., & Friedman, N. (2001). Learning dimensionality hidden variables.
Proceedings 17th Conference Uncertainty Artificial Intelligence (UAI01), pp. 144151.
Erdos, P. L., Szekely, L. A., Steel, M. A., & Warnow, T. J. (1999). logs suffice
build (almost) trees: Part II. Theoretical Computer Science, 221 (1-2), 77118.
Ezawa, K. J., & Norton, S. W. (1996). Constructing Bayesian networks predict uncollectible telecommunications accounts. IEEE Expert, 11 (5), 4551.
Farris, J. S. (1973). probability model inferring evolutionary trees. Systematic Zoology,
22 (3), 250256.
Felsenstein, J. (2003). Inferring phylogenies (2 edition). Sinauer Associates.
Friedman, N., Ninio, M., Peer, I., & Pupko, T. (2002). structural EM algorithm
phylogenetic inference.. Journal Computational Biology, 9 (2), 331353.
Friedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. Machine
Learning, 29 (2-3), 131163.
Gascuel, O., & Steel, M. (2006). Neighbor-joining revealed. Molecular Biology Evolution, 23 (11), 19972000.
Geiger, D., Heckerman, D., & Meek, C. (1996). Asymptotic model selection directed
networks hidden variables. Proceedings Twelfth Conference Uncertainty
Artificial Intelligence (UAI-96), pp. 283290. Morgan Kaufmann.
Hair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2009). Multivariate data analysis
(7 edition). Prentice Hall.
Harmeling, S., & Williams, C. K. I. (2011). Greedy learning binary latent trees. IEEE
Transactions Pattern Analysis Machine Intelligence, 33 (6), 10871097.
Hsu, D., Kakade, S., & Zhang, T. (2009). spectral algorithm learning hidden Markov
models. 22nd Annual Conference Learning Theory (COLT 2009).
Hwang, K.-B., Kim, B.-H., & Zhang, B.-T. (2006). Learning hierarchical Bayesian networks
large-scale data analysis. International Conference Neural Information Processing (ICONIP-06), pp. 670679.
Kim, J. H., & Pearl, J. (1983). computation model causal diagnostic reasoning
inference systems. Proceedings 8th International Joint Conference
Artificial Intelligence.
Kimmel, G., & Shamir, R. (2005). GERBIL: Genotype resolution block identification
using likelihood. Proceedings National Academy Sciences United States
America, 102 (1), 158162.
200

fiLatent Tree Models

Kirshner, S. (2012). Latent tree copulas. Proceedings Sixth European Workshop
Probabilistic Graphical Models (PGM-12).
Koller, D., & Friedman, N. (2009). Probabilistic graphical models: Principles techniques
(adaptive computation machine learning). MIT Press.
Kraskov, A., & Grassberger, P. (2009). Information theory statistical learning, chap.
MIC: Mutual information based hierarchical clustering, pp. 101123. Springer.
Kwoh, C.-K., & Gillies, D. F. (1996). Using hidden nodes Bayesian networks. Artificial
Intelligence, 88 (1-2), 138.
Lake, J. A. (1994). Reconstructing evolutionary trees DNA protein sequences:
Paralinear distances. Proceedings National Academy Sciences United
States America, 91 (4), 14551459.
Langseth, H., & Nielsen, T. D. (2009). Latent classification models binary data. Pattern
Recognition, 42 (11), 27242736.
Lauritzen, S. L. (1995). EM algorithm graphical association models missing
data. Computational Statistics & Data Analysis, 19 (2), 191201.
Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations probabilities
graphical structures application expert systems. Journal Royal
Statistical Society. Series B (Methodological), 50 (2), 157224.
Liu, H., Xu, M., Gu, H., Gupta, A., Lafferty, J., & Wasserman, L. (2011). Forest density
estimation. Journal Machine Learning Research, 12, 907951.
Liu, T. F., Zhang, N. L., Liu, A. H., & Poon, L. K. M. (2012). novel LTM-based method
multidimensional clustering. Proceedings Sixth European Workshop
Probabilistic Graphical Models (PGM-12).
Martin, J., & Vanlehn, K. (1995). Discrete factor analysis: Learning hidden variables
Bayesian network. Tech. rep., Department Computer Science, University Pittsburgh.
McKendrick, I. J., Gettinbya, G., Gua, Y., Reidb, S. W. J., & Revie, C. W. (2000). Using
Bayesian belief network aid differential diagnosis tropical bovine diseases.
Preventive Veterinary Medicine, 47 (3), 141156.
Mossel, E., & Roch, S. (2006). Learning nonsingular phylogenies hidden Markov models.
Annals Applied Probability, 16 (2), 583614.
Mossel, E., Roch, S., & Sly, A. (2011). Robust estimation latent tree graphical models:
Inferring hidden states inexact parameters. Submitted.
Mourad, R., Sinoquet, C., Dina, C., & Leray, P. (2011). Visualization pairwise
multilocus linkage disequilibrium structure using latent forests. PLoS ONE, 6 (12),
e27320.
Mourad, R., Sinoquet, C., & Leray, P. (2011). hierarchical Bayesian network approach
linkage disequilibrium modeling data-dimensionality reduction prior genomewide association studies. BMC Bioinformatics, 12, 16.
201

fiMourad, Sinoquet, Zhang, Liu, & Leray

Parikh, A. P., Song, L., & Xing, E. P. (2011). spectral algorithm latent tree graphical
models. Proceedings 28th International Conference Machine Learning
(ICML-2011).
Park, S., & Aggarwal, J. K. (2003). Recognition two-person interactions using hierarchical Bayesian network. first ACM International Workshop Video
Surveillance (IWVS03), pp. 6575.
Parzen, E. (1962). estimation probability density function mode. Annals
Mathematical Statistics, 33, 10651076.
Pearl, J. (1988). Probabilistic reasoning intelligent systems: Networks plausible inference. Morgan Kaufmann, Santa Mateo, CA, USA.
Poon, L. K. M., Zhang, N. L., Chen, T., & Wang, Y. (2010). Variable selection modelbased clustering: facilitate. Proceedings 27th International Conference Machine Learning (ICML-2010).
Prim, R. C. (1957). Shortest connection networks generalizations. Bell System
Technical Journal, 36, 13891401.
Raftery, A. E. (1986). Choosing models cross-classifications. American Sociological
Review, 51 (1), 145146.
Rosenblatt, M. (1956). Remarks nonparametric estimates density function.
Annals Mathematical Statistics, 27, 832837.
Saitou, N., & Nei, M. (1987). neighbor-joining method: new method reconstructing phylogenetic trees.. Molecular Biology Evolution, 4 (4), 406425.
Schwartz, G. (1978). Estimating dimension model. Annals Statistics, 6 (2),
461464.
Song, L., Parikh, A., & Xing, E. (2011). Kernel embeddings latent tree graphical models.
Twenty-Fifth Conference Neural Information Processing Systems (NIPS-11).
Spencer, C. C., Su, Z., Donnelly, P., & Marchini, J. (2009). Designing genome-wide association studies: sample size, power, imputation, choice genotyping chip..
PLoS Genetics, 5 (5), e1000477.
Steel, M. (2001).
favourite conjecture.
m.steel/files/misc/conjecture.pdf.

http://www.math.canterbury.ac.nz/-

Steel, M. (1992). complexity reconstructing trees qualitative characters
subtrees. Journal Classification, 9 (1), 91116.
Tan, V. Y. F., Anandkumar, A., & Willsky, A. (2011). Learning high-dimensional Markov
forest distributions: Analysis error rates. Journal Machine Learning Research,
12, 16171653.
International HapMap Consortium (2007). second generation human haplotype map
3.1 million SNPs. Nature, 449 (7164), 851861.
Wang, Y., Zhang, N. L., Chen, T., & Poon, L. K. M. (2011). Latent tree classifier.
European Conferences Symbolic Quantitative Approaches Reasoning
Uncertainty (ECSQARU2011), pp. 410421.
202

fiLatent Tree Models

Wang, Y., & Zhang, N. L. (2006). Severity local maxima EM algorithm: Experiences hierarchical latent class models. Proceedings Third European
Workshop Probabilistic Graphical Models (PGM-06).
Wang, Y., Zhang, N. L., & Chen, T. (2008). Latent tree models approximate inference
Bayesian networks. Journal Articial Intelligence Research, 32, 879900.
Webb, G. I., Boughton, J. R., & Wang, Z. (2005). naive Bayes: Aggregating onedependence estimators. Machine Learning, 58 (1), 5 24.
Wheeler, T. J. (2009). Large-scale neighbor-joining NINJA. Proceedings 9th
Workshop Algorithms Bioinformatics.
Xu, L., & Jordan, M. I. (1996). convergence properties EM algorithm Gaussian
mixtures. Neural Computation, 8 (1), 129151.
Xu, R., & Wunsch, D. (2005). Survey clustering algorithms. IEEE Transactions
Neural Networks, 16 (3), 645678.
Xu, R., & Wunsch, D. C. (2008). Clustering (illustrated edition). Wiley-IEEE Press.
Zhang, N. L. (2004). Hierarchical latent class models cluster analysis. Journal
Machine Learning Research, 5, 697723.
Zhang, N. L., & Kocka, T. (2004a). Effective dimensions hierarchical latent class models.
Journal Articial Intelligence Research, 21, 117.
Zhang, N. L., & Kocka, T. (2004b). Efficient learning hierarchical latent class models.
Proceedings 16th IEEE International Conference Tools Artificial
Intelligence (ICTAI), pp. 585593.
Zhang, N. L., Nielsen, T. D., & Jensen, F. V. (2004). Latent variable discovery classification models. Artificial Intelligence Medicine, 30 (3), 283299.
Zhang, N. L., Wang, Y., & Chen, T. (2008). Discovery latent structures: Experience
CoIL Challenge 2000 data set*. Journal Systems Science Complexity,
21 (2), 172183.
Zhang, N. L., Yuan, S., Chen, T., & Wang, Y. (2008). Latent tree models diagnosis
traditional Chinese medicine. Artificial Intelligence Medicine, 42 (3), 229245.

203

fiJournal Artificial Intelligence Research 47 (2013) 393-439

Submitted 9/12; published 7/13

Lifted Variable Elimination:
Decoupling Operators Constraint Language
Nima Taghipour
Daan Fierens
Jesse Davis
Hendrik Blockeel

nima.taghipour@cs.kuleuven.be
daan.fierens@cs.kuleuven.be
jesse.davis@cs.kuleuven.be
hendrik.blockeel@cs.kuleuven.be

KU Leuven, Department Computer Science
Celestijnenlaan 200A, 3001 Leuven, Belgium

Abstract
Lifted probabilistic inference algorithms exploit regularities structure graphical
models perform inference efficiently. specifically, identify groups
interchangeable variables perform inference per group, opposed per
variable. groups defined means constraints, flexibility grouping
determined expressivity constraint language. Existing approaches exact
lifted inference use specific languages (in)equality constraints, often limited
expressivity. article, decouple lifted inference constraint language.
define operators lifted inference terms relational algebra operators,
operate semantic level (the constraints extension) rather syntactic
level, making language-independent. result, lifted inference performed
using powerful constraint languages, provide opportunities lifting.
empirically demonstrate improve inference efficiency orders magnitude,
allowing exact inference approximate inference feasible.

1. Introduction
Statistical relational learning SRL (Getoor & Taskar, 2007; De Raedt, Frasconi, Kersting, & Muggleton, 2008) focuses combining first-order logic probabilistic graphical
models, permits algorithms reason complex, uncertain, structured domains.
major challenge area perform inference efficiently. First-order logic
reason level logical variables: model states X, P (X) implies Q(X),
whenever P (X) known true, one infer Q(X), without knowing X
stands for. Many approaches SRL, however, transform knowledge propositional graphical model performing inference. so, lose capacity
reason level logical variables: standard inference methods graphical models
reason ground level, repeating inference steps different
value x X, instead x.
address problem, Poole (2003) introduced concept lifted inference
graphical models. idea group together interchangeable objects, perform
inference operations group instead object. Multiple
different algorithms proposed, based variable elimination (Poole, 2003; de
Salvo Braz, Amir, & Roth, 2005; Milch, Zettlemoyer, Kersting, Haimes, & Kaelbling, 2008;
Sen, Deshpande, & Getoor, 2009b, 2009a; Choi, Hill, & Amir, 2010; Apsel & Brafman,
c
2013
AI Access Foundation. rights reserved.

fiTaghipour, Fierens, Davis, & Blockeel

2011), belief propagation (Kersting, Ahmadi, & Natarajan, 2009; Singla & Domingos, 2008),
various approaches (Van den Broeck, Taghipour, Meert, Davis, & De Raedt, 2011;
Jha, Gogate, Meliou, & Suciu, 2010; Gogate & Domingos, 2011).
group interchangeable objects typically defined means constraint
object must fulfill order belong group. type constraints
allowed, way handled, directly influence granularity
grouping, hence, efficiency subsequent lifted inference (Kisynski & Poole,
2009a). Among approaches based variable elimination, advanced system
(C-FOVE) uses specific class constraints, namely, conjunctions pairwise (in)equalities.
bare minimum required able perform lifted inference. However,
show, unnecessarily limits symmetries model capture exploit.
article, present algorithm lifted variable elimination based
C-FOVE, uses constraint language extensionally complete, is,
group variables constraint exists defines exactly group. aim,
C-FOVEs constraint manipulation redefined terms relational algebra operators.
decouples lifted inference algorithm constraint representation mechanism.
Consequently, constraint language closed operators plugged
algorithm obtain working system. Apart redefining existing operators,
also define novel operator, called lifted absorption, way. Furthermore,
propose concrete mechanism constraint representation extensionally complete,
briefly discuss operators implemented particular mechanism.
new lifted inference algorithm, constraint representation mechanism,
perform lifted inference much coarser granularity predecessors. Due this,
outperforms existing systems several orders magnitude problems, solves
inference problems could solved approximate inference methods.
basic ideas behind approach explained earlier conference paper
(Taghipour, Fierens, Davis, & Blockeel, 2012). article extends paper providing
precise motivated definitions operators, level
implemented. definitions, time, may help understand intuitive
semantic level lifted variable elimination works, serve kind gold
standard implementations lifted variable elimination, provide semantics
based reference point.
paper structured follows. Section 2 illustrates principles lifted variable
elimination example, briefly states work improves upon state art,
C-FOVE (Milch et al., 2008). Section 3 introduces formal notation terminology,
Section 4 provides high-level outline lifted variable elimination algorithm. Section
5 describes detail operators algorithm uses. Section 6 briefly discusses
efficient representation constraints themselves. Section 7 empirically compares
systems performance C-FOVE, Section 8 concludes.

2. Lifted Variable Elimination Example
Although lifted variable elimination builds simple intuitions, relatively complicated,
accurate description requires level technical detail conducive
clear understanding. reason, first illustrate basic principles lifted inference
394

fiDecoupling Lifted Variable Elimination Constraint Language

simple example, without referring technical terminology introduced
later. start describing example; next, illustrate variable elimination
example, show lifted.
2.1 Workshop Example
example Milch et al. (2008). Suppose new workshop organized.
workshop popular (that is, many people attend), may start series. Whether
person likely attend depends topic.
introduce random variable , indicating topic workshop, random
variable S, indicating whether workshop becomes series. consider N people,
person i, include random variable Ai indicates whether attends.
random variable finite domain takes values, i.e., {ai, ml, . . . } ,
{yes, no} S, {true, f alse} Ai .
joint probability distribution variables specified undirected
graphical model. set factors captures dependencies random variables
model. model, two kinds factors. person i,
factor 1 (Ai , S) states series depends whether person attends,
factor 2 (T, Ai ) states attendance depends topic. Note N
factors first type potential function 1 , factors second
type potential function 2 . imposes certain symmetry model: implies
depends persons attendance exactly way, people
topic preferences.
model defines joint probability distribution variables normalized product factors (normalized joint probabilities sum one):
Pr(T, S, A1 , . . . , ) =

n
n

1
2 (T, Ai )
1 (Ai , S)
Z
i=1

i=1

Z normalization constant.
Undirected graphical models visualized factor graphs (Kschischang, Frey, &
Loeliger, 2001), node random variable factor, edge
factor random variable variable occurs factor. Figure 1 shows
factor graph example.
2.2 Variable Elimination
on, refer values taken variable corresponding lowercase
symbols (e.g., ai shorthand Ai = ai ).
Suppose want compute marginal probability distribution Pr (S).
Pr (S) =

XX


=



A1

X

Pr (T, S, A1 , . . . , )

N
N

1 XX XY
2 (T, Ai )
1 (Ai , S)

Z


A1

(1)



i=1

395

i=1

(2)

fiTaghipour, Fierens, Davis, & Blockeel


1

1

A1

A2

...

A3


2

2


Figure 1: factor graph workshop example. Square nodes represent factors, round
nodes variables. Variables labeled name, factors potential
function.

Usually, normalization constant Z ignored computations, normalization happens end. So, focus compute
(S) =
Pr

XX


A1



N
XY

1 (Ai , S)

N


2 (T, Ai ).

(3)

i=1

i=1

(S) compute Pr
(s) possible value
straightforward way computing Pr

S, tabulate results. compute Pr(true) iterating
possible
Q
QN value
combinations (t, a1 , . . . , ) (T, A1 , . . . , ) computing N

(a
,
true)
i=1 1
i=1 2 (t, ai )
alse). variables binary, 2N +1
combination, similarly Pr(f
combinations, combination 2N 1 multiplications performed.
clearly scale.
However, improve efficiency rearranging computations. computation, multiplications performed repeatedly. Since 1 (A1 , S) 2 (T, A1 )
constant Ai except A1 , moved summations Ai , > 1,
right hand side Equation 3 becomes:
XX


1 (A1 , S)2 (T, A1 )

X



1 (Ai , S)

N


2 (T, Ai )

(4)

i=2

i=2

A2

A1

N
XY

P
Conversely, factor starting A2 independent A1 , moved outside
summation A1 , giving



N
N

X
XY
X X

2 (T, Ai )
1 (Ai , S)
1 (A1 , S)2 (T, A1 )

(5)


A2

i=2

i=2

A1

Repeating Ai eventually yields




X
X X

1 (AN , S)2 (T, )
1 (A1 , S)2 (T, A1 ) . . .




A1

396

(6)

fiDecoupling Lifted Variable Elimination Constraint Language

12 (T, A1 , S)
1 (A1 , S)
A1
true
false
true
false


true
true
false
false

2 (T, A1 )
1
1
2
2
1


SRL
SRL
DB
DB



A1
true
false
true
false

2
3
1
2
2

=


SRL
SRL
SRL
SRL
DB
DB
DB
DB

A1
true
true
false
false
true
true
false
false


true
false
true
false
true
false
true
false

12
3
6
2
1
2
4
4
2

12 (T, S)

P

A1

12 (T, A1 , S)

=


SRL
SRL
DB
DB


true
false
true
false

12
5
7
6
6

Figure 2: Two example factors, product, result summing A1
product. values 1 2 chosen arbitrarily illustration.

shows Ai , product 1 (Ai , S)2 (T, Ai ) needs computed
combination values (T, S, Ai ). binary, eight
combinations, reducing total number multiplications 8N .
Note result Formula 6 function S; yield different value
value S. words, factor S. Similarly, result 1 (A1 , S)2 (T, A1 )
depends values S, A1 (is factor variables), summation
A1 factor obtained. Thus, multiplications summations
Formula 6 best seen operating factors, individual numbers. Figure 2 illustrates
process multiplying summing factors.
result Formula 6 computed follows. First, multiply factors 1 (A1 , S)
2 (T, A1 ) value A1 , sum A1 product. exactly
computation illustrated Figure 2. summing values A1 , result depends
only; A1 longer occurs factor, factors. say
A1 eliminated. Note elimination consisted first gathering factors
containing A1 , multiplying them, summing possible values A1 .
eliminating A1 , repeat process Ai , time obtaining
factor S. factors multiplied result summed
(S).
, point single factor obtained. factor equals Pr
computation exactly Variable Elimination (VE) does. Generally,
works follows. considers one variable time, order called elimination
order. considered variable X, first retrieves factors involve X,
multiplies factors together single joint factor, finally sums X, thereby
397

fiTaghipour, Fierens, Davis, & Blockeel

eliminating X factor. Hence, step, number remaining variables
strictly decreases (by 1) also number factors decreases (because set factors
involving X replaced single factor).
elimination order heavily influence runtime. Unfortunately, finding optimal
order NP-hard. example, elimination order A1 , A2 , . . . , , ,
resulted computation 8N multiplications, O(N ).
2.3 Lifted Inference: Exploiting Symmetries Among Factors
example, avoiding many redundant computations, obtained exponential speedup compared naive computation discussed before, reducing computation
time O(2N ) O(N ). N still large. Even efficiency gained
know certain factors potential function.
example, computes product N times: Expression 6, factors
1 (Ai , S) 2 (T, Ai ) allPi, product 12 (Ai , S, ) =
1 (Ai , S)2 (T, Ai ). also computes sum Ai 12 (Ai , S, ) N times. redundancy
arises probabilistic model N people behave way, i.e.,
Ai interchangeable. idea behind lifted inference exploit symmetries,
compute product sum once. algorithmic perspective, lifted
variable elimination eliminates one Ai variable, exponentiates resulting factor
(see formula below), sums . Mathematically, Expression 6 computed
follows:


N

X


X
(1 (A1 , S)2 (T, A1 ))

(7)

A1

way lifted variable elimination manipulates set variables {A1 , . . . , }
called lifted multiplication lifted summing-out (a.k.a. lifted elimination). Note
number operations required constant N . Assuming N already known,
main operation computing N -th power, O(log N ) (logarithmic
N exact arithmetic used, constant floating point arithmetic). Thus, lifted variable
elimination runs O(log N ) time case.
2.4 Lifted Inference: Exploiting Symmetries within Factors
consider second elimination order, first eliminate Ai :
(S) =
Pr

X

N
XY

A1 ,...,AN

1 (Ai , S)

i=1

N


2 (T, Ai ) =

X

N


A1 ,...,AN i=1

i=1

1 (Ai , S)

N
XY


i=1

!

2 (T, Ai )

(8)
order, regular variable elimination works follows. inner summation (elimination ) first multiplies factors 2 (T, Ai ) factor 3 (T, A1 , . . . , ),
sums :
N
XY
i=1

2 (T, Ai ) =

X

3 (T, A1 , . . . , ) = 3 (A1 , . . . , )



398

fiDecoupling Lifted Variable Elimination Constraint Language

Note 3 function N + 1 binary variables, tabular representation 2N +1
entries, makes cost elimination O(2N +1 ). Substituting computed 3
Equation (8) yields:

Pr(S)
=

X

A1 ,...,AN

N


!

1 (Ai , S)

i=1

3 (A1 , . . . , )

multiply 3 (A1 , . . . , ) 1 (A1 , S) sum A1 , multiply result
1 (A2 , S) sum A2 , on, obtain factor 4 (S):
(S) = 4 (S)
Pr
involves N multiplications summations exponential complexity.
summary, variable elimination computes result O(2N +1 ).
elimination order also symmetries lifted inference exploit. Let us
examine 3 (T, A1 , . . . , ), product factors 2 (T, Ai ). assignment =
(A1 , . . . , ) = (a1 , . . . ) {true, f alse}N :
3 (t, a1 , . . . , ) = 2 (t, a1 ) . . . 2 (t, )
Note that, since ai {true, f alse}, multiplicands right hand side
one two values, 2 (t, true) 2 (t, f alse). is, ai = true
2 (t, true), similarly ai = f alse, 2 (t, f alse). means that,
= {Ai |ai = true} Af = {Ai |ai = f alse}, rewrite expression as:
3 (t, a1 , . . . , ) =



2 (t, true)

ai



2 (t, f alse) = 2 (t, true)|At | 2 (t, f alse)|Af | .

ai Af

shows evaluate 3 (T, A1 , . . . , ) suffices know many Ai true (call
number nt ) false (nf ); need know value individual Ai .
therefore restate 3 terms new variable #[A], called counting variable, value
two-dimensional vector (nt , nf ). Generally, #[A] take value (x, y)
x, N x + = N . call value histogram. captures distribution
values among = {A1 , . . . , }. reformulation factor terms counting
variable called counting conversion. Rewriting 3 (T, A1 , . . . , ) 3 (T, #[A]),
3 (t, (nt , nf )) = 2 (t, true)nt 2 (t, f alse)nf .
3 2(N + 1) possible input combinations (two values N + 1 values (nt , nf ),
since nt +nf = N ). tabulated time O(N ), using recursive formula 3 (t, (nt +
1, nf 1)) = 3 (t, (nt , nf )) 1 (t, true)/2 (t, f alse). Note VEs computation 3
O(2N ).
3 2(N +1) possible input states, instead 2N +1 , eliminate
O(N ):
N
X
XY
2 (T, Ai ) =
3 (T, #[A]) = 3 (#[A])


i=1



399

fiTaghipour, Fierens, Davis, & Blockeel

Using result, continue elimination:
(S) =
Pr

X

N


1 (Ai , S) 3 (#[A])

A1 ,...,AN i=1

Using counting conversion second time, reformulate result
4 (#[A], S), gives:
(S) =
Pr

X

4 (#[A], S) 3 (#[A]) =

A1 ,...,AN

X

QN

i=1 1 (Ai , S)

43 (#[A], S)

(9)

A1 ,...,AN

itself, final summation still enumerates 2N joint states variables A, computes
histogram (nt , nf ) 43 ((nt , nf ), S) state, adds 43 .
better: states result histogram (nt , nf ) value

43 ((nt , nf ), S), know exactly many joint states are, namely nNt =
N!
nt !nf ! . call multiplicity histogram (nt , nf ), denoted Mul((nt , nf )).
Thus, compute 43 ((nt , nf ), S) histogram (nt , nf ) multiply
multiplicity:
X

43 (#[A], S) =

A1 ,...,AN

X

Mul(#[A]) 43 (#[A], S)

#[A]

way enumerate N + 1 possible values #[A] instead 2N possible states
A. summarize, reformulate Equation (9)
(S) =
Pr

X

43 (#[A], S) =

A1 ,...,AN

X

Mul(#[A]) 43 (#[A], S) = 5 (S)

#[A]

shows #[A] eliminated O(N ) operations.
(S) thus complexity O(N ), instead O(2N )
whole computation Pr
elimination order. reduction complexity possible due symmetries
model allow us treat variables one unit #[A].
2.5 Capturing Symmetries
clear lifting yield important speedups, certain symmetries among factors
among inputs single factor present. exploit these, essential one
indicate variables interchangeable hence induce symmetries.
workshop example, assume, instance, every person
preferences respect topics, two types people, different potentials
(2a 2b ) associated type person. clear instead Formula 7,
X





X
A1

N

1 (A1 , S)2 (T, A1 ) ,
400

fiDecoupling Lifted Variable Elimination Constraint Language

need compute
Na

Nb
X X
X

1 (Ak , S)2a (T, Ak )
1 (Al , S)2b (T, Al )


Ak

Al

Ak Al random members first second group, Na Nb
cardinality groups. order this, need able state Ai
2a relevant, 2b is. (For particular computation, actually suffices
know size group, true general; instance, compute
marginal distribution A5 , need know group A5 in.)
main contribution related particular point. time writing,
C-FOVE system (Milch et al., 2008) considered state art lifted variable elimination. introducing counting variables, capture within-factor symmetries better
predecessor, FOVE. However, turns out, C-FOVE less good capturing
symmetries among multiple factors, compared FOVE. groups variables
factors defined means constraints, C-FOVE uses constraint language
limited FOVEs; essentially, allows conjunctive constraints.
two reasons important able group variables much
flexibility possible. First, gives flexibility user specify
graphical model itself. Second, inference, may become necessary split
groups subgroups.
cannot go detail constraint based representation point (we
later), basically, lifted inference, one may set interchangeable
variables could principle treated one group, system
cannot represent group. needs partition group smaller groups,
possibly level individuals. instance, assume groups example
{A1 , A2 , A5 , A6 , A7 } {A3 , A4 , A8 }. assume constraint language
sets variables Ai defined using constraints form {Ai |l u}.
Neither group represented using one single constraint. instance, first group
consists union {Ai |1 2} {Ai |5 7}. Using constraint language,
get four groups size 2, 3, 2 1 instead two groups size 5 3. result,
computation actually performed contain four exponentiated factors instead two:
3
2

X
X
X

1 (A5 , S)2a (T, A5 )
1 (A1 , S)2a (T, A1 )


A5

A1

1
2

X
X

1 (A8 , S)2b (T, A8 )
1 (A3 , S)2b (T, A3 )
A8

A3

Generally, lifted inference, groups may split repeatedly. Unnecessary splits
substantially hurt efficiency, one causes duplication work. Since duplicated
work may include splitting, overall effect exponential number
consecutive splits.
Ideally, constraint language property group variables,
exists constraint represents exactly group variables. case,
401

fiTaghipour, Fierens, Davis, & Blockeel

never necessary split group subgroups group cannot represented.
call language extensionally complete. main contribution article
shows perform lifted variable elimination extensionally complete
constraint language. aim, first, lifted variable elimination algorithm defined
way independent constraint representation mechanism, defining
operators terms relational algebra expressions. call algorithm GC-FOVE.
make GC-FOVE operational, kind constraint representation mechanism course
needed. constraint language L plugged GC-FOVE, long closed
respect relational algebra operators used GC-FOVE. Second, propose
extensionally complete constraint representation language based trees.
language necessarily closed respect relational algebra operators, therefore
suitable GC-FOVE. resulting system, GC-FOVETREES , perform inference
higher level granularity, therefore efficiently, C-FOVE,
use extensionally complete constraint language. effect visible particular
evidence given (which breaks symmetries hence causes group splitting);
cases, GC-FOVE achieves exponential speedups compared C-FOVE.
ends informal introduction lifted variable elimination main contribution articles makes it. following sections, first introduce formal notation
terminology, present contributions detail.

3. Representation
Lifted inference exploits symmetries probabilistic model. symmetries often occur
models repeating structures, plates (Getoor & Taskar, 2007, Ch. 7),
or, generally, probabilistic-logical models. Probabilistic-logical modeling languages
(also called probabilistic-relational languages) combine representational inferential
aspects first-order logic probability theory.
First-order logic languages refer objects (possibly various types) universe,
properties of, relationships between, objects. Formulas languages
express property holds particular object, entire set objects.
instance, fact humans mortal could written x : Human(x)
ortal(x). Probabilistic-logical models can, similar way, express probabilistic knowledge objects. instance, could state human, prior
probability 20% smokes: x : P (Smokes(x)|Human(x)) = 0.2.
ability make (probabilistic) statements entire sets objects allows
languages compactly express symmetries model. Many different languages exist
representing probabilistic-logical models (e.g., see Getoor & Taskar, 2007). use representation formalism based undirected graphical models closely related one
used earlier work lifted variable elimination (Poole, 2003; de Salvo Braz, 2007; Milch
et al., 2008).
concepts introduced section also introduced earlier work (de
Salvo Braz, 2007; Milch et al., 2008). Differences arise terminology notation
emphasize constraint part.
402

fiDecoupling Lifted Variable Elimination Constraint Language

3.1 Constraint-based Representation Formalism
undirected model factorization joint distribution set random variables (Kschischang et al., 2001). Given set random variables X = {X1 , X2 , . . . , Xn },
factor consists potential function assignment random variable
inputs. instance, factorization f (X1 , X2 , X3 ) = (X1 , X2 )(X2 , X3 ) contains
two different factors (even potential functions same).
Likewise, probabilistic-logical representation framework, model set factors. random variables operate properties of, relationships between,
objects universe. introduce terminology make concrete.
assume familiarity set relational algebra (union , intersection , difference
\, set partitioning, selection C , projection X , attribute renaming , join ); see,
instance, work Ramakrishnan Gehrke (2003).
term variable used logical probabilistic context.
avoid confusion, use term logvar refer logical variables, randvar refer
random variables. write variable names uppercase, values lowercase. Sets
sequences logvars written boldface, sets sequences randvars calligraphic;
values written boldface lowercase.
vocabulary representation includes finite set predicates finite set
constants. constant represents object universe. term either constant
logvar. predicate P arity n finite range (range(P )); interpreted
mapping n-tuples objects (constants) range. atom form
P (t1 , t2 , . . . , tn ), ti terms. ground atom atom ti constants.
ground atom represents random variable; implies interpretation, element
range(P ), corresponds assignment value random variable. Hence,
range predicate corresponds range random variables represent,
limited {true, f alse} logic.
Logvars finite domain, set constants. domain logvar
X denoted D(X). constraint relation defined set logvars, i.e.,
pair (X, CX ), X = (X1 , X2 , . . . , Xn ) tuple logvars, CX subset
D(X) = D(Xi ) (Dechter, 2003). Hence, CX set, whose elements (tuples) indicate
allowed combinations value assignments variables X. ease exposition,
identify constraint relation CX , write C instead CX X apparent
context. assume implicit ordering values CX tuples according
order logvars X. instance X = (X1 , X2 ), constraint CX = {(a, b), (c, d)}
indicates two possibilities: either X1 = X2 = b, X1 = c X2 = d.
constraint contains one tuple called singleton.
constraint may defined extensionally, listing tuples satisfy it, intensionally, means logical condition, expressed constraint language. call
constraint language L extensionally complete express relation logvars X,
i.e., subset D(X), constraint CX L whose extension exactly
subset.
constrained atom form P (X)|C, P (X) atom C constraint
X. constrained atom P (X)|C represents set ground atoms {P (x)|x C},
hence set randvars. consistency literature, call constrained atom
403

fiTaghipour, Fierens, Davis, & Blockeel

parametrized randvar (PRV), use calligraphic notation denote it. Given PRV V,
use RV (V) denote set randvars represents; also say randvars
covered V.
valuation randvar (set randvars) assignment value randvar
(an assignment values randvars set).
Example 1. PRV V = Smokes(X)|C, C = {x1 , . . . , xn }, represents n randvars
{Smokes(x1 ), . . . Smokes(xn )}.

factor f = f (Af ) consists sequence randvars Af = (A1 , . . . , )
potential function f : ni=1 range(Ai ) R+ . product two factors, f1 f2 ,
defined follows. Factor f = (A) product f1 = 1 (A1 ) f2 = 2 (A2 )
(a) = ai
= A1 A2 D(A): (a) = 1 (a1 )2 (a2 ) AiQ
= 1, 2. is, assigns randvar Ai value ai . use
denote
multiplication multiple factors. Multiplying factor scalar c means replacing
potential : x 7 c (x).
undirected
model set factors F . represents
probability distribution PF
1 Q

(A
randvars = P


follows:
P
(A)
=
F
f ), Z normalization
f
f F f
f F
Z
constant arange(A) PF (a) = 1.
parametric factor parfactor form (A)|C, = {Ai }ni=1 sequence
atoms, potential function A, C constraint logvars appearing A.1
set logvars occurring denoted logvar(A); set logvars C denoted
logvar(C). factor (A ) grounding parfactor (A) obtained
instantiating X = logvar(A) x C. set groundings parfactor g
denoted gr(g).
Example 2. Parfactor g1 = 1 (Smokes(X))|X {x1 , . . . , xn } represents set factors

gr(g1 ) = {1 (Smokes(x1 )), . . . , 1 (Smokes(xn ))}.
set parfactors G compact way defining set factors
Q F = {f |f gr(g)g
G} corresponding probability distribution PG (A) = Z1 f F f (Af ).
3.2 Counting Formulas

Milch et al. (2008) introduced idea counting formulas (parametrized) counting
randvars.
counting formula syntactic construct form #Xi C [P (X)], Xi X
called counted logvar.
grounded counting formula counting formula arguments atom
P (X), except counted logvar, constants. defines counting randvar (CRV),
meaning follows. First, define set randvars covers
RV (#XC [P (X)]) = RV (P (X)|X C). value CRV determined values
randvars covers. specifically, histogram indicates, given valuation RV (P (X)|X C), many different values X occur r range(P ).
Thus, value form {(r1 , n1 ), (r2 , n2 ), . . . , (rk , nk )}, ri range(P ) ni
1. use definition Kisynski Poole (2009a) parfactors, allows us simplify notation.

404

fiDecoupling Lifted Variable Elimination Constraint Language

corresponding count. Given histogram h, also write h(v) count v h.
Note range CRV, i.e., set possible histograms take value,
determined k = |range(P )| |C|.
Example 3. #X{x1 ,x2 ,x3 } [P (X, y, z)] grounded counting formula. covers rand-

vars P (x1 , y, z), P (x2 , y, z) P (x3 , y, z). defines CRV, value determined values three randvars; P (x1 , y, z) = true, P (x2 , y, z) = f alse
P (x3 , y, z) = true, CRV takes value {(true, 2), (f alse, 1)}.
concept CRV somewhat complicated. CRV behaves like regular randvar
ways, all. construct occur argument factor, like
regular randvars, role actually stands set randvars,
arguments factor. factor form ( , #XC [P (X)], ) equivalent
factor form ( , P (X1 ), P (X2 ), . . . , P (Xk ), ), P (Xi ) instantiations
X obtainable instantiating X value C, returning
valuation P (Xi ) value returns corresponding histogram.
Example 4. factor (#X{x1 ,x2 ,x3 } [P (X, y, z)]) equivalent factor

(P (x1 , y, z), P (x2 , y, z), P (x3 , y, z)). ({(true, 2), (f alse, 1)}) = 0.3, implies
(f alse, true, true) = (true, f alse, true) = (true, true, f alse) = 0.3.
illustrated Section 2.4, counting formulas useful capturing symmetries
within potential function. Recall workshop example. Whether person attends
workshop depends topic, dependence person.
represent single parfactor (T, A(X))|X {x1 , . . . , xn } represents
n ground factors. Eliminating requires multiplying n factors single factor
(T, A(x1 ), A(x2 ), . . . , A(xn )) summing . potential function highdimensional, tabular representation would costly. However, contains
certain symmetry: depends many times possible value A(xi ) occurs,
exactly occur. representing factor using potential function
two arguments, CRV #X{x1 ,...,xn} [A(X)], represented
concisely, computed efficiently. instance, sum A(X),
need enumerate possible (2n ) value combinations A(xi ) sum corresponding (T, A(x1 ), . . . , A(xn )), need enumerate possible (n + 1) values
histogram #X{x1 ,...,xn } [A(X)] sum corresponding (T, #X{x1 ,...,xn } [A(X)]),
multiplied multiplicity.
Note complementarity PRVs CRVs. randvars covered
PRV occur different factors, randvars covered CRV occur one
factor. Thus, PRVs impose symmetry among different factors, whereas CRVs impose
symmetry within single factor.
parametrized counting randvar (PCRV) form #X [P (X)] |CX . notation
write constraint counted logvar X part constraint CX variables
X. Similar way PRV defines set randvars groundings,
PCRV defines set CRVs groundings variables X \ {X}.
Example 5. #Y [F riend(X, )] |C represents set CRVs, one x X (C),
indicating number friends x has. C = D(X) D(Y ) D(X) = D(Y ) =
405

fiTaghipour, Fierens, Davis, & Blockeel

{ann, bob, carl}, might instance #Y [F riend(ann, )]|C = {(true, 1), (f alse, 2)}
(Ann one friend, two people friends her).
definitions previous section need extended slightly order
accommodate PCRVs. First, CRVs regular randvars, included
set randvars covered PRCV; is, RV (#Xi [P (X)]|C) = RV (P (X)|C).
Second, since counting formula binds counted logvar (it longer parameter
resulting PCRV), define logvar(#Xi [P (X)]) = X \ {Xi }. Thus, generally, logvar(A)
refers logvars occurring A, excluding counted logvars. Note logvar(C)
remains unchanged: refers logvars C, whether appear counted not.
end section two definitions useful later on.
Definition 1 (Count function) Given constraint CX , X Z XY,
function CountY|Z : CX N defined follows:
CountY|Z (t) = |Y (Z=Z (t) (CX ))|
is, tuple t, function tells us many values co-occur ts value
Z constraint. define CountY|Z (t) = 1 = .
Definition 2 (Count-normalized constraint) constraint CX , X Z
X Y, count-normalized w.r.t. Z CX
n N : CX : CountY|Z (t) = n.
n exists, call conditional count given Z CX , denote
CountY|Z (CX ).
Example 6. Let X {P, C} let constraint CX (P, C) {(ann, eric), (bob, eric),

(carl, f inn), (debbie, f inn), (carl, gemma), (debbie, gemma)}. Suppose CX indicates parent relationship: Ann parent Eric, etc. {P } count-normalized w.r.t. {C}
children (i.e., instantiations C CX : Eric, Finn Gemma) two parents according CX , formally, tuples CX holds Count{P }|{C} (t) = 2.
Conversely, {C} count-normalized w.r.t. {P } parents equally
many children. instance, Count{C}|{P } ((ann, eric)) = 1 (Ann 1 child),
Count{C}|{P } ((carl, f inn)) = 2 (Carl 2 children).

4. GC-FOVE Algorithm: Outline
turn problem performing lifted inference models specified using
representation. algorithm introduce called GC-FOVE (for Generalized C-FOVE). high level, similar C-FOVE (Milch et al., 2008), current
state-of-the-art system lifted variable elimination, differs definition
implementation operators.
Recall standard variable elimination works. eliminates randvars one one,
particular order called elimination order. Elimination consist multiplying factors
randvar occurs one factor, summing randvar.
406

fiDecoupling Lifted Variable Elimination Constraint Language

Similarly, GC-FOVE visits PRVs (as opposed individual randvars) particular
order. Ideally, eliminates PRV multiplying parfactors occurs
one parfactor, summing PRV, using lifted multiplication lifted
summing-out operators. However, operators always immediately applicable:
may necessary refine involved parfactors PRVs make so.
done using operators, call enabling operators.2
high-level description GC-FOVE shown Algorithm 1. Like C-FOVE, makes
use number operators, repeatedly selects performs one possible
operators one parfactors. uses greedy heuristic C-FOVE
selection, choosing operation minimum cost, cost operation
defined total size (number rows tabular form) potentials creates.
main difference C-FOVE GC-FOVE operators used. Four
GC-FOVEs operators (multiply, sum-out, count-convert ground-logvar)
straightforward generalization similar operator C-FOVE, difference
provide definitions work constraint representation language closed
relational algebra, instead definitions specific constraint language
used C-FOVE. Three operators (expand, count-normalize split) also
counterparts C-FOVE, need redefined substantially directly
concern constraint manipulation. lifted absorption operator (absorb) completely
new.
GC-FOVE specify particular constraint language. practice, constraints represented one way another, constraint representation mechanism plugged in. article, propose tree-based representation mechanism
constraints. Important advantages mechanism that, one hand,
extensional set represented trees, hand, constraints
still manipulated efficiently.
generalization operators, new absorption operator, tree-based
constraint language main contributions paper. Together, greatly improve
efficiency inference, clear experimental section. describing operators detail, illustrate importance using expressive constraint
language.
4.1 Constraint Language
C-FOVE, constraint set pairwise (in)equalities single logvar
constant, two logvars. Thus, single parfactor, C-FOVE represent, instance, F riend(X, )|X 6= ann, F riend(X, )|(X, ) {(ann, bob), (bob, carl)}).
Table 1 provides examples PRVs C-FOVE can/cannot represent,
Figure 3 illustrates visually. Basically, C-FOVE use conjunctive constraints,
disjunctive ones, C-FOVEs operators defined operate directly representation. GC-FOVE, hand, allows constraint relation
logvars, therefore handle PRVs. restrictions whatsoever
regarding constraints handle, maximally exploit opportunities lifting.
2. Technically speaking, multiplication also enabling operator summing-out applied
multiplication.

407

fiTaghipour, Fierens, Davis, & Blockeel

GC-FOVE
Inputs:
G: model
Q: query randvar
Algorithm:
G contains randvars Q:
PRV V eliminated lifted absorption
G apply operator absorb eliminate V G
else PRV V eliminated lifted summing-out
G apply sum-out eliminate V G
else apply enabling operator (one multiply, count-convert, expand,
count-normalize, split ground-logvar) parfactors G
end
return G
Algorithm 1: Outline GC-FOVE algorithm.
PRV
F riend(X, )
F riend(ann, )
F riend(X, )|X 6= ann
F riend(X, )|X {ann, bob}
F riend(X, )|(X, ) {(ann, bob), (bob, carl)})

C-FOVE
yes
yes
yes
yes


GC-FOVE
yes
yes
yes
yes
yes

Table 1: Examples parametrized random variables / cannot represented using
single constraint C-FOVE. Though fourth constraint (yes ) disjunctive,
C-FOVE represent using conjunction inequality constraints.
case fifth constraint. GC-FOVE represent constraints.

expressiveness constraint representation language, way constraints handled operators, crucial efficiency lifted variable elimination. reason variables continuously need re-grouped (i.e., constraints need
rewritten) inference. instance, multiply 1 (P (X))|{x1 , x2 , x3 }
2 (P (X))|{x1 , x2 , x3 } directly, resulting parfactor form 12 (P (X))|{x1 , x2 , x3 },
cannot multiply 1 (P (X))|{x1 , x2 , x3 } 2 (P (X))|{x2 , x3 , x4 , x5 } single
parfactor PRVs match. solution split constraints parfactors matching parfactors arise. particular case, model three parfactors
arises: 1 (P (x1 )), 12 (P (X))|{x2 , x3 } 2 (P (X))|{x4 , x5 }. GC-FOVEs operations result model. C-FOVE, however, splitting constraints, separates one tuple
time (splitting based substitution, Milch et al., 2008), results four parfactors: 1 (P (x1 )); 12 (P (X))|X 6= x1 , X 6= x4 , X 6= x5 ; 2 (P (x4 )); 2 (P (x5 )) (assuming
domain X {x1 , x2 , . . . , x5 }). case, C-FOVE could fact represent separate factors 2 (P (x4 )) 2 (P (x5 )) one parfactor 2 (P (X))|X 6= x1 , X 6= x2 , X 6= x3 ,
(only intersection two constraints kept lifted level),
408

fiDecoupling Lifted Variable Elimination Constraint Language


b
c

e
f


b
c

e
f
b c e f


b
c

e
f


b
c

e
f
b c e f


b
c

e
f
b c e f

b c e f

b
c

e
f

b c e f

b c e f

Figure 3: schema, gray area indicates PRV form F riend(X, )|CXY
(with standing ann, b bob, etc.) C-FOVE handle PRVs
defined conjunctive constraints; includes top three schemas,
bottom ones. GC-FOVE handle PRVs.

general, non-unary predicates, possible, Table 1 shows.
restricted constraint language, C-FOVE often create finer-grained partitions
necessary. GC-FOVE, uses extensionally complete constraint language,
suffer problem.
4.2 Lifted Absorption
Absorption (van der Gaag, 1996) additional operator known increase
efficiency. consists removing random variable model valuation
known, rewriting model equivalent one contain variable.
C-FOVE, like predecessors, use absorption, including might fact
detrimental effects due breaking symmetries. GC-FOVEs extensionally complete
constraint language, however, makes possible use absorption effectively,
even allows lifting it.
4.3 Summary Contributions
point summarize contributions work precisely.
1. present first description lifted variable elimination decouples lifted
inference algorithm constraint representation uses. done taking
C-FOVE algorithm redefining operators become independent
underlying constraint mechanism. achieved defining operators
409

fiTaghipour, Fierens, Davis, & Blockeel

terms relational algebra operators. redefinition generalizes operators
clarifies higher level work.
2. present mechanism representing constraints extensionally complete.
closed relational algebra operators, allows executing
efficiently. itself, minor contribution, necessary order obtain
operational system.
3. present new operator, called lifted absorption.
4. experimentally demonstrate practical impact contributions.
5. contribute software itself.
Contributions 1 3 (our main contributions) subject Section 5. Contribution 2 detailed Section 6, Contribution 4 Section 7. Contribution 5
http://dtai.cs.kuleuven.be/ml/systems/gc-fove.

5. GC-FOVEs Operators
section provides detailed information GC-FOVEs operators. conceptually split two categories: operators manipulate potential functions,
operators refine model first type operators applied.
start three operators belong first category: lifted multiplication, lifted
summing-out counting conversion. seen generalized versions
corresponding C-FOVE operators; algorithmically, similar. Next, discuss splitting, shattering, expansion, count normalization. operate specifically
constraints, differ strongly C-FOVEs operators. systematically compare latter, showing time C-FOVEs constraint language
operators force create fine-grained models necessary, GC-FOVE,
extensionally complete constraint language, always avoid this: whatever
set interchangeable randvars is, set represented one constraint. Finally,
discuss lifted absorption, completely new, grounding, similar
C-FOVE counterpart.
following, G refers model (i.e., set parfactors), G1 G2 means
models G1 G2 define probability distribution.
5.1 Lifted Multiplication
lifted multiplication operator multiplies whole parfactors once, instead separately multiplying ground factors cover (Poole, 2003; de Salvo Braz, 2007; Milch
et al., 2008). Figure 4 illustrates two parfactors g1 = 1 (S(X))|C g2 =
2 (S(X), A(X))|C, C = (X {x1 , . . . , xn }). Lifted multiplication equivalent
n multiplications ground level.
illustration deceptively simple, several reasons. First, naming
logvars suggests logvar X g1 corresponds X g2 . fact, g2 could
multiple logvars, different names. alignment parfactors necessary,
showing logvars different parfactors correspond (de Salvo Braz, 2007).
410

fiDecoupling Lifted Variable Elimination Constraint Language

1 (S(X))




1 (S(x1 ))

2 (S(X), A(X))
2 (S(x1 ), A(x1 ))



S(x1 )

1

3 (S(x1 ), A(x1 ))
..
.

Multiplications



2 (S(xn ), A(xn ))
2

3 (S(X), A(X))

Ground

..
.

..
.
1 (S(xn ))

Lifted
Multiplication



3 (S(xn ), A(xn ))

A(x1 )

S(x1 )

3

A(x1 )

3

A(xn )



..
.
1

Ground
Multiplications

..
.


S(xn )

2

A(xn )

S(xn )



Figure 4: Lifted Multiplication 1:1 alignment parfactors. equivalent
lifted operation (top), shown level ground factors (middle),
also terms factor graphs (bottom). denotes (par)factor multiplication.

alignment must constrain aligned logvars exactly values g1
g2 (otherwise, cannot give identical PRVs parfactors). formalize
follows.
Definition 3 (substitution) substitution = {X1 t1 , . . . , Xn tn } = {X
t} maps logvar Xi term ti , constant logvar. ti
constants, called grounding substitution, different logvars,
renaming substitution. Applying substitution expression means replacing
occurrence Xi ti ; result denoted .
Definition 4 (alignment) alignment two parfactors g = (A)|C g =
(A )|C one-to-one substitution {X X }, X logvar(A) X logvar(A ),
(X (C)) = X (C ) (with attribute renaming operator).
alignment tells multiplication operator two atoms two different parfactors
represent PRV, suffices include resulting parfactor once.
Including twice wrong, less efficient: structure parfactor
lost. reason, useful look maximal alignments map many
PRVs possible.
Example 7. Consider g1 = 1 (S(X), F (X, ))|CX,Y g2 = 2 (S(X ), F (X , ))|CX ,Y


CX,Y = CX ,Y = {xi }n1 {yj }m
1 . Using maximal alignment {X X ,

411

fiTaghipour, Fierens, Davis, & Blockeel

)}, get product parfactor 3 (S(X), F (X, ))|CX,Y . alignment establishes
1:1 association ground factor 1 (S(xi ), F (xi , yj )) corresponding
2 (S(xi ), F (xi , yj )). If, however, multiply g1 g2 alignment {X X },

result parfactor 3 (S(X), F (X, ), F (X, ))|(X, Y, ) {xi }n1 {yj }m
1 {yk }1 ,
xi unnecessarily multiplies factor 1 (S(xi ), F (xi , yj )) factors
2 (S(xi ), F (xi , yk )), k = 1, . . . , m. words, unnecessarily creates direct dependency pairs randvars F (xi , yj ), F (xi , yk ).
second complication single randvar may participate multiple factors within
certain parfactor, number factors appears may differ across parfactors. Consider parfactors g1 = 1 (S(X))|X {xi }n1 g2 = 2 (S(X), F (X, ))|(X, )
{xi }n1 {yi }m
1 . xi , 1 (S(xi )) shares randvar S(xi ) factors 2 (S(xi ), F (xi , yj )),
j = 1, . . . , m. Multiplication result single parfactor 3 (S(xi ), F (xi , ))|Y
{yi }m
1 covers factors 3 (S(xi ), F (xi , yj )), equivalent product one
factor 1 (S(xi )) factorsQ2 (S(xi ), F (xi , yj )). means must find 3
1/m (v, w).
v, w : 3 (v, w)m = 1 (v)
2
i=1 2 (v, w). gives 3 (v, w) = 1 (v)
exponentiation 1 power 1/m called scaling. result multiplication
single xi regardless xi , finally, product parfactors g1
g2 parfactor
3 (S(X), F (X, )) = 1 (S(X))1/m 2 (S(X), F (X, )) | (X, ) {xi }n1 {yj }m
1 .
Figure 5 illustrates multiplication graphically.
alignment parfactors called 1 : 1 non-counted logvars parfactors
mapped other, called m:n otherwise. Multiplication based m:n
alignment involves scaling, requires non-aligned logvars count-normalized
(Definition 2, p. 406) respect aligned logvars constraints (otherwise
single scaling exponent valid whole parfactor).
Operator 1 formally defines lifted multiplication. Note definition
assume specific format constraints.
5.2 Lifted Summing-Out
PRV occurs one parfactor, summed parfactor (Milch
et al., 2008). begin example lifted summing-out, help motivate
formal definition operator.
Example 8. Consider parfactor g = (S(X), F (X, ))|C, C = {(xi , yi,j ) :

{1, . . . , n}, j {1, . . . , m}} (Figure 6). Note count-normalized w.r.t X C. Assume want sum randvars F (xi , yi,j ) RV (F (X, )|C) ground level.
randvar F (xi , yi,j ) appears exactly one ground factor (S(xi ), F (xi , yi,j )) (see Figure 6
(middle)). therefore sum
P F (xi , yi,j ) factor independently
others, obtaining factor (S(xi )) = F (xi ,yi,j ) (S(xi ), F (xi , yi,j )). Since ground
factors (S(xi ), F (xi , yi,j )) potential , summing second argument
always results potential , compute and, instead storing copies resulting factor (S(xi )), store single factor (S(xi )) = (S(xi ))m .
end, obtain n factors, one S(xi ), = 1, . . . , n. represent
412

fiDecoupling Lifted Variable Elimination Constraint Language

1 (S(X))

1 (S(x1 ))





..
.

2 (S(X), F (X, ))

i=1

Lifted

1 (S(X))1/m 2 (S(X), F (X, ))



1/m


2 (S(x1 ), F (x1 , y1 ))
1 (S(x1 ))
Scaling 1
..
..







.
.




2 (S(x1 ), F (x1 , ym ))
1 (S(x1 ))1/m





1/m


1 (S(xn ))
2 (S(xn ), F (xn , y1 ))
..
Scaling 1
..
.
.



1 (S(xn ))1/m
2 (S(xn ), F (xn , ym ))

2
S(x1 )

..
.
2

1/m

1

F (x1 , y1 )
Scaling 1


F (x1 , ym )

Multiplications





3 (S(X), F (X, ))



3 (S(x1 ), F (x1 , y1 ))
..
.


3 (S(x1 ), F (x1 , ym ))

2 (S(x1 ), F (x1 , y1 ))
..
.
2 (S(x1 ), F (x1 , ym ))



Ground

..
.
1/m
1


S(x1 )






2 (S(xn ), F (xn , y1 ))
3 (S(xn ), F (xn , y1 ))
..
..
.
.


3 (S(xn ), F (xn , ym ))
2 (S(xn ), F (xn , ym ))




2
..
.
2

F (x1 , y1 )
S(x1 )
F (x1 , ym )

..
.

..
.
2
1

!m

Multiplications

1 (S(xn ))

1

Scaling 1



S(xn )

..
.
2

Scaling 1

F (xn , ym )

..
.
3

F (x1 , ym )

3

F (xn , y1 )

..
.
3

F (xn , ym )

Ground
Multiplications
1/m



F (x1 , y1 )



1

F (xn , y1 )

3

..
.
1/m
1


S(xn )



2
..
.
2

F (xn , y1 )
S(xn )
F (xn , ym )

Figure 5: Lifted Multiplication m:n alignment parfactors. equivalent
lifted operation (top), shown level ground factors (middle),
also terms factor graphs (bottom).

result using single parfactor g = (S(X))|C , C = {x1 , . . . , xn } = X (C).
Lifted summing-out directly computes g g one operation. Note
single exponent , must count-normalized w.r.t. X C.
Like C-FOVE counterpart, lifted summing-out operator requires one-to-one
mapping summed-out randvars factors; is, summed-out randvar
appears exactly one factor, factors different. guaranteed
eliminated atom contains logvars parfactor, since different
ground factor instantiation logvars. Further, lifted summing-out may result
identical factors ground level, exploited computing one factor
exponentiating. case logvar occurs eliminated
atom, atoms (such F (X, ) example).
already illustrated Section 2.4, counting randvars require special attention
lifted summing-out. formula like (#X [P (X)])|X {x1 , . . . , xk } really shorthand
factor (P (x1 ), P (x2 ), . . . , P (xk )) whose value depends many arguments
take particular values. principle, need sum combinations values
P (Xi ). replace summing values #X [P (X)], condition
take multiplicities latter account. multiplicity histogram
413

fiTaghipour, Fierens, Davis, & Blockeel

Operator multiply
Inputs:
(1) g1 = 1 (A1 )|C1 : parfactor G
(2) g2 = 2 (A2 )|C2 : parfactor G
(3) = {X1 X2 }: alignment g1 g2
Preconditions:
(1) = 1, 2: Yi = logvar(Ai ) \ Xi count-normalized w.r.t. Xi Ci
Output: (A)|C,
(1) C = (C1 ) C2 .
(2) = A1 A2 ,
(3) valuation A, a1 = A1 (a) a2 = A2 (a) :
1/r
1/r
(a) = 1 2 (a1 ) 2 1 (a2 ), ri = CountYi |Xi (Ci )
Postcondition: G G \ {g1 , g2 } {multiply(g1 , g2 , )}
Operator 1: Lifted multiplication. definition assumes, without loss generality,
logvars parfactors standardized apart, i.e., two parfactors share
variable names (this always achieved renaming logvars).
h = {(r1 , n1 ), (r2 , n2 ), . . . , (rk , nk )} multinomial coefficient, defined
Mul(h) = Qk

n!

i=1 ni !

.

multiplicities taken account (P)CRVs, never regular PRVs,
define PRV value v range(A): Mul(A, v) = 1 regular
PRV, Mul(A, v) = Mul(v) PCRV. Mul function identical Milch
et al.s (2008) num-assign.
mind, formal definition lifted summing-out Operator 2
mostly self-explanatory. Precondition (1) ensures randvars summed-out
P(C)RV occur exclusively parfactor. Precondition (2) ensures summed
randvar occurs exactly one, separate, ground factor. Precondition (3) ensures
logvars occurring exclusively eliminated PRV count-normalized respect
logvars PRV, one unique exponent exponentiation.
5.3 Counting Conversion
Counting randvars may present original model, also introduced
parfactors operation called counting conversion (Milch et al., 2008) (see also
Section 2.4). see useful, consider parfactor g = (S(X), F (X, ))|C,
C = {xi }ni=1 {yj }m
j=1 , assume want eliminate S(X)|C. that, first need
make sure S(xi ) occurs one factor. ground level, achieved
given S(xi ) multiplying factors (S(xi ), F (xQ
, yj )) occurs. results
single factor (S(xi ), F (xi , y1 ), . . . , F (xi , ym )) = j (S(xi ), F (xi , yj )) (see Figure 7).
high-dimensional factor, equals product identical potentials ,
F (xi , yj ) arguments mutually interchangeable: matters often values
v1 , v2 , . . . occur among them, occur. exactly kind symmetry
414

fiDecoupling Lifted Variable Elimination Constraint Language

(S(X), F (X, ))
(S(x1 ), F (x1 , y1 ))
..
.
(S(x1 ), F (x1 , ym ))

..
.
(S(xn ), F (xn , y1 ))
..
.
(S(xn ), F (xn , ym ))

S(x1 )

P

RV (F (X,Y ))


P

F (x ,y )

1
1

..
.P
F (x ,ym )

1



P

F (xn ,y )

1
..
.

P

F (xn ,ym )



..
.
F (x1 , ym ) P

(S(X))



(S(x1 ))
..
.


(S(x1 ))







(S(xn ))
..
.


(S(xn ))





S(x1 )

F (x ,ym )

1



F (xn , y1 ) P
..
.
F (xn , ym ) P

..
.

..
.
(S(xn ))m




S(x1 )

( )m

S(xn )

( )m

..
.


F (xn ,y1 )


..
.


(S(X))m

(S(x1 ))m

..
.


..
.





Exponentiate





1 ,y1 )

..
.
S(xn )

i=1

F (x1 , y1 ) PF (x


..
.


!m

S(xn )

F (xn ,ym )

..
.




Figure 6: Lifted summing-out. equivalent lifted operation (top), shown
level ground factors (middle), also terms factor graphs (bottom).

CRVs aim exploit. factor (S(xi ), F (xi , y1 ), . . . , F (xi , ym )) therefore
replaced two-dimensional (S(xi ), h) h histogram indicates often
possible value range F (xi , yj ) occurs. Thus, introducing CRV, define
two-dimensional CRV argument, opposed high-dimensional
. argued Section 2.4, reduces size potential function, hence
computational complexity, exponentially.
many situations lifted elimination cannot immediately applied, counting
conversion makes applicable. conditions sum-out operator (Section 5.2) state
atom Ai eliminated parfactor g Ai logvars
g. atom fewer logvars parfactor, counting conversion modifies
parfactor replacing another atom Aj counting formula, removes counted
logvar logvar(A). instance, example, S(X) logvar
g = (S(X), F (X, ))|C cannot eliminated original parfactor g,
counting conversion replaces F (X, ) #Y [F (X, )], allowing us sum
S(X) new parfactor g = (S(X), #Y [F (X, )])|C.
415

fiTaghipour, Fierens, Davis, & Blockeel

Operator sum-out
Inputs:
(1) g = (A)|C: parfactor G
(2) Ai : atom A, summed g1
Preconditions
(1) PRVs V, Ai |C, model G: RV (V) RV (Ai |C) =
(2) Ai contains logvars X logvar(A) X (C) singleton.
(3) Xexcl = logvar(Ai ) \ logvar(A \ Ai ) count-normalized w.r.t.
Xcom = logvar(Ai ) logvar(A \ Ai ) C
Output: (A )|C ,
(1) = \ Ai
(2) C = X com (C)
(3) assignment = (. . . , ai1 , ai+1 , . . . ) ,
P

(. . . , ai1 , ai+1 , . . . ) = ai range(Ai ) Mul(Ai , ai ) (. . . , ai1 , ai , ai+1 , . . . )r
r = CountXexcl |Xcom (C)
Postcondition: PG\{g}{sum-out(g,Ai )} = RV (Ai |C) PG
Operator 2: lifted summing-out operator.
Operator 3 formally defines counting conversion. mostly self-explanatory, apart
preconditions. Precondition 1 makes sure counting conversion, ground
level, corresponds multiplying factors differ one randvar (i.e.,
instantiation counted logvar). Precondition 2 guarantees resulting
histograms range. Precondition 3 difficult explain. imposes
kind independence logvar counted already occurring counted
logvars. Though explicitly mentioned there, precondition also required CFOVEs counting operation; implies inequality constraint exist
X counted logvar X # . similar condition FOVEs counting elimination
mentioned de Salvo Braz (2007).
see precondition 3 necessary, consider parfactor g = (S(X), #Y [A(Y )])
|(X, ) {(x1 , y2 ), (x1 , y3 ), (x2 , y1 ), (x2 , y3 ), (x3 , y1 ), (x3 , y2 )}, satisfy it.
parfactor represents three factors form (S(xi ), #Y [A(Y )])|Y {y1 , y2 , y3 }\{yi },
contribute joint distribution product
(S(x1 ), #Y {y2 ,y3 } [A(Y )]) (S(x2 ), #Y {y1 ,y3 } [A(Y )]) (S(x3 ), #Y {y1 ,y2 } [A(Y )]).
Counting conversion logvar X turns g factor form
(#X [S(X)], #Y [A(Y )])
equivalent. Note depends #X [S(X)] #Y [A(Y )].
consider valuations V1 : [S(x1 ), S(x2 ), S(x3 ), A(y1 ), A(y2 ), A(y3 )] = [t, t, f, t, t, f ]
V2 : [S(x1 ), S(x2 ), S(x3 ), A(y1 ), A(y2 ), A(y3 )] = [t, t, f, t, f, t]. valuations,
#X [S(X)] = (2, 1) #Y [A(Y )] = (2, 1), (#X [S(X)], #Y [A(Y )]) must return
value V1 V2 . original parfactor, however, returns (S(t), (1, 1))
(S(t), (1, 1)) (S(f ), (2, 0)) V1 , (S(t), (1, 1)) (S(t), (2, 0)) (S(f ), (1, 1))
416

fiDecoupling Lifted Variable Elimination Constraint Language

Counting Conversion

(S(X), F (X, ))

(S(x1 ), F (x1 , y1 ))
..
.

!





(S(X), #Y [F (X, )])

(S(x1 ), F (x1 , y1 ), . . . , F (x1 , ym )) = (S(x1 ), #Y [F (x1 , )])

(S(x1 ), F (x1 , ym ))

..
.

..
.

(S(xn ), F (xn , y1 ))
..
.

!



..
.

(S(xn ), F (xn , y1 ), . . . , F (xn , ym )) = (S(xn ), #Y [F (xn , )])

(S(xn ), F (xn , ym ))

S(x1 )



F (x1 , y1 )

..
.




F (x1 , ym )

F (x1 , ym )
S(x1 )



..
.

Counting

S(x1 )

F (x1 , ym )
F (x1 , ym )

F (x1 , ym )

..
.

..
.
S(xn )

..
.

#





F (xn , y1 )

..
.




F (xn , y1 )
S(xn )

F (xn , ym )

..
.


..
.

F (xn , y1 )
S(xn )

Counting



F (xn , ym )



#

..
.
F (xn , ym )

Figure 7: Counting conversion. equivalent lifted operation (top), shown
level ground factors (middle), also terms factor graphs (bottom).

V2 , may different. Since original parfactor distinguish valuations
factor form (#X [S(X)], #Y [A(Y )]) can, counting conversion cannot
applied case.
contrast, consider g = (S(X), #Y [A(Y )])|(X, ) {x1 , x2 , x3 } {y1 , y2 , y3 },
similar g, except constraint satisfies precondition 3. three factors represented g differ first argument, randvar S(xi ); counting
randvar #Y [A(Y )]|Y {y1 , y2 , y3 } second argument (this case g).
product, thus, represented parfactor (#X [S(X)], #Y [A(Y )])|(X, )
{x1 , x2 , x3 } {y1 , y2 , y3 }, derived g counting conversion.
5.4 Splitting Shattering
preconditions lifted multiplication, lifted summing-out counting conversion fulfilled, necessary reformulate model terms parfactors
fulfill them. instance, g1 = 1 (S(X))|X {x1 , x2 , x3 } g2 = 2 (S(X))|X
{x1 , x2 , x3 , x4 , x5 }, cannot multiply g1 g2 directly without creating unwanted de417

fiTaghipour, Fierens, Davis, & Blockeel

Operator count-convert
Inputs:
(1) g = (A)|C: parfactor G
(2) X: logvar logvar(A)
Preconditions
(1) exactly one atom Ai X logvar(Ai )
(2) X count-normalized w.r.t logvar(A) \ {X} C
(3) counted logvars X # g: X,X # (C) = X (C) X # (C)
Output: (A )|C,
(1) = \ {Ai } {Ai } Ai = #X [Ai ]
(2) assignment ai = h:
Q
(. . . , ai1 , h, ai+1 , . . . ) = ai range(Ai ) (. . . , ai1 , ai , ai+1 , . . . )h(ai )
h(ai ) denoting count ai histogram h
Postcondition: G G \ {g} {count-convert(g, X)}.
Operator 3: counting conversion operator.
pendencies. However, replace g2 g2a = 2 (S(X))|X {x1 , x2 , x3 } g2b =
2 (S(X))|X {x4 , x5 }. resulting model equivalent, new model,
multiply g1 g2a , resulting g3 = 3 (S(X))|X {x1 , x2 , x3 }.
simple case splitting parfactors (Poole, 2003; de Salvo Braz, 2007;
Milch et al., 2008). Basically, splitting two parfactors partitions parfactor part
shared parfactor, part disjoint. goal rewrite
P(C)RVs parfactors proper form. Two P(C)RVs (V1 , V2 ) proper RV (V1 )
RV (V2 ) either identical disjoint; two parfactors proper P(C)RVs
proper. pair parfactors written proper form applying following
procedure, P(C)RVs proper. Choose P(C)RV V1 one parfactor,
compare P(C)RV V2 other, rewrite first parfactor V1
split two parts: one disjoint V2 one shared V2 .
parfactors model made proper w.r.t. repeatedly applying
rewrite convergence. called shattering model.
simpler rewrite PRV proper form PCRV. describe operator handles PRVs, namely split, section discuss operator handles
PCRVs, namely expand, following section. defining split operator,
provide following auxiliary definitions, also used later on.
Definition 5 (Splitting overlap) Splitting constraint C1 Y-overlap C2 ,
denoted C1 /Y C2 , partitions C1 two subsets, containing tuples part
occurs occur, respectively, C2 . C1 /Y C2 = {{t C1 |Y (t) (C2 )}, {t
C1 |Y (t)
/ (C2 )}}.
Definition 6 (Parfactor partitioning) Given parfactor g = (A)|C partition
C = {Ci }ni=1 C, partition(g, C) = {(A)|Ci }ni=1 .
Operator 4 defines splitting parfactors. Note that, operator definition,
simplicity, assume = = P (Y), means logvars used
418

fiDecoupling Lifted Variable Elimination Constraint Language

Operator split
Inputs:
(1) g = (A)|C: parfactor G
(2) = P (Y): atom
(3) = P (Y)|C #Y [P (Y)]|C
Output: partition(g, C), C = C/Y C \ {}
Postcondition G G \ {g} split(g, A, )
Operator 4: split operator.
must same, order. always rewrite model
two PRVs predicate form. this, rewrite parfactors
follows: (i) parfactors share logvars, first standardize apart logvars two
parfactors, (ii) linearize atom logvar occurs once, i.e., rewrite
distinct logvar argument, (iii) apply renaming substitution
logvars concerned atoms logvars. instance, consider
two parfactors g1 = 1 (P (X, X))|X C1 g2 = 2 (P (Y, Z))|(Y, Z) C2 .
logvars two parfactors already different, need standardizing
apart. However, atom P (X, X) g1 linearized yet. linearize it,
rewrite g1 form 1 (P (X, X ))|(X, X ) C1 , C1 = {(x, x)|x C1 }. Finally,
rename logvars X X Z, respectively, derive 1 (P (Y, Z))|(Y, Z) C1 .
brings atom P (X, X) desired form P (Y, Z).
ease exposition, explicitly mention linearization renaming;
whenever two PRVs different parfactors compared, notation suggesting
logvars interpreted logvars linearization
renaming.
GC-FOVE wants multiply two parfactors, first checks pairs A1 |C1 ,
A2 |C2 (one parfactor) whether proper. pair found
proper, means A1 A2 form P (Y), different (but overlapping)
instantiations C1 C2 . pair split Y.
Example 9. Consider g1 = 1 (N (X, ), R(X, Y, Z))|C1 C1 = (X, Y, Z) {xi }50
i=1

5
25
50
{yi }50
i=1 {zi }i=1 , g2 = 2 (N (X, ))|C2 C2 = (X, ) {x2i }i=1 {yi }i=1 . First,
compare PRVs N (X, )|C1 N (X, )|C2 . PRVs partially overlap,
splitting necessary. split parfactors, split C1 C2 (X,Y)-overlap.
50
5
excl = C \
partitions C1 two sets: C1com = {x2i }25
1
i=1 {yi }i=1 {zi }i=1 , C1
50
5
C1com = {x2i1 }25
i=1 {yi }i=1 {zi }i=1 . C2 need split, tuples
(X,Y)-values occur C1 . splitting constraints, split
parfactors accordingly: g1 split two parfactors g1com = (N (X, ), R(X, Y, Z))|C1com
g1excl = (N (X, ), R(X, Y, Z))|C1excl , parfactor g2 remains unmodified.

splitting procedure splits two PRVs two partitions each. Similarly, involved parfactors split two partitions each. strongly
contrasts C-FOVEs approach splitting. C-FOVE operates per logvar, splits
value separate partition (splitting based substitution) (Poole, 2003; Milch
et al., 2008). Thus, may require many splits GC-FOVE requires one.
419

fiTaghipour, Fierens, Davis, & Blockeel

example, instead g1excl = (N (X, ), R(X, Y, Z))|C1excl , C-FOVE ends
1250 parfactors (N (x1 , y1 ), R(x1 , y1 , Z))|{zi }5i=1 , (N (x1 , y2 ), R(x1 , y2 , Z))|{zi }5i=1 ,
. . . , (N (x3 , y1 ), R(x3 , y1 , Z))|{zi }5i=1 , . . . , (N (x49 , y50 ), R(x49 , y50 , Z))|{zi }5i=1 .
reason GC-FOVE always split two parfactors, yielding much
coarser partitions C-FOVE, assumes extensionally complete constraint
language, whereas C-FOVE allows pairwise (in)equalities, forcing split
element separately.
5.5 Expansion Counting Formulas
handling parfactors counting formulas, rewrite P(C)RV proper
from, employ operation expansion (Milch et al., 2008). split one group
randvars RV (V) partition {RV (Vi )}m
i=1 , counting randvar counts
values RV (V) needs expanded, i.e., replaced group counting randvars {i }m
i=1 ,
counts values randvars RV (Vi ). parallel this, potential
originally V argument must replaced potential Vi
arguments; call potential expansion.
Example 10. Suppose need split g1 = 1 (#X [S(X)])|C1 g2 = 2 (S(X))|C2 ,

C1 = {x1 , . . . , x100 } C2 = {x1 , . . . , x40 }. C1 split C1com = C1 C2 = {x1 , . . . x40 }
C1excl = C1 \ C2 = {x41 , . . . x100 }. Consequently, original group randvars
parfactor g1 , namely {S(x1 ), . . . S(x100 )}, partitioned V1com = {S(x1 ), . . . S(x40 )}
V1excl = {S(x41 ), . . . S(x100 )}. preserve semantics original counting formula,
need two separate counting formulas, one V1com one V1excl , need
replace original potential 1 (#X [S(X)]) 1 (#Xcom [S(Xcom )], #Xexcl [S(Xexcl )]),
1 () depends sum two new counting randvars #Xcom [S(Xcom )]
#Xexcl [S(Xexcl )]. end effect parfactor g1 replaced new parfactor
1 (#Xcom [S(Xcom )], #Xexcl [S(Xexcl )])|C1 , C1 = C1com C1excl .
explain expansion, begin case (non-parametrized) CRVs
move general case expansion PCRVs.
5.5.1 Expansion CRVs
First consider simplest possible type CRV: #X [P (X)]|C. counts many
values X C, P (X) certain value. C partitioned, X must counted
within subset partition.
following, assume C partitioned two non-empty subsets C1 C2 .
one empty, equals C, means CRV kept
expansion needed.
itself, splitting #X [P (X)]|C #X [P (X)]|C1 #X [P (X)]|C2 trivial,
problem resulting counting formulas occur one single parfactor,
constraint always associated parfactor, particular argument
parfactor. Thus, need transform (#X [P (X)])|C parfactor form
(#X1 [P (X1 )], #X2 [P (X2 )])|C , single constraint C expresses X1 take
values C1 , X2 values C2 . easily seen C = XX1 C1 XX2 C2
420

fiDecoupling Lifted Variable Elimination Constraint Language

satisfies condition. Further, preserve semantics, should, count X1
X2 , give result corresponding count X. function
(h1 , h2 ) = (h1 h2 ),
denoting summation histograms, property. Indeed, histogram X1
(resp. X2 ) C equal X C1 (resp. C2 ), since {C1 , C2 } partition
C, sum histograms equals histogram X C.
generally, consider non-parametrized CRV #X [P (X)]|C, X X meaning X\{X} (C) singleton. constraint C = X\{X} (C) (X1 (XX1 C1 )
X2 (XX2 C2 )) joins singleton Cartesian product X (C1 ) X (C2 ),
equivalent constraint XX1 (C1 ) XX2 (C2 ). result
counting X1 (X2 ) C equivalent counting X C1 (C2 ), constraint
variables remains unchanged. shows parfactor (A, #X [P (X)])|C,
partition {C1 , C2 } C C1 C2 non-empty, rewritten form
(A, #X1 [P (X)], #X2 [P (X)])|C , C = XX1 (C1 ) XX2 (C2 ).
Note ranges counting formulas (the hi arguments) depend
cardinality C1 C2 , denote n1 n2 respectively.
5.5.2 Expansion PCRVs
Consider case X\{X} (C) singleton, i.e., parametrized CRV
V represents group CRVs, counting values subset RV (V). Given
partitioning constraint C, need expand underlying CRV corresponding potential. constraint C = XX1 (C1 ) XX2 (C2 ) remains correct (for
non-empty C1 , C2 ), even X\{X} (C) longer singleton: associates correct
values X1 X2 tuple X\{X} (C). However, result potential expansion depends size partitions, n1 n2 , CRVs
(n1 ,n2 ) result identical potentials expansion, grouped one
parfactor. account this, PCRV expansion first splits PCRV groups CRVs
joint count (n1 , n2 ), applies group corresponding
potential expansion.
formalize this, first provide following auxiliary definitions.
Definition 7 (Group-by) Given constraint C function f : C R, GroupBy(C, f ) = C/ f , x f f (x) = f (y) / denoting set quotient. is,
Group-By(C, f ) partitions C subsets elements result f .
Definition 8 (Joint-count) Given constraint C variables X, partitioned {C1 ,
C2 }, counted logvar X X; C, L = X \ {X} l = L (t),
joint-countX,{C1 ,C2 } (t) = (|X (L=l (C1 ))|, |X (L=l (C2 ))|).
PCRV V = #Xi [P (X)] |C parfactor g partially overlaps another PRV
|C model, expansion performs following g: (1) partition C X-overlap
C , resulting C/X C ; (2) partition C C = group-by(C, joint-countX,C/X C )
(this corresponds partition V CRVs number randvars common exclusive partitions C/X C ); (3) split g, based
421

fiTaghipour, Fierens, Davis, & Blockeel

Operator expand
Inputs:
(1) g = (A)|C: parfactor G
(2) = #X [P (X)]: counting formula
(3) = P (X)|C #Y [P (X)]|C
Output: {gi = (Ai )|Ci }ni=1
(1) C/X C = {C com , C excl }
(2) {C1 , . . . , Cn } = group-by(C, joint-countX,C/X C )
(3) Ci C com = Ci C excl = : = , Ai = A, Ci = Ci
(4) i:
(5) Ci = logvar(A) (Ci ) (XXcom (C com ) XXexcl (C excl ))
(6) Ai = \ {A} {Acom , Aexcl } com = {X Xcom }, excl = {X Xexcl }
(7) valuation (l, hcom , hexcl ) Ai , (l, hcom , hexcl ) = (l, hcom hexcl )
Postcondition G G \ {g} expand(g, A, )
Operator 5: expansion operator.
C = {C1 , . . . , Cn }, resulting parfactors g1 , . . . , gn require distinct expanded
potential; (4) gi , replace potential expanded version. formal definition
expansion given Operator 5.
Suppose need split parfactors g = (#Y [F (X, )])|C g =
C = {ann, bob, carl} {dave, ed, f red, gina} C = {ann, bob}
{dave, ed}. Assume F stands friendship; #Y [F (X, )]|C counts number friends
non-friends X C. random variables covered PCRV #Y [F (X, )] |C
partially overlap F (X, ) |C . need split C overlap C , yielding C com C excl , need replace original PCRV separate PCRVs C com
C excl . PCRVs require count-normalization, fact count-normalized
w.r.t. X C necessarily imply holds C com C excl .
why, addition split overlap, need orthogonal partitioning C according
joint counts. Within subset Ci partitioning, count-normalized
w.r.t. X Cicom Ciexcl .
follow four steps outlined above. Figure 8 illustrates steps. First,
find partition C/X,Y C = {C com , C excl } C com = {ann, bob} {dave, ed}
C excl = {ann, bob} {f red, gina} {carl} {dave, ed, f red, gina}. Inspecting joint
counts, see C com contains 2 possible friends Ann Bob (namely Dave
Ed), 0 Carl, whereas C excl contains 2 possible friends Ann Bob 4
Carl. Formally, joint-countY,C/X,Y C (t) equals (2,2) X (t) = ann X (t) =
bob, equals (0,4) X (t) = carl. So, within C com C excl , longer
count-normalized respect X. therefore partition C subsets {C1 , C2 } =
group-by(C, joint-countY,C/X,Y C ), gives C1 = {ann, bob} {dave, ed, f red, gina}
C2 = {carl}{dave, ed, f red, gina}. Ci , construct Ci allows
counting friends Cicom Ciexcl separately, using series joins discussed
earlier. Cicom Ciexcl non-empty, original PCRV #Y [F (X, )] |C
Example 11.

(F (X,

))|C ,

422

fiDecoupling Lifted Variable Elimination Constraint Language

C
ann dave
ann ed
bob dave
bob ed

C
ann
ann
ann
ann
bob
bob
bob
bob
carl
carl
carl
carl

dave
ed
fred
gina
dave
ed
fred
gina
dave
ed
fred
gina
C1

X
ann
ann
ann
ann
bob
bob
bob
bob

Ycom
dave
dave
ed
ed
dave
dave
ed
ed

Yexcl
fred
gina
fred
gina
fred
gina
fred
gina

C/X,Y C
ann dave
ann ed
bob dave
bob ed
ann fred
ann gina
bob fred
bob gina
carl dave
carl ed
carl fred
carl gina

group-by(C,
joint-countY,C/X,Y C )
ann dave
ann ed
ann fred
ann gina
C1
bob dave
bob ed
bob fred
bob gina
carl dave
carl ed
C2
carl fred
carl gina

C2
X

carl dave
carl ed
carl fred
carl gina

Figure 8: Illustration PCRV expansion operator. (1) count-normalized w.r.t. X
C (with X, four values associated). Splitting C overlap C
results subsets longer count-normalized w.r.t. X: joint
counts subsets (2,2) Ann Bob, (0,4) Carl.
obtain count-normalized subsets, need partition C subset C1
Ann Bob, C2 Carl; Group-By construct does.
subsets, split overlap C yield subsets
count-normalized w.r.t. X. C1 result joining common exclusive
parts according join construct motivated earlier. C2 equals C2 C2
overlap C hence need split.

replaced two PCRVs per Ci , #Ycom [F (X, Ycom )] |Ci #Yexcl [F (X, Yexcl )] |Ci ,
new potential defined (hcom , hexcl ) = (hcom hexcl ).
GC-FOVEs expansion improves C-FOVEs following way. C-FOVE uses
expansion based substitution (Milch et al., 2008). instance, Example 10, C-FOVE
splits elements C excl individually C, adding elements
separate argument parfactor involved potential function. yields
423

fiTaghipour, Fierens, Davis, & Blockeel

potential function 1 () 61 arguments, namely counting randvar #Xcom [S(Xcom )]
60 randvars S(x41 ), . . . S(x100 ). causes extreme blow size (number
entries) potential function, happen using approach. general,
C-FOVEs expansion yields potential function size O(r k (n k)r ), n = |C1 |, k =
|C1excl |, r cardinality range considered randvars (e.g., r = |range(S(.))|
Example 10). contrast, GC-FOVEs expansion yields potential function size
O(kr (n k)r ). likely scenario r k, exponentially smaller
C-FOVEs potential function. Given potential function later used
multiplication summing-out, clear GC-FOVE yield large efficiency gains
C-FOVE.
5.6 Count Normalization
Lifted multiplication, summing-out counting conversion require certain variables
count-normalized (recall Definition 2, p. 406). property hold,
achieved normalizing involved parfactor, amounts splitting
parfactor parfactors property hold (Milch et al., 2008). Concretely,
count-normalized given Z constraint C, C simply partitioned
C = Group-By(C, CountY|Z ), CountY|Z defined Definition 1; next,
parfactor split according C. formal definition count normalization shown
Operator 6.
Operator count-normalize
Inputs:
(1) g = (A)|C: parfactor G
(2) Y|Z: sets logvars indicating desired normalization property C
Preconditions
(1) logvar(A) Z logvar(A) \
Output: partition(g, group-by(C, CountY|Z ))
Postconditions G G \ {g} count-normalize(g, Y|Z)
Operator 6: count-normalization operator.
Example 12. Consider parfactor g = (P rof (P ), Supervises(P, S)) con-

straint C = {(p1 , s1 ), (p1 , s2 ), (p2 , s2 ), (p2 , s3 ), (p3 , s5 ), (p4 , s3 ), (p4 , s4 ), (p5 , s6 )}. Lifted
elimination Supervises(P, S) requires logvar (student) count-normalized respect logvar P (professor). Intuitively, need partition professors groups
professors group supervise number students. example,
C needs partitioned two, namely C1 = P {p3 ,p5 } (C) = {(p3 , s5 ), (p5 , s6 )} (tuples
involving professors 1 student) C2 = P {p1 ,p2,p4 } (C) = {(p1 , s1 ), (p1 , s2 ), (p2 , s2 ),
(p2 , s3 ), (p4 , s3 ), (p4 , s4 )} (professors 2 students). Next, parfactor g split accordingly two parfactors g1 g2 constraints C1 C2 . parfactors
ready lifted elimination Supervises(P, S).
C-FOVE requires stronger normalization property hold. every pair logvars X
requires either (1) X,Y (C) = X (C) (C) (2) X (C) = (C) X,Y (C) =
424

fiDecoupling Lifted Variable Elimination Constraint Language

(X (C)Y (C))\{hxi , xi : xi X (C)}. enforce this, C-FOVE requires finer partitions
approach does. example, C-FOVE requires C split 5 subsets
{Ci }5i=1 Ci = P {pi } (C), i.e., one group per professor. coarser partitioning used
approach cannot represented using C-FOVEs constraint language.
5.7 Absorption: Handling Evidence
value randvar observed, usually makes probabilistic inference
efficient: randvar removed model, may introduce extra independencies model. However, lifted inference, also adverse effect:
observations break symmetries among randvars. reason, important
handle observations manner preserves much symmetry possible. order
effectively handle observations lifted manner, introduce novel operator lifted
absorption.
ground setting, absorption works follows (van der Gaag, 1996). Given factor
(A) observation Ai = ai Ai A, absorption replaces (A) factor (A ),
= \ {Ai } (a1 , . . . , ai1 , ai+1 , . . . , ) = (a1 , . . . , ai1 , ai , ai+1 , . . . , ).
reduces size factor may introduce extra independencies model,
always beneficial.
n randvars (built predicate) observed value,
perform absorption lifted level treating n randvars one single group.
Consider parfactor g = (S(X), F (X, ))|(X, ) {(x1 , y1 ), . . . , (x1 , y50 )}. Assume
evidence atoms F (x1 , y1 ) F (x1 , y10 ) value true. represented
adding evidence parfactor gE model: gE = E (F (X, ))|(X, ) {x1 } {yj }10
1 ,
E (true) = 1 (the observed value) E (f alse) = 0. absorb evidence, g needs
split two, namely g1 C1 = {(x1 , y1 ), . . . , (x1 , y10 )} (the parfactor
evidence) g2 C2 = {(x1 , y11 ), . . . , (x1 , y50 )} (no evidence). Then,
absorb evidence F g1 . Performing absorption ground level would
result ten identical factors (S(x1 )) (the logvar disappears absorption). Lifted
absorption computes once, raises tenth power. Generally,
Xexcl logvars occur exclusively atom absorbed, exponent
number values Xexcl take, Xexcl must count-normalized respect
logvars. Further, logvars Xexcl removed constraint C
disappear absorption.
parfactors counting formulas, essentially reasoning used,
exponent determined non-counted logvars occurring exclusively atom
(Xnce ). logvars, together counted logvar, removed C. value
absorbed counting formula, filled , histogram indicating many
times possible value observed absorbed PRV. Since one
observed value evidence parfactor, histogram maps value number
randvars absorbed, values zero. Lifted absorption formally defined
Operator 7. provide correctness proof operator Appendix A, analyze
complexity Appendix B.
GC-FOVE handles evidence absorption follows. first creates one evidence parfactor per observed value predicate. Next, compares evidence parfactor
425

fiTaghipour, Fierens, Davis, & Blockeel

Operator absorb
Inputs:
(1) g = (A)|C: parfactor G
(2) Ai Ai = P (X) Ai = #Xi [P (X)]
(3) gE = E (P (X))|CE : evidence parfactor
Let Xexcl = X \ logvar(A \ Ai );
Xnce = Xexcl \ {Xi } Ai = #Xi [P (X)], Xexcl otherwise;
L = logvar(A) \ Xexcl ;
= observed value P (X) gE ;
Preconditions
(1) RV (Ai |C) RV (Ai |CE )
(2) Xnce count-normalized w.r.t. L C.
Output: g = (A )|C ,
(1) = \ {Ai }
(2) C = logvar(C)\Xexcl (C)
(3) (. . . , ai1 , ai+1 , . . . ) = (. . . , ai1 , e, ai+1 , . . . )r , r = CountXnce |L (C),
e = Ai = P (X)
e histogram e(o) = CountXi |logvar(A) (C), e(.) = 0 elsewhere, otherwise
(namely Ai = #Xi [P (X)])
Postcondition
G {gE } = G \ {g} {gE , absorb(g, Ai , gE )}
Operator 7: Lifted absorption.
PRV model, applying absorption possible. necessary, parfactors
model split allow absorption. (It never necessary split evidence parfactors, see precondition 1.) absorptions possible given evidence
parfactor, removed model: evidence incorporated completely.
Like sum-out operator, absorb operator effect eliminating PRVs
model. operators definitions show, however, absorb requires weaker
preconditions sum-out, means applied situations. Also,
absorb operator easily lends splitting needed constraint processing strategy
(Kisynski & Poole, 2009a), keeps model much higher granularity, requiring
fewer splits parfactors compared preemptive shattering strategy. presence
observations, often case real-world problems, effects result
large computational savings.
approach dealing evidence differs C-FOVEs two important ways.
First, C-FOVE introduces separate evidence factor ground observation = a.
causes extensive splitting: n randvars observed value,
n separate factors, C-FOVE perform (at least) n eliminations
randvars. addition, splitting may cause splitting C-FOVE continues,
destroying even opportunities lifting. show Section 7 make
inference impossible C-FOVE presence evidence.
Second, C-FOVE use absorption; inference, evidence factors
used multiplication summing-out like factors. Absorption advantageous
426

fiDecoupling Lifted Variable Elimination Constraint Language

Operator ground-logvar
Inputs:
(1) g = (A)|C: parfactor G
(2) X: logvar logvar(A)
Output: partition(g, group-by(C, X ))
Postcondition
G G \ {g} ground-logvar(g, X)
Operator 8: Grounding.
eliminates randvars model, longer need summed out.
result, approach, evidence reduces number summing-out multiplication
operations, C-FOVE increases number.
5.8 Grounding Logvar
guarantee enabling operators eventually result PRVs parfactors
allow lifted operators. illustrate this, consider model consisting
single parfactor (R(X, ), R(Y, Z), R(X, Z))|C, expresses probabilistic variant
transitivity. Since one factor, multiplications needed starting
eliminate variables. Yet, structure parfactor, single PRV
eliminated (the preconditions lifted summing counting conversion
fulfilled, none operators change that).
cases like this, operators applied, lifted always resort
last operator: grounding logvar X parfactor g (de Salvo Braz, 2007; Milch et al., 2008).
Given parfactor g = (A)|C logvar X logvar(A) X (C) = {x1 , . . . , xn },
grounding X replaces g set parfactors {g1 , . . . , gn } gi = (A)|X=xi (C).
equivalent splitting g based partition group-by(C, X ), yields
definition shown Operator 8. Note resulting parfactor gi , logvar X
take single value xi , practice X replaced constant xi removed
set logvars.
Grounding significantly increase granularity model decrease opportunities performing lifted inference: extreme case logvars grounded,
inference performed propositional level. therefore best used last
resort. practice, (G)C-FOVEs heuristic selecting operators, relies size
resulting factors, automatically effect.
Calling ground-logvar operator confused event obtaining ground model. ground-logvar grounds one logvar, necessarily
result ground model. Conversely, one may arrive ground model without ever calling
ground-logvar, simply splitting continues singleton level.

6. Representing Manipulating Constraints
shown using extensionally complete constraint language instead allowing
pairwise (in)equalities potentially yield large efficiency gains allowing
opportunities lifting. question remains represent constraints.
427

fiTaghipour, Fierens, Davis, & Blockeel

X
{x1 , x2 , x3 }

{y1 , . . . , y10 }
Z
{z1 , . . . , z5 }



{x4 , x5 }

{x5 , . . . , x20 }





{y11 , y12 } {y1 , . . . , y20 } {y1 , y2 }
Z

Z

{z1 , . . . , z10 } {z4 , z5 }





Z
{z1 , . . . , z8 }



{y3 , . . . , y10 }

Z
{z10 , z15 }



Figure 9: constraint tree representing constraint logvars X, Y, Z.
principle, could represent extensionally, lists tuples. allows
constraint represented, inefficient many logvars. Instead,
employ constraint tree, also used First Order Bayes-Ball (Meert, Taghipour, &
Blockeel, 2010). Hence, lower-level operations constraints (projection, splitting,
counting) must implemented terms constraint trees. Below, briefly explain
done.
constraint tree logvars X tree internal (non-leaf) node labeled
logvar X X, leaf labeled terminal label , edge e = (Xi , Xj )
labeled (sub-)domain D(e) D(Xi ). See Figure 9 example. use ordered
trees, nodes level tree labeled logvar,
logvar occurs one level. path root leaf edges e1 , . . . , e|X|
represents tuples Cartesian product D(ei ). example, Figure 9, left
path represents tuples {x1 , x2 , x3 } {y1 , . . . , y10 } {z1 , . . . , z5 }. constraint
represented tree union tuples represented root-to-leaf path.
Given constraint (in terms set tuples satisfy it), construct
corresponding tree bottom-up manner merging compatible edges. Different logvar
orders result trees different sizes. tree re-ordered interchanging nodes
two adjacent levels tree applying possible merges levels.
employ re-ordering simplify various constraint handling operations. projection
constraint, move projected logvars top tree discard parts
logvars. splitting, perform pairwise comparison two involved
constraint trees. First, re-order tree logvars involved split
top trees. process trees top-down comparing edges
leaving root two trees partition domains based overlap.
recursively repeat children reach last logvar involved split.
count normalization, also first apply re-ordering. partition tree
based number tuples counted logvars branch. counting number,
428

fiDecoupling Lifted Variable Elimination Constraint Language

need consider size domains associated edges. Finally,
join two constraints computed reordering trees join variables occur
top, merging levels join variables way done splitting,
extending leaf resulting tree cross-product corresponding
subtrees original trees.
Constraint trees (and way constructed) close hypercube representation used lifted belief propagation (Singla, Nath, & Domingos, 2010). However,
given constraint, constraint tree typically compact. constraint tree
Figure 9 corresponds set five hypercubes, one leaf. hypercube representation exploit fact first second hypercube, instance, share
part {x1 , x2 , x3 }. constraint tree, explicit, makes compact.
stress GC-FOVE use extensionally complete constraint representation
language. Constraint trees one representation. representations
compact cases, choice representation need consider also
tradeoff compactness ease constraint processing. Consider constraint
graph, similar trees, parent nodes share child nodes.
representation compact constraint tree, also requires complicated
constraint handling operations. instance, consider splitting, might need
split child node one parent others. operations become
complicated graphs, trivial trees.

7. Experiments
Using extensionally complete constraint language, capture symmetries
model, potentially offers ability perform operations lifted
level. However, comes cost, manipulating expressive constraints
computationally demanding. hypothesize ability perform fewer computations
capturing symmetries far outweigh cost typical inference tasks.
section, compare performances C-FOVE GC-FOVETREES (GC-FOVE using
tree representation Section 6) empirically validate hypothesis. particular,
study performances vary function two parameters: (i) domain size,
(ii) amount evidence. also empirically study whether GC-FOVETREES
solve inference tasks beyond reach C-FOVE.
Throughout section, GC-FOVE stands GC-FOVETREES .
7.1 Methodology Datasets
compare C-FOVE GC-FOVE several inference tasks synthetic realworld data. use version C-FOVE extended general parfactor multiplication
(de Salvo Braz, 2007).3 implementing GC-FOVE, started publicly available C-FOVE code (Milch, 2008), implementations maximally comparable.4
experiments, undirected model parfactors whose constraints representable
3. allows C-FOVE handle tasks entirely lifted way, otherwise would
resort grounding, e.g., social network domain (Jha et al., 2010).
4. GC-FOVE available http://dtai.cs.kuleuven.be/ml/systems/gc-fove.

429

fiTaghipour, Fierens, Davis, & Blockeel

C-FOVE. Thus, GC-FOVE initial advantage, makes comparison conservative.
experiment compute marginal probability query randvar given
evidence. query randvar selected random non-observed atoms.
evidence generated randomly selecting randvars particular predicate giving
value chosen randomly uniformly domain. reported results
averaged multiple runs different query evidence sets.
7.1.1 Experiments Synthetic Data
terms synthetic data, evaluate algorithm three standard benchmark problems. first domain called workshop attributes (Milch et al., 2008). Here, different
attributes (e.g., topic, date, etc.) describe workshop, corresponding factor
attribute shows dependency attendance person attribute.
theory contains following parfactors.
1 (Attends(X), Attr1 )
...
(Attends(X), Attrm )
m+1 (Attends(X), Series)
second domain called competing workshops (Milch et al., 2008). models fact
people likely attend workshop hot topic number
attendees influences whether workshop becomes series. theory contains
following parfactors.
1 (Attends(X), Hot(Y ))
2 (Attends(X), Series)
experiments domains, query variable Series,
evidence randvars form Attends(x).
third domain called social network (Jha et al., 2010) models peoples
smoking habits, chance asthma, dependence persons habits
diseases friendships. theory contains following parfactors.
1 (Smokes(X))
2 (Asthma(X))
3 (F riends(X, ))
4 (Asthma(X), Smokes(X))
5 (Asthma(X), F riends(X, ), Smokes(Y ))
domain, evidence randvars mix randvars form Smokes(x)
Asthma(x), query randvar randvar unobserved.
430

fiDecoupling Lifted Variable Elimination Constraint Language

7.1.2 Experiments Real-World Data
also used two datasets field statistical relational learning. first,
WebKB (Craven & Slattery, 1997), contains data 1200 webpages, including
class (e.g., course page), textual content (set words), hyperlinks
pages. model consists multiple parfactors, stating instance classes
two linked pages depend other. inference task concerns link prediction. Here,
class information observed subset pages task compute
probability hyperlink pair pages. use one Pageclass predicate
model run, average runtime multiple runs class.
used following set parfactors.
1 (P ageclass(P ))
2 (P ageclass(P ), HasW ord(P, W ))
3 (P ageclass(P1 ), Link(P1 , P2 ), P ageclass(P2 ))

second dataset, Yeast (Davis, Burnside, de Castro Dutra, Page, & Costa, 2005), contains data 7800 yeast genes, functions locations, interactions genes. model task similar WebKB (gene
functions correspond page classes, gene-to-gene interactions hyperlinks). task,
observe function information subset genes query existence
interaction two genes. Similar WebKB, also use one function model
run average results multiple runs. Here, used following set
parfactors.

1 (F unction(G))
2 (Location(G, L))
3 (F unction(G), Location(G, L))
4 (F unction(G1 ), Interaction(G1 , G2 ), F unction(G2 ))

Motivation evidence randvars. experiments, evidence randvars correspond
atoms unary predicate; call unary randvars. done purpose
introducing evidence randomly binary randvars, e.g., randvars type P (X, ),
quickly break many symmetries lifted inference possible anymore. fact,
recent theoretical results show lifted inference presence arbitrary
evidence binary randvars simply possible. limitation unique
approach, true possible exact lifted inference approach (Van den Broeck &
Davis, 2012). this, random insertion evidence binary randvars quickly
cause lifted inference algorithm resort ground inference, would blur
distinction C-FOVE, GC-FOVE, ground inference. avoid placing
evidence unary randvars.
431

fiTaghipour, Fierens, Davis, & Blockeel

GC-FOVE
C-FOVE

10

1000

GC-FOVE
C-FOVE

GC-FOVE
C-FOVE
100
Time (s)

Time(s)

Time(s)

10

1

1

10

1

0.1
200

400
600
Domain Size

800

(a) Workshop Attributes

1000

200

400
600
Domain Size

800

(b) Competing Workshops

1000

!

400

600

'

800

1000

(c) Social Network

Figure 10: Performance synthetic data varying domain sizes proportion observed randvars fixed 20%. Y-axis (runtime) drawn log scale.

7.2 Influence Domain Size
first set experiments, use synthetic datasets measure effect domain
size (number objects) runtime. vary domain size 50 1000 objects
holding proportion observed randvars (relative number observable randvars)
constant 20%. Figures 10(a) 10(c) show performance three synthetic
datasets. three models, GC-FOVE outperforms C-FOVE domain sizes.
number objects domain increases, runtimes increase algorithms.
GC-FOVEs runtime increases much lower rate C-FOVEs three models.
first two tasks, GC-FOVE one two orders magnitude faster
C-GOVE, largest domain sizes. social network domain, difference
performance becomes striking: C-FOVE cannot handle domain sizes 100 objects
more, GC-FOVE handles largest domain (1000 objects) 200 seconds.
improvement performance arises GC-FOVE better preserves symmetries present
model treating indistinguishable elements, observed not, single unit.
gain pronounced larger domains. C-FOVE makes separate partition
(and separate evidence factor) observed randvar, thus, fixed evidence
ratio, number partitions induced C-FOVE grows linearly domain size.
Moreover, costly elimination operation partition. contrast, GC-FOVE,
employs lifted absorption, keeps model higher granularity grouping
observations handles whole groups observations single lifted operation.
7.3 Influence Amount Evidence
second set experiments, measure effect proportion observed
randvars runtime, using synthetic datasets. fix domain size, vary
percentage observed randvars 0% 100%. Note percentage
observable randvars (e.g., randvars form Smokes(x)), randvars
type (so 100% mean unobserved variables left). Figures 11(a)
11(c) show performance three synthetic domains domain size
1000 objects. better demonstrate C-FOVEs behavior social networks domain,
Figure 11(d) shows performances domain 25 objects. algorithms
display similar trends across three domains. Without evidence, GC-FOVE comparable
432

fiDecoupling Lifted Variable Elimination Constraint Language

10000

GC-FOVE
C-FOVE

1000

100

100
Time (s)

Time(s)

GC-FOVE
C-FOVE

1000

10

10

1

1

0.1

0.1

0

20

40
60
Percentage Evidence

80

0.01
0

100

(a) Workshop Attributes (domain size: 1000)

20

40
60
Percentage Evidence

80

100

(b) Competing Workshops (domain size: 1000)
1000

1000
GC-FOVE
C-FOVE

GC-FOVE
C-FOVE

100

Time(s)

Time(s)

100

10

10

1

1
0.1

0.1
0

20

40
60
Percentage Evidence

80

100

0

(c) Social Network (domain size: 1000)

20

40
60
Percentage Evidence

80

100

(d) Social Network (domain size: 25)

Figure 11: Performance synthetic data varying amounts evidence fixed
domain size. Y-axis (runtime) drawn log scale.

C-FOVE. best scenario C-FOVE (i) initial model contains
(in)equality constraints, (ii) evidence, symmetries broken
inference operators applied. case, difference runtime two
algorithms overhead associated constraint processing, almost negligible.
proportion observations increases, symmetries objects
broken, GC-FOVE maintains much coarser grouping, performs inference much
efficiently, C-FOVE. domains, C-FOVEs runtime increases dramatically
increase percentage observations. evidence added, C-FOVE induces
partitions, results finer groupings objects leaves fewer opportunities
lifting. GC-FOVE performs significantly better comparison, due coarser grouping
observations employing absorption elimination model. GC-FOVEs
runtime experiences bump initial set evidence added, levels
gradually decreases (the evidence, randvars efficiently eliminated
absorption). GC-FOVE consistently finishes 200 seconds, regardless setting.
contrast, social network domain (Figure 11(c)) C-FOVE cannot handle portions
evidence greater 1% (it runs memory machine configured 30GB
memory).
results confirm coarser groupings use lifted absorption
contribute much better performance GC-FOVE.
433

fiTaghipour, Fierens, Davis, & Blockeel

6
4

GC-FOVE
C-FOVE

0.4
Time(s)

Time(s)

0.5

GC-FOVE
C-FOVE

5
3
2

0.3
0.2
0.1

1
0

20

40
60
Percentage Evidence

80

0

100

(a) Yeast

0

"

40

60


fffi ffff ff ff

%

100

(b) WebKB

Figure 12: Performance real-world data varying amounts evidence. Yaxis (runtime) drawn log scale. C-FOVE ran completion
zero-evidence experiments.

7.4 Performance Real-World Data
final set experiments, compared algorithms two real-world datasets,
WebKB Yeast. datasets, varied percentage observed page classes
functions 0% 100% steps 10%. Figures 12(a) 12(b) illustrate
results. C-FOVE could solve zero-evidence problems experiments;
cases, typically ran memory hour computation time
machine configured 30 GB memory. failure primarily due large number
observations, often forces resort inference ground level large
number objects. GC-FOVE, hand, runs successfully experimental
conditions. Furthermore, GC-FOVE consistently solve problems seconds.
synthetic data, GC-FOVEs performance improves increasing number
observations. cases randvars eliminated absorption, instead
expensive operations multiplication summation.

8. Conclusions
Constraints play crucial role lifted probabilistic inference determine degree
lifting takes places. Surprisingly, lifted inference algorithms use class
constraints based pairwise (in)equalities (Poole, 2003; de Salvo Braz et al., 2005;
Milch et al., 2008; Jha et al., 2010; Kisynski & Poole, 2009b; Van den Broeck et al., 2011);
main exception work approximate inference using lifted belief propagation
(Singla & Domingos, 2008). paper shown class constraints
overly restrictive. proposed using extensionally complete constraint languages,
capture symmetries among objects allow operations occur
lifted level. defined relevant constraint handling operations (e.g., splitting
normalization) work extensionally complete constraint languages implemented
performing lifted variable elimination. made use constraint trees efficiently represent manipulate constraints. empirically evaluated system
several domains. approach resulted three orders magnitude improvement
runtime, compared C-FOVE. Furthermore, GC-FOVE solve several tasks
intractable C-FOVE.
434

fiDecoupling Lifted Variable Elimination Constraint Language

Future work includes generalizing lifted inference algorithms currently use
inequality constraints, e.g., works Jha et al. (2010) Van den Broeck et al.
(2011), optimizing constraint handling. respect latter, interesting direction recent work de Salvo Braz, Saadati, Bui, OReilly (2012)
employs logical representation constraints, extensionally complete,
presents specialized constraint processing methods representation. Finally,
possible extend lifted absorption works evidence parfactors,
generally deterministic parfactors. another promising direction
future work.
Acknowledgments
Daan Fierens supported Research Foundation Flanders (FWO-Vlaanderen).
Jesse Davis partially supported Research Fund KULeuven (CREA/11/015
OT/11/051), EU FP7 Marie Curie Career Integration Grant (#294068). work
funded GOA/08/008 Probabilistic Logic Learning Research Fund KULeuven.
authors thank Maurice Bruynooghe Guy Van den Broeck interesting discussions
comments work text. also thank reviewers constructive
comments concrete suggestions improve article.

Appendix A. Correctness Proof Lifted Absorption
appendix, prove correctness novel lifted absorption operator. begin
providing lemmas.
Recall set parfactors G compact way defining set factors gr(G) =
{f |f gr(g) g G} corresponding probability distribution
PG (A) =

1
Z



f (Af ).

f gr(G)

Further, G G means G G define probability distribution. Thus, formally:
G G PG (A) = PG (A)

1
Z



f gr(G)

f (Af ) =

1
Z



f (Af ).

f gr(G )

following lemmas easily proven applying definition keeping
mind gr(G G ) = gr(G) gr(G ).
Lemma 1 models G, G , G : G G G G G G .
Lemma 2 Given factor f = (A1 , A2 , . . . , ) evidence factor fE = E (A1 )
E (a1 ) = 1 a1 = (the observed value) E (a1 ) = 0 otherwise, {f, fE } {f , fE }
f = (A2 , . . . , ) (a2 , . . . , ) = (o, a2 , . . . , ).
Lemma 3 model consists identical factors, G = {(A1 , . . . , )}m
i=1 ,



equivalent model single factor G = { (A1 , . . . , )} (a1 , . . . , ) =
(a1 , . . . , )m .
435

fiTaghipour, Fierens, Davis, & Blockeel

prove Absorb operator correct, i.e., postconditions hold, given
preconditions.
Theorem 1 Given model G, parfactor g G evidence parfactor gE ,
preconditions absorb operator fulfilled,
G {gE } G \ {g} {absorb(g, Ai , gE ), gE }.
Proof: G = G \ {g}, rewrite equivalence
G {g, gE } G {absorb(g, Ai , gE ), gE }.
Lemma 1, suffices prove
{g, gE } {absorb(g, Ai , gE ), gE }.
Let g = (A)|C = {A1 (X1 ), . . . , Ak (Xk )}, let gE = E (P (X))|CE , let
L = logvar(A) (non-counted logvars A), Xexcl = X \ logvar(A \ {Ai }) (logvars occurring
exclusively Ai ) L = logvar(A) \ Xexcl (non-counted logvars occurring (also) outside
Ai ). operator returns parfactor form (A )|C = {A2 , . . . , Ak }
C = logvar(C)\Xexcl (C) (see operator definition). need prove
equivalence holds. ease exposition, assume atom
counting formula absorbed (Ai operators input) A1 . first consider
case A1 atom P (X1 ), case A1 counting formula
#X [P (X1 )].
Absorption atoms. case, (a2 , . . . , ak ) = (o, a2 , . . . , ak )r
r = CountXexcl |L (C) (see operator definition, observing Xnce = Xexcl ).
definition, gr(g) = {(P (x1 ), A2 (x2 ), . . . , Ak (xk ))}lL (C) , xi = Xi (l). Precondition 1 guarantees (P (x1 ), A2 (x2 ), . . . , Ak (xk )), exists evidence
factor E (P (x1 )) gr(gE ). Lemma 2, therefore rewrite factor gr(g)
form (A2 (x2 ), . . . ), (a2 , . . . ak ) = (o, a2 , . . . , ak ), observed value
P (x1 ).
potential function factors, since one observed value
whole evidence parfactor. Therefore, two factors (P (x1 ), A2 (x2 ), . . . , Ak (xk ))
(P (x1 ), A2 (x2 ), . . . , Ak (xk )) differ first argument rewritten
factor. Precondition 2, number factors rewritten
factor constant equals CountXexcl |L (C) = r. Lemma 3, set identical
factors therefore replaced single factor potential function
(a2 , . . . , ak ) = (a2 , . . . , ak )r = (o, a2 , . . . , ak )r ,
exactly defined operator.
Absorption counting formulas. case,
(a2 , . . . , ak ) = (e, a2 , . . . , ak )r
r = CountXnce |L (C) Xnce = Xexcl \ {X} (see operator definition).
436

fiDecoupling Lifted Variable Elimination Constraint Language

define X1 = X1 \ {X}, use (x1 , X) denote X1 logvars instantiated
except counted logvar X. Now, definition,
gr(g) = {(#XCl [P (x1 , X)], A2 (x2 ), . . . , Ak (xk ))}lL (C) ,
xi = Xi (l), x1 = X1 (l) Cl = X (L=l (C)). Cl form {x1 , . . . , xn },
n = CountX|L (C) (n exists PCRVs definition count-normalized).
show correctness operator case showing factor f
gr(g), evidence parfactor gE rewritten contain evidence factor
CRV f , reasoning applied f .
Precondition 1 guarantees factor
f = (#X{x1 ,...,xn } [P (x1 , X)], A2 (x2 ), . . . , Ak (xk )),
gr(gE ) contains group evidence factors
Ef = {E (P (x1 , x1 )), . . . , E (P (x1 , xn ))}.
multiply factors Ef
E (P (x1 , x1 ), . . . , P (x1 , xn )),
E (o, o, . . . , o) = 1 E (.) = 0 elsewhere, rewrite
fE = E (#X{x1 ,...,xn } [P (x1 , X)]),
E (i) E (e) = 1, e histogram e(o) = n e(.) = 0
elsewhere, (ii) E (e ) = 0 e 6= e.
formed fE , rewrite f form (A2 (x2 ), . . . ), (a2 , . . . ak ) =
(e, a2 , . . . , ak )r r = CountXnce |L (C), argumentation regular
atoms. this, replace fE equivalent Ef , thus restoring gE . Repeating
f preserves equivalence eventually yields model operator
returns.


Appendix B. Computational Complexity Lifted Absorption
Applying lifted absorption parfactor g = (A)|C, complexity O(|C|) + O(Size()
log |C|), |C| cardinality (number tuples) constraint
Q C, Size()
equals product range sizes arguments A, i.e., Size() = Ai |range(Ai )|.
first term complexity, O(|C|), arises absorption involves projection
constraint C, worst case (with extensional representation) complexity O(|C|). second term, O(Size() log |C|), complexity computing new
potential function, involves manipulating , Size() entries (in tabular
representation), exponentiating it, complexity O(log |C|).
437

fiTaghipour, Fierens, Davis, & Blockeel

References
Apsel, U., & Brafman, R. I. (2011). Extended lifted inference joint formulas.
Proceedings 27th Conference Uncertainty Artificial Intelligence (UAI),
pp. 1118.
Choi, J., Hill, D., & Amir, E. (2010). Lifted inference relational continuous models.
Proceedings 26th Conference Uncertainty Artificial Intelligence (UAI),
pp. 126134.
Craven, M., & Slattery, S. (1997). Relational learning statistical predicate invention:
Better models hypertext. Machine Learning, 43(1/2), 97119.
Davis, J., Burnside, E. S., de Castro Dutra, I., Page, D., & Costa, V. S. (2005).
integrated approach learning Bayesian networks rules. Proceedings 16th
European Conference Machine Learning (ECML), pp. 8495.
De Raedt, L., Frasconi, P., Kersting, K., & Muggleton, S. (Eds.). (2008). Probabilistic inductive logic programming: Theory applications. Springer-Verlag, Berlin, Heidelberg.
de Salvo Braz, R. (2007). Lifted first-order probabilistic inference. Ph.D. thesis, Department
Computer Science, University Illinois Urbana-Champaign.
de Salvo Braz, R., Amir, E., & Roth, D. (2005). Lifted first-order probabilistic inference.
Proceedings 19th International Joint Conference Artificial Intelligence
(IJCAI), pp. 13191325.
de Salvo Braz, R., Saadati, S., Bui, H., & OReilly, C. (2012). Lifted arbitrary constraint solving lifted probabilistic inference. Proceedings 2nd International Workshop
Statistical Relational AI (StaRAI), pp. 18.
Dechter, R. (2003). Constraint processing. Morgan Kaufmann.
Getoor, L., & Taskar, B. (Eds.). (2007). Introduction Statistical Relational Learning.
MIT Press.
Gogate, V., & Domingos, P. (2011). Probabilistic theorem proving. Proceedings
27th Conference Uncertainty Artificial Intelligence (UAI), pp. 256265.
Jha, A., Gogate, V., Meliou, A., & Suciu, D. (2010). Lifted inference seen
side : tractable features. Proceedings 23rd Annual Conference Neural
Information Processing Systems (NIPS), pp. 973981.
Kersting, K., Ahmadi, B., & Natarajan, S. (2009). Counting belief propagation. Proceedings 25th Conference Uncertainty Artificial Intelligence (UAI), pp.
277284.
Kisynski, J., & Poole, D. (2009a). Constraint processing lifted probabilistic inference.
Proceedings 25th Conference Uncertainty Artificial Intelligence (UAI),
pp. 293302.
Kisynski, J., & Poole, D. (2009b). Lifted aggregation directed first-order probabilistic models. Proceedings 21st International Joint Conference Artificial
Intelligence (IJCAI), pp. 19221929.
438

fiDecoupling Lifted Variable Elimination Constraint Language

Kschischang, F. R., Frey, B. J., & Loeliger, H.-A. (2001). Factor graphs sum-product
algorithm. IEEE Transactions Information Theory, 47 (2), 498519.
Meert, W., Taghipour, N., & Blockeel, H. (2010). First-order bayes-ball. Proceedings
European Conference Machine Learning Knowledge Discovery Databases
(ECML PKDD), pp. 369384.
Milch, B. (2008). BLOG.. http://people.csail.mit.edu/milch/blog/.
Milch, B., Zettlemoyer, L. S., Kersting, K., Haimes, M., & Kaelbling, L. P. (2008). Lifted
probabilistic inference counting formulas. Proceedings 23rd AAAI Conference Artificial Intelligence (AAAI), pp. 10621608.
Poole, D. (2003). First-order probabilistic inference.. Proceedings 18th International
Joint Conference Artificial Intelligence (IJCAI), pp. 985991.
Ramakrishnan, R., & Gehrke, J. (2003). Database management systems (3. ed.). McGrawHill.
Sen, P., Deshpande, A., & Getoor, L. (2009a). Bisimulation-based approximate lifted inference. Proceedings 25th Conference Uncertainty Artificial Intelligence
(UAI09), pp. 496505.
Sen, P., Deshpande, A., & Getoor, L. (2009b). Prdb: managing exploiting rich correlations probabilistic databases. VLDB Journal, 18 (5), 10651090.
Singla, P., & Domingos, P. (2008). Lifted first-order belief propagation. Proceedings
23rd AAAI Conference Artificial Intelligence (AAAI), pp. 10941099.
Singla, P., Nath, A., & Domingos, P. (2010). Approximate Lifted Belief Propagation.
Proceedings 1st International Workshop Statistical Relation AI (StaRAI),
pp. 9297.
Taghipour, N., Fierens, D., Davis, J., & Blockeel, H. (2012). Lifted variable elimination
arbitrary constraints. Proceedings 15th International Conference
Artificial Intelligence Statistics (AISTATS), pp. 11941202.
Van den Broeck, G., & Davis, J. (2012). Conditioning first-order knowledge compilation
lifted probabilistic inference. Proceedings 26th AAAI Conference
Artificial Intelligence (AAAI), pp. 17.
Van den Broeck, G., Taghipour, N., Meert, W., Davis, J., & De Raedt, L. (2011). Lifted
Probabilistic Inference First-Order Knowledge Compilation. Proceedings
22nd International Joint Conference Artificial Intelligence (IJCAI), pp. 21782185.
van der Gaag, L. C. (1996). evidence absorption belief networks. Int. J. Approx.
Reasoning, 15 (3), 265286.

439

fiJournal Artificial Intelligence Research 47 (2013) 575-611

Submitted 02/13; published 07/13

Refined View Causal Graphs Component Sizes:
SP-Closed Graph Classes Beyond
Christer Backstrom
Peter Jonsson

christer.backstrom@liu.se
peter.jonsson@liu.se

Department Computer Science
Linkoping University
SE-581 83 Linkoping, Sweden

Abstract
causal graph planning instance important tool planning
practice theory. theoretical studies causal graphs largely analysed
computational complexity planning instances causal graph certain
structure, often combination parameters like domain size variables.
Chen Gimenez ignored even structure considered size weakly
connected components. proved planning tractable components
bounded constant otherwise intractable. intractability result was, however,
conditioned assumption parameterised complexity theory known
useful relationship standard complexity classes. approach problem
perspective standard complexity classes, prove planning NP-hard
classes unbounded components additional restriction refer SPclosed. argue NP-hardness theorems causal graphs difficult
apply and, thus, prove general result; even component sizes grow slowly
class densely populated graphs, planning still cannot tractable unless
polynomial hierachy collapses. results still hold restricted class
acyclic causal graphs. finally give partial characterization borderline
NP-hard NP-intermediate classes, giving insight problem.

1. Introduction
first briefly explain causal graph give short survey applications
well theoretical results reported literature. Following that, give overview
new results presented article.
1.1 Background
causal graph planning instance explicit description variable dependencies implicitly defined operators. precisely, directed graph
arc variable x another variable either x appears
precondition operator effect operator effects x y.
standard definition causal graph traced back Knoblock (1994)
although give name. used causal graph Alpine algorithm,
guidance partitioning ordering variables process automatically
deriving state abstraction hierarchies. actual name causal graph traced back
Williams Nayak (1997). approach general restricted
c
2013
AI Access Foundation. rights reserved.

fiBackstrom & Jonsson

Knoblocks. one hand, generalized concept binary variables
multi-valued variables, hand, considered acyclic causal graphs
implies operators unary, i.e. every operator changes one variable.
context work reactive planner Burton onboard space-ship control.
causal model compiled transition system could efficiently exploited
reactive controller choose appropriate operators achieve given goals. compilation
done way operators unary, claimed often
possible real applications. resulting acyclicity causal graph exploited
Burton, traversed graph bottom order issue operators order
consistent causal relationships.
Jonsson Backstrom (1998b) also studied acyclic causal graphs, referred
dependency graphs. considered subclass graphs particular structure used implicitly define corresponding class planning instances, 3S
class. class property always possible decide polynomial time
solution not, solutions may exponential length, thus
necessarily taking exponential time generate. Although one single restricted case,
3S class probably first example relating structural properties causal graph
computational complexity planning. general extensive analysis
done Domshlak Dinitz (2001a), analysed complexity planning
classes instances corresponding number different possible structures acyclic
causal graphs. However, work done context multi-agent coordination
term causal graph never used.
first two papers may viewed early examples exploiting causal
graph practice, latter papers form starting point subsequent theoretical research relationships planning complexity structure
causal graphs.
important step forward usage causal graphs paper Helmert
(2004) demonstrated causal graph particularly useful context
multi-valued variables. Previous research complexity planning multi-valued
variables focussed structure domain-transition graphs variables
(Jonsson & Backstrom, 1998a), rather causal graph. Helmert realized power
using domain-transition graphs causal graph heuristic planning.
exploited practice highly succesful Fast Downward planner (Helmert,
2006a). translates PDDL planning instances binary variables representation
multi-valued variables removes carefully chosen edges resulting causal
graph make acyclic. resulting causal graph used compute heuristic
hierarchically computing composing plan lengths subgraphs one
particular structures studied Domshlak Dinitz (2001a). Somewhat similarly, Katz
Domshlak (2010) identified subgraphs causal graph certain structures
make planning tractable. exploited able use larger variables
sets constructing pattern databases. example exploiting causal graph
make planning efficient paper factored planning Brafman Domshlak
(2006). showed structure causal graph used guide
deciding planning instance solved efficiently dividing
loosely coupled subinstances use constraint processing. basic idea causal
576

fiA Refined View Causal Graphs Component Sizes

graph represent variable dependencies is, course, quite general necessarily
restricted planning. instance, Wehrle Helmert (2009) transferred causal
graph concept context model checking.
previously mentioned, two papers Jonsson Backstrom (1998b)
Domshlak Dinitz (2001a) viewed starting point successful line
research studying relationships planning complexity structure
causal graph. 3S class Jonsson Backstrom limited
special case, Domshlak Dinitz studied classes planning instances corresponding
number general graph structures, like in-stars (aka. inverted forks), out-stars (aka.
forks), directed path graphs (aka. directed chain graphs), polytrees singly-connected
DAGs. results followed, instance, articles Brafman Domshlak (2003),
Gimenez Jonsson (2008). latter article additionally showed although 3S
instances exponential-length plans, possible generate macro representation
plan polynomial time, result extended also classes defined
structure causal graph. Many complexity results papers use
additional numerical parameters conjunction graph structure. Examples
parameters maximum domain size variables maximum in-degree
graph. increasing number possible cases analyse, allow
fine-grained analysis many cases. Consider instance case directed path
graphs. Domshlak Dinitz (2001a) proved tractable decide
plan case domains binary, Gimenez Jonsson (2009) proved
domain size 5 sufficient make problem NP-hard. Similarly, Gimenez
Jonsson (2012) proved tractability planning instances binary variables, constant
number prevail conditions causal graph polytree. Also paper
Brafman Domshlak (2006) fits line theoretical research, exhibiting
planning algorithm runs time exponential two parameters, tree-width
undirected version causal graph maximum number times variable must
change value.
research based standard definition causal graphs
set already Knoblock, although often generalisation multi-valued variables,
important exceptions. One potential problem standard defintion
whenever two variables affected operator, causal graph must
necessarily contain cycles, major reason focus mainly
planning unary operators. attempt circumvent problem, Jonsson (2009)
defined relaxed variant causal graph always introduce cycles
non-unary operators, sometimes allow fine-grained complexity analysis.
previous results relate structure causal graph complexity satisficing planning, i.e. deciding plan. also corresponding branch
research relating structure causal graph complexity cost-optimal
planning (cf., Katz & Domshlak, 2007, 2008, 2010; Katz & Keyder, 2012).
1.2 Contributions
theoretical research studies complexity planning based structure causal graph, possibly parameters like domain sizes. important
577

fiBackstrom & Jonsson

milestone deviates line research article Chen Gimenez
(2010) even consider structure causal graph simple quantitative measure, size weakly connected components. proved deciding
plan done polynomial time size weakly connected components causal graph bounded constant. one sense,
sharp final result. However, intractability result unbounded components
conditional assumtion W[1] 6 nu-FPT. assumption relies theory
parameterised complexity theory neither complexity classes assumption
related ordinary complexity classes clear way. Chen Gimenez acknowledge problems prove conditionally intractable include NP-intermediate
problems. Hence, take result take-off point investigation
component sizes reflect standard complexity classes. Since know Chen
Gimenez graph classes unbounded components NP-hard must
consider restrictions order find NP-hard classes. adding new
type closure property, SP-closure, incomparable subset-closure subset minor-closure, prove planning NP-hard SP-closed graph class
unbounded components. noted result still holds class
acyclic graphs, important considering practical relevance acyclicity
previously mentioned.
many graph classes studied literature indeed SP-closed,
also exists natural classes lack property. present one way handling
classes aid non-uniform complexity theory. case, able
show NP-hardness show polynomial hierarchy collapses second
level. fairly general result applied even component sizes grow
slowly graph class densely populated graphs. Also result
holds even restricted acyclic graphs. result used demonstrate clearly
complexity results planning based class causal graphs necessarily connection complexity generic planning problem
class causal graphs. result also raises question find (preferably natural) NP-intermediate planning problems. Chen Gimenez state NP-intermediate
problems obtained using methods similiar ones employed Bodirsky
Grohe (2008). problems hard describe natural, though. based
Ladners (1975) diagonalization technique removes large fraction input strings
problem. apparently difficult connect graph classes constructed technique
simple conditions component growth. alternative, show graph classes
component sizes grow polylogarithmically NP-intermediate double
assumption W[1] 6 nu-FPT exponential time hypothesis (Impagliazzo
& Paturi, 2001) holds. also show every k > 1, exists class Gk graphs
component size bounded |V (G)|1/k G Gk corresponding
planning problem NP-hard. results coarsely stake borderline
NP-hard NP-intermediate classes.
possible conclusion paper complexity analysis planning based
structure causal graph limited value, additional parameters
needed achieve useful results. may fair conclusion general,
cases graph structure sufficient. instance, Katz, Hoffmann, Domsh578

fiA Refined View Causal Graphs Component Sizes

lak (2013) applied result Chen Gimenez (2010) context called
red-black planning, variant delete relaxation computing heuristics. Furthermore,
even structure causal graph combined parameters,
still important know behaviour parameter isolation.
remainder article structured follows. Section 2 set notation
terminology used planning graphs, Section 3 define causal graphs
structural planning general. Section 4 contains number NP-hardness results
various special graph classes need main results. first two main
theorems article appears Section 5, define concept SP-closed graph
classes prove planning NP-hard classes component size
unbounded. Section 6 discusses problems previous theorem
similar results literature. way around problems, second main
theorem shows even without closure requirements, planning likely hard
even components grow slowly graphs appear densely class.
Section 7 contains observations concerning borderline NP-intermediate
NP-hard planning problems. article ends discussion section.

2. Preliminaries
section sets terminology notation planning graphs used article.
write |X| denote cardinality set X length sequence X, i.e.
number elements X, write ||X|| denote size representation
object X.
2.1 Planning
Since article many connections one Chen Gimenez (2010)
follow notation terminology plannning, notational variant SAS+
(Backstrom & Nebel, 1995).
instance planning problem tuple = (V, init, goal, A) whose components
defined follows:
V finite set variables, variable v V associated finite domain
D(v). Note variables necessarily propositional, is, D(v) may
finite set. state mapping defined variables V s(v) D(v)
v V . partial state mapping p defined subset vars(p) variables V
v vars(p), holds p(v) D(v), p otherwise undefined.
init state called initial state.
goal partial state.
set operators; operator consists precondition pre(a)
postcondition post(a) partial states. often use notation
hpre ; posti define operator precondition pre postcondition post.
instance, = hx = 0, = 1 ; z = 1i defines operator applicable
state s(x) = 0 s(y) = 1, effect setting variable
z 1.
579

fiBackstrom & Jonsson

state partial state W subset variable set V , write
W denote partial state resulting restricting W . say state
goal state goal = vars(goal).
define plan (for instance ) sequence operators P = a1 , . . . , .
Starting state s, define state resulting applying plan P , denoted
s[P ], inductively follows. empty plan P = , define s[] = s. non-empty
plans P define s[P ] follows, last operator P P 0 prefix
P to, including, a:
pre(a) 6= s[P 0 ] vars(pre(a)) (that is, preconditions satisfied
state s[P 0 ]), s[P 0 , a] = s[P 0 ].
Otherwise, s[P 0 , a] state equal post(a) variables v vars(post(a)),
equal s[P 0 ] variables v V \ vars(post(a)).
plan P solution plan init[P ] goal state.
concerned computational problem plan existence (PlanExist): given
instance = (V, init, goal, A), decide exists solution plan.
2.2 Graphs
directed graph pair (V, E) V vertex set E V V edge set.
undirected graph pair (V, E) V vertex set E {{u, v} | u, v V }
edge set. often say graph edge clear context whether
directed undirected. notation V (G) refers vertex set graph G
E(G) refers edge set. e = (u, v) e = {u, v} edge, vertices u
v incident e. Furthermore, directed edge (u, v) outgoing edge u
incoming edge v. directed graph G = (V, E), write U (G) denote
correspsonding undirected graph U (G) = (V, EU ) EU = {{u, v} | (u, v) E}.
is, U (G) undirected graph induced G ignoring orientation edges.
Let G = (V, E) directed graph let v0 , . . . , vk V v1 , . . . , vk
distinct (vi1 , vi ) E (1 k). sequence v0 , . . . , vk directed
path length k G v0 6= vk directed cycle length k G v0 = vk . Paths
cycles undirected graphs defined analogously, except direction
consider. graph acyclic contains cycles.
Let G = (V, E) directed graph let v V vertex. Then, v isolated
incoming outgoing edges, v source least one outgoing edge
incoming edge, v sink least one incoming edge outgoing edge
otherwise v intermediate.
Let G = (VG , EG ) H = (VH , EH ) two directed graphs. G H
isomorphic (denoted G ' H) exists bijective function f : VG VH
(u, v) EG (f (u), f (v)) EH . Furthermore, H subgraph G VH VG
EH EG (VH VH ). EH = EG (VH VH ) say subgraph H
induced vertex set VH . Isomorphisms subgraphs analogously defined
undirected graphs.
Let G undirected graph. G connected path every
pair vertices G. connected component G maximal subgraph G
580

fiA Refined View Causal Graphs Component Sizes

connected. Let G directed graph. G weakly connected U (G) connected.
weakly connected component G maximal subgraph G weakly connected.
is, weakly connected component paths every pair vertices
ignore direction edges. Let G = (VG , EG ) H = (VH , EH ) two directed
graphs VG VH disjoint. (disjoint) union G H defined
G H = (VG VH , EG EH ) commutative operation. Note graph G
consists (weakly) connected components G1 , . . . , Gn , G = G1 G2 . . . Gn .
define numeric graph parameters. directed graph G vertex
v V (G), indegree v |{u V (G) | (u, v) E(G)}|, i.e. number incoming
edges incident v, outdegree v |{u V (G) | (v, u) E(G)}|, i.e. number
outgoing edges incident v. undirected graph G, degree v V (G)
|{u V (G) | {v, u} E(G)}|, i.e. number edges incident v. extend
graphs follows. G undirected graph, deg(G) denotes largest degree
vertex V (G). Similarly, G directed graph in-deg(G) denotes largest
indegree vertex V (G) out-deg(G) denotes largest outdegree vertex
V (G). Furthermore, G undirected graph, path-length(G) denotes length
longest path G cc-size(G) denotes size largest connected component
G. G directed graph, path-length(G) denotes length longest directed path
G. also define upath-length(G) = path-length(U (G)) cc-size(G) = cc-size(U (G)).
is, upath-length(G) length longest path G ignoring direction
edges cc-size(G) size largest weakly connected component G. Note
G undirected connected graph, path-length(G) equals diameter G.
extend numeric graph properties (in-deg, path-length etc.) sets graphs
C set graphs prop graph property, prop(C) = maxGC prop(G).
2.3 Special Graph Types
literature causal graphs, well article, certain types graphs
particular interest thus useful refer names. distinguish
following types undirected graphs: tree undirected graph two
vertices connected exactly one path, i.e. acyclic connected. path graph
tree vertices degree 1 2, i.e. tree branch. star
graph tree vertices except one, centre vertex, degree 1.
directed graphs, distinguish following types: in-star graph directed
graph G U (G) star graph edges directed towards centre.
out-star graph directed graph G U (G) star graph edges
directed centre. directed path graph directed graph G U (G)
path graph, in-deg(G) 1 out-deg(G) 1, i.e. G directed path
vertices contains edges. polytree directed graph G U (G)
tree, i.e. G weakly connected directed graph constructed tree
giving unique direction every edge. polypath directed graph G U (G)
path graph, i.e. G weakly connected directed graph constructed
path graph giving unique direction every edge. fence polypath every
vertex either source sink, i.e. edges alternate direction every vertex.
581

fiBackstrom & Jonsson

noted out-star graph usually called directed star graph
graph theory, in-star graph appears standard name. hence deviate
sligthly standard terminology order logical names graph types.
Also polypath appears standard name, polypath logical term
analogy polytree. noted parallel terminology certain
graph types evolved literature causal graphs planning. instance, instars, out-stars directed paths commonly referred inverted forks, forks
directed chains, respectively.
Note number sinks sources polypath differ one, i.e.
polypath sinks + c sources c {1, 0, 1}. Furthermore, every fence
polypath, every polypath fence.
define following graphs graphs classes:
Skin denotes in-star graph one centre vertex k sources. Also define
class Sin = {Skin | k 0}.
Skout denotes out-star one centre vertex k sinks. Also define class
Sout = {Skout | k 0}.
dPk denotes directed path k vertices. Also define class dP = {dPk | 1 k}.
c , c {1, 0, 1}, denotes fence sinks + c sources. Also define
Fm
c | 1 m}, c {1, 0, 1}, class F = F1 F0 F+1 .
class Fc = {Fm

Examples graph types illustrated Figure 1.

v1
v5

v1
v2

vc
v4

v5

v3

v2

vc
v4

v0

v1

v2

v1

v2
u1

v3
u2

F31

v4

v3
S5out

S5in

v3

dP5

v1
u0

v2
u1

v3
u2

v1
u0

F30

v2
u1

v3
u2

u3

F3+1

Figure 1: Examples important graph types.
following observation polypaths used later on.
Proposition 1. Let G polypath sinks + 1 sources
path-length(G) k. |V (G)| 2mk + 1.
582

fiA Refined View Causal Graphs Component Sizes

Proof. 2m distinct paths source sink,
k 1 intermediate vertices. Hence |V (G)| + (m + 1) + 2m(k 1) = 2mk + 1.
bound obviously tight case sinks + 1 sources,
every path source sink contains exactly k 1 intermediate vertices.

3. Structurally Restricted Planning
topic study article causal graphs planning, discussing
concept first define concept domain-transition graphs (Jonsson & Backstrom,
1998a). Although used explicitly results, useful explaining
proofs later article. Let = (V, init, goal, A) planning instance.
variable v V , define domain-transition graph (DTG) v directed graph
(D(v), E), x, D(v), E contains edge (x, y) operator
post(a)(v) = either pre(a)(v) = x v 6 vars(pre(a)).
causal graph planning instance describes variables instance
depends other, implicitly defined operators.
Definition 2. causal graph planning instance = (V, init, goal, A) directed
graph CG() = (V, E) E contains edge (u, v) every pair distinct vertices u, v V u vars(pre(a)) vars(post(a)) v vars(post(a))
operator A.
causal graph gives some, all, information operators. instance,
causal graph acyclic, operators must unary, i.e. |vars(post)(a)| = 1
operators, since non-unary operator must necessarily introduce cycle according
definition. However, presence cycles necessarily mean
non-unary operators. instance, edges (u, v) (v, u) present
graph, mean operator u vars(post(a))
v vars(post(a)). However, also mean two operators a0
u vars(pre(a)), v vars(post(a)), v vars(pre(a0 )) u vars(post(a0 )), could
thus unary operators. Similarly, degree vertices provides upper bound
number pre- postconditions operators, lower bound. Suppose
vertex u indegree 2 incoming edges (v, u) (w, u). could mean
operator u vars(post(a)) v vars(pre(a))
w vars(pre(a)). However, also mean two different operators a0
v vars(pre(a)), u vars(post(a)), w vars(pre(a0 )) u vars(post(a0 )).
PlanExist problem extended planning instances causal graphs
following way. class C directed graphs, PlanExist(C) problem deciding
arbitrary planning instance CG() C, whether solution
not. is, complexity PlanExist(C) refers complexity set planning
instances whose causal graphs members C.
number results literature computational complexity
planning various classes causal graphs. However, results usually assume
graph class restricted structure, e.g. containing in-stars directed
paths. general abstract result following theorem.
583

fiBackstrom & Jonsson

Theorem 3. (Chen & Gimenez, 2010, Thm. 3.1) Let C class directed graphs.
cc-size(C) bounded, PlanExist(C) solvable polynomial time. cc-size(C)
unbounded, PlanExist(C) polynomial-time solvable (unless W[1] nu-FPT).
theorem describes crisp borderline tractable intractable graph
classes, assumption W[1] 6 nu-FPT1 . complexity
classes theory parameterised complexity cannot immediately related
usual complexity classes. scope article treat parameterised
complexity refer reader standard textbooks (Downey & Fellows, 1999; Flum
& Grohe, 2006). result theorem parameterised result, however;
condition parameterised, suffices note intractability result holds
condition difficult relate common assumptions, P 6= NP.
One reasons Chen Gimenez forced state theorem way
classification polynomial NP-hard classes would exhaustive,
since graph classes NP-intermediate. (A problem NP-intermediate
neither P NP-complete, unless P = NP.)
theorem might viewed starting point research reported
article, investigate problem perspective standard complexity
classes. instance, NP-hardness proved case unbounded components
adding restrictions, Section 5.

4. Basic Constructions
section presents results necessary theorems later article.
first three results, planning NP-hard in-stars (aka. inverted forks), out-stars
(aka. forks) directed paths (aka. directed chains), known literature,
NP-hardness result fences new. will, however, provide new proofs also
in-star out-star cases. major reason Section 6 need refer
reductions certain precisely known properties. Furthermore, original proofs
published technical report (Domshlak & Dinitz, 2001b) may thus hard
access.
Lemma 4. (Domshlak & Dinitz, 2001a, Thm. 3.IV) PlanExist(Sin ) NP-hard. result
holds even restricted operators 2 preconditions 1 postcondition.
Proof. (New proof) Proof reduction 3SAT class planning instances
causal graphs Sin . reduction constructs planning instance source
causal graph corresponds one variables formula centre corresponds
clauses. construction illustrated Figure 2 formally defined follows.
Let F = c1 . . . cm arbitrary 3SAT formula variables x1 , . . . , xn clauses
c1 , . . . , cm . Construct corresponding planning instance F = (V, init, goal, A) follows:
V = {vc , v1 , . . . , vn },
D(vc ) = {0, . . . , m}
D(vi ) = {u, f, t}, (1 n).
1. condition simplified W[1] 6 FPT class C recursively enumerable.

584

fiA Refined View Causal Graphs Component Sizes

vc
0

1

2


u


u


u

f
v1



f
v2

f
vn

Figure 2: in-star causal graph DTGs construction proof
Lemma 4.

init(vi ) = u, (1 n), init(vc ) = 0.
goal(vc ) = goal otherwise undefined.
consists following operators:
(1 n), contains operators
set-f(i) = hvi = u ; vi = f
set-t(i) = hvi = u ; vi = ti.
clause ci = (`1i `2i `3i ) j (1 j 3), k
`ji = xk `ji = xk , let contain either operator
verify-clause-pos(i, j) = hvc = 1, vk = ; vc = ii, `ji = xk ,
operator
verify-clause-neg(i, j) = hvc = 1, vk = f ; vc = ii, `ji = xk .
Clearly, instance F constructed polynomial time CG(F ) = Snin ,
remains prove F solution F satisfiable.
source variable vi changed independently. starts undefined
value u set either f , corresponding true false, respectively,
corresponding variable xi F . set either f , cannot changed again.
is, variables v1 , . . . , vn used choose commit truth assignment
x1 , . . . , xn . centre variable vc one value, i, clause ci F , plus initial
value 0. possible reach goal value inital value 0 stepping
585

fiBackstrom & Jonsson

intermediate values numerical order. step, 1 i,
three operators choose from, corresponding literals clause ci . step
possible one v1 , . . . , vn set value consistent one literals ci .
is, goal vc = achieved variables v1 , . . . , vn set values
corresponding truth assignment x1 , . . . , xn satisfies F .
restricted case (with respect pre- post-conditions) immediate
construction above.
problem known tractable, though, domain size centre variable
bounded constant (Katz & Domshlak, 2010). Furthermore, causal graph heuristic
Helmert (2004) based identifying in-star subgraphs causal graph,
noted provided variant original proof due minor technical
differences problem formulations.
Lemma 5. (Domshlak & Dinitz, 2001a, Thm. 3.III) PlanExist(Sout ) NP-hard. result
holds even restricted operators 1 precondition 1 postcondition.
Proof. (New proof) Proof reduction 3SAT class planning instances
causal graphs Sout . reduction constructs planning instance centre vertex
causal graph corresponds variables formula sink corresponds
one clauses. construction illustrated Figure 3 formally defined
follows.
v1

u

v2

vm



u



u

t0

t1

t2

tn

f0

f1

f2

fn



vc

Figure 3: out-star causal graph DTGs construction proof
Lemma 5.

Let F = c1 . . . cm arbitrary 3SAT formula variables x1 , . . . , xn clauses
c1 , . . . , cm . Construct corresponding planning instance F = (V, init, goal, A) follows:
586

fiA Refined View Causal Graphs Component Sizes

V = {vc , v1 , . . . , vm },
D(vc ) = {f0 , . . . , fn , t0 , . . . , tn }
D(vi ) = {u, s}, (1 m).
init(vi ) = u, (1 m), init(vc ) = f0 .
goal(vi ) = s, (1 m), goal(vc ) undefined.
consists following operators:
(1 n), contains operators
step-c(fi1 , fi ) = hvc = fi1 ; vc = fi i,
step-c(fi1 , ti ) = hvc = fi1 ; vc = ti i,
step-c(ti1 , fi ) = hvc = ti1 ; vc = fi
step-c(ti1 , ti ) = hvc = ti1 ; vc = ti i.
clause ci = (`1i `2i `3i ) j (1 j 3), k
`ji = xk `ji = xk , let contain either operator
verify-clause-pos(i, j) = hvc = tk ; vi = si, `ji = xk ,
operator
verify-clause-neg(i, j) = hvc = fk ; vi = si, `ji = xk .
Clearly, instance F constructed polynomial time CG(F ) = Snout ,
remains prove F solution F satisfiable.
Variable vc changed independently two values, ti fi ,
variable xi F , corresponding possible truth values xi . addition
initial value f0 (and dummy value t0 order simplify formal definition).
values tn fn reachable initial value f0 , plan correspond
path f0 , z1 , z2 , . . . , zn zi either ti fi . is, vc must pass either value
ti fi , both, i. Hence, path correspond truth assignment
variables x1 , . . . , xn F . clause ci F , corresponding variable
vi change value initial value u, unsatisfied, goal value s, satisfied.
vi three operators this, one literal ci . is, ci contains
literal xk (or xk ) vi change value u vc value tk (or fk ).
Hence, goal v1 = . . . = vm = achieved path vc
corresponds truth assignment x1 , . . . , xn satisfies F . (Note, though,
vc must always follow path way fn tn since partial assignment may
sometimes sufficient prove satisfiability.)
restricted case (with respect pre- post-conditions) immediate
construction above.
problem known tractable, though, domain size centre variable
bounded constant (Katz & Keyder, 2012).
following result planning directed-path causal graphs also known
literature.
Lemma 6. (Gimenez & Jonsson, 2009, Prop. 5.5) PlanExist(dP) NP-hard, even
variables domain size 5 operators 2 preconditions 1 postcondition.
587

fiBackstrom & Jonsson

refer Gimenez Jonsson proof. However, implicitly use
proof later article important observations make it.
reduction SAT and, thus, works also reduction 3SAT. Furthermore,
reduction transforms formula n variables clauses planning instance
(2m + 4)n variables. final remark, problem known tractable variables
domain size 2 (Domshlak & Dinitz, 2001a).
three previous results known literature, following result new
best knowledge.
Lemma 7. PlanExist(F+1 ) NP-hard. result holds even restricted operators
2 preconditions 1 postcondition.
Proof. Proof reduction 3SAT class planning instances causal graphs
F+1 .
reduction constructs planning instance sink causal graph corresponds one clauses formula, source corresponds variables.
Furthermore, source variables synchronized behaviour. construction illustrated Figure 4 formally defined follows.
Let F = c1 . . . cm arbitrary 3SAT formula variables x1 , . . . , xn clauses
c1 , . . . , cm . Construct corresponding planning instance F follows:
V = {u0 , . . . , um , v1 , . . . , vm },
D(ui ) = {f0 , . . . , fn , t0 , . . . , tn }, (0 m),
u , tu , . . . , tu , f , . . . f , ts , . . . , ts , s}, (1 m).
D(vi ) = {f0u , . . . , fm
0
0

0
init(ui ) = f0 , (0 m), init(vi ) = f0u , (1 m).
goal(vi ) = s, (1 m), goal otherwise undefined.
Let consist following operators:
i, j (1 n, 0 j m), contains operators
step-x(j, fi1 , fi ) = huj = fi1 ; uj = fi i,
step-x(j, fi1 , ti ) = huj = fi1 ; uj = ti i,
step-x(j, ti1 , fi ) = huj = ti1 ; uj = fi
step-x(j, ti1 , ti ) = huj = ti1 ; uj = ti i.
i, j, (1 n, 1 j m), contains operators
u
u , f u ) = hv = f u , u
step-clause-u(j, fi1
j
i1 j1 = fi , uj = fi ; vj = fi i,

u
u
u
u
step-clause-u(j, fi1 , ti ) = hvj = fi1 , uj1 = ti , uj = ti ; vj = ti i,
step-clause-u(j, tui1 , fiu ) = hvj = tui1 , uj1 = fi , uj = fi ; vj = fiu i,
step-clause-u(j, tui1 , tui ) = hvj = tui1 , uj1 = ti , uj = ti ; vj = tui i,
, f ) = hv = f , u

step-clause-s(j, fi1
j

i1 j1 = fi , uj = fi ; vj = fi i,
, ts ) = hv = f , u

step-clause-s(j, fi1
j

i1 j1 = ti , uj = ti ; vj = ti i,



step-clause-s(j, ti1 , fi ) = hvj = ti1 , uj1 = fi , uj = fi ; vj = fis i,
step-clause-s(j, tsi1 , tsi ) = hvj = tsi1 , uj1 = ti , uj = ti ; vj = tsi i,
j (1 j m), contains operators
finalize-clause-f(j) = hvj = fns ; vj = si
finalize-clause-t(j) = hvj = tsn ; vj = si.
588

fiA Refined View Causal Graphs Component Sizes

vi1

vi+1

vi
tu0

tu1

tu2

tun

f0u

f1u

f2u

fnu

x1 ci

x2 ci

ts0

ts1

ts2

tsn

f0s

f1s

f2s

fns



t0

t1

t2

tn

t0

t1

t2

tn

f0

f1

f2

fn

f0

f1

f2

fn

ui1

ui

Figure 4: fence causal graph DTGs construction proof
Lemma 7. (This example assumes clause ci contains literals x1 x2 ).

clause ci = (`1i `2i `3i ) j (1 j 3), k
`ji = xk `ji = xk let contain either operator
verify-pos(i, j) = hvi = tuk ; vi = tsk i, `ji = xk ,
operator
verify-neg(i, j) = hvi = fku ; vi = fks i, `ji = xk .
+1 . Hence,
Clearly, instance F constructed polynomial time CG(F ) = Fm
remains prove F solution F satisfiable.
First consider variables ui vi , i. construction domain
operators ui identical one vc proof Lemma 5, i.e.
directed path value f0 fn tn every possible truth assignment variables
x1 , . . . , xn F . Variable vi , corresponds clause ci contains two copies DTG
ui , values differ extra superscript, u s. latter copy extended
additional value s, denoting clause satisfied. operators
allows vi mimic behaviour ui ; follow corresponding path either
two copies. Furthermore, three literals ci operator

589

fiBackstrom & Jonsson

makes possible move value zku value zks value zk ui consistent
ts order reach goal value
literal. Since vi starts f0u must reach either fm

s, necessary vi make transition one literals ci . is, ui
follows path f0 , z1 , . . . , zn vi must follow path f0u , z1u , . . . , zku , zks , . . . , zns , s,
k xk occurs literal ci zk satisfying truth value literal.
consider also variable ui1 . Since operator affects value vi either
precondition ui1 ui precondition either, follows
ui1 ui must choose path vi reach goal. Since every variable vj
forces synchronization adjacent variables uj1 uj manner, follows
u0 , . . . , um must choose exactly path plan solution. thus
follows argument ui vi goal v1 = . . . = vm =
achieved path u0 , . . . , um choose
path corresponds satisfying truth assignment F .
restriction, first note immediate construction operators
3 preconditions 1 postcondition sufficient. see 2 preconditions
sufficient, consider following variation construction. step-clause-u stepclause-t operator replaced two operators follows. example, consider
u , tu ). First introduce extra value f tu D(v ). replace
operator step-clause-u(j, fi1
j


operator two new operators
u , f tu ) = hv = f u , u
u
step-clause-u(j, fi1
j

i1 j1 = ti ; vj = f ti
step-clause-u(j, f tui , tui ) = hvj = f tui , uj = ti ; vj = tui i.
u
Consider step DTG vj fi1
tui . original construction,
u , tu ), requires u
done single operator step-clause-u(j, fi1
j1 uj

u
value ti . modified construction instead requires two steps, first step fi1
u
u
new intermediate value f ti step value ti . previous
conjunctive constraint uj1 = uj = ti replaced sequential constraint first
uj1 = ti uj = ti . Although technically possible uj1 moved
new value second step taken, matter; uj1 uj must
still choose exactly path respective DTGs.
Corollary 8. PlanExist(F1 ), PlanExist(F0 ) PlanExist(F) NP-hard.
Proof. Neither two outer source vertices, u0 um , necessary construction
previous proof. Hence, omitting either reduction works also
F1 F0 . Finally, PlanExist(F) NP-hard since F+1 F.
basic results necessary main theorems following
two sections.

5. Graph Classes Closure Properties
Like results literature, results previous section classes
consisting particular graph type, like class Sin in-stars class F
fences. section depart instead study graph classes certain
closure properties. first discuss standard concepts subgraph closure minor
closure, finding first contain graphs need latter results
590

fiA Refined View Causal Graphs Component Sizes

set many graphs. reason, define new concept, SP-closure,
incomparable subgraph closure subset minor closure.
show closure concept defines borderline non-NP-hard graph classes
large number useful NP-hard classes.
5.1 Subgraph Closure Minor Closure
Suppose C class graphs closed taking subgraphs. every graph
G C case every subgraph H G must also C. Subgraph closure
sufficient purposes, though. instance, subgraph polypath always
either polypath graph every weakly connected component polypath.
However, polypath need subgraphs fences trivial size.
need closure property guarantees C contains polypath sinks,
also contains fence sinks. obvious candidate concept
minor-closure, superset subgraph-closure. concepts graph minors
minor-closure rapidly evolved important useful research area
mathematical well computational graph theory (Lovasz, 2005; Mohar, 2006).
order define graph minors first need concept edge contraction,
commonly defined follows, although definitions occur literature.
Definition 9. Let G = (V, E) directed graph let e = (u, v) E edge
u 6= v. contraction e G results new graph G0 = (V 0 , E 0 ),
V 0 = (V \ {u, v}) {w}
E 0 = {(f (x), f (y)) | (x, y) E, (x, y) 6= (u, v) (x, y) 6= (v, u)},
w new vertex, V , function f : V V 0 defined
f (u) = f (v) = w otherwise f (x) = x.
is, edge (u, v) contracted, two vertices u v replaced
single new vertex w edges previously incident either u v
redirected incident w. Figure 5 shows example edge contraction. say
graph H contraction another graph G H result contracting zero
edges G.
concept graph minors defined follows.
Definition 10. directed graph H minor directed graph G H isomorphic
graph obtained zero edge contractions subgraph G.
example illustrated Figure 6. graph G figure weakly connected
directed graph, also happens polypath. vertex v9 removed G,
restriction remaining vertices still weakly connected graph
subgraph G. Removing also v4 results graph H, consists two weakly
connected components H1 H2 . H, H1 H2 subgraphs G,
also minors G, since subgraph minor, definition. Contracting edge (v1 , v2 )
H1 results graph M1 , w1 new vertex replacing v1 v2 . Similarly,
contracting edge (v8 , v7 ) H2 results M2 . graph M1 minor G since
591

fiBackstrom & Jonsson

v9

v9
v10

v8

v10
v8

v2
v7

v5

v7

v1

v6

v5

w

v6

v3

v4

a) graph G

v3

v4

b) result contracting edge (v1 , v2 ) G.

Figure 5: Edge contraction.

result edge contraction subgraph H1 G graph M2 analogously
minor G too. Also graph , consisting two components M1 M2
minor G, since result two contractions subgraph H G.
graphs H, H1 H2 subgraphs minors G, graphs , M1 M2
minors G, subgraphs.

v6
v3
v2

v5
v4

v6
v7

v3
v8

v1

a) polypath

v7

v2
v9

G

v5

v3
v8

w1

v5
M1

v1
H1

v6
w2
M2

H2

b) subgraph H G
(where H = H1 H2 )

c) minor G
(where = M1 M2 )

Figure 6: Subgraphs minors.

trivial example minor-closed class class graphs, minor-closed
since contains graphs every minor graph graph. interestingly,
many commonly studied graph types result minor-closed classes. instance, class
Sin in-stars minor-closed, class Sout out-stars class dP
592

fiA Refined View Causal Graphs Component Sizes

directed paths. Furthermore, weakly connected minor polypath polypath
weakly connected minor polytree polytree. illustration, consider
Figure 6. graph G polypath, weakly connected graphs H1 , H2 , M1
M2 minors G, also polypaths. fact, M1 M2 also fences.
Note though, neither H polypath, since consist one
weakly connected component. worth noting, however, class F fences
minor-closed although every fence polypath; weakly connected minor fence
must polypath, necessarily fence.
Requiring minor-closed graph classes is, however, overly strong. instance, would
sufficient require every graph G C, also every weakly connected minor G
C. is, example Figure 6 would require H1 , H2 , M1 M2
C G C, would require also H C.
reasonable desirable context causal graphs. causal graph planning
instance consists two weakly connected components, components
correspond entirely independent subinstances solved separately.
Furthermore, certain natural restrictions mix well minor-closed classes.
Consider, instance, example Figure 7, acyclic graph G = (V, E),
V = {v1 , v2 , v3 , v4 } E = {(v1 , v2 ), (v2 , v3 ), (v3 , v4 ), (v1 , v4 )}. contract edge
(v1 , v4 ) new vertex w get cycle graph vertices w, v2 , v3 . is, class
acyclic graphs minor-closed general, problematic considering importance acyclic causal graphs.

v1

v2

v4

v3

v2
w

a) acyclic graph G

v3
b) contraction (v1 , v4 ) G.

Figure 7: Contracting edge acyclic graph result cycle.

5.2 SP-Closed Graph Classes
order avoid problems acyclicity (and similar problems) avoid defining
special variants contraction minor concepts, instead identify set minimal
requirements closure must satisfy order imply NP-hardness PlanExist
problem. focus one set restrictions, defining concept refer
SP-closure (where SP denotes set closed stars polypaths).
Definition 11. Let G H two directed graphs. H SP-graph G H
weakly connected either following holds:
1. H in-star subgraph G,
593

fiBackstrom & Jonsson

2. H out-star subgraph G
3. H obtained zero contractions polypath G0 G0
subgraph G.
class C graphs SP-closed contains every SP-graph every graph G C.
SP-closure number interesting properties, including following:
Proposition 12. Let G H directed graphs let C class directed graphs.
1. G polypath, every SP-graph G polypath.
2. Every SP-graph G acyclic.
3. H SP-graph G, H minor G.
4. C minor-closed, C SP-closed.
Proof. 1) Suppose G polypath. Obviously, G cannot contain in-star out-star
higher degree two, star also polypath. Hence, need
consider third case definition. note weakly connected subgraph G0
G must also polypath, contractions polypath results polypath.
2) Immediate since in-stars, out-stars polypaths acyclic contracting edges
cannot introduce cycle cases.
3) Immediate definitions minors SP-graphs.
4) Immediate 3.
proposition says makes sense talk SP-closed classes polypaths
SP-closed classes acyclic graphs. also says SP-closure minor-closure
comparable concepts; SP-closure class subset minor-closure
class.
prove following result SP-closed classes polypaths,
need main theorem.
Lemma 13. Let C SP-closed class polypaths. cc-size(C) unbounded,
PlanExist(C) NP-hard. result holds even restricted operators
2 preconditions 1 postcondition.
Proof. Proof cases depending whether directed path length C bounded not.
Case 1: Suppose path-length(C) unbounded. Let n > 1 arbitrary integer.
must graph G C G contains subgraph H directed
path graph V (H) = n. Obviously, H SP graph G, since directed path
also polypath. follows H C since C SP-closed. Furthermore, H ' dPn
NP-hardness PlanExist(C) follows Lemma 6, since n choosen arbitrarily.
Case 2: Instead suppose path-length(C) k constant k 0. Let n > 1
arbitrary integer. Since graphs C polypaths cc-size(C) unbounded,
must polypath G C V (G) n. thus follows assumption
Proposition 1 G must least sinks + 1 sources,
594

fiA Refined View Causal Graphs Component Sizes

V (G) 2mk + 1. must, thus, subgraph G0 G polypath
exactly sinks + 1 sources (i.e. G0 weakly connected) must, thus, also
+1 .
graph H obtained zero contractions G0 H ' Fm
follows H C since C SP-closed. NP-hardness PlanExist(C) thus follows
Lemma 7, since n choosen arbitrarily k constant.
see result holds even operators consideration 2
preconditions 1 postcondition, simply note restriction holds reductions
used underlying NP-hardness proofs Section 4.
Chen Gimenez (2010, Thm. 3.19) proved similar result: C class polypaths2
unbounded components unbounded number sources, PlanExist(C)
polynomial-time solvable unless W[1] nu-FPT.
order prove main result section, also need Moore bound (Biggs,
1993, p. 180), stated follows: arbitrary connected undirected graph G,
maximum number vertices
|V (G)| 1 +

k1
X

(d 1)i ,

(1)

i=0

= deg(G) k = path-length(G).
prove additional restriction graph classes SPclosed, avoid NP-intermediate problems prove NP-hardness graph classes
unbounded components.
Theorem 14. Let C SP-closed class directed graphs. cc-size(C) unbounded,
PlanExist(C) NP-hard. result holds even restricted operators
2 preconditions 1 postcondition graphs C acyclic.
Proof. First suppose constant k in-deg(C) k, out-deg(C) k
upath-length(C) k. Consider arbitrary graph G C. Obviously, deg(U (G)) 2k
path-length(U (G)) k, P
follows Moore bound component U (G)

1 + 2k k1
i=0 (2k 1) vertices. However, since cc-size(G) = cc-size(U (G))
G choosen arbitrarily, follows cc-size(C) bounded. contradicts
assumption least one in-deg(C), out-deg(C) upath-length(C) unbounded.
remainder proof three (possibly overlapping) cases.
Case 1: Suppose in-deg(C) unbounded. Let n > 0 arbitrary integer.
must graph G C containing vertex indegree n more, must
also subgraph H G H ' Snin . Hence, H C since C SP-closed. thus
follows Lemma 4 PlanExist(C) NP-hard, since n choosen arbitrarily.
Case 2: Suppose out-deg(C) unbounded. case analogous previous
one, using Lemma 5 instead Lemma 4.
Case 3: Suppose upath-length(C) unbounded. Let n > 0 arbitrary integer.
must graph G C U (G) contains path length n,
must, thus, also subgraph H G H polypath length n. Obviously, H
2. Chen Gimenez use term source-sink configuration polypath.

595

fiBackstrom & Jonsson

SP-graph G (doing zero contractions) H C since C SP-closed. thus follows
Lemma 13 PlanExist(C) NP-hard, since n choosen arbitrarily.
see result holds even operators consideration 2
preconditions 1 postcondition, simply note restriction holds reductions
used underlying NP-hardness proofs Section 4. Similarly, acyclicity restriction
holds since result based in-stars, out-stars polypaths,
acyclic graphs.
theorem somewhat restricted one Chen Gimenez since
requires additional constraint C SP-closed. hand, demonstrates
SP-closure sufficient condition avoid graph classes PlanExist NPintermediate and, thus, sharpen result NP-hardness. noted, though,
exact characterization graph classes NP-hard PlanExist.
graph classes, SP-closure captures large number interesting
graph classes. instance, class acyclic graphs SP-closed (recall class
minor-closed), although every subclass SP-closed. opposite example,
non-empty class contain single acyclic graph cannot SP-closed.

6. Beyond SP-Closed Graph Classes
section divided three parts. first discuss previous results, well
similar NP-hardness results literature, problematic, motivates
us switch non-uniform complexity theory. second part contains number
preparatory results required main theorem third part.
6.1 NP-Hardness Enough
refer planning problem generic instances varying size, depending
one parameters. archetypical example blocks world, natural
parameter number blocks. particular encoding specified number
blocks, variables operators whatever inital state goal is.
is, fix encoding get planning frame n = (Vn , ) every number,
n, blocks. is, n instances n blocks thus function
n. instances (Vn , init, goal, ) n blocks instantiations n different
init goal components Vn components. instance thus
specified three unique parameters, n, init goal, first parameter,
n, affects size instance. Furthermore, causal graph instance depends
variables operators, means instantiations frame n
causal graph, denote CG(n ). class causal graphs blocks
world instances = {CG(1 ), CG(2 ), CG(3 ), . . .}, although 1 , 2 , 3 , . . .,
thus also D, differ depending encoding.
often possible analyse complexity particular generic planning problem.
Examples complexity blocks-world planning (Gupta & Nau, 1992)
complexity various problems International Planning Competitions (IPC)
(Helmert, 2003, 2006b). context article, though, rather interested
complexity class causal graphs corresponding generic problem,
596

fiA Refined View Causal Graphs Component Sizes

complexity specific problem itself. Suppose class causal graphs
happens subset class C graphs know PlanExist(C)
tractable. infer also PlanExist(D) tractable, thus also
generic planning problems causal graphs tractable. However, order
prove PlanExist(D) NP-hard (or hard complexity class) would
prove class C graphs PlanExist(C) NP-hard C
subset D. Finding class C may trivial, though.
One problem encoding large influence densely sparsely
causal graphs occur respect size. Consider, instance, blocks world encodings
multi-valued variables boolean variables respectively. typical encoding
multi-valued variables use one variable status hand two variables
block, one position block one flag whether block clear
not. is, encodings use 2n + 1 variables n-block frame. encoding
boolean variables, hand, typically represent block position
number boolean variables, one block block on. boolean
encoding thus use n2 + 1 variables n-block frame. contain graph
every odd number vertices first case, increasingly sparse second
case. class causal graphs generic planning problem will, thus, typically
SP-closed, even closed taking subsets. Furthermore, since typically
contain member every possible number vertices, cannot possibly contain
known NP-hard sets Sin , Sout , dP etc. subset. Hence, order prove
class causal graphs hard NP (or complexity class), often
necessary make dedicated proof D. often doable, however. generic
planning problem corresponding function f takes parameter value n, e.g.
number blocks blocks world, f (n) = n . f furthermore polynomialtime computable value n, often case, also corresponding
causal graph, CG(n ), polynomial-time computable. However, even done
many generic planning problems, specific proof every specific encoding
every particular generic planning problem. holds particular classes causal
graphs; every specific class typically require dedicated proof.
order get around problems able prove general result
depend specific planning problems causal graphs, switch nonuniform complexity. makes possible prove powerful results, retaining
natural connections ordinary complexity classes. basic vehicle proving nonuniform complexity results advice-taking Turing machine, defined follows.
Definition 15. advice-taking Turing machine associated sequence advice
strings A0 , A1 , A2 , . . ., special advice tape advice function A, natural
numbers advice sequence, s.t. A(n) = . input x advice tape immediately
loaded A(||x||). continues like ordinary Turing machine, except
also access advice written advice tape.
exists polynomial p s.t. ||A(n)|| p(n), n > 0, said use
polynomial advice. complexity class P/poly set decision problems
solved advice-taking TM runs polynomial time using polynomial advice.
597

fiBackstrom & Jonsson

Note advice depends size input, content, need
even computable. Somewhat simplistically, advice-taking Turing machine
machine infinite data-base constant access time. However, input
size polynomial amount information might exponential
number instances sharing information. power polynomial advice thus still
somewhat limited useful relationships known non-uniform complexity
classes relate standard ones known. One result following.
Theorem 16. (Karp & Lipton, 1980, Thm. 6.1) NP P/poly, polynomial
hierarchy collapses second level.
6.2 Preparatory Results
carrying main theorem section, need auxiliary results.
first show planning instance causal graph G subgraph graph
H, instance extended equivalent instance H causal graph.
Lemma 17. Let planning instance let G directed graph CG()
subgraph G. planning instance G
G constructed polynomial time,
CG(G ) = G
G solution solution.
Furthermore, G maximum number pre- postconditions operators
(or one value zero ).
Proof. Let = (V, init, goal, A) planning instance let CG() = (V, E). Let
G = (VG , EG ) directed graph CG() subgraph G. Let U = VG \ V .
Construct planning instance G = (VG , initG , goalG , AG ) follows:
DG (u) = {0, 1}, u U ,
DG (v) = D(v) {?}, v V , (where ? new value D(v)).
initG (v) = init(v), v V ,
initG (u) = 0, u U .
goalG (v) = goal(v), v V ,
goalG (u) undefined u U .
Let AG consist following operators:
Let AG contain A.
edge (x, v) EG \ E x VG v V , let AG also contain
operator star(x, v) = hx = 0 ; v = ?i.
edge (x, u) EG x VG u U , let AG also contain
operator set(x, u) = hx = init(x) ; u = 1i.
598

fiA Refined View Causal Graphs Component Sizes

Obviously G constructed polynomial time CG(G ) = G, remains
prove G solution solution.
Suppose P = a1 , . . . , plan . P also plan G since goalG (u)
undefined u U a1 , . . . , AG . contrary, suppose P = a1 , . . . ,
plan G . operator ai P , three cases: (1) ai A, (2) ai set
operator (3) ai star operator. case 2, operator ai serves purpose since
modifies variable U , undefined goal value. case 3, operator ai sets
variable v V ? effect variables. goalG (v) undefined,
ai serves purpose. Otherwise must operator aj , j > i, aj
change v ? value D(v), i.e. ai serves purpose case either.
follows operator sequence P 0 obtained P removing operators
also plan G . Furthermore, since P 0 contains operators
also plan . follows plan G plan.
construction increases maximum domain size one little effect
maximum number pre- postconditions. suitable purpose, since
consider influence domain sizes article. constructions
possible want balance various factors differently.
proof forthcoming theorem also opposite taking graph
minors, is, starting minor G target graph H extend G H.
order so, need operation similar opposite edge contraction.
satisfied graph operation known edge subdivision.
Definition 18. Let G = (V, E) directed graph let (u, v) E edge
u 6= v. subdivision (u, v) G graph G0 = (V {w}, E 0 ) w new
vertex E 0 = (E \ {(u, v)}) {(u, w), (w, v)}.
Although one might consider definitions, e.g. case (u, v)
(v, u) E, one sufficient purpose follows usual extension
directed graphs (cf., Kuhn, Osthus, & Young, 2008). Usually operation called smoothing
considered inverse edge subdivision. However, smoothing viewed
restricted case edge contraction, reasonable think edge subdivision sort
inverse edge contraction. example edge subdivision illustrated Figure 8.
note like edge contraction polypath polypath, also edge
subdivision polypath polypath.
also need operation planning instances corresponding edge subdivision
causal graphs. purpose, need concept variable substitution
operators. denote substitution variable w variable v partial state
a[v/w], defined as:

x = w,
s(v),
s(x),
x vars(s) \ {v, w},
s[v/w](x) =

undefined, otherwise.
operator, operator a0 = a[v/w] defined pre(a0 ) = pre(a)[v/w]
post(a0 ) = post(a)[v/w].
599

fiBackstrom & Jonsson

v9

v9
v10

v8

v10
v8

v2
v7

v5

v7

v1

v6
v3

a) graph G

v2

v6
v4

w

v5

v1
v3

v4

b) result subdividing edge (v1 , v2 ) G.

Figure 8: Edge subdivision.

necessary concepts modifying arbitrary planning instance
result corresponds subdividing edge causal graph instance.
However, need instances causal graph polypath.
proving done, first need following lemma, states
certain reordering property plans causal graph polypath. choose
arbitrary vertex v polypath G remove v G, G falls apart two weakly
connected components C1 C2 . words, vertices G partitioned
three sets C0 , C1 C2 C0 = {v} edge directly
vertex C1 vertex C2 . follows definition causal graphs
operator changes variable C1 precondition variable
C2 vice versa. following lemma utilises fact prove sequence
operators change variable v reordered operators
change variables C1 come operators change variables C2 .
Lemma 19. Let = (V, init, goal, A) planning instance G = CG()
polypath. Let v arbitrary variable V , let C0 = {v} let C1 , C2 V two
(possibly empty) weakly connected components G result vertex v removed
G. Define Ai = {a | vars(post(a)) Ci } (0 2). Let P plan .
Let P1 , P2 Q operator sequences P = P1 , Q, P2 Q contains operator
A0 . Let Q1 subsequence Q containing operators A1 let Q2
subsequence Q containing operators A2 . P1 , Q1 , Q2 , P2 plan
.
Proof. Assume C0 , C1 C2 defined lemma recall C0 = {v}. First
note G acyclic since polypath, operators unary. follows
{A0 , A1 , A2 } partition and, thus, A0 A1 A2 = A. Let s0 = init[P1 ].
Obviously, (vars(pre(a))C2 = (vars(post(a))C2 = Q1 (vars(pre(a))C1 =
(vars(post(a)) C1 = Q2 , i.e. state holds s[a] C2 = C2
Q1 s[a] C1 = C1 Q2 . Furthermore, state holds
600

fiA Refined View Causal Graphs Component Sizes

s[a](v) = s(v) Q, since 6 A0 . follows s0 [Q] C1 = s0 [Q1 ] C1
s0 [Q] C2 = s0 [Q2 ] C2 . Hence,
s0 [Q1 , Q2 ] C0 = s0 [Q] C0 ,
s0 [Q1 , Q2 ] C1 = s0 [Q1 ] C1 = s0 [Q] C1
s0 [Q1 , Q2 ] C2 = s0 [Q2 ] C2 = s0 [Q] C2 .
is, s0 [Q1 , Q2 ] = s0 [Q] follows also P1 , Q1 , Q2 , P2 plan .
prove planning instance CG() polypath,
subdivide edge CG() create planning instance 0 CG(0 )
subdivision CG() 0 solvable solvable.
Lemma 20. Let planning instance CG() polypath let e
edge CG(). planning instance 0
0 constructed polynomial time,
CG(0 ) edge subdivision e CG()
0 solution solution.
Proof. Let = (V, init, goal, A) planning instance CG() polypath
let e = (u, v) edge CG(). Construct new instance 0 = (V 0 , init0 , goal0 , A0 )
follows:
V 0 = V {w}, D(w) = D(u) w 6 V .
init0 (v) = init(v), v V ,
init0 (w) = init(u).
goal0 = goal.
Let A0 consist following groups operators:
1. Let A0 contain operators u 6 vars(pre(a)) v 6 vars(post(a)).
2. Let A0 contain operator a[u/w] every operator
u vars(pre(a)) v vars(post(a)).
3. Let A0 contain operator copy(u, w, x) = hu = x ; w = xi every value
x D(v).
operators group 1 original operators corresponding edges
CG() except (u, v). operators group 2 operators corresponding
edge (u, v) modified instead correspond new edge (w, v). operators
group 3 correspond new edge (u, w) defined variable w
mimic variable u. Clearly, polynomial-time construction CG(0 ) edge
subdivision CG(). remains prove 0 plan plan.
If: Suppose P = a1 , . . . , plan . Construct new operator sequence P 0
A0 P follows: First, ai P u vars(pre(ai )) v
vars(post(ai )), replace ai ai [u/w]. Then, ai P u vars(post(ai )),
601

fiBackstrom & Jonsson

let x = post(ai )(u) add operator copy(u, w, x) ai ai+1 . resulting
sequence P 0 plan 0 .
if: Suppose P = a1 , . . . , plan 0 . Define corresponding state sequence
s0 , . . . , sn s0 = init0 si = s0 [a1 , . . . , ai ] (1 n). Without losing
generality, assume P shortest plan 0 , implies ai applicable
si1 every (1 n). Define three variable sets C0 , C1 C2 Lemma 19
C0 = {w}, v C1 u C2 . Also define corrsponding partition {A0 , A1 , A2 }
A0 , i.e. Ai = {a A0 | vars(post(a)) Ci } (0 2). A0 contains copy
operators nothing else. proving main result direction, first prove
following auxiliary result:
According Lemma 19 assume every longest subsequence ak , . . . , a`
contain operator A0 form ak , . . . , , am+1 , . . . , a`
ak , . . . , A1 am+1 , . . . , a` A2 . Since longest sequence, must
hold either (1) k = 1 (2) ak1 A0 . case (1) sk1 = s0 = init0 ,
sk1 (u) = sk1 (w) since init0 (u) = init0 (w). case (2) operator ak1 = copy(u, w, x)
x sk1 (w) = sk2 (u) = x. Hence, sk1 (u) = sk1 (w) = x since ak1
change u. is, either case sk1 (u) = sk1 (w). Furthermore,
(k m) holds si (C0 C2 ) = sk1 (C0 C2 ) since ai A1 . follows
si (u) = si (w) (k m). Now, every (k `), w vars(pre(ai ))
ai must form a[u/w], A, v vars(pre(ai )) definition. Hence,
ai A1 follows si1 (u) = si1 (w). Since proof holds longest
subsequences containing operator A0 conclude following,
used below:
(*) operator ai P ai = a[u/w] A, holds
si1 (u) = si1 (w).
prove main result direction, also plan since 0
plan. constructing plan P 00 P two steps. First construct
intermediate operator sequence P 0 construct plan P 00 P 0 . sequence
P 0 technically plan either 0 , intermediate step makes proof
clearer. Temporarily introduce virtual dummy operator dum precondition
postcondition, i.e. applicable state effect. construct
new operator sequence P 0 = b1 , . . . , bn {dum} follows:
ai A, bi = ai .
ai copy operator, bi = dum.
Otherwise, ai = a[u/w] operator A, let bi operator a.
Define corresponding state sequence t0 , . . . , tn t0 = init0 ti = t0 [b1 , . . . , bi ]
(1 n). claim ti V = si V (0 n). Proof induction
i:
Basis: t0 = s0 definition.
Induction: Suppose ti1 V = si1 V (1 n). three cases:
(1) ai = bi ai A. w pre- postcondition either ai bi
bi applicable ti1 since ai applicable si1 ti1 V = si1 V assumption.
Furthermore, ti V = ti1 [bi ] V = si1 [ai ] V = si V .
602

fiA Refined View Causal Graphs Component Sizes

(2) ai copy operator bi = dum. immediate definition bi
applicable ti1 ti = ti1 . Furthermore, vars(post(ai )) V =
si V = si1 V . Since ti1 V = si1 V assumption thus follows ti V = si V .
(3) ai bi [u/w] bi A. follows (*) si1 (w) = si1 (u), si1 (w) =
ti1 (u) since u V ti1 V = si1 V assumption. Since ai applicable si1 ,
pre(ai )(w) = pre(bi )(u) pre(ai )(x) = pre(bi )(x) variables V \{u}, follows
bi applicable ti1 . definition, vars(post(bi )) = vars(post(ai )) = {v}, since ai
bi must unary, thus also follows definition post(bi ) = post(ai ).
Hence, also follows ti V = si V , since ti1 V = si1 V assumption.
thus shown ti V = si V (0 n). Furthermore, clearly
ti = ti1 bi = dum. follows create plan P 00
removing dummy operators P 0 .
conclude solution 0 solution.
finally need following observations 3SAT instances. Let F 3SAT
formula n variables clauses. contains repeated clauses,

n
8n3 and, thus, ( )1/3 n 3m.
3
8
Furthermore, F represented list 3m literals requires 3m(1 + log n)
3m(1 + log 3m) bits, plus overhead. Hence, F represented cm2 bits,
constant c, later use upper bound 40m3 , safe.
also note reduction used proof Lemma 6 transforms 3SAT
instance n variables clauses planning instance N = (2m + 4)n
variables. However, n 3m N (2m + 4) 3m = 6m2 + 12m, safely
overestimated N 18m2 .
6.3 Main Theorem
prepared state prove main theorem section. follows
proof Theorem 14 in-deg(C), out-deg(C) upath-length(C) bounded
class C graphs, cc-size(C) bounded. case immediate Theorem 3
planning tractable C. begs question happens parameters
bounded constant, yet bounded slow-growing function? consider
case allowed grow slowly, long polynomially related
instance size. Since also noted practical planning problems typically
causal graph every size, require every graph G C
must also larger graph G0 C size p(|G|), polynomial p.
also define parameter (G) = max{upath-length(G), in-deg(G), out-deg(G)}, require
(G) ||G|| polynomially related. turns planning still hard
restrictions, following theorem says.
Theorem 21. Let p q increasing polynomials natural numbers. Let C
class directed graphs containing subset weakly connected graphs G1 , G2 , G3 , . . .
that:
1. |V (G1 )| p(q(1)),
|V (Gi1 )| < |V (Gi )| p(|V (Gi1 )|), > 1,
603

fiBackstrom & Jonsson

2. |V (Gi )| q( (Gi )), 1.
PlanExist(C) polynomial-time solvable, polynomial hierarchy collapses. result holds even restricted operators 2 preconditions 1 postcondition
graphs C acyclic.
Proof. Let G1 , G2 , G3 , . . . sequence weakly connected graphs C assumed
theorem. Let H1 , H2 , H3 , . . . sequence graphs defined follows: > 0,
Hi = Gj smallest j q(i) |V (Gj )|.
first prove underestimates (Hi ). Combining requirement q(i)
|V (Gj )| condition 2 theorem, |V (Gj )| q( (Gj )), get q(i) |V (Gj )|
q( (Gj )). Since Hi = Gj get q(i) |V (Hi )| q( (Hi )), is, (Hi ).
follows also |V (Hi )| holds.
prove |V (Hi )| polynomially bounded p(q(i)). Since j choosen
smallest value satisfying q(i) |V (Gj )|, must either j = 1 |V (Gj1 )| <
q(i). j = 1, Hi = Gj = G1 |V (G1 )| p(q(1)) condition 1 theorem.
Hence, |V (Hi )| = |V (G1 )| p(q(1)) p(q(i)), since p q increasing. Otherwise,
j > 1, condition 1 lemma says |V (Gj )| p(|V (Gj1 )|). Combining
inequality |V (Gj1 )| < q(i) yields |V (Gj )| p(|V (Gj1 )|) < p(q(i)),
is, |V (Hi )| p(q(i)) since Hi = Gj . Combining previous result
|V (Hi )| construction Hi yields H1 , H2 , H3 sequence graphs
non-decreasing unbounded size.
Now, define sequence A0 , A1 , A2 , . . . tuples 0, either
following holds:
1. in-deg(Hi ) Ai = (in-deg, Hi , Xi ) Xi subgraph Hi Xi ' Siin .
2. out-deg(Hi ) Ai = (out-deg, Hi , Xi ) Xi subgraph Hi
Xi ' Siout .
3. upath-length(Hi ) Ai = (upath-length, Hi , Xi ) Xi subgraph Hi
Xi polypath length i.
every > 0, least one three cases must hold since (Hi ).
Define advice-taking Turing machine uses sequence A1 , A2 , A3 , . . .
advice takes 3SAT formulae input. Assume representation formula
F padded size 40m3 bits, number clauses. Although somewhat
redundant, still reasonable encoding sense Garey Johnson (1979).
Let work follows. Let F input formula n variables clauses
let = ||F || = 40m3 . advice = (x, Ht , Xt ). First constructs planning
instance F . three cases depending x:
x = in-deg: construction, Xt subgraph Ht Ht ' Stin . Since = 40m3
n 3m, follows n t, Xt contains subgraph H 0 H 0 ' Snin .
Construct F way proof Lemma 4, using vertices H 0
variables. Then, CG(F ) = H 0 .
x = out-deg: Analogous previous case, constructing F according proof
Lemma 5 instead.
604

fiA Refined View Causal Graphs Component Sizes

x = upath-length: construction, Xt subgraph Ht polypath length
= 40m3 . Suppose Xt contains less sinks + 1 sources
path-length(Xt ) < 18m2 . follows Proposition 1
|V (Xt )| < 2m 18m2 + 1 = 36m3 + 1 < 40m3 = t.
However, contradicts construction Xt must either contain directed path
length 18m2 least sinks + 1 sources.
1. Xt contains subgraph H 0 directed path length 18m2 ,
construct planning instance F according proof Lemma 6, using
vertices H 0 variables. Then, CG(F ) ' H 0 .
2. Xt contains subgraph H 0 polypath sinks m+1 sources,
construct planning instance
F according proof Lemma 7, us0
+1
ing variables H variables. Then, CG(
F ) ' Fm . graph
fence, i.e. polypath directed paths length 1. path
stretched directed path arbitrary length repeatedly applying
Lemma 20. graph H 0 polypath used template
paths CG(
F ) stretch much order get graph
0
isomorphic H . Instance
F thus modified new instance F
CG(F ) ' H 0 .
constructions done polynomial time, cases, F
solution F satisfiable. Furthermore, CG(F ) isomorphic subgraph
Ht four cases. According Lemma 17 thus possible extend F new
+
+
planning instance +
F CG(F ) ' Ht F solution
solution. extension done polynomial time according lemma.
Since PlanExist(C) solved polynomial time assumption theorem,
thus follows solve 3SAT polynomial time. However, implies
NP P/poly, impossible unless polynomial hierarchy collapses (Theorem 16).
see result holds even operators consideration 2
preconditions 1 postcondition, simply note restriction holds reductions
used underlying NP-hardness proofs Section 4. Similarly, acyclicity restriction
holds since result based in-stars, out-stars polypaths,
acyclic graphs.
Recall generic blocks world encoding discussed beginning
section. class causal graphs blocks-world instances satisfies requirements Theorem 21, means PlanExist(D) likely tractable. However,
finding non-optimal plans blocks world tractable; plan length twice
length optimal plan found polynomial time (Gupta & Nau, 1992). is,
likely difficult problems blocks world happen exactly
causal graphs, illustrates complexity generic planning problem
cannot deduced corresponding class causal graphs alone.
605

fiBackstrom & Jonsson

7. NP-Hard NP-Intermediate Classes
theorem Chen Gimenez (2010) states crisp complexity-theoretic borderline:
component sizes bounded constant, planning polynomial-time solvable
and, otherwise, planning polynomial-time solvable. exploited extra
constraint, SP-closure, able prove NP-hardness, leaves greyzone
polynomial cases NP-hard ones. longer require classes SPclosed, longer obviously NP-hard even components unbounded.
natural question arises, say something middle ground?
instance, say something NP-intermediate cases may look like
borderline NP-hard NP-intermediate is? Although seem
likely could find results characterize borderline exactly,
least give partial answers questions. proving two theorems
related growth rate components. first shows planning still
NP-hard components grow O(|V (G)|1/k ) integers k, second one shows
planning likely NP-intermediate components grow polylogarithmically.
Theorem 22. every constant integer k > 1, class Gk graphs
cc-size(G) |V (G)|1/k G Gk PlanExist(Gk ) NP-hard.
Proof. Let k > 1 arbitrary integer. Construct graph class Gk = {G1 , G2 , G3 , . . .}
follows. > 0, let Gm mk1 components, isomorphic dPm ,
i.e. |V (Gm )| = mk components size = |V (Gm )|1/k . prove NP-hardness
PlanExist(Gk ) reduction PlanExist(dP). Let arbitrary planning instance
CG() dP. CG() = dPm > 0. Construct new instance 0
consists mk1 renamed copies . clearly polynomial time construction
since k constant < ||||. Furthermore, CG(0 ) isomorphic Gm 0
solution solution. Hence, polynomial reduction follows
Lemma 6 PlanExist(Gk ) NP-hard.
Obviously, size graphs exponential k.
second result must conditioned assumption exponential time
hypothesis (Impagliazzo & Paturi, 2001; Impagliazzo, Paturi, & Zane, 2001) holds.
hypothesis conjecture stated follows.
Definition 23. constant integers k > 2, let sk infimum real numbers
k-SAT solved O(2n ) time, n number variables
instance. exponential time hypothesis (ETH) conjecture sk > 0 k > 2.
Informally, ETH says satisfiability cannot solved subexponential time. ETH
arbitrarily choosen concept, quite strong assumption allows
defining theory similar one NP-completeness. concept called SERF
(subexponential reduction family) reduction preserves subexponential time solvability. also concept called SERF-completeness similar NP-completeness,
based SERF reductions. is, subclass NP-complete problems
also SERF-complete, meaning SERF reduced other.
Hence, one solved subexponential time, can.
606

fiA Refined View Causal Graphs Component Sizes

Theorem 24. constant integers k > 0 classes C directed graphs,
cc-size(G) logk |V (G)| G C, PlanExist(C) NP-hard unless ETH
false.
Proof. Let k > 0 arbitrary integer. Let arbitrary planning instance n
variables maximum domain size cc-size(CG()) c. components correspond independent subinstances, thus solved separately. component
state space size dc less, plan corresponding subinstance found
O(d2c ) time, using Dijkstras algorithm. Since n components, whole
instance solved O(nd2c ) time. However, follows standard assumptions
reasonable encodings n |||| ||||, looser bound
solved O(x x2c ) = O(x1+2c ) time, x = ||||.
Suppose PlanExist(C) NP-hard. polynomial reduction 3SAT
PlanExist(C). Furthermore, size 3SAT instance polynomially bounded
number variables. Hence, must polynomial p 3SAT instance
n variables, corresponding planning instance size |||| p(n).
Since number variables upper bounded ||||, follows assumption component size upper bounded logk |||| logk p(n). Hence,
k
solved O(p(n)1+2 log p(n) ) time, according earlier observation,
p(n)1+2 log

k

p(n)

= (2log p(n) )1+2 log

k

p(n)

(2(1+2 log

k

p(n)) logk p(n)

) 23 log

2k

2k

p(n)

.

2k

Furthermore, logk p(n) O(logk n), since p polynomial, 23 log p(n) 2O(log n)
2k
follows solved 2O(log n) time. However, solved 2n
time arbitrarily small , contradicts ETH. follows PlanExist(C) cannot
NP-hard unless ETH false.
Since components unbounded, problem likely solvable polynomial
time either. thus NP-intermediate problem double assumption
W[1] 6 nu-FPT ETH holds.
Theorems 22 24 together thus tell us something borderline
NP-intermediate NP-hard graph classes is. However, crisp distinction;
asymptotically, quite gap polylogarithmic functions root
functions (i.e. functions form x1/k ). One may, instance, note function
1

f (n) = 2(log n)

1
(log log n)c

lies within gap whenever 0 < c < 1.

8. Discussion
SP-closed graph classes appealing properties fit well concept stronger
subgraph-closed weaker minor-closed. also give partial characterization
borderline NP-hardness lies. However, noted earlier, possible define
types graph classes also imply planning NP-hard. One example
family G1 , G2 , G3 , . . . classes proof Theorem 22. Another specialized
and, perhaps, contrived class following, intended give contrast SP-closure
concept Gk classes.
607

fiBackstrom & Jonsson

tournament directed graph formed giving directions edge complete
graph. Let denote set tournaments note SP-closed. However,
tournaments Hamiltonian graphs (Redei, 1934) tournament n vertices,
path-length(T ) = n 1. Furthermore, path length n 1 computed
polynomial time (Bar-Noy & Naor, 1990).
Assume given 3SAT formula F n variables clauses. Let ` =
(2m + 4)n, i.e. ` polynomially bounded F . According Lemma 6 thus
construct planning instance F polynomial time
1. F contains ` variables,
2. CG(F ) ' dP` ,
3. F solution F satisfiable.
Choose arbitrary tournament ` vertices T. Find path length `1
identify CG(F ). add dummy operators corresponding remaining
edges . thus shown polynomial-time transformation 3SAT
PlanExist(T), PlanExist(T) NP-hard. One may also note variations
technique used proving PlanExist(T0 ) NP-hard many different
T0 T.
considered domain sizes tractable restrictions article,
note Theorem 24 may give ideas look tractable cases. Consider
case variable domains bounded size constant k
cc-size(G) log V (G). Using first part proof, see planning solved
O(n k 2 log n ) time. However, k 2 log n = (2log k )2 log n = (2log n )2 log k = n2 log k ,
polynomial since k constant. is, planning tractable restricted case. Even
though observation straightforward, interesting contrast Theorem 24.
also suggests even larger tractable subgraphs also consider additional
restrictions planning instances.
explicitly commented sufficient number pre- postconditions
various results, also alternative characterizations might relevant. would bear far list possibilities, let suffice one example.
concept prevail conditions, i.e. preconditions variables changed
operator, originate SAS+ formalism (Backstrom & Nebel, 1995)
recently considered also context causal graphs. Gimenez Jonsson (2012)
refer operator k-dependent precondition k variables
also change. may note proofs Lemmata 17 20 introduce
operators 1-dependent, most. Since proof Theorem 21 impose
restrictions original planning instance, follows theorem
holds also operators 1-dependent, most.
final question, one might wonder practical use know
planning tractable, NP-intermediate, severely limited component sizes? all,
planning instances likely causal graph weakly connected,
is, whole graph one single component. answer question, first important
observation make complexity planning instances directly related
complexity planning components separately.
608

fiA Refined View Causal Graphs Component Sizes

linearly (in number variables) many components. planning solved
polynomial time components instance, solved polynomial time
whole instance. Conversely, planning cannot solved polynomial time
whole instance, least one component polynomial-time solvable.
is, complexity results instances components directly related
other. words, results relevant methods artificially split causal
graph components, one way another. Examples causal-graph heuristic
Helmert (2006a), factored planning (Brafman & Domshlak, 2006) structural pattern
data bases (Katz & Domshlak, 2010).

Acknowledgments
anonymous reviewers provided valuable comments suggestions improving
article.

References
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11, 625656.
Bar-Noy, A., & Naor, J. (1990). Sorting, minimal feedback sets, Hamilton paths
tournaments. SIAM Journal Discrete Mathematics, 3 (1), 720.
Biggs, N. (1993). Algebraic Graph Theory. Cambridge Univ. Press. 2nd ed.
Bodirsky, M., & Grohe, M. (2008). Non-dichotomies constraint satisfaction complexity.
Proceedings 35th International Colloquium Automata, Languages
Programming (ICALP 2008), Reykjavik, Iceland, pp. 184196.
Brafman, R. I., & Domshlak, C. (2003). Structure complexity planning unary
operators. Journal Artificial Intelligence Research, 18, 315349.
Brafman, R. I., & Domshlak, C. (2006). Factored planning: How, when, not.
Proceedings 21st National Conference Artificial Intelligence (AAAI 2006),
Boston, MA, USA, pp. 809814. AAAI Press.
Chen, H., & Gimenez, O. (2010). Causal graphs structurally restricted planning. Journal Computer Systems Science, 76 (7), 579592.
Domshlak, C., & Dinitz, Y. (2001a). Multi-agent off-line coordination: Structure complexity. Proceedings 6th European Conference Planning (ECP01), Toledo,
Spain.
Domshlak, C., & Dinitz, Y. (2001b). Multi-agent off-line coordination: Structure complexity. Tech. rep., Department Computer Science, Ben-Gurion University. CS-0104.
Downey, R. G., & Fellows, M. R. (1999). Parameterized Complexity. Monographs Computer Science. Springer, New York.
Flum, J., & Grohe, M. (2006). Parameterized Complexity Theory, Vol. XIV Texts
Theoretical Computer Science. EATCS Series. Springer, Berlin.
609

fiBackstrom & Jonsson

Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman, New York.
Gimenez, O., & Jonsson, A. (2008). complexity planning problems simple
causal graphs. Journal Artificial Intelligence Research, 31, 319351.
Gimenez, O., & Jonsson, A. (2009). Planning chain causal graphs variables
domains size 5 NP-hard. Journal Artificial Intelligence Research, 34, 675706.
Gimenez, O., & Jonsson, A. (2012). influence k-dependence complexity
planning. Artificial Intelligence, 177-179, 2545.
Gupta, N., & Nau, D. S. (1992). complexity blocks-world planning. Artificial
Intelligence, 56 (2-3), 223254.
Helmert, M. (2003). Complexity results standard benchmark domains planning.
Artificial Intelligence, 143 (2), 219262.
Helmert, M. (2004). planning heuristic based causal graph analysis. Proceedings
14th International Conference Automated Planning Scheduling (ICAPS
2004), Whistler, BC, Canada, pp. 161170. AAAI Press.
Helmert, M. (2006a). Fast Downward planning system. Journal Artificial Intelligence
Research, 26, 191246.
Helmert, M. (2006b). New complexity results classical planning benchmarks. Proceedings 16th International Conference Automated Planning Scheduling
(ICAPS 2006), Cumbria, UK, pp. 5262. AAAI Press.
Impagliazzo, R., & Paturi, R. (2001). complexity k-SAT. Journal Computer
System Science, 62 (2), 367375.
Impagliazzo, R., Paturi, R., & Zane, F. (2001). problems strongly exponential
complexity?. Journal Computer System Science, 63 (4), 512530.
Jonsson, A. (2009). role macros tractable planning. Journal Artificial Intelligence Research, 36, 471511.
Jonsson, P., & Backstrom, C. (1998a). State-variable planning structural restrictions:
Algorithms complexity. Artificial Intelligence, 100 (1-2), 125176.
Jonsson, P., & Backstrom, C. (1998b). Tractable plan existence imply tractable
plan generation. Annals Mathematics Artificial Intelligence, 22 (3-4), 281296.
Karp, R. M., & Lipton, R. J. (1980). connections nonuniform uniform complexity classes. Proceedings 12th ACM Symposium Theory
Computing (STOC80), Los Angeles, CA, USA, pp. 302309.
Katz, M., & Domshlak, C. (2007). Structural patterns tractable sequentially-optimal
planning. Proceedings 17th International Conference Automated Planning
Scheduling (ICAPS 2007), Providence, RI, USA, pp. 200207. AAAI Press.
Katz, M., & Domshlak, C. (2008). New islands tractability cost-optimal planning.
Journal Artificial Intelligence Research, 32, 203288.
Katz, M., & Domshlak, C. (2010). Implicit abstraction heuristics. Journal Artificial
Intelligence Research, 39, 51126.
610

fiA Refined View Causal Graphs Component Sizes

Katz, M., Hoffmann, J., & Domshlak, C. (2013). said need relax variables?. Proceedings 23rd International Conference Automated Planning
Scheduling (ICAPS 2013), Rome, Italy, 126134. AAAI Press.
Katz, M., & Keyder, E. (2012). Structural patterns beyond forks: Extending complexity
boundaries classical planning. Proceedings 26th AAAI Conference
Artificial Intelligence (AAAI 2012), Toronto, ON, Canada. AAAI Press.
Knoblock, C. A. (1994). Automatically generating abstractions planning. Artificial
Intelligence, 68 (2), 243302.
Kuhn, D., Osthus, D., & Young, A. (2008). note complete subdivisions digraphs
large outdegree. Journal Graph Theory, 57 (1), 16.
Ladner, R. E. (1975). structure polynomial time reducibility. Journal
ACM, 22 (1), 155171.
Lovasz, L. (2005). Graph minor theory. Bulletin AMS, 43 (1), 7586.
Mohar, B. (2006). ... graph minor. Notices AMS, 53 (3), 338339.
Redei, L. (1934). Ein kombinatorischer Satz. Acta Litteraria Szeged, 7, 3943.
Wehrle, M., & Helmert, M. (2009). causal graph revisited directed model checking.
Proceedings Static Analysis, 16th International Symposium (SAS09), Los
Angeles, CA, USA, Vol. 5673 LNCS, pp. 86101. Springer.
Williams, B., & Nayak, P. P. (1997). reactive planner model-based executive.
Proceedings 15th International Joint Conference Artificial Intelligence
(IJCAI97), Nagoya, Japan, pp. 11781185.

611

fiJournal Artificial Intelligence Research 47 (2013) 351-391

Submitted 03/13; published 06/13

Strong Equivalence Qualitative Optimization Problems
Wolfgang Faber

faber@mat.unical.it

Department Mathematics
University Calabria
Via P. Bucci cubo 30B, 87036 Rende, Italy

Miroslaw Truszczynski

mirek@cs.uky.edu

Department Computer Science
University Kentucky
329 Rose Street, Lexington, KY 40506-00633, USA

Stefan Woltran

woltran@dbai.tuwien.ac.at

Institute Information Systems
Vienna University Technology
Favoritenstrae 911, 1040 Vienna, Austria

Abstract
introduce framework qualitative optimization problems (or, simply, optimization problems) represent preference theories. formalism uses separate modules
describe space outcomes compared (the generator ) preferences outcomes (the selector ). consider two types optimization problems. differ
way generator, model propositional theory, interpreted: standard propositional logic semantics, equilibrium-model (answer-set) semantics.
latter interpretation generators, optimization problems directly generalize
answer-set optimization programs proposed previously. study strong equivalence
optimization problems, guarantees interchangeability within larger context. characterize several versions strong equivalence obtained restricting
class optimization problems used extensions establish complexity
associated reasoning tasks. Understanding strong equivalence essential modular
representation optimization problems rewriting techniques simplify without
changing inherent properties.

1. Introduction
introduce framework qualitative optimization problems which, following design answer-set optimization (ASO) programs (Brewka, Niemela, & Truszczynski, 2003),
use separate modules describe space outcomes compared (the generator )
preferences outcomes (the selector ). optimization problems consider, selector module follows syntax semantics preference modules
ASO programs, generator given propositional theory. propositional theory interpreted according standard propositional logic semantics, is,
outcomes compared classical models generator, speak classical optimization problems (CO problems, short). generator theory interpreted
semantics equilibrium models (Pearce, 1997), speak answer-set optimization
problems (ASO problems, short). use terminology, equilibrium models
c
2013
AI Access Foundation. rights reserved.

fiFaber, Truszczynski, & Woltran

usually referred answer sets (Ferraris, 2005) historical reasons. ASO problems,
answer sets generator outcomes used determine optimal outcomes.
Representing reasoning preferences qualitative settings important
research area knowledge representation qualitative decision theory. main objectives design expressive yet intuitive languages model preferences, develop automated methods reason formal representations preferences
languages. literature subject preferences vast. refer reader articles special issue Artificial Intelligence Magazine (Goldsmith & Junker, 2008)
recent monograph Kaci (2011) thorough discussion area
additional references.
Understanding optimization problems equivalent, particular, one
interchanged another within larger context, fundamental preference
formalism. Speaking informally, optimization problems P Q interchangeable
strongly equivalent every optimization problem R (context), P R QR define
optimal models. Understanding one optimization problem equivalent
another sense essential preference analysis, modular preference representation,
rewriting techniques simplify optimization problems forms amenable
processing, without changing inherent properties. Let us consider multi-agent
setting, agents combine preferences set alternatives goal
identifying optimal ones. one agent ensemble replaced another
set optimal alternatives unaffected now, also extension
ensemble future? Strong equivalence agents optimization problems precisely
needed guarantee full interchangeability property!
notion strong equivalence general interest, means restricted preference formalisms. cases, notably classical logic, coincides equivalence,
property models. However, semantics monotone, is,
extending theory may introduce new models eliminate some, strong equivalence
becomes strictly stronger concept, one adopt theories analyzed
placed within larger context. nonmonotonicity semantics salient feature
nonmonotonic logics (Marek & Truszczynski, 1993) strong equivalence theories
nonmonotonic logics, especially logic programming answer-set semantics (Gelfond
& Lifschitz, 1991), extensively studied setting (Lifschitz, Pearce, & Valverde,
2001; Turner, 2003; Eiter, Fink, & Woltran, 2007b). Preference formalisms also often
behave nonmonotonically adding new preference may cause non-optimal outcome
(model) become optimal one. Thus, preference formalisms, equivalence strong
equivalence typically different notions. Accordingly, strong equivalence studied
logic programs rule preferences (Faber & Konczak, 2006), programs ordered disjunction (Faber, Tompits, & Woltran, 2008) programs weak constraints (Eiter,
Faber, Fink, & Woltran, 2007a).
extend study strong equivalence formalism qualitative optimization
problems. formalism motivated design answer-set optimization (ASO) programs Brewka et al. (2003). borrows two key features ASO programs make
attractive alternative preference modeling approaches based logic programming
mentioned above. First, following ASO programs, optimization problems provide
clear separation hard constraints, specify space feasible outcomes,
352

fiStrong Equivalence Qualitative Optimization Problems

preferences (soft constraints) impose preference ordering feasible outcomes. Second, optimization problems adopt syntax semantics preference rules ASO
programs correspond closely linguistic patterns simple conditional preferences
used humans.
separation preference modules hard constraints facilitates eliciting representing preferences. also important characterizing strong equivalence.
clear separation present, like logic programs ordered disjunctions (Brewka,
Niemela, & Syrjanen, 2004), strong equivalence characterizations cumbersome
account complex mostly implicit interactions hard constraints
preferences. optimization problems, impose separation, onedimensional forms strong equivalence, hard constraints preferences
added. one-dimensional concepts easier study yet provide enough information construct characterizations general case.
Main Contributions.

main contribution summarized follows.

propose general framework qualitative optimization problems, extending
several ways formalism ASO programs. focus two important instantiations framework, classes classical optimization (CO) problems
answer-set optimization (ASO) problems. latter one directly generalizes ASO
programs.
identify problem strong equivalence theories general preference formalisms. point strong equivalence equivalence coincide (in
general) preference formalisms concept strong equivalence
fundamental issues theory modularity, rewriting simplification. Strong equivalence studied earlier context logic programs logic
programs extended preferences rules atoms heads rules (and
similarly motivated). However, best knowledge, first
paper studies strong equivalence typical preference formalism
represents preferences terms preferred properties (modeled formulas)
independently constraints defining outcomes compare. such,
relevance mainstream preference research previous studies.
characterize concept strong equivalence optimization problems relative
changing selector modules. characterization independent semantics
generators so, applies CO ASP problems. also characterize
strong equivalence relative changing generators (with preferences fixed).
case, surprisingly, characterization depends semantics generators.
However, show dependence quite uniform, involves characterization strong equivalence generators relative underlying semantics,
considered propositional theories. Finally, combine
characterizations one-dimensional concepts strong equivalence characterization general combined notion.
develop results case preferences ranked. practice, preferences commonly ranked due hierarchical structure preference providers.
353

fiFaber, Truszczynski, & Woltran

general case study allows additions preferences ranks specified interval [i, j]. covers case segment hierarchy
preference providers allowed add preferences (top decision makers, middle management, low-level designers), well case distinction
importance preferences (the non-ranked case).
establish complexity deciding whether two optimization problems strongly equivalent relative changing selectors, generators, both. results show
problems range co-NP- P3 -complete.
Organization. following section, introduce concept optimization
problem necessary terminology, define equivalence problems interested
here. also discuss relationship optimization problems formalisms
literature, particular ASO programs. Section 3 provide results
case selectors may vary new hard constraints allowed. Section 4
turn characterizes strong equivalence notion, preferences unaffected
generator parts subject change. Section 5 finally show characterizations
obtained previous sections combined order capture general case
strong equivalence. complexity analysis presented Section 6, followed
discussion results considerations future directions research.
present proof sketches simpler overly technical proofs
main text facilitate understanding results intuitive level. Detailed proofs
found Appendix.
article substantially extended version earlier published conference version
(Faber, Truszczynski, & Woltran, 2012).

2. Optimization Problems
section provide basic definitions optimization problems Section 2.1,
followed Section 2.2 definitions strong equivalence notions optimization
problems studied remainder paper. Finally, Section 2.3 provide
discussion related formalisms.
2.1 Basic Definitions
qualitative optimization problem (an optimization problem, on) ordered
pair P = (T, S), called generator selector. role
generator specify family outcomes compared. role selector
define relation set outcomes and, consequently, define notion
optimal outcome. relation induces relations > : define > J J
J 6 I, J J J I. optimization problem P , write P g P
refer generator selector, respectively.
Generators. generators use propositional theories language determined
fixed countable universe (or alphabet) U propositional variables form atomic
propositions, Boolean constant , Boolean connectives , ,
define constant >, connectives usual way > := , :=
354

fiStrong Equivalence Qualitative Optimization Problems

, := ( )( ), respectively.1 Models generator, defined
semantics used, represent outcomes corresponding optimization problem.
consider two quite different semantics generators: classical propositional logic
semantics semantics equilibrium models (Pearce, 1997). Thus, outcomes
either models equilibrium models, depending semantics chosen. first semantics
interest due fundamental role widespread use classical propositional logic,
particular, means describe constraints. Equilibrium models generalize answer sets
logic programs case arbitrary propositional theories (Pearce, 1997; Ferraris, 2005)
often referred answer sets. semantics equilibrium models important
due demonstrated effectiveness logic programming semantics answer
sets knowledge representation applications. use terms equilibrium models
answer sets interchangeably.
Throughout paper, represent interpretations subsets U, contain
exactly atomic propositions interpreted true. write |= state
interpretation U (classical propositional) model formula . Furthermore,
denote set classical models formula theory Mod (T ).
Equilibrium models arise context propositional logic here-and-there,
logic HT short (Heyting, 1930). briefly recall definitions concepts,
well properties logic HT directly relevant work. refer
papers Pearce (1997) Ferraris (2005) details.
logic HT logic located intuitionistic classical logics. Interpretations logic HT pairs hI, Ji standard propositional interpretations
J. write hI, Ji |=HT denote formula holds interpretation
hI, Ji logic HT. relation |=HT defined recursively follows:
1. hI, Ji 6|=HT
2. atom a, hI, Ji |=HT precisely
3. hI, Ji |=HT hI, Ji |=HT hI, Ji |=HT
4. hI, Ji |=HT hI, Ji |=HT hI, Ji |=HT
5. hI, Ji |=HT J |= (classical satisfiability), hI, Ji 6|=HT
hI, Ji |=HT .
equilibrium model answer set propositional theory standard interpretation hI, Ii |=HT every proper subset J I, hJ, Ii 6|=HT . Answer
sets propositional theory also classical models . converse true
general. denote set answer sets theory (T ), set
HT-models ModHT (T ), is, ModHT (T ) = {hI, Ji | J, hI, Ji |=HT }.
semantics two natural concepts equivalence. Two theories T1
T2 equivalent models (classical equilibrium, respectively).
strongly equivalent every theory S, T1 T2 models
(again, classical equilibrium, respectively).
1. choice primitive connectives common language classical propositional logic,
standard logic here-and-there underlies answer-set semantics.

355

fiFaber, Truszczynski, & Woltran

classical semantics, strong equivalence equivalence coincide.
semantics equilibrium models. result Lifschitz et al. (2001) states two
theories T1 T2 strongly equivalent equilibrium models T1 T2
equivalent logic HT, is, ModHT (T1 ) = ModHT (T2 ). illustrate
notions HT-models equilibrium models, relate latter classical ones.
examples, consider classical HT-models alphabet
consisting atoms explicitly mentioned theories discussed. sufficient
determine equilibrium models one hand (which happen consist atoms
mentioned) and, other, show differ classical ones.
Example 1 Let us consider theory Ta = {a a}. classical models Ta (under
restriction mentioned above) {a}, true false possible
outcomes. HT-models (again, restriction) h, i, h, {a}i,
h{a}, {a}i. Hence, one answer set (equilibrium model) . possible
candidate, {a}, answer set. h{a}, {a}i |=HT Ta holds, also h, {a}i |=HT Ta
does. Thus, intuitively, theory contain cause hold.
Next, let us consider theory Tb = {ab}. classical models {a}, {b} {a, b},
HT-models h{a}, {a}i, h{b}, {b}i, h{a}, {a, b}i, h{b}, {a, b}i h{a, b}, {a, b}i.
answer sets therefore {a} {b}, {a, b}. intuition
theory contain cause b hold simultaneously.
Finally, let us consider theory Tc = {(a b) (b a)}. classical models
Tb , is, Mod (Tc ) = {{a}, {b}, {a, b}}. also ModHT (Tc ) =
{h{a}, {a}i, h{b}, {b}i, h{a}, {a, b}i, h{b}, {a, b}i, h{a, b}, {a, b}i, h, {a, b}i} = ModHT (Tb )
{h, {a, b}i}. answer sets Tb : (Tc ) = {{a}, {b}}.
observe Tb Tc equivalent classical equilibrium setting
(they classical equilibrium models). former implies
also strongly equivalent classical setting. However, strongly equivalent
equilibrium setting ModHT (Tb ) 6= ModHT (Tc ) (cf. characterization strong
equivalence equilibrium semantics Lifschitz et al. (2001)). indeed,
= {a b, b a}, obtain (Tb S) = {{a, b}}, (Tc S) = .
recall optimization problems classical interpretation generators
referred classical optimization problems CO problems, use
answer-set semantics generators, speak answer-set optimization problems
ASO problems.
Selectors. follow definitions preference modules ASO programs (Brewka
et al., 2003), adjusting terminology general setting. selector finite
set ranked preference rules
j
1 > > k
(1)
k j positive integers, , 1 k, propositional formulas
U. rule r form (1), number j rank r, denoted rank (r),
hd (r) = {1 , . . . , k } head r body (the condition) r, bd (r). Moreover,
write hd (r) refer formula .
rank (r) = 1 every preference rule r selector S, simple selector.
1
Otherwise, ranked. often omit 1 notation simple selectors.
356

fiStrong Equivalence Qualitative Optimization Problems

selector S, i, j {0, 1, 2, . . .} {}, define S[i,j] = {r | rank (r) j}
(where assume every integer k, k < ) write [i, j] rank interval
{k | k integer, k j}. extend notation optimization problems.
P = (T, S) rank interval [i, j], set P[i,j] = (T, S[i,j] ). rank intervals
use shorthands, example = [i, i], < [1, 1], [i, ], similar.
interpretation I, satisfaction
degree preference rule r vI (r) = min{i | |=
W
hd (r)}, |= bd (r) |= hd (r); otherwise, rule irrelevant I, vI (r) = 1.
Intuitively, lower satisfaction degree better outcome. Thus, preference
rule 1 > > k informally read follows: irrelevant outcomes (those
satisfying , satisfying ) outcomes satisfying 1 preferred,
followed outcomes satisfying 2 , outcomes satisfying 3 , etc. note
Brewka et al. (2003) represented satisfaction degree irrelevant rule special
non-numeric degree, treated equivalent 1. difference immaterial
two approaches equivalent.
Selectors determine preference relation interpretations. Given interpretations
J simple selector S, J holds precisely r S, vI (r) vJ (r).
Therefore, >S J holds J exists r vI (r) < vJ (r);
J holds every r S, vI (r) = vJ (r).
Given ranked selector S, define J every preference rule r S, vI (r) =
vJ (r), rule r0 following three conditions hold:
1. vI (r0 ) < vJ (r0 )
2. every r rank r0 , vI (r) vJ (r)
3. every r smaller rank r0 , vI (r) = vJ (r).
Moreover, >S J rule r0 three conditions hold,
J every r S, vI (r) = vJ (r). Given optimization problem
P = (T, S), often write P (and similarly > ). Furthermore, set
V 2U relation (like >, , ) 2U , write V restriction
V , is, V = {(A, B) | A, B V }. relationship equalities , >,
two optimization problems follows.
Lemma 1 optimization problems P Q, every set V 2U , PV = Q
V
Q
P
implies >PV = >Q
V V = V .
P
Proof. Suppose PV = Q
V let I, J interpretations I>V J. definiQ
Q
Q
P
P
tion, IV J J6V I. assumption IV J J6V I, implying I>V J. case IPV J
Q
IPV J JPV I. assumption IQ
V J JV hold well conclude
Q
Q
P
P
IQ
V J. direction (I>V J implies I>V J, IV J implies IV J) analogous. 2

aspects ASO selectors require additional discussion. First, preference rule
may irrelevant outcome. case outcome satisfy
condition rule or, does, satisfy formula head
rule. cases, define outcome desirable respect rule.
making choice, followed original definition (Brewka et al., 2003) (modulo
357

fiFaber, Truszczynski, & Woltran

minor simplification mentioned earlier). Obviously, choices could considered, too.
instance, could define irrelevant outcomes least desirable respect
rule. could also restrict attention selectors permit irrelevance
(a preference rule allow irrelevance body disjunction
options head tautology). would eliminate need address issue
altogether, however, price constraining definintion selector rules.
Ultimately, question right design choice secondary importance
semantics preference rules adopted provides us flexibility represent
possible definitions. particular, note semantics rule
1 > . . . > n
rule
1 > . . . > n .
words, conditions (the rule bodies) modeling device making preference
rules better correspond conditional preferences expressed natural language.
compiled away. second type irrelevance, formalism selectors allows
user override default adopted. make adopted design choice explicit,
is, making outcomes satisfying options head explicitly
desirable. Intuitively, sufficient rewrite rule (without body, since bodies
removed, shown earlier)
1 > . . . > n

1 (1 . . . n ) > . . . > n ,
or, equivalently,
1 (2 . . . n ) > . . . > n
following rewriting makes least desirable:
1 > . . . > n (1 . . . n ) ,
or, equivalently,
1 > . . . > n (1 . . . n1 ) .
Another question concerns rules one option head. Intuitively, given
semantics important, satisfaction degree always 1.
Indeed, Corollary 12 later paper provides formal result confirms statement.
Optimal (preferred) outcomes. optimization problem P , (P ) denotes set
outcomes P , is, set models (under selected semantics)
generator P . Thus, (P ) stands models P framework CO problems
answer sets P , ASO problems considered. model (P )
optimal preferred P model J (P ) J >P I. denote
set preferred models P (P ).
following lemma asserts preference relation two optimization problems
equal sets outcomes, preferred models coincide. result follows
358

fiStrong Equivalence Qualitative Optimization Problems

immediately definitions useful sequel. statement brings
subtle notational issue. Formally, (strict) preorder pair (D, >), set (the
domain preorder) > transitive acyclic binary relation (the preorder
relation). Two preorders equal domain relation
domain. Typically, whenever domain understood, refer preorders
pointing relation symbols. Often, however, write >D preorder relation
symbol make domain explicit notation. statement
result below.
Lemma 2 Let P Q optimization problems >P(P ) = >Q
(Q) . Then, (P ) = (Q).
Proof.
observed above, equality preorders implies equality domains. case, equality >P(P ) = >Q
(Q) implies (P ) = (Q). Hence,
P
Q
I, J (P ) = (Q), > J iff > J. result follows directly definition
preferred outcomes. 2
also observe eliminating rules large ranks make unpreferred outcomes preferred, never make preferred outcomes unpreferred. recall that,
given optimization problem P = (T, S), P<i = P[1,i1] = (T, S[1,i1] ) corresponding
optimization problem rules rank higher removed.
Lemma 3 every optimization problem P every 1, (P<i ) (P ).
Proof. Let us assume
/ (P<i ). case
/ (P<i ),
/ (P ),
/ (P )
P
<i
follows. Otherwise, interpretation J (P<i ) J >
I. Thus,
, say rank j, (i) v (r) < v (r); (ii) every r 0 P
rule r P<i
J

<i
rank less j, v (r 0 ) = v (r 0 ).
rank j, vJ (r0 ) vI (r0 ); (iii) every r0 P<i
J

note that, since (P<i ) = (P ), J (P ). Moreover, j < sets rules
coincide. Thus, J >P follows and,
ranks less equal j P P<i
consequently,
/ (P ). 2

2.2 Notions Equivalence
define union optimization problems expected, is, P1 = (T1 , S1 )
P2 = (T2 , S2 ), set P1 P2 = (T1 T2 , S1 S2 ). Two optimization problems P1
P2 strongly equivalent respect class R optimization problems (referred
class contexts simply contexts) every optimization problem R R,
(P1 R) = (P2 R).
consider three general classes contexts. First foremost, interested
class LU optimization problems U. also consider families LgU
LsU optimization problems form (T, ) (, S), respectively. first class
consists optimization problems which, added problem, affect
set feasible outcomes cannot affect preference relation. call optimization
problems generator problems. second class consists optimization problems which,
added problem, change set feasible outcomes change
359

fiFaber, Truszczynski, & Woltran

(in general) preference relation. call optimization problems selector problems.
one-dimensional contexts provide essential insights general case.
two classes, speak strong gen-equivalence, denoted g , strong sel-equivalence,
denoted , respectively. general class LU optimization problems simply
speak strong equivalence, denoted sg .
recall notion strong equivalence is, definition, underlying replacement property. fact, optimization problem P = (T, S) containing subproblem
Q = (T 0 , 0 ) (i.e. 0 0 S) guarantee Q replaced P
another subproblem R without changing optimal outcomes, Q sg R. Indeed,
Q sg R holds, one faithfully replace Q R optimization problem (otherwise
would (Q P 0 ) 6= (R P 0 ) P 0 LU ).
Constraining ranks rules selectors gives rise additional classes contexts parameterized rank intervals [i, j]:
s,[i,j]

1. LU

[i,j]

2. LU

= {(, S) LsU | = S[i,j] }

= {(T, S) LU | = S[i,j] }

first class contexts gives rise strong sel-equivalence respect rules
rank [i, j], denoted s,[i,j] . second class contexts yields concept strong
s,[i,j]
equivalence respect rules rank [i, j]. denote g
. call problems
[1,1]
=1
class LU = LU simple optimization problems.
2.3 Relation Preference Formalisms
Optimization problems closely related ASO programs (Brewka et al., 2003).
formalism optimization problems extends ASO programs several ways. First,
generators optimization problems arbitrary propositional theories.
semantics equilibrium models, generators properly extend logic programs
answer-set semantics, used generators ASO programs. Second, selectors
optimization problems use arbitrary propositional formulas heads preference
rules, well conditions bodies, generalizes selectors
ASO programs. Finally, optimization problems explicitly allow alternative semantics
generators, possibility mentioned pursued Brewka et al. (2003).
already noted introduction vast literature preference representation reasoning (The special issue Artificial Intelligence Magazine, Goldsmith &
Junker, 2008, monograph Kaci, 2011, two comprehensive sources relevant
references. survey preference approaches top nonmonotonic formalisms, see
Delgrande, Schaub, Tompits, & Wang, 2004). Discussing goes beyond scope
present paper, especially problem focus (strong equivalence)
considered much preference research before, essentially
relevant earlier results except already mentioned introduction (Faber &
Konczak, 2006; Faber et al., 2008; Eiter et al., 2007a). Nevertheless, since work uses
preference formalism ASO problems, extension formalism ASO programs
Brewka et al. (2003) received much attention preference research
others, make comments choice.
360

fiStrong Equivalence Qualitative Optimization Problems

First, ASO problems explicit constraints must violated (the
generator part) preferences, is, weaker constraints make outcomes
desirable others (the selector part). ASO problems match well practical settings, typically kinds constraints play. instance, product
configuration problem physical constraints limiting space available possibilities (not every type engine put small family sedan, moon roof available
basic engine option, etc.), well user preferences describe user
would like possible. Preferential reasoning (optimization) presence (hard)
constraints received substantial attention. representative approach CP-nets
(Boutilier, Brafman, Domshlak, Hoos, & Poole, 2003) combined constraints
described paper Boutilier, Brafman, Domshlak, Hoos, Poole (2004).
choice propositional logic represent constraints (the generator part formalism) standard. However, contrast approaches, addition classical
semantics also consider appealing alternative, semantics answer sets.
important resulting formalism answer-set programming (Marek & Truszczynski,
1999; Niemela, 1999) steadily gaining acceptance constraint language
supported ever improving computational tools (Calimeri, Ianni, Krennwallner, & Ricca,
2012).
hand, choice formalism selector part less obvious.
several reasons motivated us. first, one already mentioned
earlier, preference rules natural reading agreeing well linguistic
patterns humans use formulating qualitative conditional preferences. Second,
demonstrated original work ASO selectors introduced (Brewka et al.,
2003), used approximate preference relations defined CP-nets
(Boutilier et al., 2003), one broadly studied qualitative preference systems,
better computational properties. instance, dominance problem P
opposed NP-hard even PSPACE-complete generalized classes
CP-nets (Goldsmith, Lang, Truszczynski, & Wilson, 2008).
Third, individual preference rules closely related one standard approaches
representing preferences based possibilistic logic. approach (we give
basic details here, comprehensive discussion refer Kaci, 2011, Ch.
3.3.3), preference theory consists formulas, distinct rank (the assumption
ranks distinct limiting formulas repeating ranks conjuncted
single formula rank). quality outcome given score defined
minimum rank formula outcome satisfy (, formulas
satisfied). higher score, better outcome. Let {1 , . . . , n } preference
theory, index representing rank . clear preference
semantics theory described precisely captured preference rule
n > n1 > . . . > 1 > 1
= 1 . . . , = 1, . . . , n. Thus, ASO problems subsume preference
formalism based possibilistic logic.
Finally, selector part ASO problems typically consists several preference rules
rules may different ranks. allows us model preferences coming
different sources different importance. cases, main issue
361

fiFaber, Truszczynski, & Woltran

integrating individual preferences single order. single broadly
accepted way so. approach used formalism boils Pareto
principle, arguably common core integration principles. Accordingly,
formalism allows conflicting rules selector (for instance, > b b > )
leaves conflicts unresolved resulting incomparability. ranks, lower
rank, important rule is. Rules less importance used compare outcomes
rules importance distinguish them. way handling ranks
natural shows many preference formalisms.
One prominent example context prioritized (propositional) circumscription
(Lifschitz, 1985), minimization (of certain atoms models formula) defined
respect classes atoms different priority. Formally, let theory
atoms (P1 , . . . , Pn , V, F ) partition A. Then, model Mod (T ) called
(P1 , . . . , Pn , V, F )-minimal N Mod (T ), (i) N (P1 Pi1 ) =
(P1 Pi1 ) N Pi Pi 1 Si n, (ii) N F = F .
intuition behind definition atoms P = Pi minimized,
assignments V allowed vary, assignments F kept fixed. Atoms P
minimized P1 highest priority followed P2 , etc.
relation ranks quite obvious. One show (P1 , . . . , Pn , V, F )-minimal
models theory coincide preferred outcomes CO problem X = (T, S),
selector given
1

1

= {f > f > | f F } {f > f > | f F }


{p > p > | p Pi , 1 n}).
Indeed preference rules first two sets ensure interpretations
fixed part comparable, preference rules last group precisely reflect prioritized process minimization atoms P1 . . . Pn .
Let us finally mention formalism optimization problems gives
handle classical prioritized circumscription, also circumscription put
top logic programs (this meaningless, forms currently prevalent answer
set programming, answer sets necessarily minimal models, see instance Simons,
Niemela, & Soininen, 2002). end suffices apply embedding using ASO
problems instead CO problems.

3. Strong Sel-Equivalence
start analyzing case strong sel-equivalence turns core case
study. Indeed, characterizations strong sel-equivalence naturally imply characterizations general case thanks following simple observation.
Proposition 4 Let P Q optimization problems (either classical answer-set
s,[i,j]
semantics generators) [i, j] rank interval. P g
Q
every generator R LgU , P R s,[i,j] Q R.
s,[i,j]

Proof. () Let R LgU . Since P g

s,[i,j]

Q, P R g
362

Q R so, P R s,[i,j] Q R.

fiStrong Equivalence Qualitative Optimization Problems

[i,j]

() Let R optimization problem LU . P R = (P (Rg , ))(, Rs )
QR = (Q(Rg , ))(, Rs ). Moreover, assumption P (Rg , ) s,[i,j]
Q (Rg , ). Thus,
((P (Rg , )) (, Rs )) = ((Q (Rg , )) (, Rs )).
s,[i,j]

follows (P R) = (Q R) and, consequently, P g

Q. 2

Furthermore, set outcomes optimization problem P unaffected changes
selector module. follows choice semantics generators
matter characterizations strong sel-equivalence. Thus, whenever section
refer set outcomes optimization problem P , use notation (P ),
specific one, Mod (P g ) (P g ), applies CO ASO problems,
respectively.
formally state subsequent results, need one auxiliary notation.
optimization problem P , define diff P (I, J) largest k P<k J.
every k P<k J, set diff P (I, J) = . clear diff P (I, J)
well-defined. Moreover, P<1 J, diff P (I, J) 1. following lemma characterizes
relation >P Q ranked optimization problems P Q.
Lemma 5 Let P Q optimization problems, I, J interpretations. Then,
>P Q J holds one following conditions holds:
1. diff P (I, J) < diff Q (I, J) >P J;
2. diff P (I, J) > diff Q (I, J) >Q J;
3. diff P (I, J) = diff Q (I, J), >P J >Q J.
Proof. direction evident. prove only-if direction, note
cases diff P (I, J) < diff Q (I, J) diff P (I, J) > diff Q (I, J) obvious, too. Thus, let us
assume diff P (I, J) = diff Q (I, J) = i. Clearly, < (otherwise, P Q J, contrary
assumption). follows every rule r P Qs rank less i, vI (r) = vJ (r).
Next, every r P Qs rank i, vI (r) vJ (r). Finally, rules r P
r0 Qs , rank vI (r) 6= vJ (r) vI (r0 ) 6= vJ (r0 ) (since diff P (I, J) =
diff Q (I, J) = i). follows vI (r) < vJ (r) vI (r0 ) < vJ (r0 ). Thus, >P J
>Q J, needed. 2
first main result concerns strong sel-equivalence relative selectors consisting
preference rules ranks rank interval [i, j]. Special cases strong sel-equivalence
follow corollaries.
Considering strong sel-equivalence means preference rules may added optimization problems. three main effects so: outcomes equally good
may become strictly comparable, strict comparability may turned incomparability,
order strict comparability may reversed. illustrate phenomena,
show may affect strong sel-equivalence using forthcoming examples. Importantly, lead us towards conditions necessary strong sel-equivalence
motivate characterization property formally state Theorem 6.
363

fiFaber, Truszczynski, & Woltran

Example 2 Let P1 = (T1 , S1 ), T1 theory generating exactly two outcomes {a}
{b} (for example {a b}) S1 = empty. Clearly, (P1 ) = {{a}, {b}},
{a} {b} equally good respect P1 . possible make comparable

adding new preference rules. example, let R1 = (, {a > b }), 1. Now,
{a} >P1 R1 {b} thus (P1 R1 ) = {{a}}. evident pair equally good
interpretations I, J one find context consisting preference rules make
strictly preferred J (each new rule least preferred J one
strictly prefer J), precise ranks context
importance.
Example 3 Let P2 = (T1 , S2 ), T1 theory generating exactly two outcomes {a}

{b}, S2 = {a > b } rank 1. Clearly, {a} >P2 {b} therefore
(P2 ) = {{a}}. possible make {a} {b} incomparable adding appropriate

context, example R2 = (, {b > }). obtain {a} >
6 P2 R2 {b} {b} >
6 P2 R2 {a},
thus (P2 R2 ) = {{a}, {b}}.
important note rank context preference rule must exactly equal
rank original preference rule order achieve effect, otherwise one
preference rule would override other. general, pair strictly comparable
interpretations I, J one find appropriate context makes J incomparable,
contrast Example 2, context must make use rules particular ranks.
Example 4 Let P3 = (T1 , S3 ), T1 theory admitting exactly two outcomes {a}

{b}, S3 = {a > b } rank 2. Clearly, {a} >P3 {b} therefore
(P3 ) = {{a}}. possible reverse comparability {a} {b} adding
1
appropriate context, example R3 = (, {b > }). obtain {b} >P3 R3 {a}, thus
(P3 R3 ) = {{b}}.
important note that, order achieve effect, context must contain
preference rules lower ranks preference rules originally ordered J,
original ordering overridden. also means technique
applicable preference rules rank 1. general, pair strictly comparable
interpretations I, J, comparison stems preference rules rank > 1, adding
context consisting preference rules lower rank reverse comparability J
results reversed strict order. Example 3, context must make use particular
ranks.
three effects may exploited order construct examples problems
strongly sel-equivalent suggest necessary conditions strong sel-equivalence.
first effect turn preferred outcomes non-preferred, second third
turn non-preferred outcomes preferred ones. second third effects imply
conditions specialized (context needs rules particular ranks).
2

3

Example 5 Consider P4 = (T1 , {a > b }) Q4 = (T1 , {a > b }), T1
theory admitting exactly two outcomes {a} {b}. {a} >P4 {b}, {a} >Q4 {b},
(P4 ) = (Q4 ) = {{a}}. two problems therefore equivalent. However,
364

fiStrong Equivalence Qualitative Optimization Problems

discrepancy respect ranks preference rules, take advantage
order show programs strongly sel-equivalent.
3
Let us consider context R4 = (, {b > }). context exploits second effect
mentioned makes {a} {b} incomparable respect Q4 extended
R4 ({a} 6>Q4 R4 {b} {b} 6>Q4 R4 {a}) thus turning also {b} preferred outcome
(Q4 R4 ) = {{a}, {b}}. hand, new preference rule effect P4 ,
rank weaker preference rule P4 , hence (P4 R4 ) = {{a}},
therefore P4 6s,[3,i] Q4 3.
Analyzing example, observe context R4 exploits difference
preferred outcomes considering preference rules rank lower 3.
Indeed, ((P4 )<3 ) = {{a}} ((Q4 )<3 ) = {{a}, {b}}.
2

4

Example 6 Next, let us consider P5 = P4 = (T1 , {a > b }) Q5 = (T1 , {a > b }),
T1 theory admitting exactly two outcomes {a} {b}. {a} >P5 {b},
{a} >Q5 {b}, (P5 ) = (Q5 ) = {{a}}. Also here, observe ((P5 )<3 ) =
{{a}} ((Q5 )<3 ) = {{a}, {b}}. difference Example 5 preference
rule Q5 rank 4.
Also possible construct context witnesses P5 strongly sel3
3
equivalent Q5 , using preference rules rank 3: R5 = (, {a > b , b > }).
Here, directly add conflicting preference rules override preference rule Q5
overridden preference rule P5 . So, also get (P5 R5 ) = {{a}}
(Q5 R5 ) = {{a}, {b}}, P5 6s,[3,i] Q5 3.
Examples 5 6 motivate condition (1) Theorem 6. Moreover, also rather easy
see counterexample P s,[i,j] Q involve outcomes (P<i ) =
(Q<i ), selector context rank interval [i, j] make outcomes preferred.
However, different point view, condition (1) Theorem 6 also fairly weak,
cover easy cases strong sel-non-equivalence, shown following
example.
2

2

Example 7 Let us define P6 = P4 = (T1 , {a > b }) Q6 = (T1 , {b > }), T1
theory admitting exactly two outcomes {a} {b}. {a} >P6 {b}, {b} >Q6 {a},
(P6 ) = {{a}} 6= (Q6 ) = {{b}}. P6 Q6 even equivalent, hence also
P6 6s,[i,j] Q6 rank interval [i, j]. However, ((P6 )<2 ) = {{a}, {b}} ((Q6 )<2 ) =
{{a}, {b}}. condition (1) Theorem 6 satisfied rank intervals [2, j].
Condition (2) Theorem 6 covers cases like one Example 7. example
rather simple, even require context order create witness strong
sel-non-equivalence, general one create context order make certain
outcomes preferred. remains considered cases discrepancy
stemming preference rules inside context rank interval.
2

3

Example 8 Let P7 = (T1 , {a > b }) Q7 = (T1 , {a > b }), T1 theory
admitting exactly two outcomes {a} {b} (this pair problems P4 Q4
2
Example 5). Consider context R7 = (, {b > }). Unlike R4 Example 5,
365

fiFaber, Truszczynski, & Woltran

rule rank 2. context makes {a} {b} incomparable respect extended
P7 ({a} 6>P7 R7 {b} {b} 6>P7 R7 {a}), thus turning {b} preferred outcome,
keeping {a} such. Therefore, (P7 R7 ) = {{a}, {b}}. hand, new
preference rule overrides one Q7 , turning {b} preferred outcome making
{a} non-preferred, (Q7 R7 ) = {{b}}. Therefore P7 6s,[2,i] Q7 2.
Unlike Example 5, ((P7 )<2 ) = ((Q7 )<2 ) = {{a}, {b}}, different reason allows counterexample. Here, observe diff P7 ({a}, {b}) = 2 6=
diff Q7 (a, b) = 3, allows adding appropriate preference rule rank 2.
important add rule one two differing ranks. Indeed,
context comprising rules rank one serve counterexample strong
sel-equivalence, indeed P7 s,[1,1] Q7 .
finally motivates condition (3) Theorem 6: two outcomes (as discussed
earlier, restrict outcomes (P<i ) = (Q<i ) context rank interval
[i, j]) differ ranks one ranks inside rank interval, use
constructions Example 8 order obtain counterexample strong sel-equivalence.
show three conditions Theorem 6 indeed characterize strong selequivalence.
Theorem 6 ranked optimization problems P Q, every rank interval [i, j],
P s,[i,j] Q following conditions hold:
1. (P<i ) = (Q<i )
2. >P(P<i ) = >Q
(Q<i )
3. every I, J (P<i ) < diff P (I, J) < diff Q (I, J), diff P (I, J) =
diff Q (I, J) diff P (I, J) > j diff Q (I, J) > j.
proof result quite involved requires several auxiliary properties.
provide appendix (together proofs main results).
Next, discuss special cases characterization Theorem 6. First,
consider case = 1, allows simplification Theorem 6.
Corollary 7 ranked optimization problems P Q, every rank interval [1, j],
P s,[1,j] Q following conditions hold:
1. (P ) = (Q)
2. >P(P ) = >Q
(Q)
3. every I, J (P ), diff P (I, J) = diff Q (I, J) diff P (I, J) > j diff Q (I, J) >
j.
Proof. Starting Theorem 6, note selectors P<1 Q<1 empty
hence (P<1 ) = (P ) (Q<1 ) = (Q). Moreover, precondition < diff P (I, J)
< diff Q (I, J) condition (3) Theorem 6 satisfied = 1 pair
I, J (P ), one diff P (I, J) = 1 diff Q (I, J) = 1 holds, together
366

fiStrong Equivalence Qualitative Optimization Problems

diff P (I, J) = diff Q (I, J) consequent satisfied case well, allows
omitting precondition. 2
addition j = , obtain case rank-unrestricted selector contexts,
condition (3) simplified more, since diff P (I, J) > j diff Q (I, J) > j never
hold j = .
Corollary 8 optimization problems P Q, P Q (equivalently, P s,1 Q
P s,[1,] Q) following conditions hold:
1. (P ) = (Q)
2. >P(P ) = >Q
(Q)
3. every I, J (P ), diff P (I, J) = diff Q (I, J).
Next, note optimization problem P simple (all rules rank 1),
diff P (I, J) > 1 diff P (I, J) = , equivalent P J. observation leads following characterization strong sel-equivalence simple optimization
problems.
Corollary 9 simple optimization problems P Q, following statements
equivalent:
(a) P Q (equivalently, P s,[1,] Q)
(b) P s,=1 Q (equivalently, P s,[1,1] Q)
(c) (P ) = (Q) P(P ) =Q
(Q) .
Proof. implication (a)(b) evident definitions.
(b)(c) Corollary 7, j = 1, obtain (P ) = (Q). condition P(P ) =Q
(Q)
follows conditions (2) (3) corollary. Indeed, let us consider I, J (P )
P J distinguish two cases. (i) diff P (I, J) = 1 >P J
condition (2) Corollary 7, also >Q J, implying Q J. (ii) diff P (I, J) > 1
condition (3) Corollary 7, diff Q (I, J) > 1. Since P, Q simple, Q J,
consequently Q J. symmetry, also Q J implies P J. Thus,
P(P ) =Q
(Q) .
Q
P
(c)(a) (c) follows Lemma 1 >P(P ) =>Q
(Q) (P ) =(Q) . Thus,
conditions (1) (2) Corollary 8 follow. prove condition (3), let us first assume
diff P (I, J) > 1 I, J (P ). follows diff P (I, J) = thus P(P ) J. Since
Q
Q
P
Q
P(P ) =Q
(Q) , get (Q) J thus diff (I, J) = . Hence diff (I, J) = diff (I, J).

diff Q (I, J) > 1 reason analogously. last remaining case, diff P (I, J) = 1
diff Q (I, J) = 1. Thus, directly obtain diff P (I, J) = diff Q (I, J). Corollary 8, P Q
follows. 2

367

fiFaber, Truszczynski, & Woltran

Corollary 9 shows, particular, simple problems difference
relations s,1 s,=1 . property reflects role preference rules rank 2
higher. allow us break ties among optimal outcomes, defined preference
rules rank 1. Thus, eliminate outcomes family optimal
ones, cannot introduce new optimal outcomes. Therefore, affect strong
sel-equivalence simple problems. property following generalization ranked
optimization problems.
Corollary 10 Let P Q ranked optimization problems let k maximum
rank preference rule P Q. relations s,k (equivalently, s,[k,] )
s,=k (equivalently, s,[k,k] ) coincide.
Proof. Clearly, P s,k Q implies P s,=k Q. Thus, enough prove P s,=k Q
P s,k Q. Using characterization Theorem 6, observe conditions (1)
(2) P s,=k Q P s,k Q same. Since P s,=k Q,
every I, J (P<k ) k < diff P (I, J) k < diff Q (I, J), diff P (I, J) = diff Q (I, J)
diff P (I, J) > k diff Q (I, J) > k. Let us consider I, J (P<k )
diff P (I, J) > k. follows diff Q (I, J) > k. Since k maximum rank preference rule P Q, diff P (I, J) = diff Q (I, J) = . Thus, diff P (I, J) = diff Q (I, J).
case diff Q (I, J) > k similar obtain every I, J (P<k )
k < diff P (I, J) k < diff Q (I, J), diff P (I, J) = diff Q (I, J). property implies condition (3) P s,k Q. Thus, P s,k Q follows. 2
observation role preference rules ranks higher ranks rules
P Q also implies P Q strongly sel-equivalent relative selectors consisting
exclusively rules P Q equivalent (have optimal
outcomes), optimal outcomes tie P also tie Q conversely. Formally,
following result.
Corollary 11 Let P Q ranked optimization problems let k maximum
rank preference rule P Q. P s,k+1 Q (P ) = (Q)
P(P ) =Q
(Q) .
Proof. Clearly, P<k+1 = P Q<k+1 = Q so, (P<k+1 ) = (P ) (Q<k+1 ) =
(Q). Thus, only-if part follows Theorem 6 (condition (1) theorem reduces
(P ) = (Q) condition (3) implies P(P ) =Q
(Q) ). prove part, note
condition (1) Theorem 6 holds assumption. Moreover, relations >P(P )
>Q
(Q) empty so, coincide. Thus, condition (2) Theorem 6 holds. Finally,
I, J (P ), diff P (I, J) > k + 1, diff P (I, J) = so, P J. assumption, Q J, is, diff Q (I, J) = = diff P (I, J). case diff Q (I, J) > k + 1
similar. Thus, condition (3) Theorem 6 holds, too, P s,k+1 Q follows. 2
Lastly, give simple examples illustrating results used safely
modify simplify optimization problems, rewrite one another strongly selequivalent one.
368

fiStrong Equivalence Qualitative Optimization Problems

Example 9 Let P = (T, S), = {a b c, (a b), (a c), (b c)} = {a >
c , b > c }, P 0 = (T, 0 ), 0 = {a b > c }. Regarding problems
CO problems, (P ) = (P 0 ) = {{a}, {b}, {c}}. Moreover, evident
0
P(P ) =P(P 0 ) . Thus, Corollary 9, P P 0 strongly sel-equivalent. words,
faithfully replace rules > c , b > c selector optimization problem
generator single rule b > c .
example general principle, note removing preference rules
one formula head yields problem strongly sel-equivalent.
Corollary 12 Let P Q two CO ASO problems P g = Qg Qs
obtained P removing preference rules one formula head (i.e.,
rules r |hd (r)| = 1). P Q strongly sel-equivalent.
Proof. Conditions (1)-(3) Theorem 6 follow observation every interpretation every preference rule r |hd (r)| = 1, vI (r) = 1. 2

4. Strong Gen-Equivalence
focus case strong gen-equivalence. semantics generators makes
difference difference concerns fact two semantics
consider, concepts strong equivalence different. aspects characterizations same. Specifically, generators strongly equivalent relative
selected semantics. Indeed, following example shows, generators
strongly equivalent, one extend uniformly extension one problem
single outcome, trivially optimal one, too, one
outcomes so, optimal ones.
Example 10 Consider CO problem P8 = (T8 , S8 ), T8 = {a b} S8 = {a >
b }. two outcomes here, {a} {b}, is, (P8 ) = {{a}, {b}}. Let r
preference rule S8 . Clearly, v{a} (r) = 1 v{b} (r) = 2. Thus, {a} >P8 {b} so,
(P8 ) = {{a}}.
addition, let Q8 = (T80 , S8 ) CO problem, T80 = {a b} S8
above. Then, (Q8 ) = {{a}} and, trivially, (Q8 ) = {{a}}. follows P8 Q8
equivalent, specify optimal outcomes. However, strongly
gen-equivalent (and so, also strongly equivalent). Indeed, let R8 = ({a}, ).
(P8 R8 ) = {{b}} so, (P8 R8 ) = {{b}}. hand, (Q8 R8 ) = and,
therefore, (Q8 R8 ) = .
Moreover, preference relation > defined selectors problems considered
must coincide.
Example 11 Let P9 = (T9 , S9 ) CO problem, T9 = {a b c, (a b), (a
c), (b c)} S9 = {a > b , > c }. (P9 ) = {{a}, {b}, {c}},
{a} >P9 {b}, {a} >P9 {c}, {b} {c} incomparable. Thus, (P9 ) = {{a}}. Let
369

fiFaber, Truszczynski, & Woltran

Q9 = (T9 , S90 ) CO problem, S90 = {a > b > c }. Clearly, (Q9 ) = (P9 ) =
{{a}, {b}, {c}}. Moreover, {a} >Q9 {b} >Q9 {c}. Thus, (Q9 ) = {{a}} so, P9 Q9
equivalent. However, strongly (gen-)equivalent. Indeed, let R9 = ({a}, ).
Then, (P9 R9 ) = {{b}, {c}} (P9 R9 ) = {{b}}.
main insight differences preference relation may hidden
preferred outcomes but, present, exposed eliminating
preferred outcomes obscure appropriately selected generator context.
considerations apply CO ASO problems, therefore
formulate single theorem handles types problems.
Theorem 13 CO (ASO, respectively) problems P Q, P g Q
P g Qg strongly equivalent (that is, Mod (P g ) = Mod (Q g ) CO problems,
ModHT (P g ) = ModHT (Qg ) ASO problems) >PMod(P g ) = >Q
Mod(Q g ) .
view Examples 10 11, result unexpected. two examples demonstrated conditions characterization cannot, general, weakened.
Corollary 8 Theorem 13, follows strong sel-equivalence CO problems
stronger property strong gen-equivalence.
Corollary 14 CO problems P Q, P Q implies P g Q.
general implication Corollary 14 cannot reversed, shown following
example.
Example 12 Let us consider problems P10 = (T10 , S10 ) Q10 = (T10 , ), T10 =
{a b} S10 = {a > b , b > }. (P10 ) = (Q10 ) = {{a}, {b}}.
Moreover, {a} 6P10 {b} {b} 6P10 {a}. Thus, (P10 ) = {{a}, {b}}. Since Qs10 =
, also (trivially) {a} Q10 {b}. Thus, (Q10 ) = {{a}, {b}}, too,
problems P10 Q10 equivalent. strongly sel-equivalent, though. Let
R10 = (, {a > b }). Then, P10 R10 = P10 so, (P10 R10 ) = {{a}, {b}}.
hand, {a} >Q10 R10 {b}. Thus, (Q10 R10 ) = {{a}}.
However, virtue Theorem 13, strongly gen-equivalent. Indeed, trivially
g
g
g
g
Mod (P10
) = Mod (Q10
) and, writing Mod (P10
) = Mod (Q10
), relations >PM10
10
>Q
empty therefore equal.
relation strong sel-equivalence strong gen-equivalence ASO problem
complex. general, neither property implies even problems P
Q assumed simple. P Q AS(P g ) =
g
AS(Qg ) PAS(P g ) =Q
AS(Qg ) (Corollary 9), P g Q ModHT (P ) =
g
g
ModHT (Qg ) >PMod(P g ) =>Q
Mod(Q g ) (Theorem 13). Now, AS(P ) = AS(Q ) (regular
equivalence programs) imply ModHT (P g ) = ModHT (Qg ) (strong equivalence)
Q
P
>PMod(P g ) =>Q
Mod(Q g ) imply AS(P g ) =AS(Qg ) .
conclude section one corollary concerning strong gen-equivalence
problems empty selectors.

370

fiStrong Equivalence Qualitative Optimization Problems

Corollary 15 CO (ASO, respectively) problems P Q P = Qs = ,
P g Q P g Qg strongly equivalent respective semantics
(that is, Mod (P g ) = Mod (Q g ) CO problems, ModHT (P g ) = ModHT (Qg ) ASO
problems).
result evident definitions. However, also immediate consequence
Theorem 13. Indeed, optimization problems P Q empty selectors, cong
g
dition >PMod(P g ) = >Q
Mod(Q g ) equivalent Mod (P ) = Mod (Q ), consequence
strong equivalence P g Qg . Thus, problems empty selectors right
hand equivalence assertion Theorem 13 reduces strong equivalence
generators.

5. Strong Equivalence Combined Case
Finally, consider relation sg , results considering contexts combine
generators selectors. Since generators may vary here, previous section,
semantics generators matters. But, previous section, difference boils
different characterizations strong equivalence generators.
start result characterizing strong equivalence CO ASO problems
relative combined contexts (both generators selectors possibly non-empty)
selectors consisting rules rank least j, respectively.
Theorem 16 ranked CO (ASO, respectively) problems P Q, every rank
s,[i,j]
interval [i, j], P g
Q following conditions hold:
1. P g Qg strongly equivalent (that is, Mod (P g ) = Mod (Q g ) CO problems,
ModHT (P g ) = ModHT (Qg ) ASO problems)
2. >PMod(P g ) = >Q
Mod(Q g )
3. every I, J Mod (P g ) < diff P (I, J) < diff Q (I, J), diff P (I, J) =
diff Q (I, J) diff P (I, J) > j diff Q (I, J) > j
P

Q

<i
<i
4. >Mod(P
g ) = >Mod(Q g ) .

corresponding characterizations CO ASO problems differ respective conditions (1), reflect different conditions guaranteeing strong equivalence generators classical answer-set semantics. Moreover, four conditions Theorem 16 obtained suitably combining extending conditions
Theorem 6 Theorem 13. First, combined strong equivalence implies strong genequivalence, condition (1) taken Theorem 13. Second, modify conditions (2)
(3) Theorem 6 replacing (P<i ) Mod (P g ) (and accordingly (Q<i )
Mod (Qg )), classical model P g give rise optimal classical equilibrium
one upon addition context, aspect also already visible Theorem 13.
Finally, add new condition stating relations >P<i >Q<i coincide
sets models P g Qg . generators allowed extended, one
make two models outcomes extension. two
371

fiFaber, Truszczynski, & Woltran

outcomes, say J, related differently corresponding strict relations induced
rules ranks less i, say >P<i J >Q<i J, optimal J
optimal problem extending P matter preference rules ranks
interval [i, j] use (rules rank higher effect J ordered).
hand, J incomparable >Q<i , remain incomparable
Q extended. J equally good respect rules rank < i,
rendered incomparable means preference rules rank i. case, J optimal
Q extended. Finally, J >Q<i I, J remains optimal matter preference
rules ranks higher add. follows two relations >P<i >Q<i
s,[i,j]
different, cannot P g
Q condition (4) necessary.
previous section, case selectors P Q empty reduces
strong gen-equivalence generators.
Corollary 17 CO (ASO, respectively) problems P Q P = Qs =
s,[i,j]
, every rank interval [i, j], P g
Q P g Qg strongly
equivalent respective semantics (that is, Mod (P g ) = Mod (Q g ) CO problems,
ModHT (P g ) = ModHT (Qg ) ASO problems).
result simple consequence Theorem 16. condition (1) theorem
implies Mod (P g ) = Mod (Q g ) so, since selectors P Q empty,
remaining conditions become trivially true.
conclude section observations concerning relation sg CO
ASO problems. contexts relevant may contain preference rules arbitrary ranks.
start case CO problems, results stronger.
derived general theorems above, present arguments relying results
previous sections, possible since CO problems equivalence strong
equivalence generators coincide.
saw last section CO problems strictly stronger relation
g . fact, CO problems, coincides general relation sg .
Theorem 18 CO problems P Q, P sg Q P Q.
Proof. only-if implication evident. prove converse implication,
use Proposition 4, reduces checking strong equivalence checking strong
sel-equivalence. Let R LgU generator problem. Since P Q, Corollary 8
Mod (P g ) = Mod (Qg ). Consequently, Mod ((P R)g ) = Mod ((Q R)g ). Writing
Mod (P g ) 0 Mod ((P R)g ) 0 . Thus, also Corollary 8,
QR
>PMR
0 =>M 0 . Finally, condition (3) Corollary 8 P Q implies condition (3)
corollary P R Q R (as R preference rules 0 ). follows,
Corollary 8, P R Q R. Thus, Proposition 4, P sg Q. 2
case simple CO problems ranked interval [1, 1], argument
repeated using instead Corollary 8 equivalence (b) (c) Corollary
9. way, one show simple CO problems, relations s,=1
s,=1
g
coincide. Thus, Corollary 9 (the equivalence (a) (b)) Theorem 18, simple
CO problems four relations sg , s,=1
, s,=1 , coincide obtain following
g
result.
372

fiStrong Equivalence Qualitative Optimization Problems

Corollary 19 simple CO problems P Q, properties P sg Q, P s,=1
Q,
g
P s,=1 Q P Q equivalent.
simple ASO problems still sg s,=1
coincide general
g
notions different s,=1 (cf. subtle difference condition (c) compared
Corollary 9).
Corollary 20 simple ASO problems P Q, following conditions equivalent
s,[1,]

(a) P sg Q (equivalently, P g

Q)

s,[1,1]

(b) P s,=1
Q (equivalently, P g
g

Q)

(c) ModHT (P g )=ModHT (Qg ) PMod(P g ) = Q
Mod(Qg ) .
Proof. implication (a)(b) evident.
Let us assume (b). Theorem 16, ModHT (P g )=ModHT (Qg ). identity
implies Mod (P g ) = Mod (Qg ). Let us assume I, J Mod (P g ), PMod(P g ) J.
Q
>PMod(P g ) J then, Theorem 16, >Q
Mod(Qg ) J so, Mod(Qg ) J. Otherwise,

P J so, diff P (I, J) = . Theorem 16, diff Q (I, J) > 1. Since Q simple,
diff Q (I, J) = . Thus, Q J and, also, Q
Mod(Qg ) J. converse implication follows
symmetry. Thus, (c) holds.
Finally, assume (c) prove (a). end, show conditions (1)(4)
Theorem 16 hold. Directly assumptions, condition (1) holds. Condition (2) follows Lemma 1. Moreover, also Mod (P g ) = Mod (Qg ). prove
condition (3), let us assume I, J Mod (P g ) diff P (I, J) > 1. Since P simple,
P J. Thus, Q J and, consequently, diff P (I, J) = = diff Q (I, J). Finally, condition
P<i
Q<i
g
g
(4), i.e. >Mod(P
g ) = >Mod(Q g ) , obviously holds case = 1 Mod (P ) = Mod (Q ). 2

6. Complexity
section, study problems deciding various notions strong equivalence.
Typically comparisons sets outcomes characterizations determine
respective complexity. start results concerning strong sel-equivalence.
Theorem 21 Given optimization problems P Q, deciding P Q co-NP-complete
case CO problems P2 -complete case ASO problems.
Proof. [Sketch, detailed argument provided Appendix B.] membership, focus
complementary problem consider pairs interpretations I, J violate least
one conditions stated Corollary 8. Clearly, witness pair interpretations
exists, also witness pair built atoms occur
problems P Q. pair guessed, verified polynomial time (for
CO problems) polynomial time using NP oracle (for ASO problems) indeed
373

fiFaber, Truszczynski, & Woltran

violates conjunction three conditions Corollary 8. main observation
model checking polynomial classical semantics, co-NP-complete
equilibrium semantics (see Pearce, Tompits, & Woltran, 2009, Thm. 8).
Hardness follows considering equivalence problem optimizations problems
empty selectors, known co-NP-hard (for classical semantics) P2 hard (for equilibrium semantics, see Pearce et al., 2009, Thm. 11). 2
ranked case, observe increase complexity, explained
characterization given Theorem 6. Instead outcome checking, characterization
involves optimal outcome checking, difficult (unless polynomial hierarchy
collapses).
Theorem 22 Given optimization problems P Q rank interval [i, j], deciding
P s,[i,j] Q P2 -complete case CO problems P3 -complete case ASO
problems.
Proof. [Sketch, detailed argument provided Appendix B.] membership part essentially follows arguments proof Theorem 21, problem
deciding (P<i ) co-NP CO problems P2 ASO problems.
hardness part, reduce following problem sel-equivalence CO problems: Given two propositional theories , decide whether possess
minimal models. problem known P2 -complete (e.g., Eiter et al., 2007b,
Thm. 6.15), problem remains hard negation normal form (NNF)
given alphabet. adapt construction used Brewka et al., (2011).
Given negation normal form theory , construct CO problem PT setting
PTg

= [u/u0 ] {u u0 | u U },

PTs

= {u0 > u | u U },

U denotes set atoms occurring , [u/u0 ] stands theory
resulting replacing u u0 (we note ranks rules selector
1).
elements (PT ) one-to-one correspondence minimal models
. theories U follows minimal models
(PS ) = (PT ). Since problems PS PT selectors,
latter condition equivalent PS s,2 PT (which shown directly exploiting
characterization s,2 ).
Concerning hardness part ASO problems, use following problem: given
two open quantified Boolean formulas (QBFs) (X, ), (X, ), decide whether
possess minimal models. problem P3 -hard (see Lemma 30 Appendix
A). (X, ), construct P follows:
Pg = {z z 0 | z X }
{(y 0 ) w, w y, w 0 | }
{[z/z 0 ] w, w w},
Ps = {x0 > x | x X},
374

fiStrong Equivalence Qualitative Optimization Problems

[z/z 0 ] stands formula obtained replacing z z 0 (X, ) (again,
stress ranks rules selector 1). elements (P )
one-to-one correspondence minimal models (X, ). reason
show X , formulas (X, ) (X, )
minimal models P s,2 P . 2
Theorem 22 rank interval [i, j] given input. fixing interval,
hardness results still hold, provided > 1. fact, critical condition Corollary 7
(P<i ) = (Q<i ); rank intervals [1, j], selectors become empty condition
reduced (P ) = (Q), easier decide.
characterizations imply remaining problems co-NP. strong
gen-equivalence, co-NP-hardness follows directly Theorem 13 co-NP-completeness
deciding strong equivalence two propositional theories (for semantics).
Theorem 23 Given two CO (ASO, respectively) problems P Q, deciding P g Q
co-NP-complete.
Finally, combined case hardness result follows Theorem 16 co-NPcompleteness deciding strong equivalence propositional theories.
Theorem 24 Given ranked CO (ASO, respectively) problems P Q, rank interval
s,[i,j]
[i, j], deciding P g
Q co-NP-complete.
construction, hardness results hold already simple optimization problems.

7. Discussion
introduced formalism optimization problems, generalizing principles ASO
programs, particular, separation hard soft constraints (Brewka et al., 2003).
focused two important specializations optimization problems: CO problems
ASO problems. studied various forms strong equivalence classes optimization problems, depending contexts considered. Specifically, considered
following cases: new preference information added, hard constraints remain unchanged (strong sel-equivalence); hard constraints added preferences remain
unchanged (strong gen-equivalence); hard constraints preferences added
(strong equivalence). best knowledge, natural classification equivalences preference formalisms studied yet. certain cases
notions coincide (Theorem 18) longer true underlying semantics
changed ranks contexts restricted.
previous work, notion strong equivalence (both hard constraints preferences
added) studied logic programs weak constraints Eiter et al.,
(2007a) logic programs ordered disjunctions (LPODs) Faber et al., (2008).
former formalism, separation strong equivalence different notions
suggested ASO problems would possible (it instructive compare
Eiter et al., 2007a, Lemma 23, results, e.g., Corollary 20), similar separation
strong equivalence straightforward LPODs. reason syntactic nature
LPOD rules act like hard constraints preference rules time. Faber et
375

fiFaber, Truszczynski, & Woltran

al., (2008) considered strong equivalence respect contexts logic programs
(which similar strong gen-equivalence) combined case strong equivalence
(called strong equivalence arbitrary contexts there), consider
counterpart notion strong sel-equivalence. fact, even unclear whether
every LPOD generating selecting modules cleanly separated.
paper, established characterizations three types strong equivalence.
exhibit striking similarities. characterizations strong sel-equivalence CO
ASO problems Theorem 6 precisely same, mirroring fact generators subject change. Theorem 13 concerns strong gen-equivalence CO
ASO problems. case, characterizations consist two requirements: strong
equivalence generators, equality strict preference relations restricted
class models generators. difference comes fact strong
equivalence classical equilibrium-model semantics different characterizations. Theorem 16 concerns combined case strong equivalence also
differentiate CO ASO problems implicitly (as before, conditions
strong equivalence different two semantics). Moreover, characterizations
provided Theorem 16 arise rather systematic way given Theorems 6
13. case different semantics used strongly suggests
abstract principles play here. currently pursuing direction,
conjecturing inherent feature preference formalisms separation
logical preferential constraints.
Coming back LPODs, comments suggest identifying split representation formalism might interest. could lead alternative characterizations (combined) strong equivalence derived characterizations two
one-dimensional variants.
Next, note results give rise problem rewriting methods transform
optimization problems strongly equivalent ones. provided two simple examples
illustrating application results Example 9 Corollary 12. Similar examples
constructed results concerning strong gen-equivalence (combined) strong
equivalence. systematic study optimization problem rewriting rules result
strongly equivalent problems subject future work.
Finally, established complexity deciding whether optimization problems
strongly equivalent. Notably, general case strong (combined) equivalence problem co-NP-complete CO ASO problems. holds true strong
gen-equivalence problem. strong sel-equivalence problem, situation
complex. contexts form [1, j] [1, ] considered, problem deciding
strong sel-equivalence co-NP-complete CO problems P2 -complete ASO problems. rank interval allowed part input rank interval fixed [i, j],
2, problem gets computationally harder: case ASO problems, P3 -hard;
case CO problems P2 -hard. difference CO problems ASO problems
case strong sel-equivalence respect contexts consisting preference rules
ranks intervals [1, j] [1, ] comes fact corresponding concepts
strong sel-equivalence depend, particular, whether two theories equivalent
respect models (CO problems) respect equilibrium models (ASO problems).
two types equivalence different complexities. jump complexity
376

fiStrong Equivalence Qualitative Optimization Problems

strong sel-equivalence arbitrary rank intervals [i, j] allowed fixed
2 comes fact cases, concept depends properties
class outcomes optimal respect rules ranks less i,
cases depends properties class models. Decision problems concerning optimal
outcomes (such as: two theories optimal models) harder
corresponding versions problems models, explaining jump. results
strong sel-equivalence also imply ranked optimization problems cannot efficiently
simulated simple optimization problems.

Acknowledgments
thank reviewers useful constructive comments. first author
supported Regione Calabria EU POR Calabria FESR 2007-2013 within
PIA project DLVSYSTEM s.r.l., MIUR PRIN project LoDeN.
second author supported NSF grant IIS-0913459.

Appendix A. Useful Lemmas
provide several lemmas use later proofs results discussed
main body paper.
first two lemmas given without proofs, easy consequences results
Ferraris (2005) Ferraris Lifschitz (2005).
Lemma 25 Let P theory, classical model P , let [I] = {a |
U \ I} {a | I}. Then, (P [I]) = Mod (P [I ]) = {I}.
Lemma 26 Let P theory, I, J two (classical) models 6= J, let
[I, J] = {a b | I, b J}
{a b | I, b U \ J}
{a b | U \ I, b J}
{a b | U \ I, b U \ J}.
(P [I, J]) = Mod (P [I , J ])) = {I, J}.
Lemma 27 Let P optimization problem, (P<j ), j 1, let
j

j

Rj [I] = {a > > | I} {a > > | U \ I)}.

1. (P Rj [I]);
2. every J J 6= Pj J, >P Rj [I] J.
377

fiFaber, Truszczynski, & Woltran

Proof. proving (1), simplify notation, write R Rj [I]. Since (P<j ),
(P ). Clearly, (P R) = (P ) so, (P R). show (P R),
let us consider arbitrary interpretation J (P R) assume J >P R I.
particular, J 6= so, diff R (I, J) = j. diff P (I, J) < j, diff P R (I, J) < j.
Consequently, J >(P R)<j I. Since rules R rank j, follows J >P<j I,
contradiction fact (P<j ). Thus, diff P (I, J) j. Since diff R (I, J) = j,
diff P R (I, J) = j. Therefore, J >P R implies J >R I, contradiction
(since, definition Rj [I] = R, R J interpretation J). follows
every J (P R), J 6>P R I, is, (P R).
assertion (2) evident, since definition Rj [I] = R, >R J interpretation J 6= I. 2

Lemma 28 Let P optimization problem, I, J interpretations I, J (P<j ),
union following sets rules:
j 1, let Rj0 [I, J] Ls,j
U
j

{a b > > | a, b J}
j

{a b > > | I, b U \ J}
j

{a b > > | U \ I, b J}
j

{a b > > | U \ I, b U \ J}.
following hold:
1. every r Rj0 [I, J], vI (r) = vJ (r) = 1;
2. every interpretation K
/ {I, J}, rule r Rj0 [I, J] vK (r) = 2;
3. >P J J
/ (P Rj0 [I, J]).
Proof. simplify notation, write R0 Rj0 [I, J].
assertion (1) evident. prove assertion (2), note conjunction
formulas appear top options preference rules R0 equivalent
^
^
^
^


{a | I} {a | U \ I}
{b | b J} {b | b U \ J} .
formula two models: J. Thus, every interpretation K,
least one formulas appears top options preference rules R0
satisfied K. corresponding preference rule r, vK (r) = 2.
Finally, prove assertion (3), let us assume >P J. Together (1),
0
implies >P R J. Thus, J
/ (P R0 ). prove converse implication, let us
0
assume 6>P J. Together (1), implies 6>P R J. Next, note
0
diff P (J, K) < j, since J (P<j ), K 6>P R J. diff P (J, K) j, property (2)
0
proved implies K 6>P R J. Since K arbitrary interpretation different
0
J, since 6>P R J, J (P R0 ) follows. 2

378

fiStrong Equivalence Qualitative Optimization Problems

Next, note property allows us infer strong sel-equivalence two problems treated CO problems strong sel-equivalence problems
treated ASO problems (and conversely). property relies fact changing
selectors affect class outcomes. proof simple omit it.
Lemma 29 Let P Q optimization problems Mod (P g ) = (P g )
Mod (Q g ) = (Qg ), [i, j] rank interval. Then, P s,[i,j] Q P Q viewed
CO problems, P s,[i,j] Q P Q viewed ASO problems.
final results section useful complexity results.
Lemma 30 Deciding whether open QBFs (X, ) (X, ),
negation normal form, minimal models P3 -hard.
Proof. show result reduction P3 -hard problem deciding satisfiability QBFs form ZXY , negation normal form. Let
QBF form consider following formulas, Z 0 = {z 0 | z Z}, u
v fresh atoms:
^
^

=
(z z 0 ) (
x u) (v v)
zZ

=

^
zZ

xX
0

(z z ) (

^


x v) (u u).

xX

clear negation normal form. difference
compared latter uses u former uses v vice versa,
point including conjuncts v v u u occurrences u v
. show (U, ) (U, ) minimal models
(with open variables U = Z Z 0 X {u, v}) true.
note considering models minimal models (U, ) (U, )
move quantifier appears directly front .
occurrences atoms outside .
also clear contains neither u v, model (U, )
model (U, ). Consequently, holds
minimal model (U, ) minimal model (U, ).
Only-if direction: Let us assume false. Then, exists interpretation Z
atoms Z, every interpretation J atoms X, false. Let us
consider Mu = (Z \ I)0 X {u}. Clearly, Mu model YV. N model
N Mu , (Z \ I)0 N conjunct zZ (z z 0 ). Thus,
N Z = I. follows false atoms Z X interpreted N and,
consequently, X {u} N . Thus, N = Mu , implies Mu minimal model
. Essentially argument shows Mv = (Z \ I)0 X {v} minimal
model . Since Mu 6= Mv , different minimal models.
If-direction: Let us assume ZXY true. Let minimal model .
Clearly, v
/ (as \ {v} also model ). Let us assume u . Let us
assume addition X \ 6= . assumptions imply interpretations
379

fiFaber, Truszczynski, & Woltran

= Z atoms Z J = X atoms X, true. follows \{u}
model , contradiction. Thus, X . Let = Z. Since ZXY
true, interpretation J X atoms X true, atoms
Z interpreted atoms X interpreted J. follows (Z \ I)0 J
model . Since (Z \ I)0 J , contradiction. follows
u
/ . Consequently, comment above, minimal model . converse
holds symmetry argument. Thus, two formulas minimal models. 2

Lemma 31 Given ranked preference rule r, interpretation I, calculating vI (r)
done polynomial time.
Proof. Initialize variable 1. Check whether 6|= bd (r) so, halt. Then, check
whether |= hd (r) so, halt; otherwise increment continue checking;
options head r exist, set = 1. checks model checking task
propositional formula hence polynomial time. Upon halting, equal vI (r). 2

Lemma 32 Given optimization problem P two interpretations I, J, calculating
diff P (I, J) done polynomial time.
Proof. Initialize variable x , scan rules P ranked preference
rule r P , determine whether vI (r) 6= vJ (r) (in polynomial time due Lemma 31). so,
set x rank (r) rank (r) < x. processed rules, x equal diff P (I, J). 2

Lemma 33 Given optimization problem P , two interpretations I, J, deciding whether
>P J holds done polynomial time.
Proof. First, sort rules P ranks. Starting lowest rank upwards,
following rank i: Check rules rank whether vI (r) < vJ (r)
vI (r) vJ (r). vI (r) < vJ (r) holds least one rule vI (r) vJ (r)
rules rank i, accept. rules r r0 rank vI (r) < vJ (r)
vI (r0 ) > vJ (r0 ), reject. ranks processed, reject. Lemma 31, steps
doable polynomial time. 2

Lemma 34 Given classical optimization problem P interpretation I, deciding
whether (P ) co-NP.
Proof. show witness J complementary problem (deciding whether

/ (P )) verified polynomial time. J = I, verify polynomial time
satisfy propositional theory P g , well-known feasible polynomial time. Otherwise, verify polynomial time J satisfies P g J >P (both
polynomial time, latter Lemma 33). 2

380

fiStrong Equivalence Qualitative Optimization Problems

Lemma 35 Given answer set optimization problem P interpretation I, deciding
whether (P ) P2 .
Proof. show witness J complementary problem (deciding whether

/ (P )) verified polynomial time using NP oracle. J = I, verify
satisfy P g using NP oracle. possible answer-set checking
co-NP-complete (Pearce et al., 2009, Thm. 8). Otherwise, verify using NP oracle J
satisfies propositional theory P g J >P (in polynomial time Lemma 33). 2

Appendix B. Proofs
Theorem 6 ranked optimization problems P Q, every rank interval [i, j],
P s,[i,j] Q following conditions hold:
1. (P<i ) = (Q<i )
2. >P(P<i ) = >Q
(Q<i )
3. every I, J (P<i ) < diff P (I, J) < diff Q (I, J), diff P (I, J) =
diff Q (I, J) diff P (I, J) > j diff Q (I, J) > j.
s,[i,j]

Proof. () Let R LU
let (P R). Lemma 3, ((P R)<i ). Since
s,[i,j]
R LU , R<i = (, ). Thus, (P<i ). assumption, follows (Q<i ).
particular, (Q<i ) and, (Q<i ) = (Q), (Q). Since Rg = ,
(Q R). show (Q R) show J (Q R)
J >QR I. Let us assume contrary J exists. Lemma 5,
three possibilities.
First, assume diff Q (I, J) < diff R (I, J) J >Q I. latter property
implies diff Q (I, J) (otherwise, would J >Q<i I, contrary (Q<i )).
particular, Q<i J and, since (Q<i ), follows J (Q<i ).
(1), J (P<i ). Thus, (2), J >P I. diff Q (I, J) j diff R (I, J) > j and,
s,[i,j]
R LU , diff R (I, J) = . Since J >P I, J >P R I. Otherwise, diff Q (I, J) < j.
< diff Q (I, J) then, (3), diff P (I, J) = diff Q (I, J). = diff Q (I, J), (3),
diff P (I, J) i. either case, diff P (I, J) < diff R (I, J). Since J >P I, J >P R I.
s,[i,j]
Next, let us assume diff Q (I, J) > diff R (I, J) J >R I. Since R LU ,
follows diff R (I, J) so, diff Q (I, J) > i. recall (Q<i ).
Thus, J (Q<i ) and, consequently, J (P<i ). diff Q (I, J) j then, (3),
diff P (I, J) = diff Q (I, J) so, diff P (I, J) > diff R (I, J). j < diff Q (I, J) then, also
(3), j < diff P (I, J). Since diff Q (I, J) > diff R (I, J), diff R (I, J) < and, consequently,
diff R (I, J) j. Thus, diff P (I, J) > diff R (I, J) case, too. Since J >R I, J >P R
follows.
Finally, let us assume diff Q (I, J) = diff R (I, J), J >Q J >R I. Since
s,[i,j]
R LU , diff R (I, J) i. Thus, diff Q (I, J) and, since (Q<i ), J (Q<i ).
(1) J (P<i ) and, (2), J >P I. Consequently, J >P R I.
cases obtained J >P R I, contrary (P R), contradiction.
381

fiFaber, Truszczynski, & Woltran

() Let us assume (P<i ) 6= (Q<i ). Without loss generality, assume
(P<i ) \ (Q<i ) define R = (, Ri [I]) LUs,=i , Ri [I]
Lemma 27. lemma, (P R). hand, since
/ (Q<i )
s,=i Q, contrary
R Ls,=i
,


/
((Q

R)
).

Lemma
3,


/
(Q

R).
Thus,
P

6
<i
U
assumption.
follows (P<i ) = (Q<i ), is, condition (1) holds. prove condition
(2), let us consider interpretations I, J (P<i ) >P J. Let Ri0 [I, J]
selector defined Lemma 28. Since >P J, Lemma 28(3) implies J
/ (P Ri0 [I, J]).
Consequently, J
/ (Q Ri0 [I, J]). Lemma 28(3) again, follows >Q J.
Q
symmetry, > J implies >P J so, condition (2) holds.
prove condition (3), let us assume interpretations J satisfy
assumptions violate corresponding conclusion. follows, write p
diff P (I, J) q diff Q (I, J). Thus, p > q > i, p 6= q, p j
q j. Without loss generality, assume p < q. follows p finite and,
consequently, diff P (I, J) < 6= J. Moreover, < q p j.
Let us assume first p < i. take problem R = (, Ri [J]), Ri [J]
specified Lemma 27 define P 0 = P R Q0 = Q R. Since I, J (P<i )
also I, J (Q<i ). assumptions, q > i. Thus, J Qi and, particular,
J Qi I. recall 6= J. Consequently, assertion (2) Lemma 27
0
0 ) diff P 0 (I, J) =
J >Q I. Since rules R ranks i, I, J (P<i
0
0
diff P (I, J) < i. follows J 6>P (otherwise, diff P (I, J) < would
0
J >P<i I). Let us define R0 = (, Ri0 [I, J]), Ri0 [I, J] specified Lemma 28. Since
0
J 6>P I, assertion (3) lemma, (P 0 R0 ). P 0 R0 = P (R R0 ).
Thus, (P (R R0 )) and, P s,[i,j] Q, (Q (R R0 )) = (Q0 R0 ).
0
assertion (3) Lemma 28, J 6>Q I, contradiction.
Next, let p = i. Clearly, 6>P J J 6>P I. Without loss generality, let us assume
J 6>P I. Let R0 = (, Ri [I, J]), let us define P 0 = P R0 Q0 = Q R0 . Since
0 ). Moreover, J 6>P
rules R0 ranks i, I, J (P<i ) implies I, J (P<i
0
follows Lemma 28(1) J 6>P I. Let R = (, Ri [J]). rules R rank
0
0
diff P (I, J) = diff P (I, J) = i. Thus, follows J 6>P R I. Moreover, every
0
0
0 ). diff P 0 (K, I) i,
K
/ {I, J}, diff P (K, I) < i, K 6>P R follows (P<i
0
K 6>P R follows Lemma 28(2). Thus, (P 0 R). hand,
0
recall diff Q (I, J) = q > i. Thus, diff Q (I, J) > i, (Lemma 28(1)). follows
0
0
J Qi I. Consequently, Lemma 27(2), J >Q R I. Thus,
/ (Q0 R),
contradiction.
follows p > i. complete proof (3), recall p j. Clearly, 6>P J
J 6>P I. Without loss generality, let us assume J 6>P I. Let R0 = (, Ri [I, J]),
let us define P 0 = P R0 Q0 = Q R0 . Let us assume interpretation K
/
0
P0
P
P
{I, J}, K > I. Lemma 28(2), follows diff (I, K) < i. Thus, diff (I, K) < i,
0
contradiction (P<i ). Thus, every interpretation K
/ {I, J}, K 6>P
0
and, argument, K 6>P J. Consequently, every interpretation K
/ {I, J},
0
0
P<p
P<p
K 6>
K 6>
J. addition, since I, J (P<i ), Lemma 28(1) obtain
0
0
0 ). addition, Lemma 28(1),
neither >P<p J J >P<p I. Thus, I, J (P<p
0
0
diff P (I, J) = diff P (I, J) = p and, since J 6>P I, J 6>P I.
382

fiStrong Equivalence Qualitative Optimization Problems

0

0

Let R = (, Rp [J]). (i) diff P (I, J) = p, (ii) J 6>P I, (iii) rules R
0
0
rank p, follows J 6>P R I. Moreover, every K
/ {I, J}, diff P (K, I) < i,
0
0
0
0 ). diff P (K, I) i, K 6>P R follows
K 6>P R follows (P<i
Lemma 28(2) (and definition P 0 ). Thus, (P 0 R). hand,
0
recall diff Q (I, J) = q > p. Thus, diff Q (I, J) > p, (Lemma 28(1)). follows
0
0
/ (Q0 R),
J Qp I. Consequently, Lemma 27(2), J >Q R I. Thus,
s,[i,j]
0
0
0
contradiction (we recall P
Q, P = P (R R ), Q = Q (R R0 ), and,
s,[i,j]
p j, R R0 LU ). 2
Theorem 13 CO (ASO, respectively) problems P Q, P g Q
P g Qg strongly equivalent (that is, Mod (P g ) = Mod (Q g ) CO problems,
ModHT (P g ) = ModHT (Qg ) ASO problems) >PMod(P g ) = >Q
Mod(Q g ) .
Proof. () first assumption implies strong equivalence generators P g Qg
relative corresponding semantics (we recall case classical semantics,
strong standard equivalence coincide). follows every problem R LgU ,
(P R) = (Q R). Moreover, semantics, (P R) Mod (P g Rg ) Mod (P g )
and, similarly, (Q R) Mod (Qg Rg ) Mod (Qg ). Since >PMod(P g ) = >Q
Mod(Q g ) ,
QR
R
Lemma 2,
R LgU change preferences, >P(P
g Rg ) = >(Qg Rg ) .
(P R) = (Q R).

() Let us assume P g Qg strongly equivalent. Then, problem
R LgU (P R) 6= (Q R). Without loss generality, assume
interpretation I, (P R) \ (Q R). Let us define problem LgU setting
= ([I], ), [I] defined Lemma 25. lemma, (P R ) = {I}
(Q R ) = . former property implies necessarily preferred,
(P RT ), latter one implies (QRT ) = . contradiction
assumption P g Q. Thus, P g Qg strongly equivalent, is, Mod (P g ) =
Mod (Qg ), case P Q CO problems, ModHT (P g ) = ModHT (Qg ),
case P Q ASO problems.
Since ModHT (P g ) = ModHT (Qg ) implies Mod (P g ) = Mod (Qg ), latter identity holds
two cases. equality, write Mod (P g )
Mod (Qg ). remains show >PM =>Q
. Towards contradiction, let us assume
I, J exactly one two relations; without loss generality
assume >P J 6>Q J. former identity implies, particular,
6= J. Let = ([I, J], ), [I, J] theory defined Lemma 26. lemma,
(P ) = (Q ) = {I, J}. Clearly, J
/ (P ) J (Q ), contrary
assumption P g Q. 2
Theorem 16 ranked CO (ASO, respectively) problems P Q, every rank
s,[i,j]
interval [i, j], P g
Q following conditions hold:
1. P g Qg strongly equivalent (that is, Mod (P g ) = Mod (Q g ) CO problems,
ModHT (P g ) = ModHT (Qg ) ASO problems)
2. >PMod(P g ) = >Q
Mod(Q g )
383

fiFaber, Truszczynski, & Woltran

3. every I, J Mod (P g ) < diff P (I, J) < diff Q (I, J), diff P (I, J) =
diff Q (I, J) diff P (I, J) > j diff Q (I, J) > j
P

Q

<i
<i
4. >Mod(P
g ) = >Mod(Q g ) .

Proof. () Proposition 4, suffices prove every R LgU , P R s,[i,j] QR.
(1), (P R) = (Q R) (we recall (P ) denotes set outcomes optimization problem P ; (P ) = Mod (P g ) case CO problems,
(P ) = (P g ) case ASO problems). Moreover, type problems, also
(P R) Mod (P g R g ) Mod (P g ) and, similarly, (Q R) Mod (Q g R g )
Mod (Q g ). Since rules R rank least i, condition (4) follows
(P R)
(QR)
>(P R)<i =>(QR)<i . Lemma 2, ((P R)<i ) = ((Q R)<i ) so, condition
(1) Theorem 6 holds P R Q R. Since ((P R)<i ) (P R) Mod (P g ),
since corresponding inclusions hold Q, too, conditions (2)(3) theorem
P Q imply conditions (2)(3) Theorem 6 P R Q R. Thus,
Theorem 6, P R s,[i,j] Q R.
s,[i,j]

() Let us assume P g
Q. Then, P g Q follows and, Theorem 13, implies
appropriate version condition (1). Since ModHT (P g ) = ModHT (Qg ) implies Mod (P g ) =
Mod (Q g ), two versions assertion Mod (P g ) = Mod (Q g ).
proof, write Mod (P g ) and, equality, also
Mod (Q g ).
Next, interpretations I, J 6= J, define R = ([I, J], ),
[I, J] Lemma 26. Let us define P1 = P R Q1 = QR. P1 s,[i,j] Q1 .
Moreover, Lemma 26, also (P1 ) = (Q1 ) = {I, J}.
prove condition (4), let us assume >P<i J. follows >P1 J (we recall
R contains preference rules). Since (P1 ) = {I, J}, J
/ (P1 ) (P1 ).
assumption, J
/ (Q1 ). Since (Q1 ) = {I, J}, >Q1 J. particular,
(Q1 ). diff Q (I, J) < then, since R preference rules, >Q<i J. Thus, let us
assume diff Q (I, J) let us define R0 = (, Ri [J]), Ri [J] Lemma
27. Since (i) >P<i J, (ii) R preference rules, (iii) preference rules R0
0
rank i, follows >P1 R J. generator module R0 empty. follows
(P1 R0 ) = (Q1 R0 ) = {I, J}. Thus, J
/ (P1 R0 ) and, consequently, J
/ (Q1 R0 ).
Q
Q1
Since diff (I, J) i, diff (I, J) i. Moreover, (Q1 ) so, also ((Q1 )<i ).
Thus, J ((Q1 )<i ). Lemma 27, J (Q1 R0 ), contradiction. argument shows
>P<i J implies >Q<i J. converse implication follows symmetry so,
condition (4) holds.
prove condition (2), let us assume >P J. diff P (I, J) < i, >P<i J
and, (4), >Q<i J. Thus, >Q J. Let us assume diff P (I, J) i. Since
(P1 ) = {I, J} since >P J implies >P1 J, J
/ (P1 ). Thus, J
/ (Q1 ). Since
(Q1 ) = {I, J}, >Q1 J so, >Q J.
prove condition (3), without loss generality assume < diff P (I, J). Thus,
also < diff P1 (I, J) I, J ((P1 )<i ), latter follows properties (P1 ) = {I, J} diff P1 (I, J) = diff P (I, J) > i. Since P1 s,[i,j] Q1 ,
condition (3) Theorem 6 holds P1 , Q1 , J, is, diff P1 (I, J) = diff Q1 (I, J)
diff P1 (I, J) > j diff Q1 (I, J) > j. Consequently, diff P (I, J) = diff Q (I, J)
384

fiStrong Equivalence Qualitative Optimization Problems

diff P (I, J) > j diff Q (I, J) > j, is, condition (3) holds. 2
Theorem 21 Given optimization problems P Q, deciding P Q co-NP-complete
case CO problems P2 -complete case ASO problems.
Proof. membership, consider complementary problem. Corollary 8,
specified problem decide whether least one conditions (1) - (3)
holds:
1. (P ) 6= (Q), equivalently, I, exactly one identities (P )
(Q) holds;
2. I, J (P ), diff P (I, J) 6= diff Q (I, J);
3. >P(P ) 6= >Q
(Q) , equivalently, I, J, I, J (P ) (Q) exactly
one properties >P J >Q J holds.
show problem NP CO problems P2 ASO problems.
say pair interpretations I, J witness instance problem
YES instance demonstrates one conditions (1) - (3) hold. easy see
witness exists, witness I, J J consist atoms
occur P Q. witness guessed, condition (1) verified
polynomial time CO problems (this model-checking problem interpretation
theory) and, ASO problems, polynomial time assist two calls
NP oracle, since model checking equilibrium-model semantics co-NP-complete
(Theorem 8, Pearce et al. (2009)). Since condition (2) verified polynomial time
Lemma 32, condition (3) polynomial time CO problems polynomial time
assist four calls NP oracle ASO problems (Lemma 33 result
Pearce et al., (2009) mentioned above), membership part assertion follows.
hardness, observe case problems empty selectors, coincides
equivalence propositional theories case CO problems, equivalence
equilibrium theories case ASO problems. former well known co-NP-hard,
latter P2 -hard (Theorem 11, Pearce et al. (2009)). 2
Theorem 22 Given optimization problems P Q rank interval [i, j], deciding
P s,[i,j] Q P2 -complete case CO problems P3 -complete case ASO
problems.
Proof. prove membership part, consider complementary problem.
Theorem 6, problem consists deciding whether case least one
following conditions holds:
1. (P<i ) 6= (Q<i ), equivalently, interpretation I, exactly one properties (P<i ) (Q<i ) holds;
2. >P(P<i ) 6= >Q
(Q<i ) , equivalently, interpretations I, J (P<i ) (Q<i )
exactly one properties >P J >Q J holds;
3. I, J (P<i ) (Q<i ) < diff P (I, J) < diff Q (I, J),
diff P (I, J) 6= diff Q (I, J) holds diff P (I, J) j diff Q (I, J) j.
385

fiFaber, Truszczynski, & Woltran

call pair interpretations I, J demonstrates one conditions
holds witness. easy see witness, also one consists
atoms occur P Q. show complementary problem P2
CO problems P3 ASO problems showing witness guessed
verified polynomial time, using NP oracle dealing CO problem
P2 oracle dealing ASO problem.
Consider witness I, J two interpretations. One test whether I, J verifies
condition (1) (only matters here) polynomial time two calls NP oracle CO problems (Lemma 34), two calls P2 oracle ASO problems
(Lemma 35). verify condition (2), need four calls respective oracles test
I, J (P<i ) (Q<i ) polynomial-time computation test exactly one
properties >P J >Q J holds (Lemma 33). Similarly, condition (3), use
four calls respective oracles test I, J (P<i ) (Q<i ) polynomial-time
computation test condition involving diff P (I, J) diff Q (I, J) (Lemma 32).
hardness part, start case CO problems. Therefore, reduce
following problem strong sel-equivalence: given two propositional theories , decide
whether possess minimal models. problem known P2 -complete
(for instance, equivalence positive disjunctive programs known P2 -complete, see
e.g., Eiter et al., 2007b, Thm. 6.15, means testing whether two propositional formulas
particular class minimal models). problem remains hard
negation normal form alphabet. Given negation normal form theory
construct CO problem PT elements (PT ) one-to-one
correspondence minimal models . adapt construction used (Brewka
et al., 2011). Specifically, set
PTg = [u/u0 ] {u u0 | u U },
U collection atoms occurring , [u/u0 ] stands replacing u
u0 ,
PTs = {u0 > u | u U }.
first observation outcome PT must form {y 0 | U \ I}
U . interpretation U write + = {y 0 | U \ I}. clear
|= u + |= u0 , hence also |= + |= [u/u0 ].
Hence one-to-one mapping models outcomes + PT .
let us assume + (PT ). |= , N
N 6|= . Indeed N |= , N + |= PTg rules r PTs form u0 > u,
u \ N , obtain vN + (r) = 1 < 2 = vM + (r) rules r0 PTs
vN + (r0 ) = 2 = vM + (r0 ). implies N + >PT + , contradicting + (PT ). Thus,
minimal model .
Conversely, let us assume minimal model . + (PT )
N + (PT ) N + >PT + hold, implying + (PT ). Indeed,
N + >PT + , vN + (r) < vM + (r) least one r PTs vN + (r0 ) vM + (r0 )
r0 PTs . latter implies N former shows N 6= . Since N |=
contradicts assumption minimal model . follows + (PT ).
thus + (PT ) minimal model . Moreover,
U follows minimal models
386

fiStrong Equivalence Qualitative Optimization Problems

PS s,2 PT . Indeed, R LUs,2 easy verify (PS ) = (PS R)
(PT ) = (PT R). observation follows fact distinct
I, J (PS ) PS J distinct I, J (PT ) PT J. Thus,
rules R which, weaker rank, break ties, affect sets optimal
outcomes.
Concerning hardness ASO problems, use similar idea. However, shall
use following problem: given two open QBFs (X, ), (X, ), decide whether
two QBFs possess minimal models. Lemma 30, problem P3 -hard
and, moreover, assume negation normal form. reduction
combines idea reduction general ASP consistency (Eiter
& Gottlob, 1995). precisely, z X introduce new variable z 0 ,
construct P given (X, ) follows:
Pg = {z z 0 | z X }
{(y 0 ) w, w y, w 0 | }
{[z/z 0 ] w, w w},
[z/z 0 ] stands replacing z z 0 , w globally new atom.
selector set
Ps = {x0 > x | x X}.
equilibrium model Pg must contain w (otherwise w w would unsatisfied),
must also contain {y, 0 | } (otherwise w y, w 0 would
unsatisfied); write W {y, 0 | } {w} set contained equilibrium
model. Moreover, equilibrium model must form V {z 0 | z X \ V } W .
Indeed, one x x0 must hold x X satisfy xx0 , both, otherwise
hM \ {x}, |=HT Pg well, contradicting fact equilibrium model Pg .
interpretation X write + = {x0 | x X \ I} W Pg . One show
model (X, ) + equilibrium model Pg . Indeed,
satisfies (X, ), hI + , + |=HT Pg J + holds hJ, + 6|=HT Pg .
hand, satisfy (X, ) exists J
J 6|= (X, ). follows hI + \ ({y |
/ J} {y 0 | J} {w}), + |=HT Pg (the
key element argument [z/z 0 ] contains occurrences negation,
negation normal form so, + \ ({y |
/ J} {y 0 | J} {w}) 6|= [z/z 0 ];
+
property allows one show hI \({y |
/ J}{y 0 | J}{w}), + |=HT [z/z 0 ] w).
+
Thus, equilibrium model Pg .
correspondence models (X, ) outcomes (equilibrium
models) + P established, handle issue minimality case CO
problems. Let us assume first + (P ). Then, demonstrated, satisfies
(X, ). Moreover, N , N satisfy (X, ). Indeed
N would satisfy (X, ), would (i) N + (P ), (ii) rules r Ps
form u0 > u, u \ N , vN + (r) = 1 < 2 = vM + (r), (iii) rules
r0 Ps , vN + (r0 ) = 2 = vM + (r0 ); three properties would imply N + >P + , contradicting + (P ). Conversely, let us assume minimal model (X, ).
+ (P ) N + (P ) show N + >P + hold
387

fiFaber, Truszczynski, & Woltran

(implying + (P )). end, reason follows. N + >P + would hold,
vN + (r) < vM + (r) least one r Ps , vN + (r0 ) vM + (r0 ), r0 Ps .
course implies N and, since N satisfies (X, ) (we recall N +
equilibrium model Pg so, N model (X, )), contradicts assumption
minimal model (X, ). thus + (P )
minimal model (X, ). fact, reasoning case CO problems,
obtain (X, ) (X, ) minimal models
P s,2 P . 2
Theorem 23 Given two CO (ASO, respectively) problems P Q, deciding P g Q
co-NP-complete.
Proof. Deciding strong equivalence propositional theories classical semantics
co-NP-hard case, strong equivalence equivalence coincide. also coNP-hard equilibrium-model semantics (Lin, 2002). Thus, hardness part
assertion follows Corollary 15.
prove membership, consider complementary problem. Theorem 13,
consists deciding whether least one conditions (1) (2) holds:
1. P g Qg strongly equivalent or, equivalently, Mod (P g ) 6= Mod (Q g ), CO
problems, ModHT (P g ) 6= ModHT (Qg ), ASO problems;
2. >PMod(P g ) 6= >Q
Mod(Q g ) or, equivalently, interpretations I, J models
g
P Qg , exactly one properties >P J >Q J holds.
Consequently, consider pair interpretations I, J witness instance
problem YES instance model (for CO problems) hI, Ji
HT-model (for ASO problems) exactly one two theories P g Qg , I, J
models P g Qg exactly one properties >P J >Q J holds.
easy see witness exists, witness I, J
J consist atoms occur P Q. witness guessed, verifying
(showing condition (1) (2) holds) done polynomial time. well
known checking whether model (hI, Ji HT-model) propositional theory
done polynomial time, holds true deciding >P J >Q J
(Lemma 33). Thus, complementary problem NP. 2
Theorem 24 Given ranked CO (ASO, respectively) problems P Q, rank interval
s,[i,j]
[i, j], deciding P g
Q co-NP-complete.
Proof. membership, consider complementary problem. Theorem 16,
consists deciding whether least one conditions (1) - (4) holds:
1. P g Qg strongly equivalent (that is, Mod (P g ) 6= Mod (Q g ) CO problems,
ModHT (P g ) 6= ModHT (Qg ) ASO problems);
2. interpretations I, J models Mod (P g ) Mod (Q g ), exactly
one properties >PMod(P g ) J >Q
Mod(Q g ) J holds;
388

fiStrong Equivalence Qualitative Optimization Problems

3. I, J Mod (P g ) < diff P (I, J) < diff Q (I, J), diff P (I, J) 6=
diff Q (I, J) holds diff P (I, J) j diff Q (I, J) j;
P

Q

<i
<i
4. >Mod(P
g ) 6= >Mod(Q g ) or, equivalently, interpretations I, J models
Mod (P g ) Mod (Q g ), exactly one properties >P<i J >Q<i J holds.

prove complementary problem NP. proofs, use
membership witness pair interpretations I, J explicitly demonstrates one
conditions (1) - (4) holds. before, witness exists, also one consisting
atoms occurring programs P Q only. condition, given pair I, J
(restricted atoms P Q), one verify polynomial time whether condition
holds (for condition (1), repeat argument previous proof, conditions (2)
(4), use Lemma 33, condition (3) Lemma 32).
Hardness follows directly co-NP-completeness deciding strong equivalence two propositional theories either semantics consider Corollary 17. 2

References
Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2003). CP-nets: tool
representing reasoning conditional ceteris paribus preference statements.
Journal Artificial Intelligence Research, 21, 135191.
Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). Preference-based
constrained optimization CP-nets. Computational Intelligence, 20, 137157.
Brewka, G., Niemela, I., & Syrjanen, T. (2004). Logic programs ordered disjunctions.
Computational Intelligence, 20 (2), 335357.
Brewka, G., Niemela, I., & Truszczynski, M. (2003). Answer set optimization. Gottlob,
G., & Walsh, T. (Eds.), Proceedings 18th International Joint Conference
Artificial Intelligence (IJCAI 2003), pp. 867872. Morgan Kaufmann.
Brewka, G., Niemela, I., & Truszczynski, M. (2011). Answer set optimization. Unpublished
manuscript.
Calimeri, F., Ianni, G., Krennwallner, T., & Ricca, F. (2012). answer set programming
competition. AI Magazine, 33 (4), 114118.
Delgrande, J. P., Schaub, T., Tompits, H., & Wang, K. (2004). classification survey preference handling approaches nonmonotonic reasoning. Computational
Intelligence, 20 (2), 308334.
Eiter, T., Faber, W., Fink, M., & Woltran, S. (2007a). Complexity results answer set
programming bounded predicate arities implications. Annals Mathematics
Artificial Intelligence, 51 (24), 123165.
Eiter, T., Fink, M., & Woltran, S. (2007b). Semantical characterizations complexity
equivalences answer set programming. ACM Transactions Computational Logic,
8 (3).
389

fiFaber, Truszczynski, & Woltran

Eiter, T., & Gottlob, G. (1995). computational cost disjunctive logic programming:
Propositional case. Annals Mathematics Artificial Intelligence, 15 (3/4), 289
323.
Faber, W., Truszczynski, M., & Woltran, S. (2012). Strong equivalence qualitative optimization problems. Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Proceedings
13th International Conference Principles Knowledge Representation
Reasoning (KR 2012), pp. 188198. AAAI Press.
Faber, W., & Konczak, K. (2006). Strong order equivalence. Annals Mathematics
Artificial Intelligence, 47 (12), 4378.
Faber, W., Tompits, H., & Woltran, S. (2008). Notions strong equivalence logic
programs ordered disjunction. Brewka, G., & Lang, J. (Eds.), Proceedings
11th International Conference Principles Knowledge Representation
Reasoning (KR 2008), pp. 433443. AAAI Press.
Ferraris, P. (2005). Answer sets propositional theories. Baral, C., Greco, G., Leone,
N., & Terracina, G. (Eds.), Proceedings 8th International Conference Logic
Programming Nonmonotonic Reasoning (LPNMR 2005), Vol. 3662 Lecture
Notes Computer Science, pp. 119131. Springer.
Ferraris, P., & Lifschitz, V. (2005). Mathematical foundations answer set programming.
Show Them! Essays Honour Dov Gabbay, pp. 615664. College
Publications.
Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctive
databases. New Generation Computing, 9, 365385.
Goldsmith, J., Lang, J., Truszczynski, M., & Wilson, N. (2008). computational complexity dominance consistency CP-nets. Journal Artificial Intelligence
Research, 33, 403432.
Goldsmith, J., & Junker, U. (Eds.). (2008). Special Issue Preferences, Vol. 29(4) AI
Magazine.
Heyting, A. (1930). Die formalen Regeln der intuitionistischen Logik. Sitzungsberichte der
Preussischen Akademie der Wissenschaften, 1, 4256.
Kaci, S. (2011). Working Preferences. Springer.
Lifschitz, V. (1985). Computing circumscription. Joshi, A. K. (Ed.), Proceedings
9th International Joint Conference Artificial Intelligence (IJCAI 1985), pp.
121127. Morgan Kaufmann.
Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM
Transactions Computational Logic, 2 (4), 526541.
Lin, F. (2002). Reducing strong equivalence logic programs entailment classical
propositional logic. Fensel, D., Giunchiglia, F., McGuiness, D. L., & Williams, M.A. (Eds.), Proceedings 8th International Conference Principles Knowledge
Representation Reasoning (KR 2002), pp. 170176. Morgan Kaufmann.
Marek, V. W., & Truszczynski, M. (1993). Nonmonotonic Logic; Context-Dependent Reasoning. Springer, Berlin.
390

fiStrong Equivalence Qualitative Optimization Problems

Marek, V., & Truszczynski, M. (1999). Stable models alternative logic programming
paradigm. Apt, K., Marek, W., Truszczynski, M., & Warren, D. (Eds.), Logic
Programming Paradigm: 25-Year Perspective, pp. 375398. Springer, Berlin.
Niemela, I. (1999). Logic programming stable model semantics constraint programming paradigm. Annals Mathematics Artificial Intelligence, 25 (3-4), 241273.
Pearce, D. (1997). new logical characterisation stable models answer sets. Dix,
J., Pereira, L. M., & Przymusinski, T. (Eds.), Proceedings 6th International
Workshop Non-Monotonic Extensions Logic Programming (NMELP 1996), Vol.
1216 Lecture Notes Computer Science, pp. 5770. Springer.
Pearce, D., Tompits, H., & Woltran, S. (2009). Characterising equilibrium logic nested
logic programs: Reductions complexity. Theory Practice Logic Programming, 9 (5), 565616.
Simons, P., Niemela, I., & Soininen, T. (2002). Extending implementing stable
model semantics. Artificial Intelligence, 138, 181234.
Turner, H. (2003). Strong equivalence made easy: Nested expressions weight constraints.
Theory Practice Logic Programming, 3 (45), 609622.

391

fiJournal Artificial Intelligence Research 47 (2013) 253279

Submitted 02/13; published 06/13

Arcade Learning Environment:
Evaluation Platform General Agents
Marc G. Bellemare

mg17@cs.ualberta.ca

University Alberta, Edmonton, Alberta, Canada

Yavar Naddaf

yavar@empiricalresults.ca

Empirical Results Inc., Vancouver,
British Columbia, Canada

Joel Veness
Michael Bowling

veness@cs.ualberta.ca
bowling@cs.ualberta.ca

University Alberta, Edmonton, Alberta, Canada

Abstract
article introduce Arcade Learning Environment (ALE): challenge problem platform methodology evaluating development general,
domain-independent AI technology. ALE provides interface hundreds Atari 2600
game environments, one different, interesting, designed challenge
human players. ALE presents significant research challenges reinforcement learning,
model learning, model-based planning, imitation learning, transfer learning, intrinsic
motivation. importantly, provides rigorous testbed evaluating comparing approaches problems. illustrate promise ALE developing
benchmarking domain-independent agents designed using well-established AI techniques
reinforcement learning planning. so, also propose evaluation
methodology made possible ALE, reporting empirical results 55 different games.
software, including benchmark agents, publicly available.

1. Introduction
longstanding goal artificial intelligence development algorithms capable
general competency variety tasks domains without need domain-specific
tailoring. end, different theoretical frameworks proposed formalize
notion big artificial intelligence (e.g., Russell, 1997; Hutter, 2005; Legg, 2008). Similar
ideas developed around theme lifelong learning: learning reusable, highlevel understanding world raw sensory data (Thrun & Mitchell, 1995; Pierce &
Kuipers, 1997; Stober & Kuipers, 2008; Sutton et al., 2011). growing interest competitions General Game Playing competition (Genesereth, Love, & Pell, 2005),
Reinforcement Learning competition (Whiteson, Tanner, & White, 2010), International Planning competition (Coles et al., 2012) also suggests artificial intelligence
communitys desire emergence algorithms provide general competency.
Designing generally competent agents raises question best evaluate them.
Empirically evaluating general competency handful parametrized benchmark problems is, definition, flawed. evaluation prone method overfitting (Whiteson,
Tanner, Taylor, & Stone, 2011) discounts amount expert effort necessary
transfer algorithm new domains. Ideally, algorithm compared across
c
2013
AI Access Foundation. rights reserved.

fiBellemare, Naddaf, Veness, & Bowling

domains (i) varied enough claim generality, (ii) interesting enough
representative settings might faced practice, (iii) created
independent party free experimenters bias.
article, introduce Arcade Learning Environment (ALE): new challenge
problem, platform, experimental methodology empirically assessing agents designed
general competency. ALE software framework interfacing emulated Atari
2600 game environments. Atari 2600, second generation game console, originally
released 1977 remained massively popular decade. 500 games
developed Atari 2600, spanning diverse range genres shooters, beatem
ups, puzzle, sports, action-adventure games; many game genres pioneered
console. modern game consoles involve visuals, controls, general complexity
rivals real world, Atari 2600 games far simpler. spite this, still pose
variety challenging interesting situations human players.
ALE experimental methodology challenge problem general AI competency. machine learning, considered poor experimental practice train
evaluate algorithm data set, grossly over-estimate algorithms
performance. typical practice instead train training set evaluate
disjoint test set. large number available games ALE, propose similar methodology used effect: approachs domain representation
parametrization first tuned small number training games, testing
approach unseen testing games. Ideally, agents designed fashion evaluated testing games once, possibility subsequent modifications
algorithm. general competency remains long-term goal artificial intelligence,
ALE proposes achievable stepping stone: techniques general competency across
gamut Atari 2600 games. believe represents goal attainable short
time-frame yet formidable enough require new technological breakthroughs.

2. Arcade Learning Environment
begin describing main contribution, Arcade Learning Environment (ALE).
ALE software framework designed make easy develop agents play arbitrary
Atari 2600 games.
2.1 Atari 2600
Atari 2600 home video game console developed 1977 sold decade
(Montfort & Bogost, 2009). popularized use general purpose CPUs game console
hardware, game code distributed cartridges. 500 original games
released console; homebrew games continue developed today, thirty years
later. consoles joystick, well original games Adventure
Pitfall!, iconic symbols early video games. Nearly arcade games time
Pac-Man Space Invaders two well-known examples ported console.
Despite number variety games developed Atari 2600, hardware
relatively simple. 1.19Mhz CPU emulated much faster real-time
modern hardware. cartridge ROM (typically 24kB) holds game code,
console RAM holds 128 bytes (1024 bits). single game screen 160 pixels wide
254

fiThe Arcade Learning Environment: Evaluation Platform General Agents

Figure 1: Screenshots Pitfall! Space Invaders.
210 pixels high, 128-colour palette; 18 actions input game via
digital joystick: three positions joystick axis, plus single button. Atari
2600 hardware limits possible complexity games, believe strikes perfect
balance: challenging platform offering conceivable near-term advancements learning,
modelling, planning.
2.2 Interface
ALE built top Stella1 , open-source Atari 2600 emulator. allows user
interface Atari 2600 receiving joystick motions, sending screen and/or RAM
information, emulating platform. ALE also provides game-handling layer
transforms game standard reinforcement learning problem identifying
accumulated score whether game ended. default, observation consists
single game screen (frame): 2D array 7-bit pixels, 160 pixels wide 210 pixels
high. action space consists 18 discrete actions defined joystick controller.
game-handling layer also specifies minimal set actions needed play particular
game, although none results paper make use information. running
real-time, simulator generates 60 frames per second, full speed emulates
6000 frames per second. reward time-step defined game game basis,
typically taking difference score points frames. episode begins
first frame reset command issued, terminates game ends.
game-handling layer also offers ability end episode predefined number
frames2 . user therefore access several dozen games single common
interface, adding support new games relatively straightforward.
ALE provides functionality save restore state emulator.
issued save-state command, ALE saves relevant data current
game, including contents RAM, registers, address counters. restorestate command similarly resets game previously saved state. allows use
ALE generative model study topics planning model-based reinforcement
learning.
1. http://stella.sourceforge.net/
2. functionality needed small number games ensure always terminate.
prevents situations Tennis, degenerate agent could choose play indefinitely
refusing serve.

255

fiBellemare, Naddaf, Veness, & Bowling

2.3 Source Code
ALE released free, open-source software terms GNU General Public
License. latest version source code publicly available at:
http://arcadelearningenvironment.org
source code agents used benchmark experiments also available
publication page article website. ALE written
C++, variety interfaces available allow users interact ALE
programming language choice. Support new games easily added
implementing derived class representing games particular reward termination
functions.

3. Benchmark Results
Planning reinforcement learning two different AI problem formulations
naturally investigated within ALE framework. purpose presenting benchmark
results formulations two-fold. First, results provide baseline
performance traditional techniques, establishing point comparison future,
advanced, approaches. Second, describing results illustrate proposed
methodology empirical validation ALE.
3.1 Reinforcement Learning
begin providing benchmark results using SARSA(), traditional technique
model-free reinforcement learning. Note reinforcement learning setting,
agent access model game dynamics. time step,
agent selects action receives reward observation, agents aim
maximize accumulated reward. experiments, augmented SARSA()
algorithm linear function approximation, replacing traces, -greedy exploration.
detailed explanation SARSA() extensions found work Sutton
Barto (1998).
3.1.1 Feature Construction
approach reinforcement learning setting, important design issue
choice features use linear function approximation. ran experiments using
five different sets features, briefly explain; complete description
feature sets given Appendix A. sets features, BASS, DISCO RAM
originally introduced Naddaf (2010), rest novel.
Basic. Basic method, derived Naddafs BASS (2010), encodes presence
colours Atari 2600 screen. Basic method first removes image background
storing frequency colours pixel location within histogram. game
background precomputed offline, using 18,000 observations collected sample trajectories. sample trajectories generated following human-provided trajectory
random number steps subsequently selecting actions uniformly random.
256

fiThe Arcade Learning Environment: Evaluation Platform General Agents

screen divided 16 14 tiles. Basic generates one binary feature
128 colours tiles, giving total 28,672 features.
BASS. BASS method behaves identically Basic method save two respects.
First, BASS augments Basic feature set pairwise combinations features.
Second, BASS uses smaller, 8-colour encoding ensure number pairwise
combinations remains tractable.
DISCO. DISCO method aims detect objects within Atari 2600 screen.
so, first preprocesses 36,000 observations sample trajectories generated
Basic method. DISCO also performs background subtraction steps Basic
BASS. Extracted objects labelled classes. actual training, DISCO
infers class label detected objects encodes position velocity using tile
coding (Sutton & Barto, 1998).
LSH. LSH method maps raw Atari 2600 screens small set binary features
using Locally Sensitive Hashing (Gionis, Indyk, & Motwani, 1999). screens mapped
using random projections, visually similar screens likely generate
features.
RAM. RAM method works entirely different observation space
four methods. Rather receiving Atari 2600 screen observation, directly
observes Atari 2600s 1024 bits memory. bit RAM provided binary
feature together pairwise logical-AND every pair bits.
3.1.2 Evaluation Methodology
first constructed two sets games, one training testing. used
training games parameter tuning well design refinements, testing games
final evaluation methods. training set consisted five games: Asterix,
Beam Rider, Freeway, Seaquest Space Invaders. parameter search involved
finding suitable values parameters SARSA() algorithm, i.e. learning rate,
exploration rate, discount factor, decay rate . also searched space feature
generation parameters, example abstraction level BASS agent. results
parameter search summarized Appendix C. testing set constructed
choosing semi-randomly 381 games listed Wikipedia3 time writing.
games, 123 games Wikipedia page, single player mode,
adult-themed prototypes, emulated ALE. list, 50 games
chosen random form test set.
Evaluation method game performed follows. episode starts
frame follows reset command, terminates end-of-game condition
detected 5 minutes real-time play (18,000 frames), whichever comes first.
episode, agent acts every 5 frames, equivalently 12 times per second
gameplay. reinforcement learning trial consists 5,000 training episodes, followed
500 evaluation episodes learning takes place. agents performance
3. http://en.wikipedia.org/wiki/List Atari 2600 games (July 12, 2012)

257

fiBellemare, Naddaf, Veness, & Bowling

Game
Asterix
Seaquest
Boxing
H.E.R.O.
Zaxxon

Basic
862
579
-3
6053
1392

BASS
860
665
16
6459
2069

DISCO
755
422
12
2720
70

LSH
987
509
10
3836
3365

RAM
943
594
44
3281
304

Random
288
108
-1
712
0

Const
650
160
-25
0
0

Perturb
338
451
-10
148
2

Human
620
156
-2
6087
820

Table 1: Reinforcement Learning results selected games. Asterix Seaquest
part training set.

measured average score achieved evaluation episodes. game,
report methods average performance across 30 trials.
purposes comparison, also provide performance measures three simple
baseline agents Random, Const Perturb well performance non-expert
human player. Random agent picks random action every frame. Const agent
selects single fixed action throughout episode; results reflect highest score
achieved single action within game. Perturb agent selects fixed action
probability 0.95 otherwise acts uniformly randomly; game, report
performance best policy type. Additionally, provide human player results
report five-episode average score obtained beginner (who never previously
played Atari 2600 games) playing selected games. aim provide exhaustive
accurate human-level benchmarks, would beyond scope paper,
rather offer insight performance level achieved agents.
3.1.3 Results
complete report reinforcement learning results given Appendix D. Table 1
shows small subset results two training games three test games. 40 games
55, learning agents perform better baseline agents. games, e.g.,
Double Dunk, Journey Escape Tennis, no-action baseline policy performs
best essentially refusing play thus incurring negative reward. Within
40 games learning occurs, BASS method generally performs best. DISCO
performed particularly poorly compared learning methods. RAM-based
agent, surprisingly, outperform image-based methods, despite building representation raw game state. appears screen image carries structural information
easily extracted RAM bits.
reinforcement learning results show learning progress already possible Atari 2600 games, much work remains done. Different methods perform
well different games, single method performs well games. games
particularly challenging. example, platformers Montezumas Revenge seem
require high-level planning far beyond current, domain-independent methods
provide. Tennis requires fairly elaborate behaviour observing positive reward,
simple behaviour avoid negative rewards. results also highlight value
ALE experimental methodology. example, DISCO approach performs rea258

fiThe Arcade Learning Environment: Evaluation Platform General Agents

sonably well training set, suffers dramatic reduction performance
applied unseen games. suggests method less robust methods
studied. quick glance full table results Appendix D, clear
summarizing results across varied domains needs attention; explore
issue Section 4.
3.2 Planning
Arcade Learning Environment naturally used study planning techniques
using emulator generative model. Initially may seem allowing
agent plan future perfect model trivializes problem. However,
case: size state space Atari 2600 games prohibits exhaustive search.
Eighteen different actions available every frame; 60 frames per second, looking
ahead one second requires 1860 1075 simulation steps. Furthermore, rewards often
sparsely distributed, causes significant horizon effects many search algorithms.
3.2.1 Search Methods
provide benchmark ALE results two traditional search methods. method
applied online select action every time step (every five frames) game
over.
Breadth-first Search. first approach builds search tree breadth-first fashion
node limit reached. tree expanded, node values updated recursively
bottom tree root. agent selects action corresponding
branch highest discounted sum rewards. Expanding full search tree
requires large number simulation steps. instance, selecting action every 5 frames
allowing maximum 100,000 simulation steps per frame, agent look
ahead third second. many games, allows agent collect immediate
rewards avoid death little else. example, Seaquest agent must collect
swimmer return surface running air, involves planning far
beyond one second.
UCT: Upper Confidence Bounds Applied Trees. preferable alternative
exhaustively expanding tree simulate deeper promising branches.
this, need find balance expanding higher-valued branches
spending simulation steps lower-valued branches get better estimate
values. UCT algorithm, developed Kocsis Szepesvari (2006), deals
exploration-exploitation dilemma treating node search tree multi-armed
bandit problem. UCT uses variation UCB1, bandit algorithm, choose child
node visit next. common practice apply t-step random simulation end
leaf node obtain estimate longer trajectory. expanding
valuable branches tree carrying random simulation leaf nodes, UCT
known perform well many different settings (Browne et al., 2012).
UCT implementation entirely standard, except one optimization. Atari
games actually distinguish 18 actions every time step. Beam Rider,
example, action nothing, pressing button bullet already
259

fiBellemare, Naddaf, Veness, & Bowling

Game
Asterix
Seaquest
Boxing
H.E.R.O.
Zaxxon

Full Tree
2136
288
100
1324
0

UCT
290700
5132
100
12860
22610

Best Learner
987
665
44
6459
3365

Best Baseline
650
451
-1
712
2

Table 2: Results selected games. Asterix Seaquest part training set.
shot effect. exploit fact follows: expanding children
node search tree, compare resulting emulator states. Actions result
state treated duplicates one actions considered
search tree. reduces branching factor, thus allowing deeper search. every step,
also reuse part search tree corresponding selected action. Pseudocode
implementation UCT algorithm given Appendix B.
3.2.2 Experimental Setup
designed tuned algorithms based five training games used
Section 3.1, subsequently evaluated methods fifty games testing set.
training games used determine length search horizon well
constant controlling amount exploration internal nodes tree. episode
set last 5 minutes real-time play (18,000 frames), actions selected every
5 frames, matching settings Section 3.1.2. average, action selection step
took order 15 seconds. also used discount factor Section 3.1.
ran algorithms 10 episodes per game. Details algorithmic parameters
found Appendix C.
3.2.3 Results
complete report search results given Appendix D. Table 2 shows results
selected subset games. reference purposes, also include performance
best learning agent best baseline policy Table 1. Together, two search
methods performed better learning agents baseline policies 49 55
games. cases, UCT performs significantly better breadth-first search. Four
six games search methods perform best games rewards
sparse require long-term planning. Freeway, Private Eye, Montezumas
Revenge Venture.

4. Evaluation Metrics General Atari 2600 Agents
Applying algorithms large set games Sections 3.1 3.2 presents
difficulties interpreting results. agents goal games maximize
score, scores two different games cannot easily compared. game uses
scale scores, different game mechanics make games harder learn others.
challenges associated comparing general agents previously highlighted
260

fiThe Arcade Learning Environment: Evaluation Platform General Agents

a) Random

30

b) Baseline

10

c) Inter-Algorithm

9
25
20

1

8

BASS
RAM

7

0.8

6

15

5

0.6

4
10

0.4

3
2

5

0.2

1
0

0

Seaq

uest

H.E.R

.O.

Boxin

g

0

Seaq

uest

H.E.R

.O.

Boxin

g

Seaq

uest

H.E.R

.O.

Boxin

g

Figure 2: Left right: random-normalized, baseline inter-algorithm scores.

Whiteson et al. (2011). Although always report full performance tables,
Appendix D, compact summary statistics also desirable.
introduce simple metrics help compare agents across diverse set domains,
test set Atari 2600 games.
4.1 Normalized Scores
Consider scores sg,1 sg,2 achieved two algorithms game g. goal
explore methods allow us compare two sets scores S1 = {sg1 ,1 , . . . , sgn ,1 }
S2 = {sg1 ,2 , . . . , sgn ,2 }. approach take transform sg,i normalized score
zg,i aim comparing normalized scores across games; ideal case, zg,i = zg0 ,i
implies algorithm performs well game g game g 0 . order compare
algorithms set games, aggregate normalized scores game
algorithm.
natural way compare games different scoring scales normalize
scores numerical values become comparable. normalization methods
defined using notion score range [rg,min , rg,max ] computed game. Given
score range, score sg,i normalized computing zg,i := (sg,i rg,min ) / (rg,max
rg,min ).
4.1.1 Normalization Reference Score
One straightforward method normalize score range defined repeated runs
random agent across game. Here, rg,max absolute value average score
achieved random agent, rg,min = 0. Figure 2a depicts random-normalized
scores achieved BASS RAM three games. Two issues arise approach:
scale normalized scores may excessively large normalized scores generally
translation invariant. issue scale best seen game Freeway,
random agent achieves score close 0: scores achieved learning agents,
10-20 range, normalized thousands. contrast, learning agent achieves
random-normalized score greater 1 Asteroids.
261

fiBellemare, Naddaf, Veness, & Bowling

4.1.2 Normalizing Baseline Set
Rather normalizing single reference may normalize score range implied
set references. Let bg,1 , . . . , bg,k set reference scores. methods baseline
score computed using score range [mini{1,...,k} bg,i , maxi{1,...,k} bg,i ].
Given sufficiently rich set reference scores, baseline normalization allows us reduce
scores games comparable quantities, lets us know whether meaningful
performance obtained. Figure 2b shows example baseline scores. score range
scores corresponds scores achieved 37 baseline agents (Section 3.1.2):
Random, Const (one policy per action), Perturb (one policy per action).
natural idea also include scores achieved human players baseline set.
example, one may include score achieved expert well score achieved
beginner. However, using human scores raises set issues. example,
humans often play games without seeking maximize score; humans also benefit
prior knowledge difficult incorporate domain-independent agents.
4.1.3 Inter-Algorithm Normalization
third alternative normalize using scores achieved algorithms themselves.
Given n algorithms, achieving score sg,i game g, define inter-algorithm
score using score range [mini{1,...,n} sg,i , maxi{1,...,n} sg,i ]. definition, zg,i [0, 1].
special case n=2, zg,i {0, 1} indicates algorithm better
other. Figure 2c shows example inter-algorithm scores; relevant score ranges
constructed performance five learning agents.
inter-algorithm scores bounded, type normalization appealing
solution compare relative performance different methods. main drawback
gives indication objective performance best algorithm. good
example Venture: inter-algorithm score 1.0 achieved BASS
reflect fact none agents achieved score remotely comparable humans
performance. lack objective reference inter-algorithm normalization suggests
used complement scoring metrics.
4.2 Aggregating Scores
normalized scores obtained game, next step produce measure
reflects well agent performs across set games. illustrated Table
4, large table numbers easily permit comparison algorithms.
describe three methods aggregate normalized scores.
4.2.1 Average Score
straightforward method aggregating normalized scores compute
average. Without perfect score normalization, however, score averages tend heavily
influenced games Zaxxon baseline scores high. Averaging interalgorithm scores obviates issue scores bounded 0 1. Figure 3
displays average baseline inter-algorithm scores learning agents.
262

fiThe Arcade Learning Environment: Evaluation Platform General Agents

Average Baseline Scores

35

1.4

30

Median Baseline Scores

5

0.2

RAM

LSH

0.4

BASS

LSH

0.6

DISCO

10

RAM

Basic

15

DISCO

0.8

BASS

1

20

Basic

1.2

25

0

0

0.7

Avg. Inter-Algorithm Scores

1

Median Inter-Algorithm Scores

0.6
0.8

0

RAM

LSH

DISCO

0.2

0.1

BASS

0.4

Basic

RAM

0.6

LSH

0.2

DISCO

0.3

Basic

0.4

BASS

0.5

0

Figure 3: Aggregate normalized scores five reinforcement learning agents.

4.2.2 Median Score
Median scores generally robust outliers average scores. median
obtained sorting normalized scores selecting middle element (the average
two middle elements used number scores even). Figure 3 shows median
baseline inter-algorithm scores learning agents. Comparing medians averages baseline score (upper two graphs) illustrates exactly outlier sensitivity
average score, LSH method appears dramatically superior due entirely
performance Zaxxon.
4.2.3 Score Distribution
score distribution aggregate natural generalization median score: shows
fraction games algorithm achieves certain normalized score better.
essentially quantile plot inverse empirical CDF. Unlike average median
scores, score distribution accurately represents performance agent irrespective
individual scores distributed. Figure 4 shows baseline inter-algorithm score
distributions. Score distributions allow us compare different algorithms glance
one curve another, corresponding method generally obtains higher scores.
Using baseline score distribution, easily determine proportion games
methods perform better baseline policies (scores 1). interalgorithm score distribution, hand, effectively conveys relative performance
method. particular, allows us conclude BASS performs slightly better
Basic RAM, DISCO performs significantly worse methods.
263

fiBellemare, Naddaf, Veness, & Bowling

1.0

1.0

Fraction Games

Fraction Games

BASS
BASS
0.5

RAM
Basic

LSH

DISCO

Basic
RAM
0.5

LSH
DISCO

0.0
2000

50

10

8

6

4

2

0.0
1.0

0

0.8

Baseline Score

0.6

0.4

0.2

0

Inter-Algorithm Score

Figure 4: Score distribution games.

Basic
BASS
DISCO
LSH
RAM

Basic

BASS

DISCO

LSH

RAM


3218
1339
1834
2522

1832

548
1736
2029

3913
485

3317
419

3418
3617
1733

3615

2225
2920
941
1536


Table 3: Paired tests games. entry shows number games
performance first algorithm (left) better (worse) second
algorithms.
4.3 Paired Tests
alternate evaluation metric, especially useful comparing algorithms,
perform paired tests raw scores. game, performed two-tailed
Welshs t-test 99% confidence intervals determine whether one algorithms score
statistically different others. Table 3 provides, pair algorithms,
number games one algorithm performs statistically better worse
other. ternary nature, paired tests tend magnify small significant
differences scores.

5. Related Work
briefly survey recent research related Atari 2600 games prior work
construction empirical benchmarks measuring general competency.
5.1 Atari Games
attention devoted Atari 2600 game playing within reinforcement learning community. part, prior work focused challenge
finding good state features domain. Diuk, Cohen, Littman (2008) applied
DOORMAX algorithm restricted version game Pitfall!. method extracts objects displayed image game-specific object detection. objects
converted first-order logic representation world, Object-Oriented
264

fiThe Arcade Learning Environment: Evaluation Platform General Agents

Markov Decision Process (OO-MDP). results show DOORMAX discover
optimal behaviour OO-MDP within one episode. Wintermute (2010) proposed
method also extracts objects displayed image embeds logicbased architecture, SOAR. method uses forward model scene improve
performance Q-Learning algorithm (Watkins & Dayan, 1992). showed
using model, reinforcement learning agent could learn play restricted version
game Frogger. Cobo, Zang, Isbell, Thomaz (2011) investigated automatic
feature discovery games Pong Frogger, using simulator.
proposed method takes advantage human trajectories identify state features
important playing console games. Recently, Hausknecht, Khandelwal, Miikkulainen,
Stone (2012) proposed HyperNEAT-GGP, evolutionary approach finding policies play Atari 2600 games. Although HyperNEAT-GGP presented general game
playing approach, currently difficult assess general performance reported
results limited two games. Finally, authors paper (Bellemare, Veness, & Bowling, 2012) recently presented domain-independent feature generation
technique attempts focus effort around location player avatar.
work used evaluation methodology advocated one demonstrate
technique across large set testing games.
5.2 Evaluation Frameworks General Agents
Although idea using games evaluate performance agents long history
artificial intelligence, recently emphasis generality assumed
prominent role. Pell (1993) advocated design agents that, given abstract
description game, could automatically play them. work strongly influenced
design annual General Game Playing competition (Genesereth et al., 2005).
framework differs assume access compact logical description
game semantics. Schaul, Togelius, Schmidhuber (2011) also recently presented
interesting proposal using games measure general capabilities agent.
Whiteson et al. (2011) discuss number challenges designing empirical tests measure
general reinforcement learning performance; work seen attempting address
important concerns.
Starting 2004 conference workshop, Reinforcement Learning competition
(Whiteson et al., 2010) held 2009 (a new iteration competition
announced 20134 ). year new domains proposed, including standard RL benchmarks, Tetris, Infinite Mario (Mohan & Laird, 2009). typical competition domain,
agents state information summarized series high-level state variables
rather direct sensory information. Infinite Mario, example, provides agent
object-oriented observation space. past, organizers provided special Polyathlon track agents must behave medley continuous-observation,
discrete-action domains.
Another longstanding competition, International Planning Competition (IPC)5 ,
organized since 1998, aims produce new benchmarks, gather dis4. http://www.rl-competition.org
5. http://ipc.icaps-conference.org

265

fiBellemare, Naddaf, Veness, & Bowling

seminate data current state-of-the-art (Coles et al., 2012). IPC composed
different tracks corresponding different types planning problems, including factory
optimization, elevator control agent coordination. example, one problems
2011 competition consists coordinating set robots around two-dimensional
gridworld every tile painted specific colour. Domains described using
either relational reinforcement learning, yielding parametrized Markov Decision Processes
(MDPs) Partially Observable MDPs, using logic predicates, e.g. STRIPS notation.
One indication much competitions value domain variety seen
time spent finding good specification language. 2008-2009 RL competitions,
example, used RL-Glue6 specifically purpose; 2011 planning uncertainty
track IPC similar employed Relation Dynamic Influence Diagram Language.
competitions seek spur new research evaluate existing algorithms
standardized set benchmarks, independently developed, sense
vast majority domains provided research community. Thus typical
competition domain reflects existing research directions: Mountain Car Acrobot remain staples RL competition. competitions also focus research effort
domains provide high-level state variables, example location robots
floor-painting domain described above. contrast, Arcade Learning Environment
domain-independent setting force us consider question perceptual grounding:
extract meaningful state information raw game screens (or RAM information).
turn, emphasizes design algorithms applied sensor-rich domains
without significant expert knowledge.
also number attempts define formal agent performance metrics
based algorithmic information theory. first attempts due HernandezOrallo Minaya-Collado (1998) Dowe Hajek (1998). recently,
approaches Hernandez-Orallo Dowe (2010) Legg Veness (2011) appear
potential. Although frameworks general conceptually clean,
key challenge remains specify sufficiently interesting classes environments.
opinion, much work required approaches claim rival
practicality using large set existing human-designed environments agent
evaluation.

6. Final Remarks
Atari 2600 games developed humans exhibit many idiosyncrasies
make challenging exciting. Consider, example, game Pong.
Pong studied variety contexts interesting reinforcement learning
domain (Cobo et al., 2011; Stober & Kuipers, 2008; Monroy, Stanley, & Miikkulainen,
2006). Atari 2600 Pong, however, significantly complex Pong domains
developed research. Games easily last 10,000 time steps (compared 2001000
domains); observations composed 7-bit 160210 images (compared 300200
black white images work Stober Kuipers (2008), 5-6 input features
elsewhere); observations also complex, containing two players score side
walls. sheer size, Atari 2600 Pong thus larger domain. dynamics also
6. http://glue.rl-community.org

266

fiThe Arcade Learning Environment: Evaluation Platform General Agents

complicated. research implementations Pong object motion implemented
using first-order mechanics. However, Atari 2600 Pong paddle control nonlinear:
simple experimentation shows fully predicting players paddle requires knowledge
last 18 actions. many Atari games, player paddle also moves every
frame, adding degree temporal aliasing domain.
Atari 2600 Pong may appear unnecessarily contrived, fact reflects unexpected complexity problems humans faced. Most, Atari
2600 games subject similar programming artifacts: Space Invaders, example,
invaders velocity increases nonlinearly number remaining invaders.
way Atari 2600 platform provides AI researchers something unique: clean, easilyemulated domains nevertheless provide many challenges typically associated
real-world applications.
technology advance render general Atari 2600 game playing achievable,
challenge problem always extended use recent video game platforms.
natural progression, example, would move Commodore 64,
Nintendo, forth towards current generation consoles. consoles
hundreds released games, older platforms readily available emulators.
ultra-realism current generation consoles, console represents natural stepping
stone toward general real-world competency. hope using methodology
advocated paper, work bottom-up fashion towards developing
sophisticated AI technology still maintaining empirical rigor.

7. Conclusion
article introduced Arcade Learning Environment, platform evaluating
development general, domain-independent agents. ALE provides interface
hundreds Atari 2600 game environments, one different, interesting, designed
challenge human players. illustrate promise ALE challenge problem
benchmarking several domain-independent agents use well-established reinforcement
learning planning techniques. results suggest general Atari game playing
challenging intractable problem domain potential aid development
evaluation general agents.

Acknowledgments
would like thank Marc Lanctot, Erik Talvitie, Matthew Hausknecht providing
suggestions helping debug improving Arcade Learning Environment source code.
would also like thank reviewers helpful feedback enthusiasm
Atari 2600 research platform. work presented supported
Alberta Innovates Technology Futures, Alberta Innovates Centre Machine Learning
University Alberta, Natural Science Engineering Research Council
Canada. Invaluable computational resources provided Compute/Calcul Canada.

267

fiBellemare, Naddaf, Veness, & Bowling

Appendix A. Feature Set Construction
section gives detailed description five feature generation techniques
Section 3.1.
A.1 Basic Abstraction ScreenShots (BASS)
idea behind BASS directly encode colours present screen. method
motivated three observations Atari 2600 hardware games:
1. Atari 2600 hardware supports screen resolution 160210, game objects
usually larger pixels. Overall, important game events happen much
lower resolution.
2. Many Atari 2600 games static background, important objects moving screen. screen matrix densely populated, actual interesting
features screen often sparse.
3. hardware show 128 colours NTSC mode, limited
8 colours SECAM mode. Consequently, games use number
colours distinguish important objects screen.
game screen first preprocessed subtracting background, detected using simple
histogram method. BASS encodes presence eight SECAM palette
colours low resolution, depicted Figure 5. Intuitively, BASS seeks capture
presence objects certain colours different screen locations. BASS also encodes
relations objects constructing pairwise combinations encoded colour
features. Asterix, example, important know green object (player
character) red object (collectable object) vicinity. Pairwise features allow us
capture object relations.

Figure 5: Left: Freeway SECAM colours. Right: BASS colour encoding
screen.

A.2 Basic
Basic method generates set features BASS, omits pairwise
combinations. allows us study whether additional features beneficial
268

fiThe Arcade Learning Environment: Evaluation Platform General Agents

harmful learning. Basic method fewer features BASS, encodes
presence 128 colours. comparison BASS, Basic therefore represents
colour accurately, cannot represent object interactions.
A.3 Detecting Instances Classes Objects (DISCO)
feature generation method based detecting set classes representing game
entities locating instances classes screen. DISCO motivated
following additional observations Atari 2600 games:
1. game entities often instances classes objects. instance,
Figure 6 shows, many objects sample screen game Freeway,
objects instances two classes: Chicken Car. Similarly,
objects sample screen game Seaquest instances one
six classes: Fish, Swimmer, Player Submarine, Enemy Submarine, Player Bullet,
Enemy Bullet.
2. interaction two objects often generalized instances
respective classes. example, consider Car -Chicken object interactions Freeway: learning lower value associated one Chicken instance hitting
Car instance generalized instances two classes.

Figure 6: Left: Screenshot game Freeway. Although ten different cars,
considered instances single class. Right: Screenshot
game Seaquest depicting four different object classes.
DISCO first performs series preprocessing steps discover classes,
value function learning performed. agent subsequently learns play
game, DISCO generates features detecting objects screen classifying them.
DISCO process summarized following steps:
Preprocessing:
Background detection: static background matrix extracted using
histogram method, BASS.
269

fiBellemare, Naddaf, Veness, & Bowling

Algorithm 1 Locally Sensitive Hashing (LSH) Feature Generation
Constants. (hash table size), n (screen bit vector size)
l (number random bit vectors), k (number non-zero entries)
Initialization (once).
{v1 . . . vl } generateRandomVectors(l, k, n)
{hash1 . . . hashl } generateHashFunctions(l, M, n)
Input. screen matrix elements Ixy {0, . . . , 127}
LSH(I)
binarizeScreen(I) (s length n)
Initialize RlM = 0
= 1 . . . l
h=0
j = 1 . . . n
h h + I[sj =vij ] hashi [j] mod
(hash projection onto vi )
end
[M (i 1) + h] = 1
(one binary feature per random bit vector)
end
binarizeScreen(I)
Initialize Rn = 0
= 1 . . . h, x = 1 . . . w (h = 210, w = 160)
s[x + h + Ixy ] = 1
end
return
generateRandomVectors(l, k, n)
Initialize v1 . . . vl Rn = 0
= 1 . . . l
Select x1 , x2 , . . . , xk distinct coordinates 1 n uniformly random
vi [x1 ] = 1; vi [x2 ] = 1; . . . ; vi [xk ] = 1
end
return {v1 , . . . vl }
generateHashFunctions(l, M, n) (hash functions vectors random coordinates)
Initialize hash1 . . . hashl Rn = 0
= 1 . . . l, j = 1 . . . n
hashi [j] random(1, ) (uniformly random coordinate 1 M)
end
return {hash1 , . . . hashl }
Remark. sparse vector operations, LSH O(lk + n) cost per step.

270

fiThe Arcade Learning Environment: Evaluation Platform General Agents

Figure 7: Left: Screenshot game Seaquest. Right: Objects detected DISCO
game Seaquest. colour represents different class.

Blob extraction: list moving blob (foreground) objects detected
game screen.
Class discovery: set classes detected extracted blob objects.
Class filtering: Classes appear infrequently restricted small region
screen removed set.
Class merging: Classes similar shapes merged together.
Feature generation:
Class instance detection: time step, class instances detected
current screen matrix.
Feature vector generation: feature vector generated detected
instances tile-coding absolute position well relative position
velocity every pair instances different classes. Multiple instances
objects combined additively.
Figure 7 shows discovered objects Seaquest frame. image illustrates difficulties detecting objects: although DISCO correctly classifies different fish part
class, also detects life icon oxygen bar part class.
A.4 Locality Sensitive Hashing (LSH)
alternative approach BASS DISCO use well-established feature generation
methods agnostic type input receive. methods include
polynomial bases (Schweitzer & Seidmann, 1985), sparse distributed memories (Kanerva,
1988) locality sensitive hashing (LSH) (Gionis et al., 1999). paper consider
latter simple mean reducing large image space smaller, manageable
set features. input here, game screen first mapped bit vector size
7 210 160. resulting vector hashed smaller set features.
LSH performs additional random projection step ensure similar screens
likely binned together. LSH generation method detailed Algorithm 1.
271

fiBellemare, Naddaf, Veness, & Bowling

A.5 RAM-based Feature Generation
Unlike previous three methods, generate feature vectors based game screen,
RAM-based feature generation method relies contents console memory.
Atari 2600 128 8 = 1024 bits random access memory7 , must hold
complete internal state game: location game entities, timers, health indicators,
etc. RAM therefore relatively compact representation game state,
contrast game screen, also Markovian. purpose RAM-based agent
investigate whether features generated RAM affect performance differently
features generated game screens.
first part generated feature vector simply includes 1024 bits RAM.
Atari 2600 game programmers often used bits individual values, part
4-bit 8-bit words. Linear function approximation individual bits capture
value multi-bit words. also interested relation pairs
values memory. capture relations, logical-AND possible bit pairs
appended feature vector. Note linear function pairwise Ds
capture products 4-bit 8-bit words. product two n-bit
words expressed weighted sum pairwise products bits.

7. games provided RAM game cartridge: Atari Super Chip, example, offered
additional 128 bytes memory. current approach considers main memory included
Atari 2600 console.

272

fiThe Arcade Learning Environment: Evaluation Platform General Agents

Appendix B. UCT Pseudocode
Algorithm 2 UCT
Constants. (search horizon), k (simulations per step)
Variables. (search tree)
Input. (current state)
UCT(s)
empty root() 6=
empty search tree
root()
end
repeat
sample(, m)
visits(root()) = k
bestAction()
prune(, a)
(optional)
return
sample(, m)
n root()
n leaf, > depth(n)
action never taken n
(c, reward) emulate(n, a)
(run model one step)
immediate-return(c) reward
child(n, a) c
nc
(c necessarily leaf)
else
selectAction(n)
n child(n, a)
end
end
R = rollout(n, depth(n))
update-value(n, R)
(propagate values back up)
bestAction()
return arg maxa [visits(child(root(), a))]
prune(, a)
root() child(root(), a)

273

(action frequently taken root)

fiBellemare, Naddaf, Veness, & Bowling

Algorithm 3 UCT Routines
Constants. : discount factor
selectAction(n)
c children n
q
V (c) average-return(c) + log[visits(c)]
visits(n)
end
return arg maxa V (child(n, a))
rollout(n, m)
R=0
(Initialize Monte-Carlo return 0)
g=1
> 0
Select according rollout policy (e.g. uniformly randomly)
(n, reward) emulate(n, a)
R R + g reward
mm1
g g
end
return R
update-value(n, R)
R R + immediate-reward(n)
visits(n)
R
average-return(n) average-return(n) visits(n)+1
+ visits(n)+1
visits(n) visits(n) + 1
n root , i.e. parent(n) 6= null
update-value(parent(n), R)
end

274

fiThe Arcade Learning Environment: Evaluation Platform General Agents

Appendix C. Experimental Parameters
General

experiments
Reinforcement learning

Preprocessing

Background detection
Class discovery

Reinforcement
learning

agents
BASS
Basic

BASS
Basic
DISCO

RAM-based
LSH

Planning

UCT

Full-tree search

Maximum frames per episode
Frames per action
Training episodes per trial
Evaluation episodes per trial
Number trials per result
Sample screens per game
Sample screens per game
Maximum number classes
Maximum object velocity (pixels)
Minimum frequency class appearance
Discount factor
Exploration rate
Learning rate
Eligibility traces decay rate
Grid width
Grid height
Number different colours
Number different colours
Learning rate
Eligibility traces decay rate
Tile coding, number tilings
Tile coding, grid size
Learning rate
Eligibility traces decay rate
Learning rate
Eligibility traces decay rate
Number random vectors l
Number non-zero vector entries k
Per-vector hash table size
Simulations per action
Maximum search depth (frames)
Exploration constant
Maximum frames emulated per action

275

18,000
5
5,000
500
30
18,000
36,000
10
8
20%
0.999
0.05
0.5
0.9
16
14
8
128
0.1
0.9
8
8
0.2
0.5
0.5
0.5
2000
1000
50
500
300
0.1
133,000

fiBellemare, Naddaf, Veness, & Bowling

Appendix D. Detailed Results
D.1 Reinforcement Learning
Game

Basic

BASS

DISCO

LSH

RAM

Random

Const

Perturb

Asterix
Beam Rider
Freeway
Seaquest
Space Invaders

862.3
929.4
11.3
579.0
203.6

859.8
872.7
16.4
664.8
250.1

754.6
563.0
12.8
421.9
239.1

987.3
793.6
15.4
508.5
222.2

943.0
729.8
19.1
593.7
226.5

288.1
434.7
0.0
107.9
156.1

650.0
996.0
21.0
160.0
245.0

337.8
754.8
22.5
451.1
270.5

Alien
Amidar
Assault
Asteroids
Atlantis
Bank Heist
Battle Zone
Berzerk
Bowling
Boxing
Breakout
Carnival
Centipede
Chopper Command
Crazy Climber
Demon Attack
Double Dunk
Elevator Action
Enduro
Fishing Derby
Frostbite
Gopher
Gravitar
H.E.R.O.
Ice Hockey
James Bond
Journey Escape
Kangaroo
Krull
Kung-Fu Master
Montezumas Revenge
Ms. Pac-Man
Name Game
Pooyan
Pong
Private Eye
Q*Bert
River Raid
Road Runner
Robotank
Skiing
Star Gunner
Tennis
Time Pilot
Tutankham

Venture
Video Pinball
Wizard Wor
Zaxxon

939.2
64.9
465.8
829.7
62687.0
98.8
15534.3
329.2
28.5
-2.8
3.3
2323.9
7725.5
1191.4
6303.1
520.5
-15.8
3025.2
111.8
-92.6
161.0
545.8
185.3
6053.1
-13.9
197.3
-8441.0
962.4
2823.3
16416.2
10.7
1537.2
1818.9
800.3
-19.2
81.9
613.5
1708.9
67.7
12.8
-1.1
850.2
-0.2
1728.2
40.7
3532.7
0.0
15046.8
1768.8
1392.0

893.4
103.4
378.4
800.3
25375.0
71.1
12750.8
491.3
43.9
15.5
5.2
1574.2
8803.8
1581.5
7455.6
318.5
-13.1
2377.6
129.1
-92.1
161.1
1288.3
251.1
6458.8
-14.8
202.8
-14730.7
1622.1
3371.5
19544.0
0.1
1691.8
2386.8
1018.9
-19.0
100.7
497.2
1438.0
65.2
10.1
-0.7
1069.5
-0.1
2299.5
52.6
3351.0
66.0
12574.2
1981.3
2069.1

623.6
67.9
371.7
744.5
20857.3
51.4
0.0
329.0
35.2
12.4
3.9
1646.3
6210.6
1349.0
4552.9
208.8
-23.2
4.6
0.0
-89.5
176.6
295.7
197.4
2719.8
-18.9
17.3
-9392.2
457.9
2350.9
3207.0
0.0
999.6
1951.0
402.7
-19.6
-23.0
326.3
0.0
21.4
9.3
-0.1
1002.2
-0.1
0.0
0.0
2473.4
0.0
10779.5
935.6
69.8

510.2
45.1
628.0
590.7
17593.9
64.6
14548.1
441.0
26.1
10.5
2.5
1147.2
6161.6
943.0
20453.7
355.8
-21.6
3220.6
95.8
-93.2
216.9
941.8
105.9
3835.8
-15.1
77.1
-13898.9
256.4
2798.1
8715.6
0.1
1070.8
2029.8
1225.3
-19.9
684.3
529.1
1904.3
42.0
10.8
-0.0
722.9
-0.1
2429.2
85.2
2475.1
0.0
9813.9
945.5
3365.1

726.4
71.4
383.6
907.3
19932.7
190.8
15819.7
501.3
29.3
44.0
4.0
765.4
7555.4
1397.8
23410.6
324.8
-20.3
507.9
112.3
-91.6
147.9
722.5
387.7
3281.1
-9.5
133.8
-8713.5
481.7
2901.3
10361.1
0.3
1021.1
2500.1
1210.9
-19.9
111.9
565.8
1309.9
41.0
28.7
0.0
769.3
-0.1
3741.2
114.3
3412.6
0.0
16871.3
1096.2
304.3

102.0
0.8
334.3
1526.7
33058.4
15.0
2920.0
233.8
24.6
-1.5
1.5
869.2
2805.1
698.2
2335.4
289.3
-15.6
1040.9
0.0
-93.8
70.3
243.7
205.4
712.0
-14.8
23.3
-18201.7
44.4
1880.1
488.2
0.3
163.3
2012.3
501.1
-20.9
-754.0
169.0
1608.6
36.2
1.6
0.0
638.1
-24.0
3458.8
23.1
131.6
0.0
20021.1
772.4
0.0

140.0
31.0
357.0
140.0
1500.0
0.0
13000.0
670.0
30.0
-25.0
3.0
0.0
16527.0
1000.0
0.0
130.0
0.0
0.0
9.0
-99.0
160.0
0.0
0.0
0.0
-1.0
0.0
0.0
200.0
0.0
0.0
0.0
210.0
3080.0
30.0
-21.0
0.0
150.0
1070.0
900.0
17.0
0.0
600.0
0.0
500.0
0.0
550.0
0.0
705.0
300.0
0.0

313.9
37.8
497.8
539.9
12089.1
13.5
5772.0
552.9
30.0
-10.1
2.9
485.4
8937.2
973.7
2235.0
776.2
-20.3
562.9
25.9
-97.2
175.2
286.8
106.0
147.5
-6.5
82.0
-10693.9
498.4
1690.1
578.4
0.0
505.5
1854.3
540.8
-20.8
1947.3
157.4
1455.5
857.9
11.3
0.0
509.8
-0.3
718.7
17.3
2962.9
0.0
9527.9
470.3
2.0

Times Best

6

17

1

8

8

2

9

4

Table 4: Reinforcement Learning results. first five games constitute training set.
See Section 3.1 details.
.

276

fiThe Arcade Learning Environment: Evaluation Platform General Agents

D.2 Planning
Game

Full Tree

UCT

Best Learner

Best Baseline

Asterix
Beam Rider
Freeway
Seaquest
Space Invaders

2135.7
693.5
0.0
288.0
112.2

290700.0
6624.6
0.4
5132.4
2718.0

987.3
929.4
19.1
664.8
250.1

650.0
996.0
22.5
451.1
270.5

Alien
Amidar
Assault
Asteroids
Atlantis
Bank Heist
Battle Zone
Berzerk
Bowling
Boxing
Breakout
Carnival
Centipede
Chopper Command
Crazy Climber
Demon Attack
Double Dunk
Elevator Action
Enduro
Fishing Derby
Frostbite
Gopher
Gravitar
H.E.R.O.
Ice Hockey
James Bond
Journey Escape
Kangaroo
Krull
Kung-Fu Master
Montezumas Revenge
Ms. Pacman
Name Game
Pooyan
Pong
Private Eye
Q*Bert
River Raid
Road Runner
Robotank
Skiing
Star Gunner
Tennis
Time Pilot
Tutankham

Venture
Video Pinball
Wizard Wor
Zaxxon

784.0
5.2
413.7
3127.4
30460.0
21.5
6312.5
195.0
25.5
100.0
1.1
950.0
125123.0
1827.3
37110.0
442.6
-18.5
730.0
0.6
-91.6
137.2
1019.0
395.0
1323.8
-9.2
25.0
1327.3
90.0
3089.2
12127.3
0.0
1708.5
5699.0
909.7
-20.7
57.9
132.8
2178.5
245.0
1.5
0.0
1345.0
-23.8
4063.6
64.1
746.0
0.0
55567.3
3309.1
0.0

7785.0
180.3
1512.2
4660.6
193858.0
497.8
70333.3
553.5
25.1
100.0
364.4
5132.0
110422.0
34018.8
98172.2
28158.8
24.0
18100.0
286.3
37.8
270.5
20560.0
2850.0
12859.5
39.4
330.0
7683.3
1990.0
5037.0
48854.5
0.0
22336.0
15410.0
17763.4
21.0
100.0
17343.4
4449.0
38725.0
50.4
-0.8
1207.1
2.8
63854.5
225.5
74473.6
0.0
254748.0
105500.0
22610.0

939.2
103.4
628.0
907.3
62687.0
190.8
15819.7
501.3
43.9
44.0
5.2
2323.9
8803.8
1581.5
23410.6
520.5
-13.1
3220.6
129.1
-89.5
216.9
1288.3
387.7
6458.8
-9.5
202.8
-8441.0
1622.1
3371.5
19544.0
10.7
1691.8
2500.1
1225.3
-19.0
684.3
613.5
1904.3
67.7
28.7
0.0
1069.5
-0.1
3741.2
114.3
3532.7
66.0
16871.3
1981.3
3365.1

313.9
37.8
497.8
1526.7
33058.4
15.0
13000.0
670.0
30.0
-1.5
3.0
869.2
16527.0
1000.0
2335.4
776.2
0.0
1040.9
25.9
-93.8
175.2
286.8
205.4
712.0
-1.0
82.0
0.0
498.4
1880.1
578.4
0.3
505.5
3080.0
540.8
-20.8
1947.3
169.0
1608.6
900.0
17.0
0.0
638.1
0.0
3458.8
23.1
2962.9
0.0
20021.1
772.4
2.0

Times Best

4

45

3

3

Table 5: Search results. first five games constitute training set. See Section 3.2
details.
.

277

fiBellemare, Naddaf, Veness, & Bowling

References
Bellemare, M., Veness, J., & Bowling, M. (2012). Investigating contingency awareness using
Atari 2600 games. Proceedings 26th Conference Artificial Intelligence
(AAAI).
Browne, C. B., Powley, E., Whitehouse, D., Lucas, S. M., Cowling, P. I., Rohlfshagen, P.,
Tavener, S., Perez, D., Samothrakis, S., & Colton, S. (2012). survey Monte Carlo
tree search methods. IEEE Transactions Computational Intelligence AI
Games, 4 (1), 1 43.
Cobo, L. C., Zang, P., Isbell, C. L., & Thomaz, A. L. (2011). Automatic state abstraction
demonstration. Proceedings 22nd Second International Joint Conference
Articial Intelligence (IJCAI).
Coles, A., Coles, A., Olaya, A., Jimenez, S., Lopez, C., Sanner, S., & Yoon, S. (2012).
survey seventh international planning competition. AI Magazine, 33 (1), 8388.
Diuk, C., Cohen, A., & Littman, M. L. (2008). object-oriented representation efficient reinforcement learning. Proceedings 25th International Conference
Machine learning (ICML).
Dowe, D. L., & Hajek, A. R. (1998). non-behavioural, computational extension
Turing Test. Proceedings International Conference Computational Intelligence Multimedia Applications (ICCIMA).
Genesereth, M. R., Love, N., & Pell, B. (2005). General Game Playing: Overview
AAAI competition. AI Magazine, 26 (2), 6272.
Gionis, A., Indyk, P., & Motwani, R. (1999). Similarity search high dimensions via
hashing. Proceedings International Conference Large Databases.
Hausknecht, M., Khandelwal, P., Miikkulainen, R., & Stone, P. (2012). HyperNEAT-GGP:
HyperNEAT-based Atari general game player. Proceedings Genetic
Evolutionary Computation Conference (GECCO).
Hernandez-Orallo, J., & Dowe, D. L. (2010). Measuring universal intelligence: Towards
anytime intelligence test. Artificial Intelligence, 174 (18), 1508 1539.
Hernandez-Orallo, J., & Minaya-Collado, N. (1998). formal definition intelligence
based intensional variant Kolmogorov complexity. Proceedings
International Symposium Engineering Intelligent Systems (EIS).
Hutter, M. (2005). Universal Artificial Intelligence: Sequential Decisions based Algorithmic Probability. Springer, Berlin.
Kanerva, P. (1988). Sparse Distributed Memory. MIT Press.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. Proceedings
15th European Conference Machine Learning (ECML).
Legg, S. (2008). Machine Super Intelligence. Ph.D. thesis, University Lugano.
Legg, S., & Veness, J. (2011). approximation universal intelligence measure.
Proceedings Ray Solomonoff Memorial Conference.
278

fiThe Arcade Learning Environment: Evaluation Platform General Agents

Mohan, S., & Laird, J. E. (2009). Learning play Mario. Tech. rep. CCA-TR-2009-03,
Center Cognitive Architecture, University Michigan.
Monroy, G. A., Stanley, K. O., & Miikkulainen, R. (2006). Coevolution neural networks
using layered pareto archive. Proceedings 8th Genetic Evolutionary
Computation Conference (GECCO).
Montfort, N., & Bogost, I. (2009). Racing Beam: Atari Video Computer System.
MIT Press.
Naddaf, Y. (2010). Game-Independent AI Agents Playing Atari 2600 Console Games.
Masters thesis, University Alberta.
Pell, B. (1993). Strategy Generation Evaluation Meta-Game Playing. Ph.D. thesis,
University Cambridge.
Pierce, D., & Kuipers, B. (1997). Map learning uninterpreted sensors effectors.
Artificial Intelligence, 92 (1-2), 169227.
Russell, S. J. (1997). Rationality intelligence. Artificial intelligence, 94 (1), 5777.
Schaul, T., Togelius, J., & Schmidhuber, J. (2011). Measuring intelligence games.
CoRR, abs/1109.1314.
Schweitzer, P. J., & Seidmann, A. (1985). Generalized polynomial approximations Markovian decision processes. Journal mathematical analysis applications, 110 (2),
568582.
Stober, J., & Kuipers, B. (2008). pixels policies: bootstrapping agent.
Proceedings 7th IEEE International Conference Development Learning
(ICDL).
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT
Press.
Sutton, R., Modayil, J., Delp, M., Degris, T., Pilarski, P., White, A., & Precup, D. (2011).
Horde: scalable real-time architecture learning knowledge unsupervised
sensorimotor interaction. Proceedings 10th International Conference Autonomous Agents Multiagents Systems (AAMAS).
Thrun, S., & Mitchell, T. M. (1995). Lifelong robot learning. Robotics Autonomous
Systems, 15 (1), 2546.
Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279292.
Whiteson, S., Tanner, B., Taylor, M. E., & Stone, P. (2011). Protecting evaluation
overfitting empirical reinforcement learning. Proceedings IEEE Symposium
Adaptive Dynamic Programming Reinforcement Learning (ADPRL).
Whiteson, S., Tanner, B., & White, A. (2010). reinforcement learning competitions.
AI Magazine, 31 (2), 8194.
Wintermute, S. (2010). Using imagery simplify perceptual abstraction reinforcement
learning agents. Proceedings 24th Conference Artificial Intelligence
(AAAI).

279

fiJournal Artificial Intelligence Research 47 (2013) 475-519

Submitted 12/12; published 07/13

Computation Fully Proportional Representation
Nadja Betzler

nadja.betzler@campus.tu-berlin.de

Institut fur Softwaretechnik und
Theoretische Informatik
TU Berlin

Arkadii Slinko

slinko@math.auckland.ac.nz

Department Mathematics
University Auckland

Johannes Uhlmann

johannes.uhlmann@campus.tu-berlin.de

Institut fur Softwaretechnik und
Theoretische Informatik
TU Berlin

Abstract
investigate two systems fully proportional representation suggested Chamberlin & Courant Monroe. systems assign representative voter
sum misrepresentations minimized. winner determination problem
systems known NP-hard, hence work aims investigating whether
variants proposed rules and/or specific electorates problems
solved efficiently. variation rules, instead minimizing sum misrepresentations, considered minimizing maximal misrepresentation introducing effectively
two new rules. general case minimax versions classical rules appeared
still NP-hard.
investigated parameterized complexity winner determination two classical two new rules respect several parameters. mixture
positive negative results: e.g., proved fixed-parameter tractability parameter number candidates fixed-parameter intractability number winners.
single-peaked electorates results overwhelmingly positive: provide polynomial-time algorithms considered problems. rule remains
NP-hard single-peaked electorates classical Monroe rule.

1. Introduction
important conceptual difference purpose single-winner multiwinner elections. Single-winner social choice rules used make final decisions, e.g.,
elect president choose certain course action. multi-winner election rules
used elect assembly whose members authorized take final decisions
behalf society. result main property multi-winner rules satisfy
elected assembly represents society adequately. This, particular, means
final decision taken opinions existing society heard taken
consideration. Black powerfully expressed it:
c
2013
AI Access Foundation. rights reserved.

fiBetzler, Slinko, & Uhlmann

scheme proportional representation attempts secure assembly whose
membership will, far possible, proportionate volume different shades political opinion held throughout country; microcosm
true reflexion macrocosm (Black, 1958, p. 75).
although single-winner social choice rule easily extended select
assemblye.g., choosing candidates best scores applying rule repeatedly
required quantity representatives electedthis wrong approach problem
(Brams & Fishburn, 2002) (see also Lu & Boutilier, 2011 experimental evidence).
reason majoritarian logic dominates design single-winner social
choice rules cannot provide balanced assembly membership.
standard solution problem electing assembly division
election single-member districts approximately equal population. district
elects one member assembly using single-winner rule, normally plurality.
although one might question whether districting instead based total adult
population number registered voters, current practice well established
entrenched law many countries, including United States (Brams, 2008). However
main problem approach districting fact also fails
give representation minorities; minority may comprise 49% population
represented assembly. positive side districting method provides
high level accountability: voters know representative, address
particular issues even recall them, fail represent decent
standard.
Various voting systemse.g., Cumulative Voting, Single Non-Transferable vote, multiwinner variants Single Transferable Vote, various party list systemshave designed
solve problem representation minorities (Brams & Fishburn, 2002). However
none scored high accountability. may even seem certain
trade-off cannot representation minorities accountability.
However case. important idea suggested Charles Dodgson (1884),
known also Lewis Carroll, considered different form Black (1958).
idea developed Chamberlin Courant (1983) later Monroe (1995).
relative advantages methods political science point view
extensively discussed Brams (2008). Dodgson asserted representation system
find coalitions election would formed voters
necessary time information allow coalitions elect representative.
adopted, sizable minority form coalition represented.
realization idea required new concept concept misrepresentation. assumed voters form individual preferences candidates based
political ideology judgement abilities candidates participate
deliberations decision making consistent individuals would wish act
present (Chamberlin & Courant, 1983, p. 722). way revolution.
Indeed, single-winner literature voting rules widely accepted
voters political preferences complex first choices alone. However,
multi-winner voting literature fixation first preferences led researchers think
proportional representation exclusively terms first preferences. list systems
476

fiOn Computation Fully Proportional Representation

proportional representation, parties assigned number seats parliament
proportional number votes (first preferences) received. systems like
Single Non-Transferable Vote, Block Voting Cumulative Voting also take second preferences account (Levin & Nalebuff, 1995). Single Transferable Vote
system proportional representationin fact family voting methods according
Tideman Richardson (2000)that allows voters express order preference
candidates (Levin & Nalebuff, 1995). Voters rank candidates order preference;
first preference votes first looked at, votes transferred,
necessary, candidates either comfortably elected done
badly eliminated election.1
So, voter represented candidate first preference reasonable
say represented optimally misrepresentation case zero.
general, voter represented candidate ith preference may assume
misrepresented degree si . course, reasonable assume
0 = s1 s2 . . . sm . case rule measuring total misrepresentation
fully defined vector = (s1 , . . . , sm ), number candidates.
Using analogy positional scoring rules single-winner elections may say
misrepresentation function positional. general, problem choosing proper
misrepresentation function far trivial. work Levin Nalebuff (1995,
p. 4) difficulty vividly illustrated: electorate uniformly distributed
segment 0 1, choose three representatives, equally
spaced [0.25, 0.5, 0.75], selected minimize average distance
traveled nearest legislator [0.16, 0.5, 0.83]? broadest possible framework
misrepresentation function may even voter-dependent.
Staying classical positional misrepresentation functions time suppose every voter assigned representative way. Measuring total
misrepresentation whole society may adopt either Harsanyi (1995) approach
Rawlsian one (assuming utility represented ith best candidate si , i.e., nonpositive value). Harsanyi measure total
misrepresentation

X
ni si ,
MH =
i=1

ni number voters represented ith preferred candidate. According Rawls (1999) welfare maximized utility society members
least greatest. leads total misrepresentation function
MR =

max

ni >0

si .

Chamberlin Courant (1983), Monroe (1995) consider best set
representatives must minimize total misrepresentation calculate using
Borda vector scores, is, (0, 1, 2, . . . , 1) Harsanyis misrepresentation
1. Northern Ireland voting system used elections local councils, Assembly,
European Parliament. used elections Irish Republic, Malta, Australia (although
single-member constituencies prevalent Australia, apart state level elections Tasmania
ACT). Several countries recently debated adopting it.

477

fiBetzler, Slinko, & Uhlmann

function. methods however different difference important. Chamberlin Courant impose restriction function assigns candidates
voters. may potentially lead different number voters represented
candidate. remedy Chamberlin Courant suggested use weighted voting
assembly elected candidate weight equal number voters
represent. Monroe rejected approach insisted principle one member
assembly one vote. reason insisted difference numbers
voters assigned two representatives one.
reasons Monroe rejected Chamberlin Courant approach quite
substantial. Proportional allocation weights known result excessive voting powers
electorates larger constituencies much debate right
way allocating weights representatives. alternative Chamberlin Courants
method would give representatives weights proportional square root
number voters represent. justified fact, due square root
law Penrose (1946), priori voting power (as defined Penrose-Banzhaf index)
member voting body inversely proportional square root size.
basis theory, example, Poland insisted EU allocate Council-of-Minister
votes according square root nations population (Slomczynski & Zyczkowski,
2006).
computational problems Harsanyi approach entails known
NP-hard (Lu & Boutilier, 2011; Procaccia, Rosenschein, & Zohar, 2008) several classical misrepresentation functions. paper try achieve tractability multiwinner
elections three different ways. Firstly, ask whether problem finding optimal fully proportional representation becomes easier classical misrepresentation
functions adopt Rawlsian approach measurement total misrepresentation.
second goal find parameterized complexity aforementioned problems
natural choices parameters. third develop efficient algorithms
achieving optimal fully proportional representation single-peaked elections.
remainder section, formally introduce computational problems
considered paper, summarize results extant literature, describe
approaches results.
1.1 Computational Problems Considered
election pair E = (C, V ) C set candidates (or alternatives) V
ordered list voters. voter represented vote, strict, linear order
set candidates (also called voters preference order ). refer
list V preference profile, denote number voters V n. number
alternatives denoted m. order voters important (the election
anonymous), V considered multiset2 votes. paper
consider anonymous elections.
posv (c) denote position alternative c ranking voter v;
top-ranked alternative position 1, second best position 2, etc.
2. set since two different voters may preference order.

478

fiOn Computation Fully Proportional Representation

Q

Definition 1. Given profile V C, mapping r : V C +
0 called
misrepresentation function v V two candidates c, c C condition
posv (c) < posv (c ) implies r(v, c) r(v, c ).
say c preferred c vs ranking, misrepresentation v,
represented c least large misrepresentation,
represented c. classical framework misrepresentation candidate
voter function position candidate preference order voter
given = (s1 , . . . , sm ), i.e., misrepresentation function case
r(v, c) = sposv (c) .
important particular case Borda misrepresentation function defined vector
(0, 1, . . . , 1).
approval voting framework, voter represented candidate
approves, misrepresentation considered zero, otherwise equal one.
function called approval misrepresentation function. misrepresentation function positional since different voters may approve different number
candidates. Note misrepresentation functions, like Borda, derived
preference lists voters. contrast, approval misrepresentation function cannot obtained preference list without information threshold
separates approved candidates disapproved ones. general framework
misrepresentation function may arbitrary.
w : V C denote function assigns voters representatives (or
way around), i.e., assignment voter v represented candidate w(v).
total misrepresentation election w given
X
r(v, w(v)) max r(v, w(v))
vV

vV

Harsanyis classical Rawls minimax versions, respectively. say mapping w respects -criterion (or Monroe criterion) |w(V )| = k w assigns least
n/k n/k voters every candidate w(V ), k total number
representatives elected assembly. Note case -criterion set
k winners might lead higher misrepresentation set k winners.
example, consider election voters favour candidate
set winners elected greater one.
Based previous discussion, work investigate computational complexity following four combinatorial problems. two classical ones described
named Chamberlin Courant (CC), case candidate represent arbitrary number voters (and number voters weight
elected assembly), Monroe (M), case every candidate represents roughly
number voters (and representative one vote assembly). two
previously unstudied versions adopt Rawlsian approach measuring total
misrepresentation called minimax versions classical ones.
CC-Multiwinner (CC-MW)
Given: set C candidates, multiset V voters, misrepresentation
function r, misrepresentation bound R +
0 positive integer k.

Q

479

fiBetzler, Slinko, & Uhlmann


Task: Find subset
P C C size k assignment voters w

w(V ) = C vV r(v, w(v)) R.

Minimax CC-Multiwinner (Minimax CC-MW)
Given: set C candidates, multiset V voters, misrepresentation
function r, misrepresentation bound R +
0 positive integer k.

Q

C

Task: Find subset
C size k assignment voters w
w(V ) = C maxvV r(v, w(v)) R.
M-Multiwinner (M-MW)
Given: set C candidates, multiset V voters, misrepresentation
function r, misrepresentation bound R +
0 positive integer k.

Q

C

Task: Find subset
C size k assignment
voters w,
P

respects -criterion, w(V ) = C vV r(v, w(v)) R.

Minimax M-Multiwinner (Minimax M-MW)
Given: set C candidates, multiset V voters, misrepresentation
function r, misrepresentation bound R +
0 positive integer k.

Q

C

Task: Find subset
C size k assignment voters w,
respects -criterion, w(V ) = C maxvV r(v, w(v)) R.
Note finding assignment voters fixed set k winners accomplished polynomial time four problems applying network flow algorithms (see
Section 3.2). Hence, follows assume k < k < n since otherwise
four problems decided polynomial time. also note problems considered
contained NP since one guess set k winners corresponding mapping
voters check polynomial time whether satisfies corresponding conditions.
four problems stated general misrepresentation functions (since
algorithmic results hold even case) main focus work
Borda approval ones.
1.2 Previous Computational Complexity Results
study computational complexity problems context voting initiated Bartholdi III, Tovey, Trick (1989) 20 years ago became active
area research recently (Conitzer, 2010; Faliszewski & Procaccia, 2010; Faliszewski,
Hemaspaandra, & Hemaspaandra, 2010; Faliszewski, Hemaspaandra, Hemaspaandra, &
Rothe, 2009b). large number papers dealing single-winner elections
multi-winner elections whose final goal still choose single winner tiebreaking, articles (Potthof & Brams, 1998; Procaccia et al., 2008; Lu & Boutilier,
2011) deal computational complexity Multiwinner elections aimed achieving
proportional representation. particular, works contain NP-hardness proofs
CC-Multiwinner M-Multiwinner approval misrepresentation function (Procaccia et al., 2008) CC-Multiwinner Borda misrepresentation function (Lu &
Boutilier, 2011). Algorithmic approaches comprise Integer Linear Programming (Potthof &
480

fiOn Computation Fully Proportional Representation

Brams, 1998; Brams, 2008) CC-MW M-MW, approximation algorithms based
greedy strategies (Lu & Boutilier, 2011) CC-MW, polynomial-time algorithms
CC-MW M-MW instances number candidates constant (Procaccia
et al., 2008). contrast, best knowledge, computational complexity
minimax versions problems remained unstudied.
aware one work explicitly studying computational complexity
issues context multiwinner elections. Meir, Procaccia, Rosenschein, Zohar
(2008) investigate computational complexity strategic voting several multiwinner
elections winner determined polynomial time. systems considered
lead kind proportional representation.
1.3 Approach Results General Elections
first result minimax versions classical Chamberlin-Courant Monroe problems also NP-complete. words, adopting Rawlsian approach
make computation problems easier general (but see situation changes completely single-peaked elections minimax version becomes
easier indeed). Based negative results, work aims extending previous
algorithmic approaches described analysis whether settings
problems become tractable. end, parameterized algorithmics
appropriate tool aims identifying tractable special cases NP-hard problems.
cornerstone approach idea complexity problem measured total size input instance also additional parameter p, usually
nonnegative integer (but pair integers virtually anything). problem called fixed-parameter tractable algorithm solving every instance
f (p) poly(|I|) time, f computable function (Downey & Fellows, 1999; Flum
& Grohe, 2006; Niedermeier, 2006). small values p algorithm running
time might represent efficient algorithm NP-hard problem consideration.
Parameterized complexity also provides tool parameterized reductions one
show problem presumably fixed-parameter tractable. One
important parameterized complexity classes purpose W [2] (see Section 2
details). remark passing parameterized complexity analysis employed several voting problems, (e.g., see Brandt, Brill, & Seedig, 2011; Betzler,
Guo, & Niedermeier, 2010; Betzler, Hemmann, & Niedermeier, 2009; Christian, Fellows,
Rosamond, & Slinko, 2007; Dorn & Schlotter, 2010; Elkind, Faliszewski, & Slinko, 2010b;
Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a also Betzler, Bredereck,
Chen, & Niedermeier, 2012 survey).
context multiwinner elections, parameter immediately attracts attention
number k winners, many settings might much smaller number
candidates number voters. Another reasonable parameter misrepresentation bound R since ideal (or fully personalizable Lu & Boutilier, 2011) situation R
equal zero, is, every voter represented one preferred candidates.
provide parameterized complexity analysis four considered problems
Borda approval misrepresentation functions respect parameters k R.
481

fiBetzler, Slinko, & Uhlmann

Parameter

r

CC-MW

Minimax CC-MW

M-MW

Minimax M-MW

#winner k
#winner k


B

W[2]-hard ()
W[2]-hard ()

W[2]-hard ()
W[2]-hard ()

W[2]-hard ()
W[2]-hard ()

W[2]-hard ()
W[2]-hard ()

misr. R
misr. R


B

NP-h R = 0 ()
XP ()

NP-h R = 0 ()
NP-h R 1 ()
P R = 0 ()

NP-h R = 0 ()
XP ()

NP-h R = 0 ()
NP-h R 1 ()
P R = 0 ()

(R, k)
(R, k)


B

W[2]-hard ()
FPT ()

W[2]-hard ()
FPT ()

W[2]-hard ()
FPT ()

W[2]-hard ()
FPT ()

# cand.
# voters

U
U

FPT ()
FPT ()

FPT ()
FPT ()

FPT ()
FPT ()

FPT ()
FPT ()

Table 1: Parameterized complexity considered multiwinner problems instances
misrepresentation function r either approval (A), Borda (B) unrestricted (U). Results obtained follows. : Theorem 1, : Theorem 2, : Theorem 3, : Theorem 4, : Theorem 5, : Theorem 6, : Theorem 7 : Proposition 1,
Proposition 2.

addition, also investigate composite parameter (R, k) consisting number
winners misrepresentation bound.
overview results provided Table 1. number winners k
parameter, considered problems turn W[2]-hard. parameterization
total misrepresentation bound R results varied. case R = 0,
approval misrepresentation function four problems NP-hard
solvable polynomial time Borda misrepresentation function. However, Minimax
CC-MW Minimax M-MW become NP-hard every R 1. contrast, summinimization variants CC-MW M-MW Borda misrepresentation function
solvable polynomial time constant R (the corresponding parameterized complexity
class called XP). Note provided algorithm shows containment XP
respect R fixed-parameter tractability, problem remains open. inspired
analysis composite parameter (R, k), covering scenarios small
set winners represent voters small total misrepresentation.
approval misrepresentation function, still leads parameterized intractability, Borda misrepresentation function, show fixed-parameter tractability
considered problems. complete picture multivariate complexity analysis,
additionally provide fixed-parameter tractability respect parameters number
voters number candidates.
1.4 Results Single-Peaked Elections
Single-peakedness one central notions social choice political science alike
(Black, 1958; Moulin, 1991; Tideman, 2006). preferences voters single-peaked
single issue dominates formation. could ideological position
Left-Right Liberal-Conservative spectra, level taxation, immigration quota, etc.
Tideman compares single-peakedness convexity preferences discusses
482

fiOn Computation Fully Proportional Representation

CC-MW
2

O(nm )

Minimax CC-MW
O(nm)

M-MW
3

3 3

O(n k ) approval
NP-h integer mis. func.

Minimax M-MW
O(n3 m3 k3 )

Table 2: Overview computational complexity singled-peaked elections. case
polynomial-time solvability, table provides running times depending
number n voters, number candidates, number k
winners. stated otherwise, result holds arbitrary misrepresentation
function. : Theorem 8, : Proposition 4, : Theorem 10, : Proposition 5,
: Theorem 11.

reasonable assume this. refers data collection containing 87 ranked-ballot real-life
elections, access to, claims single-peaked.
single dominating issue normally represented axis voter characterized single point axis (see example Figure 1. misrepresentation
function fixed voter function single variable defined axis.
single-peakedness preferences implies function exactly one local minimum.
refer Section 5 formal proof statement.
note votes form approval ballots well linear orders, singlepeakedness profile checked linear time (Booth & Lueker, 1976; Escoffier,
Lang, & Ozturk, 2008) reconstruction order candidates axis.
case single-peaked profiles computational problems turned
allow efficient solving strategies general case (Brandt, Brill, Hemaspaandra, & Hemaspaandra, 2010; Conitzer, 2009). particular, study computational complexity voting rules NP-hard winner-determination problem shows
Condorcet-consistent onesand include Dodgson, Kemeny, Young
rulesthe winner-determination problem becomes polynomial-time solvable restrict
single-peaked profiles (Brandt et al., 2010). obvious reason
single-peakedness eliminates possibility Condorcet cycles election profile.
obvious single-peakedness must also simplify winner-determination
problem methods proportional representation. However, seems natural investigate possibility. results show many instances winner-determination
problem methods proportional representation indeed become easier too.
results summarized Table 2. CC-MW Minimax CC-MW problems solvable polynomial time arbitrary misrepresentation function.
specifically, CC-MW provide dynamic programming algorithm running O(nm2 )
time n voters candidates, Minimax CC-MW solved O(nm) time
greedy algorithm. Monroe system variants, results become
diverse. Minimax M-MW general misrepresentation function still solvable
polynomial time, M-MW NP-hard. However, positive side, still show
polynomial-time solvability M-MW approval misrepresentation function. Basically, results obtained follows. M-MW approval misrepresentation
483

fiBetzler, Slinko, & Uhlmann

function establish close connection one-dimensional rectangle stabbing problem capacities. allows provide dynamic programming algorithm based
decomposition property provided Even, Levi, Rawitz, Schieber, Shahar, Sviridenko
(2008). result transferred Minimax M-MW. NP-hardness M-MW
established many-one reduction restricted version Exact 3-Cover
problem. NP-hardness holds integer-valued misrepresentation function
maximum misrepresentation value still polynomial number candidates. However, need allow situations voter may equally misrepresented several
candidates. Hence, clear transfer corresponding many-one reduction
M-MW Borda misrepresentation function. problem computational
complexity left open.
1.5 Organization Paper
paper organized follows. Section 2, introduce main concepts parameterized complexity graph problems. Section 3 contains basic observations
relations four problems consideration fixed-parameter tractability results respect number voters number candidates. two main
contributions proved Section 4 Section 5. Section 4, present main parameterized complexity results well NP-hardness results minimax versions.
Section 5, special case single-peaked elections handled. Finally, Section 6
conclude discussion relevance results related problems
settings.

2. Preliminaries
briefly introduce framework parameterized complexity followed basic
graph problems employed paper. basic notions regarding classical
complexity theory refer Garey Johnson (1979).
2.1 Parameterized Complexity
concept parameterized complexity pioneered Downey Fellows (1999). See
also textbooks Flum Grohe (2006) Niedermeier (2006). fundamental
goal find whether seemingly unavoidable combinatorial explosion, occurring
exact algorithms NP-hard problems, confined certain problem-specific parameters. idea parameter real-life application restricted small
values only, algorithm running time exponential exclusively
respect parameter may efficient practical. provide formal definitions.
Definition 2. parameterized problem language L , finite
alphabet. second component called parameter problem.
Basically, means input parameterized problem pair (x, p), x
considered main input p parameter problem. consider
parameters positive integers composite parameters tuples several
positive integers.
484

fiOn Computation Fully Proportional Representation

Definition 3. parameterized problem L fixed-parameter tractable algorithm decides f (p) |x|O(1) time whether (x, p) L, f arbitrary
computable function depends p. complexity class fixed-parameter
tractable problems called FPT.
Unfortunately, parameterized problems fixed-parameter tractable.
end, Downey Fellows (1999) developed theory parameterized intractability
means completeness program complexity classes. specifically, defined
so-called W -hierarchy using Boolean circuits. hierarchy consists following
classes:
FPT W[1] W[2] . . . W[Sat] W[P] XP
(we refer reader book Downey & Fellows, 1999, precise description).
particular, stress concept fixed-parameter tractability different
notion polynomial-time solvability constant p since algorithm running
O(|x|p ) time imply fixed-parameter tractability. problems solved
running time O(|x|f (p) ) computable function f form complexity class called
XP.
containment W[1] FPT would imply P = NP such. would imply,
however, failure Exponential Time Hypothesis (Impagliazzo, Paturi, & Zane,
2001). Hence, commonly believed W[1]-hard problems fixed-parameter
tractable. show W[t]-hardness problem positive integer t, following
reduction concept introduced.
Definition 4. Let L, L two parameterized problems. say L reduces
L parameterized reduction two computable functions h1 :
h2 : + function f : (x, p)

N Q

1. (x, p) L f (x, p) L f computable time |x|O(1) h2 (|p|)
2. (x , p ) = f (x, p), p = h1 (p).
Analogously case NP-hardness, positive integer t, suffices give
parameterized reduction one W[t]-hard parameterized problem X parameterized
problem show W[t]-hardness . details parameterized complexity theory refer textbooks (Downey & Fellows, 1999; Flum & Grohe, 2006;
Niedermeier, 2006).
work, provide results regarding second level (presumable) parameterized intractability captured complexity class W[2]. Several parameterized
reductions work W[2]-complete Hitting Set (HS) problem: Given
family F = {F1 , . . . , Fn } sets universe U = {u1 , . . . , um } integer k 0,
decide whether hitting set U U size k understand
set U Fi U 6= every 1 n. HS NP-hard (Garey & Johnson, 1979)
W[2]-hard respect parameter k (Downey & Fellows, 1999).
2.2 Graph Problems
algorithmic results employ algorithms basic graph problems defined
following. undirected graph pair G = (U, E), consisting set U vertices
485

fiBetzler, Slinko, & Uhlmann

set E edges, edge unordered pair (size-two set) vertices. Two
vertices u, v U called adjacent {u, v} E. undirected graph G = (U, E)
vertex u U , neighborhood N (u) u set vertices adjacent u.
undirected graph G = (U, E) called bipartite vertex set U partitioned
two nonintersecting subsets U1 U2 E {{u, v} | u U1 v U2 }.
matching edge set E E e e = every two distinct edges e, e E .
maximum matching matching maximum cardinality. undirected graph
edge {u, v} associated
weight w({u, v}) maximum-weight matching
P
matching E {u,v}E w({u, v}) maximal.
directed graph directed network pair G = (U, A), consisting set U
vertices set U U directed edges (or arcs) directed edge
ordered pair vertices. flow network directed network G = (U, A)
two distinguished vertices U (the source) U (the sink target)
arc (u, v) associated nonnegative number c(u, v), called capacity. Roughly
speaking, flow function f assigns real value f (u, v) 0 f (u, v) c(u, v)
every arc (u, v) satisfies constraints every vertex v except
source sink total flow v equals total flow v. See textbook
Cormen, Leiserson, Rivest, Stein (2001) details. maximum flow flow
total flow sink maximal.
paper, make use fact maximum-weight matching bipartite
graph well maximum flow general graphs computed polynomial time
standard graph algorithms (e.g., see Cormen et al., 2001).

3. Basic Results Observations
section, shed light combinatorial relations problems
investigate parameterized complexity considered problems respect
parameters number voters number candidates. results also
employed following sections. particular, algorithms showing fixedparameter tractability used subroutines Section 4 obtain fixed-parameter
tractability respect parameterizations.
3.1 Relations Problems
Although four problems come different properties general, special cases,
coincide. One example so-called fully personalizable setting (Lu
& Boutilier, 2011), is, case misrepresentation bound R zero hence
every voter represented one best alternatives (i.e., one
misrepresentation zero). Clearly, asking set winners assignment
sum misrepresentations zero equivalent asking set winners
assignment maximum misrepresentation value zero. leads
following observation.
Observation 1. R = 0, Minimax M-Multiwinner coincides M-Multiwinner
Minimax CC-Multiwinner coincides CC-Multiwinner.
486

fiOn Computation Fully Proportional Representation

Moreover, two minimax versions problems, matters whether
particular misrepresentation value exceeds threshold R not. Hence, instance
minimax version arbitrary misrepresentation function r reduced
equivalent instance problem approval misrepresentation function r
follows. every voter v every candidate c, set r (v, c) = 1 r(v, c) > R,
r (v, c) = 0 r(v, c) R and, finally, set R := 0.
Observation 2. Minimax M-/CC-Multiwinner instance (C, V, r, R, k) misrepresentation function r, instance (C, V, r , 0, k) approval misrepresentation function r new instance yes-instance original
instance yes-instance.
direct consequence, minimax versions every algorithm approval misrepresentation function also applies instances general misrepresentation function.
Moreover, hardness results arbitrary misrepresentation function transfer approval misrepresentation function. Combining Observations 1 2, conclude
algorithm M-MW (CC-MW) instances R = 0 also solves corresponding
minimax version general misrepresentation function.
Finally, observe hardness result established approval misrepresentation
function directly transferred minimax version problem
misrepresentation function voter allowed give arbitrary number
candidates misrepresentation value R. Note hold
Borda misrepresentation function every voter v must specify exactly R+1 candidates
represent v misrepresentation R.
3.2 Numbers Voters Candidates Parameters
argue four problems considered fixed-parameter tractable respect
number candidates well respect number voters. algorithms
based brute-force search combined maximum flow matching techniques.
First, consider parameterization number voters. Then, focus
parameterization number candidates.
3.2.1 Number Voters Parameter
show considered multiwinner problems fixed-parameter tractable parameterized number n voters. basic idea assignment candidates
voters induces partition set voters voters set
partition represented candidate. Given partition set voters,
best set candidates partition found computation matching
bipartite auxiliary graph. Since may try O(kn ) O(nn ) partitions set
voters k sets resulting algorithm shows fixed-parameter tractability.
Proposition 1. (Minimax) CC-Multiwinner (Minimax) M-Multiwinner
solved nn poly(n, m) time instance n voters candidates.
Proof. First, present solution strategy Minimax CC-MW. find set k
winners, try O(kn ) partitions set voters k subsets. case yesinstance Minimax CC-MW, must partition V1 , . . . , Vk multiset voters
487

fiBetzler, Slinko, & Uhlmann

V follows. every Vi , voters Vi assigned candidate c optimal
set k winners voter assigned c. Hence, every partition, remains
select k candidates, one candidate ci every subset Vi , assigning voters
Vi ci misrepresentation voter R. Minimax CC-MW
set candidates determined computing maximum-cardinality matching
following bipartite graph. One part graph represents set candidates
part set {V1 , . . . , Vk }. Moreover, edge vertex representing
candidate c vertex representing subset Vi r(v, c) R v Vi .
straightforward verify voters represented maximal misrepresentation
bound R maximum-cardinality matching size k (all vertices
representing subsets matched) constructed graph.
Regarding running time, computation maximum-weight matching
bipartite graph nv vertices ne edges accomplished O(nv (ne + nv log nv ))
time (Fredman & Tarjan, 1987). Since number edges vertices constructed
bipartite graph polynomial number candidates k n, claimed running
time follows.
Next, focus CC-MW. Again, try partitions voters k subsets.
every partition, compute maximum-weight matching following edgeweighted bipartite graph. One part consists vertices corresponding candidates
part vertices corresponding subsets partition V1 , . . . , Vk
multiset voters.
PMoreover, edge every vertex c every vertex Vi
weight vVi r(v, c), positive integer large enough ensure
weights positive. crucial observation maximum-weight matching
every vertex V1 , . . . , Vk matched since edge weights positive (here assume
k m). Hence, computation maximum-weight matching yields set k
candidates representing subsets voters good possible. specifically,
let W denote weight maximum-weight matching. Then, kT W total
misrepresentation corresponding assignment.
Finally, observe two problems assignment voters
winners must fulfill -criterion proceed way single exception
need consider partitions every subset contains least n/k
n/k voters. running time bound follows complete analogy Minimax
CC-MW discussed above.
3.2.2 Number Candidates Parameter
fixed number candidates four considered multiwinner problems solved
efficiently. (Minimax) CC-Multiwinner parameterizedby number candim
dates fixed-parameter tractability trivial: test
k 2 subsets candidates
report set candidates minimum total misrepresentation. end, one
assigns every voter v candidate considered subset represents v
best possible way directly obtains sum misrepresentations maximum
misrepresentation.
Clearly, assignment voters fulfill -criterion. However, (Minimax) M-Multiwinner, one apply network flow algorithms find
488

fiOn Computation Fully Proportional Representation

optimal assignment voters size-k subset C set candidates (see
Preliminaries Subsection 2.2 basic definitions regarding network flows).
Minimax M-Multiwinner, construct directed network vertex every
candidate C , one vertex every voter, source, sink vertex.
arc capacity n/k lower bound n/k source every candidatevertex3 . Moreover, capacity-one arc candidate-vertex votervertex corresponding candidate represent corresponding voter
misrepresentation R. Finally, arc capacity one every
voter-vertex sink vertex. straightforward verify network
flow size n assignment voters C satisfies
-criterion every voter represented misrepresentation R.
M-Multiwinner, construction given minimax version
extended. particular, follows Theorem 2 Procaccia et al. (2008), finding
-criterion fulfilling assignment V C minimum total misrepresentation
accomplished polynomial time computation transportation problem
or, equivalently, computation minimum-weight maximum flow.
Proposition 2. (Minimax) CC-Multiwinner (Minimax) M-Multiwinner
solved O(2m nm) O(2m poly(n, m)) time, respectively, instances
candidates.

4. Number Winners Misrepresentation Bound
Parameters
section, show four problems approval Borda misrepresentation functions W[2]-hard respect number winners. misrepresentation functions provide one parameterized reduction works four
problems. investigate misrepresentation bound R parameter.
approval misrepresentation function NP-hardness R = 0 follows directly
parameterized reduction respect number winners, Borda misrepresentation function, parameter needs investigated separately. show CC-MW
M-MW XP respect R, is, solvable polynomial time
R constant. However, corresponding algorithm show fixed-parameter
tractability respect R. question whether result extended
fixed-parameter tractability respect R left open. present, however,
fixed-parameter tractability results respect composite parameter (R, k)
end section. overview results found Table 1.
4.1 Approval Misrepresentation Function
provide reduction W[2]-complete Hitting Set problem establish W[2]hardness four problems. so, discuss related results. conference paper (Procaccia, Rosenschein, & Zohar, 2007) stated NP-hardness
CC-Multiwinner M-Multiwinner follows reduction Max k-Cover
3. problem variant lower bounds (demands) solved polynomial time simple reduction
normal flow problem (Ahuja, Magnanti, & Orlin, 1993, Section 6.7).

489

fiBetzler, Slinko, & Uhlmann

(omitting problem definition construction) subsequent journal paper (Procaccia et al., 2008) reduction given Exact 3-Cover. Although
sufficient show NP-hardness, reduction Exact 3-Cover imply W[2]hardness. reduction given conceptually similar requires additional
voters deal fact sets Hitting Set instance might come
different/unbounded size.
Theorem 1. approval misrepresentation function, (Minimax) CC-Multiwinner
(Minimax) M-Multiwinner W[2]-hard respect number k winners
even R = 0. Minimax CC-Multiwinner Minimax M-Multiwinner NPcomplete.
Proof. First, show W[2]-hardness M-Multiwinner. Then, argue presented reduction works three problems well.
Given instance Hitting Set (F = {F1 , . . . , Fn }, U = {u1 , . . . , um }, k), build
instance M-Multiwinner set C candidates follows. candidate ci
C every element ui U . multiset voters VF D, VF := {vF | F F}
multiset voters indexed F |D| = n(k 1) set dummy voters.
Furthermore, every F F every ui U , let r(vF , ci ) := 0 ui F r(vF , ci ) :=
1, otherwise. Finally, every every ui U , set r(d, ci ) := 0. completes
construction. correctness show following.
Claim. hitting set size k F winner set
size k M-Multiwinner represents voters total misrepresentation R = 0.
: Let U denote size-k hitting set F C := {ci | ui U }. show one
build mapping w : V C respects -criterion total misrepresentation
zero. First, every F F, set w(vF ) := ci arbitrary chosen element ui F U .
Clearly, r(vF , ci ) = 0. far, n voters VF assigned candidates C
remains assign n(k1) voters D. Since candidate C represent
dummy voter misrepresentation zero, easily extend assignment
candidate C assigned exactly n voters.
:PLet C C denote size-k winner set let w mapping V C
vV r(v, w(v)) = 0. Since voter vF VF represented cost zero
candidate ci ui F , set U := {ui | ci C } size-k hitting set F.
completes proof M-Multiwinner. straightforward verify
construction yields parameterized reduction CC-Multiwinner. Finally,
W[2]-hardness minimax versions follows directly Observation 1 since
reduction works R = 0. Moreover, NP-hardness directly follows since reduction
clearly carried polynomial time containment NP obvious.
4.2 Borda Misrepresentation Function
refine reduction previous subsection show also Borda misrepresentation function considered problems W[2]-hard respect number k
490

fiOn Computation Fully Proportional Representation

winners parameter. However, contrast case approval misrepresentation function reduction hold case R = 0. Hence, investigate
parameter total misrepresentation R well composite parameter (R, k) subsequently.
4.2.1 Number Winners Parameter
Borda misrepresentation function, also provide many-one reduction
Hitting Set M-Multiwinner argue presented reduction works
three problems well. CC-Multiwinner W[2]-hardness also directly
follows NP-hardness reduction (also Hitting Set) provided Lu
Boutilier (2011, Thm. 8).4 reduction, however, deal M-criterion
adopted minimax versions two rules; particular, using padding
candidates voters deal M-criterion.
Theorem 2. (Minimax) CC-Multiwinner (Minimax) M-Multiwinner W[2]hard respect number k winners Borda misrepresentation function.
Minimax CC-Multiwinner Minimax M-Multiwinner NP-complete.
Proof. First, show W[2]-hardness M-Multiwinner parameterized reduction
Hitting Set. Given HS-instance (F = {F1 , . . . , Fn }, U = {u1 , . . . , um }, k) build
instance M-Multiwinner follows. Let z := nmk. set C candidates CU B,
CU := {cu | u U } B := {b1i , . . . , bzi | 1 nk}. Moreover, multiset
voters VF D, VF := {vi | Fi F} := {d1 , . . . , dn(k1) }. voter
misrepresentation function given preference list.5
n set voters vi VF following preference list:
{cu | u Fi } > b1i > . . . > bzi > {cu | u U \ Fi } > {b1j , . . . , bzj | 1 j nk, j 6= i}.
Finally, {1, . . . , n(k 1)}, voter di following preference
list:
c1 > c2 > . . . > cm > b1n+i > . . . > bzn+i > {b1j , . . . , bzj | 1 j nk, j 6= n + i}.
completes construction. correctness show following.
Claim. size-k hitting set F size-k winner
set M-Multiwinner represents voters total misrepresentation
z = nmk.
: Let U denote size-k hitting set F C := {cu | u U }. build
mapping w : V C follows. First, every Fi F, set w(vi ) := cu arbitrarily
chosen element u Fi U . Clearly, r(vi , cu ) since elements Fi top preference
list vi |Fi | m. far, n voters VF assigned candidates C .
4. proof provided extended version appeared Third International Workshop
Computational Social Choice (COMSOC-10) title Budgeted Social Choice: Framework
Multiple Recommendations Consensus Decision Making, see Thm. 6.
5. improve readability, also use sets candidates description preference lists.
set fixed arbitrary order.

491

fiBetzler, Slinko, & Uhlmann

Since candidate C represent dummy voter misrepresentation
m, one extend mapping exactly n voters assigned cu C
misrepresentation voter. Thus, total misrepresentation
assignment nm + nm(k 1) = nmk.
:PLet C C denote size-k winner set w mapping V C
vV r(v, w(v)) mnk. First, show C contain candidate bji B.
Every candidate B represent one voter misrepresentation value better
z. specifically, 1 n, bji represent voter vi
quality representation if, n < nk, bji present voter di . Since
every candidate C must assigned exactly n voters misrepresentation
bound z, conclude C B = .
remains show U := {u U | cu C } hitting set F. voter vi
VF represented candidate cu CU misrepresentation z
u Fi since candidates cu u U \ Fi occur preference list vi
candidates b1i , . . . , bzi . Thus, U hitting set F size k.
completes proof M-Multiwinner. construction yields parameterized reduction CC-Multiwinner based claim. direction
left right follows complete analogy. direction, difference
solution set C CC-Multiwinner instance might contain candidate
B. However, candidate bji , represent one voter
(that is, vi ) within required misrepresentation bound hence replaced
candidate cu Fi represents corresponding voter even better.
proof Minimax M-Multiwinner Minimax CC-Multiwinner, follows directly arguments size-k hitting set F
set winners Minimax M/CC-Multiwinner consisting k candidates
represent voters maximum misrepresentation R := 1. Hence,
W[2]-hardness well NP-hardness follow.
4.2.2 Parameter Misrepresentation Bound
Recall approval misrepresentation function, four problems NP-hard even
fully personalized setting, is, R = 0. contrast, CC-MW MMW Borda misrepresentation function, provide polynomial-time algorithms
every constant R showing minimax versions NP-hard R 1
polynomial-time solvable R = 0. First, simple exhaustive search strategy, one
obtains following.
Theorem 3. Borda misrepresentation function, CC-Multiwinner M-Multiwinner solvable polynomial time misrepresentation bound R constant.
Proof. every solution, R voters represented misrepresentation greater
0. Thus, constant values R, one try O(|V |R ) subsets R voters
find subset V V voters represented misrepresentation value
zero optimal winner set. subset V , voter v V , one
tries possible misrepresentation values 1 R, is, one tries O(RR )
possibilities V . possibility, misrepresentation value
492

fiOn Computation Fully Proportional Representation

voter determined. Since Borda exactly one candidate represent
voter specific value, also implies corresponding mapping V set
candidates. Every remaining voter assigned candidate represents
misrepresentation value zero. case CC-Multiwinner, remains check
whether k candidates become representatives whether corresponding
set candidates represent voters total misrepresentation R. case
M-Multiwinner one additionally needs check whether corresponding assignment
satisfies -criterion. follows cases optimal set k winners
computed O((|V | R)R |V ||C|) time.
Note Theorem 3 imply fixed-parameter tractability respect R,
remains open work. However, provide fixed-parameter tractability results
respect composite parameter (R, k) end section. Now, contrast
results CC-MW M-MW showing minimax versions become provably
difficult. specifically, show following.
Theorem 4. Borda misrepresentation function, minimax CC-Multiwinner
minimax M-Multiwinner solvable polynomial time total misrepresentation
bound R = 0 NP-hard every R 1.
Proof. R = 0 polynomial-time solvability follows directly fact every voter v
must assigned candidate c r(v, c) = 0 Borda misrepresentation
function one candidate. Hence, one needs check less
k candidates and, minimax M-Multiwinner whether corresponding
assignment satisfies M-criterion.
Now, show NP-hardness R = 1 reduction special case Hitting
Set. specifically, Hitting Set NP-hard even every set consists two elements
every element appears three sets (Garey, Johnson, & Stockmeyer, 1974,
Thm. 2.4).6
Given restricted HS-instance (F = {F1 , . . . , Fn }, U = {u1 , . . . , um }, k), build
election follows. Identify every set F voter identify every element
U candidate. Moreover, define following misrepresentation function.
F = {u, v} F, let misrepresentation voter F zero candidate u
one candidate v, remaining misrepresentation values assigned arbitrarily
remaining candidates. Then, following claim easy see.
Claim: hitting set size k set k winners
misrepresentation voter 1.
shows theorem Minimax CC-MW R = 1. Minimax M-MW,
one use following observation showing NP-hardness even restricted
setting. follows directly Hitting Set instances constructed NP-hardness
proof (Garey et al., 1974, Thm. 2.4) yes-instance always hitting set
every element hits either two three sets F. specifically, case
yes-instance hitting set U U every u U assigned
6. problem Vertex Cover cubic graphs.

493

fiBetzler, Slinko, & Uhlmann

1
2
3
4
5
6
7
8
9
10
11
12
13

Branch (V , R , C ) :
R < 0 |C | > k
return no;
P
wV (mindC r(w, d)) R
return yes;
Consider arbitrary v V ;
V := V \ {v};
c C r(v, c) R
R := R r(v, c) ;
C := C {c};
V := V \ {w V | r(w, c) = 0};
Branch (V , R , C )
return yes ;

14
15
16

end
return no;

Algorithm 1: Branching strategy CC-Multiwinner Borda misrepresentation
functions showing fixed-parameter tractability respect composite parameter (R, k). Initially, algorithm invoked arguments (V, R, ). Moreover, C
k provided global variables.
either two three sets F every set hit exactly one element.
hitting set one-to-one-corresponds winner set fulfilling M-criterion hence
theorem also follows Minimax M-MW R = 1. every R > 1, NP-hardness
proved similar arguments. Basically, extend previous construction follows.
every voter, add R 1 new candidates placed first R 1 positions
voter position higher R every voter. Since new candidates
clearly cannot part Minimax M-MW solution misrepresentation bound R,
one argue analogously case.
4.2.3 Composite Parameter Number Winners Misrepresentation
Bound
paragraph, focus scenario one small set winners
represent voters small total misrepresentation. modeled composite
parameter (R, k), k number winners R total misrepresentation.
show Borda misrepresentation function, four considered problems
fixed-parameter tractable.
Theorem 5. Borda misrepresentation function, CC-Multiwinner Minimax CC-Multiwinner fixed-parameter tractable respect composite parameter (R, k), k denotes number winners R misrepresentation bound.
Proof. First, provide branching strategy Minimax CC-MW. find size-k
solution proceed follows. arbitrary voter v V , branch according
494

fiOn Computation Fully Proportional Representation

candidates c r(v, c) R. possibility, create subinstance deleting
voter w r(w, c) R V recursively solve corresponding subinstance
k 1. Finally, report whether least one subinstance solution size k 1
found. recursion stops either k < 0 (reporting no) voters
represented (reporting yes).
correctness corresponding algorithm obvious since voter v must represented candidate c r(v, c) R. Regarding running time, one branches
R + 1 possibilities every considered voter decreases value k one
every subinstance. Hence, algorithm investigates (R + 1)k possibilities.
show extend branching strategy work CC-MW. branching
recursion displayed Algorithm 1 invoked arguments (V, R, ). Note
C k provided global variables.
correctness Algorithm 1 seen follows. algorithm first checks
whether misrepresentation bound solution size exceeded (Line 2). Second,
algorithm checks whether current candidate set already winner set, is,
whether voters represented assignment within misrepresentation bound
(Line 4). Otherwise, arbitrarily chosen voter v (Line 6), algorithm tries
possible ways representation without exceeding misrepresentation bound (Line 8).
possibility, decreases R value needed representation v
corresponding candidate (Line 9). possibility implies new candidate added
current solution, clearly assign voters optimally represented
candidate hence delete corresponding voters (Line 11). Finally,
recursively invoke Branch procedure corresponding subinstance (Line 12). Since
possibilities represent v considered least one possibility must lead solution
(if one exists).
Regarding running time, show recursive call (Line 12)
algorithm decreases R increases |C | (or both). initial call one C =
hence |C | increased one (Line 10). every call, case |C |
increased considered candidate c already current solution set C .
case, one cannot r(v, c) = 0 since v would deleted V
point c added C . Hence, r(v, c) > 0 R decreased (Line 9).
Since recursion ends R < 0 |C | > k (Line 2), follows recursion
depth R + k. Moreover, recursive call, one branches according R + 1
possible candidates (Line 8). Hence, algorithm executed (R+1)R+k poly(n, m)
time.
remark results Theorem 5 also hold instance misrepresentation functions nonnegative integer values |{c C | r(v, c) R}| R + 1
every voter v V . Moreover, fixed-parameter tractability already follows |{c C |
r(v, c) R}| f (k, R) computable function f . contrast, branching strategy
CC-MW Theorem 5 cannot directly transferred M-MW since due
M-criterion one cannot assign voter selected candidate even best alternative. means analogous approach parameter could reduced
and, hence size search tree could bounded. show fixed-parameter
495

fiBetzler, Slinko, & Uhlmann

tractability M-MW apply different approach employ structural observations
based M-criterion.
Consider instance (C, V, r, R, k) M-MW. Let zero-candidate candidate c C
r(v, c) = 0 least one voter v V .
Lemma 1. yes-instance M-Multiwinner Borda misrepresentation function, R + k zero-candidates.
Proof. apply proof contradiction. Assume R + k zerocandidates size-k winner set representing voters total misrepresentation R. Borda misrepresentation function, every voter v exactly
one candidate c r(v, c) = 0. c part winner set, v contributes
least one total misrepresentation since r(v, c ) 1 every c C \ {c}. Since
R + k zero-candidates, R part size-k solution.
corresponding voter represented candidate
solution misrepresentation least one. Hence, total misrepresentation
R; contradiction.
make use bounded number zero-candidates, provide another observation
exploits M-criterion solution.
Lemma 2. Consider M-Multiwinner instance Borda misrepresentation function. number n voters greater (R + 1)k, every size-k set winners
consists zero-candidates.
Proof. Assume contrary (R + 1)k voters candidate c
solution set represent voters misrepresentation value zero.
Due M-criterion since (R + 1)k voters, c must represent
least ((R + 1)k)/k = R + 1 voters misrepresentation value least one, respectively.
Since bound total misrepresentation R, c cannot part solution.
Based two previous lemmas, show following.
Theorem 6. Borda misrepresentation function, M-Multiwinner problem
fixed-parameter tractable respect composite parameter (R, k) k denotes
number winners R misrepresentation bound.
Proof. algorithm described distinguishing two cases: n (R + 1)k
n > (R + 1)k. former, fixed-parameter tractability follows Proposition 1 (showing fixed-parameter tractability w.r.t. number voters). latter,
yes-instance, Lemma 1 R + k zero-candidates Lemma 2
solution consist zero-candidates. removing zero-candidates,
fixed-parameter tractability follows Proposition 2 (showing fixed-parameter tractability w.r.t. number candidates).
Regarding running time, first case leads running time ((R + 1)k)(R+1)k
poly(n, m) second case accomplished 2R+k poly(n, m) time. Hence,
theorem follows.
496

fiOn Computation Fully Proportional Representation

Finally, show fixed-parameter tractability respect (R, k) Minimax MMW Borda misrepresentation function. corresponding algorithm based
case distinction algorithm M-MW (Theorem 7). basic idea
bounding number zero-candidates cannot transferred M-MW Minimax
M-MW, following algorithm Minimax M-MW works also M-MW leads
worse running time bound case number voters exceeds (R + 1)k.
specifically, case n > (R + 1)k, exponential running time part 4(R+1)k instead
2R+k .
Theorem 7. Borda misrepresentation function, Minimax M-Multiwinner
fixed-parameter tractable respect (R, k).
Proof. Consider Minimax M-MW instance (C, V, r, R, k) r Borda misrepresentation function. case R = 0 trivial Minimax M-MW Borda
misrepresentation function, assume R 1 following.
case n (R + 1)k, fixed-parameter tractability follows Proposition 1
(analogously proof Theorem 6). Hence, consider case n > (R + 1)k.
Let C := {c1 , . . . , cm } Ei := {v V | r(v, ci ) R} every ci C. Moreover,
let C := {ci C : |Ei | n/k}. show that, first, every solution consist
candidates C and, second, |C | 2(R + 1)k. Then, removing
candidates C , fixed-parameter tractability follows Proposition 2.
First, due M-criterion least n/k voters assigned every winning candidate solution hence candidate ci |Ei | < n/k cannot part winner
set.
Second, assume toward contradiction |C | > 2(R + 1)k. Note Borda
misrepresentation functions every voter occurs R + 1 sets E1 , . . . , Em .
Moreover, since |Ei | n/k every ci C
n > 2(R + 1)k n/k 1/(R + 1) > 2k(n/k 1) = 2n 2k.
Since considered case n > (R + 1)k 2k, contradiction.
Finally, based Proposition 2, case n > (R + 1)k, one obtains running
time bound 4(R+1)k poly(n, m).

5. Single-Peaked Elections
discussed introduction (Subsection 1.4), single-peakedness central notion
political science reflecting elections single issue dominates preferences voters.
Let us formally define property.
Definition 5. Let V profile set candidates C, let linear order
C (the societal axis). say order v V compatible c, d, e C
either c e e c holds
posv (c) < posv (d) = posv (d) < posv (e).

(1)

(We remind reader positions counted top that, higher
linear order b, position lower.) say V single-peaked
497

fiBetzler, Slinko, & Uhlmann

3

+

2
1



0


c1





3



+



2



+

c2

c3



1

+

0

c4

+
+
+



+





c1

c2

c3



c4

Figure 1: election consists three voters following preferences: c1 > c2 >
c3 > c4 , c2 > c3 > c4 > c1 , c3 > c2 > c1 > c4 . single-peakedness
witnessed societal order c1 c2 c3 c4 . diagram left-hand
side shows, every voter, Borda score alternative gets
voter marked solid line, dashed line dotted line, respectively. Note
every preference order one local maximum. voters express
Borda misrepresentations values instead, one obtains diagram
right. Here, misrepresentation function arbitrary fixed voter one
local minimum.

respect = 1, . . . , n order vi compatible . profile V called
single-peaked exists linear order C V single-peaked respect
; say witnesses single-peakedness V refer societal
order.
Proposition 3. Let V single-peaked profile set candidates C witnessed
societal order . Let r misrepresentation function V . every triple
{ci , cj , ck } C ci cj ck ck cj ci every v V
r(v, ci ) < r(v, cj ) = r(v, cj ) r(v, ck ).
Proof. definition misrepresentation function (see Definition 1) r(v, ci ) < r(v, cj )
implies posv (ci ) < posv (cj ). result follows (1) Definition 1.
section, investigate computational complexity determining proportional
representations using Chamberlin Courant Monroe methods together
variants, input profile single-peaked. discussed introduction,
input profile single-peaked voters viewed located certain axis
location bliss point. preferred candidate either one
closest right one closest left. Without loss generality may assume
voter bliss point location one candidates (who
preferred her).
498

fiOn Computation Fully Proportional Representation

clear misrepresentation function r(v, c) single-peaked profile must
satisfy following. fix voter v change c one end societal axis
value r(v, c) decrease monotonically vs preferred candidate
bliss point increase monotonically candidates beyond bliss
point. is, voter function expressing voters misrepresentation
candidates single-troughed (that is, exactly one local minimum) respect
order witnesses single-peakedness profile.
describing results, briefly outline typical shapes prominent
misrepresentation functions single-peaked settings. Borda misrepresentation function strictly ascending moving away local minimum directions.
Moreover, candidate preceding candidate local minimum misrepresentation function drops > 0 points, then, next 1 candidates
side local minimum, misrepresentation function must ascend size-one steps.
contrast, approval misrepresentation function, exactly one interval
consecutive candidates societal axis misrepresentation zero
remaining candidates outside interval misrepresentation one. minimax
variants one obtains similar structure, sense one interval
particular voter represented without exceeding given misrepresentation
bound. Note remote similarity last two cases
preferences intervals aggregating range values model introduced Farfel
Conitzer (2011).
remainder section, provide following results summarized Table 2. show CC-Multiwinner, Minimax CC-Multiwinner, Minimax MMultiwinner single-peaked elections solved polynomial time arbitrary
misrepresentation function (Theorem 8, Proposition 4, Proposition 5, respectively).
contrast three aforementioned problems, present reduction NP-hard version Exact 3-Cover problem shows M-Multiwinner NP-hard even
restricted single-peaked profiles (Theorem 11). However, approval misrepresentation function, still obtain polynomial-time solvability M-Multiwinner
single-peaked input profiles (Theorem 10). leave open computational complexity
M-Multiwinner Borda misrepresentation function single-peaked case.
5.1 (Minimax) CC-Multiwinner
show single-peaked input profiles CC-Multiwinner Minimax CC-Multiwinner polynomial-time solvable arbitrary misrepresentation function. first
provide dynamic programming algorithm case CC-Multiwinner. Second,
argue Minimax CC-Multiwinner solved optimally greedy algorithm.
5.1.1 Dynamic Programming Procedure CC-Multiwinner
CC-Multiwinner polynomial-time solvability established presenting dynamic programming algorithm leading following.
Theorem 8. single-peaked input profile arbitrary misrepresentation function
CC-Multiwinner solved O(nm2 ) time.
499

fiBetzler, Slinko, & Uhlmann

1

Function SinglePeaked-CC-MW(V , C, r, k) Input: multiset
voters V := {v1 , . . . , vn }, set candidates C := {c1 , . . . , cm },
misrepresentation function r, positive integer k. voters
single-peaked preferences according societal order ,
c1 c2 . . . cm .
Output: minimum total misrepresentation k winners.

begin
= 1, . . . ,P

4
z(i, 1) := vV r(v, ci );
5
end
6
p = 1, . . . ,
7
= p + 1,P
. . . ,
8
d(p, i) := vV max{0, r(v, cp ) r(v, ci )};
9
end
10
end
11
= 2, . . . ,
12
j = 2, . . . , min(k, i)
13
z(i, j) := minp{j1,...,i1} (z(p, j 1) d(p, i));
14
end
15
end
16
return mini{k,...,m} (z(i, k));
17 end
Algorithm 2: Dynamic programming algorithm CC-Multiwinner single-peaked
input profiles.
2

3

Proof. Throughout proof assume voters single-peaked preferences
according societal order , c1 c2 . . . cm . set C C,
minimum total misrepresentation defined
s(C ) =

X

vV

min {r(v, c )}.

c C

define dynamic programming table z, containing entry z(i, j) 1
1 j min(i, k). Informally speaking, entry z(i, j) gives minimum total
misrepresentation set j winners {c1 , . . . , ci } including ci .
dynamic programming procedure SinglePeaked-CC-MW provided Algorithm 2.
show solves CC-Multiwinner claimed running time. Regarding
correctness, show execution SinglePeaked-CC-MW following
equation satisfied

z(i, j) = min s(C ) | C {c1 , . . . , ci } |C | = j ci C .

(2)

Then, minimum total misrepresentation optimal size-k winner set clearly given
mini{k,...,m} z(i, k) (see Line 16).
500

fiOn Computation Fully Proportional Representation

proof Equation 2 follows induction j. First, argue entries z(i, 1)
satisfy Equation (2), yielding base induction. end, observe
one candidate ci winner
P set, voters must assigned ci , yielding
misrepresentation sum s({ci }) = vV r(v, ci ), see Line 4.
Next, show entry z(i, j) j > 1 (as computed Line 13) complies
Equation (2) provided z(p, j 1) 1 p < i. Consider set C {c1 , . . . , ci }
ci C |C | = j s(C ) minimum among sets. argue
z(i, j) = s(C ). Let p < cp C c 6 C p < < i.
implies p j 1. crucial observation follows. voter v
holds r(v, ci ) < r(v, cp ), single-peakedness implies r(v, cq ) r(v, cp ) >
r(v, ci ) q < p. Hence, consider set C j 1 candidates {c1 , . . . , cp }
cp C , assume value r(v, cp ) contribution voter v
total misrepresentation s(C ). Hence, adding ci C improvement
r(v, cp ) r(v, ci ) voter v r(v, cp ) > r(v, ci ). every remaining voter v,
holds r(v, ci ) r(v, cp ) hence onePcannot improve representation assigning
ci . follows s(C ) = s(C ) vV max{0, r(v, cp ) r(v, ci )} = s(C ) d(p, i)
induction assumption z(p, j 1) = s(C ). Finally, since algorithm
tries possible choices p (see Line 13) z(i, j) = s(C ).
straightforward verify running time Algorithm 2 O(nm2 ).
5.1.2 Greedy Algorithm Minimax CC-Multiwinner
single-peaked input profiles, minimax version CC-Multiwinner solved
simple greedy algorithm. basic idea iterate candidates according
societal order put solution first candidate voter
cannot represented previously selected candidates. correctness based
observation candidate representation range (or interval)
consecutive candidates voter must represented. Thus, choose
latest possible candidate represent voter representation range
ends first since candidate least good every previous candidate.
words, basic combinatorial problem cover stab given set intervals
(corresponding representation ranges voters) k points (corresponding
candidates). stabbing problem turn corresponds clique cover problem
interval graphs solved linear time (Golumbic, 1980). next section,
investigate relationships considered voting problems special (rectangle)
stabbing problems detail. Here, conclude following.
Proposition 4. single-peaked input profile arbitrary misrepresentation function Minimax-CC-Multiwinner solved O(nm) time.
5.2 (Minimax) M-Multiwinner
focus case assignment candidates winner set satisfies
M-criterion, is, required winner represents number
candidates. additional constraint makes winner determination involved. Indeed, show integer-valued misrepresentation function M-Multiwinner
501

fiBetzler, Slinko, & Uhlmann

NP-hard even input profile single-peaked. positive side, show MMultiwinner single-peaked input profiles approval misrepresentation function
Minimax M-Multiwinner arbitrary misrepresentation functions polynomialtime solvable. However, solving strategies (that also based dynamic programming) intricate (Minimax) CC-Multiwinner. proving polynomialtime solvability establish close relationship so-called 1-dimensional Rectangle Stabbing (Even et al., 2008). start polynomial-time algorithms followed
NP-hardness proof. computational complexity M-Multiwinner
Borda misrepresentation function single-peaked input profiles left open.
5.2.1 M-Multiwinner Approval Minimax M-Multiwinner
use notation Even et al. (2008) whenever possible. input consists set U
horizontal intervals set vertical lines capacity c(S) {0, . . . , |U |} every
line S. Informally, task cover (or stab) intervals minimum number
vertical lines S, line covers c(S) intervals (a vertical line covers
horizontal interval iff intersect). Since line cover c(S) intervals,
one specify interval assigned line solution. Let U (S) denote
set intervals U intersecting S. assignment function : 2U ,
A(S) U (S).
set cover assignment |A(S)| c(S)

SS A(S) = U .
One-Dimensional Rectangle Stabbing Hard Constraints (Hard1-RS):
Input: set U horizontal intervals set vertical lines capacities c(S) {0, . . . , |U |} every line S.
Task: Find minimum-cardinality cover (and corresponding assignment).

Now, consider single-peaked instance M-Multiwinner R = 0 every
winner represents exactly number voters, is, n mod k = 0 n voters
k winners. case, problem reduced Hard-1-RS follows.
every candidate vertical line according position societal axis. Since
voter v must represented candidate c r(v, c) = 0 candidates
r(v, c) = 0 ordered consecutively societal axis, represent voter
horizontal interval reaching leftmost candidate c r(v, c) = 0
rightmost candidate. Finally, vertical line associated capacity n/k,
whole number. Clearly, solution M-Multiwinner instance
R = 0 size-k cover constructed instance Hard-1-RS.
Note case, n mod k 6= 0, transformation cannot applied since
one know whether candidate line capacity n/k n/k optimal
solution.
Even et al. (2008) presented dynamic programming algorithm Hard-1-RS
running time O(|U |2 |S|2 (|U | + |S|)). Since transformation described
easily accomplished linear time, one directly obtains following.

502

fiOn Computation Fully Proportional Representation

Corollary 1. instance M-Multiwinner single-peaked profile n mod
k = 0, R = 0 (and arbitrary misrepresentation function) solved O(n2 m2 (n+
m)) time.
show single-peaked input profiles, M-Multiwinner approval misrepresentation function (and arbitrary misrepresentation bound R) solved polynomial time. end, show instances reduced version
one-dimensional rectangle stabbing goal stab maximum number horizontal intervals k vertical lines. specifically, introduce following problem
best knowledge studied before.
Maximum Balanced One-Dimensional Rectangle Stabbing (Max-Bal1-RS):
Input: multi-set U = {u1 , . . . , un } horizontal intervals, set = {S1 , . . . , Sm }
vertical lines, positive integer k.
Task: Find size-k set assignment
following statements hold.

| SS A(S)| maximum,
every , |A(S)| n/k,
|{S : |A(S)| = n/k}| n mod k, n mod k remainder
division n k.
last two restrictions problem description considered saying
kc = n mod k lines capacity n/k kf = k kc lines capacity n/k,
specifying line capacity, Hard-1-RS specific capacity
every line. difference Max-Bal-1-RS Hard-1-RS
latter intervals must covered minimum number lines whereas former
goal cover maximum number intervals k lines.
show dynamic programming algorithm Even et al. (2008) Hard-1-RS
adapted work Max-Bal-1-RS. end, employ decomposition
property (stated Observation 3 below) dynamic programming table
algorithm different.
introduce following notation state dynamic programming. interval u U , let l(u) denote left endpoint u r(u) denote right endpoint u
(that is, l(u) r(u)). Let x(S) denote coordinate line S(x) denote
vertical line associated coordinate x. two integers let [s, t] denote set
integers t.
ease presentation, assume input following normalized form
easily established. First, assume endpoints intervals
coordinates lines integers. Second, assume {x(S) | S} = [1, m]. Third,
assume endpoints intervals [1, m]. follows,
distinguish line coordinate x(S), is, identify lines
elements [1, m] (and vice versa). Finally, assume intervals u1 , u2 , . . . , un
ordered l(u1 ) l(u2 ) . . . l(un ) (we fix one ordering).
algorithm makes use fact always optimal solution satisfies
leftmost interval first property defined follows (Even et al., 2008).
503

fiBetzler, Slinko, & Uhlmann

Definition 6. Let denote size-k set lines let denote assignment.
say (S , A) leftmost interval first property following holds. Let
let ui A(S). every l(ui ) < every uj uj A(S ),
either j < r(uj ) < S.
Note leftmost interval first property defined respect fixed ordering
intervals. solution transformed equivalent one satisfying
leftmost interval first property simply swapping assignments conflicting interval
pairs, (see, e.g., Even et al., 2008). Hence, always optimal solution satisfying
leftmost interval first property one apply dynamic programming procedure based
following decomposition, analogously work Even et al. (2008, Section 2).
Observation 3. Let (S , A) optimal solution Max-Bal-1-RS satisfies
leftmost interval first property. range [x1 , x2 ] [1, m], let ui U earliest
interval among intervals covered line [x1 , x2 ] (that is, uj covered
lines range j > i). ui covered line [x1 , x2 ] \ {x1 }, right
endpoint intervals covered lines range [x1 , 1] left S.
Basically, Observation 3 used algorithm following way. Consider
range [x1 , m] assume x1 leftmost line considered solution. Moreover,
assume ui earliest interval covered line [x1 , m]. Then, every
interval uj j < covered solution, every interval u >
r(u ) < covered lines [x1 , 1], every interval ur
r(ur ) covered lines [S, m]. implies decomposition
instance two subinstances. left instance contains intervals ug g >
r(ug ) < right instance contains intervals ud r(ud ) m.
Theorem 9. Maximum Balanced One-Dimensional Rectangle Stabbing
solved O(m3 n3 k3 ) time.
Proof. use following definitions state dynamic programming algorithm. Let
kc := n mod k kf := k kc . ui U two coordinates x1 x2
r(ui ) [x1 , x2 ], let
U (ui , x1 , x2 ) := {uj U | j r(uj ) [x1 , x2 ]}.
Note ui U (ui , x1 , x2 ) U = U (u1 , 1, m).
algorithm maintains dynamic programming table entry
(ui , x1 , x2 , kc , kf , b) N
defined every ui U , two coordinates x1 x2 r(ui ) [x1 , x2 ]
x1 ui , 0 kc kc 0 kf kf kf + kc k 1
|[x1 , x2 ]| kc + kf + 1, 1 b n/k. Informally, table entry contains
maximum number intervals U (ui , x1 , x2 ) covered kc + kf + 1 lines
[x1 , x2 ] assumption x1 contained solution covers b
intervals, ui covered line [x1 , x2 ], kc solution lines different
x1 assigned n/k intervals. (Formally, kc + kf + 1 solution lines must satisfy
conditions (C1) (C6).)
504

fiOn Computation Fully Proportional Representation

Next, define subsets intervals needed decomposition left right
subinstances. ui U , two coordinates 1 x1 x2 r(ui ) [x1 , x2 ],
x [x1 , x2 ] let

,
x = x1
Ul (ui , x, x1 , x2 ) :=
{uj U | j > r(uj ) [x1 , x 1]}, otherwise

Ur (ui , x, x1 , x2 ) := U (ui , x1 , x2 ) \ (Ul (ui , x, x1 , x2 ) {ui }).
Algorithm. state algorithm explained discussing correctness
below. Basically, algorithm works three phases. first phase, dynamic
programming table initialized follows. ui U , every two coordinates x1
x2 r(ui ) [x1 , x2 ], x1 ui , every integer b [1, n/k], let
(ui , x1 , x2 , 0, 0, b) := min(b, |{u U (ui , x1 , x2 ) : x1 u}|).

(3)

second phase, table updated. update table entry (ui , x1 , x2 , kc , kf , b)
provided Algorithm 3, order update invoked determined
Algorithm 4. third phase, algorithm outputs maximum value ui U
x1 [1, . . . , m] x1 ui |[x1 , m]| k
(
(ui , x1 , m, kc 1, kf , n/k)
(4)
max
(ui , x1 , m, kc , kf 1, n/k).
Correctness. show every stage dynamic programming entry contains
value best assignment partial solution subinstance interval set
U (ui , x1 , x2 ) six conditions (C1) (C6) hold. specifically, argue
every ui U , two coordinates x1 x2 r(ui ) [x1 , x2 ] x1 ui ,
0 kc kc 0 kf kf kf + kc k 1 |[x1 , x2 ]| kc + kf + 1,
1 b n/k
[
(ui , x1 , x2 , kc , kf , b) = max |
A(S )|


sets [x1 , x2 ] assignments : 2U (ui ,x1,x2 )
ui A(S),

(C1)

|S | = kc + kf + 1 ,

(C2)

x1 ,

(C3)

|A(x1 )| b,

(C4)

|A(S )| n/k,

(C5)

|{S \ {x1 } : |A(S )| = n/k}| kc .

(C6)

505

fiBetzler, Slinko, & Uhlmann

1
2
3
4
5
6
7
8
9
10
11
12
13

Function Update(ui , x1 , x2 , kc , kf , b) begin
:= 0;
b > 1
every uj U (ui , x1 , x2 ) \ {ui } x1 uj
:= max{M, (uj , x1 , x2 , kc , kf , b 1)};
end
else
every x = x1 + 1 x2 |[x , x2 ]| kc + kf
every uj U (ui , x1 , x2 ) \ {ui } x uj
kc > 0
:= max{M, (uj , x , x2 , kc 1, kf , n/k)};
kf > 0
:= max{M, (uj , x , x2 , kc , kf 1, n/k)};

14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29

end
end
every x = x1 + 1 r(ui ) x ui
kcl 0 kcr 0 kcl + kcr = kc
kfl 0 kfr 0 kfl + kfr = kf
|[x1 , x 1]| kcl + kfl + 1 |[x, x2 ]| kcr + kfr
Ml , Mr := 0;
every uj Ul (ui , x, x1 , x2 ) x1 uj
Ml := max{Ml , (uj , x1 , x 1, kcl , kfl , b)};
end
every uj Ur (ui , x, x1 , x2 ) x uj
kcr > 0
Mr := max{Mr , (uj , x, x2 , kcr 1, kfr , n/k 1)};
kfr > 0
Mr := max{Mr , (uj , x, x2 , kcr , kfr 1, n/k 1)};

30

end
32
:= max{M, Ml + Mr };
33
end
34
end
35
end
36
end
37
(ui , x1 , x2 , kc , kf , b) := + 1;
38 end
Algorithm 3: Update step employed dynamic programming algorithm MaxBal-1-RS presented proof Theorem 9.
31

506

fiOn Computation Fully Proportional Representation

1
2
3
4
5
6
7
8
9
10
11
12
13
14

Main :
[x1 , x2 ] [1, m] increasing order x2 x1
kc = 0, . . . , kc
kf = 0, . . . , kf
|[x1 , x2 ]| kc + kf + 1 1 kc + kf k 1
b = 1, . . . , n/k
ui U r(ui ) [x1 , x2 ] x1 ui
(ui , x1 , x2 , kc , kf , b) := Update(ui , x1 , x2 , kc , kf , b);
end
end
end
end
end
end
Algorithm 4: Main loop initialization.

every entry computed initialization step (Equation 3), algorithm stores
maximum value partial solution = {x1 } (satisfies (C2) (C3)), covers ui
(C1) (which possible since x1 ui b 1), satisfies |A(x1 )| b (C4). Clearly,
(C5) (C6) hold well.
Regarding update step (see Algorithm 3), let us assume values entries
accessed update correct well-defined (discussed below). ensure (C1) entry (ui , x1 , x2 , kc , kf , b), interval ui must covered one lines
[x1 , x2 ]. argue possibilities hold conditions C1 - C6 considered systematically current maximum value stored variable .
going details, observe Algorithm 3 adds one overall maximum
value (Line 37) take account ui newly covered. correct
least one possibility cover ui considered interval, namely, x1
always cover u1 since x1 ui (Line 7 Algorithm 4) b 1 (Line 6 Algorithm 4).
Lines 3 16 Algorithm 3 consider possibility x1 used cover ui . Here,
two possibilities distinguished. first investigated possibility (Line 3 Line 7
Algorithm 3) ui covered x1 x1 cover least one interval,
is, b > 1. case, compute optimal value based value
subinstance containing ui x1 solution assigned
one interval less. end, b decreased one (that is, (C4) holds) possible
intervals U (ui , x1 , x2 ) \ {ui } (Line 4) checked leftmost covered interval
corresponding subsolution. Moreover, since kf kc remain assume
conditions (C2), (C5), (C6) hold (uj , x1 , x2 , kc , kf , b 1), also hold
(ui , x1 , x2 , kc , kf , b).
second investigated possibility (Lines 7 16 Algorithm 3) ui covered
x1 x1 cover one interval, is, b = 1. case traced back
subinstance without ui x1 . access corresponding possibilities
dynamic programming table, Algorithm 3 tries possible lines new solution lines
(Line 8) leftmost intervals covered new subinstance (Line 9). Then,
507

fiBetzler, Slinko, & Uhlmann

chooses maximum assigning capacity n/k (Line 11) n/k (Line 13)
x . Note since 1 kc + kf (Line 5 Algorithm 4) least one two cases must
possible (if least one interval covered, is, U (ui , x1 , x2 ) \
{ui } =
6 ). Assume solution corresponding table entry (uj , x , x2 , kc
1, kf , n/k)} (Line 11) (uj , x , x2 , kc , kf 1, n/k)} (Line 13), respectively, hence,
fulfilling conditions (C1) (C6) corresponding subinstance. Then, clearly
adding x1 solution assigning ui x1 gives solution fulfilling constraints
(ui , x1 , x2 , kc , kf , b) b = 1.
following loop Algorithm 3 (Lines 17 37) tries possibilities cover ui
line x 6= x1 . x 6= x1 , according Observation 3, instance divided
two subinstances. combinations sizes subsolutions tested iterating
kcl , kcr , kfl , kfr (Lines 18 19). Lines 22 23 Algorithm 3 computes
optimal solution left subinstance Lines 25 29 computes solution
right subinstance obtained assigning ui x. decomposition
subinstances defined interval sets Ur (ui , x, x1 , x2 ) Ul (ui , x, x1 , x2 ) follows directly
Observation 3. Moreover, since x1 part left subinstance unchanged
capacity bound b, conditions (C1), (C3) (C4) hold. remains show (C2),
(C5) (C6) hold, is, addition x1 considered subsolution consists kc lines
assigned n/k intervals kf lines assigned n/k
intervals. considered possibility, x newly specified solution line
according decomposition (see Observation 3 definitions Ul , Ur ) part
right subinstance. Lines 27 29, Algorithm 3 chooses maximum
possibilities x assigned n/k n/k intervals, respectively,
adapts values kcr kfr accordingly accessing corresponding table entries.
Hence, conditions hold.
Now, consider output overall algorithm, see Equation (4). first maximum
function iterates intervals ui possible leftmost solution lines hence find
pair ui x1 follows. interval ui leftmost interval covered solution
leftmost interval first property x1 leftmost line considered solution.
Then, second maximum function chooses maximum two cases x1
assigned n/k n/k intervals, respectively. Since

(C1) (C6) hold

corresponding entries, algorithm outputs maximum | SS A(S)| overall [1, m]
corresponding assignments fulfilling constraints definition MaxBal-1RS.
remains show algorithm accesses well-defined entries, is,
accessed entries computed before. ensured iterating dynamic programming table described Algorithm 4. Regarding computation
(uj , x1 , x2 , kc , kf , b 1) Line 5 Algorithm 3, parameters values except b
current entry. Line 6 Algorithm 4 iterates b increasing order
and, hence, (uj , x1 , x2 , kc , kf , b 1) computed accessed. Moreover,
condition b > 1 Line 3 Algorithm 3 ensures (uj , x1 , x2 , kc , kf , b 1) well
defined. Lines 11 13 Algorithm 3, accessed range [x , x2 ] smaller
range x1 x2 . Since algorithm iterates ranges according increasing size
(Line 2 Algorithm 4) parameter values also considered former
iteration loops, entry computed before. Line 23 Algorithm 3 accessed
508

fiOn Computation Fully Proportional Representation

entry range x1 x 1 < x2 Lines 27, 29 considered range [x, x2 ]
also strictly smaller range [x1 , x2 ]. Again, according Line 2 Algorithm 4),
entries computed before.
Running time. Regarding running time, update accomplished O(mk2 n)
time (see Algorithm 3) iterating coordinates lines (Line 17),
less k2 cases Lines 18 19, less n intervals inner loops
Lines 5, 22, 25, respectively. overall loop (Algorithm 4) gives additional factor
O(m2 n2 k): appropriate implementation accomplished iterating
less m2 coordinate ranges (Line 2), less k2 possibilities Lines 4 3, n/k
(n + 1)/k values b (Line 6), n intervals Line 7. yields running
time bound O(m2 k(n + 1)n) = O(m2 n2 k). Hence, overall running time bounded
O(n3 k3 m3 ).
instance single-peaked input profile M-Multiwinner approval
misrepresentation function reduces Max-Bal-1-RS transformation described Section 5.2.1. vertical line every candidate, horizontal interval
voter v reaching leftmost candidate r(v, c) = 0 rightmost
candidate. crucial observation is, minimizing total misrepresentation
M-Multiwinner equivalent maximizing number voters represented
candidates misrepresentation zero and, hence, maximizing number covered
intervals Max-Bal-1-RS instance. Altogether, arrive main result
section.
Theorem 10. M-Multiwinner approval misrepresentation function singlepeaked input profiles decided O(n3 m3 k3 ) time.
Recall instance Minimax M-Multiwinner R > 0 reduced
instance M-Multiwinner R = 0 approval misrepresentation function
setting voter v candidate c misrepresentation value 0, r(v, c) R,
1 otherwise (see Observations 1 2). Altogether, arrive following.
Proposition 5. instance Minimax M-Multiwinner single-peaked profile
(and arbitrary misrepresentation function) solved O(n3 m3 k3 ) time.
5.2.2 NP-Hardness M-Multiwinner Single-Peaked Election
Contrasting polynomial-time solvability results three considered problems, show integer-valued misrepresentation function MMultiwinner NP-complete even restricted instances single-peaked input profile. specifically, show M-Multiwinner NP-hard single-peaked input
profiles integer-valued misrepresentation functions maximum misrepresentation value voter bounded polynomial number candidates.
Note establishing NP-hardness allow voter assign
misrepresentation value several candidates.
NP-hardness follows reduction restricted variant Exact 3-Cover.
Restricted Exact 3-Cover (rX3C)
Input: family := {S1 , . . . , Sm } sets elements E := {e1 , . . . , en }
509

fiBetzler, Slinko, & Uhlmann

every set size 3 every element E occurs exactly three
sets.

Question: subset
every element E occurs

exactly one set SS = E?

set called exact 3-cover E. Since yes-instances n multiple
3, follows assume n divisible 3. NP-hardness rX3C follows
NP-hardness reduction case every element occurs three
subsets (Garey & Johnson, 1979) construction extend NP-hardness result
case every element occurs exactly three subsets (Gonzalez, 1985).
Theorem 11. M-Multiwinner NP-hard single-peaked input profiles integervalued misrepresentation function even maximum misrepresentation value every
voter polynomial number candidates (and every winner represents exactly three
voters).
Proof. use following notation. Consider rX3C instance (S, E). element
e E occurs three subsets Si , Sj , Sk < j < k, say first
occurrence e Si , second occurrence Sj , third occurrence Sk .
rX3C instance (S, E), define M-MW instance follows. set candidates

C := E {sj | Sj S}
multiset voters
V := {vix | ei E x {1, 2, 3}} {fi | ei E}.
is, candidate element subset four voters
element. Next, specify misrepresentation functions voters:






{1, . . . , n}
{1, . . . , n}, c C \ {ei }
{1, . . . , n}, x {1, 2, 3}, 1 z
{1, . . . , n}, x {1, 2, 3}, z >
1 j m, x {1, 2, 3}, xth occurrence ei Sj
else

r(fi , ei ) := 0
r(fi , c) := 2n2 + 1
r(vix , ez ) := + z 1
r(vix , ez ) := 2n2 + 1
r(vix , sj ) := 0
r(vix , sj ) := 1

Finally, set misrepresentation bound R := 2n2 let number winners
k := n/3 + n. showing correctness reduction, discuss three crucial
properties construction.
First, verify profile single-peaked witnessed societal order
s1 sm e1 en .
every voter fi single-peakedness obvious since misrepresentation 0 one
candidate 2n2 + 1 every candidate. every vix , within candidate set E,
misrepresentation function decreases monotonously move en e1 along
societal axis: z > i, obvious since misrepresentation remains constant
value 2n2 +1 z misrepresentation value i+z 1 hence function
510

fiOn Computation Fully Proportional Representation

clearly assumes smaller values decreasing values z. settles single-peakedness
range e1 en . see overall single-peakedness, first note e1
misrepresentation every vix least 1. Then, since misrepresentation 1
one candidates {s1 , . . . , sm } 0 remaining candidates,
single-peakedness every vix follows.
Second, since 4n voters k = (4n)/3, exactly three voters
assigned every winning candidate solution.
Third, show four voters best represented candidate ei
fi , vi1 , vi2 , vi3 . specifically, show following.
Observation 4. every ei x {1, 2, 3}, r(vix , ei ) < r(y, ei ) every V \({fi }
{vi1 } {vi2 } {vi3 }).
see correctness, observe every fixed {1, . . . , n}, r(vax , ea ) = 2a 1
every x {1, 2, 3}


1 b < a, r(vbx , ea ) = 2n2 + 1 > 2a 1 ,


< b n, r(vbx , ea ) = + b 1 > 2a 1,
b 6= a, r(fb , ea ) = 2n2 1 > 2a 1.
Now, show following.
Claim: exact 3-cover (S, E) set
k = 4n/3 candidates represent voters total misrepresentation
R = 2n2 exactly three voters assigned one candidate.
Given exact 3-cover S, show set {sj | Sj } E candidates
winning set required claim. corresponding mapping follows.
every 1 n, voter fi assigned candidate ei .
1 n x {1, 2, 3}, ei occurs xth time Sj , vix
assigned sj , else vix assigned ei .
Since exact 3-cover every element covered exactly once, follows every voter
assigned exactly one candidate every winning candidate represents three voters.
specifically, three voters vi1 , vi2 , vi3 corresponding three occurrences
element ei , one represented candidate corresponding solution
set ei occurs two voters candidate ei (the third candidate
represented ei fi ). remains compute total misrepresentation solution.
Due definition, every candidate sj represents three voters misrepresentation
0. Moreover, every candidate ei represents fi misrepresentation 0 two voters
{vi1 , vi2 , vi3 } misrepresentation r(vix , ei ) = + 1 = 2i 1 x {1, 2, 3}. Hence,
total misrepresentation
n
X

2(2i 1) = 2n(n + 1) 2n = 2n2 .

i=1

511

(5)

fiBetzler, Slinko, & Uhlmann

Consider size-k set C C winners represent voters total misrepresentation R = 2n2 . Since every voter fi , candidate represent fi
misrepresentation R ei , follows E C . Recall due M-criterion,
every candidate must represent exactly three voters. Thus, every candidate ei E must
represent two voters (besides fi ). Clearly, lower bound total misrepresentation achieved case assign every ei E two voters
represented ei least good voters. Due Observation 4, two voters
{vi1 , vi2 , vi3 }. Moreover, according Equation 5 corresponding lower bound
total misrepresentation matches total misrepresentation R = 2n2 . Since assigning
ei voter {vi1 , vi2 , vi3 } would lead strictly higher misrepresentation (Observation 4), implies ei assigned exactly two voters {vi1 , vi2 , vi3 }. Finally,
every 1 n, remains one voter vix must represented candidate
C \ E misrepresentation zero. Since |C \ E| = n/3 candidate sj
represent voter vix misrepresentation 0 element ei occurs Sj , i.e., sets
corresponding candidates C \ E must form exact 3-cover.

6. Conclusion Outlook
start summarizing relevance results work. followed
discussion closely related problems models might investigated future
research. conclude several questions directly follow results.
6.1 Relevance Results
computation set candidates fully proportionally represent society
applications many relevant settings. main problem suggested approaches
extant literature corresponding combinatorial problems NP-hard,
is, cannot solved efficiently general. raises question whether
approaches despite theoretically proven advantages (see, e.g., detailed discussion
Brams, 2008) useless practice.
One approach course try escape high complexity modifying concept
keeping still meaningful. regard tried change way total
misrepresentation calculated taking minimax (or Rawlsian) approach. appeared
help general caseall problems remain computationally hardhowever,
partially helped single-peaked elections: classical Monroe scheme remains
NP-hard, minimax version solved polynomial time.
general, several ways deal NP-hard problems. example, NPhardness based worst-case analysis hence one might able develop algorithms work efficiently instances. However, although unlikely, still might
happen outcome election leads hard instance. Then, would lead
situation political impasse unpredictable consequences.
Another common approach tackle NP-hard problems invoke approximation algorithms. scenarios like context resource allocation sharable
items nearly optimal solution might sufficient approximation algorithms meaningful (Lu & Boutilier, 2011; Skowron, Faliszewski, & Slinko, 2012); scenarios, like
political elections, use approximation algorithms hard imagine. voting rule
512

fiOn Computation Fully Proportional Representation

constitutional matter: whatever is, must adhered to. current legislation
candidate party ask recount and, approximation voting rule
used, may require using another approximation argue give better
representation. hard imagine prolonged court proceedings matters.
Based previous discussion, seems clearly desirable identify well-specified
settings optimal solution computed efficiently. extend
applicability fully proportional representation settings. regard,
conducted investigation two different directions. first class settings
parameters small (parameterized complexity analysis). second approach
restrict attention single-peaked domains.
Regarding parameterized complexity four studied problems, results negative (see Table 1). particular, natural well-motivated parameter
number winners, corresponding problems turned W[2]-complete. If,
however, addition winner set represent voters small total
misrepresentation, three four problems become tractable Borda misrepresentation function. Moreover, fixed-parameter tractability results respect
number voters number candidates, respectively, useful restricted
settings.
Regarding single-peaked elections, almost results positive come
polynomial-time algorithms (see Table 2). possible critique approach claim
single-peakedness way idealized model robust enough. smallest
honest mistake voter filling ballot may result election becoming singlepeaked. Also may secondary issue election also important
voters may lead election almost single-peaked exactly singlepeaked. regard would interesting investigate difficult find singlepeaked profile closest given one. one might employ techniques socalled distance rationalizability approach (Baigent, 1987; Meskanen & Nurmi, 2008; Elkind,
Faliszewski, & Slinko, 2010a; Elkind et al., 2010b). thus surprising near singlepeakedness starting active area research (Faliszewski, Hemaspaandra,
& Hemaspaandra, 2011; Erdelyi, Lackner, & Pfandler, 2012). Since algorithms show
polynomial-time solvability important basic case single-peakedness, might
basis developing efficient algorithms extended settings.
Summarizing, work contributes important topic making fully proportional
representation ideas practical complements analysis method Potthof
Brams (1998), Procaccia et al. (2008) Lu Boutilier (2011).
6.2 Related Problems Scenarios
concluding work several open questions, we, first, describe relations
considered problems facility location problems and, second, describe reasonable
alternative multi-winner model. topics might also lead interesting questions
future research.
513

fiBetzler, Slinko, & Uhlmann

6.2.1 Relations Facility Location.
basic scenario problem company needs choose set facility locations
serve set customers little cost possible. Fellows Fernau (2011)
investigated parameterized complexity variant problem closely related
CC-Multiwinner. Basically, facility locations considered set
candidates, customers multiset voters goal find set facility
locations serve customers. difference cost function: addition
term resembles misrepresentation every voter (customer), every facility
location comes certain cost required install facility.
Similar study, Fellows Fernau (2011) studied parameter number k
winners/selected facilities locations total cost. parameter k, W[2]-hardness
CC-Multiwinner follows reduction given facility location problem.
Regarding parameter total cost, results two papers directly comparable. due fact facility location problem stipulates
minimum cost 1 serving customer even best facility location (which
would analogue condition r(v, c) 1 misrepresentation function r).
case, considered problem fixed-parameter tractable respect total
cost. might come surprise since total cost/misrepresentation
least number voters fixed-parameter tractability respect parameter
holds four voting problems considered (Proposition 2). contrast,
condition r(v, c) 0 considered problems least W[2]-hard respect
total misrepresentation/cost (see Table 1).
close connection facility location multi-winner problems clearly seems
deserve attention future work. remark analogues several problems
considered work might also make sense context facility location problem.
example, Monroe model might apply sets facilities every facility
serve number customers. Moreover, single-peaked scenario translates,
example, setting potential facility locations along one main street
resident ranks cost using facility according distance facility
place residence.
6.2.2 Multiset Candidates Model.
may compromise solution two systems Chamberlin Courant
Monroe. may still divide voters equal almost equal groups may assign
representative one group voters. Say, n voters k
representatives elected may split voters groups sizes n/k n/k+1
allow candidate represent one group. Mathematically would
result selecting set representatives cardinality k multiset
cardinality. classic Monroe (1995) example considers subscription newspapers
common room fact better fit multiset model. Indeed, demand, say
Financial Times, strong several copies newspaper subscribed to.
still need use weighted voting assembly case weights
integers.
514

fiOn Computation Fully Proportional Representation

illustrate difference let us consider six people electing representative assembly
three. Suppose candidates must come set = {a, b, c, d} preferences
voters follows:
4

b
c


2
c
b



set variant Monroe scheme give us set representatives {a, b, c}
multiset point view natural multiset {a2 , c} answer
could interpreted mean two votes given one c. multiset point
view seems natural here, indeed, b seem represent anybody nicely.
misrepresentation nonzero set version zero multiset one.
far know computational complexity computation winner
multiset model unstudied far. first glance, seems conceivable computational complexity multiset model lies complexity CC-Multiwinner
M-Multiwinner. leads interesting questions whether set winners
according multiset model computed polynomial time electorate
single peaked.
6.3 Open Questions
Several questions arise work.
CC- M-Multiwinner Borda misrepresentation function provided algorithms showing polynomial-time solvability constant misrepresentation
bound R. problems fixed-parameter tractable respect R?
Minimax M-Multiwinner Borda misrepresentation function fixed-parameter
tractable respect composite parameter (R, k)?
M-Multiwinner single-peaked elections shown NP-hardness
integer-valued misrepresentation functions. problem fixed-parameter tractable
respect number winners k or/and respect misrepresentation
bound R?
M-Multiwinner Borda misrepresentation function polynomial-time solvable single-peaked instances?
results single-peaked elections extended generalized single-peakedness
(e.g., defined Nehring & Puppe, 2007) almost single-peaked profiles (in
sense)? might particular interest problem finding closest single-peaked profile given one would turn polynomial-time solvable
(for distance set profiles).
515

fiBetzler, Slinko, & Uhlmann

7. Acknowledgments
work done Nadja Betzler stayed research visit University
Auckland. visit funded fellowship Deutscher Akademischer Austausch
Dienst (DAAD). Johannes Uhlmann partially supported DFG, project PAWS
NI-931/10.
grateful referees whose careful thoughtful reading significantly
improved paper. Moreover, like thank Steven Brams interest work
valuable discussions Rolf Niedermeier useful comments support.

References
Ahuja, R. K., Magnanti, T. L., & Orlin, J. B. (1993). Network Flows: Theory, Algorithms,
Applications. Prentice Hall.
Baigent, N. (1987). Metric rationalisation social choice functions according principles
social choice. Mathematical Social Sciences, 13 (1), 5965.
Bartholdi III, J. J., Tovey, C. A., & Trick, M. A. (1989). computational difficulty
manipulating election. Social Choice Welfare, 6, 227241.
Betzler, N., Bredereck, R., Chen, J., & Niedermeier, R. (2012). Studies computational
aspects voting - parameterized complexity perspective. Multivariate Algorithmic Revolution Beyond, Vol. 7370 Lecture Notes Computer Science,
pp. 318363. Springer.
Betzler, N., Guo, J., & Niedermeier, R. (2010). Parameterized computational complexity
Dodgson Young elections. Information Computation, 208 (2), 165177.
Betzler, N., Hemmann, S., & Niedermeier, R. (2009). multivariate complexity analysis
determining possible winners given incomplete votes. Proceedings 21st
International Joint Conference Artificial Intelligence (IJCAI), pp. 5358.
Black, D. (1958). Theory Committees Elections. Cambridge University Press.
Booth, E., & Lueker, G. (1976). Testing consecutive ones property, interval graphs,
graph planarity using PQ-trees algorithms. Journal Computer System
Sciences, 13, 335379.
Brams, S. (2008). Mathematics Democracy. Princeton University Press.
Brams, S., & Fishburn, P. (2002). Voting procedures. Arrow, K., Sen, A. K., & Suzumura,
K. (Eds.), Handbook Social Choice Welfare, Vol. 1, pp. 173236. Elsevier.
Brandt, F., Brill, M., & Seedig, H. G. (2011). fixed-parameter tractability
composition-consistent tournament solutions. Proceedings 22nd International
Joint Conference Artificial Intelligence (IJCAI), pp. 8590. AAAI Press.
Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. A. (2010). Bypassing combinatorial protections: Polynomial-time algorithms single-peaked electorates.
Proceedings 24th AAAI Conference Artificial Intelligence (AAAI), pp. 715
722.
516

fiOn Computation Fully Proportional Representation

Chamberlin, J. R., & Courant, P. N. (1983). Representative deliberations representative
decisions: Proportional representation Borda rule. American Political Science
Review, 77 (3), 718733.
Christian, R., Fellows, M. R., Rosamond, F. A., & Slinko, A. (2007). complexity
lobbying multiple referenda. Review Economic Design, 11 (3), 217224.
Conitzer, V. (2009). Eliciting single-peaked preferences using comparison queries. Journal
Artificial Intelligence Research, 35, 161191.
Conitzer, V. (2010). Making decisions based preferences multiple agents. Communications ACM, 53 (3), 8494.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms
(2nd edition). MIT Press.
Dodgson, C. (1884). Principles Parliamentary Representation. Harrison, London.
Dorn, B., & Schlotter, I. (2010). Multivariate complexity analysis swap bribery.
Proceedings 5th International Symposium Parameterized Exact Computation (IPEC), Vol. 6478 LNCS, pp. 107122. Springer.
Downey, R. G., & Fellows, M. R. (1999). Parameterized Complexity. Springer.
Elkind, E., Faliszewski, P., & Slinko, A. (2010a). Cloning elections. Proceedings
24th AAAI Conference Artificial Intelligence (AAAI), pp. 768773.
Elkind, E., Faliszewski, P., & Slinko, A. (2010b). role distances defining voting
rules. Proceedings 9th International Conference Autonomous Agents
Multiagent Systems (AAMAS), pp. 375382.
Erdelyi, G., Lackner, M., & Pfandler, A. (2012). complexity nearly single-peaked
consistency. Proceedings 4th International Workshop Computational Social Choice (COMSOC 2012), pp. 179190.
Escoffier, B., Lang, J., & Ozturk, M. (2008). Single-peaked consistency complexity.
Proceedings 18th European Conference Artificial Intelligence (ECAI), pp.
366370. IOS Press.
Even, G., Levi, R., Rawitz, D., Schieber, B., Shahar, S., & Sviridenko, M. (2008). Algorithms capacitated rectangle stabbing lot sizing joint set-up costs. ACM
Transactions Algorithms, 4 (3), 34:134:17.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. A. (2010). Using complexity
protext elections. Communications ACM, 53 (1), 7482.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L. A., & Rothe, J. (2009a). Llull
Copeland voting computationally resist bribery constructive control. Journal
Artificial Intelligence Research, 35, 275341.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L. A., & Rothe, J. (2009b). richer
understanding complexity election systems. Ravi, S., & Shukla, S.
(Eds.), Fundamental Problems Computing: Essays Honor Professor Daniel
J. Rosenkrantz, chap. 14, pp. 375406. Springer.
517

fiBetzler, Slinko, & Uhlmann

Faliszewski, P., & Procaccia, A. (2010). AIs war manipulation: winning?. AI
Magazine, 31 (4), 5364.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. A. (2011). complexity
manipulative attacks nearly single-peaked electorates. Proceedings 13th
Conference Theoretical Aspects Rationality Knowledge, TARK XIII, pp.
228237, New York, NY, USA. ACM.
Farfel, J., & Conitzer, V. (2011). Aggregating value ranges: Preference elicitation
truthfulness. Journal Autonomous Agents Multi-Agent Systems, 22 (1), 127
150.
Fellows, M. R., & Fernau, H. (2011). Facility location problems: parameterized view.
Discrete Applied Mathematics, 159 (11), 11181130.
Flum, J., & Grohe, M. (2006). Parameterized Complexity Theory. Springer.
Fredman, M. L., & Tarjan, R. E. (1987). Fibonacci heaps uses improved network
optimization algorithms. Journal ACM, 34 (3), 596615.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman.
Garey, M. R., Johnson, D. S., & Stockmeyer, L. (1974). simplified NP-complete
problems. Proceedings sixth annual ACM symposium Theory computing
(STOC), pp. 4763. ACM.
Golumbic, M. (1980). Algorithmic Graph Theory Perfect Graphs. Academic Press.
Gonzalez, T. F. (1985). Clustering minimize maximum intercluster distance. Theoretical Computer Science, 38, 293306.
Harsanyi, J. (1995). maximin principle serve basis morality? critique
John Rawlss theory. American Political Science Review, 69 (2), 594606.
Impagliazzo, R., Paturi, R., & Zane, F. (2001). problems strongly exponential
complexity?. Journal Computer System Sciences, 63 (4), 512530.
Levin, J., & Nalebuff, B. (1995). introduction vote-counting schemes. Journal
Economic Perspectives, 9 (1), 326.
Lu, T., & Boutilier, C. (2011). Budgeted social choice: consensus personalized
decision making. Proceedings Twenty-second International Joint Conference
Artificial Intelligence (IJCAI-11), pp. 280286. Also presented COMSOC-10.
Meir, R., Procaccia, A. D., Rosenschein, J. S., & Zohar, A. (2008). complexity strategic behavior multi-winner elections. Journal Artificial Intelligence Research, 33,
149178.
Meskanen, T., & Nurmi, H. (2008). Closeness counts social choice. Braham, M., &
Steffen, F. (Eds.), Power, Freedom, Voting, pp. 289306. Springer.
Monroe, B. L. (1995). Fully proportial representation. American Political Science Review,
89 (4), 925940.
Moulin, H. (1991). Axioms Cooperative Decision Making. Cambridge University Press.
518

fiOn Computation Fully Proportional Representation

Nehring, K., & Puppe, C. (2007). structure strategy-proof social choice Part I: General characterization possibility results median spaces. Journal Economic
Theory, 135 (1), 269305.
Niedermeier, R. (2006). Invitation Fixed-Parameter Algorithms. Oxford University Press.
Penrose, L. (1946). elementary statistics majority voting. Journal Royal
Statistical Society, 109, 5357.
Potthof, R. F., & Brams, S. J. (1998). Proportional representation: Broadening options.
Journal Theoretical Politics, 10 (2), 147178.
Procaccia, A. D., Rosenschein, J. S., & Zohar, A. (2007). Multi-winner elections: Complexity manipulation, control winner-determination. Proceedings 20th
International Joint Conference Artificial Intelligence (IJCAI), pp. 14761481.
Procaccia, A. D., Rosenschein, J. S., & Zohar, A. (2008). complexity achieving
proportional representation. Social Choice Welfare, 30, 353362.
Rawls, J. (1999). Theory Justice. Cambridge: Harvard University Press, 1971, Revised
Edition (Cambridge: Harvard University Press).
Skowron, P., Faliszewski, P., & Slinko, A. M. (2012). Proportional representation resource
allocation: Approximability results. CoRR, abs/1208.1661.
Slomczynski, W., & Zyczkowski, K. (2006). Penrose voting system optimal quota. Acta
Physica Polonica, B 37 (11), 31333143.
Tideman, N., & Richardson, R. (2000). Better voting methods technology:
refinement-manageability trade-off single transferable vote. Public Choice,
103 (1-2), 1334.
Tideman, N. (2006). Collective Decisions Voting. Ashgate Publishing Ltd.

519

fiJournal Artificial Intelligence Research 47 (2013) 1-34

Submitted 10/2012; published 05/2013

Feature Subset Selection Algorithm Automatic
Recommendation Method
Guangtao Wang
Qinbao Song
Heli Sun
Xueying Zhang

gt.wang@stu.xjtu.edu.cn
qbsong@mail.xjtu.edu.cn
hlsun@mail.xjtu.edu.cn
zhangxueying.725@stu.xjtu.edu.cn

Department Computer Science & Technology,
Xian Jiaotong University, 710049, China

Baowen Xu
Yuming Zhou

bwxu@nju.edu.cn
zhouyuming@nju.edu.cn

Department Computer Science & Technology,
Nanjing University, China

Abstract
Many feature subset selection (FSS) algorithms proposed,
appropriate given feature selection problem. time, far
rarely good way choose appropriate FSS algorithms problem hand. Thus,
FSS algorithm automatic recommendation important practically useful.
paper, meta learning based FSS algorithm automatic recommendation method
presented. proposed method first identifies data sets similar
one hand k -nearest neighbor classification algorithm, distances among
data sets calculated based commonly-used data set characteristics. Then,
ranks candidate FSS algorithms according performance similar
data sets, chooses algorithms best performance appropriate ones.
performance candidate FSS algorithms evaluated multi-criteria metric
takes account classification accuracy selected features,
also runtime feature selection number selected features. proposed
recommendation method extensively tested 115 real world data sets 22 wellknown frequently-used different FSS algorithms five representative classifiers.
results show effectiveness proposed FSS algorithm recommendation method.

1. Introduction
Feature subset selection (FSS) plays important role fields data mining
machine learning. good FSS algorithm effectively remove irrelevant redundant
features take account feature interaction. leads insight
understanding data, also improves performance learner enhancing
generalization capacity interpretability learning model (Pudil, Novovicova,
Somol, & Vrnata, 1998a; Pudil, Novovicova, Somol, & Vrnata, 1998b; Molina, Belanche,
& Nebot, 2002; Guyon & Elisseeff, 2003; Saeys, Inza, & Larranaga, 2007; Liu & Yu, 2005;
Liu, Motoda, Setiono, & Zhao, 2010).
c
2013
AI Access Foundation. rights reserved.

fiWang, Song, Sun, Zhang, Xu & Zhou

Although large number FSS algorithms proposed, single
algorithm performs uniformly well feature selection problems. Experiments
(Hall, 1999; Zhao & Liu, 2007) confirmed could exist significant differences
performance (e.g., classification accuracy) among different FSS algorithms given
data set. means given data set, FSS algorithms outperform others.
raises practical important question: FSS algorithms
picked given data set? common solution apply candidate FSS algorithms given data set, choose one best performance crossvalidation strategy. However, solution quite time-consuming especially highdimensional data (Brodley, 1993).
purpose addressing problem efficient way, paper, FSS
algorithm automatic recommendation method proposed. assumption underlying
proposed method performance FSS algorithm data set related
characteristics data set. rationality assumption demonstrated
follows:
1) Generally, new FSS algorithm proposed, performance needs extensively evaluated least real world data sets. However, published FSS algorithms
rarely tested identical group data sets (Hall, 1999; Zhao & Liu, 2007; Yu &
Liu, 2003; Dash & Liu, 2003; Kononenko, 1994). is, two algorithms,
usually tested different data. implies performance FSS
algorithm biases data sets.
2) time, famous NFL (No Free Lunch) (Wolpert, 2001) theory tells us
that, particular data set, different algorithms different data-conditioned performance, performance differences vary data sets.
evidences imply relationship performance
FSS algorithm characteristics data sets. paper, intend explore
relationship utilize automatically recommend appropriate FSS algorithm(s)
given data set. recommendation process viewed specific application
meta-learning (Vilalta & Drissi, 2002; Brazdil, Carrier, Soares, & Vilalta, 2008)
used recommend algorithms classification problems (Ali & Smith, 2006; King,
Feng, & Sutherland, 1995; Brazdil, Soares, & Da Costa, 2003; Kalousis, Gama, & Hilario,
2004; Smith-Miles, 2008; Song, Wang, & Wang, 2012).
model relationship, three fundamental issues considered: i)
features (often referred meta-features) used characterize data set; ii)
evaluate performance FSS algorithm identify applicable one(s)
given data set; iii) recommend FSS algorithm(s) new data set.
paper, meta-features, frequently used meta-learning (Vilalta &
Drissi, 2002; Ali & Smith, 2006; King et al., 1995; Brazdil et al., 2003; Castiello, Castellano,
& Fanelli, 2005), employed characterize data sets. time, multi-criteria
metric, takes account classification accuracy classifier
FSS algorithm also runtime feature selection number selected features,
used evaluate performance FSS algorithm. Meanwhile, k -NN (k -Nearest
Neighbor) based method proposed recommend FSS algorithm(s) new data set.
2

fiSubset Selection Algorithm Automatic Recommendation

proposed FSS algorithm recommendation method extensively tested
115 real world data sets 22 well-known frequently-used different FSS algorithms
five representative classifiers. results show effectiveness proposed recommendation method.
rest paper organized follows. Section 2 introduces preliminaries.
Section 3 describes proposed FSS algorithm recommendation method. Section 4 provides experimental results. Section 5 conducts sensitivity analysis number
nearest data sets recommendation results. Finally, section 6 summarizes
work draws conclusions.

2. Preliminaries
section, first describe meta-features used characterize data sets. Then,
introduce multi-criteria evaluation metric used measure performance FSS
algorithms.
2.1 Meta-features Data Sets
proposed FSS algorithm recommendation method based relationship
performance FSS algorithms meta-features data sets.
recommendation viewed data mining problem, performance
FSS algorithms meta-features target function input variables,
respectively. Due ubiquity Garbage In, Garbage (Lee, Lu, Ling, & Ko, 1999)
field data mining, selection meta-features crucial proposed
FSS recommendation method.
meta-features measures extracted data sets used
uniformly characterize different data sets, underlying properties reflected.
meta-features conveniently efficiently calculated, also related
performance machine learning algorithms (Castiello et al., 2005).
15 years research study improve meta-features proposed
StatLog project (Michie, Spiegelhalter, & Taylor, 1994). number meta-features
employed characterize data sets (Brazdil et al., 2003; Castiello et al., 2005;
Michie et al., 1994; Engels & Theusinger, 1998; Gama & Brazdil, 1995; Lindner & Studer,
1999; Sohn, 1999), demonstrated working well modeling relationship
characteristics data sets performance (e.g., classification accuracy)
learning algorithms (Ali & Smith, 2006; King et al., 1995; Brazdil et al., 2003; Kalousis et al.,
2004; Smith-Miles, 2008). meta-features characterize data sets themselves,
connection learning algorithms types, use model
relationship data sets FSS algorithms.
commonly used meta-features established focusing following three
aspects data set: i) general properties, ii) statistic-based properties, iii) informationtheoretic based properties (Castiello et al., 2005). Table 11 shows details.
1. order compute information-theoretic features, data sets continuous-valued features,
needed, well-known MDL (Minimum Description Length) method Fayyad & Irani criterion
used discretize continuous values.

3

fiWang, Song, Sun, Zhang, Xu & Zhou

Category
General properties

Statistical based properties

Information-theoretic properties

Notation

F


(X, )
Skew(X)
Kurt(X)
H(C)norm
H(X)norm
I(C, X)
I(C, X)max
ENattr
N Sratio

Measure description
Number instances
Number features
Number target concept values
Data set dimensionality, = I/F
Mean absolute linear correlation coefficient possible pairs features
Mean skewness
Mean kurtosis
Normalized class entropy
Mean normalized feature entropy
Mean mutual information class attribute
Maximum mutual information class attribute
Equivalent number features, ENattr = H(C)/M I(C, X)
Noise-signal ratio, N Sratio = (H(X) I(C, X))/M I(C, X)

Table 1: Meta-features used characterize data set
2.2 Multi-criteria Metric FSS Algorithm Evaluation
section, first, classical metrics evaluating performance FSS algorithm
introduced. Then, analyzing user requirements practice application, based
metrics, new user-oriented multi-criteria metric proposed FSS algorithm
evaluation combining metrics together.
2.2.1 Classical Performance Metrics
evaluating performance FSS algorithm, following three metrics
extensively used feature selection literature: i) classification accuracy , ii) runtime
feature selection, iii) number selected features.
1) classification accuracy (acc) classifier selected features used
measure well selected features describe classification problem.
given data set, different feature subsets generally result different classification
accuracies. Thus, reasonable feature subset higher classification accuracy stronger capability depicting classification problem. classification
accuracy also reflects ability FSS algorithm identifying salient features
learning.
2) runtime (t) feature selection measures efficiency FSS algorithm
picking useful features. also viewed metric measure cost feature
selection. longer runtime, higher expenditure feature selection.
3) number selected features (n) measures simplicity feature selection
results. classification accuracies two FSS algorithms similar, usually
favor algorithm fewer features.
Feature subset selection aims improve performance learning algorithms
usually measured classification accuracy. FSS algorithms higher classification accuracy favor. However, mean runtime
number selected features could ignored. explained following two
considerations:
1) Suppose two different FSS algorithms Ai Aj , given data set D.
classification accuracy Ai slightly greater Aj ,
4

fiSubset Selection Algorithm Automatic Recommendation

runtime Ai number features selected Ai much greater
Aj , Aj often chosen.
2) Usually, prefer use algorithms higher accuracy longer runtime,
lower accuracy shorter runtime. Therefore, need tradeoff classification accuracy runtime feature selection/the number selected
features. example, real-time systems, impossible choose algorithm
high time-consumption even classification accuracy high.
Therefore, necessary allow users making user-oriented performance evaluation
different FSS algorithms. purpose, needed address problem
integrate classification accuracy runtime feature selection number
selected features obtain unified metric. paper, resort multi-criteria
metric explore problem. underlying reason lies multi-criteria metric
successfully used evaluate data mining algorithms considering positive
properties (e.g. classification accuracy) negative ones (e.g. runtime number
selected features) simultaneously (Nakhaeizadeh & Schnabl, 1997, 1998).
comparing two algorithms, besides metrics used evaluate performance,
ratio metric values also used. example, suppose A1 A2 two
different FSS algorithms, A1 better A2 terms classification accuracy, i.e.,
acc1 > acc2 2 , ratio acc1 /acc2 > 1 used show A1 better A2 well.
contrary, negative metrics runtime feature selection number
selected features, corresponding ratio < 1 means better algorithm.
Actually, multi-criteria metric adjusted ratio ratios (ARR) (Brazdil et al., 2003),
combines classification accuracy runtime together unified metric,
proposed evaluate performance learning algorithm. extend ARR integrating runtime feature selection number selected features, new
multi-criteria metric EARR (extened ARR) proposed. following discussion,
show new metric EARR inclusive, flexible, easy understand.
2.2.2 Multi-Criteria Metric EARR
Let DSet = {D1 , D2 , , DN } set N data sets, ASet = {A1 , A2 , , }
set FSS algorithms. Suppose accji classification accuracy classifier FSS
algorithm Ai data set Dj (1 , 1 j N ), tji nji denote runtime
number selected features FSS algorithm Ai data set Dj , respectively.
EARR Ai Aj Dk defined
k
EARRD
Ai ,Aj =

accki /acckj
1 + log (tki /tkj ) + log (nki /nkj )

(1 6= j M, 1 k N ),

(1)

user-predefined parameters denote relative importance
runtime feature selection number selected features, respectively.
computation metric EARR based ratios classical FSS algorithm performance metrics, classification accuracy, runtime feature selection
2. acc1 acc2 corresponding classification accuracies algorithms A1 A2 , respectively.

5

fiWang, Song, Sun, Zhang, Xu & Zhou

number selected features. definition know EARR evaluates
FSS algorithm comparing another algorithm. reasonable since
objective assert algorithm good comparing another one instead
focusing performance. example, suppose classifier 70%
classification accuracy data set, get confused whether classifier good
not. However, compare another classifier obtain 90% classification
accuracy data set, definitely say first classifier good
compared second one.
Noted that, practice, runtime difference two different FSS algorithms
usually quite great. Meanwhile, high-dimensional data sets, difference
number selected features two different FSS algorithms great well. Thus,
ratio runtime ratio number selected features usually much
wide ranges classification accuracy. simple ratio runtime
simple ratio number selected features employed, would dominate
value EARR, ratio classification accuracy drowned. order
avoid situation, common logarithm (i.e., logarithm base 10) ratio
runtime common logarithm ratio number selected features
employed.
parameters represent amount classification accuracy user
willing trade 10 times speedup/reduction runtime feature selection/the
number selected features, respectively. allows users choose algorithms
shorter runtime less features acceptable accuracy. illustrated
following example. Suppose accki = (1 + + ) acckj , runtime algorithm Ai
given data set 10 times Aj (i.e., tki = 10 tkj ), number selected
features algorithm Ai 10 times Aj (i.e., nki = 10 nkj ). Then, according
Dk
1
3
k
Eq. (1), EARR
Ai ,Aj = 1, EARR Aj ,Ai = 1(+)2 > 1. case, Aj outperforms
Ai . user prefers fast algorithms less features, Aj his/her choice.
k
value EARR varies around 1. value EARR
Ai ,Aj greater (or equal
k
to, smaller than) EARR
Aj ,Ai indicates Ai better (or equal to,
worse than) Aj .
Eq. (1) directly used evaluate performance two different FSS algorithms.
comparing multiple FSS algorithms, performance algorithm Ai ASet
given data set evaluated metric EARR
Ai defined follows:

EARRD
Ai =

1
1


X

EARRD
Ai ,Aj .

(2)

j=1j6=i

equation shows EARR FSS algorithm Ai arithmetic
mean EARRD
Ai ,Aj Ai algorithm Aj D. is, performance
FSS algorithm Ai ASet evaluated based comparisons algorithms
{ASet {Ai }}. larger value EARR, better corresponding FSS algorithm
given data set D.
3. Since log (x/y) = log (y/x) ( + )2 > 0

6

fiSubset Selection Algorithm Automatic Recommendation

3. FSS Algorithm Recommendation Method
section, first give framework FSS algorithm recommendation. Then,
introduce nearest neighbor based recommendation method detail.
3.1 Framework
Based assumption relationship performance FSS
algorithm given data set data set characteristics (aka meta-features),
proposed recommendation method firstly constructs meta-knowledge database consisting
data set meta-features FSS algorithm performance. that, help
meta-knowledge database, k-NN based method used model relationship
recommend appropriate FSS algorithms new data set.
Therefore, proposed recommendation method consists two parts: Meta-knowledge
Database Construction FSS Algorithm Recommendation. Fig. 1 shows details.
Meta-knowledge database construction
Feature selection
algorithms

Historical
data sets

Performance metric
aquirement
Meta-features
extraction

Performance metrics

Meta-features

FSS algorithm recommendation

New data set
Recommended
FSS algorithms

Metaknowledge
database
Performance
metrics

Meta-features

Meta-features
extraction

Meta-features

Nearest data sets
identification

Top r algorithms
recommendation

Ranks

FSS algorithms
ranking

Nearest
data sets

Metric
collection

Performance
metrics

Figure 1: Framework feature subset selection algorithm recommendation
1) Meta-Knowledge Database Construction
mentioned previously, meta-knowledge database consists meta-features
set historical data sets performance group FSS algorithms them.
foundation proposed recommendation method, effectiveness
recommendations depends heavily database.
meta-knowledge database constructed following three steps. Firstly,
meta-features Table 1 extracted historical data set module Metafeatures extraction. Then, candidate FSS algorithm applied historical data
set. classification accuracy, runtime feature selection number selected
features recorded, corresponding value performance metric EARR
calculated. accomplished module Performance metric calculation. Finally,
data set, tuple, composed meta-features values
performance metric EARR candidate FSS algorithms, obtained added
knowledge database.
2) FSS Algorithm Recommendation
7

fiWang, Song, Sun, Zhang, Xu & Zhou

Based introduction first part Meta-knowledge Database Construction
presented above, learning target meta-knowledge data set EARR values
instead appropriate FSS algorithm. case, demonstrated
researchers usually resort instance-based k -NN (nearest neighbors) methods
variations (Brazdil et al., 2003, 2008) algorithm recommendation. Thus, k -NN
based FSS algorithm recommendation procedure proposed.
recommending FSS algorithms new data set, firstly, meta-features
data set extracted. Then, distance new data set historical
data set calculated according meta-features. that, k nearest data sets
identified, EARR values candidate FSS algorithms k data sets
retrieved meta-knowledge database. Finally, candidate FSS algorithms
ranked according EARR values, algorithm highest EARR
achieves top rank, one second highest EARR gets second rank,
forth, top r algorithms recommended.
3.2 Recommendation Method
recommend appropriate FSS algorithms new data set Dnew based k nearest
data sets, two foundational issues solved: i) identify k nearest
data sets, ii) recommend appropriate FSS algorithms based k data
sets.
1) k nearest data sets identification
k nearest data sets Dnew identified calculating distance Dnew
historical data set based meta-features. smaller distance,
similar corresponding data set Dnew .
order effectively calculate distance two data sets, L1 norm distance
(Atkeson, Moore, & Schaal, 1997) adopted since easy understand calculate,
ability measuring similarity two data sets demonstrated
Brazdil et al. (2003).
Let Fi = <fi,1 , fi,2 , , fi,h > meta-features data set Di , fi,p
value pth feature Fi h length meta-features. L1 norm distance
data sets Di Dj formulated
dist(Di , Dj ) = kFi Fj k1 =

h
X

|fi,p fj,p |.

(3)

p=1

worth noting ranges different meta-features quite different. example,
meta-features introduced Table 1, value normalized class entropy varies
0 1, number instances millions. Thus, meta-features
different ranges directly used calculate distance two data sets, metafeatures large range would dominate distance, meta-features small
range ignored. order avoid problem, 0-1 standardized method (Eq.
(4)) employed make meta-features range [0, 1].
fi,p min (f,p )
,
max (f,p ) min (f,p )
8

(4)

fiSubset Selection Algorithm Automatic Recommendation

fi,p (1 p h) value pth meta-feature data set Di , min (f,p )
max (f,p ) denote minimum maximum values pth meta-feature historical
data sets, respectively.
2) FSS algorithm recommendation
getting k nearest data sets Dnew , performance candidate FSS
algorithms Dnew evaluated according k nearest data sets. Then,
algorithms best performance recommended.

Let Dknn = {D1 , D2 , , Dk } k nearest data sets Dnew EARR Aij
performance metric FSS algorithm Ai data set Dj Dknn (1 j k).
performance Ai new data set Dnew evaluated
knn
EARRD
Ai

=

k
X

j


EARRAij ,

j = dj

1

k
X
dt 1 , dj = dist(Dnew , Dj ).
/

(5)

t=1

j=1

Eq. (5) indicates performance FSS algorithm Ai Dnew evaluated
performance Dknn Dnew . data set Dj Dknn , smaller distance
dj Dnew , similar two data sets. means two data
sets Dp Dq , dp < dq data set Dp similar Dnew , EARR
Ai Dp important evaluating performance Ai Dnew . Thus,
weighted average, takes account relative importance data set Dknn
rather treating data set equally, employed. Moreover, domain machine
learning, reciprocal distance usually used measure similarity.
k
P
j = dj 1 / dt 1 used weight EARR Ai Dj Dknn .
t=1

According EARR candidate FSS algorithm ASet Dnew , rank
candidate FSS algorithms obtained. greater EARR, higher
rank. Then, top r (e.g., r = 3 paper) FSS algorithms picked
appropriate ones new data set Dnew .
Procedure FSSAlgorithmRecommendation shows pseudo-code recommendation.
Time complexity. recommendation procedure consists two parts. first part
(lines 1-3), k nearest data sets given new data set identified. Firstly,
meta-features F extracted function MetaFeatureExtraction(). Then,
k-nearest historical data sets identified function NeighborRecognition() based
distance F meta-features Fi historical data set Di . Suppose
P number instances Q number features given data set
D, time complexity function MetaFeatureExtraction() O(P + Q). function
NeighborRecognition(), time complexity O(n) depends number
historical data sets n. Consequently, time complexity first part O(P +Q)+O(n).
second part (lines 4-8), r FSS algorithms recommended data set
D. Since weights EARRs k nearest data sets obtained directly,
time complexity two steps O(1). time complexity estimating ranking
EARRs algorithms ASet O(k m) + O(m log(m)), k preassigned
number nearest data sets number candidate FSS algorithms.
9

fiWang, Song, Sun, Zhang, Xu & Zhou

Procedure FSSAlgorithmRecommendation
Inputs :
- new given data set;
DSet - {D1 , D2 , , Dn }, historical data sets;
ASet - {A1 , A2 , , }, candidate FSS algorithms;
MetaDataBase - {<Fi , EARRsi >|1 n} Fi EARRs
meta-features EARRs ASet Di , respectively;
k - predefined number nearest neighbors;
r - number recommended FSS algorithms.
Output: RecAlgs - Recommended FSS algorithms
//Part 1: Recognition k nearest data sets
1 F = MetaFeatureExtraction (D);//Extract meta-features
2 MetaFeatureSet = {F1 , F2 , , Fn };//Meta-feature data set DSet
3 Neighbors = NeighborRecognition (k, F, MetaFeatureSet);
//Part 2: Appropriate FSS algorithm recommendation
4 WeightSet = calculate weight data set Neighbors //See Eq. (5)
5 EARRSet = corresponding EARRs data set Neighbors MetaDataBase;
6 Estimate EARR FSS algorithm ASet according WeightSet EARRSet

Eq. (5) rank algorithms ASet based EARRs;
7 RecAlgs = top r FSS algorithms;
8 return RecAlgs;

sum up, time complexity recommendation procedure O(P + Q) + O(n) +
O(km)+O(mlog(m)). practice, data set needs conduct feature selection,
number instances P and/or number features Q much greater
number nearest data sets k number candidate FSS algorithms
m, major time consumption recommendation procedure determined
first part.

4. Experimental Results Analysis
section, experimentally evaluate proposed feature subset selection (FSS)
algorithm recommendation method recommending algorithms benchmark data
sets.
4.1 Benchmark Data Sets
115 extensively-used real world data sets, come different areas Computer,
Image, Life, Biology, Physical Text 4 , employed experiment. sizes
data sets vary 10 24863 instances, numbers features
5 27680.
statistical summary data sets shown Table 2 terms number
instances (denoted I), number features (denoted F) number target
concepts (denoted T).
4. data sets available http://archive.ics.uci.edu/ml/datasets.html, http://
featureselection.asu.edu/datasets.php, http://sci2s.ugr.es/keel/datasets.php, http://www.
upo.es/eps/bigs/datasets.html, http://tunedit.org/repo/Data, respectively.

10

fiSubset Selection Algorithm Automatic Recommendation

Data ID
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58

Data Name
ada agnostic
ada prior
anneal
anneal ORIG
AR10P 130 674
arrhythmia
audiology
autos
balance-scale
breast-cancer
breast-w
bridges version1
bridges version2
car
CLL-SUB-111 111 2856
cmc
colic
colic.ORIG
colon
credit-a
credit-g
cylinder-bands
dermatology
diabetes
ECML90x27679
ecoli
Embryonaldataset C
eucalyptus
flags
GCM Test
gina agnostic
gina prior
gina prior2
glass
grub-damage
heart-c
heart-h
heart-statlog
hepatitis
hypothyroid
ionosphere
iris
kdd ipums la 97-small
kdd ipums la 98-small
kdd ipums la 99-small
kdd JapaneseVowels test
kdd JapaneseVowels train
kdd synthetic control
kr-vs-kp
labor
Leukemia
Leukemia 3c
leukemia test 34x7129
leukemia train 38x7129
lung-cancer
lymph
Lymphoma45x4026+2classes
Lymphoma96x4026+10classes


4562
4562
898
898
130
452
226
205
625
286
699
107
107
1728
111
1473
368
368
62
690
1000
540
366
768
90
336
60
24863
194
46
3468
3468
3468
214
155
303
294
270
155
3772
351
150
7019
7485
8844
5687
4274
600
3196
57
72
72
34
38
32
148
45
96

F
49
15
39
39
675
280
70
26
5
10
10
13
13
7
2857
10
23
28
2001
16
21
40
35
9
27680
8
7130
249
30
16064
971
785
785
10
9
14
14
14
20
30
35
5
61
61
61
15
15
62
37
17
7130
7130
7130
7130
57
19
4027
4027


2
2
6
6
10
16
24
7
3
2
2
6
6
4
3
3
2
2
2
2
2
2
6
2
43
8
2
12
8
14
2
2
10
7
4
5
5
2
2
4
2
3
9
10
9
9
9
6
2
2
2
3
2
2
3
4
2
11

Data ID
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115

Data Name
Lymphoma96x4026+9classes
mfeat-fourier
mfeat-morphological
mfeat-pixel
mfeat-zernike
molecular-biology promoters
monks-problems-1 test
monks-problems-1 train
monks-problems-2 test
monks-problems-2 train
monks-problems-3 test
monks-problems-3 train
mushroom
oh0.wc
oh10.wc
oh15.wc
oh5.wc
pasture
pendigits
PIE10P 210 1520
postoperative-patient-data
primary-tumor
segment
shuttle-landing-control
sick
SMK-CAN-187 187 1815
solar-flare 1
solar-flare 2
sonar
soybean
spectf test
spectf train
spectrometer
spect test
spect train
splice
sponge
squash-stored
squash-unstored
sylva agnostic
sylva prior
TOX-171 171 1538
tr11.wc
tr12.wc
tr23.wc
tr31.wc
tr41.wc
tr45.wc
trains
vehicle
vote
vowel
wap.wc
waveform-5000
white-clover
wine
zoo


96
2000
2000
2000
2000
106
432
124
432
169
432
122
8124
1003
1050
913
918
36
10992
210
90
339
2310
15
3772
187
323
1066
208
683
269
80
531
187
80
3190
76
52
52
14395
14395
171
414
313
204
927
878
690
10
846
435
990
1560
5000
63
178
101

F
4027
77
7
241
48
59
7
7
7
7
7
7
23
3183
3239
3101
3013
23
17
1521
9
18
20
7
30
1816
13
13
61
36
45
45
103
23
23
62
46
25
24
217
109
1538
6430
5805
5833
10129
7455
8262
33
19
17
14
8461
41
32
14
18


9
10
10
10
10
2
2
2
2
2
2
2
2
10
10
10
10
3
10
10
3
22
7
2
2
2
2
3
2
19
2
2
48
2
2
3
3
3
3
2
2
4
9
8
6
7
10
10
2
4
2
11
20
3
4
3
7

Table 2: Statistical summary 115 data sets

4.2 Experimental Setup
order evaluate performance proposed FSS algorithm recommendation
method, verify whether proposed method potentially useful practice,
confirm reproducibility experiments, set experimental study follows.
4.2.1 FSS Algorithms
FSS algorithms grouped two broad categories: Wrapper Filter (Molina et al.,
2002; Kohavi & John, 1997). Wrapper method uses error rate classification
algorithm evaluation function measure feature subset, evaluation
function Filter method independent classification algorithm. accuracy
Wrapper method usually high; however, generality result limited,
computational complexity high. comparison, Filter method generality,
computational complexity low. Due fact Wrapper method
computationally expensive (Dash & Liu, 1997), Filter method usually good choice
11

fiWang, Song, Sun, Zhang, Xu & Zhou

number features large. Thus, focus Filter method
experiment.
number Filter based FSS algorithms proposed handle feature selection
problems. algorithms significantly distinguished i) search method used
generate feature subset evaluated, ii) evaluation measures used assess
feature subset (Liu & Yu, 2005; de Souza, 2004; Dash & Liu, 1997; Pudil, Novovicova,
& Kittler, 1994).
order guarantee generality experimental results, twelve well-known
latest search methods four representative evaluation measures employed.
brief introduction search methods evaluation measures follows.
1) Search methods
i) Sequential forward search (SFS): Starting empty set, sequentially add
feature results highest value objective function current
feature subset.
ii) Sequential backward search (SBS): Starting full set, sequentially eliminate
feature results smallest decrease value objective function
current feature subset.
iii) Bi-direction search (BiS): parallel implementation SFS SBS. searches
feature subset space two directions.
iv) Genetic search (GS): randomized search method performs using simple
genetic algorithm (Goldberg, 1989). genetic algorithm finds feature subset
maximize special output function using techniques inspired natural evolution.
v) Linear search (LS): extension BestFirst search (Gutlein, Frank, Hall, & Karwath, 2009) searches space feature subsets greedy hill-climbing
augmented backtracking facility.
vi) Rank search (RS) (Battiti, 1994): uses feature evaluator (such gain ratio)
rank features. feature evaluator specified, forward selection
search used generate ranking list.
vii) Scatter search (SS) (Garcia Lopez, Garcia Torres, Melian Batista, Moreno Perez,
& Moreno-Vega, 2006): method performs scatter search feature
subset space. starts population many significant diverse feature
subsets, stops assessment criteria higher given threshold
improvement longer.
viii) Stepwise search (SWS) (Kohavi & John, 1997): variation forward search.
step search process, new feature added, test performed
check features eliminated without significant reduction
output function.
ix) Tabu search (TS) (Hedar, Wang, & Fukushima, 2008): proposed combinatorial optimization problems. adaptive memory responsive exploration
combining local search process anti-cycling memory-based rules avoid
trapping local optimal solutions.
12

fiSubset Selection Algorithm Automatic Recommendation

x) Interactive search (Zhao & Liu, 2007): traverses feature subset space
maximizing target function taking consideration interaction among
features.
xi) FCBF search (Yu & Liu, 2003): evaluates features via relevance redundancy analysis, uses analysis results guideline choose features.
xii) Ranker (Kononenko, 1994; Kira & Rendell, 1992; Liu & Setiono, 1995): evaluates
feature individually ranks features values evaluation
metrics.
2) Evaluation measures
i) Consistency (Liu & Setiono, 1996; Zhao & Liu, 2007): kind measure evaluates worth feature subset level consistency target concept
instances projected onto feature subset. consistency
feature subset never lower full feature set.
ii) Dependency (Hall, 1999; Yu & Liu, 2003): kind measure evaluates worth
subset features considering individual predictive ability feature
along degree redundancy among features. FSS methods based
kind measure assume good feature subsets contain features closely
correlated target concept, uncorrelated other.
iii) Distance (Kira & Rendell, 1992; Kononenko, 1994): kind measure proposed based assumption distance instances different target
concepts greater target concepts.
iv) Probabilistic significance (Zhou & Dillon, 1988; Liu & Setiono, 1995): measure
evaluates worth feature calculating probabilistic significance
two-way function, i.e., association feature target concept.
good feature significant association target concept.
pay attention that, besides four evaluation measures,
another basic kind measure: information-based measure (Liu & Yu, 2005; de Souza, 2004;
Dash & Liu, 1997), contemplated experiments. reason demonstrated follow. information-based measure usually conjunction ranker
search method. Thus, FSS algorithms based kind measure usually provide
rank list features instead telling us features relevant learning target. case, preassign particular thresholds FSS algorithms pick
relevant features. However, effective method set thresholds
acknowledged default threshold FSS algorithms. Moreover, unfair
conclude information measure based FSS algorithms assigned threshold
appropriate comparing FSS algorithms. Therefore, kind
FSS algorithm employed experiments.
Based search methods evaluation measures introduced above, 22 different
FSS algorithms obtained. Table 3 shows brief introduction FSS algorithms.
algorithms available data mining toolkit Weka5 (Hall, Frank,
5. http://www.cs.waikato.ac.nz/ml/weka/

13

fiWang, Song, Sun, Zhang, Xu & Zhou

Holmes, Pfahringer, Reutemann, & Witten, 2009), search method INTERACT
implemented based Weka source codes available online6 .
ID
1
2
3
4
5
6
7
8
9
10
11

Search Method
BestFirst + Sequential Forward Search
BestFirst + Sequential Backward Search
BestFirst + Bi-direction Search
Genetic Search
Linear Search
Rank Search
Scatter Search
Stepwise Search
Tabu Search
Interactive Search
BestFirst + Sequential Forward Search

Evaluation Measure
Dependency
Dependency
Dependency
Dependency
Dependency
Dependency
Dependency
Dependency
Dependency
Dependency
Consistency

Notation
CFS-SFS
CFS-SBS
CFS-BiS
CFS-GS
CFS-LS
CFS-RS
CFS-SS
CFS-SWS
CFS-TS
INTERACT-D
Cons-SFS

ID
12
13
14
15
16
17
18
19
20
21
22

Search Method
BestFirst + Sequential Backward Search
BestFirst + Bi-direction Search
Genetic Search
Linear Search
Rank Search
Scatter Search
Stepwise Search
Interactive Search
FCBFsearch
Ranker
Ranker

Evaluation Measure
Consistency
Consistency
Consistency
Consistency
Consistency
Consistency
Consistency
Consistency
Dependency
Distance
Probabilistic Significance

Notation
Cons-SBS
Cons-BiS
Cons-GS
Cons-LS
Cons-RS
Cons-SS
Cons-SWS
INTERACT-C
FCBF
Relief-F
Signific

Table 3: Introduction 22 FSS algorithms
noted algorithms require particular settings certain parameters. purpose allowing researchers confirm results, introduce
parameter settings FSS algorithms. as, FSS algorithms INTERACT-D
INTERACT-C, parameter, c-contribution threshold, used identify
irrelevant features. set threshold 0.0001 suggested Zhao Liu (2007).
FSS algorithm FCBF, set relevance threshold SU (Symmetric Uncertainty) value bN/ log N cth ranked feature suggested Yu Liu (2003). FSS
algorithm Relief-F, set significance threshold 0.01 used Robnik-Sikonja
Kononenko (2003). FSS algorithm Signific, threshold, statistical significance level , used identify irrelevant features. set commonly-used value
0.01 experiment. FSS algorithms conducted Weka environment
default setting(s).
4.2.2 Classification Algorithms
Since actual relevant features real world data sets usually known advance,
impracticable directly evaluate FSS algorithm selected features. Classification
accuracy extensively used metric evaluating performance FSS algorithms,
also plays important role proposed performance metric EARR assessing
different FSS algorithms.
However, different classification algorithms different biases. FSS algorithm may
suitable classification algorithms others (de Souza, 2004). fact
affects performance evaluation FSS algorithms.
mind, order demonstrate proposed FSS algorithm recommendation method limited particular classification algorithm, five representative
classification algorithms based different hypotheses employed. bayes-based
Naive Bayes (John & Langley, 1995) Bayes Network (Friedman, Geiger, & Goldszmidt,
1997), information gain-based C4.5 (Quinlan, 1993), rule-based PART (Frank & Witten,
1998), instance-based IB1 (Aha, Kibler, & Albert, 1991), respectively.
Although Naive Bayes Bayes Net bayes-based classification algorithms,
quite different since Naive Bayes proposed based hypoth6. http://www.public.asu.edu/huanliu/INTERACT/INTERACTsoftware.html

14

fiSubset Selection Algorithm Automatic Recommendation

esis features conditional independent (John & Langley, 1995), Bayes Net
takes account feature interaction (Friedman et al., 1997).
4.2.3 Measures Evaluate Recommendation Method
FSS algorithm recommendation application meta-learning. far know,
unified measures evaluate performance meta-learning methods.
order assess proposed FSS algorithm recommendation method, two measures,
recommendation hit ratio recommendation performance ratio, defined.
Let given data set Arec FSS algorithm recommended recommendation method D, two measures introduced follows.
1) Recommendation hit ratio
intuitive evaluation criterion whether recommended FSS algorithm Arec meets
users requirements. is, whether Arec optimal FSS algorithm D, performance Arec significant difference optimal FSS algorithm.
Suppose Aopt represents optimal FSS algorithm D, ASetopt denotes FSS
algorithm set algorithm significant difference Aopt (of course
includes Aopt well). Then, measure named recommendation hit defined assess
whether recommended algorithm Arec effective D.
Definition 1 (Recommendation hit). FSS algorithm Arec recommended data
set D, recommendation hit Hit(Arec , D) defined
(
1, Arec ASetopt
Hit(Arec , D) =
.
(6)
0, otherwise
Hit(Arec , D) = 1 means recommendation effective since recommended
FSS algorithm Arec one algorithms ASetopt D, hit(Arec , D) = 0 indicates
recommended FSS algorithm Arec member ASetopt , i.e., Arec significantly
worse optimal FSS algorithm Aopt D, thus recommendation bad.
Definition 1 know recommendation hit Hit(Arec , D) used evaluate
recommendation method single data set. Thus, extended recommendation
hit ratio evaluate recommendation set data sets, defined follows.
Definition 2 Recommendation hit ratio
G

1 X
Hit Ratio(Arec ) =
Hit(Arec , Di ).
G

(7)

i=1

G number historical data sets, e.g., G = 115 experiment.
Definition 2 represents percentage data sets appropriate FSS algorithms effectively recommended recommendation method. larger value,
better recommendation method.
2) Recommendation performance ratio
recommendation hit ratio reveals whether appropriate FSS algorithm
recommended given data set, cannot tell us margin recommended
algorithm best one. Thus, new measure, recommendation performance ratio
recommendation, defined.
15

fiWang, Song, Sun, Zhang, Xu & Zhou

Definition 3 (Recommendation performance ratio). Let EARRrec EARRopt
performance recommended FSS algorithm Arec optimal FSS algorithm D,
respectively. Then, recommendation performance ratio (RPR) Arec defined
RPR(Arec , D) = EARRrec /EAARopt .

(8)

definition, best performance EARR opt employed benchmark. Without
benchmark, hard determine recommended algorithms good not.
example, suppose EARR Arec 0.59. EARR opt = 0.61,
recommendation effective since EARR Arec close EARR opt . However,
recommendation poor EARR opt = 0.91.
RPR ratio EARR recommended FSS algorithm optimal one.
measures close recommended FSS algorithm optimal one, reveals
relative performance recommended FSS algorithm. value varies 0 1,
larger value RPR, closer performance recommended FSS algorithm
optimal one. recommended algorithm optimal one
RPR = 1.
4.2.4 Values Parameters
paper, multi-criteria metric EARR proposed evaluate performance
FSS algorithm. proposed metric EARR, two parameters established
users express requirements algorithm performance.
experiment, presenting results, two representative value pairs parameters used follows:
1) = 0 = 0. setting represents situation classification
accuracy important. higher classification accuracy selected features,
better corresponding FSS algorithms.
2) 6= 0 6= 0. setting represents situation user tolerate
accuracy attenuation favor FSS algorithms shorter runtime fewer
selected features. experiment, set 10% quite different
= = 0. allows us explore impact two parameters
recommendation results.
Moreover, order explore parameters affect recommended FSS
algorithms terms classification accuracy, runtime number selected features,
different parameters settings provided. Specifically, values vary 0
10% increase 1%.
4.3 Experimental Process
order make sure soundness experimental conclusion guarantee
experiments reported reproducible, part, introduce four crucial processes
used experiments. i) meta-knowledge database construction, ii) optimal
FSS algorithm set identification given data set, iii) Recommendation method validation
iv) sensitivity analysis number nearest data sets recommendations.
1) Meta-knowledge database construction
16

fiSubset Selection Algorithm Automatic Recommendation

Procedure PerformanceEvaluation
Inputs : data = given data set, i.e, one 115 data sets;
learner = given classification algorithm, i.e., one {Naive Bayes, C4.5, PART,
IB1 Bayes Network};
FSSAlgSet = {FSSAlg 1 , FSSAlg 2 , , FSSAlg 22 }, set 22 FSS
algorithms;
Output: EARRset = {EARR 1 , EARR 2 , , EARR 22 }, EARRs 22 FSS
algorithms data;
1 = 5; FOLDS = 10;
2 = 1 22
3
EARR = 0;
4 = 1
5
randomized order data;
6
generate FOLDS bins data;
7
j = 1 FOLDS
8
TestData = bin[j ];
9
TrainData = data- TestData;
10
numberList = Null , runtimeList = Null , accuracyList = Null ;
11
k = 1 22
12
(Subset, runtime) = apply FSSAlg k TrainData;
13
number = |Subset |;
14
RedTestData = reduce TestData according selected Subset;
15
RedTrainData = reduce TrainData according selected Subset;
16
classifier = learner (RedTrainData);
17
accuracy = apply classifier RedTestData;
18
numberList [k ] = number , runtimeList [k ] = runtime, accuracyList [k ] =

accuracy;
19
20
21

k = 1 22
EARR = EARRCompution(accuracyList, runtimeList, numberList, k );
//Compute EARR FSSAlg k jth bin pass according Eqs. (1) (2)
EARR k = EARR k + EARR;

22 1 22
23
EARR = EARR /(M FOLDS );
24 return EARRset;

data set Di (1 115), i) extract meta-features Fi ; ii) calculate
EARRs 22 candidate FSS algorithms stratified 510-fold cross-validation
strategy (Kohavi, 1995), iii) combine meta-features Fi EARR FSS
algorithm together form tuple, finally added meta-knowledge database.
Since extraction meta-features combination meta-features
EARRs straightforward, present calculation EARRs, procedure PerformanceEvaluation shows details.
2) Optimal FSS algorithm set identification
optimal FSS algorithm set given data set Di consists optimal FSS algorithm data set algorithms significant performance difference
optimal one Di .
optimal FSS algorithm set given data set Di obtained via non-parametric
Friedman test (1937) followed Holm procedure test (1988) performance,
17

fiWang, Song, Sun, Zhang, Xu & Zhou

estimated 510 cross validation strategy, 22 FSS algorithms. result
Friedman test shows significant performance difference among
22 FSS algorithms, 22 FSS algorithms added optimal FSS algorithm set.
Otherwise, FSS algorithm highest performance viewed optimal one
added optimal FSS algorithm set. Then, Holm procedure test performed
identify algorithms rest 21 FSS algorithms. algorithms
significant performance differences optimal one added optimal FSS
algorithm set.
reason non-parametric test employed lies difficult
performance values follow normal distribution satisfy variance homogeneous
condition.
Note optimal FSS algorithm sets different settings parameters
different, since values two parameters directly affect required performance
values.
3) Recommendation method validation
leave-one-out strategy used empirically evaluate proposed FSS algorithm recommendation method follows: data set Di (1 115)
viewed test data, i) identify k nearest data sets training data =
{D1 , , Di1 , Di+1 , , D115 } excluding Di ; ii) calculate performance 22 candidate FSS algorithms according Eq. (5) based k nearest data sets value
k determined standard cross-validation strategy, recommend top three
Di ; iii) evaluate recommendations measures introduced section 4.2.3.
4) Sensitivity analysis number nearest data sets recommendations
order explore effect number nearest data sets recommendations provide users empirical method choose value, data set,
possible numbers nearest data sets tested. is, identifying k
nearest data sets given data set, k set 1 number historical data
sets minus 1 (e.g., 114 experiment).
4.4 Results Analysis
section, present recommendation results terms recommended FSS algorithms, hit ratio performance ratio , respectively. Due space limit
paper, list recommendations, instead present results two
significantly different pairs , i.e., ( = 0, = 0) ( = 10%, = 10%).
Afterward, also provide experimental results influence user-oriented
parameters recommendations terms classification accuracy, runtime,
number selected features, respectively.
4.4.1 Recommended Algorithms Hit Ratio
Figs. 2, 3, 4, 5 6 show first recommended FSS algorithms 115 data sets
classification algorithms Naive Bayes, C4.5, PART, IB1 Bayes Network
used, respectively.
18

fiSubset Selection Algorithm Automatic Recommendation

figure, two sub-figures corresponding recommendation results
( = 0, = 0) ( = 10%, = 10%), respectively. sub-figure,
denote correctly incorrectly recommended algorithms, respectively.

FSS algorithm ID

Correctly recommended algorithm

Incorrectly recommended algorithm

22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

96

Data set ID

FSS algorithm ID

(a) = 0, = 0
22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

96

Data set ID

(b) = 10%, = 10%

Figure 2: FSS algorithms recommended 115 data sets Naive Bayes used

FSS algorithm ID

Correctly recommended algorithm

Incorrectly recommended algorithm

22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

96

Data set ID

FSS algorithm ID

(a) = 0, = 0
22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

96

Data set ID

(b) = 10%, = 10%

Figure 3: FSS algorithms recommended 115 data sets C4.5 used
figures, observe that:
1) five classifiers, proposed method effectively recommend appropriate
FSS algorithms 115 data sets.
case ( = 0, = 0), number data sets, whose appropriate FSS
algorithms correctly recommended, 109 115 Naive Bayes, 111 115
C4.5, 109 115 PART, 108 115 IB1, 109 115 Bayes
19

fiWang, Song, Sun, Zhang, Xu & Zhou

FSS algorithm ID

Correctly recommended algorithm

Incorrectly recommended algorithm

22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

96

Data set ID

FSS algorithm ID

(a) = 0, = 0
22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

96

Data set ID

(b) = 10%, = 10%

Figure 4: FSS algorithms recommended 115 data sets PART used

FSS algorithm ID

Correctly recommended algorithm

Incorrectly recommended algorithm

22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

96

Data set ID

FSS algorithm ID

(a) = 0, = 0
22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

96

Data set ID

(b) = 10%, = 10%

Figure 5: FSS algorithms recommended 115 data sets IB1 used

Network, respectively. states recommendation method effective
classification accuracy important.
case ( = 10%, = 10%), number data sets, whose appropriate FSS
algorithms correctly recommended, 104 115 Naive Bayes, 109 115
C4.5, 110 115 PART, 106 115 IB1, 104 115 Bayes
Network, respectively. indicates recommendation method also works well
tradeoff required among classification accuracy, runtime, number
selected features.
2) distribution recommended FSS algorithms 115 data sets different
different parameters settings. distribution relatively uniform ( = 0, = 0),
20

fiSubset Selection Algorithm Automatic Recommendation

FSS algorithm ID

Correctly recommended algorithm

Incorrectly recommended algorithm

22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

97

99 101 103 105 107 109 111 113 115
98 100 102 104 106 108 110 112 114

96

Data set ID

FSS algorithm ID

(a) = 0, = 0
22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

96

Data set ID

(b) = 10%, = 10%

Figure 6: FSS algorithms recommended 115 data sets Bayes Network used

seriously biased algorithm (e.g., 22th FSS algorithm) ( =
10%, = 10%).
phenomenon similar five classifiers. explained follows.
FSS algorithms best classification accuracy distribute 115 data sets
uniformly. Thus, case ( = 0, = 0) users favor accurate classifiers,
distribution recommended FSS algorithms relatively uniform well. However,
exist FSS algorithms run faster (e.g., 22th algorithm Signific)
select fewer features (e.g., 8th algorithm CFS-SWS, 18th algorithm ConsSWS, 22th algorithm Signific) 115 data sets. reason,
case ( = 10%, = 10%) users prefer FSS algorithms less runtime
fewer features, distribution FSS algorithms best performance
115 data sets biased algorithms, recommended FSS algorithms.
3) 22th FSS algorithm performs well 85 115 data sets classifiers
( = 10%, = 10%). seems FSS algorithm generally wellperformed FSS algorithm adopted FSS tasks need
FSS algorithm recommendation. Unfortunately, case. 22th FSS
algorithm still failing perform well quarter 115 data sets.
Yet, recommendation method distinguish data sets effectively
recommend appropriate FSS algorithms them. indicates recommendation
method still necessary case.
Compared ( = 0, = 0), know case due larger
values explained follows. 22 FSS algorithms, although
classification accuracies classifier features selected different,
differences usually bounded. Meanwhile, Eq. (1) know /
set greater bound value, value EARR dominated
runtime/the number selected features. means set
relatively large value, algorithm lower time complexity algorithm
chooses smaller number features recommended, classification
21

fiWang, Song, Sun, Zhang, Xu & Zhou

accuracy selected features ignored. However, know, one
important targets feature selection improve performance learning
algorithms. unreasonable ignore classification accuracy focus
speed simplicity FSS algorithm.
Thus, real applications, values set limit classification accuracies. Generally, / bounded (accmax accmin )/accmin ,
accmax accmin denote maximum minimum classification accuracies, respectively.
Parameter setting
= 0, = 0

= 10%, = 10%


Recommendation
Alg1st
Alg2nd
Alg3rd
Top 3
Alg1st
Alg2nd
Alg3rd
Top 3

Naive Bayes
94.78
83.48
74.78
99.13
90.43
71.30
38.26
99.13

C4.5
96.52
79.13
80.87
98.26
94.78
69.57
45.22
100.0

PART
94.78
92.17
84.35
99.13
94.78
70.43
42.61
100.0

IB1
93.91
77.39
75.65
99.13
92.17
64.35
43.48
100.0

Bayes Network
94.78
83.48
73.91
98.26
90.43
71.30
36.52
99.13

Algx denotes x -th algorithm ranking list recommended Top 3 means top three
algorithms recommended.

Table 4: Hit ratio (%) recommendations five classifiers different settings
(, )
Table 4 shows hit ratio recommended FSS algorithms five classifiers.
observe that:
1) single FSS algorithm recommended, hit ratio first recommended algorithm Alg1st highest, value 96.52% least 90.43%
five classifiers. Thus, Alg1st first choice.
2) top three algorithms recommended, hit ratio 100% least
98.62%. indicates confidence top three algorithms including
appropriate one high. reason top three algorithms
recommended. Moreover, proposed recommendation method reduced
number candidate algorithms three, users pick one fits
his/her specific requirement them.
4.4.2 Recommendation Performance Ratio
Figs. 7 8 show recommendation performance ratio RPR first recommended
FSS algorithm five classifiers ( = 0, = 0) ( = 10%, = 10%),
respectively. two figures observe that, data sets two
settings , RPRs recommended FSS algorithms greater 95%
100% matter classifier used. indicates
FSS algorithms recommended proposed method close optimal one.
Table 5 shows average RPRs 115 data sets five classifiers
different settings (, ). table, classifier, columns Rec Def
shows RPR value corresponding recommended FSS algorithms default FSS
algorithms, respectively. default FSS algorithm frequent best one
115 data sets classifier.
22

fiSubset Selection Algorithm Automatic Recommendation

RPR (%)

Naive Bayes
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

RPR (%)

C4.5
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

RPR (%)

PART
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

RPR (%)

IB1
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

RPR (%)

Bayes Network
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

Figure 7: RPR 1 st recommended FSS algorithm ( = 0, = 0) five
classifiers
RPR (%)

Naive Bayes
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

RPR (%)

C4.5
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

RPR (%)

PART
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

RPR (%)

IB1
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

RPR (%)

Bayes Network
100
95
90
85
80
75
70

1

3
2

5
4

7
6

9
8

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 115
10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114

Data set ID

Figure 8: RPR 1 st recommended FSS algorithm ( = 10%, = 10%)
five classifiers

23

fiWang, Song, Sun, Zhang, Xu & Zhou

observe average RPRs range 97.32% 98.8% ( = 0,
= 0), 97.82% 98.99% ( = 10%, = 10%), respectively. Moreover,
average RPR recommended FSS algorithms surpasses default FSS
algorithms five different classifiers. means proposed recommendation
method works well greatly fits users performance requirement.
Parameter setting
= 0, = 0
= 10%, = 10%

Naive bayes
Rec
Def
98.24 96.42
98.69 91.95

C4.5
Rec
Def
98.80
98.18
97.82
92.40

PART
Rec
Def
97.61 94.79
97.89 92.40

IB1
Rec
Def
97.32
96.43
98.11
92.35

Bayes Network
Rec
Def
98.37
96.63
98.99
92.43

Table 5: Average RPR (%) 115 data sets five classifiers

Data ID
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58


NB
0.0443
0.0227
0.0118
0.0079
0.0244
0.019
0.0091
0.0111
0.011
0.0091
0.0086
0.0062
0.0068
0.0077
0.0616
0.0099
0.0074
0.0083
0.0102
0.007
0.008
0.0103
0.008
0.0066
0.0088
0.0061
0.0097
0.0083
0.007
0.0273
0.2236
0.2602
0.3691
0.008
0.0084
0.0103
0.0065
0.0084
0.0098
0.0278
0.007
0.0138
0.1219
0.1453
0.1937
0.0225
0.0149
0.0101
0.0228
0.0069
0.0195
0.0202
0.0128
0.0128
0.0075
0.0084
0.0146
0.0432

C4.5
0.0425
0.0131
0.0124
0.0092
0.0253
0.019
0.0093
0.0062
0.0076
0.0087
0.007
0.0068
0.0085
0.0087
0.0582
0.0083
0.0126
0.0077
0.0078
0.0071
0.01
0.0079
0.0083
0.0064
0.0158
0.0068
0.0078
0.0069
0.0132
0.0272
0.2231
0.2616
0.3722
0.0103
0.0068
0.0068
0.0088
0.007
0.0352
0.0243
0.0099
0.006
0.1228
0.1427
0.1955
0.0232
0.0142
0.0125
0.0245
0.0075
0.0201
0.0207
0.0135
0.013
0.0073
0.0073
0.008
0.0464

PART
0.0499
0.0147
0.0123
0.0082
0.0257
0.0221
0.0093
0.0076
0.0072
0.0084
0.0072
0.0065
0.0064
0.0086
0.0575
0.0081
0.0076
0.0128
0.0105
0.007
0.009
0.011
0.0079
0.0067
0.0101
0.0075
0.0113
0.008
0.0093
0.0291
0.2236
0.2605
0.3689
0.0083
0.0065
0.0066
0.0086
0.0084
0.0069
0.0245
0.011
0.0106
0.1214
0.144
0.1972
0.0242
0.0125
0.0101
0.0191
0.0084
0.0196
0.0165
0.0116
0.0197
0.0069
0.007
0.0095
0.0449

IB1
0.0423
0.0137
0.0117
0.0114
0.0246
0.0192
0.0114
0.0066
0.0074
0.0138
0.0075
0.0063
0.0093
0.0084
0.058
0.0082
0.0084
0.0117
0.0067
0.0069
0.0075
0.0135
0.0093
0.0069
0.0082
0.0083
0.0117
0.0082
0.0072
0.0273
0.2239
0.262
0.3689
0.0113
0.0064
0.0066
0.0059
0.0093
0.0067
0.0246
0.007
0.0116
0.1231
0.145
0.194
0.0219
0.0139
0.0092
0.0198
0.0068
0.0209
0.0192
0.0156
0.0138
0.0065
0.006
0.0082
0.0436

BNet
0.0464
0.0129
0.0116
0.0096
0.0241
0.0208
0.0113
0.0088
0.0076
0.0073
0.0083
0.011
0.0096
0.0077
0.0586
0.009
0.0085
0.007
0.0091
0.0081
0.0079
0.0088
0.0072
0.0093
0.0094
0.0077
0.0123
0.0074
0.007
0.0272
0.2255
0.2596
0.3714
0.007
0.009
0.0069
0.0061
0.0085
0.0077
0.0249
0.0086
0.0063
0.1241
0.1434
0.1935
0.0228
0.015
0.0104
0.024
0.009
0.0197
0.0165
0.0158
0.0134
0.0068
0.0069
0.0103
0.0445

Data ID
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
Average

NB
0.0446
0.0361
0.0087
0.0845
0.0225
0.0108
0.0117
0.0089
0.0092
0.0082
0.0061
0.0069
0.0611
0.203
0.1854
0.1195
0.1246
0.0147
0.0576
0.0685
0.0081
0.0086
0.0203
0.0095
0.0244
0.0683
0.0074
0.0084
0.0066
0.0096
0.0095
0.006
0.0158
0.0068
0.0097
0.0365
0.0108
0.0058
0.0082
0.4402
0.4591
0.0504
0.1012
0.04
0.0633
0.9103
0.6484
0.5864
0.0067
0.0091
0.0082
0.0088
0.7746
0.0267
0.0082
0.0106
0.0086
0.0658

C4.5
0.0439
0.0351
0.0096
0.0843
0.0177
0.0077
0.0105
0.0075
0.0067
0.0063
0.0058
0.0077
0.0496
0.1993
0.1689
0.1112
0.1208
0.0064
0.0526
0.0704
0.006
0.0085
0.0144
0.0109
0.0244
0.0671
0.0069
0.0077
0.0101
0.0091
0.0095
0.0069
0.0152
0.0073
0.0076
0.0396
0.0081
0.0062
0.0078
0.4429
0.4532
0.0496
0.095
0.0393
0.0618
0.9096
0.6448
0.5884
0.0056
0.0075
0.0074
0.0131
0.7759
0.0255
0.0075
0.0095
0.0079
0.0651

PART
0.0443
0.0407
0.0073
0.0835
0.0211
0.0065
0.0074
0.0058
0.0079
0.0071
0.006
0.0079
0.051
0.1976
0.1631
0.1105
0.1217
0.0068
0.0509
0.0641
0.0082
0.0087
0.0141
0.0054
0.0276
0.0674
0.0086
0.0411
0.0071
0.0124
0.0078
0.0085
0.0164
0.0066
0.008
0.0378
0.0064
0.0062
0.0064
0.444
0.4557
0.0502
0.0954
0.0424
0.0644
0.9091
0.6443
0.5861
0.0065
0.0102
0.0087
0.0131
0.7736
0.025
0.0066
0.0095
0.0073
0.0652

IB1
0.0477
0.034
0.0078
0.0853
0.02
0.0076
0.0068
0.008
0.0065
0.0085
0.0067
0.0097
0.0485
0.1994
0.1652
0.1103
0.1209
0.0067
0.0519
0.066
0.008
0.0072
0.0118
0.0091
0.0257
0.0692
0.0086
0.0074
0.0069
0.014
0.0124
0.0066
0.0183
0.0081
0.0065
0.0374
0.0094
0.0061
0.0068
0.4401
0.4551
0.0539
0.0966
0.0416
0.0635
0.9142
0.6464
0.5851
0.0075
0.0131
0.0064
0.0093
0.7739
0.0266
0.0063
0.0055
0.0062
0.0649

BNet
0.0427
0.0354
0.0085
0.0859
0.0194
0.0098
0.0071
0.0079
0.0064
0.0116
0.0067
0.007
0.0514
0.1983
0.1638
0.1096
0.1226
0.006
0.0533
0.0646
0.013
0.0089
0.0184
0.0082
0.0248
0.0664
0.0071
0.0132
0.0077
0.0113
0.0092
0.0079
0.0165
0.0061
0.008
0.0375
0.0077
0.0064
0.0083
0.4413
0.4545
0.0526
0.0968
0.0394
0.0625
0.9122
0.6461
0.5854
0.0055
0.0103
0.0095
0.0078
0.7746
0.0282
0.0135
0.0073
0.0064
0.0650

NB BNet denote Naive Bayes Bayes Network, respectively.

Table 6: Recommendation time 115 data sets five classifiers (in second )

24

fiSubset Selection Algorithm Automatic Recommendation

4.4.3 Recommendation Time
recommending FSS algorithms feature selection problem, recommendation
time contributed meta-features extraction, k nearest data sets identification,
candidate algorithm ranking according performance k data sets.
three recommendation time contributors, candidate algorithm ranking
related parameters performance metric EARR.
However, computation performance EARR whatever values
are. means recommendation time independent specific settings
. Thus, present recommendation time ( = 0, = 0), Table 6
shows details.
Table 6 observe given data set, recommendation time differences
five classifiers small. reason recommendation time mainly
contributed extraction meta-features, relation classifiers.
consistent time complexity analysis Section 3.2. also observe
data sets, recommendation time less 0.1 second, average value
115 data sets around 0.65 second five classifiers. much faster
conventional cross validation method.
4.4.4 Impact Parameters
Figs. 9, 10, 11, 12 13 show impact settings classification
accuracy, runtime feature selection, number selected features, Hit Ratio
RPR value, respectively.
NaiveBayes

C4.5

PART

Average accuracy

0.845

Average accuracy

IB1

Bayes Network

0.845

0.84
0.835
0.83
0.825
0.82
0.815
0.81

0.84
0.835
0.83
0.825
0.82
0.815
0.81
0.805

0.805
0

0

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

!

Figure 9: Classification accuracies five classifiers recommended FSS algorithms different values
Fig. 9 shows classification accuracies five classifiers different values
. observe that, increase either , classification
accuracies five classifiers recommended FSS algorithms decrease.
increase indicates users much prefer faster FSS algorithms
FSS algorithms get less features. Thus, proportion classification accuracy
performance decreased. means ranks FSS algorithms run faster
and/or get less features improved corresponding FSS algorithms finally
selected.
25

fiWang, Song, Sun, Zhang, Xu & Zhou

C4.5

PART

IB1

Bayes Network

2400

Average runtime (ms)

Average runtime (ms)

NaiveBayes
2400
2200
2000
1800
1600
1400
1200
1000
800
600
400
200

2200
2000
1800
1600
1400
1200
1000
800
600
400

0

0

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

!

Figure 10: Runtime FSS algorithms recommended five classifiers different
values
Fig. 10 shows runtime FSS algorithms recommended five classifiers
different values five classifiers. observe that:
1) increase , average runtime recommended FSS algorithms
classifier decreases. Note larger value means users favor faster FSS algorithms. Thus, indicates users performance requirement met since faster FSS
algorithms recommended.
2) increase , average runtime recommended FSS algorithms increases
well. proposed recommendation method, appropriate
FSS algorithms given data set recommended based nearest data sets.
Moreover, experiment, half (i.e., 69) 115 data sets,
negative correlation number selected features runtime
22 FSS algorithms. Thus, data sets kind negative correlation,
possible nearest neighbors given data set negative correlation.
Therefore, larger means longer runtime. Another possible reason larger
value means users favor FSS algorithms choose fewer features, order
get fewer features, FSS algorithms need consume relatively time.
C4.5

PART

Average number features

Average number features

NaiveBayes

100
90
80
70
60
50
40
0

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

IB1

Bayes Network

120
100
80
60
40
20
0

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

!

Figure 11: Number features selected FSS algorithms recommended
five classifiers different values
Fig. 11 shows number features selected FSS algorithms recommended
five classifiers different values . observe that:
26

fiSubset Selection Algorithm Automatic Recommendation

1) increase , average number selected features increases well.
proposed recommendation method, appropriate FSS algorithms
given data set recommended based nearest data sets. Moreover,
experiment, half (i.e., 69) 115 data sets, negative correlation number selected features runtime 22 FSS algorithms.
Thus, data sets kind negative correlation, possible
nearest neighbors given data set negative correlation. Therefore, larger
means features. Another possible reason larger value means users
favor faster FSS algorithms. possible shorter computation time obtained
via filter less features features remained.
Note exception. is, average number selected features
C4.5 decreases value small. However, decrement comes quite
small range (i.e., < 0.005).
2) increase , average number features selected recommended
FSS algorithm decreases. Note larger value means users favor FSS algorithms
get fewer features. Thus, indicates users requirement met since
FSS algorithms get fewer features recommended.
NaiveBayes

C4.5

PART

Average Hit Ratio (%)

Average Hit Ratio (%)

IB1

Bayes Network

100

100
99
98
97
96
95
94
93
92

99
98
97
96
95
94
93
92

91
0

0

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

!

Figure 12: Average Hit Ratio FSS algorithms recommended five classifiers
different values
C4.5

PART
100

99.5

99.5

Average RPR (%)

Average RPR (%)

NaiveBayes
100

99
98.5
98
97.5

IB1

Bayes Network

99
98.5
98
97.5
97

97
0

0

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1

!

Figure 13: Average RPR FSS algorithms recommended five classifiers
different values
Figs. 12 13 show average hit ratio RPR recommended FSS algorithms
different values five classifiers.
27

fiWang, Song, Sun, Zhang, Xu & Zhou

observe that, average hit ratio falls intervals [91.74%, 100%]
[92.56%, 99.13%]) . average RPR varies intervals [97.69%,
98.82%] [97.68%, 98.73%] . change , hit
ratio RPR recommended FSS algorithms vary well. However, change
intervals fall relative small interval lower bound stands fairly high level.
minimum average hit ratio 91.74% minimum average RPR
97.68%. indicates proposed FSS algorithm recommendation method
general application works well different settings .

5. Sensitivity Analysis Number Nearest Data Sets
Recommendation Results
section, analyze number nearest data sets affects recommendation performance. Based experimental results, provide guidelines
selecting appropriate number nearest data sets practice.
5.1 Experimental Method
Generally, different numbers nearest data sets (i.e., k) result different recommendations. Thus, recommending FSS algorithms feature selection problem,
appropriate k value important.
k value results higher recommendation performance preferred. However,
recommendation performance difference two different k values sometimes might
random significant. Thus, order identify appropriate k value
alternatives, first determine whether performance differences among
statistically significant. Non-parametric statistical test, Friedman test followed
Holm procedure test suggested Demsar (2006), used purpose.
experiment, conducted FSS algorithm recommendation possible k
values (i.e., 1 114) 115 data sets. identifying appropriate k
values, non-parametric statistical test conducted follows.
Firstly, Friedman test performed 114 recommendation performance
significance level 0.05. null hypothesis 114 k values perform equivalently
well proposed recommendation method 115 data sets.
Friedman test rejects null hypothesis, is, exists significant difference
among 114 k values, choose one recommendation best
performance reference. that, Holm procedure test performed find
k values recommendation performance significant difference
reference. identified k values including reference appropriate
numbers nearest data sets.
5.2 Results Analysis
Fig. 14 shows number nearest data sets (i.e., k) affects performance
recommendation method different settings , denotes
k recommendation performance significantly worse others
significance level 0.05. observe that:
28

fiSubset Selection Algorithm Automatic Recommendation

Naive Bayes

C4.5

PART

IB1

Bayes Network

Inappropriate number neighbors

1
0.995

RPR

0.99
0.985
0.98
0.975
0.97
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

97
96

99 101 103 105 107 109 111 113
98 100 102 104 106 108 110 112 114

Number nearest data sets

(a) = 0, = 0
Naive Bayes

C4.5

PART

IB1

Bayes Network

Inappropriate number neighbors

1

RPR

0.995
0.99
0.985
0.98
0.975
1

3
2

5
4

7
6

9
8

11
10

13
12

15
14

17
16

19
18

21
20

23
22

25
24

27
26

29
28

31
30

33
32

35
34

37
36

39
38

41
40

43
42

45
44

47
46

49
48

51
50

53
52

55
54

57
56

59
58

61
60

63
62

65
64

67
66

69
68

71
70

73
72

75
74

77
76

79
78

81
80

83
82

85
84

87
86

89
88

91
90

93
92

95
94

97
96

99 101 103 105 107 109 111 113
98 100 102 104 106 108 110 112 114

Number nearest data sets

(b) = 10%, = 10%

Figure 14: Number nearest data sets vs. RPR
1) = = 0 (Fig. 14(a)), five classifiers, RPR varies
different k values. Specifically, RPR fluctuant k smaller 20,
relatively flat middle part, decreases k larger 79 except
C4.5. However, increment C4.5 small (< 0.002). might due
C4.5 picks useful features build tree itself, impact feature
selection methods less. Moreover, difference among accuracies C4.5
data sets relatively small, performance metric EARR used evaluate
different FSS algorithms depends classification accuracy = = 0. Thus,
RPR C4.5 relatively stable different values k.
2) case = = 10% (Fig. 14(b)), variation RPR different
= = 0. five classifiers, RPR first decreases fluctuations,
increases, finally decreases slowly steadily. could due that,
parameters set relatively large value (such 10% experiment),
runtime ( number features selected by) FSS algorithm play
important role evaluating performance FSS algorithm. Thus,
given data set, FSS algorithms lower time complexity (or smaller number
selected features) possibly higher ranked larger RPR. Therefore,
increasing k, algorithms possibly recommended. Meanwhile,
data sets, algorithms either real appropriate algorithms
larger RPR, RPR averaged data sets relatively stable increasing
k.
29

fiWang, Song, Sun, Zhang, Xu & Zhou

3) Comparing cases = = 0 = = 10%, found appears
k < 21 former k < 29 latter, emerges k > 76
former. means cannot choose k values falling ranges.
time, also found peak values RPR = = 10% appear
range [32, 54], also one peak value ranges = = 0 except C4.5.
means set k 28% 47% number data sets, better recommendation
performance obtained.

6. Conclusion
paper, presented FSS algorithm recommendation method aim
support automatic selection appropriate FSS algorithms new feature selection
problem number candidates.
proposed recommendation method consists meta-knowledge database construction algorithm recommendation. former obtains meta-features performance candidate FSS algorithms, latter models relationship
meta-features FSS algorithm performance based k -NN method recommends appropriate algorithms feature selection problem built model.
thoroughly tested recommendation method 115 real world data sets, 22
different FSS algorithms, five representative classification algorithms two typical
users performance requirements. experimental results show recommendation
method effective.
also conducted sensitivity analysis explore number nearest
data sets (k) impacts FSS algorithm recommendation, suggest set k 28%
47% number historical data sets.
paper, utilized well-known commonly-used meta-features
characterize different data sets. meta-features informative?
informative meta-features? still open questions. knowledge,
still exist effective method answer questions. Thus, future
work, plan explore measure information meta-features
whether informative meta-features lead improvements FSS algorithm recommendation.

Acknowledgements
work supported National Natural Science Foundation China grant
61070006.

References
Aha, D. W., Kibler, D., & Albert, M. K. (1991). Instance-based learning algorithms. Machine learning, 6 (1), 3766.
Ali, S., & Smith, K. A. (2006). learning algorithm selection classification. Applied
Soft Computing, 6 (2), 119138.
30

fiSubset Selection Algorithm Automatic Recommendation

Atkeson, C. G., Moore, A. W., & Schaal, S. (1997). Locally weighted learning. Artificial
intelligence review, 11 (1), 1173.
Battiti, R. (1994). Using mutual information selecting features supervised neural net
learning. IEEE Transactions Neural Networks, 5 (4), 537550.
Brazdil, P., Carrier, C., Soares, C., & Vilalta, R. (2008). Metalearning: Applications data
mining. Springer.
Brazdil, P. B., Soares, C., & Da Costa, J. P. (2003). Ranking learning algorithms: Using IBL
meta-learning accuracy time results. Machine Learning, 50 (3), 251277.
Brodley, C. E. (1993). Addressing selective superiority problem: Automatic algorithm/model class selection. Proceedings Tenth International Conference
Machine Learning, pp. 1724. Citeseer.
Castiello, C., Castellano, G., & Fanelli, A. (2005). Meta-data: Characterization input
features meta-learning. Modeling Decisions Artificial Intelligence, 457468.
Dash, M., & Liu, H. (1997). Feature selection classification. Intelligent data analysis,
1 (3), 131156.
Dash, M., & Liu, H. (2003). Consistency-based search feature selection. Artificial Intelligence, 151 (1-2), 155176.
de Souza, J. T. (2004). Feature selection general hybrid algorithm. Ph.D. thesis,
University Ottawa.
Demsar, J. (2006). Statistical comparisons classifiers multiple data sets. Journal
Machine Learning Research, 7, 130.
Engels, R., & Theusinger, C. (1998). Using data metric preprocessing advice data
mining applications..
Frank, E., & Witten, I. H. (1998). Generating accurate rule sets without global optimization.
Proceedings 25th international conference Machine learning, pp. 144151.
Morgan Kaufmann, San Francisco, CA.
Friedman, M. (1937). use ranks avoid assumption normality implicit
analysis variance. Journal American Statistical Association, 32 (200),
675701.
Friedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. Machine
learning, 29 (2), 131163.
Gama, J., & Brazdil, P. (1995). Characterization classification algorithms. Progress
Artificial Intelligence, 189200.
Garcia Lopez, F., Garcia Torres, M., Melian Batista, B., Moreno Perez, J. A., & MorenoVega, J. M. (2006). Solving feature subset selection problem parallel scatter
search. European Journal Operational Research, 169 (2), 477489.
Goldberg, D. E. (1989). Genetic algorithms search, optimization, machine learning.
Addison-Wesley Professional.
31

fiWang, Song, Sun, Zhang, Xu & Zhou

Gutlein, M., Frank, E., Hall, M., & Karwath, A. (2009). Large-scale attribute selection
using wrappers. Proceedings IEEE Symposium Computational Intelligence
Data Mining, pp. 332339. IEEE.
Guyon, I., & Elisseeff, A. (2003). introduction variable feature selection.
Journal Machine Learning Research, 3, 11571182.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. (2009).
weka data mining software: update. ACM SIGKDD Explorations Newsletter, 11 (1),
1018.
Hall, M. A. (1999). Correlation-based Feature Selection Machine Learning. Ph.D. thesis,
University Waikato.
Hedar, A. R., Wang, J., & Fukushima, M. (2008). Tabu search attribute reduction
rough set theory. Soft Computing-A Fusion Foundations, Methodologies
Applications, 12 (9), 909918.
Hommel, G. (1988). stagewise rejective multiple test procedure based modified
bonferroni test. Biometrika, 75 (2), 383386.
John, G. H., & Langley, P. (1995). Estimating continuous distributions Bayesian classifiers. Proceedings eleventh conference uncertainty artificial intelligence,
Vol. 1, pp. 338345. Citeseer.
Kalousis, A., Gama, J., & Hilario, M. (2004). data algorithms: Understanding
inductive performance. Machine Learning, 54 (3), 275312.
King, R. D., Feng, C., & Sutherland, A. (1995). Statlog: comparison classification algorithms large real-world problems. Applied Artificial Intelligence, 9 (3), 289333.
Kira, K., & Rendell, L. (1992). practical approach feature selection. Proceedings ninth international workshop Machine learning, pp. 249256. Morgan
Kaufmann Publishers Inc.
Kohavi, R. (1995). study cross-validation bootstrap accuracy estimation
model selection. International joint Conference artificial intelligence, Vol. 14,
pp. 11371145. Citeseer.
Kohavi, R., & John, G. (1997). Wrappers feature subset selection. Artificial intelligence,
97 (1), 273324.
Kononenko, I. (1994). Estimating attributes: analysis extensions RELIEF. Proceedings European conference machine learning Machine Learning, pp.
171182. Springer-Verlag New York.
Lee, M., Lu, H., Ling, T., & Ko, Y. (1999). Cleansing data mining warehousing.
Proceedings 10th International Conference Database Expert Systems
Applications, pp. 751760. Springer.
Lindner, G., & Studer, R. (1999). AST: Support algorithm selection CBR approach. Principles Data Mining Knowledge Discovery, 418423.
Liu, H., Motoda, H., Setiono, R., & Zhao, Z. (2010). Feature Selection: Ever Evolving
Frontier Data Mining. Fourth Workshop Feature Selection Data
Mining, pp. 314. Citeseer.
32

fiSubset Selection Algorithm Automatic Recommendation

Liu, H., & Setiono, R. (1995). Chi2: Feature selection discretization numeric attributes. Proceedings Seventh International Conference Tools Artificial Intelligence, pp. 388391. IEEE.
Liu, H., & Setiono, R. (1996). probabilistic approach feature selection-a filter solution..
pp. 319327. Citeseer.
Liu, H., & Yu, L. (2005). Toward integrating feature selection algorithms classification
clustering. IEEE Transactions Knowledge Data Engineering, 17 (4), 491
502.
Michie, D., Spiegelhalter, D. J., & Taylor, C. C. (1994).
statistical classification..

Machine learning, neural

Molina, L. C., Belanche, L., & Nebot, A. (2002). Feature selection algorithms: survey
experimental evaluation. Proceedings IEEE International Conference Data
Mining, pp. 306313. IEEE.
Nakhaeizadeh, G., & Schnabl, A. (1997). Development multi-criteria metrics evaluation data mining algorithms. Proceedings 3rd International Conference
Knowledge Discovery Data mining, pp. 3742.
Nakhaeizadeh, G., & Schnabl, A. (1998). Towards personalization algorithms evaluation data mining. Proceedings 4th International Conference Knowledge
Discovery Data mining, pp. 289293.
Pudil, P., Novovicova, J., & Kittler, J. (1994). Floating search methods feature selection.
Pattern recognition letters, 15 (11), 11191125.
Pudil, P., Novovicova, J., Somol, P., & Vrnata, R. (1998a). Conceptual base feature
selection consulting system. Kybernetika, 34 (4), 451460.
Pudil, P., Novovicova, J., Somol, P., & Vrnata, R. (1998b). Feature selection expertuser
oriented approach. Advances Pattern Recognition, 573582.
Quinlan, J. R. (1993). C4.5: programs machine learning. Morgan Kaufmann.
Robnik-Sikonja, M., & Kononenko, I. (2003). Theoretical empirical analysis relieff
rrelieff. Machine learning, 53 (1), 2369.
Saeys, Y., Inza, I., & Larranaga, P. (2007). review feature selection techniques
bioinformatics. Bioinformatics, 23 (19), 25072517.
Smith-Miles, K. A. (2008). Cross-disciplinary perspectives meta-learning algorithm
selection. ACM Computing Surveys, 41 (1), 125.
Sohn, S. Y. (1999). Meta analysis classification algorithms pattern recognition. IEEE
Transactions Pattern Analysis Machine Intelligence, 21 (11), 11371144.
Song, Q. B., Wang, G. T., & Wang, C. (2012). Automatic recommendation classification
algorithms based data set characteristics. Pattern Recognition, 45 (7), 26722689.
Vilalta, R., & Drissi, Y. (2002). perspective view survey meta-learning. Artificial
Intelligence Review, 18 (2), 7795.
33

fiWang, Song, Sun, Zhang, Xu & Zhou

Wolpert, D. H. (2001). supervised learning no-free-lunch theorems. Proceedings
6th Online World Conference Soft Computing Industrial Applications, pp.
2542. Citeseer.
Yu, L., & Liu, H. (2003). Feature selection high-dimensional data: fast correlationbased filter solution. Proceedings Twentieth International Conference
Machine Leaning, Vol. 20, pp. 856863.
Zhao, Z., & Liu, H. (2007). Searching interacting features. Proceedings 20th
International Joint Conference Artifical Intelligence, pp. 11561161. Morgan Kaufmann Publishers Inc.
Zhou, X., & Dillon, T. (1988). heuristic-statistical feature selection criterion inductive machine learning real world. Proceedings IEEE International
Conference Systems, Man, Cybernetics, Vol. 1, pp. 548552. IEEE.

34

fiJournal Artificial Intelligence Research 47 (2013) 741-808

Submitted 01/13; published 08/13

Acyclicity Notions Existential Rules
Application Query Answering Ontologies
Bernardo Cuenca Grau
Ian Horrocks
Markus Krotzsch
Clemens Kupke
Despoina Magka
Boris Motik
Zhe Wang

bernardo.cuenca.grau@cs.ox.ac.uk
ian.horrocks@cs.ox.ac.uk
markus.kroetzsch@cs.ox.ac.uk
clemens.kupke@cs.ox.ac.uk
despoina.magka@cs.ox.ac.uk
boris.motik@cs.ox.ac.uk
zhe.wang@cs.ox.ac.uk

Department Computer Science, University Oxford
Parks Road, Oxford OX1 3QD, United Kingdom

Abstract
Answering conjunctive queries (CQs) set facts extended existential rules
prominent problem knowledge representation databases. problem
solved using chase algorithm, extends given set facts fresh facts
order satisfy rules. chase terminates, CQs evaluated directly
resulting set facts. chase, however, terminate necessarily, checking
whether chase terminates given set rules facts undecidable. Numerous
acyclicity notions proposed sufficient conditions chase termination.
paper, present two new acyclicity notions called model-faithful acyclicity (MFA)
model-summarising acyclicity (MSA). Furthermore, investigate landscape
known acyclicity notions establish complete taxonomy notions known us.
Finally, show MFA MSA generalise notions.
Existential rules closely related Horn fragments OWL 2 ontology
language; furthermore, several prominent OWL 2 reasoners implement CQ answering
using chase materialise relevant facts. order avoid termination problems,
many systems handle OWL 2 RL profile OWL 2; furthermore,
systems go beyond OWL 2 RL, without termination guarantees. paper
also investigate whether various acyclicity notions provide principled practical
solution problems. theoretical side, show query answering
acyclic ontologies lower complexity general ontologies. practical
side, show many commonly used OWL 2 ontologies MSA,
number facts obtained materialisation large. results thus suggest
principled development materialisation-based OWL 2 reasoners practically feasible.

1. Introduction
Existential rules first-order implications conjunctions function-free atoms
may contain existentially quantified variables implications consequent (Baget,
Leclere, Mugnier, & Salvat, 2011a; Cal, Gottlob, Lukasiewicz, Marnette, & Pieris, 2010a).
rules used variety ways databases, knowledge representation, logic
programming. database theory, existential rules known tuple-generating dependencies (Abiteboul, Hull, & Vianu, 1995) used capture wide range schema

c
2013
AI Access Foundation. rights reserved.

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

constraints. Furthermore, also used declarative data transformation rules
data exchangethe process transforming database structured according source
schema database structured according target schema (Fagin, Kolaitis, Miller, &
Popa, 2005). Existential rules also provide foundation several prominent knowledge
representation formalisms, Datalog (Cal, Gottlob, & Pieris, 2010b; Cal et al.,
2010a), also closely related logic programs function symbols
head. Practical applications existential rules range bioinformatics (Mungall, 2009)
modelling complex structures chemical compounds (Magka, Motik, & Horrocks, 2012;
Hastings, Magka, Batchelor, Duan, Stevens, Ennis, & Steinbeck, 2012).
Answering conjunctive queries (CQs) set facts extended existential rules
fundamental, yet undecidable (Beeri & Vardi, 1981) reasoning problem existential rules.
problem characterised using chase (Johnson & Klug, 1984; Maier, Mendelzon,
& Sagiv, 1979)a technique closely related hypertableau calculus (Motik, Shearer, &
Horrocks, 2009b; Baumgartner, Furbach, & Niemela, 1996). forward-chaining manner,
chase extends original set facts facts derived using rules.
result chase universal model, sense arbitrary CQ
original facts rules answered evaluating query model.
1.1 Chase Termination Acyclicity Notions
Rules existentially quantified variables headso-called generating rulesrequire
introduction fresh individuals. Cyclic applications generating rules may prevent
chase terminating, fact determining whether chase terminates set
rules facts undecidable (Deutsch, Nash, & Remmel, 2008). However, several decidable
classes existential rules identified, existing proposals classified
two main groups. first group, rules restricted possibly infinite
universal models represented using finitary means. group includes rules
universal models bounded treewidth (Baget et al., 2011a), guarded rules (Cal et al.,
2010a), sticky rules (Cal, Gottlob, & Pieris, 2011). second group, one uses
sufficient (but necessary) acyclicity notion ensures chase termination.
Roughly speaking, acyclicity notions analyse information flow rules ensure cyclic applications generating rules possible. Weak acyclicity (WA)
(Fagin et al., 2005) one first notions, extended notions
safety (Meier, Schmidt, & Lausen, 2009), stratification (Deutsch et al., 2008), acyclicity
graph rule dependencies (aGRD) (Baget, Mugnier, & Thomazo, 2011b), joint acyclicity (JA) (Krotzsch & Rudolph, 2011), super-weak acyclicity (SWA) (Marnette, 2009).
Syntactic acyclicity criteria also investigated context logic programs
function symbols rule heads, goal recognise logic programs
finite stable models. Several notions implemented state art logic
programming engines, omega-restrictedness (Syrjanen, 2001) Smodels system (Syrjanen & Niemela, 2001), lambda-restrictedness ASP grounder GrinGo
(Gebser, Schaub, & Thiele, 2007), argument-restrictedness (Lierler & Lifschitz, 2009)
DLV system (Leone, Pfeifer, Faber, Eiter, Gottlob, Perri, & Scarcello, 2006), many
others (Calimeri, Cozza, Ianni, & Leone, 2008; Greco, Spezzano, & Trubitsyna, 2012; De
Schreye & Decorte, 1994).

742

fiAcyclicity Notions Existential Rules

1.2 Applications Acyclicity Notions
Acyclicity notions interesting several reasons. First, unlike guarded rules, acyclic
rules axiomatise structures arbitrary shapes, long structures bounded
size. Second, result chase acyclic rules stored manipulated
database; important, example, data exchange, goal
materialise transformed database.
paper, argue acyclicity notions also relevant description logics (DLs)knowledge representation formalisms underpinning OWL 2 ontology
language (Cuenca Grau, Horrocks, Motik, Parsia, Patel-Schneider, & Sattler, 2008). CQ
answering DL ontologies key reasoning service many DL applications,
problem studied numerous different DLs (Calvanese, De Giacomo, Lembo, Lenzerini,
& Rosati, 2007; Krotzsch, Rudolph, & Hitzler, 2007; Glimm, Horrocks, Lutz, & Sattler,
2008; Ortiz, Calvanese, & Eiter, 2008; Lutz, Toman, & Wolter, 2009; Perez-Urbina, Motik,
& Horrocks, 2009; Rudolph & Glimm, 2010; Kontchakov, Lutz, Toman, Wolter, & Zakharyaschev, 2011). Answering CQs ontologies, however, quite technical often
high computational complexity. Therefore, practical OWL 2 reasoners frequently solve
problem using materialisationa reasoning technique relevant consequences
ontology precomputed using chase, allowing queries directly evaluated
materialised set facts. Examples materialisation-based systems include Oracles
Semantic Data Store (Wu, Eadon, Das, Chong, Kolovski, Annamalai, & Srinivasan, 2008),
Sesame (Broekstra, Kampman, & van Harmelen, 2002), OWLIM (Kiryakov, Ognyanov, &
Manov, 2005), Jena (Carroll, Dickinson, Dollin, Reynolds, Seaborne, & Wilkinson, 2004),
DLE-Jena (Meditskos & Bassiliades, 2008). reasoning possible (i) ontology
Horn (Hustadt, Motik, & Sattler, 2005) thus require disjunctive reasoning,
(ii) chase guaranteed terminate. satisfy second assumption, reasoners
often consider axioms OWL 2 RL profile (Motik, Cuenca Grau, Horrocks, Wu,
Fokoue, & Lutz, 2009a); systematically excludes generating rules thus trivially
ensures chase termination, also makes approach incomplete. Generating rules
partially supported systems OWLim (Bishop & Bojanov, 2011) Jena,
support typically ad hoc provides completeness and/or termination guarantees. Acyclicity notions used address issues: ontology Horn
acyclic, complete materialisation computed without risk non-termination.
1.3 Contributions
Motivated practical importance chase termination, paper present two
new acyclicity notions: model-faithful acyclicity (MFA) model-summarising acyclicity
(MSA). Roughly speaking, acyclicity notions use particular model rules
analyse implications existential quantifiers, call model
based. particular, MFA uses actual canonical model induced facts
rules, makes notion general. prove checking whether set
existential rules MFA 2ExpTime-complete, becomes ExpTime-complete
predicates rules bounded arity. Due high complexity, MFA may
unsuitable practical application. Thus, introduce MSA, understood
MFA analysis performed models summarise (or overestimate)
743

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

actual models. Checking MSA existential rules realised via checking entailment
ground atoms datalog programs. use close connection MSA datalog
prove checking MSA ExpTime-complete general existential rules,
becomes coNP-complete arity rule predicates bounded.
next conduct detailed investigation landscape known acyclicity notions,
augmented MFA MSA. class logic programs correspond existential rules skolemised existential quantifiers, show MSA MFA strictly
subsume existing acyclicity notions known logic programming. also show
MSA strictly general SWAone general acyclicity notions known
database theory. Furthermore, investigate relationship known notions
thus complete picture respect relative expressiveness.
MSA MFA applied general existential rules without equality. Equality incorporated via singularisationa technique proposed Marnette (2009)
transforms rules encode effects equality. Singularisation orthogonal
acyclicity: computing transformed rules, one use MFA, MSA, fact
notion check whether result acyclic; so, chase signularised rules terminates, chase result used particular way answer arbitrary CQs.
Unfortunately, singularisation nondeterministic: ways transforming rules
may produce acyclic rule sets, ways guaranteed so. paper,
refine singularisation obtain practically useful upper lower bounds acyclicity.
also show that, used JA, lower bound actually coincides WA.
next turn attention theoretical practical issues using acyclicity
materialisation-based CQ answering ontologies. theoretical side, show
checking MFA MSA Horn-SROIF ontologies ExpTime- PTime-complete,
respectively, answering CQs acyclic Horn-SROIF ontologies ExpTimecomplete well. Furthermore, show that, Horn-SHIF ontologies, complexity
checking MFA answering CQs drops PSpace. Answering CQs ExpTimecomplete general (i.e., acyclic) Horn-SHIF ontologies (Eiter, Gottlob, Ortiz, &
Simkus, 2008; Ortiz, Rudolph, & Simkus, 2011), acyclicity makes problem easier.
Furthermore, Horn ontologies extended arbitrary SWRL rules (Horrocks &
Patel-Schneider, 2004) without affecting decidability worst-case complexity, provided
union ontology SWRL rules acyclic; contrast general
case, SWRL extensions DLs easily lead undecidability.
practical side, explore limits reasoning acyclic OWL 2 ontologies
via materialisation. checked MFA, MSA, JA 336 Horn ontologies; furthermore,
estimate impact materialisation, compared size materialisation
number facts original ontologies. experiments revealed many
ontologies MSA, complex ones MSA JA; furthermore,
universal models obtained via materialisation typically large. Thus, results
suggest principled, materialisation-based reasoning ontologies beyond OWL 2
RL profile may practically feasible.
extended version paper Cuenca Grau, Horrocks, Krotzsch, Kupke,
Magka, Motik, Wang (2012) published KR 2012.

744

fiAcyclicity Notions Existential Rules

2. Preliminaries
section introduce definitions notation used rest paper.
2.1 First-Order Logic
use standard notions constants, function symbols, predicate symbols,
equality predicate, > universal truth, universal falsehood. function
predicate symbol associated nonnegative integer arity. Variables, terms, substitutions, atoms, first-order formulae, sentences, interpretations (i.e., structures), models
defined usual. slight abuse notation, often identify conjunction
set conjuncts. Furthermore, often abbreviate vector terms t1 , . . . , tn ~t;
define |~t| = n; often identify ~t set indexed terms {t1 , . . . , tn }.
(~x) stress ~x = x1 , . . . , xn free variables formula ,
denote result applying substitution . term, atom, formula ground
contain variables; fact ground atom. depth dep(t) term defined
0 constant variable, dep(t) = 1 + maxni=1 dep(ti ) = f (t1 , . . . , tn ).
term t0 subterm term t0 = = f (~s) t0 subterm si ~s;
additionally t0 6= t, t0 proper subterm t. term contained atom P (~t)
~t, occurs P (~t) subterm term ti ~t; thus, contained
P (~t), also occurs P (~t), converse may hold. term contained
(resp. occurs) set atoms contained (resp. occurs) atom I.
first-order logic, equality predicate commonly assumed predefined
interpretationthat is, every first-order interpretation required interpret
smallest reflexive relation domain. Satisfaction sentence interpretation
interpreted way written |= , entailment sentence
sentence written |= . Unless otherwise stated, use standard interpretation
equality throughout paper.
Equality, however, also treated ordinary predicate explicit axiomatisation. Let arbitrary set function-free first-order formulae. Then, =
occur ; otherwise, contains formulae (1)(3) instance formula (4)
n-ary predicate P occurring different , 1 n. Note
variables formulae (implicitly) universally quantified.
xx

(1)

x1 x2 x2 x1

(2)

x1 x2 x2 x3 x1 x3

(3)

P (x1 , . . . , xi , . . . , xn ) xi

x0i



P (x1 , . . . , x0i , . . . , xn )

(4)

treated ordinary predicate, satisfaction formula model written
|= , entailment formula formula written |= . Please note that,
according definitions, |= hold even interpretation interprets predicate
arbitrary way; contrast, |= hold interpretation interprets predicate
identity relation models domain. consequences w.r.t. |=
w.r.t. |= coincidethat is, first-order sentence constructed using
symbols , |= |= .
745

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

2.2 Rules Queries
instance finite set function-free facts. existential rule (or rule)
function-free sentence form
~x~z.[(~x, ~z) ~y .(~x, ~y )]

(5)

(~x, ~z) (~x, ~y ) conjunctions atoms, tuples variables ~x, ~y , ~z
pairwise disjoint. Formula body formula head rule. brevity,
quantifiers ~x~z often omitted. convenience, sometimes identify rule body
head set respective conjuncts. datalog rule rule ~y empty.
rule equality-free contain equality predicate . term occurs
existential rule occurs head body atom rule, definitions
extended set rules obvious way; existential rules contain function
symbols, analogous notion contained rule coincides one. Two
variables directly connected rule occur together body atom rule;
furthermore, connected transitive closure directly connected ; finally, rule
form (5) connected pairs variables w, w0 ~x ~z connected rule.
conjunctive query (CQ) formula form Q(~x) = ~y .(~x, ~y ), (~x, ~y )
conjunction atoms; query Boolean ~x empty. substitution mapping ~x
constants answer Q(~x) w.r.t. set rules instance |= Q(~x).
Answering CQs core reasoning problem many applications existential rules.
answering conjunctive query Q(~x) set rules instance I,
rest paper implicitly assume Q(~x) contain predicates
. simplifies presentation since allows us define various transformations
without take account possible predicates occur Q(~x) only.
assumption w.l.o.g., always extend tautological rules form
P (~x) P (~x) predicate P occurring Q(~x) .
Furthermore, assume occur body rule
query Q(~x). w.l.o.g. since eliminate atom form x rule body
replace x rest rule; furthermore, eliminate body atoms
form b b constants, introduce fresh predicate Oa , add new rule
Oa (a), replace body atom b conjunction Oa (x) x b x fresh
variable, finally eliminate atom x b before. Similarly, provide explicit
support inequality predicate 6. Inequality rule heads simulated using
ordinary predicate: atom form 6 occurring rule head replaced
NotEqual(s, t), NotEqual fresh ordinary predicate explicitly axiomatised
irreflexive; note that, handled regular predicate explicitly axiomatised rules
(1)(4), replacement axioms (4) must instantiated P = NotEqual well.
contrast, atoms involving inequality predicate occurring rule bodies generally require
disjunctive reasoning, supported existential rules.
Finally, assume conjunctions (~x, ~z) (~x, ~y ) rule form (5)
empty. also assume > treated ordinary unary predicates,
semantics > captured explicitly instantiating following rule
n-ary predicate P occurring :
P (x1 , . . . , xn ) >(x1 ) . . . >(xn )
746

(6)

fiAcyclicity Notions Existential Rules

assumptions ensure always satisfiable, |= y.(y)
unsatisfiable w.r.t. conventional treatment > . allowing
body atoms form >(x), without loss generality require existential
rule safe (i.e., universally quantified variable occurring head atom also
occurs body atom rule), greatly simplifies many definitions.
database theory, satisfaction entailment often considered w.r.t. finite
interpretations unique name assumption (UNA); latter ensures distinct
constants interpreted distinct elements. contrast, assumptions customary ontology-based KR. paper, assume UNA, UNA
axiomatised explicitly needed using inequality predicate (or simulation thereof).
Furthermore, paper investigate theories satisfiable finite models (i.e.,
chase finite); thus, difference finite infinite satisfiability
immaterial results.
frequently use skolemisation interpret rules Herbrand interpretations,
defined possibly infinite sets ground atoms. particular, rule r
form (5) variable yi ~y , let fri function symbol globally unique r yi
arity |~x|; furthermore, let sk substitution sk (yi ) = fri (~x) yi ~y .
Then, skolemisation sk(r) r following rule:
(~x, ~z) (~x, ~y )sk

(7)

skolemisation sk() set rules obtained skolemising rule .
Skolemisation affect answers CQsthat is, conjunctive query Q(~x)
formed predicates , instance I, substitution ,
|= Q(~x) sk() |= Q(~x).
2.3 Skolem Chase
Answering CQs characterised using chase, paper use skolem chase
variant (Marnette, 2009). Let r = skolemised rule let set ground
atoms. set ground atoms consequence r substitution exists mapping
variables r terms occurring . result
applying r I, written
r(I), union consequences r I. set
skolemised rules, (I) = r r(I). Let finite set ground atoms, let set
rules, let 0 = sk() , let 0f 0n subsets 0 containing rules
without function symbols, respectively. chase sequence sequence
sets facts I0 , I1 , . . . I0 = and, > 0, set Ii defined follows:
0n (Ii1 ) 6 Ii1 , Ii = Ii1 0n (Ii1 ),
otherwise Ii = Ii1 0f (Ii1 ).

chase defined = Ii ; note infinite. chase
used database answering CQs: substitution answer Q
|= Q. chase terminates 0 exists Ii = Ij
j i; chase terminates universally chase terminates
I. skolem chase terminates, nonoblivious chase (Fagin
et al., 2005) core chase (Deutsch et al., 2008) terminate well.
747

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

critical instance set rules contains facts constructed
using predicates occurring , constants occurring body rule ,
one special fresh constant . skolem chase terminates
skolem chase terminates universally (Marnette, 2009).
2.4 Acyclicity Notions
Checking whether skolem chase terminates given instance undecidable,
checking universal skolem chase termination conjectured undecidable well. Consequently, various sufficient acyclicity notions proposed literature. Formally, acyclicity notion X class finite sets rules; definition allows us
talk (proper) containment acyclicity notions. sometimes write
X, mean X. next introduce weak joint acyclicity: former
one first notions considered literature; show Section 3,
latter notion relatively powerful, yet still easy understand. use two notions
throughout paper present examples state various technical claims. Section 3
present definitions many acyclicity notions known literature.
following, let set rules variable occurs one rule.
position expression form P |i P n-ary predicate integer
1 n. Given rule r form (5) variable w occurring r, set PosB (w)
body positions w contains position P |i P (t1 , . . . , tn ) (~x, ~z) ti = w
vector ~t terms. set PosH (w) head positions defined analogously,
w.r.t. head atoms r. Note that, since variable occurs one rule
, sets PosB (w) PosH (w) (indirectly) associated rule contains w.
rest paper, whenever use notation PosH (w) PosB (w), silently
assume variable occurs one rule notation unambiguous.
clearly w.l.o.g. one always arbitrarily rename variables different rules.
Weak acyclicity (WA) (Fagin et al., 2005) applied existential rules contain
equality predicate. WA dependency graph WA() contains positions
vertices; furthermore, rule r form (5), variable x ~x, position
P |i PosB (x), variable ~y , graph WA() contains
regular edge P |i Q|j PosH (x) Q 6= and,
special edge P |i Q|j PosH (y) Q 6= .
Set WA WA() contain cycle involves special edge. Equality atoms
effectively ignored WA.
Joint acyclicity (JA) (Krotzsch & Rudolph, 2011) generalises WA, applicable
equality-free rules. existentially quantified variable , let Move(y)
smallest set positions
PosH (y) Move(y),
existential rule r universally quantified variable x occurring
r, PosB (x) Move(y), PosH (x) Move(y).

748

fiAcyclicity Notions Existential Rules

JA dependency graph JA() defined follows. vertices JA()
existentially quantified variables occurring . Given arbitrary two variables y1
y2 , JA dependency graph JA() contains edge y1 y2 whenever rule
contains y2 also contains universally quantified variable x PosH (x) 6=
PosB (x) Move(y1 ). Set JA JA() contain cycle.
2.5 Rule Normalisation
Existential rules often transformed existential rules replacing parts
rule head body atoms involving fresh predicates. transformation
called normalisation, often used preprocessing step bring rules
suitable form. example, Horn OWL 2 axioms translated existential rules
using well known transformations first-order logic, latter
normalised form describe Section 6. section introduce definition
rule normalisation captures similar methods known us.
Let r rule form (8), 1 , 2 , 1 , 2 conjunctions atoms
satisfying ~x1 ~x2 = ~x3 ~x4 , ~z2 ~z3 = , ~y2 ~y3 = .
1 (~x1 , ~z1 , ~z2 ) 2 (~x2 , ~z1 , ~z3 ) ~y1 , ~y2 , ~y3 .[1 (~x3 , ~y1 , ~y2 ) 2 (~x4 , ~y1 , ~y3 )]

(8)

normalisation step replaces conjunction either head body rule
atom involving fresh predicate. precisely, head normalisation step replaces
1 (~x3 , ~y1 , ~y2 ) atom Q(~x3 , ~y1 ) Q fresh predicate, thus replacing r rule
(9), adds rule (10).
1 (~x1 , ~z1 , ~z2 ) 2 (~x2 , ~z1 , ~z3 ) ~y1 , ~y3 .[Q(~x3 , ~y1 ) 2 (~x4 , ~y1 , ~y3 )]
Q(~x3 , ~y1 ) ~y2 .1 (~x3 , ~y1 , ~y2 )

(9)
(10)

Alternatively, body normalisation step replaces 1 (~x1 , ~z1 , ~z2 ) atom Q(~x1 , ~z1 )
Q fresh predicate, thus replacing r rule (11), adds rule (12).
Q(~x1 , ~z1 ) 2 (~x2 , ~z1 , ~z3 ) ~y1 , ~y2 , ~y3 .[1 (~x3 , ~y1 , ~y2 ) 2 (~x4 , ~y1 , ~y3 )]
1 (~x1 , ~z1 , ~z2 ) Q(~x1 , ~z1 )

(11)
(12)

Given set existential rules , normalisation steps often applied iteratively.
predicate Q introduced step always fresh, call normalisation without
structure sharing. contrast, normalisation structure sharing allows predicate
Q reused across different normalisation steps. example, predicate Q
introduced head normalisation step replace 1 (~x1 , ~z1 , ~z2 ), conjunction
form 1 (~x01 , ~z10 , ~z20 ) ~x01 , ~z10 , ~z20 renamings ~x1 , ~z1 , ~z2 replaced Q(~x03 , ~y10 )
without introducing corresponding rule (10). analogous optimisation used
body normalisation step.
Let 0 set rules obtained via normalisation (with without structure sharing)
. well known 0 conservative extension . Consequently,
instance BCQ Q use freshly introduced predicates,
|= Q 0 |= Q.

749

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

3. Novel Acyclicity Notions
Weak acyclicity considerably influenced field data exchange databases,
rather strict notion may sufficient many applications existential
rules. Joint acyclicity significantly relaxes weak acyclicity developed mainly
rule based knowledge representation applications.
Section 3.1 show even joint acyclicityone general acyclicity
notions developed fardoes capture rules corresponding axioms commonly found
ontologies chase terminates universally. address important limitation, propose Section 3.2 model-faithful acyclicity (MFA)a novel, general,
notion used successfully ensure chase termination many ontologies used
practice. computational cost checking MFA is, however, rather high; hence,
Section 3.3 introduce model-summarising acyclicity (MSA)a strict notion
easier check produces results MFA existing ontologies.
3.1 Limitations Existing Acyclicity Notions
motivate new acyclicity notions, first present example shows known
acyclicity notions, JA, satisfied rules equivalent simple
axioms abound OWL ontologies.
Example 1. Let set rules (13)(17).
A(x1 ) y1 .R(x1 , y1 ) B(y1 )

r1 =
r2 =

R(x2 , z1 ) B(z1 ) A(x2 )

(13)
(14)

r3 =

B(x3 ) y2 .R(x3 , y2 ) C(y2 )

(15)

r4 =

C(x4 ) D(x4 )

(16)

r5 =

R(x5 , z2 ) D(z2 ) B(x5 )

(17)

Rules r1 r2 correspond description logic axiom R.B, rule r3 corresponds
axiom B v R.C, rule r4 corresponds axiom C v D, rule r5 corresponds axiom
R.D v B. axioms common OWL ontologies.
definition JA Section 2, Move(y1 ) = {R|2 , B|1 , R|1 , A|1 }. Thus,
JA dependency graph contains edge y1 itself, set axioms
JA. contrast, following table shows chase sequence .
A()

R(, f ())

R(f (), g(f ()))

B()

B(f ())

C(g(f ()))

C()

R(, g())

D(g())

D()

C(g())

D(g(f ()))

R(, )
Rule r2 applicable R(f (), g(f ())) since I3 contain fact B(g(f ()))
necessary match atom B(z1 ) rule. Thus, chase terminates.

existing acyclicity notions essentially try estimate whether application
rule produce facts (possibly applying chase rules) repeatedly
750

fiAcyclicity Notions Existential Rules

trigger rule infinite manner. key difference various notions
rule applicability determined. particular, JA considers variable rule
isolation check satisfaction body atoms once; example, rule (14)
applicable facts generated rule (15), determined
considering variables x2 z1 rule (14) simultaneously. notions thus overestimate
rule applicability and, result, fail detect chase termination.
3.2 Model-Faithful Acyclicity (MFA)
main intuition addressing problem precise chase termination
guarantees obtained tracking rule applicability faithfully. simple solution
completely precise rule applicability: one run skolem chase
use sufficient checks identify cyclic computations. Since sufficient, necessary,
computable test given latter, must adopt practical approach.
example, raise alarm stop process chase derives cyclic term
f (~t), f occurs ~t. idea refined; example, one could stop
f occurs nested term fixed number times. choice appropriate test
thus depends application; however, experiments show, checking one
level nesting suffices many cases. particular, term f (~t) f occurring ~t
generated chase set rules Example 1.
Definition 2. term cyclic function symbol f exists term f (~s)
subterm t, term f (~u) proper subterm f (~s).
notion acyclicity declarative: given set rules transformed new
set rules 0 tracks rule dependencies using fresh predicates; then, identified
acyclic 0 entail special nullary predicate C. Since acyclicity defined
via entailment, decided using theorem proving procedure existential rules
sound complete. Acyclicity guarantees termination skolem chase,
also guarantees termination nonoblivious chase core chase. call notion modelfaithful acyclicity estimates rule application precisely, examining actual
structure universal model .
Definition 3. rule r = (~x, ~z) ~y .(~x, ~y ) variable yi ~y , let Fir
fresh unary predicate unique r yi ; furthermore, let fresh binary predicates,
let C fresh nullary predicate. Then, MFA(r) following rule:



^
^
Fir (yi )
(~x, ~z) ~y . (~x, ~y )
S(xj , yi )
yi ~


xj ~
x

set rules, MFA() smallest set contains MFA(r) rule r ,
rules (18)(19), rule (20) instantiated Fir corresponding r :

Fir (x1 )

S(x1 , x2 ) D(x1 , x2 )

(18)

D(x1 , x2 ) S(x2 , x3 ) D(x1 , x3 )

(19)

Fir (x2 )

(20)

D(x1 , x2 )

751

C

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

set model-faithful acyclic (MFA) w.r.t. instance MFA() 6|= C; furthermore, universally MFA1 MFA w.r.t. .
Example 4. Let set rules Example 1. Then, MFA(r1 ) MFA(r3 )
given (21) (22), respectively; since r1 r3 contain single existentially quantified variable each, omit superscripts Fr1 Fr3 sake clarity. Thus,
MFA() consists rules (14), (16), (17), rules (21)(22), rules (18)(19), rule
(20) instantiated Fr1 Fr3 .
A(x1 ) y1 .R(x1 , y1 ) B(y1 ) Fr1 (y1 ) S(x1 , y1 )

(21)

B(x3 ) y2 .R(x3 , y2 ) C(y2 ) Fr3 (y2 ) S(x3 , y2 )

(22)

straightforward see chase MFA() consists facts presented
Example 1, augmented following facts:
S(, f ())

D(, f ())

D(f (), g(f ()))

S(, g())

D(, g())

D(, g(f ()))

Fr1 (f ())

S(f (), g(f ()))

Fr3 (g())

Fr3 (g(f ()))

chase MFA() contain C, implies MFA() 6|= C.
result, universally MFA.

MFA formulated semantic, rather syntactic notion, thus mainly
independent algorithmic details: entailment MFA() 6|= C checked using
arbitrary sound complete first-order calculus. Section 4 discuss relationship
MFA existing notions, show MFA generalises them.
following proposition shows MFA characterises derivations skolem
chase cyclic terms occur.

Proposition 5. set rules MFA w.r.t. instance IMFA()
contains cyclic term.

Proof. Let 0 = MFA(), let I0 0 , I1 0 , . . . chase sequence 0 . Moreover,
let fri function symbol used skolemise i-th existentially quantified variable
rule r, defined Section 2.2. next prove following claims hold terms
t0 occurring Ik 0 , rule r, integer i, integer k, well k = .
1. Term form fri (~u) Fir (t) Ik 0 .
2. Term form fri (~u) t0 ~u S(t0 , t) Ik 0 .
0

3. t0 proper subterm t, D(t0 , t) Ik+2
0 ; furthermore, D(t , t) I0
0
proper subterm t.

1. rest paper often omit universally; furthermore, used acyclicity notion,
MFA means universally MFA.

752

fiAcyclicity Notions Existential Rules

(Claims 1 2, direction ) proof induction k. Set I0 0 contain
functional terms, clearly satisfies claims. induction step, assume
claims hold Ik1
consider Ik 0 . Since Ik1
Ik 0 , claims clearly hold
0
0
k1
term occurs I0 . Consider arbitrary term form fri (~u)
0
occur Ik1
u. Clearly, introduced Ik 0
0 , arbitrary term ~
application skolemisation MFA(r) rule r . Since head MFA(r)
contains atoms Fir (yi ) S(xj , yi ) xj ~x, Fir (t) Ik 0 S(t0 , t) Ik 0
t0 S~u, Fir (t) I0 S(t0 , t) I0 t0 ~u well. Finally,
since I0 = k Ik 0 , claims clearly hold k = .
(Claims 1 2, direction ) Predicate predicate Fir occur 0 head
atoms form Fir (yi ) S(xj , yi ); hence, skolemised rules contain predicates
head atoms form Fir (fri (~x)) S(xj , fri (~x)), clearly implies claim.
(Claim 3, first part k 6= ) proof induction k. base case holds
vacuously since I0 0 contain functional terms. Assume claim holds
k 1, consider arbitrary term = fri (~u) occurring Ik 0 t0
subterm ti ~u. Claim 2, S(ti , t) Ik 0 ; furthermore, ti occurs
k+1
0
Ik1
0 , induction assumption D(t , ti ) I0 . Finally, rules without
functional terms applied rules functional terms; hence, rule (19)
D(t0 , t) Ik+2
0 , required.
(Claim 3, second part) proper subterm relation transitive, rules (18)
(19) effectively define transitive closure S, clearly implies claim.
Assume I0 contains cyclic term t. Then, term t1 = fri (~s) subterm
term t2 = fri (~u) proper subterm t1 . Claims 1 3,
{Fir (t2 ), D(t2 , t1 ), Fir (t1 )} I0 . then, since 0 contains rule (20), C I0 ,
MFA. converse claim, assume MFA w.r.t. instance I.
Then, Definition 3 MFA() |= C. Since special nullary predicate C
occurs right-hand side rule (20), exist terms t1 t2 , rule r ,
predicate Fir {Fir (t1 ), D(t1 , t2 ), Fir (t2 )} I0 . Since Fir (t1 ) Fir (t2 )
contained I0 , Claim 1 implies t1 t2 form t1 = fri (u~1 ) t2 = fri (u~2 ),
respectively. Finally, D(t1 , t2 ) I0 Claim 3 imply t1 proper subterm t2 ,
I0 contains cyclic term.
characterisation implies termination skolem chase MFA rules 2ExpTime.
particular, term derived skolem chase 0 = MFA() cannot cyclic
Proposition 5; seen tree branching factor bounded
maximum arity function symbol sk(0 ) depth bounded number
function symbols sk(0 ). chase thus generate doubly exponential
number different terms atoms. 2ExpTime bound already holds rules
WA (Cal et al., 2010b), CQ answering MFA rules harder WA rules.
Proposition 6. set rules MFA w.r.t. instance I, skolem chase
terminates double exponential time.
Proof. Let 0 = MFA(), let c, f , p number constants, function symbols,
predicate symbols, respectively, occurring sk(0 ), let ` maximum arity
function symbol, let maximum arity predicate symbol sk(0 ). Consider
753

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

arbitrary term occurring I0 ; clearly, seen tree branching
factor ` containing constants leaf nodes function symbols internal nodes;
furthermore, since cyclic, dep(t) f , number leaves bounded `f ,
total number nodes bounded f `f . node assigned constant function
f
symbol, number different terms occurring I0 bounded = (c + f )f ` ,
number different atoms I0 bounded p , clearly doubly
exponential I. Consequently, size I0 doubly exponential
I. Furthermore, arbitrary set facts 0 rule r, set r(I 0 ) computed
examining mappings variables r terms occurring 0 , requires
exponential time size r polynomial time size 0 . Consequently, I0
computed time double exponential . Finally, straightforward
see I0 , computed double exponential time well.
Proposition 6, answering BCQ MFA rules 2ExpTime. next prove
checking MFA w.r.t. specific instance also 2ExpTime, checking universal MFA 2ExpTime-hard. provides tight complexity bounds problems.
Towards goal, first establish Lemma 7 relationship answering certain
kinds queries certain kinds rules checking whether related set rules
universally MFA; use relationship several hardness proofs rest paper.
Then, Theorem 8 present main complexity result.
Lemma 7. Let set weakly acyclic, constant-free, equality-free, connected rules
predicates nonzero arity, let B unary predicates, let R fresh binary
predicate, let constant, let extended rule (23).
R(z, x) B(x) y.[R(x, y) A(y)]

(23)

Then, {A(a)} 6|= B(a) universally MFA.
Proof. Let = {A(a)}, let I0 , I1 , . . . chase sequence . Furthermore,
let 0 = MFA(), let J = , let J0 0 , J1 0 , . . . chase sequence J 0 , let
f function symbol used skolemise existential quantifier rule (23). Set
constant-free, constant occurring set Ii .
next show facts Jj 0 certain form. end, ` 0,
let t` = f (. . . f () . . .) function symbol f repeated ` times (by definition,
t0 = ); also, term fact obtained t` zero applications
predicates function symbols {f, D, S, C, R} level `. induction chase
sequence J 0 , next prove sequence satisfies following property ():
fact F Jj 0 , integer ` exists F form R(, )
R(t` , t`+1 ), predicate F contained {D, S, C}, F `-level
fact predicate F contained {D, S, C, R}.
Set J0 0 = J clearly satisfies property () since fact clearly level 0. assume
Jj 0 satisfies property () j, consider application rule r 0 . r
corresponds rule (18), (19), (20), (23), result rule application clearly
satisfies property (). Otherwise, r safe body atom contains predicate
754

fiAcyclicity Notions Existential Rules

{D, S, C, R}; induction assumption, atom matched fact level `;
body atoms r connected, body atoms matched facts level;
finally, head atoms r contain function symbols different f , constants
predicates zero arity, fact derived atom head r either contains
predicate level `.
next show chase sequences , J 0 related
following property ():
fact F 0 level 1 fact F obtained replacing t1 F 0
a, F Ii F 0 Jj 0 \ J j.
proof () straightforward: J contains R(, ) B(), J1 0 contains R(, f ())
A(f ()); moreover, due (), term t1 plays chase sequence J 0
role constant chase sequence , rule applications facts
level 1 former chase sequence correspond one-to-one rule applications
latter chase sequence. omit formal details sake brevity.
assume {A(a)} |= B(a). Then, B(a) Ii holds i. property
(), integer j exists B(f ()) Jj 0 . then, due rule (23), ` j
exists A(f (f ())) J` 0 . Proposition 5, universally MFA.
Conversely, assume {A(a)} 6|= B(a). Since weakly acyclic equalityfree, super-weakly acyclic (Marnette, 2009); show Section 4 (see Theorem
19), MFA well. consider arbitrary integer j fact F Jj 0 . F
level 0 1, since MFA, fact F contain cyclic term. Furthermore,
B(a) 6 so, property (), fact F form B(f ()); thus, rule (23)
fire introduce facts level greater 1. Consequently, F contain cyclic
term, so, Proposition 5, set universally MFA.
Theorem 8. Given set rules , deciding whether MFA w.r.t. instance
2ExpTime, deciding whether universally MFA 2ExpTime-hard. results
hold even arity predicates bounded.
Proof. (Membership) Let 0 = MFA(), let I0 0 , I1 0 , . . . chase sequence 0 ,
let , p, stated proof Proposition 6. number different
atoms constructed terms bounded k = p ; note
double exponential even bounded. Let k 0 = k + 4; next show whether
0
0
MFA w.r.t. decided constructing Ik 0 checking whether C Ik 0 .
proof Proposition 6, latter done double exponential time.
0
Ik 0 = Ik 0 , I0 = Ik 0 , MFA C Ik 0 . Otherwise,
0
Ik 0 ( Ik 0 ; then, Ik+1
clearly contains least one cyclic term = fri (~t)
0
t0 = fri (~s) subterm ti ~t. Since Ik+1
satisfies Claims 13 proof
0
k+3
Proposition 5, D(ti , t) I0 ; rule (20) fact rules without functional
0
terms applied rules functional terms, C Ik 0 ; thus, C I0 ,
MFA Proposition 5.
(Hardness) prove claim reduction problem checking |= Q,
weakly acyclic set equality-free rules predicates bounded arity,

755

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

instance, Q = ~y .(~y ) Boolean conjunctive query. Cal et al. (2010b) show
that, I, , Q, deciding |= Q 2ExpTime-complete. next transform
I, , Q apply Lemma 7, proves claim.
Let 1 = {(~y ) B} B fresh predicate zero arity; clearly, |= Q
holds 1 |= B holds.
Let 2 I2 obtained eliminating constants rules 1 ; is,
initially set I2 = then, rule r constant c occurring r,
replace occurrences c fresh variable wc , add atom Oc (wc ) body r
Oc fresh predicate uniquely associated c, add fact Oc (c) I2 .
straightforward see 1 |= B I2 2 |= B.
Finally, transform 2 I2 3 , define notation. Let P fresh n+1ary predicate unique n-ary predicate PV
, let w fresh variable occurring
2 . conjunction atoms , let = P (~t) P (~t, w). Rule (24) obtained
I2 specified below, fresh unary predicate, constant c occurring I2
associated distinct, fresh variable vc , ~vc vector variables:
^
A(w) ~vc .
P (vc1 , . . . , vck , w)
(24)
P (c1 ,...,ck )I2

Finally, set 3 contains rule (24) rule
(~x, ~z, w) ~y .(~x, ~y , w)

rule

(~x, ~z) ~y .(~x, ~y ) 2 .

(25)

Clearly, predicates 3 nonzero arity; rules 3 constant-free
connected; occurs body rule (24) 2 WA, 3 WA well.
Finally, let I3 = {A(a)} fresh constant; induction chase sequences
2 I2 , 3 I3 , straightforward show that, integer fact
P (c1 , . . . , ck ), P (c1 , . . . , ck ) (I2 )i2 P (fc1 (a), . . . , fck (a), a) (I3 )i+1
3 ,
fc1 , . . . , fck skolem functions used skolemise vc1 , . . . , vck rule (24). Thus,
I2 2 |= B I3 3 |= B(a), Lemma 7 implies claim.
results Theorem 8 somewhat discouraging: known acyclicity notions
typically checked PTime NP. consider MFA upper bound
practically useful acyclicity notions. see two possibilities improving results.
Section 3.3 introduce approximation MFA easier check; experiments
(see Section 7) show notion often coincides MFA practice. Furthermore,
show next complexity lower rules following shape.
Definition 9. rule r form (5) -1 rule ~y empty ~x contains
one variable.
discuss following sections, -1 rules capture (extensions of) Horn DLs.
next show BCQ answering MFA checking -1 rules easier general
rules. Intuitively, MFA contains -1 rules, functional terms
sk(MFA()) unary hence number different terms atoms derivable
chase becomes exponentially bounded, shown following theorem.

756

fiAcyclicity Notions Existential Rules

Theorem 10. Let set -1 rules, let instance. Checking whether
MFA w.r.t. ExpTime, checking whether universally MFA ExpTime-hard.
Moreover, MFA w.r.t. I, answering BCQ ExpTime-complete.
Proof. defer proof hardness claims Section 6, deals even
smaller class rules correspond Horn description logic ontologies. particular,
prove hardness BCQ answering Lemma 59, hardness checking whether
MFA w.r.t. Lemma 60. rest proof, show membership results.
Let 0 = MFA(); let c number constants instance; let f
number function symbols rules. Since contains -1 rules, 0 also contains
-1 rules; consequently, functional terms sk(0 ) arity 1. Hence,
noncyclic term understood sequence f function symbols, total
number different noncyclic terms bounded = c (f + 1)f . total number
atoms bounded p , p number predicates maximum
arity predicate 0 . Note exponential even fixed. proof
Proposition 6, show either chase 0 terminates cyclic
term derived exponential time, proves complexity checking whether
MFA w.r.t. ExpTime.
Finally, since I0 , MFA, computed exponential time,
BCQ answered ExpTime.
3.3 Model-Summarising Acyclicity (MSA)
high cost checking MFA arises arity function symbols sk()
unbounded depth cyclic terms linear . obtain acyclicity notion
easier check, must coarsen structure used cycle analysis. thus next
introduce model-summarising acyclicity, summarises models reusing
constant satisfy existential quantifier, instead introducing deep terms.
Definition 11. Let S, D, Fir specified Definition 3; furthermore, rule
r = (~x, ~z) ~y .(~x, ~y ) variable yi ~y , let cir fresh constant unique r
yi . Then, MSA(r) following rule, MSA substitution maps
variable yi ~y cir :


^
^
Fir (yi )MSA
(~x, ~z) (~x, ~y )MSA
S(xj , yi )MSA
yi ~


xj ~
x

set rules, MSA() smallest set contains MSA(r) rule
r , rules (18)(19), rule (20) instantiated predicate Fir . Set modelsummarising acyclic (MSA) w.r.t. instance MSA() 6|= C; furthermore,
universally MSA MSA w.r.t. .
Example 12. Consider set rules Example 1. MSA(r1 ) MSA(r3 )
given rules (26) (27), respectively; since r1 r3 contain single existentially
quantified variable each, omit superscripts Fr1 , Fr3 , cr1 , cr3 sake

757

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

clarity. Thus, MSA() consists rules (14), (16), (17), rules (26)(27), rules (18)
(19), rule (20) instantiated Fr1 Fr3 .
A(x1 ) R(x1 , cr1 ) B(cr1 ) Fr1 (cr1 ) S(x1 , cr1 )

(26)

B(x3 ) R(x3 , cr3 ) C(cr3 ) Fr3 (cr3 ) S(x3 , cr3 )

(27)

following table shows chase sequence MSA().
A()

R(, cr1 )

R(cr1 , cr3 )

B()

R(, cr3 )

D(cr3 )

C()

B(cr1 )

S(cr1 , cr3 )

D()

C(cr3 )

D(, cr3 )

R(, )

S(, cr1 )

D(, cr1 )

D(cr1 , cr3 )

S(, cr3 )
Fr1 (cr1 )
Fr3 (cr3 )
result chase contain C, universally MSA.



Note MSA() equivalent set datalog rules: minor difference
rules MSA() contain several head atoms, rules clearly
transformed equivalent datalog rules. Thus, MSA checked using datalog reasoner. connection datalog complexity results Dantsin, Eiter, Gottlob,
Voronkov (2001) checking entailment ground atom datalog program provide
us upper complexity bound checking MSA Theorem 13. complexity
datalog reasoning O(r nv ) r number rules, v maximum number
variables rule, n size set facts rules applied to; thus,
checking MSA feasible rules short v small.
Theorem 13. set rules, deciding whether MSA w.r.t. instance
ExpTime, deciding whether universally MSA ExpTime-hard. two problems
coNP coNP-hard, respectively, arity predicates bounded.
Proof. (Membership) Let 0 = MSA(), note MSA w.r.t.
0 6|= C C 6 I0 . total number atoms occurring I0 p ca ,
p number predicates, c number constants, maximum arity
predicates 0 ; number clearly exponential bounded. rest
proof Theorem 8.
Assume bounded; number ground atoms I0 becomes polynomial. Furthermore, definition chase, C I0 exist sequence rules r1 , . . . , rn form ri = sequence substitutions 1 , . . . , n
{j j | j < i} I0 1 n n n = C. Clearly,
assume n p ca , polynomial. Thus, guess two sequences nondeterministic polynomial time, check required property polynomial time.
Thus, 0 |= C checked nondeterministic polynomial time, checking whether
MSA w.r.t. coNP.
758

fiAcyclicity Notions Existential Rules

(Hardness) Let set datalog rules, let instance, let Q ground
atom. Checking whether |= Q ExpTime-complete general (Dantsin et al., 2001).
Furthermore, problem NP-hard arity predicates bounded: rule
encode arbitrary Boolean conjunctive query atoms bounded arity arbitrarily
many variables, answering well known NP-hard.
Let 4 I4 obtained proof Theorem 8; then, |= Q
I4 4 |= B(a), set rules obtained 4 specified Lemma 7
universally MFA I4 4 6|= B(a). Finally, existential variable
occurs rule form (23), straightforward see universally MFA
0 universally MSA.
concluding section, present Theorem 14 Example 15, together
show MFA strictly general MSA.
Theorem 14. set rules MSA (w.r.t. instance I), MFA (w.r.t. I)
well.
Proof. Let 1 = MFA() let 2 = MSA(). Furthermore, let h mapping
ground terms constants defined h(t) = cir form fri (. . .), h(t) =
constant; atom = P (t1 , . . . , tn ), let h(A) = P (h(t1 ), . . . , h(tn ));
instance I, let h(I) = {h(A) | I}. Finally, let I0 1 , I1 1 , . . . chase sequence
1 , let I0 2 , I1 2 , . . . chase sequence 2 . Note sk(2 ) = 2
differs sk(1 ) former contains constant cir place functional term fri (~x). Please note that, although definition chase applies rules
function symbols rules without function symbols, one clearly construct chase
function-free set rules 2 using order rule applications, including one
corresponding order rule applications chase 1 . Assuming slight
modification, one show straightforward induction h(Ii 1 ) Ii 2
i; implies h(I1 ) I2 . Consequently, C 6 I2 clearly implies C 6 I1 ; hence,
MSA, MFA well, required.
Example 15. Let set rules (28)(31).
r1 =

A(x) y.R(x, y) B(y)

(28)

r2 =

B(x) y.S(x, y) (y, x)

(29)

r3 =

A(z) S(z, x) C(x)

(30)

r4 =

C(z) (z, x) A(x)

(31)

straightforward check universally MFA, universally MSA.



3.4 Acyclicity Notions Normalisation
mentioned Section 2.5, existential rules often normalised particular form;
however, cannot destroy acyclicity: set rules MFA, set rules
obtained normalisation MFA well. claim involves certain technical
assumptions treatment equality, postpone formal proof
statement Section 5. Next, however, show normalisation
positive effect acyclicity.
759

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Example 16. Let set containing following rule:
A(x) y.[B(x) A(y)]

(32)

specified Section 2.2, rule skolemised follows, causes skolem
chase instance = {A(a)} terminate.
A(x) B(x) A(f (x))

(33)

Note, however, atoms B(x) A(y) head rule share variables,
normalise rule follows, Q fresh predicate zero arity:
A(x) B(x) Q

(34)

Q y.A(y)

(35)

straightforward check normalised set rules MFA; fact, normalised
set rules even JA. Intuitively, normalisation, defined Section 2.5, ensures
functional symbol introduced normalisation depends variables
rule possible.

Normalisation, however, negative effect universal termination, shown
following example.
Example 17. Let set containing following rule:
C(z) R(z, x) B(x) y1 y2 .[R(x, y1 ) R(y1 , y2 ) B(y2 )]

(36)

One readily check universally MFA. let 0 following set rules,
obtained replacing conjunction R(y1 , y2 ) B(y2 ) rule head Q(y1 ):
C(z) R(z, x) B(x) y1 .[R(x, y1 ) Q(y1 )]
Q(y1 ) y2 .[R(y1 , y2 ) B(y2 )]

(37)
(38)

Let f1 f2 function symbols used skolemise existential quantifier rule (37)
(38), respectively. Since Q() 0 , chase 0 0 derives R(, f2 ())
B(f2 ()); then, facts, C(), rule (37) derive Q(f1 (f2 ())), rule
(38) derives R(f1 (f2 ()), f2 (f1 (f2 ()))) B(f2 (f1 (f2 ()))). chase 0 0 thus
contains cyclic term, 0 universally MFA.
Intuitively, problem occurs critical instance 0 0 also instantiates
predicate Q introduced normalisation. predicates, however, cannot occur
arbitrary input instances, use critical instance . Since Q() 6 ,
skolem chase 0 derive cyclic term, conclude
skolem chase 0 terminates instance contains facts constructed using
predicates occurring .


4. Relationship Known Acyclicity Notions
Many acyclicity notions proposed literature, relationships
partially investigated. next investigate relationship
MFA, MSA, acyclicity notions known us, produce detailed picture
relative expressiveness. show MFA MSA generalise notions.
760

fiAcyclicity Notions Existential Rules

4.1 Acyclicity Databases
Acyclicity notions considered databases data integration data exchange
scenarios. Weak acyclicity (Fagin et al., 2005) one first notions,
spurred research sophisticated notions ensuring chase termination.
4.1.1 Super-Weak Acyclicity
Marnette (2009) proposed super-weak acyclicity (SWA), generalises weak acyclicity
provided rules equality-free. next recapitulate definition SWA,
show MSA MFA strictly general SWA.
Definition 18. Let set existential rules variable occurs
one rule, let sk substitution used skolemise rules .2 place pair
hA, ii n-ary atom occurring rule 1 n. set places P 0
covers set places P if, place hA, ii P , place hA0 , i0 P 0 substitutions
0 exist = A0 0 = i0 . Given variable w occurring rule
r = ~y ., sets places In(w), Out(w), Move(w) defined follows:
set In(w) contains place hR(~t), ii R(~t) ti = w;
set Out(w) contains place hR(~t)sk , ii R(~t) ti = w;
set Move(w) smallest set places
Out(w) Move(w)
Out(w0 ) Move(w) variable w0 universally quantified
rule Move(w) covers In(w0 ).
SWA dependency graph SWA() contains vertex rule ,
edge rule r rule r0 variable x0 occurring body
head r0 existentially quantified variable occurring head r exists
Move(y) covers In(x0 ). Set super-weakly acyclic (SWA) SWA() acyclic.
Marnette (2009) uses slightly different definition: notation places
notation positions; variable may occur one rule sets In(w),
Out(w), Move(w) defined w.r.t. rule variable; rule trigger relation
used instead SWA dependency graph. simplicity, Definition 18 introduces SWA
style JA; however, definitions capture class rules.
following theorem shows MSA general SWA. Furthermore,
Example 12 argued set rules Example 1 MSA, one readily
check SWA. Consequently, MSA strictly general SWA.
Theorem 19. set rules SWA, universally MSA.
2. Substitution sk unique rule Section 2.2; however, since variable occurs
one rule, w.l.o.g. take sk substitution used skolemise rules .

761

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Proof. Let 0 = MSA(), let 0 , 1 , . . . chase sequence 0 , let
chase 0 . Furthermore, let function maps constants
maps ground functional terms (fri (~t)) = cir , fri cir introduced Section 2.2 Definition 11, respectively. Finally, let (P (t1 , . . . , tn )) = P ((t1 ), . . . , (tn )).
next prove following property (): rule r , existentially quantified variable yi occurring r, P (~t) P 6 {S, D, C}, tj ~t
tj = cir , substitution place hA, ji Move(yi ) exist P (~t) = (A ).
proof induction length chase. Since 0 = contain constant
form cir , property () holds vacuously 0 . Assume property () holds
k1 , consider arbitrary rule r , existentially quantified variable yi r,
fact P (~t) k \ k1 P 6 {S, D, C}, term tj ~t tj = cir . Fact P (~t)
derived k head atom H rule r1 MSA(). Let substitution
used rule application; clearly, H = P (~t). Furthermore, let r2 rule
r1 = MSA(r2 ), let r3 = sk(r2 ), let H 3 head atom r3 corresponds
H; clearly, (H 3 ) = P (~t). H cir position j, r = r1 since r1
rule contains cir ; thus, hH 3 , ji Out(yi ) Move(yi ), property () holds.
Otherwise, H contains position j universally quantified variable x (x) = cir .
Let B1 , . . . , Bn body atoms r1 contain x; clearly, {B1 , . . . , Bn } k1 .
atoms satisfy induction assumption, Bm {B1 , . . . , Bn }
0 , `i Move(y ) substitu` Bm contains variable x position `, place hBm

0 ). Let 0 substitution obtained
tion exist Bm = (Bm
setting 0 (w) = (w) variable w (w) functional term; clearly,
0 . then, Move(y ) covers In(x); hence, definition Move,
Bm 0 = Bm

hH 3 , ji Move(yi ), property () holds.
0
additionally prove following property (): S(cir , cir0 ) i0 ,
SWA() contains edge r r0 . Consider arbitrary fact, let yi
existentially quantified variable r corresponding cir , let k smallest integer
0
0
0
S(cir , cir0 ) k . Clearly, S(cir , cir0 ) derived k head atom S(x, cir0 )
rule r0 . Let substitution used rule application; thus, (x) = cir . Let
B1 , . . . , Bn body atoms r contain x; clearly, {B1 , . . . , Bn } k1 .
atoms satisfy property (), Bm {B1 , . . . , Bn } `
0 , `i Move(y ) substitution exist
Bm contains variable x position `, place hBm

0

Bm = (Bm ). then, previous paragraph Move(yi )
covers In(x), SWA() contains edge r r0 .
Assume MSA, C ; {Fir (t), D(t, t0 ), Fir (t0 )} holds
Fir due rules (20). then, since predicate Fir occurs 0 atom Fir (cir ),
= t0 = cir . Finally, since axiomatised 0 transitive closure S,
clearly SWA() contains path r itself, SWA.
rule set Example 1 MSA SWA. Furthermore, known SWA
general JA, two notions differ least one rule contains body
atom least one variable occurs (Krotzsch & Rudolph, 2013).
following example shows SWA strictly general JA.
Example 20. Let set following rules:
r1 =

A(x1 ) y.R(x1 , y) R(y, x1 ) R(x1 , x1 )
762

(39)

fiAcyclicity Notions Existential Rules

r2 =

R(x2 , x2 ) B(x2 )

(40)

r3 =

B(x3 ) A(x3 )

(41)

One readily verify SWA, JA.



Theorem 19 holds even contains equality predicate, provided
axiomatisation equality (cf. Section 2) taken part input. rule sets,
however, SWA, JA, MSA, MFA strictly general WA. discuss
underlying problems, well possible solutions, Section 5.
4.1.2 Acyclicity Rewriting
Spezzano Greco (2010) proposed acyclicity notion called Adn-WA. Roughly speaking, one first rewrites set rules another set rules 0 adorning positions
predicates contain infinitely many terms chase; then, one checks
whether 0 WA. rewriting algorithm rather involved, recapitulate
definition; instead, discuss means example. Spezzano Greco used
example show Adn-WA subsumed SWA, example also shows
Adn-WA subsumed MFA either.
Example 21. Let set containing following rules:
A(x) y.R(x, y)
B(z) R(z, x) A(x)

(42)
(43)

transformation Spezzano Greco (2010) produces set 0 consists
three groups rules. first group contains rules (44)(47).
Ab (x) y.Rbf (x, y)
b

bb

b

(44)

B (z) R (z, x) (x)

(45)

B b (z) Rbf (z, x) Af (x)

(46)

f

(47)

ff

(x) y.R (x, y)

n-ary predicate P , transformation introduces predicates form P ,
adornmenta string length n letters b f . Intuitively, contains letter
b position i, chase construction i-th position P contain
constants occurring instance. Rules (44)(47) derived follows. Rule (44)
obtained rule (42) marking positions variable x b, effectively
creates variant rule whose body applicable constants. Variable
head rule (44) occurs existential quantifier, corresponding position
marked f . Rule (45) obtained rule (43) analogous way. then, since
facts introduced rule (44) trigger application rule (43), latter rule marked
rule (46); predicate Af head rule (46) reflects fact variable x rule
body instantiated atom Rbf (z, x). Finally, facts derived rule (46) trigger
application rule (42), latter rule instantiated (47). point algorithm
terminates: since rule instantiated marking B f head, possible
use predicate Rff mark body rule (43) consistent way.
763

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

second group consists rules (48)(50), populate adorned predicates
contents instance.
R(x1 , x2 ) Rbb (x1 , x2 )

(48)

A(x) Ab (x)

(49)

b

B(x) B (x)

(50)

third group consists rules (51)(56), gather content adorned
predicate P fresh output predicates P .
Rbb (x1 , x2 ) R(x1 , x2 )

(51)

Rbf (x1 , x2 ) R(x1 , x2 )

(52)

ff

R (x1 , x2 ) R(x1 , x2 )
b

(53)

(x) A(x)

(54)

Af (x) A(x)

(55)

b

B (x) B(x)

(56)

straightforward check MFA. contrast, 0 WA; furthermore,
Spezzano Greco (2010) show that, instance vector ground terms
~t, P (~t) I0 P (~t) . Since 0 WA, I0 finite, and,
previously mentioned property, finite well.

following example shows MFA subsumed Adn-WA, indicates
MFA Adn-WA incomparable.
Example 22. Let set containing following rules:
A(x) y.R(x, y) B(y)

r1 =

S(z, x) B(x) y.S(x, y)

r2 =

(57)
(58)

rules first group set 0 obtained transformation shown below;
show rules second third group sake brevity.
Ab (x) y.Rbf (x, y) B f (y)
bb

b

bf

(59)

(z, x) B (x) y.S (x, y)

(60)

bf (z, x) B f (x) y.S ff (x, y)

(61)

ff

f

ff

(z, x) B (x) y.S (x, y)

(62)

last rule ensures WA dependency graph 0 contains special edge
position ff |2 itself; thus, 0 WA, therefore Adn-WA. contrast,
one readily verify MFA.

Spezzano Greco (2010) also proposed several optimisations transformation,
discussion scope paper. seen unfolding
rules certain number chase steps. seems close idea Baget
764

fiAcyclicity Notions Existential Rules

et al. (2011b), propose run chase fixed number steps checking
potential cycles. similar effect could obtained extending notion MFA
check terms contain function symbol nested fixed number times.
Finally, note transformation Spezzano Greco (2010) independent
notion used check acyclicity transformed rule set; hence, given
arbitrary acyclicity notion X, one define Adn-X obvious way. Given arbitrary
notions X X , obvious Adn-X Adn-Y ; consequently,
Adn-X 6 MFA X WA X. contrast, however, obvious
whether inclusion Adn-X Adn-Y strict whenever inclusion
X strict, whether MFA contained Adn-X X WA X.
Finally, conjecture X Adn-X holds arbitrary notion X,
formal proof conjecture. Due complex nature rewriting,
refrain analysis relationships.
4.1.3 Monitor Graph
Meier et al. (2009) propose idea similar spirit MFA. idea track
chase step additional data structure called monitor graph. chase
infinite, monitor graph contains cycles arbitrary length; conversely, one
show monitor graph contain cycle fixed length, chase
guaranteed terminate. idea closely related MFA, note definition
MFA semantic; hence, one use arbitrary theorem proving technique check
whether MFA() |= C. contrast, notion monitor graph specifically tied
nonoblivious chase. well known result nonoblivious chase depends
order rules applied; consequently, set rules identified cyclic
acyclic depending selected rule application strategy. dependence,
difficult compare monitor graph approach acyclicity notions.
4.2 Acyclicity Knowledge Representation
Existential rules capture knowledge representation formalisms Horn fragments
description logics (see Section 6), conceptual graphs (Baget, 2004; Baget et al., 2011a),
datalog rules (Cal et al., 2010a), acyclicity notions allow materialisationbased query answering knowledge bases. context, Baget (2004) Baget et al.
(2011a) proposed notion acyclic graph rule dependencies (aGRD). Intuitively, aGRD
introduces rule dependency relation r1 r2 means application
rule r1 instance subsequently trigger application rule r2 . relation
acyclic, rule trigger skolem chase terminates arbitrary
instance. formalised follows.
Definition 23. rule dependency relation set rules defined
follows. Let r1 = 1 ~y1 .1 r2 = 2 ~y2 .2 arbitrary rules , let
sk(r1 ) = 1 10 sk(r2 ) = 2 20 . Then, r1 r2 exist instance
I, substitution 1 variables sk(r1 ), substitution 2 variables sk(r2 )
1 1 I, 2 2 6 I, 2 2 10 1 , 20 2 6 10 1 . Set acyclic
graph rules dependencies (aGRD) relation acyclic.

765

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Definition 23 differs original definition Baget (2004) several ways. First,
Baget uses fresh nulls capture effect existential quantifiers, whereas Definition 23
uses skolem functions; however, change resulting relation way.
Second, Baget require 20 2 6 10 1 . condition intuitively ensures
application r1 enables r2 derive something new; analogous optimisations
proposed Deutsch et al. (2008) Greco et al. (2012). clear Definition
23 stronger one Baget. unify notions used various parts
paper, included optimisation Definition 23; however, nevertheless call
resulting stronger notion aGRD.
following example shows aGRD, even weaker form originally proposed
Baget (2004), contained SWA.
Example 24. Let set consisting following rule:
A(z1 , x, z2 ) B(z2 ) y1 y2 .A(x, y1 , y2 )

r=

(63)

see r r hold, consider skolemisation r0 r:
A(z1 , x, z2 ) B(z2 ) A(x, f1 (x), f2 (x))

sk(r) =

(64)

let arbitrary instance, let 1 2 arbitrary substitutions
{A(z1 , x, z2 )1 , B(z2 )1 } {A(z1 , x, z2 )2 , B(z2 )2 } 6 I. Since instance contains
constants, atom A(x, f1 (x), f2 (x))1 form A(a, f1 (a), f2 (a)); then,
{A(z1 , x, z2 )2 , B(z2 )2 } {A(a, f1 (a), f2 (a))} hold, must 2 (z2 ) = f2 (a);
thus, B(z2 )2 = B(f2 (a)) contained I, impossible since instance
thus contain functional terms. Note additional condition Greco et al.
(2012) plays role here. Thus, r 6 r, aGRD even weaker form
Baget (2004). However, one easily check SWA.

However, aGRD seems rather weak notion: following example shows, even
set rules without existential quantifiers cyclic according criterion.
Example 25. Let set consisting following rules:
r1 =

A(x) B(x)

(65)

r2 =

B(x) C(x)

(66)

r3 =

C(x) A(x)

(67)

see r1 r2 , let = {A(a)}, let = {x 7 a}, note A(x) I, B(x) 6 I,
B(x) {B(x)}, C(x) 6 {B(x)}. Analogously, taking = {B(a)} get
r2 r3 , taking = {C(a)} get r3 r1 . Consequently, aGRD. However,
obviously WA since contain existentially quantified variables.

Baget et al. (2011a) suggested rule dependencies become powerful
combined arbitrary acyclicity notion X. Intuitively, main idea use
partition set rules strongly connected components, check whether
component X; call notion X . idea formalised follows.
766

fiAcyclicity Notions Existential Rules

Definition 26. Let set existential rules, let rule dependency relation
. Relation extended arbitrary sets C C 0 C C 0
0
rules r C r0 C 0 exist
Sn r r . dependency partition
sequence sets 1 , . . . , n = i=1 , strongly connected
component , j 6 j 1 < j n.
Let X arbitrary acyclicity notion. Then, X dependency partition
1 , . . . , n exists that, 1 n, X, consists
single rule ri ri 6 ri .
aGRD, strongly connected component contains single rule ri
ri 6 ri . Definition 26 consider special case consists
single rule depend itself, SWA would extend aGRD; example,
rule Example 24 would SWA . extra condition Definition 26 thus
ensures aGRD contained X regardless choice X, aGRD
understood acyclicity notion obtained extending empty notion (i.e.,
notion rule set acyclic) rule dependencies.
next present two simple results. Proposition 27 precludes inclusions certain
acyclicity notions thus help us establish proper inclusions many acyclicity
notions. Furthermore, Proposition 28 shows combining acyclicity notion contained
SWA rule dependencies creates strictly stronger acyclicity notion; note
holds even weaker form rule dependencies originally proposed Baget (2004).
Proposition 27. Let X acyclicity notions X . Then, X .
Furthermore, exists set \ X whose rule dependency relation cycle
containing rules , 6 X , 6 X , X ( .
Proof. Relationship X immediate Definition 26. Assume
exists set rules \ X whose rule dependency relation cycle containing
rules . Definition 26, 6 X implies 6 X , implies .
then, clearly 6 X 6 X , latter clearly implies X ( .
Proposition 28. acyclicity notion X X SWA, X ( X
aGRD 6 X.
Proof. Set Example 24 aGRD thus X ; however, SWA
hence X either.
MSA also contain aGRD; however, unlike SWA, claim depends
optimisation Definition 23. analysis relationship MSA version
rule dependencies originally proposed Baget (2004) scope paper.
Example 29. Let set consisting following rules:
r1 =

R(x1 , x1 ) U (x1 , z) U (x2 , z) R(x1 , x2 )

(68)

r2 =

R(z, x) y.T (x, y)

(69)

r3 =

(z, x) y.U (x, y)

(70)

767

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

obvious r1 r2 , r1 6 r3 , r2 6 r1 , r2 6 r2 , r2 r3 , r3 6 r2 , r3 6 r3 . next
argue r1 6 r1 r3 6 r1 , implies aGRD.
see r1 6 r1 , assume application r1 instance produces atom
form R(a, b); due atom R(x1 , x1 ) body r1 , R(a, a) I. let
0 = {R(a, b)}; since R(a, a) I, rule application derives something new
6= b. assume substitution 2 exists makes r1 applicable 0 I;
rule application must use fact R(a, b), implies R(x1 , x1 )2 = R(a, b);
however, impossible since 6= b. Consequently, r1 6 r1 , holds even
version rule dependencies Baget (2004).
Furthermore, see r3 6 r1 , assume r3 applicable instance I,
rule application derives fact form U (a, f (a)). let 0 = {U (a, f (a))},
assume substitution 2 exists makes r1 applicable 0 I;
rule application must use fact U (a, f (a)), implies 2 (x1 ) = 2 (x2 ) =
2 (z) = f (a). Furthermore, rule r1 applicable R(a, a) I; then, rule application derive something new since R(x1 , x2 )2 = R(a, a). Consequently,
r3 6 r1 ; however, unlike previous paragraph, claim depends optimisation
Definition 23.
Consider chase MSA() shown (facts involving predicates
D, Fr2 , Fr3 omitted clarity). chase result contains C, MSA,
thus aGRD 6 MSA; corollary, also get MSA ( MSA .
R(, )

(, cr2 )

U (cr2 , cr3 )

(, )

U (, cr3 )

S(cr2 , cr3 )

U (, )

S(, cr2 )

R(, cr2 )

(cr2 , cr2 )

C

S(cr2 , cr2 )

S(, cr3 )
Note R(, cr2 ) derived R(, ), U (, cr3 ), U (cr2 , cr3 ), latter two
facts obtained distinct instantiations MSA(r3 ). Rule dependencies, however,
analyse rule applicability w.r.t. sk(r3 ), closer actual skolem chase.

contrast result, Theorem 32 show extending MFA rule
dependencies create stronger notion: MFA coincides MFA, implies
X MFA notion X X MFA. Towards goal, show
Lemma 30 independent rule sets evaluated independently, Lemma 31
single rule depend applied once.
Lemma 30. Let 1 2 sets existential rules 2 6 1 , let F
set ground facts containing function symbol sk(2 ). Then, F1 2 = (F1 )
2 .
Proof. Let F0 = F1 ; let F0 , F1 , . . . chase sequence F0 2 where, convenience, assume Fi obtained Fi1 single rule application (this
assumption clearly w.l.o.g.); let F 0 = (F0 )
2 . definition skolem chase,
0

clearly F F1 2 . Furthermore, assume F1 2 6 F 0 ; then, skolemised
rule r1 sk(1 ) form r1 = 1 (~x1 ) 1 (~x1 ) exists F 0 ( r1 (F 0 ). Fix
smallest Fi ( r1 (Fi ) (we clearly > 0), let 1 substitution used
application r1 . Furthermore, let r2 sk(2 ) skolemised rule form
768

fiAcyclicity Notions Existential Rules

r2 = 2 (~x2 ) 2 (~x2 ) used derive Fi Fi1 , let 2 substitution
used application r2 . consider arbitrary term f (~x2 ) head r2
assume f (~x2 )2 occurs Fi1 ; since function symbol f private r2 , head
r2 must already instantiated 2 ; then, 2 2 Fi1 , contradicts
assumption 2 2 Fi \ Fi1 . Thus, following property (?):
term f (~x2 ) occurring head r2 , ground term f (~x2 )2
occur Fi1 .
Finally, let function maps ground term Fi1 fresh distinct constant;
let = (Fi1 ); let 20 substitution defined 20 (w) = (2 (w)) variable w
r2 ; let 10 substitution defined follows variable w r1 :
10 (w) = f ((~t)) 1 (w) = f (~t) f function symbol private r2 ;
10 (w) = (1 (w)) otherwise.
clearly 2 20 2 20 6 I; furthermore, (?), also 1 10 2 20
1 10 6 2 20 . Moreover, 1 10 6 follows assumption smallest
integer Fi ( r1 (Fi ). then, Definition 23, r2 r1 and, consequently,
2 1 well, contradiction.
Lemma 31. Let = {r} singleton rule set r 6 r, let F set facts
containing function symbol sk(). Then, F = (F ).
Proof. Let F0 = F , let F0 , F1 , . . . sets facts
Fi+1 union
Fi result
distinct
single application r F0 ; clearly, Fi = (F0 ).


assume Fi ( ( Fi ); analogously proof Lemma 30, one show
r r, contradiction; omit details sake brevity.
Theorem 32. Let arbitrary set rules let arbitrary instance.
MFA w.r.t. I, also MFA w.r.t. I.
Proof. Assume MFA ; let arbitrary instance; let 1 , . . . , Sn
dependency partition ; let 0 = I0 = I; and, 1 n, let = i`=1 `
Ii = (Ii1 )
. definition dependency partitions, 6 i1 holds
1 n. next show that, 0 n, following two properties hold:
(a) Ii = (I0 )
,
(b) Ii contain cyclic term.
Set I0 contain functional terms hence trivially satisfies (a) (b).
consider arbitrary 0 < < n Ii1 satisfies (a) (b). induction assump

tion, Lemma 30, 6 i1 , = i1 , (I0 )
= ((I0 )i1 )i ; thus,
Ii satisfies (a). see Ii satisfies (b), note function symbol used skolemise
rules used skolemise rules i1 ; call property (?).
two ways compute Ii .
Assume = {ri } ri 6 ri . Lemma 31, Ii = ri (Ii1 );
then, Ii contain cyclic term due (?).
769

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

MFA, Ii contain cyclic term due (?) Proposition 5.
= contain cyclic
claim =
n

n
term; then, MFA w.r.t. Proposition 5.

Combinations rule dependencies acyclicity notions also considered
databases: Deutsch et al. (2008) proposed notion stratification, Meier et al. (2009)
developed idea proposed notion c-stratification. Roughly speaking,
notion checks whether strongly connected components certain rule dependency
graph WA. rule dependency notions, however, developed nonoblivious
chase thus different Definition 23, illustrated following rule:
r=

R(z, x) y.R(x, y) R(y, y)

(71)

skolem chase critical instance r infinite, r r Definition 23.
contrast, rule r pose problems nonoblivious chase. particular, assume
rule matched atom R(t1 , t2 ), derives R(t2 , t3 ) R(t3 , t3 ).
Then, rule r applicable R(t2 , t3 ) R(t3 , t3 ) since either case head atom
satisfied; hence, rule dependency graphs Deutsch et al. Meier et al.
empty. results summarised follows: rule set satisfies notion
Deutsch et al., instance exists finite nonoblivious chase sequence;
furthermore, satisfies notion Meier et al., instance chase
sequences (regardless rule application strategy) finite. Meier (2010) discusses
detail subtle differences notions. Since notions consider different
chase variant, discuss paper.
4.3 Acyclicity Logic Programming
Acyclicity notions also considered context disjunctive logic programs
function symbols answer set semantics, goal ensuring given
program finitely many answer sets, finite. notions must deal
disjunction nonmonotonic negation, one main differences
notions considered thus far. notions logic programming, however, applicable
rules without disjunction nonmonotonic negation, case ensure termination
skolem chase. Therefore, section compare specialisations
acyclicity notions logic programming aGRD, WA, JA, SWA, MSA, MFA.
simplify definitions apply skolemised existential rulesthat is,
present parts definitions handle disjunctions head nonmonotonic
negation function symbols body.
4.3.1 Finite Domain Notion
Calimeri et al. (2008) proposed finite domain (FD) notion. next recapitulate
definition, style Greco et al. (2012), come useful Section
4.3.3 introduce -acyclicity. approaches use argument graph determine
possible ways propagating ground terms positions chase. definition
argument graph WA dependency graph (see Section 2.4),

770

fiAcyclicity Notions Existential Rules

without distinction regular special edges. simplify presentation,
consistently use WA dependency graph instead argument graph.
Definition 33. Let set rules. position P |i -recursive position Q|j
WA dependency graph WA() contains cycle (consisting regular and/or special
edges) going P |i Q|j . set PosFD () finite domain positions
largest set positions that, position P |i PosFD (), rule r
form r = (~x, ~z) ~y .(~x, ~y ), head atom r form P (~t), following
conditions satisfied:
i-th component ~t variable x ~x, PosB (x) PosFD () 6= ;
i-th component ~t variable ~y , then, variable x ~x,
position Q|j PosB (x) PosFD () exists -recursive P |i .
Set FD PosFD () coincides set positions .
Note notion -recursive positions introduced symmetric: P |i
-recursive Q|j , Q|j also -recursive P |i . Furthermore, note Calimeri
et al. (2008) defined FD follows:
set rules FD if, rule r = (~x, ~z) ~y .(~x, ~y ) , atom
Q(~t) head r, j-th term ~t existential variable y,
variable x ~x, exists position P |i PosB (x) Q|j
-recursive P |i .
Conditions definition clearly correspond conditions Definition 33;
then, since PosFD () defined maximal set satisfying conditions, two
definitions FD coincide.
next show WA strictly contained FD. end, first prove WA
contained FD, present example showing inclusion strict.
Proposition 34. set rules WA, FD.
Proof. Let set rules FD. Then, exist rule r , atom Q(~t)
head r, j-th term ~t equal existential variable y, variable x ~x
position P |i PosB (x) -recursive Q|j . set PosB (x) empty (~x
contains precisely variables occurring body head rule),
choose arbitrary position P |i PosB (x). WA dependency graph WA()
contains special edge P |i Q|j . Furthermore, since Q|j -recursive P |i ,
graph WA() contains cycle going P |i Q|j . Thus, WA() clearly contains
cycle containing special edge, WA.
Example 35. Let set containing rules (72) (73).
r1 =

R(z, x) A(x) y.S(x, y)
S(x1 , x2 ) R(x1 , x2 )

r2 =

771

(72)
(73)

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Set WA since WA dependency graph contains special edge R|2 S|2
regular edge S|2 R|2 . However, FD position S|2 -recursive
A|1 PosB (x). Together Proposition 34, conclude WA ( FD.
addition, r1 r2 r2 r1 . Section 4.3.2 prove FD JA;
hence, FD ( FD , WA ( FD , FD 6 WA Propositions 27, 28, 34.

4.3.2 Argument-Restricted Rule Sets
Lierler Lifschitz (2009) proposed notion argument-restricted rule sets, whose
definition summarise next.
Definition 36. argument ranking set rules function assigns
nonnegative integer position following conditions satisfied
rule r , universally quantified variable x r, existentially quantified
variable r:
1. P |i PosH (x), Q|j PosB (x) exists (P |i ) (Q|j );
2. P |i PosH (y), Q|j PosB (x) exists (P |i ) > (Q|j ).
Set argument restricted (AR) argument ranking exists.
argument-restricted set rules finite skolem chase arbitrary instance:
straightforward induction chase sequence, one show dep(ti ) (P |i )
ground fact P (t1 , . . . , tn ) derived chase 1 n.
next show JA strictly general AR. Towards goal, first
prove auxiliary lemma establishes relationship set Move
definition JA argument ranking; next, use lemma prove AR JA;
finally present example shows inclusion proper.
Lemma 37. Let set rules, let argument ranking , let
existentially quantified variable , let Move(y) set positions used
definition JA. position P |i Move(y), position Q|j PosH (y) exists
(P |i ) (Q|j ) holds.
Proof. Let existentially quantified variable occurring rule r ,
consider arbitrary position P |i Move(y). prove claim induction
definition Move(y). base case P |i PosH (y) trivial. Assume
P |i PosH (x) variable x occurring rule r0 , PosB (x) Move(y),
P |i needs added Move(y). definition argument ranking since
P |i PosH (x), position P 0 |` PosB (x) exists (P |i ) (P 0 |` ). then, since
P 0 |` PosB (x) Move(y), induction hypothesis position Q|j PosH (y)
exists (P 0 |` ) (Q|j ). Thus, (P |i ) (Q|j ) holds, required.
Theorem 38. set rules AR, JA.
Proof. Assume AR, let argument ranking , let JA() JA
dependency graph . next prove following claim: edge JA()
variable y1 variable y2 , position Q|j PosH (y2 ), exists position
772

fiAcyclicity Notions Existential Rules

P |i PosH (y1 ) (P |i ) < (Q|j ). Consider arbitrary edge y1 y2
JA() arbitrary position Q|j PosH (y2 ). definition JA dependency
graph, rule r contains y2 also contains universally quantified variable x
x occurs head r PosB (x) Move(y1 ). Since argument ranking
, position P 0 |` PosB (x) exists (P 0 |` ) < (Q|j ). Since P 0 |` Move(y1 ),
Lemma 37 position P |i PosH (y1 ) exists (P |i ) (P 0 |` ). Thus,
(P |i ) < (Q|j ), claim holds. then, claim clearly implies JA
dependency graph JA() acyclic, therefore JA.
Example 39. Let set consisting following rules:
r1 =

R(z1 , x1 ) y1 .S(x1 , y1 )

(74)

r2 =

R(z2 , x2 ) y2 .S(y2 , x2 )

(75)

r3 =

S(x3 , x4 ) (x3 , x4 )

(76)

r4 =

(x5 , x6 ) (x6 , x5 ) R(x5 , x6 )

(77)

Let argument ranking . Then, (R|2 ) < (S|2 ) due (74); (R|2 ) < (S|1 )
due (75); (S|1 ) (T |1 ) (S|2 ) (T |2 ) due (76); (T |2 ) (R|2 )
(T |1 ) (R|2 ) due (77). Together, observations contradictory, cannot exist AR. contrast, Move(y1 ) = {S|2 , |2 } Move(y2 ) = {S|1 , |1 },
JA.
addition, r1 r3 , r2 r3 , r3 r4 , r4 r1 , r4 r2 ; hence,
AR ( AR , AR ( JA , JA 6 AR Theorem 38 Propositions 27 28.
Lierler Lifschitz (2009, Thm. 4) proved AR strictly general FD.
next present example shows FD ( AR, also settles relationships
FD AR .
Example 40. Let set consisting following rules:
A(x) y.R(x, y)

r1 =

R(x1 , x2 ) S(x1 , x2 )

r2 =
r3 =

S(z, x) B(x) A(x)

(78)
(79)
(80)

WA dependency graph contains special edge A|1 R|2 , well regular
edges R|2 S|2 S|2 A|1 ; thus, R|2 -recursive A|1 . Consequently,
rule (78) cannot satisfy conditions Definition 33, R|2 6 PosFD (),
thus FD. contrast, AR, evidenced following argument ranking:
= {A|1 7 0, B|1 7 0, R|1 7 0, R|2 7 1, S|1 7 0, S|2 7 1}
addition, r1 r2 , r2 r3 , r3 r1 ; hence, FD ( FD , FD ( AR ,
AR 6 FD Propositions 27 28.

Finally, note -restricted programs Gebser et al. (2007) -restricted
programs Syrjanen (2001) included FD AR; thus, restricted
skolemised existential rules, notions also included JA.
773

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

4.3.3 -Acyclicity
Greco et al. (2012) recently proposed notion -acylicity logic programs
function symbols. original definition -acyclicity rather complex, next
present simplified version -acyclicity applicable existential rules. unify
naming style notions paper, often write -acyclicity A.
Greco et al. (2012) introduce notion activation graph, tracks whether rule
trigger another rule. notion closely related notion rule dependencies
Definition 23, requirement arbitrary finite set ground facts
(possibly containing functional terms). understand latter needed logic
programming, consider following logic program:
r1 =

A(x) B(x) A(f (x))

(81)

r2 =

A(x) B(x) B(f (x))

(82)

restrict set Definition 23 instance, r1 6 r2 r2 6 r1 ; however,
skolem chase r1 , r2 , facts A(a) B(a) infinite. Intuitively, r1 r2 contain
function symbol f , determine whether application r1 trigger
application r2 , must allow set Definition 23 contain facts B(f (a)).
setting, however, function symbols introduced skolemisation thus
private rule, allows us restrict set Definition 23 facts without
functional terms. Thus, rest section, simply reuse rule dependency
relation Definition 23, gives us slightly stronger version existential
rules one proposed Greco et al. (2012).
Furthermore, Greco et al. (2012) handle logic programming rules functional terms
body. rules, however, considered paper, allows us omit
definition labelled argument graph simplify notion propagation graph
subset WA dependency graph.
ready present simplified version -acyclicity applicable
existential rules.
Definition 41. Let set rules. rule dependency relation taken
Definition 23, set finite domain positions PosFD () taken Definition 33.
set safe positions , written PosS (), least set positions
PosFD () PosS (), P |i PosS () if, rule r ,
least one following conditions satisfied:
P occurs head r, contain cycle going r,
atom P (~t) head sk(r) variable x occurs i-th component ~t, PosB (x) PosS () 6= .
position affected safe. propagation graph PG()
affected positions vertices, edges PG() defined weak acyclicity,
restricted affected positions. set -acyclic (A) PG() contain
cycle involves special edge.

774

fiAcyclicity Notions Existential Rules

order relate notions considered thus far, first establish containment relationships. obvious Definition 41 FD A: positions
finite domain, also safe propagation graph empty. Furthermore,
set rules Example 40 actually (all positions safe), FD; hence,
Proposition 27, FD ( A, FD ( , 6 FD . Next, Proposition 42
observes aGRD contained A, Theorem 43 shows that, perhaps somewhat
surprisingly, contained AR .
Proposition 42. set rules aGRD, A.
Proof. rule dependency relation acyclic, first safety condition
Definition 41 positions safe; then, PG() empty, A.
Theorem 43. set rules , AR .
Proof. claim clearly follows following property: rule dependency relation
one strongly connected component A, AR. Thus, assume
rule r occurs cycle . next construct mapping assigns
nonnegative integer position , show argument ranking
. rest proof, write p1
p2 WA() (see Section 2.4) contains path
(consisting regular and/or special edges) position p1 position p2 .
Due assumption , first item Definition 41 never applies. Furthermore,
let function maps set positions another set positions follows:
(S) = {P |i | PosB (x) 6= r , atom P (~t) head sk(r),
variable x occurring i-th component ~t}

Let 0 (S) = S, k (S) = (k1 (S)) k > 0, (S) = k (S). Definition 41 obvious PosS () = (PosFD ()).
next define mapping . rest proof, let set containing
position p PosFD () existentially quantified variable exists
p PosH (y). Furthermore, use convention max = 0.
position p PosFD (), define (p) follows:
0
|{p | p0
p p0 6= p}| + 1
(p) =
|{p0 | p0
p}|

p
p
6

position p PosS () \ PosFD (), define (p) follows:
h

(p) = min{k | p k (PosFD ())} + [max{(q) | q PosFD ()}]
position p p 6 PosS (), define (p) follows, m(p)
maximum number special edges occurring PG() path ending p:
(p) = m(p) + 1 + [max{(q) | q PosS ()}]
Since , PG() contain cycle involving special edge, m(p)
always nonnegative integer (p) correctly defined.
775

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

next show argument rankingthat is, satisfies conditions
Definition 36. end, consider arbitrary rule r , arbitrary existentially
quantified variable r, arbitrary universally quantified variable x r, arbitrary
position P |i PosH (y); following cases.
P |i PosFD (). Definition 33, position Q|j PosB (x) PosFD () exists
-recursive P |i . Thus, P |i 6 Q|j ; furthermore, Q|j
P |i
definition WA(). Together, latter two properties imply following:
{p0 | p0

Q|j p0 6= Q|j } {p0 | p0

P |i p0 6= P |i }

Q|j , inclusion strict since Q|j contained set righthand side, set left-hand side; thus, (Q|j ) < (P |i ) holds,
required. Q|j 6 , (Q|j ) < (P |i ) holds since definition ensures
(P |i ) (Q|j ) least 1.
P |i PosS () \ PosFD (). Let k smallest number P |i k (PosFD ()).
definition , exists position Q|j PosB (x) k1 (PosFD ()),
k 1 (Q|j ) definition . Thus, (P |i ) > (Q|j ) holds, required.
P |i 6 PosS (). first possibility position Q|j PosB (x) PosS ()
exists; then, definition , (Q|j ) < (P |i ), required.
second possibility exists affected position Q|j PosB (x); then,
Q|j least one less incoming special edge PG() P |i ; thus, also
(Q|j ) < (P |i ), required.
complete proof, must also consider arbitrary position P |i PosH (x); however,
cases analogous above, omit sake brevity.
place precisely landscape acyclicity notions, present three examples
disprove relevant containment relationships. Greco et al. (2012) stated AR
strictly contained A, unable find formal proof statement;
fact, Example 44 shows case, actually ( AR holds.
Moreover, Example 45 shows 6 MSA. Finally, Example 46 shows WA 6 A.
Example 44. Let set consisting following rules:
A(x) y.R(x, y)

r1 =

R(x1 , x2 ) S(x1 , x2 )

r2 =
r3 =

S(z, x) B(x) A(x)

(83)
(84)
(85)

r4 =

R(z, x) (x, x)

(86)

r5 =

(x, z) R(x, x)

(87)

r6 =

(z1 , x) R(z2 , x) y.T (x, y)

(88)

One readily verify following mapping positions nonnegative integers
argument ranking :
= {A|1 7 0, B|1 7 0, R|1 7 1, R|2 7 1, S|1 7 1, S|2 7 1, |1 7 1, |2 7 2}
776

fiAcyclicity Notions Existential Rules

next argue A. First, rule dependency relation holds (at least)
pairs rules shown below. Thus, rule occurs cycle,
strongly connected component .
r1 r2

r2 r3

r3 r1

r1 r4

r4 r5

r5 r2

r5 r6

r6 r5

Second, WA dependency graph contains special edge A|1 R|2 due
rule r1 , regular edge R|2 S|2 due rule r2 , regular edge S|2 A|1 due
rule r3 ; consequently, R|2 -recursive A|1 ; then, rule r1 satisfy
conditions Definition 33, R|2 6 PosFD (). Furthermore, due rule r4 ,
|1 6 PosFD () |2 6 PosFD () well. Finally, R|1 6 PosFD () due rule r5 .
Consequently, set finite domain positions given PosFD () = {A|1 , B|1 , S|1 }.
Third, argue PosS () = PosFD (). particular, need extend
PosS () R|2 : position R|2 occurs head rule r5 , since |2 finite
domain position r5 occurs cycle , neither condition Definition 41 holds.
Analogously, positions |1 |2 need added PosS () either.
Fourth, since positions R|2 , |1 , |2 affected, propagation graph PG()
contains special edge |2 due rule r6 . Consequently, A.
Finally, since strongly connected component , example also shows
AR 6 AR 6 ; then, Theorem 43, ( AR .

Example 45. Let set rules Example 29. explained example,
aGRD, MSA thus also JA, AR, FD. Proposition 42, A,
implies 6 MSA, thus 6 SWA, 6 JA, 6 AR, 6 FD.

Example 46. Let set consisting following rules:
r1 =

R(x1 , x1 ) y1 y2 .[A(x1 ) S(y1 , x1 ) S(x1 , y2 )]

(89)

r2 =

A(x2 ) B(x2 )

(90)

r3 =

B(x3 ) R(x3 , x3 )

(91)

r4 =

S(x4 , x4 ) y3 y4 .[C(x4 ) R(y3 , x4 ) R(x4 , y4 )]

(92)

r5 =

C(x5 ) D(x5 )

(93)

r6 =

D(x6 ) S(x6 , x6 )

(94)

Note r1 6 r4 r4 6 r1 , rule dependency relation two strongly
connected components: first one consists r1 , r2 , r3 , second one consists
r4 , r5 , r6 . Moreover, strongly connected component WA, WA .
contrast, position -recursive itself, PosFD () = . Moreover,
position occurs head rule (i) appears cycle (ii)
satisfy second safety condition Definition 41; hence, PosS () = , positions affected. then, PG() = WA(), A.

may seem counterintuitive AR 6 A, ( AR . Intuitively, notion
safe positions Definition 41 uses rule dependency relation, allows us
construct example AR. , extra condition always
applied rules occur cycle; thus, notion safe positions collapses
notion weaker AR, turn allows subsumed AR .
777

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

MFA = MFA
MSA

MSA

SWA

SWA

JA

JA

AR

AR


Adn-WA



FD

FD

WA

WA
aGRD

Figure 1: Landscape Acyclicity Notions
4.4 Landscape Acyclicity Notions
obtain complete picture relative expressiveness acyclicity notions considered paper, make following observations.
rule set Example 15 MFA MSA, one readily verify
r1 r2 r3 r4 r1 ; then, MSA ( MFA = MFA Proposition 27.
rule set Example 20 SWA JA, one readily verify
r1 r2 r3 r1 ; then, JA ( SWA SWA 6 JA Proposition 27.
rule set Example 1 MSA SWA, one readily verify
r1 r3 r4 r5 r2 r1 ; then, SWA ( MSA MSA 6 SWA Proposition 27.
rule set Example 22 aGRD: r1 6 r1 , r1 6 r2 , r2 6 r1 , r2 6 r2 .
Thus, aGRD 6 Adn-WA.
rule set Example 22 FD: assume positions rule set
finite domain without violating conditions Definition 33. Thus, FD 6 Adn-WA.
landscape acyclicity notions considered paper shown Figure 1.
inclusions notions shown figure strict: notion X reachable
notion via one (directed) arcs, X strictly general .
Furthermore, inclusions also complete: notion X reachable notion
via one (directed) arcs, X contain .
778

fiAcyclicity Notions Existential Rules

5. Handling Equality via Singularisation
acyclicity notions presented far provide special provision equality predicate. set rules contains equality predicate, one always axiomatise equality
explicitly check acyclicity. precisely, acyclicity (under
notion introduced thus far) guarantees termination skolem chase . Furthermore,
note MFA MSA defined entailment checks first-order logic equality,
effectively incorporates rules equality checks even rules (1)(4)
explicitly given; however, effect definition same.
handling equality explicitly may simple, approach ensure
termination skolem chase many practically relevant cases. particular,
following example shows equalities terms tend proliferate skolem
chase, lead non-termination.
Example 47. Consider set rules containing rules (95)(96).
A(x) B(x) y.[R(x, y) B(y)]
R(z, x1 ) R(z, x2 ) x1 x2

(95)
(96)

skolem chase derives following infinite set facts:
R(, f ())
B(f ()) f () A(f ())
R(f (), f (f ))) B(f (f ()))
...
Thus, universally MFA Proposition 5, Theorem 14 universally
MSA either.

worth noticing presence equality WA longer subsumed MFA
hence notions become incomparable. explained Section 2.4, WA
applied rules containing equality predicate (and without explicit axiomatisation
equality). treatment, rules Example 47 WA. This, however,
contradict results Section 4: WA require explicit axiomatisation
equality ensures termination nonoblivious chasean optimised chase variant
expands existential quantifiers necessary handles equality replacing
equal terms canonical representatives. contrast, results Section 4 ensure
termination skolem chase; since chase variant uses explicit axiomatisation
equality, results hold equality-free rules (or, equivalently, rules
containing explicit axiomatisation equality). rules Example 47 WA
equality axiomatised explicitly, explains apparent mismatch Section 4.
order use skolem chase rule sets ones Example 47, Marnette
(2009) proposed singularisation technique. Roughly speaking, singularisation replaces
equality predicate fresh binary predicate Eq clarify two
treated differently; furthermore, axiomatises Eq reflexive, symmetric, transitive,
introduce replacement rules analogous (4); finally, modifies rules
take lack replacement rules account. chase transformed rule
set model , used answer queries particular welldefined way. modification , however, nondeterministic: many ways
modify and, may ensure termination skolem chase, required
so. next recapitulate definition singularisation Marnette (2009).
779

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Definition 48. marking Mr rule r form (5) mapping assigns
variable w ~x ~z single occurrence w ; marked occurrence w rule
written w . occurrences w unmarked, occurrences constants
unmarked well. set rules, marking contains exactly one marking Mr
r . Let Eq fresh binary predicate occurring . singularisation
set Sing(, ) contain rules
Eq(x, x)

(97)

Eq(x1 , x2 ) Eq(x2 , x1 )

(98)

Eq(x1 , x2 ) Eq(x2 , x3 ) Eq(x1 , x3 )

(99)

and, rule r , rule obtained r replacing atom atom
Eq(s, t), replacing unmarked occurrence term body atom fresh
variable z 0 adding atom Eq(t, z 0 ) rule body.
Note Sing(, ) unique renaming fresh variables. Furthermore,
note rule (97) transformed safe rule explained Section 2.2. Finally,
note Sing(, ) equality-free (since Eq different predicates); therefore,
specific treatment equality needed computing chase checking acyclicity.
Example 49. Singularisation marked rule (100) produces rule (101).
A(x ) B(x) R(x, z ) C(x)

(100)

A(x) B(x1 ) R(x2 , z) Eq(x, x1 ) Eq(x, x2 ) C(x)

(101)

Note singularisation applied globally rules, including ones
contain equality predicate.

properties singularisation summarised follows. Let set rules,
let instance, let marking . Furthermore, let 0 = Sing(, ),
let 0 = I0 chase 0 . Finally, note predicate Eq interpreted
0 equivalence relation, let function maps term occurring
0 arbitrarily chosen representative equivalence class t. first-order
interpretation (I 0 ) defined follows, rng() range mapping ,
0
0
set 4(I ) universe (I 0 ), (P )(I ) interpretation predicate P :
0

4(I ) = rng()
0
(P )(I ) = {h(t1 ), . . . , (tn )i | P (t1 , . . . , tn ) I} P different Eq
0
0
(Eq)(I ) = {hx, xi | x 4(I ) }
Note (I 0 ) interprets true equalitythat is, term interpreted (I 0 )
representative equivalence class contains t; hence, (I 0 ) Herbrand
interpretation. Marnette (2010) showed that, arbitrary , interpretation (I 0 )
universal model Ithat is, (I 0 ) homomorphically embedded
arbitrary model I. Thus, (I) used query answering: Boolean
conjunctive query Q, |= Q (I 0 ) |= Q.

780

fiAcyclicity Notions Existential Rules

result reformulated follows. Let , I, , 0 specified above,
let us assume Q form Q = ~y .(~y ). Furthermore, let r following
rule, let 0 arbitrary marking r:
r=

(~y ) H

(102)

Then, characterisation singularisation implies
|= Q
Sing( {r}, 0 ) |= H
0 Sing({r}, 0 ) |= H.
Hence, answer Q w.r.t. evaluating Sing({r}, 0 ) chase
Sing(, ). straightforward generalise approach non-Boolean queries.
absence replacement rules (4) often allows skolem chase terminate
Sing(, ), may depend selected marking.
Example 50. Rule (95) Example 47 admits following two markings:
A(x ) B(x) y.[R(x, y) B(y)]


A(x) B(x ) y.[R(x, y) B(y)]

(103)
(104)

skolem chase universally terminate singularisation obtained (104)
(96). contrast, singularisation obtained (103) (96) JA.

Definition 51. X {MFA, MSA, JA}, acyclicity notion X (resp. X ) contains
finite set rules Sing(, ) X (resp. each) marking .
Clearly, X X X {MFA, MSA, JA}, Example 50 shows inclusion
proper. next show JA actually coincides WA.
Theorem 52. arbitrary finite set rules, JA WA.
Proof. (JA WA) prove contrapositive, let arbitrary set rules
WA; w.l.o.g. assume variable occurs one rule. consider
edge p q WA dependency graph WA() triple e = hp, q, ti,
= edge regular = edge special. definition WA,
e, rule r universally quantified variable x occurring head
body r exist p PosB (x), let xe one arbitrarily chosen fixed
variable; furthermore, edge e special, existentially quantified variable exists
q PosH (y), let ye one arbitrarily chosen fixed variable.
cycle WA() sequence edges e1 , . . . , en form ei = hpi , qi , ti
qi = pi+1 1 < n qn = p1 . cycle dangerous edge ek exists
special; cycle simple xei 6= xej 1 < j n.3
let 0 = e1 , . . . , en arbitrary dangerous cycle WA(). 0 simple,
show transform 0 shorter dangerous cycle. Towards goal, assume
0 contains edges ei = hpi , qi , ti ej = hpj , qj , tj 1 < j n xei = xej ;
hence, rule r contains body atoms xei occurs positions pi pj .
Furthermore, let ek arbitrarily chosen, fixed special edge 0 ; ek exists
since 0 dangerous. following possibilities.
3. Note cycle length one always simple.

781

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

k < j, let 00 = e, ei+1 , . . . , ej1 e = hpj , qi , ti i. ei regular, xei
occurs head atom r position qi ; furthermore, ei special, head
atom r contains existentially quantified variable position qi . Either way, e
edge WA(), 00 cycle WA(). Furthermore, e special k = i,
00 contains ek otherwise; hence, 00 dangerous.
Otherwise, let 00 = e1 , . . . , ei1 , e, ej+1 , . . . , en e = hpi , qj , tj i. Edges e ej
type, e edge WA() 00 cycle WA(). Furthermore, e special k = j, 00 contains ek otherwise; hence, 00 dangerous.
cases, 00 contains least one edge less 0 . Thus, iteratively transform
arbitrary dangerous cycle WA() simple dangerous cycle .
let marking marks variable w occurring body
rule r follows.
edge e = hp, q, ti exists w = xe , marks occurrence
w r position p (if multiple occurrences, one chosen arbitrarily).
Since simple, edge e unique, correctly defined.
Otherwise, marks arbitrarily chosen occurrence w r.
Let 0 = Sing(, ), let JA(0 ) JA dependency graph 0 . show
JA(0 ) contains cycle, first prove following property (?).
subpath e1 , . . . , ek edge e1 special edge ei
1 < k regular, {qi , Eq|1 } Move(ye1 ) 1 k.4
Since 0 contains rule (97), clearly Eq|1 Move(ye1 ). next prove (?) induction k. base case k = 1, q1 Move(ye1 ) definition JA.
induction step, assume claim holds subpaths length k, consider
subpath e1 , . . . , ek , ek+1 . induction assumption fact qk = pk+1 ,
pk+1 Move(ye1 ). Furthermore, variable xek+1 occurs body head atom
rule r 0 positions pk+1 qk+1 , respectively. Finally, definition
properties singularisation, PosB (xek+1 ) contains pk+1 possibly
Eq|1 . then, definition JA, qk+1 Move(ye1 ), required.
complete proof, consider arbitrary subpath e1 , . . . , e` edges
e1 e` special edge ei 1 < < k regular. (?) fact
q`1 = p` , {p` , Eq|1 } Move(ye1 ). Furthermore, previous paragraph,
PosB (xe` ) contains p` possibly Eq|1 ; then, JA(0 ) contains edge ye1 ye` .
Since cycle, JA(0 ) clearly contains cycle, 0 JA, required.
(JA WA) Assume 6 JA , exists marking
= Sing(, ) JA. assume contain existentially quantified variable occurs equality atom; w.l.o.g. always replace
equality atom atom R(x, t) add rule R(x1 , x2 ) x1 x2 R fresh
binary predicate, transformation clearly affect membership

0

4. notion subpath defined obvious way; however, please note that, although defined
sequence edges, subpaths wrap around sequence cycle.

782

fiAcyclicity Notions Existential Rules

rule set JA WA. consider arbitrary existentially quantified variable y,
arbitrary positions p PosH (y) q Move(y) involve Eq (both sets w.r.t.
0 ); induction construction Move(v), one prove WA() contains
sequence regular edges p q. proof straightforward, omit details
sake brevity. Similarly, consider arbitrary edge y1 y2 JA(0 ),
arbitrary positions p PosH (y1 ) q PosH (y2 ) involve Eq; definition
JA, variable x occurring rule y2 position involving Eq exist
Move(y1 ) PosB (x). WA() contains path consisting regular
edges p s, well special edge q. Since JA(0 ) cyclic, WA()
clearly contains cycle involving special edge.
Checking possible markings may infeasible: number candidates exponential total number variables occur rule body. Theorem 52
shows JA decided using WA. cases, following simple observation shows reduce number markings.
Definition 53. variable x relevant rule r x occurs
body r, head r contains atom P (~t) x ~t P .
Proposition 54. Let 0 markings that, rule r ,
markings r 0 coincide relevant variable r. Then,
instance I, result skolem chase Sing(, ) coincides result
skolem chase Sing(, 0 ); furthermore, Sing(, ) JA/MSA/MFA
Sing(, 0 ) JA/MSA/MFA.
Proof. Consider arbitrary rule r . variable x occurs body r,
marking various occurrences x r clearly produces rules equivalent renaming
variables. Furthermore, assume variable x occurs head r equality
atom form x t, markings x differ. Then, rules obtained r
singularisation body (up renaming variables); furthermore,
bodies contain atoms Eq(xi , x), rule heads form Eq(x, t). Since
Sing(, ) Sing(, 0 ) contain rules (97)(99), skolem chase Sing(, )
clearly derives ground atoms skolem chase Sing(, 0 ).
Despite optimisation, number markings check still exponential
size , next describe useful approximation. Let maximal set markings
that, M1 , M2 M, rule r , variable x relevant
r, markings x r M1 M2 coincide. Intuitively, contains
possible markings relevant variables, markings variables coincide.

Proposition 54 clear
that, given two sets M1 M2 , skolem chase
I; thus, let
M1 Sing(, )
M2 Sing(, ) coincides arbitrary instance

one arbitrarily chosen set markings. Also, let Sing () = Sing(, ),
let MFA class containing rule set Sing () MFA, let MSA
JA defined analogously. following proposition shows, Sing () provides
lower bound acyclicity obtained via singularisation.

783

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Proposition 55. X {MFA, MSA, JA}, X X . Furthermore,
size Sing () exponential maximal number relevant variables rule
, linear number rules .
Proof. first claim follows fact considered notions acyclicity
monotone sense every subset acyclic rule set also acyclic. second
claim follows fact that, rule r exists contains k relevant variables
variable occurs times r, contains mk different markings r.
result interesting dealing rules obtained DLs,
rule one relevant variable: rule sets, size Sing () linear
size . general case, complexity acyclicity checking increase
despite exponential increase number rules.
Theorem 56. Deciding whether MFA (MFA , MFA ) 2ExpTime-complete.
Deciding whether MSA (MSA , MSA ) ExpTime-complete.
Proof. contains equality, easy see MFA (MFA , MFA )
MFA. observed MSA. Thus, hardness follows
Theorems 8 13.
membership, first consider cases MFA , MFA , MSA , MSA .
properties decided considering exponentially many
markings. Since Sing(, ) linear size , property checked
marking MFA 2ExpTime (cf. Theorem 8) MSA ExpTime (cf. Theorem 13). yields required bound since exponential factor significant
considered complexity classes.
MFA MSA , membership follows observing membership MFA
MSA 2ExpTime ExpTime, respectively, obtained double/single
exponential bound number ground facts potentially need derived
order decide required property. Sing () exponentially larger ,
maximal number relevant ground facts still since new predicates constant
symbols introduced. increased number rules leads exponential increase
time check applicability rules doubly/singly exponentially many
steps, exponential factor affect membership decision problem
2ExpTime/ExpTime.
finish section examining interaction rule normalisation
singularisation. Note normalisation reduces number variables rule,
least first sight suggests normalisation could prevent one finding marking
ensures acyclicity singularised rules. next show cannot happen
normalisation used without structure sharing: original set rules MFA w.r.t.
set markings, transformed set rules MFA w.r.t. set markings
well. Furthermore, show hold normalisation used structure
sharing; hence, normalisation applied care used singularisation.
Theorem 57. Let set existential rules, let 0 obtained applying
single normalisation step without structure sharing, let instance.
784

fiAcyclicity Notions Existential Rules

marking Sing(, ) MFA w.r.t. extended marking 0
0 Sing(0 , 0 ) MFA w.r.t. I.
Proof. Let marking Sing(, ) MFA, let r rule
form (8) normalisation step applied, let 0 set rules obtained
application normalisation step r. next prove claim
holds head body normalisation step.
(Head Normalisation) Assume set rules 0 obtained replacing rule
r rules r1 r2 following forms, ~x = ~x3 ~x4 :
r=
r1 =
r2 =

(~x, ~z) ~y1 , ~y2 , ~y3 .[1 (~x3 , ~y1 , ~y2 ) 2 (~x4 , ~y1 , ~y3 )]
(~x, ~z) ~y1 , ~y3 .[Q(~x3 , ~y1 ) 2 (~x4 , ~y1 , ~y3 )]
Q(~x3 , ~y1 ) ~y2 .1 (~x3 , ~y1 , ~y2 )

Let 0 marking coincides rules different r, marks r1
way marks r, marks r2 possible way (note
body rule contain repeated occurrences variables); furthermore, let
= Sing(, ) = Sing(0 , 0 ). assume rule r skolemised replacing
variable ~y1 g1y (~x), variable ~y2 g2y (~x), variable ~y3
g3y (~x); rule r1 skolemised r; rule r2 skolemised replacing variable
~y2 hy (~x3 , ~y1 ). Thus, skolemised singularised rules following form;
formula 0 singularisation , freshly introduced variables contained ~z1 :
0 (~x, ~z1 ) 1 (~x3 , ~g1 (~x), ~g2 (~x)) 2 (~x4 , ~g1 (~x), ~g3 (~x))
0 (~x, ~z1 ) Q(~x3 , ~g1 (~x)) 2 (~x4 , ~g1 (~x), ~g3 (~x))
Q(~x3 , ~y1 ) 1 (~x3 , ~y1 , ~h(~x3 , ~y1 ))
Finally, inductively define partial mapping terms terms follows:
(c) = c constant c,
(f (~t)) = f ((~t)) function symbol f form hy g1y terms ~t
(~t) defined,
(hy (~s, ~g1 (~s, ~t))) = g2y ((~s), (~t)) function symbols form hy , corresponding symbol g2y , terms ~s ~t (~s) (~t) defined.
predicate
next show following property (?): A(~t)
occurring (i.e., introduced normalisation step), (t) defined
0 , 1 , . . . .
A((~t)) . proof induction chase sequence

base case holds trivially. Furthermore, since coincide rules apart r,
r1 , r2 , proof claim trivial conclusion rule different r1
i+1

r2 . remaining cases, assume w.l.o.g.
obtained
single application r1 substitution application r2 result; thus,
rules together derive following facts:

Q(~x3 , ~g1 (~x))
~
1 (~x3 , ~g1 (~x), h(~x3 , ~g1 (~x)))
2 (~x4 , ~g1 (~x), ~g3 (~x))
785

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

induction assumption, 0 ((~x), (~z)) , contains following
facts:
1 ((~x3 ), ~g1 ((~x)), ~g2 ((~x)))
2 ((~x4 ), ~g1 ((~x)), ~g3 ((~x)))
Clearly, term hy (~x3 , ~g1 (~x)) form hy (~s, ~g1 (~s, ~t)), mapping defined
term. Furthermore, definition , clear property (?) holds.
always (sub)terms
proof (?) also reveals functions symbols hy occur
.
form hy (~s, ~g1 (~s, ~t)), (u) defined term u occurring
observation following property clearly imply claim theorem: u
cyclic term (u) defined, (u) cyclic well. prove latter, suffices
consider following two cases.
Assume u cyclic due repetition function symbol f form
hy . Thus, u contains subterm form f (~s), si ~s contains subterm
form f (~t). definition , (u) contains term form f ((~s)),
s0i (~s) contains subterm form f ((~t)). Clearly, (u) cyclic.
Assume u cyclic due repetition function symbol form hy .
observation, u contains subterm form hy (~s, ~g1 (~s, ~t)),
si ~s ~t contains subterm form hy (~v , ~g1 (~v , w)).
~
definition ,

~
(u) contains subterm form g2 ((~s), (t)), s0i (~s) (~t) contains
~
Clearly, u cyclic.
subterm form g2y ((~v ), (w)).
(Body Normalisation) Assume set rules 0 obtained replacing rule
r rules r1 r2 following forms, ~x = ~x1 ~x2 ~x3 , ~x1 , ~x2 , ~x3 ,
~z1 , ~z2 , ~z3 pairwise disjoint:
r=
r1 =
r2 =

1 (~x1 , ~x2 , ~z1 , ~z2 ) 2 (~x1 , ~x3 , ~z1 , ~z3 ) ~y .(~x, ~y )
1 (~x1 , ~x2 , ~z1 , ~z2 ) Q(~x1 , ~x2 , ~z1 )
Q(~x1 , ~x2 , ~z1 ) 2 (~x1 , ~x3 , ~z1 , ~z3 ) ~y .(~x, ~y )

marked variable v, let ~uv variables used replace v singularisation. Then,
singularised rule r represented follows, clarity show
free variables various formulae, 01 02 contain atoms predicate Eq,
1 2 conjunctions atoms predicate Eq obtained renaming unmarked
occurrences variables 1 (~x1 , ~x2 , ~z1 , ~z2 ) 2 (~x1 , ~x3 , ~z1 , ~z3 ), respectively:
01 02 1 2 ~y .(~x, ~y )
let 0 marking coincides rules different r, that,
marked occurrence variable w ~x1 ~x2 ~z1 r, marks r1 r2 follows.
marked occurrence w appears 1 (~x1 , ~x2 , ~z1 , ~z2 ), corresponding
occurrence w marked r1 ; addition, w ~x1 ~x2 ~z1 , occurrence
w atom Q(~x1 , ~x2 , ~z1 ) marked r2 .

786

fiAcyclicity Notions Existential Rules

marked occurrence w appears 2 (~x1 , ~x3 , ~z1 , ~z3 ), corresponding
occurrence w marked r2 ; addition, w ~x1 ~x2 ~z1 , arbitrary
occurrence w marked r1 .
Since structure sharing, contain r1 , definition wellformed. singularisation r1 r2 0 represented follows:
001 001 Q(~x1 , ~x2 , ~z1 )
Q(~x01 , ~x2 , ~z10 ) 02 02 ~y .(~x, ~y )
definition 0 , clear 001 001 isomorphic subset 01 01 .

Based observation, routine prove that, A(~t) ISing(,M
)

~
different newly introduced predicate Q, A(t) ISing(0 ,M 0 ) , clearly
implies claim.
contrast Theorem 57, following example shows normalisation structure sharing prevent one finding marking makes normalised rules acyclic.
example shows normalisation must used care applications use singularisation deal equality.
Example 58. Let following set rules marked marking shown below.
A(x) (x , z) B(z ) y.[R(x, y) A(y)]




A(x ) (x, z) C(z ) y1 y2 .[S(x, y1 ) (y1 , y2 )]


R(z , x1 ) R(z, x2 )
S(z , x1 ) S(z, x2 )
(z , x1 ) (z, x2 )

(105)
(106)

x1 x2

(107)

x1 x2

(108)

x1 x2

(109)

One show Sing(, ) MFA w.r.t. instance given below.
= {A(a), R(a, a), (a, b), B(b), A(a0 ), S(a0 , a0 ), (a0 , b0 ), C(b0 )}
Furthermore, let M1 marking identical marks A(x ) rule (105),
let M2 marking identical marks (x , z) rule (106). One show
neither Sing(, M1 ) Sing(, M2 ) MFA w.r.t. I.
let 0 obtained applying normalisation structure sharing rules
(105) (106); thus, rules (105) (106) replaced following rules:
Q(x, z) B(z) y.[R(x, y) A(y)]

(110)

Q(x, z) C(z) y1 y2 .[S(x, y1 ) (y1 , y2 )]

(111)

A(x) (x, z) Q(x, z)

(112)

Note conjunction A(x) (x, z) occurs 0 rule (112); therefore, variable x
conjunction marked one way. This, however, effect
choosing M1 M2 : possible marking 0 make Sing(0 , 0 ) MFA w.r.t. I.
Intuitively, normalisation structure sharing reduces space available markings,
due may impossible find marking makes rules acyclic.

787

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

6. Applying Acyclicity Horn Description Logics
section apply various acyclicity notions reasoning problems description
logic (DL) ontologies. Description logics knowledge representation formalisms underpin Web Ontology Language (OWL). DL ontologies constructed atomic
concepts (i.e., unary predicates), atomic roles (i.e., binary predicates), individuals (i.e.,
constants). Special atomic concepts > denote universal truth falsehood, respectively. atomic role R, expression R inverse role; furthermore, role
atomic inverse role. DLs provide rich set constructors building concepts
(first-order formulae one free variable) atomic concepts roles. description
logic TBox set axioms, correspond first-order sentences. paper
consider Horn description logics, TBoxes translated existential rules. Furthermore, paper consider normalised TBoxes,
concepts occur nested concepts. latter assumption without loss
generality Horn description logic TBox normalised linear time,
normalised ontology model-conservative extension original one.
paper consider several logics fragments description logic
Horn-SROIF, provides formal underpinning prominent subset OWL.
normalised Horn-SROIF TBox consists axioms shown left-hand side
Table 1; table, A, B, C atomic concepts (including possibly > ), R, S,
(not necessarily atomic) roles, individual. guarantee decidability
reasoning, must satisfy certain global conditions (Kutz, Horrocks, & Sattler, 2006),
omit sake brevity. Roughly speaking, so-called simple roles
allowed occur axioms Type 2, axioms Type 6 must regular according
particular condition allows axioms represented using nondeterministic
finite automaton. also consider following fragments Horn-SROIF.
Horn-SRI TBoxes allowed contain axioms Type 2 7.
Horn-SHIF TBoxes allowed contain axioms Type 7, axioms
Type 6 satisfy R = = . Note Horn-SHIF TBoxes regular.
Horn-SHI TBoxes inherit restrictions Horn-SHIF allowed contain axioms type 2.
simplify presentation, consider general at-least number restrictions
is, concepts form n R.A n > 1. translation concepts rules
would require explicit inequality predicate. explained Section 2.2, inequality
predicate simulated using ordinary predicate, extension results
general at-least number restrictions straightforward.
rest paper allow inverse roles occur atoms, take atom
form R (t1 , t2 ) R atomic role abbreviation R(t2 , t1 ). Then,
Horn-SROIF axiom corresponds existential rule shown Table 1. explained
Section 2.2, treat > ordinary unary predicates > explicitly axiomatised. Thus, take substitution answer CQ Q(~x) w.r.t.
|= Q(~x) |= y.(y); latter condition takes account
unsatisfiable theory entails possible formulae. Due close correspondence
788

fiAcyclicity Notions Existential Rules

1.
v R.B
2.
v 1 R.B
3. u B v C
4.
v R.B
5.
RvS
6. R v
7.
v {a}

A(x) y.[R(x, y) B(y)]
A(z) R(z, x1 ) B(x1 ) R(z, x2 ) B(x2 ) x1 x2
A(x) B(x) C(x)
A(z) R(z, x) B(x)
R(x1 , x2 ) S(x1 , x2 )
R(x1 , z) S(z, x2 ) (x1 , x2 )
A(x) x

Table 1: Axioms normalised Horn-SROIF ontologies corresponding rules
description logic axioms existential rules, rest paper identify TBox
corresponding set rules.
complexity answering Boolean conjunctive queries general (i.e., acyclic)
DL TBoxes 2ExpTime- ExpTime-complete Horn-SROIF (Ortiz et al., 2011)
Horn-SHIF (Eiter et al., 2008), respectively. rest section investigate
complexity problem acyclic ontologies, well complexity acyclicity
checking. particular, Section 6.1 consider case TBox expressed
Horn-SROIF, show BCQ answering MFA checking
ExpTime-complete. Then, Section 6.2 consider Horn-SHIF TBoxes,
show complexity problems drops PSpace.
6.1 Acyclic Horn-SROIF TBoxes
start showing BCQ answering WA Horn-SRI TBoxes ExpTime-hard.
Intuitively, due axioms Type 6, used axiomatise existence
non-tree-like structures. Although regularity ensures axioms Type 6
represented nondeterministic finite automaton, automaton exponential;
consequence, axioms Type 6 axiomatise exponential non-tree-like structures,
main source complexity.
Lemma 59. Let WA Horn-SRI TBox, let instance, let F fact.
Then, checking whether |= F ExpTime-hard.
Proof. Let = (S, Q, , Q0 , Qa ) deterministic Turing machine, finite set
symbols, Q finite set states, : Q Q {, } transition function,
Q0 Q initial state, Qa accepting state. Furthermore, assume integer
k
k exists halts input length n time 2n . Given arbitrary input
Si1 , . . . , Sin , construct MFA set Horn-SRI rules instance
|= Qa (a) accepts input. simplify presentation, use
slightly general rule syntax allowed Table 1; however, rules
brought required form renaming parts rules fresh predicates.
Let ` = nk ; since k constant, ` polynomial n. construction uses unary
predicate symbol state; simplicity, distinguish
predicate symbol/state. addition, construction also uses binary predicates
Li , Ri , Ti , Ui , Di , Hi , Vi 1 `, unary predicates Ai Bi 0 `,
unary predicates O1 , . . . , On+1 , N1 , N2 . Instance contains fact A0 (a).
789

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

next present rules . set contain Horn rules without empty heads,
satisfiable minimal Herbrand model. readability, divide
groups rules prove group various facts minimal Herbrand model
I, shown schematically Figure 2. construction proceeds along
following lines.
first, second, third group rules construct exponential grid shown
bottom Figure 2, whose edges labelled H` V` . sequence
V` -edges used encode contents tape Turing machine
point time; furthermore, precisely one vertex sequence
labelled state, thus representing position head. contrast, H` -edges
connect different points time used encode transitions
Turing machine.
fourth group labels right-most V` -chain Si1 , . . . , Sin , St , St , . . . , St , St ,
St represents empty tape symbol.
fifth sixth groups ensure symbols tape
modified move Turing machine propagated time points.
seventh eighth group encode transitions Turing machine.
ninth group propagates acceptance condition top figure
labelling individual accepting state Qa .
next present rules detail.
first group rules contains rules (113)(115) 0 < `, rule (116)
1 < `.
Ai1 (x) y.[Li (x, y) Ai (y)]

(113)

Ai1 (x) y.[Ri (x, y) Ai (y)]

(114)

0

0

(115)

0

0

(116)

Ri (z, x) Li (z, x ) Ti (x, x )
0

0

Li (z, x) Ti1 (z, z ) Ri (z , x ) Ti (x, x )

I, rules axiomatise existence triangular structure top part Figure 2
containing Ti links.
second group rules contains rule (117), rules (118)(120) 0 < `,
rule (121) 1 < `.
A` (x) B0 (x)

(117)

Bi1 (x) y.[Ui (x, y) Bi (y)]

(118)

Bi1 (x) y.[Di (x, y) Bi (y)]

(119)

0

0

(120)

0

0

(121)

Ui (z, x) Di (z, x ) Vi (x, x )
0

0

Di (z, x) Vi1 (z, z ) Ui (z , x ) Vi (x, x )

rules axiomatise existence triangular structures bottom part Figure 2
containing Vi links.
790

fiAcyclicity Notions Existential Rules

L1

R1
T1

L2

Legend:

R2

T2

T2

T2

Li

Ui

Ri

Di

Ti
Hi
T`

T`

H0

H0
D1

Vi

U1

H1

V 1 U2
D2

V2
V2
V2

H2
H`

H`

O1 , Q0
V`

H`

V`

H`

Figure 2: Grid Model
third group rules contains rule (122), rules (123) (124)
0 < `.
T` (x, x0 ) H0 (x, x0 )

(122)

0

0

0

0

(123)

0

0

0

0

(124)

Ui (z, x) Hi1 (z, z ) Ui (z , x ) Hi (x, x )
Di (z, x) Hi1 (z, z ) Di (z , x ) Hi (x, x )

rules axiomatise existence Hi links, Vi links form grid size 2i 2i
shown Figure 2.
rest proof, variables w0 w` , use R` (w0 , w` ) abbreviation
R1 (w0 , w1 ) . . . R` (w`1 , w` ), wi 0 < < variable occurring
outside conjunction. Furthermore, analogously use U ` (w0 , w` ) abbreviation
U1 (w0 , w1 ) . . . U` (w`1 , w` ).
fourth group rules contains rule (125), rules (126) (127)
1 j n, rules (128)(129), St empty tape symbol. Remember
Si1 , . . . , Sin encodes input M.
A0 (z) R` (z, z 0 ) U ` (z 0 , x) O1 (x) Q0 (x)

(125)

Oj (z) V` (z, x) Oj+1 (x)

(126)

Oj (x) Sij

(127)

On+1 (z) V` (z, x) On+1 (x)

(128)

On+1 (x) St (x)

(129)

791

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Rule (125) labels grid origin sets initial state shown Figure 2. Rules
(126) ensure n subsequent nodes labelled O2 , . . . , On+1 , rule (128)
propagates On+1 rest V` -chain. Finally, rules (127) (129) ensure
nodes labelled Oj also labelled Sij , nodes labeled On+1
labeled St . Thus, group rules ensures right-most V` -chain
grid contains initial state tape M.
fifth group rules contains rules (130)(131) state Qk Q, rules
(132)(133). rules essentially ensure nodes node labelled
state Qk Q labeled N1 N2 , respectively, thus indicating
head node.
Qk (z) V` (x, z) N1 (x)

(130)

Qk (z) V` (z, x) N2 (x)

(131)

N1 (z) V` (x, z) N1 (x)

(132)

N2 (z) V` (z, x) N2 (x)

(133)

sixth group rules contains rules (134)(135) instantiated symbol
Sk S; rules ensure contents tape copied successive time
points points grid containing head.
N1 (z) Sk (z) H` (z, x) Sk (x)

(134)

N2 (z) Sk (z) H` (z, x) Sk (x)

(135)

seventh group rules contains rules (136)(137) instantiated symbol
Sk state Qk Q (Qk , Sk ) = (Qk0 , Sk0 , ). rules encode
moves head moves left.
Qk (z) Sk (z) H` (z, x) Sk0 (x)
0

0

Qk (z) Sk (z) H` (z, z ) V` (x, z ) Qk0 (x)

(136)
(137)

eighth group rules contains rules (138)(139) instantiated symbol
Sk state Qk Q (Qk , Sk ) = (Qk0 , Sk0 , ). rules encode
moves head moves right.
Qk (z) Sk (z) H` (z, x) Sk0 (x)
0

0

Qk (z) Sk (z) H` (z, z ) V` (z , x) Qk0 (x)

(138)
(139)

ninth group rules contains rules (140)(143) 1 `; rules
simply ensure acceptance propagated back root upper tree.
Qa (z) Ui (x, z) Qa (x)

(140)

Qa (z) Di (x, z) Qa (x)

(141)

Qa (z) Li (x, z) Qa (x)

(142)

Qa (z) Ri (x, z) Qa (x)

(143)

792

fiAcyclicity Notions Existential Rules

discussion shows labelling nodes grid shown Figure 2
simulates execution input Si1 , . . . , Sin , contents tape
time instant represented V` -chain, H` -links connect tape cells successive
time instants. Thus, |= Qa (a) accepts Si1 , . . . , Sin time 2` .
straightforward see WA, claim theorem holds.
proof Lemma 59 adapted obtain lower bound checking MFA
Horn-SRI rules.
Lemma 60. Checking whether Horn-SRI TBox universally MFA ExpTime-hard.
Proof. Let arbitrary deterministic Turing machine let Si1 , . . . , Sin input
k
string terminates time 2n . Si1 , . . . , Sin , let
proof Lemma 59. TBox WA, contains constant-free, equality-free,
connected rules, predicate zero arity; hence, Lemma 7, Horn-SRI
TBox 0 exists accepts Si1 , . . . , Sin 0 universally MFA.
Note Lemmas 59 60 apply Horn-SRI thus rely particular
treatment equality. deal equality predicate Horn-SROIF TBoxes
using singularisation described Section 5, leads us following result.
Theorem 61. Let Horn-SROIF TBox, let marking , let
instance, let Q BCQ. Then, checking whether Sing(T , ) MFA w.r.t.
ExpTime-complete. Furthermore, Sing(T , ) MFA w.r.t. I, checking whether
|= Q holds ExpTime-complete well.
Proof. Note rules Table 1 -1 rules. Since rules Sing(T , ) -1
rules well, Theorem 10 gives us ExpTime upper bound problems.
matching lower bounds follow Lemmas 59 60 (note every Horn-SRI TBox
also Horn-SROIF TBox) fact proofs use predicate .
fact, Theorem 10 provides us even stronger complexity bounds. particular,
even satisfy required global conditions, even extended
SWRL rules (Horrocks, Patel-Schneider, Bechhofer, & Tsarkov, 2005), rules
still -1 rules. Thus, one decide whether MFA (universally w.r.t.
instance) ExpTime, case, one answer BCQs ExpTime well.
Consequently, ontology-based applications freely use expressivity beyond
currently available OWL without increase complexity reasoning, assuming
resulting TBox acyclic.
conclude section observing MSA provides us tractable notion
Horn-SROIF rules. Intuitively, rules MSA(T ) bounded number variables predicates MSA(T ) bounded arity, eliminates sources
intractability datalog reasoning. prove matching lower bound Section 6.2
specific case Horn-SHIF ontologies.
Theorem 62. Let Horn-SROIF TBox, let marking, let instance.
Then, checking whether Sing(T , ) MSA w.r.t. PTime.

793

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Proof. one see Table 1, rules contain bounded number variables atoms body, number variables body rule
MSA(Sing(T , )) bounded well. Furthermore, datalog program MSA(Sing(T , ))
contains predicates bounded arity, chase w.r.t. polynomial size. Thus,
chase MSA(T ) computed polynomial time, implies claim.
6.2 Acyclic Horn-SHIF TBoxes
exponential lower bound Lemmas 59 60 critically depend axioms Type 6,
used encode exponential structures; furthermore, combination inverse
roles axioms Types 2 7 (i.e., inverse roles, number restrictions, nominals)
also well known problematical (Horrocks & Sattler, 2007). practice, however,
TBoxes often expressed Horn-SHIF, disallows axioms TBoxes.
next show that, TBoxes, complexity problems drops PSpace.
first prove PSpace-hardness problems. Note PSpace-hardness
proof concept satisfiability checking Baader, Calvanese, McGuinness, Nardi, PatelSchneider (2007) applicable Horn ontologies since uses disjunctive concepts.
Nonetheless, PSpace-hardness proved reduction checking QBF validity.
Lemma 63. Let WA Horn-SHI TBox, let instance, let F fact.
Then, checking whether |= F PSpace-hard.
Proof. Let = Q1 x1 . . . Qn xn .C1 . . . Ck arbitrary quantified Boolean formula defined variables x1 , . . . , xn , Qi {, }, 1 n quantifier,
Cj , 1 j k clause form Cj = Lj,1 Lj,2 Lj,3 . Checking validity
canonical PSpace-hard problem.
rest proof, binary predicate P variables w0 wm , use
P (w0 , wm ) abbreviation P (w0 , w1 ) . . . P (wm1 , wm ), wi
0 < < variable occurring outside conjunction. Let Horn-SHI
TBox containing rules (144)(147) 1 n, rule (148) clause Cj
literal Lj,m = x` occurring Cj , rule (149) clause Cj literal Lj,m = x`
occurring Cj , rule (150), rule (151) 1 n Qi = , rule (152)
1 n Qi = .
Ai1 (x) y.[Xi+ (x, y) Ai (y)]

(144)

y.[Xi (x, y) Ai (y)]
Xi+ (x, x0 ) P (x, x0 )
Xi (x, x0 ) P (x, x0 )

(145)
(146)

(z, x) (x) Cj (x)

(148)

P n` (z, x) (x) Cj (x)

(149)

C1 (x) . . . Ck (x) Fn (x)

(150)

P (x, z) Fi (z) Fi1 (x)

(151)

Ai1 (x)

X`+ (z 0 , z)
X` (z 0 , z)

Xi+ (x, z)

P

Fi (z)

n`

Xi (x, z 0 )

794

0

Fi (z ) Fi1 (x)

(147)

(152)

fiAcyclicity Notions Existential Rules

Strictly speaking, rules (148), (149), (150), (152) Horn-SHI rules,
transformed Horn-SHI rules replacing parts bodies fresh concepts.
straightforward see WA.
Let = {A0 (a)}, let chase . Due rules (144)(145),
contains binary tree depth n leaf node reachable via path
that, 1 n, contains either Xi+ Xi . interpret presence Xi+
Xi assigning variable xi f, respectively, leaf node corresponds one
possible assignment x1 , . . . , xn . Rules (148) (149) clearly label leaf node
clauses true node, rule (150) labels leaf node Fn
clauses true. Finally, rules (151) (152) label interior node tree
Fi1 according semantics appropriate quantifier . Clearly, valid
|= F0 (a), implies claim.
next turn attention upper bounds complexity answering
BCQ MFA TBox, checking whether TBox MFA. Section 6.1
considered TBox singularised according marking , section assume
equality handled means explicit axiomatisation . explain
next, singularised rules local, makes PSpace membership
proof quite difficult. example, consider following singularised rule:
A(x) x x0 B(x0 ) C(x)

(153)

Atoms A(x) B(x0 ) rule share variables therefore need matched
locally chase Sing(T , ) I; furthermore, chase exponential size,
trivial see explored using polynomial space. Nevertheless,
conjecture possible extend proof singularised rules well; however,
details involved seem quite technical, without explaining much nature BCQ
answering equality. Therefore, leave problem open restrict
technically simpler case equality encoded explicitly using .
next show answering BCQ Q MFA Horn-SHIF TBox
instance performed polynomial space. proof uses well-known tracing
technique inspecting model using polynomial space. key aspect
result, however, dealing transitive roles query, allow query
embedded non-locally chase I. Note, however, guess
embedding Q result using nondeterministic polynomial time; furthermore,
since minimal Herbrand model (i.e., since Horn), check
entailment mapped atom Q separately, use wellknown encoding Demri de Nivelle (2005) handle transitive roles.
Theorem 64. Let Horn-SHIF TBox, let instance MFA w.r.t.
I, let Q BCQ. Then, checking whether |= Q PSpace-complete.
Proof. Hardness follows Lemma 63. next present nondeterministic polynomial
space algorithm decides |= Q; Savitchs Theorem, algorithm transformed deterministic polynomial space algorithm, proves claim.
Assume BCQ Q form Q = ~y .B1 . . . Bn . Furthermore, let = sk(T ).
Since regular atomic concept, always satisfiable chase
795

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

. Furthermore, |= Q substitution variables ~y
terms exists Bi 1 n; latter clearly holds
|= Bi . shown proof Theorem 10, term form
g1 (. . . g` (a) . . .), ` less equal number function symbols . Thus,
first step deciding |= Q examine possible check |= Bi
1 n; clearly done using deterministic Turing machine uses
polynomial space store , provided individual check |= Bi also
decided polynomial space.
Bi form C(t), let 0 = , let = C. Alternatively, Bi
form R(t0 , t), let 0 extended following rules, E
fresh concepts occurring I:
E(t0 )

(154)

E(z) R(z, x) D(x)

(155)

straightforward see |= R(t0 , t) 0 |= D(t). Let 00
obtained 0 deleting rule 0 form
R(x1 , z) R(z, x2 ) R(x1 , x2 )

(156)

and, role R occurring rule, replacing rule form
A(z) R(z, x) B(x)

(157)

following rules, QA,R,B fresh concept unique A, R, B:
A(z) R(z, x) QA,R,B (x)

(158)

QA,R,B (z) R(z, x) QA,R,B (x)

(159)

QA,R,B (x) B(x)

(160)

transformation corresponds well-known elimination transitivity Demri
de Nivelle (2005), 0 |= D(t) 00 |= D(t); proof claim
straightforward omit sake brevity.
Let 00 extended equality axioms (2) (4). Since occur
body rules 00 , 00 6|= D(t) 6|= D(t).
Let chase ; 6|= D(t) D(t) 6 . Note
contains rules Types 15 Table 1, rules (2) (4), possibly rules
form E(t1 ). facts used show assertion one
following forms, b constants, constant term contains
unary function symbols, f g unary function symbols, C atomic concept,
R atomic role:
C(t),
R(a, b), R(a, f (b)), R(f (b), a), R(t, f (t)), R(f (t), t),
f (g(t)), f (t) g(t), b, f (b), equality symmetric ones.
796

fiAcyclicity Notions Existential Rules

proof induction length chase sequence , claim
follows straightforwardly form rules Types 15. Motik et al. (2009b)
prove analogous claim general description logic, proof carries
setting syntactic changes.
say x central variable rule Type 1 3, z central
variable rule Type 2 4. W.l.o.g. assume body rule Type 5
contain inverse roles; then, x1 central variable rule Type 5. Finally,
equality replacement rules (4), central variable variable replaced.
Clearly, D(t) 6 Herbrand interpretation J exists assertions form mentioned above, J, J |= , D(t) 6 J. next
show check existence J using nondeterministic Turing machine
runs polynomial space.
Let f1 , . . . , fm function symbols occurring . first guess Herbrand interpretation J 0 constants satisfying J 0 , check whether rules
Type 1 satisfied J 0 . case, consider constant c J0
call following procedure = c = 1:
1. = + 1 return true.
2. Guess Herbrand interpretation J assertion J form
specified earlier involves least one term among f1 (s), . . . , fm (s).
3. D(t) J , return false.
4. Check whether equality symmetry rule (4) satisfied J ; not, return false.
5. Check whether J J i1 . . . J 0 satisfies rule central variable
rule mapped s; case rule, return false.
6. 1 k m, recursively call procedure fk (s) + 1; one
calls returns false, return false well.
7. Return true.
Assume procedure returns true constant c, let J union J
considered process. straightforward see J D(t) 6 J; furthermore,
J |= holds since satisfaction rule r J ascertained locally,
inspecting vicinity ground term mapped central variable r.
Furthermore, recursion depth algorithm recursion level need
keep polynomially sized interpretation J , algorithm implemented using
nondeterministic Turing machine uses polynomial space.
Theorem 65. Let Horn-SHIF TBox, let instance. Then, deciding
whether MFA w.r.t. PSpace, deciding whether universally MFA
PSpace-hard.
Proof. (Membership) Rules MFA(T ) almost Horn-SHIF rules: rule (19)
made Horn-SHIF rule replacing body (which clearly affect
consequences rule), fact rule (20) contains nullary atom
797

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

head immaterial. Thus, claim proved straightforward adaptation
membership proof Theorem 64. main difference algorithm that, n
function symbols, need examine models depth n+1; however, algorithm
still uses polynomial space.
(Hardness) Let arbitrary QBF, let hardness proof
Lemma 63. TBox WA; contains constant-free, equality-free, connected
rules; contain predicate zero arity. Hence, Lemma 7, Horn-SHI
TBox 0 exists valid 0 universally MFA.
finish section proving checking whether set Horn-SHI rules
universally MSA PTime-hard; way, also obtain matching lower bound
theorem Theorem 62 Section 6.1.
Theorem 66. Checking whether Horn-SHI TBox universally MSA PTime-hard.
Proof. Let N set Horn propositional clauses form v1 . . . vn vn+1
let v propositional variable; deciding N |= v well known PTime-hard. Let
Vi concept uniquely associated propositional variable vi ; let fresh
concept; let TBox obtained transforming propositional clause N
form rule (161).
A(x) V1 (x) . . . Vn (x) Vn+1 (x)

(161)

Finally, let = {A(a)}. Clearly, N |= v holds |= V (a) holds. TBox
WA, contains constant-free, equality-free, connected rules, predicate
zero arity; hence, Lemma 7, Horn-SHI TBox 0 exists N 6|= v holds
0 universally MFA. Finally, existential variable 0 occurs
rule form (23), straightforward see 0 universally MFA
0 universally MSA.

7. Experiments
estimate extent various acyclicity notions used practice, conducted two sets experiments. First, implemented MFA, MSA, JA, WA checkers,
used check acyclicity large corpus Horn ontologies. goal
see many ontologies acyclic could thus used (suitably extended)
materialisation-based OWL reasoners. Second, computed materialisation
acyclic Horn ontologies compared number facts materialisation.
goal tests see whether materialisation-based reasoning acyclic
ontologies practically feasible.
Tests performed Windows R2 Server two Intel Xeon 3.06GHz processors.
used repository 336 OWL ontologies whose TBox axioms transformed
existential rules least one rule contains existential quantifier head.
ontologies include large subset Gardiner ontology corpus (Gardiner, Tsarkov, &
Horrocks, 2006), LUBM ontology, several Phenoscape ontologies, number
ontologies two versions Open Biomedical Ontology (OBO) corpus. Please note
798

fiAcyclicity Notions Existential Rules

test ontology obtained conceptual models (e.g., ER models
UML diagrams): due specific modelling patterns used conceptual modelling,
ontologies less likely acyclic. test ontology accessed online
ontology repository means unique ID.5 ID identifies one self-contained OWL
ontology frozen time imports resolved time ontology added
repository; furthermore, possible future version ontology assigned
fresh ID. measures ensure experiments independently repeated
point future.
7.1 Acyclicity Tests
implemented acyclicity checks adapting HermiT reasoner.6 HermiT
used transform ontology DL-clausesformulae quite close existential rules.
result, at-least number restrictions head atoms replaced existential
quantification, atoms involving datatypes eliminated, DL-clauses
head atoms removed: datatypes empty heads cause inconsistencies,
cannot prevent skolem chase terminating.
set rules obtained preprocessing steps considered combination acyclicity notion X {WA, JA, MSA, MFA} follows. contain
equality predicate, simply checked whether X. contained equality predicate, checked whether X , also checked whether 0 X 0 set
rules contain equality predicate; tests provided us
lower upper bound acyclicity, respectively. acyclicity test performed
modifying (or 0 ) required X running HermiT check particular
logical entailment critical instance.
tests revealed MFA MSA indistinguishable 336 test ontologies;
is, MFA ontologies found MSA well (the converse holds per Theorem 14).
total 213 (63.4%) ontologies found MSA, including 43 49 (87.8%)
ontologies Gardiner corpus, 164 208 (78.8%) OBO ontologies,
LUBM ontology. contrast, GALEN ontology variants, GO ontology
extensions, 55 Phenoscape ontologies found MFA.
results summarised Table 2. Given large number ontologies tested, would
impractical present results ontology individually. Instead, ontologies
grouped number generating rules (G-rules), rules containing
existential quantifier; group, Table 2 shows total number ontologies, well
numbers ontologies found MSA, JA, WA. 123 ontologies
MFA, seven ontologies ELHr , CQ answering ontologies
realised using combined approaches Lutz et al. (2009) Kontchakov et al. (2011).
five older versions OBO ontologies (IDs 00359, 00374, 00376, 00382, 00486)
MSA, whereas newer versions (IDs 00360, 00375, 00377, 00383, 00487)
MFA. contrast, two older versions OBO ontologies MFA (IDs 00432
00574), newer versions (IDs 00433 00575) MSA.
5. URL http://www.cs.ox.ac.uk/isg/ontologies/UID/xxxxx.owl used download ontology
assigned ID xxxxx.
6. http://www.hermit-reasoner.com/

799

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

G-rules
< 100
1001K
1K5K
5K12K
12K160K

ontologies without equality
Total MSA JA
WA
44
42
42
41
69
62
62
41
38
31
30
24
28
23
16
14
18
7
6
5

ontologies equality
Total MSA JA WA
48
39
39
39
41
1
0
0
17
2
1
1
10
5
0
0
23
1
0
0

Table 2: Results acyclicity tests
Finally, found 15 large OBO ontologies (including different versions
ontologies) MSA JA. Thus, MSA seems particularly useful
complex ontologies since analyses implications existentially quantified variables
precisely previously known notions. Table 3 shows ontologies
number generating rules (G-rules), whether ontology uses equality predicate
(Eq), ontology expressivity description logic family languages (DL),
number classes (C), properties (P), axioms (A) ontology contains. Different
versions ontology distinguished table old new. Two
ontologies (IDs 00762 00766) containing equality predicate MSA ,
status regarding joint acyclicity unknown: JA rules involving
equality predicate deleted, JA .
7.2 Materialisation Tests
estimate practicability materialisation acyclic ontologies, measured
maximal depth function symbol nesting terms generated materialisation critical
instances. measure, call ontology depth, interest provides us
bound size materialisation. 213 MSA ontologies, test
succeeded 207 (tests aborted finish three hours).
latter ontologies, depth distributed follows:
123 (59.4%) ontologies depth less 5;
30 (14.5%) ontologies depth 5 9;
47 (22.7%) ontologies depth 10 19;
5 (2.4%) ontologies depth 20 49;
2 (1.0%) ontologies depth 50 70.
results leads us believe many (but clearly all) ontologies manageable
depths, allow successful materialisation-based query answering.
also computed materialisation several acyclic ontologies. implementation prototypical, primary goal evaluate performance computing
materialisation, rather estimate blowup number facts. clearly

800

fiAcyclicity Notions Existential Rules

Ontology ID G-rules Eq
DL
C
P

biological process xp cell.imports-local.owl
00371
7464
yes SHIF 17296 178
117925
biological process xp cellular component.imports-local.owl (old)
00374
8270
yes SHIF 18673 186
126796
biological process xp multi organism process.imports-local.owl (old)
00382
8378
EL++ 27900 18
295396
biological process xp plant anatomy.imports-local.owl (old)
00386
7559
yes SHIF 19146 193
122062
biological process xp plant anatomy.imports-local.owl (new)
00387
12025 yes SRIF 27412 215
213956
bp xp cell.imports-local.owl
00398
7419
yes SHIF 17296 177
117881
bp xp cellular component.imports-local.owl
00400
7999
yes SHIF 18676 175
126540
cellular component xp go.imports-local.owl (old)
00415
7752
EL++ 27890
8
210765
cellular component xp go.imports-local.owl (new)
00416
12269
EL++ 37254
9
334762
fypo.owl
00476
1834
EL++
1677
22
8027
go xp regulation.imports-local.owl (old)
00486
7777
EL++ 27891
5
295138
go xp regulation.owl (old)
00488
7777
EL++ 27883
5
214080
go xp regulation.owl (new)
00489
9507
EL++ 30170
6
238200
molecular function xp regulators.imports-local.owl (old)
00536
6762
EL++ 25521
5
198170
molecular function xp regulators.imports-local.owl (new)
00537
11089
EL++ 34135
8
316057
Table 3: MSA JA ontologies
expect blowup depend linearly size input number facts; however,
results provide us rough estimate performance materialisation-based
reasoning practice. test ontologies, however, contain many facts:
ontologies often constructed general vocabularies, facts often applicationspecific thus publicly available. overcome problem, conducted two
kinds experiments.
First, computed materialisation two ontologies contain facts: LUBM
one university (ID 00347), kmi-basic-portal ontology (ID 00078). TBox
LUBM eight generating rules depth one, 100, 543 facts ma801

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Depth

#

<5
59
1070

123
30
54

time
max avg
38
0.7
71
7
9396 1807

gen. size
max avg
65
2
122
30
1286 175

mat. size
max avg
89
8
132
38
1297 189

Table 4: Materialisation times (in seconds) sizes
terialisation. Materialisation took 2 seconds, produced 231, 200 new facts,
97, 860 added generating rules. kmi-basic-portal ontology ten
generating rules depth two, 198 facts materialisation. Materialisation took 0.03 seconds, produced 744 new facts, 145 added
generating rules.
Second, ontologies identified MSA, instantiated class
property fresh individuals. computed materialisation measured
generated size (the number facts introduced generating rules divided
number facts materialisation), materialisation size (the number facts
materialisation divided number facts materialisation), time needed
compute materialisation. Since generating rules ontologies singleton body atoms (i.e., form A(x) R.C(x)), measures provide
reasonable estimate increase number facts materialisation. Table 4
summarises results tests 207 ontologies test succeeded. Ontologies grouped depth, group shows number ontologies (#),
maximal average materialisation time, generated size, materialisation size.
Thus, materialisation seems practically feasible many ontologies: 123 ontologies
depth less 5, materialisation increases ontology size factor 8.
suggests principled, materialisation-based reasoning ontologies beyond OWL 2
RL profile may feasible, especially ontologies relatively small depths.

8. Conclusions
paper, investigated acyclicity notionssufficient conditions ensure termination skolem chase existential rules. proposed two novel notions, called MFA
MSA, determined tight complexity bounds membership checking, well
conjunctive query answering acyclic existential rules.
also conducted thorough investigation acyclicity notions known literature, produced complete taxonomy relative expressiveness. results
show MFA MSA generalise previously considered notions.
next investigated ways ensure acyclicity existential rules contain
equality predicate. end, presented several optimisations singularisation
technique Marnette (2009). optimisations often reduce number acyclicity
checks needed, thus making singularisation technique suitable practical use.
Finally, studied problem answering conjunctive queries acyclic DL ontologies. theoretical side, showed acyclicity make problem computation802

fiAcyclicity Notions Existential Rules

ally easier; furthermore, provided result acyclic, one extend Horn ontologies
arbitrary SWRL rules without affecting decidability worst-case complexity
query answering. practical side, investigated extent acyclicity
notions enable principled extensions materialisation-based ontology reasoners support existential quantification. tests show many ontologies commonly used
practice acyclic, blowup number facts due materialisation
manageable. suggests principled extensions materialisation-based ontology
reasoners practically feasible useful.
interesting topic future work see whether acyclicity notions used
general logic programming setting. see several main sources technical
difficulties towards goal. First, general logic programs contain functional terms
body atoms. terms cancel function symbols introduced head atoms,
clear take account acyclicity test. Second, logic programs
contain atoms nonmonotonic negation, likely need special treatment;
Magka, Krotzsch, Horrocks (2013) recently made first step direction. Third,
might desirable modularise ways different concerns handled
thus arbitrarily combine approaches handling function symbols body and/or
head approaches dealing nonmonotonic negation.

Acknowledgments
work supported Royal Society, Seventh Framework Program (FP7)
European Commission Grant Agreement 318338, Optique, EPSRC
projects ExODA, Score!, MaSI3 .

References
Abiteboul, S., Hull, R., & Vianu, V. (1995). Foundations Databases. Addison Wesley.
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2007). Description Logic Handbook: Theory, Implementation Applications
(2nd edition). Cambridge University Press.
Baget, J.-F. (2004). Improving Forward Chaining Algorithm Conceptual Graphs
Rules. Dubois, D., Welty, C. A., & Williams, M.-A. (Eds.), Proc. 9th Int.
Conf. Principles Knowledge Representation Reasoning (KR2004), pp. 407
414, Whistler, BC, Canada. AAAI Press.
Baget, J.-F., Leclere, M., Mugnier, M.-L., & Salvat, E. (2011a). rules existential
variables: Walking decidability line. Artificial Intelligence, 175 (910), 16201654.
Baget, J.-F., Mugnier, M.-L., & Thomazo, M. (2011b). Towards Farsighted Dependencies
Existential Rules. Rudolph, S., & Gutierrez, C. (Eds.), Proc. 5th Int.
Conf. Web Reasoning Rule Systems (RR 2011), Vol. 6902 LNCS, pp. 3045,
Galway, Ireland. Springer.

803

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Baumgartner, P., Furbach, U., & Niemela, I. (1996). Hyper Tableaux. Proc.
European Workshop Logics Artificial Intelligence (JELIA 96), No. 1126
LNAI, pp. 117, Evora, Portugal. Springer.
Beeri, C., & Vardi, M. Y. (1981). Implication Problem Data Dependencies.
Even, S., & Kariv, O. (Eds.), Proc. 8th Colloquium Automata, Languages
Programming (ICALP 1981), Vol. 115 LNCS, pp. 7385, Acre (Akko), Israel.
Springer.
Bishop, B., & Bojanov, S. (2011). Implementing OWL 2 RL OWL 2 QL rule-sets
OWLIM. Dumontier, M., & Courtot, M. (Eds.), Proc. OWL: Expreiences
Directions Workshop (OWLED 2011), Vol. 796 CEUR WS Proceedings, San
Francisco, UCA, USA.
Broekstra, J., Kampman, A., & van Harmelen, F. (2002). Sesame: Generic Architecture
Storing Querying RDF RDF Schema. Horrocks, I., & Hendler, J. A.
(Eds.), Proc. 1st Int. Semantic Web Conf. (ISWC 2002), Vol. 2342 LNCS,
pp. 5468, Sardinia, Italy. Springer.
Cal, A., Gottlob, G., Lukasiewicz, T., Marnette, B., & Pieris, A. (2010a). Datalog :
Family Logical Knowledge Representation Query Languages New Applications. Proc. 25th IEEE Symposium Logic Computer Science (LICS
2010), pp. 228242, Edinburgh, United Kingdom. IEEE Computer Society.
Cal, A., Gottlob, G., & Pieris, A. (2010b). Query Answering Non-guarded Rules
Datalog . Hitzler, P., & Lukasiewicz, T. (Eds.), Proc. 4th Int. Conf.
Web Reasoning Rule Systems (RR 2010), Vol. 6333 LNCS, pp. 117, Bressanone/Brixen, Italy. Springer.
Cal, A., Gottlob, G., & Pieris, A. (2011). New Expressive Languages Ontological Query
Answering. Burgard, W., & Roth, D. (Eds.), Proc. 25th National Conference
Artificial Intelligence (AAAI 2011), pp. 15411546, San Francisco, CA, USA. AAAI
Press.
Calimeri, F., Cozza, S., Ianni, G., & Leone, N. (2008). Computable Functions ASP:
Theory Implementation. Garcia de la Banda, M., & Pontelli, E. (Eds.), Proc.
24th Int. Conf. Logic Programming (ICLP 2008), Vol. 5366 LNCS, pp.
407424, Udine, Italy. Springer.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
Reasoning Efficient Query Answering Description Logics: DL-Lite Family.
Journal Automated Reasoning, 9 (3), 385429.
Carroll, J. J., Dickinson, I., Dollin, C., Reynolds, D., Seaborne, A., & Wilkinson, K. (2004).
Jena: Implementing Semantic Web Recommendations. Feldman, S. I., Uretsky,
M., Najork, M., & Wills, C. E. (Eds.), Proc. 13th Int. Conf. World Wide
Web (WWW 2004)Alternate Track, pp. 7483, New York, NY, USA. ACM.
Cuenca Grau, B., Horrocks, I., Krotzsch, M., Kupke, C., Magka, D., Motik, B., & Wang, Z.
(2012). Acyclicity Conditions Application Query Answering Description Logics. Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Proc. 13th Int.

804

fiAcyclicity Notions Existential Rules

Conf. Principles Knowledge Representation Reasoning (KR 2012), pp.
243253, Rome, Italy.
Cuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., & Sattler, U.
(2008). OWL 2: next step OWL. Journal Web Semantics: Science, Services
Agents World Wide Web, 6 (4), 309322.
Dantsin, E., Eiter, T., Gottlob, G., & Voronkov, A. (2001). Complexity expressive
power logic programming. ACM Computing Surveys, 33 (3), 374425.
De Schreye, D., & Decorte, S. (1994). Termination Logic Programs: Never-Ending
Story. Journal Logic Programming, 1920, 199260.
Demri, S., & de Nivelle, H. (2005). Deciding Regular Grammar Logics Converse
First-Order Logic. Journal Logic, Language Information, 14 (3), 289
329.
Deutsch, A., Nash, A., & Remmel, J. B. (2008). chase revisited. Lenzerini, M., &
Lembo, D. (Eds.), Proc. 27th ACM SIGMOD-SIGACT-SIGART Symposium
Principles Database Systems (PODS 2008), pp. 149158, Vancouver, BC, Canada.
Eiter, T., Gottlob, G., Ortiz, M., & Simkus, M. (2008). Query Answering Description
Logic Horn-SHIQ. Holldobler, S., Lutz, C., & Wansing, H. (Eds.), Proc.
11th European Conference Logics Artificial Intelligence (JELIA 2008), Vol. 5293
LNCS, pp. 166179, Dresden, Germany. Springer.
Fagin, R., Kolaitis, P. G., Miller, R. J., & Popa, L. (2005). Data exchange: semantics
query answering. Theoretical Computer Science, 336 (1), 89124.
Gardiner, T., Tsarkov, D., & Horrocks, I. (2006). Framework Automated Comparison
Description Logic Reasoners. Cruz, I. F., Decker, S., Allemang, D., Preist, C.,
Schwabe, D., Mika, P., Uschold, M., & Aroyo, L. (Eds.), Proc. 5th Int. Semantic
Web Conference (ISWC 2006), Vol. 4273 LNCS, pp. 654667, Athens, GA, USA.
Springer.
Gebser, M., Schaub, T., & Thiele, S. (2007). GrinGo: New Grounder Answer Set
Programming. Baral, C., Brewka, G., & Schlipf, J. S. (Eds.), Proc. 9th
Int. Conf. Logic Programming Nonmonotonic Reasoning (LPNMR 2007), Vol.
4483 LNCS, pp. 266271, Tempe, AZ, USA.
Glimm, B., Horrocks, I., Lutz, C., & Sattler, U. (2008). Conjunctive Query Answering
Description Logic SHIQ. Journal Artificial Intelligence Research, 31, 151198.
Greco, S., Spezzano, F., & Trubitsyna, I. (2012). Termination Logic Programs
Function Symbols. Dovier, A., & Santos Costa, V. (Eds.), Proc. 8th Int.
Conf. Logic Programming (ICLP 2012), Vol. 17 Leibniz International Proceedings
Informatics, pp. 323333, Budapest, Hungary.
Hastings, J., Magka, D., Batchelor, C., Duan, L., Stevens, R., Ennis, M., & Steinbeck, C.
(2012). Structure-based classification ontology chemistry. Journal Cheminformatics, 4 (8).
Horrocks, I., & Patel-Schneider, P. F. (2004). Proposal OWL Rules Language.
Proc. 13th Int. World Wide Web Conference (WWW 2004), pp. 723731, New
York, NY, USA. ACM Press.
805

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Horrocks, I., & Sattler, U. (2007). Tableau Decision Procedure SHOIQ. Journal
Automated Reasoning, 39 (3), 249276.
Horrocks, I., Patel-Schneider, P. F., Bechhofer, S., & Tsarkov, D. (2005). Owl rules:
proposal prototype implementation. J. Web Sem., 3 (1), 2340.
Hustadt, U., Motik, B., & Sattler, U. (2005). Data Complexity Reasoning Expressive Description Logics. Proc. 19th Int. Joint Conf. Artificial Intelligence
(IJCAI 2005), pp. 466471, Edinburgh, UK. Morgan Kaufmann Publishers.
Johnson, D. S., & Klug, A. C. (1984). Testing Containment Conjunctive Queries
Functional Inclusion Dependencies. Journal Computer System Sciences,
28 (1), 167189.
Kiryakov, A., Ognyanov, D., & Manov, D. (2005). OWLIM Pragmatic Semantic Repository OWL. Dean, M., Guo, Y., Jun, W., Kaschek, R., Krishnaswamy, S., Pan,
Z., & Sheng, Q. Z. (Eds.), Proc. Int. Workshop Web Information Systems
Engineering (WISE 2005), Vol. 3807 LNCS, pp. 182192, New York, NY, USA.
Kontchakov, R., Lutz, C., Toman, D., Wolter, F., & Zakharyaschev, M. (2011). Combined Approach Ontology-Based Data Access. Walsh, T. (Ed.), Proc. 22nd
Int. Joint Conf. Artificial Intelligence (IJCAI 2011), pp. 26562661, Barcelona,
Spain.
Krotzsch, M., & Rudolph, S. (2011). Extending Decidable Existential Rules Joining
Acyclicity Guardedness. Walsh, T. (Ed.), Proc. 22nd Int. Joint Conf.
Artificial Intelligence (IJCAI 2011), pp. 963968, Barcelona, Spain.
Krotzsch, M., & Rudolph, S. (2013). Relationship Joint Acyclicity SuperWeak Acyclicity. Tech. rep. 3037, Institute AIFB, Karlsruhe Institute Technology.
Available online http://www.aifb.kit.edu/web/Techreport3013.
Krotzsch, M., Rudolph, S., & Hitzler, P. (2007). Conjunctive Queries Tractable Fragment OWL 1.1. Aberer, K., Choi, K.-S., Noy, N. F., Allemang, D., Lee, K.-I.,
Nixon, L. J. B., Golbeck, J., Mika, P., Maynard, D., Mizoguchi, R., Schreiber, G.,
& Cudre-Mauroux, P. (Eds.), Proc. 6th Int. Semantic Web Conference (ISWC
2007), Vol. 4825 LNCS, pp. 310323, Busan, Korea. Springer.
Kutz, O., Horrocks, I., & Sattler, U. (2006). Even Irresistible SROIQ.
Doherty, P., Mylopoulos, J., & Welty, C. A. (Eds.), Proc. 10th Int. Conf.
Principles Knowledge Representation Reasoning (KR 2006), pp. 6878, Lake
District, UK. AAAI Press.
Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).
DLV system knowledge representation reasoning. ACM Transactions
Computational Logic, 7 (3), 499562.
Lierler, Y., & Lifschitz, V. (2009). One Decidable Class Finitely Ground Programs. Hill, P. M., & Warren, D. S. (Eds.), Proc. 25th Int. Conf. Logic
Programming (ICLP 2009), Vol. 5649 LNCS, pp. 489493, Pasadena, CA, USA.
Springer.
Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive Query Answering Description
Logic EL Using Relational Database System. Boutilier, C. (Ed.), Proc. 21st
806

fiAcyclicity Notions Existential Rules

Int. Joint Conf. Artificial Intelligence (IJCAI 2009), pp. 20702075, Pasadena, CA,
USA.
Magka, D., Krotzsch, M., & Horrocks, I. (2013). Computing Stable Models Nonmonotonic Existential Rules. Proc. 23rd Int. Joint Conf. Artificial Intelligence
(IJCAI 2013). AAAI Press/IJCAI. appear.
Magka, D., Motik, B., & Horrocks, I. (2012). Modelling Structured Domains Using Description Graphs Logic Programming. Simperl, E., Cimiano, P., Polleres, A.,
Corcho, O., & Presutti, V. (Eds.), Proc. 9th Extended Semantic Web Conference
(ESWC 2012), Vol. 7295 LNCS, pp. 330344, Heraklion, Greece. Springer.
Maier, D., Mendelzon, A. O., & Sagiv, Y. (1979). Testing Implications Data Dependencies. ACM Transactions Database Systems, 4 (4), 455469.
Marnette, B. (2009). Generalized schema-mappings: termination tractability.
Paredaens, J., & Su, J. (Eds.), Proc. 28th ACM SIGMOD-SIGACT-SIGART
Symposium Principles Database Systems (PODS 2009), pp. 1322, Providence,
RI, USA.
Marnette, B. (2010). Tractable Schema Mappings Oblivious Termination. Ph.D.
thesis, University Oxford, Oxford, UK.
Meditskos, G., & Bassiliades, N. (2008). Combining DL Reasoner Rule Engine
Improving Entailment-Based OWL Reasoning. Sheth, A. P., Staab, S., Dean, M.,
Paolucci, M., Maynard, D., Finin, T. W., & Thirunarayan, K. (Eds.), International
Semantic Web Conference, Vol. 5318 LNCS, pp. 277292, Karlsruhe, Germany.
Meier, M. (2010). Termination Chase Algorithm. Ph.D. thesis, Universitat
Freiburg.
Meier, M., Schmidt, M., & Lausen, G. (2009). Chase Termination Beyond Stratification.
Proceedings VLDB Endowment, 2 (1), 970981.
Motik, B., Cuenca Grau, B., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2009a). OWL 2
Web Ontology Language: Profiles, W3C Recommendation.
http://www.w3.org/TR/owl2-profiles/.
Motik, B., Shearer, R., & Horrocks, I. (2009b). Hypertableau Reasoning Description
Logics. Journal Artificial Intelligence Research, 36, 165228.
Mungall, C. (2009). Experiences Using Logic Programming Bioinformatics. Hill,
P. M., & Warren, D. S. (Eds.), Proc.of 25th Int. Conf. Logic Programming
(ICLP 2009), Vol. 5649 LNCS, pp. 121, Pasadena, CA, USA. Springer.
Ortiz, M., Calvanese, D., & Eiter, T. (2008). Data Complexity Query Answering
Expressive Description Logics via Tableaux. Journal Automated Reasoning, 41 (1),
6198.
Ortiz, M., Rudolph, S., & Simkus, M. (2011). Query Answering Horn Fragments
Description Logics SHOIQ SROIQ. Walsh, T. (Ed.), Proc. 22nd
Int. Joint Conf. Artificial Intelligence (IJCAI 2011), pp. 10391044, Barcelona,
Spain.

807

fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang

Perez-Urbina, H., Motik, B., & Horrocks, I. (2009). Tractable Query Answering Rewriting Description Logic Constraints. Journal Applied Logic, 8 (2), 151232.
Rudolph, S., & Glimm, B. (2010). Nominals, Inverses, Counting, Conjunctive Queries
or: Infinity Friend!. Journal Artificial Intelligence Research, 39, 429
481.
Spezzano, F., & Greco, S. (2010). Chase Termination: Constraints Rewriting Approach.
Proceedings VLDB Endownment, 3 (1), 93104.
Syrjanen, T. (2001). Omega-Restricted Logic Programs. Eiter, T., Faber, W., &
Truszczynski, M. (Eds.), Proc. 6th Int. Conference Logic Programming
Nonmonotonic Reasoning (LPNMR 2001), Vol. 2173 LNCS, pp. 267279, Vienna,
Austria. Springer.
Syrjanen, T., & Niemela, I. (2001). Smodels System. Eiter, T., Faber, W., &
Truszczynski, M. (Eds.), Proc. 6th Int. Conf. Logic Programming Nonmonotonic Reasoning (LPNMR 2001), Vol. 2173 LNAI, pp. 434438, Vienna, Austria. Springer.
Wu, Z., Eadon, G., Das, S., Chong, E. I., Kolovski, V., Annamalai, M., & Srinivasan, J.
(2008). Implementing Inference Engine RDFS/OWL Constructs UserDefined Rules Oracle. Alonso, G., Blakeley, J. A., & Chen, A. L. P. (Eds.), Proc.
24th Int. Conf. Data Engineering (ICDE 2008), pp. 12391248, Cancun,
Mexico. IEEE.

808

fiJournal Artificial Intelligence Research 47 (2013) 613-647

Submitted 1/13; published 7/13

Asymmetric Distributed Constraint Optimization Problems
Tal Grinshpoun
Alon Grubshtein

grinshpo@cs.bgu.ac.il
alongrub@cs.bgu.ac.il

Department Computer Science
Ben-Gurion University Negev
Beer-Sheva, Israel

Roie Zivan

zivanr@bgu.ac.il

Department Industrial Engineering Management
Ben-Gurion University Negev
Beer-Sheva, Israel

Arnon Netzer
Amnon Meisels

netzerar@cs.bgu.ac.il
am@cs.bgu.ac.il

Department Computer Science
Ben-Gurion University Negev
Beer-Sheva, Israel

Abstract
Distributed Constraint Optimization (DCOP) powerful framework representing
solving distributed combinatorial problems, variables problem
owned different agents. Many multi-agent problems include constraints produce
different gains (or costs) participating agents. Asymmetric gains constrained
agents cannot naturally represented standard DCOP model.
present paper proposes general framework Asymmetric DCOPs (ADCOPs).
ADCOPs different agents may different valuations constraints
involved in. new framework bridges gap multi-agent problems tend
asymmetric structure standard symmetric DCOP model. benefits
proposed model previous attempts generalize DCOP model discussed
evaluated.
Innovative algorithms apply special properties proposed ADCOP
model presented detail. include complete algorithms substantial
advantage terms runtime network load existing algorithms (for standard
DCOPs) use alternative representations. Moreover, standard incomplete algorithms
(i.e., local search algorithms) inapplicable existing DCOP representations
asymmetric constraints applied new ADCOP framework
often fail converge local optimum yield poor results. local search algorithms
proposed present paper converge high quality solutions. experimental evidence
presented reveals proposed local search algorithms ADCOPs achieve
high quality solutions preserving high level privacy.

1. Introduction
universe asymmetric persuaded life, known us,
direct result asymmetry universe indirect consequences. universe asymmetric. Louis Pasteur
c
2013
AI Access Foundation. rights reserved.

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

Multi-agent systems (MAS) often include combinatorial problem distributed
among agents. Examples multi-agent combinatorial problems Meetings
Scheduling problem (Modi & Veloso, 2004; Gershman, Grubshtein, Meisels, Rokach, &
Zivan, 2008), Sensor nets (Zhang, Xing, Wang, & Wittenburg, 2005; Zivan, Glinton, &
Sycara, 2009), Vehicle Routing (Leaute & Faltings, 2011). natural representation
problems terms agent-owned variables terms agent-specified values
combinations assignments (whether costs utilities), encouraged study Distributed Constraint Optimization Problems (DCOPs). DCOPs powerful framework
formulating solving MAS combinatorial problems. last decade algorithmic
search techniques DCOPs intensively studied (Yeoh, Felner, & Koenig, 2010; Petcu
& Faltings, 2006; Mailler & Lesser, 2004; Gershman, Meisels, & Zivan, 2009). Since DCOPs
NP-hard, many recent studies consider incomplete algorithms (Maheswaran, Pearce, &
Tambe, 2006; Zhang et al., 2005; Pearce & Tambe, 2007; Zivan, 2008; Rogers, Farinelli,
Stranders, & Jennings, 2011).
strong relation MAS DCOPs identified discussed previous
studies (e.g., Maheswaran et al., 2006; Chapman, Rogers, & Jennings, 2008). Chapman
et al. (2008) examine analogy DCOP formulation class games
known Potential Games. importance analogy lies fact every
finite potential game possesses least one pure strategy Nash Equilibrium (NE) (Monderer
& Shapley, 1996).
world game theory, pure strategy NE stable profile actions corresponding set participants, unilateral change action single
participant yield better personal gain participant. DCOP formulation, definition coincides special solutions known local optima (minima
maxima) (Yokoo, 2000; Zhang et al., 2005). solutions sets assignments
variables made agents, single change assignment agent
reduce global gain.
source correspondence NEs local optima stems constraint structure DCOPs. constraint C variables k agents defined
mapping domains variables single (positive) real value:
C : Di1 Di2 Dik R+
definition constraint implies cost (gain) constraint
participating agents. agent lowers cost gain constraint,
constrained peers share similar decrement cost constraint. Thus,
clear change assignment reduce personal gains reduces
global gains well.
many real life situations constrained agents value differently results decisions
constrained issues even consider constraints. fact, natural
scenario typical MAS situation following examples. meeting scheduling problem, agents attend meeting may derive different utilities it.
Moreover, preferences constraints regarding time location expected
different. Another example distributed application asymmetric
smart grid (Ramchurn, Vytelingum, Rogers, & Jennings, 2011), cost users pay
electricity may higher heavy load hours, yet increase price endured
614

fiAsymmetric Distributed Constraint Optimization Problems

respect agents use evenly spread among users. Supply chain management (Burke, Brown, Dogru, & Lowe, 2007) among multiple consumers might also include
asymmetric constraints. Different consumers different levels urgency regarding
time supply, therefore latency costs endure different.
observation calls generalization standard DCOP model (Modi,
Shen, Tambe, & Yokoo, 2005; Meisels, 2007). generalized model enable
representation asymmetric gains agents involved constraint. result,
applicable asymmetric MAS scenarios.
Former studies proposed capture asymmetric gains among constrained agents introducing additional variables agent. additional variables duplicates
variables constrained agents. agent holds duplications every variable
variables constrained with. imposing hard equality constraints variables
duplications model allows agent account constraints (Maheswaran, Tambe, Bowring, Pearce, & Varakantham, 2004b; Petcu, 2007). complete
scheme duplicating variables constrained agents using rigid constraints
enforce equality assignments agents termed Private Events Variables
(PEAV).
considering complete search, PEAV formulation indeed offers solvable representation asymmetric DCOP allows use algorithms designed solve
symmetric DCOPs. main consequence using model increment
problem size, (as demonstrated experimental evaluation present paper) NP-hard problem DCOP, devastating effect performance.
situation becomes complicated considering incomplete methods. Specifically, PEAV enable use standard local search algorithms solving asymmetric problems. present paper demonstrates every allocation satisfies
hard equality constraints PEAV local optimum cannot escaped local
search algorithms.
present study proposes Asymmetric DCOPs (ADCOPs), model representing
asymmetric combinatorial multi-agent problems. ADCOPs naturally accommodate constraints participating agents different gains costs. allows agent
hold evaluation different outcomes respect constraint involved
in.
shortcomings existing DCOP algorithms solving problems represented
proposed model triggers intensive algorithmic study:
1. complete search propose algorithms solve asymmetric problem without need expand number variables problem PEAV model.
advantages performance proposed algorithms state-of-the-art complete algorithms use PEAV representation demonstrated empirically.
2. incomplete (local) search propose algorithms able converge high
quality solutions solving asymmetric problems, contrast existing DCOP local search algorithms. proof guarantees convergence provided. proposed algorithms require exchange problems information among agents.
Thus, algorithms evaluated terms solution quality, terms
615

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

privacy well. empirical results present paper demonstrate
privacy loss proposed algorithms minor.
rest paper organized follows. proposed Asymmetric DCOP model
presented Section 2 along several alternatives representing asymmetric constraints within standard DCOP model. Section 3 introduces new complete search algorithms designated efficiently correctly solve asymmetric problems. Section 4
focuses local search. demonstrates incompatibility existing local search algorithms solving asymmetric problems proposes several novel asymmetric local search
algorithms. Section 5 includes extensive experimental evaluation complete search
algorithms local search algorithms. results experimental evaluation quite
conclusive. paper summarized conclusions drawn Section 6.

2. Asymmetric Distributed Constraint Optimization
First, standard DCOP model presented followed proposed generalization
captures asymmetric constraints. Next, alternatives representing asymmetric constraints standard DCOP model described.
2.1 Distributed Constraint Optimization Problems (DCOPs)
DCOP tuple hA, X , D, Ri. finite set agents A1 , A2 , ..., . X finite
set variables X1 , X2 , ..., Xm . variable held single agent (an agent may hold
one variable). set domains D1 , D2 , ..., Dm . domain Di contains
finite set values assigned variable Xi . R set relations (constraints).
constraint C R defines non-negative cost every possible value combination
set variables, form:
C : Di1 Di2 . . . Dik R+

(1)

binary constraint refers exactly two variables form Cij : Di Dj R+ .
binary DCOP DCOP constraints binary. value assignment pair
including variable, value variables domain. partial assignment (PA)
set value assignments, variable appears once. full assignment
solution partial assignment includes variables (vars(P A) = X ).
optimal solution full assignment aggregated minimal cost.
maximization problems, constraint utilities instead costs
solution full assignment maximal aggregated utility. rest paper, unless
stated differently, problems discussed minimization problems.
2.2 Asymmetric DCOPs (ADCOPs)
ADCOPs generalize DCOPs following manner: instead assuming equal payoffs
constrained agents, ADCOP constraint explicitly defines exact payoff
participant. is, domain values mapped tuple costs, one constrained
agent.
formally, ADCOP defined following tuple hA, X , D, Ri, A, X ,
defined exactly manner DCOPs. constraint C R
616

fiAsymmetric Distributed Constraint Optimization Problems

A2
A1 \

x





3, 4

6, 1

b

7, 2

5, 8

x

1

x

2

Figure 1: two agents interaction. left-hand side presents agents costs incurred
interaction Agent A1 possible value assignments either b
costs endure depicted left value cell. Agent A2 possible
value assignments x (costs right side). right-hand side
figure provides graphical presentation resulting ADCOP network.

asymmetric DCOP defines set non-negative costs every possible value combination
set variables, takes following form:
C : Di1 Di2 Dik Rk+

(2)

definition asymmetric constraint natural general MAS problems,
requires little manipulation formulating ADCOPs. applies agent
holds exactly one variable among k variables involved constraint C. note
several variables involved constraint held agent, length
vector costs representing constraint equal number agents involved
number variables.
Consider simple example two interacting agents presented Figure 1.
problem agent pays either left- right-hand side values depicted
bi-matrix Figure 1. Agent A1 controls variable x1 may assign either b
Agent A2 controls variable x2 may assign values x y. constraint
two interacting agents maps assignment pairs cost pairs. example, agent A1
assigns value b agent A2 assigns value x, A1 cost 7 A2 cost
2. often refer cost pairs two sides constraint. right-hand side
figure illustrates ADCOP formulation problem terms agents
variables (where single constraint presented full bi-matrix left).
noted although ADCOP model bears great resemblance
graphical games model (Kearns, Littman, & Singh, 2001) two models
fundamentally different. game-theoretic agents self-interested entities, ADCOP
agents cooperative nature always follow protocol (algorithm) even
risk personal degradation gain.
2.3 Alternatives Representing Asymmetric Constraints
Extending Distributed Constraint Reasoning (DCR) (Meisels, 2007) paradigm encompass asymmetric payoffs great interest considering real world problems. Typical
problems must often take account individual state agent (remaining battery life, user preferences, etc) rarely coincide. Several alternatives representing
asymmetric constraints DCOPs discussed former papers.
617

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

2.3.1 Disclosure Constraint Payoffs
simplest way solve MAS problems asymmetric payoffs DCOPs
disclosure constraint payoffs. is, aggregate values agents taking joint action. However, constraint disclosure reveals private information (preferences) (Greenstadt,
Pearce, & Tambe, 2006; Maheswaran, Pearce, Varakantham, Bowring, & Tambe, 2005;
Yokoo, K.Suzuki, & Hirayama, 2002) many times needs avoided.
2.3.2 Use Unary Constraints
possible technique representing preferences affecting different payoffs
introduction unary constraints. Constraints added variable participating
constraint additional costs generate asymmetry.
Proposition 1 exists asymmetric DCOP cannot expressed symmetric
DCOP addition unary constraints form UAi () = .
Proof: Consider example interaction depicted Figure 1. general solution
add unary constraint variable held agents. cost binary
constraint, B(, ), unary constraint variable UA (), UB () must consistent
cost incurred agent, described following set linear
equations:
UA1 (a) + B(a, x) = 3
UA1 (a) + B(a, y) = 6
..
.
UA2 (y) + B(b, y) = 8
set equations derived problem Figure 1 solution.

Corollary 2 Symmetric DCOPs addition unary constraints strictly less
expressive asymmetric DCOPs.
Proof: remains show every problem unary symmetric binary constraints represented asymmetric DCOP. Unary constraints integral part
asymmetric DCOP model, symmetric binary constraints inherently less expressive asymmetric ones. Consequently, every symmetric DCOP (with added unary
constraints) represented asymmetric DCOP.
unary constraints approach thus shown insufficient representing asymmetric constraints. precisely, approach fails properly capture cases
personal valuation state agent dependent upon assignments agents.
618

fiAsymmetric Distributed Constraint Optimization Problems

A2
A1 \

hx,

hy,

hx, b

hy, b

ha, x

7

54

55

111

ha,

60

7

108

64

hb, x

61

108

9

65

hb,

109

56

57

13

x

1
1

x

1
2

x

2
2

x

2
1

Figure 2: interaction Figure 1 formulated PEAV-DCOP. left-hand
side presents value possible end state. right-hand side provides
graphical representation resulting PEAV-DCOP network.

2.3.3 Private Events Variables (PEAV)
PEAV model (Maheswaran et al., 2004b) successfully captures asymmetric payoffs
within standard DCOPs. incurred cost PEAV model agent involves one
mirror variable per neighbors constraint network (i.e., constrained
variable held another agent). Consistency neighbors state variables imposed
set hard equality constraints. One way represent hard constraints assign
cost calculated specific problem (Maheswaran et al., 2004b).
resulting representation asymmetric MAS problem PEAV-DCOP much
larger terms variables constraints ADCOP. Figure 2 describes
interaction Figure 1 formulated according PEAV (note minimization
problem). example x11 x22 original variables x12 x21 mirror
variables generated PEAV formulation. upper bound value used hard
constraint example 50.
cost end state depicted table left-hand side figure.
example, top-left cell represents assignments x11 = a, x22 = x, consistent
values mirror variables. Consequently, cost (7) exactly sum costs
agents original MAS problem (Figure 1).
PEAV representation problem must accommodate mirror variables,
combinations values previously considered must also taken account.
example, top-right cell represents assignments x11 = a, x22 = y, mirror
variables consistent original variables (x12 = x, x21 = b). cost (111)
includes sum costs agents original MAS problem, agent
considers value mirror variable real value agent (3 8).
value, two upper bound values (50 each) added express inconsistency
mirror variables. Consequently, PEAV matrix 4 4, including 16 payoff values
quadratic increase size search space.

3. Asymmetric Distributed Complete Search
Although DCOPs NP-hard, large number former DCOP research dedicated
complete search algorithms (Modi et al., 2005; Yeoh et al., 2010; Petcu & Faltings, 2006;
619

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

A2
A1

x



A3
A1



j



3, 4

6, 1



3, 2

4, 1

b

7, 2

5, 8

b

1, 1

3, 2

A1

A2

A3

Figure 3: Example problem.
Mailler & Lesser, 2004; Gershman et al., 2009). Unfortunately, existing complete
DCOP algorithms cannot find optimal solution solving ADCOPs. elaborate
issue beginning section introduce several novel complete
ADCOP algorithms.
3.1 Complete Search Asymmetric Constraints
One may attempt solve ADCOPs simply using existing complete DCOP algorithms.
following scenario demonstrates shortcomings attempt. Consider
SyncBB algorithm (Hirayama & Yokoo, 1997). SyncBB chosen simplicity, however, demonstration relevant existing DCOP algorithms. SyncBB partial
assignment generated sequentially Current Partial Assignment (CPA) message (cf.,
Meisels, 2007). agent receives CPA, assigns variable overall
cost partial assignment minimal. Running Branch & Bound algorithm implies
whenever cost partial assignment becomes larger upper bound,
agent holds CPA backtracks agent it.
ADCOPs standard process correct. full cost partial
assignment must include constraints held agents participate it.
words, agent Ai assigns variables compute cost CPA
based evaluation, agents higher priority (i.e., ordered it)
holding constraints agents newly assigned variable own. Consider
example problem Figure 3. attempting solve problem using SyncBB,
parts constraints held lower priority agents constraint
evaluated. Thus, resulting solution hA1 = a, A2 = y, A3 = ji cost 2.
constraints held higher priority agents (A1 example) evaluated. real
cost solution considering sides constraints 12. actual solution
hA1 = b, A2 = x, A3 = ii cost 11.
Following example, clear existing complete DCOP algorithms
longer correct ADCOP model used. complete ADCOP algorithm
must allow agents participating constraint evaluate related assignments.
exception may OptAPO algorithm (Mailler & Lesser, 2006), since perform
distributed search order resolve conflicts (Grinshpoun & Meisels, 2008). Thus,
620

fiAsymmetric Distributed Constraint Optimization Problems

(mediator) agents perform search able generate centralized (symmetric)
problem solve it.
3.2 ADCOP Complete Search Algorithms
Solving asymmetric problem requires parts binary constraint
evaluated aggregated assignments cost. Similarly DCSP case (Brito,
Meisels, Meseguer, & Zivan, 2009) considering sides constraints generally
performed two ways. One strategy solve problem two phases. first
phase, full assignment reached considering one side constraint
phase performed using symmetric DCOP algorithm. second phase,
full cost assignment verified checking complementary part
involved constraints. second phase complete new bounds set, first
phase resumed search better solution entire search space covered.
Another strategy systematically check sides constraints reaching
full assignment, forming one-phase strategy. present paper refers checking
reversed-order part constraints back-checking. Back-checking performed
either synchronously asynchronously.
next present several innovative complete algorithms designed ADCOPs.
begin introducing two asymmetric versions SyncBB algorithm. first version,
SyncABB-2ph, follows two-phase strategy, version follows one-phase
strategy. also present Asynchronous Two-Way Bounding algorithm (ATWB),
asymmetric version AFB algorithm (Gershman et al., 2009). ATWB also follows
one-phase strategy naturally performs asynchronous back-checking.
3.2.1 Synchronous Asymmetric Branch & Bound 2-phase (SyncABB-2ph)
SyncABB-2ph algorithm combination SyncBB algorithm two-phase
strategy. phase algorithm works exactly SyncBB, agent counts
costs constraints lower-indexed agents. Phase completed full
assignment reached. standard (symmetric) SyncBB operating symmetric DCOP,
means new best solution new bound found. ADCOPs backchecking needed order verify reversed order parts constraints
increment cost beyond bound.
Algorithm 1 SyncABB-2ph: phase II
received hCPA BACK MSG, CPA, costi
1: f cost constraints higher-indexed agents (Ai+1 ...An )
2: cost + f B
3:
send hCPA MSG, CPAi
4: else Ai 6= A1
5:
send hCPA BACK MSG, CPA, cost + f Ai1
6: else
7:
B cost + f
8:
broadcast hNEW SOLUTION, CPA, Bi
9:
send hCPA MSG, CPAi
621

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

A1

CPA

CPA

A1=b
A2=y
A3=j

A1=b
A2=y
A3=i

A2

A3

A1

A2

Cost=8

Cost=9

(a)

A1

(b)

CPA

CPA

A1=b
A2=y
A3=i

A1=b
A2=y
A3=i

A2

A3

A3

A1

Cost=9

A2

A3

Cost=15

(c)

(d)

Figure 4: SyncABB-2ph example limited pruning.
phase II last agent (An ) sends preceding agent (An1 ) CPA BACK MSG
message. message includes CPA one-side cost gathered phase
I. agent receives CPA BACK MSG message (Algorithm 1) performs backchecking computing cost f constraints upper-indexed agents (line 1).
addition f cost CPA (the lower bound) reaches bound B (line 2),
point continue back-checking phase since value assignment must
replaced. ensure completeness algorithm, regardless agent identified
cost exceeded global bound (the lowest cost full assignment found far),
CPA must returned last agent (line 3). global bound
reached, back-checking continues preceding agent (lines 4-5) reaches A1 .
total cost CPA existing global bound, agent A1 updates
bound B (line 7) informs agents new best solution new bound (line
8). Next, phase resumed sending CPA back last agent (line 9).
solving process parts search space expected pruned.
fact, amount pruned search space faithfully reflects effectiveness Branch &
Bound algorithm. Lines 2 3 Algorithm 1 state global bound reached
back-checking phase, CPA returned last agent. Returning CPA
last agent means pruning. Consequently, run SyncABB-2ph
algorithm pruning achieved first phase. limits pruning
performed algorithm since first phase subset constraints
considered. shortcoming algorithm illustrated Figure 4.
value A2 assigned (stage a), CPA hA1 = b, A2 = yi. global look CPA
(that considers sides constraint) reveals cost 13, higher
current bound (11 stage search). Nevertheless, first phase
algorithm one side constraint evaluated, resulting cost 8. Thus,
622

fiAsymmetric Distributed Constraint Optimization Problems

CPA advances agent A3 also assigns value (stage b). bound passed
second phase (stage d), CPA returned back agent A3 , turn
assign value A3 = j.
demonstrated pruning problem may well result poor performance
SyncABB-2ph algorithm. Indeed, experimental evaluation supported conjecture,
two-phase approach abandoned.
3.2.2 Synchronous Asymmetric Branch & Bound 1-phase (SyncABB)
SyncABB algorithm combination SyncBB algorithm one-phase
strategy. step algorithm, agent adds assignment CPA
updates cost one side constraint, CPA sent back agents
already assigned variables update lower bound adding costs
backwards directed constraints (back-checking). done replacing CPA MSG
message sent value assignment next agent (as SyncBB SyncABB2ph) CPA BACK MSG message preceding agent.
Algorithm 2 SyncABB: back-checking
received hCPA BACK MSG, CPA, costi
1: j CP A.lastId
2: f cost constraint agent Aj
3: cost + f B
4:
send hCPA MSG, CPAi Aj
5: else Ai 6= A1
6:
send hCPA BACK MSG, CPA, cost + f Ai1
7: else Aj =
8:
B cost + f
9:
broadcast hNEW SOLUTION, CPA, Bi
10:
send hCPA MSG, CPAi
11: else
12:
CP A.cost cost + f
13:
send hCPA MSG, CPAi Aj+1
handling CPA BACK MSG SyncABB presented Algorithm 2. First,
important know identity j initiator back-checking (in SyncABB-2ph
always n). Consequently, agent (in SyncABB-2ph) replaced Aj (lines
2,4). Additionally, back-checking complete (reaches A1 ) Aj last
agent (line 11), algorithm simply sends CPA next assigning agent Aj+1 (line
13).
Figure 5 illustrates CPA moved agents SyncABB algorithm. given example shows run algorithm beginning search
process problem depicted Figure 3.
main motivation one-phase version global bound reached,
CPA returned initiator back-checking (line 4), many cases
. lead effective pruning search space comparison
two-phase strategy. behavior algorithm illustrated Figure 6.
623

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

CPA

CPA

A1=a
A2=x
A3=i

A1=a
A2=x
A3=i

A1

A2

A1

A3

A2

A3

Cost=4

Cost=0

(b)

(a)
CPA

CPA

A1=a
A2=x
A3=i

A1=a
A2=x
A3=i

A1

A2

A3

A1

A2

Cost=7

Cost=9

(c)

A1

A3

(d)

CPA

CPA

A1=a
A2=x
A3=i

A1=a
A2=x
A3=i

A2

A3

A1

Cost=9

A2

A3

Cost=12

(e)

(f)
Figure 5: SyncABB-1ph example.

A1

CPA

CPA

A1=b
A2=y
A3=j

A1=b
A2=y
A3=j

A2

A3

A1

Cost=8

A2

A3

Cost=13

(a)

(b)

Figure 6: SyncABB-1ph example effective pruning.

value A2 assigned (stage a), CPA includes hA1 = b, A2 = yi. backchecking performed (stage b) cost becomes 13 bound (11 stage
search) reached. CPA passed point back agent A2 . Consequently,
search space pruned (complete assignments hA1 = b, A2 = y, A3 = ii
hA1 = b, A2 = y, A3 = ji).
624

fiAsymmetric Distributed Constraint Optimization Problems

Proposition 3 SyncABB sound complete.
Proof: soundness SyncABB immediate since CPA sent forward assigning agent new assignment evaluated agents whose assignment
included CPA. words, CPA sent forward costs generated
addition new value assignment added lower bound CPA
(Algorithm 2, lines 12-13). includes complete assignment reported solution
(lines 8-10).
completeness SyncABB follows exhaustive search structure. partial assignments whose cost exceeds global bound extended therefore
existence solution lower cost solution found algorithm ruled
out.
Termination also follows exhaustive structure Branch & Bound algorithm partial assignment explored twice.

3.2.3 Asymmetric Two-Way Bounding (ATWB)
achieve larger degree asynchronicity, one build upon existing efficient
asynchronous DCOP algorithm, AFB (Gershman et al., 2009). AFB found perform faster competing complete algorithms DPOP ADOPT. AFB
algorithm agents assign CPA sequentially SyncBB, following assignment
assigning agent triggers asynchronous checks bounds sending copies CPA
via BOUND CPA messages agents yet assigned variables.
agents receive copies CPA calculate lower bound cost constraints hold assignments CPA. lower bound sent back
assigning agent via ESTIMATE message. assigning agent aggregates bounds
ESTIMATE messages receives updated lower bound exceeds
current upper bound, agent initiates backtrack.
AFB algorithm adjusted accommodate forward bounding backward bounding thus, adjusted solving ADCOPs. words, instead
sending assigned CPA back first assigning agent sequentially SyncABB,
copies CPA sent backwards agents whose assignments included
CPA. Agents receive copy CPA compute estimate send back
(forward) assigning agent standard AFB. refer version
Asynchronous Two-Way Bounding algorithm (ATWB).
ATWB algorithm follows pseudo-code AFB (Gershman et al., 2009)
several modifications. BOUND CPA messages sent forward backwards
whenever value assigned (procedure assign CPA). Additionally, last agent
cannot declare new solution receives estimates backward bounding.
Thus, handling ESTIMATE messages must revised new version given
Algorithm 3.
estimate message received agent checks whether new estimate reaches
global bound (line 2). case, new value assigned current
agent (line 3). case last agent backward estimates arrived
(line 4), agent declare new solution (lines 5-6) assign new value (line 7).
625

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

Algorithm 3 ATWB receive estimate
received (ESTIMATE, estimate)
1: save estimate
2: (CPA.cost + saved estimates) B
3:
assign CPA()
4: else CPA full assignment estimates arrived
5:
B CPA.cost + saved estimates
6:
broadcast (NEW SOLUTION, CPA, B)
7:
assign CPA()

case forward bounding, agent still know assignment
select therefore estimate lower bound cost constraints considering
values variables domain. contrast, agent Ai receives BOUND CPA
message agent Aj ordered (backward bounding), accurately compute
cost constraints assignment assignments CPA.
precomputed h2 (v, j) function (per value v, per agent Aj holds current CPA)
gives lower bound cost constraints agents Aj
order (Ak |k > j) added estimation computation. h2 (v, j) function
also used forward bounding lower bound back-checking value v
agents Ai Aj (Ak |j < k < i). h2 function additive, since refers
back-checking yet unassigned variables.
Proposition 4 ATWB sound complete.
Proof: soundness ATWB established fact new solution stored
later reported estimates arrive last agent (Algorithm 3, lines 4-6).
point, constraints evaluated involved agents. Note
estimates received last agent include (backward) constraints. possibility
estimate yet received agent (due delay messages)
compromise algorithms soundness. case delayed estimate would triggered
need backtrack, estimate sent agent last agent would least
high therefore would trigger backtrack well.
Similarly SyncABB, completeness termination ATWB follow
exhaustive structure Branch & Bound algorithm.

4. Asymmetric Distributed Local Search
Distributed local search techniques solving DCOPs gained popularity recent
years. Although local search algorithms inherently incomplete, i.e. guarantee report optimal solution, offer practical solution significantly larger
problems. Adding asymmetry problems makes complete solving process even
difficult, fact enhances suitability local search solving ADCOPs.
next present overview standard DCOP local search algorithms followed
discussion applicability asymmetric case. introduce several novel
local search algorithms designed solving ADCOPs.
626

fiAsymmetric Distributed Constraint Optimization Problems

4.1 Local Search
general design local search algorithms DCOPs synchronous. step
algorithm agent sends assignment neighbors constraint network
receives assignments neighbors. hereby present detail two leading
algorithms apply general framework Distributed Stochastic Algorithm
(DSA) (Zhang et al., 2005) Max Gain Message (MGM) algorithm (Maheswaran,
Pearce, & Tambe, 2004a).1
initial step DSA algorithm agents randomly pick value assignment
variable. Next, agents perform sequence steps termination condition
met. step, agent sends value assignment neighbors constraints
graph receives assignments neighbors. present paper follows general
definition DCOP include synchronization mechanism.
mechanism exists, agents DSA send value messages steps
change value assignments. collecting assignments neighbors,
agent decides whether keep value assignment change it, using stochastic
strategy (see Zhang et al., 2005 details possible strategies difference
resulting performance). sketch DSA presented Algorithm 4.
Algorithm 4 Standard DSA
1: value ChooseRandomValue()
2: termination condition met
3:
send value neighbors
4:
collect neighbors values
5:
ReplacementDecision()
6:
select assign next value
MGM algorithm strapped version DBA algorithm (Yokoo, 2000;
Zhang et al., 2005). every synchronous step, agent sends current value assignment
neighbors collects current value assignments. receiving assignments
neighbors, agent computes maximal improvement (i.e., reduction cost)
local state achieved replacing assignment sends proposed
reduction neighbors. collecting proposed reductions neighbors,
agent changes assignment proposed reduction greater reductions
proposed neighbors. advanced versions MGM, agents group together
order propose common improvement thus avoid local minima smaller
group would converged. Algorithm 5 includes sketch standard MGM algorithm.
selecting random value variable (line 1), agent enters loop
iteration step algorithm. sending value assignment neighbors
collecting value assignments (lines 3-4), agent calculates best weight reduction
sends neighbors (lines 5-6). receiving possible weight reductions
neighbors agent decides whether replace assignment upon positive
decision reassigns variable (lines 7-10).
1. description considers improvement decrease number violated constraints (as
Max-CSPs).

627

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

Algorithm 5 Standard MGM
1: value ChooseRandomValue()
2: termination condition met
3:
send value neighbors
4:
collect neighbors values
5:
LR BestPossibleLocalReduction()
6:
send LR neighbors
7:
collect neighbors LRs
8:
LR > 0
9:
LR > LRs neighbors (ties broken using indexes)
10:
value value gives LR

different incomplete approach solving DCOPs implemented Max-Sum
algorithm (Farinelli, Rogers, Petcu, & Jennings, 2008). Max-Sum algorithm operates
factor graph bipartite graph nodes represent variables
constraints.2 node representing variable original DCOP connected
function-nodes represent constraints involved in. Similarly, function-node
connected variable-nodes represent variables original DCOP
included constraint represents. Agents Max-Sum perform roles different
nodes factor graph. assume agent takes role variablenodes represent variables function-node, one agents whos
variable involved constraint represents, performs role. Variable-nodes
function-nodes considered agents Max-Sum, i.e., send messages, read
messages, perform computation.
content messages sent function-nodes different content messages
sent variable-nodes. message sent variable-node function-node includes
possible value assignments, sum costs/utilities value received
function neighbors. message sent function-node variable-node
includes possible value assignment variable best (minimal minimization problem, maximal maximization problem) cost/utility achieved
combination assignments variables involved function including
costs/utilities reported destination variable. end run variable
selects value assignment received best sum costs/utilities included
messages received recently neighboring function-nodes.
4.2 Local Search Asymmetric Constraints
Let us start discussion local search algorithms ADCOPs demonstrating
shortcomings existing local search methods.
Consider problem described Figure 1. Assuming agent aware
left (agent A1 ) right (A2 ) value matrix, standard DCOP local search algorithms
DSA MGM applied problem. DSA, example, agents
2. preserve terminology Farinelli et al. (2008) call constraint representing nodes factor
graph function-nodes.

628

fiAsymmetric Distributed Constraint Optimization Problems

consider personal gain, improvement, result change values according
local state. similar situation exists respect MGM. However, maximum
change reported agents running MGM necessarily imply improvement
neighbors well.
asymmetric structure constraints alters algorithms behavior. example,
DSA MGM converge local optima standard DCOPs, true
ADCOPs. local search, agents continuously attempt change value assignment
improving value assignment exists. value assignment found
agents state system whole said stable. state necessarily
local optimum asymmetric payoffs considered. change assignment
agent may increase local cost, due asymmetry change also result
overall lower cost system whole! hand, stable solutions
comply definition Nash Equilibria (NE) unilateral change single
agent improve state. similar reasons, MGM ADCOPs looses important
monotonicity property (Maheswaran et al., 2004a). Agents sending maximal possible
improvement current state neighbors actually consider change
would cause deterioration state neighbors global state.
Nash Equilibria necessarily coincide optimum global objective
function. well known example prisoners dilemma, maximizing gain
participants, globally worst solution NE. important note
NEs exist every asymmetric problem even presence NE,
possible neither DSA MGM converge it. Thus, convergence prediction
DCOPs made Chapman et al. (2008) apply case ADCOPs.
One may attempt run existing local search algorithms derived PEAV-DCOP
asymmetric cost problem (e.g., Figure 2). However, PEAV formulation significantly
reduces usefulness standard local search algorithms.
PEAV includes hard equality constraints pair variables variable
original DCOP duplication. Consider global assignment problem
violate constraints. attempt agent replace value
assignment one variables result violation hard constraint. Thus,
representation assignment original DCOP PEAV representation forms
local optimum.
Another way describe phenomenon pointing PEAV formulation
generates new local optima, thus, implicitly, new NEs. new local optima
easily observed main diagonal cost matrix Figure 2. considering
analyzing personal costs agent interaction one sees
correspond NEs. implies PEAV formulation given problem produces
new stable points (local optima)! case example Figure 2, four new NEs
generated originally none.
PEAV formulation solve problems standard local search
algorithms. case DSA, agent considers current assignments
neighbors. case MGM, every change variable would generate inequality
would considered maximal reduction.
629

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

Algorithm 6 ACLS
1: value ChooseRandomValue()
2: termination condition met
3:
send value neighbors
4:
collect neighbors values
5:
IMP SET LocalReductions()
6:
P V RandomSelectProposedValue(IMP SET )
7:
send P V neighbors
8:
collect neighbors P V
9:
foreach neighbor
10:
send constraint cost P V
11:
collect constraint costs
12:
cost SumOfAllConstraintsCosts() C
13:
cost < currentState
14:
assign probability p: value P V

4.3 ADCOP Local Search Algorithms
aforementioned shortcomings standard local search algorithms ADCOP
model PEAV formulation call development new local search algorithms
specifically designed ADCOPs. algorithms attempt incorporate information agents local neighborhood utilize locate high quality solutions
presented next.
4.3.1 Asymmetric Coordinated Local Search (ACLS)
ACLS algorithm presented Algorithm 6, attempts combine information
agents surrounding order produce global evaluation.
proceeds synchronous steps continues running (after random initial assignment) termination condition met. step, agent running ACLS begins
sending current assignment neighbors collecting assignments
(lines 3-4). collects assignments improve local state (line 5). Based
improving set proposed assignment P V randomly picked according distribution gains proposal (line 6). proposal sent neighbors
neighbors proposals collected (lines 7,8). agent receiving proposal responds
value side constraint resulting current assignment
proposed assignment (lines 9-10). impact messages arrive, agent assesses
potential gain loss assignment (lines 11-12). ACLS agents use special
coordination value, C, representing amount cooperation neighborhood.
is, constant zero, impact messages ignored ACLS produces
results similar DSA (albeit high overhead network load privacy
degradation). agent running ACLS concludes round committing change
probability p (lines 13-14). use probability parameter p similar
use p DSA (Zhang et al., 2005). prevents many concurrent changes
neighborhood may cause thrashing.
630

fiAsymmetric Distributed Constraint Optimization Problems

Algorithm 7 MCS-MGM
1: value ChooseRandomValue()
2: termination condition met
3:
send value neighbors
4:
collect neighbors values
5:
foreach neighbor
6:
increase due new value
7:
> last known LR
8:
send constraint cost new value
9:
change constraint cost new value 0
10:
collect neighbors constraint updates
11:
update constraint neighbors
12:
LR BestPossibleLocalReduction()
13:
send LR neighbors
14:
collect neighbors LRs
15:
LR > 0
16:
LR > LRs neighbors (ties broken using indexes)
17:
value value gives LR
4.3.2 Minimal Constraint Sharing MGM (MCS-MGM)
Similarly ACLS, MCS-MGM algorithm presented Algorithm 7 also attempts
employ knowledge local neighborhood achieve better gain surroundings.
MCS-MGM algorithm also proceeds synchronous steps terminates according
predefined condition. step consists three different interaction phases.
agent begins exchanging assignments neighbors (lines 3-4). evaluates
impact neighbors assignment change local state. neighbors
assignment change degrades current state neighbors last known best
local reduction, constraint passed neighbor. is, agent sends
neighbor side constraint neighbors new value, assigns cost
zero instead (lines 5-9). updated constraints gathered local sub-problem
slightly modified (lines 10-11). Using new information, agent seeks best local
reduction sends information peers (lines 12-13). MGM, agents
declaring highest local reductions change values (lines 14-17).
4.3.3 Guaranteed Convergence Asymmetric MGM (GCA-MGM)
small adjustment MCS-MGM guarantee convergence local optima (note
converges local optima NE). Line 7 replaced by:
7:

> 0

call resulting algorithm Guaranteed Convergence Asymmetric MGM (GCAMGM). guaranteed convergence comes price. GCA-MGM expected preserve
less privacy MCS-MGM since weaker condition exchanging constraints
among agents (see Section 5).
631

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

Proposition 5 GCA-MGM guaranteed converge local optimum finite number
steps.
Proof: Assume GCA-MGM converge. Consequently, agents repeatedly
changing value assignments. change causes increase agent triggers constraint exchange therefore next time assignment change performed,
cause increase (i.e., cannot occur once). Thus, number increases cost bounded number constraints, finite. possible
increments caused exchange constraints, convergence guaranteed
standard MGM (Maheswaran et al., 2004b; Pearce & Tambe, 2007).
experiments (Section 5) demonstrate although MCS-MGM guarantee
convergence, versions converge rapidly. rapid convergence strong
impact privacy loss search process (Section 5.2).

5. Experimental Evaluation
experimental evaluation divided two parts. first part, performance
complete ADCOP algorithms presented Section 3 compared
performance standard state-of-the-art complete DCOP algorithms solving asymmetric problems represented PEAV formulation. Two standard measures
performance complete algorithms used runtime network load.
second part experimental evaluation, proposed ADCOP local search
algorithms compared state-of-the-art local search algorithms solving DCOPs.
focus evaluation incomplete algorithms quality solution
produce given limited run time. demonstrated experimental evaluation, proposed ADCOP local search algorithms converge high quality solution,
contrast standard incomplete methods converge.
privacy loss incurred running ADCOP algorithms (both complete
local search) also great interest. Following Greenstadt et al. (2006) Brito et al.
(2009), privacy loss measured terms entropy.
Several domains evaluation used. first domain, random asymmetric MaxDisCSP, used evaluate complete local search algorithms. Max-DisCSP
subclass DCOP constraint costs equal one (Modi et al., 2005). MaxCSPs commonly used experimental evaluations constraint optimization problems
(COPs) (Larrosa & Schiex, 2004) Distributed COPs (Gershman et al., 2009). MaxDisCSPs classified number agents n (assuming holds exactly one variable),
size domains k, probability constraint among pair variables p1 ,
probability occurrence violation (a non-zero cost) among two value
assignments p2 . formulation consider constraint tightness p2 average
fraction forbidden value pairs, viewed agent involved given constraint.
implies pairs allowed one involved agents disallowed
other, vice versa. result, fraction cost-inflicting pairs greater p2
value. refer fraction p2ef f . expected value is:
p2ef f = 1 (1 p2 )2
632

(3)

fiAsymmetric Distributed Constraint Optimization Problems

second evaluation domain random graphical games (Kearns et al., 2001;
Nisan, Roughgarden, Tardos, & Vazirani, 2007; Maheswaran et al., 2004a). problems, constraint two agents represents local randomly generated game.
local interactions, constrained agent assigned cost joint action (value
assignment pair) two constrained agents. goal agents reach globally
minimal cost assignment. evaluation ADCOP local search algorithms, general-form
graphical games, well scale-free networks, used. details domains
given Section 5.2.
order evaluate runtime performance algorithms, measure NonConcurrent Logical Operations (NCLOs) (cf., Netzer, Grubshtein, & Meisels, 2012).
measure, based notion atomic operations (Gershman, Zivan, Grinshpoun, Grubshtein, & Meisels, 2008), generalization NCCCs (Zivan & Meisels, 2006).
NCLOs enable comparison runtime performance algorithms basic
operation necessarily Constraint Check, ODPOP (Petcu & Faltings, 2006).
5.1 Evaluation ADCOP Complete Search Algorithms
evaluation ADCOP complete search algorithms consists three experiment
settings two settings random asymmetric Max-DisCSPs, followed graphical games
setting. 50 random instances generated set experiments results
averaged 50 instances.
first set experiments, random asymmetric Max-DisCSPs 10 agents (n =
10), 10 values (k = 10), constraint density p1 = 0.4, varying constraint tightness
0.1 p2 0.9 generated. Figures 7 8 present runtime network load
results running proposed ADCOP algorithms. Figure 7 presents results
mean number NCLOs. algorithms, measure Constraint Checks, i.e.,
NCCCs. results show SyncABB outperforms ATWB problems.
suggests asynchronicity actually impairs performance ADCOPs, contrast
symmetric case DCOPs. Verifying bound sending CPA backwards
sequentially resuming search efficient continuing search
bounds checked asynchronously. problems become tighter, effectiveness
two-way bounding increases. tight problems (p2 = 0.9) performance ATWB
close SyncABB.
results total number sent messages presented Figure 8. expected
network load ATWB higher SyncABB due overhead added
BOUND CPA ESTIMATE messages.
second set experiments, asymmetric Max-DisCSPs 6 agents (n = 6), 6
values (k = 6), constraint density p1 = 0.5, varying constraint tightness 0.1 p2 0.9
randomly generated. value p1 (0.5) chosen ensure
generated constraint graphs connected, important faithful evaluation
algorithms employ pseudo-tree (BnB-ADOPT ODPOP). Applying PEAV
formulation, equivalent set symmetric problems also generated, enabling
comparison performance existing DCOP algorithms. symmetric formulation
much larger terms variables number constraints corresponding
ADCOPs forcing use relatively small problems.
633

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

10,000,000,000

SyncABB

1,000,000,000

ATWB

NCLOs

100,000,000
10,000,000
1,000,000
100,000
10,000
1,000
100
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Problem tightness (P2)

Figure 7: Mean NCLOs complete algorithms asymmetric Max-DisCSPs (10 agents).
10,000,000,000

SyncABB

Sent messages

1,000,000,000

ATWB

100,000,000
10,000,000
1,000,000
100,000
10,000
1,000
100
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Problem tightness (P2)

Figure 8: Sent messages complete algorithms asymmetric Max-DisCSPs (10 agents).
setup, runtime network load six algorithms compared.
included proposed ADCOP algorithms SyncABB ATWB, well several state-ofthe-art DCOP algorithms (solving symmetric problems) SyncBB (Hirayama & Yokoo,
1997), AFB (Gershman et al., 2009), BnB-ADOPT (Yeoh et al., 2010), ODPOP (Petcu
& Faltings, 2006).
Figures 9 10 present results second setup. Unlike algorithms,
main computational operation ODPOP comparison combinations assignments sent computing agent offspring pseudo tree (Petcu & Faltings,
2006). Figure 9 presents runtime terms NCLOs six algorithms. ADCOP algorithms show lower runtime several orders magnitude compared SyncBB,
AFB, ODPOP. ODPOP ran heap memory (heap set 2GB) relatively tight
problems (p2 0.5). surprising, since memory ODPOP requires
exponential induced width constraint graph (Petcu & Faltings, 2006).
PEAV formulation results sparse problems. PEAV representation
asymmetric problem 10 variables p1 = 0.4 includes 46 variables density
p1 = 0.07. Consequently, BnB-ADOPT, efficient solving sparse problems, well displays runtime performance comparable ADCOP algorithms.
634

fiAsymmetric Distributed Constraint Optimization Problems

1,000,000,000

SyncABB

100,000,000
ATWB

NCLOs

10,000,000

SyncBB
(PEAV)
AFB
(PEAV)
BnB-ADOPT
(PEAV)
ODPOP
(PEAV)

1,000,000
100,000
10,000
1,000
100
10
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

Problem tightness (P2)

Figure 9: Mean NCLOs complete algorithms asymmetric Max-DisCSPs (6 agents).
1,000,000,000

SyncABB

Sent messages

100,000,000

ATWB

10,000,000
SyncBB
(PEAV)
AFB
(PEAV)
BnB-ADOPT
(PEAV)
ODPOP
(PEAV)

1,000,000
100,000
10,000
1,000
100
10
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

Problem tightness (P2)

Figure 10: Sent messages complete algorithms asymmetric Max-DisCSPs (6 agents).
However, demonstrated Figure 10, incurs high network load. fact, none
algorithms solving symmetric DCOPs (PEAV) managed complete first set
experiments (with 10 agents) due high runtime and/or network load.
third set experiments, graphical games 6 agents (n = 6), 6 values (k = 6),
varying node degree randomly generated. average node degrees used spanned
2.5 5 (which indicates complete graph). constraint matrix included 50%
zeroes, rest assignment pair values random values range [0..9].
setting particulary interesting shows varying density (node degree) effects
performamce algorithms.
Figures 11 12 present results third setup linear scale. results
indicate increased density (node degree) minor effect performance ADCOP
algorithms. hand, density problems increases, performance
BnB-ADOPT drastically impaired. suspected, number sent messages
especially high BnB-ADOPT. DCOP algorithms (using PEAV formulation)
able complete graphical games set experiments.
average privacy loss incurred running complete ADCOP algorithms
first problem setup presented Figure 13. Following Brito et al. (2009),
635

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

NCLOs

500000

SyncABB

400000

ATWB

300000

BnB-ADOPT
(PEAV)

200000

100000
0
2.5

3

3.5

4

4.5

5

Node degree

Figure 11: Mean NCLOs complete algorithms graphical games.

Sent messages

1000000

SyncABB

800000

ATWB

600000

BnB-ADOPT
(PEAV)

400000
200000
0

2.5

3

3.5

4

4.5

5

Node degree

Figure 12: Sent messages complete algorithms graphical games.
100%

Privacy loss

SyncABB
ATWB

80%

60%
40%
20%
0%

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Problem tightness (P2)
Figure 13: Privacy loss complete algorithms asymmetric Max-DisCSPs (10 agents).
privacy results calculated comparing percentage lost entropy end
computation initial entropy. results clearly indicate ATWB higher
636

fiAsymmetric Distributed Constraint Optimization Problems

10,000,000,000

SyncABB

1,000,000,000

ATWB

NCLOs

100,000,000

SyncBB

10,000,000

AFB

1,000,000
100,000

10,000
1,000

100
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Problem tightness (P2)

Figure 14: Mean NCLOs complete algorithms asymmetric Max-DisCSPs (10 agents).
10,000,000,000

SyncABB

Sent messages

1,000,000,000

ATWB

100,000,000

SyncBB

10,000,000

AFB

1,000,000
100,000
10,000

1,000
100
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Problem tightness (P2)

Figure 15: Sent messages complete algorithms asymmetric Max-DisCSPs (10 agents).
degree average privacy preservation compared SyncABB. surprising
one considers ATWB information revealed single direction,
SyncABB decreases entropy agents lower higher priority.
additional method solving problems asymmetric constraints aggregate
sides constraints simply run symmetric DCOP algorithm (Section 2.3.1).
clear downside alternative private constraint information disclosed
a-priory. interesting investigate attempt keep constraint information
private (by using ADCOPs) affects performance. following figures present experiments
performance ADCOP algorithms, SyncABB ATWB, compared
performance symmetric variants using constraints disclosure. Figures 14
15 four algorithms compared running first problem setup.
comparison SyncABB symmetric SyncBB one observe SyncABB performs 30%-40% NCLOs SyncBB, network load SyncABB
bellow one order magnitude higher SyncBB. results indicate
impact performance using ADCOPs preserving portions private
information reasonable. Different outcomes follow comparison ATWB
symmetric AFB, number NCLOs ATWB almost two orders magnitude
637

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

120,000
SyncABB

NCLOs

100,000

ATWB

80,000

SyncBB

60,000

AFB

40,000
20,000
0
2.5

3

3.5

4

4.5

5

Node degree

Figure 16: Mean NCLOs complete algorithms graphical games.
50,000

Sent messages

SyncABB
40,000

ATWB
SyncBB

30,000

AFB
20,000
10,000
0
2.5

3

3.5

4

4.5

5

Node degree

Figure 17: Sent messages complete algorithms graphical games.
larger AFB tight problems. gap even greater considering
network load.
graphical games setup, simple branch bound effective (due
variance costs), performance impairment proposed ADCOP algorithms
even refined. Figure 16 shows symmetric SyncBB outperforms SyncABB
terms runtime 25% higher density problems. gap ATWB
symmetric AFB also relatively low, ATWB 5 times faster AFB. Moreover,
variance costs renders SyncABB performs less NCLOs symmetric AFB
higher density problems. gaps network load slightly larger, shown
Figure 17.
ADCOP algorithms prevent a-priori loss private information, results
given Figure 13 reveal relatively hard problems, major part private
information revealed all. additional experiment, extent privacy loss
limited stopping search process whenever amount private information
agent gained passed predefined threshold. Figures 18 19 present
outcomes limitation terms solution quality (distance cost optimal
solution) problems first setup p2 = 0.3 p2 = 0.5, respectively.
638

fiAsymmetric Distributed Constraint Optimization Problems

6

SyncABB

Solution cost

5

ATWB

4
3
2
1
0
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%

Maximal gain private data

Solution cost

Figure 18: Solution quality limiting maximal gain private information complete algorithms asymmetric Max-DisCSPs (10 agents, p1 = 0.4, p2 = 0.3).
10
9
8
7
6
5
4
3
2
1
0

SyncABB
ATWB

10% 20% 30% 40% 50% 60% 70% 80% 90% 100%

Maximal gain private data
Figure 19: Solution quality limiting maximal gain private information complete algorithms asymmetric Max-DisCSPs (10 agents, p1 = 0.4, p2 = 0.5).

specific p2 values chosen, since p2 = 0.3 represents rather tight still satisfiable
problems, p2 = 0.5 represents harder problems mostly unsatisfiable.
p2 = 0.3 solution cost drastically reduces threshold raised maximal
private information gain 60% algorithms reach optimal solution. average
privacy loss case considerably lower around 10% algorithms (see
Figure 13). p2 = 0.5 agent usually gains private information order
reach optimal solution, seen Figure 13, average privacy loss
agents much lower.
interesting threshold values maximal gain private information
ATWB higher SyncABB, shown average privacy loss
639

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

ATWB lower (Figure 13). reason phenomenon ATWB agents
gain private information predecessors, commonly last agents order
gain information, first agent gains none. result average
agent running ATWB looses less privacy agent running SyncABB, SyncABB
privacy loss better distributed among agents. last experiment illustrates
clear tradeoff privacy loss solution quality running ADCOP algorithms
privacy gain threshold.
5.2 Evaluation ADCOP Local Search Algorithms
introduced local search algorithms evaluated three domains asymmetric MaxDisCSPs, general-form graphical games, scale-free networks. type problem,
500 different problem instances 200 agents domain size 10 values per agent
generated. presented results average 500 solutions obtained
algorithms instances. Asymmetric Max-DisCSPs generated average
10 neighbors per agent (density parameter p1 = 0.05) tightness parameter p2 = 0.7.
rest details described asymmetric Max-DisCSPs generated
evaluate complete algorithms. general-form graphical games agents average
5 neighbors each, i.e., agents connected asymmetric constraint probability
value p = 0.025 (Erdos-Renyi graphs) (Erdos & Renyi, 1960). scale-free networks
domain, graphs constructed following Barabasi-Albert model (Jackson, 2008).
two latter setups constraint costs selected range [0..100]. Costs
separately selected non uniform manner cost agent 0 probability
0.35 uniformly selected range [1..100] probability 0.65. structure
ensures improving assignment change one agent increase cost incurred
neighbors (cf. Equation 3).
scale-free networks built using Barabasi-Albert model. initial set
10 agents randomly selected connected. iteration Barabasi-Albert
procedure agent added connected 4 agents probability
proportional number links existing agents already have.
large number algorithms examined. include DSA, MGM, MGM-2, MaxSum, ACLS, MCS-MGM, GCA-MGM. algorithms executed maximum
200 cycles, cycle includes actions two consecutive value messages
sent agent (Max-Sum cycles include messages function-nodes
variable-nodes vise versa).
Figure 20 presents average solution quality asymmetric Max-DisCSPs
algorithms function cycles. MCS-MGM produced highest quality results
200 cycles best algorithms MCS-MGM, MGM-2, ACLS, GCAMGM, performance two latter algorithms similar. three ADCOP
algorithms demonstrated fast convergence. highest costs (e.g., worst solutions)
reported Max-Sum, explore much search space reported
incurred cost significantly higher reported algorithms. Consequently,
results Max-Sum left plots enable better view overall
performance remaining algorithms (and correct scale). Surprisingly, DSA produced
solutions significantly lower quality MGM. contrast performance
640

fiAsymmetric Distributed Constraint Optimization Problems

Solution cost

180

MCS-MGM

160

GCA-MGM

140

ACLS
MGM2

120
MGM

100

DSA

80
0

50

100

150

200

Cycles

Figure 20: Solution quality local search algorithms asymmetric Max-DisCSPs
12000
MCS-MGM

Solution cost

10000

GCA-MGM

8000

ACLS

6000

MGM2
MGM

4000

DSA

2000
0

50

100

150

200

Cycles

Figure 21: Solution quality local search algorithms Erdos-Renyi graphs
solving symmetric problems, DSA known produce higher quality solutions
MGM.
Figures 21 22 present similar results average solution quality graphical
games scale-free networks, respectively. notable MCS-MGM dominates
problem scenarios. GCA-MGM produces better results MGM-2 graphical games,
results similar quality scale-free networks. DSA Max-Sum produced
low quality results problem scenarios well.
worth noting MGM-2, agent optimizing another agent
cause increase valuation proposed alternative state neighboring
agents both. result, agents optimizing different pairs generate loops
assignment changes described MGM. Thus, increase size group
agents considered optimizing agent sufficient ensure convergence.
similar phenomenon, MGM-2 eventually fail provide higher quality solutions
even MGM, reported presence uncertainty (Taylor, Jain, Tandon, &
Tambe, 2009).
problem scenarios evaluated, ACLS produced results lower quality MCSMGM GCA-MGM (except similar results asymmetric Max-DisCSPs). How641

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

1200

MCS-MGM

Solution cost

1000

GCA-MGM

800

ACLS

600

MGM2

400

MGM
DSA

200
0

50

100

150

200

Cycles

Figure 22: Solution quality local search algorithms scale-free networks

Privacy loss

100%
80%

MCS-MGM

60%

GCA-MGM

40%

ACLS

20%

MGM2

0%
0

50

100

150

200

Cycles

Figure 23: Privacy loss local search algorithms asymmetric Max-DisCSPs
ever, also observable ACLS fastest algorithm converge three problem
scenarios.
results indicate cooperation inherent three proposed algorithms, ACLS, MCS-MGM, GCA-MGM, renders algorithms better suite
asymmetric case algorithms. However, despite lower costs attributed
cooperation, nature agents requires revelation private information. Thus, important asses privacy loss resulting coordination
agents, contrast standard local search (1-opt) algorithms preserve high level
privacy (Greenstadt, 2008). measure overall loss privacy system agents,
one needs aggregate number revealed constraint parts agent (Greenstadt
et al., 2006; Greenstadt, 2008).
ACLS, fraction constraint revealed line 10 (Algorithm 6), MCSMGM GCA-MGM reveal constraint information lines 8 9 (Algorithm 7). Another
algorithm attempts coordinate joint moves MGM-2 (Maheswaran et al., 2004a),
offerer agents propose several improving assignments along costs
one peers, respond lowest improving cost incurred them. Thus,
MGM-2 agents reveal much larger fraction constraint every interaction.
642

fiAsymmetric Distributed Constraint Optimization Problems

100%
MCS-MGM

Privacy loss

80%

GCA-MGM

60%

ACLS

40%

MGM2

20%
0%
0

50

100

150

200

Cycles

Figure 24: Privacy loss local search algorithms Erdos-Renyi graphs

Privacy loss

100%
80%

MCS-MGM

60%

GCA-MGM

ACLS

40%

MGM2

20%
0%

0

50

100

150

200

Cycles

Figure 25: Privacy loss local search algorithms scale-free networks
Figures 23, 24, 25 present privacy loss measurements. Agents running MGM-2
reveal problem structure, algorithms maintain substantially
higher degree constraint privacy. three problem scenarios apparent
privacy loss proposed ADCOP algorithms negligible compared privacy loss
MGM-2. Furthermore, privacy MGM-2 decreases throughout 200 cycles
algorithm (although privacy loss function notable concave structure), ACLS,
MCS-MGM, GCA-MGM lose small amount privacy first iterations,
endure additional privacy loss. results indicate quick convergence
solution may substantial impact privacy loss.

6. Conclusions
Many problems distributed nature include agents different valuations possible states world. distributed constraint optimization problems
constrained agents may different costs assigned valued constraints. present
paper proposes Asymmetric Distributed Constraint Optimization Problems (ADCOP)
model, captures inherent asymmetry distributed problems natural ef643

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

ficient way. proposed ADCOP model represents private gains without revealing private
information a-priori. Instead, agents reveal information necessary
distributed search solution. contrast alternative DCOP formulations
either centralize constraints (resulting privacy loss possibly heavy network load),
change problem complex structure (PEAV).
algorithmic impact introducing new framework discussed, well
applicability existing DCOP algorithms. Several novel algorithms proposed
complete search others local search.
considering complete search, proposed complete ADCOP algorithms eliminate need extend problem using PEAV model. Furthermore, behave
well whole range problem difficulty. Two complete ADCOP algorithms
showed superior performance (runtime well network load) compared leading (symmetric) DCOP algorithms use PEAV representation. Another alternative
aggregate sides constraints simply run symmetric DCOP algorithm.
However, method leads a-priori disclosure private constraint information,
achieving moderately better run-time performance respective ADCOP
algorithms. results indicate synchronous algorithm (SyncABB) outperforms
asynchronous algorithm (ATWB) cases. SyncABB usually performs less NCLOs, sends significantly less messages, leads better distribution privacy loss
agents. contrast, average privacy loss ATWB lower.
proposed ADCOP local search algorithms agents cooperate perform
search local neighborhood, instead maximizing gain. proof
one algorithms, GCA-MGM, guaranteed converge local optimum,
presented. PEAV representation cannot used combination existing local
search algorithms, since assignment violate hard constraints local
optimum PEAV generates. However, existing local search algorithms used
combination proposed ADCOP model. Nevertheless, empirical evaluation
demonstrated new ADCOP algorithms consistently find higher quality solutions,
high degree privacy preservation. turns fast convergence
strongly limits amount privacy lost.

References
Brito, I., Meisels, A., Meseguer, P., & Zivan, R. (2009). Distributed constraint satisfaction
partially known constraints. Constraints, 14 (2), 199234.
Burke, D. A., Brown, K. N., Dogru, M., & Lowe, B. (2007). Supply chain coordination
distributed constraint optimization. Proc. CP Workshop Distributed
Constraint Reasoning (DCR-07).
Chapman, A. C., Rogers, A., & Jennings, N. R. (2008). parameterisation algorithms
distributed constraint optimisation via potential games. Proc. AAMAS Workshop
Distributed Constraint Reasoning (DCR-08).
Erdos, P., & Renyi, A. (1960). evolution random graphs. Publication
Mathematical Institute Hungarian Academy Sciences, pp. 1761.
644

fiAsymmetric Distributed Constraint Optimization Problems

Farinelli, A., Rogers, A., Petcu, A., & Jennings, N. R. (2008). Decentralised coordination
low-power embedded devices using max-sum algorithm. Proc. AAMAS-08,
pp. 639646.
Gershman, A., Grubshtein, A., Meisels, A., Rokach, L., & Zivan, R. (2008). Scheduling
meetings agents. Proc. PATAT-08.
Gershman, A., Meisels, A., & Zivan, R. (2009). Asynchronous forward bounding. Journal
Artificial Intelligence Research (JAIR), 34, 2546.
Gershman, A., Zivan, R., Grinshpoun, T., Grubshtein, A., & Meisels, A. (2008). Measuring distributed constraint optimization algorithms. Proc. AAMAS Workshop
Distributed Constraint Reasoning (DCR-08).
Greenstadt, R. (2008). analysis privacy loss k-optimal algorithms. Proc. AAMAS
Workshop Distributed Constraint Reasoning (DCR-08).
Greenstadt, R., Pearce, J., & Tambe, M. (2006). Analysis privacy loss distributed
constraint optimization. Proc. AAAI-06, pp. 647653.
Grinshpoun, T., & Meisels, A. (2008). Completeness performance APO algorithm.
Journal Artificial Intelligence Research (JAIR), 33, 223258.
Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem.
Proc. CP-97, pp. 222236.
Jackson, M. O. (2008). Social Economic Networks. Princeton University Press.
Kearns, M. J., Littman, M. L., & Singh, S. P. (2001). Graphical models game theory.
Proc. UAI-01, pp. 253260.
Larrosa, J., & Schiex, T. (2004). Solving weighted CSP maintaining arc consistency.
Artificial Intelligence, 159, 126.
Leaute, T., & Faltings, B. (2011). Distributed constraint optimization stochastic
uncertainty. Proc. AAAI-11, pp. 6873.
Maheswaran, R. T., Pearce, J. P., & Tambe, M. (2004a). Distributed algorithms DCOP:
graphical-game-based approach. Proc. Parallel Distributed Computing Systems (PDCS-04), pp. 432439.
Maheswaran, R. T., Tambe, M., Bowring, E., Pearce, J. P., & Varakantham, P. (2004b).
Taking DCOP real world: Efficient complete solutions distributed multievent scheduling. Proc. AAMAS-04, pp. 310317.
Maheswaran, R. T., Pearce, J. P., & Tambe, M. (2006). family graphical-game-based
algorithms distributed constraint optimization problems. Coordination LargeScale Multiagent Systems, pp. 127146. Springer-Verlag.
Maheswaran, R. T., Pearce, J. P., Varakantham, P., Bowring, E., & Tambe, M. (2005).
Valuations possible states (VPS): quantitative framework analysis privacy
loss among collaborative personal assistant agents. Proc. AAMAS-05, pp. 1030
1037.
Mailler, R., & Lesser, V. R. (2004). Solving distributed constraint optimization problems
using cooperative mediation. Proc. AAMAS-04, pp. 438445.
645

fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels

Mailler, R., & Lesser, V. (2006). Asynchronous Partial Overlay: New Algorithm Solving Distributed Constraint Satisfaction Problems. Journal Artificial Intelligence
Research (JAIR), 25, 529576.
Meisels, A. (2007). Distributed Search Constrained Agents: Algorithms, Performance,
Communication. Springer Verlag.
Modi, J., & Veloso, M. (2004). Multiagent meeting scheduling rescheduling. Proc.
CP Workshop Distributed Constraint Reasoning (DCR-04).
Modi, P. J., Shen, W., Tambe, M., & Yokoo, M. (2005). ADOPT: asynchronous distributed
constraints optimizationwith quality guarantees. Artificial Intelligence, 161, 149180.
Monderer, D., & Shapley, L. S. (1996). Potential games. Games Economic Behavior,
14, 124143.
Netzer, A., Grubshtein, A., & Meisels, A. (2012). Concurrent forward bounding distributed constraint optimization problems. Artificial Intelligence, 193, 186216.
Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. V. (2007). Algorithmic Game
Theory. Cambridge University Press.
Pearce, J. P., & Tambe, M. (2007). Quality guarantees k-optimal solutions distributed
constraint optimization problems. Proc. IJCAI-07, pp. 14461451.
Petcu, A., & Faltings, B. (2006). ODPOP: algorithm open/distributed constraint
optimization. Proc. AAAI-06, pp. 703708.
Petcu, A. (2007). class algorithms distributed constraint optimization. Ph.D. thesis,
Ecole Polytechnique Fdrale de Lausanne (EPFL), Switzerland.
Ramchurn, S. D., Vytelingum, P., Rogers, A., & Jennings, N. (2011). Agent-based control
decentralized demand side management smart grid. Proc. AAMAS-11,
pp. 512.
Rogers, A., Farinelli, A., Stranders, R., & Jennings, N. R. (2011). Bounded approximate
decentralised coordination via max-sum algorithm. Artificial Intelligence, 175 (2),
730759.
Taylor, M. E., Jain, M., Tandon, P., & Tambe, M. (2009). Using DCOPs balance exploration exploitation time-critical domains. Proc. IJCAI Workshop
Distributed Constraint Reasoning (DCR-09).
Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: asynchronous branch-andbound DCOP algorithm. Journal Artificial Intelligence Research (JAIR), 38, 85
133.
Yokoo, M. (2000). Algorithms distributed constraint satisfaction problems: review.
Autonomous Agents Multi-Agent Systems, 3 (2), 185207.
Yokoo, M., K.Suzuki, & Hirayama, K. (2002). Secure distributed constraints satisfaction:
Reaching agreement without revealing private information. Proc. CP-02, pp. 387
401.
Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2005). Distributed stochastic search
distributed breakout: properties, comparishon applications constraints
optimization problems sensor networks. Artificial Intelligence, 161 (1-2), 5588.
646

fiAsymmetric Distributed Constraint Optimization Problems

Zivan, R. (2008). Anytime local search distributed constraint optimization. Proc.
AAAI-08, pp. 14491452.
Zivan, R., & Meisels, A. (2006). Message delay DisCSP search algorithms. Annals
Mathematics Artificial Intelligence, 46 (4), 415439.
Zivan, R., Glinton, R., & Sycara, K. P. (2009). Distributed constraint optimization large
teams mobile sensing agents. Proc. IAT-09, pp. 347354.

647

fiJournal Artificial Intelligence Research 47 (2013) 809-851

Submitted 04/13; published 08/13

Decidable Extension SROIQ Complex Role
Chains Unions
Milenko Mosurovic

milenko@ac.me

Faculty Natural Sciences Mathematics,
University Montenegro, Montenegro.

Nenad Krdzavac

nenadkr@tesla.rcub.bg.ac.rs

Faculty Organizational Sciences,
University Belgrade, Serbia.

Henson Graves

henson.graves@hotmail.com

Algos Associates, 2829 West Cantey Street,
Fort Worth, TX 76109 U.S.

Michael Zakharyaschev

michael@dcs.bbk.ac.uk

Department Computer Science Information Systems,
Birkbeck, University London, U.K.

Abstract
design decidable extension description logic SROIQ underlying Web
Ontology Language OWL 2. new logic, called SR+ OIQ, supports controlled use
role axioms whose right-hand side may contain role chains role unions. give
tableau algorithm checking concept satisfiability respect SR+ OIQ ontologies
prove soundness, completeness termination.

1. Introduction
ever growing number scope application areas puts constant pressure
designers ontology languages. Thus, first version Web Ontology Language
OWL, became formal W3C recommendation 2004, contained description logic
(DL, short) SHOIN allowed use basic DL ALC together inverse
transitive roles, role hierarchies, nominals unqualified cardinality restrictions.
second reincarnation OWL 2, adopted 2009, based powerful formalism,
SROIQ, extends SHOIN features complex role chains, asymmetric,
reflexive disjoint roles, qualified cardinality restrictions (Horrocks & Sattler, 2004;
Horrocks, Kutz, & Sattler, 2006; Cuenca Grau, Horrocks, Motik, Parsia, Patel-Schneider,
& Sattler, 2008).
addition role inclusions involve role chains motivated multiple use
cases life sciences domain require means describe interactions
locative properties various kinds part-whole properties (Cuenca Grau et al., 2008).
example, role inclusion axiom
hasLocation isPartOf v hasLocation
states object x located y, part z, x also located
z (Rector, 2002). However, resolved issue role chains left-hand side
c
2013
AI Access Foundation. rights reserved.

fiMosurovic, Krdzavac, Henson & Zakharyaschev

role inclusion axioms, example above, SROIQ OWL 2 fall short providing
means represent chains and/or unions roles right-hand side, often
required modelling structured objects, particular, emerging area ontological
product modelling collaborative design (Bock, Zha, Suh, & Lee, 2010).
Consider, example, product model cars Bock (2004) Krdzavac
Bock (2008), part shown UML-like diagram below:

Car

B
Wheel

Engine

powers

powers
hasEngine
hasWheel

hasWheel
Wheel

Engine

Oilpump
hasEngine

C

Car
hasHub
Hub

hasOilpump

Crankshaft

powers

Gear
powers

powers

hasCrankshaft

hasGenerator

Generator

Hub

powers

Crankshaft
powers

Figure 1: product model car (Krdzavac & Bock, 2008).
fragment Fig. 1 (A) involves two statements:
hasEngine hasCrankshaft powers v hasWheel hasHub

(1)

says whatever powered crankshaft engine car hub wheel
car and, conversely,
hasWheel hasHub v hasEngine hasCrankshaft powers

(2)

states hub wheel car powered crankshaft engine car.
fragment Fig. 1 (B) means engine car power wheels, generator
oil pump, represented axiom
hasEngine powers v hasWheel hasGenerator hasOilPump.

(3)

Finally, Fig. 1 (C) supposed mean role powers transitive:
powers powers v powers.

(4)

Role inclusion axioms form (1), (2), (4) feature original KL-ONE
terminological language (Brachman & Schmolze, 1985), called role-valuemaps could applied certain individuals. Role inclusions disjunctions
right-hand side also arise context spatial reasoning description logics (Wessel,
2001, 2002), used represent compositions RCC8-relations
PO TPP PO TPP NTPP (in English: region x partially overlaps region
810

fiA Decidable Extension SROIQ Complex Role Chains Unions

tangential proper part region z, either x partially overlaps z, x
tangential proper part z, x non-tangential proper part z).
Role inclusions complex right-hand side allowed syntax SROIQ
OWL 2, makes adequate representation models Fig. 1 problematic.
Indeed, languages, cannot exclude situations when, example, car1 related
hub1 via hasEngine hasCrankshaft powers and, time, hub1 part car2.
Axiom (1) asserts existence individual wheel car1 hub1.
main issue axioms (1) similar rewrite rules
semi-Thue systems, word problem known undecidable. One
simplest examples given Tseitin (1956) showed associative calculus
(Thue system) axioms
ac = ca, ad = da, bc = cb, bd = db, edb = be, eca = ae, abac = abacc
undecidable. Schmidt-Schau (1989) used undecidability word problem show
logic underlying KL-ONE undecidable. Baader (2003) proved (by reduction
semi-Thue systems) tractable description logic EL becomes undecidable
extended role inclusions containing role chains right-hand side.
hand, observed role inclusions single role right-hand side
increase complexity EL. Horrocks Sattler (2004) proved extension
SHIQ axioms form R v R R v R undecidable; however,
decidability regained requiring axioms involve cycles. Axioms
form (3) also lead undecidable logics: Wessel (2001, 2002) showed (by reduction
PCP) extension ALC role axioms form v R1 Rn
undecidable.
Similar problems investigated modal logic community. modal logic,
axioms form
i1 . . . p j1 . . . jm p,
(5)
known modal reduction principles, always attracted attention still present
great challenge (for example, open whether extension basic modal logic K
either axioms p p p p decidable). Axioms form (5)
give rise grammars generated production rules i1 . . .in j1 . . .jm , modal
logics axiomatised axioms called grammar logics (del Cerro & Penttonen, 1988).
shown Demri (2001) Baldoni (1998) grammar regular,
corresponding modal logic decidable ExpTime; hand, linear (contextfree) grammar logics undecidable. follows, particular, satsifiability
problem ALC knowledge bases extended role inclusions R1 . . . Rn v S1 . . . Sk also
ExpTime-complete provided grammar generated rules S1 . . . Sk R1 . . . Rn
regular (Demri, 2001, Section 5.3).
paper, design decidable extension SR+ OIQ description logic SROIQ
supports controlled use role inclusion axioms complex right-hand side
examples above. Thus, use role inclusion axioms chain union
roles right-hand side, also express equality two role chains unions
(1) (2). ensure decidability, impose certain regularity conditions
role axioms given ontology generalise syntactic restrictions Horrocks et al.
811

fiMosurovic, Krdzavac, Henson & Zakharyaschev

(2006) Kazakov (2010). conditions checked polynomial time employed,
pre-processing step, build finite automata roles ontology. Intuitively,
automaton role R recognises role chains subsumed R according
ontology passes concept C end chain whenever beginning belongs
R.C.
decision algorithm builds tableau technique developed Horrocks et al.
(2006) uses ideas Halpern Moses (1992, pp. 34-35) order pass sets
concepts along role chains required role inclusions complex right-hand side
(1)(3). axioms, tableau algorithm behaves precisely
tableau algorithm SROIQ; otherwise may suffer multiple exponential blowups
(depending number role inclusions complex right-hand side).
alternative approach modelling complex structures description logics
suggested Motik, Cuenca Grau, Horrocks, Sattler (2009). decidable formalism
based description graphs encode axioms form (1),
presence transitivity (4) (in case language generated role chain
left-hand side (1) infinite cannot represented finite graph). ensure
decidability, Motik et al. (2009) impose acyclicity conditions description graphs
allow role appear description graph DL ontology.
example, cannot straightforwardly combine description graph encoding model
Fig. 1 vehicle tax ontology containing axioms
Car u hasEngine.LargeEngine v vehicleTax.HigherTax.

(6)

SR+ OIQ, addition (6) (1)(4) cause problem.
structure paper follows. define syntax semantics
description logic SR+ OIQ next two sections. particular, Section 3 defines
gives intuition behind regularity conditions imposed SR+ OIQ role axioms.
aim Section 4 illustrate number examples new challenges
tableau construction facing dealing SR+ OIQ compared case
SROIQ. use examples motivate explain new ideas, notions techniques required tableau-based decision algorithm SR+ OIQ. Tableaux
SR+ OIQ defined formally Appendix A. Appendix B, give tableau algorithm SR+ OIQ prove sound, complete always terminates.
discuss obtained results open problems Section 5.

2. Description Logic SR+ OIQ
begin formally defining syntax semantics description logic SR+ OIQ.
alphabet SR+ OIQ consists three countably infinite disjoint sets NC , NR
NI concept names, role names individual names, respectively. also distinguish
proper subset NN $ NC , whose members called nominals. alphabet
interpreted structures, interpretations, form = (I , ), 6=
domain interpretation, interpretation function assigns every NC
subset AI , AI singleton set NN ; every R NR binary
relation RI ; every NI element aI . Following OWL 2
812

fiA Decidable Extension SROIQ Complex Role Chains Unions

standards, adopt unique name assumption allow aI = bI distinct
a, b NI .
introduce role concept constructs available SR+ OIQ.
role name R NR , inverse R R interpreted relation
(R )I = {(y, x) | (x, y) RI }.
call role names inverses basic roles, set NR = NR {R | R NR } write
rn(R) = rn(R ) = R, R NR . define SR+ OIQ-role chain R1 . . . Rn
union R1 Rn basic roles Ri , interpret new constructs taking
(R1 . . . Rn )I = R1I RnI ,
(R1 Rn )I = R1I RnI ,
denotes composition binary relations. Define function inv () role chains
taking inv (R1 . . . Rn ) = inv (Rn ) . . . inv (R1 ), inv (R) = R inv (R ) = R,
R NR .
set NR role names, distinguish proper subset NS call members
inverses simple roles; basic roles simple called nonsimple. Simple non-simple roles satisfy different constraints concepts
role inclusion axioms defined below.
SR+ OIQ-concepts, C, defined following grammar, NC , R
basic role, simple role, n positive integer (given binary):
C

::=

|

R.C


|

|

>

R.C

|
|

C

|

nS.C

C1 u C2
|

nS.C

|

C1 C2
|

|

S.Self .

interpretation concepts defined follows, ]X cardinality X:
>I = ,

= ,

(C)I = \ C ,

(C1 u C2 )I = C1I C2I ,

(C1 C2 )I = C1I C2I ,

(R.C)I = {x | C (x, y) RI },
(R.C)I = {x | ((x, y) RI C )},
(S.Self )I = {x | (x, x) },
( n S.C)I = {x | ]{y | (x, y) C } n},
( n S.C)I = {x | ]{y | (x, y) C } n}.
SR+ OIQ-knowledge base (KB, short) consists TBox, RBox ABox.
TBox, , finite set concept inclusions (CIs), expressions form
C1 v C2 . CI satisfied C1I C2I , case write |= C1 v C2 .
ABox, A, finite set assertions form
: C,

(a, b) : R,

(a, b) : S,
813

6= b,

fiMosurovic, Krdzavac, Henson & Zakharyaschev

b individual names, R basic role, simple role, C concept.
satisfaction relation ABox assertions given
|= : C

iff

aI C ,

|= (a, b) : R

iff

(aI , bI ) RI ,

|= (a, b) :

iff

(aI , bI )
/ SI ,

|= 6= b iff

aI 6= bI .

RBox, R, finite set disjointness constraints role axioms. disjointness
constraint Dis(S1 , S2 ) imposed simple roles S1 , S2 ; satisfied S1I S2I = .
role axiom (RA) following six types, S, 0 simple roles; Q0 , Q,
Q1 , . . . , Qm non-simple roles; R, R1 , . . . , Rm arbitrary basic roles:
(A) v 0 , QQ v Q, Q v Q,
(B) R1 . . . Rm v Q, QR1 . . . Rm v Q, R1 . . . Rm Q v Q, 1,
(C) R v QR1 . . . Rm , 1,
(D) R v Q1 Qm , > 1,
(E) Q0 = QR1 . . . Rm , 1,
(F) Q = Q1 Qm , > 1.
RAs form (A)(D) called role inclusions (RIs), form (E)
(F) role equalities (REs). RBox R may contain set role axioms satisfying
regularity conditions defined discussed next section.
Note that, although RAs SR+ OIQ restricted form (A)(F),
encode general role inclusions form (provided meet regularity
conditions defined below)
(R11 . . . Rn1 1 ) (R1m . . . Rnmm ) v (R1m+1 . . . Rnm+1
) (R1k . . . Rnk k ).
m+1

(7)

(In particular, one easily write RBox capturing RAs (1)(4) introduction.) detailed discussion actually represented SR+ OIQ RBoxes
also given next section.
%i chain union roles, = 1, 2, %1 v %2 (or %1 = %2 ) satisfied

%1 %I2 (respectively, %I1 = %I2 ). say KB K = (T , R, A) satisfiable
exists interpretation satisfying members , R A. case write
|= K call model K.
main reasoning problem paper concept satisfiability respect KBs:
given SR+ OIQ concept C KB K, decide whether model K
C 6= . standard reasoning problems subsumption, KB satisfiability
instance checking known reducible concept satisfiability respect
KBs. Moreover, concept satisfiability respect arbitrary KBs reduced
concept satisfiability respect KBs form (, R, ) (with empty TBoxes
ABoxes); (see Horrocks et al., 2006, Thm. 9).
814

fiA Decidable Extension SROIQ Complex Role Chains Unions

concept C, denote nom(C) set nominals occur C,
role(C) set basic roles R either R inv (R) occurs C; role(C, K)
role(C, R) contain basic roles inverses occur C K/R.

3. Regular RBoxes
mentioned introduction, unrestricted RAs easily simulate kinds undecidable problems. section, define regular RBoxes allowed SR+ OIQ.
SROIQ RAsthat is, RAs form (A) (B)our restrictions
used Kazakov (2010). suggested term regular, going use
regularity restrictions construct finite automata roles R recognise role chains
subsumed R RBox question.
Suppose R set RAs. define regularity conditions (to given Definition 3), require following binary relation 0 set role names occur
R:
rn(Ri ) 0 rn(Q), = 1, . . . , m, RIs type (B),
rn(R) 0 rn(Q), RIs type (C),
rn(R) 0 rn(Qi ), = 1, . . . , m, RIs type (D),
rn(Ri ) 0 rn(Q0 ), = 1, . . . , m, REs type (E).
Denote R transitive reflexive closure 0 . write R1 'R R2
R1 R R2 R2 R R1 , R1 R R2 R1 R R2 R2 R R1 . depth dR (R)
R R understand largest n exists chain R1 R R2 R R
Rn R R.
represent R union R = RA RB RC RD RF , RX contains
RAs R form (X), X {A, B, C, D, E, F }. also write RA,B
RA RB , etc.
RI r = (% v R) RA,B role chains %0 %00 , write %0 vr %00 either
0
% = %01 %%02 %00 = %01 R%02 , %0 = %01 inv (%)%02 %00 = %01 inv (R)%02 , %01 %02 .
write %0 vR %00 %0 vr %00 , r RA,B , denote vR reflexive
transitive closure vR . follows immediately definitions R vR
have:
Lemma 1 % = %0 R0 %00 % vR R, rn(R0 ) R rn(R).
Following Kazakov (2010), say RI (% v R0 ) RA,B stratified R if,
every R 'R R0 % = %1 R%2 , exists R1 %1 R vR R1 R1 %2 vR R0 .
call RA,B stratified every RI % v R % vR R stratified R.
every role R R, define following language LR (R) role chains regarded
words basic roles:
LR (R) = {% | % vR R}.
Theorem 2 (Kazakov, 2010) Suppose R RBox stratified RA,B .
language LR (R) regular, every role R R. Moreover, one construct nondeterministic finite automaton recognising LR (R) number transitions
exceed O(|R|2dR (R) ).
815

fiMosurovic, Krdzavac, Henson & Zakharyaschev

position define regular RBoxes.
Definition 3 RBox R called regular following conditions satisfied:
(c1) RA,B stratified;
(c2) rn(R) R rn(Q), RIs type (C);
(c3) rn(R) R rn(Qi ), = 1, . . . , m, RIs type (D);
(c4) rn(Ri ) R rn(Q0 ), = 1, . . . , m, RAs type (E);
(c5) exists quasi-order 1R R
rn(Q0 ) 1R rn(Q), RA type (E);
rn(Q) 1R rn(Qi ), = 1, . . . , m, RA type (F);
(c6) exists quasi-order 2R R
rn(Q) 2R rn(Q0 ), RA type (E);
rn(Qi ) 2R rn(Q), = 1, . . . , m, RA type (F);
(c7) exist RAs r r 0 one following conditions holds:
r 0 = (Q0 = Q0 R1 . . . Rm0 ), r = (Q = Q1 Qm ), rn(Q0 ) = rn(Q)
rn(Q0 ) = rn(Qj ), j, 1 j m;
0 ), r = (Q0 = Q R . . . R ), rn(Q0 ) = rn(Q0 )
r 0 = (Q00 = Q0 R10 . . . Rm
0
1 1

1
0
1
rn(Q0 ) = rn(Q1 );

r 0 = (Q0 = Q01 Q0m0 ), r = (Q = Q1 Qm ), rn(Q0 ) = rn(Q)
rn(Q0i ) = rn(Qj ), i, j, 1 m0 , 1 j m.
remainder section, discuss regularity conditions (c1)(c7) illustrate concrete examples. Note first condition (c1) required ensure
decidability SROIQ; mentioned introduction, dropping immediately leads
undecidability (Demri, 2001; Horrocks & Sattler, 2004). understand (c2), consider
following:
Example 4 Let R = {RQ v Q0 , Q0 v QR}. former RI type (B), latter
one type (C). Clearly, Q0 v QR satisfy (c2), RBox regular.
see situation dangerous, observe R |= RQ v QR. Now, TBox
generates infinite chains Q- R -arrows starting point, RI
RQ v QR would generate N N-grid shown left-hand side picture below:
816

fiA Decidable Extension SROIQ Complex Role Chains Unions

Q

Q
Q1

R
Q

R
Q

R
Q

Q

Q Q

Q

Q1

R
Q

Q0

R

R
Q

R
Q

R

Q
R

R


Q

Q

Q

R

R

Q
R

routine reduce undecidable N N-tiling problem KB satisfiability.
hand, RBox R0 = {R v QRQ } regular (rn(R) R0 rn(Q)).
However, cannot generate proper N N-grid (as shown right-hand side
picture above). able encode N N-tiling problem, require additional RIs
Q Q v Q1 Q Q1 Q v Q1 . resulting RBox satisfy
condition (c1).
Condition (c3) similar (c2); omission leads undecidability shown
Wessel (2002). illustrate (c4), give one example.
Example 5 Consider RBox R = {Q0 Q v Q1 , Q0 = Q Q1 }. Clearly, satisfy
(c4), condition omitted, Q0 R Q1 Q R Q1 . observe
dangerous RI Q Q1 Q v Q1 Example 4 consequence R.
Since REs (E) (F) imply Q0 v QR1 . . . Rm Q v Q1 Qm types (C)
(D), condition (c5) similar (c2) (c3). (c6), consider following:
Example 6 RBox R = {Q1 Q2 v Q2 , Q3 Q4 v Q3 , Q4 = Q2 S} regular. However,
R1 = R {Q1 = Q3 0 } regular rn(Q1 ) R1 rn(Q2 ), rn(Q4 ) R1 rn(Q3 ),
rn(S) R1 rn(Q4 ), rn(S 0 ) R1 rn(Q1 ), (c1)(c5) (c7) satisfied,
(c6) not. Now, R1 implies Q3 0 Q2 v Q2 Q3 Q2 v Q3 , obtain
Q3 Q2 SS 0 Q2 v Q2 . RBox containing RI generates language regular.
Finally, require condition (c7) view following:
Example 7 RAs Q0 = QR Q0 = Q Q1 clearly imply Q v QR. saw
Example 4, presence RI RQ v Q, would lead undecidability. Condition
(c7) allow RBoxes sort counted regular.
already noted, restrict SR+ OIQ RBoxes RAs types (A)(F) mainly
order simplify notation proofs; see (7). Every RI R1 . . . Rn v P1 . . . Pm
equivalent RI inv (Rn ) . . . inv (R1 ) v inv (Pm ) . . . inv (P1 ). particular, RI
inv (R) v inv (Qm ) . . . inv (Q1 )inv (Q) equivalent RI R v QQ1 . . . Qm type (C),
use former SR+ OIQ RBoxes provided rn(R) rn(Q). Every
0 replaced RIs R . . . R v P . . . P
RI R1 . . . Rn v P1 . . . Pk P10 . . . Pm
1
n
1
k
0
0
v P1 . . . Pm , fresh role name , without affecting satisfiability KB.
817

fiMosurovic, Krdzavac, Henson & Zakharyaschev

particular, rn(Ri ) rn(Q), represent R1 . . . Rn v P1 . . . Pk QPk+1 . . . Pm
means three SR+ OIQ RIs: R1 . . . Rn v R, inv (R) v inv (T )inv (Pk ) . . . inv (P1 )
v QPk+1 . . . Pm , fresh role names R . Instead R1 . . . Rn v P1 Pm
use R1 . . . Rn v R R v P1 Pm , fresh role name R. done
role equality axioms.
reflexivity constraint Ref (R) (saying RI reflexive) expressed means
RI v R CI > v S.Self , fresh simple role.

Example 8 RI (1) introduction represented SR+ OIQ two RIs:
hasEngine hasCrankshaft powers v Q,

(8)

Q v hasWheel hasHub,

(9)

Q fresh non-simple role name. One might suggest (9) could replaced
RI Q hasHub v hasWheel. However, case: interpretation given
satisfies former latter (obviously, Q hasHub v hasWheel
imply (9)).

Q

Q

hasWheel

hasWheel
hasHub

hasHub

Example 9 Consider (regular) RBox R = {R v Q1 R1 , Q1 v Q2 P, P = Q3 R}
ABox = {(x0 , x1 ) : P }. model R contains sequence (not necessarily
distinct) points x0 , x1 , x2 , . . . arranged according patter shown picture below:
x4

x0
Q3
P
x1

x2

Q2

Q3
P

R

Q1
R1

x7
x5

P

R

x3

Q2


Q1
R1

x6

applying tableau algorithm R (to introduced remainder
paper), construct model, represent tree-shaped structure
omitting Q1 -, Q2 - Q3 -arrows, always restored. (In general, always
omit first role right-hand side axiom type (C) (E), roles
right-hand side axiom type (D) (F).) illustrated picture
below.
818

fiA Decidable Extension SROIQ Complex Role Chains Unions

x0

x0

P

P

x1

x1

Q3

R1
x3
P
R

R1
x6

R1

R
x2

P
R

R1
x4

x2

Q1



x5

R

x3

x6

Q1



Q2

Q3

x4

x5

4. SR+ OIQ Tableaux Examples
prove decidability SR+ OIQ using tableau-based algorithm, generalisation algorithm given Horrocks et al. (2006). assume reader familiar
tableau technique standard DLs ALCI (Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2003). aim section explain, using concrete
examples, problems one encounters constructing tableaux SR+ OIQ
way resolve problems suggested paper. worked
examples, reader grasped general idea tableaux SR+ OIQ.
assume concepts negation normal form (NNF). particular,
write C, concept C, actually mean NNF C. Denote con(C) smallest
set contains C closed sub-concepts . KB K = (T , R, A),
denote con(K) union con(C), concepts C occurring K. basic role
R con(K), set |R = {C | R.C }.
4.1 RIs Role Chains Right-Hand Side
Example 10 Consider first KB K = (T , R, A),
= {a : A},

R = {R v QP },

= {A v R.>, v Q.B, v Q.C}.

start construction tableau K applying standard tableau rules ALC.
Thus, create root node x0 (corresponding ABox individual a) label
`(x0 ) = {A, R.>, Q.B, Q.C}, indicating thereby (some of) concepts
contain according K. view R.> `(x0 ), create R-successor x1 x0 .
interpretation, corresponding resulting tableau shown left-hand side
picture below, clearly model A, R.
`(x0 )
x0

`(x0 )
R

x1

x0

x1

R
Q

P
x2

satisfy R, need Q-successor x2 x0 , x1 P -successor. However,
resulting interpretation, shown right-hand side picture above,
819

fiMosurovic, Krdzavac, Henson & Zakharyaschev

tree. keep tableau tree-shaped, would prefer create x2 P -successor
x1 without drawing Q-arrow x0 x2 explicitly. trigger creation x2
ensure Q-arrow always inserted x0 x2 , add
label `(xi ) new quasi-concept form R.P .`(xi )|Q , encodes R v QP .
intended meaning quasi-concept expected: every R-successor xi must
P -successor whose label contains concepts `(xi )|Q = {C | Q.C `(xi )}. (Note
tableau nodes part syntax quasi-concepts. quasi-concepts,
fact, extend syntax expressions R.S, set ordinary
concepts.) agree extend standard tableau rules R P quasiconcepts, need one new tableau rule (which generalised later
paper):
(r1) (R v QP ) R R.P .`(x)|Q
/ `(x), set `(x) := `(x){R.P .`(x)|Q }.
Now, returning example, apply (r1) `(x0 ), `(x1 ) = obtain:


`(x0 ) := A, R.>, Q.B, Q.C, R.P .{B, C} ,


`(x1 ) := R.P ., P .{B, C} .
create P -successor x2 x1 `(x2 ) = {B, C, R.P .}, picture
below, stop complete clash-free tableau, gives model K
insert missing Q-arrow x0 x2 .
`(x0 )
x0

`(x1 )
R

x1

`(x2 )
P

x2

Note inserting missing Q-arrow example becomes problematic
extend CI B v Q .A shall add `(x0 ),
obtain clash. However, cannot without constructing arrow explicitly.
cope problem, together `(x0 )|Q , also pass `(x2 ) set

`Q (x0 ) concepts C `(x0 ) potentially occur Q .C `(x2 ), namely,
set `(x0 ) con(K)|Q . store set special memory x2 order
compare `(x2 )|Q : `(x2 )|Q 6 `
Q (x0 ), report clash. However,
solve problem yet. see why, consider extension B v Q .C
(rather B v Q .A). C belong `(x0 ), would report clash,
though addition C `(x0 ) would lead contradiction. solution suggest
situations make sure that, every concept {C | Q .C con(K)}
{Q.C | Q.C con(K)}, either `(x0 ) `(x0 ).
formalise idea tableau rules, require new notation. allow
quasi-concepts form `Q (x) = (tr , , ), tr = Q, = `(x)|Q =
`(x) con(K)|Q ; also denote first component triple `rQ (x), second
`Q (x), third `
Q (x). special memory associated node x denoted
m(x); assume originally empty. require following tableau rules,
supersede former (r1):
(r1) (R v QP ) R, rule (r3) applicable, R.P .`Q (x)
/ `(x), set
`(x) := `(x) {R.P .`Q (x)};
820

fiA Decidable Extension SROIQ Complex Role Chains Unions

(r2) P .t `(x), = (tr , , ), x P -neighbour1 `(y)
m(y), create new P -successor x set `(y) = m(y) = {t};
(r3) (R v QP ) R {Q.C | Q.C con(K)} {C | Q .C con(K)}
{D, D} `(x) = , set `(x) := `(x) {E}, E {D, D};
(clash) (tr , , ) m(x) `(x)|inv (tr ) 6 , report clash.
Example 11 illustrate, consider KB K = (T , R, A),
= {a : A},

R = {R v QP },

= {A v R.>, v Q.B, B v Q .C, C v Q.D}.

obtain following complete clash-free tableau K:
`(x0 ) = {A, R.>, Q.B},

(by v)

`(x0 ) := `(x0 ) {Q.D, C},


`(x0 ) := `(x0 ) R.P .`Q (x0 ) , `Q (x0 ) = {B, D}, `
Q (x0 ) = {C},

(by r3)
(by r1)

create x1 x0 Rx1 , `(x1 ) = {Q.B, Q.D, C},
(by R, r3)


`(x1 ) := `(x1 ) R.P .`Q (x1 ), P .`Q (x0 ) , `Q (x1 ) = {B, D}, `
Q (x1 ) = ,
(by r1, R)
create x2 x1 P x2 , m(x2 ) = {`Q (x0 )} `(x2 ) = `Q (x0 ) = {B, D},


`(x2 ) := `(x2 ) Q .C, Q.B, Q.D, C, R.P .`Q (x2 )) .

(by r2)
(by v, r3, r1)

clash `(x2 )|inv (Q) `
Q (x0 ).
4.2 RIs Role Unions Right-Hand Side
next example illustrates tableaux RIs unions right-hand side.
Example 12 Consider KB K = (T , R, A)
= {a : A},

R = {R v Q },

= {A v R .C, v R .D, C v Q.A, C v Q.B, C v T.A,
v T.A, v T.B, v Q.B}.
applying standard rules, obtain tableau shown picture below:
`(x1 ) = {C, Q.A, Q.B, T.A}

`(x2 ) = {D, T.A, T.B, Q.B}

x1

x2
R



R



x0
`(x0 ) = {A, R .C, R .D}
1. Intuitively, neighbour successor predecessor given node. formal definition notion
given Section B.

821

fiMosurovic, Krdzavac, Henson & Zakharyaschev

Now, satisfy R, draw either Q- -arrow x1 x0 , also
x2 x0 . before, explicitly. ensure arrows always
drawn, add `(xi ) quasi-concept form R.(`(xi )|Q `(xi )|T ),
`(xi )|P = {C | P.C `(xi )}. meaning quasi-concept
self-evident. Thus, extend `(xi ) to:


`(x0 ) := `(x0 ) R.( ) ,


`(x1 ) := `(x1 ) R.({A, B} {A}) ,


`(x2 ) := `(x2 ) R.({B} {A, B}) .
add either A, B `(x0 ) view quasi-concept `(x1 ),
also either B A, B view quasi-concept `(x2 ). clash-free way
extend `(x0 ) A, B. Clearly, draw Q-arrow x1 x0
-arrow x2 x0 .
formulate tableau rules handling role unions RIs, taking account
quasi-concepts triples considered above:
(r4) (R v QtT ) R {P.C | P.C con(K)}{C | P .C con(K)},
P {Q, } {D, D} `(x) = , set `(x) := `(x) {E},
E {D, D};
(r5) (R v Q ) R, rule (r4) applicable, R.(`Q (x) `T (x))
/ `(x),
set `(x) := `(x) {R.(`Q (x) `T (x))};
(r6) (t1 t2 ) `(x), ti = (tri , ti ,
), = 1, 2, j {1, 2}
tj `(x) tj m(x), take j {1, 2} set `(x) := `(x) tj
m(x) := m(x) {tj }.
4.3 RIs Role Chains Left-Hand Side
technique illustrated examples works perfectly well RIs single
role left-hand side. cope complex RIs, follow Horrocks Sattler
(2004) Horrocks et al. (2006) encode every R role(K) regular RBox R
means nondeterministic finite automaton (NFA) AR = (SAR , role(K), sR , AR , aR ),
SAR finite set states, role(K) input alphabet, sR SAR initial
state AR , AR : SAR role(K) 2SAR transition function aR SAR
accepting state. REs R, AR accepts precisely role chains
belong language LR (R); words L(AR ) = LR (R).
tableau construction, whenever R.C `(x), extend `(x) quasiconcept AsR .C, initial state AR . Next, ApR .C `(x), -neighbour
x q AR (p, ), extend `(y) AqR .C. Finally, AaR .C `(y),
accepting state AR , extend `(y) C. define tableau rules formally,
first confine attention single RI form r = (R v QP ).
start defining sets quasi-concepts allowed RBoxes containing r.
Denote qc set quasi-concepts form ApR .C R.C con(K)
822

fiA Decidable Extension SROIQ Complex Role Chains Unions

p state AR . set qc basic role , set:
|T = {AqR .C | ApR .C q AR (p, )},
qc (r) = {ApT .C | ApT .C qc exists q

qc(r) = ApR .P .(tr , , ) | p state AR , tr

(10)
(p, Q)} qc|Q ,


= Q,

qc|Q ,





(11)

qc|Q



.

(12)

convenient think labels `(x) tableaux consisting two disjoint
parts `(x) = c(x) a(x), c(x) containing standard concepts a(x) quasi-concepts;
is: c(x) con(K)
a(x) qc qc(r) {P .t | ApR .P .t qc(r)} {C | C qc (r)}.
allow quasi-concepts form aQ (x) = (Q, a(x)|Q , a(x) qc|Q ); denote
first component triple arQ (x), second aQ (x), third
Q (x).
Using new notation, rewrite (r1)(r3) follows:
(r1) r R exists C qc (r) {C, C} a(x) = , set a(x) :=
a(x) {D}, {C, C};
(r2) R.C c(x) AsR .C 6 a(x), initial state AR , set
a(x) := a(x) {AsR .C};
(r3) r R, rule (r1) applicable r AsR .P .aQ (x) 6 a(x),
initial state AR , set a(x) := a(x) {AsR .P .aQ (x)};
(r4) ApR .C a(x), q AR (p, ), -neighbour x AqR .C 6 a(y), set
a(y) := a(y) {AqR .C};
(r5) AaR .C a(x), accepting state, C
/ c(x), set c(x) := c(x) {C};
(r6) AaR .P .t a(x), accepting state, P .t
/ a(x), set

a(x) := a(x) {P .t};
(r7) P .t a(x), = (tr , , ), x P -neighbour a(y)
m(y), create new P -successor x set a(y) = m(y) = {t}.
clash rule remains before, place `. Note rule (r7)
replaced two rules one creates new node sets a(y) = {t},
rule sets a(y) := a(y) . case need m(y). illustrate
new terminology tableau rules revisiting Example 11.
Example 11 (cont.) Consider KB K = (T , R, A)
= {a : A},

R = {R v QP },

= {A v R.>, v Q.B, B v Q .C, C v Q.D}.

tableau below, AQ AR NFAs L(AQ ) = {Q}, L(AR ) = {R},
two states: initial accepting a.
c(x0 ) = {A, R.>, Q.B}, a(x0 ) = {AsQ .B},
823

(by v, r2)

fiMosurovic, Krdzavac, Henson & Zakharyaschev



a(x0 ) := a(x0 ) AsQ .D, AaQ .C , c(x0 ) := c(x0 ) {C},


a(x0 ) := a(x0 ) AsR .P .aQ (x0 ) ,

aQ (x0 ) = {AaQ .D, AaQ .B},
Q (x0 ) = {AQ .C},

(by r1, r5)

(by r3)

create x1 x0 Rx1 , c(x1 ) = , a(x1 ) = {AsQ .D, AsQ .B, AaQ .C},

(by R, r1)

a(x1 ) := a(x1 ) {AsR .P .aQ (x1 )}, aQ (x1 ) = (Q, {AaQ .D, AaQ .B}, {AaQ .C}), (by r3)


a(x1 ) := a(x1 ) AaR .P .aQ (x0 ), P .aQ (x0 ) ,
(by r4, r6)
create x2 m(x2 ) = {aQ (x0 )}, x1 P x2 , c(x2 ) = , a(x2 ) = {AaQ .D, AaQ .B}, (by r7)


c(x2 ) := {B, D, Q .C}, a(x2 ) := a(x2 ) AsQ .C ,
(by r5, v, r2)


a(x2 ) := a(x2 ) AsQ .D, AsQ .B, AaQ .C, AsR .P .(Q, {AaQ .D, AaQ .B}, ) ,
(by r1, r3)
a(x2 )|inv (Q) = {AaQ .C}
Q (x0 ), resulting tableau complete clash-free.
4.4 Interaction RIs Role Chains Right-Hand Side
Example 13 Consider KB K = (T , R, A)
= {a : A},

R = {R v QP, Q v Q1 P1 },

= {A v R.>, v Q.B, B v Q .C, C v Q.D, C v Q1 .B}.
two RIs form (C), Q occurring right-hand side R v QP
left-hand side Q v Q1 P1 . expect tableau algorithm construct
model K shown picture below:
Q1
Q

x0

x1

R

x2

P

P1

x3



A, Q.B, C, Q.D, Q1 .B

B

B, Q .C,

However, apply available rules, produce following tableau:
AsR .P .aQ (x0 ), AsQ .P1 .aQ1 (x0 )

P .aQ (x0 )

x0

x1

R

AaQ .D, AaQ .B
P

x2

aQ (x0 ) = (Q, {AaQ .D, AaQ .B}, {AaQ .C}) aQ1 (x0 ) = (Q1 , {AaQ1 .B}, ).
explicit Q-arrow x0 x2 , cannot apply (r4) obtain quasiconcept AaQ .P1 .aQ1 (x0 ), so, (r6), P1 .aQ1 (x0 ) x2 , would trigger
construction P1 -arrow x2 x3 . overcome problem, use quasiconcept encoding RI Q v Q1 P1 construction quasi-concept R v QP .
precisely, add AaQ .P1 .aQ1 (x0 ) aQ (x0 ), thus obtaining
aQ (x0 ) = {AaQ .D, AaQ .B, AaQ .P1 .aQ1 (x0 )}.
824

fiA Decidable Extension SROIQ Complex Role Chains Unions

AsR .P .aQ (x0 ) a(x0 ), apply (r4) obtain AaR .P .aQ (x0 ), so,
(r6), also P .aQ (x0 ) a(x1 ). construct x2 a(x2 ) containing three quasiconcepts AaQ .D, AaQ .B AaQ .P1 .aQ1 (x0 ), last requires existence
P1 -successor x3 .
order formalise previous idea, introduce dependency relation C. Given
RIs R1 v Q1 P1 R2 v Q2 P2 , write (R1 v Q1 P1 ) C (R2 v Q2 P2 ) states
p, q AR1 either q AR1 (p, Q2 ) q AR1 (p, Q
2 ). particular,
(Q v Q1 P1 ) C (R v QP ). R regular, hard see relation C
acyclic. Indeed, follows definition C, Lemma 1, Definition 3 AR1
rn(Q2 ) R rn(Q1 ) (since rn(Q2 ) R rn(R1 ) rn(R1 ) R rn(Q1 )).
Now, induction C define sets qc(r) RIs r = (R v QP ). C-minimal
r, qc(r) defined (12). Then, assuming qc(r 0 ) defined every r 0 C r
r = (R v QP ), set
qc(r) = {ApR .P .t | p state AR },


= (tr , , ), tr = Q, qc|Q r0 Cr qc(r 0 )|Q , qc|Q r0 Cr qc(r 0 )|Q
and, r 0 = (R0 v Q0 P 0 ) (r 0 ) qc(r 0 ),
(r 0 )|T = {AqR0 .C | ApR0 .C (r 0 ) q AR0 (p, )}.
also set
qc (r) = {ApT .C | exists q (p, Q), ApT .C qc
{AqT .C

| q (p, Q ),

[

qc(r 0 )}

r 0 Cr
ApT .C

qc

[

qc(r 0 )}.

r 0 Cr

Returning example, see r 1 C r, r 1 = (Q v Q1 P1 ), r = (R v QP ),
qc(r 1 ) remains before, qc(r) becoming larger and, particular,
contains {ApR .P .(tr1 , t1 ,
1 ) | p {s, a}},

t1 {AaQ .D, AaQ .B, AaQ .P1 .(Q1 , {AaQ1 .B}, ), AaQ .P1 .(Q1 , , )},
1 {AQ .C}.

example, qc(r) contains quasi-concept
AsR .P .(Q, {AaQ .D, AaQ .B, AaQ .P1 .(Q1 , {AaQ1 .B}, )}, {AaQ .C}).
construction tableau K Example 13, using newly defined sets qc(r),
routine left reader.
dependency relation C RIs RBoxes become complex
presence unions roles.
825

fiMosurovic, Krdzavac, Henson & Zakharyaschev

4.5 Role Equalities
Example 14 Consider RBox R two RAs: ST v R type (B) R = QP
type (E). Clearly, R = QP replaced RIs R v QP QP v R,
resulting RBox {ST v R, R v QP, QP v R} regular. Let us observe
RBoxes
R0 = {ST v R, QP v R}

R00 = {ST v R, R v QP }

regular. Denote AR NFA R determined R0 , A1 NFA R
given R00 (see picture below).
p
AR






start

p



R
Q



start

A1




R



P
q

Let us see whether use automata rules (r2) (r3)
page 823 role R. Consider KB K = (T , R, A), R
= {a : A},

= {A v R.>, v Q.B, v Q.C, v R.D}.

First try AR . applying tableau rules obtain following:
A, R.>, R.D, Q.B, Q.C, AsR .D, AsQ .B, AsQ .C

AaR .D,

x0

x1

R

apply (r3) RI R v QP add quasi-concept AsR .P .aQ (x0 )
a(x0 ), aQ (x0 ) = (Q, a(x0 )|Q , a(x0 ) qc|Q ). Q-transition AR ,
must AqR .P .aQ (x0 ) a(x0 )|Q , impossible a(x0 )|Q cannot
element itself.
Alternatively, use A1 R. gives us
R.D, As1 .P .aQ (x0 ), As1 .D
x0

AaQ .C, AaQ .B

P .aQ (x0 ), Aa1 .D,
P

x1

R

x2

aQ (x0 ) = (Q, {AaQ .C, AaQ .B}, ), defines model K add missing
Q-arrow x0 x2 .
Now, replace CI v R.> K v Q.P.> use A1 R.
case, obtain following tableau:
R.D, As1 .P .aQ (x0 ), As1 .D
x0

x1

Q

826

P

x2

fiA Decidable Extension SROIQ Complex Role Chains Unions

produce satisfying interpretation I, add R-arrow x0 x2 . However,
cannot done free (as Example 10) x2
/ DI . alternative would
use AR R0 instead R (because apply (r3) R v QP ).
obtain following tableau:
AqR .D

R.D, AsR .D
x0

Q

x1

AaR .D,
P

x2

addition R-arrow x0 x2 gives interpretation |= QP v R
x2 DI .
sum up: rule (r2) requires NFA AR , (r3) requires A1 . rule (r2)
page 823 remains rewrite rule (r1) (r3) include role equalities
follows:
(r1) r R, r = (R v QP ) r = (R = QP ), exists C qc (r)
{C, C} a(x) = , set a(x) := a(x) {D}, {C, C};
(r3) r R, r = (R v QP ) r = (R = QP ), rule (r1) applicable r
As1 .P .aQ (x) 6 a(x), initial state A1 , set a(x) :=
a(x) {As1 .P .aQ (x)}.
Note case r = (R v QP ) NFA A1 AR case r = (R = QP )
NFA A1 different AR described above.

5. Main Result Discussion
examples previous section provide basic ingredients added
SROIQ tableaux Horrocks et al. (2006) Horrocks Sattler (2007) order
obtain sound complete tableaux SR+ OIQ. present technical details
definitions Appendix A. corresponding sound, complete terminating tableau
algorithm given Appendix B. Thus, obtain following:
Theorem 15 Concept satisfiability respect SR+ OIQ KBs decidable.
noted decision algorithm Appendix B (quite sophisticated)
extension standard tableau procedure SROIQ; input RBox
contain RAs form (C)(F) tableau algorithm behaves exactly SROIQ
procedure. simplify presentation avoid number technical details, decided
optimise tableau algorithm paper. fact, plenty room
optimisations; example, one work careful choice quasi-concepts well
utilise approach Motik, Shearer, Horrocks (2009).
exact complexity concept satisfiability respect SR+ OIQ KBs still
unknown. RBox contains one RA r 1 form (C)(F), algorithm
construct set qc(r 1 ) quasi-concepts, contains subsets previously
constructed sets quasi-concepts qc(r 0 ), may suffer exponential blow-up. Furthermore, algorithm may suffer one exponential blow-up every time add
extra RA form (C)(F), thereby extend C-chains RAs,
827

fiMosurovic, Krdzavac, Henson & Zakharyaschev

set quasi-concepts may become exponentially larger. investigate complexity
full SR+ OIQ, may useful consider first various sub-languages. example,
conjecture ALCI-concept satisfiability respect regular RBoxes
contain axioms type (C) roles rn(Ri ), = 1, . . . , m, appear left-hand
side RIs, PSpace-complete. SI-concept satisfiability respect RBoxes
contain one axiom form R v QP , rn(R), rn(Q), rn(P ) different role
names transitive, also PSpace-complete.
step SROIQ SR+ OIQ is, extent, similar step SHOIQ
SROIQ: SROIQ extends SHOIQ role inclusion axioms containing role chains
left-hand side, SR+ OIQ extends SROIQ role inclusion axioms containing role
chains unions right-hand side. Attempts extend various DLs role
inclusions made since 1985 (Brachman & Schmolze, 1985; Baader, 2003; Wessel,
2001, 2002); however, resulted undecidable formalisms. Similar problems
investigated modal logic, shown regular grammar logics decidable (Demri, 2001). regularity condition RAs axioms generalises restrictions
Horrocks et al. (2006) Kazakov (2010). (However, closer inspection
results related grammar modal logics needed.) Simanck (2012) showed complex RIs SROIQ encoded using SHOIQ axioms. would interest find
whether similar reduction possible case SR+ OIQ.
One aims introducing complex role inclusion axioms DLs model complex
structured objects. Suppose, example, represent cycle shown
left-hand side picture below:
x0

x0
Q

R1
x1

x4

x1

R2

R4

R2

x2

R3

Q

R1

x3

x4

Q1

x2

Q2
R3

R4
x3

SROIQ, use RI axiom R1 R2 R3 R4 v Q, produces required
cycle chain form R1 R2 R3 R4 . Using description graphs
work Motik et al. (2009), express existence cycle whole.
SR+ OIQ, model situation following regular RBox, Q1 Q2
fresh role names:
R1 v QR4 R3 R2 ,

R2 v Q1 R1 ,


Q
1 v QR4 R3 ,

R3 v Q2 R4 ,


Q
2 v Q R1 R2 ,

R4 v Q R1 R2 R3

(see picture above). RBox produces required cycle least one Ri ,
= 1, 2, 3, 4, model. connection, would interest consider
extension SHOIQ RI axioms form (A) (C).
828

fiA Decidable Extension SROIQ Complex Role Chains Unions

Appendix A. SR+ OIQ Tableaux
observed Horrocks et al. (2006, Thm. 9), without loss generality define
tableaux SR+ OIQ KBs empty TBoxes ABoxes. Let R regular RBox
C0 SR+ OIQ concept. assume RC,D,E,F = {r | = 1, . . . , l}, where,
k1 , k, l1 1 k1 k l1 l,
r = (Ri v Qi Pi1 . . . Pimi ),

= 1, . . . , k1 ,

r = (Ri = Qi Pi1 . . . Pimi ),

= k1 + 1, . . . , k,

r = (Ri = Ti1 Timi ),

= k + 1, . . . , l1 ,

r = (Ri v Ti1 Timi ),

= l1 + 1, . . . , l.

every R role(C0 , R), construct, preprocessing step, NFA AR special
NFAs Ai , = 1, . . . , l, described below. Recall L(A) denotes language
recognised A. p state A, Ap NFA obtained making p
(only) initial state A.
Define RBox
R0 = RA,B {Qi Pi1 . . . Pimi v Ri | = k1 + 1, . . . , k}
{Tij v Ri | = k + 1, . . . , l1 , j = 1, . . . , mi },
contains axioms types (A) (B). Since R regular view conditions
(c1), (c4) (c6) Definition 3, RBox R0 stratified. Theorem 2, use R0
construct, R role(C0 , R), NFA AR = (SAR , role(C0 , R), sR , AR , aR )
L(AR ) = LR0 (R).
also define RBoxes
Ri = R0 \ {Qi Pi1 . . . Pimi v Ri },


0

R = R \ {Tij v Ri | j = 1, . . . , mi },

= k1 + 1, . . . , k,
= k + 1, . . . , l1 ,

construct NFAs Ai L(Ai ) = LRi (Ri ), = k1 + 1, . . . , l1 . = 1, . . . , k1
= l1 + 1, . . . , l, simply set Ai = ARi .
Now, going define formally set qc(C0 , R). elements qc(C0 , R)
called quasi-concepts (for C0 w.r.t. R); use define labels tableau nodes.
definition qc(C0 , R), require dependency relation C RC,D,E,F .
role name Q {rn(Qi ), rn(Ti1 ), . . . , rn(Timi ) | 1 l}, let AutIn(Q)
set {1, . . . , l} states p q Ai q Ai (p, Q)
q Ai (p, Q ). define C RC,D,E,F taking r C r j
1 j k AutIn(rn(Qj )),
k < j l h {1, . . . , mj } AutIn(rn(Tjh )).
following lemma shows transitive closure C acyclic:
Lemma 16 (i) r C r j r j C r hold.
(ii) r i1 C r i2 r i2 C r i3 , r i3 C r i1 hold.
829

fiMosurovic, Krdzavac, Henson & Zakharyaschev

Proof. Observe first AutIn(Q) Q- Q -transition Ai ,
rn(Q) 1R rn(Ri ). k rn(Ri ) 1R rn(Qi ), rn(Q) 1R rn(Qi ).
> k rn(Ri ) 1R rn(Tih ), rn(Q) 1R rn(Tih ), h {1, . . . , mi }.
(i) Let r C r j . Four cases possible.
Case 1: i, j k. AutIn(rn(Qj )), rn(Qj ) 1R rn(Qi ). Similarly,
r j C r , rn(Qi ) 1R rn(Qj ), impossible.
Case 2: j k > k. AutIn(rn(Qj )), rn(Qj ) 1R rn(Tih ),
h {1, . . . , mi }. r j C r Tih0 , 1 h0 mi , j AutIn(rn(Tih0 )).
Hence, rn(Tih0 ) 1R rn(Qj ), contradiction.
Case 3: k j > k. mirror image case 2.
Case 4: i, j > k. Tjh0 , 1 h0 mj , AutIn(rn(Tjh0 )),
rn(Tjh0 ) 1R rn(Tie ), e {1, . . . , mi }. Similarly, r j C r , Tie0 ,
1 e0 mi , rn(Tie0 ) 1R rn(Tjh ), h {1, . . . , mj }, impossible.
proof (ii) similar left reader.
q
require following notation. Let
qc = {ApR .C | R.C con(C0 ) p state AR }.
set qc basic role P , set
|P = {AqR .C | ApR .C q AR (p, P )}.
Sometimes convenient us write qc(r 0 ) place qc assume r 0 Cr ,
i, 1 l. Now, assuming qc(r j ) defined every r j C r 0 j l
1 l, define qc(r ) set Aqi .C
q state Ai ;

r
k, C = Pim
. Pi1
.(t0 , t0 , t0 ) tr0 = Qi ;

W r
r
> k, C =
h=1 (th , th , th ) th = Tih ;

th rj Cri qc(r j )|tr ;
h




h





r j Cr

qc(r j )|inv (tr ) .
h

(r ) qc(r ) basic role P , let
(r )|P = {Aqi .C | Api .C (r ) q Ai (p, P )}.
Finally, set
qc(C0 , R) =

l
[

qc(r ),

i=0

and, qc(C0 , R) basic role P ,
|P

=

l
[

( qc(r j ))|P



| = {Aq .C | Ap .C q (p, )},

j=0

830

fiA Decidable Extension SROIQ Complex Role Chains Unions

empty role chain. qc(C0 , R) 1 l, let
(
r
P . . . Pi1
.(t0 , t0 , t0 ), tr0 = Qi , k,
(r , ) = Wmim

r
r

> k,
h=1 (th , th , th ), th = Tih ,

(13)



th = |tr ,
h = qc(C0 , R)|inv (trh ) , 0 h mi . Clearly, Ai .((r , )) qc(r ).
h
Intuitively, label node u, is, = a(u), (r , ) quasi-concept
encoding RA r node u.

Example 17 Let R = {r 1 , r 2 }, r 1 = (R1 v Q1 P1 P2 ) r 2 = (R2 v T1 T2 ).
NFAs roles R two states: initial accepting a. Suppose
= {AsQ1 .C1 , AaQ .C2 , AsT1 .C3 , AsT2 .C4 , AsT2 .C5 , AaT .C6 }.
1

1


(r 1 , ) = P2 .P1 .(Q1 , {AaQ1 .C1 }, {AaQ .C2 }),
1

(r 2 , ) =

(T1 , {AaT1 .C3 }, {AaT .C6 })
1

(T2 , {AaT2 .C4 , AaT2 .C5 }, ).

Remark 18 P symmetric role (i.e., (P v P ) R), occurrence P
inv (P ) treated rn(P ). example, {P.D, P .C}|P = {D, C}.
position define SR+ OIQ tableaux. Note essential
difference compared tableaux SROIQ (Horrocks et al., 2006) rules
(p19), (p21) (p22).
tableau C0 w.r.t. R structure form = (S, c, a, E), non-empty
set, c : 2con(C0 ) , : 2qc(C0 ,R) , E : role(C0 , R) 2SS following
conditions hold:
(p1) C0 c(u0 ) u0 S,
(p2) C c(u) C
/ c(u), C either concept name R.Self ,
(p3) > c(u)
/ c(u) u,
(p4) R.Self c(u) (u, u) E(R),
(p5) R.Self c(u) (u, u) 6 E(R),
(p6) (C1 u C2 ) c(u) C1 c(u) C2 c(u),
(p7) (C1 C2 ) c(u) C1 c(u) C2 c(u),
(p8) R.C c(u) v (u, v) E(R) C c(v),
(p9) (u, v) E(R) iff (v, u) E(inv (R)),
(p10) ( nS.C) c(u) ]{v | (u, v) E(S) C c(v)} n,
831

fiMosurovic, Krdzavac, Henson & Zakharyaschev

(p11) ( nS.C) c(u) ]{v | (u, v) E(S) C c(v)} n,
(p12) ( nS.C) c(u) (u, v) E(S), C c(v) C c(v),
(p13) c(u) c(v), nom(C0 ), v = u,
(p14) nom(C0 ), vo c(vo ),
(p15) Dis(R, S) R E(R) E(S) = ,
(p16) (u, v) E(R) R v S, (u, v) E(S),2
(p17) R.C c(u) AsR .C a(u), initial state AR ,
(p18) AaR .C a(u), accepting state, C c(u),
(p19) Asi .C a(u), initial state Ai C = (r , a(u)), u
1 l,
(p20) (u, v) E(R) a(u)|R a(v),
(p21) Aai .C a(u), k, C = inv (Pimi ). inv (Pi1 ).(tr , , )
accepting state, v0 , v1 , . . . , vmi = u (vj , vj1 ) E(inv (Pij )),
1 j mi , a(v0 ) a(v0 )|inv (tr ) ,
W r
(p22) Aai .C a(u), accepting state, > k C =
h=1 (th , th , th ),
j {1, . . . , mi } tj a(u) a(u)|inv (tr )
,
j
j

(p23) a(u)| a(u).
Let = (S, c, a, E) tableau, R basic role u, v S. a(u)|R a(v)
a(v)|inv (R) a(u), write ar(R, u, v). R-arrow u v
ar(R, u, v) holds; see Proposition 20 (i). hand, meaning ar(R, u, v)
always insert R-arrow (for non-simple role R) u v without violating
tableau conditions.
Lemma 19 concept C0 satisfiable w.r.t. SR+ OIQ RBox R
exists tableau C0 w.r.t. R.
Proof. () Let = (S, c, a, E) tableau C0 w.r.t. R. Define interpretation
= (I , ) taking = S, C = {u | C c(u)}, concept name C con(C0 ).
role name R, define E(R) (by induction 1R ) RI following way.
role name R, define E(R) RI induction 1R following way. 1R minimal R, set E(R) = E(R). extend E() E(inv (R)) = {(u, v)|(v, u) E(R)}
2. v transitive closure v.

832

fiA Decidable Extension SROIQ Complex Role Chains Unions

E(S1 . . . Sn ) = E(S1 ) E(Sn ). Suppose E(S) defined 1R R.
set, wi = Pi1 . . . Pimi E(wi ) = E(Pi1 ) E(Pimi ),
E(R) = E(R)
[

{(u, v) | ar(R, u, v) & % L(Ai ) z ((u, z) E(%) (v, z) E(wi ))}

{i|R=Qi }

[

{(u, v) | ar(R, u, v) & % L(Ai ) z ((v, z) E(%) (u, z) E(wi ))}

{i|R=inv (Qi )}

[

{(u, v) | ar(R, u, v) & % L(Ai ) (u, v) E(%)}

{i|j R=Tij }

[

{(u, v) | ar(R, u, v) & % L(Ai ) (v, u) E(%)},

{i|j R=inv (Tij )}

RI

= {(u0 , un ) | u1 , . . . , un1 ((ui , ui+1 ) E(Si+1 ) S1 S2 . . . Sn L(AR ))}.

need E(R) adjust E(R) taking account omitted R-arrows RIs form
(C)(F) use RIs construction AR . picture illustrates
situation role Q two RIs QQ v Q R v QP (E(Q) E(Q) QI ).
QI
E(Q)

u0

E(Q)

u1

RI

u2

(P )I

u3

show model C0 R. end, require following:
Proposition 20 (i) (u, v) E(R) ar(R, u, v).
(ii) (u, v) E(R) ar(R, u, v).
(iii) % L(A), (u, v) E(%) .C a(u) Aa .C a(v).
(iv) (u, v) RI AsR .C a(u) AaR .C a(v).
Proof. (i) Follows (p20) (p9). precisely, (u, v) E(R) then, (p9),
(v, u) E(inv (R)). (p20), (u, v) E(R) implies a(u)|R a(v), (v, u) E(inv (R))
implies a(v)|inv (R) a(u). Thus, obtain ar(R, u, v).
(ii) Follows (i) definition E(R).
(iii) Let % = S1 . . . Sn . Since (u, v) E(%), u = u0 , . . . , un = v (ui1 , ui )
E(Si ), = 1, . . . , n. hand, since S1 . . . Sn L(A), = p0 , . . . , pn =
pi (pi1 , Si ). Ap0 .C a(u0 ). Api .C a(ui ), < n, (ii)
pi+1 (pi , Si+1 ), (ui , ui+1 ) E(Si+1 ) give Api+1 .C a(ui+1 ). Aa .C a(v).
(iv) Follows (iii) definition RI .
q
show model R considering types constraints.
Dis(S1 , S2 ): Si simple roles, SiI = E(Si ), so, (p15), S1I S2I = .
833

fiMosurovic, Krdzavac, Henson & Zakharyaschev

S1 v S2 : Si simple roles SiI = E(Si ). Thus, (u, v) S1I (u, v) E(S1 )
and, (p16), (u, v) E(S2 ); hence (u, v) S2I .
S1 . . . Sn v R: S1 . . . Sn L(AR ). (u, v) (S1 . . . Sn )I u =
u0 , . . . , un = v (ui1 , ui ) (Si )I , = 1, . . . , n. definition
(Si )I , ui1 = ui0 , . . . , uini = ui (uij1 , uij ) E(Sji ), 1 j ni ,
S1i S2i . . . Sni L(ASi ). Therefore, S11 . . . Sn11 S12 . . . Snnn L(AR ) (u, v) RI .
RR v R, RS1 . . . Sn v R S1 . . . Sn R v R considered analogously.
R v R: mentioned earlier, occurrence R treated R. follows
(u, v) E(R) (v, u) E(R), (u, v) E(R) (v, u) E(R).
addition, (u, v) RI (v, u) RI . Indeed, let (u, v) RI . Then,
definition RI , exist u = u0 , u1 , . . . , un = v (ui , ui+1 ) E(Si+1 )
S1 S2 . . . Sn L(AR ). (ui+1 , ui ) E(inv (Si+1 )) and, construction
AR , inv (Sn ) . . . inv (S1 ) L(AR ), (v, u) RI .
Ri v Qi Pi1 . . . Pimi : Let (u, v) RiI . Then, (p19), Asi .C a(u),
initial state Ai C = (r , a(u)) = inv (Pimi ). inv (Pi1 ).(Qi , a(u)|Qi , a(u)
qc(C0 , R)|inv (Qi ) ). Proposition 20, Aai .C a(v), accepting state.
Now, (p21), v0 , v1 , . . . , vmi = v (vj , vj1 ) E(inv (Pij )),
a(u)|Qi a(v0 ) a(v0 )|inv (Qi ) a(u) qc(C0 , R)|inv (Qi ) a(u), is, (v0 , v)
(Pi1 . . . Pimi )I ar(Qi , u, v0 ). Hence, (u, v0 ) QIi (u, v) (Qi Pi1 . . . Pimi )I .
Ri v Ti1 Timi : Let (u, v) RiI . Then,
(p19), Asi .C a(u),
Wm

(Tih , a(u)|Tih , a(u) qc(C0 , R)|inv (Tih ) ).
initial state Ai C = (r , a(u)) = h=1

Proposition 20, Ai .C a(v), accepting state. Now, (p22),
j {1, . . . , mi } a(u)|Tij a(v) a(v)|inv (Tij ) a(u)qc(C0 , R)|inv (Tij )
a(u), i.e., ar(Tij , u, v). Hence, (u, v) TijI (u, v) (Ti1 Timi )I .
Ri = Qi Pi1 . . . Pimi : Let (u, v) RiI . exists role chain % L(ARi )
(u, v) E(%). % L(Ai ) (u, v) (Qi Pi1 . . . Pimi )I , proof
Ri v Qi Pi1 . . . Pimi . suppose %
/ L(Ai ) shortest possible. Since % vR0 Ri ,
sequence % vr1 %1 vr2 vrn %n vrn+1 Ri , r j R0 , 1 j n + 1,
least one r j Ri . r j 6 Ri , j < n + 1, find shorter %,
r n+1 = (Qi Pi1 . . . Pimi v Ri ). Therefore, % = %00 %01 . . . %0mi %00 vR0 Qi
%0j vR0 Pij , 1 j mi . Thus, (u, v) (Qi Pi1 . . . Pimi )I .
Let (u, v) (Qi Pi1 . . . Pimi )I . exists v0 (u, v0 ) QIi
(v0 , v) (Pi1 . . . Pimi )I . case (u, v0 ) E(Qi )\E(Qi ) construction
E(Qi ) (% L(Ai ))(z) (u, z) E(%). v = z (u, v) RiI .
Otherwise proof Qi Pi1 . . . Pimi v Ri .
Ri = Ti1 Timi : Similar previous case.
prove satisfies C0 , show
C c(u) implies u C , u C con(C0 ).
834

(14)

fiA Decidable Extension SROIQ Complex Role Chains Unions

Together (p1), imply u0 (C0 )I . prove (14) induction construction concepts. C concept name (14) follows definition.
>, follows (p3), C1 u C2 , C1 C2 , R.C, qS.C, S.Self ,
(p6), (p7), (p8), (p11) (p4). case C follows (p2) (p5) case
qS.C follows (p10) (p12). Consider (only interesting) case C R.D.
Let R.D c(u) (u, v) RI . (p17) AsR .D a(u), initial
state. Therefore, Proposition 20, AaR .D a(v) accepting state.
Now, (p18), c(v); IH, v DI , thus u (R.D)I .
nom(C0 ), (p14), vo c(vo ), vo oI . u oI
c(u), so, (p13), u = vo . Thus, oI singleton set.
() Suppose = (I , ) model C0 R. define = (S, c, a, E) taking
= ,

E(R) = RI ,

c(u) = {C con(C0 ) | u C } {>}

define a(u) follows. First, define induction C auxiliary sets a0 (u, r),
r RI (C)(F). Recalling r 0 C r i, 1 l, set
a0 (u, r 0 ) = {AsR .C | initial state, R.C con(C0 ) u (R.C)I }
{AqR .C qc | S1 S2 . . . Sn L(AqR ), u (S1 .S2 . Sn .C)I
L(AqR ) u C }.
Then, assuming a0 (u, r 0 ) defined every r 0 C ri , set
a0 (u, r ) = {Aqi .C | v w (role(C0 , R)) (w, q) prefix L(Ai ),
(v, u) (w)I , C = (r ,

[

a0 (v, r 0 ))},

r 0 Cri

(w)I = S1I . . . SnI , w = S1 . . . Sn ,
prefix L(Ai ) = {(w, q) | q state Ai , w0 L(Aqi ) ww0 L(Ai )}.

Note {Asi .C | initial state, C = (r , r0 Cri a0 (u, r 0 )} a0 (u, r ).
Finally, set
l
[
a(u) =
a0 (u, r j ).
j=0

prove tableau C0 w.r.t. R. Properties (p1)(p16) follow immediately definitions c E, (p17)(p19) follow definitions
c(u) a(u). (p20), suppose (u, v) E(R), Ap .C a(u) q (p, R).
Ap .C a0 (u, r ), i. > 0 = Ai and,
definition
a0 (u, r ), u0 w (role(C0 , R)) C = (r , r0 Cri a0 (u0 , r 0 )),
(w, p) prefix L(A) (u0 , u) (w)I . Let w0 = wR. (w0 , q) prefix L(A)
(u0 , v) (w0 )I , Aq .C a0 (v, r ) a(v).
Api .C

Asi .C
u0

w

u

835

Aqi .C
R

v

fiMosurovic, Krdzavac, Henson & Zakharyaschev

= 0 (i.e., C concept C Ap .C a0 (u, r 0 )), suppose Aq .C
/ a0 (v, r 0 ).
0
definition (v, r 0 ), two reasons (Horrocks et al., 2006):
S2 . . . Sn L(Aq ) v
/ (S2 . Sn .C)I . However, implies
p
RS2 . . . Sn L(A ) u
/ (R.S2 . Sn .C)I , contrary Ap .C a0 (u).
L(Aq ) v
/ C . R L(Ap ) u
/ (R.C)I ,
contradiction.
Therefore, Aq .C a0 (v, r 0 ), a(u)|R a(v).
show (p21) (p22), suppose Aai .C a(u), accepting state.
definition a(u),
v w (role(C0 , R)) (w, a) prefix L(Ai ),

(v, u) (w) C = (r , r0 Cri a0 (v, r 0 )) = (r , a(v)). Since accepting state,
w L(Ai ), (v, u) (Ri )I .
(p21)i.e., kwe C = inv (Pimi ). inv (Pi1 ).(tr , , ), tr = Qi ,
= a(v)|Qi , = a(v) qc(C0 , R)|inv (Qi ) . also (v, u) (Qi Pi1 . . . Pimi )I ,
v0 , v1 , . . . , vmi = u (vj1 , vj ) PijI (v, v0 ) QIi . Therefore,
(p20), a(v0 ) a(v0 )|inv (tr ) .
W r


r
(p22)i.e., > kwe C =
h=1 (th , th , th ), th = Tih , th = a(v)|Tih ,


th = a(v) qc(C0 , R)|inv (Tih ) 1 h mi . also (v, u) (Ti1 Timi )I ,
j {1, . . . , mi } (v, u) TijI . Therefore, (p20), tj a(u)
a(u)|inv (tr )
j .
j

q

(p23) considered way (p20).

Appendix B. Tableau Algorithm
tableau algorithm, SR+ OIQ concepts C0 RBoxes R, works completion
graphs similarly algorithms given Horrocks et al. (2006) Horrocks Sattler
(2007). present it, require additional notation. assume given R
Appendix RC,D,E,F = {r | = 1, . . . , l}. 1 l basic role
P , P = Qi k, P {Ti1 , . . . , Timi } > k, let
qc (r , P ) = {Ap .C | exists q (p, P ), Ap .C

[

qc(r j )}

r j Cr

{Aq .C | q (p, inv (P )), Ap .C

[

qc(r j )}.

r j Cr



set qc (r ) = qc (r , Qi ), k, qc (r ) =
j=1 qc (r , Tij ), > k.
set qc (r ) quasi-concepts guessed algorithm. Let qc(C0 , R)
minimal set that:

qc(C0 , R) {Ap .C | Ap .C li=1 qc (r )} qc(C0 , R),
Ap .C qc(C0 , R) C qc(C0 , R),
P.C qc(C0 , R) C qc(C0 , R),
836

fiA Decidable Extension SROIQ Complex Role Chains Unions

(

Wm

j=1 Cj )

qc(C0 , R) {C1 , . . . , Cm } qc(C0 , R).

Unlike qc(C0 , R), set qc(C0 , R) contains sub-quasi-concepts. (Quasi-concepts
form Ap .C used make sure Ap .C belong label.)
Given SR+ OIQ concept C0 RBox R, completion graph C0 R
structure form G = (V1 , V2 , E1 , E2 , c, a, l, ),
V1 V2 = ; elements V1 called root nodes, elements V2 called
internal (or non-root) nodes;
(V, E1 ) directed forest nodes V = V1 V2 arcs E1 (its roots
incoming arcs);
E2 set arcs nodes root nodes, well arcs form (x, x),
x V2 ;
(x, y) E, E = E1 E2 , l(x, y) role(C0 , R); R0 l(x, y)
R0 v R, called R-successor x; called R-neighbour x
R-successor x x inv (R)-successor y; also, x called -neighbour
x (cf. Horrocks et al., 2006);
x V , c(x) con(C0 ) { mS.C | nS.C con(C0 ), < n}
a(x) qc(C0 , R);
symmetric binary relation V ;
nom(C0 ), x V1 c(x).
Following Horrocks et al. (2006) Horrocks Sattler (2007), distinguish
two sets nodes: V1 arbitrarily interconnected (they called root nodes),
V2 form tree structure (they called internal nodes). Intuitively,
completion graph collection trees whose root nodes arbitrarily connected
may also arcs internal nodes root nodes (see Fig. 2 page 841). also
distinguish two sets arcs: E1 connect nodes tree,
E2 remaining arcs graph.
illustrate difference R-successors neighbours, suppose (R0 v R) R
x

l(x, y) = {R0 }



l(x, y) = {R0 }, picture above. R0 - R-successor x,
x neither inv (R0 )- inv (R)-successor y; R0 - R-neighbour
x, x inv (R0 )- inv (R)-neighbour y.
ensure tableau algorithm eventually comes stop, use blocking
technique similar one Horrocks et al. (2006). node x V2 called
blocked either directly indirectly blocked. node x V2 directly blocked none
(not necessarily immediate) E1 -ancestors blocked, nodes x0 , 0
that:
0 root,
837

fiMosurovic, Krdzavac, Henson & Zakharyaschev

(x0 , x) E1 , (y 0 , y) E1 E1 -ancestor x0 ,
c(x) = c(y), c(x0 ) = c(y 0 ), a(x) = a(y), a(x0 ) = a(y 0 ) l(x0 , x) = l(y 0 , y).
case say blocks x.
root

0
0 l(y , y)

0
x0 l(x , x) x

node indirectly blocked one E1 -ancestors blocked.
simple role S, x V C con(C0 ), let
G (x, C) ={y | S-neighbour x, C c(y)
x V1 indirectly blocked}.
say completion graph G contains clash x V least one
following conditions holds:
c(x),
{A, A} c(x), concept name A,
{Ap .C, Ap .C} a(x), quasi-concept Ap .C

Sl

i=1 qc

(r

),

x S-neighbour x S.Self c(x),
Dis(R, S) R, R- S-neighbour x, V ,
( nS.C) c(x), {y0 , . . . , yn } G (x, C) yi yj , 0 < j n,
nom(C0 ), node x c(x) c(y),
C = (tr , , ) a(x) a(x)|inv (tr ) 6 .
completion graph contain clash called clash-free.
simplify tableau rules, require terminology notation originally used
Horrocks et al. (2006) Horrocks Sattler (2007). R-neighbour x
said safe either x V2 x V1 blocked. result (and
procedure) pruning node G = (V1 , V2 , E1 , E2 , c, a, l, ), denoted Prune(y),
graph obtained G following way: remove every (y, z) E and, z V2 ,
Prune(z); also remove V . result (and procedure) merging nodes
x G = (V1 , V2 , E1 , E2 , c, a, l, ), denoted Merge(y, x), graph obtained G
follows:
1. z (z, y) E:
{(x, z), (z, x)} E = , add (z, x) E (to E1 x V2 , otherwise E2 )
set l(z, x) := l(z, y),
(z, x) E, set l(z, x) := l(z, x) l(z, y),
(x, z) E, set l(x, z) := l(x, z) {inv (R) | R l(z, y)},
838

fiA Decidable Extension SROIQ Complex Role Chains Unions

remove (z, y) E;
2. root nodes z (y, z) E2 :
{(x, z), (z, x)} E = , add (x, z) E2 set l(x, z) := l(y, z),
(x, z) E, set l(x, z) := l(x, z) l(y, z),
(z, x) E, set l(z, x) := l(z, x) {inv (R) | R l(y, z)},
remove (y, z) E2 ;
3. set c(x) := c(x) c(y) a(x) := a(x) a(y);
4. add x z, z z;
5. Prune(y).
Let G = (V1 , V2 , E1 , E2 , c, a, l, ) completion graph. completion rules extend
G two ways: adding new leaf adding new root. say node x V2 ,
(y, x) E1 , level forest (V, E1 ) either = 1 V1 , > 1
V2 level 1 (V, E1 ). node x V1 level graph (V1 , E2 (V1 V1 ))
either = 0 exists nom(C0 ) c(x), > 0, x level
(i 1) (V1 , E2 (V1 V1 )) V1 level 1 (V1 , E2 (V1 V1 ))
(y, x) E2 .
tableau rules applied according following strategy: (o)-rule
highest priority; apply (=r )- (r )-rules, starting root nodes
lower levels; applications rules follow.
tableau algorithm non-deterministic. takes SR+ OIQ concept C0
RBox R input returns yes indicate whether C0 satisfiable w.r.t. R not.
algorithm starts constructing completion graph G = (V1 , V2 , E1 , E2 , c, a, l, ),

V1 = {xo | nom(C0 )} {xC0 },
V2 = ,
E1 = , E2 = ,
c(xo ) = {o}, c(xC0 ) = {C0 },
a(xo ) = , a(xC0 ) = ,
l = ,
empty.
algorithm non-deterministically applies one completion rules given Tables 1 2; keeps till either current completion graph contains clash,
case answer no, none rules applicable, case algorithm
returns yes.
prove algorithm always comes stop returns correct answer,
require following lemma:
839

fiMosurovic, Krdzavac, Henson & Zakharyaschev

Lemma 21 Let G = (V1 , V2 , E1 , E2 , c, a, l, ) structure constructed step
algorithm. Then, every x V2 , exists exactly one V (y, x) E1 .
Proof. proof induction number steps. basis induction (V2 = )
trivial. suppose claim holds step consider happens
application completion rule. applying rules (), (r8) () node x,
add one nodes V2 , x predecessor nodes. Also,
consider rules (), (o) (=r ), merge nodes, rules
change V2 E1 . Merging nodes changes graph possibly adding new edges,
deleting edges pruning nodes. Observe prune node
claim still holds delete successors belong V2 . Deleting edge
spoil claim either. Thus, enough examine cases new edge
added E1 . Merge(y, x) x V1 newly added edges belong E2 ,
applying Merge(y, x) claim still holds. interesting case apply
Merge(z, y) rule () ( nS.C) c(x), y, z G (x, C) y, z V2 .
y, z V2 , nodes z one parent node, although z ancestor
y; following fours cases possible.
Case 1: (y, x) E1 (x, z) E1 . new edge added E1 , claim
holds.
Case 2: (x, y) E1 (x, z) E1 . Again, add new edge E1 .
Case 3: (y, x) E1 (z, x) E1 . case x V2 x two parent nodes
z, impossible IH.
Case 4: (y, x) E2 (z, x) E2 . case possible either x V1 ,
( nS.C) c(x), (or z) S-neighbour x, applying ()
apply (r ) (=r ) view higher priority.
q
show termination.
Lemma 22 tableau algorithm always terminates.
Proof. sets con(C0 ), qc(C0 , R), role(C0 , R) use labels nodes edges
finite. Let l0 = ]nom(C0 ), l1 = ]con(C0 ), l2 = ]qc(C0 , R), l3 = ]role(C0 , R)
nmax = max{n | ( nR.C) con(C0 ) ( nR.C) con(C0 )}. completion graph
completion rules following properties. node x labelled two sets
c(x) con(C0 ) a(x) qc(C0 , R). number different pairs labels
exceed 2l1 +l2 . edge (x, y) labelled set l(x, y) role(C0 , R), number
different labels edges 2l3 . number different labels pair nodes
connected arc L = 2l3 +2l1 +2l2 . Therefore, path forest (V, E1 ),
starts root node length L + 2, contains blocked node. Every
application rule determined (quasi-) concept node, rule
applicable (quasi-) concept node once. completion rules never
remove labels nodes graph, rules remove nodes (), (o)
(=r ). (), (), (r ) (r8) generate new nodes, generation
triggered (quasi-) concept form R.C, nR.C, nR.C P.C label
node x. number concepts l1 + l2 . rules () (r ) generate
nmax successors given node, concept form nR.C nR.C.
840

fiA Decidable Extension SROIQ Complex Role Chains Unions

two rules generate one successor concept. follows number
created outgoing arcs node exceed l1 nmax + l2 . node removed
G (), (o) (=r ), label migrates node z. rules (), (), (r )
(r8), generate later merged (), (o) (=r ), applied
node.
Now, show number nodes completion graph limited. Together
observations above, mean apply completion rules finitely
many times, algorithm eventually come stop.
end, require following claim: x V1 level (V1 , E2 (V1 V1 )),
V2 indirectly blocked (y, x) E2 , level L + 2 (V, E1 ).
Indeed, = 0, level L + 2 indirectly blocked node
> L + 2 level indirectly blocked. x level > 0 way add edge
(y, x) E2 first apply rule (o), add E2 -edge y0 V2
x0 V1 , repeatedly apply (=r ). node x0 level 0 (V1 , E2 (V1 V1 )),
y0 level L + 2 (V, E1 ). apply rule (=r ), y0 merged
successor x1 V1 x0 created application (r ). node x1 level
1, add edge (y1 , x1 ) E2 , y1 parent y0 level L + 2 1
(V, E1 ); see Fig. 2. repeating argument, see node level
L + 2 (V, E1 ).
x0

x0
x1

y1

y1

x1

y0

Figure 2: application (=r ); bold arcs E2 nodes
V1 .
claim proved means node x V1 level L+2 (V1 , E2 (V1 V1 )),
V2 (y, x) E2 . Hence, rule (r ) cannot applied node
x level L + 2, root node level L + 3.
rule add new nodes V1 (r ). applied l1 times
given node add l1 nmax successors. beginning V1 \{xC0 } contains
l0 nodes, (r ) create l0 l1 nmax successors nodes. applying
(r ) again, obtain l0 (l1 nmax )2 new nodes (of level 2). follows
]V1 1 +

L+2
X

l0 (l1 nmax )i = O(l0 (l1 nmax )L+3 ).

i=0

number nodes V2 also limited. beginning V2 = . node V1 ,
algorithm create l1 nmax + l2 arcs lead nodes V2 . Thus, number
841

fiMosurovic, Krdzavac, Henson & Zakharyaschev

nodes level 1 V2 exceed ]V1 (l1 nmax + l2 ); number successors
]V1 (l1 nmax + l2 )2 ; finally,
]V2

L+2
X

]V1 (l1 nmax + l2 )i = O(]V1 (l1 nmax + l2 )L+3 ).

i=1

q

completes proof lemma.
next lemma shows answers returned algorithm correct.

Lemma 23 tableau algorithm returns yes exists tableau C0
w.r.t. R.
Proof. () Suppose algorithm returns yes generating clash-free completion graph
G = (V1 , V2 , E1 , E2 , c, a, l, ) completion rule applicable. Let V = V1 V2
E = E1 E2 . write (x) = x, x V1 x V2 blocked; (x) = y,
x V2 blocks x.
Define set paths(G) inductively taking (cf. Horrocks et al., 2006):
x0 V1 (x0 , x0 ) paths(G); case write Root(x0 ) = (x0 , x0 ),
paths(G), node z V2 indirectly blocked (tail (), z) E1 ,
sequence , ((z), z) paths(G).
tail () = xn tail 0 () = x0n , = (x0 , x00 ), . . . , (xn , x0n ). members
paths(G) called paths G.
define tableau = (S, c0 , a0 , E) taking = paths(G), c0 () = c(tail ()),
a0 () = a(tail ()) qc(C0 , R), paths(G),
E(R) ={(Root(x), Root(y)) | R-neighbour x}
{(u, Root(y)) | R-neighbour tail (u)}
{(Root(x), u) | tail (u) R-neighbour x}
{(u, u) | tail (u) R-neighbour tail (u)}
{(u, v) | v = u, ((y), y) R-neighbour tail (u),
u = v, ((y), y) inv (R)-neighbour tail (v)}.
prove tableau C0 w.r.t. R. Indeed, (p1) (p14) follow
initial step tableau algorithm fact labels root nodes never
removed; (p2) follows definition fact completion graph G clashfree; (p3) follows rules creating new nodes G clash-free; (p9) (p16)
follow definitions E(R) R-neighbour (and R-successor); (p6) (p7) follow
fact rules (u) (t) applicable; (p12) follows definitions
E(R) R-neighbour fact rule (guess) applicable; (p15) (p5)
follow definitions E(R) R-neighbour completion graph G
clash-free; (p17) (p18) follow fact (r1) (r3) applicable; (p19)
fact (r5i ) cannot applied; (p20) (p23) follow definitions
E(R) fact (r2) (r6) applicable. remaining cases less
straightforward. them, require following:
842

fiA Decidable Extension SROIQ Complex Role Chains Unions

(u)

C1 u C2 c(x), x indirectly blocked {C1 , C2 } 6 c(x),
c(x) := c(x) {C1 , C2 }

(t)

C1 C2 c(x), x indirectly blocked {C1 , C2 } c(x) = ,
c(x) := c(x) {D}, {C1 , C2 }

()

S.C c(x), x blocked safe S-neighbour C c(y)
create new node V2 l(x, y) := {S}, c(y) := {C, >}, a(y) :=

(self)

S.Self c(x), x blocked x S-neighbour x
add (x, x) E2 , yet, set l(x, x) := l(x, x) {S}

(guess)

( nS.C) c(x), x indirectly blocked
S-neighbour x {C, C} c(y) = ,
set c(y) := c(y) {D}, {C, C}

()

( nS.C) c(x), x blocked distinct safe
y1 , . . . , yn G (x, C), create n new successors y1 , . . . , yn V2 x; set
l(x, yi ) := {S}, c(yi ) := {C, >}, a(yi ) := , yi yj , 1 < j n

()

( nS.C) c(x), x indirectly blocked, ]S G (x, C) > n
y, z G (x, C) z hold
(1) z root node E1 -ancestor y, Merge(y, z),
(2) otherwise Merge(z, y)

(o)

if, o, o0 nom(C0 ), node 6= xo o0 c(xo ) c(y)
xo hold completion graph,
Merge(y, xo )

(r )

( nS.C) c(x), x V1 , S-neighbour x
V2 , (y, x) E2 , C c(y) indirectly blocked;
n0 n ( n0 S.C) c(x) S-neighbours
z1 , . . . , zn0 V1 x C c(zi ) zi zj , 1 i, j n0 , 6= j,
(1) guess m, 1 n, set c(x) := c(x) {( mS.C)},
(2) create new nodes y1 , . . . , ym V1
l(x, yi ) := {S}, c(yi ) := {C, >}, a(yi ) := yi yj , 1 < j

(=r )

( mS.C) c(x), x V1 , S-neighbour V2 x
C c(y), indirectly blocked S-neighbours
z1 , . . . , zm V1 x C c(zi ) zi zj , 1 i, j m, 6= j,
j0 , 1 j0 zj0 hold,
Merge(y, zj0 )
Table 1: Completion rules SR+ OIQ tableau algorithm.

843

fiMosurovic, Krdzavac, Henson & Zakharyaschev

(r1)

R.C c(x), x indirectly blocked AsR .C 6 a(x), initial state,
a(x) := a(x) {AsR .C}

(r2)

ApR .C a(x), q AR (p, ) (where ), x indirectly blocked,
-neighbour x AqR .C 6 a(y),
a(y) := a(y) {AqR .C}

(r3)

AaR .C a(x), accepting state, x indirectly blocked C
/ c(x),
c(x) := c(x) {C}

(r4i )

x indirectly blocked C qc (r ) {C, C} a(x) = ,
a(x) := a(x) {D}, {C, C}

(r5i )

x indirectly blocked, (r4i ) applicable, Asi .C 6 a(x),
C = (r , a(x)), initial state s, a(x) := a(x) {Asi .C}

(r6)

Ap .C a(x), x indirectly blocked, q (p, ) (where ),
-neighbour x Aq .C 6 a(y),
a(y) := a(y) {Aq .C}

(r7)

Aa .C a(x), accepting state, x indirectly blocked C
/ a(x),
a(x) := a(x) {C}

(r8)

P.C a(x), x blocked x safe P -neighbour C a(y),
create new node V2 set l(x, y) := {P }, c(y) := {>}, a(y) := {C}
W
C a(x), C =
j=1 Cj , x indirectly blocked, {C1 , . . . , Cm } a(x) = ,
a(x) := a(x) {D}, {C1 , . . . , Cm }

(r9)
(r10)

C a(x), C = (tr , , ), x indirectly blocked 6 a(x),
set a(x) := a(x)
Table 2: Completion rules SR+ OIQ tableau algorithm (cont.)

844

fiA Decidable Extension SROIQ Complex Role Chains Unions

Proposition 24 Suppose u paths(G), x = tail (u) x safe R-neighbour V .
v paths(G) (u, v) E(R), c0 (v) = c(y) a0 (v) = a(y) qc(C0 , R).
Proof. R-neighbour x, either (x, y) E (y, x) E. Four cases possible:
(x, y) E1 , set v = u, ((y), y).
(x, y) E2 , V1 set v = Root(y).
(y, x) E1 predecessor x. case tail 0 (u) = x,
exists path v tail (v) = u = v, (x, x); case tail 0 (u) 6= x
(i.e., x blocks tail 0 (u)), exist predecessor 0 tail 0 (u) (c(y 0 ) = c(y),
a(y 0 ) = a(y) 0 R-neighbour tail 0 (u)) path v tail (v) = 0
u = v, (x, tail 0 (u)).
(y, x) E2 x V1 , u = Root(x). set v = Root(y) V1 . V2
blocked (since safe), exists path v tail (v) = y.
q

cases, v required.

(p4) S.Self c0 (u) S.Self c(tail (u)). Since (self) applicable, tail (u)
S-neighbour tail (u), (u, u) E(R).
(p8) R.C c0 (u) R.C c(x), x = tail (u). Since () applicable, x
safe R-neighbour C c(y). Proposition 24, exists v paths(G)
(u, v) E(R) C c0 (v).
(p10) nS.C c0 (u) nS.C c(x), x = tail (u). Since completion
graph G clash-free () (=r ) applicable, ]S G (x, C) n. Suppose
(u, v) E(R) C c0 (v). definition E(R), following cases possible:
u = Root(x), v = Root(y) R-neighbour x. G (x, C) and,
since V1 , v 0 paths(G) different v = tail (v 0 )
= tail 0 (v 0 ).
x V2 , v = Root(y) R-neighbour x. case considered analogously.
u = Root(x), = tail (v) V2 , v 6= u, (y, tail 0 (v)) R-neighbour x.
case possible since nS.C c(x), x V1 , (y, x) E2 rules (r )
(=r ) applicable.
v = u x R-neighbour x. x G (x, C) v 0 paths(G)
different u (u, v 0 ) E(R) x = tail (v 0 ) x = tail 0 (v 0 ).
v = u, ((y), y) R-neighbour x. G (x, C), V2 x
predecessor y. v 0 paths(G) different v
(u, v 0 ) E(R) = tail (v 0 ) = tail 0 (v 0 ).
u = v, (x, y), x = (y) inv (R)-neighbour tail (v). tail (v)
G (x, C), V2 tail (v) one predecessor y; v 0 paths(G)
different v (u, v 0 ) E(R) tail (v) = tail (v 0 ) tail (v) = tail 0 (v 0 ).
845

fiMosurovic, Krdzavac, Henson & Zakharyaschev

Therefore, ]{v | (u, v) E(S) C c(v)} ]S G (x, C) n.
(p11) ( nS.C) c0 (u) ( nS.C) c(x), x = tail (u). Since ()
applicable, x safe S-neighbours y1 , . . . , yn C c(yi ) yi yj , 1 i, j n
j 6= i. Proposition 24, exists vi paths(G) (u, vi ) E(S)
C c0 (vi ), 1 n. addition, one (y, x) E1 and,
proof Proposition 24, (yi , x) 6 E1 tail (vi ) = yi tail 0 (vi ) = yi . So, vi vj
distinct 6= j, since tail (vi ) 6= tail (vj ) tail 0 (vi ) 6= tail 0 (vj ) (in case (yi , x) E1 ,
(x, yj ) E1 yi block yj , i.e., tail (vi ) = tail (vj ) = yi , tail 0 (vi ) 6= tail 0 (vj )).
(p13) c0 (u) c0 (v) c(tail (u)), o0 nom(C0 )
xo0 = tail (u) u = Root(xo0 ). Similarly, o00 nom(C0 ) xo00 = tail (v)
v = Root(xo00 ). Since rule (o) applicable, xo0 = xo00 , soWu = v.
r

(p22) Let Aai .C a0 (u), accepting state C =
h=1 (th , th , th ).
Aai .C a(x), x = tail (u). Since (r7) cannot applied, C a(x), since (r9)
applicable, j Cj = (trj , tj ,
j ) a(x). Now, (r10) applicable,


0
tj a(x); since G clash-free, a(x)|inv (tr )
j . Thus, tj (u)
j

a0 (u)|inv (tr )
j .
j

(p21) Let Aai .C a0 (u), C = inv (Pimi ). inv (Pi1 ).(tr , , )
accepting state. Aai .C a(tail (u)). prove induction j vj
inv (Pij ). inv (Pi1 ).(tr , , ) a(tail (vj )). j = mi , set vmi = u. (r7)
applicable tail (vmi ), inv (Pimi ). inv (Pi1 ).(tr , , ) a(tail (vmi )), establishes
induction basis. Assume claim holds j prove j 1. tail (vj )
blocked (r8) applicable, safe inv (Pij )-neighbour yj1 tail (vj )
inv (Pi(j1) ). inv (Pi1 ).(tr , , ) a(yj1 ). Proposition 24,
vj1 paths(G) (vj , vj1 ) E(inv (Pij )) inv (Pi(j1) ). inv (Pi1 ).(tr , , )
a(tail (vj1 )). j = 0, (tr , , ) a(tail (v0 )). Further, (r10) cannot
applied, a(tail (v0 )); since G clash-free, a(tail (v0 ))|inv (tr ) . Thus,
a0 (v0 ) a0 (v0 )|inv (tr ) .
() Take tableau = (S, c0 , a0 , E) C0 w.r.t. R extend following way:
(e1) Aai .C a0 (u), C = inv (Pimi ). inv (Pi1 ).(tr , , ) accepting
state, then, (p21), v0 , v1 , . . . , vmi = u (vj , vj1 ) E(inv (Pij )),
1 j mi , a0 (v0 ) a0 (v0 )|inv (tr ) . case, extend a0 (vj )
taking a0 (vj ) := a0 (vj ) {inv (Pij ). inv (Pi1 ).(tr , , )}, 0 j mi .
W r
(e2) Aai .C a0 (u), C =
h=1 (th , th , th ), then, (p22), j {1, . . . , mi }
0
tj a0 (u) a0 (u)|inv (tr )
j . case, extend (u) taking
j

a0 (u) := a0 (u) {C, Cj }.

(e3) exists C li=0 qc (r ) C 6 a0 (u), a0 (u) := a0 (u) {C}.
(e4) ( nS.C) c0 (u) (u, C) = {v | (u, v) E(S), C c(v)} = {v1 , . . . , vm }
then, view (p10), n. case, extend c0 (u) taking
c0 (u) := c0 (u) { mS.C}.
apply completion rules using extended tableau end
algorithm obtains clash-free completion graph G = (V1 , V2 , E1 , E2 , c, a, l, ) returns
846

fiA Decidable Extension SROIQ Complex Role Chains Unions

yes. purpose, define map : V steer applications nondeterministic completion rules way c(x) c0 ((x)) a(x) a0 ((x)),
nodes x V (cf. Horrocks, Kutz, & Sattler, 2005; Horrocks et al., 2006). Furthermore,
require that, pair nodes x, role R, R-successor x,
((x), (y)) E(R), x implies (x) 6= (y). ensure G clash-free,
since tableau clash-free.
define induction follows. begin with, (p14), nom(C0 ),
vo c0 (vo ), (p1), u0 C0 c0 (u0 ).
algorithm starts constructing nodes xo , nom(C0 ), xC0 c(xo ) = {o}
c(xC0 ) = {C0 }. set (xo ) = vo (xC0 ) = u0 .
Observe c(xo ) c0 ((xo )) c(xC0 ) c0 ((xC0 )); also a(xo ) = a0 ((xo ))
a(xC0 ) = a0 ((xC0 )). consider applications completion rules.
(u) applied x V C1 u C2 c(x), C1 u C2 c0 ((x)), so,
(p6), C1 , C2 c0 ((x)). apply (u), C1 , C2 added c(x),
c(x) c0 ((x)).
(t) applied x V C1 C2 c(x), C1 C2 c0 ((x)), so,
(p7), {C1 , C2 } c0 ((x)) 6= . apply (t) c(x) := c(x) {D}
{C1 , C2 } c0 ((x)), c(x) c0 ((x)).
() applied x V S.C c(x), S.C c0 ((x)), so, (p8),
v ((x), v) E(S) C c0 (v). (p3), > c0 (v) and, (p16)
v 0 , ((x), v) E(S 0 ). apply () new node created
l(x, y) := {S}, c(y) := {C, >} , a(y) := (y) = v. c(y) c0 ((y)),
a(y) a0 ((y)) ((x), (y)) E(S 0 ).
(self) applied x V S.Self c(x), S.Self c0 ((x)), so,
(p4), ((x), (x)) E(S). (p16) v 0 , ((x), (x)) E(S 0 ).
apply (self) adding arc (x, x), yet, setting l(x, x) :=
l(x, x) {S}. obtain ((x), (x)) E(S 0 ).
(guess) applied x V ( nS.C) c(x) S-neighbour x,
( nS.C) c0 ((x)), ((x), (y)) E(S), so, (p12), {C, C} c0 ((y)) 6= .
apply (guess) c(y) := c(y) {D}, {C, C} c0 ((y). Hence
c(y) c0 ((y)).
() applied x V ( nS.C) c(x), ( nS.C) c0 ((x)). (p11),
v1 , . . . , vn ((x), C), (u, C) = {v | (u, v) E(S), C
c(v)}. apply () creating n new successors y1 , . . . , yn x setting l(x, yi ) :=
{S}, c(yi ) := {C, >}, a(yi ) := , yi yj (yi ) = vi , 1 i, j n, j 6= i. Then,
v 0 , ((x), (yi )) E(S 0 ) also c(yi ) c0 ((yi )), 1 n.
() applied x V ( nS.C) c(x) {y1 , . . . , yn+1 } G (x, C),
( nS.C) c0 ((x)) {(y1 ), . . . , (yn+1 )} ((x), C). (p10),
]S ((x), C) n, j1 , j2 (yj1 ) = (yj2 ) = v. Instead yj1 ,
yj2 , write y, z; precisely yj1 root E1 -ancestor yj2
847

fiMosurovic, Krdzavac, Henson & Zakharyaschev

set z = yj1 = yj2 , otherwise set z = yj2 = yj1 . apply ()
performing Merge(y, z). Since (z) = v, required conditions hold.
(=r ), proof similar previous case.
(o) applied V o0 c(xo ) c(y), o, o0 nom(C0 ),
o0 c0 ((xo )) c0 ((y)). (p13), (xo ) = (y), therefore c(xo ) c(y)
c0 ((xo )) c0 ((y)) = c0 ((xo )). Similarly, a(xo ) a(y) a0 ((xo )). apply (o)
performing Merge(y, xo ), required conditions hold again.
(r ) applied x V1 S-neighbour x ( nS.C) c(x),
V2 , (y, x) E2 C c(y), ( nS.C) c0 ((x)), ((x), (y)) E(S)
C c0 ((y)). (p10), ]S ((x), C) n, ((x), C) = {v1 , . . . , vm },
n. apply (r ) c(x) := c(x) {( mS.C)}, create new nodes
y1 , . . . , ym V1 l(x, yi ) := {S}, c(yi ) := {C, >}, a(yi ) := , yi yj (yi ) = vi
1 m, 1 j < i. Then, v 0 , ((x), (yi )) E(S 0 ),
c(yi ) c0 ((yi )), 1 m, also, (e4), c(x) c0 ((x)).
(r1) applied x V R.C c(x), R.C c0 ((x)), so,
(p17), AsR .C a0 ((x)), initial state AR . apply (r1)
a(x) := a(x) {AsR .C}. Clearly, a(x) a0 ((x)).
(r2) applied x V ApR .C a(x), q AR (p, ), -neighbour
x, ApR .C a0 ((x)). 6= ((x), (y)) E(T ) and, (p20),
AqR .C a0 ((y)). = = x and, (p23), AqR .C a0 ((y)).
cases apply (r2) a(y) := a(y) {AqR .C}, a(y) a0 ((y)).
(r3) applied x V AaR .C a(x), accepting state,
AaR .C a0 ((x)). (p18), C c0 ((x)). apply (r3) c(x) := c(x) {C}.
Thus, c(x) c0 ((x)).
(r4i ) applied x V C qc (r ), then, (e3), {C, C} a0 ((x)) 6= .
apply (r4i ) a(x) := a(x) {D}, {C, C} a0 ((x)). Thus,
a(x) a0 ((x)).
(r5i ) applied x V , Asi .C 6 a(x), initial state Ai
C = (r , a(x)). (p19), Asi .C0 a0 ((x)), C0 = (r , a0 ((x))). Suppose
C 6= C0 . Since a(x) a0 ((x)), exists C1 qc (r ) C1 a0 ((x))
C1 6 a(x). (r4i ) applicable, C1 a(x), C1 a0 ((x)),
contradiction. Hence C = C0 . apply (r5i ) a(x) := a(x){Asi .C}.
Thus, a(x) a0 ((x)).
(r6) applied x V Ap .C a(x), q AR (p, ), -neighbour
x, Ap .C a0 ((x)). 6= ((x), (y)) E(T ) and, (p20),
Aq .C a0 ((y)). = = x and, (p23), Aq .C a0 ((y)). either case,
apply (r6) a(y) := a(y) {Aq .C}. Thus, a(y) a0 ((y)).
(r7) applied x V Aa .C a(x), accepting state,
Aa .C a0 ((x)). (e1) (e2), C a0 ((x)). apply (r7) way
a(x) := a(x) {C}. Thus, a(x) a0 ((x)).
848

fiA Decidable Extension SROIQ Complex Role Chains Unions

(r8) applied x V P.C a(x), P.C a0 ((x)), so, (e1),
v ((x), v) E(P ) C a0 (v). (p16) P v 0 ,
((x), v) E(S 0 ). apply (r8) creating new node l(x, y) := {P },
c(y) := {>}, a(y) := {C} (y) = v. Thus, c(y) c0 ((y)), a(y) a0 ((y))
((x), (y)) E(S 0 ).
W
0
(r9) applied x V C a(x), C =
j=1 Cj , C ((x)).
0
means C added ((x)) (e2), so, j Cj a0 ((x)).
apply (r9) a(x) := a(x) {Cj }. Thus, a(x) a0 ((x)).
(r10) applied x V C a(x), C = (tr , , ), C a0 ((x)).
means C added a0 ((x)) (e1) (x) = v0 , (e2). either case,
a0 ((x)). apply (r10) a(x) := a(x) . Thus, a(x) a0 ((x)).
q

completes proof lemma.

immediate consequence Lemmas 19, 22 23, obtain main Theorem 15
according concept satisfiability w.r.t. SR+ OIQ KBs decidable. worth
noting given RBox R contain RAs form (C)(F) tableau
algorithm behaves way algorithm SROIQ (Horrocks et al., 2006).
However, R contains one RA form (C)(F) algorithm construct
set qc(C0 , R) quasi-concepts, contains subsets previously constructed
sets quasi-concepts qc(r 0 ), may suffer exponential blow-up. precisely,
new quasi-concepts qc(C0 , R) built triples form (tr , , ),
qc(r 0 )|tr qc(r 0 )|inv (tr ) . Furthermore, algorithm may suffer one
exponential blow-up every time add extra RA form (C)(F) extend
sequence r i1 C r i2 , r i2 C r i3 , . . . , r ih1 C r ih set quasi-concepts may
become exponentially larger.

References
Baader, F. (2003). Restricted role-value-maps description logic existential restrictions terminological cycles. Proccedings 2003 International Workshop
Description Logics (DL2003).
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2003). Description Logic Handbook: Theory, Implementation Applications.
CUP. (2nd edition, 2007).
Baldoni, M. (1998). Normal Multimodal Logics: Automatic Deduction Logic Programming Extension. Ph.D. thesis, Universita degli Studi di Torino.
Bock, C., Zha, X., Suh, H., & Lee, J. (2010). Ontological product modeling collaborative
design. Advanced Engineering Informatics, 24, 510524.
Bock, C. (2004). UML 2 Composition Model. Journal Object Technology, 3 (10), 4774.
Brachman, R. J., & Schmolze, J. G. (1985). overview KL-ONE knowledge representation system. Cognitive Science, 9 (2), 171216.
849

fiMosurovic, Krdzavac, Henson & Zakharyaschev

Cuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., & Sattler, U.
(2008). OWL 2: next step OWL. Journal Web Semantics, 6 (4), 309322.
del Cerro, L. F., & Penttonen, M. (1988). Grammar logics. Logique et Analyse, 121, 123134.
Demri, S. (2001). complexity regularity grammar logics related modal logics.
Journal Logic Computation, 11 (6), 933960.
Halpern, J., & Moses, Y. (1992). guide completeness complexity modal logics
knowledge belief. Artificial Intelligence, 54 (2), 319379.
Horrocks, I., Kutz, O., & Sattler, U. (2005). irresistible SRIQ. Proc. First
OWL Experiences Directions Workshop.
Horrocks, I., Kutz, O., & Sattler, U. (2006). even irresistible SROIQ. Proceedings Tenth International Conference Principles Knowledge Representation
Reasoning (KR 2006), pp. 5767.
Horrocks, I., & Sattler, U. (2004). Decidability SHIQ complex role inclusion axioms.
Artificial Intelligence, 160 (1-2), 79104.
Horrocks, I., & Sattler, U. (2007). tableau decision procedure SHOIQ. Journal
Automated Reasoning, 39 (3), 249276.
Kazakov, Y. (2010). extension complex role inclusion axioms description logic
SROIQ. Proceedings IJCAR, pp. 472486.
Krdzavac, N., & Bock, C. (2008). Reasoning manufacturing part-part examples
OWL2. Tech. rep., U.S. National Institute Standards Technology, Gaithersburg,
United States America.
Motik, B., Cuenca Grau, B., Horrocks, I., & Sattler, U. (2009). Representing ontologies
using description logics, description graphs, rules. Artificial Intelligence, 173 (14),
12751309.
Motik, B., Shearer, R., & Horrocks, I. (2009). Hypertableau reasoning description logics.
Journal Artificial Intelligence Research (JAIR), 36 (1), 165228.
Rector, A. (2002). Analysis propagation along transitive roles: formalisation
GALEN experience medical ontologies. Proceedings International Workshop Description Logics 2002 (DL2002).
Schmidt-Schau, M. (1989). Subsumption KL-ONE undecidable. Proccedings
1st Int. Conf. Principles Knowledge Representation Reasoning (KR89),
pp. 421431.
Simanck, F. (2012). Elimination complex RIAs without automata. Proceedings
International Workshop Description Logics 2012 (DL2012).
Tseitin, G. (1956). Associative calculi undecidable equivalence problems. Dokl. Akad.
Nauk SSSR, 107 (3), 370371. (In Russian).
Wessel, M. (2001). Obstacles way qualitative spatial reasoning description
logics: undecidability results. Proceedings International Workshop
Description Logics (DL2001).
850

fiA Decidable Extension SROIQ Complex Role Chains Unions

Wessel, M. (2002). spatial reasoning description logics. Proceedings
International Workshop Description Logics 2002 (DL2002).

851

fiJournal Artificial Intelligence Research 47 (2013) 697740

Submitted 05/13; published 08/13

Heuristic Search Time Matters
Ethan Burns
Wheeler Ruml

eaburns cs.unh.edu
ruml cs.unh.edu

Department Computer Science
University New Hampshire
Durham, NH 03824 USA

Minh B.

minh.b.do nasa.gov

Planning Scheduling Group
SGT Inc.
NASA Ames Research Center
Moffett Field, CA 94035 USA

Abstract
many applications shortest-path algorithms, impractical find provably
optimal solution; one hope achieve appropriate balance search
time solution cost respects users preferences. Preferences come many
forms; consider utility functions linearly trade-off search time solution cost.
Many natural utility functions expressed form. example, solution
cost represents makespan plan, equally weighting search time plan makespan
minimizes time arrival goal achieved. Current state-of-theart approaches optimizing utility functions rely anytime algorithms, use
extensive training data compute termination policy. propose direct
approach, called Bugsy, incorporates utility function directly search,
obviating need separate termination policy. describe new method based
off-line parameter tuning novel benchmark domain planning time pressure
based platform-style video games. present believe first
empirical study applying anytime monitoring heuristic search, compare
proposals. results suggest parameter tuning technique give
best performance representative set training instances available. not, Bugsy
algorithm choice, performs well require off-line training.
work extends tradition research metareasoning search illustrating
benefits embedding lightweight reasoning time search algorithm itself.

1. Introduction
Many problems artificial intelligence formulated shortest path problems,
solved using heuristic search algorithms A* (Hart, Nilsson, & Raphael,
1968). Unfortunately, state spaces often grow exponentially problem size,
usually infeasible find optimal solutions shortest path problems practical interest.
Instead, practitioners tend settle suboptimal solutions, often found
efficiently expensive execute. One left choice spending
long time searching cheap solution, little time searching expensive one.
argue new approach strictly concerned optimizing solution cost,
optimizing utility function given terms solution cost search time.
c
2013
AI Access Foundation. rights reserved.

fiBurns, Ruml, &

utility function, user specify preference search time solution
cost, algorithm handles rest.
consider utility functions given linear combination search time solution
cost. important form utility function two reasons. First, easily elicited
user already explicitly application domain. example, cost
given monetary terms, usually possible ask much time one willing spend
decrease solution cost certain amount. Second, solution cost given terms
time (i.e., cost represents time required agent execute solution),
form utility function used optimize call goal achievement time;
weighting search time execution time equally, utility-aware search attempt
minimize sum two, thus attempting behave agent achieve
goal quickly possible.
existing techniques problem based anytime algorithms (Dean &
Boddy, 1988), general class algorithms emit stream solutions decreasing
cost converging optimal one. sufficient knowledge performance
profile anytime algorithm, represents probability decrease
solution cost certain amount given current solution cost additional search time,
possible create stopping policy aware users preference trading
solving time solution cost (Hansen & Zilberstein, 2001; Finkelstein & Markovitch, 2001).
two disadvantages using anytime algorithms trade-off solving time
solution cost. first profile anytime algorithm must learned off-line
representative set training instances. many settings, domain-independent
planning, problem set unknown, one cannot easily assemble representative training set. Also, often obvious parameters problem affect performance
difficult tell problem set representative. Even instance generator
available, instances generates may represent seen real world.
second issue that, stopping policy aware users preference time
cost, underlying anytime algorithm oblivious emit stream
solutions regardless desired trade-off. policy must simply best
solutions found, algorithm may waste lot time finding many
solutions simply discarded. search algorithm fully aware
possible candidate solutions available relative estimated merits.
paper presents four main contributions. First, combine anytime heuristic search
dynamic programming-based monitoring technique Hansen Zilberstein
(2001). best knowledge, first apply anytime monitoring
anytime heuristic search. Second, present simple portfolio-based method
estimates good parameter use bounded-suboptimal search algorithm optimize
given utility function. Third, present Bugsy, best-first search algorithm
rely off-line training, yet accounts users preference search time
solution cost.1 One important difference Bugsy previous proposals
trading-off deliberation time solution cost Bugsy considers trade-off directly search algorithm, whereas previous techniques, based anytime
algorithms, consider trade-off externally actual search algorithm. Finally,
1. previous version Bugsy proposed Ruml (2007), see Appendix discussion
improvements incorporated version presented here.

698

fiHeuristic Search Time Matters

present results set experiments comparing portfolio-based method, anytime monitoring, Bugsy, along utility-oblivious algorithms A* greedy
best-first search, real-time search algorithms, decision-theoretic A* (DTA*, Russell &
EricWefald, 1991), previously proposed utility-aware search. much
work discussing trade-off deliberation solution cost, best
knowledge first implement thoroughly evaluate many ideas
context heuristic search.
results experiments reveal two surprises. First, representative set
training instances available, effective approach simple technique
selecting bound use bounded-suboptimal search. Surprisingly, convincingly
dominates anytime algorithms monitoring tests. Second, neither Bugsy
anytime search monitoring dominates other. Bugsy require off-line
training, yet surprisingly, Bugsy perform well methods use training data.
representative problem set available, Bugsy algorithm choice.
work extends tradition research metareasoning planning illustrating
benefits embedding lightweight reasoning time search algorithm itself.

2. Background
section briefly describe heuristic search, present terminology used
remainder paper, discuss type utility functions addressing.
2.1 Heuristic Search
considered paper, heuristic search technique finding shortest path
nodes weighted graph; many problems specified form. Since
typical graphs much large represent explicitly, algorithms usually
generate graph lazily using function called expand. expand function returns
successors node graph. call process evaluating expand function
node expanding node, expanding node say generating
successors.
A* (Hart et al., 1968) probably best-known heuristic search algorithm. maintains two sets nodes: open list contains frontier nodes generated
yet expanded, closed list contains nodes already expanded
(a common optimization closed list also include nodes already
open list too), therefore represent duplicate states encountered again. open list
sorted f (n) = g(n) + h(n), g(n) cost path initial node
node n, h(n) heuristic estimate cheapest path cost n goal node
reachable n. algorithm proceeds removing node minimum f value
open list, expanding it, putting children open list, putting node
closed list. A* removes goal node open list, stops searching
returns path goal solution. Finally, heuristic never over-estimates
cost go called admissible. admissible heuristic, A* returns optimal
solutions.
Dechter Pearl (1988) prove heuristic satisfies property called consistency
(for nodes n m, h(n) h(m) + c(n, m), c(n, m) cost cheapest
699

fiBurns, Ruml, &

path n m), A* expands fewest possible nodes required prove
optimality solution given heuristic. practice A* often takes long
(Helmert & Roger, 2008), thus given optimal efficiency infeasible look optimal
solutions many problems. Instead, one must settle suboptimal solutions,
hope possible find sufficiently cheap solution within reasonable amount
time memory.
2.2 Suboptimal Search
Greedy best-first search (Michie & Ross, 1969) popular suboptimal search algorithm.
proceeds like A*, orders open list heuristic, h(n), idea
remaining search effort correlates remaining solution cost. words, assumes
easier find path goal nodes low h. strictly
attempting minimize search time, Thayer Ruml (2009) show greedy best-first
search different heuristic, d, effective. Instead estimating cost go,
done traditional h functions, heuristic, called distance estimate, estimates
number remaining search nodes path cheapest solution beneath node.
practice, distance estimates readily available cost-to-go heuristics provide
much better performance used greedy best-first search domains less cost
go directly correlated less search go. call greedy best-first search using
heuristic Speedy search, analogy greedy search.
greedy best-first search find solutions quickly, bound
cost solutions. Bounded-suboptimal search algorithms remedy problem. Weighted
A* (Pohl, 1970) perhaps common techniquesit proceeds like A*,
orders open list f (n) = g(n) + w h(n), w 1. weighting parameter,
w, puts emphasis heuristic estimate cost arriving node, thus
greedier A* often finds suboptimal solutions much faster A* finds
optimal ones. addition, weight provides bound suboptimality solutions:
solutions w times cost optimal solution (Pohl, 1970). Unlike
greedy best-first search, weighted A* lets user select weight, allowing provide
either cheaper solutions faster solutions depending needs.
refer reader work Thayer (2012) in-depth study suboptimal
bounded-suboptimal search algorithms, including many use heuristics.
2.3 Utility Functions
far, described A*, optimizes solution cost, bounded-suboptimal search,
finds solutions within constant factor optimal, greedy best-first search,
attempts minimize solver time. Often, none really desired: optimal solutions
require impractical amount resources, one rarely requires solutions strictly within
given bound optimal, unboundedly suboptimal solutions costly. Instead,
propose optimizing simple utility function given linear combination search time
solution cost:
U (s, t) = (wf g (s) + wt t)
(1)
solution, g (s) cost solution, time solution
returned, wf wt user-specified weights used express preference trading-off
700

fiHeuristic Search Time Matters

search time solution cost. number time units user willing spend
achieve improvement one cost unit wf /wt . quantity usually easily elicited
users already explicit application domain. cost empty
solution, g ({}), user-specified value defines utility achieved case
search gives without returning solution
linear utility function two main benefits. First, fairly expressive.
example, one optimize cost solution search time given
monetary terms. situation occur cloud computing environments computation time costs money. linear utility function also capture optimal greedy search
using 0 weight execution time solution cost respectively. Additionally,
linear utility function express goal achievement time weighting search time equally
solution makespan. practical examples minimizing goal achievement time
desired include robotic video game pathfinding problems. settings, user
often care optimal solutions take long find, may
care achieving goal quickly possible.
demonstration minimizing goal achievement time, made video
A*, Speedy search, Bugsy solving pathfinding video game pathfinding problem.
available online appendix paper web: http://youtu.be/
Yluf88V1PLU. video includes three panels, showing agent using different
search algorithm. Since focus finding cost-optimal solutions,
Speedy Bugsy agents begin moving almost immediately. A* agent stands still
long time plans optimal path, doesnt start moving Bugsy
arrived goal. occurring, Speedy agent following
extremely circuitous path; doesnt reach goal approximately 30 seconds
A*. didnt show agonizing seconds video, instead stopped recording
soon A* reached goal. Clearly, Bugsy agent, optimizes goal achievement
time, solution cost search time, preferred scenario.
quite expressive, linear utility functions also rather simple. One main benefit
simplicity that, fixed utility function, passage time decays utility
values rate. simplification allows us ignore time passed
current decision point. express utility values terms utility
outcome starting current moment time. Without benefit, mere passage
time would change relative ordering utilities different outcomes;
would need re-compute utility values every point time order select best
outcome.
consider linear utility functions work, noted one
could consider expressive functions. Step functions, example, represent
deadlines certain amount time elapsed utility acting greatly
decreases. Bugsy support functions, anytime monitoring technique
discussed Section 3.1 restrictions utility functions optimize.
Anytime monitoring naturally handle expressive functions, like step functions.

3. Previous Work
Next describe previous techniques trading-off solver time solution cost.
701

fiBurns, Ruml, &

3.1 Monitoring Anytime Algorithms
Much previous work optimizing utility functions solving time cost, Equation 1, focused finding stopping policies anytime algorithms. Anytime algorithms
(Dean & Boddy, 1988) general class algorithms find one solution,
stream solutions strictly decreasing cost. get name one
stop anytime algorithm time get current best solution. Anytime algorithms
attractive candidate optimizing utility function: since
single solution pick, opportunity choose solution
greater utility using algorithm finds single solution. Different
solutions found different times, knew time algorithm
would find solutions cost solutions, could compute
utilities return solution maximizes utility. Unfortunately, usually
possible know solutions anytime algorithm return without running it.
Instead, algorithm running, one must continually make decision: stop now,
keep going?
Deciding stop easy task, utility solution depends
cost also time needed find it. one hand, stopping early reduce
amount computation time expense costly solution.
hand, algorithm continues, may reduce solution cost enough
justify extra computation time. case, final utility worse would
algorithm stopped earlier. little extra information, however,
possible create reasonable policy.
Near Optimal Response-Time Algorithm (NORA, Shekhar & Dutta, 1989) provides
one simple stopping policy optimizing goal achievement time. NORA, simply stops
anytime algorithm current search time user-specified factor current
incumbent solutions execution time. Shekhar Dutta (1989) prove the, search
stops time factor incumbent solution cost, goal achievement
time within factor min(1 + , 1 + 1 ) optimal goal achievement time.
use NORA slightly different Shekhar Dutta (1989).
apply NORA anytime heuristic search. Instead, evaluated empirically
database query optimization problems, tree search problems, every leaf
node possible solution. also describe one could use NORA A* search,
make assumption A* stopped early without reaching goal
heuristic planning procedure used achieve goal executing partial
solution found A*. procedure often available. using NORA
anytime heuristic search, here, incumbent solution guaranteed reach
goal. disadvantage that, anytime stopping policies, cannot
better best solution found utility-oblivious anytime algorithm.
NORA finds solution within specified bound optimal goal achievement time.
Instead, Hansen Zilberstein (2001) present dynamic programming-based technique
building optimal stopping policy utility function. requires one extra piece
information: profile anytime algorithm. Hansen Zilberstein define
profile probability distribution cost solution returned algorithm,
conditioned current solution cost additional time given improve
702

fiHeuristic Search Time Matters

solution: P (qj |qi , t), qj qi two possible solution costs
additional time. profile allows reasoning solution cost may decrease
algorithm given time improve it. requires extra knowledge,
performed small experiment (not shown here) found optimal policy found
using dynamic programming performs better simpler NORA technique.
Hansen Zilbersteins technique monitors progress anytime algorithm
evaluating stopping policy discrete time intervals. algorithm considers stopping
every time units, utility achievable time algorithms current
solution costs qi is:

U (qi , t)
= stop,
(2)
V (qi , t) = max P
P
(q
|q
,
t)V
(q
,

+
t)

= continue

j
j
j
stopping policy is:

(qi , t) = argmax




U (qi , t)
= stop,
P
P
(q
|q
,
t)V
(q
,

+
t)

= continue
j
j
j

(3)

U user-specified utility function P profile anytime algorithm.
also show sophisticated technique accounts cost evaluating
policy, however, algorithms presented paper, cost evaluating policy
consists mere array lookup essentially free.
Since profile anytime algorithm usually known, must estimated.
possible estimate profile off-line one access representative set training instances. estimate profile, algorithm run training
instances 3-dimensional histogram created represent conditional probability distribution, P (qj |qi , t), needed compute stopping policy (cf. Equation 3).
Appendix C gives detailed description implementation procedure.
3.2 Anytime Heuristic Search
Anytime algorithms general class many anytime algorithms
heuristic search (Likhachev, Gordon, & Thrun, 2003; Hansen & Zhou, 2007; Richter,
Thayer, & Ruml, 2010; van den Berg, Shah, Huang, & Goldberg, 2011; Thayer, Benton, &
Helmert, 2012). paper use Anytime Repairing A* (ARA*, Likhachev et al., 2003)
since tended give best performance approaches according experiments
done Thayer Ruml (2010). ARA* executes series weighted A* searches,
smaller weight previous. Since weight bounds solution cost,
looser bounds early iterations tend find costly solutions quickly. time passes
weight decreases, solution cost, eventually converging optimal. ARA* also
special handling duplicates encountered search enables
efficient still guaranteeing bound solutions.
Like anytime heuristic search algorithms, ARA* parameters. running
ARA*, user must select weight schedule, typically comprised initial
weight amount decrement weight solution found.
behavior ARA* varies different weight schedules. experiments, used
initial weight 3.0 decrement 0.02. schedule used Likhachev
703

fiBurns, Ruml, &


1
100
h=2
B
d=2


1

h=100
d=1

h=1
C
d=1
100
1
E

Figure 1: small example graph.
et al. (2003), found gave best performance compared several
alternative schedules domains considered.
Given fixed weight schedule, anytime heuristic search algorithm emit fixed
stream solutions given problem instance; algorithm take users
utility function account. solutions found regardless whether
user wants solution fast possible optimal solution costs. Figure 1
shows small, concrete example, goal find path node node E.
node labelled heuristic value (h) number nodes remaining
goal (d), edges labelled costs. user wants optimal
solution, algorithm would ideally return path A, B, C, E. However, user
wants solution fast possible, may better find solution A, D, E,
fewer nodes, may found fewer expansions. ARA* considers cost,
distance, initial weight less 66 23 , longer, cheaper, solution
found regardless users preference. monitoring technique select
best solutions found.
3.3 Contract Search
Dionne, Thayer, Ruml (2011) consider problem contract search, goal
must returned hard deadline. Unlike real-time search (Korf, 1990),
agents next action must ready deadline, contract search requires algorithm
return complete path goal. Like optimizing utility function, contract search must
aware cost solutions also amount time required find them.
conventional approaches contract search use anytime algorithms, Dionne et al.
(2011) present Deadline-Aware Search (DAS) considers search time directly.
basic idea behind DAS consider states lead solutions deemed
reachable within deadline. Two different estimates used determine set
nodes: estimate maximum-length solution path search explore
deadline arrives, called dmax , estimate distance solution beneath
704

fiHeuristic Search Time Matters

search node open list, words d. States dmax , deemed
reachable, states pruned. search expands non-pruned nodes best-first
order f = g + h, updating dmax estimates on-line. updates cause
remaining nodes pruned remaining time deadline, DAS uses
recovery mechanism repopulate open list set pruned nodes continues
searching deadline reached.
mentioned previously, estimates readily available normal cost-to-go heuristics, h, domains. leaves question estimate dmax . Dionne et al.
(2011) show simply using remaining number possible expansions, computed via
expansion rate remaining time, appropriate due phenomenon
call search vacillation. best-first search expands nodes, typically expand straight single solution path, instead considers multiple solution paths
time, expanding nodes each. this, said vacillating
many different paths, may return work particular path
performed many expansions along others. account vacillation, Dionne et al.
introduce metric called expansion delay estimates number additional expansions performed search expansion two successive nodes along single

texp
path. define dmax = rem
delay , trem time remaining deadline,
texp average expansion rate, delay average expansion delay. compute
average expansion delay averaging difference algorithms total expansion
count node expanded generated.
Dionne et al. (2011) showed experimentally DAS performs favorably anytimebased approaches alternative contract search algorithms, indicating approach
directly considers search time may also beneficial utility function optimization.

4. Off-line Bound Selection
turn first two new methods introduced paper.
section, present simple technique trading search time
solution cost based bounded-suboptimal search. Recall bounded-suboptimal
search algorithms return solutions guaranteed within user-specified factor
optimal solution cost. practice, applications require actual bound, instead
bound used practitioners parameter tweaked speed-up search
finding solutions quickly enough. fact bound trade search time
solution cost makes prime candidate automatic parameter tuning (Rice, 1976).
exactly propose.
anytime methods discussed previous section, off-line bound selection requires representative set training instances. instances used gather
information bounded-suboptimal search trades-off search time solution
cost. requirement user select set diverse bounds try
parameters search algorithm. algorithm run N training instances suboptimality bound, creating list N pairs bound:
sols b = h(c1 , t1 ), ..., (cN , tN )i b bound passed parameter algorithm,
ci cost solution ith training instance ti time ith
solution found. Given utility function U : cost time R, select bound
705

fiBurns, Ruml, &

gives greatest expected utility training set:


X
1
bound U = argmax

U (c, t)
|sols b |
b

(4)

(c,t)sols b )

experiments, select different weight use utility function
set 1.1, 1.5, 2, 2.5, 3, 4, 6, 10. may possible reduce number weights
training set using linear interpolation estimate performance parameters
used training. simple approach also extended select
portfolio different algorithms addition different bounds. may beneficial,
example, include A* Speedy search portfolio, algorithms
likely selected cheap solutions required solution must found quickly.
see Section 6 simple technique outperforms ARA* using anytime
monitor experimental evaluation. fact, representative set training instances
available, technique tends perform better algorithms
evaluate.
related technique dove-tailing method Valenzano, Sturtevant, Schaeffer, Buro,
Kishimoto (2010). approach presented way side-stepping need
parameter tuning running parameter settings simultaneously. found that,
dove-tailing, weighted IDA* (Korf, 1985) able return first solution much faster,
dove-tailing greatly reduced high variance solving times given weight.
also found dove-tailing different operator orderings effective IDA*.
main difference work Valenzano et al. quite
different goals. concern find first solution quickly, rather select
setting better optimizes user-specified utility function. such, approach
run multiple settings time instead selects single parameter run
single search. fact, approaches complementary. Given utility-aware
algorithms parameters, one could use dove-tailing avoid need perform
offline parameter selection.

5. Best-First Utility-Guided Search
Anytime search aware utility. Monitoring bound selection require training.
section, present Bugsy2 , utility-aware search algorithm require
off-line training.
5.1 Expansion Order
Like A*, Bugsy best-first search, instead ordering open list f , Bugsy
orders open list estimate utility outcome resulting node
expansion. Since utility dependent time, mere passage time affects utility
values. differs traditional search algorithms values used order
expansions remain constant. Recall, however, using linear utility function,
utility values decay exact rate. Given this, Bugsy ignores past time
2. Bugsy acronym Best-first Utility-Guided SearchYes!

706

fiHeuristic Search Time Matters

compares utility estimates assuming time begins current decision point.
utility values match utility ultimate outcome, still
preserve relative order different choices agent make.
understand Bugsys ordering function, first consider best utility
outcome resulting node expansion computed oracle. foreknowledge maximum utility outcome, purpose search algorithm would
achieve expanding nodes along path initial node order build
solution path. Since utility function given linear combination solution cost
search time, utility value outcome written terms cost
length (possibly empty) maximum utility outcome, s:
U = (wf g (s) + wt (s) texp )

(5)

g (s) cost path (recall cost empty path user-specified
constant), (s) number nodes s, texp time required expand node.3
Given maximum utility value U , best utility outcome resulting
expanding node n is:

U
n leads maximum utility outcome

(6)
u (n) =

U wt texp otherwise
words, utility get expanding node leads maximum utility
outcome maximum utility; expanding node simply waste time,
utility maximum utility minus cost performing unnecessary expansion.
practice, know maximum utility, must rely estimates. Bugsy
uses two estimates approximate maximum utility. First, estimates cost
solution find beneath node as, f . Note f estimate,
heuristic estimate true cost go, also cheapest
solution beneath node may solution greatest utility. See Appendix
possible alternatives. Second estimates number expansions required find
solution beneath node n, exp(n). One crude estimate remaining expansions d,
distance heuristic estimates remaining nodes solution path. reality,
Bugsy experience search vacillation, discussed earlier, expanding nodes
along single solution path. account vacillation, use expansion
delay technique Dionne et al. (2011) estimate exp(n) = delay d(n). is,
expect remaining d(n) steps goal require delay expansions.
Bugsy either choose expand node, stop return empty solution.
one way Bugsy differs A*: Bugsy decides among actions search
level (such terminating search, expanding one many open nodes), whereas
A* committed expanding nodes fixed order. Bugsy node open
list represents possible outcome, Bugsys maximum utility estimated using
maximum utility estimates open nodes Equation 5:


U = max max (wf f (n) + wt d(n) delay texp ), U ({}, 0)
(7)
nopen

3. Note expansion time constant general, includes time add remove elements
data structures like open list.

707

fiBurns, Ruml, &

Bugsy(initial , u())
1. open {initial }, closed {}
2.
3.
n remove node open highest u(n) value
4.
n goal, return
5.
add n closed
6.
ns children c,
7.
c goal u(c) < 0 old version c open closed
8.
skip c
9.
else add c open
10.
expansion count power two
11.
re-compute u(n) nodes open list using recent estimates
12.
re-heapify open list
13. loop step 3
Figure 2: Pseudo-code Bugsy.
estimate U found, would possible substitute U Equation 6
estimate u (n), utility outcome expanding node open list.
However, Bugsy going expand one node, need estimate u (n)
open node; Bugsy simply expands node best estimated outcome.
Additionally, instead computing maximization Equation 7 scratch time
expand node, Bugsy simply orders open list u(n) = (wf f (n) + wt
d(n)delay texp ), iteration popping node maximum u(n) expansion.
way, algorithm directly attempts maximize utility.
Recall Figure 1, shows two paths initial node, A, goal node, E.
Bugsy accounts distance utility function, find shorter path A,
D, E utility function sufficiently emphasizes finding solutions quickly finding
cheaper solutions. hand, utility function gives preference finding
cheap solutions Bugsy spend extra search time find cheaper path, A,
B, C, E.
5.2 Implementation
Figure 2 shows high-level pseudo-code Bugsy. clarity, code elides details
computing u(n) values. algorithm proceeds like A*, selecting open node
highest u(n) expansion (line 3). node goal, returned solution
(line 4), otherwise node put closed list (line 5) children generated.
new child put onto open list (line 9) except duplicate nodes nodes
expansion estimated negative utility (which occurs utility returning
solution greater continuing search); discarded (lines 78).
Bugsy estimates current expansion time expansion delay online,
estimates change expansion. Instead re-sorting open list
expansion, Bugsy re-sorts whenever number nodes expanded power
708

fiHeuristic Search Time Matters

two, utility open node re-computed using latest set estimates
texp expansion delay (as described Section 3.3), open list re-heapified
(lines 1012). describe re-sorting step greater detail Section 5.5.
5.3 Stopping
Bugsy orders open list decreasing order u(n), stops searching maximum estimated utility less returning empty solution. may
possible continue searching anytime fashion first goal found,
utility perspective correct approach. prove here:
Theorem 1 Assuming expansion time texp constant, h admissible, exp never
overestimates expansions go, time Bugsy finds first solution, s,
solutions Bugsy would find beneath remaining nodes would result less utility
immediately returning s.
Proof: Let current time Bugsy found solution s. utility returning
U (s, ) = u (s) = (wf f (s)+wt ), u (s) utility returning now,
f (s) cost solution s. Note h admissible goal, h(s) = 0,
g(s) = g (s), f (s) = f (s), therefore u(s) = u (s). Also exp never overestimates
expansions go exp(s) = 0. Since chosen expansion u(n) u (s) every
node n open list.
Let t(n) minimum amount additional time Bugsy requires find solution
beneath unexpanded node n. t(n) texp since Bugsy must least expand n.
node n open list, best utility Bugsy could achieve going straight
cheapest goal n is:
u (n) = (wf f (n) + wt (t(n) + ))

(wf f (n) + wt (t(n) + )), since f (n) f (n) due admissibility h

(wf f (n) + wt (exp(n) texp + )), since exp never overestimates

= u(n), definition u(n)

u (s), since u (s) = u(s) chosen expansion, n

justifies Bugsys strategy returning first goal node selects expansion.
noted Bugsys estimate exp(n) = delay d(n) lower bound,
see later sections, stopping criterion performs quite well practice.
5.4 Heuristic Corrections
Many best-first search algorithms use admissible heuristic estimates never overestimate
true cost go. proof optimality A* proofs bounded suboptimality
bounded suboptimal search algorithms rely crucially admissibility property
heuristic. Bugsy fixate cost-optimal solutions guarantee bounded
cost. Instead, Bugsy attempts optimize utility function solution cost
one two terms. Since strict cost guarantees, Bugsy free drop
admissibility requirement informed inadmissible estimates available.
709

fiBurns, Ruml, &

Thayer, Dionne, Ruml (2011) show inadmissible estimates provide better
performance bounded suboptimal search. One technique attempts correct
heuristic estimates on-line using average single-step error heuristic values
node best child. Thayer et al. show technique provides good
search guidance, actually less accurate estimating true cost-to-go values
standard admissible heuristics. Bugsy, undesirable, need
good guidance, proper estimates. Thayer et al. also show learning heuristic
off-line linear regression provide accurate estimates. Unfortunately, using
off-line training would negate one Bugsys main benefits. matter empirical
evaluation whether techniques provide better performance Bugsy.
Section 6.5, show using standard admissible heuristics often gives best
performance anyway.
5.5 Resorting
Instead requiring off-line training previous approaches, Bugsy uses on-line
estimates order nodes open list. First, many analyses regard texp
constant, practice depend log-time heaps, cache behavior, multiprogramming overhead, among factors, implementation Bugsy estimates texp
global average computed search. Second, Bugsys expansion delay estimate
calculated global average difference expansion count node
generated expanded; must done on-line. Unfortunately,
on-line estimates may change node expansion, navely using latest estimates
compute u value newly generated nodes lead poor performance.
due comparisons used order open list: instead fair comparisons based
estimated utility node, recent fresh estimates new nodes
compared old possibly stale estimates nodes open
long time.
alleviate problem, implementation Bugsy uses two sets estimates:
one stable set used order open list, one ever-changing set maintaining
recent estimates. certain points throughout search, Bugsy copies upto-date estimates stable set, recomputes utility values open nodes,
re-sorts open list. open list implemented binary heap re-establish
heap property linear time number elements heap. Unfortunately,
would still expensive every node expansion, so, instead, Bugsy reorders
open list exponentially less frequently search progressesit reorders
number expansions power two. prove logarithmic scheme
adds constant amount overhead per-expansion amortized entire search.
Theorem 2 search space grows geometrically finite branching factor,
overhead reordering open list power-of-two expansions constant expansion amortized search.
Proof: Let b maximum branching factor. maximum number nodes
open list n expansions N (n) = bn n = n(b 1). total cost
710

fiHeuristic Search Time Matters

re-sorting n expansions than:
lg n

X
i=0

lg n


O(N (2 )) =

X
i=0

O(2i (b 1)), definition N
lg n

= c(b 1)

X

2i , c > 0, definition

i=0
lg n+1

= c(b 1)(2

1), identity

c(b 1)(2 2lg n 1)

Pj


i=0 2

= 2j+1 1

= c(b 1)(2n 1)

= O(n)


So, overhead per-expansion constant amortized expansions.
matter empirical evaluation determine constant overhead detrimentalwe
address Section 6.4.

6. Experimental Evaluation
techniques discussed involve approximations estimations may may
work well practice. section, present results experimental comparison
techniques better understand performance. algorithms
domains implemented C++; source code available https://github.com/
eaburns/search.
6.1 Overview
following sections, answer several questions experimentally. First, would like
ensure monitored ARA* algorithm performing best comparing
profile learned off-line oracle. see, off-line profile,
estimate true profile algorithm, quite well-informed.
Section 5.5, proved re-sorting adds constant overhead per-expansion
amortized entire search. matter empirical evaluation determine
whether benefits outweigh overhead. experiments show re-sorting
logarithmic schedule greatly outperforms Bugsy without re-sorting.
Section 5.4 pointed Bugsy require admissible heuristic estimates,
fact may perform better inadmissible, accurate heuristics. show
Bugsy performs admissible heuristics, two different types corrected
heuristics. Overall, conclude best configuration Bugsy standard
admissible heuristics.
discussed expansion delay Section 5.1. show results demonstrate
using expansion delay better simply using estimate expansions
goal. compare two variants Bugsy: one ignores newly generated nodes
found already closed list (we call duplicate nodes) one
reinserts nodes onto open list better utility estimates
711

fiBurns, Ruml, &

previously closed version. Ignoring duplicates always performs better domains,
others performs better preference short search times.
Then, compare A*, Speedy search, monitored ARA*, weighted A* learned
weight, Bugsy. find simplest approach learning good weight
weighted A* gives best performance. also find Bugsy, doesnt use
off-line training, performs well monitored ARA*, use off-line
training. Therefore, training instances available, recommend simple weighted
A* approach weight selected based performance training set.
training instances available Bugsy algorithm choice.
Lastly, compare Bugsy real-time search DTA* platform pathfinding domain. experiments, Bugsy achieves best utility.
6.2 Domains
order verify results hold variety different problems, performed
experiments four different domains. domains used described briefly
following paragraphs, detailed descriptions given Appendix B.
6.2.1 15-Puzzle
15-puzzle popular heuristic search benchmark small branching factor
duplicates. domain, used reasonably informed Manhattan distance
heuristic, implementation followed heavily optimized solver presented Burns,
Hatem, Leighton, Ruml (2012). ran 100 instances created Korf (1985),
plots including A* use results 94 instances solvable A* 6GB
memory.
6.2.2 Pancake Problem
pancake problem another standard puzzle large constant branching factor.
experiments, used instances 50 pancakes, gap heuristic (Helmert,
2010). Since many problems difficult A*, used IDA* instead A*
domain.
6.2.3 Platform Pathfinding
platform domain pathfinding domain creation dynamics based
2-dimensional platform-style video game, player must jump platforms
traverse maze. Video games often naturally element time pressure.
large state-space many cycles, reasonably informed heuristic based
visibility navigation. instances used experiments created randomly, using
generator described Appendix B. domain also particular interest
action costs given units time (each action 50ms), objective minimizing
goal achievement time expressed linear combination search time solution
cost.
712

fiHeuristic Search Time Matters

6.2.4 Grid Pathfinding
Grid pathfinding popular heuristic search benchmark, motivated robotics video
games. experiments, used two different cost models, two different movement
models. cost models standard unit-cost model life-cost model
assigns action costs shortest, direct path expensive longer,
circuitous path. captures popular adage time money. Instances
5,0005,000 grids uniformly distributed obstacles. heuristics based
Manhattan distance heuristic four-way grids, octile distance heuristic eightway grids. octile distance heuristic simple modification Manhattan
distance

multiplies shorter horizontal vertical displacement 2 accounts
eight-way move costs.
6.3 Anytime Profile Accuracy
want ensure implementation works well training instance sets
representative enough monitored ARA* perform best. subsection,
evaluate accuracy stopping policies created using estimated anytime profiles
comparing oracle. Since stopping policy guaranteed optimal
true algorithm profile, matter empirical study determine whether
estimated profile lead good policy.
estimate profile used monitored version ARA*, ran ARA*
6GB memory limit convergence 1,000 separate test instances domain.
Next, created histogram discretizing costs times solutions
10,000 bins (100 100). experimented different utility functions varying
ratio wf /wt Equation 1. Small values wf /wt give preference finding solutions
quickly, whereas large values prefer finding cheaper solutions. case platform
game, example, viewed way change speed agent
moves: slow agent might benefit search order find shorter path,
fast agent execute path quickly, may prefer find feasible solution fast
possible.
Figure 3 shows results experiment. box plots represent distribution
utility values found ARA* using estimated stopping policy, given factor
oracles utility. oracle finds solutions anytime algorithm converges
optimal solution, picks solution would maximized utility
function. Since utility values negative, larger factors represent smaller (more negative) utilities thus worse outcome. boxes surround second third quartiles,
whiskers extend extremes, circles show values 1.5
inter-quartile range outside box. center line box shows median,
gray rectangles show 95% confidence interval means. box represents
different wf /wt shown x axis. reference line drawn across = 1 (the
point oracle estimated policy performed equally well), many cases
boxes narrow indistinguishable line.
points figures lie slightly = 1 line, indicating instances
oracle performed worse estimated policy. possible due
variance solving times. experiment, ARA* runs used compute oracles
713

fiBurns, Ruml, &

platform
factor oracle

factor oracle

15-puzzle
2
1.6
1.2
1e-4

1e-3 1e-2 1e-1
cost/time preference

3
2
1

1

1e-4

1e-3
1e-2
1e-1
cost/time preference

4-way unit grids

50-pancake
factor oracle

1.3

factor oracle

1

1.2
1.1
1

1.08
1.04
1
0.96

1e-4

1e-3 1e-2 1e-1
cost/time preference

1

1e-4

1e-3 1e-2 1e-1
cost/time preference

8-way unit grids

1

4-way life grids
factor oracle

factor oracle

1.014
1.2
1.12
1.04

1.008
1.002
0.996

1e-4

1e-3 1e-2 1e-1
cost/time preference

1

1e-4

1e-3 1e-2 1e-1
cost/time preference

1

8-way life grids
factor oracle

1.012
1.008
1.004
1
1e-4

1e-3 1e-2 1e-1
cost/time preference

1

Figure 3: Comparison optimal stopping policy learned stopping policy.
714

fi15-puzzle

1

0.6

0

0
-6

-3

log10 cost/time preference

0

-6

0.6

0
-3

log10 cost/time preference

0.5

0
-6

0

0

1.6

0.8

0
-9

-6

log10 cost/time preference

-3

log10 cost/time preference

0

8-way life grids
log10 factor best utility

1.2

-6

-3

log10 cost/time preference

Resort
Resort

1

4-way life grids
log10 factor best utility

8-way unit grids
log10 factor best utility

4-way unit grids

platform
1.2

log10 factor best utility

2

log10 factor best utility

log10 factor best utility

Heuristic Search Time Matters

-3

1

0
-9

-6

log10 cost/time preference

-3

Figure 4: Bugsy: Resorting open list (circles) vs (boxes).
utilities occasionally found solutions slowly ARA* runs using estimated
stopping policy. words, caused non-determinism inherent utility
function depends solving time. obvious figure, instances quite
rare usually happened small values wf /wt , miniscule time differences
large effect utility.
results, conclude monitored ARA* implementation performs
quite well, stopping policy often stopped best solution available
emitted underlying anytime algorithm.
6.4 Resort Resort?
Section 5.5 proved re-sorting Bugsys open list power-of-two expansions
added constant overhead per-expansion amortized search. matter
empirical evaluation determine whether overhead worth effort.
re-sorting schedules possible, tried re-sorting power-of-two expansions.
Figure 4 shows utility achieved Bugsy without re-sorting.
x axes show wf /wt ratio determining preference solution cost search time
log10 scale. previous plots, smaller values indicate preference faster
search times larger values indicate preference cheaper solutions. axes show
factor utility achieved best technique instance, log10
scale. value log10 1 = 0 indicates best utility achieved technique given
715

fiBurns, Ruml, &

instance; values greater zero indicate less utility. Points show mean value
test instances error bars giving 95% confidence intervals. plots,
see re-sorting open list led significant improvements domains.
pancake puzzle, Bugsy without re-sorting unable solve instances within
6GB memory limit. remaining experiments, always enable re-sorting
exponential schedule.
6.5 Heuristic Corrections
Section 5.4, mentioned Bugsy require admissible heuristic estimates,
provides guarantees solution cost. section compare Bugsy using
standard admissible heuristics Bugsy using on-line off-line corrected heuristics.
Following Thayer et al. (2011), on-line heuristic correction used global average
single-step heuristic error node best offspring, off-line heuristic
linear combination h, g, depth, d, node. coefficients term
off-line heuristic learned solving set training problems using linear
least squares regression.
comparison shown Figure 5. plots style Figure 4. Typically on-line correction technique performed worstsome times significantly worse
two. attribute poor accuracy observed Thayer et al.
(2011). problems, 15-puzzle 8-way unit-cost grid pathfinding, off-line correction technique performed best, general simple admissible
heuristics best competitive best. remainder experiments, chose use simplest variant without corrections require
off-line training (which one Bugsys main benefits), never worst
often best near best.
6.6 Expansion Delay
Section 5.1 described simply using approximation exp(n), number
nodes expanded arrive goal beneath node n, inaccurate. search algorithm
expand nodes along path goal, instead vacillates
different solutions. account search vacillation, choose estimate exp(n) =
delay d(n), delay average expansion delaythe average number nodes
expanded search makes progress along single path goal. subsection,
show experimentally using expansion delay provides much better performance
using alone.
Figure 6 shows two versions Bugsy: one uses expansion delay, labelled
Exp. Delay, one not, labelled Without Exp. Delay. clear
figure using expansion delay beneficial. Also, see right side
plots, cheaper solutions preferred short search times, using expansion delay
using itself. wf relatively large compared
wt utility functions, exp(n) term little influence utility estimates.
716

fiHeuristic Search Time Matters

15-puzzle

0.6

log10 factor best utility

log10 factor best utility



log10 factor best utility

50-pancake

platform
Online
None
Offline

0.2

0.1

0

0
-6

-3

-3

log10 factor best utility

log10 factor best utility

0.06

0
-3

0.04

0
-6

-3

0

log10 cost/time preference
8-way life grids

log10 factor best utility

4-way life grids
log10 factor best utility

0

0.08

0

log10 cost/time preference

0.1

0.05

0
-6

-2

log10 cost/time preference
8-way unit grids

0.12

-9

-4

0

log10 cost/time preference

4-way unit grids

-6

0.08

0
-6

0

log10 cost/time preference

0.16

-3

0.06

0.03

0
-9

log10 cost/time preference

-6

-3

log10 cost/time preference

Figure 5: Bugsy: Heuristic corrections.

6.7 Duplicate Dropping
Suboptimal search algorithms expand nodes strict order increasing f . Consequently, expand node, later re-generate node via cheaper path.
call re-generations duplicates, generated via cheaper paths
say inconsistent, current path cost (and subsequently cost
paths descendants) expensive necessary (Likhachev et al.,
2003). face inconsistent nodes, search algorithm put already expanded
node back open list cost accounts new, cheaper path.
node comes front open list, re-expanded inconsistency
717

fiBurns, Ruml, &

platform

2.4

1.6

50-pancake

1.2

log10 factor best utility

log10 factor best utility

log10 factor best utility

15-puzzle

0.8

0.4

0

0
-6

-4

-2

log10 cost/time preference

0

-6

-4

-2

log10 cost/time preference

Without Exp. Delay
Exp. Delay

log10 factor best utility

log10 factor best utility

0.4

-5

0

-3

-4

-2

-1

log10 cost/time preference

0

8-way unit grids

0

0.9
0.6
0.3
0

-6

-4

-2

log10 cost/time preference

0

-6

-4

-2

log10 cost/time preference

4-way life grids

0

8-way life grids

1.8

log10 factor best utility

log10 factor best utility

0.8

0

4-way unit grids
1.2

1.2

1.2

0.6

0

1.8

1.2

0.6

0
-8

-6

-8

-4

log10 cost/time preference

-6

-4

log10 cost/time preference

Figure 6: Bugsy: Expansion delay.
propagate descendants. Unfortunately, lot
inconsistencies, search algorithm spend lot time re-expanding
nodes again. alternative technique simply ignore inconsistency
drop duplicate nodes generated. Dropping duplicates reduce
search effort needed find goal cost finding expensive solutions. Whether
dropping duplicates beneficial typically depends domain (Thayer & Ruml,
2008).
Figure 7 shows comparison Bugsy without duplicate dropping.
platform, tiles, pancake domains using duplicate dropping nearly always better
re-expanding duplicates. grid pathfinding problems,with notable excep718

fiHeuristic Search Time Matters

0.15

0.1

0.05

50-pancake
log10 factor best utility

platform
log10 factor best utility

log10 factor best utility

15-puzzle
0.8
0.6
0.4
0.2

0.24

0.16

0

0
-6

-4

-2

log10 cost/time preference

0

0
-6

-4

-2

log10 cost/time preference

Duplicate Reexpansion
Duplicate Dropping

0.12

0.06

0

-3

-2

-1

0

0.04

0.02
0.01
0

-6

-4

-2

log10 cost/time preference

0

-6

-4

-2

log10 cost/time preference

0

8-way life grids
log10 factor best utility

4-way life grids
log10 factor best utility

-4

log10 cost/time preference

8-way unit grids
log10 factor best utility

log10 factor best utility

4-way unit grids
0.18

-5

0

1.8
1.2
0.6
0

0.018
0.012
0.006
0

-8

-6

-8

-4

log10 cost/time preference

-6

-4

log10 cost/time preference

Figure 7: Bugsy: Duplicate dropping.

tion 4-way life-cost gridsre-expanding duplicate nodes seems give better performance
except solutions needed quickly possible (on left-hand side plots).
reasonable, duplicate dropping tends sacrifice solution cost order
reduce search time. Note also, values axes plots small,
results statistically significant, difference two techniques
grid problems duplicate re-expansion performs better quite small. next
section see A* actually achieves utility many cases
duplicate re-expansion outperforms duplicate dropping.
719

fiBurns, Ruml, &

platform

log10 factor best utility

log10 factor best utility

15-puzzle
0.4

0.2

0

0
-6

-3

log10 cost/time preference

0

-6

-3

log10 cost/time preference

0

log10 factor best utility

50-pancake

pee
ugsy


0.4

0.

0
-4

-

log10 cost/time preference

0

Figure 8: Comparison techniques.

6.8 Comparing Techniques
understand promising configurations techniques studying, finally turn attention comparing them.
Figures 8 9 show comparison three different techniques utility-aware
search. plots larger previous plots improve clarity,
lines. plots include A*, Speedy Search, Bugsy, ARA* monitoring
(ARA*), weighted A* weight chosen automatically different utility
function set 1.1, 1.5, 2, 2.5, 3, 4, 6, 10 (wA*). would expect,
preference shorter search times (on left-end x axis), A* performed poorly,
stubbornly stuck optimal solutions. Speedy search, however, performed quite well.
preference shifted toward desiring cheaper solutions, A* began better whereas
Speedy worse. utility-aware techniques much robust A*
720

fiHeuristic Search Time Matters

8-way unit grids
log10 factor best utility

log10 factor best utility

4-way unit grids

0.1

0

0.1

0
-6

-3

log10 cost/time preference

0

-6

0

log10 factor best utility

8-way life grids

log10 factor best utility

4-way life grids

-3

log10 cost/time preference

0

0
-9

-6

log10 cost/time preference

-9

-3

-6

log10 cost/time preference

-3

Figure 9: Comparison techniques (continued).
Speedy, neither take users preference search time solution cost
account all.
utility-aware techniques, Bugsy weighted A* automatically
selected weight performed best. Bugsy better 15-puzzle
platform domain. grid problems, Bugsy weighted A* roughly
performance right side x axes. left side, Bugsy tended get worse
relative utility-aware techniques, ARA* anytime monitor often
best performer. However, ARA* performed significantly worse middle
right-hand portion plot domains, leading us recommend weighted
A* technique simpler robust approach.
utility-aware techniques often performed well A* low-cost solutions
preferred. fast solutions preferred, techniques sometimes outperformed
Speedy search. likely indicates solution cost still played roll final utility
721

fiBurns, Ruml, &

log10 factor best utility

orz100d

0.2

0.1

0
-6

Bugsy

ARA*

-3

0

log10 cost/time preference
wA*
A*
Speedy

Figure 10: Grid pathfinding video game map.
left-most points plots. ARA* tended achieve greater utility
Bugsy solutions needed quickly, cheaper solutions preferred,
Bugsy tended better ARA*. domains, ARA* spike low utility
ratios 0.001, 1, peak appearing 106 103 life-cost
grids. peak approximately coincides utility functions estimated
profile performed worse oracle shown Figure 3, possibly indicating
1,000 training instances required utility functions.
Overall, utility-aware techniques able achieve much greater utility
utility-oblivious A* Speedy algorithms. terribly surprising. Surprisingly,
results also suggest simple parameter tuning technique often give best
performance representative set training instances available. not, Bugsy
algorithm choice performs well require off-line training.
Indeed, putting reasoning search time search algorithm itself, Bugsy
competitive techniques requiring previous experience.
6.9 Limitations
previous set experiments, saw utility-aware algorithms outperformed
Speedy search A* wide range utility functions. section, look
one domain tends case: video game grid maps.
Video games one main motivations research grid pathfinding problems.
Sturtevant (2012) observed grid maps created game designers often exhibit
different properties maps generated algorithmically. Figure 10 shows comparison
Bugsy, monitored ARA*, weighted A* automatically selected weight, Speedy,
722

fiHeuristic Search Time Matters

Figure 11: Grid pathfinding video game map.

150
100
50

200

% Speedy time

200

planning time

execution time

200

% Speedy time

% Speedy nodes

nodes expanded

150
100
50

0

8

16

instance

24

150
100
50

0

8

16

instance

24

0

8

16

instance

24

Figure 12: Nodes expanded, search time, execution time.
A* Dragon Age Origins map orz100d benchmark set Sturtevant.
map shown Figure 11. fairly wide-open area top, closed-off
bottom half containing rooms hallways. format plot figure
previous subsection. see, A* gave best performance
large range utility functions, Bugsy actually never outperformed Speedy A*
entire experiment (neither ARA*, wA* gave best performance
single data point). hypothesized Bugsys poor performance
problems easy solve, Bugsys extra computation overhead, small,
prominent.
explore hypothesis, plotted performance Bugsy given difference
Speedy using single utility function given wf = 106 , wt = 1.
723

fiBurns, Ruml, &

left-most utility function Figure 10, function Speedy search performed
best Bugsy performed poorly. Figure 12 shows number nodes expanded,
time spent executing, time spent searching Bugsyas percentages
equivalent values Speedy search. data points gathered random sample
25 instances Sturtevants (2012) scenario set orz100d map. Values
line 100% represent instances Bugsy expanded fewer nodes spent less
time searching executing, values line represent instances Bugsy
expanded nodes spent time Speedy. x axes shows rank
instances sample increasing order optimal solution lengths.
see Figure 12, Bugsy expanded number nodes
similar execution times Speedy. problems larger optimal solution
costs Bugsy slightly less execution time. major difference performance
two algorithms, however, shown right-most plot see Bugsy
required search time Speedy search almost every instance. Since Bugsy
Speedy expanded number nodes, additional time must due
Bugsys small amount extra overhead incurred re-sorting computing utility.
conclude that, barring extra overhead, Bugsy would performed well
best performer utility function. domains node expansion heuristic
computation isnt simplistic, overhead would insignificant.
6.10 Training Set Homogeneity
Section 6.8 showed weighted A* approach outperformed techniques
domains, notable exception platform domain 15-puzzle,
Bugsy best. Additionally, compared domains, weighted A* technique
performed relatively poorly video game pathfinding (cf. Figure 10 wA* outperformed utility oblivious approaches points except one). believe
poor performance wA* domains due heterogeneous training sets.
verify this, looked mean standard deviation optimal path lengths
problems domains. optimal path length viewed proxy
problem difficulty, high standard deviation statistic points diverse
set instancessome easy solve, quite difficult. platform
video game path finding domains, standard deviation optimal path length
greater 50% mean; twice domains. Note that,
domains video game map, variety layout different areas map
means instances inherently differ characteristicsmerely gathering
instances produce homogeneous set. evidence supports hypothesis
weighted A*s performance greatly hindered situations representative
training set available.
6.11 Real-time Search
main focus study algorithms off-line searchthey find entire paths
goal execution begins. real-time search (Korf, 1990), search execution
happen parallel, agent allowed fixed amount time plan
must perform action. Real-time search possibility efficient
724

fiHeuristic Search Time Matters

off-line search terms goal achievement time, search happens
parallel execution, goal achievement time simply execution time plus
small amount time required find first action. contrast off-line
approach goal achievement time sum entire search time execution
time. situations, however, starting execution complete plan
goal acceptable, may lead agent dead-end longer
reach goal, real-time search may applicable. Examples domains deadends include robotics, manufacturing (Ruml, Do, Zhou, & Fromherz, 2011), spacecraft
control: exactly applications involving high value danger, automation
worthwhile. cases, desirable find entire plan guaranteed reach
goal, execution begins.
Hernandez, Baier, Uras, Koenig (2012) introduce model comparing real-time
algorithms off-line techniques A*, called game time model. game time
model partitions time uniform intervals, agent execute single action
interval. Path planning happen parallel execution (the agent
plan step execution step t-1), goal move agent start
location goal location time intervals possible, minimizing goal achievement
time, objective discuss Section 1. game time model special
case utility functions considered paper solution cost given discrete,
fixed-duration units time.
Real-time search provides two benefits: first, may possible reduce goal
achievement time allowing search execution happen time, second,
agent start moving toward goal right awaya necessary property video games.
leaves us question whether real-time search algorithms achieve
better goal achievement time off-line utility-aware methods. one hand, realtime search algorithms spend little time searching without making progress toward
goal. hand, real-time search algorithms tend make decisions based
local information find costly solutions. results, Hernandez et al.
report best approach solves problems initially-known grid maps
number time intervals A*. previous section, showed utilityaware techniques outperformed A* utility functions. section, compare
state-of-the-art real-time search algorithm called LSS-LRTA* (Koenig & Sun, 2009)
Bugsy platform pathfinding domain.4
previous experiments, tested algorithms variety values
ratio wf /wt . Since interested goal achievement time, set wt = 1
calculate search time units seconds. means wf represents number
seconds one unit execution costthe speed agent. set real-time
constraint LSS-LRTA* allowed plan duration one unit
execution, always next action ready execution currently
executing action completed.
4. compare Time-bounded A* (TBA, Bjornsson, Bulitko, & Sturtevant, 2009), method
performed best Hernandez et al. (2012), platform domain forms directed search
graph, TBA* works undirected search graphs. also compare newer
f -LRTA* (Sturtevant, 2011), perform well LSS-LRTA* platform domain,
directed edges.

725

fiBurns, Ruml, &

platform
log10 factor best GAT

2.4

LSS-LRTA*
A*
Speedy
Bugsy

1.6

0.8

0
-4

-3

-2

log10 w_f / w_t

-1

0

Figure 13: Comparison Bugsy real-time search.
Figure 13 shows results comparison. see, LSS-LRTA* gives rather
poor performance; goal achievement times nearly match A*, Bugsy able
achieve goal much faster. shows simply allowing search execution
take place parallel sufficient reduce goal achievement time; better
spend time searching solution way goal alternative spend
long time executing poor plan.
6.12 Decision-theoretic A*
Decision-theoretic A* (DTA*, Russell & EricWefald, 1991) utility-aware algorithm
allows concurrent search execution. based ideas real-time heuristic
search, unlike traditional real-time search, action emitted fixed
amount search, DTA* decides stop searching emit action using decisiontheoretic analysis. time single best top-level action lowest cost
estimate. search emits action decided utility emitting
action outweighs utility search. DTA* uses approximation (found
off-line training) solution cost estimate top-level action improves
additional search. Using consistent heuristic, estimate increase (Nilsson,
1980), DTA* stops searching decides time required raise best
actions estimated cost point longer best action costly
expected gain determining different best action.
Compared Bugsy, DTA* relatively myopic considers cost
search involved selecting individual actions. DTA* consider additional search
required solution path commits choosing action. Bugsy
uses expansion delay reason required search effort entire
726

fiHeuristic Search Time Matters

log10 factor best utility

platform (small instances)
Speedy
A*
DTA*
Bugsy

1.2

0.8

0.4

0
-4

-3

-2

log10 w_f / w_t

-1

0

Figure 14: Comparison Bugsy DTA*.
path beneath node, DTA* reasons search required determine best
action emit right now.
implemented DTA* assess utility-aware real-time search might compare
utility-aware off-line search planning time pressure. Figure 14 shows
results comparison DTA* Bugsy platform pathfinding domain.
Unfortunately, DTA* fairly poor performance, experiment used smaller instances
consisting 25x25 blocks, instead 50x50 block instances used previous experiments.
Following Russell EricWefald (1991), gathered off-line training data DTA* using
states sampled uniformly probability 0.1 among visited real-time
search algorithm. Russell EricWefald (1991), used algorithm called SLRTA*,
used LSS-LRTA*, current state art. training set consisted
100 25x25 platform instances. also verified implementation ensuring
compared favorably A* Speedy search 15-puzzlethe domain used
Russell EricWefaldusing variety different utility functions. Figure 14,
see DTA* often significantly worse utility Bugsy, often performing
slightly better Speedy search, sometimes performing worse A*, example,
cheap solutions desired.

7. Related Work
Bugsy uses estimates search time select whether terminate continue, select node expand, may said engaging metareasoning,
is, reasoning reasoning action take. much work
topic AI since late 1980s (Dean & Boddy, 1988) continuing today (Cox & Raja,
2011).
727

fiBurns, Ruml, &

Dean Boddy (1988) consider problem faced agent trying respond
predicted events time constraints. Unlike setting, concern
choosing much time allocate prediction much allocate deliberation. solve type time-dependent planning problem, suggest use (and
also coined term) anytime algorithms. Unlike anytime-based techniques discussed
previously, attempt find stopping policy optimize utility function, Dean
Boddy used anytime algorithms means allowing different allocations time
predicting deliberation. Later, Boddy Dean (1989) show anytime
algorithms time-dependent planning framework used delivery agent
must traverse set waypoints grid, allocating time ordering
waypoints planning used travel them. Dean, Kaelbling, Kirman,
Nicholson (1993) also adapt technique scheduling deliberation execution
planning face uncertainty.
Garvey Lesser (1993) present design-to-time methods advocate using available time find best possible solution. Unlike anytime approaches interrupted time, design-to-time method requires time deadline given
upfront. way, algorithm spend time focusing finding single
good solution, instead possibly wasting time finding intermediate results. Design-to-time
also differs contract techniques like DAS (Dionne et al., 2011), designto-time framework must predefined set solvers known (or predictable)
solution times costs. design-to-time method select appropriate solver
problem deadline, possibly interleaving different solvers deemed appropriate.
information cost solutions times, design-to-time methods require, usually unavailable must learned off-line. Techniques like DAS Bugsy,
hand, use information computed on-line.
Hansen, Zilberstein, Danilchenko (1997) show heuristic search inadmissible
heuristics used make anytime heuristic search algorithms. Like techniques
presented paper, consider problem trading-off search effort solution
quality. end, propose one possible optimization function anytime heuristic
search search attempts maximize rate algorithm decreases solution
cost. Like anytime monitoring technique shown Section 3.1, evaluation function
relies learning profile anytime algorithm offline. analysis 8puzzle, conclude that, method good anytime behavior, little
benefit using instead trial-and-error-based hand tuning. surprising given
strong performance demonstrated offline-tuned weighted A* experiments.
recently, Thayer et al. (2012) proposed approach minimizing time solutions anytime algorithms. demonstrate new state-of-the-art
algorithm performs well wide variety domains, robust
previous approaches. Like Bugsy, technique relies using heuristics estimate
search effort required find solutions. However, focus solutions
require least amount effort, optimize trade-off search time
solution cost.
addition controlling expansion decisions, metareasoning also used
heuristic evaluation. Often search algorithms use maximum value computed
multiple heuristics accurate estimate cost goal. problems, like
728

fiHeuristic Search Time Matters

domain-independent planning, heuristics quite expensive, increased accuracy
gained via maximizing many heuristics may worth increased computation
time. Domshlak, Karpas, Markovitch (2010) introduce on-line learning technique
decide single heuristic compute state, instead computing many
taking max.
related work using metareasoning control combinatorial search done
area constraint satisfaction problems (CSPs), boolean satisfiability (SAT). Tolpin
Shimony (2011) use rational metareasoning decide compute value ordering
heuristics CSP solver. focus work value ordering heuristics
gave solution count estimates; solver bothered compute heuristic decision
points deemed worthwhile. experiments demonstrate new
metareasoning variant outperformed variant always computed heuristic
one computed heuristic randomly. Horvitz, Ruan, Gomes, Kautz, Selman,
Chickering (2001) apply Bayesian structure learning CSPS SAT problems.
consider problem quasi-group completion, unlike Tolpin Shimony (2011)
use on-line metareasoning control search, use off-line Bayesian learning set
hand-selected variables predict whether instances long short running.
lot work attempting estimate size search trees offline (Burns & Ruml, 2013; Knuth, 1975; Chen, 1992; Kilby, Slaney, Thiebaux, & Walsh,
2006; Korf, Reid, & Edelkamp, 2001; Zohavi, Felner, Burch, & Holte, 2010).
related topic, concerned estimating search effort entire search
performed. One may imagine leveraging technique predict search time
algorithm like Bugsy. Unfortunately, estimation methods rather costly
terms computation time, suitable estimator needed every
single node generation. Another possibility use off-line estimations find parameters
affect performance search given domain. knowledge could helpful
creating representative training sets used algorithms like weighted A* anytime
monitoring, require off-line training.

8. Conclusions
investigated utility-aware search algorithms take account user-specified
preference trading-off search time solution cost. presented three different techniques
addressing problem. first method based previous work area
learning stopping policies anytime algorithms. best knowledge,
first demonstrate techniques area heuristic search. second method
novel use algorithm selection bounded-suboptimal search chooses correct
weight use weighted A* given utility function. last technique
presented Bugsy algorithm. Bugsy technique three
require off-line training.
performed empirical study techniques context heuristic search,
investigated effect parameters algorithm performance, compared
different techniques other. Surprisingly, simplest technique learning
weight weighted A* able achieve greatest utility many problems, outperforming conventional anytime monitoring approach. Also surprisingly, Bugsy,
729

fiBurns, Ruml, &

algorithm use off-line training, performed well off-line
techniques advantage learning thousands off-line training instances.
representative set training instances available Bugsy algorithm
choice. Overall, utility-aware methods outperformed A* Speedy search
wide range utility functions. demonstrates heuristic search longer
restricted solely optimizing solution cost, freeing user choice either slow
search times expensive solutions.
Unlike previous methods trading deliberation time solution quality, Bugsy considers trade-off directly search algorithmdeciding, node, whether
result expansion worth time. new approach provides alternative anytime algorithms. Instead returning stream solutions relying external
process decide additional search effort longer justified, search process
makes judgments based node evaluations available it. empirical
results demonstrate Bugsy provides simple effective way solve shortest-path
problems computation time matters. would suggest search procedures
usefully thought black boxes controlled external termination policy
complete intelligent agents, informed users goals acting rationally
basis information collect directly maximize users utility.

Acknowledgments
greatly appreciate feedback suggestions Shlomo Zilberstein Scott Kiesel.
would also like think Richard Korf pointing work Shekhar Dutta
(1989). also grateful support NSF (grant 0812141 grant 1150068),
DARPA CSSG program (grant D11AP00242), University New Hampshire
Dissertation Year Fellowship. preliminary version Bugsy presented Ruml
(2007); see Appendix A. Elisabeth Crawford assisted original version
summer internship PARC.

Appendix A. Previous Bugsy
previous version Bugsy proposed Ruml (2007), however, early
realization differs substantially one presented here. used aggressive duplicate
re-expansion, heuristic corrections, used estimate remaining expansions
goal reached. Section 6.7 showed duplicate dropping outperforms duplicate re-expansion many domains. found inadmissible heuristics performed
poorly (cf Section 6.5) practice, even compared standard admissible estimates. Also, temper inadmissible corrected estimates, previous Bugsy
multiplied heuristic estimates arbitrary weight (min(200, (wt /wf ))/1000); version require ad hoc fix. discussed poor estimate number
remaining expansions Section 5.1, Section 6.6 showed, experimentally,
using expansion delay performs much better using alone.
Recall Bugsy uses f approximate cost path length best
utility outcome enabled expansion node. Note, however, f
function used throughout paper refer cheapest solution beneath node n,
730

fiHeuristic Search Time Matters

may goal results maximum utility. better assess available
outcomes, previous version Bugsy computed two utility estimates node: one
cheapest solution beneath node nearest solution terms
node expansions. non-unit-cost domains, two estimates may differ. example,
life-cost grid pathfinding domains, cheapest solution usually involves moving toward
top grid actions cheap, nearest solution follow straight-line
path goal. general, large number different solutions
search node, solutions may cover whole spectrum different cost/time trade-offs.
considering cheapest solution, done implementation,
may possible find solutions better utility. hand, may
costly compute multiple heuristics node, whether modification
beneficial depends domain.

Appendix B. Domains
performed experiments variety different domains, describe
detail here.
B.1 15-Puzzle
15-puzzle one popular benchmark domains heuristic search algorithms.
consists 4-by-4 frame 15 tiles placed. One slot board
contain tile, called blank. Tiles above, below, left right
blank may slid blank slot. objective 15-puzzle slide tiles
around order transform initially scrambled puzzle goal state blank
upper-left corner tiles ordered 115 going left right, top bottom.
domain interesting plans hard find, branching factor small
varies little mean 2.13 (Korf et al., 2001), duplicates,
heuristic reasonably informed.
experiments use popular 100 15-puzzle instances created Korf (1985).
plots include A*, however, used 94 instances solvable A* 6GB
memory. average optimal solution length instances 52.4. training
set, generated 1,000 instances using 1 million step random walk back goal
position. used Manhattan distance heuristic, sums vertical horizontal
distance tile must move arrive goal position. implementation follows
heavily optimized solver presented Burns et al. (2012).
B.2 Pancake Puzzle
pancake puzzle (Dweighter, 1975; Gates & Papadimitriou, 1979) another permutation
puzzle. consists stack differently sized pancakes numbered 1N . pancakes
must presented fancy breakfast, chef needs sort originally unordered
stack pancakes continually sticking spatula stack reversing order
pancakes above. Said another way, pancake problem involves sorting sequence
numbers using prefix reversal operations. simple problem interesting
creates search graph large branching factor (the number pancakes minus one).
731

fiBurns, Ruml, &

Figure 15: screenshot platform pathfinding domain (left), zoomed-out image
single instance (right). knight must find path starting
location, maze, door (on right-side left image,
center right image).

experiments, used 25 randomly generated 50-pancake puzzle instances,
training set consisted 1,000 randomly generated instances. used powerful GAP
heuristic Helmert (2010), sums number pairs adjacent pancakes
sequence.
B.3 Platform Pathfinding
platform domain pathfinding domain creation dynamics based
2-dimensional platform-style video game, written partially first author, called
mid5 . left image Figure 15 shows screenshot mid. goal knight
traverse maze initial location, jumping platform platform,
reaches door. Mid open source game available http://code.google.com/p/
mid-game. experiments game physics game ported C C++
embedded C++ search codebase. generated 1,000 training instances
100 test instances using level generator mid. example instance shown
right panel Figure 15. domain unit-cost large state space
well-informed heuristic.
available actions different combinations controller keys may pressed
single iteration games main loop: left, right, jump. Left right move
knight respective directions (holding time never considered
search domain, movements would cancel out, leaving knight
5. author Steve McCoy, also drew tile graphics shown Figure 15.

732

fiHeuristic Search Time Matters

place), jump button makes knight jump, applicable. knight jump
different heights holding jump button across multiple actions row
maximum 8. actions unit cost, cost entire solution number
game loop iterations, called frames, required execute path. frame corresponds
50ms game play.
state state space contains x, position knight using doubleprecision floating point values, velocity direction (x velocity stored
determined solely left right actions), number remaining actions
pressing jump button add additional height jump, boolean stating
whether knight currently falling. knight moves speed 3.25 units per
frame horizontal direction, jumps speed 7 units per frame, simulate
gravity falling, 0.5 units per frame added knights downward velocity
maximum 12 units per frame.
details platform domain, please refer source code repository
given start Section 6.
B.3.1 Level Generator
instances used experiments created using level generator mid,
special maze generator builds 2-dimensional platform mazes 5050 grid blocks.
block either open occluded, ensure solvability given constraints imposed
limited jump height, generator builds maze stitching together pieces
hand-created portfolio. piece consists number blocks either free
occluded, start end location traversability ensured within piece.
piece added grid location fits. piece fits
occlude block belongs previously placed piece. maze built using depthfirst procedure: piece selected random fits grid start location
lined end location predecessor placed procedure recurs.
number successors node chosen uniformly range 39 inclusive,
procedure backtracks pieces fit previous block.
maze constructed, blocks belong piece marked occluded.
right image Figure 15 shows sample level generated procedure. source
code level generator available mid source repository mentioned above.
B.3.2 Heuristic
developed heuristic platform domain based visibility navigation
(Nilsson, 1969). maze pre-processed convert grid representation set
polygons representing connected component occluded cells level. space
scaled account movement speed knight; knight fall faster
move horizontal direction, polygons end squished vertically
stretched horizontally. visibility navigation problem solved reverse
four corners goal cell center every non-occluded cell maze.
maintain admissibility, cost edge visibility problem length


visibility line, instead maximum length line divided 2
X displacements end points line. accounts fact
733

fiBurns, Ruml, &

Figure 16: visibility navigation instance platform domains heuristic. visibility path initial state goal state drawn red.

knight bemoving horizontally vertically time,
moving distance 2 scaled space still takes single frame.
search, heuristic value state computed one two different ways.
straight-line path center knight goal occluded
maximum X distances goal scaled travel speed used
heuristic estimate. Otherwise, heuristic cost path visibility graph
center cell contains knights center point minus maximum
X distance (in number frames) knights center point center
cell. Figure 16 shows map right image Figure 15, scaled, broken
polygon components, visibility path initial state goal
state drawn red.
B.4 Grid Pathfinding
final domain grid pathfinding. popular domain video games
robotics, garnered much attention heuristic search community.
experiments, used 5,000x5,000 grids four-way eight-way connectivity
uniform obstacle distributions. four-way connected grids, cell blocked
probability 0.35, eight-way connected grids cells blocked
probability 0.45. also consider two different cost models, standard
unit cost model
horizontal vertical moves cost 1 diagonal moves cost 2.
called life cost model, move cost equal row number
move took place, causing cells toward top grid preferred.
life cost model, short direct solutions found quickly, however relatively
expensive, least-cost solution involves many annoying economizing steps (Ruml &
Do, 2007). model viewed instantiation popular belief time
money, one choose incur additional cost shorter simpler path.
combination movement model cost model, generated 25 test instances 1,000
training instances. Finally, used Manhattan distance heuristic four-connected
grids octile distance heuristic eight-connected grids. life cost model
734

fiHeuristic Search Time Matters

heuristics also took account fact moving toward top grid back
may cheaper direct path.

Appendix C. Anytime Policy Estimation
challenging write algorithms rely off-line training data. algorithm
behaves unexpectedly, unclear bug implementation, bug
off-line learning procedure, training set merely insufficiently representative.
appendix, describe implemented verified procedure estimating
anytime profile.
Figure 17 shows pseudocode building profile based description given
Hansen Zilberstein (2001). algorithm accepts set solution streams
input, one stream solved instance, proceeds two steps. first step
Count-Solutions function counts number times solution cost
improved upon. function iterates solution (line 5), computes bin
histogram cost value falls (line 7), subsequent solution count
added qqtcounts time step first solution improved second
solution. addition, number total improvements solution time bin
counted qtcounts array. costbin timebin functions bin cost time values
respectively returning integer corresponding index histogram:


q qmin
costbin(q) =
(qmax qmin )/ncost


tmin
timebin(t) =
(tmax tmin )/ntime
.
second step Probabilities function converts counts computed
first step normalized probability values. achieved dividing number
steps solution cost qi improved solution cost qj (qqtcounts)
total number steps solution cost qi improved (qtcounts,
lines 28). probability values smoothed adding half smallest probability
bin representing solution cost improvement. step removes zero-probabilities,
allowing improvement considered. Finally, probabilities normalized
probability non-decreasing-cost solutions current cost time step sum
one (lines 3137). profile computed, saved disk later use
computing stopping policy.
found extremely useful simple way validate policies
debugging implementation. One option create stopping policy, run ARA*
monitoring handful instances handful utility functions verify
gives expected behavior. Unfortunately, approach rather cumbersome
prone error, evaluated policy small number instances
willing run hand. Instead, chose validate implementation plotting
polices generated training data different utility functions. plotting
extreme policies care solution cost search time, along
intermediate policies trade-off two, much simpler debug code.
735

fiBurns, Ruml, &

Profile(streams)
1. qtcounts, qqtcounts Count-Solutions(streams)
2. return Probabilities(qtcounts, qqtcounts)
Count-Solutions(streams)
3. qtcounts new int[ncost][ntime] // Initialized zero.
4. qqtcounts new int[ncost][ncost][ntime] // Initialized zero.
5. streams
6.
1 |s|
7.
qi costbin(s[i].cost)
8.
qcur qi , tcur 0
9.
// Count cost time increment solution i.
10.
j + 1 |s|
11.
qnext costbin(s[j].cost)
12.
tnext timebin(s[j].time s[i].time)
13.
// Current solution cost time solution j.
14.
= tcur tnext 1
15.
increment qtcounts[qi ][t]
16.
increment qqtcounts[qcur ][qi ][t]
17.
qcur qnext , tcur tnext
18.
// Last solution cost final time.
19.
= tcur ntime
20.
increment qtcounts[qi ][t]
21.
increment qqtcounts[qcur ][qi ][t]
22. return qtcounts, qqtcounts
Probabilities(qtcounts, qqtcounts)
23. probs new float[ncost][ncost][ntime]
24. qi 1 ncost
25.
1 ntime
26.
qtcounts[qi ][t] = 0 continue
27.
qj 1 ncost
28.
probs[qj ][qi ][t] qqtcounts[qj ][qi ][t]/qtcounts[qi ][t]
29. Smoothing: add half smallest probability elements probs improving solution cost.
30. // Normalize.
31. qi 1 ncost
32.
1 ntime
33.
sum 0
34.
qj 1 ncost
35.
sum sum + probs[qj ][qi ][t]
36.
qj 1 ncost
37.
probs[qj ][qi ][t] probs[qj ][qi ][t]/sum
38. return probs

Figure 17: Pseudocode profile estimation.

Figure 18 shows plots created platform domain. plot cost
axis time x axis. Green circles represent inputs policy
says keep searching, red crosses represent inputs policy says stop
736

fiHeuristic Search Time Matters

(a)

(b)

1000

100

200

300

2000

cost

2000

cost

cost

2000

(c)

1000

100

time

200

time

300

1000

100

200

300

time

Figure 18: Three different policies: (a) prefers cheaper solutions expense (wf =
1, wt = 0), (b) attempts trade search time solution cost (wf =
0.6, wt = 1), (c) prefers solution fast possible (wf = 0, wt =
1).

searching return solution. expected, policy always continues goal
minimize solution cost always stops goal minimize search time (cf.
left-most right-most plots Figure 18 respectively). center plot shows
also successfully found policies trade search time solution cost stopping
cost sufficiently low. Finally, left-most plot, bottom-most rightmost sides policy always stop implementation chose stop
training data available estimate profile given input values.

References
Bjornsson, Y., Bulitko, V., & Sturtevant, N. (2009). TBA*: time-bounded A*. Proceedings
Twenty-first International Joint Conference Artificial Intelligence (IJCAI09), pp. 431436.
Boddy, M., & Dean, T. (1989). Solving time-dependent planning problems,. Proceedings
Eleventh International Joint Conference Artificial Intelligence (IJCAI-89),
Vol. 2, pp. 979984.
Burns, E., Hatem, M., Leighton, M. J., & Ruml, W. (2012). Implementing fast heuristic
search code. Proceedings Fifth Annual Symposium Combinatorial Search
(SoCS-12).
Burns, E., & Ruml, W. (2013). Iterative-deepening search on-line tree size prediction.
Annals Mathematics Artificial Intelligence, S68, 123.
Chen, P. C. (1992). Heuristic sampling: method predicting performance tree
searching programs. SIAM Journal Computing, 21 (2), 295315.
Cox, M. T., & Raja, A. (2011). Metareasoning: Thinking thinking. MIT Press.
737

fiBurns, Ruml, &

Dean, T., & Boddy, M. (1988). analysis time-dependent planning. Proceedings
Seventh National Conference Artificial Intelligence (AAAI-88), pp. 4954.
Dean, T., Kaelbling, L. P., Kirman, J., & Nicholson, A. (1993). Planning deadlines
stochastic domains. Proceedings eleventh national conference Artificial
intelligence, Vol. 574, p. 579. Washington, DC.
Dechter, R., & Pearl, J. (1988). optimality A*. Kanal, L., & Kumar, V. (Eds.),
Search Artificial Intelligence, pp. 166199. Springer-Verlag.
Dionne, A. J., Thayer, J. T., & Ruml, W. (2011). Deadline-aware search using on-line measures behavior. Proceedings Fourth Annual Symposium Combinatorial
Search (SoCS-11).
Domshlak, C., Karpas, E., & Markovitch, S. (2010). max max: Online learning
speeding optimal planning. AAAI Conference Artificial Intelligence
(AAAI-10), pp. 17011706.
Dweighter, H. (1975). Elementary problem E2569. American Mathematical Monthly, 82 (10),
1010.
Finkelstein, L., & Markovitch, S. (2001). Optimal schedules monitoring anytime algorithms. Artificial Intelligence, 126 (1), 63108.
Garvey, A. J., & Lesser, V. R. (1993). Design-to-time real-time scheduling. Systems, Man
Cybernetics, IEEE Transactions on, 23 (6), 14911502.
Gates, W. H., & Papadimitriou, C. H. (1979). Bounds sorting prefix reversal. Discrete
Mathematics, 27 (1), 4757.
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial Intelligence
Research, 28 (1), 267297.
Hansen, E. A., & Zilberstein, S. (2001). Monitoring control anytime algorithms:
dynamic programming approach. Artificial Intelligence, 126, 139157.
Hansen, E. A., Zilberstein, S., & Danilchenko, V. A. (1997). Anytime heuristic search: First
results. Tech. rep., University Massachusetts, Amherst.
Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,
SSC-4 (2), 100107.
Helmert, M. (2010). Landmark heuristics pancake problem. Proceedings
Third Symposium Combinatorial Search (SoCS-10).
Helmert, M., & Roger, G. (2008). good almost perfect. Proceedings
Twenty-Third AAAI Conference Artificial Intelligence (AAAI-08).
Hernandez, C., Baier, J., Uras, T., & Koenig, S. (2012). Time-bounded adaptive A*.
Proceedings Eleventh International Joint Conference Autonomous Agents
Multiagent Systems (AAMAS-12).
Horvitz, E., Ruan, Y., Gomes, C., Kautz, H., Selman, B., & Chickering, M. (2001).
Bayesian approach tackling hard computational problems. Proceetings
Seventeenth Conference Uncertainty Artificial Intelligence (UAI-01).
738

fiHeuristic Search Time Matters

Kilby, P., Slaney, J., Thiebaux, S., & Walsh, T. (2006). Estimating search tree size.
Proceedings twenty-first national conference artificial intelligence (AAAI06).
Knuth, D. E. (1975). Estimating efficiency backtrack programs. Mathematics
computation, 29 (129), 121136.
Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic search
real-time situated agents. Autonomous Agents Multi-Agent Systems, 18 (3), 313
341.
Korf, R. E. (1985). Iterative-deepening-A*: optimal admissible tree search. Proceedings Ninth International Joint Conference Artificial Intelligence, pp.
10341036.
Korf, R. E. (1990). Real-time heuristic search. Artificial intelligence, 42 (2-3), 189211.
Korf, R. E., Reid, M., & Edelkamp, S. (2001). Time complexity iterative-deepening-A*.
Artificial Intelligence, 129 (1), 199218.
Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime a* provable bounds
sub-optimality. Advances Neural Information Processing Systems (NIPS-03),
16.
Michie, D., & Ross, R. (1969). Experiments adaptive graph traverser. Machine
Intelligence 5, pp. 301318.
Nilsson, N. J. (1969). mobile automaton: application artificial intelligence techniques. Proceedings First International Joint Conference Artificial intelligence (IJCAI-69), pp. 509520.
Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.
Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,
1, 193204.
Rice, J. R. (1976). algorithm selection problem. Advances Computers, 15, 65118.
Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime search
via restarting. Proceedings Twentieth International Conference Automated
Planning Scheduling (ICAPS-10), pp. 137144.
Ruml, W., Do, M., Zhou, R., & Fromherz, M. P. (2011). On-line planning scheduling:
application controlling modular printers. Journal Artificial Intelligence Research,
40 (1), 415468.
Ruml, W., & Do, M. B. (2007). Best-first utility-guided search. Proceedings 20th
International Joint Conference Artificial Intelligence (IJCAI-07), pp. 23782384.
Russell, S., & EricWefald (1991). right thing: studies limited rationality.
MIT Press.
Shekhar, S., & Dutta, S. (1989). Minimizing response times real time planning
search. Proceedings Eleventh International Joint Conference Artificial
Intelligence (IJCAI-89), pp. 238242. Citeseer.
739

fiBurns, Ruml, &

Sturtevant, N. (2012). Benchmarks grid-based pathfinding. Transactions Computational Intelligence AI Games, 4 (2), 144 148.
Sturtevant, N. R. (2011). Distance learning agent-centered heuristic search. Proceedings
Fourth Annual Symposium Combinatorial Search (SoCS-11).
Thayer, J. (2012). Faster Optimal Suboptimal Heuristic Search. Ph.D. thesis, University
New Hampshire.
Thayer, J. T., Benton, J., & Helmert, M. (2012). Better parameter-free anytime search
minimizing time solutions. Proceedings Fifth Annual Symposium
Combinatorial Search (SoCS-12).
Thayer, J. T., Dionne, A., & Ruml, W. (2011). Learning inadmissible heuristics
search. Proceedings Twenty-first International Conference Automated
Planning Scheduling (ICAPS-11).
Thayer, J. T., & Ruml, W. (2008). Faster weighted a*: optimistic approach
bounded suboptimal search. Proceedings Eighteenth International Conference
Automated Planning Scheduling (ICAPS-08).
Thayer, J. T., & Ruml, W. (2009). Using distance estimates heuristic search. Proceedings Nineteenth International Conference Automated Planning Scheduling (ICAPS-09).
Thayer, J. T., & Ruml, W. (2010). Anytime heuristic search: Frameworks algorithms.
Proceedings Third Annual Symposium Combinatorial Search (SoCS-10).
Tolpin, D., & Shimony, S. E. (2011). Rational deployment CSP heuristics. Proceedings Twenty-Second International Joint Conference Artificial Intelligence
(IJCAI-11).
Valenzano, R. A., Sturtevant, N., Schaeffer, J., Buro, K., & Kishimoto, A. (2010). Simultaneously searching multiple settings: alternative parameter tuning
suboptimal single-agent search algorithms. Proceedings Twentieth International Conference Automated Planning Scheduling (ICAPS-10).
van den Berg, J., Shah, R., Huang, A., & Goldberg, K. (2011). ANA*: Anytime nonparametric A*. Proceedings Twenty-fifth AAAI Conference Artificial Intelligence
(AAAI-11).
Zohavi, U., Felner, A., Burch, N., & Holte, R. (2010). Predicting performance ida*
using conditional distributions. Journal Artificial Intelligence Research, 37 (1), 41
84.

740

fiJournal Artificial Intelligence Research 47 (2013) 853-899

Submitted 03/13; published 08/13

Framing Image Description Ranking Task:
Data, Models Evaluation Metrics
Micah Hodosh
Peter Young
Julia Hockenmaier

mhodosh2@illinois.edu
pyoung2@illinois.edu
juliahmr@illinois.edu

Department Computer Science
University Illinois
Urbana, IL 61801, USA

Abstract
ability associate images natural language sentences describe
depicted hallmark image understanding, prerequisite applications sentence-based image search. analogy image search, propose
frame sentence-based image annotation task ranking given pool captions.
introduce new benchmark collection sentence-based image description search,
consisting 8,000 images paired five different captions provide
clear descriptions salient entities events. introduce number systems
perform quite well task, even though based features
obtained minimal supervision. results clearly indicate importance
training multiple captions per image, capturing syntactic (word order-based)
semantic features captions. also perform in-depth comparison human
automatic evaluation metrics task, propose strategies collecting human
judgments cheaply large scale, allowing us augment collection
additional relevance judgments captions describe image. analysis shows
metrics consider ranked list results query image sentence
significantly robust metrics based single response per query. Moreover, study suggests evaluation ranking-based image description systems
may fully automated.

1. Introduction
ability automatically describe entities, events scenes depicted image
possibly ambitious test image understanding. advances task
significant practical implications, since billions images web
personal photo collections. ability efficiently access wealth information
contain hampered limitations standard image search engines, must rely
text appears near image (Datta, Joshi, Li, & Wang, 2008; Popescu, Tsikrika, &
Kludas, 2010). lot work multi-label classification problem
associating images individual words tags (see, e.g., Blei & Jordan, 2003; Barnard,
Duygulu, Forsyth, Freitas, Blei, & Jordan, 2003; Feng & Lapata, 2008; Deschacht & Moens,
2007; Lavrenko, Manmatha, & Jeon, 2004; Makadia, Pavlovic, & Kumar, 2010; Weston,
Bengio, & Usunier, 2010), much harder problem automatically associating images
complete sentences describe recently begun attract attention.

2013 AI Access Foundation. rights reserved.

fiHodosh, Young & Hockenmaier

1.1 Related Work
Although approaches framed sentence-based image description task mapping images sentences written people (Farhadi, Hejrati, Sadeghi, Young, Rashtchian,
Hockenmaier, & Forsyth, 2010; Ordonez, Kulkarni, & Berg, 2011), research
area focused task automatically generating novel captions (Kulkarni, Premraj,
Dhar, Li, Choi, Berg, & Berg, 2011; Yang, Teo, Daume III, & Aloimonos, 2011; Li, Kulkarni, Berg, Berg, & Choi, 2011; Mitchell, Dodge, Goyal, Yamaguchi, Stratos, Han, Mensch,
Berg, Berg, & Daume III, 2012; Kuznetsova, Ordonez, Berg, Berg, & Choi, 2012; Gupta,
Verma, & Jawahar, 2012). argue paper framing image description natural language generation problem introduces number linguistic difficulties detract
attention underlying image understanding problem wish address. Since
sentence-based image description retrieval system requires ability associate images
captions describe depicted them, argue important evaluate
mapping images sentences independently generation aspect. Research caption generation also ignored image search task, arguably
much greater practical importance.
systems cited either evaluated data set group released
earlier work (Rashtchian, Young, Hodosh, & Hockenmaier, 2010), SBU Captioned Photo Dataset (Ordonez et al., 2011). data set consists 1,000 images
PASCAL VOC-2008 object recognition challenge annotated five descriptive captions purposely collected task. SBU data set consists one
million images captions harvested Flickr. Gupta et al. (2012) system
use Grubinger, Clough, Mller, Deselaerss (2006) IAPR TC-12 data set, consists
20,000 images paired longer descriptions.
Although details differ, models rely existing detectors define map images
explicit meaning representation language consisting fixed number scenes, objects
(or stuff), attributes spatial relations (Farhadi et al., 2010; Kulkarni et al., 2011;
Li et al., 2011; Yang et al., 2011; Ordonez et al., 2011; Mitchell et al., 2012).
unclear well detector-based approaches generalize: models evaluated
PASCAL VOC-2008 data set (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011;
Yang et al., 2011; Mitchell et al., 2012) rely detectors may trained
images contained corpus, Kuznetsova et al. (2012) select test set 1,000 images
SBU data set detectors work well. Moreover, among systems
evaluated PASCAL VOC-2008 data set, Kulkarni et al. (2011), Li et al. (2011),
Li et al. (2011) Mitchell et al.s (2012) results may directly comparable, since different
research groups report different evaluation metrics use different parts data set
test training data. evaluation generation systems generally well known
difficult (see, e.g., Dale & White, 2007; Reiter & Belz, 2009), typically requires expensive
human judgments consider quality content selection (what
described) surface realization (the fluency generated text). syntactic
pragmatic issues confound purely semantic question whether image correctly
described caption.

854

fiFraming Image Description Ranking Task

1.2 Approach
paper, focus task associating images sentences drawn large,
predefined pool image descriptions. descriptions generated automatically
harvested web (Feng & Lapata, 2008; Ordonez et al., 2011), written
people asked describe them. argue evaluating ability select
rank, rather generate, appropriate captions image direct test
fundamental semantic question well associate images sentences
describe well. Framing image description ranking task also number
additional advantages. First, allows us handle sentence-based image annotation
search unified framework, allowing us evaluate whether advances one task
carry other. Second, framing image description ranking problem greatly
simplifies evaluation. establishing parallel description retrieval,
use metrics evaluate tasks. Moreover, show rank
original caption, easily determined automatically, leads metrics correlate
highly systems rankings obtained human judgments, even underestimate
actual performance. also show standard automatic metrics Bleu (Papineni,
Roukos, Ward, & Zhu, 2002) Rouge (Lin, 2004) also used evaluate
caption generation systems show poor correlation human judgments, leading us
believe evaluation caption generation system automated. also
perform large-scale human evaluation, since sentences data set image
descriptions written people, need collect purely semantic judgments whether
describe images system associated with. since judgments
independent task, use evaluate image description retrieval
systems. Since collect judgments image-caption pairs publicly available
data set, also establish common benchmark enables direct comparison different
systems. believe another advantage caption generation task. Since
many possible ways describe image, generation systems liberty
less specific describe image. makes direct comparison
independently obtained judgments quality two different systems difficult,
since one system may aiming solve much harder task other, implies
unless system outputs common benchmark collection images made publicly
available, cannot shared, objective evaluation would allow community
measure progress difficult problem. since caption generation systems also
need able determine well caption describes image, data set could
potentially used evaluate semantic component.
1.3 Contributions Outline Paper
Section 2, discuss need new data set image description introduce
new, high quality, data set image description enable community compare
different systems benchmark. PASCAL VOC-2008 data set 1,000
images (Rashtchian et al., 2010) used number image description systems
(Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al.,
2012; Gupta et al., 2012), number shortcomings limit usefulness. First,
domain relatively limited, captions relatively simple. Second, since
855

fiHodosh, Young & Hockenmaier

images drawn data used PASCAL VOC-2008 object classes challenge,
difficult guarantee fair evaluation description systems rely off-the-shelf
object detectors (e.g., Felzenszwalb, McAllester, & Ramanan, 2008) data set, since
may possible identify images detectors trained on.
experiments paper therefore based larger, diverse, data set 8,000
images. Unlike data sets pair images sentences merely related
image (Feng & Lapata, 2008; Ordonez et al., 2011), image data sets
paired five different captions purposely written describe image.
Section 3, describe image description systems. image description
novel task, remains largely unknown kind model, kind
visual linguistic features requires. Instead unidirectional mapping images
sentences common current caption generation systems, map images
sentences space. allows us apply system image search
retrieving images closest query sentence, image description
annotating images sentences closest it. technique use,
Kernel Canonical Correlation Analysis (KCCA; Bach & Jordan, 2002), already
successfully used associate images (Hardoon, Szedmak, & Shawe-Taylor, 2004; Hwang
& Grauman, 2012; Hardoon, Saunders, Szedmak, & Shawe-Taylor, 2006) image regions
(Socher & Li, 2010) individual words sets tags, Canonical Correlation
Analysis (Hotelling, 1936) also used associate images related Wikipedia
articles ten different categories (Rasiwasia, Pereira, Coviello, Doyle, Lanckriet, Levy,
& Vasconcelos, 2010). However, performance techniques much
stringent task associating images sentences describe depicted
evaluated. compare number text kernels capture different linguistic
features. experimental results (discussed Section 4) demonstrate importance
robust textual representations consider semantic similarity words, hence take
linguistic diversity different captions associated image account.
visual features relatively simple. number image description systems (Farhadi et al.,
2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Kuznetsova et al., 2012) largely
rely trained detectors, e.g. obtain explicit intermediate meaning representation
depicted objects, scenes events. approach would ultimately require separate
detectors, hence labeled training data, term phrase chosen meaning
representation language. show image features capture low-level
perceptual properties fact work surprisingly well larger data set
in-domain detectors available.
Section 4, consider question evaluation, use number different metrics
compare systems. Since focus problem learning appropriate mapping
images captions, follow standard machine learning practice evaluate
ability function generalize unseen examples. Hence, separate pool
captions images used testing used train systems. first consider
metrics quality single image-caption pair, compare automatically computed
scores detailed human judgments. examine metrics evaluate ranked
lists returned systems. analysis reveals that, current level performance,
differences models may become apparent single caption per image
considered, commonly done caption generation systems. even two models
856

fiFraming Image Description Ranking Task

equally likely fail return suitable caption first result, still prefer
one likely rank good captions higher other, since arguably
provides better approximation semantic space images near captions
describe well. Since test pool contains single gold item query,
first consider metrics based rank recall gold item. show
simpler, binary judgments image descriptions good approximations
fine-grained human judgments collected large scale via crowdsourcing.
augment test pool data set relevance judgments, hope
add usefulness community resource benchmark. judgments
show actual performance systems higher recall gold item
indicates. However, comparison system rankings obtained via different metrics also
suggests differences rank recall gold item correlate highly
difference performance according binary relevance judgments.

2. New Data Set Image Description
used crowdsourcing collect descriptive captions large number images
people animals (mostly dogs). describing data set annotation methodology, discuss kind captions useful image description, motivate
need create new data sets task.
2.1 Mean Image Description?
Since automatic image description relatively novel task, worth reflecting
means describe images, wish say image. fact
substantial body work image description related image libraries (Jaimes, Jaimes,
& Chang, 2000; Shatford, 1986) useful revisit purpose. argue
three different kinds image descriptions commonly distinguished, one
type, so-called conceptual descriptions, relevance image understanding aim achieve automatic captioning. Conceptual image descriptions identify
depicted image, may abstract (e.g., concerning mood
picture may convey), image understanding mostly interested concrete descriptions
depicted scene entities, attributes relations, well events
participate in. focus actually image, conceptual descriptions
differ so-called non-visual descriptions, provide additional background information cannot obtained image alone, e.g. situation, time location
image taken. Perceptual descriptions capture low-level visual properties
images (e.g., whether photograph drawing, colors shapes dominate) little interest us, unless link properties explicitly depicted
entities. Among concrete conceptual descriptions, distinction drawn specific descriptions, may identify people locations names,
generic descriptions (which may, e.g., describe person woman skateboarder,
scene city street room). exception iconic entities
recognized (e.g., well-known public figures landmark locations Eiffel
Tower) argue image understanding focus information captured

857

fiHodosh, Young & Hockenmaier

BBC captions
(Feng Lapata 2010)

Consumption
soared
real price
drink fallen

AMD destroys
central vision

SBU Captioned Photo Dataset (Flickr)
(Ordonez et al. 2011)

Downers Grove
don't chew couch
train station (our condo pee kitchen
building
mama!
background),
way AG store
Chicago.

IAPR-TC12 data set
(Grubinger et al. 2006)

blue white airplane standing grey airport;
man red cones standing front two
red-dressed hostesses two passengers directly
stairs front airplane; brown landscape
high dark brown mountains snow-covered
summits light grey sky background;

Figure 1: data sets images captions
generic descriptions. leaves question obtain data set images paired
suitable descriptions train automatic description systems on.
2.2 Need New Data Sets
dearth images associated text available online, argue
text suitable task. work, notably natural language
processing community, focused images news articles (Feng & Lapata, 2008, 2010).
However, images often used illustrate stories, little direct connection
text (Figure 1, left). Furthermore, even captions describe depicted event,
tend focus information cannot obtained image itself. Similarly,
people provide captions images upload websites Flickr (Figure 1,
center), often describe situation images taken in, rather
actually depicted image. is, captions often provide non-visual overly
specific information (e.g., naming people appearing image location
image taken). simple reason people typically provide kinds
generic conceptual descriptions use purposes: Gricean maxims
relevance quantity (Grice, 1975) entail image captions written people
usually provide precisely kind information could obtained image
itself, thus tend bear tenuous relation actually depicted. Or,
state succinctly, captions usually written seen along images
accompany, users may wish bore readers obvious.
Ordonez et al. (2011) harvested images captions Flickr create
SBU Captioned Photo Dataset, discard vast majority images
captions actually descriptive. analysis random sample 100
images final data set revealed majority (67/100) captions describe
information cannot obtained image (e.g., naming people
locations appearing image), substantial fraction (23/100) describe small
detail image otherwise commentary image. Examples
issues shown Figure 1 (center). makes data set less useful kind
image understanding interested in: unless refer specific entities one may
actually wish identify (e.g., celebrities famous landmarks appear image),
proper nouns little help learning visual properties entity types unless one
858

fiFraming Image Description Ranking Task

data set 8,000 Flickr images 5 crowd-sourced captions
man tricks bicycle ramps front crowd.
man bike executes jump part competition crowd watches.
man rides yellow bike ramp others watch.
Bike rider jumping obstacles.
Bmx biker jumps ramp.
group people sit table front large building.
People drinking walking front brick building.
People enjoying drinks table outside large brick building.
Two people seated table drinks.
Two people sitting outdoor cafe front old building.

Figure 2: data set images paired generic conceptual descriptions
infer kind entity refer to.1 IAPR TC-12 data set (Grubinger et al.,
2006), consists 20,000 photographs potentially useful purposes, since
contains descriptions recognized image without prior information
extra knowledge. However, descriptions, consist often multiple sentences
sentence fragments, tendency lengthy (average length: 23.1 words)
overly detailed, instead focusing salient aspects photograph. example,
photo airplane Figure 1 (right), two hostesses barely visible
nevertheless described detail.
2.3 Data Sets
Since kinds captions normally provided images describe images
themselves, collected data sets images captions. captions
obtained using crowdsourcing service provided Amazon Mechanical Turk
annotate image five descriptive captions. asking people describe
people, objects, scenes activities shown picture without giving
information context picture taken, able
obtain conceptual descriptions focus information obtained
image alone. annotation process quality control described detail
Rashtchian et al. (2010)s paper. annotated two different data sets manner:
2.3.1 PASCAL VOC-2008 Data Set
first data set produced relatively small, consists 1,000 images randomly selected training validation set PASCAL 2008 object recognition
challenge (Everingham, Gool, Williams, Winn, & Zisserman, 2008). used
large number image description systems (Farhadi et al., 2010; Kulkarni et al., 2011; Li
et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Gupta et al., 2012), since almost
systems (the exception Gupta et al., 2012) rely detectors trained
1. data set Ordonez et al. (2011) also differs significantly content ours: collection
focuses images eventualities, i.e. people animals something, majority Ordonez et
al.s images (60/100) depict people animals (e.g., still lifes, landscape shots).

859

fiHodosh, Young & Hockenmaier

images data set (Felzenszwalb et al., 2008), unclear well
approaches would generalize domains labeled data train detectors
available. captions PASCAL data set also relatively simple. example,
since data set contains many pictures depict focus people something, 25% captions contain verb, additional 15% captions
contain common static verbs sit, stand, wear, look.
2.3.2 Flickr 8K Data Set
work reported paper therefore collected larger, diverse data set
consisting 8,092 images Flickr.com website. Unlike static PASCAL
images, images data set focus people animals (mainly dogs) performing
action. Examples data set shown Figure 2. images chosen
six different Flickr groups,2 tend contain well-known people locations,
manually selected depict variety scenes situations. order avoid
ungrammatical captions, allowed workers United States passed
brief spelling grammar test devised annotate images.
interested conceptual descriptions, annotators asked write sentences describe
depicted scenes, situations, events entities (people, animals, objects).
collected multiple captions image considerable degree variance
way many images described. consequence, captions
images often direct paraphrases other: entity event situation
described multiple ways (man vs. bike rider, tricks vs. jumping),
everybody mentions bike rider, everybody mentions crowd ramp.
dynamic nature images also reflected described:
Captions data set average length 11.8 words, compared 10.8 words
PASCAL data set, 40% PASCAL captions contain verb
sit, stand, wear, look, 11% captions Flickr 8K set contain
verb, additional 10% contain common verbs. data sets, Flickr
training/test/development splits human relevance judgments used evaluation
test items (Section 4) publicly available.3 online appendix paper contains
instructions workers, including qualification test pass
allowed complete tasks.

3. Systems Sentence-Based Image Description
Since image description requires ability associate images sentences, image
description systems viewed terms affinity function f (i, s) measures
degree association images sentences. evaluate ability compute
affinity functions measuring performance two tasks depend directly them.
Given candidate pool sentences Scand candidate pool images Icand , sentencebased image retrieval aims find image Icand maximizes f (i, sq ) query
sentence sq Scand . Conversely, image annotation aims find sentence Scand
2. groups called strangers!, Wild-Child (Kids Action), Dogs Action (Read Rules),
Outdoor Activities, Action Photography, Flickr-Social (two people photo)
3. http://nlp.cs.illinois.edu/HockenmaierGroup/data.html

860

fiFraming Image Description Ranking Task

maximizes f (iq , s) query image iq Icand . cases, f (i, s) course
maximized image-sentence pairs sentence describes image well:
Image search:
Image annotation:

= arg maxiIcand f (i, sq )


(1)

= arg maxsScand f (iq , s)

formulation completely general: although will, evaluation purposes, define
Scand set captions originally written images Icand ,
case, Scand could also, example, defined implicitly via caption generation
system. order evaluate well f generalizes unseen examples, evaluate
system test pools Itest Stest drawn domain disjoint
training data Dtrain = (Itrain , Strain ) development data Ddev = (Idev , Sdev ).
challenge defining f lies fact images sentences drawn two
different spaces, S. paper, present two different kinds image description
systems. One based nearest-neighbor search (NN), uses technique called
Kernel Canonical Correlation Analysis (KCCA; Bach & Jordan, 2002; Hardoon et al., 2004).
rely set known image-sentence pairs Dtrain = {hi, si}.
3.1 Nearest-Neighbor Search Image Description
Nearest-neighbor based systems use unimodal text image similarity functions directly
first find image-sentence pair training corpus Dtrain contains closest
item query, score items space similarity
item pair:
Image retrieval: fNN (i, sq ) = fI (iNN , i)

hiNN , sNN = arg max fS (sq , st ) (2)
hit ,st iDtrain

Image annotation: fNN (iq , s) = fS (sNN , s) hiNN , sNN = arg max fI (iq , )
hit ,st iDtrain

Despite simplicity, nearest-neighbor systems non-trivial baselines:
task annotating images tags keywords, methods annotate unseen images
tags nearest neighbors among training images known achieve competitive performance (Makadia et al., 2010), similar methods recently proposed
image description (Ordonez et al., 2011). Since task address allow
us return items training data, requires us rerank pool unseen captions
images, nearest-neighbor search requires two similarity functions. nearestneighbor systems use image representation KCCA-based systems, described
Section 3.3. main nearest-neighbor system, NN (NN5idf
F1 ), treats five captions
associated training image single document. reweights token
inverse document frequency (IDF) w , defines similarity two sentences
F1-measure (harmonic mean precision recall) computed IDF-reweighted
bag-of-words representation. Dtrain (w) subset training images whose captions
word w appears least once, inverse document frequency (IDF) w defined
|Dtrain |
w = log |Dtrain
(w)|+1 . IDF-reweighting potentially helpful task, since words
describe fewer images may particularly discriminative captions.
861

fiHodosh, Young & Hockenmaier

appendix, provide results NN systems use text representation
two KCCA systems.
3.2 Kernel Canonical Correlation Analysis Image Description
systems present based technique called Kernel Canonical Correlation
Analysis (Bach & Jordan, 2002; Hardoon et al., 2004). first provide brief introduction,
explain apply task.
3.2.1 Kernel Canonical Correlation Analysis (KCCA)
KCCA extension Canonical Correlation Analysis (Hotelling, 1936), takes
training data consisting pairs corresponding items hxi , yi drawn two different
feature spaces (xi X , yi Y), finds maximally correlated linear projections x
sets items newly induced common space Z. Since linear projections
raw features may capture patterns necessary explain pairing
data, KCCA implicitly maps original items higher-order spaces X 0 0 via
kernel functions KX = hX (xi ) X (xj )i, compute dot product two data points
xi xj higher-dimensional space X 0 without requiring explicit computation
mapping X . KCCA operates two resulting kernel matrices KX [i, j] =
hX (xi ) X (xj )i KY [i, j] = hY (yi ) (yj )i evaluate kernel functions
pairwise combinations items training data. returns two sets projection weights,
, maximize correlation two (projected) kernel matrices:
( , ) = arg max q
,

0 KX KY
(0 K2X + 0 KX )( 0 K2Y + 0 KY )

(3)

cast generalized eigenproblem (KX +I)1 KY (KY +I)1 KX = 2 ,
solved partial Gram-Schmidt orthogonalization (Hardoon et al., 2004; Socher & Li,
2010). regularization parameter penalizes size possible solutions, used
avoid overfitting, arises matrices invertible.
One disadvantage KCCA requires two kernel matrices training
data kept memory training. becomes prohibitive large data
sets, cause problems here, since training data consists 6,000
items (see Section 4.1).
3.2.2 Using KCCA Associate Images Sentences
KCCA successfully used associate images (Hardoon et al., 2004; Hwang &
Grauman, 2012; Hardoon et al., 2006) image regions (Socher & Li, 2010) individual
words sets tags. case, two original spaces X = = correspond
images sentences describe them. Images first mapped vectors KI (i)
whose elements KI (i)(t) = KI (it , i) evaluate image kernel function KI t-th
image Dtrain . Similarly, sentences mapped vectors KS (s) evaluate
sentence kernel function KS sentences Dtrain . learned projection weights
( , ) map KI (i) KS (s) induced space Z, expect images
appear near sentences describe well. KCCA-based image annotation
862

fiFraming Image Description Ranking Task

search system, therefore define f cosine similarity (sim) points new space:
fKCCA (i, s) = sim(KI (i), KS (s))

(4)

describe image text kernels used KCCA systems.
3.3 Image Kernels
contrast much work done image description, assumes existence
large number preexisting detectors, image representations used paper
basic, rely three different kinds low-level pixel-based perceptual
features capture color, texture (Varma & Zisserman, 2005) shape information
form SIFT descriptors (Lowe, 2004; Vedaldi & Fulkerson, 2008). believe
establishes important baseline, leave question complex image
representations affect performance future work. use two different kinds kernels:
histogram kernel K Histo , represents image single histogram feature
values computes similarity two images intersection histograms,
pyramid kernel K Py (Lazebnik, Schmid, & Ponce, 2009), represents image
pyramid nested regions, computes similarity two images terms
intersection histograms corresponding regions. cases, compute separate
kernel three types image features average result.
3.3.1 Histogram Kernel (K Histo )
image xi represented histogram Hi discrete-valued features, Hi (v)
fraction pixels xi value v. similarity two images xi xj defined
intersection histograms, i.e. percentage pixels mapped
onto pixel feature value image:
K(xi , xj ) =

V
X

min(Hi (v), Hj (v))

(5)

v=1

combine three kernels based different kinds visual features: KC captures color,
represented three CIELAB coordinates. KT captures texture, represented descriptors capture edge information different orientations centered pixel (Varma
& Zisserman, 2005). KS based SIFT descriptors, capture edge shape information manner invariant changes rotation illumination,
shown distinct across possible objects image Lowe, 2004; Vedaldi & Fulkerson,
2008. use 128 color words, 256 texture words 256 SIFT words, obtained unsupervised fashion K-means clustering 1,000 points 200 images PASCAL
2008 data set (Everingham et al., 2008). final histogram kernel K Histo average
responses three kernels KCHisto , KTHisto , KSHisto , taken pth power:

p
1 X
K Histo (xi , xj ) =
KFHisto (xi , xj )
(6)
3
F {C,S,T}

863

fiHodosh, Young & Hockenmaier

3.3.2 Pyramid Kernel K Py
spatial pyramid kernel (Lazebnik et al., 2009) generalization histogram kernel
captures similarities global, also local level. image xi
represented multiple levels scale l (l {0, 1, 2}) level partitions
image smaller smaller grid Cl = 2l 2l cells (C0 = 1, C1 = 4, C2 = 16),
cell c represented histogram Hic . similarity images xi xj level l,
Iijl , turn defined sum histogram similarities corresponding cells
0l , ..., Cl level:
Iijl

=

Cl X
V
X

min(Hic (v), Hjc (v))

(7)

c=0l v=1

Although similarities level l subsume fine-grained level l + 1 (Iijl
Iijl+1 ), similarities hold fine-grained level deemed important, since
indicate greater local similarity. pyramid kernel therefore proceeds
fine-grained (l = L) coarsest (whole-image) scale (l = 0), weights
1
similarities first encountered level l (Iijl Iijl+1 ) 2Ll
:

K

Py

(xi , xj ) =

IijL

+

L1
X
l=0

1
(I l Iijl+1 )
2Ll ij

(8)

L

=

1 0 X 1
+
Il
2L ij
2Ll+1 ij
l=1

compute three separate pyramid kernels KCPy , KTPy , KSPy based
color, texture SIFT features described above, combine single pyramid
kernel K Py , equation 6.
3.4 Basic Text Kernels
examine three different basic text kernels: bag words (BoW) kernel, Hwang
Graumans (2012) TagRank kernel, truncated string kernel (Tri).
3.4.1 Bag Words Kernel (BoW)
Since bag-of-words representations successfully used tasks involving text
images (e.g., Grangier & Bengio, 2008; Hardoon et al., 2006), include basic bag
words kernel, ignores word order represents caption simply vector
word frequencies. BoW kernel function defined cosine similarity
corresponding bag words vectors. either merge five captions training item
single document (BoW5), reduce training item single, arbitrarily chosen,
caption (BoW1). words frequency also reweighted IDF-score.
|Dtrain |
nearest neighbor approach, IDF-weight word w defined w = log |Dtrain
(w)|+1 ,
Dtrain (w) subset training images whose captions word w appears least

864

fiFraming Image Description Ranking Task

once. found square root w (BoW5
IDF-score w (BoW5idf ).



idf )

give better results standard

3.4.2 Tag Rank Kernel (TagRank)
Hwang Grauman (2012) apply KCCA keyword-based image annotation retrieval.
focus data set image paired list tags ranked importance, propose new kernel kind data. so-called tag rank kernel
(TagRank) variant bag words kernel aims capture relative importance tags reweighting according position list. Although Hwang
Grauman evaluate ability system associate images entire
sentences, also consider another data set lists tags correspond
words descriptive captions, argue linear order words captions also
reflects relative importance corresponding objects image, words
appear beginning sentence describe salient aspects image.
TagRank kernel, sentence represented two vectors, ~a ~r. ~a,
weight word based absolute position, first words sentence
always assigned high weight. absolute tag rank representation, caption
mapped vector ~a = [~a(1) . . . ~a(|V |)], |V | size vocabulary. ~a(i)
depends absolute position pi wi (if wi occurs multiple times s, pi averaged
positions). wi occur s, ~a(i) = 0. Otherwise,
~a(i) =

1
log2 (1 + pi )

(9)

~r, weight word depends current position compares distribution positions occupies training data. intuition behind relative rank
representation words higher weight occur earlier sentence usual. Here, caption mapped vector ~r = [~r(1) . . . ~r(V )] relative
tag ranks. Again, wi appear s, ~r(i) = 0. Otherwise wi relative tag rank
~r(i) indicates percent occurrences training data appear position pi .
Defining
P nik number times word wi appears position k training data,
ni = k nik total frequency wi training data:
Ppi
~r(i) = 1

k=1 nik

(10)

ni

final kernel KT given average two 2 kernels computed ~r ~a (
0 normalization terms):
"



#
V
V
1
1 X (~ri (k) ~rj (k))2
1 X (~ai (k) ~aj (k))2
KT (xi , xj ) =
exp
+ exp
(11)
2
2
~ri (k) + ~rj (k)
20
~ai (k) + ~aj (k)
k=1

k=1

Since image training data associated multiple, independently generated captions, evaluate kernel separately sentence pair average
response, instead treating multiple sentences single document.
865

fiHodosh, Young & Hockenmaier

TagRank kernel relatively sensitive overall sentence length, especially cases
subject preceded multiple adjectives modifiers (a large brown
dog vs. dog ). English, absolute tag rank generally assign high weights
subjects sentences, lower weight verbs, even lower weight objects scene
descriptions, tend follow main verb. relative tag rank may downweight
verbs, objects scene descriptions much (as long always used similar
positions sentence).
3.4.3 Trigram Kernel (Tri)
Since bag-of-words representations ignore words appear close
sentence, lose important information: image small child red hair playing
large brown dog white carpet looks quite different one small white dog
playing large red ball brown grass, although descriptions share majority
words. capture information, define trigram kernel truncated variant
string kernels (Shawe-Taylor & Cristianini, 2004) considers many single
words two captions share, also many short sequences (pairs triples) words
occur both.
word sequence w = w1 ...wk ordered list words. sentence = s1 ...sn contains
w (w s) long words w appear order specified w. is,
sentence large white dog runs catches red ball beach (when lemmatized)
contains subject-verb-object triple dog catch ball subject-verb-location
triple dog run beach. Formally, every substring (i, j) = si ...sj starts si = w1 ,
ends sj = wk , contains w considered match w. Ms,w set
substrings match sequence w:
Ms,w = {(i, j) | w = w1 ...wk si ...sj , w1 = si , wk = sj }

(12)

w restricted individual words (k = 1), string kernels identical standard
BoW kernel.
match strings s0 pair substrings (i, j) (i0 , j 0 ) s0
match word sequence w. Standard string kernels K(s, s0 ) weight matches
0
0
factor (ji+1)+(j +1) depends adjustable parameter respective
length matching substrings:
K(s, s0 ) =

X

X

X

0

0

(ji+1)+(j +1)

(13)

w (i,j)Ms,w (i0 ,j 0 )Ms0 ,w

order distinguish length matching subsequence, l(w),
length gaps (i, j) (i0 , j 0 ), replace two parameters , g , reformulate
as:
K(s, s0 ) =

X

X

X

0

0

+1)2l(w)
2l(w)
(ji+1)+(j

g

(14)

w (i,j)Ms,w (i0 ,j 0 )Ms0 ,w

found gap score g = 1, means gaps penalized,
match score = 0.5 perform best task.
866

fiFraming Image Description Ranking Task

Although string kernels generally defined sequences arbitrary length (k ),
found allowing longer sequences seem impact performance task
incurred significant computational cost. Intuitively, word pairs triplets represent
linguistic information need capture beyond BoW representation, since
include head-modifier dependencies large-dog vs. small-dog subject-verb-object
dependencies child-play-dog vs. dog-play-ball. therefore consider sequences
length k 3. w restricted sequences length k 3 ms,w = |Ms,w |,
yields following trigram kernel (Tri):
KTri (s, s0 ) =

X

ms,w ms0 ,w 2l(w)


(15)

w:k3

deal differences sentence length, normalize kernel response
two examples geometric mean two example responses themselves.
Since trigram kernel also captures sequences merely coincidental,
large white red, may seem advantageous use richer syntactic representations
dependency tree kernels (Moschitti, Pighin, & Basili, 2008), consider word
tuples correspond syntactic dependencies. However, kernels significantly
expensive compute, initial experiments indicated may perform
well trigram kernel. believe due fact image captions
contain little syntactic variation, hence surface word order may sufficient
differentiate e.g. agent action (whose mention subject
sentence) participants entities (whose mentions appear verb).
hand, many image captions contain lot syntactic ambiguity (e.g.
multiple prepositional phrases), vocabulary distinct standard
parsers trained on. may able benefit using richer
representation simply able recover sufficient accuracy.
order capture
relative importance words, also reweight sequences

IDF (or idf) weight theirQwords.
w defined before, IDF-weight
j
sequence w = wi ...wj w =
idf-weighted trigram kernel KTriidf
k=i wk .
(Tri5



idf )

therefore

KTriidf (s, s0 ) =

X

w ms,w ms0 ,w 2l(w)


(16)

w:k3

3.5 Extending Trigram Kernel Lexical Similarities
One obvious shortcoming basic text kernels require exact matches
words, cannot account fact situation, event, entity
described variety ways (see Figure 2 examples). One way capturing
linguistic diversity lexical similarities allow us define partial matches
words based semantic relatedness. Lexical similarity found success
tasks, e.g. semantic role labeling (Croce, Moschitti, & Basili, 2011),
fully exploited image description. Ordonez et al. (2011) define explicit equivalence classes
synonyms hyponyms increase natural language vocabulary corresponding
object detectors (e.g. word Dalmatian may trigger dog detector),
867

fiHodosh, Young & Hockenmaier

change underlying, pre-trained detectors themselves, ignoring potential
variation appearance between, e.g., different breeds dog. Similarly, Yang et al.s (2011)
generative model produce variety words type detected object scene,
given object scene label, word choice independent visual features.
therefore also investigate effect incorporating different kinds lexical similarities
trigram kernel allow us capture partial matches words.
explore effect incorporating lexical similarities tag-rank kernel, since
unclear affect computation ranks within sentence.
3.5.1 String Kernels Lexical Similarities
Since standard lexical similarities simS (w, wi ) necessarily yield valid kernel functions,
follow Bloehdorn, Basili, Cammisa, Moschitti (2006) use similarities
map word w vectors w
~ N -dimensional space, defined fixed vocabulary
size N . vector component w
~ (i) corresponds similarity w wi defined
:
(17)

w
~ (i) = simS (w, wi )

define corresponding word kernel function (w, w0 ), captures partial
match words w w0 according , cosine angle w
~ w
~ S0 :
(w, w0 ) = cos(~
wS , w
~ S0 )

(18)

may defined subset vocabulary. similarity words outside
vocabulary defined identify function, standard string kernel.
similarity sequences w w0 length l defined product word
kernels corresponding pairs sequence elements wi , wi0 :
(w, w0 ) =

l


(wi , wi0 )

(19)

i=1

(w) = {w0 |S (w0 , w) > 0, l(w0 ) = l(w)} set sequences non-zero
match w, string kernel KS similarity is:
KS (s, s0 ) =

X

X

ms,w ms0 ,w0 2l(w)
(w0 , w)


(20)

w w0 (w)


idf
0
obtain
IDF-weighted version kernel, KS (s, ), inner term multiplied w w0 :
X X p
KS (s, s0 ) =
w w0 ms,w ms0 ,w 2l(w)
(w0 , w)
(21)

w w0 (w)

experiments, use trigram variants kernels, restrict w
sequences length k 3.
consider three different kinds lexical similarities: WordNet-based Lin similarity
(Lin, 1998) (Lin ), distributional similarity metric (D ), novel alignment-based
868

fiFraming Image Description Ranking Task

similarity metric (A ), takes advantage fact image associated
five independently generated captions. metrics computed training corpus.
Distributional similarity also computed British National Corpus (BNC Consortium,
2007). corpora lemmatized, stop words removed similarities
computed. Since almost pair words non-zero similarity, word kernel
matrices dense, since similarities close zero,
little effect resulting kernel. therefore zero entries smaller 0.05
alignment-based kernel less 0.01 distributional kernel DC .
3.5.2 Lin Similarity Kernel (Lin )
Lins (1998) similarity relies hypernym/hyponym relations WordNet (Fellbaum,
1998) well corpus statistics. WordNet directed graph nodes (synsets)
represent word senses edges indicate is-a relations: parent sense (e.g., dog1 )
hypernym children (e.g., poodle1 dachshund1 ). Kernels based Lins similarity
found perform well tasks text categorization (Bloehdorn et al., 2006).
exception Farhadi et al. (2010), incorporate Lins similarity
model, evaluate benefit obtain it, WordNets hypernym-hyponym
relations used superficially associating images text (Weston et al.,
2010; Ordonez et al., 2011; Gupta et al., 2012). Lin similarity two word senses si , sj
defined
2 log P (LCS(si , sj ))
simLin (si , sj ) =
(22)
log P (si ) + log P (sj )
LCS(s1 , s2 ) refers lowest common subsumer s1 s2 WordNet, i.e.
specific synset ancestor (hypernym) s1 s2 . P (s) probability
randomly drawn word instance synset descendants (hyponyms).
use training data estimate P (s), follow Bloehdorn et al. (2006) assigning
word w frequent (first) noun sense sw WordNet 3.0. Hence, represent
word w WordNet sense vector w
~ Lin Lin similarities hypernyms H(sw ):
2log(f (si ))

log(f (s))+log(f (si ))
w
~ Lin (i) =
1


0

si H(s)
sw = si
otherwise

(23)

3.5.3 Distributional Similarity (DC )
Distributional similarity metrics based observation words similar
tend appear similar contexts (Jurafsky & Martin, 2008). components
w
~ DC non-negative pointwise mutual information scores (PMI) w wi , computed
corpus C:


PC (w, wi )
(24)
w
~ DC (i) = max 0, log2
PC (w)PC (wi )
PC (w) probability random sentence C contains w, PC (w, wi )
probability random sentence C contains w wi . compute two variants
869

fiHodosh, Young & Hockenmaier

metric: Dic computed image captions training corpus,
defined cooccurrences 1,928 words appear least 5 times corpus,
DBNC uses British National Corpus (BNC Consortium, 2007), defined
1,874 words appear least 5 times corpora, considers PMI scores
141,656 words appear least 5 times BNC.
3.5.4 Alignment-Based Similarity (A )
also propose novel, alignment-based, similarity metric (A ), takes advantage
fact image associated five independently generated captions,
specifically designed capture likely two words describe event
entity data set. borrow concept alignment machine translation
(Brown, Pietra, Pietra, & Mercer, 1993), instead aligning words sentences two
different languages, align pairs captions describe image. results
similarity metric better coverage data set WordNet based metrics,
much specific distributional similarities capture broad topical relatedness
rather semantic equivalence. Instead aligning complete captions, found
beneficial align nouns verbs independently other, ignore parts
speech. create two versions training corpus, one consisting nouns
caption, another one consisting verbs caption.
use Giza++ (Och & Ney, 2003) train IBM alignment models 12 (Brown et al., 1993)
pairs noun verb captions image obtain two sets translation
probabilities, one nouns (Pn (|w)) one verbs (Pv (|w)). Finally, combine
noun verb translation probabilities sum weighted relative frequency
word w tagged noun (Pn (w)) verb (Pv (w)) training corpus.
ith entry wA therefore:
w
~ (i) = Pn (wi |w)Pn (w) + Pv (wi |w)Pv (w)

(25)

define noun verb vocabulary follows: words appear least 5 times
noun, tagged noun least 50% occurrences, considered
nouns. since verbs polysemous nouns (leading broader translation
probabilities) often mistagged nouns domain, include words
verbs tagged verbs least 25 times, least 25% occurrences.
results 1180 noun 143 verb lemmas, including 11 nouns verbs.
use OpenNLP POS tagger lemmatization.
3.5.5 Comparing Similarity Metrics (Figure 3)
Figure 3 illustrates different similarity metrics, using words rider swim
examples. distributional similarities high words topically related
(e.g., swim pool ), alignment similarity tends high words used
describe entity (usually synonyms hyper/hyponyms) activity swim
paddle. Distributional similarities obtained image captions
specific domain. BNC similarities much broader help overcome data
sparsity, although BNC relatively low coverage kinds sports occur
data set. Lin similarity associates swim hypernyms sport activity,
870

fiFraming Image Description Ranking Task

Comparing similarity metrics: five words similar rider swim
Alignment
Strain
wi


wi

rider

biker
bicyclist
cyclist
bmx
bicycler

0.86
0.82
0.79
0.75
0.73

bike
dirt
motocross
motorcycle
ride

0.41
0.35
0.33
0.33
0.33

ride
horse
race
bike
jockey

swim

retrieve
paddle
dive
come
wade

0.56
0.54
0.52
0.38
0.31

pool
trunk
water
dive
goggles

0.53
0.35
0.34
0.30
0.29

fish
water
sea
pool
beach

Corpus
w

Distributional
Strain
BNC
Dic wi
DBNC

Lin
Strain
wi

Lin

0.21
0.20
0.19
0.17
0.16

traveler
cyclist
bicyclist
horseman
jockey

0.94
0.89
0.89
0.84
0.84

0.21
0.18
0.18
0.18
0.17

bathe
sport
football
activity
soccer

0.85
0.85
0.77
0.75
0.73

Figure 3: comparison lexical similarities noun rider verb swim
kinds sport football soccer. makes least suitable similarity
task (see also Section 4.3.4 experimental results), since terms
considered similar purposes identifying different ways visually similar
events entities described.
3.5.6 Combining Different Similarities
Combining different distributional alignment-based similarities allows us
capture different strengths method. define averaged similarity
captures aspects distributional similarities computed corpora:
DBNC (w, w0 ) + Dic (w, w0 )
(26)
2
every distributional kernel (w, w0 ), also define variant D+A (w, w0 )
incorporates alignment-based similarities taking maximum either kernel:4
DBNC,ic (w, w0 ) =

D+A (w, w0 ) = max(A (w, w0 ), (w, w0 ))

(27)

4. Evaluation Procedures Metrics Image Description
order evaluate scoring functions f (i, s) image-caption pairs, need evaluate
ability associate previously unseen images captions other. analogy
caption generation systems, first examine metrics aim measure quality
single image-description pair (Section 4.2). Here, focus image annotation task,
restrict attention first caption returned test item, subset
systems. collect graded human judgments small number native speakers
American English, investigate whether expert judgments approximated
4. operation may preserve positive definiteness matrix required valid kernel,
simply means effectively use (plain) CCA representation.

871

fiHodosh, Young & Hockenmaier

automatically computed Bleu (Papineni et al., 2002) Rouge (Lin & Hovy, 2003)
scores, simpler crowdsourced human judgments collected much
larger scale. Section 4.3, consider approaches evaluation aim measure
quality ranked list image-caption pairs returned system, allow us
evaluate large number systems. reasons space, focus discussion
subset systems, refer interested reader Appendix B
complete results. Since candidate pool contains one sentence image originally
associated query image sentence, first compare systems rank recall
original item. metrics computed automatically,
considered lower bounds actual performance, since image may associated
number captions describe well perhaps minor errors. show
crowdsourced human judgments mapped binary relevance judgments
correlate well fine-grained expert judgments, consider metrics based
relevance judgments.
4.1 Experimental Setup
describe data, tasks, systems evaluate experiments.
4.1.1 Data
Since PASCAL 2008 data set contains total 1,000 images, perform
experiments exclusively Flickr 8K set. split 8,000 images corpus (see
Section 2.3) three disjoint sets. training data Dtrain = hItrain , Strain consists
6,000 images, associated five captions, whereas test development data,
Dtest Ddev , consist 1,000 images associated one, arbitrarily chosen, caption.
captions preprocessed spellchecking Linux spell, normalizing compound words
(e.g., t-shirt, shirt, tee-shirt t-shirt), stop word removal, lemmatization.
4.1.2 Tasks
evaluate systems two tasks, sentence-based image annotation (or description)
sentence-based image search. image search, task return ranked list
1,000 images Itest captions (queries) Stest . Image annotation defined
analogously retrieval problem: task return ranked list 1,000 captions
Stest 1,000 test (query) images Itest . cases, ranked lists
produced independently 1,000 possible queries.
4.1.3 Systems
total 30 different systems, uses either nearest-neighbor approach
KCCA, paired different combination image text representations.
purposes discussing different evaluation metrics, focus small number
systems: best-performing nearest-neighbor-based system, NN (NN5idf
F1 ),
small number KCCA-based systems different text kernels: BoW1 BoW5
use simple bag-of-words kernel. TagRank uses
Hwang Graumans (2012)

idf
kernel, Tri5 uses trigram kernel, Tri5Sem (Tri5A,DBNC+ic Appendix B) uses
872

fiFraming Image Description Ranking Task



idf-reweighted trigram kernel distributional alignment-based similarities.
exception BoW1, arbitrarily selected single caption
training image, models use five captions training images. BoW5,
merge single document. cases, follow Moschitti (2009)
sum kernel responses cross product sentences normalization.
systems (including NN) use pyramid kernel image representation.
large-scale evaluations Section 4.3, scores models given Appendix B.
systems use Hardoon et al.s (2004) KCCA implementation, allows us
vary regularization parameter . also vary n, number dimensions (largest
eigenvalues) learned projection allowable values parameters based
early exploratory experiments. experiments reported paper, sampled
4 possible values (0.1, 0.5, 1, 5), n chosen 46 possible values range
(10, 6000). two additional parameters fixed advance text
image kernel pair: image kernels either squared cubed, text kernels
regularized multiplying values diagonal factor range (1, 15).
kernel two tasks (image annotation search), use
development set pick five settings n maximize recall original
item first result, five settings maximize recall among first five results,
five settings maximize recall among first ten results, yielding total 15
different models pair kernels task. query image (annotation)
caption (search) test set, 15 models returns ranking 1,000 test
items (sentences images). combine 15 rankings, use Borda counts (van Erp &
Schomaker, 2000), simple, deterministic method rank aggregation: N items
ranked, system assigns score N r item ranks position r = 0...N 1,
final rank item determined sum scores across systems.
break ties items median ranks across models.
4.2 Metrics Quality Individual Image-Caption Pairs
consider metrics consider quality ranked list results (Section 4.3),
first examine metrics measure quality individual image-caption pairs.
4.2.1 Human Evaluation Graded Expert Judgments
Expert scores decision well caption describes image ultimately requires
human judgment. caption generation task, number different evaluation schemes
proposed image description: Ordonez et al. (2011) presented judges
caption produced model asked make forced choice random
image image caption produced for, Kuznetsova et al. (2012) asked judges
choose captions two models given test image. forced
choice tasks may give clear ranking models, cannot compared across different
experiments unless output system made publicly available. One advantage
framing image description ranking task different systems compared
directly test pool. Forced choice evaluations also directly measure
quality captions. Following common practice natural language generation, Yang
et al. (2011) Kulkarni et al. (2011) evaluated captions graded scale relevance
873

fiHodosh, Young & Hockenmaier

... describes image
without errors
(score = 4)

selected caption ...
... describes image
minor errors
(score = 3)

... somewhat
related image
(score = 2)

... unrelated
image
(score = 1)

girl wearing
yellow shirt
sunglasses smiles.

man climbs
sheer wall
ice.

Miami basketball
player dribbles
Arizona State player.

group people
walking city street
warm weather.

boy jumps
blue pool
water.

dog grassy field,
looking up.

Basketball players
action.

man riding motor
bike kicks dirt.

Dogs pulling
sled
sled race.

Two little girls
practice martial
arts.

snowboarder
air snowy
mountain.

child jumping
tennis court.

boy blue life
jacket jumps
water.

black dog
purple collar
running.

Figure 4: 14 rating scale fine-grained expert judgments, actual examples
returned best model (Tri5Sem)
readability, Li et al. (2011) added creativity score, Mitchell et al. (2012)
compared systems based whether captions describe main aspects images,
introduce objects appropriate order, semantically correct, seemed
written human.
Since captions test pool produced people, need evaluate
linguistic quality, focus semantic correctness. order obtain
fine-grained assessment description quality, asked three different judges score imagecaption pairs returned systems graded scale 1 4. judges 21
adult native speakers American English, mostly recruited among local graduate
student population. contrast anonymous crowdsourcing-based evaluation described
Section 4.3.2, refer experts. rating scale illustrated Figure 4
actual examples returned models. score 4 means caption describes
image perfectly (without mistakes), score 3 caption almost describes
image (minor mistakes allowed, e.g. number entities), whereas score
2 indicates caption describes aspects image, could
used description, score 1 indicates caption bears relation
image. online appendix paper contains annotation guidelines. Annotators
took average ten minutes per 50 image-caption pairs, image-caption pairs
judged independently three different annotators. Inter-annotator agreement, measured
Krippendorffs (2004) , high ( = 0.81) (Artstein & Poesio, 2008). final score
image-caption pair obtained averaging three individual scores. Since
time-consuming evaluation, judged highest-ranked caption
test image annotation task, focused subset models described
above. gauge difficulty task data set, also include random
baseline. Since evaluate single caption image, interested
percentage images suitable caption returned. therefore show
models cumulative distribution test items scores thresholds ranging
874

fiFraming Image Description Ranking Task

Quality first caption (image annotation)
Cumulative distribution expert scores (% X)
= 4.0 3.66 3.33 3.0 2.66 2.33 2.0
0.5 0.6
3.4 4.1
BoW1
6.6 8.1
BoW5
9.7
11.8
TagRank 9.6
12.3

0.7
5.2
9.9
13.6
14.2

1.1
8.5
18.3
19.8
21.1

1.5
11.4
22.9
24.7
25.8

2.9
16.3
29.7
33.0
32.9

7.8
27.1
44.2
46.9
46.2

Tri5Sem 11.0

15.7

23.0

28.1

36.9

53.0

Random
NN

13.3

Table 1: Cumulative distribution expert judgments 14 scale (Figure 4), indicating
percentage image-caption pairs judged given score. Scores
averaged three judges. Superscripts indicate statistically significant difference
Tri5Sem ( : p 0.1, : p 0.05, : p 0.01).
4.0 2.0. threshold interpreted less strict mapping
fine-grained scores binary relevance judgments. order assess whether difference
models given threshold reaches statistical significance, use McNemars
significance test, paired, non-parametric test advocated evaluation
binary classifiers (Dietterich, 1998). Given output models B
set items, McNemars test considers items Bs output differ (the
discordant pairs output) test null hypothesis outputs drawn
underlying population. Among discordant pairs, compares proportion
items model successful model B proportion items
Model B successful model not. results tables, superscripts indicate
whether difference model Tri5Sem statistically significant ( : p 0.1,
: p 0.05, : p 0.01) .
Expert results (Table 1) first interpret expert scores binary relevance
judgments, therefore show cumulative distribution different thresholds in.
see clear differences random baseline, NN, KCCA models
thresholds. differences NN random model, well
KCCA model NN highly significant (p < 0.001) threshold. random
baseline returns perfect caption 0.5% images, good caption (assuming
threshold 2.66) 1.5% images, best KCCA model, Tri5Sem, returns
perfect caption 11.0% good caption 28.1% images. However,
differences among KCCA models subtle, may become apparent
lower thresholds. significant difference BoW5 TagRank
threshold, significantly better BoW1 (p < 0.001) thresholds
3.33 above. Tri5Sem outperforms models, differences BoW5
TagRank reach statistical significance threshold considered
suitable caption lowered either 3.33 (p = 0.06) 3.0 (p = 0.01), 2.66 (p = 0.08)
2.33 (p = 0.005). lack statistical significance partially explained
fact McNemars test relatively low power percentage items
two models successful low, case higher thresholds here.

875

fiHodosh, Young & Hockenmaier

show Sections 4.3.1 4.3.2 significant difference
Tri5Sem two models image annotation extend analysis
beyond highest-ranked caption. shows evaluations based
single caption returned per image may fail uncover significant differences models
become apparent multiple results considered. may also important
consider performance annotation retrieval. image retrieval task,
see Tri5Sem significantly outperforms models even first
result considered. Table 1 also reveals another artefact McNemars test: since
based absolute differences performance number discordant pairs,
difference BoW1 Tri5Sem thresholds 2.66 2.0 considered less
significant BoW5 Tri5Sem thresholds, even though
BoW1s scores lower BoW5s. Table 2, present systems average expert
scores, use Fishers Randomization Test determine statistical significance. According
evaluation, Tri5Sem significantly better models (p 0.0001
cases), since average score Tri5Sem 2.08, difference reflected
higher thresholds cumulative distribution shown Table 1.
4.2.2 Automatic Evaluation Bleu Rouge
Since human judgments expensive time-consuming collect, examine
well approximated Bleu (Papineni et al., 2002) Rouge (Lin, 2004),
two standard metrics machine translation summarization.
Bleu Rouge scores Bleu Rouge scores computed automatically
number reference captions, used evaluate number caption
generation systems (Kulkarni et al., 2011; Ordonez et al., 2011; Li et al., 2011; Kuznetsova
et al., 2012; Yang et al., 2011; Gupta et al., 2012), although unclear well
correlate human judgments task.
Given caption image associated set reference captions Ri ,
Bleu score proposed image-caption pair (i, s) based n-gram precision
Ri , Rouge based corresponding n-gram recall. common
image description, consider unigram-based scores (only 3.5% possible imagecaption pairs test non-zero bigram-based Bleu-2 score, 39.4% set
non-zero Bleu-1 score). also ignore Bleus brevity penalty, since data set
relatively little variation sentence length, would like avoid penalizing short,
generic captions include details otherwise correct. Hence, cs (w)
number times word w occurs s:
P

Bleu(i, s) =
Rouge(i, s)

=

min(cs (w),maxrRi cr (w))
P
ws cs (w)
P
P
min(cs (w),cr (w))
rRi
P wrP
rR
wr cr (w)
ws

(28)



reference candidate captions preprocessed. first tokenize sentences
OpenNLP5 tools. break hyphenated words, stripping non-alphanumeric
5. http://opennlp.apache.org

876

fiFraming Image Description Ranking Task

Avg. score first caption
(image annotation)
Expert

Bleu


Rouge

BoW1
BoW5
TagRank

1.22
1.57
1.90
1.98
1.99

0.31
0.35
0.43
0.46
0.46

0.04
0.11
0.14
0.15
0.15

Tri5Sem

2.08

0.48

0.17

Random
NN



Table 2: Comparison averaged scores according 4-point expert evaluation (Figure 4), Bleu Rouge, using five test captions reference. Superscripts indicate
statistically significant difference Tri5Sem ( : p 0.1, : p 0.05, : p 0.01).
hyphen characters, converting words lower case. Following work Lin
(2004), use stemmer (Porter, 1980) remove stopwords compute Rouge
scores. compute Bleu Rouge score system average Bleu
Rouge scores items test set.6
use Fishers Randomization Test (Fisher, 1935; Smucker, Allan, & Carterette, 2007)
assess statistical significance difference models. paired,
sampling-based test evaluates null hypothesis results models
B produced underlying distribution. sample, scores
B assign test item randomly reassigned two models, p-values
obtained comparing actual difference Bs performance
fraction samples equal greater difference models. sample 100,000
reassignments entire test set.
Bleu Rouge results (Table 2) Table 2 shows average Bleu Rouge scores
highest ranked caption pairs returned image annotation systems, computed
reference pool consisting five original captions test image (including
caption randomly selected part candidate pool). scores
lead broad conclusions average expert scores: metrics find clear
differences (p < 0.0001) random baseline models,
well NN KCCA models, none find significant difference
BoW5 TagRank. Tri5Sem outperforms KCCA models according
metrics, expert evaluation Rouge find much larger difference
BoW5 (Experts: p 0.0001, Rouge: p < 0.001) TagRank (Experts: p = 0.001,
Rouge: p = 0.005). Bleu finds significant difference TagRank (p < 0.05),
BoW5 (p < 0.05), indicates Bleu may less well suited identify
subtle differences systems.
Agreement Bleu Rouge expert scores Since difficult measure
directly well Bleu Rouge scores agree expert judgments, consider
6. systems Bleu score usually computed corpus level, since dealing
unigram scores evaluate systems sentences corpus, averaged sentence-level
Bleu scores systems report almost identical (r > 0.997) corpus-level Bleu scores.

877

fiHodosh, Young & Hockenmaier

number different relevance thresholds type score (B , R , E ), turn
binary relevance judgments. allows us use Cohens (1960) measure
agreement corresponding binarized scores. Since Bleu Rouge
require set reference captions test image, compare four different ways
defining set reference captions (for detailed scores, see Tables 8 9 appendix).
Since data set contains multiple descriptions image, first use five
captions reference. setting, Bleu reaches best agreement ( = 0.72)
E = 4.0 B = 1.0 E 3.6 B 0.8. However, high Bleu
scores generally obtained system proposes original caption. Rouge
much lower agreement ( = 0.54) expert scores, obtained R 0.4 vs.
E 4.0 E 3.6, R 0.3 E 3.0. Since data sets may
one caption per image, also evaluate reference corpus consists
single caption test pool. case, metrics reach highest
agreement expert threshold E = 4.0 (Bleu: = 0.71, Rouge: = 0.69),
thresholds B 0.8, R 0.9. conclude neither Bleu Rouge
useful scenario, since require high thresholds capture
often system returned reference caption.
Bleu Rouge used evaluate caption generation systems, cannot
assume generated caption identical one reference captions. therefore
examine extent Bleu Rouge scores agree human judgments
candidate pool contains human generated captions, disjoint reference captions. first use reference corpus four captions per image, excluding caption
use candidate pool. case, three metrics show significantly lower agreement
human judgments candidate pool contains reference caption. Bleu
reaches = 0.52 (with B 0.7 E 3.3) Rouge reaches = 0.51
(with R 0.2 E 2.6). simulate case single caption per
image available, also evaluate reference corpus consisting one
four captions. case, agreement human judgments even lower: Bleu reaches
= 0.36, Rouge reaches = 0.42. results suggest Bleu Rouge
appropriate metrics pool candidate captions contain reference
captions, lead us question usefulness evaluation caption generation
systems. consistent findings Reiter Belz (2009), studied
Bleu Rouge scores evaluate natural language generation systems, concluded
may useful metrics fluency, poor measures content quality.
4.3 Metrics Large-Scale Evaluation Image Description Systems
Metrics consider first caption returned image cannot capture fact
better model score good captions higher captions, even fails
consider best possible caption. Since systems return ranked list results
item, examine metrics allow us evaluate quality list.
contrast human evaluations described Section 4.2 above, also evaluate
image retrieval systems. first consider metrics computed automatically:
recall median rank item (image sentence) originally associated
query sentence image (Section 4.3.1). show use crowdsourcing

878

fiFraming Image Description Ranking Task

Performance: Rank original item
R@k: percentage queries original item among top X responses.
Median r: median rank original item
R@1

Image annotation
R@5 R@10 Median r

BoW1
BoW5
TagRank
Tri5

2.5
4.8
6.2
6.0
7.1

7.6
13.5
17.1
17.0
17.2

9.7
19.7
24.3
23.8
23.7

Tri5Sem

8.3

21.6

30.3

NN

251.0
64.0
58.0
56.0
53.0
34.0

R@1

Image retrieval
R@5 R@10 Median r

2.5
4.5
5.8
5.4
6.0

4.7
14.3
16.7
17.4
17.8

7.2
20.8
23.6
24.3
26.2

7.6

20.7

30.1

272.0
67.0
60.0
52.5
55.0
38.0

Table 3: Model performance measured rank original image caption (=
correct response). R@k: percentage queries correct response among
first X results. Median r: Median position correct response ranked list
results. Superscripts indicate statistically significant difference Tri5Sem ( : p 0.05,
: p 0.01).
collect large number human judgments (Section 4.3.2), use relevance
judgments define two additional metrics: rate success, akin recall,
R-precision, established information retrieval metric (Section 4.3.3). Although
metrics allow us evaluate systems, focus discussion small set
systems considered far, refer interested reader Section B appendix
scores systems.
4.3.1 Recall Median Rank Original Item
One advantage ranking framework position original caption image
among complete list 1,000 test items determined automatically. Since better
system should, average, assign higher rank original items worse system,
use ranks define number different evaluation metrics.
Recall (R@k) median rank scores Since query associated
single gold result, need concerned precision. However, recall position k
(R@k), i.e. percentage test queries model returns original item among
top k results, useful indicator performance, especially context search,
user may satisfied first k results contain single relevant item. focus
k = 1, 5, 10 (R@1, R@5, R@10). Since binary metric (for query, gold item
either found among top k results not), use McNemars test identify
statistically significant differences models. Conversely, median rank indicates
k system recall 50% (i.e. number results one would
consider order find original item half queries). Here, use Fishers
randomization identify significant differences models.
Recall (R@k) median rank results (Table 3) results Table 3 confirm
earlier observation NN baseline clearly beaten KCCA models (p < 0.001
metrics models, except R@1 search, difference BoW1
879

fiHodosh, Young & Hockenmaier

p-value p < 0.01). Since R@1 annotation scores based image-caption
pairs expert scores Table 1, compare directly. difference
R@1 expert scores, even strictest threshold 4.0 experts, indicates
measures capture often original caption returned viewed
lower bound actual performance: Tri5Sem returns original caption first
8.3% images, human judges found captions describe 11.0%
images without errors. discrepancy even larger BoW5 (6.2% vs. 9.7%)
TagRank (6.0% vs. 9.6%). consequence, automatically computed R@1 scores
indicate erroneously statistically significant difference quality
first captions returned Tri5Sem returned BoW5 TagRank, even
though differences significant according human evaluation. However,
metrics based first caption may fail identify differences
models become apparent metrics. example, R@1 reveals
significant difference Tri5 Tri5Sem annotation task, although
difference highly significant according metrics. Section 4.3.3, present
results large-scale human evaluation confirm actual differences
Tri5Sem Tri5 annotation identified first caption
taken account.
Table 11 Section B provides recall median rank scores models.
4.3.2 Collecting Binary Relevance Judgments Large Scale
order perform human evaluation system goes beyond measuring quality
highest ranked result, would obtain relevance judgments imagecaption pairs among top k results query. Since two tasks,
total 30 different systems, set consists 113,006 distinct image-caption pairs
k = 10, rendering exhaustive evaluation four-point scale described Section 4.2.1
infeasible. therefore needed reduce total number judgments needed,
define simpler annotation task could completed less time. Crowdsourcing
platforms Amazon Mechanical Turk offer new possibilities evaluation
enable us collect large number human judgments rapidly inexpensively,
number researchers evaluated caption generation systems Mechanical Turk
(Ordonez et al., 2011; Yang et al., 2011; Kuznetsova et al., 2012; Kulkarni et al., 2011; Li
et al., 2011). experiments performed scale analysis,
also evaluated well crowdsourced judgments task approximate
obtained smaller pool judges given detailed instructions.
examine whether crowdsourcing allows us collect reliable relevance judgments
large scale evaluation image description systems.
crowdsourcing task presented workers images paired ten
different captions, asked indicate (via checkboxes) captions describe
image. adapted guidelines developed fine-grained annotation
caption describes image minor errors (corresponding score 3
4-point scale) would still permitted receive positive score. guidelines also
found online appendix paper. individual task consisted six different
images, paired ten captions, included copy guidelines. accessed
880

fiFraming Image Description Ranking Task

Amazon Mechanical Turk service provided Crowdflower.com, makes
easy include control items quality control. One six images task
control item, generated taking random images development
set, using one three original captions correct responses, adding
another nine seven randomly selected captions (which verified manually
describe image) incorrect responses. used workers judged 70%
control items correctly. image-caption pair annotated three different
annotators (at total cost 0.9), final score image-caption pair
computed average number positive judgments received.
Filtering unlikely image-caption pairs order reduce number annotations
needed, devised filter based Bleu scores (Papineni et al., 2002) filter imagecaption pairs whose caption dissimilar five captions originally written
image highly unlikely describes image. found filter based
unigram Bleu-1 scores combination stemming stop word removal
standardly done Lins (2004) Rouge script (Bleupre ) proved particularly effective:
threshold Bleupre 0.25 filters 86.0% possible (1,0001,000) image-caption
pairs test set, eliminates 6.7% pairs expert score 2 32
greater, 3.5% pairs expert score 3 greater. slightly higher cutoff
Bleupre 0.26 would filter 90.4% image caption pairs, discard 12.3%
image-caption pairs expert score 2 23 7.5% image-caption pairs
expert score 3. Among 113,006 image-caption pairs actually wished
obtain judgments for, 0.25 filter eliminates 72.8%, reducing number pairs
needed annotate 30,781. Since setup required us pair image number
captions multiple 10, also annotated additional 10,374 image caption
pairs filtered out, allowing us evaluate performance filter.
98.3% filtered pairs, Mechanical Turk judges decided caption
describe image, 99.8% them, majority annotators thought so. also
found standard Bleu-1 without preprocessing effective filter: threshold
Bleu 0.330 misses 6.9% good captions (with expert score 2 23 ),
filtering 55% entire data set, whereas threshold Bleu 0.333 filters
65% entire data set, misses 11.9% good captions.
Agreement crowdsourced expert judgments use Cohens
measure agreement crowdsourced expert judgments (Table 10
appendix). best agreement obtained crowdsourced scores threshold
0.66 (i.e. least two three judges think caption describes image)
expert scores threshold 3.33 (one expert thinks caption describes
image perfectly two agree think describes image minor
errors, two experts think describes image perfectly one thinks
least related). = 0.79, significantly better approximation expert
scores possible either Bleu Rouge. also examine precision, recall
f-scores approximate relevance judgments achieve compared
relevance judgments obtained binarizing expert judgments (Table 10). 98.6%
items perfect expert score (and 95.0% items almost perfect expert
score 3.7) identified, least 94.7% items pass threshold
881

fiHodosh, Young & Hockenmaier

expert score 2.7 greater (i.e. majority experts agreed caption describes
image perfectly minor errors). Using threshold 0.66 adds 2,031 suitable
image-caption pairs 1,000 test images paired original caption. Among
1,000 test captions, 446 still describe single image, 202 describe two test images, 100
three, 252 describe four images. Among 1,000 test images, 331
single (i.e. original) caption, 202 two possible captions, 100 three possible
captions, 317 four captions.
4.3.3 Large-Scale Evaluation Relevance Judgments
crowdsourced relevance judgments allow us define two new metrics, rate
success (S@k) R-precision. believe R-precision reliable indicator
overall performance, since summarizes human judgments single number
depend arbitrary cutoff. therefore use Section 4.3.4 in-depth
analysis impact different linguistic features models incorporate. S@k
rate success scores motivated fact search engines commonly return multiple
results once. Since users may satisfied long results contain least one
relevant item, S@k scores provide direct measure utility hypothetical users.
Rate success (S@k) scores rate success metric (S@k) analogous
recall-based R@k-scores used Table 3, intended measure utility
system hypothetical user. indicates percentage test items least
one relevant result found among highest ranked k results. Following analysis
Section 4.3.2, image-caption pair considered relevant majority judges say
caption describes image.
Rate success results (Table 4) Table 4 confirms NN performs clearly
worse KCCA models. differences Tri5Sem
models shown Table 4 highly statistically significant (p < 0.001) metrics except
S@1 annotation scores, where, agreement expert scores Table 1,
differences NN BoW1 significant. unclear quality first
caption Tri5Sem returns annotation significantly better returned
models, since outperforms metrics. S@k scores
Table 4 indicate Tri5Sem returns relevant caption among top 10 responses
49.1% images, relevant image 48.5% captions. comparison
expert scores Table 1 shows S@1 annotation scores lie expert scores
threshold 3.66 3.0, comparison R@k results Table 3 shows
S@1 scores least twice high corresponding R@1 scores. is,
highest ranked response often relevant item originally associated
query original gold item itself.
R-precision scores Given crowdsourced relevance judgments, test image may
associated multiple relevant captions, test caption may
deemed relevant multiple images besides one originally written for.
queries variable number relevant answers, performance retrieval systems
commonly measured terms R-precision (Manning, Raghavan, & Schtze, 2008). Unlike
S@k scores, metric depend arbitrary cutoff, summarizes
882

fiFraming Image Description Ranking Task

Rate success (S@k)
(Percentage items relevant response among top X results)
Image annotation
S@1
S@5
S@10

Image retrieval
S@1
S@5
S@10

BoW1
BoW5
TagRank
Tri5

5.8
12.2
15.0
16.2
16.4

15.4
30.3
34.1
34.2
32.9

20.2
39.7
42.7
42.9
43.4

5.0
11.4
12.1
12.4
13.1

13.3
30.5
31.5
31.5
33.1

18.4
40.2
40.8
41.6
43.8

Tri5Sem

16.6

37.7

49.1

15.7

36.9

48.5

NN

Table 4: rate success (S@k) indicates percentage test items top X
results contain least one relevant response. Superscripts indicate statistically significant
difference Tri5Sem ( : p 0.1, : p 0.05, : p 0.01)
R-precision
Annotation
NN



Search


Total

BoW1
BoW5
TagRank
Tri5

5.2
10.7
11.1
11.7
11.6

3.8
9.6
10.5
10.5
11.0

4.5
10.1
10.8
11.1
11.3

Tri5Sem

13.7

13.4

13.5

Table 5: Model performance measured R-precision, statistically significant differences Tri5Sem ( : p 0.1, : p 0.05, : p 0.1)
performance system single number, allowing us rank models according
overall performance (see Section 4.3.4 below). S@k scores measure
whether least one relevant items ranked highly, R-precision requires relevant
items ranked highly. therefore better indicator quality mapping
images sentences, since better mapping prefer relevant captions
images irrelevant caption image.
R-precision system query qi ri known relevant items test data
defined precision rank ri (i.e. percentage relevant items among top ri
responses returned s). R-precision obtained averaging test queries.
use Fishers randomization test assess whether differences models
reaches statistical significance.
R-precision results (Table 5) Table 5 gives R-precision model types
used collecting expert judgments (Section 4.2.1). see nearest neighbor
baseline clearly KCCA models (p < 0.001). R-precision indicates
little difference BoW1, BoW5 TagRank terms overall performance. Although TagRank Tri5 outperform BoW1 slightly search (p = 0.062),
statistically significant difference among three models BoW1
Tri5 search (p = 0.01). contrast human evaluation considered
883

fiHodosh, Young & Hockenmaier

R-precision

Tri5
Ann. Search

+IDF
Ann. Search

Ann.

+Align
Search

+Align&IDF
Ann. Search

Tri5

11.6

11.0

12.5ii

11.3

13.4aaa

12.3aa

13.4a

13.2aaa,ii

+DBNC
+Dic
+DBNC+ic

12.7dd
12.7dd
12.5dd

12.1dd
12.8ddd
12.7ddd

12.9
12.8
13.3d

12.2ddd
13.1ddd
13.0ddd

13.2
13.0
13.4aa

12.8a
12.8
13.2dd

12.9
13.3
13.7

12.9a
13.4
13.4

Table 6: effect adding IDF weighting (i), alignment-based similarities (a) distributional similarities (d) Tri5 model. bolded scores indicate Tri5 (top left)
Tri5Sem (Tri5 +Align&IDF+DBNC+ic ; bottom right). Superscripts indicate statistically
significant differences result addition corresponding feature (x : p 0.1,
xx : 0.05, xxx : p 0.01). Dc = distributional similarities computed corpus c (the
BNC, training corpus image captions (ic), both)
first result (Table 1), Tri5Sem clearly outperforms models annotation
retrieval (for differences p 0.0001). Table 12 Appendix B shows scores
models.
4.3.4 Measuring Impact Linguistic Features (Table 6)
results presented far indicate clearly Tri5Sem outperforms simpler Tri5
model, considered impact individual text features distinguish
two models. Since R-precision summarizes performance system single
number, allows us easily perform analysis.
Using R-precision model comparison Table 6 shows results ablation
study compares R-precision Tri5 Tri5Sem trigrambased KCCA models use subset Tri5Sems additional features. basic Tri5
model yields bolded scores shown top left corner. Tri5Sems scores given
bottom right corner. top row contains models capture distributional
similarities, bottom three rows corresponds addition one kind
distributional similarity (computed BNC, image captions training
corpus, corpora) corresponding model top column. first column
contains models capture IDF reweighting alignment-based similarities.
second column corresponds addition IDF reweighting models first
column, third column adds alignment-based similarities models first
column. last column adds IDF-reweighting alignment-based similarities,
scores compared second third column. Superscripts indicate addition particular feature leads statistically significant improvement
model include feature otherwise identical. is,
superscripts show addition distributional similarity metric leads significant improvement model top cell column. superscripts
indicate addition IDF reweighting leads significant improvement
corresponding model without IDF reweighting immediately preceding cell

884

fiFraming Image Description Ranking Task

row. superscripts third column show addition alignment-based
similarity leads significant improvement model without IDF reweighting shown
first column row, superscripts fifth column show
addition alignment-based similarity model IDF reweighting shown
second column row leads significant improvement.
impact IDF weighting, distributional alignment-based similarities
IDF weighting almost always beneficial, improvements obtained adding
IDF weighting given text kernel reach statistical significance (indicated superscripts Table 6) two cases: performance basic Tri5 model image
annotation, performance alignment-based Tri5 model image search.
contrast, adding lexical similarities leads almost always significant highly significant
improvement. Distributional similarities (d superscripts) beneficial basic
Tri5 model tasks, help IDF weighted Tri5 model image search. Distributional similarities computed corpora also significantly improve performance
alignment-based Tri5 model incorporate IDF weighting. Adding
alignment-based Tri5 model without IDF weighting leads improvement
search (while helping slightly decreasing performance annotation, albeit
significantly so). improvements search reach statistical significance
similarities computed corpora added. Conversely, adding alignment-based
similarities non-IDF weighted Tri5 model distributional similarities
corpora leads significant improvement annotation. Finally, top cell last
column shows adding alignment-based similarities IDF-weighted Tri5 model
leads significant improvement tasks, although impact search even
greater. Comparing models performance alignment-based Tri5 model without
IDF weighting shows case, IDF weighting helps search. bottom
cells column show adding alignment-based similarities models already
use IDF weighting distributional similarities, adding IDF weighting models
distributional alignment-based similarities generally lead minor improvements.
Table 6 shows whether difference performance obtained addition
one kind feature reaches statistical significance, worth noting model
captures lexical similarities kind significantly better basic Tri5
model tasks (p 0.02 search; p < 0.0001 annotation), IDF-reweighting
leads significant improvement annotation task (p < 0.03). Moreover,
difference Tri5Sem (13.7 search; 13.4 annotation) basic Tri5 kernel
IDF-reweighting (12.5 search; 11.3 annotation) highly significant (p < 0.03 search;
p < 0.0001 annotation).
impact Lins similarity shown Table 6 performance Tri5Lin ,
model augments trigram kernel Lins (1998) WordNet-based similarity.
Tri5Sem include Lins similarity, since found development Tri5Lin
performed similarly worse basic Tri5 model automatic R@k median
rank scores. also reflected Tri5Lin R-precision scores 11.7 annotation (Tri5:
11.6) 10.7 search (Tri5: 11.0). Lins similarity may simply coarse
purposes. shown Table 3, hypernym relations WordNet lead associate terms
swimming football other. even though semantically
885

fiHodosh, Young & Hockenmaier

Correlation system rankings
S@k R@k
Annotation


@1
@5
@10

0.86
0.92
0.96

0.69
0.76
0.82

Correlation system rankings
R-precision

Search


0.97
0.97
0.97

(a) S@k vs. R@k

0.87
0.88
0.87

Annotation


R@1
R@5
R@10
Median rank

0.85
0.93
0.94
-0.92

0.68
0.78
0.79
-0.79

Search


0.94
0.96
0.97
-0.97

0.83
0.87
0.89
-0.89

(b) R-precision vs. R@k median rank

Table 7: Correlation (Spearmans Kendalls ) system rankings obtained
human metrics (S@k R-precision) automated scores (R@k median rank)
related fact different kinds sports activities, visually
dissimilar, considered related systems.
4.3.5 Human Evaluations Approximated Automatic Techniques?
R-precision S@k scores require human judgements, therefore cannot applied
datasets judgements yet collected whose scale may prohibit
ever creating definitive set judgements. However, evaluation intended measure
relative progress image description rather absolute performance, automatic
metrics may sufficient approximation, since yield similar ranking systems
R-precision S@k scores. Table 7(a) shows correlations rankings
NN KCCA systems (n = 30) obtained S@k scores obtained
corresponding R@k scores. Table 7(b) shows correlations R-precision
automatic metrics. report two rank correlation coefficients, Spearmans
Kendalls . first observe system rankings obtained via R@1 correlate highly
either R-precision S@1 based rankings. hand, also observe
R@5, R@10, median rank scores correlate well R-precision R@5
R@10 correlate well corresponding S@k metrics. suggests rankingbased metrics significantly robust metrics consider quality
first result. Moreover, results indicate framework, systems
expected rank pool images sentences written people, may enable large-scale,
fully automated, evaluation image description systems require equally
large-scale effort collect human judgments.

5. Summary Contributions Conclusions
paper, proposed frame image description task selecting ranking
descriptions among large pool descriptions provided people, framework
provides direct test purely semantic aspects image description need
concerned difficulties involved automatic generation syntactically
correct pragmatically appropriate sentences. also introduced new data set
images paired multiple captions, used data set evaluate number
nearest-neighbor KCCA-based models sentence-based image annotation well
886

fiFraming Image Description Ranking Task

converse task sentence-based image search. experiments indicate importance
capturing lexical similarities. Finally, performed in-depth analysis different
evaluation metrics image description.
5.1 Advantages Framing Image Description Ranking Task
One main motivations framing image description ranking rather
generation problem question objective, comparable evaluation ability
understand depicted images. order make progress challenging
task, important define tasks evaluation metrics allow objective
comparison different approaches. argued task ranking pool
captions written people attractive number reasons: first, results obtained
data set compared directly; second, human evaluation easier
generated captions since needs focus factual correctness description rather
grammaticality, fluency, creativity; third, statistically significant differences
systems may become apparent single caption per image considered;
finally, ranking makes possible automate evaluation, e.g. considering position
original caption. Moreover, framing image description ranking task also establishes
clear parallels image retrieval, allowing metrics used tasks.
5.2 Data Set
Flickr 8k data set 8,000 images, paired five crowdsourced captions,
unique resource image description. Although much smaller SBU corpus
(Ordonez et al., 2011), believe generic conceptual descriptions corpus
useful image understanding original Flickr captions SBU data set.
data set perhaps similar IAPR data set (Grubinger et al.,
2006), captions corpus shorter, focus salient aspects
image. focus images people animals, IAPR data set covers
slightly different domain, including city pictures landscape shots typically
depict focus people. distinct advantage corpus pairs image
multiple, independently written captions. results indicate using
single caption training time leads significant increase performance. also
shown use multiple captions define alignment-based lexical similarity
may useful image description standard distributional WordNet-based
similarities.
5.3 Models
paper first apply Kernel Canonical Correlation analysis (KCCA) sentencebased image description. results show KCCA significantly outperforms nearest
neighbor-based approaches data set 6,000 training images 1,000 test images
(although may scale better large data sets Ordonez et al.s (2011)
SBU corpus, memory requirements train KCCA may prohibitive). One
advantage KCCA-based approaches image description systems geared
specifically towards caption generation applied image de-

887

fiHodosh, Young & Hockenmaier

scription, also image retrieval, results indicate performance
tasks fairly similar.
important difference approach taken paper image
description systems features used models presented computed minimal supervision. feature relies supervised classifier
alignment-based similarity, uses POS-tagger identify nouns verbs. Despite
simplicity underlying features, models achieve relatively high performance,
considering difficulty task: Although 1.5% chance randomly
chosen test caption describe test image well, fine-grained human judgments reveal
image annotation, first caption returned best KCCA system good
description 28% test images. Furthermore, large-scale evaluation shows
best system, almost 50% chance suitable image caption
returned among first ten results. results indicate two main reasons
high performance: availability multiple captions image training
time, use robust text representations capture lexical similarities rather
requiring strict equality words. However, also clear task remains
far solved, leave question KCCA may benefit models
rely richer visual linguistic features detector responses rich syntactic
analyses future work.
5.4 Evaluating Ranking-Based Image Description Systems
main advantage framing image description ranking problem allows
direct comparison different approaches, since evaluated data set.
also makes possible borrow established evaluation metrics information retrieval,
use metrics data sets sentence-based image annotation image
search.
one hand, shown crowdsourcing used collect large number
binary judgments image-caption pairs relatively low price, crowdsourced judgments correlate well fine-grained judgments. able collect
human judgments large scale particularly important retrieval-based approaches
image description, since number relevance judgments need collected
test collection may significantly larger number judgments commonly
used evaluate single caption generation system. However, experiments image
annotation provided example human judgments first caption returned
test image reveal differences systems become apparent
results taken account. fine-grained evaluation also indicates evaluations
based single result may require potentially much larger number test items
order reveal robust statistically significant differences. Among human evaluation
metrics compared, believe R-precision computed crowdsourced
relevance judgments robust. R-precision standard metric evaluating
ranked retrieval results items varying number relevant responses, since
yields single score, also makes particularly easy compare systems. However,
S@k scores, measure percentage items top k responses contain
relevant result, perhaps direct measure useful system may prac-

888

fiFraming Image Description Ranking Task

tice. release crowdsourced relevance judgments collected order
enable others evaluate image description system data. hope
establish benchmark used direct fair large-scale comparison
arbitrary number image description systems.
hand, also shown framework systems evaluated ability rank pool images sentences may make possible perform
fully automated evaluation. Contrary current practice, analysis indicates clearly
standard metrics Bleu Rouge reliable indicators
well captions describe images, even Bleu Rouge-style preprocessing used
effective filter implausible image-caption pairs. Although consider humangenerated captions, stipulate similar observations may hold automatically generated captions, since similar criticisms Bleus appropriateness generation
machine translation evaluation well known (Reiter & Belz, 2009; Callison-Burch, Osborne, & Koehn, 2006). However, ranking-based framework test query associated
gold response originally associated with, results indicate
metrics based rank gold item lead similar conclusions human judgments. suggest evaluation ranking-based image description task
automated, performed potentially much larger scale examined here.
5.5 Implications Evaluation Caption Generation Systems
Image description can, should, also treated problem natural language
generation community. automatically generating captions indistinguishable
captions written people (an evaluation criterion used Mitchell et al. (2012)
comparison caption generation systems) requires much ability
provide factually correct information image. believe linguistic
issues need solved generation setting need evaluated separately
ability decide whether given caption describes image. unclear kinds
evaluations performed e.g. Mitchell et al. could ever automated, since question
natural automatically produced caption seems may always require human judgment.
human experiments expensive, since system generates captions,
judgments collected anew system experiment. Since
consensus constitutes good image description, independently obtained human
assessments different caption generation systems compared directly.
means direct comparison systems, e.g. performed Mitchell et al., typically
possible within one research group, since common data set different
system outputs publicly available. Although automatic scores Bleu Rouge
may still useful caption generation measures fluency (Reiter & Belz, 2009),
shown reliable metrics well caption describes image,
especially candidate pool disjoint reference captions. suggests
evaluation syntactic pragmatic aspects caption generation task
automated, may rely human judgments. However, may
possible use framework proposed paper evaluate semantic affinity
functions f (i, s) implicitly used caption generations systems.

889

fiHodosh, Young & Hockenmaier

Acknowledgments
gratefully acknowledge support project National Science Foundation
IIS Medium grant 0803603, CAREER award 1053856, CNS-1205627 CI-P.

Appendix A. Agreement Approximate Metrics Expert
Human Judgments
Tables 8 9 use Cohens Kappa () measure agreement Bleu Rouge
scores expert judgments. selected thresholds yield optimal results.
Table 10 (a) shows agreement crowdsourced judgments expert
judgments. Since best agreement expert scores obtained crowdsourced
judgments using threshold 0.6, Table 10 (b) measures precision recall resulting binary relevance judgments binarized expert judgments obtained varying
thresholds.

Appendix B. Performance Systems
following tables give results models. Section 4 body paper, NN
idf
corresponds NN5idf
F1 , Tri5Sem corresponds Tri5A,DBNC+ic .
R@k median rank scores Table 11 gives recall median rank original
item (Section 4.3.1) models.
Agreement expert Bleu/Rouge scores (Cohens )
Case 1: Scand Sref
5 reference captions/test image (Scand Sref ; R5 )
Expert
E

0.9

Bleu B
0.8
0.7

0.4

Rouge R
0.3
0.2

=4.0
3.6
3.3
3.0
2.6

0.72
0.71
0.64
0.45
0.35

0.70
0.72
0.67
0.54
0.45

0.54
0.54
0.50
0.45
0.38

0.47
0.50
0.50
0.54
0.51

0.59
0.61
0.63
0.57
0.51

0.29
0.33
0.37
0.49
0.53

1 reference caption/test image (Scand = Sref ; R1 (gold))
Expert
E

0.8

Bleu
0.6 0.5

0.9

=4.0
3.6
3.3
3.0
2.6

0.71
0.68
0.60
0.41
0.32

0.70
0.68
0.59
0.42
0.32

0.69
0.65
0.57
0.39
0.30

0.52
0.56
0.56
0.48
0.42

Rouge
0.7 0.3
0.67
0.64
0.56
0.40
0.32

0.35
0.39
0.40
0.45
0.43

Table 8: Agreement (Cohens ) binarized expert Bleu/Rouge scores
pool candidate captions contains test images reference caption(s).

890

fiFraming Image Description Ranking Task

Agreement expert Bleu/Rouge scores (Cohens )
Case 2: Scand 6 Sref
4 reference captions/ test image (R4 )
Expert
E

0.7

Bleu
0.6 0.5

0.4

Rouge
0.3 0.2

=4.0
3.6
3.3
3.0
2.6

0.50
0.51
0.52
0.47
0.41

0.40
0.43
0.46
0.48
0.47

0.44
0.43
0.40
0.39
0.33

0.40
0.43
0.44
0.50
0.48

0.23
0.28
0.32
0.41
0.44

0.26
0.30
0.34
0.47
0.51

1 reference caption/test image (R1 (other))
Expert
E

0.5

Bleu
0.4 0.3

0.4

Rouge
0.3 0.2

=4.0
3.6
3.3
3.0
2.6

0.33
0.34
0.34
0.32
0.30

0.27
0.29
0.32
0.36
0.35

0.33
0.34
0.35
0.39
0.37

0.30
0.32
0.35
0.42
0.41

0.16
0.19
0.22
0.29
0.31

0.18
0.21
0.24
0.34
0.38

Table 9: Agreement (Cohens ) binarized expert Bleu/Rouge scores
pool candidate captions may contain test images reference caption(s).

Agreement expert
lay scores (Cohens )
Expert
E
=4.0
3.6
3.3
3.0
2.6

=1.0
0.75
0.78
0.74
0.56
0.45

Lay vs. expert
relevance judgments (L = 0.66)

Lay L
0.6 0.3
0.69
0.76
0.79
0.71
0.62

0.49
0.57
0.65
0.74
0.73

(a) Agreement (Cohens ) relevance judgments obtained expert
scores (relevance = score E ) lay
scores (relevance = score L )

E

Precision

Recall

F1

=4.0
3.6
3.3
3.0
2.6
2.3

55.9
65.4
75.2
90.0
94.7
98.2

98.6
95.0
88.0
64.7
53.4
40.1

71.4
77.5
81.1
75.3
68.3
57.0

(b) Precision, recall, F1 scores binarized lay scores (L = 0.66)
binarized expert scores varying
thresholds E .

Table 10: Comparing relevance judgments obtained lay scores
obtained expert scores

891

fiHodosh, Young & Hockenmaier

S@k R-precision scores Table 12 gives S@k success rate (Section 4.3.3)
R-precision scores (Section 4.3.3) models, based crowdsourced human
judgments (Section 4.3.2).

892

fiFraming Image Description Ranking Task

Performance models (automatic evaluation)
(R@k: percentage queries original item top X results
Median r: median rank original item)
R@1

Image annotation
R@5 R@10 Median r

R@1

Image search
R@5 R@10 Median r

NN5F1
NN5idf
F1
NN5BoW5
NN5Tri(best)

1.9
2.5
2.1
2.1

5.9
7.6
5.9
5.9

8.7
9.7
9.6
9.4

251.0
251.0
258.5
248.0

2.1
2.5
2.8
2.3

5.2
4.7
6.4
6.1

7.1
7.2
9.1
9.0

278.0
272.0
266.0
240.0

BoW1
Tri1

4.8
4.6

13.5
14.4

19.7
21.0

64.0
68.0

4.5
4.5

14.3
14.0

20.8
22.5

67.0
71.0

BoW5Histo
BoW5
BoW5idf

BoW5 idf
TagRank

5.9
6.2
6.1
6.1
6.0

14.9
17.1
17.0
17.3
17.0

21.2
24.3
23.2
23.9
23.8

69.0
58.0
60.5
56.0
56.0

4.8
5.8
6.4
6.1
5.4

14.2
16.7
16.5
16.9
17.4

20.8
23.6
24.5
24.5
24.3

74.0
60.0
59.5
60.5
52.5

Tri5Histo
Tri5

6.0
7.1

15.0
17.2

21.7
23.7

63.5
53.0

5.7
6.0

14.5
17.8

22.1
26.2

67.0
55.0

Tri5Lin
Tri5DBNC
Tri5Dic
Tri5DBNC+ic

6.2
7.5
7.0
7.3

16.7
19.8
19.5
20.0

23.7
26.1
27.1
27.0

53.5
40.0
36.0
36.0

6.0
7.2
7.0
6.9

16.7
18.4
19.3
19.2

24.4
27.4
27.5
28.0

61.0
44.5
41.0
42.0

Tri5A
Tri5A,DBNC
Tri5A,Dic
Tri5A,DBNC+ic

7.2
7.9
6.9
7.6

20.2
20.3
20.2
20.7

28.0
28.4
29.5
30.0

41.0
39.0
35.0
35.0

6.8
7.8
7.3
7.4

18.5
19.0
19.9
19.4

27.7
27.4
28.7
29.2

41.5
39.0
39.5
38.0

7.6

18.8

25.1

46.0

6.2

18.0

26.5

52.0

6.8
7.3
6.7

18.7
20.4
20.0

28.9
27.5
28.9

40.0
38.0
35.0

6.7
8.1
7.0

18.2
19.1
19.7

27.6
28.4
28.8

45.0
40.5
39.0

7.3
7.5
7.2

21.1
21.3
20.8

28.3
30.0
29.6

37.0
38.0
34.0

7.5
7.8
7.4

19.2
18.9
21.4

28.7
29.0
30.1

38.0
41.5
37.5

idf,Histo
Tri5A,D
BNC+ic

6.5

18.0

26.7

45.0

6.0

18.0

24.2

48.5

idf
A,DBNC+ic

8.3

21.6

30.3

34.0

7.6

20.7

30.1

38.0



Tri5

idf



idf
Tri5
DBNC
idf
Tri5
Dic
idf
Tri5DBNC+ic


idf
Tri5A

idf
Tri5
A,DBNC
idf
Tri5A,D
ic



Tri5

Table 11: Performance models, measured percentage test items
original item returned among top 1, 5 10 results,
well median rank

idf
idf
original item. Section 4, NN5F1 = NN, Tri5A,DBNC+ic = Tri5Sem.

893

fiHodosh, Young & Hockenmaier

Performance models (human evaluation)
S@k: Percentage items relevant response among top X results
R-prec: R-precision computed relevant responses
S@1
NN5F1
NN5idf
F1
NN5BoW5
NN5Tri(best)

Image annotation
S@5 S@10 R-prec.

S@1

Image search
S@5 S@10 R-prec.

4.9
5.8
6.4
7.2

13.3
15.4
14.8
17.4

19.1
20.2
20.6
23.1

4.2
5.2
5.4
6.2

4.9
5.0
5.7
4.4

13.2
13.3
13.4
13.5

17.8
18.4
18.4
19.8

3.8
3.8
4.6
4.3

BoW1
Tri1

12.2
12.8

30.3
32.2

39.7
40.2

10.7
10.5

11.4
12.2

30.5
30.6

40.2
41.5

9.6
9.9

BoW5Histo
BoW5
BoW5idf

BoW5 idf
TagRank

13.9
15.0
13.9
15.0
16.2

29.8
34.1
32.7
34.0
34.2

39.6
42.7
42.4
42.7
42.9

9.9
11.1
11.0
11.3
11.7

11.5
12.1
13.3
12.9
12.4

28.0
31.5
30.8
31.3
31.5

38.1
40.8
41.8
41.0
41.6

9.3
10.5
10.6
10.7
10.5

Tri5Histo
Tri5

15.0
16.4

29.0
32.9

38.9
43.4

9.9
11.6

12.9
13.1

28.9
33.1

39.9
43.8

10.5
11.0

Tri5Lin
Tri5DBNC
Tri5Dic
Tri5DBNC+ic
Tri5A
Tri5A,DBNC
Tri5A,Dic
Tri5A,DBNC+ic

15.5
16.8
15.8
16.4
17.3
16.6
15.8
16.4

34.1
37.4
36.7
37.2
36.9
36.5
37.0
37.4

43.8
45.5
47.0
47.1
47.4
47.4
48.2
48.3

11.7
12.7
12.7
12.5
13.4
13.2
13.0
13.4

12.7
14.5
14.5
14.8
14.3
15.3
15.2
15.4

32.5
35.3
36.6
36.3
35.4
35.0
37.4
37.0

41.7
44.9
46.1
45.8
46.6
45.8
47.6
46.8

10.7
12.1
12.8
12.7
12.3
12.8
12.8
13.2

16.9

35.4

44.2

12.5

13.0

33.4

43.9

11.3

16.1
15.9
16.2

36.0
36.9
37.4

47.5
46.8
47.5

12.9
12.8
13.3

15.0
16.0
15.3

34.0
35.8
34.8

44.6
47.5
46.7

12.2
13.1
13.0

17.4
15.7
15.7

37.6
36.9
37.3

46.3
48.1
47.3

13.4
12.9
13.3

15.8
15.8
15.5

36.3
35.3
38.3

47.3
47.2
47.8

13.2
12.9
13.4

13.6

30.6

41.9

11.1

14.4

33.8

42.7

12.2

16.6

37.7

49.1

13.7

15.7

36.9

48.5

13.4

Tri5
Tri5
Tri5
Tri5
Tri5
Tri5
Tri5
Tri5
Tri5


idf

idf

BNC
idf

ic
idf
DBNC+ic

idf


idf
A,D
BNC
idf
A,Dic

idf,Histo
A,DBNC+ic

idf
A,DBNC+ic

Table 12: Performance models, measured percentage test items
return item deemed relevant according crowdsourced judgments
among top 1, 5 10 results,
R-precision computed judgments.

idf
idf
Section 4, NN5F1 = NN, Tri5A,DBNC+ic = Tri5Sem.

894

fiFraming Image Description Ranking Task

References
Artstein, R., & Poesio, M. (2008). Inter-coder agreement computational linguistics.
Computational Linguistics, 34 (4), 555596.
Bach, F. R., & Jordan, M. I. (2002). Kernel independent component analysis. Journal
Machine Learning Research, 3, 148.
Barnard, K., Duygulu, P., Forsyth, D., Freitas, N. D., Blei, D. M., & Jordan, M. I. (2003).
Matching words pictures. Journal Machine Learning Research, 3, 11071135.
Blei, D. M., & Jordan, M. I. (2003). Modeling annotated data. SIGIR 2003: Proceedings
26th Annual International ACM SIGIR Conference Research Development
Information Retrieval, pp. 127134, Toronto, Ontario, Canada.
Bloehdorn, S., Basili, R., Cammisa, M., & Moschitti, A. (2006). Semantic kernels text
classification based topological measures feature similarity. Proceedings
6th IEEE International Conference Data Mining (ICDM 2006), pp. 808812, Hong
Kong, China.
BNC Consortium (2007). British National Corpus, version 3 (BNC XML edition).
http://www.natcorp.ox.ac.uk.
Brown, P. F., Pietra, V. J. D., Pietra, S. A. D., & Mercer, R. L. (1993). mathematics
statistical machine translation: parameter estimation. Computational Linguistics,
19 (2), 263311.
Callison-Burch, C., Osborne, M., & Koehn, P. (2006). Re-evaluation role bleu
machine translation research. Proceedings 11th Conference European Chapter Association Computational Linguistics (EACL), pp. 249256,
Trento, Italy.
Cohen, J. (1960). coefficient agreement nominal scales. Educational Psychological Measurement, 20 (1), 3746.
Croce, D., Moschitti, A., & Basili, R. (2011). Structured lexical similarity via convolution
kernels dependency trees. Proceedings 2011 Conference Empirical
Methods Natural Language Processing (EMNLP), pp. 10341046, Edinburgh, UK.
Dale, R., & White, M. (Eds.). (2007). Workshop Shared Tasks Comparative Evaluation Natural Language Generation: Position Papers, Arlington, VA, USA.
Datta, R., Joshi, D., Li, J., & Wang, J. Z. (2008). Image retrieval: Ideas, influences,
trends new age. ACM Computing Surveys, 40 (2), 5:15:60.
Deschacht, K., & Moens, M.-F. (2007). Text analysis automatic image annotation.
Proceedings 45th Annual Meeting Association Computational Linguistics (ACL), pp. 10001007, Prague, Czech Republic.
Dietterich, T. G. (1998). Approximate statistical tests comparing supervised classification
learning algorithms. Neural Computation, 10 (7), 18951923.
Everingham, M., Gool, L. V., Williams, C., Winn, J., & Zisserman, A. (2008).
PASCAL Visual Object Classes Challenge 2008 (VOC2008) Results. http://www.
pascal-network.org/challenges/VOC/voc2008/workshop/.
895

fiHodosh, Young & Hockenmaier

Farhadi, A., Hejrati, M., Sadeghi, M. A., Young, P., Rashtchian, C., Hockenmaier, J., &
Forsyth, D. (2010). Every picture tells story: Generating sentences images.
Proceedings European Conference Computer Vision (ECCV), Part IV, pp.
1529, Heraklion, Greece.
Fellbaum, C. (1998). WordNet: Electronic Lexical Database. Bradford Books.
Felzenszwalb, P., McAllester, D., & Ramanan, D. (2008). discriminatively trained, multiscale, deformable part model. Proceedings 2008 IEEE Conference Computer Vision Pattern Recognition (CVPR), pp. 18, Anchorage, AK, USA.
Feng, Y., & Lapata, M. (2008). Automatic image annotation using auxiliary text information. Proceedings 46th Annual Meeting Association Computational
Linguistics: Human Language Technologies (ACL-08: HLT), pp. 272280, Columbus,
OH, USA.
Feng, Y., & Lapata, M. (2010). many words picture worth? automatic caption generation news images. Proceedings 48th Annual Meeting Association
Computational Linguistics (ACL), pp. 12391249, Uppsala, Sweden.
Fisher, R. A. (1935). Design Experiments. Olyver Boyd, Edinburgh, UK.
Grangier, D., & Bengio, S. (2008). discriminative kernel-based approach rank images
text queries. IEEE Transactions Pattern Analysis Machine Intelligence,
30, 13711384.
Grice, H. P. (1975). Logic conversation. Davidson, D., & Harman, G. H. (Eds.),
Logic Grammar, pp. 6475. Dickenson Publishing Co., Encino, CA, USA.
Grubinger, M., Clough, P., Mller, H., & Deselaers, T. (2006). IAPR benchmark: new
evaluation resource visual information systems. OntoImage 2006, Workshop
Language Resources Content-based Image Retrieval LREC 2006, pp. 1323,
Genoa, Italy.
Gupta, A., Verma, Y., & Jawahar, C. (2012). Choosing linguistics vision describe
images. Proceedings Twenty-Sixth AAAI Conference Artificial Intelligence,
Toronto, Ontario, Canada.
Hardoon, D. R., Saunders, C., Szedmak, S., & Shawe-Taylor, J. (2006). correlation approach automatic image annotation. Li, X., Zaane, O. R., & Li, Z.-H. (Eds.),
Advanced Data Mining Applications, Vol. 4093 Lecture Notes Computer Science, pp. 681692. Springer Berlin Heidelberg.
Hardoon, D. R., Szedmak, S. R., & Shawe-Taylor, J. R. (2004). Canonical correlation
analysis: overview application learning methods. Neural Computation, 16,
26392664.
Hotelling, H. (1936). Relations two sets variates. Biometrika, 28 (3/4), 321377.
Hwang, S., & Grauman, K. (2012). Learning relative importance objects tagged
images retrieval cross-modal search. International Journal Computer Vision,
100 (2), 134153.

896

fiFraming Image Description Ranking Task

Jaimes, A., Jaimes, R., & Chang, S.-F. (2000). conceptual framework indexing visual
information multiple levels. Internet Imaging 2000, Vol. 3964 Proceedings
SPIE, pp. 215, San Jose, CA, USA.
Jurafsky, D., & Martin, J. H. (2008). Speech Language Processing (2nd edition). Prentice
Hall.
Krippendorff, K. (2004). Content analysis: introduction methodology. Sage.
Kulkarni, G., Premraj, V., Dhar, S., Li, S., Choi, Y., Berg, A. C., & Berg, T. L. (2011).
Baby talk: Understanding generating simple image descriptions. Proceedings
2011 IEEE Conference Computer Vision Pattern Recognition (CVPR),
pp. 16011608.
Kuznetsova, P., Ordonez, V., Berg, A., Berg, T., & Choi, Y. (2012). Collective generation
natural image descriptions. Proceedings 50th Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 359368, Jeju
Island, Korea.
Lavrenko, V., Manmatha, R., & Jeon, J. (2004). model learning semantics pictures. Thrun, S., Saul, L., & Schlkopf, B. (Eds.), Advances Neural Information
Processing Systems 16, Cambridge, MA, USA.
Lazebnik, S., Schmid, C., & Ponce, J. (2009). Spatial pyramid matching. S. Dickinson,
A. Leonardis, B. S., & Tarr, M. (Eds.), Object Categorization: Computer Human
Vision Perspectives, chap. 21, pp. 401415. Cambridge University Press.
Li, S., Kulkarni, G., Berg, T. L., Berg, A. C., & Choi, Y. (2011). Composing simple image descriptions using web-scale n-grams. Proceedings Fifteenth Conference
Computational Natural Language Learning (CoNLL), pp. 220228, Portland, OR,
USA.
Lin, C.-Y. (2004). Rouge: package automatic evaluation summaries. MarieFrancine Moens, S. S. (Ed.), Text Summarization Branches Out: Proceedings
ACL-04 Workshop, pp. 7481, Barcelona, Spain.
Lin, C.-Y., & Hovy, E. H. (2003). Automatic evaluation summaries using n-gram cooccurrence statistics. Proceedings 2003 Human Language Technology Conference North American Chapter Association Computational Linguistics
(HLT-NAACL), pp. 7178, Edmonton, AB, Canada.
Lin, D. (1998). information-theoretic definition similarity. Proceedings Fifteenth International Conference Machine Learning (ICML), pp. 296304, Madison,
WI, USA.
Lowe, D. G. (2004). Distinctive image features scale-invariant keypoints. Internationa
Journal Computer Vision, 60 (2), 91110.
Makadia, A., Pavlovic, V., & Kumar, S. (2010). Baselines image annotation. International
Journal Computer Vision, 90 (1), 88105.
Manning, C. D., Raghavan, P., & Schtze, H. (2008). Introduction Information Retrieval.
Cambridge University Press.

897

fiHodosh, Young & Hockenmaier

Mitchell, M., Dodge, J., Goyal, A., Yamaguchi, K., Stratos, K., Han, X., Mensch, A., Berg,
A., Berg, T., & Daume III, H. (2012). Midge: Generating image descriptions
computer vision detections. Proceedings 13th Conference European
Chapter Association Computational Linguistics (EACL), pp. 747756, Avignon, France.
Moschitti, A. (2009). Syntactic semantic kernels short text pair categorization.
Proceedings 12th Conference European Chapter Association
Computational Linguistics (EACL), pp. 576584, Athens, Greece.
Moschitti, A., Pighin, D., & Basili, R. (2008). Tree kernels semantic role labeling.
Computational Linguistics, 34 (2), 193224.
Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignment
models. Computational Linguistics, 29 (1), 1951.
Ordonez, V., Kulkarni, G., & Berg, T. L. (2011). Im2text: Describing images using 1 million
captioned photographs. Advances Neural Information Processing Systems 24,
pp. 11431151.
Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). Bleu: method automatic
evaluation machine translation. Proceedings 40th Annual Meeting Association Computational Linguistics (ACL), pp. 311318, Philadelphia, PA, USA.
Popescu, A., Tsikrika, T., & Kludas, J. (2010). Overview Wikipedia retrieval task
ImageCLEF 2010. CLEF (Notebook Papers/LABs/Workshops), Padua, Italy.
Porter, M. F. (1980). algorithm suffix stripping. Program, 14 (3), 130137.
Rashtchian, C., Young, P., Hodosh, M., & Hockenmaier, J. (2010). Collecting image annotations using Amazons Mechanical Turk. NAACL Workshop Creating Speech
Language Data Amazons Mechanical Turk, pp. 139147, Los Angeles, CA,
USA.
Rasiwasia, N., Pereira, J. C., Coviello, E., Doyle, G., Lanckriet, G. R., Levy, R., & Vasconcelos, N. (2010). new approach cross-modal multimedia retrieval. Proceedings
International Conference Multimedia (MM), pp. 251260, New York, NY,
USA.
Reiter, E., & Belz, A. (2009). investigation validity metrics automatically evaluating natural language generation systems. Computational Linguistics,
35 (4), 529558.
Shatford, S. (1986). Analyzing subject picture: theoretical approach. Cataloging
& Classification Quarterly, 6, 3962.
Shawe-Taylor, J., & Cristianini, N. (2004). Kernel Methods Pattern Analysis. Cambridge
University Press.
Smucker, M. D., Allan, J., & Carterette, B. (2007). comparison statistical significance
tests information retrieval evaluation. Proceedings Sixteenth ACM Conference Information Knowledge Management (CIKM), pp. 623632, Lisbon,
Portugal.

898

fiFraming Image Description Ranking Task

Socher, R., & Li, F.-F. (2010). Connecting modalities: Semi-supervised segmentation
annotation images using unaligned text corpora. Proceedings 2010 IEEE
Conference Computer Vision Pattern Recognition (CVPR), pp. 966973, San
Francisco, CA, USA.
van Erp, M., & Schomaker, L. (2000). Variants Borda count method combining
ranked classifier hypotheses. Proceedings Seventh International Workshop
Frontiers Handwriting Recognition (IWFHR), pp. 443452, Nijmegen, Netherlands.
Varma, M., & Zisserman, A. (2005). statistical approach texture classification
single images. International Journal Computer Vision, 62, 6181.
Vedaldi, A., & Fulkerson, B. (2008). VLFeat: open portable library computer
vision algorithms. http://www.vlfeat.org/.
Weston, J., Bengio, S., & Usunier, N. (2010). Large scale image annotation: learning rank
joint word-image embeddings. Machine Learning, 81 (1), 2135.
Yang, Y., Teo, C., Daume III, H., & Aloimonos, Y. (2011). Corpus-guided sentence generation natural images. Proceedings 2011 Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 444454, Edinburgh, UK.

899

fiJournal Artificial Intelligence Research 47 (2013) 313-349

Submitted 03/13; published 06/13

Learning Observation Agent Software Images
Paulo Costa
Luis Botelho

paulo.costa@iscte.pt
luis.botelho@iscte.pt

Instituto de Telecomunicacoes
ISCTE-Instituto Universitario de Lisboa
Avenida das Forcas Armadas, 1649-026 Lisbon, Portugal.

Abstract
Learning observation key importance whenever agents sharing similar
features want learn other. paper presents agent architecture
enables software agents learn direct observation actions executed expert
agents performing task. possible proposed architecture
displays information essential observation, making possible software agents
observe other.
agent architecture supports learning process covers aspects learning
observation, discovering observing experts, learning observed
data, applying acquired knowledge evaluating agents progress. evaluation
provides control decision obtain new knowledge apply acquired knowledge
new problems.
combine two methods learning observed information. first one,
recall method, uses sequence actions observed solve new problems.
second one, classification method, categorizes information observed data
determines set categories new problems belong.
Results show agents able learn conditions common supervised
learning algorithms fail, agents know results actions
priori effects actions visible. results also show
approach provides better results learning methods since requires shorter
learning periods.

1. Introduction
paper describes important aspects approach enabling software agents
learn control mechanisms directly observing actions expert agent
performing task. shows innovations proposal agent software image
(Costa & Botelho, 2011) presents complete learning observation process, following
previous work subject (Costa & Botelho, 2012). paper also presents results
approach two different scenarios (see section 5). learning method used
approach usually known artificial intelligence community learning observation,
imitation learning, learning demonstration, programming demonstration, learning
watching learning showing. consistency, learning observation used
on.
Learning observation one least common complex forms learning amongst animals singular humans strict number superior
mammals. also one powerful socialisation mechanisms (Ramachandran,
c
2013
AI Access Foundation. rights reserved.

fiCosta & Botelho

2003; Bandura, 1977; Meunier, Monfardini, & Boussaoud, 2007). Research neurology
psychology shows learning observation may well one causes
exponential growth human technologies last centuries. Unlike natural selection, observation allows capabilities spread amongst individuals within generation
(Ramachandran, 2000).
Section 2 shows learning observation already used robotic agents,
proves applicability learning technique artificial systems. However,
progress learning observation limited robotics software agents cannot
observe one another way tangible entities observed. Learning observation useful software agents provides direct approach problem
solve compared techniques agents learn experience,
reinforcement learning. Instead spending time testing several hypotheses, artificial agents
acquire knowledge expert directly observing actions performs
task. allows artificial agents directly know actions necessary
perform specific task (Argall, Chernova, Veloso, & Browning, 2009; Chernova, 2009).
able observe expert agent performing actions (as opposed merely rely
observation effects) advantageous situations effects
actions directly visible environment (for example, agent communication,
manipulation software objects). Even part effect actions visible,
directly observing actions still advantageous effects could achieved
different alternative actions using one clearly better using others
(for example, using set sums instead simple multiplication). Observing actions
performed expert also advantageous representation world states requires
much memory making impossible build large enough training sets (for example,
web agents, manipulation large databases) especially agent know
effects actions priori (for example, executing invoking software program
API).
application learning observation software agents ideal societies
agents share common features internal representation methods (for
example, integration legacy systems). Without common internal representation methods, directly transferring knowledge agents impossible or, least difficult.
Learning observation makes possible learn without need common internal
representations agent makes interpretations observing.
advantages described provided motivation developing approach
learning observation software agents. major contribution approach
definition whole learning process, includes discovery, observation, storage
interpretation observed data, application acquired knowledge
continuous internal evaluation (see section 4). Agents learn observation capable
solving tasks conditions performed observed experts.
also capable performing similar task facing different conditions.
scenarios described section 5 show possibilities.
section 2 shows, best knowledge, approach learning observation software agents one presented Machado Botelho (2006). However,
Machado Botelhos proposal agents capable learning vocabulary
whereas work described paper agents capable learning control
314

fiLearning Observation Agent Software Images

mechanisms, requires developing different kind learning algorithm. addition,
approach also introduces several improvements software image (see section 3)
initially proposed Machado Botelho (2006).
software image provides software agents accessible representation
constituents capabilities, static image, actions perform, dynamic
image. approach heavily relies agent architecture software image. Agents
software image seen (consulted) agents even themselves.
software image allows software agents learn observation because, software
environments, information required learning observation automatically
visible agents body happens physical world (Quick, Dautenhahn, Nehaniv,
& Roberts, 2000). avoid misconceptions observation tangible entities
physical world, act observing software agent defined as:
Reading meta-data agents constituents, actions conditions holding
actions executed, without direct intervention observed agent.

allows observed agent (the expert) passive role observation process. learning observation humans superior mammals,
apprentice takes action obtain new knowledge, without interfering
expert agent. spite similarities Machado Botelhos (2006) approach,
approach introduced several improvements software image, particular:
inclusion agent sensors static image, addition visible
attributes, actuators actions Machado Botelhos approach.
improvement provides better description agent allows agents
know way agent understands world, explained section 3.1.
dynamic image, besides displaying executed action Machado Botelhos
approach, also displays information conditions holding action
executed, is, state environment, perceived agent sensors,
instances visible attributes. improvement enables agents
provide data observation similar training sequences used training
machine learning algorithms (condition-action pairs), explained section 3.1.
software image displays historical information actions executed
past conditions holding action executed. enables
agents acquire great amount knowledge beginning observation,
section 3.2 shows.
software image also uses ontologies hold knowledge designations
different kinds sensors, visible attributes, actions tasks. improvement
allows agents follow ontology use designations
kinds sensors, visible attributes, actions tasks, section 3.2 shows.
contributions approach restricted agent software image.
important contributions complete approach learning observation,
particular:
315

fiCosta & Botelho

discovery experts provides agent necessary tools discover,
itself, expert agents possible learn (see section 4.1).
definition two learning algorithms, used convert observed
information mechanisms choosing actions perform condition
- recall algorithm classification algorithm. recall algorithm
totally developed approach uses sequence expert actions
observed choose actions perform. classification algorithm
adaptation existing KStar algorithm (Cleary & Trigg, 1995). categorizes
information observed data determines actions perform according
categories new problems (see section 4.2).
definition internal evaluation provides agent measure
confidence knowledge. Depending confidence, agent
one two states learning process: learning state execution state (see
section 4). agents learning state, objective observe experts acquire new knowledge them. agents execution state,
objective perform task using acquired knowledge. Switching
two states depends two configurable thresholds, UpperConfidenceThreshold LowerConfidenceThreshold, explained section
4.3.
ability mimic mirror neurons, allows agent use mechanisms propose actions learning using acquired knowledge.
allows agent directly associate observed actions actions.
also allows agent propose actions conditions faced observed
expert determine agent capable proposing action
observed expert.
motivation drives agent observe expert partially covered
approach. simplification purposes, apprentice agents observation
experts top priority. apprentice agents equipped specialized sensor
focuses attention observing expert. internal evaluation allows agents
decide whether need knowledge, providing necessary
motivation observing experts, way know obtain new knowledge.
Another simplification relates determining experts observe performing
relevant actions task learn, also usually disregarded approaches
learning observation. normal circumstances, although expert features
apprentice, necessarily mean performing actions
necessary apprentice learn (by observation) perform specific task. Like
surveyed approaches, experts developed application scenarios section
5 prepared execute actions necessary task learnt.
section 5 capabilities learning approach tested two different scenarios.
first scenario especially conceived situation majority effects
agent actions visible environment. Therefore, possible
common machine learning solution learn effects actions.
316

fiLearning Observation Agent Software Images

complete understanding happening, necessary observe agent
actions. second scenario presents mountain car problem described Sutton
Barto (1998). used compare learning approach reinforcement learning
(RL) algorithm situation kind learning algorithm already shown
good approach (Mitchell, 1997).
results tests show that, approach, agents correctly learn
perform task majority effects agent actions visible
environment (see section 5.1). addition, tested situations learning
methods may provide good results (see section 5.2), reinforcement learning
scenario, results show approach able learn faster reinforcement
learning approach. Besides learning faster, agents using learning method also require
fewer actions achieve goal.
following section presents survey research visual representation
agents learning observation. Section 3 presents improvements made
previous proposals regarding software image. Section 4 describes important
aspects learning observation process. Section 5 describes test scenarios
experimental results. Finally section 6 presents conclusions future work.

2. Literature Review
section presents survey approaches learning observation
visual representation agents. describes important aspects approaches related
learning observation may contribute solve problems faced applying
learning observation software agents.
2.1 Visible Representation Software Agents
literature overview regarding learning observation shows that, exception
Machado Botelhos (2006) approach, software agents disregarded advances
learning observation since usually related robotics (Argall et al., 2009).
Software agents able distinguish software agents
remaining elements computer program disembodied nature software.
this, software agents able observe tangible entities would
observed (Etzioni, 1993; Quick et al., 2000).
Almost software approaches learning constrained observe changes
environment (the effects agent actions) knowledge obtained perform task
limited state change information (Quick et al., 2000; Argall et al., 2009). However, several
authors emphasized every action produces visible changes environment
(Byrne, 1999; Dautenhahn & Nehaniv, 2002; Botelho & Figueiredo, 2004; Machado, 2006),
thus, using state change information alone always good option. cases,
important actually see expert agent observing actions
addition effects. allows apprentice agents know exactly actions
necessary perform task, thus overcoming problems arise effects
actions visible environment agent know effects
317

fiCosta & Botelho

actions priori (Byrne, 1999; Dautenhahn & Nehaniv, 2002; Botelho & Figueiredo,
2004; Machado, 2006).
able learn observing actions agents, software agent needs
kind accessible representation body displays necessary visible features (Mataric, 1997; Botelho & Figueiredo, 2004; Machado, 2006). Research neurology
reveals human brain also uses representation human body activities
(Ramachandran, 2003). representation provides information body constituents
possible actions comes existence initial stages infant development. important factor learning observation, since allows children
acknowledge bodies capabilities. also provides ability identify entities
similar thus may worthwhile observing (Rao, Shon, & Meltzoff,
2004).
Despite neurological findings, literature review embodiment embodied
cognition shows that, besides approach (Costa & Botelho, 2011), another one
addresses problem creating kind accessible representation software agents
(Machado & Botelho, 2006). best knowledge, known
approaches concrete proposal deploying visible image software agents,
called visible software image simply software image. literature review
learning observation also provides alternatives since approaches, exception
referred ones, apply exclusively robotics (Argall et al., 2009).
Although Machado Botelhos (2006) approach software image provides
description agent constituents actions, describe kind input
agent collect software environment. Etzioni (1993) one first authors
realize lack physical body obstacle application
principles embodiment software agents way applied robotics.
Etzioni, software agent situated software environment way
robot situated physical world, characterized (its
actions) also kind inputs able collect software environment
(Etzioni, 1993).
reason, approach (Costa & Botelho, 2011), software image provides
software agents visible representation constituents, includes
sensing action capabilities, actions executed agent conditions
holding agent decided execute actions. proposal also keeps
historical record actions performed agent conditions holding
agent decided execute actions, limited amount time.
2.2 Learning Observation
survey learning observation shows one important aspects
approach learning observation learning algorithm. defines knowledge,
obtained observation, stored used, is, agent proposes
actions execute facing new problems (Argall et al., 2009). One possibility
learning algorithm follow sequence actions expert, requires
agent store sequence observed actions performed expert.
318

fiLearning Observation Agent Software Images

possibility learning algorithm, named sequencing, one commonly used learning observation approaches (Argall et al., 2009). also closely
related sequence learning humans since handles kind problems,
predicting elements sequence based preceding element, finding natural
order elements sequence selecting sequence actions achieve goal
(Clegg, DiGirolamo, & Keele, 1998; Sun, 2001). best way maintain temporal
relations elements sequence consists using properties data
structure sequences stored (Byrne, 1999; Heyes & Ray, 2000; Kulic, Ott, Lee,
Ishikawa, & Nakamura, 2011; Billing, Hellstrom, & Janlert, 2011).
Linear structures lists vectors commonly used (Byrne, 1999;
Heyes & Ray, 2000). However linear structures lack ability represent alternatives, important aspect sequential learning opens possibility
making choices inside sequence (Sun, 2001). representation alternative paths
essential representing different approaches perform task, is,
objective reached different sequences actions. hold information,
different approach needs stored alternative sequence actions. Tree structures ideal situations. element sequence represented node
tree following element chosen one branches node (Kulic
et al., 2011).
Sequencing best suited situations agents face conditions (the
sequence states environment internal states) observed experts,
often means agent following expert possible cover
possible combinations conditions time agent observing.
possibilities learning algorithm generalize acquired knowledge
use analogies acquired knowledge new problems. allows
agent face future conditions never observed, real world
situation almost always impossible observe possible conditions (Argall et al., 2009;
Sullivan, 2011). Unlike sequencing, specific sequence actions follow.
agent determines actions perform supported exclusively conditions.
One way generalizing acquired knowledge using observed conditions
actions train neural networks, described Billard Hayes (1999). hypothesis
consist using observed conditions actions feed statistical approaches
Bayesian algorithms Hidden Markov models (HMMs) (Rao et al., 2004; Hajimirsadeghi
& Ahmadabadi, 2010). conditions actions also used train supervised
learning algorithms, classification algorithms (Argall et al., 2009; Chernova,
2009; Sullivan, 2011).
Given advantages sequencing generalization analogy possibilities approach learning observation presents sequencing possibility,
recall method learning, classification possibility, trough classification method
learning. two methods learning combined increase adaptability
apprentice agents. classification method allows agent extend knowledge
conditions observed recall method allows agent easily learn
sequences actions different alternatives.
survey learning observation also reveals learning observation approach cannot limited learning algorithm. addition algorithm, must
319

fiCosta & Botelho

also include agents motivation learn, discovery observation agents,
storage interpretation information acquired observation application
newly acquired knowledge (Demiris & Hayes, 2002; Tan, 2012). One major
flaws detected surveyed approaches, besides focus robot agents, fact
global view still missing (Tan, 2012). best knowledge,
exception approach (Costa & Botelho, 2012), approaches focused solving
specific problems, solutions provide supported exclusively learning
algorithm.
Demiris Hayes (2002) provide good starting point building approach
includes aspects learning observation. approach presents learning process
that, excluding motivation, consistent Banduras (1977) social learning theory,
approximates approach learning observation humans superior mammals.
inclusion internal evaluation Demiris Hayess (2002) approach provides
learning process simple motivation mechanism. evaluation allows agent
measure performance affected consolidating knowledge
acquired observation executing actions (Wood, 2008; Hajimirsadeghi & Ahmadabadi, 2010).
agent intrinsically motivated learn knows acquired
sufficient knowledge perform task detects portions
knowledge need improvement thus require agent go back learning (Wood,
2008; Billing, Hellstrom, & Janlert, 2010). ability enhance agents knowledge
new observations important factor learning observation. According
Argall et al. (2009), one downsides learning observation fact
agents knowledge limited able observe. Using evaluation stage,
operates agent learning executing actions, provides
knowledge necessary observe experts agents ready execute
actions.
Several authors use specialized experts, teachers, monitor reinforce
agents actions (Sullivan, 2011; Hajimirsadeghi & Ahmadabadi, 2010; Chernova, 2009).
also measure agents performance provide necessary evaluation. Besides
monitoring, teachers also take corrective measures like providing appropriate
actions faced conditions agent chooses incorrect actions (Hajimirsadeghi
& Ahmadabadi, 2010). teacher also decide agent needs acquire
knowledge (Sullivan, 2011).
relation teacher agent extended allowing
communicate other. allows agent request teacher perform
specific task (Chernova, 2009). However, requires additional effort designing
expert agents since need communicate apprentice agents teach
perform task. also requires apprentice agents wait teacher
available communicate them, extend amount time spent
learning. happen expert plays passive role observation and,
addition, using teachers makes approaches closer learning teaching, goes
beyond learning observation.
different approach evaluation mimicking properties mirror neurons.
mirror neurons brain structures exist humans superior mammals
320

fiLearning Observation Agent Software Images

responsible emergence learning observation. involved tight
coupling perception motor control, providing similar responses observing
performing activity. allows agents feel like performing
actions observe expert (Ramachandran, 2000), greatly improves
easiness identifying observed actions, grounding agent actions.
ability, agent able propose actions, using mechanisms,
observing, without effectively executing them. proposed actions
compared observed determine agent able propose actions
expert. information provided comparison feeds agents internal
confidence able propose correct actions. case, agents internal
confidence builds successes failures actions previously proposed
instead metrics current actions, provided learning algorithm,
work Chernova (2009), Billing et al. (2010).
Several approaches use specific structures, forward models, emulate
behaviour mirror neurons (Rizzolatti, Fadiga, & Gallese, 1996; Demiris & Hayes, 2002;
Maistros & Hayes, 2004; Rao et al., 2004; Lopes & Santos-Victor, 2007). However
structures specifically designed robots use hardware inhibitors prevent
robot actuators executing estimated actions. main objective kind
structures create distinction description action execution,
is, create abstract representations agent actions (Kulic et al., 2011). solution
simpler provides agent control execution actions.
One characteristics reviewed approaches usually focus specific
problems, implies adaptations features whenever applied
new domains. Despite problem, shown section, reviewed approaches
provide important features adapted approach learning observation.

3. Software Image
section presents summary additional functionalities approach introduced previous work regarding software image (Machado & Botelho, 2006).
section describes new functionalities, explains reasons inclusion
software image advantageous learning observation.
approach learning observation proposes software image allows software
agents learn observing actions agents. act observing software
agent imply use computer vision; instead agents use specialized sensors
read meta-data observed agent. meta-data call software
image, defined software objects relationships among them, displayed
Figure 1. Despite current version software image primarily focused
learning observation, believe image useful purposes
(for example, improve agents interaction surrounding environment
embodiment). Additional work incrementally reveal characteristics software
image independent particular use.
proposal software image (Costa & Botelho, 2011) provides accessible
domain independent description agents constituents, actions executes
conditions holding decided execute actions. description used
321

fiCosta & Botelho

software agents interested observing represented agent comparison
description, check agents share capabilities, described
section 4.1. Figure 1 shows representation key elements software image. Like
Machado Botelhos (2006) proposal, elements agent software image
arranged two categories, static image dynamic image. static image
immutable (does change time) describes constituents agent whereas
dynamic image changes time describes activities agent.
1
1..*
1

StaticImage

1
1

1

SoftwareImage

+historySize: int

+AgentUUID: String

AgentPart

DynamicImage

1

1

0..*
0..*

1..*

Action
+descriptor: String

1

Sensor
0..*

1

+descriptor: String

<<Interface>>

DataSource

1

0..*
1

Condition

1..*
1

+value

1

VisibleAttribute

CompositeAction

0..*

+descriptor: String

ActionInstance
0..*

SimpleAction

1..*

Actuator

0..*

Snapshot
+order: int

1

+parameters

1

Figure 1: class diagram software image
improvements Machado Botelhos (2006) proposal software image
consist including agent sensors description components (the static image), combining information state software environment (provided
agent sensors) information important aspects agents internal state
observed actions enabling representation composite actions, is, actions composed sequences simpler actions. important improvements include ability
store historic data agent actions conditions holding actions,
use ontology represent knowledge agent sensors, actions visible
attributes, tasks accomplished concepts relationships exist
elements. proposal software image also defines protocol
observing snapshots.
following sections describe improvements software image greater
detail.
3.1 Agent Sensors Snapshots Agent Activity
Machado Botelhos (2006) version software image described software agents
collection parts visible attributes actuators. actuators, turn,
described collection actions agent able perform. However, also
important include agent sensors description, especially software agents
access part state environment, acquired sensors.
information collected agent sensors represents way agent understands
world - agents perspective world. sensors included static
image, agents way knowing experts observe understand world
way them. ability understand world way
322

fiLearning Observation Agent Software Images

expert important better understanding reasons behind experts actions
(Bandura, 1977; Ramachandran, 2000).
Given importance agent sensors, proposal software image includes
constituents agent part (see Figure 1). provides accurate description
agent allows agents compare others actions
perform also kind information obtain environment.
proposal software image also consider conditions holding
agent action state environment, acquired agent sensors,
instances agents visible attributes (the important aspects agents internal state)
moment agent selects action. information contained conditions
depends exclusively information provided agent sensors visible
attributes. agent sensors visible attributes, well type information
provide, defined designing agent. Section 5 shows example
sensors visible attributes set agent affects conditions.
conditions holding action play important role information provided
observation dynamic image. Unlike Machado Botelhos (2006) proposal
agents could observe action currently performed, proposal,
agents acquire snapshots activity observed agent. snapshot contains
information executed action conditions holding moment agent
decided select it. way, information provided observation similar
training sequences used training machine learning algorithms (a sequence conditionaction pairs), important aspect learning methods described section
4.2.
addition including conditions information provided observation,
action provided snapshot either simple composite (see Figure 1), is,
action composed sequence actions. allows agents handle sequences actions
single actions, observing.
3.2 Additional Innovations Software Image
section describes additional innovations proposal software image.
important innovation ability store historic data. historic data provides
limited amount past snapshots. allows observers gather knowledge much faster,
compared observing current action, necessary wait
agent perform actions. However, innovation requires conditions
hold perspective agent executing actions, is, state
environment instances visible attributes provided agent perceives
them. Without agents perspective would hard, even impossible,
observer know conditions holding past.
Using agents perspective seen limitation compared using
observers perspective acquiring conditions requires observer
agents kind sensors visible attributes expert agents
observe, understand information contained conditions (see section 4.1).
However, always ensured observer direct access environment
observed agent, like example, software environment observed
323

fiCosta & Botelho

agent running distinct process. cases, would necessary use complex
communication mechanisms observer get access information different
process. would necessary observer used information provided
software image additional mechanism, software image index
described section 4.1, provides shared repository registered software
images easily accessed.
Another innovation software image use ontology describe knowledge agent sensors, visible attributes actions, tasks accomplished
relationships elements. Using ontologies allows different agents
follow ontology use designations kinds sensors,
actions visible attributes tasks. ontology also enables specific
kinds sensors, actions visible attributes associated specific tasks,
allows agents know elements required perform task (see section 4.1).
Another important aspect ontology possibility associating two different elements, opens possibility translations different ontologies.
meta-ontology, call software image meta-ontology, created facilitate
translation. meta-ontology defines basic elements ontology
possible relationships elements. Additional information subject
presented future work.
addition innovations, proposal also defines new protocol observing
snapshots software image. functionality developed software image,
dynamic image notification, allows subscribed observers receive notifications
time new snapshot created dynamic image observed agent.
allows observers know exactly observe, is,
collect new snapshot dynamic image observed agent. following section
explains way agents learn observing (acquiring information agents software
image) expert.

4. Learning Observation
section summarizes approach regarding complete learning observation process, following previous work subject (Costa & Botelho, 2012). shows new
insight learning process focuses important aspects process discovering observing experts methods learning information provided
observation. section also describes agents internal evaluation affects
agents behaviour.
approach learning observation requires expert apprentice
agent software image since provides means comparing agents
also data observation (see section 3). presents global view learning
process comprises six activities, presented Figure 2, always happen
strict sequence. agent may also one two states regarding learning
observation process: learning state execution state. states,
agent access subset learning process activities. Figure 2 shows
activities available state.
324

fiLearning Observation Agent Software Images

Learning
state

Discovery
similar expert

Expert
observation

Storage acquired
information

Learn control knowledge
propose actions

Evaluation
agents progress

Execution
state

Acquisition current
state sensors

Learn control knowledge
propose actions

Application
learnt knowledge

Figure 2: activities learning process state
Figure 2 shows, possible activities learning state concern discovering
observing expert, retaining information acquired observation, learning control
knowledge propose actions evaluating proposed actions. possible activities
execution state concern acquiring current state environment (from agent
sensors), learning control knowledge propose actions, executing proposed actions
evaluating executed actions. Figure 2 also shows that, result mimicking
properties mirror neurons, agents capable proposing actions learning
executing actions (see section 4.2).
approach provides two distinct methods learning information acquired
observation, recall classification methods, specifically developed
approach. inspired two used algorithms learning
observation (see section 2.2). two methods combined present single solution
apprentice agents (see section 4.2), increases agents ability adapt different
situations. agents able perform observed task facing conditions
experts also similar task facing different conditions.
internal evaluation, described section 4.3, one important activities
learning process monitors agents ability propose correct actions
time. result monitoring measure agent confidence learnt
knowledge, confidence value. agent learning execution
state depending confidence regarding acquired knowledge.
following sections describe important aspects approach learning observation learning process experts discovered, agent learns
information acquired observation internal evaluation works.
4.1 Discovering Observing Expert Agents
software image, described section 3, addresses problem providing information
necessary observation way universally accessible software agents.
software image, apprentice software agents compare
discovered experts collect information actions executed expert
conditions holding time expert decided execute actions.
discovery service, software image index, developed facilitate discovery
expert agents. allows software agents register software images shared
repository agents able find them. agents use service discover
software images expert agents.
325

fiCosta & Botelho

starting observe expert, agent must know potentially possible
learn observing particular expert. possible determine
agent structures necessary task learn (see section 3.2), agents follow
Banduras (1977) social learning theory learn observing similar expert, is,
expert whose static image structure instances atomic
elements agents static image. agent uses comparison functionalities
software image described Costa Botelho (2011) compare static image SIagent
static image expert SIexpert . images match, SIagent SIexpert ,
expert observed agent able immediately recognize actions
conditions snapshots (see section 3.1), solving correspondence problems
(Alissandrakis, Nehaniv, & Dautenhahn, 2002; Argall et al., 2009).
agent knows task learn structures abilities
necessary task, siT (see section 3.2), concept expert
potentially possible learn extended, allowing agents observe expert long
intersection software images contains structures abilities, (SIagent
SIexpert ) 3 siT . enough ensure apprentice agent able recognize
conditions activities expert snapshots necessary learning
specific task. agents determine structures abilities necessary perform
task ontology, explained section 3.2.
discovering expert observe, agent subscribes experts dynamic
image notification acquires snapshots history record (see section 3.2).
notifications facilitate process observing expert since determine
ideal moment agent observe, new snapshot created
experts dynamic image. agent acquiring snapshots history record,
new snapshots created experts dynamic image also acquired stored
temporary memory.
temporary memory functions buffer observation allows agent
handle snapshots different rate acquired. also allows agent
keep record experts actions might take place reading history.
snapshots stored temporary memory handled history snapshots
handled, provides agent uninterrupted sequence snapshots
moment past current moment.
compared solutions searching history record demand,
is, find relevant information particular problem, collecting information
history record efficient solution allows agent obtain
large set experiences small amount time. Acquiring history record
ensures solution particular problem found (if really exists
history) also provides agent increased amount information might
important solve problems future.
important aspect approach learning observation preference
observing different experts. process discovering expert collecting snapshots
dynamic image referred observation period. process cyclical
meaning agent may go several observation periods learning.
beginning observation period agent free choose different expert observe,
326

fiLearning Observation Agent Software Images

increasing diversity knowledge different experts might provide different
points view task learn.
different perspectives provided experts may increase agents knowledge
conditions never observed previous agents different approach
performing task. following section shows way agent increases knowledge
handles different approaches.
4.2 Learning Observed Snapshots
section describes agent learns observed snapshots uses
acquired knowledge propose actions set conditions. describes
agent holds information contained snapshot memory. presents two
methods learning observed snapshots, recall classification methods,
explains combined present single solution proposing actions.
section also explains behaviour mirror neurons mimicked approach
useful learning.
snapshots acquired observation describe relation optimal set
conditions (C1 Cn) action A, C1 C2 Cn (see section 3.1).
relation, call experience, stored agents memory held
tree structure. Using tree structure enables sequence snapshots
observed intrinsically preserved structure, shown literature review
section 2. tree structure also facilitates consolidation agents knowledge
stores different approaches task alternative paths.
SET
SET
SET


Newexp new experience store memory
Previous experience snapshot observed
Stored false
Exp <- experience agents memory
Exp conditions Newexp
Exp action Newexp
PUT Exp sub-tree Previous
SET Stored true
BREAK
ENDIF
ENDFOR
Stored false
ADD Newexp agents memory
PUT Newexp sub-tree Previous
ENDIF

Figure 3: process storing experiences memory
Given agents observe different experts, sequence snapshots
observed broken time agent starts observing another expert. happens,
snapshot observed represents activity another expert therefore cannot
followed new snapshots. prevent fragmentation duplication (multiple
instances experience) agents memory, process storing new
327

fiCosta & Botelho

knowledge agents memory compares new experience ones existing
memory storing it. Figure 3 describes process takes place.
process described Figure 3 allows agent create new knowledge using
information already exists memory merely creating new connections
existing experiences. new experience stored exist
agents memory. tree structure holding agents memory allows agents
knowledge expressed decision tree, shown Figure 4, node
tree experience. Depending number branches starting node,
experience followed one experience, adds possibility
choosing sequence follow therefore provide different alternatives executing
task.
Previous
experiences

REFERENCE
EXPERIENCE

Experience

Experience

Experience

Experience

Experience

Following
experiences

Experience

Task

Figure 4: representation tree structure agents memory
recall classification methods learning use information contained
agents memory (the tree experiences shown Figure 4) propose actions
given conditions, call currentConditions. two methods distinguish
way use information agents memory propose
actions. recall method proposes actions determining way experiences
connected tree, whereas classification method proposes actions
categorizing individual experiences comparing categories category
current problem.
recall classification methods provide several possibilities actions.
determine actions best suited execution, reliability associated
proposed action. reliability calculated method ranges
zero one, inclusive. determines reliable action (zero reliable; one fully
reliable) method proposed it.
328

fiLearning Observation Agent Software Images

recall method proposes actions following connections experiences agents memory (see Figure 4). propose actions, method requires
reference experience agents memory indicates start following
connections. reference, call referenceExperience, represents
last action executed agent Act conditions holding action Cond.
Figures 5 6 show way referenceExperience discovered agents
memory.
FUNCTION discoverReferenceExperience(Cond,Act)
SET Similarity zero
SET RefExp
Exp <- experience memory
action Exp Act
Exp conditions Cond
RETURN Exp
ELSE
SET Val similarityBetween(conditions Exp,Cond)
Val bigger Similarity
SET RefExp Exp
SET Similarity Val
ENDIF
ENDIF
ENDIF
ENDFOR
RETURN Exp
ENDFUNCTION

Figure 5: Obtaining referenceExperience agents memory
process Figure 5 shows, referenceExperience experience
memory whose action last action executed agent whose
conditions conditions holding last executed action. Given
agent might facing conditions expert, possible
conditions holding last executed action found agents memory.
cases, referenceExperience one action shares
largest number similar conditions calculated process shown Figure 6.
discovering referenceExperience agents memory, tree subset
(the set tree branches) retrieved. tree subset represents choices experiences follow referenceExperience (see Figure 4). actions
experiences represent several action possibilities proposed recall method.
reliability action obtained similarity conditions
holding action (in experience) given currentConditions calculated process shown Figure 6. highest reliability given action
whose conditions resemble currentConditions.
Unlike recall method, classification method require reference
experience agents memory propose actions. proposed actions provided
adaptation classification algorithm trained experiences
329

fiCosta & Botelho

REQUIRE CondA size CondB
FUNCTION similarityBetween(CondA,CondB)
SET Sum zero
SET Size length set CondA
C1 <- condition Exp
Inner <- (FOR C2 <- condition Cond)
C1 equals C2
ADD one Sum
BREAK Inner
ENDIF
ENDFOR
ENDFOR
RETURN (Sum / Size)
ENDFUNCTION

Figure 6: Obtaining similarity two sets conditions

agents memory. Previous experiments (Costa & Botelho, 2012) revealed
suited algorithms classification method KStar Cleary Trigg (1995)
NNGE (Nearest Neighbour like algorithm using non-nested Generalized Exemplars
Martin, 1995). Since latter consumes resources choice falls KStar
algorithm.
KStar algorithm adapted able propose representations agent actions.
implementation KStar algorithm modified allow experiences
agents memory regarded positive examples proposed actions
deduced. categorization capabilities also enhanced allow conditions
define differences classes. propose actions, classification method
calculates distances conditions find experiences whose conditions
closer currentConditions. KStar algorithm uses entropy measure
distances two conditions (Cleary & Trigg, 1995).
reliability actions proposed classification method directly associated much conditions holding action close currentConditions. again, entropy used measure distance. example, conditions
holding proposed action identical currentConditions reliability
action 1, is, action fully reliable standpoint classification
method.
recall classification methods combined single solution. Agents use
methods propose actions choose best one current situation.
help deciding action best current situation, recall classification methods associated weightFactor, whose initial minimum value
zero. weightFactor determines methods capable proposing
suitable action current situation. reliability proposed action
combined weightFactor method proposed it, results
finalReliability (f inalReliability = reliability weightF actor). action
highest finalReliability best one current situation.
330

fiLearning Observation Agent Software Images

weightFactors change time agents capacity proposing actions
evaluated (see section 4.3). weightFactor method increases action
highest reliability proposed method proven appropriate choice
internal evaluation (see section 4.3). evaluation determines action
appropriate, weightFactor method decreases. explained section 4.3,
amount weightFactor increases decreases depends value
reliability proposed action.
recall classification methods learning propose actions agent
learning state execution state. possible actions proposed
methods simply representation agent actions, is, proposed actions
automatically executed. agent control action going
actually executed. control allows agent behave exact way
observing (in learning state) preparing execute actions (the
execution state), sense similar happens mirror neurons.
ability propose actions learning state allows agent experience
actions observes preparing perform them, proposing actions
conditions observed snapshots. advantageous since allows agent
realize capable (or not) making decisions expert. also useful
agents internal evaluation decide agent acquired sufficient knowledge
change execution state, explained following section.
4.3 Agents Internal Evaluation
section describes agents internal evaluation. shows way evaluation operates
affects transition two states learning process, learning
execution state. describes way agents confidence updated
related agents ability propose appropriate actions.
evaluation transversal process covers learning execution
state. main purpose evaluation ensure agents knowledge appropriate
mastering task, influences agents internal confidence. agents internal
confidence expresses successes failures proposing appropriate actions
faced conditions. Depending value internal confidence agent may
learning state execution state learning process. Two configurable thresholds,
UpperConfidenceThreshold LowerConfidenceThreshold determine
values agent changes learning execution state. Section 5.1
shows values selected thresholds influence agents capabilities. Figure
7 shows thresholds affect transition two states learning
process.
Figure 7 shows, agents confidence goes UpperConfidenceThreshold agent confident enough knowledge switches execution state
executes actions proposes (see section 4.2) conditions provided
sensors relevant aspects internal state (the visible attributes).
confidence goes LowerConfidenceThreshold agent stops confident
knowledge switches learning state acquires knowledge
observing experts. value internal confidence affected agents capacity
331

fiCosta & Botelho

Execution State

Learning State
UpperConfidenceTreshold

LowerConfidenceTreshold
Confidence

Figure 7: influence confidence thresholds state transition
propose appropriate actions whether observing (in learning state) preparing
execute actions (in execution state).
agents internal evaluation constantly testing agents capacity propose
correct actions, agent learning state execution state.
learning state, agent tested ability propose actions conditions
observed snapshots. agents confidence increases best action proposes
(the one highest finalReliability explained section 4.2)
action observed snapshot, otherwise confidence decreases. amount
confidence increases decreases depends reliability best action
proposed. example, action snapshot, B best action proposed
(with reliability 0.8) 6= B, agents confidence decreases 0.8.
Using reliability best proposed action factor increasing decreasing
agents confidence simplest way including confidence methods
learning actions propose (see section 4.2) calculation agents
internal confidence. way internal confidence updated gives importance
actions proposed high reliability, is, learning methods
high confidence actions propose. cases, actions correct
penalization internal confidence larger methods
low confidence actions propose means agent learnt something
wrong.
execution state, agent tested ability execute correct action
faced conditions, reflect agents perception sensors important
aspects internal state (see section 3.1). section 4.2 shows, execution
state agent selects action highest finalReliability, proposed
recall classification methods, executed. simple monitoring detects
problem prevented correct execution action. Whenever
problem detected agents confidence decreases. amount
confidence decreases depends reliability executed action (see section 4.2).
simple monitoring execution actions limitations even
though problems executing actions possible ensure
action appropriate faced conditions. overcome problem,
approach allows evaluation receive external feedback executed actions
specialized experts, teachers, evaluators specific applica332

fiLearning Observation Agent Software Images

tion domain. possibility evaluation approximates approach paradigm
learning teaching goes beyond scope paper therefore
presented future work.
Another important feature agents internal evaluation ability force
agent switch learning state independently confidence. forced switching
happens agent faced certain amount unfamiliar conditions, is,
conditions found observed snapshots. amount unfamiliar conditions
controlled configurable threshold whose value depends application domain.
explained section 3.1, conditions consist information provided agent
sensors visible attributes. conditions familiar agent observed
expert facing conditions therefore knows exactly correct action propose.
conditions familiar, agent never observed expert facing
probably means know actions propose. circumstances, amount unfamiliar conditions rises evaluation determines
executed action inappropriate. turn forced switching measure
last resort, amount unfamiliar conditions resets time agent faces familiar
condition. Therefore, amount represents number consecutive times agent
faces unfamiliar conditions.
forced switch learning state, agents confidence decreases
configurable reference value, UnfamilarConfidenceReference,
lower LowerConfidenceThreshold allow agent remain learning
state while. lower value UnfamilarConfidenceReference relation
LowerConfidenceThreshold longer agent takes change back
execution state. simplest solution keep agent learning state
time.
solutions take unfamiliar conditions account complex
require agent find expert facing conditions. Since
impossible determine agent finds experts, would necessary develop
complex mechanisms allow agent return execution state time,
thus preventing agent spending much time learning. similar behaviour
achieved reducing confidence letting internal evaluation decide
return execution state testing agents knowledge observing.
role played evaluation, namely making agent return learning state,
contributes overcome one major problems faced learning observation,
fact agents limited performing actions observed. Forcing
agent return learning state (and thus observe experts) gives agent
opportunity increase knowledge since experts may different experiences
might provide agent new knowledge.

5. Experimental Results
section describes two scenarios approach implemented. Since
scenarios software implementations, errors acquisition snapshots
conditions make sense therefore considered experiments. first
scenario designed appropriate learning observation majority
333

fiCosta & Botelho

expert activity affect state environment. second scenario compares
approach reinforcement learning approach typical reinforcement learning
experiment, mountain car experiment Sutton Barto (1998).
scenario present direct comparison solutions provided reinforcement
learning algorithm approach learning observation. statistical relevance
data collected comparisons guaranteed students t-test.
scenarios software implementations developed agents software
image. apprentice software agents observe experts effectively acquiring
snapshots experts software image. simplification, software images
apprentice agents constituents software images experts
observe. scenarios apprentice agents receive external feedback
teachers evaluators (see section 4.3) results reflect pure learning
observation approach.
Despite process discovering identifying similar expert important
step approach learning observation, results presented section
disclose process purpose focusing results benefits learning
observation. scenarios, apprentice agents use software image discovering,
identifying collecting information necessary observation experts.
Previous work software image (Costa & Botelho, 2011) presents results
aspects.
first scenario simulates agent virtual hand displays numbers sign
language. numbers provided agent software number generator
provides numbers one five. agent associated single number
generator knowledge number generators associated agents
participate simulation. time new number provided agent,
virtual hand changed display number means sign language. virtual
hand used communicating users graphical display
accessible agents.
However, agents virtual hand accessible representation current state
agents software image visible attribute (see section 3). way software
agents obtain information state agents virtual hand software
image. visible attribute represents state visible hand object five
attributes representing finger hand. attribute one two
states, DOWN.
expert agent designed scenario specialized part holds
knowledge efficient way changing virtual hand represents
number provided number generator. example, agent perceives
number one, virtual hand showing number two (the index middle fingers
UP) necessary move middle finger DOWN, whereas hand
showing number four, would necessary move middle, ring pinky fingers
DOWN. part perceives numbers number generator specialized
sensor. actuator five actions, one finger, change state
finger.
increase complexity scenario, number generators need reset
time time else stop generating new numbers. number sources either
334

fiLearning Observation Agent Software Images

Active state Inactive state. source stops providing numbers
Inactive. reset changes source back Active state. this,
expert agent another specialized part holds knowledge
refresh random number generator. state number generator perceived
specialized part sensor indicates state generator.
agent part one actuator single action resets source.
apprentice agent developed scenario learn master
two tasks, manipulating agents virtual hand display perceived numbers
resetting source, observing experts constituents capabilities. Like
experts, apprentice agents two parts. One specializes manipulating
virtual hand one sensor perceives numbers provided number
generator, one visible attribute displays state virtual hand one actuator
five actions change state finger.
part apprentice agent specializes managing source provides
numbers one sensor perceives state number source one
actuator single action resets source. Given description agent
sensors visible attributes, conditions scenario (see section 3.1) consist
number provided agent source, state virtual hand state
number source.
second scenario software implementation agent learns climb
mountain simulated sinusoidal wave. agent must abide laws physics
climb mountain, sufficient force, able climb
mountain going forward only, needs accelerate backwards forwards gain
momentum. goal scenario reach top mountain, is,
peak sinusoidal wave, taking least number decisions travelling smallest
distance (up mountain) possible.
experts, provided scenario, know optimal way (the exact moment
direction need accelerate) climb mountain reach top. experts
perceive current speed direction location mountain
sensors use information decide direction accelerate next.
choose accelerating forward, accelerating backward accelerating
(which maintains current speed).
apprentice agents learn decide direction accelerate according
location, speed direction. scenario includes two kinds apprentice agents
comparing two different learning methods. first kind apprentice
uses reinforcement learning algorithm (Q-Learning, implemented PIQLE tool
Comite, 2005) provide agent knowledge required climb mountain. reinforcement learning agent able perform three actions, accelerate forward,
accelerate backwards maintain speed.
reinforcement learning agent configured learning rate = 0.2
discount factor/rate = 0.9, settings present best results.
learning rate also decreases time following geometrical decay, allows agent
eventually stop learning period time. simple reward scheme used
reinforcement learning algorithm. agent rewarded reaches goal
scenario, top mountain. reward schemes would require use
335

fiCosta & Botelho

kind supervisor determine ideal situations apply reinforcements.
would changed comparison intended scenario, compare
learning observation situation apprentice agents need supervisors.
case reinforcement learning agent simple reward scheme.
information provided goal, embedded agent.
second kind apprentice agent uses learning observation acquire knowledge climbing mountain. agent shares constituents capabilities
experts observes, made single part two sensors one actuator. sensors provide agent location mountain current
speed (which positive agent moving forwards negative agent moving backwards). actuator provides agent three actions, accelerate forwards,
accelerate backwards maintain speed.
following sections present results simulations two scenarios.
provide learning observation agent broader set experiences,
simulations use one expert expert experiences scenario different
ways, is, receive different information environment sensors.
hand, one apprentice agent used simulations. simplification
ensures risk tested apprentice agent observe apprentices,
may mislead incorrect actions, instead observing experts.
unit time used simulation results simulation step. simulation
step represents time slot participant agents take decision. learning
observation agents, simulation step either represent observation (the acquisition
snapshot expert) subsequent learning (when agent
learning state), updating facing conditions (see section 3.1), proposing executing
action best suited faced conditions (when agent execution state)
(see section 4). reinforcement learning agents simulation step represents updating
facing conditions, selecting action conditions (from action-state pairs
stored memories) executing action interpreting rewards (updating
action-state pairs). expert agents, simulation step represents updating facing
conditions selecting executing action best suited conditions.
5.1 Results Virtual Hand Scenario
section shows impact changing confidence thresholds (see section 4.3)
time spent learning total number actions appropriately executed
agent. also shows way agents perform, terms number correct
actions, two different settings.
two settings depend sequence numbers provided number generators. control results simulation, numbers provided generators
designated pre-determined sequence. number generators provide numbers
following sequence end sequence reached source needs
reset agent. reset makes number generator provide numbers following
sequence.
first setting (exp1 ) number generators apprentice expert agents
provide sequence numbers. setting apprentice agent faces
336

fiLearning Observation Agent Software Images

conditions sequence experts observes provides good testing
ground recall method learning (see section 4.2). setting shows agent
capable performing task observed experts.
second setting (exp2 ), number generator different sequence numbers
different sizes, is, number generators need reset different times.
apprentice agent faces conditions different faced observed experts
provides good testing ground classification method learning (see section
4.2). setting shows agent capable performing task similar
observed facing different conditions.

Figure 8: impact changing confidence thresholds
Besides testing ground two learning methods, scenario also determines impact changing values UpperConfidenceThreshold
LowerConfidenceThreshold (see section 4.3). reason, settings
initially tested agents using different values thresholds. Figure 8 presents
summary results obtained second setting simulations 4000 steps (each
variation thresholds tested simulation lasting 4000 steps). choice
337

fiCosta & Botelho

second setting Figure 8 changing thresholds influence
also realistic approach scenario, since chances
agent find situation experts observes small.
explained section 4.3, confidence thresholds affect length learning period number subsequent learning periods turn affects total number
correct actions performed agent throughout simulation. UpperConfidenceThreshold low, agent may enough time learn, decreases
agents performance terms able execute correct actions.
UpperConfidenceThreshold high agent spends lot time learning,
reduces time spent execution state therefore total number actions
executed agent lower.
LowerConfidenceThreshold close UpperConfidenceThreshold agent switches learning execution state often (see section 4).
may hinder agents ability complete task slightest error causes
agent return learning state. LowerConfidenceThreshold
far apart UpperConfidenceThreshold, agent takes longer switch
learning execution. slows ability recognize mistakes
switching learning state. also slows recovery learning state
execution state.
results presented Figure 8 fall region LowerConfidenceThreshold changes zero fifty UpperConfidenceThreshold changes
equal LowerConfidenceThreshold difference ten units
LowerConfidenceThreshold. agent able perform
maximum number correct actions time provided simulation (4000 steps).
difference thresholds larger ten, total number correct actions
decreases since agent takes longer change learning execution states.
Figure 8 also shows length initial learning period increases LowerConfidenceThreshold increases. longer agent spends learning less time
perform actions. Therefore, Figure 8 shows, optimal values (for
scenario) thresholds ten LowerConfidenceThreshold fifteen
UpperConfidenceThreshold. provides agent learning period
long enough agent learn necessary skills (so majority actions performs correct) short enough allow agent perform maximum
amount actions (which 3923 actions according Figure 8).
determining best values confidence thresholds, scenario simulated two settings (exp1 exp2 ) 4000 step simulation repeated
100 times encompass time variations might exist simulations. Since
two settings prepared two learning methods mind, important look
importance given agent methods setting. Table 1 shows
average values weights recall classification methods learning (see section
4.2) setting.
Table 1 shows that, expected, recall method influence proposed
actions agent faced conditions expert (exp1 )
faces different conditions (exp2 ). first setting, weight recall method
makes likely (more 50 % chance) actions proposed method
338

fiLearning Observation Agent Software Images

Setting
exp1
exp2

Recall Weight
0.509
0.317

Classification Weight
0.491
0.683

Table 1: average weights recall classification methods setting
executed, even though actions proposed classification method also
executed. second setting, classification method influence
proposed actions largest weight. agent able use recall
method often follow sequence actions expert facing
conditions different observed expert (see section 4.2).
overview results simulating scenario two settings presented
Table 2. table compares time spent learning state execution
state, number actions agent able execute, many actions
appropriate also time simulation step learning executing
actions. results Table 2 present average values standard deviation
running simulation 100 times.

Time spent
learning (s)
Time spent
execution (s)
Total actions
executed
Amount
appropriate actions
Step time
learning state
Step time
execution state

average
stdev
average
stdev
average
stdev
average
stdev
average
stdev
average
stdev

Expert
2.415
0.606
4000
0
100 %
0
0.603
0.151

Apprentice
(exp1)
1.62
0.12
10.435
0.957
3905
0
100 %
0
17.052
1.305
2.672
0.245

Apprentice
(exp2)
134.98
22.503
23.365
6.017
3709.25
31.13
92.95 %
7.73 p.p.
35.834
2.129
6.363
1.815

Table 2: Overview results simulation virtual hand scenario
results Table 2 show agent faces conditions experts
observes (exp1 ) spends less time learning state able perform actions
throughout simulation faces different conditions (exp2 ). agent
faces different conditions (exp2 ) spends time learning needs acquire
knowledge requires knowledge come different sources improve
generalization classification method (see section 4.2). leads agent spend
time discovering different experts learn also causes agent return
learning state often.
addition, high standard deviation values show agent faces different
conditions (exp2 ) number actions executed throughout simulation, time spent
learning time spent executing actions differs considerably. variation directly
339

fiCosta & Botelho

associated randomness observed experts. time simulation run,
apprentice observes different subsets available experts different sequence,
changes knowledge retained agent throughout simulation affects
number actions executed time spent learning executing actions.
Table 2 also shows facing conditions (exp1 ) actions executed
agent appropriate, whereas facing different conditions (exp2 ) approximately 92% totality executed actions appropriate. important
indicator agent likely return learning state, starting
execute actions, facing different conditions (exp2 ).
average time spent simulation steps, Table 2 shows cases,
simulation step longer agents learning. expected since
agent learning state perform various tasks discovering expert
agents, comparing software image software images discovered experts,
acquiring snapshots storing information, proposing actions conditions
snapshots evaluating proposals (see section 4).
executing actions, simulation step apprentice agents longer
simulation step experts, understandable given apprentice agents
require processing expert. Besides using two methods proposing actions
also necessary take account influence internal evaluation. step
time executing actions also longer apprentice agent facing different
conditions (exp2 ), influences time spent executing actions. Even though
apprentice agent executes fewer actions (only 3709), compared facing
conditions (3905), spends time executing fewer actions. effect
observed time spent simulation step learning.
happens facing different conditions agent needs acquire
knowledge increases amount information agents memory. Since
recall classification methods learning need process information contained
memory, larger amount information longer takes process it. effect
felt learning executing actions agent uses methods
cases.
closer look simulation results presented Figure 9, shows progress
apprentice agents, terms number correct actions executed,
throughout simulation. figure also shows progress state learning
process (see section 4) throughout simulation apprentice agent. provide
clearer presentation, results combined groups 100 simulation steps.
Figure 9 shows that, apprentice agents face conditions expert
(exp1 ) short learning period (of 200 steps) actions execute
correct. agent faces different conditions experts observes (exp2 ),
initial learning period lasts little longer (about 300 steps) approximately 90%
executed actions correct.
agent also experiences additional learning periods (of short duration) throughout
simulation. additional learning periods mainly caused evaluation activity
mechanism forces apprentices switch learning state facing conditions
observed (see section 4.3). Although subsequent learning periods affect
time spent learning short duration. Figure 9 shows, overall
340

fiLearning Observation Agent Software Images

Figure 9: behaviour apprentice agent two settings throughout simulation

permanence subsequent learning periods exceed 3% total
simulation steps.
5.2 Results Mountain Car Scenario
mountain car scenario compares expert agents, specialized climbing mountains, learning observation agents (LbO) learn observing experts performing task learn reinforcement learning agents (RL) learn
reinforcements. participant agents face conditions, is, placed
mountain starting points. observed experts also face
conditions learning observation agent.
results present comparison based number actions, distance travelled
time spent reaching top mountain (the goal simulation).
results also determine average time simulation step agent much
time takes agent learn, is, much time takes agent reach
top mountain first time.
341

fiCosta & Botelho

Since scenario provides goal, simulation time-frame grouped attempts
achieving goal. attempt lasts variable number simulation steps,
maximum duration 500 simulation steps. agent achieves goal 500
steps attempt completed regarded successful. 500 steps goal
achieved, attempt regarded failed. simulation lasts 50000 attempts,
provide reinforcement learning agents enough time testing hypotheses
provide best results.
Table 3 presents summary important aspects scenario amount
time, number attempts, number actions distance travelled agent reach
top first time. table also shows many times agent reached top
mountain, average time simulation step average amount simulation
steps attempt reach goal. data Table 3 obtained running
scenario 100 times encompass time variations. students t-test used ensure
statistical relevance data collected running scenario.

Time reach top
first time (ns)
Attempts

reaching top first
time
Actions executed
reach top first
time
Distance travelled
reach top first
time
Number times
reached top
Average
simulation step time
(ms)
Average simulation steps spent
attempt

Expert

Apprentice
(LbO)

Apprentice
(RL)

T-TEST
(LbO - RL)

30

3300

14660

2.2 107

1

1

105

3.4 1010

136

278

52471

3.2 1010

2.73

2.73

610.37

2.5 109

50000

50000

49895

2.9 1010

0.28

4.94

0.31

2.7 1039

136

136.01

229.92

4.9 1012

Table 3: Overview results simulation mountain car scenario
Table 3 shows that, expected, expert agent exhibits best results aspects.
table also shows learning observation agent outperforms reinforcement
learning agent aspects exception time simulation step.
learning observation agent also gets close results expert aspects
exception time takes reach top simulation step time.
compared reinforcement learning agent, simulation step learning
observation agent lasts longer amount processing behind decision.
342

fiLearning Observation Agent Software Images

Nevertheless, learning observation agent requires less simulation steps complete
attempt, is, reach goal. main reason longer simulation step
learning observation agent uses two methods proposing actions (the
recall classification methods explained section 4.2) requires additional
effort combining results choosing best action them. agent also
perform set tasks, like example internal evaluation (see section
4.3). performance software used agent likely improved future
versions, would lead improvement simulation step time.
Although simulation step reinforcement agent takes less time, agent requires
steps attempts reach top mountain first time eventually
takes time learn reach top mountain results Table 3
show. puts reinforcement agent last place considering time takes
reach top first time. results t-test Table 3 show data
acquired simulations statistically relevant.

Figure 10: General view results second scenario
343

fiCosta & Botelho

addition information achieving goal first time, also important
know agents performed throughout simulation. Figure 10 shows progress
expert two apprentice agents (learning observation reinforcement
learning) throughout simulation terms distance travelled, number times
reaching top number simulation steps required reach top. clearer
presentation, results combined groups 100 attempts reach goal.
attempt lasts number simulation steps ranges 136 500, depending
number steps necessary reach top mountain (see Table 3).
results presented Figure 10 show learning observation agent performs
better reinforcement learning agent considered dimensions. figure shows
learning observation agent requires less simulation steps (in comparison
reinforcement learning apprentice) go starting point top mountain
learning it. simulation steps spent attempt stabilizes 136
(which number steps spent expert) right agent learnt
task climbing mountain. learning observation agent also requires less attempts
learn reach top (1 attempt shown Table 3).
distance travelled learning observation agent also smaller
distance travelled reinforcement learning agent. value distance,
learning observation agent, stabilizes 2.73 (the expert Table 3 shows)
right agent learns task climbing mountain, unlike happens
reinforcement learning agent. Figure 10 shows, even long learning period,
reinforcement learning agent able learn efficient way climb
mountain (the one requires least amount actions smallest distance). Even
lowest values fluctuations number actions travelled distance
still far away obtained learning observation agent.
Besides inabilities, reinforcement learning agents capability reaching
goal fluctuates 90% 100% times, almost end simulation.
means even learning reach goal, reinforcement learning agent
always able it, something also observed total number times
agent reaches top mountain Table 3. contrast, learning observation
agent exhibits stable results learning task reaching top mountain.

6. Conclusions Future Work
adoption learning observation solutions relatively new computer science and,
latest approaches show, still development (Sullivan, 2011; Kulic et al., 2011;
Tan, 2012; Fonooni, Hellstrom, & Janlert, 2012). exception work (Costa
& Botelho, 2011, 2012) Machado Botelhos (2006) work, contributions
learning observation focused robotic agents physical properties. Software
agents even software used robots neglected. Even Machado Botelhos
work limitations since addressed problem learning vocabulary
allow generalizations acquired knowledge. means that, unlike approach,
apprentice agent able learn control mechanisms neither capable dealing
conditions different observed expert.
344

fiLearning Observation Agent Software Images

Therefore, learning approach clearly contributes advance state art
learning observation, providing software agents learning solution different
methods usually applied software agents. Unlike robotic
approaches learning observation, software approach limited software
agents. also used robotic agents minor adaptations, since physical
actions controlled reflected software events. Even data collected robotic
sensors needs software representation (however complex be), since core
robot effectively running program high level decisions made program.
Thus, software approach provides broader solution approaches limited
physical properties robotic environments.
experimental results section 5 show software agents capable improving
ability perform task using approach. first scenario also shows
classification method learning essential situations agent facing
exactly sequence events expert. Namely, situations agent
faced conditions different faced experts observed.
usual scenarios learning observation, reported literature, address cases
apprentice expert agents face exactly conditions. kind
situation ideal sequence learning, reason method one
used learning observation approaches. inclusion classification
method, ability learn observation extended problems domains.
combination classification method recall method, inspired
sequence learning, ensures agent able adapt, itself, larger number
circumstances, including usual learning observation scenarios.
Besides combination two methods, approach also provides internal
evaluation mechanism constantly tests agents knowledge. allows agent
know needs acquire knowledge acquired sufficient knowledge
therefore execute actions. approach also offers possibility using external
feedbacks enhance agents evaluation, gives agents ability knowing
actions execute appropriate.
agents internal evaluation enables learning observation agents enhance
knowledge even stop observing experts start using acquired knowledge,
since starting use knowledge may go back learning state.
one major drawbacks previous learning approaches. usual way handling
manually feeding new examples whenever agent requires them. case
approach agent able decide needs return learning
state, observe experts. process require intervention since agent
find experts collect new training examples.
application approach two distinct scenarios shows adapted
different domains. scenarios also show amount time taken learning
approach decide actions execute sometimes high. However, second
scenario shows, agents able achieve goal less time reinforcement
learning approach, even situations already shown literature
adequate reinforcement learning. learning observation agents also able
achieve approximately results experts observe.
345

fiCosta & Botelho

Although apprentice agents take time choose actions execute
experts, difference smaller first scenario. Considering that, first scenario, experts knowledge expressed rules second scenario,
approach, unlike reinforcement learning, able cope increase complexity
terms number rules required express experts knowledge.
Besides providing new insight learning software agents, software
image, approach also contribute software embodiment problem. Although
main purpose directed learning observation, software image also allows visible
software agents represent called body. future work
may continue developing software image better adapt software embodiment
problem.
also intend continue testing approach different scenarios, especially
situations actions effects agent environment.
situations part effect actions visible environment. expect
results similar situation effects actions visible
environment visible effects enough distinguish actions. However,
visible effects enough distinguish actions, agents learn
effects actions might able learn properly.
example, effect action one removing number environment
adding agents internal memory effect action two removing number
environment subtracting agents internal memory. actions
different effects agent, visible effects environment exactly same.
situation, agent learns visible effects actions
able distinguish two actions.
Finally, also consider improving approach open possibility agent
performing task radically different tasks performed observed
experts. agent able use acquired knowledge way allows
perform new tasks never observed before.

Acknowledgments
paper reports PhD research work, Doctoral Program Information Science
Technology ISCTE-Instituto Universitario de Lisboa. partially supported
Fundacao para Ciencia e Tecnologia PhD Grant number SFRH/BD/44779/2008
FCT project PEst-OE/EEI/LA0008/2013

References
Alissandrakis, A., Nehaniv, C., & Dautenhahn, K. (2002). Imitation ALICE: learning
imitate corresponding actions across dissimilar embodiments. Systems, Man
Cybernetics, Part A: Systems Humans, IEEE Transactions on, 32 (4), 482496.
Argall, B. D., Chernova, S., Veloso, M., & Browning, B. (2009). survey robot learning
demonstration. Robotics Autonomous Systems, 57 (5), 469483.
Bandura, A. (1977). Social Learning Theory. Prentice Hall.
346

fiLearning Observation Agent Software Images

Billard, A., & Hayes, G. (1999). Drama, connectionist architecture control learning
autonomous robots. Adaptive Behavior, 7, 35-64.
Billing, E. A., Hellstrom, T., & Janlert, L. E. (2010). Behavior Recognition Learning
Demonstration. Proceedings IEEE International Conference Robotics
Automation, Alaska.
Billing, E., Hellstrom, T., & Janlert, L. E. (2011). Simultaneous control recognition
demonstrated behavior. Tech. rep., UmeaUniversity, Department Computing
Science.
Botelho, L. M., & Figueiredo, P. (2004). body living room tell
agent. Proceedings AAMAS 2004 Workshop Balanced Perception Action
Embodied Conversational Agents.
Byrne, R. W. (1999). Imitation without intentionality. Using string parsing copy
organization behaviour. Animal Cognition, 2 (2), 6372.
Chernova, S. (2009). Confidence-based Robot Policy Learning Demonstration. Phd,
Carnegie Mellon University.
Cleary, J. G., & Trigg, L. E. (1995). K*: Instance-based Learner Using Entropic
Distance Measure. 12th International Conference Machine Learning, pp. 108
114. Morgan Kaufmann.
Clegg, B. A., DiGirolamo, G. J., & Keele, S. W. (1998). Sequence learning. Trends
Cognitive Sciences, 2 (8), 275281.
Comite, F. D. (2005). Java Platform Reinforcement Learning Experiments. Journees
Problemes Decisionnels de Markov et Intelligence Artificielle PDMIA 2005, 100107.
Costa, P. A. M., & Botelho, L. M. (2011). Software Image Learning Observation.
Antunes, L., Pinto, H. S., Prada, R., & Trigo, P. (Eds.), Proceedings 15th
Portuguese Conference Artificial Intelligence, pp. 872884, Lisbon, Portugal.
Costa, P. A. M., & Botelho, L. M. (2012). Learning Observation Software Agents.
Proceedings 4th International Conference Agents Artificial Intelligence
(ICAART 2012), 2 (Agents), 276281.
Dautenhahn, K., & Nehaniv, C. L. (2002). agent-based perspective imitation.
Imitation animals artifacts, 140.
Demiris, J., & Hayes, G. (2002). Imitation dual-route process featuring predictive
learning components: biologically plausible computational model. Dautenhahn,
K., & Nehaniv, C. (Eds.), Imitation animals artifacts (MIT Press edition).,
pp. 327361. Cambridge.
Etzioni, O. (1993). Intelligence without Robots (A Reply Brooks). AI MAGAZINE, 14,
7-13.
Fonooni, B., Hellstrom, T., & Janlert, L.-E. (2012). Learning High-Level Behaviors
Demonstration Semantic Networks. Proceedings 4th International Conference Agents Artificial Intelligence (ICAART).
Hajimirsadeghi, H., & Ahmadabadi, M. (2010). Conceptual imitation learning: application human-robot interaction. Machine Learning, 331346.
347

fiCosta & Botelho

Heyes, C., & Ray, E. (2000). significance imitation animals?. Advances
Study Behavior, 29, 215245.
Kulic, D., Ott, C., Lee, D., Ishikawa, J., & Nakamura, Y. (2011). Incremental learning
full body motion primitives sequencing human motion observation.
International Journal Robotics Research, 31 (3), 330345.
Lopes, M., & Santos-Victor, J. (2007). developmental roadmap learning imitation
robots.. IEEE transactions systems, man, cybernetics. Part B, Cybernetics
: publication IEEE Systems, Man, Cybernetics Society, 37 (2), 30821.
Machado, J., & Botelho, L. (2006). Software agents learn observation (short
paper). Proceedings International Joint Conference Autonomous Agents
MultiAgent Systems.
Machado, J. a. (2006). Imagem Visual Corpo de Software: Aquisicao de Vocabulario por
Observacao. Masters thesis, ISCTE.
Maistros, G., & Hayes, G. (2004). Towards Imitation System Learning Robots.
Vouros, G., & Panayiotopoulos, T. (Eds.), Methods Applications Artificial
Intelligence, pp. 246255. Springer Berlin / Heidelberg.
Martin, B. (1995). Instance-Based learning : Nearest Neighbor Generalization. Masters thesis, University Waikato, Hamilton, New Zealand.
Mataric, M. J. (1997). Studying Role Embodiment Cognition. Cybernetics
Systems, 28, 457-470.
Meunier, M., Monfardini, E., & Boussaoud, D. (2007). Learning observation rhesus
monkeys.. Neurobiology learning memory, 88 (2), 2438.
Mitchell, T. (1997). Machine learning. McGraw-Hill Publishing Company, New York.
Quick, T., Dautenhahn, K., Nehaniv, C., & Roberts, G. (2000). essence embodiment:
framework understanding exploiting structural coupling system
environment. AIP conference proceedings, pp. 649660. Citeseer.
Ramachandran, V. (2000). Mirror neurons imitation learning driving force behind
great leap forward human evolution. Edge Website article http://www. edge.
org/3rd\ culture/ramachandran/ramachandran\ p1. html.
Ramachandran, V. (2003). emerging mind: Reith Lectures 2003. Profile Books.
Rao, R. P. N., Shon, A. P., & Meltzoff, A. N. (2004). Bayesian Model Imitation
Infants Robots. Imitation Social Learning Robots, Humans,
Animals, 217-247.
Rizzolatti, G., Fadiga, L., & Gallese, V. (1996). Premotor cortex recognition
motor actions. Cognitive brain research, 3 (2), 131141.
Sullivan, K. (2011). Multiagent Hierarchical Learning Demonstration. International
Joint Conference Artificial Intelligence, 28522853.
Sun, R. (2001). Introduction Sequence Learning. Lecture Notes Computer Science,
110.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning. MIT Press, Cambridge, MA.
348

fiLearning Observation Agent Software Images

Tan, H. (2012). Implementation Framework Imitation Learning Humanoid
Robot Using Cognitive Architecture. Zaier, D. R. (Ed.), Future Humanoid
Robots - Research Applications, chap. 10. InTech.
Wood, M. A. (2008). agent-independent task learning framework. Phd thesis, University
Bath.

349

fiJournal Artificial Intelligence Research 47 (2013) 71-93

Submitted 11/12; published 05/13

Identifying Class Maxi-Consistent Operators Argumentation
Srdjan Vesic

VESIC @ CRIL . FR

CRIL - CNRS
Rue Jean Souvraz SP 18
F 62307 Lens Cedex
FRANCE

Abstract
Dungs abstract argumentation theory seen general framework non-monotonic
reasoning. important question then: class logics subsumed
instantiations theory? goal paper identify study large class
logic-based instantiations Dungs theory correspond maxi-consistent operator, i.e.
function returns maximal consistent subsets inconsistent knowledge base.
words, study class instantiations every extension argumentation system
corresponds exactly one maximal consistent subset knowledge base. show
attack relation belonging class must conflict-dependent, must valid, must
conflict-complete, must symmetric etc. Then, show attack relations serve
lower upper bounds class (e.g. attack relation contains canonical undercut
member class). using results, show existing attack relations whether
belong class. also define new attack relations members
class. Finally, interpret results discuss general questions, like: added
value argumentation setting? believe work first step towards achieving
long-term goal, better understand role argumentation and, particularly,
expressivity logic-based instantiations Dung-style argumentation frameworks.

1. Introduction
question whether Dungs (1995) abstract theory used general framework nonmonotonic reasoning drawn particular amount attention among researchers artificial
intelligence. precisely, question is: existing new approaches reasoning seen
instantiations Dungs theory? certainly general question. Furthermore, different
approaches suppose available knowledge represented different form. paper studies problem setting one given finite inconsistent set classical propositional logic
formulae, refer knowledge base. number approaches dealing
inconsistent information: notable example paraconsistent logics (Priest, 2002) one
able draw (but all) conclusions inconsistent set formulae. Indeed,
paraconsistent logic allows subset inferences could obtained using classical logic
knowledge. examples dealing inconsistent knowledge include belief
revision (Gardenfors, 1988), belief merging (Konieczny & Perez, 2011) voting (Arrow, Sen, &
Suzumura, 2002). completely precise, note approaches one given
multiset instead set, example several voters express knowledge preferences number agents stating / voting proposition important. However,
paper, suppose information represented form set.
c
2013
AI Access Foundation. rights reserved.

fiV ESIC

Generally speaking, call operator function provides way go inconsistent knowledge base set subsets knowledge base. Examples operators are:
function returning maximal set inclusion consistent subsets knowledge base, called maxiconsistent operator, function returning maximal cardinality consistent subsets knowledge
base, called maxi-card operator, function returning consistent subsets knowledge base...
understand extent Dungs theory used general framework
reasoning, essential study link result obtained applying operator
knowledge base extensions argumentation framework F = (Arg(), R),
set , denote Arg(S) set arguments built S, R
relation used identifying attacks arguments. papers (Cayrol, 1995; Caminada & Amgoud, 2007; Amgoud & Besnard, 2009, 2010; Amgoud & Vesic, 2010; Gorogiannis
& Hunter, 2011) studying notions somehow related link knowledge
base corresponding argumentation framework. However, since work Dung (1995),
almost papers studying link operator instantiation Dungs theory. Cayrol (1995) showed instantiation Dungs theory using stable semantics direct
undercut attack relation, corresponds maxi-consistent operator. argumentation community,
one-to-one correspondence sometimes identified main objection pure logic-based
argumentation, additional value constructing argumentation framework
said questionable (since computing extensions applying maxiconsistent operator). However, recent work Vesic van der Torre (2012) shows
exists large class logic-based instantiations Dungs abstract theory two interesting
features: (i) returns extensions correspond maximal consistent subsets initial
knowledge base, (ii) result satisfies basic argumentation postulates (Caminada & Amgoud,
2007), e.g. consistency, closure... paper shows space logic-based instantiations
Dungs theory much larger believed.
previous result makes question class operators viewed
instantiations Dungs theory? even relevant research topic. aim
giving broad overview class. First note that, interestingly, rather big class
instantiations Dungs theory returning inconsistent results, showed Caminada Amgoud
(2007). However, one would normally prefer avoid type behaviour, study class
instantiations returning consistent results.1 Thus, long-term goal identify whole
class instantiations Dungs theory yield consistent result. However, certainly
hard task. start noticing that, given set , common well-known way deal
inconsistent information use maxi-consistent operator, i.e. select maximal consistent
subsets . Also, conjecture one biggest2 sub-classes class instantiations
returning consistent result class instantiations corresponding maxi-consistent operator.
first goal, main goal paper, study class. (Note
general approach would consider set maxi-consistent subsets selection function
f among maxi-consistent subsets. Thus, maxi-consistent sets would used
reasoning. However, present paper studies case maxi-consistent subsets
taken account since already captures significant number systems.)
1. Note consensus regarding postulates (e.g. indirect consistency), postulates
(e.g. direct consistency) enjoy much wider acceptance.
2. informally, sense: number known instantiations

72

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

particularly, paper aims answering following questions: properties
attack relations semantics used instantiations Dungs theory correspond maxiconsistent operators? necessary sufficient conditions attack relation
belongs class (under given semantics)? properties satisfy: must (not)
conflict-dependent, valid, symmetric, ... ? identify sub-classes attack relations belonging / belonging class? find lower / upper bound (in terms set
inclusion) class attack relations? existing (in literature) attack relations belong
class semantics? new attack relations belonging class?
paper organised follows: Section 2 introduces main notions argumentation theory use rest paper. Section 3 formally defines class instantiations corresponding maxi-consistent operator. Section 4 shows properties satisfied attack relations
belonging class. Section 5 identifies several classes attack relations (not-)corresponding
maxi-consistent operator. Section 6 shows (to best knowledge) existing attack relations literature whether belong class, also defines new attack relation
member class. last section concludes discusses related work.

2. Basics Argumentation
already mentioned, paper supposes one given set classical propositional logic
formulae . use well-known (e.g. Besnard & Hunter, 2001; Amgoud & Cayrol, 2002;
Gorogiannis & Hunter, 2011) logic-based approach instantiating Dungs theory. L denotes
set well-formed formulae, ` stands classical entailment, logical equivalence.
use notation MC() set maximal consistent subsets .
logical argument defined pair (support, conclusion).
Definition 1 (Argument). argument pair (, ) minimal (for set
inclusion) consistent set formulae ` .
argument = (, ), use function Supp(a) = denote support
Conc(a) = denote conclusion.
Example 1. Let = {, , }. = ({, }, ), b = ({ }, )
c = ({, }, ) arguments constructed . example,
Supp(a) = {, } Conc(a) = .
given set formulae S, denote Arg(S) set arguments constructed
S. Formally, Arg(S) = {a | argument Supp(a) S}. Let Arg(L) denote set
arguments constructedSfrom language propositional logic. given set
arguments E, denote Base(E) = aE Supp(a). suppose function Arg defined L
function Base defined Arg(L); slightly abusing notation, sometimes write
Arg (respectively Base) restriction functions set formulae (respectively
arguments).
Definition 2 (Argumentation system). argumentation system (AS) pair (A, R)
Arg(L) set arguments R binary relation. pair (a, b) R, say
attacks b. also sometimes use notation aRb instead (a, b) R.
73

fiV ESIC

order simplify notation, explicitly mention argumentation system
clear context argumentation system refer to. Since arguments built
formulae, suppose attack relation defined specifying condition every
two arguments b, attacks b condition definition
attack relation satisfied. example, condition conclusion logically
equivalent negation conclusion b. suppose attack relations defined
set Arg(L) Arg(L), every set Arg(L), use restriction attack
relation set AA. why, order simplify notation, simply write R attack
relation defined set Arg(L) Arg(L) well restriction attack relation
every set A, Arg(L).
order determine mutually acceptable sets arguments, different semantics
introduced argumentation. first introduce basic notions conflict-freeness defence.
Definition 3 (Conflict-free, defence). Let F = (A, R) AS, E A.
E conflict-free exist arguments a, b E R b
E defends every b b R exists c E
c R b.
Let us define commonly used semantics.
Definition 4 (Acceptability semantics). Let F = (A, R) B A. say set B
admissible conflict-free defends elements.
B complete extension B defends arguments contains
arguments defends.
B preferred extension maximal (with respect set inclusion) admissible set.
B stable extension B conflict-free \ B, exists b B
b R a.
B semi-stable extension B complete extension union set
B set arguments attacked B maximal (for set inclusion).
B grounded extension B minimal (for set inclusion) complete extension.
B ideal extension B maximal (for set inclusion) admissible set contained
every preferred extension.
argumentation system F = (A, R) denote Extx (F); or, slight abuse
notation, Extx (A, R) set extensions respect semantics x. use abbreviations
c, p, s, ss, g respectively complete, preferred, stable, semi-stable, grounded ideal
semantics. example, Extp (F) denotes set preferred extensions argumentation system F.
Example 2. Let F = (A, R) argumentation framework = {a, b, c, d} R =
{(b, c), (c, b), (b, d), (c, d)}. two preferred/stable/semi-stable extensions: {a, b} {a, c};
three complete extensions: {a}, {a, b} {a, c}; one grounded/ideal extension: {a}.
74

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

3. Defining Problem Setting
now, specified to, knowledge base , construct argumentation system F =
(Arg(), R), then, using chosen semantics, calculate extensions. Since components
system except semantics attack relation fixed, whether instantiation
corresponds maxi-consistent operator depends exclusively two components. next
definition provides formal definition mean saying instantiation Dungs
framework corresponds maxi-consistent operator. idea function Arg
bijection MC() extensions corresponding argumentation system.
Definition 5 (MC Ext). Let x argumentation semantics. say attack relation R
satisfies (MC Extx ) every finite set propositional formulae
Arg bijection MC() Extx (Arg(), R)
means every set MC(), holds Arg(S) Ext(Arg(), R)
every E Ext(Arg(), R), exists MC() E = Arg(S). example, say
attack relation R satisfies (MC Extc ) every finite , Arg
bijection MC() Extc (Arg(), R). Sometimes, clear context
semantics refer semantics important, use simplified notation
(MC Ext). say attack relation R falsifies (MC Extx ) R satisfy
(MC Extx ). following example shows attack relation satisfy (MC Exts ).
Example 3. Consider attack relation known defeating rebut, denoted Rdr defined
follows: two arguments b, say attacks b write aRdr b
Conc(a) ` Conc(b). attack relation falsifies (MC Exts ). see why, sufficient find
set formulae Arg bijection MC() (Arg(), Rdr ). end,
consider = { , } denote F = (Arg(), Rdr ). see MC() = {S1 , S2 }
S1 = { } S2 = { }. Denote E1 = Arg(S1 ) E2 = Arg(S2 ). Exts (F) 6=
{E1 , E2 } Rdr satisfy (MC Exts ). Consider argument = ({ }, ),
note E1 . Observe every argument b Arg(), bRdr
Conc(b) ` ( ). words, every argument b Arg(), b attacks
Conc(b) ` . Recall Definition 1 know every argument b,
Supp(b) ` Conc(b). Thus, every argument b Arg(), bRdr Supp(b) ` .
Since = { , } argument b Arg() Supp(b) ` .
Thus, argument attacked argument E2 . means E2 stable extension
F. Consequently, Arg bijection MC() Exts (F). Hence, Rdr falsifies
(MC Exts ).
3.1 Complete Incomplete Systems
two ways study link instantiated argumentation system F (containing
arguments attacks them) corresponding knowledge base (containing formulae). first scenario follows:
choose attack relation R semantics x
start finite knowledge base
75

fiV ESIC

consider system F = (Arg(), R), containing arguments built
compare result obtained using operator one obtained calculating
extensions F
case, say obtained argumentation system complete. Every complete system
infinite number arguments, every complete system F, exists finite system
F 0 F F 0 equivalent. formally define equivalence argumentation
systems topic present paper; details reader invited consult
literature subject (Amgoud, Besnard, & Vesic, 2011).
second possibility converse:
given attack relation R semantics x,
start argumentation system F = (A, R),
define set formulae used supports arguments F, is, define
def
= Base(A)
compare result obtained using operator one obtained calculating
extensions F
obtained argumentation system may incomplete, sense =
6 Arg(Base(A)).
important difference two scenarios. Namely, first case,
arguments built considered calculating Extx (F). second case,
contains formulae A, F, formulae equally represented. Let us illustrate
situation.
Example 4. Let R defined as: every a, b Arg(L), (a, b) R exists
Supp(b) Conc(a) . Let us use preferred semantics. Let F = (A, R)
= {a, b} = ({, }, ) b = ({}, ). case, since b attacks
vice versa, extension E = {b}. Note conclusion accepted argument
. However, take union formulae used supports arguments F,
obtain = {, , }. two maximal consistent subsets knowledge base:
MC() = {{, }, {, }}.
clear setting similar previous example, or, generally,
second scenario, one cannot expect Arg bijection MC() Ext(A, R). But,
incomplete argumentation system stand for? obtained? conclude system
6= Arg(Base(A)) meaningless would certainly hasty. Let us consider
question detail. Namely, know missing arguments added intelligent
agent. first add missing arguments calculate extensions
complete version system? two possible answers: (1) yes, must add missing
arguments order take account available information; (2) no, since given
argumentation system arguments constructed (in case monological argumentation) uttered (in case dialogical argumentation). arguments (1) (2) make
sense different applications: first possibility corresponds case want simulate
resource unbounded agent, take account information (where information seen
76

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

formulae) known agent(s). Note disadvantages since so, ignore
argumentational representation problem. second possibility used want
know output argumentation system is, take account fact
arguments constructed (e.g. lack computational resources, since
given argumentation framework representing dialogue everything said).
Note numerous works 1990s (Pollock, 1992; Vreeswijk, 1997; Loui, 1998) yield
conceptual philosophical arguments supporting partial computation (i.e. incomplete systems).
important part Vreeswijks (1997) work devoted defining constructing complete
argumentation systems. Loui (1998) discusses philosophical difference demonstrative
reasoning non-demonstrative reasoning claims realistic (i.e. resource-bounded)
setting, reasons demonstrative, process disputation essential reasoning. Note, however, none frameworks instantiation Dungs system,
formalisations works differ lot framework studied paper. goal
present paper argue complete systems sense better incomplete
ones (or vice versa), study possibilities limits related instantiating Dungs abstract theory. analyse difference complete incomplete systems,
find necessary point exist, order make context research
question clear. second scenario, reasonable expect correlation
result obtained directly F. why, rest paper suppose
first scenario.

4. Properties Relations Satisfying (MCExt)
section, analyse properties attack relations satisfying (MC Ext). first show
condition satisfied, function Base : Ext(F) MC() inverse function
function Arg : MC() Ext(F).
Proposition 1. Let R attack relation x acceptability semantics. relation R satisfies
(MC Extx ) then:
every MC(), = Base(Arg(S)),
every E Extx (F), E = Arg(Base(E)).
Proof. Let finite set propositional formulae let F = (Arg(), R).
Let MC() E = Arg(S). Since R satisfies (MC Ext), E Extx (F). Let
0 = Base(E) let us suppose 6= 0 . Let us study two cases.
Let \ 0 6= 0 \ 0 . means argument E
0 Supp(a) 0
/ S, contradiction.
Let 0 \ 6= 0 0 \ S. means argument E
0 Supp(a). Contradiction 0
/ S.
Since \ 0 = 0 \ = , = 0 ; words, Base(Arg(S)) = S.
Let E Extx (F) = Base(E). Since R satisfies (MC Extx ), exists
unique 0 MC() Arg(S 0 ) = E. Let us prove = 0 .
77

fiV ESIC

Let us suppose \ 0 6= let \ 0 . means argument
E Supp(a). Contradiction fact
/ S0.
Suppose 0 \ 6= 0 0 \ S. 0 0 , conclude
exists E 0 Supp(a). Contradiction fact 0
/ S.
\ 0 = 0 \ = , conclude = 0 . Thus, Arg(Base(E)) = E.

Let us illustrate result following example.
Example 5. Consider attack relation known direct undercut, denoted Rdu defined
follows: two arguments b, say attacks b write aRdu b
exists Supp(b) Conc(a) . known direct undercut satisfies (MC Exts )
(Cayrol, 1995). Proposition 1, see every , every MC(), holds
= Base(Arg(S)) and, interestingly, every E Exts (Arg(), Rdu ),
E = Arg(Base(E)).
previous result allows easily show attack relation satisfies (MC Ext),
every extension consistent base union arguments conclusions consistent.
Corollary 1. Let R attack relation x semantics. Let R satisfy (MC Extx ) let
finite set formulae. Denote F = (Arg(), R). Then, every E Extx (F), have:
Base(E) consistent

aE Conc(a) consistent
Proof. Let E Extx (F). Since R satisfies (MC Extx ), exists MC()
E = Arg(S). Proposition 1, obtain E = Arg(Base(E)). Since Arg injective function,
every 0 MC(), E = Arg(S 0 ) = 0 . Thus, = Base(E). Consequently, Base(E)
consistent set. clear
every argument E, Base(E) ` Conc(a). Since
Base(E) consistent, aE Conc(a) consistent well.
Note use previous result show attack relation satisfy (MC Ext).
Namely, attack relation returns extensions inconsistent bases, violates (MC Ext).
Corollary 2. Let R attack relation, x acceptability semantics. exists finite
knowledge base exists extension E Extx (Arg(), R) Base(E)
inconsistent, R satisfy (MC Extx ).
4.1 Conflict-Dependence Validity
subsection, study link satisfying (MC Ext) conflict-dependence
validity. attack relation conflict-dependent whenever argument attacks another one,
union supports inconsistent (Amgoud & Besnard, 2009).
Definition 6 (Conflict-dependent). Let R Arg(L) Arg(L) attack relation. say R
conflict-dependent every a, b Arg(L), (a, b) R Supp(a) Supp(b) `
.
78

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

prove conflict-dependence necessary condition satisfying (MC Ext).
completely precise, specify say semantics x returns conflict-free sets
every argumentation system (A, R), every E Extx (A, R), holds E
conflict-free respect R. semantics Definition 4 return conflict-free sets.
Proposition 2. Let R attack relation x semantics returning conflict-free sets. R
satisfies (MC Extx ), R conflict-dependent.
Proof. Let us suppose contrary, i.e. let R attack relation conflict-dependent, let
knowledge base let a, b Arg() aRb Supp(a) Supp(b) consistent.
Thus, exists set MC() Supp(a)Supp(b) S. Since R satisfies (MC Extx )
E = Arg(S) extension corresponding argumentation system F = (Arg(), R).
means a, b E. Contradiction assumption x returns conflict-free extensions.
Thus, R must conflict-dependent.
proved this, know relation satisfying (MC Ext) enjoys properties
conflict-dependent relations. example, shown attack relation conflictdependent, self-attacking arguments (Amgoud & Besnard, 2009).
Corollary 3. Let R attack relation x semantics returning conflict-free sets. R satisfies
(MC Extx ) every argument Arg(L), (a, a)
/ R.
Proof. Proposition 2, R conflict-dependent. Then, self-attacking
arguments (Amgoud & Besnard, 2009, Prop. 4).
means another way identify (some the) attack relations satisfying
(MC Ext): namely, attack relation exists self-attacking argument, given
attack relation falsifies (MC Ext) semantics returning conflict-free sets. Let us study
notion validity (Amgoud & Besnard, 2010).
Definition 7 (Valid). Let R Arg(L) Arg(L) attack relation. say R valid
every E Arg(L) holds E conflict-free, Base(E) consistent.
Let us show property incompatible conflict-dependence.
Proposition 3. exists attack relation conflict-dependent valid.
Proof. Let R attack relation suppose R conflict-dependent valid. Let
= ({}, ), b = ({}, ), c = ({ }, ) let E = {a, b, c}. Since R
valid Base(E) inconsistent, E conflict-free. Since R conflict-dependent,
(a, b)
/ R, (b, a)
/ R, (a, c)
/ R, (c, a)
/ R, (b, c)
/ R, (c, b)
/ R. Thus, E conflict-free.
Contradiction.
means attack relation R satisfies (MC Ext) must exist set E
conflict-free respect R whose base inconsistent.
Corollary 4. Let R attack relation x acceptability semantics returning conflict-free
sets let R satisfy (MC Extx ). Then, R valid.
79

fiV ESIC

proof previous fact consequence Proposition 2 Proposition 3. useful
since attack relation valid, immediately conclude violates (MC Extx )
(possible) semantics returning conflict-free sets.
general level, see asking every conflict-free set consistent base
demanding. Roughly speaking, due fact attacks binary whereas minimal
conflicts may ternary (or greater cardinality). authors argue obtain consistent
result, one concentrate admissibility conflict-freeness. example, Caminada Vesic (2012) claim n-ary attacks, n 3, simulated Dungs framework
throughout notion admissibility. Thus, idea future work could study alternative
condition, every admissible set consistent base.
4.2 Satisfying (MCExt) Different Acceptability Semantics
subsection, study properties related particular semantics. show attack
relation satisfies (MC Ext) stable semantics, satisfies semi-stable semantics also.
identify conditions attack relation satisfies (MC Ext) stable semantics. provide similar result preferred semantics. also identify sufficient condition
attack relation falsifies (MC Ext) complete semantics. Then, discuss case
single-extension semantics, like grounded ideal.
First, suppose R satisfies (MC Exts ). means every finite set formulae ,
function Arg bijection MC() Exts (Arg(), R). Since every finite set formulae
least one maximal consistent subset (even empty set) every , must
(Arg(), R) least one stable extension. Since stable extensions, stable
semi-stable semantics coincide (Caminada, 2006). Thus, obtain following proposition.
Proposition 4. Let R attack relation. R satisfies (MC Exts ) then:
every finite set formulae F = (Arg(), R), Exts (F) = Extss (F)
R satisfies (MC Extss ).
Let us prove case stable semantics, image respect Arg every
maximal consistent set extension base every extension consistent,
attack relation question satisfies (MC Ext).
Proposition 5. Let R attack relation. every set formulae F = (Arg(), R),
have:
MC(), Arg(S) Exts (F),
E Exts (F), Base(E) consistent
R satisfies (MC Exts ).
Proof. Let us prove R satisfies (MC Exts ). already know every MC(),
Arg(S) Exts (F). Let us suppose E Exts (F) let us prove exists unique set
MC() Arg(S) = E. prove set exists, uniqueness guaranteed
since S, 0 , 6= 0 Arg(S) 6= Arg(S 0 ) trivially holds. Thus, let us prove
exists MC() Arg(S) = E. Let 0 = Base(E) let us prove 0 MC()
80

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

Arg(S 0 ) = E. means contradiction, suppose 0 consistent maximal
consistent set. Then, exists 00 MC() 0 00 . assumptions
proposition, E 00 = Arg(S 00 ) stable extension F. also E ( E 00 . Since
stable extension proper subset another stable extension, E stable extension.
Contradiction. Thus, must 0 MC(). easy see E Arg(Base(E)) (namely,
every set arguments, applying function Arg base, obtain superset). Let
us prove Arg(S 0 ) = E. Suppose contrary. Then, E ( Arg(S 0 ). Since 0 MC()
Arg(S 0 ) Exts (F). Thus, E stable extension (since stable extension proper subset
another stable extension).
prove similar two conditions sufficient guarantee R satisfies (MC Ext)
preferred semantics.
Proposition 6. Let R attack relation. every set formulae F = (Arg(), R),
have:
MC(), Arg(S) Extp (F),
E Extp (F), Base(E) consistent
R satisfies (MC Extp ).
Proof property similar proof Proposition 5.
consequence two previous results, identify sufficient condition R
satisfies (MC Exts ) (MC Extp ).
Corollary 5. Let R attack relation. every set formulae F = (Arg(), R),
have:
MC(), Arg(S) Exts (F),
E Extp (F), Base(E) consistent
R satisfies (MC Exts ) (MC Extp ).
Proof. Since every stable extension preferred one (Dung, 1995), clear R satisfies
conditions Proposition 5 Proposition 6. applying propositions, R
satisfies (MC Exts ) (MC Extp ).
Let us show attack relation returns stable extension inconsistent base,
violates (MC Ext) stable, semi-stable, preferred complete semantics.
Proposition 7. Let R attack relation. exists finite set formulae
F = (Arg(), R) stable extension E Base(E) inconsistent, R falsifies
(MC Extx ) x {s, ss, p, c}.
Proof. supposed exists stable extension E Exts (F) Base(E) ` .
proved (Dung, 1995) every stable extension preferred complete one. also
know (Caminada, 2006) E must semi-stable extension. using Corollary 2, conclude
R satisfy (MC Ext) stable, semi-stable, preferred complete semantics.
81

fiV ESIC

Let us study case complete semantics. show possible attack
relation satisfy (MC Extc ). condition use result every argument
a, formula support, , exists argument b Arg()
b attacks a.
Proposition 8. Let R attack relation every finite set formulae , every
Arg(), every Supp(a), exists exists
b Arg() (b, a) R. Then, R satisfy (MC Extc ).
Proof. prove attack relation R satisfies condition proposition,
falsifies (MC Extc ). use proof contradiction. words, plan proof
follows: first, suppose R satisfies given condition. Second, means contradiction,
suppose R satisfies (MC Extc ). Third, draw conclusions obtain contradiction.
Fourth, reductio ad absurdum, conclude must R falsifies (MC Extc ).
So, let us start supposing condition proposition suppose R satisfies
(MC Extc ). Thus, Proposition 2, obtain R conflict-dependent. Since R satisfies
(MC Extc ), every , Arg bijection MC() Extc (Arg(), R). Consider
= {, , } denote F = (Arg(), R). clear MC() = {S1 , S2 } S1 = {, }
S2 = {, }. Since R satisfies (MC Extc ) Extc (F) = {E1 , E2 } E1 = Arg(S1 )
E2 = Arg(S2 ).
Let us obtain contradiction proving E3 = Arg({}) complete extension. First,
prove set conflict-free. Let a, b E3 . Since R conflict-dependent, (a, b)
/ R.
Thus, E3 conflict-free.
Let us prove E3 , b Arg() \ E3 , (a, b)
/ R
(b, a)
/ R. means contradiction, suppose contrary. conflict-dependence,
Supp(a) Supp(b) ` . must {, } Supp(a) Supp(b). Since support
every argument consistent, Supp(a) contains either . Contradiction fact
Arg({}). Thus, E3 admissible set.
Let us prove E3 defend arguments Arg() \ E3 . show this,
need prove every argument Arg() \ E3 attacked least one argument. Note
every Arg() \ E3 , holds E1 \ E2 E2 \ E1 . Without loss generality,
let E1 \ E2 . Let us prove attacked. Note every argumentation system, every
non-attacked argument complete extensions. Since
/ E2 , must attacked. sum
up:
E3 admissible set
E3 attack argument Arg() \ E3
Arg() \ E3 attack argument E3
every argument Arg() \ E3 attacked least one argument.
Thus, E3 complete extension. Contradiction claim Extc (F) = {E1 , E2 }.
reductio ad absurdum, conclude R satisfy (MC Extc ).
semantics always return unique extension, like grounded ideal
semantics? case, reasonable expect bijection MC()
82

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

set extensions, since several maximal consistent subsets . Let us formally
state fact.
Proposition 9. x semantics every argumentation system F |Extx (F)| =
1 attack relation R satisfies (MC Extx ).
Proof. Let = {, , }. Denote F = (Arg(), R). two maximal consistent subsets
, i.e. |MC()| = 2. Since supposed every argumentation system exactly one
extension semantics x, bijection MC() Extx (F).
previous simple result surprising. idea semantics one
extension contains arguments accepted according every point view.
Thus, expect link set formulae belonging minimal inconsistent
set extensions. Note sufficient conditions R identified (Gorogiannis
& Hunter, 2011) every finite set F = (Arg(), R) grounded
ideal semantics coincide extension exactly Arg( \ (1 . . . k ))
{1 , . . . , k } set minimal (for set inclusion) inconsistent subsets .

5. Identifying Classes Attack Relations (Not-)Satisfying (MCExt)
previous sections show identify properties attack relation satisfying (MC Ext)
must satisfy. also provide several results closely related choice specific acceptability semantics. section, identify classes attack relations satisfy, satisfy
(MC Ext), serve lower (upper) bounds (with respect set inclusion) (non-)satisfying
(MC Ext).
first show whole class symmetric attack relations violates (MC Ext)
semantics Definition 4.
Proposition 10. R symmetric attack relation, every x {s, ss, p, c, g, i}, R falsifies
(MC Extx ).
Proof. Proposition 9, see R violates (MC Extg ) (MC Exti ). Let us
prove acceptability semantics.
R symmetric attack relation, every conflict-free set admissible. Furthermore,
easy see case every maximal conflict-free set stable extension (and vice versa).
Since every finite argumentation system least one maximal conflict-free set, every finite
argumentation system using symmetric attack relation least one stable extension. Let R
symmetric relation suppose least one x {s, ss, p, c}, R satisfies (MC Extx ).
Corollary 4, conclude R valid. means exists finite propositional
knowledge base F = (Arg(), R) conflict-free set E Arg()
inconsistent base. Let E 0 Arg() maximal conflict-free set containing E, i.e.
E E 0 . Since E 0 maximal conflict-free set, stable extension F. Since E 0
stable extension, also semi-stable, preferred complete one. Since Base(E 0 ) `
Corollary 2 implies x {s, ss, p, c}, R fails satisfy (MC Extx ).
identify another class attack relations satisfy (MC Ext). Namely,
show every (possible) attack generating many attacks falsifies (MC Ext). First,
83

fiV ESIC

need formally define mean many attacks. introducing notion
conflict-completeness.
Definition 8 (Conflict-complete). Let R Arg(L) Arg(L) attack relation. say
R conflict-complete every minimal conflict C L (i.e. every inconsistent
set whose every proper subset consistent), every C1 , C2 C C1 6= , C2 6= ,
C1 C2 = C, every argument a1 Supp(a1 ) = C1 , exists argument a2
Supp(a2 ) = C2 (a2 , a1 ) R.
Intuitively, attack relation conflict-complete two sets form minimal conflict,
every argument built one two sets attacked argument set.
notion inspired desire describe properties class existing (and new) attack
relations. example, canonical undercut conflict-complete.
show attack relation conflict-complete, falsifies (MC Ext) stable,
semi-stable, preferred complete semantics.
Proposition 11. Let R attack relation. R conflict-complete R satisfy
(MC Extx ) x {s, ss, p, c}.
Proof. Let R conflict-complete attack relation let us use proof contradiction. Thus,
suppose exist x {s, ss, p, c} R satisfies (MC Extx ) obtain contradiction. Proposition 2, R conflict-dependent. Let = {, , }. Let
F = (Arg(), R) E = Arg({}) Arg({ }) Arg({}). prove E stable
extension F. First, prove E conflict-free. Let a, b E suppose (a, b) R.
conflict-dependence, obtain Supp(a) Supp(b) ` . Contradiction definition E,
since two arguments E union supports inconsistent. Now,
prove E attacks every argument Arg() \ E. Let a0 Arg() \ E. three cases.
Case 1: Supp(a0 ) = {, }. case, since R conflict-complete, a0 attacked
least one argument set Arg(). Case 2: Supp(a0 ) = {, }. conflictcompleteness, argument attacked argument set Arg({ }). Case 3:
Supp(a0 ) = { , } also similar, since a0 attacked argument support
{}. conclude E Exts (F). easy see Base(E) ` . Proposition 7 implies
R satisfy (MC Extx ) every x {s, ss, p, c}. Contradiction.
previous part paper studies classes attack relations. Let us define

V
particular cases attack relations. = {1 , . . . , k } set formulae, notation stands
1 . . . k .
Definition 9 (Attack relations). Let a, b Arg(L). define following attack relations:
V
defeat: aRd b Conc(a) ` Supp(b)
direct defeat: aRdd b exists Supp(b) Conc(a) `
V
undercut: aRu b exists Supp(b) Conc(a)
direct undercut: aRdu b exists Supp(b) Conc(a)
V
canonical undercut: aRcu b Conc(a) Supp(b)
84

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

rebut: aRr b Conc(a) Conc(b)
defeating rebut: aRdr b Conc(a) ` Conc(b)
conflicting attack: aRc b Supp(a) Supp(b) `
rebut + direct undercut: aRrdu b aRr b aRdu b
big argument attack: aRba b exists Supp(b) Supp(a) ` .
first seven items previous definition list are, best knowledge,
attack relations used logic-based argumentation literature. Finding exact paper
occurs first time would quite challenging task. say rebut
defined Pollock (1987, 1992). Direct undercut introduced work Elvang-Gransson,
Fox, Krause (1993) Elvang-Gransson Hunter (1995). Undercut canonical undercut defined form Besnard Hunter (2000, 2001). best knowledge,
conflicting attack used argumentation literature. possibility use relation
mentioned (Besnard & Hunter, 2008, p. 35). show enough capture
presence inconsistency make good attack relation. Namely, show later attack
relation may return inconsistent extensions. Rebut + direct undercut added author
present paper, attempt investigate possibility use rebut detect conflicts
detected direct undercut, avoid using symmetric relation (rebut). name big argument
attack idea behind attack relation due L. van der Torre (personal communication,
June 18, 2012). attack relation coined goal show reasonable attack relations taking account conclusion argument. later show (Proposition 16)
attack relation also satisfies (MC Ext). (The idea behind name attack relation
sufficient use one argument per support since conclusions important.
arguments called big since one big argument plays role whole class normal
arguments, i.e. arguments support. attack relation called big since
used big arguments.)
reader easily check canonical undercut conflict-complete, leads
conclusion every attack relation containing canonical undercut (in set-theoretic sense)
also conflict-complete.
Proposition 12. Let R Arg(L) Arg(L) attack relation. Rcu R R conflictcomplete.
Thus, Proposition 11, conclude every attack relation containing canonical undercut
falsifies (MC Ext) stable, semi-stable, preferred complete semantics.
Corollary 6. Let R attack relation. Rcu R, R satisfy (MC Extx )
x {s, ss, p, c}.
Since Rcu Ru Rd Rc , obtain soon attack relation R contains Ru ,
Rd Rc falsifies (MC Ext) stable, semi-stable, preferred complete semantics.
Corollary 7. Let R attack relation. Ru R, Rd R Rc R R falsifies
(MC Extx ) x {s, ss, p, c}.
85

fiV ESIC

Hence, whole class attack relations based undercutting satisfy
(MC Ext). also identified another class attack relations, time based rebutting,
satisfy (MC Exts ). Namely, every attack relation contained defeating rebut must
falsify (MC Exts ). Observe proof following proposition based idea
Example 3.
Proposition 13. Let R attack relation. R Rdr R satisfy (MC Exts ).
Proof. Let us suppose contrary, i.e. let R satisfy (MC Exts ). Let = { , }
F = (Arg(), R). MC() = {S1 , S2 }, S1 = { } S2 = { }. Thus,
must Exts (F) = {E1 , E2 } E1 = Arg(S1 ) E2 = Arg(S2 ). obvious
argument a1 = ({ }, ) must a1 E1 . Since E2 stable extension,
must exist argument a2 E2 (a2 , a1 ) R. Thus, must Conc(a2 ) ` .
Consequently, Conc(a2 ) ` . Recall Supp(a2 ) = { } Supp(a2 ) = { }.
Contradiction.
Since Rr Rdr previous conclusion holds every relation contained Rr .
Corollary 8. Let R attack relation. R Rr R satisfy (MC Exts ).
Proof. Let R Rr . Since Rr Rdr , R Rdr . Proposition 13, R falsifies
(MC Exts ).

6. Particular Attack Relations (MCExt)
previous section, identified classes relations satisfy (MC Ext).
section, examine detail attack relations Definition 9.
using results presented now, prove direct undercut, direct defeat big
argument attack satisfy (MC Ext) stable, semi-stable preferred semantics, falsify
semantics, whereas attack relations fail satisfy (MC Ext) semantics.
Note proved (Cayrol, 1995) direct undercut satisfies (MC Ext) case
stable semantics. Proposition 4, conclude direct undercut satisfies (MC Ext)
semi-stable semantics. So, need prove Rdu satisfies (MC Ext) case
preferred semantics.
Proposition 14. Attack relation Rdu satisfies (MC Extx ) x {s, ss, p}.
Proof. already seen Rdu satisfies (MC Ext) stable semi-stable semantics. study case preferred semantics. Let finite set formulae F =
(Arg(), Rdu ). Since already proved (Cayrol, 1995) stable extensions F exactly
Arg(S), ranges MC(), since every stable extension preferred one,
clear every MC() Arg(S) preferred extension F. Thanks
Proposition 6, need prove base every preferred extension consistent.
result follows Prop. 34 Gorogiannis Hunter (2011), since relation Rdu satisfies
conditions proposition. Thus, direct undercut satisfies (MC Extp ).
Example 6. Consider relation ; inferring inconsistent knowledge base defined
follows: given set , write ; every maximal consistent subset ,
86

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

holds ` , ` stands classical entailment. Now, consider argumentation system
using direct undercut attack relation stable semantics. Proposition 14, conclude
every , Arg bijection MC() Exts (Arg(), Rdu ). Roughly speaking,
means set formulae inferred respect ; equal set
formulae conclusions extensions corresponding argumentation framework
based direct undercut stable semantics. formally: every L, every formula
L that: ; every extension E Exts (Arg(), Rdu ), exists
E = Conc(a).
Let us show Rdd also satisfies (MC Ext) stable, semi-stable preferred semantics.
Proposition 15. Attack relation Rdd satisfies (MC Extx ) x {s, ss, p}.
Proof. Let finite knowledge base F = (Arg(), Rdd ). Let MC(). easy
see E = Arg(S) stable extension F. Namely, E conflict-free since Rdd conflictdependent. Furthermore, every argument a0 Arg() \ E, must Supp(a0 ) contains
least one formulae \ S. fact, easy conclude exists argument
E Supp(a) Conc(a) (since maximal consistent set). Thus,
attacks a0 ends part proof shows E Exts (F). Since every stable
extension semi-stable preferred one, E Extss (F) E Extp (F). Let us
suppose E preferred extension F. Since direct defeat satisfies conditions Prop. 34
Gorogiannis Hunter (2011), conclude Base(E) consistent. Corollary 5,
conclude Rdd satisfies (MC Ext) stable preferred semantics. Now, Proposition 4
implies Rdd also satisfies (MC Extss ).
show necessary look conclusions arguments order satisfy
(MC Ext). Namely, show big argument attack satisfies (MC Ext) stable, semistable preferred semantics.
Proposition 16. Attack relation Rba satisfies (MC Extx ) x {s, ss, p}.
Proof. Let us first show every MC(), holds E = Arg(S) stable extension
F = (Arg(), Rba ). Since Rba conflict-dependent, E conflict-free. Let a0 Arg() \ E
let us prove exists E aRba a0 . Since a0
/ E, exists
Supp(a0 )
/ S. Since maximal consistent subset , ` . Let 0
minimal respect set inclusion consistent set 0 ` (such set exists since
consistent) let = (S 0 , ). argument since 0 minimal consistent set
deduced. see (a, a0 ) Rba . means image respect Arg
every maximal consistent subset stable extension F. Thus, also semi-stable
preferred extension F. Let us prove every corresponding F =
(Arg(), Rba ), base every preferred extension E F consistent set. Let E Extp (F)
= Base(E). Aiming contradiction, suppose contrary, i.e. let inconsistent set.
Let 0 minimal (with respect set inclusion) inconsistent set. Denote 0 = {1 , . . . , n }.
Let E argument n Supp(a), let a0 = (S 0 \ {n }, n ). clear
(a0 , a) Rba . Since E preferred extension, conflict-free, thus a0
/ E. Furthermore, E
admissible, must exist b E (b, a) Rba . Since (b, a) Rba ,
87

fiV ESIC

exists {1, . . . , n 1} Supp(b) ` . Since 0 , exists argument
c E Supp(c). According definition Rba , would mean b attacks
c. Contradiction fact E conflict-free. So, must consistent set. shows
every corresponding F = (Arg(), Rba ), base every preferred extension E
F consistent set. Corollary 5, conclude Rba satisfies (MC Ext) stable
preferred semantics. Now, Proposition 4 implies Rba also satisfies (MC Extss ).
already know relation satisfies (MC Ext) grounded ideal semantics.
using Proposition 8, easy conclude Rdu , Rdd Rba falsify (MC Extc ).
Let us prove remaining attack relations Definition 9 satisfy (MC Ext)
neither semantics Definition 4.
Proposition 17. Attack relations Rd , Ru , Rcu , Rr , Rdr , Rrdu , Rc falsify (MC Ext) stable,
semi-stable, preferred, complete, grounded ideal semantics.
Proof. Note already showed attack relation satisfies (MC Ext) grounded
ideal semantics. So, rest proof, need consider stable, semi-stable, preferred
complete semantics.
Let us first consider attack relations Rcu , Ru , Rd Rc . using Proposition 11,
conclude relations violate (MC Ext) stable, semi-stable, preferred complete
semantics.
obvious relations Rr Rc symmetric. Note Rdr also symmetric:
comes fact ` , ` ` . Thus, Proposition
10 yields conclusion satisfy (MC Ext) neither considered acceptability
semantics.
Let us study relation Rrdu . Let = {, , } F = (Arg(), Rrdu ). Let
us define set E arguments follows: E = {a Arg() | Conc(a) 6 Conc(a) 6
( ) Conc(a) 6 }.
Prove E conflict-free. Let a, b E let aRrdu b. Whether aRr b aRdu b
important, since cases, obtain Supp(a) Supp(b) ` . Contradiction, since
two formulae whose union inconsistent set. E conflict-free set.
Suppose a0 Arg() \ E. So, Conc(a0 ) Conc(a0 ) ( ) Conc(a0 ) .
cases, a0 attacked least one argument E, namely ({}, ),
({ }, ), ({}, ). So, E stable extension, consequently, semi-stable,
preferred complete extension. obvious Base(E) inconsistent set, Corollary 2
conclude Rrdu satisfy (MC Ext) stable, semi-stable, preferred complete
semantics.

7. Discussion, Related Future Work
paper identified studied large class instantiations Dungs abstract theory corresponding maxi-consistent operator. words, studied instantiations every
extension argumentation system corresponds exactly one maximal consistent subset
knowledge base. proved properties attack relations belonging class: must
conflict-dependent, must valid, must conflict-complete, must symmetric etc.
also identified attack relations serving lower upper bounds class. using
88

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

results, showed existing attack relations argumentation literature whether
belong class. also showed first time attack relation depending
arguments conclusions return reasonable results. Furthermore, showed relation
member (MC Ext) class.
Practical benefits work reported paper, generally, work devoted
studying link class instantiations Dungs theory operator, resumed
follows.
(I) case instantiation Dungs theory shown correspond existing operator.
First, work help validate argumentation-based approach showing
cases returns result comparable non argumentation-based approach. possible
criticism instantiation useless, since one obtain result without
using argumentation. But, far true; namely, argumentation used explanatory purposes. example, one wants know certain conclusion accepted,
argument conclusion presented. argument attacked arguments on. Also, might possible construct part argumentation graph
related argument question, thus better knowledge representation (i.e. ignoring
parts knowledge base unrelated argument one wants concentrate on).
second benefit type work help reduce computational complexity
using simpler approach cases result obtained argumentation-based approaches non argumentation-based approaches same. Please note work
category (capturing operator instantiation Dungs theory) far limited
case maxi-consistent operator, shown Vesic van der Torre (2012)
exists large class instantiations abstract argumentation theory returning consistent
result substantially different one returned maxi-consistent operator.
(II) case instantiation Dungs theory correspond existing operator.
Working links instantiations Dungs theory operators even
beneficial case instantiation abstract argumentation theory corresponding known operator happens found. distinguish three possible situations.
(a) case instantiation calculates useful result obtained operator, operator unknown now. case, new operator discovered thanks
argumentation. question then, situations use argumentative approach,
apply operator? answer depends balance need computational
efficiency (which conjecture often side approach directly applying operator)
need represent knowledge format easy grasp, argue justify accepted
piece knowledge, usual advantages argumentation.
(b) case instantiation Dungs abstract theory returns useful result cannot
obtained operator. Recall operator function that, every finite knowledge
base, returns set subsets. But, argumentative approach could return result cannot
represented form, instance, argument (, ) extension, whereas (, )
not, 6= . Thus, expressive power operator-based approach might enough
distinguish subtleties. important question define instantiation
still open. Another relevant issue see context instantiations make sense
applied.
89

fiV ESIC

(c) case instantiation returns bad result. class regroups set instantiations
representing behaviour one would like avoid. general question: distinguish useful
bad instantiations? certainly hard one. Apart scientific debate, evaluation
include tests set benchmark examples. Note limits testing reasoning formalism
set benchmark examples pointed Vreeswijk (1995). Another, principled (and demanding) way proceed define set postulates satisfied
argumentation formalism (Caminada & Amgoud, 2007; Caminada, Carnielli, & Dunne, 2012).
remark, note fact instantiation may return inconsistent result,
mean completely useless. Namely, might cases arguments constructed
inconsistent knowledge base, one resolves existing inconsistencies argumentative approach, applies another inconsistency-tolerant approach.
Also, inconsistency handling use argumentation. Thus, still setting,
drastic case would first use argumentation another purpose (not dealing
inconsistencies) apply different approach reason inconsistency.
review related work. Maxi-consistent sets play major role characterization various forms non-classical logical reasoning (Bochman, 2001) belief revision
(Alchourron, Gardenfors, & Makinson, 1985). remainder section considers papers
link argumentation.
paper Cayrol (1995) one early works relating results obtained directly
knowledge base using argumentative approach. paper, shown direct
undercut satisfies (MC Ext) stable semantics, results semantics attack
relations provided. studied attack relations semantics, also
provided general study properties attack relation satisfying (MC Ext) must also satisfy.
Amgoud Vesic (2010) generalised result Cayrol (1995) case prioritised
knowledge base, showing Arg bijection preferred sub-theories (Brewka, 1989),
generalise maximal consistent sets case prioritised knowledge base, stable extensions corresponding preference-based argumentation system using direct undercut
attack relation weakest link principle preference relation.
Amgoud Besnard (2009, 2010) also studied link knowledge base corresponding argumentation system. papers introduced important notions like conflictdependence validity attack relation proved numerous results related consistency
underlying logic. However, note criterion (MC Ext) neither defined studied
papers; provided (Amgoud & Besnard, 2010, Corollary 1) link MC()
maximal conflict-free sets F = (Arg(), R). Furthermore, result proved hypotheses impossible satisfy: attack relation valid conflict-dependent,
impossible (as proved Proposition 3). results paper (Amgoud &
Besnard, 2010, e.g. Prop. 4) proved attack relation conflict-dependent
conflict-sensitive, case well-known attack relations. Consequently, majority negative results papers applicable minority
attack relations. Furthermore, examples papers often incomplete systems; thus,
surprising link MC(Base(A)) Ext(A, R) examples.
recent paper Gorogiannis Hunter (2011) studied properties attack relations
case Dung-style argumentation system instantiated classical propositional
logic. work related ideas, however, focus paper different. main
goal study extent Dungs theory used general framework reasoning.
90

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

technical side, concentrate studying properties class attack relations
satisfying (MC Ext) identifying attack relations serving lower upper bounds classes
relations non-satisfying (MC Ext).
One open questions find set conditions attack relation satisfies
conditions satisfies (MC Ext). recently, direct undercut direct
defeat known attack relations satisfying condition (Vesic, 2012). Consequently,
seemed space attack relations satisfying condition rather narrow (note similarity
direct undercut direct defeat). However, present paper shows Rba also belongs
(MC Ext), indicating class instantiations corresponding maxi-consistent
operator much larger.
formal framework studied paper classical propositional logic-based argumentation. vast majority ideas considerations present paper hold
instantiations Dungs theory, example setting studied Modgil Prakken (2013).
words, result obtained argumentation frameworks could also compared
obtained operator. slightly adapting definition operator, one study
questions: link result obtained argumentation system
obtained operator (from strict defeasible rules)? argumentation help us
find new operators? argumentation systems returning result cannot captured
operator? Answering questions certainly part future work.

Acknowledgments
author would like thank Leendert van der Torre assistance advice. useful
comments helped improve paper significantly. author also thanks three reviewers
helpful comments.
paper revised extended version conference paper: S. Vesic. Maxi-Consistent
Operators Argumentation. Proceedings 20th European Conference Artificial Intelligence (ECAI12), pages 810-815.
major part work paper carried author affiliated
Computer Science Communication Research Unit University Luxembourg. First,
author started work tenure ERCIM Alain Bensoussan Fellowship Programme, supported Marie Curie Co-funding Regional, National International Programmes (COFUND) European Commission. time, author also
funded National Research Fund, Luxembourg. Second, still University Luxembourg, author continued work paper FNR AFR postdoc project
supported National Research Fund, Luxembourg, cofunded Marie Curie
Actions European Commission (FP7-COFUND). Third, time finishing
work paper, author CRNS researcher affiliated CRIL.

References
Alchourron, C. E., Gardenfors, P., & Makinson, D. (1985). logic theory change: Partial
meet contraction revision functions. Journal Symbolic Logic, 50, 510530.
91

fiV ESIC

Amgoud, L., & Besnard, P. (2009). Bridging gap abstract argumentation systems
logic. International Conference Scalable Uncertainty Management (SUM09), pp.
1227.
Amgoud, L., & Besnard, P. (2010). formal analysis logic-based argumentation systems.
International Conference Scalable Uncertainty Management (SUM10), pp. 4255.
Amgoud, L., Besnard, P., & Vesic, S. (2011). Identifying core logic-based argumentation
systems. 23rd International Conference Tools Artificial Intelligence (ICTAI11),
pp. 633636.
Amgoud, L., & Cayrol, C. (2002). reasoning model based production acceptable arguments. Annals Mathematics Artificial Intelligence, 34, 197216.
Amgoud, L., & Vesic, S. (2010). Handling inconsistency preference-based argumentation.
Proceedings 4th International Conference Scalable uncertainty Management
(SUM10), pp. 5669.
Arrow, K. J., Sen, A. K., & Suzumura, K. (Eds.). (2002). Handbook Social Choice Welfare.
North-Holland.
Besnard, P., & Hunter, A. (2000). Towards logic-based theory argumentation. Proceedings
17th National Conference Artificial Intelligence (AAAI00), pp. 411416. AAAI Press
/ MIT Press.
Besnard, P., & Hunter, A. (2001). logic-based theory deductive arguments. Artificial Intelligence Journal, 128, 203235.
Besnard, P., & Hunter, A. (2008). Elements Argumentation. MIT Press.
Bochman, A. (2001). logical theory nonmonotonic inference belief change - numerical
methods. Springer.
Brewka, G. (1989). Preferred subtheories: extended logical framework default reasoning.
Proceedings International Joint Conference Artificial Intelligence (IJCAI89), pp.
10431048.
Caminada, M. (2006). Semi-stable semantics. Proceedings 1st International Conference
Computational Models Argument (COMMA06), pp. 121130. IOS Press.
Caminada, M., & Amgoud, L. (2007). evaluation argumentation formalisms. Artificial
Intelligence Journal, 171 (5-6), 286310.
Caminada, M., Carnielli, W., & Dunne, P. (2012). Semi-stable semantics. Journal Logic
Computation.
Caminada, M., & Vesic, S. (2012). extended conflict-freeness argumentation.. Proceedings
24th Benelux Conference Artificial Intelligence (BNAIC12), pp. 4350.
Cayrol, C. (1995). relation argumentation non-monotonic coherence-based entailment. Proceedings 14th International Joint Conference Artificial Intelligence
(IJCAI95), pp. 14431448.
Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person games. Artificial Intelligence Journal, 77,
321357.
92

fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION

Elvang-Gransson, M., Fox, J., & Krause, P. (1993). Acceptability arguments logical uncertainty. Proceedings 2nd European Conference Symbolic Quantitative
Approaches Reasoning Uncertainty (ECSQARU93), pp. 8590.
Elvang-Gransson, M., & Hunter, A. (1995). Argumentative logics: Reasoning classically
inconsistent information. Data Knowl. Eng., 16(2), 125145.
Gardenfors, P. (1988). Knowledge Flux Modeling dynamics epistemic states. Cambridge,
MA, MIT Press.
Gorogiannis, N., & Hunter, A. (2011). Instantiating abstract argumentation classical logic
arguments: Postulates properties. Artificial Intelligence Journal, 175, 14791497.
Konieczny, S., & Perez, R. P. (2011). Logic based merging. Journal Philosophical Logic, 40(2),
239270.
Loui, R. (1998). Process policy: Resource-bounded nondemonstrative reasoning. Computational Intelligence, 14(1), 138.
Modgil, S., & Prakken, H. (2013). general account argumentation preferences. Artificial
Intelligence, 195, 361397.
Pollock, J. (1987). Defeasible reasoning. Cognitive Science, 11(4), 481518.
Pollock, J. (1992). reason defeasibly. Artificial Intelligence Journal, 57, 142.
Priest, G. (2002). Paraconsistent logic. Gabbay, D., & Guenthner, F. (Eds.), Handbook Philosophical Logic, Vol. 6, pp. 287393. Dordrecht: Kluwer Academic Publishers.
Vesic, S. (2012). Maxi-consistent operators argumentation. 20th European Conference
Artificial Intelligence (ECAI12), pp. 810815.
Vesic, S., & van der Torre, L. (2012). Beyond maxi-consistent argumentation operators. 13th
European Conference Logics Artificial Intelligence (JELIA12), pp. 424436.
Vreeswijk, G. (1995). Interpolation benchmark problems defeasible reasoning. Proceedings
Second World Conference Fundamentals Artificial Intelligence (WOCFAI95),
pp. 453468.
Vreeswijk, G. (1997). Abstract argumentation systems. Artificial Intelligence Journal, 90, 225279.

93

fiJournal Artificial Intelligence Research 21 (2013) 205-251

Submitted 10/12; published 05/13

Analysis Watsons Strategies Playing Jeopardy!
Gerald Tesauro
David C. Gondek
Jonathan Lenchner
James Fan
John M. Prager

gtesauro@us.ibm.com
dgondek@us.ibm.com
lenchner@us.ibm.com
fanj@us.ibm.com
jprager@us.ibm.com

IBM TJ Watson Research Center, Yorktown Heights, NY 10598 USA

Abstract
Major advances Question Answering technology needed IBM Watson1
play Jeopardy!2 championship level show requires rapid-fire answers challenging
natural language questions, broad general knowledge, high precision, accurate confidence estimates. addition, Jeopardy! features four types decision making carrying
great strategic importance: (1) Daily Double wagering; (2) Final Jeopardy wagering; (3)
selecting next square control board; (4) deciding whether attempt
answer, i.e., buzz in. Using sophisticated strategies decisions, properly
account game state future event probabilities, significantly boost players
overall chances win, compared simple rule thumb strategies.
article presents approach developing Watsons game-playing strategies,
comprising development faithful simulation model, using learning MonteCarlo methods within simulator optimize Watsons strategic decision-making. giving detailed description game-strategy algorithms, focus
particular validating accuracy simulators predictions, documenting performance improvements using methods. Quantitative performance benefits shown
respect simple heuristic strategies, actual human contestant performance
historical episodes. extend analysis human play derive number
valuable counterintuitive examples illustrating human contestants may improve
performance show.

1. Introduction
Jeopardy! fast-paced, demanding, highly popular TV quiz show originated
US, airs dozens international markets. show features challenging
questions (called clues shows parlance) drawn broad array topics;
clues may embody manner complex ambiguous language, including vague
allusions hints, irony, humor wordplay.
rules game play regular episodes (Jeopardy! Gameplay, 2013) follows.
two main rounds play, wherein round uses board containing 30 squares,
organized five squares six different categories, square containing hidden
clue. Second-round clues higher dollar values, presumably reflecting greater difficulty.
typical play, square selected according category dollar amount
player control board, clue revealed read aloud host.
1. Registered trademark IBM Corp.
2. Registered trademark Jeopardy Productions Inc.
c
2013
AI Access Foundation. rights reserved.

fiTesauro, Gondek, Lenchner, Fan & Prager

host finishes reading clue, players may attempt answer, i.e., buzz in,
pressing signaling device. first player buzz obtains right attempt
answer; answer correct, players score increases clues dollar value,
whereas answer incorrect, players score decreases dollar value,
clue re-opened players attempt answer rebound.
One clue first round, two clues second round special Daily
Double status. player selected clue exclusive right answer,
must specify wager $5 either current score round limit, whichever
greater. game concludes single clue Final Jeopardy round.
players write sealed-bid wagers, 30 seconds write answer
clue revealed. player finishing highest dollar-value score3 wins
amount, continue playing next episode.
IBM began contemplating building computing system appear Jeopardy!
readily apparent undertaking would hugely daunting challenge
automated Question Answering (QA) technology. State-of-the-art systems time
extremely poor general open-domain QA, considerable difficulty questions
supporting evidence passages worded straightforward way. Building
DeepQA architecture, advancing performance Jeopardy! competitive level
human contestants, would ultimately require intense work four-year period
team two dozen IBM Researchers (Ferrucci, Brown, Chu-Carroll, Fan, Gondek,
Kalyanpur, ..., & Welty, 2010; Ferrucci, 2012).
Rather discussing Watsons QA performance, amply documented elsewhere, purpose paper address orthogonal significant aspect
winning Jeopardy!, namely, strategic decision-making required game play.
four types strategy decisions: (1) wagering Daily Double (DD); (2) wagering
Final Jeopardy (FJ); (3) selecting next square control board; (4) deciding whether attempt answer, i.e., buzz in. critical junctures game
often occur Final Jeopardy round playing Daily Doubles, wagering
required. Selecting judicious amount wager, based ones confidence, specific
game situation, likely outcomes remaining clues, make big difference
players overall chance win. Also, given importance Daily Doubles, follows
players square selection strategy control board result
high likelihood finding DD. Allowing ones opponents find DDs lead devastating consequences, especially playing Grand Champions caliber
Ken Jennings Brad Rutter. Furthermore, contestants optimal buzz-in strategy
change dramatically certain specific end-game scenarios. example, player whose
score half leaders score may need make desperation buzz
last clue order avoid guaranteed loss. Conversely, half leaders
score, correct strategy may never buzz in.
scant prior literature Jeopardy! game strategies, nearly qualitative heuristic, sole exception Final Jeopardy strategy, substantial
quantitative analysis embodied J! Archive (2013) Wagering calculator. Additionally, Dupee (1998) provides detailed analysis betting Final Jeopardy, particular
3. Multiple players may win finished tied first place. deviation strict zero-sum game
lead fascinating counter-intuitive strategies.

206

fiAnalysis Watsons Strategies Playing Jeopardy!

emphasis so-called two-thirds scenario, betting nothing may increase winning chances second-place player, provided least two-thirds
leaders score. qualitative guidelines aggressive conservative Daily Double betting also given, depending confidence category, ability win buzz,
positioning Final Jeopardy. specific last-clue DD bet presented best bet
either takes lead, drops exactly half leaders score (i.e., lock-tie), resulting
extra chances win. Harris (2006), one shows top contestants, provides numerous
qualitative insights strategic thinking championship level, including importance
seeking DDs bottom rows, wagering position Final Jeopardy, protecting
lead late game cautious buzzer.
article describes teams work developing collection game-strategy algorithms deployed Watsons live Jeopardy! contests human contestants.
knowledge, work constitutes first-ever quantitative comprehensive approach
Jeopardy! strategy explicitly based estimating optimizing players probability winning given Jeopardy! game state. methods enable Watson find
DDs faster humans, calculate optimal wagers buzz-in thresholds degree
precision going well beyond human capabilities live game play. brief overview
work (Tesauro, Gondek, Lenchner, Fan, & Prager, 2012) recently appeared special issue
IBM Journal Research Development. present article provides expanded
descriptions strategy algorithms, presents substantial new quantitative
documentation performance advantages obtained approach, compared
simple heuristic strategies well actual human strategies.
overall organization article follows. first provide section 1.1 glossary important technical terms notation used throughout article. Section 2
overviews general approach developing Jeopardy! simulator, use simulate contests Watson human contestants. Studying game-playing programs
simulation well-established practice computer games research. However, modeling
Jeopardy! much difficult undertaking traditional games like Checkers
Chess, due rich language content extensive imperfect information. essential
model statistical performance profiles human contestants, well tendencies wagering square selection, mining historical data contestant performance
thousands previously aired episodes. respect, Jeopardy! similar
imperfect-information games like Poker (Billings, Davidson, Schaeffer, & Szafron, 2002),
effective dynamic modeling ones opponents requisite ingredient strong
play computers humans. general overview followed sections 2.1-2.6
specific designs construction methodologies simulation component models,
emulating Daily Double placement, human performance Daily Doubles, Final Jeopardy,
regular clues square selection, well extensions models single-game
multi-game format. modeling section concludes section 2.7, presents
statistically meaningful validation study, documenting well various game statistics predicted simulator match actual statistics live matches Watson
human contestants. detailed Appendix 1, Watson played 100
Sparring Games appearing television, validation study specifically focuses final 55 games Watson faced extremely strong former
Jeopardy! champions.
207

fiTesauro, Gondek, Lenchner, Fan & Prager

Section 3 presents specific techniques designing, learning optimizing Watsons
four strategy modules course many simulated games. techniques span
range widely used methods current AI/OR research studies. Specifically, section 3.1
details approach DD wagering, combines nonlinear regression Reinforcement Learning train Game State Evaluator course millions simulated
games. Section 3.2 presents methods calculate Best-Response wagering strategy (a standard game-theoretic concept) Final Jeopardy using either offline online Monte-Carlo
sampling. Section 3.3 describes Watsons square selection strategy, important ingredient live Bayesian inference calculation probabilities various squares
containing Daily Double. Finally, section 3.4 documents Watson computes buzz-in
thresholds endgame states using combination Approximate Dynamic Programming
online Monte-Carlo trials, i.e., rollouts (Tesauro & Galperin, 1996; Bertsekas &
Castanon, 1999).
work led many new insights constitutes effective Jeopardy!
strategy, section 4 paper presents interesting counterintuitive
insights obtained, hope improving human contestant performance. Section 4.1 gives overview important decision boundaries found Watsons
Best-Response FJ strategy. Section 4.2 discusses important finding regarding human DD wagering, namely humans generally bet aggressively. Section 4.3
presents buzz threshold analysis yielding initial buzz thresholds surprisingly aggressive, rebound thresholds surprisingly conservative. Finally, section 4.4
discusses unusual seemingly paradoxical implications lock-tie FJ scenario,
leader must bet $0 guarantee win.
summarizing work lessons learned section 5, Appendix 1 provides details
Watsons competitive record, Appendix 2 gives mathematical details buzz
threshold calculation.
1.1 Glossary
section provide definitions various technical terms notation used subsequent sections describe simulation models, strategies, aspects Jeopardy! game
play.
A, B C - players highest, second highest third highest scores,
respectively, current scores.
Accuracy - probability player answer clue correctly, situations
answering mandatory (Daily Doubles Final Jeopardy).
Anti-two-thirds bet - Potential counter-strategy Two-thirds Final Jeopardy scenario (see Two-thirds bet). two-thirds bet, Bs score
4B-2A. less B less three-fourths A. Hence, could
guarantee win small bet 3A-4B. However, bet vulnerable
B making large bet significantly overtakes A.
Average Contestant model - model based aggregate statistics J! Archive
regular episode data (excluding special-case contestant populations).
208

fiAnalysis Watsons Strategies Playing Jeopardy!

Bet cover, Shut-out bet - Standard strategy leader, A, Final Jeopardy.
usually bets least 2B-A (frequently 2B-A+1). correct answer, score
least 2B, guarantees win.
Board Control - right select next clue; usually belonging player
gave last correct answer. Daily Doubles played player
control board.
Buzz attempt rate - Parameter b regular clue simulation model, denoting
average probability player attempt buzz clue.
Buzz correlation - regular clue model, quantity ij indicating degree
buzz-in decisions player j tend given clue
(see Correlation coefficient). two humans, ij = b (empirically 0.2), whereas
ij = 0 human Watson.
Buzzability - Short buzzer ability. probability given player winning
contested buzz multiple players buzz in.
Buzzing - Pressing signaling device, indicating player wishes attempt
answer clue. host finishes reading clue, first player buzz
allowed answer.
Champion model - model based aggregate statistics 100 best players
J! Archive dataset, ranked according number games won.
Correlation coefficient - simulator, quantity ij indicating degree
randomized binary events (Buzz/NoBuzz Right/Wrong) players j tend
given clue. simple example, suppose j 50%
chance answering Final Jeopardy correctly. Let P (xi , xj ) denote joint
probability correctness xi j correctness xj . correlation coefficient given ij = P (Right,Right) + P (Wrong,Wrong) - P (Right,Wrong) P (Wrong,Right). Note xi xj independent, four joint outcomes
equally likely, ij = 0. xi xj always match, ij = 1
always mismatch, ij = 1.
Exhibition Match - (See Appendix 1) televised two-game match, aired Feb.
2011, Watson competed Brad Rutter Ken Jennings, arguably
two best-ever human contestants (see Multi-game format).
Grand Champion model - model based aggregate statistics ten best players
J! Archive dataset, ranked according number games won.
Lockout, locked game - game state leaders current score cannot
surpassed opponents play remaining clues, leader
guaranteed win. Usually refers Final Jeopardy states leader
double opponents scores.
209

fiTesauro, Gondek, Lenchner, Fan & Prager

Lock-tie - Final Jeopardy situation player second place exactly
half leaders score. leader guaranteed win betting $0, enabling
second place player achieve tie first place betting everything answering
correctly.
Match equity - Objective function optimized Watson two-game Exhibition
Match, defined probability finishing first plus 0.5 times probability finishing
second. contrast, Watson simply maximized probability winning Sparring
Games.
Multi-game format - special-case format used finals Tournament
Champions, Exhibition Match Ken Jennings Brad Rutter. First,
second third place awarded based point totals two games.
event first-place tie, sudden death tie-break clue played. Depending
prize money, significant incentive finish second place.
QA - Short Question Answering. computing system suite Natural
Language Processing techniques used search for, evaluate, select candidate
answers clues.
Precision, Precision@b - regular clues, average probability player
answer correctly fraction clues (b) player chooses buzz
answer (Ferrucci et al., 2010).
Rebound - situation first player buzz gets clue wrong,
remaining players another chance buzz try answer.
Regular episode format - regular episodes, returning champion plays single
game two new challengers. First, second third place determined
point totals game, multiple players may finish tied first. player(s)
finishing first continue play next episode. little incentive
finish second, pays $1000 finishing third.
Right/wrong correlation - regular clue model, quantity ij indicating
degree correctness player j tend given clue
(see Correlation coefficient). two humans, ij = p (empirically 0.2), whereas
ij = 0 human Watson.
Rollouts - Extensive Monte-Carlo simulations used estimate probability
player winning given game state.
Sparring Games - (See Appendix 1) Two series practice games (Series 1, 2) played
Watson former Jeopardy! contestants. Series 1 games contestants selected typical average contestants appearing show. Series
2 games played champions, i.e., contestants reached finals
semi-finals annual Tournament Champions.
Tip-off effect - Information revealed initial incorrect answer helps rebound player deduce correct answer. example, clue asking New
210

fiAnalysis Watsons Strategies Playing Jeopardy!

Jersey university likely two plausible answers, Rutgers Princeton.
initial answer Princeton? ruled incorrect, rebounder
highly confident correct answer Rutgers?
Two-thirds bet - plausible Final Jeopardy strategy B cases B
least two-thirds score. Assuming makes standard bet cover least
2B-A, Bs winning chances optimized betting 3B-2A. bet,
B win whenever wrong, whereas larger bets, B also needs right.
strategy vulnerable counter-strategy (see Anti-two-thirds bet).

2. Simulation Model Approach
Since optimize Watsons strategies millions synthetic matches, important
simulations faithful enough give reasonably accurate predictions various
salient statistics live matches. Developing simulator required significant effort,
particularly development human opponent models.
use simulator optimize strategies well-established practice computer
games research. Simulated play provide orders magnitude data live game
play, suffer overfitting issues commonly encountered tuning
fixed suite test positions. usually easy devise perfect model
rules play, simulation-based approaches face significant challenge accurate models
opponent strategies required. traditional two-player zero-sum perfect-information
board games (Backgammon, Checkers, Chess, etc.) modeling normally required
one simply aim compute minimax-optimal line play, limited potential
model exploit suboptimal play opponents. contrast, repeated normalform games Prisoners Dilemma Rock-Paper-Scissors, one-shot equilibrium
strategy trivial compute insufficient win tournament competitions (Axelrod,
1984; Billings, 2000). best programs games employ degree adaptivity
and/or modeling based observed behaviors opponents. Poker another
prominent game opponent modeling essential achieve strong play (Billings et al.,
2002) . Playing equilibrium strategy opponent bluffing much little
would forego opportunity significantly boost ones expected profit.
contrast above-mentioned games, Jeopardy! domain introduces entirely
new modeling issues, arising natural language content category titles, clues,
correct answers. Obviously simulator cannot generate synthetic clues comparable
written shows writers, plausibly emulate actual contestant responses. Even basic analysis categories clues (e.g., categories tend
similar, co-occurrence likelihood categories board, type information
provided clues, type mental process needed infer correct response,
clue difficulty calibrated based round dollar value) seemed daunting
prospects success seemed remote. Likewise, modeling distributions human contestant capabilities thousands categories, correlations abilities across
different categories, seemed equally implausible.
Due considerations, initial simulator design based extremely
simplified approach. avoided attempt model games language content,
decided instead devise simplest possible stochastic process models various
211

fiTesauro, Gondek, Lenchner, Fan & Prager

events occur step game. plan examine accurately
simulator could predict outcomes real Watson-vs-human Jeopardy! matches,
refine models needed correct gross prediction errors. turned out,
simple simulation approach predicted real outcomes much accurately initially
anticipated (see section 2.7 below), major refinements necessary.
noteworthy enhancement simple stochastic process models occurred
2010, Watson acquired ability dynamically learn revealed answers
category (Prager, Brown, & Chu-Carroll, 2012). effect substantial, Watsons accuracy improved 4% first clue last clue category.
captured effect using historical data: category simulated game would
paired randomly drawn historical category, sequence five right/wrong
Watson answers known prior processing. Instead stochastically generating
right/wrong answers Watson, simulator used recorded sequence, embodied tendency better later clues category. ability simulate
learning effect instrumental ultimate development Watsons square selection
algorithm, describe section 3.3.
stochastic process simulation models informed by:
(i) properties game environment (rules play, DD placement probabilities,
etc.)
(ii) performance profiles human contestants, including tendencies wagering
square selection;
(iii) performance profiles Watson, along Watsons actual strategy algorithms;
(iv) estimates relative buzzability Watson vs. humans, i.e., often player
able win buzz two contestants attempting buzz in.
primary source information regarding (i) (ii) collection comprehensive
historical game data available J! Archive (2013) web site. obtained fine-grained
event data approximately 3000 past episodes, going back mid-1990s, annotating
order clues played, right/wrong contestant answers, DD FJ wagers,
DD locations. eliminating games special-case contestants (Teen, College,
Celebrity, etc. games), remaining data provided basis model DD placement
(section 2.1), models human contestant performance Daily Doubles (section 2.2),
Final Jeopardy (section 2.3), regular clues (section 2.4), square selection (section 2.5).
devised three different versions human model, corresponding three different levels contestant ability encountered Watsons matches human contestants (see Appendix 1 details). Average Contestant model fitted
non-tournament game data appropriate model Watsons opponents
Series 1 sparring games. Champion model designed represent much stronger
opponents Watson faced Series 2 sparring games; developed model
using data 100 best players dataset, ranked number games won. Finally, Exhibition Match Ken Jennings Brad Rutter, devised Grand
Champion model informed performance metrics 10 best players. Since
212

fiAnalysis Watsons Strategies Playing Jeopardy!

Exhibition Match used multi-game format (1st, 2nd 3rd place determined
two-game point totals), developed specialized DD FJ wagering models Game 1
Game 2 match, described section 2.6.
2.1 Daily Double Placement
calculated joint row-column frequencies J! Archive data Round 1 Round
2 DD placement; Round 2 frequencies illustrated Figure 1. analysis confirms
well-known observations DDs tend found lower rows (third, fourth
fifth) board, basically never appear top row. However, surprised
discover also column dependencies, i.e., columns likely
contain DD others. example, DDs likely appear first column,
least likely appear second column. (We speculate4 shows
producers place DDs fashion.)

Figure 1: Illustration row-column frequencies second-round DD placement 3000
previous Jeopardy! episodes. Red denotes high frequency blue denotes low
frequency.

Additional analytic insights data include: (i) two second-round DDs never
appear column. (ii) row location appears set independently
column location, independently rows DDs within game. (iii)
Round 2 column-pair statistics mostly consistent independent placement, apart
constraint (i). However, specific column pair frequencies
exhibit borderline statistically significant differences independent placement model.
Based analysis, simulator assigns DD location Round 1,
first DD location Round 2, according respective row-column frequencies.
4. noted second column often features pop-culture categories (TV shows, pop music, etc.)
could account relative paucity DDs.

213

fiTesauro, Gondek, Lenchner, Fan & Prager

remaining Round 2 DD assigned row unconditionally, column assigned conditioned first DD column.
2.2 Daily Double Accuracy/Betting Model
Round 2 DD bets vs. score

Round 2 DD bets vs. time

4500

3800
3600

4000

3400
3200

3500
Mean bet

Mean bet

3000
3000
2500

2800
2600
2400

2000

2200
2000

1500


B
C

1000
0

5000

10000
15000
Player score

20000


B
C

1800
1600
25000

0

5

10
15
20
Previously revealed clues round

25

30

Figure 2: Average Round 2 mean DD bets human contestants first place (A), second
place (B) third place (C), function player score (left), clues played
round (right).

Based appropriate historical statistics J! Archive regular episode dataset,
set mean DD accuracy parameter human contestant models 64% Average Contestants, 75% Champions, 80.5% Grand Champions. Bets made
human contestants tend round number bets $1000 $2000, rarely exceed
$5000. main dependencies observed players lead tend bet
conservatively, become extremely conservative near end game, presumably
protect lead going Final Jeopardy. dependencies clearly seen
Figure 2, plot average bets functions player score clues played
second round.
wagering tendencies built Average Contestant model,
surmised (correctly turned out) much stronger Champion Grand Champion
players would quickly realize need bet DDs extremely aggressively playing
Watson. models therefore employed aggressive heuristic strategy
would bet nearly everything, unless heuristic formula indicated player close
mathematically certain win.
2.3 Final Jeopardy Accuracy/Betting Model
historical dataset obtained J! Archive reveals mean human accuracy answering Final Jeopardy correctly approximately 50% average contestants, 60%
Champions, 66% Grand Champions. Furthermore, statistics eight
possible right/wrong triples, also clear accuracy positively correlated among
contestants, correlation coefficient F J 0.3 providing best fit data.
214

fiAnalysis Watsons Strategies Playing Jeopardy!

use parameter values simulating stochastic FJ trials, wherein implement draws
three correlated random binary right/wrong outcomes, means correlations tuned
appropriate values. performed first generating correlated real numbers
using multi-variate normal distribution, applying suitably chosen thresholds
convert 0/1 outcomes desired mean rates (Leisch, Weingessel, & Hornik, 1998).
many draws required determine precise win rate given FJ score combination, also implement lower-variance simulation method. Rather generating
single stochastic outcome triple, simulator evaluates eight outcome triples, weighted
analytically derived probabilities combination.
Second-place (B) FJ bet distribution
1

0.8

0.8
B bet / score

bet / score

First-place (A) FJ bet distribution
1

0.6

0.4

0.2

0.6

0.4

0.2

0

0
0.5

0.6

0.7
0.8
B score / score

0.9

1

0.5

0.6

0.7
0.8
B score / score

0.9

1

Figure 3: Distribution human FJ bets first-place player (left) second-place
player B (right), normalized leader score, function B/A ratio.
important factor FJ wagering score positioning, i.e., whether player
first place (A), second place (B) third place (C). develop stochastic process
models likely contestant bets, first discarded data lockout games (where
leader guaranteed win), examined numerous scatter-plots
shown Figure 3. see high density line bets corresponding well-known
strategy betting cover case Bs score doubles 2B. Likewise, two high
density lines plot Bs bets, one B bets everything, one B bets
enough overtake A. Yet considerable apparent randomization apart
known deterministic wagering principles.
thorough examination, decided segment wagering data six groups:
used three-way split based strategic breakpoints (as detailed section 4.1) Bs
score relative score (less 2/3, 2/3 3/4, 3/4), plus
binary split based whether B least double Cs score. devised
wagering models A, B, C5 choose among various types betting logic,
probabilities based observed frequencies data groups. example, model
B case (B 3/4 A, B 2C) bets follows: bet bankroll (i.e., nearly everything)
5. Curiously enough, saw evidence Cs wagers vary strategic situation, implemented
single betting model C covering six groups.

215

fiTesauro, Gondek, Lenchner, Fan & Prager

26% probability, keepout C (i.e., B-2C) 27% probability, overtake
(i.e., slightly A-B) 15% probability, two-thirds limit (i.e., 3B-2A)
8% probability, various types random bets remaining 24% probability
mass.

B
C

Real
65.3%
28.2%
7.5%

Model
64.8%
28.1%
7.4%

Table 1: Comparison actual human win rates model win rates historical replacement 2092 non-locked FJ situations past episodes.

betting models described designed solely match human bet distributions, informed human FJ win rates. However, subsequently verified
historical replacement technique models track actual human win rates quite
closely, shown Table 1. first measured empirical win rates A, B, C roles6
2092 non-locked FJ situations past episodes. took turns recalculating
win rate one role replacing bets role bet distribution corresponding model. models match target win rates well, considering
human bets likely reflect unobservable confidence estimates given FJ category.
satisfied human FJ model accurately fit historical data,
nevertheless room doubt accurately would predict human behavior
Sparring Games. notably, six data groups used estimate model
parameters contained hundred samples, error bars associated
estimated values likely large. could addressed performing
so-called second order Monte-Carlo trials (Wu & Tsang, 2004), using Gaussian draws
parameter values FJ trial instead constant values, concerned
significantly higher computational overhead approach. also possibilities contestant behavior might non-stationary time, attempt
model, contestants might alter behavior specifically play Watson. discuss later section 3.2, generally accepted FJ model basis
optimizing Watsons decisions, sole exception case Watson A,
B player may plausibly make two-thirds bet (see Glossary definition section 1.1).
2.4 Regular Clue Model
stochastic process model regular (non-DD) clues generates random correlated
binary triple indicating players attempt buzz in, random correlated binary
triple indicating whether players correct answer. case contested
buzz, buzz winner randomly selected based contestants relative buzzability
(ability win contested buzz, assumed equal all-human matches). mentioned
Glossary section 1.1, buzz-in outcomes governed two tunable parameters,
mean buzz attempt rate b buzz correlation b . right/wrong outcomes
6. human win rates sum 101%, reflecting 1% chance first-place tie.

216

fiAnalysis Watsons Strategies Playing Jeopardy!

Figure 4: Frequencies seven possible regular-clue outcomes J! Archive average contestant dataset.

likewise governed two parameters, mean precision@b (Ferrucci et al., 2010) simply
mean precision p, right/wrong correlation p . set four parameter values b,
b , p, p running extensive Monte-Carlo simulations many different parameter
combinations, selecting combination yielding best fit observed historical
frequencies seven possible outcomes regular clues, depicted Figure 4.
outcome statistics derived J! Archive records 150K regular clues.
parameter values obtained average contestants are: b = 0.61, b = 0.2, p = 0.87
p = 0.2. right/wrong correlation derived directly rebound statistics,
particular noteworthy: positive value reasonable, given correlations seen
FJ accuracy, might surprising due tip-off effect rebounds.
first player buzz gives wrong answer, eliminates plausible candidate could
significantly help rebound buzzer deduce right answer. surmise data
may reflect knowledge correlation 0.3 combined tip-off effect 0.1
produce net positive correlation 0.2.
Champion model, substantial increase attempt rate (b = 0.80)
slight increase precision (p = 0.89). Grand Champion model, estimated
increases values, b = 0.855 p = 0.915 respectively. depicted
Figure 5, also developed refined model segregating regular clue data according
round dollar value (i.e., row number), estimating separate (b, p) values
case. refinements make simulations accurate, meaningfully impact
optimization Watsons wagering square selection strategies. expect
slight improvement Watsons endgame buzzing could achieved using
separate (b, p) values, insufficient data Champions Grand Champions
estimate values. Hence deployed algorithm used constant (b, p) values clues.
2.5 Square Selection Model
human contestants tend select top-to-bottom order within given category,
also tend stay within category rather jumping across categories.
weak tendency select categories moving left-to-right across board. Based
observations, likely impact Watsons square selection, developed
217

fiTesauro, Gondek, Lenchner, Fan & Prager

Average Contestant Attempt Rate / Precision vs. Row Number
0.95

Mean Attempt Rate / Precision

0.9
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5

b(row)
b=0.61
p(row)
p=0.87

0.45
0.4
1

2

3

4

5
6
Row Number

7

8

9

10

Figure 5: Estimates Average Contestant buzz attempt rate (b) precision (p)
function round row number. Rows 1-5 denote first round clues, rows
6-10 denote second round clues.

Average Contestant model square selection stays current category
60% probability, otherwise jumps random different category. picking within
category high probability (90%) picking topmost available square.
contrast, model Champion Grand Champion square selection DD seeking based
known row statistics DD placement. Strong players generally exhibit Daily
Double seeking selecting squares, playing Watson, quickly
adopt overt DD seeking behavior.
2.6 Multi-game Wagering Model
Jeopardy! contests, winner determined performance single game.
However, show also conducts several annual tournaments, Tournament
Champions, final match utilizes point totals two games determine first,
second third place. clearly implies wagering strategies must differ Game 1
Game 2 match, need different single-game wagering.
Since limited multi-game match data available J! Archive (only
two dozen Tournament Champions final matches), would quite difficult model
expected wagering Jennings Rutter Exhibition Match purely historical
data. Fortunately, able make educated guesses considerably simplified
task. First, predicted would wager DDs aggressively games,
unless overwhelming lead. implied could continue use
aggressive heuristic DD model single games, revised definition constitutes
overwhelming match lead. Second, also expected bet aggressively
Final Jeopardy first game. meant could treat Game 1 FJ
DD situation, use revised aggressive heuristic model.
218

fiAnalysis Watsons Strategies Playing Jeopardy!

situation requiring significant modeling effort Game 2 FJ. generalized
definition A, B, C roles matches, based sum Game 1 score plus
two times Game 2 score. definition, established single-game strategies
A, B C carry two-game matches.
Given limited available match data, crude estimates could assigned
probabilities various betting strategies. However, clear data
wagering human champions much coherent logical observed wagering
regular episodes, champion wagers frequently satisfy multiple betting constraints.
observations guided development revised betting models Game 2 FJ.
example, case B legal generalized two-thirds bet (suitably defined
two-game matches), B also keep C, model B bets follows: bankroll
bet 35% probability, bet small random amount satisfies two-thirds
keepout-C limits 43% probability, bet satisfy larger two limits
22% probability.
2.7 Model Validation
first efforts validate simulators predictions occurred half-way
Watsons first series Sparring Games. point time, simulator
used develop Watsons Final Jeopardy wagering algorithm, simulator
basically running model Watson heuristic strategies Average Contestant model. predicted outcomes ex-post (after fact) predictions,
needed data live games set certain simulation parameter values, particularly
relating Watsons buzzability. encouraged see predicted rates
Watson winning game (62%), leading going Final Jeopardy (72%) winning
lockout (27%) within standard error 42 games actual rates (64%, 76%,
26% respectively). significant deviations low side predicted
final scores Watson (15800 vs. 18400 actual) humans (9300 vs. 10900 actual)
still within 95% confidence intervals.
start second series Sparring Games, able make ex-ante
(before fact) predictions, Watson actually played human champions.
predictions based mostly using J! Archive data tune parameters
Champion model, well semi-educated guesses regarding improvement buzzability
human champions, aggressively would seek wager Daily
Doubles. actual vs. predicted statistics reported Table 2.
ex-ante simulation stats turned remarkably close actual results;
rates Watson leading FJ, Watsons board control (i.e., often Watson selected
next square) human lockout rate differed one standard error.
examined much improvement could obtained ex-post recalibration
Champion model, based actual stats Sparring Games. seen Table 2,
best ex-post predictions failed significantly improve ex-ante predictions.
notable improvement Watson FJ lead human lockout rates, predictions
Watson lockout rate human final score noticeably worse.
219

fiTesauro, Gondek, Lenchner, Fan & Prager

Statistic
Watson win rate
Watson lockout
Watson FJ lead
Watson board control
Watson DDs found
Watson final score
Human final score
Human lockout

Actual
0.709 0.061
0.545 0.067
0.891 0.042
0.500 0.009
0.533 0.039
23900 1900
12400 1000
0.018 0.018

Ex-ante sim
0.724
0.502
0.806
0.516
0.520
24950
12630
0.038

Ex-post sim
0.718
0.493
0.830
0.515
0.517
24890
13830
0.023

Table 2: Comparison actual mean statistics ( std. error) 55 Series 2 Sparring Games
vs. ex-ante ex-post predicted results 30k simulation trials.

3. Optimizing Watsons Strategies Using Simulation Model
simulator described previous section enables us estimate Watsons performance given set candidate strategy modules, running extensive contests
simulation model Watson two simulated human opponents. Watson stochastic process models use performance metrics (i.e., average attempt rate, precision,
DD FJ accuracies) human models. parameter values estimated
J! Archive test sets, updated numerous times Watson improved
course project. Watson model also estimates buzzability, i.e., likelihood
win buzz humans various ability levels. estimates initially
based informal live demo games IBM Researchers, subsequently refined based Watsons performance Sparring Games. estimated Watsons
buzzability two humans 80% average contestants, 73% Champions,
70% Grand Champions.
Computation speed important factor designing strategy modules, since wagering, square selection buzz-in decisions need made seconds. Also,
strategy runs Watsons front-end, single server cores, 3000-core
back-end dedicated QA computations. result, Watsons strategy
modules run fast enough hundreds thousands simulated games performed
CPU hours. provides solid foundation evaluating optimizing
individual strategy components, presented below. strategy components
(endgame buzz threshold, endgame DD betting, Game 2 FJ betting) based
compute-intensive Monte-Carlo trials; slow perform extensive offline evaluation. Instead, strategies perform live online optimization single strategy decision
specific game state.
3.1 Daily Double Wagering
implemented principled approach DD betting, based estimating Watsons
likelihood answering DD clue correctly, estimating given bet impact
Watsons overall winning chances gets DD right wrong. former estimate
provided in-category DD confidence model. Based thousands tests
220

fiAnalysis Watsons Strategies Playing Jeopardy!

historical categories containing DDs, model estimates Watsons DD accuracy given
number previously seen clues category Watson got right wrong.
estimate impact bet winning chances, follow work Tesauro (1995)
using Reinforcement Learning (Sutton & Barto, 1998) train Game State Evaluator (GSE) course millions simulated Watson-vs-humans games. Given
feature-vector description current game state, GSE implements smooth nonlinear
function approximation using Multi-Layer Perceptron (Rumelhart, Hinton, & Williams,
1987) neural network architecture, outputs estimate probability Watson
ultimately win current game state. feature vector encoded information
scores three players, various measures remaining amount
play game (number remaining DDs, number remaining clues, total dollar value
remaining clues, etc.).
combination GSE in-category confidence enables us estimate E(bet), i.e.
equity (expected winning chances) bet, according to:
E(bet) = pDD V (SW + bet, ...) + (1 pDD ) V (SW bet, ...)

(1)

pDD in-category confidence, SW Watsons current score, V ()
game state evaluation DD played, Watsons score either increases
decreases bet. obtain optimal risk-neutral bet evaluating
E(bet) every legal bet, selecting bet highest equity. Sparring
Games, algorithm evaluated round-number bets (i.e., integer multiples $100),
due computational cost well possibility obtain extra winning chances
via first-place tie lock-tie scenario described section 1.1. Exhibition
Match, tie finishes possible, sped code enable evaluation
non-round wagers. accounted strange wager values subject
much discussion press among viewers.
practice, literal implementation risk-neutral betting according Equation 1
takes frightening amount risk, furthermore, calculation may contain least
three different sources error: (i) GSE may exhibit function approximation errors; (ii)
simulator used train GSE may exhibit modeling errors; (iii) confidence estimates
may errors due limited test-set data. therefore chose adjust risk-neutral
analysis according two established techniques Risk Analytics. First, added
penalty term Equation 1 proportional bets volatility (i.e., standard deviation
right/wrong outcomes). Second, imposed absolute limit allowable downside
risk bet, defined equity difference minimum bet actual
bet getting DD wrong. Due function approximator bias, latter technique
actually improved expectation cases, addition reducing risk. observed
certain endgame states neural net systematically betting much, due
underestimation lockout potential.
overall impact risk mitigation nearly one-third reduction average risk
individual DD bet (from 16.4% 11.3%), cost reducing expected winning
chances entire game 0.3%. Given Watson finds average 1.5-2.0
DDs per game (depending aggressively opponents also seek DDs), implies
equity cost per DD bet risk mitigation quite small, regarded overall
tradeoff highly favorable.
221

fiTesauro, Gondek, Lenchner, Fan & Prager

3.1.1 Illustrative Example
Figure 6 illustrates DD bet analysis operates, resulting bet depends
strongly in-category confidence. example taken one Sparring Games,
Watson got four consecutive clues right first category start Double
Jeopardy, found first DD attempting finish category. point,
Watsons score 11000 humans 4200. Watsons in-category confidence took maximum value, 75%, based gotten four four correct answers
previously category. Watson chose wager $6700, highly aggressive bet
human standards. (Fortunately, got DD clue right!)
(11000, 4200, 4200) Watson Daily Double Bet

(11000, 4200, 4200) Watson Daily Double Bet
0.8

0.8

Expected Winning Chances

Expected Winning Chances

0.9

0.7
0.6
0.5
0.4
DD wrong equity
DD right equity

0.3
0

2000

4000

0.75

0.7

0.65
conf 0.45
conf 0.55
conf 0.65
conf 0.75
conf 0.85
best bet

0.6

0.55
6000
Bet Amount

8000

10000

12000

0

2000

4000

6000
8000
Bet Amount

10000

12000

Figure 6: (left) Equity estimates getting DD right (top curve) wrong (bottom
curve). (right) Bet equity curves five differences in-category confidence levels,
45% 85%. Black dots show optimal risk-neutral bet increases
confidence.
left figure shows neural net equity estimates getting DD right (top curve)
wrong (bottom curve) various bet amounts. curves extremely smooth
gently decreasing slopes. right plot shows resulting equity-vs-bet curve
Watsons actual 75% confidence level (magenta curve), along four curves
different confidence values ranging 45% 85%. Black dots curve indicate
best risk-neutral bet, see bet steadily increases confidence,
$5 45%, approximately $9300 actual 75%, finally entire $11000
(hypothetical) confidence 85%.
also note effect risk mitigation, reduced Watsons actual bet
$9300 $6700. According extensive Monte-Carlo analysis bet, risk mitigation
reduced Watsons equity 0.2% (from 76.6% 76.4%), entailed significantly
less downside risk (more 10%) event Watson got DD wrong.
protection-to-cost ratio 50 1, consider risk mitigation provided
case inexpensive form disaster insurance, Watson team members
relieved see Watson risk lead DD bet.
222

fiAnalysis Watsons Strategies Playing Jeopardy!

3.1.2 Endgame Monte-Carlo Wagers
Series 2 Sparring Games, significantly boosted simulation speed regular
clues Final Jeopardy. enabled replacement neural net wagering endgame
states routine based live Monte-Carlo trials. analysis gives essentially perfect
knowledge bet achieves highest win rate simulation, although still subject
modeling errors confidence estimation errors. also eliminated primary weakness
Watsons DD strategy, neural net misevaluations endgames often resulted serious
errors could considerably exceed 1% equity loss. detailed section 3.1.3,
usage Monte-Carlo analysis endgame wagers yielded quite significant reduction
(more factor two) Watsons overall error rate DD betting.
clues remaining Final Jeopardy, dependence equity players
score exhibit complex behavior discontinuities, contrast smooth monotone
behavior observed early mid-game states. striking example plotted Figure 7.
endgame DD bet Series 2 Sparring Games Watson 19800,
humans 13000 14300, four remaining clues (two $400
two $800). Watson 4-for-4 category, translated 71.8% DD confidence.
(We opted conservative estimate 75% figure mentioned earlier, due
possible confidence estimation errors.)
see left right/wrong equity curves exhibit complex acceleration
deceleration, well periodic jumps periodicity $400. may reflect scores
discrete change occurs combinations remaining squares needed reach
certain FJ breakpoints, lockout. equity-vs-bet curve right also displays
interesting multi-modal behavior. peak lead-preserving bet around $3000.
$6400, curve begins steep ascent point lockout becomes
mathematically possible. curve continues rise $12000, correct
answer assures lockout, falls off.
(19800, 13000, 14300) Watson Daily Double Bet
0.76

0.9

0.74

0.8

0.72

Expected Winning Chances

Expected Winning Chances

(19800, 13000, 14300) Watson Daily Double Bet
1

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

2000

4000

6000

0.7
0.68
0.66
0.64
0.62
0.6
0.58

DD wrong equity
DD right equity

0

Equity @ 71.8% confidence

0.56
8000 10000 12000 14000 16000 18000 20000
Bet Amount

0

2000

4000

6000

8000 10000 12000 14000 16000 18000 20000
Bet Amount

Figure 7: MC DD bet analysis. (left) Equity estimates getting DD right (top curve)
wrong (bottom curve). (right) Bet equity curve Watsons estimated
in-category confidence 71.8%.

223

fiTesauro, Gondek, Lenchner, Fan & Prager

3.1.3 Performance Metrics Error Analysis
assessed performance neural net DD wagering two different methods. First,
noted improved win rate simulations compared Watsons previous DD
wagering algorithm, set heuristic betting rules tried safely add Watsons lead
safely catch up, without dropping certain strategically important score breakpoints.
heuristic rules embodied sound logic, suffered major limitation taking
Watsons in-category confidence account, would generate wager
regardless confidence.
Using heuristic DD betting rules, Watsons simulated win rate 61%.
neural net DD wagering using default confidence value every DD, win rate improved
64%. added emulation live DD confidence values simulation, result
jump win rate, 67%. regarded quite significant performance
improvement, given DD betting algorithm used 1.5-2.0 times per
game.
second performance metric utilizes extensive offline Monte-Carlo analysis many
neural network bets estimate average equity loss per DD bet, i.e., average difference
equity true best bet, highest simulated win rate, equity
bet selected neural net. figure approximately 0.6% per DD bet,
quite good, implied overhead improve Watsons win rate
via improved DD wagering less 1.2%. equity loss due large
errors endgame states. mentioned earlier, substantially reduced loss rate
implementing DD wagering endgames based live Monte-Carlo simulations.
reduced Watsons average equity loss per DD bet 0.6% 0.25%, half
loss rate resulting deliberately imposed risk mitigation. Hence satisfied
Watsons DD algorithm close enough optimal practical purposes.
3.1.4 Human DD Error Analysis
interesting nontrivial question arising analysis Watsons equity loss rate DD wagering compare human contestants. main
difficulty attempting analysis contestants confidence answering DD
clue correctly largely unobservable historical data. way know
confidence category, knowledge previous clues category
revealed buzz gave answer. absence confidence information,
hard ascribe error level individual DD bet, although may able
assess average wagering error entire population contestants.
devised two methods respectively provide lower upper bounds
population average wagering error, given sufficient samples historical DD bets.
first method historical replacement technique similar presented sections 2.3
3.2. historical DD, first use Average Contestant simulator run
many trials starting actual outcome state DD, reflecting contestants
actual bet actual right wrong answer. replace contestants bet
algorithmically computed bet, wherein confidence estimated solely observable
information, rerun trials modified outcome state, contestants
score changed due change bet. Averaged many DDs, equity difference
224

fiAnalysis Watsons Strategies Playing Jeopardy!

human bets algorithmic bets indicate approach better.
algorithmic bets prove better, equity difference provide lower bound
true human error rate: since algorithm access private confidence
information, would presumably obtain even better results given information.
could issues approach faithfully simulating would
happened contestant bet differently, changing bet might changed
subsequent square selection (DD seeking) subsequent DD wagering. minimized
issues limiting analysis last-DD situations. historical dataset contained
2200 regular episodes DDs played second round. analyzing
last-DD states episodes, avoid simulate subsequent DD wagers,
effect subsequent square selection minimal since DDs
found. Also, last-DD states allow us use endgame Monte-Carlo algorithmic
wagering, give stronger results neural net wagering. Confidence estimates
Monte-Carlo calculation based historical mean accuracy second-round
DDs given row location. ranges 72% top two rows 57%
bottom row.
seen Table 3, results analysis showed contestant bets average
obtained 2.9% less equity per bet Monte-Carlo algorithmic bets.
constitute lower bound true human error rate last-DD states, whereas Watsons
error rate 0.25% overall near-perfect endgames states, provides compelling
evidence Watsons superiority human contestants, least last-DD wagers.
second analysis method ignores actual right/wrong contestant answers,
instead uses Monte-Carlo analysis calculate equity loss human bet, assuming
row-based mean DD accuracies provide correct confidence estimates. type
analysis overestimate human errors, unduly penalizes small bets based
low private confidence, large bets based high private confidence. Results
analysis last-DD dataset show average error rate 4.0% per DD bet. result
consistent estimated lower bound error rate 2.9%, combination,
results provide reasonable evidence actual human error rate lies
estimated bounds.
Last-DD Player

(leader)
B,C (trailer)

Lower Bound
2.9%
0.9%
4.8%

Upper Bound
4.0%
2.2%
5.5%

Avg. Human Bet
$2870
$2590
$3120

Avg. MC Bet
$6220
$5380
$6970

Table 3: Lower upper bounds average equity loss rates historical human contestant
wagers last DD game. average human bets vs. recommended
MC bets (at default confidence values) also displayed.

closer examination analysis reveals humans systematically wager
DDs far conservatively. segregating data according whether DD player
leading trailing, found conservatism manifest cases. Leading
players average bet $2590, whereas average recommended MC bet $5380.
trailing players, average bet $3120 vs. average recommended bet $6970.
225

fiTesauro, Gondek, Lenchner, Fan & Prager

startling finding errors far costly trailers leaders,
terms equity loss. lower upper bounds error rate leaders 0.9%
2.2%, trailers, respective bounds 4.8% 5.5%! discuss
implications results human contestants section 4.2.
3.1.5 Multi-game DD Wagering
mentioned section 2.6, Game 1 Game 2 Exhibition Match required distinct
wagering strategies, differing single-game wagering. trained separate
neural networks Game 1 Game 2. Game 2 net trained first, using plausible
artificial distribution Game 1 final scores.
trained Game 2 neural net, could estimate expected probabilities
Watson ending match first, second, third place, starting combination
Game 1 final scores, extensive offline Monte-Carlo simulations. used create
three lookup tables, cases Watson ends Game 1 first, second, third
place, Watson match equities various Game 1 final score combinations, ranging
(0, 0, 0) (72000, 72000, 0) increments 6000. (Since adding subtracting constant
Game 1 scores effect match equities, without loss generality
subtract constant lowest Game 1 score zero.) Since match equities
extremely smooth grid points, bilinear interpolation provides fast highly
accurate evaluation Game 1 end states. lookup tables enabled fast training
Game 1 neural net, using simulated matches played end Game 1,
assigned expected match-equity rewards using tables.
Based earlier experience, added heuristic lockout-potential feature
Game 2 input representation, using heuristic sigmoidal formula estimate probability
Watson would win match lockout, given Game 1 Game 2 scores
dollar value remaining clues. feature appeared enable highly accurate Game
2 evaluations eliminated large endgame equity losses observed using
single-game neural net.
important difficult new issue faced Exhibition Match format
assign relative utilities finishing first, second third place. Unlike Sparring
Games reasonable objective finish first, team extensively debated
much partial credit ascribed second-place finish, Watson
defeated one two greatest Jeopardy! contestants time. Ultimately decided
base match DD wagering full credit first, half credit second, zero credit
third place finish. objective acts additional type risk control,
Watson would prefer large bet smaller safer bet large bets upside
(increased chances win) exceeded downside (increased chances finishing third).
unanimous team consensus risk would always worth taking.
Defining Watsons match equity probability finishing first plus 0.5 times probability finishing second, estimated Watsons average match equity loss per DD bet
0.3% Game 1 0.55% Game 2. majority loss case due
risk controls.
226

fiAnalysis Watsons Strategies Playing Jeopardy!

3.2 Final Jeopardy Wagering
approach Final Jeopardy wagering involves computation Best-Response strategy (Fudenberg & Tirole, 1991) (a standard game-theoretic concept) human FJ model
presented section 2.3. considered attempting compute Nash Equilibrium strategy (Fudenberg & Tirole, 1991), decided two reasons. First, due
imperfect information Final Jeopardy (contestants know confidence given
category title, know opponents confidence), would principle need
compute Bayes-Nash equilibrium (BNE), entails considerably modeling
computational challenges. Second, seems far-fetched assume Watsons opponents
would play part Nash equilibrium BNE, since average contestants
studied game theory.
using Best-Response instead BNE strategy (assuming could calculate it),
aim effectively exploit typical human wagering errors recorded historical
data. realized potentially exposes Watson two types risk. First,
Watsons live opponents turned use BNE sophisticated strategies
built human models, Watson might better playing BNE
strategy. judged risk sufficiently rare Watson would surely better
course many Sparring Games simply playing Best-Response. Second,
since Best-Response essentially deterministic strategy, contestant observed
Watson play many Final Jeopardy rounds might able detect optimally exploit
Watsons wagering strategy. However, observations limited procedures
conducting Sparring Games, contestant would play 2-3 games
Watson, would observe another 1-2 games spectator. situations,
additionally able randomize Watsons bet range bets approximately
equal expected outcomes; made difficult humans infer Watsons wagering
logic limited number observations.
Computation Best-Response proceeds follows. First, consult FJ prior
accuracy regression model estimate Watsons confidence given category title.
model trained samples Watsons performance thousands historical FJ
categories, using NLP-based feature vector representations titles. Second, given
Watsons confidence human accuracy/correlation parameters, derive analytic
probabilities eight possible right/wrong outcomes. Third, given FJ score combination, draw order 10000 Monte-Carlo samples bets human models.
Finally, evaluate equity every legal bet, given human bets right/wrong
outcome probabilities, select bet highest equity.
initial implementation algorithm slow use live play. Fortunately, extensive offline analysis using Watsons default confidence, discovered
Best-Response output could expressed terms fairly simple set logical
betting rules. example, one rules B stipulates:
B least two-thirds A, B less 2C, check whether 2C-B
(the amount cover Cs doubled score) less equal 3B-2A (the
maximum two-thirds bet). so, bet 2C-B, otherwise bet everything.
Thus Series 1 Sparring Games, deployed rule-based encapsulation
Best-Response calculation, one specific exception Watson A,
227

fiTesauro, Gondek, Lenchner, Fan & Prager

B player may reasonably consider so-called two-thirds bet, i.e., small bet aims
guarantee win whenever wrong, assuming makes standard shut-out bet
(2B-A+1). situations, Best-Response calculation calls Watson
counter B making small, tricky anti-two-thirds bet. Whether really wins
often depends exact model parameter values, considerable uncertainty,
discussed earlier section 2.3. Moreover, Watson bets small gets FJ wrong,
suggests shakiness ability play Final Jeopardy, might exploited
subsequent games, well generally looking bad. Conversely, Watson bets small
gets FJ right, risks embarrassing loss Watson could failed
bet enough win. reasons, team preferred override Best-Response
calculation, Watson simply make standard bet scenario.
proved judicious choice hindsight, five games Series 1
Best-Response would bet anti-two-thirds, B bet two-thirds
games.
Series 2 Sparring Games, Best-Response computation sped
enough enable live wager computations. team continued debate whether allow
anti-two-thirds bets, ultimately decided worth risk Watson unusually
low confidence (as happens, example, categories US Presidents, Shakespeare,
US Cities). turned out, two games series BestResponse would bet anti-two-thirds. B bet two-thirds one game
game. Watson low confidence either FJ category, live test
results anti-two-thirds strategy.
assessed performance Best-Response strategy via historical replacement technique presented section 2.3; results displayed Table 4. first column
gives actual human win rates A, B, C roles. second column shows win rates
constrained Best-Response deployed Series 1 Sparring Games,
always bets cover 2B. Note algorithm considerably improves actual human
results B C, provides smaller noticeable improvement human bets.
attribute latter gain partly consistent betting, partly judicious bets
cases tie 2B, rather trying surpass 2B $1. last column gives
results full Best-Response algorithm including general Best-Response bets A.
nearly 1% improvement win rate constrained Best-Response;
provides support efficacy anti-two-thirds sophisticated strategies,
quite statistically significant 2092 trials.


B
C

Human
65.3%
28.2%
7.5%

Constrained Best-Response
67.0%
34.4%
10.5%

Full Best-Response
67.9%
34.4%
10.5%

Table 4: Comparison actual human win rates win rates constrained
full Best-Response strategies, historical replacement 2092 non-locked FJ
situations past episodes.

228

fiAnalysis Watsons Strategies Playing Jeopardy!

Exhibition Match, devised live Best-Response algorithms Game 1
Game 2 based Monte-Carlo samples human betting models section 2.6,
probabilities eight right/wrong outcomes given Watsons FJ category confidence.
first-game FJ, cant evaluate directly FJ outcomes since still
second game play. evaluation instead based interpolation lookup
tables discussed section 3.1.5 denoting Watsons match equities various first-game
score combinations.
Due modeling uncertainties Game 2 FJ, devoted much effort interpreting
Best-Response output terms logical betting rules, well deciding whether
Best-Response decisions overridden. ultimately decided allow Watson
venture anti-two-thirds bet predicted category confidence unusually
low; otherwise Watson would always bet guarantee win answering correctly.
wagering B, betting rules would attempt finish ahead
diminish Watsons chances finishing ahead C. naturally emerged match
utility function assigned half-credit second place finish. Finally, wagering
C, Best-Response output complex derive human-interpretable rules,
Watson prepared run live calculation case. turned out,
work superfluous, since Watson lockout Game 2 Exhibition
Match.
3.3 Square Selection
considered four different factors could conceivably relevant optimal overall
objective Watson deciding square select given game state:
Selecting Daily Double square: Finding DDs quickly provide excellent
opportunity Watson significantly boost game standing, also denying
opportunity players. potential downside Watson may
small bankroll wager, may little evidence assess
likelihood answering DD clue correctly.
Retaining control board: involves estimating categories and/or square
values Watson greatest chance win buzz answer correctly.
would give Watson another chance try find DD, selected square
turns regular clue.
Learning essence category, i.e., gathering information category
type correct answers, improve accuracy subsequent clues
category (Prager et al., 2012). consideration would suggest selecting lowvalue squares first, accuracy would improved higher-value squares.
Maximizing expected score change: concept seeks best combination high
expected accuracy highest dollar value available clues obtain biggest
boost Watsons score next square.
used simulator systematically investigate numerous weighted combination
four factors. studies performed using Champion Grand Champion human models, featured overt DD seeking, aggressive DD wagering, high
229

fiTesauro, Gondek, Lenchner, Fan & Prager

DD accuracy. results showed that, prior DDs revealed, finding DDs
overwhelmingly top factor maximizing Watsons win rate, retaining control
second importance. Learning essence category appears provide effective
strategy DDs found, maximizing expected score change
appear useful improving Watsons win rate.
findings led us deploy algorithm selects squares follows. First,
unrevealed DDs, square selected maximizes pDD (i)+pRC (i)
pDD (i) probability square contains DD, pRC (i) estimated probability
Watson retain control board contain DD, = 0.1 yielded
best win rate. first term calculated using Bayesian inference, described
section 3.3.1. second probability estimated combining simulation model
human performance regular clues model Watson adjusts attempt
rate, precision buzzability function number right/wrong answers previously
given category. Second, DDs round found, algorithm
switches selecting lowest dollar value category greatest potential
learning category: based number unrevealed clues
category total dollar value.
3.3.1 Bayesian DD Probability Calculation
calculate pDD (i), probability square contains DD, according principles
Bayesian inference: combine Bayesian prior probabilities, taken historical frequencies DD locations, evidence revealed questions according Bayes rule,
obtain posterior probabilities. computation easy perform incrementally
individual question revealed, works somewhat differently Round 1 Round
2, due different number available DDs.
Round 1, one DD, computation posterior probabilities easy. Let
p(i) denote prior probability square contains DD. Let p(i) = 1 p(i) denote
prior probability contain DD. assume square j revealed
contain DD. posterior probability p(i|j) according Bayes rule given by:
p(i|j) =

p(j|i)p(i)
p(j)

(2)

p(j|i) = 1 definition, assuming 6= j. course, DD revealed,
p(i) values squares set zero.
Round 2, two DDs, probabilities independent, since
DDs cannot located column, plus column pair frequencies
historical data may explainable independent placement model.
therefore maintain joint probability distribution p(i, j) indicating probability
squares j contain DDs. initialize p(i, j) prior values, using joint DD
location frequencies historical data. assume square k revealed
contain DD. posterior probability p(i, j|k) computed according Bayes rule as:
p(i, j|k) =

p(k|i, j)p(i, j)
p(k)
230

(3)

fiAnalysis Watsons Strategies Playing Jeopardy!

p(k) = 1 p(k) marginal distribution single DD, integrating possible
locations second DD, p(k|i, j) = 1 k 6= k 6= j, else equals 0. Note
constraint two DDs never appearing column enforced setting
prior p(i, j) = 0 squares j column. guarantees
posterior always equal 0, since Bayes rule performs multiplicative updates.
square k discovered contain DD, rest board updated
similarly:
p(i, j|k) =

p(k|i, j)p(i, j)
p(k)

(4)

p(k|i, j) = 1 k = k = j, else equals 0.
3.3.2 Square Selection Performance Metrics
Live DD strategy
LRTB
Simple DD seeking
Bayes (max pDD )
Bayes (max pDD )
max(pDD + 0.1pRC )

live DD strategy
LRTB
LRTB
LRTB
Post-DD learning
Post-DD learning

Win rate
0.621
0.686
0.709
0.712
0.714

DDs found
0.322
0.510
0.562
0.562
0.562

Board control
0.512
0.518
0.520
0.520
0.520

Table 5: Simulation results two-game matches vs. Grand Champions using various square
selection strategies (500k trials). LRTB denotes left-to-right, top-to-bottom square
selection.
Table 5 report extensive benchmarking Watsons performance using five
different combinations various square selection algorithms. first column denotes
strategy available DDs played round, second column
denotes strategy DDs round played. experiments utilized
two-game match format Grand Champion models human contestants.
stated earlier, human models employ aggressive DD FJ wagering, simple DD
seeking using known row statistics DDs available. Simulations Watson use
right/wrong answers drawn historical categories, Watson exhibit learning
revealed answers category. interesting consequence Watsons learning,
model human square selection remaining DDs according anti-learning
strategy, intended frustrate Watsons learning, selecting bottom category
greatest potential benefit learning. actually observed behavior informal
testing strong human players (Ed Toutant David Sampugnaro)
Exhibition Match, evidence Jennings Rutter may selected
clues Exhibition based concept.
Results Table 5 show weakest performance obtained extremely
simple baseline strategy Left-to-Right, Top-to-Bottom (LRTB), i.e., always selecting
uppermost square leftmost available column, actual deployed strategy
Exhibition gives strongest performance. Consistent earlier findings,
231

fiTesauro, Gondek, Lenchner, Fan & Prager

see Table 5 DD seeking extremely important, especially playing
strong humans overtly seek DDs. Bayesian DD seeking method significantly
better simple DD seeking based solely row frequencies DDs. Watson
humans use simple DD seeking, Watson finds 51.0% DDs (roughly line
51.8% average board control) match win rate 68.6%. Watson
switches Bayesian DD seeking, rate finding DDs jumps 56.2%, even though
board control virtually unchanged 52.0%, win rate increases 2.3% 70.9%.
hand, Watson DD seeking, simply uses Left-to-Right, Top-toBottom selection, rate finding DDs plunges 32.2% overall win rate drops
62.1%.
additional effects seeking retain control board, selecting categories
greatest potential learning DDs revealed, smaller statistically
significant 500k trials. find optimizing weight pRC increases win rate
0.2%, maximizing learning potential remaining DDs adds another 0.3%
Watsons win rate.
3.4 Confidence Threshold Attempting Buzz
Watson attempt buzz confidence top-rated answer exceeds adjustable threshold value. vast majority game states, threshold set
default value near 50%. analysis indicating optimal
threshold, strong argument 50% threshold would maximize Watsons
expected score, ought related maximizing Watsons chance win. Furthermore, clear general default buzzing 50% confidence better
buzzing, since Watsons expected score change (0) would cases,
opponents would much better chance improve scores Watson
buzz.
approximate threshold calculation based Max-Delta objective (described
Appendix 2), suggestive evidence initial buzz threshold
aggressive. Subsequent exact Monte-Carlo analysis endgames (Appendix 2)
early game states (section 4.3) provides substantial backing aggressive initial
threshold 50%. Nevertheless, since Watson tended slightly overconfident
vicinity 50% nominal confidence, since many Watsons wrong answers
vicinity clearly revealed correct answer opponents, 50% default threshold
may prudent choice.
Near end game optimal buzz threshold may vary significantly
default value. One special-case modified buzz policy devised endgames uses
lockout-preserving calculation. Round 2 states remaining DDs, Watson
big lead, calculate whether guaranteed lockout buzzing
current square. so, lockout longer guaranteed Watson buzzes
wrong, prohibit Watson buzzing, regardless confidence.
principle, exact optimal binary buzz-in policy within simulation model
~ (c, D) = (B (c, D), B (c, D), B (c, D), B (c, D)) game state clue currently
B
3
2
1
0
play, given Watsons confidence c dollar value current clue. policy
components Bi (c, D) result testing whether c exceeds set optimal threshold values
232

fiAnalysis Watsons Strategies Playing Jeopardy!

{i , = 0, 1, 2, 3}. four values corresponding four possible states
Watson may buzz: initial state, first rebound human #1 answered incorrectly, first rebound human #2 answered incorrectly, second rebound
humans answered incorrectly. optimal policy calculated using Dynamic
Programming (DP) techniques (Bertsekas, 1995). involves writing recursion relation
value current game state K clues remaining FJ, values
possible successor states K 1 clues remaining:
VK (s) =

Z

(c)

5
X

j=1

p(Dj ) max

X

~
B(c,D
j)

~ c)VK1 (s (, Dj ))dc
p(|B,

(5)

(c) probability density Watsons confidence, p(Dj ) denotes probability
next square selected row j dollar value Dj = $400 j, max
~ c) denotes probabiloperates Watsons possible buzz/no-buzz decisions, p(|B,

ity various unit score-change combinations , denotes various possible successor
states Dj square played, score change combination occurred.
(See Appendix 2 detailed discussion recursion relation Equation 5
calculated.)
implemented exact DP solver successively expands root state
successor states K 1, K 2, ..., 0 clues remaining, 0 denotes Final Jeopardy
states. FJ states evaluated Monte-Carlo trials, values propagated
backward according Equation 5 ultimately compute optimal buzz policy
root node state. computation exact within modeling assumptions,
slow use live play K 2, due high branching factor search tree.
order achieve acceptable real-time computation taking 1-2 seconds,
therefore implemented Approximate DP calculation Equation 5 used
first step evaluate VK terms VK1 , VK1 values based
plain Monte-Carlo trials (Tesauro & Galperin, 1996; Ginsberg, 1999; Sheppard, 2002).
Due slowness exact DP calculation, unable estimate accuracy
approximate method K > 5. However, verify Approximate DP usually
gave quite good threshold estimates (within 5% exact value) K 5 remaining
squares, switchover point invoke Approximate DP deployed
live Series 2 Sparring Games human champions. analogous algorithm based
match equities also deployed Game 2 Exhibition Match, indifferent
final five clues live game, since Watson guaranteed win either
buzzing buzzing.
3.4.1 Illustrative Examples
Approximate DP buzz-in algorithm easily handles, example, so-called desperation
buzz last clue, Watson must buzz answer correctly avoid
locked (e.g., suppose Watson 4000, human contestants 10000 2000,
final clue value $1200). Generally speaking, optimal endgame buzzing shows
greatest deviation default buzzing near certain critical score breakpoints,
crossover third second place, second first place. players score
one breakpoints, aggressive buzzing usually correct. Conversely,
233

fiTesauro, Gondek, Lenchner, Fan & Prager

score critical breakpoint, players buzz much conservatively,
guard dropping breakpoint.
critical breakpoint contestant achieves guaranteed lockout.
near-lockout situations, algorithm may generate spectacular movements buzz
threshold hard believe first glance, appreciated detailed
analysis. example taken Sparring Games last-clue situation Watson
28000, humans 13500 12800, clue value $800. (initially)
surprising result optimal buzz threshold drops way zero!
buzzing answering incorrectly, Watson worse buzzing.
either case, human B player must buzz answer correctly order avoid
lockout. hand, buzzing answering correctly secures win Watson,
risk-free chance try buzz win game.
complex example occurred later game, two squares remaining (the current one $1200 final one $2000), Watson 31600,
vs. 13000 6600 humans. again, correct answer Watson wins
game. analysis shows Watson buzz regardless confidence
clue next clue, well better buzzing. first clue,
Watson buzzes wrong, B needs buzz answer correctly, reach score
14200, otherwise Watson lockout 30400. suppose Watson also gets
second clue wrong, dropping 28400. score pair (28400, 14200) good
Watson state (31600, 14200) Watson attempt either clue.
cases, Watson guaranteed win unless B answers correctly. fact, B alert,
might deliberately answer (28400, 14200) lock-tie situation;
actually better Watson (31600, 14200), although simulator model
behavior.
critical example converse situation, Bs buzz-in threshold much higher
normal, occurred earlier game. final clue ($2000 value) Watson (A)
25200, B 12800, C 2600, Watson answered incorrectly initial
buzz, dropping 23200. Despite Jeopardy! champion, B unfortunately buzzed
rebound answered incorrectly, thereby locking out. analysis shows
rebound buzz massive blunder (although understandable heat live play):
offers improvement FJ chances B right, forfeits chance win B
wrong. roles reversed, Watson would buzzed fairly aggressively
initial buzz, prevent achieving lockout, never would buzzed
rebound.
Finally, Figure 8 presents $2000 last-square situation fix human scores
(13000, 6600) systematically study Watsons initial buzz threshold varies
score. several examples huge threshold changes breakpoints crossed.
example, Watsons threshold goes aggressive (0.12) 13000,
fairly conservative (0.65) 13000. additional complex behavior arising
specific score combinations involving three players. example, 6400 Watson
take extra risk answering incorrectly, due chance may also answer
incorrectly. creates situation A=B+C Watson extra chances
achieve tie first place. principle applies 10400, A=B+C arises
Watson wrong right. different combination comes play 10800
234

fiAnalysis Watsons Strategies Playing Jeopardy!

$2000 Last Clue Threshold, Human Scores (13000, 6600)
1

Confidence Threshold

0.8

0.6

0.4

0.2

0
5000

10000

15000
20000
Watson Score

25000

30000

Figure 8: Watsons initial buzz threshold vs. score last clue ($2000) FJ.
Watson extra incentive buzz: either C right, Watson bet
cover 2C still constitute two-thirds bet.
Figure 8 also shows huge swings Watson close achieving lockout. 23000,
Watson never buzz, since chance get lockout. 25000, Watson
free shot try lockout, discussed earlier. 27000, Watson provisional
lockout needs take risk block correct answer B, 29000, Watson
free shot prevent B answering.

4. Lessons Human Contestants
Watson retired Jeopardy! contestant, future impact work
improving Jeopardy! performance relate specifically human contestants.
section, present number interesting insights may help future contestants improve
overall winning chances.
4.1 Basics Final Jeopardy Strategy
observed FJ wagers J! Archive dataset suggest many contestants appearing
show devote scant effort learning good strategies FJ wagering, apart
elementary concept wagering least 2B-A cover Bs doubled score. dont
intend section provide definitive treatise FJ strategy, illustrate
found important regions separating boundaries FJ strategy space
single plot, shown Figure 9.
Since FJ scenarios scale invariant, scenario uniquely determined two variables: Bs score relative A, Cs score relative B. ratio B
important quantity Final Jeopardy, important breakpoint (apart
B<A/2 lockout) B=2A/3, illustrated solid red line. contestants
familiar implications scenario, analogous game
235

fiTesauro, Gondek, Lenchner, Fan & Prager

Matching Pennies, wins pennies match, B wins pennies mismatch.
B least two-thirds A, B secure win whenever wrong making
small two-thirds bet (3B-2A), assuming bets cover 2B. However, strategy
vulnerable making small anti-two-thirds bet, would give B chance
win. Conversely, anti-two-thirds bet vulnerable B making large bet overtake
A. related breakpoint case B3A/4: situation Bs two-thirds bet
overtake A, anti-two-thirds option eliminated.
important breakpoints include C=B/2 (green line): line, B keep
C small bet (B-2C), line, B needs bet least (2C-B) cover
Cs doubled score. latter case may lead dilemma (2C-B) exceeds maximum
two-thirds bet (3B-2A). demarcation dilemma occurs magenta curve
(2B=A+C), also known equal spacing breakpoint, since A-B=B-C.
Breakpoints primarily affect C curves C=(A-B) (dark orange) C=2(AB) (gray). Basically, C needs able reach 2(A-B) curve chance
win, C chance (A-B) curve. scenarios lying two
curves, C minimum rational bet least 2(A-B)-C, although larger bet may
reasonable, example, CA/2 (dotted black curve) overtake A. scenario
would also dissuade trying anti-two-thirds bet B.
C least 2(A-B), general rule bet small enough stay
value. additional upper bound emerging Best Response calculation occurs
C2B/3 (blue line), cases B 3A/4. case, B
incentive bet cover 2C, C opportunity execute two-thirds bet
B, may yield wins simply staying 2(A-B).
Final Jeopardy Strategy Boundaries
1

0.8

C/B

0.6

0.4

B=2A/3
B=3A/4
C=B/2
C=2B/3
2B=A+C
C=A-B
C=2(A-B)
C=A/2

0.2

0
0.5

0.55

0.6

0.65

0.7

0.75
B/A

0.8

0.85

0.9

0.95

1

Figure 9: Illustration important Final Jeopardy strategy regions boundaries,
function Bs score relative A, Cs score relative B.

236

fiAnalysis Watsons Strategies Playing Jeopardy!

4.2 Aggressive DD Wagering
mentioned earlier section 3.1.4, analysis indicates human contestants
systematically err conservative side DD wagering, given actual likelihood
answering DD clue correctly. may reflect underestimation ignorance
likely DD accuracy, well lack quantitative means estimate impact
score increase decrease ones overall winning chances. Another possibility
contestants may recognize level aggressive bet called for, risk
averse actually try it.
section present specific historical example illustrate analysis
works, motivate potential advantages aggressive wagering, long
player reasonably good confidence able answer correctly. example
wager taken J! Archive episode aired last decade. second
place player B found last DD $800 clue category one previous clue
($400) played; clue answered correctly B. point, scores
quite close, B 10400 opponents 11400 9400.
eight remaining clues played, worth total $10800. B chose wager
$1000, got DD right, ultimately game.
course know Bs confidence situation, suspect reasonably good, because: (a) $800 second-round DDs tend easy, average contestant
accuracy 72%; (b) B already answered correctly one previous clue
category; (c) wagers $1000 tend indicative unusually low DD accuracy. Given
considerations, suspect B least 70% chance answering DD
correctly, low wager due desire avoid dropping third place
incorrect answer.
one might surmise reading section 3.1.4, analysis suggests 70% confidence, best wager True Daily Double, $10400. plot Monte-Carlo right/wrong
equity curves, equity 70% confidence, function amount wagered shown
Figure 10. Note large bets, red curve smaller magnitude slope
green curve, decelerates rapidly. bet sufficiently large, little
incremental equity loss increasing bet, since player almost chance win
point. Conversely, strong incremental gain increasing bet getting
DD right. factors tilt calculation decidedly favor maximal bet. Paradoxically, almost certain loss getting DD wrong may exactly humans
avoid betting True DDs situation. Many psychological studies documented irrational preferences taking immediate gains, avoiding immediate losses,
attributed so-called hyperbolic discounting (Ainslie, 2001). Since Jeopardy!
undiscounted game, correcting natural tendencies towards overly short-term thinking
may advisable prospective contestants.
$1000 bet, B either tied first tied second, game still
close little change equity. MC estimates Bs equity 39% right 31%
wrong. However, true DD wager, B would either obtain commanding lead
20800 estimated equity 70% answering correctly, drop zero
3% equity answering incorrectly. equity difference two bets
237

fiTesauro, Gondek, Lenchner, Fan & Prager

compelling 70% confidence: betting $1000 gives 36.6% equity, betting $10400
gives 49.9% equity, hefty improvement 13.3% overall winning chances.
Historical (10400, 11400, 9400) last DD
0.8

DD wrong equity
DD right equity
Equity @ 70% confidence

0.7

DD player winprob

0.6
0.5
0.4
0.3
0.2
0.1
0
0

2000

4000

6000
DD bet

8000

10000

12000

Figure 10: Equities getting DD right wrong 70% confidence,
example historical last-DD situation scores (10400, 11400, 9400).

4.3 Counterintuitive Buzz-in Thresholds
Probably counterintuitive result analysis buzz-in confidence thresholds
attempting answer may correct even player negative equity expectation
so. discussed Watsons 50% default threshold human contestants
Sparring Games, many seemed surprised low value,
even objected vociferously. arguments based quantitative equity
estimates, seem intuitively recognize Watsons game standing would diminish
average buzzing 50% confidence, since Watsons score change would zero
average, one opponent scores would likely increase. tried explain
clearly better alternative buzzing, Watson would
zero expected score change, unimpeded opponents would greater chances
score increase.
developed offline Monte-Carlo method computing buzz-in thresholds
human contestants (see Appendix 2 details), compare actual MC results
simple approximate formula threshold, derived below, gives insight
negative-expectation threshold comes about. complex analytic calculation,
yielding closed-form analytic expressions four threshold values, detailed
Max-Delta approximation section Appendix 2. analysis also agrees closely
MC results.
consider equities one player (the strategic player) relative baseline state,
equity E000 , clue expires score change. aim calculate
238

fiAnalysis Watsons Strategies Playing Jeopardy!

confidence threshold 0 initial buzz players confidence c = 0 ,
equities buzzing buzzing equal, i.e., EN B (c) = EB (c).
Let N = EN B E000 denote expected equity change player buzz,
either initially rebound. depend often opponents buzz
precision, good opponents, N negative value. MC
simulations early-game states refined Average Contestant model (where b p
estimated based round clue row number), N approximately -0.86% $1000
clue first round. order understand effects correlated opponent buzzing
precision, also ran simulations corresponding uncorrelated model, obtaining
N -0.96% situation.
consider case player buzzes initially. confidence values c
vicinity 0 , player loses buzz, argue outcome N :
since rebound thresholds higher 0 , shown below, player buzz
rebounds. Hence buzzing differ buzzing player wins
buzz. winning buzz answering correctly, players equity increase
positive equity gain G. early $1000 first-round clues, G appears +3.25%,
regardless whether opponents correlated uncorrelated player.
incorrect answer, due approximate linearity equity respect score changes early
game, player equity loss G, plus likely loss
opponents play rebound. uncorrelated opponents, extra loss
N , correlated opponents, lesser still negative value N ,
due fact rebound precision less initial buzz precision correlated
model. Assuming N = N simplicity, confidence values c buzzing better
buzzing determined following inequality:
cG + (1 c)(N G) N

(6)

Rearranging terms, obtain: c 0 = G/(2GN ). Since N negative, confidence
threshold less G/2G, i.e., less 50%. quoted values G
N , equation 6 yields threshold value 0 = 0.436 uncorrelated model,
0 = 0.442 correlated model.
compare actual MC threshold calculation, seen Table 6, one
player (the leader) typical early game situation, first column
played, scores (1800, -600, 1000), DD played. Similar threshold
values robustly obtained early states, regardless whether player leading
trailing. per section 3.4, 0 denotes initial threshold, 1 2 denote
first rebound thresholds, 3 denotes second rebound threshold. Note 0
values $1000 clues correlated uncorrelated models match well
approximate formula values. also statistically equal, suggests MC
calculation 0 robust sensitive dependence assumed modest
level contestant correlation.
also note increase first rebound thresholds models,
increase second rebound thresholds. makes sense expected loss
buzzing, N , diminish opponents eligible buzz. double
rebounds, N equal 0, leading threshold 0.5 according approximate
formula. increase rebound thresholds modest uncorrelated model, quite
239

fiTesauro, Gondek, Lenchner, Fan & Prager

significant correlated model. due positive correlation precision, implying
players posterior confidence reduced observing one opponents answer
incorrectly.
Similar experiments $200 clues obtain aggressive initial threshold (42% vs
44%). expected: since $200 clues easier, opponents likely
buzz answer correctly strategic player buzz. Hence magnitude
N relative G increase, yielding lower threshold. shown Table 6,
thresholds $400, $600, $800 clues take plausible intermediate values
$200 $1000 limiting cases.
clue value
$1000
$1000
$200
$200

(b , p )
(0.2, 0.2)
(0, 0)
(0.2, 0.2)
(0, 0)

0
0.44
0.44
0.42
0.42

1
0.67
0.49
0.69
0.47

2
0.68
0.50
0.68
0.48

3
0.78
0.53
0.83
0.54

Table 6: Early buzz-in thresholds correlated uncorrelated refined Average Contestant
models, based 800K MC trials 20 end-of-clue states. Test position scores
(1800, -600, 1000), one column played, DD remains played.

summary, human contestants make precise confidence estimates,
suspect buzz attempts safely 50%, likely
right wrong. would also surprised became cautious rebounds,
one opponents answered incorrectly. contrast, analysis suggests
early game, may profitable make slightly speculative buzz attempts
initial buzz, odds even slightly getting right. important
caveat speculative guesses strong tip-off effect would
significantly aid rebounder.
would also advocate exercising caution rebounds. Despite tip-off effect,
clear historical evidence human precision positively correlated, declines
rebounds. seen correlated threshold calculation, contestants well
50% initial confidence venture rebound attempt, especially double rebound.
4.4 Lock-Tie Implications
conclude section examining strange amusing consequences
Lock-Tie scenario Final Jeopardy, Bs score exactly half score.
scenario, likely bet nothing, B achieve tie first place betting
everything getting FJ right. decidedly preferable half
score, B would need get FJ right get FJ wrong order win.
preference B lower score lead unusual strategy decisions (to say
least) near end game. example, Dupee (1998) discusses DD wagering
last clue Final Jeopardy, DD player 7100 opponents 9000
1000. Dupee advocates wagering $2600, takes lead 9700 correct,
drops lock-tie 4500 incorrect.
240

fiAnalysis Watsons Strategies Playing Jeopardy!

Watsons analysis turns many last-clue DD situations lock-tie considerations lead unusual even paradoxical bets. example, episode 5516, Greg Lindsay7
faced last-clue DD decision, trailing 6200 vs. 19200 9500. Greg wagered $6000
ultimately game. However, Watson regards serious error, recommends wagering $3400 instead, achieves lock-tie 9600 correct answer.
also frequently find Watson wagering necessary last-clue DD achieve
lockout. one example, Watson 26000 opponents 19800 4400.
Watson needed bet $13600 secure lockout, puts Watson 12400
answering incorrectly. Watson instead bet $16100, also achieves lockout
correct, drops second-place lock-tie score 9900 answering incorrectly.
Watson also discovered lock-tie influence wagering several squares
end game. analysis historical last-DD human bets, found class
situations DD player trailing badly, Watson recommends betting exactly
$100 less True Daily Double. example situation DD player 5000,
opponents 21400 2800, five remaining clues DD
played, worth total $6000. Watson recommends betting $4900, certainly seems
weird inconsequential, appears real point it. Note leaders
score 21400 happens odd multiple 200 (107x200). Since remaining clues
even multiples 200, leaders score entering FJ always odd multiple
200. Now, order reach lock-tie FJ, follows DD players score must
odd multiple 100. achieved wagering $4900, appreciable chances
lock-tie, instead $5000 makes lock-tie impossible. $4900 bet offers 7.2%
equity instead 6.4%, lock-tie potential constitutes substantial portion overall
winning chances situation.
Finally, note lock-ties provide incentive players intentionally give
wrong answers. first alerted possibility puzzle editor Peter Gordon,
emailed last-clue DD scenario Watson 6000 opponents 10000
-1000. Peter recommended Watson bet $1000 get wrong purpose!
course action would require Watson get FJ right order win, whereas
large DD bet take lead, Watson needs get DD clue FJ right
order win.
subsequent testing Watsons buzz-in strategy, found number fascinating
last-clue scenarios Watson reported buzz/wrong rebound offers better
equity either buzz/right buzzing. turns scenarios occur
A=2B-V, V value last clue, C contention. (As
example, suppose A=18800, B=10000, C=7600 V=1200.) situation allows B
double chance achieve lock-tie! First all, B never buzz initially,
wrong answer results getting locked out, may buzz get right,
results lock-tie. Additionally, may buzz get wrong, reducing score
A-V = 2(B-V). happens, B reach lock-tie buzzing answering
incorrectly. scenario remote one might think seems occur
per season majority cases, lock-tie spoiled incorrect behavior
B.
7. Greg Lindsay contestant win three Sparring Games Watson.

241

fiTesauro, Gondek, Lenchner, Fan & Prager

5. Conclusions
combining original simulation model Jeopardy! state-of-the-art statistical
learning optimization techniques, created set real-time game strategy algorithms
made Watson much formidable Jeopardy! contestant. documented
detail, strategy methods resulted significant boost Watsons expected win
rate Sparring Games Exhibition Match, compared simple
heuristic strategies. DD wagering, neural net method obtained 6% improvement
win rate compared prior heuristic, estimate 0.6% improvement
using live Monte-Carlo analysis endgame DDs. FJ betting, simulations show
3% improvement simple heuristic always bets cover leading, bets
everything trailing. seen Table 5, best square selection method improves
heuristics 3-9%, depending much DD seeking done heuristic.
data heuristic endgame buzzing, conservative guess Approximate
DP method would achieve 0.5% 1% greater win rate. aggregate benefit
individual strategy improvements appears additive, since simulations put Watsons
win rate 50% using baseline strategies, versus 70% using advanced strategies.
also ample evidence strategy algorithms exceeds human capabilities real-time decision making. Historical replacement shows Watsons BestResponse FJ wagering clearly outperforms human wagers. Watson also better finding
DDs humans, seen excess fraction DDs found relative average
board control. According simulations, translates greater overall win rate.
cases Daily Double wagering endgame buzzing, clear humans
incapable real time anything like precise equity estimates, confidence estimates,
complex calculations performed algorithms evaluate possible decisions. Watsons
error rate improves humans order magnitude last-DD situations, saw
section 3.1.4. likely lesser still significant improvement earlier
DDs. difficult identify human buzzing errors: failure buzz indistinguishable
losing buzz, even contestant buzzes wrong, decision may
correct high enough confidence. surmise cases, human buzz errors
small. algorithms main advantage likely handling special-case endgame states
humans make major errors, mishandling lock-tie needlessly locking
out.
addition boosting Watsons results, work provides first-ever means
quantitative analysis applicable Jeopardy! game state covering aspects
game strategy. Consequently, unearthed wealth new insights regarding
constitutes effective strategy, much difference strategy make contestants overall ability win. illustrated numerous examples insights
throughout paper, expect even greater understanding proper Jeopardy! strategy obtained development deployment algorithms based
approaches. top humans classic board games (Chess, Backgammon, etc.)
use computer software invaluable study aids, envision studying Jeopardy!
strategy software could become vital part contestant preparation appear
show. Toward end, currently developing version DD wager calculator
242

fiAnalysis Watsons Strategies Playing Jeopardy!

deployed J! Archive. nicely complement existing FJ wager calculator,
make DD analysis widely accessible study prospective contestants.
simulation modelers, perhaps important take-home lesson work
Watson reminder merits starting approach based extreme
simplification. generally appreciated simulation predictions may insensitive
many low-level details. However, given central role natural language clues
category titles Jeopardy! gameplay, least mildly surprising successful
simulation models may completely ignore natural language content. One might
also thought simple mean-rate models would inadequate, fail capture
potentially important hot cold streaks specific categories, well variance across
contestants general QA ability. factors apparently critically important
model purposes optimizing Watsons strategies. Finally, clear
could adequately predict expected outcomes Watson vs. two humans scant livegame data. crude estimates relative buzzability, etc., made attempt
model impact Watsons unusual gameplay human performance, tipoff benefit humans Watson answers incorrectly. Despite limitations,
validation studies section 2.7 demonstrate remarkably accurate predictions performance
metrics.
Looking beyond immediate Jeopardy! domain, also foresee general applicability high-level approach coupling Decision Analytics QA Analytics,
consists building simulation model domain (including agents domain),
simulating short-term long-term risks rewards QA-based decisions,
applying learning, optimization Risk Analytics techniques develop effective decision
policies. currently investigating applications high-level approach health
care, dynamic pricing, security (i.e., counter-terrorism) domains.

Acknowledgments
grateful entire worldwide team IBM made Watson project possible, team Sony/JPI made Exhibition Match Sparring Games possible,
former Jeopardy! contestants volunteered participate live test matches
Watson. thank anonymous reviewers Ed Toutant many helpful comments suggestions improve manuscript.

Appendix A. Watsons Competitive Record
Prior appearing Jeopardy!, Watson played 100 Sparring Games
former Jeopardy! contestants realistic replica TV studio, constructed
IBM Research Center Yorktown Heights, NY. studio featured real Jeopardy!
contestant lecterns signaling devices, made use actual JPI (Jeopardy Productions Inc.) game-control system. content game (categories, clues, answers)
supplied directly JPI, consisted actual Jeopardy! episodes already
taped, yet aired. (This eliminated possibility contestants could
previously seen content used games.) professional actor, Todd Crain,
243

fiTesauro, Gondek, Lenchner, Fan & Prager

hired host games. incentivize contestants, paid $1000
first-place finish, $250 second-place finish.
initial series 73 games took place Oct. 2009 Mar. 2010. Contestants
recruited JPI, appeared show twice, none
appeared three episodes. considered players representative
average human contestants appear show. Results series games
Watson finished first 47 games (64.4%), second 15 games (20.5%), third
11 games (15.1%). also note 21 Watsons 47 wins lockout, i.e.,
guaranteed wins Watson could caught Final Jeopardy.
Watson additionally played second series 55 games Fall 2010, time
much stronger human opposition. contestants competed
shows annual Tournament Champions, done well enough reach final
semi-final rounds. Watson also considerably improved respects, particular,
full complement advanced quantitative strategies deployed games. (By
contrast, advanced strategy Series 1 games Final Jeopardy
betting.) Results series follows: Watson finished first 39 games (70.9%),
second 8 games (14.55%) third 8 games (14.55%). Watsons rate winning
lockout also improved, 30 39 games (76.9%), vs. 21/47 = 44.7% previous
series.
Finally, witnessed millions viewers, Watson played two-game Exhibition
match Ken Jennings Brad Rutter, arguably two best human Jeopardy!
contestants time. Watson took $1,000,000 first-place prize lockout,
total score 77,147. Ken Jennings took second place ($300,000) score 24,000,
Brad Rutter finished third place ($200,000) score 21,600.

Appendix B. Buzz Threshold Calculation Details
Appendix presents computational details method calculating initial buzz
rebound buzz decisions endgame state remaining Daily Doubles, current
selected square dollar value D, K remaining squares played current
square. assume optimizing buzz decision one player (the strategic
player), two opponents non-strategic players buzz decisions
determined fixed stochastic process. assume opponents
buzz decisions change going initial buzz rebound second rebound.
default strategic player Watson, although also developed similar method
compute confidence thresholds human contestants.
calculation invoked Watson live play assumes Watsons confidence
yet known, since computation must begin QA system returned
confidence value. therefore pre-compute buzz decisions discretized confidence values
0 1 discretization interval typically set 0.01.
B.1 Calculation Watson vs. Two Humans
Calculation proceeds diagramming tree possible events starting initial buzz
state leading possible end-of-clue states, corresponding different score
change combination. denote end-of-clue equities Exyz , first index
244

fiAnalysis Watsons Strategies Playing Jeopardy!

denotes Watsons score change, possible values x, z + (the players
score increased D), 0 (score remained unchanged), - (score decreased D).
Since one contestant score increase, total 20 end-of-clue
states: 12 contestant got clue right, eight one got right.
tree allows possibility Watson may buzz may buzz
four live states (0=initial buzz, 1=rebound human #1 wrong, 2=rebound
human #2 wrong, 3=rebound humans wrong) Watson eligible buzz.
Descending tree starting initial buzz state, assigns transition probabilities
every branch, using regular-clue model human performance, along probabilities
Watson win contested buzz one two humans attempting buzz.
defined tree, transition probabilities, set end-of-clue states,
algorithm first estimates end-of-clue equities Monte-Carlo trials remaining
clues Final Jeopardy. MC trials make use stochastic process models
human Watson performance regular clues presented earlier.
One useful trick employ reuse MC trial remaining clues
20 end-of-clue states, instead generating independent trials states.
done first performing trial (0, 0, 0) state, player attempted buzz
in, offsetting sequence scores scores going FJ specific
score change end-of-clue state. enables faster computation achieves
statistically significant comparisons states would result independent
trials. Additionally, trial performed, monitor step whether
Watson achieved guaranteed lockout given starting scores specific score
change combinations end-of-clue state. so, mark trial guaranteed win
end-of-clue state: obviates need simulate FJ trial, makes
simulations faithful, since Watson actually uses lockout-preserving buzzing live
play.
evaluated end-of-clue states described above, calculation works backwards evaluate progressively higher interior tree nodes. first calculate confidenceindependent values Watson-ineligible states Watson buzzes wrong.
three states: IS0 (Watson wrong initial buzz), IS1 (Watson wrong
human #1 wrong) IS2 (Watson wrong human #2 wrong). Formulas
values written below.
establish notation formulas, recall human models generate correlated
binary events start regular clue indicating whether contestants attempt
buzz, whether correct answer. binary variables persist clue
played, buzz decisions correctness change rebounds.
mind, let b00 , b01 , b10 , b11 denote probabilities four possible buzz/nobuzz joint decisions pair humans, p00 , p01 , p10 , p11 denote probabilities
four possible joint right/wrong outcomes. typically assume symmetric human models
b01 = b10 p01 = p10 . let pH = p10 + p11 = p01 + p11 denote singlecontestant human precision, bH = b10 + b11 = b01 + b11 denote single-contestant
human buzz attempt rate. values may fixed clue values, may use
estimated values depend round row number, depicted Figure 5.
245

fiTesauro, Gondek, Lenchner, Fan & Prager

notation, formula IS0 value is:
V (IS0) = b00 E00 + pH (b10 + b11 /2)(E+0 + E0+ ) + (1 pH )b10 (E0 + E0 )
+p01 b11 (E+ + E+ )/2 + p00 b11 E

(7)

Similarly, values IS1 IS2 states given by:
b11
b10
E0 +
V (IS1) =
bH
bH



p01 E+ + p00 E
1 pH



(8)

b11
b01
E0 +
V (IS2) =
bH
bH



p10 E+ + p00 E
1 pH



(9)

Note expressions require conditional probabilities remaining
eligible human buzz answer correctly, given first human buzzed answered
incorrectly. Using unconditional probabilities would correspond model re-draws
buzz/no-buzz right/wrong outcomes rebound, consistent
model.
Next evaluate live states LS0, LS1, LS2, LS3 Watson eligible buzz,
starting double-rebound state LS3, working backwards first rebound
states LS1 LS2, finally initial-buzz state LS0. compute separate evaluations
cases Watson buzzes buzz; larger determines
optimal policy optimal value function.
given Watson confidence level c, values double-rebound state
Watson buzzes buzz given respectively by:
VB (LS3, c) = cE+ + (1 c)E
VN B (LS3, c) = E0

(10)
(11)

Thus Watsons optimal buzz decision B (LS3, c) = arg maxB,N B {VB (LS3, c), VN B (LS3, c)}
optimal state value is: V (LS3, c) = max{VB (LS3, c), VN B (LS3, c)}.

Figure 11: Event tree live state 2, human #2 buzzed initially wrong.
246

fiAnalysis Watsons Strategies Playing Jeopardy!

Calculation first rebound state values proceeds diagrammed Figure 11,
considers LS2 state human #2 buzzed first answered incorrectly.
Red arrows indicate outcomes Watson buzz. Green brown arrows
indicate respective cases Watson wins buzz loses buzz. Z1 denotes
probability Watson wins contested buzz one human. analogous tree
LS1 obtained interchanging human #1 #2 indices.
b11 p10 E0+ + p00 V (LS3, c)
b01
E00 +
bH
bH
1 pH
b11 Z1 + b01
[cE+0 + (1 c)V (IS2)]
VB (LS2, c) =
bH


b11 (1 Z1 ) p10 E0+ + p00 V (LS3, c)
+
bH
1 pH


VN B (LS2, c) =



(12)

(13)

Figure 12: Event tree live state 0, i.e., initial buzz state.
Finally, Figure 12 illustrates analysis initial buzz state LS0. Z2 denotes
probability Watson wins buzz humans buzzing.
VN B (LS0, c) = b00 E000 + (b10 + b11 /2)[pH (E0+0 + E00+ ) +
(1 pH )(V (LS1, c) + V (LS2, c))]

(14)

VB (LS0, c) = b00 (cE+00 + (1 c)E00 )
+((b01 + b10 )Z1 + b11 Z2 )(cE+00 + (1 c)V (IS0))
+(b10 (1 Z1 ) + b11 (1 Z2 )/2)(pH E0+0 + (1 pH )V (LS1, c))
+(b01 (1 Z1 ) + b11 (1 Z2 )/2)(pH E00+ + (1 pH )V (LS2, c)) (15)
247

fiTesauro, Gondek, Lenchner, Fan & Prager

B.2 Calculation Human vs. Two Humans
present extension calculation strategic player
human instead Watson. scenario introduces additional complexity that, unlike
Watson, strategic players performance correlated opponents (and
vice versa).
approach hypothesizes mechanism generate correlated private confidence estimates (c0 , c1 , c2 ) player current clue revealed, drawn suitable
multi-variate confidence distribution. assume non-strategic players attempt
buzz private confidence value exceeds fixed threshold, chosen
probability mass threshold matches desired attempt rate, first
moment threshold matches desired precision. uniform (b, p) model
clues, described section 2.4, would match target values b = 0.61, p = 0.87
using Beta distribution player, Beta(0.69, 0.40), buzz threshold value set
0.572. However, obtain accurate meaningful threshold model humans
fitting different Beta distribution (b, p) parameter combination estimated
round row number, plotted Figure 5.
obtain correlated draws resulting multi-variate Beta distribution via
copula technique (Nelsen, 1999). entails drawing ~x = (x0 , x1 , x2 ) suitably
~ =
correlated multi-variate normal distribution, mapping respective CDF values X
(X0 , X1 , X2 ) lie unit interval, mapping values inverse
CDF Beta distribution. Since confidence draws correlated, result
correlated buzzing non-strategic players. obtain correlated precision
similarly generating correlated uniform numbers unit interval compare
players confidence values basis assigning right/wrong answers. correlation
coefficient 0.4 matches observed precision correlation Average Contestants.
model correlated confidence-based buzzing precision,
equipped make necessary modifications calculations described Equations 7-15
Figures 11,12. every case, opponent attempt rates precisions need
conditioned strategic players confidence value c. make accurate numeric
estimates conditional probabilities running many millions trials
simulation model, discretizing observed c trial, recording discrete
level number times 0, 1 2 opponents buzzed, 0, 1, 2 opponents
correct answer. Additionally, considering buzzing first second rebound,
strategic player needs estimate posterior confidence given one two opponents
already buzzed answered incorrectly. result significant drop
estimated confidence: example, initial confidence 80% drop posterior
value 50% double-rebound state LS3. Finally, ineligible states
IS0, IS1, IS2, expected opponent precisions must also conditioned upon strategic
player buzzing answering incorrectly.
B.3 Max-Delta Approximation
developed greatly simplified analytic approximation calculations given Equations 7-15 making following assumptions: (i) current game state far
end game (i.e., current clue value much smaller total value
248

fiAnalysis Watsons Strategies Playing Jeopardy!

remaining clues); (ii) three players intermediate probabilities winning (i.e.,
close 0 1). assumptions, players equity change end clue
approximately linear score changes three players. Intuitively, may
write: E (1 (S0 S1 ) + 2 (S0 S2 )), S0 players score S1 , S2
opponent scores, recognizing chances winning depend score positioning
relative opponents. assume opponent scores similar (which
often true early game), 1 2 , overall scaling factor.
clue value also overall scaling factor, express Max-Delta objective
buzz decision rewriting end-of-clue equities Exyz appearing Equations 7-15
Exyz = 2x z.
facilitate analytic calculation, also assume opponents buzz attempts precisions three players uncorrelated. equities
ineligible states {IS0,IS1,IS2} reduce to:
V (IS0) = 2(1 b)2 6bp(1 b/2) 2(1 p)b(1 b) 4p(1 p)b2
V (IS1) = V (IS2) = b 1 2bp

(16)

similarly rewrite equities four live states {LS0,LS1,LS2,LS3}
buzzing buzzing. double-rebound state LS3, reduce VB (LS3) = 4c
VN B (LS3) = 2. threshold confidence c = 3 , 43 = 2, 3 = 0.5.
likewise equating buzz/no-buzz equities live states, obtain closedform analytic expressions respective thresholds {0 , 1 , 2 }. first-rebound
thresholds, have:
1 = 2 =

2 + b2 (1 Z1 )(1 2p) + b(2p 3)(1 Z1 )
(b(Z1 1) + 1)(b(2p 1) + 4)

(17)

expression assumes 1 , 2 3 player buzz secondrebound state. Finally, initial buzz threshold 0 (again assuming no-buzz rebound
states) is:
wm + 2(1 b)2 2wV (IS0)
0 =
(18)
4(1 b)2 + 4w 2wV (IS0)
= 2p + 2(1 p)(1 + b 2bp) total equity change losing buzz
either opponent, w = b(1 b)Z1 + 0.5b2 Z2 probability beating one opponent
buzzer.
average human contestants, set b = 0.61, p = 0.87, Z1 = 1/2, Z2 = 1/3,
yielding first-rebound thresholds 1 = 2 = 0.478 initial buzz threshold 0 = 0.434.
four Max-Delta thresholds computed quite close uncorrelated Monte-Carlo
values reported Table 6 simulations average contestants early game states.

References
Ainslie, G. (2001). Breakdown Will. Cambridge Univ. Press.
Axelrod, R. (1984). Evolution Cooperation. Basic Books.
Bertsekas, D. P. (1995). Dynamic Programming Optimal Control. Athena Scientific.
249

fiTesauro, Gondek, Lenchner, Fan & Prager

Bertsekas, D. P., & Castanon, D. A. (1999). Rollout algorithms stochastic scheduling
problems. J. Heuristics, 5, 89108.
Billings, D. (2000). first international RoShamBo programming competition. Intl.
Computer Games Assn. Journal, 23 (1), 4250.
Billings, D., Davidson, A., Schaeffer, J., & Szafron, D. (2002). challenge poker.
Artificial Intelligence, 134 (1-2), 201240.
Dupee, M. (1998). Get Jeopardy! Win! Citadel Press.
Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur, A. A., ..., & Welty,
C. (2010). Building Watson: Overview DeepQA Project. AI Magazine, 31 (3),
5979.
Ferrucci, D. A. (2012). Introduction Watson. IBM J. Research Development, 56 (3/4), 1:11:15.
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, MA.
Ginsberg, M. L. (1999). GIB: Steps toward expert-level bridge-playing program.
Dean, T. (Ed.), Proc. Sixteenth Intl. Joint Conf. Artificial Intelligence, pp.
584589, San Francisco. Morgan Kaufmann Publishers.
Harris, B. (2006). Prisoner Trebekistan: decade Jeopardy! Crown Publishers.
J! Archive (2013). J! Archive. http://www.j-archive.com. Online; accessed 22-March-2013.
Jeopardy! Gameplay (2013). Jeopardy! Gameplay Wikipedia, Free Encyclopedia.
http://en.wikipedia.org/wiki/Jeopardy!#Gameplay. Online; accessed 22-March-2013.
Leisch, F., Weingessel, A., & Hornik, K. (1998). generation correlated artificial
binary data. Vienna Univ. Economics Business Administration, Working Paper
No. 13.
Nelsen, R. B. (1999). Introduction Copulas. Springer.
Prager, J. M., Brown, E. W., & Chu-Carroll, J. (2012). Special questions techniques.
IBM J. Research Development, 56 (3/4), 11:111:13.
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1987). Learning internal representations
error propagation. Rumelhart, D. E., McClelland, J. L., et al. (Eds.), Parallel
Distributed Processing: Volume 1: Foundations, pp. 318362. MIT Press, Cambridge.
Sheppard, B. (2002). World-championship-caliber Scrabble. Artificial Intelligence, 134 (1-2),
241275.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge, MA.
Tesauro, G. (1995). Temporal difference learning TD-Gammon. Commun. ACM, 38 (3),
5868.
Tesauro, G., & Galperin, G. (1996). On-line policy improvement using Monte-Carlo search.
Advances Neural Information Processing 9, pp. 10681074.
Tesauro, G., Gondek, D. C., Lenchner, J., Fan, J., & Prager, J. M. (2012). Simulation,
learning, optimization techniques Watsons game strategies. IBM J. Research
Development, 56 (34), 16:116:11.
250

fiAnalysis Watsons Strategies Playing Jeopardy!

Wu, F.-C., & Tsang, Y.-P. (2004). Second-order Monte Carlo uncertainty/variability analysis using correlated model parameters: application salmonid embryo survival risk
assessment. Ecological Modelling, 177, 393414.

251

fiJournal Artificial Intelligence Research 47 (2013) 441-473

Submitted 12/12; published 07/13

Decentralized Anti-coordination
Multi-agent Learning
Ludek Cigler
Boi Faltings

ludek.cigler@epfl.ch
boi.faltings@epfl.ch

Artificial Intelligence Laboratory
Ecole Polytechnique Federale de Lausanne
CH-1015 Lausanne, Switzerland

Abstract
achieve optimal outcome many situations, agents need choose distinct
actions one another. case notably many resource allocation problems,
single resource used one agent time. shall designer
multi-agent system program identical agents behave different way?
game theoretic perspective, situations lead undesirable Nash equilibria.
example consider resource allocation game two players compete exclusive
access single resource. three Nash equilibria. two pure-strategy NE
efficient, fair. one mixed-strategy NE fair, efficient. Aumanns
notion correlated equilibrium fixes problem: assumes correlation device
suggests agent action take.
However, smart coordination device might available. propose using
randomly chosen, stupid integer coordination signal. Smart agents learn action
use value coordination signal.
present multi-agent learning algorithm converges polynomial number
steps correlated equilibrium channel allocation game, variant resource
allocation game. show agents learn play coordination signal value
randomly chosen pure-strategy Nash equilibrium game. Therefore, outcome
efficient correlated equilibrium. CE becomes fair number
available coordination signal values increases.

1. Introduction
many situations, agents coordinate actions order use limited
resource: communication networks, channel might used one agent time.
driving car, agent prefers choose road less traffic, i.e. one chosen
smaller number agents. bidding one item several simultaneous
auctions, agent prefers auction less participants, usually lead
lower price. situations require agents take different decision. However,
agents identical, problem one face same.
learn behave differently everyone else?
Second problem arises agents common preferences action
want take: communication networks problem, every agent prefers transmit
quiet. traffic situation, agents might prefer shorter path. order
achieve efficient allocation, necessary precisely agents stay quiet,
take longer path. achieve agents exploited?
c
2013
AI Access Foundation. rights reserved.

fiCigler & Faltings

agents learn alternate, taking longer road one day, taking shorter
road next day?
central coordinator possesses complete information agents preferences
available resources easily recommend agent action take.
However, omniscient central coordinator always available. Therefore,
would like able use distributed scheme. consider scenarios
agents try use set resources repeatedly, use history past
interactions learn coordinate access resources future.
particular, consider problem radio channel access. problem, N agents
try transmit C non-overlapping channels. Fully decentralized schemes,
ALOHA (Abramson, 1970), achieve throughput 1e 37%, i.e. transmission succeeds probability 1e 0.37. complex schemes, based
distributed constraint optimization (Cheng, Raja, Xie, & Howitt, 2009), reach
throughput close 100%. throughput, mean probability successful transmission given channel. However, messages necessary implement schemes
create overhead eliminates part benefits.
paper propose instead use simple signal agents observe
ergodically fluctuates. signal could common clock, radio broadcasting
specified frequency, decimal part price certain stock given time, etc.
Depending stupid signal, smart agents learn take different action
value. say signal stupid, doesnt anything
game agents give meaning acting differently
value coordination signal.
Lets look simplest example channel access problem: one 2 agents try
transmit one shared channel. model situation game normal
form. Agents choose two actions: stay quiet (Q) transmit (T ).
one agent may transmit successfully time. agent transmits alone, receives
positive payoff. agent transmit channel, payoff 0. agents
try transmit channel time, transmissions fail incur
cost c.
payoff matrix game looks follows:

Q


Q
0, 0
1, 0


0, 1
c, c

game two pure-strategy Nash equilibria (NE), one player stays quiet
one transmits. also one mixed-strategy NE, player stays
1
quiet probability c+1
. two pure-strategy NE efficient, maximize
social welfare, fair: one player gets full payoff, even though
game symmetric. mixed-strategy NE fair, efficient: expected
payoff players 0.
such, Nash equilibria game rather undesirable: either efficient
fair, time. seminal paper, Aumann (1974) proposed
notion correlated equilibrium fixes problem. correlated equilibrium (CE)
probability distribution joint strategy profiles game. correlation device
442

fiDecentralized Anti-coordination Multi-agent Learning

samples distribution recommends action agent play. probability
distribution CE agents incentive deviate recommended
action.
simple game described above, exists CE fair socially
efficient: correlation device samples two pure-strategy NE probability 21 recommends players NE play. corresponds
authority tells player whether stay quiet transmit.
Correlated equilibria several nice properties: easier find succinct
representation game, polynomial time, see (Papadimitriou & Roughgarden, 2008).
Also, every Nash equilibrium correlated equilibrium. Also, convex combination
two correlated equilibria correlated equilibrium. However, smart correlation device
randomizes joint strategy profiles might always available.
possible achieve correlated equilibrium without actual correlation device.
Assume game played repeatedly, agents observe history
actions taken opponents. learn predict future action (or distribution future actions) opponents. predictions need calibrated, is,
predicted probability agent play certain action aj converge
actual frequency agent plays action aj . Agents always play action
best response predictions opponents actions. Foster Vohra (1997)
showed case, play converges set correlated equilibria.
However, paper, Foster Vohra provide specific learning rule
achieve certain CE. Furthermore, approach requires every agent able
observe actions every opponent. requirement met, convergence
correlated equilibrium guaranteed anymore.
paper, focus generalization simple channel allocation problem
described above. N agents always data transmit,
C channels transmit. assume N C. Access channel
slotted, is, agents synchronized start transmissions
time. Also, transmissions must length. one agent attempts
transmit single channel, collision occurs none transmissions
successful. unsuccessful transmission cost agent, since consume
(possibly constrained) power benefit. transmitting cost
anything.
assume agents receive binary feedback. transmitted data,
find whether transmission successful. transmit,
choose channel observe. receive information whether observed channel
free not.
described normal-form game, problem several efficient (but unfair)
pure-strategy Nash equilibria, group C agents gets assigned channels.
remaining N C agents get stranded. also fair inefficient mixed-strategy NE,
agents choose transmission channels random. example resource
allocation game above, exists correlated equilibrium efficient fair.
stupid coordination signal introduced paper helps agents learn
play (potentially) different efficient outcome value. way,
reach efficient allocation still preserving level fairness.
443

fiCigler & Faltings

main contributions work following:
propose learning strategy agents channel allocation game that, using
minimal information, converges polynomial time randomly chosen efficient
pure-strategy Nash equilibrium game.
show agents observe common discrete correlation signal,
learn play efficient pure-strategy NE signal value. result
correlated equilibrium increasingly fair number available signals K
increases.
experimentally evaluate sensitive algorithm player population
dynamic, i.e. players leave enter system. also evaluate
algorithms resistance noise, feedback players receive
coordination signal observe.
channel allocation algorithm proposed paper implemented Wang,
Wu, Hamdi, Ni (2011) real-world wireless network setting. showed
wireless devices use use actual data transmitted coordination
signal. way, able achieve 2-3 throughput gain compared random
access protocols ALOHA.
worth noting work, focus reaching correlated fair
outcome, provided agents willing cooperate. situations using
resources costs nothing, self-interested agent could stubbornly keep using it. Everyone
else better trying access resource. sometimes called
watch crazy bully strategy (Littman & Stone, 2002).
order prevent kind behavior, would need make sure order
use resource, agent pay cost. cost may already implicit
problem, fact wireless transmission costs energy, may imposed
external payments. recent work (Cigler & Faltings, 2012), show leads
equilibria rational agents indifferent accessing resource yielding,
equilibria implement allocation policy rational agents. consider
issue beyond scope paper refer reader work
deeper analysis.
rest paper organized follows: Section 2, give basic definitions
game theory theory Markov chains use throughout paper.
Section 3, present algorithm agents use learn action possible
correlation signal value. Section 4 prove algorithm converges
efficient correlated equilibrium polynomial time number agents channels.
show fairness resulting equilibria increases number signals K
increases Section 5. Section 6 highlights experiments show actual convergence
rate fairness. also show algorithm performs case population
changing dynamically. Section 7 present related work game theory
cognitive radio literature, Section 8 concludes.
444

fiDecentralized Anti-coordination Multi-agent Learning

2. Preliminaries
section, introduce basic concepts game theory theory
Markov chains going use throughout paper.
2.1 Game Theory
Game theory study interactions among independent, self-interested agents.
agent participates game called player. player utility function
associated state world. Self-interested players take actions achieve
state world maximizes utility. Game theory studies attempts
predict behaviour, well final outcome interactions. Leyton-Brown
Shoham (2008) give complete introduction game theory.
basic way represent strategic interaction (game) using so-called normal
form.
Definition 1. finite, N -person normal-form game tuple (N, A, u),
N set N players;
= A1 A2 . . . , Ai set actions available player i. vector
= (a1 , a2 , . . . , ) called action profile;
u = (u1 , u2 , . . . , uN ), ui : R utility function player assigns
action vector certain utility (payoff).
playing game, players select strategy. pure strategy
player selects one action ai Ai . vector pure strategies player =
(1 , 2 , . . . , N ) called pure strategy profile. mixed strategy selects probability
distribution entire action space, i.e. (Ai ). mixed strategy profile
vector mixed strategies player.
Definition 2. say mixed strategy player best response strategy
profile opponents strategy i0 ,
ui (i , ) ui (i0 , )
One basic goals game theory predict outcome strategic interaction.
outcome stable therefore, usually called equilibrium. One requirement outcome equilibrium none players incentive
change strategy, i.e. players play best-response strategies others.
defines perhaps important equilibrium concept, Nash equilibrium:
Definition 3. strategy profile = (1 , 2 , . . . , N ) Nash equilibrium (NE)
every player i, strategy best response strategies others .
essential Nash equilibria are, several disadvantages. First, may
hard find: Chen Deng (2006) show finding NE PPAD-complete. Second,
might multiple Nash equilibria, shown example Section 1. Third,
efficient NE may fair one, even symmetric game. give
formal definition correlated equilibrium fixes issues:
445

fiCigler & Faltings

Definition 4. Given N -player game (N, A, u), correlated equilibrium tuple (v, , ),
v tuple random variables v = (v1 , v2 , . . . , vN ) whose domains =
(D1 , D2 , . . . , DN ), joint probability distribution v, = (1 , 2 , . . . , N )
vector mappings : Di 7 Ai , player every mapping 0i : Di 7 Ai
case
X
X

(d)ui (1 (d1 ), 2 (d2 ), . . . , N (dN ))
(d)ui 01 (d1 ), 02 (d2 ), . . . , 0N (dN ) .
dD

dD

2.2 Markov Chains
learning algorithm propose analyze paper described randomized algorithm. randomized algorithm, steps depend value
random variable. One useful technique analyze randomized algorithms describe
execution Markov chain.
Markov chain random process Markov property. random process
collection random variables; usually describes evolution random value
time. process Markov property state (or value) next time step depends
exclusively value previous step, values past.
say process memoryless. imagine execution randomized
algorithm finite-state automaton non-deterministic steps, easy see
execution maps Markov chain.
formal definition Markov chain follows:
Definition 5. (Norris, 1998) Let countable set. called state
called state space. say P= (i : I) measure 0 <
I. addition total mass iI equals 1, call distribution.
work throughout probability space (, F, P). Recall random variable X
values function X : I. Suppose set
= Pr(X = i) = Pr ({ : X() = i}) .
defines distribution, distribution X. think X modelling random
state takes value probability .
say matrix P = (pij : i, j I) stochastic every row (pij : j I)
distribution.
say (Xt )t0 Markov chain initial distribution transition matrix
P
1. X0 distribution ;
2. 0, conditional Xt = i, Xt+1 distribution (pij : j I) independent
X0 , X1 , . . . , Xt1 .
explicitly, conditions state that, 0 i0 , . . . , it+1 I,
1. Pr(X0 = i0 ) = i0 ;
2. Pr(Xt+1 = it+1 |X0 = i0 , . . . , Xt = ) = pit it+1 .
446

fiDecentralized Anti-coordination Multi-agent Learning

Theorem 1. Let set states. vector hitting probabilities hA = (hA
:
{0, 1, . . . , N }) minimal non-negative solution system linear equations

1


hi = P

p
h
/A
j{0,1,...,N } ij j
Intuitively, hitting probability hA
probability Markov chain
starts state i, ever reach states A.
One property randomized algorithms particularly interested
convergence. set states algorithm converged, define
time takes reach state set state corresponding
Markov chain hitting time:
Definition 6. (Norris, 1998) Let (Xt )t0 Markov chain state space I. hitting
time subset random variable H : {0, 1, . . .} {} given
H () = inf{t 0 : Xt () A}
Specifically, interested expected hitting time set states A, given
Markov chain starts initial state X0 = i. denote quantity
kiA = Ei (H ).
general, expected hitting time set states found solving
system linear equations.
Theorem 2. vector expected hitting times k = E(H ) = (kiA : I)
minimal non-negative solution system linear equations

ki = 0 P

(1)

kiA = 1 + j
p
k
/A
ij
j
/
Convergence absorbing state may guaranteed general Markov chain.
calculate probability reaching absorbing state, use following theorem
(Norris, 1998):
Theorem 3. Let set states. vector hitting probabilities hA = (hA
:
{0, 1, . . . , N }) minimal non-negative solution system linear equations

1


hi = P

p
h
/A
ij
j
j{0,1,...,N }
Solving systems linear equations Theorems 2 3 analytically might
difficult many Markov chains though. Fortunately, Markov chain
one absorbing state = 0, move state j j, use
following theorem derive upper bound expected hitting time, proved
Rego (1992):
Theorem 4. Let = {0}.
1 : E(Xt+1 |Xt = i) <
> 1,


kiA < log +

447


1




fiCigler & Faltings

3. Learning Algorithm
section, describe algorithm agents use learn correlated equilibrium channel allocation game.
Let us denote space available correlation signals K := {0, 1, . . . , K 1},
space available channels C := {1, 2, . . . , C}. Assume C N ,
agents channels (the opposite case easier). agent strategy fi : K {0}C
uses decide channel access time receives correlation
signal kt . fi (kt ) = 0, agent transmit signal kt . agent stores
strategy simply table.
agent adapts strategy follows:
1. beginning, k0 K, fi (k0 ) initialized uniformly random C.
is, every agent picks random channel transmit on, agent monitor
channels.
2. time t:
fi (kt ) > 0, agent tries transmit channel fi (kt ).
otherwise fi (kt ) = 0, agent chooses random channel mi (t) C
monitor activity.
3. Subsequently, agent observes outcome choice: agent transmitted
channel, observes whether transmission successful. was,
agent keep strategy unchanged. collision occurred, agent sets
fi (kt ) := 0 probability p. probability 1 p, strategy remains same.
4. agent transmit, observes whether channel mi (t) monitored
free. channel free, agent sets fi (kt ) := mi (t) probability 1.
channel free, strategy fi remains same.

4. Convergence
important property learning algorithm if, fast converge
pure-strategy Nash equilibrium channel allocation game every signal value.
algorithm randomized. Therefore, instead analyzing worst-case behavior (that may
arbitrarily bad), analyze expected number steps convergence.
4.1 Convergence C = 1, K = 1
single channel single coordination signal, prove following theorem:
Theorem 5. N agents C = 1, K = 1, 0 < p < 1, expected number steps
allocation algorithm
converges
pure-strategy Nash equilibrium channel


1
allocation game p(1p) log N .
prove convergence algorithm, useful describe execution
Markov chain.
448

fiDecentralized Anti-coordination Multi-agent Learning

N agents compete single signal value, state Markov chain
vector {0, 1}N denotes agents attempting transmit. purpose
convergence proof, important many agents trying transmit,
agents. probability agents back-off
everyone. Therefore, describe algorithm execution using following chain:
Definition 7. Markov chain describing execution allocation algorithm
C = 1, K = 1, 0 < p < 1 chain whose state time Xt {0, 1, . . . , N },
Xt = j means j agents trying transmit time t.
transition probabilities chain look follows:
Pr (Xt+1 = N |Xt = 0) = 1
Pr (Xt+1 = 1|Xt = 1) = 1

ij
Pr (Xt+1 = j|Xt = i) =
p (1 p)j
j

(restart)
(absorbing)
> 1, j

transition probabilities 0. agents
transmitting channel, agent attempt access it.
probability Pr (Xt+1 = N |Xt = 0) equal 1 channel becomes
free (Xt = 0), agents spot time + 1, everyone transmit (therefore
chain state Xt+1 = N ). probability Pr (Xt+1 = 1|Xt = 1) equal one
single agent successfully transmits channel, keep transmitting
forever after, agent attempt transmit there. Finally, probability
Pr (Xt+1 = j|Xt = i) expresses fact Xt = (i agents transmit time t),
probability agent transmitted time keep transmitting time + 1
probability 1 p.
interested number steps take Markov chain first arrive
state Xt = 1 given started state X0 = N . would mean agents
converged setting one transmitting, others not.
Definition 6 defined hitting time describes quantity.
show expected value E[h1 ] hitting time state Xt = 1 (and
corollary, prove Theorem 5) following steps:
1. show expected hitting time set states = {0, 1} (Lemma 6)
2. show probability Markov chain enters state 1 entering state
0, starts state > 1 (Lemma 7)
3. Finally, using law iterated expectations, combine two lemmas show
expected hitting time state 1.
Lemma 6. Let = {0, 1}. expected
hitting

time set states Markov
1
chain described Definition 7 p log N .
Proof. first prove
hitting time set A0 = {0} slightly
expected

modified Markov chain p1 log N .
449

fiCigler & Faltings

Let us define new Markov chain (Yt )t0 following transition probabilities:
Pr (Yt+1 = 0|Yt = 0) = 1

ij
Pr (Yt+1 = j|Yt = i) =
p (1 p)j
j

(absorbing)
j 0, 1

Note transition probabilities chain (Xt )t0 , except
states 0 1. state 1 positive probability going state 0, state 0
absorbing. Clearly, expected hitting time set A0 = {0} new chain
upper bound expected hitting time set = {0, 1} old chain.
path leads state 0 new chain either go state 1
(so happened probability old chain), goes state 1,
old chain would stop state 1 (but would one step shorter).
chain state Yt = i, next state Yt+1 drawn binomial distribution
parameters (i, 1 p). expected next state therefore
E(Yt+1 |Yt = i) = i(1 p)
1
therefore use Theorem 4 := 1p
derive A0 = {0},
hitting time is:


l
1
1
A0
ki < log 1 +
log
1p
p
p

also upper bound kiA = {0, 1} old chain.
Lemma 7. probability hi Markov chain defined Definition 7 enters state 1
entering state 0, started state > 1, greater 1 p.
Proof. Calculating probability chain X enters state 1 state 0 equal
calculating hitting probability, i.e. probability chain ever enters
given state, modified Markov chain probability staying state 0
Pr (Xt+1 = 0|Xt = 0) = 1. set states A, let us denote hA
probability
Markov chain starting state ever enters state A. calculate probability,
use Theorem 3. modified Markov chain cannot leave neither state 0
state 1, computing hA
= 1 easy, since matrix system linear equations
lower triangular.
Well show hi q = 1 p > 1 using induction. first step calculating hi
{0, 1, 2}.
h0 = 0
h1 = 1
h2 = (1 p)2 h2 + 2p(1 p)h1 + p2 h0
2p(1 p)
2(1 p)
=
=
1 p.
1 (1 p)2
2p
Now, induction step, derive bound hi assuming hj q = 1 p
j < i, j 2.
450

fiDecentralized Anti-coordination Multi-agent Learning


X
ij
hi =
p (1 p)j hj
j
j=0




X
ij
p (1 p)j q ipi1 (1 p)(q h1 ) pi h0
j
j=0

= q ipi1 (1 p)(q 1) q = 1 p.
means matter state 2 Markov chain starts in, enter
state 1 earlier state 0 probability least 1 p.
finish proof bound expected hitting time state 1.
use law iterated expectations:
Theorem 8. (Billingsley, 2012) Let X random variable satisfying E(|X|) <
another random variable probability space.
E[X] = E [E[X|Y ]] ,
i.e., expected value X equal conditional expected value X given .
Let h1 random variable corresponding hitting time state 1. Define
random variable Z denoting number passes state 0 Markov chain makes
reaches state 1. Theorem 8, get:
E[h1 ] = E[E[h1 |Z]].
Lemma 6, shown expected number steps hA Markov chain
reaches set states = {0, 1}. write
E[E[h1 |Z]] = E

" Z
X

#
hA = E[Z hA ] = hA E[Z].

i=1

Lemma 7 know probability chain passes state 1
passing 0 greater 1 p. Therefore, say E[Z] E[Z 0 ]
Z 0 random variable distributed according geometric distribution success
probability 1 p.


1
hA
0
=O
log N .
E[h1 ] = hA E[Z] hA E[Z ] =
1p
p(1 p)
concludes proof Theorem 5.
shown expected time convergence algorithm finite,
polynomial. probability algorithm converge finite number
steps absorbing state? following theorem shows since expected hitting
time absorbing state finite, probability 1.
451

fiCigler & Faltings

Theorem 9. Let h1 hitting time state Xt = 1 Markov chain
Definition 7.
Pr(h1 finite) = 1.
Proof. Markov inequality, know since h1 0,
Pr(h1 )

E[h1 ]
.


Therefore,
Pr(h1 finite) = 1 lim Pr(h1 ) 1 lim




E[h1 ]
= 1.


means algorithm converges almost surely Nash equilibrium
channel allocation game.
4.2 Convergence C 1, K = 1
Theorem 10. N agents C 1, K = 1, expected number steps
learning algorithm

h converges toia pure-strategy Nash equilibrium channel allocation
1
game C 1p p1 log N + C .
Proof. beginning, least one channel,
N agents want
1
transmit. take average p log N steps get state either 1 0
agents transmit (Lemma 6). call period round.
agents backed off, take average C steps
find empty channel. call period break.
channels might oscillate round break periods parallel,
worst case, whole system oscillate
two periods.


1
single channel, takes average 1p oscillations two periods


one agent transmits channel. C 1, takes
1
average C 1p steps round break channels one

h

1
1
agent transmitting. Therefore, take average C 1p
log
N
+
C
steps
p
system converges.
4.3 Convergence C 1, K 1
show convergence time K > 1, use general problem.
Imagine K identical instances Markov chain. know
original Markov chain converges initial state absorbing state expected
time . imagine complex Markov chain: every step, selects uniformly
random one K instances original Markov chain, executes one step
instance. time Tall K instances converge absorbing states?
extension well-known Coupon collectors problem (Feller, 1968).
following theorem (Gast, 2011, Thm. 4) shows upper bound expected number
steps K instances original Markov chain converge:
452

fiDecentralized Anti-coordination Multi-agent Learning

Theorem 11. (Gast, 2011) Let K instances Markov chain
known converge absorbing state expectation steps. select randomly
one Markov chain instance time allow perform one step chain,
take average E[Tall ] K log K + 2T K + 1 steps K instances converge
absorbing states.
arbitrary C 1, K 1, following theorem follows Theorems 10 11:
Theorem 12. N agents C 1, K 1, 0 < p < 1, 0 < q < 1, expected number
steps learning algorithm converges pure-strategy Nash equilibrium
channel allocation game every k K




1
1
(K log K + 2K)C
C + log N + 1 .
1p
p
Aumann (1974) shows Nash equilibrium correlated equilibrium,
convex combination correlated equilibria correlated equilibrium. also know
pure-strategy Nash equilibria algorithm converges efficient:
collisions, every channel every signal value, agent transmits. Therefore,
conclude following:
Theorem 13. learning algorithm defined Section 3 converges expected polynomial
1
time (with respect K, C, p1 , 1p
log N ) efficient correlated equilibrium
channel allocation game.

5. Fairness
Agents decide strategy independently value coordination signal. Therefore, every agent equal chance game converges equilibrium
favorable her. agent transmit resulting equilibrium given signal
value, say agent wins slot. C available channels N agents, agent
C
wins given slot probability N
(since agent transmit two channels
time).
analyse fairness algorithm converged correlated equilibrium. algorithms converge absorbing state (such ALOHA),
need analysed intermediate states execution, believe approach justified fact algorithm converges relatively quickly, polynomial
time.
describe number signals agent wins channel
random variable Xi . variable distributed according binomial distribution
C
parameters K, N
.
measure fairness, use Jain index (Jain, Chiu, & Hawe, 1984).
advantage Jain index continuous, resource allocation strictly
fair higher Jain index (unlike measures assign binary values,
whether least half agents access resource). Also, Jain index independent
population size, unlike measures standard deviation agent allocation.
453

fiCigler & Faltings

random variable X, Jain index following:
J(X) =

(E[X])2
E[X 2 ]

C
),
X distributed according binomial distribution parameters (K, N
first second moments

C
E[X] = K
N


2
C 2
C N C
E X = K
+K

,
N
N
N
Jain index
J(X) =

C K
.
C K + (N C)

(2)

Jain index holds 0 < J(X) 1. allocation considered fair
J(X) = 1.

N
Theorem 14. C, K = N
C , limit limN CK = 0,
lim J(X) = 1,

N

allocation becomes fair N goes .
Proof. theorem follows fact
lim J(X) = lim

N

N

C K
C K + (N C)

limit equal 1, need
N C
=0
N C K
lim

holds exactly K =
assume C N ).

N
C



(that K grows asymptotically faster

N
C;

note

practical purposes, may also need know big shall choose K given C
N . following theorem shows that:
Theorem 15. Let > 0.
1
K>





N
1 ,
C

J(X) > 1 .
Proof. theorem follows straightforwardly Equation 2.
454

fiDecentralized Anti-coordination Multi-agent Learning

5

Convergence steps

10

4

10

3

10

0

10

20

30

40

50

60

70

C

Figure 1: Average number steps convergence N = 64, K = N C
{1, 2, . . . , N }.

6. Experimental Results
experiments, report average values 128 runs experiment.
Error bars graphs denote interval contains true expected value
probability 95%, provided samples follow normal distribution. error bars
missing either graph reports values obtained theoretically (Jain index
constant back-off scheme) confidence interval small scale graph.
6.1 Static Player Population
first analyze case population players remains
time.
6.1.1 Convergence
First, interested convergence allocation algorithm. Section 4
know polynomial. many steps algorithm need converge
practice?
Figure 1 presents average number convergence steps N = 64, K = N
increasing number available channels C {1, 2, . . . , N }. Interestingly, convergence
takes longest time C = N . lowest convergence time C = N2 ,
C = 1 increases again.
happens change size signal space K? Figure 2 shows
average number steps convergence fixed N , C varying K. Theoretically,
455

fiCigler & Faltings

1400

Convergence steps

1200
1000
800
600
400
200
0
0

10

20

30

40

50

60

70

K

1

1

0.9

0.9

0.8

0.8

0.7

0.7

Jain index

Jain index

Figure 2: Average number steps convergence N = 64, C =

0.6
0.5
K=N
K = Nlog N

0.4

0.2
0

20

40

60

80

100

120

0.5
K=2
K = 2log N
2

0.3

K = N2

0.2
0

140

N

K {2, . . . , N }.

0.6

0.4

2

0.3

N
2

K = 2N
20

40

60

80

100

120

140

N

(a) C = 1

(b) C =

N
2

Figure 3: Jain fairness index different settings C K, increasing N .

shown number convergence steps O(K log K) Theorem 12. However,
practice convergence resembles linear dependency K. algorithm
needs converge coordination signals.
6.1.2 Fairness

Section 5, know K = N
C , Jain fairness index converges 1
N goes infinity. fast convergence? big need choose K,
depending N C, achieve reasonable bound fairness?
456

fiDecentralized Anti-coordination Multi-agent Learning

Figure 3 shows Jain index N increases, C = 1 C = N2 respectively,
various settings K. Even though every time K = N
C (that is, K grows faster
N
C ) Jain index increases (as shown Theorem 14), marked difference
various settings K. K = N
C , Jain index (from Equation 2):
J(X) =

N
.
2N C

(3)

Therefore, C = 1, Jain index converges 0.5, C =
equal 23 N > 0, Figure 3 shows.

N
2,

Jain index

6.1.3 Optimizing Fairness
saw fair outcome allocation algorithm agents consider game
signal value independently. However, best do?
improve fairness, agent correlates decisions different signal values?
perfectly fair solution, every agent wins (and consequently transmit)
number signal values. However, assume agents know many
agents system. Therefore, agents know fair
share signal values transmit for. Nevertheless, still use information
many slots already transmitted decide whether back-off stop
transmitting collision occurs.
Definition 8. strategy fit agent round t, define cardinality
number signals strategy tells agent access:
fi
fi
|fit | = fi k K|fit (k) > 0 fi
Intuitively, agents whose strategies higher cardinality back-off often
strategy low cardinality.
compare following variations channel allocation scheme, differ
original one probability agents back collisions:
Constant scheme described Section 3; Every agent backs constant
probability p.
Linear back-off probability p =

|fit |
K .

Exponential back-off probability p =



|f |
1 Ki

parameter 0 < < 1.

Worst-agent-last case collision, agent lowest |fit | back
off. others collided, back off. greedy algorithm requires
information assume agents have.
compare fairness allocations experiments, need define Jain
index actual allocation. resource allocation vector X = (X1 , X2 , . . . , XN ),
Xi cardinality strategy used agent i. allocation X, Jain index is:
P
2
N
i=1 Xi
J(X) =
P
2
N N
i=1 Xi
457

fiCigler & Faltings

C = N/2, K = 2log2N
1
0.98

Jain index

0.96
0.94
0.92
0.9
Constant
Linear
Exponential
Worstagent

0.88
0.86
0

20

40

60

80

100

120

140

N

Figure 4: Jain fairness index channel allocation scheme various back-off probabilities, C = N2 , K = 2 log2 N

Figure 4 shows average Jain fairness index allocation back-off probability
variations. fairness approaching 1 worst-agent-last algorithm.
worst everyone using back-off probability. ratio back-off
probability lowest-cardinality agent highest-cardinality agent decreases,
fairness increases.
shows improve fairness using different back-off probabilities. Nevertheless, shape fairness curve them. Furthermore,
exponential back probabilities lead much longer convergence, shown Figure 5.
C = N2 , convergence time linear constant back-off schemes similar.
unrealistic worst-agent-last scheme obviously fastest, since resolves collisions
1 step, unlike back-off schemes.
6.2 Dynamic Player Population
take look performance algorithm population players
changing time (either new players join old players get replaced new ones).
also analyze case errors players observe either
coordination signal channel feedback noisy.
6.2.1 Joining Players
section, present results experiments group players joins
system later. corresponds new nodes joining wireless network. precisely,
458

fiDecentralized Anti-coordination Multi-agent Learning

C = N/2, K = 2log2N
Constant
Linear
Exponential
Worstagent
Convergence steps

3

10

2

10

1

10

1

2

10

10
N

Figure 5: Convergence steps various back-off probabilities.
25% players join network beginning. remaining 75% players
join network later, one one. new player joins network previous players
converged perfect channel allocation.
experiments two ways initializing strategy new player.
Greedy Either, joining players cannot observe many players already system. Therefore, initial strategy tries transmit possible
slots.
Polite Or, players observe N (t), number players already
system time t, new player joins system. Therefore, initial
strategy tries transmit slot probability N1(t) .
Figure 6 shows Jain index final allocation 75% players join later,
C = 1. players join greedy, aggressive. start
transmitting slots. hand, polite, aggressive
enough: new player starts strategy aggressive strategies
players already system. difference new player experience
collision every slot transmits in. old players experience collision
1
N (t) slots. Therefore, back less slots.
Therefore, especially constant scheme, resulting allocation unfair:
either better new players (when greedy) older players (when
players polite).
phenomenon illustrated Figure 7. compares measure called group fairness:
average throughput last 25% players joined network end (new
459

fiCigler & Faltings

C = 1, K = Nlog N, join delay = converge init population = 0.25, KPS
2

1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

Jain index

Jain index

C = 1, K = Nlog2N, join delay = converge init population = 0.25
1

0.5
0.4
0.3

0.5
0.4
0.3

0.2

0.2

Constant
Linear
Worstplayer

0.1
0
5

10

15

20

25

30

35

40

45

Constant
Linear
Worstplayer

0.1
0
5

50

10

15

20

25

N

30

35

40

45

50

N

(a) Greedy

(b) Polite

Figure 6: Joining players, Jain index. C = 1 K = N log2 N . two graphs show
results two ways initializing strategy new player.

C = 1, K = Nlog2N, join delay = converge init population = 0.25

C = 1, K = Nlog2N, join delay = converge init population = 0.25, KPS

5

0.8

Constant
Linear
Worstplayer

4.5

Constant
Linear
Worstplayer

0.7
0.6

3.5
Group fairness

Group fairness

4

3
2.5
2

0.5
0.4
0.3

1.5
0.2

1
0.5
0

10

20

30

40

50

N

0.1
0

10

20

30

40

50

N

(a) Greedy

(b) Polite

Figure 7: Joining players, group fairness. C = 1 K = N log2 N . two graphs show
results two ways initializing strategy new player.

460

fiDecentralized Anti-coordination Multi-agent Learning

C = N/2, K = 2log2N, join delay = converge init population = 0.25

C = N/2, K = 2log2N, join delay = converge init population = 0.25, KPS

1

1

0.9

0.9

0.8

0.8
0.7

0.6

Jain index

Jain index

0.7

0.5
0.4
0.3

0.5
0.4
0.3

0.2

0.2

Constant
Linear
Worstplayer

0.1
0
5

0.6

10

15

20

25

30

35

40

45

Constant
Linear
Worstplayer

0.1

50

0
5

10

15

N

20

25

30

35

40

45

50

N

(a) Greedy

(b) Polite

Figure 8: Joining players, Jain index. C = N2 K = 2 log2 N . two graphs show
results two ways initializing strategy new player.

players) divided average throughput first 25% players join network
beginning (old players).
Lets look first case players greedy. constant scheme,
ratio around 4.5. linear scheme, ratio lower, although increasing N (the
total number players) grows. worst-player-last scheme, ratio stays constant
interestingly, lower 1, means old players better
new players.
players polite, situation opposite. Old players way better
new players. constant scheme, throughput ratio 0.2.
Figures 8 9 show graphs C = N2 . Here, newly joining players
worse even start transmitting every slot.
experience collision every time (because channels slots occupied), old
players experience collision probability N1 . hand, overall
2

fairness whole population better, channels share
agent use one channel.
difference old new players even pronounced new
players polite.
6.2.2 Restarting Players
Another scenario looked happens one old players switches
replaced new player randomly initialized strategy. say
player got restarted. wireless network, corresponds situation user
restarts router. Note number players network stays same,
players forget learned start scratch.
Specifically, every round, every player probability pR
restarted. restart, start strategy initialized two ways:
461

fiCigler & Faltings

C = N/2, K = 2log N, join delay = converge init population = 0.25

C = N/2, K = 2log2N, join delay = converge init population = 0.25, KPS

2

0.95

1

Constant
Linear
Worstplayer

0.9

Constant
Linear
Worstplayer

0.9

0.85
Group fairness

Group fairness

0.8

0.8
0.75
0.7

0.6
0.5

0.65

0.4

0.6
0.55
0

0.7

10

20

30

40

50

N

0

10

20

30

40

50

N

(a) Greedy

(b) Polite

Figure 9: Joining players, group fairness. C = N2 K = 2 log2 N . two graphs show
results two ways initializing strategy new player.

Greedy Assume player know N , number players system.
signal value k K chooses randomly fi (k) C. means
attempts transmit every slot randomly chosen channel.
Polite Assume player know N . k K, chooses fi (k) C probability
C
N , fi (k) := 0 otherwise.
Figure 10 shows average overall throughput N = 32, C = 1, K = N log2 N
K = N two initialization schemes. dotted line four graphs shows
overall performance players attempt transmit randomly chosen channel
C
probability N
. baseline solution reaches 1e 37% average throughput.
probability restart increases, average throughput decreases. players
get restarted greedy, attempt transmit every slot.
one channel available, means restarted player causes collision every slot.
Therefore, surprising restart probability pR = 101 N = 32,
throughput virtually 0: every step, expectation least one player get restarted,
collision almost always.
interesting phase transition occurs pR 104 K = N log2 N ,
pR 103 K = N . There, performance
baseline random access scenario (that requires players know N though). Similar
phase transition occurs players polite, even though resulting throughput
higher, since restarted players less aggressive.
Yet another interesting, surprising, phenomenon worstplayer-last scheme still achieves highest throughput, constant back scheme
better linear back-off scheme. average overall throughput,
matters fast players able reach perfect allocation disruption.
worst-player-last scheme fastest, since resolves collision 1 step. con462

fiDecentralized Anti-coordination Multi-agent Learning

N = 32, C = 1, K = Nlog2N, KPS
1

0.9

0.9

0.8

0.8

0.7

0.7

System throughput

System throughput

N = 32, C = 1, K = Nlog2N
1

0.6
0.5
0.4
0.3
0.2
0.1
0

6

0.5
0.4
0.3
0.2

Constant
Linear
Worstplayer

0.1
4

10

0.6

10
Restart probability

0

2

10

Constant
Linear
Worstplayer
6

(a) Greedy, K = N log2 N

2

10

N = 32, C = 1, K = N, KPS
1

0.9

0.9

0.8

0.8

0.7

0.7

System throughput

System throughput

N = 32, C = 1, K = N

0.6
0.5
0.4
0.3
0.2

0

10
Restart probability

(b) Polite, K = N log2 N

1

0.1

4

10

0.6
0.5
0.4
0.3
0.2

Constant
Linear
Worstplayer
6

10

0.1
4

10
Restart probability

0

2

10

Constant
Linear
Worstplayer
6

10

(c) Greedy, K = N

4

10
Restart probability

(d) Polite, K = N

Figure 10: Restarting players, throughput, N = 32, C = 1

463

2

10

fiCigler & Faltings

N = 32, C = N/2, K = Nlog2N, KPS
1

0.9

0.9

0.8

0.8

0.7

0.7

System throughput

System throughput

N = 32, C = N/2, K = Nlog2N
1

0.6
0.5
0.4
0.3
0.2
0.1
0

6

0.5
0.4
0.3
0.2

Constant
Linear
Worstplayer

0.1
4

10

0.6

10
Restart probability

0

2

10

Constant
Linear
Worstplayer
6

(a) Greedy, K = 2 log2 N

10

N = 32, C = N/2, K = 2, KPS
1

0.9

0.9

0.8

0.8

0.7

0.7

System throughput

System throughput

N = 32, C = N/2, K = 2

0.6
0.5
0.4
0.3
0.2

0

2

10
Restart probability

(b) Polite, K = 2 log2 N

1

0.1

4

10

0.6
0.5
0.4
0.3
0.2

Constant
Linear
Worstplayer
6

10

0.1
4

10
Restart probability

0

2

10

Constant
Linear
Worstplayer
6

10

(c) Greedy, K = 2

4

2

10
Restart probability

10

(d) Polite, K = 2

Figure 11: Restarting players, throughput, N = 32, C =

N
2

stant scheme back-off probability p = 21 worse (see Theorem 12). linear scheme
slowest.
Figure 11 shows average overall throughput C = N2 , K = log2 N K = 2.
substantial difference players greedy polite. Since
many channels available, restarted player cause small number collisions
(in one channel N2 every slot), throughput decrease much.
Also, convergence time linear constant scheme
C = N2 , adapt disruption equally well.
6.2.3 Noisy Feedback
far assumed players receive perfect feedback whether transmissions
successful not. could also observe activity given channel perfectly.
going loosen assumption now.
464

fiDecentralized Anti-coordination Multi-agent Learning

N = 32, C = N/2, K = Nlog2N
1

0.9

0.9

0.8

0.8

0.7

0.7

System throughput

System throughput

N = 32, C = 1, K = Nlog2N
1

0.6
0.5
0.4
0.3
0.2
0.1
0

6

0.5
0.4
0.3
0.2

Constant
Linear
Worstplayer
10

0.6

0.1
4

10
Noisy feedback probability

0

2

10

Constant
Linear
Worstplayer
6

10

(a) C = 1, K = N log2 N

4

10
Noisy feedback probability

(b) C =

N
2

2

10

, K = 2 log2 N

Figure 12: Noisy feedback, throughput, N = 32

N = 32, C = N/2, K = Nlog2N
1

0.98

0.98

0.96

0.96

0.94

0.94

0.92

0.92

Jain index

Jain index

N = 32, C = 1, K = Nlog2N
1

0.9
0.88
0.86

0.88
0.86

0.84

0.84
Constant
Linear
Worstplayer

0.82
0.8

0.9

6

10

4

10
Noisy feedback probability

0.8

2

10

Constant
Linear
Worstplayer

0.82
6

10

(a) C = 1, K = N log2 N

4

10
Noisy feedback probability

(b) C =

N
2

2

10

, K = 2 log2 N

Figure 13: Noisy feedback, Jain index, N = 32
Suppose every step, every player probability pF feedback
receives wrong. is, player transmitted, learn transmission
successful not, vice versa. player observed channel,
learn channel free fact (and vice versa). context
wireless networks, corresponds interference wireless channel.
affect learning?
Figure 12 show average overall throughput C = 1 C = N2 respectively. one channel, constant scheme better linear scheme,
adapts faster disruptions. C = N2 , schemes equivalent,
equally fast adapt. phase transition occurs noisy feedback probability
pF = 102 .
465

fiCigler & Faltings

N = 32, C = N/2, K = Nlog2N

1

0.9

0.9

0.8

0.8

0.7

0.7

System throughput

System throughput

N = 32, C = 1, K = Nlog2N

1

0.6
0.5
0.4
0.3
0.2
0.1
0

0.6
0.5
0.4
0.3
0.2

Constant
Linear
Worstplayer
6

10

0.1
4

10
Noisy signal probability

0

2

10

Constant
Linear
Worstplayer
6

10

(a) C = 1, K = N log2 N

4

10
Noisy signal probability

(b) C =

N
2

2

10

, K = 2 log2 N

Figure 14: Noisy coordination signal, throughput, N = 32
Figure 13 shows Jain index allocation players receive noisy feedback.
usual, linear scheme better constant, even though throuput lower (as
shown above). overall throughput drops close 0, schemes
obviously almost fairness.
6.2.4 Noisy Coordination Signal
algorithm assumes players observe coordination signal every
step. signal come from? may random noise given
frequency, FM radio transmission etc. However, coordination signal might noisy,
different players observe different value. means learning would
sync. wireless networks, corresponds clock drift.
see happens case, use following experiment. every step,
every player observes correct signal (i.e. one observed everyone else)
probability 1 pS . probability pS observes false signal (that still
taken uniformly random set {0, ..., K 1}).
overall throughput shown Figure 14. see system able
cope fairly high level noise signal, drop throughput occurs
pS = 101 . case experiments noisy feedback, constant back-off
scheme able achieve higher throughput thanks faster convergence.
Jain index allocation (Figure 15) stays almost constant,
throughput drops Jain index increases. allocation random, also
fair.
6.3 Generic Multi-agent Learning Algorithms
Several algorithms proved converge correlated equilibrium proposed multi-agent learning literature. Introduction, mentioned three
learning algorithms (Foster & Vohra, 1997; Hart & Mas-Colell, 2000; Blum & Man466

fiDecentralized Anti-coordination Multi-agent Learning

N = 32, C = N/2, K = Nlog2N
1

0.98

0.98

0.96

0.96

0.94

0.94

0.92

0.92

Jain index

Jain index

N = 32, C = 1, K = Nlog2N
1

0.9
0.88
0.86

0.88
0.86

0.84

0.84
Constant
Linear
Worstplayer

0.82
0.8

0.9

6

10

4

10
Noisy signal probability

0.8

2

10

Constant
Linear
Worstplayer

0.82
6

10

(a) C = 1, K = N log2 N

4

10
Noisy signal probability

(b) C =

N
2

2

10

, K = 2 log2 N

Figure 15: Noisy coordination signal, Jain index, N = 32
sour, 2007). However, analysis Foster Vohra applicable games two
players. section, briefly recall two multi-agent learning algorithms
(Hart & Mas-Colell, 2000; Blum & Mansour, 2007), compare performance
algorithm presented Section 3.
two algorithms compare algorithm based notion minimizing regret agents experience adopting certain strategy. Intuitively,
describe concept regret follows: Imagine agent uses strategy couple
rounds game, accumulates certain payoff. would like know
payoff compare payoff acquired simple alternative strategy . difference payoff strategy regret agent perceives (ex-post)
choosing strategy strategy .
mean simple strategy? One class simple strategies strategies
always select action. external regret compares performance
strategy performance best single action ex-post.
Another class alternative strategies strategies modify strategy slightly.
Every time strategy proposes play action a, alternative strategy proposes
action a0 6= instead. internal regret defined regret strategy compared
best alternative strategy. agents adopt strategy low internal
regret, converge strategy profile close correlated equilibrium (also
shown Blum & Mansour, 2007).
Hart Mas-Colell (2000) present simple multi-agent learning algorithm
guaranteed converge correlated equilibrium. assume players
observe actions opponents every round game. Players start
choosing actions randomly. update strategy follows: Let ai
action player played round t1. action aj Ai , aj 6= ai , player calculates
difference average payoff would received played action aj
instead ai past, average payoff received far playing action ai .
mentioned above, call difference internal regret playing action ai
467

fiCigler & Faltings

C = N/2

C=1
3

10

Constant backoff
HartMasColell
BlumMansour

Constant backoff
HartMasColell
BlumMansour
3

Convergence steps

Convergence steps

10
2

10

2

10

1

10

1

10

5

10

15
N

20

25

(a) C = 1

5

10

15
N

(b) C =

20

25

N
2

Figure 16: General multi-agent learning algorithms, convergence rate.

instead action aj . player chooses action play round probability
proportional internal regret compared previous action ai . Actions negative
regret never played. previous action ai played positive probability
way, strategy certain inertia.
Hart Mas-Colell (2000) prove agents adopt adaptive procedure described above, empirical distribution play (the relative frequency playing
certain pure strategy profile) converges almost surely set correlated equilibria.
Blum Mansour (2007) present general technique convert learning algorithm
low external regret algorithm low internal regret. idea run
multiple copies external regret algorithm. step, copy returns probability
vector playing action. probability vectors combined one joint
probability vector. player observes payoff playing action, updates
payoff beliefs external regret algorithms proportionally weight
joint probability vector. authors show players use learning
algorithm low internal regret, empirical distribution game converges close
correlated equilibrium.
One low-external-regret algorithms Blum Mansour (2007) present
Polynomial Weights (PW) algorithm. There, player keeps weight
actions. every round game, updates weight proportionally loss
(negative payoff) action incurred round. Actions higher weight get
chosen higher probability.
implemented two generic multi-agent learning algorithms: internalregret-based algorithm Hart Mas-Colell (2000), PW algorithm Blum
Mansour (2007). experiments, algorithms always converge pure-strategy
Nash equilibrium channel allocation game, therefore efficient allocation.
However, resulting allocation fair, subset agents size C ever
access channels.
468

fiDecentralized Anti-coordination Multi-agent Learning

C = N/2
1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

Jain index

Jain index

C=1
1

0.5
0.4
0.3

0.4
0.3

0.2

0.2
Constant backoff
HartMasColell
BlumMansour

0.1
0
5

0.5

10

15
N

20

Constant backoff
HartMasColell
BlumMansour

0.1

25

(a) C = 1

0
5

10

15
N

(b) C =

20

25

N
2

Figure 17: General multi-agent learning algorithms, Jain index.

Figure 16 shows average number rounds algorithms take converge
stable outcome. compare performance learning algorithm Section 3.
learning algorithm, set K = 1, also converges pure-strategy
Nash equilibrium game. performed 128 runs algorithm scenario.
error-bars Figure 16 show 95% confidence interval average, assuming
convergence times distributed according normal distribution.
surprisingly, generic algorithms Hart Mas-Colell (2000) Blum
Mansour (2007) cannot match convergence speed algorithm, designed specifically
problem channel allocation. generic algorithms converge pure-strategy
NE, outcome unfair, Jain index low, evidenced Figure 17.
dont report confidence bounds Jain index, experiments
resulting Jain index same.

7. Related Work
Broadly speaking, paper interested games payoff agent receives
certain action inversely proportional number agents chose
action. achieve efficient fair outcome games? Variants
problem studied several previous works.
simplest variant Minority game (Challet, Marsili, & Zhang, 2005).
game, N agents simultaneously choose two actions. Agents chose
action chosen minority agents receive payoff 1, whereas agents whose
action choice majority receive
payoff 0. game many pure-strategy Nash
equilibria, group N 21 agents chooses one action rest choose
action. equilibria efficient, since largest possible number agents achieve
maximum payoff. However, fair: payoff losing group agents
always 0. game also one mixed-strategy NE fair: every agent chooses
469

fiCigler & Faltings

action randomly. equilibrium,
hand, efficient: expected size
minority group lower N 21 due variance action selection.
Savit, Manuca, Riolo (1999) show agents receive feedback action
minority, learn coordinate better achieve efficient outcome
repeated minority game. basing agents decisions history
past iterations. Cavagna (1999) shows result achieved agents
base decisions value random coordination signal instead using
history. direct inspiration idea global coordination signal presented
paper.
ideas literature Minority games recently found way
cognitive radio literature. Mahonen Petrova (2008) present channel allocation
problem much like ours. agents learn channel use using strategy
similar strategies minority games. difference instead preferring
action chosen minority, channel allocation problem, agent prefers channels
chosen anyone else. Using approach, Mahonen Petrova able
achieve stable throughput 50% even number agents try
transmit channel increases. However, agent essentially choosing one
fixed set strategies, cannot adapt. Therefore, difficult achieve
perfectly efficient channel allocation.
Wang et al. (2011) implemented algorithm work actual wireless
network. setting, wireless devices able monitor activity channels.
coordination signal, used actual data packets agents send.
authors shown practice, learning algorithm (which call attachment
learning) improves throughput 2-3 random access slotted ALOHA protocol.
Another, general variant problem, called dispersion game described
Grenager, Powers, Shoham (2002). dispersion game, agents choose several
actions, prefer one chosen smallest number agents.
authors define maximal dispersion outcome outcome agent move
action fewer agents. set maximal dispersion outcomes corresponds set
pure-strategy Nash equilibria game. propose various strategies converge
maximal dispersion outcome, different assumptions information available
agents. contrary work, individual agents dispersion games
particular preference actions chosen equilibria
achieved. Therefore, issues achieving fair outcome.
Verbeeck, Nowe, Parent, Tuyls (2007) use reinforcement learning, namely linear
reward-inaction automata, learn Nash equilibria common conflicting interest
games. class conflicting interest games (to channel allocation game
belongs), propose algorithm allows agents circulate various
pure-strategy Nash equilibria, outcome game fair. contrast
work, solution requires communication agents, requires
agents know strategies converged. addition, linear reward-inaction automata
guaranteed converge pure-strategy NE conflicting interest games;
may converge pure strategies.
games discussed above, including channel allocation game, form part
family potential games introduced Monderer Shapley (1996). game called
470

fiDecentralized Anti-coordination Multi-agent Learning

potential game admits potential function. potential function defined every
strategy profile, quantifies difference payoffs agent unilaterally deviates
given strategy profile. different kinds potential functions: exact (where
difference payoffs deviating agent corresponds directly difference
potential function), ordinal (where sign potential difference
sign payoff difference) etc.
Potential games several nice properties. important purestrategy Nash equilibrium local maximum potential function. finite
potential games, players reach equilibria unilaterally playing best-response,
matter initial strategy profile start from.
existence natural learning algorithm reach Nash equilibria makes potential
games interesting candidate future research. would like see kind
correlated equilibria agents converge there, use simple correlation
signal coordinate.

8. Conclusions
paper, proposed new approach reach efficient fair solutions multi-agent
resource allocation problems. Instead using centralized, smart coordination device
compute allocation, use stupid coordination signal, general random integer
k {0, 1, . . . , K 1}, priori relation problem. Agents smart:
learn, value coordination signal, action take.
game-theoretic perspective, ideal outcome game correlated equilibrium. results show using global coordination signal, agents learn play
convex combination pure-strategy Nash equilibria, correlated equilibrium.
showed learning strategy that, variant channel allocation game, converges expected polynomial number steps efficient correlated equilibrium.
also proved equilibrium becomes increasingly fair K, number available
synchronization signals, increases.
confirmed fast convergence well increasing fairness increasing K
experimentally. also investigated performance learning strategy case
agent population dynamic. new agents join population, learning strategy
still able learn efficient allocation. However, fairness allocation depend
greedy initial strategies new agents are. agents restart random
intervals, becomes important fast strategy converges. simple strategy
everyone backs transmitting constant probability able achieve higher
throughput sophisticated strategy back-off probability depends
many slots agent already transmitting. also showed experimentally
learning strategy robust noise coordination signal, well
feedback agents receive channel use. noisy scenarios, faster convergence constant back-off scheme helped achieve higher throughput
fair linear back-off scheme. Finally, compared performance learning strategy generic multi-agent learning algorithms based regret-minimization (Hart &
Mas-Colell, 2000; Blum & Mansour, 2007). generic algorithms theoretically
proven converge distribution play close correlated equilibrium,
471

fiCigler & Faltings

guaranteed converge specific CE. Indeed, experiments, algorithms
Hart Mas-Colell Blum Mansour always converged efficient unfair
pure-strategy Nash equilibrium channel allocation game.
learning algorithm presented paper implemented real wireless
network Wang et al. (2011), shown achieves 2-3 higher throughput
random access protocols ALOHA.
paper, address issue whether non-cooperative rational
agents would follow protocol outlined. work (Cigler & Faltings, 2012),
address issue show certain conditions, protocol implemented
Nash equilibrium strategies infinitely repeated resource allocation game.

References
Abramson, N. (1970). ALOHA system: another alternative computer communications. Proceedings November 17-19, 1970, fall joint computer conference,
AFIPS 70 (Fall), pp. 281285, New York, NY, USA. ACM.
Aumann, R. (1974). Subjectivity correlation randomized strategies. Journal
Mathematical Economics, 1 (1), 6796.
Billingsley, P. (2012). Probability Measure (Wiley Series Probability Statistics)
(Anniversary Edition edition). Wiley.
Blum, A., & Mansour, Y. (2007). Algorithmic game theory. Nisan, N., Roughgarden,
T., Tardos, E., & Vazirani, V. (Eds.), Algorithmic Game Theory, chap. 4. Cambridge
University Press.
Cavagna, A. (1999). Irrelevance memory minority game. Physical Review E, 59 (4),
R3783R3786.
Challet, D., Marsili, M., & Zhang, Y.-C. (2005). Minority Games: Interacting Agents
Financial Markets (Oxford Finance). Oxford University Press, New York, NY, USA.
Chen, X., & Deng, X. (2006). Settling complexity Two-Player nash equilibrium.
2006 47th Annual IEEE Symposium Foundations Computer Science (FOCS06),
pp. 261272. IEEE.
Cheng, S., Raja, A., Xie, L., & Howitt, I. (2009). distributed constraint optimization algorithm dynamic load balancing wlans. IJCAI-09 Workshop Distributed
Constraint Reasoning (DCR).
Cigler, L., & Faltings, B. (2012). Symmetric subgame perfect equilibria resource allocation. (to appear) Proceedings 26th national conference Artificial
intelligence (AAAI-12), Menlo Park, CA, USA. American Association Artificial
Intelligence.
Feller, W. (1968). Introduction Probability Theory Applications, Vol. 1, 3rd
Edition (3 edition). Wiley.
Foster, D. P., & Vohra, R. V. (1997). Calibrated learning correlated equilibrium. Games
Economic Behavior, 21 (1-2), 4055.
472

fiDecentralized Anti-coordination Multi-agent Learning

Gast, N. (2011). Computing hitting times via fluid approximation: application coupon
collector problem. ArXiv e-prints.
Grenager, T., Powers, R., & Shoham, Y. (2002). Dispersion games: general definitions
specific learning results. Proceedings Eighteenth national conference
Artificial intelligence (AAAI-02), pp. 398403, Menlo Park, CA, USA. American
Association Artificial Intelligence.
Hart, S., & Mas-Colell, A. (2000). simple adaptive procedure leading correlated equilibrium. Econometrica, 68 (5), 11271150.
Jain, R. K., Chiu, D.-M. W., & Hawe, W. R. (1984). quantitative measure fairness
discrimination resource allocation shared computer systems. Tech. rep., Digital
Equipment Corporation.
Leyton-Brown, K., & Shoham, Y. (2008). Essentials Game Theory: Concise, Multidisciplinary Introduction. Morgan & Claypool, San Rafael, CA.
Littman, M., & Stone, P. (2002). Implicit negotiation repeated games intelligent agents
VIII. Meyer, J.-J., & Tambe, M. (Eds.), Intelligent Agents VIII, Vol. 2333 Lecture
Notes Computer Science, chap. 29, pp. 393404. Springer Berlin / Heidelberg,
Berlin, Heidelberg.
Mahonen, P., & Petrova, M. (2008). Minority game cognitive radios: Cooperating without cooperation. Physical Communication, 1 (2), 94102.
Monderer, D., & Shapley, L. S. (1996). Potential games. Games Economic Behavior,
14 (1), 124 143.
Norris, J. R. (1998). Markov Chains (Cambridge Series Statistical Probabilistic
Mathematics). Cambridge University Press.
Papadimitriou, C. H., & Roughgarden, T. (2008). Computing correlated equilibria multiplayer games. Journal ACM, 55 (3), 129.
Rego, V. (1992). Naive asymptotics hitting time bounds markov chains. Acta Informatica, 29 (6), 579594.
Savit, R., Manuca, R., & Riolo, R. (1999). Adaptive competition, market efficiency,
phase transitions. Physical Review Letters, 82 (10), 22032206.
Verbeeck, K., Nowe, A., Parent, J., & Tuyls, K. (2007). Exploring selfish reinforcement
learning repeated games stochastic rewards. Autonomous Agents MultiAgent Systems, 14 (3), 239269.
Wang, L., Wu, K., Hamdi, M., & Ni, L. M. (2011). Attachment learning multi-channel
allocation distributed OFDMA networks. Parallel Distributed Systems, International Conference on, 0, 520527.

473

fiJournal Artificial Intelligence Research 47 (2013) 281-311

Submitted 10/12; published 6/13

Sharing Rewards Cooperative Connectivity Games
Yoram Bachrach

yobach@microsoft.com

Microsoft Research, Cambridge, UK

Ely Porat

porately@cs.biu.ac.il

Bar-Ilan University, Ramat-Gan, Israel

Jeffrey S. Rosenschein

jeff@cs.huji.ac.il

Hebrew University, Jerusalem, Israel

Abstract
consider selfish agents likely share revenues derived maintaining
connectivity important network servers. model network failure
one node may disrupt communication nodes cooperative game called
vertex Connectivity Game (CG). game, agent owns vertex, controls
edges going vertex. coalition agents wins fully connects
certain subset vertices graph, called primary vertices.
Power indices measure agents ability affect outcome game. show
domain, indices used determine fair share
revenues agent entitled to, identify significant possible points failure affecting
reliability communication network. show general graphs, calculating
Shapley Banzhaf power indices #P-complete, suggest polynomial algorithm
calculating trees.
also investigate finding stable payoff divisions revenues CGs, captured
game theoretic solution core, relaxations, -core least core.
show polynomial algorithm computing core CG, show testing
whether imputation -core coNP-complete. Finally, show trees,
possible test -core imputations polynomial time.

1. Introduction
key aspect multi-agent systems focus research field agent
collaboration. Cooperative game theory considers cooperation among self interested agents,
used analyze many collaborative domains (Goldman & Zilberstein, 2004;
Kraus, Shehory, & Taase, 2004; Branzei, Dimitrov, & Tijs, 2008; Dunne, van der Hoek,
Kraus, & Wooldridge, 2008; Chalkiadakis, Elkind, & Wooldridge, 2012). One important
application area multi-agent systems network analysis, examining issues ranging
communication network design (Babaoglu, Meling, & Montresor, 2002), sensor
network technologies (Lesser, Ortiz, & Tambe, 2003) social network analysis (Sabater &
Sierra, 2002). Game theory already used analyze interaction selfish
agents various network settings, network security (Roy, Ellis, Shiva, Dasgupta,
Shandilya, & Wu, 2010; Jain, Korzhyk, Vanek, Conitzer, Pechoucek, & Tambe, 2011),
resource sharing (Suris, DaSilva, Han, & MacKenzie, 2007) agent cooperation communication networks (Saad, Han, Debbah, Hjorungnes, & Basar, 2009; Easley & Kleinberg,
2010).
c
2013
AI Access Foundation. rights reserved.

fiBachrach, Porat, & Rosenschein

Consider computer network servers controlled selfish agents,
principal interested allowing communication certain set critical servers.
allow connectivity, principal incentivize agents allow communication
offering certain reward. agents must cooperate allow reliable
communication critical servers, every single agent controls small part
entire network.
1.1 Key Questions Game Theoretic Solutions
Given setting, several key questions arise. First, reward promised
entire group agents, must decide allocate reward amongst themselves.
Even agents form successful team, team may stable, agents
allocated small part reward may try form different coalition,
increase share reward. Could agents reach agreement sharing
rewards would prevent deviations? Second, fair share
agent get? measure importance individual agent bringing
desired outcome communication critical servers?
Cooperative game theory provides answers questions regarding reward sharing selfish agents, form solution concepts. solution concepts,
core relaxations (Gillies, 1953; Shapley & Shubik, 1966) focus stability, whereas
concepts power index proposed Banzhaf (1965) Shapley value (1953,
1954) focus fairness.
Power indices originated work analyzing power voting scenarios. Researchers
analyzing distribution power decision making bodies tried find precise
way measuring influence single agent context team agents
attempt reach joint decision voting procedure. formalized
measures influence so-called power indices, measure control voter
decisions larger group (Elkind, Goldberg, Goldberg, & Wooldridge, 2007b).
two prominent indices Banzhaf power index (1965) ShapleyShubik power index (1954). indices characterized using set axioms
describe desirable properties measure power voting contexts (Lehrer, 1988;
Shapley, 1953; Dubey & Shapley, 1979; Straffin, 1988). Shapley-Shubik power index
manifestation Shapley value (1953) designed find fair share
agent team agents must cooperate achieve joint reward. Although
indices mostly used measuring power voting systems, easily
adapted domains well.
paper, consider use power indices find fair ways agents
share rewards network setting described above. Further, show power
indices used find key points failure communication network. model
communication network setting, consisting servers network links
connecting them, vertex connectivity game. network modeled graph,
servers vertices, network links edges. certain subset
servers (vertices) primarya failure send information two
would constitute major system failure. Another subset servers always available
(backbone servers).
282

fiSharing Rewards Cooperative Connectivity Games

vertex Connectivity Game (CG) introduce, agent controls different
vertex graph. coalition agents use vertices controlled
coalition members backbone vertices, may send information them.
coalition wins connects primary vertices, send information
two them. power index agent game reflects criticality
maintaining connectivity. index used determine fair share total
reward agent get, could enable administrator identify potential
critical points failure network (perhaps, example, focusing maintenance
resources preventing failure).
consider computational complexity calculating Banzhaf Shapley-Shubik
power indices domain. show general graphs, computing either
indices #P-complete problem. Despite negative result, provide polynomial
algorithm restricted case graph tree. Many networks, including parts
internets backbone, constructed trees construction communication
line expensive, algorithm analyze important real-world domains.
turn finding stable payoff distributions collaborating agents, using
game theoretic solution concept core (Gillies, 1953). show core
computed polynomial time CGs. coalition CG manages connect
primary vertices, wins gains certain profit. profit divided
among members coalition. Choosing payoff vector core guarantees
subcoalition would choose split main coalition, attempt establish
network. Thus, core indicates payoff vectors stable allows allocating
gains coalition CG domain prevent subcoalitions defecting.
also consider relaxed solution concepts -core least core (Shapley
& Shubik, 1966), show testing -core imputations coNP-complete CGs.
-core imputations, although coalition may completely stable, incentive
subcoalition deviate low. Finally, show tree CGs, core least
core coincide.
paper proceeds follows. Section 2, provide background information regarding coalitional games power indices, fully define vertex connectivity game
(CG). Section 3 examine game theoretic solutions CGs. Section 3.1 discusses
fair reward distributions CGs using power indices, presents hardness result
general case polynomial algorithm restricted case trees. Section 3.2
examines stable reward distributions. shows core CGs computed
polynomial time, discusses complexity -core least-core-related problems,
examines core-related problems tree CGs. Section 4 examines related work, discussing
previous work solutions cooperative games (Section 4.1) related models
cooperative games networks (Section 4.2). conclude Section 5.

2. Preliminaries
coalitional game composed set n agents, = (a1 , . . . , ), function
mapping subset (coalition) agents real value v : 2I R. function v
called coalitional function (or sometimes characteristic function) game.
simple coalitional game, v gets values 0 1, v : 2I {0, 1}. coalition
283

fiBachrach, Porat, & Rosenschein

C wins v(C) = 1, loses v(C) = 0. set winning coalitions denoted
W (v) = {C 2I |v(C) = 1}. agent ai critical winning coalition C agents
removal coalition would make coalition lose: v(C) = 1 v(C \ {i}) = 0.
Thus, agent critical coalition contains it.
interested finding fair share rewards agent get
cooperative game, measuring influence given agent result game.
Game theoretic solutions include various values power indices. two
prominent values Banzhaf power index (1965) Shapley value (1953).
indices characterized using slightly different sets fairness axioms,
reflect desired properties power index. indices property
dummy agents, never affect value coalition, obtain index zero (the null
player axiom). Similarly, Shapley value Banzhaf index, equivalent
agents, increase value coalition contains neither
amount, index (the symmetry axiom). However, two indices behave differently regarding composition two games set agents.1 Alternatively,
indices interpreted probability agent would significantly affect
outcome game, slightly different models uncertainty regarding agents
participation game (Straffin, 1988). Although power indices widely used
measuring political power weighted voting systems, definition rely
specific features voting domain.
Banzhaf index depends number coalitions agent critical.
Agent ai marginal contribution coalition C ai C defined v(C) v(C \
{ai }). Thus ai critical C marginal contribution 1 it, ai
critical C marginal contribution 0. Banzhaf index agent ai
average marginal contribution coalitions contain , equivalently
proportion coalitions critical coalitions contain i.
Definition 1. Banzhaf index vector (v) = (1 (v), . . . , n (v))
(v) =

1
2n1

X

[v(C) v(C \ {ai })].

CN |ai C

Shapley value (1953), sometimes referred Shapley-Shubik power
index (1954) applied simple cooperative game, relies notion marginal
contribution agent permutation. amount additional utility generated
agent joins coalition predecessors permutation. denote
1. Given two games u, v agent set, define game u + v value coalition
C game u + v sum values composing games u + v(C) = u(C) + v(C).
also define max game u v value coalition composed game u v maximal
value composing games, u v(C) = max(u(C), v(C)). Similarly define min game
u v, u v(C) = min(u(C), v(C)). Shapley value fulfills linear decomposition axiom:
Shapley value agent sum game u + v sum Shapley values composing
games u v. contrast, Banzhaf index fulfills property regarding max min games,
sum powers two games sum powers max min games. related
work examines fairness axioms Shapley value Banzhaf index (Dubey & Shapley, 1979;
Straffin, 1988; Lehrer, 1988; Holler & Packel, 1983; Laruelle & Valenciano, 2001).

284

fiSharing Rewards Cooperative Connectivity Games

permutation n agents, : {1, . . . , n} {1, . . . , n} onto.
denote Sn set agent permutations. Denote predecessors ai
, = {aj |(j) < (i)}. Agent ai marginal contribution permutation
mi = v(i {ai })v(i ). Note simple game agent marginal contribution
1 permutation iff critical coalition {ai }. Shapley value
agent marginal contribution averaged across possible agent permutations.
Definition 2. Shapley value vector (1 (v), . . . , n (v))
(v) =

1 X
1 X
mi =
(v (i {i}) v (i ))
n!
n!
Sn

Sn

Shapley value Banzhaf index thought expected marginal
contribution agent certain assumptions coalition formation process.
Shapley value reflects assumption agents randomly added coalition,
every ordering agents equally probable. contrast, Banzhaf index reflects
assumption coalitions equally probable. generally, power indices
viewed probabilities events weighted voting domains (Straffin, 1988).
hardness result calculating power indices CGs considers class #P. #P
set integer-valued functions express number accepting computations
nondeterministic Turing machine polynomial time complexity. Let finite input
output alphabet Turing machines.
Definition 3. #P class consisting functions f : N exists
non-deterministic polynomial time Turing machine inputs x , f (x)
number accepting paths M.
complexity classes #P #P-complete introduced Valiant (1979a).
classes express hardness problems count number solutions.2
coalitional function v describes total utility coalition achieve,
define agents distribute utility among themselves. imputation (p1 , . . . , pn ),
sometimes also called payoff vector, P
division gains grand coalition
among agents, pi R, ni=1 pi = v(I).
P call pi payoff agent ai ,
denote payoff coalition C p(C) = i{j|aj C} pi . assumption, agents
rational attempt maximize share utility. Game theory offers
several solution concepts, determining imputations likely occur agents
act rationally.
Shapley value shown imputation, values individual
sum value grand coalition agents:
Pn agents shown
3 Given fairness axioms Shapley value fulfills, thus

(v)
=
v(I).
i=1
2. Informally, NP NP-hardness deal checking least one solution combinatorial problem
exists, #P #P-hardness deal calculating number solutions combinatorial
problem. Counting number solutions problem least hard determining
least one solution, #P-complete problems least hard (but possibly harder) NP-complete
problems; complexity classes thoroughly investigated computation complexity researchers (Papadimitriou, 2003; Valiant, 1979b; Papadimitriou & Zachos, 1982).
3. Shapley provided proof fact seminal paper Shapley value (1953).

285

fiBachrach, Porat, & Rosenschein

viewed fair imputation. However, many domains agents selfish care
little fairness. Rather, selfish agents likely interested ability
improve utility forming alternative coalitions. Stability based solution concepts
core focus deviations (Gillies, 1953).
basic stability requirement imputation individual rationality: agents
ai C, pi v({ai }), otherwise agent better own. Similarly, say
coalition B blocks imputation (p1 , . . . , pn ) p(B) < v(B), since members
B would split coalition gain utility without rest agents.
blocked imputation chosen, coalition unstable. possible define degree
subcoalition incentivized deviate grand coalition.
Definition 4. Given imputation p = (p1 , . . . , pn ), excess coalition e(C) =
v(C) p(C), quantifies amount subcoalition C gain deviating
working own.
Given imputation, coalition C blocking iff excess strictly positive e(C) > 0.
blocked payoff vector chosen, coalition unstable, higher excess
is, incentivized agents split apart current coalition form
coalition. known solution concept emphasizes stability core (Gillies,
1953).
Definition 5. Core coalitional game set payment vectors (p1 , . . . , pn )
blocked coalition, coalition C p(C) v(C).
value distribution core makes sure subset agents would split off,
coalition stable. general core empty, every possible value division
blocked coalition. paper, give results regarding computing core
vertex connectivity games. core empty (i.e., every possible value division
blocked coalition), sometimes make sense relax requirements
solution concept. domains, splitting apart current coalition structure
form alternative coalition might costly process. cases, coalitions
small incentive split apart grand coalition would so. relaxed
solution concept embodying intuition -core (Shapley & Shubik, 1966).
-core slightly relaxes inequalities Definition 5.
Definition 6. -core set imputations (p1 , . . . , pn ) following
holds: coalition C I, p(C) v(C) .
imputation -core, excess e(C) = v(C) p(C) coalition C
. large enough values , -core guaranteed non-empty.
obvious problem find smallest value makes -core non-empty.
solution concept known least core. Formally, consider game G set
{|the -core G empty}. set compact,4 minimal element min .
Definition 7. least core game G min -core G.
4. formal formal definition compactness implications found many introductory
books topology (Royden & Fitzpatrick, 1988).

286

fiSharing Rewards Cooperative Connectivity Games

Imputations least core distribute payoffs minimizing worst deficit.
words, least core minimizes maximal incentive coalition split apart
grand coalition. least core imputation, coalition gain
min deviating, < min impossible distribute payoffs way
causes deficit coalition . Another solution concept, called
nucleolus (Schmeidler, 1969) refines least core, minimizing number coalitions
maximal excess examining sorted vector excesses defining
lexicographical order them.
2.1 Connectivity Games
Consider network connecting various servers, certain subset servers
designated primary servers. goal make sure send information
two primary servers. server network may malfunction, does,
cannot send information it. paths two primary servers go
failed server, cannot send information two primary servers.
model, also assume certain subset servers guaranteed
never fail (guaranteed, say, heavy maintenance fail-safe backup); call
backbone servers.
Section 1.1 discussed several questions regarding agreements selfish agents
likely reach controls server network. model
network domain cooperative game use game theoretic solutions answer
questions. coalitional game heart model called vertex Connectivity
Game.
Definition 8. vertex Connectivity Game Domain (CGD) consists graph G = hV, Ei
vertices partitioned primary vertices Vp V , backbone vertices Vb V ,
standard vertices Vs V . require Vp Vb = , Vb Vs = , Vp Vs = ,
V = Vp Vb Vs , indeed partition.
Given CGD, define vertex Connectivity Game. game, agent
controls one standard servers. coalition wins connects pairs primary
vertices (so send information two primary servers). Let |Vs | = n,
consider set n agents = (a1 , . . . , ), agent ai controls vertex vi Vs . Given
coalition C denote set vertices C controls V (C) = {vi Vs |ai C}.
Coalition C use either vertices V (C) always-available backbone vertices
Vb . model, assume coalition also use primary vertices Vp
well.5
say set vertices V V fully connects Vp two vertices u, v Vp
path (u, p1 , p2 , . . . , pk , v) u v going vertices V ,
pi V .
5. Another possibility would allow primary vertices want connect fail (this may
occur, example, network security domains, external attacks may target key servers
network). case coalition would win manages connect non-failed primary vertices.
could also disallow sending information primary vertices (so final
destination). results paper hold different settings well.

287

fiBachrach, Porat, & Rosenschein

Definition 9. vertex Connectivity Game (CG) simple coalitional game,
value coalition C defined follows:
(
1 V (C) Vb Vp fully connects Vp
v(C) =
0 otherwise

3. Solutions Connectivity Game
Section 1.1 raised several questions regarding agreements selfish agents likely
reach controls server network. answer questions
applying game theoretic solutions Connectivity Game.
begin characterizing fair payoff distribution measuring agents importance
allowing reliable network communication. Specifically, given desire ensure communication paths primary vertices, servers network critical?
agents deserve higher share reward? Given limited resources make sure
servers fail (i.e., making backbone servers), vertices
concentrate ensure communication primary servers? Section 3.1 answers
questions using power indices.
continue examining stable allocations rewards. determine
whether agreement sharing rewards would incentivize sub-coalition agents
defect? agreement fully-resistant deviations, find stable
agreement? Section 3.2.1 answers questions using core core-related solutions.
3.1 Network Reliability Fair Reward Distribution
CG Definition 9 characteristic function maps every coalition fully
connects primary vertices single unit reward (and indicates coalitions reward zero). Section 2 discussed fairness axioms
Shapley value Banzhaf index fulfill. Due properties, apply
concepts CGs, obtain fair distribution reward games. example,
dummy servers, affect ability coalition allow full connectivity,
would power index zero, obtain reward. Similarly, equivalent agents,
impact achieving connectivity added coalition, would obtain
reward. agents forming coalition wish share rewards fair
manner, power indices thus make excellent basis forming agreement,6 highlighting
need examine computational aspects calculating indices,
section.
emphasize beyond fulfilling fairness properties, power indices also
viewed network reliability constructs. model based simple network goal
allowing communication two primary servers. network reliability
view, want identify servers which, failing, cause us lose connectivity
6. specific index used depends agents notion fairness. Different sets axioms result
different indices (Dubey & Shapley, 1979; Straffin, 1988; Holler & Packel, 1983; Laruelle & Valenciano,
2001).

288

fiSharing Rewards Cooperative Connectivity Games

primary servers. Suppose servers equal probability working
failing next day (i.e. probability 50% fail, probability 50%
work). failures independent, subset servers equal chance
surviving (regardless size). Thus, certain probability
surviving set servers fully connect primary servers. Suppose make sure
exactly one server, owned agent ai , always survives. Banzhaf power index measures
increase probability surviving subset vertices fully connect
primary servers guaranteeing vi survives.
attempting maximize probability achieving goal, higher
Banzhaf index server is, try make sure server
fail. Thus, order find significant points failure, calculate Banzhaf power
index, focus servers highest indices.7
consider computational complexity calculating power indices general
vertex connectivity games. first formally define problems.
Definition 10. CG-BANZHAF / CG-SHAPLEY: given CG graph G =
hV, Ei, primary vertices Vp V , backbone vertices Vb V , standard vertices
Vs V . n = |Vs | agents, = (a1 , . . . , ), agent ai controls vertex vi Vs .
games coalitional function v : 2I {0, 1} defined Definition 9. also
given specific target agent ai . CG-BANZHAF asked calculate Banzhaf
power index game, (v). Similarly, CG-SHAPLEY problem asked
calculate Shapley value, (v).
show general CGs, CG-BANZHAF CG-SHAPLEY #Pcomplete. first prove problems #P. reduce #SET-COVER problem
CG-BANZHAF. obtain #P-hardness CG-SHAPLEY corollary.
begin definitions.
Definition 11. #SET-COVER (#SC): given collection C = {S1 , . . . , Sn }
subsets. denote Si C Si = S. set cover subset C C Si C = S.
asked compute number covers S.
slightly different version requires finding number set covers size k:
Definition 12. #SET-COVER-K (#SC-K): set-cover size k set cover C
|C | = k. Definition 11, given C target size k, asked
compute number covers size k.
#SC #SC-K #P-hard. Garey Johnson (1979) showed #SC-K
#P-hard: considered several basic NP-complete problems, showed
counting versions #P-complete. counting version SET-COVER discussed
#SC-K. #VERTEX-COVER restricted form #SC. Vadhan (2002) showed
#VERTEX-COVER #P-hard,8 #SC also #P-hard. use #SC prove
CG-BANZHAF #P-hard. easy show #SC-K #P-complete, fact
7. Similarly, uncertainty order agent failures, Shapley value reflects
importance vertices regard network reliability.
8. also showed problem remains #P-hard even restricted classes graphs.

289

fiBachrach, Porat, & Rosenschein

#SC #P-complete difficult prove (and thus well known).
give definitions #SC #SC-K avoid confusion them, use
Vadhans result (2002) indicates #SC #P-complete. Using this, reducing
#SC CG-BANZHAF show CG-BANZHAF #P-complete.
order show CG-BANZHAF #P-complete need show two things:
first, CG-BANZHAF #P, second, reduction #P-hard problem
CG-BANZHAF.
Lemma 1. CG-BANZHAF CG-SHAPLEY #P.
Proof. Banzhaf index ai CG v (v), proportion coalitions ai
critical, coalitions contain ai . Given certain coalition C I,
polynomial check whether winswe need check whether V (C) Vb fully
connects Vp . creating new graph G , dropping edges miss
V (C) Vb G (i.e., drop edge (x, y) E either x
/ V (C) Vb


/ V (C) Vb ). check two primary vertices G connected (there
several polynomial algorithms this; simple one run depth-first search (DFS)
pairs primary vertices). thus easily test certain agent ai critical
coalition: perform test coalition, remove him,
repeat test. first test succeeds second fails, agent critical
coalition. Similarly, test whether agent ai critical agent permutation
polynomial time: simply test whether ai predecessors form losing coalition
whether {ai } form winning coalition (we using test).
Since construct deterministic polynomial Turing machine tests
agent critical coalition, construct non-deterministic Turing machine ,
first non-deterministically chooses coalition ai member of, tests
ai critical coalition. number accepting paths number
coalitions contain ai ai critical. Denote k number accepting
paths , denote |I| = |Vs | = n. Banzhaf power index agent ai
k
.
(v) = 2n1
Calculating numerator (v) thus, according Definition 3, problem #P.
Since denominator constant (given domain n agents), CG-BANZHAF
#P. similar argument using non-deterministic generation permutations instead
coalitions holds Shapley value, CG-SHAPLEY #P.
show CG-BANZHAF #P-hard. reduction #SC.
Figure 1 shows example reduction specific #SC instance.
Theorem 1. CG-BANZHAF #P-hard, even backbone vertices, i.e., Vb =
.
Proof. reduce #SC instance CG-BANZHAF instance. Consider #SC instance
collection C = {S1 , . . . , Sn }, Si C Si = S. Denote items =
{t1 , t2 , . . . , tk }. Denote items Si Si = {t(Si ,1) , t(Si ,2) , . . . , t(Si ,ki ) }. reductiongenerated CGD constructed graph G = hV, Ei follows. subset Si C,
generated CG instance vertex vSi . denote set vertices
Vsets = {i|Si C} vSi . item ti generated CG instance also vertex vti .
290

fiSharing Rewards Cooperative Connectivity Games

denote set vti vertices Vitems = i|ti vti . generated CG instance also
two special vertices va vb . vertices generated instance.
vertices generated CG connected following way. vertices Vsets
clique: every vi , vj Vsets , (vi , vj ) E. vertex va also part clique,
vi Vsets (vi , va ) E. vertex va connected vb ,
vertex connected vb , (va , vb ) E. set vertex vSi connected vertices
items set, vt(Si ,1) , vt(Si ,2) , . . . , vt(Si ,ki ) , vSi Vsets vt(Si ,j) (so
t(Si ,j) Si ) (vSi , vt(Si ,j) ) E.
define CG Vp = Vitems {vb }, Vb = , Vs = Vsets {va }, CG
game defined Definition 9. game = |Vs | = |Vsets | + 1 = |C| + 1 = n + 1
agents (where n number subsets C, input #SC problem). CGBANZHAF query regarding va . Let (v) answer CG-BANZHAF query,
k number set covers #SC instance. show k = va (v) 2m1 ,
providing one-to-one mapping set-cover original problem winning
coalition va critical generated CG.
Consider set-cover C C S. C must cover items ti S. denote
set vertices corresponding sets vertex cover VC = {vSi Vsets |Si C }.
Since C set cover original problem, vertex vtj Vitems generated
graph must connected least one vertex vi Vsets . Since vertices Vsets
clique, generated CG vti vSj connected component.
However, without va cannot reach vb vertex. Thus, VC {va } VS
winning coalition generated CG, VC not, va critical coalition.
show mapping reverse direction. Consider coalition V Vs
va critical, denote C = {Si C|vSi V }. definition, V must winning
contain va . Consider vertex vti Vitems . Since V wins, must allow vertex
Vsets reach vti , happen V contains vSj ti Sj . Thus, C
set cover original problem.
Let x number set covers #SC instance, ca number winning
coalitions va critical generated CG. Due one-to-one mapping
shown, x = ca . definition Banzhaf index, generated CG
ca
, ca = (v) 2m1 , x = (v) 2m1 .
(v) = 2m1
shown given polynomial algorithm CG-BANZHAF, solve
#SC polynomial time, CG-BANZHAF #P-hard.
recent result shows reasonable representation language cooperative
game, computing Banzhaf index #P-hard, computing Shapley value
also #P-hard (Aziz, Lachish, Paterson, & Savani, 2009). representation language said
reasonable possible represent game additional dummy agent
using representation language.9 CG representation reasonableto add
additional dummy agent simply add dummy vertex x connected
9. formally, representation language reasonable game v represent,
also represent game v defined follows. game v additional agent x present
original game v. agent set C x
/ C v (C) = v(C). agent set
C x C v (C) = v(C \ {x}). Note v v games slightly different
agent sets: v defined agent set whereas v defined agent set {x}.

291

fiBachrach, Porat, & Rosenschein

vertex. Adding isolated vertex coalition change value. Thus
obtain following corollary.

Figure 1: Example reducing #SC CG-BANZHAF. items {t1 , t2 , t3 , t4 , t5 }
sets S1 = {t1 , t3 }, S2 = {t1 , t2 , t3 }, S3 = {t3 , t5 }, S4 = {t3 , t4 , t5 }.

Corollary 1. CG-SHAPLEY #P-hard, even backbone vertices, i.e., Vb =
.
Since CG-BANZHAF CG-SHAPLEY #P #P-hard #Pcomplete problems, unlikely polynomial algorithm calculating indices
CGs would found. circumvent computational problem several ways.
One try find approximation algorithm, solve problem
restricted instances. next section, adopt second approach.
3.1.1 Computing Power Indices Tree CGs
Although computing Shapley Banzhaf power indices general CGs #P-complete,
restricting graphs structure may allow us polynomially compute indices.
examine restricted case graph tree. Consider CG graph G = hV, Ei
tree, primary vertices Vp V , backbone vertices Vb V , standard vertices
Vs V . call problem calculating Shapley Banzhaf power index
agent domain TREE-CG-SHAPLEY / TREE-CG-BANZHAF. assume
least two primary vertices va , vb Vp (otherwise, subset vertices trivially
fully connects primary vertices). first note since graph tree,
vertices veto agents present winning coalition.
292

fiSharing Rewards Cooperative Connectivity Games

Lemma 2. Consider CG graph G tree. Let va , vb Vp two primary
vertices, standard vertex vr Vs simple path va vb . vr present
winning coalitions CG game.
Proof. Since G tree, one simple path va vb . removal
vertex along simple path makes vb unreachable va . Since vr vertex,
coalition C Vs vr
/ C loses, winning coalition must contain vr .
Due Lemma 2 call standard vertex tree-CG essential lies simple
path two primary vertices.
Lemma 3. Consider CG graph G tree. Let va , vb Vp two primary
vertices. Consider vertex coalition C Vs contains standard vertices vr Vs
single simple path va vb . C allows connecting va vb
CG game. coalition C Vs contains essential vertices (i.e., standard vertices
vr Vs simple path two primary vertices va , vb Vp ), C
winning coalition v(C) = 1.
Proof. CG game use primary vertex vp Vp , backbone vertex
vb Vb . Consider coalition C contains vertices vr V single simple
path va vb . vertex vx single simple path va vb either
backbone vertex (so vx Vb ) primary vertex (so vx Vp ) standard vertex (so
vx Vs ). standard vertex, coalition, vx C.
cases use vertex, va vb connected component
coalition C. C contains essential vertices, two primary vertices va vb
connected path composed either backbone, primary, coalition vertices,
C fully connects primary vertices Vp , winning coalition.
Lemma 2 states essential vertices necessary condition coalition
win, Lemma 3 states also sufficient condition. summarize
following corollary.
Corollary 2. Tree CGs, winning coalitions exactly coalitions contain
essential vertices.
denote set essential vertices tree CG Ves . show tree CG
Shapley value distributes reward essential vertices equally, provide
similar result Banzhaf index.
Theorem 2. Consider tree CG v set Ves essential vertices. vi Ves
(v) = |V1es | otherwise (v) = 0.
Proof. Three fairness axioms Shapley value fulfills null player axiom,
symmetry axiom efficiency axiom (Shapley, 1953; Dubey & Shapley, 1979;
Straffin, 1988). null player axiom states null player, i.e., coalition
C v(C) = v(C {i}) (v) = 0. Due corollary 2 vertex
essential null player, (v) = 0. symmetry axiom deals equivalent
agents. Two agents i, j called equivalent coalition C contains neither
293

fiBachrach, Porat, & Rosenschein

(so
/ C j
/ C) adding either agent results change value,
v(C {i}) = v(C {j}). note essential vertices equivalentif
exist two essential vertices, i, j Ves , coalition C contain either
missing two essential vertices winning, v(C {i}) = v(C {j}) = 0.
Due symmetry axiom, essential vertices Shapley value,
denote es . efficiency axiom states
Pthe Shapley values agents sum
value grand coalition I,
iI (v) = v(I). Due efficiency
null player
P value vertex iP Ves es
Paxioms since
P Shapley

+
1 = v(I) =

(v)
=


iV
/ es 0, have:
iV
/ es = |Ves | es +
iI
iVes
1
es = |Ves | .
Theorem 3. Consider tree CG v set Ves essential vertices. Ves
(v) = 21|Ves | otherwise (v) = 0.
Proof. Due corollary 2 vertex essential null player,
coalition C v(C) v(C \ {i}) = 0. case, directly Definition 1
(v) = 0. suppose essential vertex. entire agent set n vertices,
|Ves | essential n |Ves | non-essential. Due Corollary 2 winning coalitions
exactly containing essential vertices, including i. Thus critical
winning coalitions. therefore 2n|Ves | different winning coalitions
critical (any n |Ves | non-essential vertices either present not),
n|Ves |
(v) = 2 2n1 = 2n|Ves |n+1 = 21|Ves | .
Corollary 3. TREE-CG-SHAPLEY TREE-CG-BANZHAF P.
Proof. Due Theorems 2 3 compute power index vertex need
know whether essential total number |Ves | essential vertices. easy
test vertex essential polynomial time, checking whether lies two
primary vertices (for example using DFS). apply test vertices
determine whether essential obtain |Ves |, apply formulas Theorem 2
Theorem 3 (depending power index interested in).
Thus, despite high complexity result general case given Section 3.1, tree
CGs polynomially calculate power indices. result important analyzing
reliability real-world networks. example, consider situation Internet
connectivity established companies, one company supplier
another company client. example cycle relationship would
company buys Internet connection company B, turn buys Internet
connection company C, eventually buys Internet connection company
A. would mean that, sense, company would become client itself,
would paying money connection. scenario cycle
unlikely, domain likely tree domain.
Yet another example agent based smart-grid technology, agents negotiate
power supply (Massoud Amin & Wollenberg, 2005; Vytelingum, Voice, Ramchurn, Rogers,
& Jennings, 2010; Pipattanasomporn, Feroze, & Rahman, 2009). scenario various
agents suppliers consumers electricity. example, several firms
solar panels producing electricity, could buy additional electricity
294

fiSharing Rewards Cooperative Connectivity Games

demand higher production capability. case, firms benefit
able send receive power firms (perhaps intermediary).
multiple paths transmit power two firms offer advantage,
cycles likely exist, making network tree.
3.2 Stable Reward Distributions
key question regarding CGs raised Section 1.1 agents likely share
reward CG. Section 3.1 focused fair allocations, according agents impact
entire coalition achieving goal. section focus stable reward allocations.
winning coalition formed, reward distribution may collapse subset agents
allocated small share reward defect form alternative coalition.
subset agents would defect secure agents larger
share rewards. reasoning captured core (see Definition 5 Section 2).
Thus, computing core allows us find test stable agreementswhen core
non-empty, contains imputations stable; empty, coalition would
unstable matter divide utility among agents. However,
compute core CG?
first note always possible concisely represent core, since may
contain infinite number imputations. However, case CGs, exist
concise representation core.
Definition 9 CGs clearly indicate CGs simple cooperative games,
value coalition either 1 0. core demanding concept simple games.
agent ai veto player present winning coalitions, ai
/ C
v(C) = 0. Section 3.1.1 noted essential vertices, lie
simple path two primary vertices, veto players. well-known fact
simple coalitional games, core non-empty iff least one veto player
game (Chalkiadakis et al., 2012). Consider simple coalitional game veto
players, every agent ai winning coalition
Pn C contain ai . Take
payoff vector
p
=
(p
,
.
.
.
,
p
)

p
>
0.
Since
1
n

i=0 pi = 1 since pi > 0 know
P
p(C) pj Ia pj < 1, p(C) < v(C) = 1, makes C blocking coalition.

hand, see payoff vector p non-veto players get nothing
core: coalition C potentially block p must
P v(C) = 1 (if v(C) = 0
cannot block), must contain veto players, pj C pj = 1, thus
cannot block p.
Due characterization core simple cooperative games, games
core represented set Iveto , consisting veto players game.
set represents core imputations: imputation
p = (p1 , . . . , pn ) core
P
P
p
=
1
(note


must


case

p
iI = 1 p imputation).
iIveto
consider computing core CGs, representation set
veto agents. note CGs monotone games. Let W winning coalition
CG (so v(W ) = 1), let C coalition game. W C also
winning coalition, v(W C) = 1 (this restated as: coalitions A, B
CG v(A B) v(A)). reason C fully connects Vp
W C also fully connects Vp , vertices available us use.
295

fiBachrach, Porat, & Rosenschein

denote set agents except ai Ii = \ {ai }. Let G CG
graph. denote Gi graph drop vertex vi owned ai ,
Gi = hVi , Ei Vi = V \ {vi } Ei = {(u, v) E|u 6= vi v 6= vi }.
show polynomial algorithm testing player veto agent CGs.
Lemma 4. Testing agent ai veto agent CG P.
Proof. first show Ii losing coalition iff ai veto agent. Ii losing
coalition due monotonicity CGs sub-coalition it, C Ii , also losing.
Thus, coalition without ai losing, ai veto player. hand, Ii
winning coalition, winning coalition ai present, definition ai
veto player. Thus, test ai veto agent need test Ii losing
winning. According Definition 9 CG, check Ii wins need check
Ii fully connects primary vertices. test performed polynomial time
trying pairs va , vb Vp , performing DFS va vb graph Gi .
Since computing core simple coalitional games requires returning list
veto agents, get following corollary.
Corollary 4. possible compute return concise representation core
CG polynomial time. representation, possible test whether core
empty test imputation core polynomial time.10
Proof. Computing core CG requires returning Iveto , set consisting veto players
game. Using Lemma 4, check agents determine
veto players. veto players, core empty. Otherwise, payoff vector
distributes 1 (the total utility v(I) = 1) among veto players gives none
non-veto players core.
3.2.1 -Core Least Core
core CGs may non-empty, case easily compute core imputations.
However, many real world networks redundancy terms connectivity, might
possible connect primary vertices even eliminating arbitrary single vertex.
networks, CG veto agent core empty. cases,
imputation would unstable, vertex subset would incentivized deviate
form coalition. Thus, may simply wish minimize incentive agent
subset deviate, examine problems related least core. Although core-related
problems CGs solved polynomial time (as shown above), show
problems related -core may hard.
Given certain proposed imputation p = (p1 , . . . , pn ), may wish test whether
imputation -core, given .
10. fact, done simple monotone coalitional game value coalition
computed polynomial time: due proof Lemma 4, games test
whether agent veto player, simple games computing core simply requires finding
veto players are.

296

fiSharing Rewards Cooperative Connectivity Games

Definition 13. -CORE-MEMBERSHIP(ECM): Given imputation p = (p1 , . . . , pn ),
decide whether -core game, words, test whether coalition
C excess e(C) .
ECM tests whether imputation (payoff division) sufficiently stable, -stable.
definition -core, imputations property coalition C
excess e(C) < . ECM basic question computing imputation
-core finding least core valuethe minimal admits non-empty -core.
show ECM coNP-complete, solved polynomial time tree
CGs. tree CGs, show core non-empty (so least core coincides
core) possible find -core imputations polynomial time.
show ECM coNP-complete CGs using reduction VERTEX-COVER,
known NP-complete (Garey & Johnson, 1979).
Theorem 4. ECM coNP-complete general CGs, even imputation tested
equal imputation p = ( n1 , . . . , n1 ) single backbone vertex.
Proof. ECM requires testing whether given imputation p = (p1 , . . . , pn )
exist coalition C excess e(C) least (for given d). Given vertex subset
C V , easy test C connects primary vertices polynomial time,
thus test whether C winning not. also easily compute payoff p(C)
coalition imputation, thus also compute excess e(C) = v(C) p(C).
Thus, ECM coNP.
show computing maximal excess emax = max{e(C)|C I}
imputation p coNP-hard. Note imputation p -core iff maximal
deficit imputation . show testing whether maximal
excess (for given d) NP-hard reducing VERTEX-COVER instance
problem.
Let graph G = hV, Ei threshold input VERTEX-COVER instance
(i.e., asked wether Gs edges could covered vertices). assume
VERTEX-COVER instance least two edges (otherwise, problem easy
solve). Denote |V | = n. construct graph G = hV , E follows. vertex
v V , create standard vertex v V (i.e., V V ). edge e E, create
primary vertex V . primary vertices called edge vertices. also create
single backbone vertex vb V . Thus Vs = V , Vp = {ve |e E} Vb = {vb }.
agents standard vertices Vs = V , n agents.
(u,v)
(u,v)
edge e = (u, v) V create two edges G : e1
= (u, ) e2
=
(v, ). words, break edge original graph two parts, putting
vertex between. original edges graph G eliminated G . Finally,
connect standard vertex v Vs = V vb . Figure 2 shows example reduction
construction used proof Theorem 4.
imputation tested equal imputation p = ( n1 , . . . , n1 ) (i.e., payoff
agents same, n1 ). threshold value generated ECM instance
= 1 nt threshold VERTEX-COVER instance.
first note coalition C loses generated CG (i.e., fails connect
primary vertices Vp ) negative excess, v(C) = 0 p(C) = |C|
n , e(C) = v(C)
297

fiBachrach, Porat, & Rosenschein

p(C) = |C|
n . Thus, maximal excess coalition minimally paid winning coalition,
i.e., coalition C minimizes p(C) winning coalitions C: arg minC{C|v(C)=1} p(C).
Since p(C) = |C|
n , maximal excess coalition winning coalition minimal size:
arg minC{C|v(C)=1} |C|. words, maximal excess coalition minimally sized
coalition connects primary vertices.11 winning coalition C size |C| =
thus excess v(C) p(C) = 1 |C| n1 = 1 ns .
Since agents game standard vertices, since Vs = V , identify
agents vertices original graph. show coalition C Vs
winning coalition iff vertex cover G.
C Vs wins, must connect two primary vertices vx , vy Vp . note due
construction two primary vertices connected directly, primary vertex
created edge e E original graph. assumed VERTEXCOVER instance least two edges, least two primary vertices
generated graph. Let primary vertex. Due construction connected
exactly two standard vertices u, w (the vertices connected edge e
original graph). neither u w part C (i.e., u
/ C w
/ C),
path vertex graph induced C, connected
primary vertex C loses v(C) = 0. Thus, C winning coalition
every primary vertex e = (u, w) E vertices u, w V original graph
G, coalition C must contain either u w. However, u C C covers edge e,
u vertex one side edge, w C C also covers edge e, w
vertex side edge. Thus, C covers edge e E, vertex cover.
hand, suppose coalition C Vs = V vertex cover G.
vertex cover, C must cover every edge e E, given edge e = (u, w), C must contain
either u w both. u C path vb : (ve , vu , vb ) (ve source
primary vertex, vu coalition, vb backbone vertex). Similarly, w C
path vb : (ve , vw , vb ) (ve source primary vertex, vw coalition,
vb backbone vertex). Therefore, path primary vertex vp vb .
Thus, primary vertices connected: given vx , vy Vp path vx
vb vb vy , C vertex cover, winning coalition.
shown C winning coalition excess 1 |C|
n generated
instance iff vertex cover size |C|. maximal excess problem generated
instance requires finding minimal size winning coalition, words finding vertex
cover minimal size. restate saying ECM instance (with = 1 nt )
yes instance iff original graph vertex cover size t.

3.2.2 Core, -Core Least Core Tree CGs
consider core related problems tree CGs. CG domain less two primary
vertices degenerate domain (where coalitions win), CG even grand
coalition standard vertices fails connect primary vertices also degen11. Finding minimally paid winning coalition general imputation similar famous
Steiner tree problem, known NP-hard. However, domain weights
vertices rather edges.

298

fiSharing Rewards Cooperative Connectivity Games

Figure 2: Example reducing VERTEX-COVER ECM CG domain. left side
original VERTEX-COVER instance, right side generated ECM
domain, primary vertices orange (denoting edges original VERTEX-COVER instance), standard vertices blue (same original
vertices VERTEX-COVER instance) backbone vertex green.

erate domain (where coalitions lose). assume CG domains section
degenerate. also assume two primary vertices directly connected
path containing backbone vertices. case,
merge primary vertices single vertex, coalition connected one
also connected one without using standard vertex.
first prove core (non-degenerate) tree CGs non-empty.
Theorem 5. Tree CGs non-empty cores (assuming domain game nondegenerate CG domain).
Proof. Lemma 2 Corollary 2 shows tree CGs, veto vertices exactly
essential vertices, lie simple path two primary vertices. note
standard vertex path two primary vertices, domain
degenerate (either primary vertices connected even empty coalition
standard vertices, still disconnected even grand coalition standard
vertices). Thus, must exist least one veto agent. Since simple games core
non-empty iff veto agents, core tree CGs non-empty.
Due Theorem 5, tree CGs least core value, minimal -core
non-empty, 0 (the core 0-core, always non-empty).
299

fiBachrach, Porat, & Rosenschein

simple games, core non-empty, core imputation distributes reward
solely veto agents. Since tree CGs veto agents exactly essential vertices
(Corollary 2) obtain following:
Corollary 5. tree CG,Plet Ves Vs set essential vertices, denote |Ves | =
m. imputation iVes pi = 1 core imputation, core
1
imputations. Specifically, imputation pi =
vi Ves pi = 0 otherwise
core imputation.
Although core non-empty tree CGs, given potential agreement form
specific imputation, may still wish find maximal excess imputation,
words test whether imputation -core (for given ).
examine complexity ECM problem tree CGs. Theorem 4 shown
problem coNP-complete general graphs, show problem solved
polynomial time tree CGs.
Theorem 6. tree CGs, ECM problem solved polynomial time. imputation -core iff p(Ves ) > 1 .
Proof. Consider tree CG imputation p = (p1 , . . . , pn ). Let veto vertices
Ves V , denote = |Ves |. Denote indices veto vertices ,
{vi |i } = Ves . seen Lemma 2, tree CGs, vertex w veto vertex
(essential), dummy vertex, coalition C v(C {w}) = v(C).
denote non-veto vertices Vd = V \ Ves , dummy vertices. denote
indices dummy vertices {vi |i D} = Vd .
P
denote total payoff vetoPvertices p(Ves ) =
iM pi , total
payoff dummy vertices p(Vd ) =
p
.

assumed

domain

iD
degenerate, grand coalition wins, v(I) = 1. Since p imputation,
p(I) = 1. Since tree CG vertices either veto vertices dummy vertices,
1 = p(I) = p(Ves ) + p(Vd ). -core constraints require p(C) > v(C) .
since pi positive, -core constraint holds losing coalitions. winning
coalition C must contain Ves Ves C, p(Ves ) > v(Ves ) = 1 , -core
constrains hold: p(Ves ) > v(Ves ) = 1 , winning coalition C
p(C) p(Ves ) p(C) p(Ves ) > v(Ves ) = 1 = v(C) . hand,
p(Ves ) < 1 , -core constraint hold coalition Ves
imputation -core.
Thus, test imputation -core need test p(Ves ) > 1 .
Since compute Ves polynomial time, test also done polynomial time,
ECM P tree CGs.

4. Related Work
paper introduced cooperative game called Connectivity Game, examined
computational aspects calculating power indices finding core solutions game.
discuss related work regarding solution concepts Section 4.1, examine similar
models cooperative games networks Section 4.2.
300

fiSharing Rewards Cooperative Connectivity Games

4.1 Solutions Cooperative Games
stability based solution concept core originated paper (Gillies, 1953).
least core introduced solution concept games empty cores (Shapley & Shubik, 1966). refinement nucleolus Schmeidler (1969). -core
nucleolus studied minimum cost spanning tree games (Granot & Huberman,
1984), somewhat reminiscent model (see below), assignment games (Solymosi & Raghavan, 1994), weighted voting games (Elkind, Goldberg, Goldberg, &
Wooldridge, 2007a). Another related problem Cost Stability (Bachrach, Elkind,
Meir, Pasechnik, Zuckerman, Rothe, & Rosenschein, 2009), measuring required external
subsidy stabilize game, studied weighted voting games (Bachrach, Meir, Zuckerman,
Rothe, & Rosenschein, 2009), network flow games (Resnick, Bachrach, Meir, & Rosenschein, 2009) game forms (Meir, Zick, & Rosenschein, 2012; Meir, Bachrach, &
Rosenschein, 2010).
Power indices originated work game theory political science, attempting
measure power players weighted voting games. games, player
certain weight, coalitions weight sum weights participants;
coalition wins weight passes certain threshold. common situation
legislative bodies. Power indices suggested way measuring influence
players games choosing outcomes. popular indices suggested
measurement Banzhaf index (1965) Shapley-Shubik index (1954).
Shapley-Shubik index (1954) direct application Shapley value (1953)
simple coalitional games. Banzhaf index emerged study voting decisionmaking bodies, certain normalized form index introduced (Banzhaf,
1965). Banzhaf index later mathematically analyzed (Dubey & Shapley, 1979),
normalization shown certain undesirable features, focusing attention
non-normalized version Banzhaf index. indices applied
analysis voting structures IMF European Union Council Ministers,
well many bodies (Leech, 2002; Machover & Felsenthal, 2001).
Shapley value payoff division rule exhibits natural fairness axioms (Shapley, 1953; Dubey & Shapley, 1979), used measure
power also fairly allocate costs, revenues credit various domains (Shubik,
1962; Dubey, 1982; Young, 1985; Bachrach, 2010; Bachrach, Graepel, Kasneci, Kosinski, &
Van Gael, 2012a; Staum, 2012). Specific examples include dividing costs multicast transmissions (Feigenbaum, Papadimitriou, & Shenker, 2001), dividing airport landing
fees (Littlechild & Owen, 1973), pollution reduction costs (Petrosjan & Zaccour, 2003),
sharing supply chain profits (Shi-hua & Peng, 2006; Bachrach, Zuckerman, Wooldridge, &
Rosenschein, 2010) sharing gains regional cooperation electricity market (Gately, 1974). Although power indices allow finding fair allocations rewards
costs, susceptible forms strategic behavior (Yokoo, Conitzer, Sandholm,
Ohta, & Iwasaki, 2005; Aziz, Bachrach, Elkind, & Paterson, 2011; Zuckerman, Faliszewski,
Bachrach, & Elkind, 2012).
differences Banzhaf Shapley-Shubik indices analyzed (Straffin,
1977), index shown reflects specific conditions voting body. Different
301

fiBachrach, Porat, & Rosenschein

axiomatizations two indices proposed (Shapley, 1953; Dubey & Shapley,
1979; Lehrer, 1988; Straffin, 1988; Laruelle, 1999; Laruelle & Valenciano, 2001).
4.2 Cooperative Games Networks
model based network goal connecting set primary servers.
cooperative games networks proposed, modeling goals networks.
related work studies one model, deals cost sharing mechanism
multicast transmissions (Feigenbaum et al., 2001; Moulin & Shenker, 2001). body
related work focuses weakly budget-balanced implementation (where, opposed
model total payments agents may exceed total cost incurred),
mechanisms resistant deviations single agents. Yet another model
examines buying path source target network (Archer & Tardos,
2002). mechanism design model examines problem eliciting truthful
reports edges regarding true costs, contrast work focuses
cooperative game full information, agents incur cost allowing
use resources.
Another similar model considers scenario agents control edges network
flow graph, coalition wins maintain certain required flow source
target (Bachrach & Rosenschein, 2009). specific model finding Banzhaf
index edge domain #P-complete, though polynomial algorithm
restricted cases. handle different scenario agents required
maintain connectivity, rather certain flow. Also, interested maintaining
connectivity every two primary vertices, rather two specific vertices (we
simulate case two specific servers two primary servers). Also,
work agents servers communication network, rather links.
model Minimum Cost Spanning Tree Game (Bird, 1976; Granot & Huberman,
1981, 1984) (MCSTG) also quite similar model. cost sharing game,
agents vertices complete edge-weighted graph, cost coalition
minimal weight tree connects coalitions vertices designated root
r. formally, vertices graph include agents = {1, 2, . . . , n}
designated root r
/ I, V = {r}, graph complete edge weighted graph
(with n(n + 1)/2 edges); cost coalition weight minimal spanning
tree subgraph induced {r}. Granot et. al show MCSTGs always
non empty cores (1981) provide algorithms finding core imputations computing
nucleolus (1984). CG model quite differentCGs revenue sharing game,
costs associated edges, backbone vertices allowed.
notably, CGs simple games (where coalition either wins loses), core
CGs sometimes empty.
generalization MCSTGs called Steiner Tree Games (Skorin-Kapov, 1995), STGs,
also somewhat similar model. STGs allow nodes players, similarly
backbone vertices, may sometimes empty core. Related work
model discusses certain sufficient, necessary, condition core STG
non-empty, polynomial algorithm testing condition (Skorin-Kapov, 1995).
Since core may non-empty even condition hold, allow
302

fiSharing Rewards Cooperative Connectivity Games

polynomially determining core STG nonempty. Again, opposed
CGs, STGs non-simple cost sharing games. Further, also examine computational
aspect power indices core-relaxations, rather non-emptiness core
focus related work. results show CGs determine whether
core empty polynomial time even return representation core.
Another twist MCSTGs results model cost coalition
weight minimal tree spans vertices {r} entire graph, rather
graph induced {r} (Faigle, Kern, Fekete, & Hochstattler, 1997).
words, allowed use nonmembers coalition connect members coalition
root. model core may empty, testing core-emptiness
NP-complete problem (Faigle et al., 1997). results regarding model show
computing nucleolus game NP-hard (Faigle, Kern, & Kuipers, 1998).
variations MCSTG discussed (Granot & Huberman, 1981; SkorinKapov, 1995; Faigle et al., 1997) cost sharing games. games, coalition
must achieve certain goal agent endowed resources (for example,
ability use edges adjacent agent). However, using resource
associated cost, coalition attempts minimize total cost incurs.12
possible convert cost-sharing game reward sharing game (Moulin, 2002;
Chalkiadakis et al., 2012),13 example defining utility coalition
high constant reward minus cost coalition incurs achieve goal
original cost sharing game. However, model crucially depends assumption
node incurs cost allowing use links, coalitions achieve network
goal utility. believe better characterizes domains computer
network already constructed, links node simply available
use. MCSTG better models domains agents must make decisions
links build future constructing link requires investment
behalf agents.
Yet another related network based cooperative games Spanning Connectivity
Games (Aziz et al., 2009) (SCG short). SCGs similar CGs
cooperative network reward sharing game. However, opposed model, SCGs
players edges multigraph, coalition wins manages span
nodes network. Yet another similar reward sharing game Path Disruption
Games (Bachrach & Porat, 2010) coalition attempts disrupt connectivity
two specific vertices. Although domains combinatorially different
CGs, previous work examines similar solution concepts: core Shapley value.
example, related work shows computing power indices domains hard
computationally tractable algorithms solving core-related problems
(at least somewhat restricted domains).

12. games coalition may even able achieve goal all, case
define cost infinite.
13. Sometimes reward sharing games also called surplus sharing games.

303

fiBachrach, Porat, & Rosenschein

4.2.1 Computing Power Indices Core
name suggests, power indices also though measure significance
agents game. However, although Shapley Banzhaf power indices
defined voting games simple cooperative game, relatively little
work examined use power indices measuring importance players
non-voting scenarios. complexity computing power indices depends concrete
representation game. game defined value coalition,
form oracle tests certain coalition answers whether wins loses,
calculating power indices difficult. naive algorithm calculating power index
agent ai enumerates coalitions permutations containing ai . Since
exponentially many coalitions permutations, naive algorithm exponential
number agents.
Related work discusses algorithms calculating power indices weighted majority
games (Matsui & Matsui, 2000), shows calculating Banzhaf Shapley-Shubik
indices weighted voting games NP-complete problems (Matsui & Matsui, 2001).
Since weighted voting games restricted case simple coalitional games, problem
calculating either index general coalitional game course NP-hard. fact,
certain cases, calculating power indices NP-hard also #P-hard. Deng
Papadimitriou (1994) show computing Shapley-Shubik index weighted voting
games #P-complete. research derived hardness results power indices
game classes, Coalitional Skill Games (Bachrach & Rosenschein, 2008)
based set-covering problem, rule based cooperative game representation
called Multi-Attribute Coalitional Game language (Ieong & Shoham, 2006).
hardness results regarding computing power indices might make using concept seem less attractive. However, many results comparing approximating
power indices, general restricted domains (Owen, 1975; Deng & Papadimitriou,
1994; Conitzer & Sandholm, 2004; Bachrach, Markakis, Resnick, Procaccia, Rosenschein, &
Saberi, 2010; Faliszewski & Hemaspaandra, 2009). line work shows although
computing power indices exactly generally hard, estimating high degree accuracy computationally tractable. example, problematic vertices network
tractably found employing approximation method (Bachrach et al., 2010)
handle arbitrary cooperative games, long possible compute value
coalition polynomial time (which easy CGs). algorithm provided
Bachrach et al. (2010) estimates power indices returns result probably
approximately correct: given game players true power index , given
target accuracy level confidence level , algorithm returns approximation
probability least 1 | | (i.e., result approximately
correct, within distance correct value). running time logarithmic
confidence quadratic accuracy, approach tractable even high
accuracy confidence. Methods computing power indices also examined
context games uncertain agent failures (Bachrach, Meir, Feldman, & Tennenholtz,
2011; Bachrach, Kash, & Shah, 2012b).
treatment model game theoretic, network domains problems akin
calculating power indices also formulated network reliability problems.
304

fiSharing Rewards Cooperative Connectivity Games

computational complexity problems studied several papers. Classical
network reliability problems consider undirected graph G = hV, Ei, edge
e E probability assigned it, pe . probability edge e remains
surviving graph.
One prominent problem s-t connectivity probability (STC-P): given
domain, compute probability path s, V surviving graph.
Another prominent problem full connectivity probability (FC-P): given
domain, compute probability surviving graph connected (so
path two vertices). One seminal paper Valiant (1979a) proved STC-P
#P-hard. Provan Ball (1983) showed FC-P also #P-hard.
problems study similar FC-P. example computing Banzhaf
power index CGs specific case FC-P, probability every vertex
subset equal (or equivalently, vertex 50% probability failures,
failures independent). Since restricted case, cannot use hardness result
Provan Ball (1983), prove even restricted case #P-complete
(which did, Section 3.1).

5. Conclusions
considered computational aspects reward sharing network connectivity
scenario, applications network reliability. modeled communication network
simple coalitional game, showed various game-theoretic solution concepts
used characterize reasonable reward sharing agreements agents might make
find significant possible points failure network. shown domain,
general graphs, computing Shapley Banzhaf power indices #P-complete.
Despite high complexity result general domain, also gave polynomial result
restricted domain graph tree.
also shown computing core done polynomial time
CG, gave simple characterization instances core non-empty CGs.
hand, shown general CGs, testing imputation
-core (or equivalently computing maximal excess coalition imputation)
coNP-complete. also given characterization core tree CGs, shown
testing -core imputations done polynomial time tree CGs.
remains topic future research tractably compute power indices CGs
restricted domains. also note Shapley Banzhaf indices
power indices studied literature, studying computational aspects indices
also interest. also examined core, -core least core. hardness results
show computing maximal excess coalition computationally hard general
CGs. would interesting see could approximated, exactly computed
restricted domains trees. Yet another open question computing
game theoretic solution concepts CGs restricted CGs. One interesting problem
computing nucleolus (Schmeidler, 1969) CGs.14 Another interesting direction ex14. example, tree CGs, imputation equally allocates rewards essential vertices
Ves nucleolus. However, believe may even exist restricted CG domains
computing -core least core tractable, computing nucleolus hard.

305

fiBachrach, Porat, & Rosenschein

amining coalition formation models (Dang, Dash, Rogers, & Jennings, 2006; Greco, Malizia,
Palopoli, & Scarcello, 2011) analyzing coalition structure generation problem (Rahwan, Ramchurn, Dang, & Jennings, 2007; Ohta, Conitzer, Ichimura, Sakurai, Iwasaki, &
Yokoo, 2009; Bachrach, Meir, Jung, & Kohli, 2010) domain.

Acknowledgments
work partially supported Israel Science Foundation grants #898/05 #1227/12,
Israel Ministry Science Technology grant #3-6797.
preliminary version paper presented Seventh International Joint
Conference Autonomous Agents Multiagent Systems (AAMAS 2008). extended
version includes complete analysis power indices CGs, complementing
previous results regarding Banzhaf index new results regarding Shapley value.
also expanded work regarding stability based solutions, version contains
analysis problems related -core least core, showing problems
coNP-hard general CGs, solved polynomial time restricted case
CGs trees. also includes complete analysis core CGs played
trees.

References
Archer, A., & Tardos, E. (2002). Frugal path mechanisms. Proceedings Thirteenth Annual ACM-SIAM Symposium Discrete Algorithms, pp. 991999. Society
Industrial Applied Mathematics.
Aziz, H., Bachrach, Y., Elkind, E., & Paterson, M. (2011). False-name manipulations
weighted voting games. Journal Artificial Intelligence Research, 40 (1), 5793.
Aziz, H., Lachish, O., Paterson, M., & Savani, R. (2009). Power indices spanning connectivity games. Algorithmic Aspects Information Management, 5567.
Babaoglu, O., Meling, H., & Montresor, A. (2002). Anthill: framework development agent-based peer-to-peer systems. Distributed Computing Systems, 2002.
Proceedings. 22nd International Conference on, pp. 1522. IEEE.
Bachrach, Y., Elkind, E., Meir, R., Pasechnik, D., Zuckerman, M., Rothe, J., & Rosenschein,
J. S. (2009). cost stability coalitional games. Proceedings 2nd
International Symposium Algorithmic Game Theory (SAGT 09), pp. 122134.
Springer.
Bachrach, Y., Markakis, E., Resnick, E., Procaccia, A., Rosenschein, J. S., & Saberi, A.
(2010). Approximating power indices: theoretical empirical analysis. Autonomous
Agents Multi-Agent Systems, 20 (2), 105122.
Bachrach, Y., Meir, R., Zuckerman, M., Rothe, J., & Rosenschein, J. S. (2009). cost
stability weighted voting games. Proceedings 8th International Conference
Autonomous Agents Multiagent Systems, pp. 12891290.
306

fiSharing Rewards Cooperative Connectivity Games

Bachrach, Y., & Porat, E. (2010). Path disruption games. Proceedings 9th International Joint Conference Autonomous Agents Multiagent Systems, pp.
11231130.
Bachrach, Y., & Rosenschein, J. S. (2008). Coalitional skill games. Proceedings
7th International Joint Conference Autonomous Agents Multiagent Systems,
pp. 10231030.
Bachrach, Y., & Rosenschein, J. S. (2009). Power threshold network flow games. Autonomous Agents Multi-Agent Systems, 18 (1), 106132.
Bachrach, Y., Zuckerman, M., Wooldridge, M., & Rosenschein, J. S. (2010). Proof systems
transformation games. Mathematical Foundations Computer Science 2010,
7889.
Bachrach, Y. (2010). Honor among thieves: collusion multi-unit auctions. Proceedings
9th International Conference Autonomous Agents Multiagent Systems:
volume 1-Volume 1, pp. 617624. International Foundation Autonomous Agents
Multiagent Systems.
Bachrach, Y., Graepel, T., Kasneci, G., Kosinski, M., & Van Gael, J. (2012a). Crowd IQ:
aggregating opinions boost performance. Proceedings 11th International
Conference Autonomous Agents Multiagent Systems-Volume 1, pp. 535542.
International Foundation Autonomous Agents Multiagent Systems.
Bachrach, Y., Kash, I., & Shah, N. (2012b). Agent failures totally balanced games
convex games. Internet Network Economics, pp. 1529. Springer.
Bachrach, Y., Meir, R., Feldman, M., & Tennenholtz, M. (2011). Solving cooperative reliability games. Proceedings Twenty Seventh Conference Uncertainty
Artificial Intelligence (UAI 2011).
Bachrach, Y., Meir, R., Jung, K., & Kohli, P. (2010). Coalitional structure generation
skill games. Twenty-Fourth AAAI Conference Artificial Intelligence (AAAI).
Banzhaf, J. F. (1965). Weighted voting doesnt work: mathematical analysis. Rutgers
Law Review, 19, 317343.
Bird, C. (1976). cost allocation spanning tree: game theoretic approach. Networks,
6 (4), 335350.
Branzei, R., Dimitrov, D., & Tijs, S. (2008). Models cooperative game theory, Vol. 556.
Springer Verlag.
Chalkiadakis, G., Elkind, E., & Wooldridge, M. (2012). Cooperative game theory: Basic
concepts computational challenges. IEEE Intelligent Systems, 8690.
Conitzer, V., & Sandholm, T. (2004). Computing Shapley values, manipulating value division schemes, checking core membership multi-issue domains. Proceedings
Nineteenth National Conference Artificial Intelligence (AAAI 2004), pp.
219225.
Dang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalition
formation efficient data fusion multi-sensor networks. Proceedings
307

fiBachrach, Porat, & Rosenschein

National Conference Artificial Intelligence, Vol. 21, p. 635. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999.
Deng, X., & Papadimitriou, C. H. (1994). complexity cooperative solution concepts. Math. Oper. Res., 19 (2), 257266.
Dubey, P., & Shapley, L. (1979). Mathematical properties Banzhaf power index.
Mathematics Operations Research, 4(2), 99131.
Dubey, P. (1982). shapley value aircraft landing feesrevisited. Management Science,
28 (8), 869874.
Dunne, P., van der Hoek, W., Kraus, S., & Wooldridge, M. (2008). Cooperative boolean
games. Proceedings 7th International Joint Conference Autonomous
Agents Multiagent Systems, pp. 10151022.
Easley, D., & Kleinberg, J. (2010). Networks, crowds, markets. Cambridge University
Press.
Elkind, E., Goldberg, L. A., Goldberg, P., & Wooldridge, M. (2007a). Computational
complexity weighted threshold games. AAAI-2007, p. 718.
Elkind, E., Goldberg, L. A., Goldberg, P. W., & Wooldridge, M. (2007b). Computational
complexity weighted threshold games. National Conference Artificial
Intelligence, pp. 718723.
Faigle, U., Kern, W., Fekete, S., & Hochstattler, W. (1997). complexity testing
membership core min-cost spanning tree games. International Journal
Game Theory, 26 (3), 361366.
Faigle, U., Kern, W., & Kuipers, J. (1998). Note computing nucleolus min-cost
spanning tree games NP-hard. International Journal Game Theory, 27 (3), 443
450.
Faliszewski, P., & Hemaspaandra, L. (2009). complexity power-index comparison.
Theoretical Computer Science, 410 (1), 101107.
Feigenbaum, J., Papadimitriou, C. H., & Shenker, S. (2001). Sharing cost multicast
transmissions. Journal Computer System Sciences, 63 (1), 2141.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman Co.
Gately, D. (1974). Sharing gains regional cooperation: game theoretic application
planning investment electric power. International Economic Review, 15 (1), 195
208.
Gillies, D. B. (1953). theorems n-person games. Ph.D. thesis, Princeton University.
Goldman, C., & Zilberstein, S. (2004). Decentralized control cooperative systems: Categorization complexity analysis. J. Artif. Intell. Res. (JAIR), 22, 143174.
Granot, D., & Huberman, G. (1981). Minimum cost spanning tree games. Mathematical
Programming, 21 (1), 118.
Granot, D., & Huberman, G. (1984). core nucleolus minimum cost spanning
tree games. Mathematical Programming, 29 (3), 323347.
308

fiSharing Rewards Cooperative Connectivity Games

Greco, G., Malizia, E., Palopoli, L., & Scarcello, F. (2011). complexity core
coalition structures. Proceedings Twenty-Second international joint
conference Artificial Intelligence-Volume Volume One, pp. 216221. AAAI Press.
Holler, M., & Packel, E. (1983). Power, luck right index. Journal Economics,
43 (1), 2129.
Ieong, S., & Shoham, Y. (2006). Multi-attribute coalitional games. Proceedings
7th ACM Conference Electronic Commerce, pp. 170179. ACM.
Jain, M., Korzhyk, D., Vanek, O., Conitzer, V., Pechoucek, M., & Tambe, M. (2011).
double oracle algorithm zero-sum security games graphs. Proceedings
Tenth International Joint Conference Autonomous Agents Multi-Agent
Systems (AAMAS), Taipei, Taiwan, pp. 327334.
Kraus, S., Shehory, O., & Taase, G. (2004). advantages compromising coalition
formation incomplete information. Proceedings Third International
Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2004),
pp. 588595.
Laruelle, A. (1999). choice power index. Papers 99-10, Valencia Instituto de
Investigaciones Economicas.
Laruelle, A., & Valenciano, F. (2001). Shapley-Shubik Banzhaf indices revisited. Mathematics Operations Research, 89104.
Leech, D. (2002). Voting power governance International Monetary Fund.
Annals Operations Research, 109 (1-4), 375397.
Lehrer, E. (1988). axiomatization Banzhaf value. International Journal Game
Theory, 17 (2), 8999.
Lesser, V., Ortiz, C. L., & Tambe, M. (2003). Distributed sensor networks: multiagent
perspective. Springer.
Littlechild, S., & Owen, G. (1973). simple expression Shapley value special
case. Management Science, 370372.
Machover, M., & Felsenthal, D. S. (2001). treaty Nice qualified majority voting.
Social Choice Welfare, 18 (3), 431464.
Massoud Amin, S., & Wollenberg, B. (2005). Toward smart grid: power delivery
21st century. Power Energy Magazine, IEEE, 3 (5), 3441.
Matsui, Y., & Matsui, T. (2000). survey algorithms calculating power indices
weighted majority games. Journal Operations Research Society Japan, 43.
Matsui, Y., & Matsui, T. (2001). NP-completeness calculating power indices weighted
majority games. Theoretical Computer Science, 263 (12), 305310.
Meir, R., Bachrach, Y., & Rosenschein, J. (2010). Minimal subsidies expense sharing
games. Algorithmic Game Theory: Proceedings Third International Symposium (SAGT 2010), Vol. 6386, p. 347. Springer.
Meir, R., Zick, Y., & Rosenschein, J. S. (2012). Optimization stability games
restricted interactions..
309

fiBachrach, Porat, & Rosenschein

Moulin, H. (2002). Axiomatic cost surplus sharing. Handbook social choice
welfare, 1, 289357.
Moulin, H., & Shenker, S. (2001). Strategyproof sharing submodular costs: budget balance
versus efficiency. Economic Theory, 18 (3), 511533.
Ohta, N., Conitzer, V., Ichimura, R., Sakurai, Y., Iwasaki, A., & Yokoo, M. (2009). Coalition structure generation utilizing compact characteristic function representations.
Principles Practice Constraint Programming, 623638.
Owen, G. (1975). Multilinear extensions Banzhaf Value. Naval Research Logistics
Quarterly, 22 (4), 741750.
Papadimitriou, C., & Zachos, S. (1982). Two remarks power counting. Theoretical
Computer Science, 269275.
Papadimitriou, C. H. (2003). Computational complexity. John Wiley Sons Ltd.
Petrosjan, L., & Zaccour, G. (2003). Time-consistent Shapley value allocation pollution
cost reduction. Journal economic dynamics control, 27 (3), 381398.
Pipattanasomporn, M., Feroze, H., & Rahman, S. (2009). Multi-agent systems distributed smart grid: Design implementation. Power Systems Conference
Exposition, 2009. PSCE09. IEEE/PES, pp. 18. IEEE.
Provan, J. S., & Ball, M. O. (1983). complexity counting cuts computing
probability graph connected. SIAM Journal Computing, 12 (4), 777788.
Rahwan, T., Ramchurn, S. D., Dang, V. D., & Jennings, N. R. (2007). Near-optimal
anytime coalition structure generation. Proceedings 20th international joint
conference Artifical intelligence, pp. 23652371. Morgan Kaufmann Publishers Inc.
Resnick, E., Bachrach, Y., Meir, R., & Rosenschein, J. S. (2009). cost stability
network flow games. Mathematical Foundations Computer Science 2009:
Thirty-Fourth International Symposium Mathematical Foundations Computer
Science, No. 5734 Lecture Notes Computer Science, pp. 636650. Springer, Novy
Smokovec, High Tatras, Slovakia.
Roy, S., Ellis, C., Shiva, S., Dasgupta, D., Shandilya, V., & Wu, Q. (2010). survey
game theory applied network security. System Sciences (HICSS), 2010 43rd
Hawaii International Conference on, pp. 110. IEEE.
Royden, H. L., & Fitzpatrick, P. (1988). Real analysis, Vol. 3. Prentice Hall Englewood
Cliffs, NJ:.
Saad, W., Han, Z., Debbah, M., Hjorungnes, A., & Basar, T. (2009). Coalitional game theory
communication networks. Signal Processing Magazine, IEEE, 26 (5), 7797.
Sabater, J., & Sierra, C. (2002). Reputation social network analysis multi-agent
systems. Proceedings First International Joint Conference Autonomous
Agents Multiagent Systems, pp. 475482.
Schmeidler, D. (1969). nucleolus characteristic function game. SIAM Journal
Applied Mathematics, 17 (6), 11631170.
310

fiSharing Rewards Cooperative Connectivity Games

Shapley, L. S. (1953). value n-person games. Contributions Theory Games,
3140.
Shapley, L. S., & Shubik, M. (1954). method evaluating distribution power
committee system. American Political Science Review, 48, 787792.
Shapley, L. S., & Shubik, M. (1966). Quasi-cores monetary economy nonconvex
preferences. Econometrica: Journal Econometric Society, 34 (4), 805827.
Shi-hua, M., & Peng, W. (2006). study profit allocation among partners supply
chain based Shapley value [j]. Industrial Engineering Management, 4,
4345.
Shubik, M. (1962). Incentives, decentralized control, assignment joint costs
internal pricing. Management Science, 8 (3), 325343.
Skorin-Kapov, D. (1995). core minimum cost Steiner tree game networks.
Annals Operations Research, 57 (1), 233249.
Solymosi, T., & Raghavan, T. (1994). algorithm finding nucleolus assignment
games. International Journal Game Theory, 23 (2), 119143.
Staum, J. (2012). Systemic risk components deposit insurance premia. Quantitative
Finance, 12 (4), 651662.
Straffin, P. (1977). Homogeneity, independence power indices. Public Choice, 30, 107
118.
Straffin, P. (1988). Shapley-Shubik Banzhaf power indices probabilities.
Shapley Value, 7181.
Suris, J. E., DaSilva, L. A., Han, Z., & MacKenzie, A. B. (2007). Cooperative game theory
distributed spectrum sharing. IEEE International Conference Communications, 2007 (ICC07), pp. 52825287. IEEE.
Vadhan, S. P. (2002). complexity counting sparse, regular, planar graphs.
SIAM Journal Computing, 31 (2), 398427.
Valiant, L. G. (1979a). complexity enumeration reliability problems. SIAM
Journal Computing, 8, 410421.
Valiant, L. (1979b). complexity enumeration reliability problems. SIAM J.
Comput., 8 (3), 410421.
Vytelingum, P., Voice, T., Ramchurn, S., Rogers, A., & Jennings, N. (2010). Agent-based
micro-storage management smart grid. Proceedings 9th International
Conference Autonomous Agents Multiagent Systems, pp. 3946.
Yokoo, M., Conitzer, V., Sandholm, T., Ohta, N., & Iwasaki, A. (2005). Coalitional games
open anonymous environments. 20th National Conference Artificial
Intelligence, pp. 509514.
Young, H. (1985). Cost allocation. Fair Allocation, 33, 6994.
Zuckerman, M., Faliszewski, P., Bachrach, Y., & Elkind, E. (2012). Manipulating quota
weighted voting games. Artificial Intelligence, 180, 119.

311

fiJournal Artificial Intelligence Research 47 (2013) 95-156

Submitted 10/12; published 5/13

Distributed Reasoning
Multiagent Simple Temporal Problems
James C. Boerkoel Jr.

boerkoel@csail.mit.edu

Computer Science Artificial Intelligence Laboratory,
Massachusetts Institute Technology, Cambridge, 02139, USA

Edmund H. Durfee

durfee@umich.edu

Computer Science Engineering,
University Michigan, Ann Arbor, MI 48109, USA

Abstract
research focuses building foundational algorithms scheduling agents assist people managing activities environments tempo complex activity
interdependencies outstrip peoples cognitive capacity. address critical challenge
reasoning individuals interacting schedules efficiently answer queries
meet scheduling goals respecting individual privacy autonomy extent possible. formally define Multiagent Simple Temporal Problem naturally capturing
reasoning distributed interconnected scheduling problems multiple individuals. hypothesis combining bottom-up top-down approaches lead
effective solution techniques. bottom-up phase, agent externalizes constraints
compactly summarize local subproblem affects agents subproblems,
whereas top-down phase agent proactively constructs internalizes new local constraints decouple subproblem others. confirm hypothesis
devising distributed algorithms calculate summaries joint solution space
multiagent scheduling problems, without centralizing otherwise redistributing
problems. distributed algorithms permit concurrent execution achieve significant
speedup current art also increase level privacy independence
individual agent reasoning. algorithms advantageous problems
interactions agents sparse compared complexity agents individual
problems.

1. Introduction
Computational scheduling agents assist people managing coordinating
activities environments tempo, limited view overall problem, complex
activity interdependencies outstrip peoples cognitive capacity. Often, schedules
multiple agents interact, requires agent coordinate schedule
schedules agents. However, individual agent, user, may strategic
interests (privacy, autonomy, etc.) prevent simply centralizing redistributing
problem. setting, scheduling agent responsible autonomously managing
scheduling constraints specified user. concrete example, consider Ann,
faces task processing implications complex constraints busy schedule.
challenge Ann schedule interdependent schedules
colleagues, family, friends interacts. time, Ann would prefer
c
2013
AI Access Foundation. rights reserved.

fiBoerkoel & Durfee

independence make scheduling decisions keep healthy separation
personal, professional, social lives.
Simple Temporal Problem (STP) formulation capable representing scheduling problems where, order pairs activities matters, order
predetermined. such, STP acts core scheduling problem representation
many interesting planning problems (Laborie & Ghallab, 1995; Bresina, Jonsson, Morris,
& Rajan, 2005; Castillo, Fernandez-Olivares, & O. Garca-Perez, 2006; Smith, Gallagher,
Zimmerman, Barbulescu, & Rubinstein, 2007; Barbulescu, Rubinstein, Smith, & Zimmerman, 2010). One major practical advantages STP representation
many efficient algorithms compute flexible spaces alternative solutions (Dechter,
Meiri, & Pearl, 1991; Hunsberger, 2002; Xu & Choueiry, 2003; Planken, de Weerdt, &
van der Krogt, 2008; Planken, de Weerdt, & Witteveen, 2010a). improves robustness
stochasticity real world unreliability human users.
instance, STP used schedule morning agendas Ann, friend
Bill, doctor Chris representing events start time, ST , end time,
ET , activity variables, capturing minimum maximum durations
time events constraints. Ann 60 minute recreational activity (RA+B )
Bill spending 90 120 minutes performing physical therapy regimen (TR )
help rehabilitate injured knee (after receiving prescription left doctor
Chris); Bill spend 60 minutes recreation (RA+B ) Ann spending 60 180
minutes work (W B ); finally, Chris spend 90 120 minutes planning physical
therapy regimen (TP C ) Ann drop giving lecture (LC ) 10:00
12:00. example scheduling problem displayed graphically Figure 1a Simple
Temporal Network (STN)a network temporal constraints variable appears
vertex domain possible clock times described self-loop, constraints
appear weighted edges. Figure 1b represents one example solutionan assignment
specific times event respects constraints.
Suppose Ann, Bill, Chris would like task personal computational
scheduling agent coordinating managing possible schedules accomplish his/her agenda also protecting his/her interests. Unfortunately, current solution
algorithms solving STPs require representing entire problem single, centralized
STP, shown Figure 1, order calculate (space of) solution schedule(s)
agents. computation, communication, privacy costs associated centralization
may unacceptable multiagent planning scheduling applications, military,
health care, disaster relief, users specify problems agents distributed fashion, agents expected provide unilateral, time-critical, coordinated scheduling
assistance, extent possible.
motivates first major contribution: formal definition Multiagent Simple Temporal Problem (MaSTP). MaSTP, along associated Multiagent Simple
Temporal Network (MaSTN) distributed representations scheduling problems
solutions. MaSTN corresponding running example displayed Figure 2a. Like centralized counterparts, MaSTPs used help solve multiagent
planning problems monitor multiagent plan execution distributed manner.
representation allows person independently specify scheduling problem
scheduling agent, allows agent, turn, independently maintain infor96

fiDistributed Reasoning Multiagent Simple Temporal Problems

8: 00,12: 00



8: 00,12: 00

90,120




8: 00,12: 00

8: 00,12: 00
60,60

+


+






120,120

10: 00,10: 00



12: 00,12: 00




90,120

8: 00,12: 00







60,180

8: 00,12: 00

8: 00,12: 00

8: 00,12: 00

(a) example problem represented network temporal constraints.

8: 00



9: 30



9: 00

8: 00
+


+






10: 00


12: 00







9: 30

9: 00




10: 00

11: 00

(b) fully assigned point solution example problem.

Figure 1: typical, centralized STP representation example problem.

mation interrelated activities user. scheduling agent, then, use
information provide user exact times queried possible timings
relationships events, without unnecessarily revealing information
agents.
second major contribution paper distributed algorithm computing
complete joint solution space, displayed Figure 2b. leads advice
robust disturbances accommodating new constraints finding
single joint solutions like Figure 1b. advantage approach new
constraint arrives (e.g., Chris bus late), agents easily recover simply eliminating newly invalidated joint schedules consideration. agents make choices
adjust new constraints, distributed algorithm simply reapplied recompute
resulting narrower space remaining possible joint schedules, subsequent
choices assured also satisfy constraints. long agents wait ramifications
choices/adjustments propagate making choices, eventually converge
schedule works, rather prematurely picking brittle schedule needs
replaced. However, flexibility comes cost ongoing communication, along
coordinating distributed decisions ensure implications one agents decision propagates another agents decision compatible. example, Ann
decides start recreating 8:30, Bills agent must wait decision propagate advising Bill options recreate, otherwise might inadvertently
choose different time.
97

fiBoerkoel & Durfee

Chris

8: 00,12: 00

8: 00,12: 00

Chris
90,120

8: 00,12: 00
8:
00,12:
00

Chris

8: 00,12: 00

Ann

8: 00,12: 00

8: 00,12: 00

Ann
60,60

00
8: 00,12:
8: 00,12:
00


Ann

Bill

8: 00,12: 00

Bill
60,60

00
8: 00,12:
00
8: 00,12:


Bill
60,60

00
8: 00,12:
00 60,60 8: 00,12:
8: 00,12:
00
8: 00,12:


00
0,0




60,60
60,60
90,120


















0,0






90,120
60,180
120,120





0,0



00
10:00,10:
00
12: 00,12:
8:
00,12:
8: 00,12:
00
8: 00,12:
00
8: 00,12:
00
00

90,120
60,180
120,120





00,10:



00
00Example

10:Our
00
12: 00,12:
8:
00,12:
8: 00,12:
00
00,12:
00 60,180
8: 00,12:
00 disOriginal
MaSTP.
(a)
first
contribution
the(a)
Multiagent
Simple
Temporal
Network 8:
representation,

allows
90,120
120,120
tributed representation multiagent STPs solutions.
10: 00,10: 00
8: 00,12: 00Example
00
8: 00,12: 00 Bill 8: 00,12: 00
Chris12: 00,12: 00 (a) Original
Ann 8: 00,12:MaSTP.
9:
00,10:
30
8:
00,9:
30
9: 30,10: 00
8: 00,9: 30
9: 00,10: 30
8: 00,8: 30
00
8:
00,12:
0090,1208: 00,12:




30
8:
00,8:




Chris
Chris

90,120
00
9: 30,10:


(a) Original Example
MaSTP.
Ann
60,60

8:
00,9:
30


Ann

9: 00,10:
30


0,0

30
8: 00,9:


Bill
Bill

60,60

30
9: 00,10:


60,60 9: 00,10: 30
8:60,150
00,9:
30 60,60 9: 00,10:
8: 00,9:
30


30




0,0
60,60
60,60




60,150








0,0




90,120
60,180
60,150








00
10:00,10:
00
12: 00,12:
9:
30,10:
11: 00,12:
00
9: 00,11:
00
10: 00,12:
00
30

90,120
60,180
120,120









00
30

10:00,10:
00
12: 00,12:
30,10:
11: 00,12:
00
9: 00,11:
00 60,18010: 00,12:
00
(b) 9:Minimal
(PPC)
Version.
90,120
120,120
90,1209: 30,10: 00
8:
00,8:
30



90,120








120,120

10:Our
00,10:
00
12: 00,12: 00
30,10: 30 Ann
11: 00,12:
00
9: 00,11:
00 Billspace
10: 00,12:
00
Chris
(b)
second
contribution
(b)
new9:distributed
algorithm
computing
complete
solutions
Minimal
(PPC)
Version.
9:
45,9:
45
8:
45,8:
45
9:
30,10:
00
8:
45,8:
45
9:
45,9:
45
to8:an00,8:
MaSTP.
30
30
8:
00,8:


Chris
Chris

90,120
00
9: 30,10:


90,1209: 30,10: 00
8:
00,8:
30



90,120








120,120

00
10:00,10:
00
12: 00,12:

120,120

00

10:00,10:
00
12: 00,12:
120,120

(b) MinimalAnn
(PPC) Version.
60,60

45
9: 45,9:
8:
45,8:
45


Ann
8:60,105
45,8:
45 60,60 9: 45,9:45



60,60


60,105






90,120
60,105



10:
00,10:
30
11: 30,12:
00

90,120




10:
00,10:
3090,12011:Version.
30,12:
00
(c)
Decoupled

45
8: 45,8:


Bill
Bill

60,60

45
9: 45,9:


60,60 9: 45,9: 45
8: 45,8:
45



60,60








60,135


9: 45,11:
00



10: 45,12:
00
60,135


00

9: 45,11:
60,13510: 45,12: 00

10: 00,10: 00
10: 00,10:
30Ann11:Version.
30,12: 00
9: 45,11: 00 Bill 10: 45,12: 00
Chris12: 00,12: 00 (c)
Decoupled
9: 00
8: 00
9: 30
8: 00
9: 00
8: 00
(c) thirdChris
contribution new(c)
distributed
temporal
decoupling algorithm computing
Decoupled
Ann Version.
Bill locally independent
00solution spaces.
00
00


9:
00
9:
30
8:
9:
00
8:


8:



Ann

Chris

Bill

9: 00
Figure 2: summary
our8:contributions

applied

example problem.
9: 30
8:00
9: 00
8:00
00



















10:
00


12:00



10:
00



12:00

10: 00

12: 00























9:
00


10:00





9:
30 Assigned
00
(d) Fully
Version.
98 11:



9:
00



10:00

9: 30
00
(d) Fully
Assigned11:Version.
(d) Fully Assigned Version.

9: 00

10: 00



9:
30




11:
00



fiDistributed Reasoning Multiagent Simple Temporal Problems

motivates third major contribution: distributed algorithm computing
temporal decoupling. temporal decoupling composed independent spaces
locally consistent schedules that, combined, form space consistent joint schedules
(Hunsberger, 2002). example temporal decoupling displayed Figure 2c, where,
example, Chris agent agreed prescribe therapy regimen 10:00 Anns
agent agreed wait begin performing 10:00. Here,
agents advice independent agents, temporal decoupling also provides
agents resiliency new constraints enhances users flexibility autonomy
making scheduling decisions. Chris bus late minute, Chris
agent absorb new constraint independently updating local solution space.
advantage approach agents establish temporal decoupling,
need communication unless new constraint renders chosen decoupling
inconsistent. temporal decoupling become inconsistent (e.g.,
Chris bus half hour late, causing violate commitment finish
prescription 10:00) agents must calculate new temporal decoupling (perhaps
establishing new hand-off deadline 10:15), independently react
newly-arriving constraints, repeating process necessary.
rest paper structured fully describe contributions.
Section 2 builds foundational background necessary understanding contributions.
Section 3 formally defines MaSTP explains important properties corresponding MaSTN. Section 4 describes distributed algorithm computing complete MaSTP
solution spaces, analytically proving algorithms correctness runtime properties,
empirically demonstrating speedup achieves previous centralized algorithms.
Section 5 describes distributed algorithm decoupling MaSTP solution spaces,
proving algorithms correctness runtime properties, empirically comparing
performance previous art demonstrate trade-offs completeness versus independence reasoning. give overview related approaches Section 6 conclude
discussion Section 7.

2. Background
section, provide definitions necessary understanding contributions, using
extending terminology previous literature.
2.1 Simple Temporal Problem
defined Dechter et al. (1991), Simple Temporal Problem (STP), = hX, Ci,
consists set n timepoint variables, X, set temporal difference constraints,
C. timepoint variable represents event continuous domain values (e.g.,
clock times) expressed constraint relative special zero timepoint
variable, z X, represents start time. temporal difference constraint cij
form xj xi bij , xi xj distinct timepoints, bij R {}
real number bound difference xj xi . Often, notational convenience,
two constraints, cij cji , represented single constraint using bound interval
form xj xi [bji , bij ].
99

fiBoerkoel & Durfee

Ann

Availability

RST
z [480, 720]

RET
z [480, 720]

TR ST z [480, 720]
TR
ET z [480, 720]

Bill

B
RST
z [480, 720]
B
RET
z [480, 720]
B
WST
z [480, 720]
B
WET
z [480, 720]

Chris

TP C
ST z [480, 720]
TP C
ET z [480, 720]
LC
ST z [600, 600]
LC
ET z [720, 720]

Duration

Ordering



RET
RST
[60, 60]

External

B
RST
RST
[0, 0]



RET
RST
0

TR
ET RST [90, 120]


TP C
ET RST 0

B
B
RET
RST
[60, 60]
B
B
RET
WST
0


B
RST
RST
[0, 0]

C
TP C
ET LST 0


TP C
ET RST 0

B
B
WET
WST
[60, 180]

C
TP C
ET PST [90, 120]

C
LC
ET LST [120, 120]

Table 1: Summary constraints running example problem.
schedule assignment specific time values timepoint variables. STP
consistent least one solution, schedule respects constraints.
Table 1, formalize running example (introduced Section 1) specific
constraints. activity two timepoint variables representing start time (ST )
end time (ET ), respectively. example, activities scheduled
morning (8:00-12:00), constrained (Availability column) take place within 480
720 minutes zero timepoint z, case represents midnight. Duration
constraints specified bounds difference activitys end time
start time. Ordering constraints dictate order agents activities must
take place respect other. Finally, formal introduction external
constraints deferred later (Section 3), last column represents constraints
span subproblems different agents. Figure 1b illustrates schedule represents
solution particular problem.
2.2 Simple Temporal Network
exploit extant graphical algorithms (e.g., shortest path algorithms) efficiently reason constraints STP, STP associated Simple Temporal Network (STN), represented weighted, directed graph, G = hV, Ei, called
distance graph (Dechter & Pearl, 1987). set vertices V contains vertex vi
timepoint variable xi X, E set directed edges, where, constraint
cij form xj xi bij , directed edge eij vi vj constructed initial
weight wij = bij . graphical short-hand, edge vi vj assumed
bi-directional, capturing edge weights single interval label, [wji , wij ],
100

fiDistributed Reasoning Multiagent Simple Temporal Problems

vj vi [wji , wij ] wij wji initialized exists corresponding
constraint cij C cji C, respectively. STP consistent exist
negative cycles corresponding STN distance graph.
reference edge, ezi , timepoint vi edge vi zero timepoint z. another short-hand, reference edge ezi represented graphically
self-loop vi . self-loop representation underscores reference edge eiz
thought unary constraint implicitly defines vi domain, wzi wiz
represent earliest latest times assigned vi , respectively. work,
assume z always included V that, construction G,
reference edge ezi added z every timepoint variable, vi Vz .
graphical STN representation example STP given Table 1 displayed

Figure 2a. example, duration constraint TR
ET RST [90, 120] represented

graphically directed edge TR
ST TR ET label [90, 120]. Notice
B
B
label edge RET WST infinite upper bound, since Bill
must start work ends recreation, corresponding constraint given
soon ends recreation must occur. Finally, constraint LC
ST z
,


label

[10:00,10:00],

represents
[600, 600] translated unary loop LC
ST
Chris constrained start lecture exactly 600 minutes midnight (or
exactly 10:00 AM). Throughout work, use STP STN notation.
distinction STP notation captures properties original problem,
pair variables constrained bounds, whereas STN notation convenient,
graphical representation STP problems agents algorithmically manipulate
order find solutions by, example, capturing implied constraints new tightened
edges graph.
2.3 Useful Simple Temporal Network Properties
Temporal networks minimal decomposable provide efficient representation
STPs solution space useful advice-giving scheduling agents.
2.3.1 Minimality
minimal edge eij one whose interval bounds, wij wji , exactly specify set
values difference vj vi [wji , wij ] part solution (Dechter
et al., 1991). temporal network minimal edges minimal.
minimal network representation solution space STP. example, Figure 2b
minimal STN, whereas Figure 2a not, since would allow Ann start recreation
at, say, 9:31 Figure 2c also not, since allow Ann start 9:30.
practically, scheduling agent use minimal representation exactly efficiently
suggest scheduling possibilities users without overlooking options suggesting options
work.
2.3.2 Decomposability
Decomposability facilitates maintenance minimality capturing constraints that,
satisfied, lead global solutions. temporal network decomposable
assignment values subset timepoint variables locally consistent (satisfies
101

fiBoerkoel & Durfee

constraints involving variables) extended solution (Dechter et al.,
1991). STN typically made decomposable explicitly adding otherwise implicit
constraints and/or tightening weights existing edges variable domains
provably consistent values remain. example, Figure 1b trivially decomposable, since
assigning variable single value within minimal domain assures part
solution. Figure 2b, hand, decomposable, since, instance,
= 10:30 TR = 11:00, self-consistent (because
assignment RET
ET
constraints directly link two variables), cannot extended full solution.
scheduling agent use decomposable temporal network directly propagate
newly-arriving constraint area network single-step, backtrack-free
manner.
sum, STN minimal decomposable represents entire set
solutions establishing tightest bounds timepoint variables (i) solutions eliminated (ii) self-consistent assignment specific times subset
timepoint variables respects bounds extended solution efficient,
backtrack-free manner.
2.4 Simple Temporal Problem Consistency Algorithms
subsection, highlight various existing algorithms help establish STN
solution properties introduced previous subsection.
2.4.1 Full Path Consistency
Full Path Consistency
(FPC) establishes minimality decomposability STP

instance n3 time (recall n = |V |) applying all-pairs-shortest-path algorithm,
Floyd-Warshall (1962), STN, resulting fully-connected distance graph
(Dechter et al., 1991). Floyd-Warshall algorithm, presented Algorithm 1, finds
tightest possible path every pair timepoints, vi vj , fully-connected
distance graph, i, j, k, wij wik + wkj . graph checked consistency
validating negative cycles, is, 6= j, ensuring wij + wji 0.
example FPC version Anns STP subproblem presented Figure 3a. Note
agent using FPC representation provide exact bounds values
lead solutions pair variables, regardless whether corresponding
constraint present original STP formulation.
2.4.2 Graph Triangulation
next two forms consistency require triangulated (also called chordal) temporal
network. triangulated graph one whose largest non-bisected cycle triangle (of
length three). Conceptually, graph triangulated process considering vertices
adjacent edges, one one, adding edges neighbors currentlyconsidered vertex edge previously existed, eliminating vertex
consideration, vertices eliminated (Golumbic, 1980). basic graph
triangulation process presented Algorithm 2. set edges added
process called fill edges order timepoints eliminated
consideration referred elimination order , o. Figure 3b shows topology
102

fiDistributed Reasoning Multiagent Simple Temporal Problems

Algorithm 1: Floyd-Warshall
Input: fully-connected distance graph G = hV, Ei
Output: FPC distance graph G inconsistent
1 k = 1 . . . n
2
= 1 . . . n
3
j = 1 . . . n
4
wij min(wij , wik + wkj )
5
wij + wji < 0
6
return inconsistent
7

return G

Algorithm 2: Triangulate
Input: distance graph G = hV, Ei; elimination order = (v1 , v2 , . . . , vn1 , vn )
Output: triangulated distance graph G
1 k = 1 . . . n
2
forall i, j > k s.t. eik , ejk E
3
E E {eij }
4

return G

triangulated version Anns distance graph timepoints eliminated order
, RA , RA , RA ).
= (T RET
ET
ST
ST
quantity induced graph width distance graph relative o,
defined maximum, vk , size vk set not-yet-eliminated neighbors

time elimination. triangulate algorithm, then, operates n o2 time.
Elimination orders often chosen attempt find minimal triangulation,
attempt minimize total number fill edges. While, generally speaking, finding
minimum triangulation graph NP-complete problem, heuristics minimum
degree (selecting vertex fewest edges) minimum fill (selecting vertex
adds fewest fill edges) used efficiently find elimination orders approximate
minimum triangulation (Kjaerulff, 1990).
2.4.3 Directional Path Consistency
alternative FPC checking STP consistency establish Directional Path
Consistency (DPC) temporal network. DPC algorithm (Dechter et al., 1991),
presented Algorithm 3, takes triangulated graph corresponding elimination order,
o, input. traverses timepoint, vk , order o, tightening edges
pair neighboring timepoints, vi , vj , (where vi vj connected vk via edges eik
ejk respectively) appear vk order
o, using rule wij min(wij , wik +
wkj ). time complexity DPC n o2 , instead establishing minimality,
establishes property solution recovered DPC distance graph
backtrack-free manner variables assigned reverse elimination order. example
103

fi






[60,150]

[60,




90,120

9: 00,10: 30

9: 00,10: 30

60,60







[60,150]




[90,180]
90,120

9: 00,10: 30

Boerkoel & Durfee

10: 30,12: 00

Ann

8: 00,9: 30










10: 30,12: 00

(a) Anns FPC STN.




90,120

9: 00,10: 30

8: 00,11: 00

Ann

8: 00,12: 00

60,60







9: 00,10: 30

60,60







[60,150]

[60,



8: 00,12: 00

Ann

8: 00,9: 30




90,120

9: 00,10: 30




8: 00,12: 00

(b) Anns DPC STN.




90,120

9: 00,10: 30

10: 30,12: 00

(c) Anns PPC STN.

Figure 3: Alternative forms Ann
consistency applied Anns STP.
Ann
9: 00,10: 30

8: 00,9: 30




8: 00,9: 30

9: 00,10: 30

60,60

60,60


Algorithm 3: Directional Path Consistency
(DPC)





Input: triangulated temporal [60,150]
network G = hV, Ei corresponding elimination
[60,150]
[90,180]
order = (v1 , v2 , . . . , vn1 , vn )


Output: DPC distance graph G
inconsistent







90,120
1 k = 1 . . . n
90,120
9: 00,10: 30
10: 30,12: 00
2
forall > k s.t. eik E
9: 00,10: 30
10: 30,12: 00
3
forall j > s.t. ejk E
4
wij min(wij , wik + wkj )
5
wji min(wji , wjk + wki )
Ann
6
wij + wji < 0
9: 00,10: 30
8: 00,9: 30
7
return inconsistent
8

return G




60,60

[60,150]




[90,180]






, RA , RA , RA ),
90,120
DPC version Anns problem, using elimination order = (T RET
ET
ST
ST
presented Figure 3b. Basically,
establishing
DPC
00
sufficient establishing whether
9: 00,10:
30
10:
30,12:

consistent schedules exist not, limits scheduling agent giving useful advice
last variable eliminated.
Section 4.1, discuss combine reasoning DPC triangulate
algorithms execution distributed. Combining reasoning yields
example bucket-elimination algorithm. Bucket-elimination algorithms (Dechter,
1999) general class algorithms calculating knowledge compilations, solution
space representations solutions extracted backtrack-free, linear-time
manner. adaptive consistency algorithm (Dechter & Pearl, 1987; Dechter, 2003)
calculates knowledge compilation general constraint satisfaction problems (Dechter,
1999). Adaptive consistency eliminates variables one one, variable
eliminates, reasons bucket constraints variable involved deduce
new constraints remaining non-eliminated variables. solution remain104

fiDistributed Reasoning Multiagent Simple Temporal Problems

Algorithm 4: Plankens Partial Path Consistency (P3 C)
Input: triangulated temporal network G = hV, Ei elimination order
= (v1 , v2 , . . . , vn1 , vn )
Output: PPC distance graph G inconsistent
1 G DP C(G, o)
2 return inconsistent DPC
3 k = n . . . 1
4
forall i, j > k s.t. eik , ejk E
5
wik min(wik , wij + wjk )
6
wkj min(wkj , wki + wij )
7

return G

ing subproblem extended solution original problem, since solution
accounts constraints entailed eliminated variable. DPC important step
establishing Partial Path Consistency, discuss next.
2.4.4 Partial Path Consistency
Bliek Sam-Haroud (1999) demonstrate Partial Path Consistency (PPC)
sufficient establishing minimality STP instance calculating tightest possible
path subset edges exist within triangulated distance graph.
example Xu Choueirys algorithm 4STP (Xu & Choueiry, 2003), processes
updates queue potentially inconsistent triangles (4) triangulated
graph. Alternatively, algorithm P3 C, Planken et al. (2008) sweep
triangles systematic order, gives guaranteed upper bound runtime,
bound known 4STP. P3 C algorithm, included Algorithm 4
executes DPC algorithm first phase executes reverse traversal
DPC algorithm second phase, edge weights updated
reverse elimination

order. Thus P3 C achieves complexity, n o2 , DPC algorithm.
exploiting sparse network topology, PPC-based algorithms
may establish minimality much

faster FPC algorithms practice (O n o2 n3 ) (Xu & Choueiry, 2003;
Planken et al., 2008). PPC representation Anns subproblem using elimination
, RA , RA , RA ) displayed Figure 3c.
order = (T RET
ET
ST
ST
PPC approximates decomposability since assignments fully-connected subsets variables (those belong clique triangulated network)
guaranteed extensible full solution. However solutions still recovered
backtrack-free manner either requiring constraint propagation subsequent
variable assignment assigning variables reverse simplicial elimination order elimination order variables yields triangulated network (that
is, introduces new fill edges) (Planken et al., 2008). agent using PPC representation offer advice pair variables share edge triangulated
graphthose originally related via constraint original formulation
connected fill edges. While, unlike FPC temporal networks, agent using
105

fiBoerkoel & Durfee

PPC network cannot answer queries regarding arbitrary pairs variables (i.e.,
share edge), sparser PPC structure important benefits agents
independent private reasoning, discussed Section 3.1.2.
2.5 Temporal Decoupling Problem
Hunsberger (2002) formally defined concept temporal decoupling STPs.

partitioning STP Ss variables
V Bff, leads naturally

AintoA fftwo sets,B V


B
definition two sub-STPs, = V , C
= V , C B , C C B
constraints defined exclusively variables V V B , respectively.
B form temporal decoupling if:
B consistent STPs;
Merging locally consistent solutions problems B yields solution
S.
Notice temporal decoupling exists original STP consistent.
Alternatively, B form temporal decoupling S, B said
temporally independent. Temporal Decoupling Problem (TDP), then, defined

B , C C B combined
finding two sets decoupling constraints,


CA ffand CB


ff

B

B respectively,
form = V , C C = V B , C B C
B form temporal decoupling STP S. minimal decoupling one where,


C B relaxed (increasing
bound decoupling constraint either C

bound constraint inclusive) removed, B longer
form decoupling. original TDP algorithm (Hunsberger, 2002) executes centrally
C B propagating
iterates proposing new constraints add C

constraints reestablish FPC corresponding global distance graph
subsequently proposed decoupling constraints guaranteed consistent. iteration
occurs constraint spans B constraints
rendered moot due new decoupling constraints.
temporal decoupling trades complete solution space possibly messy interdependencies partial solution space nice independence properties. Independent
reasoning, critical applications must provide time-critical, unilateral
scheduling advice environments communication costly uncertain, comes
cost eliminating valid joint solutions. Section 4.3, present various flexibility
metrics quantify portion solution space retained given temporal
decoupling, use quantify trade-off.

3. Multiagent Simple Temporal Problem
problem paper addresses developing compact, distributed representation of, distributed algorithms finding (a temporal decoupling of) joint
solution space of, multiagent scheduling problems. section formally defines distributed representation form Multiagent Simple Temporal Problem, extends
definitions minimality decomposability representation, characterizes
independence privacy within representation. Sections 4 5 describe
106

fiDistributed Reasoning Multiagent Simple Temporal Problems

distributed algorithms find either complete temporally decoupled solution spaces
providing users flexible sound scheduling alternatives. algorithms avoid
unnecessarily centralizing redistributing agents subproblems also achieve significant
speedup current state-of-the-art approaches.
3.1 Multiagent Simple Temporal Problem Formulation
Multiagent Simple Temporal Problem (MaSTP) composed local STP
subproblems, one agents, set constraints CX establish
relationships local subproblems different agents (Boerkoel & Durfee,

2010,
ff

2011; Boerkoel, 2012). agent local STP subproblem defined SL = VL , CLi 1 ,
where:
VLi defined agent set local variables, composed timepoints
assignable agent along variable representing agent reference z;
CLi defined agent set intra-agent local constraints, local
constraint, cij CLi , defined bound bij difference two local
variables, vj vi bij , vi , vj VLi .
Figure 2a, variables constraints entirely within boxes labeled Chris, Ann,
Bill represent persons respective local STP subproblem running example.
Notice, sets VLi partition set (non-reference) timepoint variables, Vz .
CX set inter-agent external constraints, external constraint
defined bound difference two variables local different
agents, vi VLi vj VLj , 6= j. However, agent knows subset
external constraints involve local timepoints and, by-product external
constraints, also aware subset non-local variables, where:
agent set external constraints, involves exactly one
CX
agent local timepoint variables (since constraints inherently binary);

VXi agent set external timepoint variables, local
.
agent j 6= i, known agent due external constraint CX

sets
external variables
ofi external constraints CX = CX set
VX = VX . Together, agent set known timepoints VLi VXi set known
. Note assumes constraint known agent
constraints CLi CX
least one variable involved constraint. Figure 2a, external constraints
variables denoted dashed edges.

then, MaSTP,
formally,
M, defined STP = hVM , CM

VM = VL CM = CX CL .
1. Throughout paper, use superscripts index agents subscripts index variables
constraints/edges.

107

fiBoerkoel & Durfee

Figure 4: High-level overview MaSTP structure.

3.1.1 Minimality Decomposability
point, discussed MaSTP problem formulation. However, also discuss properties corresponding Multiagent Simple Temporal Network (MaSTN). MaSTP converted equivalent MaSTN way
STP converted STN, definition agent local external edges,
, follows analogously definition C C , respectively. Like
ELi EX
X
L
STN, MaSTN algorithmically manipulated represent useful information.
Here, discuss STN properties minimality decomposability translate
MaSTN.
MaSTN
decentralized one), properties
(a) STN (albeit (b)
(c) minimality
decomposability extend unhindered multiagent temporal networks. Thus, minimal
MaSTN one edges minimal. Likewise, MaSTN decomposable
self-consistent assignment values subset variables extended full
joint solution.
Calculating MaSTN minimal decomposable requires computing
fully-connected network, which, multiagent setting, clobbers independence
agents subproblems: agents timepoints connected every
timepoint every agent. Full connectivity obliterates privacy (since v VLi , v
VXj j 6= i) requires every scheduling decision coordinated among agents.
reason, work focuses instead establishing partial path consistency approximate
decomposability retaining loosely-coupled structure may exist MaSTN.
3.1.2 Algorithm-Centric MaSTP Partitioning

(a)

(b)

MaSTP formalization presented naturally captures MaSTPs using agent-centric
perspective. However, algorithmically, often easier discuss MaSTP terms
parts problem agent solve independently, parts require shared
effort solve. Thus, introduce additional terminology helps improve
precision comprehension algorithmic descriptions analytical
arguments.
108

fiDistributed Reasoning Multiagent Simple Temporal Problems

(a)

(a) agent external, interface, private timepoints.

(b)

(b) Local vs. External.

(c)

(c) Private vs. Shared.

Figure 5: Alternative partitionings agents STP.
natural distribution MaSTP representation affords partitioning
MaSTP independent (private) interdependent (shared) components. start
defining shared STP, SS = hVS , CS i, composed of:
VS = VX {z}the set shared variables comprised variables
involved least one external constraint;
CS = {cij | vi , vj VS }the set shared constraints defined constraints
pairs shared variables, includes entire set external constraints
CX , could also include otherwise local constraints exist two shared
variables belonging single agent.
Notice that, illustrated Figure 4, shared STP overlaps agents local
, three distinct sets:
(a) agent known timepoints, V (b)
subproblem, thus divides
VXi agent set external variables, defined before;
VIi = VLi VS agent set interface variables, defined agent set
local variables involved one external constraints;
VPi = VLi \ VS agent set private variables, defined agent local
variables involved external constraints.
three sets variables depicted graphically Figure 5a. Figure 5 also highlights two alternate partitionings MaSTP agent-centric local versus external
components (Figure 5b) algorithm-centric independent (private) versus interdependent
(shared) components (Figure 5c). formally, allows us define agent private
109

fiBoerkoel & Durfee



ff
subproblem, SPi = VPi , CPi , agent set private constraints, CPi = CLi \ CS ,
subset agent local constraints include least one private variables.
partitioning depicted Figure 5c useful algorithmically establishes
parts agents subnetwork independent agents (private),
parts inherently interdependent (shared). Notice agent local constraints
included private subproblem long include private variable, even
also involve shared variable. agent able propagate changes
constraint, private constraint, without directly affecting shared timepoint
constraint. Private edges connected shared timepoint appear hang Figure 5c
shared timepoint actually part shared subproblem.
3.1.3 Independence
Algorithms use distributed MaSTN representation reason scheduling problems span multiple agents strategic (e.g., privacy) computational (e.g., concurrency) advantages. extent advantages realized largely depends
level independent reasoning agent able perform local problem. define two timepoints independent path connects
MaSTN, dependent otherwise. Notice dependencies agents
inherently flow set shared variables, VS . implication agent
independently (and thus concurrently, asynchronously, privately, autonomously, etc.)
reason private subproblem SPi independently SPj j 6= i.
Theorem 1. dependencies agent local subproblem, SLi , another
agent js (j 6= i) local subproblem SLj , exist exclusively shared STP, SS .
Proof. contradiction, assume exist variables vi VPi vj VPj vi
vj independent given SS . implies exists path constraint
network vi vj involves pair private variables vi0 VPi vj0 VPj
connected via constraint. However, contradiction, since vi0 vj0 would,
definition, belong VS , thus SS . Therefore, every pair variables vi VPi
vj VPj independent given SS .
3.1.4 Privacy
work, assume agents cooperative. However, time, user
may still wish avoid gratuitous revelation details schedule
agents people, extent possible. next look privacy preserved
byproduct distributed problem representation level independent reasoning
established Theorem 1. Obviously, coordination agents activities
inherent privacy costs. However, show costs limited shared
timepoints edges them.
Notice Figure 2a variable Anns Bills agent starts knowing
, due Bills shared constraint Ann. However,
recreational start time variable RST
Anns agent establish PPC using variety different elimination orderings, Anns
agent alone cannot establish PPC timepoints without adding new external edges.
Anns problem contains two different externally constrained timepoints
110

fiDistributed Reasoning Multiagent Simple Temporal Problems

share local constraint path, regardless elimination order used. So, example

Anns agent eliminate private timepoints (TR
ET RET )
, triangulation process would construct new external edge
eliminate RST

B
shared timepoints TR
ST RST shown Figure 2b. effectively adds TR ST

Bills agents set external timepoints. TR ST already shared Chris
shared edge, triangulation process
agent, fill edge RST
allows Bills agent become aware shared components Anns problem.
question becomes: Bills agent continue process draw inferences
Anns private timepoints edges? Theorem 2 shows that, without exogenous source
information, agent able infer existence of, number of, bounds
another agents private timepoints, even implicitly influence agents subproblem
shared constraint paths.
Theorem 2. agent infer existence bounds another agents private edges,
subsequently existence private timepoints, solely shared STN.
Proof. First, prove existence bounds private edge cannot inferred
shared STN. Assume agent private edge, eik EPi . definition, least
one vi vk private; without loss generality, assume vi VPi . every pair
edges eij ejk capable entailing (the bounds of) eik , regardless whether vj
shared private, vi VPi implies eij EPi private. Hence, pair edges capable
implying private edge must also contain least one private edge. Therefore, private
edge cannot inferred shared edges alone.
Thus, since agent cannot extend view shared STN include another agents
private edges, cannot infer another agents private timepoints.
Theorem 2 implies SS (the variables constraints represented
dashed lines Figure 2b) represents maximum portion MaSTP agents
infer without exogenous (or hypothesized) source information, even collude
reveal entire shared subnetwork. Hence, given distribution MaSTP M,
agent executes multiagent algorithm reveal private timepoints
constraints, guaranteed agent j 6= able infer private
timepoint VPi private constraint CPi also executing multiagent algorithmat
least without requiring conjecture ulterior (methods inferring) information
part agent j. generally, necessary inevitable one agent knows
infers entire shared STP SS .
3.2 Multiagent Temporal Decoupling Problem
next adapt original definition temporal decoupling (Hunsberger, 2002) described Section 2.5 apply MaSTP. set agents local STP subproblems
{SL1 , SL2 , . . . , SLn } form temporal decoupling MaSTP if:
{SL1 , SL2 , . . . , SLn } consistent STPs;
Merging combination locally-consistent solutions problems
{SL1 , SL2 , . . . , SLn } yields solution M.
111

fiBoerkoel & Durfee

(a)

(b)

(a)

(c)

(b)

Figure 6: temporal decoupling problem calculates new local constraints render
constraints agents superfluous.
Alternatively, {SL1 , SL2 , . . . , SLn } form temporal decoupling M, said
temporally independent. illustrated Figure 6, objective Multiagent

Temporal Decoupling Problem
find set constraints C

(MaTDP)
ff



1
2
n
agent SL+ = VL , CL C , {SL+ , SL+ , . . . , SL+ } temporal
decoupling MaSTP M. Note solving MaTDP mean agents
subproblems somehow become inherently independent (with respect
original MaSTP), rather new decoupling constraints provide agents
way perform sound reasoning completely independently other.
, depicted dotted lines right-hand side
Notice new constraints, C
Figure 6, allow safe removal superfluous external constraints involving agent
local variables, external constraints also removed figure. Finally, notice local variables edges previously part shared problem (marked
right-hand side Figure 6 double edges) treated algorithmically
private. Figure 1b Figure 2c represent temporal decouplings example,
new tighter unary decoupling constraints, essence, replace external edges
(shown faded). minimal decoupling one where, bound decoupling coni agent relaxed (or removed), {S 1
2
n
straint c C
L+ , SL+ , . . . , SL+ }
longer decoupling. Figure 2c example minimal decoupling whereas de
facto decoupling formed full assignment (such one Figure 1b) minimal.

4. Distributed Algorithms Calculating Partial Path Consistency
section, introduce Distributed Partial Path Consistency (D4PPC) algorithm
establishing PPC MaSTN. illustrated Figure 7, algorithm works
solving a+1 subproblems: private agent subproblems one shared STP. Like
original P3 C algorithm (Algorithm 4 page 105), subproblems solved
112

fiDistributed Reasoning Multiagent Simple Temporal Problems

9: 30,10: 00

90,120







8: 00,11: 00

Ann

8: 00,12: 00

60,60




Bill

8: 00,12: 00













8: 00,12: 00

60,60




[60, )




120,120

10: 00,10: 00

12: 00,12: 00




90,120

8: 00,12: 00

8: 00,10: 30

60,180

8: 00,12: 00




8: 00,12: 00

Phase 2: Eliminate Shared Timepoints
0,0







9: 30,10: 00
Chris




[60, )

8: 00,11: 00

Ann




[60, )

9: 30,10: 30

DPPC (Algorithm 8)

[0, )

Shared STN

8: 00,9: 30
Bill

Phase 3: Reinstate Shared Timepoints
[0,60]

Shared STN







9: 30,10: 00
Chris

0,0
[60,150]

8: 00,9: 30

Ann







[60,150]

9: 30,10: 30

8: 00,9: 30
Bill




Chris

9: 30,10: 00

90,120




Ann

8: 00,9: 30

9: 00,10: 30

60,60







8: 00,9: 30
0,0




Bill

9: 00,10: 30

60,60




60,150


120,120

10: 00,10: 00



12: 00,12: 00




90,120

9: 30,10: 30




11: 00,12: 00




9: 00,11: 00

60,180




10: 00,12: 00

PPC (Algorithm 6)

Phase 4 - Reinstate Private Timepoints
8: 00,8: 30

Figure 7: distributed PPC algorithms operate four distinct phases.

113

DDPC (Algorithm 7)

Chris

8: 00,12: 00

DPC (Algorithm 5)

Phase 1: Eliminate Private Timepoints

fiBoerkoel & Durfee

two phases: forward sweep eliminates timepoints compute implied constraints
establish DPC second, reverse sweep reinstates nodes updates incident edges
establish full minimality PPC. order maximize concurrency independence
distributed version algorithm, carefully partition execution four phases.
Agents work together perform forward (Phase 2, Figure 7) reverse (Phase 3,
Figure 7) sweeps P3 C algorithm respectively shared STP, agent
independently performs forward (Phase 1, Figure 7) reverse (Phase 4, Figure 7)
sweeps P3 C algorithm private subproblem.
Section 4.1, introduce 4DPC 4PPC algorithms, serve
subroutines D4PPC algorithm establish DPC PPC agents private
subproblem 4DPC algorithm tweaks original DPC algorithm agent
independently triangulate establish DPC private portion subproblem (Phase 1). Then, later Phase 4, agent executes 4PPC reinstate private
timepoints complete process establishing PPC private subproblem. Next,
Section 4.2.1, describe D4DPC algorithm carefully distributes execution
4DPC algorithm that, separately establishing DPC private STNs,
agents work together triangulate update remaining shared portion MaSTN
globally consistent manner, thus establishing DPC MaSTN whole (Phases
1 2). Finally, present overarching D4PPC algorithm Section 4.2.2.
agent executes D4PPC separately. D4PPC first invokes D4DPC establish DPC
MaSTN (Phases 1 2), executes distributed version 4PPCs reverse sweep
agents cooperatively establish PPC shared portion MaSTN (Phase
3), finally invokes 4PPC finish PPC establishment agents separate private
subproblem (Phase 4). conclude section proving that, despite distribution
execution, algorithms maintain correctness (Section 4.2.3), empirically demonstrating that, result concurrent execution, D4PPC algorithm
achieves high levels speedup centralized counterparts (Section 4.3).
4.1 Centralized Partial Path Consistency Revisited
DPC (Algorithm 3 page 104) P3 C (Algorithm 4 page 105) algorithms
take variable-elimination ordering already triangulated STN input. However,
aim decentralize algorithm execution, requiring already triangulated network
complete variable elimination order punts providing distributed solution
critical algorithmic requirement best, requires centralized representation entire
network worst, thus invalidating many motivations distribution first
place. Hence, point section demonstrate graph triangulation
process elimination order construction process incorporated DPC
algorithm, whose execution later distribute, added computational overhead.
Observe triangulation (Algorithm 2 page 103) DPC algorithms end
traversing graphs exactly order, processing combined.
4DPC algorithm (Algorithm 5) result modifying DPC algorithm based
two insights: (i) 4DPC construct variable elimination order execution
applying SelectNextTimepoint procedure (line 3), heuristically chooses
next timepoint, vk , eliminate; (ii) 4DPC considers implications
114

fiDistributed Reasoning Multiagent Simple Temporal Problems

Algorithm 5: Triangulating Directional Path Consistency (4DPC)
Input: STN G = hV, Ei
Output: triangulated, DPC STN G corresponding elimination order
= (v1 , v2 , . . . , vn1 , vn ), inconsistent
1 ()
2 |V | > 0
3
vk SelectNextTimepoint(hV, Ei , o)
4
V V \ {vk }
5
o.append(vk )
6
forall vi , vj V s.t. eik , ejk E
7
E E {eij }
8
wij min(wij , wik + wkj )
9
wji min(wji , wjk + wki )
10
wij + wji < 0
11
return inconsistent
12

return G,

pair temporal difference constraints involving removed timepoint variable, necessarily considers exact fill edges triangulation process would added. 4DPC
requires original distance graph representation STN, G input. Line 7 adds,
necessary, newly-created fill edges vk non-eliminated neighbors
proceeds propagate implications eliminated timepoints constraints forward
lines 89. Like DPC algorithm, 4DPC halts soon detects inconsistency
(line 11). Incorporating triangulation process 4DPC algorithm reduces
problem distributing DPC graph triangulation algorithms distributing execution 4DPC algorithm alone. 4DPC algorithm example
bucket-elimination algorithm property elimination process could
stop point, solution remaining subproblem guaranteed extensible full solution involving eliminated timepoints. Thus, solution derived
DPC network assigning timepoints reverse elimination order.
example, consider Anns agent, refer agent A, executing 4DPC
algorithm Anns subproblem (see Figure 8a). algorithm starts using minimum

fill heuristic select variable TR
ET elimination adds TR ET elimination order.
Next agent loops pair TR
ET neighbors. case one
pair neighboring edges: unary edge, represented algorithmically
edge shared reference timepoint z, edge TR
ST . Together, edges

imply tighter unary constraint TR ST , lowering upper bound 10:30
guaranteed occur least 90 minutes eliminated TR
ET . eliminating


values TR ST domain inconsistent TR ET , agent guaranteed
solution remaining (non-eliminated) subproblem exists, solution extensible
include TR
ET .
elimination. case notice RA involved
Next agent selects RET
ET


path RST TR ST . addition updating domains neighboring timepoints,
115

fiBoerkoel & Durfee

Ann
8: 00,12: 00
Ann 8: 00,12: 00
00
8: 00,12:
00 60,60 8: 00,12:




60,60







90,120







8: 00,12:
0090,1208: 00,12:00

8: 00,12: 00

Ann
8: 00,12: 00
Ann

00
8: 00,12:
00 60,60 8: 00,12:




60,60







90,120



8: 00,10:
30





8: 00,12:00

8: 00,11: 00 Ann
8: 00,12: 00
8: 00,12: 00
8: 00,11: 00 Ann
8: 00,12:
00 60,60 8: 00,12:
00




60,60





[60,
[60,



90,120






90,120


8: 00,10: 3090,1208: 00,12: 00
8: 00,12: 00
8: 00,10: 30
8: 00,12: 00
8: 00,12: 00
8: 00,12: 00
8: 00,12: 00
8:and
00,10:
30 eliminating
8:
00,12:
00
(a)
forward1:
sweep
4PPC
(4DPC) works apply
selecting DPC
timepoint,


(a)ThePhase
Agents
independently

local
subproblem.

consideration, calculating constraints implied remaining neighbors.

(a) PhaseAnn
1: Agents independentlyAnn
apply DPC local
subproblem.
9: 00,10: 30
Ann
8: 00,9: 30

Ann 9: 00,10: 30

30
8: 00,9:
30 60,60 9: 00,10:




60,60


60,150


60,150



90,120




8: 00,9:
30 60,60 9: 00,10:

30


60,60




[60,150]

8: 00,12: 00
9: 00,10: 30
60,60
8: 00,12: 00
8: 00,9:
30




60,60




[60,150]

[60,150]



[60,150]



8: 00,9: 30

Ann

9: 00,10: 30




90,120





00
11: 00,12:


9: 30,10:
3090,12011: 00,12:
00
9: 30,10: 3090,120
8: 00,12: 00
11: 00,12: 00
9: 30,10: 30
11: 00,12: 00
9:
30,10:
30
8: 00,12:
00
(b) Phase 4: Agents independently apply
PPC

8: 00,9: 30

Ann

90,120








9: 30,10: 3090,1208: 00,12: 00

8: 00,12: 00
9: 30,10:
30 subproblem.

local
(b)
Phase
4: Agents
independently
PPC intoreverse
theirorder,
local
subproblem.
(b)

reverse sweep
4PPC
works reinstatingapply
timepoint
tightening
incident
edges respect newly-updated, explicit constraints neighbors.

Figure 8: Agent executing two-part 4PPC Anns private subproblem.
viewed first (a) last (b) phases overall D4PPC algorithm.

TR involving RA . guarantee
agent must also capture path RST
ST
ET
TR ,
integrity path retained, agent adds fill edge RST
ST
lower bound 60 infinite upper bound (as implied path). addition fill
edges reason output 4DPC triangulated network. Note typically
minimum fill heuristic would select variables add fill edges selecting ones
do, explain Section 4.2.1, improve concurrency, restrict agent
eliminating private timepoints prior shared timepoints.
4DPC completes, remaining, non-eliminated timepoints involved external constraints, addressed distributed algorithms described shortly
Section 4.2. turning distributed algorithms, however, first describe
4PPC, agent apply complete computation PPC private
subproblem Phase 4. 4PPC algorithm, included Algorithm 6, nearly identically
follows original P3 C algorithm, replacing DPC 4DPC algorithm, dropping triangulation elimination order requirements, adding line 5 explicitly

116

fiDistributed Reasoning Multiagent Simple Temporal Problems

Algorithm 6: Triangulating Partial Path Consistency (4PPC)
Input: STN G = hV, Ei; DPC STN G w/ corresponding elimination order
Output: triangulated, PPC STN G inconsistent
1 provided
2
G, 4DP C(G)
3
return inconsistent 4DPC

8

k = n . . . 1
V V vk
forall i, j > k s.t. eik , ejk E
wik min(wik , wij + wjk )
wkj min(wkj , wki + wij )

9

return G

4
5
6
7

reinstate eliminated timepoint reverse sweep. 4PPC algorithm complements 4DPC algorithm reinstating eliminated timepoints reverse elimination
order. However timepoint reinstated, incident edges updated respect
previously reinstated neighbors, whose explicit edges inductively guaranteed
minimal property 4DPC algorithm.
Figure 8b shows Anns subproblem agent returned establishing PPC
shared timepoints, soon described Section 4.2. convey reverse reinstatement order, note Figure 8b works right left. Agent starts selecting
, last private timepoint eliminated, reinstatement. agent loops
RET
neighbors, time updating incident edge respect
pair RET
explicit minimal third edge (in Figure 8b, three incident edges:
neighbors edge them). results
domain RET
, occurs exactly 60 minutes RA ,
updated domain [9:00,10:30] RET
ST

new upper bound edge shared TR
.
TR

similarly
reinstated,
completing
ST
ET
execution algorithm. Next, prove 4PPC algorithm correct
runs n (G + o2 ) time Theorems 3 4 respectively.
Theorem 3. 4DPC 4PPC algorithms establish DPC PPC STN,
respectively.
Proof. difference Algorithm 6 P3 C algorithm (Algorithm 4, page 105),
call 4DPC obtain elimination order, triangulate, establish DPC.
loop Algorithm 5 (line 2), along lines 35, establish total order, o,
vertices. Given o, lines 2, 6, 7 exactly execute triangulate algorithm (Algorithm 2,
page 103), triangulates graph lines 2, 6, 8, 11 exactly execute
DPC algorithm (Algorithm 3, page 104). Thus 4DPC algorithm establishes DPC.
remainder algorithm exactly follows P3 C algorithm, Planken et al. (2008)
prove correctly establishes PPC.

117

fiBoerkoel & Durfee


Theorem 4. 4PPC executes n (G + o2 ) time, G complexity
variable selection heuristic (as applied G) graph width induced o.
Proof. Besides call 4DPC
first line, Algorithm 6 exactly executes P3 C

STN G, requires n o2 time, proven Planken et al. (2008). Meanwhile,
outer loop Algorithm 5 (line 2) executed n times. iteration,
operations require constant time SelectNextTimepoint heuristic (line 3),
whose cost G function size complexity G, inner loop (line 6),
complexity o2 .
Note elimination order provided input, costs variable selection heuristic become embedded algorithm. costs range
constant time (if selection arbitrary) NP-hard (if selection optimal), typically polynomial number vertices n number constraints (Kjaerulff, 1990).
Thus, algorithm internalizes computational cost typically assumed part
preprocessing. analyses consistent convention, better
capture computation costs associated directly manipulating underlying
temporal network, include G costs remaining analyses.
4.2 Distributed Partial Path Consistency Algorithm
Agents execute 4DPC 4PPC algorithms separately private STNs (Phases
1 4, Figure 7), correctly solving shared STN (Phases 2 3, Figure 7) requires
cooperation. accomplish this, introduce distributed partial path consistency
algorithm D4PPC. presentation parallels previous section, begin
forward-sweeping D4DPC algorithm triangulating establishing DPC
MaSTN instance Section 4.2.1, follow reverse sweep D4PPC
algorithm Section 4.2.2.
4.2.1 D4DPC Algorithm
Consider example Figure 8a. Agent successfully independently

execute 4DPC two private timepoints TR
ET RET . point, consider
TR .
would happen agent proceeded eliminating timepoints RET
ST
remaining timepoint connected portions MaSTN belong
agents, agent must consider actions impact agents vice
, unbeknownst
versa. example, suppose agent considering eliminating RST
B . case, agent would
agent A, Bills agent (agent B) already eliminated RST

B
eliminate RST assuming edge RST still exists, reality, not.
result, computation agent could result superfluous reasoning reasoning
stale information, ultimately could jeopardize integrity output
algorithm whole. Next, discuss algorithm avoids problematic
situations.
distributed algorithm D4DPC (Algorithm 7) novel, distributed implementation
bucket-elimination algorithm establishing DPC multiagent temporal networks
(Phases 1 2, Figure 7). agent starts completing Phase 1 applying 4DPC
private STP (lines 12), presented previous section illustrated Figure 8a.
118

fiDistributed Reasoning Multiagent Simple Temporal Problems

Algorithm 7: Distributed Directional Path Consistency (D4DPC)


ff
Input: Agent portion distance graph G = V , E

Output: Agent portion triangulated, DPC
distance graph G
corresponding elimination orders oiP = v1 , . . . vni oS = (v1 , . . . vnS ),
P
inconsistent


ff
1 G , oiP 4DP C( VPi , E )
2 return inconsistent 4DPC
3 oS ()
4 |VIi | > 0
5
RequestLock(oS )


ff
6
vk SelectNextTimepoint( VIi , E , oS )
7
oS .append(vk )
8
ReleaseLock(oS )
9
VIi VIi \ {vk }
10
forall vi VXi oS s.t. eik E updates vi yet received
11
E E BlockReceiveUpdatedEdges(Agent(vi ))
12
13
14
15
16
17
18
19
20
21
22

forall vi , vj VSi s.t. eik , ejk E
E E {eij }
wij min(wij , wik + wkj )
wji min(wji , wjk + wki )
wij + wji < 0
Broadcast(inconsistent)
return inconsistent
else
SendUpdatedEdge(eij , Agent(vi ))
SendUpdatedEdge(eij , Agent(vj ))
return G , oiP , oiS

output 4DPC agents private problem (shown Figure 9a) viewed
summary private subproblem impacts shared problem. words,
schedules consistent remaining shared portion agents subproblem
guaranteed extensible solution agents subproblem. result,
rather jointly reasoning entire MaSTN, agents need cooperatively
reason potentially much smaller shared STN.
Continuing Phase 2, agent still responsible eliminating
timepoints shared STN, securing lock shared timepoint
elimination ordering (line 5), selecting one interface timepoints vk eliminate (line 6),
recording vk shared elimination ordering (line 7), releasing lock (line 8).
done first-come, first-served basis. avoid deadlocks establish precise
ordering timepoints, two agents request lock time,
lock simply goes agent smallest id. Then, performing basic 4DPC
inner loop selected timepoint, agent blocks received updated edge
119

fiBoerkoel & Durfee

Shared STN



Shared STN

9: 30,10: 00

Chris

9: 30,10:
Shared
STN 00
Chris



Shared STN

9: 30,10: 00

Chris

9: 30,10: 00
Shared
STN
Chris



Shared STN

9: 30,10: 00

Chris


[0, )

0,0




[0, ) [60, )




0,0




[60, )

9: 00,10: 30
8: 00,11:
00
8: 00,10:
00




Ann

Bill
8:
00,10:
30


[60, )
[60, )
9: 00,10:
0,0 30
8: 00,10: 30

8: 00,11:
[0, ) 00
Ann



8: 00,10: 00
Bill








[60, )
[0, ) [60, )
0,0
9: 30,10: 30
8: 00,11:
00
8: 00,10:
00


30



Ann 9: 00,10:
Bill

[60, )
[60, )

9: 30,10: 30
0,0
Ann 9: 00,10: 30

8: 00,11:
[0, ) 00




[0, ) [60, )




0,0

8: 00,11:
00




9: 30,10:30

Ann
[60, )

8: 00,10: 00
Bill
[60, )




8: 00,9: 30


Bill
8:
00
[60, ) 00,10:

8:subproblem.
00,9:
30
8: 00,11:
00
9:
30,10: 30
(a)
D4DPC
portion
D4PPC
uses
blocking
communication
9: 30,10:
00
(a)The
Phase
2: Collaboratively
applyalgorithm
DDPC
shared
Ann network 8:triangulated
Christimepoints eliminated
Bill 00
00,10:
ensure
0,0
STN manner. [0, )
globallyShared
consistent

(a) Phase 2: Collaboratively
apply DDPC shared subproblem.




Shared STN




[0, ) [60, )

9: 30,10: 00

Chris


8: 00,11:
00


9: 30,10: 00
Shared
STN
Chris

8: 00,11:
[0, )00




Shared STN

9: 30,10: 00

Chris




0,0

9: 30,10:30

Ann
[60, )
Ann



9: 30,10:
0,030


[0, ) [60, )

8: 00,11:
00









0,0

9: 30,10:30

Ann
[60, )

[60, )



[60, )

8: 00,9: 30


Bill


8: 00,9: 30
Bill
60,150


[60, )

30
60,150 8: 00,9:


Bill

[60, )

8: 00,11:
9: 30,10:
8: 00,9: 30
[0,60]00
0,030
Ann
Bill
[0, )
60,150








[0,60] [60, )
[60,150]
0,0
Shared STN
) 30
8:[0,
00,9:
30
8: 00,9:
30
9: 30,10: 00
60,1509: 30,10:





8:
00,11:
00 Ann
Chris
Bill



[60, )
[60,150]
8:
00,9:
30
9: 30,10: 30
8: 00,9: 30
9: 30,10:
00
Phase
3: Collaboratively
DPPC
shared subproblem.
8: 00,11:apply
00 Ann
Chris
Bill
9: 30,10: 00
Shared
STN
Chris

(b)

(b) agents reinstate timepoints reverse sweep D4PPC al(b) Phase 3: Collaboratively apply DPPC shared subproblem.
gorithm, agent responds message processed previous
phase updated edge information edge.

Figure 9: second third phases D4PPC algorithm require coordination (as
represented block arrows) agents establish PPC shared STN.
120

fiDistributed Reasoning Multiagent Simple Temporal Problems

information respect timepoints share edge vk appear
shared elimination ordering (line 11). involves adding edge, necessary,
updating weights minimum existing newly received weights.
steps completed, agent safely proceed lines 1221,
identical inner loop 4DPC algorithm (Algorithm 5) except lines 2021,
send updated edge information neighboring agent. continues
agent eliminated interface timepoints.
Returning running example, Figure 8a represents first step D4DPC
algorithm. Note, agents need complete eliminating private timepoints
agent proceed eliminating shared timepoints. example, Figure 9b, agents
C begin eliminating agent B does. due heterogeneity
either agents capabilities subproblems. case, agent C appends

timepoint TP C
ET shared elimination order agent appends RST . However,

shared edges TP C
ET RST , agents continue
concurrently (without blocking line 11). Note agents C compute new
domain TR
ET ; however, agent records update [9:00,10:30] locally.
agent selects eliminate TR
ET , thus must block receive updates due
TP C
,

agent

records
agent
Cs
tighter
update [9:30,10:30]. elimination
ET
agent remaining timepoints also leads messages agent B. However agent B
B final step. Note that, agent B
receives updates eliminates RST
B
attempted eliminate RST agent completed computing new edges
B, agent B would forced block received edge updates
, would appear RB shared elimination order.
regarding RST
ST
4.2.2 D4PPC Algorithm
D4PPC algorithm (Algorithm 8) invokes preceding algorithms accomplishes
four phases depicted Figure 7. starts invoking D4DPC algorithm,
results globally DPC triangulated network (or detection inconsistency), along
elimination order vertices (lines 12). new contribution D4PPC
algorithm agents cooperatively performing reverse sweep establish PPC
shared STN (Phase 3 Figure 7), invoking 4PPC algorithm finish
establishing PPC private STN (Phase 4).
cooperatively establish PPC shared STN, D4PPC algorithm traverses
vertices reverse order and, instead calculating updating third edge based
two neighboring edges D4DPC does, updates neighboring edges based
(newly) updated third edge. Thus, guarantee updates correctly shared
correctly incorporate information agents, third edge external
agent, must wait receives updated edge weights agent responsible
updating last line 8. edge eij < j, agent last
agent update edge, since timepoint appears earliest elimination order.
incident edge weights updated respect updated third edge (lines 9
12). performing updates edge, agent communicates updated
weights agent also shares edge (line 14). agent sent
121

fiBoerkoel & Durfee

Algorithm 8: Distributed Partial Path Consistency (D4PPC)


ff
Input: agent local STP instance G = V , E
Output: agent
portion
PPC network G inconsistent


1 G , oiP = v1 , . . . vni
, oS = (v1 , . . . vnS ) D4DPC (G )
P

2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

return inconsistent D4DPC
k = nS . . . 1 s.t. vk VIi
V V vk
= nS . . . k + 1 s.t. eik E
j = nS . . . + 1 s.t. ejk E
w , w yet updated
eij EX
ij
ji
wij , wji BlockReceiveUpdatedEdge(Agent(vi ))
wik min(wik , wij + wjk )
wki min(wki , wkj + wji )
wkj min(wkj , wki + wij )
wjk min(wjk , wji + wik )
j = 1 . . . k 1 s.t. eij , ejk E vj VXi
SendUpdatedEdge(Agent(vj ), eik )


ff
4PPC ( VPi , E , oiP )
return G

update regarding edge D4DPC. Note mechanisms place
guaranteeing correct communication need executed external edges.
Figure 9b shows process action. first timepoint reinstated also
B . property DPC graphs, RB domain [8:00-9:30]
last eliminated: RST
ST
guaranteed minimal, is, represent exact set values could part
joint solution. D4PPC algorithm, then, propagates information captured
tighter edges domains variables appear later elimination order back
MaSTN variables appear earlier. Agent B kicks algorithm
skipping inner-most loop (since one neighbor appears it:
de facto z reference point), sending updated domain agent A. Notice even
B updated domain update shared timepoints,
though agent might need RST
message received once. Then, agent reinstates Anns variables, one one,
RB
uses information update upper bounds edges RST
ST
, also domain RA . shared timepoints reinstated,
TST
ST
algorithm terminates agent finishes propagating shared updates
private network (as illustrated Figure 8b). Notice line 15, agent supplies
previously computed oP 4PPC, ensuring 4DPC skipped timepoints
reinstated reverse oP order.
Overall, D4PPC algorithm introduces three points synchrony execution:
contention shared elimination order two calls BlockReceiveUpdatedEdge. simplify understanding analysis algorithms, made
122

fiDistributed Reasoning Multiagent Simple Temporal Problems

synchronization points explicit. previous formulation algorithms (Boerkoel &
Durfee, 2010) allows agents proceed optimistically beyond synchronization points.
example, agent could optimistically begin eliminating one timepoints
officially obtaining shared elimination order lock, long reevaluates whether
agents concurrently eliminated neighboring timepoint lock obtained.
Likewise, reverse-sweep, agent could begin updating private edges
optimistic assumption current view network up-to-date, backjumping computation new edge update arrives fit assumption.
cases, proceeding optimistically never leads incorrect computation,
computation may wasted invalidating updates later arrive, agents would sat
idle anyway waiting updates. Hence, worst nothing lost, best
optimistic assumptions hold agents gotten head start processing.
4.2.3 Theoretical Analysis
section, prove D4PPC algorithm correct showing
deadlock free (Theorem 5) establishes PPC (Theorem 6), also prove
added communication change underlying runtime complexity (Theorem 7).
Theorem 5. D4PPC deadlock free.
Proof. start proving first call D4DPC deadlock free. two
lines D4DPC (Algorithm 7) agents may block agents: line 5 line 11.
line 5, one lock (on shared elimination order), requests lock
granted first-come, first-served basis, ties broken according agent
id. Further, agent lock elimination order, oS , executes two local
operations select variable append oS releasing lock line 8.
SelectNextTimepoint independent, local decision requiring locally known
information. Hence, deadlock cannot occur result contention oS .
leaves line 11. Assume, way contradiction, line 11 causes deadlock.
implies two (or more) agents, j, 6= j agent
simultaneously waiting communication line 11. Thus, exists
timepoint vxj VXi VLj agent waiting receive updated edges agent j,
also vyi VXj VLi agent j waiting receive updated edges
agent i. Notice vyj must appear vxi agent copy oS because, otherwise,
time vyj appeared oS , agent would already sent agent j edge updates
pertaining vxi (lines 2021) previous loop iteration vxi eliminated
(and added oS line 7). However, reason, vxi must appear vyj
agent js copy oS . contradiction, one shared elimination
order agents append granted mutually-exclusive access.
argument extends inductively three agents, line 11 also
cause deadlock, presents contradiction.
Therefore D4DPC algorithm deadlock free. call D4DPC,
D4PPC algorithm traverses MaSTN exact opposite order D4DPC
algorithm, proof remainder D4PPC algorithm deadlock free follows,
mutandis mutatis.

123

fiBoerkoel & Durfee

Theorem 6. D4PPC correctly establishes PPC MaSTN.
Proof (Sketch). 2 algorithm starts correctly establishing DPC MaSTN. Since,
definition, none agents private timepoints share edges private timepoints
agent, agent apply 4DPC private subproblem independently
(lines 12). Given nature 4DPC algorithm bucket-elimination algorithm
(solutions remaining subproblem guaranteed extensible eliminated variables), agent computed constraints interface variables capture
impact private subproblem shared subproblem. remaining algorithm
applies 4DPC algorithm agents shared timepoints. Lines 58 guarantee
globally consistent elimination ordering shared timepoints established. Finally,
lines 11 2021 guarantee edge weights used agent stale
consistent among agents involved.
Then, algorithm executes operations second phase 4PPC
algorithm, distributed fashion, using blocking communication guarantee
computation performed using correctly updated edge weights.

Theorem 7. D4PPC executes (nP + nS ) o2 time, nP = maxi |VPi |, nS =
|VS |, graph width induced o.
Proof. Beyond lines added communication, D4PPC algorithm exactly executes
4PPC caveat elimination order restricted eliminating private
timepoints prior shared timepoints. lines code added communication
increase work constant factor within 4PPC algorithm (for edge update
performed 4PPC, one message sent received). However, agents must
block edge updates agents, agent may need wait agent
complete local computation. worst case, elimination subsequent
revisiting shared timepoints must done completely sequentially, puts

algorithm complexity class 4PPC algorithm, (nP + nS ) o2 .
Note Theorem 7 provides worst-case analysis. best case, complete concurrency
possible, putting runtime closer nL o2 , nL = |VL | less equal
nP + nS . is, best case, blocking occurs (and agents execute 100%
concurrently), leading costs agents executing 4DPC subproblems.
Note best case likely realized when, instance, external
constraints. empirical evaluations, present next, find run times fall
somewhere two extremes practice closer best case looselycoupled problems.
4.3 Empirical Evaluation
section, empirically evaluate distributed algorithm solving MaSTP.
performance distributed algorithm relies size agents private
subproblem relative size complexity collective shared subproblem.
greater portion problem private agent, rather shared,
2. full version this, remaining proof sketches, available online appendix associated
publication.

124

fiDistributed Reasoning Multiagent Simple Temporal Problems

greater level independent reasoning concurrency, thus faster overall
solve time distributed algorithm compared centralized algorithm.
4.3.1 Experimental Setup
Random Problem Generator. evaluate algorithms solving MaSTPs using
random problem generator described Hunsberger (2002), adapt
generates multiagent STP instances. problem instance agents
start timepoints end timepoints 10 activities. activity constrained
occur within time interval [0,600] relative global zero reference timepoint, z.
activitys duration constrained lower bound, lb, chosen uniformly interval
[0,60] upper bound chosen uniformly interval [lb, lb + 60]. addition
constraints, generator adds 50 additional local constraints agent X
total external constraints. additional constraints, eij , bound
chosen uniformly interval [wij (wij + wji ), wij ], vi vj chosen,
replacement, set timepoints uniform probability, [0, 1]
tightness parameter dictates maximum portion interval tightened,
whose default value set = 1 experiments. particular problem
generator provides us upside directly systematically controlling number
external constraints relative number (and size/complexity of) agent subproblems.
Factory Scheduling Problem Benchmark. second source problems
multiagent factory scheduling domain (Boerkoel, Planken, Wilcox, & Shah, 2013).
randomly generated MaSTPs simulate agents working together complete tasks
construction large structural workpiece manufacturing environment, using realistic task duration, wait, deadline constraint settings. publicly available benchmark (Boerkoel et al., 2013) distinguishes structural constraintsthe existence
provide underlying structure temporal network (e.g., task durations minimum maximum durations must complete
makespan), refinement constraintsthose instantiate constraints bounds
particular weights (e.g., task-specific deadline duration constraints). former encode
general task structure knowledge, later encode particular domain knowledge
factory manager refine space schedules feasible schedules remain.
experiments, process constraints equally, whether structural constraint refined particular bound not. evaluate approaches problem data
available: number agents increases (A {2, 4, 8, 12, 16, 20}, = 20A) also
total number tasks increases (A = 16, {80, 160, 240, 320, 400, 480, 560}). Unlike
Random Problem Generator, set problems distinctive underlying
problem size (inter)constrainedness agent problem dictated real-world
factory needs, rather generated uniformly distributed across agents.
Experimental Procedure. capture expected trends particular problem source
(Random Factory Scheduling) parameter setting, evaluate average performance algorithm 50 independently-generated trials. include error bars representing one standard deviation results. Note, many cases, error bars
appear smaller tick marks used represent data points. algorithms
programmed Java, 3 GHz processor using 4 GB RAM. purposes
125

fiBoerkoel & Durfee

modeling concurrent, multiagent system, interrupted agent given
opportunity perform single edge update evaluation also single communication
(sending receiving one message), systematically sharing processor agents
involved. approaches use minimum fill heuristic (Kjaerulff, 1990). applied
approaches connected networks agents, although intuitively, performance
algorithms would enhanced applying disparate agent networks independently. Finally, problem instances generated lead consistent STP instances
evaluate full application algorithm. necessary algorithms,
excluding inconsistent STP instances avoids overestimating reductions execution times
algorithm halts soon inconsistency found. Moreover, unlike previous
approaches, algorithms require input STPs triangulated (Xu & Choueiry,
2003; Planken et al., 2008).
Evaluation Metrics. solving traditional CSP, one primary measures
unit computation constraint check. Meisels Zivan (2007) extend metric
distributed setting introducing non-concurrent constraint check (nccc). Note
agents solving distributed problem form partial order constraint checks based
fact (i) two constraint checks performed within agent must performed
sequentially (ii) constraint check xi performed agent prior sending message
mij ordered constraint check xj performed agent j receipt
mij . nccc metric, then, simply length longest critical path partial
ordering constraint checks. generalized nccc metric work counting
number non-concurrent edge updates: number cycles takes establish PPC
MaSTP, agent given opportunity update check bounds
single edge cycle computation, although agents may spend cycle idly
blocking updates agents.
report non-concurrent edge updates rather simulated algorithm runtime
due limitations simulating distributed system. First, heterogeneity agent
capabilities underlying sources message latency vary dramatically across different
real distributed computing systems. systematic, compelling way estimate
runtime distributed systems assumption-free, unbiased manner, instead
provide implementation- system-independent evaluation. Second, separately
maintaining state many agents simulated distributed system introduces large
amount overhead due practical issues memory swapping, unduly inhibits
accurate fair algorithm runtime comparisons. Since D4PPC requires significant
number messages (which would typically incur latency), separately count number
computation cycles least one agent sends message, described later,
allows rudimentary runtime projections latency. report total number
messages sent D4PPC later Section 5.3.1, compare distributed
temporal decoupling algorithm.
4.3.2 Empirical Comparison
One main benefits associate performing computation
distributed fashion promotes greater concurrency. section, explore
well distributed algorithms exploit concurrent computation, reporting number
126

fiDistributed Reasoning Multiagent Simple Temporal Problems

non-concurrent edge updates along number computational cycles require
messages. compare following approaches:
FW Floyd-Warshall algorithm executed centralized version problem;
4PPC 4PPC algorithm executed single agent centralized version
problem;
D4PPC w/ Latency D4PPC algorithm assume every computational cycle might incur message latency requires an-order-of-magnitude
time performing single edge update;
D4PPC w/o Latencyour D4PPC algorithm extra message latency
penalties.
Random Problems. Figure 10a compares algorithms performance problems
Random Problem generator, level coupling, measured number
external constraints increases. one would expect, density overall network increases, 4PPC approaches costs fully-connected FW algorithm.
Without latency, D4PPC algorithm, expectation, maintains steady improvement
centralized counterpart, ranging 12 times speedup (centralized computation/distributed computation) X = 100 nearly 23 times speedup X = 3200,
within 12% perfect speedup 25 agents.
Interestingly, even external constraints (X = 0), D4PPC algorithm achieves 18-fold, rather 25-fold, improvement 4PPC. due
heterogeneity complexity individual agent problems.
external constraints, opportunities agents easy-to-solve
local problems help agents out, thus effectively load-balance. number
external constraints increases, overall time complexity 4PPC
D4PPC w/o Latency approaches; however, opportunities load-balancing synchronization points also increase. results indicate increased opportunities
load-balancing outweigh costs increased synchronization number external
constraints increases.
Coordination does, however, introduce overhead. D4PPC w/ Latency curve
Figure 10a, try account message latency penalizing D4PPC extra
computational cost equivalent 10 edge updates every message cycle. practice,
represents rough estimate costs communication, since (i) messages
sent require agent block (i.e., many messages received prior need)
(ii) message latency could lead compounding delays elsewhere network. Even
penalty message latency, distributed approach maintains advantage
centralized approach, albeit much smaller one (e.g., 20% improvement
X = 100). number external constraints increases, however, effects
additional latency penalty become mitigated since (i) network becomes dense,
new external constraint increasingly less likely spur new messages (i.e., edge
would already created communicated), (ii) extra message latency
costs amortized across greater number agents.
127

fiBoerkoel & Durfee

1e+009
Nonconcurrent Edge Updates

Nonconcurrent Edge Updates

1e+009
1e+008
1e+007
1e+006
100000
FW
PPC
DPPC w/ Latency
DPPC w/o Latency

10000
1000
50

100

200

400

800

FW
PPC
DPPC w/ Latency
DPPC w/o Latency

1e+008
1e+007
1e+006
100000
10000
1000

1600

3200

1

Number External Constraints (X)

2

4

8

16

32

Number Agents (A)

(a) Non-concurrent edge updates number
external constraints X increases.

(b) Non-concurrent edge updates number
agents increases.

Figure 10: Empirical comparison D4PPC randomly generated problem set.
Figure 10b shows number non-concurrent edge updates number agents
grows. number non-concurrent edge updates grows linearly number
agents across approaches. Interestingly, estimate effects message
latency, cross-over point 4PPC D4PPC w/ Latency. certain level
message latency mean that, small number agents, faster centralize
computation using 4PPC utilize parallelism slow communication,
number agents grows, centralized problem becomes unwieldy distribution
computation makes D4PPC w/ Latency superior again. Figure 10b also shows
expected runtime D4PPC increases slowly FW 4PPC,
D4PPCs speedup increases number agents seen widening relative gap
4PPC D4PPC curves. Thus, D4PPC scales increasing number
agents better 4PPC.
Factory Scheduling Problems. high level, Figure 11 Factory Scheduling
Problems shows many trends saw Figure 10. are, however,
notable differences. First, plot using log scale, like Figure 10, since (i)
parameters grow linear scale, (ii) leave much expensive FW
approach better compare similar approaches. Second, number
tasks constraints across agents subproblems uniform, like Random
Problem case, leading constraint networks based underlying structure
realistic problems. number tasks agents increase, D4PPC clearly
scales better centralized counter-part, demonstrating robustness heterogeneity
across agent problems. number tasks low (T = 80), D4PPC exhibits 8.5
times speedup 4PPC steadily grows 12.3 fold speedup number tasks
grows (recall problems distributed across 16 agents). Similarly, relative gap
D4PPC 4PPC grows linearly number agents, settling within 30% perfect
speedup. Finally, set experiments clearly demonstrates costs high
message latency overcome number complexity agents local problems
grows sufficiently high.
128

fiDistributed Reasoning Multiagent Simple Temporal Problems

8000

PPC
DPPC w/ Latency
DPPC w/o Latency

10000

Nonconcurrent Edge Updates

Nonconcurrent Edge Updates

12000

8000
6000
4000
2000
0

PPC
DPPC w/ Latency
DPPC w/o Latency

7000
6000
5000
4000
3000
2000
1000
0

80

160

240

320

400

480

560

2

Number Tasks (T)

4

6

8

10

12

14

16

18

20

Number Agents (A)

(a) Non-concurrent edge updates number
tasks increases.

(b) Non-concurrent edge updates number
agents increases.

Figure 11: Empirical comparison D4PPC factory scheduling problem set.

Total Effort. minimum-fill variable ordering heuristic myopically selects timepoint, set timepoints, whose elimination expects lead fewest added
fill edges. Since centralized algorithm, 4PPC, places restrictions heuristic,
expect heuristic perform well, adding fill edges. D4PPC, hand,
restricts private timepoints eliminated prior shared timepoints, restricts
agent eliminating timepoints. Intuitively, expect additional restrictions hurt heuristic performance, is, lead triangulations
fill edges. increase overall number fill edges, turn, increases number
edges, thus overall number edge updates required update network. evaluate
efficiently effort distributed across agents, compare 4PPC D4PPC
total number fill edges added total number edge updates (summed across
agents). compute ratio D4PPC versus 4PPC effort using metrics
across two parameters directly impact constraint density: number external
constraints X randomly generated problems, number tasks
factory scheduling problems. Results displayed Figure 12.
Overall, algorithms, total number fill edges edge updates increases
X increases. Figure 12a displays relative 4PPC, number fill edges
edge updates computed D4PPC increases faster rate low X values,
slower rate higher X values, leading 57% increase total edge updates 11%
increase total fill edges peak. multiple trends occurring here. Early
(X = 0 . . . 200), heterogeneity individual agents private subproblems dictates
elimination shared timepoints done agent gets first,
necessarily correlated least-connected shared timepoint. number external
constraints increases, however, agents ability load balance elimination shared
timepoints improveswhen agents spending time competing shared
elimination order lock, one least amount (shared) computation (which
correlated fewest added shared fill edges) get it. improved load-balancing
also accentuated fact X increases, shared network density,
129

fiBoerkoel & Durfee

3

Edge Updates
Fill Edges

1.6

Ratio Effort: DPPC vs. PPC

Ratio Effort: DPPC vs. PPC

1.7

1.5
1.4
1.3
1.2
1.1
1

Edge Updates
Fill Edges

2.8
2.6
2.4
2.2
2
1.8
1.6
1.4
1.2
1

50

100

200

400

800

1600

3200

80

Number External Constraints (X)

160

240

320

400

480

560

Number Tasks (T)

(a) Relative (to centralized) number added fill
edges number external constraints X increases randomly generated problem set.

(b) Relative (to centralized) number added fill
edges number tasks increases
factory scheduling set.

Figure 12: Empirical comparison D4PPC terms total effort.

increasing number fill edges must inevitably added approaches,
thus dampening relative advantage 4PPC D4PPC.
results displayed Figure 12a show trends density external constraints
increases random problems. Figure 12b, hand, shows
overall number constraints increased generally, relative total effort monotonically decreases factory scheduling problems. validates previous study
showed eliminating private timepoints shared timepoints actually improves
performance variable elimination heuristics taking advantage structural knowledge avoid increasing connectedness agents problems (Boerkoel & Durfee,
2009). Thus, complexity local problems grows relative complexity
shared problem, case well-structured, loosely coupled factory scheduling problems, distributed application variable ordering heuristic (as D4PPC)
improves performance centralized application (as 4PPC). Interestingly,
factory scheduling problem set, variability number shared timepoints per agent
initially causes relative margin extra fill edges much larger randomly
generated problems, settling sufficient number tasks added.
4.3.3 Summary
section, presented D4PPC algorithm, distributed version P3 C algorithm, exchanges local constraint summaries agents establish minimal,
partially path consistent MaSTNs. D4PPC algorithm utilizes D4DPC algorithm
agent independently eliminates private timepoint variables coordinating eliminate shared variables, effect exactly summarizing impact
subproblem agents problems. remainder D4PPC algorithm
essentially reverse sweep D4DPC algorithm, care taken ensure
agent synchronizes edge weights agents prior updating
local edges. prove algorithm correctly calculates joint solution space
130

fiDistributed Reasoning Multiagent Simple Temporal Problems

MaSTP without unnecessarily revealing private variables. D4PPC
worst-case complexity centralized counterpart, show empirically exploits
concurrency outperform centralized approaches practice. scales much slowly
number agents centralized approaches achieves within 12% perfect
speedup relative size complexity agents local problems grow problems
studied.

5. Distributed Algorithm Calculating Temporal Decouplings
D4PPC algorithm outputs space possible joint solutions MaSTP,
depicted Phase 4 Figure 7. However, discussed Section 1, potential limitation
approach dependencies agents problems maintained. agents
must coordinate decisions using full representation avoid giving inconsistent advice,
Anns agent advises Ann start recreation 8:00 Bills agent advises
wait 9:00. Thus, advice one agent could potentially lead
update (e.g., Anns decision start recreation 8:00) would need propagated
agent offers advice guaranteed consistent. presents
challenge updates frequent communication expensive (e.g., slow), uncertain
(e.g., intermittent), otherwise problematic. Agents must coordinate re-establish partial
path consistency either re-executing D4PPC algorithm employing recent
incremental versions algorithm recognize updates might propagate
small portion MaSTN (Boerkoel et al., 2013). temporal decoupling,
hand, gives agent ability reason users local schedule
completely independent manner. allows agents give unilateral, responsive,
sound, though generally incomplete, advice.
goal Multiagent Temporal Decoupling (MaTD) algorithm find set
decoupling constraints C render MaSTPs external constraints CX moot,
thus agents subproblems independent (see Section 3.2). goal achieved
assigning values variables reverse sweep (as Figure 1b),
sacrifices flexibility provided maintaining solution spaces.
insight assigning private timepoints matter independence,
assign shared variables, tighten private variables response
assignments (Section 5.1). show that, many cases, assignments shared variables
relaxed increase flexibility (Section 5.2). Overall, algorithms compute
temporal decoupling making heuristic choices reduce flexibility sacrificed. Later
Section 5.3, describe ways measuring flexibility, empirically evaluate different
algorithmic choices affect flexibility well runtime.
shown Figure 13, Phases 1 2 algorithm, establish DPC
MaSTP, D4PPC algorithm (shown Figure 7). new Phase
3, however, agents establish temporal decoupling assigning shared timepoints
reverse order agents eliminated Phase 2. Next, optional Phase 4,
agents revisit shared timepoint original elimination order relax decoupling
constraints maximum extent possible, resulting minimal decoupling. Phase 5,
agent independently establishes PPC local problem,
last phase D4PPC algorithm.
131

fiBoerkoel & Durfee

9: 30,10: 00

90,120







Ann

8: 00,11: 00

8: 00,12: 00

60,60




8: 00,12: 00













Bill

8: 00,12: 00

60,60




[60,


120,120

10: 00,10: 00



12: 00,12: 00




90,120

8: 00,12: 00

8: 00,10: 30




60,180

8: 00,12: 00

8: 00,12: 00

Phase 2: Eliminate Shared Timepoints

Eliminate



9: 30,10: 00

[0,

0,0
[60,




8: 00,11: 00

[60,







8: 00,9: 30

9: 30,10: 30

Phase 3: Reinstate Assign Shared Timepoints
Decouple



9: 45,9: 45

=
9: 45,9: 45

[60,




8: 45,8: 45



8: 45,8: 45







8: 45,8: 45



8: 45,8: 45

10: 08,10: 08



10: 08,10: 08

Relax



9: 30,10: 00

[60,




8: 45,8: 45




8: 45,8: 45
Phase 5: Reinstate Private Timepoints
=



Chris

9: 30,10: 00

8: 00,8: 30



90,120




8: 45,8: 45



Ann
60,60







10: 00,10: 30

8: 45,8: 45


10: 00




8: 45,8: 45

9: 45,9: 45

8: 45,8: 45













Bill

9: 45,9: 45

60,60




60,105


120,120

10: 00,10: 00



12: 00,12: 00




90,120

10: 00,10: 30

11: 30,12: 00

9: 45,11: 00

60,135




10: 45,12: 00

PPC (Algorithm 6)

Relaxation
(Algorithm 10)

Phase 4 (optional): Relax Shared Timepoint Domains

MaTD/MaTDR (Algorithm 9)

Chris

DDPC (Algorithm 7)

8: 00,12: 00

DPC (Algorithm 5)

Phase 1: Eliminate Private Timepoints

Figure 13: MaTD algorithm replaces shared D4PPC phase D4PPC algorithm (depicted Figure 7) decoupling phase assigns shared timepoints
reverse elimination order (Phase 3) optional Relaxation phase, timepoints
revisited flexibility recovered extent possible.

132

fiDistributed Reasoning Multiagent Simple Temporal Problems

5.1 Distributed Multiagent Temporal Decoupling Algorithm
MaTD algorithm, presented Algorithm 9, starts (lines 1-2) executing D4DPC
algorithm (Algorithm 7 page 119) triangulate propagate constraints, eliminating shared timepoints VS last. D4DPC propagates inconsistent graph,
algorithm returns inconsistent; else, illustrated first two phases Figure 13,
resulting MaSTN captures implications agents private constraints reflected
tighter domains shared timepoints. Next, MaTD initializes empty C (line 3)
steps vertices reverse elimination order. example, means
B (line 4). However, agent reinstates interface timepoint, simstarting RST
ply assigns rather updating incident edges case reverse sweep
D4PPC algorithm. Typically, assigning reinstated timepoint, domain must
updated respect previously assigned shared timepoints. However,
B first reinstated variable, MaTD skips inner loop (lines 7-11)
RST
vertices later oS .
B guaranteed minimal, meaning agent B
point, domain RST
assign remaining value still guaranteed globally consistent.
choice value assign made line 12 function HeuristicAssign.
default, HeuristicAssign assigns timepoint midpoint bounds interval split remaining flexibility middle; later discuss alternative assignment
heuristics. Notice D4DPC algorithm first executed, agent B would
B midpoint original domain 8:00-12:00 rather updated doassign RST
main 8:00-9:30, would result inconsistent assignment (to 10:00). However,
B happens 8:45 C (line 14). line 13,
MaTD instead adds constraint RST

B shares external edges Anns timepoints.
sent agent A, RST
. Note, agent would consider processing variable right
next vertex RST
away, inner loop (lines 7-11) forces agent wait message agent B
(line 9). message arrives, agent updates edge weights accordingly (lines 10A least 60 minutes RB = 8:45, RA domain
11). case, given RST
ST
ST
tightened [9:45, 10:30]. line 12, agent chooses decoupling point
occurs
splitting difference, thus adding (and communicating) constraint RST
10:08. process repeated timepoints VS assigned.
resulting network decoupling constraints shown Phase 3 Figure 13.
avoid inconsistency due concurrency, calculating decoupling constraints
vk , agent blocks line 9 receives fresh, newly-computed weights wzj , wjz
j > k.
vj agent (Agent(vj ), sent line 13) external edge ejk EX
implies sequentialization, also allows concurrency whenever variables
share external edge. example, Phase 3 Figure 13, TP C
ET
share edge, agent assigned RA , agent agent C
RST
ST
TP C respectively.
concurrently independently update assign RST
ET
Finally, moment skipping optional Phase 4 Figure 13, agent establishes PPC response new decoupling constraints executing 4PPC private STN Phase 5. algorithm represents improvement previous approaches
(Hunsberger, 2002; Planken, de Weerdt, & Witteveen, 2010a) it: (i) distributed,
rather centralized; (ii) executes sparser, efficient network representation;
133

fiBoerkoel & Durfee

Algorithm 9: Multiagent Temporal Decoupling (MaTD) optional Relaxation
(MaTDR)
Input: G , agent known portion distance graph corresponding MaSTP
instance M, field indicating whether RELAX decoupling
, agent decoupling constraints, G , agent PPC distance graph
Output: C

w.r.t. C
1 G , oiL , oS = (v1 , v2 , . . . vn ) D4DPC (G )
2 return inconsistent D4DPC
=
3 C
4 k = n . . . 1 vk VIi
5
V V vk
DP C w , w DP C w
6
wzk
zk
kz
kz
7
j = n . . . k + 1 ejk E

8
ejk EX
9
wzj , wjz BlockReceiveUpdatedEdges(Agent(vj ))
10
11
12
13
14

wzk min(wzk , wzj + wjk )
wkz min(wkz , wkj + wjz )
wkz , wzk HeuristicAssign(vk , G)

SendUpdatedEdge(wzk , wkz , Agent(vj ) j < k, ejk EX


C C {(z vk [wzk , wkz ])}

16

RELAX
Relaxation (G , w DP C )
G , C

17



return 4PPC (GL+
, oiL ), C

15

(iii) eliminates assumption input graphs must consistent; (iv) performs
decoupling embedded procedure within existing D4PPC algorithm, rather
outer-loop.
mentioned, simple default HeuristicAssign assign vk midpoint
directional path consistent domain (which corresponds using rules wzk
wzk 21 (wzk + wkz ); wkz wzk ). Section 5.3.2, explore evaluate alternative
HeuristicAssign function. general, however, narrowing variable assignments single
values constraining necessary. Fortunately, agents optionally call relaxation algorithm (introduced Section 5.2 shown Figure 13 Phase 4) replaces
C set minimal decoupling constraints.

Theorem 8. MaTD algorithm overall time complexity (nP + nS ) o2 ,
nP = maxi |VPi | nS = |VS |, requires (mX ) messages, mX = |EX |.

Proof. MaTD algorithm calculates DPC PPC (nP + nS ) o2 time. Unary,
decoupling constraints calculated nS external variables, vk VS (lines 414), iterating vk (o ) neighbors (lines 7-11). Thus decoupling requires (nS ) nS o2 time, MaTD overall time complexity
(nP + nS ) o2 . MaTD algorithm sends exactly one message external
constraint line 13, total (mX ) messages.
134

fiDistributed Reasoning Multiagent Simple Temporal Problems

Theorem 9. MaTD algorithm sound.
Proof. Lines 1-2 return inconsistent whenever input MaSTP consistent.
contradiction, assume exists external constraint cxy bound bxy
satisfied decoupling constraints cxz czy , calculated MaTD,
bounds b0xz b0zy respectively, are. case, b0xz + b0zy > bxy . WLOG, let x <
elimination order oS .
Note, time vx visited (in line 4), following true:
wxy bxy ;

(1)

wzy + wyz = 0;

(2)

b0zy = wzy .

(3)

(1) true since line 1 computes DPC using oS ; (2) true since line 12
already executed vy , (3) true construction czy line 14.
update wxz occurs line 11, and, since exy external, one updates
0 = min(w , w
wxz
xz
xy + wyz ), thus
0
wxz
wxy + wyz .

(4)

Combining (1), (2), (4), yields fact:
0
wxz
+ wzy wxy bxy .

(5)

0 may updated future iterations line 11 possibly
time wxz
00 , lines 11 12 tighten (never relax). Thus,
line 12 produce wxz
(5) implies
00
0
wxz
+ wzy wxz
+ wzy wxy bxy .

(6)

00 ; fact, along (3) (6), implies
line 14, cxz constructed bxz = wxz
bxz + bzy bxy . However, contradiction assumption b0xz + b0zy > bxy ,
constraints C calculated MaTD form temporal decoupling M.

Theorem 10. MaTD algorithm complete.
Proof (Sketch). basic intuition proof provided fact MaTD
algorithm simply general, distributed version basic backtrack-free assignment procedure consistently applied DPC distance graph. show
choose bounds new, unary decoupling constraints vk (effectively line 12),
wzk , wkz path consistent respect variables.
distance graph DPC, also updates lines 10-11 guarantee wzk , wkz
path consistent respect vk j > k (since path vj vk
represented edge ejk distance graph). proactive edge tightening
occurs, happens line 13 guarantees wzk + wkz = 0, done pathconsistent edges thus never introduce negative cycle (or empty domain).
MaSTP consistent, MaTD algorithm guaranteed find temporal decoupling.
135

fiBoerkoel & Durfee

5.2 Minimal Temporal Decoupling Relaxation Algorithm
One key properties minimal MaSTP represent space consistent
joint schedules, turn used hedge scheduling dynamism.
larger space solutions is, flexibility agents to, e.g., add new constraints,
mitigating risk invalidating solution schedules. Flexibility , then,
measure completeness solution space. Flexibility good increases
agents collective abilities autonomously react disturbances new constraints,
time, flexibility joint solution space limits individual agent
unilaterally independently exploiting autonomy. MaTD algorithm explicitly
trades away flexibility increased independence assignment process line 12.
section, describe algorithm attempts recover much flexibility
possible maximize agents ability autonomously, yet independently, react dynamic
scheduling changes.
goal Multiagent Temporal Decoupling Relaxation (MaTDR),
version MaTD executes Relaxation algorithm (Algorithm 10)
subprocedure, replace set decoupling constraints produced MaTD
0
algorithm, C , set minimal decoupling constraints, C . Recall page 111

minimal decoupling one where, bound decoupling constraint c C
1
2
n
agent relaxed, {SL+ , SL+ , . . . , SL+ } longer guaranteed form
decoupling. Clearly temporal decoupling produced running MaTD using
default heuristic example problem, shown Phase 3 Figure 13, minimal
decoupling bounds TP C
ET could relaxed include entire original domain
. basic idea Relaxation algorithm revisit
still decoupled RST
external timepoint vk and, holding domains external timepoint
variables constant, relax bounds vk decoupling constraints much possible.
describe execution algorithm describing execution trace
running example problem. depicted Phase 4 Figure 13, Relaxation works origC
inal oS order, thus starts TP C
ET . First, Chris agent removes TP ET decoupling
constraints restores TP C
ET domain [9:30,10:00] updating corresponding edge
weights stored DPC values (line 3). Notice lines 2-19 similar reverse
sweep D4PPC algorithm, except separate, shadow bound representation used updated respect original external constraint bounds (not
tightened edge weights) ensure later-constructed decoupling constraints minimally constraining. Also, lines 13-18, decoupling constraint constructed
bound potential, new constraint (e.g., kz ) tighter already implied edge
weight (e.g., kz < wkz ). example, constraint involving TP C
ET


occur RST . Therefore RST currently set occur 10:08
(=10:08) TP C
occur 10:00 (w =10:00), 6< w,
ET already constrained
0
decoupling constraints added set C TP C
ET (allowing retain original
domain [9:30,10:00]).
, whose domain relaxes back [8:00,9:30]. However,
next variable consider RST

B , whose current domain [8:45,8:45],
since RST shares synchronization constraint RST
[8:45,8:45].
Anns agent end re-adopting original decoupling constraint RST

Next, agent recovers RST original DPC domain [9:30,10:30] tightens ensure

136

fiDistributed Reasoning Multiagent Simple Temporal Problems

Algorithm 10: Relaxation
DP C , w DP C , v V
Input: G , DPC weights, wzk
k
X
kz
0i
Output: C , agent minimal decoupling constraints, G , agent PPC distance
0
graph w.r.t. Ci
0i
1 C
2 k = 1 . . . n vk VIi
DP C , w
DP C
3
wzk wzk
kz wkz
4
zk kz
5
j = 1 n ejk E

6
ejk EX
7
j < k wzj , wjz BlockReceiveUpdatedEdges(Agent(vj ))
8
cjk exists zk min(zk , bjk wjz )
9
ckj exists kz min(kz , bkj wzj )
10
11
12
13
14
15

else j < k
wzk min(wzk , wzj + wjk )
wkz min(wkz , wkj + wjz )
kz < wkz
wkz kz
0
0
Ci Ci {(z vk kz )}

18

zk < wzk
wzk zk
0
0
Ci Ci {(vk z zk )}

19


SendUpdatedEdge(wzk , wkz , Agent(vj ) j > k, ejk EX

16
17

0

20

return G , Ci

C
follows TP C
ET new domain [9:30,10:00]. case, decoupling TP ET
requires new lower bound 10:00 results flexible domain [10:00,10:30]
. minimal decoupling constraints corresponding temporal network
RST
Relaxation calculates running example presented Phase 4 Figure 13
shared portion network. Similarly, Phase 5 shows implications incorporating
decoupling constraints agents PPC subproblem.

Relaxation algorithm applies two different kinds updates. edge ejk
considered line 6 local agent i, Relaxation algorithm executes lines 11-12,
update actual edge weights wzk wkz manner D4PPC
algorithm, guaranteeing values captured within bounds interval consistent
least value vj domain (so locally PPC).
hand, edge ejk external, Relaxation algorithm instead executes lines 8-9,
update shadow edge weights zk kz way guarantees consistent
values vj domain (so temporally decoupled). Note
updates restrictive, lead new decoupling constraints
tighter vk current domain.
137

fiBoerkoel & Durfee

Theorem 11. Relaxation algorithm overall time complexity (nS )
requires (mX ) messages.
Proof. Unary, decoupling constraints recalculated nS shared variables,
require visiting vk VS (o ) neighbors (lines 2-19), iterating
vk (o ) neighbors (lines 5-12). Thus Relaxation algorithm requires (nS )
time. Relaxation algorithm sends exactly one message external constraint
line 19, total (mX ) messages.
Notice Relaxation algorithm called subroutine MaTD algorithm,

runs less time, overall MaTDR algorithm runtime still (nP + nS ) o2 .
Theorem 12. local constraints calculated Relaxation algorithm form minimal temporal decoupling S.
0

Proof (Sketch). proof set C forms temporal decoupling roughly analogous
proof Theorem 5.1. contradiction, show bound bxz
0
0
decoupling constraint cxz C relaxed small, positive value xz > 0, C
longer temporal decoupling. lines 8-9 imply exists
either bxz = bxy bzy , thus bxz + xz + bzy > bxy (and thus longer
temporal decoupling), bzy = bxy (bxz + xz ) (and either decoupling
requires altering bzy order maintain temporal decoupling).
5.3 Evaluation
following subsections, reuse basic experimental setup Section 4.3
empirically evaluate performance MaTDR algorithms computational effort
Section 5.3.1, impact flexibility variations MaTDR algorithm Section 5.3.2. Like original D4DPC algorithms, decoupling algorithms performance
depends size agents private subproblem versus size shared subproblem. number external constraints relative number agents increases,
less reasoning occur independently, also resulting decoupled solution spaces
subject increasing number local constraints, thus diminish flexibility.
5.3.1 Evaluation Computational Effort
empirically compared:
MaTDR default MaTD algorithm Relaxation;
Centralized MaTDR single agent executes MaTDR centralized version
problem;
D4PPC execution D4PPC distributed algorithm establishing PPC
MaSTP (but decoupling);
TDPour implementation fastest variation (the RGB variation) (centralized) TDP algorithm reported Hunsberger (2002).
138

fiDistributed Reasoning Multiagent Simple Temporal Problems

implement original TDP approach, use Floyd-Warshall algorithm initially
establish FPC, incremental update described Planken (2008) maintain FPC
new constraints posted. evaluated approaches across two metrics. nonconcurrent edge update metric, which, described Section 4.3, number computational cycles edge updated agents simulated multiagent
environment completed executions algorithm. metric report
section total number messages exchanged agents.
Random Problems. evaluate algorithms randomly generated
factory scheduling problem sets described Section 4.3.1. results shown Figure 14
demonstrate MaTDR algorithm clearly dominates original TDP approach
terms execution time, even MaTDR algorithm executed centralized
fashion, demonstrating advantages exploiting structure using PPC (versus FPC)
dividing problem local shared subproblems. advantage
MaTDR original TDP approach incorporates decoupling procedure
within single execution constraint propagation rather introducing decoupling
constraints one time outer loop reestablishes FPC new decoupling
constraint added. Additionally, compared centralized version MaTDR
algorithm, distributed version speedup varies 19.4 24.7.
demonstrates structures generated problem instances support parallelism
distributed algorithm exploit structure achieve significant amounts
parallelism.
MaTDR algorithm also dominates D4PPC algorithm terms computation number messages. means MaTDR algorithm calculate temporal
decoupling less computational effort D4PPC algorithm establish PPC
MaSTP. MaTDR generally bound runtime complexity
D4PPC (due applying D4DPC algorithm), complexity actual
decoupling portion procedure less practice argued Theorem 8.
MaTDR algorithm calculates communicates new bounds unary reference edges,
renders external edges moot thus need reason them.
contrast, D4PPC algorithm must calculate, communicate, maintain new bounds
every shared edge. total number messages sent algorithms grows linearly number agents and, perhaps less intuitively, sublinearly number
external constraints. indicates that, network becomes saturated,
new external constraint increasingly likely expressed edge would
already require communication, thus requires new messages.
Factory Scheduling Problems. also evaluated algorithms using factory problem set, MaTDR exhibited similarly large speedups Centralized MaTDR
approach (ranging 4 5 orders magnitude depending number tasks).
excluded TDP approach charts Figure 15 zoom differences
(Centralized) MaTDR D4PPC algorithms, much subtle.
still achieving impressive speedups centralized counterpart, MaTDR algorithms
computational advantages D4PPC less pronounced (Figure 14) due
loosely-coupled nature factory problem set. Similarly, relative drop
139

fiBoerkoel & Durfee

1e+009
Nonconcurrent Edge Updates

Nonconcurrent Edge Updates

1e+009
1e+008
1e+007
1e+006
100000
TDP
Centralized MaTDR
DPPC
MaTDR

10000
1000
50

100

200

400

800

TDP
Centralized MaTDR
DPPC
MaTDR

1e+008
1e+007
1e+006
100000
10000
1000

1600

3200

1

2

4

Number External Constraints (X)

(a) Nonconcurrent computation number
external constraints X increases.

16

32

(b) Nonconcurrent computation number
agents increases.
1e+008

DPPC
MaTDR

DPPC
MaTDR

1e+007

1e+006
Number Messages

Total Number Messages

1e+007

8

Number Agents (A)

100000

10000

1000

1e+006
100000
10000
1000

100

100
50

100

200

400

800

1600

3200

2

Number External Constraints (X)

4

8

16

32

Number Agents (A)

(c) Number messages number external
constraints X increases.

(d) Number messages number agents
increases.

Figure 14: Empirical evaluation MaTDR randomly generated problem set.
external constraints leads, turn, fewer shared edges, thus fewer messages overall,
mitigating substantial gap Figures 14c 14d.
fact MaTDR algorithm dominates D4PPC algorithm implies that,
even original TDP algorithm adapted make use state-of-the-art D4PPC
algorithm, MaTDR algorithm would still outperform revised TDP approach terms
computational effort. Overall, confirmed could exploit structure
MaSTP instances calculate temporal decoupling efficiently before,
also distributed manner, avoiding (previously-required) centralization costs,
exploiting parallelism lead significant levels speedup. next ask whether
quality solution produced MaTDR algorithm competitive terms
solution space completeness.
5.3.2 Evaluation Completeness (Flexibility)
Hunsberger (2002) introduced two metrics, flexibility (F lex) conversely rigidity
(Rig), act relative measures number total solutions represented
140

fiDistributed Reasoning Multiagent Simple Temporal Problems

4500

Centralized MaTDR
DPPC
MaTDR

6000

Centralized MaTDR
DPPC
MaTDR

4000
Nonconcurrent Edge Updates

Nonconcurrent Edge Updates

7000

5000
4000
3000
2000
1000

3500
3000
2500
2000
1500
1000
500

0

0
80

160

240

320

400

480

560

2

4

Number Tasks (T)

(a) Nonconcurrent computation number
tasks increases.

12

16

20

(b) Nonconcurrent computation number
agents increases.
2000

DPPC
MaTDR

DPPC
1800 MaTDR

2500

1600
Number Messages

Total Number Messages

3000

8

Number Agents (A)

2000
1500
1000

1400
1200
1000
800
600
400

500

200
0

0
80

160

240

320

400

480

560

2

Number Tasks (T)

4

8

12

16

20

Number Agents (A)

(c) Number messages number tasks
increases.

(d) Number messages number agents
increases.

Figure 15: Empirical evaluation MaTDR factory scheduling problem set.
temporal network, allowing quality level completeness alternative temporal
decouplings compared. defined flexibility pair timepoints, vi
vj , sum F lex(vi , vj ) = wij + wji always non-negative consistent STPs.
1
rigidity pair timepoints defined Rig(vi , vj ) = 1+F lex(v
, rigidity
,vj )
entire STP root mean square (RMS) value rigidity values
pairs timepoints:

X
2
Rig(G) =
[Rig(vi , vj )]2 .
n (n + 1)
i<j

implies Rig(G) [0, 1], Rig(G) = 0 G constraints
Rig(G) = 1 G single solution (Hunsberger, 2002). Since Rig(G) requires FPC
calculate, work apply metric post-processing evaluation technique centralizing establishing FPC temporal decouplings returned
algorithms. exist centralized, polynomial time algorithm calculating
optimal temporal decoupling (Planken, de Weerdt, & Witteveen, 2010a), requires
141

fiBoerkoel & Durfee

evaluation metric linear function distance graph edge weights,
aggregate rigidity function, Rig(G), unfortunately, not.
MaTDR algorithms default HeuristicAssign function assigns timepoint
midpoint currently-calculated bounds. assumption assignment
midpoint (along relaxation) attempts divide slack evenly, practice subsequent
assignments influenced earlier ones. example, Figure 13, TR
ST assigned
B . Hence, perhaps
10:08AM, rather 10:00AM, due earlier assignment RST
smarter ways assign timepoints maintain greater amounts flexibility.
evaluate one alternative heuristic, locality heuristic, thought
application least-constraining value heuristic attempts less myopic
assignment procedure considering loss flexibility neighboring timepoints. Here,
agent assigns vk value reduces domains neighboring timepoints
least. described Hunsberger (2002), original TDP approach attempts maximize
flexibility progressively tightening reference bounds timepoints fraction
total amount would required decoupling.
Evaluation. set experiments, compare rigidity temporal decouplings calculated by:
Midpoint variant MaTD algorithm HeuristicAssign uses
(default) midpoint heuristic, without Relaxation;
Midpoint+R MaTD algorithm using midpoint heuristic along
Relaxation sub-routine;
Locality variant MaTD algorithm HeuristicAssign assigns vk
value reduces domains neighboring, local timepoints least (no
Relaxation);
Locality+R MaTD algorithm using locality heuristic along Relaxation sub-routine;
Input rigidity input MaSTN;
TDP implementation Hunsbergers RLF variation TDP algorithm
(where r = 0.5 = 1.0 lead computational multiplier approximately
9) reported calculate least rigid decoupling Hunsberger (2002)
(rather RGB variation used earlier, reported efficient).
first experiment, used Random Problem Generator parameter settings = 25 X = {50, 200, 800}. left-hand side Table 2 displays rigidity
temporal decoupling calculated approach problems. Unsurprisingly, number external constraints increases, level rigidity across
approaches, including inherent rigidity input MaSTN. Combing rigidity
results evaluation computational effort displayed Figure 14, look
trade-offs efficiency quality temporal decoupling approaches.
average, compared Midpoint, Midpoint+R approach decreases rigidity 51.0%
increasing computational effort 30.2%, Locality approach decreases rigidity
142

fiDistributed Reasoning Multiagent Simple Temporal Problems

Table 2: comparison much four different MaTD variants increase rigidity compared input MaSTN previous centralized approach (TDP) across randomly
generated factory scheduling problem sets.
Randomly Generated Problems

Factory Scheduling Problems

X = 50

X = 200

X = 800

= 80

= 320

= 560

Input

0.418

0.549

0.729

0.274

0.148

0.119

Locality+R

0.508

0.699

0.878

0.756

0.838

0.838

Midpoint+R

0.496

0.699

0.886

0.765

0.853

0.855

Locality

0.621

0.842

0.988

0.965

0.983

0.982

Midpoint

0.628

0.849

0.988

0.968

0.983

0.988

TDP

0.482

0.668

0.865

0.720

0.722

0.706

2.0% increasing computational effort 146%. Midpoint+R approach, significantly improves output decoupling least computational overhead. Locality
heuristic, hand, doubles computational overhead providing
significant improvement rigidity. also explored combining rigidity-decreasing
heuristics, increase computational effort tended additive (the Locality+R approach increases effort 172%), decrease rigidity not. fact,
heuristics tried led statistically significant decrease rigidity compared
original Midpoint+R approach cases investigated. Locality+R approach
came closest, decreasing rigidity 49.9% expectation.
second experiment, used Factory Scheduling Problem benchmark
parameter settings = 16 = {80, 320, 560} ensured problem set
tight makespan; results appear right-hand side Table 2. Interestingly,
number tasks increases, level rigidity input MaSTN decreases,
rigidity calculated decouplings plateaus. adding tasks
directly correlate adding interdependencies: tasks happen naturally
dependent one another assigned different agents level coupling affected.
setting tight makespan set tasks effect making critical path
workflow rigid, leaves many workflow paths flexible. However, decoupling
effectively introduces many additional interim makespan deadlines, lead many
rigid paths workflow. Overall, increased structure problems led
starker differences approaches. Computing temporal decoupling results 3fold increase rigidity input MaSTP regardless decoupling approached
used. again, including relaxation phase decreased rigidity, additional 20.2%
margin using Midpoint heuristic 21.5% margin using Locality
heuristic. differences flexibility outputs Midpoint(+R)
computationally expensive Locality(+R) approaches insignificant.
far conclusive evidence variable assignment heuristics
would outperform either default midpoint locality heuristics. does, however,
point robustness MaTDR algorithm recovering flexible decouplings.
143

fiBoerkoel & Durfee

significant difference Locality Midpoint heuristics,
Locality+R Minimality+R approaches, addition relaxation led significant
improvement cases. fact MaTDR algorithm alone increases rigidity
less strategy attributed structure MaSTP
rigidity measured. MaTDR algorithm improves distribution flexibility
shared timepoints reactively, instead proactively trying guess good values.
MaTD algorithm tightens bounds, general triangulated graph structure formed
elimination order branches impact tightening. instance, timepoint
assigned, defers flexibility possibly many neighboring timepoints,
Relaxation algorithm recovers flexibility neighboring timepoints
recovering flexibility originally assigned timepoint.
Notice Table 2 original TDP approach increases rigidity least,
averaging 20.6% less rigidity Midpoint+R approach randomly generated
problem set 15.9% factory scheduling problems. However, lower rigidity
comes significant computational costthe original TDP approach incurs, expectation, 10,000 times computational effort Midpoint+R approach. Further,
original TDP approach access edge information involving pair timepoints
entire, centralized MaSTN, clobbering privacy, MaTDR makes heuristic decoupling decisions much limited information, maintaining greater levels
agent privacy. scheduling environments costs centralization (e.g., privacy) alone would discourage using original TDP approach, others computational
effort may prohibitive constraints arise faster centralized TDP algorithm
calculate temporal decoupling. Further, differences rigidity decoupling approaches may become mitigated scheduling problems many external constraints
enforce synchronization (e.g., Anns Bills recreational start time). synchronization requires fully assigning timepoints order decouple, may flexibility
recover, makes efficient, assignment-based MaTD algorithm better choice.
5.3.3 Summary
MaTDR algorithm combines reasoning D4PPC algorithm decoupling
procedure first assigns, relaxes, shared timepoints way leads minimal
decoupling MaSTP. showed algorithm complexity
original D4PPC algorithm, reduces solve time expectation. Overall,
space problems investigated, Midpoint+R approach, expectation, outputs
high-quality temporal decoupling approaches quality (within 20.6% random
problems 15.9% factory scheduling problems) state-of-the-art centralized
approach (Hunsberger, 2002), distributed, privacy-maintaining manner multiple
orders-of-magnitude faster previous centralized approach.

6. Related Work
section, summarize related approaches highlight applications could
benefit using MaSTP formulation algorithms.
144

fiDistributed Reasoning Multiagent Simple Temporal Problems

6.1 Simple Temporal Problem Uncertainty
Simple Temporal Problem Uncertainty (STPU) (Vidal & Ghallab, 1996; Vidal
& Fargier, 1999) partitions set constraints STP set requirement links
set contingent links. Requirement contingent temporal difference
constraints, defined Section 2.1. difference requirement link
assigned agent whereas contingent link exogenously assigned outside control
agent value ij [bji , bij ]. STPU checked consistency,
also various classes controllability , including strong, weak, dynamic variants
(Vidal, 2000; Morris, Muscettola, & Vidal, 2001; Morris & Muscettola, 2005; Lau, Li, &
Yap, 2006; Hunsberger, 2009). Whereas consistent STP one exist schedules
satisfy constraints, controllable STPU one exist satisfying schedules
regardless contingent links assigned. Typical strategies establishing
maintaining controllability include preemptively constraining requirement timepoints
remaining values consistent possible contingencies. work
explicitly differentiate constraints exogenously updated
cannot. instead use space solutions hedge dynamic constraints.
However, nice parallel STPU literature, MaTD algorithm viewed
negotiation agents preemptively add new decoupling constraints control
uncertainty contingencies introduced interactions agents.
6.2 Applications Multiagent Scheduling
Temporal constraint networks represent spaces feasible schedules compact intervals
time calculated efficiently. reason, temporal network naturally lends
online plan monitoring dispatchable executionan online approach whereby
dispatcher uses flexible times representation efficiently adapt scheduling upheavals
introducing new constraints. plan monitor flag current schedule
become infeasible, dispatcher notify agents time assigns variables
immediately prior execution (Muscettola, Morris, & Tsamardinos, 1998). Another contribution work show advantages extend distributed, multiagent
temporal constraint networks, also introducing level independence agents
exploit many ways. Properties temporal networks minimality decomposability proven essential representing solution space many centralized
applications project scheduling (Cesta, Oddi, & Smith, 2002), medical informatics
(Anselma, Terenziani, Montani, & Bottrighi, 2006), air traffic control (Buzing & Witteveen,
2004), spacecraft control (Fukunaga, Rabideau, Chien, & Yan, 1997). Unfortunately,
multiagent scheduling applications (Laborie & Ghallab, 1995; Bresina et al., 2005; Castillo
et al., 2006; Smith et al., 2007; Barbulescu et al., 2010) wishing exploit properties
previously relied either centralized temporal network representation or, independence also needed, completely disjoint, separate agent networks. highlight
specific example applications may benefit work described paper.
approach originally described Smith et al. (2007) extended Barbulescu
et al. (2010) exploits flexibility STNs distributed framework. general framework problems solve contains models uncertainty durations
utilities different activities. Using greedy heuristic, scheduler selects set
145

fiBoerkoel & Durfee

activities would maximize agent utility, extracts duration bounds distribution possible durations activity, thus creating STP local agent.
agent captures current state local problem form STN representation local solution space, agent uses help hedge uncertainty.
agent maintains current state problem new constraints arise using efficient,
incremental STN consistency algorithms (e.g., Cesta & Oddi, 1996; Planken, de Weerdt, &
Yorke-Smith, 2010b). agent maintains local STN problem representation
improved replacement STN identified scheduler mechanism. efficient statemaintenance strategy frees agents spend greater portion time exploring alternative
allocations schedulings activities agents. Barbulescu et al.s approach divides
problem separate, localized STP instances, requiring distributed state manager
react communicate local scheduling changes may affect agents.
deal challenge coordination, Barbulescu et al. establish acceptable time, ,
within interdependent activities agents considered synchronized. long
agent execute activities within prescribed s, assume consistency
agents. risk inconsistencies agents mitigated (i) restricting
synchronization scheduling limited time horizon (ii) allowing agents abandon
synchronization soon determined unrealizable.
Shah Williams (2008), Shah, Conrad, Williams (2009) Conrad Williams
(2011) generalize idea multiagent, disjunctive scheduling problems calculating dispatchable representations. Shah Williams (2008) recognize many disjunctive scheduling possibilities contain significant redundancy, gain representational
efficiency reusing redundant portions existing solution representations much
possible. algorithm propagates disjunct using recursive, incremental constraint
compilation technique called dynamic back propagation, keeping list implications
disjunct temporal network. centralized compilation leads
much compact representation previous approach (Tsamardinos, Pollack, &
Ganchev, 2001), also faster plan monitoring avoiding need simultaneously
separately update disparate STP.
domains offer examples work could benefit putting approach
practice. Representing joint solution space multiagent temporal network could
instead offer agent complete view available scheduling possibilities well
increased understanding problem impacts (or impacted by) agents
problems. Further, directly representing reasoning interacting scheduling problem multiple agents also eliminates need agents execute separate threads
execution monitor communicate state changes. Finally, directly implementing
multiagent temporal network allows agents flexibly directly strike trade-off
representing complete joint solution space internalizing decoupling constraints just-in-time manner (e.g., using time-horizon concept Barbulescu et al.,
2010), rather rely additional mechanisms manage coordinate state.
6.3 Distributed Finite-Domain Constraint Reasoning
Distributed Constraint Satisfaction Problem (DCSP) distributed constraint-based
problem formulation variables discrete, finite domain, rather temporal,
146

fiDistributed Reasoning Multiagent Simple Temporal Problems

continuous domain. Two seminal algorithms solving DCSP Asynchronous
Backtracking (ABT) Asynchronous Weak-Commitment (AWC) search algorithms
(Yokoo, Durfee, Ishida, & Kuwabara, 1998). ABT, AWC, variants algorithms
based asynchronous variable assignment, use message passing no-goods resolve
conflicts. Armstrong Durfee (1997), Hirayama, Yokoo, Sycara (2004), Silaghi
Faltings (2005) provide variants algorithms perform intelligent prioritization agents, order local agent variables dynamically, aggregate exchanges
information agents complex local problems. However, approaches based assignment no-good learning may less applicable continuous-domain, constraint-based
scheduling problems, typical strategies focus maintaining consistent sets solutions using inference. Mailler Lessers Asynchronous Partial Overlay (APO) algorithm
(Mailler & Lesser, 2006) deals inconsistencies agents mediation,
time centralizes view problem, thus may conflict privacy goals
work. Asynchronous Forward Checking (AFC), proposed evaluated Meisels
Zivan (2007), provides mechanisms asynchronously increasing consistency across agents;
however pay-off algorithmavoiding expensive backtracking operationsis
challenge faced MaSTP algorithms.
Distributed Constraint Optimization Problem (DCOP) generalization
DCSP general utility cost functions (soft constraints) assign utility
cost every possible combination assignments particular subset variables, replacing set hard constraints. DCSP translated DCOP converting
constraints cost functions infinite cost inconsistent assignments. before,
utility function known least one agent, DCOP solved finding
assignment values variables maximizes total utility (or minimizes total cost).
ADOPT (Modi, Shen, Tambe, & Yokoo, 2005) BnB-ADOPT (Yeoh, Felner, & Koenig,
2010) decentralized, complete search algorithms solving DCOP using bestfirst branch-and-bound depth-first principles respectively. OptAPO algorithm
optimization variant APO algorithm Mailler Lesser (2004). ADOPT
OptAPO generalizations AWC APO respectively, though case, instead
terminating first feasible assignment values variables, agents must exhaust
entire search space guarantee assignment return optimal one.
DPOP algorithm (Petcu & Faltings, 2005), also distributed implementation
general bucket-elimination algorithm solving DCOPs, probably
similar approach. DPOP requires linear number messages solve
DCOP, suffers exponentially (in induced width constraint graph) large
message sizes. approach, hand, exploit relatively simple temporal
constraints compactly encode impact eliminated variables using binary constraints.
6.4 Multiagent Planning
term planning encompasses many specific problem domains including classical (Fikes
& Nilsson, 1972), Hierarchical Task Networks (Erol, Hendler, & Nau, 1994), MDPbased planning (Bellman, 1966; Sutton & Barto, 1998). high level, planning involves
developing policies (partially-ordered) sequences actions (provably probabilistically) evolve state world way achieves set goals optimizes
147

fiBoerkoel & Durfee

objective function. many types planning problems, plan policy must
also consider types uncertainty typically found scheduling (e.g., uncertainty
observations, effects actions, etc.). comparison, work, events
scheduled already determined taken input. output, instead
sort general policy (partial) sequence actions, specification
times assigned timepoint variables satisfy temporal constraints,
schedules considered equal. Planning scheduling, interrelated (Myers
& Smith, 1999; Garrido & Barber, 2001; Halsey, Long, & Fox, 2004), often treated
separate subproblems (e.g., McVey, Atkins, Durfee, & Shin, 1997). Smith, Frank,
Jonsson (2000), give complete comparison planning scheduling, suggest
difference [between planning scheduling] subtle one: scheduling problems
involve small, fixed set choices, planning problems often involve cascading sets
choices interact complex ways.
many planning approaches, particularly multiagent planning (for
complete introduction, see desJardins, Durfee, Ortiz Jr, & Wolverton, 1999; de Weerdt
& Clement, 2009) decentralized planning (e.g., desJardins & Wolverton, 1999; Bernstein, Zilberstein, & Immerman, 2000) relate inspire approach solving
multiagent scheduling problems. First, long history exploiting loosely-coupled
structure multiagent planning; Witwicki Durfee (2010) offer one recent example.
Second, main challenge multiagent planninghow interleave local planning interagent coordinationis also apt multiagent scheduling problems. planning,
approaches agents develop local plans work integrate plans
(e.g., Georgeff, 1983), approaches work interdependencies agents first
build local plans fit commitments (e.g., ter Mors, Valk, & Witteveen, 2004),
approaches blur dichotomy interleaving planning coordination (e.g.,
Clement, Durfee, & Barrett, 2007 establishing multiple levels abstraction).
Third, planning scheduling involve ordering events checking cycles (to
ensure goals/conditions clobbered planning ensure consistency scheduling), particularly challenging cycles potentially distributed across multiple
agents (Cox, Durfee, & Bartold, 2005).
6.5 Resource Task Allocation Problems
Allocating tasks resources multiple agents studied variety settings (e.g.,
Goldberg, Cicirello, Dias, Simmons, Smith, & Stentz, 2003; Nair, Ito, Tambe, & Marsella,
2002; Sandholm, 1993; Simmons, Apfelbaum, Fox, Goldman, Haigh, Musliner, Pelican,
& Thrun, 2000; Wellman, Walsh, Wurman, & MacKie-Mason, 2001; Zlot & Stentz, 2006).
Typically problems involve either assigning set tasks limited number agents
perform or, alternatively, assigning scarce resources agents require
resources. common approach handling task allocation market-based
approach (e.g., Nair et al., 2002), agents place bids tasks (or subsets tasks
combinatorial auctions) according calculated costs performing tasks,
tasks assigned lowest bidder. market-based approaches allow
agents locally exchange tasks order quickly respond dynamic environment (e.g.,
Sandholm, 1993). recent approaches (Goldberg et al., 2003; Zlot & Stentz, 2006)
148

fiDistributed Reasoning Multiagent Simple Temporal Problems

allow agents negotiate various levels task abstraction/decomposition, primary
temporal reasoning occurs within agent, uses scheduling information estimate
costs bid. Similarly, bidding them, agents append temporal constraints
tasks, time-windows, help capture/enforce relevant precedence constraints
tasks different agents.
work assumes task resource allocation problems already
solved, or, necessary, constraints place prevent concurrent, overlapping use
resource duplication redundant activity. Additionally, whereas task/resource
allocation cast assignment problem, work deals largely reasoning
bounds support flexible times representations. Finally noted greater detail
Zlot Stentz (2006), optimal, centralized approaches solving problem exist,
NP-hard nature problem, coupled uncertain dynamic environment,
leads recent approaches distributed well heuristic approximate
nature. contrast, work assumes deterministic complete approaches,
explicitly model relative costs values various schedules. Instead, agents
provide users autonomy make cost/value judgments,
turn, provide advice implications scheduling decisions.
6.6 Operations Research
MaSTP representations capable representing particular class scheduling
problems. Operations Research (OR) community also interested solving (often
NP-hard) scheduling problems. overview comparison two fields, Gomes (2000,
2001) classifies problems optimization problems, utility function tends
play important role. Additionally, Gomes notes tends represent problems using
mathematical modeling languages linear non-linear inequalities, uses tools
linear programming, mixed-integer linear programming, non-linear models.
Typically, approaches gain traction exploiting problem structuring. example
approaches timetabling edge-finding (Laborie, 2003) techniques
tightening bounds possible activities occur. full review
many models (e.g., Traveling Salesperson Problem, Job Shop Scheduling Problem,
Resource Constrained Project Scheduling Problem, Timetabling, etc.) beyond scope
paper, worth pointing synergy AI scheduling
communities growing (Baptiste, Le Pape, & Nuijten, 1995; Bartak, 1999; Laborie, 2003;
Baptiste, Laborie, Le Pape, & Nuijten, 2006; Oddi, Rasconi, & Cesta, 2010).

7. Conclusion
work presented paper builds foundational algorithms scheduling agents
assist people managing activities, despite distributed information, implicit
constraints, costs sharing information among agents (e.g., delays, privacy, autonomy,
etc.), possibility new constraints dynamically arising. Agents flexibly combine
shared reasoning interactions schedules independent reasoning
local problems. externalizing constraints compactly summarize local subproblems affect other, internalizing new local constraints
decouple problems one another. approach advantageous
149

fiBoerkoel & Durfee

problems interactions agents sparse compared complexity
agents individual scheduling problems, algorithms achieve significant computational speedup current art.
particularly, contributed formal definition Multiagent Simple Temporal Problem analyzed benefits distributed representation affords.
presented D4PPC algorithm, first distributed algorithm calculating
decentralized representation complete space joint solutions, proved
correctly establishes partial-path consistency worst-case runtime complexity
equal previous state-of-the-art. empirically demonstrated D4PPC scales
problems containing agents better state-of-the-art centralized counterpart,
exhibits steady margin speedup. Exactly effectively load-balances computational effort depends number external constraints coupling agents problems,
D4PPC achieves 22-fold reduction nonconcurrent computational effort
4PPC problems 25 agents problems studied. Additionally, formally defined Multiagent Temporal Decoupling Problem along first distributed
algorithm solving it. proved MaTD algorithm correct, demonstrated
analytically empirically calculates temporal decoupling upwards four
orders-of-magnitude faster previous approaches, exploiting sparse structure parallelism exists. Additionally, introduced Relaxation algorithm relaxing
bounds existing decoupling constraints form minimal temporal decoupling,
empirically showed algorithm decrease rigidity upwards 50% (within 1521% state-of-the-art centralized approach) increasing computational effort
little 20% problems studied. Overall, shown combination
MaTD MaTDR algorithms calculate temporal decoupling faster
D4PPC algorithm, four orders-of-magnitude faster previous state-of-the-art
centralized TDP algorithm.
work leads many interesting ongoing future research directions. First,
use MaSTN monitor plan execution dispatch scheduling advice users
distributed manner (as done centralized dispatching in, e.g., Drake, see Conrad
& Williams, 2011) rely ability efficiently maintain MaSTNs (Boerkoel et al.,
2013) comprehensive empirical understanding inherent trade-offs
costs maintaining PPC versus loss flexibility temporal decouplings. Second,
MaSTP formulation could adapted include models uncertainty utility,
centralized STP (Rossi, Venable, & Yorke-Smith, 2006). Optimally solving
temporal decoupling problem general models utility NP-hard problem,
even centralized case (Planken, de Weerdt, & Witteveen, 2010a). Thus, designing
mechanisms augment distributed temporal decoupling algorithm encourage
agents solve MaTDP distributed globally optimal (rather
locally minimal) manner open challenge spans multiagent scheduling
algorithmic game theory. Finally, ideas presented MaSTP extended
more-general, disjunctive scheduling problems (Boerkoel & Durfee, 2012, 2013).
combinatorics disjunctive problems leads significant challengesfinding solutions
NP-hard, structure underlying temporal network, inherently
binary MaSTP known priori, become conflated tangled combinatorial
number possible disjunctive choices.
150

fiDistributed Reasoning Multiagent Simple Temporal Problems

Acknowledgments
work supported, part, NSF grants IIS-0534280 IIS-0964512,
AFOSR Contract No. FA9550-07-1-0262, 2011 Rackham Predoctoral
Fellowship. would like thank Leon Planken, Michael Wellman, Martha Pollack, Amy
Cohn, Stefan Witwicki, Jason Sleight, Elizabeth Boerkoel, Julie Shah helpful
suggestions.

References
Anselma, L., Terenziani, P., Montani, S., & Bottrighi, A. (2006). Towards comprehensive
treatment repetitions, periodicity temporal constraints clinical guidelines.
Artificial Intelligence Medicine, 38 (2), 171195.
Armstrong, A., & Durfee, E. (1997). Dynamic prioritization complex agents distributed
constraint satisfaction problems. Proceedings International Joint Conference
Artificial Intelligence (IJCAI-97), pp. 620625.
Baptiste, P., Laborie, P., Le Pape, C., & Nuijten, W. (2006). Constraint-based scheduling
planning. Foundations Artificial Intelligence, 2, 761799.
Baptiste, P., Le Pape, C., & Nuijten, W. (1995). Incorporating efficient operations research
algorithms constraint-based scheduling. Proceedings First International
Joint Workshop Artificial Intelligence Operations Research.
Barbulescu, L., Rubinstein, Z. B., Smith, S. F., & Zimmerman, T. L. (2010). Distributed
coordination mobile agent teams: advantage planning ahead. Proceedings
Ninth International Conference Autonomous Agents Multiagent Systems
(AAMAS 2010), pp. 13311338.
Bartak, R. (1999). Constraint programming: pursuit holy grail. Proceedings
Week Doctoral Students (WDS99 -invited lecture), pp. 555564.
Bellman, R. (1966). Dynamic programming. Science, 153 (3731), 3437.
Bernstein, D., Zilberstein, S., & Immerman, N. (2000). complexity decentralized
control Markov decision processes. Proceedings Sixteenth Conference
Uncertainty Artificial Intelligence, pp. 3237.
Bliek, C., & Sam-Haroud, D. (1999). Path consistency triangulated constraint graphs.
Proceedings International Joint Conference Artificial Intelligence (IJCAI99), Vol. 16, pp. 456461.
Boerkoel, J. (2012). Distributed Approaches Solving Constraint-based Multiagent
Scheduling Problems. Ph.D. thesis, University Michigan.
Boerkoel, J., & Durfee, E. (2009). Evaluating hybrid constraint tightening scheduling
agents. Proceedings Eighth International Conference Autonomous Agents
Multiagent Systems (AAMAS 2009), pp. 673680.
Boerkoel, J., & Durfee, E. (2010). comparison algorithms solving multiagent
simple temporal problem. Proceedings Twentieth International Conference
Automated Planning Scheduling (ICAPS 2010), pp. 2633.
151

fiBoerkoel & Durfee

Boerkoel, J., & Durfee, E. (2011). Distributed algorithms solving multiagent temporal decoupling problem. Proceedings Tenth International Conference
Autonomous Agents Multiagent Systems (AAMAS 2011), pp. 141148.
Boerkoel, J., & Durfee, E. (2012). distributed approach summarizing spaces multiagent schedules. Proceedings Twenty-Sixth Conference Artificial Intelligence (AAAI-12), 17421748.
Boerkoel, J., & Durfee, E. (2013). Decoupling multiagent disjunctive temporal problem.
Proceedings Twenty-Seventh Conference Artificial Intelligence (AAAI-13),
appear.
Boerkoel, J., Planken, L., Wilcox, R., & Shah, J. (2013). Distributed algorithms
incrementally maintaining multiagent simple temporal networks. Proceedings
Twenty-Third International Conference Automated Planning Scheduling
(ICAPS 2013), appear.
Bresina, J., Jonsson, A. K., Morris, P., & Rajan, K. (2005). Activity planning
Mars exploration rovers. Proceedings Fifteenth International Conference
Automated Planning Scheduling (ICAPS 2005), pp. 4049.
Buzing, P., & Witteveen, C. (2004). Distributed (re) planning preference information. Proceedings Sixteenth Belgium-Netherlands Conference Artificial
Intelligence, pp. 155162.
Castillo, L., Fernandez-Olivares, J., & O. Garca-Perez, F. P. (2006). Efficiently handling
temporal knowledge HTN planner. Proceedings Sixteenth International
Conference Automated Planning Scheduling (ICAPS 2006), pp. 6372.
Cesta, A., & Oddi, A. (1996). Gaining efficiency flexibility simple temporal problem. Proceedings 3rd Workshop Temporal Representation Reasoning
(TIME96), pp. 4550.
Cesta, A., Oddi, A., & Smith, S. (2002). constraint-based method project scheduling
time windows. Journal Heuristics, 8 (1), 109136.
Clement, B., Durfee, E., & Barrett, A. (2007). Abstract reasoning planning coordination. Journal Artificial Intelligence Research, 28 (1), 453515.
Conrad, P., & Williams, B. (2011). Drake: efficient executive temporal plans
choice. Journal Artificial Intelligence Research, 42 (1), 607659.
Cox, J., Durfee, E., & Bartold, T. (2005). distributed framework solving multiagent plan coordination problem. Proceedings Fourth International Joint
Conference Autonomous Agents Multiagent Systems (AAMAS 2005), pp. 821
827.
de Weerdt, M., & Clement, B. (2009). Introduction planning multiagent systems.
Multiagent Grid Systems, 5 (4), 345355.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Knowledge
Representation, Vol. 49, pp. 6195.
152

fiDistributed Reasoning Multiagent Simple Temporal Problems

Dechter, R., & Pearl, J. (1987). Network-based heuristics constraint-satisfaction problems. Artificial Intelligence, 34 (1), 138.
Dechter, R. (1999). Bucket elimination: unifying framework reasoning. Artificial
Intelligence, 113 (1-2), 4185.
desJardins, M., & Wolverton, M. (1999). Coordinating distributed planning system. AI
Magazine, 20 (4), 4553.
desJardins, M. E., Durfee, E. H., Ortiz Jr, C. L., & Wolverton, M. J. (1999). survey
research distributed, continual planning. AI Magazine, 20 (4), 1322.
Erol, K., Hendler, J., & Nau, D. S. (1994). Semantics hierarchical task-network planning.
Tech. rep., University Maryland College Park, College Park, MD, USA.
Fikes, R., & Nilsson, N. (1972). STRIPS: new approach application theorem
proving problem solving. Artificial intelligence, 2 (3-4), 189208.
Floyd, R. (1962). Algorithm 97: Shortest path. Communications ACM, 5 (6), 345.
Fukunaga, A., Rabideau, G., Chien, S., & Yan, D. (1997). Aspen: framework automated planning scheduling spacecraft control operations. Proceedings
International Symposium AI, Robotics Automation Space.
Garrido, A., & Barber, F. (2001). Integrating planning scheduling. Applied Artificial
Intelligence, 15 (5), 471491.
Georgeff, M. (1983). Communication interaction multi-agent planning. Proceedings
Third National Conference Artificial Intelligence (AAAI-83), pp. 125129.
Goldberg, D., Cicirello, V., Dias, M., Simmons, R., Smith, S., & Stentz, A. (2003). Marketbased multi-robot planning distributed layered architecture. Multi-Robot Systems: Swarms Intelligent Automata: Proceedings 2003 International
Workshop Multi-Robot Systems, Vol. 2, pp. 2738.
Golumbic, M. (1980). Algorithmic graph theory perfect graphs. Academic Press.
Gomes, C. (2000). Artificial intelligence operations research: Challenges opportunities planning scheduling. Knowledge Engineering Review, 15 (1), 110.
Gomes, C. (2001). intersection AI OR. Knowledge Engineering Review,
16 (1), 14.
Halsey, K., Long, D., & Fox, M. (2004). Crikey-a temporal planner looking integration scheduling planning. ICAPS Workshop Integrating Planning
Scheduling, pp. 4652.
Hirayama, K., Yokoo, M., & Sycara, K. (2004). easy-hard-easy cost profile distributed
constraint satisfaction. Transactions Information Processing Society Japan, 45,
22172225.
Hunsberger, L. (2002). Algorithms temporal decoupling problem multi-agent planning. Proceedings Eighteenth National Conference Artificial Intelligence
(AAAI-02), pp. 468475.
Hunsberger, L. (2009). Fixing semantics dynamic controllability providing
practical characterization dynamic execution strategies. Procedings 16th
153

fiBoerkoel & Durfee

International Symposium Temporal Representation Reasoning(TIME 2009),
pp. 155162.
Kjaerulff, U. (1990). Triangulation graphs - algorithms giving small total state space.
Tech. rep., Aalborg University.
Laborie, P. (2003). Algorithms propagating resource constraints AI planning
scheduling: Existing approaches new results. Artificial Intelligence, 143 (2), 151
188.
Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. Proceedings Fourteenth International Joint Conference Artificial Intelligence
(IJCAI-95), pp. 16431649.
Lau, H. C., Li, J., & Yap, R. H. (2006). Robust controllability temporal constraint
networks uncertainty. Tools Artificial Intelligence, 2006. ICTAI06.
18th IEEE International Conference on, pp. 288296.
Mailler, R., & Lesser, V. (2006). Asynchronous partial overlay: new algorithm solving
distributed constraint satisfaction problems. Journal Artificial Intelligence Research, 25 (1), 529576.
Mailler, R., & Lesser, V. (2004). Solving Distributed Constraint Optimization Problems
Using Cooperative Mediation. Proceedings Third International Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2004), pp. 438445.
McVey, C., Atkins, E., Durfee, E., & Shin, K. (1997). Development iterative real-time
scheduler planner feedback. Proceedings Fifteenth International Joint
Conference Artificial Intelligence (IJCAI-97), pp. 12671272.
Meisels, A., & Zivan, R. (2007). Asynchronous forward-checking DisCSPs. Constraints,
12 (1), 131150.
Modi, P., Shen, W., Tambe, M., & Yokoo, M. (2005). Adopt: Asynchronous distributed
constraint optimization quality guarantees. Artificial Intelligence, 161 (1-2), 149
180.
Morris, P., & Muscettola, N. (2005). Temporal dynamic controllability revisited. Proceedings Twentieth National Conference Artificial Intelligence (AAAI-05),
pp. 11931198.
Morris, P., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporal
uncertainty. International Joint Conference Artificial Intelligence (IJCAI-01),
pp. 494502.
Muscettola, N., Morris, P., & Tsamardinos, I. (1998). Reformulating temporal plans
efficient execution. Proceedings International Conference Principles
Knowledge Representation Reasoning (KR 1998), pp. 444452.
Myers, K., & Smith, S. (1999). Issues integration planning scheduling
enterprise control. Proceedings DARPA Symposium Advances Enterprise
Control., 217223.
154

fiDistributed Reasoning Multiagent Simple Temporal Problems

Nair, R., Ito, T., Tambe, M., & Marsella, S. (2002). Task allocation robocup rescue
simulation domain: short note. Proceedings RoboCup 2001: Robot Soccer
World Cup V, pp. 751754.
Oddi, A., Rasconi, R., & Cesta, A. (2010). Casting project scheduling time windows
DTP. Proceedings ICAPS Workshop Constraint Satisfaction Techniques
Planning Scheduling Problems (COPLAS 2010), pp. 4249.
Petcu, A., & Faltings, B. (2005). scalable method multiagent constraint optimization.
International Joint Conference Artificial Intelligence (IJCAI-05), Vol. 19, pp.
266271.
Planken, L. (2008). Incrementally solving STP enforcing partial path consistency.
Proceedings Twenty-seventh Workshop UK Planning Scheduling
Special Interest Group (PlanSIG 2008), pp. 8794.
Planken, L., de Weerdt, M., & van der Krogt, R. (2008). P3 C: new algorithm
simple temporal problem. Proceedings Eighteenth International Conference
Automated Planning Scheduling (ICAPS 2008), pp. 256263.
Planken, L. R., de Weerdt, M. M., & Witteveen, C. (2010a). Optimal temporal decoupling
multiagent systems. Proceedings Ninth International Joint Conference
Autonomous Agents Multiagent Systems (AAMAS 2010), pp. 789796.
Planken, L. R., de Weerdt, M. M., & Yorke-Smith, N. (2010b). Incrementally solving STNs
enforcing partial path consistency. Proceedings Twentieth International
Conference Automated Planning Scheduling (ICAPS 2010), pp. 129136.
Rossi, F., Venable, K., & Yorke-Smith, N. (2006). Uncertainty soft temporal constraint
problems: general framework controllability algorithms fuzzy case. Journal Artificial Intelligence Research, 27 (1), 617674.
Sandholm, T. (1993). implementation contract net protocol based marginal
cost calculations. Proceedings National Conference Artificial Intelligence
(AAAI-93), pp. 256256.
Shah, J., & Williams, B. (2008). Fast dynamic scheduling disjunctive temporal constraint networks incremental compilation. Proceedings Eighteenth
International Conference Automated Planning Scheduling (ICAPS 2008), pp.
322329.
Shah, J. A., Conrad, P. R., & Williams, B. C. (2009). Fast distributed multi-agent plan execution dynamic task assignment scheduling. Proceedings Nineteenth
International Conference Automated Planning Scheduling (ICAPS 2009), pp.
289296.
Silaghi, M., & Faltings, B. (2005). Asynchronous aggregation consistency distributed
constraint satisfaction. Artificial Intelligence, 161 (1-2), 2553.
Simmons, R., Apfelbaum, D., Fox, D., Goldman, R., Haigh, K., Musliner, D., Pelican, M., &
Thrun, S. (2000). Coordinated deployment multiple, heterogeneous robots. Proceedings International Conference Intelligent Robots Systems (IROS),
pp. 22542260.
155

fiBoerkoel & Durfee

Smith, D., Frank, J., & Jonsson, A. (2000). Bridging gap planning scheduling. Knowledge Engineering Review, 15 (1), 4783.
Smith, S., Gallagher, A., Zimmerman, T., Barbulescu, L., & Rubinstein, Z. (2007). Distributed management flexible times schedules. Proceedings Sixth International Conference Autonomous Agents Multiagent Systems (AAMAS 2007),
pp. 472479.
Sutton, R., & Barto, A. (1998). Reinforcement learning: introduction, Vol. 1. Cambridge
Univ Press.
ter Mors, A. W., Valk, J. M., & Witteveen, C. (2004). Coordinating autonomous planners.
Proceedings International Conference Artificial Intelligence (ICAI04),
pp. 795801.
Tsamardinos, I., Pollack, M., & Ganchev, P. (2001). Flexible dispatch disjunctive plans.
Proceedings Sixth European Conference Planning (ECP-06), pp. 417422.
Vidal, T. (2000). Controllability characterization checking contingent temporal
constraint networks. Principles Knowledge Representation ReasoningInternational Conference, pp. 559570.
Vidal, T., & Fargier, H. (1999). Handling contingency temporal constraint networks:
consistency controllabilities. Journal Experimental & Theoretical Artificial
Intelligence, 11 (1), 2345.
Vidal, T., & Ghallab, M. (1996). Dealing uncertain durations temporal constraint
networks dedicated planning. Proceedings Twelfth European Conference
Artificial Intelligence (ECAI-96), pp. 4854.
Wellman, M., Walsh, W., Wurman, P., & MacKie-Mason, J. (2001). Auction protocols
decentralized scheduling. Games Economic Behavior, 35 (1/2), 271303.
Witwicki, S. J., & Durfee, E. H. (2010). Influence-based policy abstraction weaklycoupled Dec-POMDPs. Proceedings Twentieth International Conference
Automated Planning Scheduling (ICAPS 2010), pp. 185192.
Xu, L., & Choueiry, B. (2003). new efficient algorithm solving simple temporal
problem. Proceedings Tenth International Symposium Temporal Representation Reasoning, 2003 Fourth International Conference Temporal
Logic (TIME-ICTL 03), pp. 212222.
Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: asynchronous branch-andbound DCOP algorithm. Journal Artificial Intelligence Research, 38, 85133.
Yokoo, M., Durfee, E., Ishida, T., & Kuwabara, K. (1998). distributed constraint
satisfaction problem: Formalization algorithms. IEEE Transactions Knowledge
Data Engineering, 10 (5), 673685.
Zlot, R., & Stentz, A. (2006). Market-based multirobot coordination complex tasks.
International Journal Robotics Research, 25 (1), 73101.

156

fiJournal Artificial Intelligence Research 47 (2013) 35-70

Submitted 12/12; published 05/13

Scheduling Dynamic Aircraft Repair Shop
Limited Repair Resources
Maliheh Aramon Bajestani
J. Christopher Beck

maramon@mie.utoronto.ca
jcb@mie.utoronto.ca

Department Mechanical & Industrial Engineering
University Toronto, Canada

Abstract
address dynamic repair shop scheduling problem context military aircraft
fleet management goal maintain full complement aircraft longterm. number flights, requirement specific number type
aircraft, already scheduled long horizon. need assign aircraft flights
schedule repair activities considering flights requirements, repair capacity,
aircraft failures. number aircraft awaiting repair dynamically changes
time due failures therefore necessary rebuild repair schedule online.
solve problem, view dynamic repair shop successive static repair scheduling
sub-problems shorter time periods. propose complete approach based
logic-based Benders decomposition solve static sub-problems, design different
rescheduling policies schedule dynamic repair shop. Computational experiments
demonstrate Benders model able find prove optimal solutions average
four times faster mixed integer programming model. rescheduling approach
aspects scheduling longer horizon quickly adjusting schedule
increases aircraft available long term 10% compared approaches
either one aspects alone.

1. Introduction
United States Air Force website outlines readiness one vital elements ensure
operational effectiveness defense strategies (Schwartz, 2012). Deficiency resourcing
operations maintenance stated common culprit poor readiness. Since
air forces budget-constrained highly dynamic environments, optimal allocation
resources activities maintain readiness appropriate level challenging.
paper, study problem context military aircraft repair shop readiness
defined ability effectively carry pre-scheduled missions. need decide
failed aircraft repaired guarantee availability aircraft high
steady level. However, high frequency unexpected failures military aircraft (Safaei,
Banjevic, & Jardine, 2011) limited repair resources workforce, tools, space
(Kozanidis, Gavranis, & Kostarelou, 2012) constrain consistent aircraft availability.
Motivated work Safaei et al. (2010, 2011), study problem scheduling
military aircraft repair shop, number flights planned long horizon.
Every flight, also called wave, maximum requirement specific number aircraft
different types though partially carried without maximum complement.
beginning time horizon, aircraft either ready pre-flight check
c
2013
AI Access Foundation. rights reserved.

fiAramon Bajestani & Beck

awaiting repair repair shop. Aircraft flow long horizon illustrated Figure 1.
goal determine assignment aircraft waves schedule repair jobs
maximize flight coverage, is, extent aircraft requirements
flights met. aircraft fails pre- post-flight check, enters
repair shop incorporated current repair schedule. aircraft failure
requires set independent repair activities known characteristics processing
times resource requirements scheduled repair resources limited capacity.

Allocated Flight



Pre-Flight Check

Failure

Flight

Post-Flight Check

Yes
Yes

Repair Shop

Failure



Figure 1: Aircraft flow among waves, checks, repair shop long horizon.
central idea solution approach view dynamic repair shop successive static sub-problems shorter time periods. solution static sub-problem
determines assignment aircraft flights schedule repair jobs maximizing
flight coverage. failed aircraft enters repair shop previous repair
schedule still execution, reschedule repair activities solving new static
sub-problem.
proving NP-hardness static sub-problem, explore several techniques
solve problem: mixed integer programming (MIP); constraint programming (CP);
logic-based Benders decomposition (LBBD) using either MIP CP; dispatching
heuristic motivated Apparent Tardiness Cost (ATC) dispatching rule.
design three different rescheduling policies based length scheduling horizon
frequently rescheduling done.
perform two separate empirical studies. first indicates integration
dispatching heuristic LBBD results lowest mean run-time techniques
tested optimally schedule repair shop. second experiment demonstrates
defining static scheduling problem longer horizon rescheduling
frequently provide flights 10% higher coverage either one alone.
remainder paper organized follows: define problem, provide
overview relevant literature Section 2. Section 3 proves NP-hardness
static sub-problem, defines number solution approaches it, presents details
proposed policies rescheduling dynamic repair shop, describes model
aircraft failures. computational results performance different scheduling
techniques rescheduling done described Section 4.
discussion solution approach results presented Section 5. end
conclusion directions future work Section 6.
36

fiScheduling Dynamic Aircraft Repair Shop

2. Background
section, formal definition problem given relevant literature
reviewed.
2.1 Problem Definition
Figure 2 snapshot problem time 0, circles represent aircraft. number
flights (five shown) corresponding pre- post-flight checks already
scheduled long horizon. assumed total number aircraft constant
long horizon. number aircraft (three diagram) ready pre-flight
check others currently shop awaiting repair proceed
pre-flight check. Failure detected check assume check
always correctly assess status aircraft negligible cost duration
check incorporated length corresponding wave.

0
Repair Shop

...
st1
Wave-1

et1 st
2

et2
Wave-2

st3

et3
Wave-3

...

st4

et4
Wave-4

st5

et5
Wave-5

Checks

Figure 2: Snapshot problem time 0 long horizon.
goal assign aircraft waves maximize coverage time
creating feasible repair schedule. scheduling problem constraints
repair shop limited capacity aircraft subject breakdown. assume
aircraft fails, goes repair shop waits repair operations
performed.
use following notation represent problem.
N set aircraft. n failure rate aircraft n N denoting
frequency failure per time unit. example failure rate 0.2 per day,
means mean time aircraft failure 5 days.
K set aircraft types. Ik denotes set aircraft type k K k
aircraft ready (i.e., repair shop time 0). Let |Ik | denote number
aircraft type k, |Ik | k aircraft type k repair shop time 0.
k mean failure rate aircraft type k.
R set repair resources (called trades). maximum capacity trade r R
Cr .
W set waves. wave, w W , start-time, stw , end-time,
etw . wave requires akw aircraft type k.
J set existing jobs repair shop. job associated specific
aircraft type. Mr set jobs requiring trade r. job might require
37

fiAramon Bajestani & Beck

one trade completed. processing time job j trade r pjr
cjr capacity trade r required job j.
model deterioration aircraft, time flies wave failure rate, n ,
increases percent, i.e., failure rate (1 + 0.01 )n flight. aircraft
fails, failure rate repair returns failure.
words, one standard repair models maintenance literature, repair
minimal (Wang, 2002). probability diagnosing aircraft n failed pre-
post-flight checks function failure rate right checks denoted f pre (n )
f post (n ). probability failure detection pre-flight checks smaller
post-flight checks aircraft either released repair shop
already passed previous post-flight check successfully (Safaei et al., 2011).
find probability failure aircraft pre- post-flight checks specific
wave, need track complete history aircraft. example, assume
given aircraft repaired assigned first wave, three paths:
aircraft fails pre-flight check; aircraft passes pre-flight check, flies wave,
fails post-flight check; aircraft passes pre-flight check, flies wave,
passes post-flight check. Therefore, availability aircraft second wave
represented random variable whose expected value depends probability
three different paths scheduling decisions repair failed aircraft
second wave. Similarly availability aircraft subsequent waves depends
entire path checks, repair shop, waves. number waves
aircraft increase, size state space become prohibitive. Furthermore,
repair scheduling decisions impact aircraft histories: probability
aircraft available third wave different depending repaired time
first wave second wave. details approximating failure
probabilities presented Section 3.2.1.
complexity problem shown, prove NP-hard
Section 3.1.
2.2 Literature Review
section provides necessary background repair shop scheduling problem
logic-based Benders decomposition.
2.2.1 Repair Shop Scheduling
Repair shops mainly studied machine-repairman problem (Haque & Armstrong, 2007; Stecke, 1992) set workers set machines
subject failures therefore need repair. Workers machines respectively correspond trades aircraft, problem. number workers less
number machines, necessary allocate repair jobs workers goal
optimizing given performance measure (e.g., total expected machine downtime)
long-term. Derman, Liberman, Ross (1980) early work solving
scheduling problem repair shop single repairman. showed repairing failed machines non-decreasing order failure rate stochastically maximizes
38

fiScheduling Dynamic Aircraft Repair Shop

number working machines. literature scheduling repair shop
extended considering multiple repairmen, preemptive non-preemptive repair,
different failure repair distributions. comprehensive review literature
scheduling repair system provided Iravani, Krishnamurthy, Chao (2007).
analytical models literature mainly developed using Markov Decision
Processes (dynamic programming) guarantee optimality given performance
measure long-term. models often consider combinatorics
real scheduling problems different repair capacity limits, different due dates,
different resource processing requirements. Therefore, typically result static
dispatching-type repair policy similar found Derman et al. (1980). However,
problem, waves different plane requirements processing times
resource requirements repair activities become known enter repair
shop. Therefore, believe better performance achieved dealing directly
combinatorics explicitly scheduling repair shop meet waves.
handle uncertain combinatorial structure scheduling problems, use
dynamic scheduling approach.
Dynamic scheduling methodology developed scheduling literature
operational uncertainties like machine breakdowns unexpected arrival new
orders prevent execution schedule planned (Aytug, Lawley, McKay, Mohan,
& Uzsoy, 2005; ODonovan, Uzsoy, & McKay, 1999). dynamic scheduling problem
often viewed collection linked static sub-problems. Taking view makes
myriad algorithms developed static scheduling problems applicable. developed
algorithms deal combinatorics scheduling problems optimize
quality schedule discrete time points, i.e., static sub-problem. However,
cannot completely deal operational uncertainties, real-time disruption
requires modification schedule either permit execution improve
quality schedule considering recently revealed information. process
modifying previous schedule called rescheduling (Vieira, Hermann, & Lin, 2003;
Aytug et al., 2005; Bidot, Vidal, Laborie, & Beck, 2009). solve static sub-problems
connect using rescheduling strategies main aspects dynamic
scheduling research. Although aware using dynamic scheduling repair
system, successfully applied variety scheduling problems including single
machine (Ovacik & Uzsoy, 1994; ODonovan et al., 1999; Cowling & Johansson, 2002),
parallel machines (Vieira, Hermann, & Lin, 2000; Ovacik & Uzsoy, 1995), job shop
(Sabuncuoglu & Bayiz, 2000; Liu, Ong, & Ng, 2005; Vinod & Sridharan, 2011).
areas literature similarities static problem operational
level maintenance scheduling problem, general, flight maintenance planning
problem military aircraft, specifically. former literature addresses problem
finding schedule given maintenance activities sum maintenance costs
minimized. focus operational level, determining maintenance activities
performed time period (Budai, Huisman, & Dekker, 2006). Starting early
work Wagner, Giglio, Glaser (1964), literature extended developing
mathematical models effective solution approaches variety applications (Frost
& Dechter, 1998; Haghani & Shafahi, 2002; Budai et al., 2006; Grigoriev, van de Klundert,
& Spieksma, 2006). latter literature studies problem maintenance planning
39

fiAramon Bajestani & Beck

mission assignment military aircraft goal decide aircraft fly
one perform maintenance on, maximizing long-term availability. Similar
maintenance scheduling literature, mathematical programming common approach
solve problems literature. Kozanidis, Gavranis, Kostarelou (2012) recently
proposed mixed integer non-linear programming model optimize joint flight
maintenance plan mission aircraft.
Safaei et al. (2010) modeled static problem addressed operational level
maintenance scheduling problem using MIP. MIP includes assignment problem
two network problems: former assigns aircraft waves latter calculates
expected number available aircraft waves well expected number
available workers repair jobs. later extended work using slightly
different MIP model time-indexed approach used enforce workforce
availability constraint verified validity model number instances
different combinations workforce sizes (Safaei et al., 2011).
difference static problem addressed paper previous
works operational maintenance scheduling objective function (flight coverage) depends scheduling decisions also outcomes preand post-flight checks. two quite different components problem motivate
decomposition approach, logic-based Benders decomposition, reviewed below.
2.2.2 Logic-Based Benders Decomposition
classical Benders decomposition (Benders, 1962; Geoffrion & Graves, 1974) mathematical programming approach solving large-scale mixed integer programming models.
partitions problem mixed integer master problem (MP) relaxation
global model set linear sub-problems (SPs). Solving problem classical
Benders involves iteratively solving MP optimality using solution generate sub-problems. linear programming dual SPs solved derive
tightest bound global cost function. bound greater equal
current MP solution (assuming maximization problem), MP solution SP
solutions constitute globally optimal solution. Otherwise, constraint, Benders cut,
added MP express violated bound another iteration performed.
Logic-based Benders decomposition (Hooker & Yan, 1995; Hooker & Ottosson, 2003)
developed excluding necessity MP mixed integer model SPs
linear. Therefore, inference duals (Hooker, 2005) SPs solved rather
linear duals find tightest bound global cost function original
constraints current MP solution. Although logic-based Benders decomposition
flexibility modeling problems, standard procedure derive
Benders cuts.
Representing relaxation SPs MP, designing strong Benders cut
great importance decreasing computational effort identify globally feasible
optimal solution. former results MP solutions likely satisfy SPs,
latter rules large number MP solutions iteration (Hooker, 2007).
Logic-based Benders decomposition shown effective wide range
problems including scheduling (Hooker, 2005, 2007; Beck, 2010), facility vehicle
40

fiScheduling Dynamic Aircraft Repair Shop

allocation (Fazel-Zarandi & Beck, 2012), queue design control problems (Terekhov,
Beck, & Brown, 2009).

3. Solution Approach
main idea solution approach view dynamic problem linked successive
static sub-problems. noted above, common approach dynamic scheduling.
view results rescheduling strategy based scheduling static sub-problems
shorter time periods. Therefore, two sub-goals: solve connect
static sub-problems. section, first show static problem NP-hard
present different solution techniques solving it. define three rescheduling
strategies designed connect static sub-problems. Finally, describe approach
modeling dynamic events, i.e., aircraft failures.
3.1 Complexity Static Repair Shop Problem
establish NP-hardness static repair shop problem reduction single
machine scheduling problem objective ofP
minimizing weighted number tardy
jobs common due date, i.e., 1|dj = d| wj Uj 1 dj , wj , Uj denote
due date, weight, variable representing whether job tardy job j,
respectively. Note job j tardy processing finished due date.
problem equivalent one dimensional knapsack problem non-uniform profit
shown NP-complete reduction PARTITION problem (Pinedo,
2002).
Theorem 1. static problem NP-hard.
Proof. show instance single machine scheduling problem, I, common due date objective minimizing weighted number tardy jobs
reduces static repair shop problem. instance I, assume jobs,
jth processing time tj , weight wj , common due date d. Without
loss generality, assume weights, wj , interval [0, 1].
objective schedule jobs sum weights tardy jobs minimized equivalently sum non-tardy job weights maximized. instance
I, instance static repair shop problem formulated one
wave, failed aircraft repair shop (|N | = ), aircraft types
(|K| = ), one repair resource (|R| = 1) capacity C = 1. start-time
wave st1 = d, requiring aircraft. failed aircraft, j, different type,
corresponds one repair job repair shop processing time pj1 = tj
resource requirement cj1 = 1 single resource. probability failure precheck wave aircraft j (1 wj ). repaired aircraft j contributes flight
coverage survives pre-check probability wj . Therefore, maximize flight
coverage, goal schedule failed aircraft sum probabilities
1. notation used describing problem scheduling literature || represents
machine environment, describes processing characteristics constraints detail, denotes
objective function (Pinedo, 2002).

41

fiAramon Bajestani & Beck

P
repaired aircraft survives pre-check, i.e.,
wj maximized. goal equivalent
maximizing sum non-tardy job weights instance I. single machine
scheduling problem objective
weighted number tardy jobs
P
common due date, i.e., 1|dj = d| wj Uj , NP-hard (Pinedo, 2002), conclude
static repair shop problem also NP-hard.
3.2 Scheduling Techniques
investigate number approaches solve repair shop scheduling problem including
mixed integer programming, constraint programming, logic-based Benders decomposition,
dispatch rule, simple hybrid approach. approaches described detail
section.
3.2.1 Mixed Integer Programming
Mixed integer programming (MIP) default solution approach many scheduling
problems (Heinz & Beck, 2012). MIP formulation, constraints represented
form linear equalities and/or inequalities polyhedral theory linear programming
techniques relaxation cutting planes embedded state-of-the-art MIP
solvers applied solve problem (Queyranne & Schulz, 1994; Heinz & Beck, 2012).
propose novel mixed integer programming model uncertainty outcome
checks modeled expectation. model different and, show
Section 4.1.2, significantly faster Safaei et al. (2010, 2011). Table 1
summarizes notation defined Section 2.1 defines decision variables
MIP model.
section, without loss generality, interpret W set waves
current static sub-problem consider start-times waves due dates finish
repair aircraft. Therefore, define = {di |i = 1, 2, ..., |W |, |W | + 1}
ordered set due dates consisting wave start-times plus big value, B, sorted
ascending order. specifically, di equals start-time i-th wave, sti .
limited repair capacity, possible failed aircraft cannot repaired
time waves. case, due date repair job assigned
d|W |+1 = B. model, B equals sum start-time last wave
maximum processing times jobs trades, i.e., d|W | + max(pjr )
j,r

enforce repair resource capacity d|W | .
explained Section 2.1, exact calculation aircraft failure probability
consequently expected number available aircraft intractable since depends
complete aircraft histories. Therefore, distinguish aircraft based type
use recursive equation (Equation 4) approximate expected number available
aircraft. details Equation (4) provided later section. aircraft type
k, average failure rate, k , used calculate probability failure preand post-flight checks, respectively: kpre = f pre (k ) kpost = f post (k ). Furthermore,
failure rate aircraft assumed remain constant scheduling horizon
static problem increase flying wave. Therefore, approximation
likely underestimate number actual aircraft failures.
42

fiScheduling Dynamic Aircraft Repair Shop

Notation
N = {1, ..., n, ..., |N |}
K = {1, ..., k, ..., |K|}
R = {1, ..., r, ..., |R|}
W = {1, ..., w, ..., |W |}
J = {1, ..., j, ..., |J|}
n
Ik
k
k

set aircraft
set aircraft types
set trades
set waves
set repair jobs (failed aircraft) repair shop
failure rate aircraft n
set aircraft type k
number aircraft type k repair shop time 0
ThePaverage failure rate aircraft type k equal


pre
k

kpost

stw

etw

akw

Mr

Cr

pjr

cjr

= {d1 , ..., di , ..., d|W |+1 }The
B

Decision Variables
Zkw
xij
stjr
Inferred Variables
Ukw
Ekw
etjr

nIk

n

|Ik |

probability aircraft type k fails pre-flight check
probability aircraft type k fails post-flight check
start-time wave w
end-time wave w
maximum number aircraft type k required wave w
set repair jobs requiring trade r
maximum capacity trade r
processing time job j trade r
capacity trade r required process job j
set due dates di = sti , |W | d|W |+1 = B
big value equal d|W | + max(pjr )
j,r

number aircraft type k assigned fly wave w
xij = 1 ith due date assigned job j,
xij = 0 otherwise
start-time job j trade r
number aircraft type k whose repair due date stw
expected number available aircraft type k wave w
end-time job j trade r

Table 1: Summary notation; decision variables inferred variables MIP
model.

MIP model shown Figure 3 Zkw , number aircraft type k
assigned fly wave w, true decision variable: choose send fewer aircraft
wave currently (in expectation) available. contrast, Ekw expected
number aircraft type k available wave w based probabilistic outcomes
previous waves number newly repaired aircraft (Ukw ). refer model
MIP rely default branch-and-bound search IBM ILOG CPLEX
12.3 solver, state-of-the-art commercial MIP solver solve it. details MIP model
summarized follows:
43

fiAramon Bajestani & Beck

Maximize

|W | |K|
X
X

Zkw

(1)

w=1 k=1

Subject to:
X
Ukw =

k, w

(2)

k

(3)

w(w 6= 1), k

(4)

Zkw akw ,

k, w

(5)

Zkw Ekw ,

k, w

(6)

j

(7)

j, r

(8)

j, r

(9)

t(t st|W | ), r

(10)

i, j

(11)

k, w

(12)

j, r

(13)

k, w

(14)

xij ,

jIk , i=w

Ek1 = (k + Uk1 )(1 kpre ),
Ekw = (Ek(w1) Zk(w1) + Ukw )(1
X
+
Zkv (1 kpost )(1 kpre ),

kpre )

vVw

|W |+1

X

xij = 1,

i=1

stjr + pjr = etjr ,
|W |+1

etjr

X

xij di ,

i=1

X

cjr ((t stjr ) (t < etjr )) Cr ,

jMr

xij {0, 1},
0 Ekw |N |,
+

stjr , etjr Z {0},
+

Zkw Z {0}, Zkw |N |,

Figure 3: global MIP model static repair shop scheduling problem.
objective function (1) maximizes number aircraft assigned waves. Although modeled uncertain outcome flight checks expectation,
objective function expected wave coverage (i) wave
specific upper bounds plane requirements (ii) maximum wave coverage
wave 1. expected number available aircraft, Ekw ,
requirement, akw , given wave, extra aircraft fly wave
contribute coverage. flying extra planes, decrease
probability available next wave.
Equation (2) calculates number aircraft type k whose repair due date stw .
words, summing decision variables xij job j aircraft
type k i-th due date corresponds start-time wave w gives
44

fiScheduling Dynamic Aircraft Repair Shop

number aircraft type k leaving repair shop right pre-flight check
wave w.
Equation (3) calculates expected number available aircraft type k
first wave.
Equation (4) calculates expected number available aircraft type k
waves. first term includes aircraft available used previous
wave, i.e., (Ek(w1) Zk(w1) ), newly arrived repair shop, i.e.,
Ukw . second term sums aircraft become available
completed waves since previous wave started Vw = {v|v W, stw1 < etv
stw }.
Constraints (5) (6) ensure number aircraft assigned fly
wave less equal number aircraft required expected
number available.
Constraint (7) assigns exactly one due date job.
Equation (8) calculates end-time jobs.
Constraint (9) guarantees end-time job less equal
assigned due date.
Constraint (10) logical-and constraint enforcing capacity limit trade r
summing capacity required set jobs repair time t. Since
jobs start-time last wave contribute coverage,
capacity constraint enforced start-time last wave, i.e., st|W | .
logical constraint evaluates 1 two component constraints
evaluate 1 0 otherwise. logical inequality evaluates 1
true 0 otherwise. example, job j repair time t,
logical inequalities, (stjr t) (t < etjr ) evaluate 1 logical-and
constraint, therefore, evaluates 1. linearize constraint, rely default
approaches IBM ILOG CPLEX handling logical constraints. approaches
translate logical constraints equivalent linear counterparts creation
new variables constraints (CPLEX, 2011).
Constraints (11) (14) define domains decision variables.
3.2.2 Constraint Programming
Constraint programming paradigm solving combinatorial optimization problems.
success constraint programming (CP) solving wide variety scheduling problems
well established literature (Beck, Davenport, Davis, & Fox, 1998; Baptiste, Pape,
& Nuijten, 2001). scheduling problems usually defined one several instances
constraints satisfaction problem (CSP) (Baptiste et al., 2001). instance CSP
formally described triple (V, D, C) V = {V1 , V2 , ..., Vn } set
n variables, = {D1 , D2 , ..., Dn } set variable domains, Di corresponding
possible values Vi take, C = {C1 , C2 , ..., Cm } set constraints,
45

fiAramon Bajestani & Beck

defined subset variables. constraint Ck = {Vi , ..., Vj } defined
Cartesian product domains variables scope Di ... Dj satisfied
assignment variables scope corresponds one value tuples
constraint relation (Beck, 1999). Representing scheduling problems using CSPs results
modeling flexibility compared mixed integer programming models
restriction type decision variables constraints.
CP solves scheduling problems applying three general tools heuristic search, constraint propagation, backtracking within branch-and-bound search tree (Beck, 1999;
Beck & Refalo, 2003). Constraint propagation, one key principles contributing
success CP, exploited representing problem conjunction global constraints, embeds efficient inference techniques reduce solution space
within branch-and-bound search tree (Baptiste et al., 2001). possibility using two
global constraints, cumulative global cardinality, formulate static repair shop
problem motivates CP model shown Figure 4.
formulate problem using CP, use decision variables Table 1.
However, instead xij , define Dj corresponding assigned due date job j.
CP model differs MIP several constraints defined below.
global cardinality constraint (gcc) syntax gcc(card, value, base)
card, value, base arrays variables, values, variables, respectively. gcc
constraint satisfied value[i] taken card[i] elements base. CP model,
aircraft type k, Constraint (15) enforces Ukw counts number times
start-time wave w assigned due date jobs associated failed aircraft
type k.
cumulative constraint syntax cumulative(s, p, c, C) = {s1 , s2 , ..., sn },
p = {p1 , p2 , ..., pn }, c = {c1 , c2 , ..., cn } vectors start-time variables, processing time values, amount required resource job, respectively,
C total resource capacity value. cumulative constraint ensures total
amount resource capacity used time never exceeds C (Hooker, 2005).
Constraint (17) enforces time windows: job j trade r cannot started later
(Dj pjr ). Constraint (18) defines domain decision variables Dj .

Maximize Objective (1)
Subject to:
Constraints (3) (6), (12), (14)
gcc([Uk1 , Uk2 , ..., Uk|W | ], [st1 , st2 , ..., st|W | ], [DjIk ]),

k

(15)

cumulative([stjr |j Mr ], [pjr |j Mr ], [cjr |j Mr ], Cr ),

r

(16)

j, r

(17)

j

(18)

0 stjr Dj pjr ,
Dj {st1 , st2 , ..., st|W | , B},

Figure 4: CP model static repair shop scheduling problem.
46

fiScheduling Dynamic Aircraft Repair Shop

implement model using IBM ILOG CP Optimizer 12.3 default search
used. start-time variables, stjr , defined IloIntervalVar objects. implement
global constraints, use IloDistribute class gcc constraint IloPulse
IloAlwaysIn functions cumulative constraint. Note that, cumulative constraint
implemented time point st|W | .
3.2.3 Logic-Based Benders Decomposition
static problem requires making two different decisions, assigning aircraft waves
scheduling repair jobs failed aircraft, decomposition approach may well suited.
logic-based Benders decomposition (LBBD) method formulated master
problem assigns aircraft waves maximize wave coverage sub-problems create
repair schedules given due dates derived master problem solution.
propose four variations: Benders-MIP Benders-MIP-T, master problems
solved using MIP, latter tighter sub-problem relaxation (T stands tighter);
Benders-CP Benders-CP-T constraint programming-based master problem.
models use CP scheduling sub-problems.
Due-Date Assignment Master Problem (DAMP): MIP Model formulate
master problem MIP model, use binary variable xij job j i-th due
date meaning global MIP model. MIP formulation DAMP
follows:

Maximize Objective (1)
Subject to:

(19)

Constraints (2) (7), (11), (12), (14)
|W |+1

X

cjr pjr Cr max (

jMr

jMr

X

xij di ),

r

(20)

i=1

MIP cuts

(21)

master problem incorporates number constraints global MIP model.
represent start-times jobs fully represent capacity
trades. common Benders decomposition, master problem includes relaxation
sub-problems (Constraints 20) Benders cuts (Constraints 21).
Sub-problem Relaxation Defining area job j area rectangle height
cjr width pjr , Constraint (20) relaxation capacity trade, expressing
limit area jobs executed. limit defined using area bounded
capacity trade time interval [0, ] maximum due date
assigned jobs trade. relaxation due Hooker (2005, 2007).
tighten relaxation sub-problems Benders-MIP-T approach enforcing
analogous limit multiple intervals: [0, stw ] wave w. interval,
sum areas jobs whose assigned due date less equal end-time
interval must less equal available area. relaxation special
47

fiAramon Bajestani & Beck

case interval relaxation due Hooker (2005, 2007). Formally, tighter relaxation
replaces Constraint (20) with:
|W |+1

X
jMr

cjr pjr ((

X

xij di ) stw ) stw Cr ,

r, w

(22)

i=1

P|W |+1
(( i=1 xij di ) stw ) logical inequality evaluating 1 assigned
due date job j less equal stw .
Benders Cuts defining cut formally, demonstrate intuition
example. Consider due date set, = {14, 17, 20, 35}, and, given trade five
jobs, current master solution: x21 = 1, x12 = 1, x43 = 1, x14 = 1, x15 = 1. Job 1
assigned second due date, 17, job 2 first due date, 14, on.
current solution infeasible due resource capacity trade, know
least one jobs must later due date current master solution.
can, therefore, constrain sum consecutive xij including ones
currently assigned 1 one less number jobs. example, cut
would be:

(x11 + x21 ) + (x12 )+
(x13 + x23 + x33 + x43 ) + (x14 ) + (x15 ) 5 1
variables represent possible due dates less equal currently assigned
jobs. constraining variables one less number jobs,
least one job must assigned later due date.
Formally, assume iteration h, solution DAMP assigns set, Q, due
dates jobs trade r. Assume feasible solution trade r
assignments Q. cut iteration h is:
X X

xij |Mr | 1,

r

(23)

jMr iI h
jr

h = {i0 |i0 i, xh = 1} set due date indices
job j trade r, Ijr
ij
less equal due date index assigned job j iteration h |Mr |
number jobs trade r. validity cut proved Section 3.2.6.

Due-Date Assignment Master Problem: CP Model also formulate
DAMP using CP. Let Dj variable corresponding due date job j similar
global CP model.
48

fiScheduling Dynamic Aircraft Repair Shop

Maximize Objective (1)
Subject to:
Constraints (3) (6), (12), (14), (15), (18)
X
cjr pjr Cr max (Dj ),

r

jMr

jMr

(24)

CP cuts

(25)

master problem modeled using CP includes several constraints global CP
model. Constraint (24) represents relaxation repair capacity limit trades
guaranteeing sum processing areas set jobs trade
exceed maximum available area.
tighter relaxation CP-based DAMP replaces (24) following defining
Benders-CP-T approach logical inequality (Dj stw ) evaluates 1
due date job j, Dj , less equal start time wave w, stw .
X

cjr pjr (Dj stw ) stw Cr ,

r, w

jMr

CP cut based reasoning MIP cuts. assigned set due
dates jobs trade r feasible solution SP, cut guarantee
next iteration least one assigned due dates greater value.
Formally, cut is:
_

Dj > Djh ,

j Mr

Djh due date assigned job j iteration h,
constraints Mr set jobs trade r.

(26)
W

represents logical-or

Repair Scheduling Sub-problem Given set due dates assigned jobs
trade, goal repair scheduling sub-problem (RSSP) assign start-times
jobs satisfy due dates trade capacity. use CP formulation
RSSP trade modeled cumulative constraint.
cumulative([stjr |j Mr ], [pjr |j Mr ], [cjr |j Mr ], Cr ),
0 stjr Djh pjr ,

r
j, r

(27)

Recall [stjr |j Mr ] tuple start-time variables jobs trade r,
Djh value assigned due date job j master problem iteration h.
parameters pjr , cjr , Cr defined Table 1. Constraint (27) enforces time windows
similar constraint (17). worth mentioning RSSP, due date job j,
Djh , value; however, decision variable, Dj , global CP model.
Since CP approaches shown significantly efficient MIP simple
scheduling problems resource capacity constraints (Hooker & Ottosson, 2003; Hooker,
2005, 2007), experiment MIP formulations sub-problems.
49

fiAramon Bajestani & Beck

implement master problems Benders-MIP Benders-MIP-T, use IBM
ILOG CPLEX 12.3 solver; Benders-CP Benders-CP-T master problems
RSSP implemented IBM ILOG CP Optimizer 12.3. details implementation
global constraints similar Section 3.2.2.
3.2.4 Dispatching Heuristic
Since static problem NP-hard, solving optimality may prohibitively expensive.
therefore investigate heuristic approach, inspired Apparent Tardiness Cost
(ATC) heuristic, composite dispatching rule typically applied single machine
scheduling problem sum weighted tardiness objective (Pinedo, 2005).
heuristic computes ranking index job sorts jobs ascending order
index. heuristic iterates jobs, scheduling job earliest
available time. ranking index use follows:
Ij = ST (kj ) exp(

F Nj
),
F Cj

j

let kj denote type aircraft j, ST (kj ) start-time first wave
requires aircraft type kj . F Nj fraction total number aircraft type
kj required first wave requires kj , F Cj maximum proportion
capacity needed job j required trades, follows.
F Cj = max(
r

pjr cjr
)
ST (kj )Cr

Intuitively, earlier start-time first relevant wave, higher proportion
aircraft required wave, lower proportion capacity required
wave, sooner job scheduled. exponential function used place
weight start-time.
preliminary experiments, three dispatching heuristics investigated,
chosen heuristic performing best. first two heuristics rank jobs slightly
max(pjr )

max(pjr cjr )

different ranking indices equal Ij = ST (kj ) rF Nj Ij = ST (kj ) r F Nj ,
respectively. third heuristic two-stage approach based decomposition.
first stage finds number aircraft type assigned wave second stage
schedules jobs increasing order max(pjr cjr ) considering values determined
j,r

first stage upper bounds number jobs required wave.
preliminary experiments demonstrated chosen dispatching rule results average
6% higher wave coverage compared first two heuristics coverage
third heuristic advantage easy understand implement.
3.2.5 Hybrid Heuristic-Complete Approaches
hybrid heuristic-complete approach heuristic solution provides lower bound
maximization objective (Equation 1) may improve performance complete
approaches. Therefore, simple hybrid first runs dispatching heuristic uses
objective value starting lower bound complete approaches. Assume
50

fiScheduling Dynamic Aircraft Repair Shop

heuristic finds solution, S, f (S) number aircraft assigned waves.
complete approaches modified adding following constraint:
|W | |K|
X
X

Zkw f (S)

w=1 k=1

LBBD variations, constraint added master problem.
3.2.6 Theoretical Results
guarantee finite convergence LBBD model globally optimal solution,
Benders cuts must valid master decision variables must finite domains.
Benders cut valid given iteration, h, (1) excludes current globally
infeasible assignment master problem without (2) removing globally optimal
assignments (Chu & Xia, 2004). former guarantees finite convergence
latter guarantees optimality. decision variables DAMP finite domain,
sufficient prove satisfaction two conditions.
Theorem 2. Cut (23) valid.
Proof. condition (1), sub-problem iteration h trade r, definition:
X X

xij = |Mr |

jMr iI h
jr

Consequently, cut (23) excludes current assignment master problem.
condition (2), consider global optimal solution satisfy cut (23)
generated iteration h. cut states least one job must greater
due date h, violate cut, jobs must equal lesser due
dates iteration h. However, sub-problem infeasible
iteration h, sub-problem equal lesser due dates must also infeasible
available capacity trade less. Therefore, must infeasible
contradict assumption globally optimal.
Therefore, cut valid.
analogous argument holds cut (26).
3.3 Rescheduling Strategies
dynamic repair shop problem long horizon viewed static scheduling
sub-problems successive time periods. Lets assume start repairing failed
aircraft assigning waves based computed schedule time 0. wave
might start repair way repair shop. aircraft fails pre-flight
check, goes repair shop. failed aircraft requires set independent repair
activities known processing times resource requirements. repair shop,
previously failed aircraft might already repaired, might repair,
others might awaiting repair. failed aircraft enters repair shop,
new static repair scheduling sub-problem set existing jobs (J), number
51

fiAramon Bajestani & Beck

aircraft repair shop aircraft type (k ), failure rates
aircraft (n ) updated. set existing jobs includes recently failed aircraft
previously failed aircraft whose repairs still way yet started.
new static sub-problem added constraint, namely repairs currently
way cannot disrupted.
connect static sub-problems using three different policies denoted Pij
j define length scheduling horizon frequency rescheduling number
waves, respectively. three policies, schedule repair activities, observe
aircraft failures, respond failures rescheduling repair activities.
three policies discussed follows:
P11 : Figure 5, show P11 schedules one wave time (i = 1) reschedules
wave (j = 1). P11 myopic policy aiming providing next first
wave highest possible coverage.
P31 : contrast P11 , P31 (Figure 5), scheduling horizon three waves
rescheduling still done wave. P31 longer scheduling horizon
P11 trades-off coverage among next three waves. worth mentioning
chosen three length scheduling horizon three waves
usually scheduled daily based real data (Safaei et al., 2011).
P33 : policy scheduling horizon length three waves reschedules
every third wave (Figure 5). P33 might trade-off lower coverage next
first wave higher coverages second third waves; however,
lower frequency rescheduling.

3.4 Modeling Aircraft Failures
model dynamic events, simulate aircraft failures pre- post-flight checks.
Every aircraft either passes fails check. aircraft fails, new set repair
activities known processing times resource requirements added repair
shop. aircraft passes, flies wave required. mentioned Section 2.1,
repair failure rate aircraft returns failure
increases percent time flies wave due deterioration. n initial
failure rate aircraft n N , failure rate flying w waves without failure
n (1 + 0.01 )w .

4. Computational Experiments
section, present two separate empirical studies. first study compares
scheduling techniques experimentally presents insights algorithms performance deeper analysis results. second study investigates impact
using different scheduling techniques rescheduling policies observed wave
coverage.
52

fiScheduling Dynamic Aircraft Repair Shop

P11 Policy:
Scheduling Horizon

Scheduling Horizon
0

Scheduling Horizon

Scheduling Horizon

...
st1

et1

st2

Wave-1

et2
st3

Wave-2

et3

st4

Wave-3

et4
Wave-4

Scheduling Horizon

P31 Policy:

Scheduling Horizon

Scheduling Horizon
0

...
st1

et1

st2

Wave-1

et2
st3

Wave-2

et3

st4

Wave-3

et4
Wave-4

P33 Policy:
Scheduling Horizon

Scheduling Horizon
0

...
st1

et1

st2

Wave-1

et2
et3

st3

Wave-2

Wave-3

st4

et4
Wave-4

Figure 5: rescheduling policies.
4.1 Experimental Results Scheduling Techniques
sub-section describes experiment comparing different solution techniques scheduling static repair shop.
4.1.1 Experimental Setup
problem instances 10 30 aircraft (in steps 1), 3 4 trades, 3 4 waves.
Five instances combination parameters generated, resulting 420 instances
(21 total aircraft counts 2 trades counts 2 waves counts 5 instances).
Aircraft: number aircraft types equal |N5 | , |N | number aircraft.
aircraft randomly assigned different types uniform probability. number
aircraft type k |Ik |. failure rate aircraft randomly chosen
uniform distribution [0, 0.5]. failure rate aircraft type k, k , mean failure
rate aircraft type k. functions used represent aircraft n probability
failures pre- post-flight checks, respectively, f pre (n ) = (1en ) f post (n ) =
(1e3n ). worth mentioning conditions reliability function extreme
values failure rates hold true functions used. failure rate goes 0,
probability failure equals 0, failure rate goes , probability failure
equals 1.
Waves: plane requirement aircraft type wave randomly generated
integer uniform distribution [1, |Ik |]. length wave drawn uniform
53

fiAramon Bajestani & Beck

probability [3, 5]. make instance loose enough permit feasible solutions yet
tight enough challenging, lower bound length scheduling horizon (H)
needed. sum processing areas jobs trade, r, divided
trade capacity denoted Sr . LB = max(Sr ) lower bound time required
r
schedule jobs use H = 1.2 LB. end-time wave, etw , generated
et|W | = H rand[0, 3] final wave, |W |, etw = stw+1 rand[0, 3] w < |W |.
Trades: capacity limit trade set Cr = 10.
Repair Jobs: Eighty percent aircraft repair shop beginning, resulting
|J| = 0.8|N | repair jobs. jobs randomly assigned trades replacement
number jobs per trade equal |J|/2. job requires least one
trade require one trade. capacity trade r used job j, cjr ,
drawn [1, 10] processing time, pjr , drawn [r, 10r]: jobs trades
lower indices shorter processing times trades higher indices.
Though problem instances generated randomly, setting experiment
includes three numerical examples Safaei et al. (2011) based real data.
Furthermore, setting consists instances results problem instances
one half times bigger examples used literature (Safaei et al., 2011)
number aircraft 10, 15, 20; number waves 3 4; number
trades aircraft types equal 3 2.
experiments run 7200-second time limit AMD 270 CPU 1
MB cache per core, 4 GB main memory, running Red Hat Enterprise Linux 4.
4.1.2 Experimental Results
Figure 6 shows scatter-plots run-times six complete approaches. axes
log-scale, points line = x indicate lower run-time algorithm
y-axis. numbers boxes indicate number points
line. Run-times counted equal differ less 10%.
graphs indicate benefit MIP CP, Benders-CP MIP, BendersMIP Benders-CP MIP, Benders-MIP-T Benders-MIP, BendersCP-T Benders-CP. Table 2 presents data, sorted descending percentage
problems solved optimality, algorithms. changes results compared
previous work (Aramon Bajestani & Beck, 2011b) due improved scheduling models,
different solvers, different test problems. scheduling algorithms enhanced
using smaller value B, resource capacity constraint enforced shorter interval,
i.e., [0, st|W | ], efficient formulations Constraints (5), (6), (20) used.
mean run-time MIP model given Safaei et al. (2011) eight scenarios
10 aircraft 3 waves 294.75 seconds. However, proposed MIP model
run-time 2.64 seconds average ten instances number
aircraft waves, indicating significantly faster Safaei et al.s model.
MIP vs. CP MIP approach clear superiority CP, achieving lower
run-time 89% problem instances. CP model outperforms MIP
5% instances solve optimality within time limit.
investigation results shows mean quality CP solution 0.27%
54

fiScheduling Dynamic Aircraft Repair Shop

MIP vs. CP

10000

Benders-CP vs. MIP

10000

20

35

169
1000

100

100

100

10
1

Benders-MIP

1000

Benders-CP

1000

MIP

Benders-MIP vs. Benders-CP

10000

10
1

10
1

23
0.1

0.1

0.1

220

372
0.01
0.01

1

100

0.01
0.01

10000

1

CP

10000

Benders-MIP-T vs. Benders-MIP

10000

10
1

Benders-CP-T vs. Benders-CP
122

100
10

100

10

0.1

378
1

100

1

1
0.1

0.1

10000

1000

Benders-CP-T

Benders-MIP-T

100

100

Benders-CP

1000

1000

Benders-MIP

1

162

34

0.01
0.01

368
0.01
0.01

10000

MIP

Benders-MIP vs. MIP

10000

100

161

229
0.01
0.01
10000

1

MIP

100

0.01
0.01
10000

1

100

10000

Benders-CP

Benders-MIP

Figure 6: Run-times (seconds) six complete models.

Method
Benders-MIP-T-Hybrid
Benders-MIP-T
Benders-MIP
MIP
MIP-Hybrid
Benders-CP
Benders-CP-T
Dispatching Rule
CP

Mean
Time (s)
211.98
213.12
227.94
837.04
924.30
1373.16
1356.70
0
6857.14

Iter.

% MP

% SP

66.63 (8.0)
66.44 (8.0)
64.66 (8.0)
75.72 (15.5)
66.42 (10.0)
-

51.39 (55.05)
51.84 (53.98)
61.75 (67.44)
84.30 (96.96)
85.36 (97.36)
-

48.61 (44.95)
48.16 (46.02)
38.25 (32.56)
15.70 (3.04)
14.64 (2.64)
-

% Solved
optimality
98.10
97.86
97.62
93.57
91.19
85.24
85.00
9.76
4.76

Table 2: mean run-time, mean (the median) number master problem iterations,
mean (median) percentage run-time spent solving master problem
sub-problems, percentage problems solved optimality
approaches.

55

fiAramon Bajestani & Beck

best found solution across algorithms. Therefore, poor performance CP due
weakness proving optimality.
Benders-CP vs. MIP Benders-CP approach better MIP terms runtime 52% instances performing worse 40%. However, Table 2 favors MIP
terms overall performance, smaller mean run-time, mainly instances
solved optimality within time limit.
Benders-MIP vs. Benders-CP Benders-MIP approach achieves better runtime Benders-CP 88% test problems, performing worse 8%.
branching heuristics Benders-CP often lead initial feasible master solution
tighter due dates initial master solution Benders-MIP. tighter, globally
infeasible initial solution means CP-based master problem model requires
iterations find globally feasible solution.
Benders-MIP vs. MIP Benders-MIP approach achieves better run-time
MIP 90% test problems worse run-time 8%, achieving lower mean
run-time solving higher proportion problem instances. time horizon
short, MIP approach faster, however, longer horizons jobs,
number constraints variables grows, substantially reducing performance.
Benders-MIP-T vs. Benders-MIP tighter relaxation Benders-MIP-T slightly
speeds LBBD: Benders-MIP-T better run-time Benders-MIP 55%
problems instances worse 39%. mean run-time decreases 6% tighter
relaxation solves one instance optimality. Tightening relaxation sub-problems
increases mean number iterations spite expectation. closer look
results shows mean number iterations instances solved optimality
approaches (97.38% instances) decreases: 39.15 41.24 Benders-MIP-T
Benders-MIP, respectively. However, mean number iterations instances
timed approaches (1.9% instances) increases 1051.38 BendersMIP 1259.88 Benders-MIP-T. Therefore, increase number iterations
results timed-out instances support tighter relaxation
requires iterations optimality.
Furthermore, percentage time solving master problem decreases compared
Benders-MIP, sub-problem percentage run-time increases. latter observation
sub-problems Benders-MIP quickly proved insoluble
initial propagation CP sub-problem model, violate tighter relaxation BendersMIP-T master problem. Therefore, tighter model, sub-problem solver called
easy sub-problems, increasing percentage run-time spend sub-problems.
Benders-CP-T vs. Benders-CP tighter relaxation CP-based master problem
results slightly lower mean run-time; however, shown Figure 6, performance
comparison even.
Incomplete Hybrid Approaches dispatching heuristic fast, finding feasible solution problems. However, finds (but, course, prove) optimal
solution 9.76% instances Benders-MIP-T finds proves optimality
56

fiScheduling Dynamic Aircraft Repair Shop

instances 0.99 seconds average. seems heuristic find optimal solution problem instance relatively easy. mean quality
heuristic solution 16% optimal. industries expensive assets, reduction
solution quality translate costly under-use valuable resource (e.g., fighter
aircraft costs vicinity 100 million dollars). However, finding feasible solution almost instantaneously large problem instances makes heuristic approach compelling
situations long run-time might delay carrying waves. example,
wave starts within short time, flying wave lower coverage (achieved
dispatching heuristic) better carrying long solving time
complete approaches.
evaluate effect combining dispatching heuristic complete approaches, examine using hybrid heuristic-complete approach. smaller feasible set
direct consequence defining bound cost function. MIP model
searches feasible set, LBBD methods explore infeasible space, one intuition
MIP model benefit using heuristic solution. However, solving
master problem LBBD requires searching relaxed feasible space therefore
heuristic starting solution may also speed solving.
Table 2 shows marginal benefit bounding Benders-MIP-T approaches
dispatching heuristic solution. Bootstrap paired-t tests (Cohen, 1995) also indicate
significant difference mean run-time p 0.01 either hybrid.
Scalability Figure 7 shows results number aircraft per wave increases.
|N |
aggregate results truncating |W
| using instances three waves three
four trades. Note point represents 30 problem instances except x = 3
20 problems instances. omitted x = 10 10 problem instances
point. y-axis log-scale.
results show LBBD variations outperform techniques across
ratios.
Summary following observations performance scheduling techniques
supported empirical study.
LBBD approach combining mixed integer programming constraint programming outperforms mixed integer programming model. mean run-time
Benders-MIP almost 4 times lower MIP. Furthermore, defining time ratio given instance MIP run-time divided Benders-MIP run-time,
Benders-MIP almost 32 times faster MIP, average, geometric mean
time ratio 31.56. time ratios range [0.01, 94132.67] median 38.32.
tighter relaxation slightly speeds LBBD. Benders-MIP-T Benders-CP-T,
both, run-time 1.2 times faster Benders-MIP Benders-CP,
respectively.
dispatching heuristic provide optimal solution easy problem instances. However, mean percent relative error heuristic almost 16% overall,
indicating dispatching rule effective enough industries
high equipment cost.
57

fiAramon Bajestani & Beck

10000

CP
MIP
MIP-Hybrid
Benders-CP
Benders-CP-T
Benders-MIP
Benders-MIP-T
Benders-MIP-T-Hybrid

Mean Run-Time (sec)

1000

100

10

1

0.1

0.01
3

4

5

6

7

8

9

Aircraft/Wave

Figure 7: Mean run-time vs. number aircraft per wave (|W | = 3).
simple hybridization complete approaches dispatching heuristic
result statistically significant difference run-time.
4.2 Experimental Results Rescheduling Strategies
sub-section describes experiment investigating impact applying different scheduling techniques rescheduling policies dynamic repair shop.
4.2.1 Experimental Setup
problem instances, number aircraft, number trades, total
number waves set {10, 15, 20, 25, 30}, {4}, {30} respectively. combination
5 instances total 25 instances. instance simulated 20 times.
parameters problem instances generated Section 4.1 following
modifications:
Aircraft: failure rate aircraft increased = 5 percent time used.
Repair Jobs: Repair jobs entered repair shop time 0 randomly assigned
trades. probability assigning job trade considered 0.5.
Waves: start-time wave generated st1 = rand[ H3 , H2 ] first wave,
stw = etw1 + rand(0, 40) 1 < w 30. mentioned earlier total number
waves 30. value H calculated Section 4.1.
Dynamic events: simulate aircraft failure, generate random value
uniform distribution [0, 1] aircraft check. random value less
aircrafts probability failure, aircraft fails; otherwise, passes. aircrafts
probability failure pre- post-flight checks calculated using (1 en )
(1 e3n ), respectively. Recall that, n failure rate aircraft, n N ,
58

fiScheduling Dynamic Aircraft Repair Shop

increases = 5 percent time aircraft flies wave. Note passing
pre-flight check wave necessarily mean aircraft flies wave.
number available aircraft requirements, aircraft fly
randomly selected passed pre-flight check meet requirements.
latter assumption implies aircraft ready beginning wave checked
regardless wave requirements. Since assumed pre- post-flight
checks negligible cost, assumption reasonable discover potential aircraft
failures sooner likely increase availability subsequent waves.
experiment three techniques including MIP, Benders-MIP-T, dispatching rule discussed Section 3.2. time-limit schedule repair activities
decision time point 600 seconds. execute best feasible schedule found
time-limit algorithm times out. case Benders-MIP-T times out, schedule created dispatching heuristic executed Benders-MIP-T create
feasible schedule times-out.
static problem, scheduling uses IBM ILOG CPLEX 12.3 IBM ILOG
CP Optimizer 12.3. simulation implemented C++.
4.2.2 Experimental Results
section, discuss results compare performance different scheduling
rescheduling techniques availability aircraft long run.
investigate effect modeling aircraft failures using expected coverage.
Figures 8, 9, 10 illustrate mean observed coverage flight w {1, 2, ..., 28}
different scheduling rescheduling techniques. Denoting wpl
coverage flight
Pw
i=1 ipl
w l-th simulation instance p given policy, Owpl =
represents
w
mean observed coverage flight w instance p simulation
l.
mean observed
P
P
P

L

Owpl

coverage flight w, shown figures, calculated Ow = p=1 P l=1
, P
L
L number instances simulations, respectively. Table 3 shows mean
observed coverage flight 28, i.e., O28 variance observed coverage
flight 28 scheduling techniques rescheduling policies. illustrated, BendersMIP-T using P31 achieves least 10% higher mean coverage combinations
scheduling rescheduling techniques lowest variance.
impact scheduling algorithms complete technique anticipated
achieve higher flight coverage takes expected probabilistic information
Method
Benders-MIP-T
MIP
Dispatching heuristic

P11
0.67 [0.03]
0.52 [0.03]
0.61 [0.04]

O28 [var(.)]
P31
0.77 [0.01]
0.64 [0.03]
0.61 [0.04]

P33
0.70 [0.01]
0.60 [0.02]
0.63 [0.03]

P11
45
34
42

(.)
P31
56
46
44

P33
48
38
47

Table 3: mean (variance) observed coverage flight 28 (O28 [var(.)])
mean percentage available aircraft first flight ().

59

fi1

1

0.9

0.9

0.8

0.8

0.7

0.7

Mean Observed Coverage

Mean Observed Coverage

Aramon Bajestani & Beck

0.6
0.5
0.4
0.3
0.2

0.5
0.4
0.3
0.2

Benders-MIP-T: P31
Benders-MIP-T: P11
Benders-MIP-T: P33

0.1

0.6

MIP: P31
MIP: P11
MIP: P33

0.1

0

0

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

Flight

Flight

Figure 8: Mean observed coverage three
different policies using BendersMIP-T.

Figure 9: Mean observed coverage
three different policies using
MIP.

1
0.9

Mean Observed Coverage

0.8
0.7
0.6
0.5
0.4
0.3
0.2

Heuristic: P31
Heuristic: P11
Heuristic: P33

0.1
0

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

Flight

Figure 10: Mean observed coverage three
different policies using dispatching heuristic.

account creating repair schedule, dispatching heuristic
property. shown Table 3, Benders-MIP-T complete technique results
higher mean observed coverage policies compared dispatching heuristic.
However, MIP, incorporating mean known information uncertainty scheduling
60

fiScheduling Dynamic Aircraft Repair Shop

repair activities, results flights lower coverage dispatching heuristic
two rescheduling policies, P11 P33 . understand MIP performance, make
two conjectures.
first conjecture poor performance MIP algorithm frequently times static sub-problems best found feasible solution
dispatching heuristic used create repair schedule. However, results
support conjecture. MIP algorithm times 13% scheduling subproblems feasible solution found each, implying dispatching heuristic
never used find repair schedule.
second conjecture low coverage achieved MIP attributed
different way scheduling repair activities compared two scheduling
techniques. deeper look schedules static sub-problems shows dispatching heuristic Benders-MIP-T schedule repair activities earliest possible
time; however, MIP usually not. Repairing aircraft earlier makes aircraft
available intuitively increases coverage long run, even though number
pre-flight checks aircraft go increases expectation. quick adjustment
schedule makes failed planes available start-time
next flight. investigate impact making aircraft available earlier using given
scheduling technique,
define mean percentage available aircraft first flight
P
P
P
P

L



kpl

k=1
(Pij ) = p=1 l=1
kpl denote percentage aircraft available
P LS
beginning first flight k-th static sub-problem l-th simulation
instance p number static sub-problems Pij policy, respectively. example,
P31 policy given p l, first static sub-problem includes flights 1, 2, 3.
Then, 1pl number aircraft available flight 1 divided total number
aircraft. second static sub-problem schedules flights 2, 3, 4. Therefore, 2pl
equal number aircraft available flight 2 divided total number aircraft.
follow procedure find kpl 28 static sub-problems P31 policy.
find (P11 ) (P33 ) using argument considering number static
sub-problems 30 10, respectively.
Comparing pair scheduling rescheduling techniques Table 3,
positive relationship making aircraft available earlier wave coverage
long term supports conjecture: mean percentage available aircraft
first flight () increases, mean observed coverage long rum (O28 ) also
increases.

impact rescheduling policies illustrated Figures 8 9, P11 policy
either Benders-MIP-T MIP short-term (i.e., first three flights) outperforms two policies. However, P31 policy leads consistently higher
coverage schedules longer horizon adjusts schedule soon
aircraft failures occur. Although P31 dispatching heuristic also responds quickly
aircraft failures, incorporate length scheduling horizon
ranking index repair activities always repairs aircraft earliest possible
time, resulting flights coverage P11 .
Figure 11 displays cumulative percentage flights coverage less
equal Benders-MIP-T, dispatching heuristic MIP denotes
61

fiAramon Bajestani & Beck

values x-axis. best performing approach fewer flights low
coverage flights high coverage. Therefore, curve closer
lower right-hand corner. illustrated, Benders-MIP-T using P31 performs better
combination. P31 rescheduling policy computationally expensive
two policies, run-time per one static sub-problem, however, small compared
length scheduling horizon usually one day real applications (Safaei
et al., 2011). P31 policy using Benders-MIP-T run-time average 67 seconds
per one static sub-problem less 249 seconds 90% static sub-problems.
100

P31-Benders-MIP-T
P11-Benders-MIP-T
P33-Benders-MIP-T
P31-Heuristic
P11-Heuristic
P33-Heuristic
P31-MIP
P11-MIP
P33-MIP

90

Percentage Flights

80
70
60
50
40
30
20
10
0
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Flight Coverage

Figure 11: percentage flights coverage less equal , denotes
values x-axis.
summary, analysis results identifies Benders-MIP-T P31 (BendersMIP-T:P31 ) best combination scheduling rescheduling techniques
providing flights higher mean coverage long term. Furthermore,
lowest variance observed coverage compared scheduling
rescheduling techniques.
impact modeling uncertainty expectation random
aircraft failures, coverage achieved scheduling algorithm random variable.
ultimate goal construct repair schedule optimal specific realization uncertainty actually occurs. However, since complete information
aircraft failures known future uncertainty dependent previous repair
decisions, impossible find repair schedule ideal realization
uncertainty. discussed earlier, modeled aircraft failures using expected
value find optimal repair schedule. Since treating uncertainty expectation form may far optimal actual realization uncertainty, perform
sensitivity analysis failure rates aircraft investigate optimal repair
schedule Benders-MIP-T:P31 hedged various uncertain situations.
62

fiScheduling Dynamic Aircraft Repair Shop

Using problem instances Section 4.2.1, two experiments set
failure rate aircraft (n ) increased n +0.05 n +0.1. results
show mean observed coverage flight 28 decreases 0.69 0.62,
variance observed coverage change, indicating modeling uncertainty
using expected probabilistic information reasonable approach.
find possible upper bound (tighter 1) mean observed coverage
flight w scheduling algorithm, define policy called Relaxed relaxes
repair capacity limit repairs failed aircraft maximum processing times
trades. Although Relaxed policy makes aircraft available waves
earlier repair scheduling policy, cannot guarantee results
upper bound observed coverage unless waves requirements.
optimal decision might trade immediate low coverage future higher coverage
plane requirements waves different. Applying Relaxed scheduling
policy instances Section 4.2.1, mean observed coverage flight
28, i.e. Ow , 24% higher best identified algorithm, Benders-MIP-T:P31 .
specifically, Relaxed policy results mean coverage 0.95 variance 0.002.
impact longer scheduling horizon vs. frequent rescheduling
P31 policy changes repair schedule flight trades-off coverage among
three consecutive flights scheduling longer horizon. contrast, P11 policy
schedules one flight reacts flight P33 policy reasons longer
term without quick response dynamic events. already shown Figures 8
9, P31 policy complete techniques results higher mean coverage.
P11 policy outperforms P33 early waves, P33 provides later waves
higher coverage.
superiority policy P31 indicates features quick response dynamic events long-term reasoning contribute overall performance. contribution feature significantly dependent several parameters aircraft
failure rates, plane requirements, repair capacity. failure rate high,
probability aircraft diagnosed failed pre- post- flight checks higher.
Therefore, arrival rate aircraft repair shop higher previously
constructed schedule likely executed is. system, frequent
rescheduling likely increase coverage. plane requirements
waves widely varying repair capacity limit tight, trading-off coverage
among flights scheduling longer horizon significantly contributes
availability aircraft long term.
Summary following observations scheduling rescheduling
done supported second empirical study:
Solving dynamic repair shop problem using Benders-MIP-T scheduling technique P31 rescheduling policy results observed coverage higher
mean lower variance combination tested.
positive relationship making failed aircraft available early
possible achieving higher coverage long term.
63

fiAramon Bajestani & Beck

Since variance P31 policy Benders-MIP-T sensitive
small changes aircraft failures, modeling uncertainty respect
mean reasonable approach balance different uncertain scenarios.

5. Discussion
experimental results demonstrate incorporating probabilistic execution
time reasoning schedule repair activities results better system performance.
showed decomposition technique, LBBD, rescheduling policy P31 result
10% higher mean observed coverage long term, increasing utilization
valuable resources. decomposition technique considers mean known probabilistic
information uncertainty longer scheduling horizon repairs failed aircraft
earliest time. P31 rescheduling policy takes advantage up-to-date information
frequently. also shown variance coverage increase
aircraft failures increase, supporting core idea solution approach: dynamic
repair shop problem viewed collection static sub-problems uncertainty
aircraft failures treated expectation.
Optimizing respect mean considering specific class scheduling problems limitations solution approach. address detail discuss
ideas deal them.
Modeling uncertainty Optimizing respect expected coverage
unfavorable consequences: constructed repair schedule may remarkably poor
performance particular realizations uncertainty might happen actuality (Birge
& Louveaux, 1997). number possible approaches solving dynamic
problem. briefly discuss method below.
Leaving availability slack repair resources make schedule robust
flexible (Branke & Mattfeld, 2002, 2005; Davenport, Gefflot, & Beck, 2001)
first approach. example, Branke Mattfeld (2002, 2005) propose anticipatory
scheduling algorithm predict future job arrivals dynamic scheduling problem.
secondary objective, called flexibility, included within static sub-problem penalize
early idleness machines. experimentally show approach improves
system performance. conclusion consistent observation Section
4.2.2 positive relationship repairing aircraft earlier achieving
higher coverage. would therefore interesting adjust MIP model
flexibility term added objective function quantify value making repair
resources available early possible. However, appears none existing work
slack-based techniques uses analytical reasoning decide amount slack
level penalization early slack used different levels stochasticity.
Modeling static sub-problem two-stage stochastic programming second
approach (Birge & Louveaux, 1997). first stage decision corresponds constructing
repair schedule occurs aircraft failures pre- post-flight checks. second
stage decision, includes allocation aircraft flights, occurs pre-flight
number aircraft type k assigned fly
checks. One approach define Zkw
wave w scenario s. scenario represents possible realization aircraft failures
64

fiScheduling Dynamic Aircraft Repair Shop

horizon static sub-problem
p(s). Therefore, objective
P probability
P P
. main modeling challenge
function (Equation 1) written p(s) k w Zkw
calculate probability scenario. already explained Section 2.1,
uncertainty problem exogenous information dependent first-stage
decisions hard represent closed tractable form. Computationally,
two-stage stochastic programming models substantially challenging
discrete optimization problems (Dyer & Stougie, 2003) therefore ability solve
models problem optimality doubtful.
third approach use multi-stage dynamic programming solving dynamic
repair shop problem (Iravani et al., 2007). goal construct repair schedule
decision epoch, marked arrival newly failed aircraft repair shop,
coverage maximized long term. Using dynamic programming
framework, state repair shop decision time point tuple aircraft
failure rates, aircraft processing times, aircraft resource requirements.
decision action assign start-times failed aircraft repair shop.
several challenges modeling problem classical dynamic program. First,
expected wave coverage result current state action taken cannot
represented closed form expression combinatorics involved
scheduling problem. Second, probabilities repair shop transitions
new state next decision epoch result current state, action taken,
revealed uncertainty aircraft failures known hard calculate
mainly, again, due combinatorics scheduling decisions fact
processing times resource requirements repair operations become known
upon aircraft failure. challenges indicate analytical tools classical
dynamic programming methodology cannot used modeling problem. However, AI
techniques broader scope applicability machine learning (Sutton &
Barto, 1998), online stochastic combinatorial optimization (Van Hentenryck & Bent, 2006),
hindsight optimization (Burns, Benton, Ruml, Yoon, & Do, 2012) investigated
potential approaches future work.
Extending scheduling problem Although results demonstrated specific class scheduling problems constraint repair capacity limit,
solution approach adapted complex scheduling problems. specifically,
proposed MIP CP algorithms static sub-problem easily extended
handle types scheduling constraints precedence constraints. However,
modeling problem via decomposition approach would require additional effort.
existence precedence constraints among repair activities failed aircraft makes
scheduling different repair resources dependent. Therefore, separate RSSP
repair resource cannot defined. One possible idea represent scheduling problem
single sub-problem appropriate relaxation Benders cut developed.
Taking another perspective, decomposed problem stochastic long-term planning deterministic short-term scheduling problems DAMP RSSP, respectively.
long-term plan, deal uncertainty using known information
probability aircraft failures trade-off coverage flights. short65

fiAramon Bajestani & Beck

term schedule, construct feasible repair schedule achieve coverage decided
long-term plan. designed different rescheduling policies investigate
information revealed time effectively used adjust repair schedule
change long-term plan. conclude changing long-term plan based shortterm information cannot completely incorporated long-term plan
beginning significantly increases utilization airplanes.
typical hierarchical optimization approach deal interdependency different levels decision makings. However communication technique designed
paper, capable utilizing short-term deterministic scheduling long-term
stochastic planning likely lead higher system performance. problem
addressed here, assignment aircraft flights scheduling repair
activities repair shop represent long-term short-term reasoning, respectively. wide range operational decisions viewed integrated optimization
problems, pattern algorithms designed might applicable. Combining
maintenance inventory planning job production scheduling example
integrated operational problem higher level decision-making, maintenance inventory policy determined whereas lower level, jobs scheduled
(Terekhov, Dogru, Ozen, & Beck, 2012; Aramon Bajestani, 2013). maintenance
inventory policy leads infeasible scheduling problem lower level, higher
level needs informed information inventory maintenance decisions adjusted. Therefore, overall approach demonstrated applications
problems typically solved hierarchical optimization approach.

6. Conclusion
paper, address problem scheduling dynamic repair shop context
aircraft fleet management. goal maximize flight coverage longterm considering repair capacity aircraft failures. number failed
aircraft dynamically changes aircraft breakdowns. proposed solution solves
dynamic problem successive static scheduling problems shorter time periods.
Several scheduling algorithms different rescheduling policies proposed schedule
repair activities online dynamic reaction aircraft failures. length
scheduling horizon frequency rescheduling features defining three
policies.
computational results show optimization approach using logic-based Benders decomposition, scheduling longer horizon, incorporating mean known
information aircraft failures, adjusting repair schedule soon new jobs enter
repair shop yield higher mean coverage reasonable approach balance
different uncertain scenarios.
Developing richer solution approaches better handle uncertainty challenging
interesting topic pursue future work. However, within solution technique,
establishing formal framework exactly determine long future
plan ahead quickly change schedule based new information
also interesting direction future work. answer two questions
seems highly dependent arrival rate new information impact
66

fiScheduling Dynamic Aircraft Repair Shop

new information overall system performance. quantify two values
starting point provide solid responses two questions.

Acknowledgments
research supported part Natural Sciences Engineering Research
Council Canada (NSERC) consortium members Centre Maintenance Optimization & Reliability Engineering (C-MORE). Thanks Nima Safaei Dragan Banjevic
introducing problem us subsequent discussions. paper combined
extended version conference paper (Aramon Bajestani & Beck, 2011b) workshop
paper (Aramon Bajestani & Beck, 2011a) already appeared.

References
Aramon Bajestani, M. (2013). Integrating Maintenance Planning Production Scheduling: Making Operational Decisions Strategic Perspective. Ph.D. thesis, Department Mechanical & Industrial Engineering, University Toronto, Canada.
Forthcoming.
Aramon Bajestani, M., & Beck, J. C. (2011a). Scheduling dynamic aircraft repair shop.
Proceedings ICAPS2011 Workshop Scheduling Planning Applications.
Aramon Bajestani, M., & Beck, J. C. (2011b). Scheduling aircraft repair shop.
Proceedings Twenty-First International Conference Automated Planning
Scheduling (ICAPS2011), pp. 1017.
Aytug, H., Lawley, M., McKay, K., Mohan, S., & Uzsoy, R. (2005). Executing production
schedules face uncertainties: review future directions. European Journal
Operational Research, 161, 86110.
Baptiste, P., Pape, C. L., & Nuijten, W. (2001). Constraint-based Scheduling. Kluwer
Academic Publishers, Boston/Dordrecht/London.
Beck, J. C. (1999). Texture Measurements Basis Heuristic Commitment Techniques
Constraint-Directed Scheduling. Ph.D. thesis, Department Computer Science,
University Toronto, Canada.
Beck, J. C. (2010). Checking-up branch-and-check. Proceedings Sixteenth International Conference Principles Practice Constraint Programming (CP2010),
pp. 8498.
Beck, J. C., Davenport, A. J., Davis, E. D., & Fox, M. S. (1998). ODO project: Toward
unified basis constraint-directed scheduling. Journal Scheduling, 1, 89125.
Beck, J. C., & Refalo, P. (2003). hybrid approach scheduling earliness
tardiness costs. Annals Operations Research, 118, 4971.
Benders, J. (1962). Partitioning procedures solving mixed-variables programming problems. Numerische Mathematik, 4, 238252.
Bidot, J., Vidal, T., Laborie, P., & Beck, J. C. (2009). theoretical practical framework
scheduling stochastic environment. Journal Scheduling, 12, 315344.
67

fiAramon Bajestani & Beck

Birge, J. R., & Louveaux, F. (1997). Introduction Stochastic Programming. Springer
Verlag, New York, USA.
Branke, J., & Mattfeld, D. C. (2002). Anticipatory scheduling dynamic job shop problems. Proceedings ICAPS2002 Workshop On-line Planning Scheduling, pp. 310.
Branke, J., & Mattfeld, D. C. (2005). Anticipation flexibility dynamic scheduling.
International Journal Production Research, 43, 31033129.
Budai, G., Huisman, D., & Dekker, R. (2006). Scheduling preventive railway maintenance
activities. Journal Operational Research Society, 57, 10351044.
Burns, E., Benton, J., Ruml, W., Yoon, S., & Do, M. B. (2012). Anticipatory on-line planning. Proceedings Twenty-Second International Conference Automated
Planning Scheduling (ICAPS2012), pp. 333337.
Chu, Y., & Xia, Q. (2004). Generating Benders cuts general class integer programming problems. Proceedings First International Conference Integration
AI Techniques Constraint Programming (CPAIOR2004), pp. 127136.
Cohen, P. R. (1995). Empirical Methods Artificial Intelligence. MIT Press, Cambridge, Mass.
Cowling, P., & Johansson, M. (2002). Using real time information effective dynamic
scheduling. European Journal Operational Research, 139, 230244.
CPLEX (2011). IBM ILOG CPLEX 12.3 Users Manual. IBM ILOG.
http://pic.dhe.ibm.com/infocenter/cosinfoc/v12r3/index.jsp.

Available

Davenport, A. J., Gefflot, C., & Beck, J. C. (2001). Slack-based techniques robust
schedules. Proceedings Sixth European Conference Planning (ECP-2001).
Derman, C., Lieberman, G. J., & Ross, S. M. (1980). optimal assignment servers
repairman. Journal Applied Probabilities, 19, 577581.
Dyer, M., & Stougie, L. (2003). Computational complexity stochastic programming
problems. Spor-report 2003-20, Department Mathematics Computer Science,
Eindhoven Technical University, Eindhoven.
Fazel-Zarandi, M. M., & Beck, J. C. (2012). Using logic-based Benders decomposition
solve capacity- distance-constrained plant location problem. INFORMS
Journal Computing, 24, 399415.
Frost, D., & Dechter, R. (1998). Optimizing constraints: case study scheduling
maintenance electric power units. Lecture Notes Computer Science, 1520, 469
488.
Geoffrion, A. M., & Graves, G. W. (1974). Multicommodity distribution system design
Benders decomposition. Management Science, 20, 822844.
Grigoriev, A., van de Klundert, J., & Spieksma, F. C. R. (2006). Modeling solving
periodic maintenance problem. European Journal Operational Research, 172,
783797.
68

fiScheduling Dynamic Aircraft Repair Shop

Haghani, A., & Shafahi, Y. (2002). Bus maintenance systems maintenance scheduling:
Model formulations solutions. Transportation Research Part A, 36, 453482.
Haque, L., & Armstrong, M. J. (2007). survey machine interference problem.
European Journal Operational Research, 179, 469482.
Heinz, S., & Beck, J. C. (2012). Reconsidering mixed integer programming MIPbased hybrids scheduling. Proceedings Ninth International Conference
Integration AI Techniques Constraint Programming Combinatorial
Optimization Problems (CPAIOR2012), pp. 211227.
Hooker, J. (2005). hybrid method planning scheduling. Constraints, 10, 385401.
Hooker, J. (2007). Planning scheduling logic-based Benders decomposition. Operations Research, 55, 588602.
Hooker, J., & Ottosson, G. (2003). Logic-based Benders decomposition. Mathematical
Programming, 96, 3360.
Hooker, J., & Yan, H. (1995). Logic circuit verification Benders decomposition.
Saraswat, V., & Van Hentenryck, P. (Eds.), Principles Practice Constraint
Programming: Newport Papers, chap. 15, pp. 267288. MIT Press.
Iravani, S. M. R., Krishnamurthy, V., & Chao, G. H. (2007). Optimal server scheduling
nonpreemptive finite-population queueing systems. Queueing System, 55, 95105.
Kozanidis, G., Gavranis, A., & Kostarelou, E. (2012). Mixed integer least squares optimization flight maintenance planning mission aircraft. Naval Research Logistics,
59, 212229.
Liu, S. Q., Ong, H. L., & Ng, K. M. (2005). Metaheuristics minimizing makespan
dynamic shop scheduling problem. Advances Engineering Software, 36, 199205.
ODonovan, R., Uzsoy, R., & McKay, K. N. (1999). Predictable scheduling single
machine breakdowns sensitive jobs. International Journal Production
Research, 37, 42174233.
Ovacik, I. M., & Uzsoy, R. (1994). Rolling horizon algorithms single-machine dynamic
scheduling problem sequence-dependent setup times. International Journal
Production Research, 32, 12431263.
Ovacik, I. M., & Uzsoy, R. (1995). Rolling horizon procedures dynamic parallel machine
scheduling sequence-dependent setup times. International Journal Production
Research, 33, 31733192.
Pinedo, M. (2002). Scheduling: Theory, Algorithms, Systems (2nd edition). Prentice
Hall, New Jersey, USA.
Pinedo, M. (2005). Planning Scheduling Manufacturing Services. Springer Series
Operations Research. Springer.
Queyranne, M., & Schulz, A. (1994). Polyhedral approaches machine scheduling problems. Tech. rep. 408/1994, Department Mathematics, Technische Universitat Berlin,
Germany. revised 1996.
69

fiAramon Bajestani & Beck

Sabuncuoglu, I., & Bayiz, M. (2000). Analysis reactive scheduling problems job shop
environment. European Journal Operational Research, 126, 567586.
Safaei, N., Banjevic, D., & Jardine, A. K. S. (2010). Workforce constrained maintenance
scheduling aircraft fleet: case study. Proceedings Sixteenth ISSAT International Conference Reliability Quality Design, pp. 291297.
Safaei, N., Banjevic, D., & Jardine, A. K. S. (2011). Workforce-constrained maintenance
scheduling military aircraft fleet: case study. Annals Operations Research,
186, 295316.
Schwartz, N. (2012). Balancing risk: Readiness, force structure, modernization.
CSAF remarks 2012 Air Force Reserve Senior Leader Conference. Available
http://www.af.mil/shared/media/document/AFD-120611-028.pdf.
Stecke, K. E. (1992). Machine Interference: Assignment Machines Operators. Handbook
Industrial Engineering (2nd edition). John Wiley & Sons.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge, Mass.
Terekhov, D., Beck, J. C., & Brown, K. N. (2009). constraint programming approach
solving queueing design control problem. INFORMS Journal Computing,
21, 546561.
Terekhov, D., Dogru, M. K., Ozen, U., & Beck, J. C. (2012). Solving two-machine assembly scheduling problems inventory constraints. Computers Industrial
Engineering, 63, 120134.
Van Hentenryck, P., & Bent, R. (2006). Online Stochastic Combinatorial Optimization.
MIT Press.
Vieira, G. E., Hermann, J. W., & Lin, E. (2000). Predicting performance rescheduling
strategies parallel machine systems. Journal Manufacturing Systems, 19, 256
266.
Vieira, G. E., Hermann, J. W., & Lin, E. (2003). Rescheduling manufacturing systems:
framework strategies, policies methods. Journal Scheduling, 6, 3692.
Vinod, V., & Sridharan, R. (2011). Simulation modeling analysis due-date assignment
methods scheduling decision rules dynamic job shop production system.
International Journal Production Economics, 129, 127146.
Wagner, H. M., Giglio, R. J., & Glaser, R. G. (1964). Preventive maintenance scheduling
mathematical programming. Management Science, 10, 316334.
Wang, H. (2002). survey maintenance policies deteriorating systems. European
Journal Operational Research, 139, 469489.

70

fi
