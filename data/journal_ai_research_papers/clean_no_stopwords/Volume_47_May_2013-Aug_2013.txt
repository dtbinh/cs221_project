Journal Artificial Intelligence Research 47 (2013) 521-573Submitted 01/13; published 07/13Topic Segmentation LabelingAsynchronous ConversationsShafiq Jotysjoty@qf.org.qaQatar Computing Research InstituteQatar FoundationDoha, QatarGiuseppe CareniniRaymond T. Ngcarenini@cs.ubc.carng@cs.ubc.caUniversity British ColumbiaVancouver, BC, Canada, V6T 1Z4AbstractTopic segmentation labeling often considered prerequisite higher-level conversation analysis shown useful many Natural Language Processing(NLP) applications. present two new corpora email blog conversations annotatedtopics, evaluate annotator reliability segmentation labeling tasksasynchronous conversations. propose complete computational frameworktopic segmentation labeling asynchronous conversations. approach extendsstate-of-the-art methods considering fine-grained structure asynchronous conversation, along conversational features applying recent graph-based methodsNLP. topic segmentation, propose two novel unsupervised models exploitfine-grained conversational structure, novel graph-theoretic supervised modelcombines lexical, conversational topic features. topic labeling, propose two novel(unsupervised) random walk models respectively capture conversation specific cluestwo different sources: leading sentences fine-grained conversational structure. Empirical evaluation shows segmentation labeling performedbest models beat state-of-the-art, highly correlated human annotations.1. Introductionever increasing popularity Internet technologies, common nowadayspeople discuss events, issues, tasks personal experiences social media (e.g.,Facebook, Twitter, blogs, fora) email (Verna, 2010; Baron, 2008). examples asynchronous conversations participants communicatedifferent times. huge amount textual data generated everyday conversations calls automated methods conversational text analysis. Effective processingconversational texts great strategic value organizations individuals (Carenini, Murray, & Ng, 2011). instance, managers find informationexchanged email conversations within company extremely valuable decisionauditing. decision turns ill-advised, mining relevant conversations mayhelp determining responsibility accountability. Similarly, conversations ledfavorable decisions could mined identify effective communication patterns sourceswithin company. public blogging services (e.g., Twitter, Slashdot), conversations ofc2013AI Access Foundation. rights reserved.fiJoty, Carenini, & Ngten get large involving hundreds bloggers making potentially thousands comments.major event political uprising Egypt, relevant messages postedthousands millions. simply feasible read messages relevantevent, mining summarization technologies help providing overviewpeople saying positive negative opinions expressed. Miningsummarizing conversations also aid improved indexing searching.personal level, informative summary conversation could greatly support new participant get speed join already existing conversation. could also helpsomeone quickly prepare follow-up discussion conversation already partof, occurred long ago remember details.Topic segmentation labeling often considered prerequisite higher-levelconversation analysis (Bangalore, Di Fabbrizio, & Stent, 2006) shownuseful many Natural Language Processing (NLP) applications including automatic summarization (Harabagiu & Lacatusu, 2005; Kleinbauer, Becker, & Becker, 2007; Dias, Alves,& Lopes, 2007), text generation (Barzilay & Lee, 2004), information extraction (Allan,2002), conversation visualization (Liu, Zhou, Pan, Song, Qian, Cai, & Lian, 2012).Adapting standard definition topic (Galley, McKeown, Fosler-Lussier, & Jing,2003) asynchronous conversations, consider topic somethingparticipants discuss argue express opinions. Multiple topics seem occurnaturally social interactions, whether synchronous (e.g., meetings, chats) asynchronous(e.g., emails, blogs). naturally occurring ICSI multi-party meetings (Janin et al.2003), Galley et al. (2003) report average 7.5 topical segments per conversation.multi-party chat, Elsner Charniak (2010) report average 2.75 discussions activetime. email blog corpora, present article, annotators foundaverage 2.5 10.77 topics per email blog conversation, respectively.Topic segmentation refers task grouping sentences asynchronousconversation set coherent topical clusters (or segments)1 , topic labelingtask assigning short description topical clusters facilitate interpretations topics (Purver, 2011). example, sample truncated email conversationcorpora shown Figure 1, majority three annotators found three different topics (or clusters). Likewise, truncated blog conversation shown Figure 2,annotators found six different topics. right column figure specifiesparticular segmentation assigning topic ID (or cluster ID) sentences belonging topic. topics figure also differentiated using differentcolors. topic labels assigned annotators listed conversation (e.g.,Telecon cancellation, Tag document, Responding I18N Figure 1).extensive research conducted topic segmentation monolog (e.g.,news articles) synchronous dialog (e.g., meetings), none studied problemsegmenting labeling asynchronous conversations (e.g., email, blog). Therefore,reliable annotation scheme, standard corpus, agreed-upon metrics available.Also, key observation that, asynchronous nature, usequotation (Crystal, 2001), topics conversations often interleavedchange sequential way. is, look temporal order sentences1. article, use terms topical cluster topical segment interchangeably.522fiTopic Segmentation Labeling Asynchronous ConversationsFrom: Brian To: rdf core Subject: 20030220 telecon Date: Tue Feb 17 13:52:15propose cancel weeks telecon schedule another 12 Mar 2004, needed.would like get moving comments TAG architecture document.Jan still reviewing?aim get comments end week agreement email next week?Topic[1][2][2][2]From: Jeremy To: Brian Subject: Re: 20030220 telecon Date: Wed Feb 18 05:18:10> propose cancel weeks telecon schedule another 12 Mar 2004, needed.> .. agreement email next week?think means formally respond I18N charmod comments, shall tellintend to, e-mail discussion shown disagreement.e.g. informed RDF Core WG decisions, one indicated unhappiness - howeverformally discussed issues; likely to.[3][3]From: Brian To: Jeremy Subject: Re: 20030220 telecon Date: Wed Feb 18 13:16:21> think means formally respond I18N charmod comments, shall> tell intend to, e-mail discussion shown disagreement.Ah, problem. understood correctly going last call anyway.> e.g. informed RDF Core WG decisions, one indicated unhappiness> - however formally discussed issues; likely to.deadline?I'm prepared decide email formally respond email.[3][3][3]From: Pat To: Brian Subject: Re: 20030220 telecon Date: Wed Feb 18 16:56:26> propose cancel weeks telecon schedule another 12 Mar 2004, needed.Im assuming cancelled unless hear otherwise.Maybe default?> would like get moving comments TAG architecture document.still plan write rather long diatribe find time.doubt rest WG endorse send along asap, hopefully time next week.[1][1][2][2]From: Jeremy To: Brian Subject: Re: 20030220 telecon Date: Thu Feb 19 05:42:21> Ah. problem. understood correctly going last call anyway.Yes could change draft informal response indicate formal responseincluded LC review comments new documents.> deadline?> I'm prepared decide email formally respond email.Two weeks received message ....i.e. Cannes-I suspect also real deadline, imagine want make final decisions Cannes.happy draft formal response pretty vacuous, e-mail vote. pretty vacuous, e-mail vote.[3][3][3][3]Topic LabelsTopic 1 (green): Telecon cancellation, Topic 2 (magenta): TAG document, Topic 3 (blue): Responding I18N.Figure 1: Sample truncated email conversation email corpus. color indicatesdifferent topic. right column specifies topic assignments sentences.523fiJoty, Carenini, & NgAuthor: Soulskill Title: Bethesda Releases Daggerfall Free Type: ArticleThursday, Bethesda announced 15th anniversary Elder Scrolls series, releasingElder Scrolls II: Daggerfall free.aren't providing support game anymore, posted detailed description getgame running DOSBox.Fans series easily relive experience getting completely lost enormous dungeons.Save often.Fragment(a)Topic[1][1](b)[2][2](c)[2][2][2][2]Author: Datamonstar Title: Nice nice nice nice... Comment id: 1 Parent id: None Type: Comment>Fans series easily relive experience getting completely lost enormous dungeons.>Save often.... well really, since game soooo old, still huge HUGE gameworld.Really, It's big.Can't wait play it.makes Oblivion look like Sesame Street.Author: Freetardo Title: Re: Nice nice nice nice... Comment id: 2 Parent id: 1 Type: CommentYes big, thing again.quite monotonous times, really.[3](d)[3](e)[4]Author: gbarules2999 Title: Re: Nice nice nice nice... Comment id: 3 Parent id: 1 Type: CommentRandomly generated HUGE isn't nearly good designed small.Back Morrowind, folks.(f)[5]Author: drinkypoo Title: Re: Nice nice nice nice... Comment id: 4 Parent id: 3 Type: Comment>Randomly generated HUGE isn't nearly good designed small.solution obviously combine approaches.way single game satisfy types players.(g)[4][4](h)[1](i)[1](j)[3][3]Author: ElrondHubbard Title: Rest well night -- Comment id: 5 Parent id: None Type: Comment-- tomorrow, sail kingdom... Daggerfall.Many, many enjoyable hours spent playing game could (should) working thesis.Chief complaint: repetitive dungeons, stitched together seemingly near-randomly prefabbed bitspieces repeated endlessly.Still, great game.[1]Author: Anonymous Title: Re:Rest well night -- Comment id: 6 Parent id: 5 Type: Comment>Many, many enjoyable hours spent playing game could (should) working thesisSo, thesis go?>Chief complaint: repetitive dungeons, stitched together seemingly near-randomly great gamealso think great game.(k)[0](l)[1]Topic LabelsTopic 1 (green): Free release Daggerfall reaction, Topic 2 (purple): Game contents size, Topic 3 (orange): Bugsfaults, Topic 4 (magenta): Game design, Topic 5 (blue): gaming options, Topic 0 (red): `OFF-TOPIC'.Figure 2: Sample truncated blog conversation blog corpus. color indicates differenttopic. right column (i.e., Topic) specifies topic assignments sentences.Fragment column specifies fragments FQG (see Section 3.1.3).524fiTopic Segmentation Labeling Asynchronous Conversationsconversation, discussion topic may appear intersect discussionothers. seen Figure 1, discussion topic 3 second thirdemail, topics 1 2 revisited fourth email, topic 3 brought backfifth email. Therefore, sequentiality constraint topic segmentation monologsynchronous dialog hold asynchronous conversation. result,expect models proved successful monolog synchronous dialogeffective, directly applied asynchronous conversation.contributions article aim remedy problems. First, present twonew corpora email blog conversations annotated topics, evaluate annotatorreliability topic segmentation labeling tasks using new set metrics,also used evaluate computational models. knowledge,first corpora made publicly available. Second, present completetopic segmentation labeling framework asynchronous conversations. approachextends state-of-the-art methods (for monologs synchronous dialogs) consideringfine-grained structure asynchronous conversation along conversationalfeatures. so, apply recent graph-based methods NLP (Mihalcea & Radev,2011) min-cut random walk paragraph, sentence word graphs.topic segmentation, propose two novel unsupervised models exploit,principled way, fine-grained conversational structure beyond lexical information.also propose novel graph-theoretic supervised topic segmentation model combineslexical, conversational, topic features. topic labeling, propose generate labelsusing unsupervised extractive approach identifies representative phrasestext. Specifically, propose two novel random walk models respectively capturestwo forms conversation specific information: (i) fact leading sentencestopical cluster often carry informative clues, (ii) fine-grained conversationalstructure. best knowledge, also first comprehensive study addressproblem topic segmentation labeling asynchronous conversation.framework tested series experiments. Experimental results topicsegmentation task show unsupervised segmentation models benefit consider finer conversational structure asynchronous conversations. comparisonsupervised segmentation model unsupervised models reveals supervisedmethod, optimizing relative weights features, outperforms unsupervisedones even using labeled conversations. Remarkably, segmentation decisionsbest unsupervised supervised models also highly correlated humanannotations. experiments topic labeling task, show randomwalk model performs better exploits conversation specific clues leadingsentences conversational structure. evaluation end-to-end system alsoshows promising results corpora, compared human annotations.rest article, discussing related work Section 2, presentsegmentation labeling models Section 3. describe corpora evaluation metrics Section 4. experiments analysis presented Section 5.summarize contributions consider directions future work Section 6.525fiJoty, Carenini, & Ng2. Related WorkThree research areas directly related study: topic segmentation, topic labeling,extracting conversation structure asynchronous conversations.2.1 Topic SegmentationTopic segmentation extensively studied monologs synchronous dialogstask divide discourse topically coherent sequential segments (fordetailed overview see Purver, 2011). unsupervised models rely discourse cohesionphenomenon, intuition sentences segment lexically similarsentences preceding following segment. approachesmainly differ measure lexical similarity sentences.One early approach TextTiling (Hearst, 1997), still forms baselinemany recent advancements. operates three steps: tokenization, lexical score determination, depth score computation. tokenization step, forms fixedlength pseudo-sentences, containing n stemmed words. considers blocks kpseudo-sentences, gap two consecutive pseudo-sentences measurescosine-based lexical similarity adjacent blocks representing vectors term frequencies. Finally, measures depth similarity valley gap,assigns topic boundaries appropriate sentence gaps based threshold.similarity computed basis raw term frequency (TF) vectors,cause problems sparseness, treats terms independently. Choi,Hastings, Moore (2001) use Latent Semantic Analysis (LSA) measure similarityshow LSA-based similarity performs better raw TF-based similarity.Unlike TextTiling, uses threshold decide topic boundaries, Choi et al. usedivisive clustering find topical segments. use similarity measures basedTF LSA features supervised segmentation model.Another variation cohesion-based approach LCSeg (Galley et al., 2003),uses lexical chains (Morris & Hirst, 1991). LCSeg first finds chains based termrepetitions, weights based term frequency chain length. cosine similarity two adjacent blocks lexical chain vectors used measure lexicalcohesion TextTiling-like algorithm find segments. LCSeg achieves results comparable previous approaches (e.g., Choi et al., 2001) monolog (i.e., newspaper)synchronous dialog (i.e., meeting). Galley et al. also propose supervised modelsegmenting meeting transcripts. use C4.5 probabilistic classifier lexicalconversational features show outperforms unsupervised method (LCSeg).Hsueh, Moore, Renals (2006) apply models Galley et al. (2003)manual transcripts ASR (automatic speech recognizer) output meetings.perform segmentation coarse (topic) fine (subtopic) levels. topic level,get similar results Galley et al. supervised model outperforming LCSeg. However, subtopic level, LCSeg surprisingly outperforms supervised model indicatingfiner topic shifts better characterized lexical similarity alone.work, initially show LCSeg performs poorly, applied temporalordering asynchronous conversation. because, mentioned earlier, topicsasynchronous conversations interleaved change sequentially following526fiTopic Segmentation Labeling Asynchronous Conversationstemporal order sentences. address this, propose novel extension LCSegleverages fine conversational structure asynchronous conversations. also proposenovel supervised segmentation model asynchronous conversation achieves evenhigher segmentation accuracy combining lexical, conversational, topic features.Malioutov Barzilay (2006) use minimum cut clustering model segment spokenlectures (i.e., spoken monolog). form weighted undirected graph nodesrepresent sentences weighted edges represent TF.IDF-based cosine similaritysentences. segmentation solved graph partitioning problemassumption sentences segment similar, sentencesdifferent segments dissimilar. optimize normalized cut criterion (Shi &Malik, 2000) extract segments. general, minimization normalized cutNP-complete. However, sequentiality constraint topic segmentation monolog allowsfind exact solution polynomial time. approach performs betterapproach Choi et al. (2001) corpus spoken lectures. Since sequentialityconstraint hold asynchronous conversation, implement model withoutconstraint approximating solution, compare models.Probabilistic generative models, variants Latent Dirichlet Allocation (LDA)(Blei, Ng, & Jordan, 2003) also proven successful topic segmentationmonolog synchronous dialog. Blei Moreno (2001) propose aspect Hidden MarkovModel (AHMM) perform topic segmentation written spoken (i.e., transcribed)monologs, show AHMM model outperforms HMM task. Purveret al. (2006) propose variant LDA segmenting meeting transcripts, use topwords topic-word distributions topic labels. However, approach outperform LCSeg. Eisenstein Barzilay (2008) propose another variant incorporatingcue words (sequential) segmentation model. follow-up work, Eisenstein (2009)proposes constrained LDA model uses multi-scale lexical cohesion perform hierarchical topic segmentation. Nguyen, Boyd-Graber, Resnik (2012) successfully incorporate speaker identity hierarchical nonparametric model segmenting synchronousconversations (e.g., meeting, debate). work, demonstrate general LDAmodel performs topic segmentation asynchronous conversation propose novelextension LDA exploits fine conversational structure.2.2 Topic Labelingfirst comprehensive approach topic labeling, Mei, Shen, Zhai (2007) proposemethods label multinomial topic models (e.g., topic-word distributions returnedLDA). Crucial approach measure semantic similaritytopic-word distribution candidate topic label extracted corpus.perform task assuming another word distribution label derivingKullback-Leibler divergence two distributions. turns measureequivalent weighted point-wise mutual information (PMI) topic-wordscandidate label, weights actually probabilities topic-worddistribution. use Maximum Marginal Relevance (MMR) (Carbonell & Goldstein,1998) select labels relevant, redundant. labeling multipletopic-word distributions, find discriminative labels, adjust semantic similarity527fiJoty, Carenini, & Ngscoring function candidate label also similar topics gets lowerscore. work, also use MMR promote diversity labels topic. However,get distinguishable labels different topical segments conversation, rankwords high scoring word one topic high scores topics.Recently, Lau, Grieser, Newman, Baldwin (2011) propose methods learn topiclabels Wikipedia titles. use top-10 words topic-word distributionextract candidate labels Wikipedia. extract number featuresrepresent candidate label. features actually different metrics usedliterature measure association topic words candidate label (e.g.,PMI, t-test, chi-square test). use Amazon Mechanical Turk get humans ranktop-10 candidate labels use average scores learn regression model.Zhao, Jiang, He, Song, Achananuparp, Lim, Li (2011a) addresses problemtopical keyphrase extraction Twitter. Initially use modified Twitter-LDA model(Zhao, Jiang, Weng, He, Lim, Yan, & Li, 2011b), assumes single topic assignmenttweet, discover topics corpus. Then, use PageRank (Page, Brin,Motwani, & Winograd, 1999) rank words topic-word distribution. Finally,perform bi-gram test generate keyphrases top ranked words topic.studies try mine topics whole corpus, problemfind topical segments label given conversation, topicsclosely related distributional variations subtle (e.g., Game contents size, Gamedesign Figure 2). Therefore, statistical association metrics like PMI, t-test, chi-squaretest may reliable case data scarcity. Also conversation-level,topics specific particular discussion (e.g., Telecon cancellation, TAGdocument, Responding I18N Figure 1) exploiting external knowledge baseslike Wikipedia source candidate labels reasonable option us. fact,none human-authored labels developement set appears Wikipedia title.Therefore, propose generate topic labels using keyphrase extraction methodfinds representative phrase(s) given text.Several supervised unsupervised methods proposed keyphrase extraction (for comprehensive overview see Medelyan, 2009). supervised models (e.g.,Hulth, 2003; Medelyan, Frnak, & Witten, 2009) follow two-stage framework. First,candidate keyphrases extracted using n-gram sequences shallow parser (chunker).Second, classifier filters candidates. strategy quite successful,domain specific labor intensive. Every new domain may require new annotations,times becomes expensive unrealistic. contrast, approach adoptunsupervised paradigm, robust across new domains, still capableachieving comparable performance supervised methods.Mihalcea Tarau (2004) use graph-based (unsupervised) random walk modelextract keyphrases journal abstracts achieve state-of-the-art performance(Mihalcea & Radev, 2011).2 However, model generic designed exploitproperties asynchronous conversations. propose two novel random walk modelsincorporate conversation specific information. Specifically, models exploit information2. original work published Mihalcea Tarau (2004).528fiTopic Segmentation Labeling Asynchronous Conversationstwo different sources: (i) leading sentences topical segments, (ii)fine conversational structure conversation.2.3 Conversational Structure ExtractionSeveral approaches proposed capture underlying conversational structureconversation. Recent work synchronous conversations focusing disentangling multi-party chats, linear structure. example, several studies proposemodels disentangle multi-party chat (Elsner & Charniak, 2010, 2011; Wang & Oard,2009; Mayfield, Adamson, & Rose, 2012). hand, asynchronous conversationslike email social media services (e.g., Gmail, Twitter) generally organize commentstree-structured threads using headers. Automatic methods uncover complexstructures also proposed (e.g., Wang, Wang, Zhai, & Han, 2011; Aumayr, Chan,& Hayes, 2011). However, use quotation asynchronous conversations expressconversational structure finer grained informative onerevealed reply-to relations comments (Carenini et al., 2011). example,Figures 1 2, proximity quoted paragraph unquoted one represent informative conversational link two (i.e., talktopic) would appear looking reply-to relations.previously presented novel method capture email conversation finerlevel analyzing embedded quotations emails (Carenini, Ng, & Zhou, 2007).Fragment Quotation Graph (FQG) formed, shown beneficial emailsummarization (Carenini, Ng, & Zhou, 2008) dialog act modeling (Joty, Carenini,& Lin, 2011). work, generalize FQG asynchronous conversationdemonstrate topic segmentation labeling models also benefit significantlyfine conversational structure asynchronous conversation.3. Topic Models Asynchronous ConversationsDeveloping topic segmentation labeling models asynchronous conversations challenging partly specific characteristics media. mentioned earlier,unlike monolog (e.g., news article) synchronous dialog (e.g., meeting), topicsasynchronous conversations may change sequential way, topics interleaved. Furthermore, noticed Figures 1 2, writing style varies amongparticipants, many people tend use informal, short ungrammatical sentences,thus making discourse much less structured. One aspect asynchronous conversationfirst glance may appear help topic modeling message comesheader. However, often headers convey much topical information sometimeseven misleading. example, blog conversation (Figure 2), participantskeep talking different topics using title (i.e., nice nice nice),convey topic information. Arguably, unique properties asynchronousconversations limit application state-of-the-art techniques successfulmonolog synchronous dialog. Below, first describe techniquespresent extended effectively deal asynchronous conversations.529fiJoty, Carenini, & Ng3.1 Topic Segmentation Modelsfirst study problem topic segmentation asynchronous conversation. Therefore, first show existing models, originally developedmonolog synchronous dialog, naively applied asynchronous conversations.Then, pointing limitations, propose novel topic segmentation modelsasynchronous conversations.3.1.1 Existing ModelsLCSeg (Galley et al., 2003) LDA (Blei et al., 2003) two state-of-the-art unsupervised models topic segmentation monolog synchronous dialog (Purver, 2011).following, briefly describe models directly appliedasynchronous conversations.Lexical Cohesion-based Segmenter (LCSeg)LCSeg sequential segmentation model originally developed segmenting meeting transcripts. exploits linguistic property called lexical cohesion, assumes topicchanges likely occur strong word repetitions start end. first computeslexical chains (Morris & Hirst, 1991) non-stop word based word repetitions.3chains weighted according term frequency chain length.populated compact chains get higher scores. algorithm works twoadjacent analysis windows, fixed size k, empirically determined.sentence boundary, computes cosine similarity (or lexical cohesion function)two windows representing window vector chain-scores words.Specifically, lexical cohesion windows (X ) computed with:PNwi,X .wi,YLexCoh(X, ) = cos sim(X, ) = qP i=1PNN22i=1 wi,Yi=1 wi,X .(1)N number chainsrank(Ci ) chain Ci overlaps {X, }wi, =0otherwisesharp change local minima resulting similarity curve signals high probabilitytopic boundary. curve smoothed, local minimum computessegmentation probability based relative depth nearest peaks either side.Points highest segmentation probability selected hypothesized topicboundaries. method similar TextTiling (Hearst, 1997) except similaritycomputed based scores chains instead term frequencies.LCSeg directly applied asynchronous conversation arranging comments based arrival time (i.e., temporal order) running algorithm gettopic boundaries.3. One also consider lexical semantic relations (e.g., synonym, hypernym) lexical chainingbest results account repetition.530fiTopic Segmentation Labeling Asynchronous ConversationsLatent Dirichlet Allocation (LDA)LDA generative model relies fundamental idea documents admixtures topics, topic multinomial distribution words. specifiesfollowing distribution words within document:P (xij ) =KXP (xij |zij = k, bk )P (zij = k|i )(2)k=1K number topics, P (xij |zij = k, bk ) probability word xij documenttopic k, P (zij = k|i ) probability k th topic sampled wordtoken xij . refer multinomial distributions bk topic-word documenttopic distributions, respectively. Figure 3 shows resultant graphical model platenotation N documents, K topics Mi tokens document i. Note that,standard Dirichlet priors bk , respectively. Variational EM usedestimate b (Blei et al., 2003). One also use Gibbs sampling directly estimateposterior distribution z, i.e., P (zij = k|xij ); namely, topic assignments wordtokens (Steyvers & Griffiths, 2007).zi,jbkxi,jKMiNFigure 3: Graphical model LDA plate notation.framework directly applied asynchronous conversation consideringcomment document. assuming words sentence occur independentlyestimate topic assignments sentence follows:P (zm = k|s) =P (zm = k|xm )(3)xmFinally, topic assigned by:k = argmaxk P (zm = k|s)(4)3.1.2 Limitations Existing Modelsmain limitation two models discussed make bag-of-words(BOW) assumption ignoring facts specific multi-party, asynchronous conversation. LCSeg considers term frequency closely terms occur531fiJoty, Carenini, & Ngtemporal order sentences. topics interleaved change sequentiallytemporal order, often case asynchronous conversation, LCSeg wouldfail find topical segments correctly.hand, information relevant LDA term frequency. Several extensions LDA BOW approach proposed. example, Wallach (2006)extends model beyond BOW considering n-gram sequences. Griffiths, Steyvers, Blei,Tenenbaum (2005) present extension sensitive word-order automatically learns syntactic well semantic factors guide word choice. Boyd-GraberBlei (2008) describe another extension consider syntax sentences.argue models still inadequate finding topical segments correctlyasynchronous conversations especially topics closely related distributional variations subtle (e.g., Game contents size Game design). betteridentify topics one needs consider features specific asynchronous conversations(e.g., conversation structure, speaker, recipient). following, propose novelunsupervised supervised topic segmentation models incorporate features.3.1.3 Proposed Unsupervised ModelsOne important indicators topic segmentation asynchronous conversationconversation structure. seen examples (Figures 1 2), participantsoften reply post and/or use quotations talk topic. Notice alsouse quotations express conversational structure finer levelgranularity one revealed reply-to relations. corpora, found averagequotation usage 9.85 per blog conversation 6.44 per email conversation. Therefore,need leverage key information get best models. Specifically,need capture conversation structure quotation (i.e., text fragment) level,incorporate structure segmentation models principled way.following, first describe capture conversation structurefragment level. show unsupervised models LCSeg LDA extended take conversation structure account, generating two novel unsupervisedmodels topic segmentation asynchronous conversation.Extracting Finer-level Conversation StructureSince consecutive turns asynchronous conversations far apart time, participants reply post comment, quoted version original message oftenincluded (specially email) default draft reply order preserve context.Furthermore, people tend break quoted message different questions,requests claims dealt separately. result, message, unlessbeginning, contain mix quoted novel paragraphs (or fragments) may wellreflect reply-to relationship paragraphs finer level granularityone explicitly recorded comments. proposed novel approach capturefiner level conversation structure form graph called Fragment QuotationGraph (FQG) (Carenini et al., 2007). following, demonstrate buildFQG sample blog conversation shown Figure 2. Figure 4(a) showsblog conversation, sake illustration, instead showing real content,532fiTopic Segmentation Labeling Asynchronous Conversationsabbreviate sequence labels (e.g., a, b), label corresponding text fragment(see Fragment column Figure 2). Building FQG two-step process.Figure 4: (a) main Article C omments fragments exampleFigure 2. Arrows indicate reply-to relations. (b) corresponding FQG.Node creation: Initially, processing whole conversation, identify newquoted fragments different depth levels. depth level quoted fragmentdetermined number quotation marks (e.g., >, >>, >>>). instance,comment C1 contains new fragment c quoted fragment b depth level 1. C6contains two new fragments k l, two quoted fragments j depth level1, on. second step, compare fragmentsbased lexical overlap find distinct fragments. necessary, splitfragments step. example, ef C3 divided e f distinctfragments compared fragments C4 . process gives 12 distinctfragments constitute nodes FQG shown Figure 4(b).Edge creation: create edges represent likely replying relationship fragments assuming new fragment potential reply neighboring quotations depth level 1. example, fragments C6 Figure 4(a), createtwo edges k (i.e., (k,i),(k,j)) one edge l (i.e., (l,j)) Figure 4(b).comment contain quotation, fragments linked newfragments comment replies, capturing original reply-to relation.Note FQG approximation reply relations fragments.cases, proximity may indicate connection cases connection exist fragments never adjacent comment. Furthermore,process could lead less accurate conversational structure quotation marks (orcues) present. Nonetheless, previously showed considering FQGbeneficial dialog act modeling (Joty et al., 2011) email summarization (Careniniet al., 2008). study, show topic segmentation (this Section) labeling533fiJoty, Carenini, & Ng(Section 3.2) models also benefit significantly fine conversational structureasynchronous conversation. Minimizing noise FQGs left future work.LCSeg FQG (LCSeg+FQG)examine FQG carefully, paths (considering fragments first commentroot nodes) interpreted subconversations, topic shifts likely occuralong pathway walk path. incorporate FQG LCSeg three steps.Path extraction: First, extract paths FQG. example, FQGFigure 4(b), extract paths < a, j, l >, < b, c, e, g >, < b, c, >, on.LCSeg application: run LCSeg algorithm extracted pathsseparately collect segmentations. example, applied LCSeg <b, c, e, g > < b, c, > paths separately, may get following segmentations< b, c | e, g > < b, c | >, | denotes segment boundary.4 Noticefragment multiple paths (e.g., b, c) eventually cause sentencesmultiple segments. So, final step, need consolidation method.Consolidation: intuition sentences consolidated segment appeartogether segment often LCSeg applied step 2,appear together segment, least similar. achieve this,construct weighted undirected graph G(V, E), nodes V representsentences edge weights w(x, y) represent number segmentssentences x appear together; x appear together segment,cosine similarity used edge weights. formally,(n,w(x, y) =cos sim(x, y),x appear together n segments n > 0n = 0measure cosine similarity sentences x follows:Pcos sim(x, y) = qPtfw,x .tfw,yqP2 .2tfx,xxi xyi tfyi ,ywx,y(5)tfa,s denotes term frequency term sentence s. cosine similarity(0 cos sim(x, y) 1) provides informative edge weights sentence pairsdirectly connected LCSeg segmentation decisions.5 Now, consolidationproblem formulated k-way-mincut graph partitioning problemnormalized cut (Ncut) criterion (Shi & Malik, 2000):4. convenience, showing segmentations fragment level, segmentationsactually sentence level.5. earlier work (Joty, Carenini, Murray, & Ng, 2010), consider cosine similaritytwo sentences appear together segments. However, later found includingcosine similarity offers 2% absolute gain segmentation performance.534fiTopic Segmentation Labeling Asynchronous ConversationsN cutk (V ) =cut(A1 , V A1 ) cut(A2 , V A2 )cut(Ak , V Ak )++ +assoc(A1 , V )assoc(A2 , V )assoc(Ak , V )(6)A1 , A2 Ak form partition (i.e., disjoint sets nodes) graph,V Ak set difference V (i.e., set nodes) Ak . cut(A, B)measures total edge weight nodes set nodes set B,assoc(A, V ) measures total edge weight nodes set nodesgraph. formally:cut(A, B) =Xw(u, v)(7)w(u, t)(8)uA,vBassoc(A, V ) =XuA,tVNote partitioning problem solved using correlation clusteringmethod (e.g., Bansal, Blum, & Chawla, 2002). Previous work graph-based topicsegmentation (Malioutov & Barzilay, 2006) shown Ncut criterionappropriate cut criterion, accounts total edge weightconnecting B, therefore, favors cutting small sets isolated nodesgraph. However, solving Ncut NP-complete. Hence, approximate solutionfollowing method proposed Shi Malik, (2000), time efficientsuccessfully applied image segmentation computer vision.Notice approach makes difference FQG conversation contains one path. fact, corpora found average number paths7.12 16.43 per email blog conversations, respectively.LDA FQG (LDA+FQG)key advantage probabilistic Bayesian models, LDA, allow usincorporate multiple knowledge sources coherent way form priors (orregularizer). incorporate FQG LDA, propose regularize LDA twosentences adjacent fragments likely appear topical cluster.first step towards aim regularize topic-word distributions (i.e., b Figure3) word network two connected words get similar topic distributions.now, assume given word network undirected graph G(V, E),nodes V representing words edges (u, v)E representing links wordsu v. want regularize topic-word distributions LDA two connectedwords u v word network similar topic distributions (i.e., bk (u) bk (v)k = 1 . . . K). standard conjugate Dirichlet prior Dir(bk |), however allow usthat, words share common variance parameter, mutuallyindependent except normalization constraint (Minka, 1999). Recently, Andrzejewski, Zhu,Craven (2009) describe method encode must-links cannot-links535fiJoty, Carenini, & Ngwords using Dirichlet Forest prior. goal encode must-links. Therefore,reimplemented model capability encoding (must-)links.Must-links words (a, b), (b, c), (x, y) Figure 5(a) encodedLDA using Dirichlet Tree (DT) prior. Like traditional Dirichlet, DT prioralso conjugate multinomial, different parameterization. Insteadrepresenting multinomial sample outcome K-sided die, tree representation(e.g., Figure 5(b)), sample (i.e., leaf tree) represented outcome finitestochastic process. probability leaf (i.e., word case) product branchprobabilities leading leaf. DT prior distribution leaf probabilities.Let n edge weight leading node n, C(n) children node n, Lleaves tree, internal nodes, L(n) leaves subtree noden. generate sample bk DT() drawing multinomial internal nodeDir( C(i) ) (i.e., edge weights node children). probabilitydensity function DT(bk |) given by:(i)!l 1 XDT (bk |)blkbkj(9)iIjL(i)P(i) = jC(i) j , difference in-degree out-degreeinternal node i. Notice (i) = 0 I, DT reduces standard Dirichlet.Suppose given word network shown Figure 5(a). networkdecomposed collection chains (e.g., (a, b, c), (p), (x, y)). chaincontaining multiple elements (e.g., (a, b, c), (x, y)), subtree DT (Figure 5(b)),one internal node (blank Figure) words chain leaves. weightinternal node leaves , regularization strengthparameter standard symmetric Dirichlet prior bk . root nodeDT connects internal nodes |L(i)| weight. leaves (words)single element chains (e.g, (p)) connected root DT directlyweight . Notice = 1, (i) = 0, reduces standard LDA (i.e.,regularization). tuning control strength regularization.3xbppc2bcx(b)(a)Figure 5: (a) Sample word network, (b) Dirichlet Tree (DT) built word network.point left explained construct word network.regularize LDA FQG, construct word network word linkedwords adjacent fragments FQG. Specifically, word wi f ragx536fiTopic Segmentation Labeling Asynchronous Conversationsword wj f ragy wi 6=wj , create link (wi , wj ) x = (x, y)Ef qg , Ef qgset edges FQG. implicitly compels two sentences adjacentfragments similar topic distributions, appear topical segment.3.1.4 Proposed Supervised ModelAlthough unsupervised models discussed previous section key advantagerequiring labeled data, limited ability learn domain-specificknowledge possible large diverse set features (Eisenstein & Barzilay, 2008).Beside discourse cohesion, captures changes content, important domain-specific distinctive features signal topic change. example, discoursemarkers (or cue phrases) (e.g., okay, anyway, now, so) prosodic cues (e.g., longer pause)directly provide clues topic change, shown useful featurestopic segmentation monolog synchronous dialog (Passonneau & Litman, 1997; Galleyet al., 2003). hypothesize asynchronous conversations also featuredistinctive characteristics topic shifts. example, features like sender recipientarguably useful segmenting asynchronous conversations, different participantsless active discussion different topics. Therefore, next stepbuild even accurate topic segmentation model asynchronous conversations,propose combine different sources possibly useful information principled way.supervised framework serves viable option combine large number features optimize relative weights decision making, relies labeled datatraining. amount labeled data required achieve acceptable performancealways important factor consider choosing supervised vs. unsupervised.work, propose supervised segmentation model outperforms unsupervisedmodels, even trained small number labelled conversations.supervised model built graph-theoretic framework usedmany NLP tasks, including coreference resolution (Soon, Ng, & Lim, 2001) chatdisentanglement (Elsner & Charniak, 2010). method works two steps.Classification: binary classifier trained labeled dataset, markspair sentences given conversation different topics.Graph partitioning: weighted undirected graph G = (V, E) formed,nodes V represent sentences conversation edge-weights w(x, y)denote probability (given classifier) two sentences x appeartopic. optimal partition extracted.Sentence pair classificationclassifiers accuracy deciding whether pair sentences xdifferent topics crucial models performance. Note since sentencepair conversation defines data point, conversation containing n sentences gives1+2+. . .+(n-1)= n(n1)= O(n2 ) training examples. Therefore, training dataset containing2Pm ni (ni 1)conversations gives i=1training examples, ni number sentences2thconversation. quadratic expansion training examples enables classifierachieve best classification accuracy labeled conversations.537fiJoty, Carenini, & Ngpairing sentences email conversation email corpus, gottotal 14, 528 data points 58.8% class (i.e.,likely email), pairing sentences blog conversation blogcorpus, got total 572, 772 data points 86.3% different class (i.e.,different likely blog).6 select best classifier, experimentedvariety classifiers full feature set (Table 2). Table 1 shows performanceclassifiers averaged leave-one-out procedure, i.e., corpus containingconversations, train 1 conversations test rest.ClassifierKNNLRLRRMLR (rbf)SVM (lin)SVM (rbf)Majority classTypeRegularizernon-parametricparametricparametricnon-parametricparametricnon-parametric-l2l1l2-Accuracy (Blog)TrainTest62.7%61.4 %90.8% 91.9%86.8%87.6%91.7%82.0%76.6%78.7 %80.5%77.9%86.3% (different)Accuracy (Email)TrainTest54.6%55.2%71.7%72.5%69.9%67.7%91.1%62.1%68.3%69.6%75.9%67.7%58.8% (same)Table 1: Performance classifiers using full feature set (Table 2). trainingset, regularizer strength (or C SVMs) learned 10-fold cross validation.K-Nearest Neighbor (KNN) performs poorly. Logistic Regression (LR) l2regularizer delivers highest accuracy datasets. Support Vector Machines (SVMs)(Cortes & Vapnik, 1995) linear rbf kernels perform reasonably well,well LR. Ridged Multinomial Logistic Regression (RMLR) (Krishnapuram et al.2005), kernelized LR, extremely overfits data. opted LR l2 regularizerdelivers best performance term accuracy, alsoefficient. limited memory BFGS (L-BFGS) fitting algorithm used LR efficientterms time (quadratic convergence rate; fastest among listed models) space(O(mD), memory parameter L-BFGS number features).Table 2 summarizes full feature set mean test set accuracy (using leave-oneout procedure) achieved different types features LR classifier.Lexical features encode similarity two sentences x based rawcontent. Term frequency-based similarity widely used feature previous work, e.g.,TextTiling (Hearst, 1997). compute feature considering two analysis windows,fixed size k. Let X window including sentence x preceding k 1sentences, window including sentence following k 1 sentences.measure cosine similarity two windows representing vectorsTF.IDF (Salton & McGill, 1986) values words. Another important domain specificfeature proved useful previous research (e.g., Galley et al., 2003) cue words(or discourse markers) sign presence topic boundary (e.g., coming up, joiningus news). Since work concerns conversations (not monologs), adopt cue word6. See Section 4 detailed description corpora. class labels produced takingmaximum vote three annotators.538fiTopic Segmentation Labeling Asynchronous ConversationsLexicalAccuracy: 86.8 Precision: 62.4 Recall: 4.6 (Blog)Accuracy: 59.6 Precision: 59.7 Recall: 99.8 (Email)F IDF1F IDF2Cue WordsQATF.IDF-based similarity x window size k=1.TF.IDF-based similarity x window size k=2.Either x contains cue word.x asks question explicitly using ? answers using(yes, yeah, okay, ok, no, nope).Either x greeting word (hi, hello, thanks, thx, tnx, thank.)GreetConversationAccuracy: 88.2 Precision: 81.6 Recall: 20.5 (Blog)Accuracy: 65.3 Precision: 66.7 Recall: 85.1 (Email)GapSpeakerF QG1gap x number sentence(s).x sender (yes no).Distance x FQG terms fragment id.(i.e., |f rag id(y) f rag id(x)|).Distance x FQG terms number edges.Distance x FQG number edgestime considering undirected graph.whether x comment one replyother.x mentions ys speaker vice versa.F QG2F QG3Same/ReplyNameTopicAccuracy: 89.3 Precision: 86.4 Recall: 17.3 (Blog)Accuracy: 67.5 Precision: 68.9 Recall: 76.8 (Email)LSA1LSA2LDALDA+FQGLCSegLCSeg+FQGLexCohLSA-based similarity x window size k=1.LSA-based similarity x window size k=2.LDA segmentation decision x (same different).LDA+FQG segmentation decision x (same different).LCSeg segmentation decision x (same different).LCSeg+FQG segmentation decision x (same different).Lexical cohesion x y.CombinedAccuracy: 91.9 Precision: 78.8 Recall: 25.8 (Blog)Accuracy: 72.5 Precision: 70.4 Recall: 81.5 (Email)Table 2: Features average performance testsets (using leave-one-out).539fiJoty, Carenini, & Nglist derived automatically meeting corpus Galley et al. (2003). answersgreets x likely topic. Therefore, use QuestionAnswer (QA) pairs greeting words two lexical features.Conversational features capture conversational properties asynchronous conversation. Time gap speaker commonly used features segmenting synchronousconversations (e.g., Galley et al. 2003). encode similar information asynchronous media counting number sentences x (in temporal order)gap, senders speakers. strongest baseline Speaker (see Section 5.1)also proves effectiveness asynchronous domains. results Section 5.1 also suggestfine conversational structure form FQG beneficial incorporated unsupervised segmentation models. encode valuable informationsupervised segmentation model computing three distance features FQG:F QG1 , F QG2 , F QG3 . State-of-the-art email blog systems use reply-to relationgroup comments threads. ys comment reply xs comment,likely two sentences talk topic. Participants sometimes mention others name multi-party conversations make disentanglement easier (Elsner& Charniak, 2010). also use feature supervised segmentation model.Topic features complex encode topic information existing segmentationmodels. Choi et al. (2001) used Latent Semantic Analysis (LSA) measure similaritytwo sentences showed LSA-based similarity yields better resultsdirect TF.IDF-based similarity since surmounts problems synonymy (e.g., car,auto) polysemy (e.g., money bank, river bank). compute LSA, first constructword-document matrix W conversation, Wi,j = frequency wordcomment j IDF score word i. perform truncated Singular Value Decomposition(SVD) W : W Uk k VkT , represent word k dimensional7 vector ki .sentence represented weightedsum word vectors. Formally, LSAPkrepresentation sentence =tf.i , tfi = term frequencyword sentence s. like TF.IDF-based similarity, compute LSAbased similarity sentences x y, time representing correspondingwindows (i.e., X ) LSA vectors.segmentation decisions LDA, LDA+FQG, LCSeg LCSeg+FQG modelsdescribed previous section also encoded topic features.8 described Section 3.1.1, LCSeg computes lexical cohesion (LexCoh) function two consecutivewindows based scores lexical chains. Galley et al. (2003) shows significantimprovement function used feature supervised (sequential) topicsegmentation model meetings. However, since problem topic segmentationsequential, want compute function two given windows X (notnecessary consecutive). that, first extract lexical chains scoresspans (i.e., beginning end sentence numbers) conversation. lexical cohesionfunction computed method described Equation 1.7. study, k empirically set 14 number comments based held-out development set.8. earlier work (Joty, Carenini, Murray, & Ng, 2011) include segmentation decisionsLDA+FQG LCSeg+FQG models features. However, including features improvesclassification accuracy segmentation accuracy.540fiTopic Segmentation Labeling Asynchronous Conversations0.350.30.250.20.150.1EmailBlogLCSegLCSeg+FQGLexCohLDA+FQGLDALSA2LSA1NameSame/ReplyF QG2F QG3F QG1GapSpeakerQAGreetCueF.IDF2F.IDF15 1020Figure 6: Relative importance features averaged leave-one-out.describe classifiers performance terms raw accuracy (correct decisions/total),precision recall class different types features averaged leaveone-out procedure (Table 2). Among feature types, topic features yield highestaccuracy same-class precision corpora (p < 0.01).9 Conversational features alsoproved important achieve higher accuracy lexical features (p < 0.01).Lexical features poor accuracy, slightly higher majority baselinealways picks likely class. However, combine features, getbest performance (p < 0.005). results demonstrate importance topicalconversational features beyond lexical features used existing segmentationmodels. compare performance two corpora, noticeblog accuracy same-class precision higher email, same-classrecall much lower. Although reasonable given class distributions twocorpora (i.e., 13.7% 58.8% examples same-class blog email, respectively), surprisingly, tried deal problem applying baggingtechnique (Breiman, 1996), performance improve significantly. Noteclassification errors occurred sentence-pair classification phase recoveredgraph partitioning step (see below). reason incorrect decisionsoutvoted nearby sentences clustered correctly.analyze contribution individual features. Figure 6 shows relativeimportance features based absolute values coefficients LRclassifier. segmentation decision LCSeg+FQG important featuredomains. Same/Reply also effective feature, especially blog. blog,Speaker feature also plays important role. F QG2 (distance number edgesdirected FQG) also effective domains, especially email. twofeatures FQG (F QG1 , F QG3 ) also relevant email.Finally, order determine many annotated conversations need achievebest segmentation performance, Figure 7 shows classification error rate (incorrectdecisions/total), tested 5 randomly selected conversations trained increasing9. tests statistical significance performed using paired t-test.541fiJoty, Carenini, & NgClassification error ratenumber randomly added conversations. classifier appears achieve best performance small number labeled conversations. blog, error rate flattens8 conversations, email, happens 15. surprisingsince blog conversations much longer (an average 220.55 sentences) email conversations (an average 26.3 sentences), generating similar number training examplesconversations (recall, n sentences get O(n2 ) training examples).5045403530252015105EmailBlog246810121416182022242628303234Number training conversationsFigure 7: Error rate vs. number training conversations.Graph partitioningGiven weighted undirected graph G = (V, E), nodes V represent sentencesedge-weights w(x, y) denote probability (given classifier) twosentences x appear topic, formulate segmentation taskk-way-mincut graph partitioning problem intuition sentences segmentdiscuss topic, sentences different segments discuss differenttopics. optimize normalized cut criterion (i.e., equation 6) extract optimalpartition done consolidating various segments LCSeg+FQG.3.2 Topic Labeling Modelsmethods automatically identify topical segments asynchronous conversation, next step pipeline generate one informativedescriptions topic labels segment facilitate interpretations topics.first address problem asynchronous conversation.Ideally, topic label meaningful, semantically similar underlying topic,general discriminative (when multiple topics) (Mei et al., 2007). Traditionally,top k words multinomial topic model like LDA used describe topic. However,pointed Mei et al., word-level, topic labels may become genericimpose cognitive difficulties user interpret meaning topic associatingwords together. example, Figure 2, without reading text, words{release, free, reaction, Daggerfall}, may difficult user understandtopic Daggerfalls free release peoples reaction it. hand,labels expressed sentence-level, may become specific cover542fiTopic Segmentation Labeling Asynchronous Conversationswhole theme topic (Mei et al., 2007). Based observations, recent studies(e.g., Mei et al., 2007; Lau et al., 2011) advocate phrase-level topic labels,also consistent monolog corpora built part Topic DetectionTracking (TDT) project10 . Note also observe preference phrase-level labelswithin asynchronous conversational corpora human annotators withoutspecific instructions spontaneously generated topic labels phrase-level. Consideringthis, treat phrase-level target level granularity topic label.problem different problem keyphrase indexing (Medelyan,2009) task find set keyphrases either given textcontrolled vocabulary (i.e., domain-specific terminologies) describe topics coveredtext. setting, controlled vocabulary. Furthermore,exploiting generic knowledge bases like Wikipedia source devising controlledvocabulary (Medelyan, 2009) viable option case since topics specific particular discussion (e.g., Free release Daggerfall reaction, Game contentssize Figure 2). fact, none human-authored labels developement setappears verbatim Wikipedia. propose generate topic labels using keyphraseextraction approach identifies representative phrase(s) given text.adapt graph-based unsupervised ranking framework, domain independent,without relying labeled data achieves state-of-the-art performance keyphraseextraction (Mihalcea & Radev, 2011). Figure 8 shows topic labeling framework. Given(topically) segmented conversation, system generates k keyphrases describetopic conversation. discuss different components system.Word RankingwordsSegmentedinput conversationSegment-levelRankingtop wordsPhraseGenerationPreprocessorConversation-levelRankingtop wordsconversationlevel phrasesSegment-levelphrasesk output phrasesRedundancyCheckingrelevantphrasesConversation-levelPhrase RerankingFigure 8: Topic labeling framework asynchronous conversation.3.2.1 Preprocessingpreprocessing step, tokenize text apply syntactic filter selectwords certain part-of-speech (POS). use state-of-the-art tagger11 tokenize10. http://projects.ldc.upenn.edu/TDT/11. Available http://cogcomp.cs.illinois.edu/page/software543fiJoty, Carenini, & Ngtext annotate tokens POS tags. experimented five differentsyntactic filters. select (i) nouns, (ii) nouns adjectives, (iii) nouns, adjectivesverbs, (iv) nouns, adjectives, verbs adverbs, (v) words, respectively.filters also exclude stopwords. second filter, selects nouns adjectives,achieves best performance development set, also consistentfinding Mihalcea Tarau (2004). Therefore, syntactic filter used system.3.2.2 Word Rankingwords selected preprocessing step correspond nodes graph. directapplication ranking method described Mihalcea Tarau (2004) would defineedges based co-occurrence relation respective words, applyPageRank (Page et al., 1999) algorithm rank nodes. argue co-occurrencerelations may insufficient finding topic labels asynchronous conversation.better identify labels one needs consider aspects specific asynchronousconversation. particular, propose exploit two different forms conversation specificinformation graph-based ranking model: (1) informative clues leadingsentences topical segment, (2) fine-grained conversational structure (i.e.,Fragment Quotation Graph (FQG)) asynchronous conversation. following,describe two novel extensions turn.Incorporating Information Leading Sentencesgeneral, leading sentences topic segment carry informative clues topiclabels, since speakers likely try signal topic shiftintroduce new topic. key observation especially true asynchronousconversations, topics interleaved less structured. example, Figure 2,notice almost every case, leading sentences topical segments coversinformation conveyed labels. property confirmed Figure 9,shows percentage non-stopwords human-authored labels appear leadingsentences segments development set. first sentence covers 29%38% words gold labels blog email corpora, respectively. firsttwo sentences cover around 35% 45% words gold labels blog email,respectively. consider first three sentences, coverage raises 39%49% blog email, respectively. increment less add sentences.leverage useful information ranking model, propose followingbiased random walk model, P (w|Uk ), score word w given set leadingsentences Uk topic segment k, expressed convex combination relevanceleading sentences Uk (i.e., (w|Uk )) relatedness words segment:P (w|Uk ) = PX(w|Uk )e(y, w)P+ (1 )P (y|Uk )zCk (z|Uk )zCk e(y, z)(10)yCkvalue (0 1), call bias, trade-off twocomponents set empirically. higher values , give weightwords relevance leading sentences compared relatedness words544fiTopic Segmentation Labeling Asynchronous Conversations5550EmailBlog44.8645402542.0152.9444.5738.9838.0834.73353050.6548.9528.74OneTwoFourThreeFiveFigure 9: Percentage words human-authored labels appearing leading sentencestopical segments.segment. Here, Ck set words segment k, represents nodesgraph. denominators components normalization. define (w|Uk ) as:(w|Uk ) = log(tfwUk + 1).log(tfwk + 1)(11)tfwUk tfwk number times word w appears Uk segment k, respectively. similar model proven successful measuring relevance sentencequery query-based sentence retrieval (Allan, Wade, & Bolivar, 2003).Recall multiple topics conversation, requirement topiclabels labels different topics discriminative (or distinguishable) (Meiet al., 2007). implicitly indicates high scoring word one segmenthigh scores segments conversation. Keeping criterion mind,define (undirected) edge weights e(y, w) equation 10 follows:ke(y, w) = tfw,ylogKk00.5 + tfw,y(12)kK denotes number topics (or topic segments) conversation, tfw,y0ktfw,y number times words w co-occur window size segmentk segments except k conversation, respectively. Notice measuresimilar spirit TF.IDF metric (Salton & McGill, 1986), co-occurrencelevel. co-occurrence relationship words captures syntactic dependencieslexical cohesion text, also used Mihalcea Tarau (2004).12Equation 10 written matrix notation as:= [Q + (1 )R]T = ,Q R square matrices Qi,j =(13)P (j|Uk )zC (z|Uk )i, Ri,j =kP e(i,j),jC e(i,j)respectively. Notice stochastic matrix (i.e., rows add 1),ktherefore, treated transition matrix Markov chain. assume12. Mihalcea Tarau (2004) use unweighted graph key phrase extraction. However, experiments, get better results weighted graph.545fiJoty, Carenini, & Ngword state Markov chain, Ai,j specifies transition probability statestate j corresponding Markov chain. Another interpretation givenbiased random walk graph. Imagine performing random walk graph,every time step, probability , transition made wordsrelevant leading sentences probability 1 , transition maderelated words segment. Every transition weighted according correspondingelements Q R. vector looking stationary distributionMarkov chain also (normalized) eigenvector eigenvalue 1. Markovchain unique stationary distribution ergodic (Seneta, 1981).ensure Markov chain property reserving small probability jumpingstate current state (Page et al., 1999).13 larger matrices,efficiently computed iterative method called power method.Incorporating Conversational StructureSection 3.1, described fine conversation structure form FragmentQuotation Graph (FQG) effectively exploited topic segmentation models.hypothesize topic labeling model also benefit FQG. previouswork email summarization (Carenini et al., 2008), applied PageRank FQGmeasure importance sentence demonstrated benefits using FQG.finding implies important node FQG likely cover important aspecttopics discussed conversation. intuition that, topic label,keyword co-occur keywords, also comeimportant fragment FQG. believe mutually reinforcing relationshipFQG Word Co-occurrence Graph (WCG) reflectedrankings. proposal implement idea process co-ranking (Zhou etal., 2007) heterogeneous graph, three random walks combined together.Let G = (V, E) = (VF VW , EF EW EF W ) heterogeneous graph fragmentswords. shown Figure 10, contains three sub-graphs. First, GF = (VF , EF )unweighted directed FQG, VF denoting set fragments EF denoting setdirected links fragments. Second, GW = (VW , EW ) weighted undirectedWCG, VW set words segment EW set edge-weightsdefined equation 12. Third, GF W = (VF W , EF W ) weighted bipartite graphties GF GW together representing occurrence relations wordsfragments. Here, VF W = VF VW , weighted undirected edges EF W connectfragment vf VF word vw VW , weight representing number timesword vw occurs fragment vf .co-ranking framework combines three random walks, one GF , one GWone GF W . Let F W denote transition matrices (intra-class) random walksGF GW , respectively, f w denote respective stationary distributions.Since, GF W bipartite graph, (inter-class) random walk GF W describedtwo transition matrices, F W|VF ||VW | W F|VW ||VF | . One intra-class step changesprobability distribution (f, 0) (F f, 0) (0, w) (0, W w), one inter13. simplicity, make random jump component explicit equations. But, readerskeep mind transition matrices described article contain component.546fiTopic Segmentation Labeling Asynchronous ConversationsGWGFFigure 10: Three sub-graphs used co-ranking: fragment quotation graph GF ,word co-occurrence graph GW , bipartite graph GF W ties two together.Blue nodes represent fragments, red nodes represent words.class step changes distribution (f, w) (W F w, F W f ) (for details see Zhou,Orshanskiy, Zha, & Giles, 2007). coupling regulated parameter (0 1)determines extent ranking words fragments dependother. Specifically, two update steps power method are:f t+1 = (1 ) (F f ) + W F (F W W F )wtwt+1= (1 ) (W w ) + F W (W F F W )f(14)(15)described co-ranking framework assuming WCGcorresponding FQG. However, recall WCG built topic segment,FQG described far (Figure 4) based whole conversation. order constructFQG topic segment conversation, take fragments (and edges)conversation-level FQG include sentences segment.operation two consequences. One, conversation-level fragments may pruned.Two, sentences conversation-level fragment may discarded. example,FQG topic (segment) ID 1 Figure 2 includes fragments a, h, i, j, l,edges them. Fragment j, contains three sentences conversation-levelFQG, contains one sentence FQG topic ID 1.3.2.3 Phrase Generationranked list words describing topical segment, select topkeywords constructing keyphrases (labels) keywords. take similarapproach Mihalcea Tarau (2004). Specifically, mark selected keywordstext, collapse sequences adjacent keywords keyphrases. example,consider first sentence, .. 15th anniversary Elder Scrolls series .. Figure 2.Elder, Scrolls series selected keywords, since appear adjacent text,547fiJoty, Carenini, & Ngcollapsed one single keyphrase Elder Scrolls series. score keyphrasedetermined taking maximum score constituents (i.e., keywords).Rather constructing keyphrases post-processing phase, do,alternative approach first extract candidate phrases using either n-gram sequenceschunker preprocessing, rank candidates (e.g., Medelyan, 2009;Hulth, 2003). However, determining optimal value n n-gram sequenceissue, including possible n-gram sequences ranking excessively increasesproblem size. Mei et al. (2007) also show using chunker leads poor results dueinaccuracies chunker, especially applied new domain like ours.3.2.4 Conversation-Level Phrase Re-rankingfar, extracted phrases topic segment ignoring restconversation. method fails find label constituents appear outsidesegment. example, Blog corpus, phrase server security humanauthored label server security firewall appear topical segment,appears whole conversation. fact, development set, 14% 8%words blog email labels, respectively, come part conversationoutside topic segment. Thus, propose extract informative phraseswhole conversation, re-rank respect individual topics (or segments)combine relevant conversation-level phrases segment-level ones.rank words whole conversation applying ranking models describedSection 3.2.2 extract phrases using method described Section 3.2.3. Noteapply biased random walk model whole conversation,concept leading sentences distinction topics. Therefore, applywhole conversation, adjust biased random walk model (Equation 10) follows:P (w) =Xe(y, w)P (y)zCk e(y, z)PyCk(16)e(y, w) = tfw,y , number times words w co-occur window sizeconversation. hand, co-ranking framework, applied wholeconversation, combines two conversation-level graphs: FQG, WCG.re-rank phrases extracted whole conversation respect particulartopic conversation, reuse score words topic segment (givenranking models Section 3.2.2). before, score (conversation-level) phrasedetermined taking maximum (segment-level) score constituents (words).word occur topic segment, score assumed 0.3.2.5 Redundancy Checkingranked list labels (keyphrases), last step produce finalk labels output. selecting multiple labels topic, expect new labelsdiverse without redundant information achieve broad coverage topic.use Maximum Marginal Relevance (MMR) (Carbonell & Goldstein, 1998) criterionselect labels relevant, redundant. Specifically, select labels oneone, maximizing following MMR criterion time:548fiTopic Segmentation Labeling Asynchronous Conversationsl = argmaxlW [ Score(l) (1 ) maxlS Sim(l, l)](17)W set labels set labels already selected output.define similarity two labels l l as: Sim(l, l) = /nl ,number overlapping (modulo stemming) words l l, nl numberwords l. parameter (0 1) quantifies amount redundancy allowed.4. Corpora MetricsDue lack publicly available corpora asynchronous conversations annotatedtopics, developed first corpora annotated topic information.4.1 Data Collectionemail, selected publicly available BC3 email corpus (Ulrich, Murray, & Carenini,2008) contains 40 email conversations World Wide Web Consortium (W3C)mailing list14 . BC3 corpus, previously annotated sentence-level speech acts, subjectivity, extractive abstractive summaries, one growing number corporaused email research (Carenini et al., 2011). average 5 emails per conversation total 1024 sentences excluding quoted sentences. conversationalso provides thread structure based reply-to relations emails.blog, manually selected 20 conversations various lengths, short enoughstill feasible humans annotate, popular technology-related news websiteSlashdot15 . Slashdot selected provides reply-to links comments,allowing accurate thread reconstruction, since comments moderated userssite, expected decent standard. conversation Slashdot beginsarticle (i.e., short synopsis paragraph possibly link original story),followed lengthy discussion section containing multiple threads commentssingle comments. unlike email conversation contains single threademails. main article assumed root conversation tree (basedreply-to), threads single comments form sub-trees tree.blog corpus, total 4, 411 sentences. total number comments perblog conversation varies 30 101 average 60.3, number threads perconversation varies 3 16 average 8.35 number single commentsvaries 5 50 average 20.25.4.2 Topic AnnotationTopic segmentation labeling general nontrivial subjective task evenhumans, particularly text unedited less organized (Purver, 2011).conversation phenomenon called Schism makes even challenging conversations.schism, new conversation takes birth existing one, necessarilytopic shift participants refocus attention onto other,14. http://research.microsoft.com/en-us/um/people/nickcr/w3c-summary.html15. http://slashdot.org/549fiJoty, Carenini, & Ngaway whoever held floor parent conversation (Sacks, Schegloff, & Jefferson,1974). example email conversation shown Figure 1, schism takes placeparticipants discuss topic responding I18N. annotators agree facttopic responding I18N swerves topic TAG document.properly design effective annotation manual procedure, performed twophase pilot study carrying actual annotation. initial annotation manualinspired AMI annotation manual used topic segmentation ICSI meetingtranscripts16 . pilot study, selected two blog conversations Slashdot fiveemail conversations W3C corpus. Note conversations pickedcorpora. Later experiments use conversations developmentset tuning different parameters computational models. first phasepilot study five computer science graduate students volunteered annotation,generating five different annotations conversation. revised annotationmanual based feedback detailed analysis possible sources disagreement.second phase, tested procedure university postdoc annotation.prepared two different annotation manuals one email one blog. chosemainly two reasons. (i) discussed earlier, email blog conversationsstructurally different specific characteristics. (ii) email corpusalready annotations (e.g., abstract summaries) could reuse topicannotation, whereas blog corpus brand new without existing annotation.actual annotation recruited paid three cognitive science fourth yearunder-graduates, native speakers English also Slashdot bloggers. average,took 7 28.5 hours annotate 40 email 20 blog conversations,respectively. all, three different annotations conversation corpora.blog conversations, task finding topics carried four steps:1. annotators read conversation (i.e., article, threads comments singlecomments) wrote short summary ( 3 sentences) threads.2. provided short high-level descriptions topics discussed conversation(e.g., Game contents size, Bugs faults). descriptions serve referencetopic labels work. target number topics labels givenadvance instructed find many topics neededconvey overall content conversation.3. assigned appropriate topic sentence. However, sentencecovered one topic, labeled relevant topics accordingorder relevance. used predefined topic OFF-TOPIC sentencefit topic. Wherever appropriate also used two predefinedtopics: INTRO (e.g., hi X) END (e.g., Best, X).4. annotators authored single high-level 250 words summary whole conversation. step intended help remember anything mayforgotten revise annotations previous three steps.16. http://mmm.idiap.ch/private/ami/annotation/TopicSegmentationGuidelinesNonScenario.pdf550fiTopic Segmentation Labeling Asynchronous Conversationsemail conversation BC3, already three human-authored summaries.So, along actual conversations, provided annotators summariesgive brief overview discussion. reading conversation associatedsummaries, performed tasks 2 3 procedure follow annotatingblogs. annotators carried tasks paper. created hierarchical threadview conversation based reply-to relations comments (or emails)using indentations printed participants information different color Gmail.email corpus, three annotators found 100, 77 92 topics respectively (269total), blog corpus, found 251, 119 192 topics respectively (562total). Table 3 shows basic statistics computed three annotationsconversations.17 average, 26.3 sentences 2.5 topics per email conversation,220.55 sentences 10.77 topics per blog conversation. average, topic emailconversations contains 12.6 sentences, topic blog conversations contains 27.16sentences. average number topics active time 1.4 5.81 emailblog conversations, respectively. average entropy corresponds granularityannotation (as described next Section) 0.94 email conversations 2.62blog conversations. statistics (i.e., number topics topic density)indicate substantial amount segmentation (and labeling) do.NumberNumberAverageAverageEntropysentencestopicstopic lengthtopic densityMeanEmail Blog26.3220.552.510.7712.627.161.45.810.942.62MaxEmail Blog554307233561.173.110.122.73.42MinEmail Blog1310515311.6712.7501.58Table 3: Statistics three human annotations per conversation.4.3 Evaluation (and Agreement) Metricssection describe metrics used compare different annotations. metricsmeasure much annotators agree other, well modelsvarious baselines perform. given conversation, different annotationsdifferent numbers topics, different topic assignments sentences (i.e., clustering)different topic labels. describe metrics used measure segmentationperformance followed metrics used measure labeling performance.4.3.1 Metrics Topic Segmentationdifferent annotations group sentences different numbers clusters, agreementmetrics widely used supervised classification, statistic F1 score,applicable. Again, problem topic segmentation asynchronous conversation17. got 100% agreement two predefined topics INTRO END. Therefore, computations excluded sentences marked either INTRO END.551fiJoty, Carenini, & Ngsequential nature. Therefore, standard metrics widely used sequential topicsegmentation monolog synchronous dialog, Pk (Beeferman, Berger, &Lafferty, 1999) W indowDif f (W D) (Pevzner & Hearst, 2002), also applicable.Rather, one-to-one local agreement metrics described Elsner Charniak(2010) appropriate segmentation task.one-to-one metric measures global agreement two annotations pairingtopical segments two annotations way (i.e., computing optimalmax-weight bipartite matching) maximizes total overlap, reportspercentage overlap. local agreement metric lock measures agreement within contextk sentences. compute loc3 score m-th sentence two annotations,consider previous 3 sentences: m-1, m-2 m-3, mark eitherdifferent depending topic assignment. loc3 score two annotationsmean agreement different judgments, averaged sentences.See Appendix detailed description metrics concrete examples.report annotators agreement found one-to-one loc3 metrics Table 4.human annotation, measure agreement two human annotationsseparately, report mean agreements. email, get high agreementmetrics, though local agreement (average 83%) little higher global one(average 80%). blog, annotators high agreement loc3 (average 80%),disagree one-to-one (average 54%). low one-to-one agreementblog quite acceptable since blog conversations much longer less focusedemail conversations (see Table 3). analyzing two corpora also noticedblogs, people informal often make implicit jokes (see Figure 2). result,segmentation task blogs challenging humans well models.Note similar annotation task chat disentanglement, Elsner Charniak (2010)report average one-to-one score 53%. Since one-to-one score naive baselines (seeSection 5.1) much lower human agreement, metric differentiates human-likeperformance baseline. Therefore, computing one-to-one correlation humanannotations legitimate evaluation models.one-to-oneloc3MeanEmail Blog80.454.283.280.1MaxEmail Blog100.084.1100.094.0MinEmail Blog31.325.343.763.3Table 4: Annotator agreement one-to-one loc3 two corpora.analyze source disagreement annotation, find farfrequent reason one observed Elsner Charniak (2010)chat disentanglement task; namely, annotators specific (i.e., fine) others(i.e., coarse). determine level specificity annotation, similarly ElsnerCharniak, use information-theoretic concept entropy. consider topicrandomly picked sentence conversation random variable X, entropy H(X)measures level details annotation. topics k length nkconversation length N , compute H(X) follows:552fiTopic Segmentation Labeling Asynchronous ConversationsH(X) =KXnkk=1Nlog2nkN(18)K total number topics (or topical segments) conversation.entropy gets higher number topics increases topics evenly distributedconversation. corpora, varies 0 2.7 email conversations1.58 3.42 blog conversations (Table 3). variations demonstrate differencesspecificity different annotators, determine agreement generalstructure. quantify this, use many-to-one metric proposed ElsnerCharniak (2010). maps source clusters single target clustergets highest overlap, computes total percentage overlap.metric asymmetrical, used performance evaluation.18 However,provides insights annotation specificity. example, one splits clusteranother annotator multiple sub-clusters then, many-to-one score finecoarse annotation 100%. corpora, mapping fine (high-entropy) coarse(low-entropy) annotation get high many-to-one score, average 95% emailconversations average 72% blog conversations (Table 5). suggestsfiner annotations mostly scopic boundaries coarser ones.many-to-oneMeanEmail Blog94.972.3MaxEmail Blog10098.2MinEmail Blog61.151.4Table 5: Annotator agreement many-to-one two corpora.4.3.2 Metrics Topic LabelingRecall extract keyphrases text topic labels. Traditionally keyphrase extraction evaluated using precision, recall F-measure based exact matchesextracted keyphrases human-assigned keyphrases (e.g., Mihalcea Tarau,2004; Medelyan et al., 2009). However, noted approach based exactmatches underestimates performance (Turney, 2000). example, comparedreference keyphrase Game contents size, credible candidate keyphrase Game contents gets evaluated wrong metric. Therefore, recent studies (Zesch & Gurevych,2009; Kim, Baldwin, & Kan, 2010a) suggest use n-gram-based metrics accountnear-misses, similar ones used text summarization, e.g., ROUGE (Lin, 2004),machine translation, e.g., BLEU (Papineni, Roukos, Ward, & Zhu, 2002).Kim et al. (2010a) evaluated utility different n-gram-based metrics keyphraseextraction showed metric call mutual-overlap (m-o), correlateshuman judgments.19 Therefore, one metrics use evaluating topic18. One easily optimize assigning different topic source sentences.19. Kim et al. (2010a) call metric R-precision (R-p), different actual definitionR-p keyphrase evaluation given Zesch Gurevych (2009). Originally, R-p precisionmeasured number candidate keyphrases equals number gold keyphrases.553fiJoty, Carenini, & Nglabeling models m-o. Given reference keyphrase pr length (in words) nr , candidatekeyphrase pc length nc , number overlapping (modulo stemming)words pr pc , mutual-overlap formally defined as:mutualoverlap(pr , pc ) =max(nr , nc )(19)metric gives full credit exact matches morphological variants, partial credit two cases overlapping phrases: (i) candidate keyphrase includesreference keyphrase, (ii) candidate keyphrase part referencekeyphrase. Notice m-o defined evaluates single candidate keyphrasereference keyphrase. setting, single reference keyphrase (i.e., topic label)topical cluster, mentioned before, may want models extracttop k keyphrases. Therefore, modify m-o evaluate set k candidate keyphrases Pcreference keyphrase pr follows, calling weighted-mutual-overlap (w-m-o):weightedmutualoverlap(pr , Pc ) =kXi=1S(pic )max(nr , nic )(20)PS(pic ) normalized score (i.e., S(pic ) satisfies 0 S(pic ) 1 ki=1 S(pic ) = 1)i-th candidate phrase pic Pc . k = 1, metric equivalent m-o,higher values k, takes sum k m-o scores, weighted normalized score.w-m-o metric described considers word overlap ignores semantic relations (e.g., synonymy, hypernymy) words. However, annotatorswriting topic descriptions, may use words directly conversation,semantically related. example, given reference keyphrase meeting agenda,lexical semantic variants like meeting schedule meeting plan treatedcorrect. Therefore, also consider generalization w-m-o incorporates lexicalsemantics. define weighted-semantic-mutual-overlap (w-s-m-o) follows:weightedsemanticmutualoverlap(pr , Pc ) =kXi=1Ptr prPtc pic(tr , tc )max(nr , nic )S(pic )(21)(tr , tc ) semantic similarity nouns tr tc . value (tr , tc )0 1, 1 denotes notably high similarity 0 denotes little-to-none. Noticethat, since metric considers semantic similarity possible pairs nouns,value measure greater 100% (when presented percentage). usemetrics (e.g., lin similarity, wup similarity) provided WordNet::Similarity package(Pedersen, Patwardhan, & Michelizzi, 2004) computing WordNet-based similarity,always choose frequent sense noun. results get similar acrosssimilarity metrics. brevity, mention lin similarity article.4.3.3 Metrics End-to-End Evaluationlike human annotators, end-to-end system takes asynchronous conversationinput, finds topical segments conversation, assigns short descriptions554fiTopic Segmentation Labeling Asynchronous Conversations(topic labels) topical segments. would fairly easy compute agreementtopic labels based mutual overlaps, number topics topical segmentsfixed across annotations given conversation. However, since different annotators(system human) identify different number topics different clusteringsentences, measuring annotator (model human) agreement topic labelstrivial task. solve this, first map clusters one annotation (say A1 )clusters another (say A2 ) optimal one-to-one mapping described previoussection. that, compute w-m-o w-s-m-o scores labels mapped(or paired) clusters. Formally, li1 label cluster c1i A1 mappedcluster c2j label lj2 A2 , compute w-m-o(li1 , lj2 ) w-s-m-o(li1 , lj2 ).Table 6 reports human agreement w-m-o w-s-m-o two corpora. Similarsegmentation, get higher agreement labeling metrics email. Plausibly,reasons remain same; length characteristics (e.g., informal, less focused)blog conversations make annotators disagree more. However, note measurescomputed based one-to-one mappings clusters may reflectagreement one would get annotators asked label segments.w-m-ow-s-m-oMeanEmail Blog36.819.942.528.2MaxEmail Blog100.054.2107.360.8MinEmail Blog0.00.00.05.2Table 6: Annotator agreement w-m-o w-s-m-o two corpora.5. Experimentssection present experimental results. First, show performancesegmentation models. show performance topic labeling models basedmanual segmentation. Finally, present performance end-to-end system.5.1 Topic Segmentation Evaluationsection present experimental setup results segmentation task.5.1.1 Experimental Setup Segmentationran six different topic segmentation models corpora presented Section 4.first model graph-based unsupervised segmentation model presented MalioutovBarzilay (2006). Since sequentiality constraint topic segmentation monologsynchronous dialog hold asynchronous conversation, implementmodel without constraint. Specifically, model (call M&B) constructs weightedundirected graph G(V, E), nodes V represent sentences edge weightsw(x, y) represent cosine similarity (Equation 5) sentences x y.finds topical segments optimizing normalized cut criterion (Equation 6). Thus,M&B considers conversation globally, models lexical similarity.555fiJoty, Carenini, & Ngfive models LDA, LDA+FQG, LCSeg, LCSeg+FQG Supervisedmodel (SUP) described Section 3. tunable parameters different modelsset based performance developement set. hyperparametersLDA set default values (=50/K, =0.01) suggested SteyversGriffiths (2007).20 regularization strength LDA+FQG set 20.parameters LCSeg set default values since setting delivers bestperformance development set. fair comparison, set numbertopics per conversation models. least two three annotators agreetopic number, set number, otherwise set floor value average topicnumber. mean statistics six model annotations shown Table 7. Comparingstatistics human annotations Table 3, notice numberswithin bounds human annotations.21EmailBlogTopic numberTopic lengthTopic densityEntropyTopic numberTopic lengthTopic densityEntropyM&B2.4112.411.900.9910.6520.327.382.54LDA2.1013.31.830.9810.6520.329.393.33LDA+FQG1.9015.501.600.7510.6520.328.322.37LCSeg2.4112.411.010.8110.6520.321.002.85LCSeg+FQG2.4112.411.390.9310.6520.325.212.81SUP2.4112.411.420.9810.6520.325.302.85Table 7: Mean statistics different models annotationalso evaluate following baselines, useful model outperform.different sentence conversation constitutes separate topic.whole conversation constitutes single topic.Speaker sentences participant constitute separate topic.Blocks k (= 5, 10, 15, 20, 25, 30): consecutive group k sentencestemporal order conversation constitutes separate topic.5.1.2 Results SegmentationTable 8 presents human agreement agreement models humanannotators corpora. model annotation, measure agreementthree human annotations separately using metrics described Section 4.3.1, reportmean agreements. table, also show performance two best baselinesSpeaker Blocks k.20. performance LDA seem sensitive values .21. Although topic numbers per conversation fixed different models, LDA LDA+FQG mayfind less number topics (see Equation 3 4).556fiTopic Segmentation Labeling Asynchronous ConversationsEmailBlogMean 1-to-1Max 1-to-1Min 1-to-1Mean loc3Max loc3Min loc3Mean 1-to-1Max 1-to-1Min 1-to-1Mean loc3Max loc3Min loc3BaselinesSpeaker Blocks M&B LDAk51.838.362.857.394.377.1 100.0 100.023.414.636.324.364.157.462.454.197.073.1 100.0 100.027.442.636.338.133.532.030.025.261.146.045.342.113.015.618.215.367.052.854.153.087.168.464.365.653.442.345.138.6ModelsLDA+ LCSeg LCSeg SUPFQG+FQG61.562.269.372.3100.0 100.0 100.0 100.024.033.138.042.460.672.072.775.8100.0 100.0 100.0 100.038.440.740.640.428.036.646.748.556.353.667.466.116.123.726.628.455.456.575.177.267.176.089.096.446.343.156.763.2Human80.4100.031.383.2100.043.754.284.125.380.194.063.3Table 8: Topic segmentation performance two best Baselines, Human Models.Blocks k column, k = 5 email k = 20 blog.baselines perform rather poorly. different worst baselinemean one-to-one scores 0.05 0.10, mean loc3 scores 0.47 0.25blog email corpus, respectively. Blocks 5 one best baselines email,performs poorly blog mean one-to-one 0.19 mean loc3 0.54.contrary, Blocks 20 one best baselines blog, performs poorly email.intuitive since average number topics topic length blog conversations(10.77 27.16) much higher email (2.5 12.6). optimalconversations containing one topic, performance rapidly degradesnumber topics increases. mean one-to-one scores 0.29 0.28 mean loc3scores 0.53 0.54 blog email corpora, respectively. Speaker strongestbaseline domains.22 several cases beats under-performing models.email corpus, one-to-one, generally models agree annotatorsbaselines do, less annotators agree other. observesimilar trend local metric loc3 , however metric, models fail beatbest baselines. Notice human agreement annotations quite low (seeMin scores), even lower mean agreement baselines. explained before,due fact human annotations much fine-grained others.blog corpus, agreement global metric (one-to-one) much loweremail corpus. reasons already explained Section 4.3.1. noticesimilar trend metrics under-performing models fail beat baselines,others perform better baselines, worse human annotators.comparison among models reveals general pattern. probabilistic generative models LDA LDA+FQG perform disappointingly corpora. likelyexplanation independence assumption made models computingdistribution topics sentence distributions words causes nearby22. many anonymous authors blog corpus. treated separate author.557fiJoty, Carenini, & Ngsentences (i.e., local context) excessively distributed topics. Another reasoncould limited amount data available training. corpora, averagenumber sentences per blog conversation 220.55 per email conversation 26.3,might sufficient LDA models (Murphy, 2012). compare performance LDA+FQG performance LDA, get significant improvementLDA+FQG metrics corpora (p<0.01). regularizationFQG prevents local context excessively distributed topics.unsupervised graph-based model M&B performs better LDA modelscases (i.e., except loc3 blog) (p < 0.001). However, performance still farperformance top performing models like LCSeg+FQG supervised model.reason even though, constructing complete graph, method considersconversation globally, models lexical similarity disregards importantfeatures asynchronous conversation like fine conversation structure speaker.Comparison LCSeg LDAs M&B reveals LCSeg general bettermodel. LCSeg outperforms LDA wide margin one-to-one two datasetsloc3 email (p < 0.001). difference LCSeg LDA loc3 blog alsosignificant p < 0.01. LCSeg also outperforms M&B cases (p < 0.01) exceptone-to-one email. Since LCSeg sequential model extracts topics keepingcontext intact. helps achieve high loc3 agreement shorter conversations likeemail conversations. But, longer conversations like blog conversations, overdoes(i.e., extracts larger chunks sentences topic segment) gets low loc3 agreement.unsurprising look topic density Table 7 two datasets densitylow blog corpus compared annotators well performing models.Another reason superior performance LDAs M&B could term weightingscheme. Unlike LDAs M&B, consider repetition, LCSeg also considerstightly repetition happens. However, still large gap performanceLCSeg top performing models (LCSeg+FQG, supervised). explainedearlier, topics asynchronous conversation may change sequentially temporalorder sentences. topics interleaved LCSeg fails identify correctly.Furthermore, LCSeg consider important features beyond lexical cohesion.incorporate FQG LCSeg, get significant improvement one-to-onecorpora loc3 blog (p<0.0001). Even though improvement loc3email significant, agreement quite high compared unsupervisedmodels. Overall, LCSeg+FQG best unsupervised model. supports claimsentences connected reply-to relations FQG usually refer topic.Finally, combine features graph-based supervised model (SUPTable 8), get significant improvement LCSeg+FQG metrics acrossdomains (p<0.01). agreements achieved supervised model also much closerhuman annotators. Beside features, improvement might also duefact that, constructing complete graph, model considers relationspossible sentence pairs conversation, believe key requirement topicsegmentation asynchronous conversations.558fiTopic Segmentation Labeling Asynchronous Conversations5.2 Topic Labeling Evaluationsection present experimental evaluation topic labeling modelsmodels provided manual (or gold) segmentation. allows us judgeperformance independently topic segmentation task.5.2.1 Experimental Setup Topic Labelingmentioned Section 4, email corpus, three annotators found 100, 7792 topics (or topical segments) respectively (269 total), blog corpus,found 251, 119 192 topics respectively (562 total). annotators wrote shorthigh-level description topic. descriptions serve reference topic labelsevaluation.23 goal topic labeling models automatically generateinformative descriptions topical segment. compare approachtwo baselines. first baseline FreqBL ranks words according frequencies.second baseline LeadBL, expressed equation 11, ranks words basedrelevance leading sentences topical segment.also compare model two state-of-the-art keyphrase extraction methods.first one unsupervised general TextRank model proposed Mihalcea Tarau(2004) (call M&T) incorporate conversation specific information.second one supervised model Maui proposed Medelyan et al. (2009). Briefly, Mauifirst extracts n-grams maximum length 3 candidate keyphrases.bagged decision tree classifier filters candidates using nine different features. Duelack labeled training data asynchronous conversations, train Maui humanannotated dataset released part SemEval-2010 task 5 automatic keyphraseextraction scientific articles (Kim, Medelyan, Kan, & Baldwin, 2010b). datasetcontains 244 scientific papers ACM digital library, comes set authorassigned reader-assigned keyphrases. total number keyphrases assigned244 articles authors readers 3705.experimented two different versions biased random walk modelincorporates informative clues leading sentences. One, BiasRW, includeconversation-level phrase (Section 3.2.4), one BiasRW+, does.parameter Uk , set leading sentences, empirically set first two sentencesbias parameter set 0.85 based development set.experimented four different versions co-ranking framework dependingtype random walk performed word co-occurrence graph (WCG)whether model includes conversation-level phrases. Let CorGen denoteco-ranking model general random walk WCG, CorBias denote coranking model biased random walk WCG. two models includeconversation-level phrase CorGen+ CorBias+ do. coupling strengthco-occurrence window size empirically set 0.4 2, respectively, baseddevelopment set. dumping factor set default value 0.85.Note models (except Maui) baselines follow preprocessingpost-processing (i.e., phrase generation redundancy checking) steps. value23. Notice setting, topic segment one reference label compare with.Therefore, show human agreement topic labeling task Table 9 10.559fiJoty, Carenini, & Ngphrase generation set 25% total number words cluster,redundancy checking set 0.35 based development set.5.2.2 Results Topic Labelingevaluate performance different models using metrics described Section4.3.2. Table 9 10, respectively, show mean weighted-mutual-overlap (w-m-o)weighted-semantic-mutual-overlap (w-s-m-o) scores percentage different modelsdifferent values k (i.e., number output labels) two corpora.baselines proved strong, beating existing models almost everycase. tells us frequency words topic segment occurrenceleading sentences carry important information topic labeling. Generally speaking,LeadBL better baseline email, blog FreqBL better LeadBL.supervised model Maui worst performer metrics two corpora.performance also consistently low across corpora particular value k.possible explanation Maui trained domain (scientific articles),rather different asynchronous conversations. Another reason may Mauiconsider conversational features.general random walk model M&T also delivers poor performance corpora,failing beat baselines measures. indicates random walk modelbased co-occurrence relations words sufficient finding topiclabels asynchronous conversations. needs consider conversation specific information.incorporating clues leading sentences, biased random walk modelBiasRW improves performance significantly baselines metricsvalues k two corpora (p<0.05). demonstrates usefulness consideringleading sentences information source topic labeling asynchronous conversation.BaselinesModelsFreqBLLeadBLM&TMauiBiasRWBiasRW+CorGenCorGen+CorBiasCorBias+k=1Email Blog22.86 19.0522.41 18.1715.87 18.2310.48 10.0324.77 20.8324.91 23.6517.60 20.7618.32 22.4424.84 20.9625.13 23.83k=2Email Blog17.47 16.1718.94 15.9512.68 14.319.869.5619.78 17.2820.36 19.6915.32 17.6415.86 19.6519.88 17.7320.20 19.97k=3Email Blog14.96 13.8315.92 13.7510.33 12.159.039.2317.38 15.0618.09 17.7615.14 15.7815.46 18.0117.61 16.2218.21 18.33k=4Email Blog13.17 13.4514.36 12.619.6311.388.718.9016.24 14.5316.20 16.7814.23 15.0314.89 16.9016.99 15.6417.15 17.28k=5Email Blog12.06 12.5913.76 11.939.0711.038.508.5315.80 14.2615.78 15.8614.08 14.7514.45 16.1316.81 15.3816.90 16.55Table 9: Mean weighted-mutual-overlap (w-m-o) scores different values k two corpora.general co-ranking model CorGen, incorporating conversation structure,outperforms baselines metrics k blog (p<0.05), failsmany cases email. blog, also significant difference BiasRWCorGen w-m-o k (Table 9), CorGen outperforms BiasRW w-s-m-o (Table10) higher values k (2,3,4,5) (p<0.05). hand, email, BiasRW alwaysoutperforms CorGen metrics k (p<0.05). conclude that, blog,560fiTopic Segmentation Labeling Asynchronous Conversationsexploiting conversation structure seems beneficial leading sentences,whereas email, observe opposite. reason could topic segmentsblog much longer email (average length 27.16 vs. 12.6). Therefore,FQGs blog segments generally larger capture informationFQGs email segments. Besides, email discussions focused blog discussions.leading sentences email segments carry informative clues blogsegments. also confirmed Figure 9, leading sentences email coverhuman-authored words blog.BaselinesModelsFreqBLLead-BLM&TMauiBiasRWBiasRW+CorGenCorGen+CorBiasCorBias+k=1Email Blog23.36 23.5224.99 21.1918.71 22.0814.79 14.1428.87 24.6327.96 24.5123.66 24.6923.50 24.3028.44 25.6627.97 25.26k=2Email Blog20.50 21.0321.69 20.6116.25 19.5913.76 13.6724.76 22.5124.71 23.0521.97 23.8322.09 24.3526.39 24.1526.34 24.19k=3Email Blog19.82 20.1820.40 19.4914.62 17.9113.03 12.8722.48 21.3622.56 22.8821.51 22.8621.96 23.8924.47 23.1824.69 23.60k=4Email Blog18.47 19.5819.57 18.9814.29 17.2712.69 12.1021.67 20.9521.19 22.0820.98 22.3721.36 23.4223.70 22.7623.65 23.44k=5Email Blog17.81 19.2719.17 18.7114.06 16.9211.73 11.5221.28 20.7820.82 21.7320.44 22.2220.90 23.0023.56 22.6723.23 23.20Table 10: Mean weighted-semantic-mutual-overlap scores different values k two corpora.combining two forms conversation specific information single model,CorBias delivers improved performance CorGen BiasRW metrics.email, CorBias significantly better CorGen k metrics (p<0.01).blog, CorBias gets significant improvement BiasRW higher values k (3, 4, 5)metrics (p<0.05). two sources information complementary helpovercome domain-specific limitations respective models. Therefore, oneexploit information sources build generic domain-independent system.include conversation-level phrases (+ versions), get significant improvement w-m-o blog (p<0.01), email. may blog conversations many topical segments email conversations (average topic number10.77 vs. 2.5). Thus, little information label topical segment outside segment email conversations. However, note including conversation-levelphrases hurt performance significantly case.analyze performance, Table 11 shows mean w-m-o scoresbest k output labels considered. allows us judge models abilitygenerate best label top k list. results much clearer here. Generallyspeaking, among models include conversation-level phrases, CorBiasbest model, including conversation-level phrases improves performance further.Table 12 shows examples test set system-generated (i.e.,CorBias+) labels similar human-authored ones. also many caseslike ones Table 13, system-generated labels reasonable, althoughget low w-m-o w-s-m-o scores compared human-authored labels.561fiJoty, Carenini, & NgBaselinesModelsFreqBLLeadBLM&TMauiBiasRWBiasRW+CorGenCorGen+CorBiasCorBias+k=2Email Blog27.02 23.6928.72 21.6921.45 21.7014.00 14.8529.34 24.9229.47 25.8823.45 25.0524.56 25.8728.98 25.2729.76 25.96k=3Email Blog29.79 24.2930.86 23.1423.12 23.1815.57 17.3331.42 25.1831.43 27.3828.44 25.7228.46 26.6130.90 26.4131.04 27.65k=4Email Blog31.12 24.8831.99 24.1925.23 23.8217.15 19.2332.58 25.8932.96 28.4730.10 26.4031.14 27.6332.24 27.1433.61 28.63k=5Email Blog31.25 25.5831.99 25.3325.45 24.0718.40 20.0332.97 26.6433.87 29.1730.33 27.1032.91 28.5033.25 27.6535.35 29.58Table 11: Mean weighted-mutual-overlap (w-m-o) scores best k labels considered.EmailBlogHuman-authoredDetails Bristol meetingNashville conferenceMeeting agendaDesign guidelinesContact Stevenfaster light (FTL) travelDr. Paul LavioletteVietnam Iraq warfarePulsarsLinux distributionsSystem-generated (top 5)Bristol, face2face meeting, England, OctoberNashville conference, Courseware developers, mid October, eventdetailed agenda, main point, meetings, revision, wcag meetingsgeneral rule, design guidelines, accessible design, absolutes, forbidSteven Pemberton, contact, charter, status, schedule w3cFTL travel, need FTL, limited FTL, FTL drives, long FTLDr. Paul Laviolette, bang theory, systems theory, extraterrestial beacons, laughVietnam war, incapable guerrilla war, war information, war ii, vietnamese warmean pulsars, pulsars slow time, long pulsars, relative pulsars, set pulsarslinux distro, linux support, major linux, viable linuxTable 12: Examples Human-authored labels System-generated labels.Human-authoredMeeting time placeArchaeologyBio AlBudget ConstraintsFood choiceSystem-generatedOctober, mid October, timing, w3c timing issues, Ottawareligious site, burial site, ritual site, barrows tombAl Gilman, standards reformer, repair interest group, ER IG, ER teamsbudget, notice, costs, smaller companies, travelroast turkey breast, default choices, small number, vegetable rataouille, lunchTable 13: Examples System-generated labels reasonable get low scores.562fiTopic Segmentation Labeling Asynchronous Conversationshuman-authored labels corpora abstractivenature. Annotators often write labels rather simply copying keyphrasestext. so, rely expertise general world knowledgemay go beyond contents conversation. fact, although annotators reuse manywords conversation, 9.81% human-authored labels blog 12.74%human-authored labels email appear verbatim respective conversations.Generating human-like labels require deeper understanding text robusttextual inference, extractive approach provide useful input.5.3 Full System Evaluationsection present performance end-to-end system. first segmentgiven asynchronous conversation using best topic segmenter (the supervised model),feed output best topic labeler (the CorBias+ model). Table 14 presentshuman agreement agreement system human annotators basedbest k outputs. system annotation measure agreement w-m-ow-s-m-o three human annotations using method described Section 4.3.3.EmailBlogMean w-m-oMax w-m-oMean w-s-m-oMax w-s-m-oMean w-m-oMax w-m-oMean w-s-m-oMax w-s-m-ok=119.19100.024.98108.439.7126.6715.4647.10k=223.62100.032.08108.4311.7126.6719.7747.28Systemk=3k=426.1927.06100.0100.034.6336.92108.43 108.4314.5515.8335.0035.0023.3525.5747.2848.54Humank=528.06100.038.95108.4316.7235.0026.2348.5436.84100.042.54107.3119.9754.1728.2260.76Table 14: Performance end-to-end system human agreement.Notice email, system gets 100% agreement w-m-o metric conversations. However, substantial gap mean max w-m-o scores.Similarly, w-s-m-o, system achieves maximum 108% agreement, meanvaries 25% 39% depending different values k. blog, w-m-o w-s-m-oscores much lower. maximum scores achieved w-m-o w-s-m-o metrics blog35% 49% (for k = 5), respectively. mean w-m-o score varies 10%17%, mean w-s-m-o score varies 15% 28% different values k.demonstrates difficulties topic segmentation labeling tasks blog conversations.Comparing Table 11, notice inaccuracies topic segmenter affectsoverall performance. However, results encouraging. Even though lowervalues k substantial gap results human agreement,value k increases, results get closer human agreement, especially w-s-m-o.563fiJoty, Carenini, & Ng6. Conclusion Future Directionwork presents two new corpora email blog conversations annotated topics,which, along proposed metrics, allow researchers evaluate work quantitatively. also present complete computational framework topic segmentationlabeling asynchronous conversation.24 approach extends state-of-the-art methodsconsidering fine-grained structure asynchronous conversation, alongconversational features. applying recent graph-based methods NLPmin-cut random walk paragraph, sentence word graphs.topic segmentation, extend LDA LCSeg unsupervised models incorporate fine-grained conversational structure (the Fragment Quotation Graph (FQG)),generating two novel unsupervised models LDA+FQG LCSeg+FQG. additionthat, also present novel graph-theoretic supervised segmentation model combineslexical, conversational topic features. topic labeling, propose two novel randomwalk models extract representative keyphrases text, respectivelycapturing conversation specific clues two different sources: leading sentencesfine conversational structure (i.e., FQG).Experimental results topic segmentation task demonstrate LDALCSeg benefit significantly extended consider FQG, LCSeg+FQGbest unsupervised model. comparison supervised segmentation modelunsupervised models shows supervised method outperforms unsupervised ones even using labeled conversations, best segmentation modeloverall. outputs LCSeg+FQG supervised model also highly correlatedhuman annotations local global metrics. experiment topiclabeling task reveals random walk models perform better exploitconversation specific clues best results achieved sources cluesexploited. evaluation complete end-to-end system also shows promising resultscompared human performance.work extended many ways. Given human-authoredlabels abstractive nature, plan extend labeling framework generateabstract human-like labels could better synthesize information expressedtopic segment. promising approach would rely sophisticated methodsinformation extraction, combined semantics (e.g., phrase entailment) datato-text generation techniques. Another interesting venue future work performextrinsic evaluation methods. Instead testing respect humangold standard, would extremely interesting see effective usedsupport NLP tasks, summarization conversation visualization.also interested future transfer approach similar domains domainadaptation methods. plan work synchronous asynchronous domains.24. annotated corpora, annotation manual source code made publicly availablewww.cs.ubc.ca/labs/lci/bc3.html564fiTopic Segmentation Labeling Asynchronous ConversationsBibliographic NotePortions work previously published two conference proceedings (Joty et al.,2010, 2011). article significantly extends previous work several ways,notably: (i) complete topic modeling pipeline presenting novel topic labelingframework (Section 3.2), (ii) propose new set metrics topic labeling task(Section 5.2), (iii) present new annotated corpus blog conversations, showtopic segmentation labeling models perform new dataset (Section 4 5),(iv) demonstrate performance end-to-end system (Section 5.3).Acknowledgmentswork conducted University British Columbia. acknowledgefunding support NSERC Canada Graduate Scholarship (CGS-D), NSERC BIN StrategicNetwork NSERC discovery grant. grateful annotators greateffort. Many thanks Gabriel Murray, Jackie Cheung, Yashar Mehdad, Shima Gerani,Kelsey Allen anonymous reviewers thoughtful suggestions comments.Appendix A. Metrics Topic SegmentationA.1 One-to-One MetricConsider two different annotations conversation 10 sentences (denoted colored boxes) Figure 11(a). annotation, topics distinguisheddifferent colors. example, model output four topics, whereas human annotation three topics. compute one-to-one accuracy, take model outputmap segments optimally (by computing optimal max-weight bipartite matching)segments gold-standard human annotation. example, red segmentmodel output mapped green segment human annotation. transformmodel output based mapping compute percentage overlap one-toone accuracy. example, seven ten sentences overlap, therefore, one-to-oneaccuracy 70%.A.2 Lock MetricConsider model output (at left column) human annotation (atright column) conversation 5 sentences (denoted colored boxes)Figure 12. Similar Figure 11, topics annotation distinguished usingdifferent colors. Suppose want measure loc3 score fifth sentence (markedyellow arrows bottom two annotations). annotation, lookprevious 3 sentences transform based whether differenttopics. example, model output one previous three sentences (red),human annotation two previous three sentences (green),compared sentence consideration. transformed annotations,topics denoted gray boxes different topics denoted black boxes.565fiJoty, Carenini, & NgOne-to-OneaccuracyModel Humanoutput annotationTransform modeloutput accordingoptimal mapping70%Transformed Humanmodel output annotationModeloutput(b)(a)Figure 11: Computing one-to-one accuracy.566fiTopic Segmentation Labeling Asynchronous Conversationscompute loc3 measuring overlap different judgments 3-sentencewindow. example, two three overlap, therefore, loc3 agreement 66.6%.Loc3 accuracy66.6%different?ModelOutputdifferent?Transformedhuman annotationTransformedmodel outputHumanannotationFigure 12: Computing loc3 accuracy.ReferencesAllan, J. (2002). Topic Detection Tracking: Event-based Information Organization, pp.116. Kluwer Academic Publishers, Norwell, MA, USA.Allan, J., Wade, C., & Bolivar, A. (2003). Retrieval Novelty Detection SentenceLevel. Proceedings 26th annual international ACM SIGIR conferenceResearch development informaion retrieval, SIGIR 03, pp. 314321, Toronto,Canada. ACM.Andrzejewski, D., Zhu, X., & Craven, M. (2009). Incorporating domain knowledge topicmodeling via dirichlet forest priors. Proceedings 26th Annual International567fiJoty, Carenini, & NgConference Machine Learning, ICML 09, pp. 2532, Montreal, Quebec, Canada.ACM.Aumayr, E., Chan, J., & Hayes, C. (2011). Reconstruction threaded conversationsonline discussion forums. Proceedings Fifth International AAAI ConferenceWeblogs Social Media (ICWSM-11), pp. 2633.Bangalore, S., Di Fabbrizio, G., & Stent, A. (2006). Learning Structure Task-DrivenHuman-Human Dialogs. Proceedings 21st International Conference Computational Linguistics 44th annual meeting Association Computational Linguistics, pp. 201208. ACL.Bansal, N., Blum, A., & Chawla, S. (2002). Correlation clustering. Proceedings 43rdSymposium Foundations Computer Science, FOCS 02, pp. 238, Washington,DC, USA. IEEE Computer Society.Baron, N. S. (2008). Always on: Language online mobile world. Oxford ; NewYork : Oxford University Press.Barzilay, R., & Lee, L. (2004). Catching drift: Probabilistic content models, applications generation summarization. HLT-NAACL.Beeferman, D., Berger, A., & Lafferty, J. (1999). Statistical models text segmentation.Machine Learning, Vol. 34, pp. 177210, Hingham, MA, USA. Kluwer AcademicPublishers.Blei, D., Ng, A., & Jordan, M. (2003). Latent Dirichlet Allocation. Journal MachineLearning Research, 3, 9931022.Blei, D. M., & Moreno, P. J. (2001). Topic segmentation aspect hidden markovmodel. Proceedings 24th annual international ACM SIGIR conferenceResearch development information retrieval, SIGIR 01, pp. 343348, New York,NY, USA. ACM.Boyd-Graber, J., & Blei, D. M. (2008). Syntactic topic models. Neural InformationProcessing Systems.Breiman, L. (1996). Bagging predictors. Machine Learning, 24 (2), 123140.Carbonell, J., & Goldstein, J. (1998). use MMR, diversity-based rerankingreordering documents producing summaries. Proceedings 21st annualinternational ACM SIGIR conference Research development informationretrieval, pp. 335336, Melbourne, Australia. ACM.Carenini, G., Murray, G., & Ng, R. (2011). Methods mining summarizing textconversations, Vol. 3. Morgan Claypool.Carenini, G., Ng, R. T., & Zhou, X. (2007). Summarizing Email Conversations ClueWords. Proceedings 16th international conference World Wide Web, pp.91100, Banff, Canada. ACM.Carenini, G., Ng, R. T., & Zhou, X. (2008). Summarizing Emails ConversationalCohesion Subjectivity. Proceedings 46th Annual Meeting Association Computational Linguistics: Human Language Technologies, pp. 353361,OH. ACL.568fiTopic Segmentation Labeling Asynchronous ConversationsChoi, F. Y. Y., Hastings, P. W., & Moore, J. (2001). Latent semantic analysis textsegmentation. Proceedings 2001 Conference Empirical Methods NaturalLanguage Processing, EMNLP01, pp. 109117, Pittsburgh, USA. ACL.Cortes, C., & Vapnik, V. N. (1995). Support Vector Networks. Machine Learning, 20,273297.Crystal, D. (2001). Language Internet. Cambridge University Press.Dias, G., Alves, E., & Lopes, J. G. P. (2007). Topic Segmentation Algorithms TextSummarization Passage Retrieval: Exhaustive Evaluation. Proceedings22nd national conference Artificial intelligence - Volume 2, pp. 13341339,Vancouver, BC, Canada. AAAI.Eisenstein, J. (2009). Hierarchical text segmentation multi-scale lexical cohesion.Proceedings Human Language Technologies: 2009 Annual ConferenceNorth American Chapter Association Computational Linguistics, NAACL09, pp. 353361, Stroudsburg, PA, USA. Association Computational Linguistics.Eisenstein, J., & Barzilay, R. (2008). Bayesian unsupervised topic segmentation. Proceedings Conference Empirical Methods Natural Language Processing, EMNLP08, pp. 334343, Honolulu, Hawaii. Association Computational Linguistics.Elsner, M., & Charniak, E. (2010). Disentangling chat. Computational Linguistics, 36,389409.Elsner, M., & Charniak, E. (2011). Disentangling chat local coherence models. Proceedings 49th Annual Meeting Association Computational Linguistics:Human Language Technologies - Volume 1, HLT 11, pp. 11791189, Stroudsburg, PA,USA. Association Computational Linguistics.Galley, M., McKeown, K., Fosler-Lussier, E., & Jing, H. (2003). Discourse segmentationmulti-party conversation. Proceedings 41st Annual Meeting AssociationComputational Linguistics - Volume 1, ACL 03, pp. 562569, Sapporo, Japan.ACL.Griffiths, T. L., Steyvers, M., Blei, D. M., & Tenenbaum, J. B. (2005). Integrating topicssyntax. Advances Neural Information Processing Systems, pp. 537544. MITPress.Harabagiu, S., & Lacatusu, F. (2005). Topic Themes Multi-document Summarization.Proceedings 28th annual international ACM SIGIR conference Researchdevelopment information retrieval, pp. 202209, Salvador, Brazil. ACM.Hearst, M. A. (1997). TextTiling: segmenting text multi-paragraph subtopic passages.Computational Linguistics, 23 (1), 3364.Hsueh, P., Moore, J. D., & Renals, S. (2006). Automatic segmentation multiparty dialogue. Proceedings 11th Conference European ChapterAssociation Computational Linguistics, EACL06, Trento, Italy. ACL.Hulth, A. (2003). Improved automatic keyword extraction given linguistic knowledge. Proceedings 2003 conference Empirical methods natural languageprocessing, EMNLP 03, pp. 216223. Association Computational Linguistics.569fiJoty, Carenini, & NgJanin, A., Baron, D., Edwards, J., Ellis, D., Gelbart, D., Morgan, N., Peskin, B., Pfau, T.,Shriberg, E., Stolcke, A., & Wooters, C. (2003). ICSI Meeting Corpus. Proceedings IEEE International Conference Acoustics, Speech, Signal Processing(ICASSP-03), pp. 364367.Joty, S., Carenini, G., & Lin, C. (2011). Unsupervised modeling dialog acts asynchronous conversations. Proceedings twenty second International Joint Conference Artificial Intelligence (IJCAI), Barcelona.Joty, S., Carenini, G., Murray, G., & Ng, R. (2010). Exploiting conversation structureunsupervised topic segmentation Emails. Proceedings conferenceEmpirical Methods Natural Language Processing, EMNLP10, pp. 388398, Massachusetts, USA. ACL.Joty, S., Carenini, G., Murray, G., & Ng, R. (2011). Supervised topic segmentation Emailconversations. Proceedings Fifth International AAAI Conference WeblogsSocial Media, ICWSM11, pp. 530533, Barcelona, Spain. AAAI.Kim, S., Baldwin, T., & Kan, M. (2010a). Evaluating n-gram based evaluation metricsautomatic keyphrase extraction. Proceedings 23rd International ConferenceComputational Linguistics, COLING10, pp. 572580, Beijing, China. ACL.Kim, S. N., Medelyan, O., Kan, M.-Y., & Baldwin, T. (2010b). Semeval-2010 task 5 :Automatic keyphrase extraction scientific articles. Proceedings 5thInternational Workshop Semantic Evaluation, pp. 2126, Uppsala, Sweden. Association Computational Linguistics.Kleinbauer, T., Becker, S., & Becker, T. (2007). Combining Multiple Information LayersAutomatic Generation Indicative Meeting Abstracts. ProceedingsEleventh European Workshop Natural Language Generation, ENLG07, pp. 151154, Stroudsburg, PA, USA. Association Computational Linguistics.Lau, J., Grieser, K., Newman, D., & Baldwin, T. (2011). Automatic Labelling TopicModels. Proceedings 49th annual meeting Association ComputationalLinguistics, pp. 15361545, Portland, USA. ACL.Lin, C.-Y. (2004). ROUGE: package automatic evaluation summaries. ProceedingsWorkshop Text Summarization Branches Out, pp. 7481, Barcelona.Liu, S., Zhou, M. X., Pan, S., Song, Y., Qian, W., Cai, W., & Lian, X. (2012). TIARA:interactive, topic-based visual text summarization analysis. ACM Trans. Intell.Syst. Technol., 3 (2), 25:125:28.Malioutov, I., & Barzilay, R. (2006). Minimum cut model spoken lecture segmentation.Proceedings 21st International Conference Computational Linguistics44th annual meeting Association Computational Linguistics, ACL-44,pp. 2532, Sydney, Australia. Association Computational Linguistics.Mayfield, E., Adamson, D., & Rose, C. P. (2012). Hierarchical conversation structure prediction multi-party chat. Proceedings 13th Annual Meeting SpecialInterest Group Discourse Dialogue, SIGDIAL 12, pp. 6069, Stroudsburg, PA,USA. Association Computational Linguistics.570fiTopic Segmentation Labeling Asynchronous ConversationsMedelyan, O. (2009). Human-competitive automatic topic indexing. Ph.D. thesis,University Waikato, Hamilton, New Zealand.Medelyan, O., Frank, E., & Witten, I. H. (2009). Human-competitive tagging using automatic keyphrase extraction. Proceedings 2009 Conference EmpiricalMethods Natural Language Processing, EMNLP09, pp. 13181327, Singapore. Association Computational Linguistics.Mei, Q., Shen, X., & Zhai, C. (2007). Automatic labeling Multinomial topic models.Proceedings 13th ACM SIGKDD international conference Knowledgediscovery data mining, pp. 490499, California, USA. ACM.Mihalcea, R., & Radev, D. (2011). Graph-based natural language processing informationretrieval. Cambridge University Press.Mihalcea, R., & Tarau, P. (2004). Textrank: Bringing order text. Proceedings2004 Conference Empirical Methods Natural Language Processing, EMNLP04,pp. 404411, Barcelona, Spain.Minka, T. (1999). dirichlet-tree distribution. Tech. rep., Justsystem Pittsburgh Research Center.Morris, J., & Hirst, G. (1991). Lexical cohesion computed thesaural relationsindicator structure text. Computational Linguistics, 17 (1), 2148.Murphy, K. (2012). Machine Learning Probabilistic Perspective. MIT Press.Nguyen, V.-A., Boyd-Graber, J., & Resnik, P. (2012). Sits: hierarchical nonparametricmodel using speaker identity topic segmentation multiparty conversations.Proceedings 50th Annual Meeting Association Computational Linguistics: Long Papers - Volume 1, ACL 12, pp. 7887, Stroudsburg, PA, USA. AssociationComputational Linguistics.Page, L., Brin, S., Motwani, R., & Winograd, T. (1999). pagerank citation ranking:Bringing order web.. Technical report 1999-66.Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: method automaticevaluation machine translation. Proceedings 40th Annual MeetingAssociation Computational Linguistics, ACL02, pp. 311318, Philadelphia, Pennsylvania. Association Computational Linguistics.Passonneau, R. J., & Litman, D. J. (1997). Discourse segmentation human automated means. Computational Linguistics, 23 (1), 103139.Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet::Similarity - MeasuringRelatedness Concepts. Proceedings Fifth Annual Meeting NorthAmerican Chapter Association Computational Linguistics (NAACL-04),pp. 3841, Boston, MA.Pevzner, L., & Hearst, M. A. (2002). critique improvement evaluation metrictext segmentation. Computational Linguistics, 28 (1), 1936.Purver, M. (2011). Topic segmentation. Tur, G., & de Mori, R. (Eds.), Spoken LanguageUnderstanding: Systems Extracting Semantic Information Speech, pp. 291317. Wiley.571fiJoty, Carenini, & NgPurver, M., Kording, K. P., Griffiths, T. L., & Tenenbaum, J. B. (2006). Unsupervisedtopic modelling multi-party spoken discourse. Proceedings ACL06, pp.1724, Sydney, Australia. ACL.Sacks, H., Schegloff, A., & Jefferson, G. (1974). simplest systematics organizationturn-taking conversation. Language, 50, 696735.Salton, G., & McGill, M. J. (1986). Introduction Modern Information Retrieval. McGrawHill, Inc., New York, NY, USA.Seneta, E. (1981). Non-negative Matrices Markov Chains. Springer-Verlag.Shi, J., & Malik, J. (2000). Normalized cuts image segmentation. IEEE Trans. PatternAnal. Mach. Intell., 22 (8), 888905.Soon, W. M., Ng, H. T., & Lim, D. C. Y. (2001). machine learning approach coreferenceresolution noun phrases. Computational Linguistics, 27 (4), 521544.Steyvers, M., & Griffiths, T. (2007). Latent Semantic Analysis: Road Meaning, chap.Probabilistic topic models. Laurence Erlbaum.Turney, P. D. (2000). Learning algorithms keyphrase extraction. Information Retrieval,2 (4), 303336.Ulrich, J., Murray, G., & Carenini, G. (2008). publicly available annotated corpussupervised email summarization. EMAIL-2008 Workshop, pp. 428435. AAAI.Verna, P. (2010). blogosphere: Colliding social mainstream media. eMarketer.Wallach, H. M. (2006). Topic modeling: beyond bag-of-words. Proceedings 23rdinternational conference Machine learning, ICML 06, pp. 977984, Pittsburgh,Pennsylvania. ACM.Wang, H., Wang, C., Zhai, C., & Han, J. (2011). Learning online discussion structuresconditional random fields. Proceedings 34th international ACM SIGIRconference Research development Information Retrieval, SIGIR 11, pp.435444, Beijing, China. ACM.Wang, L., & Oard, D. W. (2009). Context-based message expansion disentanglementinterleaved text conversations. Proceedings Human Language Technologies:2009 Annual Conference North American Chapter Association Computational Linguistics, NAACL 09, pp. 200208, Stroudsburg, PA, USA. AssociationComputational Linguistics.Zesch, T., & Gurevych, I. (2009). Approximate matching evaluating keyphrase extraction. Proceedings 7th International Conference Recent AdvancesNatural Language Processing, RANLP09, pp. 484489, Borovets, Bulgaria.Zhao, W. X., Jiang, J., He, J., Song, Y., Achananuparp, P., Lim, E.-P., & Li, X. (2011a).Topical keyphrase extraction twitter. Proceedings 49th Annual Meeting Association Computational Linguistics: Human Language Technologies- Volume 1, HLT 11, pp. 379388, Stroudsburg, PA, USA. Association Computational Linguistics.572fiTopic Segmentation Labeling Asynchronous ConversationsZhao, W. X., Jiang, J., Weng, J., He, J., Lim, E.-P., Yan, H., & Li, X. (2011b). Comparingtwitter traditional media using topic models. Proceedings 33rd European conference Advances information retrieval, ECIR11, pp. 338349, Berlin,Heidelberg. Springer-Verlag.Zhou, D., Orshanskiy, S. A., Zha, H., & Giles, C. L. (2007). Co-ranking authorsdocuments heterogeneous network. Proceedings 2007 Seventh IEEEInternational Conference Data Mining, ICDM 07, pp. 739744, Washington, DC,USA. IEEE Computer Society.573fiJournal Artificial Intelligence Research 47 (2013) 649-695Submitted 02/13; published 08/13Protecting Privacy Distributed ComputationMulti-agent Decision MakingThomas LeauteBoi Faltingsthomas.leaute@a3.epfl.chboi.faltings@epfl.chEcole Polytechnique Federale de Lausanne (EPFL)Artificial Intelligence Laboratory (LIA)Station 14CH-1015 Lausanne, SwitzerlandAbstractlarge-scale theft data corporate servers becoming increasingly common,becomes interesting examine alternatives paradigm centralizing sensitive datalarge databases. Instead, one could use cryptography distributed computationsensitive data supplied processed encrypted form, finalresult made known. paper, examine paradigm usedimplement constraint satisfaction, technique solve broad class AI problemsresource allocation, planning, scheduling, diagnosis. previous workprivacy constraint satisfaction attempted protect specific types information,particular feasibility particular combinations decisions. formalizeextend restricted notions privacy introducing four types private information,including feasibility decisions final decisions made, also identitiesparticipants topology problem. present distributed algorithmsallow computing solutions constraint satisfaction problems maintaining fourtypes privacy. formally prove privacy properties algorithms, showexperiments compare respective performance benchmark problems.1. IntroductionProtecting privacy information becoming crucial concern many usersincreasingly ubiquitous Information Communication Technologies. Companies investlot effort keeping secret internal costs future development strategiesactors market, importantly competitors. Individuals alsoneed privacy personal information: instance, carelessly disclosing onesactivity schedule location might reveal burglars opportunities break ones home.hand, accessing using private information often necessary solveproblems depend data. context supply chain management, companiesneed exchange information contractors subcontractors quantitiesgoods must produced, price. scheduling meetings variousevents friends co-workers, individuals confronted challenge takingcoordinated scheduling decisions, protecting respective availability schedules.Artificial Intelligence crucial tool help people make better decisionsprivacy concerns, delegating part decision problem personal intelligentagents executing carefully chosen algorithms far complex performed2013 AI Access Foundation. rights reserved.fiLeaute & Faltingshuman alone. particular, framework Constraint Satisfaction Problems(CSPs) core AI technology successfully applied many decision-makingproblems, configuration scheduling, solving strategic games. showdistributed AI algorithms used solve CSPs, providing strong guaranteesprivacy problem knowledge, use techniques borrowedcryptography. makes possible solve coordination problems depend secretdata, without reveal data parties. hand, distributed,encrypted computation involving message exchange cost terms performance,suitable tradeoff privacy scalability must found.1.1 Motivating Examplespaper, present set novel, privacy-protecting algorithms Distributed Constraint Satisfaction Problems (DisCSPs), wide class multi-agent decision-making problems applications many problems configuration, scheduling, planning, designdiagnosis. consider three examples illustrate privacy requirements mightarise: meeting scheduling, airport slot allocation, computing game equilibria.meeting scheduling problem (Maheswaran, Tambe, Bowring, Pearce, & Varakantham, 2004), number meetings need scheduled, involving possibly overlapping setsparticipants. Taking account respective availability constraints, participantsgiven meeting must agree time meeting. One given participantinvolved multiple meetings, creates constraints meetings. problem class, participants usually want protect privacy respective availabilityschedules, well lists meetings involved in.Another problem class airport slot allocation (Rassenti, Smith, & Bulfin, 1982),airlines express interests combinations takeoff landing time slots airports, corresponding possible travel routes aircraft. end goal airportsefficiently allocate slots airlines, point view airlines crucialcombinations slots interested remain private, indicateroutes intend fly, sensitive strategic information want hidecompetitors.Finally, consider general class one-shot strategic games, party game(Singh, Soni, & Wellman, 2004): players invited party, must decide whetherattend, based respective intrinsic costs attendance, whether peoplelike dislike also choose attend. Players would best play strategies formNash equilibrium, single player better deviating chosenstrategy. problem computing equilibrium typical example multiagent decision-making problem, privacy issue: players necessarily wantreveal attendance costs, whether like dislike another invitee.1.2 Four Types Private Informationseen previous examples, information participants would likekeep private differ nature; propose classify four privacy types.briefly introduce illustrate here; formal definitions given Section 2.2.1.650fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making1. Agent privacy relates identities participants. Consider instanceCEO wants schedule two meetings respectively journalistanother companys CEO. Revealing journalist CEOs involvementdecision-making problem could leak companies plans merge.case agent privacy considered critical.2. Topology privacy covers information presence constraints.type critical information airline companies want keep secret airportslot allocation problem: presence constraint airline specificairport reveals airlines strategic plans offer flights airport.3. Constraint privacy nature constraints. covers instanceparticipants availability schedules meeting scheduling problem, and,party game, whether player likes dislikes invitees.4. Decision privacy solution eventually chosen problem.Depending problem class, type privacy may may relevant.meeting scheduling problem, time chosen meeting necessarilyrevealed participants meeting; however desirable hideinformation non-attendees.Like previous work privacy DisCSP, assume participants honest,curious (Goldreich, 2009), honestly follow algorithm, interestedlearning much possible agents private information based messages exchanged. Note honesty assumption mean agentsassumed faithfully report true constraints algorithm; may temptedstrategize reporting slightly different constraints, hoping would lead algorithm select solution problem deem preferable them. issueincentive-compatibility addressed related work Petcu, Faltings,Parkes (2008), orthogonal issue privacy addressed paper. Furthermore, agent would take risk reporting constraints different true constraints:reporting relaxed constraints could yield solution violates true constraintswould therefore viable, reporting tighter constraints could make overallproblem infeasible algorithm fail find solution all.hand, algorithms depart previous work two respects. First,previous work almost exclusively focused constraint privacy, often ignoring agent,topology decision privacy. show address four types, algorithmspropose correspond various points tradeoff different levels privacyefficiency. Second, literature focuses quantitatively measuringreducing amount privacy loss various DisCSP algorithms, developedalgorithms give strong guarantees certain pieces private informationleaked. contrast, previous privacy-protecting algorithms, typically casepiece private information may leaked (small) probability.rest paper organized follows. Section 2 first formally defines DisCSPframework four aforementioned types privacy. Section 3 presents firstalgorithm, called P-DPOP+. Section 4 describes P3/2 -DPOP+ algorithm,651fiLeaute & Faltingsvariant achieves higher level decision privacy, expense additionalcomputational overhead. Another variant, called P2 -DPOP+, introduced Section 5order improve constraint privacy. Finally, Section 6 compares performancealgorithms previous state art, several classes benchmarks.2. Preliminariessection first formally defines DisCSP framework (Section 2.1), introducesfour types privacy (Section 2.2).2.1 Distributed Constraint Satisfactionproviding formal definition Distributed Constraint Satisfaction (Section 2.1.1),recall existing algorithms DisCSP optimization variant (Section 2.1.2).2.1.1 DefinitionDistributed Constraint Satisfaction Problem formally defined follows.Definition 1 (DisCSP). discrete DisCSP tuple < A, X , a, D, C >:= {a1 , ..., ak } set agents;X = {x1 , ..., xn } set variables;: X mapping assigns control variable xi agent a(xi );= {D1 , ..., Dn } set finite variable domains; variable xi takes values Di ;C = {c1 , ..., cm } set constraints, ci s(ci )-ary function scope(xi1 , , xis(ci ) ), ci : Di1 .. Dis(ci ) {false, true}, assigning false infeasibletuples, true feasible ones.Vsolution complete assignment conjunction ci C ci = true,case exactly assignment consistent constraints.important assumptions DisCSP framework following. First,assume details given constraint ci known agents involved;agent wants keep constraints private, formulate wayinvolve variables controls. Furthermore, assume two neighboring agents(i.e. agents share least one constraint) able communicatesecurely, messages delivered FIFO order finite time.hand, assume two non-neighboring agents initially ignore everythingother, even including involvement problem. particular, DisCSP algorithmprotects agent privacy require communicate directly,even allow discover others presence. Finally, assume agent honestlyfollows protocol, focus preventing private information leaks agents.Figure 1 introduces simple graph coloring problem instance used illustrate algorithms throughout rest paper. assume five nodes652fiProtecting Privacy thru Distributed Computation Multi-agent Decision MakingR 6= x16=6=x2x4 6= B6=6=x36=x5 6 {B, R}Figure 1: DisCSP constraint graph simple graph coloring problem instance.graph correspond five different agents, must choose color among red,blue green. decisions modeled five variables x1 , . . . , x5 domains{R, B, G}. agent may express secret, unary constraint variable; instance,x1 want assigned color red. Binary, inequality constraints imposedpair neighboring nodes, known two agents involved.Distributed Constraint Optimization (DCOP) extension DisCSP formalism,constraints specify variable assignments feasible infeasible,also assign costs (or utilities) assignments. (optimal) solutionDCOP one minimizes sum costs (or maximizes sum utilities).algorithms paper easily generalized solve DCOPs, complexityincrease linear upper bound (assumed integer) costoptimal solution. generalization left outside scope paper sakeconciseness, addressed Leaute Faltings (2011) Leaute (2011).2.1.2 Complete Algorithms DisCSPsrange distributed algorithms exist literature solve DisCSPs DCOPs.seen belonging two classes, depending order variables.largest class consists algorithms order variables along linear order,ABT (Yokoo, Durfee, Ishida, & Kuwabara, 1992), AWC (Yokoo, 1995), SynchBB (Hirayama & Yokoo, 1997), AAS (Silaghi, Sam-Haroud, & Faltings, 2000), AFC (Meisels &Zivan, 2003), DisFC (Brito & Meseguer, 2003), (Comp)APO (Mailler & Lesser, 2003; Grinshpoun & Meisels, 2008), ConcDB (Zivan & Meisels, 2004), AFB (Gershman, Meisels, &Zivan, 2006) ConcFB (Netzer, Meisels, & Grubshtein, 2010). linear order maychosen fixed initially algorithm run, dynamically revised online.second class, variables ordered along tree-based partial order. includesADOPT (Modi, Shen, Tambe, & Yokoo, 2005) variants BnB-ADOPT (Yeoh,Felner, & Koenig, 2010) BnB-ADOPT+ (Gutierrez & Meseguer, 2010), DPOP (Petcu& Faltings, 2005) countless variants, NCBB (Chechetka & Sycara, 2006),order variables following pseudo-tree (Definition 2). Among aforementionedpseudo-tree-based algorithms, DPOP one using Dynamic Programming (DP),others based search. algorithms proposed perform DPdifferent partial variable orders: Action-GDL uses junction trees (Vinyals, RodrguezAguilar, & Cerquides, 2010), DCTE cluster trees (Brito & Meseguer, 2010).653fiLeaute & Faltings2.1.3 DPOP AlgorithmDPOP algorithm originally designed solve optimization problems (DCOPs)described terms utility maximization. One way apply pure satisfaction problems(DisCSPs) first reformulate DisCSP Max-DisCSP, constraintslonger boolean rather take values {0, 1}, 0 stands feasibility1 infeasibility. cost-minimizing variant DPOP (described below)applied find solution minimal cost, cost (hereafter called feasibilityvalue) corresponds number constraint violations (which want equal 0).Overview Algorithm DPOP instance general bucket eliminationscheme Dechter (2003), performed distributedly (Algorithm 1). requires first arrangingconstraint graph pseudo-tree, formally defined follows.Definition 2 (Pseudo-tree). pseudo-tree generalization tree, nodeallowed links (back-edges) remote ancestors (pseudo-parents) remotedescendants (pseudo-children), never nodes branches tree.pseudo-tree arrangement constraint graph Figure 1 illustrated Figure 2.pseudo-tree naturally decomposes original problem two, loosely coupled subproblems, corresponding two branches, perform rest algorithmparallel. Figure 2 also shows FEAS messages (originally called UTIL messagescontext utility maximization) exchanged propagation feasibilityvalues, following multi-party dynamic programming computation (lines 1 12).Algorithm 1 Overal DPOP algorithm, variable xRequire: pseudo-tree ordering variables; px denotes xs parent1: // (UTIL propagation) Propagate feasibility values pseudo-tree:2: m(x, px , ) c{c C | xscope(c) scope(c )(childrenx pseudo childrenx )=} c(x, )// Join received messages:yi childrenx5:Wait message (FEAS, mi (x, )) yi6:sepyi scope(mi )7:m(x, px , ) m(x, px , ) + mi (x, )3:4:// Project x:x root variable10:x (px , ) arg minx {m(x, px , )}11:Send message (FEAS, m(x (px , ), px , )) px12: else x arg minx {m(x)} // m(x, px , ) actually depends x8:9:13:14:15:16:17:// (VALUE propagation) Propagate decisions top-down along pseudo-tree:x rootWait message (DECISION, px , ) parent pxx x (px = px , )yi childrenx send message (DECISION, sepyi ) yi654fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingx2x3 x2R B G0 1 0x5 x3x3R0B0G1x4 x3x2x3 R B GR0 1 0B0 0 0G0 0 0x2x3x5x4x1x1 x4x2x4 R B GR0 0 0B0 0 1G0 1 0Figure 2: Multiparty dynamic programming computation feasible value x2 , basedpseudo-tree arrangement constraint graph Figure 1. dashededge represents back-edge pseudo-parent pseudo-tree.part algorithm, messages travel bottom-up along tree edges. Consider instancemessage sent agent a(x5 ) parent agent a(x3 ). message resultprojection (lines 10 11) variable x5 conjunction (line 2) x5 twoconstraints x5 6= x3 x5 6= B, summarizes minimal number constraint violations a(x5 ) achieve, function ancestor variable x3 . generally,message sent variable x summarizes minimal number constraint violationsachievable aggregate subproblem owned entire subtree rooted x,function whose scope called separator x (line 6). DPOP, separator x necessarily includes xs parent px , potentially ancestor variables; indicatednotation m(px , ). instance, message x4 x3 summarizes minimal numberconstraint violations achievable entire subtree rooted x4 , function x4separator {px4 = x3 , x2 }. Notice separator variable x contain variablesneighbors x; example, x2 x4 separator descendent x4constraint x2 . privacy-aware algorithms presented later paper,notion separator extended allow separators necessarily includeparent variable, may include multiple codenames referring variables,might necessarily ancestors pseudo-tree.Upon receiving messages x5 x3 x4 x3 (line 5), agent a(x3 ) joins(line 7) constraint x3 6= x2 . Variable x3 projected resulting jointtable, produces message x3 x2 (lines 10 11). end feasibilitypropagation (line 12), root variable x2 chooses value x2 minimizesnumber constraint violations entire problem (e.g. x2 = R). decisionpropagated downwards along tree-edges via DECISION messages (originally calledVALUE messages) variables assigned optimal values (lines 13 17).655fiLeaute & FaltingsComplexity Given pseudo-tree ordering n variables, DPOPs bottom-uptop-down phases exchange exactly (n 1) messages (one tree edge).However, DECISION message contains (n 1) variable assignments,FEAS message sent given variable x contain exponentially many feasibility values,contains table representation function |sepx | variables. sizesepmaxlargest FEAS message therefore O(Dmax), Dmax size largestvariable domain, sepmax = maxx |sepx | < n 1 width pseudo-tree.best case, width equal treewidth constraint graph; however findingpseudo-tree achieves minimal width NP-hard. practice, pseudo-treegenerated heuristic, distributed, depth-first traversal constraint graph (OnlineAppendix 1), producing so-called DFS tree pseudo-tree parentchild relationships neighbors constraint graph. Since DPOP exchanges(n 1) FEAS messages, overall complexity terms runtime (measured numbersepmaxconstraint checks), memory, information exchange O(n Dmax).Privacy Properties privacy-aware algorithms Section 3 based DPOP,two desirable properties allow higher levels privacy. First, DPOPrequires message exchanges neighboring agents, provided pseudotree used DFS tree; necessary protect agent privacy. Greenstadt, Pearce,Tambe (2006) made opposite claim pseudo-trees detrimental privacycompared linear orderings; however claim valid type privacyconsidered constraint privacy, hold agent privacy topology privacyguaranteed, i.e. pseudo-tree publicly known agents. second, DPinherited property DPOPs performance depend constraint tightness,i.e. easy hard satisfy constraint. other, search-based algorithms,inferences constraint tightness made observing runtime amountinformation exchanged (Silaghi & Mitra, 2004). case meeting scheduling problems,constraint tightness maps directly participants levels availability, privateinformation. application domains leak constraint tightness tolerable,algorithms based search rather DP used, many privacy-enhancingtechniques presented paper DPOP also applicable search-based algorithms.2.2 Privacy DisCSPsSection 2.2.1 formally defines four types privacy considered paper. Section 2.2.2recalls previous work attempted address various subsets privacy types.2.2.1 Privacy DefinitionsDefinition 3 introduces concept semi-private information (Faltings, Leaute, & Petcu,2008), may inevitably leaked DisCSP algorithm.Definition 3 (Semi-private information). Semi-private information refers informationproblem and/or solution agent might consider private,inevitably leaked agents views chosen solution DisCSP.words, semi-private information covers everything given agent discoveragents making inferences simply based initial knowledge problem656fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingvalues variables take solution. instance, graph coloring probleminvolving two colors, node infer color neighborscolor assigned chosen solution, provided solution correct. Excludingsemi-private information, distinguish four types private information agentsmay desire protect (Faltings et al., 2008).Definition 4 (Agent privacy). agent able discover identity, evenexistence non-neighboring agents. particular consequence type privacytwo agents allowed communicate directly share constraint.Figure 1, means instance agent a(x1 ) able discoverexistence identities agents a(x3 ) a(x5 ). Even two non-neighboring agentscommunicate directly, agent privacy might still leaked contents messages;paper propose method based codenames fully protect agent privacy.Definition 5 (Topology privacy). agent able discover existencetopological constructs constraint graph, nodes (i.e. variables), edges (i.e.constraints), cycles, unless owns variable involved construct.Figure 1, topology privacy means instance agent a(x1 ) discovermany neighbors x2 besides itself. However, a(x1 ) might discover existencecycle involving x1 , x2 x4 . tolerated x1 involved cycle,a(x1 ) discover length cycle (i.e. x2 x4 share neighbor).Definition 6 (Constraint privacy). agent able discover natureconstraint involve variable owns.Figure 1, example breach constraint privacy would agent a(x1 )able discover agent a(x4 ) want assigned color blue.type privacy DisCSP literature mostly focuses on.Definition 7 (Decision privacy). agent able discover value anotheragents variable takes chosen solution (modulo semi-private information).distributed graph coloring problem, means agent discover colorneighbor (let alone non-neighboring agent) solution chosen problem.2.2.2 Previous Work Privacy DisCSPdiscussing information may leaked given algorithm, preventit, important clarify information assumed initially known agent.Initial Knowledge Assumptions paper, use following three assumptions,currently widely used DisCSP literature.1. agent knows agents variables neighbors variables,know agents (not even existence);2. variable domain known owner agent agents owningneighboring variables, agents ignore existence variable;657fiLeaute & Faltings3. constraint fully known agents owning variables scope,agent knows anything constraint (not even existence).Brito Meseguer (2003) introduced Partially Known Constraints (PKCs), whosescopes known agents involved, knowledge whose nature (which assignments allowed disallowed) distributed among agents. relaxationAssumption 3; however worth noting algorithms presented paperstill support PKCs without introducing privacy leaks enforcing assumption,PKC decomposed number constraints copy variablesAssumption 3 holds. instance, agents a1 . . . share knowledge unary PKCvariable x, constraint decomposed n unary constraints,constraint ci known fully agent ai expressed copyvariable xi owned ai . Equality constraints added problem enforce equalitycopy variables. However, introduction copy variables detrimentaldecision privacy. Grubshtein, Grinshpoun, Meisels, Zivan (2009) later proposedsimilar concept asymmetric constraints, also reformulated symmetricconstraints copy variables purpose applying algorithms.previous work adopted dual approach, assuming variables publicknown agents, constraint known one agent (Silaghi et al., 2000;Yokoo, Suzuki, & Hirayama, 2002; Silaghi, 2005a). Silaghi (2005b) even proposed framework constraints secret everyone. dual approach disadvantage necessarily violating topology privacy, since variables public.Measuring Constraint Privacy Loss literature privacy DisCSPsfocuses constraint privacy. Metrics proposed evaluate constraint privacyloss algorithms, particular distributed meeting scheduling (Franzin, Freuder, Rossi,& Wallace, 2004; Wallace & Freuder, 2005). Maheswaran, Pearce, Bowring, Varakantham,Tambe (2006) designed framework called Valuation Possible States (VPS)used measure constraint privacy loss OptAPO SynchBB algorithms,considered impact whether problem topology public partiallyknown agents. Greenstadt et al. (2006) also applied VPS evaluate DPOPADOPT meeting scheduling problems, assumption problem topologypublic. Doshi, Matsui, Silaghi, Yokoo, Zanker (2008) proposed consider costprivacy loss optimization problems, order elegantly balance privacy optimality.Preventing Constraint Privacy Loss previous work also proposed approachespartially reduce constraint privacy loss. instance, Brito Meseguer (2007) describedmodification Distributed Forward Checking (DisFC) algorithm DisCSPsagents allowed lie finite time order achieve higher levels privacy. However, performance search-based algorithms like DisFC leaks informationconstraint tightness, explained end Section 2.1.3. avoid subtle privacyleak, one must either perform full exhaustive search, option chosen Silaghi,resort Dynamic Programming, option chosen paper.cryptographic technique secret sharing (Shamir, 1979; Ben-Or, Goldwasser, &Wigderson, 1988) also applied Silaghi, Faltings, Petcu (2006) Greenstadt,Grosz, Smith (2007) lower constraint privacy DPOP, assuming constraintgraph topology public knowledge. Cryptography also applied provide strong658fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingguarantees constraint privacy preservation multi-agent decision making. instance,Yokoo Suzuki (2002), Yokoo et al. (2002) Yokoo, Suzuki, Hirayama (2005)showed public key encryption scheme used solve DisCSPs using multipleservers, protecting constraint privacy decision privacy. Bilogrevic, Jadliwala,Hubaux, Aad, Niemi (2011) solved single-meeting scheduling problems using similartechniques, one semi-trusted server. paper however, consider algorithmsmake use third parties, third parties might available. Herlea,Claessens, Preneel, Neven, Piessens, Decker (2001) showed use Secure MultipartyComputation (SMC) 1 securely schedule single meeting, without relying servers.SMC, agents collaboratively compute value given, publicly known functionprivate inputs, without revealing inputs. Herlea et al. (2001), inputsparticipants availability given time, function outputs whetheravailable.MPC-DisCSP4 Algorithm Silaghi (2005a) also applied SMC solve generalDisCSPs, private inputs agents constraint valuations, functionreturns randomly chosen solution. algorithm proceeds follows (Leaute, 2011).agent ai first creates vector Fi one entry per candidate solution DisCSP, equal1 candidate solution satisfies ai private constraints, 0 otherwise. reducesize Fi , candidate solutions may filtered publicly known constraints,exists any. Using Shamirs polynomial secret sharing technique (Shamir, 1979; BenOr et al., 1988), agent ai sends one secret share Fij vector Fiagent aj , receives corresponding secret shares Fji respective vectors. Agent aimultiplies together secret shares received. multiplication Shamir secretshares non-trivial operation, secret share value polynomial,multiplying two polynomials increases degree output, must always remainlower number |A| agents resolvable. Therefore, multiplicationtwo secret shares, agent ai must perform complex sequence operations involvingexchange messages order reduce degree output.performing (|A| 1) pairwise multiplications secret shares, agent ai vector Fi contains secret shares 1 entries corresponding globally feasible solutions.Agent ai performs transformation Fi one secret share 1remains, identifying one particular feasible solution (if exists one). selectingfirst entry would posteriori reveal previous entries correspond infeasiblesolutions DisCSP; prevent privacy leak, vector Fi first collaboratively,randomly permuted using mix-net. Agent ai performs sequence iterative operations Fi (including communication-intensive multiplications) set entriessecret shares 0, except one secret share 1 corresponding chosen solutionDisCSP (if any). vector Fi un-shuffled re-traversing mix-netreverse. Finally, agent ai compute secret shares domain index variableschosen assignment, reveal secret shares owners variables.algorithm numerous drawbacks. First, agent must know variablesdomains construct initial vector Fi , immediately violates agent privacytopology privacy (Table 3.3, page 664). Second, Shamirs secret sharing scheme1. Silaghi uses different acronym MPC concept.659fiLeaute & Faltingsmajority threshold scheme, means least half agents collude,discover everyones private information. Even though, paper, assumingagents honest collude, consequence thresholdscheme provide privacy guarantee problem involves two agents.Third, algorithm often practical small problems, performsfull exhaustive search; demonstrated experimental results Section 6.3. P-DPOP+ : Full Agent Privacy Partial Topology, ConstraintDecision Privacysection describes variant DPOP algorithm guarantees full agent privacy.also partially protects topology, constraint, decision privacy. Algorithm 2improvement P-DPOP algorithm originally proposed (Faltings et al., 2008).Like DPOP, algorithm performs dynamic programming DFS-tree orderingvariables (Figure 2). Algorithms first elect one variable, generate DFS treerooted variable given Online Appendices 1 2. algorithmsreveal pseudo-tree entirety agent; instead, agent discovers(pseudo-)parents (pseudo-)children variables. sake simplicity,hereafter assume without loss generality constraint graph consists singlecomponent. problem actually consisted two fully decoupled subproblems,subproblem would solved parallel, independently others.Algorithm 2 Overal P-DPOP+ algorithm, variable xRequire: DFS-tree ordering variables1: // Choose exchange codenames x domain Dx :2: Wait message (CODES, yix , Dyxi , yxi ) yi {parentx } pseudo parentsx3: yi childrenx pseudo childrenx4:xyi large random number5:Dxyi list |Dx | random, unique identifiers6:xyi random permutation [1, . . . , |Dx |]7:Send message (CODES, xyi , Dxyi , xyi ) yi12:// Choose exchange obfuscation key x:Wait record message (KEY, keyyxi ) yi pseudo parentsx (if any)yi pseudo childrenxkeyxyi vector large random numbers B bits, indexed DxSend message (KEY, keyxyi ) yi13:Propagate feasibility values pseudo-tree (Algorithm 3, Section 3.1)14:// Propagate decisions top-down along pseudo-tree (Section 3.2):x rootWait message (DECISION, px , ) parent pxx x (px = px , ) // x () computed Algorithm 3, line 21yi childrenx) yi , sepyi Algorithm 3, line 12Send message (DECISION, sep8:9:10:11:15:16:17:18:19:660fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making3.1 Finding Feasible Value Root Variablealready illustrated DPOP Section 2.1.3, agents perform bottom-up propagation feasibility values along pseudo-tree. done Algorithm 3,extension DPOPs UTIL propagation phase (the extensions indicated commentsbold), improves algorithm originally proposed (Faltings et al., 2008)patching important constraint privacy leak single-variable FEAS messagessent variables singleton separators. following sections describe obfuscationtechniques used protect private information could leaked feasibilitymessages, using codenames (Section 3.1.1) addition random numbers (Section 3.1.2).Algorithm 3 Algorithm find feasible value root DFS tree, variable xRequire: DFS-tree ordering variables; px denotes xs parent1: // Join local constraints:2: m(x, px , ) c{c C | xscope(c) scope(c )(childrenx pseudo childrenx )=} c(x, )3:4:5:// Apply codenames:yi {px } pseudo parentsxm(x, px , ) replace (yi , Dyi ) m(x, px , ) (yix , Dyxi ) Algorithm 2, line 2,apply permutation yxi Dyxi// Obfuscate infeasible entries:r large, positive,random number B bitsm(x, px , )m(x, px , ) = 08: m(x, px , )m(x, px , ) + r m(x, px , ) > 06:7:9:10:11:12:13:14:15:// Join received messages:yi childrenxWait message (FEAS, mi (x, )) yisepyi scope(mi )z childrenx pseudo childrenx // resolve codenamesmi (x, ) identify (xz , Dxz ) (x, Dx ) mi (x, ) (if xz present)m(x, px , ) m(x, px , ) + mi (x, )// De-obfuscate feasibility values respect x:17: yi pseudo childrenx18:m(x, px , ) m(x, px , ) keyxyi (x) // keyxyi Algorithm 2, line 1116:// Project x:x root variable21:x (px , ) arg minx {m(x, px , )}22:m(px , ) minx {m(x, px , )}19:20:23:24:25:26:27:// Obfuscate feasibility values:yi pseudo parentsxm(px , ) m(px , ) + keyyxi (yix ) // keyyxi Algorithm 2, line 9Send message (FEAS, m(px , )) pxelse x arg minx {m(x)} // m(x, px , ) actually depends x661fiLeaute & Faltings3.1.1 Hiding Variable Names Values Using CodenamesConsider feasibility message x1 x4 sent agent a(x1 ) parent variable x4Figure 2. message recalled Figure 3(a), reformulated terms minimizingnumber constraint violations. message actually received cleartext, wouldbreach agent privacy topology privacy: agent a(x4 ) would able inferdependency message variable x2 existence agent a(x2 ) (which violatesagent privacy) fact x2 neighbor one unknown nodes x1 .x1 x4x2x4 R B GR0 0 0B0 0 1G0 1 0(a) cleartextx4RBGx1 x49283720 0 00 0 10 1 0(b) partly obfuscatedx4RBGx1 x4928372620961 983655620961 983655620961 983656534687534688534687(c) fully obfuscatedFigure 3: message sent agent a(x1 ) parent variable x4 Figure 2.order patch privacy leaks, variable x2 domain D2 = {R, B, G} replaced random codenames xx2 1 = 928372 D2x1 = {, , } (Figure 3b) preliminarilygenerated a(x2 ) communicated directly leaf back-edge (Algorithm 2,lines 2 7). leaf applies codenames output message (Algorithm 3, line 5),resolved propagation reaches root back-edge (Algorithm 3, line 14). knowing codenames, agents between, a(x4 ),infer existence cycle constraint graph involving unknown ancestor descendent. tolerated definition topology privacy (Definition 5)since also involved cycle. secret, random permutation 2x1 also appliedD2x1 ; useful problem classes variable domains public. Noticex4 also constraint x2 , reasoning would still hold, x2 wouldsent different codename xx2 4 x4 , would able resolveunknown codename xx2 1 x2 . case, x4 separator would {x3 , xx2 1 , xx2 4 },message sent x3 would three-dimensional instead two-dimensional.3.1.2 Obfuscating Feasibility ValuesHiding variable names values using codenames addresses leaks agent topologyprivacy. However, address fact feasibility values messagex1 x4 Figure 3(b) violate constraint privacy, reveal x4 subtreealways find feasible solution subproblem x4 = R, regardless valueobfuscated variable 928372. patch privacy leak, feasibility values obfuscatedadding large, random numbers generated root back-edge (x2 )sent secure channel leaf back-edge (Algorithm 2, lines 9 12).number bits B random numbers problem-independent parameteralgorithm. obfuscation performed way different random number662fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingadded feasibility values associated value x2 , Figure 3(c), usingobfuscation key [620961, 983655, 534687]. random numbers added leafback-edge outgoing message (Algorithm 3, line 25), eventuallysubtracted propagation reaches root back-edge (Algorithm 3, line 18).Notice obfuscation scheme achieves two objectives: 1) hides x4absolute feasibility values subtree, 2) hides relative dependenciesvalues obfuscated variable 928372, different random numbers usedvalue obfuscated domain {, , }. Agent a(x4 ) still able infer relativedependencies variable x4 , necessary perform projectionvariable, unable tell, value (obfuscated) variable, whethersubtrees problem feasible, not, many constraints violated. Noticeparticular that, given value obfuscated variable (i.e. column), agent a(x4 )know whether assignments x4 feasible, therefore wouldincorrect simply assume lowest obfuscated feasibility entries decrypts 0.Similarly, equal entries column correspond high probability entriesnumber constraint violations, number necessarily 0,would incorrect infer correspond feasible entries.Notice also obfuscation scheme applicable presence backedge, i.e. message contains parent variable. Considerinstance single-variable message x5 x3 , recalled Figure 4(a). agent a(x3 ) knewx5 leaf pseudo-tree, cleartext message would reveal agent a(x5 )s privatelocal constraint x5 6 {B, R} agent a(x3 ), previous obfuscation schemeapply absence back-edges. Notice threat constraint privacytempered fact P-DPOP+ guarantees terms topology privacy preventagent a(x3 ) discovering x5 indeed leaf. a(x3 )s point view, largersubproblem might hanging variable x5 Figure 2, message could actuallyaggregation multiple agents subproblems.x3RBGx5 x3# conflicts001(a) cleartextx3x5 x3# conflictsRBG00730957(b) obfuscatedFigure 4: message received agent a(x3 ) Figure 2.reduce privacy leak present original algorithm (Faltings et al., 2008),propose new additional obfuscation scheme consists adding large (B-bit), positive,random numbers positive entries single-variable messages, order obfuscatetrue numbers constraint violations (Algorithm 3, line 8 Figure 4(b)).random numbers never subtracted back, must added zero entries, otherwise algorithm would fail find solution violation. Feasible entries stillrevealed, numbers constraint violations infeasible entries remain obfuscated.663fiLeaute & Faltings3.2 Propagating Final Decisionsfeasibility values propagated way root pseudotree, feasible assignment root variable found (if exists one),assignment propagated pseudo-tree (Algorithm 2, lines 14 19).variable uses assignments contained message parent, order lookcorresponding assignment (line 17). sends child assignmentsvariables separator (line 19), using codenamesprotect agent topology privacy. Decision privacy partially guaranteed,variable learns values chosen parent pseudo-parents other,non-neighboring variables separator hidden unknown codenames.3.3 Algorithm Propertiessection first formally proves algorithm complete, analyses complexity.present algorithm variant lower complexity. Finally, privacy guaranteesprovided algorithms (summarized Table 3.3) formally described.privacy type:agenttopologyconstraintdecisionP-DPOP(+)fullfullfull-partialpartialpartialpartialpartialpartialfullpartialpartialfullfullpartial3/2-DPOP(+)PP2 -DPOP(+)MPC-DisCSP4Table 1: Privacy guarantees various algorithms.3.3.1 Completeness ComplexityTheorem 1. Provided codename clashes, P-DPOP+ (Algorithm 2) terminates returns feasible solution DisCSP, exists one.Proof. exchanging codenames obfuscation keys, guaranteed requirenumber messages quadratic number n variables, bottom-uppropagation feasibility values (Algorithm 3) terminates sending exactly (n 1)messages (one tree-edge). One prove induction (left reader)multi-party dynamic programming computation almost surely correctly revealsvariable x (obfuscated) feasibility subtrees subproblem, function xpossibly ancestor variables pseudo-tree. process may fail casecollisions codenames, roots two overlapping back-edges choosecodenames. codename clashes inherent privacy-protecting algorithms,made improbable desired augmenting size codename space.Finally, top-down decision propagation phase (Algorithm 2, lines 14 19) guaranteed yield feasible assignment variable (if exists one), exchangeexactly (n 1) messages (one tree-edge).664fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingcomes complexity algorithm terms number messagesexchanged, bottleneck election root variable (Online Appendix 1),requires O( n2 ) messages, diameter constraint graph, degree,n number variables. However, (n 1) messages containing feasibilityvalues exponentially large: message sent variable x expressed |sepx ||sep |variable codenames (Algorithm 3, line 12), therefore contains O(Dmaxx ) feasibilityvalues, Dmax size largest variable domain. overall complexityterms information exchange, memory runtime (measured number constraintsepmaxchecks) therefore O(n Dmax), sepmax = maxx |sepx |. DPOP,except P-DPOP+ variable may appear multiple times different codenamesseparator, hereby increasing value sepmax . However, increasemultiplicative factor upper bounded degree constraint graph, sincenumber codenames given variable equal number neighbors.Empirically, experimental results Section 6 suggest that, almost problemclasses considered, median value sepmax tends grow rather linearly n.3.3.2 P-DPOP: Trading Topology Privacy Performancepossible reduce sizes |sepxi | separators, enforcing agent a(x)send codename x x xs (pseudo-)children, unlike Algorithm 2 (lines2 7). variant identified absence plus sign exponent; P-DPOPversion algorithm initially proposed Faltings et al. (2008).result change, variables previously may occurred multiple timesfeasibility message different codenames appearonce, sepmax < n. worst-case complexity P-DPOPbecomes DPOP (Petcu & Faltings, 2005), sepmax equalwidth pseudo-tree, bounded treewidth constraint graph.However, privacy considerations prevents use P-DPOP DPOPs efficient,less privacy-aware pseudo-tree generation heuristics, resulting higher-width pseudo-trees.complexity P-DPOP hereby decreased compared P-DPOP+ , sendingcodename x variable x (pseudo-)children drawbacks termstopology privacy, analyzed below.3.3.3 Full Agent Privacytwo ways identity agent could leaked non-neighbor B:1) algorithm require B exchange messages other, 2) Agentreceive message whose content refers identifiably B. Case 1 never happenalgorithms, ever involve exchanging messages neighboringagents. Case 2 addressed mainly use codenames.Theorem 2. P-DPOP(+) algorithms guarantee full agent privacy.Proof. P-DPOP(+) algorithms proceed following sequential phases (the preliminary phases root election pseudo-tree generation addressed online appendices):Bottom-up feasibility propagation (Algorithm 3) feasibility message containsfunction (line 11) set variables, whose names, transmitted clear665fiLeaute & Faltingstext, could identify owner agent. prevent agent privacy leak, P-DPOP(+)replaces variable names secret, random codenames, follows.Consider variable x pseudo-tree. Note feasibility message sent xancestor x function x. message sent x functionx, x projected message sent (line 22). Variable x cannotre-appear feasibility message higher pseudo-tree, agents localproblem involve variable lower pseudo-tree (line 2).Similarly, consider feasibility message sent descendant xpseudo-tree, assume first leaf pseudo-tree. Sincechildren, feasibility message sends function variableslocal problem. local problem involves x, replace x codename xy(line 5) sends feasibility message. One prove inferencefeasibility message sent variable x contain x either;(and necessarily) contain one several codenames xyi .Since codenames xyi random numbers chosen x (Algorithm 2, line 4),communicated (through channels assumed secure) respectiveneighbors yi x (Algorithm 2, line 7), non-neighbor x receiving messageinvolving xyi discover identity owner agent.domain Dx variable x could also contain values might identify owneragent. fix privacy risk, xs domain also replaced obfuscated domains Dxyirandom numbers, similarly way variable names obfuscated.paper, make simplifying assumption variables domainsize (which naturally holds many problem classes), one variables domainsize give information owner agent. Otherwise, variable domainspadded fake values order make size.Top-down decision propagation (Section 3.2) messages contain assignmentsvariables (Algorithm 2, line 19), also obfuscated using codenames.concludes proof that, P-DPOP(+) algorithms, agent receivemessage infer identity non-neighboring agent.3.3.4 Partial Topology PrivacyTheorem 3. P-DPOP guarantees partial topology privacy. minor leaks topologyprivacy lie fact variable might able discover lower bound neighborvariables degree constraint graph, lower bound total number variables.Proof. Root election pseudo-tree generation left online appendices.Bottom-up feasibility propagation (Algorithm 3) variable x receives FEASmessage child, containing function whose scope might reveal topologicalinformation. variable scope represented secret codename y,however x may able decrypt codename y, neighbor x(or x itself), sent codename neighbors.results leak topology privacy: x discovers, neighboring ancestor y,666fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingwhether least one neighbor given child x. cannotdiscover exactly many neighbors are.Furthermore, case x neighbors, x cannot decrypt y,still infer exists another, non-neighboring ancestor correspondingcodename. another breach topology privacy. sentcodename neighbors, x also discover whether ancestorleast one neighbor xs children. Moreover, since codenameslarge random numbers almost surely unique, x may discover existenceseveral, distinct non-neighboring ancestors.Top-down decision propagation (Section 3.2) variable receives messageparent, contain codenames variables variable valuesalready present FEAS message received previous phase.concludes proof P-DPOP partially protects topology privacy. limitedtopology information leaked variable concerns branch pseudo-tree;information leaked branch, even existence.Theorem 4. use different codenames (pseudo-)child improves topologyprivacy P-DPOP+ compared P-DPOP, bounds still leaked.Proof. Consider variable x receives FEAS message including secret codenamecorresponding variable (6= x). sent different codenameneighbors, x longer able decrypt y, even neighbor x. consequence,x longer able infer whether refers known neighbor x, unknown,non-neighboring variable. However, since codename corresponds unique backedge pseudo-tree, pair (, ) unknown codenames xs received FEASmessage (if pair exists), least one following statements must hold:refer two different ancestors x, therefore x discovers leasttwo ancestors (which might known, pseudo-parent); and/orsent two different descendants x (and possibly including)sender child y, therefore x discovers least two descendants(and including) (which might known, pseudo-child y).Therefore x might able refine lower bound total number variables.3.3.5 Partial Constraint PrivacyTheorem 5. P-DPOP(+) algorithms guarantee partial constraint privacy. localfeasibility subproblem partial variable assignment X may leaked, even Xcannot extended overall feasible solution (i.e. semi-private information).Proof. Information constraints transmitted feasibility propagation (Algorithm 3). Based knowledge optimal variable assignments transmittedlast phase (Section 3.2), feasibility information may decrypted.667fiLeaute & FaltingsSingle-variable feasibility messages variable px receives feasibility messageinvolving px , message obfuscated adding secret randomnumbers infeasible entries (line 8). Feasible entries remain equal 0, pxidentify entries refer respectively feasible infeasible assignments px .However, addition secret, positive, random number infeasible entryensures upper bound number constraint violations leaked,made loose desired choosing random numbers large necessary.Multi-variable feasibility messages FEAS message involves least onevariable yi , message entries obfuscated adding large randomnumbers keyyxi (yix ) B bits (line 25). Furthermore, keyyxi (yix ) knownsender x message pseudo-parent yi , recipient px ,therefore cannot subtract de-obfuscate entries.Assume, simplicity, message m(px , yix ) involves two variablespx yix ; argument extends easily variables. recipient px mightable make inferences: 1) fixing yix comparing obfuscated entriescorresponding different values px ; 2) fixing px varying yix instead.1. given value yix , entries obfuscated addingrandom number keyyxi (yix ) (line 25), px compute relative differencesfeasibility values various assignments px . However, cannot decryptabsolute values without knowing keyyxi (yix ). particular, lowest obfuscatedvalue necessarily equal keyyxi (yix ), necessarily decrypt0: values px may infeasible particular value yix .one exception: feasible solution found problemyix = yix px = px , m(px , yix ) necessarily decrypts 0, thereforepx able infer keyyxi (yix ). fixing yix = yix messagesubtracting keyyxi (yix ), reasoning made single-variablecase, feasible infeasible entries identifiable, numbersconstraint violations infeasible entries remain obfuscated.2. given value px , feasibility value m(px , yix ) obfuscatedadding different, secret random number keyyxi (yix ). Choosing numberbits B sufficiently large makes sure useful information (relative,absolute) obtained comparing obfuscated feasibility values.concludes proof P-DPOP(+) guarantees partial constraint privacy.3.3.6 Partial Decision PrivacyTheorem 6. P-DPOP(+) algorithms guarantee partial decision privacy. leak liesfact variable might discover values chosen neighbors.Proof. First notice algorithm cannot leak information chosen valuesvariables lower pseudo-tree, since variables projectedfeasibility messages received. However, decision propagation phase,variable receives message parent contains chosen values parent668fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingpseudo-parents. message may also contain codenames assignments other, nonneighboring variables, recipient able decode. Furthermore, domainsshuffled using secret permutations, making impossible decode codenamevalue non-neighboring variable index variables domain.4. P3/2 -DPOP+ : Adding Full Decision Privacysection presents another variant P-DPOP+ algorithm achieves full decisionprivacy. results novel algorithm, seen hybridP-DPOP+ P2 -DPOP (Leaute & Faltings, 2009) algorithms, called P3/2 -DPOP+.4.1 Overview AlgorithmAlgorithm 4 patches decision privacy leak P-DPOP+ removing decision propagation phase. root variable assigned value, order variablesassigned values, variable made root turn (unless first feasibility propagationrevealed problem infeasible, case algorithm terminate early).3intuition behind P /2 -DPOP+ algorithm therefore P-DPOP+ bottom-upfeasibility propagation phase repeated multiple times, time different variable xroot pseudo-tree (lines 10 15). end iteration, constraintx = x added problem enforce consistency across iterations (line 16).Algorithm 4 Overall P3/2 -DPOP+ algorithm full decision privacy, variable xRequire: first temporary DFS tree, unique ID idx , tight strict lower bound+next unique ID id+x , upper bound n total number variablesidxid+x idxz }| { z }| {1: vectorx [1, . . . , 1, 0, 1, . . . , 1, 1, . . . , 1]|{z}n+2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:// Exchange public key shares:privatex generate private ElGamal key xpublicx generate set (id+x idx + 1) public key shares corresponding privatexshare publicx ToPrevious((SHARE, share)) Algorithm 9= 1 . . . n+Wait record one message (SHARE, share)share 6 publicx ToPrevious((SHARE, share)) Algorithm 9Generate compound ElGamal public key based public key sharesvectorx 6=Choose new root (Algorithm 5, Section 4.2)Construct new pseudo-tree rooted new root (Online Appendix 2)Exchange codenames x domain Dx (Algorithm 2, lines 2 7)Choose exchange obfuscation key x (Algorithm 2, lines 9 12)Propagate feasibility values pseudo-tree (Algorithm 3, except line 21)x root Add local constraint x = x , x Algorithm 3, line 27669fiLeaute & Faltings4.2 Choosing New Root Variableiteratively reroot pseudo-tree, propose use improved version rerootingprocedure initially introduced P2 -DPOP algorithm (Leaute & Faltings, 2009).procedure requires n variables assigned unique ID; algorithmachieve presented Online Appendix 3. algorithm reveals variable xunique ID idx , well tight strict lower bound next unique ID id+x (i.e.+ total number variables.+1),upperboundnnext unique ID equals id+xvariable x creates Boolean vector vectorx single zero entry indexcorresponding unique ID idx (Algorithm 4, line 1); vector shuffled usingrandom permutation used hide sequence variables become roots.keep permutation secret, vector first encrypted using ElGamal encryption(Appendix A), based compound public key jointly produced agents (Algorithm 4,lines 2 9). asymmetric encryption scheme enables agent (re-)encryptentries vectors using common public key, decryptionperformed collaboratively agents, using respective private keys.Algorithm 5 Algorithm choose new root, variable xProcedure: ShuffleVectors() variable x1: myID large random number2: px random permutation [1 . . . n+ ]// Propagate xs encrypted vector backwards along circular orderingvectorx E(vectorx ) // encrypts vector using compound public key5: ToPrevious((VECT, myID, vectorx , 1)) Algorithm 9 Appendix B3:4:// Process received vectors7: true8:Wait message (VECT, id, vector, round) next variable6:9:10:11:12:13:14:15:16:17:18:19:20:round = 1id 6= myID j = (idx + 1) . . . id+x vector[j] 1else round round + 1 // xs vector; move next roundround > 1 x current rootround round + 1 // root starts round except firstround = 3 vector px (vector) // shuffle vectorround = 4 id = myID // done processing vectorxvectorx vectorcontinue// Pass vector backwards along circular orderingvector E(vector) // re-encrypts vector using compound public keyToPrevious((VECT, id, vector, round)) Algorithm 9 Appendix BProcedure: Reroot() variable x21: repeat entry Decrypt(pop(vectorx )) entry 6= 1 // Algorithm 622: entry = 0 x new root670fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingagents proceed Algorithm 5. variable x first starts procedureShuffleVectors(), run performance improvementprevious work (Leaute & Faltings, 2009), performed iteration.vectors passed variable variable round-robin fashion, using circular messagerouting algorithm presented Appendix B. agent applies secret permutationvector shuffle it. ShuffleVectors() proceeds four rounds. round 1(started line 5, Algorithm 5), vector makes full round along circular ordering,variable x overwrites entries 1 (line 10),positions vectorx (Algorithm 4, line 1). 1 entries accountIDs [idx + 1, id+x ] assigned variable (Online Appendix 3).x received back vectorx , enters incomplete round 2 (line 11)vectorx passed reaches current root (line 12). root starts round 3(line 13), variable x shuffles vector using secret permutation px(line 14). incomplete round 4 returns fully shuffled vector owner (line 16).reroot variable ordering beginning iteration P3/2 -DPOP+ ,variable x calls procedure Reroot(), removes decrypts first elementvectorx . Entries decrypt 1 correspond unassigned IDs skipped.single entry decrypts 0 identifies new root. decryption process (Algorithm 6)collaborative effort involves variable using private ElGamal key partiallydecrypt cyphertext, travels around circular variable ordering wayvectors, gets back sender variable, finally fully decrypt it.Algorithm 6 Collaborative decryption multiply-encrypted cyphertext eProcedure: Decrypt(e) variable x1: codename large random number used secret codename x2: codenamesx codenamesx {codename}3: ToPrevious((DECR, codename, e)) Algorithm 94: Wait message (DECR, codename, e ) next variable ordering5: return decryption e using xs private keyProcedure: CollaborativeDecryption() variable x6: loop7:Wait message (DECR, c, e) next variable ordering8:c 6 codenamesx9:e partial decryption e using xs private key10:ToPrevious((DECR, c, e )) Algorithm 94.3 Algorithm Properties3first analyze completeness complexity properties P /2 -DPOP(+) algorithms, move privacy properties.4.3.1 Completeness ComplexityTheorem 7. Provided codename clashes, P3/2 -DPOP+ algorithmterminates returns feasible solution DisCSP, exists one.671fiLeaute & FaltingsProof. basis Theorem 1, remains prove rerooting Algorithm 5terminates correct, overall algorithm remains correct. latter easyprove: iteration, feasible value found root variable (if existsone), value necessarily consistent chosen assignments previous rootssince assignments enforced new, additional constraints (Algorithm 4, line 16).comes rerooting procedure, unique ID assignment algorithm (OnlineAppendix 3) ensures n variables gets unique ID 0 . . . (n+ 1). Therefore,variable 0 entry unique position vector (Algorithm 4, line 1). Round 1Algorithm 5 also makes sure vectors 1 entries positions.ensures exactly one variable become new root iteration, since vectorsapplied sequence permutations, variable root twice.3terms complexity, P /2 -DPOP+ proceeds similar way P-DPOP+ (Section 3.3), except bottom-up feasibility propagation phase repeated n times (eachtime different root variable). overall complexity information exchange theresepfore becomes O(n2 Dmaxmax ), sepmax maximum separator size variables,iterations, therefore likely higher exponent PDPOP+ . information exchanged rerooting protocol negligible comparison.sepruntime complexity (measured number constraint checks) also O(n2 Dmaxmax ),sepmemory complexity O(n Dmaxmax ), removing decision propagation phase makes become unnecessary compute record x (px , ) (Algorithm 3,line 21). experimental results graph coloring benchmarks (Section 6.1) suggestmedian value sepmax may greater median value sepmax PDPOP+ small multiplicative factor. terms number ElGamal cryptographicoperations, rerooting procedure requires total n(3n 1)n+ O(n3 ) encryptions:n variables (re-)encrypts (3n 1) vectors size n+ (each variables vectorperforms 3 full rounds, except roots vector, performs 2 full rounds),n+ n + n 2incrmin , incrmin constant input parameter algorithm.procedure also requires total n2 n+ O(n3 ) collaborative decryptions:n variables (partially) decrypts n vectors size n+ .4.3.2 Full Agent PrivacyTheorem 8. P3/2 -DPOP(+) algorithms guarantee full agent privacy.Proof. unique ID assignment circular routing algorithms guarantee full agent privacy, demonstrated respectively Online Appendix 3 Appendix B.Pseudo-tree rerooting (Algorithm 5) messages sent ShuffleVectors() contain variable ID, vector ElGamal cyphertexts, round number. IDused recipient detect whether vector vector; largerandom number chosen owner agent (Algorithm 5, line 1), thereforecannot linked identity owner agent agent. ElGamalvector round number also contain information could usedidentify agent. Also note procedure used exchange ElGamal publickey shares (Algorithm 4, lines 2 9) leak information agents672fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingidentities. Reroot() procedure makes use collaborative decryptionalgorithm, whose properties terms agent privacy discussed below.Collaborative decryption (Algorithm 6) procedure exchanges messages contain ElGamal cyphertext, codename used like variable ID Algorithm 5.codename similarly set large random number chosen current agent,cannot linked identity agent agent.3concludes proof P /2 -DPOP(+) algorithms guarantee agent privacy.4.3.3 Partial Topology Privacy3topology privacy P /2 -DPOP(+) slightly worse P-DPOP(+) .Theorem 9. P3/2 -DPOP(+) algorithms guarantee partial topology privacy. variable unavoidably discovers total number variables problem, might alsodiscover lower bound neighbor variables degree constraint graph. advan33tages P /2 -DPOP+ P /2 -DPOP P-DPOP+ P-DPOP.Proof. Since one feasibility propagation phase per variable problem, totalnumber variables inevitably becomes public. following analyzes topology privacyproperties phase P3/2 -DPOP(+) already present P-DPOP(+) , exceptunique ID assignment (Online Appendix 3) secure message routing (Appendix B).Exchange ElGamal key shares (Algorithm 4, lines 29) messages containing ElGamal key shares contain information could used makeinferences topology constraint graph.Pseudo-tree rerooting (Algorithm 5) message travels along circular variableordering using message routing algorithm Appendix B, contains:vector encrypted (and re-encrypted operation) therefore cannot provide topological information;id identifies owner vector; secret, large random number,owner vector identify itself;round number take following values:round = 1 indicates vector modified, variablesetting turn values 1;round = 2 indicates vector sent rootpseudo-tree. happen vector (unknown) root;round = 3 indicates vector shuffled variable;round = 4 indicates vector way back owner.happen vector belonging (unknown) root.Reroot() uses decryption algorithm whose properties described below.673fiLeaute & FaltingsCollaborative decryption (Algorithm 6) DECR messages passed along circular variable ordering, containing secret codename original sender variable,variable capable deciphering codename. last partmessage payload ElGamal cyphertext, remains encrypted reachesback original sender, therefore leak topological information.3concludes proof P /2 -DPOP(+) guarantees partial topology privacy.4.3.4 Partial Constraint Privacy3constraint privacy properties P /2 -DPOP(+) algorithms differ PDPOP(+) , former protect decision privacy (which benefits constraint privacy),also reveal total number variables problem (which hurts constraint privacy).Theorem 10. P3/2 -DPOP(+) algorithms guarantee partial constraint privacy.leaks P-DPOP(+) (Section 3.3.5), happen less frequently.Proof. Single-variable feasibility messages leak amount constraint privacyP-DPOP(+) ; notice however that, since P3/2 -DPOP(+) algorithms reveal totalnumber variables, circumstances may possible variable discoverchild leaf, feasibility message sends therefore contains informationlocal subproblem only. However, multi-variable feasibility messages leak potentially muchless information P-DPOP(+) : consider simpler non-restrictive case3two-variable message m(px , yix ) received px . P /2 -DPOP(+) protectsdecision privacy, px longer discovers value yix chosen yix , thereforelonger able infer entries corresponding px = px decrypts 0.One exception following three conditions simultaneously hold: 1) P3/2 -DPOPused, 2) codename yix refers variable yix neighbor px , 3) yixsemi-private information px ; px still discover yix , able make3inferences P-DPOP(+) . first condition satisfied, i.e. P /2 -DPOP+3used instead P /2 -DPOP, px able link codename yix known3variable. also case P /2 -DPOP used, second conditionhold. Finally, first two conditions hold, px able discover yixsemi-private information, i.e. infer knowledge problem,chosen value px .4.3.5 Full Decision PrivacyTheorem 11. P3/2 -DPOP(+) algorithms guarantee full decision privacy.Proof. leak decision privacy P-DPOP(+) fixed removing decision propagation phase. Instead, variable ordering rerooted, feasibility propagationphase restarted. possible compare feasibility messages received oneiteration next infer decision made previous iteration:messages comparable, since different codenames obfuscation keys used.674fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making5. P2 -DPOP+ : Adding Full Constraint Privacydescribe previous, non-fully secure obfuscation scheme replacedElGamal homomorphic encryption (Appendix A) achieve full constraint privacy,corresponds original P2 -DPOP algorithm (Leaute & Faltings, 2009), improveduse multiple codenames. important limitation ElGamal schemefully homomorphic: possible compute two encrypted Booleans,possible compute encrypted Boolean cleartextBoolean. consequence, bottom-up feasibility propagation performedvariable ordering variable one child, i.e. linear variableordering (Figure 5), using message routing algorithm Appendix B. Otherwise,pseudo-tree variable ordering, variable two children would able jointwo encrypted feasibility messages sent children. could addressed usingfully homomorphic encryption scheme Gentry (2009), however unclear whetherscheme would practically applicable would sufficient performance.x2x3x1x5x4Figure 5: (counter-clock-wise) circular variable ordering corresponding Figure 2.5.1 Propagating Encrypted Feasibility Values along Linear Variable Ordercontrast Figure 2, illustrates multi-party dynamic programming pseudotree variable ordering (counting constraint violations), Figure 6 shows (in cleartext)carried linear ordering (in Boolean domain). assumescircular communication structure preliminarily set described Appendix B.Algorithm 7 gives detailed pseudocode procedure, intendedreplacement line 15 Algorithm 4. differences pseudo-tree-based Algorithm 3 following. First, Algorithm 3 initially reformulated DisCSPMax-DisCSP minimize number constraint violations, Algorithm 7 worksdirectly original DisCSP problem. means conjunction operatorreplaces sum operator (lines 2 10), disjunction operator replacesoperator min (line 13). Notice also that, case linear ordering, variables localsubproblem longer necessarily involves parent variable ordering (line 2),like x4 shares constraint x5 Figures 5 6.next difference variable x longer partially de-obfuscates feasibilitymatrix projecting (Algorithm 3, line 18). reason ElGamalscheme homomorphic, therefore longer necessary first (partially) decrypt675fiLeaute & Faltingsx2x3 x2RBtrue falseGtruex2x3x3RBGx5 x3x2RBtrue falsetruetruefalse falsex4 x5x2RBtrue falsetrue truetrue truex3RBGx5Gtruetruefalsex4x4RBGGtruetruetruex1x1 x4x2RBtrue truetrue truetrue falseGtruefalsetrueFigure 6: Multiparty dynamic programming computation (in cleartext) feasible valuevariable x2 , using linear variable ordering based Figure 5.Algorithm 7 Propagating feasibility values along linear ordering, variable x1: // Join local constraints:V2: m(x, ) c{c C | xscope(c ) scope(c )(childrenx pseudo childrenx )=} c(x, )// Apply codenames:4: yi {parentx } pseudo parentsx5:m(x, ) replace (yi , Dyi ) m(x, ) (yix , Dyxi ) Algorithm 2, line 2,apply permutation yxi Dyxi3:6:7:8:9:10:// Join received message:Wait message (FEAS, ()) next variable orderingz childrenx pseudo childrenx() identify (xz , Dxz ) (x, Dx ) () (if xz present)m(x, ) m(x, ) ()// Project x:x rootW variable13:m() E ( x m(x, )) // re-encrypts using compound public key14:ToPrevious((FEAS, m())) Algorithm 915: else x FeasibleValue(m(x, )) Algorithm 811:12:676fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingfeasibility values project x using operator x . root variable requiresdecryption (Algorithm 7, line 15) find value x variable x whose encryptedfeasibility value decrypts true (if any). described following section.5.2 Decrypting Feasible Value Root Variabledecryption feasibility values root collaborative process variable partially decrypts cyphertext using private key (Algorithm 6). dichotomyprocedure Algorithm 8 uses least log2 |Dx | log2 |Dx | + 1 decryptionsfind feasible assignment root variable, detect infeasibility.Algorithm 8 Finding feasible value encrypted feasibility matrix m(x)Procedure: FeasibleValue(m (x = xil . . . xir ))1: il < ir hthenki half remaining subdomain:j // cutil +ir2:il ,2W3:f easible Decrypt iI (x = xi ) Algorithm 64:f easible = true return FeasibleValue(m(x = xiI ))5:else return FeasibleValue x = xi[il ,ir ]Ielse // one value remains x7:f easible Decrypt(m (x = xil )) Algorithm 68:f easible = true return xil else return null6:5.3 Algorithm Propertiesfirst analyze completeness complexity properties P2 -DPOP(+) algorithms,move privacy properties.5.3.1 Completeness ComplexityTheorem 12. Provided codename clashes, P2 -DPOP+ algorithmterminates returns feasible solution DisCSP, exists one.Proof. Termination follows Theorem 7, fact message routingprocedure Appendix B guarantees feasibility messages eventually reach destinations. comes completeness, homomorphic property ElGamal schemeensures projection variable x encrypted feasibility matrix correct,feasibility message received variable linear ordering summarizes(encrypted) feasibility lower agents aggregated subproblems, function highervariables. particular, feasibility message received root allows find valuevariable satisfies overall problem, exists one.analysis complexity algorithm remains similar analysis Secseption 4.3: O(n2 Dmaxmax ) information exchange number constraint checks,sepO(n Dmaxmax ) memory, sepmax maximum separator size alongsuccessive linear variable orderings, instead along pseudo-trees. requirement677fiLeaute & Faltingsvariable may one child tends make exponent increase significantly,illustrated empirically Section 6. terms number ElGamal cryptographic operations, addition cost rerooting variable ordering (Section 4.3), algorithmsepalso requires O(n2 Dmaxmax ) encryptions, O(n log Dmax ) collaborative decryptions.5.3.2 Full Agent PrivacyTheorem 13. P2 -DPOP(+) algorithms guarantee full agent privacy.3Proof. changes introduced P2 -DPOP(+) respect P /2 -DPOP(+)feasibility propagation, finding feasible value root variable.ElGamal feasibility propagation (Algorithm 7) point view agent privacy, procedure Algorithm 3, using Algorithm 9 messagerouting, algorithms guarantee agent privacy.Root variable assignment (Algorithm 8) consists iteratively calling procedure Algorithm 6, already shown guarantee agent privacy.concludes proof P2 -DPOP(+) algorithms guarantee agent privacy.5.3.3 Partial Topology PrivacyTheorem 14. P2 -DPOP(+) algorithms guarantee partial topology privacy. additionlimited leaks topology privacy P3/2 -DPOP(+) , agent might also ablediscover exists another branch constraint graph involved in.3Proof. two relevant differences P /2 -DPOP(+) : linear variable ordering, choice value root variable requires collaborative decryption.ElGamal feasibility propagation (Algorithm 7) exchange FEAS messages alonglinear variable ordering, algorithm makes use circular message routingprocedure, shown Appendix B guarantee full topology privacy. However,last variable linear ordering needs know last order initiatefeasibility propagation; therefore, contraposition, non-last variables knowlast, and, particular, non-last leaves pseudo-tree discoverexistence another branch. minor leak topology privacy already presentunique variable ID assignment algorithm (Online Appendix 3). Besides this,topology privacy properties feasibility propagation phases P2 -DPOPP2 -DPOP+ P-DPOP P-DPOP+ , respectively.Root variable assignment (Algorithm 8) algorithm involves recursively callingcollaborative decryption procedure, shown guarantee full topology privacy.concludes proof P2 -DPOP(+) guarantees partial topology privacy.678fiProtecting Privacy thru Distributed Computation Multi-agent Decision Making5.3.4 Full Constraint PrivacyTheorem 15. P2 -DPOP(+) algorithms guarantee full constraint privacy.Proof. P2 -DPOP(+) algorithms fix leaks constraint privacy P<2 -DPOP(+) ,replacing cryptographically insecure obfuscation addition random numbers, cryptographically secure ElGamal encryption (Appendix A). makeslonger possible compare two encrypted feasibility values without decrypting them,would require collaboration agents (or amount computation breakencryption made arbitrarily high worst case increasing ElGamalkey size). particular, possible compute logical two cyphertextswithout decrypting them, result remains encrypted, cannot compared twoinputs decide one true, any.5.3.5 Full Decision PrivacyTheorem 16. P2 -DPOP(+) algorithms guarantee full decision privacy.Proof. proof applies Theorem 11.6. Experimental Resultsreport empirical performance algorithms state-of-the-art MPCDisCSP4 algorithm, four classes benchmarks: graph coloring, meeting scheduling,resource allocation, game equilibrium. compare MPC-DisCSP4,knowledge general DisCSP algorithm provides strong privacyguarantees. problem class, choice DisCSP formulation crucial,dictates four types privacy defined based DisCSP constraint graphrelate actual privacy original problem. particular, P -DPOP(+) algorithms use standard DisCSP assumption constraint known agentsowning variable scope (Section 2.2.2). Therefore, agent wants hideconstraint neighboring agents, must express constraint copies neighbors variables. Additional equality constraints must introduced make copy variablesequal respective original variables. contrast, MPC-DisCSP4 make useDisCSP assumption, therefore need introduction copy variables.first performance metric simulated time (Sultanik, Lass, & Regli, 2007),used, agents simulated single machine, estimate time wouldtaken solve problem run parallel dedicated machines (ignoringcommunication delays). two metrics number messages amountinformation exchanged. metric, report median least 100 probleminstances, 95% confidence intervals. obfuscation P<2 -DPOP(+) , usedrandom numbers B = 128 bits, P2 -DPOP(+) used 512-bit ElGamal encryption.MPC-DisCSP4 also used 512 bits Paillier encryption. unique variable IDgeneration procedure P>1 -DPOP(+) , parameter incrmin set 10. algorithmsimplemented inside Java-based FRODO platform DisCSP (Leaute, Ottens, &Szymanek, 2009), coupled CSP solver JaCoP (Kuchcinski & Szymanek, 2011).experiments run 2.2-GHz, dual-core computer, Java 1.6 Javaheap space 2 GB. timeout set 10 min (wall-clock time).679fiLeaute & Faltings6.1 Graph Coloringfirst report performance algorithms distributed, 3-color graph coloringproblems. graphs randomly generated varying numbers nodes,edge density fixed 0.4. Notice that, fixed number colors fixed edgedensity, increasing number nodes increases degree graph, thereforereduces number feasible solutions; explains trends followinggraphs. DisCSP formulation involves one decision variable per node, assumesvariable controlled single-variable agent. Notice inter-agent constraintsbinary inequality constraints, therefore decision privacy relevant problem class:knowing ones chosen color insufficient infer respective colors ones neighbors.study tradeoff privacy performance MPC-DisCSP4, consideredvariant denoted MPC-DisCSP4 , assumes inter-agent inequality constraints (i.e.node neighborhoods) public, final choice colors protected. agentSimulated time (in ms)106Induced width10MPC5MPC108P2 -DPOP+P2 -DPOP1043103P2-DPOP3P2-DPOP6+4P-DPOP+102P-DPOP2DPOP1010345678Number nodes9103Number messages10645678Number nodes910Information exchanged (in bytes)108105107MPCMPC104P>1 -DPOP+3106P>1 -DPOP10P-DPOP+102105P-DPOP101100DPOP345678Number nodes910410310345678Number nodesFigure 7: Performance graph coloring problems.680910fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingfirst enumerates feasible solutions overall problem (Section 2.2.2), usescryptographic techniques securely randomly choose one feasible solutions.exists none, algorithm therefore terminates without cryptographic operationsexchanging messages. explains phase transition MPC-DisCSP4following graphs, since probability infeasibility increases problem size.Figure 7 shows MPC-DisCSP4 (denoted MPC subsequent figures)scales poorly, timing problems 6 nodes. MPC-DisCSP4performs better; however, mentioned before, protects final choices colors.small numbers nodes, total state space small, MPC-DisCSP4 performsrelatively well; numbers nodes 9, problem instances mostly infeasible,MPC-DisCSP4 quickly detects infeasibility without exchange message.efficient algorithms far P-DPOP(+) , whose performance curvesleast one order magnitude algorithms. particular, P-DPOPs runtimesensibly DPOP (the communication overhead almost solely due rootSimulated time (in ms)105Induced width1412104P-DPOP+10P-DPOPDPOP1038610241214161820Number nodes2212Number messages10514161820Number nodes22Information exchanged (in bytes)1091081041071061031051021214161820Number nodes104221214161820Number nodesFigure 8: Performance larger graph coloring problems.68122fiLeaute & Faltingselection algorithm). cost improved topology privacy P-DPOP+ vs. P-DPOPstarts show problem sizes 7, induced widths P-DPOP+ pseudotrees start deviate P-DPOP DPOP. Full decision privacy comes much highercosts: P3/2 -DPOP(+) curve 1 3 orders magnitude P-DPOP(+) s,even though induced widths remain sensibly same. suggests rerootingpseudo-tree (which involves expensive cryptographic operations) far complexitybottleneck, even full constraint privacy additionally guaranteed P2 -DPOP(+) ,whose linear variable orderings nevertheless significantly higher induced widthsP<2 -DPOP(+) pseudo-tree orderings. Notice slope runtime curve decreasesproblem size increases; due fact problems becomeinfeasible, P>1 -DPOP(+) algorithms able terminate first iterationinfeasible problems. Similarly P-DPOP+ vs. P-DPOP, cost improved topologyprivacy visible 7 nodes; P2 -DPOP+ even timed problems size 10.Finally, Figure 7 illustrates fact MPC-DisCSP4 tends send large numberssmall messages, P>1 -DPOP(+) algorithms send lower numbers larger messages.Figure 8 compares performance P-DPOP(+) DPOP larger graph coloring problem instances. larger problems, improved topology privacy PDPOP+ comes complexity price high scale 12 nodes.hand, P-DPOPs curves one two orders magnitude DPOP,P-DPOPs median runtime problem instances size 22 30 s.6.2 Meeting Schedulingreport experimental results random meeting scheduling benchmarks. variednumber meetings, keeping number participants per meeting 2.meeting, participants randomly drawn common pool 3 agents. goalassign time meeting among 8 available time slots, agent requiredattend simultaneous meetings. pool agents deliberately chosen small increasecomplexity problems, increasing probability agent take partmultiple meetings. Note fixing pool size number participants permeeting still generates unbounded number different problem instances increasenumber meetings, since state space (the Cartesian product domainsdecision variables) keeps increasing number meetings/decisions made.DisCSP formulation problem class following. agent ownsone variable domain size 8 meeting participates in. allDifferentconstraint variables enforce meetings scheduled differenttimes. meeting, binary equality constraint expressed correspondingvariables owned two participants enforces participants agree timemeeting. Notice inter-agent constraints binary equality constraints,3therefore P /2 -DPOP(+) bring additional privacy compared P-DPOP(+) ,since values neighboring variables semi-private information; therefore,report performance P3/2 -DPOP(+) . MPC-DisCSP4, simplified formulationintroducing one variable per meeting, owned initiator. way,meeting, initiator made public, exact list participants remains secret(it revealed posteriori participants meeting attend it).682fiProtecting Privacy thru Distributed Computation Multi-agent Decision MakingSimulated time (in ms)1065105P2 -DPOP+P2 -DPOP104MPC43P-DPOP+103P-DPOP2DPOP102101Induced width61012345Number meetings61Number messages1062345Number meetings6Information exchanged (in bytes)10810510710410631010510210410110012345Number meetings103612345Number meetings6Figure 9: Performance meeting scheduling problems.seen Figure 9, P2 -DPOPs performance comparable MPCDisCSP4 (but much stronger privacy guarantees), although former sends significantly information smallest problems, significantly fewer messageslargest problems could solve within timeout limit. hand,majority threshold scheme, MPC-DisCSP4 actually could provide privacyguarantees problems size 1, since involved 2 agents. algorithms couldscale problems size 4, timed larger problems. P2 -DPOP+ increased topology privacy comes price made time earlier P2 -DPOP;complexity increase due P2 -DPOP+ steeper induced width curve.P-DPOP(+) algorithms remain efficient far: perform 12 orders magnitude better others, terms runtime informationexchanged. like graph coloring, improved topology privacy P-DPOP+ comesprice negligible small problems, grow one order magnitudeproblems size 6, even induced width remains close P-DPOP. terms683fiLeaute & Faltingsruntime information exchange, P-DPOP worse DPOP small factor(since median induced width); however sends approximately one ordermagnitude messages (which mostly due pseudo-tree root election mechanism).6.3 Resource AllocationNext, performed experiments distributed resource allocation benchmarks. Probleminstances produced using combinatorial auction problem generator CATS (LeytonBrown, Pearson, & Shoham, 2000), ignoring bid prices. used temporal matchingdistribution modeling allocation airport takeoff/landing slots, fixing total numberslots (i.e. resources) 8, varying numbers bids. bid requestbundle 2 resources (a takeoff slot corresponding landing slot). Multiple requestsmay placed airline company; airline exactly one fulfilled.Simulated time (in ms)106Induced width51054MPC1043P2 -DPOP(+)P-DPOP(+)1032DPOP10210110123456Number bids7813456Number bids78Information exchanged (in bytes)Number messages1062109108105107104106103105102101104123456Number bids71038123456Number bidsFigure 10: Performance resource allocation problems.68478fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingproblem modeled DisCSP follows (Leaute & Faltings, 2009). Oneagent introduced bidder/airline resource/slot, assumingresource controller different resource provider/airport2 . resource X,bidder B requests resource, one binary variable xb controlledresource provider, models whether B allocatedP resource (xb = 1)(xb = 0). resource provider also expresses one constraint1 variablesenforce resource allocated one interested bidders.variable xb , also introduce one copy variable bx owned bidder B,constraint xb = bx . bidder B expresses constraint variables,enforcing allocated two resources correspond exactly onerequests. introduction copy variables motivated DisCSP assumptionagent knows constraints involving variables, serves two privacy-relatedpurposes: 1) full list agents placing requests given resource knownresource provider, 2) full list resources requested given agent (andbundles) known agent itself. Like meeting scheduling problem class,inter-agent constraints equality constraints, therefore report performanceP3/2 -DPOP(+) , whose privacy guarantees P-DPOP(+) .MPC-DisCSP4, DisCSP formulation simplified introducing copyvariables hold bidders, since necessary protect constraint privacy: biddersrequest resources expressing constraints directly variables ownedresource providers. However, since MPC-DisCSP4 assumes variables public,order increase topology privacy introduced, resource, many variablesbidders, regardless whether actually interested resource. reducesize search space, assumed 1 constraints public.Figure 10 shows performance MPC-DisCSP4 decreases fastnumber requests, algorithm able scale beyond problemssize 4. P2 -DPOP(+) algorithms seem scale better, able solve problemsinvolving 5 requests. three metrics, algorithms largely outperformedP-DPOP(+) , whose runtime curve remarkably flat, almost overlaps runtimecurve DPOP, consistent undistinguishable induced width curves.overhead P-DPOP(+) compared DPOP slightly larger terms informationexchanged, goes one order magnitude terms number messages. PDPOP+ P2 -DPOP+ performed respective non-plus variants.6.4 Strategic Game EquilibriaFinally, report experimental results one last class problem benchmarks,corresponds distributed computation pure Nash equilibria strategic games.used particular example party game introduced Singh et al. (2004),one-shot, simultaneous-move, graphical game (Kearns, Littman, & Singh, 2001)players invited common party, players possible strategies whetherattend party not. Players arranged undirected social graph,defines invitees player knows. players reward attending2. CATS assumes single auctioneer, specify slot airport;assumed resource provided separate resource provider.685fiLeaute & Faltingsparty depends whether acquaintances also decide attend, whetherlikes not. reward 1 per attendee likes, minus 1 per attendee dislikes,minus constant cost attendance [0, 1]. reward attending 0.problem computing Nash equilibrium game formulatedDisCSP follows. player agent, owns one binary variablestrategy, one copy variable strategy acquaintances. variableconstrained equal copy variables, using binary equality constraints likeresource allocation problems (Section 6.3). agent also expresses one constraintvariables, allows particular strategy agent best responseneighbors joint strategies. Notice resulting constraint graphgame graph, due presence copy variables. solution DisCSP thereforeyields joint strategy profile players pure Nash equilibrium, sinceplayer plays best-response neighbors. Notice also that, since player holds copySimulated time (in ms)106Induced width1091058104P2 -DPOP(+)7MPC6P-DPOP103(+)54DPOP32102110123456Number players72Number messages1053456Number players7Information exchanged (in bytes)10810710410631010510210110423456Number players103723456Number playersFigure 11: Performance party games.6867fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingvariable neighbors strategy, strategies semi-private informationcannot protected, report performance P3/2 -DPOP(+) .MPC-DisCSP4, DisCSP formulation simplified introducing copyvariables (Vickrey & Koller, 2002). interesting consequence difference that,contrary P1 -DPOP(+) , MPC-DisCSP4 able hide players chosen strategyneighbors. context party game, useful playersdecide attend party, since necessarily eventually discover whetheracquaintances also decided attend not. hand, player declinesinvitation directly discover anything list attendees. might stillable make indirect inferences decisions acquaintances, basedfact decision decline best response respective chosen strategies.Figure 11 reports performance algorithms random acyclic game graphsdegree 2 (i.e. trees node 2 children), varying numbersplayers. P2 -DPOP(+) algorithms able scale problems size 5due rapidly increasing induced width, outperformed MPC-DisCSP4least one order magnitude across three metrics. algorithms still performedlargely worse P-DPOP(+) algorithms, capable scaling much largerproblems. because, setting, induced width remains bounded: sincegame graphs acyclic, DPOPs induced width constantly equal 2,FEAS message sent agent ax parent agent ay expressed ay strategyvariable copy ax strategy variable held ay . P-DPOP(+) induced widthincreased 2 agent ay 2 children pseudo-tree, usingdifferent codename ay strategy variable. result, performance overheadP-DPOP(+) compared DPOP minimal terms runtime; slightly largerinformation exchanged, reaches one order magnitude number messages.7. Conclusionpaper, addressed issue providing strong privacy guarantees Distributed Constraint Satisfaction Problems (DisCSPs). defined four types information problem agents might want hide other: agent privacy(hiding agents identity non-neighbors), topology privacy (keeping topologyconstraint graph private), constraint privacy (protecting knowledge constraints), decision privacy (the final value variable knownowner agent). Departing previous work literature, addressedsubsets privacy types, often focused quantifying privacy loss various algorithms, proposed set algorithms strong guaranteesinformation provably leaked.carried performance experiments four different classes benchmarks:graph coloring, meeting scheduling, resource allocation, game equilibrium computation.results show algorithms provide stronger privacy guarantees, alsoscale better previous state art. explored tradeoffprivacy performance: P-DPOP+ variant shown scale much betterothers, guarantee partial constraint decision privacy, may stillconsidered sufficient many problem classes. Full decision privacy (P3/2 -DPOP+ ) full687fiLeaute & Faltingsconstraint privacy (P2 -DPOP+ ) come significantly higher prices computation timeinformation exchange, which, todays hardware, limits applicability smallerproblem instances. compared performance algorithms MPCDisCSP4 algorithm, considered previous state art DisCSPstrong privacy guarantees. first three classes benchmarks, algorithmsalmost systematically outperformed MPC-DisCSP4 terms runtime numbermessages exchanged; however, MPC-DisCSP4 proved exchange less informationP>1 -DPOP+ . game equilibrium computation, MPC-DisCSP4 scaled much betterP2 -DPOP+ along three metrics, still largely outperformed P-DPOP+ .terms practical applicability, shown algorithms scale mediumsize problems beyond reach previous state art general DisCSPstrong privacy guarantees. also investigated application algorithmsreal-life meeting scheduling, collaboration Nokia Research Center Lausanne.Future work could extend techniques paper along several directions. First,restricted pure satisfaction problems sake simplicity,algorithms easily extended solve Distributed Constraint Optimization Problems (DCOPs). fact, P<2 -DPOP+ algorithms already optimization algorithms;P2 -DPOP+ requires changes applied DCOPs. changes involvereplacing ElGamal-encrypted Boolean feasibility values ElGamal-encrypted, bit-wisevector representations integer cost values, described Yokoo Suzuki (2002).would incur increase complexity linear upper bound costoptimal solution. optimization variant MPC-DisCSP4, called MPC-DisWCSP4,also already proposed Silaghi Mitra (2004); report performance comparisonsalgorithms publications (Leaute & Faltings, 2011; Leaute, 2011).avenues future research could result relaxing assumption agentshonest, curious. number challenging issues arise attempting applytechniques paper self-interested agents manipulate protocolorder achieve solutions better suit selfish preferences. One issueverifiability, involves making possible check whether protocols executeddesigned, without need decrypt messages exchanged. Another interesting issuewhether possible modify algorithms make incentive-compatible,agents best interest honestly follow protocol.Appendix A. Cooperative ElGamal Homomorphic EncryptionHomomorphic encryption crucial building block privacy-preserving algorithmsintroduced paper. Encryption process message appendix,Boolean turned cyphertext, way decrypting cyphertextretrieve initial cleartext message impossible (or, case, computationallyhard worst case) without knowledge secret encryption key usedproduce cyphertext. encryption scheme said homomorphic possibleperform operations cyphertexts translate operations initial cleartextmessages, without need know encryption key. ElGamal encryption (Elgamal,1985) one encryption scheme possesses homomorphic property.688fiProtecting Privacy thru Distributed Computation Multi-agent Decision MakingA.1 Basic ElGamal Encryption BooleansElGamal encryption used encrypt Booleans performing followingoperations encrypted Booleans possible without knowledge decryption key:encrypted cleartext Boolean;two encrypted Booleans.ElGamal encryption homomorphic, public key cryptography system basedintractability Diffie-Hellman problem (Tsiounis & Yung, 1998), proceedsfollows. Let p safe prime form 2rt + 1, r large random number,large prime. numbers computations modulo p. Let g generatorZp , i.e. g powers cover [1, p 1]. p g assumed public knowledge,ElGamal private key chosen random number x [1, p 2], associated publickey = gx . cleartext number encrypted follows:E(m) = (, ) = (my r , gr )(1)r random number chosen encryptor. Decryption proceeds follows:r==m.x(gr )xuseful feature ElGamal encryption allows randomize encrypted valuegenerate new encryption bearing similarity original value. RandomizingE(m) Eq. (1) yields:E 2 (m) = (y r , g r ) = (my r+r , gr+r )still decodes m. encrypt Booleans, represent false 1, truevalue z 6= 1, allows us compute operations:E(m) true = E 2 (m) ;E(m) false = E(1)E(m1 ) E(m2 ) = (1 2 , 1 2 ) = E(m1 m2 ) .A.2 Cooperative ElGamal Encryptionprevious ElGamal encryption scheme, decryption performed single step,using private key, secret agent originally encrypted message.However, also possible perform ElGamal encryption way agentsneed cooperate order perform decryption. possible usecompound ElGamal key (x, y) generated cooperatively agents (Pedersen, 1991):Distributed Key Generation ElGamal key pairs (xi , yi ) n agents combined following fashion obtain compound key pair (x, y):x = ni=1 xi= ni=1 yi .Distributed Decryption agent publishes decryption share xi , messagedecrypted follows:= x =m.ni=1 xi689fiLeaute & FaltingsAppendix B. Routing Messages along Circular Variable Orderingorder implement round-robin exchange vectors briefly presented Section 4.1,variables ordered along circular ordering mapped chosen pseudo-tree,illustrated Figure 5 (page 675) . variable needs able send messageprevious variable (i.e. clock-wise) ordering, challengeneighboring variables communicate directly. Furthermore, protect agenttopology privacy, agent know overall circular ordering. solve issue,Algorithm 9 algorithm used P2 -DPOP (Leaute & Faltings, 2009) route messages.Algorithm 9 Sending message clock-wise circular variable ordering.Procedure: ToPrevious(M ) variable x1: x root pseudo-tree Send message (LAST, ) xs last child2: else Send message (PREV, ) xs parentProcedure: RouteMessages() variable x3: loop4:Wait incoming message (type, ) neighbor yi5:type = LAST6:x leaf Deliver message x7:else Send message (LAST, ) xs last child8:else type = PREV9:yi xs first child Deliver message x10:else Send message (LAST, ) child yi xs list childrenConsider instance message agent a(x1 ) wants send previousvariable x4 , a(x1 ) know it. Agent a(x1 ) wraps PREVmessage sends parent variable x4 (line 2). sender variable x1x4 first (and only) child, a(x4 ) infers deliver (line 9). Considera(x4 ) wants forward previous variable x5 , a(x4 )know. Like before, a(x4 ) sends message (PREV, ) parent variable x3 ,reacts sending message (LAST, ) last child preceding x4 list children,x5 (line 10). LAST messages indicate payload deliveredlast leaf current subtree (line 7); therefore, a(x5 ) delivers (line 6) sincechildren. root wants send message previous variable, also usesLAST message forward last leaf overall pseudo-tree (line 1).Theorem 17. Algorithm 9 guarantees full agent privacy.Proof. goal algorithm precisely address agent privacy issues pseudotree rerooting procedure, involves variable sending message previousvariable circular ordering variables. guarantee existcircular ordering two consecutive variables owned neighboring agents,necessary protect agent privacy. Therefore, Algorithm 9 responsible routingmessages paths involve communication neighboring agents.routing procedure involves encapsulating routed messages insidePREV LAST messages, contain payload. Therefore, long690fiProtecting Privacy thru Distributed Computation Multi-agent Decision Makingrouted messages contain information used identify nonneighboring agent, routing procedure guarantees agent privacy.Theorem 18. Algorithm 9 guarantees full topology privacy.Proof. purpose algorithm enable variables propagate messages alongcircular variable ordering, without need know topological informationconstraint graph, knowledge respective (pseudo-)parents(pseudo-)children pseudo-tree. ToPrevious() makes possible send messageprevious variable circular ordering, without knowing variable is.reception (PREV, ) message indicates sender child wantsincluded message delivered previous variable, eitherrecipient PREV message, unknown descendant thereof.reception (LAST, ) message ones parent indicates unknownvariable (either unknown root pseudo-tree, unknown childunknown ancestor, another branch) wants delivered previous variable,ones descendant pseudo-tree.ReferencesBen-Or, M., Goldwasser, S., & Wigderson, A. (1988). Completeness theorems noncryptographic fault-tolerant distributed computation (extended abstract). Proceedings Twentieth Annual ACM Symposium Theory Computing (STOC88),pp. 110.Bilogrevic, I., Jadliwala, M., Hubaux, J.-P., Aad, I., & Niemi, V. (2011). Privacy-preservingactivity scheduling mobile devices. Proceedings First ACM COnferenceData Application Security PrivacY (CODASPY11), pp. 261272.Brito, I., & Meseguer, P. (2003). Distributed forward checking. ProceedingsNinth International Conference Principles Practice Constraint Programming(CP03), Vol. 2833 Lecture Notes Computer Science, pp. 801806.Brito, I., & Meseguer, P. (2007). Distributed forward checking may lie privacy.Proceedings Ninth International Workshop Distributed Constraint Reasoning(CP-DCR07).Brito, I., & Meseguer, P. (2010). Cluster tree elimination distributed constraint optimization quality guarantees. Fundamenta Informaticae, 102, 263286.Chechetka, A., & Sycara, K. (2006). No-commitment branch bound search distributed constraint optimization. Proceedings Fifth International Joint Conference Autonomous Agents Multiagent Systems (AAMAS06), pp. 14271429.Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.691fiLeaute & FaltingsDoshi, P., Matsui, T., Silaghi, M.-C., Yokoo, M., & Zanker, M. (2008). Distributed privateconstraint optimization. Proceedings 2008 IEEE/WIC/ACM InternationalConference Intelligent Agent Technology (IAT08), pp. 277281.Elgamal, T. (1985). public key cryptosystem signature scheme based discretelogarithms. IEEE Transactions Information Theory, 31 (4), 469472.Faltings, B., Leaute, T., & Petcu, A. (2008). Privacy guarantees distributed constraint satisfaction. Proceedings 2008 IEEE/WIC/ACM International Conference Intelligent Agent Technology (IAT08), pp. 350358.Franzin, M. S., Freuder, E. C., Rossi, F., & Wallace, R. J. (2004). Multi-agent constraintsystems preferences: Efficiency, solution quality, privacy loss. ComputationalIntelligence, 20 (2), 264286.Gentry, C. (2009). Fully homomorphic encryption using ideal lattices. ProceedingsForty-first Annual ACM Symposium Theory Computing (STOC09), pp. 169178. ACM Special Interest Group Algorithms Computation Theory (SIGACT).Gershman, A., Meisels, A., & Zivan, R. (2006). Asynchronous forward-bounding distributed constraints optimization. Proceedings Seventeenth European Conference Artificial Intelligence (ECAI06), pp. 103107.Goldreich, O. (2009). Foundations Cryptography, Vol. 2, Basic Applications. CambridgeUniversity Press.Greenstadt, R., Grosz, B., & Smith, M. D. (2007). SSDPOP: Using secret sharingimprove privacy DCOP. Proceedings Ninth International WorkshopDistributed Constraint Reasoning (CP-DCR07).Greenstadt, R., Pearce, J. P., & Tambe, M. (2006). Analysis privacy loss distributedconstraint optimization. Proceedings Twenty-First National ConferenceArtificial Intelligence (AAAI06), pp. 647653.Grinshpoun, T., & Meisels, A. (2008). Completeness performance APO algorithm.Journal Artificial Intelligence Research (JAIR), 33, 223258.Grubshtein, A., Grinshpoun, T., Meisels, A., & Zivan, R. (2009). Asymmetric distributedconstraint optimization. Proceedings IJCAI09 Distributed Constraint Reasoning Workshop (DCR09), pp. 6074.Gutierrez, P., & Meseguer, P. (2010). BnB-ADOPT+ several soft arc consistencylevels. Proceedings Nineteenth European Conference Artificial Intelligence(ECAI10), No. 215 Frontiers Artificial Intelligence Applications, pp. 6772.Herlea, T., Claessens, J., Preneel, B., Neven, G., Piessens, F., & Decker, B. D. (2001). securely scheduling meeting. Proceedings Sixteenth International ConferenceInformation Security Trusted information: new decade challenge (SEC01),International Federation Information Processing (IFIP) Series, pp. 183198.Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem.Proceedings Third International Conference Principles PracticeConstraint Programming (CP97), Vol. 1330 Lecture Notes Computer Science,pp. 222236.692fiProtecting Privacy thru Distributed Computation Multi-agent Decision MakingKearns, M. J., Littman, M. L., & Singh, S. P. (2001). Graphical models game theory.Proceedings Seventeenth Conference Uncertainty Artificial Intelligence(UAI01), pp. 253260.Kuchcinski, K., & Szymanek, R. (2011). Java library: JaCoP Java constraint programmingsolver. http://jacop.osolpro.com/.Leaute, T. (2011). Distributed Constraint Optimization: Privacy Guarantees StochasticUncertainty. PhD thesis, Ecole Polytechnique Federale de Lausanne (EPFL).Leaute, T., & Faltings, B. (2009). Privacy-preserving multi-agent constraint satisfaction.Proceedings 2009 IEEE International Conference PrivAcy, Security, riSkTrust (PASSAT09), pp. 1725.Leaute, T., & Faltings, B. (2011). Coordinating logistics operations privacy guarantees. Proceedings Twenty-Second International Joint Conference ArtificialIntelligence (IJCAI11), pp. 24822487.Leaute, T., Ottens, B., & Szymanek, R. (2009). FRODO 2.0: open-source frameworkdistributed constraint optimization. Proc. IJCAI09 Distributed ConstraintReasoning Workshop (DCR09), pp. 160164. http://frodo2.sourceforge.net.Leyton-Brown, K., Pearson, M., & Shoham, Y. (2000). Towards universal test suitecombinatorial auction algorithms. Proceedings Second ACM ConferenceElectronic Commerce (EC00), pp. 6676. ACM Special Interest Group ElectronicCommerce (SIGEcom). http://www.cs.ubc.ca/~kevinlb/CATS.Maheswaran, R. T., Pearce, J. P., Bowring, E., Varakantham, P., & Tambe, M. (2006).Privacy loss distributed constraint reasoning: quantitative framework analysisapplications. Autonomous Agents Multi-Agent Systems (JAAMAS), 13 (1),2760.Maheswaran, R. T., Tambe, M., Bowring, E., Pearce, J. P., & Varakantham, P. (2004).Taking DCOP real world: Efficient complete solutions distributed multievent scheduling. Proceedings Third International Joint Conference Autonomous Agents Multiagent Systems (AAMAS04), Vol. 1, pp. 310317. ACMSpecial Interest Group Artificial Intelligence (SIGART).Mailler, R., & Lesser, V. R. (2003). mediation based protocol distributed constraintsatisfaction. Proceedings Fourth International Workshop Distributed Constraint Reasoning (DCR03).Meisels, A., & Zivan, R. (2003). Asynchronous forward-checking DisCSPs. ProceedingsFourth International Workshop Distributed Constraint Reasoning (DCR03).Modi, P. J., Shen, W.-M., Tambe, M., & Yokoo, M. (2005). ADOPT: Asynchronous distributed constraint optimization quality guarantees. Artificial Intelligence, 161,149180.Netzer, A., Meisels, A., & Grubshtein, A. (2010). Concurrent forward bounding DCOPs.Proceedings Twelfth International Workshop Distributed Constraint Reasoning (DCR10), pp. 6579.693fiLeaute & FaltingsPedersen, T. P. (1991). threshold cryptosystem without trusted party (extended abstract). Advances Cryptology EUROCRYPT91, Workshop TheoryApplication Cryptographic Techniques, Proceedings, Vol. 547 Lecture NotesComputer Science, pp. 522526.Petcu, A., & Faltings, B. (2005). DPOP: Scalable Method Multiagent ConstraintOptimization. Proceedings Nineteenth International Joint ConferenceArtificial Intelligence (IJCAI05), pp. 266271.Petcu, A., Faltings, B., & Parkes, D. C. (2008). M-DPOP: Faithful distributed implementation efficient social choice problems. Journal Artificial Intelligence Research(JAIR), 32, 705755.Rassenti, S. J., Smith, V. L., & Bulfin, R. L. (1982). combinatorial auction mechanismairport time slot allocation. Bell Journal Economics, 13 (2), 402417.Shamir, A. (1979). share secret. Communications ACM, 22 (11), 612613.Silaghi, M.-C. (2005a). Hiding absence solution distributed constraint satisfactionproblem (poster). Proceedings Eighteenth International Florida ArtificialIntelligence Research Society Conference (FLAIRS05), pp. 854855.Silaghi, M.-C. (2005b). Using secure DisCSP solvers generalized Vickrey auctionscomplete stochastic techniques. Proceedings IJCAI05 Distributed Constraint Reasoning Workshop.Silaghi, M.-C., Faltings, B., & Petcu, A. (2006). Secure combinatorial optimization simulating DFS tree-based variable elimination. Proceedings Ninth InternationalSymposium Artificial Intelligence Mathematics.Silaghi, M.-C., & Mitra, D. (2004). Distributed constraint satisfaction optimizationprivacy enforcement. Proceedings 2004 IEEE/WIC/ACM InternationalConference Intelligent Agent Technology (IAT04), pp. 531535.Silaghi, M.-C., Sam-Haroud, D., & Faltings, B. (2000). Asynchronous search aggregations. Proceedings Seventeenth National Conference Artificial Intelligence Twelfth Conference Innovative Applications Artificial Intelligence(AAAI/IAAI00), pp. 917922.Singh, S., Soni, V., & Wellman, M. P. (2004). Computing approximate Bayes-Nash equilibriatree-games incomplete information. Proceedings Fifth ACM ConferenceElectronic Commerce (EC04), pp. 8190.Sultanik, E. A., Lass, R. N., & Regli, W. C. (2007). DCOPolis: framework simulatingdeploying distributed constraint optimization algorithms. ProceedingsNinth International Workshop Distributed Constraint Reasoning (CP-DCR07).Tsiounis, Y., & Yung, M. (1998). security Elgamal-based encryption. Proceedings First International Workshop Practice Theory Public KeyCryptography (PKC98), Vol. 1431 Lecture Notes Computer Science, pp. 117134.Vickrey, D., & Koller, D. (2002). Multi-agent algorithms solving graphical games. Proceedings Eighteenth National Conference Artificial Intelligence (AAAI02),pp. 345351.694fiProtecting Privacy thru Distributed Computation Multi-agent Decision MakingVinyals, M., Rodrguez-Aguilar, J. A., & Cerquides, J. (2010). Constructing unifyingtheory dynamic programming DCOP algorithms via generalized distributivelaw. Autonomous Agents Multi-Agent Systems (JAAMAS), 22 (3), 439464.Wallace, R. J., & Freuder, E. C. (2005). Constraint-based reasoning privacy/efficiencytradeoffs multi-agent problem solving. Artificial Intelligence, 161 (12), 209227.Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: asynchronous branch-andbound DCOP algorithm. Journal Artificial Intelligence Research (JAIR), 38, 85133.Yokoo, M. (1995). Asynchronous weak-commitment search solving distributed constraintsatisfaction problems. Proceedings First International Conference Principles Practice Constraint Programming (CP95), No. 976 Lecture NotesComputer Science, pp. 88102.Yokoo, M., Durfee, E. H., Ishida, T., & Kuwabara, K. (1992). Distributed constraint satisfaction formalizing distributed problem solving. Proceedings TwelfthInternational Conference Distributed Computing Systems (ICDCS92), pp. 614621.Yokoo, M., & Suzuki, K. (2002). Secure multi-agent dynamic programming based homomorphic encryption application combinatorial auctions. ProceedingsFirst International Joint Conference Autonomous Agents Multi-AgentSystems (AAMAS02), pp. 112119.Yokoo, M., Suzuki, K., & Hirayama, K. (2002). Secure distributed constraint satisfaction:Reaching agreement without revealing private information. Proc. 8th Intl. Conf.Principles Practice Constraint Prog. (CP02), Vol. 2470 LNCS, pp. 387401.Yokoo, M., Suzuki, K., & Hirayama, K. (2005). Secure distributed constraint satisfaction:Reaching agreement without revealing private information. Artificial Intelligence,161 (12, Distributed Constraint Satisfaction), 229245.Zivan, R., & Meisels, A. (2004). Concurrent dynamic backtracking distributed CSPs.Proceedings Tenth International Conference Principles PracticeConstraint Programming (CP04), Vol. 3258 Lecture Notes Computer Science,pp. 782787.695fiJournal Artificial Intelligence Research 47 (2013) 157-203Submitted 11/12; published 05/13Survey Latent Tree Models ApplicationsRaphael Mouradraphael.mourad@aliceadsl.frLINA, UMR CNRS 6241,Ecole Polytechnique de lUniversite de NantesNantes, Cedex 3, 44306 FranceChristine Sinoquetchristine.sinoquet@univ-nantes.frLINA, UMR CNRS 6241, Universite de NantesNantes, Cedex, 44322 FranceNevin L. ZhangTengfei Liulzhang@cse.ust.hkliutf@cse.ust.hkDepartment Computer Science & Engineering, HKUSTClear Water Bay Road, Kowloon, Hong KongPhilippe Lerayphilippe.leray@univ-nantes.frLINA, UMR CNRS 6241,Ecole Polytechnique de lUniversite de NantesNantes, Cedex 3, 44306 FranceAbstractdata analysis, latent variables play central role help provide powerfulinsights wide variety phenomena, ranging biological human sciences.latent tree model, particular type probabilistic graphical models, deserves attention.simple structure - tree - allows simple efficient inference, latent variablescapture complex relationships. past decade, latent tree model subjectsignificant theoretical methodological developments. review, proposecomprehensive study model. First summarize key ideas underlying model.Second explain efficiently learned data. Third illustrate usewithin three types applications: latent structure discovery, multidimensional clustering,probabilistic inference. Finally, conclude give promising directions futureresearches field.1. Introductionstatistics, latent variables (LVs), opposed observed variables (OVs), randomvariables directly measured. wide range statistical models, called latentvariable models, relate set OVs set LVs. models, LVs explaindependences among OVs hence offer compact intelligible insights data. MoreoverLVs allow reduce data dimensionality generate conditionally independent variables,considerably simplifies downstream analysis. Applications numerous covermany scientific fields. typically case domains psychology, sociology,economics, also biological sciences artificial intelligence, cite examples.fields may need complex constructs cannot observed directly. instance,human personality psychology social class socio-economics refer higher levelabstractions observed reality.c2013AI Access Foundation. rights reserved.fiMourad, Sinoquet, Zhang, Liu, & Leray1.1 ContextLatent tree model (LTM)1 class latent variable models received considerable attention. LTM probabilistic tree-structured graphical model leaf nodesobserved internal nodes either observed latent. model appealingsince simple structure - tree - allows simple efficient inference, latentvariables capture complex relationships.subclass LTMs first developed phylogenetic community (Felsenstein,2003). context, leaf nodes observed taxa internal nodes represent unobserved taxum ancestors. instance, molecular genetic evolution, processevolution DNA scale, obviously hopeless study DNA sequences deadspecies collecting DNA. Nevertheless, evolutionary latent models usedinfer probable ancestral sequences knowing contemporary living species sequences.Neighbor joining represents one first algorithms developed LTM learningphylogenetic context (Saitou & Nei, 1987; Gascuel & Steel, 2006). still popularquick compute allows find optimal model polynomial timecertain assumptions.past decade, LTMs general form extensive investigation applied many fields. instance applied humaninteraction recognition. Human interaction recognition challenging task,multiple body parts concomitant inclusions (Aggarwal & Cai, 1999). purpose,use LTM allows segment interaction multi-level fashion (Park & Aggarwal,2003): body part positions estimated low-level LVs, overall body positionestimated high-level LV. LTMs also used medical diagnosis (Zhang,Yuan, Chen, & Wang, 2008). context, LTMs provide way identify,LVs, different syndrome factors cannot directly observed physician.1.2 Contributionspaper, present comprehensive study LTM broad-brush view recenttheoretical methodological developments. LTM must paid attention (i)offers deep insights latent structure discovery (Saitou & Nei, 1987), (ii) appliedmultidimensional clustering (Chen, Zhang, Liu, Poon, & Wang, 2012) (iii) allowsefficient probabilistic inference (Wang, Zhang, & Chen, 2008). Somewhat surprisingly,extensive review research area published.addition reviewing LTM research area, also contribute analysisperspective advance understanding subject. establish categorizationlearning methods. present generic learning algorithms implementing fundamentalprinciples. generic algorithms partly different literatureadapted broader context. Besides, performances algorithmsliterature compared context small, large large simulatedreal datasets. Finally, discuss future directions, adaptation LTMcontinuous data.1. LTM previously called hierarchical latent class model (Zhang, 2004), namediscarded model inherently reveal hierarchy.158fiLatent Tree ModelsFigure 1: Illustration graph theory terminology.1.3 Paper Organizationpaper organized follows. Section 2 presents latent tree model relatedtheoretical developments. Section 3, review methods developed learn latent treemodels two main situations: learning structure known learningcase. Then, Section 4 presents details three types applications latent treemodels: latent structure discovery, multidimensional clustering probabilistic inference.applications classification also discussed. Finally, last two sections 56 conclude point future directions.2. Theorysection, first introduce graph terminology present LTM. Latent classesprobabilistic inference clustering next presented. Scoring LTMs discussed.also present concepts marginal equivalence, equivalence model parsimony, usefulLTM learning. Then, explain necessity trade-off latent variablecomplexity partial structure complexity.Variables denoted capital letters, e.g. A, B C, whereas lower-case lettersrefer values variables take, e.g. a, b c. Bold-face letters represent setsobjects, A, B C sets variables a, b c value sets.observed variable denoted X whereas latent variable denoted H. variableknow observed latent denoted V .2.1 Graph Theory Terminologypresenting LTM, first need define graph-related terms, illustratedFigure 1. graph G(V, E) composed set nodes V set edges E V V.edge pair nodes (Va , Vb ) E. edge undirected (noted Va Vb ) (Vb , Va ) Edirected (noted Va Vb ) not.159fiMourad, Sinoquet, Zhang, Liu, & LerayFigure 2: (a) Directed tree. (b) Undirected tree. light shade (blue) indicatesobserved variables whereas dark shade (red) points latent variables.directed graph graph whose edges directed. directed graph, nodeVa parent node Vb exists edge Va Vb . node Vbcalled child node Va . Nodes siblings share parent. nodeVc root parent. directed path node Vd node Va sequencenodes node except last one, edge next nodesequence. node Va descendant node Vd directed pathVd Va . node Vd called ancestor node Va .undirected graph contains undirected edges. undirected graph, node Vaneighbor another node Vb edge them. leafnode one neighbor. internal node node least two neighbors.undirected path path edges oriented direction.clique set pairwise connected nodes (in tree, clique simply edge).separator set nodes whose removal disconnect two cliques (in tree,separator simply internal node). tree graph two nodesconnected exactly one path.2.2 Latent Tree ModelLTM tree-structured graphical model latent variables. composed tree structure - (V, E), set parameters, . tree either directed (i.e.Bayesian network; Zhang, 2004) undirected (i.e. Markov random field; Choi, Tan,Anandkumar, Willsky, 2011). representations described Figure 2. setnodes V = {V1 , ..., Vn+m } represents n + observed latent variables. X = {X1 , ..., Xn }set observed variables H = {H1 , ..., Hm } set latent variables. Leafnodes OVs internal nodes either observed latent. Variables eitherdiscrete continuous. set k edges E = {E1 , ..., Ek } captures direct dependencesvariables.directed setting (Figure 2a), set parameters consists probability distributions, one variable. Given variable Vi parents P aVi , conditionaldistribution P (Vi |P aVi ) defined. variable Vi parent, marginal distribution P (Vi ) defined instead. joint probability distribution (JPD) model160fiLatent Tree Modelsformulated as:n+mP (V) = i=1P (Vi |P aVi ).(1)illustrate model, let us take example Figure 2a. composed setOVs {X1 , ..., X7 } set LVs {H1 , H2 }. JPD writes as:P (X1 , ..., X7 , H1 , H2 ) = P (X1 |H1 ) P (X2 |H1 ) P (X3 |H1 ) P (H1 |X7 ) P (X7 )P (X4 |X7 ) P (H2 |X7 ) P (X5 |H2 ) P (X6 |H2 ).(2)undirected setting (Figure 2b), set parameters consists probabilitydistributions, one clique separator. LTM, cliques edges separatorsinternal nodes. Let {I1 , ..., Ij } separators. JPD model formulatedas:(V ,V )E P (Va , Vb ),(3)P (V) = bj=1 P (Ij )(d(Ij )1)d(Ij ) degree internal node Ij . JPD undirected model Figure2b writes as:P (X1 , H1 ) P (X2 , H1 ) P (X3 , H1 ) P (H1 , X7 ) P (X4 , X7 )P (H1 ) P (H1 ) P (H1 ) P (X7 )P (X7 , H2 ) P (X5 , H2 ) P (X6 , H2 ).P (X7 ) P (H2 ) P (H2 )P (X1 , ..., X7 , H1 , H2 ) =(4)following, seek simplicity, restrain study categorical variables,i.e. random variables finite number states. also mainly focus LTMwhose internal nodes LVs. works LTM developed twomodel settings.2.3 Latent Classes ClusteringLV number states, representing latent class. latent classestogether represent soft partition data define finite mixture model (FMM).LTM seen multiple FMMs connected form tree. Given data point,probability belonging particular class computed using Bayes formula.computation called class assignment.LTM, LV Hj represents partition data. observation `vector values x` = {x`1 , ..., x`n } set OVs X, probability membershipclass c LV Hj computed follows:P (x` |Hj = c) P (Hj = c)P (x` )P0`0 P (x , H |Hj = c) P (Hj = c)= Pk HP0`c=1H0 P (x , H |Hj = c) P (Hj = c)P (Hj = c|x` ) =(5)H0 = H\{Hj } k cardinality Hj . last formula, reader might getimpression complexity class assignment exponential. However, trees,161fiMourad, Sinoquet, Zhang, Liu, & Leraylinear2 - thus efficient - probabilistic inference, using message passing (Kim & Pearl, 1983),used compute P (Hj = c|x` ).Probabilistic inference LV values two applications: clustering latent dataimputation. Clustering using LTMs illustrated seen detail Section 4.2.Latent data imputation process inferring, observation `, valuesLVs. variables called imputed LVs. Section 3.2.2, see latent dataimputation basis fast variable clustering-based LTM learning methods.2.4 Scoring Latent Tree Modelstheory, every score, Akaike information criterion (AIC) (Akaike, 1970)Bayesian information criterion (BIC) (Schwartz, 1978), could used scoringLTMs. practice, BIC score often used LTMs. Let consider set n OVsX = {X1 , ..., Xn } collection N identical independently distributed (i.i.d.)observations Dx = {x1 , ..., xN }. BIC composed two terms:1BIC(T, Dx ) = log P (Dx | L , ) dim(T ) log N,2(6)L maximum likelihood parameters, dim(T ) model dimension Nnumber observations. first term evaluates fit model data.computed probabilistic inference P (x` ) observation `. second termscore penalizes model according dimension, prevent overfitting.models without latent variables, dimension simply calculated numberfree parameters. sometimes called standard dimension. LVs present,standard dimension longer appropriate measure model complexity, effectivedimension used instead (Geiger, Heckerman, & Meek, 1996). Effective dimensioncomputed rank Jacobian matrix mapping model parametersOV joint distribution.2.5 Model ParsimonyLet us consider two LTMs, = (T, ) M0 = (T 0 , 0 ), built set nOVs, X = {X1 , ..., Xn }. say M0 marginally equivalent jointdistributions OVs equal:P (X1 , ..., Xn |T, ) = P (X1 , ..., Xn |T 0 , 0 ).(7)two marginally equivalent models dimension, equivalent models.model parsimonious3 exist another model M0marginally equivalent smaller dimension. parsimonious model bestpossible score. contain redundant LVs redundant latent classes.represents model infer data. Two conditions ensure LTMinclude redundant LVs (Pearl, 1988):2. Actually, trees, inference linear number edges |E|, thus also linear numbern + observed latent variables, |E| n + 1.3. notion parsimony also called minimality Pearl (1988).162fiLatent Tree ModelsFigure 3: Illustration trade-off latent variable complexity partial structure complexity latent tree models. Superscript represents LV cardinality. SeeFigure 2 node color code.LV must least three (observed latent) neighbors. twoneighbors, simply replaced direct link two.two variables connected edge LTM neither perfectly dependentindependent.also condition ensuring LTM include redundant latentclasses. Let H LV LTM. set k variables Z = {Z1 , ..., Zk }neighbors H. LTM regular (Zhang, 2004) LV H:|H|ki=1 |Zi |.maxki=1 |Zi |(8)Zhang (2004) showed parsimonious models necessarily regular. Thusmodel search restricted space regular models. Zhang also demonstrated2space regular models upper bounded 23n , n number OVs.2.6 Trade-off Latent Variable Complexity Partial StructureComplexityZhang Kocka (2004b) distinguished two kinds model complexity LTM: latentvariable complexity refers LV cardinalities partial structure complexity44. paper, Zhang Kocka (2004b) called structure complexity. better understanding,prefer make distinction (complete) structure includes LV cardinalities partialstructure not.163fiMourad, Sinoquet, Zhang, Liu, & Lerayedges number LVs graph. trade-off two complexitiesimportant role play one wants choose model. trade-off illustratedFigure 3. instance, let us consider latent class model (i.e. model oneLV, abbreviated LCM) versus LTM marginal likelihood (marginallyequivalent models). LCM model showing highest LV complexitylowest partial structure complexity. might low score local dependencespresent OVs. opposite, model low LV complexity highpartial structure complexity, binary tree binary LVs, would also low score,LVs would unnecessary. Depending application, model showinggood trade-off two complexities preferred, would presentbetter score might easier interpret.3. Statistical Learningsection, present generic algorithms implementing fundamental principles learning LTMs. algorithms partly different proposed literature,adapted broader context. Moreover provide unified presentation algorithms, context survey. learning model data,two main situations distinguished: structure known parameterslearned, complicated situation unknown.3.1 Known Structuresimplest situation, structure known, i.e. dependences variables also number LVs respective cardinalities (i.e. numberslatent classes). problem estimate probability parameters. solve problem,one use expectation-maximization (EM), popular algorithm learning parameters face LVs (Dempster, Laird, & Rubin, 1977; Lauritzen, 1995).EM leads computational burden large LTMs, efficient procedure,call LCM-based EM, used. methods different EM, spectraltechniques, also developed.3.1.1 Expectation-maximizationIdeally, learning parameters, would like maximize log-likelihood setN i.i.d. observed data Dx = {x1 , ..., xN }:XL(; Dx ) = log P (Dx |) = logP (Dx , H|).(9)HHowever, directly maximizing L(; Dx ) Equation (9) often intractable involves logarithm (large) sum. overcome difficulty, EM implements iterative approach. iteration, optimizes instead following expected log-likelihoodconditional current parameters :Q(; ) = EDh |Dx ,t [log P (Dx , Dh |)](10)Dx completed missing data Dh = {h1 , ..., hN } inferred using . Notecompleting missing data, EM easily deal partially observed variables.164fiLatent Tree ModelsAlgorithm 1 LCM-based EM parameter learning (LCMB-EM, adapted HarmelingWilliams, 2011)INPUT:, tree structure LTM.OUTPUT:, parameters LTM.1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:0 graph rooting(T ) /* choose LV root */Ho /* initialization set imputed latent variables */0loopTLCM = {TLCM1 , ..., TLCMk } identif LCM graph(T 0 , Ho )LCM = {LCM1 , ..., LCMk } EM (TLCM )|TLCM | > 10 0 children parameters(LCM )else0 0 children parent parameters(LCM)breakendHo Ho impute LV data(LCM ) /* parents observed */end loopEM ( 0 ) /* global EM using 0 starting point */important drawback EM guarantee reach global optimum.reduce probability getting trapped local maximum, random restarts (multiplestarts different random initial parameters) simulated annealing represent well-usedsolutions. Wang Zhang (2006) showed random restarts suffice LTMsmall variables strongly dependent other. Supplemental materialB.1, also present experiments random restarts EM. appearspossible give simple answer many restarts used dependsmodel. Besides, convergence sometimes reached even large numberrestarts.3.1.2 LCM-based EMAlthough inference linear LTMs, running EM might prohibitive. One solutionspeed EM computations consists chaining two steps: first step divide-andconquer strategy local - LCM - learning, followed final step carrying globallearning. LCM-based EM (LCMB-EM) parameter learning method5 presentedAlgorithm 1 illustrated Figure 4. first step, parameters locally learnedbottom-up LCM-based learning procedure explained follows. LV first5. learning procedure similar one proposed binary trees Harmeling Williams(2011).165fiMourad, Sinoquet, Zhang, Liu, & LerayFigure 4: Illustration LCM-based EM parameter learning algorithm (adaptedHarmeling Williams, 2011). See Figure 2 node color code.chosen root LTM (line 1; note point discussed detailSection 3.2.5). rooted LTM, every LCM {X, H} identified (line 5), i.e. every LVH whose children OVs X. Then, LCM parameters quickly learnedEM (line 6) used update current LTM parameters (lines 7 12). parameterslearned LCM, distributions unknown values LV Hprobabilistically inferred observation6 (line 13; details, see Section 2.3,paragraph 2). distributions used weighted observations. turn,weighted observations seed learning processes LCMs (nowobserved) LVs Ho remaining OVs used LCM learning yet.Iterating two operations (LCM learning latent data imputation) leads bottomup LCM-based EM procedure enabling local fast parameter learning LTMs. Finally,LTM parameters refined global EM using starting point locally learnedparameters (line 15). EM, also provide results experiments evaluatingefficiency random restarts (see Supplemental material B.1). results showLCMB-EM converges better EM. However convergence achieved largestdataset studied.3.1.3 Spectral MethodsRecently, Parikh et al. (2011) applied spectral techniques LTM parameter learning.method directly estimates joint distribution OVs without explicitly recovering6. recall process named latent data imputation.166fiLatent Tree ModelsLTM parameters. algorithm useful LTM parameters required,instance, probabilistic inference OVs only. work Parikh et al. alleviatesrestriction approach Mossel et al. (2006) requiring conditional probabilitytables invertible, generalizes method Hsu et al. (2009) specifichidden Markov models.Parikh et al. (2011) reformulated message passing algorithm using algebraicformulation:Xn+mP (x) =i=1P (vi |P avi )H>= r (Mj1 Mj2 ... MjJ 1r ),(11)x = {x1 , ..., xn } observation, Xr root, r marginal probability vectorroot Mj1 , Mj2 , ..., MjJ incoming message matrices roots children.Children message matrices calculated similar manner:1 (Mj1 Mj2 ... MjJ 1i ),Mi = Ti(12)Xi root child, Mi outgoing message matrix Xi , Ti third order tensor related conditional probability matrix Xi P aXi (i.e. Xr ),1 mode-1 vectorMj1 , Mj2 , ..., MjJ Xi children incoming messagesproduct. original message passing algorithm, messages recursivelycalculated starting leaves going root.drawback previous representation message passing still needs modelparameters. tackle issue, key recover P (x) using invertible transformations.Message matrices calculated transforming message Mj two invertiblematrices Lj Rj (Lj R1j = I):1111 (Lj1 L1Mi = Tij1 Mj1 Rj1 Lj2 Mj2 Rj2 ... LjJ MjJ RjJ RjJ 1i ).(13)matrices Lj , Mj Rj recovered singular vectors Uj empiricalprobability matrices P (Xj , Xj ) OVs Xj left neighbor OV Xj . leadsefficient computation message passing involving sequence singular valuedecompositions empirical pairwise joint probability matrices. refer workParikh et al. (2011) details singular value decomposition spectralalgorithm. Compared EM, spectral method entail problem gettingtrapped local maxima. Moreover, performs comparable better EMorders magnitude faster.3.1.4 Methodsmethods exist parameter learning. Gradient descent (Kwoh & Gillies, 1996;Binder, Koller, Russel, & Kanazawa, 1997) variations Gauss-Newton method(Xu & Jordan, 1996) help accelerate sometimes slow convergence EM. However,require evaluation first and/or second derivatives likelihood function.Bayesian learning, variational Bayes (Attias, 1999) offers counterpart EM.167fiMourad, Sinoquet, Zhang, Liu, & Leray3.2 Unknown StructureRegrettably, time, priori information LTM structure.compels learn every part model, i.e. number LVs, cardinalities,dependences parameters. learning task represents challenging issue,various methods conceived. section, provide surveyalgorithms. determination LV cardinalities, well time complexityscalability algorithms also discussed. end establishing summary relativelearning methods.Structure learning approaches fall three categories. first one comprisedsearch-based methods, inspired standard Bayesian network learning. second onebased variable clustering related hierarchical procedures. last categoryrelies notion distances comes phylogenetics.3.2.1 Search-based MethodsSearch-based methods aim finding model optimal according scoringmetric. BNs without LVs, BIC score often used. context LTM, BICsuffers theoretical shortcoming pointed Section 2.4. However, empiricalresults indicate shortcoming seem compromise model quality practice (Zhang & Kocka, 2004a). So, researchers still use BIC comes learning LTM.Many search procedures proposed. explore space regular LTMs.focus on: (i) naive one conceptually simple computationally expensive (ii) advanced one reduces search spaceimplements fast parameter learning local EM.Naive Greedy SearchNaive greedy search (NGS) consists starting LCM visiting spaceregular LTM partial structures. neighborhood current model exploredgreedy search operations addition removal latent node, noderelocation7 . partial structure neighbor, cardinalities LVs optimizedaddition dismissal state relative LV. model search (partialstructure LV cardinality), candidate models learned EM evaluatedscore. best candidate model shows score superior current model score,former used seed next step. Otherwise, NGS stops current modelconsidered best model. Therefore, step search, learning approachnecessitates evaluate score large number candidate models. leadshuge computational burden because, candidate model evaluation, likelihoodcomputed EM.7. Node relocation picks child LV grafts child another LV connectedformer LV.168fiLatent Tree ModelsAdvanced Greedy SearchAdvanced greedy search (AGS) relies three strategies reduce complexity.Advanced greedy search presented Algorithm 2. First, AGS focuses smallerspace models explore NGS (Zhang & Kocka, 2004b). algorithm performspartial structure search LV cardinality exploration simultaneously. purpose,two additional operators used: addition removal latent state LV.Second, AGS follows grow-restructure-thin strategy reduce complexitysearch space (Chen, Zhang, & Wang, 2008; Chen et al., 2012). strategy consistsdividing five operators three groups. group applied given stepmodel search. First, latent node latent state introduction (NI SI, respectively)used make current model complex8 (grow, line 3). Then, node relocation(NR) rearranges connections variables (restructure, line 4). Finally, latent nodelatent state deletion (ND SD, respectively) make current model simpler (thin,line 5).Third, one needs assess BIC score candidate models. Learning parametersnew models thus required. achieve fast learning, Chen et al. (2008, 2012)compute likelihood instead so-called restricted likelihood local EMprocedure (line 12). principle relies optimizing parameters variables whoseconnection cardinality changed candidate model. Parameters remainingvariables kept identical current model.Operation Granularitystarting simplest solution (an LCM), Zhang Kocka (2004b) observedcomparison BIC scores candidate model 0 current onemight relevant criterion. problem strategy always leadsincrease cardinality LCM, without introducing LVs model (see trade-offLV complexity partial structure complexity Section 2.6). tackleissue, propose instead assess so-called improvement ratio grow step:IRBIC (T 0 , |DX ) =BIC(T 0 , DX ) BIC(T, DX ),dim(T 0 ) dim(T )(14)difference BIC scores candidate model 0 current modeldivided difference respective dimensions.3.2.2 Methods Based Variable Clusteringmajor drawback search-based methods evaluation maximum likelihoodpresence LVs, well large space explore local search, still entailscomputational burden. Approaches relying variable clustering represent efficientmuch faster alternatives. rely two key points: grouping variables identifyLVs constructing model bottom-up strategy. Three main categoriesdeveloped, depending structures learned: binary trees, non-binary trees8. Note node relocation used locally NI increase number children.169fiMourad, Sinoquet, Zhang, Liu, & LerayAlgorithm 2 Advanced greedy search LTM learning (AGS, adapted EAST, Chenet al., 2012)INPUT:X, set n observed variables {X1 , ..., Xn }.OUTPUT:, respectively tree structure parameters LTM constructed.1:2:3:4:5:6:(T 0 , 0 ) latent class model(X) /* LCM learning using EM */loop = 0, 1,... convergence00(T , ) local search(N SI, , ) /* grow */000000(T , ) local search(N R, , ) /* restructure */0000(T i+1 , i+1 ) local search(N SD, , ) /* thin */end loop7:8:9:10:11:12:13:14:15:16:17:18:/* description function local search(operators, T, ) */(T 0 , 0 ) (T, )loop j = 0, 1,... convergence= {T1 , ..., T` } neighborhood(operators, j ) j= {1 , ..., ` }local EM (T, j ) /* except j */BIC(T, )/dim(T, ) operators = N SIj+1 arg maxTBIC(T, )otherwisej+1 EM (T j+1 )j+1 neighborhood(N I, j )(T j+1 , j+1 ) local search(N R, j+1 , j+1 )endend loopforests.Binary TreesBinary tree learning represents simple situation. instance, one simply compute agglomerative hierarchical clustering (Xu & Wunsch, 2005) learnLTM structure. algorithm called agglomerative hierarchical cluster-based learning (AHCB). purpose clustering, pairwise mutual information (MI) representswell-suited similarity measure variables (Cover & Thomas, 1991; Kraskov &Grassberger, 2009). MI two variables Vi Vj defined follows:I(Vi ; Vj ) =X Xp(vi , vj ) logvi Vi vj Vjp(vi , vj ).p(vi ) p(vj )(15)Single, complete average linkage used, depending cluster compactness required.inferred hierarchy provides binary tree (the partial structure) leaf nodes170fiLatent Tree ModelsFigure 5: Illustration LCM-based LTM learning procedure set 4 variables{X1 , X2 , X3 , X4 }.OVs internal nodes LVs (Wang et al., 2008; Harmeling & Williams, 2011). Then,LV cardinalities parameters learned (for details, see Section 3.2.4 Section 3.1,respectively).AHCB, cluster hierarchy represents LV. MI LVvariables (observed latent) approximated linkage criterion. Insteadapproximation, another solution consists directly computing MI variables, whatever status, i.e. observed latent (Hwang, Kim, & Zhang, 2006; Harmeling & Williams, 2011). compute MI, values LVs imputed LCM-basedlearning. Algorithm 3 presents LCM-based LTM learning (LCMB-LTM) algorithm9implementing solution. First, working node set W initialized set OVsX = {X1 , ..., Xn } (line 1). empty graph created W (line 2). pairvariables showing highest MI, {Wi , Wj }, selected (line 5). LCM ({Wi , Wj }, H)learned (line 6), allowing locally estimate LV cardinality (through greedy search)parameters, impute values H (line 7). values H known,used observed variable (line 8). new step clustering, followed LCM learningLV value imputation, performed. Iterating step loop allowsconstruct LTM bottom-up recursive procedure. step procedure,parameters lcm current LCM used update current parameters 0LTM (line 10). two nodes remaining, two nodes connected10 (line12), corresponding parameters learned using maximum likelihood (line 13)loop broken. constructing LTM, final step globally learns LTM parametersusing 0 starting point (line 17). LCMB-LTM yields slightly better BIC resultsAHCB large datasets (Harmeling & Williams, 2011). LCMB-LTM illustratedset 4 variables {X1 , X2 , X3 , X4 } Figure 5.Harmeling Williams (2011) justified selecting pair variables showinghighest MI step LCMB-LTM. Let us consider working node set (observedimputed latent) variables W = {W1 , ..., W` }. step LCMB-LTM, unknown9. algorithm called LCMB-LTM distinguish LCMB-EM parameter learning (Algorithm1). algorithms similar rely LCM-based learning.10. prevents introduction redundant LV, see Section 2.5, second paragraph.171fiMourad, Sinoquet, Zhang, Liu, & LerayAlgorithm 3 LCM-based LTM learning (LCMB-LTM, adapted BIN-T, HarmelingWilliams, 2011)INPUT:X, set n observed variables {X1 , ..., Xn }.OUTPUT:(V, E) , respectively tree structure parameters LTM constructed.1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:W X /* Initialization working set variables */(V, E) empty tree(W) /* tree W edges */0loop{Wi , Wj } pair highest I(W)lcm latent class model({Wi , Wj })H impute LV data(lcm)W W\{Wi , Wj } H /* remove children add imputed parent */E E edges(lcm); V V H0 0 children parameters(lcm)|W| = 2E E edge two remaining nodes(W)0 0 learn remaining parameters(W) /* max likelihood estimation */breakendend loopEM ( 0 ) /* global EM using 0 starting point */JPD P (W) approximated JPD Q(W):Q(W) = P (Wi , Wj ) Wk W\{Wi ,Wj } P (Wk )=P (Wi , Wj )Wk W P (Wk ),P (Wi ) P (Wj )(16)Wi Wj dependent. proper measure assess divergenceP (W) Q(W) Kullback-Leibler (KL) divergence, easy calculatesituation:XXKL(P ||Q) =P (W) log P (W)P (W) log Q(W)W= I(Wi ; Wj ) +WXWP (W) logP (W),Wk W P (Wk )(17)I(Wi ; Wj ) mutual information Wi Wj . last term constant, maximization KL P Q simply consists selecting pairvariables highest MI introducing LV model construction.172fiLatent Tree ModelsNon-binary TreesAlthough modeling binary trees performs well practice (Harmeling & Williams,2011), would worth alleviating binarity restriction. Indeed might provide bettermodel faithfulness interpretation less LVs would required. severalways learn non-binary trees without necessitating much additional computationalcost. instance, Wang et al. (2008) first learn binary tree. Then, check pairneighbor LVs tree. information redundant two LVs (i.e.model parsimonious), LV node child LV noderemoved remaining node connected every child removed node. Althoughapproach Wang et al. rigorous, lead practice find treesclose binary trees.Another solution consists identifying cliques pairwise dependent variables detectpresence LVs (Martin & Vanlehn, 1995; Mourad, Sinoquet, & Leray, 2011).purpose, Mourad et al. propose alternate two main steps: (i) agglomerative step,clique partitioning method used identify disjoint cliques variables; (ii)clique, containing least two nodes, connected LV LCM.LCM, parameters learned using EM LV data imputed probabilistic inference. Algorithm 3 (line 5), possible replace selection pair variableshighest MI clique partitioning step clique leads constructLCM impute corresponding LV values.Flat Treesalgorithms discussed far section based idea hierarchicalvariable clustering. Bridged Island (BI) algorithm Liu et al. (2012) takes slightlydifferent approach. first partitions set observed variables subsetscalled sibling clusters. creates LCM sibling cluster introducinglatent variable optimizing cardinality well model parameters. that,imputes values latent variables links latent variables formtree structure using Chow-Lius algorithm. EM algorithm run endoptimize parameters whole model. highlight difference BIvariable clustering algorithms, call models produces flat LTMs. Siblingcluster determination key step BI. BI determines sibling clusters one one.determine first sibling cluster, starts pair variables maximumempirical MI. cluster expanded adding variables one another.step, variable dependent variables already clusteradded cluster. that, unidimensionality test (UD test) determines whetherdependences among variables cluster properly modeled one latentvariable. test fails, expansion process terminated first sibling clusterdetermined. Thereafter, process repeats remaining observed variablesgrouped sibling clusters.173fiMourad, Sinoquet, Zhang, Liu, & LerayFigure 6: Latent forest models. See Figure 2 node color code.Forestsnumber variables analyze large (e.g. 1000 variables), mightreasonable learn forest instead tree many variables mightsignificantly dependent (see Figure 6). call model latent forestmodel (LFM). many advantages LTM, reducing complexityprobabilistic inference (which depends number edges). learn LFM, existsmultiple approaches. instance, AHCB, one use cluster validation criteriondecide cut hierarchy. Regarding LCMB-LTM (Algorithm 3), twooptions. one hand, Harmeling Williams (2011) check optimal cardinalitycurrent LV H (additional step line 6). optimal cardinality equals 1,means LV useful model construction algorithm stops.hand, partitioning variables cliques (which replaces step line5), algorithm Mourad et al. (2011) terminates single-node cliquesdiscovered.build LFM, one also first construct LTM use independencetesting method Tan et al. (2011) pruning non-significant edges. method providesguarantees satisfy structural risk consistencies. Similar works non-parametricanalysis also developed Liu et al. (2011). worth mentioning that,ensure model parsimony, pruning non-significant edges LTM followedremoval latent nodes longer connected minimum three nodes.3.2.3 Distance-based Methodsclass methods originally developed phylogenetics (Felsenstein, 2003).phylogenetic tree binary LTM showing evolutionary relations among set taxa.Compared LTM learning methods, distance-based ones provide strong guarantees inference optimal model. section, first define distancespresent learning algorithms: neighbor joining (phylogenetic tree inference), distance-based174fiLatent Tree ModelsFigure 7: Illustration ascertaining child-parent (a b) sibling relations (c).dotted edge two nodes means two nodes linked pathunknown length. figure, nodes colored whiteeither observed latent.method dedicated general LTM learning recent spectral methods.Distances VariablesDistances restricted LTMs whose variables share state space X ,e.g. binary variables (Lake, 1994). Distances functions pairwise distributions.discrete tree model G(V, E) (e.g. LTM), distance two variables Vi Vjis:| det(Jij )|dij = log q,(18)det(Mi ) det(Mj )ijJij joint probability matrix Vi Vj (i.e. Jab= p(Vi = a, Vj = b), a, b= p(V = a)).X ), diagonal marginal probability matrix Vi (i.e. Maaspecial case discrete tree models, called symmetric discrete tree models (Choiet al., 2011), distance simpler form. Symmetric discrete tree models characterizedfact every variable uniform marginal distribution pairvariables Vi Vj connected edge E verifies following property:1 (K 1) ij vi = vjp(vi |vj ) =ijotherwise,K cardinality common Vi Vj , ij (0, 1/K), known crossoverprobability. symmetric discrete tree models, distance two variables ViVj then:dij = (K 1) log (1 Kij ).(19)Note one-to-one correspondence distances model parameterssymmetric discrete tree models (for details, see Choi et al., 2011).175fiMourad, Sinoquet, Zhang, Liu, & Lerayaforementioned distances additive tree metrics (Erdos, Szekely, Steel, & Warnow,1999):Xdk` =dij , k, ` V.(20)(Vi ,Vj )P ath((k,`);E)Choi et al. (2011) showed additive tree distances allow ascertain child-parentsibling relationships variables parsimonious LTM. Let us considerthree variables Vi , Vj , Vk V. Choi et al. define ijk difference distancesdik djk (ijk = dik djk ). distance dij Vi Vj , following twoproperties ijk hold:ijk = dij , Vk V\{Vi , Vj }, Vi leaf node Vj parent node;ijk = dij , Vk V\{Vi , Vj }, Vj leaf node Vi parentnode;dij < ijk = ijk0 < dij , Vk , Vk0 V\{Vi , Vj }, Vi Vj leaf nodesshare parent node, i.e. belong sibling group.Neighbor Joiningprinciple neighbor joining (NJ) quite simple (Saitou & Nei, 1987; Gascuel &Steel, 2006). NJ starts star-shaped tree. iteratively selects two taxaj, creates new taxum u connect them. selection pair seeks optimizefollowing Q criterion:Q(i, j) = (n 2) dijnXk=1diknXdjk ,(21)k=1n number taxa dij additive tree distance j.distance new taxum u estimated follows:!nnXX11diu = dij +dikdjk ,(22)22(n 2)k=1k=1dju calculated symmetry. distances new taxum utaxa tree computed as:duk =11(dik diu ) + (djk dju ) .22(23)success distance methods NJ comes factproved efficient terms sample complexity. Cavender-Farris modelevolution (Cavender, 1978; Farris, 1973), Atteson (1999) showed possibleguarantee maxi,j |dij dij | < probability least if:22 ln 2nexp max dij,(24)Ni,j(1 exp())2176fiLatent Tree ModelsN number mutation sites (i.e. number observations) n numbertaxa (i.e. number OVs). Erdos et al. (1999) demonstratedevolutionary model reconstruction method, N grows least fast log n,model assuming i.i.d. observations, grows least n log n. Erdos et al.also proposed new algorithm, called Dyadic Closure Method, sample complexitypower log n, mutation probabilities lie fixed interval. Daskalakis etal. (2009) proved Steels conjecture (Steel, 2001)states mutationprobabilities edges tree less p = ( 2 1)/23/2 discretized,tree recovered log n. Recently, Mossel et al. (2011) proved log2 nsuffices discretization assumed.phylogenetics, scientist often faced set different trees11construction consensus tree thus required. computational complexityconstruction studied polynomial algorithm proposed Steel etal. (1992).Learning Dedicated General LTMsubsection, present latest developments Choi et al. (2011) generalLTM learning, i.e. learning restricted phylogenetic trees. restrictedanalysis data whose variables share state space, instance binary data.Assuming data generated parsimonious LTM, additive tree metric property allowsexactly recover child-parent sibling relations distances (see Subsection DistancesVariables, last paragraph). Another advantage OVs necessarilyconstrained leaf nodes (this seen next paragraph).distance-based general LTM learning (DBG) implemented Algorithm 4, detailed follows. First, working node set W initialized set observedvariables X = {X1 , ..., Xn } (line 1). Distances computed three variables W(line 2). empty tree created W (line 3). following steps successivelyiterated (lines 4 16):procedure (based properties described Subsection Distances Variables, last paragraph) allows identify nodes parent-child relationnodes siblings (line 5). procedure generates three different sets nodegroups: set parent-child groups, PC = {P C1 , ..., P Cp }, set sibling groups,= {S1 , ..., Sq } set remaining single nodes, R = {R1 , ..., Rr };content working node set W replaced parent nodes belongingparents(PC) remaining single nodes belonging R (line 6);group sibling nodes S, new parent LV H created added W(lines 7 8);update distances working node set (line 9), distancesnew LVs remaining variables W calculated (the calculation easilyderived previously computed distances; details, see Choi et al., 2011);11. instance different genes used infer trees.177fiMourad, Sinoquet, Zhang, Liu, & LerayAlgorithm 4 Distance-based general LTM learning (DBG, adapted RG, Choi et al.,2011)INPUT:X, set n observed variables {X1 , ..., Xn }.OUTPUT:, respectively tree structure parameters LTM constructed.1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:W X /* Initialization working set variables */inf dist computation(W) /* three variables W */(V, E) empty tree(W) /* tree W edges */loop(PC,S,R) test relations(D,W) /* see paragraph 3 section */W (parents(PC), R) /* parents singles */LCMT LCM trees(S) /* LCM tree sibling group */W W latent variables(LCMT)inf dist computation(W) /* LVs W */E E edges(PC) edges(LCMT)V V latent variables(LCMT)|W| = 2E E edge two remaining nodes(W)breakelse |W| = 1 break endend loopEM (T ) /* See Section 3.1 */working node set W contains strictly two nodes, new stepstarted. Otherwise, two possible situations: working node set Wcontains two nodes, nodes connected12 procedure completed(lines 12 14); working node set W contains one node, iterationstops (line 15).learning partial structure, model parameters (line 17) learned (see Section3.1).practice, Choi et al. (2011) restricted learning symmetric discrete distributions13 (see definition Subsection Distances Variables). restriction presentsmajor advantage: allows derive model parameters use distances previously learned structure recovery. words, learning structure,need recover parameters EM. due one-to-one correspondencedistance model parameters (for details, see Choi et al., 2011).12. prevents introduction redundant LV, see Section 2.5, second paragraph.13. Nevertheless, algorithm applied non-symmetric discrete distributions. requirementvariables share state space.178fiLatent Tree Modelsdiminish computational complexity DBG, Choi et al. (2011) propose firstlearn minimum spanning tree (MST) based distances OVs. Then, tree,identify set internal nodes. internal node Vi neighbor nodesnbd(Vi ), apply DBG outputs latent tree. global model, subtree{Vi , nbd(Vi )} replaced corresponding latent tree. strategy allowsreduce computational complexity latent tree construction MST fastcompute DBG applied restricted number variables. term samplecomplexity, DBG derived algorithms require log n observations recoveringmodel high probability. sample complexity equal one Chow-Liualgorithm (Tan et al., 2011).Another version DBG algorithm developed assumed observations generated genuine LTM. prevent incorporation irrelevantLVs, applying DBG subtrees {Vi , nbd(Vi )}, integrated modellatent trees increase BIC score.Spectral MethodsRecent works extended previous distance methods following spectral approach.one hand, Anandkumar et al. (2011) addressed multivariate setting observedlatent nodes random vectors rather scalars. approach dealgeneral linear models containing categorical continuous variables. Another important improvement method sample complexity bound given termsnatural correlation conditions generalize restrictive effective depth conditions previous works (Erdos et al., 1999; Choi et al., 2011). proposed extensionconsists replacing step line 5 Algorithm 4 quartet test14 relying spectral techniques (more specifically, canonical correlation analysis; Hair, Black, Babin,Anderson, 2009). Given four observed variables {X1 , X2 , X3 , X4 }, spectral quartet testdistinguishes four possible tree topologies (see Figure 8). correct topology{{Xi , Xj }, {Xi0 , Xj 0 }} if:|E[Xi Xj> ]| |E[Xi0 Xj>0 ]| > |E[Xi0 Xj> ]| |E[Xi Xj>0 ]| ,(25)|M | := k`=1 ` (M ) product k largest singular values matrixE[M ] expectation (estimated using covariance matrix).hand, Song et al. (2011) proposed non-parametric learning basedkernel density estimation (KDE) (Rosenblatt, 1956; Parzen, 1962). KDE particularlyrelevant model learning, case non-Gaussian continuous variables showing multimodality skewness. Given set N i.i.d. observed data Dx = {x1 , ..., xN }, jointdistribution modeled :N n1 XYk(xj , xij ),P (x) =N(26)i=1 j=1x = {x1 , ..., xn } observation, k(x, x0 ) Gaussian radial basis function Nnumber observations. Kernels k(x, x0 ) represented inner products h(x), (x0 )iF14. Quartet tests widely used phylogenetic tree inference. first authors adapt LTMlearning Chen Zhang (2006).179fiMourad, Sinoquet, Zhang, Liu, & LerayFigure 8: four possible tree topologies quartet test. See Figure 2 node colorcode.feature map : R F. products kernels also kernels, productnj=1 k(xj , x0j ) written single inner product hnj=1 (xj ), nj=1 (x0j )iF n ,tensor product. Let CX := EX [nj=1 (Xj )] Hilbert space embedding KDEdistribution P (X). expectation P (X) formulated hCX , nj=1 (xj )iF n .exploiting given latent tree structure, key Hilbert space embedding allowsdecompose CX simpler tensors. Similarly work Parikh et al. (2011), messagepassing parameter estimation reformulated tensor notation (see workSong et al., 2011, details). learn structure, non-parametric additivetree metric used. two variables Vi Vj , distance is:111>>dij = log |Cij Cij|? + log |Cii Cii> |? + log |Cjj Cjj|? .244(27)Then, given distances variables, NJ DBG used learn structure.3.2.4 Determination Latent Variable CardinalitiesLCM learning, LV cardinality determined examination possible values (up maximum) choosing one maximizes criterion,BIC (Raftery, 1986). cardinality value, parameters required calculatelikelihood appearing optimization criterion. purpose, random restartsEM generally used learn parameters low probability getting trappedlocal maxima. drawback method cannot applied LTM learning, EM becomes time-consuming several LVs. better solution consistsusing greedy search approach, starting preset value LV cardinality (generallyequal 2) incrementing meet optimal criterion. However, solution stillremains computationally demanding (Zhang, 2004).tackle issue computational burden, several strategies proposed.instance, one simply set small value LV cardinalities. Following idea,Hwang collaborators (2006) constrain LVs binary variables. workedbinary trees whose OVs also binary, restriction severe practice. Nevertheless, case non-binary OVs and/or non-binary trees, fast method presentsseveral drawbacks: one hand, small cardinality lead important loss180fiLatent Tree Modelsinformation; hand, large cardinality entail model overfittingunnecessary computational burden.rigorous, Wang et al.s approach (2008) relies regularity (see Section 2.5). Knowing cardinality neighbor variables Zi , cardinality LV H determinedfollows:ki=1 |Zi |.(28)|H| =maxki=1 |Zi |fast approach efficient LVs owning number neighbors. Thuspracticable binary trees trees whose LV degrees small (close 3).context large scale data analysis (several thousands variables), Mourad et al. (2011)proposed estimate cardinality LV given number children. rationaleunderlying approach following: child nodes LV has, largernumber combinations values child variables. Therefore, cardinalitylatent variable depend number child nodes. Nonetheless, keepmodel complexity within reasonable limits, maximum cardinality fixed.Two additional methods proposed offer better trade-off accuracycomputational cost. first one uses search-based agglomerative state-clusteringprocedure (Elidan & Friedman, 2001). idea relies Markov blanket LV.LTMs, Markov blanket LV H, noted MBH , composed parentchildren. Markov blanket represents set variables directly interact H.Elidan Friedmans method sets initial cardinality H based empirical jointdistribution MBH , noted P (MBH ). H initialized state configurationfound P (MBH ). cardinality repeatedly decreased successive mergingoperations: states hi hj , whose merging entails best optimization given score,merged. repeating operations till H one state, cardinality valueleading best score selected. second method relies local fast parameterestimation LCM learning (Harmeling & Williams, 2011). presented firstparagraph section, greedy search approach used. starts presetvalue increments meet optimal criterion. greedy search becomes efficientbecause, cardinality value test, parameters quickly learned constant time.3.2.5 Choosing RootLTM root cannot learned data. However sometimes need determineroot. instance, LCM-based parameter learning (see Algorithm 1) easilyperformed root chosen.root determined priori knowledge data. instance,consider latent structure LTM represents hierarchy concepts (i.e. taxonomyontology). Thus, LV root corresponds highest abstract level, whereas LVnode OVs children interpreted lowest abstract level. Actually,variable clustering-based algorithms implicitly implement priori knowledge.3.2.6 Time Complexity Scalabilitytime complexity generic LTM learning algorithms summarized Table 1.table, compare algorithms, approaches, models time complexities. also181fiMourad, Sinoquet, Zhang, Liu, & LerayAlgorithmCLApproach-ModelTreeComplexityO(n2 N )Instantiation(Chow & Liu, 1968)NGSScoreTreeO(sn5 N )DHC (Zhang, 2004)AGS, Alg. 2ScoreTreeO(sn2 N )AHCBVariableclusteringForestO(n2 N )LCMB-LTM, Alg. 3VariableclusteringForestO(n2 N )HSHC (Zhang & Kocka, 2004b)EAST (Chen et al., 2012)LTAB (Wang et al., 2008)BIN-A (Harmeling & Williams, 2011)BIN-G (Harmeling & Williams, 2011)CFHLC (Mourad et al., 2011)BI (Liu et al., 2012)NJInformationdistanceTreeO(n3 N )DBG, Alg. 4InformationdistanceO(n3 NTreeO(n2 N+n4 )+n4 )NINJA (Saitou & Nei, 1987; Wheeler, 2009)RG (Choi et al., 2011)CLRG (Choi et al., 2011)regCLRG (Choi et al., 2011)Table 1: Computational time complexities generic algorithms dedicated latent treemodel (LTM) learning. number observed variables, number observations number steps (in search-based algorithms) denoted n, Ns, respectively. CL: Chow-Lius algorithm; NGS: naive greedy search (Section3.2.1); AGS: advanced greedy search (Section 3.2.1); LCMB-LTM: latent classmodel-based LTM learning (Section 3.2.2); NJ: neighbor joining (Section 3.2.3);DBG: distance-based general LTM learning (Section 3.2.3).give examples instantiations generic algorithms. Online resources summarizedAppendix A. order simplify comparison time complexities, considernumber n variables (input data), number N observations numbersteps (for search-based algorithms). LTM learning algorithms comparedChow-Liu algorithm learning tree without LVs. Details complexitycalculation LTM learning algorithms provided Supplemental material B.2.tree contain LV, learning model done efficientlyO(n2 N ) using Prims algorithm (1957). situation complicatedtree contains LVs. complexity finding regular LTM lowest score2O(23n ). Search-based methods implement heuristics reduce large complexity.overall complexity decomposed product three main terms: numbersteps, structure learning complexity parameter learning complexity. opposite,variable clustering- distance-based methods, overall complexity decomposedsum. Nevertheless, development new operators greedy searchapplication local EM led significant improvements (from O(sn5 N ) O(sn2 N )).Variable clustering-based methods computationally efficient multiple reasons.rely pairwise dependence computation identify LVs connections,LCM-based learning determine LV cardinality. Regarding distance-based methods,NJ provides reasonable complexity O(n3 N ), whereas DBG presents high complexityO(n3 N + n4 ). However, last complexity corresponds worst case, treelearn hidden Markov model. Besides, Choi et al. provide modified DBGreduces complexity O(n2 N + n4 ).182fiLatent Tree ModelsAlgorithmNumber variablesNumber observationsType dataCL1LCMDHCSHCHSHCEASTLTABBIN-ABIN-GCFHLCBINJRG2CLRG2regCLRG2AlgorithmNumber variablesNumber observationsType dataCL1LCMDHCSHCHSHCEASTLTABBIN-ABIN-GCFHLCBINJRG2CLRG2regCLRG2BinTreeBinForest5500simu0.015.83123.8343.8615.1420.175.972.682.611.337.66non-binnon-binnon-binnon-binAlarm371000simu0.1534.32timetime3729.78158.644366.93277.016388.6983.31574.572.0386.121.2899.935.421223.19319.62non-binnon-binnon-binnon-binnon-binnon-binnon-binnon-bin4500simu0.011.4318.7927.0713.8512.562.83.003.06119.38non-binnon-binnon-binnon-binForest20500simu0.040.97timeAsiaHannover851003589simureal0.010.001.0258.5816.239.864.555.391.51.93.795.020.9710.2216.700.2317.870.618.67.877.650.154.750.163.490.063.630.046.54Coil-42 NewsGroup4210040008121realreal0.452.17678.191467.10timetimetimetimetimetimetime751683time2197.69387.211152.70436.411302.10560.91291.41193.256311.99non-bin1325.38non-bin274.37non-bin927.22non-bin345.09Car7869real0.012.541609.72150.2318.7963.5535.363.723.722.769.26non-binnon-binnon-binnon-binHapGen10001000simu121.36bugtimetimetimetimetime3573.207671.20787.218977.02non-binnon-binnon-binnon-binTree19500simu0.041.61time4258.0687.04309.4786.520.630.296.6183.34non-binnon-binnon-binnon-binHapMap10000116realmemorymemorytimetimetimetimetimememorymemory2852.6timememorymemorymemorymemoryLong running timeShort running timeTable 2: Comparison running times algorithms literature small,large large simulated real datasets. 1: CL learns tree without LVs;2: RG, CLRG regCLRG learn tree whose internal nodes observedlatent. time: long running time; memory: out-of-memory; non-binary:impossible process non-binary data. 3: results work Chen (2008).183fiMourad, Sinoquet, Zhang, Liu, & LerayAlgorithmNumber variablesNumber observationsType dataBinTreeBinForest4500simuAsia5500simuHannover8100simu53589realCarTree7869real19500simuCL1-3222.80-3350.20-281.430-7859.60-7161.20-106280LCM-3361.830-3646.98-346.2310-7754.63-7127.818-100100DHC-2825.110-3038.660-269.326-7710.961-7049.9822timeSHC-2825.110-3056.770-268.044-7709.710-7056.184-10095.9217HSHC-2825.10-3056.770-270.590-7709.710-7057.493-10087.548EAST-2825.110-3056.760-283.826-7709.690-7051.977-10092.455LTAB-3332.948-379147-727.323-7876.480-8084.8857 -13410.27390BIN-A-29910-31460-296.010-77560-7137.741-100100BIN-G-29910-31460-296.010-77560-7133.843-100100CFHLC-3682.860-3302.560-280.862-8032.390-7200.7626-10070.4310BI-28500-30740-2830-77111-706317-100732NJnon-binnon-bin-288.391-77143non-binnon-binRG2non-binnon-bin-287.132-7711.44non-binnon-binCLRG2non-binnon-bin-271.810-7710.12non-binnon-binregCLRG2non-binnon-bin-266.140-7742.423non-binnon-binAlgorithmForestAlarmCoil-42NewsGroupHapGenHapMap203742100100010000Number observations5001000400081211000116Type datasimusimurealrealsimurealCL1-113300-112810-364440-1214000-1912500memoryNumber variablesLCM-107090-218593489-49581491-124390768bugmemoryDHCtimetimetimetimetimetimeSHC-10777.811timetimetimetimetimeHSHC-10775.250-11322.8384timetimetimetime-10777.085 -12315.66589-35982.43timetimetime-14207.87392 -17733.87239 -43655.3746timebugtimeEASTLTABBIN-A-107080-17640551-37380104-11906033-3010103962memoryBIN-G-107080-17600589-3740478-120230231-3017903006memory-17856.0418 -51878.73151 -129101.4488 -367875.31706-373523876CFHLC-10762.38BI-107616-12296125-36682152NJnon-binnon-binRG2non-binCLRG2regCLRG2-117278134-2678811347timenon-bin-11761039non-binmemorynon-binnon-bin-120274380non-binmemorynon-binnon-binnon-bin-11758046non-binmemorynon-binnon-binnon-bin-118938161non-binmemoryHigh BICLow BICTable 3: Comparison BIC scores algorithms literature small, largelarge simulated real datasets. 1: CL learns tree without LVs;2: RG, CLRG regCLRG learn tree whose internal nodes observedlatent. time: long running time; memory: out-of-memory; non-binary:impossible process non-binary data. 3: results work Chen (2008).184fiLatent Tree Modelsalgorithms proposed literature differ generic algorithmspresented. Tables 2 3, compare algorithms literature small, largelarge simulated real datasets15 . Moreover provide results standardalgorithms: CL model-based LCM-based approaches. dataset, learnedmodel training data evaluated BIC score test data. repeatedexperiments 10 times. programs allowed run maximum 6 hours. Datasetsdescribed Supplemental material B.316 . report BIC score standarddeviation running time.small datasets (n 10 variables), search-based methods lead best BIC values,except Asia dataset distance-based method, regCLRG, best one.surprising since search-based methods evaluate large number models findoptimal one. Nevertheless, large datasets (10 n 100), search-based methodsrequire long running times thus cannot used datasets Coil-42NewsGroup ones. context, variable clustering-based distance-based methodsmuch efficient yielding accurate results. Regarding large datasetcontext (n > 100), variable clustering-based distance-based methods learnLTMs17 . CFHLC18 approach able process HapMap data containing 117observations 10k variables. datasets, observe using CL model LCMpredominantly leads lower BIC scores using LTM, except largelarge datasets.3.2.7 SummaryLTM learning subject many methodological developments. structureknown, EM often preferred. Nevertheless, large LTMs, EM leads considerablerunning times local maxima. address problem, LCM-based EM allowsquickly learn parameters, spectral methods help find optimal solutionLTM parameters required. structure unknown, search-based approachesrepresent standard methods Bayesian network learning. However suitablelearning small LTMs. tackle issue, variable clustering-based methods representefficient alternatives. methods based idea grouping variables identifyLVs bottom-up manner. Recently, phylogenetic algorithms adaptedgeneral LTM learning. Compared methods, guarantee exactly recovergenerative LTM structure conditions.15. fair comparison, used implementation NJ provided Choi et al. (2011).16. Although algorithms NJ, RG, CLRG regCLRG process kind data shared state space(binary data, ternary data, ...), implementation provided Choi et al. (2011) processbinary data. Hence algorithms applied datasets. recall RG, CLRGregCLRG exactly learn LTM instead tree whose internal nodes compelledlatent.17. Although shown Tables 2 3, NJ, RG, CLRG regCLRG able process 1000binary variables experiments.18. work Mourad et al. (2011), CFHLC implements window-based approach scale largedatasets (n 100k variables). fair comparison, window-based approachused.185fiMourad, Sinoquet, Zhang, Liu, & LerayFigure 9: Illustration phylogenetic tree reconstruction.4. Applicationssection, discuss illustrate three types applications LTMs: latent structurediscovery, multidimensional clustering probabilistic inference. end section,also briefly present applications classification.4.1 Latent Structure DiscoveryLatent structure discovery aims revealing: (i) latent information underlying data, i.e.unobservable variables abstract concepts role play data analysis,(ii) latent relationships, i.e. relationships existing observed latent information,also pieces latent information themselves. purpose, LTM analysisrepresents powerful tool latent information latent relationships modeledLVs graph edges, respectively. Thanks LTMs, latent structure discoveryapplied several fields: marketing (Zhang, Wang, & Chen, 2008), medicine (Zhang,Nielsen, & Jensen, 2004; Zhang et al., 2008), genetics (Hwang et al., 2006; Mourad et al.,2011) phylogenetics (Felsenstein, 2003; Friedman, Ninio, Peer, & Pupko, 2002). Letus take example phylogenetics major application LTMs structurediscovery.phylogenetics, purpose infer tree representing evolutionary connections observed species. Let us consider human closest living relatives:orangutan, gorilla, bonobo chimpanzee. DNA sequences, possiblereconstruct phylogenetic tree. DNA sequences sequences letters A, , G C.evolution species, DNA sequences modified mutational processes.186fiLatent Tree ModelsFigure 10: Latent tree model learned dataset Danish beer consumption. Edgewidths proportional mutual information nodes. latentvariable, number latent classes indicated brackets. See Figure 2node color code. Lantern software.species characterized DNA sequence. One popular algorithmsphylogenetic tree reconstruction NJ (described Section 3.2.3, Neighbor Joining).starts considering tree star linking species (see illustration Figure 9).distances species calculated based DNA sequences. Chimpanzeebonobo present shortest distance thus regrouped new latent node.distances updated last previous step reiterated constructionfinal phylogenetic tree. tree first links chimpanzee bonobo, human,gorilla orangutan. success NJ comes fact that, compared previoushierarchical clustering methods UPGMA (Unweighted Pair Group MethodArithmetic Mean), assume species evolve rate. lengthedge represents time separating two species. Moreover, assuming distancescorrect, NJ outputs correct tree.4.2 Multidimensional ClusteringCluster analysis, also called clustering, aims assigning set observations severalgroups (called clusters) observations belonging cluster similarsense (Xu & Wunsch, 2008). LTMs particular tools produce multipleclusterings: LV represents partition data, related specific subsetvariables. application called multidimensional clustering mainlyexplored Chen et al. (2012).Let us illustrate LTM-based multidimensional clustering using dataset surveyDanish beer market consumption. purpose, use user-friendly softwareLantern. dataset consists 11 variables 463 consumers. variable representsbeer brand evaluated four possible answers survey questionnaire:never seen brand (s0); seen before, never tasted (s1); tasted,drink regularly (s2) drink regularly (s3).187fiMourad, Sinoquet, Zhang, Liu, & LerayFigure 11: Information curves latent variable H1. Lantern software.learned model presented Figure 10. BIC score 4851.99. modelcontains 3 LVs: H0 , H1 H2 . LVs 2, 3 2 latent classes, respectively. Letus start H1 simplest interpretable LV. Let X1 , X2 , ..., Xn OVs sorteddecreasing values pairwise MI H1 OV Xi . Two different informationcurves analyzed Figure 11: (i) curve pairwise mutual information I(H1 ; Xi )H1 OV Xi , (ii) curve cumulative information I(H1 ; X1 , ..., Xi )representing MI H1 first OVs X1 , ..., Xi . curve pairwise mutualinformation shows TuborgClas, followed CarlSpec Heineken, beersrelated H1 . curve cumulative information presents complementary information.cumulative information curve increases monotonically reaches maximumn. ratio I(H1 ; X1 , ..., Xi )/I(H1 ; X1 , ..., Xn ) information coverage firstOVs. ratio equal 1, means H1 conditionally independent Xi+1 , ..., Xngiven first OVs. practice first OVs whose information coverage less95% considered relevant. Using cumulative information curve, observe H1related TuborgClas, CarlSpec Heineken, represent group beersdifferent others. TuborgClas CarlSpec frequent beers, bit darkercolor different taste two main mass-market beers, GronTuborgCarlsberg. Although Danish, Heineken one largest brand worldDanes would tasted sometimes travels abroad. ResultsLVs discussed shown (interpretation remains H1 ). H0related CeresTop, CeresRoyal, Pokal, Fuglsang, CarlsSpec FaxeFad (i.e. minor localbeers), whereas H2 connected GronTuborg Carlsberg (i.e., two mainmass-market beers).188fiLatent Tree Modelss0s1s2s3Class1, priorTub Carl0.0300.07 0.120.89 0.810.02 0.07= 0.36Hein0.080.30.570.05Class2, priorTub Carl0.06 0.150.56 0.740.32 0.110.060= 0.27Hein0.360.40.230.01Class3, priorTub Carl0000.010.14 0.390.86 0.61= 0.37Hein0.020.170.660.16Table 4: Class conditional probability tables latent variable H1. Tub: TuborgClas;Carl: CarlsSpec; Hein: Heineken.H2Class1Class2Class10.550.45H1Class20.710.29Class30.110.89Table 5: Conditional probability distributions latent variable H2 given H1 .Class conditional probability distributions (CCPDs) H1 presented Table 4.Using table, easy interpret latent classes. instance, first class (Class1)represents 36% consumers (prior = 0.36). class, conditional probabilitiess2 higher 0.5. means consumers tasted beers,drink regularly. second class (Class2) contains 27% consumersrepresents people saw beers tasted them. last class (Class3)includes 37% consumers represents people tasted beers drinkregularly. Results LVs discussed shown. CCPDs relativeH0 show division group consumers tasted beers (Class1)complicated group consumers never saw brands, saw tasted(Class2). Regarding H2 , CCPDs report consumers tasted beers(Class1) consumers drink regularly (Class2). Using LTM, alsoanalyze relations different partitions. conditional probability distributionP (H2 |H1 ) given Table 5. observe consumer behaviors similar twogroups beers. instance, consumers tasted regularly drink H1 groupbeers (Class3 H1 ) generally also drink regularly H2 group beers (Class2 H2 ).example, able find consumer profiles specific beer brands. Multidimensional clustering thanks LTMs helps discover multiple facets data (i.e. LVs)partition data along facet (i.e. latent class). Moreover, general relationsmultiple facets highlighted connections LVs.4.3 Probabilistic InferenceProbabilistic inference process answering probabilistic queries form p(x|y),event x given knowledge (Koller & Friedman, 2009), using Bayes formula:p(x|y) =p(y|x)p(x).p(y)189(29)fiMourad, Sinoquet, Zhang, Liu, & Leray10101010102N=1kN=10kN=100k110Time (hour)100110102312410820241416644166441664C101010001011210LTM (1k)LTM (10k)LTM (100k)LBPCL (100k)LCM (100k)12241081611010LTM (1k)LTM (10k)LTM (100k)CTPLBPCL (100k)LCM (100k)01041021001011021241081Figure 12: Experiments ALARM BARLEY networks: a) running times LTMlearning using LTAB algorithm (Wang et al., 2008), b) approximation accuracy probabilistic inference c) running time inference. Approximationaccuracy measured Kullback-Leibler divergence approximateinferred distributions exact inferred distributions obtained clique treepropagation original BN. N C designate sample sizemaximal cardinality latent variables, respectively. results comework Wang et al. (2008).Probabilistic inference used many circumstances, credit card fraud detection(Ezawa & Norton, 1996) disease diagnostic (McKendrick, Gettinbya, Gua, Reidb, &Revie, 2000).190fiLatent Tree ModelsProbabilistic inference general BN known NP-hard task (Cooper, 1990).tackle issue, one approximate original BN using maximum weight spanningtree learned relying Chow Lius algorithm (1968). drawback riskinaccuracy inference results. context, LTM provides efficient simplesolution, because: (i) thanks tree structure, model allows linear computationsrespect number OVs, time, (ii) represent complex relationsOVs multiple LVs. learning LTM performing inferencetime-consuming Wang et al. (2008) propose following strategy: first, offline modellearning performed, answers probabilistic queries quickly computed online.However, recent spectral methods (Parikh et al., 2011) considerably reduced model learningphase, require learn model structure. makes inferencelarge LTMs possible (around several hundred OVs) thus renders evenattractive.Inferential complexity depend number OVs, also LVcardinalities: higher cardinality, higher complexity. Hence Wang et al.(2008) propose tradeoff inferential complexity model approximation accuracyfixing maximal cardinality C LVs.Wang et al. (2008) empirically demonstrated high performance LTM-based inference 8 well-known Bayesian networks literature. principle consistslearning LTM provide best approximation original BN.purpose, data sampled original BN LTM learned data.illustrate inference, let us consider two examples, ALARM BARLEYnetworks show lowest highest inferential complexities among aforementioned networks, respectively. ALARM network contains 37 nodes, characterizedaverage indegree 1.24 (max: 4) average cardinality 2.84 (max: 4).BARLEY network contains 48 nodes; average indegree 1.75 (max: 4) averagecardinality 8.77 (max: 67). Two parameters central user: (i) N , samplesize entails long model learning running times leads better model accuracies,(ii) C, maximal cardinality LVs entails long model learning inferencerunning times leads higher model accuracies.Figure 12, LTM-based method compared standard inference approaches: LCM-based approach, Chow-Liu (CL) model-based approach loopybelief propagation (LBP) (Pearl, 1988). Exact inference clique tree propagation(CTP) (Lauritzen & Spiegelhalter, 1988) original BN considered reference.Figure 12a reports running times LTM learning using LTAB algorithm (Wang et al.,2008). Running times almost linearly increase N C. Regarding inference accuracy (Figure 12b), LTM-based method outperforms methods N Chigh, e.g. N = 100k C = 8 ALARM network. regards inference runningtimes (Figure 12c), benefits using LTM-based method high ALARMnetwork, high inferential complexity network. experiments, note CLalso interesting, choice latter LTM dependonline inference time allowed. time limited, CL would preferred.case, LTM would chosen.191fiMourad, Sinoquet, Zhang, Liu, & Leray4.4 ApplicationsBeside latent structure discovery, multidimensional clustering probabilistic inference,interesting applications LTMs.simple efficient classifier naive Bayes. model assumes OVs independent conditional class variable. assumption often violated datahence numerous adaptations developed improve classifier performance.Naive Bayes generalized introducing latent nodes internal discrete nodes(Zhang et al., 2004) continuous nodes (Langseth & Nielsen, 2009), mediating relation leaves class variable. model identical LTM exceptroot observed. Recently, Wang et al. (2011) proposed classifier based LTM.class, specific LTM learned latent tree classifier built aggregatingLTMs. classifier outperforms naive Bayes many successful classifierstree augmented naive Bayes (Friedman, Geiger, & Goldszmidt, 1997) averagedone-dependence estimator (Webb, Boughton, & Wang, 2005).specifically research fields, LTM used human interactionrecognition, haplotype inference genetics diagnosis traditional medicine. Humaninteraction recognition challenging task, multiple body parts concomitantinclusions (Aggarwal & Cai, 1999). purpose, use LTM allows segmentinteraction multi-level fashion (Park & Aggarwal, 2003): body part positionsestimated low-level LVs, overall body position estimated highlevel LV. genetics, need inferring haplotypic data (i.e. latent geneticDNA sequences) genotypic data (observed data). Kimmel Shamir (2005) performefficient haplotypic inference using two-layer LFM. Finally, Zhang et al. (2008) appliedLTMs traditional Chinese medicine (TCM). discovered latent structureobtained matches TCM theories. model provides objective justificationancient theories.5. Discussiondata analysis, LTM represents emerging popular topic offers several advantages:model allows discover interpretable latent structure.latent variable intended represent way cluster categorical data, connections latent variables meant express relations multipleclustering ways.Multiple latent variables organized tree greatly improve flexibility probabilistic modeling while, time, ensuring linear - thus fast - probabilisticinference.Applications LTMs summarized Table 6, recapitulates three types applications details, examples, references generic algorithms, scalability large datasets,software bibliographical references.past decade, extensive research efforts done LTM learning.structure known, standard EM LCM-based EM spectral methods used.192fiLatent Tree ModelsTable 6: Summary main applications latent tree model.structure unknown, three classes methods proposed: search-based,variable clustering-based distance-based methods. first one slow leadsaccurate models. second one drastically decreases running times. Finally, last classguarantees exactly recover generative LTM structure assumptionLVs number states number known.spite aforementioned advances, use LTM presents drawbacks.example, data dimension large large, model learning still remains prohibitive. Regarding probabilistic inference, LTM provides better results standardChow-Lius approach, leads computational burden.6. Future DirectionsProgress LTM made, still much done. multiplepromising directions. instance, recent work developed LTM continuous data analysis (Poon, Zhang, Chen, & Wang, 2010; Choi et al., 2011). authors investigatedrelationships LTM ontology (Hwang et al., 2006), LTM-based dependencevisualization (Mourad, Sinoquet, Dina, & Leray, 2011). Although researchcarried application causal discovery latent trait analysis, argueLTM might represent interesting avenues research.LTM Continuous Data: Recently, LTM modeling applied continuousdata analysis (Poon et al., 2010; Choi et al., 2011; Song et al., 2011; Kirshner, 2012).instance, Poon et al. (2010) proposed new model, called pouch latent tree model(PLTM). PLTM identical LTM, except observed node LTM replacedpouch node representing aggregation multiple continuous OVs. PLTMrepresents generalization Gaussian mixture model (GMM) one LVallowed. proposal Poon et al. originates fact model-based clusteringcontinuous data sensitive selected variables. Similarly categorical clustering(Section 4.2), high-dimensional continuous data, multiple ways partitiondata, multiple LVs PLTM able take account. Poon et al.193fiMourad, Sinoquet, Zhang, Liu, & Leraydeveloped search-based algorithm PLTM learning. latter algorithm closelyrelated EAST algorithm (Zhang & Kocka, 2004b) dedicated LTM learningthus quite slow. Hence, development new methods dedicated efficient PLTMlearning certainly represents interesting perspectives research. Besides, next step wouldalso development LTM dedicated mixed data analysis, i.e. combining categoricalcontinuous data.LTM Structure Ontology: possible relate LTM ontology, particulartaxonomy (tree-structured ontology). instance, applying LTM microarraydataset yeast cell-cycle, Hwang et al. (2006) showed LVs significantly related specific gene ontology terms, organelle organization cellular physiologicalprocess. Thus taxonomy could help interpret LVs. Moreover taxonomy structure couldused priori structure.Dependence Visualization: LTM provide compact interpretable view dependences variables, thanks graphical nature latent variables (Mouradet al., 2011). Compared heat map (Barrett, Fry, Maller, & Daly, 2005)display pairwise dependences variables, LTM helps visualize pairwisehigher-order dependences. Pairwise dependence represented chain lengthlinking two leaf variables, whereas higher-order dependences simply representedset leaf variables connected common LV.Causal Discovery: argue LTM represents simple efficient model causaldiscovery, following reasons:LTM root known, model interpreted hierarchy.hierarchy, LVs distributed multiple layers. multiple LV layers represent different degrees information compactness (i.e. data dimension reduction),since LV captures patterns child variables. connexion variablesparent-child relationships allows easy natural moves general (toplayers) specific (bottom layers) causes, vice-versa. Thus, causal discoveryguided hierarchical model feature.constructing model variables X = {X1 , ..., Xn }, one wants testdirect dependence Xi another variable present network,easily computed test independence Xi conditionalparent Xi . practical advantage conditional test meant assessdirect dependence number degrees freedom required low (becauseparent Xi used condition test), ensures good power.Latent Trait Analysis: Similarly generalization LCM LTM, wouldworth developing extension latent trait model tree-structured modelinternal nodes continuous LVs. instance, would alleviate drawbacks localindependence latent trait model would provide multiple facets thanks LVsdealing high-dimensional data.194fiLatent Tree ModelsAcknowledgmentsauthors deeply indebted four anonymous reviewers invaluable comments helping improve manuscript. work supported BILBioinformatics Research Project Pays de la Loire Region, France. authors alsograteful Carsten Poulsen (Aalborg University, Denmark) providing Danish beerdata, Yi Wang (National University Singapore) LTAB algorithm, Tao Chen (EMCCorporation, Beijing, China) EAST algorithm, Stefan Harmeling (Max Planck Institute, Germany) BIN-A BIN-G algorithms, Myung Jin Choi (Two SigmaInvestments, USA) Vincent Tan (University Wisconsin-Madison, USA) RG,CLRG regCLRG algorithms.Appendix A. Online Resources MentionedSoftware:BIN-A, BIN-G, CL LCM:http://people.kyb.tuebingen.mpg.de/harmeling/code/ltt-1.4.tarCFHLC:https://sites.google.com/site/raphaelmouradeng/home/programsDHC, SHC HSHC:http://www.cse.ust.hk/faculty/lzhang/ltm/index.htm (hlcm-distribute.zip)http://www.cse.ust.hk/faculty/lzhang/ltm/index.htm (toolBox.zip)EAST:http://www.cse.ust.hk/faculty/lzhang/ltm/index.htm (EAST.zip)Lantern:http://www.cse.ust.hk/faculty/lzhang/ltm/index.htm (Lantern2.0-beta.exe)NJ, RG, CLRG regCLRG:http://people.csail.mit.edu/myungjin/latentTree.htmlNJ (fast implementation):http://nimbletwist.com/software/ninjadatasets used algorithm comparison available :https://sites.google.com/site/raphaelmouradeng/home/programsAppendix B. Supplemental MaterialB.1 Experiments Parameter Learning EMstudied number random restarts required, practice, obtain convergenceEM (Section 3.1.1) LCMB-EM (Section 3.1.2) optimal solution. BIC scorespresented Figure 13. EM, used method Chickering Heckerman(1997) implemented software LTAB (Wang et al., 2008). analyzed three195fiMourad, Sinoquet, Zhang, Liu, & LerayFigure 13: impact number random restarts convergence expectationmaximization (EM). a) EM. b) LCMB-EM. number restarts reportedx-axis y-axis indicates BIC scores.datasets: two small ones (BinTree Asia) large one (Tree). first two,convergence achieved 20 2000 restarts, respectively. large dataset,convergence never achieved, even 5000 restarts. LCMB-EM, used softwareBIN-A (Harmeling & Williams, 2011). analyzed three datasets: one small one (Asia)two large ones (Tree, Alarm). Convergence achieved first two datasetsone parameter initialization, whereas later largest, convergencenever achieved (we able assess 1000 restartsprohibitive running time).B.2 Time Complexityrecall reader n number variables (input data), N numberobservations number steps (for search-based algorithms). time complexitiesgeneric algorithms LTM learning detailed follows:Naive greedy search (NGS). O(s) steps needed convergencesearch-based methods. step, O(n2 ) new models generateduse 3 operators: addition/removal LV node relocation (Zhang, 2004).model, cardinality optimized LV, O(n2 ) new modelsgenerated (Zhang, 2004). model, parameters learned using EM,196fiLatent Tree Modelsachieved O(nN ). Thus, overall complexity : O(s) O(n2 ) O(n2 ) O(nN ) =O(sn5 N ).Advanced greedy search (AGS), Algorithm 2. O(s) steps neededconvergence search-based methods. step, O(n2 ) new modelsgenerated use 5 operators: addition/removal LV, node relocationaddition/dismissal state relative LV (Zhang & Kocka, 2004b).model, model evaluation realized local EM O(N ). choosingbest model step, parameters learned using EM, achievedO(nN ). Thus, overall complexity : O(s) (O(n2 ) O(N ) + O(nN )) = O(sn2 N ).Agglomerative hierarchical clustering-based learning (AHCB). agglomerative hierarchical clustering achieved O(n2 N )19 . LV cardinality parameterslearned O(N ) thanks LCM parameter learning. O(n) LVs, thuscomplexity (O(N ) O(n)). final global EM parameter learning doneO(nN ). Thus, overall complexity : O(n2 N )+(O(N )O(n))+O(nN ) = O(n2 N ).Latent class model-based LTM learning (LCMB-LTM), Algorithm 3. Pairwise mutual information values computed O(n2 N ). LCM learned O(N ).LCM learning called O(n) times, i.e. new LV added model. LVcardinality parameters learned LCM learning. final global EM parameter learning done O(nN ). Thus, overall complexity : O(n2 N ) +(O(N ) O(n)) + O(nN ) = O(n2 N ).Neighbor joining (NJ). learn structure, O(n) steps. step,pairwise distances computed O(n2 N ). Structure learning thus requires O(n3 N )computations. learning structure, parameters learned EMLCMB-EM O(nN ). Thus, overall complexity : O(n3 N ) + O(nN ) = O(n3 N ).Distance-based general LTM learning (DBG), Algorithm 4. First distances computed O(n3 N ). minimum spanning tree learned before,complexity reduced O(n2 N ). Then, learn structure, testing child-parentsibling relations necessitates O(n4 ) operations worst case, i.e.tree hidden Markov model. Parameters learned EM LCMB-EMO(nN ). Thus, overall complexity : O(n3 N ) + O(n4 ) + O(nN ) = O(n3 N + n4 )O(n2 N ) + O(n4 ) + O(nN ) = O(n2 N + n4 ).B.3 Description Datasets Used Literature Algorithm ComparisonSmall datasets (n 10 variables):BinTree. Datasets generated using binary tree 7 variables (4 leaves 3internal nodes), eight states. leaf data used. traintest datasets consist 500 observations. model comes workHarmeling Williams (2011).19. complexity agglomerative hierarchical clustering O(n2 N ) using single linkage criterion.complexity higher criteria.197fiMourad, Sinoquet, Zhang, Liu, & LerayBinForest. Datasets generated binary forest composed two trees. Onetree 3 variables (2 leaves 1 internal node), one 5 variables (3leaves 2 internal nodes). leaf data used. train test datasetsconsist 500 observations. model comes work HarmelingWilliams (2011).Asia. Datasets generated using well-known Asia network containing 8 binaryOVs. train test datasets consist 100 observations.Hannover. Real dataset containing 5 binary variables. dataset splittrain dataset test dataset. consist 3573 3589 observations,respectively. dataset comes work Zhang (2004).Car. Real dataset containing 7 variables. dataset split traindataset test dataset. consist 859 869 observations, respectively.dataset available :http://archive.ics.uci.edu/ml/.Large datasets (10 n 100 variables):Tree. Datasets generated using tree 50 variables (19 leaves 31 internalnodes). leaf data used. train test datasets consist 500observations.Forest. Datasets generated using tree 50 variables (20 leaves 30 internalnodes). leaf data used. train test datasets consist 500observations.Alarm. Datasets generated using well-known Alarm network containing 37 OVs.train test datasets consist 1000 observations.Coil-42. Real dataset containing 42 variables. dataset split traindataset test dataset. consist 5822 4000 observations, respectively.dataset comes work Zhang Kocka (2004b).NewsGroup. Real dataset containing 100 binary variables. datasetsplit train dataset test dataset. consist 8121 observations.dataset available :http://cs.nyu.edu/roweis/data/20news w100.mat.large datasets (n > 100 variables):HapGen. Datasets generated 1000 genetic variables using HAPGEN software (Spencer, Su, Donnelly, & Marchini, 2009). train test datasetsconsist 1000 observations.HapMap. Real dataset containing 10000 binary variables. datasetsplit train dataset test dataset. consist 118 116 observations,respectively. dataset comes HapMap phase III (The International HapMapConsortium, 2007) concerns Utah residents Northern Western Europeanancestry (CEU).198fiLatent Tree ModelsReferencesAggarwal, J., & Cai, Q. (1999). Human motion analysis: review. Computer VisionImage Understanding, 73 (3), 428440.Akaike, H. (1970). Statistical predictor identification. Annals Institute StatisticalMathematics, 22 (1), 203217.Anandkumar, A., Chaudhuri, K., Hsu, D., Kakade, S. M., Song, L., & Zhang, T. (2011).Spectral methods learning multivariate latent tree structure. Twenty-FifthConference Neural Information Processing Systems (NIPS-11).Atteson, K. (1999). performance neighbor-joining methods phylogenetic reconstruction. Algorithmica, 25 (2), 251278.Attias, H. (1999). Inferring parameters structure latent variable models variationalBayes. Proceedings 15th Conference Uncertainty Artificial Intelligence(UAI-99), pp. 2130.Barrett, J. C., Fry, B., Maller, J., & Daly, M. J. (2005). Haploview: analysis visualizationLD haplotype maps. Bioinformatics, 21 (2), 263265.Binder, J., Koller, D., Russel, S., & Kanazawa, K. (1997). Adaptive probabilistic networkshidden variables. Machine Learning, 29 (2-3), 213244.Cavender, J. A. (1978). Taxonomy confidence. Mathematical Biosciences, 40 (3-4),271280.Chen, T., & Zhang, N. L. (2006). Quartet-based learning hierarchical latent class models:Discovery shallow latent variables. Proceedings 9th International SymposiumArtificial Intelligence Mathematics.Chen, T. (2008). Search-based learning latent tree models. Ph.D. thesis, Hong KongUniversity Science Technology.Chen, T., Zhang, N. L., Liu, T., Poon, K. M., & Wang, Y. (2012). Model-based multidimensional clustering categorical data. Artificial Intelligence, 176 (1), 22462269.Chen, T., Zhang, N. L., & Wang, Y. (2008). Efficient model evaluation searchbased approach latent structure discovery. Proceedings Fourth EuropeanWorkshop Probabilistic Graphical Models (PGM-08), pp. 5764.Chickering, D. M., & Heckerman, D. (1997). Efficient approximations marginallikelihood Bayesian networks hidden variables. Machine Learning, 29 (2-3),181212.Choi, M. J., Tan, V. Y., Anandkumar, A., & Willsky, A. S. (2011). Learning latent treegraphical models. Journal Machine Learning Research, 12, 17711812.Chow, C. K., & Liu, C. N. (1968). Approximating discrete probability distributionsdependence trees. IEEE Transactions Information Theory, 14 (3), 462467.Cooper, G. F. (1990). computational complexity probabilistic inference usingBayesian belief networks. Artificial Intelligence, 42 (2-3), 393405.Cover, T. M., & Thomas, J. A. (1991). Elements information theory. Wiley-Interscience.199fiMourad, Sinoquet, Zhang, Liu, & LerayDaskalakis, C., Mossel, E., & Roch, S. (2009). Evolutionary trees Ising modelBethe lattice: proof Steels conjecture. Probability Theory Related Fields,149 (1-2), 149189.Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete data viaEM algorithm. Journal Royal Statistical Society. Series B (Methodological),39, 138.Elidan, G., & Friedman, N. (2001). Learning dimensionality hidden variables.Proceedings 17th Conference Uncertainty Artificial Intelligence (UAI01), pp. 144151.Erdos, P. L., Szekely, L. A., Steel, M. A., & Warnow, T. J. (1999). logs sufficebuild (almost) trees: Part II. Theoretical Computer Science, 221 (1-2), 77118.Ezawa, K. J., & Norton, S. W. (1996). Constructing Bayesian networks predict uncollectible telecommunications accounts. IEEE Expert, 11 (5), 4551.Farris, J. S. (1973). probability model inferring evolutionary trees. Systematic Zoology,22 (3), 250256.Felsenstein, J. (2003). Inferring phylogenies (2 edition). Sinauer Associates.Friedman, N., Ninio, M., Peer, I., & Pupko, T. (2002). structural EM algorithmphylogenetic inference.. Journal Computational Biology, 9 (2), 331353.Friedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. MachineLearning, 29 (2-3), 131163.Gascuel, O., & Steel, M. (2006). Neighbor-joining revealed. Molecular Biology Evolution, 23 (11), 19972000.Geiger, D., Heckerman, D., & Meek, C. (1996). Asymptotic model selection directednetworks hidden variables. Proceedings Twelfth Conference UncertaintyArtificial Intelligence (UAI-96), pp. 283290. Morgan Kaufmann.Hair, J. F., Black, W. C., Babin, B. J., & Anderson, R. E. (2009). Multivariate data analysis(7 edition). Prentice Hall.Harmeling, S., & Williams, C. K. I. (2011). Greedy learning binary latent trees. IEEETransactions Pattern Analysis Machine Intelligence, 33 (6), 10871097.Hsu, D., Kakade, S., & Zhang, T. (2009). spectral algorithm learning hidden Markovmodels. 22nd Annual Conference Learning Theory (COLT 2009).Hwang, K.-B., Kim, B.-H., & Zhang, B.-T. (2006). Learning hierarchical Bayesian networkslarge-scale data analysis. International Conference Neural Information Processing (ICONIP-06), pp. 670679.Kim, J. H., & Pearl, J. (1983). computation model causal diagnostic reasoninginference systems. Proceedings 8th International Joint ConferenceArtificial Intelligence.Kimmel, G., & Shamir, R. (2005). GERBIL: Genotype resolution block identificationusing likelihood. Proceedings National Academy Sciences United StatesAmerica, 102 (1), 158162.200fiLatent Tree ModelsKirshner, S. (2012). Latent tree copulas. Proceedings Sixth European WorkshopProbabilistic Graphical Models (PGM-12).Koller, D., & Friedman, N. (2009). Probabilistic graphical models: Principles techniques(adaptive computation machine learning). MIT Press.Kraskov, A., & Grassberger, P. (2009). Information theory statistical learning, chap.MIC: Mutual information based hierarchical clustering, pp. 101123. Springer.Kwoh, C.-K., & Gillies, D. F. (1996). Using hidden nodes Bayesian networks. ArtificialIntelligence, 88 (1-2), 138.Lake, J. A. (1994). Reconstructing evolutionary trees DNA protein sequences:Paralinear distances. Proceedings National Academy Sciences UnitedStates America, 91 (4), 14551459.Langseth, H., & Nielsen, T. D. (2009). Latent classification models binary data. PatternRecognition, 42 (11), 27242736.Lauritzen, S. L. (1995). EM algorithm graphical association models missingdata. Computational Statistics & Data Analysis, 19 (2), 191201.Lauritzen, S. L., & Spiegelhalter, D. J. (1988). Local computations probabilitiesgraphical structures application expert systems. Journal RoyalStatistical Society. Series B (Methodological), 50 (2), 157224.Liu, H., Xu, M., Gu, H., Gupta, A., Lafferty, J., & Wasserman, L. (2011). Forest densityestimation. Journal Machine Learning Research, 12, 907951.Liu, T. F., Zhang, N. L., Liu, A. H., & Poon, L. K. M. (2012). novel LTM-based methodmultidimensional clustering. Proceedings Sixth European WorkshopProbabilistic Graphical Models (PGM-12).Martin, J., & Vanlehn, K. (1995). Discrete factor analysis: Learning hidden variablesBayesian network. Tech. rep., Department Computer Science, University Pittsburgh.McKendrick, I. J., Gettinbya, G., Gua, Y., Reidb, S. W. J., & Revie, C. W. (2000). UsingBayesian belief network aid differential diagnosis tropical bovine diseases.Preventive Veterinary Medicine, 47 (3), 141156.Mossel, E., & Roch, S. (2006). Learning nonsingular phylogenies hidden Markov models.Annals Applied Probability, 16 (2), 583614.Mossel, E., Roch, S., & Sly, A. (2011). Robust estimation latent tree graphical models:Inferring hidden states inexact parameters. Submitted.Mourad, R., Sinoquet, C., Dina, C., & Leray, P. (2011). Visualization pairwisemultilocus linkage disequilibrium structure using latent forests. PLoS ONE, 6 (12),e27320.Mourad, R., Sinoquet, C., & Leray, P. (2011). hierarchical Bayesian network approachlinkage disequilibrium modeling data-dimensionality reduction prior genomewide association studies. BMC Bioinformatics, 12, 16.201fiMourad, Sinoquet, Zhang, Liu, & LerayParikh, A. P., Song, L., & Xing, E. P. (2011). spectral algorithm latent tree graphicalmodels. Proceedings 28th International Conference Machine Learning(ICML-2011).Park, S., & Aggarwal, J. K. (2003). Recognition two-person interactions using hierarchical Bayesian network. first ACM International Workshop VideoSurveillance (IWVS03), pp. 6575.Parzen, E. (1962). estimation probability density function mode. AnnalsMathematical Statistics, 33, 10651076.Pearl, J. (1988). Probabilistic reasoning intelligent systems: Networks plausible inference. Morgan Kaufmann, Santa Mateo, CA, USA.Poon, L. K. M., Zhang, N. L., Chen, T., & Wang, Y. (2010). Variable selection modelbased clustering: facilitate. Proceedings 27th International Conference Machine Learning (ICML-2010).Prim, R. C. (1957). Shortest connection networks generalizations. Bell SystemTechnical Journal, 36, 13891401.Raftery, A. E. (1986). Choosing models cross-classifications. American SociologicalReview, 51 (1), 145146.Rosenblatt, M. (1956). Remarks nonparametric estimates density function.Annals Mathematical Statistics, 27, 832837.Saitou, N., & Nei, M. (1987). neighbor-joining method: new method reconstructing phylogenetic trees.. Molecular Biology Evolution, 4 (4), 406425.Schwartz, G. (1978). Estimating dimension model. Annals Statistics, 6 (2),461464.Song, L., Parikh, A., & Xing, E. (2011). Kernel embeddings latent tree graphical models.Twenty-Fifth Conference Neural Information Processing Systems (NIPS-11).Spencer, C. C., Su, Z., Donnelly, P., & Marchini, J. (2009). Designing genome-wide association studies: sample size, power, imputation, choice genotyping chip..PLoS Genetics, 5 (5), e1000477.Steel, M. (2001).favourite conjecture.m.steel/files/misc/conjecture.pdf.http://www.math.canterbury.ac.nz/-Steel, M. (1992). complexity reconstructing trees qualitative characterssubtrees. Journal Classification, 9 (1), 91116.Tan, V. Y. F., Anandkumar, A., & Willsky, A. (2011). Learning high-dimensional Markovforest distributions: Analysis error rates. Journal Machine Learning Research,12, 16171653.International HapMap Consortium (2007). second generation human haplotype map3.1 million SNPs. Nature, 449 (7164), 851861.Wang, Y., Zhang, N. L., Chen, T., & Poon, L. K. M. (2011). Latent tree classifier.European Conferences Symbolic Quantitative Approaches ReasoningUncertainty (ECSQARU2011), pp. 410421.202fiLatent Tree ModelsWang, Y., & Zhang, N. L. (2006). Severity local maxima EM algorithm: Experiences hierarchical latent class models. Proceedings Third EuropeanWorkshop Probabilistic Graphical Models (PGM-06).Wang, Y., Zhang, N. L., & Chen, T. (2008). Latent tree models approximate inferenceBayesian networks. Journal Articial Intelligence Research, 32, 879900.Webb, G. I., Boughton, J. R., & Wang, Z. (2005). naive Bayes: Aggregating onedependence estimators. Machine Learning, 58 (1), 5 24.Wheeler, T. J. (2009). Large-scale neighbor-joining NINJA. Proceedings 9thWorkshop Algorithms Bioinformatics.Xu, L., & Jordan, M. I. (1996). convergence properties EM algorithm Gaussianmixtures. Neural Computation, 8 (1), 129151.Xu, R., & Wunsch, D. (2005). Survey clustering algorithms. IEEE TransactionsNeural Networks, 16 (3), 645678.Xu, R., & Wunsch, D. C. (2008). Clustering (illustrated edition). Wiley-IEEE Press.Zhang, N. L. (2004). Hierarchical latent class models cluster analysis. JournalMachine Learning Research, 5, 697723.Zhang, N. L., & Kocka, T. (2004a). Effective dimensions hierarchical latent class models.Journal Articial Intelligence Research, 21, 117.Zhang, N. L., & Kocka, T. (2004b). Efficient learning hierarchical latent class models.Proceedings 16th IEEE International Conference Tools ArtificialIntelligence (ICTAI), pp. 585593.Zhang, N. L., Nielsen, T. D., & Jensen, F. V. (2004). Latent variable discovery classification models. Artificial Intelligence Medicine, 30 (3), 283299.Zhang, N. L., Wang, Y., & Chen, T. (2008). Discovery latent structures: ExperienceCoIL Challenge 2000 data set*. Journal Systems Science Complexity,21 (2), 172183.Zhang, N. L., Yuan, S., Chen, T., & Wang, Y. (2008). Latent tree models diagnosistraditional Chinese medicine. Artificial Intelligence Medicine, 42 (3), 229245.203fiJournal Artificial Intelligence Research 47 (2013) 393-439Submitted 9/12; published 7/13Lifted Variable Elimination:Decoupling Operators Constraint LanguageNima TaghipourDaan FierensJesse DavisHendrik Blockeelnima.taghipour@cs.kuleuven.bedaan.fierens@cs.kuleuven.bejesse.davis@cs.kuleuven.behendrik.blockeel@cs.kuleuven.beKU Leuven, Department Computer ScienceCelestijnenlaan 200A, 3001 Leuven, BelgiumAbstractLifted probabilistic inference algorithms exploit regularities structure graphicalmodels perform inference efficiently. specifically, identify groupsinterchangeable variables perform inference per group, opposed pervariable. groups defined means constraints, flexibility groupingdetermined expressivity constraint language. Existing approaches exactlifted inference use specific languages (in)equality constraints, often limitedexpressivity. article, decouple lifted inference constraint language.define operators lifted inference terms relational algebra operators,operate semantic level (the constraints extension) rather syntacticlevel, making language-independent. result, lifted inference performedusing powerful constraint languages, provide opportunities lifting.empirically demonstrate improve inference efficiency orders magnitude,allowing exact inference approximate inference feasible.1. IntroductionStatistical relational learning SRL (Getoor & Taskar, 2007; De Raedt, Frasconi, Kersting, & Muggleton, 2008) focuses combining first-order logic probabilistic graphicalmodels, permits algorithms reason complex, uncertain, structured domains.major challenge area perform inference efficiently. First-order logicreason level logical variables: model states X, P (X) implies Q(X),whenever P (X) known true, one infer Q(X), without knowing Xstands for. Many approaches SRL, however, transform knowledge propositional graphical model performing inference. so, lose capacityreason level logical variables: standard inference methods graphical modelsreason ground level, repeating inference steps differentvalue x X, instead x.address problem, Poole (2003) introduced concept lifted inferencegraphical models. idea group together interchangeable objects, performinference operations group instead object. Multipledifferent algorithms proposed, based variable elimination (Poole, 2003; deSalvo Braz, Amir, & Roth, 2005; Milch, Zettlemoyer, Kersting, Haimes, & Kaelbling, 2008;Sen, Deshpande, & Getoor, 2009b, 2009a; Choi, Hill, & Amir, 2010; Apsel & Brafman,c2013AI Access Foundation. rights reserved.fiTaghipour, Fierens, Davis, & Blockeel2011), belief propagation (Kersting, Ahmadi, & Natarajan, 2009; Singla & Domingos, 2008),various approaches (Van den Broeck, Taghipour, Meert, Davis, & De Raedt, 2011;Jha, Gogate, Meliou, & Suciu, 2010; Gogate & Domingos, 2011).group interchangeable objects typically defined means constraintobject must fulfill order belong group. type constraintsallowed, way handled, directly influence granularitygrouping, hence, efficiency subsequent lifted inference (Kisynski & Poole,2009a). Among approaches based variable elimination, advanced system(C-FOVE) uses specific class constraints, namely, conjunctions pairwise (in)equalities.bare minimum required able perform lifted inference. However,show, unnecessarily limits symmetries model capture exploit.article, present algorithm lifted variable elimination basedC-FOVE, uses constraint language extensionally complete, is,group variables constraint exists defines exactly group. aim,C-FOVEs constraint manipulation redefined terms relational algebra operators.decouples lifted inference algorithm constraint representation mechanism.Consequently, constraint language closed operators pluggedalgorithm obtain working system. Apart redefining existing operators,also define novel operator, called lifted absorption, way. Furthermore,propose concrete mechanism constraint representation extensionally complete,briefly discuss operators implemented particular mechanism.new lifted inference algorithm, constraint representation mechanism,perform lifted inference much coarser granularity predecessors. Due this,outperforms existing systems several orders magnitude problems, solvesinference problems could solved approximate inference methods.basic ideas behind approach explained earlier conference paper(Taghipour, Fierens, Davis, & Blockeel, 2012). article extends paper providingprecise motivated definitions operators, levelimplemented. definitions, time, may help understand intuitivesemantic level lifted variable elimination works, serve kind goldstandard implementations lifted variable elimination, provide semanticsbased reference point.paper structured follows. Section 2 illustrates principles lifted variableelimination example, briefly states work improves upon state art,C-FOVE (Milch et al., 2008). Section 3 introduces formal notation terminology,Section 4 provides high-level outline lifted variable elimination algorithm. Section5 describes detail operators algorithm uses. Section 6 briefly discussesefficient representation constraints themselves. Section 7 empirically comparessystems performance C-FOVE, Section 8 concludes.2. Lifted Variable Elimination ExampleAlthough lifted variable elimination builds simple intuitions, relatively complicated,accurate description requires level technical detail conduciveclear understanding. reason, first illustrate basic principles lifted inference394fiDecoupling Lifted Variable Elimination Constraint Languagesimple example, without referring technical terminology introducedlater. start describing example; next, illustrate variable eliminationexample, show lifted.2.1 Workshop Exampleexample Milch et al. (2008). Suppose new workshop organized.workshop popular (that is, many people attend), may start series. Whetherperson likely attend depends topic.introduce random variable , indicating topic workshop, randomvariable S, indicating whether workshop becomes series. consider N people,person i, include random variable Ai indicates whether attends.random variable finite domain takes values, i.e., {ai, ml, . . . } ,{yes, no} S, {true, f alse} Ai .joint probability distribution variables specified undirectedgraphical model. set factors captures dependencies random variablesmodel. model, two kinds factors. person i,factor 1 (Ai , S) states series depends whether person attends,factor 2 (T, Ai ) states attendance depends topic. Note Nfactors first type potential function 1 , factors secondtype potential function 2 . imposes certain symmetry model: impliesdepends persons attendance exactly way, peopletopic preferences.model defines joint probability distribution variables normalized product factors (normalized joint probabilities sum one):Pr(T, S, A1 , . . . , ) =nn12 (T, Ai )1 (Ai , S)Zi=1i=1Z normalization constant.Undirected graphical models visualized factor graphs (Kschischang, Frey, &Loeliger, 2001), node random variable factor, edgefactor random variable variable occurs factor. Figure 1 showsfactor graph example.2.2 Variable Eliminationon, refer values taken variable corresponding lowercasesymbols (e.g., ai shorthand Ai = ai ).Suppose want compute marginal probability distribution Pr (S).Pr (S) =XX=A1XPr (T, S, A1 , . . . , )NN1 XX XY2 (T, Ai )1 (Ai , S)ZA1(1)i=1395i=1(2)fiTaghipour, Fierens, Davis, & Blockeel11A1A2...A322Figure 1: factor graph workshop example. Square nodes represent factors, roundnodes variables. Variables labeled name, factors potentialfunction.Usually, normalization constant Z ignored computations, normalization happens end. So, focus compute(S) =PrXXA1NXY1 (Ai , S)N2 (T, Ai ).(3)i=1i=1(S) compute Pr(s) possible valuestraightforward way computing PrS, tabulate results. compute Pr(true) iteratingpossibleQQN valuecombinations (t, a1 , . . . , ) (T, A1 , . . . , ) computing N(a,true)i=1 1i=1 2 (t, ai )alse). variables binary, 2N +1combination, similarly Pr(fcombinations, combination 2N 1 multiplications performed.clearly scale.However, improve efficiency rearranging computations. computation, multiplications performed repeatedly. Since 1 (A1 , S) 2 (T, A1 )constant Ai except A1 , moved summations Ai , > 1,right hand side Equation 3 becomes:XX1 (A1 , S)2 (T, A1 )X1 (Ai , S)N2 (T, Ai )(4)i=2i=2A2A1NXYPConversely, factor starting A2 independent A1 , moved outsidesummation A1 , givingNNXXYX X2 (T, Ai )1 (Ai , S)1 (A1 , S)2 (T, A1 )(5)A2i=2i=2A1Repeating Ai eventually yieldsXX X1 (AN , S)2 (T, )1 (A1 , S)2 (T, A1 ) . . .A1396(6)fiDecoupling Lifted Variable Elimination Constraint Language12 (T, A1 , S)1 (A1 , S)A1truefalsetruefalsetruetruefalsefalse2 (T, A1 )11221SRLSRLDBDBA1truefalsetruefalse23122=SRLSRLSRLSRLDBDBDBDBA1truetruefalsefalsetruetruefalsefalsetruefalsetruefalsetruefalsetruefalse123621244212 (T, S)PA112 (T, A1 , S)=SRLSRLDBDBtruefalsetruefalse125766Figure 2: Two example factors, product, result summing A1product. values 1 2 chosen arbitrarily illustration.shows Ai , product 1 (Ai , S)2 (T, Ai ) needs computedcombination values (T, S, Ai ). binary, eightcombinations, reducing total number multiplications 8N .Note result Formula 6 function S; yield different valuevalue S. words, factor S. Similarly, result 1 (A1 , S)2 (T, A1 )depends values S, A1 (is factor variables), summationA1 factor obtained. Thus, multiplications summationsFormula 6 best seen operating factors, individual numbers. Figure 2 illustratesprocess multiplying summing factors.result Formula 6 computed follows. First, multiply factors 1 (A1 , S)2 (T, A1 ) value A1 , sum A1 product. exactlycomputation illustrated Figure 2. summing values A1 , result dependsonly; A1 longer occurs factor, factors. sayA1 eliminated. Note elimination consisted first gathering factorscontaining A1 , multiplying them, summing possible values A1 .eliminating A1 , repeat process Ai , time obtainingfactor S. factors multiplied result summed(S)., point single factor obtained. factor equals Prcomputation exactly Variable Elimination (VE) does. Generally,works follows. considers one variable time, order called eliminationorder. considered variable X, first retrieves factors involve X,multiplies factors together single joint factor, finally sums X, thereby397fiTaghipour, Fierens, Davis, & Blockeeleliminating X factor. Hence, step, number remaining variablesstrictly decreases (by 1) also number factors decreases (because set factorsinvolving X replaced single factor).elimination order heavily influence runtime. Unfortunately, finding optimalorder NP-hard. example, elimination order A1 , A2 , . . . , , ,resulted computation 8N multiplications, O(N ).2.3 Lifted Inference: Exploiting Symmetries Among Factorsexample, avoiding many redundant computations, obtained exponential speedup compared naive computation discussed before, reducing computationtime O(2N ) O(N ). N still large. Even efficiency gainedknow certain factors potential function.example, computes product N times: Expression 6, factors1 (Ai , S) 2 (T, Ai ) allPi, product 12 (Ai , S, ) =1 (Ai , S)2 (T, Ai ). also computes sum Ai 12 (Ai , S, ) N times. redundancyarises probabilistic model N people behave way, i.e.,Ai interchangeable. idea behind lifted inference exploit symmetries,compute product sum once. algorithmic perspective, liftedvariable elimination eliminates one Ai variable, exponentiates resulting factor(see formula below), sums . Mathematically, Expression 6 computedfollows:NXX(1 (A1 , S)2 (T, A1 ))(7)A1way lifted variable elimination manipulates set variables {A1 , . . . , }called lifted multiplication lifted summing-out (a.k.a. lifted elimination). Notenumber operations required constant N . Assuming N already known,main operation computing N -th power, O(log N ) (logarithmicN exact arithmetic used, constant floating point arithmetic). Thus, lifted variableelimination runs O(log N ) time case.2.4 Lifted Inference: Exploiting Symmetries within Factorsconsider second elimination order, first eliminate Ai :(S) =PrXNXYA1 ,...,AN1 (Ai , S)i=1N2 (T, Ai ) =XNA1 ,...,AN i=1i=11 (Ai , S)NXYi=1!2 (T, Ai )(8)order, regular variable elimination works follows. inner summation (elimination ) first multiplies factors 2 (T, Ai ) factor 3 (T, A1 , . . . , ),sums :NXYi=12 (T, Ai ) =X3 (T, A1 , . . . , ) = 3 (A1 , . . . , )398fiDecoupling Lifted Variable Elimination Constraint LanguageNote 3 function N + 1 binary variables, tabular representation 2N +1entries, makes cost elimination O(2N +1 ). Substituting computed 3Equation (8) yields:Pr(S)=XA1 ,...,ANN!1 (Ai , S)i=13 (A1 , . . . , )multiply 3 (A1 , . . . , ) 1 (A1 , S) sum A1 , multiply result1 (A2 , S) sum A2 , on, obtain factor 4 (S):(S) = 4 (S)Prinvolves N multiplications summations exponential complexity.summary, variable elimination computes result O(2N +1 ).elimination order also symmetries lifted inference exploit. Let usexamine 3 (T, A1 , . . . , ), product factors 2 (T, Ai ). assignment =(A1 , . . . , ) = (a1 , . . . ) {true, f alse}N :3 (t, a1 , . . . , ) = 2 (t, a1 ) . . . 2 (t, )Note that, since ai {true, f alse}, multiplicands right hand sideone two values, 2 (t, true) 2 (t, f alse). is, ai = true2 (t, true), similarly ai = f alse, 2 (t, f alse). means that,= {Ai |ai = true} Af = {Ai |ai = f alse}, rewrite expression as:3 (t, a1 , . . . , ) =2 (t, true)ai2 (t, f alse) = 2 (t, true)|At | 2 (t, f alse)|Af | .ai Afshows evaluate 3 (T, A1 , . . . , ) suffices know many Ai true (callnumber nt ) false (nf ); need know value individual Ai .therefore restate 3 terms new variable #[A], called counting variable, valuetwo-dimensional vector (nt , nf ). Generally, #[A] take value (x, y)x, N x + = N . call value histogram. captures distributionvalues among = {A1 , . . . , }. reformulation factor terms countingvariable called counting conversion. Rewriting 3 (T, A1 , . . . , ) 3 (T, #[A]),3 (t, (nt , nf )) = 2 (t, true)nt 2 (t, f alse)nf .3 2(N + 1) possible input combinations (two values N + 1 values (nt , nf ),since nt +nf = N ). tabulated time O(N ), using recursive formula 3 (t, (nt +1, nf 1)) = 3 (t, (nt , nf )) 1 (t, true)/2 (t, f alse). Note VEs computation 3O(2N ).3 2(N +1) possible input states, instead 2N +1 , eliminateO(N ):NXXY2 (T, Ai ) =3 (T, #[A]) = 3 (#[A])i=1399fiTaghipour, Fierens, Davis, & BlockeelUsing result, continue elimination:(S) =PrXN1 (Ai , S) 3 (#[A])A1 ,...,AN i=1Using counting conversion second time, reformulate result4 (#[A], S), gives:(S) =PrX4 (#[A], S) 3 (#[A]) =A1 ,...,ANXQNi=1 1 (Ai , S)43 (#[A], S)(9)A1 ,...,ANitself, final summation still enumerates 2N joint states variables A, computeshistogram (nt , nf ) 43 ((nt , nf ), S) state, adds 43 .better: states result histogram (nt , nf ) value43 ((nt , nf ), S), know exactly many joint states are, namely nNt =N!nt !nf ! . call multiplicity histogram (nt , nf ), denoted Mul((nt , nf )).Thus, compute 43 ((nt , nf ), S) histogram (nt , nf ) multiplymultiplicity:X43 (#[A], S) =A1 ,...,ANXMul(#[A]) 43 (#[A], S)#[A]way enumerate N + 1 possible values #[A] instead 2N possible statesA. summarize, reformulate Equation (9)(S) =PrX43 (#[A], S) =A1 ,...,ANXMul(#[A]) 43 (#[A], S) = 5 (S)#[A]shows #[A] eliminated O(N ) operations.(S) thus complexity O(N ), instead O(2N )whole computation Prelimination order. reduction complexity possible due symmetriesmodel allow us treat variables one unit #[A].2.5 Capturing Symmetriesclear lifting yield important speedups, certain symmetries among factorsamong inputs single factor present. exploit these, essential oneindicate variables interchangeable hence induce symmetries.workshop example, assume, instance, every personpreferences respect topics, two types people, different potentials(2a 2b ) associated type person. clear instead Formula 7,XXA1N1 (A1 , S)2 (T, A1 ) ,400fiDecoupling Lifted Variable Elimination Constraint Languageneed computeNaNbX XX1 (Ak , S)2a (T, Ak )1 (Al , S)2b (T, Al )AkAlAk Al random members first second group, Na Nbcardinality groups. order this, need able state Ai2a relevant, 2b is. (For particular computation, actually sufficesknow size group, true general; instance, computemarginal distribution A5 , need know group A5 in.)main contribution related particular point. time writing,C-FOVE system (Milch et al., 2008) considered state art lifted variable elimination. introducing counting variables, capture within-factor symmetries betterpredecessor, FOVE. However, turns out, C-FOVE less good capturingsymmetries among multiple factors, compared FOVE. groups variablesfactors defined means constraints, C-FOVE uses constraint languagelimited FOVEs; essentially, allows conjunctive constraints.two reasons important able group variables muchflexibility possible. First, gives flexibility user specifygraphical model itself. Second, inference, may become necessary splitgroups subgroups.cannot go detail constraint based representation point (welater), basically, lifted inference, one may set interchangeablevariables could principle treated one group, systemcannot represent group. needs partition group smaller groups,possibly level individuals. instance, assume groups example{A1 , A2 , A5 , A6 , A7 } {A3 , A4 , A8 }. assume constraint languagesets variables Ai defined using constraints form {Ai |l u}.Neither group represented using one single constraint. instance, first groupconsists union {Ai |1 2} {Ai |5 7}. Using constraint language,get four groups size 2, 3, 2 1 instead two groups size 5 3. result,computation actually performed contain four exponentiated factors instead two:32XXX1 (A5 , S)2a (T, A5 )1 (A1 , S)2a (T, A1 )A5A112XX1 (A8 , S)2b (T, A8 )1 (A3 , S)2b (T, A3 )A8A3Generally, lifted inference, groups may split repeatedly. Unnecessary splitssubstantially hurt efficiency, one causes duplication work. Since duplicatedwork may include splitting, overall effect exponential numberconsecutive splits.Ideally, constraint language property group variables,exists constraint represents exactly group variables. case,401fiTaghipour, Fierens, Davis, & Blockeelnever necessary split group subgroups group cannot represented.call language extensionally complete. main contribution articleshows perform lifted variable elimination extensionally completeconstraint language. aim, first, lifted variable elimination algorithm definedway independent constraint representation mechanism, definingoperators terms relational algebra expressions. call algorithm GC-FOVE.make GC-FOVE operational, kind constraint representation mechanism courseneeded. constraint language L plugged GC-FOVE, long closedrespect relational algebra operators used GC-FOVE. Second, proposeextensionally complete constraint representation language based trees.language necessarily closed respect relational algebra operators, thereforesuitable GC-FOVE. resulting system, GC-FOVETREES , perform inferencehigher level granularity, therefore efficiently, C-FOVE,use extensionally complete constraint language. effect visible particularevidence given (which breaks symmetries hence causes group splitting);cases, GC-FOVE achieves exponential speedups compared C-FOVE.ends informal introduction lifted variable elimination main contribution articles makes it. following sections, first introduce formal notationterminology, present contributions detail.3. RepresentationLifted inference exploits symmetries probabilistic model. symmetries often occurmodels repeating structures, plates (Getoor & Taskar, 2007, Ch. 7),or, generally, probabilistic-logical models. Probabilistic-logical modeling languages(also called probabilistic-relational languages) combine representational inferentialaspects first-order logic probability theory.First-order logic languages refer objects (possibly various types) universe,properties of, relationships between, objects. Formulas languagesexpress property holds particular object, entire set objects.instance, fact humans mortal could written x : Human(x)ortal(x). Probabilistic-logical models can, similar way, express probabilistic knowledge objects. instance, could state human, priorprobability 20% smokes: x : P (Smokes(x)|Human(x)) = 0.2.ability make (probabilistic) statements entire sets objects allowslanguages compactly express symmetries model. Many different languages existrepresenting probabilistic-logical models (e.g., see Getoor & Taskar, 2007). use representation formalism based undirected graphical models closely related oneused earlier work lifted variable elimination (Poole, 2003; de Salvo Braz, 2007; Milchet al., 2008).concepts introduced section also introduced earlier work (deSalvo Braz, 2007; Milch et al., 2008). Differences arise terminology notationemphasize constraint part.402fiDecoupling Lifted Variable Elimination Constraint Language3.1 Constraint-based Representation Formalismundirected model factorization joint distribution set random variables (Kschischang et al., 2001). Given set random variables X = {X1 , X2 , . . . , Xn },factor consists potential function assignment random variableinputs. instance, factorization f (X1 , X2 , X3 ) = (X1 , X2 )(X2 , X3 ) containstwo different factors (even potential functions same).Likewise, probabilistic-logical representation framework, model set factors. random variables operate properties of, relationships between,objects universe. introduce terminology make concrete.assume familiarity set relational algebra (union , intersection , difference\, set partitioning, selection C , projection X , attribute renaming , join ); see,instance, work Ramakrishnan Gehrke (2003).term variable used logical probabilistic context.avoid confusion, use term logvar refer logical variables, randvar referrandom variables. write variable names uppercase, values lowercase. Setssequences logvars written boldface, sets sequences randvars calligraphic;values written boldface lowercase.vocabulary representation includes finite set predicates finite setconstants. constant represents object universe. term either constantlogvar. predicate P arity n finite range (range(P )); interpretedmapping n-tuples objects (constants) range. atom formP (t1 , t2 , . . . , tn ), ti terms. ground atom atom ti constants.ground atom represents random variable; implies interpretation, elementrange(P ), corresponds assignment value random variable. Hence,range predicate corresponds range random variables represent,limited {true, f alse} logic.Logvars finite domain, set constants. domain logvarX denoted D(X). constraint relation defined set logvars, i.e.,pair (X, CX ), X = (X1 , X2 , . . . , Xn ) tuple logvars, CX subsetD(X) = D(Xi ) (Dechter, 2003). Hence, CX set, whose elements (tuples) indicateallowed combinations value assignments variables X. ease exposition,identify constraint relation CX , write C instead CX X apparentcontext. assume implicit ordering values CX tuples accordingorder logvars X. instance X = (X1 , X2 ), constraint CX = {(a, b), (c, d)}indicates two possibilities: either X1 = X2 = b, X1 = c X2 = d.constraint contains one tuple called singleton.constraint may defined extensionally, listing tuples satisfy it, intensionally, means logical condition, expressed constraint language. callconstraint language L extensionally complete express relation logvars X,i.e., subset D(X), constraint CX L whose extension exactlysubset.constrained atom form P (X)|C, P (X) atom C constraintX. constrained atom P (X)|C represents set ground atoms {P (x)|x C},hence set randvars. consistency literature, call constrained atom403fiTaghipour, Fierens, Davis, & Blockeelparametrized randvar (PRV), use calligraphic notation denote it. Given PRV V,use RV (V) denote set randvars represents; also say randvarscovered V.valuation randvar (set randvars) assignment value randvar(an assignment values randvars set).Example 1. PRV V = Smokes(X)|C, C = {x1 , . . . , xn }, represents n randvars{Smokes(x1 ), . . . Smokes(xn )}.factor f = f (Af ) consists sequence randvars Af = (A1 , . . . , )potential function f : ni=1 range(Ai ) R+ . product two factors, f1 f2 ,defined follows. Factor f = (A) product f1 = 1 (A1 ) f2 = 2 (A2 )(a) = ai= A1 A2 D(A): (a) = 1 (a1 )2 (a2 ) AiQ= 1, 2. is, assigns randvar Ai value ai . usedenotemultiplication multiple factors. Multiplying factor scalar c means replacingpotential : x 7 c (x).undirectedmodel set factors F . representsprobability distribution PF1 Q(Arandvars = Pfollows:P(A)=Ff ), Z normalizationff F ff FZconstant arange(A) PF (a) = 1.parametric factor parfactor form (A)|C, = {Ai }ni=1 sequenceatoms, potential function A, C constraint logvars appearing A.1set logvars occurring denoted logvar(A); set logvars C denotedlogvar(C). factor (A ) grounding parfactor (A) obtainedinstantiating X = logvar(A) x C. set groundings parfactor gdenoted gr(g).Example 2. Parfactor g1 = 1 (Smokes(X))|X {x1 , . . . , xn } represents set factorsgr(g1 ) = {1 (Smokes(x1 )), . . . , 1 (Smokes(xn ))}.set parfactors G compact way defining set factorsQ F = {f |f gr(g)gG} corresponding probability distribution PG (A) = Z1 f F f (Af ).3.2 Counting FormulasMilch et al. (2008) introduced idea counting formulas (parametrized) countingrandvars.counting formula syntactic construct form #Xi C [P (X)], Xi Xcalled counted logvar.grounded counting formula counting formula arguments atomP (X), except counted logvar, constants. defines counting randvar (CRV),meaning follows. First, define set randvars coversRV (#XC [P (X)]) = RV (P (X)|X C). value CRV determined valuesrandvars covers. specifically, histogram indicates, given valuation RV (P (X)|X C), many different values X occur r range(P ).Thus, value form {(r1 , n1 ), (r2 , n2 ), . . . , (rk , nk )}, ri range(P ) ni1. use definition Kisynski Poole (2009a) parfactors, allows us simplify notation.404fiDecoupling Lifted Variable Elimination Constraint Languagecorresponding count. Given histogram h, also write h(v) count v h.Note range CRV, i.e., set possible histograms take value,determined k = |range(P )| |C|.Example 3. #X{x1 ,x2 ,x3 } [P (X, y, z)] grounded counting formula. covers rand-vars P (x1 , y, z), P (x2 , y, z) P (x3 , y, z). defines CRV, value determined values three randvars; P (x1 , y, z) = true, P (x2 , y, z) = f alseP (x3 , y, z) = true, CRV takes value {(true, 2), (f alse, 1)}.concept CRV somewhat complicated. CRV behaves like regular randvarways, all. construct occur argument factor, likeregular randvars, role actually stands set randvars,arguments factor. factor form ( , #XC [P (X)], ) equivalentfactor form ( , P (X1 ), P (X2 ), . . . , P (Xk ), ), P (Xi ) instantiationsX obtainable instantiating X value C, returningvaluation P (Xi ) value returns corresponding histogram.Example 4. factor (#X{x1 ,x2 ,x3 } [P (X, y, z)]) equivalent factor(P (x1 , y, z), P (x2 , y, z), P (x3 , y, z)). ({(true, 2), (f alse, 1)}) = 0.3, implies(f alse, true, true) = (true, f alse, true) = (true, true, f alse) = 0.3.illustrated Section 2.4, counting formulas useful capturing symmetrieswithin potential function. Recall workshop example. Whether person attendsworkshop depends topic, dependence person.represent single parfactor (T, A(X))|X {x1 , . . . , xn } representsn ground factors. Eliminating requires multiplying n factors single factor(T, A(x1 ), A(x2 ), . . . , A(xn )) summing . potential function highdimensional, tabular representation would costly. However, containscertain symmetry: depends many times possible value A(xi ) occurs,exactly occur. representing factor using potential functiontwo arguments, CRV #X{x1 ,...,xn} [A(X)], representedconcisely, computed efficiently. instance, sum A(X),need enumerate possible (2n ) value combinations A(xi ) sum corresponding (T, A(x1 ), . . . , A(xn )), need enumerate possible (n + 1) valueshistogram #X{x1 ,...,xn } [A(X)] sum corresponding (T, #X{x1 ,...,xn } [A(X)]),multiplied multiplicity.Note complementarity PRVs CRVs. randvars coveredPRV occur different factors, randvars covered CRV occur onefactor. Thus, PRVs impose symmetry among different factors, whereas CRVs imposesymmetry within single factor.parametrized counting randvar (PCRV) form #X [P (X)] |CX . notationwrite constraint counted logvar X part constraint CX variablesX. Similar way PRV defines set randvars groundings,PCRV defines set CRVs groundings variables X \ {X}.Example 5. #Y [F riend(X, )] |C represents set CRVs, one x X (C),indicating number friends x has. C = D(X) D(Y ) D(X) = D(Y ) =405fiTaghipour, Fierens, Davis, & Blockeel{ann, bob, carl}, might instance #Y [F riend(ann, )]|C = {(true, 1), (f alse, 2)}(Ann one friend, two people friends her).definitions previous section need extended slightly orderaccommodate PCRVs. First, CRVs regular randvars, includedset randvars covered PRCV; is, RV (#Xi [P (X)]|C) = RV (P (X)|C).Second, since counting formula binds counted logvar (it longer parameterresulting PCRV), define logvar(#Xi [P (X)]) = X \ {Xi }. Thus, generally, logvar(A)refers logvars occurring A, excluding counted logvars. Note logvar(C)remains unchanged: refers logvars C, whether appear counted not.end section two definitions useful later on.Definition 1 (Count function) Given constraint CX , X Z XY,function CountY|Z : CX N defined follows:CountY|Z (t) = |Y (Z=Z (t) (CX ))|is, tuple t, function tells us many values co-occur ts valueZ constraint. define CountY|Z (t) = 1 = .Definition 2 (Count-normalized constraint) constraint CX , X ZX Y, count-normalized w.r.t. Z CXn N : CX : CountY|Z (t) = n.n exists, call conditional count given Z CX , denoteCountY|Z (CX ).Example 6. Let X {P, C} let constraint CX (P, C) {(ann, eric), (bob, eric),(carl, f inn), (debbie, f inn), (carl, gemma), (debbie, gemma)}. Suppose CX indicates parent relationship: Ann parent Eric, etc. {P } count-normalized w.r.t. {C}children (i.e., instantiations C CX : Eric, Finn Gemma) two parents according CX , formally, tuples CX holds Count{P }|{C} (t) = 2.Conversely, {C} count-normalized w.r.t. {P } parents equallymany children. instance, Count{C}|{P } ((ann, eric)) = 1 (Ann 1 child),Count{C}|{P } ((carl, f inn)) = 2 (Carl 2 children).4. GC-FOVE Algorithm: Outlineturn problem performing lifted inference models specified usingrepresentation. algorithm introduce called GC-FOVE (for Generalized C-FOVE). high level, similar C-FOVE (Milch et al., 2008), currentstate-of-the-art system lifted variable elimination, differs definitionimplementation operators.Recall standard variable elimination works. eliminates randvars one one,particular order called elimination order. Elimination consist multiplying factorsrandvar occurs one factor, summing randvar.406fiDecoupling Lifted Variable Elimination Constraint LanguageSimilarly, GC-FOVE visits PRVs (as opposed individual randvars) particularorder. Ideally, eliminates PRV multiplying parfactors occursone parfactor, summing PRV, using lifted multiplication liftedsumming-out operators. However, operators always immediately applicable:may necessary refine involved parfactors PRVs make so.done using operators, call enabling operators.2high-level description GC-FOVE shown Algorithm 1. Like C-FOVE, makesuse number operators, repeatedly selects performs one possibleoperators one parfactors. uses greedy heuristic C-FOVEselection, choosing operation minimum cost, cost operationdefined total size (number rows tabular form) potentials creates.main difference C-FOVE GC-FOVE operators used. FourGC-FOVEs operators (multiply, sum-out, count-convert ground-logvar)straightforward generalization similar operator C-FOVE, differenceprovide definitions work constraint representation language closedrelational algebra, instead definitions specific constraint languageused C-FOVE. Three operators (expand, count-normalize split) alsocounterparts C-FOVE, need redefined substantially directlyconcern constraint manipulation. lifted absorption operator (absorb) completelynew.GC-FOVE specify particular constraint language. practice, constraints represented one way another, constraint representation mechanism plugged in. article, propose tree-based representation mechanismconstraints. Important advantages mechanism that, one hand,extensional set represented trees, hand, constraintsstill manipulated efficiently.generalization operators, new absorption operator, tree-basedconstraint language main contributions paper. Together, greatly improveefficiency inference, clear experimental section. describing operators detail, illustrate importance using expressive constraintlanguage.4.1 Constraint LanguageC-FOVE, constraint set pairwise (in)equalities single logvarconstant, two logvars. Thus, single parfactor, C-FOVE represent, instance, F riend(X, )|X 6= ann, F riend(X, )|(X, ) {(ann, bob), (bob, carl)}).Table 1 provides examples PRVs C-FOVE can/cannot represent,Figure 3 illustrates visually. Basically, C-FOVE use conjunctive constraints,disjunctive ones, C-FOVEs operators defined operate directly representation. GC-FOVE, hand, allows constraint relationlogvars, therefore handle PRVs. restrictions whatsoeverregarding constraints handle, maximally exploit opportunities lifting.2. Technically speaking, multiplication also enabling operator summing-out appliedmultiplication.407fiTaghipour, Fierens, Davis, & BlockeelGC-FOVEInputs:G: modelQ: query randvarAlgorithm:G contains randvars Q:PRV V eliminated lifted absorptionG apply operator absorb eliminate V Gelse PRV V eliminated lifted summing-outG apply sum-out eliminate V Gelse apply enabling operator (one multiply, count-convert, expand,count-normalize, split ground-logvar) parfactors Gendreturn GAlgorithm 1: Outline GC-FOVE algorithm.PRVF riend(X, )F riend(ann, )F riend(X, )|X 6= annF riend(X, )|X {ann, bob}F riend(X, )|(X, ) {(ann, bob), (bob, carl)})C-FOVEyesyesyesyesGC-FOVEyesyesyesyesyesTable 1: Examples parametrized random variables / cannot represented usingsingle constraint C-FOVE. Though fourth constraint (yes ) disjunctive,C-FOVE represent using conjunction inequality constraints.case fifth constraint. GC-FOVE represent constraints.expressiveness constraint representation language, way constraints handled operators, crucial efficiency lifted variable elimination. reason variables continuously need re-grouped (i.e., constraints needrewritten) inference. instance, multiply 1 (P (X))|{x1 , x2 , x3 }2 (P (X))|{x1 , x2 , x3 } directly, resulting parfactor form 12 (P (X))|{x1 , x2 , x3 },cannot multiply 1 (P (X))|{x1 , x2 , x3 } 2 (P (X))|{x2 , x3 , x4 , x5 } singleparfactor PRVs match. solution split constraints parfactors matching parfactors arise. particular case, model three parfactorsarises: 1 (P (x1 )), 12 (P (X))|{x2 , x3 } 2 (P (X))|{x4 , x5 }. GC-FOVEs operations result model. C-FOVE, however, splitting constraints, separates one tupletime (splitting based substitution, Milch et al., 2008), results four parfactors: 1 (P (x1 )); 12 (P (X))|X 6= x1 , X 6= x4 , X 6= x5 ; 2 (P (x4 )); 2 (P (x5 )) (assumingdomain X {x1 , x2 , . . . , x5 }). case, C-FOVE could fact represent separate factors 2 (P (x4 )) 2 (P (x5 )) one parfactor 2 (P (X))|X 6= x1 , X 6= x2 , X 6= x3 ,(only intersection two constraints kept lifted level),408fiDecoupling Lifted Variable Elimination Constraint Languagebcefbcefb c e fbcefbcefb c e fbcefb c e fb c e fbcefb c e fb c e fFigure 3: schema, gray area indicates PRV form F riend(X, )|CXY(with standing ann, b bob, etc.) C-FOVE handle PRVsdefined conjunctive constraints; includes top three schemas,bottom ones. GC-FOVE handle PRVs.general, non-unary predicates, possible, Table 1 shows.restricted constraint language, C-FOVE often create finer-grained partitionsnecessary. GC-FOVE, uses extensionally complete constraint language,suffer problem.4.2 Lifted AbsorptionAbsorption (van der Gaag, 1996) additional operator known increaseefficiency. consists removing random variable model valuationknown, rewriting model equivalent one contain variable.C-FOVE, like predecessors, use absorption, including might factdetrimental effects due breaking symmetries. GC-FOVEs extensionally completeconstraint language, however, makes possible use absorption effectively,even allows lifting it.4.3 Summary Contributionspoint summarize contributions work precisely.1. present first description lifted variable elimination decouples liftedinference algorithm constraint representation uses. done takingC-FOVE algorithm redefining operators become independentunderlying constraint mechanism. achieved defining operators409fiTaghipour, Fierens, Davis, & Blockeelterms relational algebra operators. redefinition generalizes operatorsclarifies higher level work.2. present mechanism representing constraints extensionally complete.closed relational algebra operators, allows executingefficiently. itself, minor contribution, necessary order obtainoperational system.3. present new operator, called lifted absorption.4. experimentally demonstrate practical impact contributions.5. contribute software itself.Contributions 1 3 (our main contributions) subject Section 5. Contribution 2 detailed Section 6, Contribution 4 Section 7. Contribution 5http://dtai.cs.kuleuven.be/ml/systems/gc-fove.5. GC-FOVEs Operatorssection provides detailed information GC-FOVEs operators. conceptually split two categories: operators manipulate potential functions,operators refine model first type operators applied.start three operators belong first category: lifted multiplication, liftedsumming-out counting conversion. seen generalized versionscorresponding C-FOVE operators; algorithmically, similar. Next, discuss splitting, shattering, expansion, count normalization. operate specificallyconstraints, differ strongly C-FOVEs operators. systematically compare latter, showing time C-FOVEs constraint languageoperators force create fine-grained models necessary, GC-FOVE,extensionally complete constraint language, always avoid this: whateverset interchangeable randvars is, set represented one constraint. Finally,discuss lifted absorption, completely new, grounding, similarC-FOVE counterpart.following, G refers model (i.e., set parfactors), G1 G2 meansmodels G1 G2 define probability distribution.5.1 Lifted Multiplicationlifted multiplication operator multiplies whole parfactors once, instead separately multiplying ground factors cover (Poole, 2003; de Salvo Braz, 2007; Milchet al., 2008). Figure 4 illustrates two parfactors g1 = 1 (S(X))|C g2 =2 (S(X), A(X))|C, C = (X {x1 , . . . , xn }). Lifted multiplication equivalentn multiplications ground level.illustration deceptively simple, several reasons. First, naminglogvars suggests logvar X g1 corresponds X g2 . fact, g2 couldmultiple logvars, different names. alignment parfactors necessary,showing logvars different parfactors correspond (de Salvo Braz, 2007).410fiDecoupling Lifted Variable Elimination Constraint Language1 (S(X))1 (S(x1 ))2 (S(X), A(X))2 (S(x1 ), A(x1 ))S(x1 )13 (S(x1 ), A(x1 ))...Multiplications2 (S(xn ), A(xn ))23 (S(X), A(X))Ground......1 (S(xn ))LiftedMultiplication3 (S(xn ), A(xn ))A(x1 )S(x1 )3A(x1 )3A(xn )...1GroundMultiplications...S(xn )2A(xn )S(xn )Figure 4: Lifted Multiplication 1:1 alignment parfactors. equivalentlifted operation (top), shown level ground factors (middle),also terms factor graphs (bottom). denotes (par)factor multiplication.alignment must constrain aligned logvars exactly values g1g2 (otherwise, cannot give identical PRVs parfactors). formalizefollows.Definition 3 (substitution) substitution = {X1 t1 , . . . , Xn tn } = {Xt} maps logvar Xi term ti , constant logvar. ticonstants, called grounding substitution, different logvars,renaming substitution. Applying substitution expression means replacingoccurrence Xi ti ; result denoted .Definition 4 (alignment) alignment two parfactors g = (A)|C g =(A )|C one-to-one substitution {X X }, X logvar(A) X logvar(A ),(X (C)) = X (C ) (with attribute renaming operator).alignment tells multiplication operator two atoms two different parfactorsrepresent PRV, suffices include resulting parfactor once.Including twice wrong, less efficient: structure parfactorlost. reason, useful look maximal alignments map manyPRVs possible.Example 7. Consider g1 = 1 (S(X), F (X, ))|CX,Y g2 = 2 (S(X ), F (X , ))|CX ,YCX,Y = CX ,Y = {xi }n1 {yj }m1 . Using maximal alignment {X X ,411fiTaghipour, Fierens, Davis, & Blockeel)}, get product parfactor 3 (S(X), F (X, ))|CX,Y . alignment establishes1:1 association ground factor 1 (S(xi ), F (xi , yj )) corresponding2 (S(xi ), F (xi , yj )). If, however, multiply g1 g2 alignment {X X },result parfactor 3 (S(X), F (X, ), F (X, ))|(X, Y, ) {xi }n1 {yj }m1 {yk }1 ,xi unnecessarily multiplies factor 1 (S(xi ), F (xi , yj )) factors2 (S(xi ), F (xi , yk )), k = 1, . . . , m. words, unnecessarily creates direct dependency pairs randvars F (xi , yj ), F (xi , yk ).second complication single randvar may participate multiple factors withincertain parfactor, number factors appears may differ across parfactors. Consider parfactors g1 = 1 (S(X))|X {xi }n1 g2 = 2 (S(X), F (X, ))|(X, ){xi }n1 {yi }m1 . xi , 1 (S(xi )) shares randvar S(xi ) factors 2 (S(xi ), F (xi , yj )),j = 1, . . . , m. Multiplication result single parfactor 3 (S(xi ), F (xi , ))|Y{yi }m1 covers factors 3 (S(xi ), F (xi , yj )), equivalent product onefactor 1 (S(xi )) factorsQ2 (S(xi ), F (xi , yj )). means must find 31/m (v, w).v, w : 3 (v, w)m = 1 (v)2i=1 2 (v, w). gives 3 (v, w) = 1 (v)exponentiation 1 power 1/m called scaling. result multiplicationsingle xi regardless xi , finally, product parfactors g1g2 parfactor3 (S(X), F (X, )) = 1 (S(X))1/m 2 (S(X), F (X, )) | (X, ) {xi }n1 {yj }m1 .Figure 5 illustrates multiplication graphically.alignment parfactors called 1 : 1 non-counted logvars parfactorsmapped other, called m:n otherwise. Multiplication based m:nalignment involves scaling, requires non-aligned logvars count-normalized(Definition 2, p. 406) respect aligned logvars constraints (otherwisesingle scaling exponent valid whole parfactor).Operator 1 formally defines lifted multiplication. Note definitionassume specific format constraints.5.2 Lifted Summing-OutPRV occurs one parfactor, summed parfactor (Milchet al., 2008). begin example lifted summing-out, help motivateformal definition operator.Example 8. Consider parfactor g = (S(X), F (X, ))|C, C = {(xi , yi,j ) :{1, . . . , n}, j {1, . . . , m}} (Figure 6). Note count-normalized w.r.t X C. Assume want sum randvars F (xi , yi,j ) RV (F (X, )|C) ground level.randvar F (xi , yi,j ) appears exactly one ground factor (S(xi ), F (xi , yi,j )) (see Figure 6(middle)). therefore sumP F (xi , yi,j ) factor independentlyothers, obtaining factor (S(xi )) = F (xi ,yi,j ) (S(xi ), F (xi , yi,j )). Since groundfactors (S(xi ), F (xi , yi,j )) potential , summing second argumentalways results potential , compute and, instead storing copies resulting factor (S(xi )), store single factor (S(xi )) = (S(xi ))m .end, obtain n factors, one S(xi ), = 1, . . . , n. represent412fiDecoupling Lifted Variable Elimination Constraint Language1 (S(X))1 (S(x1 ))...2 (S(X), F (X, ))i=1Lifted1 (S(X))1/m 2 (S(X), F (X, ))1/m2 (S(x1 ), F (x1 , y1 ))1 (S(x1 ))Scaling 1......2 (S(x1 ), F (x1 , ym ))1 (S(x1 ))1/m1/m1 (S(xn ))2 (S(xn ), F (xn , y1 ))..Scaling 1....1 (S(xn ))1/m2 (S(xn ), F (xn , ym ))2S(x1 )...21/m1F (x1 , y1 )Scaling 1F (x1 , ym )Multiplications3 (S(X), F (X, ))3 (S(x1 ), F (x1 , y1 ))...3 (S(x1 ), F (x1 , ym ))2 (S(x1 ), F (x1 , y1 ))...2 (S(x1 ), F (x1 , ym ))Ground...1/m1S(x1 )2 (S(xn ), F (xn , y1 ))3 (S(xn ), F (xn , y1 ))......3 (S(xn ), F (xn , ym ))2 (S(xn ), F (xn , ym ))2...2F (x1 , y1 )S(x1 )F (x1 , ym )......21!mMultiplications1 (S(xn ))1Scaling 1S(xn )...2Scaling 1F (xn , ym )...3F (x1 , ym )3F (xn , y1 )...3F (xn , ym )GroundMultiplications1/mF (x1 , y1 )1F (xn , y1 )3...1/m1S(xn )2...2F (xn , y1 )S(xn )F (xn , ym )Figure 5: Lifted Multiplication m:n alignment parfactors. equivalentlifted operation (top), shown level ground factors (middle),also terms factor graphs (bottom).result using single parfactor g = (S(X))|C , C = {x1 , . . . , xn } = X (C).Lifted summing-out directly computes g g one operation. Notesingle exponent , must count-normalized w.r.t. X C.Like C-FOVE counterpart, lifted summing-out operator requires one-to-onemapping summed-out randvars factors; is, summed-out randvarappears exactly one factor, factors different. guaranteedeliminated atom contains logvars parfactor, since differentground factor instantiation logvars. Further, lifted summing-out may resultidentical factors ground level, exploited computing one factorexponentiating. case logvar occurs eliminatedatom, atoms (such F (X, ) example).already illustrated Section 2.4, counting randvars require special attentionlifted summing-out. formula like (#X [P (X)])|X {x1 , . . . , xk } really shorthandfactor (P (x1 ), P (x2 ), . . . , P (xk )) whose value depends many argumentstake particular values. principle, need sum combinations valuesP (Xi ). replace summing values #X [P (X)], conditiontake multiplicities latter account. multiplicity histogram413fiTaghipour, Fierens, Davis, & BlockeelOperator multiplyInputs:(1) g1 = 1 (A1 )|C1 : parfactor G(2) g2 = 2 (A2 )|C2 : parfactor G(3) = {X1 X2 }: alignment g1 g2Preconditions:(1) = 1, 2: Yi = logvar(Ai ) \ Xi count-normalized w.r.t. Xi CiOutput: (A)|C,(1) C = (C1 ) C2 .(2) = A1 A2 ,(3) valuation A, a1 = A1 (a) a2 = A2 (a) :1/r1/r(a) = 1 2 (a1 ) 2 1 (a2 ), ri = CountYi |Xi (Ci )Postcondition: G G \ {g1 , g2 } {multiply(g1 , g2 , )}Operator 1: Lifted multiplication. definition assumes, without loss generality,logvars parfactors standardized apart, i.e., two parfactors sharevariable names (this always achieved renaming logvars).h = {(r1 , n1 ), (r2 , n2 ), . . . , (rk , nk )} multinomial coefficient, definedMul(h) = Qkn!i=1 ni !.multiplicities taken account (P)CRVs, never regular PRVs,define PRV value v range(A): Mul(A, v) = 1 regularPRV, Mul(A, v) = Mul(v) PCRV. Mul function identical Milchet al.s (2008) num-assign.mind, formal definition lifted summing-out Operator 2mostly self-explanatory. Precondition (1) ensures randvars summed-outP(C)RV occur exclusively parfactor. Precondition (2) ensures summedrandvar occurs exactly one, separate, ground factor. Precondition (3) ensureslogvars occurring exclusively eliminated PRV count-normalized respectlogvars PRV, one unique exponent exponentiation.5.3 Counting ConversionCounting randvars may present original model, also introducedparfactors operation called counting conversion (Milch et al., 2008) (see alsoSection 2.4). see useful, consider parfactor g = (S(X), F (X, ))|C,C = {xi }ni=1 {yj }mj=1 , assume want eliminate S(X)|C. that, first needmake sure S(xi ) occurs one factor. ground level, achievedgiven S(xi ) multiplying factors (S(xi ), F (xQ, yj )) occurs. resultssingle factor (S(xi ), F (xi , y1 ), . . . , F (xi , ym )) = j (S(xi ), F (xi , yj )) (see Figure 7).high-dimensional factor, equals product identical potentials ,F (xi , yj ) arguments mutually interchangeable: matters often valuesv1 , v2 , . . . occur among them, occur. exactly kind symmetry414fiDecoupling Lifted Variable Elimination Constraint Language(S(X), F (X, ))(S(x1 ), F (x1 , y1 ))...(S(x1 ), F (x1 , ym ))...(S(xn ), F (xn , y1 ))...(S(xn ), F (xn , ym ))S(x1 )PRV (F (X,Y ))PF (x ,y )11...PF (x ,ym )1PF (xn ,y )1...PF (xn ,ym )...F (x1 , ym ) P(S(X))(S(x1 ))...(S(x1 ))(S(xn ))...(S(xn ))S(x1 )F (x ,ym )1F (xn , y1 ) P...F (xn , ym ) P......(S(xn ))mS(x1 )( )mS(xn )( )m...F (xn ,y1 )...(S(X))m(S(x1 ))m......Exponentiate1 ,y1 )...S(xn )i=1F (x1 , y1 ) PF (x...!mS(xn )F (xn ,ym )...Figure 6: Lifted summing-out. equivalent lifted operation (top), shownlevel ground factors (middle), also terms factor graphs (bottom).CRVs aim exploit. factor (S(xi ), F (xi , y1 ), . . . , F (xi , ym )) thereforereplaced two-dimensional (S(xi ), h) h histogram indicates oftenpossible value range F (xi , yj ) occurs. Thus, introducing CRV, definetwo-dimensional CRV argument, opposed high-dimensional. argued Section 2.4, reduces size potential function, hencecomputational complexity, exponentially.many situations lifted elimination cannot immediately applied, countingconversion makes applicable. conditions sum-out operator (Section 5.2) stateatom Ai eliminated parfactor g Ai logvarsg. atom fewer logvars parfactor, counting conversion modifiesparfactor replacing another atom Aj counting formula, removes countedlogvar logvar(A). instance, example, S(X) logvarg = (S(X), F (X, ))|C cannot eliminated original parfactor g,counting conversion replaces F (X, ) #Y [F (X, )], allowing us sumS(X) new parfactor g = (S(X), #Y [F (X, )])|C.415fiTaghipour, Fierens, Davis, & BlockeelOperator sum-outInputs:(1) g = (A)|C: parfactor G(2) Ai : atom A, summed g1Preconditions(1) PRVs V, Ai |C, model G: RV (V) RV (Ai |C) =(2) Ai contains logvars X logvar(A) X (C) singleton.(3) Xexcl = logvar(Ai ) \ logvar(A \ Ai ) count-normalized w.r.t.Xcom = logvar(Ai ) logvar(A \ Ai ) COutput: (A )|C ,(1) = \ Ai(2) C = X com (C)(3) assignment = (. . . , ai1 , ai+1 , . . . ) ,P(. . . , ai1 , ai+1 , . . . ) = ai range(Ai ) Mul(Ai , ai ) (. . . , ai1 , ai , ai+1 , . . . )rr = CountXexcl |Xcom (C)Postcondition: PG\{g}{sum-out(g,Ai )} = RV (Ai |C) PGOperator 2: lifted summing-out operator.Operator 3 formally defines counting conversion. mostly self-explanatory, apartpreconditions. Precondition 1 makes sure counting conversion, groundlevel, corresponds multiplying factors differ one randvar (i.e.,instantiation counted logvar). Precondition 2 guarantees resultinghistograms range. Precondition 3 difficult explain. imposeskind independence logvar counted already occurring countedlogvars. Though explicitly mentioned there, precondition also required CFOVEs counting operation; implies inequality constraint existX counted logvar X # . similar condition FOVEs counting eliminationmentioned de Salvo Braz (2007).see precondition 3 necessary, consider parfactor g = (S(X), #Y [A(Y )])|(X, ) {(x1 , y2 ), (x1 , y3 ), (x2 , y1 ), (x2 , y3 ), (x3 , y1 ), (x3 , y2 )}, satisfy it.parfactor represents three factors form (S(xi ), #Y [A(Y )])|Y {y1 , y2 , y3 }\{yi },contribute joint distribution product(S(x1 ), #Y {y2 ,y3 } [A(Y )]) (S(x2 ), #Y {y1 ,y3 } [A(Y )]) (S(x3 ), #Y {y1 ,y2 } [A(Y )]).Counting conversion logvar X turns g factor form(#X [S(X)], #Y [A(Y )])equivalent. Note depends #X [S(X)] #Y [A(Y )].consider valuations V1 : [S(x1 ), S(x2 ), S(x3 ), A(y1 ), A(y2 ), A(y3 )] = [t, t, f, t, t, f ]V2 : [S(x1 ), S(x2 ), S(x3 ), A(y1 ), A(y2 ), A(y3 )] = [t, t, f, t, f, t]. valuations,#X [S(X)] = (2, 1) #Y [A(Y )] = (2, 1), (#X [S(X)], #Y [A(Y )]) must returnvalue V1 V2 . original parfactor, however, returns (S(t), (1, 1))(S(t), (1, 1)) (S(f ), (2, 0)) V1 , (S(t), (1, 1)) (S(t), (2, 0)) (S(f ), (1, 1))416fiDecoupling Lifted Variable Elimination Constraint LanguageCounting Conversion(S(X), F (X, ))(S(x1 ), F (x1 , y1 ))...!(S(X), #Y [F (X, )])(S(x1 ), F (x1 , y1 ), . . . , F (x1 , ym )) = (S(x1 ), #Y [F (x1 , )])(S(x1 ), F (x1 , ym ))......(S(xn ), F (xn , y1 ))...!...(S(xn ), F (xn , y1 ), . . . , F (xn , ym )) = (S(xn ), #Y [F (xn , )])(S(xn ), F (xn , ym ))S(x1 )F (x1 , y1 )...F (x1 , ym )F (x1 , ym )S(x1 )...CountingS(x1 )F (x1 , ym )F (x1 , ym )F (x1 , ym )......S(xn )...#F (xn , y1 )...F (xn , y1 )S(xn )F (xn , ym )......F (xn , y1 )S(xn )CountingF (xn , ym )#...F (xn , ym )Figure 7: Counting conversion. equivalent lifted operation (top), shownlevel ground factors (middle), also terms factor graphs (bottom).V2 , may different. Since original parfactor distinguish valuationsfactor form (#X [S(X)], #Y [A(Y )]) can, counting conversion cannotapplied case.contrast, consider g = (S(X), #Y [A(Y )])|(X, ) {x1 , x2 , x3 } {y1 , y2 , y3 },similar g, except constraint satisfies precondition 3. three factors represented g differ first argument, randvar S(xi ); countingrandvar #Y [A(Y )]|Y {y1 , y2 , y3 } second argument (this case g).product, thus, represented parfactor (#X [S(X)], #Y [A(Y )])|(X, ){x1 , x2 , x3 } {y1 , y2 , y3 }, derived g counting conversion.5.4 Splitting Shatteringpreconditions lifted multiplication, lifted summing-out counting conversion fulfilled, necessary reformulate model terms parfactorsfulfill them. instance, g1 = 1 (S(X))|X {x1 , x2 , x3 } g2 = 2 (S(X))|X{x1 , x2 , x3 , x4 , x5 }, cannot multiply g1 g2 directly without creating unwanted de417fiTaghipour, Fierens, Davis, & BlockeelOperator count-convertInputs:(1) g = (A)|C: parfactor G(2) X: logvar logvar(A)Preconditions(1) exactly one atom Ai X logvar(Ai )(2) X count-normalized w.r.t logvar(A) \ {X} C(3) counted logvars X # g: X,X # (C) = X (C) X # (C)Output: (A )|C,(1) = \ {Ai } {Ai } Ai = #X [Ai ](2) assignment ai = h:Q(. . . , ai1 , h, ai+1 , . . . ) = ai range(Ai ) (. . . , ai1 , ai , ai+1 , . . . )h(ai )h(ai ) denoting count ai histogram hPostcondition: G G \ {g} {count-convert(g, X)}.Operator 3: counting conversion operator.pendencies. However, replace g2 g2a = 2 (S(X))|X {x1 , x2 , x3 } g2b =2 (S(X))|X {x4 , x5 }. resulting model equivalent, new model,multiply g1 g2a , resulting g3 = 3 (S(X))|X {x1 , x2 , x3 }.simple case splitting parfactors (Poole, 2003; de Salvo Braz, 2007;Milch et al., 2008). Basically, splitting two parfactors partitions parfactor partshared parfactor, part disjoint. goal rewriteP(C)RVs parfactors proper form. Two P(C)RVs (V1 , V2 ) proper RV (V1 )RV (V2 ) either identical disjoint; two parfactors proper P(C)RVsproper. pair parfactors written proper form applying followingprocedure, P(C)RVs proper. Choose P(C)RV V1 one parfactor,compare P(C)RV V2 other, rewrite first parfactor V1split two parts: one disjoint V2 one shared V2 .parfactors model made proper w.r.t. repeatedly applyingrewrite convergence. called shattering model.simpler rewrite PRV proper form PCRV. describe operator handles PRVs, namely split, section discuss operator handlesPCRVs, namely expand, following section. defining split operator,provide following auxiliary definitions, also used later on.Definition 5 (Splitting overlap) Splitting constraint C1 Y-overlap C2 ,denoted C1 /Y C2 , partitions C1 two subsets, containing tuples partoccurs occur, respectively, C2 . C1 /Y C2 = {{t C1 |Y (t) (C2 )}, {tC1 |Y (t)/ (C2 )}}.Definition 6 (Parfactor partitioning) Given parfactor g = (A)|C partitionC = {Ci }ni=1 C, partition(g, C) = {(A)|Ci }ni=1 .Operator 4 defines splitting parfactors. Note that, operator definition,simplicity, assume = = P (Y), means logvars used418fiDecoupling Lifted Variable Elimination Constraint LanguageOperator splitInputs:(1) g = (A)|C: parfactor G(2) = P (Y): atom(3) = P (Y)|C #Y [P (Y)]|COutput: partition(g, C), C = C/Y C \ {}Postcondition G G \ {g} split(g, A, )Operator 4: split operator.must same, order. always rewrite modeltwo PRVs predicate form. this, rewrite parfactorsfollows: (i) parfactors share logvars, first standardize apart logvars twoparfactors, (ii) linearize atom logvar occurs once, i.e., rewritedistinct logvar argument, (iii) apply renaming substitutionlogvars concerned atoms logvars. instance, considertwo parfactors g1 = 1 (P (X, X))|X C1 g2 = 2 (P (Y, Z))|(Y, Z) C2 .logvars two parfactors already different, need standardizingapart. However, atom P (X, X) g1 linearized yet. linearize it,rewrite g1 form 1 (P (X, X ))|(X, X ) C1 , C1 = {(x, x)|x C1 }. Finally,rename logvars X X Z, respectively, derive 1 (P (Y, Z))|(Y, Z) C1 .brings atom P (X, X) desired form P (Y, Z).ease exposition, explicitly mention linearization renaming;whenever two PRVs different parfactors compared, notation suggestinglogvars interpreted logvars linearizationrenaming.GC-FOVE wants multiply two parfactors, first checks pairs A1 |C1 ,A2 |C2 (one parfactor) whether proper. pair foundproper, means A1 A2 form P (Y), different (but overlapping)instantiations C1 C2 . pair split Y.Example 9. Consider g1 = 1 (N (X, ), R(X, Y, Z))|C1 C1 = (X, Y, Z) {xi }50i=152550{yi }50i=1 {zi }i=1 , g2 = 2 (N (X, ))|C2 C2 = (X, ) {x2i }i=1 {yi }i=1 . First,compare PRVs N (X, )|C1 N (X, )|C2 . PRVs partially overlap,splitting necessary. split parfactors, split C1 C2 (X,Y)-overlap.505excl = C \partitions C1 two sets: C1com = {x2i }251i=1 {yi }i=1 {zi }i=1 , C1505C1com = {x2i1 }25i=1 {yi }i=1 {zi }i=1 . C2 need split, tuples(X,Y)-values occur C1 . splitting constraints, splitparfactors accordingly: g1 split two parfactors g1com = (N (X, ), R(X, Y, Z))|C1comg1excl = (N (X, ), R(X, Y, Z))|C1excl , parfactor g2 remains unmodified.splitting procedure splits two PRVs two partitions each. Similarly, involved parfactors split two partitions each. stronglycontrasts C-FOVEs approach splitting. C-FOVE operates per logvar, splitsvalue separate partition (splitting based substitution) (Poole, 2003; Milchet al., 2008). Thus, may require many splits GC-FOVE requires one.419fiTaghipour, Fierens, Davis, & Blockeelexample, instead g1excl = (N (X, ), R(X, Y, Z))|C1excl , C-FOVE ends1250 parfactors (N (x1 , y1 ), R(x1 , y1 , Z))|{zi }5i=1 , (N (x1 , y2 ), R(x1 , y2 , Z))|{zi }5i=1 ,. . . , (N (x3 , y1 ), R(x3 , y1 , Z))|{zi }5i=1 , . . . , (N (x49 , y50 ), R(x49 , y50 , Z))|{zi }5i=1 .reason GC-FOVE always split two parfactors, yielding muchcoarser partitions C-FOVE, assumes extensionally complete constraintlanguage, whereas C-FOVE allows pairwise (in)equalities, forcing splitelement separately.5.5 Expansion Counting Formulashandling parfactors counting formulas, rewrite P(C)RV properfrom, employ operation expansion (Milch et al., 2008). split one grouprandvars RV (V) partition {RV (Vi )}mi=1 , counting randvar countsvalues RV (V) needs expanded, i.e., replaced group counting randvars {i }mi=1 ,counts values randvars RV (Vi ). parallel this, potentialoriginally V argument must replaced potential Viarguments; call potential expansion.Example 10. Suppose need split g1 = 1 (#X [S(X)])|C1 g2 = 2 (S(X))|C2 ,C1 = {x1 , . . . , x100 } C2 = {x1 , . . . , x40 }. C1 split C1com = C1 C2 = {x1 , . . . x40 }C1excl = C1 \ C2 = {x41 , . . . x100 }. Consequently, original group randvarsparfactor g1 , namely {S(x1 ), . . . S(x100 )}, partitioned V1com = {S(x1 ), . . . S(x40 )}V1excl = {S(x41 ), . . . S(x100 )}. preserve semantics original counting formula,need two separate counting formulas, one V1com one V1excl , needreplace original potential 1 (#X [S(X)]) 1 (#Xcom [S(Xcom )], #Xexcl [S(Xexcl )]),1 () depends sum two new counting randvars #Xcom [S(Xcom )]#Xexcl [S(Xexcl )]. end effect parfactor g1 replaced new parfactor1 (#Xcom [S(Xcom )], #Xexcl [S(Xexcl )])|C1 , C1 = C1com C1excl .explain expansion, begin case (non-parametrized) CRVsmove general case expansion PCRVs.5.5.1 Expansion CRVsFirst consider simplest possible type CRV: #X [P (X)]|C. counts manyvalues X C, P (X) certain value. C partitioned, X must countedwithin subset partition.following, assume C partitioned two non-empty subsets C1 C2 .one empty, equals C, means CRV keptexpansion needed.itself, splitting #X [P (X)]|C #X [P (X)]|C1 #X [P (X)]|C2 trivial,problem resulting counting formulas occur one single parfactor,constraint always associated parfactor, particular argumentparfactor. Thus, need transform (#X [P (X)])|C parfactor form(#X1 [P (X1 )], #X2 [P (X2 )])|C , single constraint C expresses X1 takevalues C1 , X2 values C2 . easily seen C = XX1 C1 XX2 C2420fiDecoupling Lifted Variable Elimination Constraint Languagesatisfies condition. Further, preserve semantics, should, count X1X2 , give result corresponding count X. function(h1 , h2 ) = (h1 h2 ),denoting summation histograms, property. Indeed, histogram X1(resp. X2 ) C equal X C1 (resp. C2 ), since {C1 , C2 } partitionC, sum histograms equals histogram X C.generally, consider non-parametrized CRV #X [P (X)]|C, X X meaning X\{X} (C) singleton. constraint C = X\{X} (C) (X1 (XX1 C1 )X2 (XX2 C2 )) joins singleton Cartesian product X (C1 ) X (C2 ),equivalent constraint XX1 (C1 ) XX2 (C2 ). resultcounting X1 (X2 ) C equivalent counting X C1 (C2 ), constraintvariables remains unchanged. shows parfactor (A, #X [P (X)])|C,partition {C1 , C2 } C C1 C2 non-empty, rewritten form(A, #X1 [P (X)], #X2 [P (X)])|C , C = XX1 (C1 ) XX2 (C2 ).Note ranges counting formulas (the hi arguments) dependcardinality C1 C2 , denote n1 n2 respectively.5.5.2 Expansion PCRVsConsider case X\{X} (C) singleton, i.e., parametrized CRVV represents group CRVs, counting values subset RV (V). Givenpartitioning constraint C, need expand underlying CRV corresponding potential. constraint C = XX1 (C1 ) XX2 (C2 ) remains correct (fornon-empty C1 , C2 ), even X\{X} (C) longer singleton: associates correctvalues X1 X2 tuple X\{X} (C). However, result potential expansion depends size partitions, n1 n2 , CRVs(n1 ,n2 ) result identical potentials expansion, grouped oneparfactor. account this, PCRV expansion first splits PCRV groups CRVsjoint count (n1 , n2 ), applies group correspondingpotential expansion.formalize this, first provide following auxiliary definitions.Definition 7 (Group-by) Given constraint C function f : C R, GroupBy(C, f ) = C/ f , x f f (x) = f (y) / denoting set quotient. is,Group-By(C, f ) partitions C subsets elements result f .Definition 8 (Joint-count) Given constraint C variables X, partitioned {C1 ,C2 }, counted logvar X X; C, L = X \ {X} l = L (t),joint-countX,{C1 ,C2 } (t) = (|X (L=l (C1 ))|, |X (L=l (C2 ))|).PCRV V = #Xi [P (X)] |C parfactor g partially overlaps another PRV|C model, expansion performs following g: (1) partition C X-overlapC , resulting C/X C ; (2) partition C C = group-by(C, joint-countX,C/X C )(this corresponds partition V CRVs number randvars common exclusive partitions C/X C ); (3) split g, based421fiTaghipour, Fierens, Davis, & BlockeelOperator expandInputs:(1) g = (A)|C: parfactor G(2) = #X [P (X)]: counting formula(3) = P (X)|C #Y [P (X)]|COutput: {gi = (Ai )|Ci }ni=1(1) C/X C = {C com , C excl }(2) {C1 , . . . , Cn } = group-by(C, joint-countX,C/X C )(3) Ci C com = Ci C excl = : = , Ai = A, Ci = Ci(4) i:(5) Ci = logvar(A) (Ci ) (XXcom (C com ) XXexcl (C excl ))(6) Ai = \ {A} {Acom , Aexcl } com = {X Xcom }, excl = {X Xexcl }(7) valuation (l, hcom , hexcl ) Ai , (l, hcom , hexcl ) = (l, hcom hexcl )Postcondition G G \ {g} expand(g, A, )Operator 5: expansion operator.C = {C1 , . . . , Cn }, resulting parfactors g1 , . . . , gn require distinct expandedpotential; (4) gi , replace potential expanded version. formal definitionexpansion given Operator 5.Suppose need split parfactors g = (#Y [F (X, )])|C g =C = {ann, bob, carl} {dave, ed, f red, gina} C = {ann, bob}{dave, ed}. Assume F stands friendship; #Y [F (X, )]|C counts number friendsnon-friends X C. random variables covered PCRV #Y [F (X, )] |Cpartially overlap F (X, ) |C . need split C overlap C , yielding C com C excl , need replace original PCRV separate PCRVs C comC excl . PCRVs require count-normalization, fact count-normalizedw.r.t. X C necessarily imply holds C com C excl .why, addition split overlap, need orthogonal partitioning C accordingjoint counts. Within subset Ci partitioning, count-normalizedw.r.t. X Cicom Ciexcl .follow four steps outlined above. Figure 8 illustrates steps. First,find partition C/X,Y C = {C com , C excl } C com = {ann, bob} {dave, ed}C excl = {ann, bob} {f red, gina} {carl} {dave, ed, f red, gina}. Inspecting jointcounts, see C com contains 2 possible friends Ann Bob (namely DaveEd), 0 Carl, whereas C excl contains 2 possible friends Ann Bob 4Carl. Formally, joint-countY,C/X,Y C (t) equals (2,2) X (t) = ann X (t) =bob, equals (0,4) X (t) = carl. So, within C com C excl , longercount-normalized respect X. therefore partition C subsets {C1 , C2 } =group-by(C, joint-countY,C/X,Y C ), gives C1 = {ann, bob} {dave, ed, f red, gina}C2 = {carl}{dave, ed, f red, gina}. Ci , construct Ci allowscounting friends Cicom Ciexcl separately, using series joins discussedearlier. Cicom Ciexcl non-empty, original PCRV #Y [F (X, )] |CExample 11.(F (X,))|C ,422fiDecoupling Lifted Variable Elimination Constraint LanguageCann daveann edbob davebob edCannannannannbobbobbobbobcarlcarlcarlcarldaveedfredginadaveedfredginadaveedfredginaC1XannannannannbobbobbobbobYcomdavedaveededdavedaveededYexclfredginafredginafredginafredginaC/X,Y Cann daveann edbob davebob edann fredann ginabob fredbob ginacarl davecarl edcarl fredcarl ginagroup-by(C,joint-countY,C/X,Y C )ann daveann edann fredann ginaC1bob davebob edbob fredbob ginacarl davecarl edC2carl fredcarl ginaC2Xcarl davecarl edcarl fredcarl ginaFigure 8: Illustration PCRV expansion operator. (1) count-normalized w.r.t. XC (with X, four values associated). Splitting C overlap Cresults subsets longer count-normalized w.r.t. X: jointcounts subsets (2,2) Ann Bob, (0,4) Carl.obtain count-normalized subsets, need partition C subset C1Ann Bob, C2 Carl; Group-By construct does.subsets, split overlap C yield subsetscount-normalized w.r.t. X. C1 result joining common exclusiveparts according join construct motivated earlier. C2 equals C2 C2overlap C hence need split.replaced two PCRVs per Ci , #Ycom [F (X, Ycom )] |Ci #Yexcl [F (X, Yexcl )] |Ci ,new potential defined (hcom , hexcl ) = (hcom hexcl ).GC-FOVEs expansion improves C-FOVEs following way. C-FOVE usesexpansion based substitution (Milch et al., 2008). instance, Example 10, C-FOVEsplits elements C excl individually C, adding elementsseparate argument parfactor involved potential function. yields423fiTaghipour, Fierens, Davis, & Blockeelpotential function 1 () 61 arguments, namely counting randvar #Xcom [S(Xcom )]60 randvars S(x41 ), . . . S(x100 ). causes extreme blow size (numberentries) potential function, happen using approach. general,C-FOVEs expansion yields potential function size O(r k (n k)r ), n = |C1 |, k =|C1excl |, r cardinality range considered randvars (e.g., r = |range(S(.))|Example 10). contrast, GC-FOVEs expansion yields potential function sizeO(kr (n k)r ). likely scenario r k, exponentially smallerC-FOVEs potential function. Given potential function later usedmultiplication summing-out, clear GC-FOVE yield large efficiency gainsC-FOVE.5.6 Count NormalizationLifted multiplication, summing-out counting conversion require certain variablescount-normalized (recall Definition 2, p. 406). property hold,achieved normalizing involved parfactor, amounts splittingparfactor parfactors property hold (Milch et al., 2008). Concretely,count-normalized given Z constraint C, C simply partitionedC = Group-By(C, CountY|Z ), CountY|Z defined Definition 1; next,parfactor split according C. formal definition count normalization shownOperator 6.Operator count-normalizeInputs:(1) g = (A)|C: parfactor G(2) Y|Z: sets logvars indicating desired normalization property CPreconditions(1) logvar(A) Z logvar(A) \Output: partition(g, group-by(C, CountY|Z ))Postconditions G G \ {g} count-normalize(g, Y|Z)Operator 6: count-normalization operator.Example 12. Consider parfactor g = (P rof (P ), Supervises(P, S)) con-straint C = {(p1 , s1 ), (p1 , s2 ), (p2 , s2 ), (p2 , s3 ), (p3 , s5 ), (p4 , s3 ), (p4 , s4 ), (p5 , s6 )}. Liftedelimination Supervises(P, S) requires logvar (student) count-normalized respect logvar P (professor). Intuitively, need partition professors groupsprofessors group supervise number students. example,C needs partitioned two, namely C1 = P {p3 ,p5 } (C) = {(p3 , s5 ), (p5 , s6 )} (tuplesinvolving professors 1 student) C2 = P {p1 ,p2,p4 } (C) = {(p1 , s1 ), (p1 , s2 ), (p2 , s2 ),(p2 , s3 ), (p4 , s3 ), (p4 , s4 )} (professors 2 students). Next, parfactor g split accordingly two parfactors g1 g2 constraints C1 C2 . parfactorsready lifted elimination Supervises(P, S).C-FOVE requires stronger normalization property hold. every pair logvars Xrequires either (1) X,Y (C) = X (C) (C) (2) X (C) = (C) X,Y (C) =424fiDecoupling Lifted Variable Elimination Constraint Language(X (C)Y (C))\{hxi , xi : xi X (C)}. enforce this, C-FOVE requires finer partitionsapproach does. example, C-FOVE requires C split 5 subsets{Ci }5i=1 Ci = P {pi } (C), i.e., one group per professor. coarser partitioning usedapproach cannot represented using C-FOVEs constraint language.5.7 Absorption: Handling Evidencevalue randvar observed, usually makes probabilistic inferenceefficient: randvar removed model, may introduce extra independencies model. However, lifted inference, also adverse effect:observations break symmetries among randvars. reason, importanthandle observations manner preserves much symmetry possible. ordereffectively handle observations lifted manner, introduce novel operator liftedabsorption.ground setting, absorption works follows (van der Gaag, 1996). Given factor(A) observation Ai = ai Ai A, absorption replaces (A) factor (A ),= \ {Ai } (a1 , . . . , ai1 , ai+1 , . . . , ) = (a1 , . . . , ai1 , ai , ai+1 , . . . , ).reduces size factor may introduce extra independencies model,always beneficial.n randvars (built predicate) observed value,perform absorption lifted level treating n randvars one single group.Consider parfactor g = (S(X), F (X, ))|(X, ) {(x1 , y1 ), . . . , (x1 , y50 )}. Assumeevidence atoms F (x1 , y1 ) F (x1 , y10 ) value true. representedadding evidence parfactor gE model: gE = E (F (X, ))|(X, ) {x1 } {yj }101 ,E (true) = 1 (the observed value) E (f alse) = 0. absorb evidence, g needssplit two, namely g1 C1 = {(x1 , y1 ), . . . , (x1 , y10 )} (the parfactorevidence) g2 C2 = {(x1 , y11 ), . . . , (x1 , y50 )} (no evidence). Then,absorb evidence F g1 . Performing absorption ground level wouldresult ten identical factors (S(x1 )) (the logvar disappears absorption). Liftedabsorption computes once, raises tenth power. Generally,Xexcl logvars occur exclusively atom absorbed, exponentnumber values Xexcl take, Xexcl must count-normalized respectlogvars. Further, logvars Xexcl removed constraint Cdisappear absorption.parfactors counting formulas, essentially reasoning used,exponent determined non-counted logvars occurring exclusively atom(Xnce ). logvars, together counted logvar, removed C. valueabsorbed counting formula, filled , histogram indicating manytimes possible value observed absorbed PRV. Since oneobserved value evidence parfactor, histogram maps value numberrandvars absorbed, values zero. Lifted absorption formally definedOperator 7. provide correctness proof operator Appendix A, analyzecomplexity Appendix B.GC-FOVE handles evidence absorption follows. first creates one evidence parfactor per observed value predicate. Next, compares evidence parfactor425fiTaghipour, Fierens, Davis, & BlockeelOperator absorbInputs:(1) g = (A)|C: parfactor G(2) Ai Ai = P (X) Ai = #Xi [P (X)](3) gE = E (P (X))|CE : evidence parfactorLet Xexcl = X \ logvar(A \ Ai );Xnce = Xexcl \ {Xi } Ai = #Xi [P (X)], Xexcl otherwise;L = logvar(A) \ Xexcl ;= observed value P (X) gE ;Preconditions(1) RV (Ai |C) RV (Ai |CE )(2) Xnce count-normalized w.r.t. L C.Output: g = (A )|C ,(1) = \ {Ai }(2) C = logvar(C)\Xexcl (C)(3) (. . . , ai1 , ai+1 , . . . ) = (. . . , ai1 , e, ai+1 , . . . )r , r = CountXnce |L (C),e = Ai = P (X)e histogram e(o) = CountXi |logvar(A) (C), e(.) = 0 elsewhere, otherwise(namely Ai = #Xi [P (X)])PostconditionG {gE } = G \ {g} {gE , absorb(g, Ai , gE )}Operator 7: Lifted absorption.PRV model, applying absorption possible. necessary, parfactorsmodel split allow absorption. (It never necessary split evidence parfactors, see precondition 1.) absorptions possible given evidenceparfactor, removed model: evidence incorporated completely.Like sum-out operator, absorb operator effect eliminating PRVsmodel. operators definitions show, however, absorb requires weakerpreconditions sum-out, means applied situations. Also,absorb operator easily lends splitting needed constraint processing strategy(Kisynski & Poole, 2009a), keeps model much higher granularity, requiringfewer splits parfactors compared preemptive shattering strategy. presenceobservations, often case real-world problems, effects resultlarge computational savings.approach dealing evidence differs C-FOVEs two important ways.First, C-FOVE introduces separate evidence factor ground observation = a.causes extensive splitting: n randvars observed value,n separate factors, C-FOVE perform (at least) n eliminationsrandvars. addition, splitting may cause splitting C-FOVE continues,destroying even opportunities lifting. show Section 7 makeinference impossible C-FOVE presence evidence.Second, C-FOVE use absorption; inference, evidence factorsused multiplication summing-out like factors. Absorption advantageous426fiDecoupling Lifted Variable Elimination Constraint LanguageOperator ground-logvarInputs:(1) g = (A)|C: parfactor G(2) X: logvar logvar(A)Output: partition(g, group-by(C, X ))PostconditionG G \ {g} ground-logvar(g, X)Operator 8: Grounding.eliminates randvars model, longer need summed out.result, approach, evidence reduces number summing-out multiplicationoperations, C-FOVE increases number.5.8 Grounding Logvarguarantee enabling operators eventually result PRVs parfactorsallow lifted operators. illustrate this, consider model consistingsingle parfactor (R(X, ), R(Y, Z), R(X, Z))|C, expresses probabilistic varianttransitivity. Since one factor, multiplications needed startingeliminate variables. Yet, structure parfactor, single PRVeliminated (the preconditions lifted summing counting conversionfulfilled, none operators change that).cases like this, operators applied, lifted always resortlast operator: grounding logvar X parfactor g (de Salvo Braz, 2007; Milch et al., 2008).Given parfactor g = (A)|C logvar X logvar(A) X (C) = {x1 , . . . , xn },grounding X replaces g set parfactors {g1 , . . . , gn } gi = (A)|X=xi (C).equivalent splitting g based partition group-by(C, X ), yieldsdefinition shown Operator 8. Note resulting parfactor gi , logvar Xtake single value xi , practice X replaced constant xi removedset logvars.Grounding significantly increase granularity model decrease opportunities performing lifted inference: extreme case logvars grounded,inference performed propositional level. therefore best used lastresort. practice, (G)C-FOVEs heuristic selecting operators, relies sizeresulting factors, automatically effect.Calling ground-logvar operator confused event obtaining ground model. ground-logvar grounds one logvar, necessarilyresult ground model. Conversely, one may arrive ground model without ever callingground-logvar, simply splitting continues singleton level.6. Representing Manipulating Constraintsshown using extensionally complete constraint language instead allowingpairwise (in)equalities potentially yield large efficiency gains allowingopportunities lifting. question remains represent constraints.427fiTaghipour, Fierens, Davis, & BlockeelX{x1 , x2 , x3 }{y1 , . . . , y10 }Z{z1 , . . . , z5 }{x4 , x5 }{x5 , . . . , x20 }{y11 , y12 } {y1 , . . . , y20 } {y1 , y2 }ZZ{z1 , . . . , z10 } {z4 , z5 }Z{z1 , . . . , z8 }{y3 , . . . , y10 }Z{z10 , z15 }Figure 9: constraint tree representing constraint logvars X, Y, Z.principle, could represent extensionally, lists tuples. allowsconstraint represented, inefficient many logvars. Instead,employ constraint tree, also used First Order Bayes-Ball (Meert, Taghipour, &Blockeel, 2010). Hence, lower-level operations constraints (projection, splitting,counting) must implemented terms constraint trees. Below, briefly explaindone.constraint tree logvars X tree internal (non-leaf) node labeledlogvar X X, leaf labeled terminal label , edge e = (Xi , Xj )labeled (sub-)domain D(e) D(Xi ). See Figure 9 example. use orderedtrees, nodes level tree labeled logvar,logvar occurs one level. path root leaf edges e1 , . . . , e|X|represents tuples Cartesian product D(ei ). example, Figure 9, leftpath represents tuples {x1 , x2 , x3 } {y1 , . . . , y10 } {z1 , . . . , z5 }. constraintrepresented tree union tuples represented root-to-leaf path.Given constraint (in terms set tuples satisfy it), constructcorresponding tree bottom-up manner merging compatible edges. Different logvarorders result trees different sizes. tree re-ordered interchanging nodestwo adjacent levels tree applying possible merges levels.employ re-ordering simplify various constraint handling operations. projectionconstraint, move projected logvars top tree discard partslogvars. splitting, perform pairwise comparison two involvedconstraint trees. First, re-order tree logvars involved splittop trees. process trees top-down comparing edgesleaving root two trees partition domains based overlap.recursively repeat children reach last logvar involved split.count normalization, also first apply re-ordering. partition treebased number tuples counted logvars branch. counting number,428fiDecoupling Lifted Variable Elimination Constraint Languageneed consider size domains associated edges. Finally,join two constraints computed reordering trees join variables occurtop, merging levels join variables way done splitting,extending leaf resulting tree cross-product correspondingsubtrees original trees.Constraint trees (and way constructed) close hypercube representation used lifted belief propagation (Singla, Nath, & Domingos, 2010). However,given constraint, constraint tree typically compact. constraint treeFigure 9 corresponds set five hypercubes, one leaf. hypercube representation exploit fact first second hypercube, instance, sharepart {x1 , x2 , x3 }. constraint tree, explicit, makes compact.stress GC-FOVE use extensionally complete constraint representationlanguage. Constraint trees one representation. representationscompact cases, choice representation need consider alsotradeoff compactness ease constraint processing. Consider constraintgraph, similar trees, parent nodes share child nodes.representation compact constraint tree, also requires complicatedconstraint handling operations. instance, consider splitting, might needsplit child node one parent others. operations becomecomplicated graphs, trivial trees.7. ExperimentsUsing extensionally complete constraint language, capture symmetriesmodel, potentially offers ability perform operations liftedlevel. However, comes cost, manipulating expressive constraintscomputationally demanding. hypothesize ability perform fewer computationscapturing symmetries far outweigh cost typical inference tasks.section, compare performances C-FOVE GC-FOVETREES (GC-FOVE usingtree representation Section 6) empirically validate hypothesis. particular,study performances vary function two parameters: (i) domain size,(ii) amount evidence. also empirically study whether GC-FOVETREESsolve inference tasks beyond reach C-FOVE.Throughout section, GC-FOVE stands GC-FOVETREES .7.1 Methodology Datasetscompare C-FOVE GC-FOVE several inference tasks synthetic realworld data. use version C-FOVE extended general parfactor multiplication(de Salvo Braz, 2007).3 implementing GC-FOVE, started publicly available C-FOVE code (Milch, 2008), implementations maximally comparable.4experiments, undirected model parfactors whose constraints representable3. allows C-FOVE handle tasks entirely lifted way, otherwise wouldresort grounding, e.g., social network domain (Jha et al., 2010).4. GC-FOVE available http://dtai.cs.kuleuven.be/ml/systems/gc-fove.429fiTaghipour, Fierens, Davis, & BlockeelC-FOVE. Thus, GC-FOVE initial advantage, makes comparison conservative.experiment compute marginal probability query randvar givenevidence. query randvar selected random non-observed atoms.evidence generated randomly selecting randvars particular predicate givingvalue chosen randomly uniformly domain. reported resultsaveraged multiple runs different query evidence sets.7.1.1 Experiments Synthetic Dataterms synthetic data, evaluate algorithm three standard benchmark problems. first domain called workshop attributes (Milch et al., 2008). Here, differentattributes (e.g., topic, date, etc.) describe workshop, corresponding factorattribute shows dependency attendance person attribute.theory contains following parfactors.1 (Attends(X), Attr1 )...(Attends(X), Attrm )m+1 (Attends(X), Series)second domain called competing workshops (Milch et al., 2008). models factpeople likely attend workshop hot topic numberattendees influences whether workshop becomes series. theory containsfollowing parfactors.1 (Attends(X), Hot(Y ))2 (Attends(X), Series)experiments domains, query variable Series,evidence randvars form Attends(x).third domain called social network (Jha et al., 2010) models peoplessmoking habits, chance asthma, dependence persons habitsdiseases friendships. theory contains following parfactors.1 (Smokes(X))2 (Asthma(X))3 (F riends(X, ))4 (Asthma(X), Smokes(X))5 (Asthma(X), F riends(X, ), Smokes(Y ))domain, evidence randvars mix randvars form Smokes(x)Asthma(x), query randvar randvar unobserved.430fiDecoupling Lifted Variable Elimination Constraint Language7.1.2 Experiments Real-World Dataalso used two datasets field statistical relational learning. first,WebKB (Craven & Slattery, 1997), contains data 1200 webpages, includingclass (e.g., course page), textual content (set words), hyperlinkspages. model consists multiple parfactors, stating instance classestwo linked pages depend other. inference task concerns link prediction. Here,class information observed subset pages task computeprobability hyperlink pair pages. use one Pageclass predicatemodel run, average runtime multiple runs class.used following set parfactors.1 (P ageclass(P ))2 (P ageclass(P ), HasW ord(P, W ))3 (P ageclass(P1 ), Link(P1 , P2 ), P ageclass(P2 ))second dataset, Yeast (Davis, Burnside, de Castro Dutra, Page, & Costa, 2005), contains data 7800 yeast genes, functions locations, interactions genes. model task similar WebKB (genefunctions correspond page classes, gene-to-gene interactions hyperlinks). task,observe function information subset genes query existenceinteraction two genes. Similar WebKB, also use one function modelrun average results multiple runs. Here, used following setparfactors.1 (F unction(G))2 (Location(G, L))3 (F unction(G), Location(G, L))4 (F unction(G1 ), Interaction(G1 , G2 ), F unction(G2 ))Motivation evidence randvars. experiments, evidence randvars correspondatoms unary predicate; call unary randvars. done purposeintroducing evidence randomly binary randvars, e.g., randvars type P (X, ),quickly break many symmetries lifted inference possible anymore. fact,recent theoretical results show lifted inference presence arbitraryevidence binary randvars simply possible. limitation uniqueapproach, true possible exact lifted inference approach (Van den Broeck &Davis, 2012). this, random insertion evidence binary randvars quicklycause lifted inference algorithm resort ground inference, would blurdistinction C-FOVE, GC-FOVE, ground inference. avoid placingevidence unary randvars.431fiTaghipour, Fierens, Davis, & BlockeelGC-FOVEC-FOVE101000GC-FOVEC-FOVEGC-FOVEC-FOVE100Time (s)Time(s)Time(s)10111010.1200400600Domain Size800(a) Workshop Attributes1000200400600Domain Size800(b) Competing Workshops1000!400600'8001000(c) Social NetworkFigure 10: Performance synthetic data varying domain sizes proportion observed randvars fixed 20%. Y-axis (runtime) drawn log scale.7.2 Influence Domain Sizefirst set experiments, use synthetic datasets measure effect domainsize (number objects) runtime. vary domain size 50 1000 objectsholding proportion observed randvars (relative number observable randvars)constant 20%. Figures 10(a) 10(c) show performance three syntheticdatasets. three models, GC-FOVE outperforms C-FOVE domain sizes.number objects domain increases, runtimes increase algorithms.GC-FOVEs runtime increases much lower rate C-FOVEs three models.first two tasks, GC-FOVE one two orders magnitude fasterC-GOVE, largest domain sizes. social network domain, differenceperformance becomes striking: C-FOVE cannot handle domain sizes 100 objectsmore, GC-FOVE handles largest domain (1000 objects) 200 seconds.improvement performance arises GC-FOVE better preserves symmetries presentmodel treating indistinguishable elements, observed not, single unit.gain pronounced larger domains. C-FOVE makes separate partition(and separate evidence factor) observed randvar, thus, fixed evidenceratio, number partitions induced C-FOVE grows linearly domain size.Moreover, costly elimination operation partition. contrast, GC-FOVE,employs lifted absorption, keeps model higher granularity groupingobservations handles whole groups observations single lifted operation.7.3 Influence Amount Evidencesecond set experiments, measure effect proportion observedrandvars runtime, using synthetic datasets. fix domain size, varypercentage observed randvars 0% 100%. Note percentageobservable randvars (e.g., randvars form Smokes(x)), randvarstype (so 100% mean unobserved variables left). Figures 11(a)11(c) show performance three synthetic domains domain size1000 objects. better demonstrate C-FOVEs behavior social networks domain,Figure 11(d) shows performances domain 25 objects. algorithmsdisplay similar trends across three domains. Without evidence, GC-FOVE comparable432fiDecoupling Lifted Variable Elimination Constraint Language10000GC-FOVEC-FOVE1000100100Time (s)Time(s)GC-FOVEC-FOVE10001010110.10.10204060Percentage Evidence800.010100(a) Workshop Attributes (domain size: 1000)204060Percentage Evidence80100(b) Competing Workshops (domain size: 1000)10001000GC-FOVEC-FOVEGC-FOVEC-FOVE100Time(s)Time(s)1001010110.10.10204060Percentage Evidence801000(c) Social Network (domain size: 1000)204060Percentage Evidence80100(d) Social Network (domain size: 25)Figure 11: Performance synthetic data varying amounts evidence fixeddomain size. Y-axis (runtime) drawn log scale.C-FOVE. best scenario C-FOVE (i) initial model contains(in)equality constraints, (ii) evidence, symmetries brokeninference operators applied. case, difference runtime twoalgorithms overhead associated constraint processing, almost negligible.proportion observations increases, symmetries objectsbroken, GC-FOVE maintains much coarser grouping, performs inference muchefficiently, C-FOVE. domains, C-FOVEs runtime increases dramaticallyincrease percentage observations. evidence added, C-FOVE inducespartitions, results finer groupings objects leaves fewer opportunitieslifting. GC-FOVE performs significantly better comparison, due coarser groupingobservations employing absorption elimination model. GC-FOVEsruntime experiences bump initial set evidence added, levelsgradually decreases (the evidence, randvars efficiently eliminatedabsorption). GC-FOVE consistently finishes 200 seconds, regardless setting.contrast, social network domain (Figure 11(c)) C-FOVE cannot handle portionsevidence greater 1% (it runs memory machine configured 30GBmemory).results confirm coarser groupings use lifted absorptioncontribute much better performance GC-FOVE.433fiTaghipour, Fierens, Davis, & Blockeel64GC-FOVEC-FOVE0.4Time(s)Time(s)0.5GC-FOVEC-FOVE5320.30.20.110204060Percentage Evidence800100(a) Yeast0"4060fffi ffff ff ff%100(b) WebKBFigure 12: Performance real-world data varying amounts evidence. Yaxis (runtime) drawn log scale. C-FOVE ran completionzero-evidence experiments.7.4 Performance Real-World Datafinal set experiments, compared algorithms two real-world datasets,WebKB Yeast. datasets, varied percentage observed page classesfunctions 0% 100% steps 10%. Figures 12(a) 12(b) illustrateresults. C-FOVE could solve zero-evidence problems experiments;cases, typically ran memory hour computation timemachine configured 30 GB memory. failure primarily due large numberobservations, often forces resort inference ground level largenumber objects. GC-FOVE, hand, runs successfully experimentalconditions. Furthermore, GC-FOVE consistently solve problems seconds.synthetic data, GC-FOVEs performance improves increasing numberobservations. cases randvars eliminated absorption, insteadexpensive operations multiplication summation.8. ConclusionsConstraints play crucial role lifted probabilistic inference determine degreelifting takes places. Surprisingly, lifted inference algorithms use classconstraints based pairwise (in)equalities (Poole, 2003; de Salvo Braz et al., 2005;Milch et al., 2008; Jha et al., 2010; Kisynski & Poole, 2009b; Van den Broeck et al., 2011);main exception work approximate inference using lifted belief propagation(Singla & Domingos, 2008). paper shown class constraintsoverly restrictive. proposed using extensionally complete constraint languages,capture symmetries among objects allow operations occurlifted level. defined relevant constraint handling operations (e.g., splittingnormalization) work extensionally complete constraint languages implementedperforming lifted variable elimination. made use constraint trees efficiently represent manipulate constraints. empirically evaluated systemseveral domains. approach resulted three orders magnitude improvementruntime, compared C-FOVE. Furthermore, GC-FOVE solve several tasksintractable C-FOVE.434fiDecoupling Lifted Variable Elimination Constraint LanguageFuture work includes generalizing lifted inference algorithms currently useinequality constraints, e.g., works Jha et al. (2010) Van den Broeck et al.(2011), optimizing constraint handling. respect latter, interesting direction recent work de Salvo Braz, Saadati, Bui, OReilly (2012)employs logical representation constraints, extensionally complete,presents specialized constraint processing methods representation. Finally,possible extend lifted absorption works evidence parfactors,generally deterministic parfactors. another promising directionfuture work.AcknowledgmentsDaan Fierens supported Research Foundation Flanders (FWO-Vlaanderen).Jesse Davis partially supported Research Fund KULeuven (CREA/11/015OT/11/051), EU FP7 Marie Curie Career Integration Grant (#294068). workfunded GOA/08/008 Probabilistic Logic Learning Research Fund KULeuven.authors thank Maurice Bruynooghe Guy Van den Broeck interesting discussionscomments work text. also thank reviewers constructivecomments concrete suggestions improve article.Appendix A. Correctness Proof Lifted Absorptionappendix, prove correctness novel lifted absorption operator. beginproviding lemmas.Recall set parfactors G compact way defining set factors gr(G) ={f |f gr(g) g G} corresponding probability distributionPG (A) =1Zf (Af ).f gr(G)Further, G G means G G define probability distribution. Thus, formally:G G PG (A) = PG (A)1Zf gr(G)f (Af ) =1Zf (Af ).f gr(G )following lemmas easily proven applying definition keepingmind gr(G G ) = gr(G) gr(G ).Lemma 1 models G, G , G : G G G G G G .Lemma 2 Given factor f = (A1 , A2 , . . . , ) evidence factor fE = E (A1 )E (a1 ) = 1 a1 = (the observed value) E (a1 ) = 0 otherwise, {f, fE } {f , fE }f = (A2 , . . . , ) (a2 , . . . , ) = (o, a2 , . . . , ).Lemma 3 model consists identical factors, G = {(A1 , . . . , )}mi=1 ,equivalent model single factor G = { (A1 , . . . , )} (a1 , . . . , ) =(a1 , . . . , )m .435fiTaghipour, Fierens, Davis, & Blockeelprove Absorb operator correct, i.e., postconditions hold, givenpreconditions.Theorem 1 Given model G, parfactor g G evidence parfactor gE ,preconditions absorb operator fulfilled,G {gE } G \ {g} {absorb(g, Ai , gE ), gE }.Proof: G = G \ {g}, rewrite equivalenceG {g, gE } G {absorb(g, Ai , gE ), gE }.Lemma 1, suffices prove{g, gE } {absorb(g, Ai , gE ), gE }.Let g = (A)|C = {A1 (X1 ), . . . , Ak (Xk )}, let gE = E (P (X))|CE , letL = logvar(A) (non-counted logvars A), Xexcl = X \ logvar(A \ {Ai }) (logvars occurringexclusively Ai ) L = logvar(A) \ Xexcl (non-counted logvars occurring (also) outsideAi ). operator returns parfactor form (A )|C = {A2 , . . . , Ak }C = logvar(C)\Xexcl (C) (see operator definition). need proveequivalence holds. ease exposition, assume atomcounting formula absorbed (Ai operators input) A1 . first considercase A1 atom P (X1 ), case A1 counting formula#X [P (X1 )].Absorption atoms. case, (a2 , . . . , ak ) = (o, a2 , . . . , ak )rr = CountXexcl |L (C) (see operator definition, observing Xnce = Xexcl ).definition, gr(g) = {(P (x1 ), A2 (x2 ), . . . , Ak (xk ))}lL (C) , xi = Xi (l). Precondition 1 guarantees (P (x1 ), A2 (x2 ), . . . , Ak (xk )), exists evidencefactor E (P (x1 )) gr(gE ). Lemma 2, therefore rewrite factor gr(g)form (A2 (x2 ), . . . ), (a2 , . . . ak ) = (o, a2 , . . . , ak ), observed valueP (x1 ).potential function factors, since one observed valuewhole evidence parfactor. Therefore, two factors (P (x1 ), A2 (x2 ), . . . , Ak (xk ))(P (x1 ), A2 (x2 ), . . . , Ak (xk )) differ first argument rewrittenfactor. Precondition 2, number factors rewrittenfactor constant equals CountXexcl |L (C) = r. Lemma 3, set identicalfactors therefore replaced single factor potential function(a2 , . . . , ak ) = (a2 , . . . , ak )r = (o, a2 , . . . , ak )r ,exactly defined operator.Absorption counting formulas. case,(a2 , . . . , ak ) = (e, a2 , . . . , ak )rr = CountXnce |L (C) Xnce = Xexcl \ {X} (see operator definition).436fiDecoupling Lifted Variable Elimination Constraint Languagedefine X1 = X1 \ {X}, use (x1 , X) denote X1 logvars instantiatedexcept counted logvar X. Now, definition,gr(g) = {(#XCl [P (x1 , X)], A2 (x2 ), . . . , Ak (xk ))}lL (C) ,xi = Xi (l), x1 = X1 (l) Cl = X (L=l (C)). Cl form {x1 , . . . , xn },n = CountX|L (C) (n exists PCRVs definition count-normalized).show correctness operator case showing factor fgr(g), evidence parfactor gE rewritten contain evidence factorCRV f , reasoning applied f .Precondition 1 guarantees factorf = (#X{x1 ,...,xn } [P (x1 , X)], A2 (x2 ), . . . , Ak (xk )),gr(gE ) contains group evidence factorsEf = {E (P (x1 , x1 )), . . . , E (P (x1 , xn ))}.multiply factors EfE (P (x1 , x1 ), . . . , P (x1 , xn )),E (o, o, . . . , o) = 1 E (.) = 0 elsewhere, rewritefE = E (#X{x1 ,...,xn } [P (x1 , X)]),E (i) E (e) = 1, e histogram e(o) = n e(.) = 0elsewhere, (ii) E (e ) = 0 e 6= e.formed fE , rewrite f form (A2 (x2 ), . . . ), (a2 , . . . ak ) =(e, a2 , . . . , ak )r r = CountXnce |L (C), argumentation regularatoms. this, replace fE equivalent Ef , thus restoring gE . Repeatingf preserves equivalence eventually yields model operatorreturns.Appendix B. Computational Complexity Lifted AbsorptionApplying lifted absorption parfactor g = (A)|C, complexity O(|C|) + O(Size()log |C|), |C| cardinality (number tuples) constraintQ C, Size()equals product range sizes arguments A, i.e., Size() = Ai |range(Ai )|.first term complexity, O(|C|), arises absorption involves projectionconstraint C, worst case (with extensional representation) complexity O(|C|). second term, O(Size() log |C|), complexity computing newpotential function, involves manipulating , Size() entries (in tabularrepresentation), exponentiating it, complexity O(log |C|).437fiTaghipour, Fierens, Davis, & BlockeelReferencesApsel, U., & Brafman, R. I. (2011). Extended lifted inference joint formulas.Proceedings 27th Conference Uncertainty Artificial Intelligence (UAI),pp. 1118.Choi, J., Hill, D., & Amir, E. (2010). Lifted inference relational continuous models.Proceedings 26th Conference Uncertainty Artificial Intelligence (UAI),pp. 126134.Craven, M., & Slattery, S. (1997). Relational learning statistical predicate invention:Better models hypertext. Machine Learning, 43(1/2), 97119.Davis, J., Burnside, E. S., de Castro Dutra, I., Page, D., & Costa, V. S. (2005).integrated approach learning Bayesian networks rules. Proceedings 16thEuropean Conference Machine Learning (ECML), pp. 8495.De Raedt, L., Frasconi, P., Kersting, K., & Muggleton, S. (Eds.). (2008). Probabilistic inductive logic programming: Theory applications. Springer-Verlag, Berlin, Heidelberg.de Salvo Braz, R. (2007). Lifted first-order probabilistic inference. Ph.D. thesis, DepartmentComputer Science, University Illinois Urbana-Champaign.de Salvo Braz, R., Amir, E., & Roth, D. (2005). Lifted first-order probabilistic inference.Proceedings 19th International Joint Conference Artificial Intelligence(IJCAI), pp. 13191325.de Salvo Braz, R., Saadati, S., Bui, H., & OReilly, C. (2012). Lifted arbitrary constraint solving lifted probabilistic inference. Proceedings 2nd International WorkshopStatistical Relational AI (StaRAI), pp. 18.Dechter, R. (2003). Constraint processing. Morgan Kaufmann.Getoor, L., & Taskar, B. (Eds.). (2007). Introduction Statistical Relational Learning.MIT Press.Gogate, V., & Domingos, P. (2011). Probabilistic theorem proving. Proceedings27th Conference Uncertainty Artificial Intelligence (UAI), pp. 256265.Jha, A., Gogate, V., Meliou, A., & Suciu, D. (2010). Lifted inference seenside : tractable features. Proceedings 23rd Annual Conference NeuralInformation Processing Systems (NIPS), pp. 973981.Kersting, K., Ahmadi, B., & Natarajan, S. (2009). Counting belief propagation. Proceedings 25th Conference Uncertainty Artificial Intelligence (UAI), pp.277284.Kisynski, J., & Poole, D. (2009a). Constraint processing lifted probabilistic inference.Proceedings 25th Conference Uncertainty Artificial Intelligence (UAI),pp. 293302.Kisynski, J., & Poole, D. (2009b). Lifted aggregation directed first-order probabilistic models. Proceedings 21st International Joint Conference ArtificialIntelligence (IJCAI), pp. 19221929.438fiDecoupling Lifted Variable Elimination Constraint LanguageKschischang, F. R., Frey, B. J., & Loeliger, H.-A. (2001). Factor graphs sum-productalgorithm. IEEE Transactions Information Theory, 47 (2), 498519.Meert, W., Taghipour, N., & Blockeel, H. (2010). First-order bayes-ball. ProceedingsEuropean Conference Machine Learning Knowledge Discovery Databases(ECML PKDD), pp. 369384.Milch, B. (2008). BLOG.. http://people.csail.mit.edu/milch/blog/.Milch, B., Zettlemoyer, L. S., Kersting, K., Haimes, M., & Kaelbling, L. P. (2008). Liftedprobabilistic inference counting formulas. Proceedings 23rd AAAI Conference Artificial Intelligence (AAAI), pp. 10621608.Poole, D. (2003). First-order probabilistic inference.. Proceedings 18th InternationalJoint Conference Artificial Intelligence (IJCAI), pp. 985991.Ramakrishnan, R., & Gehrke, J. (2003). Database management systems (3. ed.). McGrawHill.Sen, P., Deshpande, A., & Getoor, L. (2009a). Bisimulation-based approximate lifted inference. Proceedings 25th Conference Uncertainty Artificial Intelligence(UAI09), pp. 496505.Sen, P., Deshpande, A., & Getoor, L. (2009b). Prdb: managing exploiting rich correlations probabilistic databases. VLDB Journal, 18 (5), 10651090.Singla, P., & Domingos, P. (2008). Lifted first-order belief propagation. Proceedings23rd AAAI Conference Artificial Intelligence (AAAI), pp. 10941099.Singla, P., Nath, A., & Domingos, P. (2010). Approximate Lifted Belief Propagation.Proceedings 1st International Workshop Statistical Relation AI (StaRAI),pp. 9297.Taghipour, N., Fierens, D., Davis, J., & Blockeel, H. (2012). Lifted variable eliminationarbitrary constraints. Proceedings 15th International ConferenceArtificial Intelligence Statistics (AISTATS), pp. 11941202.Van den Broeck, G., & Davis, J. (2012). Conditioning first-order knowledge compilationlifted probabilistic inference. Proceedings 26th AAAI ConferenceArtificial Intelligence (AAAI), pp. 17.Van den Broeck, G., Taghipour, N., Meert, W., Davis, J., & De Raedt, L. (2011). LiftedProbabilistic Inference First-Order Knowledge Compilation. Proceedings22nd International Joint Conference Artificial Intelligence (IJCAI), pp. 21782185.van der Gaag, L. C. (1996). evidence absorption belief networks. Int. J. Approx.Reasoning, 15 (3), 265286.439fiJournal Artificial Intelligence Research 47 (2013) 575-611Submitted 02/13; published 07/13Refined View Causal Graphs Component Sizes:SP-Closed Graph Classes BeyondChrister BackstromPeter Jonssonchrister.backstrom@liu.sepeter.jonsson@liu.seDepartment Computer ScienceLinkoping UniversitySE-581 83 Linkoping, SwedenAbstractcausal graph planning instance important tool planningpractice theory. theoretical studies causal graphs largely analysedcomputational complexity planning instances causal graph certainstructure, often combination parameters like domain size variables.Chen Gimenez ignored even structure considered size weaklyconnected components. proved planning tractable componentsbounded constant otherwise intractable. intractability result was, however,conditioned assumption parameterised complexity theory knownuseful relationship standard complexity classes. approach problemperspective standard complexity classes, prove planning NP-hardclasses unbounded components additional restriction refer SPclosed. argue NP-hardness theorems causal graphs difficultapply and, thus, prove general result; even component sizes grow slowlyclass densely populated graphs, planning still cannot tractable unlesspolynomial hierachy collapses. results still hold restricted classacyclic causal graphs. finally give partial characterization borderlineNP-hard NP-intermediate classes, giving insight problem.1. Introductionfirst briefly explain causal graph give short survey applicationswell theoretical results reported literature. Following that, give overviewnew results presented article.1.1 Backgroundcausal graph planning instance explicit description variable dependencies implicitly defined operators. precisely, directed grapharc variable x another variable either x appearsprecondition operator effect operator effects x y.standard definition causal graph traced back Knoblock (1994)although give name. used causal graph Alpine algorithm,guidance partitioning ordering variables process automaticallyderiving state abstraction hierarchies. actual name causal graph traced backWilliams Nayak (1997). approach general restrictedc2013AI Access Foundation. rights reserved.fiBackstrom & JonssonKnoblocks. one hand, generalized concept binary variablesmulti-valued variables, hand, considered acyclic causal graphsimplies operators unary, i.e. every operator changes one variable.context work reactive planner Burton onboard space-ship control.causal model compiled transition system could efficiently exploitedreactive controller choose appropriate operators achieve given goals. compilationdone way operators unary, claimed oftenpossible real applications. resulting acyclicity causal graph exploitedBurton, traversed graph bottom order issue operators orderconsistent causal relationships.Jonsson Backstrom (1998b) also studied acyclic causal graphs, referreddependency graphs. considered subclass graphs particular structure used implicitly define corresponding class planning instances, 3Sclass. class property always possible decide polynomial timesolution not, solutions may exponential length, thusnecessarily taking exponential time generate. Although one single restricted case,3S class probably first example relating structural properties causal graphcomputational complexity planning. general extensive analysisdone Domshlak Dinitz (2001a), analysed complexity planningclasses instances corresponding number different possible structures acycliccausal graphs. However, work done context multi-agent coordinationterm causal graph never used.first two papers may viewed early examples exploiting causalgraph practice, latter papers form starting point subsequent theoretical research relationships planning complexity structurecausal graphs.important step forward usage causal graphs paper Helmert(2004) demonstrated causal graph particularly useful contextmulti-valued variables. Previous research complexity planning multi-valuedvariables focussed structure domain-transition graphs variables(Jonsson & Backstrom, 1998a), rather causal graph. Helmert realized powerusing domain-transition graphs causal graph heuristic planning.exploited practice highly succesful Fast Downward planner (Helmert,2006a). translates PDDL planning instances binary variables representationmulti-valued variables removes carefully chosen edges resulting causalgraph make acyclic. resulting causal graph used compute heuristichierarchically computing composing plan lengths subgraphs oneparticular structures studied Domshlak Dinitz (2001a). Somewhat similarly, KatzDomshlak (2010) identified subgraphs causal graph certain structuresmake planning tractable. exploited able use larger variablessets constructing pattern databases. example exploiting causal graphmake planning efficient paper factored planning Brafman Domshlak(2006). showed structure causal graph used guidedeciding planning instance solved efficiently dividingloosely coupled subinstances use constraint processing. basic idea causal576fiA Refined View Causal Graphs Component Sizesgraph represent variable dependencies is, course, quite general necessarilyrestricted planning. instance, Wehrle Helmert (2009) transferred causalgraph concept context model checking.previously mentioned, two papers Jonsson Backstrom (1998b)Domshlak Dinitz (2001a) viewed starting point successful lineresearch studying relationships planning complexity structurecausal graph. 3S class Jonsson Backstrom limitedspecial case, Domshlak Dinitz studied classes planning instances correspondingnumber general graph structures, like in-stars (aka. inverted forks), out-stars (aka.forks), directed path graphs (aka. directed chain graphs), polytrees singly-connectedDAGs. results followed, instance, articles Brafman Domshlak (2003),Gimenez Jonsson (2008). latter article additionally showed although 3Sinstances exponential-length plans, possible generate macro representationplan polynomial time, result extended also classes definedstructure causal graph. Many complexity results papers useadditional numerical parameters conjunction graph structure. Examplesparameters maximum domain size variables maximum in-degreegraph. increasing number possible cases analyse, allowfine-grained analysis many cases. Consider instance case directed pathgraphs. Domshlak Dinitz (2001a) proved tractable decideplan case domains binary, Gimenez Jonsson (2009) proveddomain size 5 sufficient make problem NP-hard. Similarly, GimenezJonsson (2012) proved tractability planning instances binary variables, constantnumber prevail conditions causal graph polytree. Also paperBrafman Domshlak (2006) fits line theoretical research, exhibitingplanning algorithm runs time exponential two parameters, tree-widthundirected version causal graph maximum number times variable mustchange value.research based standard definition causal graphsset already Knoblock, although often generalisation multi-valued variables,important exceptions. One potential problem standard defintionwhenever two variables affected operator, causal graph mustnecessarily contain cycles, major reason focus mainlyplanning unary operators. attempt circumvent problem, Jonsson (2009)defined relaxed variant causal graph always introduce cyclesnon-unary operators, sometimes allow fine-grained complexity analysis.previous results relate structure causal graph complexity satisficing planning, i.e. deciding plan. also corresponding branchresearch relating structure causal graph complexity cost-optimalplanning (cf., Katz & Domshlak, 2007, 2008, 2010; Katz & Keyder, 2012).1.2 Contributionstheoretical research studies complexity planning based structure causal graph, possibly parameters like domain sizes. important577fiBackstrom & Jonssonmilestone deviates line research article Chen Gimenez(2010) even consider structure causal graph simple quantitative measure, size weakly connected components. proved decidingplan done polynomial time size weakly connected components causal graph bounded constant. one sense,sharp final result. However, intractability result unbounded componentsconditional assumtion W[1] 6 nu-FPT. assumption relies theoryparameterised complexity theory neither complexity classes assumptionrelated ordinary complexity classes clear way. Chen Gimenez acknowledge problems prove conditionally intractable include NP-intermediateproblems. Hence, take result take-off point investigationcomponent sizes reflect standard complexity classes. Since know ChenGimenez graph classes unbounded components NP-hard mustconsider restrictions order find NP-hard classes. adding newtype closure property, SP-closure, incomparable subset-closure subset minor-closure, prove planning NP-hard SP-closed graph classunbounded components. noted result still holds classacyclic graphs, important considering practical relevance acyclicitypreviously mentioned.many graph classes studied literature indeed SP-closed,also exists natural classes lack property. present one way handlingclasses aid non-uniform complexity theory. case, ableshow NP-hardness show polynomial hierarchy collapses secondlevel. fairly general result applied even component sizes growslowly graph class densely populated graphs. Also resultholds even restricted acyclic graphs. result used demonstrate clearlycomplexity results planning based class causal graphs necessarily connection complexity generic planning problemclass causal graphs. result also raises question find (preferably natural) NP-intermediate planning problems. Chen Gimenez state NP-intermediateproblems obtained using methods similiar ones employed BodirskyGrohe (2008). problems hard describe natural, though. basedLadners (1975) diagonalization technique removes large fraction input stringsproblem. apparently difficult connect graph classes constructed techniquesimple conditions component growth. alternative, show graph classescomponent sizes grow polylogarithmically NP-intermediate doubleassumption W[1] 6 nu-FPT exponential time hypothesis (Impagliazzo& Paturi, 2001) holds. also show every k > 1, exists class Gk graphscomponent size bounded |V (G)|1/k G Gk correspondingplanning problem NP-hard. results coarsely stake borderlineNP-hard NP-intermediate classes.possible conclusion paper complexity analysis planning basedstructure causal graph limited value, additional parametersneeded achieve useful results. may fair conclusion general,cases graph structure sufficient. instance, Katz, Hoffmann, Domsh578fiA Refined View Causal Graphs Component Sizeslak (2013) applied result Chen Gimenez (2010) context calledred-black planning, variant delete relaxation computing heuristics. Furthermore,even structure causal graph combined parameters,still important know behaviour parameter isolation.remainder article structured follows. Section 2 set notationterminology used planning graphs, Section 3 define causal graphsstructural planning general. Section 4 contains number NP-hardness resultsvarious special graph classes need main results. first two maintheorems article appears Section 5, define concept SP-closed graphclasses prove planning NP-hard classes component sizeunbounded. Section 6 discusses problems previous theoremsimilar results literature. way around problems, second maintheorem shows even without closure requirements, planning likely hardeven components grow slowly graphs appear densely class.Section 7 contains observations concerning borderline NP-intermediateNP-hard planning problems. article ends discussion section.2. Preliminariessection sets terminology notation planning graphs used article.write |X| denote cardinality set X length sequence X, i.e.number elements X, write ||X|| denote size representationobject X.2.1 PlanningSince article many connections one Chen Gimenez (2010)follow notation terminology plannning, notational variant SAS+(Backstrom & Nebel, 1995).instance planning problem tuple = (V, init, goal, A) whose componentsdefined follows:V finite set variables, variable v V associated finite domainD(v). Note variables necessarily propositional, is, D(v) mayfinite set. state mapping defined variables V s(v) D(v)v V . partial state mapping p defined subset vars(p) variables Vv vars(p), holds p(v) D(v), p otherwise undefined.init state called initial state.goal partial state.set operators; operator consists precondition pre(a)postcondition post(a) partial states. often use notationhpre ; posti define operator precondition pre postcondition post.instance, = hx = 0, = 1 ; z = 1i defines operator applicablestate s(x) = 0 s(y) = 1, effect setting variablez 1.579fiBackstrom & Jonssonstate partial state W subset variable set V , writeW denote partial state resulting restricting W . say stategoal state goal = vars(goal).define plan (for instance ) sequence operators P = a1 , . . . , .Starting state s, define state resulting applying plan P , denoteds[P ], inductively follows. empty plan P = , define s[] = s. non-emptyplans P define s[P ] follows, last operator P P 0 prefixP to, including, a:pre(a) 6= s[P 0 ] vars(pre(a)) (that is, preconditions satisfiedstate s[P 0 ]), s[P 0 , a] = s[P 0 ].Otherwise, s[P 0 , a] state equal post(a) variables v vars(post(a)),equal s[P 0 ] variables v V \ vars(post(a)).plan P solution plan init[P ] goal state.concerned computational problem plan existence (PlanExist): giveninstance = (V, init, goal, A), decide exists solution plan.2.2 Graphsdirected graph pair (V, E) V vertex set E V V edge set.undirected graph pair (V, E) V vertex set E {{u, v} | u, v V }edge set. often say graph edge clear context whetherdirected undirected. notation V (G) refers vertex set graph GE(G) refers edge set. e = (u, v) e = {u, v} edge, vertices uv incident e. Furthermore, directed edge (u, v) outgoing edge uincoming edge v. directed graph G = (V, E), write U (G) denotecorrespsonding undirected graph U (G) = (V, EU ) EU = {{u, v} | (u, v) E}.is, U (G) undirected graph induced G ignoring orientation edges.Let G = (V, E) directed graph let v0 , . . . , vk V v1 , . . . , vkdistinct (vi1 , vi ) E (1 k). sequence v0 , . . . , vk directedpath length k G v0 6= vk directed cycle length k G v0 = vk . Pathscycles undirected graphs defined analogously, except directionconsider. graph acyclic contains cycles.Let G = (V, E) directed graph let v V vertex. Then, v isolatedincoming outgoing edges, v source least one outgoing edgeincoming edge, v sink least one incoming edge outgoing edgeotherwise v intermediate.Let G = (VG , EG ) H = (VH , EH ) two directed graphs. G Hisomorphic (denoted G ' H) exists bijective function f : VG VH(u, v) EG (f (u), f (v)) EH . Furthermore, H subgraph G VH VGEH EG (VH VH ). EH = EG (VH VH ) say subgraph Hinduced vertex set VH . Isomorphisms subgraphs analogously definedundirected graphs.Let G undirected graph. G connected path everypair vertices G. connected component G maximal subgraph G580fiA Refined View Causal Graphs Component Sizesconnected. Let G directed graph. G weakly connected U (G) connected.weakly connected component G maximal subgraph G weakly connected.is, weakly connected component paths every pair verticesignore direction edges. Let G = (VG , EG ) H = (VH , EH ) two directedgraphs VG VH disjoint. (disjoint) union G H definedG H = (VG VH , EG EH ) commutative operation. Note graph Gconsists (weakly) connected components G1 , . . . , Gn , G = G1 G2 . . . Gn .define numeric graph parameters. directed graph G vertexv V (G), indegree v |{u V (G) | (u, v) E(G)}|, i.e. number incomingedges incident v, outdegree v |{u V (G) | (v, u) E(G)}|, i.e. numberoutgoing edges incident v. undirected graph G, degree v V (G)|{u V (G) | {v, u} E(G)}|, i.e. number edges incident v. extendgraphs follows. G undirected graph, deg(G) denotes largest degreevertex V (G). Similarly, G directed graph in-deg(G) denotes largestindegree vertex V (G) out-deg(G) denotes largest outdegree vertexV (G). Furthermore, G undirected graph, path-length(G) denotes lengthlongest path G cc-size(G) denotes size largest connected componentG. G directed graph, path-length(G) denotes length longest directed pathG. also define upath-length(G) = path-length(U (G)) cc-size(G) = cc-size(U (G)).is, upath-length(G) length longest path G ignoring directionedges cc-size(G) size largest weakly connected component G. NoteG undirected connected graph, path-length(G) equals diameter G.extend numeric graph properties (in-deg, path-length etc.) sets graphsC set graphs prop graph property, prop(C) = maxGC prop(G).2.3 Special Graph Typesliterature causal graphs, well article, certain types graphsparticular interest thus useful refer names. distinguishfollowing types undirected graphs: tree undirected graph twovertices connected exactly one path, i.e. acyclic connected. path graphtree vertices degree 1 2, i.e. tree branch. stargraph tree vertices except one, centre vertex, degree 1.directed graphs, distinguish following types: in-star graph directedgraph G U (G) star graph edges directed towards centre.out-star graph directed graph G U (G) star graph edgesdirected centre. directed path graph directed graph G U (G)path graph, in-deg(G) 1 out-deg(G) 1, i.e. G directed pathvertices contains edges. polytree directed graph G U (G)tree, i.e. G weakly connected directed graph constructed treegiving unique direction every edge. polypath directed graph G U (G)path graph, i.e. G weakly connected directed graph constructedpath graph giving unique direction every edge. fence polypath everyvertex either source sink, i.e. edges alternate direction every vertex.581fiBackstrom & Jonssonnoted out-star graph usually called directed star graphgraph theory, in-star graph appears standard name. hence deviatesligthly standard terminology order logical names graph types.Also polypath appears standard name, polypath logical termanalogy polytree. noted parallel terminology certaingraph types evolved literature causal graphs planning. instance, instars, out-stars directed paths commonly referred inverted forks, forksdirected chains, respectively.Note number sinks sources polypath differ one, i.e.polypath sinks + c sources c {1, 0, 1}. Furthermore, every fencepolypath, every polypath fence.define following graphs graphs classes:Skin denotes in-star graph one centre vertex k sources. Also defineclass Sin = {Skin | k 0}.Skout denotes out-star one centre vertex k sinks. Also define classSout = {Skout | k 0}.dPk denotes directed path k vertices. Also define class dP = {dPk | 1 k}.c , c {1, 0, 1}, denotes fence sinks + c sources. Also defineFmc | 1 m}, c {1, 0, 1}, class F = F1 F0 F+1 .class Fc = {FmExamples graph types illustrated Figure 1.v1v5v1v2vcv4v5v3v2vcv4v0v1v2v1v2u1v3u2F31v4v3S5outS5inv3dP5v1u0v2u1v3u2v1u0F30v2u1v3u2u3F3+1Figure 1: Examples important graph types.following observation polypaths used later on.Proposition 1. Let G polypath sinks + 1 sourcespath-length(G) k. |V (G)| 2mk + 1.582fiA Refined View Causal Graphs Component SizesProof. 2m distinct paths source sink,k 1 intermediate vertices. Hence |V (G)| + (m + 1) + 2m(k 1) = 2mk + 1.bound obviously tight case sinks + 1 sources,every path source sink contains exactly k 1 intermediate vertices.3. Structurally Restricted Planningtopic study article causal graphs planning, discussingconcept first define concept domain-transition graphs (Jonsson & Backstrom,1998a). Although used explicitly results, useful explainingproofs later article. Let = (V, init, goal, A) planning instance.variable v V , define domain-transition graph (DTG) v directed graph(D(v), E), x, D(v), E contains edge (x, y) operatorpost(a)(v) = either pre(a)(v) = x v 6 vars(pre(a)).causal graph planning instance describes variables instancedepends other, implicitly defined operators.Definition 2. causal graph planning instance = (V, init, goal, A) directedgraph CG() = (V, E) E contains edge (u, v) every pair distinct vertices u, v V u vars(pre(a)) vars(post(a)) v vars(post(a))operator A.causal graph gives some, all, information operators. instance,causal graph acyclic, operators must unary, i.e. |vars(post)(a)| = 1operators, since non-unary operator must necessarily introduce cycle accordingdefinition. However, presence cycles necessarily meannon-unary operators. instance, edges (u, v) (v, u) presentgraph, mean operator u vars(post(a))v vars(post(a)). However, also mean two operators a0u vars(pre(a)), v vars(post(a)), v vars(pre(a0 )) u vars(post(a0 )), couldthus unary operators. Similarly, degree vertices provides upper boundnumber pre- postconditions operators, lower bound. Supposevertex u indegree 2 incoming edges (v, u) (w, u). could meanoperator u vars(post(a)) v vars(pre(a))w vars(pre(a)). However, also mean two different operators a0v vars(pre(a)), u vars(post(a)), w vars(pre(a0 )) u vars(post(a0 )).PlanExist problem extended planning instances causal graphsfollowing way. class C directed graphs, PlanExist(C) problem decidingarbitrary planning instance CG() C, whether solutionnot. is, complexity PlanExist(C) refers complexity set planninginstances whose causal graphs members C.number results literature computational complexityplanning various classes causal graphs. However, results usually assumegraph class restricted structure, e.g. containing in-stars directedpaths. general abstract result following theorem.583fiBackstrom & JonssonTheorem 3. (Chen & Gimenez, 2010, Thm. 3.1) Let C class directed graphs.cc-size(C) bounded, PlanExist(C) solvable polynomial time. cc-size(C)unbounded, PlanExist(C) polynomial-time solvable (unless W[1] nu-FPT).theorem describes crisp borderline tractable intractable graphclasses, assumption W[1] 6 nu-FPT1 . complexityclasses theory parameterised complexity cannot immediately relatedusual complexity classes. scope article treat parameterisedcomplexity refer reader standard textbooks (Downey & Fellows, 1999; Flum& Grohe, 2006). result theorem parameterised result, however;condition parameterised, suffices note intractability result holdscondition difficult relate common assumptions, P 6= NP.One reasons Chen Gimenez forced state theorem wayclassification polynomial NP-hard classes would exhaustive,since graph classes NP-intermediate. (A problem NP-intermediateneither P NP-complete, unless P = NP.)theorem might viewed starting point research reportedarticle, investigate problem perspective standard complexityclasses. instance, NP-hardness proved case unbounded componentsadding restrictions, Section 5.4. Basic Constructionssection presents results necessary theorems later article.first three results, planning NP-hard in-stars (aka. inverted forks), out-stars(aka. forks) directed paths (aka. directed chains), known literature,NP-hardness result fences new. will, however, provide new proofs alsoin-star out-star cases. major reason Section 6 need referreductions certain precisely known properties. Furthermore, original proofspublished technical report (Domshlak & Dinitz, 2001b) may thus hardaccess.Lemma 4. (Domshlak & Dinitz, 2001a, Thm. 3.IV) PlanExist(Sin ) NP-hard. resultholds even restricted operators 2 preconditions 1 postcondition.Proof. (New proof) Proof reduction 3SAT class planning instancescausal graphs Sin . reduction constructs planning instance sourcecausal graph corresponds one variables formula centre correspondsclauses. construction illustrated Figure 2 formally defined follows.Let F = c1 . . . cm arbitrary 3SAT formula variables x1 , . . . , xn clausesc1 , . . . , cm . Construct corresponding planning instance F = (V, init, goal, A) follows:V = {vc , v1 , . . . , vn },D(vc ) = {0, . . . , m}D(vi ) = {u, f, t}, (1 n).1. condition simplified W[1] 6 FPT class C recursively enumerable.584fiA Refined View Causal Graphs Component Sizesvc012uuufv1fv2fvnFigure 2: in-star causal graph DTGs construction proofLemma 4.init(vi ) = u, (1 n), init(vc ) = 0.goal(vc ) = goal otherwise undefined.consists following operators:(1 n), contains operatorsset-f(i) = hvi = u ; vi = fset-t(i) = hvi = u ; vi = ti.clause ci = (`1i `2i `3i ) j (1 j 3), k`ji = xk `ji = xk , let contain either operatorverify-clause-pos(i, j) = hvc = 1, vk = ; vc = ii, `ji = xk ,operatorverify-clause-neg(i, j) = hvc = 1, vk = f ; vc = ii, `ji = xk .Clearly, instance F constructed polynomial time CG(F ) = Snin ,remains prove F solution F satisfiable.source variable vi changed independently. starts undefinedvalue u set either f , corresponding true false, respectively,corresponding variable xi F . set either f , cannot changed again.is, variables v1 , . . . , vn used choose commit truth assignmentx1 , . . . , xn . centre variable vc one value, i, clause ci F , plus initialvalue 0. possible reach goal value inital value 0 stepping585fiBackstrom & Jonssonintermediate values numerical order. step, 1 i,three operators choose from, corresponding literals clause ci . steppossible one v1 , . . . , vn set value consistent one literals ci .is, goal vc = achieved variables v1 , . . . , vn set valuescorresponding truth assignment x1 , . . . , xn satisfies F .restricted case (with respect pre- post-conditions) immediateconstruction above.problem known tractable, though, domain size centre variablebounded constant (Katz & Domshlak, 2010). Furthermore, causal graph heuristicHelmert (2004) based identifying in-star subgraphs causal graph,noted provided variant original proof due minor technicaldifferences problem formulations.Lemma 5. (Domshlak & Dinitz, 2001a, Thm. 3.III) PlanExist(Sout ) NP-hard. resultholds even restricted operators 1 precondition 1 postcondition.Proof. (New proof) Proof reduction 3SAT class planning instancescausal graphs Sout . reduction constructs planning instance centre vertexcausal graph corresponds variables formula sink correspondsone clauses. construction illustrated Figure 3 formally definedfollows.v1uv2vmuut0t1t2tnf0f1f2fnvcFigure 3: out-star causal graph DTGs construction proofLemma 5.Let F = c1 . . . cm arbitrary 3SAT formula variables x1 , . . . , xn clausesc1 , . . . , cm . Construct corresponding planning instance F = (V, init, goal, A) follows:586fiA Refined View Causal Graphs Component SizesV = {vc , v1 , . . . , vm },D(vc ) = {f0 , . . . , fn , t0 , . . . , tn }D(vi ) = {u, s}, (1 m).init(vi ) = u, (1 m), init(vc ) = f0 .goal(vi ) = s, (1 m), goal(vc ) undefined.consists following operators:(1 n), contains operatorsstep-c(fi1 , fi ) = hvc = fi1 ; vc = fi i,step-c(fi1 , ti ) = hvc = fi1 ; vc = ti i,step-c(ti1 , fi ) = hvc = ti1 ; vc = fistep-c(ti1 , ti ) = hvc = ti1 ; vc = ti i.clause ci = (`1i `2i `3i ) j (1 j 3), k`ji = xk `ji = xk , let contain either operatorverify-clause-pos(i, j) = hvc = tk ; vi = si, `ji = xk ,operatorverify-clause-neg(i, j) = hvc = fk ; vi = si, `ji = xk .Clearly, instance F constructed polynomial time CG(F ) = Snout ,remains prove F solution F satisfiable.Variable vc changed independently two values, ti fi ,variable xi F , corresponding possible truth values xi . additioninitial value f0 (and dummy value t0 order simplify formal definition).values tn fn reachable initial value f0 , plan correspondpath f0 , z1 , z2 , . . . , zn zi either ti fi . is, vc must pass either valueti fi , both, i. Hence, path correspond truth assignmentvariables x1 , . . . , xn F . clause ci F , corresponding variablevi change value initial value u, unsatisfied, goal value s, satisfied.vi three operators this, one literal ci . is, ci containsliteral xk (or xk ) vi change value u vc value tk (or fk ).Hence, goal v1 = . . . = vm = achieved path vccorresponds truth assignment x1 , . . . , xn satisfies F . (Note, though,vc must always follow path way fn tn since partial assignment maysometimes sufficient prove satisfiability.)restricted case (with respect pre- post-conditions) immediateconstruction above.problem known tractable, though, domain size centre variablebounded constant (Katz & Keyder, 2012).following result planning directed-path causal graphs also knownliterature.Lemma 6. (Gimenez & Jonsson, 2009, Prop. 5.5) PlanExist(dP) NP-hard, evenvariables domain size 5 operators 2 preconditions 1 postcondition.587fiBackstrom & Jonssonrefer Gimenez Jonsson proof. However, implicitly useproof later article important observations make it.reduction SAT and, thus, works also reduction 3SAT. Furthermore,reduction transforms formula n variables clauses planning instance(2m + 4)n variables. final remark, problem known tractable variablesdomain size 2 (Domshlak & Dinitz, 2001a).three previous results known literature, following result newbest knowledge.Lemma 7. PlanExist(F+1 ) NP-hard. result holds even restricted operators2 preconditions 1 postcondition.Proof. Proof reduction 3SAT class planning instances causal graphsF+1 .reduction constructs planning instance sink causal graph corresponds one clauses formula, source corresponds variables.Furthermore, source variables synchronized behaviour. construction illustrated Figure 4 formally defined follows.Let F = c1 . . . cm arbitrary 3SAT formula variables x1 , . . . , xn clausesc1 , . . . , cm . Construct corresponding planning instance F follows:V = {u0 , . . . , um , v1 , . . . , vm },D(ui ) = {f0 , . . . , fn , t0 , . . . , tn }, (0 m),u , tu , . . . , tu , f , . . . f , ts , . . . , ts , s}, (1 m).D(vi ) = {f0u , . . . , fm000init(ui ) = f0 , (0 m), init(vi ) = f0u , (1 m).goal(vi ) = s, (1 m), goal otherwise undefined.Let consist following operators:i, j (1 n, 0 j m), contains operatorsstep-x(j, fi1 , fi ) = huj = fi1 ; uj = fi i,step-x(j, fi1 , ti ) = huj = fi1 ; uj = ti i,step-x(j, ti1 , fi ) = huj = ti1 ; uj = fistep-x(j, ti1 , ti ) = huj = ti1 ; uj = ti i.i, j, (1 n, 1 j m), contains operatorsuu , f u ) = hv = f u , ustep-clause-u(j, fi1ji1 j1 = fi , uj = fi ; vj = fi i,uuuustep-clause-u(j, fi1 , ti ) = hvj = fi1 , uj1 = ti , uj = ti ; vj = ti i,step-clause-u(j, tui1 , fiu ) = hvj = tui1 , uj1 = fi , uj = fi ; vj = fiu i,step-clause-u(j, tui1 , tui ) = hvj = tui1 , uj1 = ti , uj = ti ; vj = tui i,, f ) = hv = f , ustep-clause-s(j, fi1ji1 j1 = fi , uj = fi ; vj = fi i,, ts ) = hv = f , ustep-clause-s(j, fi1ji1 j1 = ti , uj = ti ; vj = ti i,step-clause-s(j, ti1 , fi ) = hvj = ti1 , uj1 = fi , uj = fi ; vj = fis i,step-clause-s(j, tsi1 , tsi ) = hvj = tsi1 , uj1 = ti , uj = ti ; vj = tsi i,j (1 j m), contains operatorsfinalize-clause-f(j) = hvj = fns ; vj = sifinalize-clause-t(j) = hvj = tsn ; vj = si.588fiA Refined View Causal Graphs Component Sizesvi1vi+1vitu0tu1tu2tunf0uf1uf2ufnux1 cix2 cits0ts1ts2tsnf0sf1sf2sfnst0t1t2tnt0t1t2tnf0f1f2fnf0f1f2fnui1uiFigure 4: fence causal graph DTGs construction proofLemma 7. (This example assumes clause ci contains literals x1 x2 ).clause ci = (`1i `2i `3i ) j (1 j 3), k`ji = xk `ji = xk let contain either operatorverify-pos(i, j) = hvi = tuk ; vi = tsk i, `ji = xk ,operatorverify-neg(i, j) = hvi = fku ; vi = fks i, `ji = xk .+1 . Hence,Clearly, instance F constructed polynomial time CG(F ) = Fmremains prove F solution F satisfiable.First consider variables ui vi , i. construction domainoperators ui identical one vc proof Lemma 5, i.e.directed path value f0 fn tn every possible truth assignment variablesx1 , . . . , xn F . Variable vi , corresponds clause ci contains two copies DTGui , values differ extra superscript, u s. latter copy extendedadditional value s, denoting clause satisfied. operatorsallows vi mimic behaviour ui ; follow corresponding path eithertwo copies. Furthermore, three literals ci operator589fiBackstrom & Jonssonmakes possible move value zku value zks value zk ui consistentts order reach goal valueliteral. Since vi starts f0u must reach either fms, necessary vi make transition one literals ci . is, uifollows path f0 , z1 , . . . , zn vi must follow path f0u , z1u , . . . , zku , zks , . . . , zns , s,k xk occurs literal ci zk satisfying truth value literal.consider also variable ui1 . Since operator affects value vi eitherprecondition ui1 ui precondition either, followsui1 ui must choose path vi reach goal. Since every variable vjforces synchronization adjacent variables uj1 uj manner, followsu0 , . . . , um must choose exactly path plan solution. thusfollows argument ui vi goal v1 = . . . = vm =achieved path u0 , . . . , um choosepath corresponds satisfying truth assignment F .restriction, first note immediate construction operators3 preconditions 1 postcondition sufficient. see 2 preconditionssufficient, consider following variation construction. step-clause-u stepclause-t operator replaced two operators follows. example, consideru , tu ). First introduce extra value f tu D(v ). replaceoperator step-clause-u(j, fi1joperator two new operatorsu , f tu ) = hv = f u , uustep-clause-u(j, fi1ji1 j1 = ti ; vj = f tistep-clause-u(j, f tui , tui ) = hvj = f tui , uj = ti ; vj = tui i.uConsider step DTG vj fi1tui . original construction,u , tu ), requires udone single operator step-clause-u(j, fi1j1 ujuvalue ti . modified construction instead requires two steps, first step fi1uunew intermediate value f ti step value ti . previousconjunctive constraint uj1 = uj = ti replaced sequential constraint firstuj1 = ti uj = ti . Although technically possible uj1 movednew value second step taken, matter; uj1 uj muststill choose exactly path respective DTGs.Corollary 8. PlanExist(F1 ), PlanExist(F0 ) PlanExist(F) NP-hard.Proof. Neither two outer source vertices, u0 um , necessary constructionprevious proof. Hence, omitting either reduction works alsoF1 F0 . Finally, PlanExist(F) NP-hard since F+1 F.basic results necessary main theorems followingtwo sections.5. Graph Classes Closure PropertiesLike results literature, results previous section classesconsisting particular graph type, like class Sin in-stars class Ffences. section depart instead study graph classes certainclosure properties. first discuss standard concepts subgraph closure minorclosure, finding first contain graphs need latter results590fiA Refined View Causal Graphs Component Sizesset many graphs. reason, define new concept, SP-closure,incomparable subgraph closure subset minor closure.show closure concept defines borderline non-NP-hard graph classeslarge number useful NP-hard classes.5.1 Subgraph Closure Minor ClosureSuppose C class graphs closed taking subgraphs. every graphG C case every subgraph H G must also C. Subgraph closuresufficient purposes, though. instance, subgraph polypath alwayseither polypath graph every weakly connected component polypath.However, polypath need subgraphs fences trivial size.need closure property guarantees C contains polypath sinks,also contains fence sinks. obvious candidate conceptminor-closure, superset subgraph-closure. concepts graph minorsminor-closure rapidly evolved important useful research areamathematical well computational graph theory (Lovasz, 2005; Mohar, 2006).order define graph minors first need concept edge contraction,commonly defined follows, although definitions occur literature.Definition 9. Let G = (V, E) directed graph let e = (u, v) E edgeu 6= v. contraction e G results new graph G0 = (V 0 , E 0 ),V 0 = (V \ {u, v}) {w}E 0 = {(f (x), f (y)) | (x, y) E, (x, y) 6= (u, v) (x, y) 6= (v, u)},w new vertex, V , function f : V V 0 definedf (u) = f (v) = w otherwise f (x) = x.is, edge (u, v) contracted, two vertices u v replacedsingle new vertex w edges previously incident either u vredirected incident w. Figure 5 shows example edge contraction. saygraph H contraction another graph G H result contracting zeroedges G.concept graph minors defined follows.Definition 10. directed graph H minor directed graph G H isomorphicgraph obtained zero edge contractions subgraph G.example illustrated Figure 6. graph G figure weakly connecteddirected graph, also happens polypath. vertex v9 removed G,restriction remaining vertices still weakly connected graphsubgraph G. Removing also v4 results graph H, consists two weaklyconnected components H1 H2 . H, H1 H2 subgraphs G,also minors G, since subgraph minor, definition. Contracting edge (v1 , v2 )H1 results graph M1 , w1 new vertex replacing v1 v2 . Similarly,contracting edge (v8 , v7 ) H2 results M2 . graph M1 minor G since591fiBackstrom & Jonssonv9v9v10v8v10v8v2v7v5v7v1v6v5wv6v3v4a) graph Gv3v4b) result contracting edge (v1 , v2 ) G.Figure 5: Edge contraction.result edge contraction subgraph H1 G graph M2 analogouslyminor G too. Also graph , consisting two components M1 M2minor G, since result two contractions subgraph H G.graphs H, H1 H2 subgraphs minors G, graphs , M1 M2minors G, subgraphs.v6v3v2v5v4v6v7v3v8v1a) polypathv7v2v9Gv5v3v8w1v5M1v1H1v6w2M2H2b) subgraph H G(where H = H1 H2 )c) minor G(where = M1 M2 )Figure 6: Subgraphs minors.trivial example minor-closed class class graphs, minor-closedsince contains graphs every minor graph graph. interestingly,many commonly studied graph types result minor-closed classes. instance, classSin in-stars minor-closed, class Sout out-stars class dP592fiA Refined View Causal Graphs Component Sizesdirected paths. Furthermore, weakly connected minor polypath polypathweakly connected minor polytree polytree. illustration, considerFigure 6. graph G polypath, weakly connected graphs H1 , H2 , M1M2 minors G, also polypaths. fact, M1 M2 also fences.Note though, neither H polypath, since consist oneweakly connected component. worth noting, however, class F fencesminor-closed although every fence polypath; weakly connected minor fencemust polypath, necessarily fence.Requiring minor-closed graph classes is, however, overly strong. instance, wouldsufficient require every graph G C, also every weakly connected minor GC. is, example Figure 6 would require H1 , H2 , M1 M2C G C, would require also H C.reasonable desirable context causal graphs. causal graph planninginstance consists two weakly connected components, componentscorrespond entirely independent subinstances solved separately.Furthermore, certain natural restrictions mix well minor-closed classes.Consider, instance, example Figure 7, acyclic graph G = (V, E),V = {v1 , v2 , v3 , v4 } E = {(v1 , v2 ), (v2 , v3 ), (v3 , v4 ), (v1 , v4 )}. contract edge(v1 , v4 ) new vertex w get cycle graph vertices w, v2 , v3 . is, classacyclic graphs minor-closed general, problematic considering importance acyclic causal graphs.v1v2v4v3v2wa) acyclic graph Gv3b) contraction (v1 , v4 ) G.Figure 7: Contracting edge acyclic graph result cycle.5.2 SP-Closed Graph Classesorder avoid problems acyclicity (and similar problems) avoid definingspecial variants contraction minor concepts, instead identify set minimalrequirements closure must satisfy order imply NP-hardness PlanExistproblem. focus one set restrictions, defining concept referSP-closure (where SP denotes set closed stars polypaths).Definition 11. Let G H two directed graphs. H SP-graph G Hweakly connected either following holds:1. H in-star subgraph G,593fiBackstrom & Jonsson2. H out-star subgraph G3. H obtained zero contractions polypath G0 G0subgraph G.class C graphs SP-closed contains every SP-graph every graph G C.SP-closure number interesting properties, including following:Proposition 12. Let G H directed graphs let C class directed graphs.1. G polypath, every SP-graph G polypath.2. Every SP-graph G acyclic.3. H SP-graph G, H minor G.4. C minor-closed, C SP-closed.Proof. 1) Suppose G polypath. Obviously, G cannot contain in-star out-starhigher degree two, star also polypath. Hence, needconsider third case definition. note weakly connected subgraph G0G must also polypath, contractions polypath results polypath.2) Immediate since in-stars, out-stars polypaths acyclic contracting edgescannot introduce cycle cases.3) Immediate definitions minors SP-graphs.4) Immediate 3.proposition says makes sense talk SP-closed classes polypathsSP-closed classes acyclic graphs. also says SP-closure minor-closurecomparable concepts; SP-closure class subset minor-closureclass.prove following result SP-closed classes polypaths,need main theorem.Lemma 13. Let C SP-closed class polypaths. cc-size(C) unbounded,PlanExist(C) NP-hard. result holds even restricted operators2 preconditions 1 postcondition.Proof. Proof cases depending whether directed path length C bounded not.Case 1: Suppose path-length(C) unbounded. Let n > 1 arbitrary integer.must graph G C G contains subgraph H directedpath graph V (H) = n. Obviously, H SP graph G, since directed pathalso polypath. follows H C since C SP-closed. Furthermore, H ' dPnNP-hardness PlanExist(C) follows Lemma 6, since n choosen arbitrarily.Case 2: Instead suppose path-length(C) k constant k 0. Let n > 1arbitrary integer. Since graphs C polypaths cc-size(C) unbounded,must polypath G C V (G) n. thus follows assumptionProposition 1 G must least sinks + 1 sources,594fiA Refined View Causal Graphs Component SizesV (G) 2mk + 1. must, thus, subgraph G0 G polypathexactly sinks + 1 sources (i.e. G0 weakly connected) must, thus, also+1 .graph H obtained zero contractions G0 H ' Fmfollows H C since C SP-closed. NP-hardness PlanExist(C) thus followsLemma 7, since n choosen arbitrarily k constant.see result holds even operators consideration 2preconditions 1 postcondition, simply note restriction holds reductionsused underlying NP-hardness proofs Section 4.Chen Gimenez (2010, Thm. 3.19) proved similar result: C class polypaths2unbounded components unbounded number sources, PlanExist(C)polynomial-time solvable unless W[1] nu-FPT.order prove main result section, also need Moore bound (Biggs,1993, p. 180), stated follows: arbitrary connected undirected graph G,maximum number vertices|V (G)| 1 +k1X(d 1)i ,(1)i=0= deg(G) k = path-length(G).prove additional restriction graph classes SPclosed, avoid NP-intermediate problems prove NP-hardness graph classesunbounded components.Theorem 14. Let C SP-closed class directed graphs. cc-size(C) unbounded,PlanExist(C) NP-hard. result holds even restricted operators2 preconditions 1 postcondition graphs C acyclic.Proof. First suppose constant k in-deg(C) k, out-deg(C) kupath-length(C) k. Consider arbitrary graph G C. Obviously, deg(U (G)) 2kpath-length(U (G)) k, Pfollows Moore bound component U (G)1 + 2k k1i=0 (2k 1) vertices. However, since cc-size(G) = cc-size(U (G))G choosen arbitrarily, follows cc-size(C) bounded. contradictsassumption least one in-deg(C), out-deg(C) upath-length(C) unbounded.remainder proof three (possibly overlapping) cases.Case 1: Suppose in-deg(C) unbounded. Let n > 0 arbitrary integer.must graph G C containing vertex indegree n more, mustalso subgraph H G H ' Snin . Hence, H C since C SP-closed. thusfollows Lemma 4 PlanExist(C) NP-hard, since n choosen arbitrarily.Case 2: Suppose out-deg(C) unbounded. case analogous previousone, using Lemma 5 instead Lemma 4.Case 3: Suppose upath-length(C) unbounded. Let n > 0 arbitrary integer.must graph G C U (G) contains path length n,must, thus, also subgraph H G H polypath length n. Obviously, H2. Chen Gimenez use term source-sink configuration polypath.595fiBackstrom & JonssonSP-graph G (doing zero contractions) H C since C SP-closed. thus followsLemma 13 PlanExist(C) NP-hard, since n choosen arbitrarily.see result holds even operators consideration 2preconditions 1 postcondition, simply note restriction holds reductionsused underlying NP-hardness proofs Section 4. Similarly, acyclicity restrictionholds since result based in-stars, out-stars polypaths,acyclic graphs.theorem somewhat restricted one Chen Gimenez sincerequires additional constraint C SP-closed. hand, demonstratesSP-closure sufficient condition avoid graph classes PlanExist NPintermediate and, thus, sharpen result NP-hardness. noted, though,exact characterization graph classes NP-hard PlanExist.graph classes, SP-closure captures large number interestinggraph classes. instance, class acyclic graphs SP-closed (recall classminor-closed), although every subclass SP-closed. opposite example,non-empty class contain single acyclic graph cannot SP-closed.6. Beyond SP-Closed Graph Classessection divided three parts. first discuss previous results, wellsimilar NP-hardness results literature, problematic, motivatesus switch non-uniform complexity theory. second part contains numberpreparatory results required main theorem third part.6.1 NP-Hardness Enoughrefer planning problem generic instances varying size, dependingone parameters. archetypical example blocks world, naturalparameter number blocks. particular encoding specified numberblocks, variables operators whatever inital state goal is.is, fix encoding get planning frame n = (Vn , ) every number,n, blocks. is, n instances n blocks thus functionn. instances (Vn , init, goal, ) n blocks instantiations n differentinit goal components Vn components. instance thusspecified three unique parameters, n, init goal, first parameter,n, affects size instance. Furthermore, causal graph instance dependsvariables operators, means instantiations frame ncausal graph, denote CG(n ). class causal graphs blocksworld instances = {CG(1 ), CG(2 ), CG(3 ), . . .}, although 1 , 2 , 3 , . . .,thus also D, differ depending encoding.often possible analyse complexity particular generic planning problem.Examples complexity blocks-world planning (Gupta & Nau, 1992)complexity various problems International Planning Competitions (IPC)(Helmert, 2003, 2006b). context article, though, rather interestedcomplexity class causal graphs corresponding generic problem,596fiA Refined View Causal Graphs Component Sizescomplexity specific problem itself. Suppose class causal graphshappens subset class C graphs know PlanExist(C)tractable. infer also PlanExist(D) tractable, thus alsogeneric planning problems causal graphs tractable. However, orderprove PlanExist(D) NP-hard (or hard complexity class) wouldprove class C graphs PlanExist(C) NP-hard Csubset D. Finding class C may trivial, though.One problem encoding large influence densely sparselycausal graphs occur respect size. Consider, instance, blocks world encodingsmulti-valued variables boolean variables respectively. typical encodingmulti-valued variables use one variable status hand two variablesblock, one position block one flag whether block clearnot. is, encodings use 2n + 1 variables n-block frame. encodingboolean variables, hand, typically represent block positionnumber boolean variables, one block block on. booleanencoding thus use n2 + 1 variables n-block frame. contain graphevery odd number vertices first case, increasingly sparse secondcase. class causal graphs generic planning problem will, thus, typicallySP-closed, even closed taking subsets. Furthermore, since typicallycontain member every possible number vertices, cannot possibly containknown NP-hard sets Sin , Sout , dP etc. subset. Hence, order proveclass causal graphs hard NP (or complexity class), oftennecessary make dedicated proof D. often doable, however. genericplanning problem corresponding function f takes parameter value n, e.g.number blocks blocks world, f (n) = n . f furthermore polynomialtime computable value n, often case, also correspondingcausal graph, CG(n ), polynomial-time computable. However, even donemany generic planning problems, specific proof every specific encodingevery particular generic planning problem. holds particular classes causalgraphs; every specific class typically require dedicated proof.order get around problems able prove general resultdepend specific planning problems causal graphs, switch nonuniform complexity. makes possible prove powerful results, retainingnatural connections ordinary complexity classes. basic vehicle proving nonuniform complexity results advice-taking Turing machine, defined follows.Definition 15. advice-taking Turing machine associated sequence advicestrings A0 , A1 , A2 , . . ., special advice tape advice function A, naturalnumbers advice sequence, s.t. A(n) = . input x advice tape immediatelyloaded A(||x||). continues like ordinary Turing machine, exceptalso access advice written advice tape.exists polynomial p s.t. ||A(n)|| p(n), n > 0, said usepolynomial advice. complexity class P/poly set decision problemssolved advice-taking TM runs polynomial time using polynomial advice.597fiBackstrom & JonssonNote advice depends size input, content, needeven computable. Somewhat simplistically, advice-taking Turing machinemachine infinite data-base constant access time. However, inputsize polynomial amount information might exponentialnumber instances sharing information. power polynomial advice thus stillsomewhat limited useful relationships known non-uniform complexityclasses relate standard ones known. One result following.Theorem 16. (Karp & Lipton, 1980, Thm. 6.1) NP P/poly, polynomialhierarchy collapses second level.6.2 Preparatory Resultscarrying main theorem section, need auxiliary results.first show planning instance causal graph G subgraph graphH, instance extended equivalent instance H causal graph.Lemma 17. Let planning instance let G directed graph CG()subgraph G. planning instance GG constructed polynomial time,CG(G ) = GG solution solution.Furthermore, G maximum number pre- postconditions operators(or one value zero ).Proof. Let = (V, init, goal, A) planning instance let CG() = (V, E). LetG = (VG , EG ) directed graph CG() subgraph G. Let U = VG \ V .Construct planning instance G = (VG , initG , goalG , AG ) follows:DG (u) = {0, 1}, u U ,DG (v) = D(v) {?}, v V , (where ? new value D(v)).initG (v) = init(v), v V ,initG (u) = 0, u U .goalG (v) = goal(v), v V ,goalG (u) undefined u U .Let AG consist following operators:Let AG contain A.edge (x, v) EG \ E x VG v V , let AG also containoperator star(x, v) = hx = 0 ; v = ?i.edge (x, u) EG x VG u U , let AG also containoperator set(x, u) = hx = init(x) ; u = 1i.598fiA Refined View Causal Graphs Component SizesObviously G constructed polynomial time CG(G ) = G, remainsprove G solution solution.Suppose P = a1 , . . . , plan . P also plan G since goalG (u)undefined u U a1 , . . . , AG . contrary, suppose P = a1 , . . . ,plan G . operator ai P , three cases: (1) ai A, (2) ai setoperator (3) ai star operator. case 2, operator ai serves purpose sincemodifies variable U , undefined goal value. case 3, operator ai setsvariable v V ? effect variables. goalG (v) undefined,ai serves purpose. Otherwise must operator aj , j > i, ajchange v ? value D(v), i.e. ai serves purpose case either.follows operator sequence P 0 obtained P removing operatorsalso plan G . Furthermore, since P 0 contains operatorsalso plan . follows plan G plan.construction increases maximum domain size one little effectmaximum number pre- postconditions. suitable purpose, sinceconsider influence domain sizes article. constructionspossible want balance various factors differently.proof forthcoming theorem also opposite taking graphminors, is, starting minor G target graph H extend G H.order so, need operation similar opposite edge contraction.satisfied graph operation known edge subdivision.Definition 18. Let G = (V, E) directed graph let (u, v) E edgeu 6= v. subdivision (u, v) G graph G0 = (V {w}, E 0 ) w newvertex E 0 = (E \ {(u, v)}) {(u, w), (w, v)}.Although one might consider definitions, e.g. case (u, v)(v, u) E, one sufficient purpose follows usual extensiondirected graphs (cf., Kuhn, Osthus, & Young, 2008). Usually operation called smoothingconsidered inverse edge subdivision. However, smoothing viewedrestricted case edge contraction, reasonable think edge subdivision sortinverse edge contraction. example edge subdivision illustrated Figure 8.note like edge contraction polypath polypath, also edgesubdivision polypath polypath.also need operation planning instances corresponding edge subdivisioncausal graphs. purpose, need concept variable substitutionoperators. denote substitution variable w variable v partial statea[v/w], defined as:x = w,s(v),s(x),x vars(s) \ {v, w},s[v/w](x) =undefined, otherwise.operator, operator a0 = a[v/w] defined pre(a0 ) = pre(a)[v/w]post(a0 ) = post(a)[v/w].599fiBackstrom & Jonssonv9v9v10v8v10v8v2v7v5v7v1v6v3a) graph Gv2v6v4wv5v1v3v4b) result subdividing edge (v1 , v2 ) G.Figure 8: Edge subdivision.necessary concepts modifying arbitrary planning instanceresult corresponds subdividing edge causal graph instance.However, need instances causal graph polypath.proving done, first need following lemma, statescertain reordering property plans causal graph polypath. choosearbitrary vertex v polypath G remove v G, G falls apart two weaklyconnected components C1 C2 . words, vertices G partitionedthree sets C0 , C1 C2 C0 = {v} edge directlyvertex C1 vertex C2 . follows definition causal graphsoperator changes variable C1 precondition variableC2 vice versa. following lemma utilises fact prove sequenceoperators change variable v reordered operatorschange variables C1 come operators change variables C2 .Lemma 19. Let = (V, init, goal, A) planning instance G = CG()polypath. Let v arbitrary variable V , let C0 = {v} let C1 , C2 V two(possibly empty) weakly connected components G result vertex v removedG. Define Ai = {a | vars(post(a)) Ci } (0 2). Let P plan .Let P1 , P2 Q operator sequences P = P1 , Q, P2 Q contains operatorA0 . Let Q1 subsequence Q containing operators A1 let Q2subsequence Q containing operators A2 . P1 , Q1 , Q2 , P2 plan.Proof. Assume C0 , C1 C2 defined lemma recall C0 = {v}. Firstnote G acyclic since polypath, operators unary. follows{A0 , A1 , A2 } partition and, thus, A0 A1 A2 = A. Let s0 = init[P1 ].Obviously, (vars(pre(a))C2 = (vars(post(a))C2 = Q1 (vars(pre(a))C1 =(vars(post(a)) C1 = Q2 , i.e. state holds s[a] C2 = C2Q1 s[a] C1 = C1 Q2 . Furthermore, state holds600fiA Refined View Causal Graphs Component Sizess[a](v) = s(v) Q, since 6 A0 . follows s0 [Q] C1 = s0 [Q1 ] C1s0 [Q] C2 = s0 [Q2 ] C2 . Hence,s0 [Q1 , Q2 ] C0 = s0 [Q] C0 ,s0 [Q1 , Q2 ] C1 = s0 [Q1 ] C1 = s0 [Q] C1s0 [Q1 , Q2 ] C2 = s0 [Q2 ] C2 = s0 [Q] C2 .is, s0 [Q1 , Q2 ] = s0 [Q] follows also P1 , Q1 , Q2 , P2 plan .prove planning instance CG() polypath,subdivide edge CG() create planning instance 0 CG(0 )subdivision CG() 0 solvable solvable.Lemma 20. Let planning instance CG() polypath let eedge CG(). planning instance 00 constructed polynomial time,CG(0 ) edge subdivision e CG()0 solution solution.Proof. Let = (V, init, goal, A) planning instance CG() polypathlet e = (u, v) edge CG(). Construct new instance 0 = (V 0 , init0 , goal0 , A0 )follows:V 0 = V {w}, D(w) = D(u) w 6 V .init0 (v) = init(v), v V ,init0 (w) = init(u).goal0 = goal.Let A0 consist following groups operators:1. Let A0 contain operators u 6 vars(pre(a)) v 6 vars(post(a)).2. Let A0 contain operator a[u/w] every operatoru vars(pre(a)) v vars(post(a)).3. Let A0 contain operator copy(u, w, x) = hu = x ; w = xi every valuex D(v).operators group 1 original operators corresponding edgesCG() except (u, v). operators group 2 operators correspondingedge (u, v) modified instead correspond new edge (w, v). operatorsgroup 3 correspond new edge (u, w) defined variable wmimic variable u. Clearly, polynomial-time construction CG(0 ) edgesubdivision CG(). remains prove 0 plan plan.If: Suppose P = a1 , . . . , plan . Construct new operator sequence P 0A0 P follows: First, ai P u vars(pre(ai )) vvars(post(ai )), replace ai ai [u/w]. Then, ai P u vars(post(ai )),601fiBackstrom & Jonssonlet x = post(ai )(u) add operator copy(u, w, x) ai ai+1 . resultingsequence P 0 plan 0 .if: Suppose P = a1 , . . . , plan 0 . Define corresponding state sequences0 , . . . , sn s0 = init0 si = s0 [a1 , . . . , ai ] (1 n). Without losinggenerality, assume P shortest plan 0 , implies ai applicablesi1 every (1 n). Define three variable sets C0 , C1 C2 Lemma 19C0 = {w}, v C1 u C2 . Also define corrsponding partition {A0 , A1 , A2 }A0 , i.e. Ai = {a A0 | vars(post(a)) Ci } (0 2). A0 contains copyoperators nothing else. proving main result direction, first provefollowing auxiliary result:According Lemma 19 assume every longest subsequence ak , . . . , a`contain operator A0 form ak , . . . , , am+1 , . . . , a`ak , . . . , A1 am+1 , . . . , a` A2 . Since longest sequence, musthold either (1) k = 1 (2) ak1 A0 . case (1) sk1 = s0 = init0 ,sk1 (u) = sk1 (w) since init0 (u) = init0 (w). case (2) operator ak1 = copy(u, w, x)x sk1 (w) = sk2 (u) = x. Hence, sk1 (u) = sk1 (w) = x since ak1change u. is, either case sk1 (u) = sk1 (w). Furthermore,(k m) holds si (C0 C2 ) = sk1 (C0 C2 ) since ai A1 . followssi (u) = si (w) (k m). Now, every (k `), w vars(pre(ai ))ai must form a[u/w], A, v vars(pre(ai )) definition. Hence,ai A1 follows si1 (u) = si1 (w). Since proof holds longestsubsequences containing operator A0 conclude following,used below:(*) operator ai P ai = a[u/w] A, holdssi1 (u) = si1 (w).prove main result direction, also plan since 0plan. constructing plan P 00 P two steps. First constructintermediate operator sequence P 0 construct plan P 00 P 0 . sequenceP 0 technically plan either 0 , intermediate step makes proofclearer. Temporarily introduce virtual dummy operator dum preconditionpostcondition, i.e. applicable state effect. constructnew operator sequence P 0 = b1 , . . . , bn {dum} follows:ai A, bi = ai .ai copy operator, bi = dum.Otherwise, ai = a[u/w] operator A, let bi operator a.Define corresponding state sequence t0 , . . . , tn t0 = init0 ti = t0 [b1 , . . . , bi ](1 n). claim ti V = si V (0 n). Proof inductioni:Basis: t0 = s0 definition.Induction: Suppose ti1 V = si1 V (1 n). three cases:(1) ai = bi ai A. w pre- postcondition either ai bibi applicable ti1 since ai applicable si1 ti1 V = si1 V assumption.Furthermore, ti V = ti1 [bi ] V = si1 [ai ] V = si V .602fiA Refined View Causal Graphs Component Sizes(2) ai copy operator bi = dum. immediate definition biapplicable ti1 ti = ti1 . Furthermore, vars(post(ai )) V =si V = si1 V . Since ti1 V = si1 V assumption thus follows ti V = si V .(3) ai bi [u/w] bi A. follows (*) si1 (w) = si1 (u), si1 (w) =ti1 (u) since u V ti1 V = si1 V assumption. Since ai applicable si1 ,pre(ai )(w) = pre(bi )(u) pre(ai )(x) = pre(bi )(x) variables V \{u}, followsbi applicable ti1 . definition, vars(post(bi )) = vars(post(ai )) = {v}, since aibi must unary, thus also follows definition post(bi ) = post(ai ).Hence, also follows ti V = si V , since ti1 V = si1 V assumption.thus shown ti V = si V (0 n). Furthermore, clearlyti = ti1 bi = dum. follows create plan P 00removing dummy operators P 0 .conclude solution 0 solution.finally need following observations 3SAT instances. Let F 3SATformula n variables clauses. contains repeated clauses,n8n3 and, thus, ( )1/3 n 3m.38Furthermore, F represented list 3m literals requires 3m(1 + log n)3m(1 + log 3m) bits, plus overhead. Hence, F represented cm2 bits,constant c, later use upper bound 40m3 , safe.also note reduction used proof Lemma 6 transforms 3SATinstance n variables clauses planning instance N = (2m + 4)nvariables. However, n 3m N (2m + 4) 3m = 6m2 + 12m, safelyoverestimated N 18m2 .6.3 Main Theoremprepared state prove main theorem section. followsproof Theorem 14 in-deg(C), out-deg(C) upath-length(C) boundedclass C graphs, cc-size(C) bounded. case immediate Theorem 3planning tractable C. begs question happens parametersbounded constant, yet bounded slow-growing function? considercase allowed grow slowly, long polynomially relatedinstance size. Since also noted practical planning problems typicallycausal graph every size, require every graph G Cmust also larger graph G0 C size p(|G|), polynomial p.also define parameter (G) = max{upath-length(G), in-deg(G), out-deg(G)}, require(G) ||G|| polynomially related. turns planning still hardrestrictions, following theorem says.Theorem 21. Let p q increasing polynomials natural numbers. Let Cclass directed graphs containing subset weakly connected graphs G1 , G2 , G3 , . . .that:1. |V (G1 )| p(q(1)),|V (Gi1 )| < |V (Gi )| p(|V (Gi1 )|), > 1,603fiBackstrom & Jonsson2. |V (Gi )| q( (Gi )), 1.PlanExist(C) polynomial-time solvable, polynomial hierarchy collapses. result holds even restricted operators 2 preconditions 1 postconditiongraphs C acyclic.Proof. Let G1 , G2 , G3 , . . . sequence weakly connected graphs C assumedtheorem. Let H1 , H2 , H3 , . . . sequence graphs defined follows: > 0,Hi = Gj smallest j q(i) |V (Gj )|.first prove underestimates (Hi ). Combining requirement q(i)|V (Gj )| condition 2 theorem, |V (Gj )| q( (Gj )), get q(i) |V (Gj )|q( (Gj )). Since Hi = Gj get q(i) |V (Hi )| q( (Hi )), is, (Hi ).follows also |V (Hi )| holds.prove |V (Hi )| polynomially bounded p(q(i)). Since j choosensmallest value satisfying q(i) |V (Gj )|, must either j = 1 |V (Gj1 )| <q(i). j = 1, Hi = Gj = G1 |V (G1 )| p(q(1)) condition 1 theorem.Hence, |V (Hi )| = |V (G1 )| p(q(1)) p(q(i)), since p q increasing. Otherwise,j > 1, condition 1 lemma says |V (Gj )| p(|V (Gj1 )|). Combininginequality |V (Gj1 )| < q(i) yields |V (Gj )| p(|V (Gj1 )|) < p(q(i)),is, |V (Hi )| p(q(i)) since Hi = Gj . Combining previous result|V (Hi )| construction Hi yields H1 , H2 , H3 sequence graphsnon-decreasing unbounded size.Now, define sequence A0 , A1 , A2 , . . . tuples 0, eitherfollowing holds:1. in-deg(Hi ) Ai = (in-deg, Hi , Xi ) Xi subgraph Hi Xi ' Siin .2. out-deg(Hi ) Ai = (out-deg, Hi , Xi ) Xi subgraph HiXi ' Siout .3. upath-length(Hi ) Ai = (upath-length, Hi , Xi ) Xi subgraph HiXi polypath length i.every > 0, least one three cases must hold since (Hi ).Define advice-taking Turing machine uses sequence A1 , A2 , A3 , . . .advice takes 3SAT formulae input. Assume representation formulaF padded size 40m3 bits, number clauses. Although somewhatredundant, still reasonable encoding sense Garey Johnson (1979).Let work follows. Let F input formula n variables clauseslet = ||F || = 40m3 . advice = (x, Ht , Xt ). First constructs planninginstance F . three cases depending x:x = in-deg: construction, Xt subgraph Ht Ht ' Stin . Since = 40m3n 3m, follows n t, Xt contains subgraph H 0 H 0 ' Snin .Construct F way proof Lemma 4, using vertices H 0variables. Then, CG(F ) = H 0 .x = out-deg: Analogous previous case, constructing F according proofLemma 5 instead.604fiA Refined View Causal Graphs Component Sizesx = upath-length: construction, Xt subgraph Ht polypath length= 40m3 . Suppose Xt contains less sinks + 1 sourcespath-length(Xt ) < 18m2 . follows Proposition 1|V (Xt )| < 2m 18m2 + 1 = 36m3 + 1 < 40m3 = t.However, contradicts construction Xt must either contain directed pathlength 18m2 least sinks + 1 sources.1. Xt contains subgraph H 0 directed path length 18m2 ,construct planning instance F according proof Lemma 6, usingvertices H 0 variables. Then, CG(F ) ' H 0 .2. Xt contains subgraph H 0 polypath sinks m+1 sources,construct planning instanceF according proof Lemma 7, us0+1ing variables H variables. Then, CG(F ) ' Fm . graphfence, i.e. polypath directed paths length 1. pathstretched directed path arbitrary length repeatedly applyingLemma 20. graph H 0 polypath used templatepaths CG(F ) stretch much order get graph0isomorphic H . InstanceF thus modified new instance FCG(F ) ' H 0 .constructions done polynomial time, cases, Fsolution F satisfiable. Furthermore, CG(F ) isomorphic subgraphHt four cases. According Lemma 17 thus possible extend F new++planning instance +F CG(F ) ' Ht F solutionsolution. extension done polynomial time according lemma.Since PlanExist(C) solved polynomial time assumption theorem,thus follows solve 3SAT polynomial time. However, impliesNP P/poly, impossible unless polynomial hierarchy collapses (Theorem 16).see result holds even operators consideration 2preconditions 1 postcondition, simply note restriction holds reductionsused underlying NP-hardness proofs Section 4. Similarly, acyclicity restrictionholds since result based in-stars, out-stars polypaths,acyclic graphs.Recall generic blocks world encoding discussed beginningsection. class causal graphs blocks-world instances satisfies requirements Theorem 21, means PlanExist(D) likely tractable. However,finding non-optimal plans blocks world tractable; plan length twicelength optimal plan found polynomial time (Gupta & Nau, 1992). is,likely difficult problems blocks world happen exactlycausal graphs, illustrates complexity generic planning problemcannot deduced corresponding class causal graphs alone.605fiBackstrom & Jonsson7. NP-Hard NP-Intermediate Classestheorem Chen Gimenez (2010) states crisp complexity-theoretic borderline:component sizes bounded constant, planning polynomial-time solvableand, otherwise, planning polynomial-time solvable. exploited extraconstraint, SP-closure, able prove NP-hardness, leaves greyzonepolynomial cases NP-hard ones. longer require classes SPclosed, longer obviously NP-hard even components unbounded.natural question arises, say something middle ground?instance, say something NP-intermediate cases may look likeborderline NP-hard NP-intermediate is? Although seemlikely could find results characterize borderline exactly,least give partial answers questions. proving two theoremsrelated growth rate components. first shows planning stillNP-hard components grow O(|V (G)|1/k ) integers k, second one showsplanning likely NP-intermediate components grow polylogarithmically.Theorem 22. every constant integer k > 1, class Gk graphscc-size(G) |V (G)|1/k G Gk PlanExist(Gk ) NP-hard.Proof. Let k > 1 arbitrary integer. Construct graph class Gk = {G1 , G2 , G3 , . . .}follows. > 0, let Gm mk1 components, isomorphic dPm ,i.e. |V (Gm )| = mk components size = |V (Gm )|1/k . prove NP-hardnessPlanExist(Gk ) reduction PlanExist(dP). Let arbitrary planning instanceCG() dP. CG() = dPm > 0. Construct new instance 0consists mk1 renamed copies . clearly polynomial time constructionsince k constant < ||||. Furthermore, CG(0 ) isomorphic Gm 0solution solution. Hence, polynomial reduction followsLemma 6 PlanExist(Gk ) NP-hard.Obviously, size graphs exponential k.second result must conditioned assumption exponential timehypothesis (Impagliazzo & Paturi, 2001; Impagliazzo, Paturi, & Zane, 2001) holds.hypothesis conjecture stated follows.Definition 23. constant integers k > 2, let sk infimum real numbersk-SAT solved O(2n ) time, n number variablesinstance. exponential time hypothesis (ETH) conjecture sk > 0 k > 2.Informally, ETH says satisfiability cannot solved subexponential time. ETHarbitrarily choosen concept, quite strong assumption allowsdefining theory similar one NP-completeness. concept called SERF(subexponential reduction family) reduction preserves subexponential time solvability. also concept called SERF-completeness similar NP-completeness,based SERF reductions. is, subclass NP-complete problemsalso SERF-complete, meaning SERF reduced other.Hence, one solved subexponential time, can.606fiA Refined View Causal Graphs Component SizesTheorem 24. constant integers k > 0 classes C directed graphs,cc-size(G) logk |V (G)| G C, PlanExist(C) NP-hard unless ETHfalse.Proof. Let k > 0 arbitrary integer. Let arbitrary planning instance nvariables maximum domain size cc-size(CG()) c. components correspond independent subinstances, thus solved separately. componentstate space size dc less, plan corresponding subinstance foundO(d2c ) time, using Dijkstras algorithm. Since n components, wholeinstance solved O(nd2c ) time. However, follows standard assumptionsreasonable encodings n |||| ||||, looser boundsolved O(x x2c ) = O(x1+2c ) time, x = ||||.Suppose PlanExist(C) NP-hard. polynomial reduction 3SATPlanExist(C). Furthermore, size 3SAT instance polynomially boundednumber variables. Hence, must polynomial p 3SAT instancen variables, corresponding planning instance size |||| p(n).Since number variables upper bounded ||||, follows assumption component size upper bounded logk |||| logk p(n). Hence,ksolved O(p(n)1+2 log p(n) ) time, according earlier observation,p(n)1+2 logkp(n)= (2log p(n) )1+2 logkp(n)(2(1+2 logkp(n)) logk p(n)) 23 log2k2kp(n).2kFurthermore, logk p(n) O(logk n), since p polynomial, 23 log p(n) 2O(log n)2kfollows solved 2O(log n) time. However, solved 2ntime arbitrarily small , contradicts ETH. follows PlanExist(C) cannotNP-hard unless ETH false.Since components unbounded, problem likely solvable polynomialtime either. thus NP-intermediate problem double assumptionW[1] 6 nu-FPT ETH holds.Theorems 22 24 together thus tell us something borderlineNP-intermediate NP-hard graph classes is. However, crisp distinction;asymptotically, quite gap polylogarithmic functions rootfunctions (i.e. functions form x1/k ). One may, instance, note function1f (n) = 2(log n)1(log log n)clies within gap whenever 0 < c < 1.8. DiscussionSP-closed graph classes appealing properties fit well concept strongersubgraph-closed weaker minor-closed. also give partial characterizationborderline NP-hardness lies. However, noted earlier, possible definetypes graph classes also imply planning NP-hard. One examplefamily G1 , G2 , G3 , . . . classes proof Theorem 22. Another specializedand, perhaps, contrived class following, intended give contrast SP-closureconcept Gk classes.607fiBackstrom & Jonssontournament directed graph formed giving directions edge completegraph. Let denote set tournaments note SP-closed. However,tournaments Hamiltonian graphs (Redei, 1934) tournament n vertices,path-length(T ) = n 1. Furthermore, path length n 1 computedpolynomial time (Bar-Noy & Naor, 1990).Assume given 3SAT formula F n variables clauses. Let ` =(2m + 4)n, i.e. ` polynomially bounded F . According Lemma 6 thusconstruct planning instance F polynomial time1. F contains ` variables,2. CG(F ) ' dP` ,3. F solution F satisfiable.Choose arbitrary tournament ` vertices T. Find path length `1identify CG(F ). add dummy operators corresponding remainingedges . thus shown polynomial-time transformation 3SATPlanExist(T), PlanExist(T) NP-hard. One may also note variationstechnique used proving PlanExist(T0 ) NP-hard many differentT0 T.considered domain sizes tractable restrictions article,note Theorem 24 may give ideas look tractable cases. Considercase variable domains bounded size constant kcc-size(G) log V (G). Using first part proof, see planning solvedO(n k 2 log n ) time. However, k 2 log n = (2log k )2 log n = (2log n )2 log k = n2 log k ,polynomial since k constant. is, planning tractable restricted case. Eventhough observation straightforward, interesting contrast Theorem 24.also suggests even larger tractable subgraphs also consider additionalrestrictions planning instances.explicitly commented sufficient number pre- postconditionsvarious results, also alternative characterizations might relevant. would bear far list possibilities, let suffice one example.concept prevail conditions, i.e. preconditions variables changedoperator, originate SAS+ formalism (Backstrom & Nebel, 1995)recently considered also context causal graphs. Gimenez Jonsson (2012)refer operator k-dependent precondition k variablesalso change. may note proofs Lemmata 17 20 introduceoperators 1-dependent, most. Since proof Theorem 21 imposerestrictions original planning instance, follows theoremholds also operators 1-dependent, most.final question, one might wonder practical use knowplanning tractable, NP-intermediate, severely limited component sizes? all,planning instances likely causal graph weakly connected,is, whole graph one single component. answer question, first importantobservation make complexity planning instances directly relatedcomplexity planning components separately.608fiA Refined View Causal Graphs Component Sizeslinearly (in number variables) many components. planning solvedpolynomial time components instance, solved polynomial timewhole instance. Conversely, planning cannot solved polynomial timewhole instance, least one component polynomial-time solvable.is, complexity results instances components directly relatedother. words, results relevant methods artificially split causalgraph components, one way another. Examples causal-graph heuristicHelmert (2006a), factored planning (Brafman & Domshlak, 2006) structural patterndata bases (Katz & Domshlak, 2010).Acknowledgmentsanonymous reviewers provided valuable comments suggestions improvingarticle.ReferencesBackstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. ComputationalIntelligence, 11, 625656.Bar-Noy, A., & Naor, J. (1990). Sorting, minimal feedback sets, Hamilton pathstournaments. SIAM Journal Discrete Mathematics, 3 (1), 720.Biggs, N. (1993). Algebraic Graph Theory. Cambridge Univ. Press. 2nd ed.Bodirsky, M., & Grohe, M. (2008). Non-dichotomies constraint satisfaction complexity.Proceedings 35th International Colloquium Automata, LanguagesProgramming (ICALP 2008), Reykjavik, Iceland, pp. 184196.Brafman, R. I., & Domshlak, C. (2003). Structure complexity planning unaryoperators. Journal Artificial Intelligence Research, 18, 315349.Brafman, R. I., & Domshlak, C. (2006). Factored planning: How, when, not.Proceedings 21st National Conference Artificial Intelligence (AAAI 2006),Boston, MA, USA, pp. 809814. AAAI Press.Chen, H., & Gimenez, O. (2010). Causal graphs structurally restricted planning. Journal Computer Systems Science, 76 (7), 579592.Domshlak, C., & Dinitz, Y. (2001a). Multi-agent off-line coordination: Structure complexity. Proceedings 6th European Conference Planning (ECP01), Toledo,Spain.Domshlak, C., & Dinitz, Y. (2001b). Multi-agent off-line coordination: Structure complexity. Tech. rep., Department Computer Science, Ben-Gurion University. CS-0104.Downey, R. G., & Fellows, M. R. (1999). Parameterized Complexity. Monographs Computer Science. Springer, New York.Flum, J., & Grohe, M. (2006). Parameterized Complexity Theory, Vol. XIV TextsTheoretical Computer Science. EATCS Series. Springer, Berlin.609fiBackstrom & JonssonGarey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-Completeness. W. H. Freeman, New York.Gimenez, O., & Jonsson, A. (2008). complexity planning problems simplecausal graphs. Journal Artificial Intelligence Research, 31, 319351.Gimenez, O., & Jonsson, A. (2009). Planning chain causal graphs variablesdomains size 5 NP-hard. Journal Artificial Intelligence Research, 34, 675706.Gimenez, O., & Jonsson, A. (2012). influence k-dependence complexityplanning. Artificial Intelligence, 177-179, 2545.Gupta, N., & Nau, D. S. (1992). complexity blocks-world planning. ArtificialIntelligence, 56 (2-3), 223254.Helmert, M. (2003). Complexity results standard benchmark domains planning.Artificial Intelligence, 143 (2), 219262.Helmert, M. (2004). planning heuristic based causal graph analysis. Proceedings14th International Conference Automated Planning Scheduling (ICAPS2004), Whistler, BC, Canada, pp. 161170. AAAI Press.Helmert, M. (2006a). Fast Downward planning system. Journal Artificial IntelligenceResearch, 26, 191246.Helmert, M. (2006b). New complexity results classical planning benchmarks. Proceedings 16th International Conference Automated Planning Scheduling(ICAPS 2006), Cumbria, UK, pp. 5262. AAAI Press.Impagliazzo, R., & Paturi, R. (2001). complexity k-SAT. Journal ComputerSystem Science, 62 (2), 367375.Impagliazzo, R., Paturi, R., & Zane, F. (2001). problems strongly exponentialcomplexity?. Journal Computer System Science, 63 (4), 512530.Jonsson, A. (2009). role macros tractable planning. Journal Artificial Intelligence Research, 36, 471511.Jonsson, P., & Backstrom, C. (1998a). State-variable planning structural restrictions:Algorithms complexity. Artificial Intelligence, 100 (1-2), 125176.Jonsson, P., & Backstrom, C. (1998b). Tractable plan existence imply tractableplan generation. Annals Mathematics Artificial Intelligence, 22 (3-4), 281296.Karp, R. M., & Lipton, R. J. (1980). connections nonuniform uniform complexity classes. Proceedings 12th ACM Symposium TheoryComputing (STOC80), Los Angeles, CA, USA, pp. 302309.Katz, M., & Domshlak, C. (2007). Structural patterns tractable sequentially-optimalplanning. Proceedings 17th International Conference Automated PlanningScheduling (ICAPS 2007), Providence, RI, USA, pp. 200207. AAAI Press.Katz, M., & Domshlak, C. (2008). New islands tractability cost-optimal planning.Journal Artificial Intelligence Research, 32, 203288.Katz, M., & Domshlak, C. (2010). Implicit abstraction heuristics. Journal ArtificialIntelligence Research, 39, 51126.610fiA Refined View Causal Graphs Component SizesKatz, M., Hoffmann, J., & Domshlak, C. (2013). said need relax variables?. Proceedings 23rd International Conference Automated PlanningScheduling (ICAPS 2013), Rome, Italy, 126134. AAAI Press.Katz, M., & Keyder, E. (2012). Structural patterns beyond forks: Extending complexityboundaries classical planning. Proceedings 26th AAAI ConferenceArtificial Intelligence (AAAI 2012), Toronto, ON, Canada. AAAI Press.Knoblock, C. A. (1994). Automatically generating abstractions planning. ArtificialIntelligence, 68 (2), 243302.Kuhn, D., Osthus, D., & Young, A. (2008). note complete subdivisions digraphslarge outdegree. Journal Graph Theory, 57 (1), 16.Ladner, R. E. (1975). structure polynomial time reducibility. JournalACM, 22 (1), 155171.Lovasz, L. (2005). Graph minor theory. Bulletin AMS, 43 (1), 7586.Mohar, B. (2006). ... graph minor. Notices AMS, 53 (3), 338339.Redei, L. (1934). Ein kombinatorischer Satz. Acta Litteraria Szeged, 7, 3943.Wehrle, M., & Helmert, M. (2009). causal graph revisited directed model checking.Proceedings Static Analysis, 16th International Symposium (SAS09), LosAngeles, CA, USA, Vol. 5673 LNCS, pp. 86101. Springer.Williams, B., & Nayak, P. P. (1997). reactive planner model-based executive.Proceedings 15th International Joint Conference Artificial Intelligence(IJCAI97), Nagoya, Japan, pp. 11781185.611fiJournal Artificial Intelligence Research 47 (2013) 351-391Submitted 03/13; published 06/13Strong Equivalence Qualitative Optimization ProblemsWolfgang Faberfaber@mat.unical.itDepartment MathematicsUniversity CalabriaVia P. Bucci cubo 30B, 87036 Rende, ItalyMiroslaw Truszczynskimirek@cs.uky.eduDepartment Computer ScienceUniversity Kentucky329 Rose Street, Lexington, KY 40506-00633, USAStefan Woltranwoltran@dbai.tuwien.ac.atInstitute Information SystemsVienna University TechnologyFavoritenstrae 911, 1040 Vienna, AustriaAbstractintroduce framework qualitative optimization problems (or, simply, optimization problems) represent preference theories. formalism uses separate modulesdescribe space outcomes compared (the generator ) preferences outcomes (the selector ). consider two types optimization problems. differway generator, model propositional theory, interpreted: standard propositional logic semantics, equilibrium-model (answer-set) semantics.latter interpretation generators, optimization problems directly generalizeanswer-set optimization programs proposed previously. study strong equivalenceoptimization problems, guarantees interchangeability within larger context. characterize several versions strong equivalence obtained restrictingclass optimization problems used extensions establish complexityassociated reasoning tasks. Understanding strong equivalence essential modularrepresentation optimization problems rewriting techniques simplify withoutchanging inherent properties.1. Introductionintroduce framework qualitative optimization problems which, following design answer-set optimization (ASO) programs (Brewka, Niemela, & Truszczynski, 2003),use separate modules describe space outcomes compared (the generator )preferences outcomes (the selector ). optimization problems consider, selector module follows syntax semantics preference modulesASO programs, generator given propositional theory. propositional theory interpreted according standard propositional logic semantics, is,outcomes compared classical models generator, speak classical optimization problems (CO problems, short). generator theory interpretedsemantics equilibrium models (Pearce, 1997), speak answer-set optimizationproblems (ASO problems, short). use terminology, equilibrium modelsc2013AI Access Foundation. rights reserved.fiFaber, Truszczynski, & Woltranusually referred answer sets (Ferraris, 2005) historical reasons. ASO problems,answer sets generator outcomes used determine optimal outcomes.Representing reasoning preferences qualitative settings importantresearch area knowledge representation qualitative decision theory. main objectives design expressive yet intuitive languages model preferences, develop automated methods reason formal representations preferenceslanguages. literature subject preferences vast. refer reader articles special issue Artificial Intelligence Magazine (Goldsmith & Junker, 2008)recent monograph Kaci (2011) thorough discussion areaadditional references.Understanding optimization problems equivalent, particular, oneinterchanged another within larger context, fundamental preferenceformalism. Speaking informally, optimization problems P Q interchangeablestrongly equivalent every optimization problem R (context), P R QR defineoptimal models. Understanding one optimization problem equivalentanother sense essential preference analysis, modular preference representation,rewriting techniques simplify optimization problems forms amenableprocessing, without changing inherent properties. Let us consider multi-agentsetting, agents combine preferences set alternatives goalidentifying optimal ones. one agent ensemble replaced anotherset optimal alternatives unaffected now, also extensionensemble future? Strong equivalence agents optimization problems preciselyneeded guarantee full interchangeability property!notion strong equivalence general interest, means restricted preference formalisms. cases, notably classical logic, coincides equivalence,property models. However, semantics monotone, is,extending theory may introduce new models eliminate some, strong equivalencebecomes strictly stronger concept, one adopt theories analyzedplaced within larger context. nonmonotonicity semantics salient featurenonmonotonic logics (Marek & Truszczynski, 1993) strong equivalence theoriesnonmonotonic logics, especially logic programming answer-set semantics (Gelfond& Lifschitz, 1991), extensively studied setting (Lifschitz, Pearce, & Valverde,2001; Turner, 2003; Eiter, Fink, & Woltran, 2007b). Preference formalisms also oftenbehave nonmonotonically adding new preference may cause non-optimal outcome(model) become optimal one. Thus, preference formalisms, equivalence strongequivalence typically different notions. Accordingly, strong equivalence studiedlogic programs rule preferences (Faber & Konczak, 2006), programs ordered disjunction (Faber, Tompits, & Woltran, 2008) programs weak constraints (Eiter,Faber, Fink, & Woltran, 2007a).extend study strong equivalence formalism qualitative optimizationproblems. formalism motivated design answer-set optimization (ASO) programs Brewka et al. (2003). borrows two key features ASO programs makeattractive alternative preference modeling approaches based logic programmingmentioned above. First, following ASO programs, optimization problems provideclear separation hard constraints, specify space feasible outcomes,352fiStrong Equivalence Qualitative Optimization Problemspreferences (soft constraints) impose preference ordering feasible outcomes. Second, optimization problems adopt syntax semantics preference rules ASOprograms correspond closely linguistic patterns simple conditional preferencesused humans.separation preference modules hard constraints facilitates eliciting representing preferences. also important characterizing strong equivalence.clear separation present, like logic programs ordered disjunctions (Brewka,Niemela, & Syrjanen, 2004), strong equivalence characterizations cumbersomeaccount complex mostly implicit interactions hard constraintspreferences. optimization problems, impose separation, onedimensional forms strong equivalence, hard constraints preferencesadded. one-dimensional concepts easier study yet provide enough information construct characterizations general case.Main Contributions.main contribution summarized follows.propose general framework qualitative optimization problems, extendingseveral ways formalism ASO programs. focus two important instantiations framework, classes classical optimization (CO) problemsanswer-set optimization (ASO) problems. latter one directly generalizes ASOprograms.identify problem strong equivalence theories general preference formalisms. point strong equivalence equivalence coincide (ingeneral) preference formalisms concept strong equivalencefundamental issues theory modularity, rewriting simplification. Strong equivalence studied earlier context logic programs logicprograms extended preferences rules atoms heads rules (andsimilarly motivated). However, best knowledge, firstpaper studies strong equivalence typical preference formalismrepresents preferences terms preferred properties (modeled formulas)independently constraints defining outcomes compare. such,relevance mainstream preference research previous studies.characterize concept strong equivalence optimization problems relativechanging selector modules. characterization independent semanticsgenerators so, applies CO ASP problems. also characterizestrong equivalence relative changing generators (with preferences fixed).case, surprisingly, characterization depends semantics generators.However, show dependence quite uniform, involves characterization strong equivalence generators relative underlying semantics,considered propositional theories. Finally, combinecharacterizations one-dimensional concepts strong equivalence characterization general combined notion.develop results case preferences ranked. practice, preferences commonly ranked due hierarchical structure preference providers.353fiFaber, Truszczynski, & Woltrangeneral case study allows additions preferences ranks specified interval [i, j]. covers case segment hierarchypreference providers allowed add preferences (top decision makers, middle management, low-level designers), well case distinctionimportance preferences (the non-ranked case).establish complexity deciding whether two optimization problems strongly equivalent relative changing selectors, generators, both. results showproblems range co-NP- P3 -complete.Organization. following section, introduce concept optimizationproblem necessary terminology, define equivalence problems interestedhere. also discuss relationship optimization problems formalismsliterature, particular ASO programs. Section 3 provide resultscase selectors may vary new hard constraints allowed. Section 4turn characterizes strong equivalence notion, preferences unaffectedgenerator parts subject change. Section 5 finally show characterizationsobtained previous sections combined order capture general casestrong equivalence. complexity analysis presented Section 6, followeddiscussion results considerations future directions research.present proof sketches simpler overly technical proofsmain text facilitate understanding results intuitive level. Detailed proofsfound Appendix.article substantially extended version earlier published conference version(Faber, Truszczynski, & Woltran, 2012).2. Optimization Problemssection provide basic definitions optimization problems Section 2.1,followed Section 2.2 definitions strong equivalence notions optimizationproblems studied remainder paper. Finally, Section 2.3 providediscussion related formalisms.2.1 Basic Definitionsqualitative optimization problem (an optimization problem, on) orderedpair P = (T, S), called generator selector. rolegenerator specify family outcomes compared. role selectordefine relation set outcomes and, consequently, define notionoptimal outcome. relation induces relations > : define > J JJ 6 I, J J J I. optimization problem P , write P g Prefer generator selector, respectively.Generators. generators use propositional theories language determinedfixed countable universe (or alphabet) U propositional variables form atomicpropositions, Boolean constant , Boolean connectives , ,define constant >, connectives usual way > := , :=354fiStrong Equivalence Qualitative Optimization Problems, := ( )( ), respectively.1 Models generator, definedsemantics used, represent outcomes corresponding optimization problem.consider two quite different semantics generators: classical propositional logicsemantics semantics equilibrium models (Pearce, 1997). Thus, outcomeseither models equilibrium models, depending semantics chosen. first semanticsinterest due fundamental role widespread use classical propositional logic,particular, means describe constraints. Equilibrium models generalize answer setslogic programs case arbitrary propositional theories (Pearce, 1997; Ferraris, 2005)often referred answer sets. semantics equilibrium models importantdue demonstrated effectiveness logic programming semantics answersets knowledge representation applications. use terms equilibrium modelsanswer sets interchangeably.Throughout paper, represent interpretations subsets U, containexactly atomic propositions interpreted true. write |= stateinterpretation U (classical propositional) model formula . Furthermore,denote set classical models formula theory Mod (T ).Equilibrium models arise context propositional logic here-and-there,logic HT short (Heyting, 1930). briefly recall definitions concepts,well properties logic HT directly relevant work. referpapers Pearce (1997) Ferraris (2005) details.logic HT logic located intuitionistic classical logics. Interpretations logic HT pairs hI, Ji standard propositional interpretationsJ. write hI, Ji |=HT denote formula holds interpretationhI, Ji logic HT. relation |=HT defined recursively follows:1. hI, Ji 6|=HT2. atom a, hI, Ji |=HT precisely3. hI, Ji |=HT hI, Ji |=HT hI, Ji |=HT4. hI, Ji |=HT hI, Ji |=HT hI, Ji |=HT5. hI, Ji |=HT J |= (classical satisfiability), hI, Ji 6|=HThI, Ji |=HT .equilibrium model answer set propositional theory standard interpretation hI, Ii |=HT every proper subset J I, hJ, Ii 6|=HT . Answersets propositional theory also classical models . converse truegeneral. denote set answer sets theory (T ), setHT-models ModHT (T ), is, ModHT (T ) = {hI, Ji | J, hI, Ji |=HT }.semantics two natural concepts equivalence. Two theories T1T2 equivalent models (classical equilibrium, respectively).strongly equivalent every theory S, T1 T2 models(again, classical equilibrium, respectively).1. choice primitive connectives common language classical propositional logic,standard logic here-and-there underlies answer-set semantics.355fiFaber, Truszczynski, & Woltranclassical semantics, strong equivalence equivalence coincide.semantics equilibrium models. result Lifschitz et al. (2001) states twotheories T1 T2 strongly equivalent equilibrium models T1 T2equivalent logic HT, is, ModHT (T1 ) = ModHT (T2 ). illustratenotions HT-models equilibrium models, relate latter classical ones.examples, consider classical HT-models alphabetconsisting atoms explicitly mentioned theories discussed. sufficientdetermine equilibrium models one hand (which happen consist atomsmentioned) and, other, show differ classical ones.Example 1 Let us consider theory Ta = {a a}. classical models Ta (underrestriction mentioned above) {a}, true false possibleoutcomes. HT-models (again, restriction) h, i, h, {a}i,h{a}, {a}i. Hence, one answer set (equilibrium model) . possiblecandidate, {a}, answer set. h{a}, {a}i |=HT Ta holds, also h, {a}i |=HT Tadoes. Thus, intuitively, theory contain cause hold.Next, let us consider theory Tb = {ab}. classical models {a}, {b} {a, b},HT-models h{a}, {a}i, h{b}, {b}i, h{a}, {a, b}i, h{b}, {a, b}i h{a, b}, {a, b}i.answer sets therefore {a} {b}, {a, b}. intuitiontheory contain cause b hold simultaneously.Finally, let us consider theory Tc = {(a b) (b a)}. classical modelsTb , is, Mod (Tc ) = {{a}, {b}, {a, b}}. also ModHT (Tc ) ={h{a}, {a}i, h{b}, {b}i, h{a}, {a, b}i, h{b}, {a, b}i, h{a, b}, {a, b}i, h, {a, b}i} = ModHT (Tb ){h, {a, b}i}. answer sets Tb : (Tc ) = {{a}, {b}}.observe Tb Tc equivalent classical equilibrium setting(they classical equilibrium models). former impliesalso strongly equivalent classical setting. However, strongly equivalentequilibrium setting ModHT (Tb ) 6= ModHT (Tc ) (cf. characterization strongequivalence equilibrium semantics Lifschitz et al. (2001)). indeed,= {a b, b a}, obtain (Tb S) = {{a, b}}, (Tc S) = .recall optimization problems classical interpretation generatorsreferred classical optimization problems CO problems, useanswer-set semantics generators, speak answer-set optimization problemsASO problems.Selectors. follow definitions preference modules ASO programs (Brewkaet al., 2003), adjusting terminology general setting. selector finiteset ranked preference rulesj1 > > k(1)k j positive integers, , 1 k, propositional formulasU. rule r form (1), number j rank r, denoted rank (r),hd (r) = {1 , . . . , k } head r body (the condition) r, bd (r). Moreover,write hd (r) refer formula .rank (r) = 1 every preference rule r selector S, simple selector.1Otherwise, ranked. often omit 1 notation simple selectors.356fiStrong Equivalence Qualitative Optimization Problemsselector S, i, j {0, 1, 2, . . .} {}, define S[i,j] = {r | rank (r) j}(where assume every integer k, k < ) write [i, j] rank interval{k | k integer, k j}. extend notation optimization problems.P = (T, S) rank interval [i, j], set P[i,j] = (T, S[i,j] ). rank intervalsuse shorthands, example = [i, i], < [1, 1], [i, ], similar.interpretation I, satisfactiondegree preference rule r vI (r) = min{i | |=Whd (r)}, |= bd (r) |= hd (r); otherwise, rule irrelevant I, vI (r) = 1.Intuitively, lower satisfaction degree better outcome. Thus, preferencerule 1 > > k informally read follows: irrelevant outcomes (thosesatisfying , satisfying ) outcomes satisfying 1 preferred,followed outcomes satisfying 2 , outcomes satisfying 3 , etc. noteBrewka et al. (2003) represented satisfaction degree irrelevant rule specialnon-numeric degree, treated equivalent 1. difference immaterialtwo approaches equivalent.Selectors determine preference relation interpretations. Given interpretationsJ simple selector S, J holds precisely r S, vI (r) vJ (r).Therefore, >S J holds J exists r vI (r) < vJ (r);J holds every r S, vI (r) = vJ (r).Given ranked selector S, define J every preference rule r S, vI (r) =vJ (r), rule r0 following three conditions hold:1. vI (r0 ) < vJ (r0 )2. every r rank r0 , vI (r) vJ (r)3. every r smaller rank r0 , vI (r) = vJ (r).Moreover, >S J rule r0 three conditions hold,J every r S, vI (r) = vJ (r). Given optimization problemP = (T, S), often write P (and similarly > ). Furthermore, setV 2U relation (like >, , ) 2U , write V restrictionV , is, V = {(A, B) | A, B V }. relationship equalities , >,two optimization problems follows.Lemma 1 optimization problems P Q, every set V 2U , PV = QVQPimplies >PV = >QV V = V .PProof. Suppose PV = QV let I, J interpretations I>V J. definiQQQPPtion, IV J J6V I. assumption IV J J6V I, implying I>V J. case IPV JQIPV J JPV I. assumption IQV J JV hold well concludeQQPPIQV J. direction (I>V J implies I>V J, IV J implies IV J) analogous. 2aspects ASO selectors require additional discussion. First, preference rulemay irrelevant outcome. case outcome satisfycondition rule or, does, satisfy formula headrule. cases, define outcome desirable respect rule.making choice, followed original definition (Brewka et al., 2003) (modulo357fiFaber, Truszczynski, & Woltranminor simplification mentioned earlier). Obviously, choices could considered, too.instance, could define irrelevant outcomes least desirable respectrule. could also restrict attention selectors permit irrelevance(a preference rule allow irrelevance body disjunctionoptions head tautology). would eliminate need address issuealtogether, however, price constraining definintion selector rules.Ultimately, question right design choice secondary importancesemantics preference rules adopted provides us flexibility representpossible definitions. particular, note semantics rule1 > . . . > nrule1 > . . . > n .words, conditions (the rule bodies) modeling device making preferencerules better correspond conditional preferences expressed natural language.compiled away. second type irrelevance, formalism selectors allowsuser override default adopted. make adopted design choice explicit,is, making outcomes satisfying options head explicitlydesirable. Intuitively, sufficient rewrite rule (without body, since bodiesremoved, shown earlier)1 > . . . > n1 (1 . . . n ) > . . . > n ,or, equivalently,1 (2 . . . n ) > . . . > nfollowing rewriting makes least desirable:1 > . . . > n (1 . . . n ) ,or, equivalently,1 > . . . > n (1 . . . n1 ) .Another question concerns rules one option head. Intuitively, givensemantics important, satisfaction degree always 1.Indeed, Corollary 12 later paper provides formal result confirms statement.Optimal (preferred) outcomes. optimization problem P , (P ) denotes setoutcomes P , is, set models (under selected semantics)generator P . Thus, (P ) stands models P framework CO problemsanswer sets P , ASO problems considered. model (P )optimal preferred P model J (P ) J >P I. denoteset preferred models P (P ).following lemma asserts preference relation two optimization problemsequal sets outcomes, preferred models coincide. result follows358fiStrong Equivalence Qualitative Optimization Problemsimmediately definitions useful sequel. statement bringssubtle notational issue. Formally, (strict) preorder pair (D, >), set (thedomain preorder) > transitive acyclic binary relation (the preorderrelation). Two preorders equal domain relationdomain. Typically, whenever domain understood, refer preorderspointing relation symbols. Often, however, write >D preorder relationsymbol make domain explicit notation. statementresult below.Lemma 2 Let P Q optimization problems >P(P ) = >Q(Q) . Then, (P ) = (Q).Proof.observed above, equality preorders implies equality domains. case, equality >P(P ) = >Q(Q) implies (P ) = (Q). Hence,PQI, J (P ) = (Q), > J iff > J. result follows directly definitionpreferred outcomes. 2also observe eliminating rules large ranks make unpreferred outcomes preferred, never make preferred outcomes unpreferred. recall that,given optimization problem P = (T, S), P<i = P[1,i1] = (T, S[1,i1] ) correspondingoptimization problem rules rank higher removed.Lemma 3 every optimization problem P every 1, (P<i ) (P ).Proof. Let us assume/ (P<i ). case/ (P<i ),/ (P ),/ (P )P<ifollows. Otherwise, interpretation J (P<i ) J >I. Thus,, say rank j, (i) v (r) < v (r); (ii) every r 0 Prule r P<iJ<irank less j, v (r 0 ) = v (r 0 ).rank j, vJ (r0 ) vI (r0 ); (iii) every r0 P<iJnote that, since (P<i ) = (P ), J (P ). Moreover, j < sets rulescoincide. Thus, J >P follows and,ranks less equal j P P<iconsequently,/ (P ). 22.2 Notions Equivalencedefine union optimization problems expected, is, P1 = (T1 , S1 )P2 = (T2 , S2 ), set P1 P2 = (T1 T2 , S1 S2 ). Two optimization problems P1P2 strongly equivalent respect class R optimization problems (referredclass contexts simply contexts) every optimization problem R R,(P1 R) = (P2 R).consider three general classes contexts. First foremost, interestedclass LU optimization problems U. also consider families LgULsU optimization problems form (T, ) (, S), respectively. first classconsists optimization problems which, added problem, affectset feasible outcomes cannot affect preference relation. call optimizationproblems generator problems. second class consists optimization problems which,added problem, change set feasible outcomes change359fiFaber, Truszczynski, & Woltran(in general) preference relation. call optimization problems selector problems.one-dimensional contexts provide essential insights general case.two classes, speak strong gen-equivalence, denoted g , strong sel-equivalence,denoted , respectively. general class LU optimization problems simplyspeak strong equivalence, denoted sg .recall notion strong equivalence is, definition, underlying replacement property. fact, optimization problem P = (T, S) containing subproblemQ = (T 0 , 0 ) (i.e. 0 0 S) guarantee Q replaced Panother subproblem R without changing optimal outcomes, Q sg R. Indeed,Q sg R holds, one faithfully replace Q R optimization problem (otherwisewould (Q P 0 ) 6= (R P 0 ) P 0 LU ).Constraining ranks rules selectors gives rise additional classes contexts parameterized rank intervals [i, j]:s,[i,j]1. LU[i,j]2. LU= {(, S) LsU | = S[i,j] }= {(T, S) LU | = S[i,j] }first class contexts gives rise strong sel-equivalence respect rulesrank [i, j], denoted s,[i,j] . second class contexts yields concept strongs,[i,j]equivalence respect rules rank [i, j]. denote g. call problems[1,1]=1class LU = LU simple optimization problems.2.3 Relation Preference FormalismsOptimization problems closely related ASO programs (Brewka et al., 2003).formalism optimization problems extends ASO programs several ways. First,generators optimization problems arbitrary propositional theories.semantics equilibrium models, generators properly extend logic programsanswer-set semantics, used generators ASO programs. Second, selectorsoptimization problems use arbitrary propositional formulas heads preferencerules, well conditions bodies, generalizes selectorsASO programs. Finally, optimization problems explicitly allow alternative semanticsgenerators, possibility mentioned pursued Brewka et al. (2003).already noted introduction vast literature preference representation reasoning (The special issue Artificial Intelligence Magazine, Goldsmith &Junker, 2008, monograph Kaci, 2011, two comprehensive sources relevantreferences. survey preference approaches top nonmonotonic formalisms, seeDelgrande, Schaub, Tompits, & Wang, 2004). Discussing goes beyond scopepresent paper, especially problem focus (strong equivalence)considered much preference research before, essentiallyrelevant earlier results except already mentioned introduction (Faber &Konczak, 2006; Faber et al., 2008; Eiter et al., 2007a). Nevertheless, since work usespreference formalism ASO problems, extension formalism ASO programsBrewka et al. (2003) received much attention preference researchothers, make comments choice.360fiStrong Equivalence Qualitative Optimization ProblemsFirst, ASO problems explicit constraints must violated (thegenerator part) preferences, is, weaker constraints make outcomesdesirable others (the selector part). ASO problems match well practical settings, typically kinds constraints play. instance, productconfiguration problem physical constraints limiting space available possibilities (not every type engine put small family sedan, moon roof availablebasic engine option, etc.), well user preferences describe userwould like possible. Preferential reasoning (optimization) presence (hard)constraints received substantial attention. representative approach CP-nets(Boutilier, Brafman, Domshlak, Hoos, & Poole, 2003) combined constraintsdescribed paper Boutilier, Brafman, Domshlak, Hoos, Poole (2004).choice propositional logic represent constraints (the generator part formalism) standard. However, contrast approaches, addition classicalsemantics also consider appealing alternative, semantics answer sets.important resulting formalism answer-set programming (Marek & Truszczynski,1999; Niemela, 1999) steadily gaining acceptance constraint languagesupported ever improving computational tools (Calimeri, Ianni, Krennwallner, & Ricca,2012).hand, choice formalism selector part less obvious.several reasons motivated us. first, one already mentionedearlier, preference rules natural reading agreeing well linguisticpatterns humans use formulating qualitative conditional preferences. Second,demonstrated original work ASO selectors introduced (Brewka et al.,2003), used approximate preference relations defined CP-nets(Boutilier et al., 2003), one broadly studied qualitative preference systems,better computational properties. instance, dominance problem Popposed NP-hard even PSPACE-complete generalized classesCP-nets (Goldsmith, Lang, Truszczynski, & Wilson, 2008).Third, individual preference rules closely related one standard approachesrepresenting preferences based possibilistic logic. approach (we givebasic details here, comprehensive discussion refer Kaci, 2011, Ch.3.3.3), preference theory consists formulas, distinct rank (the assumptionranks distinct limiting formulas repeating ranks conjunctedsingle formula rank). quality outcome given score definedminimum rank formula outcome satisfy (, formulassatisfied). higher score, better outcome. Let {1 , . . . , n } preferencetheory, index representing rank . clear preferencesemantics theory described precisely captured preference rulen > n1 > . . . > 1 > 1= 1 . . . , = 1, . . . , n. Thus, ASO problems subsume preferenceformalism based possibilistic logic.Finally, selector part ASO problems typically consists several preference rulesrules may different ranks. allows us model preferences comingdifferent sources different importance. cases, main issue361fiFaber, Truszczynski, & Woltranintegrating individual preferences single order. single broadlyaccepted way so. approach used formalism boils Paretoprinciple, arguably common core integration principles. Accordingly,formalism allows conflicting rules selector (for instance, > b b > )leaves conflicts unresolved resulting incomparability. ranks, lowerrank, important rule is. Rules less importance used compare outcomesrules importance distinguish them. way handling ranksnatural shows many preference formalisms.One prominent example context prioritized (propositional) circumscription(Lifschitz, 1985), minimization (of certain atoms models formula) definedrespect classes atoms different priority. Formally, let theoryatoms (P1 , . . . , Pn , V, F ) partition A. Then, model Mod (T ) called(P1 , . . . , Pn , V, F )-minimal N Mod (T ), (i) N (P1 Pi1 ) =(P1 Pi1 ) N Pi Pi 1 Si n, (ii) N F = F .intuition behind definition atoms P = Pi minimized,assignments V allowed vary, assignments F kept fixed. Atoms Pminimized P1 highest priority followed P2 , etc.relation ranks quite obvious. One show (P1 , . . . , Pn , V, F )-minimalmodels theory coincide preferred outcomes CO problem X = (T, S),selector given11= {f > f > | f F } {f > f > | f F }{p > p > | p Pi , 1 n}).Indeed preference rules first two sets ensure interpretationsfixed part comparable, preference rules last group precisely reflect prioritized process minimization atoms P1 . . . Pn .Let us finally mention formalism optimization problems giveshandle classical prioritized circumscription, also circumscription puttop logic programs (this meaningless, forms currently prevalent answerset programming, answer sets necessarily minimal models, see instance Simons,Niemela, & Soininen, 2002). end suffices apply embedding using ASOproblems instead CO problems.3. Strong Sel-Equivalencestart analyzing case strong sel-equivalence turns core casestudy. Indeed, characterizations strong sel-equivalence naturally imply characterizations general case thanks following simple observation.Proposition 4 Let P Q optimization problems (either classical answer-sets,[i,j]semantics generators) [i, j] rank interval. P gQevery generator R LgU , P R s,[i,j] Q R.s,[i,j]Proof. () Let R LgU . Since P gs,[i,j]Q, P R g362Q R so, P R s,[i,j] Q R.fiStrong Equivalence Qualitative Optimization Problems[i,j]() Let R optimization problem LU . P R = (P (Rg , ))(, Rs )QR = (Q(Rg , ))(, Rs ). Moreover, assumption P (Rg , ) s,[i,j]Q (Rg , ). Thus,((P (Rg , )) (, Rs )) = ((Q (Rg , )) (, Rs )).s,[i,j]follows (P R) = (Q R) and, consequently, P gQ. 2Furthermore, set outcomes optimization problem P unaffected changesselector module. follows choice semantics generatorsmatter characterizations strong sel-equivalence. Thus, whenever sectionrefer set outcomes optimization problem P , use notation (P ),specific one, Mod (P g ) (P g ), applies CO ASO problems,respectively.formally state subsequent results, need one auxiliary notation.optimization problem P , define diff P (I, J) largest k P<k J.every k P<k J, set diff P (I, J) = . clear diff P (I, J)well-defined. Moreover, P<1 J, diff P (I, J) 1. following lemma characterizesrelation >P Q ranked optimization problems P Q.Lemma 5 Let P Q optimization problems, I, J interpretations. Then,>P Q J holds one following conditions holds:1. diff P (I, J) < diff Q (I, J) >P J;2. diff P (I, J) > diff Q (I, J) >Q J;3. diff P (I, J) = diff Q (I, J), >P J >Q J.Proof. direction evident. prove only-if direction, notecases diff P (I, J) < diff Q (I, J) diff P (I, J) > diff Q (I, J) obvious, too. Thus, let usassume diff P (I, J) = diff Q (I, J) = i. Clearly, < (otherwise, P Q J, contraryassumption). follows every rule r P Qs rank less i, vI (r) = vJ (r).Next, every r P Qs rank i, vI (r) vJ (r). Finally, rules r Pr0 Qs , rank vI (r) 6= vJ (r) vI (r0 ) 6= vJ (r0 ) (since diff P (I, J) =diff Q (I, J) = i). follows vI (r) < vJ (r) vI (r0 ) < vJ (r0 ). Thus, >P J>Q J, needed. 2first main result concerns strong sel-equivalence relative selectors consistingpreference rules ranks rank interval [i, j]. Special cases strong sel-equivalencefollow corollaries.Considering strong sel-equivalence means preference rules may added optimization problems. three main effects so: outcomes equally goodmay become strictly comparable, strict comparability may turned incomparability,order strict comparability may reversed. illustrate phenomena,show may affect strong sel-equivalence using forthcoming examples. Importantly, lead us towards conditions necessary strong sel-equivalencemotivate characterization property formally state Theorem 6.363fiFaber, Truszczynski, & WoltranExample 2 Let P1 = (T1 , S1 ), T1 theory generating exactly two outcomes {a}{b} (for example {a b}) S1 = empty. Clearly, (P1 ) = {{a}, {b}},{a} {b} equally good respect P1 . possible make comparableadding new preference rules. example, let R1 = (, {a > b }), 1. Now,{a} >P1 R1 {b} thus (P1 R1 ) = {{a}}. evident pair equally goodinterpretations I, J one find context consisting preference rules makestrictly preferred J (each new rule least preferred J onestrictly prefer J), precise ranks contextimportance.Example 3 Let P2 = (T1 , S2 ), T1 theory generating exactly two outcomes {a}{b}, S2 = {a > b } rank 1. Clearly, {a} >P2 {b} therefore(P2 ) = {{a}}. possible make {a} {b} incomparable adding appropriatecontext, example R2 = (, {b > }). obtain {a} >6 P2 R2 {b} {b} >6 P2 R2 {a},thus (P2 R2 ) = {{a}, {b}}.important note rank context preference rule must exactly equalrank original preference rule order achieve effect, otherwise onepreference rule would override other. general, pair strictly comparableinterpretations I, J one find appropriate context makes J incomparable,contrast Example 2, context must make use rules particular ranks.Example 4 Let P3 = (T1 , S3 ), T1 theory admitting exactly two outcomes {a}{b}, S3 = {a > b } rank 2. Clearly, {a} >P3 {b} therefore(P3 ) = {{a}}. possible reverse comparability {a} {b} adding1appropriate context, example R3 = (, {b > }). obtain {b} >P3 R3 {a}, thus(P3 R3 ) = {{b}}.important note that, order achieve effect, context must containpreference rules lower ranks preference rules originally ordered J,original ordering overridden. also means techniqueapplicable preference rules rank 1. general, pair strictly comparableinterpretations I, J, comparison stems preference rules rank > 1, addingcontext consisting preference rules lower rank reverse comparability Jresults reversed strict order. Example 3, context must make use particularranks.three effects may exploited order construct examples problemsstrongly sel-equivalent suggest necessary conditions strong sel-equivalence.first effect turn preferred outcomes non-preferred, second thirdturn non-preferred outcomes preferred ones. second third effects implyconditions specialized (context needs rules particular ranks).23Example 5 Consider P4 = (T1 , {a > b }) Q4 = (T1 , {a > b }), T1theory admitting exactly two outcomes {a} {b}. {a} >P4 {b}, {a} >Q4 {b},(P4 ) = (Q4 ) = {{a}}. two problems therefore equivalent. However,364fiStrong Equivalence Qualitative Optimization Problemsdiscrepancy respect ranks preference rules, take advantageorder show programs strongly sel-equivalent.3Let us consider context R4 = (, {b > }). context exploits second effectmentioned makes {a} {b} incomparable respect Q4 extendedR4 ({a} 6>Q4 R4 {b} {b} 6>Q4 R4 {a}) thus turning also {b} preferred outcome(Q4 R4 ) = {{a}, {b}}. hand, new preference rule effect P4 ,rank weaker preference rule P4 , hence (P4 R4 ) = {{a}},therefore P4 6s,[3,i] Q4 3.Analyzing example, observe context R4 exploits differencepreferred outcomes considering preference rules rank lower 3.Indeed, ((P4 )<3 ) = {{a}} ((Q4 )<3 ) = {{a}, {b}}.24Example 6 Next, let us consider P5 = P4 = (T1 , {a > b }) Q5 = (T1 , {a > b }),T1 theory admitting exactly two outcomes {a} {b}. {a} >P5 {b},{a} >Q5 {b}, (P5 ) = (Q5 ) = {{a}}. Also here, observe ((P5 )<3 ) ={{a}} ((Q5 )<3 ) = {{a}, {b}}. difference Example 5 preferencerule Q5 rank 4.Also possible construct context witnesses P5 strongly sel33equivalent Q5 , using preference rules rank 3: R5 = (, {a > b , b > }).Here, directly add conflicting preference rules override preference rule Q5overridden preference rule P5 . So, also get (P5 R5 ) = {{a}}(Q5 R5 ) = {{a}, {b}}, P5 6s,[3,i] Q5 3.Examples 5 6 motivate condition (1) Theorem 6. Moreover, also rather easysee counterexample P s,[i,j] Q involve outcomes (P<i ) =(Q<i ), selector context rank interval [i, j] make outcomes preferred.However, different point view, condition (1) Theorem 6 also fairly weak,cover easy cases strong sel-non-equivalence, shown followingexample.22Example 7 Let us define P6 = P4 = (T1 , {a > b }) Q6 = (T1 , {b > }), T1theory admitting exactly two outcomes {a} {b}. {a} >P6 {b}, {b} >Q6 {a},(P6 ) = {{a}} 6= (Q6 ) = {{b}}. P6 Q6 even equivalent, hence alsoP6 6s,[i,j] Q6 rank interval [i, j]. However, ((P6 )<2 ) = {{a}, {b}} ((Q6 )<2 ) ={{a}, {b}}. condition (1) Theorem 6 satisfied rank intervals [2, j].Condition (2) Theorem 6 covers cases like one Example 7. examplerather simple, even require context order create witness strongsel-non-equivalence, general one create context order make certainoutcomes preferred. remains considered cases discrepancystemming preference rules inside context rank interval.23Example 8 Let P7 = (T1 , {a > b }) Q7 = (T1 , {a > b }), T1 theoryadmitting exactly two outcomes {a} {b} (this pair problems P4 Q42Example 5). Consider context R7 = (, {b > }). Unlike R4 Example 5,365fiFaber, Truszczynski, & Woltranrule rank 2. context makes {a} {b} incomparable respect extendedP7 ({a} 6>P7 R7 {b} {b} 6>P7 R7 {a}), thus turning {b} preferred outcome,keeping {a} such. Therefore, (P7 R7 ) = {{a}, {b}}. hand, newpreference rule overrides one Q7 , turning {b} preferred outcome making{a} non-preferred, (Q7 R7 ) = {{b}}. Therefore P7 6s,[2,i] Q7 2.Unlike Example 5, ((P7 )<2 ) = ((Q7 )<2 ) = {{a}, {b}}, different reason allows counterexample. Here, observe diff P7 ({a}, {b}) = 2 6=diff Q7 (a, b) = 3, allows adding appropriate preference rule rank 2.important add rule one two differing ranks. Indeed,context comprising rules rank one serve counterexample strongsel-equivalence, indeed P7 s,[1,1] Q7 .finally motivates condition (3) Theorem 6: two outcomes (as discussedearlier, restrict outcomes (P<i ) = (Q<i ) context rank interval[i, j]) differ ranks one ranks inside rank interval, useconstructions Example 8 order obtain counterexample strong sel-equivalence.show three conditions Theorem 6 indeed characterize strong selequivalence.Theorem 6 ranked optimization problems P Q, every rank interval [i, j],P s,[i,j] Q following conditions hold:1. (P<i ) = (Q<i )2. >P(P<i ) = >Q(Q<i )3. every I, J (P<i ) < diff P (I, J) < diff Q (I, J), diff P (I, J) =diff Q (I, J) diff P (I, J) > j diff Q (I, J) > j.proof result quite involved requires several auxiliary properties.provide appendix (together proofs main results).Next, discuss special cases characterization Theorem 6. First,consider case = 1, allows simplification Theorem 6.Corollary 7 ranked optimization problems P Q, every rank interval [1, j],P s,[1,j] Q following conditions hold:1. (P ) = (Q)2. >P(P ) = >Q(Q)3. every I, J (P ), diff P (I, J) = diff Q (I, J) diff P (I, J) > j diff Q (I, J) >j.Proof. Starting Theorem 6, note selectors P<1 Q<1 emptyhence (P<1 ) = (P ) (Q<1 ) = (Q). Moreover, precondition < diff P (I, J)< diff Q (I, J) condition (3) Theorem 6 satisfied = 1 pairI, J (P ), one diff P (I, J) = 1 diff Q (I, J) = 1 holds, together366fiStrong Equivalence Qualitative Optimization Problemsdiff P (I, J) = diff Q (I, J) consequent satisfied case well, allowsomitting precondition. 2addition j = , obtain case rank-unrestricted selector contexts,condition (3) simplified more, since diff P (I, J) > j diff Q (I, J) > j neverhold j = .Corollary 8 optimization problems P Q, P Q (equivalently, P s,1 QP s,[1,] Q) following conditions hold:1. (P ) = (Q)2. >P(P ) = >Q(Q)3. every I, J (P ), diff P (I, J) = diff Q (I, J).Next, note optimization problem P simple (all rules rank 1),diff P (I, J) > 1 diff P (I, J) = , equivalent P J. observation leads following characterization strong sel-equivalence simple optimizationproblems.Corollary 9 simple optimization problems P Q, following statementsequivalent:(a) P Q (equivalently, P s,[1,] Q)(b) P s,=1 Q (equivalently, P s,[1,1] Q)(c) (P ) = (Q) P(P ) =Q(Q) .Proof. implication (a)(b) evident definitions.(b)(c) Corollary 7, j = 1, obtain (P ) = (Q). condition P(P ) =Q(Q)follows conditions (2) (3) corollary. Indeed, let us consider I, J (P )P J distinguish two cases. (i) diff P (I, J) = 1 >P Jcondition (2) Corollary 7, also >Q J, implying Q J. (ii) diff P (I, J) > 1condition (3) Corollary 7, diff Q (I, J) > 1. Since P, Q simple, Q J,consequently Q J. symmetry, also Q J implies P J. Thus,P(P ) =Q(Q) .QP(c)(a) (c) follows Lemma 1 >P(P ) =>Q(Q) (P ) =(Q) . Thus,conditions (1) (2) Corollary 8 follow. prove condition (3), let us first assumediff P (I, J) > 1 I, J (P ). follows diff P (I, J) = thus P(P ) J. SinceQQPQP(P ) =Q(Q) , get (Q) J thus diff (I, J) = . Hence diff (I, J) = diff (I, J).diff Q (I, J) > 1 reason analogously. last remaining case, diff P (I, J) = 1diff Q (I, J) = 1. Thus, directly obtain diff P (I, J) = diff Q (I, J). Corollary 8, P Qfollows. 2367fiFaber, Truszczynski, & WoltranCorollary 9 shows, particular, simple problems differencerelations s,1 s,=1 . property reflects role preference rules rank 2higher. allow us break ties among optimal outcomes, defined preferencerules rank 1. Thus, eliminate outcomes family optimalones, cannot introduce new optimal outcomes. Therefore, affect strongsel-equivalence simple problems. property following generalization rankedoptimization problems.Corollary 10 Let P Q ranked optimization problems let k maximumrank preference rule P Q. relations s,k (equivalently, s,[k,] )s,=k (equivalently, s,[k,k] ) coincide.Proof. Clearly, P s,k Q implies P s,=k Q. Thus, enough prove P s,=k QP s,k Q. Using characterization Theorem 6, observe conditions (1)(2) P s,=k Q P s,k Q same. Since P s,=k Q,every I, J (P<k ) k < diff P (I, J) k < diff Q (I, J), diff P (I, J) = diff Q (I, J)diff P (I, J) > k diff Q (I, J) > k. Let us consider I, J (P<k )diff P (I, J) > k. follows diff Q (I, J) > k. Since k maximum rank preference rule P Q, diff P (I, J) = diff Q (I, J) = . Thus, diff P (I, J) = diff Q (I, J).case diff Q (I, J) > k similar obtain every I, J (P<k )k < diff P (I, J) k < diff Q (I, J), diff P (I, J) = diff Q (I, J). property implies condition (3) P s,k Q. Thus, P s,k Q follows. 2observation role preference rules ranks higher ranks rulesP Q also implies P Q strongly sel-equivalent relative selectors consistingexclusively rules P Q equivalent (have optimaloutcomes), optimal outcomes tie P also tie Q conversely. Formally,following result.Corollary 11 Let P Q ranked optimization problems let k maximumrank preference rule P Q. P s,k+1 Q (P ) = (Q)P(P ) =Q(Q) .Proof. Clearly, P<k+1 = P Q<k+1 = Q so, (P<k+1 ) = (P ) (Q<k+1 ) =(Q). Thus, only-if part follows Theorem 6 (condition (1) theorem reduces(P ) = (Q) condition (3) implies P(P ) =Q(Q) ). prove part, notecondition (1) Theorem 6 holds assumption. Moreover, relations >P(P )>Q(Q) empty so, coincide. Thus, condition (2) Theorem 6 holds. Finally,I, J (P ), diff P (I, J) > k + 1, diff P (I, J) = so, P J. assumption, Q J, is, diff Q (I, J) = = diff P (I, J). case diff Q (I, J) > k + 1similar. Thus, condition (3) Theorem 6 holds, too, P s,k+1 Q follows. 2Lastly, give simple examples illustrating results used safelymodify simplify optimization problems, rewrite one another strongly selequivalent one.368fiStrong Equivalence Qualitative Optimization ProblemsExample 9 Let P = (T, S), = {a b c, (a b), (a c), (b c)} = {a >c , b > c }, P 0 = (T, 0 ), 0 = {a b > c }. Regarding problemsCO problems, (P ) = (P 0 ) = {{a}, {b}, {c}}. Moreover, evident0P(P ) =P(P 0 ) . Thus, Corollary 9, P P 0 strongly sel-equivalent. words,faithfully replace rules > c , b > c selector optimization problemgenerator single rule b > c .example general principle, note removing preference rulesone formula head yields problem strongly sel-equivalent.Corollary 12 Let P Q two CO ASO problems P g = Qg Qsobtained P removing preference rules one formula head (i.e.,rules r |hd (r)| = 1). P Q strongly sel-equivalent.Proof. Conditions (1)-(3) Theorem 6 follow observation every interpretation every preference rule r |hd (r)| = 1, vI (r) = 1. 24. Strong Gen-Equivalencefocus case strong gen-equivalence. semantics generators makesdifference difference concerns fact two semanticsconsider, concepts strong equivalence different. aspects characterizations same. Specifically, generators strongly equivalent relativeselected semantics. Indeed, following example shows, generatorsstrongly equivalent, one extend uniformly extension one problemsingle outcome, trivially optimal one, too, oneoutcomes so, optimal ones.Example 10 Consider CO problem P8 = (T8 , S8 ), T8 = {a b} S8 = {a >b }. two outcomes here, {a} {b}, is, (P8 ) = {{a}, {b}}. Let rpreference rule S8 . Clearly, v{a} (r) = 1 v{b} (r) = 2. Thus, {a} >P8 {b} so,(P8 ) = {{a}}.addition, let Q8 = (T80 , S8 ) CO problem, T80 = {a b} S8above. Then, (Q8 ) = {{a}} and, trivially, (Q8 ) = {{a}}. follows P8 Q8equivalent, specify optimal outcomes. However, stronglygen-equivalent (and so, also strongly equivalent). Indeed, let R8 = ({a}, ).(P8 R8 ) = {{b}} so, (P8 R8 ) = {{b}}. hand, (Q8 R8 ) = and,therefore, (Q8 R8 ) = .Moreover, preference relation > defined selectors problems consideredmust coincide.Example 11 Let P9 = (T9 , S9 ) CO problem, T9 = {a b c, (a b), (ac), (b c)} S9 = {a > b , > c }. (P9 ) = {{a}, {b}, {c}},{a} >P9 {b}, {a} >P9 {c}, {b} {c} incomparable. Thus, (P9 ) = {{a}}. Let369fiFaber, Truszczynski, & WoltranQ9 = (T9 , S90 ) CO problem, S90 = {a > b > c }. Clearly, (Q9 ) = (P9 ) ={{a}, {b}, {c}}. Moreover, {a} >Q9 {b} >Q9 {c}. Thus, (Q9 ) = {{a}} so, P9 Q9equivalent. However, strongly (gen-)equivalent. Indeed, let R9 = ({a}, ).Then, (P9 R9 ) = {{b}, {c}} (P9 R9 ) = {{b}}.main insight differences preference relation may hiddenpreferred outcomes but, present, exposed eliminatingpreferred outcomes obscure appropriately selected generator context.considerations apply CO ASO problems, thereforeformulate single theorem handles types problems.Theorem 13 CO (ASO, respectively) problems P Q, P g QP g Qg strongly equivalent (that is, Mod (P g ) = Mod (Q g ) CO problems,ModHT (P g ) = ModHT (Qg ) ASO problems) >PMod(P g ) = >QMod(Q g ) .view Examples 10 11, result unexpected. two examples demonstrated conditions characterization cannot, general, weakened.Corollary 8 Theorem 13, follows strong sel-equivalence CO problemsstronger property strong gen-equivalence.Corollary 14 CO problems P Q, P Q implies P g Q.general implication Corollary 14 cannot reversed, shown followingexample.Example 12 Let us consider problems P10 = (T10 , S10 ) Q10 = (T10 , ), T10 ={a b} S10 = {a > b , b > }. (P10 ) = (Q10 ) = {{a}, {b}}.Moreover, {a} 6P10 {b} {b} 6P10 {a}. Thus, (P10 ) = {{a}, {b}}. Since Qs10 =, also (trivially) {a} Q10 {b}. Thus, (Q10 ) = {{a}, {b}}, too,problems P10 Q10 equivalent. strongly sel-equivalent, though. LetR10 = (, {a > b }). Then, P10 R10 = P10 so, (P10 R10 ) = {{a}, {b}}.hand, {a} >Q10 R10 {b}. Thus, (Q10 R10 ) = {{a}}.However, virtue Theorem 13, strongly gen-equivalent. Indeed, triviallyggggMod (P10) = Mod (Q10) and, writing Mod (P10) = Mod (Q10), relations >PM1010>Qempty therefore equal.relation strong sel-equivalence strong gen-equivalence ASO problemcomplex. general, neither property implies even problems PQ assumed simple. P Q AS(P g ) =gAS(Qg ) PAS(P g ) =QAS(Qg ) (Corollary 9), P g Q ModHT (P ) =ggModHT (Qg ) >PMod(P g ) =>QMod(Q g ) (Theorem 13). Now, AS(P ) = AS(Q ) (regularequivalence programs) imply ModHT (P g ) = ModHT (Qg ) (strong equivalence)QP>PMod(P g ) =>QMod(Q g ) imply AS(P g ) =AS(Qg ) .conclude section one corollary concerning strong gen-equivalenceproblems empty selectors.370fiStrong Equivalence Qualitative Optimization ProblemsCorollary 15 CO (ASO, respectively) problems P Q P = Qs = ,P g Q P g Qg strongly equivalent respective semantics(that is, Mod (P g ) = Mod (Q g ) CO problems, ModHT (P g ) = ModHT (Qg ) ASOproblems).result evident definitions. However, also immediate consequenceTheorem 13. Indeed, optimization problems P Q empty selectors, conggdition >PMod(P g ) = >QMod(Q g ) equivalent Mod (P ) = Mod (Q ), consequencestrong equivalence P g Qg . Thus, problems empty selectors righthand equivalence assertion Theorem 13 reduces strong equivalencegenerators.5. Strong Equivalence Combined CaseFinally, consider relation sg , results considering contexts combinegenerators selectors. Since generators may vary here, previous section,semantics generators matters. But, previous section, difference boilsdifferent characterizations strong equivalence generators.start result characterizing strong equivalence CO ASO problemsrelative combined contexts (both generators selectors possibly non-empty)selectors consisting rules rank least j, respectively.Theorem 16 ranked CO (ASO, respectively) problems P Q, every ranks,[i,j]interval [i, j], P gQ following conditions hold:1. P g Qg strongly equivalent (that is, Mod (P g ) = Mod (Q g ) CO problems,ModHT (P g ) = ModHT (Qg ) ASO problems)2. >PMod(P g ) = >QMod(Q g )3. every I, J Mod (P g ) < diff P (I, J) < diff Q (I, J), diff P (I, J) =diff Q (I, J) diff P (I, J) > j diff Q (I, J) > jPQ<i<i4. >Mod(Pg ) = >Mod(Q g ) .corresponding characterizations CO ASO problems differ respective conditions (1), reflect different conditions guaranteeing strong equivalence generators classical answer-set semantics. Moreover, four conditions Theorem 16 obtained suitably combining extending conditionsTheorem 6 Theorem 13. First, combined strong equivalence implies strong genequivalence, condition (1) taken Theorem 13. Second, modify conditions (2)(3) Theorem 6 replacing (P<i ) Mod (P g ) (and accordingly (Q<i )Mod (Qg )), classical model P g give rise optimal classical equilibriumone upon addition context, aspect also already visible Theorem 13.Finally, add new condition stating relations >P<i >Q<i coincidesets models P g Qg . generators allowed extended, onemake two models outcomes extension. two371fiFaber, Truszczynski, & Woltranoutcomes, say J, related differently corresponding strict relations inducedrules ranks less i, say >P<i J >Q<i J, optimal Joptimal problem extending P matter preference rules ranksinterval [i, j] use (rules rank higher effect J ordered).hand, J incomparable >Q<i , remain incomparableQ extended. J equally good respect rules rank < i,rendered incomparable means preference rules rank i. case, J optimalQ extended. Finally, J >Q<i I, J remains optimal matter preferencerules ranks higher add. follows two relations >P<i >Q<is,[i,j]different, cannot P gQ condition (4) necessary.previous section, case selectors P Q empty reducesstrong gen-equivalence generators.Corollary 17 CO (ASO, respectively) problems P Q P = Qs =s,[i,j], every rank interval [i, j], P gQ P g Qg stronglyequivalent respective semantics (that is, Mod (P g ) = Mod (Q g ) CO problems,ModHT (P g ) = ModHT (Qg ) ASO problems).result simple consequence Theorem 16. condition (1) theoremimplies Mod (P g ) = Mod (Q g ) so, since selectors P Q empty,remaining conditions become trivially true.conclude section observations concerning relation sg COASO problems. contexts relevant may contain preference rules arbitrary ranks.start case CO problems, results stronger.derived general theorems above, present arguments relying resultsprevious sections, possible since CO problems equivalence strongequivalence generators coincide.saw last section CO problems strictly stronger relationg . fact, CO problems, coincides general relation sg .Theorem 18 CO problems P Q, P sg Q P Q.Proof. only-if implication evident. prove converse implication,use Proposition 4, reduces checking strong equivalence checking strongsel-equivalence. Let R LgU generator problem. Since P Q, Corollary 8Mod (P g ) = Mod (Qg ). Consequently, Mod ((P R)g ) = Mod ((Q R)g ). WritingMod (P g ) 0 Mod ((P R)g ) 0 . Thus, also Corollary 8,QR>PMR0 =>M 0 . Finally, condition (3) Corollary 8 P Q implies condition (3)corollary P R Q R (as R preference rules 0 ). follows,Corollary 8, P R Q R. Thus, Proposition 4, P sg Q. 2case simple CO problems ranked interval [1, 1], argumentrepeated using instead Corollary 8 equivalence (b) (c) Corollary9. way, one show simple CO problems, relations s,=1s,=1gcoincide. Thus, Corollary 9 (the equivalence (a) (b)) Theorem 18, simpleCO problems four relations sg , s,=1, s,=1 , coincide obtain followinggresult.372fiStrong Equivalence Qualitative Optimization ProblemsCorollary 19 simple CO problems P Q, properties P sg Q, P s,=1Q,gP s,=1 Q P Q equivalent.simple ASO problems still sg s,=1coincide generalgnotions different s,=1 (cf. subtle difference condition (c) comparedCorollary 9).Corollary 20 simple ASO problems P Q, following conditions equivalents,[1,](a) P sg Q (equivalently, P gQ)s,[1,1](b) P s,=1Q (equivalently, P ggQ)(c) ModHT (P g )=ModHT (Qg ) PMod(P g ) = QMod(Qg ) .Proof. implication (a)(b) evident.Let us assume (b). Theorem 16, ModHT (P g )=ModHT (Qg ). identityimplies Mod (P g ) = Mod (Qg ). Let us assume I, J Mod (P g ), PMod(P g ) J.Q>PMod(P g ) J then, Theorem 16, >QMod(Qg ) J so, Mod(Qg ) J. Otherwise,P J so, diff P (I, J) = . Theorem 16, diff Q (I, J) > 1. Since Q simple,diff Q (I, J) = . Thus, Q J and, also, QMod(Qg ) J. converse implication followssymmetry. Thus, (c) holds.Finally, assume (c) prove (a). end, show conditions (1)(4)Theorem 16 hold. Directly assumptions, condition (1) holds. Condition (2) follows Lemma 1. Moreover, also Mod (P g ) = Mod (Qg ). provecondition (3), let us assume I, J Mod (P g ) diff P (I, J) > 1. Since P simple,P J. Thus, Q J and, consequently, diff P (I, J) = = diff Q (I, J). Finally, conditionP<iQ<igg(4), i.e. >Mod(Pg ) = >Mod(Q g ) , obviously holds case = 1 Mod (P ) = Mod (Q ). 26. Complexitysection, study problems deciding various notions strong equivalence.Typically comparisons sets outcomes characterizations determinerespective complexity. start results concerning strong sel-equivalence.Theorem 21 Given optimization problems P Q, deciding P Q co-NP-completecase CO problems P2 -complete case ASO problems.Proof. [Sketch, detailed argument provided Appendix B.] membership, focuscomplementary problem consider pairs interpretations I, J violate leastone conditions stated Corollary 8. Clearly, witness pair interpretationsexists, also witness pair built atoms occurproblems P Q. pair guessed, verified polynomial time (forCO problems) polynomial time using NP oracle (for ASO problems) indeed373fiFaber, Truszczynski, & Woltranviolates conjunction three conditions Corollary 8. main observationmodel checking polynomial classical semantics, co-NP-completeequilibrium semantics (see Pearce, Tompits, & Woltran, 2009, Thm. 8).Hardness follows considering equivalence problem optimizations problemsempty selectors, known co-NP-hard (for classical semantics) P2 hard (for equilibrium semantics, see Pearce et al., 2009, Thm. 11). 2ranked case, observe increase complexity, explainedcharacterization given Theorem 6. Instead outcome checking, characterizationinvolves optimal outcome checking, difficult (unless polynomial hierarchycollapses).Theorem 22 Given optimization problems P Q rank interval [i, j], decidingP s,[i,j] Q P2 -complete case CO problems P3 -complete case ASOproblems.Proof. [Sketch, detailed argument provided Appendix B.] membership part essentially follows arguments proof Theorem 21, problemdeciding (P<i ) co-NP CO problems P2 ASO problems.hardness part, reduce following problem sel-equivalence CO problems: Given two propositional theories , decide whether possessminimal models. problem known P2 -complete (e.g., Eiter et al., 2007b,Thm. 6.15), problem remains hard negation normal form (NNF)given alphabet. adapt construction used Brewka et al., (2011).Given negation normal form theory , construct CO problem PT settingPTg= [u/u0 ] {u u0 | u U },PTs= {u0 > u | u U },U denotes set atoms occurring , [u/u0 ] stands theoryresulting replacing u u0 (we note ranks rules selector1).elements (PT ) one-to-one correspondence minimal models. theories U follows minimal models(PS ) = (PT ). Since problems PS PT selectors,latter condition equivalent PS s,2 PT (which shown directly exploitingcharacterization s,2 ).Concerning hardness part ASO problems, use following problem: giventwo open quantified Boolean formulas (QBFs) (X, ), (X, ), decide whetherpossess minimal models. problem P3 -hard (see Lemma 30 AppendixA). (X, ), construct P follows:Pg = {z z 0 | z X }{(y 0 ) w, w y, w 0 | }{[z/z 0 ] w, w w},Ps = {x0 > x | x X},374fiStrong Equivalence Qualitative Optimization Problems[z/z 0 ] stands formula obtained replacing z z 0 (X, ) (again,stress ranks rules selector 1). elements (P )one-to-one correspondence minimal models (X, ). reasonshow X , formulas (X, ) (X, )minimal models P s,2 P . 2Theorem 22 rank interval [i, j] given input. fixing interval,hardness results still hold, provided > 1. fact, critical condition Corollary 7(P<i ) = (Q<i ); rank intervals [1, j], selectors become empty conditionreduced (P ) = (Q), easier decide.characterizations imply remaining problems co-NP. stronggen-equivalence, co-NP-hardness follows directly Theorem 13 co-NP-completenessdeciding strong equivalence two propositional theories (for semantics).Theorem 23 Given two CO (ASO, respectively) problems P Q, deciding P g Qco-NP-complete.Finally, combined case hardness result follows Theorem 16 co-NPcompleteness deciding strong equivalence propositional theories.Theorem 24 Given ranked CO (ASO, respectively) problems P Q, rank intervals,[i,j][i, j], deciding P gQ co-NP-complete.construction, hardness results hold already simple optimization problems.7. Discussionintroduced formalism optimization problems, generalizing principles ASOprograms, particular, separation hard soft constraints (Brewka et al., 2003).focused two important specializations optimization problems: CO problemsASO problems. studied various forms strong equivalence classes optimization problems, depending contexts considered. Specifically, consideredfollowing cases: new preference information added, hard constraints remain unchanged (strong sel-equivalence); hard constraints added preferences remainunchanged (strong gen-equivalence); hard constraints preferences added(strong equivalence). best knowledge, natural classification equivalences preference formalisms studied yet. certain casesnotions coincide (Theorem 18) longer true underlying semanticschanged ranks contexts restricted.previous work, notion strong equivalence (both hard constraints preferencesadded) studied logic programs weak constraints Eiter et al.,(2007a) logic programs ordered disjunctions (LPODs) Faber et al., (2008).former formalism, separation strong equivalence different notionssuggested ASO problems would possible (it instructive compareEiter et al., 2007a, Lemma 23, results, e.g., Corollary 20), similar separationstrong equivalence straightforward LPODs. reason syntactic natureLPOD rules act like hard constraints preference rules time. Faber et375fiFaber, Truszczynski, & Woltranal., (2008) considered strong equivalence respect contexts logic programs(which similar strong gen-equivalence) combined case strong equivalence(called strong equivalence arbitrary contexts there), considercounterpart notion strong sel-equivalence. fact, even unclear whetherevery LPOD generating selecting modules cleanly separated.paper, established characterizations three types strong equivalence.exhibit striking similarities. characterizations strong sel-equivalence COASO problems Theorem 6 precisely same, mirroring fact generators subject change. Theorem 13 concerns strong gen-equivalence COASO problems. case, characterizations consist two requirements: strongequivalence generators, equality strict preference relations restrictedclass models generators. difference comes fact strongequivalence classical equilibrium-model semantics different characterizations. Theorem 16 concerns combined case strong equivalence alsodifferentiate CO ASO problems implicitly (as before, conditionsstrong equivalence different two semantics). Moreover, characterizationsprovided Theorem 16 arise rather systematic way given Theorems 613. case different semantics used strongly suggestsabstract principles play here. currently pursuing direction,conjecturing inherent feature preference formalisms separationlogical preferential constraints.Coming back LPODs, comments suggest identifying split representation formalism might interest. could lead alternative characterizations (combined) strong equivalence derived characterizations twoone-dimensional variants.Next, note results give rise problem rewriting methods transformoptimization problems strongly equivalent ones. provided two simple examplesillustrating application results Example 9 Corollary 12. Similar examplesconstructed results concerning strong gen-equivalence (combined) strongequivalence. systematic study optimization problem rewriting rules resultstrongly equivalent problems subject future work.Finally, established complexity deciding whether optimization problemsstrongly equivalent. Notably, general case strong (combined) equivalence problem co-NP-complete CO ASO problems. holds true stronggen-equivalence problem. strong sel-equivalence problem, situationcomplex. contexts form [1, j] [1, ] considered, problem decidingstrong sel-equivalence co-NP-complete CO problems P2 -complete ASO problems. rank interval allowed part input rank interval fixed [i, j],2, problem gets computationally harder: case ASO problems, P3 -hard;case CO problems P2 -hard. difference CO problems ASO problemscase strong sel-equivalence respect contexts consisting preference rulesranks intervals [1, j] [1, ] comes fact corresponding conceptsstrong sel-equivalence depend, particular, whether two theories equivalentrespect models (CO problems) respect equilibrium models (ASO problems).two types equivalence different complexities. jump complexity376fiStrong Equivalence Qualitative Optimization Problemsstrong sel-equivalence arbitrary rank intervals [i, j] allowed fixed2 comes fact cases, concept depends propertiesclass outcomes optimal respect rules ranks less i,cases depends properties class models. Decision problems concerning optimaloutcomes (such as: two theories optimal models) hardercorresponding versions problems models, explaining jump. resultsstrong sel-equivalence also imply ranked optimization problems cannot efficientlysimulated simple optimization problems.Acknowledgmentsthank reviewers useful constructive comments. first authorsupported Regione Calabria EU POR Calabria FESR 2007-2013 withinPIA project DLVSYSTEM s.r.l., MIUR PRIN project LoDeN.second author supported NSF grant IIS-0913459.Appendix A. Useful Lemmasprovide several lemmas use later proofs results discussedmain body paper.first two lemmas given without proofs, easy consequences resultsFerraris (2005) Ferraris Lifschitz (2005).Lemma 25 Let P theory, classical model P , let [I] = {a |U \ I} {a | I}. Then, (P [I]) = Mod (P [I ]) = {I}.Lemma 26 Let P theory, I, J two (classical) models 6= J, let[I, J] = {a b | I, b J}{a b | I, b U \ J}{a b | U \ I, b J}{a b | U \ I, b U \ J}.(P [I, J]) = Mod (P [I , J ])) = {I, J}.Lemma 27 Let P optimization problem, (P<j ), j 1, letjjRj [I] = {a > > | I} {a > > | U \ I)}.1. (P Rj [I]);2. every J J 6= Pj J, >P Rj [I] J.377fiFaber, Truszczynski, & WoltranProof. proving (1), simplify notation, write R Rj [I]. Since (P<j ),(P ). Clearly, (P R) = (P ) so, (P R). show (P R),let us consider arbitrary interpretation J (P R) assume J >P R I.particular, J 6= so, diff R (I, J) = j. diff P (I, J) < j, diff P R (I, J) < j.Consequently, J >(P R)<j I. Since rules R rank j, follows J >P<j I,contradiction fact (P<j ). Thus, diff P (I, J) j. Since diff R (I, J) = j,diff P R (I, J) = j. Therefore, J >P R implies J >R I, contradiction(since, definition Rj [I] = R, R J interpretation J). followsevery J (P R), J 6>P R I, is, (P R).assertion (2) evident, since definition Rj [I] = R, >R J interpretation J 6= I. 2Lemma 28 Let P optimization problem, I, J interpretations I, J (P<j ),union following sets rules:j 1, let Rj0 [I, J] Ls,jUj{a b > > | a, b J}j{a b > > | I, b U \ J}j{a b > > | U \ I, b J}j{a b > > | U \ I, b U \ J}.following hold:1. every r Rj0 [I, J], vI (r) = vJ (r) = 1;2. every interpretation K/ {I, J}, rule r Rj0 [I, J] vK (r) = 2;3. >P J J/ (P Rj0 [I, J]).Proof. simplify notation, write R0 Rj0 [I, J].assertion (1) evident. prove assertion (2), note conjunctionformulas appear top options preference rules R0 equivalent^^^^{a | I} {a | U \ I}{b | b J} {b | b U \ J} .formula two models: J. Thus, every interpretation K,least one formulas appears top options preference rules R0satisfied K. corresponding preference rule r, vK (r) = 2.Finally, prove assertion (3), let us assume >P J. Together (1),0implies >P R J. Thus, J/ (P R0 ). prove converse implication, let us0assume 6>P J. Together (1), implies 6>P R J. Next, note0diff P (J, K) < j, since J (P<j ), K 6>P R J. diff P (J, K) j, property (2)0proved implies K 6>P R J. Since K arbitrary interpretation different0J, since 6>P R J, J (P R0 ) follows. 2378fiStrong Equivalence Qualitative Optimization ProblemsNext, note property allows us infer strong sel-equivalence two problems treated CO problems strong sel-equivalence problemstreated ASO problems (and conversely). property relies fact changingselectors affect class outcomes. proof simple omit it.Lemma 29 Let P Q optimization problems Mod (P g ) = (P g )Mod (Q g ) = (Qg ), [i, j] rank interval. Then, P s,[i,j] Q P Q viewedCO problems, P s,[i,j] Q P Q viewed ASO problems.final results section useful complexity results.Lemma 30 Deciding whether open QBFs (X, ) (X, ),negation normal form, minimal models P3 -hard.Proof. show result reduction P3 -hard problem deciding satisfiability QBFs form ZXY , negation normal form. LetQBF form consider following formulas, Z 0 = {z 0 | z Z}, uv fresh atoms:^^=(z z 0 ) (x u) (v v)zZ=^zZxX0(z z ) (^x v) (u u).xXclear negation normal form. differencecompared latter uses u former uses v vice versa,point including conjuncts v v u u occurrences u v. show (U, ) (U, ) minimal models(with open variables U = Z Z 0 X {u, v}) true.note considering models minimal models (U, ) (U, )move quantifier appears directly front .occurrences atoms outside .also clear contains neither u v, model (U, )model (U, ). Consequently, holdsminimal model (U, ) minimal model (U, ).Only-if direction: Let us assume false. Then, exists interpretation Zatoms Z, every interpretation J atoms X, false. Let usconsider Mu = (Z \ I)0 X {u}. Clearly, Mu model YV. N modelN Mu , (Z \ I)0 N conjunct zZ (z z 0 ). Thus,N Z = I. follows false atoms Z X interpreted N and,consequently, X {u} N . Thus, N = Mu , implies Mu minimal model. Essentially argument shows Mv = (Z \ I)0 X {v} minimalmodel . Since Mu 6= Mv , different minimal models.If-direction: Let us assume ZXY true. Let minimal model .Clearly, v/ (as \ {v} also model ). Let us assume u . Let usassume addition X \ 6= . assumptions imply interpretations379fiFaber, Truszczynski, & Woltran= Z atoms Z J = X atoms X, true. follows \{u}model , contradiction. Thus, X . Let = Z. Since ZXYtrue, interpretation J X atoms X true, atomsZ interpreted atoms X interpreted J. follows (Z \ I)0 Jmodel . Since (Z \ I)0 J , contradiction. followsu/ . Consequently, comment above, minimal model . converseholds symmetry argument. Thus, two formulas minimal models. 2Lemma 31 Given ranked preference rule r, interpretation I, calculating vI (r)done polynomial time.Proof. Initialize variable 1. Check whether 6|= bd (r) so, halt. Then, checkwhether |= hd (r) so, halt; otherwise increment continue checking;options head r exist, set = 1. checks model checking taskpropositional formula hence polynomial time. Upon halting, equal vI (r). 2Lemma 32 Given optimization problem P two interpretations I, J, calculatingdiff P (I, J) done polynomial time.Proof. Initialize variable x , scan rules P ranked preferencerule r P , determine whether vI (r) 6= vJ (r) (in polynomial time due Lemma 31). so,set x rank (r) rank (r) < x. processed rules, x equal diff P (I, J). 2Lemma 33 Given optimization problem P , two interpretations I, J, deciding whether>P J holds done polynomial time.Proof. First, sort rules P ranks. Starting lowest rank upwards,following rank i: Check rules rank whether vI (r) < vJ (r)vI (r) vJ (r). vI (r) < vJ (r) holds least one rule vI (r) vJ (r)rules rank i, accept. rules r r0 rank vI (r) < vJ (r)vI (r0 ) > vJ (r0 ), reject. ranks processed, reject. Lemma 31, stepsdoable polynomial time. 2Lemma 34 Given classical optimization problem P interpretation I, decidingwhether (P ) co-NP.Proof. show witness J complementary problem (deciding whether/ (P )) verified polynomial time. J = I, verify polynomial timesatisfy propositional theory P g , well-known feasible polynomial time. Otherwise, verify polynomial time J satisfies P g J >P (bothpolynomial time, latter Lemma 33). 2380fiStrong Equivalence Qualitative Optimization ProblemsLemma 35 Given answer set optimization problem P interpretation I, decidingwhether (P ) P2 .Proof. show witness J complementary problem (deciding whether/ (P )) verified polynomial time using NP oracle. J = I, verifysatisfy P g using NP oracle. possible answer-set checkingco-NP-complete (Pearce et al., 2009, Thm. 8). Otherwise, verify using NP oracle Jsatisfies propositional theory P g J >P (in polynomial time Lemma 33). 2Appendix B. ProofsTheorem 6 ranked optimization problems P Q, every rank interval [i, j],P s,[i,j] Q following conditions hold:1. (P<i ) = (Q<i )2. >P(P<i ) = >Q(Q<i )3. every I, J (P<i ) < diff P (I, J) < diff Q (I, J), diff P (I, J) =diff Q (I, J) diff P (I, J) > j diff Q (I, J) > j.s,[i,j]Proof. () Let R LUlet (P R). Lemma 3, ((P R)<i ). Sinces,[i,j]R LU , R<i = (, ). Thus, (P<i ). assumption, follows (Q<i ).particular, (Q<i ) and, (Q<i ) = (Q), (Q). Since Rg = ,(Q R). show (Q R) show J (Q R)J >QR I. Let us assume contrary J exists. Lemma 5,three possibilities.First, assume diff Q (I, J) < diff R (I, J) J >Q I. latter propertyimplies diff Q (I, J) (otherwise, would J >Q<i I, contrary (Q<i )).particular, Q<i J and, since (Q<i ), follows J (Q<i ).(1), J (P<i ). Thus, (2), J >P I. diff Q (I, J) j diff R (I, J) > j and,s,[i,j]R LU , diff R (I, J) = . Since J >P I, J >P R I. Otherwise, diff Q (I, J) < j.< diff Q (I, J) then, (3), diff P (I, J) = diff Q (I, J). = diff Q (I, J), (3),diff P (I, J) i. either case, diff P (I, J) < diff R (I, J). Since J >P I, J >P R I.s,[i,j]Next, let us assume diff Q (I, J) > diff R (I, J) J >R I. Since R LU ,follows diff R (I, J) so, diff Q (I, J) > i. recall (Q<i ).Thus, J (Q<i ) and, consequently, J (P<i ). diff Q (I, J) j then, (3),diff P (I, J) = diff Q (I, J) so, diff P (I, J) > diff R (I, J). j < diff Q (I, J) then, also(3), j < diff P (I, J). Since diff Q (I, J) > diff R (I, J), diff R (I, J) < and, consequently,diff R (I, J) j. Thus, diff P (I, J) > diff R (I, J) case, too. Since J >R I, J >P Rfollows.Finally, let us assume diff Q (I, J) = diff R (I, J), J >Q J >R I. Sinces,[i,j]R LU , diff R (I, J) i. Thus, diff Q (I, J) and, since (Q<i ), J (Q<i ).(1) J (P<i ) and, (2), J >P I. Consequently, J >P R I.cases obtained J >P R I, contrary (P R), contradiction.381fiFaber, Truszczynski, & Woltran() Let us assume (P<i ) 6= (Q<i ). Without loss generality, assume(P<i ) \ (Q<i ) define R = (, Ri [I]) LUs,=i , Ri [I]Lemma 27. lemma, (P R). hand, since/ (Q<i )s,=i Q, contraryR Ls,=i,/((QR)).Lemma3,/(QR).Thus,P6<iUassumption.follows (P<i ) = (Q<i ), is, condition (1) holds. prove condition(2), let us consider interpretations I, J (P<i ) >P J. Let Ri0 [I, J]selector defined Lemma 28. Since >P J, Lemma 28(3) implies J/ (P Ri0 [I, J]).Consequently, J/ (Q Ri0 [I, J]). Lemma 28(3) again, follows >Q J.Qsymmetry, > J implies >P J so, condition (2) holds.prove condition (3), let us assume interpretations J satisfyassumptions violate corresponding conclusion. follows, write pdiff P (I, J) q diff Q (I, J). Thus, p > q > i, p 6= q, p jq j. Without loss generality, assume p < q. follows p finite and,consequently, diff P (I, J) < 6= J. Moreover, < q p j.Let us assume first p < i. take problem R = (, Ri [J]), Ri [J]specified Lemma 27 define P 0 = P R Q0 = Q R. Since I, J (P<i )also I, J (Q<i ). assumptions, q > i. Thus, J Qi and, particular,J Qi I. recall 6= J. Consequently, assertion (2) Lemma 2700 ) diff P 0 (I, J) =J >Q I. Since rules R ranks i, I, J (P<i00diff P (I, J) < i. follows J 6>P (otherwise, diff P (I, J) < would0J >P<i I). Let us define R0 = (, Ri0 [I, J]), Ri0 [I, J] specified Lemma 28. Since0J 6>P I, assertion (3) lemma, (P 0 R0 ). P 0 R0 = P (R R0 ).Thus, (P (R R0 )) and, P s,[i,j] Q, (Q (R R0 )) = (Q0 R0 ).0assertion (3) Lemma 28, J 6>Q I, contradiction.Next, let p = i. Clearly, 6>P J J 6>P I. Without loss generality, let us assumeJ 6>P I. Let R0 = (, Ri [I, J]), let us define P 0 = P R0 Q0 = Q R0 . Since0 ). Moreover, J 6>Prules R0 ranks i, I, J (P<i ) implies I, J (P<i0follows Lemma 28(1) J 6>P I. Let R = (, Ri [J]). rules R rank00diff P (I, J) = diff P (I, J) = i. Thus, follows J 6>P R I. Moreover, every000 ). diff P 0 (K, I) i,K/ {I, J}, diff P (K, I) < i, K 6>P R follows (P<i0K 6>P R follows Lemma 28(2). Thus, (P 0 R). hand,0recall diff Q (I, J) = q > i. Thus, diff Q (I, J) > i, (Lemma 28(1)). follows00J Qi I. Consequently, Lemma 27(2), J >Q R I. Thus,/ (Q0 R),contradiction.follows p > i. complete proof (3), recall p j. Clearly, 6>P JJ 6>P I. Without loss generality, let us assume J 6>P I. Let R0 = (, Ri [I, J]),let us define P 0 = P R0 Q0 = Q R0 . Let us assume interpretation K/0P0PP{I, J}, K > I. Lemma 28(2), follows diff (I, K) < i. Thus, diff (I, K) < i,0contradiction (P<i ). Thus, every interpretation K/ {I, J}, K 6>P0and, argument, K 6>P J. Consequently, every interpretation K/ {I, J},00P<pP<pK 6>K 6>J. addition, since I, J (P<i ), Lemma 28(1) obtain000 ). addition, Lemma 28(1),neither >P<p J J >P<p I. Thus, I, J (P<p00diff P (I, J) = diff P (I, J) = p and, since J 6>P I, J 6>P I.382fiStrong Equivalence Qualitative Optimization Problems00Let R = (, Rp [J]). (i) diff P (I, J) = p, (ii) J 6>P I, (iii) rules R00rank p, follows J 6>P R I. Moreover, every K/ {I, J}, diff P (K, I) < i,0000 ). diff P (K, I) i, K 6>P R followsK 6>P R follows (P<iLemma 28(2) (and definition P 0 ). Thus, (P 0 R). hand,0recall diff Q (I, J) = q > p. Thus, diff Q (I, J) > p, (Lemma 28(1)). follows00/ (Q0 R),J Qp I. Consequently, Lemma 27(2), J >Q R I. Thus,s,[i,j]000contradiction (we recall PQ, P = P (R R ), Q = Q (R R0 ), and,s,[i,j]p j, R R0 LU ). 2Theorem 13 CO (ASO, respectively) problems P Q, P g QP g Qg strongly equivalent (that is, Mod (P g ) = Mod (Q g ) CO problems,ModHT (P g ) = ModHT (Qg ) ASO problems) >PMod(P g ) = >QMod(Q g ) .Proof. () first assumption implies strong equivalence generators P g Qgrelative corresponding semantics (we recall case classical semantics,strong standard equivalence coincide). follows every problem R LgU ,(P R) = (Q R). Moreover, semantics, (P R) Mod (P g Rg ) Mod (P g )and, similarly, (Q R) Mod (Qg Rg ) Mod (Qg ). Since >PMod(P g ) = >QMod(Q g ) ,QRRLemma 2,R LgU change preferences, >P(Pg Rg ) = >(Qg Rg ) .(P R) = (Q R).() Let us assume P g Qg strongly equivalent. Then, problemR LgU (P R) 6= (Q R). Without loss generality, assumeinterpretation I, (P R) \ (Q R). Let us define problem LgU setting= ([I], ), [I] defined Lemma 25. lemma, (P R ) = {I}(Q R ) = . former property implies necessarily preferred,(P RT ), latter one implies (QRT ) = . contradictionassumption P g Q. Thus, P g Qg strongly equivalent, is, Mod (P g ) =Mod (Qg ), case P Q CO problems, ModHT (P g ) = ModHT (Qg ),case P Q ASO problems.Since ModHT (P g ) = ModHT (Qg ) implies Mod (P g ) = Mod (Qg ), latter identity holdstwo cases. equality, write Mod (P g )Mod (Qg ). remains show >PM =>Q. Towards contradiction, let us assumeI, J exactly one two relations; without loss generalityassume >P J 6>Q J. former identity implies, particular,6= J. Let = ([I, J], ), [I, J] theory defined Lemma 26. lemma,(P ) = (Q ) = {I, J}. Clearly, J/ (P ) J (Q ), contraryassumption P g Q. 2Theorem 16 ranked CO (ASO, respectively) problems P Q, every ranks,[i,j]interval [i, j], P gQ following conditions hold:1. P g Qg strongly equivalent (that is, Mod (P g ) = Mod (Q g ) CO problems,ModHT (P g ) = ModHT (Qg ) ASO problems)2. >PMod(P g ) = >QMod(Q g )383fiFaber, Truszczynski, & Woltran3. every I, J Mod (P g ) < diff P (I, J) < diff Q (I, J), diff P (I, J) =diff Q (I, J) diff P (I, J) > j diff Q (I, J) > jPQ<i<i4. >Mod(Pg ) = >Mod(Q g ) .Proof. () Proposition 4, suffices prove every R LgU , P R s,[i,j] QR.(1), (P R) = (Q R) (we recall (P ) denotes set outcomes optimization problem P ; (P ) = Mod (P g ) case CO problems,(P ) = (P g ) case ASO problems). Moreover, type problems, also(P R) Mod (P g R g ) Mod (P g ) and, similarly, (Q R) Mod (Q g R g )Mod (Q g ). Since rules R rank least i, condition (4) follows(P R)(QR)>(P R)<i =>(QR)<i . Lemma 2, ((P R)<i ) = ((Q R)<i ) so, condition(1) Theorem 6 holds P R Q R. Since ((P R)<i ) (P R) Mod (P g ),since corresponding inclusions hold Q, too, conditions (2)(3) theoremP Q imply conditions (2)(3) Theorem 6 P R Q R. Thus,Theorem 6, P R s,[i,j] Q R.s,[i,j]() Let us assume P gQ. Then, P g Q follows and, Theorem 13, impliesappropriate version condition (1). Since ModHT (P g ) = ModHT (Qg ) implies Mod (P g ) =Mod (Q g ), two versions assertion Mod (P g ) = Mod (Q g ).proof, write Mod (P g ) and, equality, alsoMod (Q g ).Next, interpretations I, J 6= J, define R = ([I, J], ),[I, J] Lemma 26. Let us define P1 = P R Q1 = QR. P1 s,[i,j] Q1 .Moreover, Lemma 26, also (P1 ) = (Q1 ) = {I, J}.prove condition (4), let us assume >P<i J. follows >P1 J (we recallR contains preference rules). Since (P1 ) = {I, J}, J/ (P1 ) (P1 ).assumption, J/ (Q1 ). Since (Q1 ) = {I, J}, >Q1 J. particular,(Q1 ). diff Q (I, J) < then, since R preference rules, >Q<i J. Thus, let usassume diff Q (I, J) let us define R0 = (, Ri [J]), Ri [J] Lemma27. Since (i) >P<i J, (ii) R preference rules, (iii) preference rules R00rank i, follows >P1 R J. generator module R0 empty. follows(P1 R0 ) = (Q1 R0 ) = {I, J}. Thus, J/ (P1 R0 ) and, consequently, J/ (Q1 R0 ).QQ1Since diff (I, J) i, diff (I, J) i. Moreover, (Q1 ) so, also ((Q1 )<i ).Thus, J ((Q1 )<i ). Lemma 27, J (Q1 R0 ), contradiction. argument shows>P<i J implies >Q<i J. converse implication follows symmetry so,condition (4) holds.prove condition (2), let us assume >P J. diff P (I, J) < i, >P<i Jand, (4), >Q<i J. Thus, >Q J. Let us assume diff P (I, J) i. Since(P1 ) = {I, J} since >P J implies >P1 J, J/ (P1 ). Thus, J/ (Q1 ). Since(Q1 ) = {I, J}, >Q1 J so, >Q J.prove condition (3), without loss generality assume < diff P (I, J). Thus,also < diff P1 (I, J) I, J ((P1 )<i ), latter follows properties (P1 ) = {I, J} diff P1 (I, J) = diff P (I, J) > i. Since P1 s,[i,j] Q1 ,condition (3) Theorem 6 holds P1 , Q1 , J, is, diff P1 (I, J) = diff Q1 (I, J)diff P1 (I, J) > j diff Q1 (I, J) > j. Consequently, diff P (I, J) = diff Q (I, J)384fiStrong Equivalence Qualitative Optimization Problemsdiff P (I, J) > j diff Q (I, J) > j, is, condition (3) holds. 2Theorem 21 Given optimization problems P Q, deciding P Q co-NP-completecase CO problems P2 -complete case ASO problems.Proof. membership, consider complementary problem. Corollary 8,specified problem decide whether least one conditions (1) - (3)holds:1. (P ) 6= (Q), equivalently, I, exactly one identities (P )(Q) holds;2. I, J (P ), diff P (I, J) 6= diff Q (I, J);3. >P(P ) 6= >Q(Q) , equivalently, I, J, I, J (P ) (Q) exactlyone properties >P J >Q J holds.show problem NP CO problems P2 ASO problems.say pair interpretations I, J witness instance problemYES instance demonstrates one conditions (1) - (3) hold. easy seewitness exists, witness I, J J consist atomsoccur P Q. witness guessed, condition (1) verifiedpolynomial time CO problems (this model-checking problem interpretationtheory) and, ASO problems, polynomial time assist two callsNP oracle, since model checking equilibrium-model semantics co-NP-complete(Theorem 8, Pearce et al. (2009)). Since condition (2) verified polynomial timeLemma 32, condition (3) polynomial time CO problems polynomial timeassist four calls NP oracle ASO problems (Lemma 33 resultPearce et al., (2009) mentioned above), membership part assertion follows.hardness, observe case problems empty selectors, coincidesequivalence propositional theories case CO problems, equivalenceequilibrium theories case ASO problems. former well known co-NP-hard,latter P2 -hard (Theorem 11, Pearce et al. (2009)). 2Theorem 22 Given optimization problems P Q rank interval [i, j], decidingP s,[i,j] Q P2 -complete case CO problems P3 -complete case ASOproblems.Proof. prove membership part, consider complementary problem.Theorem 6, problem consists deciding whether case least onefollowing conditions holds:1. (P<i ) 6= (Q<i ), equivalently, interpretation I, exactly one properties (P<i ) (Q<i ) holds;2. >P(P<i ) 6= >Q(Q<i ) , equivalently, interpretations I, J (P<i ) (Q<i )exactly one properties >P J >Q J holds;3. I, J (P<i ) (Q<i ) < diff P (I, J) < diff Q (I, J),diff P (I, J) 6= diff Q (I, J) holds diff P (I, J) j diff Q (I, J) j.385fiFaber, Truszczynski, & Woltrancall pair interpretations I, J demonstrates one conditionsholds witness. easy see witness, also one consistsatoms occur P Q. show complementary problem P2CO problems P3 ASO problems showing witness guessedverified polynomial time, using NP oracle dealing CO problemP2 oracle dealing ASO problem.Consider witness I, J two interpretations. One test whether I, J verifiescondition (1) (only matters here) polynomial time two calls NP oracle CO problems (Lemma 34), two calls P2 oracle ASO problems(Lemma 35). verify condition (2), need four calls respective oracles testI, J (P<i ) (Q<i ) polynomial-time computation test exactly oneproperties >P J >Q J holds (Lemma 33). Similarly, condition (3), usefour calls respective oracles test I, J (P<i ) (Q<i ) polynomial-timecomputation test condition involving diff P (I, J) diff Q (I, J) (Lemma 32).hardness part, start case CO problems. Therefore, reducefollowing problem strong sel-equivalence: given two propositional theories , decidewhether possess minimal models. problem known P2 -complete(for instance, equivalence positive disjunctive programs known P2 -complete, seee.g., Eiter et al., 2007b, Thm. 6.15, means testing whether two propositional formulasparticular class minimal models). problem remains hardnegation normal form alphabet. Given negation normal form theoryconstruct CO problem PT elements (PT ) one-to-onecorrespondence minimal models . adapt construction used (Brewkaet al., 2011). Specifically, setPTg = [u/u0 ] {u u0 | u U },U collection atoms occurring , [u/u0 ] stands replacing uu0 ,PTs = {u0 > u | u U }.first observation outcome PT must form {y 0 | U \ I}U . interpretation U write + = {y 0 | U \ I}. clear|= u + |= u0 , hence also |= + |= [u/u0 ].Hence one-to-one mapping models outcomes + PT .let us assume + (PT ). |= , NN 6|= . Indeed N |= , N + |= PTg rules r PTs form u0 > u,u \ N , obtain vN + (r) = 1 < 2 = vM + (r) rules r0 PTsvN + (r0 ) = 2 = vM + (r0 ). implies N + >PT + , contradicting + (PT ). Thus,minimal model .Conversely, let us assume minimal model . + (PT )N + (PT ) N + >PT + hold, implying + (PT ). Indeed,N + >PT + , vN + (r) < vM + (r) least one r PTs vN + (r0 ) vM + (r0 )r0 PTs . latter implies N former shows N 6= . Since N |=contradicts assumption minimal model . follows + (PT ).thus + (PT ) minimal model . Moreover,U follows minimal models386fiStrong Equivalence Qualitative Optimization ProblemsPS s,2 PT . Indeed, R LUs,2 easy verify (PS ) = (PS R)(PT ) = (PT R). observation follows fact distinctI, J (PS ) PS J distinct I, J (PT ) PT J. Thus,rules R which, weaker rank, break ties, affect sets optimaloutcomes.Concerning hardness ASO problems, use similar idea. However, shalluse following problem: given two open QBFs (X, ), (X, ), decide whethertwo QBFs possess minimal models. Lemma 30, problem P3 -hardand, moreover, assume negation normal form. reductioncombines idea reduction general ASP consistency (Eiter& Gottlob, 1995). precisely, z X introduce new variable z 0 ,construct P given (X, ) follows:Pg = {z z 0 | z X }{(y 0 ) w, w y, w 0 | }{[z/z 0 ] w, w w},[z/z 0 ] stands replacing z z 0 , w globally new atom.selector setPs = {x0 > x | x X}.equilibrium model Pg must contain w (otherwise w w would unsatisfied),must also contain {y, 0 | } (otherwise w y, w 0 wouldunsatisfied); write W {y, 0 | } {w} set contained equilibriummodel. Moreover, equilibrium model must form V {z 0 | z X \ V } W .Indeed, one x x0 must hold x X satisfy xx0 , both, otherwisehM \ {x}, |=HT Pg well, contradicting fact equilibrium model Pg .interpretation X write + = {x0 | x X \ I} W Pg . One showmodel (X, ) + equilibrium model Pg . Indeed,satisfies (X, ), hI + , + |=HT Pg J + holds hJ, + 6|=HT Pg .hand, satisfy (X, ) exists JJ 6|= (X, ). follows hI + \ ({y |/ J} {y 0 | J} {w}), + |=HT Pg (thekey element argument [z/z 0 ] contains occurrences negation,negation normal form so, + \ ({y |/ J} {y 0 | J} {w}) 6|= [z/z 0 ];+property allows one show hI \({y |/ J}{y 0 | J}{w}), + |=HT [z/z 0 ] w).+Thus, equilibrium model Pg .correspondence models (X, ) outcomes (equilibriummodels) + P established, handle issue minimality case COproblems. Let us assume first + (P ). Then, demonstrated, satisfies(X, ). Moreover, N , N satisfy (X, ). IndeedN would satisfy (X, ), would (i) N + (P ), (ii) rules r Psform u0 > u, u \ N , vN + (r) = 1 < 2 = vM + (r), (iii) rulesr0 Ps , vN + (r0 ) = 2 = vM + (r0 ); three properties would imply N + >P + , contradicting + (P ). Conversely, let us assume minimal model (X, ).+ (P ) N + (P ) show N + >P + hold387fiFaber, Truszczynski, & Woltran(implying + (P )). end, reason follows. N + >P + would hold,vN + (r) < vM + (r) least one r Ps , vN + (r0 ) vM + (r0 ), r0 Ps .course implies N and, since N satisfies (X, ) (we recall N +equilibrium model Pg so, N model (X, )), contradicts assumptionminimal model (X, ). thus + (P )minimal model (X, ). fact, reasoning case CO problems,obtain (X, ) (X, ) minimal modelsP s,2 P . 2Theorem 23 Given two CO (ASO, respectively) problems P Q, deciding P g Qco-NP-complete.Proof. Deciding strong equivalence propositional theories classical semanticsco-NP-hard case, strong equivalence equivalence coincide. also coNP-hard equilibrium-model semantics (Lin, 2002). Thus, hardness partassertion follows Corollary 15.prove membership, consider complementary problem. Theorem 13,consists deciding whether least one conditions (1) (2) holds:1. P g Qg strongly equivalent or, equivalently, Mod (P g ) 6= Mod (Q g ), COproblems, ModHT (P g ) 6= ModHT (Qg ), ASO problems;2. >PMod(P g ) 6= >QMod(Q g ) or, equivalently, interpretations I, J modelsgP Qg , exactly one properties >P J >Q J holds.Consequently, consider pair interpretations I, J witness instanceproblem YES instance model (for CO problems) hI, JiHT-model (for ASO problems) exactly one two theories P g Qg , I, Jmodels P g Qg exactly one properties >P J >Q J holds.easy see witness exists, witness I, JJ consist atoms occur P Q. witness guessed, verifying(showing condition (1) (2) holds) done polynomial time. wellknown checking whether model (hI, Ji HT-model) propositional theorydone polynomial time, holds true deciding >P J >Q J(Lemma 33). Thus, complementary problem NP. 2Theorem 24 Given ranked CO (ASO, respectively) problems P Q, rank intervals,[i,j][i, j], deciding P gQ co-NP-complete.Proof. membership, consider complementary problem. Theorem 16,consists deciding whether least one conditions (1) - (4) holds:1. P g Qg strongly equivalent (that is, Mod (P g ) 6= Mod (Q g ) CO problems,ModHT (P g ) 6= ModHT (Qg ) ASO problems);2. interpretations I, J models Mod (P g ) Mod (Q g ), exactlyone properties >PMod(P g ) J >QMod(Q g ) J holds;388fiStrong Equivalence Qualitative Optimization Problems3. I, J Mod (P g ) < diff P (I, J) < diff Q (I, J), diff P (I, J) 6=diff Q (I, J) holds diff P (I, J) j diff Q (I, J) j;PQ<i<i4. >Mod(Pg ) 6= >Mod(Q g ) or, equivalently, interpretations I, J modelsMod (P g ) Mod (Q g ), exactly one properties >P<i J >Q<i J holds.prove complementary problem NP. proofs, usemembership witness pair interpretations I, J explicitly demonstrates oneconditions (1) - (4) holds. before, witness exists, also one consistingatoms occurring programs P Q only. condition, given pair I, J(restricted atoms P Q), one verify polynomial time whether conditionholds (for condition (1), repeat argument previous proof, conditions (2)(4), use Lemma 33, condition (3) Lemma 32).Hardness follows directly co-NP-completeness deciding strong equivalence two propositional theories either semantics consider Corollary 17. 2ReferencesBoutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2003). CP-nets: toolrepresenting reasoning conditional ceteris paribus preference statements.Journal Artificial Intelligence Research, 21, 135191.Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). Preference-basedconstrained optimization CP-nets. Computational Intelligence, 20, 137157.Brewka, G., Niemela, I., & Syrjanen, T. (2004). Logic programs ordered disjunctions.Computational Intelligence, 20 (2), 335357.Brewka, G., Niemela, I., & Truszczynski, M. (2003). Answer set optimization. Gottlob,G., & Walsh, T. (Eds.), Proceedings 18th International Joint ConferenceArtificial Intelligence (IJCAI 2003), pp. 867872. Morgan Kaufmann.Brewka, G., Niemela, I., & Truszczynski, M. (2011). Answer set optimization. Unpublishedmanuscript.Calimeri, F., Ianni, G., Krennwallner, T., & Ricca, F. (2012). answer set programmingcompetition. AI Magazine, 33 (4), 114118.Delgrande, J. P., Schaub, T., Tompits, H., & Wang, K. (2004). classification survey preference handling approaches nonmonotonic reasoning. ComputationalIntelligence, 20 (2), 308334.Eiter, T., Faber, W., Fink, M., & Woltran, S. (2007a). Complexity results answer setprogramming bounded predicate arities implications. Annals MathematicsArtificial Intelligence, 51 (24), 123165.Eiter, T., Fink, M., & Woltran, S. (2007b). Semantical characterizations complexityequivalences answer set programming. ACM Transactions Computational Logic,8 (3).389fiFaber, Truszczynski, & WoltranEiter, T., & Gottlob, G. (1995). computational cost disjunctive logic programming:Propositional case. Annals Mathematics Artificial Intelligence, 15 (3/4), 289323.Faber, W., Truszczynski, M., & Woltran, S. (2012). Strong equivalence qualitative optimization problems. Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Proceedings13th International Conference Principles Knowledge RepresentationReasoning (KR 2012), pp. 188198. AAAI Press.Faber, W., & Konczak, K. (2006). Strong order equivalence. Annals MathematicsArtificial Intelligence, 47 (12), 4378.Faber, W., Tompits, H., & Woltran, S. (2008). Notions strong equivalence logicprograms ordered disjunction. Brewka, G., & Lang, J. (Eds.), Proceedings11th International Conference Principles Knowledge RepresentationReasoning (KR 2008), pp. 433443. AAAI Press.Ferraris, P. (2005). Answer sets propositional theories. Baral, C., Greco, G., Leone,N., & Terracina, G. (Eds.), Proceedings 8th International Conference LogicProgramming Nonmonotonic Reasoning (LPNMR 2005), Vol. 3662 LectureNotes Computer Science, pp. 119131. Springer.Ferraris, P., & Lifschitz, V. (2005). Mathematical foundations answer set programming.Show Them! Essays Honour Dov Gabbay, pp. 615664. CollegePublications.Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctivedatabases. New Generation Computing, 9, 365385.Goldsmith, J., Lang, J., Truszczynski, M., & Wilson, N. (2008). computational complexity dominance consistency CP-nets. Journal Artificial IntelligenceResearch, 33, 403432.Goldsmith, J., & Junker, U. (Eds.). (2008). Special Issue Preferences, Vol. 29(4) AIMagazine.Heyting, A. (1930). Die formalen Regeln der intuitionistischen Logik. Sitzungsberichte derPreussischen Akademie der Wissenschaften, 1, 4256.Kaci, S. (2011). Working Preferences. Springer.Lifschitz, V. (1985). Computing circumscription. Joshi, A. K. (Ed.), Proceedings9th International Joint Conference Artificial Intelligence (IJCAI 1985), pp.121127. Morgan Kaufmann.Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACMTransactions Computational Logic, 2 (4), 526541.Lin, F. (2002). Reducing strong equivalence logic programs entailment classicalpropositional logic. Fensel, D., Giunchiglia, F., McGuiness, D. L., & Williams, M.A. (Eds.), Proceedings 8th International Conference Principles KnowledgeRepresentation Reasoning (KR 2002), pp. 170176. Morgan Kaufmann.Marek, V. W., & Truszczynski, M. (1993). Nonmonotonic Logic; Context-Dependent Reasoning. Springer, Berlin.390fiStrong Equivalence Qualitative Optimization ProblemsMarek, V., & Truszczynski, M. (1999). Stable models alternative logic programmingparadigm. Apt, K., Marek, W., Truszczynski, M., & Warren, D. (Eds.), LogicProgramming Paradigm: 25-Year Perspective, pp. 375398. Springer, Berlin.Niemela, I. (1999). Logic programming stable model semantics constraint programming paradigm. Annals Mathematics Artificial Intelligence, 25 (3-4), 241273.Pearce, D. (1997). new logical characterisation stable models answer sets. Dix,J., Pereira, L. M., & Przymusinski, T. (Eds.), Proceedings 6th InternationalWorkshop Non-Monotonic Extensions Logic Programming (NMELP 1996), Vol.1216 Lecture Notes Computer Science, pp. 5770. Springer.Pearce, D., Tompits, H., & Woltran, S. (2009). Characterising equilibrium logic nestedlogic programs: Reductions complexity. Theory Practice Logic Programming, 9 (5), 565616.Simons, P., Niemela, I., & Soininen, T. (2002). Extending implementing stablemodel semantics. Artificial Intelligence, 138, 181234.Turner, H. (2003). Strong equivalence made easy: Nested expressions weight constraints.Theory Practice Logic Programming, 3 (45), 609622.391fiJournal Artificial Intelligence Research 47 (2013) 253279Submitted 02/13; published 06/13Arcade Learning Environment:Evaluation Platform General AgentsMarc G. Bellemaremg17@cs.ualberta.caUniversity Alberta, Edmonton, Alberta, CanadaYavar Naddafyavar@empiricalresults.caEmpirical Results Inc., Vancouver,British Columbia, CanadaJoel VenessMichael Bowlingveness@cs.ualberta.cabowling@cs.ualberta.caUniversity Alberta, Edmonton, Alberta, CanadaAbstractarticle introduce Arcade Learning Environment (ALE): challenge problem platform methodology evaluating development general,domain-independent AI technology. ALE provides interface hundreds Atari 2600game environments, one different, interesting, designed challengehuman players. ALE presents significant research challenges reinforcement learning,model learning, model-based planning, imitation learning, transfer learning, intrinsicmotivation. importantly, provides rigorous testbed evaluating comparing approaches problems. illustrate promise ALE developingbenchmarking domain-independent agents designed using well-established AI techniquesreinforcement learning planning. so, also propose evaluationmethodology made possible ALE, reporting empirical results 55 different games.software, including benchmark agents, publicly available.1. Introductionlongstanding goal artificial intelligence development algorithms capablegeneral competency variety tasks domains without need domain-specifictailoring. end, different theoretical frameworks proposed formalizenotion big artificial intelligence (e.g., Russell, 1997; Hutter, 2005; Legg, 2008). Similarideas developed around theme lifelong learning: learning reusable, highlevel understanding world raw sensory data (Thrun & Mitchell, 1995; Pierce &Kuipers, 1997; Stober & Kuipers, 2008; Sutton et al., 2011). growing interest competitions General Game Playing competition (Genesereth, Love, & Pell, 2005),Reinforcement Learning competition (Whiteson, Tanner, & White, 2010), International Planning competition (Coles et al., 2012) also suggests artificial intelligencecommunitys desire emergence algorithms provide general competency.Designing generally competent agents raises question best evaluate them.Empirically evaluating general competency handful parametrized benchmark problems is, definition, flawed. evaluation prone method overfitting (Whiteson,Tanner, Taylor, & Stone, 2011) discounts amount expert effort necessarytransfer algorithm new domains. Ideally, algorithm compared acrossc2013AI Access Foundation. rights reserved.fiBellemare, Naddaf, Veness, & Bowlingdomains (i) varied enough claim generality, (ii) interesting enoughrepresentative settings might faced practice, (iii) createdindependent party free experimenters bias.article, introduce Arcade Learning Environment (ALE): new challengeproblem, platform, experimental methodology empirically assessing agents designedgeneral competency. ALE software framework interfacing emulated Atari2600 game environments. Atari 2600, second generation game console, originallyreleased 1977 remained massively popular decade. 500 gamesdeveloped Atari 2600, spanning diverse range genres shooters, beatemups, puzzle, sports, action-adventure games; many game genres pioneeredconsole. modern game consoles involve visuals, controls, general complexityrivals real world, Atari 2600 games far simpler. spite this, still posevariety challenging interesting situations human players.ALE experimental methodology challenge problem general AI competency. machine learning, considered poor experimental practice trainevaluate algorithm data set, grossly over-estimate algorithmsperformance. typical practice instead train training set evaluatedisjoint test set. large number available games ALE, propose similar methodology used effect: approachs domain representationparametrization first tuned small number training games, testingapproach unseen testing games. Ideally, agents designed fashion evaluated testing games once, possibility subsequent modificationsalgorithm. general competency remains long-term goal artificial intelligence,ALE proposes achievable stepping stone: techniques general competency acrossgamut Atari 2600 games. believe represents goal attainable shorttime-frame yet formidable enough require new technological breakthroughs.2. Arcade Learning Environmentbegin describing main contribution, Arcade Learning Environment (ALE).ALE software framework designed make easy develop agents play arbitraryAtari 2600 games.2.1 Atari 2600Atari 2600 home video game console developed 1977 sold decade(Montfort & Bogost, 2009). popularized use general purpose CPUs game consolehardware, game code distributed cartridges. 500 original gamesreleased console; homebrew games continue developed today, thirty yearslater. consoles joystick, well original games AdventurePitfall!, iconic symbols early video games. Nearly arcade games timePac-Man Space Invaders two well-known examples ported console.Despite number variety games developed Atari 2600, hardwarerelatively simple. 1.19Mhz CPU emulated much faster real-timemodern hardware. cartridge ROM (typically 24kB) holds game code,console RAM holds 128 bytes (1024 bits). single game screen 160 pixels wide254fiThe Arcade Learning Environment: Evaluation Platform General AgentsFigure 1: Screenshots Pitfall! Space Invaders.210 pixels high, 128-colour palette; 18 actions input game viadigital joystick: three positions joystick axis, plus single button. Atari2600 hardware limits possible complexity games, believe strikes perfectbalance: challenging platform offering conceivable near-term advancements learning,modelling, planning.2.2 InterfaceALE built top Stella1 , open-source Atari 2600 emulator. allows userinterface Atari 2600 receiving joystick motions, sending screen and/or RAMinformation, emulating platform. ALE also provides game-handling layertransforms game standard reinforcement learning problem identifyingaccumulated score whether game ended. default, observation consistssingle game screen (frame): 2D array 7-bit pixels, 160 pixels wide 210 pixelshigh. action space consists 18 discrete actions defined joystick controller.game-handling layer also specifies minimal set actions needed play particulargame, although none results paper make use information. runningreal-time, simulator generates 60 frames per second, full speed emulates6000 frames per second. reward time-step defined game game basis,typically taking difference score points frames. episode beginsfirst frame reset command issued, terminates game ends.game-handling layer also offers ability end episode predefined numberframes2 . user therefore access several dozen games single commoninterface, adding support new games relatively straightforward.ALE provides functionality save restore state emulator.issued save-state command, ALE saves relevant data currentgame, including contents RAM, registers, address counters. restorestate command similarly resets game previously saved state. allows useALE generative model study topics planning model-based reinforcementlearning.1. http://stella.sourceforge.net/2. functionality needed small number games ensure always terminate.prevents situations Tennis, degenerate agent could choose play indefinitelyrefusing serve.255fiBellemare, Naddaf, Veness, & Bowling2.3 Source CodeALE released free, open-source software terms GNU General PublicLicense. latest version source code publicly available at:http://arcadelearningenvironment.orgsource code agents used benchmark experiments also availablepublication page article website. ALE writtenC++, variety interfaces available allow users interact ALEprogramming language choice. Support new games easily addedimplementing derived class representing games particular reward terminationfunctions.3. Benchmark ResultsPlanning reinforcement learning two different AI problem formulationsnaturally investigated within ALE framework. purpose presenting benchmarkresults formulations two-fold. First, results provide baselineperformance traditional techniques, establishing point comparison future,advanced, approaches. Second, describing results illustrate proposedmethodology empirical validation ALE.3.1 Reinforcement Learningbegin providing benchmark results using SARSA(), traditional techniquemodel-free reinforcement learning. Note reinforcement learning setting,agent access model game dynamics. time step,agent selects action receives reward observation, agents aimmaximize accumulated reward. experiments, augmented SARSA()algorithm linear function approximation, replacing traces, -greedy exploration.detailed explanation SARSA() extensions found work SuttonBarto (1998).3.1.1 Feature Constructionapproach reinforcement learning setting, important design issuechoice features use linear function approximation. ran experiments usingfive different sets features, briefly explain; complete descriptionfeature sets given Appendix A. sets features, BASS, DISCO RAMoriginally introduced Naddaf (2010), rest novel.Basic. Basic method, derived Naddafs BASS (2010), encodes presencecolours Atari 2600 screen. Basic method first removes image backgroundstoring frequency colours pixel location within histogram. gamebackground precomputed offline, using 18,000 observations collected sample trajectories. sample trajectories generated following human-provided trajectoryrandom number steps subsequently selecting actions uniformly random.256fiThe Arcade Learning Environment: Evaluation Platform General Agentsscreen divided 16 14 tiles. Basic generates one binary feature128 colours tiles, giving total 28,672 features.BASS. BASS method behaves identically Basic method save two respects.First, BASS augments Basic feature set pairwise combinations features.Second, BASS uses smaller, 8-colour encoding ensure number pairwisecombinations remains tractable.DISCO. DISCO method aims detect objects within Atari 2600 screen.so, first preprocesses 36,000 observations sample trajectories generatedBasic method. DISCO also performs background subtraction steps BasicBASS. Extracted objects labelled classes. actual training, DISCOinfers class label detected objects encodes position velocity using tilecoding (Sutton & Barto, 1998).LSH. LSH method maps raw Atari 2600 screens small set binary featuresusing Locally Sensitive Hashing (Gionis, Indyk, & Motwani, 1999). screens mappedusing random projections, visually similar screens likely generatefeatures.RAM. RAM method works entirely different observation spacefour methods. Rather receiving Atari 2600 screen observation, directlyobserves Atari 2600s 1024 bits memory. bit RAM provided binaryfeature together pairwise logical-AND every pair bits.3.1.2 Evaluation Methodologyfirst constructed two sets games, one training testing. usedtraining games parameter tuning well design refinements, testing gamesfinal evaluation methods. training set consisted five games: Asterix,Beam Rider, Freeway, Seaquest Space Invaders. parameter search involvedfinding suitable values parameters SARSA() algorithm, i.e. learning rate,exploration rate, discount factor, decay rate . also searched space featuregeneration parameters, example abstraction level BASS agent. resultsparameter search summarized Appendix C. testing set constructedchoosing semi-randomly 381 games listed Wikipedia3 time writing.games, 123 games Wikipedia page, single player mode,adult-themed prototypes, emulated ALE. list, 50 gameschosen random form test set.Evaluation method game performed follows. episode startsframe follows reset command, terminates end-of-game conditiondetected 5 minutes real-time play (18,000 frames), whichever comes first.episode, agent acts every 5 frames, equivalently 12 times per secondgameplay. reinforcement learning trial consists 5,000 training episodes, followed500 evaluation episodes learning takes place. agents performance3. http://en.wikipedia.org/wiki/List Atari 2600 games (July 12, 2012)257fiBellemare, Naddaf, Veness, & BowlingGameAsterixSeaquestBoxingH.E.R.O.ZaxxonBasic862579-360531392BASS8606651664592069DISCO75542212272070LSH9875091038363365RAM943594443281304Random288108-17120Const650160-2500Perturb338451-101482Human620156-26087820Table 1: Reinforcement Learning results selected games. Asterix Seaquestpart training set.measured average score achieved evaluation episodes. game,report methods average performance across 30 trials.purposes comparison, also provide performance measures three simplebaseline agents Random, Const Perturb well performance non-experthuman player. Random agent picks random action every frame. Const agentselects single fixed action throughout episode; results reflect highest scoreachieved single action within game. Perturb agent selects fixed actionprobability 0.95 otherwise acts uniformly randomly; game, reportperformance best policy type. Additionally, provide human player resultsreport five-episode average score obtained beginner (who never previouslyplayed Atari 2600 games) playing selected games. aim provide exhaustiveaccurate human-level benchmarks, would beyond scope paper,rather offer insight performance level achieved agents.3.1.3 Resultscomplete report reinforcement learning results given Appendix D. Table 1shows small subset results two training games three test games. 40 games55, learning agents perform better baseline agents. games, e.g.,Double Dunk, Journey Escape Tennis, no-action baseline policy performsbest essentially refusing play thus incurring negative reward. Within40 games learning occurs, BASS method generally performs best. DISCOperformed particularly poorly compared learning methods. RAM-basedagent, surprisingly, outperform image-based methods, despite building representation raw game state. appears screen image carries structural informationeasily extracted RAM bits.reinforcement learning results show learning progress already possible Atari 2600 games, much work remains done. Different methods performwell different games, single method performs well games. gamesparticularly challenging. example, platformers Montezumas Revenge seemrequire high-level planning far beyond current, domain-independent methodsprovide. Tennis requires fairly elaborate behaviour observing positive reward,simple behaviour avoid negative rewards. results also highlight valueALE experimental methodology. example, DISCO approach performs rea258fiThe Arcade Learning Environment: Evaluation Platform General Agentssonably well training set, suffers dramatic reduction performanceapplied unseen games. suggests method less robust methodsstudied. quick glance full table results Appendix D, clearsummarizing results across varied domains needs attention; exploreissue Section 4.3.2 PlanningArcade Learning Environment naturally used study planning techniquesusing emulator generative model. Initially may seem allowingagent plan future perfect model trivializes problem. However,case: size state space Atari 2600 games prohibits exhaustive search.Eighteen different actions available every frame; 60 frames per second, lookingahead one second requires 1860 1075 simulation steps. Furthermore, rewards oftensparsely distributed, causes significant horizon effects many search algorithms.3.2.1 Search Methodsprovide benchmark ALE results two traditional search methods. methodapplied online select action every time step (every five frames) gameover.Breadth-first Search. first approach builds search tree breadth-first fashionnode limit reached. tree expanded, node values updated recursivelybottom tree root. agent selects action correspondingbranch highest discounted sum rewards. Expanding full search treerequires large number simulation steps. instance, selecting action every 5 framesallowing maximum 100,000 simulation steps per frame, agent lookahead third second. many games, allows agent collect immediaterewards avoid death little else. example, Seaquest agent must collectswimmer return surface running air, involves planning farbeyond one second.UCT: Upper Confidence Bounds Applied Trees. preferable alternativeexhaustively expanding tree simulate deeper promising branches.this, need find balance expanding higher-valued branchesspending simulation steps lower-valued branches get better estimatevalues. UCT algorithm, developed Kocsis Szepesvari (2006), dealsexploration-exploitation dilemma treating node search tree multi-armedbandit problem. UCT uses variation UCB1, bandit algorithm, choose childnode visit next. common practice apply t-step random simulation endleaf node obtain estimate longer trajectory. expandingvaluable branches tree carrying random simulation leaf nodes, UCTknown perform well many different settings (Browne et al., 2012).UCT implementation entirely standard, except one optimization. Atarigames actually distinguish 18 actions every time step. Beam Rider,example, action nothing, pressing button bullet already259fiBellemare, Naddaf, Veness, & BowlingGameAsterixSeaquestBoxingH.E.R.O.ZaxxonFull Tree213628810013240UCT29070051321001286022610Best Learner9876654464593365Best Baseline650451-17122Table 2: Results selected games. Asterix Seaquest part training set.shot effect. exploit fact follows: expanding childrennode search tree, compare resulting emulator states. Actions resultstate treated duplicates one actions consideredsearch tree. reduces branching factor, thus allowing deeper search. every step,also reuse part search tree corresponding selected action. Pseudocodeimplementation UCT algorithm given Appendix B.3.2.2 Experimental Setupdesigned tuned algorithms based five training games usedSection 3.1, subsequently evaluated methods fifty games testing set.training games used determine length search horizon wellconstant controlling amount exploration internal nodes tree. episodeset last 5 minutes real-time play (18,000 frames), actions selected every5 frames, matching settings Section 3.1.2. average, action selection steptook order 15 seconds. also used discount factor Section 3.1.ran algorithms 10 episodes per game. Details algorithmic parametersfound Appendix C.3.2.3 Resultscomplete report search results given Appendix D. Table 2 shows resultsselected subset games. reference purposes, also include performancebest learning agent best baseline policy Table 1. Together, two searchmethods performed better learning agents baseline policies 49 55games. cases, UCT performs significantly better breadth-first search. Foursix games search methods perform best games rewardssparse require long-term planning. Freeway, Private Eye, MontezumasRevenge Venture.4. Evaluation Metrics General Atari 2600 AgentsApplying algorithms large set games Sections 3.1 3.2 presentsdifficulties interpreting results. agents goal games maximizescore, scores two different games cannot easily compared. game usesscale scores, different game mechanics make games harder learn others.challenges associated comparing general agents previously highlighted260fiThe Arcade Learning Environment: Evaluation Platform General Agentsa) Random30b) Baseline10c) Inter-Algorithm9252018BASSRAM70.861550.64100.43250.2100SeaquestH.E.R.O.Boxing0SeaquestH.E.R.O.BoxingSeaquestH.E.R.O.BoxingFigure 2: Left right: random-normalized, baseline inter-algorithm scores.Whiteson et al. (2011). Although always report full performance tables,Appendix D, compact summary statistics also desirable.introduce simple metrics help compare agents across diverse set domains,test set Atari 2600 games.4.1 Normalized ScoresConsider scores sg,1 sg,2 achieved two algorithms game g. goalexplore methods allow us compare two sets scores S1 = {sg1 ,1 , . . . , sgn ,1 }S2 = {sg1 ,2 , . . . , sgn ,2 }. approach take transform sg,i normalized scorezg,i aim comparing normalized scores across games; ideal case, zg,i = zg0 ,iimplies algorithm performs well game g game g 0 . order comparealgorithms set games, aggregate normalized scores gamealgorithm.natural way compare games different scoring scales normalizescores numerical values become comparable. normalization methodsdefined using notion score range [rg,min , rg,max ] computed game. Givenscore range, score sg,i normalized computing zg,i := (sg,i rg,min ) / (rg,maxrg,min ).4.1.1 Normalization Reference ScoreOne straightforward method normalize score range defined repeated runsrandom agent across game. Here, rg,max absolute value average scoreachieved random agent, rg,min = 0. Figure 2a depicts random-normalizedscores achieved BASS RAM three games. Two issues arise approach:scale normalized scores may excessively large normalized scores generallytranslation invariant. issue scale best seen game Freeway,random agent achieves score close 0: scores achieved learning agents,10-20 range, normalized thousands. contrast, learning agent achievesrandom-normalized score greater 1 Asteroids.261fiBellemare, Naddaf, Veness, & Bowling4.1.2 Normalizing Baseline SetRather normalizing single reference may normalize score range impliedset references. Let bg,1 , . . . , bg,k set reference scores. methods baselinescore computed using score range [mini{1,...,k} bg,i , maxi{1,...,k} bg,i ].Given sufficiently rich set reference scores, baseline normalization allows us reducescores games comparable quantities, lets us know whether meaningfulperformance obtained. Figure 2b shows example baseline scores. score rangescores corresponds scores achieved 37 baseline agents (Section 3.1.2):Random, Const (one policy per action), Perturb (one policy per action).natural idea also include scores achieved human players baseline set.example, one may include score achieved expert well score achievedbeginner. However, using human scores raises set issues. example,humans often play games without seeking maximize score; humans also benefitprior knowledge difficult incorporate domain-independent agents.4.1.3 Inter-Algorithm Normalizationthird alternative normalize using scores achieved algorithms themselves.Given n algorithms, achieving score sg,i game g, define inter-algorithmscore using score range [mini{1,...,n} sg,i , maxi{1,...,n} sg,i ]. definition, zg,i [0, 1].special case n=2, zg,i {0, 1} indicates algorithm betterother. Figure 2c shows example inter-algorithm scores; relevant score rangesconstructed performance five learning agents.inter-algorithm scores bounded, type normalization appealingsolution compare relative performance different methods. main drawbackgives indication objective performance best algorithm. goodexample Venture: inter-algorithm score 1.0 achieved BASSreflect fact none agents achieved score remotely comparable humansperformance. lack objective reference inter-algorithm normalization suggestsused complement scoring metrics.4.2 Aggregating Scoresnormalized scores obtained game, next step produce measurereflects well agent performs across set games. illustrated Table4, large table numbers easily permit comparison algorithms.describe three methods aggregate normalized scores.4.2.1 Average Scorestraightforward method aggregating normalized scores computeaverage. Without perfect score normalization, however, score averages tend heavilyinfluenced games Zaxxon baseline scores high. Averaging interalgorithm scores obviates issue scores bounded 0 1. Figure 3displays average baseline inter-algorithm scores learning agents.262fiThe Arcade Learning Environment: Evaluation Platform General AgentsAverage Baseline Scores351.430Median Baseline Scores50.2RAMLSH0.4BASSLSH0.6DISCO10RAMBasic15DISCO0.8BASS120Basic1.225000.7Avg. Inter-Algorithm Scores1Median Inter-Algorithm Scores0.60.80RAMLSHDISCO0.20.1BASS0.4BasicRAM0.6LSH0.2DISCO0.3Basic0.4BASS0.50Figure 3: Aggregate normalized scores five reinforcement learning agents.4.2.2 Median ScoreMedian scores generally robust outliers average scores. medianobtained sorting normalized scores selecting middle element (the averagetwo middle elements used number scores even). Figure 3 shows medianbaseline inter-algorithm scores learning agents. Comparing medians averages baseline score (upper two graphs) illustrates exactly outlier sensitivityaverage score, LSH method appears dramatically superior due entirelyperformance Zaxxon.4.2.3 Score Distributionscore distribution aggregate natural generalization median score: showsfraction games algorithm achieves certain normalized score better.essentially quantile plot inverse empirical CDF. Unlike average medianscores, score distribution accurately represents performance agent irrespectiveindividual scores distributed. Figure 4 shows baseline inter-algorithm scoredistributions. Score distributions allow us compare different algorithms glanceone curve another, corresponding method generally obtains higher scores.Using baseline score distribution, easily determine proportion gamesmethods perform better baseline policies (scores 1). interalgorithm score distribution, hand, effectively conveys relative performancemethod. particular, allows us conclude BASS performs slightly betterBasic RAM, DISCO performs significantly worse methods.263fiBellemare, Naddaf, Veness, & Bowling1.01.0Fraction GamesFraction GamesBASSBASS0.5RAMBasicLSHDISCOBasicRAM0.5LSHDISCO0.02000501086420.01.000.8Baseline Score0.60.40.20Inter-Algorithm ScoreFigure 4: Score distribution games.BasicBASSDISCOLSHRAMBasicBASSDISCOLSHRAM3218133918342522183254817362029391348533174193418361717333615222529209411536Table 3: Paired tests games. entry shows number gamesperformance first algorithm (left) better (worse) secondalgorithms.4.3 Paired Testsalternate evaluation metric, especially useful comparing algorithms,perform paired tests raw scores. game, performed two-tailedWelshs t-test 99% confidence intervals determine whether one algorithms scorestatistically different others. Table 3 provides, pair algorithms,number games one algorithm performs statistically better worseother. ternary nature, paired tests tend magnify small significantdifferences scores.5. Related Workbriefly survey recent research related Atari 2600 games prior workconstruction empirical benchmarks measuring general competency.5.1 Atari Gamesattention devoted Atari 2600 game playing within reinforcement learning community. part, prior work focused challengefinding good state features domain. Diuk, Cohen, Littman (2008) appliedDOORMAX algorithm restricted version game Pitfall!. method extracts objects displayed image game-specific object detection. objectsconverted first-order logic representation world, Object-Oriented264fiThe Arcade Learning Environment: Evaluation Platform General AgentsMarkov Decision Process (OO-MDP). results show DOORMAX discoveroptimal behaviour OO-MDP within one episode. Wintermute (2010) proposedmethod also extracts objects displayed image embeds logicbased architecture, SOAR. method uses forward model scene improveperformance Q-Learning algorithm (Watkins & Dayan, 1992). showedusing model, reinforcement learning agent could learn play restricted versiongame Frogger. Cobo, Zang, Isbell, Thomaz (2011) investigated automaticfeature discovery games Pong Frogger, using simulator.proposed method takes advantage human trajectories identify state featuresimportant playing console games. Recently, Hausknecht, Khandelwal, Miikkulainen,Stone (2012) proposed HyperNEAT-GGP, evolutionary approach finding policies play Atari 2600 games. Although HyperNEAT-GGP presented general gameplaying approach, currently difficult assess general performance reportedresults limited two games. Finally, authors paper (Bellemare, Veness, & Bowling, 2012) recently presented domain-independent feature generationtechnique attempts focus effort around location player avatar.work used evaluation methodology advocated one demonstratetechnique across large set testing games.5.2 Evaluation Frameworks General AgentsAlthough idea using games evaluate performance agents long historyartificial intelligence, recently emphasis generality assumedprominent role. Pell (1993) advocated design agents that, given abstractdescription game, could automatically play them. work strongly influenceddesign annual General Game Playing competition (Genesereth et al., 2005).framework differs assume access compact logical descriptiongame semantics. Schaul, Togelius, Schmidhuber (2011) also recently presentedinteresting proposal using games measure general capabilities agent.Whiteson et al. (2011) discuss number challenges designing empirical tests measuregeneral reinforcement learning performance; work seen attempting addressimportant concerns.Starting 2004 conference workshop, Reinforcement Learning competition(Whiteson et al., 2010) held 2009 (a new iteration competitionannounced 20134 ). year new domains proposed, including standard RL benchmarks, Tetris, Infinite Mario (Mohan & Laird, 2009). typical competition domain,agents state information summarized series high-level state variablesrather direct sensory information. Infinite Mario, example, provides agentobject-oriented observation space. past, organizers provided special Polyathlon track agents must behave medley continuous-observation,discrete-action domains.Another longstanding competition, International Planning Competition (IPC)5 ,organized since 1998, aims produce new benchmarks, gather dis4. http://www.rl-competition.org5. http://ipc.icaps-conference.org265fiBellemare, Naddaf, Veness, & Bowlingseminate data current state-of-the-art (Coles et al., 2012). IPC composeddifferent tracks corresponding different types planning problems, including factoryoptimization, elevator control agent coordination. example, one problems2011 competition consists coordinating set robots around two-dimensionalgridworld every tile painted specific colour. Domains described usingeither relational reinforcement learning, yielding parametrized Markov Decision Processes(MDPs) Partially Observable MDPs, using logic predicates, e.g. STRIPS notation.One indication much competitions value domain variety seentime spent finding good specification language. 2008-2009 RL competitions,example, used RL-Glue6 specifically purpose; 2011 planning uncertaintytrack IPC similar employed Relation Dynamic Influence Diagram Language.competitions seek spur new research evaluate existing algorithmsstandardized set benchmarks, independently developed, sensevast majority domains provided research community. Thus typicalcompetition domain reflects existing research directions: Mountain Car Acrobot remain staples RL competition. competitions also focus research effortdomains provide high-level state variables, example location robotsfloor-painting domain described above. contrast, Arcade Learning Environmentdomain-independent setting force us consider question perceptual grounding:extract meaningful state information raw game screens (or RAM information).turn, emphasizes design algorithms applied sensor-rich domainswithout significant expert knowledge.also number attempts define formal agent performance metricsbased algorithmic information theory. first attempts due HernandezOrallo Minaya-Collado (1998) Dowe Hajek (1998). recently,approaches Hernandez-Orallo Dowe (2010) Legg Veness (2011) appearpotential. Although frameworks general conceptually clean,key challenge remains specify sufficiently interesting classes environments.opinion, much work required approaches claim rivalpracticality using large set existing human-designed environments agentevaluation.6. Final RemarksAtari 2600 games developed humans exhibit many idiosyncrasiesmake challenging exciting. Consider, example, game Pong.Pong studied variety contexts interesting reinforcement learningdomain (Cobo et al., 2011; Stober & Kuipers, 2008; Monroy, Stanley, & Miikkulainen,2006). Atari 2600 Pong, however, significantly complex Pong domainsdeveloped research. Games easily last 10,000 time steps (compared 2001000domains); observations composed 7-bit 160210 images (compared 300200black white images work Stober Kuipers (2008), 5-6 input featureselsewhere); observations also complex, containing two players score sidewalls. sheer size, Atari 2600 Pong thus larger domain. dynamics also6. http://glue.rl-community.org266fiThe Arcade Learning Environment: Evaluation Platform General Agentscomplicated. research implementations Pong object motion implementedusing first-order mechanics. However, Atari 2600 Pong paddle control nonlinear:simple experimentation shows fully predicting players paddle requires knowledgelast 18 actions. many Atari games, player paddle also moves everyframe, adding degree temporal aliasing domain.Atari 2600 Pong may appear unnecessarily contrived, fact reflects unexpected complexity problems humans faced. Most, Atari2600 games subject similar programming artifacts: Space Invaders, example,invaders velocity increases nonlinearly number remaining invaders.way Atari 2600 platform provides AI researchers something unique: clean, easilyemulated domains nevertheless provide many challenges typically associatedreal-world applications.technology advance render general Atari 2600 game playing achievable,challenge problem always extended use recent video game platforms.natural progression, example, would move Commodore 64,Nintendo, forth towards current generation consoles. consoleshundreds released games, older platforms readily available emulators.ultra-realism current generation consoles, console represents natural steppingstone toward general real-world competency. hope using methodologyadvocated paper, work bottom-up fashion towards developingsophisticated AI technology still maintaining empirical rigor.7. Conclusionarticle introduced Arcade Learning Environment, platform evaluatingdevelopment general, domain-independent agents. ALE provides interfacehundreds Atari 2600 game environments, one different, interesting, designedchallenge human players. illustrate promise ALE challenge problembenchmarking several domain-independent agents use well-established reinforcementlearning planning techniques. results suggest general Atari game playingchallenging intractable problem domain potential aid developmentevaluation general agents.Acknowledgmentswould like thank Marc Lanctot, Erik Talvitie, Matthew Hausknecht providingsuggestions helping debug improving Arcade Learning Environment source code.would also like thank reviewers helpful feedback enthusiasmAtari 2600 research platform. work presented supportedAlberta Innovates Technology Futures, Alberta Innovates Centre Machine LearningUniversity Alberta, Natural Science Engineering Research CouncilCanada. Invaluable computational resources provided Compute/Calcul Canada.267fiBellemare, Naddaf, Veness, & BowlingAppendix A. Feature Set Constructionsection gives detailed description five feature generation techniquesSection 3.1.A.1 Basic Abstraction ScreenShots (BASS)idea behind BASS directly encode colours present screen. methodmotivated three observations Atari 2600 hardware games:1. Atari 2600 hardware supports screen resolution 160210, game objectsusually larger pixels. Overall, important game events happen muchlower resolution.2. Many Atari 2600 games static background, important objects moving screen. screen matrix densely populated, actual interestingfeatures screen often sparse.3. hardware show 128 colours NTSC mode, limited8 colours SECAM mode. Consequently, games use numbercolours distinguish important objects screen.game screen first preprocessed subtracting background, detected using simplehistogram method. BASS encodes presence eight SECAM palettecolours low resolution, depicted Figure 5. Intuitively, BASS seeks capturepresence objects certain colours different screen locations. BASS also encodesrelations objects constructing pairwise combinations encoded colourfeatures. Asterix, example, important know green object (playercharacter) red object (collectable object) vicinity. Pairwise features allow uscapture object relations.Figure 5: Left: Freeway SECAM colours. Right: BASS colour encodingscreen.A.2 BasicBasic method generates set features BASS, omits pairwisecombinations. allows us study whether additional features beneficial268fiThe Arcade Learning Environment: Evaluation Platform General Agentsharmful learning. Basic method fewer features BASS, encodespresence 128 colours. comparison BASS, Basic therefore representscolour accurately, cannot represent object interactions.A.3 Detecting Instances Classes Objects (DISCO)feature generation method based detecting set classes representing gameentities locating instances classes screen. DISCO motivatedfollowing additional observations Atari 2600 games:1. game entities often instances classes objects. instance,Figure 6 shows, many objects sample screen game Freeway,objects instances two classes: Chicken Car. Similarly,objects sample screen game Seaquest instances onesix classes: Fish, Swimmer, Player Submarine, Enemy Submarine, Player Bullet,Enemy Bullet.2. interaction two objects often generalized instancesrespective classes. example, consider Car -Chicken object interactions Freeway: learning lower value associated one Chicken instance hittingCar instance generalized instances two classes.Figure 6: Left: Screenshot game Freeway. Although ten different cars,considered instances single class. Right: Screenshotgame Seaquest depicting four different object classes.DISCO first performs series preprocessing steps discover classes,value function learning performed. agent subsequently learns playgame, DISCO generates features detecting objects screen classifying them.DISCO process summarized following steps:Preprocessing:Background detection: static background matrix extracted usinghistogram method, BASS.269fiBellemare, Naddaf, Veness, & BowlingAlgorithm 1 Locally Sensitive Hashing (LSH) Feature GenerationConstants. (hash table size), n (screen bit vector size)l (number random bit vectors), k (number non-zero entries)Initialization (once).{v1 . . . vl } generateRandomVectors(l, k, n){hash1 . . . hashl } generateHashFunctions(l, M, n)Input. screen matrix elements Ixy {0, . . . , 127}LSH(I)binarizeScreen(I) (s length n)Initialize RlM = 0= 1 . . . lh=0j = 1 . . . nh h + I[sj =vij ] hashi [j] mod(hash projection onto vi )end[M (i 1) + h] = 1(one binary feature per random bit vector)endbinarizeScreen(I)Initialize Rn = 0= 1 . . . h, x = 1 . . . w (h = 210, w = 160)s[x + h + Ixy ] = 1endreturngenerateRandomVectors(l, k, n)Initialize v1 . . . vl Rn = 0= 1 . . . lSelect x1 , x2 , . . . , xk distinct coordinates 1 n uniformly randomvi [x1 ] = 1; vi [x2 ] = 1; . . . ; vi [xk ] = 1endreturn {v1 , . . . vl }generateHashFunctions(l, M, n) (hash functions vectors random coordinates)Initialize hash1 . . . hashl Rn = 0= 1 . . . l, j = 1 . . . nhashi [j] random(1, ) (uniformly random coordinate 1 M)endreturn {hash1 , . . . hashl }Remark. sparse vector operations, LSH O(lk + n) cost per step.270fiThe Arcade Learning Environment: Evaluation Platform General AgentsFigure 7: Left: Screenshot game Seaquest. Right: Objects detected DISCOgame Seaquest. colour represents different class.Blob extraction: list moving blob (foreground) objects detectedgame screen.Class discovery: set classes detected extracted blob objects.Class filtering: Classes appear infrequently restricted small regionscreen removed set.Class merging: Classes similar shapes merged together.Feature generation:Class instance detection: time step, class instances detectedcurrent screen matrix.Feature vector generation: feature vector generated detectedinstances tile-coding absolute position well relative positionvelocity every pair instances different classes. Multiple instancesobjects combined additively.Figure 7 shows discovered objects Seaquest frame. image illustrates difficulties detecting objects: although DISCO correctly classifies different fish partclass, also detects life icon oxygen bar part class.A.4 Locality Sensitive Hashing (LSH)alternative approach BASS DISCO use well-established feature generationmethods agnostic type input receive. methods includepolynomial bases (Schweitzer & Seidmann, 1985), sparse distributed memories (Kanerva,1988) locality sensitive hashing (LSH) (Gionis et al., 1999). paper considerlatter simple mean reducing large image space smaller, manageableset features. input here, game screen first mapped bit vector size7 210 160. resulting vector hashed smaller set features.LSH performs additional random projection step ensure similar screenslikely binned together. LSH generation method detailed Algorithm 1.271fiBellemare, Naddaf, Veness, & BowlingA.5 RAM-based Feature GenerationUnlike previous three methods, generate feature vectors based game screen,RAM-based feature generation method relies contents console memory.Atari 2600 128 8 = 1024 bits random access memory7 , must holdcomplete internal state game: location game entities, timers, health indicators,etc. RAM therefore relatively compact representation game state,contrast game screen, also Markovian. purpose RAM-based agentinvestigate whether features generated RAM affect performance differentlyfeatures generated game screens.first part generated feature vector simply includes 1024 bits RAM.Atari 2600 game programmers often used bits individual values, part4-bit 8-bit words. Linear function approximation individual bits capturevalue multi-bit words. also interested relation pairsvalues memory. capture relations, logical-AND possible bit pairsappended feature vector. Note linear function pairwise Dscapture products 4-bit 8-bit words. product two n-bitwords expressed weighted sum pairwise products bits.7. games provided RAM game cartridge: Atari Super Chip, example, offeredadditional 128 bytes memory. current approach considers main memory includedAtari 2600 console.272fiThe Arcade Learning Environment: Evaluation Platform General AgentsAppendix B. UCT PseudocodeAlgorithm 2 UCTConstants. (search horizon), k (simulations per step)Variables. (search tree)Input. (current state)UCT(s)empty root() 6=empty search treeroot()endrepeatsample(, m)visits(root()) = kbestAction()prune(, a)(optional)returnsample(, m)n root()n leaf, > depth(n)action never taken n(c, reward) emulate(n, a)(run model one step)immediate-return(c) rewardchild(n, a) cnc(c necessarily leaf)elseselectAction(n)n child(n, a)endendR = rollout(n, depth(n))update-value(n, R)(propagate values back up)bestAction()return arg maxa [visits(child(root(), a))]prune(, a)root() child(root(), a)273(action frequently taken root)fiBellemare, Naddaf, Veness, & BowlingAlgorithm 3 UCT RoutinesConstants. : discount factorselectAction(n)c children nqV (c) average-return(c) + log[visits(c)]visits(n)endreturn arg maxa V (child(n, a))rollout(n, m)R=0(Initialize Monte-Carlo return 0)g=1> 0Select according rollout policy (e.g. uniformly randomly)(n, reward) emulate(n, a)R R + g rewardmm1g gendreturn Rupdate-value(n, R)R R + immediate-reward(n)visits(n)Raverage-return(n) average-return(n) visits(n)+1+ visits(n)+1visits(n) visits(n) + 1n root , i.e. parent(n) 6= nullupdate-value(parent(n), R)end274fiThe Arcade Learning Environment: Evaluation Platform General AgentsAppendix C. Experimental ParametersGeneralexperimentsReinforcement learningPreprocessingBackground detectionClass discoveryReinforcementlearningagentsBASSBasicBASSBasicDISCORAM-basedLSHPlanningUCTFull-tree searchMaximum frames per episodeFrames per actionTraining episodes per trialEvaluation episodes per trialNumber trials per resultSample screens per gameSample screens per gameMaximum number classesMaximum object velocity (pixels)Minimum frequency class appearanceDiscount factorExploration rateLearning rateEligibility traces decay rateGrid widthGrid heightNumber different coloursNumber different coloursLearning rateEligibility traces decay rateTile coding, number tilingsTile coding, grid sizeLearning rateEligibility traces decay rateLearning rateEligibility traces decay rateNumber random vectors lNumber non-zero vector entries kPer-vector hash table sizeSimulations per actionMaximum search depth (frames)Exploration constantMaximum frames emulated per action27518,00055,0005003018,00036,00010820%0.9990.050.50.9161481280.10.9880.20.50.50.520001000505003000.1133,000fiBellemare, Naddaf, Veness, & BowlingAppendix D. Detailed ResultsD.1 Reinforcement LearningGameBasicBASSDISCOLSHRAMRandomConstPerturbAsterixBeam RiderFreewaySeaquestSpace Invaders862.3929.411.3579.0203.6859.8872.716.4664.8250.1754.6563.012.8421.9239.1987.3793.615.4508.5222.2943.0729.819.1593.7226.5288.1434.70.0107.9156.1650.0996.021.0160.0245.0337.8754.822.5451.1270.5AlienAmidarAssaultAsteroidsAtlantisBank HeistBattle ZoneBerzerkBowlingBoxingBreakoutCarnivalCentipedeChopper CommandCrazy ClimberDemon AttackDouble DunkElevator ActionEnduroFishing DerbyFrostbiteGopherGravitarH.E.R.O.Ice HockeyJames BondJourney EscapeKangarooKrullKung-Fu MasterMontezumas RevengeMs. Pac-ManName GamePooyanPongPrivate EyeQ*BertRiver RaidRoad RunnerRobotankSkiingStar GunnerTennisTime PilotTutankhamVentureVideo PinballWizard WorZaxxon939.264.9465.8829.762687.098.815534.3329.228.5-2.83.32323.97725.51191.46303.1520.5-15.83025.2111.8-92.6161.0545.8185.36053.1-13.9197.3-8441.0962.42823.316416.210.71537.21818.9800.3-19.281.9613.51708.967.712.8-1.1850.2-0.21728.240.73532.70.015046.81768.81392.0893.4103.4378.4800.325375.071.112750.8491.343.915.55.21574.28803.81581.57455.6318.5-13.12377.6129.1-92.1161.11288.3251.16458.8-14.8202.8-14730.71622.13371.519544.00.11691.82386.81018.9-19.0100.7497.21438.065.210.1-0.71069.5-0.12299.552.63351.066.012574.21981.32069.1623.667.9371.7744.520857.351.40.0329.035.212.43.91646.36210.61349.04552.9208.8-23.24.60.0-89.5176.6295.7197.42719.8-18.917.3-9392.2457.92350.93207.00.0999.61951.0402.7-19.6-23.0326.30.021.49.3-0.11002.2-0.10.00.02473.40.010779.5935.669.8510.245.1628.0590.717593.964.614548.1441.026.110.52.51147.26161.6943.020453.7355.8-21.63220.695.8-93.2216.9941.8105.93835.8-15.177.1-13898.9256.42798.18715.60.11070.82029.81225.3-19.9684.3529.11904.342.010.8-0.0722.9-0.12429.285.22475.10.09813.9945.53365.1726.471.4383.6907.319932.7190.815819.7501.329.344.04.0765.47555.41397.823410.6324.8-20.3507.9112.3-91.6147.9722.5387.73281.1-9.5133.8-8713.5481.72901.310361.10.31021.12500.11210.9-19.9111.9565.81309.941.028.70.0769.3-0.13741.2114.33412.60.016871.31096.2304.3102.00.8334.31526.733058.415.02920.0233.824.6-1.51.5869.22805.1698.22335.4289.3-15.61040.90.0-93.870.3243.7205.4712.0-14.823.3-18201.744.41880.1488.20.3163.32012.3501.1-20.9-754.0169.01608.636.21.60.0638.1-24.03458.823.1131.60.020021.1772.40.0140.031.0357.0140.01500.00.013000.0670.030.0-25.03.00.016527.01000.00.0130.00.00.09.0-99.0160.00.00.00.0-1.00.00.0200.00.00.00.0210.03080.030.0-21.00.0150.01070.0900.017.00.0600.00.0500.00.0550.00.0705.0300.00.0313.937.8497.8539.912089.113.55772.0552.930.0-10.12.9485.48937.2973.72235.0776.2-20.3562.925.9-97.2175.2286.8106.0147.5-6.582.0-10693.9498.41690.1578.40.0505.51854.3540.8-20.81947.3157.41455.5857.911.30.0509.8-0.3718.717.32962.90.09527.9470.32.0Times Best617188294Table 4: Reinforcement Learning results. first five games constitute training set.See Section 3.1 details..276fiThe Arcade Learning Environment: Evaluation Platform General AgentsD.2 PlanningGameFull TreeUCTBest LearnerBest BaselineAsterixBeam RiderFreewaySeaquestSpace Invaders2135.7693.50.0288.0112.2290700.06624.60.45132.42718.0987.3929.419.1664.8250.1650.0996.022.5451.1270.5AlienAmidarAssaultAsteroidsAtlantisBank HeistBattle ZoneBerzerkBowlingBoxingBreakoutCarnivalCentipedeChopper CommandCrazy ClimberDemon AttackDouble DunkElevator ActionEnduroFishing DerbyFrostbiteGopherGravitarH.E.R.O.Ice HockeyJames BondJourney EscapeKangarooKrullKung-Fu MasterMontezumas RevengeMs. PacmanName GamePooyanPongPrivate EyeQ*BertRiver RaidRoad RunnerRobotankSkiingStar GunnerTennisTime PilotTutankhamVentureVideo PinballWizard WorZaxxon784.05.2413.73127.430460.021.56312.5195.025.5100.01.1950.0125123.01827.337110.0442.6-18.5730.00.6-91.6137.21019.0395.01323.8-9.225.01327.390.03089.212127.30.01708.55699.0909.7-20.757.9132.82178.5245.01.50.01345.0-23.84063.664.1746.00.055567.33309.10.07785.0180.31512.24660.6193858.0497.870333.3553.525.1100.0364.45132.0110422.034018.898172.228158.824.018100.0286.337.8270.520560.02850.012859.539.4330.07683.31990.05037.048854.50.022336.015410.017763.421.0100.017343.44449.038725.050.4-0.81207.12.863854.5225.574473.60.0254748.0105500.022610.0939.2103.4628.0907.362687.0190.815819.7501.343.944.05.22323.98803.81581.523410.6520.5-13.13220.6129.1-89.5216.91288.3387.76458.8-9.5202.8-8441.01622.13371.519544.010.71691.82500.11225.3-19.0684.3613.51904.367.728.70.01069.5-0.13741.2114.33532.766.016871.31981.33365.1313.937.8497.81526.733058.415.013000.0670.030.0-1.53.0869.216527.01000.02335.4776.20.01040.925.9-93.8175.2286.8205.4712.0-1.082.00.0498.41880.1578.40.3505.53080.0540.8-20.81947.3169.01608.6900.017.00.0638.10.03458.823.12962.90.020021.1772.42.0Times Best44533Table 5: Search results. first five games constitute training set. See Section 3.2details..277fiBellemare, Naddaf, Veness, & BowlingReferencesBellemare, M., Veness, J., & Bowling, M. (2012). Investigating contingency awareness usingAtari 2600 games. Proceedings 26th Conference Artificial Intelligence(AAAI).Browne, C. B., Powley, E., Whitehouse, D., Lucas, S. M., Cowling, P. I., Rohlfshagen, P.,Tavener, S., Perez, D., Samothrakis, S., & Colton, S. (2012). survey Monte Carlotree search methods. IEEE Transactions Computational Intelligence AIGames, 4 (1), 1 43.Cobo, L. C., Zang, P., Isbell, C. L., & Thomaz, A. L. (2011). Automatic state abstractiondemonstration. Proceedings 22nd Second International Joint ConferenceArticial Intelligence (IJCAI).Coles, A., Coles, A., Olaya, A., Jimenez, S., Lopez, C., Sanner, S., & Yoon, S. (2012).survey seventh international planning competition. AI Magazine, 33 (1), 8388.Diuk, C., Cohen, A., & Littman, M. L. (2008). object-oriented representation efficient reinforcement learning. Proceedings 25th International ConferenceMachine learning (ICML).Dowe, D. L., & Hajek, A. R. (1998). non-behavioural, computational extensionTuring Test. Proceedings International Conference Computational Intelligence Multimedia Applications (ICCIMA).Genesereth, M. R., Love, N., & Pell, B. (2005). General Game Playing: OverviewAAAI competition. AI Magazine, 26 (2), 6272.Gionis, A., Indyk, P., & Motwani, R. (1999). Similarity search high dimensions viahashing. Proceedings International Conference Large Databases.Hausknecht, M., Khandelwal, P., Miikkulainen, R., & Stone, P. (2012). HyperNEAT-GGP:HyperNEAT-based Atari general game player. Proceedings GeneticEvolutionary Computation Conference (GECCO).Hernandez-Orallo, J., & Dowe, D. L. (2010). Measuring universal intelligence: Towardsanytime intelligence test. Artificial Intelligence, 174 (18), 1508 1539.Hernandez-Orallo, J., & Minaya-Collado, N. (1998). formal definition intelligencebased intensional variant Kolmogorov complexity. ProceedingsInternational Symposium Engineering Intelligent Systems (EIS).Hutter, M. (2005). Universal Artificial Intelligence: Sequential Decisions based Algorithmic Probability. Springer, Berlin.Kanerva, P. (1988). Sparse Distributed Memory. MIT Press.Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. Proceedings15th European Conference Machine Learning (ECML).Legg, S. (2008). Machine Super Intelligence. Ph.D. thesis, University Lugano.Legg, S., & Veness, J. (2011). approximation universal intelligence measure.Proceedings Ray Solomonoff Memorial Conference.278fiThe Arcade Learning Environment: Evaluation Platform General AgentsMohan, S., & Laird, J. E. (2009). Learning play Mario. Tech. rep. CCA-TR-2009-03,Center Cognitive Architecture, University Michigan.Monroy, G. A., Stanley, K. O., & Miikkulainen, R. (2006). Coevolution neural networksusing layered pareto archive. Proceedings 8th Genetic EvolutionaryComputation Conference (GECCO).Montfort, N., & Bogost, I. (2009). Racing Beam: Atari Video Computer System.MIT Press.Naddaf, Y. (2010). Game-Independent AI Agents Playing Atari 2600 Console Games.Masters thesis, University Alberta.Pell, B. (1993). Strategy Generation Evaluation Meta-Game Playing. Ph.D. thesis,University Cambridge.Pierce, D., & Kuipers, B. (1997). Map learning uninterpreted sensors effectors.Artificial Intelligence, 92 (1-2), 169227.Russell, S. J. (1997). Rationality intelligence. Artificial intelligence, 94 (1), 5777.Schaul, T., Togelius, J., & Schmidhuber, J. (2011). Measuring intelligence games.CoRR, abs/1109.1314.Schweitzer, P. J., & Seidmann, A. (1985). Generalized polynomial approximations Markovian decision processes. Journal mathematical analysis applications, 110 (2),568582.Stober, J., & Kuipers, B. (2008). pixels policies: bootstrapping agent.Proceedings 7th IEEE International Conference Development Learning(ICDL).Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MITPress.Sutton, R., Modayil, J., Delp, M., Degris, T., Pilarski, P., White, A., & Precup, D. (2011).Horde: scalable real-time architecture learning knowledge unsupervisedsensorimotor interaction. Proceedings 10th International Conference Autonomous Agents Multiagents Systems (AAMAS).Thrun, S., & Mitchell, T. M. (1995). Lifelong robot learning. Robotics AutonomousSystems, 15 (1), 2546.Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279292.Whiteson, S., Tanner, B., Taylor, M. E., & Stone, P. (2011). Protecting evaluationoverfitting empirical reinforcement learning. Proceedings IEEE SymposiumAdaptive Dynamic Programming Reinforcement Learning (ADPRL).Whiteson, S., Tanner, B., & White, A. (2010). reinforcement learning competitions.AI Magazine, 31 (2), 8194.Wintermute, S. (2010). Using imagery simplify perceptual abstraction reinforcementlearning agents. Proceedings 24th Conference Artificial Intelligence(AAAI).279fiJournal Artificial Intelligence Research 47 (2013) 475-519Submitted 12/12; published 07/13Computation Fully Proportional RepresentationNadja Betzlernadja.betzler@campus.tu-berlin.deInstitut fur Softwaretechnik undTheoretische InformatikTU BerlinArkadii Slinkoslinko@math.auckland.ac.nzDepartment MathematicsUniversity AucklandJohannes Uhlmannjohannes.uhlmann@campus.tu-berlin.deInstitut fur Softwaretechnik undTheoretische InformatikTU BerlinAbstractinvestigate two systems fully proportional representation suggested Chamberlin & Courant Monroe. systems assign representative votersum misrepresentations minimized. winner determination problemsystems known NP-hard, hence work aims investigating whethervariants proposed rules and/or specific electorates problemssolved efficiently. variation rules, instead minimizing sum misrepresentations, considered minimizing maximal misrepresentation introducing effectivelytwo new rules. general case minimax versions classical rules appearedstill NP-hard.investigated parameterized complexity winner determination two classical two new rules respect several parameters. mixturepositive negative results: e.g., proved fixed-parameter tractability parameter number candidates fixed-parameter intractability number winners.single-peaked electorates results overwhelmingly positive: provide polynomial-time algorithms considered problems. rule remainsNP-hard single-peaked electorates classical Monroe rule.1. Introductionimportant conceptual difference purpose single-winner multiwinner elections. Single-winner social choice rules used make final decisions, e.g.,elect president choose certain course action. multi-winner election rulesused elect assembly whose members authorized take final decisionsbehalf society. result main property multi-winner rules satisfyelected assembly represents society adequately. This, particular, meansfinal decision taken opinions existing society heard takenconsideration. Black powerfully expressed it:c2013AI Access Foundation. rights reserved.fiBetzler, Slinko, & Uhlmannscheme proportional representation attempts secure assembly whosemembership will, far possible, proportionate volume different shades political opinion held throughout country; microcosmtrue reflexion macrocosm (Black, 1958, p. 75).although single-winner social choice rule easily extended selectassemblye.g., choosing candidates best scores applying rule repeatedlyrequired quantity representatives electedthis wrong approach problem(Brams & Fishburn, 2002) (see also Lu & Boutilier, 2011 experimental evidence).reason majoritarian logic dominates design single-winner socialchoice rules cannot provide balanced assembly membership.standard solution problem electing assembly divisionelection single-member districts approximately equal population. districtelects one member assembly using single-winner rule, normally plurality.although one might question whether districting instead based total adultpopulation number registered voters, current practice well establishedentrenched law many countries, including United States (Brams, 2008). Howevermain problem approach districting fact also failsgive representation minorities; minority may comprise 49% populationrepresented assembly. positive side districting method provideshigh level accountability: voters know representative, addressparticular issues even recall them, fail represent decentstandard.Various voting systemse.g., Cumulative Voting, Single Non-Transferable vote, multiwinner variants Single Transferable Vote, various party list systemshave designedsolve problem representation minorities (Brams & Fishburn, 2002). Howevernone scored high accountability. may even seem certaintrade-off cannot representation minorities accountability.However case. important idea suggested Charles Dodgson (1884),known also Lewis Carroll, considered different form Black (1958).idea developed Chamberlin Courant (1983) later Monroe (1995).relative advantages methods political science point viewextensively discussed Brams (2008). Dodgson asserted representation systemfind coalitions election would formed votersnecessary time information allow coalitions elect representative.adopted, sizable minority form coalition represented.realization idea required new concept concept misrepresentation. assumed voters form individual preferences candidates basedpolitical ideology judgement abilities candidates participatedeliberations decision making consistent individuals would wish actpresent (Chamberlin & Courant, 1983, p. 722). way revolution.Indeed, single-winner literature voting rules widely acceptedvoters political preferences complex first choices alone. However,multi-winner voting literature fixation first preferences led researchers thinkproportional representation exclusively terms first preferences. list systems476fiOn Computation Fully Proportional Representationproportional representation, parties assigned number seats parliamentproportional number votes (first preferences) received. systems likeSingle Non-Transferable Vote, Block Voting Cumulative Voting also take second preferences account (Levin & Nalebuff, 1995). Single Transferable Votesystem proportional representationin fact family voting methods accordingTideman Richardson (2000)that allows voters express order preferencecandidates (Levin & Nalebuff, 1995). Voters rank candidates order preference;first preference votes first looked at, votes transferred,necessary, candidates either comfortably elected donebadly eliminated election.1So, voter represented candidate first preference reasonablesay represented optimally misrepresentation case zero.general, voter represented candidate ith preference may assumemisrepresented degree si . course, reasonable assume0 = s1 s2 . . . sm . case rule measuring total misrepresentationfully defined vector = (s1 , . . . , sm ), number candidates.Using analogy positional scoring rules single-winner elections may saymisrepresentation function positional. general, problem choosing propermisrepresentation function far trivial. work Levin Nalebuff (1995,p. 4) difficulty vividly illustrated: electorate uniformly distributedsegment 0 1, choose three representatives, equallyspaced [0.25, 0.5, 0.75], selected minimize average distancetraveled nearest legislator [0.16, 0.5, 0.83]? broadest possible frameworkmisrepresentation function may even voter-dependent.Staying classical positional misrepresentation functions time suppose every voter assigned representative way. Measuring totalmisrepresentation whole society may adopt either Harsanyi (1995) approachRawlsian one (assuming utility represented ith best candidate si , i.e., nonpositive value). Harsanyi measure totalmisrepresentationXni si ,MH =i=1ni number voters represented ith preferred candidate. According Rawls (1999) welfare maximized utility society membersleast greatest. leads total misrepresentation functionMR =maxni >0si .Chamberlin Courant (1983), Monroe (1995) consider best setrepresentatives must minimize total misrepresentation calculate usingBorda vector scores, is, (0, 1, 2, . . . , 1) Harsanyis misrepresentation1. Northern Ireland voting system used elections local councils, Assembly,European Parliament. used elections Irish Republic, Malta, Australia (althoughsingle-member constituencies prevalent Australia, apart state level elections TasmaniaACT). Several countries recently debated adopting it.477fiBetzler, Slinko, & Uhlmannfunction. methods however different difference important. Chamberlin Courant impose restriction function assigns candidatesvoters. may potentially lead different number voters representedcandidate. remedy Chamberlin Courant suggested use weighted votingassembly elected candidate weight equal number votersrepresent. Monroe rejected approach insisted principle one memberassembly one vote. reason insisted difference numbersvoters assigned two representatives one.reasons Monroe rejected Chamberlin Courant approach quitesubstantial. Proportional allocation weights known result excessive voting powerselectorates larger constituencies much debate rightway allocating weights representatives. alternative Chamberlin Courantsmethod would give representatives weights proportional square rootnumber voters represent. justified fact, due square rootlaw Penrose (1946), priori voting power (as defined Penrose-Banzhaf index)member voting body inversely proportional square root size.basis theory, example, Poland insisted EU allocate Council-of-Ministervotes according square root nations population (Slomczynski & Zyczkowski,2006).computational problems Harsanyi approach entails knownNP-hard (Lu & Boutilier, 2011; Procaccia, Rosenschein, & Zohar, 2008) several classical misrepresentation functions. paper try achieve tractability multiwinnerelections three different ways. Firstly, ask whether problem finding optimal fully proportional representation becomes easier classical misrepresentationfunctions adopt Rawlsian approach measurement total misrepresentation.second goal find parameterized complexity aforementioned problemsnatural choices parameters. third develop efficient algorithmsachieving optimal fully proportional representation single-peaked elections.remainder section, formally introduce computational problemsconsidered paper, summarize results extant literature, describeapproaches results.1.1 Computational Problems Consideredelection pair E = (C, V ) C set candidates (or alternatives) Vordered list voters. voter represented vote, strict, linear orderset candidates (also called voters preference order ). referlist V preference profile, denote number voters V n. numberalternatives denoted m. order voters important (the electionanonymous), V considered multiset2 votes. paperconsider anonymous elections.posv (c) denote position alternative c ranking voter v;top-ranked alternative position 1, second best position 2, etc.2. set since two different voters may preference order.478fiOn Computation Fully Proportional RepresentationQDefinition 1. Given profile V C, mapping r : V C +0 calledmisrepresentation function v V two candidates c, c C conditionposv (c) < posv (c ) implies r(v, c) r(v, c ).say c preferred c vs ranking, misrepresentation v,represented c least large misrepresentation,represented c. classical framework misrepresentation candidatevoter function position candidate preference order votergiven = (s1 , . . . , sm ), i.e., misrepresentation function caser(v, c) = sposv (c) .important particular case Borda misrepresentation function defined vector(0, 1, . . . , 1).approval voting framework, voter represented candidateapproves, misrepresentation considered zero, otherwise equal one.function called approval misrepresentation function. misrepresentation function positional since different voters may approve different numbercandidates. Note misrepresentation functions, like Borda, derivedpreference lists voters. contrast, approval misrepresentation function cannot obtained preference list without information thresholdseparates approved candidates disapproved ones. general frameworkmisrepresentation function may arbitrary.w : V C denote function assigns voters representatives (orway around), i.e., assignment voter v represented candidate w(v).total misrepresentation election w givenXr(v, w(v)) max r(v, w(v))vVvVHarsanyis classical Rawls minimax versions, respectively. say mapping w respects -criterion (or Monroe criterion) |w(V )| = k w assigns leastn/k n/k voters every candidate w(V ), k total numberrepresentatives elected assembly. Note case -criterion setk winners might lead higher misrepresentation set k winners.example, consider election voters favour candidateset winners elected greater one.Based previous discussion, work investigate computational complexity following four combinatorial problems. two classical ones describednamed Chamberlin Courant (CC), case candidate represent arbitrary number voters (and number voters weightelected assembly), Monroe (M), case every candidate represents roughlynumber voters (and representative one vote assembly). twopreviously unstudied versions adopt Rawlsian approach measuring totalmisrepresentation called minimax versions classical ones.CC-Multiwinner (CC-MW)Given: set C candidates, multiset V voters, misrepresentationfunction r, misrepresentation bound R +0 positive integer k.Q479fiBetzler, Slinko, & UhlmannTask: Find subsetP C C size k assignment voters ww(V ) = C vV r(v, w(v)) R.Minimax CC-Multiwinner (Minimax CC-MW)Given: set C candidates, multiset V voters, misrepresentationfunction r, misrepresentation bound R +0 positive integer k.QCTask: Find subsetC size k assignment voters ww(V ) = C maxvV r(v, w(v)) R.M-Multiwinner (M-MW)Given: set C candidates, multiset V voters, misrepresentationfunction r, misrepresentation bound R +0 positive integer k.QCTask: Find subsetC size k assignmentvoters w,Prespects -criterion, w(V ) = C vV r(v, w(v)) R.Minimax M-Multiwinner (Minimax M-MW)Given: set C candidates, multiset V voters, misrepresentationfunction r, misrepresentation bound R +0 positive integer k.QCTask: Find subsetC size k assignment voters w,respects -criterion, w(V ) = C maxvV r(v, w(v)) R.Note finding assignment voters fixed set k winners accomplished polynomial time four problems applying network flow algorithms (seeSection 3.2). Hence, follows assume k < k < n since otherwisefour problems decided polynomial time. also note problems consideredcontained NP since one guess set k winners corresponding mappingvoters check polynomial time whether satisfies corresponding conditions.four problems stated general misrepresentation functions (sincealgorithmic results hold even case) main focus workBorda approval ones.1.2 Previous Computational Complexity Resultsstudy computational complexity problems context voting initiated Bartholdi III, Tovey, Trick (1989) 20 years ago became activearea research recently (Conitzer, 2010; Faliszewski & Procaccia, 2010; Faliszewski,Hemaspaandra, & Hemaspaandra, 2010; Faliszewski, Hemaspaandra, Hemaspaandra, &Rothe, 2009b). large number papers dealing single-winner electionsmulti-winner elections whose final goal still choose single winner tiebreaking, articles (Potthof & Brams, 1998; Procaccia et al., 2008; Lu & Boutilier,2011) deal computational complexity Multiwinner elections aimed achievingproportional representation. particular, works contain NP-hardness proofsCC-Multiwinner M-Multiwinner approval misrepresentation function (Procaccia et al., 2008) CC-Multiwinner Borda misrepresentation function (Lu &Boutilier, 2011). Algorithmic approaches comprise Integer Linear Programming (Potthof &480fiOn Computation Fully Proportional RepresentationBrams, 1998; Brams, 2008) CC-MW M-MW, approximation algorithms basedgreedy strategies (Lu & Boutilier, 2011) CC-MW, polynomial-time algorithmsCC-MW M-MW instances number candidates constant (Procacciaet al., 2008). contrast, best knowledge, computational complexityminimax versions problems remained unstudied.aware one work explicitly studying computational complexityissues context multiwinner elections. Meir, Procaccia, Rosenschein, Zohar(2008) investigate computational complexity strategic voting several multiwinnerelections winner determined polynomial time. systems consideredlead kind proportional representation.1.3 Approach Results General Electionsfirst result minimax versions classical Chamberlin-Courant Monroe problems also NP-complete. words, adopting Rawlsian approachmake computation problems easier general (but see situation changes completely single-peaked elections minimax version becomeseasier indeed). Based negative results, work aims extending previousalgorithmic approaches described analysis whether settingsproblems become tractable. end, parameterized algorithmicsappropriate tool aims identifying tractable special cases NP-hard problems.cornerstone approach idea complexity problem measured total size input instance also additional parameter p, usuallynonnegative integer (but pair integers virtually anything). problem called fixed-parameter tractable algorithm solving every instancef (p) poly(|I|) time, f computable function (Downey & Fellows, 1999; Flum& Grohe, 2006; Niedermeier, 2006). small values p algorithm runningtime might represent efficient algorithm NP-hard problem consideration.Parameterized complexity also provides tool parameterized reductions oneshow problem presumably fixed-parameter tractable. Oneimportant parameterized complexity classes purpose W [2] (see Section 2details). remark passing parameterized complexity analysis employed several voting problems, (e.g., see Brandt, Brill, & Seedig, 2011; Betzler,Guo, & Niedermeier, 2010; Betzler, Hemmann, & Niedermeier, 2009; Christian, Fellows,Rosamond, & Slinko, 2007; Dorn & Schlotter, 2010; Elkind, Faliszewski, & Slinko, 2010b;Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a also Betzler, Bredereck,Chen, & Niedermeier, 2012 survey).context multiwinner elections, parameter immediately attracts attentionnumber k winners, many settings might much smaller numbercandidates number voters. Another reasonable parameter misrepresentation bound R since ideal (or fully personalizable Lu & Boutilier, 2011) situation Requal zero, is, every voter represented one preferred candidates.provide parameterized complexity analysis four considered problemsBorda approval misrepresentation functions respect parameters k R.481fiBetzler, Slinko, & UhlmannParameterrCC-MWMinimax CC-MWM-MWMinimax M-MW#winner k#winner kBW[2]-hard ()W[2]-hard ()W[2]-hard ()W[2]-hard ()W[2]-hard ()W[2]-hard ()W[2]-hard ()W[2]-hard ()misr. Rmisr. RBNP-h R = 0 ()XP ()NP-h R = 0 ()NP-h R 1 ()P R = 0 ()NP-h R = 0 ()XP ()NP-h R = 0 ()NP-h R 1 ()P R = 0 ()(R, k)(R, k)BW[2]-hard ()FPT ()W[2]-hard ()FPT ()W[2]-hard ()FPT ()W[2]-hard ()FPT ()# cand.# votersUUFPT ()FPT ()FPT ()FPT ()FPT ()FPT ()FPT ()FPT ()Table 1: Parameterized complexity considered multiwinner problems instancesmisrepresentation function r either approval (A), Borda (B) unrestricted (U). Results obtained follows. : Theorem 1, : Theorem 2, : Theorem 3, : Theorem 4, : Theorem 5, : Theorem 6, : Theorem 7 : Proposition 1,Proposition 2.addition, also investigate composite parameter (R, k) consisting numberwinners misrepresentation bound.overview results provided Table 1. number winners kparameter, considered problems turn W[2]-hard. parameterizationtotal misrepresentation bound R results varied. case R = 0,approval misrepresentation function four problems NP-hardsolvable polynomial time Borda misrepresentation function. However, MinimaxCC-MW Minimax M-MW become NP-hard every R 1. contrast, summinimization variants CC-MW M-MW Borda misrepresentation functionsolvable polynomial time constant R (the corresponding parameterized complexityclass called XP). Note provided algorithm shows containment XPrespect R fixed-parameter tractability, problem remains open. inspiredanalysis composite parameter (R, k), covering scenarios smallset winners represent voters small total misrepresentation.approval misrepresentation function, still leads parameterized intractability, Borda misrepresentation function, show fixed-parameter tractabilityconsidered problems. complete picture multivariate complexity analysis,additionally provide fixed-parameter tractability respect parameters numbervoters number candidates.1.4 Results Single-Peaked ElectionsSingle-peakedness one central notions social choice political science alike(Black, 1958; Moulin, 1991; Tideman, 2006). preferences voters single-peakedsingle issue dominates formation. could ideological positionLeft-Right Liberal-Conservative spectra, level taxation, immigration quota, etc.Tideman compares single-peakedness convexity preferences discusses482fiOn Computation Fully Proportional RepresentationCC-MW2O(nm )Minimax CC-MWO(nm)M-MW33 3O(n k ) approvalNP-h integer mis. func.Minimax M-MWO(n3 m3 k3 )Table 2: Overview computational complexity singled-peaked elections. casepolynomial-time solvability, table provides running times dependingnumber n voters, number candidates, number kwinners. stated otherwise, result holds arbitrary misrepresentationfunction. : Theorem 8, : Proposition 4, : Theorem 10, : Proposition 5,: Theorem 11.reasonable assume this. refers data collection containing 87 ranked-ballot real-lifeelections, access to, claims single-peaked.single dominating issue normally represented axis voter characterized single point axis (see example Figure 1. misrepresentationfunction fixed voter function single variable defined axis.single-peakedness preferences implies function exactly one local minimum.refer Section 5 formal proof statement.note votes form approval ballots well linear orders, singlepeakedness profile checked linear time (Booth & Lueker, 1976; Escoffier,Lang, & Ozturk, 2008) reconstruction order candidates axis.case single-peaked profiles computational problems turnedallow efficient solving strategies general case (Brandt, Brill, Hemaspaandra, & Hemaspaandra, 2010; Conitzer, 2009). particular, study computational complexity voting rules NP-hard winner-determination problem showsCondorcet-consistent onesand include Dodgson, Kemeny, Youngrulesthe winner-determination problem becomes polynomial-time solvable restrictsingle-peaked profiles (Brandt et al., 2010). obvious reasonsingle-peakedness eliminates possibility Condorcet cycles election profile.obvious single-peakedness must also simplify winner-determinationproblem methods proportional representation. However, seems natural investigate possibility. results show many instances winner-determinationproblem methods proportional representation indeed become easier too.results summarized Table 2. CC-MW Minimax CC-MW problems solvable polynomial time arbitrary misrepresentation function.specifically, CC-MW provide dynamic programming algorithm running O(nm2 )time n voters candidates, Minimax CC-MW solved O(nm) timegreedy algorithm. Monroe system variants, results becomediverse. Minimax M-MW general misrepresentation function still solvablepolynomial time, M-MW NP-hard. However, positive side, still showpolynomial-time solvability M-MW approval misrepresentation function. Basically, results obtained follows. M-MW approval misrepresentation483fiBetzler, Slinko, & Uhlmannfunction establish close connection one-dimensional rectangle stabbing problem capacities. allows provide dynamic programming algorithm baseddecomposition property provided Even, Levi, Rawitz, Schieber, Shahar, Sviridenko(2008). result transferred Minimax M-MW. NP-hardness M-MWestablished many-one reduction restricted version Exact 3-Coverproblem. NP-hardness holds integer-valued misrepresentation functionmaximum misrepresentation value still polynomial number candidates. However, need allow situations voter may equally misrepresented severalcandidates. Hence, clear transfer corresponding many-one reductionM-MW Borda misrepresentation function. problem computationalcomplexity left open.1.5 Organization Paperpaper organized follows. Section 2, introduce main concepts parameterized complexity graph problems. Section 3 contains basic observationsrelations four problems consideration fixed-parameter tractability results respect number voters number candidates. two maincontributions proved Section 4 Section 5. Section 4, present main parameterized complexity results well NP-hardness results minimax versions.Section 5, special case single-peaked elections handled. Finally, Section 6conclude discussion relevance results related problemssettings.2. Preliminariesbriefly introduce framework parameterized complexity followed basicgraph problems employed paper. basic notions regarding classicalcomplexity theory refer Garey Johnson (1979).2.1 Parameterized Complexityconcept parameterized complexity pioneered Downey Fellows (1999). Seealso textbooks Flum Grohe (2006) Niedermeier (2006). fundamentalgoal find whether seemingly unavoidable combinatorial explosion, occurringexact algorithms NP-hard problems, confined certain problem-specific parameters. idea parameter real-life application restricted smallvalues only, algorithm running time exponential exclusivelyrespect parameter may efficient practical. provide formal definitions.Definition 2. parameterized problem language L , finitealphabet. second component called parameter problem.Basically, means input parameterized problem pair (x, p), xconsidered main input p parameter problem. considerparameters positive integers composite parameters tuples severalpositive integers.484fiOn Computation Fully Proportional RepresentationDefinition 3. parameterized problem L fixed-parameter tractable algorithm decides f (p) |x|O(1) time whether (x, p) L, f arbitrarycomputable function depends p. complexity class fixed-parametertractable problems called FPT.Unfortunately, parameterized problems fixed-parameter tractable.end, Downey Fellows (1999) developed theory parameterized intractabilitymeans completeness program complexity classes. specifically, definedso-called W -hierarchy using Boolean circuits. hierarchy consists followingclasses:FPT W[1] W[2] . . . W[Sat] W[P] XP(we refer reader book Downey & Fellows, 1999, precise description).particular, stress concept fixed-parameter tractability differentnotion polynomial-time solvability constant p since algorithm runningO(|x|p ) time imply fixed-parameter tractability. problems solvedrunning time O(|x|f (p) ) computable function f form complexity class calledXP.containment W[1] FPT would imply P = NP such. would imply,however, failure Exponential Time Hypothesis (Impagliazzo, Paturi, & Zane,2001). Hence, commonly believed W[1]-hard problems fixed-parametertractable. show W[t]-hardness problem positive integer t, followingreduction concept introduced.Definition 4. Let L, L two parameterized problems. say L reducesL parameterized reduction two computable functions h1 :h2 : + function f : (x, p)N Q1. (x, p) L f (x, p) L f computable time |x|O(1) h2 (|p|)2. (x , p ) = f (x, p), p = h1 (p).Analogously case NP-hardness, positive integer t, suffices giveparameterized reduction one W[t]-hard parameterized problem X parameterizedproblem show W[t]-hardness . details parameterized complexity theory refer textbooks (Downey & Fellows, 1999; Flum & Grohe, 2006;Niedermeier, 2006).work, provide results regarding second level (presumable) parameterized intractability captured complexity class W[2]. Several parameterizedreductions work W[2]-complete Hitting Set (HS) problem: Givenfamily F = {F1 , . . . , Fn } sets universe U = {u1 , . . . , um } integer k 0,decide whether hitting set U U size k understandset U Fi U 6= every 1 n. HS NP-hard (Garey & Johnson, 1979)W[2]-hard respect parameter k (Downey & Fellows, 1999).2.2 Graph Problemsalgorithmic results employ algorithms basic graph problems definedfollowing. undirected graph pair G = (U, E), consisting set U vertices485fiBetzler, Slinko, & Uhlmannset E edges, edge unordered pair (size-two set) vertices. Twovertices u, v U called adjacent {u, v} E. undirected graph G = (U, E)vertex u U , neighborhood N (u) u set vertices adjacent u.undirected graph G = (U, E) called bipartite vertex set U partitionedtwo nonintersecting subsets U1 U2 E {{u, v} | u U1 v U2 }.matching edge set E E e e = every two distinct edges e, e E .maximum matching matching maximum cardinality. undirected graphedge {u, v} associatedweight w({u, v}) maximum-weight matchingPmatching E {u,v}E w({u, v}) maximal.directed graph directed network pair G = (U, A), consisting set Uvertices set U U directed edges (or arcs) directed edgeordered pair vertices. flow network directed network G = (U, A)two distinguished vertices U (the source) U (the sink target)arc (u, v) associated nonnegative number c(u, v), called capacity. Roughlyspeaking, flow function f assigns real value f (u, v) 0 f (u, v) c(u, v)every arc (u, v) satisfies constraints every vertex v exceptsource sink total flow v equals total flow v. See textbookCormen, Leiserson, Rivest, Stein (2001) details. maximum flow flowtotal flow sink maximal.paper, make use fact maximum-weight matching bipartitegraph well maximum flow general graphs computed polynomial timestandard graph algorithms (e.g., see Cormen et al., 2001).3. Basic Results Observationssection, shed light combinatorial relations problemsinvestigate parameterized complexity considered problems respectparameters number voters number candidates. results alsoemployed following sections. particular, algorithms showing fixedparameter tractability used subroutines Section 4 obtain fixed-parametertractability respect parameterizations.3.1 Relations ProblemsAlthough four problems come different properties general, special cases,coincide. One example so-called fully personalizable setting (Lu& Boutilier, 2011), is, case misrepresentation bound R zero henceevery voter represented one best alternatives (i.e., onemisrepresentation zero). Clearly, asking set winners assignmentsum misrepresentations zero equivalent asking set winnersassignment maximum misrepresentation value zero. leadsfollowing observation.Observation 1. R = 0, Minimax M-Multiwinner coincides M-MultiwinnerMinimax CC-Multiwinner coincides CC-Multiwinner.486fiOn Computation Fully Proportional RepresentationMoreover, two minimax versions problems, matters whetherparticular misrepresentation value exceeds threshold R not. Hence, instanceminimax version arbitrary misrepresentation function r reducedequivalent instance problem approval misrepresentation function rfollows. every voter v every candidate c, set r (v, c) = 1 r(v, c) > R,r (v, c) = 0 r(v, c) R and, finally, set R := 0.Observation 2. Minimax M-/CC-Multiwinner instance (C, V, r, R, k) misrepresentation function r, instance (C, V, r , 0, k) approval misrepresentation function r new instance yes-instance originalinstance yes-instance.direct consequence, minimax versions every algorithm approval misrepresentation function also applies instances general misrepresentation function.Moreover, hardness results arbitrary misrepresentation function transfer approval misrepresentation function. Combining Observations 1 2, concludealgorithm M-MW (CC-MW) instances R = 0 also solves correspondingminimax version general misrepresentation function.Finally, observe hardness result established approval misrepresentationfunction directly transferred minimax version problemmisrepresentation function voter allowed give arbitrary numbercandidates misrepresentation value R. Note holdBorda misrepresentation function every voter v must specify exactly R+1 candidatesrepresent v misrepresentation R.3.2 Numbers Voters Candidates Parametersargue four problems considered fixed-parameter tractable respectnumber candidates well respect number voters. algorithmsbased brute-force search combined maximum flow matching techniques.First, consider parameterization number voters. Then, focusparameterization number candidates.3.2.1 Number Voters Parametershow considered multiwinner problems fixed-parameter tractable parameterized number n voters. basic idea assignment candidatesvoters induces partition set voters voters setpartition represented candidate. Given partition set voters,best set candidates partition found computation matchingbipartite auxiliary graph. Since may try O(kn ) O(nn ) partitions setvoters k sets resulting algorithm shows fixed-parameter tractability.Proposition 1. (Minimax) CC-Multiwinner (Minimax) M-Multiwinnersolved nn poly(n, m) time instance n voters candidates.Proof. First, present solution strategy Minimax CC-MW. find set kwinners, try O(kn ) partitions set voters k subsets. case yesinstance Minimax CC-MW, must partition V1 , . . . , Vk multiset voters487fiBetzler, Slinko, & UhlmannV follows. every Vi , voters Vi assigned candidate c optimalset k winners voter assigned c. Hence, every partition, remainsselect k candidates, one candidate ci every subset Vi , assigning votersVi ci misrepresentation voter R. Minimax CC-MWset candidates determined computing maximum-cardinality matchingfollowing bipartite graph. One part graph represents set candidatespart set {V1 , . . . , Vk }. Moreover, edge vertex representingcandidate c vertex representing subset Vi r(v, c) R v Vi .straightforward verify voters represented maximal misrepresentationbound R maximum-cardinality matching size k (all verticesrepresenting subsets matched) constructed graph.Regarding running time, computation maximum-weight matchingbipartite graph nv vertices ne edges accomplished O(nv (ne + nv log nv ))time (Fredman & Tarjan, 1987). Since number edges vertices constructedbipartite graph polynomial number candidates k n, claimed runningtime follows.Next, focus CC-MW. Again, try partitions voters k subsets.every partition, compute maximum-weight matching following edgeweighted bipartite graph. One part consists vertices corresponding candidatespart vertices corresponding subsets partition V1 , . . . , Vkmultiset voters.PMoreover, edge every vertex c every vertex Viweight vVi r(v, c), positive integer large enough ensureweights positive. crucial observation maximum-weight matchingevery vertex V1 , . . . , Vk matched since edge weights positive (here assumek m). Hence, computation maximum-weight matching yields set kcandidates representing subsets voters good possible. specifically,let W denote weight maximum-weight matching. Then, kT W totalmisrepresentation corresponding assignment.Finally, observe two problems assignment voterswinners must fulfill -criterion proceed way single exceptionneed consider partitions every subset contains least n/kn/k voters. running time bound follows complete analogy MinimaxCC-MW discussed above.3.2.2 Number Candidates Parameterfixed number candidates four considered multiwinner problems solvedefficiently. (Minimax) CC-Multiwinner parameterizedby number candimdates fixed-parameter tractability trivial: testk 2 subsets candidatesreport set candidates minimum total misrepresentation. end, oneassigns every voter v candidate considered subset represents vbest possible way directly obtains sum misrepresentations maximummisrepresentation.Clearly, assignment voters fulfill -criterion. However, (Minimax) M-Multiwinner, one apply network flow algorithms find488fiOn Computation Fully Proportional Representationoptimal assignment voters size-k subset C set candidates (seePreliminaries Subsection 2.2 basic definitions regarding network flows).Minimax M-Multiwinner, construct directed network vertex everycandidate C , one vertex every voter, source, sink vertex.arc capacity n/k lower bound n/k source every candidatevertex3 . Moreover, capacity-one arc candidate-vertex votervertex corresponding candidate represent corresponding votermisrepresentation R. Finally, arc capacity one everyvoter-vertex sink vertex. straightforward verify networkflow size n assignment voters C satisfies-criterion every voter represented misrepresentation R.M-Multiwinner, construction given minimax versionextended. particular, follows Theorem 2 Procaccia et al. (2008), finding-criterion fulfilling assignment V C minimum total misrepresentationaccomplished polynomial time computation transportation problemor, equivalently, computation minimum-weight maximum flow.Proposition 2. (Minimax) CC-Multiwinner (Minimax) M-Multiwinnersolved O(2m nm) O(2m poly(n, m)) time, respectively, instancescandidates.4. Number Winners Misrepresentation BoundParameterssection, show four problems approval Borda misrepresentation functions W[2]-hard respect number winners. misrepresentation functions provide one parameterized reduction works fourproblems. investigate misrepresentation bound R parameter.approval misrepresentation function NP-hardness R = 0 follows directlyparameterized reduction respect number winners, Borda misrepresentation function, parameter needs investigated separately. show CC-MWM-MW XP respect R, is, solvable polynomial timeR constant. However, corresponding algorithm show fixed-parametertractability respect R. question whether result extendedfixed-parameter tractability respect R left open. present, however,fixed-parameter tractability results respect composite parameter (R, k)end section. overview results found Table 1.4.1 Approval Misrepresentation Functionprovide reduction W[2]-complete Hitting Set problem establish W[2]hardness four problems. so, discuss related results. conference paper (Procaccia, Rosenschein, & Zohar, 2007) stated NP-hardnessCC-Multiwinner M-Multiwinner follows reduction Max k-Cover3. problem variant lower bounds (demands) solved polynomial time simple reductionnormal flow problem (Ahuja, Magnanti, & Orlin, 1993, Section 6.7).489fiBetzler, Slinko, & Uhlmann(omitting problem definition construction) subsequent journal paper (Procaccia et al., 2008) reduction given Exact 3-Cover. Althoughsufficient show NP-hardness, reduction Exact 3-Cover imply W[2]hardness. reduction given conceptually similar requires additionalvoters deal fact sets Hitting Set instance might comedifferent/unbounded size.Theorem 1. approval misrepresentation function, (Minimax) CC-Multiwinner(Minimax) M-Multiwinner W[2]-hard respect number k winnerseven R = 0. Minimax CC-Multiwinner Minimax M-Multiwinner NPcomplete.Proof. First, show W[2]-hardness M-Multiwinner. Then, argue presented reduction works three problems well.Given instance Hitting Set (F = {F1 , . . . , Fn }, U = {u1 , . . . , um }, k), buildinstance M-Multiwinner set C candidates follows. candidate ciC every element ui U . multiset voters VF D, VF := {vF | F F}multiset voters indexed F |D| = n(k 1) set dummy voters.Furthermore, every F F every ui U , let r(vF , ci ) := 0 ui F r(vF , ci ) :=1, otherwise. Finally, every every ui U , set r(d, ci ) := 0. completesconstruction. correctness show following.Claim. hitting set size k F winner setsize k M-Multiwinner represents voters total misrepresentation R = 0.: Let U denote size-k hitting set F C := {ci | ui U }. show onebuild mapping w : V C respects -criterion total misrepresentationzero. First, every F F, set w(vF ) := ci arbitrary chosen element ui F U .Clearly, r(vF , ci ) = 0. far, n voters VF assigned candidates Cremains assign n(k1) voters D. Since candidate C representdummy voter misrepresentation zero, easily extend assignmentcandidate C assigned exactly n voters.:PLet C C denote size-k winner set let w mapping V CvV r(v, w(v)) = 0. Since voter vF VF represented cost zerocandidate ci ui F , set U := {ui | ci C } size-k hitting set F.completes proof M-Multiwinner. straightforward verifyconstruction yields parameterized reduction CC-Multiwinner. Finally,W[2]-hardness minimax versions follows directly Observation 1 sincereduction works R = 0. Moreover, NP-hardness directly follows since reductionclearly carried polynomial time containment NP obvious.4.2 Borda Misrepresentation Functionrefine reduction previous subsection show also Borda misrepresentation function considered problems W[2]-hard respect number k490fiOn Computation Fully Proportional Representationwinners parameter. However, contrast case approval misrepresentation function reduction hold case R = 0. Hence, investigateparameter total misrepresentation R well composite parameter (R, k) subsequently.4.2.1 Number Winners ParameterBorda misrepresentation function, also provide many-one reductionHitting Set M-Multiwinner argue presented reduction worksthree problems well. CC-Multiwinner W[2]-hardness also directlyfollows NP-hardness reduction (also Hitting Set) provided LuBoutilier (2011, Thm. 8).4 reduction, however, deal M-criterionadopted minimax versions two rules; particular, using paddingcandidates voters deal M-criterion.Theorem 2. (Minimax) CC-Multiwinner (Minimax) M-Multiwinner W[2]hard respect number k winners Borda misrepresentation function.Minimax CC-Multiwinner Minimax M-Multiwinner NP-complete.Proof. First, show W[2]-hardness M-Multiwinner parameterized reductionHitting Set. Given HS-instance (F = {F1 , . . . , Fn }, U = {u1 , . . . , um }, k) buildinstance M-Multiwinner follows. Let z := nmk. set C candidates CU B,CU := {cu | u U } B := {b1i , . . . , bzi | 1 nk}. Moreover, multisetvoters VF D, VF := {vi | Fi F} := {d1 , . . . , dn(k1) }. votermisrepresentation function given preference list.5n set voters vi VF following preference list:{cu | u Fi } > b1i > . . . > bzi > {cu | u U \ Fi } > {b1j , . . . , bzj | 1 j nk, j 6= i}.Finally, {1, . . . , n(k 1)}, voter di following preferencelist:c1 > c2 > . . . > cm > b1n+i > . . . > bzn+i > {b1j , . . . , bzj | 1 j nk, j 6= n + i}.completes construction. correctness show following.Claim. size-k hitting set F size-k winnerset M-Multiwinner represents voters total misrepresentationz = nmk.: Let U denote size-k hitting set F C := {cu | u U }. buildmapping w : V C follows. First, every Fi F, set w(vi ) := cu arbitrarilychosen element u Fi U . Clearly, r(vi , cu ) since elements Fi top preferencelist vi |Fi | m. far, n voters VF assigned candidates C .4. proof provided extended version appeared Third International WorkshopComputational Social Choice (COMSOC-10) title Budgeted Social Choice: FrameworkMultiple Recommendations Consensus Decision Making, see Thm. 6.5. improve readability, also use sets candidates description preference lists.set fixed arbitrary order.491fiBetzler, Slinko, & UhlmannSince candidate C represent dummy voter misrepresentationm, one extend mapping exactly n voters assigned cu Cmisrepresentation voter. Thus, total misrepresentationassignment nm + nm(k 1) = nmk.:PLet C C denote size-k winner set w mapping V CvV r(v, w(v)) mnk. First, show C contain candidate bji B.Every candidate B represent one voter misrepresentation value betterz. specifically, 1 n, bji represent voter viquality representation if, n < nk, bji present voter di . Sinceevery candidate C must assigned exactly n voters misrepresentationbound z, conclude C B = .remains show U := {u U | cu C } hitting set F. voter viVF represented candidate cu CU misrepresentation zu Fi since candidates cu u U \ Fi occur preference list vicandidates b1i , . . . , bzi . Thus, U hitting set F size k.completes proof M-Multiwinner. construction yields parameterized reduction CC-Multiwinner based claim. directionleft right follows complete analogy. direction, differencesolution set C CC-Multiwinner instance might contain candidateB. However, candidate bji , represent one voter(that is, vi ) within required misrepresentation bound hence replacedcandidate cu Fi represents corresponding voter even better.proof Minimax M-Multiwinner Minimax CC-Multiwinner, follows directly arguments size-k hitting set Fset winners Minimax M/CC-Multiwinner consisting k candidatesrepresent voters maximum misrepresentation R := 1. Hence,W[2]-hardness well NP-hardness follow.4.2.2 Parameter Misrepresentation BoundRecall approval misrepresentation function, four problems NP-hard evenfully personalized setting, is, R = 0. contrast, CC-MW MMW Borda misrepresentation function, provide polynomial-time algorithmsevery constant R showing minimax versions NP-hard R 1polynomial-time solvable R = 0. First, simple exhaustive search strategy, oneobtains following.Theorem 3. Borda misrepresentation function, CC-Multiwinner M-Multiwinner solvable polynomial time misrepresentation bound R constant.Proof. every solution, R voters represented misrepresentation greater0. Thus, constant values R, one try O(|V |R ) subsets R votersfind subset V V voters represented misrepresentation valuezero optimal winner set. subset V , voter v V , onetries possible misrepresentation values 1 R, is, one tries O(RR )possibilities V . possibility, misrepresentation value492fiOn Computation Fully Proportional Representationvoter determined. Since Borda exactly one candidate representvoter specific value, also implies corresponding mapping V setcandidates. Every remaining voter assigned candidate representsmisrepresentation value zero. case CC-Multiwinner, remains checkwhether k candidates become representatives whether correspondingset candidates represent voters total misrepresentation R. caseM-Multiwinner one additionally needs check whether corresponding assignmentsatisfies -criterion. follows cases optimal set k winnerscomputed O((|V | R)R |V ||C|) time.Note Theorem 3 imply fixed-parameter tractability respect R,remains open work. However, provide fixed-parameter tractability resultsrespect composite parameter (R, k) end section. Now, contrastresults CC-MW M-MW showing minimax versions become provablydifficult. specifically, show following.Theorem 4. Borda misrepresentation function, minimax CC-Multiwinnerminimax M-Multiwinner solvable polynomial time total misrepresentationbound R = 0 NP-hard every R 1.Proof. R = 0 polynomial-time solvability follows directly fact every voter vmust assigned candidate c r(v, c) = 0 Borda misrepresentationfunction one candidate. Hence, one needs check lessk candidates and, minimax M-Multiwinner whether correspondingassignment satisfies M-criterion.Now, show NP-hardness R = 1 reduction special case HittingSet. specifically, Hitting Set NP-hard even every set consists two elementsevery element appears three sets (Garey, Johnson, & Stockmeyer, 1974,Thm. 2.4).6Given restricted HS-instance (F = {F1 , . . . , Fn }, U = {u1 , . . . , um }, k), buildelection follows. Identify every set F voter identify every elementU candidate. Moreover, define following misrepresentation function.F = {u, v} F, let misrepresentation voter F zero candidate uone candidate v, remaining misrepresentation values assigned arbitrarilyremaining candidates. Then, following claim easy see.Claim: hitting set size k set k winnersmisrepresentation voter 1.shows theorem Minimax CC-MW R = 1. Minimax M-MW,one use following observation showing NP-hardness even restrictedsetting. follows directly Hitting Set instances constructed NP-hardnessproof (Garey et al., 1974, Thm. 2.4) yes-instance always hitting setevery element hits either two three sets F. specifically, caseyes-instance hitting set U U every u U assigned6. problem Vertex Cover cubic graphs.493fiBetzler, Slinko, & Uhlmann12345678910111213Branch (V , R , C ) :R < 0 |C | > kreturn no;PwV (mindC r(w, d)) Rreturn yes;Consider arbitrary v V ;V := V \ {v};c C r(v, c) RR := R r(v, c) ;C := C {c};V := V \ {w V | r(w, c) = 0};Branch (V , R , C )return yes ;141516endreturn no;Algorithm 1: Branching strategy CC-Multiwinner Borda misrepresentationfunctions showing fixed-parameter tractability respect composite parameter (R, k). Initially, algorithm invoked arguments (V, R, ). Moreover, Ck provided global variables.either two three sets F every set hit exactly one element.hitting set one-to-one-corresponds winner set fulfilling M-criterion hencetheorem also follows Minimax M-MW R = 1. every R > 1, NP-hardnessproved similar arguments. Basically, extend previous construction follows.every voter, add R 1 new candidates placed first R 1 positionsvoter position higher R every voter. Since new candidatesclearly cannot part Minimax M-MW solution misrepresentation bound R,one argue analogously case.4.2.3 Composite Parameter Number Winners MisrepresentationBoundparagraph, focus scenario one small set winnersrepresent voters small total misrepresentation. modeled compositeparameter (R, k), k number winners R total misrepresentation.show Borda misrepresentation function, four considered problemsfixed-parameter tractable.Theorem 5. Borda misrepresentation function, CC-Multiwinner Minimax CC-Multiwinner fixed-parameter tractable respect composite parameter (R, k), k denotes number winners R misrepresentation bound.Proof. First, provide branching strategy Minimax CC-MW. find size-ksolution proceed follows. arbitrary voter v V , branch according494fiOn Computation Fully Proportional Representationcandidates c r(v, c) R. possibility, create subinstance deletingvoter w r(w, c) R V recursively solve corresponding subinstancek 1. Finally, report whether least one subinstance solution size k 1found. recursion stops either k < 0 (reporting no) votersrepresented (reporting yes).correctness corresponding algorithm obvious since voter v must represented candidate c r(v, c) R. Regarding running time, one branchesR + 1 possibilities every considered voter decreases value k oneevery subinstance. Hence, algorithm investigates (R + 1)k possibilities.show extend branching strategy work CC-MW. branchingrecursion displayed Algorithm 1 invoked arguments (V, R, ). NoteC k provided global variables.correctness Algorithm 1 seen follows. algorithm first checkswhether misrepresentation bound solution size exceeded (Line 2). Second,algorithm checks whether current candidate set already winner set, is,whether voters represented assignment within misrepresentation bound(Line 4). Otherwise, arbitrarily chosen voter v (Line 6), algorithm triespossible ways representation without exceeding misrepresentation bound (Line 8).possibility, decreases R value needed representation vcorresponding candidate (Line 9). possibility implies new candidate addedcurrent solution, clearly assign voters optimally representedcandidate hence delete corresponding voters (Line 11). Finally,recursively invoke Branch procedure corresponding subinstance (Line 12). Sincepossibilities represent v considered least one possibility must lead solution(if one exists).Regarding running time, show recursive call (Line 12)algorithm decreases R increases |C | (or both). initial call one C =hence |C | increased one (Line 10). every call, case |C |increased considered candidate c already current solution set C .case, one cannot r(v, c) = 0 since v would deleted Vpoint c added C . Hence, r(v, c) > 0 R decreased (Line 9).Since recursion ends R < 0 |C | > k (Line 2), follows recursiondepth R + k. Moreover, recursive call, one branches according R + 1possible candidates (Line 8). Hence, algorithm executed (R+1)R+k poly(n, m)time.remark results Theorem 5 also hold instance misrepresentation functions nonnegative integer values |{c C | r(v, c) R}| R + 1every voter v V . Moreover, fixed-parameter tractability already follows |{c C |r(v, c) R}| f (k, R) computable function f . contrast, branching strategyCC-MW Theorem 5 cannot directly transferred M-MW since dueM-criterion one cannot assign voter selected candidate even best alternative. means analogous approach parameter could reducedand, hence size search tree could bounded. show fixed-parameter495fiBetzler, Slinko, & Uhlmanntractability M-MW apply different approach employ structural observationsbased M-criterion.Consider instance (C, V, r, R, k) M-MW. Let zero-candidate candidate c Cr(v, c) = 0 least one voter v V .Lemma 1. yes-instance M-Multiwinner Borda misrepresentation function, R + k zero-candidates.Proof. apply proof contradiction. Assume R + k zerocandidates size-k winner set representing voters total misrepresentation R. Borda misrepresentation function, every voter v exactlyone candidate c r(v, c) = 0. c part winner set, v contributesleast one total misrepresentation since r(v, c ) 1 every c C \ {c}. SinceR + k zero-candidates, R part size-k solution.corresponding voter represented candidatesolution misrepresentation least one. Hence, total misrepresentationR; contradiction.make use bounded number zero-candidates, provide another observationexploits M-criterion solution.Lemma 2. Consider M-Multiwinner instance Borda misrepresentation function. number n voters greater (R + 1)k, every size-k set winnersconsists zero-candidates.Proof. Assume contrary (R + 1)k voters candidate csolution set represent voters misrepresentation value zero.Due M-criterion since (R + 1)k voters, c must representleast ((R + 1)k)/k = R + 1 voters misrepresentation value least one, respectively.Since bound total misrepresentation R, c cannot part solution.Based two previous lemmas, show following.Theorem 6. Borda misrepresentation function, M-Multiwinner problemfixed-parameter tractable respect composite parameter (R, k) k denotesnumber winners R misrepresentation bound.Proof. algorithm described distinguishing two cases: n (R + 1)kn > (R + 1)k. former, fixed-parameter tractability follows Proposition 1 (showing fixed-parameter tractability w.r.t. number voters). latter,yes-instance, Lemma 1 R + k zero-candidates Lemma 2solution consist zero-candidates. removing zero-candidates,fixed-parameter tractability follows Proposition 2 (showing fixed-parameter tractability w.r.t. number candidates).Regarding running time, first case leads running time ((R + 1)k)(R+1)kpoly(n, m) second case accomplished 2R+k poly(n, m) time. Hence,theorem follows.496fiOn Computation Fully Proportional RepresentationFinally, show fixed-parameter tractability respect (R, k) Minimax MMW Borda misrepresentation function. corresponding algorithm basedcase distinction algorithm M-MW (Theorem 7). basic ideabounding number zero-candidates cannot transferred M-MW MinimaxM-MW, following algorithm Minimax M-MW works also M-MW leadsworse running time bound case number voters exceeds (R + 1)k.specifically, case n > (R + 1)k, exponential running time part 4(R+1)k instead2R+k .Theorem 7. Borda misrepresentation function, Minimax M-Multiwinnerfixed-parameter tractable respect (R, k).Proof. Consider Minimax M-MW instance (C, V, r, R, k) r Borda misrepresentation function. case R = 0 trivial Minimax M-MW Bordamisrepresentation function, assume R 1 following.case n (R + 1)k, fixed-parameter tractability follows Proposition 1(analogously proof Theorem 6). Hence, consider case n > (R + 1)k.Let C := {c1 , . . . , cm } Ei := {v V | r(v, ci ) R} every ci C. Moreover,let C := {ci C : |Ei | n/k}. show that, first, every solution consistcandidates C and, second, |C | 2(R + 1)k. Then, removingcandidates C , fixed-parameter tractability follows Proposition 2.First, due M-criterion least n/k voters assigned every winning candidate solution hence candidate ci |Ei | < n/k cannot part winnerset.Second, assume toward contradiction |C | > 2(R + 1)k. Note Bordamisrepresentation functions every voter occurs R + 1 sets E1 , . . . , Em .Moreover, since |Ei | n/k every ci Cn > 2(R + 1)k n/k 1/(R + 1) > 2k(n/k 1) = 2n 2k.Since considered case n > (R + 1)k 2k, contradiction.Finally, based Proposition 2, case n > (R + 1)k, one obtains runningtime bound 4(R+1)k poly(n, m).5. Single-Peaked Electionsdiscussed introduction (Subsection 1.4), single-peakedness central notionpolitical science reflecting elections single issue dominates preferences voters.Let us formally define property.Definition 5. Let V profile set candidates C, let linear orderC (the societal axis). say order v V compatible c, d, e Ceither c e e c holdsposv (c) < posv (d) = posv (d) < posv (e).(1)(We remind reader positions counted top that, higherlinear order b, position lower.) say V single-peaked497fiBetzler, Slinko, & Uhlmann3+210c13+2+c2c31+0c4++++c1c2c3c4Figure 1: election consists three voters following preferences: c1 > c2 >c3 > c4 , c2 > c3 > c4 > c1 , c3 > c2 > c1 > c4 . single-peakednesswitnessed societal order c1 c2 c3 c4 . diagram left-handside shows, every voter, Borda score alternative getsvoter marked solid line, dashed line dotted line, respectively. Noteevery preference order one local maximum. voters expressBorda misrepresentations values instead, one obtains diagramright. Here, misrepresentation function arbitrary fixed voter onelocal minimum.respect = 1, . . . , n order vi compatible . profile V calledsingle-peaked exists linear order C V single-peaked respect; say witnesses single-peakedness V refer societalorder.Proposition 3. Let V single-peaked profile set candidates C witnessedsocietal order . Let r misrepresentation function V . every triple{ci , cj , ck } C ci cj ck ck cj ci every v Vr(v, ci ) < r(v, cj ) = r(v, cj ) r(v, ck ).Proof. definition misrepresentation function (see Definition 1) r(v, ci ) < r(v, cj )implies posv (ci ) < posv (cj ). result follows (1) Definition 1.section, investigate computational complexity determining proportionalrepresentations using Chamberlin Courant Monroe methods togethervariants, input profile single-peaked. discussed introduction,input profile single-peaked voters viewed located certain axislocation bliss point. preferred candidate either oneclosest right one closest left. Without loss generality may assumevoter bliss point location one candidates (whopreferred her).498fiOn Computation Fully Proportional Representationclear misrepresentation function r(v, c) single-peaked profile mustsatisfy following. fix voter v change c one end societal axisvalue r(v, c) decrease monotonically vs preferred candidatebliss point increase monotonically candidates beyond blisspoint. is, voter function expressing voters misrepresentationcandidates single-troughed (that is, exactly one local minimum) respectorder witnesses single-peakedness profile.describing results, briefly outline typical shapes prominentmisrepresentation functions single-peaked settings. Borda misrepresentation function strictly ascending moving away local minimum directions.Moreover, candidate preceding candidate local minimum misrepresentation function drops > 0 points, then, next 1 candidatesside local minimum, misrepresentation function must ascend size-one steps.contrast, approval misrepresentation function, exactly one intervalconsecutive candidates societal axis misrepresentation zeroremaining candidates outside interval misrepresentation one. minimaxvariants one obtains similar structure, sense one intervalparticular voter represented without exceeding given misrepresentationbound. Note remote similarity last two casespreferences intervals aggregating range values model introduced FarfelConitzer (2011).remainder section, provide following results summarized Table 2. show CC-Multiwinner, Minimax CC-Multiwinner, Minimax MMultiwinner single-peaked elections solved polynomial time arbitrarymisrepresentation function (Theorem 8, Proposition 4, Proposition 5, respectively).contrast three aforementioned problems, present reduction NP-hard version Exact 3-Cover problem shows M-Multiwinner NP-hard evenrestricted single-peaked profiles (Theorem 11). However, approval misrepresentation function, still obtain polynomial-time solvability M-Multiwinnersingle-peaked input profiles (Theorem 10). leave open computational complexityM-Multiwinner Borda misrepresentation function single-peaked case.5.1 (Minimax) CC-Multiwinnershow single-peaked input profiles CC-Multiwinner Minimax CC-Multiwinner polynomial-time solvable arbitrary misrepresentation function. firstprovide dynamic programming algorithm case CC-Multiwinner. Second,argue Minimax CC-Multiwinner solved optimally greedy algorithm.5.1.1 Dynamic Programming Procedure CC-MultiwinnerCC-Multiwinner polynomial-time solvability established presenting dynamic programming algorithm leading following.Theorem 8. single-peaked input profile arbitrary misrepresentation functionCC-Multiwinner solved O(nm2 ) time.499fiBetzler, Slinko, & Uhlmann1Function SinglePeaked-CC-MW(V , C, r, k) Input: multisetvoters V := {v1 , . . . , vn }, set candidates C := {c1 , . . . , cm },misrepresentation function r, positive integer k. voterssingle-peaked preferences according societal order ,c1 c2 . . . cm .Output: minimum total misrepresentation k winners.begin= 1, . . . ,P4z(i, 1) := vV r(v, ci );5end6p = 1, . . . ,7= p + 1,P. . . ,8d(p, i) := vV max{0, r(v, cp ) r(v, ci )};9end10end11= 2, . . . ,12j = 2, . . . , min(k, i)13z(i, j) := minp{j1,...,i1} (z(p, j 1) d(p, i));14end15end16return mini{k,...,m} (z(i, k));17 endAlgorithm 2: Dynamic programming algorithm CC-Multiwinner single-peakedinput profiles.23Proof. Throughout proof assume voters single-peaked preferencesaccording societal order , c1 c2 . . . cm . set C C,minimum total misrepresentation defineds(C ) =XvVmin {r(v, c )}.c Cdefine dynamic programming table z, containing entry z(i, j) 11 j min(i, k). Informally speaking, entry z(i, j) gives minimum totalmisrepresentation set j winners {c1 , . . . , ci } including ci .dynamic programming procedure SinglePeaked-CC-MW provided Algorithm 2.show solves CC-Multiwinner claimed running time. Regardingcorrectness, show execution SinglePeaked-CC-MW followingequation satisfiedz(i, j) = min s(C ) | C {c1 , . . . , ci } |C | = j ci C .(2)Then, minimum total misrepresentation optimal size-k winner set clearly givenmini{k,...,m} z(i, k) (see Line 16).500fiOn Computation Fully Proportional Representationproof Equation 2 follows induction j. First, argue entries z(i, 1)satisfy Equation (2), yielding base induction. end, observeone candidate ci winnerP set, voters must assigned ci , yieldingmisrepresentation sum s({ci }) = vV r(v, ci ), see Line 4.Next, show entry z(i, j) j > 1 (as computed Line 13) compliesEquation (2) provided z(p, j 1) 1 p < i. Consider set C {c1 , . . . , ci }ci C |C | = j s(C ) minimum among sets. arguez(i, j) = s(C ). Let p < cp C c 6 C p < < i.implies p j 1. crucial observation follows. voter vholds r(v, ci ) < r(v, cp ), single-peakedness implies r(v, cq ) r(v, cp ) >r(v, ci ) q < p. Hence, consider set C j 1 candidates {c1 , . . . , cp }cp C , assume value r(v, cp ) contribution voter vtotal misrepresentation s(C ). Hence, adding ci C improvementr(v, cp ) r(v, ci ) voter v r(v, cp ) > r(v, ci ). every remaining voter v,holds r(v, ci ) r(v, cp ) hence onePcannot improve representation assigningci . follows s(C ) = s(C ) vV max{0, r(v, cp ) r(v, ci )} = s(C ) d(p, i)induction assumption z(p, j 1) = s(C ). Finally, since algorithmtries possible choices p (see Line 13) z(i, j) = s(C ).straightforward verify running time Algorithm 2 O(nm2 ).5.1.2 Greedy Algorithm Minimax CC-Multiwinnersingle-peaked input profiles, minimax version CC-Multiwinner solvedsimple greedy algorithm. basic idea iterate candidates accordingsocietal order put solution first candidate votercannot represented previously selected candidates. correctness basedobservation candidate representation range (or interval)consecutive candidates voter must represented. Thus, chooselatest possible candidate represent voter representation rangeends first since candidate least good every previous candidate.words, basic combinatorial problem cover stab given set intervals(corresponding representation ranges voters) k points (correspondingcandidates). stabbing problem turn corresponds clique cover probleminterval graphs solved linear time (Golumbic, 1980). next section,investigate relationships considered voting problems special (rectangle)stabbing problems detail. Here, conclude following.Proposition 4. single-peaked input profile arbitrary misrepresentation function Minimax-CC-Multiwinner solved O(nm) time.5.2 (Minimax) M-Multiwinnerfocus case assignment candidates winner set satisfiesM-criterion, is, required winner represents numbercandidates. additional constraint makes winner determination involved. Indeed, show integer-valued misrepresentation function M-Multiwinner501fiBetzler, Slinko, & UhlmannNP-hard even input profile single-peaked. positive side, show MMultiwinner single-peaked input profiles approval misrepresentation functionMinimax M-Multiwinner arbitrary misrepresentation functions polynomialtime solvable. However, solving strategies (that also based dynamic programming) intricate (Minimax) CC-Multiwinner. proving polynomialtime solvability establish close relationship so-called 1-dimensional Rectangle Stabbing (Even et al., 2008). start polynomial-time algorithms followedNP-hardness proof. computational complexity M-MultiwinnerBorda misrepresentation function single-peaked input profiles left open.5.2.1 M-Multiwinner Approval Minimax M-Multiwinneruse notation Even et al. (2008) whenever possible. input consists set Uhorizontal intervals set vertical lines capacity c(S) {0, . . . , |U |} everyline S. Informally, task cover (or stab) intervals minimum numbervertical lines S, line covers c(S) intervals (a vertical line covershorizontal interval iff intersect). Since line cover c(S) intervals,one specify interval assigned line solution. Let U (S) denoteset intervals U intersecting S. assignment function : 2U ,A(S) U (S).set cover assignment |A(S)| c(S)SS A(S) = U .One-Dimensional Rectangle Stabbing Hard Constraints (Hard1-RS):Input: set U horizontal intervals set vertical lines capacities c(S) {0, . . . , |U |} every line S.Task: Find minimum-cardinality cover (and corresponding assignment).Now, consider single-peaked instance M-Multiwinner R = 0 everywinner represents exactly number voters, is, n mod k = 0 n votersk winners. case, problem reduced Hard-1-RS follows.every candidate vertical line according position societal axis. Sincevoter v must represented candidate c r(v, c) = 0 candidatesr(v, c) = 0 ordered consecutively societal axis, represent voterhorizontal interval reaching leftmost candidate c r(v, c) = 0rightmost candidate. Finally, vertical line associated capacity n/k,whole number. Clearly, solution M-Multiwinner instanceR = 0 size-k cover constructed instance Hard-1-RS.Note case, n mod k 6= 0, transformation cannot applied sinceone know whether candidate line capacity n/k n/k optimalsolution.Even et al. (2008) presented dynamic programming algorithm Hard-1-RSrunning time O(|U |2 |S|2 (|U | + |S|)). Since transformation describedeasily accomplished linear time, one directly obtains following.502fiOn Computation Fully Proportional RepresentationCorollary 1. instance M-Multiwinner single-peaked profile n modk = 0, R = 0 (and arbitrary misrepresentation function) solved O(n2 m2 (n+m)) time.show single-peaked input profiles, M-Multiwinner approval misrepresentation function (and arbitrary misrepresentation bound R) solved polynomial time. end, show instances reduced versionone-dimensional rectangle stabbing goal stab maximum number horizontal intervals k vertical lines. specifically, introduce following problembest knowledge studied before.Maximum Balanced One-Dimensional Rectangle Stabbing (Max-Bal1-RS):Input: multi-set U = {u1 , . . . , un } horizontal intervals, set = {S1 , . . . , Sm }vertical lines, positive integer k.Task: Find size-k set assignmentfollowing statements hold.| SS A(S)| maximum,every , |A(S)| n/k,|{S : |A(S)| = n/k}| n mod k, n mod k remainderdivision n k.last two restrictions problem description considered sayingkc = n mod k lines capacity n/k kf = k kc lines capacity n/k,specifying line capacity, Hard-1-RS specific capacityevery line. difference Max-Bal-1-RS Hard-1-RSlatter intervals must covered minimum number lines whereas formergoal cover maximum number intervals k lines.show dynamic programming algorithm Even et al. (2008) Hard-1-RSadapted work Max-Bal-1-RS. end, employ decompositionproperty (stated Observation 3 below) dynamic programming tablealgorithm different.introduce following notation state dynamic programming. interval u U , let l(u) denote left endpoint u r(u) denote right endpoint u(that is, l(u) r(u)). Let x(S) denote coordinate line S(x) denotevertical line associated coordinate x. two integers let [s, t] denote setintegers t.ease presentation, assume input following normalized formeasily established. First, assume endpoints intervalscoordinates lines integers. Second, assume {x(S) | S} = [1, m]. Third,assume endpoints intervals [1, m]. follows,distinguish line coordinate x(S), is, identify lineselements [1, m] (and vice versa). Finally, assume intervals u1 , u2 , . . . , unordered l(u1 ) l(u2 ) . . . l(un ) (we fix one ordering).algorithm makes use fact always optimal solution satisfiesleftmost interval first property defined follows (Even et al., 2008).503fiBetzler, Slinko, & UhlmannDefinition 6. Let denote size-k set lines let denote assignment.say (S , A) leftmost interval first property following holds. Letlet ui A(S). every l(ui ) < every uj uj A(S ),either j < r(uj ) < S.Note leftmost interval first property defined respect fixed orderingintervals. solution transformed equivalent one satisfyingleftmost interval first property simply swapping assignments conflicting intervalpairs, (see, e.g., Even et al., 2008). Hence, always optimal solution satisfyingleftmost interval first property one apply dynamic programming procedure basedfollowing decomposition, analogously work Even et al. (2008, Section 2).Observation 3. Let (S , A) optimal solution Max-Bal-1-RS satisfiesleftmost interval first property. range [x1 , x2 ] [1, m], let ui U earliestinterval among intervals covered line [x1 , x2 ] (that is, uj coveredlines range j > i). ui covered line [x1 , x2 ] \ {x1 }, rightendpoint intervals covered lines range [x1 , 1] left S.Basically, Observation 3 used algorithm following way. Considerrange [x1 , m] assume x1 leftmost line considered solution. Moreover,assume ui earliest interval covered line [x1 , m]. Then, everyinterval uj j < covered solution, every interval u >r(u ) < covered lines [x1 , 1], every interval urr(ur ) covered lines [S, m]. implies decompositioninstance two subinstances. left instance contains intervals ug g >r(ug ) < right instance contains intervals ud r(ud ) m.Theorem 9. Maximum Balanced One-Dimensional Rectangle Stabbingsolved O(m3 n3 k3 ) time.Proof. use following definitions state dynamic programming algorithm. Letkc := n mod k kf := k kc . ui U two coordinates x1 x2r(ui ) [x1 , x2 ], letU (ui , x1 , x2 ) := {uj U | j r(uj ) [x1 , x2 ]}.Note ui U (ui , x1 , x2 ) U = U (u1 , 1, m).algorithm maintains dynamic programming table entry(ui , x1 , x2 , kc , kf , b) Ndefined every ui U , two coordinates x1 x2 r(ui ) [x1 , x2 ]x1 ui , 0 kc kc 0 kf kf kf + kc k 1|[x1 , x2 ]| kc + kf + 1, 1 b n/k. Informally, table entry containsmaximum number intervals U (ui , x1 , x2 ) covered kc + kf + 1 lines[x1 , x2 ] assumption x1 contained solution covers bintervals, ui covered line [x1 , x2 ], kc solution lines differentx1 assigned n/k intervals. (Formally, kc + kf + 1 solution lines must satisfyconditions (C1) (C6).)504fiOn Computation Fully Proportional RepresentationNext, define subsets intervals needed decomposition left rightsubinstances. ui U , two coordinates 1 x1 x2 r(ui ) [x1 , x2 ],x [x1 , x2 ] let,x = x1Ul (ui , x, x1 , x2 ) :={uj U | j > r(uj ) [x1 , x 1]}, otherwiseUr (ui , x, x1 , x2 ) := U (ui , x1 , x2 ) \ (Ul (ui , x, x1 , x2 ) {ui }).Algorithm. state algorithm explained discussing correctnessbelow. Basically, algorithm works three phases. first phase, dynamicprogramming table initialized follows. ui U , every two coordinates x1x2 r(ui ) [x1 , x2 ], x1 ui , every integer b [1, n/k], let(ui , x1 , x2 , 0, 0, b) := min(b, |{u U (ui , x1 , x2 ) : x1 u}|).(3)second phase, table updated. update table entry (ui , x1 , x2 , kc , kf , b)provided Algorithm 3, order update invoked determinedAlgorithm 4. third phase, algorithm outputs maximum value ui Ux1 [1, . . . , m] x1 ui |[x1 , m]| k((ui , x1 , m, kc 1, kf , n/k)(4)max(ui , x1 , m, kc , kf 1, n/k).Correctness. show every stage dynamic programming entry containsvalue best assignment partial solution subinstance interval setU (ui , x1 , x2 ) six conditions (C1) (C6) hold. specifically, argueevery ui U , two coordinates x1 x2 r(ui ) [x1 , x2 ] x1 ui ,0 kc kc 0 kf kf kf + kc k 1 |[x1 , x2 ]| kc + kf + 1,1 b n/k[(ui , x1 , x2 , kc , kf , b) = max |A(S )|sets [x1 , x2 ] assignments : 2U (ui ,x1,x2 )ui A(S),(C1)|S | = kc + kf + 1 ,(C2)x1 ,(C3)|A(x1 )| b,(C4)|A(S )| n/k,(C5)|{S \ {x1 } : |A(S )| = n/k}| kc .(C6)505fiBetzler, Slinko, & Uhlmann12345678910111213Function Update(ui , x1 , x2 , kc , kf , b) begin:= 0;b > 1every uj U (ui , x1 , x2 ) \ {ui } x1 uj:= max{M, (uj , x1 , x2 , kc , kf , b 1)};endelseevery x = x1 + 1 x2 |[x , x2 ]| kc + kfevery uj U (ui , x1 , x2 ) \ {ui } x ujkc > 0:= max{M, (uj , x , x2 , kc 1, kf , n/k)};kf > 0:= max{M, (uj , x , x2 , kc , kf 1, n/k)};14151617181920212223242526272829endendevery x = x1 + 1 r(ui ) x uikcl 0 kcr 0 kcl + kcr = kckfl 0 kfr 0 kfl + kfr = kf|[x1 , x 1]| kcl + kfl + 1 |[x, x2 ]| kcr + kfrMl , Mr := 0;every uj Ul (ui , x, x1 , x2 ) x1 ujMl := max{Ml , (uj , x1 , x 1, kcl , kfl , b)};endevery uj Ur (ui , x, x1 , x2 ) x ujkcr > 0Mr := max{Mr , (uj , x, x2 , kcr 1, kfr , n/k 1)};kfr > 0Mr := max{Mr , (uj , x, x2 , kcr , kfr 1, n/k 1)};30end32:= max{M, Ml + Mr };33end34end35end36end37(ui , x1 , x2 , kc , kf , b) := + 1;38 endAlgorithm 3: Update step employed dynamic programming algorithm MaxBal-1-RS presented proof Theorem 9.31506fiOn Computation Fully Proportional Representation1234567891011121314Main :[x1 , x2 ] [1, m] increasing order x2 x1kc = 0, . . . , kckf = 0, . . . , kf|[x1 , x2 ]| kc + kf + 1 1 kc + kf k 1b = 1, . . . , n/kui U r(ui ) [x1 , x2 ] x1 ui(ui , x1 , x2 , kc , kf , b) := Update(ui , x1 , x2 , kc , kf , b);endendendendendendAlgorithm 4: Main loop initialization.every entry computed initialization step (Equation 3), algorithm storesmaximum value partial solution = {x1 } (satisfies (C2) (C3)), covers ui(C1) (which possible since x1 ui b 1), satisfies |A(x1 )| b (C4). Clearly,(C5) (C6) hold well.Regarding update step (see Algorithm 3), let us assume values entriesaccessed update correct well-defined (discussed below). ensure (C1) entry (ui , x1 , x2 , kc , kf , b), interval ui must covered one lines[x1 , x2 ]. argue possibilities hold conditions C1 - C6 considered systematically current maximum value stored variable .going details, observe Algorithm 3 adds one overall maximumvalue (Line 37) take account ui newly covered. correctleast one possibility cover ui considered interval, namely, x1always cover u1 since x1 ui (Line 7 Algorithm 4) b 1 (Line 6 Algorithm 4).Lines 3 16 Algorithm 3 consider possibility x1 used cover ui . Here,two possibilities distinguished. first investigated possibility (Line 3 Line 7Algorithm 3) ui covered x1 x1 cover least one interval,is, b > 1. case, compute optimal value based valuesubinstance containing ui x1 solution assignedone interval less. end, b decreased one (that is, (C4) holds) possibleintervals U (ui , x1 , x2 ) \ {ui } (Line 4) checked leftmost covered intervalcorresponding subsolution. Moreover, since kf kc remain assumeconditions (C2), (C5), (C6) hold (uj , x1 , x2 , kc , kf , b 1), also hold(ui , x1 , x2 , kc , kf , b).second investigated possibility (Lines 7 16 Algorithm 3) ui coveredx1 x1 cover one interval, is, b = 1. case traced backsubinstance without ui x1 . access corresponding possibilitiesdynamic programming table, Algorithm 3 tries possible lines new solution lines(Line 8) leftmost intervals covered new subinstance (Line 9). Then,507fiBetzler, Slinko, & Uhlmannchooses maximum assigning capacity n/k (Line 11) n/k (Line 13)x . Note since 1 kc + kf (Line 5 Algorithm 4) least one two cases mustpossible (if least one interval covered, is, U (ui , x1 , x2 ) \{ui } =6 ). Assume solution corresponding table entry (uj , x , x2 , kc1, kf , n/k)} (Line 11) (uj , x , x2 , kc , kf 1, n/k)} (Line 13), respectively, hence,fulfilling conditions (C1) (C6) corresponding subinstance. Then, clearlyadding x1 solution assigning ui x1 gives solution fulfilling constraints(ui , x1 , x2 , kc , kf , b) b = 1.following loop Algorithm 3 (Lines 17 37) tries possibilities cover uiline x 6= x1 . x 6= x1 , according Observation 3, instance dividedtwo subinstances. combinations sizes subsolutions tested iteratingkcl , kcr , kfl , kfr (Lines 18 19). Lines 22 23 Algorithm 3 computesoptimal solution left subinstance Lines 25 29 computes solutionright subinstance obtained assigning ui x. decompositionsubinstances defined interval sets Ur (ui , x, x1 , x2 ) Ul (ui , x, x1 , x2 ) follows directlyObservation 3. Moreover, since x1 part left subinstance unchangedcapacity bound b, conditions (C1), (C3) (C4) hold. remains show (C2),(C5) (C6) hold, is, addition x1 considered subsolution consists kc linesassigned n/k intervals kf lines assigned n/kintervals. considered possibility, x newly specified solution lineaccording decomposition (see Observation 3 definitions Ul , Ur ) partright subinstance. Lines 27 29, Algorithm 3 chooses maximumpossibilities x assigned n/k n/k intervals, respectively,adapts values kcr kfr accordingly accessing corresponding table entries.Hence, conditions hold.Now, consider output overall algorithm, see Equation (4). first maximumfunction iterates intervals ui possible leftmost solution lines hence findpair ui x1 follows. interval ui leftmost interval covered solutionleftmost interval first property x1 leftmost line considered solution.Then, second maximum function chooses maximum two cases x1assigned n/k n/k intervals, respectively. Since(C1) (C6) holdcorresponding entries, algorithm outputs maximum | SS A(S)| overall [1, m]corresponding assignments fulfilling constraints definition MaxBal-1RS.remains show algorithm accesses well-defined entries, is,accessed entries computed before. ensured iterating dynamic programming table described Algorithm 4. Regarding computation(uj , x1 , x2 , kc , kf , b 1) Line 5 Algorithm 3, parameters values except bcurrent entry. Line 6 Algorithm 4 iterates b increasing orderand, hence, (uj , x1 , x2 , kc , kf , b 1) computed accessed. Moreover,condition b > 1 Line 3 Algorithm 3 ensures (uj , x1 , x2 , kc , kf , b 1) welldefined. Lines 11 13 Algorithm 3, accessed range [x , x2 ] smallerrange x1 x2 . Since algorithm iterates ranges according increasing size(Line 2 Algorithm 4) parameter values also considered formeriteration loops, entry computed before. Line 23 Algorithm 3 accessed508fiOn Computation Fully Proportional Representationentry range x1 x 1 < x2 Lines 27, 29 considered range [x, x2 ]also strictly smaller range [x1 , x2 ]. Again, according Line 2 Algorithm 4),entries computed before.Running time. Regarding running time, update accomplished O(mk2 n)time (see Algorithm 3) iterating coordinates lines (Line 17),less k2 cases Lines 18 19, less n intervals inner loopsLines 5, 22, 25, respectively. overall loop (Algorithm 4) gives additional factorO(m2 n2 k): appropriate implementation accomplished iteratingless m2 coordinate ranges (Line 2), less k2 possibilities Lines 4 3, n/k(n + 1)/k values b (Line 6), n intervals Line 7. yields runningtime bound O(m2 k(n + 1)n) = O(m2 n2 k). Hence, overall running time boundedO(n3 k3 m3 ).instance single-peaked input profile M-Multiwinner approvalmisrepresentation function reduces Max-Bal-1-RS transformation described Section 5.2.1. vertical line every candidate, horizontal intervalvoter v reaching leftmost candidate r(v, c) = 0 rightmostcandidate. crucial observation is, minimizing total misrepresentationM-Multiwinner equivalent maximizing number voters representedcandidates misrepresentation zero and, hence, maximizing number coveredintervals Max-Bal-1-RS instance. Altogether, arrive main resultsection.Theorem 10. M-Multiwinner approval misrepresentation function singlepeaked input profiles decided O(n3 m3 k3 ) time.Recall instance Minimax M-Multiwinner R > 0 reducedinstance M-Multiwinner R = 0 approval misrepresentation functionsetting voter v candidate c misrepresentation value 0, r(v, c) R,1 otherwise (see Observations 1 2). Altogether, arrive following.Proposition 5. instance Minimax M-Multiwinner single-peaked profile(and arbitrary misrepresentation function) solved O(n3 m3 k3 ) time.5.2.2 NP-Hardness M-Multiwinner Single-Peaked ElectionContrasting polynomial-time solvability results three considered problems, show integer-valued misrepresentation function MMultiwinner NP-complete even restricted instances single-peaked input profile. specifically, show M-Multiwinner NP-hard single-peaked inputprofiles integer-valued misrepresentation functions maximum misrepresentation value voter bounded polynomial number candidates.Note establishing NP-hardness allow voter assignmisrepresentation value several candidates.NP-hardness follows reduction restricted variant Exact 3-Cover.Restricted Exact 3-Cover (rX3C)Input: family := {S1 , . . . , Sm } sets elements E := {e1 , . . . , en }509fiBetzler, Slinko, & Uhlmannevery set size 3 every element E occurs exactly threesets.Question: subsetevery element E occursexactly one set SS = E?set called exact 3-cover E. Since yes-instances n multiple3, follows assume n divisible 3. NP-hardness rX3C followsNP-hardness reduction case every element occurs threesubsets (Garey & Johnson, 1979) construction extend NP-hardness resultcase every element occurs exactly three subsets (Gonzalez, 1985).Theorem 11. M-Multiwinner NP-hard single-peaked input profiles integervalued misrepresentation function even maximum misrepresentation value everyvoter polynomial number candidates (and every winner represents exactly threevoters).Proof. use following notation. Consider rX3C instance (S, E). elemente E occurs three subsets Si , Sj , Sk < j < k, say firstoccurrence e Si , second occurrence Sj , third occurrence Sk .rX3C instance (S, E), define M-MW instance follows. set candidatesC := E {sj | Sj S}multiset votersV := {vix | ei E x {1, 2, 3}} {fi | ei E}.is, candidate element subset four voterselement. Next, specify misrepresentation functions voters:{1, . . . , n}{1, . . . , n}, c C \ {ei }{1, . . . , n}, x {1, 2, 3}, 1 z{1, . . . , n}, x {1, 2, 3}, z >1 j m, x {1, 2, 3}, xth occurrence ei Sjelser(fi , ei ) := 0r(fi , c) := 2n2 + 1r(vix , ez ) := + z 1r(vix , ez ) := 2n2 + 1r(vix , sj ) := 0r(vix , sj ) := 1Finally, set misrepresentation bound R := 2n2 let number winnersk := n/3 + n. showing correctness reduction, discuss three crucialproperties construction.First, verify profile single-peaked witnessed societal orders1 sm e1 en .every voter fi single-peakedness obvious since misrepresentation 0 onecandidate 2n2 + 1 every candidate. every vix , within candidate set E,misrepresentation function decreases monotonously move en e1 alongsocietal axis: z > i, obvious since misrepresentation remains constantvalue 2n2 +1 z misrepresentation value i+z 1 hence function510fiOn Computation Fully Proportional Representationclearly assumes smaller values decreasing values z. settles single-peakednessrange e1 en . see overall single-peakedness, first note e1misrepresentation every vix least 1. Then, since misrepresentation 1one candidates {s1 , . . . , sm } 0 remaining candidates,single-peakedness every vix follows.Second, since 4n voters k = (4n)/3, exactly three votersassigned every winning candidate solution.Third, show four voters best represented candidate eifi , vi1 , vi2 , vi3 . specifically, show following.Observation 4. every ei x {1, 2, 3}, r(vix , ei ) < r(y, ei ) every V \({fi }{vi1 } {vi2 } {vi3 }).see correctness, observe every fixed {1, . . . , n}, r(vax , ea ) = 2a 1every x {1, 2, 3}1 b < a, r(vbx , ea ) = 2n2 + 1 > 2a 1 ,< b n, r(vbx , ea ) = + b 1 > 2a 1,b 6= a, r(fb , ea ) = 2n2 1 > 2a 1.Now, show following.Claim: exact 3-cover (S, E) setk = 4n/3 candidates represent voters total misrepresentationR = 2n2 exactly three voters assigned one candidate.Given exact 3-cover S, show set {sj | Sj } E candidateswinning set required claim. corresponding mapping follows.every 1 n, voter fi assigned candidate ei .1 n x {1, 2, 3}, ei occurs xth time Sj , vixassigned sj , else vix assigned ei .Since exact 3-cover every element covered exactly once, follows every voterassigned exactly one candidate every winning candidate represents three voters.specifically, three voters vi1 , vi2 , vi3 corresponding three occurrenceselement ei , one represented candidate corresponding solutionset ei occurs two voters candidate ei (the third candidaterepresented ei fi ). remains compute total misrepresentation solution.Due definition, every candidate sj represents three voters misrepresentation0. Moreover, every candidate ei represents fi misrepresentation 0 two voters{vi1 , vi2 , vi3 } misrepresentation r(vix , ei ) = + 1 = 2i 1 x {1, 2, 3}. Hence,total misrepresentationnX2(2i 1) = 2n(n + 1) 2n = 2n2 .i=1511(5)fiBetzler, Slinko, & UhlmannConsider size-k set C C winners represent voters total misrepresentation R = 2n2 . Since every voter fi , candidate represent fimisrepresentation R ei , follows E C . Recall due M-criterion,every candidate must represent exactly three voters. Thus, every candidate ei E mustrepresent two voters (besides fi ). Clearly, lower bound total misrepresentation achieved case assign every ei E two votersrepresented ei least good voters. Due Observation 4, two voters{vi1 , vi2 , vi3 }. Moreover, according Equation 5 corresponding lower boundtotal misrepresentation matches total misrepresentation R = 2n2 . Since assigningei voter {vi1 , vi2 , vi3 } would lead strictly higher misrepresentation (Observation 4), implies ei assigned exactly two voters {vi1 , vi2 , vi3 }. Finally,every 1 n, remains one voter vix must represented candidateC \ E misrepresentation zero. Since |C \ E| = n/3 candidate sjrepresent voter vix misrepresentation 0 element ei occurs Sj , i.e., setscorresponding candidates C \ E must form exact 3-cover.6. Conclusion Outlookstart summarizing relevance results work. followeddiscussion closely related problems models might investigated futureresearch. conclude several questions directly follow results.6.1 Relevance Resultscomputation set candidates fully proportionally represent societyapplications many relevant settings. main problem suggested approachesextant literature corresponding combinatorial problems NP-hard,is, cannot solved efficiently general. raises question whetherapproaches despite theoretically proven advantages (see, e.g., detailed discussionBrams, 2008) useless practice.One approach course try escape high complexity modifying conceptkeeping still meaningful. regard tried change way totalmisrepresentation calculated taking minimax (or Rawlsian) approach. appearedhelp general caseall problems remain computationally hardhowever,partially helped single-peaked elections: classical Monroe scheme remainsNP-hard, minimax version solved polynomial time.general, several ways deal NP-hard problems. example, NPhardness based worst-case analysis hence one might able develop algorithms work efficiently instances. However, although unlikely, still mighthappen outcome election leads hard instance. Then, would leadsituation political impasse unpredictable consequences.Another common approach tackle NP-hard problems invoke approximation algorithms. scenarios like context resource allocation sharableitems nearly optimal solution might sufficient approximation algorithms meaningful (Lu & Boutilier, 2011; Skowron, Faliszewski, & Slinko, 2012); scenarios, likepolitical elections, use approximation algorithms hard imagine. voting rule512fiOn Computation Fully Proportional Representationconstitutional matter: whatever is, must adhered to. current legislationcandidate party ask recount and, approximation voting ruleused, may require using another approximation argue give betterrepresentation. hard imagine prolonged court proceedings matters.Based previous discussion, seems clearly desirable identify well-specifiedsettings optimal solution computed efficiently. extendapplicability fully proportional representation settings. regard,conducted investigation two different directions. first class settingsparameters small (parameterized complexity analysis). second approachrestrict attention single-peaked domains.Regarding parameterized complexity four studied problems, results negative (see Table 1). particular, natural well-motivated parameternumber winners, corresponding problems turned W[2]-complete. If,however, addition winner set represent voters small totalmisrepresentation, three four problems become tractable Borda misrepresentation function. Moreover, fixed-parameter tractability results respectnumber voters number candidates, respectively, useful restrictedsettings.Regarding single-peaked elections, almost results positive comepolynomial-time algorithms (see Table 2). possible critique approach claimsingle-peakedness way idealized model robust enough. smallesthonest mistake voter filling ballot may result election becoming singlepeaked. Also may secondary issue election also importantvoters may lead election almost single-peaked exactly singlepeaked. regard would interesting investigate difficult find singlepeaked profile closest given one. one might employ techniques socalled distance rationalizability approach (Baigent, 1987; Meskanen & Nurmi, 2008; Elkind,Faliszewski, & Slinko, 2010a; Elkind et al., 2010b). thus surprising near singlepeakedness starting active area research (Faliszewski, Hemaspaandra,& Hemaspaandra, 2011; Erdelyi, Lackner, & Pfandler, 2012). Since algorithms showpolynomial-time solvability important basic case single-peakedness, mightbasis developing efficient algorithms extended settings.Summarizing, work contributes important topic making fully proportionalrepresentation ideas practical complements analysis method PotthofBrams (1998), Procaccia et al. (2008) Lu Boutilier (2011).6.2 Related Problems Scenariosconcluding work several open questions, we, first, describe relationsconsidered problems facility location problems and, second, describe reasonablealternative multi-winner model. topics might also lead interesting questionsfuture research.513fiBetzler, Slinko, & Uhlmann6.2.1 Relations Facility Location.basic scenario problem company needs choose set facility locationsserve set customers little cost possible. Fellows Fernau (2011)investigated parameterized complexity variant problem closely relatedCC-Multiwinner. Basically, facility locations considered setcandidates, customers multiset voters goal find set facilitylocations serve customers. difference cost function: additionterm resembles misrepresentation every voter (customer), every facilitylocation comes certain cost required install facility.Similar study, Fellows Fernau (2011) studied parameter number kwinners/selected facilities locations total cost. parameter k, W[2]-hardnessCC-Multiwinner follows reduction given facility location problem.Regarding parameter total cost, results two papers directly comparable. due fact facility location problem stipulatesminimum cost 1 serving customer even best facility location (whichwould analogue condition r(v, c) 1 misrepresentation function r).case, considered problem fixed-parameter tractable respect totalcost. might come surprise since total cost/misrepresentationleast number voters fixed-parameter tractability respect parameterholds four voting problems considered (Proposition 2). contrast,condition r(v, c) 0 considered problems least W[2]-hard respecttotal misrepresentation/cost (see Table 1).close connection facility location multi-winner problems clearly seemsdeserve attention future work. remark analogues several problemsconsidered work might also make sense context facility location problem.example, Monroe model might apply sets facilities every facilityserve number customers. Moreover, single-peaked scenario translates,example, setting potential facility locations along one main streetresident ranks cost using facility according distance facilityplace residence.6.2.2 Multiset Candidates Model.may compromise solution two systems Chamberlin CourantMonroe. may still divide voters equal almost equal groups may assignrepresentative one group voters. Say, n voters krepresentatives elected may split voters groups sizes n/k n/k+1allow candidate represent one group. Mathematically wouldresult selecting set representatives cardinality k multisetcardinality. classic Monroe (1995) example considers subscription newspaperscommon room fact better fit multiset model. Indeed, demand, sayFinancial Times, strong several copies newspaper subscribed to.still need use weighted voting assembly case weightsintegers.514fiOn Computation Fully Proportional Representationillustrate difference let us consider six people electing representative assemblythree. Suppose candidates must come set = {a, b, c, d} preferencesvoters follows:4bc2cbset variant Monroe scheme give us set representatives {a, b, c}multiset point view natural multiset {a2 , c} answercould interpreted mean two votes given one c. multiset pointview seems natural here, indeed, b seem represent anybody nicely.misrepresentation nonzero set version zero multiset one.far know computational complexity computation winnermultiset model unstudied far. first glance, seems conceivable computational complexity multiset model lies complexity CC-MultiwinnerM-Multiwinner. leads interesting questions whether set winnersaccording multiset model computed polynomial time electoratesingle peaked.6.3 Open QuestionsSeveral questions arise work.CC- M-Multiwinner Borda misrepresentation function provided algorithms showing polynomial-time solvability constant misrepresentationbound R. problems fixed-parameter tractable respect R?Minimax M-Multiwinner Borda misrepresentation function fixed-parametertractable respect composite parameter (R, k)?M-Multiwinner single-peaked elections shown NP-hardnessinteger-valued misrepresentation functions. problem fixed-parameter tractablerespect number winners k or/and respect misrepresentationbound R?M-Multiwinner Borda misrepresentation function polynomial-time solvable single-peaked instances?results single-peaked elections extended generalized single-peakedness(e.g., defined Nehring & Puppe, 2007) almost single-peaked profiles (insense)? might particular interest problem finding closest single-peaked profile given one would turn polynomial-time solvable(for distance set profiles).515fiBetzler, Slinko, & Uhlmann7. Acknowledgmentswork done Nadja Betzler stayed research visit UniversityAuckland. visit funded fellowship Deutscher Akademischer AustauschDienst (DAAD). Johannes Uhlmann partially supported DFG, project PAWSNI-931/10.grateful referees whose careful thoughtful reading significantlyimproved paper. Moreover, like thank Steven Brams interest workvaluable discussions Rolf Niedermeier useful comments support.ReferencesAhuja, R. K., Magnanti, T. L., & Orlin, J. B. (1993). Network Flows: Theory, Algorithms,Applications. Prentice Hall.Baigent, N. (1987). Metric rationalisation social choice functions according principlessocial choice. Mathematical Social Sciences, 13 (1), 5965.Bartholdi III, J. J., Tovey, C. A., & Trick, M. A. (1989). computational difficultymanipulating election. Social Choice Welfare, 6, 227241.Betzler, N., Bredereck, R., Chen, J., & Niedermeier, R. (2012). Studies computationalaspects voting - parameterized complexity perspective. Multivariate Algorithmic Revolution Beyond, Vol. 7370 Lecture Notes Computer Science,pp. 318363. Springer.Betzler, N., Guo, J., & Niedermeier, R. (2010). Parameterized computational complexityDodgson Young elections. Information Computation, 208 (2), 165177.Betzler, N., Hemmann, S., & Niedermeier, R. (2009). multivariate complexity analysisdetermining possible winners given incomplete votes. Proceedings 21stInternational Joint Conference Artificial Intelligence (IJCAI), pp. 5358.Black, D. (1958). Theory Committees Elections. Cambridge University Press.Booth, E., & Lueker, G. (1976). Testing consecutive ones property, interval graphs,graph planarity using PQ-trees algorithms. Journal Computer SystemSciences, 13, 335379.Brams, S. (2008). Mathematics Democracy. Princeton University Press.Brams, S., & Fishburn, P. (2002). Voting procedures. Arrow, K., Sen, A. K., & Suzumura,K. (Eds.), Handbook Social Choice Welfare, Vol. 1, pp. 173236. Elsevier.Brandt, F., Brill, M., & Seedig, H. G. (2011). fixed-parameter tractabilitycomposition-consistent tournament solutions. Proceedings 22nd InternationalJoint Conference Artificial Intelligence (IJCAI), pp. 8590. AAAI Press.Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. A. (2010). Bypassing combinatorial protections: Polynomial-time algorithms single-peaked electorates.Proceedings 24th AAAI Conference Artificial Intelligence (AAAI), pp. 715722.516fiOn Computation Fully Proportional RepresentationChamberlin, J. R., & Courant, P. N. (1983). Representative deliberations representativedecisions: Proportional representation Borda rule. American Political ScienceReview, 77 (3), 718733.Christian, R., Fellows, M. R., Rosamond, F. A., & Slinko, A. (2007). complexitylobbying multiple referenda. Review Economic Design, 11 (3), 217224.Conitzer, V. (2009). Eliciting single-peaked preferences using comparison queries. JournalArtificial Intelligence Research, 35, 161191.Conitzer, V. (2010). Making decisions based preferences multiple agents. Communications ACM, 53 (3), 8494.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms(2nd edition). MIT Press.Dodgson, C. (1884). Principles Parliamentary Representation. Harrison, London.Dorn, B., & Schlotter, I. (2010). Multivariate complexity analysis swap bribery.Proceedings 5th International Symposium Parameterized Exact Computation (IPEC), Vol. 6478 LNCS, pp. 107122. Springer.Downey, R. G., & Fellows, M. R. (1999). Parameterized Complexity. Springer.Elkind, E., Faliszewski, P., & Slinko, A. (2010a). Cloning elections. Proceedings24th AAAI Conference Artificial Intelligence (AAAI), pp. 768773.Elkind, E., Faliszewski, P., & Slinko, A. (2010b). role distances defining votingrules. Proceedings 9th International Conference Autonomous AgentsMultiagent Systems (AAMAS), pp. 375382.Erdelyi, G., Lackner, M., & Pfandler, A. (2012). complexity nearly single-peakedconsistency. Proceedings 4th International Workshop Computational Social Choice (COMSOC 2012), pp. 179190.Escoffier, B., Lang, J., & Ozturk, M. (2008). Single-peaked consistency complexity.Proceedings 18th European Conference Artificial Intelligence (ECAI), pp.366370. IOS Press.Even, G., Levi, R., Rawitz, D., Schieber, B., Shahar, S., & Sviridenko, M. (2008). Algorithms capacitated rectangle stabbing lot sizing joint set-up costs. ACMTransactions Algorithms, 4 (3), 34:134:17.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. A. (2010). Using complexityprotext elections. Communications ACM, 53 (1), 7482.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L. A., & Rothe, J. (2009a). LlullCopeland voting computationally resist bribery constructive control. JournalArtificial Intelligence Research, 35, 275341.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L. A., & Rothe, J. (2009b). richerunderstanding complexity election systems. Ravi, S., & Shukla, S.(Eds.), Fundamental Problems Computing: Essays Honor Professor DanielJ. Rosenkrantz, chap. 14, pp. 375406. Springer.517fiBetzler, Slinko, & UhlmannFaliszewski, P., & Procaccia, A. (2010). AIs war manipulation: winning?. AIMagazine, 31 (4), 5364.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. A. (2011). complexitymanipulative attacks nearly single-peaked electorates. Proceedings 13thConference Theoretical Aspects Rationality Knowledge, TARK XIII, pp.228237, New York, NY, USA. ACM.Farfel, J., & Conitzer, V. (2011). Aggregating value ranges: Preference elicitationtruthfulness. Journal Autonomous Agents Multi-Agent Systems, 22 (1), 127150.Fellows, M. R., & Fernau, H. (2011). Facility location problems: parameterized view.Discrete Applied Mathematics, 159 (11), 11181130.Flum, J., & Grohe, M. (2006). Parameterized Complexity Theory. Springer.Fredman, M. L., & Tarjan, R. E. (1987). Fibonacci heaps uses improved networkoptimization algorithms. Journal ACM, 34 (3), 596615.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-Completeness. W. H. Freeman.Garey, M. R., Johnson, D. S., & Stockmeyer, L. (1974). simplified NP-completeproblems. Proceedings sixth annual ACM symposium Theory computing(STOC), pp. 4763. ACM.Golumbic, M. (1980). Algorithmic Graph Theory Perfect Graphs. Academic Press.Gonzalez, T. F. (1985). Clustering minimize maximum intercluster distance. Theoretical Computer Science, 38, 293306.Harsanyi, J. (1995). maximin principle serve basis morality? critiqueJohn Rawlss theory. American Political Science Review, 69 (2), 594606.Impagliazzo, R., Paturi, R., & Zane, F. (2001). problems strongly exponentialcomplexity?. Journal Computer System Sciences, 63 (4), 512530.Levin, J., & Nalebuff, B. (1995). introduction vote-counting schemes. JournalEconomic Perspectives, 9 (1), 326.Lu, T., & Boutilier, C. (2011). Budgeted social choice: consensus personalizeddecision making. Proceedings Twenty-second International Joint ConferenceArtificial Intelligence (IJCAI-11), pp. 280286. Also presented COMSOC-10.Meir, R., Procaccia, A. D., Rosenschein, J. S., & Zohar, A. (2008). complexity strategic behavior multi-winner elections. Journal Artificial Intelligence Research, 33,149178.Meskanen, T., & Nurmi, H. (2008). Closeness counts social choice. Braham, M., &Steffen, F. (Eds.), Power, Freedom, Voting, pp. 289306. Springer.Monroe, B. L. (1995). Fully proportial representation. American Political Science Review,89 (4), 925940.Moulin, H. (1991). Axioms Cooperative Decision Making. Cambridge University Press.518fiOn Computation Fully Proportional RepresentationNehring, K., & Puppe, C. (2007). structure strategy-proof social choice Part I: General characterization possibility results median spaces. Journal EconomicTheory, 135 (1), 269305.Niedermeier, R. (2006). Invitation Fixed-Parameter Algorithms. Oxford University Press.Penrose, L. (1946). elementary statistics majority voting. Journal RoyalStatistical Society, 109, 5357.Potthof, R. F., & Brams, S. J. (1998). Proportional representation: Broadening options.Journal Theoretical Politics, 10 (2), 147178.Procaccia, A. D., Rosenschein, J. S., & Zohar, A. (2007). Multi-winner elections: Complexity manipulation, control winner-determination. Proceedings 20thInternational Joint Conference Artificial Intelligence (IJCAI), pp. 14761481.Procaccia, A. D., Rosenschein, J. S., & Zohar, A. (2008). complexity achievingproportional representation. Social Choice Welfare, 30, 353362.Rawls, J. (1999). Theory Justice. Cambridge: Harvard University Press, 1971, RevisedEdition (Cambridge: Harvard University Press).Skowron, P., Faliszewski, P., & Slinko, A. M. (2012). Proportional representation resourceallocation: Approximability results. CoRR, abs/1208.1661.Slomczynski, W., & Zyczkowski, K. (2006). Penrose voting system optimal quota. ActaPhysica Polonica, B 37 (11), 31333143.Tideman, N., & Richardson, R. (2000). Better voting methods technology:refinement-manageability trade-off single transferable vote. Public Choice,103 (1-2), 1334.Tideman, N. (2006). Collective Decisions Voting. Ashgate Publishing Ltd.519fiJournal Artificial Intelligence Research 47 (2013) 1-34Submitted 10/2012; published 05/2013Feature Subset Selection Algorithm AutomaticRecommendation MethodGuangtao WangQinbao SongHeli SunXueying Zhanggt.wang@stu.xjtu.edu.cnqbsong@mail.xjtu.edu.cnhlsun@mail.xjtu.edu.cnzhangxueying.725@stu.xjtu.edu.cnDepartment Computer Science & Technology,Xian Jiaotong University, 710049, ChinaBaowen XuYuming Zhoubwxu@nju.edu.cnzhouyuming@nju.edu.cnDepartment Computer Science & Technology,Nanjing University, ChinaAbstractMany feature subset selection (FSS) algorithms proposed,appropriate given feature selection problem. time, farrarely good way choose appropriate FSS algorithms problem hand. Thus,FSS algorithm automatic recommendation important practically useful.paper, meta learning based FSS algorithm automatic recommendation methodpresented. proposed method first identifies data sets similarone hand k -nearest neighbor classification algorithm, distances amongdata sets calculated based commonly-used data set characteristics. Then,ranks candidate FSS algorithms according performance similardata sets, chooses algorithms best performance appropriate ones.performance candidate FSS algorithms evaluated multi-criteria metrictakes account classification accuracy selected features,also runtime feature selection number selected features. proposedrecommendation method extensively tested 115 real world data sets 22 wellknown frequently-used different FSS algorithms five representative classifiers.results show effectiveness proposed FSS algorithm recommendation method.1. IntroductionFeature subset selection (FSS) plays important role fields data miningmachine learning. good FSS algorithm effectively remove irrelevant redundantfeatures take account feature interaction. leads insightunderstanding data, also improves performance learner enhancinggeneralization capacity interpretability learning model (Pudil, Novovicova,Somol, & Vrnata, 1998a; Pudil, Novovicova, Somol, & Vrnata, 1998b; Molina, Belanche,& Nebot, 2002; Guyon & Elisseeff, 2003; Saeys, Inza, & Larranaga, 2007; Liu & Yu, 2005;Liu, Motoda, Setiono, & Zhao, 2010).c2013AI Access Foundation. rights reserved.fiWang, Song, Sun, Zhang, Xu & ZhouAlthough large number FSS algorithms proposed, singlealgorithm performs uniformly well feature selection problems. Experiments(Hall, 1999; Zhao & Liu, 2007) confirmed could exist significant differencesperformance (e.g., classification accuracy) among different FSS algorithms givendata set. means given data set, FSS algorithms outperform others.raises practical important question: FSS algorithmspicked given data set? common solution apply candidate FSS algorithms given data set, choose one best performance crossvalidation strategy. However, solution quite time-consuming especially highdimensional data (Brodley, 1993).purpose addressing problem efficient way, paper, FSSalgorithm automatic recommendation method proposed. assumption underlyingproposed method performance FSS algorithm data set relatedcharacteristics data set. rationality assumption demonstratedfollows:1) Generally, new FSS algorithm proposed, performance needs extensively evaluated least real world data sets. However, published FSS algorithmsrarely tested identical group data sets (Hall, 1999; Zhao & Liu, 2007; Yu &Liu, 2003; Dash & Liu, 2003; Kononenko, 1994). is, two algorithms,usually tested different data. implies performance FSSalgorithm biases data sets.2) time, famous NFL (No Free Lunch) (Wolpert, 2001) theory tells usthat, particular data set, different algorithms different data-conditioned performance, performance differences vary data sets.evidences imply relationship performanceFSS algorithm characteristics data sets. paper, intend explorerelationship utilize automatically recommend appropriate FSS algorithm(s)given data set. recommendation process viewed specific applicationmeta-learning (Vilalta & Drissi, 2002; Brazdil, Carrier, Soares, & Vilalta, 2008)used recommend algorithms classification problems (Ali & Smith, 2006; King,Feng, & Sutherland, 1995; Brazdil, Soares, & Da Costa, 2003; Kalousis, Gama, & Hilario,2004; Smith-Miles, 2008; Song, Wang, & Wang, 2012).model relationship, three fundamental issues considered: i)features (often referred meta-features) used characterize data set; ii)evaluate performance FSS algorithm identify applicable one(s)given data set; iii) recommend FSS algorithm(s) new data set.paper, meta-features, frequently used meta-learning (Vilalta &Drissi, 2002; Ali & Smith, 2006; King et al., 1995; Brazdil et al., 2003; Castiello, Castellano,& Fanelli, 2005), employed characterize data sets. time, multi-criteriametric, takes account classification accuracy classifierFSS algorithm also runtime feature selection number selected features,used evaluate performance FSS algorithm. Meanwhile, k -NN (k -NearestNeighbor) based method proposed recommend FSS algorithm(s) new data set.2fiSubset Selection Algorithm Automatic Recommendationproposed FSS algorithm recommendation method extensively tested115 real world data sets 22 well-known frequently-used different FSS algorithmsfive representative classifiers. results show effectiveness proposed recommendation method.rest paper organized follows. Section 2 introduces preliminaries.Section 3 describes proposed FSS algorithm recommendation method. Section 4 provides experimental results. Section 5 conducts sensitivity analysis numbernearest data sets recommendation results. Finally, section 6 summarizeswork draws conclusions.2. Preliminariessection, first describe meta-features used characterize data sets. Then,introduce multi-criteria evaluation metric used measure performance FSSalgorithms.2.1 Meta-features Data Setsproposed FSS algorithm recommendation method based relationshipperformance FSS algorithms meta-features data sets.recommendation viewed data mining problem, performanceFSS algorithms meta-features target function input variables,respectively. Due ubiquity Garbage In, Garbage (Lee, Lu, Ling, & Ko, 1999)field data mining, selection meta-features crucial proposedFSS recommendation method.meta-features measures extracted data sets useduniformly characterize different data sets, underlying properties reflected.meta-features conveniently efficiently calculated, also relatedperformance machine learning algorithms (Castiello et al., 2005).15 years research study improve meta-features proposedStatLog project (Michie, Spiegelhalter, & Taylor, 1994). number meta-featuresemployed characterize data sets (Brazdil et al., 2003; Castiello et al., 2005;Michie et al., 1994; Engels & Theusinger, 1998; Gama & Brazdil, 1995; Lindner & Studer,1999; Sohn, 1999), demonstrated working well modeling relationshipcharacteristics data sets performance (e.g., classification accuracy)learning algorithms (Ali & Smith, 2006; King et al., 1995; Brazdil et al., 2003; Kalousis et al.,2004; Smith-Miles, 2008). meta-features characterize data sets themselves,connection learning algorithms types, use modelrelationship data sets FSS algorithms.commonly used meta-features established focusing following threeaspects data set: i) general properties, ii) statistic-based properties, iii) informationtheoretic based properties (Castiello et al., 2005). Table 11 shows details.1. order compute information-theoretic features, data sets continuous-valued features,needed, well-known MDL (Minimum Description Length) method Fayyad & Irani criterionused discretize continuous values.3fiWang, Song, Sun, Zhang, Xu & ZhouCategoryGeneral propertiesStatistical based propertiesInformation-theoretic propertiesNotationF(X, )Skew(X)Kurt(X)H(C)normH(X)normI(C, X)I(C, X)maxENattrN SratioMeasure descriptionNumber instancesNumber featuresNumber target concept valuesData set dimensionality, = I/FMean absolute linear correlation coefficient possible pairs featuresMean skewnessMean kurtosisNormalized class entropyMean normalized feature entropyMean mutual information class attributeMaximum mutual information class attributeEquivalent number features, ENattr = H(C)/M I(C, X)Noise-signal ratio, N Sratio = (H(X) I(C, X))/M I(C, X)Table 1: Meta-features used characterize data set2.2 Multi-criteria Metric FSS Algorithm Evaluationsection, first, classical metrics evaluating performance FSS algorithmintroduced. Then, analyzing user requirements practice application, basedmetrics, new user-oriented multi-criteria metric proposed FSS algorithmevaluation combining metrics together.2.2.1 Classical Performance Metricsevaluating performance FSS algorithm, following three metricsextensively used feature selection literature: i) classification accuracy , ii) runtimefeature selection, iii) number selected features.1) classification accuracy (acc) classifier selected features usedmeasure well selected features describe classification problem.given data set, different feature subsets generally result different classificationaccuracies. Thus, reasonable feature subset higher classification accuracy stronger capability depicting classification problem. classificationaccuracy also reflects ability FSS algorithm identifying salient featureslearning.2) runtime (t) feature selection measures efficiency FSS algorithmpicking useful features. also viewed metric measure cost featureselection. longer runtime, higher expenditure feature selection.3) number selected features (n) measures simplicity feature selectionresults. classification accuracies two FSS algorithms similar, usuallyfavor algorithm fewer features.Feature subset selection aims improve performance learning algorithmsusually measured classification accuracy. FSS algorithms higher classification accuracy favor. However, mean runtimenumber selected features could ignored. explained following twoconsiderations:1) Suppose two different FSS algorithms Ai Aj , given data set D.classification accuracy Ai slightly greater Aj ,4fiSubset Selection Algorithm Automatic Recommendationruntime Ai number features selected Ai much greaterAj , Aj often chosen.2) Usually, prefer use algorithms higher accuracy longer runtime,lower accuracy shorter runtime. Therefore, need tradeoff classification accuracy runtime feature selection/the number selectedfeatures. example, real-time systems, impossible choose algorithmhigh time-consumption even classification accuracy high.Therefore, necessary allow users making user-oriented performance evaluationdifferent FSS algorithms. purpose, needed address problemintegrate classification accuracy runtime feature selection numberselected features obtain unified metric. paper, resort multi-criteriametric explore problem. underlying reason lies multi-criteria metricsuccessfully used evaluate data mining algorithms considering positiveproperties (e.g. classification accuracy) negative ones (e.g. runtime numberselected features) simultaneously (Nakhaeizadeh & Schnabl, 1997, 1998).comparing two algorithms, besides metrics used evaluate performance,ratio metric values also used. example, suppose A1 A2 twodifferent FSS algorithms, A1 better A2 terms classification accuracy, i.e.,acc1 > acc2 2 , ratio acc1 /acc2 > 1 used show A1 better A2 well.contrary, negative metrics runtime feature selection numberselected features, corresponding ratio < 1 means better algorithm.Actually, multi-criteria metric adjusted ratio ratios (ARR) (Brazdil et al., 2003),combines classification accuracy runtime together unified metric,proposed evaluate performance learning algorithm. extend ARR integrating runtime feature selection number selected features, newmulti-criteria metric EARR (extened ARR) proposed. following discussion,show new metric EARR inclusive, flexible, easy understand.2.2.2 Multi-Criteria Metric EARRLet DSet = {D1 , D2 , , DN } set N data sets, ASet = {A1 , A2 , , }set FSS algorithms. Suppose accji classification accuracy classifier FSSalgorithm Ai data set Dj (1 , 1 j N ), tji nji denote runtimenumber selected features FSS algorithm Ai data set Dj , respectively.EARR Ai Aj Dk definedkEARRDAi ,Aj =accki /acckj1 + log (tki /tkj ) + log (nki /nkj )(1 6= j M, 1 k N ),(1)user-predefined parameters denote relative importanceruntime feature selection number selected features, respectively.computation metric EARR based ratios classical FSS algorithm performance metrics, classification accuracy, runtime feature selection2. acc1 acc2 corresponding classification accuracies algorithms A1 A2 , respectively.5fiWang, Song, Sun, Zhang, Xu & Zhounumber selected features. definition know EARR evaluatesFSS algorithm comparing another algorithm. reasonable sinceobjective assert algorithm good comparing another one insteadfocusing performance. example, suppose classifier 70%classification accuracy data set, get confused whether classifier goodnot. However, compare another classifier obtain 90% classificationaccuracy data set, definitely say first classifier goodcompared second one.Noted that, practice, runtime difference two different FSS algorithmsusually quite great. Meanwhile, high-dimensional data sets, differencenumber selected features two different FSS algorithms great well. Thus,ratio runtime ratio number selected features usually muchwide ranges classification accuracy. simple ratio runtimesimple ratio number selected features employed, would dominatevalue EARR, ratio classification accuracy drowned. orderavoid situation, common logarithm (i.e., logarithm base 10) ratioruntime common logarithm ratio number selected featuresemployed.parameters represent amount classification accuracy userwilling trade 10 times speedup/reduction runtime feature selection/thenumber selected features, respectively. allows users choose algorithmsshorter runtime less features acceptable accuracy. illustratedfollowing example. Suppose accki = (1 + + ) acckj , runtime algorithm Aigiven data set 10 times Aj (i.e., tki = 10 tkj ), number selectedfeatures algorithm Ai 10 times Aj (i.e., nki = 10 nkj ). Then, accordingDk13kEq. (1), EARRAi ,Aj = 1, EARR Aj ,Ai = 1(+)2 > 1. case, Aj outperformsAi . user prefers fast algorithms less features, Aj his/her choice.kvalue EARR varies around 1. value EARRAi ,Aj greater (or equalkto, smaller than) EARRAj ,Ai indicates Ai better (or equal to,worse than) Aj .Eq. (1) directly used evaluate performance two different FSS algorithms.comparing multiple FSS algorithms, performance algorithm Ai ASetgiven data set evaluated metric EARRAi defined follows:EARRDAi =11XEARRDAi ,Aj .(2)j=1j6=iequation shows EARR FSS algorithm Ai arithmeticmean EARRDAi ,Aj Ai algorithm Aj D. is, performanceFSS algorithm Ai ASet evaluated based comparisons algorithms{ASet {Ai }}. larger value EARR, better corresponding FSS algorithmgiven data set D.3. Since log (x/y) = log (y/x) ( + )2 > 06fiSubset Selection Algorithm Automatic Recommendation3. FSS Algorithm Recommendation Methodsection, first give framework FSS algorithm recommendation. Then,introduce nearest neighbor based recommendation method detail.3.1 FrameworkBased assumption relationship performance FSSalgorithm given data set data set characteristics (aka meta-features),proposed recommendation method firstly constructs meta-knowledge database consistingdata set meta-features FSS algorithm performance. that, helpmeta-knowledge database, k-NN based method used model relationshiprecommend appropriate FSS algorithms new data set.Therefore, proposed recommendation method consists two parts: Meta-knowledgeDatabase Construction FSS Algorithm Recommendation. Fig. 1 shows details.Meta-knowledge database constructionFeature selectionalgorithmsHistoricaldata setsPerformance metricaquirementMeta-featuresextractionPerformance metricsMeta-featuresFSS algorithm recommendationNew data setRecommendedFSS algorithmsMetaknowledgedatabasePerformancemetricsMeta-featuresMeta-featuresextractionMeta-featuresNearest data setsidentificationTop r algorithmsrecommendationRanksFSS algorithmsrankingNearestdata setsMetriccollectionPerformancemetricsFigure 1: Framework feature subset selection algorithm recommendation1) Meta-Knowledge Database Constructionmentioned previously, meta-knowledge database consists meta-featuresset historical data sets performance group FSS algorithms them.foundation proposed recommendation method, effectivenessrecommendations depends heavily database.meta-knowledge database constructed following three steps. Firstly,meta-features Table 1 extracted historical data set module Metafeatures extraction. Then, candidate FSS algorithm applied historical dataset. classification accuracy, runtime feature selection number selectedfeatures recorded, corresponding value performance metric EARRcalculated. accomplished module Performance metric calculation. Finally,data set, tuple, composed meta-features valuesperformance metric EARR candidate FSS algorithms, obtained addedknowledge database.2) FSS Algorithm Recommendation7fiWang, Song, Sun, Zhang, Xu & ZhouBased introduction first part Meta-knowledge Database Constructionpresented above, learning target meta-knowledge data set EARR valuesinstead appropriate FSS algorithm. case, demonstratedresearchers usually resort instance-based k -NN (nearest neighbors) methodsvariations (Brazdil et al., 2003, 2008) algorithm recommendation. Thus, k -NNbased FSS algorithm recommendation procedure proposed.recommending FSS algorithms new data set, firstly, meta-featuresdata set extracted. Then, distance new data set historicaldata set calculated according meta-features. that, k nearest data setsidentified, EARR values candidate FSS algorithms k data setsretrieved meta-knowledge database. Finally, candidate FSS algorithmsranked according EARR values, algorithm highest EARRachieves top rank, one second highest EARR gets second rank,forth, top r algorithms recommended.3.2 Recommendation Methodrecommend appropriate FSS algorithms new data set Dnew based k nearestdata sets, two foundational issues solved: i) identify k nearestdata sets, ii) recommend appropriate FSS algorithms based k datasets.1) k nearest data sets identificationk nearest data sets Dnew identified calculating distance Dnewhistorical data set based meta-features. smaller distance,similar corresponding data set Dnew .order effectively calculate distance two data sets, L1 norm distance(Atkeson, Moore, & Schaal, 1997) adopted since easy understand calculate,ability measuring similarity two data sets demonstratedBrazdil et al. (2003).Let Fi = <fi,1 , fi,2 , , fi,h > meta-features data set Di , fi,pvalue pth feature Fi h length meta-features. L1 norm distancedata sets Di Dj formulateddist(Di , Dj ) = kFi Fj k1 =hX|fi,p fj,p |.(3)p=1worth noting ranges different meta-features quite different. example,meta-features introduced Table 1, value normalized class entropy varies0 1, number instances millions. Thus, meta-featuresdifferent ranges directly used calculate distance two data sets, metafeatures large range would dominate distance, meta-features smallrange ignored. order avoid problem, 0-1 standardized method (Eq.(4)) employed make meta-features range [0, 1].fi,p min (f,p ),max (f,p ) min (f,p )8(4)fiSubset Selection Algorithm Automatic Recommendationfi,p (1 p h) value pth meta-feature data set Di , min (f,p )max (f,p ) denote minimum maximum values pth meta-feature historicaldata sets, respectively.2) FSS algorithm recommendationgetting k nearest data sets Dnew , performance candidate FSSalgorithms Dnew evaluated according k nearest data sets. Then,algorithms best performance recommended.Let Dknn = {D1 , D2 , , Dk } k nearest data sets Dnew EARR Aijperformance metric FSS algorithm Ai data set Dj Dknn (1 j k).performance Ai new data set Dnew evaluatedknnEARRDAi=kXjEARRAij ,j = dj1kXdt 1 , dj = dist(Dnew , Dj )./(5)t=1j=1Eq. (5) indicates performance FSS algorithm Ai Dnew evaluatedperformance Dknn Dnew . data set Dj Dknn , smaller distancedj Dnew , similar two data sets. means two datasets Dp Dq , dp < dq data set Dp similar Dnew , EARRAi Dp important evaluating performance Ai Dnew . Thus,weighted average, takes account relative importance data set Dknnrather treating data set equally, employed. Moreover, domain machinelearning, reciprocal distance usually used measure similarity.kPj = dj 1 / dt 1 used weight EARR Ai Dj Dknn .t=1According EARR candidate FSS algorithm ASet Dnew , rankcandidate FSS algorithms obtained. greater EARR, higherrank. Then, top r (e.g., r = 3 paper) FSS algorithms pickedappropriate ones new data set Dnew .Procedure FSSAlgorithmRecommendation shows pseudo-code recommendation.Time complexity. recommendation procedure consists two parts. first part(lines 1-3), k nearest data sets given new data set identified. Firstly,meta-features F extracted function MetaFeatureExtraction(). Then,k-nearest historical data sets identified function NeighborRecognition() baseddistance F meta-features Fi historical data set Di . SupposeP number instances Q number features given data setD, time complexity function MetaFeatureExtraction() O(P + Q). functionNeighborRecognition(), time complexity O(n) depends numberhistorical data sets n. Consequently, time complexity first part O(P +Q)+O(n).second part (lines 4-8), r FSS algorithms recommended data setD. Since weights EARRs k nearest data sets obtained directly,time complexity two steps O(1). time complexity estimating rankingEARRs algorithms ASet O(k m) + O(m log(m)), k preassignednumber nearest data sets number candidate FSS algorithms.9fiWang, Song, Sun, Zhang, Xu & ZhouProcedure FSSAlgorithmRecommendationInputs :- new given data set;DSet - {D1 , D2 , , Dn }, historical data sets;ASet - {A1 , A2 , , }, candidate FSS algorithms;MetaDataBase - {<Fi , EARRsi >|1 n} Fi EARRsmeta-features EARRs ASet Di , respectively;k - predefined number nearest neighbors;r - number recommended FSS algorithms.Output: RecAlgs - Recommended FSS algorithms//Part 1: Recognition k nearest data sets1 F = MetaFeatureExtraction (D);//Extract meta-features2 MetaFeatureSet = {F1 , F2 , , Fn };//Meta-feature data set DSet3 Neighbors = NeighborRecognition (k, F, MetaFeatureSet);//Part 2: Appropriate FSS algorithm recommendation4 WeightSet = calculate weight data set Neighbors //See Eq. (5)5 EARRSet = corresponding EARRs data set Neighbors MetaDataBase;6 Estimate EARR FSS algorithm ASet according WeightSet EARRSetEq. (5) rank algorithms ASet based EARRs;7 RecAlgs = top r FSS algorithms;8 return RecAlgs;sum up, time complexity recommendation procedure O(P + Q) + O(n) +O(km)+O(mlog(m)). practice, data set needs conduct feature selection,number instances P and/or number features Q much greaternumber nearest data sets k number candidate FSS algorithmsm, major time consumption recommendation procedure determinedfirst part.4. Experimental Results Analysissection, experimentally evaluate proposed feature subset selection (FSS)algorithm recommendation method recommending algorithms benchmark datasets.4.1 Benchmark Data Sets115 extensively-used real world data sets, come different areas Computer,Image, Life, Biology, Physical Text 4 , employed experiment. sizesdata sets vary 10 24863 instances, numbers features5 27680.statistical summary data sets shown Table 2 terms numberinstances (denoted I), number features (denoted F) number targetconcepts (denoted T).4. data sets available http://archive.ics.uci.edu/ml/datasets.html, http://featureselection.asu.edu/datasets.php, http://sci2s.ugr.es/keel/datasets.php, http://www.upo.es/eps/bigs/datasets.html, http://tunedit.org/repo/Data, respectively.10fiSubset Selection Algorithm Automatic RecommendationData ID12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758Data Nameada agnosticada priorannealanneal ORIGAR10P 130 674arrhythmiaaudiologyautosbalance-scalebreast-cancerbreast-wbridges version1bridges version2carCLL-SUB-111 111 2856cmccoliccolic.ORIGcoloncredit-acredit-gcylinder-bandsdermatologydiabetesECML90x27679ecoliEmbryonaldataset CeucalyptusflagsGCM Testgina agnosticgina priorgina prior2glassgrub-damageheart-cheart-hheart-statloghepatitishypothyroidionosphereiriskdd ipums la 97-smallkdd ipums la 98-smallkdd ipums la 99-smallkdd JapaneseVowels testkdd JapaneseVowels trainkdd synthetic controlkr-vs-kplaborLeukemiaLeukemia 3cleukemia test 34x7129leukemia train 38x7129lung-cancerlymphLymphoma45x4026+2classesLymphoma96x4026+10classes45624562898898130452226205625286699107107172811114733683686269010005403667689033660248631944634683468346821415530329427015537723511507019748588445687427460031965772723438321484596F491539396752807026510101313728571023282001162140359276808713024930160649717857851091414142030355616161151562371771307130713071305719402740272266101624732266433222222624382128142210745522423910999622232234211Data ID5960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115Data NameLymphoma96x4026+9classesmfeat-fouriermfeat-morphologicalmfeat-pixelmfeat-zernikemolecular-biology promotersmonks-problems-1 testmonks-problems-1 trainmonks-problems-2 testmonks-problems-2 trainmonks-problems-3 testmonks-problems-3 trainmushroomoh0.wcoh10.wcoh15.wcoh5.wcpasturependigitsPIE10P 210 1520postoperative-patient-dataprimary-tumorsegmentshuttle-landing-controlsickSMK-CAN-187 187 1815solar-flare 1solar-flare 2sonarsoybeanspectf testspectf trainspectrometerspect testspect trainsplicespongesquash-storedsquash-unstoredsylva agnosticsylva priorTOX-171 171 1538tr11.wctr12.wctr23.wctr31.wctr41.wctr45.wctrainsvehiclevotevowelwap.wcwaveform-5000white-cloverwinezoo96200020002000200010643212443216943212281241003105091391836109922109033923101537721873231066208683269805311878031907652521439514395171414313204927878690108464359901560500063178101F4027777241485977777723318332393101301323171521918207301816131361364545103232362462524217109153864305805583310129745582623319171484614132141891010101022222222101010103101032272222321922482233332249867101024211203437Table 2: Statistical summary 115 data sets4.2 Experimental Setuporder evaluate performance proposed FSS algorithm recommendationmethod, verify whether proposed method potentially useful practice,confirm reproducibility experiments, set experimental study follows.4.2.1 FSS AlgorithmsFSS algorithms grouped two broad categories: Wrapper Filter (Molina et al.,2002; Kohavi & John, 1997). Wrapper method uses error rate classificationalgorithm evaluation function measure feature subset, evaluationfunction Filter method independent classification algorithm. accuracyWrapper method usually high; however, generality result limited,computational complexity high. comparison, Filter method generality,computational complexity low. Due fact Wrapper methodcomputationally expensive (Dash & Liu, 1997), Filter method usually good choice11fiWang, Song, Sun, Zhang, Xu & Zhounumber features large. Thus, focus Filter methodexperiment.number Filter based FSS algorithms proposed handle feature selectionproblems. algorithms significantly distinguished i) search method usedgenerate feature subset evaluated, ii) evaluation measures used assessfeature subset (Liu & Yu, 2005; de Souza, 2004; Dash & Liu, 1997; Pudil, Novovicova,& Kittler, 1994).order guarantee generality experimental results, twelve well-knownlatest search methods four representative evaluation measures employed.brief introduction search methods evaluation measures follows.1) Search methodsi) Sequential forward search (SFS): Starting empty set, sequentially addfeature results highest value objective function currentfeature subset.ii) Sequential backward search (SBS): Starting full set, sequentially eliminatefeature results smallest decrease value objective functioncurrent feature subset.iii) Bi-direction search (BiS): parallel implementation SFS SBS. searchesfeature subset space two directions.iv) Genetic search (GS): randomized search method performs using simplegenetic algorithm (Goldberg, 1989). genetic algorithm finds feature subsetmaximize special output function using techniques inspired natural evolution.v) Linear search (LS): extension BestFirst search (Gutlein, Frank, Hall, & Karwath, 2009) searches space feature subsets greedy hill-climbingaugmented backtracking facility.vi) Rank search (RS) (Battiti, 1994): uses feature evaluator (such gain ratio)rank features. feature evaluator specified, forward selectionsearch used generate ranking list.vii) Scatter search (SS) (Garcia Lopez, Garcia Torres, Melian Batista, Moreno Perez,& Moreno-Vega, 2006): method performs scatter search featuresubset space. starts population many significant diverse featuresubsets, stops assessment criteria higher given thresholdimprovement longer.viii) Stepwise search (SWS) (Kohavi & John, 1997): variation forward search.step search process, new feature added, test performedcheck features eliminated without significant reductionoutput function.ix) Tabu search (TS) (Hedar, Wang, & Fukushima, 2008): proposed combinatorial optimization problems. adaptive memory responsive explorationcombining local search process anti-cycling memory-based rules avoidtrapping local optimal solutions.12fiSubset Selection Algorithm Automatic Recommendationx) Interactive search (Zhao & Liu, 2007): traverses feature subset spacemaximizing target function taking consideration interaction amongfeatures.xi) FCBF search (Yu & Liu, 2003): evaluates features via relevance redundancy analysis, uses analysis results guideline choose features.xii) Ranker (Kononenko, 1994; Kira & Rendell, 1992; Liu & Setiono, 1995): evaluatesfeature individually ranks features values evaluationmetrics.2) Evaluation measuresi) Consistency (Liu & Setiono, 1996; Zhao & Liu, 2007): kind measure evaluates worth feature subset level consistency target conceptinstances projected onto feature subset. consistencyfeature subset never lower full feature set.ii) Dependency (Hall, 1999; Yu & Liu, 2003): kind measure evaluates worthsubset features considering individual predictive ability featurealong degree redundancy among features. FSS methods basedkind measure assume good feature subsets contain features closelycorrelated target concept, uncorrelated other.iii) Distance (Kira & Rendell, 1992; Kononenko, 1994): kind measure proposed based assumption distance instances different targetconcepts greater target concepts.iv) Probabilistic significance (Zhou & Dillon, 1988; Liu & Setiono, 1995): measureevaluates worth feature calculating probabilistic significancetwo-way function, i.e., association feature target concept.good feature significant association target concept.pay attention that, besides four evaluation measures,another basic kind measure: information-based measure (Liu & Yu, 2005; de Souza, 2004;Dash & Liu, 1997), contemplated experiments. reason demonstrated follow. information-based measure usually conjunction rankersearch method. Thus, FSS algorithms based kind measure usually providerank list features instead telling us features relevant learning target. case, preassign particular thresholds FSS algorithms pickrelevant features. However, effective method set thresholdsacknowledged default threshold FSS algorithms. Moreover, unfairconclude information measure based FSS algorithms assigned thresholdappropriate comparing FSS algorithms. Therefore, kindFSS algorithm employed experiments.Based search methods evaluation measures introduced above, 22 differentFSS algorithms obtained. Table 3 shows brief introduction FSS algorithms.algorithms available data mining toolkit Weka5 (Hall, Frank,5. http://www.cs.waikato.ac.nz/ml/weka/13fiWang, Song, Sun, Zhang, Xu & ZhouHolmes, Pfahringer, Reutemann, & Witten, 2009), search method INTERACTimplemented based Weka source codes available online6 .ID1234567891011Search MethodBestFirst + Sequential Forward SearchBestFirst + Sequential Backward SearchBestFirst + Bi-direction SearchGenetic SearchLinear SearchRank SearchScatter SearchStepwise SearchTabu SearchInteractive SearchBestFirst + Sequential Forward SearchEvaluation MeasureDependencyDependencyDependencyDependencyDependencyDependencyDependencyDependencyDependencyDependencyConsistencyNotationCFS-SFSCFS-SBSCFS-BiSCFS-GSCFS-LSCFS-RSCFS-SSCFS-SWSCFS-TSINTERACT-DCons-SFSID1213141516171819202122Search MethodBestFirst + Sequential Backward SearchBestFirst + Bi-direction SearchGenetic SearchLinear SearchRank SearchScatter SearchStepwise SearchInteractive SearchFCBFsearchRankerRankerEvaluation MeasureConsistencyConsistencyConsistencyConsistencyConsistencyConsistencyConsistencyConsistencyDependencyDistanceProbabilistic SignificanceNotationCons-SBSCons-BiSCons-GSCons-LSCons-RSCons-SSCons-SWSINTERACT-CFCBFRelief-FSignificTable 3: Introduction 22 FSS algorithmsnoted algorithms require particular settings certain parameters. purpose allowing researchers confirm results, introduceparameter settings FSS algorithms. as, FSS algorithms INTERACT-DINTERACT-C, parameter, c-contribution threshold, used identifyirrelevant features. set threshold 0.0001 suggested Zhao Liu (2007).FSS algorithm FCBF, set relevance threshold SU (Symmetric Uncertainty) value bN/ log N cth ranked feature suggested Yu Liu (2003). FSSalgorithm Relief-F, set significance threshold 0.01 used Robnik-SikonjaKononenko (2003). FSS algorithm Signific, threshold, statistical significance level , used identify irrelevant features. set commonly-used value0.01 experiment. FSS algorithms conducted Weka environmentdefault setting(s).4.2.2 Classification AlgorithmsSince actual relevant features real world data sets usually known advance,impracticable directly evaluate FSS algorithm selected features. Classificationaccuracy extensively used metric evaluating performance FSS algorithms,also plays important role proposed performance metric EARR assessingdifferent FSS algorithms.However, different classification algorithms different biases. FSS algorithm maysuitable classification algorithms others (de Souza, 2004). factaffects performance evaluation FSS algorithms.mind, order demonstrate proposed FSS algorithm recommendation method limited particular classification algorithm, five representativeclassification algorithms based different hypotheses employed. bayes-basedNaive Bayes (John & Langley, 1995) Bayes Network (Friedman, Geiger, & Goldszmidt,1997), information gain-based C4.5 (Quinlan, 1993), rule-based PART (Frank & Witten,1998), instance-based IB1 (Aha, Kibler, & Albert, 1991), respectively.Although Naive Bayes Bayes Net bayes-based classification algorithms,quite different since Naive Bayes proposed based hypoth6. http://www.public.asu.edu/huanliu/INTERACT/INTERACTsoftware.html14fiSubset Selection Algorithm Automatic Recommendationesis features conditional independent (John & Langley, 1995), Bayes Nettakes account feature interaction (Friedman et al., 1997).4.2.3 Measures Evaluate Recommendation MethodFSS algorithm recommendation application meta-learning. far know,unified measures evaluate performance meta-learning methods.order assess proposed FSS algorithm recommendation method, two measures,recommendation hit ratio recommendation performance ratio, defined.Let given data set Arec FSS algorithm recommended recommendation method D, two measures introduced follows.1) Recommendation hit ratiointuitive evaluation criterion whether recommended FSS algorithm Arec meetsusers requirements. is, whether Arec optimal FSS algorithm D, performance Arec significant difference optimal FSS algorithm.Suppose Aopt represents optimal FSS algorithm D, ASetopt denotes FSSalgorithm set algorithm significant difference Aopt (of courseincludes Aopt well). Then, measure named recommendation hit defined assesswhether recommended algorithm Arec effective D.Definition 1 (Recommendation hit). FSS algorithm Arec recommended dataset D, recommendation hit Hit(Arec , D) defined(1, Arec ASetoptHit(Arec , D) =.(6)0, otherwiseHit(Arec , D) = 1 means recommendation effective since recommendedFSS algorithm Arec one algorithms ASetopt D, hit(Arec , D) = 0 indicatesrecommended FSS algorithm Arec member ASetopt , i.e., Arec significantlyworse optimal FSS algorithm Aopt D, thus recommendation bad.Definition 1 know recommendation hit Hit(Arec , D) used evaluaterecommendation method single data set. Thus, extended recommendationhit ratio evaluate recommendation set data sets, defined follows.Definition 2 Recommendation hit ratioG1 XHit Ratio(Arec ) =Hit(Arec , Di ).G(7)i=1G number historical data sets, e.g., G = 115 experiment.Definition 2 represents percentage data sets appropriate FSS algorithms effectively recommended recommendation method. larger value,better recommendation method.2) Recommendation performance ratiorecommendation hit ratio reveals whether appropriate FSS algorithmrecommended given data set, cannot tell us margin recommendedalgorithm best one. Thus, new measure, recommendation performance ratiorecommendation, defined.15fiWang, Song, Sun, Zhang, Xu & ZhouDefinition 3 (Recommendation performance ratio). Let EARRrec EARRoptperformance recommended FSS algorithm Arec optimal FSS algorithm D,respectively. Then, recommendation performance ratio (RPR) Arec definedRPR(Arec , D) = EARRrec /EAARopt .(8)definition, best performance EARR opt employed benchmark. Withoutbenchmark, hard determine recommended algorithms good not.example, suppose EARR Arec 0.59. EARR opt = 0.61,recommendation effective since EARR Arec close EARR opt . However,recommendation poor EARR opt = 0.91.RPR ratio EARR recommended FSS algorithm optimal one.measures close recommended FSS algorithm optimal one, revealsrelative performance recommended FSS algorithm. value varies 0 1,larger value RPR, closer performance recommended FSS algorithmoptimal one. recommended algorithm optimal oneRPR = 1.4.2.4 Values Parameterspaper, multi-criteria metric EARR proposed evaluate performanceFSS algorithm. proposed metric EARR, two parameters establishedusers express requirements algorithm performance.experiment, presenting results, two representative value pairs parameters used follows:1) = 0 = 0. setting represents situation classificationaccuracy important. higher classification accuracy selected features,better corresponding FSS algorithms.2) 6= 0 6= 0. setting represents situation user tolerateaccuracy attenuation favor FSS algorithms shorter runtime fewerselected features. experiment, set 10% quite different= = 0. allows us explore impact two parametersrecommendation results.Moreover, order explore parameters affect recommended FSSalgorithms terms classification accuracy, runtime number selected features,different parameters settings provided. Specifically, values vary 010% increase 1%.4.3 Experimental Processorder make sure soundness experimental conclusion guaranteeexperiments reported reproducible, part, introduce four crucial processesused experiments. i) meta-knowledge database construction, ii) optimalFSS algorithm set identification given data set, iii) Recommendation method validationiv) sensitivity analysis number nearest data sets recommendations.1) Meta-knowledge database construction16fiSubset Selection Algorithm Automatic RecommendationProcedure PerformanceEvaluationInputs : data = given data set, i.e, one 115 data sets;learner = given classification algorithm, i.e., one {Naive Bayes, C4.5, PART,IB1 Bayes Network};FSSAlgSet = {FSSAlg 1 , FSSAlg 2 , , FSSAlg 22 }, set 22 FSSalgorithms;Output: EARRset = {EARR 1 , EARR 2 , , EARR 22 }, EARRs 22 FSSalgorithms data;1 = 5; FOLDS = 10;2 = 1 223EARR = 0;4 = 15randomized order data;6generate FOLDS bins data;7j = 1 FOLDS8TestData = bin[j ];9TrainData = data- TestData;10numberList = Null , runtimeList = Null , accuracyList = Null ;11k = 1 2212(Subset, runtime) = apply FSSAlg k TrainData;13number = |Subset |;14RedTestData = reduce TestData according selected Subset;15RedTrainData = reduce TrainData according selected Subset;16classifier = learner (RedTrainData);17accuracy = apply classifier RedTestData;18numberList [k ] = number , runtimeList [k ] = runtime, accuracyList [k ] =accuracy;192021k = 1 22EARR = EARRCompution(accuracyList, runtimeList, numberList, k );//Compute EARR FSSAlg k jth bin pass according Eqs. (1) (2)EARR k = EARR k + EARR;22 1 2223EARR = EARR /(M FOLDS );24 return EARRset;data set Di (1 115), i) extract meta-features Fi ; ii) calculateEARRs 22 candidate FSS algorithms stratified 510-fold cross-validationstrategy (Kohavi, 1995), iii) combine meta-features Fi EARR FSSalgorithm together form tuple, finally added meta-knowledge database.Since extraction meta-features combination meta-featuresEARRs straightforward, present calculation EARRs, procedure PerformanceEvaluation shows details.2) Optimal FSS algorithm set identificationoptimal FSS algorithm set given data set Di consists optimal FSS algorithm data set algorithms significant performance differenceoptimal one Di .optimal FSS algorithm set given data set Di obtained via non-parametricFriedman test (1937) followed Holm procedure test (1988) performance,17fiWang, Song, Sun, Zhang, Xu & Zhouestimated 510 cross validation strategy, 22 FSS algorithms. resultFriedman test shows significant performance difference among22 FSS algorithms, 22 FSS algorithms added optimal FSS algorithm set.Otherwise, FSS algorithm highest performance viewed optimal oneadded optimal FSS algorithm set. Then, Holm procedure test performedidentify algorithms rest 21 FSS algorithms. algorithmssignificant performance differences optimal one added optimal FSSalgorithm set.reason non-parametric test employed lies difficultperformance values follow normal distribution satisfy variance homogeneouscondition.Note optimal FSS algorithm sets different settings parametersdifferent, since values two parameters directly affect required performancevalues.3) Recommendation method validationleave-one-out strategy used empirically evaluate proposed FSS algorithm recommendation method follows: data set Di (1 115)viewed test data, i) identify k nearest data sets training data ={D1 , , Di1 , Di+1 , , D115 } excluding Di ; ii) calculate performance 22 candidate FSS algorithms according Eq. (5) based k nearest data sets valuek determined standard cross-validation strategy, recommend top threeDi ; iii) evaluate recommendations measures introduced section 4.2.3.4) Sensitivity analysis number nearest data sets recommendationsorder explore effect number nearest data sets recommendations provide users empirical method choose value, data set,possible numbers nearest data sets tested. is, identifying knearest data sets given data set, k set 1 number historical datasets minus 1 (e.g., 114 experiment).4.4 Results Analysissection, present recommendation results terms recommended FSS algorithms, hit ratio performance ratio , respectively. Due space limitpaper, list recommendations, instead present results twosignificantly different pairs , i.e., ( = 0, = 0) ( = 10%, = 10%).Afterward, also provide experimental results influence user-orientedparameters recommendations terms classification accuracy, runtime,number selected features, respectively.4.4.1 Recommended Algorithms Hit RatioFigs. 2, 3, 4, 5 6 show first recommended FSS algorithms 115 data setsclassification algorithms Naive Bayes, C4.5, PART, IB1 Bayes Networkused, respectively.18fiSubset Selection Algorithm Automatic Recommendationfigure, two sub-figures corresponding recommendation results( = 0, = 0) ( = 10%, = 10%), respectively. sub-figure,denote correctly incorrectly recommended algorithms, respectively.FSS algorithm IDCorrectly recommended algorithmIncorrectly recommended algorithm2221201918171615141312111098765432113254769811101312151417161918212023222524272629283130333235343736393841404342454447464948515053525554575659586160636265646766696871707372757477767978818083828584878689889190939295949799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 1149799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 11496Data set IDFSS algorithm ID(a) = 0, = 022212019181716151413121110987654321132547698111013121514171619182120232225242726292831303332353437363938414043424544474649485150535255545756595861606362656467666968717073727574777679788180838285848786898891909392959496Data set ID(b) = 10%, = 10%Figure 2: FSS algorithms recommended 115 data sets Naive Bayes usedFSS algorithm IDCorrectly recommended algorithmIncorrectly recommended algorithm2221201918171615141312111098765432113254769811101312151417161918212023222524272629283130333235343736393841404342454447464948515053525554575659586160636265646766696871707372757477767978818083828584878689889190939295949799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 1149799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 11496Data set IDFSS algorithm ID(a) = 0, = 022212019181716151413121110987654321132547698111013121514171619182120232225242726292831303332353437363938414043424544474649485150535255545756595861606362656467666968717073727574777679788180838285848786898891909392959496Data set ID(b) = 10%, = 10%Figure 3: FSS algorithms recommended 115 data sets C4.5 usedfigures, observe that:1) five classifiers, proposed method effectively recommend appropriateFSS algorithms 115 data sets.case ( = 0, = 0), number data sets, whose appropriate FSSalgorithms correctly recommended, 109 115 Naive Bayes, 111 115C4.5, 109 115 PART, 108 115 IB1, 109 115 Bayes19fiWang, Song, Sun, Zhang, Xu & ZhouFSS algorithm IDCorrectly recommended algorithmIncorrectly recommended algorithm2221201918171615141312111098765432113254769811101312151417161918212023222524272629283130333235343736393841404342454447464948515053525554575659586160636265646766696871707372757477767978818083828584878689889190939295949799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 1149799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 11496Data set IDFSS algorithm ID(a) = 0, = 022212019181716151413121110987654321132547698111013121514171619182120232225242726292831303332353437363938414043424544474649485150535255545756595861606362656467666968717073727574777679788180838285848786898891909392959496Data set ID(b) = 10%, = 10%Figure 4: FSS algorithms recommended 115 data sets PART usedFSS algorithm IDCorrectly recommended algorithmIncorrectly recommended algorithm2221201918171615141312111098765432113254769811101312151417161918212023222524272629283130333235343736393841404342454447464948515053525554575659586160636265646766696871707372757477767978818083828584878689889190939295949799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 1149799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 11496Data set IDFSS algorithm ID(a) = 0, = 022212019181716151413121110987654321132547698111013121514171619182120232225242726292831303332353437363938414043424544474649485150535255545756595861606362656467666968717073727574777679788180838285848786898891909392959496Data set ID(b) = 10%, = 10%Figure 5: FSS algorithms recommended 115 data sets IB1 usedNetwork, respectively. states recommendation method effectiveclassification accuracy important.case ( = 10%, = 10%), number data sets, whose appropriate FSSalgorithms correctly recommended, 104 115 Naive Bayes, 109 115C4.5, 110 115 PART, 106 115 IB1, 104 115 BayesNetwork, respectively. indicates recommendation method also works welltradeoff required among classification accuracy, runtime, numberselected features.2) distribution recommended FSS algorithms 115 data sets differentdifferent parameters settings. distribution relatively uniform ( = 0, = 0),20fiSubset Selection Algorithm Automatic RecommendationFSS algorithm IDCorrectly recommended algorithmIncorrectly recommended algorithm2221201918171615141312111098765432113254769811101312151417161918212023222524272629283130333235343736393841404342454447464948515053525554575659586160636265646766696871707372757477767978818083828584878689889190939295949799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 1149799 101 103 105 107 109 111 113 11598 100 102 104 106 108 110 112 11496Data set IDFSS algorithm ID(a) = 0, = 022212019181716151413121110987654321132547698111013121514171619182120232225242726292831303332353437363938414043424544474649485150535255545756595861606362656467666968717073727574777679788180838285848786898891909392959496Data set ID(b) = 10%, = 10%Figure 6: FSS algorithms recommended 115 data sets Bayes Network usedseriously biased algorithm (e.g., 22th FSS algorithm) ( =10%, = 10%).phenomenon similar five classifiers. explained follows.FSS algorithms best classification accuracy distribute 115 data setsuniformly. Thus, case ( = 0, = 0) users favor accurate classifiers,distribution recommended FSS algorithms relatively uniform well. However,exist FSS algorithms run faster (e.g., 22th algorithm Signific)select fewer features (e.g., 8th algorithm CFS-SWS, 18th algorithm ConsSWS, 22th algorithm Signific) 115 data sets. reason,case ( = 10%, = 10%) users prefer FSS algorithms less runtimefewer features, distribution FSS algorithms best performance115 data sets biased algorithms, recommended FSS algorithms.3) 22th FSS algorithm performs well 85 115 data sets classifiers( = 10%, = 10%). seems FSS algorithm generally wellperformed FSS algorithm adopted FSS tasks needFSS algorithm recommendation. Unfortunately, case. 22th FSSalgorithm still failing perform well quarter 115 data sets.Yet, recommendation method distinguish data sets effectivelyrecommend appropriate FSS algorithms them. indicates recommendationmethod still necessary case.Compared ( = 0, = 0), know case due largervalues explained follows. 22 FSS algorithms, althoughclassification accuracies classifier features selected different,differences usually bounded. Meanwhile, Eq. (1) know /set greater bound value, value EARR dominatedruntime/the number selected features. means setrelatively large value, algorithm lower time complexity algorithmchooses smaller number features recommended, classification21fiWang, Song, Sun, Zhang, Xu & Zhouaccuracy selected features ignored. However, know, oneimportant targets feature selection improve performance learningalgorithms. unreasonable ignore classification accuracy focusspeed simplicity FSS algorithm.Thus, real applications, values set limit classification accuracies. Generally, / bounded (accmax accmin )/accmin ,accmax accmin denote maximum minimum classification accuracies, respectively.Parameter setting= 0, = 0= 10%, = 10%RecommendationAlg1stAlg2ndAlg3rdTop 3Alg1stAlg2ndAlg3rdTop 3Naive Bayes94.7883.4874.7899.1390.4371.3038.2699.13C4.596.5279.1380.8798.2694.7869.5745.22100.0PART94.7892.1784.3599.1394.7870.4342.61100.0IB193.9177.3975.6599.1392.1764.3543.48100.0Bayes Network94.7883.4873.9198.2690.4371.3036.5299.13Algx denotes x -th algorithm ranking list recommended Top 3 means top threealgorithms recommended.Table 4: Hit ratio (%) recommendations five classifiers different settings(, )Table 4 shows hit ratio recommended FSS algorithms five classifiers.observe that:1) single FSS algorithm recommended, hit ratio first recommended algorithm Alg1st highest, value 96.52% least 90.43%five classifiers. Thus, Alg1st first choice.2) top three algorithms recommended, hit ratio 100% least98.62%. indicates confidence top three algorithms includingappropriate one high. reason top three algorithmsrecommended. Moreover, proposed recommendation method reducednumber candidate algorithms three, users pick one fitshis/her specific requirement them.4.4.2 Recommendation Performance RatioFigs. 7 8 show recommendation performance ratio RPR first recommendedFSS algorithm five classifiers ( = 0, = 0) ( = 10%, = 10%),respectively. two figures observe that, data sets twosettings , RPRs recommended FSS algorithms greater 95%100% matter classifier used. indicatesFSS algorithms recommended proposed method close optimal one.Table 5 shows average RPRs 115 data sets five classifiersdifferent settings (, ). table, classifier, columns Rec Defshows RPR value corresponding recommended FSS algorithms default FSSalgorithms, respectively. default FSS algorithm frequent best one115 data sets classifier.22fiSubset Selection Algorithm Automatic RecommendationRPR (%)Naive Bayes10095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDRPR (%)C4.510095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDRPR (%)PART10095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDRPR (%)IB110095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDRPR (%)Bayes Network10095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDFigure 7: RPR 1 st recommended FSS algorithm ( = 0, = 0) fiveclassifiersRPR (%)Naive Bayes10095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDRPR (%)C4.510095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDRPR (%)PART10095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDRPR (%)IB110095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDRPR (%)Bayes Network10095908580757013254769811 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 101 103 105 107 109 111 113 11510 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114Data set IDFigure 8: RPR 1 st recommended FSS algorithm ( = 10%, = 10%)five classifiers23fiWang, Song, Sun, Zhang, Xu & Zhouobserve average RPRs range 97.32% 98.8% ( = 0,= 0), 97.82% 98.99% ( = 10%, = 10%), respectively. Moreover,average RPR recommended FSS algorithms surpasses default FSSalgorithms five different classifiers. means proposed recommendationmethod works well greatly fits users performance requirement.Parameter setting= 0, = 0= 10%, = 10%Naive bayesRecDef98.24 96.4298.69 91.95C4.5RecDef98.8098.1897.8292.40PARTRecDef97.61 94.7997.89 92.40IB1RecDef97.3296.4398.1192.35Bayes NetworkRecDef98.3796.6398.9992.43Table 5: Average RPR (%) 115 data sets five classifiersData ID12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758NB0.04430.02270.01180.00790.02440.0190.00910.01110.0110.00910.00860.00620.00680.00770.06160.00990.00740.00830.01020.0070.0080.01030.0080.00660.00880.00610.00970.00830.0070.02730.22360.26020.36910.0080.00840.01030.00650.00840.00980.02780.0070.01380.12190.14530.19370.02250.01490.01010.02280.00690.01950.02020.01280.01280.00750.00840.01460.0432C4.50.04250.01310.01240.00920.02530.0190.00930.00620.00760.00870.0070.00680.00850.00870.05820.00830.01260.00770.00780.00710.010.00790.00830.00640.01580.00680.00780.00690.01320.02720.22310.26160.37220.01030.00680.00680.00880.0070.03520.02430.00990.0060.12280.14270.19550.02320.01420.01250.02450.00750.02010.02070.01350.0130.00730.00730.0080.0464PART0.04990.01470.01230.00820.02570.02210.00930.00760.00720.00840.00720.00650.00640.00860.05750.00810.00760.01280.01050.0070.0090.0110.00790.00670.01010.00750.01130.0080.00930.02910.22360.26050.36890.00830.00650.00660.00860.00840.00690.02450.0110.01060.12140.1440.19720.02420.01250.01010.01910.00840.01960.01650.01160.01970.00690.0070.00950.0449IB10.04230.01370.01170.01140.02460.01920.01140.00660.00740.01380.00750.00630.00930.00840.0580.00820.00840.01170.00670.00690.00750.01350.00930.00690.00820.00830.01170.00820.00720.02730.22390.2620.36890.01130.00640.00660.00590.00930.00670.02460.0070.01160.12310.1450.1940.02190.01390.00920.01980.00680.02090.01920.01560.01380.00650.0060.00820.0436BNet0.04640.01290.01160.00960.02410.02080.01130.00880.00760.00730.00830.0110.00960.00770.05860.0090.00850.0070.00910.00810.00790.00880.00720.00930.00940.00770.01230.00740.0070.02720.22550.25960.37140.0070.0090.00690.00610.00850.00770.02490.00860.00630.12410.14340.19350.02280.0150.01040.0240.0090.01970.01650.01580.01340.00680.00690.01030.0445Data ID5960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115AverageNB0.04460.03610.00870.08450.02250.01080.01170.00890.00920.00820.00610.00690.06110.2030.18540.11950.12460.01470.05760.06850.00810.00860.02030.00950.02440.06830.00740.00840.00660.00960.00950.0060.01580.00680.00970.03650.01080.00580.00820.44020.45910.05040.10120.040.06330.91030.64840.58640.00670.00910.00820.00880.77460.02670.00820.01060.00860.0658C4.50.04390.03510.00960.08430.01770.00770.01050.00750.00670.00630.00580.00770.04960.19930.16890.11120.12080.00640.05260.07040.0060.00850.01440.01090.02440.06710.00690.00770.01010.00910.00950.00690.01520.00730.00760.03960.00810.00620.00780.44290.45320.04960.0950.03930.06180.90960.64480.58840.00560.00750.00740.01310.77590.02550.00750.00950.00790.0651PART0.04430.04070.00730.08350.02110.00650.00740.00580.00790.00710.0060.00790.0510.19760.16310.11050.12170.00680.05090.06410.00820.00870.01410.00540.02760.06740.00860.04110.00710.01240.00780.00850.01640.00660.0080.03780.00640.00620.00640.4440.45570.05020.09540.04240.06440.90910.64430.58610.00650.01020.00870.01310.77360.0250.00660.00950.00730.0652IB10.04770.0340.00780.08530.020.00760.00680.0080.00650.00850.00670.00970.04850.19940.16520.11030.12090.00670.05190.0660.0080.00720.01180.00910.02570.06920.00860.00740.00690.0140.01240.00660.01830.00810.00650.03740.00940.00610.00680.44010.45510.05390.09660.04160.06350.91420.64640.58510.00750.01310.00640.00930.77390.02660.00630.00550.00620.0649BNet0.04270.03540.00850.08590.01940.00980.00710.00790.00640.01160.00670.0070.05140.19830.16380.10960.12260.0060.05330.06460.0130.00890.01840.00820.02480.06640.00710.01320.00770.01130.00920.00790.01650.00610.0080.03750.00770.00640.00830.44130.45450.05260.09680.03940.06250.91220.64610.58540.00550.01030.00950.00780.77460.02820.01350.00730.00640.0650NB BNet denote Naive Bayes Bayes Network, respectively.Table 6: Recommendation time 115 data sets five classifiers (in second )24fiSubset Selection Algorithm Automatic Recommendation4.4.3 Recommendation Timerecommending FSS algorithms feature selection problem, recommendationtime contributed meta-features extraction, k nearest data sets identification,candidate algorithm ranking according performance k data sets.three recommendation time contributors, candidate algorithm rankingrelated parameters performance metric EARR.However, computation performance EARR whatever valuesare. means recommendation time independent specific settings. Thus, present recommendation time ( = 0, = 0), Table 6shows details.Table 6 observe given data set, recommendation time differencesfive classifiers small. reason recommendation time mainlycontributed extraction meta-features, relation classifiers.consistent time complexity analysis Section 3.2. also observedata sets, recommendation time less 0.1 second, average value115 data sets around 0.65 second five classifiers. much fasterconventional cross validation method.4.4.4 Impact ParametersFigs. 9, 10, 11, 12 13 show impact settings classificationaccuracy, runtime feature selection, number selected features, Hit RatioRPR value, respectively.NaiveBayesC4.5PARTAverage accuracy0.845Average accuracyIB1Bayes Network0.8450.840.8350.830.8250.820.8150.810.840.8350.830.8250.820.8150.810.8050.805000.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1!Figure 9: Classification accuracies five classifiers recommended FSS algorithms different valuesFig. 9 shows classification accuracies five classifiers different values. observe that, increase either , classificationaccuracies five classifiers recommended FSS algorithms decrease.increase indicates users much prefer faster FSS algorithmsFSS algorithms get less features. Thus, proportion classification accuracyperformance decreased. means ranks FSS algorithms run fasterand/or get less features improved corresponding FSS algorithms finallyselected.25fiWang, Song, Sun, Zhang, Xu & ZhouC4.5PARTIB1Bayes Network2400Average runtime (ms)Average runtime (ms)NaiveBayes240022002000180016001400120010008006004002002200200018001600140012001000800600400000.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1!Figure 10: Runtime FSS algorithms recommended five classifiers differentvaluesFig. 10 shows runtime FSS algorithms recommended five classifiersdifferent values five classifiers. observe that:1) increase , average runtime recommended FSS algorithmsclassifier decreases. Note larger value means users favor faster FSS algorithms. Thus, indicates users performance requirement met since faster FSSalgorithms recommended.2) increase , average runtime recommended FSS algorithms increaseswell. proposed recommendation method, appropriateFSS algorithms given data set recommended based nearest data sets.Moreover, experiment, half (i.e., 69) 115 data sets,negative correlation number selected features runtime22 FSS algorithms. Thus, data sets kind negative correlation,possible nearest neighbors given data set negative correlation.Therefore, larger means longer runtime. Another possible reason largervalue means users favor FSS algorithms choose fewer features, orderget fewer features, FSS algorithms need consume relatively time.C4.5PARTAverage number featuresAverage number featuresNaiveBayes10090807060504000.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1IB1Bayes Network1201008060402000.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1!Figure 11: Number features selected FSS algorithms recommendedfive classifiers different valuesFig. 11 shows number features selected FSS algorithms recommendedfive classifiers different values . observe that:26fiSubset Selection Algorithm Automatic Recommendation1) increase , average number selected features increases well.proposed recommendation method, appropriate FSS algorithmsgiven data set recommended based nearest data sets. Moreover,experiment, half (i.e., 69) 115 data sets, negative correlation number selected features runtime 22 FSS algorithms.Thus, data sets kind negative correlation, possiblenearest neighbors given data set negative correlation. Therefore, largermeans features. Another possible reason larger value means usersfavor faster FSS algorithms. possible shorter computation time obtainedvia filter less features features remained.Note exception. is, average number selected featuresC4.5 decreases value small. However, decrement comes quitesmall range (i.e., < 0.005).2) increase , average number features selected recommendedFSS algorithm decreases. Note larger value means users favor FSS algorithmsget fewer features. Thus, indicates users requirement met sinceFSS algorithms get fewer features recommended.NaiveBayesC4.5PARTAverage Hit Ratio (%)Average Hit Ratio (%)IB1Bayes Network1001009998979695949392999897969594939291000.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1!Figure 12: Average Hit Ratio FSS algorithms recommended five classifiersdifferent valuesC4.5PART10099.599.5Average RPR (%)Average RPR (%)NaiveBayes1009998.59897.5IB1Bayes Network9998.59897.59797000.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1!Figure 13: Average RPR FSS algorithms recommended five classifiersdifferent valuesFigs. 12 13 show average hit ratio RPR recommended FSS algorithmsdifferent values five classifiers.27fiWang, Song, Sun, Zhang, Xu & Zhouobserve that, average hit ratio falls intervals [91.74%, 100%][92.56%, 99.13%]) . average RPR varies intervals [97.69%,98.82%] [97.68%, 98.73%] . change , hitratio RPR recommended FSS algorithms vary well. However, changeintervals fall relative small interval lower bound stands fairly high level.minimum average hit ratio 91.74% minimum average RPR97.68%. indicates proposed FSS algorithm recommendation methodgeneral application works well different settings .5. Sensitivity Analysis Number Nearest Data SetsRecommendation Resultssection, analyze number nearest data sets affects recommendation performance. Based experimental results, provide guidelinesselecting appropriate number nearest data sets practice.5.1 Experimental MethodGenerally, different numbers nearest data sets (i.e., k) result different recommendations. Thus, recommending FSS algorithms feature selection problem,appropriate k value important.k value results higher recommendation performance preferred. However,recommendation performance difference two different k values sometimes mightrandom significant. Thus, order identify appropriate k valuealternatives, first determine whether performance differences amongstatistically significant. Non-parametric statistical test, Friedman test followedHolm procedure test suggested Demsar (2006), used purpose.experiment, conducted FSS algorithm recommendation possible kvalues (i.e., 1 114) 115 data sets. identifying appropriate kvalues, non-parametric statistical test conducted follows.Firstly, Friedman test performed 114 recommendation performancesignificance level 0.05. null hypothesis 114 k values perform equivalentlywell proposed recommendation method 115 data sets.Friedman test rejects null hypothesis, is, exists significant differenceamong 114 k values, choose one recommendation bestperformance reference. that, Holm procedure test performed findk values recommendation performance significant differencereference. identified k values including reference appropriatenumbers nearest data sets.5.2 Results AnalysisFig. 14 shows number nearest data sets (i.e., k) affects performancerecommendation method different settings , denotesk recommendation performance significantly worse otherssignificance level 0.05. observe that:28fiSubset Selection Algorithm Automatic RecommendationNaive BayesC4.5PARTIB1Bayes NetworkInappropriate number neighbors10.995RPR0.990.9850.980.9750.971325476981110131215141716191821202322252427262928313033323534373639384140434245444746494851505352555457565958616063626564676669687170737275747776797881808382858487868988919093929594979699 101 103 105 107 109 111 11398 100 102 104 106 108 110 112 114Number nearest data sets(a) = 0, = 0Naive BayesC4.5PARTIB1Bayes NetworkInappropriate number neighbors1RPR0.9950.990.9850.980.9751325476981110131215141716191821202322252427262928313033323534373639384140434245444746494851505352555457565958616063626564676669687170737275747776797881808382858487868988919093929594979699 101 103 105 107 109 111 11398 100 102 104 106 108 110 112 114Number nearest data sets(b) = 10%, = 10%Figure 14: Number nearest data sets vs. RPR1) = = 0 (Fig. 14(a)), five classifiers, RPR variesdifferent k values. Specifically, RPR fluctuant k smaller 20,relatively flat middle part, decreases k larger 79 exceptC4.5. However, increment C4.5 small (< 0.002). might dueC4.5 picks useful features build tree itself, impact featureselection methods less. Moreover, difference among accuracies C4.5data sets relatively small, performance metric EARR used evaluatedifferent FSS algorithms depends classification accuracy = = 0. Thus,RPR C4.5 relatively stable different values k.2) case = = 10% (Fig. 14(b)), variation RPR different= = 0. five classifiers, RPR first decreases fluctuations,increases, finally decreases slowly steadily. could due that,parameters set relatively large value (such 10% experiment),runtime ( number features selected by) FSS algorithm playimportant role evaluating performance FSS algorithm. Thus,given data set, FSS algorithms lower time complexity (or smaller numberselected features) possibly higher ranked larger RPR. Therefore,increasing k, algorithms possibly recommended. Meanwhile,data sets, algorithms either real appropriate algorithmslarger RPR, RPR averaged data sets relatively stable increasingk.29fiWang, Song, Sun, Zhang, Xu & Zhou3) Comparing cases = = 0 = = 10%, found appearsk < 21 former k < 29 latter, emerges k > 76former. means cannot choose k values falling ranges.time, also found peak values RPR = = 10% appearrange [32, 54], also one peak value ranges = = 0 except C4.5.means set k 28% 47% number data sets, better recommendationperformance obtained.6. Conclusionpaper, presented FSS algorithm recommendation method aimsupport automatic selection appropriate FSS algorithms new feature selectionproblem number candidates.proposed recommendation method consists meta-knowledge database construction algorithm recommendation. former obtains meta-features performance candidate FSS algorithms, latter models relationshipmeta-features FSS algorithm performance based k -NN method recommends appropriate algorithms feature selection problem built model.thoroughly tested recommendation method 115 real world data sets, 22different FSS algorithms, five representative classification algorithms two typicalusers performance requirements. experimental results show recommendationmethod effective.also conducted sensitivity analysis explore number nearestdata sets (k) impacts FSS algorithm recommendation, suggest set k 28%47% number historical data sets.paper, utilized well-known commonly-used meta-featurescharacterize different data sets. meta-features informative?informative meta-features? still open questions. knowledge,still exist effective method answer questions. Thus, futurework, plan explore measure information meta-featureswhether informative meta-features lead improvements FSS algorithm recommendation.Acknowledgementswork supported National Natural Science Foundation China grant61070006.ReferencesAha, D. W., Kibler, D., & Albert, M. K. (1991). Instance-based learning algorithms. Machine learning, 6 (1), 3766.Ali, S., & Smith, K. A. (2006). learning algorithm selection classification. AppliedSoft Computing, 6 (2), 119138.30fiSubset Selection Algorithm Automatic RecommendationAtkeson, C. G., Moore, A. W., & Schaal, S. (1997). Locally weighted learning. Artificialintelligence review, 11 (1), 1173.Battiti, R. (1994). Using mutual information selecting features supervised neural netlearning. IEEE Transactions Neural Networks, 5 (4), 537550.Brazdil, P., Carrier, C., Soares, C., & Vilalta, R. (2008). Metalearning: Applications datamining. Springer.Brazdil, P. B., Soares, C., & Da Costa, J. P. (2003). Ranking learning algorithms: Using IBLmeta-learning accuracy time results. Machine Learning, 50 (3), 251277.Brodley, C. E. (1993). Addressing selective superiority problem: Automatic algorithm/model class selection. Proceedings Tenth International ConferenceMachine Learning, pp. 1724. Citeseer.Castiello, C., Castellano, G., & Fanelli, A. (2005). Meta-data: Characterization inputfeatures meta-learning. Modeling Decisions Artificial Intelligence, 457468.Dash, M., & Liu, H. (1997). Feature selection classification. Intelligent data analysis,1 (3), 131156.Dash, M., & Liu, H. (2003). Consistency-based search feature selection. Artificial Intelligence, 151 (1-2), 155176.de Souza, J. T. (2004). Feature selection general hybrid algorithm. Ph.D. thesis,University Ottawa.Demsar, J. (2006). Statistical comparisons classifiers multiple data sets. JournalMachine Learning Research, 7, 130.Engels, R., & Theusinger, C. (1998). Using data metric preprocessing advice datamining applications..Frank, E., & Witten, I. H. (1998). Generating accurate rule sets without global optimization.Proceedings 25th international conference Machine learning, pp. 144151.Morgan Kaufmann, San Francisco, CA.Friedman, M. (1937). use ranks avoid assumption normality implicitanalysis variance. Journal American Statistical Association, 32 (200),675701.Friedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. Machinelearning, 29 (2), 131163.Gama, J., & Brazdil, P. (1995). Characterization classification algorithms. ProgressArtificial Intelligence, 189200.Garcia Lopez, F., Garcia Torres, M., Melian Batista, B., Moreno Perez, J. A., & MorenoVega, J. M. (2006). Solving feature subset selection problem parallel scattersearch. European Journal Operational Research, 169 (2), 477489.Goldberg, D. E. (1989). Genetic algorithms search, optimization, machine learning.Addison-Wesley Professional.31fiWang, Song, Sun, Zhang, Xu & ZhouGutlein, M., Frank, E., Hall, M., & Karwath, A. (2009). Large-scale attribute selectionusing wrappers. Proceedings IEEE Symposium Computational IntelligenceData Mining, pp. 332339. IEEE.Guyon, I., & Elisseeff, A. (2003). introduction variable feature selection.Journal Machine Learning Research, 3, 11571182.Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. (2009).weka data mining software: update. ACM SIGKDD Explorations Newsletter, 11 (1),1018.Hall, M. A. (1999). Correlation-based Feature Selection Machine Learning. Ph.D. thesis,University Waikato.Hedar, A. R., Wang, J., & Fukushima, M. (2008). Tabu search attribute reductionrough set theory. Soft Computing-A Fusion Foundations, MethodologiesApplications, 12 (9), 909918.Hommel, G. (1988). stagewise rejective multiple test procedure based modifiedbonferroni test. Biometrika, 75 (2), 383386.John, G. H., & Langley, P. (1995). Estimating continuous distributions Bayesian classifiers. Proceedings eleventh conference uncertainty artificial intelligence,Vol. 1, pp. 338345. Citeseer.Kalousis, A., Gama, J., & Hilario, M. (2004). data algorithms: Understandinginductive performance. Machine Learning, 54 (3), 275312.King, R. D., Feng, C., & Sutherland, A. (1995). Statlog: comparison classification algorithms large real-world problems. Applied Artificial Intelligence, 9 (3), 289333.Kira, K., & Rendell, L. (1992). practical approach feature selection. Proceedings ninth international workshop Machine learning, pp. 249256. MorganKaufmann Publishers Inc.Kohavi, R. (1995). study cross-validation bootstrap accuracy estimationmodel selection. International joint Conference artificial intelligence, Vol. 14,pp. 11371145. Citeseer.Kohavi, R., & John, G. (1997). Wrappers feature subset selection. Artificial intelligence,97 (1), 273324.Kononenko, I. (1994). Estimating attributes: analysis extensions RELIEF. Proceedings European conference machine learning Machine Learning, pp.171182. Springer-Verlag New York.Lee, M., Lu, H., Ling, T., & Ko, Y. (1999). Cleansing data mining warehousing.Proceedings 10th International Conference Database Expert SystemsApplications, pp. 751760. Springer.Lindner, G., & Studer, R. (1999). AST: Support algorithm selection CBR approach. Principles Data Mining Knowledge Discovery, 418423.Liu, H., Motoda, H., Setiono, R., & Zhao, Z. (2010). Feature Selection: Ever EvolvingFrontier Data Mining. Fourth Workshop Feature Selection DataMining, pp. 314. Citeseer.32fiSubset Selection Algorithm Automatic RecommendationLiu, H., & Setiono, R. (1995). Chi2: Feature selection discretization numeric attributes. Proceedings Seventh International Conference Tools Artificial Intelligence, pp. 388391. IEEE.Liu, H., & Setiono, R. (1996). probabilistic approach feature selection-a filter solution..pp. 319327. Citeseer.Liu, H., & Yu, L. (2005). Toward integrating feature selection algorithms classificationclustering. IEEE Transactions Knowledge Data Engineering, 17 (4), 491502.Michie, D., Spiegelhalter, D. J., & Taylor, C. C. (1994).statistical classification..Machine learning, neuralMolina, L. C., Belanche, L., & Nebot, A. (2002). Feature selection algorithms: surveyexperimental evaluation. Proceedings IEEE International Conference DataMining, pp. 306313. IEEE.Nakhaeizadeh, G., & Schnabl, A. (1997). Development multi-criteria metrics evaluation data mining algorithms. Proceedings 3rd International ConferenceKnowledge Discovery Data mining, pp. 3742.Nakhaeizadeh, G., & Schnabl, A. (1998). Towards personalization algorithms evaluation data mining. Proceedings 4th International Conference KnowledgeDiscovery Data mining, pp. 289293.Pudil, P., Novovicova, J., & Kittler, J. (1994). Floating search methods feature selection.Pattern recognition letters, 15 (11), 11191125.Pudil, P., Novovicova, J., Somol, P., & Vrnata, R. (1998a). Conceptual base featureselection consulting system. Kybernetika, 34 (4), 451460.Pudil, P., Novovicova, J., Somol, P., & Vrnata, R. (1998b). Feature selection expertuseroriented approach. Advances Pattern Recognition, 573582.Quinlan, J. R. (1993). C4.5: programs machine learning. Morgan Kaufmann.Robnik-Sikonja, M., & Kononenko, I. (2003). Theoretical empirical analysis relieffrrelieff. Machine learning, 53 (1), 2369.Saeys, Y., Inza, I., & Larranaga, P. (2007). review feature selection techniquesbioinformatics. Bioinformatics, 23 (19), 25072517.Smith-Miles, K. A. (2008). Cross-disciplinary perspectives meta-learning algorithmselection. ACM Computing Surveys, 41 (1), 125.Sohn, S. Y. (1999). Meta analysis classification algorithms pattern recognition. IEEETransactions Pattern Analysis Machine Intelligence, 21 (11), 11371144.Song, Q. B., Wang, G. T., & Wang, C. (2012). Automatic recommendation classificationalgorithms based data set characteristics. Pattern Recognition, 45 (7), 26722689.Vilalta, R., & Drissi, Y. (2002). perspective view survey meta-learning. ArtificialIntelligence Review, 18 (2), 7795.33fiWang, Song, Sun, Zhang, Xu & ZhouWolpert, D. H. (2001). supervised learning no-free-lunch theorems. Proceedings6th Online World Conference Soft Computing Industrial Applications, pp.2542. Citeseer.Yu, L., & Liu, H. (2003). Feature selection high-dimensional data: fast correlationbased filter solution. Proceedings Twentieth International ConferenceMachine Leaning, Vol. 20, pp. 856863.Zhao, Z., & Liu, H. (2007). Searching interacting features. Proceedings 20thInternational Joint Conference Artifical Intelligence, pp. 11561161. Morgan Kaufmann Publishers Inc.Zhou, X., & Dillon, T. (1988). heuristic-statistical feature selection criterion inductive machine learning real world. Proceedings IEEE InternationalConference Systems, Man, Cybernetics, Vol. 1, pp. 548552. IEEE.34fiJournal Artificial Intelligence Research 47 (2013) 741-808Submitted 01/13; published 08/13Acyclicity Notions Existential RulesApplication Query Answering OntologiesBernardo Cuenca GrauIan HorrocksMarkus KrotzschClemens KupkeDespoina MagkaBoris MotikZhe Wangbernardo.cuenca.grau@cs.ox.ac.ukian.horrocks@cs.ox.ac.ukmarkus.kroetzsch@cs.ox.ac.ukclemens.kupke@cs.ox.ac.ukdespoina.magka@cs.ox.ac.ukboris.motik@cs.ox.ac.ukzhe.wang@cs.ox.ac.ukDepartment Computer Science, University OxfordParks Road, Oxford OX1 3QD, United KingdomAbstractAnswering conjunctive queries (CQs) set facts extended existential rulesprominent problem knowledge representation databases. problemsolved using chase algorithm, extends given set facts fresh factsorder satisfy rules. chase terminates, CQs evaluated directlyresulting set facts. chase, however, terminate necessarily, checkingwhether chase terminates given set rules facts undecidable. Numerousacyclicity notions proposed sufficient conditions chase termination.paper, present two new acyclicity notions called model-faithful acyclicity (MFA)model-summarising acyclicity (MSA). Furthermore, investigate landscapeknown acyclicity notions establish complete taxonomy notions known us.Finally, show MFA MSA generalise notions.Existential rules closely related Horn fragments OWL 2 ontologylanguage; furthermore, several prominent OWL 2 reasoners implement CQ answeringusing chase materialise relevant facts. order avoid termination problems,many systems handle OWL 2 RL profile OWL 2; furthermore,systems go beyond OWL 2 RL, without termination guarantees. paperalso investigate whether various acyclicity notions provide principled practicalsolution problems. theoretical side, show query answeringacyclic ontologies lower complexity general ontologies. practicalside, show many commonly used OWL 2 ontologies MSA,number facts obtained materialisation large. results thus suggestprincipled development materialisation-based OWL 2 reasoners practically feasible.1. IntroductionExistential rules first-order implications conjunctions function-free atomsmay contain existentially quantified variables implications consequent (Baget,Leclere, Mugnier, & Salvat, 2011a; Cal, Gottlob, Lukasiewicz, Marnette, & Pieris, 2010a).rules used variety ways databases, knowledge representation, logicprogramming. database theory, existential rules known tuple-generating dependencies (Abiteboul, Hull, & Vianu, 1995) used capture wide range schemac2013AI Access Foundation. rights reserved.fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangconstraints. Furthermore, also used declarative data transformation rulesdata exchangethe process transforming database structured according sourceschema database structured according target schema (Fagin, Kolaitis, Miller, &Popa, 2005). Existential rules also provide foundation several prominent knowledgerepresentation formalisms, Datalog (Cal, Gottlob, & Pieris, 2010b; Cal et al.,2010a), also closely related logic programs function symbolshead. Practical applications existential rules range bioinformatics (Mungall, 2009)modelling complex structures chemical compounds (Magka, Motik, & Horrocks, 2012;Hastings, Magka, Batchelor, Duan, Stevens, Ennis, & Steinbeck, 2012).Answering conjunctive queries (CQs) set facts extended existential rulesfundamental, yet undecidable (Beeri & Vardi, 1981) reasoning problem existential rules.problem characterised using chase (Johnson & Klug, 1984; Maier, Mendelzon,& Sagiv, 1979)a technique closely related hypertableau calculus (Motik, Shearer, &Horrocks, 2009b; Baumgartner, Furbach, & Niemela, 1996). forward-chaining manner,chase extends original set facts facts derived using rules.result chase universal model, sense arbitrary CQoriginal facts rules answered evaluating query model.1.1 Chase Termination Acyclicity NotionsRules existentially quantified variables headso-called generating rulesrequireintroduction fresh individuals. Cyclic applications generating rules may preventchase terminating, fact determining whether chase terminates setrules facts undecidable (Deutsch, Nash, & Remmel, 2008). However, several decidableclasses existential rules identified, existing proposals classifiedtwo main groups. first group, rules restricted possibly infiniteuniversal models represented using finitary means. group includes rulesuniversal models bounded treewidth (Baget et al., 2011a), guarded rules (Cal et al.,2010a), sticky rules (Cal, Gottlob, & Pieris, 2011). second group, one usessufficient (but necessary) acyclicity notion ensures chase termination.Roughly speaking, acyclicity notions analyse information flow rules ensure cyclic applications generating rules possible. Weak acyclicity (WA)(Fagin et al., 2005) one first notions, extended notionssafety (Meier, Schmidt, & Lausen, 2009), stratification (Deutsch et al., 2008), acyclicitygraph rule dependencies (aGRD) (Baget, Mugnier, & Thomazo, 2011b), joint acyclicity (JA) (Krotzsch & Rudolph, 2011), super-weak acyclicity (SWA) (Marnette, 2009).Syntactic acyclicity criteria also investigated context logic programsfunction symbols rule heads, goal recognise logic programsfinite stable models. Several notions implemented state art logicprogramming engines, omega-restrictedness (Syrjanen, 2001) Smodels system (Syrjanen & Niemela, 2001), lambda-restrictedness ASP grounder GrinGo(Gebser, Schaub, & Thiele, 2007), argument-restrictedness (Lierler & Lifschitz, 2009)DLV system (Leone, Pfeifer, Faber, Eiter, Gottlob, Perri, & Scarcello, 2006), manyothers (Calimeri, Cozza, Ianni, & Leone, 2008; Greco, Spezzano, & Trubitsyna, 2012; DeSchreye & Decorte, 1994).742fiAcyclicity Notions Existential Rules1.2 Applications Acyclicity NotionsAcyclicity notions interesting several reasons. First, unlike guarded rules, acyclicrules axiomatise structures arbitrary shapes, long structures boundedsize. Second, result chase acyclic rules stored manipulateddatabase; important, example, data exchange, goalmaterialise transformed database.paper, argue acyclicity notions also relevant description logics (DLs)knowledge representation formalisms underpinning OWL 2 ontologylanguage (Cuenca Grau, Horrocks, Motik, Parsia, Patel-Schneider, & Sattler, 2008). CQanswering DL ontologies key reasoning service many DL applications,problem studied numerous different DLs (Calvanese, De Giacomo, Lembo, Lenzerini,& Rosati, 2007; Krotzsch, Rudolph, & Hitzler, 2007; Glimm, Horrocks, Lutz, & Sattler,2008; Ortiz, Calvanese, & Eiter, 2008; Lutz, Toman, & Wolter, 2009; Perez-Urbina, Motik,& Horrocks, 2009; Rudolph & Glimm, 2010; Kontchakov, Lutz, Toman, Wolter, & Zakharyaschev, 2011). Answering CQs ontologies, however, quite technical oftenhigh computational complexity. Therefore, practical OWL 2 reasoners frequently solveproblem using materialisationa reasoning technique relevant consequencesontology precomputed using chase, allowing queries directly evaluatedmaterialised set facts. Examples materialisation-based systems include OraclesSemantic Data Store (Wu, Eadon, Das, Chong, Kolovski, Annamalai, & Srinivasan, 2008),Sesame (Broekstra, Kampman, & van Harmelen, 2002), OWLIM (Kiryakov, Ognyanov, &Manov, 2005), Jena (Carroll, Dickinson, Dollin, Reynolds, Seaborne, & Wilkinson, 2004),DLE-Jena (Meditskos & Bassiliades, 2008). reasoning possible (i) ontologyHorn (Hustadt, Motik, & Sattler, 2005) thus require disjunctive reasoning,(ii) chase guaranteed terminate. satisfy second assumption, reasonersoften consider axioms OWL 2 RL profile (Motik, Cuenca Grau, Horrocks, Wu,Fokoue, & Lutz, 2009a); systematically excludes generating rules thus triviallyensures chase termination, also makes approach incomplete. Generating rulespartially supported systems OWLim (Bishop & Bojanov, 2011) Jena,support typically ad hoc provides completeness and/or termination guarantees. Acyclicity notions used address issues: ontology Hornacyclic, complete materialisation computed without risk non-termination.1.3 ContributionsMotivated practical importance chase termination, paper present twonew acyclicity notions: model-faithful acyclicity (MFA) model-summarising acyclicity(MSA). Roughly speaking, acyclicity notions use particular model rulesanalyse implications existential quantifiers, call modelbased. particular, MFA uses actual canonical model induced factsrules, makes notion general. prove checking whether setexistential rules MFA 2ExpTime-complete, becomes ExpTime-completepredicates rules bounded arity. Due high complexity, MFA mayunsuitable practical application. Thus, introduce MSA, understoodMFA analysis performed models summarise (or overestimate)743fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangactual models. Checking MSA existential rules realised via checking entailmentground atoms datalog programs. use close connection MSA datalogprove checking MSA ExpTime-complete general existential rules,becomes coNP-complete arity rule predicates bounded.next conduct detailed investigation landscape known acyclicity notions,augmented MFA MSA. class logic programs correspond existential rules skolemised existential quantifiers, show MSA MFA strictlysubsume existing acyclicity notions known logic programming. also showMSA strictly general SWAone general acyclicity notions knowndatabase theory. Furthermore, investigate relationship known notionsthus complete picture respect relative expressiveness.MSA MFA applied general existential rules without equality. Equality incorporated via singularisationa technique proposed Marnette (2009)transforms rules encode effects equality. Singularisation orthogonalacyclicity: computing transformed rules, one use MFA, MSA, factnotion check whether result acyclic; so, chase signularised rules terminates, chase result used particular way answer arbitrary CQs.Unfortunately, singularisation nondeterministic: ways transforming rulesmay produce acyclic rule sets, ways guaranteed so. paper,refine singularisation obtain practically useful upper lower bounds acyclicity.also show that, used JA, lower bound actually coincides WA.next turn attention theoretical practical issues using acyclicitymaterialisation-based CQ answering ontologies. theoretical side, showchecking MFA MSA Horn-SROIF ontologies ExpTime- PTime-complete,respectively, answering CQs acyclic Horn-SROIF ontologies ExpTimecomplete well. Furthermore, show that, Horn-SHIF ontologies, complexitychecking MFA answering CQs drops PSpace. Answering CQs ExpTimecomplete general (i.e., acyclic) Horn-SHIF ontologies (Eiter, Gottlob, Ortiz, &Simkus, 2008; Ortiz, Rudolph, & Simkus, 2011), acyclicity makes problem easier.Furthermore, Horn ontologies extended arbitrary SWRL rules (Horrocks &Patel-Schneider, 2004) without affecting decidability worst-case complexity, providedunion ontology SWRL rules acyclic; contrast generalcase, SWRL extensions DLs easily lead undecidability.practical side, explore limits reasoning acyclic OWL 2 ontologiesvia materialisation. checked MFA, MSA, JA 336 Horn ontologies; furthermore,estimate impact materialisation, compared size materialisationnumber facts original ontologies. experiments revealed manyontologies MSA, complex ones MSA JA; furthermore,universal models obtained via materialisation typically large. Thus, resultssuggest principled, materialisation-based reasoning ontologies beyond OWL 2RL profile may practically feasible.extended version paper Cuenca Grau, Horrocks, Krotzsch, Kupke,Magka, Motik, Wang (2012) published KR 2012.744fiAcyclicity Notions Existential Rules2. Preliminariessection introduce definitions notation used rest paper.2.1 First-Order Logicuse standard notions constants, function symbols, predicate symbols,equality predicate, > universal truth, universal falsehood. functionpredicate symbol associated nonnegative integer arity. Variables, terms, substitutions, atoms, first-order formulae, sentences, interpretations (i.e., structures), modelsdefined usual. slight abuse notation, often identify conjunctionset conjuncts. Furthermore, often abbreviate vector terms t1 , . . . , tn ~t;define |~t| = n; often identify ~t set indexed terms {t1 , . . . , tn }.(~x) stress ~x = x1 , . . . , xn free variables formula ,denote result applying substitution . term, atom, formula groundcontain variables; fact ground atom. depth dep(t) term defined0 constant variable, dep(t) = 1 + maxni=1 dep(ti ) = f (t1 , . . . , tn ).term t0 subterm term t0 = = f (~s) t0 subterm si ~s;additionally t0 6= t, t0 proper subterm t. term contained atom P (~t)~t, occurs P (~t) subterm term ti ~t; thus, containedP (~t), also occurs P (~t), converse may hold. term contained(resp. occurs) set atoms contained (resp. occurs) atom I.first-order logic, equality predicate commonly assumed predefinedinterpretationthat is, every first-order interpretation required interpretsmallest reflexive relation domain. Satisfaction sentence interpretationinterpreted way written |= , entailment sentencesentence written |= . Unless otherwise stated, use standard interpretationequality throughout paper.Equality, however, also treated ordinary predicate explicit axiomatisation. Let arbitrary set function-free first-order formulae. Then, =occur ; otherwise, contains formulae (1)(3) instance formula (4)n-ary predicate P occurring different , 1 n. Notevariables formulae (implicitly) universally quantified.xx(1)x1 x2 x2 x1(2)x1 x2 x2 x3 x1 x3(3)P (x1 , . . . , xi , . . . , xn ) xix0iP (x1 , . . . , x0i , . . . , xn )(4)treated ordinary predicate, satisfaction formula model written|= , entailment formula formula written |= . Please note that,according definitions, |= hold even interpretation interprets predicatearbitrary way; contrast, |= hold interpretation interprets predicateidentity relation models domain. consequences w.r.t. |=w.r.t. |= coincidethat is, first-order sentence constructed usingsymbols , |= |= .745fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang2.2 Rules Queriesinstance finite set function-free facts. existential rule (or rule)function-free sentence form~x~z.[(~x, ~z) ~y .(~x, ~y )](5)(~x, ~z) (~x, ~y ) conjunctions atoms, tuples variables ~x, ~y , ~zpairwise disjoint. Formula body formula head rule. brevity,quantifiers ~x~z often omitted. convenience, sometimes identify rule bodyhead set respective conjuncts. datalog rule rule ~y empty.rule equality-free contain equality predicate . term occursexistential rule occurs head body atom rule, definitionsextended set rules obvious way; existential rules contain functionsymbols, analogous notion contained rule coincides one. Twovariables directly connected rule occur together body atom rule;furthermore, connected transitive closure directly connected ; finally, ruleform (5) connected pairs variables w, w0 ~x ~z connected rule.conjunctive query (CQ) formula form Q(~x) = ~y .(~x, ~y ), (~x, ~y )conjunction atoms; query Boolean ~x empty. substitution mapping ~xconstants answer Q(~x) w.r.t. set rules instance |= Q(~x).Answering CQs core reasoning problem many applications existential rules.answering conjunctive query Q(~x) set rules instance I,rest paper implicitly assume Q(~x) contain predicates. simplifies presentation since allows us define various transformationswithout take account possible predicates occur Q(~x) only.assumption w.l.o.g., always extend tautological rules formP (~x) P (~x) predicate P occurring Q(~x) .Furthermore, assume occur body rulequery Q(~x). w.l.o.g. since eliminate atom form x rule bodyreplace x rest rule; furthermore, eliminate body atomsform b b constants, introduce fresh predicate Oa , add new ruleOa (a), replace body atom b conjunction Oa (x) x b x freshvariable, finally eliminate atom x b before. Similarly, provide explicitsupport inequality predicate 6. Inequality rule heads simulated usingordinary predicate: atom form 6 occurring rule head replacedNotEqual(s, t), NotEqual fresh ordinary predicate explicitly axiomatisedirreflexive; note that, handled regular predicate explicitly axiomatised rules(1)(4), replacement axioms (4) must instantiated P = NotEqual well.contrast, atoms involving inequality predicate occurring rule bodies generally requiredisjunctive reasoning, supported existential rules.Finally, assume conjunctions (~x, ~z) (~x, ~y ) rule form (5)empty. also assume > treated ordinary unary predicates,semantics > captured explicitly instantiating following rulen-ary predicate P occurring :P (x1 , . . . , xn ) >(x1 ) . . . >(xn )746(6)fiAcyclicity Notions Existential Rulesassumptions ensure always satisfiable, |= y.(y)unsatisfiable w.r.t. conventional treatment > . allowingbody atoms form >(x), without loss generality require existentialrule safe (i.e., universally quantified variable occurring head atom alsooccurs body atom rule), greatly simplifies many definitions.database theory, satisfaction entailment often considered w.r.t. finiteinterpretations unique name assumption (UNA); latter ensures distinctconstants interpreted distinct elements. contrast, assumptions customary ontology-based KR. paper, assume UNA, UNAaxiomatised explicitly needed using inequality predicate (or simulation thereof).Furthermore, paper investigate theories satisfiable finite models (i.e.,chase finite); thus, difference finite infinite satisfiabilityimmaterial results.frequently use skolemisation interpret rules Herbrand interpretations,defined possibly infinite sets ground atoms. particular, rule rform (5) variable yi ~y , let fri function symbol globally unique r yiarity |~x|; furthermore, let sk substitution sk (yi ) = fri (~x) yi ~y .Then, skolemisation sk(r) r following rule:(~x, ~z) (~x, ~y )sk(7)skolemisation sk() set rules obtained skolemising rule .Skolemisation affect answers CQsthat is, conjunctive query Q(~x)formed predicates , instance I, substitution ,|= Q(~x) sk() |= Q(~x).2.3 Skolem ChaseAnswering CQs characterised using chase, paper use skolem chasevariant (Marnette, 2009). Let r = skolemised rule let set groundatoms. set ground atoms consequence r substitution exists mappingvariables r terms occurring . resultapplying r I, writtenr(I), union consequences r I. setskolemised rules, (I) = r r(I). Let finite set ground atoms, let setrules, let 0 = sk() , let 0f 0n subsets 0 containing ruleswithout function symbols, respectively. chase sequence sequencesets facts I0 , I1 , . . . I0 = and, > 0, set Ii defined follows:0n (Ii1 ) 6 Ii1 , Ii = Ii1 0n (Ii1 ),otherwise Ii = Ii1 0f (Ii1 ).chase defined = Ii ; note infinite. chaseused database answering CQs: substitution answer Q|= Q. chase terminates 0 exists Ii = Ijj i; chase terminates universally chase terminatesI. skolem chase terminates, nonoblivious chase (Faginet al., 2005) core chase (Deutsch et al., 2008) terminate well.747fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangcritical instance set rules contains facts constructedusing predicates occurring , constants occurring body rule ,one special fresh constant . skolem chase terminatesskolem chase terminates universally (Marnette, 2009).2.4 Acyclicity NotionsChecking whether skolem chase terminates given instance undecidable,checking universal skolem chase termination conjectured undecidable well. Consequently, various sufficient acyclicity notions proposed literature. Formally, acyclicity notion X class finite sets rules; definition allows ustalk (proper) containment acyclicity notions. sometimes writeX, mean X. next introduce weak joint acyclicity: formerone first notions considered literature; show Section 3,latter notion relatively powerful, yet still easy understand. use two notionsthroughout paper present examples state various technical claims. Section 3present definitions many acyclicity notions known literature.following, let set rules variable occurs one rule.position expression form P |i P n-ary predicate integer1 n. Given rule r form (5) variable w occurring r, set PosB (w)body positions w contains position P |i P (t1 , . . . , tn ) (~x, ~z) ti = wvector ~t terms. set PosH (w) head positions defined analogously,w.r.t. head atoms r. Note that, since variable occurs one rule, sets PosB (w) PosH (w) (indirectly) associated rule contains w.rest paper, whenever use notation PosH (w) PosB (w), silentlyassume variable occurs one rule notation unambiguous.clearly w.l.o.g. one always arbitrarily rename variables different rules.Weak acyclicity (WA) (Fagin et al., 2005) applied existential rules containequality predicate. WA dependency graph WA() contains positionsvertices; furthermore, rule r form (5), variable x ~x, positionP |i PosB (x), variable ~y , graph WA() containsregular edge P |i Q|j PosH (x) Q 6= and,special edge P |i Q|j PosH (y) Q 6= .Set WA WA() contain cycle involves special edge. Equality atomseffectively ignored WA.Joint acyclicity (JA) (Krotzsch & Rudolph, 2011) generalises WA, applicableequality-free rules. existentially quantified variable , let Move(y)smallest set positionsPosH (y) Move(y),existential rule r universally quantified variable x occurringr, PosB (x) Move(y), PosH (x) Move(y).748fiAcyclicity Notions Existential RulesJA dependency graph JA() defined follows. vertices JA()existentially quantified variables occurring . Given arbitrary two variables y1y2 , JA dependency graph JA() contains edge y1 y2 whenever rulecontains y2 also contains universally quantified variable x PosH (x) 6=PosB (x) Move(y1 ). Set JA JA() contain cycle.2.5 Rule NormalisationExistential rules often transformed existential rules replacing partsrule head body atoms involving fresh predicates. transformationcalled normalisation, often used preprocessing step bring rulessuitable form. example, Horn OWL 2 axioms translated existential rulesusing well known transformations first-order logic, latternormalised form describe Section 6. section introduce definitionrule normalisation captures similar methods known us.Let r rule form (8), 1 , 2 , 1 , 2 conjunctions atomssatisfying ~x1 ~x2 = ~x3 ~x4 , ~z2 ~z3 = , ~y2 ~y3 = .1 (~x1 , ~z1 , ~z2 ) 2 (~x2 , ~z1 , ~z3 ) ~y1 , ~y2 , ~y3 .[1 (~x3 , ~y1 , ~y2 ) 2 (~x4 , ~y1 , ~y3 )](8)normalisation step replaces conjunction either head body ruleatom involving fresh predicate. precisely, head normalisation step replaces1 (~x3 , ~y1 , ~y2 ) atom Q(~x3 , ~y1 ) Q fresh predicate, thus replacing r rule(9), adds rule (10).1 (~x1 , ~z1 , ~z2 ) 2 (~x2 , ~z1 , ~z3 ) ~y1 , ~y3 .[Q(~x3 , ~y1 ) 2 (~x4 , ~y1 , ~y3 )]Q(~x3 , ~y1 ) ~y2 .1 (~x3 , ~y1 , ~y2 )(9)(10)Alternatively, body normalisation step replaces 1 (~x1 , ~z1 , ~z2 ) atom Q(~x1 , ~z1 )Q fresh predicate, thus replacing r rule (11), adds rule (12).Q(~x1 , ~z1 ) 2 (~x2 , ~z1 , ~z3 ) ~y1 , ~y2 , ~y3 .[1 (~x3 , ~y1 , ~y2 ) 2 (~x4 , ~y1 , ~y3 )]1 (~x1 , ~z1 , ~z2 ) Q(~x1 , ~z1 )(11)(12)Given set existential rules , normalisation steps often applied iteratively.predicate Q introduced step always fresh, call normalisation withoutstructure sharing. contrast, normalisation structure sharing allows predicateQ reused across different normalisation steps. example, predicate Qintroduced head normalisation step replace 1 (~x1 , ~z1 , ~z2 ), conjunctionform 1 (~x01 , ~z10 , ~z20 ) ~x01 , ~z10 , ~z20 renamings ~x1 , ~z1 , ~z2 replaced Q(~x03 , ~y10 )without introducing corresponding rule (10). analogous optimisation usedbody normalisation step.Let 0 set rules obtained via normalisation (with without structure sharing). well known 0 conservative extension . Consequently,instance BCQ Q use freshly introduced predicates,|= Q 0 |= Q.749fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang3. Novel Acyclicity NotionsWeak acyclicity considerably influenced field data exchange databases,rather strict notion may sufficient many applications existentialrules. Joint acyclicity significantly relaxes weak acyclicity developed mainlyrule based knowledge representation applications.Section 3.1 show even joint acyclicityone general acyclicitynotions developed fardoes capture rules corresponding axioms commonly foundontologies chase terminates universally. address important limitation, propose Section 3.2 model-faithful acyclicity (MFA)a novel, general,notion used successfully ensure chase termination many ontologies usedpractice. computational cost checking MFA is, however, rather high; hence,Section 3.3 introduce model-summarising acyclicity (MSA)a strict notioneasier check produces results MFA existing ontologies.3.1 Limitations Existing Acyclicity Notionsmotivate new acyclicity notions, first present example shows knownacyclicity notions, JA, satisfied rules equivalent simpleaxioms abound OWL ontologies.Example 1. Let set rules (13)(17).A(x1 ) y1 .R(x1 , y1 ) B(y1 )r1 =r2 =R(x2 , z1 ) B(z1 ) A(x2 )(13)(14)r3 =B(x3 ) y2 .R(x3 , y2 ) C(y2 )(15)r4 =C(x4 ) D(x4 )(16)r5 =R(x5 , z2 ) D(z2 ) B(x5 )(17)Rules r1 r2 correspond description logic axiom R.B, rule r3 correspondsaxiom B v R.C, rule r4 corresponds axiom C v D, rule r5 corresponds axiomR.D v B. axioms common OWL ontologies.definition JA Section 2, Move(y1 ) = {R|2 , B|1 , R|1 , A|1 }. Thus,JA dependency graph contains edge y1 itself, set axiomsJA. contrast, following table shows chase sequence .A()R(, f ())R(f (), g(f ()))B()B(f ())C(g(f ()))C()R(, g())D(g())D()C(g())D(g(f ()))R(, )Rule r2 applicable R(f (), g(f ())) since I3 contain fact B(g(f ()))necessary match atom B(z1 ) rule. Thus, chase terminates.existing acyclicity notions essentially try estimate whether applicationrule produce facts (possibly applying chase rules) repeatedly750fiAcyclicity Notions Existential Rulestrigger rule infinite manner. key difference various notionsrule applicability determined. particular, JA considers variable ruleisolation check satisfaction body atoms once; example, rule (14)applicable facts generated rule (15), determinedconsidering variables x2 z1 rule (14) simultaneously. notions thus overestimaterule applicability and, result, fail detect chase termination.3.2 Model-Faithful Acyclicity (MFA)main intuition addressing problem precise chase terminationguarantees obtained tracking rule applicability faithfully. simple solutioncompletely precise rule applicability: one run skolem chaseuse sufficient checks identify cyclic computations. Since sufficient, necessary,computable test given latter, must adopt practical approach.example, raise alarm stop process chase derives cyclic termf (~t), f occurs ~t. idea refined; example, one could stopf occurs nested term fixed number times. choice appropriate testthus depends application; however, experiments show, checking onelevel nesting suffices many cases. particular, term f (~t) f occurring ~tgenerated chase set rules Example 1.Definition 2. term cyclic function symbol f exists term f (~s)subterm t, term f (~u) proper subterm f (~s).notion acyclicity declarative: given set rules transformed newset rules 0 tracks rule dependencies using fresh predicates; then, identifiedacyclic 0 entail special nullary predicate C. Since acyclicity definedvia entailment, decided using theorem proving procedure existential rulessound complete. Acyclicity guarantees termination skolem chase,also guarantees termination nonoblivious chase core chase. call notion modelfaithful acyclicity estimates rule application precisely, examining actualstructure universal model .Definition 3. rule r = (~x, ~z) ~y .(~x, ~y ) variable yi ~y , let Firfresh unary predicate unique r yi ; furthermore, let fresh binary predicates,let C fresh nullary predicate. Then, MFA(r) following rule:^^Fir (yi )(~x, ~z) ~y . (~x, ~y )S(xj , yi )yi ~xj ~xset rules, MFA() smallest set contains MFA(r) rule r ,rules (18)(19), rule (20) instantiated Fir corresponding r :Fir (x1 )S(x1 , x2 ) D(x1 , x2 )(18)D(x1 , x2 ) S(x2 , x3 ) D(x1 , x3 )(19)Fir (x2 )(20)D(x1 , x2 )751CfiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangset model-faithful acyclic (MFA) w.r.t. instance MFA() 6|= C; furthermore, universally MFA1 MFA w.r.t. .Example 4. Let set rules Example 1. Then, MFA(r1 ) MFA(r3 )given (21) (22), respectively; since r1 r3 contain single existentially quantified variable each, omit superscripts Fr1 Fr3 sake clarity. Thus,MFA() consists rules (14), (16), (17), rules (21)(22), rules (18)(19), rule(20) instantiated Fr1 Fr3 .A(x1 ) y1 .R(x1 , y1 ) B(y1 ) Fr1 (y1 ) S(x1 , y1 )(21)B(x3 ) y2 .R(x3 , y2 ) C(y2 ) Fr3 (y2 ) S(x3 , y2 )(22)straightforward see chase MFA() consists facts presentedExample 1, augmented following facts:S(, f ())D(, f ())D(f (), g(f ()))S(, g())D(, g())D(, g(f ()))Fr1 (f ())S(f (), g(f ()))Fr3 (g())Fr3 (g(f ()))chase MFA() contain C, implies MFA() 6|= C.result, universally MFA.MFA formulated semantic, rather syntactic notion, thus mainlyindependent algorithmic details: entailment MFA() 6|= C checked usingarbitrary sound complete first-order calculus. Section 4 discuss relationshipMFA existing notions, show MFA generalises them.following proposition shows MFA characterises derivations skolemchase cyclic terms occur.Proposition 5. set rules MFA w.r.t. instance IMFA()contains cyclic term.Proof. Let 0 = MFA(), let I0 0 , I1 0 , . . . chase sequence 0 . Moreover,let fri function symbol used skolemise i-th existentially quantified variablerule r, defined Section 2.2. next prove following claims hold termst0 occurring Ik 0 , rule r, integer i, integer k, well k = .1. Term form fri (~u) Fir (t) Ik 0 .2. Term form fri (~u) t0 ~u S(t0 , t) Ik 0 .03. t0 proper subterm t, D(t0 , t) Ik+20 ; furthermore, D(t , t) I00proper subterm t.1. rest paper often omit universally; furthermore, used acyclicity notion,MFA means universally MFA.752fiAcyclicity Notions Existential Rules(Claims 1 2, direction ) proof induction k. Set I0 0 containfunctional terms, clearly satisfies claims. induction step, assumeclaims hold Ik1consider Ik 0 . Since Ik1Ik 0 , claims clearly hold00k1term occurs I0 . Consider arbitrary term form fri (~u)0occur Ik1u. Clearly, introduced Ik 00 , arbitrary term ~application skolemisation MFA(r) rule r . Since head MFA(r)contains atoms Fir (yi ) S(xj , yi ) xj ~x, Fir (t) Ik 0 S(t0 , t) Ik 0t0 S~u, Fir (t) I0 S(t0 , t) I0 t0 ~u well. Finally,since I0 = k Ik 0 , claims clearly hold k = .(Claims 1 2, direction ) Predicate predicate Fir occur 0 headatoms form Fir (yi ) S(xj , yi ); hence, skolemised rules contain predicateshead atoms form Fir (fri (~x)) S(xj , fri (~x)), clearly implies claim.(Claim 3, first part k 6= ) proof induction k. base case holdsvacuously since I0 0 contain functional terms. Assume claim holdsk 1, consider arbitrary term = fri (~u) occurring Ik 0 t0subterm ti ~u. Claim 2, S(ti , t) Ik 0 ; furthermore, ti occursk+10Ik10 , induction assumption D(t , ti ) I0 . Finally, rules withoutfunctional terms applied rules functional terms; hence, rule (19)D(t0 , t) Ik+20 , required.(Claim 3, second part) proper subterm relation transitive, rules (18)(19) effectively define transitive closure S, clearly implies claim.Assume I0 contains cyclic term t. Then, term t1 = fri (~s) subtermterm t2 = fri (~u) proper subterm t1 . Claims 1 3,{Fir (t2 ), D(t2 , t1 ), Fir (t1 )} I0 . then, since 0 contains rule (20), C I0 ,MFA. converse claim, assume MFA w.r.t. instance I.Then, Definition 3 MFA() |= C. Since special nullary predicate Coccurs right-hand side rule (20), exist terms t1 t2 , rule r ,predicate Fir {Fir (t1 ), D(t1 , t2 ), Fir (t2 )} I0 . Since Fir (t1 ) Fir (t2 )contained I0 , Claim 1 implies t1 t2 form t1 = fri (u~1 ) t2 = fri (u~2 ),respectively. Finally, D(t1 , t2 ) I0 Claim 3 imply t1 proper subterm t2 ,I0 contains cyclic term.characterisation implies termination skolem chase MFA rules 2ExpTime.particular, term derived skolem chase 0 = MFA() cannot cyclicProposition 5; seen tree branching factor boundedmaximum arity function symbol sk(0 ) depth bounded numberfunction symbols sk(0 ). chase thus generate doubly exponentialnumber different terms atoms. 2ExpTime bound already holds rulesWA (Cal et al., 2010b), CQ answering MFA rules harder WA rules.Proposition 6. set rules MFA w.r.t. instance I, skolem chaseterminates double exponential time.Proof. Let 0 = MFA(), let c, f , p number constants, function symbols,predicate symbols, respectively, occurring sk(0 ), let ` maximum arityfunction symbol, let maximum arity predicate symbol sk(0 ). Consider753fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangarbitrary term occurring I0 ; clearly, seen tree branchingfactor ` containing constants leaf nodes function symbols internal nodes;furthermore, since cyclic, dep(t) f , number leaves bounded `f ,total number nodes bounded f `f . node assigned constant functionfsymbol, number different terms occurring I0 bounded = (c + f )f ` ,number different atoms I0 bounded p , clearly doublyexponential I. Consequently, size I0 doubly exponentialI. Furthermore, arbitrary set facts 0 rule r, set r(I 0 ) computedexamining mappings variables r terms occurring 0 , requiresexponential time size r polynomial time size 0 . Consequently, I0computed time double exponential . Finally, straightforwardsee I0 , computed double exponential time well.Proposition 6, answering BCQ MFA rules 2ExpTime. next provechecking MFA w.r.t. specific instance also 2ExpTime, checking universal MFA 2ExpTime-hard. provides tight complexity bounds problems.Towards goal, first establish Lemma 7 relationship answering certainkinds queries certain kinds rules checking whether related set rulesuniversally MFA; use relationship several hardness proofs rest paper.Then, Theorem 8 present main complexity result.Lemma 7. Let set weakly acyclic, constant-free, equality-free, connected rulespredicates nonzero arity, let B unary predicates, let R fresh binarypredicate, let constant, let extended rule (23).R(z, x) B(x) y.[R(x, y) A(y)](23)Then, {A(a)} 6|= B(a) universally MFA.Proof. Let = {A(a)}, let I0 , I1 , . . . chase sequence . Furthermore,let 0 = MFA(), let J = , let J0 0 , J1 0 , . . . chase sequence J 0 , letf function symbol used skolemise existential quantifier rule (23). Setconstant-free, constant occurring set Ii .next show facts Jj 0 certain form. end, ` 0,let t` = f (. . . f () . . .) function symbol f repeated ` times (by definition,t0 = ); also, term fact obtained t` zero applicationspredicates function symbols {f, D, S, C, R} level `. induction chasesequence J 0 , next prove sequence satisfies following property ():fact F Jj 0 , integer ` exists F form R(, )R(t` , t`+1 ), predicate F contained {D, S, C}, F `-levelfact predicate F contained {D, S, C, R}.Set J0 0 = J clearly satisfies property () since fact clearly level 0. assumeJj 0 satisfies property () j, consider application rule r 0 . rcorresponds rule (18), (19), (20), (23), result rule application clearlysatisfies property (). Otherwise, r safe body atom contains predicate754fiAcyclicity Notions Existential Rules{D, S, C, R}; induction assumption, atom matched fact level `;body atoms r connected, body atoms matched facts level;finally, head atoms r contain function symbols different f , constantspredicates zero arity, fact derived atom head r either containspredicate level `.next show chase sequences , J 0 relatedfollowing property ():fact F 0 level 1 fact F obtained replacing t1 F 0a, F Ii F 0 Jj 0 \ J j.proof () straightforward: J contains R(, ) B(), J1 0 contains R(, f ())A(f ()); moreover, due (), term t1 plays chase sequence J 0role constant chase sequence , rule applications factslevel 1 former chase sequence correspond one-to-one rule applicationslatter chase sequence. omit formal details sake brevity.assume {A(a)} |= B(a). Then, B(a) Ii holds i. property(), integer j exists B(f ()) Jj 0 . then, due rule (23), ` jexists A(f (f ())) J` 0 . Proposition 5, universally MFA.Conversely, assume {A(a)} 6|= B(a). Since weakly acyclic equalityfree, super-weakly acyclic (Marnette, 2009); show Section 4 (see Theorem19), MFA well. consider arbitrary integer j fact F Jj 0 . Flevel 0 1, since MFA, fact F contain cyclic term. Furthermore,B(a) 6 so, property (), fact F form B(f ()); thus, rule (23)fire introduce facts level greater 1. Consequently, F contain cyclicterm, so, Proposition 5, set universally MFA.Theorem 8. Given set rules , deciding whether MFA w.r.t. instance2ExpTime, deciding whether universally MFA 2ExpTime-hard. resultshold even arity predicates bounded.Proof. (Membership) Let 0 = MFA(), let I0 0 , I1 0 , . . . chase sequence 0 ,let , p, stated proof Proposition 6. number differentatoms constructed terms bounded k = p ; notedouble exponential even bounded. Let k 0 = k + 4; next show whether00MFA w.r.t. decided constructing Ik 0 checking whether C Ik 0 .proof Proposition 6, latter done double exponential time.0Ik 0 = Ik 0 , I0 = Ik 0 , MFA C Ik 0 . Otherwise,0Ik 0 ( Ik 0 ; then, Ik+1clearly contains least one cyclic term = fri (~t)0t0 = fri (~s) subterm ti ~t. Since Ik+1satisfies Claims 13 proof0k+3Proposition 5, D(ti , t) I0 ; rule (20) fact rules without functional0terms applied rules functional terms, C Ik 0 ; thus, C I0 ,MFA Proposition 5.(Hardness) prove claim reduction problem checking |= Q,weakly acyclic set equality-free rules predicates bounded arity,755fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wanginstance, Q = ~y .(~y ) Boolean conjunctive query. Cal et al. (2010b) showthat, I, , Q, deciding |= Q 2ExpTime-complete. next transformI, , Q apply Lemma 7, proves claim.Let 1 = {(~y ) B} B fresh predicate zero arity; clearly, |= Qholds 1 |= B holds.Let 2 I2 obtained eliminating constants rules 1 ; is,initially set I2 = then, rule r constant c occurring r,replace occurrences c fresh variable wc , add atom Oc (wc ) body rOc fresh predicate uniquely associated c, add fact Oc (c) I2 .straightforward see 1 |= B I2 2 |= B.Finally, transform 2 I2 3 , define notation. Let P fresh n+1ary predicate unique n-ary predicate PV, let w fresh variable occurring2 . conjunction atoms , let = P (~t) P (~t, w). Rule (24) obtainedI2 specified below, fresh unary predicate, constant c occurring I2associated distinct, fresh variable vc , ~vc vector variables:^A(w) ~vc .P (vc1 , . . . , vck , w)(24)P (c1 ,...,ck )I2Finally, set 3 contains rule (24) rule(~x, ~z, w) ~y .(~x, ~y , w)rule(~x, ~z) ~y .(~x, ~y ) 2 .(25)Clearly, predicates 3 nonzero arity; rules 3 constant-freeconnected; occurs body rule (24) 2 WA, 3 WA well.Finally, let I3 = {A(a)} fresh constant; induction chase sequences2 I2 , 3 I3 , straightforward show that, integer factP (c1 , . . . , ck ), P (c1 , . . . , ck ) (I2 )i2 P (fc1 (a), . . . , fck (a), a) (I3 )i+13 ,fc1 , . . . , fck skolem functions used skolemise vc1 , . . . , vck rule (24). Thus,I2 2 |= B I3 3 |= B(a), Lemma 7 implies claim.results Theorem 8 somewhat discouraging: known acyclicity notionstypically checked PTime NP. consider MFA upper boundpractically useful acyclicity notions. see two possibilities improving results.Section 3.3 introduce approximation MFA easier check; experiments(see Section 7) show notion often coincides MFA practice. Furthermore,show next complexity lower rules following shape.Definition 9. rule r form (5) -1 rule ~y empty ~x containsone variable.discuss following sections, -1 rules capture (extensions of) Horn DLs.next show BCQ answering MFA checking -1 rules easier generalrules. Intuitively, MFA contains -1 rules, functional termssk(MFA()) unary hence number different terms atoms derivablechase becomes exponentially bounded, shown following theorem.756fiAcyclicity Notions Existential RulesTheorem 10. Let set -1 rules, let instance. Checking whetherMFA w.r.t. ExpTime, checking whether universally MFA ExpTime-hard.Moreover, MFA w.r.t. I, answering BCQ ExpTime-complete.Proof. defer proof hardness claims Section 6, deals evensmaller class rules correspond Horn description logic ontologies. particular,prove hardness BCQ answering Lemma 59, hardness checking whetherMFA w.r.t. Lemma 60. rest proof, show membership results.Let 0 = MFA(); let c number constants instance; let fnumber function symbols rules. Since contains -1 rules, 0 also contains-1 rules; consequently, functional terms sk(0 ) arity 1. Hence,noncyclic term understood sequence f function symbols, totalnumber different noncyclic terms bounded = c (f + 1)f . total numberatoms bounded p , p number predicates maximumarity predicate 0 . Note exponential even fixed. proofProposition 6, show either chase 0 terminates cyclicterm derived exponential time, proves complexity checking whetherMFA w.r.t. ExpTime.Finally, since I0 , MFA, computed exponential time,BCQ answered ExpTime.3.3 Model-Summarising Acyclicity (MSA)high cost checking MFA arises arity function symbols sk()unbounded depth cyclic terms linear . obtain acyclicity notioneasier check, must coarsen structure used cycle analysis. thus nextintroduce model-summarising acyclicity, summarises models reusingconstant satisfy existential quantifier, instead introducing deep terms.Definition 11. Let S, D, Fir specified Definition 3; furthermore, ruler = (~x, ~z) ~y .(~x, ~y ) variable yi ~y , let cir fresh constant unique ryi . Then, MSA(r) following rule, MSA substitution mapsvariable yi ~y cir :^^Fir (yi )MSA(~x, ~z) (~x, ~y )MSAS(xj , yi )MSAyi ~xj ~xset rules, MSA() smallest set contains MSA(r) ruler , rules (18)(19), rule (20) instantiated predicate Fir . Set modelsummarising acyclic (MSA) w.r.t. instance MSA() 6|= C; furthermore,universally MSA MSA w.r.t. .Example 12. Consider set rules Example 1. MSA(r1 ) MSA(r3 )given rules (26) (27), respectively; since r1 r3 contain single existentiallyquantified variable each, omit superscripts Fr1 , Fr3 , cr1 , cr3 sake757fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangclarity. Thus, MSA() consists rules (14), (16), (17), rules (26)(27), rules (18)(19), rule (20) instantiated Fr1 Fr3 .A(x1 ) R(x1 , cr1 ) B(cr1 ) Fr1 (cr1 ) S(x1 , cr1 )(26)B(x3 ) R(x3 , cr3 ) C(cr3 ) Fr3 (cr3 ) S(x3 , cr3 )(27)following table shows chase sequence MSA().A()R(, cr1 )R(cr1 , cr3 )B()R(, cr3 )D(cr3 )C()B(cr1 )S(cr1 , cr3 )D()C(cr3 )D(, cr3 )R(, )S(, cr1 )D(, cr1 )D(cr1 , cr3 )S(, cr3 )Fr1 (cr1 )Fr3 (cr3 )result chase contain C, universally MSA.Note MSA() equivalent set datalog rules: minor differencerules MSA() contain several head atoms, rules clearlytransformed equivalent datalog rules. Thus, MSA checked using datalog reasoner. connection datalog complexity results Dantsin, Eiter, Gottlob,Voronkov (2001) checking entailment ground atom datalog program provideus upper complexity bound checking MSA Theorem 13. complexitydatalog reasoning O(r nv ) r number rules, v maximum numbervariables rule, n size set facts rules applied to; thus,checking MSA feasible rules short v small.Theorem 13. set rules, deciding whether MSA w.r.t. instanceExpTime, deciding whether universally MSA ExpTime-hard. two problemscoNP coNP-hard, respectively, arity predicates bounded.Proof. (Membership) Let 0 = MSA(), note MSA w.r.t.0 6|= C C 6 I0 . total number atoms occurring I0 p ca ,p number predicates, c number constants, maximum aritypredicates 0 ; number clearly exponential bounded. restproof Theorem 8.Assume bounded; number ground atoms I0 becomes polynomial. Furthermore, definition chase, C I0 exist sequence rules r1 , . . . , rn form ri = sequence substitutions 1 , . . . , n{j j | j < i} I0 1 n n n = C. Clearly,assume n p ca , polynomial. Thus, guess two sequences nondeterministic polynomial time, check required property polynomial time.Thus, 0 |= C checked nondeterministic polynomial time, checking whetherMSA w.r.t. coNP.758fiAcyclicity Notions Existential Rules(Hardness) Let set datalog rules, let instance, let Q groundatom. Checking whether |= Q ExpTime-complete general (Dantsin et al., 2001).Furthermore, problem NP-hard arity predicates bounded: ruleencode arbitrary Boolean conjunctive query atoms bounded arity arbitrarilymany variables, answering well known NP-hard.Let 4 I4 obtained proof Theorem 8; then, |= QI4 4 |= B(a), set rules obtained 4 specified Lemma 7universally MFA I4 4 6|= B(a). Finally, existential variableoccurs rule form (23), straightforward see universally MFA0 universally MSA.concluding section, present Theorem 14 Example 15, togethershow MFA strictly general MSA.Theorem 14. set rules MSA (w.r.t. instance I), MFA (w.r.t. I)well.Proof. Let 1 = MFA() let 2 = MSA(). Furthermore, let h mappingground terms constants defined h(t) = cir form fri (. . .), h(t) =constant; atom = P (t1 , . . . , tn ), let h(A) = P (h(t1 ), . . . , h(tn ));instance I, let h(I) = {h(A) | I}. Finally, let I0 1 , I1 1 , . . . chase sequence1 , let I0 2 , I1 2 , . . . chase sequence 2 . Note sk(2 ) = 2differs sk(1 ) former contains constant cir place functional term fri (~x). Please note that, although definition chase applies rulesfunction symbols rules without function symbols, one clearly construct chasefunction-free set rules 2 using order rule applications, including onecorresponding order rule applications chase 1 . Assuming slightmodification, one show straightforward induction h(Ii 1 ) Ii 2i; implies h(I1 ) I2 . Consequently, C 6 I2 clearly implies C 6 I1 ; hence,MSA, MFA well, required.Example 15. Let set rules (28)(31).r1 =A(x) y.R(x, y) B(y)(28)r2 =B(x) y.S(x, y) (y, x)(29)r3 =A(z) S(z, x) C(x)(30)r4 =C(z) (z, x) A(x)(31)straightforward check universally MFA, universally MSA.3.4 Acyclicity Notions Normalisationmentioned Section 2.5, existential rules often normalised particular form;however, cannot destroy acyclicity: set rules MFA, set rulesobtained normalisation MFA well. claim involves certain technicalassumptions treatment equality, postpone formal proofstatement Section 5. Next, however, show normalisationpositive effect acyclicity.759fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangExample 16. Let set containing following rule:A(x) y.[B(x) A(y)](32)specified Section 2.2, rule skolemised follows, causes skolemchase instance = {A(a)} terminate.A(x) B(x) A(f (x))(33)Note, however, atoms B(x) A(y) head rule share variables,normalise rule follows, Q fresh predicate zero arity:A(x) B(x) Q(34)Q y.A(y)(35)straightforward check normalised set rules MFA; fact, normalisedset rules even JA. Intuitively, normalisation, defined Section 2.5, ensuresfunctional symbol introduced normalisation depends variablesrule possible.Normalisation, however, negative effect universal termination, shownfollowing example.Example 17. Let set containing following rule:C(z) R(z, x) B(x) y1 y2 .[R(x, y1 ) R(y1 , y2 ) B(y2 )](36)One readily check universally MFA. let 0 following set rules,obtained replacing conjunction R(y1 , y2 ) B(y2 ) rule head Q(y1 ):C(z) R(z, x) B(x) y1 .[R(x, y1 ) Q(y1 )]Q(y1 ) y2 .[R(y1 , y2 ) B(y2 )](37)(38)Let f1 f2 function symbols used skolemise existential quantifier rule (37)(38), respectively. Since Q() 0 , chase 0 0 derives R(, f2 ())B(f2 ()); then, facts, C(), rule (37) derive Q(f1 (f2 ())), rule(38) derives R(f1 (f2 ()), f2 (f1 (f2 ()))) B(f2 (f1 (f2 ()))). chase 0 0 thuscontains cyclic term, 0 universally MFA.Intuitively, problem occurs critical instance 0 0 also instantiatespredicate Q introduced normalisation. predicates, however, cannot occurarbitrary input instances, use critical instance . Since Q() 6 ,skolem chase 0 derive cyclic term, concludeskolem chase 0 terminates instance contains facts constructed usingpredicates occurring .4. Relationship Known Acyclicity NotionsMany acyclicity notions proposed literature, relationshipspartially investigated. next investigate relationshipMFA, MSA, acyclicity notions known us, produce detailed picturerelative expressiveness. show MFA MSA generalise notions.760fiAcyclicity Notions Existential Rules4.1 Acyclicity DatabasesAcyclicity notions considered databases data integration data exchangescenarios. Weak acyclicity (Fagin et al., 2005) one first notions,spurred research sophisticated notions ensuring chase termination.4.1.1 Super-Weak AcyclicityMarnette (2009) proposed super-weak acyclicity (SWA), generalises weak acyclicityprovided rules equality-free. next recapitulate definition SWA,show MSA MFA strictly general SWA.Definition 18. Let set existential rules variable occursone rule, let sk substitution used skolemise rules .2 place pairhA, ii n-ary atom occurring rule 1 n. set places P 0covers set places P if, place hA, ii P , place hA0 , i0 P 0 substitutions0 exist = A0 0 = i0 . Given variable w occurring ruler = ~y ., sets places In(w), Out(w), Move(w) defined follows:set In(w) contains place hR(~t), ii R(~t) ti = w;set Out(w) contains place hR(~t)sk , ii R(~t) ti = w;set Move(w) smallest set placesOut(w) Move(w)Out(w0 ) Move(w) variable w0 universally quantifiedrule Move(w) covers In(w0 ).SWA dependency graph SWA() contains vertex rule ,edge rule r rule r0 variable x0 occurring bodyhead r0 existentially quantified variable occurring head r existsMove(y) covers In(x0 ). Set super-weakly acyclic (SWA) SWA() acyclic.Marnette (2009) uses slightly different definition: notation placesnotation positions; variable may occur one rule sets In(w),Out(w), Move(w) defined w.r.t. rule variable; rule trigger relationused instead SWA dependency graph. simplicity, Definition 18 introduces SWAstyle JA; however, definitions capture class rules.following theorem shows MSA general SWA. Furthermore,Example 12 argued set rules Example 1 MSA, one readilycheck SWA. Consequently, MSA strictly general SWA.Theorem 19. set rules SWA, universally MSA.2. Substitution sk unique rule Section 2.2; however, since variable occursone rule, w.l.o.g. take sk substitution used skolemise rules .761fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangProof. Let 0 = MSA(), let 0 , 1 , . . . chase sequence 0 , letchase 0 . Furthermore, let function maps constantsmaps ground functional terms (fri (~t)) = cir , fri cir introduced Section 2.2 Definition 11, respectively. Finally, let (P (t1 , . . . , tn )) = P ((t1 ), . . . , (tn )).next prove following property (): rule r , existentially quantified variable yi occurring r, P (~t) P 6 {S, D, C}, tj ~ttj = cir , substitution place hA, ji Move(yi ) exist P (~t) = (A ).proof induction length chase. Since 0 = contain constantform cir , property () holds vacuously 0 . Assume property () holdsk1 , consider arbitrary rule r , existentially quantified variable yi r,fact P (~t) k \ k1 P 6 {S, D, C}, term tj ~t tj = cir . Fact P (~t)derived k head atom H rule r1 MSA(). Let substitutionused rule application; clearly, H = P (~t). Furthermore, let r2 ruler1 = MSA(r2 ), let r3 = sk(r2 ), let H 3 head atom r3 correspondsH; clearly, (H 3 ) = P (~t). H cir position j, r = r1 since r1rule contains cir ; thus, hH 3 , ji Out(yi ) Move(yi ), property () holds.Otherwise, H contains position j universally quantified variable x (x) = cir .Let B1 , . . . , Bn body atoms r1 contain x; clearly, {B1 , . . . , Bn } k1 .atoms satisfy induction assumption, Bm {B1 , . . . , Bn }0 , `i Move(y ) substitu` Bm contains variable x position `, place hBm0 ). Let 0 substitution obtainedtion exist Bm = (Bmsetting 0 (w) = (w) variable w (w) functional term; clearly,0 . then, Move(y ) covers In(x); hence, definition Move,Bm 0 = BmhH 3 , ji Move(yi ), property () holds.0additionally prove following property (): S(cir , cir0 ) i0 ,SWA() contains edge r r0 . Consider arbitrary fact, let yiexistentially quantified variable r corresponding cir , let k smallest integer000S(cir , cir0 ) k . Clearly, S(cir , cir0 ) derived k head atom S(x, cir0 )rule r0 . Let substitution used rule application; thus, (x) = cir . LetB1 , . . . , Bn body atoms r contain x; clearly, {B1 , . . . , Bn } k1 .atoms satisfy property (), Bm {B1 , . . . , Bn } `0 , `i Move(y ) substitution existBm contains variable x position `, place hBm0Bm = (Bm ). then, previous paragraph Move(yi )covers In(x), SWA() contains edge r r0 .Assume MSA, C ; {Fir (t), D(t, t0 ), Fir (t0 )} holdsFir due rules (20). then, since predicate Fir occurs 0 atom Fir (cir ),= t0 = cir . Finally, since axiomatised 0 transitive closure S,clearly SWA() contains path r itself, SWA.rule set Example 1 MSA SWA. Furthermore, known SWAgeneral JA, two notions differ least one rule contains bodyatom least one variable occurs (Krotzsch & Rudolph, 2013).following example shows SWA strictly general JA.Example 20. Let set following rules:r1 =A(x1 ) y.R(x1 , y) R(y, x1 ) R(x1 , x1 )762(39)fiAcyclicity Notions Existential Rulesr2 =R(x2 , x2 ) B(x2 )(40)r3 =B(x3 ) A(x3 )(41)One readily verify SWA, JA.Theorem 19 holds even contains equality predicate, providedaxiomatisation equality (cf. Section 2) taken part input. rule sets,however, SWA, JA, MSA, MFA strictly general WA. discussunderlying problems, well possible solutions, Section 5.4.1.2 Acyclicity RewritingSpezzano Greco (2010) proposed acyclicity notion called Adn-WA. Roughly speaking, one first rewrites set rules another set rules 0 adorning positionspredicates contain infinitely many terms chase; then, one checkswhether 0 WA. rewriting algorithm rather involved, recapitulatedefinition; instead, discuss means example. Spezzano Greco usedexample show Adn-WA subsumed SWA, example also showsAdn-WA subsumed MFA either.Example 21. Let set containing following rules:A(x) y.R(x, y)B(z) R(z, x) A(x)(42)(43)transformation Spezzano Greco (2010) produces set 0 consiststhree groups rules. first group contains rules (44)(47).Ab (x) y.Rbf (x, y)bbbb(44)B (z) R (z, x) (x)(45)B b (z) Rbf (z, x) Af (x)(46)f(47)ff(x) y.R (x, y)n-ary predicate P , transformation introduces predicates form P ,adornmenta string length n letters b f . Intuitively, contains letterb position i, chase construction i-th position P containconstants occurring instance. Rules (44)(47) derived follows. Rule (44)obtained rule (42) marking positions variable x b, effectivelycreates variant rule whose body applicable constants. Variablehead rule (44) occurs existential quantifier, corresponding positionmarked f . Rule (45) obtained rule (43) analogous way. then, sincefacts introduced rule (44) trigger application rule (43), latter rule markedrule (46); predicate Af head rule (46) reflects fact variable x rulebody instantiated atom Rbf (z, x). Finally, facts derived rule (46) triggerapplication rule (42), latter rule instantiated (47). point algorithmterminates: since rule instantiated marking B f head, possibleuse predicate Rff mark body rule (43) consistent way.763fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangsecond group consists rules (48)(50), populate adorned predicatescontents instance.R(x1 , x2 ) Rbb (x1 , x2 )(48)A(x) Ab (x)(49)bB(x) B (x)(50)third group consists rules (51)(56), gather content adornedpredicate P fresh output predicates P .Rbb (x1 , x2 ) R(x1 , x2 )(51)Rbf (x1 , x2 ) R(x1 , x2 )(52)ffR (x1 , x2 ) R(x1 , x2 )b(53)(x) A(x)(54)Af (x) A(x)(55)bB (x) B(x)(56)straightforward check MFA. contrast, 0 WA; furthermore,Spezzano Greco (2010) show that, instance vector ground terms~t, P (~t) I0 P (~t) . Since 0 WA, I0 finite, and,previously mentioned property, finite well.following example shows MFA subsumed Adn-WA, indicatesMFA Adn-WA incomparable.Example 22. Let set containing following rules:A(x) y.R(x, y) B(y)r1 =S(z, x) B(x) y.S(x, y)r2 =(57)(58)rules first group set 0 obtained transformation shown below;show rules second third group sake brevity.Ab (x) y.Rbf (x, y) B f (y)bbbbf(59)(z, x) B (x) y.S (x, y)(60)bf (z, x) B f (x) y.S ff (x, y)(61)fffff(z, x) B (x) y.S (x, y)(62)last rule ensures WA dependency graph 0 contains special edgeposition ff |2 itself; thus, 0 WA, therefore Adn-WA. contrast,one readily verify MFA.Spezzano Greco (2010) also proposed several optimisations transformation,discussion scope paper. seen unfoldingrules certain number chase steps. seems close idea Baget764fiAcyclicity Notions Existential Ruleset al. (2011b), propose run chase fixed number steps checkingpotential cycles. similar effect could obtained extending notion MFAcheck terms contain function symbol nested fixed number times.Finally, note transformation Spezzano Greco (2010) independentnotion used check acyclicity transformed rule set; hence, givenarbitrary acyclicity notion X, one define Adn-X obvious way. Given arbitrarynotions X X , obvious Adn-X Adn-Y ; consequently,Adn-X 6 MFA X WA X. contrast, however, obviouswhether inclusion Adn-X Adn-Y strict whenever inclusionX strict, whether MFA contained Adn-X X WA X.Finally, conjecture X Adn-X holds arbitrary notion X,formal proof conjecture. Due complex nature rewriting,refrain analysis relationships.4.1.3 Monitor GraphMeier et al. (2009) propose idea similar spirit MFA. idea trackchase step additional data structure called monitor graph. chaseinfinite, monitor graph contains cycles arbitrary length; conversely, oneshow monitor graph contain cycle fixed length, chaseguaranteed terminate. idea closely related MFA, note definitionMFA semantic; hence, one use arbitrary theorem proving technique checkwhether MFA() |= C. contrast, notion monitor graph specifically tiednonoblivious chase. well known result nonoblivious chase dependsorder rules applied; consequently, set rules identified cyclicacyclic depending selected rule application strategy. dependence,difficult compare monitor graph approach acyclicity notions.4.2 Acyclicity Knowledge RepresentationExistential rules capture knowledge representation formalisms Horn fragmentsdescription logics (see Section 6), conceptual graphs (Baget, 2004; Baget et al., 2011a),datalog rules (Cal et al., 2010a), acyclicity notions allow materialisationbased query answering knowledge bases. context, Baget (2004) Baget et al.(2011a) proposed notion acyclic graph rule dependencies (aGRD). Intuitively, aGRDintroduces rule dependency relation r1 r2 means applicationrule r1 instance subsequently trigger application rule r2 . relationacyclic, rule trigger skolem chase terminates arbitraryinstance. formalised follows.Definition 23. rule dependency relation set rules definedfollows. Let r1 = 1 ~y1 .1 r2 = 2 ~y2 .2 arbitrary rules , letsk(r1 ) = 1 10 sk(r2 ) = 2 20 . Then, r1 r2 exist instanceI, substitution 1 variables sk(r1 ), substitution 2 variables sk(r2 )1 1 I, 2 2 6 I, 2 2 10 1 , 20 2 6 10 1 . Set acyclicgraph rules dependencies (aGRD) relation acyclic.765fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangDefinition 23 differs original definition Baget (2004) several ways. First,Baget uses fresh nulls capture effect existential quantifiers, whereas Definition 23uses skolem functions; however, change resulting relation way.Second, Baget require 20 2 6 10 1 . condition intuitively ensuresapplication r1 enables r2 derive something new; analogous optimisationsproposed Deutsch et al. (2008) Greco et al. (2012). clear Definition23 stronger one Baget. unify notions used various partspaper, included optimisation Definition 23; however, nevertheless callresulting stronger notion aGRD.following example shows aGRD, even weaker form originally proposedBaget (2004), contained SWA.Example 24. Let set consisting following rule:A(z1 , x, z2 ) B(z2 ) y1 y2 .A(x, y1 , y2 )r=(63)see r r hold, consider skolemisation r0 r:A(z1 , x, z2 ) B(z2 ) A(x, f1 (x), f2 (x))sk(r) =(64)let arbitrary instance, let 1 2 arbitrary substitutions{A(z1 , x, z2 )1 , B(z2 )1 } {A(z1 , x, z2 )2 , B(z2 )2 } 6 I. Since instance containsconstants, atom A(x, f1 (x), f2 (x))1 form A(a, f1 (a), f2 (a)); then,{A(z1 , x, z2 )2 , B(z2 )2 } {A(a, f1 (a), f2 (a))} hold, must 2 (z2 ) = f2 (a);thus, B(z2 )2 = B(f2 (a)) contained I, impossible since instancethus contain functional terms. Note additional condition Greco et al.(2012) plays role here. Thus, r 6 r, aGRD even weaker formBaget (2004). However, one easily check SWA.However, aGRD seems rather weak notion: following example shows, evenset rules without existential quantifiers cyclic according criterion.Example 25. Let set consisting following rules:r1 =A(x) B(x)(65)r2 =B(x) C(x)(66)r3 =C(x) A(x)(67)see r1 r2 , let = {A(a)}, let = {x 7 a}, note A(x) I, B(x) 6 I,B(x) {B(x)}, C(x) 6 {B(x)}. Analogously, taking = {B(a)} getr2 r3 , taking = {C(a)} get r3 r1 . Consequently, aGRD. However,obviously WA since contain existentially quantified variables.Baget et al. (2011a) suggested rule dependencies become powerfulcombined arbitrary acyclicity notion X. Intuitively, main idea usepartition set rules strongly connected components, check whethercomponent X; call notion X . idea formalised follows.766fiAcyclicity Notions Existential RulesDefinition 26. Let set existential rules, let rule dependency relation. Relation extended arbitrary sets C C 0 C C 00rules r C r0 C 0 existSn r r . dependency partitionsequence sets 1 , . . . , n = i=1 , strongly connectedcomponent , j 6 j 1 < j n.Let X arbitrary acyclicity notion. Then, X dependency partition1 , . . . , n exists that, 1 n, X, consistssingle rule ri ri 6 ri .aGRD, strongly connected component contains single rule riri 6 ri . Definition 26 consider special case consistssingle rule depend itself, SWA would extend aGRD; example,rule Example 24 would SWA . extra condition Definition 26 thusensures aGRD contained X regardless choice X, aGRDunderstood acyclicity notion obtained extending empty notion (i.e.,notion rule set acyclic) rule dependencies.next present two simple results. Proposition 27 precludes inclusions certainacyclicity notions thus help us establish proper inclusions many acyclicitynotions. Furthermore, Proposition 28 shows combining acyclicity notion containedSWA rule dependencies creates strictly stronger acyclicity notion; noteholds even weaker form rule dependencies originally proposed Baget (2004).Proposition 27. Let X acyclicity notions X . Then, X .Furthermore, exists set \ X whose rule dependency relation cyclecontaining rules , 6 X , 6 X , X ( .Proof. Relationship X immediate Definition 26. Assumeexists set rules \ X whose rule dependency relation cycle containingrules . Definition 26, 6 X implies 6 X , implies .then, clearly 6 X 6 X , latter clearly implies X ( .Proposition 28. acyclicity notion X X SWA, X ( XaGRD 6 X.Proof. Set Example 24 aGRD thus X ; however, SWAhence X either.MSA also contain aGRD; however, unlike SWA, claim dependsoptimisation Definition 23. analysis relationship MSA versionrule dependencies originally proposed Baget (2004) scope paper.Example 29. Let set consisting following rules:r1 =R(x1 , x1 ) U (x1 , z) U (x2 , z) R(x1 , x2 )(68)r2 =R(z, x) y.T (x, y)(69)r3 =(z, x) y.U (x, y)(70)767fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangobvious r1 r2 , r1 6 r3 , r2 6 r1 , r2 6 r2 , r2 r3 , r3 6 r2 , r3 6 r3 . nextargue r1 6 r1 r3 6 r1 , implies aGRD.see r1 6 r1 , assume application r1 instance produces atomform R(a, b); due atom R(x1 , x1 ) body r1 , R(a, a) I. let0 = {R(a, b)}; since R(a, a) I, rule application derives something new6= b. assume substitution 2 exists makes r1 applicable 0 I;rule application must use fact R(a, b), implies R(x1 , x1 )2 = R(a, b);however, impossible since 6= b. Consequently, r1 6 r1 , holds evenversion rule dependencies Baget (2004).Furthermore, see r3 6 r1 , assume r3 applicable instance I,rule application derives fact form U (a, f (a)). let 0 = {U (a, f (a))},assume substitution 2 exists makes r1 applicable 0 I;rule application must use fact U (a, f (a)), implies 2 (x1 ) = 2 (x2 ) =2 (z) = f (a). Furthermore, rule r1 applicable R(a, a) I; then, rule application derive something new since R(x1 , x2 )2 = R(a, a). Consequently,r3 6 r1 ; however, unlike previous paragraph, claim depends optimisationDefinition 23.Consider chase MSA() shown (facts involving predicatesD, Fr2 , Fr3 omitted clarity). chase result contains C, MSA,thus aGRD 6 MSA; corollary, also get MSA ( MSA .R(, )(, cr2 )U (cr2 , cr3 )(, )U (, cr3 )S(cr2 , cr3 )U (, )S(, cr2 )R(, cr2 )(cr2 , cr2 )CS(cr2 , cr2 )S(, cr3 )Note R(, cr2 ) derived R(, ), U (, cr3 ), U (cr2 , cr3 ), latter twofacts obtained distinct instantiations MSA(r3 ). Rule dependencies, however,analyse rule applicability w.r.t. sk(r3 ), closer actual skolem chase.contrast result, Theorem 32 show extending MFA ruledependencies create stronger notion: MFA coincides MFA, impliesX MFA notion X X MFA. Towards goal, showLemma 30 independent rule sets evaluated independently, Lemma 31single rule depend applied once.Lemma 30. Let 1 2 sets existential rules 2 6 1 , let Fset ground facts containing function symbol sk(2 ). Then, F1 2 = (F1 )2 .Proof. Let F0 = F1 ; let F0 , F1 , . . . chase sequence F0 2 where, convenience, assume Fi obtained Fi1 single rule application (thisassumption clearly w.l.o.g.); let F 0 = (F0 )2 . definition skolem chase,0clearly F F1 2 . Furthermore, assume F1 2 6 F 0 ; then, skolemisedrule r1 sk(1 ) form r1 = 1 (~x1 ) 1 (~x1 ) exists F 0 ( r1 (F 0 ). Fixsmallest Fi ( r1 (Fi ) (we clearly > 0), let 1 substitution usedapplication r1 . Furthermore, let r2 sk(2 ) skolemised rule form768fiAcyclicity Notions Existential Rulesr2 = 2 (~x2 ) 2 (~x2 ) used derive Fi Fi1 , let 2 substitutionused application r2 . consider arbitrary term f (~x2 ) head r2assume f (~x2 )2 occurs Fi1 ; since function symbol f private r2 , headr2 must already instantiated 2 ; then, 2 2 Fi1 , contradictsassumption 2 2 Fi \ Fi1 . Thus, following property (?):term f (~x2 ) occurring head r2 , ground term f (~x2 )2occur Fi1 .Finally, let function maps ground term Fi1 fresh distinct constant;let = (Fi1 ); let 20 substitution defined 20 (w) = (2 (w)) variable wr2 ; let 10 substitution defined follows variable w r1 :10 (w) = f ((~t)) 1 (w) = f (~t) f function symbol private r2 ;10 (w) = (1 (w)) otherwise.clearly 2 20 2 20 6 I; furthermore, (?), also 1 10 2 201 10 6 2 20 . Moreover, 1 10 6 follows assumption smallestinteger Fi ( r1 (Fi ). then, Definition 23, r2 r1 and, consequently,2 1 well, contradiction.Lemma 31. Let = {r} singleton rule set r 6 r, let F set factscontaining function symbol sk(). Then, F = (F ).Proof. Let F0 = F , let F0 , F1 , . . . sets factsFi+1 unionFi resultdistinctsingle application r F0 ; clearly, Fi = (F0 ).assume Fi ( ( Fi ); analogously proof Lemma 30, one showr r, contradiction; omit details sake brevity.Theorem 32. Let arbitrary set rules let arbitrary instance.MFA w.r.t. I, also MFA w.r.t. I.Proof. Assume MFA ; let arbitrary instance; let 1 , . . . , Sndependency partition ; let 0 = I0 = I; and, 1 n, let = i`=1 `Ii = (Ii1 ). definition dependency partitions, 6 i1 holds1 n. next show that, 0 n, following two properties hold:(a) Ii = (I0 ),(b) Ii contain cyclic term.Set I0 contain functional terms hence trivially satisfies (a) (b).consider arbitrary 0 < < n Ii1 satisfies (a) (b). induction assumption, Lemma 30, 6 i1 , = i1 , (I0 )= ((I0 )i1 )i ; thus,Ii satisfies (a). see Ii satisfies (b), note function symbol used skolemiserules used skolemise rules i1 ; call property (?).two ways compute Ii .Assume = {ri } ri 6 ri . Lemma 31, Ii = ri (Ii1 );then, Ii contain cyclic term due (?).769fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangMFA, Ii contain cyclic term due (?) Proposition 5.= contain cyclicclaim =nnterm; then, MFA w.r.t. Proposition 5.Combinations rule dependencies acyclicity notions also considereddatabases: Deutsch et al. (2008) proposed notion stratification, Meier et al. (2009)developed idea proposed notion c-stratification. Roughly speaking,notion checks whether strongly connected components certain rule dependencygraph WA. rule dependency notions, however, developed nonobliviouschase thus different Definition 23, illustrated following rule:r=R(z, x) y.R(x, y) R(y, y)(71)skolem chase critical instance r infinite, r r Definition 23.contrast, rule r pose problems nonoblivious chase. particular, assumerule matched atom R(t1 , t2 ), derives R(t2 , t3 ) R(t3 , t3 ).Then, rule r applicable R(t2 , t3 ) R(t3 , t3 ) since either case head atomsatisfied; hence, rule dependency graphs Deutsch et al. Meier et al.empty. results summarised follows: rule set satisfies notionDeutsch et al., instance exists finite nonoblivious chase sequence;furthermore, satisfies notion Meier et al., instance chasesequences (regardless rule application strategy) finite. Meier (2010) discussesdetail subtle differences notions. Since notions consider differentchase variant, discuss paper.4.3 Acyclicity Logic ProgrammingAcyclicity notions also considered context disjunctive logic programsfunction symbols answer set semantics, goal ensuring givenprogram finitely many answer sets, finite. notions must dealdisjunction nonmonotonic negation, one main differencesnotions considered thus far. notions logic programming, however, applicablerules without disjunction nonmonotonic negation, case ensure terminationskolem chase. Therefore, section compare specialisationsacyclicity notions logic programming aGRD, WA, JA, SWA, MSA, MFA.simplify definitions apply skolemised existential rulesthat is,present parts definitions handle disjunctions head nonmonotonicnegation function symbols body.4.3.1 Finite Domain NotionCalimeri et al. (2008) proposed finite domain (FD) notion. next recapitulatedefinition, style Greco et al. (2012), come useful Section4.3.3 introduce -acyclicity. approaches use argument graph determinepossible ways propagating ground terms positions chase. definitionargument graph WA dependency graph (see Section 2.4),770fiAcyclicity Notions Existential Ruleswithout distinction regular special edges. simplify presentation,consistently use WA dependency graph instead argument graph.Definition 33. Let set rules. position P |i -recursive position Q|jWA dependency graph WA() contains cycle (consisting regular and/or specialedges) going P |i Q|j . set PosFD () finite domain positionslargest set positions that, position P |i PosFD (), rule rform r = (~x, ~z) ~y .(~x, ~y ), head atom r form P (~t), followingconditions satisfied:i-th component ~t variable x ~x, PosB (x) PosFD () 6= ;i-th component ~t variable ~y , then, variable x ~x,position Q|j PosB (x) PosFD () exists -recursive P |i .Set FD PosFD () coincides set positions .Note notion -recursive positions introduced symmetric: P |i-recursive Q|j , Q|j also -recursive P |i . Furthermore, note Calimeriet al. (2008) defined FD follows:set rules FD if, rule r = (~x, ~z) ~y .(~x, ~y ) , atomQ(~t) head r, j-th term ~t existential variable y,variable x ~x, exists position P |i PosB (x) Q|j-recursive P |i .Conditions definition clearly correspond conditions Definition 33;then, since PosFD () defined maximal set satisfying conditions, twodefinitions FD coincide.next show WA strictly contained FD. end, first prove WAcontained FD, present example showing inclusion strict.Proposition 34. set rules WA, FD.Proof. Let set rules FD. Then, exist rule r , atom Q(~t)head r, j-th term ~t equal existential variable y, variable x ~xposition P |i PosB (x) -recursive Q|j . set PosB (x) empty (~xcontains precisely variables occurring body head rule),choose arbitrary position P |i PosB (x). WA dependency graph WA()contains special edge P |i Q|j . Furthermore, since Q|j -recursive P |i ,graph WA() contains cycle going P |i Q|j . Thus, WA() clearly containscycle containing special edge, WA.Example 35. Let set containing rules (72) (73).r1 =R(z, x) A(x) y.S(x, y)S(x1 , x2 ) R(x1 , x2 )r2 =771(72)(73)fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangSet WA since WA dependency graph contains special edge R|2 S|2regular edge S|2 R|2 . However, FD position S|2 -recursiveA|1 PosB (x). Together Proposition 34, conclude WA ( FD.addition, r1 r2 r2 r1 . Section 4.3.2 prove FD JA;hence, FD ( FD , WA ( FD , FD 6 WA Propositions 27, 28, 34.4.3.2 Argument-Restricted Rule SetsLierler Lifschitz (2009) proposed notion argument-restricted rule sets, whosedefinition summarise next.Definition 36. argument ranking set rules function assignsnonnegative integer position following conditions satisfiedrule r , universally quantified variable x r, existentially quantifiedvariable r:1. P |i PosH (x), Q|j PosB (x) exists (P |i ) (Q|j );2. P |i PosH (y), Q|j PosB (x) exists (P |i ) > (Q|j ).Set argument restricted (AR) argument ranking exists.argument-restricted set rules finite skolem chase arbitrary instance:straightforward induction chase sequence, one show dep(ti ) (P |i )ground fact P (t1 , . . . , tn ) derived chase 1 n.next show JA strictly general AR. Towards goal, firstprove auxiliary lemma establishes relationship set Movedefinition JA argument ranking; next, use lemma prove AR JA;finally present example shows inclusion proper.Lemma 37. Let set rules, let argument ranking , letexistentially quantified variable , let Move(y) set positions useddefinition JA. position P |i Move(y), position Q|j PosH (y) exists(P |i ) (Q|j ) holds.Proof. Let existentially quantified variable occurring rule r ,consider arbitrary position P |i Move(y). prove claim inductiondefinition Move(y). base case P |i PosH (y) trivial. AssumeP |i PosH (x) variable x occurring rule r0 , PosB (x) Move(y),P |i needs added Move(y). definition argument ranking sinceP |i PosH (x), position P 0 |` PosB (x) exists (P |i ) (P 0 |` ). then, sinceP 0 |` PosB (x) Move(y), induction hypothesis position Q|j PosH (y)exists (P 0 |` ) (Q|j ). Thus, (P |i ) (Q|j ) holds, required.Theorem 38. set rules AR, JA.Proof. Assume AR, let argument ranking , let JA() JAdependency graph . next prove following claim: edge JA()variable y1 variable y2 , position Q|j PosH (y2 ), exists position772fiAcyclicity Notions Existential RulesP |i PosH (y1 ) (P |i ) < (Q|j ). Consider arbitrary edge y1 y2JA() arbitrary position Q|j PosH (y2 ). definition JA dependencygraph, rule r contains y2 also contains universally quantified variable xx occurs head r PosB (x) Move(y1 ). Since argument ranking, position P 0 |` PosB (x) exists (P 0 |` ) < (Q|j ). Since P 0 |` Move(y1 ),Lemma 37 position P |i PosH (y1 ) exists (P |i ) (P 0 |` ). Thus,(P |i ) < (Q|j ), claim holds. then, claim clearly implies JAdependency graph JA() acyclic, therefore JA.Example 39. Let set consisting following rules:r1 =R(z1 , x1 ) y1 .S(x1 , y1 )(74)r2 =R(z2 , x2 ) y2 .S(y2 , x2 )(75)r3 =S(x3 , x4 ) (x3 , x4 )(76)r4 =(x5 , x6 ) (x6 , x5 ) R(x5 , x6 )(77)Let argument ranking . Then, (R|2 ) < (S|2 ) due (74); (R|2 ) < (S|1 )due (75); (S|1 ) (T |1 ) (S|2 ) (T |2 ) due (76); (T |2 ) (R|2 )(T |1 ) (R|2 ) due (77). Together, observations contradictory, cannot exist AR. contrast, Move(y1 ) = {S|2 , |2 } Move(y2 ) = {S|1 , |1 },JA.addition, r1 r3 , r2 r3 , r3 r4 , r4 r1 , r4 r2 ; hence,AR ( AR , AR ( JA , JA 6 AR Theorem 38 Propositions 27 28.Lierler Lifschitz (2009, Thm. 4) proved AR strictly general FD.next present example shows FD ( AR, also settles relationshipsFD AR .Example 40. Let set consisting following rules:A(x) y.R(x, y)r1 =R(x1 , x2 ) S(x1 , x2 )r2 =r3 =S(z, x) B(x) A(x)(78)(79)(80)WA dependency graph contains special edge A|1 R|2 , well regularedges R|2 S|2 S|2 A|1 ; thus, R|2 -recursive A|1 . Consequently,rule (78) cannot satisfy conditions Definition 33, R|2 6 PosFD (),thus FD. contrast, AR, evidenced following argument ranking:= {A|1 7 0, B|1 7 0, R|1 7 0, R|2 7 1, S|1 7 0, S|2 7 1}addition, r1 r2 , r2 r3 , r3 r1 ; hence, FD ( FD , FD ( AR ,AR 6 FD Propositions 27 28.Finally, note -restricted programs Gebser et al. (2007) -restrictedprograms Syrjanen (2001) included FD AR; thus, restrictedskolemised existential rules, notions also included JA.773fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang4.3.3 -AcyclicityGreco et al. (2012) recently proposed notion -acylicity logic programsfunction symbols. original definition -acyclicity rather complex, nextpresent simplified version -acyclicity applicable existential rules. unifynaming style notions paper, often write -acyclicity A.Greco et al. (2012) introduce notion activation graph, tracks whether ruletrigger another rule. notion closely related notion rule dependenciesDefinition 23, requirement arbitrary finite set ground facts(possibly containing functional terms). understand latter needed logicprogramming, consider following logic program:r1 =A(x) B(x) A(f (x))(81)r2 =A(x) B(x) B(f (x))(82)restrict set Definition 23 instance, r1 6 r2 r2 6 r1 ; however,skolem chase r1 , r2 , facts A(a) B(a) infinite. Intuitively, r1 r2 containfunction symbol f , determine whether application r1 triggerapplication r2 , must allow set Definition 23 contain facts B(f (a)).setting, however, function symbols introduced skolemisation thusprivate rule, allows us restrict set Definition 23 facts withoutfunctional terms. Thus, rest section, simply reuse rule dependencyrelation Definition 23, gives us slightly stronger version existentialrules one proposed Greco et al. (2012).Furthermore, Greco et al. (2012) handle logic programming rules functional termsbody. rules, however, considered paper, allows us omitdefinition labelled argument graph simplify notion propagation graphsubset WA dependency graph.ready present simplified version -acyclicity applicableexistential rules.Definition 41. Let set rules. rule dependency relation takenDefinition 23, set finite domain positions PosFD () taken Definition 33.set safe positions , written PosS (), least set positionsPosFD () PosS (), P |i PosS () if, rule r ,least one following conditions satisfied:P occurs head r, contain cycle going r,atom P (~t) head sk(r) variable x occurs i-th component ~t, PosB (x) PosS () 6= .position affected safe. propagation graph PG()affected positions vertices, edges PG() defined weak acyclicity,restricted affected positions. set -acyclic (A) PG() containcycle involves special edge.774fiAcyclicity Notions Existential Rulesorder relate notions considered thus far, first establish containment relationships. obvious Definition 41 FD A: positionsfinite domain, also safe propagation graph empty. Furthermore,set rules Example 40 actually (all positions safe), FD; hence,Proposition 27, FD ( A, FD ( , 6 FD . Next, Proposition 42observes aGRD contained A, Theorem 43 shows that, perhaps somewhatsurprisingly, contained AR .Proposition 42. set rules aGRD, A.Proof. rule dependency relation acyclic, first safety conditionDefinition 41 positions safe; then, PG() empty, A.Theorem 43. set rules , AR .Proof. claim clearly follows following property: rule dependency relationone strongly connected component A, AR. Thus, assumerule r occurs cycle . next construct mapping assignsnonnegative integer position , show argument ranking. rest proof, write p1p2 WA() (see Section 2.4) contains path(consisting regular and/or special edges) position p1 position p2 .Due assumption , first item Definition 41 never applies. Furthermore,let function maps set positions another set positions follows:(S) = {P |i | PosB (x) 6= r , atom P (~t) head sk(r),variable x occurring i-th component ~t}Let 0 (S) = S, k (S) = (k1 (S)) k > 0, (S) = k (S). Definition 41 obvious PosS () = (PosFD ()).next define mapping . rest proof, let set containingposition p PosFD () existentially quantified variable existsp PosH (y). Furthermore, use convention max = 0.position p PosFD (), define (p) follows:0|{p | p0p p0 6= p}| + 1(p) =|{p0 | p0p}|pp6position p PosS () \ PosFD (), define (p) follows:h(p) = min{k | p k (PosFD ())} + [max{(q) | q PosFD ()}]position p p 6 PosS (), define (p) follows, m(p)maximum number special edges occurring PG() path ending p:(p) = m(p) + 1 + [max{(q) | q PosS ()}]Since , PG() contain cycle involving special edge, m(p)always nonnegative integer (p) correctly defined.775fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangnext show argument rankingthat is, satisfies conditionsDefinition 36. end, consider arbitrary rule r , arbitrary existentiallyquantified variable r, arbitrary universally quantified variable x r, arbitraryposition P |i PosH (y); following cases.P |i PosFD (). Definition 33, position Q|j PosB (x) PosFD () exists-recursive P |i . Thus, P |i 6 Q|j ; furthermore, Q|jP |idefinition WA(). Together, latter two properties imply following:{p0 | p0Q|j p0 6= Q|j } {p0 | p0P |i p0 6= P |i }Q|j , inclusion strict since Q|j contained set righthand side, set left-hand side; thus, (Q|j ) < (P |i ) holds,required. Q|j 6 , (Q|j ) < (P |i ) holds since definition ensures(P |i ) (Q|j ) least 1.P |i PosS () \ PosFD (). Let k smallest number P |i k (PosFD ()).definition , exists position Q|j PosB (x) k1 (PosFD ()),k 1 (Q|j ) definition . Thus, (P |i ) > (Q|j ) holds, required.P |i 6 PosS (). first possibility position Q|j PosB (x) PosS ()exists; then, definition , (Q|j ) < (P |i ), required.second possibility exists affected position Q|j PosB (x); then,Q|j least one less incoming special edge PG() P |i ; thus, also(Q|j ) < (P |i ), required.complete proof, must also consider arbitrary position P |i PosH (x); however,cases analogous above, omit sake brevity.place precisely landscape acyclicity notions, present three examplesdisprove relevant containment relationships. Greco et al. (2012) stated ARstrictly contained A, unable find formal proof statement;fact, Example 44 shows case, actually ( AR holds.Moreover, Example 45 shows 6 MSA. Finally, Example 46 shows WA 6 A.Example 44. Let set consisting following rules:A(x) y.R(x, y)r1 =R(x1 , x2 ) S(x1 , x2 )r2 =r3 =S(z, x) B(x) A(x)(83)(84)(85)r4 =R(z, x) (x, x)(86)r5 =(x, z) R(x, x)(87)r6 =(z1 , x) R(z2 , x) y.T (x, y)(88)One readily verify following mapping positions nonnegative integersargument ranking := {A|1 7 0, B|1 7 0, R|1 7 1, R|2 7 1, S|1 7 1, S|2 7 1, |1 7 1, |2 7 2}776fiAcyclicity Notions Existential Rulesnext argue A. First, rule dependency relation holds (at least)pairs rules shown below. Thus, rule occurs cycle,strongly connected component .r1 r2r2 r3r3 r1r1 r4r4 r5r5 r2r5 r6r6 r5Second, WA dependency graph contains special edge A|1 R|2 duerule r1 , regular edge R|2 S|2 due rule r2 , regular edge S|2 A|1 duerule r3 ; consequently, R|2 -recursive A|1 ; then, rule r1 satisfyconditions Definition 33, R|2 6 PosFD (). Furthermore, due rule r4 ,|1 6 PosFD () |2 6 PosFD () well. Finally, R|1 6 PosFD () due rule r5 .Consequently, set finite domain positions given PosFD () = {A|1 , B|1 , S|1 }.Third, argue PosS () = PosFD (). particular, need extendPosS () R|2 : position R|2 occurs head rule r5 , since |2 finitedomain position r5 occurs cycle , neither condition Definition 41 holds.Analogously, positions |1 |2 need added PosS () either.Fourth, since positions R|2 , |1 , |2 affected, propagation graph PG()contains special edge |2 due rule r6 . Consequently, A.Finally, since strongly connected component , example also showsAR 6 AR 6 ; then, Theorem 43, ( AR .Example 45. Let set rules Example 29. explained example,aGRD, MSA thus also JA, AR, FD. Proposition 42, A,implies 6 MSA, thus 6 SWA, 6 JA, 6 AR, 6 FD.Example 46. Let set consisting following rules:r1 =R(x1 , x1 ) y1 y2 .[A(x1 ) S(y1 , x1 ) S(x1 , y2 )](89)r2 =A(x2 ) B(x2 )(90)r3 =B(x3 ) R(x3 , x3 )(91)r4 =S(x4 , x4 ) y3 y4 .[C(x4 ) R(y3 , x4 ) R(x4 , y4 )](92)r5 =C(x5 ) D(x5 )(93)r6 =D(x6 ) S(x6 , x6 )(94)Note r1 6 r4 r4 6 r1 , rule dependency relation two stronglyconnected components: first one consists r1 , r2 , r3 , second one consistsr4 , r5 , r6 . Moreover, strongly connected component WA, WA .contrast, position -recursive itself, PosFD () = . Moreover,position occurs head rule (i) appears cycle (ii)satisfy second safety condition Definition 41; hence, PosS () = , positions affected. then, PG() = WA(), A.may seem counterintuitive AR 6 A, ( AR . Intuitively, notionsafe positions Definition 41 uses rule dependency relation, allows usconstruct example AR. , extra condition alwaysapplied rules occur cycle; thus, notion safe positions collapsesnotion weaker AR, turn allows subsumed AR .777fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangMFA = MFAMSAMSASWASWAJAJAARARAdn-WAFDFDWAWAaGRDFigure 1: Landscape Acyclicity Notions4.4 Landscape Acyclicity Notionsobtain complete picture relative expressiveness acyclicity notions considered paper, make following observations.rule set Example 15 MFA MSA, one readily verifyr1 r2 r3 r4 r1 ; then, MSA ( MFA = MFA Proposition 27.rule set Example 20 SWA JA, one readily verifyr1 r2 r3 r1 ; then, JA ( SWA SWA 6 JA Proposition 27.rule set Example 1 MSA SWA, one readily verifyr1 r3 r4 r5 r2 r1 ; then, SWA ( MSA MSA 6 SWA Proposition 27.rule set Example 22 aGRD: r1 6 r1 , r1 6 r2 , r2 6 r1 , r2 6 r2 .Thus, aGRD 6 Adn-WA.rule set Example 22 FD: assume positions rule setfinite domain without violating conditions Definition 33. Thus, FD 6 Adn-WA.landscape acyclicity notions considered paper shown Figure 1.inclusions notions shown figure strict: notion X reachablenotion via one (directed) arcs, X strictly general .Furthermore, inclusions also complete: notion X reachable notionvia one (directed) arcs, X contain .778fiAcyclicity Notions Existential Rules5. Handling Equality via Singularisationacyclicity notions presented far provide special provision equality predicate. set rules contains equality predicate, one always axiomatise equalityexplicitly check acyclicity. precisely, acyclicity (undernotion introduced thus far) guarantees termination skolem chase . Furthermore,note MFA MSA defined entailment checks first-order logic equality,effectively incorporates rules equality checks even rules (1)(4)explicitly given; however, effect definition same.handling equality explicitly may simple, approach ensuretermination skolem chase many practically relevant cases. particular,following example shows equalities terms tend proliferate skolemchase, lead non-termination.Example 47. Consider set rules containing rules (95)(96).A(x) B(x) y.[R(x, y) B(y)]R(z, x1 ) R(z, x2 ) x1 x2(95)(96)skolem chase derives following infinite set facts:R(, f ())B(f ()) f () A(f ())R(f (), f (f ))) B(f (f ()))...Thus, universally MFA Proposition 5, Theorem 14 universallyMSA either.worth noticing presence equality WA longer subsumed MFAhence notions become incomparable. explained Section 2.4, WAapplied rules containing equality predicate (and without explicit axiomatisationequality). treatment, rules Example 47 WA. This, however,contradict results Section 4: WA require explicit axiomatisationequality ensures termination nonoblivious chasean optimised chase variantexpands existential quantifiers necessary handles equality replacingequal terms canonical representatives. contrast, results Section 4 ensuretermination skolem chase; since chase variant uses explicit axiomatisationequality, results hold equality-free rules (or, equivalently, rulescontaining explicit axiomatisation equality). rules Example 47 WAequality axiomatised explicitly, explains apparent mismatch Section 4.order use skolem chase rule sets ones Example 47, Marnette(2009) proposed singularisation technique. Roughly speaking, singularisation replacesequality predicate fresh binary predicate Eq clarify twotreated differently; furthermore, axiomatises Eq reflexive, symmetric, transitive,introduce replacement rules analogous (4); finally, modifies rulestake lack replacement rules account. chase transformed ruleset model , used answer queries particular welldefined way. modification , however, nondeterministic: many waysmodify and, may ensure termination skolem chase, requiredso. next recapitulate definition singularisation Marnette (2009).779fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangDefinition 48. marking Mr rule r form (5) mapping assignsvariable w ~x ~z single occurrence w ; marked occurrence w rulewritten w . occurrences w unmarked, occurrences constantsunmarked well. set rules, marking contains exactly one marking Mrr . Let Eq fresh binary predicate occurring . singularisationset Sing(, ) contain rulesEq(x, x)(97)Eq(x1 , x2 ) Eq(x2 , x1 )(98)Eq(x1 , x2 ) Eq(x2 , x3 ) Eq(x1 , x3 )(99)and, rule r , rule obtained r replacing atom atomEq(s, t), replacing unmarked occurrence term body atom freshvariable z 0 adding atom Eq(t, z 0 ) rule body.Note Sing(, ) unique renaming fresh variables. Furthermore,note rule (97) transformed safe rule explained Section 2.2. Finally,note Sing(, ) equality-free (since Eq different predicates); therefore,specific treatment equality needed computing chase checking acyclicity.Example 49. Singularisation marked rule (100) produces rule (101).A(x ) B(x) R(x, z ) C(x)(100)A(x) B(x1 ) R(x2 , z) Eq(x, x1 ) Eq(x, x2 ) C(x)(101)Note singularisation applied globally rules, including onescontain equality predicate.properties singularisation summarised follows. Let set rules,let instance, let marking . Furthermore, let 0 = Sing(, ),let 0 = I0 chase 0 . Finally, note predicate Eq interpreted0 equivalence relation, let function maps term occurring0 arbitrarily chosen representative equivalence class t. first-orderinterpretation (I 0 ) defined follows, rng() range mapping ,00set 4(I ) universe (I 0 ), (P )(I ) interpretation predicate P :04(I ) = rng()0(P )(I ) = {h(t1 ), . . . , (tn )i | P (t1 , . . . , tn ) I} P different Eq00(Eq)(I ) = {hx, xi | x 4(I ) }Note (I 0 ) interprets true equalitythat is, term interpreted (I 0 )representative equivalence class contains t; hence, (I 0 ) Herbrandinterpretation. Marnette (2010) showed that, arbitrary , interpretation (I 0 )universal model Ithat is, (I 0 ) homomorphically embeddedarbitrary model I. Thus, (I) used query answering: Booleanconjunctive query Q, |= Q (I 0 ) |= Q.780fiAcyclicity Notions Existential Rulesresult reformulated follows. Let , I, , 0 specified above,let us assume Q form Q = ~y .(~y ). Furthermore, let r followingrule, let 0 arbitrary marking r:r=(~y ) H(102)Then, characterisation singularisation implies|= QSing( {r}, 0 ) |= H0 Sing({r}, 0 ) |= H.Hence, answer Q w.r.t. evaluating Sing({r}, 0 ) chaseSing(, ). straightforward generalise approach non-Boolean queries.absence replacement rules (4) often allows skolem chase terminateSing(, ), may depend selected marking.Example 50. Rule (95) Example 47 admits following two markings:A(x ) B(x) y.[R(x, y) B(y)]A(x) B(x ) y.[R(x, y) B(y)](103)(104)skolem chase universally terminate singularisation obtained (104)(96). contrast, singularisation obtained (103) (96) JA.Definition 51. X {MFA, MSA, JA}, acyclicity notion X (resp. X ) containsfinite set rules Sing(, ) X (resp. each) marking .Clearly, X X X {MFA, MSA, JA}, Example 50 shows inclusionproper. next show JA actually coincides WA.Theorem 52. arbitrary finite set rules, JA WA.Proof. (JA WA) prove contrapositive, let arbitrary set rulesWA; w.l.o.g. assume variable occurs one rule. consideredge p q WA dependency graph WA() triple e = hp, q, ti,= edge regular = edge special. definition WA,e, rule r universally quantified variable x occurring headbody r exist p PosB (x), let xe one arbitrarily chosen fixedvariable; furthermore, edge e special, existentially quantified variable existsq PosH (y), let ye one arbitrarily chosen fixed variable.cycle WA() sequence edges e1 , . . . , en form ei = hpi , qi , tiqi = pi+1 1 < n qn = p1 . cycle dangerous edge ek existsspecial; cycle simple xei 6= xej 1 < j n.3let 0 = e1 , . . . , en arbitrary dangerous cycle WA(). 0 simple,show transform 0 shorter dangerous cycle. Towards goal, assume0 contains edges ei = hpi , qi , ti ej = hpj , qj , tj 1 < j n xei = xej ;hence, rule r contains body atoms xei occurs positions pi pj .Furthermore, let ek arbitrarily chosen, fixed special edge 0 ; ek existssince 0 dangerous. following possibilities.3. Note cycle length one always simple.781fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangk < j, let 00 = e, ei+1 , . . . , ej1 e = hpj , qi , ti i. ei regular, xeioccurs head atom r position qi ; furthermore, ei special, headatom r contains existentially quantified variable position qi . Either way, eedge WA(), 00 cycle WA(). Furthermore, e special k = i,00 contains ek otherwise; hence, 00 dangerous.Otherwise, let 00 = e1 , . . . , ei1 , e, ej+1 , . . . , en e = hpi , qj , tj i. Edges e ejtype, e edge WA() 00 cycle WA(). Furthermore, e special k = j, 00 contains ek otherwise; hence, 00 dangerous.cases, 00 contains least one edge less 0 . Thus, iteratively transformarbitrary dangerous cycle WA() simple dangerous cycle .let marking marks variable w occurring bodyrule r follows.edge e = hp, q, ti exists w = xe , marks occurrencew r position p (if multiple occurrences, one chosen arbitrarily).Since simple, edge e unique, correctly defined.Otherwise, marks arbitrarily chosen occurrence w r.Let 0 = Sing(, ), let JA(0 ) JA dependency graph 0 . showJA(0 ) contains cycle, first prove following property (?).subpath e1 , . . . , ek edge e1 special edge ei1 < k regular, {qi , Eq|1 } Move(ye1 ) 1 k.4Since 0 contains rule (97), clearly Eq|1 Move(ye1 ). next prove (?) induction k. base case k = 1, q1 Move(ye1 ) definition JA.induction step, assume claim holds subpaths length k, considersubpath e1 , . . . , ek , ek+1 . induction assumption fact qk = pk+1 ,pk+1 Move(ye1 ). Furthermore, variable xek+1 occurs body head atomrule r 0 positions pk+1 qk+1 , respectively. Finally, definitionproperties singularisation, PosB (xek+1 ) contains pk+1 possiblyEq|1 . then, definition JA, qk+1 Move(ye1 ), required.complete proof, consider arbitrary subpath e1 , . . . , e` edgese1 e` special edge ei 1 < < k regular. (?) factq`1 = p` , {p` , Eq|1 } Move(ye1 ). Furthermore, previous paragraph,PosB (xe` ) contains p` possibly Eq|1 ; then, JA(0 ) contains edge ye1 ye` .Since cycle, JA(0 ) clearly contains cycle, 0 JA, required.(JA WA) Assume 6 JA , exists marking= Sing(, ) JA. assume contain existentially quantified variable occurs equality atom; w.l.o.g. always replaceequality atom atom R(x, t) add rule R(x1 , x2 ) x1 x2 R freshbinary predicate, transformation clearly affect membership04. notion subpath defined obvious way; however, please note that, although definedsequence edges, subpaths wrap around sequence cycle.782fiAcyclicity Notions Existential Rulesrule set JA WA. consider arbitrary existentially quantified variable y,arbitrary positions p PosH (y) q Move(y) involve Eq (both sets w.r.t.0 ); induction construction Move(v), one prove WA() containssequence regular edges p q. proof straightforward, omit detailssake brevity. Similarly, consider arbitrary edge y1 y2 JA(0 ),arbitrary positions p PosH (y1 ) q PosH (y2 ) involve Eq; definitionJA, variable x occurring rule y2 position involving Eq existMove(y1 ) PosB (x). WA() contains path consisting regularedges p s, well special edge q. Since JA(0 ) cyclic, WA()clearly contains cycle involving special edge.Checking possible markings may infeasible: number candidates exponential total number variables occur rule body. Theorem 52shows JA decided using WA. cases, following simple observation shows reduce number markings.Definition 53. variable x relevant rule r x occursbody r, head r contains atom P (~t) x ~t P .Proposition 54. Let 0 markings that, rule r ,markings r 0 coincide relevant variable r. Then,instance I, result skolem chase Sing(, ) coincides resultskolem chase Sing(, 0 ); furthermore, Sing(, ) JA/MSA/MFASing(, 0 ) JA/MSA/MFA.Proof. Consider arbitrary rule r . variable x occurs body r,marking various occurrences x r clearly produces rules equivalent renamingvariables. Furthermore, assume variable x occurs head r equalityatom form x t, markings x differ. Then, rules obtained rsingularisation body (up renaming variables); furthermore,bodies contain atoms Eq(xi , x), rule heads form Eq(x, t). SinceSing(, ) Sing(, 0 ) contain rules (97)(99), skolem chase Sing(, )clearly derives ground atoms skolem chase Sing(, 0 ).Despite optimisation, number markings check still exponentialsize , next describe useful approximation. Let maximal set markingsthat, M1 , M2 M, rule r , variable x relevantr, markings x r M1 M2 coincide. Intuitively, containspossible markings relevant variables, markings variables coincide.Proposition 54 clearthat, given two sets M1 M2 , skolem chaseI; thus, letM1 Sing(, )M2 Sing(, ) coincides arbitrary instanceone arbitrarily chosen set markings. Also, let Sing () = Sing(, ),let MFA class containing rule set Sing () MFA, let MSAJA defined analogously. following proposition shows, Sing () provideslower bound acyclicity obtained via singularisation.783fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangProposition 55. X {MFA, MSA, JA}, X X . Furthermore,size Sing () exponential maximal number relevant variables rule, linear number rules .Proof. first claim follows fact considered notions acyclicitymonotone sense every subset acyclic rule set also acyclic. secondclaim follows fact that, rule r exists contains k relevant variablesvariable occurs times r, contains mk different markings r.result interesting dealing rules obtained DLs,rule one relevant variable: rule sets, size Sing () linearsize . general case, complexity acyclicity checking increasedespite exponential increase number rules.Theorem 56. Deciding whether MFA (MFA , MFA ) 2ExpTime-complete.Deciding whether MSA (MSA , MSA ) ExpTime-complete.Proof. contains equality, easy see MFA (MFA , MFA )MFA. observed MSA. Thus, hardness followsTheorems 8 13.membership, first consider cases MFA , MFA , MSA , MSA .properties decided considering exponentially manymarkings. Since Sing(, ) linear size , property checkedmarking MFA 2ExpTime (cf. Theorem 8) MSA ExpTime (cf. Theorem 13). yields required bound since exponential factor significantconsidered complexity classes.MFA MSA , membership follows observing membership MFAMSA 2ExpTime ExpTime, respectively, obtained double/singleexponential bound number ground facts potentially need derivedorder decide required property. Sing () exponentially larger ,maximal number relevant ground facts still since new predicates constantsymbols introduced. increased number rules leads exponential increasetime check applicability rules doubly/singly exponentially manysteps, exponential factor affect membership decision problem2ExpTime/ExpTime.finish section examining interaction rule normalisationsingularisation. Note normalisation reduces number variables rule,least first sight suggests normalisation could prevent one finding markingensures acyclicity singularised rules. next show cannot happennormalisation used without structure sharing: original set rules MFA w.r.t.set markings, transformed set rules MFA w.r.t. set markingswell. Furthermore, show hold normalisation used structuresharing; hence, normalisation applied care used singularisation.Theorem 57. Let set existential rules, let 0 obtained applyingsingle normalisation step without structure sharing, let instance.784fiAcyclicity Notions Existential Rulesmarking Sing(, ) MFA w.r.t. extended marking 00 Sing(0 , 0 ) MFA w.r.t. I.Proof. Let marking Sing(, ) MFA, let r ruleform (8) normalisation step applied, let 0 set rules obtainedapplication normalisation step r. next prove claimholds head body normalisation step.(Head Normalisation) Assume set rules 0 obtained replacing ruler rules r1 r2 following forms, ~x = ~x3 ~x4 :r=r1 =r2 =(~x, ~z) ~y1 , ~y2 , ~y3 .[1 (~x3 , ~y1 , ~y2 ) 2 (~x4 , ~y1 , ~y3 )](~x, ~z) ~y1 , ~y3 .[Q(~x3 , ~y1 ) 2 (~x4 , ~y1 , ~y3 )]Q(~x3 , ~y1 ) ~y2 .1 (~x3 , ~y1 , ~y2 )Let 0 marking coincides rules different r, marks r1way marks r, marks r2 possible way (notebody rule contain repeated occurrences variables); furthermore, let= Sing(, ) = Sing(0 , 0 ). assume rule r skolemised replacingvariable ~y1 g1y (~x), variable ~y2 g2y (~x), variable ~y3g3y (~x); rule r1 skolemised r; rule r2 skolemised replacing variable~y2 hy (~x3 , ~y1 ). Thus, skolemised singularised rules following form;formula 0 singularisation , freshly introduced variables contained ~z1 :0 (~x, ~z1 ) 1 (~x3 , ~g1 (~x), ~g2 (~x)) 2 (~x4 , ~g1 (~x), ~g3 (~x))0 (~x, ~z1 ) Q(~x3 , ~g1 (~x)) 2 (~x4 , ~g1 (~x), ~g3 (~x))Q(~x3 , ~y1 ) 1 (~x3 , ~y1 , ~h(~x3 , ~y1 ))Finally, inductively define partial mapping terms terms follows:(c) = c constant c,(f (~t)) = f ((~t)) function symbol f form hy g1y terms ~t(~t) defined,(hy (~s, ~g1 (~s, ~t))) = g2y ((~s), (~t)) function symbols form hy , corresponding symbol g2y , terms ~s ~t (~s) (~t) defined.predicatenext show following property (?): A(~t)occurring (i.e., introduced normalisation step), (t) defined0 , 1 , . . . .A((~t)) . proof induction chase sequencebase case holds trivially. Furthermore, since coincide rules apart r,r1 , r2 , proof claim trivial conclusion rule different r1i+1r2 . remaining cases, assume w.l.o.g.obtainedsingle application r1 substitution application r2 result; thus,rules together derive following facts:Q(~x3 , ~g1 (~x))~1 (~x3 , ~g1 (~x), h(~x3 , ~g1 (~x)))2 (~x4 , ~g1 (~x), ~g3 (~x))785fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wanginduction assumption, 0 ((~x), (~z)) , contains followingfacts:1 ((~x3 ), ~g1 ((~x)), ~g2 ((~x)))2 ((~x4 ), ~g1 ((~x)), ~g3 ((~x)))Clearly, term hy (~x3 , ~g1 (~x)) form hy (~s, ~g1 (~s, ~t)), mapping definedterm. Furthermore, definition , clear property (?) holds.always (sub)termsproof (?) also reveals functions symbols hy occur.form hy (~s, ~g1 (~s, ~t)), (u) defined term u occurringobservation following property clearly imply claim theorem: ucyclic term (u) defined, (u) cyclic well. prove latter, sufficesconsider following two cases.Assume u cyclic due repetition function symbol f formhy . Thus, u contains subterm form f (~s), si ~s contains subtermform f (~t). definition , (u) contains term form f ((~s)),s0i (~s) contains subterm form f ((~t)). Clearly, (u) cyclic.Assume u cyclic due repetition function symbol form hy .observation, u contains subterm form hy (~s, ~g1 (~s, ~t)),si ~s ~t contains subterm form hy (~v , ~g1 (~v , w)).~definition ,~(u) contains subterm form g2 ((~s), (t)), s0i (~s) (~t) contains~Clearly, u cyclic.subterm form g2y ((~v ), (w)).(Body Normalisation) Assume set rules 0 obtained replacing ruler rules r1 r2 following forms, ~x = ~x1 ~x2 ~x3 , ~x1 , ~x2 , ~x3 ,~z1 , ~z2 , ~z3 pairwise disjoint:r=r1 =r2 =1 (~x1 , ~x2 , ~z1 , ~z2 ) 2 (~x1 , ~x3 , ~z1 , ~z3 ) ~y .(~x, ~y )1 (~x1 , ~x2 , ~z1 , ~z2 ) Q(~x1 , ~x2 , ~z1 )Q(~x1 , ~x2 , ~z1 ) 2 (~x1 , ~x3 , ~z1 , ~z3 ) ~y .(~x, ~y )marked variable v, let ~uv variables used replace v singularisation. Then,singularised rule r represented follows, clarity showfree variables various formulae, 01 02 contain atoms predicate Eq,1 2 conjunctions atoms predicate Eq obtained renaming unmarkedoccurrences variables 1 (~x1 , ~x2 , ~z1 , ~z2 ) 2 (~x1 , ~x3 , ~z1 , ~z3 ), respectively:01 02 1 2 ~y .(~x, ~y )let 0 marking coincides rules different r, that,marked occurrence variable w ~x1 ~x2 ~z1 r, marks r1 r2 follows.marked occurrence w appears 1 (~x1 , ~x2 , ~z1 , ~z2 ), correspondingoccurrence w marked r1 ; addition, w ~x1 ~x2 ~z1 , occurrencew atom Q(~x1 , ~x2 , ~z1 ) marked r2 .786fiAcyclicity Notions Existential Rulesmarked occurrence w appears 2 (~x1 , ~x3 , ~z1 , ~z3 ), correspondingoccurrence w marked r2 ; addition, w ~x1 ~x2 ~z1 , arbitraryoccurrence w marked r1 .Since structure sharing, contain r1 , definition wellformed. singularisation r1 r2 0 represented follows:001 001 Q(~x1 , ~x2 , ~z1 )Q(~x01 , ~x2 , ~z10 ) 02 02 ~y .(~x, ~y )definition 0 , clear 001 001 isomorphic subset 01 01 .Based observation, routine prove that, A(~t) ISing(,M)~different newly introduced predicate Q, A(t) ISing(0 ,M 0 ) , clearlyimplies claim.contrast Theorem 57, following example shows normalisation structure sharing prevent one finding marking makes normalised rules acyclic.example shows normalisation must used care applications use singularisation deal equality.Example 58. Let following set rules marked marking shown below.A(x) (x , z) B(z ) y.[R(x, y) A(y)]A(x ) (x, z) C(z ) y1 y2 .[S(x, y1 ) (y1 , y2 )]R(z , x1 ) R(z, x2 )S(z , x1 ) S(z, x2 )(z , x1 ) (z, x2 )(105)(106)x1 x2(107)x1 x2(108)x1 x2(109)One show Sing(, ) MFA w.r.t. instance given below.= {A(a), R(a, a), (a, b), B(b), A(a0 ), S(a0 , a0 ), (a0 , b0 ), C(b0 )}Furthermore, let M1 marking identical marks A(x ) rule (105),let M2 marking identical marks (x , z) rule (106). One showneither Sing(, M1 ) Sing(, M2 ) MFA w.r.t. I.let 0 obtained applying normalisation structure sharing rules(105) (106); thus, rules (105) (106) replaced following rules:Q(x, z) B(z) y.[R(x, y) A(y)](110)Q(x, z) C(z) y1 y2 .[S(x, y1 ) (y1 , y2 )](111)A(x) (x, z) Q(x, z)(112)Note conjunction A(x) (x, z) occurs 0 rule (112); therefore, variable xconjunction marked one way. This, however, effectchoosing M1 M2 : possible marking 0 make Sing(0 , 0 ) MFA w.r.t. I.Intuitively, normalisation structure sharing reduces space available markings,due may impossible find marking makes rules acyclic.787fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang6. Applying Acyclicity Horn Description Logicssection apply various acyclicity notions reasoning problems descriptionlogic (DL) ontologies. Description logics knowledge representation formalisms underpin Web Ontology Language (OWL). DL ontologies constructed atomicconcepts (i.e., unary predicates), atomic roles (i.e., binary predicates), individuals (i.e.,constants). Special atomic concepts > denote universal truth falsehood, respectively. atomic role R, expression R inverse role; furthermore, roleatomic inverse role. DLs provide rich set constructors building concepts(first-order formulae one free variable) atomic concepts roles. descriptionlogic TBox set axioms, correspond first-order sentences. paperconsider Horn description logics, TBoxes translated existential rules. Furthermore, paper consider normalised TBoxes,concepts occur nested concepts. latter assumption without lossgenerality Horn description logic TBox normalised linear time,normalised ontology model-conservative extension original one.paper consider several logics fragments description logicHorn-SROIF, provides formal underpinning prominent subset OWL.normalised Horn-SROIF TBox consists axioms shown left-hand sideTable 1; table, A, B, C atomic concepts (including possibly > ), R, S,(not necessarily atomic) roles, individual. guarantee decidabilityreasoning, must satisfy certain global conditions (Kutz, Horrocks, & Sattler, 2006),omit sake brevity. Roughly speaking, so-called simple rolesallowed occur axioms Type 2, axioms Type 6 must regular accordingparticular condition allows axioms represented using nondeterministicfinite automaton. also consider following fragments Horn-SROIF.Horn-SRI TBoxes allowed contain axioms Type 2 7.Horn-SHIF TBoxes allowed contain axioms Type 7, axiomsType 6 satisfy R = = . Note Horn-SHIF TBoxes regular.Horn-SHI TBoxes inherit restrictions Horn-SHIF allowed contain axioms type 2.simplify presentation, consider general at-least number restrictionsis, concepts form n R.A n > 1. translation concepts ruleswould require explicit inequality predicate. explained Section 2.2, inequalitypredicate simulated using ordinary predicate, extension resultsgeneral at-least number restrictions straightforward.rest paper allow inverse roles occur atoms, take atomform R (t1 , t2 ) R atomic role abbreviation R(t2 , t1 ). Then,Horn-SROIF axiom corresponds existential rule shown Table 1. explainedSection 2.2, treat > ordinary unary predicates > explicitly axiomatised. Thus, take substitution answer CQ Q(~x) w.r.t.|= Q(~x) |= y.(y); latter condition takes accountunsatisfiable theory entails possible formulae. Due close correspondence788fiAcyclicity Notions Existential Rules1.v R.B2.v 1 R.B3. u B v C4.v R.B5.RvS6. R v7.v {a}A(x) y.[R(x, y) B(y)]A(z) R(z, x1 ) B(x1 ) R(z, x2 ) B(x2 ) x1 x2A(x) B(x) C(x)A(z) R(z, x) B(x)R(x1 , x2 ) S(x1 , x2 )R(x1 , z) S(z, x2 ) (x1 , x2 )A(x) xTable 1: Axioms normalised Horn-SROIF ontologies corresponding rulesdescription logic axioms existential rules, rest paper identify TBoxcorresponding set rules.complexity answering Boolean conjunctive queries general (i.e., acyclic)DL TBoxes 2ExpTime- ExpTime-complete Horn-SROIF (Ortiz et al., 2011)Horn-SHIF (Eiter et al., 2008), respectively. rest section investigatecomplexity problem acyclic ontologies, well complexity acyclicitychecking. particular, Section 6.1 consider case TBox expressedHorn-SROIF, show BCQ answering MFA checkingExpTime-complete. Then, Section 6.2 consider Horn-SHIF TBoxes,show complexity problems drops PSpace.6.1 Acyclic Horn-SROIF TBoxesstart showing BCQ answering WA Horn-SRI TBoxes ExpTime-hard.Intuitively, due axioms Type 6, used axiomatise existencenon-tree-like structures. Although regularity ensures axioms Type 6represented nondeterministic finite automaton, automaton exponential;consequence, axioms Type 6 axiomatise exponential non-tree-like structures,main source complexity.Lemma 59. Let WA Horn-SRI TBox, let instance, let F fact.Then, checking whether |= F ExpTime-hard.Proof. Let = (S, Q, , Q0 , Qa ) deterministic Turing machine, finite setsymbols, Q finite set states, : Q Q {, } transition function,Q0 Q initial state, Qa accepting state. Furthermore, assume integerkk exists halts input length n time 2n . Given arbitrary inputSi1 , . . . , Sin , construct MFA set Horn-SRI rules instance|= Qa (a) accepts input. simplify presentation, useslightly general rule syntax allowed Table 1; however, rulesbrought required form renaming parts rules fresh predicates.Let ` = nk ; since k constant, ` polynomial n. construction uses unarypredicate symbol state; simplicity, distinguishpredicate symbol/state. addition, construction also uses binary predicatesLi , Ri , Ti , Ui , Di , Hi , Vi 1 `, unary predicates Ai Bi 0 `,unary predicates O1 , . . . , On+1 , N1 , N2 . Instance contains fact A0 (a).789fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wangnext present rules . set contain Horn rules without empty heads,satisfiable minimal Herbrand model. readability, dividegroups rules prove group various facts minimal Herbrand modelI, shown schematically Figure 2. construction proceeds alongfollowing lines.first, second, third group rules construct exponential grid shownbottom Figure 2, whose edges labelled H` V` . sequenceV` -edges used encode contents tape Turing machinepoint time; furthermore, precisely one vertex sequencelabelled state, thus representing position head. contrast, H` -edgesconnect different points time used encode transitionsTuring machine.fourth group labels right-most V` -chain Si1 , . . . , Sin , St , St , . . . , St , St ,St represents empty tape symbol.fifth sixth groups ensure symbols tapemodified move Turing machine propagated time points.seventh eighth group encode transitions Turing machine.ninth group propagates acceptance condition top figurelabelling individual accepting state Qa .next present rules detail.first group rules contains rules (113)(115) 0 < `, rule (116)1 < `.Ai1 (x) y.[Li (x, y) Ai (y)](113)Ai1 (x) y.[Ri (x, y) Ai (y)](114)00(115)00(116)Ri (z, x) Li (z, x ) Ti (x, x )00Li (z, x) Ti1 (z, z ) Ri (z , x ) Ti (x, x )I, rules axiomatise existence triangular structure top part Figure 2containing Ti links.second group rules contains rule (117), rules (118)(120) 0 < `,rule (121) 1 < `.A` (x) B0 (x)(117)Bi1 (x) y.[Ui (x, y) Bi (y)](118)Bi1 (x) y.[Di (x, y) Bi (y)](119)00(120)00(121)Ui (z, x) Di (z, x ) Vi (x, x )00Di (z, x) Vi1 (z, z ) Ui (z , x ) Vi (x, x )rules axiomatise existence triangular structures bottom part Figure 2containing Vi links.790fiAcyclicity Notions Existential RulesL1R1T1L2Legend:R2T2T2T2LiUiRiDiTiHiT`T`H0H0D1ViU1H1V 1 U2D2V2V2V2H2H`H`O1 , Q0V`H`V`H`Figure 2: Grid Modelthird group rules contains rule (122), rules (123) (124)0 < `.T` (x, x0 ) H0 (x, x0 )(122)0000(123)0000(124)Ui (z, x) Hi1 (z, z ) Ui (z , x ) Hi (x, x )Di (z, x) Hi1 (z, z ) Di (z , x ) Hi (x, x )rules axiomatise existence Hi links, Vi links form grid size 2i 2ishown Figure 2.rest proof, variables w0 w` , use R` (w0 , w` ) abbreviationR1 (w0 , w1 ) . . . R` (w`1 , w` ), wi 0 < < variable occurringoutside conjunction. Furthermore, analogously use U ` (w0 , w` ) abbreviationU1 (w0 , w1 ) . . . U` (w`1 , w` ).fourth group rules contains rule (125), rules (126) (127)1 j n, rules (128)(129), St empty tape symbol. RememberSi1 , . . . , Sin encodes input M.A0 (z) R` (z, z 0 ) U ` (z 0 , x) O1 (x) Q0 (x)(125)Oj (z) V` (z, x) Oj+1 (x)(126)Oj (x) Sij(127)On+1 (z) V` (z, x) On+1 (x)(128)On+1 (x) St (x)(129)791fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangRule (125) labels grid origin sets initial state shown Figure 2. Rules(126) ensure n subsequent nodes labelled O2 , . . . , On+1 , rule (128)propagates On+1 rest V` -chain. Finally, rules (127) (129) ensurenodes labelled Oj also labelled Sij , nodes labeled On+1labeled St . Thus, group rules ensures right-most V` -chaingrid contains initial state tape M.fifth group rules contains rules (130)(131) state Qk Q, rules(132)(133). rules essentially ensure nodes node labelledstate Qk Q labeled N1 N2 , respectively, thus indicatinghead node.Qk (z) V` (x, z) N1 (x)(130)Qk (z) V` (z, x) N2 (x)(131)N1 (z) V` (x, z) N1 (x)(132)N2 (z) V` (z, x) N2 (x)(133)sixth group rules contains rules (134)(135) instantiated symbolSk S; rules ensure contents tape copied successive timepoints points grid containing head.N1 (z) Sk (z) H` (z, x) Sk (x)(134)N2 (z) Sk (z) H` (z, x) Sk (x)(135)seventh group rules contains rules (136)(137) instantiated symbolSk state Qk Q (Qk , Sk ) = (Qk0 , Sk0 , ). rules encodemoves head moves left.Qk (z) Sk (z) H` (z, x) Sk0 (x)00Qk (z) Sk (z) H` (z, z ) V` (x, z ) Qk0 (x)(136)(137)eighth group rules contains rules (138)(139) instantiated symbolSk state Qk Q (Qk , Sk ) = (Qk0 , Sk0 , ). rules encodemoves head moves right.Qk (z) Sk (z) H` (z, x) Sk0 (x)00Qk (z) Sk (z) H` (z, z ) V` (z , x) Qk0 (x)(138)(139)ninth group rules contains rules (140)(143) 1 `; rulessimply ensure acceptance propagated back root upper tree.Qa (z) Ui (x, z) Qa (x)(140)Qa (z) Di (x, z) Qa (x)(141)Qa (z) Li (x, z) Qa (x)(142)Qa (z) Ri (x, z) Qa (x)(143)792fiAcyclicity Notions Existential Rulesdiscussion shows labelling nodes grid shown Figure 2simulates execution input Si1 , . . . , Sin , contents tapetime instant represented V` -chain, H` -links connect tape cells successivetime instants. Thus, |= Qa (a) accepts Si1 , . . . , Sin time 2` .straightforward see WA, claim theorem holds.proof Lemma 59 adapted obtain lower bound checking MFAHorn-SRI rules.Lemma 60. Checking whether Horn-SRI TBox universally MFA ExpTime-hard.Proof. Let arbitrary deterministic Turing machine let Si1 , . . . , Sin inputkstring terminates time 2n . Si1 , . . . , Sin , letproof Lemma 59. TBox WA, contains constant-free, equality-free,connected rules, predicate zero arity; hence, Lemma 7, Horn-SRITBox 0 exists accepts Si1 , . . . , Sin 0 universally MFA.Note Lemmas 59 60 apply Horn-SRI thus rely particulartreatment equality. deal equality predicate Horn-SROIF TBoxesusing singularisation described Section 5, leads us following result.Theorem 61. Let Horn-SROIF TBox, let marking , letinstance, let Q BCQ. Then, checking whether Sing(T , ) MFA w.r.t.ExpTime-complete. Furthermore, Sing(T , ) MFA w.r.t. I, checking whether|= Q holds ExpTime-complete well.Proof. Note rules Table 1 -1 rules. Since rules Sing(T , ) -1rules well, Theorem 10 gives us ExpTime upper bound problems.matching lower bounds follow Lemmas 59 60 (note every Horn-SRI TBoxalso Horn-SROIF TBox) fact proofs use predicate .fact, Theorem 10 provides us even stronger complexity bounds. particular,even satisfy required global conditions, even extendedSWRL rules (Horrocks, Patel-Schneider, Bechhofer, & Tsarkov, 2005), rulesstill -1 rules. Thus, one decide whether MFA (universally w.r.t.instance) ExpTime, case, one answer BCQs ExpTime well.Consequently, ontology-based applications freely use expressivity beyondcurrently available OWL without increase complexity reasoning, assumingresulting TBox acyclic.conclude section observing MSA provides us tractable notionHorn-SROIF rules. Intuitively, rules MSA(T ) bounded number variables predicates MSA(T ) bounded arity, eliminates sourcesintractability datalog reasoning. prove matching lower bound Section 6.2specific case Horn-SHIF ontologies.Theorem 62. Let Horn-SROIF TBox, let marking, let instance.Then, checking whether Sing(T , ) MSA w.r.t. PTime.793fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangProof. one see Table 1, rules contain bounded number variables atoms body, number variables body ruleMSA(Sing(T , )) bounded well. Furthermore, datalog program MSA(Sing(T , ))contains predicates bounded arity, chase w.r.t. polynomial size. Thus,chase MSA(T ) computed polynomial time, implies claim.6.2 Acyclic Horn-SHIF TBoxesexponential lower bound Lemmas 59 60 critically depend axioms Type 6,used encode exponential structures; furthermore, combination inverseroles axioms Types 2 7 (i.e., inverse roles, number restrictions, nominals)also well known problematical (Horrocks & Sattler, 2007). practice, however,TBoxes often expressed Horn-SHIF, disallows axioms TBoxes.next show that, TBoxes, complexity problems drops PSpace.first prove PSpace-hardness problems. Note PSpace-hardnessproof concept satisfiability checking Baader, Calvanese, McGuinness, Nardi, PatelSchneider (2007) applicable Horn ontologies since uses disjunctive concepts.Nonetheless, PSpace-hardness proved reduction checking QBF validity.Lemma 63. Let WA Horn-SHI TBox, let instance, let F fact.Then, checking whether |= F PSpace-hard.Proof. Let = Q1 x1 . . . Qn xn .C1 . . . Ck arbitrary quantified Boolean formula defined variables x1 , . . . , xn , Qi {, }, 1 n quantifier,Cj , 1 j k clause form Cj = Lj,1 Lj,2 Lj,3 . Checking validitycanonical PSpace-hard problem.rest proof, binary predicate P variables w0 wm , useP (w0 , wm ) abbreviation P (w0 , w1 ) . . . P (wm1 , wm ), wi0 < < variable occurring outside conjunction. Let Horn-SHITBox containing rules (144)(147) 1 n, rule (148) clause Cjliteral Lj,m = x` occurring Cj , rule (149) clause Cj literal Lj,m = x`occurring Cj , rule (150), rule (151) 1 n Qi = , rule (152)1 n Qi = .Ai1 (x) y.[Xi+ (x, y) Ai (y)](144)y.[Xi (x, y) Ai (y)]Xi+ (x, x0 ) P (x, x0 )Xi (x, x0 ) P (x, x0 )(145)(146)(z, x) (x) Cj (x)(148)P n` (z, x) (x) Cj (x)(149)C1 (x) . . . Ck (x) Fn (x)(150)P (x, z) Fi (z) Fi1 (x)(151)Ai1 (x)X`+ (z 0 , z)X` (z 0 , z)Xi+ (x, z)PFi (z)n`Xi (x, z 0 )7940Fi (z ) Fi1 (x)(147)(152)fiAcyclicity Notions Existential RulesStrictly speaking, rules (148), (149), (150), (152) Horn-SHI rules,transformed Horn-SHI rules replacing parts bodies fresh concepts.straightforward see WA.Let = {A0 (a)}, let chase . Due rules (144)(145),contains binary tree depth n leaf node reachable via paththat, 1 n, contains either Xi+ Xi . interpret presence Xi+Xi assigning variable xi f, respectively, leaf node corresponds onepossible assignment x1 , . . . , xn . Rules (148) (149) clearly label leaf nodeclauses true node, rule (150) labels leaf node Fnclauses true. Finally, rules (151) (152) label interior node treeFi1 according semantics appropriate quantifier . Clearly, valid|= F0 (a), implies claim.next turn attention upper bounds complexity answeringBCQ MFA TBox, checking whether TBox MFA. Section 6.1considered TBox singularised according marking , section assumeequality handled means explicit axiomatisation . explainnext, singularised rules local, makes PSpace membershipproof quite difficult. example, consider following singularised rule:A(x) x x0 B(x0 ) C(x)(153)Atoms A(x) B(x0 ) rule share variables therefore need matchedlocally chase Sing(T , ) I; furthermore, chase exponential size,trivial see explored using polynomial space. Nevertheless,conjecture possible extend proof singularised rules well; however,details involved seem quite technical, without explaining much nature BCQanswering equality. Therefore, leave problem open restricttechnically simpler case equality encoded explicitly using .next show answering BCQ Q MFA Horn-SHIF TBoxinstance performed polynomial space. proof uses well-known tracingtechnique inspecting model using polynomial space. key aspectresult, however, dealing transitive roles query, allow queryembedded non-locally chase I. Note, however, guessembedding Q result using nondeterministic polynomial time; furthermore,since minimal Herbrand model (i.e., since Horn), checkentailment mapped atom Q separately, use wellknown encoding Demri de Nivelle (2005) handle transitive roles.Theorem 64. Let Horn-SHIF TBox, let instance MFA w.r.t.I, let Q BCQ. Then, checking whether |= Q PSpace-complete.Proof. Hardness follows Lemma 63. next present nondeterministic polynomialspace algorithm decides |= Q; Savitchs Theorem, algorithm transformed deterministic polynomial space algorithm, proves claim.Assume BCQ Q form Q = ~y .B1 . . . Bn . Furthermore, let = sk(T ).Since regular atomic concept, always satisfiable chase795fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wang. Furthermore, |= Q substitution variables ~yterms exists Bi 1 n; latter clearly holds|= Bi . shown proof Theorem 10, term formg1 (. . . g` (a) . . .), ` less equal number function symbols . Thus,first step deciding |= Q examine possible check |= Bi1 n; clearly done using deterministic Turing machine usespolynomial space store , provided individual check |= Bi alsodecided polynomial space.Bi form C(t), let 0 = , let = C. Alternatively, Biform R(t0 , t), let 0 extended following rules, Efresh concepts occurring I:E(t0 )(154)E(z) R(z, x) D(x)(155)straightforward see |= R(t0 , t) 0 |= D(t). Let 00obtained 0 deleting rule 0 formR(x1 , z) R(z, x2 ) R(x1 , x2 )(156)and, role R occurring rule, replacing rule formA(z) R(z, x) B(x)(157)following rules, QA,R,B fresh concept unique A, R, B:A(z) R(z, x) QA,R,B (x)(158)QA,R,B (z) R(z, x) QA,R,B (x)(159)QA,R,B (x) B(x)(160)transformation corresponds well-known elimination transitivity Demride Nivelle (2005), 0 |= D(t) 00 |= D(t); proof claimstraightforward omit sake brevity.Let 00 extended equality axioms (2) (4). Since occurbody rules 00 , 00 6|= D(t) 6|= D(t).Let chase ; 6|= D(t) D(t) 6 . Notecontains rules Types 15 Table 1, rules (2) (4), possibly rulesform E(t1 ). facts used show assertion onefollowing forms, b constants, constant term containsunary function symbols, f g unary function symbols, C atomic concept,R atomic role:C(t),R(a, b), R(a, f (b)), R(f (b), a), R(t, f (t)), R(f (t), t),f (g(t)), f (t) g(t), b, f (b), equality symmetric ones.796fiAcyclicity Notions Existential Rulesproof induction length chase sequence , claimfollows straightforwardly form rules Types 15. Motik et al. (2009b)prove analogous claim general description logic, proof carriessetting syntactic changes.say x central variable rule Type 1 3, z centralvariable rule Type 2 4. W.l.o.g. assume body rule Type 5contain inverse roles; then, x1 central variable rule Type 5. Finally,equality replacement rules (4), central variable variable replaced.Clearly, D(t) 6 Herbrand interpretation J exists assertions form mentioned above, J, J |= , D(t) 6 J. nextshow check existence J using nondeterministic Turing machineruns polynomial space.Let f1 , . . . , fm function symbols occurring . first guess Herbrand interpretation J 0 constants satisfying J 0 , check whether rulesType 1 satisfied J 0 . case, consider constant c J0call following procedure = c = 1:1. = + 1 return true.2. Guess Herbrand interpretation J assertion J formspecified earlier involves least one term among f1 (s), . . . , fm (s).3. D(t) J , return false.4. Check whether equality symmetry rule (4) satisfied J ; not, return false.5. Check whether J J i1 . . . J 0 satisfies rule central variablerule mapped s; case rule, return false.6. 1 k m, recursively call procedure fk (s) + 1; onecalls returns false, return false well.7. Return true.Assume procedure returns true constant c, let J union Jconsidered process. straightforward see J D(t) 6 J; furthermore,J |= holds since satisfaction rule r J ascertained locally,inspecting vicinity ground term mapped central variable r.Furthermore, recursion depth algorithm recursion level needkeep polynomially sized interpretation J , algorithm implemented usingnondeterministic Turing machine uses polynomial space.Theorem 65. Let Horn-SHIF TBox, let instance. Then, decidingwhether MFA w.r.t. PSpace, deciding whether universally MFAPSpace-hard.Proof. (Membership) Rules MFA(T ) almost Horn-SHIF rules: rule (19)made Horn-SHIF rule replacing body (which clearly affectconsequences rule), fact rule (20) contains nullary atom797fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & Wanghead immaterial. Thus, claim proved straightforward adaptationmembership proof Theorem 64. main difference algorithm that, nfunction symbols, need examine models depth n+1; however, algorithmstill uses polynomial space.(Hardness) Let arbitrary QBF, let hardness proofLemma 63. TBox WA; contains constant-free, equality-free, connectedrules; contain predicate zero arity. Hence, Lemma 7, Horn-SHITBox 0 exists valid 0 universally MFA.finish section proving checking whether set Horn-SHI rulesuniversally MSA PTime-hard; way, also obtain matching lower boundtheorem Theorem 62 Section 6.1.Theorem 66. Checking whether Horn-SHI TBox universally MSA PTime-hard.Proof. Let N set Horn propositional clauses form v1 . . . vn vn+1let v propositional variable; deciding N |= v well known PTime-hard. LetVi concept uniquely associated propositional variable vi ; let freshconcept; let TBox obtained transforming propositional clause Nform rule (161).A(x) V1 (x) . . . Vn (x) Vn+1 (x)(161)Finally, let = {A(a)}. Clearly, N |= v holds |= V (a) holds. TBoxWA, contains constant-free, equality-free, connected rules, predicatezero arity; hence, Lemma 7, Horn-SHI TBox 0 exists N 6|= v holds0 universally MFA. Finally, existential variable 0 occursrule form (23), straightforward see 0 universally MFA0 universally MSA.7. Experimentsestimate extent various acyclicity notions used practice, conducted two sets experiments. First, implemented MFA, MSA, JA, WA checkers,used check acyclicity large corpus Horn ontologies. goalsee many ontologies acyclic could thus used (suitably extended)materialisation-based OWL reasoners. Second, computed materialisationacyclic Horn ontologies compared number facts materialisation.goal tests see whether materialisation-based reasoning acyclicontologies practically feasible.Tests performed Windows R2 Server two Intel Xeon 3.06GHz processors.used repository 336 OWL ontologies whose TBox axioms transformedexistential rules least one rule contains existential quantifier head.ontologies include large subset Gardiner ontology corpus (Gardiner, Tsarkov, &Horrocks, 2006), LUBM ontology, several Phenoscape ontologies, numberontologies two versions Open Biomedical Ontology (OBO) corpus. Please note798fiAcyclicity Notions Existential Rulestest ontology obtained conceptual models (e.g., ER modelsUML diagrams): due specific modelling patterns used conceptual modelling,ontologies less likely acyclic. test ontology accessed onlineontology repository means unique ID.5 ID identifies one self-contained OWLontology frozen time imports resolved time ontology addedrepository; furthermore, possible future version ontology assignedfresh ID. measures ensure experiments independently repeatedpoint future.7.1 Acyclicity Testsimplemented acyclicity checks adapting HermiT reasoner.6 HermiTused transform ontology DL-clausesformulae quite close existential rules.result, at-least number restrictions head atoms replaced existentialquantification, atoms involving datatypes eliminated, DL-clauseshead atoms removed: datatypes empty heads cause inconsistencies,cannot prevent skolem chase terminating.set rules obtained preprocessing steps considered combination acyclicity notion X {WA, JA, MSA, MFA} follows. containequality predicate, simply checked whether X. contained equality predicate, checked whether X , also checked whether 0 X 0 setrules contain equality predicate; tests provided uslower upper bound acyclicity, respectively. acyclicity test performedmodifying (or 0 ) required X running HermiT check particularlogical entailment critical instance.tests revealed MFA MSA indistinguishable 336 test ontologies;is, MFA ontologies found MSA well (the converse holds per Theorem 14).total 213 (63.4%) ontologies found MSA, including 43 49 (87.8%)ontologies Gardiner corpus, 164 208 (78.8%) OBO ontologies,LUBM ontology. contrast, GALEN ontology variants, GO ontologyextensions, 55 Phenoscape ontologies found MFA.results summarised Table 2. Given large number ontologies tested, wouldimpractical present results ontology individually. Instead, ontologiesgrouped number generating rules (G-rules), rules containingexistential quantifier; group, Table 2 shows total number ontologies, wellnumbers ontologies found MSA, JA, WA. 123 ontologiesMFA, seven ontologies ELHr , CQ answering ontologiesrealised using combined approaches Lutz et al. (2009) Kontchakov et al. (2011).five older versions OBO ontologies (IDs 00359, 00374, 00376, 00382, 00486)MSA, whereas newer versions (IDs 00360, 00375, 00377, 00383, 00487)MFA. contrast, two older versions OBO ontologies MFA (IDs 0043200574), newer versions (IDs 00433 00575) MSA.5. URL http://www.cs.ox.ac.uk/isg/ontologies/UID/xxxxx.owl used download ontologyassigned ID xxxxx.6. http://www.hermit-reasoner.com/799fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangG-rules< 1001001K1K5K5K12K12K160Kontologies without equalityTotal MSA JAWA4442424169626241383130242823161418765ontologies equalityTotal MSA JA WA4839393941100172111050023100Table 2: Results acyclicity testsFinally, found 15 large OBO ontologies (including different versionsontologies) MSA JA. Thus, MSA seems particularly usefulcomplex ontologies since analyses implications existentially quantified variablesprecisely previously known notions. Table 3 shows ontologiesnumber generating rules (G-rules), whether ontology uses equality predicate(Eq), ontology expressivity description logic family languages (DL),number classes (C), properties (P), axioms (A) ontology contains. Differentversions ontology distinguished table old new. Twoontologies (IDs 00762 00766) containing equality predicate MSA ,status regarding joint acyclicity unknown: JA rules involvingequality predicate deleted, JA .7.2 Materialisation Testsestimate practicability materialisation acyclic ontologies, measuredmaximal depth function symbol nesting terms generated materialisation criticalinstances. measure, call ontology depth, interest provides usbound size materialisation. 213 MSA ontologies, testsucceeded 207 (tests aborted finish three hours).latter ontologies, depth distributed follows:123 (59.4%) ontologies depth less 5;30 (14.5%) ontologies depth 5 9;47 (22.7%) ontologies depth 10 19;5 (2.4%) ontologies depth 20 49;2 (1.0%) ontologies depth 50 70.results leads us believe many (but clearly all) ontologies manageabledepths, allow successful materialisation-based query answering.also computed materialisation several acyclic ontologies. implementation prototypical, primary goal evaluate performance computingmaterialisation, rather estimate blowup number facts. clearly800fiAcyclicity Notions Existential RulesOntology ID G-rules EqDLCPbiological process xp cell.imports-local.owl003717464yes SHIF 17296 178117925biological process xp cellular component.imports-local.owl (old)003748270yes SHIF 18673 186126796biological process xp multi organism process.imports-local.owl (old)003828378EL++ 27900 18295396biological process xp plant anatomy.imports-local.owl (old)003867559yes SHIF 19146 193122062biological process xp plant anatomy.imports-local.owl (new)0038712025 yes SRIF 27412 215213956bp xp cell.imports-local.owl003987419yes SHIF 17296 177117881bp xp cellular component.imports-local.owl004007999yes SHIF 18676 175126540cellular component xp go.imports-local.owl (old)004157752EL++ 278908210765cellular component xp go.imports-local.owl (new)0041612269EL++ 372549334762fypo.owl004761834EL++1677228027go xp regulation.imports-local.owl (old)004867777EL++ 278915295138go xp regulation.owl (old)004887777EL++ 278835214080go xp regulation.owl (new)004899507EL++ 301706238200molecular function xp regulators.imports-local.owl (old)005366762EL++ 255215198170molecular function xp regulators.imports-local.owl (new)0053711089EL++ 341358316057Table 3: MSA JA ontologiesexpect blowup depend linearly size input number facts; however,results provide us rough estimate performance materialisation-basedreasoning practice. test ontologies, however, contain many facts:ontologies often constructed general vocabularies, facts often applicationspecific thus publicly available. overcome problem, conducted twokinds experiments.First, computed materialisation two ontologies contain facts: LUBMone university (ID 00347), kmi-basic-portal ontology (ID 00078). TBoxLUBM eight generating rules depth one, 100, 543 facts ma801fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangDepth#<55910701233054timemax avg380.77179396 1807gen. sizemax avg652122301286 175mat. sizemax avg898132381297 189Table 4: Materialisation times (in seconds) sizesterialisation. Materialisation took 2 seconds, produced 231, 200 new facts,97, 860 added generating rules. kmi-basic-portal ontology tengenerating rules depth two, 198 facts materialisation. Materialisation took 0.03 seconds, produced 744 new facts, 145 addedgenerating rules.Second, ontologies identified MSA, instantiated classproperty fresh individuals. computed materialisation measuredgenerated size (the number facts introduced generating rules dividednumber facts materialisation), materialisation size (the number factsmaterialisation divided number facts materialisation), time neededcompute materialisation. Since generating rules ontologies singleton body atoms (i.e., form A(x) R.C(x)), measures providereasonable estimate increase number facts materialisation. Table 4summarises results tests 207 ontologies test succeeded. Ontologies grouped depth, group shows number ontologies (#),maximal average materialisation time, generated size, materialisation size.Thus, materialisation seems practically feasible many ontologies: 123 ontologiesdepth less 5, materialisation increases ontology size factor 8.suggests principled, materialisation-based reasoning ontologies beyond OWL 2RL profile may feasible, especially ontologies relatively small depths.8. Conclusionspaper, investigated acyclicity notionssufficient conditions ensure termination skolem chase existential rules. proposed two novel notions, called MFAMSA, determined tight complexity bounds membership checking, wellconjunctive query answering acyclic existential rules.also conducted thorough investigation acyclicity notions known literature, produced complete taxonomy relative expressiveness. resultsshow MFA MSA generalise previously considered notions.next investigated ways ensure acyclicity existential rules containequality predicate. end, presented several optimisations singularisationtechnique Marnette (2009). optimisations often reduce number acyclicitychecks needed, thus making singularisation technique suitable practical use.Finally, studied problem answering conjunctive queries acyclic DL ontologies. theoretical side, showed acyclicity make problem computation802fiAcyclicity Notions Existential Rulesally easier; furthermore, provided result acyclic, one extend Horn ontologiesarbitrary SWRL rules without affecting decidability worst-case complexityquery answering. practical side, investigated extent acyclicitynotions enable principled extensions materialisation-based ontology reasoners support existential quantification. tests show many ontologies commonly usedpractice acyclic, blowup number facts due materialisationmanageable. suggests principled extensions materialisation-based ontologyreasoners practically feasible useful.interesting topic future work see whether acyclicity notions usedgeneral logic programming setting. see several main sources technicaldifficulties towards goal. First, general logic programs contain functional termsbody atoms. terms cancel function symbols introduced head atoms,clear take account acyclicity test. Second, logic programscontain atoms nonmonotonic negation, likely need special treatment;Magka, Krotzsch, Horrocks (2013) recently made first step direction. Third,might desirable modularise ways different concerns handledthus arbitrarily combine approaches handling function symbols body and/orhead approaches dealing nonmonotonic negation.Acknowledgmentswork supported Royal Society, Seventh Framework Program (FP7)European Commission Grant Agreement 318338, Optique, EPSRCprojects ExODA, Score!, MaSI3 .ReferencesAbiteboul, S., Hull, R., & Vianu, V. (1995). Foundations Databases. Addison Wesley.Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.).(2007). Description Logic Handbook: Theory, Implementation Applications(2nd edition). Cambridge University Press.Baget, J.-F. (2004). Improving Forward Chaining Algorithm Conceptual GraphsRules. Dubois, D., Welty, C. A., & Williams, M.-A. (Eds.), Proc. 9th Int.Conf. Principles Knowledge Representation Reasoning (KR2004), pp. 407414, Whistler, BC, Canada. AAAI Press.Baget, J.-F., Leclere, M., Mugnier, M.-L., & Salvat, E. (2011a). rules existentialvariables: Walking decidability line. Artificial Intelligence, 175 (910), 16201654.Baget, J.-F., Mugnier, M.-L., & Thomazo, M. (2011b). Towards Farsighted DependenciesExistential Rules. Rudolph, S., & Gutierrez, C. (Eds.), Proc. 5th Int.Conf. Web Reasoning Rule Systems (RR 2011), Vol. 6902 LNCS, pp. 3045,Galway, Ireland. Springer.803fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangBaumgartner, P., Furbach, U., & Niemela, I. (1996). Hyper Tableaux. Proc.European Workshop Logics Artificial Intelligence (JELIA 96), No. 1126LNAI, pp. 117, Evora, Portugal. Springer.Beeri, C., & Vardi, M. Y. (1981). Implication Problem Data Dependencies.Even, S., & Kariv, O. (Eds.), Proc. 8th Colloquium Automata, LanguagesProgramming (ICALP 1981), Vol. 115 LNCS, pp. 7385, Acre (Akko), Israel.Springer.Bishop, B., & Bojanov, S. (2011). Implementing OWL 2 RL OWL 2 QL rule-setsOWLIM. Dumontier, M., & Courtot, M. (Eds.), Proc. OWL: ExpreiencesDirections Workshop (OWLED 2011), Vol. 796 CEUR WS Proceedings, SanFrancisco, UCA, USA.Broekstra, J., Kampman, A., & van Harmelen, F. (2002). Sesame: Generic ArchitectureStoring Querying RDF RDF Schema. Horrocks, I., & Hendler, J. A.(Eds.), Proc. 1st Int. Semantic Web Conf. (ISWC 2002), Vol. 2342 LNCS,pp. 5468, Sardinia, Italy. Springer.Cal, A., Gottlob, G., Lukasiewicz, T., Marnette, B., & Pieris, A. (2010a). Datalog :Family Logical Knowledge Representation Query Languages New Applications. Proc. 25th IEEE Symposium Logic Computer Science (LICS2010), pp. 228242, Edinburgh, United Kingdom. IEEE Computer Society.Cal, A., Gottlob, G., & Pieris, A. (2010b). Query Answering Non-guarded RulesDatalog . Hitzler, P., & Lukasiewicz, T. (Eds.), Proc. 4th Int. Conf.Web Reasoning Rule Systems (RR 2010), Vol. 6333 LNCS, pp. 117, Bressanone/Brixen, Italy. Springer.Cal, A., Gottlob, G., & Pieris, A. (2011). New Expressive Languages Ontological QueryAnswering. Burgard, W., & Roth, D. (Eds.), Proc. 25th National ConferenceArtificial Intelligence (AAAI 2011), pp. 15411546, San Francisco, CA, USA. AAAIPress.Calimeri, F., Cozza, S., Ianni, G., & Leone, N. (2008). Computable Functions ASP:Theory Implementation. Garcia de la Banda, M., & Pontelli, E. (Eds.), Proc.24th Int. Conf. Logic Programming (ICLP 2008), Vol. 5366 LNCS, pp.407424, Udine, Italy. Springer.Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). TractableReasoning Efficient Query Answering Description Logics: DL-Lite Family.Journal Automated Reasoning, 9 (3), 385429.Carroll, J. J., Dickinson, I., Dollin, C., Reynolds, D., Seaborne, A., & Wilkinson, K. (2004).Jena: Implementing Semantic Web Recommendations. Feldman, S. I., Uretsky,M., Najork, M., & Wills, C. E. (Eds.), Proc. 13th Int. Conf. World WideWeb (WWW 2004)Alternate Track, pp. 7483, New York, NY, USA. ACM.Cuenca Grau, B., Horrocks, I., Krotzsch, M., Kupke, C., Magka, D., Motik, B., & Wang, Z.(2012). Acyclicity Conditions Application Query Answering Description Logics. Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Proc. 13th Int.804fiAcyclicity Notions Existential RulesConf. Principles Knowledge Representation Reasoning (KR 2012), pp.243253, Rome, Italy.Cuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., & Sattler, U.(2008). OWL 2: next step OWL. Journal Web Semantics: Science, ServicesAgents World Wide Web, 6 (4), 309322.Dantsin, E., Eiter, T., Gottlob, G., & Voronkov, A. (2001). Complexity expressivepower logic programming. ACM Computing Surveys, 33 (3), 374425.De Schreye, D., & Decorte, S. (1994). Termination Logic Programs: Never-EndingStory. Journal Logic Programming, 1920, 199260.Demri, S., & de Nivelle, H. (2005). Deciding Regular Grammar Logics ConverseFirst-Order Logic. Journal Logic, Language Information, 14 (3), 289329.Deutsch, A., Nash, A., & Remmel, J. B. (2008). chase revisited. Lenzerini, M., &Lembo, D. (Eds.), Proc. 27th ACM SIGMOD-SIGACT-SIGART SymposiumPrinciples Database Systems (PODS 2008), pp. 149158, Vancouver, BC, Canada.Eiter, T., Gottlob, G., Ortiz, M., & Simkus, M. (2008). Query Answering DescriptionLogic Horn-SHIQ. Holldobler, S., Lutz, C., & Wansing, H. (Eds.), Proc.11th European Conference Logics Artificial Intelligence (JELIA 2008), Vol. 5293LNCS, pp. 166179, Dresden, Germany. Springer.Fagin, R., Kolaitis, P. G., Miller, R. J., & Popa, L. (2005). Data exchange: semanticsquery answering. Theoretical Computer Science, 336 (1), 89124.Gardiner, T., Tsarkov, D., & Horrocks, I. (2006). Framework Automated ComparisonDescription Logic Reasoners. Cruz, I. F., Decker, S., Allemang, D., Preist, C.,Schwabe, D., Mika, P., Uschold, M., & Aroyo, L. (Eds.), Proc. 5th Int. SemanticWeb Conference (ISWC 2006), Vol. 4273 LNCS, pp. 654667, Athens, GA, USA.Springer.Gebser, M., Schaub, T., & Thiele, S. (2007). GrinGo: New Grounder Answer SetProgramming. Baral, C., Brewka, G., & Schlipf, J. S. (Eds.), Proc. 9thInt. Conf. Logic Programming Nonmonotonic Reasoning (LPNMR 2007), Vol.4483 LNCS, pp. 266271, Tempe, AZ, USA.Glimm, B., Horrocks, I., Lutz, C., & Sattler, U. (2008). Conjunctive Query AnsweringDescription Logic SHIQ. Journal Artificial Intelligence Research, 31, 151198.Greco, S., Spezzano, F., & Trubitsyna, I. (2012). Termination Logic ProgramsFunction Symbols. Dovier, A., & Santos Costa, V. (Eds.), Proc. 8th Int.Conf. Logic Programming (ICLP 2012), Vol. 17 Leibniz International ProceedingsInformatics, pp. 323333, Budapest, Hungary.Hastings, J., Magka, D., Batchelor, C., Duan, L., Stevens, R., Ennis, M., & Steinbeck, C.(2012). Structure-based classification ontology chemistry. Journal Cheminformatics, 4 (8).Horrocks, I., & Patel-Schneider, P. F. (2004). Proposal OWL Rules Language.Proc. 13th Int. World Wide Web Conference (WWW 2004), pp. 723731, NewYork, NY, USA. ACM Press.805fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangHorrocks, I., & Sattler, U. (2007). Tableau Decision Procedure SHOIQ. JournalAutomated Reasoning, 39 (3), 249276.Horrocks, I., Patel-Schneider, P. F., Bechhofer, S., & Tsarkov, D. (2005). Owl rules:proposal prototype implementation. J. Web Sem., 3 (1), 2340.Hustadt, U., Motik, B., & Sattler, U. (2005). Data Complexity Reasoning Expressive Description Logics. Proc. 19th Int. Joint Conf. Artificial Intelligence(IJCAI 2005), pp. 466471, Edinburgh, UK. Morgan Kaufmann Publishers.Johnson, D. S., & Klug, A. C. (1984). Testing Containment Conjunctive QueriesFunctional Inclusion Dependencies. Journal Computer System Sciences,28 (1), 167189.Kiryakov, A., Ognyanov, D., & Manov, D. (2005). OWLIM Pragmatic Semantic Repository OWL. Dean, M., Guo, Y., Jun, W., Kaschek, R., Krishnaswamy, S., Pan,Z., & Sheng, Q. Z. (Eds.), Proc. Int. Workshop Web Information SystemsEngineering (WISE 2005), Vol. 3807 LNCS, pp. 182192, New York, NY, USA.Kontchakov, R., Lutz, C., Toman, D., Wolter, F., & Zakharyaschev, M. (2011). Combined Approach Ontology-Based Data Access. Walsh, T. (Ed.), Proc. 22ndInt. Joint Conf. Artificial Intelligence (IJCAI 2011), pp. 26562661, Barcelona,Spain.Krotzsch, M., & Rudolph, S. (2011). Extending Decidable Existential Rules JoiningAcyclicity Guardedness. Walsh, T. (Ed.), Proc. 22nd Int. Joint Conf.Artificial Intelligence (IJCAI 2011), pp. 963968, Barcelona, Spain.Krotzsch, M., & Rudolph, S. (2013). Relationship Joint Acyclicity SuperWeak Acyclicity. Tech. rep. 3037, Institute AIFB, Karlsruhe Institute Technology.Available online http://www.aifb.kit.edu/web/Techreport3013.Krotzsch, M., Rudolph, S., & Hitzler, P. (2007). Conjunctive Queries Tractable Fragment OWL 1.1. Aberer, K., Choi, K.-S., Noy, N. F., Allemang, D., Lee, K.-I.,Nixon, L. J. B., Golbeck, J., Mika, P., Maynard, D., Mizoguchi, R., Schreiber, G.,& Cudre-Mauroux, P. (Eds.), Proc. 6th Int. Semantic Web Conference (ISWC2007), Vol. 4825 LNCS, pp. 310323, Busan, Korea. Springer.Kutz, O., Horrocks, I., & Sattler, U. (2006). Even Irresistible SROIQ.Doherty, P., Mylopoulos, J., & Welty, C. A. (Eds.), Proc. 10th Int. Conf.Principles Knowledge Representation Reasoning (KR 2006), pp. 6878, LakeDistrict, UK. AAAI Press.Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).DLV system knowledge representation reasoning. ACM TransactionsComputational Logic, 7 (3), 499562.Lierler, Y., & Lifschitz, V. (2009). One Decidable Class Finitely Ground Programs. Hill, P. M., & Warren, D. S. (Eds.), Proc. 25th Int. Conf. LogicProgramming (ICLP 2009), Vol. 5649 LNCS, pp. 489493, Pasadena, CA, USA.Springer.Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive Query Answering DescriptionLogic EL Using Relational Database System. Boutilier, C. (Ed.), Proc. 21st806fiAcyclicity Notions Existential RulesInt. Joint Conf. Artificial Intelligence (IJCAI 2009), pp. 20702075, Pasadena, CA,USA.Magka, D., Krotzsch, M., & Horrocks, I. (2013). Computing Stable Models Nonmonotonic Existential Rules. Proc. 23rd Int. Joint Conf. Artificial Intelligence(IJCAI 2013). AAAI Press/IJCAI. appear.Magka, D., Motik, B., & Horrocks, I. (2012). Modelling Structured Domains Using Description Graphs Logic Programming. Simperl, E., Cimiano, P., Polleres, A.,Corcho, O., & Presutti, V. (Eds.), Proc. 9th Extended Semantic Web Conference(ESWC 2012), Vol. 7295 LNCS, pp. 330344, Heraklion, Greece. Springer.Maier, D., Mendelzon, A. O., & Sagiv, Y. (1979). Testing Implications Data Dependencies. ACM Transactions Database Systems, 4 (4), 455469.Marnette, B. (2009). Generalized schema-mappings: termination tractability.Paredaens, J., & Su, J. (Eds.), Proc. 28th ACM SIGMOD-SIGACT-SIGARTSymposium Principles Database Systems (PODS 2009), pp. 1322, Providence,RI, USA.Marnette, B. (2010). Tractable Schema Mappings Oblivious Termination. Ph.D.thesis, University Oxford, Oxford, UK.Meditskos, G., & Bassiliades, N. (2008). Combining DL Reasoner Rule EngineImproving Entailment-Based OWL Reasoning. Sheth, A. P., Staab, S., Dean, M.,Paolucci, M., Maynard, D., Finin, T. W., & Thirunarayan, K. (Eds.), InternationalSemantic Web Conference, Vol. 5318 LNCS, pp. 277292, Karlsruhe, Germany.Meier, M. (2010). Termination Chase Algorithm. Ph.D. thesis, UniversitatFreiburg.Meier, M., Schmidt, M., & Lausen, G. (2009). Chase Termination Beyond Stratification.Proceedings VLDB Endowment, 2 (1), 970981.Motik, B., Cuenca Grau, B., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2009a). OWL 2Web Ontology Language: Profiles, W3C Recommendation.http://www.w3.org/TR/owl2-profiles/.Motik, B., Shearer, R., & Horrocks, I. (2009b). Hypertableau Reasoning DescriptionLogics. Journal Artificial Intelligence Research, 36, 165228.Mungall, C. (2009). Experiences Using Logic Programming Bioinformatics. Hill,P. M., & Warren, D. S. (Eds.), Proc.of 25th Int. Conf. Logic Programming(ICLP 2009), Vol. 5649 LNCS, pp. 121, Pasadena, CA, USA. Springer.Ortiz, M., Calvanese, D., & Eiter, T. (2008). Data Complexity Query AnsweringExpressive Description Logics via Tableaux. Journal Automated Reasoning, 41 (1),6198.Ortiz, M., Rudolph, S., & Simkus, M. (2011). Query Answering Horn FragmentsDescription Logics SHOIQ SROIQ. Walsh, T. (Ed.), Proc. 22ndInt. Joint Conf. Artificial Intelligence (IJCAI 2011), pp. 10391044, Barcelona,Spain.807fiCuenca Grau, Horrocks, Krotzsch, Kupke, Magka, Motik, & WangPerez-Urbina, H., Motik, B., & Horrocks, I. (2009). Tractable Query Answering Rewriting Description Logic Constraints. Journal Applied Logic, 8 (2), 151232.Rudolph, S., & Glimm, B. (2010). Nominals, Inverses, Counting, Conjunctive Queriesor: Infinity Friend!. Journal Artificial Intelligence Research, 39, 429481.Spezzano, F., & Greco, S. (2010). Chase Termination: Constraints Rewriting Approach.Proceedings VLDB Endownment, 3 (1), 93104.Syrjanen, T. (2001). Omega-Restricted Logic Programs. Eiter, T., Faber, W., &Truszczynski, M. (Eds.), Proc. 6th Int. Conference Logic ProgrammingNonmonotonic Reasoning (LPNMR 2001), Vol. 2173 LNCS, pp. 267279, Vienna,Austria. Springer.Syrjanen, T., & Niemela, I. (2001). Smodels System. Eiter, T., Faber, W., &Truszczynski, M. (Eds.), Proc. 6th Int. Conf. Logic Programming Nonmonotonic Reasoning (LPNMR 2001), Vol. 2173 LNAI, pp. 434438, Vienna, Austria. Springer.Wu, Z., Eadon, G., Das, S., Chong, E. I., Kolovski, V., Annamalai, M., & Srinivasan, J.(2008). Implementing Inference Engine RDFS/OWL Constructs UserDefined Rules Oracle. Alonso, G., Blakeley, J. A., & Chen, A. L. P. (Eds.), Proc.24th Int. Conf. Data Engineering (ICDE 2008), pp. 12391248, Cancun,Mexico. IEEE.808fiJournal Artificial Intelligence Research 47 (2013) 613-647Submitted 1/13; published 7/13Asymmetric Distributed Constraint Optimization ProblemsTal GrinshpounAlon Grubshteingrinshpo@cs.bgu.ac.ilalongrub@cs.bgu.ac.ilDepartment Computer ScienceBen-Gurion University NegevBeer-Sheva, IsraelRoie Zivanzivanr@bgu.ac.ilDepartment Industrial Engineering ManagementBen-Gurion University NegevBeer-Sheva, IsraelArnon NetzerAmnon Meiselsnetzerar@cs.bgu.ac.ilam@cs.bgu.ac.ilDepartment Computer ScienceBen-Gurion University NegevBeer-Sheva, IsraelAbstractDistributed Constraint Optimization (DCOP) powerful framework representingsolving distributed combinatorial problems, variables problemowned different agents. Many multi-agent problems include constraints producedifferent gains (or costs) participating agents. Asymmetric gains constrainedagents cannot naturally represented standard DCOP model.present paper proposes general framework Asymmetric DCOPs (ADCOPs).ADCOPs different agents may different valuations constraintsinvolved in. new framework bridges gap multi-agent problems tendasymmetric structure standard symmetric DCOP model. benefitsproposed model previous attempts generalize DCOP model discussedevaluated.Innovative algorithms apply special properties proposed ADCOPmodel presented detail. include complete algorithms substantialadvantage terms runtime network load existing algorithms (for standardDCOPs) use alternative representations. Moreover, standard incomplete algorithms(i.e., local search algorithms) inapplicable existing DCOP representationsasymmetric constraints applied new ADCOP frameworkoften fail converge local optimum yield poor results. local search algorithmsproposed present paper converge high quality solutions. experimental evidencepresented reveals proposed local search algorithms ADCOPs achievehigh quality solutions preserving high level privacy.1. Introductionuniverse asymmetric persuaded life, known us,direct result asymmetry universe indirect consequences. universe asymmetric. Louis Pasteurc2013AI Access Foundation. rights reserved.fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsMulti-agent systems (MAS) often include combinatorial problem distributedamong agents. Examples multi-agent combinatorial problems MeetingsScheduling problem (Modi & Veloso, 2004; Gershman, Grubshtein, Meisels, Rokach, &Zivan, 2008), Sensor nets (Zhang, Xing, Wang, & Wittenburg, 2005; Zivan, Glinton, &Sycara, 2009), Vehicle Routing (Leaute & Faltings, 2011). natural representationproblems terms agent-owned variables terms agent-specified valuescombinations assignments (whether costs utilities), encouraged study Distributed Constraint Optimization Problems (DCOPs). DCOPs powerful frameworkformulating solving MAS combinatorial problems. last decade algorithmicsearch techniques DCOPs intensively studied (Yeoh, Felner, & Koenig, 2010; Petcu& Faltings, 2006; Mailler & Lesser, 2004; Gershman, Meisels, & Zivan, 2009). Since DCOPsNP-hard, many recent studies consider incomplete algorithms (Maheswaran, Pearce, &Tambe, 2006; Zhang et al., 2005; Pearce & Tambe, 2007; Zivan, 2008; Rogers, Farinelli,Stranders, & Jennings, 2011).strong relation MAS DCOPs identified discussed previousstudies (e.g., Maheswaran et al., 2006; Chapman, Rogers, & Jennings, 2008). Chapmanet al. (2008) examine analogy DCOP formulation class gamesknown Potential Games. importance analogy lies fact everyfinite potential game possesses least one pure strategy Nash Equilibrium (NE) (Monderer& Shapley, 1996).world game theory, pure strategy NE stable profile actions corresponding set participants, unilateral change action singleparticipant yield better personal gain participant. DCOP formulation, definition coincides special solutions known local optima (minimamaxima) (Yokoo, 2000; Zhang et al., 2005). solutions sets assignmentsvariables made agents, single change assignment agentreduce global gain.source correspondence NEs local optima stems constraint structure DCOPs. constraint C variables k agents definedmapping domains variables single (positive) real value:C : Di1 Di2 Dik R+definition constraint implies cost (gain) constraintparticipating agents. agent lowers cost gain constraint,constrained peers share similar decrement cost constraint. Thus,clear change assignment reduce personal gains reducesglobal gains well.many real life situations constrained agents value differently results decisionsconstrained issues even consider constraints. fact, naturalscenario typical MAS situation following examples. meeting scheduling problem, agents attend meeting may derive different utilities it.Moreover, preferences constraints regarding time location expecteddifferent. Another example distributed application asymmetricsmart grid (Ramchurn, Vytelingum, Rogers, & Jennings, 2011), cost users payelectricity may higher heavy load hours, yet increase price endured614fiAsymmetric Distributed Constraint Optimization Problemsrespect agents use evenly spread among users. Supply chain management (Burke, Brown, Dogru, & Lowe, 2007) among multiple consumers might also includeasymmetric constraints. Different consumers different levels urgency regardingtime supply, therefore latency costs endure different.observation calls generalization standard DCOP model (Modi,Shen, Tambe, & Yokoo, 2005; Meisels, 2007). generalized model enablerepresentation asymmetric gains agents involved constraint. result,applicable asymmetric MAS scenarios.Former studies proposed capture asymmetric gains among constrained agents introducing additional variables agent. additional variables duplicatesvariables constrained agents. agent holds duplications every variablevariables constrained with. imposing hard equality constraints variablesduplications model allows agent account constraints (Maheswaran, Tambe, Bowring, Pearce, & Varakantham, 2004b; Petcu, 2007). completescheme duplicating variables constrained agents using rigid constraintsenforce equality assignments agents termed Private Events Variables(PEAV).considering complete search, PEAV formulation indeed offers solvable representation asymmetric DCOP allows use algorithms designed solvesymmetric DCOPs. main consequence using model incrementproblem size, (as demonstrated experimental evaluation present paper) NP-hard problem DCOP, devastating effect performance.situation becomes complicated considering incomplete methods. Specifically, PEAV enable use standard local search algorithms solving asymmetric problems. present paper demonstrates every allocation satisfieshard equality constraints PEAV local optimum cannot escaped localsearch algorithms.present study proposes Asymmetric DCOPs (ADCOPs), model representingasymmetric combinatorial multi-agent problems. ADCOPs naturally accommodate constraints participating agents different gains costs. allows agenthold evaluation different outcomes respect constraint involvedin.shortcomings existing DCOP algorithms solving problems representedproposed model triggers intensive algorithmic study:1. complete search propose algorithms solve asymmetric problem without need expand number variables problem PEAV model.advantages performance proposed algorithms state-of-the-art complete algorithms use PEAV representation demonstrated empirically.2. incomplete (local) search propose algorithms able converge highquality solutions solving asymmetric problems, contrast existing DCOP local search algorithms. proof guarantees convergence provided. proposed algorithms require exchange problems information among agents.Thus, algorithms evaluated terms solution quality, terms615fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meiselsprivacy well. empirical results present paper demonstrateprivacy loss proposed algorithms minor.rest paper organized follows. proposed Asymmetric DCOP modelpresented Section 2 along several alternatives representing asymmetric constraints within standard DCOP model. Section 3 introduces new complete search algorithms designated efficiently correctly solve asymmetric problems. Section 4focuses local search. demonstrates incompatibility existing local search algorithms solving asymmetric problems proposes several novel asymmetric local searchalgorithms. Section 5 includes extensive experimental evaluation complete searchalgorithms local search algorithms. results experimental evaluation quiteconclusive. paper summarized conclusions drawn Section 6.2. Asymmetric Distributed Constraint OptimizationFirst, standard DCOP model presented followed proposed generalizationcaptures asymmetric constraints. Next, alternatives representing asymmetric constraints standard DCOP model described.2.1 Distributed Constraint Optimization Problems (DCOPs)DCOP tuple hA, X , D, Ri. finite set agents A1 , A2 , ..., . X finiteset variables X1 , X2 , ..., Xm . variable held single agent (an agent may holdone variable). set domains D1 , D2 , ..., Dm . domain Di containsfinite set values assigned variable Xi . R set relations (constraints).constraint C R defines non-negative cost every possible value combinationset variables, form:C : Di1 Di2 . . . Dik R+(1)binary constraint refers exactly two variables form Cij : Di Dj R+ .binary DCOP DCOP constraints binary. value assignment pairincluding variable, value variables domain. partial assignment (PA)set value assignments, variable appears once. full assignmentsolution partial assignment includes variables (vars(P A) = X ).optimal solution full assignment aggregated minimal cost.maximization problems, constraint utilities instead costssolution full assignment maximal aggregated utility. rest paper, unlessstated differently, problems discussed minimization problems.2.2 Asymmetric DCOPs (ADCOPs)ADCOPs generalize DCOPs following manner: instead assuming equal payoffsconstrained agents, ADCOP constraint explicitly defines exact payoffparticipant. is, domain values mapped tuple costs, one constrainedagent.formally, ADCOP defined following tuple hA, X , D, Ri, A, X ,defined exactly manner DCOPs. constraint C R616fiAsymmetric Distributed Constraint Optimization ProblemsA2A1 \x3, 46, 1b7, 25, 8x1x2Figure 1: two agents interaction. left-hand side presents agents costs incurredinteraction Agent A1 possible value assignments either bcosts endure depicted left value cell. Agent A2 possiblevalue assignments x (costs right side). right-hand sidefigure provides graphical presentation resulting ADCOP network.asymmetric DCOP defines set non-negative costs every possible value combinationset variables, takes following form:C : Di1 Di2 Dik Rk+(2)definition asymmetric constraint natural general MAS problems,requires little manipulation formulating ADCOPs. applies agentholds exactly one variable among k variables involved constraint C. noteseveral variables involved constraint held agent, lengthvector costs representing constraint equal number agents involvednumber variables.Consider simple example two interacting agents presented Figure 1.problem agent pays either left- right-hand side values depictedbi-matrix Figure 1. Agent A1 controls variable x1 may assign either bAgent A2 controls variable x2 may assign values x y. constrainttwo interacting agents maps assignment pairs cost pairs. example, agent A1assigns value b agent A2 assigns value x, A1 cost 7 A2 cost2. often refer cost pairs two sides constraint. right-hand sidefigure illustrates ADCOP formulation problem terms agentsvariables (where single constraint presented full bi-matrix left).noted although ADCOP model bears great resemblancegraphical games model (Kearns, Littman, & Singh, 2001) two modelsfundamentally different. game-theoretic agents self-interested entities, ADCOPagents cooperative nature always follow protocol (algorithm) evenrisk personal degradation gain.2.3 Alternatives Representing Asymmetric ConstraintsExtending Distributed Constraint Reasoning (DCR) (Meisels, 2007) paradigm encompass asymmetric payoffs great interest considering real world problems. Typicalproblems must often take account individual state agent (remaining battery life, user preferences, etc) rarely coincide. Several alternatives representingasymmetric constraints DCOPs discussed former papers.617fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels2.3.1 Disclosure Constraint Payoffssimplest way solve MAS problems asymmetric payoffs DCOPsdisclosure constraint payoffs. is, aggregate values agents taking joint action. However, constraint disclosure reveals private information (preferences) (Greenstadt,Pearce, & Tambe, 2006; Maheswaran, Pearce, Varakantham, Bowring, & Tambe, 2005;Yokoo, K.Suzuki, & Hirayama, 2002) many times needs avoided.2.3.2 Use Unary Constraintspossible technique representing preferences affecting different payoffsintroduction unary constraints. Constraints added variable participatingconstraint additional costs generate asymmetry.Proposition 1 exists asymmetric DCOP cannot expressed symmetricDCOP addition unary constraints form UAi () = .Proof: Consider example interaction depicted Figure 1. general solutionadd unary constraint variable held agents. cost binaryconstraint, B(, ), unary constraint variable UA (), UB () must consistentcost incurred agent, described following set linearequations:UA1 (a) + B(a, x) = 3UA1 (a) + B(a, y) = 6...UA2 (y) + B(b, y) = 8set equations derived problem Figure 1 solution.Corollary 2 Symmetric DCOPs addition unary constraints strictly lessexpressive asymmetric DCOPs.Proof: remains show every problem unary symmetric binary constraints represented asymmetric DCOP. Unary constraints integral partasymmetric DCOP model, symmetric binary constraints inherently less expressive asymmetric ones. Consequently, every symmetric DCOP (with added unaryconstraints) represented asymmetric DCOP.unary constraints approach thus shown insufficient representing asymmetric constraints. precisely, approach fails properly capture casespersonal valuation state agent dependent upon assignments agents.618fiAsymmetric Distributed Constraint Optimization ProblemsA2A1 \hx,hy,hx, bhy, bha, x75455111ha,60710864hb, x61108965hb,109565713x11x12x22x21Figure 2: interaction Figure 1 formulated PEAV-DCOP. left-handside presents value possible end state. right-hand side providesgraphical representation resulting PEAV-DCOP network.2.3.3 Private Events Variables (PEAV)PEAV model (Maheswaran et al., 2004b) successfully captures asymmetric payoffswithin standard DCOPs. incurred cost PEAV model agent involves onemirror variable per neighbors constraint network (i.e., constrainedvariable held another agent). Consistency neighbors state variables imposedset hard equality constraints. One way represent hard constraints assigncost calculated specific problem (Maheswaran et al., 2004b).resulting representation asymmetric MAS problem PEAV-DCOP muchlarger terms variables constraints ADCOP. Figure 2 describesinteraction Figure 1 formulated according PEAV (note minimizationproblem). example x11 x22 original variables x12 x21 mirrorvariables generated PEAV formulation. upper bound value used hardconstraint example 50.cost end state depicted table left-hand side figure.example, top-left cell represents assignments x11 = a, x22 = x, consistentvalues mirror variables. Consequently, cost (7) exactly sum costsagents original MAS problem (Figure 1).PEAV representation problem must accommodate mirror variables,combinations values previously considered must also taken account.example, top-right cell represents assignments x11 = a, x22 = y, mirrorvariables consistent original variables (x12 = x, x21 = b). cost (111)includes sum costs agents original MAS problem, agentconsiders value mirror variable real value agent (3 8).value, two upper bound values (50 each) added express inconsistencymirror variables. Consequently, PEAV matrix 4 4, including 16 payoff valuesquadratic increase size search space.3. Asymmetric Distributed Complete SearchAlthough DCOPs NP-hard, large number former DCOP research dedicatedcomplete search algorithms (Modi et al., 2005; Yeoh et al., 2010; Petcu & Faltings, 2006;619fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsA2A1xA3A1j3, 46, 13, 24, 1b7, 25, 8b1, 13, 2A1A2A3Figure 3: Example problem.Mailler & Lesser, 2004; Gershman et al., 2009). Unfortunately, existing completeDCOP algorithms cannot find optimal solution solving ADCOPs. elaborateissue beginning section introduce several novel completeADCOP algorithms.3.1 Complete Search Asymmetric ConstraintsOne may attempt solve ADCOPs simply using existing complete DCOP algorithms.following scenario demonstrates shortcomings attempt. ConsiderSyncBB algorithm (Hirayama & Yokoo, 1997). SyncBB chosen simplicity, however, demonstration relevant existing DCOP algorithms. SyncBB partialassignment generated sequentially Current Partial Assignment (CPA) message (cf.,Meisels, 2007). agent receives CPA, assigns variable overallcost partial assignment minimal. Running Branch & Bound algorithm implieswhenever cost partial assignment becomes larger upper bound,agent holds CPA backtracks agent it.ADCOPs standard process correct. full cost partialassignment must include constraints held agents participate it.words, agent Ai assigns variables compute cost CPAbased evaluation, agents higher priority (i.e., ordered it)holding constraints agents newly assigned variable own. Considerexample problem Figure 3. attempting solve problem using SyncBB,parts constraints held lower priority agents constraintevaluated. Thus, resulting solution hA1 = a, A2 = y, A3 = ji cost 2.constraints held higher priority agents (A1 example) evaluated. realcost solution considering sides constraints 12. actual solutionhA1 = b, A2 = x, A3 = ii cost 11.Following example, clear existing complete DCOP algorithmslonger correct ADCOP model used. complete ADCOP algorithmmust allow agents participating constraint evaluate related assignments.exception may OptAPO algorithm (Mailler & Lesser, 2006), since performdistributed search order resolve conflicts (Grinshpoun & Meisels, 2008). Thus,620fiAsymmetric Distributed Constraint Optimization Problems(mediator) agents perform search able generate centralized (symmetric)problem solve it.3.2 ADCOP Complete Search AlgorithmsSolving asymmetric problem requires parts binary constraintevaluated aggregated assignments cost. Similarly DCSP case (Brito,Meisels, Meseguer, & Zivan, 2009) considering sides constraints generallyperformed two ways. One strategy solve problem two phases. firstphase, full assignment reached considering one side constraintphase performed using symmetric DCOP algorithm. second phase,full cost assignment verified checking complementary partinvolved constraints. second phase complete new bounds set, firstphase resumed search better solution entire search space covered.Another strategy systematically check sides constraints reachingfull assignment, forming one-phase strategy. present paper refers checkingreversed-order part constraints back-checking. Back-checking performedeither synchronously asynchronously.next present several innovative complete algorithms designed ADCOPs.begin introducing two asymmetric versions SyncBB algorithm. first version,SyncABB-2ph, follows two-phase strategy, version follows one-phasestrategy. also present Asynchronous Two-Way Bounding algorithm (ATWB),asymmetric version AFB algorithm (Gershman et al., 2009). ATWB also followsone-phase strategy naturally performs asynchronous back-checking.3.2.1 Synchronous Asymmetric Branch & Bound 2-phase (SyncABB-2ph)SyncABB-2ph algorithm combination SyncBB algorithm two-phasestrategy. phase algorithm works exactly SyncBB, agent countscosts constraints lower-indexed agents. Phase completed fullassignment reached. standard (symmetric) SyncBB operating symmetric DCOP,means new best solution new bound found. ADCOPs backchecking needed order verify reversed order parts constraintsincrement cost beyond bound.Algorithm 1 SyncABB-2ph: phase IIreceived hCPA BACK MSG, CPA, costi1: f cost constraints higher-indexed agents (Ai+1 ...An )2: cost + f B3:send hCPA MSG, CPAi4: else Ai 6= A15:send hCPA BACK MSG, CPA, cost + f Ai16: else7:B cost + f8:broadcast hNEW SOLUTION, CPA, Bi9:send hCPA MSG, CPAi621fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsA1CPACPAA1=bA2=yA3=jA1=bA2=yA3=iA2A3A1A2Cost=8Cost=9(a)A1(b)CPACPAA1=bA2=yA3=iA1=bA2=yA3=iA2A3A3A1Cost=9A2A3Cost=15(c)(d)Figure 4: SyncABB-2ph example limited pruning.phase II last agent (An ) sends preceding agent (An1 ) CPA BACK MSGmessage. message includes CPA one-side cost gathered phaseI. agent receives CPA BACK MSG message (Algorithm 1) performs backchecking computing cost f constraints upper-indexed agents (line 1).addition f cost CPA (the lower bound) reaches bound B (line 2),point continue back-checking phase since value assignment mustreplaced. ensure completeness algorithm, regardless agent identifiedcost exceeded global bound (the lowest cost full assignment found far),CPA must returned last agent (line 3). global boundreached, back-checking continues preceding agent (lines 4-5) reaches A1 .total cost CPA existing global bound, agent A1 updatesbound B (line 7) informs agents new best solution new bound (line8). Next, phase resumed sending CPA back last agent (line 9).solving process parts search space expected pruned.fact, amount pruned search space faithfully reflects effectiveness Branch &Bound algorithm. Lines 2 3 Algorithm 1 state global bound reachedback-checking phase, CPA returned last agent. Returning CPAlast agent means pruning. Consequently, run SyncABB-2phalgorithm pruning achieved first phase. limits pruningperformed algorithm since first phase subset constraintsconsidered. shortcoming algorithm illustrated Figure 4.value A2 assigned (stage a), CPA hA1 = b, A2 = yi. global look CPA(that considers sides constraint) reveals cost 13, highercurrent bound (11 stage search). Nevertheless, first phasealgorithm one side constraint evaluated, resulting cost 8. Thus,622fiAsymmetric Distributed Constraint Optimization ProblemsCPA advances agent A3 also assigns value (stage b). bound passedsecond phase (stage d), CPA returned back agent A3 , turnassign value A3 = j.demonstrated pruning problem may well result poor performanceSyncABB-2ph algorithm. Indeed, experimental evaluation supported conjecture,two-phase approach abandoned.3.2.2 Synchronous Asymmetric Branch & Bound 1-phase (SyncABB)SyncABB algorithm combination SyncBB algorithm one-phasestrategy. step algorithm, agent adds assignment CPAupdates cost one side constraint, CPA sent back agentsalready assigned variables update lower bound adding costsbackwards directed constraints (back-checking). done replacing CPA MSGmessage sent value assignment next agent (as SyncBB SyncABB2ph) CPA BACK MSG message preceding agent.Algorithm 2 SyncABB: back-checkingreceived hCPA BACK MSG, CPA, costi1: j CP A.lastId2: f cost constraint agent Aj3: cost + f B4:send hCPA MSG, CPAi Aj5: else Ai 6= A16:send hCPA BACK MSG, CPA, cost + f Ai17: else Aj =8:B cost + f9:broadcast hNEW SOLUTION, CPA, Bi10:send hCPA MSG, CPAi11: else12:CP A.cost cost + f13:send hCPA MSG, CPAi Aj+1handling CPA BACK MSG SyncABB presented Algorithm 2. First,important know identity j initiator back-checking (in SyncABB-2phalways n). Consequently, agent (in SyncABB-2ph) replaced Aj (lines2,4). Additionally, back-checking complete (reaches A1 ) Aj lastagent (line 11), algorithm simply sends CPA next assigning agent Aj+1 (line13).Figure 5 illustrates CPA moved agents SyncABB algorithm. given example shows run algorithm beginning searchprocess problem depicted Figure 3.main motivation one-phase version global bound reached,CPA returned initiator back-checking (line 4), many cases. lead effective pruning search space comparisontwo-phase strategy. behavior algorithm illustrated Figure 6.623fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsCPACPAA1=aA2=xA3=iA1=aA2=xA3=iA1A2A1A3A2A3Cost=4Cost=0(b)(a)CPACPAA1=aA2=xA3=iA1=aA2=xA3=iA1A2A3A1A2Cost=7Cost=9(c)A1A3(d)CPACPAA1=aA2=xA3=iA1=aA2=xA3=iA2A3A1Cost=9A2A3Cost=12(e)(f)Figure 5: SyncABB-1ph example.A1CPACPAA1=bA2=yA3=jA1=bA2=yA3=jA2A3A1Cost=8A2A3Cost=13(a)(b)Figure 6: SyncABB-1ph example effective pruning.value A2 assigned (stage a), CPA includes hA1 = b, A2 = yi. backchecking performed (stage b) cost becomes 13 bound (11 stagesearch) reached. CPA passed point back agent A2 . Consequently,search space pruned (complete assignments hA1 = b, A2 = y, A3 = iihA1 = b, A2 = y, A3 = ji).624fiAsymmetric Distributed Constraint Optimization ProblemsProposition 3 SyncABB sound complete.Proof: soundness SyncABB immediate since CPA sent forward assigning agent new assignment evaluated agents whose assignmentincluded CPA. words, CPA sent forward costs generatedaddition new value assignment added lower bound CPA(Algorithm 2, lines 12-13). includes complete assignment reported solution(lines 8-10).completeness SyncABB follows exhaustive search structure. partial assignments whose cost exceeds global bound extended thereforeexistence solution lower cost solution found algorithm ruledout.Termination also follows exhaustive structure Branch & Bound algorithm partial assignment explored twice.3.2.3 Asymmetric Two-Way Bounding (ATWB)achieve larger degree asynchronicity, one build upon existing efficientasynchronous DCOP algorithm, AFB (Gershman et al., 2009). AFB found perform faster competing complete algorithms DPOP ADOPT. AFBalgorithm agents assign CPA sequentially SyncBB, following assignmentassigning agent triggers asynchronous checks bounds sending copies CPAvia BOUND CPA messages agents yet assigned variables.agents receive copies CPA calculate lower bound cost constraints hold assignments CPA. lower bound sent backassigning agent via ESTIMATE message. assigning agent aggregates boundsESTIMATE messages receives updated lower bound exceedscurrent upper bound, agent initiates backtrack.AFB algorithm adjusted accommodate forward bounding backward bounding thus, adjusted solving ADCOPs. words, insteadsending assigned CPA back first assigning agent sequentially SyncABB,copies CPA sent backwards agents whose assignments includedCPA. Agents receive copy CPA compute estimate send back(forward) assigning agent standard AFB. refer versionAsynchronous Two-Way Bounding algorithm (ATWB).ATWB algorithm follows pseudo-code AFB (Gershman et al., 2009)several modifications. BOUND CPA messages sent forward backwardswhenever value assigned (procedure assign CPA). Additionally, last agentcannot declare new solution receives estimates backward bounding.Thus, handling ESTIMATE messages must revised new version givenAlgorithm 3.estimate message received agent checks whether new estimate reachesglobal bound (line 2). case, new value assigned currentagent (line 3). case last agent backward estimates arrived(line 4), agent declare new solution (lines 5-6) assign new value (line 7).625fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsAlgorithm 3 ATWB receive estimatereceived (ESTIMATE, estimate)1: save estimate2: (CPA.cost + saved estimates) B3:assign CPA()4: else CPA full assignment estimates arrived5:B CPA.cost + saved estimates6:broadcast (NEW SOLUTION, CPA, B)7:assign CPA()case forward bounding, agent still know assignmentselect therefore estimate lower bound cost constraints consideringvalues variables domain. contrast, agent Ai receives BOUND CPAmessage agent Aj ordered (backward bounding), accurately computecost constraints assignment assignments CPA.precomputed h2 (v, j) function (per value v, per agent Aj holds current CPA)gives lower bound cost constraints agents Ajorder (Ak |k > j) added estimation computation. h2 (v, j) functionalso used forward bounding lower bound back-checking value vagents Ai Aj (Ak |j < k < i). h2 function additive, since refersback-checking yet unassigned variables.Proposition 4 ATWB sound complete.Proof: soundness ATWB established fact new solution storedlater reported estimates arrive last agent (Algorithm 3, lines 4-6).point, constraints evaluated involved agents. Noteestimates received last agent include (backward) constraints. possibilityestimate yet received agent (due delay messages)compromise algorithms soundness. case delayed estimate would triggeredneed backtrack, estimate sent agent last agent would leasthigh therefore would trigger backtrack well.Similarly SyncABB, completeness termination ATWB followexhaustive structure Branch & Bound algorithm.4. Asymmetric Distributed Local SearchDistributed local search techniques solving DCOPs gained popularity recentyears. Although local search algorithms inherently incomplete, i.e. guarantee report optimal solution, offer practical solution significantly largerproblems. Adding asymmetry problems makes complete solving process evendifficult, fact enhances suitability local search solving ADCOPs.next present overview standard DCOP local search algorithms followeddiscussion applicability asymmetric case. introduce several novellocal search algorithms designed solving ADCOPs.626fiAsymmetric Distributed Constraint Optimization Problems4.1 Local Searchgeneral design local search algorithms DCOPs synchronous. stepalgorithm agent sends assignment neighbors constraint networkreceives assignments neighbors. hereby present detail two leadingalgorithms apply general framework Distributed Stochastic Algorithm(DSA) (Zhang et al., 2005) Max Gain Message (MGM) algorithm (Maheswaran,Pearce, & Tambe, 2004a).1initial step DSA algorithm agents randomly pick value assignmentvariable. Next, agents perform sequence steps termination conditionmet. step, agent sends value assignment neighbors constraintsgraph receives assignments neighbors. present paper follows generaldefinition DCOP include synchronization mechanism.mechanism exists, agents DSA send value messages stepschange value assignments. collecting assignments neighbors,agent decides whether keep value assignment change it, using stochasticstrategy (see Zhang et al., 2005 details possible strategies differenceresulting performance). sketch DSA presented Algorithm 4.Algorithm 4 Standard DSA1: value ChooseRandomValue()2: termination condition met3:send value neighbors4:collect neighbors values5:ReplacementDecision()6:select assign next valueMGM algorithm strapped version DBA algorithm (Yokoo, 2000;Zhang et al., 2005). every synchronous step, agent sends current value assignmentneighbors collects current value assignments. receiving assignmentsneighbors, agent computes maximal improvement (i.e., reduction cost)local state achieved replacing assignment sends proposedreduction neighbors. collecting proposed reductions neighbors,agent changes assignment proposed reduction greater reductionsproposed neighbors. advanced versions MGM, agents group togetherorder propose common improvement thus avoid local minima smallergroup would converged. Algorithm 5 includes sketch standard MGM algorithm.selecting random value variable (line 1), agent enters loopiteration step algorithm. sending value assignment neighborscollecting value assignments (lines 3-4), agent calculates best weight reductionsends neighbors (lines 5-6). receiving possible weight reductionsneighbors agent decides whether replace assignment upon positivedecision reassigns variable (lines 7-10).1. description considers improvement decrease number violated constraints (asMax-CSPs).627fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsAlgorithm 5 Standard MGM1: value ChooseRandomValue()2: termination condition met3:send value neighbors4:collect neighbors values5:LR BestPossibleLocalReduction()6:send LR neighbors7:collect neighbors LRs8:LR > 09:LR > LRs neighbors (ties broken using indexes)10:value value gives LRdifferent incomplete approach solving DCOPs implemented Max-Sumalgorithm (Farinelli, Rogers, Petcu, & Jennings, 2008). Max-Sum algorithm operatesfactor graph bipartite graph nodes represent variablesconstraints.2 node representing variable original DCOP connectedfunction-nodes represent constraints involved in. Similarly, function-nodeconnected variable-nodes represent variables original DCOPincluded constraint represents. Agents Max-Sum perform roles differentnodes factor graph. assume agent takes role variablenodes represent variables function-node, one agents whosvariable involved constraint represents, performs role. Variable-nodesfunction-nodes considered agents Max-Sum, i.e., send messages, readmessages, perform computation.content messages sent function-nodes different content messagessent variable-nodes. message sent variable-node function-node includespossible value assignments, sum costs/utilities value receivedfunction neighbors. message sent function-node variable-nodeincludes possible value assignment variable best (minimal minimization problem, maximal maximization problem) cost/utility achievedcombination assignments variables involved function includingcosts/utilities reported destination variable. end run variableselects value assignment received best sum costs/utilities includedmessages received recently neighboring function-nodes.4.2 Local Search Asymmetric ConstraintsLet us start discussion local search algorithms ADCOPs demonstratingshortcomings existing local search methods.Consider problem described Figure 1. Assuming agent awareleft (agent A1 ) right (A2 ) value matrix, standard DCOP local search algorithmsDSA MGM applied problem. DSA, example, agents2. preserve terminology Farinelli et al. (2008) call constraint representing nodes factorgraph function-nodes.628fiAsymmetric Distributed Constraint Optimization Problemsconsider personal gain, improvement, result change values accordinglocal state. similar situation exists respect MGM. However, maximumchange reported agents running MGM necessarily imply improvementneighbors well.asymmetric structure constraints alters algorithms behavior. example,DSA MGM converge local optima standard DCOPs, trueADCOPs. local search, agents continuously attempt change value assignmentimproving value assignment exists. value assignment foundagents state system whole said stable. state necessarilylocal optimum asymmetric payoffs considered. change assignmentagent may increase local cost, due asymmetry change also resultoverall lower cost system whole! hand, stable solutionscomply definition Nash Equilibria (NE) unilateral change singleagent improve state. similar reasons, MGM ADCOPs looses importantmonotonicity property (Maheswaran et al., 2004a). Agents sending maximal possibleimprovement current state neighbors actually consider changewould cause deterioration state neighbors global state.Nash Equilibria necessarily coincide optimum global objectivefunction. well known example prisoners dilemma, maximizing gainparticipants, globally worst solution NE. important noteNEs exist every asymmetric problem even presence NE,possible neither DSA MGM converge it. Thus, convergence predictionDCOPs made Chapman et al. (2008) apply case ADCOPs.One may attempt run existing local search algorithms derived PEAV-DCOPasymmetric cost problem (e.g., Figure 2). However, PEAV formulation significantlyreduces usefulness standard local search algorithms.PEAV includes hard equality constraints pair variables variableoriginal DCOP duplication. Consider global assignment problemviolate constraints. attempt agent replace valueassignment one variables result violation hard constraint. Thus,representation assignment original DCOP PEAV representation formslocal optimum.Another way describe phenomenon pointing PEAV formulationgenerates new local optima, thus, implicitly, new NEs. new local optimaeasily observed main diagonal cost matrix Figure 2. consideringanalyzing personal costs agent interaction one seescorrespond NEs. implies PEAV formulation given problem producesnew stable points (local optima)! case example Figure 2, four new NEsgenerated originally none.PEAV formulation solve problems standard local searchalgorithms. case DSA, agent considers current assignmentsneighbors. case MGM, every change variable would generate inequalitywould considered maximal reduction.629fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsAlgorithm 6 ACLS1: value ChooseRandomValue()2: termination condition met3:send value neighbors4:collect neighbors values5:IMP SET LocalReductions()6:P V RandomSelectProposedValue(IMP SET )7:send P V neighbors8:collect neighbors P V9:foreach neighbor10:send constraint cost P V11:collect constraint costs12:cost SumOfAllConstraintsCosts() C13:cost < currentState14:assign probability p: value P V4.3 ADCOP Local Search Algorithmsaforementioned shortcomings standard local search algorithms ADCOPmodel PEAV formulation call development new local search algorithmsspecifically designed ADCOPs. algorithms attempt incorporate information agents local neighborhood utilize locate high quality solutionspresented next.4.3.1 Asymmetric Coordinated Local Search (ACLS)ACLS algorithm presented Algorithm 6, attempts combine informationagents surrounding order produce global evaluation.proceeds synchronous steps continues running (after random initial assignment) termination condition met. step, agent running ACLS beginssending current assignment neighbors collecting assignments(lines 3-4). collects assignments improve local state (line 5). Basedimproving set proposed assignment P V randomly picked according distribution gains proposal (line 6). proposal sent neighborsneighbors proposals collected (lines 7,8). agent receiving proposal respondsvalue side constraint resulting current assignmentproposed assignment (lines 9-10). impact messages arrive, agent assessespotential gain loss assignment (lines 11-12). ACLS agents use specialcoordination value, C, representing amount cooperation neighborhood.is, constant zero, impact messages ignored ACLS producesresults similar DSA (albeit high overhead network load privacydegradation). agent running ACLS concludes round committing changeprobability p (lines 13-14). use probability parameter p similaruse p DSA (Zhang et al., 2005). prevents many concurrent changesneighborhood may cause thrashing.630fiAsymmetric Distributed Constraint Optimization ProblemsAlgorithm 7 MCS-MGM1: value ChooseRandomValue()2: termination condition met3:send value neighbors4:collect neighbors values5:foreach neighbor6:increase due new value7:> last known LR8:send constraint cost new value9:change constraint cost new value 010:collect neighbors constraint updates11:update constraint neighbors12:LR BestPossibleLocalReduction()13:send LR neighbors14:collect neighbors LRs15:LR > 016:LR > LRs neighbors (ties broken using indexes)17:value value gives LR4.3.2 Minimal Constraint Sharing MGM (MCS-MGM)Similarly ACLS, MCS-MGM algorithm presented Algorithm 7 also attemptsemploy knowledge local neighborhood achieve better gain surroundings.MCS-MGM algorithm also proceeds synchronous steps terminates accordingpredefined condition. step consists three different interaction phases.agent begins exchanging assignments neighbors (lines 3-4). evaluatesimpact neighbors assignment change local state. neighborsassignment change degrades current state neighbors last known bestlocal reduction, constraint passed neighbor. is, agent sendsneighbor side constraint neighbors new value, assigns costzero instead (lines 5-9). updated constraints gathered local sub-problemslightly modified (lines 10-11). Using new information, agent seeks best localreduction sends information peers (lines 12-13). MGM, agentsdeclaring highest local reductions change values (lines 14-17).4.3.3 Guaranteed Convergence Asymmetric MGM (GCA-MGM)small adjustment MCS-MGM guarantee convergence local optima (noteconverges local optima NE). Line 7 replaced by:7:> 0call resulting algorithm Guaranteed Convergence Asymmetric MGM (GCAMGM). guaranteed convergence comes price. GCA-MGM expected preserveless privacy MCS-MGM since weaker condition exchanging constraintsamong agents (see Section 5).631fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsProposition 5 GCA-MGM guaranteed converge local optimum finite numbersteps.Proof: Assume GCA-MGM converge. Consequently, agents repeatedlychanging value assignments. change causes increase agent triggers constraint exchange therefore next time assignment change performed,cause increase (i.e., cannot occur once). Thus, number increases cost bounded number constraints, finite. possibleincrements caused exchange constraints, convergence guaranteedstandard MGM (Maheswaran et al., 2004b; Pearce & Tambe, 2007).experiments (Section 5) demonstrate although MCS-MGM guaranteeconvergence, versions converge rapidly. rapid convergence strongimpact privacy loss search process (Section 5.2).5. Experimental Evaluationexperimental evaluation divided two parts. first part, performancecomplete ADCOP algorithms presented Section 3 comparedperformance standard state-of-the-art complete DCOP algorithms solving asymmetric problems represented PEAV formulation. Two standard measuresperformance complete algorithms used runtime network load.second part experimental evaluation, proposed ADCOP local searchalgorithms compared state-of-the-art local search algorithms solving DCOPs.focus evaluation incomplete algorithms quality solutionproduce given limited run time. demonstrated experimental evaluation, proposed ADCOP local search algorithms converge high quality solution,contrast standard incomplete methods converge.privacy loss incurred running ADCOP algorithms (both completelocal search) also great interest. Following Greenstadt et al. (2006) Brito et al.(2009), privacy loss measured terms entropy.Several domains evaluation used. first domain, random asymmetric MaxDisCSP, used evaluate complete local search algorithms. Max-DisCSPsubclass DCOP constraint costs equal one (Modi et al., 2005). MaxCSPs commonly used experimental evaluations constraint optimization problems(COPs) (Larrosa & Schiex, 2004) Distributed COPs (Gershman et al., 2009). MaxDisCSPs classified number agents n (assuming holds exactly one variable),size domains k, probability constraint among pair variables p1 ,probability occurrence violation (a non-zero cost) among two valueassignments p2 . formulation consider constraint tightness p2 averagefraction forbidden value pairs, viewed agent involved given constraint.implies pairs allowed one involved agents disallowedother, vice versa. result, fraction cost-inflicting pairs greater p2value. refer fraction p2ef f . expected value is:p2ef f = 1 (1 p2 )2632(3)fiAsymmetric Distributed Constraint Optimization Problemssecond evaluation domain random graphical games (Kearns et al., 2001;Nisan, Roughgarden, Tardos, & Vazirani, 2007; Maheswaran et al., 2004a). problems, constraint two agents represents local randomly generated game.local interactions, constrained agent assigned cost joint action (valueassignment pair) two constrained agents. goal agents reach globallyminimal cost assignment. evaluation ADCOP local search algorithms, general-formgraphical games, well scale-free networks, used. details domainsgiven Section 5.2.order evaluate runtime performance algorithms, measure NonConcurrent Logical Operations (NCLOs) (cf., Netzer, Grubshtein, & Meisels, 2012).measure, based notion atomic operations (Gershman, Zivan, Grinshpoun, Grubshtein, & Meisels, 2008), generalization NCCCs (Zivan & Meisels, 2006).NCLOs enable comparison runtime performance algorithms basicoperation necessarily Constraint Check, ODPOP (Petcu & Faltings, 2006).5.1 Evaluation ADCOP Complete Search Algorithmsevaluation ADCOP complete search algorithms consists three experimentsettings two settings random asymmetric Max-DisCSPs, followed graphical gamessetting. 50 random instances generated set experiments resultsaveraged 50 instances.first set experiments, random asymmetric Max-DisCSPs 10 agents (n =10), 10 values (k = 10), constraint density p1 = 0.4, varying constraint tightness0.1 p2 0.9 generated. Figures 7 8 present runtime network loadresults running proposed ADCOP algorithms. Figure 7 presents resultsmean number NCLOs. algorithms, measure Constraint Checks, i.e.,NCCCs. results show SyncABB outperforms ATWB problems.suggests asynchronicity actually impairs performance ADCOPs, contrastsymmetric case DCOPs. Verifying bound sending CPA backwardssequentially resuming search efficient continuing searchbounds checked asynchronously. problems become tighter, effectivenesstwo-way bounding increases. tight problems (p2 = 0.9) performance ATWBclose SyncABB.results total number sent messages presented Figure 8. expectednetwork load ATWB higher SyncABB due overhead addedBOUND CPA ESTIMATE messages.second set experiments, asymmetric Max-DisCSPs 6 agents (n = 6), 6values (k = 6), constraint density p1 = 0.5, varying constraint tightness 0.1 p2 0.9randomly generated. value p1 (0.5) chosen ensuregenerated constraint graphs connected, important faithful evaluationalgorithms employ pseudo-tree (BnB-ADOPT ODPOP). Applying PEAVformulation, equivalent set symmetric problems also generated, enablingcomparison performance existing DCOP algorithms. symmetric formulationmuch larger terms variables number constraints correspondingADCOPs forcing use relatively small problems.633fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels10,000,000,000SyncABB1,000,000,000ATWBNCLOs100,000,00010,000,0001,000,000100,00010,0001,0001000.10.20.30.40.50.60.70.80.9Problem tightness (P2)Figure 7: Mean NCLOs complete algorithms asymmetric Max-DisCSPs (10 agents).10,000,000,000SyncABBSent messages1,000,000,000ATWB100,000,00010,000,0001,000,000100,00010,0001,0001000.10.20.30.40.50.60.70.80.9Problem tightness (P2)Figure 8: Sent messages complete algorithms asymmetric Max-DisCSPs (10 agents).setup, runtime network load six algorithms compared.included proposed ADCOP algorithms SyncABB ATWB, well several state-ofthe-art DCOP algorithms (solving symmetric problems) SyncBB (Hirayama & Yokoo,1997), AFB (Gershman et al., 2009), BnB-ADOPT (Yeoh et al., 2010), ODPOP (Petcu& Faltings, 2006).Figures 9 10 present results second setup. Unlike algorithms,main computational operation ODPOP comparison combinations assignments sent computing agent offspring pseudo tree (Petcu & Faltings,2006). Figure 9 presents runtime terms NCLOs six algorithms. ADCOP algorithms show lower runtime several orders magnitude compared SyncBB,AFB, ODPOP. ODPOP ran heap memory (heap set 2GB) relatively tightproblems (p2 0.5). surprising, since memory ODPOP requiresexponential induced width constraint graph (Petcu & Faltings, 2006).PEAV formulation results sparse problems. PEAV representationasymmetric problem 10 variables p1 = 0.4 includes 46 variables densityp1 = 0.07. Consequently, BnB-ADOPT, efficient solving sparse problems, well displays runtime performance comparable ADCOP algorithms.634fiAsymmetric Distributed Constraint Optimization Problems1,000,000,000SyncABB100,000,000ATWBNCLOs10,000,000SyncBB(PEAV)AFB(PEAV)BnB-ADOPT(PEAV)ODPOP(PEAV)1,000,000100,00010,0001,000100100.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9Problem tightness (P2)Figure 9: Mean NCLOs complete algorithms asymmetric Max-DisCSPs (6 agents).1,000,000,000SyncABBSent messages100,000,000ATWB10,000,000SyncBB(PEAV)AFB(PEAV)BnB-ADOPT(PEAV)ODPOP(PEAV)1,000,000100,00010,0001,000100100.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9Problem tightness (P2)Figure 10: Sent messages complete algorithms asymmetric Max-DisCSPs (6 agents).However, demonstrated Figure 10, incurs high network load. fact, nonealgorithms solving symmetric DCOPs (PEAV) managed complete first setexperiments (with 10 agents) due high runtime and/or network load.third set experiments, graphical games 6 agents (n = 6), 6 values (k = 6),varying node degree randomly generated. average node degrees used spanned2.5 5 (which indicates complete graph). constraint matrix included 50%zeroes, rest assignment pair values random values range [0..9].setting particulary interesting shows varying density (node degree) effectsperformamce algorithms.Figures 11 12 present results third setup linear scale. resultsindicate increased density (node degree) minor effect performance ADCOPalgorithms. hand, density problems increases, performanceBnB-ADOPT drastically impaired. suspected, number sent messagesespecially high BnB-ADOPT. DCOP algorithms (using PEAV formulation)able complete graphical games set experiments.average privacy loss incurred running complete ADCOP algorithmsfirst problem setup presented Figure 13. Following Brito et al. (2009),635fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsNCLOs500000SyncABB400000ATWB300000BnB-ADOPT(PEAV)20000010000002.533.544.55Node degreeFigure 11: Mean NCLOs complete algorithms graphical games.Sent messages1000000SyncABB800000ATWB600000BnB-ADOPT(PEAV)40000020000002.533.544.55Node degreeFigure 12: Sent messages complete algorithms graphical games.100%Privacy lossSyncABBATWB80%60%40%20%0%0.10.20.30.40.50.60.70.80.9Problem tightness (P2)Figure 13: Privacy loss complete algorithms asymmetric Max-DisCSPs (10 agents).privacy results calculated comparing percentage lost entropy endcomputation initial entropy. results clearly indicate ATWB higher636fiAsymmetric Distributed Constraint Optimization Problems10,000,000,000SyncABB1,000,000,000ATWBNCLOs100,000,000SyncBB10,000,000AFB1,000,000100,00010,0001,0001000.10.20.30.40.50.60.70.80.9Problem tightness (P2)Figure 14: Mean NCLOs complete algorithms asymmetric Max-DisCSPs (10 agents).10,000,000,000SyncABBSent messages1,000,000,000ATWB100,000,000SyncBB10,000,000AFB1,000,000100,00010,0001,0001000.10.20.30.40.50.60.70.80.9Problem tightness (P2)Figure 15: Sent messages complete algorithms asymmetric Max-DisCSPs (10 agents).degree average privacy preservation compared SyncABB. surprisingone considers ATWB information revealed single direction,SyncABB decreases entropy agents lower higher priority.additional method solving problems asymmetric constraints aggregatesides constraints simply run symmetric DCOP algorithm (Section 2.3.1).clear downside alternative private constraint information discloseda-priory. interesting investigate attempt keep constraint informationprivate (by using ADCOPs) affects performance. following figures present experimentsperformance ADCOP algorithms, SyncABB ATWB, comparedperformance symmetric variants using constraints disclosure. Figures 1415 four algorithms compared running first problem setup.comparison SyncABB symmetric SyncBB one observe SyncABB performs 30%-40% NCLOs SyncBB, network load SyncABBbellow one order magnitude higher SyncBB. results indicateimpact performance using ADCOPs preserving portions privateinformation reasonable. Different outcomes follow comparison ATWBsymmetric AFB, number NCLOs ATWB almost two orders magnitude637fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels120,000SyncABBNCLOs100,000ATWB80,000SyncBB60,000AFB40,00020,00002.533.544.55Node degreeFigure 16: Mean NCLOs complete algorithms graphical games.50,000Sent messagesSyncABB40,000ATWBSyncBB30,000AFB20,00010,00002.533.544.55Node degreeFigure 17: Sent messages complete algorithms graphical games.larger AFB tight problems. gap even greater consideringnetwork load.graphical games setup, simple branch bound effective (duevariance costs), performance impairment proposed ADCOP algorithmseven refined. Figure 16 shows symmetric SyncBB outperforms SyncABBterms runtime 25% higher density problems. gap ATWBsymmetric AFB also relatively low, ATWB 5 times faster AFB. Moreover,variance costs renders SyncABB performs less NCLOs symmetric AFBhigher density problems. gaps network load slightly larger, shownFigure 17.ADCOP algorithms prevent a-priori loss private information, resultsgiven Figure 13 reveal relatively hard problems, major part privateinformation revealed all. additional experiment, extent privacy losslimited stopping search process whenever amount private informationagent gained passed predefined threshold. Figures 18 19 presentoutcomes limitation terms solution quality (distance cost optimalsolution) problems first setup p2 = 0.3 p2 = 0.5, respectively.638fiAsymmetric Distributed Constraint Optimization Problems6SyncABBSolution cost5ATWB4321010% 20% 30% 40% 50% 60% 70% 80% 90% 100%Maximal gain private dataSolution costFigure 18: Solution quality limiting maximal gain private information complete algorithms asymmetric Max-DisCSPs (10 agents, p1 = 0.4, p2 = 0.3).109876543210SyncABBATWB10% 20% 30% 40% 50% 60% 70% 80% 90% 100%Maximal gain private dataFigure 19: Solution quality limiting maximal gain private information complete algorithms asymmetric Max-DisCSPs (10 agents, p1 = 0.4, p2 = 0.5).specific p2 values chosen, since p2 = 0.3 represents rather tight still satisfiableproblems, p2 = 0.5 represents harder problems mostly unsatisfiable.p2 = 0.3 solution cost drastically reduces threshold raised maximalprivate information gain 60% algorithms reach optimal solution. averageprivacy loss case considerably lower around 10% algorithms (seeFigure 13). p2 = 0.5 agent usually gains private information orderreach optimal solution, seen Figure 13, average privacy lossagents much lower.interesting threshold values maximal gain private informationATWB higher SyncABB, shown average privacy loss639fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsATWB lower (Figure 13). reason phenomenon ATWB agentsgain private information predecessors, commonly last agents ordergain information, first agent gains none. result averageagent running ATWB looses less privacy agent running SyncABB, SyncABBprivacy loss better distributed among agents. last experiment illustratesclear tradeoff privacy loss solution quality running ADCOP algorithmsprivacy gain threshold.5.2 Evaluation ADCOP Local Search Algorithmsintroduced local search algorithms evaluated three domains asymmetric MaxDisCSPs, general-form graphical games, scale-free networks. type problem,500 different problem instances 200 agents domain size 10 values per agentgenerated. presented results average 500 solutions obtainedalgorithms instances. Asymmetric Max-DisCSPs generated average10 neighbors per agent (density parameter p1 = 0.05) tightness parameter p2 = 0.7.rest details described asymmetric Max-DisCSPs generatedevaluate complete algorithms. general-form graphical games agents average5 neighbors each, i.e., agents connected asymmetric constraint probabilityvalue p = 0.025 (Erdos-Renyi graphs) (Erdos & Renyi, 1960). scale-free networksdomain, graphs constructed following Barabasi-Albert model (Jackson, 2008).two latter setups constraint costs selected range [0..100]. Costsseparately selected non uniform manner cost agent 0 probability0.35 uniformly selected range [1..100] probability 0.65. structureensures improving assignment change one agent increase cost incurredneighbors (cf. Equation 3).scale-free networks built using Barabasi-Albert model. initial set10 agents randomly selected connected. iteration Barabasi-Albertprocedure agent added connected 4 agents probabilityproportional number links existing agents already have.large number algorithms examined. include DSA, MGM, MGM-2, MaxSum, ACLS, MCS-MGM, GCA-MGM. algorithms executed maximum200 cycles, cycle includes actions two consecutive value messagessent agent (Max-Sum cycles include messages function-nodesvariable-nodes vise versa).Figure 20 presents average solution quality asymmetric Max-DisCSPsalgorithms function cycles. MCS-MGM produced highest quality results200 cycles best algorithms MCS-MGM, MGM-2, ACLS, GCAMGM, performance two latter algorithms similar. three ADCOPalgorithms demonstrated fast convergence. highest costs (e.g., worst solutions)reported Max-Sum, explore much search space reportedincurred cost significantly higher reported algorithms. Consequently,results Max-Sum left plots enable better view overallperformance remaining algorithms (and correct scale). Surprisingly, DSA producedsolutions significantly lower quality MGM. contrast performance640fiAsymmetric Distributed Constraint Optimization ProblemsSolution cost180MCS-MGM160GCA-MGM140ACLSMGM2120MGM100DSA80050100150200CyclesFigure 20: Solution quality local search algorithms asymmetric Max-DisCSPs12000MCS-MGMSolution cost10000GCA-MGM8000ACLS6000MGM2MGM4000DSA2000050100150200CyclesFigure 21: Solution quality local search algorithms Erdos-Renyi graphssolving symmetric problems, DSA known produce higher quality solutionsMGM.Figures 21 22 present similar results average solution quality graphicalgames scale-free networks, respectively. notable MCS-MGM dominatesproblem scenarios. GCA-MGM produces better results MGM-2 graphical games,results similar quality scale-free networks. DSA Max-Sum producedlow quality results problem scenarios well.worth noting MGM-2, agent optimizing another agentcause increase valuation proposed alternative state neighboringagents both. result, agents optimizing different pairs generate loopsassignment changes described MGM. Thus, increase size groupagents considered optimizing agent sufficient ensure convergence.similar phenomenon, MGM-2 eventually fail provide higher quality solutionseven MGM, reported presence uncertainty (Taylor, Jain, Tandon, &Tambe, 2009).problem scenarios evaluated, ACLS produced results lower quality MCSMGM GCA-MGM (except similar results asymmetric Max-DisCSPs). How641fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meisels1200MCS-MGMSolution cost1000GCA-MGM800ACLS600MGM2400MGMDSA200050100150200CyclesFigure 22: Solution quality local search algorithms scale-free networksPrivacy loss100%80%MCS-MGM60%GCA-MGM40%ACLS20%MGM20%050100150200CyclesFigure 23: Privacy loss local search algorithms asymmetric Max-DisCSPsever, also observable ACLS fastest algorithm converge three problemscenarios.results indicate cooperation inherent three proposed algorithms, ACLS, MCS-MGM, GCA-MGM, renders algorithms better suiteasymmetric case algorithms. However, despite lower costs attributedcooperation, nature agents requires revelation private information. Thus, important asses privacy loss resulting coordinationagents, contrast standard local search (1-opt) algorithms preserve high levelprivacy (Greenstadt, 2008). measure overall loss privacy system agents,one needs aggregate number revealed constraint parts agent (Greenstadtet al., 2006; Greenstadt, 2008).ACLS, fraction constraint revealed line 10 (Algorithm 6), MCSMGM GCA-MGM reveal constraint information lines 8 9 (Algorithm 7). Anotheralgorithm attempts coordinate joint moves MGM-2 (Maheswaran et al., 2004a),offerer agents propose several improving assignments along costsone peers, respond lowest improving cost incurred them. Thus,MGM-2 agents reveal much larger fraction constraint every interaction.642fiAsymmetric Distributed Constraint Optimization Problems100%MCS-MGMPrivacy loss80%GCA-MGM60%ACLS40%MGM220%0%050100150200CyclesFigure 24: Privacy loss local search algorithms Erdos-Renyi graphsPrivacy loss100%80%MCS-MGM60%GCA-MGMACLS40%MGM220%0%050100150200CyclesFigure 25: Privacy loss local search algorithms scale-free networksFigures 23, 24, 25 present privacy loss measurements. Agents running MGM-2reveal problem structure, algorithms maintain substantiallyhigher degree constraint privacy. three problem scenarios apparentprivacy loss proposed ADCOP algorithms negligible compared privacy lossMGM-2. Furthermore, privacy MGM-2 decreases throughout 200 cyclesalgorithm (although privacy loss function notable concave structure), ACLS,MCS-MGM, GCA-MGM lose small amount privacy first iterations,endure additional privacy loss. results indicate quick convergencesolution may substantial impact privacy loss.6. ConclusionsMany problems distributed nature include agents different valuations possible states world. distributed constraint optimization problemsconstrained agents may different costs assigned valued constraints. presentpaper proposes Asymmetric Distributed Constraint Optimization Problems (ADCOP)model, captures inherent asymmetry distributed problems natural ef643fiGrinshpoun, Grubshtein, Zivan, Netzer, & Meiselsficient way. proposed ADCOP model represents private gains without revealing privateinformation a-priori. Instead, agents reveal information necessarydistributed search solution. contrast alternative DCOP formulationseither centralize constraints (resulting privacy loss possibly heavy network load),change problem complex structure (PEAV).algorithmic impact introducing new framework discussed, wellapplicability existing DCOP algorithms. Several novel algorithms proposedcomplete search others local search.considering complete search, proposed complete ADCOP algorithms eliminate need extend problem using PEAV model. Furthermore, behavewell whole range problem difficulty. Two complete ADCOP algorithmsshowed superior performance (runtime well network load) compared leading (symmetric) DCOP algorithms use PEAV representation. Another alternativeaggregate sides constraints simply run symmetric DCOP algorithm.However, method leads a-priori disclosure private constraint information,achieving moderately better run-time performance respective ADCOPalgorithms. results indicate synchronous algorithm (SyncABB) outperformsasynchronous algorithm (ATWB) cases. SyncABB usually performs less NCLOs, sends significantly less messages, leads better distribution privacy lossagents. contrast, average privacy loss ATWB lower.proposed ADCOP local search algorithms agents cooperate performsearch local neighborhood, instead maximizing gain. proofone algorithms, GCA-MGM, guaranteed converge local optimum,presented. PEAV representation cannot used combination existing localsearch algorithms, since assignment violate hard constraints localoptimum PEAV generates. However, existing local search algorithms usedcombination proposed ADCOP model. Nevertheless, empirical evaluationdemonstrated new ADCOP algorithms consistently find higher quality solutions,high degree privacy preservation. turns fast convergencestrongly limits amount privacy lost.ReferencesBrito, I., Meisels, A., Meseguer, P., & Zivan, R. (2009). Distributed constraint satisfactionpartially known constraints. Constraints, 14 (2), 199234.Burke, D. A., Brown, K. N., Dogru, M., & Lowe, B. (2007). Supply chain coordinationdistributed constraint optimization. Proc. CP Workshop DistributedConstraint Reasoning (DCR-07).Chapman, A. C., Rogers, A., & Jennings, N. R. (2008). parameterisation algorithmsdistributed constraint optimisation via potential games. Proc. AAMAS WorkshopDistributed Constraint Reasoning (DCR-08).Erdos, P., & Renyi, A. (1960). evolution random graphs. PublicationMathematical Institute Hungarian Academy Sciences, pp. 1761.644fiAsymmetric Distributed Constraint Optimization ProblemsFarinelli, A., Rogers, A., Petcu, A., & Jennings, N. R. (2008). Decentralised coordinationlow-power embedded devices using max-sum algorithm. Proc. AAMAS-08,pp. 639646.Gershman, A., Grubshtein, A., Meisels, A., Rokach, L., & Zivan, R. (2008). Schedulingmeetings agents. Proc. PATAT-08.Gershman, A., Meisels, A., & Zivan, R. (2009). Asynchronous forward bounding. JournalArtificial Intelligence Research (JAIR), 34, 2546.Gershman, A., Zivan, R., Grinshpoun, T., Grubshtein, A., & Meisels, A. (2008). Measuring distributed constraint optimization algorithms. Proc. AAMAS WorkshopDistributed Constraint Reasoning (DCR-08).Greenstadt, R. (2008). analysis privacy loss k-optimal algorithms. Proc. AAMASWorkshop Distributed Constraint Reasoning (DCR-08).Greenstadt, R., Pearce, J., & Tambe, M. (2006). Analysis privacy loss distributedconstraint optimization. Proc. AAAI-06, pp. 647653.Grinshpoun, T., & Meisels, A. (2008). Completeness performance APO algorithm.Journal Artificial Intelligence Research (JAIR), 33, 223258.Hirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem.Proc. CP-97, pp. 222236.Jackson, M. O. (2008). Social Economic Networks. Princeton University Press.Kearns, M. J., Littman, M. L., & Singh, S. P. (2001). Graphical models game theory.Proc. UAI-01, pp. 253260.Larrosa, J., & Schiex, T. (2004). Solving weighted CSP maintaining arc consistency.Artificial Intelligence, 159, 126.Leaute, T., & Faltings, B. (2011). Distributed constraint optimization stochasticuncertainty. Proc. AAAI-11, pp. 6873.Maheswaran, R. T., Pearce, J. P., & Tambe, M. (2004a). Distributed algorithms DCOP:graphical-game-based approach. Proc. Parallel Distributed Computing Systems (PDCS-04), pp. 432439.Maheswaran, R. T., Tambe, M., Bowring, E., Pearce, J. P., & Varakantham, P. (2004b).Taking DCOP real world: Efficient complete solutions distributed multievent scheduling. Proc. AAMAS-04, pp. 310317.Maheswaran, R. T., Pearce, J. P., & Tambe, M. (2006). family graphical-game-basedalgorithms distributed constraint optimization problems. Coordination LargeScale Multiagent Systems, pp. 127146. Springer-Verlag.Maheswaran, R. T., Pearce, J. P., Varakantham, P., Bowring, E., & Tambe, M. (2005).Valuations possible states (VPS): quantitative framework analysis privacyloss among collaborative personal assistant agents. Proc. AAMAS-05, pp. 10301037.Mailler, R., & Lesser, V. R. (2004). Solving distributed constraint optimization problemsusing cooperative mediation. Proc. AAMAS-04, pp. 438445.645fiGrinshpoun, Grubshtein, Zivan, Netzer, & MeiselsMailler, R., & Lesser, V. (2006). Asynchronous Partial Overlay: New Algorithm Solving Distributed Constraint Satisfaction Problems. Journal Artificial IntelligenceResearch (JAIR), 25, 529576.Meisels, A. (2007). Distributed Search Constrained Agents: Algorithms, Performance,Communication. Springer Verlag.Modi, J., & Veloso, M. (2004). Multiagent meeting scheduling rescheduling. Proc.CP Workshop Distributed Constraint Reasoning (DCR-04).Modi, P. J., Shen, W., Tambe, M., & Yokoo, M. (2005). ADOPT: asynchronous distributedconstraints optimizationwith quality guarantees. Artificial Intelligence, 161, 149180.Monderer, D., & Shapley, L. S. (1996). Potential games. Games Economic Behavior,14, 124143.Netzer, A., Grubshtein, A., & Meisels, A. (2012). Concurrent forward bounding distributed constraint optimization problems. Artificial Intelligence, 193, 186216.Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. V. (2007). Algorithmic GameTheory. Cambridge University Press.Pearce, J. P., & Tambe, M. (2007). Quality guarantees k-optimal solutions distributedconstraint optimization problems. Proc. IJCAI-07, pp. 14461451.Petcu, A., & Faltings, B. (2006). ODPOP: algorithm open/distributed constraintoptimization. Proc. AAAI-06, pp. 703708.Petcu, A. (2007). class algorithms distributed constraint optimization. Ph.D. thesis,Ecole Polytechnique Fdrale de Lausanne (EPFL), Switzerland.Ramchurn, S. D., Vytelingum, P., Rogers, A., & Jennings, N. (2011). Agent-based controldecentralized demand side management smart grid. Proc. AAMAS-11,pp. 512.Rogers, A., Farinelli, A., Stranders, R., & Jennings, N. R. (2011). Bounded approximatedecentralised coordination via max-sum algorithm. Artificial Intelligence, 175 (2),730759.Taylor, M. E., Jain, M., Tandon, P., & Tambe, M. (2009). Using DCOPs balance exploration exploitation time-critical domains. Proc. IJCAI WorkshopDistributed Constraint Reasoning (DCR-09).Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: asynchronous branch-andbound DCOP algorithm. Journal Artificial Intelligence Research (JAIR), 38, 85133.Yokoo, M. (2000). Algorithms distributed constraint satisfaction problems: review.Autonomous Agents Multi-Agent Systems, 3 (2), 185207.Yokoo, M., K.Suzuki, & Hirayama, K. (2002). Secure distributed constraints satisfaction:Reaching agreement without revealing private information. Proc. CP-02, pp. 387401.Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2005). Distributed stochastic searchdistributed breakout: properties, comparishon applications constraintsoptimization problems sensor networks. Artificial Intelligence, 161 (1-2), 5588.646fiAsymmetric Distributed Constraint Optimization ProblemsZivan, R. (2008). Anytime local search distributed constraint optimization. Proc.AAAI-08, pp. 14491452.Zivan, R., & Meisels, A. (2006). Message delay DisCSP search algorithms. AnnalsMathematics Artificial Intelligence, 46 (4), 415439.Zivan, R., Glinton, R., & Sycara, K. P. (2009). Distributed constraint optimization largeteams mobile sensing agents. Proc. IAT-09, pp. 347354.647fiJournal Artificial Intelligence Research 47 (2013) 809-851Submitted 04/13; published 08/13Decidable Extension SROIQ Complex RoleChains UnionsMilenko Mosurovicmilenko@ac.meFaculty Natural Sciences Mathematics,University Montenegro, Montenegro.Nenad Krdzavacnenadkr@tesla.rcub.bg.ac.rsFaculty Organizational Sciences,University Belgrade, Serbia.Henson Graveshenson.graves@hotmail.comAlgos Associates, 2829 West Cantey Street,Fort Worth, TX 76109 U.S.Michael Zakharyaschevmichael@dcs.bbk.ac.ukDepartment Computer Science Information Systems,Birkbeck, University London, U.K.Abstractdesign decidable extension description logic SROIQ underlying WebOntology Language OWL 2. new logic, called SR+ OIQ, supports controlled userole axioms whose right-hand side may contain role chains role unions. givetableau algorithm checking concept satisfiability respect SR+ OIQ ontologiesprove soundness, completeness termination.1. Introductionever growing number scope application areas puts constant pressuredesigners ontology languages. Thus, first version Web Ontology LanguageOWL, became formal W3C recommendation 2004, contained description logic(DL, short) SHOIN allowed use basic DL ALC together inversetransitive roles, role hierarchies, nominals unqualified cardinality restrictions.second reincarnation OWL 2, adopted 2009, based powerful formalism,SROIQ, extends SHOIN features complex role chains, asymmetric,reflexive disjoint roles, qualified cardinality restrictions (Horrocks & Sattler, 2004;Horrocks, Kutz, & Sattler, 2006; Cuenca Grau, Horrocks, Motik, Parsia, Patel-Schneider,& Sattler, 2008).addition role inclusions involve role chains motivated multiple usecases life sciences domain require means describe interactionslocative properties various kinds part-whole properties (Cuenca Grau et al., 2008).example, role inclusion axiomhasLocation isPartOf v hasLocationstates object x located y, part z, x also locatedz (Rector, 2002). However, resolved issue role chains left-hand sidec2013AI Access Foundation. rights reserved.fiMosurovic, Krdzavac, Henson & Zakharyaschevrole inclusion axioms, example above, SROIQ OWL 2 fall short providingmeans represent chains and/or unions roles right-hand side, oftenrequired modelling structured objects, particular, emerging area ontologicalproduct modelling collaborative design (Bock, Zha, Suh, & Lee, 2010).Consider, example, product model cars Bock (2004) KrdzavacBock (2008), part shown UML-like diagram below:CarBWheelEnginepowerspowershasEnginehasWheelhasWheelWheelEngineOilpumphasEngineCCarhasHubHubhasOilpumpCrankshaftpowersGearpowerspowershasCrankshafthasGeneratorGeneratorHubpowersCrankshaftpowersFigure 1: product model car (Krdzavac & Bock, 2008).fragment Fig. 1 (A) involves two statements:hasEngine hasCrankshaft powers v hasWheel hasHub(1)says whatever powered crankshaft engine car hub wheelcar and, conversely,hasWheel hasHub v hasEngine hasCrankshaft powers(2)states hub wheel car powered crankshaft engine car.fragment Fig. 1 (B) means engine car power wheels, generatoroil pump, represented axiomhasEngine powers v hasWheel hasGenerator hasOilPump.(3)Finally, Fig. 1 (C) supposed mean role powers transitive:powers powers v powers.(4)Role inclusion axioms form (1), (2), (4) feature original KL-ONEterminological language (Brachman & Schmolze, 1985), called role-valuemaps could applied certain individuals. Role inclusions disjunctionsright-hand side also arise context spatial reasoning description logics (Wessel,2001, 2002), used represent compositions RCC8-relationsPO TPP PO TPP NTPP (in English: region x partially overlaps region810fiA Decidable Extension SROIQ Complex Role Chains Unionstangential proper part region z, either x partially overlaps z, xtangential proper part z, x non-tangential proper part z).Role inclusions complex right-hand side allowed syntax SROIQOWL 2, makes adequate representation models Fig. 1 problematic.Indeed, languages, cannot exclude situations when, example, car1 relatedhub1 via hasEngine hasCrankshaft powers and, time, hub1 part car2.Axiom (1) asserts existence individual wheel car1 hub1.main issue axioms (1) similar rewrite rulessemi-Thue systems, word problem known undecidable. Onesimplest examples given Tseitin (1956) showed associative calculus(Thue system) axiomsac = ca, ad = da, bc = cb, bd = db, edb = be, eca = ae, abac = abaccundecidable. Schmidt-Schau (1989) used undecidability word problem showlogic underlying KL-ONE undecidable. Baader (2003) proved (by reductionsemi-Thue systems) tractable description logic EL becomes undecidableextended role inclusions containing role chains right-hand side.hand, observed role inclusions single role right-hand sideincrease complexity EL. Horrocks Sattler (2004) proved extensionSHIQ axioms form R v R R v R undecidable; however,decidability regained requiring axioms involve cycles. Axiomsform (3) also lead undecidable logics: Wessel (2001, 2002) showed (by reductionPCP) extension ALC role axioms form v R1 Rnundecidable.Similar problems investigated modal logic community. modal logic,axioms formi1 . . . p j1 . . . jm p,(5)known modal reduction principles, always attracted attention still presentgreat challenge (for example, open whether extension basic modal logic Keither axioms p p p p decidable). Axioms form (5)give rise grammars generated production rules i1 . . .in j1 . . .jm , modallogics axiomatised axioms called grammar logics (del Cerro & Penttonen, 1988).shown Demri (2001) Baldoni (1998) grammar regular,corresponding modal logic decidable ExpTime; hand, linear (contextfree) grammar logics undecidable. follows, particular, satsifiabilityproblem ALC knowledge bases extended role inclusions R1 . . . Rn v S1 . . . Sk alsoExpTime-complete provided grammar generated rules S1 . . . Sk R1 . . . Rnregular (Demri, 2001, Section 5.3).paper, design decidable extension SR+ OIQ description logic SROIQsupports controlled use role inclusion axioms complex right-hand sideexamples above. Thus, use role inclusion axioms chain unionroles right-hand side, also express equality two role chains unions(1) (2). ensure decidability, impose certain regularity conditionsrole axioms given ontology generalise syntactic restrictions Horrocks et al.811fiMosurovic, Krdzavac, Henson & Zakharyaschev(2006) Kazakov (2010). conditions checked polynomial time employed,pre-processing step, build finite automata roles ontology. Intuitively,automaton role R recognises role chains subsumed R accordingontology passes concept C end chain whenever beginning belongsR.C.decision algorithm builds tableau technique developed Horrocks et al.(2006) uses ideas Halpern Moses (1992, pp. 34-35) order pass setsconcepts along role chains required role inclusions complex right-hand side(1)(3). axioms, tableau algorithm behaves preciselytableau algorithm SROIQ; otherwise may suffer multiple exponential blowups(depending number role inclusions complex right-hand side).alternative approach modelling complex structures description logicssuggested Motik, Cuenca Grau, Horrocks, Sattler (2009). decidable formalismbased description graphs encode axioms form (1),presence transitivity (4) (in case language generated role chainleft-hand side (1) infinite cannot represented finite graph). ensuredecidability, Motik et al. (2009) impose acyclicity conditions description graphsallow role appear description graph DL ontology.example, cannot straightforwardly combine description graph encoding modelFig. 1 vehicle tax ontology containing axiomsCar u hasEngine.LargeEngine v vehicleTax.HigherTax.(6)SR+ OIQ, addition (6) (1)(4) cause problem.structure paper follows. define syntax semanticsdescription logic SR+ OIQ next two sections. particular, Section 3 definesgives intuition behind regularity conditions imposed SR+ OIQ role axioms.aim Section 4 illustrate number examples new challengestableau construction facing dealing SR+ OIQ compared caseSROIQ. use examples motivate explain new ideas, notions techniques required tableau-based decision algorithm SR+ OIQ. TableauxSR+ OIQ defined formally Appendix A. Appendix B, give tableau algorithm SR+ OIQ prove sound, complete always terminates.discuss obtained results open problems Section 5.2. Description Logic SR+ OIQbegin formally defining syntax semantics description logic SR+ OIQ.alphabet SR+ OIQ consists three countably infinite disjoint sets NC , NRNI concept names, role names individual names, respectively. also distinguishproper subset NN $ NC , whose members called nominals. alphabetinterpreted structures, interpretations, form = (I , ), 6=domain interpretation, interpretation function assigns every NCsubset AI , AI singleton set NN ; every R NR binaryrelation RI ; every NI element aI . Following OWL 2812fiA Decidable Extension SROIQ Complex Role Chains Unionsstandards, adopt unique name assumption allow aI = bI distincta, b NI .introduce role concept constructs available SR+ OIQ.role name R NR , inverse R R interpreted relation(R )I = {(y, x) | (x, y) RI }.call role names inverses basic roles, set NR = NR {R | R NR } writern(R) = rn(R ) = R, R NR . define SR+ OIQ-role chain R1 . . . Rnunion R1 Rn basic roles Ri , interpret new constructs taking(R1 . . . Rn )I = R1I RnI ,(R1 Rn )I = R1I RnI ,denotes composition binary relations. Define function inv () role chainstaking inv (R1 . . . Rn ) = inv (Rn ) . . . inv (R1 ), inv (R) = R inv (R ) = R,R NR .set NR role names, distinguish proper subset NS call membersinverses simple roles; basic roles simple called nonsimple. Simple non-simple roles satisfy different constraints conceptsrole inclusion axioms defined below.SR+ OIQ-concepts, C, defined following grammar, NC , Rbasic role, simple role, n positive integer (given binary):C::=|R.C||>R.C||C|nS.CC1 u C2|nS.C|C1 C2||S.Self .interpretation concepts defined follows, ]X cardinality X:>I = ,= ,(C)I = \ C ,(C1 u C2 )I = C1I C2I ,(C1 C2 )I = C1I C2I ,(R.C)I = {x | C (x, y) RI },(R.C)I = {x | ((x, y) RI C )},(S.Self )I = {x | (x, x) },( n S.C)I = {x | ]{y | (x, y) C } n},( n S.C)I = {x | ]{y | (x, y) C } n}.SR+ OIQ-knowledge base (KB, short) consists TBox, RBox ABox.TBox, , finite set concept inclusions (CIs), expressions formC1 v C2 . CI satisfied C1I C2I , case write |= C1 v C2 .ABox, A, finite set assertions form: C,(a, b) : R,(a, b) : S,8136= b,fiMosurovic, Krdzavac, Henson & Zakharyaschevb individual names, R basic role, simple role, C concept.satisfaction relation ABox assertions given|= : CiffaI C ,|= (a, b) : Riff(aI , bI ) RI ,|= (a, b) :iff(aI , bI )/ SI ,|= 6= b iffaI 6= bI .RBox, R, finite set disjointness constraints role axioms. disjointnessconstraint Dis(S1 , S2 ) imposed simple roles S1 , S2 ; satisfied S1I S2I = .role axiom (RA) following six types, S, 0 simple roles; Q0 , Q,Q1 , . . . , Qm non-simple roles; R, R1 , . . . , Rm arbitrary basic roles:(A) v 0 , QQ v Q, Q v Q,(B) R1 . . . Rm v Q, QR1 . . . Rm v Q, R1 . . . Rm Q v Q, 1,(C) R v QR1 . . . Rm , 1,(D) R v Q1 Qm , > 1,(E) Q0 = QR1 . . . Rm , 1,(F) Q = Q1 Qm , > 1.RAs form (A)(D) called role inclusions (RIs), form (E)(F) role equalities (REs). RBox R may contain set role axioms satisfyingregularity conditions defined discussed next section.Note that, although RAs SR+ OIQ restricted form (A)(F),encode general role inclusions form (provided meet regularityconditions defined below)(R11 . . . Rn1 1 ) (R1m . . . Rnmm ) v (R1m+1 . . . Rnm+1) (R1k . . . Rnk k ).m+1(7)(In particular, one easily write RBox capturing RAs (1)(4) introduction.) detailed discussion actually represented SR+ OIQ RBoxesalso given next section.%i chain union roles, = 1, 2, %1 v %2 (or %1 = %2 ) satisfied%1 %I2 (respectively, %I1 = %I2 ). say KB K = (T , R, A) satisfiableexists interpretation satisfying members , R A. case write|= K call model K.main reasoning problem paper concept satisfiability respect KBs:given SR+ OIQ concept C KB K, decide whether model KC 6= . standard reasoning problems subsumption, KB satisfiabilityinstance checking known reducible concept satisfiability respectKBs. Moreover, concept satisfiability respect arbitrary KBs reducedconcept satisfiability respect KBs form (, R, ) (with empty TBoxesABoxes); (see Horrocks et al., 2006, Thm. 9).814fiA Decidable Extension SROIQ Complex Role Chains Unionsconcept C, denote nom(C) set nominals occur C,role(C) set basic roles R either R inv (R) occurs C; role(C, K)role(C, R) contain basic roles inverses occur C K/R.3. Regular RBoxesmentioned introduction, unrestricted RAs easily simulate kinds undecidable problems. section, define regular RBoxes allowed SR+ OIQ.SROIQ RAsthat is, RAs form (A) (B)our restrictionsused Kazakov (2010). suggested term regular, going useregularity restrictions construct finite automata roles R recognise role chainssubsumed R RBox question.Suppose R set RAs. define regularity conditions (to given Definition 3), require following binary relation 0 set role names occurR:rn(Ri ) 0 rn(Q), = 1, . . . , m, RIs type (B),rn(R) 0 rn(Q), RIs type (C),rn(R) 0 rn(Qi ), = 1, . . . , m, RIs type (D),rn(Ri ) 0 rn(Q0 ), = 1, . . . , m, REs type (E).Denote R transitive reflexive closure 0 . write R1 'R R2R1 R R2 R2 R R1 , R1 R R2 R1 R R2 R2 R R1 . depth dR (R)R R understand largest n exists chain R1 R R2 R RRn R R.represent R union R = RA RB RC RD RF , RX containsRAs R form (X), X {A, B, C, D, E, F }. also write RA,BRA RB , etc.RI r = (% v R) RA,B role chains %0 %00 , write %0 vr %00 either0% = %01 %%02 %00 = %01 R%02 , %0 = %01 inv (%)%02 %00 = %01 inv (R)%02 , %01 %02 .write %0 vR %00 %0 vr %00 , r RA,B , denote vR reflexivetransitive closure vR . follows immediately definitions R vRhave:Lemma 1 % = %0 R0 %00 % vR R, rn(R0 ) R rn(R).Following Kazakov (2010), say RI (% v R0 ) RA,B stratified R if,every R 'R R0 % = %1 R%2 , exists R1 %1 R vR R1 R1 %2 vR R0 .call RA,B stratified every RI % v R % vR R stratified R.every role R R, define following language LR (R) role chains regardedwords basic roles:LR (R) = {% | % vR R}.Theorem 2 (Kazakov, 2010) Suppose R RBox stratified RA,B .language LR (R) regular, every role R R. Moreover, one construct nondeterministic finite automaton recognising LR (R) number transitionsexceed O(|R|2dR (R) ).815fiMosurovic, Krdzavac, Henson & Zakharyaschevposition define regular RBoxes.Definition 3 RBox R called regular following conditions satisfied:(c1) RA,B stratified;(c2) rn(R) R rn(Q), RIs type (C);(c3) rn(R) R rn(Qi ), = 1, . . . , m, RIs type (D);(c4) rn(Ri ) R rn(Q0 ), = 1, . . . , m, RAs type (E);(c5) exists quasi-order 1R Rrn(Q0 ) 1R rn(Q), RA type (E);rn(Q) 1R rn(Qi ), = 1, . . . , m, RA type (F);(c6) exists quasi-order 2R Rrn(Q) 2R rn(Q0 ), RA type (E);rn(Qi ) 2R rn(Q), = 1, . . . , m, RA type (F);(c7) exist RAs r r 0 one following conditions holds:r 0 = (Q0 = Q0 R1 . . . Rm0 ), r = (Q = Q1 Qm ), rn(Q0 ) = rn(Q)rn(Q0 ) = rn(Qj ), j, 1 j m;0 ), r = (Q0 = Q R . . . R ), rn(Q0 ) = rn(Q0 )r 0 = (Q00 = Q0 R10 . . . Rm01 1101rn(Q0 ) = rn(Q1 );r 0 = (Q0 = Q01 Q0m0 ), r = (Q = Q1 Qm ), rn(Q0 ) = rn(Q)rn(Q0i ) = rn(Qj ), i, j, 1 m0 , 1 j m.remainder section, discuss regularity conditions (c1)(c7) illustrate concrete examples. Note first condition (c1) required ensuredecidability SROIQ; mentioned introduction, dropping immediately leadsundecidability (Demri, 2001; Horrocks & Sattler, 2004). understand (c2), considerfollowing:Example 4 Let R = {RQ v Q0 , Q0 v QR}. former RI type (B), latterone type (C). Clearly, Q0 v QR satisfy (c2), RBox regular.see situation dangerous, observe R |= RQ v QR. Now, TBoxgenerates infinite chains Q- R -arrows starting point, RIRQ v QR would generate N N-grid shown left-hand side picture below:816fiA Decidable Extension SROIQ Complex Role Chains UnionsQQQ1RQRQRQQQ QQQ1RQQ0RRQRQRQRRQQQRRQRroutine reduce undecidable N N-tiling problem KB satisfiability.hand, RBox R0 = {R v QRQ } regular (rn(R) R0 rn(Q)).However, cannot generate proper N N-grid (as shown right-hand sidepicture above). able encode N N-tiling problem, require additional RIsQ Q v Q1 Q Q1 Q v Q1 . resulting RBox satisfycondition (c1).Condition (c3) similar (c2); omission leads undecidability shownWessel (2002). illustrate (c4), give one example.Example 5 Consider RBox R = {Q0 Q v Q1 , Q0 = Q Q1 }. Clearly, satisfy(c4), condition omitted, Q0 R Q1 Q R Q1 . observedangerous RI Q Q1 Q v Q1 Example 4 consequence R.Since REs (E) (F) imply Q0 v QR1 . . . Rm Q v Q1 Qm types (C)(D), condition (c5) similar (c2) (c3). (c6), consider following:Example 6 RBox R = {Q1 Q2 v Q2 , Q3 Q4 v Q3 , Q4 = Q2 S} regular. However,R1 = R {Q1 = Q3 0 } regular rn(Q1 ) R1 rn(Q2 ), rn(Q4 ) R1 rn(Q3 ),rn(S) R1 rn(Q4 ), rn(S 0 ) R1 rn(Q1 ), (c1)(c5) (c7) satisfied,(c6) not. Now, R1 implies Q3 0 Q2 v Q2 Q3 Q2 v Q3 , obtainQ3 Q2 SS 0 Q2 v Q2 . RBox containing RI generates language regular.Finally, require condition (c7) view following:Example 7 RAs Q0 = QR Q0 = Q Q1 clearly imply Q v QR. sawExample 4, presence RI RQ v Q, would lead undecidability. Condition(c7) allow RBoxes sort counted regular.already noted, restrict SR+ OIQ RBoxes RAs types (A)(F) mainlyorder simplify notation proofs; see (7). Every RI R1 . . . Rn v P1 . . . Pmequivalent RI inv (Rn ) . . . inv (R1 ) v inv (Pm ) . . . inv (P1 ). particular, RIinv (R) v inv (Qm ) . . . inv (Q1 )inv (Q) equivalent RI R v QQ1 . . . Qm type (C),use former SR+ OIQ RBoxes provided rn(R) rn(Q). Every0 replaced RIs R . . . R v P . . . PRI R1 . . . Rn v P1 . . . Pk P10 . . . Pm1n1k00v P1 . . . Pm , fresh role name , without affecting satisfiability KB.817fiMosurovic, Krdzavac, Henson & Zakharyaschevparticular, rn(Ri ) rn(Q), represent R1 . . . Rn v P1 . . . Pk QPk+1 . . . Pmmeans three SR+ OIQ RIs: R1 . . . Rn v R, inv (R) v inv (T )inv (Pk ) . . . inv (P1 )v QPk+1 . . . Pm , fresh role names R . Instead R1 . . . Rn v P1 Pmuse R1 . . . Rn v R R v P1 Pm , fresh role name R. donerole equality axioms.reflexivity constraint Ref (R) (saying RI reflexive) expressed meansRI v R CI > v S.Self , fresh simple role.Example 8 RI (1) introduction represented SR+ OIQ two RIs:hasEngine hasCrankshaft powers v Q,(8)Q v hasWheel hasHub,(9)Q fresh non-simple role name. One might suggest (9) could replacedRI Q hasHub v hasWheel. However, case: interpretation givensatisfies former latter (obviously, Q hasHub v hasWheelimply (9)).QQhasWheelhasWheelhasHubhasHubExample 9 Consider (regular) RBox R = {R v Q1 R1 , Q1 v Q2 P, P = Q3 R}ABox = {(x0 , x1 ) : P }. model R contains sequence (not necessarilydistinct) points x0 , x1 , x2 , . . . arranged according patter shown picture below:x4x0Q3Px1x2Q2Q3PRQ1R1x7x5PRx3Q2Q1R1x6applying tableau algorithm R (to introduced remainderpaper), construct model, represent tree-shaped structureomitting Q1 -, Q2 - Q3 -arrows, always restored. (In general, alwaysomit first role right-hand side axiom type (C) (E), rolesright-hand side axiom type (D) (F).) illustrated picturebelow.818fiA Decidable Extension SROIQ Complex Role Chains Unionsx0x0PPx1x1Q3R1x3PRR1x6R1Rx2PRR1x4x2Q1x5Rx3x6Q1Q2Q3x4x54. SR+ OIQ Tableaux Examplesprove decidability SR+ OIQ using tableau-based algorithm, generalisation algorithm given Horrocks et al. (2006). assume reader familiartableau technique standard DLs ALCI (Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2003). aim section explain, using concreteexamples, problems one encounters constructing tableaux SR+ OIQway resolve problems suggested paper. workedexamples, reader grasped general idea tableaux SR+ OIQ.assume concepts negation normal form (NNF). particular,write C, concept C, actually mean NNF C. Denote con(C) smallestset contains C closed sub-concepts . KB K = (T , R, A),denote con(K) union con(C), concepts C occurring K. basic roleR con(K), set |R = {C | R.C }.4.1 RIs Role Chains Right-Hand SideExample 10 Consider first KB K = (T , R, A),= {a : A},R = {R v QP },= {A v R.>, v Q.B, v Q.C}.start construction tableau K applying standard tableau rules ALC.Thus, create root node x0 (corresponding ABox individual a) label`(x0 ) = {A, R.>, Q.B, Q.C}, indicating thereby (some of) conceptscontain according K. view R.> `(x0 ), create R-successor x1 x0 .interpretation, corresponding resulting tableau shown left-hand sidepicture below, clearly model A, R.`(x0 )x0`(x0 )Rx1x0x1RQPx2satisfy R, need Q-successor x2 x0 , x1 P -successor. However,resulting interpretation, shown right-hand side picture above,819fiMosurovic, Krdzavac, Henson & Zakharyaschevtree. keep tableau tree-shaped, would prefer create x2 P -successorx1 without drawing Q-arrow x0 x2 explicitly. trigger creation x2ensure Q-arrow always inserted x0 x2 , addlabel `(xi ) new quasi-concept form R.P .`(xi )|Q , encodes R v QP .intended meaning quasi-concept expected: every R-successor xi mustP -successor whose label contains concepts `(xi )|Q = {C | Q.C `(xi )}. (Notetableau nodes part syntax quasi-concepts. quasi-concepts,fact, extend syntax expressions R.S, set ordinaryconcepts.) agree extend standard tableau rules R P quasiconcepts, need one new tableau rule (which generalised laterpaper):(r1) (R v QP ) R R.P .`(x)|Q/ `(x), set `(x) := `(x){R.P .`(x)|Q }.Now, returning example, apply (r1) `(x0 ), `(x1 ) = obtain:`(x0 ) := A, R.>, Q.B, Q.C, R.P .{B, C} ,`(x1 ) := R.P ., P .{B, C} .create P -successor x2 x1 `(x2 ) = {B, C, R.P .}, picturebelow, stop complete clash-free tableau, gives model Kinsert missing Q-arrow x0 x2 .`(x0 )x0`(x1 )Rx1`(x2 )Px2Note inserting missing Q-arrow example becomes problematicextend CI B v Q .A shall add `(x0 ),obtain clash. However, cannot without constructing arrow explicitly.cope problem, together `(x0 )|Q , also pass `(x2 ) set`Q (x0 ) concepts C `(x0 ) potentially occur Q .C `(x2 ), namely,set `(x0 ) con(K)|Q . store set special memory x2 ordercompare `(x2 )|Q : `(x2 )|Q 6 `Q (x0 ), report clash. However,solve problem yet. see why, consider extension B v Q .C(rather B v Q .A). C belong `(x0 ), would report clash,though addition C `(x0 ) would lead contradiction. solution suggestsituations make sure that, every concept {C | Q .C con(K)}{Q.C | Q.C con(K)}, either `(x0 ) `(x0 ).formalise idea tableau rules, require new notation. allowquasi-concepts form `Q (x) = (tr , , ), tr = Q, = `(x)|Q =`(x) con(K)|Q ; also denote first component triple `rQ (x), second`Q (x), third `Q (x). special memory associated node x denotedm(x); assume originally empty. require following tableau rules,supersede former (r1):(r1) (R v QP ) R, rule (r3) applicable, R.P .`Q (x)/ `(x), set`(x) := `(x) {R.P .`Q (x)};820fiA Decidable Extension SROIQ Complex Role Chains Unions(r2) P .t `(x), = (tr , , ), x P -neighbour1 `(y)m(y), create new P -successor x set `(y) = m(y) = {t};(r3) (R v QP ) R {Q.C | Q.C con(K)} {C | Q .C con(K)}{D, D} `(x) = , set `(x) := `(x) {E}, E {D, D};(clash) (tr , , ) m(x) `(x)|inv (tr ) 6 , report clash.Example 11 illustrate, consider KB K = (T , R, A),= {a : A},R = {R v QP },= {A v R.>, v Q.B, B v Q .C, C v Q.D}.obtain following complete clash-free tableau K:`(x0 ) = {A, R.>, Q.B},(by v)`(x0 ) := `(x0 ) {Q.D, C},`(x0 ) := `(x0 ) R.P .`Q (x0 ) , `Q (x0 ) = {B, D}, `Q (x0 ) = {C},(by r3)(by r1)create x1 x0 Rx1 , `(x1 ) = {Q.B, Q.D, C},(by R, r3)`(x1 ) := `(x1 ) R.P .`Q (x1 ), P .`Q (x0 ) , `Q (x1 ) = {B, D}, `Q (x1 ) = ,(by r1, R)create x2 x1 P x2 , m(x2 ) = {`Q (x0 )} `(x2 ) = `Q (x0 ) = {B, D},`(x2 ) := `(x2 ) Q .C, Q.B, Q.D, C, R.P .`Q (x2 )) .(by r2)(by v, r3, r1)clash `(x2 )|inv (Q) `Q (x0 ).4.2 RIs Role Unions Right-Hand Sidenext example illustrates tableaux RIs unions right-hand side.Example 12 Consider KB K = (T , R, A)= {a : A},R = {R v Q },= {A v R .C, v R .D, C v Q.A, C v Q.B, C v T.A,v T.A, v T.B, v Q.B}.applying standard rules, obtain tableau shown picture below:`(x1 ) = {C, Q.A, Q.B, T.A}`(x2 ) = {D, T.A, T.B, Q.B}x1x2RRx0`(x0 ) = {A, R .C, R .D}1. Intuitively, neighbour successor predecessor given node. formal definition notiongiven Section B.821fiMosurovic, Krdzavac, Henson & ZakharyaschevNow, satisfy R, draw either Q- -arrow x1 x0 , alsox2 x0 . before, explicitly. ensure arrows alwaysdrawn, add `(xi ) quasi-concept form R.(`(xi )|Q `(xi )|T ),`(xi )|P = {C | P.C `(xi )}. meaning quasi-conceptself-evident. Thus, extend `(xi ) to:`(x0 ) := `(x0 ) R.( ) ,`(x1 ) := `(x1 ) R.({A, B} {A}) ,`(x2 ) := `(x2 ) R.({B} {A, B}) .add either A, B `(x0 ) view quasi-concept `(x1 ),also either B A, B view quasi-concept `(x2 ). clash-free wayextend `(x0 ) A, B. Clearly, draw Q-arrow x1 x0-arrow x2 x0 .formulate tableau rules handling role unions RIs, taking accountquasi-concepts triples considered above:(r4) (R v QtT ) R {P.C | P.C con(K)}{C | P .C con(K)},P {Q, } {D, D} `(x) = , set `(x) := `(x) {E},E {D, D};(r5) (R v Q ) R, rule (r4) applicable, R.(`Q (x) `T (x))/ `(x),set `(x) := `(x) {R.(`Q (x) `T (x))};(r6) (t1 t2 ) `(x), ti = (tri , ti ,), = 1, 2, j {1, 2}tj `(x) tj m(x), take j {1, 2} set `(x) := `(x) tjm(x) := m(x) {tj }.4.3 RIs Role Chains Left-Hand Sidetechnique illustrated examples works perfectly well RIs singlerole left-hand side. cope complex RIs, follow Horrocks Sattler(2004) Horrocks et al. (2006) encode every R role(K) regular RBox Rmeans nondeterministic finite automaton (NFA) AR = (SAR , role(K), sR , AR , aR ),SAR finite set states, role(K) input alphabet, sR SAR initialstate AR , AR : SAR role(K) 2SAR transition function aR SARaccepting state. REs R, AR accepts precisely role chainsbelong language LR (R); words L(AR ) = LR (R).tableau construction, whenever R.C `(x), extend `(x) quasiconcept AsR .C, initial state AR . Next, ApR .C `(x), -neighbourx q AR (p, ), extend `(y) AqR .C. Finally, AaR .C `(y),accepting state AR , extend `(y) C. define tableau rules formally,first confine attention single RI form r = (R v QP ).start defining sets quasi-concepts allowed RBoxes containing r.Denote qc set quasi-concepts form ApR .C R.C con(K)822fiA Decidable Extension SROIQ Complex Role Chains Unionsp state AR . set qc basic role , set:|T = {AqR .C | ApR .C q AR (p, )},qc (r) = {ApT .C | ApT .C qc exists qqc(r) = ApR .P .(tr , , ) | p state AR , tr(10)(p, Q)} qc|Q ,= Q,qc|Q ,(11)qc|Q.(12)convenient think labels `(x) tableaux consisting two disjointparts `(x) = c(x) a(x), c(x) containing standard concepts a(x) quasi-concepts;is: c(x) con(K)a(x) qc qc(r) {P .t | ApR .P .t qc(r)} {C | C qc (r)}.allow quasi-concepts form aQ (x) = (Q, a(x)|Q , a(x) qc|Q ); denotefirst component triple arQ (x), second aQ (x), thirdQ (x).Using new notation, rewrite (r1)(r3) follows:(r1) r R exists C qc (r) {C, C} a(x) = , set a(x) :=a(x) {D}, {C, C};(r2) R.C c(x) AsR .C 6 a(x), initial state AR , seta(x) := a(x) {AsR .C};(r3) r R, rule (r1) applicable r AsR .P .aQ (x) 6 a(x),initial state AR , set a(x) := a(x) {AsR .P .aQ (x)};(r4) ApR .C a(x), q AR (p, ), -neighbour x AqR .C 6 a(y), seta(y) := a(y) {AqR .C};(r5) AaR .C a(x), accepting state, C/ c(x), set c(x) := c(x) {C};(r6) AaR .P .t a(x), accepting state, P .t/ a(x), seta(x) := a(x) {P .t};(r7) P .t a(x), = (tr , , ), x P -neighbour a(y)m(y), create new P -successor x set a(y) = m(y) = {t}.clash rule remains before, place `. Note rule (r7)replaced two rules one creates new node sets a(y) = {t},rule sets a(y) := a(y) . case need m(y). illustratenew terminology tableau rules revisiting Example 11.Example 11 (cont.) Consider KB K = (T , R, A)= {a : A},R = {R v QP },= {A v R.>, v Q.B, B v Q .C, C v Q.D}.tableau below, AQ AR NFAs L(AQ ) = {Q}, L(AR ) = {R},two states: initial accepting a.c(x0 ) = {A, R.>, Q.B}, a(x0 ) = {AsQ .B},823(by v, r2)fiMosurovic, Krdzavac, Henson & Zakharyascheva(x0 ) := a(x0 ) AsQ .D, AaQ .C , c(x0 ) := c(x0 ) {C},a(x0 ) := a(x0 ) AsR .P .aQ (x0 ) ,aQ (x0 ) = {AaQ .D, AaQ .B},Q (x0 ) = {AQ .C},(by r1, r5)(by r3)create x1 x0 Rx1 , c(x1 ) = , a(x1 ) = {AsQ .D, AsQ .B, AaQ .C},(by R, r1)a(x1 ) := a(x1 ) {AsR .P .aQ (x1 )}, aQ (x1 ) = (Q, {AaQ .D, AaQ .B}, {AaQ .C}), (by r3)a(x1 ) := a(x1 ) AaR .P .aQ (x0 ), P .aQ (x0 ) ,(by r4, r6)create x2 m(x2 ) = {aQ (x0 )}, x1 P x2 , c(x2 ) = , a(x2 ) = {AaQ .D, AaQ .B}, (by r7)c(x2 ) := {B, D, Q .C}, a(x2 ) := a(x2 ) AsQ .C ,(by r5, v, r2)a(x2 ) := a(x2 ) AsQ .D, AsQ .B, AaQ .C, AsR .P .(Q, {AaQ .D, AaQ .B}, ) ,(by r1, r3)a(x2 )|inv (Q) = {AaQ .C}Q (x0 ), resulting tableau complete clash-free.4.4 Interaction RIs Role Chains Right-Hand SideExample 13 Consider KB K = (T , R, A)= {a : A},R = {R v QP, Q v Q1 P1 },= {A v R.>, v Q.B, B v Q .C, C v Q.D, C v Q1 .B}.two RIs form (C), Q occurring right-hand side R v QPleft-hand side Q v Q1 P1 . expect tableau algorithm constructmodel K shown picture below:Q1Qx0x1Rx2PP1x3A, Q.B, C, Q.D, Q1 .BBB, Q .C,However, apply available rules, produce following tableau:AsR .P .aQ (x0 ), AsQ .P1 .aQ1 (x0 )P .aQ (x0 )x0x1RAaQ .D, AaQ .BPx2aQ (x0 ) = (Q, {AaQ .D, AaQ .B}, {AaQ .C}) aQ1 (x0 ) = (Q1 , {AaQ1 .B}, ).explicit Q-arrow x0 x2 , cannot apply (r4) obtain quasiconcept AaQ .P1 .aQ1 (x0 ), so, (r6), P1 .aQ1 (x0 ) x2 , would triggerconstruction P1 -arrow x2 x3 . overcome problem, use quasiconcept encoding RI Q v Q1 P1 construction quasi-concept R v QP .precisely, add AaQ .P1 .aQ1 (x0 ) aQ (x0 ), thus obtainingaQ (x0 ) = {AaQ .D, AaQ .B, AaQ .P1 .aQ1 (x0 )}.824fiA Decidable Extension SROIQ Complex Role Chains UnionsAsR .P .aQ (x0 ) a(x0 ), apply (r4) obtain AaR .P .aQ (x0 ), so,(r6), also P .aQ (x0 ) a(x1 ). construct x2 a(x2 ) containing three quasiconcepts AaQ .D, AaQ .B AaQ .P1 .aQ1 (x0 ), last requires existenceP1 -successor x3 .order formalise previous idea, introduce dependency relation C. GivenRIs R1 v Q1 P1 R2 v Q2 P2 , write (R1 v Q1 P1 ) C (R2 v Q2 P2 ) statesp, q AR1 either q AR1 (p, Q2 ) q AR1 (p, Q2 ). particular,(Q v Q1 P1 ) C (R v QP ). R regular, hard see relation Cacyclic. Indeed, follows definition C, Lemma 1, Definition 3 AR1rn(Q2 ) R rn(Q1 ) (since rn(Q2 ) R rn(R1 ) rn(R1 ) R rn(Q1 )).Now, induction C define sets qc(r) RIs r = (R v QP ). C-minimalr, qc(r) defined (12). Then, assuming qc(r 0 ) defined every r 0 C rr = (R v QP ), setqc(r) = {ApR .P .t | p state AR },= (tr , , ), tr = Q, qc|Q r0 Cr qc(r 0 )|Q , qc|Q r0 Cr qc(r 0 )|Qand, r 0 = (R0 v Q0 P 0 ) (r 0 ) qc(r 0 ),(r 0 )|T = {AqR0 .C | ApR0 .C (r 0 ) q AR0 (p, )}.also setqc (r) = {ApT .C | exists q (p, Q), ApT .C qc{AqT .C| q (p, Q ),[qc(r 0 )}r 0 CrApT .Cqc[qc(r 0 )}.r 0 CrReturning example, see r 1 C r, r 1 = (Q v Q1 P1 ), r = (R v QP ),qc(r 1 ) remains before, qc(r) becoming larger and, particular,contains {ApR .P .(tr1 , t1 ,1 ) | p {s, a}},t1 {AaQ .D, AaQ .B, AaQ .P1 .(Q1 , {AaQ1 .B}, ), AaQ .P1 .(Q1 , , )},1 {AQ .C}.example, qc(r) contains quasi-conceptAsR .P .(Q, {AaQ .D, AaQ .B, AaQ .P1 .(Q1 , {AaQ1 .B}, )}, {AaQ .C}).construction tableau K Example 13, using newly defined sets qc(r),routine left reader.dependency relation C RIs RBoxes become complexpresence unions roles.825fiMosurovic, Krdzavac, Henson & Zakharyaschev4.5 Role EqualitiesExample 14 Consider RBox R two RAs: ST v R type (B) R = QPtype (E). Clearly, R = QP replaced RIs R v QP QP v R,resulting RBox {ST v R, R v QP, QP v R} regular. Let us observeRBoxesR0 = {ST v R, QP v R}R00 = {ST v R, R v QP }regular. Denote AR NFA R determined R0 , A1 NFA Rgiven R00 (see picture below).pARstartpRQstartA1RPqLet us see whether use automata rules (r2) (r3)page 823 role R. Consider KB K = (T , R, A), R= {a : A},= {A v R.>, v Q.B, v Q.C, v R.D}.First try AR . applying tableau rules obtain following:A, R.>, R.D, Q.B, Q.C, AsR .D, AsQ .B, AsQ .CAaR .D,x0x1Rapply (r3) RI R v QP add quasi-concept AsR .P .aQ (x0 )a(x0 ), aQ (x0 ) = (Q, a(x0 )|Q , a(x0 ) qc|Q ). Q-transition AR ,must AqR .P .aQ (x0 ) a(x0 )|Q , impossible a(x0 )|Q cannotelement itself.Alternatively, use A1 R. gives usR.D, As1 .P .aQ (x0 ), As1 .Dx0AaQ .C, AaQ .BP .aQ (x0 ), Aa1 .D,Px1Rx2aQ (x0 ) = (Q, {AaQ .C, AaQ .B}, ), defines model K add missingQ-arrow x0 x2 .Now, replace CI v R.> K v Q.P.> use A1 R.case, obtain following tableau:R.D, As1 .P .aQ (x0 ), As1 .Dx0x1Q826Px2fiA Decidable Extension SROIQ Complex Role Chains Unionsproduce satisfying interpretation I, add R-arrow x0 x2 . However,cannot done free (as Example 10) x2/ DI . alternative woulduse AR R0 instead R (because apply (r3) R v QP ).obtain following tableau:AqR .DR.D, AsR .Dx0Qx1AaR .D,Px2addition R-arrow x0 x2 gives interpretation |= QP v Rx2 DI .sum up: rule (r2) requires NFA AR , (r3) requires A1 . rule (r2)page 823 remains rewrite rule (r1) (r3) include role equalitiesfollows:(r1) r R, r = (R v QP ) r = (R = QP ), exists C qc (r){C, C} a(x) = , set a(x) := a(x) {D}, {C, C};(r3) r R, r = (R v QP ) r = (R = QP ), rule (r1) applicable rAs1 .P .aQ (x) 6 a(x), initial state A1 , set a(x) :=a(x) {As1 .P .aQ (x)}.Note case r = (R v QP ) NFA A1 AR case r = (R = QP )NFA A1 different AR described above.5. Main Result Discussionexamples previous section provide basic ingredients addedSROIQ tableaux Horrocks et al. (2006) Horrocks Sattler (2007) orderobtain sound complete tableaux SR+ OIQ. present technical detailsdefinitions Appendix A. corresponding sound, complete terminating tableaualgorithm given Appendix B. Thus, obtain following:Theorem 15 Concept satisfiability respect SR+ OIQ KBs decidable.noted decision algorithm Appendix B (quite sophisticated)extension standard tableau procedure SROIQ; input RBoxcontain RAs form (C)(F) tableau algorithm behaves exactly SROIQprocedure. simplify presentation avoid number technical details, decidedoptimise tableau algorithm paper. fact, plenty roomoptimisations; example, one work careful choice quasi-concepts wellutilise approach Motik, Shearer, Horrocks (2009).exact complexity concept satisfiability respect SR+ OIQ KBs stillunknown. RBox contains one RA r 1 form (C)(F), algorithmconstruct set qc(r 1 ) quasi-concepts, contains subsets previouslyconstructed sets quasi-concepts qc(r 0 ), may suffer exponential blow-up. Furthermore, algorithm may suffer one exponential blow-up every time addextra RA form (C)(F), thereby extend C-chains RAs,827fiMosurovic, Krdzavac, Henson & Zakharyaschevset quasi-concepts may become exponentially larger. investigate complexityfull SR+ OIQ, may useful consider first various sub-languages. example,conjecture ALCI-concept satisfiability respect regular RBoxescontain axioms type (C) roles rn(Ri ), = 1, . . . , m, appear left-handside RIs, PSpace-complete. SI-concept satisfiability respect RBoxescontain one axiom form R v QP , rn(R), rn(Q), rn(P ) different rolenames transitive, also PSpace-complete.step SROIQ SR+ OIQ is, extent, similar step SHOIQSROIQ: SROIQ extends SHOIQ role inclusion axioms containing role chainsleft-hand side, SR+ OIQ extends SROIQ role inclusion axioms containing rolechains unions right-hand side. Attempts extend various DLs roleinclusions made since 1985 (Brachman & Schmolze, 1985; Baader, 2003; Wessel,2001, 2002); however, resulted undecidable formalisms. Similar problemsinvestigated modal logic, shown regular grammar logics decidable (Demri, 2001). regularity condition RAs axioms generalises restrictionsHorrocks et al. (2006) Kazakov (2010). (However, closer inspectionresults related grammar modal logics needed.) Simanck (2012) showed complex RIs SROIQ encoded using SHOIQ axioms. would interest findwhether similar reduction possible case SR+ OIQ.One aims introducing complex role inclusion axioms DLs model complexstructured objects. Suppose, example, represent cycle shownleft-hand side picture below:x0x0QR1x1x4x1R2R4R2x2R3QR1x3x4Q1x2Q2R3R4x3SROIQ, use RI axiom R1 R2 R3 R4 v Q, produces requiredcycle chain form R1 R2 R3 R4 . Using description graphswork Motik et al. (2009), express existence cycle whole.SR+ OIQ, model situation following regular RBox, Q1 Q2fresh role names:R1 v QR4 R3 R2 ,R2 v Q1 R1 ,Q1 v QR4 R3 ,R3 v Q2 R4 ,Q2 v Q R1 R2 ,R4 v Q R1 R2 R3(see picture above). RBox produces required cycle least one Ri ,= 1, 2, 3, 4, model. connection, would interest considerextension SHOIQ RI axioms form (A) (C).828fiA Decidable Extension SROIQ Complex Role Chains UnionsAppendix A. SR+ OIQ Tableauxobserved Horrocks et al. (2006, Thm. 9), without loss generality definetableaux SR+ OIQ KBs empty TBoxes ABoxes. Let R regular RBoxC0 SR+ OIQ concept. assume RC,D,E,F = {r | = 1, . . . , l}, where,k1 , k, l1 1 k1 k l1 l,r = (Ri v Qi Pi1 . . . Pimi ),= 1, . . . , k1 ,r = (Ri = Qi Pi1 . . . Pimi ),= k1 + 1, . . . , k,r = (Ri = Ti1 Timi ),= k + 1, . . . , l1 ,r = (Ri v Ti1 Timi ),= l1 + 1, . . . , l.every R role(C0 , R), construct, preprocessing step, NFA AR specialNFAs Ai , = 1, . . . , l, described below. Recall L(A) denotes languagerecognised A. p state A, Ap NFA obtained making p(only) initial state A.Define RBoxR0 = RA,B {Qi Pi1 . . . Pimi v Ri | = k1 + 1, . . . , k}{Tij v Ri | = k + 1, . . . , l1 , j = 1, . . . , mi },contains axioms types (A) (B). Since R regular view conditions(c1), (c4) (c6) Definition 3, RBox R0 stratified. Theorem 2, use R0construct, R role(C0 , R), NFA AR = (SAR , role(C0 , R), sR , AR , aR )L(AR ) = LR0 (R).also define RBoxesRi = R0 \ {Qi Pi1 . . . Pimi v Ri },0R = R \ {Tij v Ri | j = 1, . . . , mi },= k1 + 1, . . . , k,= k + 1, . . . , l1 ,construct NFAs Ai L(Ai ) = LRi (Ri ), = k1 + 1, . . . , l1 . = 1, . . . , k1= l1 + 1, . . . , l, simply set Ai = ARi .Now, going define formally set qc(C0 , R). elements qc(C0 , R)called quasi-concepts (for C0 w.r.t. R); use define labels tableau nodes.definition qc(C0 , R), require dependency relation C RC,D,E,F .role name Q {rn(Qi ), rn(Ti1 ), . . . , rn(Timi ) | 1 l}, let AutIn(Q)set {1, . . . , l} states p q Ai q Ai (p, Q)q Ai (p, Q ). define C RC,D,E,F taking r C r j1 j k AutIn(rn(Qj )),k < j l h {1, . . . , mj } AutIn(rn(Tjh )).following lemma shows transitive closure C acyclic:Lemma 16 (i) r C r j r j C r hold.(ii) r i1 C r i2 r i2 C r i3 , r i3 C r i1 hold.829fiMosurovic, Krdzavac, Henson & ZakharyaschevProof. Observe first AutIn(Q) Q- Q -transition Ai ,rn(Q) 1R rn(Ri ). k rn(Ri ) 1R rn(Qi ), rn(Q) 1R rn(Qi ).> k rn(Ri ) 1R rn(Tih ), rn(Q) 1R rn(Tih ), h {1, . . . , mi }.(i) Let r C r j . Four cases possible.Case 1: i, j k. AutIn(rn(Qj )), rn(Qj ) 1R rn(Qi ). Similarly,r j C r , rn(Qi ) 1R rn(Qj ), impossible.Case 2: j k > k. AutIn(rn(Qj )), rn(Qj ) 1R rn(Tih ),h {1, . . . , mi }. r j C r Tih0 , 1 h0 mi , j AutIn(rn(Tih0 )).Hence, rn(Tih0 ) 1R rn(Qj ), contradiction.Case 3: k j > k. mirror image case 2.Case 4: i, j > k. Tjh0 , 1 h0 mj , AutIn(rn(Tjh0 )),rn(Tjh0 ) 1R rn(Tie ), e {1, . . . , mi }. Similarly, r j C r , Tie0 ,1 e0 mi , rn(Tie0 ) 1R rn(Tjh ), h {1, . . . , mj }, impossible.proof (ii) similar left reader.qrequire following notation. Letqc = {ApR .C | R.C con(C0 ) p state AR }.set qc basic role P , set|P = {AqR .C | ApR .C q AR (p, P )}.Sometimes convenient us write qc(r 0 ) place qc assume r 0 Cr ,i, 1 l. Now, assuming qc(r j ) defined every r j C r 0 j l1 l, define qc(r ) set Aqi .Cq state Ai ;rk, C = Pim. Pi1.(t0 , t0 , t0 ) tr0 = Qi ;W rr> k, C =h=1 (th , th , th ) th = Tih ;th rj Cri qc(r j )|tr ;hhr j Crqc(r j )|inv (tr ) .h(r ) qc(r ) basic role P , let(r )|P = {Aqi .C | Api .C (r ) q Ai (p, P )}.Finally, setqc(C0 , R) =l[qc(r ),i=0and, qc(C0 , R) basic role P ,|P=l[( qc(r j ))|P| = {Aq .C | Ap .C q (p, )},j=0830fiA Decidable Extension SROIQ Complex Role Chains Unionsempty role chain. qc(C0 , R) 1 l, let(rP . . . Pi1.(t0 , t0 , t0 ), tr0 = Qi , k,(r , ) = Wmimrr> k,h=1 (th , th , th ), th = Tih ,(13)th = |tr ,h = qc(C0 , R)|inv (trh ) , 0 h mi . Clearly, Ai .((r , )) qc(r ).hIntuitively, label node u, is, = a(u), (r , ) quasi-conceptencoding RA r node u.Example 17 Let R = {r 1 , r 2 }, r 1 = (R1 v Q1 P1 P2 ) r 2 = (R2 v T1 T2 ).NFAs roles R two states: initial accepting a. Suppose= {AsQ1 .C1 , AaQ .C2 , AsT1 .C3 , AsT2 .C4 , AsT2 .C5 , AaT .C6 }.11(r 1 , ) = P2 .P1 .(Q1 , {AaQ1 .C1 }, {AaQ .C2 }),1(r 2 , ) =(T1 , {AaT1 .C3 }, {AaT .C6 })1(T2 , {AaT2 .C4 , AaT2 .C5 }, ).Remark 18 P symmetric role (i.e., (P v P ) R), occurrence Pinv (P ) treated rn(P ). example, {P.D, P .C}|P = {D, C}.position define SR+ OIQ tableaux. Note essentialdifference compared tableaux SROIQ (Horrocks et al., 2006) rules(p19), (p21) (p22).tableau C0 w.r.t. R structure form = (S, c, a, E), non-emptyset, c : 2con(C0 ) , : 2qc(C0 ,R) , E : role(C0 , R) 2SS followingconditions hold:(p1) C0 c(u0 ) u0 S,(p2) C c(u) C/ c(u), C either concept name R.Self ,(p3) > c(u)/ c(u) u,(p4) R.Self c(u) (u, u) E(R),(p5) R.Self c(u) (u, u) 6 E(R),(p6) (C1 u C2 ) c(u) C1 c(u) C2 c(u),(p7) (C1 C2 ) c(u) C1 c(u) C2 c(u),(p8) R.C c(u) v (u, v) E(R) C c(v),(p9) (u, v) E(R) iff (v, u) E(inv (R)),(p10) ( nS.C) c(u) ]{v | (u, v) E(S) C c(v)} n,831fiMosurovic, Krdzavac, Henson & Zakharyaschev(p11) ( nS.C) c(u) ]{v | (u, v) E(S) C c(v)} n,(p12) ( nS.C) c(u) (u, v) E(S), C c(v) C c(v),(p13) c(u) c(v), nom(C0 ), v = u,(p14) nom(C0 ), vo c(vo ),(p15) Dis(R, S) R E(R) E(S) = ,(p16) (u, v) E(R) R v S, (u, v) E(S),2(p17) R.C c(u) AsR .C a(u), initial state AR ,(p18) AaR .C a(u), accepting state, C c(u),(p19) Asi .C a(u), initial state Ai C = (r , a(u)), u1 l,(p20) (u, v) E(R) a(u)|R a(v),(p21) Aai .C a(u), k, C = inv (Pimi ). inv (Pi1 ).(tr , , )accepting state, v0 , v1 , . . . , vmi = u (vj , vj1 ) E(inv (Pij )),1 j mi , a(v0 ) a(v0 )|inv (tr ) ,W r(p22) Aai .C a(u), accepting state, > k C =h=1 (th , th , th ),j {1, . . . , mi } tj a(u) a(u)|inv (tr ),jj(p23) a(u)| a(u).Let = (S, c, a, E) tableau, R basic role u, v S. a(u)|R a(v)a(v)|inv (R) a(u), write ar(R, u, v). R-arrow u var(R, u, v) holds; see Proposition 20 (i). hand, meaning ar(R, u, v)always insert R-arrow (for non-simple role R) u v without violatingtableau conditions.Lemma 19 concept C0 satisfiable w.r.t. SR+ OIQ RBox Rexists tableau C0 w.r.t. R.Proof. () Let = (S, c, a, E) tableau C0 w.r.t. R. Define interpretation= (I , ) taking = S, C = {u | C c(u)}, concept name C con(C0 ).role name R, define E(R) (by induction 1R ) RI following way.role name R, define E(R) RI induction 1R following way. 1R minimal R, set E(R) = E(R). extend E() E(inv (R)) = {(u, v)|(v, u) E(R)}2. v transitive closure v.832fiA Decidable Extension SROIQ Complex Role Chains UnionsE(S1 . . . Sn ) = E(S1 ) E(Sn ). Suppose E(S) defined 1R R.set, wi = Pi1 . . . Pimi E(wi ) = E(Pi1 ) E(Pimi ),E(R) = E(R)[{(u, v) | ar(R, u, v) & % L(Ai ) z ((u, z) E(%) (v, z) E(wi ))}{i|R=Qi }[{(u, v) | ar(R, u, v) & % L(Ai ) z ((v, z) E(%) (u, z) E(wi ))}{i|R=inv (Qi )}[{(u, v) | ar(R, u, v) & % L(Ai ) (u, v) E(%)}{i|j R=Tij }[{(u, v) | ar(R, u, v) & % L(Ai ) (v, u) E(%)},{i|j R=inv (Tij )}RI= {(u0 , un ) | u1 , . . . , un1 ((ui , ui+1 ) E(Si+1 ) S1 S2 . . . Sn L(AR ))}.need E(R) adjust E(R) taking account omitted R-arrows RIs form(C)(F) use RIs construction AR . picture illustratessituation role Q two RIs QQ v Q R v QP (E(Q) E(Q) QI ).QIE(Q)u0E(Q)u1RIu2(P )Iu3show model C0 R. end, require following:Proposition 20 (i) (u, v) E(R) ar(R, u, v).(ii) (u, v) E(R) ar(R, u, v).(iii) % L(A), (u, v) E(%) .C a(u) Aa .C a(v).(iv) (u, v) RI AsR .C a(u) AaR .C a(v).Proof. (i) Follows (p20) (p9). precisely, (u, v) E(R) then, (p9),(v, u) E(inv (R)). (p20), (u, v) E(R) implies a(u)|R a(v), (v, u) E(inv (R))implies a(v)|inv (R) a(u). Thus, obtain ar(R, u, v).(ii) Follows (i) definition E(R).(iii) Let % = S1 . . . Sn . Since (u, v) E(%), u = u0 , . . . , un = v (ui1 , ui )E(Si ), = 1, . . . , n. hand, since S1 . . . Sn L(A), = p0 , . . . , pn =pi (pi1 , Si ). Ap0 .C a(u0 ). Api .C a(ui ), < n, (ii)pi+1 (pi , Si+1 ), (ui , ui+1 ) E(Si+1 ) give Api+1 .C a(ui+1 ). Aa .C a(v).(iv) Follows (iii) definition RI .qshow model R considering types constraints.Dis(S1 , S2 ): Si simple roles, SiI = E(Si ), so, (p15), S1I S2I = .833fiMosurovic, Krdzavac, Henson & ZakharyaschevS1 v S2 : Si simple roles SiI = E(Si ). Thus, (u, v) S1I (u, v) E(S1 )and, (p16), (u, v) E(S2 ); hence (u, v) S2I .S1 . . . Sn v R: S1 . . . Sn L(AR ). (u, v) (S1 . . . Sn )I u =u0 , . . . , un = v (ui1 , ui ) (Si )I , = 1, . . . , n. definition(Si )I , ui1 = ui0 , . . . , uini = ui (uij1 , uij ) E(Sji ), 1 j ni ,S1i S2i . . . Sni L(ASi ). Therefore, S11 . . . Sn11 S12 . . . Snnn L(AR ) (u, v) RI .RR v R, RS1 . . . Sn v R S1 . . . Sn R v R considered analogously.R v R: mentioned earlier, occurrence R treated R. follows(u, v) E(R) (v, u) E(R), (u, v) E(R) (v, u) E(R).addition, (u, v) RI (v, u) RI . Indeed, let (u, v) RI . Then,definition RI , exist u = u0 , u1 , . . . , un = v (ui , ui+1 ) E(Si+1 )S1 S2 . . . Sn L(AR ). (ui+1 , ui ) E(inv (Si+1 )) and, constructionAR , inv (Sn ) . . . inv (S1 ) L(AR ), (v, u) RI .Ri v Qi Pi1 . . . Pimi : Let (u, v) RiI . Then, (p19), Asi .C a(u),initial state Ai C = (r , a(u)) = inv (Pimi ). inv (Pi1 ).(Qi , a(u)|Qi , a(u)qc(C0 , R)|inv (Qi ) ). Proposition 20, Aai .C a(v), accepting state.Now, (p21), v0 , v1 , . . . , vmi = v (vj , vj1 ) E(inv (Pij )),a(u)|Qi a(v0 ) a(v0 )|inv (Qi ) a(u) qc(C0 , R)|inv (Qi ) a(u), is, (v0 , v)(Pi1 . . . Pimi )I ar(Qi , u, v0 ). Hence, (u, v0 ) QIi (u, v) (Qi Pi1 . . . Pimi )I .Ri v Ti1 Timi : Let (u, v) RiI . Then,(p19), Asi .C a(u),Wm(Tih , a(u)|Tih , a(u) qc(C0 , R)|inv (Tih ) ).initial state Ai C = (r , a(u)) = h=1Proposition 20, Ai .C a(v), accepting state. Now, (p22),j {1, . . . , mi } a(u)|Tij a(v) a(v)|inv (Tij ) a(u)qc(C0 , R)|inv (Tij )a(u), i.e., ar(Tij , u, v). Hence, (u, v) TijI (u, v) (Ti1 Timi )I .Ri = Qi Pi1 . . . Pimi : Let (u, v) RiI . exists role chain % L(ARi )(u, v) E(%). % L(Ai ) (u, v) (Qi Pi1 . . . Pimi )I , proofRi v Qi Pi1 . . . Pimi . suppose %/ L(Ai ) shortest possible. Since % vR0 Ri ,sequence % vr1 %1 vr2 vrn %n vrn+1 Ri , r j R0 , 1 j n + 1,least one r j Ri . r j 6 Ri , j < n + 1, find shorter %,r n+1 = (Qi Pi1 . . . Pimi v Ri ). Therefore, % = %00 %01 . . . %0mi %00 vR0 Qi%0j vR0 Pij , 1 j mi . Thus, (u, v) (Qi Pi1 . . . Pimi )I .Let (u, v) (Qi Pi1 . . . Pimi )I . exists v0 (u, v0 ) QIi(v0 , v) (Pi1 . . . Pimi )I . case (u, v0 ) E(Qi )\E(Qi ) constructionE(Qi ) (% L(Ai ))(z) (u, z) E(%). v = z (u, v) RiI .Otherwise proof Qi Pi1 . . . Pimi v Ri .Ri = Ti1 Timi : Similar previous case.prove satisfies C0 , showC c(u) implies u C , u C con(C0 ).834(14)fiA Decidable Extension SROIQ Complex Role Chains UnionsTogether (p1), imply u0 (C0 )I . prove (14) induction construction concepts. C concept name (14) follows definition.>, follows (p3), C1 u C2 , C1 C2 , R.C, qS.C, S.Self ,(p6), (p7), (p8), (p11) (p4). case C follows (p2) (p5) caseqS.C follows (p10) (p12). Consider (only interesting) case C R.D.Let R.D c(u) (u, v) RI . (p17) AsR .D a(u), initialstate. Therefore, Proposition 20, AaR .D a(v) accepting state.Now, (p18), c(v); IH, v DI , thus u (R.D)I .nom(C0 ), (p14), vo c(vo ), vo oI . u oIc(u), so, (p13), u = vo . Thus, oI singleton set.() Suppose = (I , ) model C0 R. define = (S, c, a, E) taking= ,E(R) = RI ,c(u) = {C con(C0 ) | u C } {>}define a(u) follows. First, define induction C auxiliary sets a0 (u, r),r RI (C)(F). Recalling r 0 C r i, 1 l, seta0 (u, r 0 ) = {AsR .C | initial state, R.C con(C0 ) u (R.C)I }{AqR .C qc | S1 S2 . . . Sn L(AqR ), u (S1 .S2 . Sn .C)IL(AqR ) u C }.Then, assuming a0 (u, r 0 ) defined every r 0 C ri , seta0 (u, r ) = {Aqi .C | v w (role(C0 , R)) (w, q) prefix L(Ai ),(v, u) (w)I , C = (r ,[a0 (v, r 0 ))},r 0 Cri(w)I = S1I . . . SnI , w = S1 . . . Sn ,prefix L(Ai ) = {(w, q) | q state Ai , w0 L(Aqi ) ww0 L(Ai )}.Note {Asi .C | initial state, C = (r , r0 Cri a0 (u, r 0 )} a0 (u, r ).Finally, setl[a(u) =a0 (u, r j ).j=0prove tableau C0 w.r.t. R. Properties (p1)(p16) follow immediately definitions c E, (p17)(p19) follow definitionsc(u) a(u). (p20), suppose (u, v) E(R), Ap .C a(u) q (p, R).Ap .C a0 (u, r ), i. > 0 = Ai and,definitiona0 (u, r ), u0 w (role(C0 , R)) C = (r , r0 Cri a0 (u0 , r 0 )),(w, p) prefix L(A) (u0 , u) (w)I . Let w0 = wR. (w0 , q) prefix L(A)(u0 , v) (w0 )I , Aq .C a0 (v, r ) a(v).Api .CAsi .Cu0wu835Aqi .CRvfiMosurovic, Krdzavac, Henson & Zakharyaschev= 0 (i.e., C concept C Ap .C a0 (u, r 0 )), suppose Aq .C/ a0 (v, r 0 ).0definition (v, r 0 ), two reasons (Horrocks et al., 2006):S2 . . . Sn L(Aq ) v/ (S2 . Sn .C)I . However, impliespRS2 . . . Sn L(A ) u/ (R.S2 . Sn .C)I , contrary Ap .C a0 (u).L(Aq ) v/ C . R L(Ap ) u/ (R.C)I ,contradiction.Therefore, Aq .C a0 (v, r 0 ), a(u)|R a(v).show (p21) (p22), suppose Aai .C a(u), accepting state.definition a(u),v w (role(C0 , R)) (w, a) prefix L(Ai ),(v, u) (w) C = (r , r0 Cri a0 (v, r 0 )) = (r , a(v)). Since accepting state,w L(Ai ), (v, u) (Ri )I .(p21)i.e., kwe C = inv (Pimi ). inv (Pi1 ).(tr , , ), tr = Qi ,= a(v)|Qi , = a(v) qc(C0 , R)|inv (Qi ) . also (v, u) (Qi Pi1 . . . Pimi )I ,v0 , v1 , . . . , vmi = u (vj1 , vj ) PijI (v, v0 ) QIi . Therefore,(p20), a(v0 ) a(v0 )|inv (tr ) .W rr(p22)i.e., > kwe C =h=1 (th , th , th ), th = Tih , th = a(v)|Tih ,th = a(v) qc(C0 , R)|inv (Tih ) 1 h mi . also (v, u) (Ti1 Timi )I ,j {1, . . . , mi } (v, u) TijI . Therefore, (p20), tj a(u)a(u)|inv (tr )j .jq(p23) considered way (p20).Appendix B. Tableau Algorithmtableau algorithm, SR+ OIQ concepts C0 RBoxes R, works completiongraphs similarly algorithms given Horrocks et al. (2006) Horrocks Sattler(2007). present it, require additional notation. assume given RAppendix RC,D,E,F = {r | = 1, . . . , l}. 1 l basic roleP , P = Qi k, P {Ti1 , . . . , Timi } > k, letqc (r , P ) = {Ap .C | exists q (p, P ), Ap .C[qc(r j )}r j Cr{Aq .C | q (p, inv (P )), Ap .C[qc(r j )}.r j Crset qc (r ) = qc (r , Qi ), k, qc (r ) =j=1 qc (r , Tij ), > k.set qc (r ) quasi-concepts guessed algorithm. Let qc(C0 , R)minimal set that:qc(C0 , R) {Ap .C | Ap .C li=1 qc (r )} qc(C0 , R),Ap .C qc(C0 , R) C qc(C0 , R),P.C qc(C0 , R) C qc(C0 , R),836fiA Decidable Extension SROIQ Complex Role Chains Unions(Wmj=1 Cj )qc(C0 , R) {C1 , . . . , Cm } qc(C0 , R).Unlike qc(C0 , R), set qc(C0 , R) contains sub-quasi-concepts. (Quasi-conceptsform Ap .C used make sure Ap .C belong label.)Given SR+ OIQ concept C0 RBox R, completion graph C0 Rstructure form G = (V1 , V2 , E1 , E2 , c, a, l, ),V1 V2 = ; elements V1 called root nodes, elements V2 calledinternal (or non-root) nodes;(V, E1 ) directed forest nodes V = V1 V2 arcs E1 (its rootsincoming arcs);E2 set arcs nodes root nodes, well arcs form (x, x),x V2 ;(x, y) E, E = E1 E2 , l(x, y) role(C0 , R); R0 l(x, y)R0 v R, called R-successor x; called R-neighbour xR-successor x x inv (R)-successor y; also, x called -neighbourx (cf. Horrocks et al., 2006);x V , c(x) con(C0 ) { mS.C | nS.C con(C0 ), < n}a(x) qc(C0 , R);symmetric binary relation V ;nom(C0 ), x V1 c(x).Following Horrocks et al. (2006) Horrocks Sattler (2007), distinguishtwo sets nodes: V1 arbitrarily interconnected (they called root nodes),V2 form tree structure (they called internal nodes). Intuitively,completion graph collection trees whose root nodes arbitrarily connectedmay also arcs internal nodes root nodes (see Fig. 2 page 841). alsodistinguish two sets arcs: E1 connect nodes tree,E2 remaining arcs graph.illustrate difference R-successors neighbours, suppose (R0 v R) Rxl(x, y) = {R0 }l(x, y) = {R0 }, picture above. R0 - R-successor x,x neither inv (R0 )- inv (R)-successor y; R0 - R-neighbourx, x inv (R0 )- inv (R)-neighbour y.ensure tableau algorithm eventually comes stop, use blockingtechnique similar one Horrocks et al. (2006). node x V2 calledblocked either directly indirectly blocked. node x V2 directly blocked none(not necessarily immediate) E1 -ancestors blocked, nodes x0 , 0that:0 root,837fiMosurovic, Krdzavac, Henson & Zakharyaschev(x0 , x) E1 , (y 0 , y) E1 E1 -ancestor x0 ,c(x) = c(y), c(x0 ) = c(y 0 ), a(x) = a(y), a(x0 ) = a(y 0 ) l(x0 , x) = l(y 0 , y).case say blocks x.root00 l(y , y)0x0 l(x , x) xnode indirectly blocked one E1 -ancestors blocked.simple role S, x V C con(C0 ), letG (x, C) ={y | S-neighbour x, C c(y)x V1 indirectly blocked}.say completion graph G contains clash x V least onefollowing conditions holds:c(x),{A, A} c(x), concept name A,{Ap .C, Ap .C} a(x), quasi-concept Ap .CSli=1 qc(r),x S-neighbour x S.Self c(x),Dis(R, S) R, R- S-neighbour x, V ,( nS.C) c(x), {y0 , . . . , yn } G (x, C) yi yj , 0 < j n,nom(C0 ), node x c(x) c(y),C = (tr , , ) a(x) a(x)|inv (tr ) 6 .completion graph contain clash called clash-free.simplify tableau rules, require terminology notation originally usedHorrocks et al. (2006) Horrocks Sattler (2007). R-neighbour xsaid safe either x V2 x V1 blocked. result (andprocedure) pruning node G = (V1 , V2 , E1 , E2 , c, a, l, ), denoted Prune(y),graph obtained G following way: remove every (y, z) E and, z V2 ,Prune(z); also remove V . result (and procedure) merging nodesx G = (V1 , V2 , E1 , E2 , c, a, l, ), denoted Merge(y, x), graph obtained Gfollows:1. z (z, y) E:{(x, z), (z, x)} E = , add (z, x) E (to E1 x V2 , otherwise E2 )set l(z, x) := l(z, y),(z, x) E, set l(z, x) := l(z, x) l(z, y),(x, z) E, set l(x, z) := l(x, z) {inv (R) | R l(z, y)},838fiA Decidable Extension SROIQ Complex Role Chains Unionsremove (z, y) E;2. root nodes z (y, z) E2 :{(x, z), (z, x)} E = , add (x, z) E2 set l(x, z) := l(y, z),(x, z) E, set l(x, z) := l(x, z) l(y, z),(z, x) E, set l(z, x) := l(z, x) {inv (R) | R l(y, z)},remove (y, z) E2 ;3. set c(x) := c(x) c(y) a(x) := a(x) a(y);4. add x z, z z;5. Prune(y).Let G = (V1 , V2 , E1 , E2 , c, a, l, ) completion graph. completion rules extendG two ways: adding new leaf adding new root. say node x V2 ,(y, x) E1 , level forest (V, E1 ) either = 1 V1 , > 1V2 level 1 (V, E1 ). node x V1 level graph (V1 , E2 (V1 V1 ))either = 0 exists nom(C0 ) c(x), > 0, x level(i 1) (V1 , E2 (V1 V1 )) V1 level 1 (V1 , E2 (V1 V1 ))(y, x) E2 .tableau rules applied according following strategy: (o)-rulehighest priority; apply (=r )- (r )-rules, starting root nodeslower levels; applications rules follow.tableau algorithm non-deterministic. takes SR+ OIQ concept C0RBox R input returns yes indicate whether C0 satisfiable w.r.t. R not.algorithm starts constructing completion graph G = (V1 , V2 , E1 , E2 , c, a, l, ),V1 = {xo | nom(C0 )} {xC0 },V2 = ,E1 = , E2 = ,c(xo ) = {o}, c(xC0 ) = {C0 },a(xo ) = , a(xC0 ) = ,l = ,empty.algorithm non-deterministically applies one completion rules given Tables 1 2; keeps till either current completion graph contains clash,case answer no, none rules applicable, case algorithmreturns yes.prove algorithm always comes stop returns correct answer,require following lemma:839fiMosurovic, Krdzavac, Henson & ZakharyaschevLemma 21 Let G = (V1 , V2 , E1 , E2 , c, a, l, ) structure constructed stepalgorithm. Then, every x V2 , exists exactly one V (y, x) E1 .Proof. proof induction number steps. basis induction (V2 = )trivial. suppose claim holds step consider happensapplication completion rule. applying rules (), (r8) () node x,add one nodes V2 , x predecessor nodes. Also,consider rules (), (o) (=r ), merge nodes, ruleschange V2 E1 . Merging nodes changes graph possibly adding new edges,deleting edges pruning nodes. Observe prune nodeclaim still holds delete successors belong V2 . Deleting edgespoil claim either. Thus, enough examine cases new edgeadded E1 . Merge(y, x) x V1 newly added edges belong E2 ,applying Merge(y, x) claim still holds. interesting case applyMerge(z, y) rule () ( nS.C) c(x), y, z G (x, C) y, z V2 .y, z V2 , nodes z one parent node, although z ancestory; following fours cases possible.Case 1: (y, x) E1 (x, z) E1 . new edge added E1 , claimholds.Case 2: (x, y) E1 (x, z) E1 . Again, add new edge E1 .Case 3: (y, x) E1 (z, x) E1 . case x V2 x two parent nodesz, impossible IH.Case 4: (y, x) E2 (z, x) E2 . case possible either x V1 ,( nS.C) c(x), (or z) S-neighbour x, applying ()apply (r ) (=r ) view higher priority.qshow termination.Lemma 22 tableau algorithm always terminates.Proof. sets con(C0 ), qc(C0 , R), role(C0 , R) use labels nodes edgesfinite. Let l0 = ]nom(C0 ), l1 = ]con(C0 ), l2 = ]qc(C0 , R), l3 = ]role(C0 , R)nmax = max{n | ( nR.C) con(C0 ) ( nR.C) con(C0 )}. completion graphcompletion rules following properties. node x labelled two setsc(x) con(C0 ) a(x) qc(C0 , R). number different pairs labelsexceed 2l1 +l2 . edge (x, y) labelled set l(x, y) role(C0 , R), numberdifferent labels edges 2l3 . number different labels pair nodesconnected arc L = 2l3 +2l1 +2l2 . Therefore, path forest (V, E1 ),starts root node length L + 2, contains blocked node. Everyapplication rule determined (quasi-) concept node, ruleapplicable (quasi-) concept node once. completion rules neverremove labels nodes graph, rules remove nodes (), (o)(=r ). (), (), (r ) (r8) generate new nodes, generationtriggered (quasi-) concept form R.C, nR.C, nR.C P.C labelnode x. number concepts l1 + l2 . rules () (r ) generatenmax successors given node, concept form nR.C nR.C.840fiA Decidable Extension SROIQ Complex Role Chains Unionstwo rules generate one successor concept. follows numbercreated outgoing arcs node exceed l1 nmax + l2 . node removedG (), (o) (=r ), label migrates node z. rules (), (), (r )(r8), generate later merged (), (o) (=r ), appliednode.Now, show number nodes completion graph limited. Togetherobservations above, mean apply completion rules finitelymany times, algorithm eventually come stop.end, require following claim: x V1 level (V1 , E2 (V1 V1 )),V2 indirectly blocked (y, x) E2 , level L + 2 (V, E1 ).Indeed, = 0, level L + 2 indirectly blocked node> L + 2 level indirectly blocked. x level > 0 way add edge(y, x) E2 first apply rule (o), add E2 -edge y0 V2x0 V1 , repeatedly apply (=r ). node x0 level 0 (V1 , E2 (V1 V1 )),y0 level L + 2 (V, E1 ). apply rule (=r ), y0 mergedsuccessor x1 V1 x0 created application (r ). node x1 level1, add edge (y1 , x1 ) E2 , y1 parent y0 level L + 2 1(V, E1 ); see Fig. 2. repeating argument, see node levelL + 2 (V, E1 ).x0x0x1y1y1x1y0Figure 2: application (=r ); bold arcs E2 nodesV1 .claim proved means node x V1 level L+2 (V1 , E2 (V1 V1 )),V2 (y, x) E2 . Hence, rule (r ) cannot applied nodex level L + 2, root node level L + 3.rule add new nodes V1 (r ). applied l1 timesgiven node add l1 nmax successors. beginning V1 \{xC0 } containsl0 nodes, (r ) create l0 l1 nmax successors nodes. applying(r ) again, obtain l0 (l1 nmax )2 new nodes (of level 2). follows]V1 1 +L+2Xl0 (l1 nmax )i = O(l0 (l1 nmax )L+3 ).i=0number nodes V2 also limited. beginning V2 = . node V1 ,algorithm create l1 nmax + l2 arcs lead nodes V2 . Thus, number841fiMosurovic, Krdzavac, Henson & Zakharyaschevnodes level 1 V2 exceed ]V1 (l1 nmax + l2 ); number successors]V1 (l1 nmax + l2 )2 ; finally,]V2L+2X]V1 (l1 nmax + l2 )i = O(]V1 (l1 nmax + l2 )L+3 ).i=1qcompletes proof lemma.next lemma shows answers returned algorithm correct.Lemma 23 tableau algorithm returns yes exists tableau C0w.r.t. R.Proof. () Suppose algorithm returns yes generating clash-free completion graphG = (V1 , V2 , E1 , E2 , c, a, l, ) completion rule applicable. Let V = V1 V2E = E1 E2 . write (x) = x, x V1 x V2 blocked; (x) = y,x V2 blocks x.Define set paths(G) inductively taking (cf. Horrocks et al., 2006):x0 V1 (x0 , x0 ) paths(G); case write Root(x0 ) = (x0 , x0 ),paths(G), node z V2 indirectly blocked (tail (), z) E1 ,sequence , ((z), z) paths(G).tail () = xn tail 0 () = x0n , = (x0 , x00 ), . . . , (xn , x0n ). memberspaths(G) called paths G.define tableau = (S, c0 , a0 , E) taking = paths(G), c0 () = c(tail ()),a0 () = a(tail ()) qc(C0 , R), paths(G),E(R) ={(Root(x), Root(y)) | R-neighbour x}{(u, Root(y)) | R-neighbour tail (u)}{(Root(x), u) | tail (u) R-neighbour x}{(u, u) | tail (u) R-neighbour tail (u)}{(u, v) | v = u, ((y), y) R-neighbour tail (u),u = v, ((y), y) inv (R)-neighbour tail (v)}.prove tableau C0 w.r.t. R. Indeed, (p1) (p14) followinitial step tableau algorithm fact labels root nodes neverremoved; (p2) follows definition fact completion graph G clashfree; (p3) follows rules creating new nodes G clash-free; (p9) (p16)follow definitions E(R) R-neighbour (and R-successor); (p6) (p7) followfact rules (u) (t) applicable; (p12) follows definitionsE(R) R-neighbour fact rule (guess) applicable; (p15) (p5)follow definitions E(R) R-neighbour completion graph Gclash-free; (p17) (p18) follow fact (r1) (r3) applicable; (p19)fact (r5i ) cannot applied; (p20) (p23) follow definitionsE(R) fact (r2) (r6) applicable. remaining cases lessstraightforward. them, require following:842fiA Decidable Extension SROIQ Complex Role Chains Unions(u)C1 u C2 c(x), x indirectly blocked {C1 , C2 } 6 c(x),c(x) := c(x) {C1 , C2 }(t)C1 C2 c(x), x indirectly blocked {C1 , C2 } c(x) = ,c(x) := c(x) {D}, {C1 , C2 }()S.C c(x), x blocked safe S-neighbour C c(y)create new node V2 l(x, y) := {S}, c(y) := {C, >}, a(y) :=(self)S.Self c(x), x blocked x S-neighbour xadd (x, x) E2 , yet, set l(x, x) := l(x, x) {S}(guess)( nS.C) c(x), x indirectly blockedS-neighbour x {C, C} c(y) = ,set c(y) := c(y) {D}, {C, C}()( nS.C) c(x), x blocked distinct safey1 , . . . , yn G (x, C), create n new successors y1 , . . . , yn V2 x; setl(x, yi ) := {S}, c(yi ) := {C, >}, a(yi ) := , yi yj , 1 < j n()( nS.C) c(x), x indirectly blocked, ]S G (x, C) > ny, z G (x, C) z hold(1) z root node E1 -ancestor y, Merge(y, z),(2) otherwise Merge(z, y)(o)if, o, o0 nom(C0 ), node 6= xo o0 c(xo ) c(y)xo hold completion graph,Merge(y, xo )(r )( nS.C) c(x), x V1 , S-neighbour xV2 , (y, x) E2 , C c(y) indirectly blocked;n0 n ( n0 S.C) c(x) S-neighboursz1 , . . . , zn0 V1 x C c(zi ) zi zj , 1 i, j n0 , 6= j,(1) guess m, 1 n, set c(x) := c(x) {( mS.C)},(2) create new nodes y1 , . . . , ym V1l(x, yi ) := {S}, c(yi ) := {C, >}, a(yi ) := yi yj , 1 < j(=r )( mS.C) c(x), x V1 , S-neighbour V2 xC c(y), indirectly blocked S-neighboursz1 , . . . , zm V1 x C c(zi ) zi zj , 1 i, j m, 6= j,j0 , 1 j0 zj0 hold,Merge(y, zj0 )Table 1: Completion rules SR+ OIQ tableau algorithm.843fiMosurovic, Krdzavac, Henson & Zakharyaschev(r1)R.C c(x), x indirectly blocked AsR .C 6 a(x), initial state,a(x) := a(x) {AsR .C}(r2)ApR .C a(x), q AR (p, ) (where ), x indirectly blocked,-neighbour x AqR .C 6 a(y),a(y) := a(y) {AqR .C}(r3)AaR .C a(x), accepting state, x indirectly blocked C/ c(x),c(x) := c(x) {C}(r4i )x indirectly blocked C qc (r ) {C, C} a(x) = ,a(x) := a(x) {D}, {C, C}(r5i )x indirectly blocked, (r4i ) applicable, Asi .C 6 a(x),C = (r , a(x)), initial state s, a(x) := a(x) {Asi .C}(r6)Ap .C a(x), x indirectly blocked, q (p, ) (where ),-neighbour x Aq .C 6 a(y),a(y) := a(y) {Aq .C}(r7)Aa .C a(x), accepting state, x indirectly blocked C/ a(x),a(x) := a(x) {C}(r8)P.C a(x), x blocked x safe P -neighbour C a(y),create new node V2 set l(x, y) := {P }, c(y) := {>}, a(y) := {C}WC a(x), C =j=1 Cj , x indirectly blocked, {C1 , . . . , Cm } a(x) = ,a(x) := a(x) {D}, {C1 , . . . , Cm }(r9)(r10)C a(x), C = (tr , , ), x indirectly blocked 6 a(x),set a(x) := a(x)Table 2: Completion rules SR+ OIQ tableau algorithm (cont.)844fiA Decidable Extension SROIQ Complex Role Chains UnionsProposition 24 Suppose u paths(G), x = tail (u) x safe R-neighbour V .v paths(G) (u, v) E(R), c0 (v) = c(y) a0 (v) = a(y) qc(C0 , R).Proof. R-neighbour x, either (x, y) E (y, x) E. Four cases possible:(x, y) E1 , set v = u, ((y), y).(x, y) E2 , V1 set v = Root(y).(y, x) E1 predecessor x. case tail 0 (u) = x,exists path v tail (v) = u = v, (x, x); case tail 0 (u) 6= x(i.e., x blocks tail 0 (u)), exist predecessor 0 tail 0 (u) (c(y 0 ) = c(y),a(y 0 ) = a(y) 0 R-neighbour tail 0 (u)) path v tail (v) = 0u = v, (x, tail 0 (u)).(y, x) E2 x V1 , u = Root(x). set v = Root(y) V1 . V2blocked (since safe), exists path v tail (v) = y.qcases, v required.(p4) S.Self c0 (u) S.Self c(tail (u)). Since (self) applicable, tail (u)S-neighbour tail (u), (u, u) E(R).(p8) R.C c0 (u) R.C c(x), x = tail (u). Since () applicable, xsafe R-neighbour C c(y). Proposition 24, exists v paths(G)(u, v) E(R) C c0 (v).(p10) nS.C c0 (u) nS.C c(x), x = tail (u). Since completiongraph G clash-free () (=r ) applicable, ]S G (x, C) n. Suppose(u, v) E(R) C c0 (v). definition E(R), following cases possible:u = Root(x), v = Root(y) R-neighbour x. G (x, C) and,since V1 , v 0 paths(G) different v = tail (v 0 )= tail 0 (v 0 ).x V2 , v = Root(y) R-neighbour x. case considered analogously.u = Root(x), = tail (v) V2 , v 6= u, (y, tail 0 (v)) R-neighbour x.case possible since nS.C c(x), x V1 , (y, x) E2 rules (r )(=r ) applicable.v = u x R-neighbour x. x G (x, C) v 0 paths(G)different u (u, v 0 ) E(R) x = tail (v 0 ) x = tail 0 (v 0 ).v = u, ((y), y) R-neighbour x. G (x, C), V2 xpredecessor y. v 0 paths(G) different v(u, v 0 ) E(R) = tail (v 0 ) = tail 0 (v 0 ).u = v, (x, y), x = (y) inv (R)-neighbour tail (v). tail (v)G (x, C), V2 tail (v) one predecessor y; v 0 paths(G)different v (u, v 0 ) E(R) tail (v) = tail (v 0 ) tail (v) = tail 0 (v 0 ).845fiMosurovic, Krdzavac, Henson & ZakharyaschevTherefore, ]{v | (u, v) E(S) C c(v)} ]S G (x, C) n.(p11) ( nS.C) c0 (u) ( nS.C) c(x), x = tail (u). Since ()applicable, x safe S-neighbours y1 , . . . , yn C c(yi ) yi yj , 1 i, j nj 6= i. Proposition 24, exists vi paths(G) (u, vi ) E(S)C c0 (vi ), 1 n. addition, one (y, x) E1 and,proof Proposition 24, (yi , x) 6 E1 tail (vi ) = yi tail 0 (vi ) = yi . So, vi vjdistinct 6= j, since tail (vi ) 6= tail (vj ) tail 0 (vi ) 6= tail 0 (vj ) (in case (yi , x) E1 ,(x, yj ) E1 yi block yj , i.e., tail (vi ) = tail (vj ) = yi , tail 0 (vi ) 6= tail 0 (vj )).(p13) c0 (u) c0 (v) c(tail (u)), o0 nom(C0 )xo0 = tail (u) u = Root(xo0 ). Similarly, o00 nom(C0 ) xo00 = tail (v)v = Root(xo00 ). Since rule (o) applicable, xo0 = xo00 , soWu = v.r(p22) Let Aai .C a0 (u), accepting state C =h=1 (th , th , th ).Aai .C a(x), x = tail (u). Since (r7) cannot applied, C a(x), since (r9)applicable, j Cj = (trj , tj ,j ) a(x). Now, (r10) applicable,0tj a(x); since G clash-free, a(x)|inv (tr )j . Thus, tj (u)ja0 (u)|inv (tr )j .j(p21) Let Aai .C a0 (u), C = inv (Pimi ). inv (Pi1 ).(tr , , )accepting state. Aai .C a(tail (u)). prove induction j vjinv (Pij ). inv (Pi1 ).(tr , , ) a(tail (vj )). j = mi , set vmi = u. (r7)applicable tail (vmi ), inv (Pimi ). inv (Pi1 ).(tr , , ) a(tail (vmi )), establishesinduction basis. Assume claim holds j prove j 1. tail (vj )blocked (r8) applicable, safe inv (Pij )-neighbour yj1 tail (vj )inv (Pi(j1) ). inv (Pi1 ).(tr , , ) a(yj1 ). Proposition 24,vj1 paths(G) (vj , vj1 ) E(inv (Pij )) inv (Pi(j1) ). inv (Pi1 ).(tr , , )a(tail (vj1 )). j = 0, (tr , , ) a(tail (v0 )). Further, (r10) cannotapplied, a(tail (v0 )); since G clash-free, a(tail (v0 ))|inv (tr ) . Thus,a0 (v0 ) a0 (v0 )|inv (tr ) .() Take tableau = (S, c0 , a0 , E) C0 w.r.t. R extend following way:(e1) Aai .C a0 (u), C = inv (Pimi ). inv (Pi1 ).(tr , , ) acceptingstate, then, (p21), v0 , v1 , . . . , vmi = u (vj , vj1 ) E(inv (Pij )),1 j mi , a0 (v0 ) a0 (v0 )|inv (tr ) . case, extend a0 (vj )taking a0 (vj ) := a0 (vj ) {inv (Pij ). inv (Pi1 ).(tr , , )}, 0 j mi .W r(e2) Aai .C a0 (u), C =h=1 (th , th , th ), then, (p22), j {1, . . . , mi }0tj a0 (u) a0 (u)|inv (tr )j . case, extend (u) takingja0 (u) := a0 (u) {C, Cj }.(e3) exists C li=0 qc (r ) C 6 a0 (u), a0 (u) := a0 (u) {C}.(e4) ( nS.C) c0 (u) (u, C) = {v | (u, v) E(S), C c(v)} = {v1 , . . . , vm }then, view (p10), n. case, extend c0 (u) takingc0 (u) := c0 (u) { mS.C}.apply completion rules using extended tableau endalgorithm obtains clash-free completion graph G = (V1 , V2 , E1 , E2 , c, a, l, ) returns846fiA Decidable Extension SROIQ Complex Role Chains Unionsyes. purpose, define map : V steer applications nondeterministic completion rules way c(x) c0 ((x)) a(x) a0 ((x)),nodes x V (cf. Horrocks, Kutz, & Sattler, 2005; Horrocks et al., 2006). Furthermore,require that, pair nodes x, role R, R-successor x,((x), (y)) E(R), x implies (x) 6= (y). ensure G clash-free,since tableau clash-free.define induction follows. begin with, (p14), nom(C0 ),vo c0 (vo ), (p1), u0 C0 c0 (u0 ).algorithm starts constructing nodes xo , nom(C0 ), xC0 c(xo ) = {o}c(xC0 ) = {C0 }. set (xo ) = vo (xC0 ) = u0 .Observe c(xo ) c0 ((xo )) c(xC0 ) c0 ((xC0 )); also a(xo ) = a0 ((xo ))a(xC0 ) = a0 ((xC0 )). consider applications completion rules.(u) applied x V C1 u C2 c(x), C1 u C2 c0 ((x)), so,(p6), C1 , C2 c0 ((x)). apply (u), C1 , C2 added c(x),c(x) c0 ((x)).(t) applied x V C1 C2 c(x), C1 C2 c0 ((x)), so,(p7), {C1 , C2 } c0 ((x)) 6= . apply (t) c(x) := c(x) {D}{C1 , C2 } c0 ((x)), c(x) c0 ((x)).() applied x V S.C c(x), S.C c0 ((x)), so, (p8),v ((x), v) E(S) C c0 (v). (p3), > c0 (v) and, (p16)v 0 , ((x), v) E(S 0 ). apply () new node createdl(x, y) := {S}, c(y) := {C, >} , a(y) := (y) = v. c(y) c0 ((y)),a(y) a0 ((y)) ((x), (y)) E(S 0 ).(self) applied x V S.Self c(x), S.Self c0 ((x)), so,(p4), ((x), (x)) E(S). (p16) v 0 , ((x), (x)) E(S 0 ).apply (self) adding arc (x, x), yet, setting l(x, x) :=l(x, x) {S}. obtain ((x), (x)) E(S 0 ).(guess) applied x V ( nS.C) c(x) S-neighbour x,( nS.C) c0 ((x)), ((x), (y)) E(S), so, (p12), {C, C} c0 ((y)) 6= .apply (guess) c(y) := c(y) {D}, {C, C} c0 ((y). Hencec(y) c0 ((y)).() applied x V ( nS.C) c(x), ( nS.C) c0 ((x)). (p11),v1 , . . . , vn ((x), C), (u, C) = {v | (u, v) E(S), Cc(v)}. apply () creating n new successors y1 , . . . , yn x setting l(x, yi ) :={S}, c(yi ) := {C, >}, a(yi ) := , yi yj (yi ) = vi , 1 i, j n, j 6= i. Then,v 0 , ((x), (yi )) E(S 0 ) also c(yi ) c0 ((yi )), 1 n.() applied x V ( nS.C) c(x) {y1 , . . . , yn+1 } G (x, C),( nS.C) c0 ((x)) {(y1 ), . . . , (yn+1 )} ((x), C). (p10),]S ((x), C) n, j1 , j2 (yj1 ) = (yj2 ) = v. Instead yj1 ,yj2 , write y, z; precisely yj1 root E1 -ancestor yj2847fiMosurovic, Krdzavac, Henson & Zakharyaschevset z = yj1 = yj2 , otherwise set z = yj2 = yj1 . apply ()performing Merge(y, z). Since (z) = v, required conditions hold.(=r ), proof similar previous case.(o) applied V o0 c(xo ) c(y), o, o0 nom(C0 ),o0 c0 ((xo )) c0 ((y)). (p13), (xo ) = (y), therefore c(xo ) c(y)c0 ((xo )) c0 ((y)) = c0 ((xo )). Similarly, a(xo ) a(y) a0 ((xo )). apply (o)performing Merge(y, xo ), required conditions hold again.(r ) applied x V1 S-neighbour x ( nS.C) c(x),V2 , (y, x) E2 C c(y), ( nS.C) c0 ((x)), ((x), (y)) E(S)C c0 ((y)). (p10), ]S ((x), C) n, ((x), C) = {v1 , . . . , vm },n. apply (r ) c(x) := c(x) {( mS.C)}, create new nodesy1 , . . . , ym V1 l(x, yi ) := {S}, c(yi ) := {C, >}, a(yi ) := , yi yj (yi ) = vi1 m, 1 j < i. Then, v 0 , ((x), (yi )) E(S 0 ),c(yi ) c0 ((yi )), 1 m, also, (e4), c(x) c0 ((x)).(r1) applied x V R.C c(x), R.C c0 ((x)), so,(p17), AsR .C a0 ((x)), initial state AR . apply (r1)a(x) := a(x) {AsR .C}. Clearly, a(x) a0 ((x)).(r2) applied x V ApR .C a(x), q AR (p, ), -neighbourx, ApR .C a0 ((x)). 6= ((x), (y)) E(T ) and, (p20),AqR .C a0 ((y)). = = x and, (p23), AqR .C a0 ((y)).cases apply (r2) a(y) := a(y) {AqR .C}, a(y) a0 ((y)).(r3) applied x V AaR .C a(x), accepting state,AaR .C a0 ((x)). (p18), C c0 ((x)). apply (r3) c(x) := c(x) {C}.Thus, c(x) c0 ((x)).(r4i ) applied x V C qc (r ), then, (e3), {C, C} a0 ((x)) 6= .apply (r4i ) a(x) := a(x) {D}, {C, C} a0 ((x)). Thus,a(x) a0 ((x)).(r5i ) applied x V , Asi .C 6 a(x), initial state AiC = (r , a(x)). (p19), Asi .C0 a0 ((x)), C0 = (r , a0 ((x))). SupposeC 6= C0 . Since a(x) a0 ((x)), exists C1 qc (r ) C1 a0 ((x))C1 6 a(x). (r4i ) applicable, C1 a(x), C1 a0 ((x)),contradiction. Hence C = C0 . apply (r5i ) a(x) := a(x){Asi .C}.Thus, a(x) a0 ((x)).(r6) applied x V Ap .C a(x), q AR (p, ), -neighbourx, Ap .C a0 ((x)). 6= ((x), (y)) E(T ) and, (p20),Aq .C a0 ((y)). = = x and, (p23), Aq .C a0 ((y)). either case,apply (r6) a(y) := a(y) {Aq .C}. Thus, a(y) a0 ((y)).(r7) applied x V Aa .C a(x), accepting state,Aa .C a0 ((x)). (e1) (e2), C a0 ((x)). apply (r7) waya(x) := a(x) {C}. Thus, a(x) a0 ((x)).848fiA Decidable Extension SROIQ Complex Role Chains Unions(r8) applied x V P.C a(x), P.C a0 ((x)), so, (e1),v ((x), v) E(P ) C a0 (v). (p16) P v 0 ,((x), v) E(S 0 ). apply (r8) creating new node l(x, y) := {P },c(y) := {>}, a(y) := {C} (y) = v. Thus, c(y) c0 ((y)), a(y) a0 ((y))((x), (y)) E(S 0 ).W0(r9) applied x V C a(x), C =j=1 Cj , C ((x)).0means C added ((x)) (e2), so, j Cj a0 ((x)).apply (r9) a(x) := a(x) {Cj }. Thus, a(x) a0 ((x)).(r10) applied x V C a(x), C = (tr , , ), C a0 ((x)).means C added a0 ((x)) (e1) (x) = v0 , (e2). either case,a0 ((x)). apply (r10) a(x) := a(x) . Thus, a(x) a0 ((x)).qcompletes proof lemma.immediate consequence Lemmas 19, 22 23, obtain main Theorem 15according concept satisfiability w.r.t. SR+ OIQ KBs decidable. worthnoting given RBox R contain RAs form (C)(F) tableaualgorithm behaves way algorithm SROIQ (Horrocks et al., 2006).However, R contains one RA form (C)(F) algorithm constructset qc(C0 , R) quasi-concepts, contains subsets previously constructedsets quasi-concepts qc(r 0 ), may suffer exponential blow-up. precisely,new quasi-concepts qc(C0 , R) built triples form (tr , , ),qc(r 0 )|tr qc(r 0 )|inv (tr ) . Furthermore, algorithm may suffer oneexponential blow-up every time add extra RA form (C)(F) extendsequence r i1 C r i2 , r i2 C r i3 , . . . , r ih1 C r ih set quasi-concepts maybecome exponentially larger.ReferencesBaader, F. (2003). Restricted role-value-maps description logic existential restrictions terminological cycles. Proccedings 2003 International WorkshopDescription Logics (DL2003).Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.).(2003). Description Logic Handbook: Theory, Implementation Applications.CUP. (2nd edition, 2007).Baldoni, M. (1998). Normal Multimodal Logics: Automatic Deduction Logic Programming Extension. Ph.D. thesis, Universita degli Studi di Torino.Bock, C., Zha, X., Suh, H., & Lee, J. (2010). Ontological product modeling collaborativedesign. Advanced Engineering Informatics, 24, 510524.Bock, C. (2004). UML 2 Composition Model. Journal Object Technology, 3 (10), 4774.Brachman, R. J., & Schmolze, J. G. (1985). overview KL-ONE knowledge representation system. Cognitive Science, 9 (2), 171216.849fiMosurovic, Krdzavac, Henson & ZakharyaschevCuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., & Sattler, U.(2008). OWL 2: next step OWL. Journal Web Semantics, 6 (4), 309322.del Cerro, L. F., & Penttonen, M. (1988). Grammar logics. Logique et Analyse, 121, 123134.Demri, S. (2001). complexity regularity grammar logics related modal logics.Journal Logic Computation, 11 (6), 933960.Halpern, J., & Moses, Y. (1992). guide completeness complexity modal logicsknowledge belief. Artificial Intelligence, 54 (2), 319379.Horrocks, I., Kutz, O., & Sattler, U. (2005). irresistible SRIQ. Proc. FirstOWL Experiences Directions Workshop.Horrocks, I., Kutz, O., & Sattler, U. (2006). even irresistible SROIQ. Proceedings Tenth International Conference Principles Knowledge RepresentationReasoning (KR 2006), pp. 5767.Horrocks, I., & Sattler, U. (2004). Decidability SHIQ complex role inclusion axioms.Artificial Intelligence, 160 (1-2), 79104.Horrocks, I., & Sattler, U. (2007). tableau decision procedure SHOIQ. JournalAutomated Reasoning, 39 (3), 249276.Kazakov, Y. (2010). extension complex role inclusion axioms description logicSROIQ. Proceedings IJCAR, pp. 472486.Krdzavac, N., & Bock, C. (2008). Reasoning manufacturing part-part examplesOWL2. Tech. rep., U.S. National Institute Standards Technology, Gaithersburg,United States America.Motik, B., Cuenca Grau, B., Horrocks, I., & Sattler, U. (2009). Representing ontologiesusing description logics, description graphs, rules. Artificial Intelligence, 173 (14),12751309.Motik, B., Shearer, R., & Horrocks, I. (2009). Hypertableau reasoning description logics.Journal Artificial Intelligence Research (JAIR), 36 (1), 165228.Rector, A. (2002). Analysis propagation along transitive roles: formalisationGALEN experience medical ontologies. Proceedings International Workshop Description Logics 2002 (DL2002).Schmidt-Schau, M. (1989). Subsumption KL-ONE undecidable. Proccedings1st Int. Conf. Principles Knowledge Representation Reasoning (KR89),pp. 421431.Simanck, F. (2012). Elimination complex RIAs without automata. ProceedingsInternational Workshop Description Logics 2012 (DL2012).Tseitin, G. (1956). Associative calculi undecidable equivalence problems. Dokl. Akad.Nauk SSSR, 107 (3), 370371. (In Russian).Wessel, M. (2001). Obstacles way qualitative spatial reasoning descriptionlogics: undecidability results. Proceedings International WorkshopDescription Logics (DL2001).850fiA Decidable Extension SROIQ Complex Role Chains UnionsWessel, M. (2002). spatial reasoning description logics. ProceedingsInternational Workshop Description Logics 2002 (DL2002).851fiJournal Artificial Intelligence Research 47 (2013) 697740Submitted 05/13; published 08/13Heuristic Search Time MattersEthan BurnsWheeler Rumleaburns cs.unh.eduruml cs.unh.eduDepartment Computer ScienceUniversity New HampshireDurham, NH 03824 USAMinh B.minh.b.do nasa.govPlanning Scheduling GroupSGT Inc.NASA Ames Research CenterMoffett Field, CA 94035 USAAbstractmany applications shortest-path algorithms, impractical find provablyoptimal solution; one hope achieve appropriate balance searchtime solution cost respects users preferences. Preferences come manyforms; consider utility functions linearly trade-off search time solution cost.Many natural utility functions expressed form. example, solutioncost represents makespan plan, equally weighting search time plan makespanminimizes time arrival goal achieved. Current state-of-theart approaches optimizing utility functions rely anytime algorithms, useextensive training data compute termination policy. propose directapproach, called Bugsy, incorporates utility function directly search,obviating need separate termination policy. describe new method basedoff-line parameter tuning novel benchmark domain planning time pressurebased platform-style video games. present believe firstempirical study applying anytime monitoring heuristic search, compareproposals. results suggest parameter tuning technique givebest performance representative set training instances available. not, Bugsyalgorithm choice, performs well require off-line training.work extends tradition research metareasoning search illustratingbenefits embedding lightweight reasoning time search algorithm itself.1. IntroductionMany problems artificial intelligence formulated shortest path problems,solved using heuristic search algorithms A* (Hart, Nilsson, & Raphael,1968). Unfortunately, state spaces often grow exponentially problem size,usually infeasible find optimal solutions shortest path problems practical interest.Instead, practitioners tend settle suboptimal solutions, often foundefficiently expensive execute. One left choice spendinglong time searching cheap solution, little time searching expensive one.argue new approach strictly concerned optimizing solution cost,optimizing utility function given terms solution cost search time.c2013AI Access Foundation. rights reserved.fiBurns, Ruml, &utility function, user specify preference search time solutioncost, algorithm handles rest.consider utility functions given linear combination search time solutioncost. important form utility function two reasons. First, easily eliciteduser already explicitly application domain. example, costgiven monetary terms, usually possible ask much time one willing spenddecrease solution cost certain amount. Second, solution cost given termstime (i.e., cost represents time required agent execute solution),form utility function used optimize call goal achievement time;weighting search time execution time equally, utility-aware search attemptminimize sum two, thus attempting behave agent achievegoal quickly possible.existing techniques problem based anytime algorithms (Dean &Boddy, 1988), general class algorithms emit stream solutions decreasingcost converging optimal one. sufficient knowledge performanceprofile anytime algorithm, represents probability decreasesolution cost certain amount given current solution cost additional search time,possible create stopping policy aware users preference tradingsolving time solution cost (Hansen & Zilberstein, 2001; Finkelstein & Markovitch, 2001).two disadvantages using anytime algorithms trade-off solving timesolution cost. first profile anytime algorithm must learned off-linerepresentative set training instances. many settings, domain-independentplanning, problem set unknown, one cannot easily assemble representative training set. Also, often obvious parameters problem affect performancedifficult tell problem set representative. Even instance generatoravailable, instances generates may represent seen real world.second issue that, stopping policy aware users preference timecost, underlying anytime algorithm oblivious emit streamsolutions regardless desired trade-off. policy must simply bestsolutions found, algorithm may waste lot time finding manysolutions simply discarded. search algorithm fully awarepossible candidate solutions available relative estimated merits.paper presents four main contributions. First, combine anytime heuristic searchdynamic programming-based monitoring technique Hansen Zilberstein(2001). best knowledge, first apply anytime monitoringanytime heuristic search. Second, present simple portfolio-based methodestimates good parameter use bounded-suboptimal search algorithm optimizegiven utility function. Third, present Bugsy, best-first search algorithmrely off-line training, yet accounts users preference search timesolution cost.1 One important difference Bugsy previous proposalstrading-off deliberation time solution cost Bugsy considers trade-off directly search algorithm, whereas previous techniques, based anytimealgorithms, consider trade-off externally actual search algorithm. Finally,1. previous version Bugsy proposed Ruml (2007), see Appendix discussionimprovements incorporated version presented here.698fiHeuristic Search Time Matterspresent results set experiments comparing portfolio-based method, anytime monitoring, Bugsy, along utility-oblivious algorithms A* greedybest-first search, real-time search algorithms, decision-theoretic A* (DTA*, Russell &EricWefald, 1991), previously proposed utility-aware search. muchwork discussing trade-off deliberation solution cost, bestknowledge first implement thoroughly evaluate many ideascontext heuristic search.results experiments reveal two surprises. First, representative settraining instances available, effective approach simple techniqueselecting bound use bounded-suboptimal search. Surprisingly, convincinglydominates anytime algorithms monitoring tests. Second, neither Bugsyanytime search monitoring dominates other. Bugsy require off-linetraining, yet surprisingly, Bugsy perform well methods use training data.representative problem set available, Bugsy algorithm choice.work extends tradition research metareasoning planning illustratingbenefits embedding lightweight reasoning time search algorithm itself.2. Backgroundsection briefly describe heuristic search, present terminology usedremainder paper, discuss type utility functions addressing.2.1 Heuristic Searchconsidered paper, heuristic search technique finding shortest pathnodes weighted graph; many problems specified form. Sincetypical graphs much large represent explicitly, algorithms usuallygenerate graph lazily using function called expand. expand function returnssuccessors node graph. call process evaluating expand functionnode expanding node, expanding node say generatingsuccessors.A* (Hart et al., 1968) probably best-known heuristic search algorithm. maintains two sets nodes: open list contains frontier nodes generatedyet expanded, closed list contains nodes already expanded(a common optimization closed list also include nodes alreadyopen list too), therefore represent duplicate states encountered again. open listsorted f (n) = g(n) + h(n), g(n) cost path initial nodenode n, h(n) heuristic estimate cheapest path cost n goal nodereachable n. algorithm proceeds removing node minimum f valueopen list, expanding it, putting children open list, putting nodeclosed list. A* removes goal node open list, stops searchingreturns path goal solution. Finally, heuristic never over-estimatescost go called admissible. admissible heuristic, A* returns optimalsolutions.Dechter Pearl (1988) prove heuristic satisfies property called consistency(for nodes n m, h(n) h(m) + c(n, m), c(n, m) cost cheapest699fiBurns, Ruml, &path n m), A* expands fewest possible nodes required proveoptimality solution given heuristic. practice A* often takes long(Helmert & Roger, 2008), thus given optimal efficiency infeasible look optimalsolutions many problems. Instead, one must settle suboptimal solutions,hope possible find sufficiently cheap solution within reasonable amounttime memory.2.2 Suboptimal SearchGreedy best-first search (Michie & Ross, 1969) popular suboptimal search algorithm.proceeds like A*, orders open list heuristic, h(n), idearemaining search effort correlates remaining solution cost. words, assumeseasier find path goal nodes low h. strictlyattempting minimize search time, Thayer Ruml (2009) show greedy best-firstsearch different heuristic, d, effective. Instead estimating cost go,done traditional h functions, heuristic, called distance estimate, estimatesnumber remaining search nodes path cheapest solution beneath node.practice, distance estimates readily available cost-to-go heuristics providemuch better performance used greedy best-first search domains less costgo directly correlated less search go. call greedy best-first search usingheuristic Speedy search, analogy greedy search.greedy best-first search find solutions quickly, boundcost solutions. Bounded-suboptimal search algorithms remedy problem. WeightedA* (Pohl, 1970) perhaps common techniquesit proceeds like A*,orders open list f (n) = g(n) + w h(n), w 1. weighting parameter,w, puts emphasis heuristic estimate cost arriving node, thusgreedier A* often finds suboptimal solutions much faster A* findsoptimal ones. addition, weight provides bound suboptimality solutions:solutions w times cost optimal solution (Pohl, 1970). Unlikegreedy best-first search, weighted A* lets user select weight, allowing provideeither cheaper solutions faster solutions depending needs.refer reader work Thayer (2012) in-depth study suboptimalbounded-suboptimal search algorithms, including many use heuristics.2.3 Utility Functionsfar, described A*, optimizes solution cost, bounded-suboptimal search,finds solutions within constant factor optimal, greedy best-first search,attempts minimize solver time. Often, none really desired: optimal solutionsrequire impractical amount resources, one rarely requires solutions strictly withingiven bound optimal, unboundedly suboptimal solutions costly. Instead,propose optimizing simple utility function given linear combination search timesolution cost:U (s, t) = (wf g (s) + wt t)(1)solution, g (s) cost solution, time solutionreturned, wf wt user-specified weights used express preference trading-off700fiHeuristic Search Time Matterssearch time solution cost. number time units user willing spendachieve improvement one cost unit wf /wt . quantity usually easily elicitedusers already explicit application domain. cost emptysolution, g ({}), user-specified value defines utility achieved casesearch gives without returning solutionlinear utility function two main benefits. First, fairly expressive.example, one optimize cost solution search time givenmonetary terms. situation occur cloud computing environments computation time costs money. linear utility function also capture optimal greedy searchusing 0 weight execution time solution cost respectively. Additionally,linear utility function express goal achievement time weighting search time equallysolution makespan. practical examples minimizing goal achievement timedesired include robotic video game pathfinding problems. settings, useroften care optimal solutions take long find, maycare achieving goal quickly possible.demonstration minimizing goal achievement time, made videoA*, Speedy search, Bugsy solving pathfinding video game pathfinding problem.available online appendix paper web: http://youtu.be/Yluf88V1PLU. video includes three panels, showing agent using differentsearch algorithm. Since focus finding cost-optimal solutions,Speedy Bugsy agents begin moving almost immediately. A* agent stands stilllong time plans optimal path, doesnt start moving Bugsyarrived goal. occurring, Speedy agent followingextremely circuitous path; doesnt reach goal approximately 30 secondsA*. didnt show agonizing seconds video, instead stopped recordingsoon A* reached goal. Clearly, Bugsy agent, optimizes goal achievementtime, solution cost search time, preferred scenario.quite expressive, linear utility functions also rather simple. One main benefitsimplicity that, fixed utility function, passage time decays utilityvalues rate. simplification allows us ignore time passedcurrent decision point. express utility values terms utilityoutcome starting current moment time. Without benefit, mere passagetime would change relative ordering utilities different outcomes;would need re-compute utility values every point time order select bestoutcome.consider linear utility functions work, noted onecould consider expressive functions. Step functions, example, representdeadlines certain amount time elapsed utility acting greatlydecreases. Bugsy support functions, anytime monitoring techniquediscussed Section 3.1 restrictions utility functions optimize.Anytime monitoring naturally handle expressive functions, like step functions.3. Previous WorkNext describe previous techniques trading-off solver time solution cost.701fiBurns, Ruml, &3.1 Monitoring Anytime AlgorithmsMuch previous work optimizing utility functions solving time cost, Equation 1, focused finding stopping policies anytime algorithms. Anytime algorithms(Dean & Boddy, 1988) general class algorithms find one solution,stream solutions strictly decreasing cost. get name onestop anytime algorithm time get current best solution. Anytime algorithmsattractive candidate optimizing utility function: sincesingle solution pick, opportunity choose solutiongreater utility using algorithm finds single solution. Differentsolutions found different times, knew time algorithmwould find solutions cost solutions, could computeutilities return solution maximizes utility. Unfortunately, usuallypossible know solutions anytime algorithm return without running it.Instead, algorithm running, one must continually make decision: stop now,keep going?Deciding stop easy task, utility solution dependscost also time needed find it. one hand, stopping early reduceamount computation time expense costly solution.hand, algorithm continues, may reduce solution cost enoughjustify extra computation time. case, final utility worse wouldalgorithm stopped earlier. little extra information, however,possible create reasonable policy.Near Optimal Response-Time Algorithm (NORA, Shekhar & Dutta, 1989) providesone simple stopping policy optimizing goal achievement time. NORA, simply stopsanytime algorithm current search time user-specified factor currentincumbent solutions execution time. Shekhar Dutta (1989) prove the, searchstops time factor incumbent solution cost, goal achievementtime within factor min(1 + , 1 + 1 ) optimal goal achievement time.use NORA slightly different Shekhar Dutta (1989).apply NORA anytime heuristic search. Instead, evaluated empiricallydatabase query optimization problems, tree search problems, every leafnode possible solution. also describe one could use NORA A* search,make assumption A* stopped early without reaching goalheuristic planning procedure used achieve goal executing partialsolution found A*. procedure often available. using NORAanytime heuristic search, here, incumbent solution guaranteed reachgoal. disadvantage that, anytime stopping policies, cannotbetter best solution found utility-oblivious anytime algorithm.NORA finds solution within specified bound optimal goal achievement time.Instead, Hansen Zilberstein (2001) present dynamic programming-based techniquebuilding optimal stopping policy utility function. requires one extra pieceinformation: profile anytime algorithm. Hansen Zilberstein defineprofile probability distribution cost solution returned algorithm,conditioned current solution cost additional time given improve702fiHeuristic Search Time Matterssolution: P (qj |qi , t), qj qi two possible solution costsadditional time. profile allows reasoning solution cost may decreasealgorithm given time improve it. requires extra knowledge,performed small experiment (not shown here) found optimal policy foundusing dynamic programming performs better simpler NORA technique.Hansen Zilbersteins technique monitors progress anytime algorithmevaluating stopping policy discrete time intervals. algorithm considers stoppingevery time units, utility achievable time algorithms currentsolution costs qi is:U (qi , t)= stop,(2)V (qi , t) = max PP(q|q,t)V(q,+t)= continuejjjstopping policy is:(qi , t) = argmaxU (qi , t)= stop,PP(q|q,t)V(q,+t)= continuejjj(3)U user-specified utility function P profile anytime algorithm.also show sophisticated technique accounts cost evaluatingpolicy, however, algorithms presented paper, cost evaluating policyconsists mere array lookup essentially free.Since profile anytime algorithm usually known, must estimated.possible estimate profile off-line one access representative set training instances. estimate profile, algorithm run traininginstances 3-dimensional histogram created represent conditional probability distribution, P (qj |qi , t), needed compute stopping policy (cf. Equation 3).Appendix C gives detailed description implementation procedure.3.2 Anytime Heuristic SearchAnytime algorithms general class many anytime algorithmsheuristic search (Likhachev, Gordon, & Thrun, 2003; Hansen & Zhou, 2007; Richter,Thayer, & Ruml, 2010; van den Berg, Shah, Huang, & Goldberg, 2011; Thayer, Benton, &Helmert, 2012). paper use Anytime Repairing A* (ARA*, Likhachev et al., 2003)since tended give best performance approaches according experimentsdone Thayer Ruml (2010). ARA* executes series weighted A* searches,smaller weight previous. Since weight bounds solution cost,looser bounds early iterations tend find costly solutions quickly. time passesweight decreases, solution cost, eventually converging optimal. ARA* alsospecial handling duplicates encountered search enablesefficient still guaranteeing bound solutions.Like anytime heuristic search algorithms, ARA* parameters. runningARA*, user must select weight schedule, typically comprised initialweight amount decrement weight solution found.behavior ARA* varies different weight schedules. experiments, usedinitial weight 3.0 decrement 0.02. schedule used Likhachev703fiBurns, Ruml, &1100h=2Bd=21h=100d=1h=1Cd=11001EFigure 1: small example graph.et al. (2003), found gave best performance compared severalalternative schedules domains considered.Given fixed weight schedule, anytime heuristic search algorithm emit fixedstream solutions given problem instance; algorithm take usersutility function account. solutions found regardless whetheruser wants solution fast possible optimal solution costs. Figure 1shows small, concrete example, goal find path node node E.node labelled heuristic value (h) number nodes remaininggoal (d), edges labelled costs. user wants optimalsolution, algorithm would ideally return path A, B, C, E. However, userwants solution fast possible, may better find solution A, D, E,fewer nodes, may found fewer expansions. ARA* considers cost,distance, initial weight less 66 23 , longer, cheaper, solutionfound regardless users preference. monitoring technique selectbest solutions found.3.3 Contract SearchDionne, Thayer, Ruml (2011) consider problem contract search, goalmust returned hard deadline. Unlike real-time search (Korf, 1990),agents next action must ready deadline, contract search requires algorithmreturn complete path goal. Like optimizing utility function, contract search mustaware cost solutions also amount time required find them.conventional approaches contract search use anytime algorithms, Dionne et al.(2011) present Deadline-Aware Search (DAS) considers search time directly.basic idea behind DAS consider states lead solutions deemedreachable within deadline. Two different estimates used determine setnodes: estimate maximum-length solution path search exploredeadline arrives, called dmax , estimate distance solution beneath704fiHeuristic Search Time Matterssearch node open list, words d. States dmax , deemedreachable, states pruned. search expands non-pruned nodes best-firstorder f = g + h, updating dmax estimates on-line. updates causeremaining nodes pruned remaining time deadline, DAS usesrecovery mechanism repopulate open list set pruned nodes continuessearching deadline reached.mentioned previously, estimates readily available normal cost-to-go heuristics, h, domains. leaves question estimate dmax . Dionne et al.(2011) show simply using remaining number possible expansions, computed viaexpansion rate remaining time, appropriate due phenomenoncall search vacillation. best-first search expands nodes, typically expand straight single solution path, instead considers multiple solution pathstime, expanding nodes each. this, said vacillatingmany different paths, may return work particular pathperformed many expansions along others. account vacillation, Dionne et al.introduce metric called expansion delay estimates number additional expansions performed search expansion two successive nodes along singletexppath. define dmax = remdelay , trem time remaining deadline,texp average expansion rate, delay average expansion delay. computeaverage expansion delay averaging difference algorithms total expansioncount node expanded generated.Dionne et al. (2011) showed experimentally DAS performs favorably anytimebased approaches alternative contract search algorithms, indicating approachdirectly considers search time may also beneficial utility function optimization.4. Off-line Bound Selectionturn first two new methods introduced paper.section, present simple technique trading search timesolution cost based bounded-suboptimal search. Recall bounded-suboptimalsearch algorithms return solutions guaranteed within user-specified factoroptimal solution cost. practice, applications require actual bound, insteadbound used practitioners parameter tweaked speed-up searchfinding solutions quickly enough. fact bound trade search timesolution cost makes prime candidate automatic parameter tuning (Rice, 1976).exactly propose.anytime methods discussed previous section, off-line bound selection requires representative set training instances. instances used gatherinformation bounded-suboptimal search trades-off search time solutioncost. requirement user select set diverse bounds tryparameters search algorithm. algorithm run N training instances suboptimality bound, creating list N pairs bound:sols b = h(c1 , t1 ), ..., (cN , tN )i b bound passed parameter algorithm,ci cost solution ith training instance ti time ithsolution found. Given utility function U : cost time R, select bound705fiBurns, Ruml, &gives greatest expected utility training set:X1bound U = argmaxU (c, t)|sols b |b(4)(c,t)sols b )experiments, select different weight use utility functionset 1.1, 1.5, 2, 2.5, 3, 4, 6, 10. may possible reduce number weightstraining set using linear interpolation estimate performance parametersused training. simple approach also extended selectportfolio different algorithms addition different bounds. may beneficial,example, include A* Speedy search portfolio, algorithmslikely selected cheap solutions required solution must found quickly.see Section 6 simple technique outperforms ARA* using anytimemonitor experimental evaluation. fact, representative set training instancesavailable, technique tends perform better algorithmsevaluate.related technique dove-tailing method Valenzano, Sturtevant, Schaeffer, Buro,Kishimoto (2010). approach presented way side-stepping needparameter tuning running parameter settings simultaneously. found that,dove-tailing, weighted IDA* (Korf, 1985) able return first solution much faster,dove-tailing greatly reduced high variance solving times given weight.also found dove-tailing different operator orderings effective IDA*.main difference work Valenzano et al. quitedifferent goals. concern find first solution quickly, rather selectsetting better optimizes user-specified utility function. such, approachrun multiple settings time instead selects single parameter runsingle search. fact, approaches complementary. Given utility-awarealgorithms parameters, one could use dove-tailing avoid need performoffline parameter selection.5. Best-First Utility-Guided SearchAnytime search aware utility. Monitoring bound selection require training.section, present Bugsy2 , utility-aware search algorithm requireoff-line training.5.1 Expansion OrderLike A*, Bugsy best-first search, instead ordering open list f , Bugsyorders open list estimate utility outcome resulting nodeexpansion. Since utility dependent time, mere passage time affects utilityvalues. differs traditional search algorithms values used orderexpansions remain constant. Recall, however, using linear utility function,utility values decay exact rate. Given this, Bugsy ignores past time2. Bugsy acronym Best-first Utility-Guided SearchYes!706fiHeuristic Search Time Matterscompares utility estimates assuming time begins current decision point.utility values match utility ultimate outcome, stillpreserve relative order different choices agent make.understand Bugsys ordering function, first consider best utilityoutcome resulting node expansion computed oracle. foreknowledge maximum utility outcome, purpose search algorithm wouldachieve expanding nodes along path initial node order buildsolution path. Since utility function given linear combination solution costsearch time, utility value outcome written terms costlength (possibly empty) maximum utility outcome, s:U = (wf g (s) + wt (s) texp )(5)g (s) cost path (recall cost empty path user-specifiedconstant), (s) number nodes s, texp time required expand node.3Given maximum utility value U , best utility outcome resultingexpanding node n is:Un leads maximum utility outcome(6)u (n) =U wt texp otherwisewords, utility get expanding node leads maximum utilityoutcome maximum utility; expanding node simply waste time,utility maximum utility minus cost performing unnecessary expansion.practice, know maximum utility, must rely estimates. Bugsyuses two estimates approximate maximum utility. First, estimates costsolution find beneath node as, f . Note f estimate,heuristic estimate true cost go, also cheapestsolution beneath node may solution greatest utility. See Appendixpossible alternatives. Second estimates number expansions required findsolution beneath node n, exp(n). One crude estimate remaining expansions d,distance heuristic estimates remaining nodes solution path. reality,Bugsy experience search vacillation, discussed earlier, expanding nodesalong single solution path. account vacillation, use expansiondelay technique Dionne et al. (2011) estimate exp(n) = delay d(n). is,expect remaining d(n) steps goal require delay expansions.Bugsy either choose expand node, stop return empty solution.one way Bugsy differs A*: Bugsy decides among actions searchlevel (such terminating search, expanding one many open nodes), whereasA* committed expanding nodes fixed order. Bugsy node openlist represents possible outcome, Bugsys maximum utility estimated usingmaximum utility estimates open nodes Equation 5:U = max max (wf f (n) + wt d(n) delay texp ), U ({}, 0)(7)nopen3. Note expansion time constant general, includes time add remove elementsdata structures like open list.707fiBurns, Ruml, &Bugsy(initial , u())1. open {initial }, closed {}2.3.n remove node open highest u(n) value4.n goal, return5.add n closed6.ns children c,7.c goal u(c) < 0 old version c open closed8.skip c9.else add c open10.expansion count power two11.re-compute u(n) nodes open list using recent estimates12.re-heapify open list13. loop step 3Figure 2: Pseudo-code Bugsy.estimate U found, would possible substitute U Equation 6estimate u (n), utility outcome expanding node open list.However, Bugsy going expand one node, need estimate u (n)open node; Bugsy simply expands node best estimated outcome.Additionally, instead computing maximization Equation 7 scratch timeexpand node, Bugsy simply orders open list u(n) = (wf f (n) + wtd(n)delay texp ), iteration popping node maximum u(n) expansion.way, algorithm directly attempts maximize utility.Recall Figure 1, shows two paths initial node, A, goal node, E.Bugsy accounts distance utility function, find shorter path A,D, E utility function sufficiently emphasizes finding solutions quickly findingcheaper solutions. hand, utility function gives preference findingcheap solutions Bugsy spend extra search time find cheaper path, A,B, C, E.5.2 ImplementationFigure 2 shows high-level pseudo-code Bugsy. clarity, code elides detailscomputing u(n) values. algorithm proceeds like A*, selecting open nodehighest u(n) expansion (line 3). node goal, returned solution(line 4), otherwise node put closed list (line 5) children generated.new child put onto open list (line 9) except duplicate nodes nodesexpansion estimated negative utility (which occurs utility returningsolution greater continuing search); discarded (lines 78).Bugsy estimates current expansion time expansion delay online,estimates change expansion. Instead re-sorting open listexpansion, Bugsy re-sorts whenever number nodes expanded power708fiHeuristic Search Time Matterstwo, utility open node re-computed using latest set estimatestexp expansion delay (as described Section 3.3), open list re-heapified(lines 1012). describe re-sorting step greater detail Section 5.5.5.3 StoppingBugsy orders open list decreasing order u(n), stops searching maximum estimated utility less returning empty solution. maypossible continue searching anytime fashion first goal found,utility perspective correct approach. prove here:Theorem 1 Assuming expansion time texp constant, h admissible, exp neveroverestimates expansions go, time Bugsy finds first solution, s,solutions Bugsy would find beneath remaining nodes would result less utilityimmediately returning s.Proof: Let current time Bugsy found solution s. utility returningU (s, ) = u (s) = (wf f (s)+wt ), u (s) utility returning now,f (s) cost solution s. Note h admissible goal, h(s) = 0,g(s) = g (s), f (s) = f (s), therefore u(s) = u (s). Also exp never overestimatesexpansions go exp(s) = 0. Since chosen expansion u(n) u (s) everynode n open list.Let t(n) minimum amount additional time Bugsy requires find solutionbeneath unexpanded node n. t(n) texp since Bugsy must least expand n.node n open list, best utility Bugsy could achieve going straightcheapest goal n is:u (n) = (wf f (n) + wt (t(n) + ))(wf f (n) + wt (t(n) + )), since f (n) f (n) due admissibility h(wf f (n) + wt (exp(n) texp + )), since exp never overestimates= u(n), definition u(n)u (s), since u (s) = u(s) chosen expansion, njustifies Bugsys strategy returning first goal node selects expansion.noted Bugsys estimate exp(n) = delay d(n) lower bound,see later sections, stopping criterion performs quite well practice.5.4 Heuristic CorrectionsMany best-first search algorithms use admissible heuristic estimates never overestimatetrue cost go. proof optimality A* proofs bounded suboptimalitybounded suboptimal search algorithms rely crucially admissibility propertyheuristic. Bugsy fixate cost-optimal solutions guarantee boundedcost. Instead, Bugsy attempts optimize utility function solution costone two terms. Since strict cost guarantees, Bugsy free dropadmissibility requirement informed inadmissible estimates available.709fiBurns, Ruml, &Thayer, Dionne, Ruml (2011) show inadmissible estimates provide betterperformance bounded suboptimal search. One technique attempts correctheuristic estimates on-line using average single-step error heuristic valuesnode best child. Thayer et al. show technique provides goodsearch guidance, actually less accurate estimating true cost-to-go valuesstandard admissible heuristics. Bugsy, undesirable, needgood guidance, proper estimates. Thayer et al. also show learning heuristicoff-line linear regression provide accurate estimates. Unfortunately, usingoff-line training would negate one Bugsys main benefits. matter empiricalevaluation whether techniques provide better performance Bugsy.Section 6.5, show using standard admissible heuristics often gives bestperformance anyway.5.5 ResortingInstead requiring off-line training previous approaches, Bugsy uses on-lineestimates order nodes open list. First, many analyses regard texpconstant, practice depend log-time heaps, cache behavior, multiprogramming overhead, among factors, implementation Bugsy estimates texpglobal average computed search. Second, Bugsys expansion delay estimatecalculated global average difference expansion count nodegenerated expanded; must done on-line. Unfortunately,on-line estimates may change node expansion, navely using latest estimatescompute u value newly generated nodes lead poor performance.due comparisons used order open list: instead fair comparisons basedestimated utility node, recent fresh estimates new nodescompared old possibly stale estimates nodes openlong time.alleviate problem, implementation Bugsy uses two sets estimates:one stable set used order open list, one ever-changing set maintainingrecent estimates. certain points throughout search, Bugsy copies upto-date estimates stable set, recomputes utility values open nodes,re-sorts open list. open list implemented binary heap re-establishheap property linear time number elements heap. Unfortunately,would still expensive every node expansion, so, instead, Bugsy reordersopen list exponentially less frequently search progressesit reordersnumber expansions power two. prove logarithmic schemeadds constant amount overhead per-expansion amortized entire search.Theorem 2 search space grows geometrically finite branching factor,overhead reordering open list power-of-two expansions constant expansion amortized search.Proof: Let b maximum branching factor. maximum number nodesopen list n expansions N (n) = bn n = n(b 1). total cost710fiHeuristic Search Time Mattersre-sorting n expansions than:lg nXi=0lg nO(N (2 )) =Xi=0O(2i (b 1)), definition Nlg n= c(b 1)X2i , c > 0, definitioni=0lg n+1= c(b 1)(21), identityc(b 1)(2 2lg n 1)Pji=0 2= 2j+1 1= c(b 1)(2n 1)= O(n)So, overhead per-expansion constant amortized expansions.matter empirical evaluation determine constant overhead detrimentalweaddress Section 6.4.6. Experimental Evaluationtechniques discussed involve approximations estimations may maywork well practice. section, present results experimental comparisontechniques better understand performance. algorithmsdomains implemented C++; source code available https://github.com/eaburns/search.6.1 Overviewfollowing sections, answer several questions experimentally. First, would likeensure monitored ARA* algorithm performing best comparingprofile learned off-line oracle. see, off-line profile,estimate true profile algorithm, quite well-informed.Section 5.5, proved re-sorting adds constant overhead per-expansionamortized entire search. matter empirical evaluation determinewhether benefits outweigh overhead. experiments show re-sortinglogarithmic schedule greatly outperforms Bugsy without re-sorting.Section 5.4 pointed Bugsy require admissible heuristic estimates,fact may perform better inadmissible, accurate heuristics. showBugsy performs admissible heuristics, two different types correctedheuristics. Overall, conclude best configuration Bugsy standardadmissible heuristics.discussed expansion delay Section 5.1. show results demonstrateusing expansion delay better simply using estimate expansionsgoal. compare two variants Bugsy: one ignores newly generated nodesfound already closed list (we call duplicate nodes) onereinserts nodes onto open list better utility estimates711fiBurns, Ruml, &previously closed version. Ignoring duplicates always performs better domains,others performs better preference short search times.Then, compare A*, Speedy search, monitored ARA*, weighted A* learnedweight, Bugsy. find simplest approach learning good weightweighted A* gives best performance. also find Bugsy, doesnt useoff-line training, performs well monitored ARA*, use off-linetraining. Therefore, training instances available, recommend simple weightedA* approach weight selected based performance training set.training instances available Bugsy algorithm choice.Lastly, compare Bugsy real-time search DTA* platform pathfinding domain. experiments, Bugsy achieves best utility.6.2 Domainsorder verify results hold variety different problems, performedexperiments four different domains. domains used described brieflyfollowing paragraphs, detailed descriptions given Appendix B.6.2.1 15-Puzzle15-puzzle popular heuristic search benchmark small branching factorduplicates. domain, used reasonably informed Manhattan distanceheuristic, implementation followed heavily optimized solver presented Burns,Hatem, Leighton, Ruml (2012). ran 100 instances created Korf (1985),plots including A* use results 94 instances solvable A* 6GBmemory.6.2.2 Pancake Problempancake problem another standard puzzle large constant branching factor.experiments, used instances 50 pancakes, gap heuristic (Helmert,2010). Since many problems difficult A*, used IDA* instead A*domain.6.2.3 Platform Pathfindingplatform domain pathfinding domain creation dynamics based2-dimensional platform-style video game, player must jump platformstraverse maze. Video games often naturally element time pressure.large state-space many cycles, reasonably informed heuristic basedvisibility navigation. instances used experiments created randomly, usinggenerator described Appendix B. domain also particular interestaction costs given units time (each action 50ms), objective minimizinggoal achievement time expressed linear combination search time solutioncost.712fiHeuristic Search Time Matters6.2.4 Grid PathfindingGrid pathfinding popular heuristic search benchmark, motivated robotics videogames. experiments, used two different cost models, two different movementmodels. cost models standard unit-cost model life-cost modelassigns action costs shortest, direct path expensive longer,circuitous path. captures popular adage time money. Instances5,0005,000 grids uniformly distributed obstacles. heuristics basedManhattan distance heuristic four-way grids, octile distance heuristic eightway grids. octile distance heuristic simple modification Manhattandistancemultiplies shorter horizontal vertical displacement 2 accountseight-way move costs.6.3 Anytime Profile Accuracywant ensure implementation works well training instance setsrepresentative enough monitored ARA* perform best. subsection,evaluate accuracy stopping policies created using estimated anytime profilescomparing oracle. Since stopping policy guaranteed optimaltrue algorithm profile, matter empirical study determine whetherestimated profile lead good policy.estimate profile used monitored version ARA*, ran ARA*6GB memory limit convergence 1,000 separate test instances domain.Next, created histogram discretizing costs times solutions10,000 bins (100 100). experimented different utility functions varyingratio wf /wt Equation 1. Small values wf /wt give preference finding solutionsquickly, whereas large values prefer finding cheaper solutions. case platformgame, example, viewed way change speed agentmoves: slow agent might benefit search order find shorter path,fast agent execute path quickly, may prefer find feasible solution fastpossible.Figure 3 shows results experiment. box plots represent distributionutility values found ARA* using estimated stopping policy, given factororacles utility. oracle finds solutions anytime algorithm convergesoptimal solution, picks solution would maximized utilityfunction. Since utility values negative, larger factors represent smaller (more negative) utilities thus worse outcome. boxes surround second third quartiles,whiskers extend extremes, circles show values 1.5inter-quartile range outside box. center line box shows median,gray rectangles show 95% confidence interval means. box representsdifferent wf /wt shown x axis. reference line drawn across = 1 (thepoint oracle estimated policy performed equally well), many casesboxes narrow indistinguishable line.points figures lie slightly = 1 line, indicating instancesoracle performed worse estimated policy. possible duevariance solving times. experiment, ARA* runs used compute oracles713fiBurns, Ruml, &platformfactor oraclefactor oracle15-puzzle21.61.21e-41e-3 1e-2 1e-1cost/time preference32111e-41e-31e-21e-1cost/time preference4-way unit grids50-pancakefactor oracle1.3factor oracle11.21.111.081.0410.961e-41e-3 1e-2 1e-1cost/time preference11e-41e-3 1e-2 1e-1cost/time preference8-way unit grids14-way life gridsfactor oraclefactor oracle1.0141.21.121.041.0081.0020.9961e-41e-3 1e-2 1e-1cost/time preference11e-41e-3 1e-2 1e-1cost/time preference18-way life gridsfactor oracle1.0121.0081.00411e-41e-3 1e-2 1e-1cost/time preference1Figure 3: Comparison optimal stopping policy learned stopping policy.714fi15-puzzle10.600-6-3log10 cost/time preference0-60.60-3log10 cost/time preference0.50-6001.60.80-9-6log10 cost/time preference-3log10 cost/time preference08-way life gridslog10 factor best utility1.2-6-3log10 cost/time preferenceResortResort14-way life gridslog10 factor best utility8-way unit gridslog10 factor best utility4-way unit gridsplatform1.2log10 factor best utility2log10 factor best utilitylog10 factor best utilityHeuristic Search Time Matters-310-9-6log10 cost/time preference-3Figure 4: Bugsy: Resorting open list (circles) vs (boxes).utilities occasionally found solutions slowly ARA* runs using estimatedstopping policy. words, caused non-determinism inherent utilityfunction depends solving time. obvious figure, instances quiterare usually happened small values wf /wt , miniscule time differenceslarge effect utility.results, conclude monitored ARA* implementation performsquite well, stopping policy often stopped best solution availableemitted underlying anytime algorithm.6.4 Resort Resort?Section 5.5 proved re-sorting Bugsys open list power-of-two expansionsadded constant overhead per-expansion amortized search. matterempirical evaluation determine whether overhead worth effort.re-sorting schedules possible, tried re-sorting power-of-two expansions.Figure 4 shows utility achieved Bugsy without re-sorting.x axes show wf /wt ratio determining preference solution cost search timelog10 scale. previous plots, smaller values indicate preference fastersearch times larger values indicate preference cheaper solutions. axes showfactor utility achieved best technique instance, log10scale. value log10 1 = 0 indicates best utility achieved technique given715fiBurns, Ruml, &instance; values greater zero indicate less utility. Points show mean valuetest instances error bars giving 95% confidence intervals. plots,see re-sorting open list led significant improvements domains.pancake puzzle, Bugsy without re-sorting unable solve instances within6GB memory limit. remaining experiments, always enable re-sortingexponential schedule.6.5 Heuristic CorrectionsSection 5.4, mentioned Bugsy require admissible heuristic estimates,provides guarantees solution cost. section compare Bugsy usingstandard admissible heuristics Bugsy using on-line off-line corrected heuristics.Following Thayer et al. (2011), on-line heuristic correction used global averagesingle-step heuristic error node best offspring, off-line heuristiclinear combination h, g, depth, d, node. coefficients termoff-line heuristic learned solving set training problems using linearleast squares regression.comparison shown Figure 5. plots style Figure 4. Typically on-line correction technique performed worstsome times significantly worsetwo. attribute poor accuracy observed Thayer et al.(2011). problems, 15-puzzle 8-way unit-cost grid pathfinding, off-line correction technique performed best, general simple admissibleheuristics best competitive best. remainder experiments, chose use simplest variant without corrections requireoff-line training (which one Bugsys main benefits), never worstoften best near best.6.6 Expansion DelaySection 5.1 described simply using approximation exp(n), numbernodes expanded arrive goal beneath node n, inaccurate. search algorithmexpand nodes along path goal, instead vacillatesdifferent solutions. account search vacillation, choose estimate exp(n) =delay d(n), delay average expansion delaythe average number nodesexpanded search makes progress along single path goal. subsection,show experimentally using expansion delay provides much better performanceusing alone.Figure 6 shows two versions Bugsy: one uses expansion delay, labelledExp. Delay, one not, labelled Without Exp. Delay. clearfigure using expansion delay beneficial. Also, see right sideplots, cheaper solutions preferred short search times, using expansion delayusing itself. wf relatively large comparedwt utility functions, exp(n) term little influence utility estimates.716fiHeuristic Search Time Matters15-puzzle0.6log10 factor best utilitylog10 factor best utilitylog10 factor best utility50-pancakeplatformOnlineNoneOffline0.20.100-6-3-3log10 factor best utilitylog10 factor best utility0.060-30.040-6-30log10 cost/time preference8-way life gridslog10 factor best utility4-way life gridslog10 factor best utility00.080log10 cost/time preference0.10.050-6-2log10 cost/time preference8-way unit grids0.12-9-40log10 cost/time preference4-way unit grids-60.080-60log10 cost/time preference0.16-30.060.030-9log10 cost/time preference-6-3log10 cost/time preferenceFigure 5: Bugsy: Heuristic corrections.6.7 Duplicate DroppingSuboptimal search algorithms expand nodes strict order increasing f . Consequently, expand node, later re-generate node via cheaper path.call re-generations duplicates, generated via cheaper pathssay inconsistent, current path cost (and subsequently costpaths descendants) expensive necessary (Likhachev et al.,2003). face inconsistent nodes, search algorithm put already expandednode back open list cost accounts new, cheaper path.node comes front open list, re-expanded inconsistency717fiBurns, Ruml, &platform2.41.650-pancake1.2log10 factor best utilitylog10 factor best utilitylog10 factor best utility15-puzzle0.80.400-6-4-2log10 cost/time preference0-6-4-2log10 cost/time preferenceWithout Exp. DelayExp. Delaylog10 factor best utilitylog10 factor best utility0.4-50-3-4-2-1log10 cost/time preference08-way unit grids00.90.60.30-6-4-2log10 cost/time preference0-6-4-2log10 cost/time preference4-way life grids08-way life grids1.8log10 factor best utilitylog10 factor best utility0.804-way unit grids1.21.21.20.601.81.20.60-8-6-8-4log10 cost/time preference-6-4log10 cost/time preferenceFigure 6: Bugsy: Expansion delay.propagate descendants. Unfortunately, lotinconsistencies, search algorithm spend lot time re-expandingnodes again. alternative technique simply ignore inconsistencydrop duplicate nodes generated. Dropping duplicates reducesearch effort needed find goal cost finding expensive solutions. Whetherdropping duplicates beneficial typically depends domain (Thayer & Ruml,2008).Figure 7 shows comparison Bugsy without duplicate dropping.platform, tiles, pancake domains using duplicate dropping nearly always betterre-expanding duplicates. grid pathfinding problems,with notable excep718fiHeuristic Search Time Matters0.150.10.0550-pancakelog10 factor best utilityplatformlog10 factor best utilitylog10 factor best utility15-puzzle0.80.60.40.20.240.1600-6-4-2log10 cost/time preference00-6-4-2log10 cost/time preferenceDuplicate ReexpansionDuplicate Dropping0.120.060-3-2-100.040.020.010-6-4-2log10 cost/time preference0-6-4-2log10 cost/time preference08-way life gridslog10 factor best utility4-way life gridslog10 factor best utility-4log10 cost/time preference8-way unit gridslog10 factor best utilitylog10 factor best utility4-way unit grids0.18-501.81.20.600.0180.0120.0060-8-6-8-4log10 cost/time preference-6-4log10 cost/time preferenceFigure 7: Bugsy: Duplicate dropping.tion 4-way life-cost gridsre-expanding duplicate nodes seems give better performanceexcept solutions needed quickly possible (on left-hand side plots).reasonable, duplicate dropping tends sacrifice solution cost orderreduce search time. Note also, values axes plots small,results statistically significant, difference two techniquesgrid problems duplicate re-expansion performs better quite small. nextsection see A* actually achieves utility many casesduplicate re-expansion outperforms duplicate dropping.719fiBurns, Ruml, &platformlog10 factor best utilitylog10 factor best utility15-puzzle0.40.200-6-3log10 cost/time preference0-6-3log10 cost/time preference0log10 factor best utility50-pancakepeeugsy0.40.0-4-log10 cost/time preference0Figure 8: Comparison techniques.6.8 Comparing Techniquesunderstand promising configurations techniques studying, finally turn attention comparing them.Figures 8 9 show comparison three different techniques utility-awaresearch. plots larger previous plots improve clarity,lines. plots include A*, Speedy Search, Bugsy, ARA* monitoring(ARA*), weighted A* weight chosen automatically different utilityfunction set 1.1, 1.5, 2, 2.5, 3, 4, 6, 10 (wA*). would expect,preference shorter search times (on left-end x axis), A* performed poorly,stubbornly stuck optimal solutions. Speedy search, however, performed quite well.preference shifted toward desiring cheaper solutions, A* began better whereasSpeedy worse. utility-aware techniques much robust A*720fiHeuristic Search Time Matters8-way unit gridslog10 factor best utilitylog10 factor best utility4-way unit grids0.100.10-6-3log10 cost/time preference0-60log10 factor best utility8-way life gridslog10 factor best utility4-way life grids-3log10 cost/time preference00-9-6log10 cost/time preference-9-3-6log10 cost/time preference-3Figure 9: Comparison techniques (continued).Speedy, neither take users preference search time solution costaccount all.utility-aware techniques, Bugsy weighted A* automaticallyselected weight performed best. Bugsy better 15-puzzleplatform domain. grid problems, Bugsy weighted A* roughlyperformance right side x axes. left side, Bugsy tended get worserelative utility-aware techniques, ARA* anytime monitor oftenbest performer. However, ARA* performed significantly worse middleright-hand portion plot domains, leading us recommend weightedA* technique simpler robust approach.utility-aware techniques often performed well A* low-cost solutionspreferred. fast solutions preferred, techniques sometimes outperformedSpeedy search. likely indicates solution cost still played roll final utility721fiBurns, Ruml, &log10 factor best utilityorz100d0.20.10-6BugsyARA*-30log10 cost/time preferencewA*A*SpeedyFigure 10: Grid pathfinding video game map.left-most points plots. ARA* tended achieve greater utilityBugsy solutions needed quickly, cheaper solutions preferred,Bugsy tended better ARA*. domains, ARA* spike low utilityratios 0.001, 1, peak appearing 106 103 life-costgrids. peak approximately coincides utility functions estimatedprofile performed worse oracle shown Figure 3, possibly indicating1,000 training instances required utility functions.Overall, utility-aware techniques able achieve much greater utilityutility-oblivious A* Speedy algorithms. terribly surprising. Surprisingly,results also suggest simple parameter tuning technique often give bestperformance representative set training instances available. not, Bugsyalgorithm choice performs well require off-line training.Indeed, putting reasoning search time search algorithm itself, Bugsycompetitive techniques requiring previous experience.6.9 Limitationsprevious set experiments, saw utility-aware algorithms outperformedSpeedy search A* wide range utility functions. section, lookone domain tends case: video game grid maps.Video games one main motivations research grid pathfinding problems.Sturtevant (2012) observed grid maps created game designers often exhibitdifferent properties maps generated algorithmically. Figure 10 shows comparisonBugsy, monitored ARA*, weighted A* automatically selected weight, Speedy,722fiHeuristic Search Time MattersFigure 11: Grid pathfinding video game map.15010050200% Speedy time200planning timeexecution time200% Speedy time% Speedy nodesnodes expanded150100500816instance24150100500816instance240816instance24Figure 12: Nodes expanded, search time, execution time.A* Dragon Age Origins map orz100d benchmark set Sturtevant.map shown Figure 11. fairly wide-open area top, closed-offbottom half containing rooms hallways. format plot figureprevious subsection. see, A* gave best performancelarge range utility functions, Bugsy actually never outperformed Speedy A*entire experiment (neither ARA*, wA* gave best performancesingle data point). hypothesized Bugsys poor performanceproblems easy solve, Bugsys extra computation overhead, small,prominent.explore hypothesis, plotted performance Bugsy given differenceSpeedy using single utility function given wf = 106 , wt = 1.723fiBurns, Ruml, &left-most utility function Figure 10, function Speedy search performedbest Bugsy performed poorly. Figure 12 shows number nodes expanded,time spent executing, time spent searching Bugsyas percentagesequivalent values Speedy search. data points gathered random sample25 instances Sturtevants (2012) scenario set orz100d map. Valuesline 100% represent instances Bugsy expanded fewer nodes spent lesstime searching executing, values line represent instances Bugsyexpanded nodes spent time Speedy. x axes shows rankinstances sample increasing order optimal solution lengths.see Figure 12, Bugsy expanded number nodessimilar execution times Speedy. problems larger optimal solutioncosts Bugsy slightly less execution time. major difference performancetwo algorithms, however, shown right-most plot see Bugsyrequired search time Speedy search almost every instance. Since BugsySpeedy expanded number nodes, additional time must dueBugsys small amount extra overhead incurred re-sorting computing utility.conclude that, barring extra overhead, Bugsy would performed wellbest performer utility function. domains node expansion heuristiccomputation isnt simplistic, overhead would insignificant.6.10 Training Set HomogeneitySection 6.8 showed weighted A* approach outperformed techniquesdomains, notable exception platform domain 15-puzzle,Bugsy best. Additionally, compared domains, weighted A* techniqueperformed relatively poorly video game pathfinding (cf. Figure 10 wA* outperformed utility oblivious approaches points except one). believepoor performance wA* domains due heterogeneous training sets.verify this, looked mean standard deviation optimal path lengthsproblems domains. optimal path length viewed proxyproblem difficulty, high standard deviation statistic points diverseset instancessome easy solve, quite difficult. platformvideo game path finding domains, standard deviation optimal path lengthgreater 50% mean; twice domains. Note that,domains video game map, variety layout different areas mapmeans instances inherently differ characteristicsmerely gatheringinstances produce homogeneous set. evidence supports hypothesisweighted A*s performance greatly hindered situations representativetraining set available.6.11 Real-time Searchmain focus study algorithms off-line searchthey find entire pathsgoal execution begins. real-time search (Korf, 1990), search executionhappen parallel, agent allowed fixed amount time planmust perform action. Real-time search possibility efficient724fiHeuristic Search Time Mattersoff-line search terms goal achievement time, search happensparallel execution, goal achievement time simply execution time plussmall amount time required find first action. contrast off-lineapproach goal achievement time sum entire search time executiontime. situations, however, starting execution complete plangoal acceptable, may lead agent dead-end longerreach goal, real-time search may applicable. Examples domains deadends include robotics, manufacturing (Ruml, Do, Zhou, & Fromherz, 2011), spacecraftcontrol: exactly applications involving high value danger, automationworthwhile. cases, desirable find entire plan guaranteed reachgoal, execution begins.Hernandez, Baier, Uras, Koenig (2012) introduce model comparing real-timealgorithms off-line techniques A*, called game time model. game timemodel partitions time uniform intervals, agent execute single actioninterval. Path planning happen parallel execution (the agentplan step execution step t-1), goal move agent startlocation goal location time intervals possible, minimizing goal achievementtime, objective discuss Section 1. game time model specialcase utility functions considered paper solution cost given discrete,fixed-duration units time.Real-time search provides two benefits: first, may possible reduce goalachievement time allowing search execution happen time, second,agent start moving toward goal right awaya necessary property video games.leaves us question whether real-time search algorithms achievebetter goal achievement time off-line utility-aware methods. one hand, realtime search algorithms spend little time searching without making progress towardgoal. hand, real-time search algorithms tend make decisions basedlocal information find costly solutions. results, Hernandez et al.report best approach solves problems initially-known grid mapsnumber time intervals A*. previous section, showed utilityaware techniques outperformed A* utility functions. section, comparestate-of-the-art real-time search algorithm called LSS-LRTA* (Koenig & Sun, 2009)Bugsy platform pathfinding domain.4previous experiments, tested algorithms variety valuesratio wf /wt . Since interested goal achievement time, set wt = 1calculate search time units seconds. means wf represents numberseconds one unit execution costthe speed agent. set real-timeconstraint LSS-LRTA* allowed plan duration one unitexecution, always next action ready execution currentlyexecuting action completed.4. compare Time-bounded A* (TBA, Bjornsson, Bulitko, & Sturtevant, 2009), methodperformed best Hernandez et al. (2012), platform domain forms directed searchgraph, TBA* works undirected search graphs. also compare newerf -LRTA* (Sturtevant, 2011), perform well LSS-LRTA* platform domain,directed edges.725fiBurns, Ruml, &platformlog10 factor best GAT2.4LSS-LRTA*A*SpeedyBugsy1.60.80-4-3-2log10 w_f / w_t-10Figure 13: Comparison Bugsy real-time search.Figure 13 shows results comparison. see, LSS-LRTA* gives ratherpoor performance; goal achievement times nearly match A*, Bugsy ableachieve goal much faster. shows simply allowing search executiontake place parallel sufficient reduce goal achievement time; betterspend time searching solution way goal alternative spendlong time executing poor plan.6.12 Decision-theoretic A*Decision-theoretic A* (DTA*, Russell & EricWefald, 1991) utility-aware algorithmallows concurrent search execution. based ideas real-time heuristicsearch, unlike traditional real-time search, action emitted fixedamount search, DTA* decides stop searching emit action using decisiontheoretic analysis. time single best top-level action lowest costestimate. search emits action decided utility emittingaction outweighs utility search. DTA* uses approximation (foundoff-line training) solution cost estimate top-level action improvesadditional search. Using consistent heuristic, estimate increase (Nilsson,1980), DTA* stops searching decides time required raise bestactions estimated cost point longer best action costlyexpected gain determining different best action.Compared Bugsy, DTA* relatively myopic considers costsearch involved selecting individual actions. DTA* consider additional searchrequired solution path commits choosing action. Bugsyuses expansion delay reason required search effort entire726fiHeuristic Search Time Matterslog10 factor best utilityplatform (small instances)SpeedyA*DTA*Bugsy1.20.80.40-4-3-2log10 w_f / w_t-10Figure 14: Comparison Bugsy DTA*.path beneath node, DTA* reasons search required determine bestaction emit right now.implemented DTA* assess utility-aware real-time search might compareutility-aware off-line search planning time pressure. Figure 14 showsresults comparison DTA* Bugsy platform pathfinding domain.Unfortunately, DTA* fairly poor performance, experiment used smaller instancesconsisting 25x25 blocks, instead 50x50 block instances used previous experiments.Following Russell EricWefald (1991), gathered off-line training data DTA* usingstates sampled uniformly probability 0.1 among visited real-timesearch algorithm. Russell EricWefald (1991), used algorithm called SLRTA*,used LSS-LRTA*, current state art. training set consisted100 25x25 platform instances. also verified implementation ensuringcompared favorably A* Speedy search 15-puzzlethe domain usedRussell EricWefaldusing variety different utility functions. Figure 14,see DTA* often significantly worse utility Bugsy, often performingslightly better Speedy search, sometimes performing worse A*, example,cheap solutions desired.7. Related WorkBugsy uses estimates search time select whether terminate continue, select node expand, may said engaging metareasoning,is, reasoning reasoning action take. much worktopic AI since late 1980s (Dean & Boddy, 1988) continuing today (Cox & Raja,2011).727fiBurns, Ruml, &Dean Boddy (1988) consider problem faced agent trying respondpredicted events time constraints. Unlike setting, concernchoosing much time allocate prediction much allocate deliberation. solve type time-dependent planning problem, suggest use (andalso coined term) anytime algorithms. Unlike anytime-based techniques discussedpreviously, attempt find stopping policy optimize utility function, DeanBoddy used anytime algorithms means allowing different allocations timepredicting deliberation. Later, Boddy Dean (1989) show anytimealgorithms time-dependent planning framework used delivery agentmust traverse set waypoints grid, allocating time orderingwaypoints planning used travel them. Dean, Kaelbling, Kirman,Nicholson (1993) also adapt technique scheduling deliberation executionplanning face uncertainty.Garvey Lesser (1993) present design-to-time methods advocate using available time find best possible solution. Unlike anytime approaches interrupted time, design-to-time method requires time deadline givenupfront. way, algorithm spend time focusing finding singlegood solution, instead possibly wasting time finding intermediate results. Design-to-timealso differs contract techniques like DAS (Dionne et al., 2011), designto-time framework must predefined set solvers known (or predictable)solution times costs. design-to-time method select appropriate solverproblem deadline, possibly interleaving different solvers deemed appropriate.information cost solutions times, design-to-time methods require, usually unavailable must learned off-line. Techniques like DAS Bugsy,hand, use information computed on-line.Hansen, Zilberstein, Danilchenko (1997) show heuristic search inadmissibleheuristics used make anytime heuristic search algorithms. Like techniquespresented paper, consider problem trading-off search effort solutionquality. end, propose one possible optimization function anytime heuristicsearch search attempts maximize rate algorithm decreases solutioncost. Like anytime monitoring technique shown Section 3.1, evaluation functionrelies learning profile anytime algorithm offline. analysis 8puzzle, conclude that, method good anytime behavior, littlebenefit using instead trial-and-error-based hand tuning. surprising givenstrong performance demonstrated offline-tuned weighted A* experiments.recently, Thayer et al. (2012) proposed approach minimizing time solutions anytime algorithms. demonstrate new state-of-the-artalgorithm performs well wide variety domains, robustprevious approaches. Like Bugsy, technique relies using heuristics estimatesearch effort required find solutions. However, focus solutionsrequire least amount effort, optimize trade-off search timesolution cost.addition controlling expansion decisions, metareasoning also usedheuristic evaluation. Often search algorithms use maximum value computedmultiple heuristics accurate estimate cost goal. problems, like728fiHeuristic Search Time Mattersdomain-independent planning, heuristics quite expensive, increased accuracygained via maximizing many heuristics may worth increased computationtime. Domshlak, Karpas, Markovitch (2010) introduce on-line learning techniquedecide single heuristic compute state, instead computing manytaking max.related work using metareasoning control combinatorial search donearea constraint satisfaction problems (CSPs), boolean satisfiability (SAT). TolpinShimony (2011) use rational metareasoning decide compute value orderingheuristics CSP solver. focus work value ordering heuristicsgave solution count estimates; solver bothered compute heuristic decisionpoints deemed worthwhile. experiments demonstrate newmetareasoning variant outperformed variant always computed heuristicone computed heuristic randomly. Horvitz, Ruan, Gomes, Kautz, Selman,Chickering (2001) apply Bayesian structure learning CSPS SAT problems.consider problem quasi-group completion, unlike Tolpin Shimony (2011)use on-line metareasoning control search, use off-line Bayesian learning sethand-selected variables predict whether instances long short running.lot work attempting estimate size search trees offline (Burns & Ruml, 2013; Knuth, 1975; Chen, 1992; Kilby, Slaney, Thiebaux, & Walsh,2006; Korf, Reid, & Edelkamp, 2001; Zohavi, Felner, Burch, & Holte, 2010).related topic, concerned estimating search effort entire searchperformed. One may imagine leveraging technique predict search timealgorithm like Bugsy. Unfortunately, estimation methods rather costlyterms computation time, suitable estimator needed everysingle node generation. Another possibility use off-line estimations find parametersaffect performance search given domain. knowledge could helpfulcreating representative training sets used algorithms like weighted A* anytimemonitoring, require off-line training.8. Conclusionsinvestigated utility-aware search algorithms take account user-specifiedpreference trading-off search time solution cost. presented three different techniquesaddressing problem. first method based previous work arealearning stopping policies anytime algorithms. best knowledge,first demonstrate techniques area heuristic search. second methodnovel use algorithm selection bounded-suboptimal search chooses correctweight use weighted A* given utility function. last techniquepresented Bugsy algorithm. Bugsy technique threerequire off-line training.performed empirical study techniques context heuristic search,investigated effect parameters algorithm performance, compareddifferent techniques other. Surprisingly, simplest technique learningweight weighted A* able achieve greatest utility many problems, outperforming conventional anytime monitoring approach. Also surprisingly, Bugsy,729fiBurns, Ruml, &algorithm use off-line training, performed well off-linetechniques advantage learning thousands off-line training instances.representative set training instances available Bugsy algorithmchoice. Overall, utility-aware methods outperformed A* Speedy searchwide range utility functions. demonstrates heuristic search longerrestricted solely optimizing solution cost, freeing user choice either slowsearch times expensive solutions.Unlike previous methods trading deliberation time solution quality, Bugsy considers trade-off directly search algorithmdeciding, node, whetherresult expansion worth time. new approach provides alternative anytime algorithms. Instead returning stream solutions relying externalprocess decide additional search effort longer justified, search processmakes judgments based node evaluations available it. empiricalresults demonstrate Bugsy provides simple effective way solve shortest-pathproblems computation time matters. would suggest search proceduresusefully thought black boxes controlled external termination policycomplete intelligent agents, informed users goals acting rationallybasis information collect directly maximize users utility.Acknowledgmentsgreatly appreciate feedback suggestions Shlomo Zilberstein Scott Kiesel.would also like think Richard Korf pointing work Shekhar Dutta(1989). also grateful support NSF (grant 0812141 grant 1150068),DARPA CSSG program (grant D11AP00242), University New HampshireDissertation Year Fellowship. preliminary version Bugsy presented Ruml(2007); see Appendix A. Elisabeth Crawford assisted original versionsummer internship PARC.Appendix A. Previous Bugsyprevious version Bugsy proposed Ruml (2007), however, earlyrealization differs substantially one presented here. used aggressive duplicatere-expansion, heuristic corrections, used estimate remaining expansionsgoal reached. Section 6.7 showed duplicate dropping outperforms duplicate re-expansion many domains. found inadmissible heuristics performedpoorly (cf Section 6.5) practice, even compared standard admissible estimates. Also, temper inadmissible corrected estimates, previous Bugsymultiplied heuristic estimates arbitrary weight (min(200, (wt /wf ))/1000); version require ad hoc fix. discussed poor estimate numberremaining expansions Section 5.1, Section 6.6 showed, experimentally,using expansion delay performs much better using alone.Recall Bugsy uses f approximate cost path length bestutility outcome enabled expansion node. Note, however, ffunction used throughout paper refer cheapest solution beneath node n,730fiHeuristic Search Time Mattersmay goal results maximum utility. better assess availableoutcomes, previous version Bugsy computed two utility estimates node: onecheapest solution beneath node nearest solution termsnode expansions. non-unit-cost domains, two estimates may differ. example,life-cost grid pathfinding domains, cheapest solution usually involves moving towardtop grid actions cheap, nearest solution follow straight-linepath goal. general, large number different solutionssearch node, solutions may cover whole spectrum different cost/time trade-offs.considering cheapest solution, done implementation,may possible find solutions better utility. hand, maycostly compute multiple heuristics node, whether modificationbeneficial depends domain.Appendix B. Domainsperformed experiments variety different domains, describedetail here.B.1 15-Puzzle15-puzzle one popular benchmark domains heuristic search algorithms.consists 4-by-4 frame 15 tiles placed. One slot boardcontain tile, called blank. Tiles above, below, left rightblank may slid blank slot. objective 15-puzzle slide tilesaround order transform initially scrambled puzzle goal state blankupper-left corner tiles ordered 115 going left right, top bottom.domain interesting plans hard find, branching factor smallvaries little mean 2.13 (Korf et al., 2001), duplicates,heuristic reasonably informed.experiments use popular 100 15-puzzle instances created Korf (1985).plots include A*, however, used 94 instances solvable A* 6GBmemory. average optimal solution length instances 52.4. trainingset, generated 1,000 instances using 1 million step random walk back goalposition. used Manhattan distance heuristic, sums vertical horizontaldistance tile must move arrive goal position. implementation followsheavily optimized solver presented Burns et al. (2012).B.2 Pancake Puzzlepancake puzzle (Dweighter, 1975; Gates & Papadimitriou, 1979) another permutationpuzzle. consists stack differently sized pancakes numbered 1N . pancakesmust presented fancy breakfast, chef needs sort originally unorderedstack pancakes continually sticking spatula stack reversing orderpancakes above. Said another way, pancake problem involves sorting sequencenumbers using prefix reversal operations. simple problem interestingcreates search graph large branching factor (the number pancakes minus one).731fiBurns, Ruml, &Figure 15: screenshot platform pathfinding domain (left), zoomed-out imagesingle instance (right). knight must find path startinglocation, maze, door (on right-side left image,center right image).experiments, used 25 randomly generated 50-pancake puzzle instances,training set consisted 1,000 randomly generated instances. used powerful GAPheuristic Helmert (2010), sums number pairs adjacent pancakessequence.B.3 Platform Pathfindingplatform domain pathfinding domain creation dynamics based2-dimensional platform-style video game, written partially first author, calledmid5 . left image Figure 15 shows screenshot mid. goal knighttraverse maze initial location, jumping platform platform,reaches door. Mid open source game available http://code.google.com/p/mid-game. experiments game physics game ported C C++embedded C++ search codebase. generated 1,000 training instances100 test instances using level generator mid. example instance shownright panel Figure 15. domain unit-cost large state spacewell-informed heuristic.available actions different combinations controller keys may pressedsingle iteration games main loop: left, right, jump. Left right moveknight respective directions (holding time never consideredsearch domain, movements would cancel out, leaving knight5. author Steve McCoy, also drew tile graphics shown Figure 15.732fiHeuristic Search Time Mattersplace), jump button makes knight jump, applicable. knight jumpdifferent heights holding jump button across multiple actions rowmaximum 8. actions unit cost, cost entire solution numbergame loop iterations, called frames, required execute path. frame corresponds50ms game play.state state space contains x, position knight using doubleprecision floating point values, velocity direction (x velocity storeddetermined solely left right actions), number remaining actionspressing jump button add additional height jump, boolean statingwhether knight currently falling. knight moves speed 3.25 units perframe horizontal direction, jumps speed 7 units per frame, simulategravity falling, 0.5 units per frame added knights downward velocitymaximum 12 units per frame.details platform domain, please refer source code repositorygiven start Section 6.B.3.1 Level Generatorinstances used experiments created using level generator mid,special maze generator builds 2-dimensional platform mazes 5050 grid blocks.block either open occluded, ensure solvability given constraints imposedlimited jump height, generator builds maze stitching together pieceshand-created portfolio. piece consists number blocks either freeoccluded, start end location traversability ensured within piece.piece added grid location fits. piece fitsocclude block belongs previously placed piece. maze built using depthfirst procedure: piece selected random fits grid start locationlined end location predecessor placed procedure recurs.number successors node chosen uniformly range 39 inclusive,procedure backtracks pieces fit previous block.maze constructed, blocks belong piece marked occluded.right image Figure 15 shows sample level generated procedure. sourcecode level generator available mid source repository mentioned above.B.3.2 Heuristicdeveloped heuristic platform domain based visibility navigation(Nilsson, 1969). maze pre-processed convert grid representation setpolygons representing connected component occluded cells level. spacescaled account movement speed knight; knight fall fastermove horizontal direction, polygons end squished verticallystretched horizontally. visibility navigation problem solved reversefour corners goal cell center every non-occluded cell maze.maintain admissibility, cost edge visibility problem lengthvisibility line, instead maximum length line divided 2X displacements end points line. accounts fact733fiBurns, Ruml, &Figure 16: visibility navigation instance platform domains heuristic. visibility path initial state goal state drawn red.knight bemoving horizontally vertically time,moving distance 2 scaled space still takes single frame.search, heuristic value state computed one two different ways.straight-line path center knight goal occludedmaximum X distances goal scaled travel speed usedheuristic estimate. Otherwise, heuristic cost path visibility graphcenter cell contains knights center point minus maximumX distance (in number frames) knights center point centercell. Figure 16 shows map right image Figure 15, scaled, brokenpolygon components, visibility path initial state goalstate drawn red.B.4 Grid Pathfindingfinal domain grid pathfinding. popular domain video gamesrobotics, garnered much attention heuristic search community.experiments, used 5,000x5,000 grids four-way eight-way connectivityuniform obstacle distributions. four-way connected grids, cell blockedprobability 0.35, eight-way connected grids cells blockedprobability 0.45. also consider two different cost models, standardunit cost modelhorizontal vertical moves cost 1 diagonal moves cost 2.called life cost model, move cost equal row numbermove took place, causing cells toward top grid preferred.life cost model, short direct solutions found quickly, however relativelyexpensive, least-cost solution involves many annoying economizing steps (Ruml &Do, 2007). model viewed instantiation popular belief timemoney, one choose incur additional cost shorter simpler path.combination movement model cost model, generated 25 test instances 1,000training instances. Finally, used Manhattan distance heuristic four-connectedgrids octile distance heuristic eight-connected grids. life cost model734fiHeuristic Search Time Mattersheuristics also took account fact moving toward top grid backmay cheaper direct path.Appendix C. Anytime Policy Estimationchallenging write algorithms rely off-line training data. algorithmbehaves unexpectedly, unclear bug implementation, bugoff-line learning procedure, training set merely insufficiently representative.appendix, describe implemented verified procedure estimatinganytime profile.Figure 17 shows pseudocode building profile based description givenHansen Zilberstein (2001). algorithm accepts set solution streamsinput, one stream solved instance, proceeds two steps. first stepCount-Solutions function counts number times solution costimproved upon. function iterates solution (line 5), computes binhistogram cost value falls (line 7), subsequent solution countadded qqtcounts time step first solution improved secondsolution. addition, number total improvements solution time bincounted qtcounts array. costbin timebin functions bin cost time valuesrespectively returning integer corresponding index histogram:q qmincostbin(q) =(qmax qmin )/ncosttmintimebin(t) =(tmax tmin )/ntime.second step Probabilities function converts counts computedfirst step normalized probability values. achieved dividing numbersteps solution cost qi improved solution cost qj (qqtcounts)total number steps solution cost qi improved (qtcounts,lines 28). probability values smoothed adding half smallest probabilitybin representing solution cost improvement. step removes zero-probabilities,allowing improvement considered. Finally, probabilities normalizedprobability non-decreasing-cost solutions current cost time step sumone (lines 3137). profile computed, saved disk later usecomputing stopping policy.found extremely useful simple way validate policiesdebugging implementation. One option create stopping policy, run ARA*monitoring handful instances handful utility functions verifygives expected behavior. Unfortunately, approach rather cumbersomeprone error, evaluated policy small number instanceswilling run hand. Instead, chose validate implementation plottingpolices generated training data different utility functions. plottingextreme policies care solution cost search time, alongintermediate policies trade-off two, much simpler debug code.735fiBurns, Ruml, &Profile(streams)1. qtcounts, qqtcounts Count-Solutions(streams)2. return Probabilities(qtcounts, qqtcounts)Count-Solutions(streams)3. qtcounts new int[ncost][ntime] // Initialized zero.4. qqtcounts new int[ncost][ncost][ntime] // Initialized zero.5. streams6.1 |s|7.qi costbin(s[i].cost)8.qcur qi , tcur 09.// Count cost time increment solution i.10.j + 1 |s|11.qnext costbin(s[j].cost)12.tnext timebin(s[j].time s[i].time)13.// Current solution cost time solution j.14.= tcur tnext 115.increment qtcounts[qi ][t]16.increment qqtcounts[qcur ][qi ][t]17.qcur qnext , tcur tnext18.// Last solution cost final time.19.= tcur ntime20.increment qtcounts[qi ][t]21.increment qqtcounts[qcur ][qi ][t]22. return qtcounts, qqtcountsProbabilities(qtcounts, qqtcounts)23. probs new float[ncost][ncost][ntime]24. qi 1 ncost25.1 ntime26.qtcounts[qi ][t] = 0 continue27.qj 1 ncost28.probs[qj ][qi ][t] qqtcounts[qj ][qi ][t]/qtcounts[qi ][t]29. Smoothing: add half smallest probability elements probs improving solution cost.30. // Normalize.31. qi 1 ncost32.1 ntime33.sum 034.qj 1 ncost35.sum sum + probs[qj ][qi ][t]36.qj 1 ncost37.probs[qj ][qi ][t] probs[qj ][qi ][t]/sum38. return probsFigure 17: Pseudocode profile estimation.Figure 18 shows plots created platform domain. plot costaxis time x axis. Green circles represent inputs policysays keep searching, red crosses represent inputs policy says stop736fiHeuristic Search Time Matters(a)(b)10001002003002000cost2000costcost2000(c)1000100time200time3001000100200300timeFigure 18: Three different policies: (a) prefers cheaper solutions expense (wf =1, wt = 0), (b) attempts trade search time solution cost (wf =0.6, wt = 1), (c) prefers solution fast possible (wf = 0, wt =1).searching return solution. expected, policy always continues goalminimize solution cost always stops goal minimize search time (cf.left-most right-most plots Figure 18 respectively). center plot showsalso successfully found policies trade search time solution cost stoppingcost sufficiently low. Finally, left-most plot, bottom-most rightmost sides policy always stop implementation chose stoptraining data available estimate profile given input values.ReferencesBjornsson, Y., Bulitko, V., & Sturtevant, N. (2009). TBA*: time-bounded A*. ProceedingsTwenty-first International Joint Conference Artificial Intelligence (IJCAI09), pp. 431436.Boddy, M., & Dean, T. (1989). Solving time-dependent planning problems,. ProceedingsEleventh International Joint Conference Artificial Intelligence (IJCAI-89),Vol. 2, pp. 979984.Burns, E., Hatem, M., Leighton, M. J., & Ruml, W. (2012). Implementing fast heuristicsearch code. Proceedings Fifth Annual Symposium Combinatorial Search(SoCS-12).Burns, E., & Ruml, W. (2013). Iterative-deepening search on-line tree size prediction.Annals Mathematics Artificial Intelligence, S68, 123.Chen, P. C. (1992). Heuristic sampling: method predicting performance treesearching programs. SIAM Journal Computing, 21 (2), 295315.Cox, M. T., & Raja, A. (2011). Metareasoning: Thinking thinking. MIT Press.737fiBurns, Ruml, &Dean, T., & Boddy, M. (1988). analysis time-dependent planning. ProceedingsSeventh National Conference Artificial Intelligence (AAAI-88), pp. 4954.Dean, T., Kaelbling, L. P., Kirman, J., & Nicholson, A. (1993). Planning deadlinesstochastic domains. Proceedings eleventh national conference Artificialintelligence, Vol. 574, p. 579. Washington, DC.Dechter, R., & Pearl, J. (1988). optimality A*. Kanal, L., & Kumar, V. (Eds.),Search Artificial Intelligence, pp. 166199. Springer-Verlag.Dionne, A. J., Thayer, J. T., & Ruml, W. (2011). Deadline-aware search using on-line measures behavior. Proceedings Fourth Annual Symposium CombinatorialSearch (SoCS-11).Domshlak, C., Karpas, E., & Markovitch, S. (2010). max max: Online learningspeeding optimal planning. AAAI Conference Artificial Intelligence(AAAI-10), pp. 17011706.Dweighter, H. (1975). Elementary problem E2569. American Mathematical Monthly, 82 (10),1010.Finkelstein, L., & Markovitch, S. (2001). Optimal schedules monitoring anytime algorithms. Artificial Intelligence, 126 (1), 63108.Garvey, A. J., & Lesser, V. R. (1993). Design-to-time real-time scheduling. Systems, ManCybernetics, IEEE Transactions on, 23 (6), 14911502.Gates, W. H., & Papadimitriou, C. H. (1979). Bounds sorting prefix reversal. DiscreteMathematics, 27 (1), 4757.Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. Journal Artificial IntelligenceResearch, 28 (1), 267297.Hansen, E. A., & Zilberstein, S. (2001). Monitoring control anytime algorithms:dynamic programming approach. Artificial Intelligence, 126, 139157.Hansen, E. A., Zilberstein, S., & Danilchenko, V. A. (1997). Anytime heuristic search: Firstresults. Tech. rep., University Massachusetts, Amherst.Hart, P. E., Nilsson, N. J., & Raphael, B. (1968). formal basis heuristic determination minimum cost paths. IEEE Transactions Systems Science Cybernetics,SSC-4 (2), 100107.Helmert, M. (2010). Landmark heuristics pancake problem. ProceedingsThird Symposium Combinatorial Search (SoCS-10).Helmert, M., & Roger, G. (2008). good almost perfect. ProceedingsTwenty-Third AAAI Conference Artificial Intelligence (AAAI-08).Hernandez, C., Baier, J., Uras, T., & Koenig, S. (2012). Time-bounded adaptive A*.Proceedings Eleventh International Joint Conference Autonomous AgentsMultiagent Systems (AAMAS-12).Horvitz, E., Ruan, Y., Gomes, C., Kautz, H., Selman, B., & Chickering, M. (2001).Bayesian approach tackling hard computational problems. ProceetingsSeventeenth Conference Uncertainty Artificial Intelligence (UAI-01).738fiHeuristic Search Time MattersKilby, P., Slaney, J., Thiebaux, S., & Walsh, T. (2006). Estimating search tree size.Proceedings twenty-first national conference artificial intelligence (AAAI06).Knuth, D. E. (1975). Estimating efficiency backtrack programs. Mathematicscomputation, 29 (129), 121136.Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic searchreal-time situated agents. Autonomous Agents Multi-Agent Systems, 18 (3), 313341.Korf, R. E. (1985). Iterative-deepening-A*: optimal admissible tree search. Proceedings Ninth International Joint Conference Artificial Intelligence, pp.10341036.Korf, R. E. (1990). Real-time heuristic search. Artificial intelligence, 42 (2-3), 189211.Korf, R. E., Reid, M., & Edelkamp, S. (2001). Time complexity iterative-deepening-A*.Artificial Intelligence, 129 (1), 199218.Likhachev, M., Gordon, G., & Thrun, S. (2003). ARA*: Anytime a* provable boundssub-optimality. Advances Neural Information Processing Systems (NIPS-03),16.Michie, D., & Ross, R. (1969). Experiments adaptive graph traverser. MachineIntelligence 5, pp. 301318.Nilsson, N. J. (1969). mobile automaton: application artificial intelligence techniques. Proceedings First International Joint Conference Artificial intelligence (IJCAI-69), pp. 509520.Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga Publishing Co.Pohl, I. (1970). Heuristic search viewed path finding graph. Artificial Intelligence,1, 193204.Rice, J. R. (1976). algorithm selection problem. Advances Computers, 15, 65118.Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime searchvia restarting. Proceedings Twentieth International Conference AutomatedPlanning Scheduling (ICAPS-10), pp. 137144.Ruml, W., Do, M., Zhou, R., & Fromherz, M. P. (2011). On-line planning scheduling:application controlling modular printers. Journal Artificial Intelligence Research,40 (1), 415468.Ruml, W., & Do, M. B. (2007). Best-first utility-guided search. Proceedings 20thInternational Joint Conference Artificial Intelligence (IJCAI-07), pp. 23782384.Russell, S., & EricWefald (1991). right thing: studies limited rationality.MIT Press.Shekhar, S., & Dutta, S. (1989). Minimizing response times real time planningsearch. Proceedings Eleventh International Joint Conference ArtificialIntelligence (IJCAI-89), pp. 238242. Citeseer.739fiBurns, Ruml, &Sturtevant, N. (2012). Benchmarks grid-based pathfinding. Transactions Computational Intelligence AI Games, 4 (2), 144 148.Sturtevant, N. R. (2011). Distance learning agent-centered heuristic search. ProceedingsFourth Annual Symposium Combinatorial Search (SoCS-11).Thayer, J. (2012). Faster Optimal Suboptimal Heuristic Search. Ph.D. thesis, UniversityNew Hampshire.Thayer, J. T., Benton, J., & Helmert, M. (2012). Better parameter-free anytime searchminimizing time solutions. Proceedings Fifth Annual SymposiumCombinatorial Search (SoCS-12).Thayer, J. T., Dionne, A., & Ruml, W. (2011). Learning inadmissible heuristicssearch. Proceedings Twenty-first International Conference AutomatedPlanning Scheduling (ICAPS-11).Thayer, J. T., & Ruml, W. (2008). Faster weighted a*: optimistic approachbounded suboptimal search. Proceedings Eighteenth International ConferenceAutomated Planning Scheduling (ICAPS-08).Thayer, J. T., & Ruml, W. (2009). Using distance estimates heuristic search. Proceedings Nineteenth International Conference Automated Planning Scheduling (ICAPS-09).Thayer, J. T., & Ruml, W. (2010). Anytime heuristic search: Frameworks algorithms.Proceedings Third Annual Symposium Combinatorial Search (SoCS-10).Tolpin, D., & Shimony, S. E. (2011). Rational deployment CSP heuristics. Proceedings Twenty-Second International Joint Conference Artificial Intelligence(IJCAI-11).Valenzano, R. A., Sturtevant, N., Schaeffer, J., Buro, K., & Kishimoto, A. (2010). Simultaneously searching multiple settings: alternative parameter tuningsuboptimal single-agent search algorithms. Proceedings Twentieth International Conference Automated Planning Scheduling (ICAPS-10).van den Berg, J., Shah, R., Huang, A., & Goldberg, K. (2011). ANA*: Anytime nonparametric A*. Proceedings Twenty-fifth AAAI Conference Artificial Intelligence(AAAI-11).Zohavi, U., Felner, A., Burch, N., & Holte, R. (2010). Predicting performance ida*using conditional distributions. Journal Artificial Intelligence Research, 37 (1), 4184.740fiJournal Artificial Intelligence Research 47 (2013) 853-899Submitted 03/13; published 08/13Framing Image Description Ranking Task:Data, Models Evaluation MetricsMicah HodoshPeter YoungJulia Hockenmaiermhodosh2@illinois.edupyoung2@illinois.edujuliahmr@illinois.eduDepartment Computer ScienceUniversity IllinoisUrbana, IL 61801, USAAbstractability associate images natural language sentences describedepicted hallmark image understanding, prerequisite applications sentence-based image search. analogy image search, proposeframe sentence-based image annotation task ranking given pool captions.introduce new benchmark collection sentence-based image description search,consisting 8,000 images paired five different captions provideclear descriptions salient entities events. introduce number systemsperform quite well task, even though based featuresobtained minimal supervision. results clearly indicate importancetraining multiple captions per image, capturing syntactic (word order-based)semantic features captions. also perform in-depth comparison humanautomatic evaluation metrics task, propose strategies collecting humanjudgments cheaply large scale, allowing us augment collectionadditional relevance judgments captions describe image. analysis showsmetrics consider ranked list results query image sentencesignificantly robust metrics based single response per query. Moreover, study suggests evaluation ranking-based image description systemsmay fully automated.1. Introductionability automatically describe entities, events scenes depicted imagepossibly ambitious test image understanding. advances tasksignificant practical implications, since billions images webpersonal photo collections. ability efficiently access wealth informationcontain hampered limitations standard image search engines, must relytext appears near image (Datta, Joshi, Li, & Wang, 2008; Popescu, Tsikrika, &Kludas, 2010). lot work multi-label classification problemassociating images individual words tags (see, e.g., Blei & Jordan, 2003; Barnard,Duygulu, Forsyth, Freitas, Blei, & Jordan, 2003; Feng & Lapata, 2008; Deschacht & Moens,2007; Lavrenko, Manmatha, & Jeon, 2004; Makadia, Pavlovic, & Kumar, 2010; Weston,Bengio, & Usunier, 2010), much harder problem automatically associating imagescomplete sentences describe recently begun attract attention.2013 AI Access Foundation. rights reserved.fiHodosh, Young & Hockenmaier1.1 Related WorkAlthough approaches framed sentence-based image description task mapping images sentences written people (Farhadi, Hejrati, Sadeghi, Young, Rashtchian,Hockenmaier, & Forsyth, 2010; Ordonez, Kulkarni, & Berg, 2011), researcharea focused task automatically generating novel captions (Kulkarni, Premraj,Dhar, Li, Choi, Berg, & Berg, 2011; Yang, Teo, Daume III, & Aloimonos, 2011; Li, Kulkarni, Berg, Berg, & Choi, 2011; Mitchell, Dodge, Goyal, Yamaguchi, Stratos, Han, Mensch,Berg, Berg, & Daume III, 2012; Kuznetsova, Ordonez, Berg, Berg, & Choi, 2012; Gupta,Verma, & Jawahar, 2012). argue paper framing image description natural language generation problem introduces number linguistic difficulties detractattention underlying image understanding problem wish address. Sincesentence-based image description retrieval system requires ability associate imagescaptions describe depicted them, argue important evaluatemapping images sentences independently generation aspect. Research caption generation also ignored image search task, arguablymuch greater practical importance.systems cited either evaluated data set group releasedearlier work (Rashtchian, Young, Hodosh, & Hockenmaier, 2010), SBU Captioned Photo Dataset (Ordonez et al., 2011). data set consists 1,000 imagesPASCAL VOC-2008 object recognition challenge annotated five descriptive captions purposely collected task. SBU data set consists onemillion images captions harvested Flickr. Gupta et al. (2012) systemuse Grubinger, Clough, Mller, Deselaerss (2006) IAPR TC-12 data set, consists20,000 images paired longer descriptions.Although details differ, models rely existing detectors define map imagesexplicit meaning representation language consisting fixed number scenes, objects(or stuff), attributes spatial relations (Farhadi et al., 2010; Kulkarni et al., 2011;Li et al., 2011; Yang et al., 2011; Ordonez et al., 2011; Mitchell et al., 2012).unclear well detector-based approaches generalize: models evaluatedPASCAL VOC-2008 data set (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011;Yang et al., 2011; Mitchell et al., 2012) rely detectors may trainedimages contained corpus, Kuznetsova et al. (2012) select test set 1,000 imagesSBU data set detectors work well. Moreover, among systemsevaluated PASCAL VOC-2008 data set, Kulkarni et al. (2011), Li et al. (2011),Li et al. (2011) Mitchell et al.s (2012) results may directly comparable, since differentresearch groups report different evaluation metrics use different parts data settest training data. evaluation generation systems generally well knowndifficult (see, e.g., Dale & White, 2007; Reiter & Belz, 2009), typically requires expensivehuman judgments consider quality content selection (whatdescribed) surface realization (the fluency generated text). syntacticpragmatic issues confound purely semantic question whether image correctlydescribed caption.854fiFraming Image Description Ranking Task1.2 Approachpaper, focus task associating images sentences drawn large,predefined pool image descriptions. descriptions generated automaticallyharvested web (Feng & Lapata, 2008; Ordonez et al., 2011), writtenpeople asked describe them. argue evaluating ability selectrank, rather generate, appropriate captions image direct testfundamental semantic question well associate images sentencesdescribe well. Framing image description ranking task also numberadditional advantages. First, allows us handle sentence-based image annotationsearch unified framework, allowing us evaluate whether advances one taskcarry other. Second, framing image description ranking problem greatlysimplifies evaluation. establishing parallel description retrieval,use metrics evaluate tasks. Moreover, show rankoriginal caption, easily determined automatically, leads metrics correlatehighly systems rankings obtained human judgments, even underestimateactual performance. also show standard automatic metrics Bleu (Papineni,Roukos, Ward, & Zhu, 2002) Rouge (Lin, 2004) also used evaluatecaption generation systems show poor correlation human judgments, leading usbelieve evaluation caption generation system automated. alsoperform large-scale human evaluation, since sentences data set imagedescriptions written people, need collect purely semantic judgments whetherdescribe images system associated with. since judgmentsindependent task, use evaluate image description retrievalsystems. Since collect judgments image-caption pairs publicly availabledata set, also establish common benchmark enables direct comparison differentsystems. believe another advantage caption generation task. Sincemany possible ways describe image, generation systems libertyless specific describe image. makes direct comparisonindependently obtained judgments quality two different systems difficult,since one system may aiming solve much harder task other, impliesunless system outputs common benchmark collection images made publiclyavailable, cannot shared, objective evaluation would allow communitymeasure progress difficult problem. since caption generation systems alsoneed able determine well caption describes image, data set couldpotentially used evaluate semantic component.1.3 Contributions Outline PaperSection 2, discuss need new data set image description introducenew, high quality, data set image description enable community comparedifferent systems benchmark. PASCAL VOC-2008 data set 1,000images (Rashtchian et al., 2010) used number image description systems(Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al.,2012; Gupta et al., 2012), number shortcomings limit usefulness. First,domain relatively limited, captions relatively simple. Second, since855fiHodosh, Young & Hockenmaierimages drawn data used PASCAL VOC-2008 object classes challenge,difficult guarantee fair evaluation description systems rely off-the-shelfobject detectors (e.g., Felzenszwalb, McAllester, & Ramanan, 2008) data set, sincemay possible identify images detectors trained on.experiments paper therefore based larger, diverse, data set 8,000images. Unlike data sets pair images sentences merely relatedimage (Feng & Lapata, 2008; Ordonez et al., 2011), image data setspaired five different captions purposely written describe image.Section 3, describe image description systems. image descriptionnovel task, remains largely unknown kind model, kindvisual linguistic features requires. Instead unidirectional mapping imagessentences common current caption generation systems, map imagessentences space. allows us apply system image searchretrieving images closest query sentence, image descriptionannotating images sentences closest it. technique use,Kernel Canonical Correlation Analysis (KCCA; Bach & Jordan, 2002), alreadysuccessfully used associate images (Hardoon, Szedmak, & Shawe-Taylor, 2004; Hwang& Grauman, 2012; Hardoon, Saunders, Szedmak, & Shawe-Taylor, 2006) image regions(Socher & Li, 2010) individual words sets tags, Canonical CorrelationAnalysis (Hotelling, 1936) also used associate images related Wikipediaarticles ten different categories (Rasiwasia, Pereira, Coviello, Doyle, Lanckriet, Levy,& Vasconcelos, 2010). However, performance techniques muchstringent task associating images sentences describe depictedevaluated. compare number text kernels capture different linguisticfeatures. experimental results (discussed Section 4) demonstrate importancerobust textual representations consider semantic similarity words, hence takelinguistic diversity different captions associated image account.visual features relatively simple. number image description systems (Farhadi et al.,2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Kuznetsova et al., 2012) largelyrely trained detectors, e.g. obtain explicit intermediate meaning representationdepicted objects, scenes events. approach would ultimately require separatedetectors, hence labeled training data, term phrase chosen meaningrepresentation language. show image features capture low-levelperceptual properties fact work surprisingly well larger data setin-domain detectors available.Section 4, consider question evaluation, use number different metricscompare systems. Since focus problem learning appropriate mappingimages captions, follow standard machine learning practice evaluateability function generalize unseen examples. Hence, separate poolcaptions images used testing used train systems. first considermetrics quality single image-caption pair, compare automatically computedscores detailed human judgments. examine metrics evaluate rankedlists returned systems. analysis reveals that, current level performance,differences models may become apparent single caption per imageconsidered, commonly done caption generation systems. even two models856fiFraming Image Description Ranking Taskequally likely fail return suitable caption first result, still preferone likely rank good captions higher other, since arguablyprovides better approximation semantic space images near captionsdescribe well. Since test pool contains single gold item query,first consider metrics based rank recall gold item. showsimpler, binary judgments image descriptions good approximationsfine-grained human judgments collected large scale via crowdsourcing.augment test pool data set relevance judgments, hopeadd usefulness community resource benchmark. judgmentsshow actual performance systems higher recall gold itemindicates. However, comparison system rankings obtained via different metrics alsosuggests differences rank recall gold item correlate highlydifference performance according binary relevance judgments.2. New Data Set Image Descriptionused crowdsourcing collect descriptive captions large number imagespeople animals (mostly dogs). describing data set annotation methodology, discuss kind captions useful image description, motivateneed create new data sets task.2.1 Mean Image Description?Since automatic image description relatively novel task, worth reflectingmeans describe images, wish say image. factsubstantial body work image description related image libraries (Jaimes, Jaimes,& Chang, 2000; Shatford, 1986) useful revisit purpose. arguethree different kinds image descriptions commonly distinguished, onetype, so-called conceptual descriptions, relevance image understanding aim achieve automatic captioning. Conceptual image descriptions identifydepicted image, may abstract (e.g., concerning moodpicture may convey), image understanding mostly interested concrete descriptionsdepicted scene entities, attributes relations, well eventsparticipate in. focus actually image, conceptual descriptionsdiffer so-called non-visual descriptions, provide additional background information cannot obtained image alone, e.g. situation, time locationimage taken. Perceptual descriptions capture low-level visual propertiesimages (e.g., whether photograph drawing, colors shapes dominate) little interest us, unless link properties explicitly depictedentities. Among concrete conceptual descriptions, distinction drawn specific descriptions, may identify people locations names,generic descriptions (which may, e.g., describe person woman skateboarder,scene city street room). exception iconic entitiesrecognized (e.g., well-known public figures landmark locations EiffelTower) argue image understanding focus information captured857fiHodosh, Young & HockenmaierBBC captions(Feng Lapata 2010)Consumptionsoaredreal pricedrink fallenAMD destroyscentral visionSBU Captioned Photo Dataset (Flickr)(Ordonez et al. 2011)Downers Grovedon't chew couchtrain station (our condo pee kitchenbuildingmama!background),way AG storeChicago.IAPR-TC12 data set(Grubinger et al. 2006)blue white airplane standing grey airport;man red cones standing front twored-dressed hostesses two passengers directlystairs front airplane; brown landscapehigh dark brown mountains snow-coveredsummits light grey sky background;Figure 1: data sets images captionsgeneric descriptions. leaves question obtain data set images pairedsuitable descriptions train automatic description systems on.2.2 Need New Data Setsdearth images associated text available online, arguetext suitable task. work, notably natural languageprocessing community, focused images news articles (Feng & Lapata, 2008, 2010).However, images often used illustrate stories, little direct connectiontext (Figure 1, left). Furthermore, even captions describe depicted event,tend focus information cannot obtained image itself. Similarly,people provide captions images upload websites Flickr (Figure 1,center), often describe situation images taken in, ratheractually depicted image. is, captions often provide non-visual overlyspecific information (e.g., naming people appearing image locationimage taken). simple reason people typically provide kindsgeneric conceptual descriptions use purposes: Gricean maximsrelevance quantity (Grice, 1975) entail image captions written peopleusually provide precisely kind information could obtained imageitself, thus tend bear tenuous relation actually depicted. Or,state succinctly, captions usually written seen along imagesaccompany, users may wish bore readers obvious.Ordonez et al. (2011) harvested images captions Flickr createSBU Captioned Photo Dataset, discard vast majority imagescaptions actually descriptive. analysis random sample 100images final data set revealed majority (67/100) captions describeinformation cannot obtained image (e.g., naming peoplelocations appearing image), substantial fraction (23/100) describe smalldetail image otherwise commentary image. Examplesissues shown Figure 1 (center). makes data set less useful kindimage understanding interested in: unless refer specific entities one mayactually wish identify (e.g., celebrities famous landmarks appear image),proper nouns little help learning visual properties entity types unless one858fiFraming Image Description Ranking Taskdata set 8,000 Flickr images 5 crowd-sourced captionsman tricks bicycle ramps front crowd.man bike executes jump part competition crowd watches.man rides yellow bike ramp others watch.Bike rider jumping obstacles.Bmx biker jumps ramp.group people sit table front large building.People drinking walking front brick building.People enjoying drinks table outside large brick building.Two people seated table drinks.Two people sitting outdoor cafe front old building.Figure 2: data set images paired generic conceptual descriptionsinfer kind entity refer to.1 IAPR TC-12 data set (Grubinger et al.,2006), consists 20,000 photographs potentially useful purposes, sincecontains descriptions recognized image without prior informationextra knowledge. However, descriptions, consist often multiple sentencessentence fragments, tendency lengthy (average length: 23.1 words)overly detailed, instead focusing salient aspects photograph. example,photo airplane Figure 1 (right), two hostesses barely visiblenevertheless described detail.2.3 Data SetsSince kinds captions normally provided images describe imagesthemselves, collected data sets images captions. captionsobtained using crowdsourcing service provided Amazon Mechanical Turkannotate image five descriptive captions. asking people describepeople, objects, scenes activities shown picture without givinginformation context picture taken, ableobtain conceptual descriptions focus information obtainedimage alone. annotation process quality control described detailRashtchian et al. (2010)s paper. annotated two different data sets manner:2.3.1 PASCAL VOC-2008 Data Setfirst data set produced relatively small, consists 1,000 images randomly selected training validation set PASCAL 2008 object recognitionchallenge (Everingham, Gool, Williams, Winn, & Zisserman, 2008). usedlarge number image description systems (Farhadi et al., 2010; Kulkarni et al., 2011; Liet al., 2011; Yang et al., 2011; Mitchell et al., 2012; Gupta et al., 2012), since almostsystems (the exception Gupta et al., 2012) rely detectors trained1. data set Ordonez et al. (2011) also differs significantly content ours: collectionfocuses images eventualities, i.e. people animals something, majority Ordonez etal.s images (60/100) depict people animals (e.g., still lifes, landscape shots).859fiHodosh, Young & Hockenmaierimages data set (Felzenszwalb et al., 2008), unclear wellapproaches would generalize domains labeled data train detectorsavailable. captions PASCAL data set also relatively simple. example,since data set contains many pictures depict focus people something, 25% captions contain verb, additional 15% captionscontain common static verbs sit, stand, wear, look.2.3.2 Flickr 8K Data Setwork reported paper therefore collected larger, diverse data setconsisting 8,092 images Flickr.com website. Unlike static PASCALimages, images data set focus people animals (mainly dogs) performingaction. Examples data set shown Figure 2. images chosensix different Flickr groups,2 tend contain well-known people locations,manually selected depict variety scenes situations. order avoidungrammatical captions, allowed workers United States passedbrief spelling grammar test devised annotate images.interested conceptual descriptions, annotators asked write sentences describedepicted scenes, situations, events entities (people, animals, objects).collected multiple captions image considerable degree varianceway many images described. consequence, captionsimages often direct paraphrases other: entity event situationdescribed multiple ways (man vs. bike rider, tricks vs. jumping),everybody mentions bike rider, everybody mentions crowd ramp.dynamic nature images also reflected described:Captions data set average length 11.8 words, compared 10.8 wordsPASCAL data set, 40% PASCAL captions contain verbsit, stand, wear, look, 11% captions Flickr 8K set containverb, additional 10% contain common verbs. data sets, Flickrtraining/test/development splits human relevance judgments used evaluationtest items (Section 4) publicly available.3 online appendix paper containsinstructions workers, including qualification test passallowed complete tasks.3. Systems Sentence-Based Image DescriptionSince image description requires ability associate images sentences, imagedescription systems viewed terms affinity function f (i, s) measuresdegree association images sentences. evaluate ability computeaffinity functions measuring performance two tasks depend directly them.Given candidate pool sentences Scand candidate pool images Icand , sentencebased image retrieval aims find image Icand maximizes f (i, sq ) querysentence sq Scand . Conversely, image annotation aims find sentence Scand2. groups called strangers!, Wild-Child (Kids Action), Dogs Action (Read Rules),Outdoor Activities, Action Photography, Flickr-Social (two people photo)3. http://nlp.cs.illinois.edu/HockenmaierGroup/data.html860fiFraming Image Description Ranking Taskmaximizes f (iq , s) query image iq Icand . cases, f (i, s) coursemaximized image-sentence pairs sentence describes image well:Image search:Image annotation:= arg maxiIcand f (i, sq )(1)= arg maxsScand f (iq , s)formulation completely general: although will, evaluation purposes, defineScand set captions originally written images Icand ,case, Scand could also, example, defined implicitly via caption generationsystem. order evaluate well f generalizes unseen examples, evaluatesystem test pools Itest Stest drawn domain disjointtraining data Dtrain = (Itrain , Strain ) development data Ddev = (Idev , Sdev ).challenge defining f lies fact images sentences drawn twodifferent spaces, S. paper, present two different kinds image descriptionsystems. One based nearest-neighbor search (NN), uses technique calledKernel Canonical Correlation Analysis (KCCA; Bach & Jordan, 2002; Hardoon et al., 2004).rely set known image-sentence pairs Dtrain = {hi, si}.3.1 Nearest-Neighbor Search Image DescriptionNearest-neighbor based systems use unimodal text image similarity functions directlyfirst find image-sentence pair training corpus Dtrain contains closestitem query, score items space similarityitem pair:Image retrieval: fNN (i, sq ) = fI (iNN , i)hiNN , sNN = arg max fS (sq , st ) (2)hit ,st iDtrainImage annotation: fNN (iq , s) = fS (sNN , s) hiNN , sNN = arg max fI (iq , )hit ,st iDtrainDespite simplicity, nearest-neighbor systems non-trivial baselines:task annotating images tags keywords, methods annotate unseen imagestags nearest neighbors among training images known achieve competitive performance (Makadia et al., 2010), similar methods recently proposedimage description (Ordonez et al., 2011). Since task address allowus return items training data, requires us rerank pool unseen captionsimages, nearest-neighbor search requires two similarity functions. nearestneighbor systems use image representation KCCA-based systems, describedSection 3.3. main nearest-neighbor system, NN (NN5idfF1 ), treats five captionsassociated training image single document. reweights tokeninverse document frequency (IDF) w , defines similarity two sentencesF1-measure (harmonic mean precision recall) computed IDF-reweightedbag-of-words representation. Dtrain (w) subset training images whose captionsword w appears least once, inverse document frequency (IDF) w defined|Dtrain |w = log |Dtrain(w)|+1 . IDF-reweighting potentially helpful task, since wordsdescribe fewer images may particularly discriminative captions.861fiHodosh, Young & Hockenmaierappendix, provide results NN systems use text representationtwo KCCA systems.3.2 Kernel Canonical Correlation Analysis Image Descriptionsystems present based technique called Kernel Canonical CorrelationAnalysis (Bach & Jordan, 2002; Hardoon et al., 2004). first provide brief introduction,explain apply task.3.2.1 Kernel Canonical Correlation Analysis (KCCA)KCCA extension Canonical Correlation Analysis (Hotelling, 1936), takestraining data consisting pairs corresponding items hxi , yi drawn two differentfeature spaces (xi X , yi Y), finds maximally correlated linear projections xsets items newly induced common space Z. Since linear projectionsraw features may capture patterns necessary explain pairingdata, KCCA implicitly maps original items higher-order spaces X 0 0 viakernel functions KX = hX (xi ) X (xj )i, compute dot product two data pointsxi xj higher-dimensional space X 0 without requiring explicit computationmapping X . KCCA operates two resulting kernel matrices KX [i, j] =hX (xi ) X (xj )i KY [i, j] = hY (yi ) (yj )i evaluate kernel functionspairwise combinations items training data. returns two sets projection weights,, maximize correlation two (projected) kernel matrices:( , ) = arg max q,0 KX KY(0 K2X + 0 KX )( 0 K2Y + 0 KY )(3)cast generalized eigenproblem (KX +I)1 KY (KY +I)1 KX = 2 ,solved partial Gram-Schmidt orthogonalization (Hardoon et al., 2004; Socher & Li,2010). regularization parameter penalizes size possible solutions, usedavoid overfitting, arises matrices invertible.One disadvantage KCCA requires two kernel matrices trainingdata kept memory training. becomes prohibitive large datasets, cause problems here, since training data consists 6,000items (see Section 4.1).3.2.2 Using KCCA Associate Images SentencesKCCA successfully used associate images (Hardoon et al., 2004; Hwang &Grauman, 2012; Hardoon et al., 2006) image regions (Socher & Li, 2010) individualwords sets tags. case, two original spaces X = = correspondimages sentences describe them. Images first mapped vectors KI (i)whose elements KI (i)(t) = KI (it , i) evaluate image kernel function KI t-thimage Dtrain . Similarly, sentences mapped vectors KS (s) evaluatesentence kernel function KS sentences Dtrain . learned projection weights( , ) map KI (i) KS (s) induced space Z, expect imagesappear near sentences describe well. KCCA-based image annotation862fiFraming Image Description Ranking Tasksearch system, therefore define f cosine similarity (sim) points new space:fKCCA (i, s) = sim(KI (i), KS (s))(4)describe image text kernels used KCCA systems.3.3 Image Kernelscontrast much work done image description, assumes existencelarge number preexisting detectors, image representations used paperbasic, rely three different kinds low-level pixel-based perceptualfeatures capture color, texture (Varma & Zisserman, 2005) shape informationform SIFT descriptors (Lowe, 2004; Vedaldi & Fulkerson, 2008). believeestablishes important baseline, leave question complex imagerepresentations affect performance future work. use two different kinds kernels:histogram kernel K Histo , represents image single histogram featurevalues computes similarity two images intersection histograms,pyramid kernel K Py (Lazebnik, Schmid, & Ponce, 2009), represents imagepyramid nested regions, computes similarity two images termsintersection histograms corresponding regions. cases, compute separatekernel three types image features average result.3.3.1 Histogram Kernel (K Histo )image xi represented histogram Hi discrete-valued features, Hi (v)fraction pixels xi value v. similarity two images xi xj definedintersection histograms, i.e. percentage pixels mappedonto pixel feature value image:K(xi , xj ) =VXmin(Hi (v), Hj (v))(5)v=1combine three kernels based different kinds visual features: KC captures color,represented three CIELAB coordinates. KT captures texture, represented descriptors capture edge information different orientations centered pixel (Varma& Zisserman, 2005). KS based SIFT descriptors, capture edge shape information manner invariant changes rotation illumination,shown distinct across possible objects image Lowe, 2004; Vedaldi & Fulkerson,2008. use 128 color words, 256 texture words 256 SIFT words, obtained unsupervised fashion K-means clustering 1,000 points 200 images PASCAL2008 data set (Everingham et al., 2008). final histogram kernel K Histo averageresponses three kernels KCHisto , KTHisto , KSHisto , taken pth power:p1 XK Histo (xi , xj ) =KFHisto (xi , xj )(6)3F {C,S,T}863fiHodosh, Young & Hockenmaier3.3.2 Pyramid Kernel K Pyspatial pyramid kernel (Lazebnik et al., 2009) generalization histogram kernelcaptures similarities global, also local level. image xirepresented multiple levels scale l (l {0, 1, 2}) level partitionsimage smaller smaller grid Cl = 2l 2l cells (C0 = 1, C1 = 4, C2 = 16),cell c represented histogram Hic . similarity images xi xj level l,Iijl , turn defined sum histogram similarities corresponding cells0l , ..., Cl level:Iijl=Cl XVXmin(Hic (v), Hjc (v))(7)c=0l v=1Although similarities level l subsume fine-grained level l + 1 (IijlIijl+1 ), similarities hold fine-grained level deemed important, sinceindicate greater local similarity. pyramid kernel therefore proceedsfine-grained (l = L) coarsest (whole-image) scale (l = 0), weights1similarities first encountered level l (Iijl Iijl+1 ) 2Ll:KPy(xi , xj ) =IijL+L1Xl=01(I l Iijl+1 )2Ll ij(8)L=1 0 X 1+Il2L ij2Ll+1 ijl=1compute three separate pyramid kernels KCPy , KTPy , KSPy basedcolor, texture SIFT features described above, combine single pyramidkernel K Py , equation 6.3.4 Basic Text Kernelsexamine three different basic text kernels: bag words (BoW) kernel, HwangGraumans (2012) TagRank kernel, truncated string kernel (Tri).3.4.1 Bag Words Kernel (BoW)Since bag-of-words representations successfully used tasks involving textimages (e.g., Grangier & Bengio, 2008; Hardoon et al., 2006), include basic bagwords kernel, ignores word order represents caption simply vectorword frequencies. BoW kernel function defined cosine similaritycorresponding bag words vectors. either merge five captions training itemsingle document (BoW5), reduce training item single, arbitrarily chosen,caption (BoW1). words frequency also reweighted IDF-score.|Dtrain |nearest neighbor approach, IDF-weight word w defined w = log |Dtrain(w)|+1 ,Dtrain (w) subset training images whose captions word w appears least864fiFraming Image Description Ranking Taskonce. found square root w (BoW5IDF-score w (BoW5idf ).idf )give better results standard3.4.2 Tag Rank Kernel (TagRank)Hwang Grauman (2012) apply KCCA keyword-based image annotation retrieval.focus data set image paired list tags ranked importance, propose new kernel kind data. so-called tag rank kernel(TagRank) variant bag words kernel aims capture relative importance tags reweighting according position list. Although HwangGrauman evaluate ability system associate images entiresentences, also consider another data set lists tags correspondwords descriptive captions, argue linear order words captions alsoreflects relative importance corresponding objects image, wordsappear beginning sentence describe salient aspects image.TagRank kernel, sentence represented two vectors, ~a ~r. ~a,weight word based absolute position, first words sentencealways assigned high weight. absolute tag rank representation, captionmapped vector ~a = [~a(1) . . . ~a(|V |)], |V | size vocabulary. ~a(i)depends absolute position pi wi (if wi occurs multiple times s, pi averagedpositions). wi occur s, ~a(i) = 0. Otherwise,~a(i) =1log2 (1 + pi )(9)~r, weight word depends current position compares distribution positions occupies training data. intuition behind relative rankrepresentation words higher weight occur earlier sentence usual. Here, caption mapped vector ~r = [~r(1) . . . ~r(V )] relativetag ranks. Again, wi appear s, ~r(i) = 0. Otherwise wi relative tag rank~r(i) indicates percent occurrences training data appear position pi .DefiningP nik number times word wi appears position k training data,ni = k nik total frequency wi training data:Ppi~r(i) = 1k=1 nik(10)nifinal kernel KT given average two 2 kernels computed ~r ~a (0 normalization terms):"#VV11 X (~ri (k) ~rj (k))21 X (~ai (k) ~aj (k))2KT (xi , xj ) =exp+ exp(11)22~ri (k) + ~rj (k)20~ai (k) + ~aj (k)k=1k=1Since image training data associated multiple, independently generated captions, evaluate kernel separately sentence pair averageresponse, instead treating multiple sentences single document.865fiHodosh, Young & HockenmaierTagRank kernel relatively sensitive overall sentence length, especially casessubject preceded multiple adjectives modifiers (a large browndog vs. dog ). English, absolute tag rank generally assign high weightssubjects sentences, lower weight verbs, even lower weight objects scenedescriptions, tend follow main verb. relative tag rank may downweightverbs, objects scene descriptions much (as long always used similarpositions sentence).3.4.3 Trigram Kernel (Tri)Since bag-of-words representations ignore words appear closesentence, lose important information: image small child red hair playinglarge brown dog white carpet looks quite different one small white dogplaying large red ball brown grass, although descriptions share majoritywords. capture information, define trigram kernel truncated variantstring kernels (Shawe-Taylor & Cristianini, 2004) considers many singlewords two captions share, also many short sequences (pairs triples) wordsoccur both.word sequence w = w1 ...wk ordered list words. sentence = s1 ...sn containsw (w s) long words w appear order specified w. is,sentence large white dog runs catches red ball beach (when lemmatized)contains subject-verb-object triple dog catch ball subject-verb-locationtriple dog run beach. Formally, every substring (i, j) = si ...sj starts si = w1 ,ends sj = wk , contains w considered match w. Ms,w setsubstrings match sequence w:Ms,w = {(i, j) | w = w1 ...wk si ...sj , w1 = si , wk = sj }(12)w restricted individual words (k = 1), string kernels identical standardBoW kernel.match strings s0 pair substrings (i, j) (i0 , j 0 ) s0match word sequence w. Standard string kernels K(s, s0 ) weight matches00factor (ji+1)+(j +1) depends adjustable parameter respectivelength matching substrings:K(s, s0 ) =XXX00(ji+1)+(j +1)(13)w (i,j)Ms,w (i0 ,j 0 )Ms0 ,worder distinguish length matching subsequence, l(w),length gaps (i, j) (i0 , j 0 ), replace two parameters , g , reformulateas:K(s, s0 ) =XXX00+1)2l(w)2l(w)(ji+1)+(jg(14)w (i,j)Ms,w (i0 ,j 0 )Ms0 ,wfound gap score g = 1, means gaps penalized,match score = 0.5 perform best task.866fiFraming Image Description Ranking TaskAlthough string kernels generally defined sequences arbitrary length (k ),found allowing longer sequences seem impact performance taskincurred significant computational cost. Intuitively, word pairs triplets representlinguistic information need capture beyond BoW representation, sinceinclude head-modifier dependencies large-dog vs. small-dog subject-verb-objectdependencies child-play-dog vs. dog-play-ball. therefore consider sequenceslength k 3. w restricted sequences length k 3 ms,w = |Ms,w |,yields following trigram kernel (Tri):KTri (s, s0 ) =Xms,w ms0 ,w 2l(w)(15)w:k3deal differences sentence length, normalize kernel responsetwo examples geometric mean two example responses themselves.Since trigram kernel also captures sequences merely coincidental,large white red, may seem advantageous use richer syntactic representationsdependency tree kernels (Moschitti, Pighin, & Basili, 2008), consider wordtuples correspond syntactic dependencies. However, kernels significantlyexpensive compute, initial experiments indicated may performwell trigram kernel. believe due fact image captionscontain little syntactic variation, hence surface word order may sufficientdifferentiate e.g. agent action (whose mention subjectsentence) participants entities (whose mentions appear verb).hand, many image captions contain lot syntactic ambiguity (e.g.multiple prepositional phrases), vocabulary distinct standardparsers trained on. may able benefit using richerrepresentation simply able recover sufficient accuracy.order capturerelative importance words, also reweight sequencesIDF (or idf) weight theirQwords.w defined before, IDF-weightjsequence w = wi ...wj w =idf-weighted trigram kernel KTriidfk=i wk .(Tri5idf )thereforeKTriidf (s, s0 ) =Xw ms,w ms0 ,w 2l(w)(16)w:k33.5 Extending Trigram Kernel Lexical SimilaritiesOne obvious shortcoming basic text kernels require exact matcheswords, cannot account fact situation, event, entitydescribed variety ways (see Figure 2 examples). One way capturinglinguistic diversity lexical similarities allow us define partial matcheswords based semantic relatedness. Lexical similarity found successtasks, e.g. semantic role labeling (Croce, Moschitti, & Basili, 2011),fully exploited image description. Ordonez et al. (2011) define explicit equivalence classessynonyms hyponyms increase natural language vocabulary correspondingobject detectors (e.g. word Dalmatian may trigger dog detector),867fiHodosh, Young & Hockenmaierchange underlying, pre-trained detectors themselves, ignoring potentialvariation appearance between, e.g., different breeds dog. Similarly, Yang et al.s (2011)generative model produce variety words type detected object scene,given object scene label, word choice independent visual features.therefore also investigate effect incorporating different kinds lexical similaritiestrigram kernel allow us capture partial matches words.explore effect incorporating lexical similarities tag-rank kernel, sinceunclear affect computation ranks within sentence.3.5.1 String Kernels Lexical SimilaritiesSince standard lexical similarities simS (w, wi ) necessarily yield valid kernel functions,follow Bloehdorn, Basili, Cammisa, Moschitti (2006) use similaritiesmap word w vectors w~ N -dimensional space, defined fixed vocabularysize N . vector component w~ (i) corresponds similarity w wi defined:(17)w~ (i) = simS (w, wi )define corresponding word kernel function (w, w0 ), captures partialmatch words w w0 according , cosine angle w~ w~ S0 :(w, w0 ) = cos(~wS , w~ S0 )(18)may defined subset vocabulary. similarity words outsidevocabulary defined identify function, standard string kernel.similarity sequences w w0 length l defined product wordkernels corresponding pairs sequence elements wi , wi0 :(w, w0 ) =l(wi , wi0 )(19)i=1(w) = {w0 |S (w0 , w) > 0, l(w0 ) = l(w)} set sequences non-zeromatch w, string kernel KS similarity is:KS (s, s0 ) =XXms,w ms0 ,w0 2l(w)(w0 , w)(20)w w0 (w)idf0obtainIDF-weighted version kernel, KS (s, ), inner term multiplied w w0 :X X pKS (s, s0 ) =w w0 ms,w ms0 ,w 2l(w)(w0 , w)(21)w w0 (w)experiments, use trigram variants kernels, restrict wsequences length k 3.consider three different kinds lexical similarities: WordNet-based Lin similarity(Lin, 1998) (Lin ), distributional similarity metric (D ), novel alignment-based868fiFraming Image Description Ranking Tasksimilarity metric (A ), takes advantage fact image associatedfive independently generated captions. metrics computed training corpus.Distributional similarity also computed British National Corpus (BNC Consortium,2007). corpora lemmatized, stop words removed similaritiescomputed. Since almost pair words non-zero similarity, word kernelmatrices dense, since similarities close zero,little effect resulting kernel. therefore zero entries smaller 0.05alignment-based kernel less 0.01 distributional kernel DC .3.5.2 Lin Similarity Kernel (Lin )Lins (1998) similarity relies hypernym/hyponym relations WordNet (Fellbaum,1998) well corpus statistics. WordNet directed graph nodes (synsets)represent word senses edges indicate is-a relations: parent sense (e.g., dog1 )hypernym children (e.g., poodle1 dachshund1 ). Kernels based Lins similarityfound perform well tasks text categorization (Bloehdorn et al., 2006).exception Farhadi et al. (2010), incorporate Lins similaritymodel, evaluate benefit obtain it, WordNets hypernym-hyponymrelations used superficially associating images text (Weston et al.,2010; Ordonez et al., 2011; Gupta et al., 2012). Lin similarity two word senses si , sjdefined2 log P (LCS(si , sj ))simLin (si , sj ) =(22)log P (si ) + log P (sj )LCS(s1 , s2 ) refers lowest common subsumer s1 s2 WordNet, i.e.specific synset ancestor (hypernym) s1 s2 . P (s) probabilityrandomly drawn word instance synset descendants (hyponyms).use training data estimate P (s), follow Bloehdorn et al. (2006) assigningword w frequent (first) noun sense sw WordNet 3.0. Hence, representword w WordNet sense vector w~ Lin Lin similarities hypernyms H(sw ):2log(f (si ))log(f (s))+log(f (si ))w~ Lin (i) =10si H(s)sw = siotherwise(23)3.5.3 Distributional Similarity (DC )Distributional similarity metrics based observation words similartend appear similar contexts (Jurafsky & Martin, 2008). componentsw~ DC non-negative pointwise mutual information scores (PMI) w wi , computedcorpus C:PC (w, wi )(24)w~ DC (i) = max 0, log2PC (w)PC (wi )PC (w) probability random sentence C contains w, PC (w, wi )probability random sentence C contains w wi . compute two variants869fiHodosh, Young & Hockenmaiermetric: Dic computed image captions training corpus,defined cooccurrences 1,928 words appear least 5 times corpus,DBNC uses British National Corpus (BNC Consortium, 2007), defined1,874 words appear least 5 times corpora, considers PMI scores141,656 words appear least 5 times BNC.3.5.4 Alignment-Based Similarity (A )also propose novel, alignment-based, similarity metric (A ), takes advantagefact image associated five independently generated captions,specifically designed capture likely two words describe evententity data set. borrow concept alignment machine translation(Brown, Pietra, Pietra, & Mercer, 1993), instead aligning words sentences twodifferent languages, align pairs captions describe image. resultssimilarity metric better coverage data set WordNet based metrics,much specific distributional similarities capture broad topical relatednessrather semantic equivalence. Instead aligning complete captions, foundbeneficial align nouns verbs independently other, ignore partsspeech. create two versions training corpus, one consisting nounscaption, another one consisting verbs caption.use Giza++ (Och & Ney, 2003) train IBM alignment models 12 (Brown et al., 1993)pairs noun verb captions image obtain two sets translationprobabilities, one nouns (Pn (|w)) one verbs (Pv (|w)). Finally, combinenoun verb translation probabilities sum weighted relative frequencyword w tagged noun (Pn (w)) verb (Pv (w)) training corpus.ith entry wA therefore:w~ (i) = Pn (wi |w)Pn (w) + Pv (wi |w)Pv (w)(25)define noun verb vocabulary follows: words appear least 5 timesnoun, tagged noun least 50% occurrences, considerednouns. since verbs polysemous nouns (leading broader translationprobabilities) often mistagged nouns domain, include wordsverbs tagged verbs least 25 times, least 25% occurrences.results 1180 noun 143 verb lemmas, including 11 nouns verbs.use OpenNLP POS tagger lemmatization.3.5.5 Comparing Similarity Metrics (Figure 3)Figure 3 illustrates different similarity metrics, using words rider swimexamples. distributional similarities high words topically related(e.g., swim pool ), alignment similarity tends high words useddescribe entity (usually synonyms hyper/hyponyms) activity swimpaddle. Distributional similarities obtained image captionsspecific domain. BNC similarities much broader help overcome datasparsity, although BNC relatively low coverage kinds sports occurdata set. Lin similarity associates swim hypernyms sport activity,870fiFraming Image Description Ranking TaskComparing similarity metrics: five words similar rider swimAlignmentStrainwiwiriderbikerbicyclistcyclistbmxbicycler0.860.820.790.750.73bikedirtmotocrossmotorcycleride0.410.350.330.330.33ridehorseracebikejockeyswimretrievepaddledivecomewade0.560.540.520.380.31pooltrunkwaterdivegoggles0.530.350.340.300.29fishwaterseapoolbeachCorpuswDistributionalStrainBNCDic wiDBNCLinStrainwiLin0.210.200.190.170.16travelercyclistbicyclisthorsemanjockey0.940.890.890.840.840.210.180.180.180.17bathesportfootballactivitysoccer0.850.850.770.750.73Figure 3: comparison lexical similarities noun rider verb swimkinds sport football soccer. makes least suitable similaritytask (see also Section 4.3.4 experimental results), since termsconsidered similar purposes identifying different ways visually similarevents entities described.3.5.6 Combining Different SimilaritiesCombining different distributional alignment-based similarities allows uscapture different strengths method. define averaged similaritycaptures aspects distributional similarities computed corpora:DBNC (w, w0 ) + Dic (w, w0 )(26)2every distributional kernel (w, w0 ), also define variant D+A (w, w0 )incorporates alignment-based similarities taking maximum either kernel:4DBNC,ic (w, w0 ) =D+A (w, w0 ) = max(A (w, w0 ), (w, w0 ))(27)4. Evaluation Procedures Metrics Image Descriptionorder evaluate scoring functions f (i, s) image-caption pairs, need evaluateability associate previously unseen images captions other. analogycaption generation systems, first examine metrics aim measure qualitysingle image-description pair (Section 4.2). Here, focus image annotation task,restrict attention first caption returned test item, subsetsystems. collect graded human judgments small number native speakersAmerican English, investigate whether expert judgments approximated4. operation may preserve positive definiteness matrix required valid kernel,simply means effectively use (plain) CCA representation.871fiHodosh, Young & Hockenmaierautomatically computed Bleu (Papineni et al., 2002) Rouge (Lin & Hovy, 2003)scores, simpler crowdsourced human judgments collected muchlarger scale. Section 4.3, consider approaches evaluation aim measurequality ranked list image-caption pairs returned system, allow usevaluate large number systems. reasons space, focus discussionsubset systems, refer interested reader Appendix Bcomplete results. Since candidate pool contains one sentence image originallyassociated query image sentence, first compare systems rank recalloriginal item. metrics computed automatically,considered lower bounds actual performance, since image may associatednumber captions describe well perhaps minor errors. showcrowdsourced human judgments mapped binary relevance judgmentscorrelate well fine-grained expert judgments, consider metrics basedrelevance judgments.4.1 Experimental Setupdescribe data, tasks, systems evaluate experiments.4.1.1 DataSince PASCAL 2008 data set contains total 1,000 images, performexperiments exclusively Flickr 8K set. split 8,000 images corpus (seeSection 2.3) three disjoint sets. training data Dtrain = hItrain , Strain consists6,000 images, associated five captions, whereas test development data,Dtest Ddev , consist 1,000 images associated one, arbitrarily chosen, caption.captions preprocessed spellchecking Linux spell, normalizing compound words(e.g., t-shirt, shirt, tee-shirt t-shirt), stop word removal, lemmatization.4.1.2 Tasksevaluate systems two tasks, sentence-based image annotation (or description)sentence-based image search. image search, task return ranked list1,000 images Itest captions (queries) Stest . Image annotation definedanalogously retrieval problem: task return ranked list 1,000 captionsStest 1,000 test (query) images Itest . cases, ranked listsproduced independently 1,000 possible queries.4.1.3 Systemstotal 30 different systems, uses either nearest-neighbor approachKCCA, paired different combination image text representations.purposes discussing different evaluation metrics, focus small numbersystems: best-performing nearest-neighbor-based system, NN (NN5idfF1 ),small number KCCA-based systems different text kernels: BoW1 BoW5use simple bag-of-words kernel. TagRank usesHwang Graumans (2012)idfkernel, Tri5 uses trigram kernel, Tri5Sem (Tri5A,DBNC+ic Appendix B) uses872fiFraming Image Description Ranking Taskidf-reweighted trigram kernel distributional alignment-based similarities.exception BoW1, arbitrarily selected single captiontraining image, models use five captions training images. BoW5,merge single document. cases, follow Moschitti (2009)sum kernel responses cross product sentences normalization.systems (including NN) use pyramid kernel image representation.large-scale evaluations Section 4.3, scores models given Appendix B.systems use Hardoon et al.s (2004) KCCA implementation, allows usvary regularization parameter . also vary n, number dimensions (largesteigenvalues) learned projection allowable values parameters basedearly exploratory experiments. experiments reported paper, sampled4 possible values (0.1, 0.5, 1, 5), n chosen 46 possible values range(10, 6000). two additional parameters fixed advance textimage kernel pair: image kernels either squared cubed, text kernelsregularized multiplying values diagonal factor range (1, 15).kernel two tasks (image annotation search), usedevelopment set pick five settings n maximize recall originalitem first result, five settings maximize recall among first five results,five settings maximize recall among first ten results, yielding total 15different models pair kernels task. query image (annotation)caption (search) test set, 15 models returns ranking 1,000 testitems (sentences images). combine 15 rankings, use Borda counts (van Erp &Schomaker, 2000), simple, deterministic method rank aggregation: N itemsranked, system assigns score N r item ranks position r = 0...N 1,final rank item determined sum scores across systems.break ties items median ranks across models.4.2 Metrics Quality Individual Image-Caption Pairsconsider metrics consider quality ranked list results (Section 4.3),first examine metrics measure quality individual image-caption pairs.4.2.1 Human Evaluation Graded Expert JudgmentsExpert scores decision well caption describes image ultimately requireshuman judgment. caption generation task, number different evaluation schemesproposed image description: Ordonez et al. (2011) presented judgescaption produced model asked make forced choice randomimage image caption produced for, Kuznetsova et al. (2012) asked judgeschoose captions two models given test image. forcedchoice tasks may give clear ranking models, cannot compared across differentexperiments unless output system made publicly available. One advantageframing image description ranking task different systems compareddirectly test pool. Forced choice evaluations also directly measurequality captions. Following common practice natural language generation, Yanget al. (2011) Kulkarni et al. (2011) evaluated captions graded scale relevance873fiHodosh, Young & Hockenmaier... describes imagewithout errors(score = 4)selected caption ...... describes imageminor errors(score = 3)... somewhatrelated image(score = 2)... unrelatedimage(score = 1)girl wearingyellow shirtsunglasses smiles.man climbssheer wallice.Miami basketballplayer dribblesArizona State player.group peoplewalking city streetwarm weather.boy jumpsblue poolwater.dog grassy field,looking up.Basketball playersaction.man riding motorbike kicks dirt.Dogs pullingsledsled race.Two little girlspractice martialarts.snowboarderair snowymountain.child jumpingtennis court.boy blue lifejacket jumpswater.black dogpurple collarrunning.Figure 4: 14 rating scale fine-grained expert judgments, actual examplesreturned best model (Tri5Sem)readability, Li et al. (2011) added creativity score, Mitchell et al. (2012)compared systems based whether captions describe main aspects images,introduce objects appropriate order, semantically correct, seemedwritten human.Since captions test pool produced people, need evaluatelinguistic quality, focus semantic correctness. order obtainfine-grained assessment description quality, asked three different judges score imagecaption pairs returned systems graded scale 1 4. judges 21adult native speakers American English, mostly recruited among local graduatestudent population. contrast anonymous crowdsourcing-based evaluation describedSection 4.3.2, refer experts. rating scale illustrated Figure 4actual examples returned models. score 4 means caption describesimage perfectly (without mistakes), score 3 caption almost describesimage (minor mistakes allowed, e.g. number entities), whereas score2 indicates caption describes aspects image, couldused description, score 1 indicates caption bears relationimage. online appendix paper contains annotation guidelines. Annotatorstook average ten minutes per 50 image-caption pairs, image-caption pairsjudged independently three different annotators. Inter-annotator agreement, measuredKrippendorffs (2004) , high ( = 0.81) (Artstein & Poesio, 2008). final scoreimage-caption pair obtained averaging three individual scores. Sincetime-consuming evaluation, judged highest-ranked captiontest image annotation task, focused subset models describedabove. gauge difficulty task data set, also include randombaseline. Since evaluate single caption image, interestedpercentage images suitable caption returned. therefore showmodels cumulative distribution test items scores thresholds ranging874fiFraming Image Description Ranking TaskQuality first caption (image annotation)Cumulative distribution expert scores (% X)= 4.0 3.66 3.33 3.0 2.66 2.33 2.00.5 0.63.4 4.1BoW16.6 8.1BoW59.711.8TagRank 9.612.30.75.29.913.614.21.18.518.319.821.11.511.422.924.725.82.916.329.733.032.97.827.144.246.946.2Tri5Sem 11.015.723.028.136.953.0RandomNN13.3Table 1: Cumulative distribution expert judgments 14 scale (Figure 4), indicatingpercentage image-caption pairs judged given score. Scoresaveraged three judges. Superscripts indicate statistically significant differenceTri5Sem ( : p 0.1, : p 0.05, : p 0.01).4.0 2.0. threshold interpreted less strict mappingfine-grained scores binary relevance judgments. order assess whether differencemodels given threshold reaches statistical significance, use McNemarssignificance test, paired, non-parametric test advocated evaluationbinary classifiers (Dietterich, 1998). Given output models Bset items, McNemars test considers items Bs output differ (thediscordant pairs output) test null hypothesis outputs drawnunderlying population. Among discordant pairs, compares proportionitems model successful model B proportion itemsModel B successful model not. results tables, superscripts indicatewhether difference model Tri5Sem statistically significant ( : p 0.1,: p 0.05, : p 0.01) .Expert results (Table 1) first interpret expert scores binary relevancejudgments, therefore show cumulative distribution different thresholds in.see clear differences random baseline, NN, KCCA modelsthresholds. differences NN random model, wellKCCA model NN highly significant (p < 0.001) threshold. randombaseline returns perfect caption 0.5% images, good caption (assumingthreshold 2.66) 1.5% images, best KCCA model, Tri5Sem, returnsperfect caption 11.0% good caption 28.1% images. However,differences among KCCA models subtle, may become apparentlower thresholds. significant difference BoW5 TagRankthreshold, significantly better BoW1 (p < 0.001) thresholds3.33 above. Tri5Sem outperforms models, differences BoW5TagRank reach statistical significance threshold consideredsuitable caption lowered either 3.33 (p = 0.06) 3.0 (p = 0.01), 2.66 (p = 0.08)2.33 (p = 0.005). lack statistical significance partially explainedfact McNemars test relatively low power percentage itemstwo models successful low, case higher thresholds here.875fiHodosh, Young & Hockenmaiershow Sections 4.3.1 4.3.2 significant differenceTri5Sem two models image annotation extend analysisbeyond highest-ranked caption. shows evaluations basedsingle caption returned per image may fail uncover significant differences modelsbecome apparent multiple results considered. may also importantconsider performance annotation retrieval. image retrieval task,see Tri5Sem significantly outperforms models even firstresult considered. Table 1 also reveals another artefact McNemars test: sincebased absolute differences performance number discordant pairs,difference BoW1 Tri5Sem thresholds 2.66 2.0 considered lesssignificant BoW5 Tri5Sem thresholds, even thoughBoW1s scores lower BoW5s. Table 2, present systems average expertscores, use Fishers Randomization Test determine statistical significance. Accordingevaluation, Tri5Sem significantly better models (p 0.0001cases), since average score Tri5Sem 2.08, difference reflectedhigher thresholds cumulative distribution shown Table 1.4.2.2 Automatic Evaluation Bleu RougeSince human judgments expensive time-consuming collect, examinewell approximated Bleu (Papineni et al., 2002) Rouge (Lin, 2004),two standard metrics machine translation summarization.Bleu Rouge scores Bleu Rouge scores computed automaticallynumber reference captions, used evaluate number captiongeneration systems (Kulkarni et al., 2011; Ordonez et al., 2011; Li et al., 2011; Kuznetsovaet al., 2012; Yang et al., 2011; Gupta et al., 2012), although unclear wellcorrelate human judgments task.Given caption image associated set reference captions Ri ,Bleu score proposed image-caption pair (i, s) based n-gram precisionRi , Rouge based corresponding n-gram recall. commonimage description, consider unigram-based scores (only 3.5% possible imagecaption pairs test non-zero bigram-based Bleu-2 score, 39.4% setnon-zero Bleu-1 score). also ignore Bleus brevity penalty, since data setrelatively little variation sentence length, would like avoid penalizing short,generic captions include details otherwise correct. Hence, cs (w)number times word w occurs s:PBleu(i, s) =Rouge(i, s)=min(cs (w),maxrRi cr (w))Pws cs (w)PPmin(cs (w),cr (w))rRiP wrPrRwr cr (w)ws(28)reference candidate captions preprocessed. first tokenize sentencesOpenNLP5 tools. break hyphenated words, stripping non-alphanumeric5. http://opennlp.apache.org876fiFraming Image Description Ranking TaskAvg. score first caption(image annotation)ExpertBleuRougeBoW1BoW5TagRank1.221.571.901.981.990.310.350.430.460.460.040.110.140.150.15Tri5Sem2.080.480.17RandomNNTable 2: Comparison averaged scores according 4-point expert evaluation (Figure 4), Bleu Rouge, using five test captions reference. Superscripts indicatestatistically significant difference Tri5Sem ( : p 0.1, : p 0.05, : p 0.01).hyphen characters, converting words lower case. Following work Lin(2004), use stemmer (Porter, 1980) remove stopwords compute Rougescores. compute Bleu Rouge score system average BleuRouge scores items test set.6use Fishers Randomization Test (Fisher, 1935; Smucker, Allan, & Carterette, 2007)assess statistical significance difference models. paired,sampling-based test evaluates null hypothesis results modelsB produced underlying distribution. sample, scoresB assign test item randomly reassigned two models, p-valuesobtained comparing actual difference Bs performancefraction samples equal greater difference models. sample 100,000reassignments entire test set.Bleu Rouge results (Table 2) Table 2 shows average Bleu Rouge scoreshighest ranked caption pairs returned image annotation systems, computedreference pool consisting five original captions test image (includingcaption randomly selected part candidate pool). scoreslead broad conclusions average expert scores: metrics find cleardifferences (p < 0.0001) random baseline models,well NN KCCA models, none find significant differenceBoW5 TagRank. Tri5Sem outperforms KCCA models accordingmetrics, expert evaluation Rouge find much larger differenceBoW5 (Experts: p 0.0001, Rouge: p < 0.001) TagRank (Experts: p = 0.001,Rouge: p = 0.005). Bleu finds significant difference TagRank (p < 0.05),BoW5 (p < 0.05), indicates Bleu may less well suited identifysubtle differences systems.Agreement Bleu Rouge expert scores Since difficult measuredirectly well Bleu Rouge scores agree expert judgments, consider6. systems Bleu score usually computed corpus level, since dealingunigram scores evaluate systems sentences corpus, averaged sentence-levelBleu scores systems report almost identical (r > 0.997) corpus-level Bleu scores.877fiHodosh, Young & Hockenmaiernumber different relevance thresholds type score (B , R , E ), turnbinary relevance judgments. allows us use Cohens (1960) measureagreement corresponding binarized scores. Since Bleu Rougerequire set reference captions test image, compare four different waysdefining set reference captions (for detailed scores, see Tables 8 9 appendix).Since data set contains multiple descriptions image, first use fivecaptions reference. setting, Bleu reaches best agreement ( = 0.72)E = 4.0 B = 1.0 E 3.6 B 0.8. However, high Bleuscores generally obtained system proposes original caption. Rougemuch lower agreement ( = 0.54) expert scores, obtained R 0.4 vs.E 4.0 E 3.6, R 0.3 E 3.0. Since data sets mayone caption per image, also evaluate reference corpus consistssingle caption test pool. case, metrics reach highestagreement expert threshold E = 4.0 (Bleu: = 0.71, Rouge: = 0.69),thresholds B 0.8, R 0.9. conclude neither Bleu Rougeuseful scenario, since require high thresholds captureoften system returned reference caption.Bleu Rouge used evaluate caption generation systems, cannotassume generated caption identical one reference captions. thereforeexamine extent Bleu Rouge scores agree human judgmentscandidate pool contains human generated captions, disjoint reference captions. first use reference corpus four captions per image, excluding captionuse candidate pool. case, three metrics show significantly lower agreementhuman judgments candidate pool contains reference caption. Bleureaches = 0.52 (with B 0.7 E 3.3) Rouge reaches = 0.51(with R 0.2 E 2.6). simulate case single caption perimage available, also evaluate reference corpus consisting onefour captions. case, agreement human judgments even lower: Bleu reaches= 0.36, Rouge reaches = 0.42. results suggest Bleu Rougeappropriate metrics pool candidate captions contain referencecaptions, lead us question usefulness evaluation caption generationsystems. consistent findings Reiter Belz (2009), studiedBleu Rouge scores evaluate natural language generation systems, concludedmay useful metrics fluency, poor measures content quality.4.3 Metrics Large-Scale Evaluation Image Description SystemsMetrics consider first caption returned image cannot capture factbetter model score good captions higher captions, even failsconsider best possible caption. Since systems return ranked list resultsitem, examine metrics allow us evaluate quality list.contrast human evaluations described Section 4.2 above, also evaluateimage retrieval systems. first consider metrics computed automatically:recall median rank item (image sentence) originally associatedquery sentence image (Section 4.3.1). show use crowdsourcing878fiFraming Image Description Ranking TaskPerformance: Rank original itemR@k: percentage queries original item among top X responses.Median r: median rank original itemR@1Image annotationR@5 R@10 Median rBoW1BoW5TagRankTri52.54.86.26.07.17.613.517.117.017.29.719.724.323.823.7Tri5Sem8.321.630.3NN251.064.058.056.053.034.0R@1Image retrievalR@5 R@10 Median r2.54.55.85.46.04.714.316.717.417.87.220.823.624.326.27.620.730.1272.067.060.052.555.038.0Table 3: Model performance measured rank original image caption (=correct response). R@k: percentage queries correct response amongfirst X results. Median r: Median position correct response ranked listresults. Superscripts indicate statistically significant difference Tri5Sem ( : p 0.05,: p 0.01).collect large number human judgments (Section 4.3.2), use relevancejudgments define two additional metrics: rate success, akin recall,R-precision, established information retrieval metric (Section 4.3.3). Althoughmetrics allow us evaluate systems, focus discussion small setsystems considered far, refer interested reader Section B appendixscores systems.4.3.1 Recall Median Rank Original ItemOne advantage ranking framework position original caption imageamong complete list 1,000 test items determined automatically. Since bettersystem should, average, assign higher rank original items worse system,use ranks define number different evaluation metrics.Recall (R@k) median rank scores Since query associatedsingle gold result, need concerned precision. However, recall position k(R@k), i.e. percentage test queries model returns original item amongtop k results, useful indicator performance, especially context search,user may satisfied first k results contain single relevant item. focusk = 1, 5, 10 (R@1, R@5, R@10). Since binary metric (for query, gold itemeither found among top k results not), use McNemars test identifystatistically significant differences models. Conversely, median rank indicatesk system recall 50% (i.e. number results one wouldconsider order find original item half queries). Here, use Fishersrandomization identify significant differences models.Recall (R@k) median rank results (Table 3) results Table 3 confirmearlier observation NN baseline clearly beaten KCCA models (p < 0.001metrics models, except R@1 search, difference BoW1879fiHodosh, Young & Hockenmaierp-value p < 0.01). Since R@1 annotation scores based image-captionpairs expert scores Table 1, compare directly. differenceR@1 expert scores, even strictest threshold 4.0 experts, indicatesmeasures capture often original caption returned viewedlower bound actual performance: Tri5Sem returns original caption first8.3% images, human judges found captions describe 11.0%images without errors. discrepancy even larger BoW5 (6.2% vs. 9.7%)TagRank (6.0% vs. 9.6%). consequence, automatically computed R@1 scoresindicate erroneously statistically significant difference qualityfirst captions returned Tri5Sem returned BoW5 TagRank, eventhough differences significant according human evaluation. However,metrics based first caption may fail identify differencesmodels become apparent metrics. example, R@1 revealssignificant difference Tri5 Tri5Sem annotation task, althoughdifference highly significant according metrics. Section 4.3.3, presentresults large-scale human evaluation confirm actual differencesTri5Sem Tri5 annotation identified first captiontaken account.Table 11 Section B provides recall median rank scores models.4.3.2 Collecting Binary Relevance Judgments Large Scaleorder perform human evaluation system goes beyond measuring qualityhighest ranked result, would obtain relevance judgments imagecaption pairs among top k results query. Since two tasks,total 30 different systems, set consists 113,006 distinct image-caption pairsk = 10, rendering exhaustive evaluation four-point scale described Section 4.2.1infeasible. therefore needed reduce total number judgments needed,define simpler annotation task could completed less time. Crowdsourcingplatforms Amazon Mechanical Turk offer new possibilities evaluationenable us collect large number human judgments rapidly inexpensively,number researchers evaluated caption generation systems Mechanical Turk(Ordonez et al., 2011; Yang et al., 2011; Kuznetsova et al., 2012; Kulkarni et al., 2011; Liet al., 2011). experiments performed scale analysis,also evaluated well crowdsourced judgments task approximateobtained smaller pool judges given detailed instructions.examine whether crowdsourcing allows us collect reliable relevance judgmentslarge scale evaluation image description systems.crowdsourcing task presented workers images paired tendifferent captions, asked indicate (via checkboxes) captions describeimage. adapted guidelines developed fine-grained annotationcaption describes image minor errors (corresponding score 34-point scale) would still permitted receive positive score. guidelines alsofound online appendix paper. individual task consisted six differentimages, paired ten captions, included copy guidelines. accessed880fiFraming Image Description Ranking TaskAmazon Mechanical Turk service provided Crowdflower.com, makeseasy include control items quality control. One six images taskcontrol item, generated taking random images developmentset, using one three original captions correct responses, addinganother nine seven randomly selected captions (which verified manuallydescribe image) incorrect responses. used workers judged 70%control items correctly. image-caption pair annotated three differentannotators (at total cost 0.9), final score image-caption paircomputed average number positive judgments received.Filtering unlikely image-caption pairs order reduce number annotationsneeded, devised filter based Bleu scores (Papineni et al., 2002) filter imagecaption pairs whose caption dissimilar five captions originally writtenimage highly unlikely describes image. found filter basedunigram Bleu-1 scores combination stemming stop word removalstandardly done Lins (2004) Rouge script (Bleupre ) proved particularly effective:threshold Bleupre 0.25 filters 86.0% possible (1,0001,000) image-captionpairs test set, eliminates 6.7% pairs expert score 2 32greater, 3.5% pairs expert score 3 greater. slightly higher cutoffBleupre 0.26 would filter 90.4% image caption pairs, discard 12.3%image-caption pairs expert score 2 23 7.5% image-caption pairsexpert score 3. Among 113,006 image-caption pairs actually wishedobtain judgments for, 0.25 filter eliminates 72.8%, reducing number pairsneeded annotate 30,781. Since setup required us pair image numbercaptions multiple 10, also annotated additional 10,374 image captionpairs filtered out, allowing us evaluate performance filter.98.3% filtered pairs, Mechanical Turk judges decided captiondescribe image, 99.8% them, majority annotators thought so. alsofound standard Bleu-1 without preprocessing effective filter: thresholdBleu 0.330 misses 6.9% good captions (with expert score 2 23 ),filtering 55% entire data set, whereas threshold Bleu 0.333 filters65% entire data set, misses 11.9% good captions.Agreement crowdsourced expert judgments use Cohensmeasure agreement crowdsourced expert judgments (Table 10appendix). best agreement obtained crowdsourced scores threshold0.66 (i.e. least two three judges think caption describes image)expert scores threshold 3.33 (one expert thinks caption describesimage perfectly two agree think describes image minorerrors, two experts think describes image perfectly one thinksleast related). = 0.79, significantly better approximation expertscores possible either Bleu Rouge. also examine precision, recallf-scores approximate relevance judgments achieve comparedrelevance judgments obtained binarizing expert judgments (Table 10). 98.6%items perfect expert score (and 95.0% items almost perfect expertscore 3.7) identified, least 94.7% items pass threshold881fiHodosh, Young & Hockenmaierexpert score 2.7 greater (i.e. majority experts agreed caption describesimage perfectly minor errors). Using threshold 0.66 adds 2,031 suitableimage-caption pairs 1,000 test images paired original caption. Among1,000 test captions, 446 still describe single image, 202 describe two test images, 100three, 252 describe four images. Among 1,000 test images, 331single (i.e. original) caption, 202 two possible captions, 100 three possiblecaptions, 317 four captions.4.3.3 Large-Scale Evaluation Relevance Judgmentscrowdsourced relevance judgments allow us define two new metrics, ratesuccess (S@k) R-precision. believe R-precision reliable indicatoroverall performance, since summarizes human judgments single numberdepend arbitrary cutoff. therefore use Section 4.3.4 in-depthanalysis impact different linguistic features models incorporate. S@krate success scores motivated fact search engines commonly return multipleresults once. Since users may satisfied long results contain least onerelevant item, S@k scores provide direct measure utility hypothetical users.Rate success (S@k) scores rate success metric (S@k) analogousrecall-based R@k-scores used Table 3, intended measure utilitysystem hypothetical user. indicates percentage test items leastone relevant result found among highest ranked k results. Following analysisSection 4.3.2, image-caption pair considered relevant majority judges saycaption describes image.Rate success results (Table 4) Table 4 confirms NN performs clearlyworse KCCA models. differences Tri5Semmodels shown Table 4 highly statistically significant (p < 0.001) metrics exceptS@1 annotation scores, where, agreement expert scores Table 1,differences NN BoW1 significant. unclear quality firstcaption Tri5Sem returns annotation significantly better returnedmodels, since outperforms metrics. S@k scoresTable 4 indicate Tri5Sem returns relevant caption among top 10 responses49.1% images, relevant image 48.5% captions. comparisonexpert scores Table 1 shows S@1 annotation scores lie expert scoresthreshold 3.66 3.0, comparison R@k results Table 3 showsS@1 scores least twice high corresponding R@1 scores. is,highest ranked response often relevant item originally associatedquery original gold item itself.R-precision scores Given crowdsourced relevance judgments, test image mayassociated multiple relevant captions, test caption maydeemed relevant multiple images besides one originally written for.queries variable number relevant answers, performance retrieval systemscommonly measured terms R-precision (Manning, Raghavan, & Schtze, 2008). UnlikeS@k scores, metric depend arbitrary cutoff, summarizes882fiFraming Image Description Ranking TaskRate success (S@k)(Percentage items relevant response among top X results)Image annotationS@1S@5S@10Image retrievalS@1S@5S@10BoW1BoW5TagRankTri55.812.215.016.216.415.430.334.134.232.920.239.742.742.943.45.011.412.112.413.113.330.531.531.533.118.440.240.841.643.8Tri5Sem16.637.749.115.736.948.5NNTable 4: rate success (S@k) indicates percentage test items top Xresults contain least one relevant response. Superscripts indicate statistically significantdifference Tri5Sem ( : p 0.1, : p 0.05, : p 0.01)R-precisionAnnotationNNSearchTotalBoW1BoW5TagRankTri55.210.711.111.711.63.89.610.510.511.04.510.110.811.111.3Tri5Sem13.713.413.5Table 5: Model performance measured R-precision, statistically significant differences Tri5Sem ( : p 0.1, : p 0.05, : p 0.1)performance system single number, allowing us rank models accordingoverall performance (see Section 4.3.4 below). S@k scores measurewhether least one relevant items ranked highly, R-precision requires relevantitems ranked highly. therefore better indicator quality mappingimages sentences, since better mapping prefer relevant captionsimages irrelevant caption image.R-precision system query qi ri known relevant items test datadefined precision rank ri (i.e. percentage relevant items among top riresponses returned s). R-precision obtained averaging test queries.use Fishers randomization test assess whether differences modelsreaches statistical significance.R-precision results (Table 5) Table 5 gives R-precision model typesused collecting expert judgments (Section 4.2.1). see nearest neighborbaseline clearly KCCA models (p < 0.001). R-precision indicateslittle difference BoW1, BoW5 TagRank terms overall performance. Although TagRank Tri5 outperform BoW1 slightly search (p = 0.062),statistically significant difference among three models BoW1Tri5 search (p = 0.01). contrast human evaluation considered883fiHodosh, Young & HockenmaierR-precisionTri5Ann. Search+IDFAnn. SearchAnn.+AlignSearch+Align&IDFAnn. SearchTri511.611.012.5ii11.313.4aaa12.3aa13.4a13.2aaa,ii+DBNC+Dic+DBNC+ic12.7dd12.7dd12.5dd12.1dd12.8ddd12.7ddd12.912.813.3d12.2ddd13.1ddd13.0ddd13.213.013.4aa12.8a12.813.2dd12.913.313.712.9a13.413.4Table 6: effect adding IDF weighting (i), alignment-based similarities (a) distributional similarities (d) Tri5 model. bolded scores indicate Tri5 (top left)Tri5Sem (Tri5 +Align&IDF+DBNC+ic ; bottom right). Superscripts indicate statisticallysignificant differences result addition corresponding feature (x : p 0.1,xx : 0.05, xxx : p 0.01). Dc = distributional similarities computed corpus c (theBNC, training corpus image captions (ic), both)first result (Table 1), Tri5Sem clearly outperforms models annotationretrieval (for differences p 0.0001). Table 12 Appendix B shows scoresmodels.4.3.4 Measuring Impact Linguistic Features (Table 6)results presented far indicate clearly Tri5Sem outperforms simpler Tri5model, considered impact individual text features distinguishtwo models. Since R-precision summarizes performance system singlenumber, allows us easily perform analysis.Using R-precision model comparison Table 6 shows results ablationstudy compares R-precision Tri5 Tri5Sem trigrambased KCCA models use subset Tri5Sems additional features. basic Tri5model yields bolded scores shown top left corner. Tri5Sems scores givenbottom right corner. top row contains models capture distributionalsimilarities, bottom three rows corresponds addition one kinddistributional similarity (computed BNC, image captions trainingcorpus, corpora) corresponding model top column. first columncontains models capture IDF reweighting alignment-based similarities.second column corresponds addition IDF reweighting models firstcolumn, third column adds alignment-based similarities models firstcolumn. last column adds IDF-reweighting alignment-based similarities,scores compared second third column. Superscripts indicate addition particular feature leads statistically significant improvementmodel include feature otherwise identical. is,superscripts show addition distributional similarity metric leads significant improvement model top cell column. superscriptsindicate addition IDF reweighting leads significant improvementcorresponding model without IDF reweighting immediately preceding cell884fiFraming Image Description Ranking Taskrow. superscripts third column show addition alignment-basedsimilarity leads significant improvement model without IDF reweighting shownfirst column row, superscripts fifth column showaddition alignment-based similarity model IDF reweighting shownsecond column row leads significant improvement.impact IDF weighting, distributional alignment-based similaritiesIDF weighting almost always beneficial, improvements obtained addingIDF weighting given text kernel reach statistical significance (indicated superscripts Table 6) two cases: performance basic Tri5 model imageannotation, performance alignment-based Tri5 model image search.contrast, adding lexical similarities leads almost always significant highly significantimprovement. Distributional similarities (d superscripts) beneficial basicTri5 model tasks, help IDF weighted Tri5 model image search. Distributional similarities computed corpora also significantly improve performancealignment-based Tri5 model incorporate IDF weighting. Addingalignment-based Tri5 model without IDF weighting leads improvementsearch (while helping slightly decreasing performance annotation, albeitsignificantly so). improvements search reach statistical significancesimilarities computed corpora added. Conversely, adding alignment-basedsimilarities non-IDF weighted Tri5 model distributional similaritiescorpora leads significant improvement annotation. Finally, top cell lastcolumn shows adding alignment-based similarities IDF-weighted Tri5 modelleads significant improvement tasks, although impact search evengreater. Comparing models performance alignment-based Tri5 model withoutIDF weighting shows case, IDF weighting helps search. bottomcells column show adding alignment-based similarities models alreadyuse IDF weighting distributional similarities, adding IDF weighting modelsdistributional alignment-based similarities generally lead minor improvements.Table 6 shows whether difference performance obtained additionone kind feature reaches statistical significance, worth noting modelcaptures lexical similarities kind significantly better basic Tri5model tasks (p 0.02 search; p < 0.0001 annotation), IDF-reweightingleads significant improvement annotation task (p < 0.03). Moreover,difference Tri5Sem (13.7 search; 13.4 annotation) basic Tri5 kernelIDF-reweighting (12.5 search; 11.3 annotation) highly significant (p < 0.03 search;p < 0.0001 annotation).impact Lins similarity shown Table 6 performance Tri5Lin ,model augments trigram kernel Lins (1998) WordNet-based similarity.Tri5Sem include Lins similarity, since found development Tri5Linperformed similarly worse basic Tri5 model automatic R@k medianrank scores. also reflected Tri5Lin R-precision scores 11.7 annotation (Tri5:11.6) 10.7 search (Tri5: 11.0). Lins similarity may simply coarsepurposes. shown Table 3, hypernym relations WordNet lead associate termsswimming football other. even though semantically885fiHodosh, Young & HockenmaierCorrelation system rankingsS@k R@kAnnotation@1@5@100.860.920.960.690.760.82Correlation system rankingsR-precisionSearch0.970.970.97(a) S@k vs. R@k0.870.880.87AnnotationR@1R@5R@10Median rank0.850.930.94-0.920.680.780.79-0.79Search0.940.960.97-0.970.830.870.89-0.89(b) R-precision vs. R@k median rankTable 7: Correlation (Spearmans Kendalls ) system rankings obtainedhuman metrics (S@k R-precision) automated scores (R@k median rank)related fact different kinds sports activities, visuallydissimilar, considered related systems.4.3.5 Human Evaluations Approximated Automatic Techniques?R-precision S@k scores require human judgements, therefore cannot applieddatasets judgements yet collected whose scale may prohibitever creating definitive set judgements. However, evaluation intended measurerelative progress image description rather absolute performance, automaticmetrics may sufficient approximation, since yield similar ranking systemsR-precision S@k scores. Table 7(a) shows correlations rankingsNN KCCA systems (n = 30) obtained S@k scores obtainedcorresponding R@k scores. Table 7(b) shows correlations R-precisionautomatic metrics. report two rank correlation coefficients, SpearmansKendalls . first observe system rankings obtained via R@1 correlate highlyeither R-precision S@1 based rankings. hand, also observeR@5, R@10, median rank scores correlate well R-precision R@5R@10 correlate well corresponding S@k metrics. suggests rankingbased metrics significantly robust metrics consider qualityfirst result. Moreover, results indicate framework, systemsexpected rank pool images sentences written people, may enable large-scale,fully automated, evaluation image description systems require equallylarge-scale effort collect human judgments.5. Summary Contributions Conclusionspaper, proposed frame image description task selecting rankingdescriptions among large pool descriptions provided people, frameworkprovides direct test purely semantic aspects image description needconcerned difficulties involved automatic generation syntacticallycorrect pragmatically appropriate sentences. also introduced new data setimages paired multiple captions, used data set evaluate numbernearest-neighbor KCCA-based models sentence-based image annotation well886fiFraming Image Description Ranking Taskconverse task sentence-based image search. experiments indicate importancecapturing lexical similarities. Finally, performed in-depth analysis differentevaluation metrics image description.5.1 Advantages Framing Image Description Ranking TaskOne main motivations framing image description ranking rathergeneration problem question objective, comparable evaluation abilityunderstand depicted images. order make progress challengingtask, important define tasks evaluation metrics allow objectivecomparison different approaches. argued task ranking poolcaptions written people attractive number reasons: first, results obtaineddata set compared directly; second, human evaluation easiergenerated captions since needs focus factual correctness description rathergrammaticality, fluency, creativity; third, statistically significant differencessystems may become apparent single caption per image considered;finally, ranking makes possible automate evaluation, e.g. considering positionoriginal caption. Moreover, framing image description ranking task also establishesclear parallels image retrieval, allowing metrics used tasks.5.2 Data SetFlickr 8k data set 8,000 images, paired five crowdsourced captions,unique resource image description. Although much smaller SBU corpus(Ordonez et al., 2011), believe generic conceptual descriptions corpususeful image understanding original Flickr captions SBU data set.data set perhaps similar IAPR data set (Grubinger et al.,2006), captions corpus shorter, focus salient aspectsimage. focus images people animals, IAPR data set coversslightly different domain, including city pictures landscape shots typicallydepict focus people. distinct advantage corpus pairs imagemultiple, independently written captions. results indicate usingsingle caption training time leads significant increase performance. alsoshown use multiple captions define alignment-based lexical similaritymay useful image description standard distributional WordNet-basedsimilarities.5.3 Modelspaper first apply Kernel Canonical Correlation analysis (KCCA) sentencebased image description. results show KCCA significantly outperforms nearestneighbor-based approaches data set 6,000 training images 1,000 test images(although may scale better large data sets Ordonez et al.s (2011)SBU corpus, memory requirements train KCCA may prohibitive). Oneadvantage KCCA-based approaches image description systems gearedspecifically towards caption generation applied image de-887fiHodosh, Young & Hockenmaierscription, also image retrieval, results indicate performancetasks fairly similar.important difference approach taken paper imagedescription systems features used models presented computed minimal supervision. feature relies supervised classifieralignment-based similarity, uses POS-tagger identify nouns verbs. Despitesimplicity underlying features, models achieve relatively high performance,considering difficulty task: Although 1.5% chance randomlychosen test caption describe test image well, fine-grained human judgments revealimage annotation, first caption returned best KCCA system gooddescription 28% test images. Furthermore, large-scale evaluation showsbest system, almost 50% chance suitable image captionreturned among first ten results. results indicate two main reasonshigh performance: availability multiple captions image trainingtime, use robust text representations capture lexical similarities ratherrequiring strict equality words. However, also clear task remainsfar solved, leave question KCCA may benefit modelsrely richer visual linguistic features detector responses rich syntacticanalyses future work.5.4 Evaluating Ranking-Based Image Description Systemsmain advantage framing image description ranking problem allowsdirect comparison different approaches, since evaluated data set.also makes possible borrow established evaluation metrics information retrieval,use metrics data sets sentence-based image annotation imagesearch.one hand, shown crowdsourcing used collect large numberbinary judgments image-caption pairs relatively low price, crowdsourced judgments correlate well fine-grained judgments. able collecthuman judgments large scale particularly important retrieval-based approachesimage description, since number relevance judgments need collectedtest collection may significantly larger number judgments commonlyused evaluate single caption generation system. However, experiments imageannotation provided example human judgments first caption returnedtest image reveal differences systems become apparentresults taken account. fine-grained evaluation also indicates evaluationsbased single result may require potentially much larger number test itemsorder reveal robust statistically significant differences. Among human evaluationmetrics compared, believe R-precision computed crowdsourcedrelevance judgments robust. R-precision standard metric evaluatingranked retrieval results items varying number relevant responses, sinceyields single score, also makes particularly easy compare systems. However,S@k scores, measure percentage items top k responses containrelevant result, perhaps direct measure useful system may prac-888fiFraming Image Description Ranking Tasktice. release crowdsourced relevance judgments collected orderenable others evaluate image description system data. hopeestablish benchmark used direct fair large-scale comparisonarbitrary number image description systems.hand, also shown framework systems evaluated ability rank pool images sentences may make possible performfully automated evaluation. Contrary current practice, analysis indicates clearlystandard metrics Bleu Rouge reliable indicatorswell captions describe images, even Bleu Rouge-style preprocessing usedeffective filter implausible image-caption pairs. Although consider humangenerated captions, stipulate similar observations may hold automatically generated captions, since similar criticisms Bleus appropriateness generationmachine translation evaluation well known (Reiter & Belz, 2009; Callison-Burch, Osborne, & Koehn, 2006). However, ranking-based framework test query associatedgold response originally associated with, results indicatemetrics based rank gold item lead similar conclusions human judgments. suggest evaluation ranking-based image description taskautomated, performed potentially much larger scale examined here.5.5 Implications Evaluation Caption Generation SystemsImage description can, should, also treated problem natural languagegeneration community. automatically generating captions indistinguishablecaptions written people (an evaluation criterion used Mitchell et al. (2012)comparison caption generation systems) requires much abilityprovide factually correct information image. believe linguisticissues need solved generation setting need evaluated separatelyability decide whether given caption describes image. unclear kindsevaluations performed e.g. Mitchell et al. could ever automated, since questionnatural automatically produced caption seems may always require human judgment.human experiments expensive, since system generates captions,judgments collected anew system experiment. Sinceconsensus constitutes good image description, independently obtained humanassessments different caption generation systems compared directly.means direct comparison systems, e.g. performed Mitchell et al., typicallypossible within one research group, since common data set differentsystem outputs publicly available. Although automatic scores Bleu Rougemay still useful caption generation measures fluency (Reiter & Belz, 2009),shown reliable metrics well caption describes image,especially candidate pool disjoint reference captions. suggestsevaluation syntactic pragmatic aspects caption generation taskautomated, may rely human judgments. However, maypossible use framework proposed paper evaluate semantic affinityfunctions f (i, s) implicitly used caption generations systems.889fiHodosh, Young & HockenmaierAcknowledgmentsgratefully acknowledge support project National Science FoundationIIS Medium grant 0803603, CAREER award 1053856, CNS-1205627 CI-P.Appendix A. Agreement Approximate Metrics ExpertHuman JudgmentsTables 8 9 use Cohens Kappa () measure agreement Bleu Rougescores expert judgments. selected thresholds yield optimal results.Table 10 (a) shows agreement crowdsourced judgments expertjudgments. Since best agreement expert scores obtained crowdsourcedjudgments using threshold 0.6, Table 10 (b) measures precision recall resulting binary relevance judgments binarized expert judgments obtained varyingthresholds.Appendix B. Performance Systemsfollowing tables give results models. Section 4 body paper, NNidfcorresponds NN5idfF1 , Tri5Sem corresponds Tri5A,DBNC+ic .R@k median rank scores Table 11 gives recall median rank originalitem (Section 4.3.1) models.Agreement expert Bleu/Rouge scores (Cohens )Case 1: Scand Sref5 reference captions/test image (Scand Sref ; R5 )ExpertE0.9Bleu B0.80.70.4Rouge R0.30.2=4.03.63.33.02.60.720.710.640.450.350.700.720.670.540.450.540.540.500.450.380.470.500.500.540.510.590.610.630.570.510.290.330.370.490.531 reference caption/test image (Scand = Sref ; R1 (gold))ExpertE0.8Bleu0.6 0.50.9=4.03.63.33.02.60.710.680.600.410.320.700.680.590.420.320.690.650.570.390.300.520.560.560.480.42Rouge0.7 0.30.670.640.560.400.320.350.390.400.450.43Table 8: Agreement (Cohens ) binarized expert Bleu/Rouge scorespool candidate captions contains test images reference caption(s).890fiFraming Image Description Ranking TaskAgreement expert Bleu/Rouge scores (Cohens )Case 2: Scand 6 Sref4 reference captions/ test image (R4 )ExpertE0.7Bleu0.6 0.50.4Rouge0.3 0.2=4.03.63.33.02.60.500.510.520.470.410.400.430.460.480.470.440.430.400.390.330.400.430.440.500.480.230.280.320.410.440.260.300.340.470.511 reference caption/test image (R1 (other))ExpertE0.5Bleu0.4 0.30.4Rouge0.3 0.2=4.03.63.33.02.60.330.340.340.320.300.270.290.320.360.350.330.340.350.390.370.300.320.350.420.410.160.190.220.290.310.180.210.240.340.38Table 9: Agreement (Cohens ) binarized expert Bleu/Rouge scorespool candidate captions may contain test images reference caption(s).Agreement expertlay scores (Cohens )ExpertE=4.03.63.33.02.6=1.00.750.780.740.560.45Lay vs. expertrelevance judgments (L = 0.66)Lay L0.6 0.30.690.760.790.710.620.490.570.650.740.73(a) Agreement (Cohens ) relevance judgments obtained expertscores (relevance = score E ) layscores (relevance = score L )EPrecisionRecallF1=4.03.63.33.02.62.355.965.475.290.094.798.298.695.088.064.753.440.171.477.581.175.368.357.0(b) Precision, recall, F1 scores binarized lay scores (L = 0.66)binarized expert scores varyingthresholds E .Table 10: Comparing relevance judgments obtained lay scoresobtained expert scores891fiHodosh, Young & HockenmaierS@k R-precision scores Table 12 gives S@k success rate (Section 4.3.3)R-precision scores (Section 4.3.3) models, based crowdsourced humanjudgments (Section 4.3.2).892fiFraming Image Description Ranking TaskPerformance models (automatic evaluation)(R@k: percentage queries original item top X resultsMedian r: median rank original item)R@1Image annotationR@5 R@10 Median rR@1Image searchR@5 R@10 Median rNN5F1NN5idfF1NN5BoW5NN5Tri(best)1.92.52.12.15.97.65.95.98.79.79.69.4251.0251.0258.5248.02.12.52.82.35.24.76.46.17.17.29.19.0278.0272.0266.0240.0BoW1Tri14.84.613.514.419.721.064.068.04.54.514.314.020.822.567.071.0BoW5HistoBoW5BoW5idfBoW5 idfTagRank5.96.26.16.16.014.917.117.017.317.021.224.323.223.923.869.058.060.556.056.04.85.86.46.15.414.216.716.516.917.420.823.624.524.524.374.060.059.560.552.5Tri5HistoTri56.07.115.017.221.723.763.553.05.76.014.517.822.126.267.055.0Tri5LinTri5DBNCTri5DicTri5DBNC+ic6.27.57.07.316.719.819.520.023.726.127.127.053.540.036.036.06.07.27.06.916.718.419.319.224.427.427.528.061.044.541.042.0Tri5ATri5A,DBNCTri5A,DicTri5A,DBNC+ic7.27.96.97.620.220.320.220.728.028.429.530.041.039.035.035.06.87.87.37.418.519.019.919.427.727.428.729.241.539.039.538.07.618.825.146.06.218.026.552.06.87.36.718.720.420.028.927.528.940.038.035.06.78.17.018.219.119.727.628.428.845.040.539.07.37.57.221.121.320.828.330.029.637.038.034.07.57.87.419.218.921.428.729.030.138.041.537.5idf,HistoTri5A,DBNC+ic6.518.026.745.06.018.024.248.5idfA,DBNC+ic8.321.630.334.07.620.730.138.0Tri5idfidfTri5DBNCidfTri5DicidfTri5DBNC+icidfTri5AidfTri5A,DBNCidfTri5A,DicTri5Table 11: Performance models, measured percentage test itemsoriginal item returned among top 1, 5 10 results,well median rankidfidforiginal item. Section 4, NN5F1 = NN, Tri5A,DBNC+ic = Tri5Sem.893fiHodosh, Young & HockenmaierPerformance models (human evaluation)S@k: Percentage items relevant response among top X resultsR-prec: R-precision computed relevant responsesS@1NN5F1NN5idfF1NN5BoW5NN5Tri(best)Image annotationS@5 S@10 R-prec.S@1Image searchS@5 S@10 R-prec.4.95.86.47.213.315.414.817.419.120.220.623.14.25.25.46.24.95.05.74.413.213.313.413.517.818.418.419.83.83.84.64.3BoW1Tri112.212.830.332.239.740.210.710.511.412.230.530.640.241.59.69.9BoW5HistoBoW5BoW5idfBoW5 idfTagRank13.915.013.915.016.229.834.132.734.034.239.642.742.442.742.99.911.111.011.311.711.512.113.312.912.428.031.530.831.331.538.140.841.841.041.69.310.510.610.710.5Tri5HistoTri515.016.429.032.938.943.49.911.612.913.128.933.139.943.810.511.0Tri5LinTri5DBNCTri5DicTri5DBNC+icTri5ATri5A,DBNCTri5A,DicTri5A,DBNC+ic15.516.815.816.417.316.615.816.434.137.436.737.236.936.537.037.443.845.547.047.147.447.448.248.311.712.712.712.513.413.213.013.412.714.514.514.814.315.315.215.432.535.336.636.335.435.037.437.041.744.946.145.846.645.847.646.810.712.112.812.712.312.812.813.216.935.444.212.513.033.443.911.316.115.916.236.036.937.447.546.847.512.912.813.315.016.015.334.035.834.844.647.546.712.213.113.017.415.715.737.636.937.346.348.147.313.412.913.315.815.815.536.335.338.347.347.247.813.212.913.413.630.641.911.114.433.842.712.216.637.749.113.715.736.948.513.4Tri5Tri5Tri5Tri5Tri5Tri5Tri5Tri5Tri5idfidfBNCidficidfDBNC+icidfidfA,DBNCidfA,Dicidf,HistoA,DBNC+icidfA,DBNC+icTable 12: Performance models, measured percentage test itemsreturn item deemed relevant according crowdsourced judgmentsamong top 1, 5 10 results,R-precision computed judgments.idfidfSection 4, NN5F1 = NN, Tri5A,DBNC+ic = Tri5Sem.894fiFraming Image Description Ranking TaskReferencesArtstein, R., & Poesio, M. (2008). Inter-coder agreement computational linguistics.Computational Linguistics, 34 (4), 555596.Bach, F. R., & Jordan, M. I. (2002). Kernel independent component analysis. JournalMachine Learning Research, 3, 148.Barnard, K., Duygulu, P., Forsyth, D., Freitas, N. D., Blei, D. M., & Jordan, M. I. (2003).Matching words pictures. Journal Machine Learning Research, 3, 11071135.Blei, D. M., & Jordan, M. I. (2003). Modeling annotated data. SIGIR 2003: Proceedings26th Annual International ACM SIGIR Conference Research DevelopmentInformation Retrieval, pp. 127134, Toronto, Ontario, Canada.Bloehdorn, S., Basili, R., Cammisa, M., & Moschitti, A. (2006). Semantic kernels textclassification based topological measures feature similarity. Proceedings6th IEEE International Conference Data Mining (ICDM 2006), pp. 808812, HongKong, China.BNC Consortium (2007). British National Corpus, version 3 (BNC XML edition).http://www.natcorp.ox.ac.uk.Brown, P. F., Pietra, V. J. D., Pietra, S. A. D., & Mercer, R. L. (1993). mathematicsstatistical machine translation: parameter estimation. Computational Linguistics,19 (2), 263311.Callison-Burch, C., Osborne, M., & Koehn, P. (2006). Re-evaluation role bleumachine translation research. Proceedings 11th Conference European Chapter Association Computational Linguistics (EACL), pp. 249256,Trento, Italy.Cohen, J. (1960). coefficient agreement nominal scales. Educational Psychological Measurement, 20 (1), 3746.Croce, D., Moschitti, A., & Basili, R. (2011). Structured lexical similarity via convolutionkernels dependency trees. Proceedings 2011 Conference EmpiricalMethods Natural Language Processing (EMNLP), pp. 10341046, Edinburgh, UK.Dale, R., & White, M. (Eds.). (2007). Workshop Shared Tasks Comparative Evaluation Natural Language Generation: Position Papers, Arlington, VA, USA.Datta, R., Joshi, D., Li, J., & Wang, J. Z. (2008). Image retrieval: Ideas, influences,trends new age. ACM Computing Surveys, 40 (2), 5:15:60.Deschacht, K., & Moens, M.-F. (2007). Text analysis automatic image annotation.Proceedings 45th Annual Meeting Association Computational Linguistics (ACL), pp. 10001007, Prague, Czech Republic.Dietterich, T. G. (1998). Approximate statistical tests comparing supervised classificationlearning algorithms. Neural Computation, 10 (7), 18951923.Everingham, M., Gool, L. V., Williams, C., Winn, J., & Zisserman, A. (2008).PASCAL Visual Object Classes Challenge 2008 (VOC2008) Results. http://www.pascal-network.org/challenges/VOC/voc2008/workshop/.895fiHodosh, Young & HockenmaierFarhadi, A., Hejrati, M., Sadeghi, M. A., Young, P., Rashtchian, C., Hockenmaier, J., &Forsyth, D. (2010). Every picture tells story: Generating sentences images.Proceedings European Conference Computer Vision (ECCV), Part IV, pp.1529, Heraklion, Greece.Fellbaum, C. (1998). WordNet: Electronic Lexical Database. Bradford Books.Felzenszwalb, P., McAllester, D., & Ramanan, D. (2008). discriminatively trained, multiscale, deformable part model. Proceedings 2008 IEEE Conference Computer Vision Pattern Recognition (CVPR), pp. 18, Anchorage, AK, USA.Feng, Y., & Lapata, M. (2008). Automatic image annotation using auxiliary text information. Proceedings 46th Annual Meeting Association ComputationalLinguistics: Human Language Technologies (ACL-08: HLT), pp. 272280, Columbus,OH, USA.Feng, Y., & Lapata, M. (2010). many words picture worth? automatic caption generation news images. Proceedings 48th Annual Meeting AssociationComputational Linguistics (ACL), pp. 12391249, Uppsala, Sweden.Fisher, R. A. (1935). Design Experiments. Olyver Boyd, Edinburgh, UK.Grangier, D., & Bengio, S. (2008). discriminative kernel-based approach rank imagestext queries. IEEE Transactions Pattern Analysis Machine Intelligence,30, 13711384.Grice, H. P. (1975). Logic conversation. Davidson, D., & Harman, G. H. (Eds.),Logic Grammar, pp. 6475. Dickenson Publishing Co., Encino, CA, USA.Grubinger, M., Clough, P., Mller, H., & Deselaers, T. (2006). IAPR benchmark: newevaluation resource visual information systems. OntoImage 2006, WorkshopLanguage Resources Content-based Image Retrieval LREC 2006, pp. 1323,Genoa, Italy.Gupta, A., Verma, Y., & Jawahar, C. (2012). Choosing linguistics vision describeimages. Proceedings Twenty-Sixth AAAI Conference Artificial Intelligence,Toronto, Ontario, Canada.Hardoon, D. R., Saunders, C., Szedmak, S., & Shawe-Taylor, J. (2006). correlation approach automatic image annotation. Li, X., Zaane, O. R., & Li, Z.-H. (Eds.),Advanced Data Mining Applications, Vol. 4093 Lecture Notes Computer Science, pp. 681692. Springer Berlin Heidelberg.Hardoon, D. R., Szedmak, S. R., & Shawe-Taylor, J. R. (2004). Canonical correlationanalysis: overview application learning methods. Neural Computation, 16,26392664.Hotelling, H. (1936). Relations two sets variates. Biometrika, 28 (3/4), 321377.Hwang, S., & Grauman, K. (2012). Learning relative importance objects taggedimages retrieval cross-modal search. International Journal Computer Vision,100 (2), 134153.896fiFraming Image Description Ranking TaskJaimes, A., Jaimes, R., & Chang, S.-F. (2000). conceptual framework indexing visualinformation multiple levels. Internet Imaging 2000, Vol. 3964 ProceedingsSPIE, pp. 215, San Jose, CA, USA.Jurafsky, D., & Martin, J. H. (2008). Speech Language Processing (2nd edition). PrenticeHall.Krippendorff, K. (2004). Content analysis: introduction methodology. Sage.Kulkarni, G., Premraj, V., Dhar, S., Li, S., Choi, Y., Berg, A. C., & Berg, T. L. (2011).Baby talk: Understanding generating simple image descriptions. Proceedings2011 IEEE Conference Computer Vision Pattern Recognition (CVPR),pp. 16011608.Kuznetsova, P., Ordonez, V., Berg, A., Berg, T., & Choi, Y. (2012). Collective generationnatural image descriptions. Proceedings 50th Annual Meeting Association Computational Linguistics (Volume 1: Long Papers), pp. 359368, JejuIsland, Korea.Lavrenko, V., Manmatha, R., & Jeon, J. (2004). model learning semantics pictures. Thrun, S., Saul, L., & Schlkopf, B. (Eds.), Advances Neural InformationProcessing Systems 16, Cambridge, MA, USA.Lazebnik, S., Schmid, C., & Ponce, J. (2009). Spatial pyramid matching. S. Dickinson,A. Leonardis, B. S., & Tarr, M. (Eds.), Object Categorization: Computer HumanVision Perspectives, chap. 21, pp. 401415. Cambridge University Press.Li, S., Kulkarni, G., Berg, T. L., Berg, A. C., & Choi, Y. (2011). Composing simple image descriptions using web-scale n-grams. Proceedings Fifteenth ConferenceComputational Natural Language Learning (CoNLL), pp. 220228, Portland, OR,USA.Lin, C.-Y. (2004). Rouge: package automatic evaluation summaries. MarieFrancine Moens, S. S. (Ed.), Text Summarization Branches Out: ProceedingsACL-04 Workshop, pp. 7481, Barcelona, Spain.Lin, C.-Y., & Hovy, E. H. (2003). Automatic evaluation summaries using n-gram cooccurrence statistics. Proceedings 2003 Human Language Technology Conference North American Chapter Association Computational Linguistics(HLT-NAACL), pp. 7178, Edmonton, AB, Canada.Lin, D. (1998). information-theoretic definition similarity. Proceedings Fifteenth International Conference Machine Learning (ICML), pp. 296304, Madison,WI, USA.Lowe, D. G. (2004). Distinctive image features scale-invariant keypoints. InternationaJournal Computer Vision, 60 (2), 91110.Makadia, A., Pavlovic, V., & Kumar, S. (2010). Baselines image annotation. InternationalJournal Computer Vision, 90 (1), 88105.Manning, C. D., Raghavan, P., & Schtze, H. (2008). Introduction Information Retrieval.Cambridge University Press.897fiHodosh, Young & HockenmaierMitchell, M., Dodge, J., Goyal, A., Yamaguchi, K., Stratos, K., Han, X., Mensch, A., Berg,A., Berg, T., & Daume III, H. (2012). Midge: Generating image descriptionscomputer vision detections. Proceedings 13th Conference EuropeanChapter Association Computational Linguistics (EACL), pp. 747756, Avignon, France.Moschitti, A. (2009). Syntactic semantic kernels short text pair categorization.Proceedings 12th Conference European Chapter AssociationComputational Linguistics (EACL), pp. 576584, Athens, Greece.Moschitti, A., Pighin, D., & Basili, R. (2008). Tree kernels semantic role labeling.Computational Linguistics, 34 (2), 193224.Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignmentmodels. Computational Linguistics, 29 (1), 1951.Ordonez, V., Kulkarni, G., & Berg, T. L. (2011). Im2text: Describing images using 1 millioncaptioned photographs. Advances Neural Information Processing Systems 24,pp. 11431151.Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). Bleu: method automaticevaluation machine translation. Proceedings 40th Annual Meeting Association Computational Linguistics (ACL), pp. 311318, Philadelphia, PA, USA.Popescu, A., Tsikrika, T., & Kludas, J. (2010). Overview Wikipedia retrieval taskImageCLEF 2010. CLEF (Notebook Papers/LABs/Workshops), Padua, Italy.Porter, M. F. (1980). algorithm suffix stripping. Program, 14 (3), 130137.Rashtchian, C., Young, P., Hodosh, M., & Hockenmaier, J. (2010). Collecting image annotations using Amazons Mechanical Turk. NAACL Workshop Creating SpeechLanguage Data Amazons Mechanical Turk, pp. 139147, Los Angeles, CA,USA.Rasiwasia, N., Pereira, J. C., Coviello, E., Doyle, G., Lanckriet, G. R., Levy, R., & Vasconcelos, N. (2010). new approach cross-modal multimedia retrieval. ProceedingsInternational Conference Multimedia (MM), pp. 251260, New York, NY,USA.Reiter, E., & Belz, A. (2009). investigation validity metrics automatically evaluating natural language generation systems. Computational Linguistics,35 (4), 529558.Shatford, S. (1986). Analyzing subject picture: theoretical approach. Cataloging& Classification Quarterly, 6, 3962.Shawe-Taylor, J., & Cristianini, N. (2004). Kernel Methods Pattern Analysis. CambridgeUniversity Press.Smucker, M. D., Allan, J., & Carterette, B. (2007). comparison statistical significancetests information retrieval evaluation. Proceedings Sixteenth ACM Conference Information Knowledge Management (CIKM), pp. 623632, Lisbon,Portugal.898fiFraming Image Description Ranking TaskSocher, R., & Li, F.-F. (2010). Connecting modalities: Semi-supervised segmentationannotation images using unaligned text corpora. Proceedings 2010 IEEEConference Computer Vision Pattern Recognition (CVPR), pp. 966973, SanFrancisco, CA, USA.van Erp, M., & Schomaker, L. (2000). Variants Borda count method combiningranked classifier hypotheses. Proceedings Seventh International WorkshopFrontiers Handwriting Recognition (IWFHR), pp. 443452, Nijmegen, Netherlands.Varma, M., & Zisserman, A. (2005). statistical approach texture classificationsingle images. International Journal Computer Vision, 62, 6181.Vedaldi, A., & Fulkerson, B. (2008). VLFeat: open portable library computervision algorithms. http://www.vlfeat.org/.Weston, J., Bengio, S., & Usunier, N. (2010). Large scale image annotation: learning rankjoint word-image embeddings. Machine Learning, 81 (1), 2135.Yang, Y., Teo, C., Daume III, H., & Aloimonos, Y. (2011). Corpus-guided sentence generation natural images. Proceedings 2011 Conference Empirical MethodsNatural Language Processing (EMNLP), pp. 444454, Edinburgh, UK.899fiJournal Artificial Intelligence Research 47 (2013) 313-349Submitted 03/13; published 06/13Learning Observation Agent Software ImagesPaulo CostaLuis Botelhopaulo.costa@iscte.ptluis.botelho@iscte.ptInstituto de TelecomunicacoesISCTE-Instituto Universitario de LisboaAvenida das Forcas Armadas, 1649-026 Lisbon, Portugal.AbstractLearning observation key importance whenever agents sharing similarfeatures want learn other. paper presents agent architectureenables software agents learn direct observation actions executed expertagents performing task. possible proposed architecturedisplays information essential observation, making possible software agentsobserve other.agent architecture supports learning process covers aspects learningobservation, discovering observing experts, learning observeddata, applying acquired knowledge evaluating agents progress. evaluationprovides control decision obtain new knowledge apply acquired knowledgenew problems.combine two methods learning observed information. first one,recall method, uses sequence actions observed solve new problems.second one, classification method, categorizes information observed datadetermines set categories new problems belong.Results show agents able learn conditions common supervisedlearning algorithms fail, agents know results actionspriori effects actions visible. results also showapproach provides better results learning methods since requires shorterlearning periods.1. Introductionpaper describes important aspects approach enabling software agentslearn control mechanisms directly observing actions expert agentperforming task. shows innovations proposal agent software image(Costa & Botelho, 2011) presents complete learning observation process, followingprevious work subject (Costa & Botelho, 2012). paper also presents resultsapproach two different scenarios (see section 5). learning method usedapproach usually known artificial intelligence community learning observation,imitation learning, learning demonstration, programming demonstration, learningwatching learning showing. consistency, learning observation usedon.Learning observation one least common complex forms learning amongst animals singular humans strict number superiormammals. also one powerful socialisation mechanisms (Ramachandran,c2013AI Access Foundation. rights reserved.fiCosta & Botelho2003; Bandura, 1977; Meunier, Monfardini, & Boussaoud, 2007). Research neurologypsychology shows learning observation may well one causesexponential growth human technologies last centuries. Unlike natural selection, observation allows capabilities spread amongst individuals within generation(Ramachandran, 2000).Section 2 shows learning observation already used robotic agents,proves applicability learning technique artificial systems. However,progress learning observation limited robotics software agents cannotobserve one another way tangible entities observed. Learning observation useful software agents provides direct approach problemsolve compared techniques agents learn experience,reinforcement learning. Instead spending time testing several hypotheses, artificial agentsacquire knowledge expert directly observing actions performstask. allows artificial agents directly know actions necessaryperform specific task (Argall, Chernova, Veloso, & Browning, 2009; Chernova, 2009).able observe expert agent performing actions (as opposed merely relyobservation effects) advantageous situations effectsactions directly visible environment (for example, agent communication,manipulation software objects). Even part effect actions visible,directly observing actions still advantageous effects could achieveddifferent alternative actions using one clearly better using others(for example, using set sums instead simple multiplication). Observing actionsperformed expert also advantageous representation world states requiresmuch memory making impossible build large enough training sets (for example,web agents, manipulation large databases) especially agent knoweffects actions priori (for example, executing invoking software programAPI).application learning observation software agents ideal societiesagents share common features internal representation methods (forexample, integration legacy systems). Without common internal representation methods, directly transferring knowledge agents impossible or, least difficult.Learning observation makes possible learn without need common internalrepresentations agent makes interpretations observing.advantages described provided motivation developing approachlearning observation software agents. major contribution approachdefinition whole learning process, includes discovery, observation, storageinterpretation observed data, application acquired knowledgecontinuous internal evaluation (see section 4). Agents learn observation capablesolving tasks conditions performed observed experts.also capable performing similar task facing different conditions.scenarios described section 5 show possibilities.section 2 shows, best knowledge, approach learning observation software agents one presented Machado Botelho (2006). However,Machado Botelhos proposal agents capable learning vocabularywhereas work described paper agents capable learning control314fiLearning Observation Agent Software Imagesmechanisms, requires developing different kind learning algorithm. addition,approach also introduces several improvements software image (see section 3)initially proposed Machado Botelho (2006).software image provides software agents accessible representationconstituents capabilities, static image, actions perform, dynamicimage. approach heavily relies agent architecture software image. Agentssoftware image seen (consulted) agents even themselves.software image allows software agents learn observation because, softwareenvironments, information required learning observation automaticallyvisible agents body happens physical world (Quick, Dautenhahn, Nehaniv,& Roberts, 2000). avoid misconceptions observation tangible entitiesphysical world, act observing software agent defined as:Reading meta-data agents constituents, actions conditions holdingactions executed, without direct intervention observed agent.allows observed agent (the expert) passive role observation process. learning observation humans superior mammals,apprentice takes action obtain new knowledge, without interferingexpert agent. spite similarities Machado Botelhos (2006) approach,approach introduced several improvements software image, particular:inclusion agent sensors static image, addition visibleattributes, actuators actions Machado Botelhos approach.improvement provides better description agent allows agentsknow way agent understands world, explained section 3.1.dynamic image, besides displaying executed action Machado Botelhosapproach, also displays information conditions holding actionexecuted, is, state environment, perceived agent sensors,instances visible attributes. improvement enables agentsprovide data observation similar training sequences used trainingmachine learning algorithms (condition-action pairs), explained section 3.1.software image displays historical information actions executedpast conditions holding action executed. enablesagents acquire great amount knowledge beginning observation,section 3.2 shows.software image also uses ontologies hold knowledge designationsdifferent kinds sensors, visible attributes, actions tasks. improvementallows agents follow ontology use designationskinds sensors, visible attributes, actions tasks, section 3.2 shows.contributions approach restricted agent software image.important contributions complete approach learning observation,particular:315fiCosta & Botelhodiscovery experts provides agent necessary tools discover,itself, expert agents possible learn (see section 4.1).definition two learning algorithms, used convert observedinformation mechanisms choosing actions perform condition- recall algorithm classification algorithm. recall algorithmtotally developed approach uses sequence expert actionsobserved choose actions perform. classification algorithmadaptation existing KStar algorithm (Cleary & Trigg, 1995). categorizesinformation observed data determines actions perform accordingcategories new problems (see section 4.2).definition internal evaluation provides agent measureconfidence knowledge. Depending confidence, agentone two states learning process: learning state execution state (seesection 4). agents learning state, objective observe experts acquire new knowledge them. agents execution state,objective perform task using acquired knowledge. Switchingtwo states depends two configurable thresholds, UpperConfidenceThreshold LowerConfidenceThreshold, explained section4.3.ability mimic mirror neurons, allows agent use mechanisms propose actions learning using acquired knowledge.allows agent directly associate observed actions actions.also allows agent propose actions conditions faced observedexpert determine agent capable proposing actionobserved expert.motivation drives agent observe expert partially coveredapproach. simplification purposes, apprentice agents observationexperts top priority. apprentice agents equipped specialized sensorfocuses attention observing expert. internal evaluation allows agentsdecide whether need knowledge, providing necessarymotivation observing experts, way know obtain new knowledge.Another simplification relates determining experts observe performingrelevant actions task learn, also usually disregarded approacheslearning observation. normal circumstances, although expert featuresapprentice, necessarily mean performing actionsnecessary apprentice learn (by observation) perform specific task. Likesurveyed approaches, experts developed application scenarios section5 prepared execute actions necessary task learnt.section 5 capabilities learning approach tested two different scenarios.first scenario especially conceived situation majority effectsagent actions visible environment. Therefore, possiblecommon machine learning solution learn effects actions.316fiLearning Observation Agent Software Imagescomplete understanding happening, necessary observe agentactions. second scenario presents mountain car problem described SuttonBarto (1998). used compare learning approach reinforcement learning(RL) algorithm situation kind learning algorithm already showngood approach (Mitchell, 1997).results tests show that, approach, agents correctly learnperform task majority effects agent actions visibleenvironment (see section 5.1). addition, tested situations learningmethods may provide good results (see section 5.2), reinforcement learningscenario, results show approach able learn faster reinforcementlearning approach. Besides learning faster, agents using learning method also requirefewer actions achieve goal.following section presents survey research visual representationagents learning observation. Section 3 presents improvements madeprevious proposals regarding software image. Section 4 describes importantaspects learning observation process. Section 5 describes test scenariosexperimental results. Finally section 6 presents conclusions future work.2. Literature Reviewsection presents survey approaches learning observationvisual representation agents. describes important aspects approaches relatedlearning observation may contribute solve problems faced applyinglearning observation software agents.2.1 Visible Representation Software Agentsliterature overview regarding learning observation shows that, exceptionMachado Botelhos (2006) approach, software agents disregarded advanceslearning observation since usually related robotics (Argall et al., 2009).Software agents able distinguish software agentsremaining elements computer program disembodied nature software.this, software agents able observe tangible entities wouldobserved (Etzioni, 1993; Quick et al., 2000).Almost software approaches learning constrained observe changesenvironment (the effects agent actions) knowledge obtained perform tasklimited state change information (Quick et al., 2000; Argall et al., 2009). However, severalauthors emphasized every action produces visible changes environment(Byrne, 1999; Dautenhahn & Nehaniv, 2002; Botelho & Figueiredo, 2004; Machado, 2006),thus, using state change information alone always good option. cases,important actually see expert agent observing actionsaddition effects. allows apprentice agents know exactly actionsnecessary perform task, thus overcoming problems arise effectsactions visible environment agent know effects317fiCosta & Botelhoactions priori (Byrne, 1999; Dautenhahn & Nehaniv, 2002; Botelho & Figueiredo,2004; Machado, 2006).able learn observing actions agents, software agent needskind accessible representation body displays necessary visible features (Mataric, 1997; Botelho & Figueiredo, 2004; Machado, 2006). Research neurologyreveals human brain also uses representation human body activities(Ramachandran, 2003). representation provides information body constituentspossible actions comes existence initial stages infant development. important factor learning observation, since allows childrenacknowledge bodies capabilities. also provides ability identify entitiessimilar thus may worthwhile observing (Rao, Shon, & Meltzoff,2004).Despite neurological findings, literature review embodiment embodiedcognition shows that, besides approach (Costa & Botelho, 2011), another oneaddresses problem creating kind accessible representation software agents(Machado & Botelho, 2006). best knowledge, knownapproaches concrete proposal deploying visible image software agents,called visible software image simply software image. literature reviewlearning observation also provides alternatives since approaches, exceptionreferred ones, apply exclusively robotics (Argall et al., 2009).Although Machado Botelhos (2006) approach software image providesdescription agent constituents actions, describe kind inputagent collect software environment. Etzioni (1993) one first authorsrealize lack physical body obstacle applicationprinciples embodiment software agents way applied robotics.Etzioni, software agent situated software environment wayrobot situated physical world, characterized (itsactions) also kind inputs able collect software environment(Etzioni, 1993).reason, approach (Costa & Botelho, 2011), software image providessoftware agents visible representation constituents, includessensing action capabilities, actions executed agent conditionsholding agent decided execute actions. proposal also keepshistorical record actions performed agent conditions holdingagent decided execute actions, limited amount time.2.2 Learning Observationsurvey learning observation shows one important aspectsapproach learning observation learning algorithm. defines knowledge,obtained observation, stored used, is, agent proposesactions execute facing new problems (Argall et al., 2009). One possibilitylearning algorithm follow sequence actions expert, requiresagent store sequence observed actions performed expert.318fiLearning Observation Agent Software Imagespossibility learning algorithm, named sequencing, one commonly used learning observation approaches (Argall et al., 2009). also closelyrelated sequence learning humans since handles kind problems,predicting elements sequence based preceding element, finding naturalorder elements sequence selecting sequence actions achieve goal(Clegg, DiGirolamo, & Keele, 1998; Sun, 2001). best way maintain temporalrelations elements sequence consists using properties datastructure sequences stored (Byrne, 1999; Heyes & Ray, 2000; Kulic, Ott, Lee,Ishikawa, & Nakamura, 2011; Billing, Hellstrom, & Janlert, 2011).Linear structures lists vectors commonly used (Byrne, 1999;Heyes & Ray, 2000). However linear structures lack ability represent alternatives, important aspect sequential learning opens possibilitymaking choices inside sequence (Sun, 2001). representation alternative pathsessential representing different approaches perform task, is,objective reached different sequences actions. hold information,different approach needs stored alternative sequence actions. Tree structures ideal situations. element sequence represented nodetree following element chosen one branches node (Kulicet al., 2011).Sequencing best suited situations agents face conditions (thesequence states environment internal states) observed experts,often means agent following expert possible coverpossible combinations conditions time agent observing.possibilities learning algorithm generalize acquired knowledgeuse analogies acquired knowledge new problems. allowsagent face future conditions never observed, real worldsituation almost always impossible observe possible conditions (Argall et al., 2009;Sullivan, 2011). Unlike sequencing, specific sequence actions follow.agent determines actions perform supported exclusively conditions.One way generalizing acquired knowledge using observed conditionsactions train neural networks, described Billard Hayes (1999). hypothesisconsist using observed conditions actions feed statistical approachesBayesian algorithms Hidden Markov models (HMMs) (Rao et al., 2004; Hajimirsadeghi& Ahmadabadi, 2010). conditions actions also used train supervisedlearning algorithms, classification algorithms (Argall et al., 2009; Chernova,2009; Sullivan, 2011).Given advantages sequencing generalization analogy possibilities approach learning observation presents sequencing possibility,recall method learning, classification possibility, trough classification methodlearning. two methods learning combined increase adaptabilityapprentice agents. classification method allows agent extend knowledgeconditions observed recall method allows agent easily learnsequences actions different alternatives.survey learning observation also reveals learning observation approach cannot limited learning algorithm. addition algorithm, must319fiCosta & Botelhoalso include agents motivation learn, discovery observation agents,storage interpretation information acquired observation applicationnewly acquired knowledge (Demiris & Hayes, 2002; Tan, 2012). One majorflaws detected surveyed approaches, besides focus robot agents, factglobal view still missing (Tan, 2012). best knowledge,exception approach (Costa & Botelho, 2012), approaches focused solvingspecific problems, solutions provide supported exclusively learningalgorithm.Demiris Hayes (2002) provide good starting point building approachincludes aspects learning observation. approach presents learning processthat, excluding motivation, consistent Banduras (1977) social learning theory,approximates approach learning observation humans superior mammals.inclusion internal evaluation Demiris Hayess (2002) approach provideslearning process simple motivation mechanism. evaluation allows agentmeasure performance affected consolidating knowledgeacquired observation executing actions (Wood, 2008; Hajimirsadeghi & Ahmadabadi, 2010).agent intrinsically motivated learn knows acquiredsufficient knowledge perform task detects portionsknowledge need improvement thus require agent go back learning (Wood,2008; Billing, Hellstrom, & Janlert, 2010). ability enhance agents knowledgenew observations important factor learning observation. AccordingArgall et al. (2009), one downsides learning observation factagents knowledge limited able observe. Using evaluation stage,operates agent learning executing actions, providesknowledge necessary observe experts agents ready executeactions.Several authors use specialized experts, teachers, monitor reinforceagents actions (Sullivan, 2011; Hajimirsadeghi & Ahmadabadi, 2010; Chernova, 2009).also measure agents performance provide necessary evaluation. Besidesmonitoring, teachers also take corrective measures like providing appropriateactions faced conditions agent chooses incorrect actions (Hajimirsadeghi& Ahmadabadi, 2010). teacher also decide agent needs acquireknowledge (Sullivan, 2011).relation teacher agent extended allowingcommunicate other. allows agent request teacher performspecific task (Chernova, 2009). However, requires additional effort designingexpert agents since need communicate apprentice agents teachperform task. also requires apprentice agents wait teacheravailable communicate them, extend amount time spentlearning. happen expert plays passive role observation and,addition, using teachers makes approaches closer learning teaching, goesbeyond learning observation.different approach evaluation mimicking properties mirror neurons.mirror neurons brain structures exist humans superior mammals320fiLearning Observation Agent Software Imagesresponsible emergence learning observation. involved tightcoupling perception motor control, providing similar responses observingperforming activity. allows agents feel like performingactions observe expert (Ramachandran, 2000), greatly improveseasiness identifying observed actions, grounding agent actions.ability, agent able propose actions, using mechanisms,observing, without effectively executing them. proposed actionscompared observed determine agent able propose actionsexpert. information provided comparison feeds agents internalconfidence able propose correct actions. case, agents internalconfidence builds successes failures actions previously proposedinstead metrics current actions, provided learning algorithm,work Chernova (2009), Billing et al. (2010).Several approaches use specific structures, forward models, emulatebehaviour mirror neurons (Rizzolatti, Fadiga, & Gallese, 1996; Demiris & Hayes, 2002;Maistros & Hayes, 2004; Rao et al., 2004; Lopes & Santos-Victor, 2007). Howeverstructures specifically designed robots use hardware inhibitors preventrobot actuators executing estimated actions. main objective kindstructures create distinction description action execution,is, create abstract representations agent actions (Kulic et al., 2011). solutionsimpler provides agent control execution actions.One characteristics reviewed approaches usually focus specificproblems, implies adaptations features whenever appliednew domains. Despite problem, shown section, reviewed approachesprovide important features adapted approach learning observation.3. Software Imagesection presents summary additional functionalities approach introduced previous work regarding software image (Machado & Botelho, 2006).section describes new functionalities, explains reasons inclusionsoftware image advantageous learning observation.approach learning observation proposes software image allows softwareagents learn observing actions agents. act observing softwareagent imply use computer vision; instead agents use specialized sensorsread meta-data observed agent. meta-data call softwareimage, defined software objects relationships among them, displayedFigure 1. Despite current version software image primarily focusedlearning observation, believe image useful purposes(for example, improve agents interaction surrounding environmentembodiment). Additional work incrementally reveal characteristics softwareimage independent particular use.proposal software image (Costa & Botelho, 2011) provides accessibledomain independent description agents constituents, actions executesconditions holding decided execute actions. description used321fiCosta & Botelhosoftware agents interested observing represented agent comparisondescription, check agents share capabilities, describedsection 4.1. Figure 1 shows representation key elements software image. LikeMachado Botelhos (2006) proposal, elements agent software imagearranged two categories, static image dynamic image. static imageimmutable (does change time) describes constituents agent whereasdynamic image changes time describes activities agent.11..*1StaticImage111SoftwareImage+historySize: int+AgentUUID: StringAgentPartDynamicImage110..*0..*1..*Action+descriptor: String1Sensor0..*1+descriptor: String<<Interface>>DataSource10..*1Condition1..*1+value1VisibleAttributeCompositeAction0..*+descriptor: StringActionInstance0..*SimpleAction1..*Actuator0..*Snapshot+order: int1+parameters1Figure 1: class diagram software imageimprovements Machado Botelhos (2006) proposal software imageconsist including agent sensors description components (the static image), combining information state software environment (providedagent sensors) information important aspects agents internal stateobserved actions enabling representation composite actions, is, actions composed sequences simpler actions. important improvements include abilitystore historic data agent actions conditions holding actions,use ontology represent knowledge agent sensors, actions visibleattributes, tasks accomplished concepts relationships existelements. proposal software image also defines protocolobserving snapshots.following sections describe improvements software image greaterdetail.3.1 Agent Sensors Snapshots Agent ActivityMachado Botelhos (2006) version software image described software agentscollection parts visible attributes actuators. actuators, turn,described collection actions agent able perform. However, alsoimportant include agent sensors description, especially software agentsaccess part state environment, acquired sensors.information collected agent sensors represents way agent understandsworld - agents perspective world. sensors included staticimage, agents way knowing experts observe understand worldway them. ability understand world way322fiLearning Observation Agent Software Imagesexpert important better understanding reasons behind experts actions(Bandura, 1977; Ramachandran, 2000).Given importance agent sensors, proposal software image includesconstituents agent part (see Figure 1). provides accurate descriptionagent allows agents compare others actionsperform also kind information obtain environment.proposal software image also consider conditions holdingagent action state environment, acquired agent sensors,instances agents visible attributes (the important aspects agents internal state)moment agent selects action. information contained conditionsdepends exclusively information provided agent sensors visibleattributes. agent sensors visible attributes, well type informationprovide, defined designing agent. Section 5 shows examplesensors visible attributes set agent affects conditions.conditions holding action play important role information providedobservation dynamic image. Unlike Machado Botelhos (2006) proposalagents could observe action currently performed, proposal,agents acquire snapshots activity observed agent. snapshot containsinformation executed action conditions holding moment agentdecided select it. way, information provided observation similartraining sequences used training machine learning algorithms (a sequence conditionaction pairs), important aspect learning methods described section4.2.addition including conditions information provided observation,action provided snapshot either simple composite (see Figure 1), is,action composed sequence actions. allows agents handle sequences actionssingle actions, observing.3.2 Additional Innovations Software Imagesection describes additional innovations proposal software image.important innovation ability store historic data. historic data provideslimited amount past snapshots. allows observers gather knowledge much faster,compared observing current action, necessary waitagent perform actions. However, innovation requires conditionshold perspective agent executing actions, is, stateenvironment instances visible attributes provided agent perceivesthem. Without agents perspective would hard, even impossible,observer know conditions holding past.Using agents perspective seen limitation compared usingobservers perspective acquiring conditions requires observeragents kind sensors visible attributes expert agentsobserve, understand information contained conditions (see section 4.1).However, always ensured observer direct access environmentobserved agent, like example, software environment observed323fiCosta & Botelhoagent running distinct process. cases, would necessary use complexcommunication mechanisms observer get access information differentprocess. would necessary observer used information providedsoftware image additional mechanism, software image indexdescribed section 4.1, provides shared repository registered softwareimages easily accessed.Another innovation software image use ontology describe knowledge agent sensors, visible attributes actions, tasks accomplishedrelationships elements. Using ontologies allows different agentsfollow ontology use designations kinds sensors,actions visible attributes tasks. ontology also enables specifickinds sensors, actions visible attributes associated specific tasks,allows agents know elements required perform task (see section 4.1).Another important aspect ontology possibility associating two different elements, opens possibility translations different ontologies.meta-ontology, call software image meta-ontology, created facilitatetranslation. meta-ontology defines basic elements ontologypossible relationships elements. Additional information subjectpresented future work.addition innovations, proposal also defines new protocol observingsnapshots software image. functionality developed software image,dynamic image notification, allows subscribed observers receive notificationstime new snapshot created dynamic image observed agent.allows observers know exactly observe, is,collect new snapshot dynamic image observed agent. following sectionexplains way agents learn observing (acquiring information agents softwareimage) expert.4. Learning Observationsection summarizes approach regarding complete learning observation process, following previous work subject (Costa & Botelho, 2012). shows newinsight learning process focuses important aspects process discovering observing experts methods learning information providedobservation. section also describes agents internal evaluation affectsagents behaviour.approach learning observation requires expert apprenticeagent software image since provides means comparing agentsalso data observation (see section 3). presents global view learningprocess comprises six activities, presented Figure 2, always happenstrict sequence. agent may also one two states regarding learningobservation process: learning state execution state. states,agent access subset learning process activities. Figure 2 showsactivities available state.324fiLearning Observation Agent Software ImagesLearningstateDiscoverysimilar expertExpertobservationStorage acquiredinformationLearn control knowledgepropose actionsEvaluationagents progressExecutionstateAcquisition currentstate sensorsLearn control knowledgepropose actionsApplicationlearnt knowledgeFigure 2: activities learning process stateFigure 2 shows, possible activities learning state concern discoveringobserving expert, retaining information acquired observation, learning controlknowledge propose actions evaluating proposed actions. possible activitiesexecution state concern acquiring current state environment (from agentsensors), learning control knowledge propose actions, executing proposed actionsevaluating executed actions. Figure 2 also shows that, result mimickingproperties mirror neurons, agents capable proposing actions learningexecuting actions (see section 4.2).approach provides two distinct methods learning information acquiredobservation, recall classification methods, specifically developedapproach. inspired two used algorithms learningobservation (see section 2.2). two methods combined present single solutionapprentice agents (see section 4.2), increases agents ability adapt differentsituations. agents able perform observed task facing conditionsexperts also similar task facing different conditions.internal evaluation, described section 4.3, one important activitieslearning process monitors agents ability propose correct actionstime. result monitoring measure agent confidence learntknowledge, confidence value. agent learning executionstate depending confidence regarding acquired knowledge.following sections describe important aspects approach learning observation learning process experts discovered, agent learnsinformation acquired observation internal evaluation works.4.1 Discovering Observing Expert Agentssoftware image, described section 3, addresses problem providing informationnecessary observation way universally accessible software agents.software image, apprentice software agents comparediscovered experts collect information actions executed expertconditions holding time expert decided execute actions.discovery service, software image index, developed facilitate discoveryexpert agents. allows software agents register software images sharedrepository agents able find them. agents use service discoversoftware images expert agents.325fiCosta & Botelhostarting observe expert, agent must know potentially possiblelearn observing particular expert. possible determineagent structures necessary task learn (see section 3.2), agents followBanduras (1977) social learning theory learn observing similar expert, is,expert whose static image structure instances atomicelements agents static image. agent uses comparison functionalitiessoftware image described Costa Botelho (2011) compare static image SIagentstatic image expert SIexpert . images match, SIagent SIexpert ,expert observed agent able immediately recognize actionsconditions snapshots (see section 3.1), solving correspondence problems(Alissandrakis, Nehaniv, & Dautenhahn, 2002; Argall et al., 2009).agent knows task learn structures abilitiesnecessary task, siT (see section 3.2), concept expertpotentially possible learn extended, allowing agents observe expert longintersection software images contains structures abilities, (SIagentSIexpert ) 3 siT . enough ensure apprentice agent able recognizeconditions activities expert snapshots necessary learningspecific task. agents determine structures abilities necessary performtask ontology, explained section 3.2.discovering expert observe, agent subscribes experts dynamicimage notification acquires snapshots history record (see section 3.2).notifications facilitate process observing expert since determineideal moment agent observe, new snapshot createdexperts dynamic image. agent acquiring snapshots history record,new snapshots created experts dynamic image also acquired storedtemporary memory.temporary memory functions buffer observation allows agenthandle snapshots different rate acquired. also allows agentkeep record experts actions might take place reading history.snapshots stored temporary memory handled history snapshotshandled, provides agent uninterrupted sequence snapshotsmoment past current moment.compared solutions searching history record demand,is, find relevant information particular problem, collecting informationhistory record efficient solution allows agent obtainlarge set experiences small amount time. Acquiring history recordensures solution particular problem found (if really existshistory) also provides agent increased amount information mightimportant solve problems future.important aspect approach learning observation preferenceobserving different experts. process discovering expert collecting snapshotsdynamic image referred observation period. process cyclicalmeaning agent may go several observation periods learning.beginning observation period agent free choose different expert observe,326fiLearning Observation Agent Software Imagesincreasing diversity knowledge different experts might provide differentpoints view task learn.different perspectives provided experts may increase agents knowledgeconditions never observed previous agents different approachperforming task. following section shows way agent increases knowledgehandles different approaches.4.2 Learning Observed Snapshotssection describes agent learns observed snapshots usesacquired knowledge propose actions set conditions. describesagent holds information contained snapshot memory. presents twomethods learning observed snapshots, recall classification methods,explains combined present single solution proposing actions.section also explains behaviour mirror neurons mimicked approachuseful learning.snapshots acquired observation describe relation optimal setconditions (C1 Cn) action A, C1 C2 Cn (see section 3.1).relation, call experience, stored agents memory heldtree structure. Using tree structure enables sequence snapshotsobserved intrinsically preserved structure, shown literature reviewsection 2. tree structure also facilitates consolidation agents knowledgestores different approaches task alternative paths.SETSETSETNewexp new experience store memoryPrevious experience snapshot observedStored falseExp <- experience agents memoryExp conditions NewexpExp action NewexpPUT Exp sub-tree PreviousSET Stored trueBREAKENDIFENDFORStored falseADD Newexp agents memoryPUT Newexp sub-tree PreviousENDIFFigure 3: process storing experiences memoryGiven agents observe different experts, sequence snapshotsobserved broken time agent starts observing another expert. happens,snapshot observed represents activity another expert therefore cannotfollowed new snapshots. prevent fragmentation duplication (multipleinstances experience) agents memory, process storing new327fiCosta & Botelhoknowledge agents memory compares new experience ones existingmemory storing it. Figure 3 describes process takes place.process described Figure 3 allows agent create new knowledge usinginformation already exists memory merely creating new connectionsexisting experiences. new experience stored existagents memory. tree structure holding agents memory allows agentsknowledge expressed decision tree, shown Figure 4, nodetree experience. Depending number branches starting node,experience followed one experience, adds possibilitychoosing sequence follow therefore provide different alternatives executingtask.PreviousexperiencesREFERENCEEXPERIENCEExperienceExperienceExperienceExperienceExperienceFollowingexperiencesExperienceTaskFigure 4: representation tree structure agents memoryrecall classification methods learning use information containedagents memory (the tree experiences shown Figure 4) propose actionsgiven conditions, call currentConditions. two methods distinguishway use information agents memory proposeactions. recall method proposes actions determining way experiencesconnected tree, whereas classification method proposes actionscategorizing individual experiences comparing categories categorycurrent problem.recall classification methods provide several possibilities actions.determine actions best suited execution, reliability associatedproposed action. reliability calculated method rangeszero one, inclusive. determines reliable action (zero reliable; one fullyreliable) method proposed it.328fiLearning Observation Agent Software Imagesrecall method proposes actions following connections experiences agents memory (see Figure 4). propose actions, method requiresreference experience agents memory indicates start followingconnections. reference, call referenceExperience, representslast action executed agent Act conditions holding action Cond.Figures 5 6 show way referenceExperience discovered agentsmemory.FUNCTION discoverReferenceExperience(Cond,Act)SET Similarity zeroSET RefExpExp <- experience memoryaction Exp ActExp conditions CondRETURN ExpELSESET Val similarityBetween(conditions Exp,Cond)Val bigger SimilaritySET RefExp ExpSET Similarity ValENDIFENDIFENDIFENDFORRETURN ExpENDFUNCTIONFigure 5: Obtaining referenceExperience agents memoryprocess Figure 5 shows, referenceExperience experiencememory whose action last action executed agent whoseconditions conditions holding last executed action. Givenagent might facing conditions expert, possibleconditions holding last executed action found agents memory.cases, referenceExperience one action shareslargest number similar conditions calculated process shown Figure 6.discovering referenceExperience agents memory, tree subset(the set tree branches) retrieved. tree subset represents choices experiences follow referenceExperience (see Figure 4). actionsexperiences represent several action possibilities proposed recall method.reliability action obtained similarity conditionsholding action (in experience) given currentConditions calculated process shown Figure 6. highest reliability given actionwhose conditions resemble currentConditions.Unlike recall method, classification method require referenceexperience agents memory propose actions. proposed actions providedadaptation classification algorithm trained experiences329fiCosta & BotelhoREQUIRE CondA size CondBFUNCTION similarityBetween(CondA,CondB)SET Sum zeroSET Size length set CondAC1 <- condition ExpInner <- (FOR C2 <- condition Cond)C1 equals C2ADD one SumBREAK InnerENDIFENDFORENDFORRETURN (Sum / Size)ENDFUNCTIONFigure 6: Obtaining similarity two sets conditionsagents memory. Previous experiments (Costa & Botelho, 2012) revealedsuited algorithms classification method KStar Cleary Trigg (1995)NNGE (Nearest Neighbour like algorithm using non-nested Generalized ExemplarsMartin, 1995). Since latter consumes resources choice falls KStaralgorithm.KStar algorithm adapted able propose representations agent actions.implementation KStar algorithm modified allow experiencesagents memory regarded positive examples proposed actionsdeduced. categorization capabilities also enhanced allow conditionsdefine differences classes. propose actions, classification methodcalculates distances conditions find experiences whose conditionscloser currentConditions. KStar algorithm uses entropy measuredistances two conditions (Cleary & Trigg, 1995).reliability actions proposed classification method directly associated much conditions holding action close currentConditions. again, entropy used measure distance. example, conditionsholding proposed action identical currentConditions reliabilityaction 1, is, action fully reliable standpoint classificationmethod.recall classification methods combined single solution. Agents usemethods propose actions choose best one current situation.help deciding action best current situation, recall classification methods associated weightFactor, whose initial minimum valuezero. weightFactor determines methods capable proposingsuitable action current situation. reliability proposed actioncombined weightFactor method proposed it, resultsfinalReliability (f inalReliability = reliability weightF actor). actionhighest finalReliability best one current situation.330fiLearning Observation Agent Software ImagesweightFactors change time agents capacity proposing actionsevaluated (see section 4.3). weightFactor method increases actionhighest reliability proposed method proven appropriate choiceinternal evaluation (see section 4.3). evaluation determines actionappropriate, weightFactor method decreases. explained section 4.3,amount weightFactor increases decreases depends valuereliability proposed action.recall classification methods learning propose actions agentlearning state execution state. possible actions proposedmethods simply representation agent actions, is, proposed actionsautomatically executed. agent control action goingactually executed. control allows agent behave exact wayobserving (in learning state) preparing execute actions (theexecution state), sense similar happens mirror neurons.ability propose actions learning state allows agent experienceactions observes preparing perform them, proposing actionsconditions observed snapshots. advantageous since allows agentrealize capable (or not) making decisions expert. also usefulagents internal evaluation decide agent acquired sufficient knowledgechange execution state, explained following section.4.3 Agents Internal Evaluationsection describes agents internal evaluation. shows way evaluation operatesaffects transition two states learning process, learningexecution state. describes way agents confidence updatedrelated agents ability propose appropriate actions.evaluation transversal process covers learning executionstate. main purpose evaluation ensure agents knowledge appropriatemastering task, influences agents internal confidence. agents internalconfidence expresses successes failures proposing appropriate actionsfaced conditions. Depending value internal confidence agent maylearning state execution state learning process. Two configurable thresholds,UpperConfidenceThreshold LowerConfidenceThreshold determinevalues agent changes learning execution state. Section 5.1shows values selected thresholds influence agents capabilities. Figure7 shows thresholds affect transition two states learningprocess.Figure 7 shows, agents confidence goes UpperConfidenceThreshold agent confident enough knowledge switches execution stateexecutes actions proposes (see section 4.2) conditions providedsensors relevant aspects internal state (the visible attributes).confidence goes LowerConfidenceThreshold agent stops confidentknowledge switches learning state acquires knowledgeobserving experts. value internal confidence affected agents capacity331fiCosta & BotelhoExecution StateLearning StateUpperConfidenceTresholdLowerConfidenceTresholdConfidenceFigure 7: influence confidence thresholds state transitionpropose appropriate actions whether observing (in learning state) preparingexecute actions (in execution state).agents internal evaluation constantly testing agents capacity proposecorrect actions, agent learning state execution state.learning state, agent tested ability propose actions conditionsobserved snapshots. agents confidence increases best action proposes(the one highest finalReliability explained section 4.2)action observed snapshot, otherwise confidence decreases. amountconfidence increases decreases depends reliability best actionproposed. example, action snapshot, B best action proposed(with reliability 0.8) 6= B, agents confidence decreases 0.8.Using reliability best proposed action factor increasing decreasingagents confidence simplest way including confidence methodslearning actions propose (see section 4.2) calculation agentsinternal confidence. way internal confidence updated gives importanceactions proposed high reliability, is, learning methodshigh confidence actions propose. cases, actions correctpenalization internal confidence larger methodslow confidence actions propose means agent learnt somethingwrong.execution state, agent tested ability execute correct actionfaced conditions, reflect agents perception sensors importantaspects internal state (see section 3.1). section 4.2 shows, executionstate agent selects action highest finalReliability, proposedrecall classification methods, executed. simple monitoring detectsproblem prevented correct execution action. Wheneverproblem detected agents confidence decreases. amountconfidence decreases depends reliability executed action (see section 4.2).simple monitoring execution actions limitations eventhough problems executing actions possible ensureaction appropriate faced conditions. overcome problem,approach allows evaluation receive external feedback executed actionsspecialized experts, teachers, evaluators specific applica332fiLearning Observation Agent Software Imagestion domain. possibility evaluation approximates approach paradigmlearning teaching goes beyond scope paper thereforepresented future work.Another important feature agents internal evaluation ability forceagent switch learning state independently confidence. forced switchinghappens agent faced certain amount unfamiliar conditions, is,conditions found observed snapshots. amount unfamiliar conditionscontrolled configurable threshold whose value depends application domain.explained section 3.1, conditions consist information provided agentsensors visible attributes. conditions familiar agent observedexpert facing conditions therefore knows exactly correct action propose.conditions familiar, agent never observed expert facingprobably means know actions propose. circumstances, amount unfamiliar conditions rises evaluation determinesexecuted action inappropriate. turn forced switching measurelast resort, amount unfamiliar conditions resets time agent faces familiarcondition. Therefore, amount represents number consecutive times agentfaces unfamiliar conditions.forced switch learning state, agents confidence decreasesconfigurable reference value, UnfamilarConfidenceReference,lower LowerConfidenceThreshold allow agent remain learningstate while. lower value UnfamilarConfidenceReference relationLowerConfidenceThreshold longer agent takes change backexecution state. simplest solution keep agent learning statetime.solutions take unfamiliar conditions account complexrequire agent find expert facing conditions. Sinceimpossible determine agent finds experts, would necessary developcomplex mechanisms allow agent return execution state time,thus preventing agent spending much time learning. similar behaviourachieved reducing confidence letting internal evaluation decidereturn execution state testing agents knowledge observing.role played evaluation, namely making agent return learning state,contributes overcome one major problems faced learning observation,fact agents limited performing actions observed. Forcingagent return learning state (and thus observe experts) gives agentopportunity increase knowledge since experts may different experiencesmight provide agent new knowledge.5. Experimental Resultssection describes two scenarios approach implemented. Sincescenarios software implementations, errors acquisition snapshotsconditions make sense therefore considered experiments. firstscenario designed appropriate learning observation majority333fiCosta & Botelhoexpert activity affect state environment. second scenario comparesapproach reinforcement learning approach typical reinforcement learningexperiment, mountain car experiment Sutton Barto (1998).scenario present direct comparison solutions provided reinforcementlearning algorithm approach learning observation. statistical relevancedata collected comparisons guaranteed students t-test.scenarios software implementations developed agents softwareimage. apprentice software agents observe experts effectively acquiringsnapshots experts software image. simplification, software imagesapprentice agents constituents software images expertsobserve. scenarios apprentice agents receive external feedbackteachers evaluators (see section 4.3) results reflect pure learningobservation approach.Despite process discovering identifying similar expert importantstep approach learning observation, results presented sectiondisclose process purpose focusing results benefits learningobservation. scenarios, apprentice agents use software image discovering,identifying collecting information necessary observation experts.Previous work software image (Costa & Botelho, 2011) presents resultsaspects.first scenario simulates agent virtual hand displays numbers signlanguage. numbers provided agent software number generatorprovides numbers one five. agent associated single numbergenerator knowledge number generators associated agentsparticipate simulation. time new number provided agent,virtual hand changed display number means sign language. virtualhand used communicating users graphical displayaccessible agents.However, agents virtual hand accessible representation current stateagents software image visible attribute (see section 3). way softwareagents obtain information state agents virtual hand softwareimage. visible attribute represents state visible hand object fiveattributes representing finger hand. attribute one twostates, DOWN.expert agent designed scenario specialized part holdsknowledge efficient way changing virtual hand representsnumber provided number generator. example, agent perceivesnumber one, virtual hand showing number two (the index middle fingersUP) necessary move middle finger DOWN, whereas handshowing number four, would necessary move middle, ring pinky fingersDOWN. part perceives numbers number generator specializedsensor. actuator five actions, one finger, change statefinger.increase complexity scenario, number generators need resettime time else stop generating new numbers. number sources either334fiLearning Observation Agent Software ImagesActive state Inactive state. source stops providing numbersInactive. reset changes source back Active state. this,expert agent another specialized part holds knowledgerefresh random number generator. state number generator perceivedspecialized part sensor indicates state generator.agent part one actuator single action resets source.apprentice agent developed scenario learn mastertwo tasks, manipulating agents virtual hand display perceived numbersresetting source, observing experts constituents capabilities. Likeexperts, apprentice agents two parts. One specializes manipulatingvirtual hand one sensor perceives numbers provided numbergenerator, one visible attribute displays state virtual hand one actuatorfive actions change state finger.part apprentice agent specializes managing source providesnumbers one sensor perceives state number source oneactuator single action resets source. Given description agentsensors visible attributes, conditions scenario (see section 3.1) consistnumber provided agent source, state virtual hand statenumber source.second scenario software implementation agent learns climbmountain simulated sinusoidal wave. agent must abide laws physicsclimb mountain, sufficient force, able climbmountain going forward only, needs accelerate backwards forwards gainmomentum. goal scenario reach top mountain, is,peak sinusoidal wave, taking least number decisions travelling smallestdistance (up mountain) possible.experts, provided scenario, know optimal way (the exact momentdirection need accelerate) climb mountain reach top. expertsperceive current speed direction location mountainsensors use information decide direction accelerate next.choose accelerating forward, accelerating backward accelerating(which maintains current speed).apprentice agents learn decide direction accelerate accordinglocation, speed direction. scenario includes two kinds apprentice agentscomparing two different learning methods. first kind apprenticeuses reinforcement learning algorithm (Q-Learning, implemented PIQLE toolComite, 2005) provide agent knowledge required climb mountain. reinforcement learning agent able perform three actions, accelerate forward,accelerate backwards maintain speed.reinforcement learning agent configured learning rate = 0.2discount factor/rate = 0.9, settings present best results.learning rate also decreases time following geometrical decay, allows agenteventually stop learning period time. simple reward scheme usedreinforcement learning algorithm. agent rewarded reaches goalscenario, top mountain. reward schemes would require use335fiCosta & Botelhokind supervisor determine ideal situations apply reinforcements.would changed comparison intended scenario, comparelearning observation situation apprentice agents need supervisors.case reinforcement learning agent simple reward scheme.information provided goal, embedded agent.second kind apprentice agent uses learning observation acquire knowledge climbing mountain. agent shares constituents capabilitiesexperts observes, made single part two sensors one actuator. sensors provide agent location mountain currentspeed (which positive agent moving forwards negative agent moving backwards). actuator provides agent three actions, accelerate forwards,accelerate backwards maintain speed.following sections present results simulations two scenarios.provide learning observation agent broader set experiences,simulations use one expert expert experiences scenario differentways, is, receive different information environment sensors.hand, one apprentice agent used simulations. simplificationensures risk tested apprentice agent observe apprentices,may mislead incorrect actions, instead observing experts.unit time used simulation results simulation step. simulationstep represents time slot participant agents take decision. learningobservation agents, simulation step either represent observation (the acquisitionsnapshot expert) subsequent learning (when agentlearning state), updating facing conditions (see section 3.1), proposing executingaction best suited faced conditions (when agent execution state)(see section 4). reinforcement learning agents simulation step represents updatingfacing conditions, selecting action conditions (from action-state pairsstored memories) executing action interpreting rewards (updatingaction-state pairs). expert agents, simulation step represents updating facingconditions selecting executing action best suited conditions.5.1 Results Virtual Hand Scenariosection shows impact changing confidence thresholds (see section 4.3)time spent learning total number actions appropriately executedagent. also shows way agents perform, terms number correctactions, two different settings.two settings depend sequence numbers provided number generators. control results simulation, numbers provided generatorsdesignated pre-determined sequence. number generators provide numbersfollowing sequence end sequence reached source needsreset agent. reset makes number generator provide numbers followingsequence.first setting (exp1 ) number generators apprentice expert agentsprovide sequence numbers. setting apprentice agent faces336fiLearning Observation Agent Software Imagesconditions sequence experts observes provides good testingground recall method learning (see section 4.2). setting shows agentcapable performing task observed experts.second setting (exp2 ), number generator different sequence numbersdifferent sizes, is, number generators need reset different times.apprentice agent faces conditions different faced observed expertsprovides good testing ground classification method learning (see section4.2). setting shows agent capable performing task similarobserved facing different conditions.Figure 8: impact changing confidence thresholdsBesides testing ground two learning methods, scenario also determines impact changing values UpperConfidenceThresholdLowerConfidenceThreshold (see section 4.3). reason, settingsinitially tested agents using different values thresholds. Figure 8 presentssummary results obtained second setting simulations 4000 steps (eachvariation thresholds tested simulation lasting 4000 steps). choice337fiCosta & Botelhosecond setting Figure 8 changing thresholds influencealso realistic approach scenario, since chancesagent find situation experts observes small.explained section 4.3, confidence thresholds affect length learning period number subsequent learning periods turn affects total numbercorrect actions performed agent throughout simulation. UpperConfidenceThreshold low, agent may enough time learn, decreasesagents performance terms able execute correct actions.UpperConfidenceThreshold high agent spends lot time learning,reduces time spent execution state therefore total number actionsexecuted agent lower.LowerConfidenceThreshold close UpperConfidenceThreshold agent switches learning execution state often (see section 4).may hinder agents ability complete task slightest error causesagent return learning state. LowerConfidenceThresholdfar apart UpperConfidenceThreshold, agent takes longer switchlearning execution. slows ability recognize mistakesswitching learning state. also slows recovery learning stateexecution state.results presented Figure 8 fall region LowerConfidenceThreshold changes zero fifty UpperConfidenceThreshold changesequal LowerConfidenceThreshold difference ten unitsLowerConfidenceThreshold. agent able performmaximum number correct actions time provided simulation (4000 steps).difference thresholds larger ten, total number correct actionsdecreases since agent takes longer change learning execution states.Figure 8 also shows length initial learning period increases LowerConfidenceThreshold increases. longer agent spends learning less timeperform actions. Therefore, Figure 8 shows, optimal values (forscenario) thresholds ten LowerConfidenceThreshold fifteenUpperConfidenceThreshold. provides agent learning periodlong enough agent learn necessary skills (so majority actions performs correct) short enough allow agent perform maximumamount actions (which 3923 actions according Figure 8).determining best values confidence thresholds, scenario simulated two settings (exp1 exp2 ) 4000 step simulation repeated100 times encompass time variations might exist simulations. Sincetwo settings prepared two learning methods mind, important lookimportance given agent methods setting. Table 1 showsaverage values weights recall classification methods learning (see section4.2) setting.Table 1 shows that, expected, recall method influence proposedactions agent faced conditions expert (exp1 )faces different conditions (exp2 ). first setting, weight recall methodmakes likely (more 50 % chance) actions proposed method338fiLearning Observation Agent Software ImagesSettingexp1exp2Recall Weight0.5090.317Classification Weight0.4910.683Table 1: average weights recall classification methods settingexecuted, even though actions proposed classification method alsoexecuted. second setting, classification method influenceproposed actions largest weight. agent able use recallmethod often follow sequence actions expert facingconditions different observed expert (see section 4.2).overview results simulating scenario two settings presentedTable 2. table compares time spent learning state executionstate, number actions agent able execute, many actionsappropriate also time simulation step learning executingactions. results Table 2 present average values standard deviationrunning simulation 100 times.Time spentlearning (s)Time spentexecution (s)Total actionsexecutedAmountappropriate actionsStep timelearning stateStep timeexecution stateaveragestdevaveragestdevaveragestdevaveragestdevaveragestdevaveragestdevExpert2.4150.60640000100 %00.6030.151Apprentice(exp1)1.620.1210.4350.95739050100 %017.0521.3052.6720.245Apprentice(exp2)134.9822.50323.3656.0173709.2531.1392.95 %7.73 p.p.35.8342.1296.3631.815Table 2: Overview results simulation virtual hand scenarioresults Table 2 show agent faces conditions expertsobserves (exp1 ) spends less time learning state able perform actionsthroughout simulation faces different conditions (exp2 ). agentfaces different conditions (exp2 ) spends time learning needs acquireknowledge requires knowledge come different sources improvegeneralization classification method (see section 4.2). leads agent spendtime discovering different experts learn also causes agent returnlearning state often.addition, high standard deviation values show agent faces differentconditions (exp2 ) number actions executed throughout simulation, time spentlearning time spent executing actions differs considerably. variation directly339fiCosta & Botelhoassociated randomness observed experts. time simulation run,apprentice observes different subsets available experts different sequence,changes knowledge retained agent throughout simulation affectsnumber actions executed time spent learning executing actions.Table 2 also shows facing conditions (exp1 ) actions executedagent appropriate, whereas facing different conditions (exp2 ) approximately 92% totality executed actions appropriate. importantindicator agent likely return learning state, startingexecute actions, facing different conditions (exp2 ).average time spent simulation steps, Table 2 shows cases,simulation step longer agents learning. expected sinceagent learning state perform various tasks discovering expertagents, comparing software image software images discovered experts,acquiring snapshots storing information, proposing actions conditionssnapshots evaluating proposals (see section 4).executing actions, simulation step apprentice agents longersimulation step experts, understandable given apprentice agentsrequire processing expert. Besides using two methods proposing actionsalso necessary take account influence internal evaluation. steptime executing actions also longer apprentice agent facing differentconditions (exp2 ), influences time spent executing actions. Even thoughapprentice agent executes fewer actions (only 3709), compared facingconditions (3905), spends time executing fewer actions. effectobserved time spent simulation step learning.happens facing different conditions agent needs acquireknowledge increases amount information agents memory. Sincerecall classification methods learning need process information containedmemory, larger amount information longer takes process it. effectfelt learning executing actions agent uses methodscases.closer look simulation results presented Figure 9, shows progressapprentice agents, terms number correct actions executed,throughout simulation. figure also shows progress state learningprocess (see section 4) throughout simulation apprentice agent. provideclearer presentation, results combined groups 100 simulation steps.Figure 9 shows that, apprentice agents face conditions expert(exp1 ) short learning period (of 200 steps) actions executecorrect. agent faces different conditions experts observes (exp2 ),initial learning period lasts little longer (about 300 steps) approximately 90%executed actions correct.agent also experiences additional learning periods (of short duration) throughoutsimulation. additional learning periods mainly caused evaluation activitymechanism forces apprentices switch learning state facing conditionsobserved (see section 4.3). Although subsequent learning periods affecttime spent learning short duration. Figure 9 shows, overall340fiLearning Observation Agent Software ImagesFigure 9: behaviour apprentice agent two settings throughout simulationpermanence subsequent learning periods exceed 3% totalsimulation steps.5.2 Results Mountain Car Scenariomountain car scenario compares expert agents, specialized climbing mountains, learning observation agents (LbO) learn observing experts performing task learn reinforcement learning agents (RL) learnreinforcements. participant agents face conditions, is, placedmountain starting points. observed experts also faceconditions learning observation agent.results present comparison based number actions, distance travelledtime spent reaching top mountain (the goal simulation).results also determine average time simulation step agent muchtime takes agent learn, is, much time takes agent reachtop mountain first time.341fiCosta & BotelhoSince scenario provides goal, simulation time-frame grouped attemptsachieving goal. attempt lasts variable number simulation steps,maximum duration 500 simulation steps. agent achieves goal 500steps attempt completed regarded successful. 500 steps goalachieved, attempt regarded failed. simulation lasts 50000 attempts,provide reinforcement learning agents enough time testing hypothesesprovide best results.Table 3 presents summary important aspects scenario amounttime, number attempts, number actions distance travelled agent reachtop first time. table also shows many times agent reached topmountain, average time simulation step average amount simulationsteps attempt reach goal. data Table 3 obtained runningscenario 100 times encompass time variations. students t-test used ensurestatistical relevance data collected running scenario.Time reach topfirst time (ns)Attemptsreaching top firsttimeActions executedreach top firsttimeDistance travelledreach top firsttimeNumber timesreached topAveragesimulation step time(ms)Average simulation steps spentattemptExpertApprentice(LbO)Apprentice(RL)T-TEST(LbO - RL)303300146602.2 107111053.4 1010136278524713.2 10102.732.73610.372.5 1095000050000498952.9 10100.284.940.312.7 1039136136.01229.924.9 1012Table 3: Overview results simulation mountain car scenarioTable 3 shows that, expected, expert agent exhibits best results aspects.table also shows learning observation agent outperforms reinforcementlearning agent aspects exception time simulation step.learning observation agent also gets close results expert aspectsexception time takes reach top simulation step time.compared reinforcement learning agent, simulation step learningobservation agent lasts longer amount processing behind decision.342fiLearning Observation Agent Software ImagesNevertheless, learning observation agent requires less simulation steps completeattempt, is, reach goal. main reason longer simulation steplearning observation agent uses two methods proposing actions (therecall classification methods explained section 4.2) requires additionaleffort combining results choosing best action them. agent alsoperform set tasks, like example internal evaluation (see section4.3). performance software used agent likely improved futureversions, would lead improvement simulation step time.Although simulation step reinforcement agent takes less time, agent requiressteps attempts reach top mountain first time eventuallytakes time learn reach top mountain results Table 3show. puts reinforcement agent last place considering time takesreach top first time. results t-test Table 3 show dataacquired simulations statistically relevant.Figure 10: General view results second scenario343fiCosta & Botelhoaddition information achieving goal first time, also importantknow agents performed throughout simulation. Figure 10 shows progressexpert two apprentice agents (learning observation reinforcementlearning) throughout simulation terms distance travelled, number timesreaching top number simulation steps required reach top. clearerpresentation, results combined groups 100 attempts reach goal.attempt lasts number simulation steps ranges 136 500, dependingnumber steps necessary reach top mountain (see Table 3).results presented Figure 10 show learning observation agent performsbetter reinforcement learning agent considered dimensions. figure showslearning observation agent requires less simulation steps (in comparisonreinforcement learning apprentice) go starting point top mountainlearning it. simulation steps spent attempt stabilizes 136(which number steps spent expert) right agent learnttask climbing mountain. learning observation agent also requires less attemptslearn reach top (1 attempt shown Table 3).distance travelled learning observation agent also smallerdistance travelled reinforcement learning agent. value distance,learning observation agent, stabilizes 2.73 (the expert Table 3 shows)right agent learns task climbing mountain, unlike happensreinforcement learning agent. Figure 10 shows, even long learning period,reinforcement learning agent able learn efficient way climbmountain (the one requires least amount actions smallest distance). Evenlowest values fluctuations number actions travelled distancestill far away obtained learning observation agent.Besides inabilities, reinforcement learning agents capability reachinggoal fluctuates 90% 100% times, almost end simulation.means even learning reach goal, reinforcement learning agentalways able it, something also observed total number timesagent reaches top mountain Table 3. contrast, learning observationagent exhibits stable results learning task reaching top mountain.6. Conclusions Future Workadoption learning observation solutions relatively new computer science and,latest approaches show, still development (Sullivan, 2011; Kulic et al., 2011;Tan, 2012; Fonooni, Hellstrom, & Janlert, 2012). exception work (Costa& Botelho, 2011, 2012) Machado Botelhos (2006) work, contributionslearning observation focused robotic agents physical properties. Softwareagents even software used robots neglected. Even Machado Botelhoswork limitations since addressed problem learning vocabularyallow generalizations acquired knowledge. means that, unlike approach,apprentice agent able learn control mechanisms neither capable dealingconditions different observed expert.344fiLearning Observation Agent Software ImagesTherefore, learning approach clearly contributes advance state artlearning observation, providing software agents learning solution differentmethods usually applied software agents. Unlike roboticapproaches learning observation, software approach limited softwareagents. also used robotic agents minor adaptations, since physicalactions controlled reflected software events. Even data collected roboticsensors needs software representation (however complex be), since corerobot effectively running program high level decisions made program.Thus, software approach provides broader solution approaches limitedphysical properties robotic environments.experimental results section 5 show software agents capable improvingability perform task using approach. first scenario also showsclassification method learning essential situations agent facingexactly sequence events expert. Namely, situations agentfaced conditions different faced experts observed.usual scenarios learning observation, reported literature, address casesapprentice expert agents face exactly conditions. kindsituation ideal sequence learning, reason method oneused learning observation approaches. inclusion classificationmethod, ability learn observation extended problems domains.combination classification method recall method, inspiredsequence learning, ensures agent able adapt, itself, larger numbercircumstances, including usual learning observation scenarios.Besides combination two methods, approach also provides internalevaluation mechanism constantly tests agents knowledge. allows agentknow needs acquire knowledge acquired sufficient knowledgetherefore execute actions. approach also offers possibility using externalfeedbacks enhance agents evaluation, gives agents ability knowingactions execute appropriate.agents internal evaluation enables learning observation agents enhanceknowledge even stop observing experts start using acquired knowledge,since starting use knowledge may go back learning state.one major drawbacks previous learning approaches. usual way handlingmanually feeding new examples whenever agent requires them. caseapproach agent able decide needs return learningstate, observe experts. process require intervention since agentfind experts collect new training examples.application approach two distinct scenarios shows adapteddifferent domains. scenarios also show amount time taken learningapproach decide actions execute sometimes high. However, secondscenario shows, agents able achieve goal less time reinforcementlearning approach, even situations already shown literatureadequate reinforcement learning. learning observation agents also ableachieve approximately results experts observe.345fiCosta & BotelhoAlthough apprentice agents take time choose actions executeexperts, difference smaller first scenario. Considering that, first scenario, experts knowledge expressed rules second scenario,approach, unlike reinforcement learning, able cope increase complexityterms number rules required express experts knowledge.Besides providing new insight learning software agents, softwareimage, approach also contribute software embodiment problem. Althoughmain purpose directed learning observation, software image also allows visiblesoftware agents represent called body. future workmay continue developing software image better adapt software embodimentproblem.also intend continue testing approach different scenarios, especiallysituations actions effects agent environment.situations part effect actions visible environment. expectresults similar situation effects actions visibleenvironment visible effects enough distinguish actions. However,visible effects enough distinguish actions, agents learneffects actions might able learn properly.example, effect action one removing number environmentadding agents internal memory effect action two removing numberenvironment subtracting agents internal memory. actionsdifferent effects agent, visible effects environment exactly same.situation, agent learns visible effects actionsable distinguish two actions.Finally, also consider improving approach open possibility agentperforming task radically different tasks performed observedexperts. agent able use acquired knowledge way allowsperform new tasks never observed before.Acknowledgmentspaper reports PhD research work, Doctoral Program Information ScienceTechnology ISCTE-Instituto Universitario de Lisboa. partially supportedFundacao para Ciencia e Tecnologia PhD Grant number SFRH/BD/44779/2008FCT project PEst-OE/EEI/LA0008/2013ReferencesAlissandrakis, A., Nehaniv, C., & Dautenhahn, K. (2002). Imitation ALICE: learningimitate corresponding actions across dissimilar embodiments. Systems, ManCybernetics, Part A: Systems Humans, IEEE Transactions on, 32 (4), 482496.Argall, B. D., Chernova, S., Veloso, M., & Browning, B. (2009). survey robot learningdemonstration. Robotics Autonomous Systems, 57 (5), 469483.Bandura, A. (1977). Social Learning Theory. Prentice Hall.346fiLearning Observation Agent Software ImagesBillard, A., & Hayes, G. (1999). Drama, connectionist architecture control learningautonomous robots. Adaptive Behavior, 7, 35-64.Billing, E. A., Hellstrom, T., & Janlert, L. E. (2010). Behavior Recognition LearningDemonstration. Proceedings IEEE International Conference RoboticsAutomation, Alaska.Billing, E., Hellstrom, T., & Janlert, L. E. (2011). Simultaneous control recognitiondemonstrated behavior. Tech. rep., UmeaUniversity, Department ComputingScience.Botelho, L. M., & Figueiredo, P. (2004). body living room tellagent. Proceedings AAMAS 2004 Workshop Balanced Perception ActionEmbodied Conversational Agents.Byrne, R. W. (1999). Imitation without intentionality. Using string parsing copyorganization behaviour. Animal Cognition, 2 (2), 6372.Chernova, S. (2009). Confidence-based Robot Policy Learning Demonstration. Phd,Carnegie Mellon University.Cleary, J. G., & Trigg, L. E. (1995). K*: Instance-based Learner Using EntropicDistance Measure. 12th International Conference Machine Learning, pp. 108114. Morgan Kaufmann.Clegg, B. A., DiGirolamo, G. J., & Keele, S. W. (1998). Sequence learning. TrendsCognitive Sciences, 2 (8), 275281.Comite, F. D. (2005). Java Platform Reinforcement Learning Experiments. JourneesProblemes Decisionnels de Markov et Intelligence Artificielle PDMIA 2005, 100107.Costa, P. A. M., & Botelho, L. M. (2011). Software Image Learning Observation.Antunes, L., Pinto, H. S., Prada, R., & Trigo, P. (Eds.), Proceedings 15thPortuguese Conference Artificial Intelligence, pp. 872884, Lisbon, Portugal.Costa, P. A. M., & Botelho, L. M. (2012). Learning Observation Software Agents.Proceedings 4th International Conference Agents Artificial Intelligence(ICAART 2012), 2 (Agents), 276281.Dautenhahn, K., & Nehaniv, C. L. (2002). agent-based perspective imitation.Imitation animals artifacts, 140.Demiris, J., & Hayes, G. (2002). Imitation dual-route process featuring predictivelearning components: biologically plausible computational model. Dautenhahn,K., & Nehaniv, C. (Eds.), Imitation animals artifacts (MIT Press edition).,pp. 327361. Cambridge.Etzioni, O. (1993). Intelligence without Robots (A Reply Brooks). AI MAGAZINE, 14,7-13.Fonooni, B., Hellstrom, T., & Janlert, L.-E. (2012). Learning High-Level BehaviorsDemonstration Semantic Networks. Proceedings 4th International Conference Agents Artificial Intelligence (ICAART).Hajimirsadeghi, H., & Ahmadabadi, M. (2010). Conceptual imitation learning: application human-robot interaction. Machine Learning, 331346.347fiCosta & BotelhoHeyes, C., & Ray, E. (2000). significance imitation animals?. AdvancesStudy Behavior, 29, 215245.Kulic, D., Ott, C., Lee, D., Ishikawa, J., & Nakamura, Y. (2011). Incremental learningfull body motion primitives sequencing human motion observation.International Journal Robotics Research, 31 (3), 330345.Lopes, M., & Santos-Victor, J. (2007). developmental roadmap learning imitationrobots.. IEEE transactions systems, man, cybernetics. Part B, Cybernetics: publication IEEE Systems, Man, Cybernetics Society, 37 (2), 30821.Machado, J., & Botelho, L. (2006). Software agents learn observation (shortpaper). Proceedings International Joint Conference Autonomous AgentsMultiAgent Systems.Machado, J. a. (2006). Imagem Visual Corpo de Software: Aquisicao de Vocabulario porObservacao. Masters thesis, ISCTE.Maistros, G., & Hayes, G. (2004). Towards Imitation System Learning Robots.Vouros, G., & Panayiotopoulos, T. (Eds.), Methods Applications ArtificialIntelligence, pp. 246255. Springer Berlin / Heidelberg.Martin, B. (1995). Instance-Based learning : Nearest Neighbor Generalization. Masters thesis, University Waikato, Hamilton, New Zealand.Mataric, M. J. (1997). Studying Role Embodiment Cognition. CyberneticsSystems, 28, 457-470.Meunier, M., Monfardini, E., & Boussaoud, D. (2007). Learning observation rhesusmonkeys.. Neurobiology learning memory, 88 (2), 2438.Mitchell, T. (1997). Machine learning. McGraw-Hill Publishing Company, New York.Quick, T., Dautenhahn, K., Nehaniv, C., & Roberts, G. (2000). essence embodiment:framework understanding exploiting structural coupling systemenvironment. AIP conference proceedings, pp. 649660. Citeseer.Ramachandran, V. (2000). Mirror neurons imitation learning driving force behindgreat leap forward human evolution. Edge Website article http://www. edge.org/3rd\ culture/ramachandran/ramachandran\ p1. html.Ramachandran, V. (2003). emerging mind: Reith Lectures 2003. Profile Books.Rao, R. P. N., Shon, A. P., & Meltzoff, A. N. (2004). Bayesian Model ImitationInfants Robots. Imitation Social Learning Robots, Humans,Animals, 217-247.Rizzolatti, G., Fadiga, L., & Gallese, V. (1996). Premotor cortex recognitionmotor actions. Cognitive brain research, 3 (2), 131141.Sullivan, K. (2011). Multiagent Hierarchical Learning Demonstration. InternationalJoint Conference Artificial Intelligence, 28522853.Sun, R. (2001). Introduction Sequence Learning. Lecture Notes Computer Science,110.Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning. MIT Press, Cambridge, MA.348fiLearning Observation Agent Software ImagesTan, H. (2012). Implementation Framework Imitation Learning HumanoidRobot Using Cognitive Architecture. Zaier, D. R. (Ed.), Future HumanoidRobots - Research Applications, chap. 10. InTech.Wood, M. A. (2008). agent-independent task learning framework. Phd thesis, UniversityBath.349fiJournal Artificial Intelligence Research 47 (2013) 71-93Submitted 11/12; published 05/13Identifying Class Maxi-Consistent Operators ArgumentationSrdjan VesicVESIC @ CRIL . FRCRIL - CNRSRue Jean Souvraz SP 18F 62307 Lens CedexFRANCEAbstractDungs abstract argumentation theory seen general framework non-monotonicreasoning. important question then: class logics subsumedinstantiations theory? goal paper identify study large classlogic-based instantiations Dungs theory correspond maxi-consistent operator, i.e.function returns maximal consistent subsets inconsistent knowledge base.words, study class instantiations every extension argumentation systemcorresponds exactly one maximal consistent subset knowledge base. showattack relation belonging class must conflict-dependent, must valid, mustconflict-complete, must symmetric etc. Then, show attack relations servelower upper bounds class (e.g. attack relation contains canonical undercutmember class). using results, show existing attack relations whetherbelong class. also define new attack relations membersclass. Finally, interpret results discuss general questions, like: addedvalue argumentation setting? believe work first step towards achievinglong-term goal, better understand role argumentation and, particularly,expressivity logic-based instantiations Dung-style argumentation frameworks.1. Introductionquestion whether Dungs (1995) abstract theory used general framework nonmonotonic reasoning drawn particular amount attention among researchers artificialintelligence. precisely, question is: existing new approaches reasoning seeninstantiations Dungs theory? certainly general question. Furthermore, differentapproaches suppose available knowledge represented different form. paper studies problem setting one given finite inconsistent set classical propositional logicformulae, refer knowledge base. number approaches dealinginconsistent information: notable example paraconsistent logics (Priest, 2002) oneable draw (but all) conclusions inconsistent set formulae. Indeed,paraconsistent logic allows subset inferences could obtained using classical logicknowledge. examples dealing inconsistent knowledge include beliefrevision (Gardenfors, 1988), belief merging (Konieczny & Perez, 2011) voting (Arrow, Sen, &Suzumura, 2002). completely precise, note approaches one givenmultiset instead set, example several voters express knowledge preferences number agents stating / voting proposition important. However,paper, suppose information represented form set.c2013AI Access Foundation. rights reserved.fiV ESICGenerally speaking, call operator function provides way go inconsistent knowledge base set subsets knowledge base. Examples operators are:function returning maximal set inclusion consistent subsets knowledge base, called maxiconsistent operator, function returning maximal cardinality consistent subsets knowledgebase, called maxi-card operator, function returning consistent subsets knowledge base...understand extent Dungs theory used general frameworkreasoning, essential study link result obtained applying operatorknowledge base extensions argumentation framework F = (Arg(), R),set , denote Arg(S) set arguments built S, Rrelation used identifying attacks arguments. papers (Cayrol, 1995; Caminada & Amgoud, 2007; Amgoud & Besnard, 2009, 2010; Amgoud & Vesic, 2010; Gorogiannis& Hunter, 2011) studying notions somehow related link knowledgebase corresponding argumentation framework. However, since work Dung (1995),almost papers studying link operator instantiation Dungs theory. Cayrol (1995) showed instantiation Dungs theory using stable semantics directundercut attack relation, corresponds maxi-consistent operator. argumentation community,one-to-one correspondence sometimes identified main objection pure logic-basedargumentation, additional value constructing argumentation frameworksaid questionable (since computing extensions applying maxiconsistent operator). However, recent work Vesic van der Torre (2012) showsexists large class logic-based instantiations Dungs abstract theory two interestingfeatures: (i) returns extensions correspond maximal consistent subsets initialknowledge base, (ii) result satisfies basic argumentation postulates (Caminada & Amgoud,2007), e.g. consistency, closure... paper shows space logic-based instantiationsDungs theory much larger believed.previous result makes question class operators viewedinstantiations Dungs theory? even relevant research topic. aimgiving broad overview class. First note that, interestingly, rather big classinstantiations Dungs theory returning inconsistent results, showed Caminada Amgoud(2007). However, one would normally prefer avoid type behaviour, study classinstantiations returning consistent results.1 Thus, long-term goal identify wholeclass instantiations Dungs theory yield consistent result. However, certainlyhard task. start noticing that, given set , common well-known way dealinconsistent information use maxi-consistent operator, i.e. select maximal consistentsubsets . Also, conjecture one biggest2 sub-classes class instantiationsreturning consistent result class instantiations corresponding maxi-consistent operator.first goal, main goal paper, study class. (Notegeneral approach would consider set maxi-consistent subsets selection functionf among maxi-consistent subsets. Thus, maxi-consistent sets would usedreasoning. However, present paper studies case maxi-consistent subsetstaken account since already captures significant number systems.)1. Note consensus regarding postulates (e.g. indirect consistency), postulates(e.g. direct consistency) enjoy much wider acceptance.2. informally, sense: number known instantiations72fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONparticularly, paper aims answering following questions: propertiesattack relations semantics used instantiations Dungs theory correspond maxiconsistent operators? necessary sufficient conditions attack relationbelongs class (under given semantics)? properties satisfy: must (not)conflict-dependent, valid, symmetric, ... ? identify sub-classes attack relations belonging / belonging class? find lower / upper bound (in terms setinclusion) class attack relations? existing (in literature) attack relations belongclass semantics? new attack relations belonging class?paper organised follows: Section 2 introduces main notions argumentation theory use rest paper. Section 3 formally defines class instantiations corresponding maxi-consistent operator. Section 4 shows properties satisfied attack relationsbelonging class. Section 5 identifies several classes attack relations (not-)correspondingmaxi-consistent operator. Section 6 shows (to best knowledge) existing attack relations literature whether belong class, also defines new attack relationmember class. last section concludes discusses related work.2. Basics Argumentationalready mentioned, paper supposes one given set classical propositional logicformulae . use well-known (e.g. Besnard & Hunter, 2001; Amgoud & Cayrol, 2002;Gorogiannis & Hunter, 2011) logic-based approach instantiating Dungs theory. L denotesset well-formed formulae, ` stands classical entailment, logical equivalence.use notation MC() set maximal consistent subsets .logical argument defined pair (support, conclusion).Definition 1 (Argument). argument pair (, ) minimal (for setinclusion) consistent set formulae ` .argument = (, ), use function Supp(a) = denote supportConc(a) = denote conclusion.Example 1. Let = {, , }. = ({, }, ), b = ({ }, )c = ({, }, ) arguments constructed . example,Supp(a) = {, } Conc(a) = .given set formulae S, denote Arg(S) set arguments constructedS. Formally, Arg(S) = {a | argument Supp(a) S}. Let Arg(L) denote setarguments constructedSfrom language propositional logic. given setarguments E, denote Base(E) = aE Supp(a). suppose function Arg defined Lfunction Base defined Arg(L); slightly abusing notation, sometimes writeArg (respectively Base) restriction functions set formulae (respectivelyarguments).Definition 2 (Argumentation system). argumentation system (AS) pair (A, R)Arg(L) set arguments R binary relation. pair (a, b) R, sayattacks b. also sometimes use notation aRb instead (a, b) R.73fiV ESICorder simplify notation, explicitly mention argumentation systemclear context argumentation system refer to. Since arguments builtformulae, suppose attack relation defined specifying condition everytwo arguments b, attacks b condition definitionattack relation satisfied. example, condition conclusion logicallyequivalent negation conclusion b. suppose attack relations definedset Arg(L) Arg(L), every set Arg(L), use restriction attackrelation set AA. why, order simplify notation, simply write R attackrelation defined set Arg(L) Arg(L) well restriction attack relationevery set A, Arg(L).order determine mutually acceptable sets arguments, different semanticsintroduced argumentation. first introduce basic notions conflict-freeness defence.Definition 3 (Conflict-free, defence). Let F = (A, R) AS, E A.E conflict-free exist arguments a, b E R bE defends every b b R exists c Ec R b.Let us define commonly used semantics.Definition 4 (Acceptability semantics). Let F = (A, R) B A. say set Badmissible conflict-free defends elements.B complete extension B defends arguments containsarguments defends.B preferred extension maximal (with respect set inclusion) admissible set.B stable extension B conflict-free \ B, exists b Bb R a.B semi-stable extension B complete extension union setB set arguments attacked B maximal (for set inclusion).B grounded extension B minimal (for set inclusion) complete extension.B ideal extension B maximal (for set inclusion) admissible set containedevery preferred extension.argumentation system F = (A, R) denote Extx (F); or, slight abusenotation, Extx (A, R) set extensions respect semantics x. use abbreviationsc, p, s, ss, g respectively complete, preferred, stable, semi-stable, grounded idealsemantics. example, Extp (F) denotes set preferred extensions argumentation system F.Example 2. Let F = (A, R) argumentation framework = {a, b, c, d} R ={(b, c), (c, b), (b, d), (c, d)}. two preferred/stable/semi-stable extensions: {a, b} {a, c};three complete extensions: {a}, {a, b} {a, c}; one grounded/ideal extension: {a}.74fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATION3. Defining Problem Settingnow, specified to, knowledge base , construct argumentation system F =(Arg(), R), then, using chosen semantics, calculate extensions. Since componentssystem except semantics attack relation fixed, whether instantiationcorresponds maxi-consistent operator depends exclusively two components. nextdefinition provides formal definition mean saying instantiation Dungsframework corresponds maxi-consistent operator. idea function Argbijection MC() extensions corresponding argumentation system.Definition 5 (MC Ext). Let x argumentation semantics. say attack relation Rsatisfies (MC Extx ) every finite set propositional formulaeArg bijection MC() Extx (Arg(), R)means every set MC(), holds Arg(S) Ext(Arg(), R)every E Ext(Arg(), R), exists MC() E = Arg(S). example, sayattack relation R satisfies (MC Extc ) every finite , Argbijection MC() Extc (Arg(), R). Sometimes, clear contextsemantics refer semantics important, use simplified notation(MC Ext). say attack relation R falsifies (MC Extx ) R satisfy(MC Extx ). following example shows attack relation satisfy (MC Exts ).Example 3. Consider attack relation known defeating rebut, denoted Rdr definedfollows: two arguments b, say attacks b write aRdr bConc(a) ` Conc(b). attack relation falsifies (MC Exts ). see why, sufficient findset formulae Arg bijection MC() (Arg(), Rdr ). end,consider = { , } denote F = (Arg(), Rdr ). see MC() = {S1 , S2 }S1 = { } S2 = { }. Denote E1 = Arg(S1 ) E2 = Arg(S2 ). Exts (F) 6={E1 , E2 } Rdr satisfy (MC Exts ). Consider argument = ({ }, ),note E1 . Observe every argument b Arg(), bRdrConc(b) ` ( ). words, every argument b Arg(), b attacksConc(b) ` . Recall Definition 1 know every argument b,Supp(b) ` Conc(b). Thus, every argument b Arg(), bRdr Supp(b) ` .Since = { , } argument b Arg() Supp(b) ` .Thus, argument attacked argument E2 . means E2 stable extensionF. Consequently, Arg bijection MC() Exts (F). Hence, Rdr falsifies(MC Exts ).3.1 Complete Incomplete Systemstwo ways study link instantiated argumentation system F (containingarguments attacks them) corresponding knowledge base (containing formulae). first scenario follows:choose attack relation R semantics xstart finite knowledge base75fiV ESICconsider system F = (Arg(), R), containing arguments builtcompare result obtained using operator one obtained calculatingextensions Fcase, say obtained argumentation system complete. Every complete systeminfinite number arguments, every complete system F, exists finite systemF 0 F F 0 equivalent. formally define equivalence argumentationsystems topic present paper; details reader invited consultliterature subject (Amgoud, Besnard, & Vesic, 2011).second possibility converse:given attack relation R semantics x,start argumentation system F = (A, R),define set formulae used supports arguments F, is, definedef= Base(A)compare result obtained using operator one obtained calculatingextensions Fobtained argumentation system may incomplete, sense =6 Arg(Base(A)).important difference two scenarios. Namely, first case,arguments built considered calculating Extx (F). second case,contains formulae A, F, formulae equally represented. Let us illustratesituation.Example 4. Let R defined as: every a, b Arg(L), (a, b) R existsSupp(b) Conc(a) . Let us use preferred semantics. Let F = (A, R)= {a, b} = ({, }, ) b = ({}, ). case, since b attacksvice versa, extension E = {b}. Note conclusion accepted argument. However, take union formulae used supports arguments F,obtain = {, , }. two maximal consistent subsets knowledge base:MC() = {{, }, {, }}.clear setting similar previous example, or, generally,second scenario, one cannot expect Arg bijection MC() Ext(A, R). But,incomplete argumentation system stand for? obtained? conclude system6= Arg(Base(A)) meaningless would certainly hasty. Let us considerquestion detail. Namely, know missing arguments added intelligentagent. first add missing arguments calculate extensionscomplete version system? two possible answers: (1) yes, must add missingarguments order take account available information; (2) no, since givenargumentation system arguments constructed (in case monological argumentation) uttered (in case dialogical argumentation). arguments (1) (2) makesense different applications: first possibility corresponds case want simulateresource unbounded agent, take account information (where information seen76fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONformulae) known agent(s). Note disadvantages since so, ignoreargumentational representation problem. second possibility used wantknow output argumentation system is, take account factarguments constructed (e.g. lack computational resources, sincegiven argumentation framework representing dialogue everything said).Note numerous works 1990s (Pollock, 1992; Vreeswijk, 1997; Loui, 1998) yieldconceptual philosophical arguments supporting partial computation (i.e. incomplete systems).important part Vreeswijks (1997) work devoted defining constructing completeargumentation systems. Loui (1998) discusses philosophical difference demonstrativereasoning non-demonstrative reasoning claims realistic (i.e. resource-bounded)setting, reasons demonstrative, process disputation essential reasoning. Note, however, none frameworks instantiation Dungs system,formalisations works differ lot framework studied paper. goalpresent paper argue complete systems sense better incompleteones (or vice versa), study possibilities limits related instantiating Dungs abstract theory. analyse difference complete incomplete systems,find necessary point exist, order make context researchquestion clear. second scenario, reasonable expect correlationresult obtained directly F. why, rest paper supposefirst scenario.4. Properties Relations Satisfying (MCExt)section, analyse properties attack relations satisfying (MC Ext). first showcondition satisfied, function Base : Ext(F) MC() inverse functionfunction Arg : MC() Ext(F).Proposition 1. Let R attack relation x acceptability semantics. relation R satisfies(MC Extx ) then:every MC(), = Base(Arg(S)),every E Extx (F), E = Arg(Base(E)).Proof. Let finite set propositional formulae let F = (Arg(), R).Let MC() E = Arg(S). Since R satisfies (MC Ext), E Extx (F). Let0 = Base(E) let us suppose 6= 0 . Let us study two cases.Let \ 0 6= 0 \ 0 . means argument E0 Supp(a) 0/ S, contradiction.Let 0 \ 6= 0 0 \ S. means argument E0 Supp(a). Contradiction 0/ S.Since \ 0 = 0 \ = , = 0 ; words, Base(Arg(S)) = S.Let E Extx (F) = Base(E). Since R satisfies (MC Extx ), existsunique 0 MC() Arg(S 0 ) = E. Let us prove = 0 .77fiV ESICLet us suppose \ 0 6= let \ 0 . means argumentE Supp(a). Contradiction fact/ S0.Suppose 0 \ 6= 0 0 \ S. 0 0 , concludeexists E 0 Supp(a). Contradiction fact 0/ S.\ 0 = 0 \ = , conclude = 0 . Thus, Arg(Base(E)) = E.Let us illustrate result following example.Example 5. Consider attack relation known direct undercut, denoted Rdu definedfollows: two arguments b, say attacks b write aRdu bexists Supp(b) Conc(a) . known direct undercut satisfies (MC Exts )(Cayrol, 1995). Proposition 1, see every , every MC(), holds= Base(Arg(S)) and, interestingly, every E Exts (Arg(), Rdu ),E = Arg(Base(E)).previous result allows easily show attack relation satisfies (MC Ext),every extension consistent base union arguments conclusions consistent.Corollary 1. Let R attack relation x semantics. Let R satisfy (MC Extx ) letfinite set formulae. Denote F = (Arg(), R). Then, every E Extx (F), have:Base(E) consistentaE Conc(a) consistentProof. Let E Extx (F). Since R satisfies (MC Extx ), exists MC()E = Arg(S). Proposition 1, obtain E = Arg(Base(E)). Since Arg injective function,every 0 MC(), E = Arg(S 0 ) = 0 . Thus, = Base(E). Consequently, Base(E)consistent set. clearevery argument E, Base(E) ` Conc(a). SinceBase(E) consistent, aE Conc(a) consistent well.Note use previous result show attack relation satisfy (MC Ext).Namely, attack relation returns extensions inconsistent bases, violates (MC Ext).Corollary 2. Let R attack relation, x acceptability semantics. exists finiteknowledge base exists extension E Extx (Arg(), R) Base(E)inconsistent, R satisfy (MC Extx ).4.1 Conflict-Dependence Validitysubsection, study link satisfying (MC Ext) conflict-dependencevalidity. attack relation conflict-dependent whenever argument attacks another one,union supports inconsistent (Amgoud & Besnard, 2009).Definition 6 (Conflict-dependent). Let R Arg(L) Arg(L) attack relation. say Rconflict-dependent every a, b Arg(L), (a, b) R Supp(a) Supp(b) `.78fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONprove conflict-dependence necessary condition satisfying (MC Ext).completely precise, specify say semantics x returns conflict-free setsevery argumentation system (A, R), every E Extx (A, R), holds Econflict-free respect R. semantics Definition 4 return conflict-free sets.Proposition 2. Let R attack relation x semantics returning conflict-free sets. Rsatisfies (MC Extx ), R conflict-dependent.Proof. Let us suppose contrary, i.e. let R attack relation conflict-dependent, letknowledge base let a, b Arg() aRb Supp(a) Supp(b) consistent.Thus, exists set MC() Supp(a)Supp(b) S. Since R satisfies (MC Extx )E = Arg(S) extension corresponding argumentation system F = (Arg(), R).means a, b E. Contradiction assumption x returns conflict-free extensions.Thus, R must conflict-dependent.proved this, know relation satisfying (MC Ext) enjoys propertiesconflict-dependent relations. example, shown attack relation conflictdependent, self-attacking arguments (Amgoud & Besnard, 2009).Corollary 3. Let R attack relation x semantics returning conflict-free sets. R satisfies(MC Extx ) every argument Arg(L), (a, a)/ R.Proof. Proposition 2, R conflict-dependent. Then, self-attackingarguments (Amgoud & Besnard, 2009, Prop. 4).means another way identify (some the) attack relations satisfying(MC Ext): namely, attack relation exists self-attacking argument, givenattack relation falsifies (MC Ext) semantics returning conflict-free sets. Let us studynotion validity (Amgoud & Besnard, 2010).Definition 7 (Valid). Let R Arg(L) Arg(L) attack relation. say R validevery E Arg(L) holds E conflict-free, Base(E) consistent.Let us show property incompatible conflict-dependence.Proposition 3. exists attack relation conflict-dependent valid.Proof. Let R attack relation suppose R conflict-dependent valid. Let= ({}, ), b = ({}, ), c = ({ }, ) let E = {a, b, c}. Since Rvalid Base(E) inconsistent, E conflict-free. Since R conflict-dependent,(a, b)/ R, (b, a)/ R, (a, c)/ R, (c, a)/ R, (b, c)/ R, (c, b)/ R. Thus, E conflict-free.Contradiction.means attack relation R satisfies (MC Ext) must exist set Econflict-free respect R whose base inconsistent.Corollary 4. Let R attack relation x acceptability semantics returning conflict-freesets let R satisfy (MC Extx ). Then, R valid.79fiV ESICproof previous fact consequence Proposition 2 Proposition 3. usefulsince attack relation valid, immediately conclude violates (MC Extx )(possible) semantics returning conflict-free sets.general level, see asking every conflict-free set consistent basedemanding. Roughly speaking, due fact attacks binary whereas minimalconflicts may ternary (or greater cardinality). authors argue obtain consistentresult, one concentrate admissibility conflict-freeness. example, Caminada Vesic (2012) claim n-ary attacks, n 3, simulated Dungs frameworkthroughout notion admissibility. Thus, idea future work could study alternativecondition, every admissible set consistent base.4.2 Satisfying (MCExt) Different Acceptability Semanticssubsection, study properties related particular semantics. show attackrelation satisfies (MC Ext) stable semantics, satisfies semi-stable semantics also.identify conditions attack relation satisfies (MC Ext) stable semantics. provide similar result preferred semantics. also identify sufficient conditionattack relation falsifies (MC Ext) complete semantics. Then, discuss casesingle-extension semantics, like grounded ideal.First, suppose R satisfies (MC Exts ). means every finite set formulae ,function Arg bijection MC() Exts (Arg(), R). Since every finite set formulaeleast one maximal consistent subset (even empty set) every , must(Arg(), R) least one stable extension. Since stable extensions, stablesemi-stable semantics coincide (Caminada, 2006). Thus, obtain following proposition.Proposition 4. Let R attack relation. R satisfies (MC Exts ) then:every finite set formulae F = (Arg(), R), Exts (F) = Extss (F)R satisfies (MC Extss ).Let us prove case stable semantics, image respect Arg everymaximal consistent set extension base every extension consistent,attack relation question satisfies (MC Ext).Proposition 5. Let R attack relation. every set formulae F = (Arg(), R),have:MC(), Arg(S) Exts (F),E Exts (F), Base(E) consistentR satisfies (MC Exts ).Proof. Let us prove R satisfies (MC Exts ). already know every MC(),Arg(S) Exts (F). Let us suppose E Exts (F) let us prove exists unique setMC() Arg(S) = E. prove set exists, uniqueness guaranteedsince S, 0 , 6= 0 Arg(S) 6= Arg(S 0 ) trivially holds. Thus, let us proveexists MC() Arg(S) = E. Let 0 = Base(E) let us prove 0 MC()80fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONArg(S 0 ) = E. means contradiction, suppose 0 consistent maximalconsistent set. Then, exists 00 MC() 0 00 . assumptionsproposition, E 00 = Arg(S 00 ) stable extension F. also E ( E 00 . Sincestable extension proper subset another stable extension, E stable extension.Contradiction. Thus, must 0 MC(). easy see E Arg(Base(E)) (namely,every set arguments, applying function Arg base, obtain superset). Letus prove Arg(S 0 ) = E. Suppose contrary. Then, E ( Arg(S 0 ). Since 0 MC()Arg(S 0 ) Exts (F). Thus, E stable extension (since stable extension proper subsetanother stable extension).prove similar two conditions sufficient guarantee R satisfies (MC Ext)preferred semantics.Proposition 6. Let R attack relation. every set formulae F = (Arg(), R),have:MC(), Arg(S) Extp (F),E Extp (F), Base(E) consistentR satisfies (MC Extp ).Proof property similar proof Proposition 5.consequence two previous results, identify sufficient condition Rsatisfies (MC Exts ) (MC Extp ).Corollary 5. Let R attack relation. every set formulae F = (Arg(), R),have:MC(), Arg(S) Exts (F),E Extp (F), Base(E) consistentR satisfies (MC Exts ) (MC Extp ).Proof. Since every stable extension preferred one (Dung, 1995), clear R satisfiesconditions Proposition 5 Proposition 6. applying propositions, Rsatisfies (MC Exts ) (MC Extp ).Let us show attack relation returns stable extension inconsistent base,violates (MC Ext) stable, semi-stable, preferred complete semantics.Proposition 7. Let R attack relation. exists finite set formulaeF = (Arg(), R) stable extension E Base(E) inconsistent, R falsifies(MC Extx ) x {s, ss, p, c}.Proof. supposed exists stable extension E Exts (F) Base(E) ` .proved (Dung, 1995) every stable extension preferred complete one. alsoknow (Caminada, 2006) E must semi-stable extension. using Corollary 2, concludeR satisfy (MC Ext) stable, semi-stable, preferred complete semantics.81fiV ESICLet us study case complete semantics. show possible attackrelation satisfy (MC Extc ). condition use result every argumenta, formula support, , exists argument b Arg()b attacks a.Proposition 8. Let R attack relation every finite set formulae , everyArg(), every Supp(a), exists existsb Arg() (b, a) R. Then, R satisfy (MC Extc ).Proof. prove attack relation R satisfies condition proposition,falsifies (MC Extc ). use proof contradiction. words, plan prooffollows: first, suppose R satisfies given condition. Second, means contradiction,suppose R satisfies (MC Extc ). Third, draw conclusions obtain contradiction.Fourth, reductio ad absurdum, conclude must R falsifies (MC Extc ).So, let us start supposing condition proposition suppose R satisfies(MC Extc ). Thus, Proposition 2, obtain R conflict-dependent. Since R satisfies(MC Extc ), every , Arg bijection MC() Extc (Arg(), R). Consider= {, , } denote F = (Arg(), R). clear MC() = {S1 , S2 } S1 = {, }S2 = {, }. Since R satisfies (MC Extc ) Extc (F) = {E1 , E2 } E1 = Arg(S1 )E2 = Arg(S2 ).Let us obtain contradiction proving E3 = Arg({}) complete extension. First,prove set conflict-free. Let a, b E3 . Since R conflict-dependent, (a, b)/ R.Thus, E3 conflict-free.Let us prove E3 , b Arg() \ E3 , (a, b)/ R(b, a)/ R. means contradiction, suppose contrary. conflict-dependence,Supp(a) Supp(b) ` . must {, } Supp(a) Supp(b). Since supportevery argument consistent, Supp(a) contains either . Contradiction factArg({}). Thus, E3 admissible set.Let us prove E3 defend arguments Arg() \ E3 . show this,need prove every argument Arg() \ E3 attacked least one argument. Noteevery Arg() \ E3 , holds E1 \ E2 E2 \ E1 . Without loss generality,let E1 \ E2 . Let us prove attacked. Note every argumentation system, everynon-attacked argument complete extensions. Since/ E2 , must attacked. sumup:E3 admissible setE3 attack argument Arg() \ E3Arg() \ E3 attack argument E3every argument Arg() \ E3 attacked least one argument.Thus, E3 complete extension. Contradiction claim Extc (F) = {E1 , E2 }.reductio ad absurdum, conclude R satisfy (MC Extc ).semantics always return unique extension, like grounded idealsemantics? case, reasonable expect bijection MC()82fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONset extensions, since several maximal consistent subsets . Let us formallystate fact.Proposition 9. x semantics every argumentation system F |Extx (F)| =1 attack relation R satisfies (MC Extx ).Proof. Let = {, , }. Denote F = (Arg(), R). two maximal consistent subsets, i.e. |MC()| = 2. Since supposed every argumentation system exactly oneextension semantics x, bijection MC() Extx (F).previous simple result surprising. idea semantics oneextension contains arguments accepted according every point view.Thus, expect link set formulae belonging minimal inconsistentset extensions. Note sufficient conditions R identified (Gorogiannis& Hunter, 2011) every finite set F = (Arg(), R) groundedideal semantics coincide extension exactly Arg( \ (1 . . . k )){1 , . . . , k } set minimal (for set inclusion) inconsistent subsets .5. Identifying Classes Attack Relations (Not-)Satisfying (MCExt)previous sections show identify properties attack relation satisfying (MC Ext)must satisfy. also provide several results closely related choice specific acceptability semantics. section, identify classes attack relations satisfy, satisfy(MC Ext), serve lower (upper) bounds (with respect set inclusion) (non-)satisfying(MC Ext).first show whole class symmetric attack relations violates (MC Ext)semantics Definition 4.Proposition 10. R symmetric attack relation, every x {s, ss, p, c, g, i}, R falsifies(MC Extx ).Proof. Proposition 9, see R violates (MC Extg ) (MC Exti ). Let usprove acceptability semantics.R symmetric attack relation, every conflict-free set admissible. Furthermore,easy see case every maximal conflict-free set stable extension (and vice versa).Since every finite argumentation system least one maximal conflict-free set, every finiteargumentation system using symmetric attack relation least one stable extension. Let Rsymmetric relation suppose least one x {s, ss, p, c}, R satisfies (MC Extx ).Corollary 4, conclude R valid. means exists finite propositionalknowledge base F = (Arg(), R) conflict-free set E Arg()inconsistent base. Let E 0 Arg() maximal conflict-free set containing E, i.e.E E 0 . Since E 0 maximal conflict-free set, stable extension F. Since E 0stable extension, also semi-stable, preferred complete one. Since Base(E 0 ) `Corollary 2 implies x {s, ss, p, c}, R fails satisfy (MC Extx ).identify another class attack relations satisfy (MC Ext). Namely,show every (possible) attack generating many attacks falsifies (MC Ext). First,83fiV ESICneed formally define mean many attacks. introducing notionconflict-completeness.Definition 8 (Conflict-complete). Let R Arg(L) Arg(L) attack relation. sayR conflict-complete every minimal conflict C L (i.e. every inconsistentset whose every proper subset consistent), every C1 , C2 C C1 6= , C2 6= ,C1 C2 = C, every argument a1 Supp(a1 ) = C1 , exists argument a2Supp(a2 ) = C2 (a2 , a1 ) R.Intuitively, attack relation conflict-complete two sets form minimal conflict,every argument built one two sets attacked argument set.notion inspired desire describe properties class existing (and new) attackrelations. example, canonical undercut conflict-complete.show attack relation conflict-complete, falsifies (MC Ext) stable,semi-stable, preferred complete semantics.Proposition 11. Let R attack relation. R conflict-complete R satisfy(MC Extx ) x {s, ss, p, c}.Proof. Let R conflict-complete attack relation let us use proof contradiction. Thus,suppose exist x {s, ss, p, c} R satisfies (MC Extx ) obtain contradiction. Proposition 2, R conflict-dependent. Let = {, , }. LetF = (Arg(), R) E = Arg({}) Arg({ }) Arg({}). prove E stableextension F. First, prove E conflict-free. Let a, b E suppose (a, b) R.conflict-dependence, obtain Supp(a) Supp(b) ` . Contradiction definition E,since two arguments E union supports inconsistent. Now,prove E attacks every argument Arg() \ E. Let a0 Arg() \ E. three cases.Case 1: Supp(a0 ) = {, }. case, since R conflict-complete, a0 attackedleast one argument set Arg(). Case 2: Supp(a0 ) = {, }. conflictcompleteness, argument attacked argument set Arg({ }). Case 3:Supp(a0 ) = { , } also similar, since a0 attacked argument support{}. conclude E Exts (F). easy see Base(E) ` . Proposition 7 impliesR satisfy (MC Extx ) every x {s, ss, p, c}. Contradiction.previous part paper studies classes attack relations. Let us defineVparticular cases attack relations. = {1 , . . . , k } set formulae, notation stands1 . . . k .Definition 9 (Attack relations). Let a, b Arg(L). define following attack relations:Vdefeat: aRd b Conc(a) ` Supp(b)direct defeat: aRdd b exists Supp(b) Conc(a) `Vundercut: aRu b exists Supp(b) Conc(a)direct undercut: aRdu b exists Supp(b) Conc(a)Vcanonical undercut: aRcu b Conc(a) Supp(b)84fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONrebut: aRr b Conc(a) Conc(b)defeating rebut: aRdr b Conc(a) ` Conc(b)conflicting attack: aRc b Supp(a) Supp(b) `rebut + direct undercut: aRrdu b aRr b aRdu bbig argument attack: aRba b exists Supp(b) Supp(a) ` .first seven items previous definition list are, best knowledge,attack relations used logic-based argumentation literature. Finding exact paperoccurs first time would quite challenging task. say rebutdefined Pollock (1987, 1992). Direct undercut introduced work Elvang-Gransson,Fox, Krause (1993) Elvang-Gransson Hunter (1995). Undercut canonical undercut defined form Besnard Hunter (2000, 2001). best knowledge,conflicting attack used argumentation literature. possibility use relationmentioned (Besnard & Hunter, 2008, p. 35). show enough capturepresence inconsistency make good attack relation. Namely, show later attackrelation may return inconsistent extensions. Rebut + direct undercut added authorpresent paper, attempt investigate possibility use rebut detect conflictsdetected direct undercut, avoid using symmetric relation (rebut). name big argumentattack idea behind attack relation due L. van der Torre (personal communication,June 18, 2012). attack relation coined goal show reasonable attack relations taking account conclusion argument. later show (Proposition 16)attack relation also satisfies (MC Ext). (The idea behind name attack relationsufficient use one argument per support since conclusions important.arguments called big since one big argument plays role whole class normalarguments, i.e. arguments support. attack relation called big sinceused big arguments.)reader easily check canonical undercut conflict-complete, leadsconclusion every attack relation containing canonical undercut (in set-theoretic sense)also conflict-complete.Proposition 12. Let R Arg(L) Arg(L) attack relation. Rcu R R conflictcomplete.Thus, Proposition 11, conclude every attack relation containing canonical undercutfalsifies (MC Ext) stable, semi-stable, preferred complete semantics.Corollary 6. Let R attack relation. Rcu R, R satisfy (MC Extx )x {s, ss, p, c}.Since Rcu Ru Rd Rc , obtain soon attack relation R contains Ru ,Rd Rc falsifies (MC Ext) stable, semi-stable, preferred complete semantics.Corollary 7. Let R attack relation. Ru R, Rd R Rc R R falsifies(MC Extx ) x {s, ss, p, c}.85fiV ESICHence, whole class attack relations based undercutting satisfy(MC Ext). also identified another class attack relations, time based rebutting,satisfy (MC Exts ). Namely, every attack relation contained defeating rebut mustfalsify (MC Exts ). Observe proof following proposition based ideaExample 3.Proposition 13. Let R attack relation. R Rdr R satisfy (MC Exts ).Proof. Let us suppose contrary, i.e. let R satisfy (MC Exts ). Let = { , }F = (Arg(), R). MC() = {S1 , S2 }, S1 = { } S2 = { }. Thus,must Exts (F) = {E1 , E2 } E1 = Arg(S1 ) E2 = Arg(S2 ). obviousargument a1 = ({ }, ) must a1 E1 . Since E2 stable extension,must exist argument a2 E2 (a2 , a1 ) R. Thus, must Conc(a2 ) ` .Consequently, Conc(a2 ) ` . Recall Supp(a2 ) = { } Supp(a2 ) = { }.Contradiction.Since Rr Rdr previous conclusion holds every relation contained Rr .Corollary 8. Let R attack relation. R Rr R satisfy (MC Exts ).Proof. Let R Rr . Since Rr Rdr , R Rdr . Proposition 13, R falsifies(MC Exts ).6. Particular Attack Relations (MCExt)previous section, identified classes relations satisfy (MC Ext).section, examine detail attack relations Definition 9.using results presented now, prove direct undercut, direct defeat bigargument attack satisfy (MC Ext) stable, semi-stable preferred semantics, falsifysemantics, whereas attack relations fail satisfy (MC Ext) semantics.Note proved (Cayrol, 1995) direct undercut satisfies (MC Ext) casestable semantics. Proposition 4, conclude direct undercut satisfies (MC Ext)semi-stable semantics. So, need prove Rdu satisfies (MC Ext) casepreferred semantics.Proposition 14. Attack relation Rdu satisfies (MC Extx ) x {s, ss, p}.Proof. already seen Rdu satisfies (MC Ext) stable semi-stable semantics. study case preferred semantics. Let finite set formulae F =(Arg(), Rdu ). Since already proved (Cayrol, 1995) stable extensions F exactlyArg(S), ranges MC(), since every stable extension preferred one,clear every MC() Arg(S) preferred extension F. ThanksProposition 6, need prove base every preferred extension consistent.result follows Prop. 34 Gorogiannis Hunter (2011), since relation Rdu satisfiesconditions proposition. Thus, direct undercut satisfies (MC Extp ).Example 6. Consider relation ; inferring inconsistent knowledge base definedfollows: given set , write ; every maximal consistent subset ,86fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONholds ` , ` stands classical entailment. Now, consider argumentation systemusing direct undercut attack relation stable semantics. Proposition 14, concludeevery , Arg bijection MC() Exts (Arg(), Rdu ). Roughly speaking,means set formulae inferred respect ; equal setformulae conclusions extensions corresponding argumentation frameworkbased direct undercut stable semantics. formally: every L, every formulaL that: ; every extension E Exts (Arg(), Rdu ), existsE = Conc(a).Let us show Rdd also satisfies (MC Ext) stable, semi-stable preferred semantics.Proposition 15. Attack relation Rdd satisfies (MC Extx ) x {s, ss, p}.Proof. Let finite knowledge base F = (Arg(), Rdd ). Let MC(). easysee E = Arg(S) stable extension F. Namely, E conflict-free since Rdd conflictdependent. Furthermore, every argument a0 Arg() \ E, must Supp(a0 ) containsleast one formulae \ S. fact, easy conclude exists argumentE Supp(a) Conc(a) (since maximal consistent set). Thus,attacks a0 ends part proof shows E Exts (F). Since every stableextension semi-stable preferred one, E Extss (F) E Extp (F). Let ussuppose E preferred extension F. Since direct defeat satisfies conditions Prop. 34Gorogiannis Hunter (2011), conclude Base(E) consistent. Corollary 5,conclude Rdd satisfies (MC Ext) stable preferred semantics. Now, Proposition 4implies Rdd also satisfies (MC Extss ).show necessary look conclusions arguments order satisfy(MC Ext). Namely, show big argument attack satisfies (MC Ext) stable, semistable preferred semantics.Proposition 16. Attack relation Rba satisfies (MC Extx ) x {s, ss, p}.Proof. Let us first show every MC(), holds E = Arg(S) stable extensionF = (Arg(), Rba ). Since Rba conflict-dependent, E conflict-free. Let a0 Arg() \ Elet us prove exists E aRba a0 . Since a0/ E, existsSupp(a0 )/ S. Since maximal consistent subset , ` . Let 0minimal respect set inclusion consistent set 0 ` (such set exists sinceconsistent) let = (S 0 , ). argument since 0 minimal consistent setdeduced. see (a, a0 ) Rba . means image respect Argevery maximal consistent subset stable extension F. Thus, also semi-stablepreferred extension F. Let us prove every corresponding F =(Arg(), Rba ), base every preferred extension E F consistent set. Let E Extp (F)= Base(E). Aiming contradiction, suppose contrary, i.e. let inconsistent set.Let 0 minimal (with respect set inclusion) inconsistent set. Denote 0 = {1 , . . . , n }.Let E argument n Supp(a), let a0 = (S 0 \ {n }, n ). clear(a0 , a) Rba . Since E preferred extension, conflict-free, thus a0/ E. Furthermore, Eadmissible, must exist b E (b, a) Rba . Since (b, a) Rba ,87fiV ESICexists {1, . . . , n 1} Supp(b) ` . Since 0 , exists argumentc E Supp(c). According definition Rba , would mean b attacksc. Contradiction fact E conflict-free. So, must consistent set. showsevery corresponding F = (Arg(), Rba ), base every preferred extension EF consistent set. Corollary 5, conclude Rba satisfies (MC Ext) stablepreferred semantics. Now, Proposition 4 implies Rba also satisfies (MC Extss ).already know relation satisfies (MC Ext) grounded ideal semantics.using Proposition 8, easy conclude Rdu , Rdd Rba falsify (MC Extc ).Let us prove remaining attack relations Definition 9 satisfy (MC Ext)neither semantics Definition 4.Proposition 17. Attack relations Rd , Ru , Rcu , Rr , Rdr , Rrdu , Rc falsify (MC Ext) stable,semi-stable, preferred, complete, grounded ideal semantics.Proof. Note already showed attack relation satisfies (MC Ext) groundedideal semantics. So, rest proof, need consider stable, semi-stable, preferredcomplete semantics.Let us first consider attack relations Rcu , Ru , Rd Rc . using Proposition 11,conclude relations violate (MC Ext) stable, semi-stable, preferred completesemantics.obvious relations Rr Rc symmetric. Note Rdr also symmetric:comes fact ` , ` ` . Thus, Proposition10 yields conclusion satisfy (MC Ext) neither considered acceptabilitysemantics.Let us study relation Rrdu . Let = {, , } F = (Arg(), Rrdu ). Letus define set E arguments follows: E = {a Arg() | Conc(a) 6 Conc(a) 6( ) Conc(a) 6 }.Prove E conflict-free. Let a, b E let aRrdu b. Whether aRr b aRdu bimportant, since cases, obtain Supp(a) Supp(b) ` . Contradiction, sincetwo formulae whose union inconsistent set. E conflict-free set.Suppose a0 Arg() \ E. So, Conc(a0 ) Conc(a0 ) ( ) Conc(a0 ) .cases, a0 attacked least one argument E, namely ({}, ),({ }, ), ({}, ). So, E stable extension, consequently, semi-stable,preferred complete extension. obvious Base(E) inconsistent set, Corollary 2conclude Rrdu satisfy (MC Ext) stable, semi-stable, preferred completesemantics.7. Discussion, Related Future Workpaper identified studied large class instantiations Dungs abstract theory corresponding maxi-consistent operator. words, studied instantiations everyextension argumentation system corresponds exactly one maximal consistent subsetknowledge base. proved properties attack relations belonging class: mustconflict-dependent, must valid, must conflict-complete, must symmetric etc.also identified attack relations serving lower upper bounds class. using88fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONresults, showed existing attack relations argumentation literature whetherbelong class. also showed first time attack relation dependingarguments conclusions return reasonable results. Furthermore, showed relationmember (MC Ext) class.Practical benefits work reported paper, generally, work devotedstudying link class instantiations Dungs theory operator, resumedfollows.(I) case instantiation Dungs theory shown correspond existing operator.First, work help validate argumentation-based approach showingcases returns result comparable non argumentation-based approach. possiblecriticism instantiation useless, since one obtain result withoutusing argumentation. But, far true; namely, argumentation used explanatory purposes. example, one wants know certain conclusion accepted,argument conclusion presented. argument attacked arguments on. Also, might possible construct part argumentation graphrelated argument question, thus better knowledge representation (i.e. ignoringparts knowledge base unrelated argument one wants concentrate on).second benefit type work help reduce computational complexityusing simpler approach cases result obtained argumentation-based approaches non argumentation-based approaches same. Please note workcategory (capturing operator instantiation Dungs theory) far limitedcase maxi-consistent operator, shown Vesic van der Torre (2012)exists large class instantiations abstract argumentation theory returning consistentresult substantially different one returned maxi-consistent operator.(II) case instantiation Dungs theory correspond existing operator.Working links instantiations Dungs theory operators evenbeneficial case instantiation abstract argumentation theory corresponding known operator happens found. distinguish three possible situations.(a) case instantiation calculates useful result obtained operator, operator unknown now. case, new operator discovered thanksargumentation. question then, situations use argumentative approach,apply operator? answer depends balance need computationalefficiency (which conjecture often side approach directly applying operator)need represent knowledge format easy grasp, argue justify acceptedpiece knowledge, usual advantages argumentation.(b) case instantiation Dungs abstract theory returns useful result cannotobtained operator. Recall operator function that, every finite knowledgebase, returns set subsets. But, argumentative approach could return result cannotrepresented form, instance, argument (, ) extension, whereas (, )not, 6= . Thus, expressive power operator-based approach might enoughdistinguish subtleties. important question define instantiationstill open. Another relevant issue see context instantiations make senseapplied.89fiV ESIC(c) case instantiation returns bad result. class regroups set instantiationsrepresenting behaviour one would like avoid. general question: distinguish usefulbad instantiations? certainly hard one. Apart scientific debate, evaluationinclude tests set benchmark examples. Note limits testing reasoning formalismset benchmark examples pointed Vreeswijk (1995). Another, principled (and demanding) way proceed define set postulates satisfiedargumentation formalism (Caminada & Amgoud, 2007; Caminada, Carnielli, & Dunne, 2012).remark, note fact instantiation may return inconsistent result,mean completely useless. Namely, might cases arguments constructedinconsistent knowledge base, one resolves existing inconsistencies argumentative approach, applies another inconsistency-tolerant approach.Also, inconsistency handling use argumentation. Thus, still setting,drastic case would first use argumentation another purpose (not dealinginconsistencies) apply different approach reason inconsistency.review related work. Maxi-consistent sets play major role characterization various forms non-classical logical reasoning (Bochman, 2001) belief revision(Alchourron, Gardenfors, & Makinson, 1985). remainder section considers paperslink argumentation.paper Cayrol (1995) one early works relating results obtained directlyknowledge base using argumentative approach. paper, shown directundercut satisfies (MC Ext) stable semantics, results semantics attackrelations provided. studied attack relations semantics, alsoprovided general study properties attack relation satisfying (MC Ext) must also satisfy.Amgoud Vesic (2010) generalised result Cayrol (1995) case prioritisedknowledge base, showing Arg bijection preferred sub-theories (Brewka, 1989),generalise maximal consistent sets case prioritised knowledge base, stable extensions corresponding preference-based argumentation system using direct undercutattack relation weakest link principle preference relation.Amgoud Besnard (2009, 2010) also studied link knowledge base corresponding argumentation system. papers introduced important notions like conflictdependence validity attack relation proved numerous results related consistencyunderlying logic. However, note criterion (MC Ext) neither defined studiedpapers; provided (Amgoud & Besnard, 2010, Corollary 1) link MC()maximal conflict-free sets F = (Arg(), R). Furthermore, result proved hypotheses impossible satisfy: attack relation valid conflict-dependent,impossible (as proved Proposition 3). results paper (Amgoud &Besnard, 2010, e.g. Prop. 4) proved attack relation conflict-dependentconflict-sensitive, case well-known attack relations. Consequently, majority negative results papers applicable minorityattack relations. Furthermore, examples papers often incomplete systems; thus,surprising link MC(Base(A)) Ext(A, R) examples.recent paper Gorogiannis Hunter (2011) studied properties attack relationscase Dung-style argumentation system instantiated classical propositionallogic. work related ideas, however, focus paper different. maingoal study extent Dungs theory used general framework reasoning.90fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONtechnical side, concentrate studying properties class attack relationssatisfying (MC Ext) identifying attack relations serving lower upper bounds classesrelations non-satisfying (MC Ext).One open questions find set conditions attack relation satisfiesconditions satisfies (MC Ext). recently, direct undercut directdefeat known attack relations satisfying condition (Vesic, 2012). Consequently,seemed space attack relations satisfying condition rather narrow (note similaritydirect undercut direct defeat). However, present paper shows Rba also belongs(MC Ext), indicating class instantiations corresponding maxi-consistentoperator much larger.formal framework studied paper classical propositional logic-based argumentation. vast majority ideas considerations present paper holdinstantiations Dungs theory, example setting studied Modgil Prakken (2013).words, result obtained argumentation frameworks could also comparedobtained operator. slightly adapting definition operator, one studyquestions: link result obtained argumentation systemobtained operator (from strict defeasible rules)? argumentation help usfind new operators? argumentation systems returning result cannot capturedoperator? Answering questions certainly part future work.Acknowledgmentsauthor would like thank Leendert van der Torre assistance advice. usefulcomments helped improve paper significantly. author also thanks three reviewershelpful comments.paper revised extended version conference paper: S. Vesic. Maxi-ConsistentOperators Argumentation. Proceedings 20th European Conference Artificial Intelligence (ECAI12), pages 810-815.major part work paper carried author affiliatedComputer Science Communication Research Unit University Luxembourg. First,author started work tenure ERCIM Alain Bensoussan Fellowship Programme, supported Marie Curie Co-funding Regional, National International Programmes (COFUND) European Commission. time, author alsofunded National Research Fund, Luxembourg. Second, still University Luxembourg, author continued work paper FNR AFR postdoc projectsupported National Research Fund, Luxembourg, cofunded Marie CurieActions European Commission (FP7-COFUND). Third, time finishingwork paper, author CRNS researcher affiliated CRIL.ReferencesAlchourron, C. E., Gardenfors, P., & Makinson, D. (1985). logic theory change: Partialmeet contraction revision functions. Journal Symbolic Logic, 50, 510530.91fiV ESICAmgoud, L., & Besnard, P. (2009). Bridging gap abstract argumentation systemslogic. International Conference Scalable Uncertainty Management (SUM09), pp.1227.Amgoud, L., & Besnard, P. (2010). formal analysis logic-based argumentation systems.International Conference Scalable Uncertainty Management (SUM10), pp. 4255.Amgoud, L., Besnard, P., & Vesic, S. (2011). Identifying core logic-based argumentationsystems. 23rd International Conference Tools Artificial Intelligence (ICTAI11),pp. 633636.Amgoud, L., & Cayrol, C. (2002). reasoning model based production acceptable arguments. Annals Mathematics Artificial Intelligence, 34, 197216.Amgoud, L., & Vesic, S. (2010). Handling inconsistency preference-based argumentation.Proceedings 4th International Conference Scalable uncertainty Management(SUM10), pp. 5669.Arrow, K. J., Sen, A. K., & Suzumura, K. (Eds.). (2002). Handbook Social Choice Welfare.North-Holland.Besnard, P., & Hunter, A. (2000). Towards logic-based theory argumentation. Proceedings17th National Conference Artificial Intelligence (AAAI00), pp. 411416. AAAI Press/ MIT Press.Besnard, P., & Hunter, A. (2001). logic-based theory deductive arguments. Artificial Intelligence Journal, 128, 203235.Besnard, P., & Hunter, A. (2008). Elements Argumentation. MIT Press.Bochman, A. (2001). logical theory nonmonotonic inference belief change - numericalmethods. Springer.Brewka, G. (1989). Preferred subtheories: extended logical framework default reasoning.Proceedings International Joint Conference Artificial Intelligence (IJCAI89), pp.10431048.Caminada, M. (2006). Semi-stable semantics. Proceedings 1st International ConferenceComputational Models Argument (COMMA06), pp. 121130. IOS Press.Caminada, M., & Amgoud, L. (2007). evaluation argumentation formalisms. ArtificialIntelligence Journal, 171 (5-6), 286310.Caminada, M., Carnielli, W., & Dunne, P. (2012). Semi-stable semantics. Journal LogicComputation.Caminada, M., & Vesic, S. (2012). extended conflict-freeness argumentation.. Proceedings24th Benelux Conference Artificial Intelligence (BNAIC12), pp. 4350.Cayrol, C. (1995). relation argumentation non-monotonic coherence-based entailment. Proceedings 14th International Joint Conference Artificial Intelligence(IJCAI95), pp. 14431448.Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person games. Artificial Intelligence Journal, 77,321357.92fiI DENTIFYING C LASS AXI -C ONSISTENT PERATORS RGUMENTATIONElvang-Gransson, M., Fox, J., & Krause, P. (1993). Acceptability arguments logical uncertainty. Proceedings 2nd European Conference Symbolic QuantitativeApproaches Reasoning Uncertainty (ECSQARU93), pp. 8590.Elvang-Gransson, M., & Hunter, A. (1995). Argumentative logics: Reasoning classicallyinconsistent information. Data Knowl. Eng., 16(2), 125145.Gardenfors, P. (1988). Knowledge Flux Modeling dynamics epistemic states. Cambridge,MA, MIT Press.Gorogiannis, N., & Hunter, A. (2011). Instantiating abstract argumentation classical logicarguments: Postulates properties. Artificial Intelligence Journal, 175, 14791497.Konieczny, S., & Perez, R. P. (2011). Logic based merging. Journal Philosophical Logic, 40(2),239270.Loui, R. (1998). Process policy: Resource-bounded nondemonstrative reasoning. Computational Intelligence, 14(1), 138.Modgil, S., & Prakken, H. (2013). general account argumentation preferences. ArtificialIntelligence, 195, 361397.Pollock, J. (1987). Defeasible reasoning. Cognitive Science, 11(4), 481518.Pollock, J. (1992). reason defeasibly. Artificial Intelligence Journal, 57, 142.Priest, G. (2002). Paraconsistent logic. Gabbay, D., & Guenthner, F. (Eds.), Handbook Philosophical Logic, Vol. 6, pp. 287393. Dordrecht: Kluwer Academic Publishers.Vesic, S. (2012). Maxi-consistent operators argumentation. 20th European ConferenceArtificial Intelligence (ECAI12), pp. 810815.Vesic, S., & van der Torre, L. (2012). Beyond maxi-consistent argumentation operators. 13thEuropean Conference Logics Artificial Intelligence (JELIA12), pp. 424436.Vreeswijk, G. (1995). Interpolation benchmark problems defeasible reasoning. ProceedingsSecond World Conference Fundamentals Artificial Intelligence (WOCFAI95),pp. 453468.Vreeswijk, G. (1997). Abstract argumentation systems. Artificial Intelligence Journal, 90, 225279.93fiJournal Artificial Intelligence Research 21 (2013) 205-251Submitted 10/12; published 05/13Analysis Watsons Strategies Playing Jeopardy!Gerald TesauroDavid C. GondekJonathan LenchnerJames FanJohn M. Pragergtesauro@us.ibm.comdgondek@us.ibm.comlenchner@us.ibm.comfanj@us.ibm.comjprager@us.ibm.comIBM TJ Watson Research Center, Yorktown Heights, NY 10598 USAAbstractMajor advances Question Answering technology needed IBM Watson1play Jeopardy!2 championship level show requires rapid-fire answers challengingnatural language questions, broad general knowledge, high precision, accurate confidence estimates. addition, Jeopardy! features four types decision making carryinggreat strategic importance: (1) Daily Double wagering; (2) Final Jeopardy wagering; (3)selecting next square control board; (4) deciding whether attemptanswer, i.e., buzz in. Using sophisticated strategies decisions, properlyaccount game state future event probabilities, significantly boost playersoverall chances win, compared simple rule thumb strategies.article presents approach developing Watsons game-playing strategies,comprising development faithful simulation model, using learning MonteCarlo methods within simulator optimize Watsons strategic decision-making. giving detailed description game-strategy algorithms, focusparticular validating accuracy simulators predictions, documenting performance improvements using methods. Quantitative performance benefits shownrespect simple heuristic strategies, actual human contestant performancehistorical episodes. extend analysis human play derive numbervaluable counterintuitive examples illustrating human contestants may improveperformance show.1. IntroductionJeopardy! fast-paced, demanding, highly popular TV quiz show originatedUS, airs dozens international markets. show features challengingquestions (called clues shows parlance) drawn broad array topics;clues may embody manner complex ambiguous language, including vagueallusions hints, irony, humor wordplay.rules game play regular episodes (Jeopardy! Gameplay, 2013) follows.two main rounds play, wherein round uses board containing 30 squares,organized five squares six different categories, square containing hiddenclue. Second-round clues higher dollar values, presumably reflecting greater difficulty.typical play, square selected according category dollar amountplayer control board, clue revealed read aloud host.1. Registered trademark IBM Corp.2. Registered trademark Jeopardy Productions Inc.c2013AI Access Foundation. rights reserved.fiTesauro, Gondek, Lenchner, Fan & Pragerhost finishes reading clue, players may attempt answer, i.e., buzz in,pressing signaling device. first player buzz obtains right attemptanswer; answer correct, players score increases clues dollar value,whereas answer incorrect, players score decreases dollar value,clue re-opened players attempt answer rebound.One clue first round, two clues second round special DailyDouble status. player selected clue exclusive right answer,must specify wager $5 either current score round limit, whichevergreater. game concludes single clue Final Jeopardy round.players write sealed-bid wagers, 30 seconds write answerclue revealed. player finishing highest dollar-value score3 winsamount, continue playing next episode.IBM began contemplating building computing system appear Jeopardy!readily apparent undertaking would hugely daunting challengeautomated Question Answering (QA) technology. State-of-the-art systems timeextremely poor general open-domain QA, considerable difficulty questionssupporting evidence passages worded straightforward way. BuildingDeepQA architecture, advancing performance Jeopardy! competitive levelhuman contestants, would ultimately require intense work four-year periodteam two dozen IBM Researchers (Ferrucci, Brown, Chu-Carroll, Fan, Gondek,Kalyanpur, ..., & Welty, 2010; Ferrucci, 2012).Rather discussing Watsons QA performance, amply documented elsewhere, purpose paper address orthogonal significant aspectwinning Jeopardy!, namely, strategic decision-making required game play.four types strategy decisions: (1) wagering Daily Double (DD); (2) wageringFinal Jeopardy (FJ); (3) selecting next square control board; (4) deciding whether attempt answer, i.e., buzz in. critical junctures gameoften occur Final Jeopardy round playing Daily Doubles, wageringrequired. Selecting judicious amount wager, based ones confidence, specificgame situation, likely outcomes remaining clues, make big differenceplayers overall chance win. Also, given importance Daily Doubles, followsplayers square selection strategy control board resulthigh likelihood finding DD. Allowing ones opponents find DDs lead devastating consequences, especially playing Grand Champions caliberKen Jennings Brad Rutter. Furthermore, contestants optimal buzz-in strategychange dramatically certain specific end-game scenarios. example, player whosescore half leaders score may need make desperation buzzlast clue order avoid guaranteed loss. Conversely, half leadersscore, correct strategy may never buzz in.scant prior literature Jeopardy! game strategies, nearly qualitative heuristic, sole exception Final Jeopardy strategy, substantialquantitative analysis embodied J! Archive (2013) Wagering calculator. Additionally, Dupee (1998) provides detailed analysis betting Final Jeopardy, particular3. Multiple players may win finished tied first place. deviation strict zero-sum gamelead fascinating counter-intuitive strategies.206fiAnalysis Watsons Strategies Playing Jeopardy!emphasis so-called two-thirds scenario, betting nothing may increase winning chances second-place player, provided least two-thirdsleaders score. qualitative guidelines aggressive conservative Daily Double betting also given, depending confidence category, ability win buzz,positioning Final Jeopardy. specific last-clue DD bet presented best beteither takes lead, drops exactly half leaders score (i.e., lock-tie), resultingextra chances win. Harris (2006), one shows top contestants, provides numerousqualitative insights strategic thinking championship level, including importanceseeking DDs bottom rows, wagering position Final Jeopardy, protectinglead late game cautious buzzer.article describes teams work developing collection game-strategy algorithms deployed Watsons live Jeopardy! contests human contestants.knowledge, work constitutes first-ever quantitative comprehensive approachJeopardy! strategy explicitly based estimating optimizing players probability winning given Jeopardy! game state. methods enable Watson findDDs faster humans, calculate optimal wagers buzz-in thresholds degreeprecision going well beyond human capabilities live game play. brief overviewwork (Tesauro, Gondek, Lenchner, Fan, & Prager, 2012) recently appeared special issueIBM Journal Research Development. present article provides expandeddescriptions strategy algorithms, presents substantial new quantitativedocumentation performance advantages obtained approach, comparedsimple heuristic strategies well actual human strategies.overall organization article follows. first provide section 1.1 glossary important technical terms notation used throughout article. Section 2overviews general approach developing Jeopardy! simulator, use simulate contests Watson human contestants. Studying game-playing programssimulation well-established practice computer games research. However, modelingJeopardy! much difficult undertaking traditional games like CheckersChess, due rich language content extensive imperfect information. essentialmodel statistical performance profiles human contestants, well tendencies wagering square selection, mining historical data contestant performancethousands previously aired episodes. respect, Jeopardy! similarimperfect-information games like Poker (Billings, Davidson, Schaeffer, & Szafron, 2002),effective dynamic modeling ones opponents requisite ingredient strongplay computers humans. general overview followed sections 2.1-2.6specific designs construction methodologies simulation component models,emulating Daily Double placement, human performance Daily Doubles, Final Jeopardy,regular clues square selection, well extensions models single-gamemulti-game format. modeling section concludes section 2.7, presentsstatistically meaningful validation study, documenting well various game statistics predicted simulator match actual statistics live matches Watsonhuman contestants. detailed Appendix 1, Watson played 100Sparring Games appearing television, validation study specifically focuses final 55 games Watson faced extremely strong formerJeopardy! champions.207fiTesauro, Gondek, Lenchner, Fan & PragerSection 3 presents specific techniques designing, learning optimizing Watsonsfour strategy modules course many simulated games. techniques spanrange widely used methods current AI/OR research studies. Specifically, section 3.1details approach DD wagering, combines nonlinear regression Reinforcement Learning train Game State Evaluator course millions simulatedgames. Section 3.2 presents methods calculate Best-Response wagering strategy (a standard game-theoretic concept) Final Jeopardy using either offline online Monte-Carlosampling. Section 3.3 describes Watsons square selection strategy, important ingredient live Bayesian inference calculation probabilities various squarescontaining Daily Double. Finally, section 3.4 documents Watson computes buzz-inthresholds endgame states using combination Approximate Dynamic Programmingonline Monte-Carlo trials, i.e., rollouts (Tesauro & Galperin, 1996; Bertsekas &Castanon, 1999).work led many new insights constitutes effective Jeopardy!strategy, section 4 paper presents interesting counterintuitiveinsights obtained, hope improving human contestant performance. Section 4.1 gives overview important decision boundaries found WatsonsBest-Response FJ strategy. Section 4.2 discusses important finding regarding human DD wagering, namely humans generally bet aggressively. Section 4.3presents buzz threshold analysis yielding initial buzz thresholds surprisingly aggressive, rebound thresholds surprisingly conservative. Finally, section 4.4discusses unusual seemingly paradoxical implications lock-tie FJ scenario,leader must bet $0 guarantee win.summarizing work lessons learned section 5, Appendix 1 provides detailsWatsons competitive record, Appendix 2 gives mathematical details buzzthreshold calculation.1.1 Glossarysection provide definitions various technical terms notation used subsequent sections describe simulation models, strategies, aspects Jeopardy! gameplay.A, B C - players highest, second highest third highest scores,respectively, current scores.Accuracy - probability player answer clue correctly, situationsanswering mandatory (Daily Doubles Final Jeopardy).Anti-two-thirds bet - Potential counter-strategy Two-thirds Final Jeopardy scenario (see Two-thirds bet). two-thirds bet, Bs score4B-2A. less B less three-fourths A. Hence, couldguarantee win small bet 3A-4B. However, bet vulnerableB making large bet significantly overtakes A.Average Contestant model - model based aggregate statistics J! Archiveregular episode data (excluding special-case contestant populations).208fiAnalysis Watsons Strategies Playing Jeopardy!Bet cover, Shut-out bet - Standard strategy leader, A, Final Jeopardy.usually bets least 2B-A (frequently 2B-A+1). correct answer, scoreleast 2B, guarantees win.Board Control - right select next clue; usually belonging playergave last correct answer. Daily Doubles played playercontrol board.Buzz attempt rate - Parameter b regular clue simulation model, denotingaverage probability player attempt buzz clue.Buzz correlation - regular clue model, quantity ij indicating degreebuzz-in decisions player j tend given clue(see Correlation coefficient). two humans, ij = b (empirically 0.2), whereasij = 0 human Watson.Buzzability - Short buzzer ability. probability given player winningcontested buzz multiple players buzz in.Buzzing - Pressing signaling device, indicating player wishes attemptanswer clue. host finishes reading clue, first player buzzallowed answer.Champion model - model based aggregate statistics 100 best playersJ! Archive dataset, ranked according number games won.Correlation coefficient - simulator, quantity ij indicating degreerandomized binary events (Buzz/NoBuzz Right/Wrong) players j tendgiven clue. simple example, suppose j 50%chance answering Final Jeopardy correctly. Let P (xi , xj ) denote jointprobability correctness xi j correctness xj . correlation coefficient given ij = P (Right,Right) + P (Wrong,Wrong) - P (Right,Wrong) P (Wrong,Right). Note xi xj independent, four joint outcomesequally likely, ij = 0. xi xj always match, ij = 1always mismatch, ij = 1.Exhibition Match - (See Appendix 1) televised two-game match, aired Feb.2011, Watson competed Brad Rutter Ken Jennings, arguablytwo best-ever human contestants (see Multi-game format).Grand Champion model - model based aggregate statistics ten best playersJ! Archive dataset, ranked according number games won.Lockout, locked game - game state leaders current score cannotsurpassed opponents play remaining clues, leaderguaranteed win. Usually refers Final Jeopardy states leaderdouble opponents scores.209fiTesauro, Gondek, Lenchner, Fan & PragerLock-tie - Final Jeopardy situation player second place exactlyhalf leaders score. leader guaranteed win betting $0, enablingsecond place player achieve tie first place betting everything answeringcorrectly.Match equity - Objective function optimized Watson two-game ExhibitionMatch, defined probability finishing first plus 0.5 times probability finishingsecond. contrast, Watson simply maximized probability winning SparringGames.Multi-game format - special-case format used finals TournamentChampions, Exhibition Match Ken Jennings Brad Rutter. First,second third place awarded based point totals two games.event first-place tie, sudden death tie-break clue played. Dependingprize money, significant incentive finish second place.QA - Short Question Answering. computing system suite NaturalLanguage Processing techniques used search for, evaluate, select candidateanswers clues.Precision, Precision@b - regular clues, average probability playeranswer correctly fraction clues (b) player chooses buzzanswer (Ferrucci et al., 2010).Rebound - situation first player buzz gets clue wrong,remaining players another chance buzz try answer.Regular episode format - regular episodes, returning champion plays singlegame two new challengers. First, second third place determinedpoint totals game, multiple players may finish tied first. player(s)finishing first continue play next episode. little incentivefinish second, pays $1000 finishing third.Right/wrong correlation - regular clue model, quantity ij indicatingdegree correctness player j tend given clue(see Correlation coefficient). two humans, ij = p (empirically 0.2), whereasij = 0 human Watson.Rollouts - Extensive Monte-Carlo simulations used estimate probabilityplayer winning given game state.Sparring Games - (See Appendix 1) Two series practice games (Series 1, 2) playedWatson former Jeopardy! contestants. Series 1 games contestants selected typical average contestants appearing show. Series2 games played champions, i.e., contestants reached finalssemi-finals annual Tournament Champions.Tip-off effect - Information revealed initial incorrect answer helps rebound player deduce correct answer. example, clue asking New210fiAnalysis Watsons Strategies Playing Jeopardy!Jersey university likely two plausible answers, Rutgers Princeton.initial answer Princeton? ruled incorrect, rebounderhighly confident correct answer Rutgers?Two-thirds bet - plausible Final Jeopardy strategy B cases Bleast two-thirds score. Assuming makes standard bet cover least2B-A, Bs winning chances optimized betting 3B-2A. bet,B win whenever wrong, whereas larger bets, B also needs right.strategy vulnerable counter-strategy (see Anti-two-thirds bet).2. Simulation Model ApproachSince optimize Watsons strategies millions synthetic matches, importantsimulations faithful enough give reasonably accurate predictions varioussalient statistics live matches. Developing simulator required significant effort,particularly development human opponent models.use simulator optimize strategies well-established practice computergames research. Simulated play provide orders magnitude data live gameplay, suffer overfitting issues commonly encountered tuningfixed suite test positions. usually easy devise perfect modelrules play, simulation-based approaches face significant challenge accurate modelsopponent strategies required. traditional two-player zero-sum perfect-informationboard games (Backgammon, Checkers, Chess, etc.) modeling normally requiredone simply aim compute minimax-optimal line play, limited potentialmodel exploit suboptimal play opponents. contrast, repeated normalform games Prisoners Dilemma Rock-Paper-Scissors, one-shot equilibriumstrategy trivial compute insufficient win tournament competitions (Axelrod,1984; Billings, 2000). best programs games employ degree adaptivityand/or modeling based observed behaviors opponents. Poker anotherprominent game opponent modeling essential achieve strong play (Billings et al.,2002) . Playing equilibrium strategy opponent bluffing much littlewould forego opportunity significantly boost ones expected profit.contrast above-mentioned games, Jeopardy! domain introduces entirelynew modeling issues, arising natural language content category titles, clues,correct answers. Obviously simulator cannot generate synthetic clues comparablewritten shows writers, plausibly emulate actual contestant responses. Even basic analysis categories clues (e.g., categories tendsimilar, co-occurrence likelihood categories board, type informationprovided clues, type mental process needed infer correct response,clue difficulty calibrated based round dollar value) seemed dauntingprospects success seemed remote. Likewise, modeling distributions human contestant capabilities thousands categories, correlations abilities acrossdifferent categories, seemed equally implausible.Due considerations, initial simulator design based extremelysimplified approach. avoided attempt model games language content,decided instead devise simplest possible stochastic process models various211fiTesauro, Gondek, Lenchner, Fan & Pragerevents occur step game. plan examine accuratelysimulator could predict outcomes real Watson-vs-human Jeopardy! matches,refine models needed correct gross prediction errors. turned out,simple simulation approach predicted real outcomes much accurately initiallyanticipated (see section 2.7 below), major refinements necessary.noteworthy enhancement simple stochastic process models occurred2010, Watson acquired ability dynamically learn revealed answerscategory (Prager, Brown, & Chu-Carroll, 2012). effect substantial, Watsons accuracy improved 4% first clue last clue category.captured effect using historical data: category simulated game wouldpaired randomly drawn historical category, sequence five right/wrongWatson answers known prior processing. Instead stochastically generatingright/wrong answers Watson, simulator used recorded sequence, embodied tendency better later clues category. ability simulatelearning effect instrumental ultimate development Watsons square selectionalgorithm, describe section 3.3.stochastic process simulation models informed by:(i) properties game environment (rules play, DD placement probabilities,etc.)(ii) performance profiles human contestants, including tendencies wageringsquare selection;(iii) performance profiles Watson, along Watsons actual strategy algorithms;(iv) estimates relative buzzability Watson vs. humans, i.e., often playerable win buzz two contestants attempting buzz in.primary source information regarding (i) (ii) collection comprehensivehistorical game data available J! Archive (2013) web site. obtained fine-grainedevent data approximately 3000 past episodes, going back mid-1990s, annotatingorder clues played, right/wrong contestant answers, DD FJ wagers,DD locations. eliminating games special-case contestants (Teen, College,Celebrity, etc. games), remaining data provided basis model DD placement(section 2.1), models human contestant performance Daily Doubles (section 2.2),Final Jeopardy (section 2.3), regular clues (section 2.4), square selection (section 2.5).devised three different versions human model, corresponding three different levels contestant ability encountered Watsons matches human contestants (see Appendix 1 details). Average Contestant model fittednon-tournament game data appropriate model Watsons opponentsSeries 1 sparring games. Champion model designed represent much strongeropponents Watson faced Series 2 sparring games; developed modelusing data 100 best players dataset, ranked number games won. Finally, Exhibition Match Ken Jennings Brad Rutter, devised GrandChampion model informed performance metrics 10 best players. Since212fiAnalysis Watsons Strategies Playing Jeopardy!Exhibition Match used multi-game format (1st, 2nd 3rd place determinedtwo-game point totals), developed specialized DD FJ wagering models Game 1Game 2 match, described section 2.6.2.1 Daily Double Placementcalculated joint row-column frequencies J! Archive data Round 1 Round2 DD placement; Round 2 frequencies illustrated Figure 1. analysis confirmswell-known observations DDs tend found lower rows (third, fourthfifth) board, basically never appear top row. However, surpriseddiscover also column dependencies, i.e., columns likelycontain DD others. example, DDs likely appear first column,least likely appear second column. (We speculate4 showsproducers place DDs fashion.)Figure 1: Illustration row-column frequencies second-round DD placement 3000previous Jeopardy! episodes. Red denotes high frequency blue denotes lowfrequency.Additional analytic insights data include: (i) two second-round DDs neverappear column. (ii) row location appears set independentlycolumn location, independently rows DDs within game. (iii)Round 2 column-pair statistics mostly consistent independent placement, apartconstraint (i). However, specific column pair frequenciesexhibit borderline statistically significant differences independent placement model.Based analysis, simulator assigns DD location Round 1,first DD location Round 2, according respective row-column frequencies.4. noted second column often features pop-culture categories (TV shows, pop music, etc.)could account relative paucity DDs.213fiTesauro, Gondek, Lenchner, Fan & Pragerremaining Round 2 DD assigned row unconditionally, column assigned conditioned first DD column.2.2 Daily Double Accuracy/Betting ModelRound 2 DD bets vs. scoreRound 2 DD bets vs. time4500380036004000340032003500Mean betMean bet3000300025002800260024002000220020001500BC1000050001000015000Player score20000BC180016002500005101520Previously revealed clues round2530Figure 2: Average Round 2 mean DD bets human contestants first place (A), secondplace (B) third place (C), function player score (left), clues playedround (right).Based appropriate historical statistics J! Archive regular episode dataset,set mean DD accuracy parameter human contestant models 64% Average Contestants, 75% Champions, 80.5% Grand Champions. Bets madehuman contestants tend round number bets $1000 $2000, rarely exceed$5000. main dependencies observed players lead tend betconservatively, become extremely conservative near end game, presumablyprotect lead going Final Jeopardy. dependencies clearly seenFigure 2, plot average bets functions player score clues playedsecond round.wagering tendencies built Average Contestant model,surmised (correctly turned out) much stronger Champion Grand Championplayers would quickly realize need bet DDs extremely aggressively playingWatson. models therefore employed aggressive heuristic strategywould bet nearly everything, unless heuristic formula indicated player closemathematically certain win.2.3 Final Jeopardy Accuracy/Betting Modelhistorical dataset obtained J! Archive reveals mean human accuracy answering Final Jeopardy correctly approximately 50% average contestants, 60%Champions, 66% Grand Champions. Furthermore, statistics eightpossible right/wrong triples, also clear accuracy positively correlated amongcontestants, correlation coefficient F J 0.3 providing best fit data.214fiAnalysis Watsons Strategies Playing Jeopardy!use parameter values simulating stochastic FJ trials, wherein implement drawsthree correlated random binary right/wrong outcomes, means correlations tunedappropriate values. performed first generating correlated real numbersusing multi-variate normal distribution, applying suitably chosen thresholdsconvert 0/1 outcomes desired mean rates (Leisch, Weingessel, & Hornik, 1998).many draws required determine precise win rate given FJ score combination, also implement lower-variance simulation method. Rather generatingsingle stochastic outcome triple, simulator evaluates eight outcome triples, weightedanalytically derived probabilities combination.Second-place (B) FJ bet distribution10.80.8B bet / scorebet / scoreFirst-place (A) FJ bet distribution10.60.40.20.60.40.2000.50.60.70.8B score / score0.910.50.60.70.8B score / score0.91Figure 3: Distribution human FJ bets first-place player (left) second-placeplayer B (right), normalized leader score, function B/A ratio.important factor FJ wagering score positioning, i.e., whether playerfirst place (A), second place (B) third place (C). develop stochastic processmodels likely contestant bets, first discarded data lockout games (whereleader guaranteed win), examined numerous scatter-plotsshown Figure 3. see high density line bets corresponding well-knownstrategy betting cover case Bs score doubles 2B. Likewise, two highdensity lines plot Bs bets, one B bets everything, one B betsenough overtake A. Yet considerable apparent randomization apartknown deterministic wagering principles.thorough examination, decided segment wagering data six groups:used three-way split based strategic breakpoints (as detailed section 4.1) Bsscore relative score (less 2/3, 2/3 3/4, 3/4), plusbinary split based whether B least double Cs score. devisedwagering models A, B, C5 choose among various types betting logic,probabilities based observed frequencies data groups. example, modelB case (B 3/4 A, B 2C) bets follows: bet bankroll (i.e., nearly everything)5. Curiously enough, saw evidence Cs wagers vary strategic situation, implementedsingle betting model C covering six groups.215fiTesauro, Gondek, Lenchner, Fan & Prager26% probability, keepout C (i.e., B-2C) 27% probability, overtake(i.e., slightly A-B) 15% probability, two-thirds limit (i.e., 3B-2A)8% probability, various types random bets remaining 24% probabilitymass.BCReal65.3%28.2%7.5%Model64.8%28.1%7.4%Table 1: Comparison actual human win rates model win rates historical replacement 2092 non-locked FJ situations past episodes.betting models described designed solely match human bet distributions, informed human FJ win rates. However, subsequently verifiedhistorical replacement technique models track actual human win rates quiteclosely, shown Table 1. first measured empirical win rates A, B, C roles62092 non-locked FJ situations past episodes. took turns recalculatingwin rate one role replacing bets role bet distribution corresponding model. models match target win rates well, consideringhuman bets likely reflect unobservable confidence estimates given FJ category.satisfied human FJ model accurately fit historical data,nevertheless room doubt accurately would predict human behaviorSparring Games. notably, six data groups used estimate modelparameters contained hundred samples, error bars associatedestimated values likely large. could addressed performingso-called second order Monte-Carlo trials (Wu & Tsang, 2004), using Gaussian drawsparameter values FJ trial instead constant values, concernedsignificantly higher computational overhead approach. also possibilities contestant behavior might non-stationary time, attemptmodel, contestants might alter behavior specifically play Watson. discuss later section 3.2, generally accepted FJ model basisoptimizing Watsons decisions, sole exception case Watson A,B player may plausibly make two-thirds bet (see Glossary definition section 1.1).2.4 Regular Clue Modelstochastic process model regular (non-DD) clues generates random correlatedbinary triple indicating players attempt buzz in, random correlated binarytriple indicating whether players correct answer. case contestedbuzz, buzz winner randomly selected based contestants relative buzzability(ability win contested buzz, assumed equal all-human matches). mentionedGlossary section 1.1, buzz-in outcomes governed two tunable parameters,mean buzz attempt rate b buzz correlation b . right/wrong outcomes6. human win rates sum 101%, reflecting 1% chance first-place tie.216fiAnalysis Watsons Strategies Playing Jeopardy!Figure 4: Frequencies seven possible regular-clue outcomes J! Archive average contestant dataset.likewise governed two parameters, mean precision@b (Ferrucci et al., 2010) simplymean precision p, right/wrong correlation p . set four parameter values b,b , p, p running extensive Monte-Carlo simulations many different parametercombinations, selecting combination yielding best fit observed historicalfrequencies seven possible outcomes regular clues, depicted Figure 4.outcome statistics derived J! Archive records 150K regular clues.parameter values obtained average contestants are: b = 0.61, b = 0.2, p = 0.87p = 0.2. right/wrong correlation derived directly rebound statistics,particular noteworthy: positive value reasonable, given correlations seenFJ accuracy, might surprising due tip-off effect rebounds.first player buzz gives wrong answer, eliminates plausible candidate couldsignificantly help rebound buzzer deduce right answer. surmise datamay reflect knowledge correlation 0.3 combined tip-off effect 0.1produce net positive correlation 0.2.Champion model, substantial increase attempt rate (b = 0.80)slight increase precision (p = 0.89). Grand Champion model, estimatedincreases values, b = 0.855 p = 0.915 respectively. depictedFigure 5, also developed refined model segregating regular clue data accordinground dollar value (i.e., row number), estimating separate (b, p) valuescase. refinements make simulations accurate, meaningfully impactoptimization Watsons wagering square selection strategies. expectslight improvement Watsons endgame buzzing could achieved usingseparate (b, p) values, insufficient data Champions Grand Championsestimate values. Hence deployed algorithm used constant (b, p) values clues.2.5 Square Selection Modelhuman contestants tend select top-to-bottom order within given category,also tend stay within category rather jumping across categories.weak tendency select categories moving left-to-right across board. Basedobservations, likely impact Watsons square selection, developed217fiTesauro, Gondek, Lenchner, Fan & PragerAverage Contestant Attempt Rate / Precision vs. Row Number0.95Mean Attempt Rate / Precision0.90.850.80.750.70.650.60.550.5b(row)b=0.61p(row)p=0.870.450.4123456Row Number78910Figure 5: Estimates Average Contestant buzz attempt rate (b) precision (p)function round row number. Rows 1-5 denote first round clues, rows6-10 denote second round clues.Average Contestant model square selection stays current category60% probability, otherwise jumps random different category. picking withincategory high probability (90%) picking topmost available square.contrast, model Champion Grand Champion square selection DD seeking basedknown row statistics DD placement. Strong players generally exhibit DailyDouble seeking selecting squares, playing Watson, quicklyadopt overt DD seeking behavior.2.6 Multi-game Wagering ModelJeopardy! contests, winner determined performance single game.However, show also conducts several annual tournaments, TournamentChampions, final match utilizes point totals two games determine first,second third place. clearly implies wagering strategies must differ Game 1Game 2 match, need different single-game wagering.Since limited multi-game match data available J! Archive (onlytwo dozen Tournament Champions final matches), would quite difficult modelexpected wagering Jennings Rutter Exhibition Match purely historicaldata. Fortunately, able make educated guesses considerably simplifiedtask. First, predicted would wager DDs aggressively games,unless overwhelming lead. implied could continue useaggressive heuristic DD model single games, revised definition constitutesoverwhelming match lead. Second, also expected bet aggressivelyFinal Jeopardy first game. meant could treat Game 1 FJDD situation, use revised aggressive heuristic model.218fiAnalysis Watsons Strategies Playing Jeopardy!situation requiring significant modeling effort Game 2 FJ. generalizeddefinition A, B, C roles matches, based sum Game 1 score plustwo times Game 2 score. definition, established single-game strategiesA, B C carry two-game matches.Given limited available match data, crude estimates could assignedprobabilities various betting strategies. However, clear datawagering human champions much coherent logical observed wageringregular episodes, champion wagers frequently satisfy multiple betting constraints.observations guided development revised betting models Game 2 FJ.example, case B legal generalized two-thirds bet (suitably definedtwo-game matches), B also keep C, model B bets follows: bankrollbet 35% probability, bet small random amount satisfies two-thirdskeepout-C limits 43% probability, bet satisfy larger two limits22% probability.2.7 Model Validationfirst efforts validate simulators predictions occurred half-wayWatsons first series Sparring Games. point time, simulatorused develop Watsons Final Jeopardy wagering algorithm, simulatorbasically running model Watson heuristic strategies Average Contestant model. predicted outcomes ex-post (after fact) predictions,needed data live games set certain simulation parameter values, particularlyrelating Watsons buzzability. encouraged see predicted ratesWatson winning game (62%), leading going Final Jeopardy (72%) winninglockout (27%) within standard error 42 games actual rates (64%, 76%,26% respectively). significant deviations low side predictedfinal scores Watson (15800 vs. 18400 actual) humans (9300 vs. 10900 actual)still within 95% confidence intervals.start second series Sparring Games, able make ex-ante(before fact) predictions, Watson actually played human champions.predictions based mostly using J! Archive data tune parametersChampion model, well semi-educated guesses regarding improvement buzzabilityhuman champions, aggressively would seek wager DailyDoubles. actual vs. predicted statistics reported Table 2.ex-ante simulation stats turned remarkably close actual results;rates Watson leading FJ, Watsons board control (i.e., often Watson selectednext square) human lockout rate differed one standard error.examined much improvement could obtained ex-post recalibrationChampion model, based actual stats Sparring Games. seen Table 2,best ex-post predictions failed significantly improve ex-ante predictions.notable improvement Watson FJ lead human lockout rates, predictionsWatson lockout rate human final score noticeably worse.219fiTesauro, Gondek, Lenchner, Fan & PragerStatisticWatson win rateWatson lockoutWatson FJ leadWatson board controlWatson DDs foundWatson final scoreHuman final scoreHuman lockoutActual0.709 0.0610.545 0.0670.891 0.0420.500 0.0090.533 0.03923900 190012400 10000.018 0.018Ex-ante sim0.7240.5020.8060.5160.52024950126300.038Ex-post sim0.7180.4930.8300.5150.51724890138300.023Table 2: Comparison actual mean statistics ( std. error) 55 Series 2 Sparring Gamesvs. ex-ante ex-post predicted results 30k simulation trials.3. Optimizing Watsons Strategies Using Simulation Modelsimulator described previous section enables us estimate Watsons performance given set candidate strategy modules, running extensive contestssimulation model Watson two simulated human opponents. Watson stochastic process models use performance metrics (i.e., average attempt rate, precision,DD FJ accuracies) human models. parameter values estimatedJ! Archive test sets, updated numerous times Watson improvedcourse project. Watson model also estimates buzzability, i.e., likelihoodwin buzz humans various ability levels. estimates initiallybased informal live demo games IBM Researchers, subsequently refined based Watsons performance Sparring Games. estimated Watsonsbuzzability two humans 80% average contestants, 73% Champions,70% Grand Champions.Computation speed important factor designing strategy modules, since wagering, square selection buzz-in decisions need made seconds. Also,strategy runs Watsons front-end, single server cores, 3000-coreback-end dedicated QA computations. result, Watsons strategymodules run fast enough hundreds thousands simulated games performedCPU hours. provides solid foundation evaluating optimizingindividual strategy components, presented below. strategy components(endgame buzz threshold, endgame DD betting, Game 2 FJ betting) basedcompute-intensive Monte-Carlo trials; slow perform extensive offline evaluation. Instead, strategies perform live online optimization single strategy decisionspecific game state.3.1 Daily Double Wageringimplemented principled approach DD betting, based estimating Watsonslikelihood answering DD clue correctly, estimating given bet impactWatsons overall winning chances gets DD right wrong. former estimateprovided in-category DD confidence model. Based thousands tests220fiAnalysis Watsons Strategies Playing Jeopardy!historical categories containing DDs, model estimates Watsons DD accuracy givennumber previously seen clues category Watson got right wrong.estimate impact bet winning chances, follow work Tesauro (1995)using Reinforcement Learning (Sutton & Barto, 1998) train Game State Evaluator (GSE) course millions simulated Watson-vs-humans games. Givenfeature-vector description current game state, GSE implements smooth nonlinearfunction approximation using Multi-Layer Perceptron (Rumelhart, Hinton, & Williams,1987) neural network architecture, outputs estimate probability Watsonultimately win current game state. feature vector encoded informationscores three players, various measures remaining amountplay game (number remaining DDs, number remaining clues, total dollar valueremaining clues, etc.).combination GSE in-category confidence enables us estimate E(bet), i.e.equity (expected winning chances) bet, according to:E(bet) = pDD V (SW + bet, ...) + (1 pDD ) V (SW bet, ...)(1)pDD in-category confidence, SW Watsons current score, V ()game state evaluation DD played, Watsons score either increasesdecreases bet. obtain optimal risk-neutral bet evaluatingE(bet) every legal bet, selecting bet highest equity. SparringGames, algorithm evaluated round-number bets (i.e., integer multiples $100),due computational cost well possibility obtain extra winning chancesvia first-place tie lock-tie scenario described section 1.1. ExhibitionMatch, tie finishes possible, sped code enable evaluationnon-round wagers. accounted strange wager values subjectmuch discussion press among viewers.practice, literal implementation risk-neutral betting according Equation 1takes frightening amount risk, furthermore, calculation may contain leastthree different sources error: (i) GSE may exhibit function approximation errors; (ii)simulator used train GSE may exhibit modeling errors; (iii) confidence estimatesmay errors due limited test-set data. therefore chose adjust risk-neutralanalysis according two established techniques Risk Analytics. First, addedpenalty term Equation 1 proportional bets volatility (i.e., standard deviationright/wrong outcomes). Second, imposed absolute limit allowable downsiderisk bet, defined equity difference minimum bet actualbet getting DD wrong. Due function approximator bias, latter techniqueactually improved expectation cases, addition reducing risk. observedcertain endgame states neural net systematically betting much, dueunderestimation lockout potential.overall impact risk mitigation nearly one-third reduction average riskindividual DD bet (from 16.4% 11.3%), cost reducing expected winningchances entire game 0.3%. Given Watson finds average 1.5-2.0DDs per game (depending aggressively opponents also seek DDs), impliesequity cost per DD bet risk mitigation quite small, regarded overalltradeoff highly favorable.221fiTesauro, Gondek, Lenchner, Fan & Prager3.1.1 Illustrative ExampleFigure 6 illustrates DD bet analysis operates, resulting bet dependsstrongly in-category confidence. example taken one Sparring Games,Watson got four consecutive clues right first category start DoubleJeopardy, found first DD attempting finish category. point,Watsons score 11000 humans 4200. Watsons in-category confidence took maximum value, 75%, based gotten four four correct answerspreviously category. Watson chose wager $6700, highly aggressive bethuman standards. (Fortunately, got DD clue right!)(11000, 4200, 4200) Watson Daily Double Bet(11000, 4200, 4200) Watson Daily Double Bet0.80.8Expected Winning ChancesExpected Winning Chances0.90.70.60.50.4DD wrong equityDD right equity0.30200040000.750.70.65conf 0.45conf 0.55conf 0.65conf 0.75conf 0.85best bet0.60.556000Bet Amount8000100001200002000400060008000Bet Amount1000012000Figure 6: (left) Equity estimates getting DD right (top curve) wrong (bottomcurve). (right) Bet equity curves five differences in-category confidence levels,45% 85%. Black dots show optimal risk-neutral bet increasesconfidence.left figure shows neural net equity estimates getting DD right (top curve)wrong (bottom curve) various bet amounts. curves extremely smoothgently decreasing slopes. right plot shows resulting equity-vs-bet curveWatsons actual 75% confidence level (magenta curve), along four curvesdifferent confidence values ranging 45% 85%. Black dots curve indicatebest risk-neutral bet, see bet steadily increases confidence,$5 45%, approximately $9300 actual 75%, finally entire $11000(hypothetical) confidence 85%.also note effect risk mitigation, reduced Watsons actual bet$9300 $6700. According extensive Monte-Carlo analysis bet, risk mitigationreduced Watsons equity 0.2% (from 76.6% 76.4%), entailed significantlyless downside risk (more 10%) event Watson got DD wrong.protection-to-cost ratio 50 1, consider risk mitigation providedcase inexpensive form disaster insurance, Watson team membersrelieved see Watson risk lead DD bet.222fiAnalysis Watsons Strategies Playing Jeopardy!3.1.2 Endgame Monte-Carlo WagersSeries 2 Sparring Games, significantly boosted simulation speed regularclues Final Jeopardy. enabled replacement neural net wagering endgamestates routine based live Monte-Carlo trials. analysis gives essentially perfectknowledge bet achieves highest win rate simulation, although still subjectmodeling errors confidence estimation errors. also eliminated primary weaknessWatsons DD strategy, neural net misevaluations endgames often resulted seriouserrors could considerably exceed 1% equity loss. detailed section 3.1.3,usage Monte-Carlo analysis endgame wagers yielded quite significant reduction(more factor two) Watsons overall error rate DD betting.clues remaining Final Jeopardy, dependence equity playersscore exhibit complex behavior discontinuities, contrast smooth monotonebehavior observed early mid-game states. striking example plotted Figure 7.endgame DD bet Series 2 Sparring Games Watson 19800,humans 13000 14300, four remaining clues (two $400two $800). Watson 4-for-4 category, translated 71.8% DD confidence.(We opted conservative estimate 75% figure mentioned earlier, duepossible confidence estimation errors.)see left right/wrong equity curves exhibit complex accelerationdeceleration, well periodic jumps periodicity $400. may reflect scoresdiscrete change occurs combinations remaining squares needed reachcertain FJ breakpoints, lockout. equity-vs-bet curve right also displaysinteresting multi-modal behavior. peak lead-preserving bet around $3000.$6400, curve begins steep ascent point lockout becomesmathematically possible. curve continues rise $12000, correctanswer assures lockout, falls off.(19800, 13000, 14300) Watson Daily Double Bet0.760.90.740.80.72Expected Winning ChancesExpected Winning Chances(19800, 13000, 14300) Watson Daily Double Bet10.70.60.50.40.30.20.102000400060000.70.680.660.640.620.60.58DD wrong equityDD right equity0Equity @ 71.8% confidence0.568000 10000 12000 14000 16000 18000 20000Bet Amount02000400060008000 10000 12000 14000 16000 18000 20000Bet AmountFigure 7: MC DD bet analysis. (left) Equity estimates getting DD right (top curve)wrong (bottom curve). (right) Bet equity curve Watsons estimatedin-category confidence 71.8%.223fiTesauro, Gondek, Lenchner, Fan & Prager3.1.3 Performance Metrics Error Analysisassessed performance neural net DD wagering two different methods. First,noted improved win rate simulations compared Watsons previous DDwagering algorithm, set heuristic betting rules tried safely add Watsons leadsafely catch up, without dropping certain strategically important score breakpoints.heuristic rules embodied sound logic, suffered major limitation takingWatsons in-category confidence account, would generate wagerregardless confidence.Using heuristic DD betting rules, Watsons simulated win rate 61%.neural net DD wagering using default confidence value every DD, win rate improved64%. added emulation live DD confidence values simulation, resultjump win rate, 67%. regarded quite significant performanceimprovement, given DD betting algorithm used 1.5-2.0 times pergame.second performance metric utilizes extensive offline Monte-Carlo analysis manyneural network bets estimate average equity loss per DD bet, i.e., average differenceequity true best bet, highest simulated win rate, equitybet selected neural net. figure approximately 0.6% per DD bet,quite good, implied overhead improve Watsons win ratevia improved DD wagering less 1.2%. equity loss due largeerrors endgame states. mentioned earlier, substantially reduced loss rateimplementing DD wagering endgames based live Monte-Carlo simulations.reduced Watsons average equity loss per DD bet 0.6% 0.25%, halfloss rate resulting deliberately imposed risk mitigation. Hence satisfiedWatsons DD algorithm close enough optimal practical purposes.3.1.4 Human DD Error Analysisinteresting nontrivial question arising analysis Watsons equity loss rate DD wagering compare human contestants. maindifficulty attempting analysis contestants confidence answering DDclue correctly largely unobservable historical data. way knowconfidence category, knowledge previous clues categoryrevealed buzz gave answer. absence confidence information,hard ascribe error level individual DD bet, although may ableassess average wagering error entire population contestants.devised two methods respectively provide lower upper boundspopulation average wagering error, given sufficient samples historical DD bets.first method historical replacement technique similar presented sections 2.33.2. historical DD, first use Average Contestant simulator runmany trials starting actual outcome state DD, reflecting contestantsactual bet actual right wrong answer. replace contestants betalgorithmically computed bet, wherein confidence estimated solely observableinformation, rerun trials modified outcome state, contestantsscore changed due change bet. Averaged many DDs, equity difference224fiAnalysis Watsons Strategies Playing Jeopardy!human bets algorithmic bets indicate approach better.algorithmic bets prove better, equity difference provide lower boundtrue human error rate: since algorithm access private confidenceinformation, would presumably obtain even better results given information.could issues approach faithfully simulating wouldhappened contestant bet differently, changing bet might changedsubsequent square selection (DD seeking) subsequent DD wagering. minimizedissues limiting analysis last-DD situations. historical dataset contained2200 regular episodes DDs played second round. analyzinglast-DD states episodes, avoid simulate subsequent DD wagers,effect subsequent square selection minimal since DDsfound. Also, last-DD states allow us use endgame Monte-Carlo algorithmicwagering, give stronger results neural net wagering. Confidence estimatesMonte-Carlo calculation based historical mean accuracy second-roundDDs given row location. ranges 72% top two rows 57%bottom row.seen Table 3, results analysis showed contestant bets averageobtained 2.9% less equity per bet Monte-Carlo algorithmic bets.constitute lower bound true human error rate last-DD states, whereas Watsonserror rate 0.25% overall near-perfect endgames states, provides compellingevidence Watsons superiority human contestants, least last-DD wagers.second analysis method ignores actual right/wrong contestant answers,instead uses Monte-Carlo analysis calculate equity loss human bet, assumingrow-based mean DD accuracies provide correct confidence estimates. typeanalysis overestimate human errors, unduly penalizes small bets basedlow private confidence, large bets based high private confidence. Resultsanalysis last-DD dataset show average error rate 4.0% per DD bet. resultconsistent estimated lower bound error rate 2.9%, combination,results provide reasonable evidence actual human error rate liesestimated bounds.Last-DD Player(leader)B,C (trailer)Lower Bound2.9%0.9%4.8%Upper Bound4.0%2.2%5.5%Avg. Human Bet$2870$2590$3120Avg. MC Bet$6220$5380$6970Table 3: Lower upper bounds average equity loss rates historical human contestantwagers last DD game. average human bets vs. recommendedMC bets (at default confidence values) also displayed.closer examination analysis reveals humans systematically wagerDDs far conservatively. segregating data according whether DD playerleading trailing, found conservatism manifest cases. Leadingplayers average bet $2590, whereas average recommended MC bet $5380.trailing players, average bet $3120 vs. average recommended bet $6970.225fiTesauro, Gondek, Lenchner, Fan & Pragerstartling finding errors far costly trailers leaders,terms equity loss. lower upper bounds error rate leaders 0.9%2.2%, trailers, respective bounds 4.8% 5.5%! discussimplications results human contestants section 4.2.3.1.5 Multi-game DD Wageringmentioned section 2.6, Game 1 Game 2 Exhibition Match required distinctwagering strategies, differing single-game wagering. trained separateneural networks Game 1 Game 2. Game 2 net trained first, using plausibleartificial distribution Game 1 final scores.trained Game 2 neural net, could estimate expected probabilitiesWatson ending match first, second, third place, starting combinationGame 1 final scores, extensive offline Monte-Carlo simulations. used createthree lookup tables, cases Watson ends Game 1 first, second, thirdplace, Watson match equities various Game 1 final score combinations, ranging(0, 0, 0) (72000, 72000, 0) increments 6000. (Since adding subtracting constantGame 1 scores effect match equities, without loss generalitysubtract constant lowest Game 1 score zero.) Since match equitiesextremely smooth grid points, bilinear interpolation provides fast highlyaccurate evaluation Game 1 end states. lookup tables enabled fast trainingGame 1 neural net, using simulated matches played end Game 1,assigned expected match-equity rewards using tables.Based earlier experience, added heuristic lockout-potential featureGame 2 input representation, using heuristic sigmoidal formula estimate probabilityWatson would win match lockout, given Game 1 Game 2 scoresdollar value remaining clues. feature appeared enable highly accurate Game2 evaluations eliminated large endgame equity losses observed usingsingle-game neural net.important difficult new issue faced Exhibition Match formatassign relative utilities finishing first, second third place. Unlike SparringGames reasonable objective finish first, team extensively debatedmuch partial credit ascribed second-place finish, Watsondefeated one two greatest Jeopardy! contestants time. Ultimately decidedbase match DD wagering full credit first, half credit second, zero creditthird place finish. objective acts additional type risk control,Watson would prefer large bet smaller safer bet large bets upside(increased chances win) exceeded downside (increased chances finishing third).unanimous team consensus risk would always worth taking.Defining Watsons match equity probability finishing first plus 0.5 times probability finishing second, estimated Watsons average match equity loss per DD bet0.3% Game 1 0.55% Game 2. majority loss case duerisk controls.226fiAnalysis Watsons Strategies Playing Jeopardy!3.2 Final Jeopardy Wageringapproach Final Jeopardy wagering involves computation Best-Response strategy (Fudenberg & Tirole, 1991) (a standard game-theoretic concept) human FJ modelpresented section 2.3. considered attempting compute Nash Equilibrium strategy (Fudenberg & Tirole, 1991), decided two reasons. First, dueimperfect information Final Jeopardy (contestants know confidence givencategory title, know opponents confidence), would principle needcompute Bayes-Nash equilibrium (BNE), entails considerably modelingcomputational challenges. Second, seems far-fetched assume Watsons opponentswould play part Nash equilibrium BNE, since average contestantsstudied game theory.using Best-Response instead BNE strategy (assuming could calculate it),aim effectively exploit typical human wagering errors recorded historicaldata. realized potentially exposes Watson two types risk. First,Watsons live opponents turned use BNE sophisticated strategiesbuilt human models, Watson might better playing BNEstrategy. judged risk sufficiently rare Watson would surely bettercourse many Sparring Games simply playing Best-Response. Second,since Best-Response essentially deterministic strategy, contestant observedWatson play many Final Jeopardy rounds might able detect optimally exploitWatsons wagering strategy. However, observations limited proceduresconducting Sparring Games, contestant would play 2-3 gamesWatson, would observe another 1-2 games spectator. situations,additionally able randomize Watsons bet range bets approximatelyequal expected outcomes; made difficult humans infer Watsons wageringlogic limited number observations.Computation Best-Response proceeds follows. First, consult FJ prioraccuracy regression model estimate Watsons confidence given category title.model trained samples Watsons performance thousands historical FJcategories, using NLP-based feature vector representations titles. Second, givenWatsons confidence human accuracy/correlation parameters, derive analyticprobabilities eight possible right/wrong outcomes. Third, given FJ score combination, draw order 10000 Monte-Carlo samples bets human models.Finally, evaluate equity every legal bet, given human bets right/wrongoutcome probabilities, select bet highest equity.initial implementation algorithm slow use live play. Fortunately, extensive offline analysis using Watsons default confidence, discoveredBest-Response output could expressed terms fairly simple set logicalbetting rules. example, one rules B stipulates:B least two-thirds A, B less 2C, check whether 2C-B(the amount cover Cs doubled score) less equal 3B-2A (themaximum two-thirds bet). so, bet 2C-B, otherwise bet everything.Thus Series 1 Sparring Games, deployed rule-based encapsulationBest-Response calculation, one specific exception Watson A,227fiTesauro, Gondek, Lenchner, Fan & PragerB player may reasonably consider so-called two-thirds bet, i.e., small bet aimsguarantee win whenever wrong, assuming makes standard shut-out bet(2B-A+1). situations, Best-Response calculation calls Watsoncounter B making small, tricky anti-two-thirds bet. Whether really winsoften depends exact model parameter values, considerable uncertainty,discussed earlier section 2.3. Moreover, Watson bets small gets FJ wrong,suggests shakiness ability play Final Jeopardy, might exploitedsubsequent games, well generally looking bad. Conversely, Watson bets smallgets FJ right, risks embarrassing loss Watson could failedbet enough win. reasons, team preferred override Best-Responsecalculation, Watson simply make standard bet scenario.proved judicious choice hindsight, five games Series 1Best-Response would bet anti-two-thirds, B bet two-thirdsgames.Series 2 Sparring Games, Best-Response computation spedenough enable live wager computations. team continued debate whether allowanti-two-thirds bets, ultimately decided worth risk Watson unusuallylow confidence (as happens, example, categories US Presidents, Shakespeare,US Cities). turned out, two games series BestResponse would bet anti-two-thirds. B bet two-thirds one gamegame. Watson low confidence either FJ category, live testresults anti-two-thirds strategy.assessed performance Best-Response strategy via historical replacement technique presented section 2.3; results displayed Table 4. first columngives actual human win rates A, B, C roles. second column shows win ratesconstrained Best-Response deployed Series 1 Sparring Games,always bets cover 2B. Note algorithm considerably improves actual humanresults B C, provides smaller noticeable improvement human bets.attribute latter gain partly consistent betting, partly judicious betscases tie 2B, rather trying surpass 2B $1. last column givesresults full Best-Response algorithm including general Best-Response bets A.nearly 1% improvement win rate constrained Best-Response;provides support efficacy anti-two-thirds sophisticated strategies,quite statistically significant 2092 trials.BCHuman65.3%28.2%7.5%Constrained Best-Response67.0%34.4%10.5%Full Best-Response67.9%34.4%10.5%Table 4: Comparison actual human win rates win rates constrainedfull Best-Response strategies, historical replacement 2092 non-locked FJsituations past episodes.228fiAnalysis Watsons Strategies Playing Jeopardy!Exhibition Match, devised live Best-Response algorithms Game 1Game 2 based Monte-Carlo samples human betting models section 2.6,probabilities eight right/wrong outcomes given Watsons FJ category confidence.first-game FJ, cant evaluate directly FJ outcomes since stillsecond game play. evaluation instead based interpolation lookuptables discussed section 3.1.5 denoting Watsons match equities various first-gamescore combinations.Due modeling uncertainties Game 2 FJ, devoted much effort interpretingBest-Response output terms logical betting rules, well deciding whetherBest-Response decisions overridden. ultimately decided allow Watsonventure anti-two-thirds bet predicted category confidence unusuallylow; otherwise Watson would always bet guarantee win answering correctly.wagering B, betting rules would attempt finish aheaddiminish Watsons chances finishing ahead C. naturally emerged matchutility function assigned half-credit second place finish. Finally, wageringC, Best-Response output complex derive human-interpretable rules,Watson prepared run live calculation case. turned out,work superfluous, since Watson lockout Game 2 ExhibitionMatch.3.3 Square Selectionconsidered four different factors could conceivably relevant optimal overallobjective Watson deciding square select given game state:Selecting Daily Double square: Finding DDs quickly provide excellentopportunity Watson significantly boost game standing, also denyingopportunity players. potential downside Watson maysmall bankroll wager, may little evidence assesslikelihood answering DD clue correctly.Retaining control board: involves estimating categories and/or squarevalues Watson greatest chance win buzz answer correctly.would give Watson another chance try find DD, selected squareturns regular clue.Learning essence category, i.e., gathering information categorytype correct answers, improve accuracy subsequent cluescategory (Prager et al., 2012). consideration would suggest selecting lowvalue squares first, accuracy would improved higher-value squares.Maximizing expected score change: concept seeks best combination highexpected accuracy highest dollar value available clues obtain biggestboost Watsons score next square.used simulator systematically investigate numerous weighted combinationfour factors. studies performed using Champion Grand Champion human models, featured overt DD seeking, aggressive DD wagering, high229fiTesauro, Gondek, Lenchner, Fan & PragerDD accuracy. results showed that, prior DDs revealed, finding DDsoverwhelmingly top factor maximizing Watsons win rate, retaining controlsecond importance. Learning essence category appears provide effectivestrategy DDs found, maximizing expected score changeappear useful improving Watsons win rate.findings led us deploy algorithm selects squares follows. First,unrevealed DDs, square selected maximizes pDD (i)+pRC (i)pDD (i) probability square contains DD, pRC (i) estimated probabilityWatson retain control board contain DD, = 0.1 yieldedbest win rate. first term calculated using Bayesian inference, describedsection 3.3.1. second probability estimated combining simulation modelhuman performance regular clues model Watson adjusts attemptrate, precision buzzability function number right/wrong answers previouslygiven category. Second, DDs round found, algorithmswitches selecting lowest dollar value category greatest potentiallearning category: based number unrevealed cluescategory total dollar value.3.3.1 Bayesian DD Probability Calculationcalculate pDD (i), probability square contains DD, according principlesBayesian inference: combine Bayesian prior probabilities, taken historical frequencies DD locations, evidence revealed questions according Bayes rule,obtain posterior probabilities. computation easy perform incrementallyindividual question revealed, works somewhat differently Round 1 Round2, due different number available DDs.Round 1, one DD, computation posterior probabilities easy. Letp(i) denote prior probability square contains DD. Let p(i) = 1 p(i) denoteprior probability contain DD. assume square j revealedcontain DD. posterior probability p(i|j) according Bayes rule given by:p(i|j) =p(j|i)p(i)p(j)(2)p(j|i) = 1 definition, assuming 6= j. course, DD revealed,p(i) values squares set zero.Round 2, two DDs, probabilities independent, sinceDDs cannot located column, plus column pair frequencieshistorical data may explainable independent placement model.therefore maintain joint probability distribution p(i, j) indicating probabilitysquares j contain DDs. initialize p(i, j) prior values, using joint DDlocation frequencies historical data. assume square k revealedcontain DD. posterior probability p(i, j|k) computed according Bayes rule as:p(i, j|k) =p(k|i, j)p(i, j)p(k)230(3)fiAnalysis Watsons Strategies Playing Jeopardy!p(k) = 1 p(k) marginal distribution single DD, integrating possiblelocations second DD, p(k|i, j) = 1 k 6= k 6= j, else equals 0. Noteconstraint two DDs never appearing column enforced settingprior p(i, j) = 0 squares j column. guaranteesposterior always equal 0, since Bayes rule performs multiplicative updates.square k discovered contain DD, rest board updatedsimilarly:p(i, j|k) =p(k|i, j)p(i, j)p(k)(4)p(k|i, j) = 1 k = k = j, else equals 0.3.3.2 Square Selection Performance MetricsLive DD strategyLRTBSimple DD seekingBayes (max pDD )Bayes (max pDD )max(pDD + 0.1pRC )live DD strategyLRTBLRTBLRTBPost-DD learningPost-DD learningWin rate0.6210.6860.7090.7120.714DDs found0.3220.5100.5620.5620.562Board control0.5120.5180.5200.5200.520Table 5: Simulation results two-game matches vs. Grand Champions using various squareselection strategies (500k trials). LRTB denotes left-to-right, top-to-bottom squareselection.Table 5 report extensive benchmarking Watsons performance using fivedifferent combinations various square selection algorithms. first column denotesstrategy available DDs played round, second columndenotes strategy DDs round played. experiments utilizedtwo-game match format Grand Champion models human contestants.stated earlier, human models employ aggressive DD FJ wagering, simple DDseeking using known row statistics DDs available. Simulations Watson useright/wrong answers drawn historical categories, Watson exhibit learningrevealed answers category. interesting consequence Watsons learning,model human square selection remaining DDs according anti-learningstrategy, intended frustrate Watsons learning, selecting bottom categorygreatest potential benefit learning. actually observed behavior informaltesting strong human players (Ed Toutant David Sampugnaro)Exhibition Match, evidence Jennings Rutter may selectedclues Exhibition based concept.Results Table 5 show weakest performance obtained extremelysimple baseline strategy Left-to-Right, Top-to-Bottom (LRTB), i.e., always selectinguppermost square leftmost available column, actual deployed strategyExhibition gives strongest performance. Consistent earlier findings,231fiTesauro, Gondek, Lenchner, Fan & Pragersee Table 5 DD seeking extremely important, especially playingstrong humans overtly seek DDs. Bayesian DD seeking method significantlybetter simple DD seeking based solely row frequencies DDs. Watsonhumans use simple DD seeking, Watson finds 51.0% DDs (roughly line51.8% average board control) match win rate 68.6%. Watsonswitches Bayesian DD seeking, rate finding DDs jumps 56.2%, even thoughboard control virtually unchanged 52.0%, win rate increases 2.3% 70.9%.hand, Watson DD seeking, simply uses Left-to-Right, Top-toBottom selection, rate finding DDs plunges 32.2% overall win rate drops62.1%.additional effects seeking retain control board, selecting categoriesgreatest potential learning DDs revealed, smaller statisticallysignificant 500k trials. find optimizing weight pRC increases win rate0.2%, maximizing learning potential remaining DDs adds another 0.3%Watsons win rate.3.4 Confidence Threshold Attempting BuzzWatson attempt buzz confidence top-rated answer exceeds adjustable threshold value. vast majority game states, threshold setdefault value near 50%. analysis indicating optimalthreshold, strong argument 50% threshold would maximize Watsonsexpected score, ought related maximizing Watsons chance win. Furthermore, clear general default buzzing 50% confidence betterbuzzing, since Watsons expected score change (0) would cases,opponents would much better chance improve scores Watsonbuzz.approximate threshold calculation based Max-Delta objective (describedAppendix 2), suggestive evidence initial buzz thresholdaggressive. Subsequent exact Monte-Carlo analysis endgames (Appendix 2)early game states (section 4.3) provides substantial backing aggressive initialthreshold 50%. Nevertheless, since Watson tended slightly overconfidentvicinity 50% nominal confidence, since many Watsons wrong answersvicinity clearly revealed correct answer opponents, 50% default thresholdmay prudent choice.Near end game optimal buzz threshold may vary significantlydefault value. One special-case modified buzz policy devised endgames useslockout-preserving calculation. Round 2 states remaining DDs, Watsonbig lead, calculate whether guaranteed lockout buzzingcurrent square. so, lockout longer guaranteed Watson buzzeswrong, prohibit Watson buzzing, regardless confidence.principle, exact optimal binary buzz-in policy within simulation model~ (c, D) = (B (c, D), B (c, D), B (c, D), B (c, D)) game state clue currentlyB3210play, given Watsons confidence c dollar value current clue. policycomponents Bi (c, D) result testing whether c exceeds set optimal threshold values232fiAnalysis Watsons Strategies Playing Jeopardy!{i , = 0, 1, 2, 3}. four values corresponding four possible statesWatson may buzz: initial state, first rebound human #1 answered incorrectly, first rebound human #2 answered incorrectly, second reboundhumans answered incorrectly. optimal policy calculated using DynamicProgramming (DP) techniques (Bertsekas, 1995). involves writing recursion relationvalue current game state K clues remaining FJ, valuespossible successor states K 1 clues remaining:VK (s) =Z(c)5Xj=1p(Dj ) maxX~B(c,Dj)~ c)VK1 (s (, Dj ))dcp(|B,(5)(c) probability density Watsons confidence, p(Dj ) denotes probabilitynext square selected row j dollar value Dj = $400 j, max~ c) denotes probabiloperates Watsons possible buzz/no-buzz decisions, p(|B,ity various unit score-change combinations , denotes various possible successorstates Dj square played, score change combination occurred.(See Appendix 2 detailed discussion recursion relation Equation 5calculated.)implemented exact DP solver successively expands root statesuccessor states K 1, K 2, ..., 0 clues remaining, 0 denotes Final Jeopardystates. FJ states evaluated Monte-Carlo trials, values propagatedbackward according Equation 5 ultimately compute optimal buzz policyroot node state. computation exact within modeling assumptions,slow use live play K 2, due high branching factor search tree.order achieve acceptable real-time computation taking 1-2 seconds,therefore implemented Approximate DP calculation Equation 5 usedfirst step evaluate VK terms VK1 , VK1 values basedplain Monte-Carlo trials (Tesauro & Galperin, 1996; Ginsberg, 1999; Sheppard, 2002).Due slowness exact DP calculation, unable estimate accuracyapproximate method K > 5. However, verify Approximate DP usuallygave quite good threshold estimates (within 5% exact value) K 5 remainingsquares, switchover point invoke Approximate DP deployedlive Series 2 Sparring Games human champions. analogous algorithm basedmatch equities also deployed Game 2 Exhibition Match, indifferentfinal five clues live game, since Watson guaranteed win eitherbuzzing buzzing.3.4.1 Illustrative ExamplesApproximate DP buzz-in algorithm easily handles, example, so-called desperationbuzz last clue, Watson must buzz answer correctly avoidlocked (e.g., suppose Watson 4000, human contestants 10000 2000,final clue value $1200). Generally speaking, optimal endgame buzzing showsgreatest deviation default buzzing near certain critical score breakpoints,crossover third second place, second first place. players scoreone breakpoints, aggressive buzzing usually correct. Conversely,233fiTesauro, Gondek, Lenchner, Fan & Pragerscore critical breakpoint, players buzz much conservatively,guard dropping breakpoint.critical breakpoint contestant achieves guaranteed lockout.near-lockout situations, algorithm may generate spectacular movements buzzthreshold hard believe first glance, appreciated detailedanalysis. example taken Sparring Games last-clue situation Watson28000, humans 13500 12800, clue value $800. (initially)surprising result optimal buzz threshold drops way zero!buzzing answering incorrectly, Watson worse buzzing.either case, human B player must buzz answer correctly order avoidlockout. hand, buzzing answering correctly secures win Watson,risk-free chance try buzz win game.complex example occurred later game, two squares remaining (the current one $1200 final one $2000), Watson 31600,vs. 13000 6600 humans. again, correct answer Watson winsgame. analysis shows Watson buzz regardless confidenceclue next clue, well better buzzing. first clue,Watson buzzes wrong, B needs buzz answer correctly, reach score14200, otherwise Watson lockout 30400. suppose Watson also getssecond clue wrong, dropping 28400. score pair (28400, 14200) goodWatson state (31600, 14200) Watson attempt either clue.cases, Watson guaranteed win unless B answers correctly. fact, B alert,might deliberately answer (28400, 14200) lock-tie situation;actually better Watson (31600, 14200), although simulator modelbehavior.critical example converse situation, Bs buzz-in threshold much highernormal, occurred earlier game. final clue ($2000 value) Watson (A)25200, B 12800, C 2600, Watson answered incorrectly initialbuzz, dropping 23200. Despite Jeopardy! champion, B unfortunately buzzedrebound answered incorrectly, thereby locking out. analysis showsrebound buzz massive blunder (although understandable heat live play):offers improvement FJ chances B right, forfeits chance win Bwrong. roles reversed, Watson would buzzed fairly aggressivelyinitial buzz, prevent achieving lockout, never would buzzedrebound.Finally, Figure 8 presents $2000 last-square situation fix human scores(13000, 6600) systematically study Watsons initial buzz threshold variesscore. several examples huge threshold changes breakpoints crossed.example, Watsons threshold goes aggressive (0.12) 13000,fairly conservative (0.65) 13000. additional complex behavior arisingspecific score combinations involving three players. example, 6400 Watsontake extra risk answering incorrectly, due chance may also answerincorrectly. creates situation A=B+C Watson extra chancesachieve tie first place. principle applies 10400, A=B+C arisesWatson wrong right. different combination comes play 10800234fiAnalysis Watsons Strategies Playing Jeopardy!$2000 Last Clue Threshold, Human Scores (13000, 6600)1Confidence Threshold0.80.60.40.205000100001500020000Watson Score2500030000Figure 8: Watsons initial buzz threshold vs. score last clue ($2000) FJ.Watson extra incentive buzz: either C right, Watson betcover 2C still constitute two-thirds bet.Figure 8 also shows huge swings Watson close achieving lockout. 23000,Watson never buzz, since chance get lockout. 25000, Watsonfree shot try lockout, discussed earlier. 27000, Watson provisionallockout needs take risk block correct answer B, 29000, Watsonfree shot prevent B answering.4. Lessons Human ContestantsWatson retired Jeopardy! contestant, future impact workimproving Jeopardy! performance relate specifically human contestants.section, present number interesting insights may help future contestants improveoverall winning chances.4.1 Basics Final Jeopardy Strategyobserved FJ wagers J! Archive dataset suggest many contestants appearingshow devote scant effort learning good strategies FJ wagering, apartelementary concept wagering least 2B-A cover Bs doubled score. dontintend section provide definitive treatise FJ strategy, illustratefound important regions separating boundaries FJ strategy spacesingle plot, shown Figure 9.Since FJ scenarios scale invariant, scenario uniquely determined two variables: Bs score relative A, Cs score relative B. ratio Bimportant quantity Final Jeopardy, important breakpoint (apartB<A/2 lockout) B=2A/3, illustrated solid red line. contestantsfamiliar implications scenario, analogous game235fiTesauro, Gondek, Lenchner, Fan & PragerMatching Pennies, wins pennies match, B wins pennies mismatch.B least two-thirds A, B secure win whenever wrong makingsmall two-thirds bet (3B-2A), assuming bets cover 2B. However, strategyvulnerable making small anti-two-thirds bet, would give B chancewin. Conversely, anti-two-thirds bet vulnerable B making large bet overtakeA. related breakpoint case B3A/4: situation Bs two-thirds betovertake A, anti-two-thirds option eliminated.important breakpoints include C=B/2 (green line): line, B keepC small bet (B-2C), line, B needs bet least (2C-B) coverCs doubled score. latter case may lead dilemma (2C-B) exceeds maximumtwo-thirds bet (3B-2A). demarcation dilemma occurs magenta curve(2B=A+C), also known equal spacing breakpoint, since A-B=B-C.Breakpoints primarily affect C curves C=(A-B) (dark orange) C=2(AB) (gray). Basically, C needs able reach 2(A-B) curve chancewin, C chance (A-B) curve. scenarios lying twocurves, C minimum rational bet least 2(A-B)-C, although larger bet mayreasonable, example, CA/2 (dotted black curve) overtake A. scenariowould also dissuade trying anti-two-thirds bet B.C least 2(A-B), general rule bet small enough stayvalue. additional upper bound emerging Best Response calculation occursC2B/3 (blue line), cases B 3A/4. case, Bincentive bet cover 2C, C opportunity execute two-thirds betB, may yield wins simply staying 2(A-B).Final Jeopardy Strategy Boundaries10.8C/B0.60.4B=2A/3B=3A/4C=B/2C=2B/32B=A+CC=A-BC=2(A-B)C=A/20.200.50.550.60.650.70.75B/A0.80.850.90.951Figure 9: Illustration important Final Jeopardy strategy regions boundaries,function Bs score relative A, Cs score relative B.236fiAnalysis Watsons Strategies Playing Jeopardy!4.2 Aggressive DD Wageringmentioned earlier section 3.1.4, analysis indicates human contestantssystematically err conservative side DD wagering, given actual likelihoodanswering DD clue correctly. may reflect underestimation ignorancelikely DD accuracy, well lack quantitative means estimate impactscore increase decrease ones overall winning chances. Another possibilitycontestants may recognize level aggressive bet called for, riskaverse actually try it.section present specific historical example illustrate analysisworks, motivate potential advantages aggressive wagering, longplayer reasonably good confidence able answer correctly. examplewager taken J! Archive episode aired last decade. secondplace player B found last DD $800 clue category one previous clue($400) played; clue answered correctly B. point, scoresquite close, B 10400 opponents 11400 9400.eight remaining clues played, worth total $10800. B chose wager$1000, got DD right, ultimately game.course know Bs confidence situation, suspect reasonably good, because: (a) $800 second-round DDs tend easy, average contestantaccuracy 72%; (b) B already answered correctly one previous cluecategory; (c) wagers $1000 tend indicative unusually low DD accuracy. Givenconsiderations, suspect B least 70% chance answering DDcorrectly, low wager due desire avoid dropping third placeincorrect answer.one might surmise reading section 3.1.4, analysis suggests 70% confidence, best wager True Daily Double, $10400. plot Monte-Carlo right/wrongequity curves, equity 70% confidence, function amount wagered shownFigure 10. Note large bets, red curve smaller magnitude slopegreen curve, decelerates rapidly. bet sufficiently large, littleincremental equity loss increasing bet, since player almost chance winpoint. Conversely, strong incremental gain increasing bet gettingDD right. factors tilt calculation decidedly favor maximal bet. Paradoxically, almost certain loss getting DD wrong may exactly humansavoid betting True DDs situation. Many psychological studies documented irrational preferences taking immediate gains, avoiding immediate losses,attributed so-called hyperbolic discounting (Ainslie, 2001). Since Jeopardy!undiscounted game, correcting natural tendencies towards overly short-term thinkingmay advisable prospective contestants.$1000 bet, B either tied first tied second, game stillclose little change equity. MC estimates Bs equity 39% right 31%wrong. However, true DD wager, B would either obtain commanding lead20800 estimated equity 70% answering correctly, drop zero3% equity answering incorrectly. equity difference two bets237fiTesauro, Gondek, Lenchner, Fan & Pragercompelling 70% confidence: betting $1000 gives 36.6% equity, betting $10400gives 49.9% equity, hefty improvement 13.3% overall winning chances.Historical (10400, 11400, 9400) last DD0.8DD wrong equityDD right equityEquity @ 70% confidence0.7DD player winprob0.60.50.40.30.20.100200040006000DD bet80001000012000Figure 10: Equities getting DD right wrong 70% confidence,example historical last-DD situation scores (10400, 11400, 9400).4.3 Counterintuitive Buzz-in ThresholdsProbably counterintuitive result analysis buzz-in confidence thresholdsattempting answer may correct even player negative equity expectationso. discussed Watsons 50% default threshold human contestantsSparring Games, many seemed surprised low value,even objected vociferously. arguments based quantitative equityestimates, seem intuitively recognize Watsons game standing would diminishaverage buzzing 50% confidence, since Watsons score change would zeroaverage, one opponent scores would likely increase. tried explainclearly better alternative buzzing, Watson wouldzero expected score change, unimpeded opponents would greater chancesscore increase.developed offline Monte-Carlo method computing buzz-in thresholdshuman contestants (see Appendix 2 details), compare actual MC resultssimple approximate formula threshold, derived below, gives insightnegative-expectation threshold comes about. complex analytic calculation,yielding closed-form analytic expressions four threshold values, detailedMax-Delta approximation section Appendix 2. analysis also agrees closelyMC results.consider equities one player (the strategic player) relative baseline state,equity E000 , clue expires score change. aim calculate238fiAnalysis Watsons Strategies Playing Jeopardy!confidence threshold 0 initial buzz players confidence c = 0 ,equities buzzing buzzing equal, i.e., EN B (c) = EB (c).Let N = EN B E000 denote expected equity change player buzz,either initially rebound. depend often opponents buzzprecision, good opponents, N negative value. MCsimulations early-game states refined Average Contestant model (where b pestimated based round clue row number), N approximately -0.86% $1000clue first round. order understand effects correlated opponent buzzingprecision, also ran simulations corresponding uncorrelated model, obtainingN -0.96% situation.consider case player buzzes initially. confidence values cvicinity 0 , player loses buzz, argue outcome N :since rebound thresholds higher 0 , shown below, player buzzrebounds. Hence buzzing differ buzzing player winsbuzz. winning buzz answering correctly, players equity increasepositive equity gain G. early $1000 first-round clues, G appears +3.25%,regardless whether opponents correlated uncorrelated player.incorrect answer, due approximate linearity equity respect score changes earlygame, player equity loss G, plus likely lossopponents play rebound. uncorrelated opponents, extra lossN , correlated opponents, lesser still negative value N ,due fact rebound precision less initial buzz precision correlatedmodel. Assuming N = N simplicity, confidence values c buzzing betterbuzzing determined following inequality:cG + (1 c)(N G) N(6)Rearranging terms, obtain: c 0 = G/(2GN ). Since N negative, confidencethreshold less G/2G, i.e., less 50%. quoted values GN , equation 6 yields threshold value 0 = 0.436 uncorrelated model,0 = 0.442 correlated model.compare actual MC threshold calculation, seen Table 6, oneplayer (the leader) typical early game situation, first columnplayed, scores (1800, -600, 1000), DD played. Similar thresholdvalues robustly obtained early states, regardless whether player leadingtrailing. per section 3.4, 0 denotes initial threshold, 1 2 denotefirst rebound thresholds, 3 denotes second rebound threshold. Note 0values $1000 clues correlated uncorrelated models match wellapproximate formula values. also statistically equal, suggests MCcalculation 0 robust sensitive dependence assumed modestlevel contestant correlation.also note increase first rebound thresholds models,increase second rebound thresholds. makes sense expected lossbuzzing, N , diminish opponents eligible buzz. doublerebounds, N equal 0, leading threshold 0.5 according approximateformula. increase rebound thresholds modest uncorrelated model, quite239fiTesauro, Gondek, Lenchner, Fan & Pragersignificant correlated model. due positive correlation precision, implyingplayers posterior confidence reduced observing one opponents answerincorrectly.Similar experiments $200 clues obtain aggressive initial threshold (42% vs44%). expected: since $200 clues easier, opponents likelybuzz answer correctly strategic player buzz. Hence magnitudeN relative G increase, yielding lower threshold. shown Table 6,thresholds $400, $600, $800 clues take plausible intermediate values$200 $1000 limiting cases.clue value$1000$1000$200$200(b , p )(0.2, 0.2)(0, 0)(0.2, 0.2)(0, 0)00.440.440.420.4210.670.490.690.4720.680.500.680.4830.780.530.830.54Table 6: Early buzz-in thresholds correlated uncorrelated refined Average Contestantmodels, based 800K MC trials 20 end-of-clue states. Test position scores(1800, -600, 1000), one column played, DD remains played.summary, human contestants make precise confidence estimates,suspect buzz attempts safely 50%, likelyright wrong. would also surprised became cautious rebounds,one opponents answered incorrectly. contrast, analysis suggestsearly game, may profitable make slightly speculative buzz attemptsinitial buzz, odds even slightly getting right. importantcaveat speculative guesses strong tip-off effect wouldsignificantly aid rebounder.would also advocate exercising caution rebounds. Despite tip-off effect,clear historical evidence human precision positively correlated, declinesrebounds. seen correlated threshold calculation, contestants well50% initial confidence venture rebound attempt, especially double rebound.4.4 Lock-Tie Implicationsconclude section examining strange amusing consequencesLock-Tie scenario Final Jeopardy, Bs score exactly half score.scenario, likely bet nothing, B achieve tie first place bettingeverything getting FJ right. decidedly preferable halfscore, B would need get FJ right get FJ wrong order win.preference B lower score lead unusual strategy decisions (to sayleast) near end game. example, Dupee (1998) discusses DD wageringlast clue Final Jeopardy, DD player 7100 opponents 90001000. Dupee advocates wagering $2600, takes lead 9700 correct,drops lock-tie 4500 incorrect.240fiAnalysis Watsons Strategies Playing Jeopardy!Watsons analysis turns many last-clue DD situations lock-tie considerations lead unusual even paradoxical bets. example, episode 5516, Greg Lindsay7faced last-clue DD decision, trailing 6200 vs. 19200 9500. Greg wagered $6000ultimately game. However, Watson regards serious error, recommends wagering $3400 instead, achieves lock-tie 9600 correct answer.also frequently find Watson wagering necessary last-clue DD achievelockout. one example, Watson 26000 opponents 19800 4400.Watson needed bet $13600 secure lockout, puts Watson 12400answering incorrectly. Watson instead bet $16100, also achieves lockoutcorrect, drops second-place lock-tie score 9900 answering incorrectly.Watson also discovered lock-tie influence wagering several squaresend game. analysis historical last-DD human bets, found classsituations DD player trailing badly, Watson recommends betting exactly$100 less True Daily Double. example situation DD player 5000,opponents 21400 2800, five remaining clues DDplayed, worth total $6000. Watson recommends betting $4900, certainly seemsweird inconsequential, appears real point it. Note leadersscore 21400 happens odd multiple 200 (107x200). Since remaining clueseven multiples 200, leaders score entering FJ always odd multiple200. Now, order reach lock-tie FJ, follows DD players score mustodd multiple 100. achieved wagering $4900, appreciable chanceslock-tie, instead $5000 makes lock-tie impossible. $4900 bet offers 7.2%equity instead 6.4%, lock-tie potential constitutes substantial portion overallwinning chances situation.Finally, note lock-ties provide incentive players intentionally givewrong answers. first alerted possibility puzzle editor Peter Gordon,emailed last-clue DD scenario Watson 6000 opponents 10000-1000. Peter recommended Watson bet $1000 get wrong purpose!course action would require Watson get FJ right order win, whereaslarge DD bet take lead, Watson needs get DD clue FJ rightorder win.subsequent testing Watsons buzz-in strategy, found number fascinatinglast-clue scenarios Watson reported buzz/wrong rebound offers betterequity either buzz/right buzzing. turns scenarios occurA=2B-V, V value last clue, C contention. (Asexample, suppose A=18800, B=10000, C=7600 V=1200.) situation allows Bdouble chance achieve lock-tie! First all, B never buzz initially,wrong answer results getting locked out, may buzz get right,results lock-tie. Additionally, may buzz get wrong, reducing scoreA-V = 2(B-V). happens, B reach lock-tie buzzing answeringincorrectly. scenario remote one might think seems occurper season majority cases, lock-tie spoiled incorrect behaviorB.7. Greg Lindsay contestant win three Sparring Games Watson.241fiTesauro, Gondek, Lenchner, Fan & Prager5. Conclusionscombining original simulation model Jeopardy! state-of-the-art statisticallearning optimization techniques, created set real-time game strategy algorithmsmade Watson much formidable Jeopardy! contestant. documenteddetail, strategy methods resulted significant boost Watsons expected winrate Sparring Games Exhibition Match, compared simpleheuristic strategies. DD wagering, neural net method obtained 6% improvementwin rate compared prior heuristic, estimate 0.6% improvementusing live Monte-Carlo analysis endgame DDs. FJ betting, simulations show3% improvement simple heuristic always bets cover leading, betseverything trailing. seen Table 5, best square selection method improvesheuristics 3-9%, depending much DD seeking done heuristic.data heuristic endgame buzzing, conservative guess ApproximateDP method would achieve 0.5% 1% greater win rate. aggregate benefitindividual strategy improvements appears additive, since simulations put Watsonswin rate 50% using baseline strategies, versus 70% using advanced strategies.also ample evidence strategy algorithms exceeds human capabilities real-time decision making. Historical replacement shows Watsons BestResponse FJ wagering clearly outperforms human wagers. Watson also better findingDDs humans, seen excess fraction DDs found relative averageboard control. According simulations, translates greater overall win rate.cases Daily Double wagering endgame buzzing, clear humansincapable real time anything like precise equity estimates, confidence estimates,complex calculations performed algorithms evaluate possible decisions. Watsonserror rate improves humans order magnitude last-DD situations, sawsection 3.1.4. likely lesser still significant improvement earlierDDs. difficult identify human buzzing errors: failure buzz indistinguishablelosing buzz, even contestant buzzes wrong, decision maycorrect high enough confidence. surmise cases, human buzz errorssmall. algorithms main advantage likely handling special-case endgame stateshumans make major errors, mishandling lock-tie needlessly lockingout.addition boosting Watsons results, work provides first-ever meansquantitative analysis applicable Jeopardy! game state covering aspectsgame strategy. Consequently, unearthed wealth new insights regardingconstitutes effective strategy, much difference strategy make contestants overall ability win. illustrated numerous examples insightsthroughout paper, expect even greater understanding proper Jeopardy! strategy obtained development deployment algorithms basedapproaches. top humans classic board games (Chess, Backgammon, etc.)use computer software invaluable study aids, envision studying Jeopardy!strategy software could become vital part contestant preparation appearshow. Toward end, currently developing version DD wager calculator242fiAnalysis Watsons Strategies Playing Jeopardy!deployed J! Archive. nicely complement existing FJ wager calculator,make DD analysis widely accessible study prospective contestants.simulation modelers, perhaps important take-home lesson workWatson reminder merits starting approach based extremesimplification. generally appreciated simulation predictions may insensitivemany low-level details. However, given central role natural language cluescategory titles Jeopardy! gameplay, least mildly surprising successfulsimulation models may completely ignore natural language content. One mightalso thought simple mean-rate models would inadequate, fail capturepotentially important hot cold streaks specific categories, well variance acrosscontestants general QA ability. factors apparently critically importantmodel purposes optimizing Watsons strategies. Finally, clearcould adequately predict expected outcomes Watson vs. two humans scant livegame data. crude estimates relative buzzability, etc., made attemptmodel impact Watsons unusual gameplay human performance, tipoff benefit humans Watson answers incorrectly. Despite limitations,validation studies section 2.7 demonstrate remarkably accurate predictions performancemetrics.Looking beyond immediate Jeopardy! domain, also foresee general applicability high-level approach coupling Decision Analytics QA Analytics,consists building simulation model domain (including agents domain),simulating short-term long-term risks rewards QA-based decisions,applying learning, optimization Risk Analytics techniques develop effective decisionpolicies. currently investigating applications high-level approach healthcare, dynamic pricing, security (i.e., counter-terrorism) domains.Acknowledgmentsgrateful entire worldwide team IBM made Watson project possible, team Sony/JPI made Exhibition Match Sparring Games possible,former Jeopardy! contestants volunteered participate live test matchesWatson. thank anonymous reviewers Ed Toutant many helpful comments suggestions improve manuscript.Appendix A. Watsons Competitive RecordPrior appearing Jeopardy!, Watson played 100 Sparring Gamesformer Jeopardy! contestants realistic replica TV studio, constructedIBM Research Center Yorktown Heights, NY. studio featured real Jeopardy!contestant lecterns signaling devices, made use actual JPI (Jeopardy Productions Inc.) game-control system. content game (categories, clues, answers)supplied directly JPI, consisted actual Jeopardy! episodes alreadytaped, yet aired. (This eliminated possibility contestants couldpreviously seen content used games.) professional actor, Todd Crain,243fiTesauro, Gondek, Lenchner, Fan & Pragerhired host games. incentivize contestants, paid $1000first-place finish, $250 second-place finish.initial series 73 games took place Oct. 2009 Mar. 2010. Contestantsrecruited JPI, appeared show twice, noneappeared three episodes. considered players representativeaverage human contestants appear show. Results series gamesWatson finished first 47 games (64.4%), second 15 games (20.5%), third11 games (15.1%). also note 21 Watsons 47 wins lockout, i.e.,guaranteed wins Watson could caught Final Jeopardy.Watson additionally played second series 55 games Fall 2010, timemuch stronger human opposition. contestants competedshows annual Tournament Champions, done well enough reach finalsemi-final rounds. Watson also considerably improved respects, particular,full complement advanced quantitative strategies deployed games. (Bycontrast, advanced strategy Series 1 games Final Jeopardybetting.) Results series follows: Watson finished first 39 games (70.9%),second 8 games (14.55%) third 8 games (14.55%). Watsons rate winninglockout also improved, 30 39 games (76.9%), vs. 21/47 = 44.7% previousseries.Finally, witnessed millions viewers, Watson played two-game Exhibitionmatch Ken Jennings Brad Rutter, arguably two best human Jeopardy!contestants time. Watson took $1,000,000 first-place prize lockout,total score 77,147. Ken Jennings took second place ($300,000) score 24,000,Brad Rutter finished third place ($200,000) score 21,600.Appendix B. Buzz Threshold Calculation DetailsAppendix presents computational details method calculating initial buzzrebound buzz decisions endgame state remaining Daily Doubles, currentselected square dollar value D, K remaining squares played currentsquare. assume optimizing buzz decision one player (the strategicplayer), two opponents non-strategic players buzz decisionsdetermined fixed stochastic process. assume opponentsbuzz decisions change going initial buzz rebound second rebound.default strategic player Watson, although also developed similar methodcompute confidence thresholds human contestants.calculation invoked Watson live play assumes Watsons confidenceyet known, since computation must begin QA system returnedconfidence value. therefore pre-compute buzz decisions discretized confidence values0 1 discretization interval typically set 0.01.B.1 Calculation Watson vs. Two HumansCalculation proceeds diagramming tree possible events starting initial buzzstate leading possible end-of-clue states, corresponding different scorechange combination. denote end-of-clue equities Exyz , first index244fiAnalysis Watsons Strategies Playing Jeopardy!denotes Watsons score change, possible values x, z + (the playersscore increased D), 0 (score remained unchanged), - (score decreased D).Since one contestant score increase, total 20 end-of-cluestates: 12 contestant got clue right, eight one got right.tree allows possibility Watson may buzz may buzzfour live states (0=initial buzz, 1=rebound human #1 wrong, 2=reboundhuman #2 wrong, 3=rebound humans wrong) Watson eligible buzz.Descending tree starting initial buzz state, assigns transition probabilitiesevery branch, using regular-clue model human performance, along probabilitiesWatson win contested buzz one two humans attempting buzz.defined tree, transition probabilities, set end-of-clue states,algorithm first estimates end-of-clue equities Monte-Carlo trials remainingclues Final Jeopardy. MC trials make use stochastic process modelshuman Watson performance regular clues presented earlier.One useful trick employ reuse MC trial remaining clues20 end-of-clue states, instead generating independent trials states.done first performing trial (0, 0, 0) state, player attempted buzzin, offsetting sequence scores scores going FJ specificscore change end-of-clue state. enables faster computation achievesstatistically significant comparisons states would result independenttrials. Additionally, trial performed, monitor step whetherWatson achieved guaranteed lockout given starting scores specific scorechange combinations end-of-clue state. so, mark trial guaranteed winend-of-clue state: obviates need simulate FJ trial, makessimulations faithful, since Watson actually uses lockout-preserving buzzing liveplay.evaluated end-of-clue states described above, calculation works backwards evaluate progressively higher interior tree nodes. first calculate confidenceindependent values Watson-ineligible states Watson buzzes wrong.three states: IS0 (Watson wrong initial buzz), IS1 (Watson wronghuman #1 wrong) IS2 (Watson wrong human #2 wrong). Formulasvalues written below.establish notation formulas, recall human models generate correlatedbinary events start regular clue indicating whether contestants attemptbuzz, whether correct answer. binary variables persist clueplayed, buzz decisions correctness change rebounds.mind, let b00 , b01 , b10 , b11 denote probabilities four possible buzz/nobuzz joint decisions pair humans, p00 , p01 , p10 , p11 denote probabilitiesfour possible joint right/wrong outcomes. typically assume symmetric human modelsb01 = b10 p01 = p10 . let pH = p10 + p11 = p01 + p11 denote singlecontestant human precision, bH = b10 + b11 = b01 + b11 denote single-contestanthuman buzz attempt rate. values may fixed clue values, may useestimated values depend round row number, depicted Figure 5.245fiTesauro, Gondek, Lenchner, Fan & Pragernotation, formula IS0 value is:V (IS0) = b00 E00 + pH (b10 + b11 /2)(E+0 + E0+ ) + (1 pH )b10 (E0 + E0 )+p01 b11 (E+ + E+ )/2 + p00 b11 E(7)Similarly, values IS1 IS2 states given by:b11b10E0 +V (IS1) =bHbHp01 E+ + p00 E1 pH(8)b11b01E0 +V (IS2) =bHbHp10 E+ + p00 E1 pH(9)Note expressions require conditional probabilities remainingeligible human buzz answer correctly, given first human buzzed answeredincorrectly. Using unconditional probabilities would correspond model re-drawsbuzz/no-buzz right/wrong outcomes rebound, consistentmodel.Next evaluate live states LS0, LS1, LS2, LS3 Watson eligible buzz,starting double-rebound state LS3, working backwards first reboundstates LS1 LS2, finally initial-buzz state LS0. compute separate evaluationscases Watson buzzes buzz; larger determinesoptimal policy optimal value function.given Watson confidence level c, values double-rebound stateWatson buzzes buzz given respectively by:VB (LS3, c) = cE+ + (1 c)EVN B (LS3, c) = E0(10)(11)Thus Watsons optimal buzz decision B (LS3, c) = arg maxB,N B {VB (LS3, c), VN B (LS3, c)}optimal state value is: V (LS3, c) = max{VB (LS3, c), VN B (LS3, c)}.Figure 11: Event tree live state 2, human #2 buzzed initially wrong.246fiAnalysis Watsons Strategies Playing Jeopardy!Calculation first rebound state values proceeds diagrammed Figure 11,considers LS2 state human #2 buzzed first answered incorrectly.Red arrows indicate outcomes Watson buzz. Green brown arrowsindicate respective cases Watson wins buzz loses buzz. Z1 denotesprobability Watson wins contested buzz one human. analogous treeLS1 obtained interchanging human #1 #2 indices.b11 p10 E0+ + p00 V (LS3, c)b01E00 +bHbH1 pHb11 Z1 + b01[cE+0 + (1 c)V (IS2)]VB (LS2, c) =bHb11 (1 Z1 ) p10 E0+ + p00 V (LS3, c)+bH1 pHVN B (LS2, c) =(12)(13)Figure 12: Event tree live state 0, i.e., initial buzz state.Finally, Figure 12 illustrates analysis initial buzz state LS0. Z2 denotesprobability Watson wins buzz humans buzzing.VN B (LS0, c) = b00 E000 + (b10 + b11 /2)[pH (E0+0 + E00+ ) +(1 pH )(V (LS1, c) + V (LS2, c))](14)VB (LS0, c) = b00 (cE+00 + (1 c)E00 )+((b01 + b10 )Z1 + b11 Z2 )(cE+00 + (1 c)V (IS0))+(b10 (1 Z1 ) + b11 (1 Z2 )/2)(pH E0+0 + (1 pH )V (LS1, c))+(b01 (1 Z1 ) + b11 (1 Z2 )/2)(pH E00+ + (1 pH )V (LS2, c)) (15)247fiTesauro, Gondek, Lenchner, Fan & PragerB.2 Calculation Human vs. Two Humanspresent extension calculation strategic playerhuman instead Watson. scenario introduces additional complexity that, unlikeWatson, strategic players performance correlated opponents (andvice versa).approach hypothesizes mechanism generate correlated private confidence estimates (c0 , c1 , c2 ) player current clue revealed, drawn suitablemulti-variate confidence distribution. assume non-strategic players attemptbuzz private confidence value exceeds fixed threshold, chosenprobability mass threshold matches desired attempt rate, firstmoment threshold matches desired precision. uniform (b, p) modelclues, described section 2.4, would match target values b = 0.61, p = 0.87using Beta distribution player, Beta(0.69, 0.40), buzz threshold value set0.572. However, obtain accurate meaningful threshold model humansfitting different Beta distribution (b, p) parameter combination estimatedround row number, plotted Figure 5.obtain correlated draws resulting multi-variate Beta distribution viacopula technique (Nelsen, 1999). entails drawing ~x = (x0 , x1 , x2 ) suitably~ =correlated multi-variate normal distribution, mapping respective CDF values X(X0 , X1 , X2 ) lie unit interval, mapping values inverseCDF Beta distribution. Since confidence draws correlated, resultcorrelated buzzing non-strategic players. obtain correlated precisionsimilarly generating correlated uniform numbers unit interval compareplayers confidence values basis assigning right/wrong answers. correlationcoefficient 0.4 matches observed precision correlation Average Contestants.model correlated confidence-based buzzing precision,equipped make necessary modifications calculations described Equations 7-15Figures 11,12. every case, opponent attempt rates precisions needconditioned strategic players confidence value c. make accurate numericestimates conditional probabilities running many millions trialssimulation model, discretizing observed c trial, recording discretelevel number times 0, 1 2 opponents buzzed, 0, 1, 2 opponentscorrect answer. Additionally, considering buzzing first second rebound,strategic player needs estimate posterior confidence given one two opponentsalready buzzed answered incorrectly. result significant dropestimated confidence: example, initial confidence 80% drop posteriorvalue 50% double-rebound state LS3. Finally, ineligible statesIS0, IS1, IS2, expected opponent precisions must also conditioned upon strategicplayer buzzing answering incorrectly.B.3 Max-Delta Approximationdeveloped greatly simplified analytic approximation calculations given Equations 7-15 making following assumptions: (i) current game state farend game (i.e., current clue value much smaller total value248fiAnalysis Watsons Strategies Playing Jeopardy!remaining clues); (ii) three players intermediate probabilities winning (i.e.,close 0 1). assumptions, players equity change end clueapproximately linear score changes three players. Intuitively, maywrite: E (1 (S0 S1 ) + 2 (S0 S2 )), S0 players score S1 , S2opponent scores, recognizing chances winning depend score positioningrelative opponents. assume opponent scores similar (whichoften true early game), 1 2 , overall scaling factor.clue value also overall scaling factor, express Max-Delta objectivebuzz decision rewriting end-of-clue equities Exyz appearing Equations 7-15Exyz = 2x z.facilitate analytic calculation, also assume opponents buzz attempts precisions three players uncorrelated. equitiesineligible states {IS0,IS1,IS2} reduce to:V (IS0) = 2(1 b)2 6bp(1 b/2) 2(1 p)b(1 b) 4p(1 p)b2V (IS1) = V (IS2) = b 1 2bp(16)similarly rewrite equities four live states {LS0,LS1,LS2,LS3}buzzing buzzing. double-rebound state LS3, reduce VB (LS3) = 4cVN B (LS3) = 2. threshold confidence c = 3 , 43 = 2, 3 = 0.5.likewise equating buzz/no-buzz equities live states, obtain closedform analytic expressions respective thresholds {0 , 1 , 2 }. first-reboundthresholds, have:1 = 2 =2 + b2 (1 Z1 )(1 2p) + b(2p 3)(1 Z1 )(b(Z1 1) + 1)(b(2p 1) + 4)(17)expression assumes 1 , 2 3 player buzz secondrebound state. Finally, initial buzz threshold 0 (again assuming no-buzz reboundstates) is:wm + 2(1 b)2 2wV (IS0)0 =(18)4(1 b)2 + 4w 2wV (IS0)= 2p + 2(1 p)(1 + b 2bp) total equity change losing buzzeither opponent, w = b(1 b)Z1 + 0.5b2 Z2 probability beating one opponentbuzzer.average human contestants, set b = 0.61, p = 0.87, Z1 = 1/2, Z2 = 1/3,yielding first-rebound thresholds 1 = 2 = 0.478 initial buzz threshold 0 = 0.434.four Max-Delta thresholds computed quite close uncorrelated Monte-Carlovalues reported Table 6 simulations average contestants early game states.ReferencesAinslie, G. (2001). Breakdown Will. Cambridge Univ. Press.Axelrod, R. (1984). Evolution Cooperation. Basic Books.Bertsekas, D. P. (1995). Dynamic Programming Optimal Control. Athena Scientific.249fiTesauro, Gondek, Lenchner, Fan & PragerBertsekas, D. P., & Castanon, D. A. (1999). Rollout algorithms stochastic schedulingproblems. J. Heuristics, 5, 89108.Billings, D. (2000). first international RoShamBo programming competition. Intl.Computer Games Assn. Journal, 23 (1), 4250.Billings, D., Davidson, A., Schaeffer, J., & Szafron, D. (2002). challenge poker.Artificial Intelligence, 134 (1-2), 201240.Dupee, M. (1998). Get Jeopardy! Win! Citadel Press.Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur, A. A., ..., & Welty,C. (2010). Building Watson: Overview DeepQA Project. AI Magazine, 31 (3),5979.Ferrucci, D. A. (2012). Introduction Watson. IBM J. Research Development, 56 (3/4), 1:11:15.Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, MA.Ginsberg, M. L. (1999). GIB: Steps toward expert-level bridge-playing program.Dean, T. (Ed.), Proc. Sixteenth Intl. Joint Conf. Artificial Intelligence, pp.584589, San Francisco. Morgan Kaufmann Publishers.Harris, B. (2006). Prisoner Trebekistan: decade Jeopardy! Crown Publishers.J! Archive (2013). J! Archive. http://www.j-archive.com. Online; accessed 22-March-2013.Jeopardy! Gameplay (2013). Jeopardy! Gameplay Wikipedia, Free Encyclopedia.http://en.wikipedia.org/wiki/Jeopardy!#Gameplay. Online; accessed 22-March-2013.Leisch, F., Weingessel, A., & Hornik, K. (1998). generation correlated artificialbinary data. Vienna Univ. Economics Business Administration, Working PaperNo. 13.Nelsen, R. B. (1999). Introduction Copulas. Springer.Prager, J. M., Brown, E. W., & Chu-Carroll, J. (2012). Special questions techniques.IBM J. Research Development, 56 (3/4), 11:111:13.Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1987). Learning internal representationserror propagation. Rumelhart, D. E., McClelland, J. L., et al. (Eds.), ParallelDistributed Processing: Volume 1: Foundations, pp. 318362. MIT Press, Cambridge.Sheppard, B. (2002). World-championship-caliber Scrabble. Artificial Intelligence, 134 (1-2),241275.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, MA.Tesauro, G. (1995). Temporal difference learning TD-Gammon. Commun. ACM, 38 (3),5868.Tesauro, G., & Galperin, G. (1996). On-line policy improvement using Monte-Carlo search.Advances Neural Information Processing 9, pp. 10681074.Tesauro, G., Gondek, D. C., Lenchner, J., Fan, J., & Prager, J. M. (2012). Simulation,learning, optimization techniques Watsons game strategies. IBM J. ResearchDevelopment, 56 (34), 16:116:11.250fiAnalysis Watsons Strategies Playing Jeopardy!Wu, F.-C., & Tsang, Y.-P. (2004). Second-order Monte Carlo uncertainty/variability analysis using correlated model parameters: application salmonid embryo survival riskassessment. Ecological Modelling, 177, 393414.251fiJournal Artificial Intelligence Research 47 (2013) 441-473Submitted 12/12; published 07/13Decentralized Anti-coordinationMulti-agent LearningLudek CiglerBoi Faltingsludek.cigler@epfl.chboi.faltings@epfl.chArtificial Intelligence LaboratoryEcole Polytechnique Federale de LausanneCH-1015 Lausanne, SwitzerlandAbstractachieve optimal outcome many situations, agents need choose distinctactions one another. case notably many resource allocation problems,single resource used one agent time. shall designermulti-agent system program identical agents behave different way?game theoretic perspective, situations lead undesirable Nash equilibria.example consider resource allocation game two players compete exclusiveaccess single resource. three Nash equilibria. two pure-strategy NEefficient, fair. one mixed-strategy NE fair, efficient. Aumannsnotion correlated equilibrium fixes problem: assumes correlation devicesuggests agent action take.However, smart coordination device might available. propose usingrandomly chosen, stupid integer coordination signal. Smart agents learn actionuse value coordination signal.present multi-agent learning algorithm converges polynomial numbersteps correlated equilibrium channel allocation game, variant resourceallocation game. show agents learn play coordination signal valuerandomly chosen pure-strategy Nash equilibrium game. Therefore, outcomeefficient correlated equilibrium. CE becomes fair numberavailable coordination signal values increases.1. Introductionmany situations, agents coordinate actions order use limitedresource: communication networks, channel might used one agent time.driving car, agent prefers choose road less traffic, i.e. one chosensmaller number agents. bidding one item several simultaneousauctions, agent prefers auction less participants, usually leadlower price. situations require agents take different decision. However,agents identical, problem one face same.learn behave differently everyone else?Second problem arises agents common preferences actionwant take: communication networks problem, every agent prefers transmitquiet. traffic situation, agents might prefer shorter path. orderachieve efficient allocation, necessary precisely agents stay quiet,take longer path. achieve agents exploited?c2013AI Access Foundation. rights reserved.fiCigler & Faltingsagents learn alternate, taking longer road one day, taking shorterroad next day?central coordinator possesses complete information agents preferencesavailable resources easily recommend agent action take.However, omniscient central coordinator always available. Therefore,would like able use distributed scheme. consider scenariosagents try use set resources repeatedly, use history pastinteractions learn coordinate access resources future.particular, consider problem radio channel access. problem, N agentstry transmit C non-overlapping channels. Fully decentralized schemes,ALOHA (Abramson, 1970), achieve throughput 1e 37%, i.e. transmission succeeds probability 1e 0.37. complex schemes, baseddistributed constraint optimization (Cheng, Raja, Xie, & Howitt, 2009), reachthroughput close 100%. throughput, mean probability successful transmission given channel. However, messages necessary implement schemescreate overhead eliminates part benefits.paper propose instead use simple signal agents observeergodically fluctuates. signal could common clock, radio broadcastingspecified frequency, decimal part price certain stock given time, etc.Depending stupid signal, smart agents learn take different actionvalue. say signal stupid, doesnt anythinggame agents give meaning acting differentlyvalue coordination signal.Lets look simplest example channel access problem: one 2 agents trytransmit one shared channel. model situation game normalform. Agents choose two actions: stay quiet (Q) transmit (T ).one agent may transmit successfully time. agent transmits alone, receivespositive payoff. agent transmit channel, payoff 0. agentstry transmit channel time, transmissions fail incurcost c.payoff matrix game looks follows:QQ0, 01, 00, 1c, cgame two pure-strategy Nash equilibria (NE), one player stays quietone transmits. also one mixed-strategy NE, player stays1quiet probability c+1. two pure-strategy NE efficient, maximizesocial welfare, fair: one player gets full payoff, even thoughgame symmetric. mixed-strategy NE fair, efficient: expectedpayoff players 0.such, Nash equilibria game rather undesirable: either efficientfair, time. seminal paper, Aumann (1974) proposednotion correlated equilibrium fixes problem. correlated equilibrium (CE)probability distribution joint strategy profiles game. correlation device442fiDecentralized Anti-coordination Multi-agent Learningsamples distribution recommends action agent play. probabilitydistribution CE agents incentive deviate recommendedaction.simple game described above, exists CE fair sociallyefficient: correlation device samples two pure-strategy NE probability 21 recommends players NE play. correspondsauthority tells player whether stay quiet transmit.Correlated equilibria several nice properties: easier find succinctrepresentation game, polynomial time, see (Papadimitriou & Roughgarden, 2008).Also, every Nash equilibrium correlated equilibrium. Also, convex combinationtwo correlated equilibria correlated equilibrium. However, smart correlation devicerandomizes joint strategy profiles might always available.possible achieve correlated equilibrium without actual correlation device.Assume game played repeatedly, agents observe historyactions taken opponents. learn predict future action (or distribution future actions) opponents. predictions need calibrated, is,predicted probability agent play certain action aj convergeactual frequency agent plays action aj . Agents always play actionbest response predictions opponents actions. Foster Vohra (1997)showed case, play converges set correlated equilibria.However, paper, Foster Vohra provide specific learning ruleachieve certain CE. Furthermore, approach requires every agent ableobserve actions every opponent. requirement met, convergencecorrelated equilibrium guaranteed anymore.paper, focus generalization simple channel allocation problemdescribed above. N agents always data transmit,C channels transmit. assume N C. Access channelslotted, is, agents synchronized start transmissionstime. Also, transmissions must length. one agent attemptstransmit single channel, collision occurs none transmissionssuccessful. unsuccessful transmission cost agent, since consume(possibly constrained) power benefit. transmitting costanything.assume agents receive binary feedback. transmitted data,find whether transmission successful. transmit,choose channel observe. receive information whether observed channelfree not.described normal-form game, problem several efficient (but unfair)pure-strategy Nash equilibria, group C agents gets assigned channels.remaining N C agents get stranded. also fair inefficient mixed-strategy NE,agents choose transmission channels random. example resourceallocation game above, exists correlated equilibrium efficient fair.stupid coordination signal introduced paper helps agents learnplay (potentially) different efficient outcome value. way,reach efficient allocation still preserving level fairness.443fiCigler & Faltingsmain contributions work following:propose learning strategy agents channel allocation game that, usingminimal information, converges polynomial time randomly chosen efficientpure-strategy Nash equilibrium game.show agents observe common discrete correlation signal,learn play efficient pure-strategy NE signal value. resultcorrelated equilibrium increasingly fair number available signals Kincreases.experimentally evaluate sensitive algorithm player populationdynamic, i.e. players leave enter system. also evaluatealgorithms resistance noise, feedback players receivecoordination signal observe.channel allocation algorithm proposed paper implemented Wang,Wu, Hamdi, Ni (2011) real-world wireless network setting. showedwireless devices use use actual data transmitted coordinationsignal. way, able achieve 2-3 throughput gain compared randomaccess protocols ALOHA.worth noting work, focus reaching correlated fairoutcome, provided agents willing cooperate. situations usingresources costs nothing, self-interested agent could stubbornly keep using it. Everyoneelse better trying access resource. sometimes calledwatch crazy bully strategy (Littman & Stone, 2002).order prevent kind behavior, would need make sure orderuse resource, agent pay cost. cost may already implicitproblem, fact wireless transmission costs energy, may imposedexternal payments. recent work (Cigler & Faltings, 2012), show leadsequilibria rational agents indifferent accessing resource yielding,equilibria implement allocation policy rational agents. considerissue beyond scope paper refer reader workdeeper analysis.rest paper organized follows: Section 2, give basic definitionsgame theory theory Markov chains use throughout paper.Section 3, present algorithm agents use learn action possiblecorrelation signal value. Section 4 prove algorithm convergesefficient correlated equilibrium polynomial time number agents channels.show fairness resulting equilibria increases number signals Kincreases Section 5. Section 6 highlights experiments show actual convergencerate fairness. also show algorithm performs case populationchanging dynamically. Section 7 present related work game theorycognitive radio literature, Section 8 concludes.444fiDecentralized Anti-coordination Multi-agent Learning2. Preliminariessection, introduce basic concepts game theory theoryMarkov chains going use throughout paper.2.1 Game TheoryGame theory study interactions among independent, self-interested agents.agent participates game called player. player utility functionassociated state world. Self-interested players take actions achievestate world maximizes utility. Game theory studies attemptspredict behaviour, well final outcome interactions. Leyton-BrownShoham (2008) give complete introduction game theory.basic way represent strategic interaction (game) using so-called normalform.Definition 1. finite, N -person normal-form game tuple (N, A, u),N set N players;= A1 A2 . . . , Ai set actions available player i. vector= (a1 , a2 , . . . , ) called action profile;u = (u1 , u2 , . . . , uN ), ui : R utility function player assignsaction vector certain utility (payoff).playing game, players select strategy. pure strategyplayer selects one action ai Ai . vector pure strategies player =(1 , 2 , . . . , N ) called pure strategy profile. mixed strategy selects probabilitydistribution entire action space, i.e. (Ai ). mixed strategy profilevector mixed strategies player.Definition 2. say mixed strategy player best response strategyprofile opponents strategy i0 ,ui (i , ) ui (i0 , )One basic goals game theory predict outcome strategic interaction.outcome stable therefore, usually called equilibrium. One requirement outcome equilibrium none players incentivechange strategy, i.e. players play best-response strategies others.defines perhaps important equilibrium concept, Nash equilibrium:Definition 3. strategy profile = (1 , 2 , . . . , N ) Nash equilibrium (NE)every player i, strategy best response strategies others .essential Nash equilibria are, several disadvantages. First, mayhard find: Chen Deng (2006) show finding NE PPAD-complete. Second,might multiple Nash equilibria, shown example Section 1. Third,efficient NE may fair one, even symmetric game. giveformal definition correlated equilibrium fixes issues:445fiCigler & FaltingsDefinition 4. Given N -player game (N, A, u), correlated equilibrium tuple (v, , ),v tuple random variables v = (v1 , v2 , . . . , vN ) whose domains =(D1 , D2 , . . . , DN ), joint probability distribution v, = (1 , 2 , . . . , N )vector mappings : Di 7 Ai , player every mapping 0i : Di 7 AicaseXX(d)ui (1 (d1 ), 2 (d2 ), . . . , N (dN ))(d)ui 01 (d1 ), 02 (d2 ), . . . , 0N (dN ) .dDdD2.2 Markov Chainslearning algorithm propose analyze paper described randomized algorithm. randomized algorithm, steps depend valuerandom variable. One useful technique analyze randomized algorithms describeexecution Markov chain.Markov chain random process Markov property. random processcollection random variables; usually describes evolution random valuetime. process Markov property state (or value) next time step dependsexclusively value previous step, values past.say process memoryless. imagine execution randomizedalgorithm finite-state automaton non-deterministic steps, easy seeexecution maps Markov chain.formal definition Markov chain follows:Definition 5. (Norris, 1998) Let countable set. called statecalled state space. say P= (i : I) measure 0 <I. addition total mass iI equals 1, call distribution.work throughout probability space (, F, P). Recall random variable Xvalues function X : I. Suppose set= Pr(X = i) = Pr ({ : X() = i}) .defines distribution, distribution X. think X modelling randomstate takes value probability .say matrix P = (pij : i, j I) stochastic every row (pij : j I)distribution.say (Xt )t0 Markov chain initial distribution transition matrixP1. X0 distribution ;2. 0, conditional Xt = i, Xt+1 distribution (pij : j I) independentX0 , X1 , . . . , Xt1 .explicitly, conditions state that, 0 i0 , . . . , it+1 I,1. Pr(X0 = i0 ) = i0 ;2. Pr(Xt+1 = it+1 |X0 = i0 , . . . , Xt = ) = pit it+1 .446fiDecentralized Anti-coordination Multi-agent LearningTheorem 1. Let set states. vector hitting probabilities hA = (hA:{0, 1, . . . , N }) minimal non-negative solution system linear equations1hi = Pph/Aj{0,1,...,N } ij jIntuitively, hitting probability hAprobability Markov chainstarts state i, ever reach states A.One property randomized algorithms particularly interestedconvergence. set states algorithm converged, definetime takes reach state set state correspondingMarkov chain hitting time:Definition 6. (Norris, 1998) Let (Xt )t0 Markov chain state space I. hittingtime subset random variable H : {0, 1, . . .} {} givenH () = inf{t 0 : Xt () A}Specifically, interested expected hitting time set states A, givenMarkov chain starts initial state X0 = i. denote quantitykiA = Ei (H ).general, expected hitting time set states found solvingsystem linear equations.Theorem 2. vector expected hitting times k = E(H ) = (kiA : I)minimal non-negative solution system linear equationski = 0 P(1)kiA = 1 + jpk/Aijj/Convergence absorbing state may guaranteed general Markov chain.calculate probability reaching absorbing state, use following theorem(Norris, 1998):Theorem 3. Let set states. vector hitting probabilities hA = (hA:{0, 1, . . . , N }) minimal non-negative solution system linear equations1hi = Pph/Aijjj{0,1,...,N }Solving systems linear equations Theorems 2 3 analytically mightdifficult many Markov chains though. Fortunately, Markov chainone absorbing state = 0, move state j j, usefollowing theorem derive upper bound expected hitting time, provedRego (1992):Theorem 4. Let = {0}.1 : E(Xt+1 |Xt = i) <> 1,kiA < log +4471fiCigler & Faltings3. Learning Algorithmsection, describe algorithm agents use learn correlated equilibrium channel allocation game.Let us denote space available correlation signals K := {0, 1, . . . , K 1},space available channels C := {1, 2, . . . , C}. Assume C N ,agents channels (the opposite case easier). agent strategy fi : K {0}Cuses decide channel access time receives correlationsignal kt . fi (kt ) = 0, agent transmit signal kt . agent storesstrategy simply table.agent adapts strategy follows:1. beginning, k0 K, fi (k0 ) initialized uniformly random C.is, every agent picks random channel transmit on, agent monitorchannels.2. time t:fi (kt ) > 0, agent tries transmit channel fi (kt ).otherwise fi (kt ) = 0, agent chooses random channel mi (t) Cmonitor activity.3. Subsequently, agent observes outcome choice: agent transmittedchannel, observes whether transmission successful. was,agent keep strategy unchanged. collision occurred, agent setsfi (kt ) := 0 probability p. probability 1 p, strategy remains same.4. agent transmit, observes whether channel mi (t) monitoredfree. channel free, agent sets fi (kt ) := mi (t) probability 1.channel free, strategy fi remains same.4. Convergenceimportant property learning algorithm if, fast convergepure-strategy Nash equilibrium channel allocation game every signal value.algorithm randomized. Therefore, instead analyzing worst-case behavior (that mayarbitrarily bad), analyze expected number steps convergence.4.1 Convergence C = 1, K = 1single channel single coordination signal, prove following theorem:Theorem 5. N agents C = 1, K = 1, 0 < p < 1, expected number stepsallocation algorithmconvergespure-strategy Nash equilibrium channel1allocation game p(1p) log N .prove convergence algorithm, useful describe executionMarkov chain.448fiDecentralized Anti-coordination Multi-agent LearningN agents compete single signal value, state Markov chainvector {0, 1}N denotes agents attempting transmit. purposeconvergence proof, important many agents trying transmit,agents. probability agents back-offeveryone. Therefore, describe algorithm execution using following chain:Definition 7. Markov chain describing execution allocation algorithmC = 1, K = 1, 0 < p < 1 chain whose state time Xt {0, 1, . . . , N },Xt = j means j agents trying transmit time t.transition probabilities chain look follows:Pr (Xt+1 = N |Xt = 0) = 1Pr (Xt+1 = 1|Xt = 1) = 1ijPr (Xt+1 = j|Xt = i) =p (1 p)jj(restart)(absorbing)> 1, jtransition probabilities 0. agentstransmitting channel, agent attempt access it.probability Pr (Xt+1 = N |Xt = 0) equal 1 channel becomesfree (Xt = 0), agents spot time + 1, everyone transmit (thereforechain state Xt+1 = N ). probability Pr (Xt+1 = 1|Xt = 1) equal onesingle agent successfully transmits channel, keep transmittingforever after, agent attempt transmit there. Finally, probabilityPr (Xt+1 = j|Xt = i) expresses fact Xt = (i agents transmit time t),probability agent transmitted time keep transmitting time + 1probability 1 p.interested number steps take Markov chain first arrivestate Xt = 1 given started state X0 = N . would mean agentsconverged setting one transmitting, others not.Definition 6 defined hitting time describes quantity.show expected value E[h1 ] hitting time state Xt = 1 (andcorollary, prove Theorem 5) following steps:1. show expected hitting time set states = {0, 1} (Lemma 6)2. show probability Markov chain enters state 1 entering state0, starts state > 1 (Lemma 7)3. Finally, using law iterated expectations, combine two lemmas showexpected hitting time state 1.Lemma 6. Let = {0, 1}. expectedhittingtime set states Markov1chain described Definition 7 p log N .Proof. first provehitting time set A0 = {0} slightlyexpectedmodified Markov chain p1 log N .449fiCigler & FaltingsLet us define new Markov chain (Yt )t0 following transition probabilities:Pr (Yt+1 = 0|Yt = 0) = 1ijPr (Yt+1 = j|Yt = i) =p (1 p)jj(absorbing)j 0, 1Note transition probabilities chain (Xt )t0 , exceptstates 0 1. state 1 positive probability going state 0, state 0absorbing. Clearly, expected hitting time set A0 = {0} new chainupper bound expected hitting time set = {0, 1} old chain.path leads state 0 new chain either go state 1(so happened probability old chain), goes state 1,old chain would stop state 1 (but would one step shorter).chain state Yt = i, next state Yt+1 drawn binomial distributionparameters (i, 1 p). expected next state thereforeE(Yt+1 |Yt = i) = i(1 p)1therefore use Theorem 4 := 1pderive A0 = {0},hitting time is:l11A0ki < log 1 +log1pppalso upper bound kiA = {0, 1} old chain.Lemma 7. probability hi Markov chain defined Definition 7 enters state 1entering state 0, started state > 1, greater 1 p.Proof. Calculating probability chain X enters state 1 state 0 equalcalculating hitting probability, i.e. probability chain ever entersgiven state, modified Markov chain probability staying state 0Pr (Xt+1 = 0|Xt = 0) = 1. set states A, let us denote hAprobabilityMarkov chain starting state ever enters state A. calculate probability,use Theorem 3. modified Markov chain cannot leave neither state 0state 1, computing hA= 1 easy, since matrix system linear equationslower triangular.Well show hi q = 1 p > 1 using induction. first step calculating hi{0, 1, 2}.h0 = 0h1 = 1h2 = (1 p)2 h2 + 2p(1 p)h1 + p2 h02p(1 p)2(1 p)==1 p.1 (1 p)22pNow, induction step, derive bound hi assuming hj q = 1 pj < i, j 2.450fiDecentralized Anti-coordination Multi-agent LearningXijhi =p (1 p)j hjjj=0Xijp (1 p)j q ipi1 (1 p)(q h1 ) pi h0jj=0= q ipi1 (1 p)(q 1) q = 1 p.means matter state 2 Markov chain starts in, enterstate 1 earlier state 0 probability least 1 p.finish proof bound expected hitting time state 1.use law iterated expectations:Theorem 8. (Billingsley, 2012) Let X random variable satisfying E(|X|) <another random variable probability space.E[X] = E [E[X|Y ]] ,i.e., expected value X equal conditional expected value X given .Let h1 random variable corresponding hitting time state 1. Definerandom variable Z denoting number passes state 0 Markov chain makesreaches state 1. Theorem 8, get:E[h1 ] = E[E[h1 |Z]].Lemma 6, shown expected number steps hA Markov chainreaches set states = {0, 1}. writeE[E[h1 |Z]] = E" ZX#hA = E[Z hA ] = hA E[Z].i=1Lemma 7 know probability chain passes state 1passing 0 greater 1 p. Therefore, say E[Z] E[Z 0 ]Z 0 random variable distributed according geometric distribution successprobability 1 p.1hA0=Olog N .E[h1 ] = hA E[Z] hA E[Z ] =1pp(1 p)concludes proof Theorem 5.shown expected time convergence algorithm finite,polynomial. probability algorithm converge finite numbersteps absorbing state? following theorem shows since expected hittingtime absorbing state finite, probability 1.451fiCigler & FaltingsTheorem 9. Let h1 hitting time state Xt = 1 Markov chainDefinition 7.Pr(h1 finite) = 1.Proof. Markov inequality, know since h1 0,Pr(h1 )E[h1 ].Therefore,Pr(h1 finite) = 1 lim Pr(h1 ) 1 limE[h1 ]= 1.means algorithm converges almost surely Nash equilibriumchannel allocation game.4.2 Convergence C 1, K = 1Theorem 10. N agents C 1, K = 1, expected number stepslearning algorithmh converges toia pure-strategy Nash equilibrium channel allocation1game C 1p p1 log N + C .Proof. beginning, least one channel,N agents want1transmit. take average p log N steps get state either 1 0agents transmit (Lemma 6). call period round.agents backed off, take average C stepsfind empty channel. call period break.channels might oscillate round break periods parallel,worst case, whole system oscillatetwo periods.1single channel, takes average 1p oscillations two periodsone agent transmits channel. C 1, takes1average C 1p steps round break channels oneh11agent transmitting. Therefore, take average C 1plogN+Cstepspsystem converges.4.3 Convergence C 1, K 1show convergence time K > 1, use general problem.Imagine K identical instances Markov chain. knoworiginal Markov chain converges initial state absorbing state expectedtime . imagine complex Markov chain: every step, selects uniformlyrandom one K instances original Markov chain, executes one stepinstance. time Tall K instances converge absorbing states?extension well-known Coupon collectors problem (Feller, 1968).following theorem (Gast, 2011, Thm. 4) shows upper bound expected numbersteps K instances original Markov chain converge:452fiDecentralized Anti-coordination Multi-agent LearningTheorem 11. (Gast, 2011) Let K instances Markov chainknown converge absorbing state expectation steps. select randomlyone Markov chain instance time allow perform one step chain,take average E[Tall ] K log K + 2T K + 1 steps K instances convergeabsorbing states.arbitrary C 1, K 1, following theorem follows Theorems 10 11:Theorem 12. N agents C 1, K 1, 0 < p < 1, 0 < q < 1, expected numbersteps learning algorithm converges pure-strategy Nash equilibriumchannel allocation game every k K11(K log K + 2K)CC + log N + 1 .1ppAumann (1974) shows Nash equilibrium correlated equilibrium,convex combination correlated equilibria correlated equilibrium. also knowpure-strategy Nash equilibria algorithm converges efficient:collisions, every channel every signal value, agent transmits. Therefore,conclude following:Theorem 13. learning algorithm defined Section 3 converges expected polynomial1time (with respect K, C, p1 , 1plog N ) efficient correlated equilibriumchannel allocation game.5. FairnessAgents decide strategy independently value coordination signal. Therefore, every agent equal chance game converges equilibriumfavorable her. agent transmit resulting equilibrium given signalvalue, say agent wins slot. C available channels N agents, agentCwins given slot probability N(since agent transmit two channelstime).analyse fairness algorithm converged correlated equilibrium. algorithms converge absorbing state (such ALOHA),need analysed intermediate states execution, believe approach justified fact algorithm converges relatively quickly, polynomialtime.describe number signals agent wins channelrandom variable Xi . variable distributed according binomial distributionCparameters K, N.measure fairness, use Jain index (Jain, Chiu, & Hawe, 1984).advantage Jain index continuous, resource allocation strictlyfair higher Jain index (unlike measures assign binary values,whether least half agents access resource). Also, Jain index independentpopulation size, unlike measures standard deviation agent allocation.453fiCigler & Faltingsrandom variable X, Jain index following:J(X) =(E[X])2E[X 2 ]C),X distributed according binomial distribution parameters (K, Nfirst second momentsCE[X] = KN2C 2C N CE X = K+K,NNNJain indexJ(X) =C K.C K + (N C)(2)Jain index holds 0 < J(X) 1. allocation considered fairJ(X) = 1.NTheorem 14. C, K = NC , limit limN CK = 0,lim J(X) = 1,Nallocation becomes fair N goes .Proof. theorem follows factlim J(X) = limNNC KC K + (N C)limit equal 1, needN C=0N C Klimholds exactly K =assume C N ).NC(that K grows asymptotically fasterNC;notepractical purposes, may also need know big shall choose K given CN . following theorem shows that:Theorem 15. Let > 0.1K>N1 ,CJ(X) > 1 .Proof. theorem follows straightforwardly Equation 2.454fiDecentralized Anti-coordination Multi-agent Learning5Convergence steps10410310010203040506070CFigure 1: Average number steps convergence N = 64, K = N C{1, 2, . . . , N }.6. Experimental Resultsexperiments, report average values 128 runs experiment.Error bars graphs denote interval contains true expected valueprobability 95%, provided samples follow normal distribution. error barsmissing either graph reports values obtained theoretically (Jain indexconstant back-off scheme) confidence interval small scale graph.6.1 Static Player Populationfirst analyze case population players remainstime.6.1.1 ConvergenceFirst, interested convergence allocation algorithm. Section 4know polynomial. many steps algorithm need convergepractice?Figure 1 presents average number convergence steps N = 64, K = Nincreasing number available channels C {1, 2, . . . , N }. Interestingly, convergencetakes longest time C = N . lowest convergence time C = N2 ,C = 1 increases again.happens change size signal space K? Figure 2 showsaverage number steps convergence fixed N , C varying K. Theoretically,455fiCigler & Faltings1400Convergence steps120010008006004002000010203040506070K110.90.90.80.80.70.7Jain indexJain indexFigure 2: Average number steps convergence N = 64, C =0.60.5K=NK = Nlog N0.40.20204060801001200.5K=2K = 2log N20.3K = N20.20140NK {2, . . . , N }.0.60.420.3N2K = 2N20406080100120140N(a) C = 1(b) C =N2Figure 3: Jain fairness index different settings C K, increasing N .shown number convergence steps O(K log K) Theorem 12. However,practice convergence resembles linear dependency K. algorithmneeds converge coordination signals.6.1.2 FairnessSection 5, know K = NC , Jain fairness index converges 1N goes infinity. fast convergence? big need choose K,depending N C, achieve reasonable bound fairness?456fiDecentralized Anti-coordination Multi-agent LearningFigure 3 shows Jain index N increases, C = 1 C = N2 respectively,various settings K. Even though every time K = NC (that is, K grows fasterNC ) Jain index increases (as shown Theorem 14), marked differencevarious settings K. K = NC , Jain index (from Equation 2):J(X) =N.2N C(3)Therefore, C = 1, Jain index converges 0.5, C =equal 23 N > 0, Figure 3 shows.N2,Jain index6.1.3 Optimizing Fairnesssaw fair outcome allocation algorithm agents consider gamesignal value independently. However, best do?improve fairness, agent correlates decisions different signal values?perfectly fair solution, every agent wins (and consequently transmit)number signal values. However, assume agents know manyagents system. Therefore, agents know fairshare signal values transmit for. Nevertheless, still use informationmany slots already transmitted decide whether back-off stoptransmitting collision occurs.Definition 8. strategy fit agent round t, define cardinalitynumber signals strategy tells agent access:fifi|fit | = fi k K|fit (k) > 0 fiIntuitively, agents whose strategies higher cardinality back-off oftenstrategy low cardinality.compare following variations channel allocation scheme, differoriginal one probability agents back collisions:Constant scheme described Section 3; Every agent backs constantprobability p.Linear back-off probability p =|fit |K .Exponential back-off probability p =|f |1 Kiparameter 0 < < 1.Worst-agent-last case collision, agent lowest |fit | backoff. others collided, back off. greedy algorithm requiresinformation assume agents have.compare fairness allocations experiments, need define Jainindex actual allocation. resource allocation vector X = (X1 , X2 , . . . , XN ),Xi cardinality strategy used agent i. allocation X, Jain index is:P2Ni=1 XiJ(X) =P2N Ni=1 Xi457fiCigler & FaltingsC = N/2, K = 2log2N10.98Jain index0.960.940.920.9ConstantLinearExponentialWorstagent0.880.86020406080100120140NFigure 4: Jain fairness index channel allocation scheme various back-off probabilities, C = N2 , K = 2 log2 NFigure 4 shows average Jain fairness index allocation back-off probabilityvariations. fairness approaching 1 worst-agent-last algorithm.worst everyone using back-off probability. ratio back-offprobability lowest-cardinality agent highest-cardinality agent decreases,fairness increases.shows improve fairness using different back-off probabilities. Nevertheless, shape fairness curve them. Furthermore,exponential back probabilities lead much longer convergence, shown Figure 5.C = N2 , convergence time linear constant back-off schemes similar.unrealistic worst-agent-last scheme obviously fastest, since resolves collisions1 step, unlike back-off schemes.6.2 Dynamic Player Populationtake look performance algorithm population playerschanging time (either new players join old players get replaced new ones).also analyze case errors players observe eithercoordination signal channel feedback noisy.6.2.1 Joining Playerssection, present results experiments group players joinssystem later. corresponds new nodes joining wireless network. precisely,458fiDecentralized Anti-coordination Multi-agent LearningC = N/2, K = 2log2NConstantLinearExponentialWorstagentConvergence steps310210110121010NFigure 5: Convergence steps various back-off probabilities.25% players join network beginning. remaining 75% playersjoin network later, one one. new player joins network previous playersconverged perfect channel allocation.experiments two ways initializing strategy new player.Greedy Either, joining players cannot observe many players already system. Therefore, initial strategy tries transmit possibleslots.Polite Or, players observe N (t), number players alreadysystem time t, new player joins system. Therefore, initialstrategy tries transmit slot probability N1(t) .Figure 6 shows Jain index final allocation 75% players join later,C = 1. players join greedy, aggressive. starttransmitting slots. hand, polite, aggressiveenough: new player starts strategy aggressive strategiesplayers already system. difference new player experiencecollision every slot transmits in. old players experience collision1N (t) slots. Therefore, back less slots.Therefore, especially constant scheme, resulting allocation unfair:either better new players (when greedy) older players (whenplayers polite).phenomenon illustrated Figure 7. compares measure called group fairness:average throughput last 25% players joined network end (new459fiCigler & FaltingsC = 1, K = Nlog N, join delay = converge init population = 0.25, KPS210.90.90.80.80.70.70.60.6Jain indexJain indexC = 1, K = Nlog2N, join delay = converge init population = 0.2510.50.40.30.50.40.30.20.2ConstantLinearWorstplayer0.1051015202530354045ConstantLinearWorstplayer0.1055010152025N3035404550N(a) Greedy(b) PoliteFigure 6: Joining players, Jain index. C = 1 K = N log2 N . two graphs showresults two ways initializing strategy new player.C = 1, K = Nlog2N, join delay = converge init population = 0.25C = 1, K = Nlog2N, join delay = converge init population = 0.25, KPS50.8ConstantLinearWorstplayer4.5ConstantLinearWorstplayer0.70.63.5Group fairnessGroup fairness432.520.50.40.31.50.210.501020304050N0.101020304050N(a) Greedy(b) PoliteFigure 7: Joining players, group fairness. C = 1 K = N log2 N . two graphs showresults two ways initializing strategy new player.460fiDecentralized Anti-coordination Multi-agent LearningC = N/2, K = 2log2N, join delay = converge init population = 0.25C = N/2, K = 2log2N, join delay = converge init population = 0.25, KPS110.90.90.80.80.70.6Jain indexJain index0.70.50.40.30.50.40.30.20.2ConstantLinearWorstplayer0.1050.61015202530354045ConstantLinearWorstplayer0.150051015N20253035404550N(a) Greedy(b) PoliteFigure 8: Joining players, Jain index. C = N2 K = 2 log2 N . two graphs showresults two ways initializing strategy new player.players) divided average throughput first 25% players join networkbeginning (old players).Lets look first case players greedy. constant scheme,ratio around 4.5. linear scheme, ratio lower, although increasing N (thetotal number players) grows. worst-player-last scheme, ratio stays constantinterestingly, lower 1, means old players betternew players.players polite, situation opposite. Old players way betternew players. constant scheme, throughput ratio 0.2.Figures 8 9 show graphs C = N2 . Here, newly joining playersworse even start transmitting every slot.experience collision every time (because channels slots occupied), oldplayers experience collision probability N1 . hand, overall2fairness whole population better, channels shareagent use one channel.difference old new players even pronounced newplayers polite.6.2.2 Restarting PlayersAnother scenario looked happens one old players switchesreplaced new player randomly initialized strategy. sayplayer got restarted. wireless network, corresponds situation userrestarts router. Note number players network stays same,players forget learned start scratch.Specifically, every round, every player probability pRrestarted. restart, start strategy initialized two ways:461fiCigler & FaltingsC = N/2, K = 2log N, join delay = converge init population = 0.25C = N/2, K = 2log2N, join delay = converge init population = 0.25, KPS20.951ConstantLinearWorstplayer0.9ConstantLinearWorstplayer0.90.85Group fairnessGroup fairness0.80.80.750.70.60.50.650.40.60.5500.71020304050N01020304050N(a) Greedy(b) PoliteFigure 9: Joining players, group fairness. C = N2 K = 2 log2 N . two graphs showresults two ways initializing strategy new player.Greedy Assume player know N , number players system.signal value k K chooses randomly fi (k) C. meansattempts transmit every slot randomly chosen channel.Polite Assume player know N . k K, chooses fi (k) C probabilityCN , fi (k) := 0 otherwise.Figure 10 shows average overall throughput N = 32, C = 1, K = N log2 NK = N two initialization schemes. dotted line four graphs showsoverall performance players attempt transmit randomly chosen channelCprobability N. baseline solution reaches 1e 37% average throughput.probability restart increases, average throughput decreases. playersget restarted greedy, attempt transmit every slot.one channel available, means restarted player causes collision every slot.Therefore, surprising restart probability pR = 101 N = 32,throughput virtually 0: every step, expectation least one player get restarted,collision almost always.interesting phase transition occurs pR 104 K = N log2 N ,pR 103 K = N . There, performancebaseline random access scenario (that requires players know N though). Similarphase transition occurs players polite, even though resulting throughputhigher, since restarted players less aggressive.Yet another interesting, surprising, phenomenon worstplayer-last scheme still achieves highest throughput, constant back schemebetter linear back-off scheme. average overall throughput,matters fast players able reach perfect allocation disruption.worst-player-last scheme fastest, since resolves collision 1 step. con462fiDecentralized Anti-coordination Multi-agent LearningN = 32, C = 1, K = Nlog2N, KPS10.90.90.80.80.70.7System throughputSystem throughputN = 32, C = 1, K = Nlog2N10.60.50.40.30.20.1060.50.40.30.2ConstantLinearWorstplayer0.14100.610Restart probability0210ConstantLinearWorstplayer6(a) Greedy, K = N log2 N210N = 32, C = 1, K = N, KPS10.90.90.80.80.70.7System throughputSystem throughputN = 32, C = 1, K = N0.60.50.40.30.2010Restart probability(b) Polite, K = N log2 N10.14100.60.50.40.30.2ConstantLinearWorstplayer6100.1410Restart probability0210ConstantLinearWorstplayer610(c) Greedy, K = N410Restart probability(d) Polite, K = NFigure 10: Restarting players, throughput, N = 32, C = 1463210fiCigler & FaltingsN = 32, C = N/2, K = Nlog2N, KPS10.90.90.80.80.70.7System throughputSystem throughputN = 32, C = N/2, K = Nlog2N10.60.50.40.30.20.1060.50.40.30.2ConstantLinearWorstplayer0.14100.610Restart probability0210ConstantLinearWorstplayer6(a) Greedy, K = 2 log2 N10N = 32, C = N/2, K = 2, KPS10.90.90.80.80.70.7System throughputSystem throughputN = 32, C = N/2, K = 20.60.50.40.30.20210Restart probability(b) Polite, K = 2 log2 N10.14100.60.50.40.30.2ConstantLinearWorstplayer6100.1410Restart probability0210ConstantLinearWorstplayer610(c) Greedy, K = 24210Restart probability10(d) Polite, K = 2Figure 11: Restarting players, throughput, N = 32, C =N2stant scheme back-off probability p = 21 worse (see Theorem 12). linear schemeslowest.Figure 11 shows average overall throughput C = N2 , K = log2 N K = 2.substantial difference players greedy polite. Sincemany channels available, restarted player cause small number collisions(in one channel N2 every slot), throughput decrease much.Also, convergence time linear constant schemeC = N2 , adapt disruption equally well.6.2.3 Noisy Feedbackfar assumed players receive perfect feedback whether transmissionssuccessful not. could also observe activity given channel perfectly.going loosen assumption now.464fiDecentralized Anti-coordination Multi-agent LearningN = 32, C = N/2, K = Nlog2N10.90.90.80.80.70.7System throughputSystem throughputN = 32, C = 1, K = Nlog2N10.60.50.40.30.20.1060.50.40.30.2ConstantLinearWorstplayer100.60.1410Noisy feedback probability0210ConstantLinearWorstplayer610(a) C = 1, K = N log2 N410Noisy feedback probability(b) C =N2210, K = 2 log2 NFigure 12: Noisy feedback, throughput, N = 32N = 32, C = N/2, K = Nlog2N10.980.980.960.960.940.940.920.92Jain indexJain indexN = 32, C = 1, K = Nlog2N10.90.880.860.880.860.840.84ConstantLinearWorstplayer0.820.80.9610410Noisy feedback probability0.8210ConstantLinearWorstplayer0.82610(a) C = 1, K = N log2 N410Noisy feedback probability(b) C =N2210, K = 2 log2 NFigure 13: Noisy feedback, Jain index, N = 32Suppose every step, every player probability pF feedbackreceives wrong. is, player transmitted, learn transmissionsuccessful not, vice versa. player observed channel,learn channel free fact (and vice versa). contextwireless networks, corresponds interference wireless channel.affect learning?Figure 12 show average overall throughput C = 1 C = N2 respectively. one channel, constant scheme better linear scheme,adapts faster disruptions. C = N2 , schemes equivalent,equally fast adapt. phase transition occurs noisy feedback probabilitypF = 102 .465fiCigler & FaltingsN = 32, C = N/2, K = Nlog2N10.90.90.80.80.70.7System throughputSystem throughputN = 32, C = 1, K = Nlog2N10.60.50.40.30.20.100.60.50.40.30.2ConstantLinearWorstplayer6100.1410Noisy signal probability0210ConstantLinearWorstplayer610(a) C = 1, K = N log2 N410Noisy signal probability(b) C =N2210, K = 2 log2 NFigure 14: Noisy coordination signal, throughput, N = 32Figure 13 shows Jain index allocation players receive noisy feedback.usual, linear scheme better constant, even though throuput lower (asshown above). overall throughput drops close 0, schemesobviously almost fairness.6.2.4 Noisy Coordination Signalalgorithm assumes players observe coordination signal everystep. signal come from? may random noise givenfrequency, FM radio transmission etc. However, coordination signal might noisy,different players observe different value. means learning wouldsync. wireless networks, corresponds clock drift.see happens case, use following experiment. every step,every player observes correct signal (i.e. one observed everyone else)probability 1 pS . probability pS observes false signal (that stilltaken uniformly random set {0, ..., K 1}).overall throughput shown Figure 14. see system ablecope fairly high level noise signal, drop throughput occurspS = 101 . case experiments noisy feedback, constant back-offscheme able achieve higher throughput thanks faster convergence.Jain index allocation (Figure 15) stays almost constant,throughput drops Jain index increases. allocation random, alsofair.6.3 Generic Multi-agent Learning AlgorithmsSeveral algorithms proved converge correlated equilibrium proposed multi-agent learning literature. Introduction, mentioned threelearning algorithms (Foster & Vohra, 1997; Hart & Mas-Colell, 2000; Blum & Man466fiDecentralized Anti-coordination Multi-agent LearningN = 32, C = N/2, K = Nlog2N10.980.980.960.960.940.940.920.92Jain indexJain indexN = 32, C = 1, K = Nlog2N10.90.880.860.880.860.840.84ConstantLinearWorstplayer0.820.80.9610410Noisy signal probability0.8210ConstantLinearWorstplayer0.82610(a) C = 1, K = N log2 N410Noisy signal probability(b) C =N2210, K = 2 log2 NFigure 15: Noisy coordination signal, Jain index, N = 32sour, 2007). However, analysis Foster Vohra applicable games twoplayers. section, briefly recall two multi-agent learning algorithms(Hart & Mas-Colell, 2000; Blum & Mansour, 2007), compare performancealgorithm presented Section 3.two algorithms compare algorithm based notion minimizing regret agents experience adopting certain strategy. Intuitively,describe concept regret follows: Imagine agent uses strategy couplerounds game, accumulates certain payoff. would like knowpayoff compare payoff acquired simple alternative strategy . difference payoff strategy regret agent perceives (ex-post)choosing strategy strategy .mean simple strategy? One class simple strategies strategiesalways select action. external regret compares performancestrategy performance best single action ex-post.Another class alternative strategies strategies modify strategy slightly.Every time strategy proposes play action a, alternative strategy proposesaction a0 6= instead. internal regret defined regret strategy comparedbest alternative strategy. agents adopt strategy low internalregret, converge strategy profile close correlated equilibrium (alsoshown Blum & Mansour, 2007).Hart Mas-Colell (2000) present simple multi-agent learning algorithmguaranteed converge correlated equilibrium. assume playersobserve actions opponents every round game. Players startchoosing actions randomly. update strategy follows: Let aiaction player played round t1. action aj Ai , aj 6= ai , player calculatesdifference average payoff would received played action ajinstead ai past, average payoff received far playing action ai .mentioned above, call difference internal regret playing action ai467fiCigler & FaltingsC = N/2C=1310Constant backoffHartMasColellBlumMansourConstant backoffHartMasColellBlumMansour3Convergence stepsConvergence steps1021021011011051015N2025(a) C = 151015N(b) C =2025N2Figure 16: General multi-agent learning algorithms, convergence rate.instead action aj . player chooses action play round probabilityproportional internal regret compared previous action ai . Actions negativeregret never played. previous action ai played positive probabilityway, strategy certain inertia.Hart Mas-Colell (2000) prove agents adopt adaptive procedure described above, empirical distribution play (the relative frequency playingcertain pure strategy profile) converges almost surely set correlated equilibria.Blum Mansour (2007) present general technique convert learning algorithmlow external regret algorithm low internal regret. idea runmultiple copies external regret algorithm. step, copy returns probabilityvector playing action. probability vectors combined one jointprobability vector. player observes payoff playing action, updatespayoff beliefs external regret algorithms proportionally weightjoint probability vector. authors show players use learningalgorithm low internal regret, empirical distribution game converges closecorrelated equilibrium.One low-external-regret algorithms Blum Mansour (2007) presentPolynomial Weights (PW) algorithm. There, player keeps weightactions. every round game, updates weight proportionally loss(negative payoff) action incurred round. Actions higher weight getchosen higher probability.implemented two generic multi-agent learning algorithms: internalregret-based algorithm Hart Mas-Colell (2000), PW algorithm BlumMansour (2007). experiments, algorithms always converge pure-strategyNash equilibrium channel allocation game, therefore efficient allocation.However, resulting allocation fair, subset agents size C everaccess channels.468fiDecentralized Anti-coordination Multi-agent LearningC = N/210.90.90.80.80.70.70.60.6Jain indexJain indexC=110.50.40.30.40.30.20.2Constant backoffHartMasColellBlumMansour0.1050.51015N20Constant backoffHartMasColellBlumMansour0.125(a) C = 1051015N(b) C =2025N2Figure 17: General multi-agent learning algorithms, Jain index.Figure 16 shows average number rounds algorithms take convergestable outcome. compare performance learning algorithm Section 3.learning algorithm, set K = 1, also converges pure-strategyNash equilibrium game. performed 128 runs algorithm scenario.error-bars Figure 16 show 95% confidence interval average, assumingconvergence times distributed according normal distribution.surprisingly, generic algorithms Hart Mas-Colell (2000) BlumMansour (2007) cannot match convergence speed algorithm, designed specificallyproblem channel allocation. generic algorithms converge pure-strategyNE, outcome unfair, Jain index low, evidenced Figure 17.dont report confidence bounds Jain index, experimentsresulting Jain index same.7. Related WorkBroadly speaking, paper interested games payoff agent receivescertain action inversely proportional number agents choseaction. achieve efficient fair outcome games? Variantsproblem studied several previous works.simplest variant Minority game (Challet, Marsili, & Zhang, 2005).game, N agents simultaneously choose two actions. Agents choseaction chosen minority agents receive payoff 1, whereas agents whoseaction choice majority receivepayoff 0. game many pure-strategy Nashequilibria, group N 21 agents chooses one action rest chooseaction. equilibria efficient, since largest possible number agents achievemaximum payoff. However, fair: payoff losing group agentsalways 0. game also one mixed-strategy NE fair: every agent chooses469fiCigler & Faltingsaction randomly. equilibrium,hand, efficient: expected sizeminority group lower N 21 due variance action selection.Savit, Manuca, Riolo (1999) show agents receive feedback actionminority, learn coordinate better achieve efficient outcomerepeated minority game. basing agents decisions historypast iterations. Cavagna (1999) shows result achieved agentsbase decisions value random coordination signal instead usinghistory. direct inspiration idea global coordination signal presentedpaper.ideas literature Minority games recently found waycognitive radio literature. Mahonen Petrova (2008) present channel allocationproblem much like ours. agents learn channel use using strategysimilar strategies minority games. difference instead preferringaction chosen minority, channel allocation problem, agent prefers channelschosen anyone else. Using approach, Mahonen Petrova ableachieve stable throughput 50% even number agents trytransmit channel increases. However, agent essentially choosing onefixed set strategies, cannot adapt. Therefore, difficult achieveperfectly efficient channel allocation.Wang et al. (2011) implemented algorithm work actual wirelessnetwork. setting, wireless devices able monitor activity channels.coordination signal, used actual data packets agents send.authors shown practice, learning algorithm (which call attachmentlearning) improves throughput 2-3 random access slotted ALOHA protocol.Another, general variant problem, called dispersion game describedGrenager, Powers, Shoham (2002). dispersion game, agents choose severalactions, prefer one chosen smallest number agents.authors define maximal dispersion outcome outcome agent moveaction fewer agents. set maximal dispersion outcomes corresponds setpure-strategy Nash equilibria game. propose various strategies convergemaximal dispersion outcome, different assumptions information availableagents. contrary work, individual agents dispersion gamesparticular preference actions chosen equilibriaachieved. Therefore, issues achieving fair outcome.Verbeeck, Nowe, Parent, Tuyls (2007) use reinforcement learning, namely linearreward-inaction automata, learn Nash equilibria common conflicting interestgames. class conflicting interest games (to channel allocation gamebelongs), propose algorithm allows agents circulate variouspure-strategy Nash equilibria, outcome game fair. contrastwork, solution requires communication agents, requiresagents know strategies converged. addition, linear reward-inaction automataguaranteed converge pure-strategy NE conflicting interest games;may converge pure strategies.games discussed above, including channel allocation game, form partfamily potential games introduced Monderer Shapley (1996). game called470fiDecentralized Anti-coordination Multi-agent Learningpotential game admits potential function. potential function defined everystrategy profile, quantifies difference payoffs agent unilaterally deviatesgiven strategy profile. different kinds potential functions: exact (wheredifference payoffs deviating agent corresponds directly differencepotential function), ordinal (where sign potential differencesign payoff difference) etc.Potential games several nice properties. important purestrategy Nash equilibrium local maximum potential function. finitepotential games, players reach equilibria unilaterally playing best-response,matter initial strategy profile start from.existence natural learning algorithm reach Nash equilibria makes potentialgames interesting candidate future research. would like see kindcorrelated equilibria agents converge there, use simple correlationsignal coordinate.8. Conclusionspaper, proposed new approach reach efficient fair solutions multi-agentresource allocation problems. Instead using centralized, smart coordination devicecompute allocation, use stupid coordination signal, general random integerk {0, 1, . . . , K 1}, priori relation problem. Agents smart:learn, value coordination signal, action take.game-theoretic perspective, ideal outcome game correlated equilibrium. results show using global coordination signal, agents learn playconvex combination pure-strategy Nash equilibria, correlated equilibrium.showed learning strategy that, variant channel allocation game, converges expected polynomial number steps efficient correlated equilibrium.also proved equilibrium becomes increasingly fair K, number availablesynchronization signals, increases.confirmed fast convergence well increasing fairness increasing Kexperimentally. also investigated performance learning strategy caseagent population dynamic. new agents join population, learning strategystill able learn efficient allocation. However, fairness allocation dependgreedy initial strategies new agents are. agents restart randomintervals, becomes important fast strategy converges. simple strategyeveryone backs transmitting constant probability able achieve higherthroughput sophisticated strategy back-off probability dependsmany slots agent already transmitting. also showed experimentallylearning strategy robust noise coordination signal, wellfeedback agents receive channel use. noisy scenarios, faster convergence constant back-off scheme helped achieve higher throughputfair linear back-off scheme. Finally, compared performance learning strategy generic multi-agent learning algorithms based regret-minimization (Hart &Mas-Colell, 2000; Blum & Mansour, 2007). generic algorithms theoreticallyproven converge distribution play close correlated equilibrium,471fiCigler & Faltingsguaranteed converge specific CE. Indeed, experiments, algorithmsHart Mas-Colell Blum Mansour always converged efficient unfairpure-strategy Nash equilibrium channel allocation game.learning algorithm presented paper implemented real wirelessnetwork Wang et al. (2011), shown achieves 2-3 higher throughputrandom access protocols ALOHA.paper, address issue whether non-cooperative rationalagents would follow protocol outlined. work (Cigler & Faltings, 2012),address issue show certain conditions, protocol implementedNash equilibrium strategies infinitely repeated resource allocation game.ReferencesAbramson, N. (1970). ALOHA system: another alternative computer communications. Proceedings November 17-19, 1970, fall joint computer conference,AFIPS 70 (Fall), pp. 281285, New York, NY, USA. ACM.Aumann, R. (1974). Subjectivity correlation randomized strategies. JournalMathematical Economics, 1 (1), 6796.Billingsley, P. (2012). Probability Measure (Wiley Series Probability Statistics)(Anniversary Edition edition). Wiley.Blum, A., & Mansour, Y. (2007). Algorithmic game theory. Nisan, N., Roughgarden,T., Tardos, E., & Vazirani, V. (Eds.), Algorithmic Game Theory, chap. 4. CambridgeUniversity Press.Cavagna, A. (1999). Irrelevance memory minority game. Physical Review E, 59 (4),R3783R3786.Challet, D., Marsili, M., & Zhang, Y.-C. (2005). Minority Games: Interacting AgentsFinancial Markets (Oxford Finance). Oxford University Press, New York, NY, USA.Chen, X., & Deng, X. (2006). Settling complexity Two-Player nash equilibrium.2006 47th Annual IEEE Symposium Foundations Computer Science (FOCS06),pp. 261272. IEEE.Cheng, S., Raja, A., Xie, L., & Howitt, I. (2009). distributed constraint optimization algorithm dynamic load balancing wlans. IJCAI-09 Workshop DistributedConstraint Reasoning (DCR).Cigler, L., & Faltings, B. (2012). Symmetric subgame perfect equilibria resource allocation. (to appear) Proceedings 26th national conference Artificialintelligence (AAAI-12), Menlo Park, CA, USA. American Association ArtificialIntelligence.Feller, W. (1968). Introduction Probability Theory Applications, Vol. 1, 3rdEdition (3 edition). Wiley.Foster, D. P., & Vohra, R. V. (1997). Calibrated learning correlated equilibrium. GamesEconomic Behavior, 21 (1-2), 4055.472fiDecentralized Anti-coordination Multi-agent LearningGast, N. (2011). Computing hitting times via fluid approximation: application couponcollector problem. ArXiv e-prints.Grenager, T., Powers, R., & Shoham, Y. (2002). Dispersion games: general definitionsspecific learning results. Proceedings Eighteenth national conferenceArtificial intelligence (AAAI-02), pp. 398403, Menlo Park, CA, USA. AmericanAssociation Artificial Intelligence.Hart, S., & Mas-Colell, A. (2000). simple adaptive procedure leading correlated equilibrium. Econometrica, 68 (5), 11271150.Jain, R. K., Chiu, D.-M. W., & Hawe, W. R. (1984). quantitative measure fairnessdiscrimination resource allocation shared computer systems. Tech. rep., DigitalEquipment Corporation.Leyton-Brown, K., & Shoham, Y. (2008). Essentials Game Theory: Concise, Multidisciplinary Introduction. Morgan & Claypool, San Rafael, CA.Littman, M., & Stone, P. (2002). Implicit negotiation repeated games intelligent agentsVIII. Meyer, J.-J., & Tambe, M. (Eds.), Intelligent Agents VIII, Vol. 2333 LectureNotes Computer Science, chap. 29, pp. 393404. Springer Berlin / Heidelberg,Berlin, Heidelberg.Mahonen, P., & Petrova, M. (2008). Minority game cognitive radios: Cooperating without cooperation. Physical Communication, 1 (2), 94102.Monderer, D., & Shapley, L. S. (1996). Potential games. Games Economic Behavior,14 (1), 124 143.Norris, J. R. (1998). Markov Chains (Cambridge Series Statistical ProbabilisticMathematics). Cambridge University Press.Papadimitriou, C. H., & Roughgarden, T. (2008). Computing correlated equilibria multiplayer games. Journal ACM, 55 (3), 129.Rego, V. (1992). Naive asymptotics hitting time bounds markov chains. Acta Informatica, 29 (6), 579594.Savit, R., Manuca, R., & Riolo, R. (1999). Adaptive competition, market efficiency,phase transitions. Physical Review Letters, 82 (10), 22032206.Verbeeck, K., Nowe, A., Parent, J., & Tuyls, K. (2007). Exploring selfish reinforcementlearning repeated games stochastic rewards. Autonomous Agents MultiAgent Systems, 14 (3), 239269.Wang, L., Wu, K., Hamdi, M., & Ni, L. M. (2011). Attachment learning multi-channelallocation distributed OFDMA networks. Parallel Distributed Systems, International Conference on, 0, 520527.473fiJournal Artificial Intelligence Research 47 (2013) 281-311Submitted 10/12; published 6/13Sharing Rewards Cooperative Connectivity GamesYoram Bachrachyobach@microsoft.comMicrosoft Research, Cambridge, UKEly Poratporately@cs.biu.ac.ilBar-Ilan University, Ramat-Gan, IsraelJeffrey S. Rosenscheinjeff@cs.huji.ac.ilHebrew University, Jerusalem, IsraelAbstractconsider selfish agents likely share revenues derived maintainingconnectivity important network servers. model network failureone node may disrupt communication nodes cooperative game calledvertex Connectivity Game (CG). game, agent owns vertex, controlsedges going vertex. coalition agents wins fully connectscertain subset vertices graph, called primary vertices.Power indices measure agents ability affect outcome game. showdomain, indices used determine fair sharerevenues agent entitled to, identify significant possible points failure affectingreliability communication network. show general graphs, calculatingShapley Banzhaf power indices #P-complete, suggest polynomial algorithmcalculating trees.also investigate finding stable payoff divisions revenues CGs, capturedgame theoretic solution core, relaxations, -core least core.show polynomial algorithm computing core CG, show testingwhether imputation -core coNP-complete. Finally, show trees,possible test -core imputations polynomial time.1. Introductionkey aspect multi-agent systems focus research field agentcollaboration. Cooperative game theory considers cooperation among self interested agents,used analyze many collaborative domains (Goldman & Zilberstein, 2004;Kraus, Shehory, & Taase, 2004; Branzei, Dimitrov, & Tijs, 2008; Dunne, van der Hoek,Kraus, & Wooldridge, 2008; Chalkiadakis, Elkind, & Wooldridge, 2012). One importantapplication area multi-agent systems network analysis, examining issues rangingcommunication network design (Babaoglu, Meling, & Montresor, 2002), sensornetwork technologies (Lesser, Ortiz, & Tambe, 2003) social network analysis (Sabater &Sierra, 2002). Game theory already used analyze interaction selfishagents various network settings, network security (Roy, Ellis, Shiva, Dasgupta,Shandilya, & Wu, 2010; Jain, Korzhyk, Vanek, Conitzer, Pechoucek, & Tambe, 2011),resource sharing (Suris, DaSilva, Han, & MacKenzie, 2007) agent cooperation communication networks (Saad, Han, Debbah, Hjorungnes, & Basar, 2009; Easley & Kleinberg,2010).c2013AI Access Foundation. rights reserved.fiBachrach, Porat, & RosenscheinConsider computer network servers controlled selfish agents,principal interested allowing communication certain set critical servers.allow connectivity, principal incentivize agents allow communicationoffering certain reward. agents must cooperate allow reliablecommunication critical servers, every single agent controls small partentire network.1.1 Key Questions Game Theoretic SolutionsGiven setting, several key questions arise. First, reward promisedentire group agents, must decide allocate reward amongst themselves.Even agents form successful team, team may stable, agentsallocated small part reward may try form different coalition,increase share reward. Could agents reach agreement sharingrewards would prevent deviations? Second, fair shareagent get? measure importance individual agent bringingdesired outcome communication critical servers?Cooperative game theory provides answers questions regarding reward sharing selfish agents, form solution concepts. solution concepts,core relaxations (Gillies, 1953; Shapley & Shubik, 1966) focus stability, whereasconcepts power index proposed Banzhaf (1965) Shapley value (1953,1954) focus fairness.Power indices originated work analyzing power voting scenarios. Researchersanalyzing distribution power decision making bodies tried find preciseway measuring influence single agent context team agentsattempt reach joint decision voting procedure. formalizedmeasures influence so-called power indices, measure control voterdecisions larger group (Elkind, Goldberg, Goldberg, & Wooldridge, 2007b).two prominent indices Banzhaf power index (1965) ShapleyShubik power index (1954). indices characterized using set axiomsdescribe desirable properties measure power voting contexts (Lehrer, 1988;Shapley, 1953; Dubey & Shapley, 1979; Straffin, 1988). Shapley-Shubik power indexmanifestation Shapley value (1953) designed find fair shareagent team agents must cooperate achieve joint reward. Althoughindices mostly used measuring power voting systems, easilyadapted domains well.paper, consider use power indices find fair ways agentsshare rewards network setting described above. Further, show powerindices used find key points failure communication network. modelcommunication network setting, consisting servers network linksconnecting them, vertex connectivity game. network modeled graph,servers vertices, network links edges. certain subsetservers (vertices) primarya failure send information twowould constitute major system failure. Another subset servers always available(backbone servers).282fiSharing Rewards Cooperative Connectivity Gamesvertex Connectivity Game (CG) introduce, agent controls differentvertex graph. coalition agents use vertices controlledcoalition members backbone vertices, may send information them.coalition wins connects primary vertices, send informationtwo them. power index agent game reflects criticalitymaintaining connectivity. index used determine fair share totalreward agent get, could enable administrator identify potentialcritical points failure network (perhaps, example, focusing maintenanceresources preventing failure).consider computational complexity calculating Banzhaf Shapley-Shubikpower indices domain. show general graphs, computing eitherindices #P-complete problem. Despite negative result, provide polynomialalgorithm restricted case graph tree. Many networks, including partsinternets backbone, constructed trees construction communicationline expensive, algorithm analyze important real-world domains.turn finding stable payoff distributions collaborating agents, usinggame theoretic solution concept core (Gillies, 1953). show corecomputed polynomial time CGs. coalition CG manages connectprimary vertices, wins gains certain profit. profit dividedamong members coalition. Choosing payoff vector core guaranteessubcoalition would choose split main coalition, attempt establishnetwork. Thus, core indicates payoff vectors stable allows allocatinggains coalition CG domain prevent subcoalitions defecting.also consider relaxed solution concepts -core least core (Shapley& Shubik, 1966), show testing -core imputations coNP-complete CGs.-core imputations, although coalition may completely stable, incentivesubcoalition deviate low. Finally, show tree CGs, core leastcore coincide.paper proceeds follows. Section 2, provide background information regarding coalitional games power indices, fully define vertex connectivity game(CG). Section 3 examine game theoretic solutions CGs. Section 3.1 discussesfair reward distributions CGs using power indices, presents hardness resultgeneral case polynomial algorithm restricted case trees. Section 3.2examines stable reward distributions. shows core CGs computedpolynomial time, discusses complexity -core least-core-related problems,examines core-related problems tree CGs. Section 4 examines related work, discussingprevious work solutions cooperative games (Section 4.1) related modelscooperative games networks (Section 4.2). conclude Section 5.2. Preliminariescoalitional game composed set n agents, = (a1 , . . . , ), functionmapping subset (coalition) agents real value v : 2I R. function vcalled coalitional function (or sometimes characteristic function) game.simple coalitional game, v gets values 0 1, v : 2I {0, 1}. coalition283fiBachrach, Porat, & RosenscheinC wins v(C) = 1, loses v(C) = 0. set winning coalitions denotedW (v) = {C 2I |v(C) = 1}. agent ai critical winning coalition C agentsremoval coalition would make coalition lose: v(C) = 1 v(C \ {i}) = 0.Thus, agent critical coalition contains it.interested finding fair share rewards agent getcooperative game, measuring influence given agent result game.Game theoretic solutions include various values power indices. twoprominent values Banzhaf power index (1965) Shapley value (1953).indices characterized using slightly different sets fairness axioms,reflect desired properties power index. indices propertydummy agents, never affect value coalition, obtain index zero (the nullplayer axiom). Similarly, Shapley value Banzhaf index, equivalentagents, increase value coalition contains neitheramount, index (the symmetry axiom). However, two indices behave differently regarding composition two games set agents.1 Alternatively,indices interpreted probability agent would significantly affectoutcome game, slightly different models uncertainty regarding agentsparticipation game (Straffin, 1988). Although power indices widely usedmeasuring political power weighted voting systems, definition relyspecific features voting domain.Banzhaf index depends number coalitions agent critical.Agent ai marginal contribution coalition C ai C defined v(C) v(C \{ai }). Thus ai critical C marginal contribution 1 it, aicritical C marginal contribution 0. Banzhaf index agent aiaverage marginal contribution coalitions contain , equivalentlyproportion coalitions critical coalitions contain i.Definition 1. Banzhaf index vector (v) = (1 (v), . . . , n (v))(v) =12n1X[v(C) v(C \ {ai })].CN |ai CShapley value (1953), sometimes referred Shapley-Shubik powerindex (1954) applied simple cooperative game, relies notion marginalcontribution agent permutation. amount additional utility generatedagent joins coalition predecessors permutation. denote1. Given two games u, v agent set, define game u + v value coalitionC game u + v sum values composing games u + v(C) = u(C) + v(C).also define max game u v value coalition composed game u v maximalvalue composing games, u v(C) = max(u(C), v(C)). Similarly define min gameu v, u v(C) = min(u(C), v(C)). Shapley value fulfills linear decomposition axiom:Shapley value agent sum game u + v sum Shapley values composinggames u v. contrast, Banzhaf index fulfills property regarding max min games,sum powers two games sum powers max min games. relatedwork examines fairness axioms Shapley value Banzhaf index (Dubey & Shapley, 1979;Straffin, 1988; Lehrer, 1988; Holler & Packel, 1983; Laruelle & Valenciano, 2001).284fiSharing Rewards Cooperative Connectivity Gamespermutation n agents, : {1, . . . , n} {1, . . . , n} onto.denote Sn set agent permutations. Denote predecessors ai, = {aj |(j) < (i)}. Agent ai marginal contribution permutationmi = v(i {ai })v(i ). Note simple game agent marginal contribution1 permutation iff critical coalition {ai }. Shapley valueagent marginal contribution averaged across possible agent permutations.Definition 2. Shapley value vector (1 (v), . . . , n (v))(v) =1 X1 Xmi =(v (i {i}) v (i ))n!n!SnSnShapley value Banzhaf index thought expected marginalcontribution agent certain assumptions coalition formation process.Shapley value reflects assumption agents randomly added coalition,every ordering agents equally probable. contrast, Banzhaf index reflectsassumption coalitions equally probable. generally, power indicesviewed probabilities events weighted voting domains (Straffin, 1988).hardness result calculating power indices CGs considers class #P. #Pset integer-valued functions express number accepting computationsnondeterministic Turing machine polynomial time complexity. Let finite inputoutput alphabet Turing machines.Definition 3. #P class consisting functions f : N existsnon-deterministic polynomial time Turing machine inputs x , f (x)number accepting paths M.complexity classes #P #P-complete introduced Valiant (1979a).classes express hardness problems count number solutions.2coalitional function v describes total utility coalition achieve,define agents distribute utility among themselves. imputation (p1 , . . . , pn ),sometimes also called payoff vector, Pdivision gains grand coalitionamong agents, pi R, ni=1 pi = v(I).P call pi payoff agent ai ,denote payoff coalition C p(C) = i{j|aj C} pi . assumption, agentsrational attempt maximize share utility. Game theory offersseveral solution concepts, determining imputations likely occur agentsact rationally.Shapley value shown imputation, values individualsum value grand coalition agents:Pn agents shown3 Given fairness axioms Shapley value fulfills, thus(v)=v(I).i=12. Informally, NP NP-hardness deal checking least one solution combinatorial problemexists, #P #P-hardness deal calculating number solutions combinatorialproblem. Counting number solutions problem least hard determiningleast one solution, #P-complete problems least hard (but possibly harder) NP-completeproblems; complexity classes thoroughly investigated computation complexity researchers (Papadimitriou, 2003; Valiant, 1979b; Papadimitriou & Zachos, 1982).3. Shapley provided proof fact seminal paper Shapley value (1953).285fiBachrach, Porat, & Rosenscheinviewed fair imputation. However, many domains agents selfish carelittle fairness. Rather, selfish agents likely interested abilityimprove utility forming alternative coalitions. Stability based solution conceptscore focus deviations (Gillies, 1953).basic stability requirement imputation individual rationality: agentsai C, pi v({ai }), otherwise agent better own. Similarly, saycoalition B blocks imputation (p1 , . . . , pn ) p(B) < v(B), since membersB would split coalition gain utility without rest agents.blocked imputation chosen, coalition unstable. possible define degreesubcoalition incentivized deviate grand coalition.Definition 4. Given imputation p = (p1 , . . . , pn ), excess coalition e(C) =v(C) p(C), quantifies amount subcoalition C gain deviatingworking own.Given imputation, coalition C blocking iff excess strictly positive e(C) > 0.blocked payoff vector chosen, coalition unstable, higher excessis, incentivized agents split apart current coalition formcoalition. known solution concept emphasizes stability core (Gillies,1953).Definition 5. Core coalitional game set payment vectors (p1 , . . . , pn )blocked coalition, coalition C p(C) v(C).value distribution core makes sure subset agents would split off,coalition stable. general core empty, every possible value divisionblocked coalition. paper, give results regarding computing corevertex connectivity games. core empty (i.e., every possible value divisionblocked coalition), sometimes make sense relax requirementssolution concept. domains, splitting apart current coalition structureform alternative coalition might costly process. cases, coalitionssmall incentive split apart grand coalition would so. relaxedsolution concept embodying intuition -core (Shapley & Shubik, 1966).-core slightly relaxes inequalities Definition 5.Definition 6. -core set imputations (p1 , . . . , pn ) followingholds: coalition C I, p(C) v(C) .imputation -core, excess e(C) = v(C) p(C) coalition C. large enough values , -core guaranteed non-empty.obvious problem find smallest value makes -core non-empty.solution concept known least core. Formally, consider game G set{|the -core G empty}. set compact,4 minimal element min .Definition 7. least core game G min -core G.4. formal formal definition compactness implications found many introductorybooks topology (Royden & Fitzpatrick, 1988).286fiSharing Rewards Cooperative Connectivity GamesImputations least core distribute payoffs minimizing worst deficit.words, least core minimizes maximal incentive coalition split apartgrand coalition. least core imputation, coalition gainmin deviating, < min impossible distribute payoffs waycauses deficit coalition . Another solution concept, callednucleolus (Schmeidler, 1969) refines least core, minimizing number coalitionsmaximal excess examining sorted vector excesses defininglexicographical order them.2.1 Connectivity GamesConsider network connecting various servers, certain subset serversdesignated primary servers. goal make sure send informationtwo primary servers. server network may malfunction, does,cannot send information it. paths two primary servers gofailed server, cannot send information two primary servers.model, also assume certain subset servers guaranteednever fail (guaranteed, say, heavy maintenance fail-safe backup); callbackbone servers.Section 1.1 discussed several questions regarding agreements selfish agentslikely reach controls server network. modelnetwork domain cooperative game use game theoretic solutions answerquestions. coalitional game heart model called vertex ConnectivityGame.Definition 8. vertex Connectivity Game Domain (CGD) consists graph G = hV, Eivertices partitioned primary vertices Vp V , backbone vertices Vb V ,standard vertices Vs V . require Vp Vb = , Vb Vs = , Vp Vs = ,V = Vp Vb Vs , indeed partition.Given CGD, define vertex Connectivity Game. game, agentcontrols one standard servers. coalition wins connects pairs primaryvertices (so send information two primary servers). Let |Vs | = n,consider set n agents = (a1 , . . . , ), agent ai controls vertex vi Vs . Givencoalition C denote set vertices C controls V (C) = {vi Vs |ai C}.Coalition C use either vertices V (C) always-available backbone verticesVb . model, assume coalition also use primary vertices Vpwell.5say set vertices V V fully connects Vp two vertices u, v Vppath (u, p1 , p2 , . . . , pk , v) u v going vertices V ,pi V .5. Another possibility would allow primary vertices want connect fail (this mayoccur, example, network security domains, external attacks may target key serversnetwork). case coalition would win manages connect non-failed primary vertices.could also disallow sending information primary vertices (so finaldestination). results paper hold different settings well.287fiBachrach, Porat, & RosenscheinDefinition 9. vertex Connectivity Game (CG) simple coalitional game,value coalition C defined follows:(1 V (C) Vb Vp fully connects Vpv(C) =0 otherwise3. Solutions Connectivity GameSection 1.1 raised several questions regarding agreements selfish agents likelyreach controls server network. answer questionsapplying game theoretic solutions Connectivity Game.begin characterizing fair payoff distribution measuring agents importanceallowing reliable network communication. Specifically, given desire ensure communication paths primary vertices, servers network critical?agents deserve higher share reward? Given limited resources make sureservers fail (i.e., making backbone servers), verticesconcentrate ensure communication primary servers? Section 3.1 answersquestions using power indices.continue examining stable allocations rewards. determinewhether agreement sharing rewards would incentivize sub-coalition agentsdefect? agreement fully-resistant deviations, find stableagreement? Section 3.2.1 answers questions using core core-related solutions.3.1 Network Reliability Fair Reward DistributionCG Definition 9 characteristic function maps every coalition fullyconnects primary vertices single unit reward (and indicates coalitions reward zero). Section 2 discussed fairness axiomsShapley value Banzhaf index fulfill. Due properties, applyconcepts CGs, obtain fair distribution reward games. example,dummy servers, affect ability coalition allow full connectivity,would power index zero, obtain reward. Similarly, equivalent agents,impact achieving connectivity added coalition, would obtainreward. agents forming coalition wish share rewards fairmanner, power indices thus make excellent basis forming agreement,6 highlightingneed examine computational aspects calculating indices,section.emphasize beyond fulfilling fairness properties, power indices alsoviewed network reliability constructs. model based simple network goalallowing communication two primary servers. network reliabilityview, want identify servers which, failing, cause us lose connectivity6. specific index used depends agents notion fairness. Different sets axioms resultdifferent indices (Dubey & Shapley, 1979; Straffin, 1988; Holler & Packel, 1983; Laruelle & Valenciano,2001).288fiSharing Rewards Cooperative Connectivity Gamesprimary servers. Suppose servers equal probability workingfailing next day (i.e. probability 50% fail, probability 50%work). failures independent, subset servers equal chancesurviving (regardless size). Thus, certain probabilitysurviving set servers fully connect primary servers. Suppose make sureexactly one server, owned agent ai , always survives. Banzhaf power index measuresincrease probability surviving subset vertices fully connectprimary servers guaranteeing vi survives.attempting maximize probability achieving goal, higherBanzhaf index server is, try make sure serverfail. Thus, order find significant points failure, calculate Banzhaf powerindex, focus servers highest indices.7consider computational complexity calculating power indices generalvertex connectivity games. first formally define problems.Definition 10. CG-BANZHAF / CG-SHAPLEY: given CG graph G =hV, Ei, primary vertices Vp V , backbone vertices Vb V , standard verticesVs V . n = |Vs | agents, = (a1 , . . . , ), agent ai controls vertex vi Vs .games coalitional function v : 2I {0, 1} defined Definition 9. alsogiven specific target agent ai . CG-BANZHAF asked calculate Banzhafpower index game, (v). Similarly, CG-SHAPLEY problem askedcalculate Shapley value, (v).show general CGs, CG-BANZHAF CG-SHAPLEY #Pcomplete. first prove problems #P. reduce #SET-COVER problemCG-BANZHAF. obtain #P-hardness CG-SHAPLEY corollary.begin definitions.Definition 11. #SET-COVER (#SC): given collection C = {S1 , . . . , Sn }subsets. denote Si C Si = S. set cover subset C C Si C = S.asked compute number covers S.slightly different version requires finding number set covers size k:Definition 12. #SET-COVER-K (#SC-K): set-cover size k set cover C|C | = k. Definition 11, given C target size k, askedcompute number covers size k.#SC #SC-K #P-hard. Garey Johnson (1979) showed #SC-K#P-hard: considered several basic NP-complete problems, showedcounting versions #P-complete. counting version SET-COVER discussed#SC-K. #VERTEX-COVER restricted form #SC. Vadhan (2002) showed#VERTEX-COVER #P-hard,8 #SC also #P-hard. use #SC proveCG-BANZHAF #P-hard. easy show #SC-K #P-complete, fact7. Similarly, uncertainty order agent failures, Shapley value reflectsimportance vertices regard network reliability.8. also showed problem remains #P-hard even restricted classes graphs.289fiBachrach, Porat, & Rosenschein#SC #P-complete difficult prove (and thus well known).give definitions #SC #SC-K avoid confusion them, useVadhans result (2002) indicates #SC #P-complete. Using this, reducing#SC CG-BANZHAF show CG-BANZHAF #P-complete.order show CG-BANZHAF #P-complete need show two things:first, CG-BANZHAF #P, second, reduction #P-hard problemCG-BANZHAF.Lemma 1. CG-BANZHAF CG-SHAPLEY #P.Proof. Banzhaf index ai CG v (v), proportion coalitions aicritical, coalitions contain ai . Given certain coalition C I,polynomial check whether winswe need check whether V (C) Vb fullyconnects Vp . creating new graph G , dropping edges missV (C) Vb G (i.e., drop edge (x, y) E either x/ V (C) Vb/ V (C) Vb ). check two primary vertices G connected (thereseveral polynomial algorithms this; simple one run depth-first search (DFS)pairs primary vertices). thus easily test certain agent ai criticalcoalition: perform test coalition, remove him,repeat test. first test succeeds second fails, agent criticalcoalition. Similarly, test whether agent ai critical agent permutationpolynomial time: simply test whether ai predecessors form losing coalitionwhether {ai } form winning coalition (we using test).Since construct deterministic polynomial Turing machine testsagent critical coalition, construct non-deterministic Turing machine ,first non-deterministically chooses coalition ai member of, testsai critical coalition. number accepting paths numbercoalitions contain ai ai critical. Denote k number acceptingpaths , denote |I| = |Vs | = n. Banzhaf power index agent aik.(v) = 2n1Calculating numerator (v) thus, according Definition 3, problem #P.Since denominator constant (given domain n agents), CG-BANZHAF#P. similar argument using non-deterministic generation permutations insteadcoalitions holds Shapley value, CG-SHAPLEY #P.show CG-BANZHAF #P-hard. reduction #SC.Figure 1 shows example reduction specific #SC instance.Theorem 1. CG-BANZHAF #P-hard, even backbone vertices, i.e., Vb =.Proof. reduce #SC instance CG-BANZHAF instance. Consider #SC instancecollection C = {S1 , . . . , Sn }, Si C Si = S. Denote items ={t1 , t2 , . . . , tk }. Denote items Si Si = {t(Si ,1) , t(Si ,2) , . . . , t(Si ,ki ) }. reductiongenerated CGD constructed graph G = hV, Ei follows. subset Si C,generated CG instance vertex vSi . denote set verticesVsets = {i|Si C} vSi . item ti generated CG instance also vertex vti .290fiSharing Rewards Cooperative Connectivity Gamesdenote set vti vertices Vitems = i|ti vti . generated CG instance alsotwo special vertices va vb . vertices generated instance.vertices generated CG connected following way. vertices Vsetsclique: every vi , vj Vsets , (vi , vj ) E. vertex va also part clique,vi Vsets (vi , va ) E. vertex va connected vb ,vertex connected vb , (va , vb ) E. set vertex vSi connected verticesitems set, vt(Si ,1) , vt(Si ,2) , . . . , vt(Si ,ki ) , vSi Vsets vt(Si ,j) (sot(Si ,j) Si ) (vSi , vt(Si ,j) ) E.define CG Vp = Vitems {vb }, Vb = , Vs = Vsets {va }, CGgame defined Definition 9. game = |Vs | = |Vsets | + 1 = |C| + 1 = n + 1agents (where n number subsets C, input #SC problem). CGBANZHAF query regarding va . Let (v) answer CG-BANZHAF query,k number set covers #SC instance. show k = va (v) 2m1 ,providing one-to-one mapping set-cover original problem winningcoalition va critical generated CG.Consider set-cover C C S. C must cover items ti S. denoteset vertices corresponding sets vertex cover VC = {vSi Vsets |Si C }.Since C set cover original problem, vertex vtj Vitems generatedgraph must connected least one vertex vi Vsets . Since vertices Vsetsclique, generated CG vti vSj connected component.However, without va cannot reach vb vertex. Thus, VC {va } VSwinning coalition generated CG, VC not, va critical coalition.show mapping reverse direction. Consider coalition V Vsva critical, denote C = {Si C|vSi V }. definition, V must winningcontain va . Consider vertex vti Vitems . Since V wins, must allow vertexVsets reach vti , happen V contains vSj ti Sj . Thus, Cset cover original problem.Let x number set covers #SC instance, ca number winningcoalitions va critical generated CG. Due one-to-one mappingshown, x = ca . definition Banzhaf index, generated CGca, ca = (v) 2m1 , x = (v) 2m1 .(v) = 2m1shown given polynomial algorithm CG-BANZHAF, solve#SC polynomial time, CG-BANZHAF #P-hard.recent result shows reasonable representation language cooperativegame, computing Banzhaf index #P-hard, computing Shapley valuealso #P-hard (Aziz, Lachish, Paterson, & Savani, 2009). representation language saidreasonable possible represent game additional dummy agentusing representation language.9 CG representation reasonableto addadditional dummy agent simply add dummy vertex x connected9. formally, representation language reasonable game v represent,also represent game v defined follows. game v additional agent x presentoriginal game v. agent set C x/ C v (C) = v(C). agent setC x C v (C) = v(C \ {x}). Note v v games slightly differentagent sets: v defined agent set whereas v defined agent set {x}.291fiBachrach, Porat, & Rosenscheinvertex. Adding isolated vertex coalition change value. Thusobtain following corollary.Figure 1: Example reducing #SC CG-BANZHAF. items {t1 , t2 , t3 , t4 , t5 }sets S1 = {t1 , t3 }, S2 = {t1 , t2 , t3 }, S3 = {t3 , t5 }, S4 = {t3 , t4 , t5 }.Corollary 1. CG-SHAPLEY #P-hard, even backbone vertices, i.e., Vb =.Since CG-BANZHAF CG-SHAPLEY #P #P-hard #Pcomplete problems, unlikely polynomial algorithm calculating indicesCGs would found. circumvent computational problem several ways.One try find approximation algorithm, solve problemrestricted instances. next section, adopt second approach.3.1.1 Computing Power Indices Tree CGsAlthough computing Shapley Banzhaf power indices general CGs #P-complete,restricting graphs structure may allow us polynomially compute indices.examine restricted case graph tree. Consider CG graph G = hV, Eitree, primary vertices Vp V , backbone vertices Vb V , standard verticesVs V . call problem calculating Shapley Banzhaf power indexagent domain TREE-CG-SHAPLEY / TREE-CG-BANZHAF. assumeleast two primary vertices va , vb Vp (otherwise, subset vertices triviallyfully connects primary vertices). first note since graph tree,vertices veto agents present winning coalition.292fiSharing Rewards Cooperative Connectivity GamesLemma 2. Consider CG graph G tree. Let va , vb Vp two primaryvertices, standard vertex vr Vs simple path va vb . vr presentwinning coalitions CG game.Proof. Since G tree, one simple path va vb . removalvertex along simple path makes vb unreachable va . Since vr vertex,coalition C Vs vr/ C loses, winning coalition must contain vr .Due Lemma 2 call standard vertex tree-CG essential lies simplepath two primary vertices.Lemma 3. Consider CG graph G tree. Let va , vb Vp two primaryvertices. Consider vertex coalition C Vs contains standard vertices vr Vssingle simple path va vb . C allows connecting va vbCG game. coalition C Vs contains essential vertices (i.e., standard verticesvr Vs simple path two primary vertices va , vb Vp ), Cwinning coalition v(C) = 1.Proof. CG game use primary vertex vp Vp , backbone vertexvb Vb . Consider coalition C contains vertices vr V single simplepath va vb . vertex vx single simple path va vb eitherbackbone vertex (so vx Vb ) primary vertex (so vx Vp ) standard vertex (sovx Vs ). standard vertex, coalition, vx C.cases use vertex, va vb connected componentcoalition C. C contains essential vertices, two primary vertices va vbconnected path composed either backbone, primary, coalition vertices,C fully connects primary vertices Vp , winning coalition.Lemma 2 states essential vertices necessary condition coalitionwin, Lemma 3 states also sufficient condition. summarizefollowing corollary.Corollary 2. Tree CGs, winning coalitions exactly coalitions containessential vertices.denote set essential vertices tree CG Ves . show tree CGShapley value distributes reward essential vertices equally, providesimilar result Banzhaf index.Theorem 2. Consider tree CG v set Ves essential vertices. vi Ves(v) = |V1es | otherwise (v) = 0.Proof. Three fairness axioms Shapley value fulfills null player axiom,symmetry axiom efficiency axiom (Shapley, 1953; Dubey & Shapley, 1979;Straffin, 1988). null player axiom states null player, i.e., coalitionC v(C) = v(C {i}) (v) = 0. Due corollary 2 vertexessential null player, (v) = 0. symmetry axiom deals equivalentagents. Two agents i, j called equivalent coalition C contains neither293fiBachrach, Porat, & Rosenschein(so/ C j/ C) adding either agent results change value,v(C {i}) = v(C {j}). note essential vertices equivalentifexist two essential vertices, i, j Ves , coalition C contain eithermissing two essential vertices winning, v(C {i}) = v(C {j}) = 0.Due symmetry axiom, essential vertices Shapley value,denote es . efficiency axiom statesPthe Shapley values agents sumvalue grand coalition I,iI (v) = v(I). Due efficiencynull playerP value vertex iP Ves esPaxioms sinceP Shapley+1 = v(I) =(v)=iV/ es 0, have:iV/ es = |Ves | es +iIiVes1es = |Ves | .Theorem 3. Consider tree CG v set Ves essential vertices. Ves(v) = 21|Ves | otherwise (v) = 0.Proof. Due corollary 2 vertex essential null player,coalition C v(C) v(C \ {i}) = 0. case, directly Definition 1(v) = 0. suppose essential vertex. entire agent set n vertices,|Ves | essential n |Ves | non-essential. Due Corollary 2 winning coalitionsexactly containing essential vertices, including i. Thus criticalwinning coalitions. therefore 2n|Ves | different winning coalitionscritical (any n |Ves | non-essential vertices either present not),n|Ves |(v) = 2 2n1 = 2n|Ves |n+1 = 21|Ves | .Corollary 3. TREE-CG-SHAPLEY TREE-CG-BANZHAF P.Proof. Due Theorems 2 3 compute power index vertex needknow whether essential total number |Ves | essential vertices. easytest vertex essential polynomial time, checking whether lies twoprimary vertices (for example using DFS). apply test verticesdetermine whether essential obtain |Ves |, apply formulas Theorem 2Theorem 3 (depending power index interested in).Thus, despite high complexity result general case given Section 3.1, treeCGs polynomially calculate power indices. result important analyzingreliability real-world networks. example, consider situation Internetconnectivity established companies, one company supplieranother company client. example cycle relationship wouldcompany buys Internet connection company B, turn buys Internetconnection company C, eventually buys Internet connection companyA. would mean that, sense, company would become client itself,would paying money connection. scenario cycleunlikely, domain likely tree domain.Yet another example agent based smart-grid technology, agents negotiatepower supply (Massoud Amin & Wollenberg, 2005; Vytelingum, Voice, Ramchurn, Rogers,& Jennings, 2010; Pipattanasomporn, Feroze, & Rahman, 2009). scenario variousagents suppliers consumers electricity. example, several firmssolar panels producing electricity, could buy additional electricity294fiSharing Rewards Cooperative Connectivity Gamesdemand higher production capability. case, firms benefitable send receive power firms (perhaps intermediary).multiple paths transmit power two firms offer advantage,cycles likely exist, making network tree.3.2 Stable Reward Distributionskey question regarding CGs raised Section 1.1 agents likely sharereward CG. Section 3.1 focused fair allocations, according agents impactentire coalition achieving goal. section focus stable reward allocations.winning coalition formed, reward distribution may collapse subset agentsallocated small share reward defect form alternative coalition.subset agents would defect secure agents largershare rewards. reasoning captured core (see Definition 5 Section 2).Thus, computing core allows us find test stable agreementswhen corenon-empty, contains imputations stable; empty, coalition wouldunstable matter divide utility among agents. However,compute core CG?first note always possible concisely represent core, since maycontain infinite number imputations. However, case CGs, existconcise representation core.Definition 9 CGs clearly indicate CGs simple cooperative games,value coalition either 1 0. core demanding concept simple games.agent ai veto player present winning coalitions, ai/ Cv(C) = 0. Section 3.1.1 noted essential vertices, liesimple path two primary vertices, veto players. well-known factsimple coalitional games, core non-empty iff least one veto playergame (Chalkiadakis et al., 2012). Consider simple coalitional game vetoplayers, every agent ai winning coalitionPn C contain ai . Takepayoff vectorp=(p,...,p)p>0.Since1ni=0 pi = 1 since pi > 0 knowPp(C) pj Ia pj < 1, p(C) < v(C) = 1, makes C blocking coalition.hand, see payoff vector p non-veto players get nothingcore: coalition C potentially block p mustP v(C) = 1 (if v(C) = 0cannot block), must contain veto players, pj C pj = 1, thuscannot block p.Due characterization core simple cooperative games, gamescore represented set Iveto , consisting veto players game.set represents core imputations: imputationp = (p1 , . . . , pn ) corePPp=1(notemustcasepiI = 1 p imputation).iIvetoconsider computing core CGs, representation setveto agents. note CGs monotone games. Let W winning coalitionCG (so v(W ) = 1), let C coalition game. W C alsowinning coalition, v(W C) = 1 (this restated as: coalitions A, BCG v(A B) v(A)). reason C fully connects VpW C also fully connects Vp , vertices available us use.295fiBachrach, Porat, & Rosenscheindenote set agents except ai Ii = \ {ai }. Let G CGgraph. denote Gi graph drop vertex vi owned ai ,Gi = hVi , Ei Vi = V \ {vi } Ei = {(u, v) E|u 6= vi v 6= vi }.show polynomial algorithm testing player veto agent CGs.Lemma 4. Testing agent ai veto agent CG P.Proof. first show Ii losing coalition iff ai veto agent. Ii losingcoalition due monotonicity CGs sub-coalition it, C Ii , also losing.Thus, coalition without ai losing, ai veto player. hand, Iiwinning coalition, winning coalition ai present, definition aiveto player. Thus, test ai veto agent need test Ii losingwinning. According Definition 9 CG, check Ii wins need checkIi fully connects primary vertices. test performed polynomial timetrying pairs va , vb Vp , performing DFS va vb graph Gi .Since computing core simple coalitional games requires returning listveto agents, get following corollary.Corollary 4. possible compute return concise representation coreCG polynomial time. representation, possible test whether coreempty test imputation core polynomial time.10Proof. Computing core CG requires returning Iveto , set consisting veto playersgame. Using Lemma 4, check agents determineveto players. veto players, core empty. Otherwise, payoff vectordistributes 1 (the total utility v(I) = 1) among veto players gives nonenon-veto players core.3.2.1 -Core Least Corecore CGs may non-empty, case easily compute core imputations.However, many real world networks redundancy terms connectivity, mightpossible connect primary vertices even eliminating arbitrary single vertex.networks, CG veto agent core empty. cases,imputation would unstable, vertex subset would incentivized deviateform coalition. Thus, may simply wish minimize incentive agentsubset deviate, examine problems related least core. Although core-relatedproblems CGs solved polynomial time (as shown above), showproblems related -core may hard.Given certain proposed imputation p = (p1 , . . . , pn ), may wish test whetherimputation -core, given .10. fact, done simple monotone coalitional game value coalitioncomputed polynomial time: due proof Lemma 4, games testwhether agent veto player, simple games computing core simply requires findingveto players are.296fiSharing Rewards Cooperative Connectivity GamesDefinition 13. -CORE-MEMBERSHIP(ECM): Given imputation p = (p1 , . . . , pn ),decide whether -core game, words, test whether coalitionC excess e(C) .ECM tests whether imputation (payoff division) sufficiently stable, -stable.definition -core, imputations property coalition Cexcess e(C) < . ECM basic question computing imputation-core finding least core valuethe minimal admits non-empty -core.show ECM coNP-complete, solved polynomial time treeCGs. tree CGs, show core non-empty (so least core coincidescore) possible find -core imputations polynomial time.show ECM coNP-complete CGs using reduction VERTEX-COVER,known NP-complete (Garey & Johnson, 1979).Theorem 4. ECM coNP-complete general CGs, even imputation testedequal imputation p = ( n1 , . . . , n1 ) single backbone vertex.Proof. ECM requires testing whether given imputation p = (p1 , . . . , pn )exist coalition C excess e(C) least (for given d). Given vertex subsetC V , easy test C connects primary vertices polynomial time,thus test whether C winning not. also easily compute payoff p(C)coalition imputation, thus also compute excess e(C) = v(C) p(C).Thus, ECM coNP.show computing maximal excess emax = max{e(C)|C I}imputation p coNP-hard. Note imputation p -core iff maximaldeficit imputation . show testing whether maximalexcess (for given d) NP-hard reducing VERTEX-COVER instanceproblem.Let graph G = hV, Ei threshold input VERTEX-COVER instance(i.e., asked wether Gs edges could covered vertices). assumeVERTEX-COVER instance least two edges (otherwise, problem easysolve). Denote |V | = n. construct graph G = hV , E follows. vertexv V , create standard vertex v V (i.e., V V ). edge e E, createprimary vertex V . primary vertices called edge vertices. also createsingle backbone vertex vb V . Thus Vs = V , Vp = {ve |e E} Vb = {vb }.agents standard vertices Vs = V , n agents.(u,v)(u,v)edge e = (u, v) V create two edges G : e1= (u, ) e2=(v, ). words, break edge original graph two parts, puttingvertex between. original edges graph G eliminated G . Finally,connect standard vertex v Vs = V vb . Figure 2 shows example reductionconstruction used proof Theorem 4.imputation tested equal imputation p = ( n1 , . . . , n1 ) (i.e., payoffagents same, n1 ). threshold value generated ECM instance= 1 nt threshold VERTEX-COVER instance.first note coalition C loses generated CG (i.e., fails connectprimary vertices Vp ) negative excess, v(C) = 0 p(C) = |C|n , e(C) = v(C)297fiBachrach, Porat, & Rosenscheinp(C) = |C|n . Thus, maximal excess coalition minimally paid winning coalition,i.e., coalition C minimizes p(C) winning coalitions C: arg minC{C|v(C)=1} p(C).Since p(C) = |C|n , maximal excess coalition winning coalition minimal size:arg minC{C|v(C)=1} |C|. words, maximal excess coalition minimally sizedcoalition connects primary vertices.11 winning coalition C size |C| =thus excess v(C) p(C) = 1 |C| n1 = 1 ns .Since agents game standard vertices, since Vs = V , identifyagents vertices original graph. show coalition C Vswinning coalition iff vertex cover G.C Vs wins, must connect two primary vertices vx , vy Vp . note dueconstruction two primary vertices connected directly, primary vertexcreated edge e E original graph. assumed VERTEXCOVER instance least two edges, least two primary verticesgenerated graph. Let primary vertex. Due construction connectedexactly two standard vertices u, w (the vertices connected edge eoriginal graph). neither u w part C (i.e., u/ C w/ C),path vertex graph induced C, connectedprimary vertex C loses v(C) = 0. Thus, C winning coalitionevery primary vertex e = (u, w) E vertices u, w V original graphG, coalition C must contain either u w. However, u C C covers edge e,u vertex one side edge, w C C also covers edge e, wvertex side edge. Thus, C covers edge e E, vertex cover.hand, suppose coalition C Vs = V vertex cover G.vertex cover, C must cover every edge e E, given edge e = (u, w), C must containeither u w both. u C path vb : (ve , vu , vb ) (ve sourceprimary vertex, vu coalition, vb backbone vertex). Similarly, w Cpath vb : (ve , vw , vb ) (ve source primary vertex, vw coalition,vb backbone vertex). Therefore, path primary vertex vp vb .Thus, primary vertices connected: given vx , vy Vp path vxvb vb vy , C vertex cover, winning coalition.shown C winning coalition excess 1 |C|n generatedinstance iff vertex cover size |C|. maximal excess problem generatedinstance requires finding minimal size winning coalition, words finding vertexcover minimal size. restate saying ECM instance (with = 1 nt )yes instance iff original graph vertex cover size t.3.2.2 Core, -Core Least Core Tree CGsconsider core related problems tree CGs. CG domain less two primaryvertices degenerate domain (where coalitions win), CG even grandcoalition standard vertices fails connect primary vertices also degen11. Finding minimally paid winning coalition general imputation similar famousSteiner tree problem, known NP-hard. However, domain weightsvertices rather edges.298fiSharing Rewards Cooperative Connectivity GamesFigure 2: Example reducing VERTEX-COVER ECM CG domain. left sideoriginal VERTEX-COVER instance, right side generated ECMdomain, primary vertices orange (denoting edges original VERTEX-COVER instance), standard vertices blue (same originalvertices VERTEX-COVER instance) backbone vertex green.erate domain (where coalitions lose). assume CG domains sectiondegenerate. also assume two primary vertices directly connectedpath containing backbone vertices. case,merge primary vertices single vertex, coalition connected onealso connected one without using standard vertex.first prove core (non-degenerate) tree CGs non-empty.Theorem 5. Tree CGs non-empty cores (assuming domain game nondegenerate CG domain).Proof. Lemma 2 Corollary 2 shows tree CGs, veto vertices exactlyessential vertices, lie simple path two primary vertices. notestandard vertex path two primary vertices, domaindegenerate (either primary vertices connected even empty coalitionstandard vertices, still disconnected even grand coalition standardvertices). Thus, must exist least one veto agent. Since simple games corenon-empty iff veto agents, core tree CGs non-empty.Due Theorem 5, tree CGs least core value, minimal -corenon-empty, 0 (the core 0-core, always non-empty).299fiBachrach, Porat, & Rosenscheinsimple games, core non-empty, core imputation distributes rewardsolely veto agents. Since tree CGs veto agents exactly essential vertices(Corollary 2) obtain following:Corollary 5. tree CG,Plet Ves Vs set essential vertices, denote |Ves | =m. imputation iVes pi = 1 core imputation, core1imputations. Specifically, imputation pi =vi Ves pi = 0 otherwisecore imputation.Although core non-empty tree CGs, given potential agreement formspecific imputation, may still wish find maximal excess imputation,words test whether imputation -core (for given ).examine complexity ECM problem tree CGs. Theorem 4 shownproblem coNP-complete general graphs, show problem solvedpolynomial time tree CGs.Theorem 6. tree CGs, ECM problem solved polynomial time. imputation -core iff p(Ves ) > 1 .Proof. Consider tree CG imputation p = (p1 , . . . , pn ). Let veto verticesVes V , denote = |Ves |. Denote indices veto vertices ,{vi |i } = Ves . seen Lemma 2, tree CGs, vertex w veto vertex(essential), dummy vertex, coalition C v(C {w}) = v(C).denote non-veto vertices Vd = V \ Ves , dummy vertices. denoteindices dummy vertices {vi |i D} = Vd .Pdenote total payoff vetoPvertices p(Ves ) =iM pi , totalpayoff dummy vertices p(Vd ) =p.assumeddomainiDdegenerate, grand coalition wins, v(I) = 1. Since p imputation,p(I) = 1. Since tree CG vertices either veto vertices dummy vertices,1 = p(I) = p(Ves ) + p(Vd ). -core constraints require p(C) > v(C) .since pi positive, -core constraint holds losing coalitions. winningcoalition C must contain Ves Ves C, p(Ves ) > v(Ves ) = 1 , -coreconstrains hold: p(Ves ) > v(Ves ) = 1 , winning coalition Cp(C) p(Ves ) p(C) p(Ves ) > v(Ves ) = 1 = v(C) . hand,p(Ves ) < 1 , -core constraint hold coalition Vesimputation -core.Thus, test imputation -core need test p(Ves ) > 1 .Since compute Ves polynomial time, test also done polynomial time,ECM P tree CGs.4. Related Workpaper introduced cooperative game called Connectivity Game, examinedcomputational aspects calculating power indices finding core solutions game.discuss related work regarding solution concepts Section 4.1, examine similarmodels cooperative games networks Section 4.2.300fiSharing Rewards Cooperative Connectivity Games4.1 Solutions Cooperative Gamesstability based solution concept core originated paper (Gillies, 1953).least core introduced solution concept games empty cores (Shapley & Shubik, 1966). refinement nucleolus Schmeidler (1969). -corenucleolus studied minimum cost spanning tree games (Granot & Huberman,1984), somewhat reminiscent model (see below), assignment games (Solymosi & Raghavan, 1994), weighted voting games (Elkind, Goldberg, Goldberg, &Wooldridge, 2007a). Another related problem Cost Stability (Bachrach, Elkind,Meir, Pasechnik, Zuckerman, Rothe, & Rosenschein, 2009), measuring required externalsubsidy stabilize game, studied weighted voting games (Bachrach, Meir, Zuckerman,Rothe, & Rosenschein, 2009), network flow games (Resnick, Bachrach, Meir, & Rosenschein, 2009) game forms (Meir, Zick, & Rosenschein, 2012; Meir, Bachrach, &Rosenschein, 2010).Power indices originated work game theory political science, attemptingmeasure power players weighted voting games. games, playercertain weight, coalitions weight sum weights participants;coalition wins weight passes certain threshold. common situationlegislative bodies. Power indices suggested way measuring influenceplayers games choosing outcomes. popular indices suggestedmeasurement Banzhaf index (1965) Shapley-Shubik index (1954).Shapley-Shubik index (1954) direct application Shapley value (1953)simple coalitional games. Banzhaf index emerged study voting decisionmaking bodies, certain normalized form index introduced (Banzhaf,1965). Banzhaf index later mathematically analyzed (Dubey & Shapley, 1979),normalization shown certain undesirable features, focusing attentionnon-normalized version Banzhaf index. indices appliedanalysis voting structures IMF European Union Council Ministers,well many bodies (Leech, 2002; Machover & Felsenthal, 2001).Shapley value payoff division rule exhibits natural fairness axioms (Shapley, 1953; Dubey & Shapley, 1979), used measurepower also fairly allocate costs, revenues credit various domains (Shubik,1962; Dubey, 1982; Young, 1985; Bachrach, 2010; Bachrach, Graepel, Kasneci, Kosinski, &Van Gael, 2012a; Staum, 2012). Specific examples include dividing costs multicast transmissions (Feigenbaum, Papadimitriou, & Shenker, 2001), dividing airport landingfees (Littlechild & Owen, 1973), pollution reduction costs (Petrosjan & Zaccour, 2003),sharing supply chain profits (Shi-hua & Peng, 2006; Bachrach, Zuckerman, Wooldridge, &Rosenschein, 2010) sharing gains regional cooperation electricity market (Gately, 1974). Although power indices allow finding fair allocations rewardscosts, susceptible forms strategic behavior (Yokoo, Conitzer, Sandholm,Ohta, & Iwasaki, 2005; Aziz, Bachrach, Elkind, & Paterson, 2011; Zuckerman, Faliszewski,Bachrach, & Elkind, 2012).differences Banzhaf Shapley-Shubik indices analyzed (Straffin,1977), index shown reflects specific conditions voting body. Different301fiBachrach, Porat, & Rosenscheinaxiomatizations two indices proposed (Shapley, 1953; Dubey & Shapley,1979; Lehrer, 1988; Straffin, 1988; Laruelle, 1999; Laruelle & Valenciano, 2001).4.2 Cooperative Games Networksmodel based network goal connecting set primary servers.cooperative games networks proposed, modeling goals networks.related work studies one model, deals cost sharing mechanismmulticast transmissions (Feigenbaum et al., 2001; Moulin & Shenker, 2001). bodyrelated work focuses weakly budget-balanced implementation (where, opposedmodel total payments agents may exceed total cost incurred),mechanisms resistant deviations single agents. Yet another modelexamines buying path source target network (Archer & Tardos,2002). mechanism design model examines problem eliciting truthfulreports edges regarding true costs, contrast work focusescooperative game full information, agents incur cost allowinguse resources.Another similar model considers scenario agents control edges networkflow graph, coalition wins maintain certain required flow sourcetarget (Bachrach & Rosenschein, 2009). specific model finding Banzhafindex edge domain #P-complete, though polynomial algorithmrestricted cases. handle different scenario agents requiredmaintain connectivity, rather certain flow. Also, interested maintainingconnectivity every two primary vertices, rather two specific vertices (wesimulate case two specific servers two primary servers). Also,work agents servers communication network, rather links.model Minimum Cost Spanning Tree Game (Bird, 1976; Granot & Huberman,1981, 1984) (MCSTG) also quite similar model. cost sharing game,agents vertices complete edge-weighted graph, cost coalitionminimal weight tree connects coalitions vertices designated rootr. formally, vertices graph include agents = {1, 2, . . . , n}designated root r/ I, V = {r}, graph complete edge weighted graph(with n(n + 1)/2 edges); cost coalition weight minimal spanningtree subgraph induced {r}. Granot et. al show MCSTGs alwaysnon empty cores (1981) provide algorithms finding core imputations computingnucleolus (1984). CG model quite differentCGs revenue sharing game,costs associated edges, backbone vertices allowed.notably, CGs simple games (where coalition either wins loses), coreCGs sometimes empty.generalization MCSTGs called Steiner Tree Games (Skorin-Kapov, 1995), STGs,also somewhat similar model. STGs allow nodes players, similarlybackbone vertices, may sometimes empty core. Related workmodel discusses certain sufficient, necessary, condition core STGnon-empty, polynomial algorithm testing condition (Skorin-Kapov, 1995).Since core may non-empty even condition hold, allow302fiSharing Rewards Cooperative Connectivity Gamespolynomially determining core STG nonempty. Again, opposedCGs, STGs non-simple cost sharing games. Further, also examine computationalaspect power indices core-relaxations, rather non-emptiness corefocus related work. results show CGs determine whethercore empty polynomial time even return representation core.Another twist MCSTGs results model cost coalitionweight minimal tree spans vertices {r} entire graph, rathergraph induced {r} (Faigle, Kern, Fekete, & Hochstattler, 1997).words, allowed use nonmembers coalition connect members coalitionroot. model core may empty, testing core-emptinessNP-complete problem (Faigle et al., 1997). results regarding model showcomputing nucleolus game NP-hard (Faigle, Kern, & Kuipers, 1998).variations MCSTG discussed (Granot & Huberman, 1981; SkorinKapov, 1995; Faigle et al., 1997) cost sharing games. games, coalitionmust achieve certain goal agent endowed resources (for example,ability use edges adjacent agent). However, using resourceassociated cost, coalition attempts minimize total cost incurs.12possible convert cost-sharing game reward sharing game (Moulin, 2002;Chalkiadakis et al., 2012),13 example defining utility coalitionhigh constant reward minus cost coalition incurs achieve goaloriginal cost sharing game. However, model crucially depends assumptionnode incurs cost allowing use links, coalitions achieve networkgoal utility. believe better characterizes domains computernetwork already constructed, links node simply availableuse. MCSTG better models domains agents must make decisionslinks build future constructing link requires investmentbehalf agents.Yet another related network based cooperative games Spanning ConnectivityGames (Aziz et al., 2009) (SCG short). SCGs similar CGscooperative network reward sharing game. However, opposed model, SCGsplayers edges multigraph, coalition wins manages spannodes network. Yet another similar reward sharing game Path DisruptionGames (Bachrach & Porat, 2010) coalition attempts disrupt connectivitytwo specific vertices. Although domains combinatorially differentCGs, previous work examines similar solution concepts: core Shapley value.example, related work shows computing power indices domains hardcomputationally tractable algorithms solving core-related problems(at least somewhat restricted domains).12. games coalition may even able achieve goal all, casedefine cost infinite.13. Sometimes reward sharing games also called surplus sharing games.303fiBachrach, Porat, & Rosenschein4.2.1 Computing Power Indices Corename suggests, power indices also though measure significanceagents game. However, although Shapley Banzhaf power indicesdefined voting games simple cooperative game, relatively littlework examined use power indices measuring importance playersnon-voting scenarios. complexity computing power indices depends concreterepresentation game. game defined value coalition,form oracle tests certain coalition answers whether wins loses,calculating power indices difficult. naive algorithm calculating power indexagent ai enumerates coalitions permutations containing ai . Sinceexponentially many coalitions permutations, naive algorithm exponentialnumber agents.Related work discusses algorithms calculating power indices weighted majoritygames (Matsui & Matsui, 2000), shows calculating Banzhaf Shapley-Shubikindices weighted voting games NP-complete problems (Matsui & Matsui, 2001).Since weighted voting games restricted case simple coalitional games, problemcalculating either index general coalitional game course NP-hard. fact,certain cases, calculating power indices NP-hard also #P-hard. DengPapadimitriou (1994) show computing Shapley-Shubik index weighted votinggames #P-complete. research derived hardness results power indicesgame classes, Coalitional Skill Games (Bachrach & Rosenschein, 2008)based set-covering problem, rule based cooperative game representationcalled Multi-Attribute Coalitional Game language (Ieong & Shoham, 2006).hardness results regarding computing power indices might make using concept seem less attractive. However, many results comparing approximatingpower indices, general restricted domains (Owen, 1975; Deng & Papadimitriou,1994; Conitzer & Sandholm, 2004; Bachrach, Markakis, Resnick, Procaccia, Rosenschein, &Saberi, 2010; Faliszewski & Hemaspaandra, 2009). line work shows althoughcomputing power indices exactly generally hard, estimating high degree accuracy computationally tractable. example, problematic vertices networktractably found employing approximation method (Bachrach et al., 2010)handle arbitrary cooperative games, long possible compute valuecoalition polynomial time (which easy CGs). algorithm providedBachrach et al. (2010) estimates power indices returns result probablyapproximately correct: given game players true power index , giventarget accuracy level confidence level , algorithm returns approximationprobability least 1 | | (i.e., result approximatelycorrect, within distance correct value). running time logarithmicconfidence quadratic accuracy, approach tractable even highaccuracy confidence. Methods computing power indices also examinedcontext games uncertain agent failures (Bachrach, Meir, Feldman, & Tennenholtz,2011; Bachrach, Kash, & Shah, 2012b).treatment model game theoretic, network domains problems akincalculating power indices also formulated network reliability problems.304fiSharing Rewards Cooperative Connectivity Gamescomputational complexity problems studied several papers. Classicalnetwork reliability problems consider undirected graph G = hV, Ei, edgee E probability assigned it, pe . probability edge e remainssurviving graph.One prominent problem s-t connectivity probability (STC-P): givendomain, compute probability path s, V surviving graph.Another prominent problem full connectivity probability (FC-P): givendomain, compute probability surviving graph connected (sopath two vertices). One seminal paper Valiant (1979a) proved STC-P#P-hard. Provan Ball (1983) showed FC-P also #P-hard.problems study similar FC-P. example computing Banzhafpower index CGs specific case FC-P, probability every vertexsubset equal (or equivalently, vertex 50% probability failures,failures independent). Since restricted case, cannot use hardness resultProvan Ball (1983), prove even restricted case #P-complete(which did, Section 3.1).5. Conclusionsconsidered computational aspects reward sharing network connectivityscenario, applications network reliability. modeled communication networksimple coalitional game, showed various game-theoretic solution conceptsused characterize reasonable reward sharing agreements agents might makefind significant possible points failure network. shown domain,general graphs, computing Shapley Banzhaf power indices #P-complete.Despite high complexity result general domain, also gave polynomial resultrestricted domain graph tree.also shown computing core done polynomial timeCG, gave simple characterization instances core non-empty CGs.hand, shown general CGs, testing imputation-core (or equivalently computing maximal excess coalition imputation)coNP-complete. also given characterization core tree CGs, showntesting -core imputations done polynomial time tree CGs.remains topic future research tractably compute power indices CGsrestricted domains. also note Shapley Banzhaf indicespower indices studied literature, studying computational aspects indicesalso interest. also examined core, -core least core. hardness resultsshow computing maximal excess coalition computationally hard generalCGs. would interesting see could approximated, exactly computedrestricted domains trees. Yet another open question computinggame theoretic solution concepts CGs restricted CGs. One interesting problemcomputing nucleolus (Schmeidler, 1969) CGs.14 Another interesting direction ex14. example, tree CGs, imputation equally allocates rewards essential verticesVes nucleolus. However, believe may even exist restricted CG domainscomputing -core least core tractable, computing nucleolus hard.305fiBachrach, Porat, & Rosenscheinamining coalition formation models (Dang, Dash, Rogers, & Jennings, 2006; Greco, Malizia,Palopoli, & Scarcello, 2011) analyzing coalition structure generation problem (Rahwan, Ramchurn, Dang, & Jennings, 2007; Ohta, Conitzer, Ichimura, Sakurai, Iwasaki, &Yokoo, 2009; Bachrach, Meir, Jung, & Kohli, 2010) domain.Acknowledgmentswork partially supported Israel Science Foundation grants #898/05 #1227/12,Israel Ministry Science Technology grant #3-6797.preliminary version paper presented Seventh International JointConference Autonomous Agents Multiagent Systems (AAMAS 2008). extendedversion includes complete analysis power indices CGs, complementingprevious results regarding Banzhaf index new results regarding Shapley value.also expanded work regarding stability based solutions, version containsanalysis problems related -core least core, showing problemscoNP-hard general CGs, solved polynomial time restricted caseCGs trees. also includes complete analysis core CGs playedtrees.ReferencesArcher, A., & Tardos, E. (2002). Frugal path mechanisms. Proceedings Thirteenth Annual ACM-SIAM Symposium Discrete Algorithms, pp. 991999. SocietyIndustrial Applied Mathematics.Aziz, H., Bachrach, Y., Elkind, E., & Paterson, M. (2011). False-name manipulationsweighted voting games. Journal Artificial Intelligence Research, 40 (1), 5793.Aziz, H., Lachish, O., Paterson, M., & Savani, R. (2009). Power indices spanning connectivity games. Algorithmic Aspects Information Management, 5567.Babaoglu, O., Meling, H., & Montresor, A. (2002). Anthill: framework development agent-based peer-to-peer systems. Distributed Computing Systems, 2002.Proceedings. 22nd International Conference on, pp. 1522. IEEE.Bachrach, Y., Elkind, E., Meir, R., Pasechnik, D., Zuckerman, M., Rothe, J., & Rosenschein,J. S. (2009). cost stability coalitional games. Proceedings 2ndInternational Symposium Algorithmic Game Theory (SAGT 09), pp. 122134.Springer.Bachrach, Y., Markakis, E., Resnick, E., Procaccia, A., Rosenschein, J. S., & Saberi, A.(2010). Approximating power indices: theoretical empirical analysis. AutonomousAgents Multi-Agent Systems, 20 (2), 105122.Bachrach, Y., Meir, R., Zuckerman, M., Rothe, J., & Rosenschein, J. S. (2009). coststability weighted voting games. Proceedings 8th International ConferenceAutonomous Agents Multiagent Systems, pp. 12891290.306fiSharing Rewards Cooperative Connectivity GamesBachrach, Y., & Porat, E. (2010). Path disruption games. Proceedings 9th International Joint Conference Autonomous Agents Multiagent Systems, pp.11231130.Bachrach, Y., & Rosenschein, J. S. (2008). Coalitional skill games. Proceedings7th International Joint Conference Autonomous Agents Multiagent Systems,pp. 10231030.Bachrach, Y., & Rosenschein, J. S. (2009). Power threshold network flow games. Autonomous Agents Multi-Agent Systems, 18 (1), 106132.Bachrach, Y., Zuckerman, M., Wooldridge, M., & Rosenschein, J. S. (2010). Proof systemstransformation games. Mathematical Foundations Computer Science 2010,7889.Bachrach, Y. (2010). Honor among thieves: collusion multi-unit auctions. Proceedings9th International Conference Autonomous Agents Multiagent Systems:volume 1-Volume 1, pp. 617624. International Foundation Autonomous AgentsMultiagent Systems.Bachrach, Y., Graepel, T., Kasneci, G., Kosinski, M., & Van Gael, J. (2012a). Crowd IQ:aggregating opinions boost performance. Proceedings 11th InternationalConference Autonomous Agents Multiagent Systems-Volume 1, pp. 535542.International Foundation Autonomous Agents Multiagent Systems.Bachrach, Y., Kash, I., & Shah, N. (2012b). Agent failures totally balanced gamesconvex games. Internet Network Economics, pp. 1529. Springer.Bachrach, Y., Meir, R., Feldman, M., & Tennenholtz, M. (2011). Solving cooperative reliability games. Proceedings Twenty Seventh Conference UncertaintyArtificial Intelligence (UAI 2011).Bachrach, Y., Meir, R., Jung, K., & Kohli, P. (2010). Coalitional structure generationskill games. Twenty-Fourth AAAI Conference Artificial Intelligence (AAAI).Banzhaf, J. F. (1965). Weighted voting doesnt work: mathematical analysis. RutgersLaw Review, 19, 317343.Bird, C. (1976). cost allocation spanning tree: game theoretic approach. Networks,6 (4), 335350.Branzei, R., Dimitrov, D., & Tijs, S. (2008). Models cooperative game theory, Vol. 556.Springer Verlag.Chalkiadakis, G., Elkind, E., & Wooldridge, M. (2012). Cooperative game theory: Basicconcepts computational challenges. IEEE Intelligent Systems, 8690.Conitzer, V., & Sandholm, T. (2004). Computing Shapley values, manipulating value division schemes, checking core membership multi-issue domains. ProceedingsNineteenth National Conference Artificial Intelligence (AAAI 2004), pp.219225.Dang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalitionformation efficient data fusion multi-sensor networks. Proceedings307fiBachrach, Porat, & RosenscheinNational Conference Artificial Intelligence, Vol. 21, p. 635. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999.Deng, X., & Papadimitriou, C. H. (1994). complexity cooperative solution concepts. Math. Oper. Res., 19 (2), 257266.Dubey, P., & Shapley, L. (1979). Mathematical properties Banzhaf power index.Mathematics Operations Research, 4(2), 99131.Dubey, P. (1982). shapley value aircraft landing feesrevisited. Management Science,28 (8), 869874.Dunne, P., van der Hoek, W., Kraus, S., & Wooldridge, M. (2008). Cooperative booleangames. Proceedings 7th International Joint Conference AutonomousAgents Multiagent Systems, pp. 10151022.Easley, D., & Kleinberg, J. (2010). Networks, crowds, markets. Cambridge UniversityPress.Elkind, E., Goldberg, L. A., Goldberg, P., & Wooldridge, M. (2007a). Computationalcomplexity weighted threshold games. AAAI-2007, p. 718.Elkind, E., Goldberg, L. A., Goldberg, P. W., & Wooldridge, M. (2007b). Computationalcomplexity weighted threshold games. National Conference ArtificialIntelligence, pp. 718723.Faigle, U., Kern, W., Fekete, S., & Hochstattler, W. (1997). complexity testingmembership core min-cost spanning tree games. International JournalGame Theory, 26 (3), 361366.Faigle, U., Kern, W., & Kuipers, J. (1998). Note computing nucleolus min-costspanning tree games NP-hard. International Journal Game Theory, 27 (3), 443450.Faliszewski, P., & Hemaspaandra, L. (2009). complexity power-index comparison.Theoretical Computer Science, 410 (1), 101107.Feigenbaum, J., Papadimitriou, C. H., & Shenker, S. (2001). Sharing cost multicasttransmissions. Journal Computer System Sciences, 63 (1), 2141.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-Completeness. W. H. Freeman Co.Gately, D. (1974). Sharing gains regional cooperation: game theoretic applicationplanning investment electric power. International Economic Review, 15 (1), 195208.Gillies, D. B. (1953). theorems n-person games. Ph.D. thesis, Princeton University.Goldman, C., & Zilberstein, S. (2004). Decentralized control cooperative systems: Categorization complexity analysis. J. Artif. Intell. Res. (JAIR), 22, 143174.Granot, D., & Huberman, G. (1981). Minimum cost spanning tree games. MathematicalProgramming, 21 (1), 118.Granot, D., & Huberman, G. (1984). core nucleolus minimum cost spanningtree games. Mathematical Programming, 29 (3), 323347.308fiSharing Rewards Cooperative Connectivity GamesGreco, G., Malizia, E., Palopoli, L., & Scarcello, F. (2011). complexity corecoalition structures. Proceedings Twenty-Second international jointconference Artificial Intelligence-Volume Volume One, pp. 216221. AAAI Press.Holler, M., & Packel, E. (1983). Power, luck right index. Journal Economics,43 (1), 2129.Ieong, S., & Shoham, Y. (2006). Multi-attribute coalitional games. Proceedings7th ACM Conference Electronic Commerce, pp. 170179. ACM.Jain, M., Korzhyk, D., Vanek, O., Conitzer, V., Pechoucek, M., & Tambe, M. (2011).double oracle algorithm zero-sum security games graphs. ProceedingsTenth International Joint Conference Autonomous Agents Multi-AgentSystems (AAMAS), Taipei, Taiwan, pp. 327334.Kraus, S., Shehory, O., & Taase, G. (2004). advantages compromising coalitionformation incomplete information. Proceedings Third InternationalJoint Conference Autonomous Agents Multiagent Systems (AAMAS 2004),pp. 588595.Laruelle, A. (1999). choice power index. Papers 99-10, Valencia Instituto deInvestigaciones Economicas.Laruelle, A., & Valenciano, F. (2001). Shapley-Shubik Banzhaf indices revisited. Mathematics Operations Research, 89104.Leech, D. (2002). Voting power governance International Monetary Fund.Annals Operations Research, 109 (1-4), 375397.Lehrer, E. (1988). axiomatization Banzhaf value. International Journal GameTheory, 17 (2), 8999.Lesser, V., Ortiz, C. L., & Tambe, M. (2003). Distributed sensor networks: multiagentperspective. Springer.Littlechild, S., & Owen, G. (1973). simple expression Shapley value specialcase. Management Science, 370372.Machover, M., & Felsenthal, D. S. (2001). treaty Nice qualified majority voting.Social Choice Welfare, 18 (3), 431464.Massoud Amin, S., & Wollenberg, B. (2005). Toward smart grid: power delivery21st century. Power Energy Magazine, IEEE, 3 (5), 3441.Matsui, Y., & Matsui, T. (2000). survey algorithms calculating power indicesweighted majority games. Journal Operations Research Society Japan, 43.Matsui, Y., & Matsui, T. (2001). NP-completeness calculating power indices weightedmajority games. Theoretical Computer Science, 263 (12), 305310.Meir, R., Bachrach, Y., & Rosenschein, J. (2010). Minimal subsidies expense sharinggames. Algorithmic Game Theory: Proceedings Third International Symposium (SAGT 2010), Vol. 6386, p. 347. Springer.Meir, R., Zick, Y., & Rosenschein, J. S. (2012). Optimization stability gamesrestricted interactions..309fiBachrach, Porat, & RosenscheinMoulin, H. (2002). Axiomatic cost surplus sharing. Handbook social choicewelfare, 1, 289357.Moulin, H., & Shenker, S. (2001). Strategyproof sharing submodular costs: budget balanceversus efficiency. Economic Theory, 18 (3), 511533.Ohta, N., Conitzer, V., Ichimura, R., Sakurai, Y., Iwasaki, A., & Yokoo, M. (2009). Coalition structure generation utilizing compact characteristic function representations.Principles Practice Constraint Programming, 623638.Owen, G. (1975). Multilinear extensions Banzhaf Value. Naval Research LogisticsQuarterly, 22 (4), 741750.Papadimitriou, C., & Zachos, S. (1982). Two remarks power counting. TheoreticalComputer Science, 269275.Papadimitriou, C. H. (2003). Computational complexity. John Wiley Sons Ltd.Petrosjan, L., & Zaccour, G. (2003). Time-consistent Shapley value allocation pollutioncost reduction. Journal economic dynamics control, 27 (3), 381398.Pipattanasomporn, M., Feroze, H., & Rahman, S. (2009). Multi-agent systems distributed smart grid: Design implementation. Power Systems ConferenceExposition, 2009. PSCE09. IEEE/PES, pp. 18. IEEE.Provan, J. S., & Ball, M. O. (1983). complexity counting cuts computingprobability graph connected. SIAM Journal Computing, 12 (4), 777788.Rahwan, T., Ramchurn, S. D., Dang, V. D., & Jennings, N. R. (2007). Near-optimalanytime coalition structure generation. Proceedings 20th international jointconference Artifical intelligence, pp. 23652371. Morgan Kaufmann Publishers Inc.Resnick, E., Bachrach, Y., Meir, R., & Rosenschein, J. S. (2009). cost stabilitynetwork flow games. Mathematical Foundations Computer Science 2009:Thirty-Fourth International Symposium Mathematical Foundations ComputerScience, No. 5734 Lecture Notes Computer Science, pp. 636650. Springer, NovySmokovec, High Tatras, Slovakia.Roy, S., Ellis, C., Shiva, S., Dasgupta, D., Shandilya, V., & Wu, Q. (2010). surveygame theory applied network security. System Sciences (HICSS), 2010 43rdHawaii International Conference on, pp. 110. IEEE.Royden, H. L., & Fitzpatrick, P. (1988). Real analysis, Vol. 3. Prentice Hall EnglewoodCliffs, NJ:.Saad, W., Han, Z., Debbah, M., Hjorungnes, A., & Basar, T. (2009). Coalitional game theorycommunication networks. Signal Processing Magazine, IEEE, 26 (5), 7797.Sabater, J., & Sierra, C. (2002). Reputation social network analysis multi-agentsystems. Proceedings First International Joint Conference AutonomousAgents Multiagent Systems, pp. 475482.Schmeidler, D. (1969). nucleolus characteristic function game. SIAM JournalApplied Mathematics, 17 (6), 11631170.310fiSharing Rewards Cooperative Connectivity GamesShapley, L. S. (1953). value n-person games. Contributions Theory Games,3140.Shapley, L. S., & Shubik, M. (1954). method evaluating distribution powercommittee system. American Political Science Review, 48, 787792.Shapley, L. S., & Shubik, M. (1966). Quasi-cores monetary economy nonconvexpreferences. Econometrica: Journal Econometric Society, 34 (4), 805827.Shi-hua, M., & Peng, W. (2006). study profit allocation among partners supplychain based Shapley value [j]. Industrial Engineering Management, 4,4345.Shubik, M. (1962). Incentives, decentralized control, assignment joint costsinternal pricing. Management Science, 8 (3), 325343.Skorin-Kapov, D. (1995). core minimum cost Steiner tree game networks.Annals Operations Research, 57 (1), 233249.Solymosi, T., & Raghavan, T. (1994). algorithm finding nucleolus assignmentgames. International Journal Game Theory, 23 (2), 119143.Staum, J. (2012). Systemic risk components deposit insurance premia. QuantitativeFinance, 12 (4), 651662.Straffin, P. (1977). Homogeneity, independence power indices. Public Choice, 30, 107118.Straffin, P. (1988). Shapley-Shubik Banzhaf power indices probabilities.Shapley Value, 7181.Suris, J. E., DaSilva, L. A., Han, Z., & MacKenzie, A. B. (2007). Cooperative game theorydistributed spectrum sharing. IEEE International Conference Communications, 2007 (ICC07), pp. 52825287. IEEE.Vadhan, S. P. (2002). complexity counting sparse, regular, planar graphs.SIAM Journal Computing, 31 (2), 398427.Valiant, L. G. (1979a). complexity enumeration reliability problems. SIAMJournal Computing, 8, 410421.Valiant, L. (1979b). complexity enumeration reliability problems. SIAM J.Comput., 8 (3), 410421.Vytelingum, P., Voice, T., Ramchurn, S., Rogers, A., & Jennings, N. (2010). Agent-basedmicro-storage management smart grid. Proceedings 9th InternationalConference Autonomous Agents Multiagent Systems, pp. 3946.Yokoo, M., Conitzer, V., Sandholm, T., Ohta, N., & Iwasaki, A. (2005). Coalitional gamesopen anonymous environments. 20th National Conference ArtificialIntelligence, pp. 509514.Young, H. (1985). Cost allocation. Fair Allocation, 33, 6994.Zuckerman, M., Faliszewski, P., Bachrach, Y., & Elkind, E. (2012). Manipulating quotaweighted voting games. Artificial Intelligence, 180, 119.311fiJournal Artificial Intelligence Research 47 (2013) 95-156Submitted 10/12; published 5/13Distributed ReasoningMultiagent Simple Temporal ProblemsJames C. Boerkoel Jr.boerkoel@csail.mit.eduComputer Science Artificial Intelligence Laboratory,Massachusetts Institute Technology, Cambridge, 02139, USAEdmund H. Durfeedurfee@umich.eduComputer Science Engineering,University Michigan, Ann Arbor, MI 48109, USAAbstractresearch focuses building foundational algorithms scheduling agents assist people managing activities environments tempo complex activityinterdependencies outstrip peoples cognitive capacity. address critical challengereasoning individuals interacting schedules efficiently answer queriesmeet scheduling goals respecting individual privacy autonomy extent possible. formally define Multiagent Simple Temporal Problem naturally capturingreasoning distributed interconnected scheduling problems multiple individuals. hypothesis combining bottom-up top-down approaches leadeffective solution techniques. bottom-up phase, agent externalizes constraintscompactly summarize local subproblem affects agents subproblems,whereas top-down phase agent proactively constructs internalizes new local constraints decouple subproblem others. confirm hypothesisdevising distributed algorithms calculate summaries joint solution spacemultiagent scheduling problems, without centralizing otherwise redistributingproblems. distributed algorithms permit concurrent execution achieve significantspeedup current art also increase level privacy independenceindividual agent reasoning. algorithms advantageous problemsinteractions agents sparse compared complexity agents individualproblems.1. IntroductionComputational scheduling agents assist people managing coordinatingactivities environments tempo, limited view overall problem, complexactivity interdependencies outstrip peoples cognitive capacity. Often, schedulesmultiple agents interact, requires agent coordinate scheduleschedules agents. However, individual agent, user, may strategicinterests (privacy, autonomy, etc.) prevent simply centralizing redistributingproblem. setting, scheduling agent responsible autonomously managingscheduling constraints specified user. concrete example, consider Ann,faces task processing implications complex constraints busy schedule.challenge Ann schedule interdependent schedulescolleagues, family, friends interacts. time, Ann would preferc2013AI Access Foundation. rights reserved.fiBoerkoel & Durfeeindependence make scheduling decisions keep healthy separationpersonal, professional, social lives.Simple Temporal Problem (STP) formulation capable representing scheduling problems where, order pairs activities matters, orderpredetermined. such, STP acts core scheduling problem representationmany interesting planning problems (Laborie & Ghallab, 1995; Bresina, Jonsson, Morris,& Rajan, 2005; Castillo, Fernandez-Olivares, & O. Garca-Perez, 2006; Smith, Gallagher,Zimmerman, Barbulescu, & Rubinstein, 2007; Barbulescu, Rubinstein, Smith, & Zimmerman, 2010). One major practical advantages STP representationmany efficient algorithms compute flexible spaces alternative solutions (Dechter,Meiri, & Pearl, 1991; Hunsberger, 2002; Xu & Choueiry, 2003; Planken, de Weerdt, &van der Krogt, 2008; Planken, de Weerdt, & Witteveen, 2010a). improves robustnessstochasticity real world unreliability human users.instance, STP used schedule morning agendas Ann, friendBill, doctor Chris representing events start time, ST , end time,ET , activity variables, capturing minimum maximum durationstime events constraints. Ann 60 minute recreational activity (RA+B )Bill spending 90 120 minutes performing physical therapy regimen (TR )help rehabilitate injured knee (after receiving prescription left doctorChris); Bill spend 60 minutes recreation (RA+B ) Ann spending 60 180minutes work (W B ); finally, Chris spend 90 120 minutes planning physicaltherapy regimen (TP C ) Ann drop giving lecture (LC ) 10:0012:00. example scheduling problem displayed graphically Figure 1a SimpleTemporal Network (STN)a network temporal constraints variable appearsvertex domain possible clock times described self-loop, constraintsappear weighted edges. Figure 1b represents one example solutionan assignmentspecific times event respects constraints.Suppose Ann, Bill, Chris would like task personal computationalscheduling agent coordinating managing possible schedules accomplish his/her agenda also protecting his/her interests. Unfortunately, current solutionalgorithms solving STPs require representing entire problem single, centralizedSTP, shown Figure 1, order calculate (space of) solution schedule(s)agents. computation, communication, privacy costs associated centralizationmay unacceptable multiagent planning scheduling applications, military,health care, disaster relief, users specify problems agents distributed fashion, agents expected provide unilateral, time-critical, coordinated schedulingassistance, extent possible.motivates first major contribution: formal definition Multiagent Simple Temporal Problem (MaSTP). MaSTP, along associated Multiagent SimpleTemporal Network (MaSTN) distributed representations scheduling problemssolutions. MaSTN corresponding running example displayed Figure 2a. Like centralized counterparts, MaSTPs used help solve multiagentplanning problems monitor multiagent plan execution distributed manner.representation allows person independently specify scheduling problemscheduling agent, allows agent, turn, independently maintain infor96fiDistributed Reasoning Multiagent Simple Temporal Problems8: 00,12: 008: 00,12: 0090,1208: 00,12: 008: 00,12: 0060,60++120,12010: 00,10: 0012: 00,12: 0090,1208: 00,12: 0060,1808: 00,12: 008: 00,12: 008: 00,12: 00(a) example problem represented network temporal constraints.8: 009: 309: 008: 00++10: 0012: 009: 309: 0010: 0011: 00(b) fully assigned point solution example problem.Figure 1: typical, centralized STP representation example problem.mation interrelated activities user. scheduling agent, then, useinformation provide user exact times queried possible timingsrelationships events, without unnecessarily revealing informationagents.second major contribution paper distributed algorithm computingcomplete joint solution space, displayed Figure 2b. leads advicerobust disturbances accommodating new constraints findingsingle joint solutions like Figure 1b. advantage approach newconstraint arrives (e.g., Chris bus late), agents easily recover simply eliminating newly invalidated joint schedules consideration. agents make choicesadjust new constraints, distributed algorithm simply reapplied recomputeresulting narrower space remaining possible joint schedules, subsequentchoices assured also satisfy constraints. long agents wait ramificationschoices/adjustments propagate making choices, eventually convergeschedule works, rather prematurely picking brittle schedule needsreplaced. However, flexibility comes cost ongoing communication, alongcoordinating distributed decisions ensure implications one agents decision propagates another agents decision compatible. example, Anndecides start recreating 8:30, Bills agent must wait decision propagate advising Bill options recreate, otherwise might inadvertentlychoose different time.97fiBoerkoel & DurfeeChris8: 00,12: 008: 00,12: 00Chris90,1208: 00,12: 008:00,12:00Chris8: 00,12: 00Ann8: 00,12: 008: 00,12: 00Ann60,60008: 00,12:8: 00,12:00AnnBill8: 00,12: 00Bill60,60008: 00,12:008: 00,12:Bill60,60008: 00,12:00 60,60 8: 00,12:8: 00,12:008: 00,12:000,060,6060,6090,1200,090,12060,180120,1200,00010:00,10:0012: 00,12:8:00,12:8: 00,12:008: 00,12:008: 00,12:000090,12060,180120,12000,10:0000Example10:Our0012: 00,12:8:00,12:8: 00,12:0000,12:00 60,1808: 00,12:00 disOriginalMaSTP.(a)firstcontributionthe(a)MultiagentSimpleTemporalNetwork 8:representation,allows90,120120,120tributed representation multiagent STPs solutions.10: 00,10: 008: 00,12: 00Example008: 00,12: 00 Bill 8: 00,12: 00Chris12: 00,12: 00 (a) OriginalAnn 8: 00,12:MaSTP.9:00,10:308:00,9:309: 30,10: 008: 00,9: 309: 00,10: 308: 00,8: 30008:00,12:0090,1208: 00,12:308:00,8:ChrisChris90,120009: 30,10:(a) Original ExampleMaSTP.Ann60,608:00,9:30Ann9: 00,10:300,0308: 00,9:BillBill60,60309: 00,10:60,60 9: 00,10: 308:60,15000,9:30 60,60 9: 00,10:8: 00,9:30300,060,6060,6060,1500,090,12060,18060,1500010:00,10:0012: 00,12:9:30,10:11: 00,12:009: 00,11:0010: 00,12:003090,12060,180120,120003010:00,10:0012: 00,12:30,10:11: 00,12:009: 00,11:00 60,18010: 00,12:00(b) 9:Minimal(PPC)Version.90,120120,12090,1209: 30,10: 008:00,8:3090,120120,12010:Our00,10:0012: 00,12: 0030,10: 30 Ann11: 00,12:009: 00,11:00 Billspace10: 00,12:00Chris(b)secondcontribution(b)new9:distributedalgorithmcomputingcompletesolutionsMinimal(PPC)Version.9:45,9:458:45,8:459:30,10:008:45,8:459:45,9:45to8:an00,8:MaSTP.30308:00,8:ChrisChris90,120009: 30,10:90,1209: 30,10: 008:00,8:3090,120120,1200010:00,10:0012: 00,12:120,1200010:00,10:0012: 00,12:120,120(b) MinimalAnn(PPC) Version.60,60459: 45,9:8:45,8:45Ann8:60,10545,8:45 60,60 9: 45,9:4560,6060,10590,12060,10510:00,10:3011: 30,12:0090,12010:00,10:3090,12011:Version.30,12:00(c)Decoupled458: 45,8:BillBill60,60459: 45,9:60,60 9: 45,9: 458: 45,8:4560,6060,1359: 45,11:0010: 45,12:0060,135009: 45,11:60,13510: 45,12: 0010: 00,10: 0010: 00,10:30Ann11:Version.30,12: 009: 45,11: 00 Bill 10: 45,12: 00Chris12: 00,12: 00 (c)Decoupled9: 008: 009: 308: 009: 008: 00(c) thirdChriscontribution new(c)distributedtemporaldecoupling algorithm computingDecoupledAnn Version.Bill locally independent00solution spaces.00009:009:308:9:008:8:AnnChrisBill9: 00Figure 2: summaryour8:contributionsappliedexample problem.9: 308:009: 008:000010:0012:0010:0012:0010: 0012: 009:0010:009:30 Assigned00(d) FullyVersion.98 11:9:0010:009: 3000(d) FullyAssigned11:Version.(d) Fully Assigned Version.9: 0010: 009:3011:00fiDistributed Reasoning Multiagent Simple Temporal Problemsmotivates third major contribution: distributed algorithm computingtemporal decoupling. temporal decoupling composed independent spaceslocally consistent schedules that, combined, form space consistent joint schedules(Hunsberger, 2002). example temporal decoupling displayed Figure 2c, where,example, Chris agent agreed prescribe therapy regimen 10:00 Annsagent agreed wait begin performing 10:00. Here,agents advice independent agents, temporal decoupling also providesagents resiliency new constraints enhances users flexibility autonomymaking scheduling decisions. Chris bus late minute, Chrisagent absorb new constraint independently updating local solution space.advantage approach agents establish temporal decoupling,need communication unless new constraint renders chosen decouplinginconsistent. temporal decoupling become inconsistent (e.g.,Chris bus half hour late, causing violate commitment finishprescription 10:00) agents must calculate new temporal decoupling (perhapsestablishing new hand-off deadline 10:15), independently reactnewly-arriving constraints, repeating process necessary.rest paper structured fully describe contributions.Section 2 builds foundational background necessary understanding contributions.Section 3 formally defines MaSTP explains important properties corresponding MaSTN. Section 4 describes distributed algorithm computing complete MaSTPsolution spaces, analytically proving algorithms correctness runtime properties,empirically demonstrating speedup achieves previous centralized algorithms.Section 5 describes distributed algorithm decoupling MaSTP solution spaces,proving algorithms correctness runtime properties, empirically comparingperformance previous art demonstrate trade-offs completeness versus independence reasoning. give overview related approaches Section 6 concludediscussion Section 7.2. Backgroundsection, provide definitions necessary understanding contributions, usingextending terminology previous literature.2.1 Simple Temporal Problemdefined Dechter et al. (1991), Simple Temporal Problem (STP), = hX, Ci,consists set n timepoint variables, X, set temporal difference constraints,C. timepoint variable represents event continuous domain values (e.g.,clock times) expressed constraint relative special zero timepointvariable, z X, represents start time. temporal difference constraint cijform xj xi bij , xi xj distinct timepoints, bij R {}real number bound difference xj xi . Often, notational convenience,two constraints, cij cji , represented single constraint using bound intervalform xj xi [bji , bij ].99fiBoerkoel & DurfeeAnnAvailabilityRSTz [480, 720]RETz [480, 720]TR ST z [480, 720]TRET z [480, 720]BillBRSTz [480, 720]BRETz [480, 720]BWSTz [480, 720]BWETz [480, 720]ChrisTP CST z [480, 720]TP CET z [480, 720]LCST z [600, 600]LCET z [720, 720]DurationOrderingRETRST[60, 60]ExternalBRSTRST[0, 0]RETRST0TRET RST [90, 120]TP CET RST 0BBRETRST[60, 60]BBRETWST0BRSTRST[0, 0]CTP CET LST 0TP CET RST 0BBWETWST[60, 180]CTP CET PST [90, 120]CLCET LST [120, 120]Table 1: Summary constraints running example problem.schedule assignment specific time values timepoint variables. STPconsistent least one solution, schedule respects constraints.Table 1, formalize running example (introduced Section 1) specificconstraints. activity two timepoint variables representing start time (ST )end time (ET ), respectively. example, activities scheduledmorning (8:00-12:00), constrained (Availability column) take place within 480720 minutes zero timepoint z, case represents midnight. Durationconstraints specified bounds difference activitys end timestart time. Ordering constraints dictate order agents activities musttake place respect other. Finally, formal introduction externalconstraints deferred later (Section 3), last column represents constraintsspan subproblems different agents. Figure 1b illustrates schedule representssolution particular problem.2.2 Simple Temporal Networkexploit extant graphical algorithms (e.g., shortest path algorithms) efficiently reason constraints STP, STP associated Simple Temporal Network (STN), represented weighted, directed graph, G = hV, Ei, calleddistance graph (Dechter & Pearl, 1987). set vertices V contains vertex vitimepoint variable xi X, E set directed edges, where, constraintcij form xj xi bij , directed edge eij vi vj constructed initialweight wij = bij . graphical short-hand, edge vi vj assumedbi-directional, capturing edge weights single interval label, [wji , wij ],100fiDistributed Reasoning Multiagent Simple Temporal Problemsvj vi [wji , wij ] wij wji initialized exists correspondingconstraint cij C cji C, respectively. STP consistent existnegative cycles corresponding STN distance graph.reference edge, ezi , timepoint vi edge vi zero timepoint z. another short-hand, reference edge ezi represented graphicallyself-loop vi . self-loop representation underscores reference edge eizthought unary constraint implicitly defines vi domain, wzi wizrepresent earliest latest times assigned vi , respectively. work,assume z always included V that, construction G,reference edge ezi added z every timepoint variable, vi Vz .graphical STN representation example STP given Table 1 displayedFigure 2a. example, duration constraint TRET RST [90, 120] representedgraphically directed edge TRST TR ET label [90, 120]. NoticeBBlabel edge RET WST infinite upper bound, since Billmust start work ends recreation, corresponding constraint givensoon ends recreation must occur. Finally, constraint LCST z,label[10:00,10:00],represents[600, 600] translated unary loop LCSTChris constrained start lecture exactly 600 minutes midnight (orexactly 10:00 AM). Throughout work, use STP STN notation.distinction STP notation captures properties original problem,pair variables constrained bounds, whereas STN notation convenient,graphical representation STP problems agents algorithmically manipulateorder find solutions by, example, capturing implied constraints new tightenededges graph.2.3 Useful Simple Temporal Network PropertiesTemporal networks minimal decomposable provide efficient representationSTPs solution space useful advice-giving scheduling agents.2.3.1 Minimalityminimal edge eij one whose interval bounds, wij wji , exactly specify setvalues difference vj vi [wji , wij ] part solution (Dechteret al., 1991). temporal network minimal edges minimal.minimal network representation solution space STP. example, Figure 2bminimal STN, whereas Figure 2a not, since would allow Ann start recreationat, say, 9:31 Figure 2c also not, since allow Ann start 9:30.practically, scheduling agent use minimal representation exactly efficientlysuggest scheduling possibilities users without overlooking options suggesting optionswork.2.3.2 DecomposabilityDecomposability facilitates maintenance minimality capturing constraints that,satisfied, lead global solutions. temporal network decomposableassignment values subset timepoint variables locally consistent (satisfies101fiBoerkoel & Durfeeconstraints involving variables) extended solution (Dechter et al.,1991). STN typically made decomposable explicitly adding otherwise implicitconstraints and/or tightening weights existing edges variable domainsprovably consistent values remain. example, Figure 1b trivially decomposable, sinceassigning variable single value within minimal domain assures partsolution. Figure 2b, hand, decomposable, since, instance,= 10:30 TR = 11:00, self-consistent (becauseassignment RETETconstraints directly link two variables), cannot extended full solution.scheduling agent use decomposable temporal network directly propagatenewly-arriving constraint area network single-step, backtrack-freemanner.sum, STN minimal decomposable represents entire setsolutions establishing tightest bounds timepoint variables (i) solutions eliminated (ii) self-consistent assignment specific times subsettimepoint variables respects bounds extended solution efficient,backtrack-free manner.2.4 Simple Temporal Problem Consistency Algorithmssubsection, highlight various existing algorithms help establish STNsolution properties introduced previous subsection.2.4.1 Full Path ConsistencyFull Path Consistency(FPC) establishes minimality decomposability STPinstance n3 time (recall n = |V |) applying all-pairs-shortest-path algorithm,Floyd-Warshall (1962), STN, resulting fully-connected distance graph(Dechter et al., 1991). Floyd-Warshall algorithm, presented Algorithm 1, findstightest possible path every pair timepoints, vi vj , fully-connecteddistance graph, i, j, k, wij wik + wkj . graph checked consistencyvalidating negative cycles, is, 6= j, ensuring wij + wji 0.example FPC version Anns STP subproblem presented Figure 3a. Noteagent using FPC representation provide exact bounds valueslead solutions pair variables, regardless whether correspondingconstraint present original STP formulation.2.4.2 Graph Triangulationnext two forms consistency require triangulated (also called chordal) temporalnetwork. triangulated graph one whose largest non-bisected cycle triangle (oflength three). Conceptually, graph triangulated process considering verticesadjacent edges, one one, adding edges neighbors currentlyconsidered vertex edge previously existed, eliminating vertexconsideration, vertices eliminated (Golumbic, 1980). basic graphtriangulation process presented Algorithm 2. set edges addedprocess called fill edges order timepoints eliminatedconsideration referred elimination order , o. Figure 3b shows topology102fiDistributed Reasoning Multiagent Simple Temporal ProblemsAlgorithm 1: Floyd-WarshallInput: fully-connected distance graph G = hV, EiOutput: FPC distance graph G inconsistent1 k = 1 . . . n2= 1 . . . n3j = 1 . . . n4wij min(wij , wik + wkj )5wij + wji < 06return inconsistent7return GAlgorithm 2: TriangulateInput: distance graph G = hV, Ei; elimination order = (v1 , v2 , . . . , vn1 , vn )Output: triangulated distance graph G1 k = 1 . . . n2forall i, j > k s.t. eik , ejk E3E E {eij }4return Gtriangulated version Anns distance graph timepoints eliminated order, RA , RA , RA ).= (T RETETSTSTquantity induced graph width distance graph relative o,defined maximum, vk , size vk set not-yet-eliminated neighborstime elimination. triangulate algorithm, then, operates n o2 time.Elimination orders often chosen attempt find minimal triangulation,attempt minimize total number fill edges. While, generally speaking, findingminimum triangulation graph NP-complete problem, heuristics minimumdegree (selecting vertex fewest edges) minimum fill (selecting vertexadds fewest fill edges) used efficiently find elimination orders approximateminimum triangulation (Kjaerulff, 1990).2.4.3 Directional Path Consistencyalternative FPC checking STP consistency establish Directional PathConsistency (DPC) temporal network. DPC algorithm (Dechter et al., 1991),presented Algorithm 3, takes triangulated graph corresponding elimination order,o, input. traverses timepoint, vk , order o, tightening edgespair neighboring timepoints, vi , vj , (where vi vj connected vk via edges eikejk respectively) appear vk ordero, using rule wij min(wij , wik +wkj ). time complexity DPC n o2 , instead establishing minimality,establishes property solution recovered DPC distance graphbacktrack-free manner variables assigned reverse elimination order. example103fi[60,150][60,90,1209: 00,10: 309: 00,10: 3060,60[60,150][90,180]90,1209: 00,10: 30Boerkoel & Durfee10: 30,12: 00Ann8: 00,9: 3010: 30,12: 00(a) Anns FPC STN.90,1209: 00,10: 308: 00,11: 00Ann8: 00,12: 0060,609: 00,10: 3060,60[60,150][60,8: 00,12: 00Ann8: 00,9: 3090,1209: 00,10: 308: 00,12: 00(b) Anns DPC STN.90,1209: 00,10: 3010: 30,12: 00(c) Anns PPC STN.Figure 3: Alternative forms Annconsistency applied Anns STP.Ann9: 00,10: 308: 00,9: 308: 00,9: 309: 00,10: 3060,6060,60Algorithm 3: Directional Path Consistency(DPC)Input: triangulated temporal [60,150]network G = hV, Ei corresponding elimination[60,150][90,180]order = (v1 , v2 , . . . , vn1 , vn )Output: DPC distance graph Ginconsistent90,1201 k = 1 . . . n90,1209: 00,10: 3010: 30,12: 002forall > k s.t. eik E9: 00,10: 3010: 30,12: 003forall j > s.t. ejk E4wij min(wij , wik + wkj )5wji min(wji , wjk + wki )Ann6wij + wji < 09: 00,10: 308: 00,9: 307return inconsistent8return G60,60[60,150][90,180], RA , RA , RA ),90,120DPC version Anns problem, using elimination order = (T RETETSTSTpresented Figure 3b. Basically,establishingDPC00sufficient establishing whether9: 00,10:3010:30,12:consistent schedules exist not, limits scheduling agent giving useful advicelast variable eliminated.Section 4.1, discuss combine reasoning DPC triangulatealgorithms execution distributed. Combining reasoning yieldsexample bucket-elimination algorithm. Bucket-elimination algorithms (Dechter,1999) general class algorithms calculating knowledge compilations, solutionspace representations solutions extracted backtrack-free, linear-timemanner. adaptive consistency algorithm (Dechter & Pearl, 1987; Dechter, 2003)calculates knowledge compilation general constraint satisfaction problems (Dechter,1999). Adaptive consistency eliminates variables one one, variableeliminates, reasons bucket constraints variable involved deducenew constraints remaining non-eliminated variables. solution remain104fiDistributed Reasoning Multiagent Simple Temporal ProblemsAlgorithm 4: Plankens Partial Path Consistency (P3 C)Input: triangulated temporal network G = hV, Ei elimination order= (v1 , v2 , . . . , vn1 , vn )Output: PPC distance graph G inconsistent1 G DP C(G, o)2 return inconsistent DPC3 k = n . . . 14forall i, j > k s.t. eik , ejk E5wik min(wik , wij + wjk )6wkj min(wkj , wki + wij )7return Ging subproblem extended solution original problem, since solutionaccounts constraints entailed eliminated variable. DPC important stepestablishing Partial Path Consistency, discuss next.2.4.4 Partial Path ConsistencyBliek Sam-Haroud (1999) demonstrate Partial Path Consistency (PPC)sufficient establishing minimality STP instance calculating tightest possiblepath subset edges exist within triangulated distance graph.example Xu Choueirys algorithm 4STP (Xu & Choueiry, 2003), processesupdates queue potentially inconsistent triangles (4) triangulatedgraph. Alternatively, algorithm P3 C, Planken et al. (2008) sweeptriangles systematic order, gives guaranteed upper bound runtime,bound known 4STP. P3 C algorithm, included Algorithm 4executes DPC algorithm first phase executes reverse traversalDPC algorithm second phase, edge weights updatedreverse eliminationorder. Thus P3 C achieves complexity, n o2 , DPC algorithm.exploiting sparse network topology, PPC-based algorithmsmay establish minimality muchfaster FPC algorithms practice (O n o2 n3 ) (Xu & Choueiry, 2003;Planken et al., 2008). PPC representation Anns subproblem using elimination, RA , RA , RA ) displayed Figure 3c.order = (T RETETSTSTPPC approximates decomposability since assignments fully-connected subsets variables (those belong clique triangulated network)guaranteed extensible full solution. However solutions still recoveredbacktrack-free manner either requiring constraint propagation subsequentvariable assignment assigning variables reverse simplicial elimination order elimination order variables yields triangulated network (thatis, introduces new fill edges) (Planken et al., 2008). agent using PPC representation offer advice pair variables share edge triangulatedgraphthose originally related via constraint original formulationconnected fill edges. While, unlike FPC temporal networks, agent using105fiBoerkoel & DurfeePPC network cannot answer queries regarding arbitrary pairs variables (i.e.,share edge), sparser PPC structure important benefits agentsindependent private reasoning, discussed Section 3.1.2.2.5 Temporal Decoupling ProblemHunsberger (2002) formally defined concept temporal decoupling STPs.partitioning STP Ss variablesV Bff, leads naturallyAintoA fftwo sets,B VBdefinition two sub-STPs, = V , C= V , C B , C C Bconstraints defined exclusively variables V V B , respectively.B form temporal decoupling if:B consistent STPs;Merging locally consistent solutions problems B yields solutionS.Notice temporal decoupling exists original STP consistent.Alternatively, B form temporal decoupling S, B saidtemporally independent. Temporal Decoupling Problem (TDP), then, definedB , C C B combinedfinding two sets decoupling constraints,CA ffand CBffBB respectively,form = V , C C = V B , C B CB form temporal decoupling STP S. minimal decoupling one where,C B relaxed (increasingbound decoupling constraint either Cbound constraint inclusive) removed, B longerform decoupling. original TDP algorithm (Hunsberger, 2002) executes centrallyC B propagatingiterates proposing new constraints add Cconstraints reestablish FPC corresponding global distance graphsubsequently proposed decoupling constraints guaranteed consistent. iterationoccurs constraint spans B constraintsrendered moot due new decoupling constraints.temporal decoupling trades complete solution space possibly messy interdependencies partial solution space nice independence properties. Independentreasoning, critical applications must provide time-critical, unilateralscheduling advice environments communication costly uncertain, comescost eliminating valid joint solutions. Section 4.3, present various flexibilitymetrics quantify portion solution space retained given temporaldecoupling, use quantify trade-off.3. Multiagent Simple Temporal Problemproblem paper addresses developing compact, distributed representation of, distributed algorithms finding (a temporal decoupling of) jointsolution space of, multiagent scheduling problems. section formally defines distributed representation form Multiagent Simple Temporal Problem, extendsdefinitions minimality decomposability representation, characterizesindependence privacy within representation. Sections 4 5 describe106fiDistributed Reasoning Multiagent Simple Temporal Problemsdistributed algorithms find either complete temporally decoupled solution spacesproviding users flexible sound scheduling alternatives. algorithms avoidunnecessarily centralizing redistributing agents subproblems also achieve significantspeedup current state-of-the-art approaches.3.1 Multiagent Simple Temporal Problem FormulationMultiagent Simple Temporal Problem (MaSTP) composed local STPsubproblems, one agents, set constraints CX establishrelationships local subproblems different agents (Boerkoel & Durfee,2010,ff2011; Boerkoel, 2012). agent local STP subproblem defined SL = VL , CLi 1 ,where:VLi defined agent set local variables, composed timepointsassignable agent along variable representing agent reference z;CLi defined agent set intra-agent local constraints, localconstraint, cij CLi , defined bound bij difference two localvariables, vj vi bij , vi , vj VLi .Figure 2a, variables constraints entirely within boxes labeled Chris, Ann,Bill represent persons respective local STP subproblem running example.Notice, sets VLi partition set (non-reference) timepoint variables, Vz .CX set inter-agent external constraints, external constraintdefined bound difference two variables local differentagents, vi VLi vj VLj , 6= j. However, agent knows subsetexternal constraints involve local timepoints and, by-product externalconstraints, also aware subset non-local variables, where:agent set external constraints, involves exactly oneCXagent local timepoint variables (since constraints inherently binary);VXi agent set external timepoint variables, local.agent j 6= i, known agent due external constraint CXsetsexternal variablesofi external constraints CX = CX setVX = VX . Together, agent set known timepoints VLi VXi set known. Note assumes constraint known agentconstraints CLi CXleast one variable involved constraint. Figure 2a, external constraintsvariables denoted dashed edges.then, MaSTP,formally,M, defined STP = hVM , CMVM = VL CM = CX CL .1. Throughout paper, use superscripts index agents subscripts index variablesconstraints/edges.107fiBoerkoel & DurfeeFigure 4: High-level overview MaSTP structure.3.1.1 Minimality Decomposabilitypoint, discussed MaSTP problem formulation. However, also discuss properties corresponding Multiagent Simple Temporal Network (MaSTN). MaSTP converted equivalent MaSTN waySTP converted STN, definition agent local external edges,, follows analogously definition C C , respectively. LikeELi EXXLSTN, MaSTN algorithmically manipulated represent useful information.Here, discuss STN properties minimality decomposability translateMaSTN.MaSTNdecentralized one), properties(a) STN (albeit (b)(c) minimalitydecomposability extend unhindered multiagent temporal networks. Thus, minimalMaSTN one edges minimal. Likewise, MaSTN decomposableself-consistent assignment values subset variables extended fulljoint solution.Calculating MaSTN minimal decomposable requires computingfully-connected network, which, multiagent setting, clobbers independenceagents subproblems: agents timepoints connected everytimepoint every agent. Full connectivity obliterates privacy (since v VLi , vVXj j 6= i) requires every scheduling decision coordinated among agents.reason, work focuses instead establishing partial path consistency approximatedecomposability retaining loosely-coupled structure may exist MaSTN.3.1.2 Algorithm-Centric MaSTP Partitioning(a)(b)MaSTP formalization presented naturally captures MaSTPs using agent-centricperspective. However, algorithmically, often easier discuss MaSTP termsparts problem agent solve independently, parts require sharedeffort solve. Thus, introduce additional terminology helps improveprecision comprehension algorithmic descriptions analyticalarguments.108fiDistributed Reasoning Multiagent Simple Temporal Problems(a)(a) agent external, interface, private timepoints.(b)(b) Local vs. External.(c)(c) Private vs. Shared.Figure 5: Alternative partitionings agents STP.natural distribution MaSTP representation affords partitioningMaSTP independent (private) interdependent (shared) components. startdefining shared STP, SS = hVS , CS i, composed of:VS = VX {z}the set shared variables comprised variablesinvolved least one external constraint;CS = {cij | vi , vj VS }the set shared constraints defined constraintspairs shared variables, includes entire set external constraintsCX , could also include otherwise local constraints exist two sharedvariables belonging single agent.Notice that, illustrated Figure 4, shared STP overlaps agents local, three distinct sets:(a) agent known timepoints, V (b)subproblem, thus dividesVXi agent set external variables, defined before;VIi = VLi VS agent set interface variables, defined agent setlocal variables involved one external constraints;VPi = VLi \ VS agent set private variables, defined agent localvariables involved external constraints.three sets variables depicted graphically Figure 5a. Figure 5 also highlights two alternate partitionings MaSTP agent-centric local versus externalcomponents (Figure 5b) algorithm-centric independent (private) versus interdependent(shared) components (Figure 5c). formally, allows us define agent private109fiBoerkoel & Durfeeffsubproblem, SPi = VPi , CPi , agent set private constraints, CPi = CLi \ CS ,subset agent local constraints include least one private variables.partitioning depicted Figure 5c useful algorithmically establishesparts agents subnetwork independent agents (private),parts inherently interdependent (shared). Notice agent local constraintsincluded private subproblem long include private variable, evenalso involve shared variable. agent able propagate changesconstraint, private constraint, without directly affecting shared timepointconstraint. Private edges connected shared timepoint appear hang Figure 5cshared timepoint actually part shared subproblem.3.1.3 IndependenceAlgorithms use distributed MaSTN representation reason scheduling problems span multiple agents strategic (e.g., privacy) computational (e.g., concurrency) advantages. extent advantages realized largely dependslevel independent reasoning agent able perform local problem. define two timepoints independent path connectsMaSTN, dependent otherwise. Notice dependencies agentsinherently flow set shared variables, VS . implication agentindependently (and thus concurrently, asynchronously, privately, autonomously, etc.)reason private subproblem SPi independently SPj j 6= i.Theorem 1. dependencies agent local subproblem, SLi , anotheragent js (j 6= i) local subproblem SLj , exist exclusively shared STP, SS .Proof. contradiction, assume exist variables vi VPi vj VPj vivj independent given SS . implies exists path constraintnetwork vi vj involves pair private variables vi0 VPi vj0 VPjconnected via constraint. However, contradiction, since vi0 vj0 would,definition, belong VS , thus SS . Therefore, every pair variables vi VPivj VPj independent given SS .3.1.4 Privacywork, assume agents cooperative. However, time, usermay still wish avoid gratuitous revelation details scheduleagents people, extent possible. next look privacy preservedbyproduct distributed problem representation level independent reasoningestablished Theorem 1. Obviously, coordination agents activitiesinherent privacy costs. However, show costs limited sharedtimepoints edges them.Notice Figure 2a variable Anns Bills agent starts knowing, due Bills shared constraint Ann. However,recreational start time variable RSTAnns agent establish PPC using variety different elimination orderings, Annsagent alone cannot establish PPC timepoints without adding new external edges.Anns problem contains two different externally constrained timepoints110fiDistributed Reasoning Multiagent Simple Temporal Problemsshare local constraint path, regardless elimination order used. So, exampleAnns agent eliminate private timepoints (TRET RET ), triangulation process would construct new external edgeeliminate RSTBshared timepoints TRST RST shown Figure 2b. effectively adds TR STBills agents set external timepoints. TR ST already shared Chrisshared edge, triangulation processagent, fill edge RSTallows Bills agent become aware shared components Anns problem.question becomes: Bills agent continue process draw inferencesAnns private timepoints edges? Theorem 2 shows that, without exogenous sourceinformation, agent able infer existence of, number of, boundsanother agents private timepoints, even implicitly influence agents subproblemshared constraint paths.Theorem 2. agent infer existence bounds another agents private edges,subsequently existence private timepoints, solely shared STN.Proof. First, prove existence bounds private edge cannot inferredshared STN. Assume agent private edge, eik EPi . definition, leastone vi vk private; without loss generality, assume vi VPi . every pairedges eij ejk capable entailing (the bounds of) eik , regardless whether vjshared private, vi VPi implies eij EPi private. Hence, pair edges capableimplying private edge must also contain least one private edge. Therefore, privateedge cannot inferred shared edges alone.Thus, since agent cannot extend view shared STN include another agentsprivate edges, cannot infer another agents private timepoints.Theorem 2 implies SS (the variables constraints representeddashed lines Figure 2b) represents maximum portion MaSTP agentsinfer without exogenous (or hypothesized) source information, even colludereveal entire shared subnetwork. Hence, given distribution MaSTP M,agent executes multiagent algorithm reveal private timepointsconstraints, guaranteed agent j 6= able infer privatetimepoint VPi private constraint CPi also executing multiagent algorithmatleast without requiring conjecture ulterior (methods inferring) informationpart agent j. generally, necessary inevitable one agent knowsinfers entire shared STP SS .3.2 Multiagent Temporal Decoupling Problemnext adapt original definition temporal decoupling (Hunsberger, 2002) described Section 2.5 apply MaSTP. set agents local STP subproblems{SL1 , SL2 , . . . , SLn } form temporal decoupling MaSTP if:{SL1 , SL2 , . . . , SLn } consistent STPs;Merging combination locally-consistent solutions problems{SL1 , SL2 , . . . , SLn } yields solution M.111fiBoerkoel & Durfee(a)(b)(a)(c)(b)Figure 6: temporal decoupling problem calculates new local constraints renderconstraints agents superfluous.Alternatively, {SL1 , SL2 , . . . , SLn } form temporal decoupling M, saidtemporally independent. illustrated Figure 6, objective MultiagentTemporal Decoupling Problemfind set constraints C(MaTDP)ff12nagent SL+ = VL , CL C , {SL+ , SL+ , . . . , SL+ } temporaldecoupling MaSTP M. Note solving MaTDP mean agentssubproblems somehow become inherently independent (with respectoriginal MaSTP), rather new decoupling constraints provide agentsway perform sound reasoning completely independently other., depicted dotted lines right-hand sideNotice new constraints, CFigure 6, allow safe removal superfluous external constraints involving agentlocal variables, external constraints also removed figure. Finally, notice local variables edges previously part shared problem (markedright-hand side Figure 6 double edges) treated algorithmicallyprivate. Figure 1b Figure 2c represent temporal decouplings example,new tighter unary decoupling constraints, essence, replace external edges(shown faded). minimal decoupling one where, bound decoupling coni agent relaxed (or removed), {S 12nstraint c CL+ , SL+ , . . . , SL+ }longer decoupling. Figure 2c example minimal decoupling whereas defacto decoupling formed full assignment (such one Figure 1b) minimal.4. Distributed Algorithms Calculating Partial Path Consistencysection, introduce Distributed Partial Path Consistency (D4PPC) algorithmestablishing PPC MaSTN. illustrated Figure 7, algorithm workssolving a+1 subproblems: private agent subproblems one shared STP. Likeoriginal P3 C algorithm (Algorithm 4 page 105), subproblems solved112fiDistributed Reasoning Multiagent Simple Temporal Problems9: 30,10: 0090,1208: 00,11: 00Ann8: 00,12: 0060,60Bill8: 00,12: 008: 00,12: 0060,60[60, )120,12010: 00,10: 0012: 00,12: 0090,1208: 00,12: 008: 00,10: 3060,1808: 00,12: 008: 00,12: 00Phase 2: Eliminate Shared Timepoints0,09: 30,10: 00Chris[60, )8: 00,11: 00Ann[60, )9: 30,10: 30DPPC (Algorithm 8)[0, )Shared STN8: 00,9: 30BillPhase 3: Reinstate Shared Timepoints[0,60]Shared STN9: 30,10: 00Chris0,0[60,150]8: 00,9: 30Ann[60,150]9: 30,10: 308: 00,9: 30BillChris9: 30,10: 0090,120Ann8: 00,9: 309: 00,10: 3060,608: 00,9: 300,0Bill9: 00,10: 3060,6060,150120,12010: 00,10: 0012: 00,12: 0090,1209: 30,10: 3011: 00,12: 009: 00,11: 0060,18010: 00,12: 00PPC (Algorithm 6)Phase 4 - Reinstate Private Timepoints8: 00,8: 30Figure 7: distributed PPC algorithms operate four distinct phases.113DDPC (Algorithm 7)Chris8: 00,12: 00DPC (Algorithm 5)Phase 1: Eliminate Private TimepointsfiBoerkoel & Durfeetwo phases: forward sweep eliminates timepoints compute implied constraintsestablish DPC second, reverse sweep reinstates nodes updates incident edgesestablish full minimality PPC. order maximize concurrency independencedistributed version algorithm, carefully partition execution four phases.Agents work together perform forward (Phase 2, Figure 7) reverse (Phase 3,Figure 7) sweeps P3 C algorithm respectively shared STP, agentindependently performs forward (Phase 1, Figure 7) reverse (Phase 4, Figure 7)sweeps P3 C algorithm private subproblem.Section 4.1, introduce 4DPC 4PPC algorithms, servesubroutines D4PPC algorithm establish DPC PPC agents privatesubproblem 4DPC algorithm tweaks original DPC algorithm agentindependently triangulate establish DPC private portion subproblem (Phase 1). Then, later Phase 4, agent executes 4PPC reinstate privatetimepoints complete process establishing PPC private subproblem. Next,Section 4.2.1, describe D4DPC algorithm carefully distributes execution4DPC algorithm that, separately establishing DPC private STNs,agents work together triangulate update remaining shared portion MaSTNglobally consistent manner, thus establishing DPC MaSTN whole (Phases1 2). Finally, present overarching D4PPC algorithm Section 4.2.2.agent executes D4PPC separately. D4PPC first invokes D4DPC establish DPCMaSTN (Phases 1 2), executes distributed version 4PPCs reverse sweepagents cooperatively establish PPC shared portion MaSTN (Phase3), finally invokes 4PPC finish PPC establishment agents separate privatesubproblem (Phase 4). conclude section proving that, despite distributionexecution, algorithms maintain correctness (Section 4.2.3), empirically demonstrating that, result concurrent execution, D4PPC algorithmachieves high levels speedup centralized counterparts (Section 4.3).4.1 Centralized Partial Path Consistency RevisitedDPC (Algorithm 3 page 104) P3 C (Algorithm 4 page 105) algorithmstake variable-elimination ordering already triangulated STN input. However,aim decentralize algorithm execution, requiring already triangulated networkcomplete variable elimination order punts providing distributed solutioncritical algorithmic requirement best, requires centralized representation entirenetwork worst, thus invalidating many motivations distribution firstplace. Hence, point section demonstrate graph triangulationprocess elimination order construction process incorporated DPCalgorithm, whose execution later distribute, added computational overhead.Observe triangulation (Algorithm 2 page 103) DPC algorithms endtraversing graphs exactly order, processing combined.4DPC algorithm (Algorithm 5) result modifying DPC algorithm basedtwo insights: (i) 4DPC construct variable elimination order executionapplying SelectNextTimepoint procedure (line 3), heuristically choosesnext timepoint, vk , eliminate; (ii) 4DPC considers implications114fiDistributed Reasoning Multiagent Simple Temporal ProblemsAlgorithm 5: Triangulating Directional Path Consistency (4DPC)Input: STN G = hV, EiOutput: triangulated, DPC STN G corresponding elimination order= (v1 , v2 , . . . , vn1 , vn ), inconsistent1 ()2 |V | > 03vk SelectNextTimepoint(hV, Ei , o)4V V \ {vk }5o.append(vk )6forall vi , vj V s.t. eik , ejk E7E E {eij }8wij min(wij , wik + wkj )9wji min(wji , wjk + wki )10wij + wji < 011return inconsistent12return G,pair temporal difference constraints involving removed timepoint variable, necessarily considers exact fill edges triangulation process would added. 4DPCrequires original distance graph representation STN, G input. Line 7 adds,necessary, newly-created fill edges vk non-eliminated neighborsproceeds propagate implications eliminated timepoints constraints forwardlines 89. Like DPC algorithm, 4DPC halts soon detects inconsistency(line 11). Incorporating triangulation process 4DPC algorithm reducesproblem distributing DPC graph triangulation algorithms distributing execution 4DPC algorithm alone. 4DPC algorithm examplebucket-elimination algorithm property elimination process couldstop point, solution remaining subproblem guaranteed extensible full solution involving eliminated timepoints. Thus, solution derivedDPC network assigning timepoints reverse elimination order.example, consider Anns agent, refer agent A, executing 4DPCalgorithm Anns subproblem (see Figure 8a). algorithm starts using minimumfill heuristic select variable TRET elimination adds TR ET elimination order.Next agent loops pair TRET neighbors. case onepair neighboring edges: unary edge, represented algorithmicallyedge shared reference timepoint z, edge TRST . Together, edgesimply tighter unary constraint TR ST , lowering upper bound 10:30guaranteed occur least 90 minutes eliminated TRET . eliminatingvalues TR ST domain inconsistent TR ET , agent guaranteedsolution remaining (non-eliminated) subproblem exists, solution extensibleinclude TRET .elimination. case notice RA involvedNext agent selects RETETpath RST TR ST . addition updating domains neighboring timepoints,115fiBoerkoel & DurfeeAnn8: 00,12: 00Ann 8: 00,12: 00008: 00,12:00 60,60 8: 00,12:60,6090,1208: 00,12:0090,1208: 00,12:008: 00,12: 00Ann8: 00,12: 00Ann008: 00,12:00 60,60 8: 00,12:60,6090,1208: 00,10:308: 00,12:008: 00,11: 00 Ann8: 00,12: 008: 00,12: 008: 00,11: 00 Ann8: 00,12:00 60,60 8: 00,12:0060,60[60,[60,90,12090,1208: 00,10: 3090,1208: 00,12: 008: 00,12: 008: 00,10: 308: 00,12: 008: 00,12: 008: 00,12: 008: 00,12: 008:and00,10:30 eliminating8:00,12:00(a)forward1:sweep4PPC(4DPC) works applyselecting DPCtimepoint,(a)ThePhaseAgentsindependentlylocalsubproblem.consideration, calculating constraints implied remaining neighbors.(a) PhaseAnn1: Agents independentlyAnnapply DPC localsubproblem.9: 00,10: 30Ann8: 00,9: 30Ann 9: 00,10: 30308: 00,9:30 60,60 9: 00,10:60,6060,15060,15090,1208: 00,9:30 60,60 9: 00,10:3060,60[60,150]8: 00,12: 009: 00,10: 3060,608: 00,12: 008: 00,9:3060,60[60,150][60,150][60,150]8: 00,9: 30Ann9: 00,10: 3090,1200011: 00,12:9: 30,10:3090,12011: 00,12:009: 30,10: 3090,1208: 00,12: 0011: 00,12: 009: 30,10: 3011: 00,12: 009:30,10:308: 00,12:00(b) Phase 4: Agents independently applyPPC8: 00,9: 30Ann90,1209: 30,10: 3090,1208: 00,12: 008: 00,12: 009: 30,10:30 subproblem.local(b)Phase4: AgentsindependentlyPPC intoreversetheirorder,localsubproblem.(b)reverse sweep4PPCworks reinstatingapplytimepointtighteningincidentedges respect newly-updated, explicit constraints neighbors.Figure 8: Agent executing two-part 4PPC Anns private subproblem.viewed first (a) last (b) phases overall D4PPC algorithm.TR involving RA . guaranteeagent must also capture path RSTSTETTR ,integrity path retained, agent adds fill edge RSTSTlower bound 60 infinite upper bound (as implied path). addition filledges reason output 4DPC triangulated network. Note typicallyminimum fill heuristic would select variables add fill edges selecting onesdo, explain Section 4.2.1, improve concurrency, restrict agenteliminating private timepoints prior shared timepoints.4DPC completes, remaining, non-eliminated timepoints involved external constraints, addressed distributed algorithms described shortlySection 4.2. turning distributed algorithms, however, first describe4PPC, agent apply complete computation PPC privatesubproblem Phase 4. 4PPC algorithm, included Algorithm 6, nearly identicallyfollows original P3 C algorithm, replacing DPC 4DPC algorithm, dropping triangulation elimination order requirements, adding line 5 explicitly116fiDistributed Reasoning Multiagent Simple Temporal ProblemsAlgorithm 6: Triangulating Partial Path Consistency (4PPC)Input: STN G = hV, Ei; DPC STN G w/ corresponding elimination orderOutput: triangulated, PPC STN G inconsistent1 provided2G, 4DP C(G)3return inconsistent 4DPC8k = n . . . 1V V vkforall i, j > k s.t. eik , ejk Ewik min(wik , wij + wjk )wkj min(wkj , wki + wij )9return G4567reinstate eliminated timepoint reverse sweep. 4PPC algorithm complements 4DPC algorithm reinstating eliminated timepoints reverse eliminationorder. However timepoint reinstated, incident edges updated respectpreviously reinstated neighbors, whose explicit edges inductively guaranteedminimal property 4DPC algorithm.Figure 8b shows Anns subproblem agent returned establishing PPCshared timepoints, soon described Section 4.2. convey reverse reinstatement order, note Figure 8b works right left. Agent starts selecting, last private timepoint eliminated, reinstatement. agent loopsRETneighbors, time updating incident edge respectpair RETexplicit minimal third edge (in Figure 8b, three incident edges:neighbors edge them). resultsdomain RET, occurs exactly 60 minutes RA ,updated domain [9:00,10:30] RETSTnew upper bound edge shared TR.TRsimilarlyreinstated,completingSTETexecution algorithm. Next, prove 4PPC algorithm correctruns n (G + o2 ) time Theorems 3 4 respectively.Theorem 3. 4DPC 4PPC algorithms establish DPC PPC STN,respectively.Proof. difference Algorithm 6 P3 C algorithm (Algorithm 4, page 105),call 4DPC obtain elimination order, triangulate, establish DPC.loop Algorithm 5 (line 2), along lines 35, establish total order, o,vertices. Given o, lines 2, 6, 7 exactly execute triangulate algorithm (Algorithm 2,page 103), triangulates graph lines 2, 6, 8, 11 exactly executeDPC algorithm (Algorithm 3, page 104). Thus 4DPC algorithm establishes DPC.remainder algorithm exactly follows P3 C algorithm, Planken et al. (2008)prove correctly establishes PPC.117fiBoerkoel & DurfeeTheorem 4. 4PPC executes n (G + o2 ) time, G complexityvariable selection heuristic (as applied G) graph width induced o.Proof. Besides call 4DPCfirst line, Algorithm 6 exactly executes P3 CSTN G, requires n o2 time, proven Planken et al. (2008). Meanwhile,outer loop Algorithm 5 (line 2) executed n times. iteration,operations require constant time SelectNextTimepoint heuristic (line 3),whose cost G function size complexity G, inner loop (line 6),complexity o2 .Note elimination order provided input, costs variable selection heuristic become embedded algorithm. costs rangeconstant time (if selection arbitrary) NP-hard (if selection optimal), typically polynomial number vertices n number constraints (Kjaerulff, 1990).Thus, algorithm internalizes computational cost typically assumed partpreprocessing. analyses consistent convention, bettercapture computation costs associated directly manipulating underlyingtemporal network, include G costs remaining analyses.4.2 Distributed Partial Path Consistency AlgorithmAgents execute 4DPC 4PPC algorithms separately private STNs (Phases1 4, Figure 7), correctly solving shared STN (Phases 2 3, Figure 7) requirescooperation. accomplish this, introduce distributed partial path consistencyalgorithm D4PPC. presentation parallels previous section, beginforward-sweeping D4DPC algorithm triangulating establishing DPCMaSTN instance Section 4.2.1, follow reverse sweep D4PPCalgorithm Section 4.2.2.4.2.1 D4DPC AlgorithmConsider example Figure 8a. Agent successfully independentlyexecute 4DPC two private timepoints TRET RET . point, considerTR .would happen agent proceeded eliminating timepoints RETSTremaining timepoint connected portions MaSTN belongagents, agent must consider actions impact agents vice, unbeknownstversa. example, suppose agent considering eliminating RSTB . case, agent wouldagent A, Bills agent (agent B) already eliminated RSTBeliminate RST assuming edge RST still exists, reality, not.result, computation agent could result superfluous reasoning reasoningstale information, ultimately could jeopardize integrity outputalgorithm whole. Next, discuss algorithm avoids problematicsituations.distributed algorithm D4DPC (Algorithm 7) novel, distributed implementationbucket-elimination algorithm establishing DPC multiagent temporal networks(Phases 1 2, Figure 7). agent starts completing Phase 1 applying 4DPCprivate STP (lines 12), presented previous section illustrated Figure 8a.118fiDistributed Reasoning Multiagent Simple Temporal ProblemsAlgorithm 7: Distributed Directional Path Consistency (D4DPC)ffInput: Agent portion distance graph G = V , EOutput: Agent portion triangulated, DPCdistance graph Gcorresponding elimination orders oiP = v1 , . . . vni oS = (v1 , . . . vnS ),Pinconsistentff1 G , oiP 4DP C( VPi , E )2 return inconsistent 4DPC3 oS ()4 |VIi | > 05RequestLock(oS )ff6vk SelectNextTimepoint( VIi , E , oS )7oS .append(vk )8ReleaseLock(oS )9VIi VIi \ {vk }10forall vi VXi oS s.t. eik E updates vi yet received11E E BlockReceiveUpdatedEdges(Agent(vi ))1213141516171819202122forall vi , vj VSi s.t. eik , ejk EE E {eij }wij min(wij , wik + wkj )wji min(wji , wjk + wki )wij + wji < 0Broadcast(inconsistent)return inconsistentelseSendUpdatedEdge(eij , Agent(vi ))SendUpdatedEdge(eij , Agent(vj ))return G , oiP , oiSoutput 4DPC agents private problem (shown Figure 9a) viewedsummary private subproblem impacts shared problem. words,schedules consistent remaining shared portion agents subproblemguaranteed extensible solution agents subproblem. result,rather jointly reasoning entire MaSTN, agents need cooperativelyreason potentially much smaller shared STN.Continuing Phase 2, agent still responsible eliminatingtimepoints shared STN, securing lock shared timepointelimination ordering (line 5), selecting one interface timepoints vk eliminate (line 6),recording vk shared elimination ordering (line 7), releasing lock (line 8).done first-come, first-served basis. avoid deadlocks establish preciseordering timepoints, two agents request lock time,lock simply goes agent smallest id. Then, performing basic 4DPCinner loop selected timepoint, agent blocks received updated edge119fiBoerkoel & DurfeeShared STNShared STN9: 30,10: 00Chris9: 30,10:SharedSTN 00ChrisShared STN9: 30,10: 00Chris9: 30,10: 00SharedSTNChrisShared STN9: 30,10: 00Chris[0, )0,0[0, ) [60, )0,0[60, )9: 00,10: 308: 00,11:008: 00,10:00AnnBill8:00,10:30[60, )[60, )9: 00,10:0,0 308: 00,10: 308: 00,11:[0, ) 00Ann8: 00,10: 00Bill[60, )[0, ) [60, )0,09: 30,10: 308: 00,11:008: 00,10:0030Ann 9: 00,10:Bill[60, )[60, )9: 30,10: 300,0Ann 9: 00,10: 308: 00,11:[0, ) 00[0, ) [60, )0,08: 00,11:009: 30,10:30Ann[60, )8: 00,10: 00Bill[60, )8: 00,9: 30Bill8:00[60, ) 00,10:8:subproblem.00,9:308: 00,11:009:30,10: 30(a)D4DPCportionD4PPCusesblockingcommunication9: 30,10:00(a)ThePhase2: CollaborativelyapplyalgorithmDDPCsharedAnn network 8:triangulatedChristimepoints eliminatedBill 0000,10:ensure0,0STN manner. [0, )globallySharedconsistent(a) Phase 2: Collaborativelyapply DDPC shared subproblem.Shared STN[0, ) [60, )9: 30,10: 00Chris8: 00,11:009: 30,10: 00SharedSTNChris8: 00,11:[0, )00Shared STN9: 30,10: 00Chris0,09: 30,10:30Ann[60, )Ann9: 30,10:0,030[0, ) [60, )8: 00,11:000,09: 30,10:30Ann[60, )[60, )[60, )8: 00,9: 30Bill8: 00,9: 30Bill60,150[60, )3060,150 8: 00,9:Bill[60, )8: 00,11:9: 30,10:8: 00,9: 30[0,60]000,030AnnBill[0, )60,150[0,60] [60, )[60,150]0,0Shared STN) 308:[0,00,9:308: 00,9:309: 30,10: 0060,1509: 30,10:8:00,11:00 AnnChrisBill[60, )[60,150]8:00,9:309: 30,10: 308: 00,9: 309: 30,10:00Phase3: CollaborativelyDPPCshared subproblem.8: 00,11:apply00 AnnChrisBill9: 30,10: 00SharedSTNChris(b)(b) agents reinstate timepoints reverse sweep D4PPC al(b) Phase 3: Collaboratively apply DPPC shared subproblem.gorithm, agent responds message processed previousphase updated edge information edge.Figure 9: second third phases D4PPC algorithm require coordination (asrepresented block arrows) agents establish PPC shared STN.120fiDistributed Reasoning Multiagent Simple Temporal Problemsinformation respect timepoints share edge vk appearshared elimination ordering (line 11). involves adding edge, necessary,updating weights minimum existing newly received weights.steps completed, agent safely proceed lines 1221,identical inner loop 4DPC algorithm (Algorithm 5) except lines 2021,send updated edge information neighboring agent. continuesagent eliminated interface timepoints.Returning running example, Figure 8a represents first step D4DPCalgorithm. Note, agents need complete eliminating private timepointsagent proceed eliminating shared timepoints. example, Figure 9b, agentsC begin eliminating agent B does. due heterogeneityeither agents capabilities subproblems. case, agent C appendstimepoint TP CET shared elimination order agent appends RST . However,shared edges TP CET RST , agents continueconcurrently (without blocking line 11). Note agents C compute newdomain TRET ; however, agent records update [9:00,10:30] locally.agent selects eliminate TRET , thus must block receive updates dueTP C,agentrecordsagentCstighterupdate [9:30,10:30]. eliminationETagent remaining timepoints also leads messages agent B. However agent BB final step. Note that, agent Breceives updates eliminates RSTBattempted eliminate RST agent completed computing new edgesB, agent B would forced block received edge updates, would appear RB shared elimination order.regarding RSTST4.2.2 D4PPC AlgorithmD4PPC algorithm (Algorithm 8) invokes preceding algorithms accomplishesfour phases depicted Figure 7. starts invoking D4DPC algorithm,results globally DPC triangulated network (or detection inconsistency), alongelimination order vertices (lines 12). new contribution D4PPCalgorithm agents cooperatively performing reverse sweep establish PPCshared STN (Phase 3 Figure 7), invoking 4PPC algorithm finishestablishing PPC private STN (Phase 4).cooperatively establish PPC shared STN, D4PPC algorithm traversesvertices reverse order and, instead calculating updating third edge basedtwo neighboring edges D4DPC does, updates neighboring edges based(newly) updated third edge. Thus, guarantee updates correctly sharedcorrectly incorporate information agents, third edge externalagent, must wait receives updated edge weights agent responsibleupdating last line 8. edge eij < j, agent lastagent update edge, since timepoint appears earliest elimination order.incident edge weights updated respect updated third edge (lines 912). performing updates edge, agent communicates updatedweights agent also shares edge (line 14). agent sent121fiBoerkoel & DurfeeAlgorithm 8: Distributed Partial Path Consistency (D4PPC)ffInput: agent local STP instance G = V , EOutput: agentportionPPC network G inconsistent1 G , oiP = v1 , . . . vni, oS = (v1 , . . . vnS ) D4DPC (G )P2345678910111213141516return inconsistent D4DPCk = nS . . . 1 s.t. vk VIiV V vk= nS . . . k + 1 s.t. eik Ej = nS . . . + 1 s.t. ejk Ew , w yet updatedeij EXijjiwij , wji BlockReceiveUpdatedEdge(Agent(vi ))wik min(wik , wij + wjk )wki min(wki , wkj + wji )wkj min(wkj , wki + wij )wjk min(wjk , wji + wik )j = 1 . . . k 1 s.t. eij , ejk E vj VXiSendUpdatedEdge(Agent(vj ), eik )ff4PPC ( VPi , E , oiP )return Gupdate regarding edge D4DPC. Note mechanisms placeguaranteeing correct communication need executed external edges.Figure 9b shows process action. first timepoint reinstated alsoB . property DPC graphs, RB domain [8:00-9:30]last eliminated: RSTSTguaranteed minimal, is, represent exact set values could partjoint solution. D4PPC algorithm, then, propagates information capturedtighter edges domains variables appear later elimination order backMaSTN variables appear earlier. Agent B kicks algorithmskipping inner-most loop (since one neighbor appears it:de facto z reference point), sending updated domain agent A. Notice evenB updated domain update shared timepoints,though agent might need RSTmessage received once. Then, agent reinstates Anns variables, one one,RBuses information update upper bounds edges RSTST, also domain RA . shared timepoints reinstated,TSTSTalgorithm terminates agent finishes propagating shared updatesprivate network (as illustrated Figure 8b). Notice line 15, agent suppliespreviously computed oP 4PPC, ensuring 4DPC skipped timepointsreinstated reverse oP order.Overall, D4PPC algorithm introduces three points synchrony execution:contention shared elimination order two calls BlockReceiveUpdatedEdge. simplify understanding analysis algorithms, made122fiDistributed Reasoning Multiagent Simple Temporal Problemssynchronization points explicit. previous formulation algorithms (Boerkoel &Durfee, 2010) allows agents proceed optimistically beyond synchronization points.example, agent could optimistically begin eliminating one timepointsofficially obtaining shared elimination order lock, long reevaluates whetheragents concurrently eliminated neighboring timepoint lock obtained.Likewise, reverse-sweep, agent could begin updating private edgesoptimistic assumption current view network up-to-date, backjumping computation new edge update arrives fit assumption.cases, proceeding optimistically never leads incorrect computation,computation may wasted invalidating updates later arrive, agents would satidle anyway waiting updates. Hence, worst nothing lost, bestoptimistic assumptions hold agents gotten head start processing.4.2.3 Theoretical Analysissection, prove D4PPC algorithm correct showingdeadlock free (Theorem 5) establishes PPC (Theorem 6), also proveadded communication change underlying runtime complexity (Theorem 7).Theorem 5. D4PPC deadlock free.Proof. start proving first call D4DPC deadlock free. twolines D4DPC (Algorithm 7) agents may block agents: line 5 line 11.line 5, one lock (on shared elimination order), requests lockgranted first-come, first-served basis, ties broken according agentid. Further, agent lock elimination order, oS , executes two localoperations select variable append oS releasing lock line 8.SelectNextTimepoint independent, local decision requiring locally knowninformation. Hence, deadlock cannot occur result contention oS .leaves line 11. Assume, way contradiction, line 11 causes deadlock.implies two (or more) agents, j, 6= j agentsimultaneously waiting communication line 11. Thus, existstimepoint vxj VXi VLj agent waiting receive updated edges agent j,also vyi VXj VLi agent j waiting receive updated edgesagent i. Notice vyj must appear vxi agent copy oS because, otherwise,time vyj appeared oS , agent would already sent agent j edge updatespertaining vxi (lines 2021) previous loop iteration vxi eliminated(and added oS line 7). However, reason, vxi must appear vyjagent js copy oS . contradiction, one shared eliminationorder agents append granted mutually-exclusive access.argument extends inductively three agents, line 11 alsocause deadlock, presents contradiction.Therefore D4DPC algorithm deadlock free. call D4DPC,D4PPC algorithm traverses MaSTN exact opposite order D4DPCalgorithm, proof remainder D4PPC algorithm deadlock free follows,mutandis mutatis.123fiBoerkoel & DurfeeTheorem 6. D4PPC correctly establishes PPC MaSTN.Proof (Sketch). 2 algorithm starts correctly establishing DPC MaSTN. Since,definition, none agents private timepoints share edges private timepointsagent, agent apply 4DPC private subproblem independently(lines 12). Given nature 4DPC algorithm bucket-elimination algorithm(solutions remaining subproblem guaranteed extensible eliminated variables), agent computed constraints interface variables captureimpact private subproblem shared subproblem. remaining algorithmapplies 4DPC algorithm agents shared timepoints. Lines 58 guaranteeglobally consistent elimination ordering shared timepoints established. Finally,lines 11 2021 guarantee edge weights used agent staleconsistent among agents involved.Then, algorithm executes operations second phase 4PPCalgorithm, distributed fashion, using blocking communication guaranteecomputation performed using correctly updated edge weights.Theorem 7. D4PPC executes (nP + nS ) o2 time, nP = maxi |VPi |, nS =|VS |, graph width induced o.Proof. Beyond lines added communication, D4PPC algorithm exactly executes4PPC caveat elimination order restricted eliminating privatetimepoints prior shared timepoints. lines code added communicationincrease work constant factor within 4PPC algorithm (for edge updateperformed 4PPC, one message sent received). However, agents mustblock edge updates agents, agent may need wait agentcomplete local computation. worst case, elimination subsequentrevisiting shared timepoints must done completely sequentially, putsalgorithm complexity class 4PPC algorithm, (nP + nS ) o2 .Note Theorem 7 provides worst-case analysis. best case, complete concurrencypossible, putting runtime closer nL o2 , nL = |VL | less equalnP + nS . is, best case, blocking occurs (and agents execute 100%concurrently), leading costs agents executing 4DPC subproblems.Note best case likely realized when, instance, externalconstraints. empirical evaluations, present next, find run times fallsomewhere two extremes practice closer best case looselycoupled problems.4.3 Empirical Evaluationsection, empirically evaluate distributed algorithm solving MaSTP.performance distributed algorithm relies size agents privatesubproblem relative size complexity collective shared subproblem.greater portion problem private agent, rather shared,2. full version this, remaining proof sketches, available online appendix associatedpublication.124fiDistributed Reasoning Multiagent Simple Temporal Problemsgreater level independent reasoning concurrency, thus faster overallsolve time distributed algorithm compared centralized algorithm.4.3.1 Experimental SetupRandom Problem Generator. evaluate algorithms solving MaSTPs usingrandom problem generator described Hunsberger (2002), adaptgenerates multiagent STP instances. problem instance agentsstart timepoints end timepoints 10 activities. activity constrainedoccur within time interval [0,600] relative global zero reference timepoint, z.activitys duration constrained lower bound, lb, chosen uniformly interval[0,60] upper bound chosen uniformly interval [lb, lb + 60]. additionconstraints, generator adds 50 additional local constraints agent Xtotal external constraints. additional constraints, eij , boundchosen uniformly interval [wij (wij + wji ), wij ], vi vj chosen,replacement, set timepoints uniform probability, [0, 1]tightness parameter dictates maximum portion interval tightened,whose default value set = 1 experiments. particular problemgenerator provides us upside directly systematically controlling numberexternal constraints relative number (and size/complexity of) agent subproblems.Factory Scheduling Problem Benchmark. second source problemsmultiagent factory scheduling domain (Boerkoel, Planken, Wilcox, & Shah, 2013).randomly generated MaSTPs simulate agents working together complete tasksconstruction large structural workpiece manufacturing environment, using realistic task duration, wait, deadline constraint settings. publicly available benchmark (Boerkoel et al., 2013) distinguishes structural constraintsthe existenceprovide underlying structure temporal network (e.g., task durations minimum maximum durations must completemakespan), refinement constraintsthose instantiate constraints boundsparticular weights (e.g., task-specific deadline duration constraints). former encodegeneral task structure knowledge, later encode particular domain knowledgefactory manager refine space schedules feasible schedules remain.experiments, process constraints equally, whether structural constraint refined particular bound not. evaluate approaches problem dataavailable: number agents increases (A {2, 4, 8, 12, 16, 20}, = 20A) alsototal number tasks increases (A = 16, {80, 160, 240, 320, 400, 480, 560}). UnlikeRandom Problem Generator, set problems distinctive underlyingproblem size (inter)constrainedness agent problem dictated real-worldfactory needs, rather generated uniformly distributed across agents.Experimental Procedure. capture expected trends particular problem source(Random Factory Scheduling) parameter setting, evaluate average performance algorithm 50 independently-generated trials. include error bars representing one standard deviation results. Note, many cases, error barsappear smaller tick marks used represent data points. algorithmsprogrammed Java, 3 GHz processor using 4 GB RAM. purposes125fiBoerkoel & Durfeemodeling concurrent, multiagent system, interrupted agent givenopportunity perform single edge update evaluation also single communication(sending receiving one message), systematically sharing processor agentsinvolved. approaches use minimum fill heuristic (Kjaerulff, 1990). appliedapproaches connected networks agents, although intuitively, performancealgorithms would enhanced applying disparate agent networks independently. Finally, problem instances generated lead consistent STP instancesevaluate full application algorithm. necessary algorithms,excluding inconsistent STP instances avoids overestimating reductions execution timesalgorithm halts soon inconsistency found. Moreover, unlike previousapproaches, algorithms require input STPs triangulated (Xu & Choueiry,2003; Planken et al., 2008).Evaluation Metrics. solving traditional CSP, one primary measuresunit computation constraint check. Meisels Zivan (2007) extend metricdistributed setting introducing non-concurrent constraint check (nccc). Noteagents solving distributed problem form partial order constraint checks basedfact (i) two constraint checks performed within agent must performedsequentially (ii) constraint check xi performed agent prior sending messagemij ordered constraint check xj performed agent j receiptmij . nccc metric, then, simply length longest critical path partialordering constraint checks. generalized nccc metric work countingnumber non-concurrent edge updates: number cycles takes establish PPCMaSTP, agent given opportunity update check boundssingle edge cycle computation, although agents may spend cycle idlyblocking updates agents.report non-concurrent edge updates rather simulated algorithm runtimedue limitations simulating distributed system. First, heterogeneity agentcapabilities underlying sources message latency vary dramatically across differentreal distributed computing systems. systematic, compelling way estimateruntime distributed systems assumption-free, unbiased manner, insteadprovide implementation- system-independent evaluation. Second, separatelymaintaining state many agents simulated distributed system introduces largeamount overhead due practical issues memory swapping, unduly inhibitsaccurate fair algorithm runtime comparisons. Since D4PPC requires significantnumber messages (which would typically incur latency), separately count numbercomputation cycles least one agent sends message, described later,allows rudimentary runtime projections latency. report total numbermessages sent D4PPC later Section 5.3.1, compare distributedtemporal decoupling algorithm.4.3.2 Empirical ComparisonOne main benefits associate performing computationdistributed fashion promotes greater concurrency. section, explorewell distributed algorithms exploit concurrent computation, reporting number126fiDistributed Reasoning Multiagent Simple Temporal Problemsnon-concurrent edge updates along number computational cycles requiremessages. compare following approaches:FW Floyd-Warshall algorithm executed centralized version problem;4PPC 4PPC algorithm executed single agent centralized versionproblem;D4PPC w/ Latency D4PPC algorithm assume every computational cycle might incur message latency requires an-order-of-magnitudetime performing single edge update;D4PPC w/o Latencyour D4PPC algorithm extra message latencypenalties.Random Problems. Figure 10a compares algorithms performance problemsRandom Problem generator, level coupling, measured numberexternal constraints increases. one would expect, density overall network increases, 4PPC approaches costs fully-connected FW algorithm.Without latency, D4PPC algorithm, expectation, maintains steady improvementcentralized counterpart, ranging 12 times speedup (centralized computation/distributed computation) X = 100 nearly 23 times speedup X = 3200,within 12% perfect speedup 25 agents.Interestingly, even external constraints (X = 0), D4PPC algorithm achieves 18-fold, rather 25-fold, improvement 4PPC. dueheterogeneity complexity individual agent problems.external constraints, opportunities agents easy-to-solvelocal problems help agents out, thus effectively load-balance. numberexternal constraints increases, overall time complexity 4PPCD4PPC w/o Latency approaches; however, opportunities load-balancing synchronization points also increase. results indicate increased opportunitiesload-balancing outweigh costs increased synchronization number externalconstraints increases.Coordination does, however, introduce overhead. D4PPC w/ Latency curveFigure 10a, try account message latency penalizing D4PPC extracomputational cost equivalent 10 edge updates every message cycle. practice,represents rough estimate costs communication, since (i) messagessent require agent block (i.e., many messages received prior need)(ii) message latency could lead compounding delays elsewhere network. Evenpenalty message latency, distributed approach maintains advantagecentralized approach, albeit much smaller one (e.g., 20% improvementX = 100). number external constraints increases, however, effectsadditional latency penalty become mitigated since (i) network becomes dense,new external constraint increasingly less likely spur new messages (i.e., edgewould already created communicated), (ii) extra message latencycosts amortized across greater number agents.127fiBoerkoel & Durfee1e+009Nonconcurrent Edge UpdatesNonconcurrent Edge Updates1e+0091e+0081e+0071e+006100000FWPPCDPPC w/ LatencyDPPC w/o Latency10000100050100200400800FWPPCDPPC w/ LatencyDPPC w/o Latency1e+0081e+0071e+006100000100001000160032001Number External Constraints (X)2481632Number Agents (A)(a) Non-concurrent edge updates numberexternal constraints X increases.(b) Non-concurrent edge updates numberagents increases.Figure 10: Empirical comparison D4PPC randomly generated problem set.Figure 10b shows number non-concurrent edge updates number agentsgrows. number non-concurrent edge updates grows linearly numberagents across approaches. Interestingly, estimate effects messagelatency, cross-over point 4PPC D4PPC w/ Latency. certain levelmessage latency mean that, small number agents, faster centralizecomputation using 4PPC utilize parallelism slow communication,number agents grows, centralized problem becomes unwieldy distributioncomputation makes D4PPC w/ Latency superior again. Figure 10b also showsexpected runtime D4PPC increases slowly FW 4PPC,D4PPCs speedup increases number agents seen widening relative gap4PPC D4PPC curves. Thus, D4PPC scales increasing numberagents better 4PPC.Factory Scheduling Problems. high level, Figure 11 Factory SchedulingProblems shows many trends saw Figure 10. are, however,notable differences. First, plot using log scale, like Figure 10, since (i)parameters grow linear scale, (ii) leave much expensive FWapproach better compare similar approaches. Second, numbertasks constraints across agents subproblems uniform, like RandomProblem case, leading constraint networks based underlying structurerealistic problems. number tasks agents increase, D4PPC clearlyscales better centralized counter-part, demonstrating robustness heterogeneityacross agent problems. number tasks low (T = 80), D4PPC exhibits 8.5times speedup 4PPC steadily grows 12.3 fold speedup number tasksgrows (recall problems distributed across 16 agents). Similarly, relative gapD4PPC 4PPC grows linearly number agents, settling within 30% perfectspeedup. Finally, set experiments clearly demonstrates costs highmessage latency overcome number complexity agents local problemsgrows sufficiently high.128fiDistributed Reasoning Multiagent Simple Temporal Problems8000PPCDPPC w/ LatencyDPPC w/o Latency10000Nonconcurrent Edge UpdatesNonconcurrent Edge Updates1200080006000400020000PPCDPPC w/ LatencyDPPC w/o Latency70006000500040003000200010000801602403204004805602Number Tasks (T)468101214161820Number Agents (A)(a) Non-concurrent edge updates numbertasks increases.(b) Non-concurrent edge updates numberagents increases.Figure 11: Empirical comparison D4PPC factory scheduling problem set.Total Effort. minimum-fill variable ordering heuristic myopically selects timepoint, set timepoints, whose elimination expects lead fewest addedfill edges. Since centralized algorithm, 4PPC, places restrictions heuristic,expect heuristic perform well, adding fill edges. D4PPC, hand,restricts private timepoints eliminated prior shared timepoints, restrictsagent eliminating timepoints. Intuitively, expect additional restrictions hurt heuristic performance, is, lead triangulationsfill edges. increase overall number fill edges, turn, increases numberedges, thus overall number edge updates required update network. evaluateefficiently effort distributed across agents, compare 4PPC D4PPCtotal number fill edges added total number edge updates (summed acrossagents). compute ratio D4PPC versus 4PPC effort using metricsacross two parameters directly impact constraint density: number externalconstraints X randomly generated problems, number tasksfactory scheduling problems. Results displayed Figure 12.Overall, algorithms, total number fill edges edge updates increasesX increases. Figure 12a displays relative 4PPC, number fill edgesedge updates computed D4PPC increases faster rate low X values,slower rate higher X values, leading 57% increase total edge updates 11%increase total fill edges peak. multiple trends occurring here. Early(X = 0 . . . 200), heterogeneity individual agents private subproblems dictateselimination shared timepoints done agent gets first,necessarily correlated least-connected shared timepoint. number externalconstraints increases, however, agents ability load balance elimination sharedtimepoints improveswhen agents spending time competing sharedelimination order lock, one least amount (shared) computation (whichcorrelated fewest added shared fill edges) get it. improved load-balancingalso accentuated fact X increases, shared network density,129fiBoerkoel & Durfee3Edge UpdatesFill Edges1.6Ratio Effort: DPPC vs. PPCRatio Effort: DPPC vs. PPC1.71.51.41.31.21.11Edge UpdatesFill Edges2.82.62.42.221.81.61.41.21501002004008001600320080Number External Constraints (X)160240320400480560Number Tasks (T)(a) Relative (to centralized) number added filledges number external constraints X increases randomly generated problem set.(b) Relative (to centralized) number added filledges number tasks increasesfactory scheduling set.Figure 12: Empirical comparison D4PPC terms total effort.increasing number fill edges must inevitably added approaches,thus dampening relative advantage 4PPC D4PPC.results displayed Figure 12a show trends density external constraintsincreases random problems. Figure 12b, hand, showsoverall number constraints increased generally, relative total effort monotonically decreases factory scheduling problems. validates previous studyshowed eliminating private timepoints shared timepoints actually improvesperformance variable elimination heuristics taking advantage structural knowledge avoid increasing connectedness agents problems (Boerkoel & Durfee,2009). Thus, complexity local problems grows relative complexityshared problem, case well-structured, loosely coupled factory scheduling problems, distributed application variable ordering heuristic (as D4PPC)improves performance centralized application (as 4PPC). Interestingly,factory scheduling problem set, variability number shared timepoints per agentinitially causes relative margin extra fill edges much larger randomlygenerated problems, settling sufficient number tasks added.4.3.3 Summarysection, presented D4PPC algorithm, distributed version P3 C algorithm, exchanges local constraint summaries agents establish minimal,partially path consistent MaSTNs. D4PPC algorithm utilizes D4DPC algorithmagent independently eliminates private timepoint variables coordinating eliminate shared variables, effect exactly summarizing impactsubproblem agents problems. remainder D4PPC algorithmessentially reverse sweep D4DPC algorithm, care taken ensureagent synchronizes edge weights agents prior updatinglocal edges. prove algorithm correctly calculates joint solution space130fiDistributed Reasoning Multiagent Simple Temporal ProblemsMaSTP without unnecessarily revealing private variables. D4PPCworst-case complexity centralized counterpart, show empirically exploitsconcurrency outperform centralized approaches practice. scales much slowlynumber agents centralized approaches achieves within 12% perfectspeedup relative size complexity agents local problems grow problemsstudied.5. Distributed Algorithm Calculating Temporal DecouplingsD4PPC algorithm outputs space possible joint solutions MaSTP,depicted Phase 4 Figure 7. However, discussed Section 1, potential limitationapproach dependencies agents problems maintained. agentsmust coordinate decisions using full representation avoid giving inconsistent advice,Anns agent advises Ann start recreation 8:00 Bills agent adviseswait 9:00. Thus, advice one agent could potentially leadupdate (e.g., Anns decision start recreation 8:00) would need propagatedagent offers advice guaranteed consistent. presentschallenge updates frequent communication expensive (e.g., slow), uncertain(e.g., intermittent), otherwise problematic. Agents must coordinate re-establish partialpath consistency either re-executing D4PPC algorithm employing recentincremental versions algorithm recognize updates might propagatesmall portion MaSTN (Boerkoel et al., 2013). temporal decoupling,hand, gives agent ability reason users local schedulecompletely independent manner. allows agents give unilateral, responsive,sound, though generally incomplete, advice.goal Multiagent Temporal Decoupling (MaTD) algorithm find setdecoupling constraints C render MaSTPs external constraints CX moot,thus agents subproblems independent (see Section 3.2). goal achievedassigning values variables reverse sweep (as Figure 1b),sacrifices flexibility provided maintaining solution spaces.insight assigning private timepoints matter independence,assign shared variables, tighten private variables responseassignments (Section 5.1). show that, many cases, assignments shared variablesrelaxed increase flexibility (Section 5.2). Overall, algorithms computetemporal decoupling making heuristic choices reduce flexibility sacrificed. LaterSection 5.3, describe ways measuring flexibility, empirically evaluate differentalgorithmic choices affect flexibility well runtime.shown Figure 13, Phases 1 2 algorithm, establish DPCMaSTP, D4PPC algorithm (shown Figure 7). new Phase3, however, agents establish temporal decoupling assigning shared timepointsreverse order agents eliminated Phase 2. Next, optional Phase 4,agents revisit shared timepoint original elimination order relax decouplingconstraints maximum extent possible, resulting minimal decoupling. Phase 5,agent independently establishes PPC local problem,last phase D4PPC algorithm.131fiBoerkoel & Durfee9: 30,10: 0090,120Ann8: 00,11: 008: 00,12: 0060,608: 00,12: 00Bill8: 00,12: 0060,60[60,120,12010: 00,10: 0012: 00,12: 0090,1208: 00,12: 008: 00,10: 3060,1808: 00,12: 008: 00,12: 00Phase 2: Eliminate Shared TimepointsEliminate9: 30,10: 00[0,0,0[60,8: 00,11: 00[60,8: 00,9: 309: 30,10: 30Phase 3: Reinstate Assign Shared TimepointsDecouple9: 45,9: 45=9: 45,9: 45[60,8: 45,8: 458: 45,8: 458: 45,8: 458: 45,8: 4510: 08,10: 0810: 08,10: 08Relax9: 30,10: 00[60,8: 45,8: 458: 45,8: 45Phase 5: Reinstate Private Timepoints=Chris9: 30,10: 008: 00,8: 3090,1208: 45,8: 45Ann60,6010: 00,10: 308: 45,8: 4510: 008: 45,8: 459: 45,9: 458: 45,8: 45Bill9: 45,9: 4560,6060,105120,12010: 00,10: 0012: 00,12: 0090,12010: 00,10: 3011: 30,12: 009: 45,11: 0060,13510: 45,12: 00PPC (Algorithm 6)Relaxation(Algorithm 10)Phase 4 (optional): Relax Shared Timepoint DomainsMaTD/MaTDR (Algorithm 9)ChrisDDPC (Algorithm 7)8: 00,12: 00DPC (Algorithm 5)Phase 1: Eliminate Private TimepointsFigure 13: MaTD algorithm replaces shared D4PPC phase D4PPC algorithm (depicted Figure 7) decoupling phase assigns shared timepointsreverse elimination order (Phase 3) optional Relaxation phase, timepointsrevisited flexibility recovered extent possible.132fiDistributed Reasoning Multiagent Simple Temporal Problems5.1 Distributed Multiagent Temporal Decoupling AlgorithmMaTD algorithm, presented Algorithm 9, starts (lines 1-2) executing D4DPCalgorithm (Algorithm 7 page 119) triangulate propagate constraints, eliminating shared timepoints VS last. D4DPC propagates inconsistent graph,algorithm returns inconsistent; else, illustrated first two phases Figure 13,resulting MaSTN captures implications agents private constraints reflectedtighter domains shared timepoints. Next, MaTD initializes empty C (line 3)steps vertices reverse elimination order. example, meansB (line 4). However, agent reinstates interface timepoint, simstarting RSTply assigns rather updating incident edges case reverse sweepD4PPC algorithm. Typically, assigning reinstated timepoint, domain mustupdated respect previously assigned shared timepoints. However,B first reinstated variable, MaTD skips inner loop (lines 7-11)RSTvertices later oS .B guaranteed minimal, meaning agent Bpoint, domain RSTassign remaining value still guaranteed globally consistent.choice value assign made line 12 function HeuristicAssign.default, HeuristicAssign assigns timepoint midpoint bounds interval split remaining flexibility middle; later discuss alternative assignmentheuristics. Notice D4DPC algorithm first executed, agent B wouldB midpoint original domain 8:00-12:00 rather updated doassign RSTmain 8:00-9:30, would result inconsistent assignment (to 10:00). However,B happens 8:45 C (line 14). line 13,MaTD instead adds constraint RSTB shares external edges Anns timepoints.sent agent A, RST. Note, agent would consider processing variable rightnext vertex RSTaway, inner loop (lines 7-11) forces agent wait message agent B(line 9). message arrives, agent updates edge weights accordingly (lines 10A least 60 minutes RB = 8:45, RA domain11). case, given RSTSTSTtightened [9:45, 10:30]. line 12, agent chooses decoupling pointoccurssplitting difference, thus adding (and communicating) constraint RST10:08. process repeated timepoints VS assigned.resulting network decoupling constraints shown Phase 3 Figure 13.avoid inconsistency due concurrency, calculating decoupling constraintsvk , agent blocks line 9 receives fresh, newly-computed weights wzj , wjzj > k.vj agent (Agent(vj ), sent line 13) external edge ejk EXimplies sequentialization, also allows concurrency whenever variablesshare external edge. example, Phase 3 Figure 13, TP CETshare edge, agent assigned RA , agent agent CRSTSTTP C respectively.concurrently independently update assign RSTETFinally, moment skipping optional Phase 4 Figure 13, agent establishes PPC response new decoupling constraints executing 4PPC private STN Phase 5. algorithm represents improvement previous approaches(Hunsberger, 2002; Planken, de Weerdt, & Witteveen, 2010a) it: (i) distributed,rather centralized; (ii) executes sparser, efficient network representation;133fiBoerkoel & DurfeeAlgorithm 9: Multiagent Temporal Decoupling (MaTD) optional Relaxation(MaTDR)Input: G , agent known portion distance graph corresponding MaSTPinstance M, field indicating whether RELAX decoupling, agent decoupling constraints, G , agent PPC distance graphOutput: Cw.r.t. C1 G , oiL , oS = (v1 , v2 , . . . vn ) D4DPC (G )2 return inconsistent D4DPC=3 C4 k = n . . . 1 vk VIi5V V vkDP C w , w DP C w6wzkzkkzkz7j = n . . . k + 1 ejk E8ejk EX9wzj , wjz BlockReceiveUpdatedEdges(Agent(vj ))1011121314wzk min(wzk , wzj + wjk )wkz min(wkz , wkj + wjz )wkz , wzk HeuristicAssign(vk , G)SendUpdatedEdge(wzk , wkz , Agent(vj ) j < k, ejk EXC C {(z vk [wzk , wkz ])}16RELAXRelaxation (G , w DP C )G , C17return 4PPC (GL+, oiL ), C15(iii) eliminates assumption input graphs must consistent; (iv) performsdecoupling embedded procedure within existing D4PPC algorithm, ratherouter-loop.mentioned, simple default HeuristicAssign assign vk midpointdirectional path consistent domain (which corresponds using rules wzkwzk 21 (wzk + wkz ); wkz wzk ). Section 5.3.2, explore evaluate alternativeHeuristicAssign function. general, however, narrowing variable assignments singlevalues constraining necessary. Fortunately, agents optionally call relaxation algorithm (introduced Section 5.2 shown Figure 13 Phase 4) replacesC set minimal decoupling constraints.Theorem 8. MaTD algorithm overall time complexity (nP + nS ) o2 ,nP = maxi |VPi | nS = |VS |, requires (mX ) messages, mX = |EX |.Proof. MaTD algorithm calculates DPC PPC (nP + nS ) o2 time. Unary,decoupling constraints calculated nS external variables, vk VS (lines 414), iterating vk (o ) neighbors (lines 7-11). Thus decoupling requires (nS ) nS o2 time, MaTD overall time complexity(nP + nS ) o2 . MaTD algorithm sends exactly one message externalconstraint line 13, total (mX ) messages.134fiDistributed Reasoning Multiagent Simple Temporal ProblemsTheorem 9. MaTD algorithm sound.Proof. Lines 1-2 return inconsistent whenever input MaSTP consistent.contradiction, assume exists external constraint cxy bound bxysatisfied decoupling constraints cxz czy , calculated MaTD,bounds b0xz b0zy respectively, are. case, b0xz + b0zy > bxy . WLOG, let x <elimination order oS .Note, time vx visited (in line 4), following true:wxy bxy ;(1)wzy + wyz = 0;(2)b0zy = wzy .(3)(1) true since line 1 computes DPC using oS ; (2) true since line 12already executed vy , (3) true construction czy line 14.update wxz occurs line 11, and, since exy external, one updates0 = min(w , wwxzxzxy + wyz ), thus0wxzwxy + wyz .(4)Combining (1), (2), (4), yields fact:0wxz+ wzy wxy bxy .(5)0 may updated future iterations line 11 possiblytime wxz00 , lines 11 12 tighten (never relax). Thus,line 12 produce wxz(5) implies000wxz+ wzy wxz+ wzy wxy bxy .(6)00 ; fact, along (3) (6), impliesline 14, cxz constructed bxz = wxzbxz + bzy bxy . However, contradiction assumption b0xz + b0zy > bxy ,constraints C calculated MaTD form temporal decoupling M.Theorem 10. MaTD algorithm complete.Proof (Sketch). basic intuition proof provided fact MaTDalgorithm simply general, distributed version basic backtrack-free assignment procedure consistently applied DPC distance graph. showchoose bounds new, unary decoupling constraints vk (effectively line 12),wzk , wkz path consistent respect variables.distance graph DPC, also updates lines 10-11 guarantee wzk , wkzpath consistent respect vk j > k (since path vj vkrepresented edge ejk distance graph). proactive edge tighteningoccurs, happens line 13 guarantees wzk + wkz = 0, done pathconsistent edges thus never introduce negative cycle (or empty domain).MaSTP consistent, MaTD algorithm guaranteed find temporal decoupling.135fiBoerkoel & Durfee5.2 Minimal Temporal Decoupling Relaxation AlgorithmOne key properties minimal MaSTP represent space consistentjoint schedules, turn used hedge scheduling dynamism.larger space solutions is, flexibility agents to, e.g., add new constraints,mitigating risk invalidating solution schedules. Flexibility , then,measure completeness solution space. Flexibility good increasesagents collective abilities autonomously react disturbances new constraints,time, flexibility joint solution space limits individual agentunilaterally independently exploiting autonomy. MaTD algorithm explicitlytrades away flexibility increased independence assignment process line 12.section, describe algorithm attempts recover much flexibilitypossible maximize agents ability autonomously, yet independently, react dynamicscheduling changes.goal Multiagent Temporal Decoupling Relaxation (MaTDR),version MaTD executes Relaxation algorithm (Algorithm 10)subprocedure, replace set decoupling constraints produced MaTD0algorithm, C , set minimal decoupling constraints, C . Recall page 111minimal decoupling one where, bound decoupling constraint c C12nagent relaxed, {SL+ , SL+ , . . . , SL+ } longer guaranteed formdecoupling. Clearly temporal decoupling produced running MaTD usingdefault heuristic example problem, shown Phase 3 Figure 13, minimaldecoupling bounds TP CET could relaxed include entire original domain. basic idea Relaxation algorithm revisitstill decoupled RSTexternal timepoint vk and, holding domains external timepointvariables constant, relax bounds vk decoupling constraints much possible.describe execution algorithm describing execution tracerunning example problem. depicted Phase 4 Figure 13, Relaxation works origCinal oS order, thus starts TP CET . First, Chris agent removes TP ET decouplingconstraints restores TP CET domain [9:30,10:00] updating corresponding edgeweights stored DPC values (line 3). Notice lines 2-19 similar reversesweep D4PPC algorithm, except separate, shadow bound representation used updated respect original external constraint bounds (nottightened edge weights) ensure later-constructed decoupling constraints minimally constraining. Also, lines 13-18, decoupling constraint constructedbound potential, new constraint (e.g., kz ) tighter already implied edgeweight (e.g., kz < wkz ). example, constraint involving TP CEToccur RST . Therefore RST currently set occur 10:08(=10:08) TP Coccur 10:00 (w =10:00), 6< w,ET already constrained0decoupling constraints added set C TP CET (allowing retain originaldomain [9:30,10:00])., whose domain relaxes back [8:00,9:30]. However,next variable consider RSTB , whose current domain [8:45,8:45],since RST shares synchronization constraint RST[8:45,8:45].Anns agent end re-adopting original decoupling constraint RSTNext, agent recovers RST original DPC domain [9:30,10:30] tightens ensure136fiDistributed Reasoning Multiagent Simple Temporal ProblemsAlgorithm 10: RelaxationDP C , w DP C , v VInput: G , DPC weights, wzkkXkz0iOutput: C , agent minimal decoupling constraints, G , agent PPC distance0graph w.r.t. Ci0i1 C2 k = 1 . . . n vk VIiDP C , wDP C3wzk wzkkz wkz4zk kz5j = 1 n ejk E6ejk EX7j < k wzj , wjz BlockReceiveUpdatedEdges(Agent(vj ))8cjk exists zk min(zk , bjk wjz )9ckj exists kz min(kz , bkj wzj )101112131415else j < kwzk min(wzk , wzj + wjk )wkz min(wkz , wkj + wjz )kz < wkzwkz kz00Ci Ci {(z vk kz )}18zk < wzkwzk zk00Ci Ci {(vk z zk )}19SendUpdatedEdge(wzk , wkz , Agent(vj ) j > k, ejk EX1617020return G , CiCfollows TP CET new domain [9:30,10:00]. case, decoupling TP ETrequires new lower bound 10:00 results flexible domain [10:00,10:30]. minimal decoupling constraints corresponding temporal networkRSTRelaxation calculates running example presented Phase 4 Figure 13shared portion network. Similarly, Phase 5 shows implications incorporatingdecoupling constraints agents PPC subproblem.Relaxation algorithm applies two different kinds updates. edge ejkconsidered line 6 local agent i, Relaxation algorithm executes lines 11-12,update actual edge weights wzk wkz manner D4PPCalgorithm, guaranteeing values captured within bounds interval consistentleast value vj domain (so locally PPC).hand, edge ejk external, Relaxation algorithm instead executes lines 8-9,update shadow edge weights zk kz way guarantees consistentvalues vj domain (so temporally decoupled). Noteupdates restrictive, lead new decoupling constraintstighter vk current domain.137fiBoerkoel & DurfeeTheorem 11. Relaxation algorithm overall time complexity (nS )requires (mX ) messages.Proof. Unary, decoupling constraints recalculated nS shared variables,require visiting vk VS (o ) neighbors (lines 2-19), iteratingvk (o ) neighbors (lines 5-12). Thus Relaxation algorithm requires (nS )time. Relaxation algorithm sends exactly one message external constraintline 19, total (mX ) messages.Notice Relaxation algorithm called subroutine MaTD algorithm,runs less time, overall MaTDR algorithm runtime still (nP + nS ) o2 .Theorem 12. local constraints calculated Relaxation algorithm form minimal temporal decoupling S.0Proof (Sketch). proof set C forms temporal decoupling roughly analogousproof Theorem 5.1. contradiction, show bound bxz00decoupling constraint cxz C relaxed small, positive value xz > 0, Clonger temporal decoupling. lines 8-9 imply existseither bxz = bxy bzy , thus bxz + xz + bzy > bxy (and thus longertemporal decoupling), bzy = bxy (bxz + xz ) (and either decouplingrequires altering bzy order maintain temporal decoupling).5.3 Evaluationfollowing subsections, reuse basic experimental setup Section 4.3empirically evaluate performance MaTDR algorithms computational effortSection 5.3.1, impact flexibility variations MaTDR algorithm Section 5.3.2. Like original D4DPC algorithms, decoupling algorithms performancedepends size agents private subproblem versus size shared subproblem. number external constraints relative number agents increases,less reasoning occur independently, also resulting decoupled solution spacessubject increasing number local constraints, thus diminish flexibility.5.3.1 Evaluation Computational Effortempirically compared:MaTDR default MaTD algorithm Relaxation;Centralized MaTDR single agent executes MaTDR centralized versionproblem;D4PPC execution D4PPC distributed algorithm establishing PPCMaSTP (but decoupling);TDPour implementation fastest variation (the RGB variation) (centralized) TDP algorithm reported Hunsberger (2002).138fiDistributed Reasoning Multiagent Simple Temporal Problemsimplement original TDP approach, use Floyd-Warshall algorithm initiallyestablish FPC, incremental update described Planken (2008) maintain FPCnew constraints posted. evaluated approaches across two metrics. nonconcurrent edge update metric, which, described Section 4.3, number computational cycles edge updated agents simulated multiagentenvironment completed executions algorithm. metric reportsection total number messages exchanged agents.Random Problems. evaluate algorithms randomly generatedfactory scheduling problem sets described Section 4.3.1. results shown Figure 14demonstrate MaTDR algorithm clearly dominates original TDP approachterms execution time, even MaTDR algorithm executed centralizedfashion, demonstrating advantages exploiting structure using PPC (versus FPC)dividing problem local shared subproblems. advantageMaTDR original TDP approach incorporates decoupling procedurewithin single execution constraint propagation rather introducing decouplingconstraints one time outer loop reestablishes FPC new decouplingconstraint added. Additionally, compared centralized version MaTDRalgorithm, distributed version speedup varies 19.4 24.7.demonstrates structures generated problem instances support parallelismdistributed algorithm exploit structure achieve significant amountsparallelism.MaTDR algorithm also dominates D4PPC algorithm terms computation number messages. means MaTDR algorithm calculate temporaldecoupling less computational effort D4PPC algorithm establish PPCMaSTP. MaTDR generally bound runtime complexityD4PPC (due applying D4DPC algorithm), complexity actualdecoupling portion procedure less practice argued Theorem 8.MaTDR algorithm calculates communicates new bounds unary reference edges,renders external edges moot thus need reason them.contrast, D4PPC algorithm must calculate, communicate, maintain new boundsevery shared edge. total number messages sent algorithms grows linearly number agents and, perhaps less intuitively, sublinearly numberexternal constraints. indicates that, network becomes saturated,new external constraint increasingly likely expressed edge wouldalready require communication, thus requires new messages.Factory Scheduling Problems. also evaluated algorithms using factory problem set, MaTDR exhibited similarly large speedups Centralized MaTDRapproach (ranging 4 5 orders magnitude depending number tasks).excluded TDP approach charts Figure 15 zoom differences(Centralized) MaTDR D4PPC algorithms, much subtle.still achieving impressive speedups centralized counterpart, MaTDR algorithmscomputational advantages D4PPC less pronounced (Figure 14) dueloosely-coupled nature factory problem set. Similarly, relative drop139fiBoerkoel & Durfee1e+009Nonconcurrent Edge UpdatesNonconcurrent Edge Updates1e+0091e+0081e+0071e+006100000TDPCentralized MaTDRDPPCMaTDR10000100050100200400800TDPCentralized MaTDRDPPCMaTDR1e+0081e+0071e+00610000010000100016003200124Number External Constraints (X)(a) Nonconcurrent computation numberexternal constraints X increases.1632(b) Nonconcurrent computation numberagents increases.1e+008DPPCMaTDRDPPCMaTDR1e+0071e+006Number MessagesTotal Number Messages1e+0078Number Agents (A)1000001000010001e+00610000010000100010010050100200400800160032002Number External Constraints (X)481632Number Agents (A)(c) Number messages number externalconstraints X increases.(d) Number messages number agentsincreases.Figure 14: Empirical evaluation MaTDR randomly generated problem set.external constraints leads, turn, fewer shared edges, thus fewer messages overall,mitigating substantial gap Figures 14c 14d.fact MaTDR algorithm dominates D4PPC algorithm implies that,even original TDP algorithm adapted make use state-of-the-art D4PPCalgorithm, MaTDR algorithm would still outperform revised TDP approach termscomputational effort. Overall, confirmed could exploit structureMaSTP instances calculate temporal decoupling efficiently before,also distributed manner, avoiding (previously-required) centralization costs,exploiting parallelism lead significant levels speedup. next ask whetherquality solution produced MaTDR algorithm competitive termssolution space completeness.5.3.2 Evaluation Completeness (Flexibility)Hunsberger (2002) introduced two metrics, flexibility (F lex) conversely rigidity(Rig), act relative measures number total solutions represented140fiDistributed Reasoning Multiagent Simple Temporal Problems4500Centralized MaTDRDPPCMaTDR6000Centralized MaTDRDPPCMaTDR4000Nonconcurrent Edge UpdatesNonconcurrent Edge Updates700050004000300020001000350030002500200015001000500008016024032040048056024Number Tasks (T)(a) Nonconcurrent computation numbertasks increases.121620(b) Nonconcurrent computation numberagents increases.2000DPPCMaTDRDPPC1800 MaTDR25001600Number MessagesTotal Number Messages30008Number Agents (A)20001500100014001200100080060040050020000801602403204004805602Number Tasks (T)48121620Number Agents (A)(c) Number messages number tasksincreases.(d) Number messages number agentsincreases.Figure 15: Empirical evaluation MaTDR factory scheduling problem set.temporal network, allowing quality level completeness alternative temporaldecouplings compared. defined flexibility pair timepoints, vivj , sum F lex(vi , vj ) = wij + wji always non-negative consistent STPs.1rigidity pair timepoints defined Rig(vi , vj ) = 1+F lex(v, rigidity,vj )entire STP root mean square (RMS) value rigidity valuespairs timepoints:X2Rig(G) =[Rig(vi , vj )]2 .n (n + 1)i<jimplies Rig(G) [0, 1], Rig(G) = 0 G constraintsRig(G) = 1 G single solution (Hunsberger, 2002). Since Rig(G) requires FPCcalculate, work apply metric post-processing evaluation technique centralizing establishing FPC temporal decouplings returnedalgorithms. exist centralized, polynomial time algorithm calculatingoptimal temporal decoupling (Planken, de Weerdt, & Witteveen, 2010a), requires141fiBoerkoel & Durfeeevaluation metric linear function distance graph edge weights,aggregate rigidity function, Rig(G), unfortunately, not.MaTDR algorithms default HeuristicAssign function assigns timepointmidpoint currently-calculated bounds. assumption assignmentmidpoint (along relaxation) attempts divide slack evenly, practice subsequentassignments influenced earlier ones. example, Figure 13, TRST assignedB . Hence, perhaps10:08AM, rather 10:00AM, due earlier assignment RSTsmarter ways assign timepoints maintain greater amounts flexibility.evaluate one alternative heuristic, locality heuristic, thoughtapplication least-constraining value heuristic attempts less myopicassignment procedure considering loss flexibility neighboring timepoints. Here,agent assigns vk value reduces domains neighboring timepointsleast. described Hunsberger (2002), original TDP approach attempts maximizeflexibility progressively tightening reference bounds timepoints fractiontotal amount would required decoupling.Evaluation. set experiments, compare rigidity temporal decouplings calculated by:Midpoint variant MaTD algorithm HeuristicAssign uses(default) midpoint heuristic, without Relaxation;Midpoint+R MaTD algorithm using midpoint heuristic alongRelaxation sub-routine;Locality variant MaTD algorithm HeuristicAssign assigns vkvalue reduces domains neighboring, local timepoints least (noRelaxation);Locality+R MaTD algorithm using locality heuristic along Relaxation sub-routine;Input rigidity input MaSTN;TDP implementation Hunsbergers RLF variation TDP algorithm(where r = 0.5 = 1.0 lead computational multiplier approximately9) reported calculate least rigid decoupling Hunsberger (2002)(rather RGB variation used earlier, reported efficient).first experiment, used Random Problem Generator parameter settings = 25 X = {50, 200, 800}. left-hand side Table 2 displays rigiditytemporal decoupling calculated approach problems. Unsurprisingly, number external constraints increases, level rigidity acrossapproaches, including inherent rigidity input MaSTN. Combing rigidityresults evaluation computational effort displayed Figure 14, looktrade-offs efficiency quality temporal decoupling approaches.average, compared Midpoint, Midpoint+R approach decreases rigidity 51.0%increasing computational effort 30.2%, Locality approach decreases rigidity142fiDistributed Reasoning Multiagent Simple Temporal ProblemsTable 2: comparison much four different MaTD variants increase rigidity compared input MaSTN previous centralized approach (TDP) across randomlygenerated factory scheduling problem sets.Randomly Generated ProblemsFactory Scheduling ProblemsX = 50X = 200X = 800= 80= 320= 560Input0.4180.5490.7290.2740.1480.119Locality+R0.5080.6990.8780.7560.8380.838Midpoint+R0.4960.6990.8860.7650.8530.855Locality0.6210.8420.9880.9650.9830.982Midpoint0.6280.8490.9880.9680.9830.988TDP0.4820.6680.8650.7200.7220.7062.0% increasing computational effort 146%. Midpoint+R approach, significantly improves output decoupling least computational overhead. Localityheuristic, hand, doubles computational overhead providingsignificant improvement rigidity. also explored combining rigidity-decreasingheuristics, increase computational effort tended additive (the Locality+R approach increases effort 172%), decrease rigidity not. fact,heuristics tried led statistically significant decrease rigidity comparedoriginal Midpoint+R approach cases investigated. Locality+R approachcame closest, decreasing rigidity 49.9% expectation.second experiment, used Factory Scheduling Problem benchmarkparameter settings = 16 = {80, 320, 560} ensured problem settight makespan; results appear right-hand side Table 2. Interestingly,number tasks increases, level rigidity input MaSTN decreases,rigidity calculated decouplings plateaus. adding tasksdirectly correlate adding interdependencies: tasks happen naturallydependent one another assigned different agents level coupling affected.setting tight makespan set tasks effect making critical pathworkflow rigid, leaves many workflow paths flexible. However, decouplingeffectively introduces many additional interim makespan deadlines, lead manyrigid paths workflow. Overall, increased structure problems ledstarker differences approaches. Computing temporal decoupling results 3fold increase rigidity input MaSTP regardless decoupling approachedused. again, including relaxation phase decreased rigidity, additional 20.2%margin using Midpoint heuristic 21.5% margin using Localityheuristic. differences flexibility outputs Midpoint(+R)computationally expensive Locality(+R) approaches insignificant.far conclusive evidence variable assignment heuristicswould outperform either default midpoint locality heuristics. does, however,point robustness MaTDR algorithm recovering flexible decouplings.143fiBoerkoel & Durfeesignificant difference Locality Midpoint heuristics,Locality+R Minimality+R approaches, addition relaxation led significantimprovement cases. fact MaTDR algorithm alone increases rigidityless strategy attributed structure MaSTPrigidity measured. MaTDR algorithm improves distribution flexibilityshared timepoints reactively, instead proactively trying guess good values.MaTD algorithm tightens bounds, general triangulated graph structure formedelimination order branches impact tightening. instance, timepointassigned, defers flexibility possibly many neighboring timepoints,Relaxation algorithm recovers flexibility neighboring timepointsrecovering flexibility originally assigned timepoint.Notice Table 2 original TDP approach increases rigidity least,averaging 20.6% less rigidity Midpoint+R approach randomly generatedproblem set 15.9% factory scheduling problems. However, lower rigiditycomes significant computational costthe original TDP approach incurs, expectation, 10,000 times computational effort Midpoint+R approach. Further,original TDP approach access edge information involving pair timepointsentire, centralized MaSTN, clobbering privacy, MaTDR makes heuristic decoupling decisions much limited information, maintaining greater levelsagent privacy. scheduling environments costs centralization (e.g., privacy) alone would discourage using original TDP approach, others computationaleffort may prohibitive constraints arise faster centralized TDP algorithmcalculate temporal decoupling. Further, differences rigidity decoupling approaches may become mitigated scheduling problems many external constraintsenforce synchronization (e.g., Anns Bills recreational start time). synchronization requires fully assigning timepoints order decouple, may flexibilityrecover, makes efficient, assignment-based MaTD algorithm better choice.5.3.3 SummaryMaTDR algorithm combines reasoning D4PPC algorithm decouplingprocedure first assigns, relaxes, shared timepoints way leads minimaldecoupling MaSTP. showed algorithm complexityoriginal D4PPC algorithm, reduces solve time expectation. Overall,space problems investigated, Midpoint+R approach, expectation, outputshigh-quality temporal decoupling approaches quality (within 20.6% randomproblems 15.9% factory scheduling problems) state-of-the-art centralizedapproach (Hunsberger, 2002), distributed, privacy-maintaining manner multipleorders-of-magnitude faster previous centralized approach.6. Related Worksection, summarize related approaches highlight applications couldbenefit using MaSTP formulation algorithms.144fiDistributed Reasoning Multiagent Simple Temporal Problems6.1 Simple Temporal Problem UncertaintySimple Temporal Problem Uncertainty (STPU) (Vidal & Ghallab, 1996; Vidal& Fargier, 1999) partitions set constraints STP set requirement linksset contingent links. Requirement contingent temporal differenceconstraints, defined Section 2.1. difference requirement linkassigned agent whereas contingent link exogenously assigned outside controlagent value ij [bji , bij ]. STPU checked consistency,also various classes controllability , including strong, weak, dynamic variants(Vidal, 2000; Morris, Muscettola, & Vidal, 2001; Morris & Muscettola, 2005; Lau, Li, &Yap, 2006; Hunsberger, 2009). Whereas consistent STP one exist schedulessatisfy constraints, controllable STPU one exist satisfying schedulesregardless contingent links assigned. Typical strategies establishingmaintaining controllability include preemptively constraining requirement timepointsremaining values consistent possible contingencies. workexplicitly differentiate constraints exogenously updatedcannot. instead use space solutions hedge dynamic constraints.However, nice parallel STPU literature, MaTD algorithm viewednegotiation agents preemptively add new decoupling constraints controluncertainty contingencies introduced interactions agents.6.2 Applications Multiagent SchedulingTemporal constraint networks represent spaces feasible schedules compact intervalstime calculated efficiently. reason, temporal network naturally lendsonline plan monitoring dispatchable executionan online approach wherebydispatcher uses flexible times representation efficiently adapt scheduling upheavalsintroducing new constraints. plan monitor flag current schedulebecome infeasible, dispatcher notify agents time assigns variablesimmediately prior execution (Muscettola, Morris, & Tsamardinos, 1998). Another contribution work show advantages extend distributed, multiagenttemporal constraint networks, also introducing level independence agentsexploit many ways. Properties temporal networks minimality decomposability proven essential representing solution space many centralizedapplications project scheduling (Cesta, Oddi, & Smith, 2002), medical informatics(Anselma, Terenziani, Montani, & Bottrighi, 2006), air traffic control (Buzing & Witteveen,2004), spacecraft control (Fukunaga, Rabideau, Chien, & Yan, 1997). Unfortunately,multiagent scheduling applications (Laborie & Ghallab, 1995; Bresina et al., 2005; Castilloet al., 2006; Smith et al., 2007; Barbulescu et al., 2010) wishing exploit propertiespreviously relied either centralized temporal network representation or, independence also needed, completely disjoint, separate agent networks. highlightspecific example applications may benefit work described paper.approach originally described Smith et al. (2007) extended Barbulescuet al. (2010) exploits flexibility STNs distributed framework. general framework problems solve contains models uncertainty durationsutilities different activities. Using greedy heuristic, scheduler selects set145fiBoerkoel & Durfeeactivities would maximize agent utility, extracts duration bounds distribution possible durations activity, thus creating STP local agent.agent captures current state local problem form STN representation local solution space, agent uses help hedge uncertainty.agent maintains current state problem new constraints arise using efficient,incremental STN consistency algorithms (e.g., Cesta & Oddi, 1996; Planken, de Weerdt, &Yorke-Smith, 2010b). agent maintains local STN problem representationimproved replacement STN identified scheduler mechanism. efficient statemaintenance strategy frees agents spend greater portion time exploring alternativeallocations schedulings activities agents. Barbulescu et al.s approach dividesproblem separate, localized STP instances, requiring distributed state managerreact communicate local scheduling changes may affect agents.deal challenge coordination, Barbulescu et al. establish acceptable time, ,within interdependent activities agents considered synchronized. longagent execute activities within prescribed s, assume consistencyagents. risk inconsistencies agents mitigated (i) restrictingsynchronization scheduling limited time horizon (ii) allowing agents abandonsynchronization soon determined unrealizable.Shah Williams (2008), Shah, Conrad, Williams (2009) Conrad Williams(2011) generalize idea multiagent, disjunctive scheduling problems calculating dispatchable representations. Shah Williams (2008) recognize many disjunctive scheduling possibilities contain significant redundancy, gain representationalefficiency reusing redundant portions existing solution representations muchpossible. algorithm propagates disjunct using recursive, incremental constraintcompilation technique called dynamic back propagation, keeping list implicationsdisjunct temporal network. centralized compilation leadsmuch compact representation previous approach (Tsamardinos, Pollack, &Ganchev, 2001), also faster plan monitoring avoiding need simultaneouslyseparately update disparate STP.domains offer examples work could benefit putting approachpractice. Representing joint solution space multiagent temporal network couldinstead offer agent complete view available scheduling possibilities wellincreased understanding problem impacts (or impacted by) agentsproblems. Further, directly representing reasoning interacting scheduling problem multiple agents also eliminates need agents execute separate threadsexecution monitor communicate state changes. Finally, directly implementingmultiagent temporal network allows agents flexibly directly strike trade-offrepresenting complete joint solution space internalizing decoupling constraints just-in-time manner (e.g., using time-horizon concept Barbulescu et al.,2010), rather rely additional mechanisms manage coordinate state.6.3 Distributed Finite-Domain Constraint ReasoningDistributed Constraint Satisfaction Problem (DCSP) distributed constraint-basedproblem formulation variables discrete, finite domain, rather temporal,146fiDistributed Reasoning Multiagent Simple Temporal Problemscontinuous domain. Two seminal algorithms solving DCSP AsynchronousBacktracking (ABT) Asynchronous Weak-Commitment (AWC) search algorithms(Yokoo, Durfee, Ishida, & Kuwabara, 1998). ABT, AWC, variants algorithmsbased asynchronous variable assignment, use message passing no-goods resolveconflicts. Armstrong Durfee (1997), Hirayama, Yokoo, Sycara (2004), SilaghiFaltings (2005) provide variants algorithms perform intelligent prioritization agents, order local agent variables dynamically, aggregate exchangesinformation agents complex local problems. However, approaches based assignment no-good learning may less applicable continuous-domain, constraint-basedscheduling problems, typical strategies focus maintaining consistent sets solutions using inference. Mailler Lessers Asynchronous Partial Overlay (APO) algorithm(Mailler & Lesser, 2006) deals inconsistencies agents mediation,time centralizes view problem, thus may conflict privacy goalswork. Asynchronous Forward Checking (AFC), proposed evaluated MeiselsZivan (2007), provides mechanisms asynchronously increasing consistency across agents;however pay-off algorithmavoiding expensive backtracking operationsischallenge faced MaSTP algorithms.Distributed Constraint Optimization Problem (DCOP) generalizationDCSP general utility cost functions (soft constraints) assign utilitycost every possible combination assignments particular subset variables, replacing set hard constraints. DCSP translated DCOP convertingconstraints cost functions infinite cost inconsistent assignments. before,utility function known least one agent, DCOP solved findingassignment values variables maximizes total utility (or minimizes total cost).ADOPT (Modi, Shen, Tambe, & Yokoo, 2005) BnB-ADOPT (Yeoh, Felner, & Koenig,2010) decentralized, complete search algorithms solving DCOP using bestfirst branch-and-bound depth-first principles respectively. OptAPO algorithmoptimization variant APO algorithm Mailler Lesser (2004). ADOPTOptAPO generalizations AWC APO respectively, though case, insteadterminating first feasible assignment values variables, agents must exhaustentire search space guarantee assignment return optimal one.DPOP algorithm (Petcu & Faltings, 2005), also distributed implementationgeneral bucket-elimination algorithm solving DCOPs, probablysimilar approach. DPOP requires linear number messages solveDCOP, suffers exponentially (in induced width constraint graph) largemessage sizes. approach, hand, exploit relatively simple temporalconstraints compactly encode impact eliminated variables using binary constraints.6.4 Multiagent Planningterm planning encompasses many specific problem domains including classical (Fikes& Nilsson, 1972), Hierarchical Task Networks (Erol, Hendler, & Nau, 1994), MDPbased planning (Bellman, 1966; Sutton & Barto, 1998). high level, planning involvesdeveloping policies (partially-ordered) sequences actions (provably probabilistically) evolve state world way achieves set goals optimizes147fiBoerkoel & Durfeeobjective function. many types planning problems, plan policy mustalso consider types uncertainty typically found scheduling (e.g., uncertaintyobservations, effects actions, etc.). comparison, work, eventsscheduled already determined taken input. output, insteadsort general policy (partial) sequence actions, specificationtimes assigned timepoint variables satisfy temporal constraints,schedules considered equal. Planning scheduling, interrelated (Myers& Smith, 1999; Garrido & Barber, 2001; Halsey, Long, & Fox, 2004), often treatedseparate subproblems (e.g., McVey, Atkins, Durfee, & Shin, 1997). Smith, Frank,Jonsson (2000), give complete comparison planning scheduling, suggestdifference [between planning scheduling] subtle one: scheduling problemsinvolve small, fixed set choices, planning problems often involve cascading setschoices interact complex ways.many planning approaches, particularly multiagent planning (forcomplete introduction, see desJardins, Durfee, Ortiz Jr, & Wolverton, 1999; de Weerdt& Clement, 2009) decentralized planning (e.g., desJardins & Wolverton, 1999; Bernstein, Zilberstein, & Immerman, 2000) relate inspire approach solvingmultiagent scheduling problems. First, long history exploiting loosely-coupledstructure multiagent planning; Witwicki Durfee (2010) offer one recent example.Second, main challenge multiagent planninghow interleave local planning interagent coordinationis also apt multiagent scheduling problems. planning,approaches agents develop local plans work integrate plans(e.g., Georgeff, 1983), approaches work interdependencies agents firstbuild local plans fit commitments (e.g., ter Mors, Valk, & Witteveen, 2004),approaches blur dichotomy interleaving planning coordination (e.g.,Clement, Durfee, & Barrett, 2007 establishing multiple levels abstraction).Third, planning scheduling involve ordering events checking cycles (toensure goals/conditions clobbered planning ensure consistency scheduling), particularly challenging cycles potentially distributed across multipleagents (Cox, Durfee, & Bartold, 2005).6.5 Resource Task Allocation ProblemsAllocating tasks resources multiple agents studied variety settings (e.g.,Goldberg, Cicirello, Dias, Simmons, Smith, & Stentz, 2003; Nair, Ito, Tambe, & Marsella,2002; Sandholm, 1993; Simmons, Apfelbaum, Fox, Goldman, Haigh, Musliner, Pelican,& Thrun, 2000; Wellman, Walsh, Wurman, & MacKie-Mason, 2001; Zlot & Stentz, 2006).Typically problems involve either assigning set tasks limited number agentsperform or, alternatively, assigning scarce resources agents requireresources. common approach handling task allocation market-basedapproach (e.g., Nair et al., 2002), agents place bids tasks (or subsets taskscombinatorial auctions) according calculated costs performing tasks,tasks assigned lowest bidder. market-based approaches allowagents locally exchange tasks order quickly respond dynamic environment (e.g.,Sandholm, 1993). recent approaches (Goldberg et al., 2003; Zlot & Stentz, 2006)148fiDistributed Reasoning Multiagent Simple Temporal Problemsallow agents negotiate various levels task abstraction/decomposition, primarytemporal reasoning occurs within agent, uses scheduling information estimatecosts bid. Similarly, bidding them, agents append temporal constraintstasks, time-windows, help capture/enforce relevant precedence constraintstasks different agents.work assumes task resource allocation problems alreadysolved, or, necessary, constraints place prevent concurrent, overlapping useresource duplication redundant activity. Additionally, whereas task/resourceallocation cast assignment problem, work deals largely reasoningbounds support flexible times representations. Finally noted greater detailZlot Stentz (2006), optimal, centralized approaches solving problem exist,NP-hard nature problem, coupled uncertain dynamic environment,leads recent approaches distributed well heuristic approximatenature. contrast, work assumes deterministic complete approaches,explicitly model relative costs values various schedules. Instead, agentsprovide users autonomy make cost/value judgments,turn, provide advice implications scheduling decisions.6.6 Operations ResearchMaSTP representations capable representing particular class schedulingproblems. Operations Research (OR) community also interested solving (oftenNP-hard) scheduling problems. overview comparison two fields, Gomes (2000,2001) classifies problems optimization problems, utility function tendsplay important role. Additionally, Gomes notes tends represent problems usingmathematical modeling languages linear non-linear inequalities, uses toolslinear programming, mixed-integer linear programming, non-linear models.Typically, approaches gain traction exploiting problem structuring. exampleapproaches timetabling edge-finding (Laborie, 2003) techniquestightening bounds possible activities occur. full reviewmany models (e.g., Traveling Salesperson Problem, Job Shop Scheduling Problem,Resource Constrained Project Scheduling Problem, Timetabling, etc.) beyond scopepaper, worth pointing synergy AI schedulingcommunities growing (Baptiste, Le Pape, & Nuijten, 1995; Bartak, 1999; Laborie, 2003;Baptiste, Laborie, Le Pape, & Nuijten, 2006; Oddi, Rasconi, & Cesta, 2010).7. Conclusionwork presented paper builds foundational algorithms scheduling agentsassist people managing activities, despite distributed information, implicitconstraints, costs sharing information among agents (e.g., delays, privacy, autonomy,etc.), possibility new constraints dynamically arising. Agents flexibly combineshared reasoning interactions schedules independent reasoninglocal problems. externalizing constraints compactly summarize local subproblems affect other, internalizing new local constraintsdecouple problems one another. approach advantageous149fiBoerkoel & Durfeeproblems interactions agents sparse compared complexityagents individual scheduling problems, algorithms achieve significant computational speedup current art.particularly, contributed formal definition Multiagent Simple Temporal Problem analyzed benefits distributed representation affords.presented D4PPC algorithm, first distributed algorithm calculatingdecentralized representation complete space joint solutions, provedcorrectly establishes partial-path consistency worst-case runtime complexityequal previous state-of-the-art. empirically demonstrated D4PPC scalesproblems containing agents better state-of-the-art centralized counterpart,exhibits steady margin speedup. Exactly effectively load-balances computational effort depends number external constraints coupling agents problems,D4PPC achieves 22-fold reduction nonconcurrent computational effort4PPC problems 25 agents problems studied. Additionally, formally defined Multiagent Temporal Decoupling Problem along first distributedalgorithm solving it. proved MaTD algorithm correct, demonstratedanalytically empirically calculates temporal decoupling upwards fourorders-of-magnitude faster previous approaches, exploiting sparse structure parallelism exists. Additionally, introduced Relaxation algorithm relaxingbounds existing decoupling constraints form minimal temporal decoupling,empirically showed algorithm decrease rigidity upwards 50% (within 1521% state-of-the-art centralized approach) increasing computational effortlittle 20% problems studied. Overall, shown combinationMaTD MaTDR algorithms calculate temporal decoupling fasterD4PPC algorithm, four orders-of-magnitude faster previous state-of-the-artcentralized TDP algorithm.work leads many interesting ongoing future research directions. First,use MaSTN monitor plan execution dispatch scheduling advice usersdistributed manner (as done centralized dispatching in, e.g., Drake, see Conrad& Williams, 2011) rely ability efficiently maintain MaSTNs (Boerkoel et al.,2013) comprehensive empirical understanding inherent trade-offscosts maintaining PPC versus loss flexibility temporal decouplings. Second,MaSTP formulation could adapted include models uncertainty utility,centralized STP (Rossi, Venable, & Yorke-Smith, 2006). Optimally solvingtemporal decoupling problem general models utility NP-hard problem,even centralized case (Planken, de Weerdt, & Witteveen, 2010a). Thus, designingmechanisms augment distributed temporal decoupling algorithm encourageagents solve MaTDP distributed globally optimal (ratherlocally minimal) manner open challenge spans multiagent schedulingalgorithmic game theory. Finally, ideas presented MaSTP extendedmore-general, disjunctive scheduling problems (Boerkoel & Durfee, 2012, 2013).combinatorics disjunctive problems leads significant challengesfinding solutionsNP-hard, structure underlying temporal network, inherentlybinary MaSTP known priori, become conflated tangled combinatorialnumber possible disjunctive choices.150fiDistributed Reasoning Multiagent Simple Temporal ProblemsAcknowledgmentswork supported, part, NSF grants IIS-0534280 IIS-0964512,AFOSR Contract No. FA9550-07-1-0262, 2011 Rackham PredoctoralFellowship. would like thank Leon Planken, Michael Wellman, Martha Pollack, AmyCohn, Stefan Witwicki, Jason Sleight, Elizabeth Boerkoel, Julie Shah helpfulsuggestions.ReferencesAnselma, L., Terenziani, P., Montani, S., & Bottrighi, A. (2006). Towards comprehensivetreatment repetitions, periodicity temporal constraints clinical guidelines.Artificial Intelligence Medicine, 38 (2), 171195.Armstrong, A., & Durfee, E. (1997). Dynamic prioritization complex agents distributedconstraint satisfaction problems. Proceedings International Joint ConferenceArtificial Intelligence (IJCAI-97), pp. 620625.Baptiste, P., Laborie, P., Le Pape, C., & Nuijten, W. (2006). Constraint-based schedulingplanning. Foundations Artificial Intelligence, 2, 761799.Baptiste, P., Le Pape, C., & Nuijten, W. (1995). Incorporating efficient operations researchalgorithms constraint-based scheduling. Proceedings First InternationalJoint Workshop Artificial Intelligence Operations Research.Barbulescu, L., Rubinstein, Z. B., Smith, S. F., & Zimmerman, T. L. (2010). Distributedcoordination mobile agent teams: advantage planning ahead. ProceedingsNinth International Conference Autonomous Agents Multiagent Systems(AAMAS 2010), pp. 13311338.Bartak, R. (1999). Constraint programming: pursuit holy grail. ProceedingsWeek Doctoral Students (WDS99 -invited lecture), pp. 555564.Bellman, R. (1966). Dynamic programming. Science, 153 (3731), 3437.Bernstein, D., Zilberstein, S., & Immerman, N. (2000). complexity decentralizedcontrol Markov decision processes. Proceedings Sixteenth ConferenceUncertainty Artificial Intelligence, pp. 3237.Bliek, C., & Sam-Haroud, D. (1999). Path consistency triangulated constraint graphs.Proceedings International Joint Conference Artificial Intelligence (IJCAI99), Vol. 16, pp. 456461.Boerkoel, J. (2012). Distributed Approaches Solving Constraint-based MultiagentScheduling Problems. Ph.D. thesis, University Michigan.Boerkoel, J., & Durfee, E. (2009). Evaluating hybrid constraint tightening schedulingagents. Proceedings Eighth International Conference Autonomous AgentsMultiagent Systems (AAMAS 2009), pp. 673680.Boerkoel, J., & Durfee, E. (2010). comparison algorithms solving multiagentsimple temporal problem. Proceedings Twentieth International ConferenceAutomated Planning Scheduling (ICAPS 2010), pp. 2633.151fiBoerkoel & DurfeeBoerkoel, J., & Durfee, E. (2011). Distributed algorithms solving multiagent temporal decoupling problem. Proceedings Tenth International ConferenceAutonomous Agents Multiagent Systems (AAMAS 2011), pp. 141148.Boerkoel, J., & Durfee, E. (2012). distributed approach summarizing spaces multiagent schedules. Proceedings Twenty-Sixth Conference Artificial Intelligence (AAAI-12), 17421748.Boerkoel, J., & Durfee, E. (2013). Decoupling multiagent disjunctive temporal problem.Proceedings Twenty-Seventh Conference Artificial Intelligence (AAAI-13),appear.Boerkoel, J., Planken, L., Wilcox, R., & Shah, J. (2013). Distributed algorithmsincrementally maintaining multiagent simple temporal networks. ProceedingsTwenty-Third International Conference Automated Planning Scheduling(ICAPS 2013), appear.Bresina, J., Jonsson, A. K., Morris, P., & Rajan, K. (2005). Activity planningMars exploration rovers. Proceedings Fifteenth International ConferenceAutomated Planning Scheduling (ICAPS 2005), pp. 4049.Buzing, P., & Witteveen, C. (2004). Distributed (re) planning preference information. Proceedings Sixteenth Belgium-Netherlands Conference ArtificialIntelligence, pp. 155162.Castillo, L., Fernandez-Olivares, J., & O. Garca-Perez, F. P. (2006). Efficiently handlingtemporal knowledge HTN planner. Proceedings Sixteenth InternationalConference Automated Planning Scheduling (ICAPS 2006), pp. 6372.Cesta, A., & Oddi, A. (1996). Gaining efficiency flexibility simple temporal problem. Proceedings 3rd Workshop Temporal Representation Reasoning(TIME96), pp. 4550.Cesta, A., Oddi, A., & Smith, S. (2002). constraint-based method project schedulingtime windows. Journal Heuristics, 8 (1), 109136.Clement, B., Durfee, E., & Barrett, A. (2007). Abstract reasoning planning coordination. Journal Artificial Intelligence Research, 28 (1), 453515.Conrad, P., & Williams, B. (2011). Drake: efficient executive temporal planschoice. Journal Artificial Intelligence Research, 42 (1), 607659.Cox, J., Durfee, E., & Bartold, T. (2005). distributed framework solving multiagent plan coordination problem. Proceedings Fourth International JointConference Autonomous Agents Multiagent Systems (AAMAS 2005), pp. 821827.de Weerdt, M., & Clement, B. (2009). Introduction planning multiagent systems.Multiagent Grid Systems, 5 (4), 345355.Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. KnowledgeRepresentation, Vol. 49, pp. 6195.152fiDistributed Reasoning Multiagent Simple Temporal ProblemsDechter, R., & Pearl, J. (1987). Network-based heuristics constraint-satisfaction problems. Artificial Intelligence, 34 (1), 138.Dechter, R. (1999). Bucket elimination: unifying framework reasoning. ArtificialIntelligence, 113 (1-2), 4185.desJardins, M., & Wolverton, M. (1999). Coordinating distributed planning system. AIMagazine, 20 (4), 4553.desJardins, M. E., Durfee, E. H., Ortiz Jr, C. L., & Wolverton, M. J. (1999). surveyresearch distributed, continual planning. AI Magazine, 20 (4), 1322.Erol, K., Hendler, J., & Nau, D. S. (1994). Semantics hierarchical task-network planning.Tech. rep., University Maryland College Park, College Park, MD, USA.Fikes, R., & Nilsson, N. (1972). STRIPS: new approach application theoremproving problem solving. Artificial intelligence, 2 (3-4), 189208.Floyd, R. (1962). Algorithm 97: Shortest path. Communications ACM, 5 (6), 345.Fukunaga, A., Rabideau, G., Chien, S., & Yan, D. (1997). Aspen: framework automated planning scheduling spacecraft control operations. ProceedingsInternational Symposium AI, Robotics Automation Space.Garrido, A., & Barber, F. (2001). Integrating planning scheduling. Applied ArtificialIntelligence, 15 (5), 471491.Georgeff, M. (1983). Communication interaction multi-agent planning. ProceedingsThird National Conference Artificial Intelligence (AAAI-83), pp. 125129.Goldberg, D., Cicirello, V., Dias, M., Simmons, R., Smith, S., & Stentz, A. (2003). Marketbased multi-robot planning distributed layered architecture. Multi-Robot Systems: Swarms Intelligent Automata: Proceedings 2003 InternationalWorkshop Multi-Robot Systems, Vol. 2, pp. 2738.Golumbic, M. (1980). Algorithmic graph theory perfect graphs. Academic Press.Gomes, C. (2000). Artificial intelligence operations research: Challenges opportunities planning scheduling. Knowledge Engineering Review, 15 (1), 110.Gomes, C. (2001). intersection AI OR. Knowledge Engineering Review,16 (1), 14.Halsey, K., Long, D., & Fox, M. (2004). Crikey-a temporal planner looking integration scheduling planning. ICAPS Workshop Integrating PlanningScheduling, pp. 4652.Hirayama, K., Yokoo, M., & Sycara, K. (2004). easy-hard-easy cost profile distributedconstraint satisfaction. Transactions Information Processing Society Japan, 45,22172225.Hunsberger, L. (2002). Algorithms temporal decoupling problem multi-agent planning. Proceedings Eighteenth National Conference Artificial Intelligence(AAAI-02), pp. 468475.Hunsberger, L. (2009). Fixing semantics dynamic controllability providingpractical characterization dynamic execution strategies. Procedings 16th153fiBoerkoel & DurfeeInternational Symposium Temporal Representation Reasoning(TIME 2009),pp. 155162.Kjaerulff, U. (1990). Triangulation graphs - algorithms giving small total state space.Tech. rep., Aalborg University.Laborie, P. (2003). Algorithms propagating resource constraints AI planningscheduling: Existing approaches new results. Artificial Intelligence, 143 (2), 151188.Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. Proceedings Fourteenth International Joint Conference Artificial Intelligence(IJCAI-95), pp. 16431649.Lau, H. C., Li, J., & Yap, R. H. (2006). Robust controllability temporal constraintnetworks uncertainty. Tools Artificial Intelligence, 2006. ICTAI06.18th IEEE International Conference on, pp. 288296.Mailler, R., & Lesser, V. (2006). Asynchronous partial overlay: new algorithm solvingdistributed constraint satisfaction problems. Journal Artificial Intelligence Research, 25 (1), 529576.Mailler, R., & Lesser, V. (2004). Solving Distributed Constraint Optimization ProblemsUsing Cooperative Mediation. Proceedings Third International Joint Conference Autonomous Agents Multiagent Systems (AAMAS 2004), pp. 438445.McVey, C., Atkins, E., Durfee, E., & Shin, K. (1997). Development iterative real-timescheduler planner feedback. Proceedings Fifteenth International JointConference Artificial Intelligence (IJCAI-97), pp. 12671272.Meisels, A., & Zivan, R. (2007). Asynchronous forward-checking DisCSPs. Constraints,12 (1), 131150.Modi, P., Shen, W., Tambe, M., & Yokoo, M. (2005). Adopt: Asynchronous distributedconstraint optimization quality guarantees. Artificial Intelligence, 161 (1-2), 149180.Morris, P., & Muscettola, N. (2005). Temporal dynamic controllability revisited. Proceedings Twentieth National Conference Artificial Intelligence (AAAI-05),pp. 11931198.Morris, P., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporaluncertainty. International Joint Conference Artificial Intelligence (IJCAI-01),pp. 494502.Muscettola, N., Morris, P., & Tsamardinos, I. (1998). Reformulating temporal plansefficient execution. Proceedings International Conference PrinciplesKnowledge Representation Reasoning (KR 1998), pp. 444452.Myers, K., & Smith, S. (1999). Issues integration planning schedulingenterprise control. Proceedings DARPA Symposium Advances EnterpriseControl., 217223.154fiDistributed Reasoning Multiagent Simple Temporal ProblemsNair, R., Ito, T., Tambe, M., & Marsella, S. (2002). Task allocation robocup rescuesimulation domain: short note. Proceedings RoboCup 2001: Robot SoccerWorld Cup V, pp. 751754.Oddi, A., Rasconi, R., & Cesta, A. (2010). Casting project scheduling time windowsDTP. Proceedings ICAPS Workshop Constraint Satisfaction TechniquesPlanning Scheduling Problems (COPLAS 2010), pp. 4249.Petcu, A., & Faltings, B. (2005). scalable method multiagent constraint optimization.International Joint Conference Artificial Intelligence (IJCAI-05), Vol. 19, pp.266271.Planken, L. (2008). Incrementally solving STP enforcing partial path consistency.Proceedings Twenty-seventh Workshop UK Planning SchedulingSpecial Interest Group (PlanSIG 2008), pp. 8794.Planken, L., de Weerdt, M., & van der Krogt, R. (2008). P3 C: new algorithmsimple temporal problem. Proceedings Eighteenth International ConferenceAutomated Planning Scheduling (ICAPS 2008), pp. 256263.Planken, L. R., de Weerdt, M. M., & Witteveen, C. (2010a). Optimal temporal decouplingmultiagent systems. Proceedings Ninth International Joint ConferenceAutonomous Agents Multiagent Systems (AAMAS 2010), pp. 789796.Planken, L. R., de Weerdt, M. M., & Yorke-Smith, N. (2010b). Incrementally solving STNsenforcing partial path consistency. Proceedings Twentieth InternationalConference Automated Planning Scheduling (ICAPS 2010), pp. 129136.Rossi, F., Venable, K., & Yorke-Smith, N. (2006). Uncertainty soft temporal constraintproblems: general framework controllability algorithms fuzzy case. Journal Artificial Intelligence Research, 27 (1), 617674.Sandholm, T. (1993). implementation contract net protocol based marginalcost calculations. Proceedings National Conference Artificial Intelligence(AAAI-93), pp. 256256.Shah, J., & Williams, B. (2008). Fast dynamic scheduling disjunctive temporal constraint networks incremental compilation. Proceedings EighteenthInternational Conference Automated Planning Scheduling (ICAPS 2008), pp.322329.Shah, J. A., Conrad, P. R., & Williams, B. C. (2009). Fast distributed multi-agent plan execution dynamic task assignment scheduling. Proceedings NineteenthInternational Conference Automated Planning Scheduling (ICAPS 2009), pp.289296.Silaghi, M., & Faltings, B. (2005). Asynchronous aggregation consistency distributedconstraint satisfaction. Artificial Intelligence, 161 (1-2), 2553.Simmons, R., Apfelbaum, D., Fox, D., Goldman, R., Haigh, K., Musliner, D., Pelican, M., &Thrun, S. (2000). Coordinated deployment multiple, heterogeneous robots. Proceedings International Conference Intelligent Robots Systems (IROS),pp. 22542260.155fiBoerkoel & DurfeeSmith, D., Frank, J., & Jonsson, A. (2000). Bridging gap planning scheduling. Knowledge Engineering Review, 15 (1), 4783.Smith, S., Gallagher, A., Zimmerman, T., Barbulescu, L., & Rubinstein, Z. (2007). Distributed management flexible times schedules. Proceedings Sixth International Conference Autonomous Agents Multiagent Systems (AAMAS 2007),pp. 472479.Sutton, R., & Barto, A. (1998). Reinforcement learning: introduction, Vol. 1. CambridgeUniv Press.ter Mors, A. W., Valk, J. M., & Witteveen, C. (2004). Coordinating autonomous planners.Proceedings International Conference Artificial Intelligence (ICAI04),pp. 795801.Tsamardinos, I., Pollack, M., & Ganchev, P. (2001). Flexible dispatch disjunctive plans.Proceedings Sixth European Conference Planning (ECP-06), pp. 417422.Vidal, T. (2000). Controllability characterization checking contingent temporalconstraint networks. Principles Knowledge Representation ReasoningInternational Conference, pp. 559570.Vidal, T., & Fargier, H. (1999). Handling contingency temporal constraint networks:consistency controllabilities. Journal Experimental & Theoretical ArtificialIntelligence, 11 (1), 2345.Vidal, T., & Ghallab, M. (1996). Dealing uncertain durations temporal constraintnetworks dedicated planning. Proceedings Twelfth European ConferenceArtificial Intelligence (ECAI-96), pp. 4854.Wellman, M., Walsh, W., Wurman, P., & MacKie-Mason, J. (2001). Auction protocolsdecentralized scheduling. Games Economic Behavior, 35 (1/2), 271303.Witwicki, S. J., & Durfee, E. H. (2010). Influence-based policy abstraction weaklycoupled Dec-POMDPs. Proceedings Twentieth International ConferenceAutomated Planning Scheduling (ICAPS 2010), pp. 185192.Xu, L., & Choueiry, B. (2003). new efficient algorithm solving simple temporalproblem. Proceedings Tenth International Symposium Temporal Representation Reasoning, 2003 Fourth International Conference TemporalLogic (TIME-ICTL 03), pp. 212222.Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: asynchronous branch-andbound DCOP algorithm. Journal Artificial Intelligence Research, 38, 85133.Yokoo, M., Durfee, E., Ishida, T., & Kuwabara, K. (1998). distributed constraintsatisfaction problem: Formalization algorithms. IEEE Transactions KnowledgeData Engineering, 10 (5), 673685.Zlot, R., & Stentz, A. (2006). Market-based multirobot coordination complex tasks.International Journal Robotics Research, 25 (1), 73101.156fiJournal Artificial Intelligence Research 47 (2013) 35-70Submitted 12/12; published 05/13Scheduling Dynamic Aircraft Repair ShopLimited Repair ResourcesMaliheh Aramon BajestaniJ. Christopher Beckmaramon@mie.utoronto.cajcb@mie.utoronto.caDepartment Mechanical & Industrial EngineeringUniversity Toronto, CanadaAbstractaddress dynamic repair shop scheduling problem context military aircraftfleet management goal maintain full complement aircraft longterm. number flights, requirement specific number typeaircraft, already scheduled long horizon. need assign aircraft flightsschedule repair activities considering flights requirements, repair capacity,aircraft failures. number aircraft awaiting repair dynamically changestime due failures therefore necessary rebuild repair schedule online.solve problem, view dynamic repair shop successive static repair schedulingsub-problems shorter time periods. propose complete approach basedlogic-based Benders decomposition solve static sub-problems, design differentrescheduling policies schedule dynamic repair shop. Computational experimentsdemonstrate Benders model able find prove optimal solutions averagefour times faster mixed integer programming model. rescheduling approachaspects scheduling longer horizon quickly adjusting scheduleincreases aircraft available long term 10% compared approacheseither one aspects alone.1. IntroductionUnited States Air Force website outlines readiness one vital elements ensureoperational effectiveness defense strategies (Schwartz, 2012). Deficiency resourcingoperations maintenance stated common culprit poor readiness. Sinceair forces budget-constrained highly dynamic environments, optimal allocationresources activities maintain readiness appropriate level challenging.paper, study problem context military aircraft repair shop readinessdefined ability effectively carry pre-scheduled missions. need decidefailed aircraft repaired guarantee availability aircraft highsteady level. However, high frequency unexpected failures military aircraft (Safaei,Banjevic, & Jardine, 2011) limited repair resources workforce, tools, space(Kozanidis, Gavranis, & Kostarelou, 2012) constrain consistent aircraft availability.Motivated work Safaei et al. (2010, 2011), study problem schedulingmilitary aircraft repair shop, number flights planned long horizon.Every flight, also called wave, maximum requirement specific number aircraftdifferent types though partially carried without maximum complement.beginning time horizon, aircraft either ready pre-flight checkc2013AI Access Foundation. rights reserved.fiAramon Bajestani & Beckawaiting repair repair shop. Aircraft flow long horizon illustrated Figure 1.goal determine assignment aircraft waves schedule repair jobsmaximize flight coverage, is, extent aircraft requirementsflights met. aircraft fails pre- post-flight check, entersrepair shop incorporated current repair schedule. aircraft failurerequires set independent repair activities known characteristics processingtimes resource requirements scheduled repair resources limited capacity.Allocated FlightPre-Flight CheckFailureFlightPost-Flight CheckYesYesRepair ShopFailureFigure 1: Aircraft flow among waves, checks, repair shop long horizon.central idea solution approach view dynamic repair shop successive static sub-problems shorter time periods. solution static sub-problemdetermines assignment aircraft flights schedule repair jobs maximizingflight coverage. failed aircraft enters repair shop previous repairschedule still execution, reschedule repair activities solving new staticsub-problem.proving NP-hardness static sub-problem, explore several techniquessolve problem: mixed integer programming (MIP); constraint programming (CP);logic-based Benders decomposition (LBBD) using either MIP CP; dispatchingheuristic motivated Apparent Tardiness Cost (ATC) dispatching rule.design three different rescheduling policies based length scheduling horizonfrequently rescheduling done.perform two separate empirical studies. first indicates integrationdispatching heuristic LBBD results lowest mean run-time techniquestested optimally schedule repair shop. second experiment demonstratesdefining static scheduling problem longer horizon reschedulingfrequently provide flights 10% higher coverage either one alone.remainder paper organized follows: define problem, provideoverview relevant literature Section 2. Section 3 proves NP-hardnessstatic sub-problem, defines number solution approaches it, presents detailsproposed policies rescheduling dynamic repair shop, describes modelaircraft failures. computational results performance different schedulingtechniques rescheduling done described Section 4.discussion solution approach results presented Section 5. endconclusion directions future work Section 6.36fiScheduling Dynamic Aircraft Repair Shop2. Backgroundsection, formal definition problem given relevant literaturereviewed.2.1 Problem DefinitionFigure 2 snapshot problem time 0, circles represent aircraft. numberflights (five shown) corresponding pre- post-flight checks alreadyscheduled long horizon. assumed total number aircraft constantlong horizon. number aircraft (three diagram) ready pre-flightcheck others currently shop awaiting repair proceedpre-flight check. Failure detected check assume checkalways correctly assess status aircraft negligible cost durationcheck incorporated length corresponding wave.0Repair Shop...st1Wave-1et1 st2et2Wave-2st3et3Wave-3...st4et4Wave-4st5et5Wave-5ChecksFigure 2: Snapshot problem time 0 long horizon.goal assign aircraft waves maximize coverage timecreating feasible repair schedule. scheduling problem constraintsrepair shop limited capacity aircraft subject breakdown. assumeaircraft fails, goes repair shop waits repair operationsperformed.use following notation represent problem.N set aircraft. n failure rate aircraft n N denotingfrequency failure per time unit. example failure rate 0.2 per day,means mean time aircraft failure 5 days.K set aircraft types. Ik denotes set aircraft type k K kaircraft ready (i.e., repair shop time 0). Let |Ik | denote numberaircraft type k, |Ik | k aircraft type k repair shop time 0.k mean failure rate aircraft type k.R set repair resources (called trades). maximum capacity trade r RCr .W set waves. wave, w W , start-time, stw , end-time,etw . wave requires akw aircraft type k.J set existing jobs repair shop. job associated specificaircraft type. Mr set jobs requiring trade r. job might require37fiAramon Bajestani & Beckone trade completed. processing time job j trade r pjrcjr capacity trade r required job j.model deterioration aircraft, time flies wave failure rate, n ,increases percent, i.e., failure rate (1 + 0.01 )n flight. aircraftfails, failure rate repair returns failure.words, one standard repair models maintenance literature, repairminimal (Wang, 2002). probability diagnosing aircraft n failed pre-post-flight checks function failure rate right checks denoted f pre (n )f post (n ). probability failure detection pre-flight checks smallerpost-flight checks aircraft either released repair shopalready passed previous post-flight check successfully (Safaei et al., 2011).find probability failure aircraft pre- post-flight checks specificwave, need track complete history aircraft. example, assumegiven aircraft repaired assigned first wave, three paths:aircraft fails pre-flight check; aircraft passes pre-flight check, flies wave,fails post-flight check; aircraft passes pre-flight check, flies wave,passes post-flight check. Therefore, availability aircraft second waverepresented random variable whose expected value depends probabilitythree different paths scheduling decisions repair failed aircraftsecond wave. Similarly availability aircraft subsequent waves dependsentire path checks, repair shop, waves. number wavesaircraft increase, size state space become prohibitive. Furthermore,repair scheduling decisions impact aircraft histories: probabilityaircraft available third wave different depending repaired timefirst wave second wave. details approximating failureprobabilities presented Section 3.2.1.complexity problem shown, prove NP-hardSection 3.1.2.2 Literature Reviewsection provides necessary background repair shop scheduling problemlogic-based Benders decomposition.2.2.1 Repair Shop SchedulingRepair shops mainly studied machine-repairman problem (Haque & Armstrong, 2007; Stecke, 1992) set workers set machinessubject failures therefore need repair. Workers machines respectively correspond trades aircraft, problem. number workers lessnumber machines, necessary allocate repair jobs workers goaloptimizing given performance measure (e.g., total expected machine downtime)long-term. Derman, Liberman, Ross (1980) early work solvingscheduling problem repair shop single repairman. showed repairing failed machines non-decreasing order failure rate stochastically maximizes38fiScheduling Dynamic Aircraft Repair Shopnumber working machines. literature scheduling repair shopextended considering multiple repairmen, preemptive non-preemptive repair,different failure repair distributions. comprehensive review literaturescheduling repair system provided Iravani, Krishnamurthy, Chao (2007).analytical models literature mainly developed using Markov DecisionProcesses (dynamic programming) guarantee optimality given performancemeasure long-term. models often consider combinatoricsreal scheduling problems different repair capacity limits, different due dates,different resource processing requirements. Therefore, typically result staticdispatching-type repair policy similar found Derman et al. (1980). However,problem, waves different plane requirements processing timesresource requirements repair activities become known enter repairshop. Therefore, believe better performance achieved dealing directlycombinatorics explicitly scheduling repair shop meet waves.handle uncertain combinatorial structure scheduling problems, usedynamic scheduling approach.Dynamic scheduling methodology developed scheduling literatureoperational uncertainties like machine breakdowns unexpected arrival neworders prevent execution schedule planned (Aytug, Lawley, McKay, Mohan,& Uzsoy, 2005; ODonovan, Uzsoy, & McKay, 1999). dynamic scheduling problemoften viewed collection linked static sub-problems. Taking view makesmyriad algorithms developed static scheduling problems applicable. developedalgorithms deal combinatorics scheduling problems optimizequality schedule discrete time points, i.e., static sub-problem. However,cannot completely deal operational uncertainties, real-time disruptionrequires modification schedule either permit execution improvequality schedule considering recently revealed information. processmodifying previous schedule called rescheduling (Vieira, Hermann, & Lin, 2003;Aytug et al., 2005; Bidot, Vidal, Laborie, & Beck, 2009). solve static sub-problemsconnect using rescheduling strategies main aspects dynamicscheduling research. Although aware using dynamic scheduling repairsystem, successfully applied variety scheduling problems including singlemachine (Ovacik & Uzsoy, 1994; ODonovan et al., 1999; Cowling & Johansson, 2002),parallel machines (Vieira, Hermann, & Lin, 2000; Ovacik & Uzsoy, 1995), job shop(Sabuncuoglu & Bayiz, 2000; Liu, Ong, & Ng, 2005; Vinod & Sridharan, 2011).areas literature similarities static problem operationallevel maintenance scheduling problem, general, flight maintenance planningproblem military aircraft, specifically. former literature addresses problemfinding schedule given maintenance activities sum maintenance costsminimized. focus operational level, determining maintenance activitiesperformed time period (Budai, Huisman, & Dekker, 2006). Starting earlywork Wagner, Giglio, Glaser (1964), literature extended developingmathematical models effective solution approaches variety applications (Frost& Dechter, 1998; Haghani & Shafahi, 2002; Budai et al., 2006; Grigoriev, van de Klundert,& Spieksma, 2006). latter literature studies problem maintenance planning39fiAramon Bajestani & Beckmission assignment military aircraft goal decide aircraft flyone perform maintenance on, maximizing long-term availability. Similarmaintenance scheduling literature, mathematical programming common approachsolve problems literature. Kozanidis, Gavranis, Kostarelou (2012) recentlyproposed mixed integer non-linear programming model optimize joint flightmaintenance plan mission aircraft.Safaei et al. (2010) modeled static problem addressed operational levelmaintenance scheduling problem using MIP. MIP includes assignment problemtwo network problems: former assigns aircraft waves latter calculatesexpected number available aircraft waves well expected numberavailable workers repair jobs. later extended work using slightlydifferent MIP model time-indexed approach used enforce workforceavailability constraint verified validity model number instancesdifferent combinations workforce sizes (Safaei et al., 2011).difference static problem addressed paper previousworks operational maintenance scheduling objective function (flight coverage) depends scheduling decisions also outcomes preand post-flight checks. two quite different components problem motivatedecomposition approach, logic-based Benders decomposition, reviewed below.2.2.2 Logic-Based Benders Decompositionclassical Benders decomposition (Benders, 1962; Geoffrion & Graves, 1974) mathematical programming approach solving large-scale mixed integer programming models.partitions problem mixed integer master problem (MP) relaxationglobal model set linear sub-problems (SPs). Solving problem classicalBenders involves iteratively solving MP optimality using solution generate sub-problems. linear programming dual SPs solved derivetightest bound global cost function. bound greater equalcurrent MP solution (assuming maximization problem), MP solution SPsolutions constitute globally optimal solution. Otherwise, constraint, Benders cut,added MP express violated bound another iteration performed.Logic-based Benders decomposition (Hooker & Yan, 1995; Hooker & Ottosson, 2003)developed excluding necessity MP mixed integer model SPslinear. Therefore, inference duals (Hooker, 2005) SPs solved ratherlinear duals find tightest bound global cost function originalconstraints current MP solution. Although logic-based Benders decompositionflexibility modeling problems, standard procedure deriveBenders cuts.Representing relaxation SPs MP, designing strong Benders cutgreat importance decreasing computational effort identify globally feasibleoptimal solution. former results MP solutions likely satisfy SPs,latter rules large number MP solutions iteration (Hooker, 2007).Logic-based Benders decomposition shown effective wide rangeproblems including scheduling (Hooker, 2005, 2007; Beck, 2010), facility vehicle40fiScheduling Dynamic Aircraft Repair Shopallocation (Fazel-Zarandi & Beck, 2012), queue design control problems (Terekhov,Beck, & Brown, 2009).3. Solution Approachmain idea solution approach view dynamic problem linked successivestatic sub-problems. noted above, common approach dynamic scheduling.view results rescheduling strategy based scheduling static sub-problemsshorter time periods. Therefore, two sub-goals: solve connectstatic sub-problems. section, first show static problem NP-hardpresent different solution techniques solving it. define three reschedulingstrategies designed connect static sub-problems. Finally, describe approachmodeling dynamic events, i.e., aircraft failures.3.1 Complexity Static Repair Shop Problemestablish NP-hardness static repair shop problem reduction singlemachine scheduling problem objective ofPminimizing weighted number tardyjobs common due date, i.e., 1|dj = d| wj Uj 1 dj , wj , Uj denotedue date, weight, variable representing whether job tardy job j,respectively. Note job j tardy processing finished due date.problem equivalent one dimensional knapsack problem non-uniform profitshown NP-complete reduction PARTITION problem (Pinedo,2002).Theorem 1. static problem NP-hard.Proof. show instance single machine scheduling problem, I, common due date objective minimizing weighted number tardy jobsreduces static repair shop problem. instance I, assume jobs,jth processing time tj , weight wj , common due date d. Withoutloss generality, assume weights, wj , interval [0, 1].objective schedule jobs sum weights tardy jobs minimized equivalently sum non-tardy job weights maximized. instanceI, instance static repair shop problem formulated onewave, failed aircraft repair shop (|N | = ), aircraft types(|K| = ), one repair resource (|R| = 1) capacity C = 1. start-timewave st1 = d, requiring aircraft. failed aircraft, j, different type,corresponds one repair job repair shop processing time pj1 = tjresource requirement cj1 = 1 single resource. probability failure precheck wave aircraft j (1 wj ). repaired aircraft j contributes flightcoverage survives pre-check probability wj . Therefore, maximize flightcoverage, goal schedule failed aircraft sum probabilities1. notation used describing problem scheduling literature || representsmachine environment, describes processing characteristics constraints detail, denotesobjective function (Pinedo, 2002).41fiAramon Bajestani & BeckPrepaired aircraft survives pre-check, i.e.,wj maximized. goal equivalentmaximizing sum non-tardy job weights instance I. single machinescheduling problem objectiveweighted number tardy jobsPcommon due date, i.e., 1|dj = d| wj Uj , NP-hard (Pinedo, 2002), concludestatic repair shop problem also NP-hard.3.2 Scheduling Techniquesinvestigate number approaches solve repair shop scheduling problem includingmixed integer programming, constraint programming, logic-based Benders decomposition,dispatch rule, simple hybrid approach. approaches described detailsection.3.2.1 Mixed Integer ProgrammingMixed integer programming (MIP) default solution approach many schedulingproblems (Heinz & Beck, 2012). MIP formulation, constraints representedform linear equalities and/or inequalities polyhedral theory linear programmingtechniques relaxation cutting planes embedded state-of-the-art MIPsolvers applied solve problem (Queyranne & Schulz, 1994; Heinz & Beck, 2012).propose novel mixed integer programming model uncertainty outcomechecks modeled expectation. model different and, showSection 4.1.2, significantly faster Safaei et al. (2010, 2011). Table 1summarizes notation defined Section 2.1 defines decision variablesMIP model.section, without loss generality, interpret W set wavescurrent static sub-problem consider start-times waves due dates finishrepair aircraft. Therefore, define = {di |i = 1, 2, ..., |W |, |W | + 1}ordered set due dates consisting wave start-times plus big value, B, sortedascending order. specifically, di equals start-time i-th wave, sti .limited repair capacity, possible failed aircraft cannot repairedtime waves. case, due date repair job assignedd|W |+1 = B. model, B equals sum start-time last wavemaximum processing times jobs trades, i.e., d|W | + max(pjr )j,renforce repair resource capacity d|W | .explained Section 2.1, exact calculation aircraft failure probabilityconsequently expected number available aircraft intractable since dependscomplete aircraft histories. Therefore, distinguish aircraft based typeuse recursive equation (Equation 4) approximate expected number availableaircraft. details Equation (4) provided later section. aircraft typek, average failure rate, k , used calculate probability failure preand post-flight checks, respectively: kpre = f pre (k ) kpost = f post (k ). Furthermore,failure rate aircraft assumed remain constant scheduling horizonstatic problem increase flying wave. Therefore, approximationlikely underestimate number actual aircraft failures.42fiScheduling Dynamic Aircraft Repair ShopNotationN = {1, ..., n, ..., |N |}K = {1, ..., k, ..., |K|}R = {1, ..., r, ..., |R|}W = {1, ..., w, ..., |W |}J = {1, ..., j, ..., |J|}nIkkkset aircraftset aircraft typesset tradesset wavesset repair jobs (failed aircraft) repair shopfailure rate aircraft nset aircraft type knumber aircraft type k repair shop time 0ThePaverage failure rate aircraft type k equalprekkpoststwetwakwMrCrpjrcjr= {d1 , ..., di , ..., d|W |+1 }TheBDecision VariablesZkwxijstjrInferred VariablesUkwEkwetjrnIkn|Ik |probability aircraft type k fails pre-flight checkprobability aircraft type k fails post-flight checkstart-time wave wend-time wave wmaximum number aircraft type k required wave wset repair jobs requiring trade rmaximum capacity trade rprocessing time job j trade rcapacity trade r required process job jset due dates di = sti , |W | d|W |+1 = Bbig value equal d|W | + max(pjr )j,rnumber aircraft type k assigned fly wave wxij = 1 ith due date assigned job j,xij = 0 otherwisestart-time job j trade rnumber aircraft type k whose repair due date stwexpected number available aircraft type k wave wend-time job j trade rTable 1: Summary notation; decision variables inferred variables MIPmodel.MIP model shown Figure 3 Zkw , number aircraft type kassigned fly wave w, true decision variable: choose send fewer aircraftwave currently (in expectation) available. contrast, Ekw expectednumber aircraft type k available wave w based probabilistic outcomesprevious waves number newly repaired aircraft (Ukw ). refer modelMIP rely default branch-and-bound search IBM ILOG CPLEX12.3 solver, state-of-the-art commercial MIP solver solve it. details MIP modelsummarized follows:43fiAramon Bajestani & BeckMaximize|W | |K|XXZkw(1)w=1 k=1Subject to:XUkw =k, w(2)k(3)w(w 6= 1), k(4)Zkw akw ,k, w(5)Zkw Ekw ,k, w(6)j(7)j, r(8)j, r(9)t(t st|W | ), r(10)i, j(11)k, w(12)j, r(13)k, w(14)xij ,jIk , i=wEk1 = (k + Uk1 )(1 kpre ),Ekw = (Ek(w1) Zk(w1) + Ukw )(1X+Zkv (1 kpost )(1 kpre ),kpre )vVw|W |+1Xxij = 1,i=1stjr + pjr = etjr ,|W |+1etjrXxij di ,i=1Xcjr ((t stjr ) (t < etjr )) Cr ,jMrxij {0, 1},0 Ekw |N |,+stjr , etjr Z {0},+Zkw Z {0}, Zkw |N |,Figure 3: global MIP model static repair shop scheduling problem.objective function (1) maximizes number aircraft assigned waves. Although modeled uncertain outcome flight checks expectation,objective function expected wave coverage (i) wavespecific upper bounds plane requirements (ii) maximum wave coveragewave 1. expected number available aircraft, Ekw ,requirement, akw , given wave, extra aircraft fly wavecontribute coverage. flying extra planes, decreaseprobability available next wave.Equation (2) calculates number aircraft type k whose repair due date stw .words, summing decision variables xij job j aircrafttype k i-th due date corresponds start-time wave w gives44fiScheduling Dynamic Aircraft Repair Shopnumber aircraft type k leaving repair shop right pre-flight checkwave w.Equation (3) calculates expected number available aircraft type kfirst wave.Equation (4) calculates expected number available aircraft type kwaves. first term includes aircraft available used previouswave, i.e., (Ek(w1) Zk(w1) ), newly arrived repair shop, i.e.,Ukw . second term sums aircraft become availablecompleted waves since previous wave started Vw = {v|v W, stw1 < etvstw }.Constraints (5) (6) ensure number aircraft assigned flywave less equal number aircraft required expectednumber available.Constraint (7) assigns exactly one due date job.Equation (8) calculates end-time jobs.Constraint (9) guarantees end-time job less equalassigned due date.Constraint (10) logical-and constraint enforcing capacity limit trade rsumming capacity required set jobs repair time t. Sincejobs start-time last wave contribute coverage,capacity constraint enforced start-time last wave, i.e., st|W | .logical constraint evaluates 1 two component constraintsevaluate 1 0 otherwise. logical inequality evaluates 1true 0 otherwise. example, job j repair time t,logical inequalities, (stjr t) (t < etjr ) evaluate 1 logical-andconstraint, therefore, evaluates 1. linearize constraint, rely defaultapproaches IBM ILOG CPLEX handling logical constraints. approachestranslate logical constraints equivalent linear counterparts creationnew variables constraints (CPLEX, 2011).Constraints (11) (14) define domains decision variables.3.2.2 Constraint ProgrammingConstraint programming paradigm solving combinatorial optimization problems.success constraint programming (CP) solving wide variety scheduling problemswell established literature (Beck, Davenport, Davis, & Fox, 1998; Baptiste, Pape,& Nuijten, 2001). scheduling problems usually defined one several instancesconstraints satisfaction problem (CSP) (Baptiste et al., 2001). instance CSPformally described triple (V, D, C) V = {V1 , V2 , ..., Vn } setn variables, = {D1 , D2 , ..., Dn } set variable domains, Di correspondingpossible values Vi take, C = {C1 , C2 , ..., Cm } set constraints,45fiAramon Bajestani & Beckdefined subset variables. constraint Ck = {Vi , ..., Vj } definedCartesian product domains variables scope Di ... Dj satisfiedassignment variables scope corresponds one value tuplesconstraint relation (Beck, 1999). Representing scheduling problems using CSPs resultsmodeling flexibility compared mixed integer programming modelsrestriction type decision variables constraints.CP solves scheduling problems applying three general tools heuristic search, constraint propagation, backtracking within branch-and-bound search tree (Beck, 1999;Beck & Refalo, 2003). Constraint propagation, one key principles contributingsuccess CP, exploited representing problem conjunction global constraints, embeds efficient inference techniques reduce solution spacewithin branch-and-bound search tree (Baptiste et al., 2001). possibility using twoglobal constraints, cumulative global cardinality, formulate static repair shopproblem motivates CP model shown Figure 4.formulate problem using CP, use decision variables Table 1.However, instead xij , define Dj corresponding assigned due date job j.CP model differs MIP several constraints defined below.global cardinality constraint (gcc) syntax gcc(card, value, base)card, value, base arrays variables, values, variables, respectively. gccconstraint satisfied value[i] taken card[i] elements base. CP model,aircraft type k, Constraint (15) enforces Ukw counts number timesstart-time wave w assigned due date jobs associated failed aircrafttype k.cumulative constraint syntax cumulative(s, p, c, C) = {s1 , s2 , ..., sn },p = {p1 , p2 , ..., pn }, c = {c1 , c2 , ..., cn } vectors start-time variables, processing time values, amount required resource job, respectively,C total resource capacity value. cumulative constraint ensures totalamount resource capacity used time never exceeds C (Hooker, 2005).Constraint (17) enforces time windows: job j trade r cannot started later(Dj pjr ). Constraint (18) defines domain decision variables Dj .Maximize Objective (1)Subject to:Constraints (3) (6), (12), (14)gcc([Uk1 , Uk2 , ..., Uk|W | ], [st1 , st2 , ..., st|W | ], [DjIk ]),k(15)cumulative([stjr |j Mr ], [pjr |j Mr ], [cjr |j Mr ], Cr ),r(16)j, r(17)j(18)0 stjr Dj pjr ,Dj {st1 , st2 , ..., st|W | , B},Figure 4: CP model static repair shop scheduling problem.46fiScheduling Dynamic Aircraft Repair Shopimplement model using IBM ILOG CP Optimizer 12.3 default searchused. start-time variables, stjr , defined IloIntervalVar objects. implementglobal constraints, use IloDistribute class gcc constraint IloPulseIloAlwaysIn functions cumulative constraint. Note that, cumulative constraintimplemented time point st|W | .3.2.3 Logic-Based Benders Decompositionstatic problem requires making two different decisions, assigning aircraft wavesscheduling repair jobs failed aircraft, decomposition approach may well suited.logic-based Benders decomposition (LBBD) method formulated masterproblem assigns aircraft waves maximize wave coverage sub-problems createrepair schedules given due dates derived master problem solution.propose four variations: Benders-MIP Benders-MIP-T, master problemssolved using MIP, latter tighter sub-problem relaxation (T stands tighter);Benders-CP Benders-CP-T constraint programming-based master problem.models use CP scheduling sub-problems.Due-Date Assignment Master Problem (DAMP): MIP Model formulatemaster problem MIP model, use binary variable xij job j i-th duedate meaning global MIP model. MIP formulation DAMPfollows:Maximize Objective (1)Subject to:(19)Constraints (2) (7), (11), (12), (14)|W |+1Xcjr pjr Cr max (jMrjMrXxij di ),r(20)i=1MIP cuts(21)master problem incorporates number constraints global MIP model.represent start-times jobs fully represent capacitytrades. common Benders decomposition, master problem includes relaxationsub-problems (Constraints 20) Benders cuts (Constraints 21).Sub-problem Relaxation Defining area job j area rectangle heightcjr width pjr , Constraint (20) relaxation capacity trade, expressinglimit area jobs executed. limit defined using area boundedcapacity trade time interval [0, ] maximum due dateassigned jobs trade. relaxation due Hooker (2005, 2007).tighten relaxation sub-problems Benders-MIP-T approach enforcinganalogous limit multiple intervals: [0, stw ] wave w. interval,sum areas jobs whose assigned due date less equal end-timeinterval must less equal available area. relaxation special47fiAramon Bajestani & Beckcase interval relaxation due Hooker (2005, 2007). Formally, tighter relaxationreplaces Constraint (20) with:|W |+1XjMrcjr pjr ((Xxij di ) stw ) stw Cr ,r, w(22)i=1P|W |+1(( i=1 xij di ) stw ) logical inequality evaluating 1 assigneddue date job j less equal stw .Benders Cuts defining cut formally, demonstrate intuitionexample. Consider due date set, = {14, 17, 20, 35}, and, given trade fivejobs, current master solution: x21 = 1, x12 = 1, x43 = 1, x14 = 1, x15 = 1. Job 1assigned second due date, 17, job 2 first due date, 14, on.current solution infeasible due resource capacity trade, knowleast one jobs must later due date current master solution.can, therefore, constrain sum consecutive xij including onescurrently assigned 1 one less number jobs. example, cutwould be:(x11 + x21 ) + (x12 )+(x13 + x23 + x33 + x43 ) + (x14 ) + (x15 ) 5 1variables represent possible due dates less equal currently assignedjobs. constraining variables one less number jobs,least one job must assigned later due date.Formally, assume iteration h, solution DAMP assigns set, Q, duedates jobs trade r. Assume feasible solution trade rassignments Q. cut iteration h is:X Xxij |Mr | 1,r(23)jMr iI hjrh = {i0 |i0 i, xh = 1} set due date indicesjob j trade r, Ijrijless equal due date index assigned job j iteration h |Mr |number jobs trade r. validity cut proved Section 3.2.6.Due-Date Assignment Master Problem: CP Model also formulateDAMP using CP. Let Dj variable corresponding due date job j similarglobal CP model.48fiScheduling Dynamic Aircraft Repair ShopMaximize Objective (1)Subject to:Constraints (3) (6), (12), (14), (15), (18)Xcjr pjr Cr max (Dj ),rjMrjMr(24)CP cuts(25)master problem modeled using CP includes several constraints global CPmodel. Constraint (24) represents relaxation repair capacity limit tradesguaranteeing sum processing areas set jobs tradeexceed maximum available area.tighter relaxation CP-based DAMP replaces (24) following definingBenders-CP-T approach logical inequality (Dj stw ) evaluates 1due date job j, Dj , less equal start time wave w, stw .Xcjr pjr (Dj stw ) stw Cr ,r, wjMrCP cut based reasoning MIP cuts. assigned set duedates jobs trade r feasible solution SP, cut guaranteenext iteration least one assigned due dates greater value.Formally, cut is:_Dj > Djh ,j MrDjh due date assigned job j iteration h,constraints Mr set jobs trade r.(26)Wrepresents logical-orRepair Scheduling Sub-problem Given set due dates assigned jobstrade, goal repair scheduling sub-problem (RSSP) assign start-timesjobs satisfy due dates trade capacity. use CP formulationRSSP trade modeled cumulative constraint.cumulative([stjr |j Mr ], [pjr |j Mr ], [cjr |j Mr ], Cr ),0 stjr Djh pjr ,rj, r(27)Recall [stjr |j Mr ] tuple start-time variables jobs trade r,Djh value assigned due date job j master problem iteration h.parameters pjr , cjr , Cr defined Table 1. Constraint (27) enforces time windowssimilar constraint (17). worth mentioning RSSP, due date job j,Djh , value; however, decision variable, Dj , global CP model.Since CP approaches shown significantly efficient MIP simplescheduling problems resource capacity constraints (Hooker & Ottosson, 2003; Hooker,2005, 2007), experiment MIP formulations sub-problems.49fiAramon Bajestani & Beckimplement master problems Benders-MIP Benders-MIP-T, use IBMILOG CPLEX 12.3 solver; Benders-CP Benders-CP-T master problemsRSSP implemented IBM ILOG CP Optimizer 12.3. details implementationglobal constraints similar Section 3.2.2.3.2.4 Dispatching HeuristicSince static problem NP-hard, solving optimality may prohibitively expensive.therefore investigate heuristic approach, inspired Apparent Tardiness Cost(ATC) heuristic, composite dispatching rule typically applied single machinescheduling problem sum weighted tardiness objective (Pinedo, 2005).heuristic computes ranking index job sorts jobs ascending orderindex. heuristic iterates jobs, scheduling job earliestavailable time. ranking index use follows:Ij = ST (kj ) exp(F Nj),F Cjjlet kj denote type aircraft j, ST (kj ) start-time first waverequires aircraft type kj . F Nj fraction total number aircraft typekj required first wave requires kj , F Cj maximum proportioncapacity needed job j required trades, follows.F Cj = max(rpjr cjr)ST (kj )CrIntuitively, earlier start-time first relevant wave, higher proportionaircraft required wave, lower proportion capacity requiredwave, sooner job scheduled. exponential function used placeweight start-time.preliminary experiments, three dispatching heuristics investigated,chosen heuristic performing best. first two heuristics rank jobs slightlymax(pjr )max(pjr cjr )different ranking indices equal Ij = ST (kj ) rF Nj Ij = ST (kj ) r F Nj ,respectively. third heuristic two-stage approach based decomposition.first stage finds number aircraft type assigned wave second stageschedules jobs increasing order max(pjr cjr ) considering values determinedj,rfirst stage upper bounds number jobs required wave.preliminary experiments demonstrated chosen dispatching rule results average6% higher wave coverage compared first two heuristics coveragethird heuristic advantage easy understand implement.3.2.5 Hybrid Heuristic-Complete Approacheshybrid heuristic-complete approach heuristic solution provides lower boundmaximization objective (Equation 1) may improve performance completeapproaches. Therefore, simple hybrid first runs dispatching heuristic usesobjective value starting lower bound complete approaches. Assume50fiScheduling Dynamic Aircraft Repair Shopheuristic finds solution, S, f (S) number aircraft assigned waves.complete approaches modified adding following constraint:|W | |K|XXZkw f (S)w=1 k=1LBBD variations, constraint added master problem.3.2.6 Theoretical Resultsguarantee finite convergence LBBD model globally optimal solution,Benders cuts must valid master decision variables must finite domains.Benders cut valid given iteration, h, (1) excludes current globallyinfeasible assignment master problem without (2) removing globally optimalassignments (Chu & Xia, 2004). former guarantees finite convergencelatter guarantees optimality. decision variables DAMP finite domain,sufficient prove satisfaction two conditions.Theorem 2. Cut (23) valid.Proof. condition (1), sub-problem iteration h trade r, definition:X Xxij = |Mr |jMr iI hjrConsequently, cut (23) excludes current assignment master problem.condition (2), consider global optimal solution satisfy cut (23)generated iteration h. cut states least one job must greaterdue date h, violate cut, jobs must equal lesser duedates iteration h. However, sub-problem infeasibleiteration h, sub-problem equal lesser due dates must also infeasibleavailable capacity trade less. Therefore, must infeasiblecontradict assumption globally optimal.Therefore, cut valid.analogous argument holds cut (26).3.3 Rescheduling Strategiesdynamic repair shop problem long horizon viewed static schedulingsub-problems successive time periods. Lets assume start repairing failedaircraft assigning waves based computed schedule time 0. wavemight start repair way repair shop. aircraft fails pre-flightcheck, goes repair shop. failed aircraft requires set independent repairactivities known processing times resource requirements. repair shop,previously failed aircraft might already repaired, might repair,others might awaiting repair. failed aircraft enters repair shop,new static repair scheduling sub-problem set existing jobs (J), number51fiAramon Bajestani & Beckaircraft repair shop aircraft type (k ), failure ratesaircraft (n ) updated. set existing jobs includes recently failed aircraftpreviously failed aircraft whose repairs still way yet started.new static sub-problem added constraint, namely repairs currentlyway cannot disrupted.connect static sub-problems using three different policies denoted Pijj define length scheduling horizon frequency rescheduling numberwaves, respectively. three policies, schedule repair activities, observeaircraft failures, respond failures rescheduling repair activities.three policies discussed follows:P11 : Figure 5, show P11 schedules one wave time (i = 1) rescheduleswave (j = 1). P11 myopic policy aiming providing next firstwave highest possible coverage.P31 : contrast P11 , P31 (Figure 5), scheduling horizon three wavesrescheduling still done wave. P31 longer scheduling horizonP11 trades-off coverage among next three waves. worth mentioningchosen three length scheduling horizon three wavesusually scheduled daily based real data (Safaei et al., 2011).P33 : policy scheduling horizon length three waves reschedulesevery third wave (Figure 5). P33 might trade-off lower coverage nextfirst wave higher coverages second third waves; however,lower frequency rescheduling.3.4 Modeling Aircraft Failuresmodel dynamic events, simulate aircraft failures pre- post-flight checks.Every aircraft either passes fails check. aircraft fails, new set repairactivities known processing times resource requirements added repairshop. aircraft passes, flies wave required. mentioned Section 2.1,repair failure rate aircraft returns failureincreases percent time flies wave due deterioration. n initialfailure rate aircraft n N , failure rate flying w waves without failuren (1 + 0.01 )w .4. Computational Experimentssection, present two separate empirical studies. first study comparesscheduling techniques experimentally presents insights algorithms performance deeper analysis results. second study investigates impactusing different scheduling techniques rescheduling policies observed wavecoverage.52fiScheduling Dynamic Aircraft Repair ShopP11 Policy:Scheduling HorizonScheduling Horizon0Scheduling HorizonScheduling Horizon...st1et1st2Wave-1et2st3Wave-2et3st4Wave-3et4Wave-4Scheduling HorizonP31 Policy:Scheduling HorizonScheduling Horizon0...st1et1st2Wave-1et2st3Wave-2et3st4Wave-3et4Wave-4P33 Policy:Scheduling HorizonScheduling Horizon0...st1et1st2Wave-1et2et3st3Wave-2Wave-3st4et4Wave-4Figure 5: rescheduling policies.4.1 Experimental Results Scheduling Techniquessub-section describes experiment comparing different solution techniques scheduling static repair shop.4.1.1 Experimental Setupproblem instances 10 30 aircraft (in steps 1), 3 4 trades, 3 4 waves.Five instances combination parameters generated, resulting 420 instances(21 total aircraft counts 2 trades counts 2 waves counts 5 instances).Aircraft: number aircraft types equal |N5 | , |N | number aircraft.aircraft randomly assigned different types uniform probability. numberaircraft type k |Ik |. failure rate aircraft randomly chosenuniform distribution [0, 0.5]. failure rate aircraft type k, k , mean failurerate aircraft type k. functions used represent aircraft n probabilityfailures pre- post-flight checks, respectively, f pre (n ) = (1en ) f post (n ) =(1e3n ). worth mentioning conditions reliability function extremevalues failure rates hold true functions used. failure rate goes 0,probability failure equals 0, failure rate goes , probability failureequals 1.Waves: plane requirement aircraft type wave randomly generatedinteger uniform distribution [1, |Ik |]. length wave drawn uniform53fiAramon Bajestani & Beckprobability [3, 5]. make instance loose enough permit feasible solutions yettight enough challenging, lower bound length scheduling horizon (H)needed. sum processing areas jobs trade, r, dividedtrade capacity denoted Sr . LB = max(Sr ) lower bound time requiredrschedule jobs use H = 1.2 LB. end-time wave, etw , generatedet|W | = H rand[0, 3] final wave, |W |, etw = stw+1 rand[0, 3] w < |W |.Trades: capacity limit trade set Cr = 10.Repair Jobs: Eighty percent aircraft repair shop beginning, resulting|J| = 0.8|N | repair jobs. jobs randomly assigned trades replacementnumber jobs per trade equal |J|/2. job requires least onetrade require one trade. capacity trade r used job j, cjr ,drawn [1, 10] processing time, pjr , drawn [r, 10r]: jobs tradeslower indices shorter processing times trades higher indices.Though problem instances generated randomly, setting experimentincludes three numerical examples Safaei et al. (2011) based real data.Furthermore, setting consists instances results problem instancesone half times bigger examples used literature (Safaei et al., 2011)number aircraft 10, 15, 20; number waves 3 4; numbertrades aircraft types equal 3 2.experiments run 7200-second time limit AMD 270 CPU 1MB cache per core, 4 GB main memory, running Red Hat Enterprise Linux 4.4.1.2 Experimental ResultsFigure 6 shows scatter-plots run-times six complete approaches. axeslog-scale, points line = x indicate lower run-time algorithmy-axis. numbers boxes indicate number pointsline. Run-times counted equal differ less 10%.graphs indicate benefit MIP CP, Benders-CP MIP, BendersMIP Benders-CP MIP, Benders-MIP-T Benders-MIP, BendersCP-T Benders-CP. Table 2 presents data, sorted descending percentageproblems solved optimality, algorithms. changes results comparedprevious work (Aramon Bajestani & Beck, 2011b) due improved scheduling models,different solvers, different test problems. scheduling algorithms enhancedusing smaller value B, resource capacity constraint enforced shorter interval,i.e., [0, st|W | ], efficient formulations Constraints (5), (6), (20) used.mean run-time MIP model given Safaei et al. (2011) eight scenarios10 aircraft 3 waves 294.75 seconds. However, proposed MIP modelrun-time 2.64 seconds average ten instances numberaircraft waves, indicating significantly faster Safaei et al.s model.MIP vs. CP MIP approach clear superiority CP, achieving lowerrun-time 89% problem instances. CP model outperforms MIP5% instances solve optimality within time limit.investigation results shows mean quality CP solution 0.27%54fiScheduling Dynamic Aircraft Repair ShopMIP vs. CP10000Benders-CP vs. MIP1000020351691000100100100101Benders-MIP1000Benders-CP1000MIPBenders-MIP vs. Benders-CP10000101101230.10.10.12203720.010.0111000.010.01100001CP10000Benders-MIP-T vs. Benders-MIP10000101Benders-CP-T vs. Benders-CP12210010100100.13781100110.10.1100001000Benders-CP-TBenders-MIP-T100100Benders-CP10001000Benders-MIP1162340.010.013680.010.0110000MIPBenders-MIP vs. MIP100001001612290.010.01100001MIP1000.010.0110000110010000Benders-CPBenders-MIPFigure 6: Run-times (seconds) six complete models.MethodBenders-MIP-T-HybridBenders-MIP-TBenders-MIPMIPMIP-HybridBenders-CPBenders-CP-TDispatching RuleCPMeanTime (s)211.98213.12227.94837.04924.301373.161356.7006857.14Iter.% MP% SP66.63 (8.0)66.44 (8.0)64.66 (8.0)75.72 (15.5)66.42 (10.0)-51.39 (55.05)51.84 (53.98)61.75 (67.44)84.30 (96.96)85.36 (97.36)-48.61 (44.95)48.16 (46.02)38.25 (32.56)15.70 (3.04)14.64 (2.64)-% Solvedoptimality98.1097.8697.6293.5791.1985.2485.009.764.76Table 2: mean run-time, mean (the median) number master problem iterations,mean (median) percentage run-time spent solving master problemsub-problems, percentage problems solved optimalityapproaches.55fiAramon Bajestani & Beckbest found solution across algorithms. Therefore, poor performance CP dueweakness proving optimality.Benders-CP vs. MIP Benders-CP approach better MIP terms runtime 52% instances performing worse 40%. However, Table 2 favors MIPterms overall performance, smaller mean run-time, mainly instancessolved optimality within time limit.Benders-MIP vs. Benders-CP Benders-MIP approach achieves better runtime Benders-CP 88% test problems, performing worse 8%.branching heuristics Benders-CP often lead initial feasible master solutiontighter due dates initial master solution Benders-MIP. tighter, globallyinfeasible initial solution means CP-based master problem model requiresiterations find globally feasible solution.Benders-MIP vs. MIP Benders-MIP approach achieves better run-timeMIP 90% test problems worse run-time 8%, achieving lower meanrun-time solving higher proportion problem instances. time horizonshort, MIP approach faster, however, longer horizons jobs,number constraints variables grows, substantially reducing performance.Benders-MIP-T vs. Benders-MIP tighter relaxation Benders-MIP-T slightlyspeeds LBBD: Benders-MIP-T better run-time Benders-MIP 55%problems instances worse 39%. mean run-time decreases 6% tighterrelaxation solves one instance optimality. Tightening relaxation sub-problemsincreases mean number iterations spite expectation. closer lookresults shows mean number iterations instances solved optimalityapproaches (97.38% instances) decreases: 39.15 41.24 Benders-MIP-TBenders-MIP, respectively. However, mean number iterations instancestimed approaches (1.9% instances) increases 1051.38 BendersMIP 1259.88 Benders-MIP-T. Therefore, increase number iterationsresults timed-out instances support tighter relaxationrequires iterations optimality.Furthermore, percentage time solving master problem decreases comparedBenders-MIP, sub-problem percentage run-time increases. latter observationsub-problems Benders-MIP quickly proved insolubleinitial propagation CP sub-problem model, violate tighter relaxation BendersMIP-T master problem. Therefore, tighter model, sub-problem solver calledeasy sub-problems, increasing percentage run-time spend sub-problems.Benders-CP-T vs. Benders-CP tighter relaxation CP-based master problemresults slightly lower mean run-time; however, shown Figure 6, performancecomparison even.Incomplete Hybrid Approaches dispatching heuristic fast, finding feasible solution problems. However, finds (but, course, prove) optimalsolution 9.76% instances Benders-MIP-T finds proves optimality56fiScheduling Dynamic Aircraft Repair Shopinstances 0.99 seconds average. seems heuristic find optimal solution problem instance relatively easy. mean qualityheuristic solution 16% optimal. industries expensive assets, reductionsolution quality translate costly under-use valuable resource (e.g., fighteraircraft costs vicinity 100 million dollars). However, finding feasible solution almost instantaneously large problem instances makes heuristic approach compellingsituations long run-time might delay carrying waves. example,wave starts within short time, flying wave lower coverage (achieveddispatching heuristic) better carrying long solving timecomplete approaches.evaluate effect combining dispatching heuristic complete approaches, examine using hybrid heuristic-complete approach. smaller feasible setdirect consequence defining bound cost function. MIP modelsearches feasible set, LBBD methods explore infeasible space, one intuitionMIP model benefit using heuristic solution. However, solvingmaster problem LBBD requires searching relaxed feasible space thereforeheuristic starting solution may also speed solving.Table 2 shows marginal benefit bounding Benders-MIP-T approachesdispatching heuristic solution. Bootstrap paired-t tests (Cohen, 1995) also indicatesignificant difference mean run-time p 0.01 either hybrid.Scalability Figure 7 shows results number aircraft per wave increases.|N |aggregate results truncating |W| using instances three waves threefour trades. Note point represents 30 problem instances except x = 320 problems instances. omitted x = 10 10 problem instancespoint. y-axis log-scale.results show LBBD variations outperform techniques acrossratios.Summary following observations performance scheduling techniquessupported empirical study.LBBD approach combining mixed integer programming constraint programming outperforms mixed integer programming model. mean run-timeBenders-MIP almost 4 times lower MIP. Furthermore, defining time ratio given instance MIP run-time divided Benders-MIP run-time,Benders-MIP almost 32 times faster MIP, average, geometric meantime ratio 31.56. time ratios range [0.01, 94132.67] median 38.32.tighter relaxation slightly speeds LBBD. Benders-MIP-T Benders-CP-T,both, run-time 1.2 times faster Benders-MIP Benders-CP,respectively.dispatching heuristic provide optimal solution easy problem instances. However, mean percent relative error heuristic almost 16% overall,indicating dispatching rule effective enough industrieshigh equipment cost.57fiAramon Bajestani & Beck10000CPMIPMIP-HybridBenders-CPBenders-CP-TBenders-MIPBenders-MIP-TBenders-MIP-T-HybridMean Run-Time (sec)10001001010.10.013456789Aircraft/WaveFigure 7: Mean run-time vs. number aircraft per wave (|W | = 3).simple hybridization complete approaches dispatching heuristicresult statistically significant difference run-time.4.2 Experimental Results Rescheduling Strategiessub-section describes experiment investigating impact applying different scheduling techniques rescheduling policies dynamic repair shop.4.2.1 Experimental Setupproblem instances, number aircraft, number trades, totalnumber waves set {10, 15, 20, 25, 30}, {4}, {30} respectively. combination5 instances total 25 instances. instance simulated 20 times.parameters problem instances generated Section 4.1 followingmodifications:Aircraft: failure rate aircraft increased = 5 percent time used.Repair Jobs: Repair jobs entered repair shop time 0 randomly assignedtrades. probability assigning job trade considered 0.5.Waves: start-time wave generated st1 = rand[ H3 , H2 ] first wave,stw = etw1 + rand(0, 40) 1 < w 30. mentioned earlier total numberwaves 30. value H calculated Section 4.1.Dynamic events: simulate aircraft failure, generate random valueuniform distribution [0, 1] aircraft check. random value lessaircrafts probability failure, aircraft fails; otherwise, passes. aircraftsprobability failure pre- post-flight checks calculated using (1 en )(1 e3n ), respectively. Recall that, n failure rate aircraft, n N ,58fiScheduling Dynamic Aircraft Repair Shopincreases = 5 percent time aircraft flies wave. Note passingpre-flight check wave necessarily mean aircraft flies wave.number available aircraft requirements, aircraft flyrandomly selected passed pre-flight check meet requirements.latter assumption implies aircraft ready beginning wave checkedregardless wave requirements. Since assumed pre- post-flightchecks negligible cost, assumption reasonable discover potential aircraftfailures sooner likely increase availability subsequent waves.experiment three techniques including MIP, Benders-MIP-T, dispatching rule discussed Section 3.2. time-limit schedule repair activitiesdecision time point 600 seconds. execute best feasible schedule foundtime-limit algorithm times out. case Benders-MIP-T times out, schedule created dispatching heuristic executed Benders-MIP-T createfeasible schedule times-out.static problem, scheduling uses IBM ILOG CPLEX 12.3 IBM ILOGCP Optimizer 12.3. simulation implemented C++.4.2.2 Experimental Resultssection, discuss results compare performance different schedulingrescheduling techniques availability aircraft long run.investigate effect modeling aircraft failures using expected coverage.Figures 8, 9, 10 illustrate mean observed coverage flight w {1, 2, ..., 28}different scheduling rescheduling techniques. Denoting wplcoverage flightPwi=1 iplw l-th simulation instance p given policy, Owpl =representswmean observed coverage flight w instance p simulationl.mean observedPPPLOwplcoverage flight w, shown figures, calculated Ow = p=1 P l=1, PLL number instances simulations, respectively. Table 3 shows meanobserved coverage flight 28, i.e., O28 variance observed coverageflight 28 scheduling techniques rescheduling policies. illustrated, BendersMIP-T using P31 achieves least 10% higher mean coverage combinationsscheduling rescheduling techniques lowest variance.impact scheduling algorithms complete technique anticipatedachieve higher flight coverage takes expected probabilistic informationMethodBenders-MIP-TMIPDispatching heuristicP110.67 [0.03]0.52 [0.03]0.61 [0.04]O28 [var(.)]P310.77 [0.01]0.64 [0.03]0.61 [0.04]P330.70 [0.01]0.60 [0.02]0.63 [0.03]P11453442(.)P31564644P33483847Table 3: mean (variance) observed coverage flight 28 (O28 [var(.)])mean percentage available aircraft first flight ().59fi110.90.90.80.80.70.7Mean Observed CoverageMean Observed CoverageAramon Bajestani & Beck0.60.50.40.30.20.50.40.30.2Benders-MIP-T: P31Benders-MIP-T: P11Benders-MIP-T: P330.10.6MIP: P31MIP: P11MIP: P330.1001 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 281 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28FlightFlightFigure 8: Mean observed coverage threedifferent policies using BendersMIP-T.Figure 9: Mean observed coveragethree different policies usingMIP.10.9Mean Observed Coverage0.80.70.60.50.40.30.2Heuristic: P31Heuristic: P11Heuristic: P330.101 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28FlightFigure 10: Mean observed coverage threedifferent policies using dispatching heuristic.account creating repair schedule, dispatching heuristicproperty. shown Table 3, Benders-MIP-T complete technique resultshigher mean observed coverage policies compared dispatching heuristic.However, MIP, incorporating mean known information uncertainty scheduling60fiScheduling Dynamic Aircraft Repair Shoprepair activities, results flights lower coverage dispatching heuristictwo rescheduling policies, P11 P33 . understand MIP performance, maketwo conjectures.first conjecture poor performance MIP algorithm frequently times static sub-problems best found feasible solutiondispatching heuristic used create repair schedule. However, resultssupport conjecture. MIP algorithm times 13% scheduling subproblems feasible solution found each, implying dispatching heuristicnever used find repair schedule.second conjecture low coverage achieved MIP attributeddifferent way scheduling repair activities compared two schedulingtechniques. deeper look schedules static sub-problems shows dispatching heuristic Benders-MIP-T schedule repair activities earliest possibletime; however, MIP usually not. Repairing aircraft earlier makes aircraftavailable intuitively increases coverage long run, even though numberpre-flight checks aircraft go increases expectation. quick adjustmentschedule makes failed planes available start-timenext flight. investigate impact making aircraft available earlier using givenscheduling technique,define mean percentage available aircraft first flightPPPPLkplk=1(Pij ) = p=1 l=1kpl denote percentage aircraft availableP LSbeginning first flight k-th static sub-problem l-th simulationinstance p number static sub-problems Pij policy, respectively. example,P31 policy given p l, first static sub-problem includes flights 1, 2, 3.Then, 1pl number aircraft available flight 1 divided total numberaircraft. second static sub-problem schedules flights 2, 3, 4. Therefore, 2plequal number aircraft available flight 2 divided total number aircraft.follow procedure find kpl 28 static sub-problems P31 policy.find (P11 ) (P33 ) using argument considering number staticsub-problems 30 10, respectively.Comparing pair scheduling rescheduling techniques Table 3,positive relationship making aircraft available earlier wave coveragelong term supports conjecture: mean percentage available aircraftfirst flight () increases, mean observed coverage long rum (O28 ) alsoincreases.impact rescheduling policies illustrated Figures 8 9, P11 policyeither Benders-MIP-T MIP short-term (i.e., first three flights) outperforms two policies. However, P31 policy leads consistently highercoverage schedules longer horizon adjusts schedule soonaircraft failures occur. Although P31 dispatching heuristic also responds quicklyaircraft failures, incorporate length scheduling horizonranking index repair activities always repairs aircraft earliest possibletime, resulting flights coverage P11 .Figure 11 displays cumulative percentage flights coverage lessequal Benders-MIP-T, dispatching heuristic MIP denotes61fiAramon Bajestani & Beckvalues x-axis. best performing approach fewer flights lowcoverage flights high coverage. Therefore, curve closerlower right-hand corner. illustrated, Benders-MIP-T using P31 performs bettercombination. P31 rescheduling policy computationally expensivetwo policies, run-time per one static sub-problem, however, small comparedlength scheduling horizon usually one day real applications (Safaeiet al., 2011). P31 policy using Benders-MIP-T run-time average 67 secondsper one static sub-problem less 249 seconds 90% static sub-problems.100P31-Benders-MIP-TP11-Benders-MIP-TP33-Benders-MIP-TP31-HeuristicP11-HeuristicP33-HeuristicP31-MIPP11-MIPP33-MIP90Percentage Flights807060504030201000.10.20.30.40.50.60.70.80.91Flight CoverageFigure 11: percentage flights coverage less equal , denotesvalues x-axis.summary, analysis results identifies Benders-MIP-T P31 (BendersMIP-T:P31 ) best combination scheduling rescheduling techniquesproviding flights higher mean coverage long term. Furthermore,lowest variance observed coverage compared schedulingrescheduling techniques.impact modeling uncertainty expectation randomaircraft failures, coverage achieved scheduling algorithm random variable.ultimate goal construct repair schedule optimal specific realization uncertainty actually occurs. However, since complete informationaircraft failures known future uncertainty dependent previous repairdecisions, impossible find repair schedule ideal realizationuncertainty. discussed earlier, modeled aircraft failures using expectedvalue find optimal repair schedule. Since treating uncertainty expectation form may far optimal actual realization uncertainty, performsensitivity analysis failure rates aircraft investigate optimal repairschedule Benders-MIP-T:P31 hedged various uncertain situations.62fiScheduling Dynamic Aircraft Repair ShopUsing problem instances Section 4.2.1, two experiments setfailure rate aircraft (n ) increased n +0.05 n +0.1. resultsshow mean observed coverage flight 28 decreases 0.69 0.62,variance observed coverage change, indicating modeling uncertaintyusing expected probabilistic information reasonable approach.find possible upper bound (tighter 1) mean observed coverageflight w scheduling algorithm, define policy called Relaxed relaxesrepair capacity limit repairs failed aircraft maximum processing timestrades. Although Relaxed policy makes aircraft available wavesearlier repair scheduling policy, cannot guarantee resultsupper bound observed coverage unless waves requirements.optimal decision might trade immediate low coverage future higher coverageplane requirements waves different. Applying Relaxed schedulingpolicy instances Section 4.2.1, mean observed coverage flight28, i.e. Ow , 24% higher best identified algorithm, Benders-MIP-T:P31 .specifically, Relaxed policy results mean coverage 0.95 variance 0.002.impact longer scheduling horizon vs. frequent reschedulingP31 policy changes repair schedule flight trades-off coverage amongthree consecutive flights scheduling longer horizon. contrast, P11 policyschedules one flight reacts flight P33 policy reasons longerterm without quick response dynamic events. already shown Figures 89, P31 policy complete techniques results higher mean coverage.P11 policy outperforms P33 early waves, P33 provides later waveshigher coverage.superiority policy P31 indicates features quick response dynamic events long-term reasoning contribute overall performance. contribution feature significantly dependent several parameters aircraftfailure rates, plane requirements, repair capacity. failure rate high,probability aircraft diagnosed failed pre- post- flight checks higher.Therefore, arrival rate aircraft repair shop higher previouslyconstructed schedule likely executed is. system, frequentrescheduling likely increase coverage. plane requirementswaves widely varying repair capacity limit tight, trading-off coverageamong flights scheduling longer horizon significantly contributesavailability aircraft long term.Summary following observations scheduling reschedulingdone supported second empirical study:Solving dynamic repair shop problem using Benders-MIP-T scheduling technique P31 rescheduling policy results observed coverage highermean lower variance combination tested.positive relationship making failed aircraft available earlypossible achieving higher coverage long term.63fiAramon Bajestani & BeckSince variance P31 policy Benders-MIP-T sensitivesmall changes aircraft failures, modeling uncertainty respectmean reasonable approach balance different uncertain scenarios.5. Discussionexperimental results demonstrate incorporating probabilistic executiontime reasoning schedule repair activities results better system performance.showed decomposition technique, LBBD, rescheduling policy P31 result10% higher mean observed coverage long term, increasing utilizationvaluable resources. decomposition technique considers mean known probabilisticinformation uncertainty longer scheduling horizon repairs failed aircraftearliest time. P31 rescheduling policy takes advantage up-to-date informationfrequently. also shown variance coverage increaseaircraft failures increase, supporting core idea solution approach: dynamicrepair shop problem viewed collection static sub-problems uncertaintyaircraft failures treated expectation.Optimizing respect mean considering specific class scheduling problems limitations solution approach. address detail discussideas deal them.Modeling uncertainty Optimizing respect expected coverageunfavorable consequences: constructed repair schedule may remarkably poorperformance particular realizations uncertainty might happen actuality (Birge& Louveaux, 1997). number possible approaches solving dynamicproblem. briefly discuss method below.Leaving availability slack repair resources make schedule robustflexible (Branke & Mattfeld, 2002, 2005; Davenport, Gefflot, & Beck, 2001)first approach. example, Branke Mattfeld (2002, 2005) propose anticipatoryscheduling algorithm predict future job arrivals dynamic scheduling problem.secondary objective, called flexibility, included within static sub-problem penalizeearly idleness machines. experimentally show approach improvessystem performance. conclusion consistent observation Section4.2.2 positive relationship repairing aircraft earlier achievinghigher coverage. would therefore interesting adjust MIP modelflexibility term added objective function quantify value making repairresources available early possible. However, appears none existing workslack-based techniques uses analytical reasoning decide amount slacklevel penalization early slack used different levels stochasticity.Modeling static sub-problem two-stage stochastic programming secondapproach (Birge & Louveaux, 1997). first stage decision corresponds constructingrepair schedule occurs aircraft failures pre- post-flight checks. secondstage decision, includes allocation aircraft flights, occurs pre-flightnumber aircraft type k assigned flychecks. One approach define Zkwwave w scenario s. scenario represents possible realization aircraft failures64fiScheduling Dynamic Aircraft Repair Shophorizon static sub-problemp(s). Therefore, objectiveP probabilityP P. main modeling challengefunction (Equation 1) written p(s) k w Zkwcalculate probability scenario. already explained Section 2.1,uncertainty problem exogenous information dependent first-stagedecisions hard represent closed tractable form. Computationally,two-stage stochastic programming models substantially challengingdiscrete optimization problems (Dyer & Stougie, 2003) therefore ability solvemodels problem optimality doubtful.third approach use multi-stage dynamic programming solving dynamicrepair shop problem (Iravani et al., 2007). goal construct repair scheduledecision epoch, marked arrival newly failed aircraft repair shop,coverage maximized long term. Using dynamic programmingframework, state repair shop decision time point tuple aircraftfailure rates, aircraft processing times, aircraft resource requirements.decision action assign start-times failed aircraft repair shop.several challenges modeling problem classical dynamic program. First,expected wave coverage result current state action taken cannotrepresented closed form expression combinatorics involvedscheduling problem. Second, probabilities repair shop transitionsnew state next decision epoch result current state, action taken,revealed uncertainty aircraft failures known hard calculatemainly, again, due combinatorics scheduling decisions factprocessing times resource requirements repair operations become knownupon aircraft failure. challenges indicate analytical tools classicaldynamic programming methodology cannot used modeling problem. However, AItechniques broader scope applicability machine learning (Sutton &Barto, 1998), online stochastic combinatorial optimization (Van Hentenryck & Bent, 2006),hindsight optimization (Burns, Benton, Ruml, Yoon, & Do, 2012) investigatedpotential approaches future work.Extending scheduling problem Although results demonstrated specific class scheduling problems constraint repair capacity limit,solution approach adapted complex scheduling problems. specifically,proposed MIP CP algorithms static sub-problem easily extendedhandle types scheduling constraints precedence constraints. However,modeling problem via decomposition approach would require additional effort.existence precedence constraints among repair activities failed aircraft makesscheduling different repair resources dependent. Therefore, separate RSSPrepair resource cannot defined. One possible idea represent scheduling problemsingle sub-problem appropriate relaxation Benders cut developed.Taking another perspective, decomposed problem stochastic long-term planning deterministic short-term scheduling problems DAMP RSSP, respectively.long-term plan, deal uncertainty using known informationprobability aircraft failures trade-off coverage flights. short65fiAramon Bajestani & Beckterm schedule, construct feasible repair schedule achieve coverage decidedlong-term plan. designed different rescheduling policies investigateinformation revealed time effectively used adjust repair schedulechange long-term plan. conclude changing long-term plan based shortterm information cannot completely incorporated long-term planbeginning significantly increases utilization airplanes.typical hierarchical optimization approach deal interdependency different levels decision makings. However communication technique designedpaper, capable utilizing short-term deterministic scheduling long-termstochastic planning likely lead higher system performance. problemaddressed here, assignment aircraft flights scheduling repairactivities repair shop represent long-term short-term reasoning, respectively. wide range operational decisions viewed integrated optimizationproblems, pattern algorithms designed might applicable. Combiningmaintenance inventory planning job production scheduling exampleintegrated operational problem higher level decision-making, maintenance inventory policy determined whereas lower level, jobs scheduled(Terekhov, Dogru, Ozen, & Beck, 2012; Aramon Bajestani, 2013). maintenanceinventory policy leads infeasible scheduling problem lower level, higherlevel needs informed information inventory maintenance decisions adjusted. Therefore, overall approach demonstrated applicationsproblems typically solved hierarchical optimization approach.6. Conclusionpaper, address problem scheduling dynamic repair shop contextaircraft fleet management. goal maximize flight coverage longterm considering repair capacity aircraft failures. number failedaircraft dynamically changes aircraft breakdowns. proposed solution solvesdynamic problem successive static scheduling problems shorter time periods.Several scheduling algorithms different rescheduling policies proposed schedulerepair activities online dynamic reaction aircraft failures. lengthscheduling horizon frequency rescheduling features defining threepolicies.computational results show optimization approach using logic-based Benders decomposition, scheduling longer horizon, incorporating mean knowninformation aircraft failures, adjusting repair schedule soon new jobs enterrepair shop yield higher mean coverage reasonable approach balancedifferent uncertain scenarios.Developing richer solution approaches better handle uncertainty challenginginteresting topic pursue future work. However, within solution technique,establishing formal framework exactly determine long futureplan ahead quickly change schedule based new informationalso interesting direction future work. answer two questionsseems highly dependent arrival rate new information impact66fiScheduling Dynamic Aircraft Repair Shopnew information overall system performance. quantify two valuesstarting point provide solid responses two questions.Acknowledgmentsresearch supported part Natural Sciences Engineering ResearchCouncil Canada (NSERC) consortium members Centre Maintenance Optimization & Reliability Engineering (C-MORE). Thanks Nima Safaei Dragan Banjevicintroducing problem us subsequent discussions. paper combinedextended version conference paper (Aramon Bajestani & Beck, 2011b) workshoppaper (Aramon Bajestani & Beck, 2011a) already appeared.ReferencesAramon Bajestani, M. (2013). Integrating Maintenance Planning Production Scheduling: Making Operational Decisions Strategic Perspective. Ph.D. thesis, Department Mechanical & Industrial Engineering, University Toronto, Canada.Forthcoming.Aramon Bajestani, M., & Beck, J. C. (2011a). Scheduling dynamic aircraft repair shop.Proceedings ICAPS2011 Workshop Scheduling Planning Applications.Aramon Bajestani, M., & Beck, J. C. (2011b). Scheduling aircraft repair shop.Proceedings Twenty-First International Conference Automated PlanningScheduling (ICAPS2011), pp. 1017.Aytug, H., Lawley, M., McKay, K., Mohan, S., & Uzsoy, R. (2005). Executing productionschedules face uncertainties: review future directions. European JournalOperational Research, 161, 86110.Baptiste, P., Pape, C. L., & Nuijten, W. (2001). Constraint-based Scheduling. KluwerAcademic Publishers, Boston/Dordrecht/London.Beck, J. C. (1999). Texture Measurements Basis Heuristic Commitment TechniquesConstraint-Directed Scheduling. Ph.D. thesis, Department Computer Science,University Toronto, Canada.Beck, J. C. (2010). Checking-up branch-and-check. Proceedings Sixteenth International Conference Principles Practice Constraint Programming (CP2010),pp. 8498.Beck, J. C., Davenport, A. J., Davis, E. D., & Fox, M. S. (1998). ODO project: Towardunified basis constraint-directed scheduling. Journal Scheduling, 1, 89125.Beck, J. C., & Refalo, P. (2003). hybrid approach scheduling earlinesstardiness costs. Annals Operations Research, 118, 4971.Benders, J. (1962). Partitioning procedures solving mixed-variables programming problems. Numerische Mathematik, 4, 238252.Bidot, J., Vidal, T., Laborie, P., & Beck, J. C. (2009). theoretical practical frameworkscheduling stochastic environment. Journal Scheduling, 12, 315344.67fiAramon Bajestani & BeckBirge, J. R., & Louveaux, F. (1997). Introduction Stochastic Programming. SpringerVerlag, New York, USA.Branke, J., & Mattfeld, D. C. (2002). Anticipatory scheduling dynamic job shop problems. Proceedings ICAPS2002 Workshop On-line Planning Scheduling, pp. 310.Branke, J., & Mattfeld, D. C. (2005). Anticipation flexibility dynamic scheduling.International Journal Production Research, 43, 31033129.Budai, G., Huisman, D., & Dekker, R. (2006). Scheduling preventive railway maintenanceactivities. Journal Operational Research Society, 57, 10351044.Burns, E., Benton, J., Ruml, W., Yoon, S., & Do, M. B. (2012). Anticipatory on-line planning. Proceedings Twenty-Second International Conference AutomatedPlanning Scheduling (ICAPS2012), pp. 333337.Chu, Y., & Xia, Q. (2004). Generating Benders cuts general class integer programming problems. Proceedings First International Conference IntegrationAI Techniques Constraint Programming (CPAIOR2004), pp. 127136.Cohen, P. R. (1995). Empirical Methods Artificial Intelligence. MIT Press, Cambridge, Mass.Cowling, P., & Johansson, M. (2002). Using real time information effective dynamicscheduling. European Journal Operational Research, 139, 230244.CPLEX (2011). IBM ILOG CPLEX 12.3 Users Manual. IBM ILOG.http://pic.dhe.ibm.com/infocenter/cosinfoc/v12r3/index.jsp.AvailableDavenport, A. J., Gefflot, C., & Beck, J. C. (2001). Slack-based techniques robustschedules. Proceedings Sixth European Conference Planning (ECP-2001).Derman, C., Lieberman, G. J., & Ross, S. M. (1980). optimal assignment serversrepairman. Journal Applied Probabilities, 19, 577581.Dyer, M., & Stougie, L. (2003). Computational complexity stochastic programmingproblems. Spor-report 2003-20, Department Mathematics Computer Science,Eindhoven Technical University, Eindhoven.Fazel-Zarandi, M. M., & Beck, J. C. (2012). Using logic-based Benders decompositionsolve capacity- distance-constrained plant location problem. INFORMSJournal Computing, 24, 399415.Frost, D., & Dechter, R. (1998). Optimizing constraints: case study schedulingmaintenance electric power units. Lecture Notes Computer Science, 1520, 469488.Geoffrion, A. M., & Graves, G. W. (1974). Multicommodity distribution system designBenders decomposition. Management Science, 20, 822844.Grigoriev, A., van de Klundert, J., & Spieksma, F. C. R. (2006). Modeling solvingperiodic maintenance problem. European Journal Operational Research, 172,783797.68fiScheduling Dynamic Aircraft Repair ShopHaghani, A., & Shafahi, Y. (2002). Bus maintenance systems maintenance scheduling:Model formulations solutions. Transportation Research Part A, 36, 453482.Haque, L., & Armstrong, M. J. (2007). survey machine interference problem.European Journal Operational Research, 179, 469482.Heinz, S., & Beck, J. C. (2012). Reconsidering mixed integer programming MIPbased hybrids scheduling. Proceedings Ninth International ConferenceIntegration AI Techniques Constraint Programming CombinatorialOptimization Problems (CPAIOR2012), pp. 211227.Hooker, J. (2005). hybrid method planning scheduling. Constraints, 10, 385401.Hooker, J. (2007). Planning scheduling logic-based Benders decomposition. Operations Research, 55, 588602.Hooker, J., & Ottosson, G. (2003). Logic-based Benders decomposition. MathematicalProgramming, 96, 3360.Hooker, J., & Yan, H. (1995). Logic circuit verification Benders decomposition.Saraswat, V., & Van Hentenryck, P. (Eds.), Principles Practice ConstraintProgramming: Newport Papers, chap. 15, pp. 267288. MIT Press.Iravani, S. M. R., Krishnamurthy, V., & Chao, G. H. (2007). Optimal server schedulingnonpreemptive finite-population queueing systems. Queueing System, 55, 95105.Kozanidis, G., Gavranis, A., & Kostarelou, E. (2012). Mixed integer least squares optimization flight maintenance planning mission aircraft. Naval Research Logistics,59, 212229.Liu, S. Q., Ong, H. L., & Ng, K. M. (2005). Metaheuristics minimizing makespandynamic shop scheduling problem. Advances Engineering Software, 36, 199205.ODonovan, R., Uzsoy, R., & McKay, K. N. (1999). Predictable scheduling singlemachine breakdowns sensitive jobs. International Journal ProductionResearch, 37, 42174233.Ovacik, I. M., & Uzsoy, R. (1994). Rolling horizon algorithms single-machine dynamicscheduling problem sequence-dependent setup times. International JournalProduction Research, 32, 12431263.Ovacik, I. M., & Uzsoy, R. (1995). Rolling horizon procedures dynamic parallel machinescheduling sequence-dependent setup times. International Journal ProductionResearch, 33, 31733192.Pinedo, M. (2002). Scheduling: Theory, Algorithms, Systems (2nd edition). PrenticeHall, New Jersey, USA.Pinedo, M. (2005). Planning Scheduling Manufacturing Services. Springer SeriesOperations Research. Springer.Queyranne, M., & Schulz, A. (1994). Polyhedral approaches machine scheduling problems. Tech. rep. 408/1994, Department Mathematics, Technische Universitat Berlin,Germany. revised 1996.69fiAramon Bajestani & BeckSabuncuoglu, I., & Bayiz, M. (2000). Analysis reactive scheduling problems job shopenvironment. European Journal Operational Research, 126, 567586.Safaei, N., Banjevic, D., & Jardine, A. K. S. (2010). Workforce constrained maintenancescheduling aircraft fleet: case study. Proceedings Sixteenth ISSAT International Conference Reliability Quality Design, pp. 291297.Safaei, N., Banjevic, D., & Jardine, A. K. S. (2011). Workforce-constrained maintenancescheduling military aircraft fleet: case study. Annals Operations Research,186, 295316.Schwartz, N. (2012). Balancing risk: Readiness, force structure, modernization.CSAF remarks 2012 Air Force Reserve Senior Leader Conference. Availablehttp://www.af.mil/shared/media/document/AFD-120611-028.pdf.Stecke, K. E. (1992). Machine Interference: Assignment Machines Operators. HandbookIndustrial Engineering (2nd edition). John Wiley & Sons.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, Mass.Terekhov, D., Beck, J. C., & Brown, K. N. (2009). constraint programming approachsolving queueing design control problem. INFORMS Journal Computing,21, 546561.Terekhov, D., Dogru, M. K., Ozen, U., & Beck, J. C. (2012). Solving two-machine assembly scheduling problems inventory constraints. Computers IndustrialEngineering, 63, 120134.Van Hentenryck, P., & Bent, R. (2006). Online Stochastic Combinatorial Optimization.MIT Press.Vieira, G. E., Hermann, J. W., & Lin, E. (2000). Predicting performance reschedulingstrategies parallel machine systems. Journal Manufacturing Systems, 19, 256266.Vieira, G. E., Hermann, J. W., & Lin, E. (2003). Rescheduling manufacturing systems:framework strategies, policies methods. Journal Scheduling, 6, 3692.Vinod, V., & Sridharan, R. (2011). Simulation modeling analysis due-date assignmentmethods scheduling decision rules dynamic job shop production system.International Journal Production Economics, 129, 127146.Wagner, H. M., Giglio, R. J., & Glaser, R. G. (1964). Preventive maintenance schedulingmathematical programming. Management Science, 10, 316334.Wang, H. (2002). survey maintenance policies deteriorating systems. EuropeanJournal Operational Research, 139, 469489.70fi