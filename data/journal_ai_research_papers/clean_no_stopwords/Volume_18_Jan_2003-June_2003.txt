Journal Articial Intelligence Research 18 (2003) 149-181

Submitted 10/02; published 02/03

Wrapper Maintenance: Machine Learning Approach
Kristina Lerman

lerman@isi.edu

USC Information Sciences Institute
4676 Admiralty Way
Marina del Rey, CA 90292 USA

Steven N. Minton

minton@fetch.com

Fetch Technologies
4676 Admiralty Way
Marina del Rey, CA 90292 USA

Craig A. Knoblock

knoblock@isi.edu

USC Information Sciences Institute Fetch Technologies
4676 Admiralty Way
Marina del Rey, CA 90292 USA

Abstract
proliferation online information sources led increased use wrappers
extracting data Web sources. previous research focused
quick ecient generation wrappers, development tools wrapper maintenance received less attention. important research problem Web
sources often change ways prevent wrappers extracting data correctly.
present ecient algorithm learns structural information data positive
examples alone. describe information used two wrapper maintenance applications: wrapper verication reinduction. wrapper verication system
detects wrapper extracting correct data, usually Web source
changed format. reinduction algorithm automatically recovers changes
Web source identifying data Web pages new wrapper may generated
source. validate approach, monitored 27 wrappers period year.
verication algorithm correctly discovered 35 37 wrapper changes, made
16 mistakes, resulting precision 0.73 recall 0.95. validated reinduction algorithm ten Web sources. able successfully reinduce wrappers,
obtaining precision recall values 0.90 0.80 data extraction task.

1. Introduction
tremendous amount information available online, much information
formatted easily read human users, computer applications. Extracting
information semi-structured Web pages increasingly important capability
Web-based software applications perform information management functions,
shopping agents (Doorenbos, Etzioni, & Weld, 1997) virtual travel assistants (Knoblock,
Minton, Ambite, Muslea, Oh, & Frank, 2001b; Ambite, Barish, Knoblock, Muslea, Oh, &
Minton, 2002), among others. applications, often referred agents, rely
Web wrappers extract information semi-structured sources convert
structured format. Semi-structured sources explicitly specied
grammar schema, implicit grammar used identify relevant
c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiLerman, Minton & Knoblock

information page. Even text sources email messages structure
heading exploited extract date, sender, addressee, title, body
messages. sources, online catalogs, regular structure
exploited extract data automatically.
Wrappers rely extraction rules identify data eld extracted. Semiautomatic creation extraction rules, wrapper induction, active area
research recent years (Knoblock, Lerman, Minton, & Muslea, 2001a; Kushmerick, Weld,
& Doorenbos, 1997). advanced wrapper generation systems use machine
learning techniques learn extraction rules example. instance, wrapper
induction tool developed USC (Knoblock et al., 2001a; Muslea, Minton, & Knoblock,
1998) commercialized Fetch Technologies, allows user mark data
extracted several example pages online source using graphical user interface.
system generates landmark-based extraction rules data rely
page layout. USC wrapper tool able eciently create extraction rules
small number examples; moreover, extract data pages contain lists,
nested structures, complicated formatting layouts.
comparison wrapper induction, wrapper maintenance received less attention.
important problem, even slight changes Web page layout break
wrapper uses landmark-based rules prevent extracting data correctly.
paper discuss approach wrapper maintenance problem, consists
two parts: wrapper verication reinduction. wrapper verication system monitors
validity data returned wrapper. site changes, wrapper may extract
nothing data correct. verication system detect data
inconsistency notify operator automatically launch wrapper repair process.
wrapper reinduction system repairs extraction rules wrapper works
changed pages.

Pages
labeled

Web
pages

Reinduction System

GUI

Labeled
Web pages

Wrapper
Induction
System

Wrapper
Extracted
data
Change
detected

Automatic
Re-labeling

Wrapper
Verification

Figure 1: Life cycle wrapper
Figure 1 graphically illustrates entire life cycle wrapper. shown gure,
wrapper induction system takes set web pages labeled examples data
extracted. output wrapper induction system wrapper, consisting set
150

fiWrapper Maintenance

extraction rules describe locate desired information Web page.
wrapper verication system uses functioning wrapper collect extracted data.
learns patterns describing structure data. patterns used verify
wrapper correctly extracting data later date. change detected, system
automatically repair wrapper using structural information locate examples
data new pages re-running wrapper induction system examples.
core wrapper maintenance applications machine learning algorithm
learns structural information common data elds. paper introduce
algorithm, DataProG, describe application wrapper maintenance tasks
detail. Though focus web applications, learning technique web-specic,
used data validation general.
Note distinguish two types extraction rules: landmark-based rules extract data exploiting structure Web page, content-based rules,
refer content patterns simply patterns, exploit structure eld itself.
previous work focused learning landmark rules information extraction (Muslea,
Minton, & Knoblock, 2001). current work shows augmenting rules
content-based patterns provides foundation sophisticated wrapper maintenance applications.

2. Learning Content Patterns
goal research extract information semi-structured information sources.
typically involves identifying small chunks highly informative data formatted
pages (as opposed parsing natural language text). Either convention design,
elds usually structured: phone numbers, prices, dates, street addresses, names, schedules, etc. Several examples street addresses given Fig. 2. Clearly, strings
arbitrary, share similarities. objective work learn
structure elds.
4676 Admiralty Way
10924 Pico Boulevard
512 Oak Street
2431 Main Street
5257 Adams Boulevard

Figure 2: Examples street address eld

2.1 Data Representation
previous work, researchers described elds extracted Web pages characterlevel grammar (Goan, Benson, & Etzioni, 1996) collection global features,
number words density numeric characters (Kushmerick, 1999). employ
intermediate word-level representation balances descriptive power specicity
character-level representation compactness computational eciency
global representation. Words, accurately tokens, strings generated
151

fiLerman, Minton & Knoblock

alphabet containing dierent types characters: alphabetic, numeric, punctuation,
etc. use tokens character types assign one syntactic categories:
alphabetic, numeric, etc. categories form hierarchy depicted Fig. 3,
arrows point general less general categories. unique specic token type
created every string appears least k examples, determined preprocessing
step. hierarchical representation allows multi-level generalization. Thus, token
Boulevard belongs general token types Alphanum (alphanumeric strings), Alpha
(alphabetic strings), Upper (capitalized words), well specic type representing
string Boulevard. representation exible may expanded include
domain specic information. example, numeric type divided categories
include range information number Large (larger 1000), Medium
(medium numbers, 10 1000) Small (smaller 10) number
digits: 1, 2, 3digit. Likewise, may explicitly include knowledge type
information parsed, e.g., 5-digit numbers could represented zipcode.

TOKEN

PUNCT

ALPHANUM

ALPHA

UPPER

NUMBER

LOWER

SMALL MEDIUM LARGE

ALLCAPS

CA

HTML

1Digit

Boulevard

2Digit

3Digit

310

Figure 3: Portion token type syntactic hierarchy
found sequence specic general token types useful
describing content information character-level nite state representations
used previous work (Carrasco & Oncina, 1994; Goan et al., 1996). character-level
description far ne grained compactly describe data and, therefore, leads poor
generality. coarse-grained token-level representation appropriate Web
data types. addition, data representation schemes used previous work attempt
describe entire data eld, use starting ending sequences,
patterns, tokens capture structure data elds. reason
similar one above: using starting ending patterns allows us generalize
structural information many complex elds lot variability.
elds, e.g., addresses, usually regularity start end
exploit. call starting ending patterns collectively data prototype.
example, consider set street addresses Fig. 2. examples start
152

fiWrapper Maintenance

pattern <Number Upper> end specic type <Boulevard> generally
<Upper>. Note pattern language allow loops recursion. believe
recursive expressions useful representations types data trying
learn, harder learn lead over-generalization.
2.2 Learning Positive Examples
problem learning data prototype set examples labeled
belonging (or not) class may stated one two related ways: classication
conservation task. classication task, positive negative instances
class used learn rule correctly classify new examples. Classication
algorithms, like FOIL (Quinlan, 1990), use negative examples guide specialization
rule. construct discriminating descriptions satised
positive examples negative examples. conservation task, hand,
attempts nd characteristic description (Dietterich & Michalski, 1981) conserved
patterns (Brazma, Jonassen, Eidhammer, & Gilbert, 1995), set positive examples
class. Unlike discriminating description, characteristic description often include
redundant features. example, learning description street addresses, city
names serving negative examples, classication algorithm learn <Number>
good description, street addresses start none city names
do. capitalized word follows number addresses redundant feature,
add discriminating power learned description. However,
application using description encounters zipcode future, incorrectly
classify street address. problem could avoided <Number Upper>
learned description street addresses. Therefore, negative examples
available learning algorithm, description capture regularity
data, including redundant features, order correctly identify new instances
class dierentiate classes. Ideally, characteristic description
learned positive examples alone discriminating description learned
classication algorithm positive negative examples, negative examples
drawn innitely many classes. widely used machine learning
algorithms (e.g., decision trees (Quinlan, 1993), inductive logic programming (Muggleton,
1991)) solve classication task, fewer algorithms learn characteristic
descriptions.
applications, appropriate source negative examples problematic; therefore,
chose frame learning problem conservation task. introduce algorithm
learns data prototypes positive examples data eld alone. algorithm
nds statistically signicant sequences tokens. sequence token types signicant
occurs frequently would expected tokens generated randomly
independently one another. words, sequence constitutes pattern
describes many positive examples data highly unlikely
generated chance.
algorithm estimates baseline probability token types occurrence
proportion types examples data eld type. Suppose
learning description set street addresses Fig. 2, already found
153

fiLerman, Minton & Knoblock

signicant token sequence e.g., pattern consisting single token <Number>
want determine whether specic pattern, <Number Upper>, also
signicant pattern. Knowing probability occurrence type Upper,
compute many times Upper expected follow Number completely chance.
observe considerably greater number sequences, conclude longer
pattern also signicant.
use hypothesis testing (Papoulis, 1990) decide whether pattern signicant.
null hypothesis observed instances pattern generated chance,
via random, independent generation individual token types. Hypothesis testing
decides, given condence level, whether data supports rejecting null hypothesis.
Suppose n identical sequences generated random source. probability
token type (whose overall probability occurrence p) next type
k sequences binomial distribution. large n, binomial distribution
approaches normal distribution P (x, , ) = np 2 = np(1p). cumulative
probability probability observing least n1 events:
P (k n1 ) =


n1

P (x, , )dx

(1)

use polynomial approximation formulas (Abramowitz & Stegun, 1964) compute
value integral.
signicance level test, , probability null hypothesis rejected
even though true, given cumulative probability above. Suppose set
= 0.05. means expect observe least n1 events 5% time
null hypothesis. number observed events greater, reject null hypothesis
(at given signicance level), i.e., decide observation signicant. Note
hypothesis test derived observation (data). constraint reduces
number degrees freedom test; therefore, must subtract one number
observed events. also prevents anomalous case single occurrence
rare event judged signicant.
2.3 DataProG Algorithm
describe DataProG, algorithm nds statistically signicant patterns
set token sequences. preprocessing step text tokenized, tokens
assigned one syntactic types (see Figure 3). patterns encoded
type prex tree, node corresponds token type. DataProG relies
signicance judgements grow tree prune nodes. Every path
resulting tree starting root node corresponds signicant pattern found
algorithm. section, focus discussion version algorithm
learns starting patterns. algorithm easily adapted learn ending patterns.
present pseudocode DataProG algorithm Table 1. DataProG grows
pattern tree incrementally (1) nding signicant specializations (i.e., longer patterns) pattern (2) pruning less signicant generalizations (or specializations) among patterns length. last step, DataProG extracts
signicant patterns pattern tree, including generalizations (i.e., shorter patterns) found signicant given specic (i.e., longer) patterns.
154

fiWrapper Maintenance

DATAPROG MAIN LOOP
Create root node tree;
next node Q tree
Create children Q;
Prune nodes;
Extract patterns tree;

CREATE CHILDREN Q
token type next position examples
Let C = NewNode;
Let C.token = T;
Let C.examples = Q.examples followed T;
Let C.count = |C.examples|;
Let C.pattern = concat(Q.pattern );
Signicant(C.count, Q.count, T.probability)
AddChildToTree(C, Q);
End
End loop

PRUNE NODES
child C Q
sibling C s.t. S.pattern C.pattern
Let N = C.count S.count
Not(Signicant(N, Q.count, C.token.probability))
Delete C;
break;
Else
Delete S;
End
End loop
End C loop

EXTRACT PATTERNS TREE
Create empty list;
every node Q tree
every child C Q
Let N = C.count (Si .count|Si Children(C))
Signicant( N, Q.count, C.token.probability)
Add C.pattern list;
Return (list patterns);

Table 1: Pseudocode DataProG algorithm

155

fiLerman, Minton & Knoblock

tree empty initially, children added root node. children
represent tokens occur rst position training examples often
expected chance. example, learning addresses examples
Fig. 2, root two child nodes: Alphanum Number. tree extended
incrementally node Q. new child added Q every signicant specialization
pattern ending Q. explained previously, child node judged signicant
respect parent node number occurrences pattern ending
child node suciently large, given number occurrences pattern ending
parent node baseline probability token type used extend pattern.
illustrate addresses example, suppose already found pattern <Number
Upper> signicant. ways extend tree (see Fig. 4) given data:
<Number Upper Alphanum>, <Number Upper Alpha>, <Number Upper Upper>,
<Number Upper Street>, <Number Upper Boulevard>, <Number Upper Way>.
last patterns judged signicant = 0.05. example,
<Number Upper Upper> signicant, Upper follows pattern <Number
Upper> times,1 probability observing least many longer
sequences purely chance 0.0002.2 Since probability less , judge
sequence signicant.

ROOT
NUMBER
UPPER

ALPHANUM

ALPHA

UPPER

Boulevard

Street

Figure 4: Pattern tree describes structure addresses. Dashed lines link nodes
deleted pruning step.

next step prune tree. algorithm examines pair sibling nodes,
one general other, eliminates less signicant pair.
precisely, algorithm iterates newly created children Q,
least general, every pair children Ci Cj , Ci .pattern
Cj .pattern (i.e., Cj .pattern strictly general Ci .pattern), algorithm keeps
Cj explains signicantly data; otherwise, keeps Ci . 3
1. small numbers used illustrative purposes typical data sets
patterns learned much larger.
2. calculation cumulative probability depends occurrence probability Upper. count
occurrence token type independently others. example, occurrence probability
(relative fraction) type Upper 0.18.
3. DataProG based earlier version algorithm, DataPro, described conference paper (Lerman & Minton, 2000). Note original version algorithm, specic patterns
always kept, regardless whether general patterns found signicant not.

156

fiWrapper Maintenance

Let us illustrate pruning step example pattern tree Fig. 4. eliminate node AlphaNum, examples match pattern <Number Upper Alphanum> also match pattern <Number Upper Alpha> thus, Alphanum
signicant given specialization Alpha. eliminate node Alpha similar
reason. Next, check whether <Number Upper Upper> signicant given patterns
<Number Upper Boulevard> <Number Upper Street>. 2 instances
address eld match pattern <Number Upper Boulevard>, 2 addresses
match <Number Upper Street>. <Number Upper Upper> matches signicantly
4 addresses, retained specic patterns pruned
tree; otherwise, deleted specic ones kept. every example
described one pattern given length, pruning step ensures size
tree remains polynomial number tokens, thereby, guaranteeing reasonable
performance algorithm.
entire tree expanded, nal step extract signicant patterns
tree. Here, algorithm judges whether shorter (more general) pattern, e.g.,
<Number Upper>, signicant given longer specializations it, e.g., <Number
Upper Boulevard> <Number Upper Street>. amounts testing whether
excess number examples explained shorter pattern, longer
patterns, signicant. pattern ends terminal node tree signicant.
Note set signicant patterns may cover examples data set,
fraction occur frequently expected chance (at signicance
level). Tables 24 show examples several data elds yellow pages source (Bigbook)
stock quote source (Y ahoo Quote), well starting patterns learned
eld.

3. Applications Pattern Learning
explained introduction, wrapper induction systems use information
layout Web pages create data extraction rules therefore vulnerable changes
layout, occur frequently site redesigned. cases wrapper
continues extract, data longer correct. output wrapper may also
change format source data changed: e.g., $ dropped
price eld (9.95 instead $9.95), book availability changes Ships
immediately Stock: ships immediately. applications, Web
agents (Ambite et al., 2002; Chalupsky et al., 2001), rely data extracted wrappers,
wrapper maintenance important research problem. divide wrapper maintenance problem two parts, described separately paper. Wrapper verication
automatically detects wrapper extracting data correctly Web source,
wrapper reinduction automatically xes broken wrappers. applications learn
description data, patterns learned DataProG signicant part.

introduced strong bias specic patterns results, led high proportion
false positives wrapper verication experiments. Eliminating specicity bias, improved
performance algorithm verication task.

157

fiLerman, Minton & Knoblock

BUSINESS NAME
Chado Tea House
Saladang
Information Sciences Institute
Chaya Venice
Acorda Therapeutics
Cajun Kitchen
Advanced Medical Billing Services
Vega 1 Electrical Corporation
21st Century Foundation
TIS Season Gift Shop
Hide Sushi Japanese Restaurant
Aoat Sushi
Prebica Coee & Cafe
L Orangerie
Emils Hardware
Natalee Thai Restaurant
Casablanca
Antica Pizzeria
NOBU Photographic Studio
Lotus Eaters
Essex Coney
National Restaurant
Siam Corner Cafe
Grand Casino French Bakery
Alejo Presto Trattoria
Titos Tacos Mexican Restaurant Inc
Killer Shrimp
Manhattan Wonton CO
Starting patterns
<Alpha Upper>
<Alpha Upper Upper Restaurant>
<Alpha >

ADDRESS
8422 West 1st Street
363 South Fair Oaks Avenue
4676 Admiralty Way
110 Navy Street
330 West 58th Street
420 South Fairview Avenue
9478 River Road
1723 East 8th Street
100 East 85th Street
15 Lincoln Road
2040 Sawtelle Boulevard
87 East Colorado Boulevard
4325 Glencoe Avenue
903 North La Cienega Boulevard
2525 South Robertson Boulevard
998 South Robertson Boulevard
220 Lincoln Boulevard
13455 Maxella Avenue
236 West 27th Street
182 5th Avenue
1359 Coney Island Avenue
273 Brighton Beach Avenue
10438 National Boulevard
3826 Main Street
4002 Lincoln Boulevard
11222 Washington Place
523 Washington Boulevard
8475 Melrose Place
<Number Upper Upper>
<Number Upper Upper Avenue>
<Number Upper Upper Boulevard>

Table 2: Examples business name address elds Bigbook source,
patterns learned

158

fiWrapper Maintenance

CITY
Los Angeles
Pasadena
Marina Del Rey
Venice
New York
Goleta
Marcy
Brooklyn
New York
Bualo
Los Angeles
Pasadena
Marina Del Rey
West Hollywood
Los Angeles
Los Angeles
Venice
Marina Del Rey
New York
New York
Brooklyn
Brooklyn
Los Angeles
Culver City
Marina Del Rey
Culver City
Marina Del Rey
West Hollywood
Starting patterns
<Upper Upper>
<Upper Upper Rey>

STATE
CA
CA
CA
CA
NY
CA
NY
NY
NY
NY
CA
CA
CA
CA
CA
CA
CA
CA
NY
NY
NY
NY
CA
CA
CA
CA
CA
CA

PHONE
( 323 ) 655
( 626 ) 793
( 310 ) 822
( 310 ) 396
( 212 ) 376
( 805 ) 683
( 315 ) 793
( 718 ) 998
( 212 ) 249
( 716 ) 839
( 310 ) 477
( 626 ) 792
( 310 ) 823
( 310 ) 652
( 310 ) 839
( 310 ) 855
( 310 ) 392
( 310 ) 577
( 212 ) 924
( 212 ) 929
( 718 ) 253
( 718 ) 646
( 310 ) 559
( 310 ) 202
( 310 ) 822
( 310 ) 391
( 310 ) 578
( 323 ) 655

<AllCaps>

<( 3digit ) 3digit - Large>

-

2056
8123
1511
1179
7552
8864
1871
2550
3612
5090
7242
9779
4446
9770
8571
9380
5751
8182
7840
4800
1002
1225
1357
6969
0095
5780
2293
6030

Table 3: Examples city, state phone number elds Bigbook source,
patterns learned

159

fiLerman, Minton & Knoblock

PRICE CHANGE
+ 0 . 51
+ 1 . 51
+ 4 . 08
+ 0 . 83
+ 2 . 35
- 10 . 84
- 1 . 24
- 1 . 59
- 2 . 94
+ 1 . 04
- 0 . 81
+ 4 . 45
+ 0 . 16
- 3 . 48
+ 0 . 49
- 3 . 38
+ 1 . 15
- 2 . 86
- 6 . 46
- 0 . 82
+ 2 . 00
+ 0 . 13
- 1 . 63
Starting patterns
<Punct 1digit . 2digit>

TICKER
INTC
IBM
AOL

LU
ATHM
COMS
CSCO
GTE
AAPL
MOT
HWP
DELL
GM
CIEN
EGRP
HLIT
RIMM
C
GPS
CFLO
DCLK
NT
BFRE
QCOM

VOLUME
17 , 610 , 300
4 , 922 , 400
24 , 257 , 300
8 , 504 , 000
9 , 789 , 300
5 , 646 , 400
15 , 388 , 200
19 , 135 , 900
1 , 414 , 900
2 , 291 , 800
3 , 599 , 600
2 , 147 , 700
40 , 292 , 100
1 , 398 , 100
4 , 120 , 200
7 , 007 , 400
543 , 400
307 , 500
6 , 145 , 400
1 , 023 , 600
157 , 700
1 , 368 , 100
4 , 579 , 900
149 , 000
7 , 928 , 900

<AllCaps>

<Number , 3digit , 3digit>

PRICE
122 3 / 4
109 5 / 16
63 13 / 16
53 1 / 16
68
29 7 / 8
57 11 / 32
134 1 / 2
65 15 / 16
117 3 / 4
169 1 / 4
145 5 / 16
57 3 / 16
77 15 / 16
142
25 7 / 8
128 13 / 16
132 1 / 4
49 15 / 16
44 5 / 8
103 1 / 4
106
124 1 / 8
46 9 / 16
128 1 / 16
<Medium 1digit / Number>
<Medium 15 / 16 >

Table 4: Data examples ahoo Quote source, patterns learned

160

fiWrapper Maintenance

3.1 Wrapper Verification
data extracted wrapper changes signicantly, indication
Web source may changed format. wrapper verication system uses examples
data extracted wrapper past known correct order
acquire description data. learned description contains features two types:
patterns learned DataProG global numeric features, density tokens
particular type. application checks description still applies
new data extracted wrapper. Thus, wrapper verication specic instance
data validation task.
verication algorithm works following way. set queries used retrieve
HTML pages wrapper extracts (correct) training examples. algorithm
computes values vector features, "k, describes eld training
examples. features include patterns describe common beginnings (or
endings) eld. verication phase, wrapper generates set (new)
test examples pages retrieved using set queries, computes feature
vector "r associated eld test examples. two distributions, "k "r
(see Fig. 5), statistically (at signicance level), wrapper judged
extracting correctly; otherwise, judged failed.

16
training set
test set

feature value

14
12
10
8
6
4
2
0
1

2

3

4

5

6

7

feature

Figure 5: hypothetical distribution features training test examples

eld described vector, whose ith component value ith feature,
number examples match pattern j. addition patterns, use
following numeric features describe sets training test examples: average
number tuples-per-page, mean number tokens examples, mean token length,
density alphabetic, numeric, HTML-tag punctuation types. use goodness
method (Papoulis 1990) decide whether two distributions same. use
goodness method, must rst compute Pearsons test statistic data.
Pearsons test statistic dened as:
161

fiLerman, Minton & Knoblock

q=



(ti ei )2
i=1

ei

(2)

ti observed value ith feature test data, ei expected
value feature, number features. patterns ei = nri /N ,
ri number training examples explained ith patter, N number
examples training set n number examples test set. numeric
features ei simply value feature training set. test statistic q
chi-squared distribution 1 independent degrees freedom. q < 2 (m 1; ),
conclude signicance level two distributions same; otherwise,
conclude dierent. Values 2 dierent values looked
statistics table calculated using approximation formula.
order use test statistic reliably, helps use many independent features
possible. series verication experiments reported (Lerman & Minton, 2000),
used starting ending patterns average number tuples-per-page feature
computing value q. found method tended overestimate
test statistic, features (starting ending patterns) independent.
experiments reported paper, use starting patterns, order
increase number features, added numeric features description data.
3.1.1 Results
monitored 27 wrappers (representing 23 distinct Web sources) period ten
months, May 1999 March 2000. sources listed Table 5. wrapper,
results 1530 queries stored periodically, every 710 days. used
query set source, except hotel source, accepted dated queries,
change dates periodically get valid results. set new results
(test examples) compared last correct wrapper output (training examples).
verication algorithm used DataProG learn starting patterns numeric
features eld training examples made decision high signicance
level (corresponding = 0.001) whether test set statistically similar
training set. none starting patterns matched test examples data
found changed signicantly data eld, concluded wrapper failed
extract correctly source; otherwise, data elds returned statistically
similar data, concluded wrapper working correctly.
manual check 438 comparisons revealed 37 wrapper changes attributable
changes source layout data format.4 verication algorithm correctly discovered 35 changes made 15 mistakes. mistakes, 13 false positives,
means verication program decided wrapper failed reality
working correctly. two errors important false negatives,
meaning algorithm detect change data source. numbers
4. Seven were, fact, internal wrapper itself, wrapper modied extract
$22.00 instead 22.00 price eld. actions mostly outside control,
chose classify wrapper changes.

162

fiWrapper Maintenance

Source
airport
altavista
Amazon
arrowlist

Type
tuple/list
list
tuple
list

Bigbook
Barnes&N oble
borders
cuisinenet

tuple
tuple
list
list

geocoder
hotel
mapquest
northernlight
parking
Quote
Smartpages
showtimes
theatre
W ashington P ost
whitepages
yahoo people
ahoo Quote
yahoo weather
cia f actbook

tuple
list
tuple
list
list
tuple
tuple
list
list
tuple
list
list
tuple
tuple
tuple

Data Fields
airport code, name
url, title
book author, title, price, availability, isbn
part number, manufacturer, price, status,
description, url
business name, address, city, state, phone
book author, title, price, availability, isbn
book author, title, price, availability
restaurant name, cuisine, address, city, state,
phone, link
latitude, longitude, street, city, state
name, price, distance, url
hours, minutes, distance, url
url, title
lotname, dailyrate
stock ticker, price, pricechange, volume
name, address, city, state, phone
movie, showtimes
theater name, url, address
taxi price
business name, address, city, state, phone
name, address, city, state, phone
stock ticker, price, pricechange, volume
temperature, forecast
country area, borders, population, etc.

Table 5: List sources used experiments data elds extracted them. Source
type refers much data source returns response query single
tuple list tuples. airport source, type changed single tuple
list time.

163

fiLerman, Minton & Knoblock

result following precision, recall accuracy values:
P

=

R =
=

true positives
= 0.73 ,
true positives + f alse positives
true positives
= 0.95 ,
true positives + f alse negatives
true positives + true negatives
= 0.97 .
positives + negatives

results improvement reported (Lerman & Minton, 2000),
produced P = 0.47, R = 0.95, = 0.91. poor precision value reported
work due 40 false positives obtained data set. attribute improvements eliminating specicity bias patterns learned DataProG
changing feature set include starting patterns additional numeric
features. Note improvement result simply adding numeric features.
check this, ran verication experiments subset data (the last 278 comparisons) using global numeric features obtained P = 0.92 R = 0.55, whereas
using patterns numeric features results values P = 0.71 R = 1.00
data set.
3.1.2 Discussion Results
Though succeeded signicantly reducing number false positives,
managed eliminate altogether. number reasons presence,
point limitations approach.
split types errors roughly three entirely independent classes:
improper tokenization, incomplete data coverage, data format changes. URL eld
(Table 6) accounted signicant fraction false positives, large part due
design tokenizer, splits text strings punctuation marks. URL
contains embedded punctuation (as part alphanumeric key associated user
session id), split varying number tokens, hard capture
regularity eld. solution rewrite tokenizer recognize URLs
well dened specications exist. address problem ongoing work.
algorithm also failed sometimes (e.g., arrowlist, showtimes) learned long
specic descriptions. worth pointing out, however, performed correctly
two dozen comparisons sources. types errors caused incomplete
data coverage: larger, varied training data set would produce general patterns,
would perform better verication task. striking example data coverage
problem occurred stock quotes source: day training data collected,
many movements stock price up, opposite true
day test data collected. result, price change elds two days
dissimilar. Finally, DataProG learns format data, false positives
inevitably result changes data format indicate problem
algorithm. case factbook source, units area changed
km2 sq km.
164

fiWrapper Maintenance

hotel, mapquest (5 cases): URL eld contains alphanumeric keys, embedded punctuation symbols. tokenizer splits eld many tokens. key
format changes from:
http://. . .&Stamp=Q4aaiEGSp68*itn/hot%3da11204,itn/agencies/newitn. . .
http://. . .&Stamp=8bEgGEQrCo*itn/hot%3da11204,itn/agencies/newitn. . .
one occasion, server name inside URL changed:
http://enterprise.mapquest.com/mqmapgend?MQMapGenRequest=. . .
http://sitemap.mapquest.com/mqmapgend?MQMapGenRequest=. . .
showtimes, arrowlist (5 cases ): Instance showtimes eld part number
description elds (arrowlist) long. Many long, overly specic patterns
learned elds: e.g.,
<( Number : 2digit AllCaps ) , ( Small : 2digit ) , ( Small : 2digit ) , ( 4 : 2digit
) , 6 : 2digit , 7 : 2digit , 9 : 2digit , 10 : 2digit >

altavista (1 case): Database search engine appears updated. dierent
set results returned query.
quote (1 case): Data changed many positive negative price movements test examples
factbook (1 case): Data format changed:
f rom <Number km2 >
<Number sq km >
Table 6: List sources false positive results verication task

165

fiLerman, Minton & Knoblock

3.2 Wrapper Reinduction
wrapper stops extracting correctly, next challenge rebuild automatically (Cohen, 1999). extraction rules wrappers (Muslea et al., 2001), well
many others (cf. (Kushmerick et al., 1997; Hsu & Dung, 1998)), generated machine
learning algorithm, takes input several pages source labeled examples
data extract page. assumed user labeled examples correctly. label least pages wrapper fails correctly identifying
examples data them, use examples input induction algorithm,
STALKER,5 generate new extraction rules.6 Note need identify data every page depending regular data layout is, Stalker
learn extraction rules using small number correctly labeled pages. solution
bootstrap wrapper induction process (which learns landmark-based rules) learning
content-based rules. want re-learn landmark-based rules, types
sites use, rules tend much accurate ecient content-based
rules.
employ method takes set training examples, extracted source
wrapper known working correctly, set pages
source, uses mixture supervised unsupervised learning techniques identify
examples data eld new pages. assume format data
change. Patterns learned DataProG play signicant role reinduction task.
addition patterns, features, length training examples
structural information pages used. fact, page structure used
critical step algorithm, discuss approach learning detail next
paragraph.
3.2.1 Page Template Algorithm
Many Web sources use templates, page skeletons, automatically generate pages
results database query. evident example Fig. 6.
template consists heading RESULTS, followed number results match
query, phrase Click links associated businesses information,
heading LISTINGS, followed anchors map, driving directions, add
Directory bolded phrase Appears Category. Obviously, data
part template rather, appears slots template elements.
Given two example pages source, induce template
used generate (Table 7). template nding algorithm looks sequences
tokens HTML tags text appear exactly page.
algorithm works following way: pick smallest page set template
seed. Starting rst token page, grow sequence appending tokens
5. matter, fact, matter wrapper induction system used. easily replace
Stalker HLRT (Kushmerick et al., 1997) generate extraction rules.
6. paper discuss wrapper reinduction information sources return single tuple
results per page, detail page. order create data extraction rules sources return lists
tuples, Stalker wrapper induction algorithm requires user specify rst last elements
list, well least two consecutive elements. Therefore, need able identify
data elements high degree certainty.

166

fiWrapper Maintenance

(a)

(b)
Figure 6: Fragments two Web pages source displaying restaurant information.

167

fiLerman, Minton & Knoblock

it, subject condition sequence appears every page. managed
build sequence thats least three tokens long7 , sequence appears exactly
page, becomes part page template. Templates play important role
helping identify correct data examples pages.
input:
P = set N Web pages
output:
= page template
begin
p = shortest(P )
= null
= null
= rsttoken(p) lasttoken(p)
= concat(s, t)
( appears every page P )
=
continue
else

n= N
page=1 count(s, page)
( n = N length(s) 3 )
add-to-template(T, s)
end
= null
end
end
end
Table 7: Pseudocode template nding algorithm

3.2.2 Automatic Labeling Algorithm
Figure 7 schematic outline reinduction algorithm, consists automatic
data labeling wrapper induction. latter aspect described detail
work (Muslea et al., 2001), focus discussion automatic data
labeling algorithm.
First, DataProG learns starting ending patterns describe set training examples. training examples collected wrappers normal operation, correctly extracting data Web source. patterns used
identify possible examples data eld new pages. addition patterns,
also calculate mean (and variance) number-of-tokens training examples. new page scanned identify text segments begin one
starting patterns end one ending patterns. Text segments con7. best value minimum length page template element determined empirically
three.

168

fiWrapper Maintenance

extract

extracted
data

Wrapper

learn
labeled
Web pages

Wrapper
Induction
System

patterns
apply

Web
pages

extracts
score

group

Figure 7: Schematic outline reinduction algorithm
tain signicantly fewer tokens expected based old number-of-tokens
distribution, eliminated set candidate extracts. learned patterns
often general match many, possibly hundreds, text segments page.
Among spurious text segments correct example data eld. rest
discussion concerned identifying correct examples data pages.
exploit simple priori assumptions structure Web pages help
us separate interesting extracts noise. expect examples data eld
appear roughly position context page. example,
Fig. 6 shows fragments two Web pages source displaying restaurant information. pages relevant information restaurant appears
heading LISTINGS phrase Appears Category:. Thus,
expect eld, e.g., address, appear place, slot, within page
template. Moreover, information trying extract usually part
page template; therefore, candidate extracts part page template
eliminated consideration. Restaurant address always follows restaurant name (in
bold) precedes city zip code, i.e., appears context every page.
given eld either visible user every page, invisible (part HTML
tag) every page. order use information separate extracts, describe
candidate extract feature vector, includes positional information, dened
(page template) slot number context. context captured adjacent tokens:
one token immediately preceding candidate extract one token immediately following it. also use binary feature value one token visible
user, zero part HTML tag. candidate extracts assigned
feature vectors, split groups, within group, candidate extracts
described feature vector.
next step score groups based similarity training examples.
expect highest scoring group contain correct examples data eld. One scoring
method involves assigning rank groups based many extracts
common training examples. technique generally works well,
least data usually remains Web page layout changes.
169

fiLerman, Minton & Knoblock

course, assumption apply data changes frequently, weather
information, ight arrival times, stock quotes, etc. However, found even
sources, enough overlap data approach works. scoring
algorithm assigns zero groups, i.e., exist extracts common training
examples, second scoring algorithm invoked. scoring method follows wrapper
verication procedure nds group similar training examples
based patterns learned training examples.
nal step wrapper reinduction process provide extracts top
ranking group Stalker wrapper induction algorithm (Muslea et al., 2001) along
new pages. Stalker learns data extraction rules changed pages. Note
examples provided Stalker required correct examples eld.
set automatically labeled examples includes false positives, Stalker learn
correct extraction rules eld. False negatives problem, however.
reinduction algorithm could nd correct example data page, page
simply used wrapper induction stage.
3.2.3 Results
evaluate reinduction algorithm used ten sources (listed Table 5)
returned single tuple results per page, detail page.8 method data collection
described Sec. 3.1.1. period October 1999 March 2000
eight format changes sources. Since set much small evaluation
purposes, created articial test set considering ten data sets collected
source period. evaluated algorithm using extract data
Web pages correct output known. Specically, took ten tuples set
collected one date, used information extract data ten pages (randomly
chosen) collected later date, regardless whether source actually changed
not. reserved remaining pages collected later date testing learned
Stalker rules.
output reinduction algorithm list tuples extracted ten pages,
well extraction rules generated Stalker pages. Though cases
able extract every eld every pages, still learn good extraction rules
Stalker long examples eld correctly labeled. evaluated
reinduction algorithm two stages: rst, checked many data elds source
identied successfully; second, checked quality learned Stalker rules
using extract data test pages.
Extracting content-based rules judged data eld successfully extracted automatic labeling algorithm able identify correctly least two
ten pages. minimum number examples Stalker needs create extraction rules. practice, low success rate occurred one eld two
8. use geocoder cia f actbook wrappers experiments. geocoder wrapper
accessed source another application; therefore, pages available us analysis.
reason excluding f actbook plain text source, methods apply Web
pages. Note also verication experiments, two wrappers mapquest source,
extracting dierent data. experiments described below, used one contained
data time period.

170

fiWrapper Maintenance

sources: Quote ahoo Quote. sources, eld successfully
extracted, correctly identied least three, cases almost all,
pages set. false positive occurred reinduction algorithm incorrectly identied text page correct example data eld. many cases, false positives
consisted partial elds, e.g., Cloudy rather Mostly Cloudy (yahoo weather).
false negative occurred algorithm identify examples data eld.
ran reinduction experiment attempting extract elds listed Table 8.
second column table lists fractions data sets eld successfully
extracted. able correctly identify elds 277 times across data sets making
61 mistakes, 31 attributed false positives 30 false negatives.
several reasons reinduction algorithm failed operate perfectly. many
cases reason small training set.9 achieve better learning yellowpages-type sources Bigbook Smartpages using training examples (see Fig. 8).
two cases, errors attributable changes format data, resulted
failure patterns capture structure data correctly: e.g., airport source
changed airport names capitalized words allcaps, Quote source
patterns able identify negative price changes learned
data set stocks positive price change. two sources
reinduction algorithm could distinguish correct examples eld
examples data type: Quote source, cases extracted
opening price high price stock price eld, yahoo weather source,
extracted high low temperature, rather current temperature. problem
also evident Smartpages source, city name appeared several places
page. cases, user intervention meta-analysis elds may necessary
improve results data extraction.
Extracting landmark-based rules nal validation experiment consisted
using automatically generated wrappers extract data test pages. last three
columns Table 8 list precision, recall accuracy extracting data test pages.
performance good elds, notable exception STATE eld
Bigbook source. eld, pattern <Allcaps> overly general, wrong
group received highest score scoring step reinduction algorithm.
average precision recall values P = 0.90 R = 0.80.
Within data set studied, sources, listed Table 9, experienced total seven
changes. addition sources, airport source changed format data
returned, since simultaneously changed presentation data detail page
list, could use data learn Stalker rules. Table 9 shows performance
automatically reinduced wrappers changed sources. elds precision P ,
important performance measures, close maximum value, indicating
false positives. However, small values recall indicate
examples elds extracted. result traced limitation
approach: eld appears dierent context, one rule necessary
9. Limitations data collection procedure prevented us accumulating large data sets
sources; therefore, order keep methodology uniform across sources, decided use
smaller training sets.

171

fiLerman, Minton & Knoblock

source/field
airport code
airport name
Amazon author
Amazon title
Amazon price
Amazon ISBN
Amazon availability
Barnes&N oble author
Barnes&N oble title
Barnes&N oble price
Barnes&N oble ISBN
Barnes&N oble availability
Bigbook name
Bigbook street
Bigbook city
Bigbook state
Bigbook phone
mapquest time
mapquest distance
Quote pricechange
Quote ticker
Quote volume
Quote shareprice
Smartpages name
Smartpages street
Smartpages city
Smartpages state
Smartpages phone
ahoo Quote pricechange
ahoo Quote ticker
ahoo Quote volume
ahoo Quote shareprice
W ashington P ost price
W eather temp
W eather outlook
average

ex %
100
90
100
70
100
100
60
100
80
90
100
90
70
90
70
100
90
100
100
50
63
100
38
80
80
0
100
100
100
100
100
80
100
40
90
83

p
1.0
1.0
97.3
98.8
1.0
1.0
1.0
0.93
0.96
1.0
1.0
1.0
1.0
1.0
0.91
0.04
1.0
1.0
1.0
0.38
0.93
1.0
0.46
1.0
1.0
0.68
1.0
0.99
1.0
1.0
1.0
1.0
1.0
0.36
0.83
0.90

r
1.0
1.0
0.92
0.81
0.99
0.91
0.86
0.96
0.62
0.68
0.95
0.92
0.76
0.87
0.98
0.50
0.30
0.98
0.98
0.36
0.87
0.88
0.60
0.82
0.52
0.58
0.70
1.0
0.41
0.98
0.99
0.59
1.0
0.82
1.0
0.80

Table 8: Reinduction results ten Web sources. rst column lists fraction
elds source correctly extracted pattern-based algorithm.
judged eld extracted algorithm correctly identied least
two examples it. last two columns list precision recall data
extraction task using reinduced wrappers.

172

fiWrapper Maintenance

100

extraction accuracy (%)

80

60

40
PHONE
STATE
CITY
NAME
STREET

20

0
0

5

10

15

20

25

number training examples

Figure 8: Performance reinduction algorithm elds Smartpages source
size training set increased

source/field
Amazon author
Amazon title
Amazon price
Amazon ISBN
Amazon availability
Barnes&N oble author
Barnes&N oble title
Barnes&N oble price
Barnes&N oble ISBN
Barnes&N oble availability
Quote pricechange
Quote ticker

P
1.0
1.0
0.9
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.0
1.0

R
1.0
0.7
0.9
0.9
0.9
0.5
0.8
1.0
1.0
1.0
0.0
1.0


1.0
0.7
0.9
0.9
0.9
0.5
0.8
1.0
1.0
1.0
0.0
1.0

source/field
Smartpages name
Smartpages street
Smartpages city
Smartpages state
Smartpages phone
ahoo Quote pricechange
ahoo Quote ticker
ahoo Quote volume
ahoo Quote shareprice
Quote volume
Quote shareprice

P
1.0
N/A
0.0
1.0
N/A
1.0
1.0
1.0
1.0

R
0.9
0.0
0.0
0.9
0.0
0.2
0.5
0.7
0.7


0.9
0.0
0.0
0.9
0.0
0.2
0.5
0.7
0.7

1.0
0.0

1.0
N/A

1.0
0.0

Table 9: Precision, recall, accuracy learned STALKER rules changed
sources

extract source. cases, extract subset examples
share context, ignore rest examples.
mentioned earlier, believe achieve better performance yellow-pagestype sources Bigbook Smartpages using training examples. Figure 8 shows
eect increasing size training example set performance automatically
generated wrappers Smartpages source. number training examples goes
up, accuracy extracted elds goes up.
173

fiLerman, Minton & Knoblock

3.2.4 Lists
also applied reinduction algorithm extract data pages containing lists
tuples, and, many cases, successfully extracted least several examples
eld several pages. However, order learn correct extraction rules sources
returning lists data, Stalker requires rst, last least two consecutive
list elements correctly specied. methods presented cannot guarantee
required list elements extracted, unless list elements extracted.
currently working new approaches data extraction lists (Lerman, Knoblock, &
Minton, 2001) enable us use Stalker learn correct data extraction rules.

4. Previous Work
signicant amount research activity area pattern learning.
section discuss two approaches, grammar induction relational learning,
compare performance DataProG tasks Web wrapper application
domain. Section 4.2 review previous work topics related wrapper maintenance,
Section 4.3 discuss related work information extraction wrapper induction.
4.1 Pattern Learning
4.1.1 Grammar induction
Several researchers addressed problem learning structure, patterns, describing text data. particular, grammar induction algorithms used past
learn common structure set strings. Carrasco Oncina proposed ALERGIA (Carrasco & Oncina, 1994), stochastic grammar induction algorithm learns
regular language positive examples language. ALERGIA starts nite
state automaton (FSA) initialized prex tree represents strings
language. ALERGIA uses state-merging approach (Angluin, 1982; Stolcke & Omohundro, 1994) FSA generalized merging pairs statistically similar (at
signicance level) subtrees. Similarity based purely relative frequencies
substrings encoded subtrees. end result minimum FSA consistent
grammar.
Goan et al. (Goan et al., 1996) found applied data domains commonly
found Web, addresses, phone numbers, etc., ALERGIA tended merge
many states, resulting over-general grammar. proposed modications
ALERGIA, resulting algorithm WIL, aimed reducing number faulty merges.
modications motivated observation symbol string belong one
following syntactic categories: NUMBER, LOWER, UPPER DELIM.
viewed syntactic level, data strings contain additional structural information
eectively exploited reduce number faulty merges. WIL merges two subtrees
similar (in ALERGIA sense) also if, every level, contain nodes
syntactic type. WIL also adds wildcard generalization step
transitions corresponding symbols category approximately evenly
distributed range syntactic type (e.g., 09 numerals) replaced
single transition corresponding type (e.g., NUMBER). Goan et al. demonstrated
174

fiWrapper Maintenance

grammars learned WIL eective recognizing new strings several
relevant Web domains.
compared performance WIL DataProG wrapper verication task.
used WIL learn grammar token level using data examples extracted
wrappers, character level done Goan et al.Another dierence
Goan et al. that, whereas needed order 100 strings arrive high
accuracy rate, order 2030 examples work with. Note
longer apply wildcard generalization step FSA would need many
examples decide whether token approximately evenly distributed
syntactic type. Instead, compare DataProG two versions WIL: one without
wildcard generalization (WIL1), one every token initial FSA replaced
syntactic type (WIL2). addition syntactic types used Goan et al.,
also introduce another type ALNUM consistent patterns learned
DataProG. Neither version WIL allows multi-level generalization.
algorithms tested data extracted wrappers 26 Web sources ten
dierent occasions period several months (see Sec. 3.1). Results 2030 queries
stored every time. wrapper, one data set used training examples,
data set extracted next date used test examples. used WIL1
WIL2 learn grammar eld training examples used
grammar recognize test examples. grammar recognized 80%
test examples data eld, concluded recognized entire data eld; otherwise,
concluded grammar recognize eld, possibly data
changed. procedure used wrapper verication experiments,
described greater detail Section 3.1.1. period time covered
data, 21 occasions Web site changed, thereby causing data
extracted wrapper change well. precision recall values WIL1
(grammar induction specic tokens) P = 0.20, R = 0.81; WIL2 (grammar
induction wildcards representing tokens syntactic categories) values P = 0.55
R = 0.76. WIL1 learned overly specic grammar, resulted high rate
false positives verication task, WIL2 learned overly general grammar,
resulting slightly false negatives. recall precision value DataProG
data P = 0.73 R = 1.0.
Recently Thollard et al. (Thollard, Dupont, & de la Higuera, 2000) introduced MDI,
extension ALERGIA. MDI shown generate better grammars least one
domain reducing number faulty merges states . MDI replaces ALERGIAs
state merging criterion global measure attempts minimize KullbackLeibler divergence learned automaton training sample
time keeping size automaton small possible. clear whether MDI
(or combination MDI/WIL) lead better grammars common Web data types.
suspect not, regular grammars capture multitude data types
found Web. example, business names, restaurant names shown Table 2
may well dened structure, yet many start two capitalized words
end word Restaurant constitute patterns learned DataProG.
175

fiLerman, Minton & Knoblock

4.1.2 Relational learning
sequence n tokens, pattern also viewed non-recursive n-ary predicate.
Therefore, use relation-learning algorithm like FOIL (Quinlan, 1990) learn them.
Given set positive negative examples class, FOIL learns rst order predicate
logic clauses dening class. Specically, nds discriminating description covers
many positive none negative examples.
used Foil.6 no-negative-literals option learn patterns describing several
dierent data elds. cases closed world assumption used construct negative
examples known objects: thus, Bigbook source, names addresses
negative examples phone number class. used following encoding
translate training examples allow foil.6 learn logical relations. data eld,
FOIL learned clauses form
data f ield(A) := P (A) f ollowed by(A, B) P (B) ,

(3)

denition eld, B tokens, terms right hand side
predicates. predicate f ollowed by(A, B) expresses sequential relation
tokens. predicate P (A) allows us specify token specic token (e.g.,
John(A)) general type (e.g., Upper(A), Alpha(A)), thus, allowing FOIL
multi-level generalization capability DataProG.
ran Foil.6 examples associated Bigbook (see Tables 23).
relational denitions learned Foil.6 examples shown Table 10.
many cases, similarities denitions learned FOIL
patterns learned DataProG, though clauses learned FOIL tended overly
general. Another problem given examples class little structure,
names book titles, FOIL tended create clauses covered single examples,
failed nd clauses. general, description learned FOIL depended critically
supplied negative examples eld. example, trying
learn denition book titles presence prices, FOIL would learn something
starts capitalized word title. author names supplied negative
examples well, learned denition would dierent. Therefore, using FOIL
situations complete set negative examples known available,
problematic.
4.2 Wrapper Maintenance
Kushmerick (Kushmerick, 1999) addressed problem wrapper verication proposing
algorithm Rapture verify wrapper correctly extracts data Web page.
work, data eld described collection global features,
word count, average word length, density types, i.e., proportion characters
training examples HTML, alphabetic, numeric type. Rapture calculated
mean variance features distribution training examples. Given
set queries wrapper output known, Rapture generates new result
query calculates probability generating observed value every feature.
Individual feature probabilities combined produce overall probability
wrapper extracted data correctly. probability exceeds certain threshold,
176

fiWrapper Maintenance

*** Warning:
NAME(A)
NAME(A)
NAME(A)

following definition cover 23 tuples relation
:= AllCaps(A), followed by(A,B)
:= Upper(A), followed by(A,B), Number(B)
:= followed by(A,B), Venice(B)

STREET(A) := Large(A), followed by(A,B)
STREET(A) := Medium(A), followed by(A,B), AlphaNum(B)

** Warning:
CITY(A)
CITY(A)
CITY(A)
CITY(A)
CITY(A)

following definition cover 9 tuples relation
:= Los(A)
:= Marina(A)
:= New(A)
:= Brooklyn(A)
:= West(A), followed by(A,B), Alpha(B)

STATE(A) := CA(A)
STATE(A) := NY(A)
PHONE(A) := ((A)

Table 10: Denitions learned foil.6 Bigbook source
Rapture decides wrapper correct; otherwise, failed. Kushmerick
found HTML density alone correctly identify almost changes
sources monitored. fact, adding features probability calculation
signicantly reduced algorithms performance. compared Raptures performance
verication task approach, found Rapture missed 17 wrapper changes
(false negatives) relied solely HTML density feature. 10
relatively little prior work wrapper reinduction problem. Cohen (Cohen, 1999) adapted WHIRL, soft logic incorporates notion statistical
text similarity, recognize page structure narrow class pages: containing
simple lists simple hotlists (dened anchor-URL pairs). Previously extracted data,
combined page structure recognition heuristics, used reconstruct wrapper
page structure changed. Cohen conducted wrapper maintenance experiments using original data corrupted data examples WHIRL. However, procedure
corrupting data neither realistic representative data Web changes.
Although cannot present guarantee good performance algorithm wrapper reinduction sources containing lists, handle realistic data changes Web
sources returning detail pages.
10. Although use dierent statistical test cannot compare performance algorithm
Rapture directly, doubt would outperform algorithm data set used global
numeric features, because, noted Section 3.1.1, using patterns well global numeric features
verication task outperforms using numeric features only.

177

fiLerman, Minton & Knoblock

4.3 Information Extraction
system, used reinduction task, related spirit many information
extraction (IE) systems developed group others uses learned
representation data extract information specic texts. Like wrapper induction
systems (see (Muslea et al., 2001; Kushmerick et al., 1997; Freitag & Kushmerick, 2000)),
domain independent works best semi-structured data, e.g., Web pages.
handle free text well systems, AutoSlog (Rilo, 1993)
Whisk (Soderland, 1999), free text fewer non-trivial regularities algorithm
exploit. Unlike wrapper induction, extract data based features
appear near text, rather based content data itself. However, unlike Whisk,
also learns content rules, reinduction system represents eld independently
elds, advantage, instance, web source changes
order data elds appear. Another dierence system designed run
automatically, without requiring user interaction label informative examples.
main part purely automatic, reinduction system fails achieve accuracy
IE systems rely labeled examples train system; however,
see major limitation, since designed complement existing extraction
tools, rather supersede them. words, consider reinduction task
successful accurately extract sucient number examples use wrapper
induction system. system use resulting wrapper accurately extract
rest data source.
many similarities approach used RoadRunner system, developed concurrently system reported recently (Crescenzi,
Mecca, & Merialdo, 2001b, 2001a). goal system automatically extract
data Web sources exploiting similarities page structure across multiple pages.
RoadRunner works inducing grammar Web pages comparing several pages
containing long lists data. grammar expressed HTML tag level,
similar extraction rules generated Stalker. RoadRunner system
shown successfully extract data several Web sites. two signicant dierences
work (i) way detecting changes know
wrapper rebuilt (ii) reinduction algorithm works detail pages
only, RoadRunner works lists. believe data-centric approach
exible allow us extract data diverse information sources
RoadRunner approach looks page structure.

5. Conclusion
paper described DataProG algorithm, learns structural information data eld set examples eld. use patterns
two Web wrapper maintenance applications: (i) verification detecting wrapper
stops extracting data correctly Web source, (ii) reinduction identifying new
examples data eld order rebuild wrapper stops working. verication algorithm performed accuracy 97%, much better results reported
earlier work (Lerman & Minton, 2000). reinduction task, patterns
used identify large number data elds Web pages, turn used
178

fiWrapper Maintenance

automatically learn Stalker rules Web sources. new extraction rules
validated using successfully extract data sets test pages.
remains work done wrapper maintenance. current algorithms
sucient automatically re-generate Stalker rules sources return lists tuples.
However, preliminary results indicate (Lerman et al., 2001) feasible combine
information structure data priori expectations structure
Web pages containing lists automatically extract data lists assign rows
columns. believe techniques eventually eliminate need user
mark Web pages enable us automatically generate wrappers Web sources. Another exciting direction future work using DataProG algorithm automatically
create wrappers new sources domain given existing wrappers sources
domain. example, learn author, title price elds
AmazonBooks source, use extract elds Barnes&N obleBooks
source. Preliminary results show indeed feasible. Automatic wrapper generation
important cornerstone information-based applications, including Web agents.

6. Acknowledgments
would like thank Priyanka Pushkarna carrying wrapper verication experiments.
research reported supported part Defense Advanced Research
Projects Agency (DARPA) Air Force Research Laboratory contract/agreement
numbers F30602-01-C-0197, F30602-00-1-0504, F30602-98-2-0109, part Air Force
Oce Scientic Research grant number F49620-01-1-0053, part Integrated
Media Systems Center, National Science Foundation (NSF) Engineering Research Center,
cooperative agreement number EEC-9529152 part NSF award number
DMI-0090978. U.S. Government authorized reproduce distribute reports
Governmental purposes notwithstanding copy right annotation thereon. views
conclusions contained herein authors interpreted
necessarily representing ocial policies endorsements, either expressed implied,
organizations person connected them.

References
Abramowitz, M., & Stegun, I. A. (1964). Handbook mathematical functions formulas, graphs mathematical tables. Applied Math. Series 55. National Bureau
Standards, Washington, D.C.
Ambite, J.-L., Barish, G., Knoblock, C. A., Muslea, M., Oh, J., & Minton, S. (2002).
Getting there: Interactive planning agent execution optimizing
travel. Fourteenth Innovative Applications Articial Intelligence Conference
(IAAI-2002), Edmonton, Alberta, Canada, 2002.
Angluin, D. (1982). Inference reversible languages. Journal ACM, 29 (3), 741765.
179

fiLerman, Minton & Knoblock

Brazma, A., Jonassen, I., Eidhammer, I., & Gilbert, D. (1995). Approaches automatic discovery patterns biosequences. Tech. rep., Department Informatics,
University Bergen.
Carrasco, R. C., & Oncina, J. (1994). Learning stochastic regular grammars means
state merging method. Lecture Notes Computer Science, 862, 139.
Chalupsky, H., et al. (2001). Electric elves: Applying agent technology support human
organizations. Proceedings Thirteenth Annual Conference Innovative
Applications Articial Intelligence (IAAI-2001), Seattle, WA.
Cohen, W. W. (1999). Recognizing structure web pages using similarity queries. Proc.
16th National Conference Articial Intelligence (AAAI-1999), pp. 5966.
Crescenzi, V., Mecca, G., & Merialdo, P. (2001a). Automatic web information extraction
roadrunner system. Proceedings International Workshop Data
Semantics Web Information Systems (DASWIS-2001).
Crescenzi, V., Mecca, G., & Merialdo, P. (2001b). RoadRunner: Towards automatic data
extraction large web sites. Proceedings 27th Conference Large
Databases (VLDB) Rome, Italy.
Dietterich, T., & Michalski, R. (1981). Inductive learning structural descriptions.. Articial Intelligence, 16, 257294.
Doorenbos, R. B., Etzioni, O., & Weld, D. S. (1997). scalable comparison-shopping
agent world-wide webs. Proceeding First International Confence
Autonomous Agents, Marina del Rey.
Freitag, D., & Kushmerick, N. (2000). Boosted wrapper induction. Proceedings 7th
Conference Articial Intelligence (AAAI-2000), pp. 577583. AAAI Press, Menlo
Park, CA.
Goan, T., Benson, N., & Etzioni, O. (1996). grammar inference algorithm world
wide web.. Proceedings AAAI Spring Symposium Machine Learning Information Access, Stanford University, CA.
Hsu, C.-N., & Dung, M.-T. (1998). Generating nite-state transducers semi-structured
data extraction web. Journal Information Systems, 23, 521538.
Knoblock, C. A., Lerman, K., Minton, S., & Muslea, I. (2001a). Accurately reliably
extracting data web: machine learning approach. IEEE Data Engineering
Bulletin, 23 (4), 3341.
Knoblock, C. A., Minton, S., Ambite, J. L., Muslea, M., Oh, J., , & Frank, M. (2001b).
Mixed-initiative, multi-source information assistants. Tenth International
World Wide Web Conference (WWW10), Hong Kong.
Kushmerick, N. (1999). Regression testing wrapper maintenance.. Proceedings
14th National Conference Articial Intelligence (AAAI-1999).
180

fiWrapper Maintenance

Kushmerick, N., Weld, D. S., & Doorenbos, R. B. (1997). Wrapper induction information extraction. Proceedings Intl. Joint Conference Articial Intelligence
(IJCAI), pp. 729737.
Lerman, K., Knoblock, C. A., & Minton, S. (2001). Automatic data extraction lists
tables web sources. Proceedings workshop Advances Text Extraction
Mining (IJCAI-2001) Menlo Park. AAAI Press.
Lerman, K., & Minton, S. (2000). Learning common structure data. Proceedings
15th National Conference Articial Intelligence (AAAI-2000) Menlo Park.
AAAI Press.
Muggleton, S. (1991). Inductive logic programming. New Generation Computing, 8, 295
318.
Muslea, I., Minton, S., & Knoblock, C. (1998). Wrapper induction semistructured webbased information sources.. Proceedings Conference Automated Learning
Discovery (CONALD).
Muslea, I., Minton, S., & Knoblock, C. A. (2001). Hierarchical wrapper induction
semistructured information sources. Autonomous Agents Multi-Agent Systems, 4,
93114.
Papoulis, A. (1990). Probability Statistics. Prentice Hall, Englewood Clis, NJ.
Quinlan, J. R. (1990). Learning logical denitions relations.. Machine Learning, 5 (3),
239266.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann, San
Mateo, CA.
Rilo, E. (1993). Automatically constructing dictionary information extraction tasks.
Proceedings 11th National Conference Articial Intelligence, pp. 811816
Menlo Park, CA, USA. AAAI Press.
Soderland, S. (1999). Learning information extraction rules semi-structured free
text. Machine Learning, 34 (1-3), 233272.
Stolcke, A., & Omohundro, S. (1994). Inference nite-state probabilistic grammars.
Proceedings 2nd Int. Colloquium Grammar Induction, (ICGI-94), pp. 106
118.
Thollard, F., Dupont, P., & de la Higuera, C. (2000). Probabilistic DFA inference using
Kullback-Leibler divergence minimality. Proceedings 17th International
Conf. Machine Learning, pp. 975982. Morgan Kaufmann, San Francisco, CA.

181

fi
ff
fi
! #"$ %
'&)( *,+.-//021304!(657720

89:;< =?>2@
/-!AB: %&=C>2@
/0

DFEHGJIKGJLMNOM2GQPSRUTWV$PSXZY,I[Y,PSXZY\PS]<Y)^
_

G)Ea`cbZT2R,dfegRhEaM2RUiZT2YjV$PSXZY\IKY\PSXZY\PS]<YkRUPSX
_

npqso r3w
tu vxqWy?z3{#|

G)EHlJYmN3NHMPSl

}~33HJ.Hff

\3#s#'J?)f
sffpa
O$
$
z uwuy?qrz$u3rq
) 2s'w292
h.
6J.

}~$OJw$$3\~.

ws
ff
w,32!s
! <\6


qrrqz$ra
$H$\?ws
fQ
$ ,6.

~333Q}$$3 ~3$3ff

f)J ws
f
)w2fQa
O$

?H

6sff f[m<s.
)
ff fiff 9 ff
[f
99Kf9ffS [ ?2 Jff 6Khs$#fC
fif.#
wf9s9fs2 f
C ff.<fJ?. "!K< f9ff9
f#
f
fi %ff$ w &H 6f ff <ff?h ff.< 'f9s9fs2(m #)

!S
!%$*
p !+ <ff.
ff Cf,ff [ Q
? 9

-99pf
./K
! h. 2f. # Cff fiff 3 ff01 #.

ffQ

2ff
$ 9# 3ffi ff [ps hf4 hSf )5 9Uf f9[
fff
fi 2s\ sfi 2 /
! ff\
Q 2!/.

f Jf
6#
# hff

7ff)
9wfff
fi 5 98 9ff fpps9fi :;9U 2
ff.'w< f2,

f <H3ff$ 9ff (ffi Cf=sfi 9Zff> !6f
. 9 ffff)
$ m?fi U Q
!
9&s
fi U
ff
7f96

B@ AC;D ffEF+\G ffHIE
JLKMN.OPOQKMMRTS#KUV&W'XKMYKZ[\MY]ff^K^]#[RTS0_0[RT]ffZ.MP`[a6K4MOQ]#W/K]#b/[a6KW'_0W/KPX`_#Z.c[a.KOQ]ffZ[YXRTd'N6[R]ffZe_#Z.c
[a6K]#Xfff_#Z.RTg_0[RT]ffZh]#b8[a6K?W"_0WiKPX j
.k lmk u$onzu{
p%Z^e_#ZV&MRT[N._0[R]ffZ.M8]#b'KPS#KPXV*c._ V2UoRTb1K#`0q:K_0XKOQ]ffZ6brX]ffZ[YKcq4RT[a&[a6K,W.X]#d'UTK^s]#b8tuPvuQwx2y1z'y1z{}|8~ffv
y1wuQuQ00z'vj++MYW/KOPR_#UUTV#`*_#M,_&W.XKURo^eRZ._0XVMY[YKPWh[Y]S0_0XRT]ffN'M:RoZ[YKUUoRTf#KZ[:[_#MY*MrK#jf6jT`.W'Uo_#Z.Z.RZ6f6`c6KQ
OPRMR]ffZ^e_0*RZ6f6`XK_#MY]ffZ.RZ.f `8R[RMZ'_0[N6X_#U=_#Z.cXK_#MY]ffZ._0d"UTK[Y]c.RMOP_0XcKPS#KPXV[a.RZ6fd"N6[q4a._0[&RM
XKUTKPS0_#Z[[Y]_#Oa.RTKPS#K4[a6K^KPOPRTKZ[UTV#j6]#X\RZ'MY[_#Z.OQK#`ffd/KPbr]#XK,MY[_0X[RZ6f3[Y]q4XRT[YK:[a.RM8W'_0W/KPX`#q:Ka._#c
[Y]OQ]ffZ'MRc6KPX[a6KXKUKPS;_#Z[UR[YKPX_0[N6XK?]ffZ[a6K[Y]#W"RO0`"_#Z.c]ffZ.UTVhRT[P"fff_0[a6KPXRZ6f]ffZ]ffN6Xc6KMY*M4_#UU[a6K
W'_0W/KPXM_0di]ffN.[4XKUTKPS0_#Z.OQK}[a._0[4q:K&a'_S#K2_0[a._#Z'cUTKcN.M[Y]MYKP[3_q(_V]ffN6Xb_S#]ffN6XR[YK&OQ]]#hd/]]#*MP`
d/KOP_#N.MYK?[a6KPV_0XK]#b8Z6]ea6KUWh[Y]e[a6K?[_#MY]#bqXRT[RZ.f&[a'RM(W'_0W/KPXja6K_0d'RoURT[V[Y]eb1]*OPN.M,]ffZq4a._0[
RM4XKUTKPS0_#Z[2r]#X3c'N._#UUTV[Y]c.RoMOP_0Xcqa._0[RMZ6]#[ ,OP_#Zd/K}OQ]ffZ.MRc6KPXKc_#M_OQKZ[YX_#UI`iO a._0X_#OQ[YKPXRM[RO
brK_0[N6XK4]#bBRZ[YKUURf#KZ.OQK#RT[=RoMd/KURTKPS#Kc[a._0[+] S#KPX,0]#bB[a.K4Z6KN6X]ffZ'_#U.OQ]ffZ.Z6KOQ[RT]ffZ'M=]#b/]ffN6X\d'X_#RZ.M


"

(

:

\





-//0 %% !=U
= C2
H
!fi;
:! %&% f &2%3% 2 =

fi

~33



s~$w

~ww$

_0XK3RZ.a.Rd'RT[Y]#XV2_#Z.cMYKPXS#K[Y]&fffRS#KN6WMYKZ.M]#XR_#U'RoZ6W'N6[M *N6d.X_#^_#Z.R_#ZB`ff
3XKRZ6KPX` fi9K_0X Um`## j
a.RoMK *W'U_#RoZ.Mq4aVRTXXKUKPS;_#Z.OQK#` N'Z.c6KPX3S;_0X RT]ffN.M3Z._#^KM_#MRZ.c6KPW/KZ.c6KZ'OQK#`iRTXXKc.N.Z.c'_#Z.OQV#`BR Z 'N*
KZ.OQK_0d'RoURT[V#`Z6] S#KU[V#`=MYKPW'_0X _0d'RURT[V#`RMZ.] q(_#c._V*M}OQ]ffZ'MRc6KPXKc_#M}_#ZRo^W/]#X[_#Z[}Z6]#[RT]ffZRZ^e_#ZV
KUc'M]#b+_0X[R OPR_#U9RZ[YKUoURTf#KZ.OQKMYKPK_MN.XS#KPVbr]#X3^e]#XK&c.KP[_#RUMP`iK#jf6jT`
XKRZ.KP
X fi*N6d.X _#^e_#Z.R_#ZB`
# 6N6d.X_#^e_#Z'R_#ZKP[4_#UmjT` # # j
p%Z [a6Kb1]ffUU] q4RZ.f6`+q:K_0XKOQ]ffZ.OQKPXZ6Kc q4RT[a wuQuQ00z u !0wwYu; !#z.y1z{#j p%Z [a.RMb1X_#^eKPq+]#Xi`
[a6K[_#MY RM[VW'ROP_#UoUTV [a._0[]#bc6KP[YKPX^eRoZ.RZ6fqa6KP[a6KPXMY]ff^K W'RTKOQK]#bZ.] q4UTKc.f#K #
_ "N6KPXV.%
$
OP_#Z d/Kc.KPXRTS#Kc brX]ff^ _Z6] q4UTKc6f#Kd'_#MY'
K &(
j KPS#KPX_#U4XK_#MY]ffZ.RZ.fMOa.K^KMOP_#Z diK[_0#KZ RZ[Y]
_#OPOQ]ffN.Z[:a.KPXK#`brX]ff^ [a6KOPU_#MMROP_#U.]ffZ.K&RZ6brKPXKZ.OQKRM\OPU_#MMROP_#U6KZ[_#RU^KZ[ =[Y]}^]#XKMY]#W'a.RoMY[ROP_0[YKc
]ffZ6KM?OQ]ff^e^]ffZ6MYKZ.MYKRZ.b1KPXKZ'OQK jJ a6KZc6K_#URoZ6fq4R[aMN'OaXK_#MY]ffZ.RoZ6f}[_#MMP`6XKUTKPS;_#Z'OQKRM:]#br[YKZ
K*W'UT]ffRT[YKc&MY]3_#M9[Y]?^e_0#K,RZ.b1KPXKZ'OQK+^]#XK:KPOPRTKZ[8b1X]ff^ _OQ]ff^W'N6[_0[R]ffZ._#UWi]ffRoZ[9]#b.SRKPqjp%Z&]#[a6KPX
XK_#MY]ffZ'RZ6f W.X]#d'UK^eMP`[a6KLW'N6XW/]ffMYK RM[Y] K *W'URoOPRT[UTV c6KPX RTS#KLMY]ff^KRZ[YKZ.MR]ffZ._#UUTVOa._0X _#OQ[YKPXRTgPKc
W'RTKOQKM&]#b*Z6] q4UTKc6f#KLrK#jf6jT`=[YKUU:^K_#UU\qa._0[}V#]ffN *Z6] q _0d/]ffN6[2,q:KPKP[V. j .]#XeMN.Oa W.X]#d'UTK^eM
r[a._0[_0XKZ.]#[:XKc.N.OPRTd'UK4[Y]ec6KOPRMRT]ffZW.X]#d'UTK^M `XKUTKPS;_#Z'OQK3_#UoMY]a._#M,_2X]ffUTK3[Y]W'U_ V#`*b1]#XRZ'MY[_#Z.OQK
dV_#UUT] q4RZ6fN.M[Y]Oa._0X _#OQ[YKPXRTgPKe[a6K2W'RKOQKM]#b:RZ6br]#X^e_0[RT]ffZq:K_0XKRZ[YKPXKMY[YKcLRZdVb1]#Xf#KP[Y[RoZ6f
[a6K]#[a.KPX]ffZ6KMPj
9]q4a._0[?K *[YKZ[RM?[a6Kf#]ff_#U\]#b:Ro^W.X] SRZ.fRZ.b1KPXKZ'OQKXK_#Oa._0d"UT*K ) p%Z ]#Xc6KPX[Y]_#c.c6XKMM3[a.RM
W/]ffRZ[P`"_e#KPVRMMN6K}RM[a6+
K ,!0.x -/6vI#v0y !0z"#1 ,!0.
x -"3u 2ffyr5v 4}]ffZ6K#jp%Z.c6KPKcB`i_#MMN.^eK[a._0[q+K}Z.] qs[a._0[
[a6K+XKMY]ffUN6[R]ffZ?]#b6MY]ff^K\XK_#MY]ffZ.RZ6f4W.X]#d'UTK^M OP_#Zd/K\MWiKcN6W]ffZ.OQK+XKUTKPS0_#Z[RZ6br]#X^e_0[RT]ffZ?a'_#Md/KPKZ
KUROPR[YKcBj+p%Z[a.KMRT[N._0[R]ffZq4a6KPXKRT[4RM4OQ]ff^W'N6[_0[RT]ffZ'_#UUTVha._0Xc6KPX4[Y]W/]ffRZ[]ffN6[4MN'OaRZ6br]#X^e_0[RT]ffZ
brX]ff^ [a.K}RZ6W"N6[[a._#Z[Y]XK_#MY]ffZc'RTXKOQ[UTVbrX]ff^ [a.K}RZ6W"N6[P`'OQ]ff^W'N.[_0[RT]ffZ._#U9diKZ.K [M4_0XK2a._0Xc[Y]
d/KK W/KOQ[YKcBjpb:MY]6`9_#UT[YKPX Z._0[RTS#KN.MKM?]#b+XKUTKPS;_#Z'OQKeb1]#XXK_#MY]ffZ.RZ.f_0XK[Y]d/KeRZS#KMY[RTfff_0[YKcBj.]#X
RZ.M[_#Z.OQK#`9MYK_0X Oa.RZ.fhb1]#X}XKUTKPS0_#Z.OQKeRZ6br]#X^e_0[RT]ffZLOP_#Zd/KeUR^eRT[YKc dV OQ]ffZ.MRc6KPX RZ6f]ffZ.UTVW'RTKOQKM]#b
*Z6] q4UKc6f#K,[a._0[\OP_#Zd/K,f#KZ6KPX _0[YKcRZ_3[YX_#OQ[_0d"UTKq(_V#jpbiMN'OaeRZ.b1]#X^_0[RT]ffZ2c6KPW/KZ.c2]ffZ.UTV}]ffZ[a6K
*Z6] q4UKc6f#K\d'_#MK#`0_#Z.]#[a6KPX9W/]ffMMRTd'UTK=_0W.W'X]ff_#Oa&RM [Y]r[YKZ[_0[RTS#KUTV.OQ]ff^eWiKZ'M_0[YK\[a6K:OQ]ff^W'N6[_0[R]ffZ._#U
XKMY]ffN.XOQKMMWiKZ[RoZ c6KPXRTS*RZ6fL[a.KXKUTKPS0_#Z.OQK RZ6br]#X^e_0[RT]ffZ [a6X]ffN6fffa ^e_#Z6
V "N6KPXRKMOQ]ff^W'N.[RZ6f
W'RTKOQKM]#bXKUTKPS;_#Z[RZ6br]#X^e_0[R]ffZhOP_#Z[a6KZhd/K?S*RTKPq:Kch_#M4_br]#X^ ]#b8OQ]ff^W'RUo_0[RT]ffZ" j
.k l87:9; u=<\q u>U*?#q z<qr
@R[Y[UTKRM3Z.] q4ZL_0d/]ffN6[3[a6KeOQ]ff^W"N6[_0[RT]ffZ._#U=OQ]ff^eW'UTK6RT[V]#b+XKUKPS;_#Z.OQK#ja'RMW'_0W/KPX3OQ]ffZ[YXRTd"N6[YKM
[Y] UU[a.RMfff_0W j&a6K2OQ]ff^W'UTK 6RT[V]#b+MYKPS#KPX _#UUT]#fffROId'_#MYKc XKUTKPS;_#Z'OQK&XKU_0[RT]ffZ.M3RM3Rc6KZ[R KcRZ _
W.X]#W/]ffMR[RT]ffZ._#U=MYKP[Y[RoZ6f6B
j A:VUT]#fffROId"_#MYKcq:K^eK_#Z [a'_0[}[a6KZ6]#[RT]ffZ.M}]#b,XKUTKPS0_#Z.OQKq+Kb1]*OPN.M}]ffZ
_0XK2Z6]#[4K *[YX_;UT]#fffRoOP_#U9d"N6[d'N.RoUT[RZ.MRoc6K?[a6K}U]#fffRDO C([a6KPV_0XK&c6K Z6KcN.MRZ6f[a6K}MY[_#Z'c._0XcU]#fffROP_#U
Z6]#[RT]ffZ'M\]#b(OPU_#MMROP_#Urbr]#X^&N.U_*`*^]c.KUm`UT]#fffRoOP_#Uic.Kc.N.OQ[RT]ffZB`KP[O0j\a.KMY[YXKMM,RM+Uo_#Rce]ffZZ6]#[RT]ffZ'M+]#b
XKUTKPS0_#Z.OQK}[a._0[OP_#ZW.X] S#K}a6KUW.brN'U/b1]#X3R^W.X] S*RZ6feRZ6brKPXKZ.OQK_#Z'cB`"RZW'_0X[ROPN'U_0X`6[a6K&^]ffMY[d'_#MRO
br]#X^ ]#b=R[P`iOPU_#MMROP_#U9KZ[_#RUo^KZ[P.j EKUTKPS0_#Z.OQK2RMOP_0W'[N6XKcdVhXKUo_0[RT]ffZ.M4RoZ[a6K2^KP[_#U_#Z6fffN'_0f#K&]#b
[a6K&UT]#fffRO0`.[a._0[RMP`.q:Kbr]#X^e_#UoRTgPK?XKUTKPS0_#Z.OQK}_#M_eXKUo_0[RT]ffZd/KP[q:KPKZ]#Gd F%KOQ[M]#b8[a6KW'X]#W/]ffMRT[RT]ffZ._#U
U_#Z6fffN'_0f#K2rbr]#X^&N.U_#M+]#X:MYKP[M:]#bUoRT[YKPX_#UIM H S0_0XR_0d"UTKM 9[aN.M\K *W.XKMMRZ6f}[a6K4b_#OQ[([a._0[:M]ff^K]# F%KOQ[(RM
XKUTKPS0_#Z[[Y]MY]ff^K]#[a6KPX]ffZ6K#j
,q:] Z6]#[RT]ffZ.MW'U_ V _ OQKZ[YX_#UX]ffUTK RZ [a.RoMeW'_0W/KPXj 4a6K X MY[]ffZ6K#%
` JmPuPxe0z'v0y 0 KLM!0wN
x /TD
;#w ymQ PQuy1zitRu -6uPz"tuPz u SRZ.c.KPWiKZ'c6KZ.OQK&b1]#XMa.]#X[ 4[YKUUM[a._0[_W.X]#W/]ffMRT[R]ffZ._#Ubr]#X^&N.UT
_ &sRM
RZ.c.KPWiKZ'c6KZ[,brX]ff^ _fffRTS#KZ MYKPV
[ U ]#b=S;_0X R_0d'UTKMRTb=_#Z.c]ffZ.UTVhRTb=RT[OP_#Zd/K}XKPqXRT[Y[YKZWK "N.RTS0_#UTKZ[UV
_#M&_br]#X^&N.U_RZq4a.RO aZ6]ffZ.K]#b[a6KS;_0X R_0d'UTKM}RX
Z U _0W.W/K_0XMja6KMKOQ]ffZ.c]ffZ.KRM[a6KZ.]#[RT]ffZ
]#Yb M!0wm{uvmvy1z{ {#yr0uQz uPv UZ![;#w ymQ PQuLyrz
M!0wN
x /T#
&j p[hRMhRZ[R^e_0[YKUTV UoRZ6#Kc [Y] [a6K
\^]*_

fif.w~3}33f$3ws

Z6]#[RT]ffZ]#b+br]#X^&N.U_;IS0_0XR_0d'UTKRZ'c6KPW/KZ.c6KZ.OQK&d/KOP_#N.MYK#`9_#Mq+KMa6] q`9[a6KXKMN'UT[3]#b:br]#Xf#KP[Y[RZ.f[a6K
MYKP[?]#b:S;_0X R_0d'UTKM U RZL_b1]#X ^}N.UoT
_ &sOP_#ZdiKc6K Z6Kc _#M?[a6KeMY[YX]ffZ.f#KMY[OQ]ffZ.MYWK "N6KZ.OQK]#b & d/KRZ6f
RZ.c.KPWiKZ'c6KZ[b1X]ff^ Uej A:]#[a Z6]#[RT]ffZ'M&a'_S#Kh_0W.W/K_0XKc RZ[a.KUR[YKPX_0[N6XKN.Z.c6KPX}S;_0XR]ffN.M}Z'_#^KM
_#Z.cq4RT[aMYKPS#KPX_#U/c.R iKPXKZ[?rd'N6[:WK "N.RS;_#UTKZ[ \c6K Z.RT[R]ffZ.MP`_#Z.c_0XK?a.Rfffa.UTVN.MYKPbN.U.br]#X,^e_#ZVe[_#MY*M
RZh_#N6[Y]ff^_0[YKcXK_#M]ffZ.RZ6f_#Z.c^_#ZVW.X]#d"UTK^eM(RZh_0X[R OPR_#UBRZ[YKUURTf#KZ.OQK C
0j}/*v !#xffvuthtutD/vy0!0z #z"t%I!0z6u M/'uPz uff
=z"t0yrz{ffj\6]#X^&N.U_;IS0_0XR_0d'UKRZ.c.KPWiKZ'c6KZ.OQKOP_#Zd/K
N'MYKPbrN'U8b1]#X&Oa6KORZ.f N.Z"M_0[RoM _0d'RUoRT[V]#Xb1]#X&OQ]ffZ.MYKW"N6KZ.OQK Z.c.RZ.f6j&p%Z.c6KPKc `9MY[YXN'OQ[N6XRZ6f
[a.K?Z6] q4UTKc6f#K?d"_#MYK?dV Z.c.RoZ6f&N'MYKPbrN'U"RZ'c6KPW/KZ.c6KZ.OPRTKM:^e_ Vd/K3q+]#X[ac6]ffRZ6f2d/KPbr]#XK3XN.Z*
Z'RZ6f_#ZVMYK_0XO a_#UTf#]#XR[a.^hj=a.RoM+W'XRZ.OPRTW"UTKRM(_0[q:]#XRZL fi^RTXY
fi OQpUTX _#RT[aB`0## j+p%Z
]#W'[R^e_#UOP_#MYKMP`9b1]#X?K6 _#^W'UK#`_hM_0[RM _0d'RURT[VhW.X]#d'UK^ qRUU9diKc6KOQ]ff^eWi]ffMKcRZ[Y]_hM^e_#UU
ZN.^}d/KPX]#b4M_0[RoM _0d'RUoRT[VW.X]#d'UK^eM?]ffZ K_#MRTKPX&Z.] q4UTKc.f#Kd'_#MYKMrq4RT[a UTKMMS;_0X R_0d'UTKM _#M
Ma6] q4Z dV 8 _0X _#Z.cX

KUoc6KPX[ #ff jfiM}[Y] R^W.X] SRoZ6fRZ6brKPXKZ.OQK#`[a.RM}OP_#Zd/KW"_0X[ROPN*
Uo_0XUTVa.KUTW.bN.U8RZ [a6KMR[N._0[RT]ffZ q4a6KPXK[a6KeMYKP[]#b " N6KPXRTKM?N.Z'c6KPXOQ]ffZ.MRc.KPX_0[RT]ffZRM?UoR^eRT[YKc
[Y] br]#X^&N.U_#M $ [a._0[_0XKLMYV*Z[_#OQ[ROP_#UoUTV]#XMYK^e_#Z[ROP_#UUTV.RZ.c6KPW/KZ.c6KZ[?brX]ff^ _MYKP[ U ]#b

S0_0XR_0d"UTKMPj
jW/'uQw 4h#z6 |+uPw yrz{MYKPK2RZW'_0X[ROPN'U_0Xfi^eRTXfiOQpUX_#RT[aB`0## `\t0ym{#z!0 y1&MYKPK2[a6K&q+]#X

V 3_0Xq4RO a6K#` # ff j EKZ'c6KPXRZ6f_b1]#X ^}N.Uo_ &RZ'c6KPW/KZ.c6KZ[brX]ff^ _MYKP[ U ]#b(S;_0XRo_0d'UTKM
[a.X]ffN6fffaS;_0XRo_0d'UTK4br]#Xf#KP[Y[RZ.f&fffRS#KM+X RMYK4[Y]_}b1]#X ^}N.Uo_[a._0[(RM "N6KPXVIWK "N.RTS0_#UTKZ[\[Y] & qjXj[Pj
U RZ [a6KMYKZ.MK[a._0[KPS#KPXV UT]#fffROP_#UOQ]ffZ.MWK "N6KZ'OQK $ ]#b & [a._0[RMeRZ.c.KPWiKZ'c6KZ[2brX]ff^ U
_#UoMY]hRM?_UT]#fffROP_#UOQ]ffZ.MYWK "N6KZ.OQK]#b & ]ffZ.OQKe^e_#c6KRZ'c6KPW/KZ.c6KZ[4brX]ff^ U` _#Z'c [a6KOQ]ffZS#KPXMK
a.]ffUc.Me_#Mq+KUoUmj p%Z[YKPXKMY[RZ6fffUV#`,[a6KMYKP[]#b?_#UU[a6Kb1]#X ^}N.Uo_#MeRZ.c6KPW/KZ.c.KZ[brX]ff^ _ MYKP[]#b
S0_0XR_0d"UTKMRM_ MY[_0d"UTK W.X]*c.N.OQ[RT]ffZ KUc *RTKPf#KUm` }p%Z6]ffN6K#` # ff `_#Z'c br]*OPN.MRZ6f ]ffZ
MN.Oah_2W.X]c.N'OQ[RT]ffZ KUcRM:S;_#UN'_0d'UTKb1]#XMYKPS#KPX _#U/XK_#MY]ffZ.RZ.f2MOa6K^KMj\6]#X4RZ'MY[_#Z.OQK#`6RZ[a6K
OQ]ffZ'MRMY[YKZ.OQVId'_#MYKc}brX_#^KPq:]#Xbr]#Xc.Ro_0fffZ6]ffMRM\5 E4KRT[YKPX` # `ff[a.1K "N6KPXRTKM9q+K:_0XK(RZ[YKPXKMY[YKc
RoZ}_0XK([a6K(OQ]ff Z 'RoOQ[M9]#b"[a6K(MYVM[YK^[Y]d/K(c.R_0fffZ6]ffMKcB`#RmjK#jT`#[a6K,OPU_#N.MYKM[a._0[8_0XK,RZ.c.KPWiKZ'c6KZ[
brX]ff^KPS#KPXV&S0_0XR_0d"UTKN.MYKc2[Y]XKPW.XKMYKZ[=[a6KMYV*MY[YK^h`K *OQKPW'[=[a6K4_0d'Z.]#X^e_#URT[VW.X]#Wi]ffMRT[RT]ffZ.M
N'MYKch[Y]eKZ.OQ]*c6K?[a6K}OQ]ff^W/]ffZ6KZ[4br_#RUoN6XKMPj
j ;z !0|,ut{+
u P;uQvIw / 5v /wyrz{#`\ v ! -"5y WO P;PutwYu; !0z'y1z{ffje6]#X^&N.U_;IS0_0XR_0d'UK2RoZ.c6KPW/KZ.c6KZ.OQK&RM

_#KPV Z6]#[RT]ffZ br]#Xc.KOQ]ff^W/]ffMRZ6f_LW'X]#W/]ffMRT[RT]ffZ._#U(*Z6] q4UTKc6f#Kd"_#MYK br]#XMa6]#X[ `,RmjK#jT`
_ Z'RT[YKMYKP[2]#bW'X]#W/]ffMRT[RT]ffZ._#U=b1]#X^&N.U_#M`=RZ[Y] M^e_#UoUTKPX}MN.d.d'_#MYKMPj *N.O _c6KOQ]ff^eWi]ffMRT[RT]ffZ
RoM_#UU8[a6K^e]#XKS;_#UoN._0d'UTK_#M[a.KeZN.^}d/KPX?]#b(S;_0XRo_0d'UTKM3[a6KeMN.d.d'_#MYKMc.KPWiKZ'c.M]ffZRMUT] qj
W.[R^e_#UUV#` _Z6] q4UTKc6f#K+d'_#MYK &"!$# $ (&%('''% $*),+(RMbrN'UUTV3c6KOQ]ff^W/]ffM_0d'UTK:RTb.RT[OP_#Z&d/K\q4XRT[Y[YKZ
_#N
&-! & (/. '('(' . & ) q4a.KPX%
K &10(_#Z.c &/2c.KPWiKZ'c]ffZc.RM FY]ffRZ[3MKP[M]#b:S;_0XRo_0d'UTKM3br]#X_#UU
fi^eRTX
35!
4 6.j *N'Oa c6KOQ]ff^W/]ffMRT[RT]ffZ'M?q+KPXKOQ]ffZ.MRc6KPXKc RZMYKPS#KPX _#U\W'_0W/KPXM5 8_0XRT*aB` # 7
fi8OQp%UTX_#RT[a 9
` 0##*ff _0,X "N.RM fi9]#IX "N6KP[P/` 0##3qRT[aLMY]ff^KPq4a'_0[c.:R /KPXKZ[^e]#[RTS;_0[R]ffZ.MPj
4a6K^]ffMY[RoZ[N.R[RTS#Kh^]#[RTS0_0[RT]ffZ br]#XMYK_0XO a.RZ6fMN.Oa c.KOQ]ff^W/]ffMRT[RT]ffZ.MRoM[a._0[RT[fffRS#KM_
d/KP[Y[YKPXN.Z.c.KPXMY[_#Z.c.RoZ6f]#b.[a6K:*Z6] q4UKc6f#K+d"_#MYK#`#dV}MY[YXN.OQ[N6X RZ6fR[q4RT[a}XKMYW/KOQ[[Y]erWi]ffMMRTd'UTK
c'RM FY]ffRZ[(d'N.[Z6]#[Z6KOQKMM_0X RUTV.:MYKP[M]#b[Y]#W'ROPM; _0,X "N.RYM fi9]#IX "N6KP[P,` 0## j
<6j P uQym0u LwYuP y1 0y !0z 0z"t yr
z ,!#z6 y1vuPz M4DO% v !0TuPw%#z'vwYu; !#z.y1z{#=
j KOQ]ff^W/]ffMRZ.f _ W'X]#W/]ffMRT[RT]ffZ._#U
*Z6] q4UTKc6f#Kd'_#MY'
K & RZ[Y] MN6d.d'_#MK5
# & ( %('('('>% & ) +W.X] S#KM_#UMY][Y] diKXKUTKPS0_#Z[b1]#Xc6K Z*
RoZ6f&RoZ.OQ]ffZ.MRM[YKZ.OQVI[Y]ffUKPX_#Z[(XKUo_0[RT]ffZ.M:_#M(q+KUU/_#M(d/KURTKPb/XKPS*RMR]ffZ]#W/KPX_0[Y]#XMj=a6K?_0W.W.X]ff_#O
W'X]#W/]ffMYKcd@
V ?(a.]#W.X__#Z'X
c 8_0XRa [ ##ff}W.X]*OQKPKc.M2_#M&b1]ffUU] q4MM C[a6K*Z6] q4UTKc6f#Kd'_#MYK &
\^]^\

fi

~33



s~$w

~ww$

RoM XMY[2W'_0X[RT[R]ffZ6Kc RoZ[Y]@# & ( %('('('&% & ) +MN.O [a._0[[a6KhRZ[YKPXMYKOQ[RT]ffZ ]#b[a6KhU_#Z6fffN._0f#KM]#b
[a.KeMN6d.d'_#MKM2RIjK#jT` [a6KMYKP[MU 6 & 0m4]#b:S;_0XRo_0d'UTKM[a6KeMN6d.d"_#MYKM3c6KPW/KZ.c]ffZ"_0XKe_#M
M^e_#UU_#M?W/]ffMMRd'UTK#/[a6KZ $ RM?RZ.b1KPXXKcbrX]ff^ &sqjXj[Pj2[a6KfffRTS#KZLW'_0X[RT[RT]ffZ RTb+_#Z'c ]ffZ.UTVRb
[a.K2OQ]ffDZ FYN.Z'OQ[RT]ffZ ]#b+_#UU &10+MN.Oa [a'_0[
ff U . &10 fi
ffU. $8 !
4 RoMOQ]ffZ'MRMY[YKZ[_#Z.c
KZ[_#RU
$\j\p%Z_eXKPS*RMR]ffZhMRT[N._0[RT]ffZ `6[a.RM_0W.W'X]ff_#Oa_#UMY]eKZ.MN6XKM,[a._0[4[a6K]ffZ.UTV]ffUchd/KURKPbrM
[a'_0[^e_ Vd/K[a6X] q4Z_q(_V _0XK2_0di]ffN.[4[a6K}S;_0XRo_0d'UTKMXKUTKPS0_#Z[[Y][a.K}RZ6W"N6[br]#X^}N'U_*j48R
Z'_#UUTV#`ff_#M=XKOQKZ[UTV2Ma6] q4Z2dV&MY]ff^eK]#b"[a.K_#N6[a6]#XM]#bi[a6K,W.XKMYKZ[W"_0WiKPX `ffb1]#Xf#KP[Y[RZ6fOP_#Zed/K
_#c.S;_#Z[_0f#KP]ffN.MUTVK W"UT]ffRT[YKc_#M_q:K_0#KZ.RZ6f^KOa'_#Z.RM^ b1]#XXKOQ] S#KPXRZ6fhOQ]ffZ.MRoMY[YKZ.OQVhbrX]ff^
_#ZRZ.OQ]ffZ.MRMY[YKZ[ A5 @9_#Z6%
f fi_0,X "N.RMP` 0# ff j
j P uQym0u /^-6tff#vuQff
j fi diKUoRTKPb.N6WBc._0[YK\]#W/KPX_0[Y]#X=^_0W'M9_*Z6] qUTKc6f#K:d'_#MYYK & _#Z.c}_#Z2RZ.W'N6[br]#X^&N.U_
$K *W.XKMMRoZ6fMY]ff^eK:K *W'URoOPRT[ KPS#]ffUN6[R]ffZ}]#b"[a6K:q+]#XUoc[Y]?_3Z6KPq Z.] q4UTKc.f#K+d'_#MK & $\G & _#Z.c
&
$XKMYW/KOQ[RTS#KUV}XKPW'XKMYKZ[[a.K_0f#KZ[ M+Z.] q4UTKc.f#K P5u M!0wu_#Z.c vuPw[a.K,KPS#]ffUN6[RT]ffZ2]#bi[a6K
q:]#XUcK W.XKMMYKcdV3[a6K+N.W/c'_0[YK#j KPS#KPX_#U_#N6[a6]#XM9_0XfffN6Kc[a._0[9_#Z}N6WBc._0[YK]#W/KPX_0[Y]#XMa6]ffN.Uc
W'XKMYKPXS#K+[a6K+W"_0X[ ]#b.[a6K+Z.] q4UTKc.f#K\d'_#MYK:Z6]#[9OQ]ffZ'OQKPXZ6Kc}dV?[a6K:N6WBc._0[YK#j94a.RMUK_#c.M [Y][a6K
br]ffUUT] q4RZ6f[a6XKPKQMY[_0f#KW'X]OQKMMP`/W.X]#W/]ffMYKcRoZ.c6KPW/KZ.c6KZ[UTVdV ]ffa.KPX[V#` @9N6;_#MgPKPq4ROQg#`B_#Z.c
_#c._#URoZ.MY0_; A:N.fff*_ F[ # ff\_#Z.c2dVKPXgRTf_#Z.c ER [ # ff_#Z'ceZ._#^Kch_#Z.c
!"!$#.`
XKMYW/KOQ[RTS#KUTV.I C,Rrc6KP[YKPX^eRZ.K[a6KS0_0XR_0d'UKM8XKUTKPS0_#Z[+[Y][a6K4N.W/c'_0[YK#`Z._#^KUTV#`%
ff U. $8
RoR14b1]#Xf#KP[[a6KMYKeS0_0XR_0d'UKMRoZ &s[Y]h]#d.[_#RZ_hZ.KPq b1]#X ^}N.Uo_
&'")(%+* U, . & %
ff U. $8Y
RoRR12K *W'_#Z.c dV $\j p%Z ^e]#XKLOQ]ff^W'_#OQ[[YKPX^eMP`[a.RMN6WBc._0[YK]#W/KPX_0[Y]#XhRMK W.XKMMYKc dV
&- $!.&'")(%+* U, . & %
ff U. $8Y0+
/ $\j\aN.MP`*d/]#[ah]ffN6X,XKMN'UT[M(]ffZh S4RZ'c6KPW/KZ.c6KZ.OQK
_#Z'c}S0_0XR_0d"UTK+br]#Xf#KP[Y[RZ.f3_0XK:XKUTKPS;_#Z[8[Y]?[a6K,OQ]ff^W'N6[_0[R]ffZ._#U*RMMN6KM9W/KPX[_#RZ.RoZ6f4[Y]3[a.RM*RZ.c
]#b8d/KURTKPb9N6WBc._0[YKMPj
jwu0 !0z.yrz{ Q P3!/*v} v0y !0z21}t,u Py1 0y !0z xe ;y1z{31 -" #z.z.yrz{#j @ ]#fffRoOP_#U:Uo_#Z6fffN._0f#KM&b1]#X2XK_#M]ffZ.RZ6f
_0d/]ffN6[_#OQ[RT]ffZeK W.XKMM8[a6K,K /KOQ[Mc6KP[YKPX^RZ.RMY[RoO\]#X=Z6]#[P`OQ]ffZ.c.RT[RT]ffZ'_#U]#X+Z6]#[ 9]#b"_#OQ[RT]ffZ'MdV
^eK_#Z.M\]#bW.X]#W/]ffMRT[RT]ffZ'_#U6b1]#X ^}N.Uo_#M
KUTbr]ffZ.+
c fi @9RTbMOa.R[Yg#` # *_#Z.c.KPq:_#UUI` # .._0XfffRKPX`
@9_#Z6f6` fi _0IX "N.RoMP` 0##*4KPXgRTf6` @9_#Z6f6*` _0IX "N.RoMP` fi ]ffU_#OPMYKPi9` 0# Z.c.RoZ6fe[a6K2S0_0XR
_0d"UTKM([a6K?K /KOQ[M4_0XKc6KPW/KZ.c.KZ[(]ffZKZ._0d'UKM([Y]Rc6KZ[RTbrVe[a6K?S0_0XR_0d'UTKM:q4a.]ffMYK?[YXN6[aS0_#UN6K
^_Vd/KOa._#Z6f#KcdVe[a6K3_#OQ[RT]ffZB6^]#XKP] S#KPX`.br]#X^&N.U_;UR[YKPX_#U'RZ'c6KPW/KZ.c6KZ.OQK65_}XK Z6K^KZ[
]#b SRZ.c6KPW/KZ.c.KZ.OQK2[a._0[q:KRZ[YX]*c.N.OQK5L_#UMY][YKUUoMN.MRZq4a.RO ac.RTXKOQ[R]ffZ rb1X]ff^ b_#UMYK
[Y]h[YX N6K&_#Z'c H ]#X?b1X]ff^ [YX N6K}[Y]hb_#UMYK 4[a6K&W/]ffMMRTd"UTK}O a._#Z6f#K^e_V]*OPOPN6Xja.RoMRMKMYW/KOPR_#UoUTV
N'MYKPbrN'U/b1]#X UT[YKPXRZ6f2]ffN6[RXXKUTKPS0_#Z[_#OQ[R]ffZ.MRZh_ec.KOPRMRT]ffZh^e_0*RZ6f]#X4W'U_#Z.Z.RoZ6f}W'X]#d'UTK^hj
j -iwY0u PuPwYuPz u?wYu -"wYuQPuPz'vI#v0y !0z.1
j @]#fffROP_#U'Uo_#Z6fffN._0f#KM=br]#X\XKPW.XKMYKZ[RZ6f?W.XKPb1KPXKZ'OQKqXRT[YK,KUK^KZ*
[_0XVf#]ff_#UM_#M3W'X]#W/]ffMRT[RT]ffZ._#Ub1]#X ^}N.Uo_#M_#Z'cR[RM3OQXN'OPR_#U[Y]Roc6KZ[Rb1V[a.]ffMYK2S;_0XRo_0d'UTKM[a._0[
a'_S#KZ.]3Ro Z 'N6KZ.OQK(]ffZ[a.K_0f#KZ[ M+W.XKPbrKPXKZ.OQK#ja6KPXKPb1]#XK#`b1]#X^&N.U_;IS0_0XR_0d"UTK:RoZ.c6KPW/KZ.c6KZ.OQK
a'_#M,_#ZRo^W/]#X[_#Z[:X]ffUTK3[Y]2W'U_ V"*br]#XRZ.MY[_#Z'OQK#`[a.KbrX_#^KPq:]#X]#b9MY]0OP_#UUKc uPvuPw y1 -*0w0y PM/
W'XKPb1KPXKZ.OQK,MY[_0[YK^KZ[M=]#b"_#Z_#Z.N
c K_0XU [ # <8RZ[YKPXW.XKP[M_3W'XKPb1KPXKZ.OQK:R[YK^ $ C3798;:<7
dV Cbr]#X_#ZVW'_#RTX3]#b:q+]#X Uc.M2>= % =@?MN.Oa [a._0[eR1=BA !C7`\RR1D=@?EA !: 7 _#Z.c RRR1F= _#Z.c
=@?OQ]ffRZ.OPRc6K]ffZ _#UU4S0_0XR_0d"UTK+
$ 0z"tG7 0wu yrz"tu -6uQz"tuQz'v w !0x2`[a6KZ q:K a'_S#KL_ M[YXROQ[
W'XKPb1KPXKZ.OQK]#b = ] S#KPX=@?1j
.k lIHKJ u{rffmuw{gz3{MLON r|wz3{#>Pz$uw{gu=>J*?q z=<qsr
a6K4XKMY[\]#bB[a.KW'_0W/KPX+RM\MY[YXN.OQ[N6XKc_#M+b1]ffUU] q4MPj fib1[YKPX(MY]ff^Kb1]#X^_#U.W.XKUoR^eRZ._0X RTKMfffRTS#KZRZLKO
[RT]ffZ `[a6K(#KPV2Z.]#[RT]ffZ2]#b"br]#X^&N.U_;IS0_0XR_0d'UK:RZ'c6KPW/KZ.c6KZ.OQK:RM8W.XKMYKZ[YKcRZ KOQ[R]ffZ j A:KOP_#N.MK4RT[
\^]+Q

fif.w~3}33f$3ws

OP_0W.[N6XKM=_3S#KPXV2d'_#MRO:br]#X^]#b/UT]#fffROId'_#MKceRZ.c6KPW/KZ.c.KZ.OQK#`0[a.RM8XKU_0[R]ffZa._#M=_#UTXK_#c.V}d/KPKZRZ[YX]0
c.N.OQKcRoZ2[a6KURT[YKPX_0[N.XK,N.Z.c6KPX=MYKPS#KPX _#U.Z._#^KMP`URT#K,R Z "N6KZ.OQK_0d'RUoRT[V5 A:]ffN6[RUoRTKPX` # < `*XKUTKPS0_#Z.OQK
[Y]_MN6Gd FYKOQ[4^e_0[Y[YKPX5 @_0#K^eKPV#KPX` # # `i]#XXKc.N.Z'c._#Z.OQVL ]ffa.KPX[VKP[_#UmjT` # ff j fiUT[a6]ffN.fffaRT[
RMOQ]ffZ.OQKPW'[N._#UUTV&_#Z.c2[YKOa.Z'ROP_#UUTV&MR^W'UK#`;[a'RMZ6]#[RT]ffZa._#MZ.]#[diKPKZM[N.c.RTKc2RZ_?MYV*MY[YK^e_0[RoO(q:_ V#`
_#Z.c}]ffN6X8S#KPXV X MY[OQ]ffZ[YXRTd"N6[RT]ffZ_#Ro^eM9_0[ UoURZ6f,[a.RoMfff_0W ` XMY[dVfffRSRZ.f4MYKPS#KPX_#U*WK "N.RTS0_#UTKZ[9Oa'_0XY
_#OQ[YKPXRTg_0[R]ffZ.M]#b[a.RMZ6]#[R]ffZ r[a.RoM4RMN'MYKPbrN'Um`'_#MMYKPS#KPX_#U9W'_0W/KPXM4RZ[YX]*c.N.OQKc_#Z'cN.MYKc[a6K&M_#^K
OQ]ffZ.OQKPW.[MN'Z.c6KPX}c':R iKPXKZ[2Z._#^KM `+_#Z.c MKOQ]ffZ.c dVRoZS#KMY[Rfff_0[RZ6f OP_0XKPbrN'UUTVRT[M&OQ]ff^W'N6[_0[R]ffZ._#U
OQ]ff^W'UK *RT[V#j=p%ZW'_0X[ROPN.Uo_0X`q:KMa6] q [a._0[P`.RZ[a.K?f#KZ6KPX_#UBOP_#MYK#`'O a6KO*RZ6fq4a6KP[a6KPX_2br]#X^&N.U_2RM
RZ.c.KPWiKZ'c6KZ[brX]ff^ _MYKP[:]#b S0_0XR_0d'UKM\RM 'OQ]ff^W'UKP[YK#j+a6KZ `q:Kf#]&d/KPV#]ffZ.ce[a.RoM=S#KPXVMR^W'UTK
Z6]#[RT]ffZdVeRZ[YX]c.N'OPRZ6f?[a6K^]#XK Z6KQIf#X_#RZ6KcZ6]#[RT]ffZ]# b !#w N
x /* '
yvuQwY0 yrz"tu -6uQzituQz u(RZ]#X c6KPX
[Y]c.RMOQXR^eRZ'_0[YK[a6KMRT[N._0[R]ffZqa6KPXK_b1]#X^&N.UT
_ & OQ]ffZS#KPV*MM]ff^KRZ6br]#X^e_0[RT]ffZ_0d/]ffN6[?_UoRT[YKPX_#U
d'N6[2Z6] RZ6br]#X^e_0[RT]ffZ _0d/]ffN6[&R[M&Z.KPfff_0[RT]ffZBjLa.RM}XK Z.K^KZ[2RM&a6KUTW.bN.U\q4a6KZ6KPS#KPX2[a6KW/]ffU_0XRT[V
]#b3RZ6br]#X^e_0[RT]ffZ RMMRTfffZ'R OP_#Z[P`q4a.RO RM&[a6KOP_#MYKRZ ^e_#ZV fip KUc.MhRZ.OPUN'c.RZ6fOPU]ffMYKc*Iq:]#XUc
XK_#MY]ffZ'RZ6f_#Z'cXK_#M]ffZ.RZ6f_0d/]ffN6[_#OQ[RT]ffZ'M j3JLK2_#UoMY]MY[N'c6VMYKPS#KPX_#URZ[YKPXKMY[RoZ6fZ6]#[R]ffZ.Mc.KPXRTS#Kc
brX]ff^b1]#X ^}N.Uo_;IS;_0XRo_0d'UTK(_#Z.cbr]#X^}N'U_;URT[YKPX_#URZ.c.KPWiKZ'c6KZ.OQK#`#MN.O ae_#M[a6KZ6]#[R]ffZ2]#by1.
x -"y
(ut M!0Iw
x /* 2 & RM @9RT[%: S=_0XY+MR^eW'UR Kc2RTbBRT[:c6KPW/KZ.c.M]ffZKPS#KPXVeUR[YKPX_#U9rS0_0XR_0d'UK ]OPOPN.XXRZ6f}RZRT[ =_#Z.c
N
[a6KOQ]#XXKMYW/]ffZ.c.RoZ6fW.X]*OQKMM]#bMRo^W'URTbrV*RZ6f_b1]#X ^}N.Uo_*j KMYW'R[YK[a.RMOQ]ff^W'UTK 6RT[VL_#Z.cd/KOP_#N.MYK
[a6KMRTgPKe]#b_MR^W'UoR Kcb1]#X ^}N.Uo_OP_#ZZ6KPS#KPX&d/KU_0Xf#KPX&[a._#Z[a6KMRgPKe]#b,[a6K]#X RTfffRZ._#U8br]#X^&N.U_*`
MR^eW'UR OP_0[R]ffZ}OP_#ZW.X] S#K_3S;_#UN'_0d'UTK(XKUTKPS0_#Z.OQKQId'_#MYKcW.XKPW.X]OQKMMRZ6f3b1]#X+R^W.X] SRoZ6f^_#ZV2br]#X^eM
]#bRZ6brKPXKZ.OQK#j
p%%
Z KOQ[RT]ffZ <6`q:K[N6XZ[Y][a6K4MYKOQ]ffZ.ce#KPV2Z.]#[RT]ffZB`Z'_#^KUTYV M!0wm{uvmvy1z{?{#yr0uQzPuv ![;#w ymQ PQu
yrzY !0wN
x /* 5 @RT
Z fi EKRT[YKPX ` # < j+a6K3br]#Xf#KP[Y[RZ6fW'X]OQKMM+W"U_V*M,_#ZhR^W/]#X[_#Z[+X]ffUTK?RZ^e_#ZV
fip?[_#MYM&_#Z.c a._#Md/KPKZM[N.c.RTKcRoZ[a6KURT[YKPX_0[N6XKN.Z.c6KPXS;_0XR]ffN.M]#[a6KPX2Z._#^KM`MN'Oa_#M}S0_0XR
_0d'UTK&KUR^RZ._0[RT]ffZB`i]#X^e_0XfffRoZ._#URTg_0[RT]ffZ ?]ffa.Uo_#MP*` ]#X _#Um` fi _0KZ.Z.RI` ##ff j KPS#KPX _#UMYK^e_#Z[ROP_#U
Oa'_0X_#OQ[YKPXRTg_0[RT]ffZ'M}_#Z.c^KP[_0[a6KP]#XKP[ROW.X]#W/KPX[RTKM3]#b(br]#Xf#KP[Y[RZ6f_0XKW.XKMYKZ[YKc j A(_#MYKc]ffZ[a.RM
Z6]#[RT]ffZ `.q+K}RZ[YX]c.N'OQK_#Z_#c.c.R[RT]ffZ._#UBZ6]#[RT]ffZ]#b8c.KPWiKZ'c6KZ.OQK?d/KP[q:KPKZ[q+]b1]#X ^}N.Uo_#M,fffRTS#KZ_MYKP[
]#b/S;_0X R_0d'UTKMM C9q+KMY[_0[YK4[a'_0[ & RoMWK "N'RTS;_#UKZ[[Yff
]
qjXj[Pj U RTb/_#Z.ce]ffZ'UTV&Rb"d/]#[abr]#X^&N.U_#M=_0XKUT]#f0
ROP_#UUV}WK "N.RTS0_#UTKZ[=]ffZ.OQK^_#c6K4RZ.c.KPWiKZ'c6KZ[8brX]ff^ KPS#KPXVS;_0XRo_0d'UTK,K 6OQKPW.[\[a6]ffMK4]#b Uj<KPXK_0fff_#RZB`
RT[,RM(R^W/]#X[_#Z[([Y]e^e_0#K_2c.RMY[RoZ.OQ[RT]ffZdiKP[q+KPKZ_2S;_0XRo_0d'UTK3_#Z.chRT[M(Z6KPfff_0[RT]ffZrbr]#XRZ.M[_#Z.OQK#`6]ffZ6K
OP_#ZdiKRZ[YKPXKMY[YKcRoZ[a6K4W/]ffMR[RTS#KOQ]ff Z 'ROQ[M+]#bB_MYV*MY[YK^h`]ffZ.UTV. j6]#X:[a.RM=W"N6XW/]ffMYK#`ffq:KRZ[YX]*c.N.OQK
_?Z6]#[RT]ffZ2]#b/URT[YKPX _#Ubr]#Xf#KP[Y[RZ.f[a._0[XK Z.KM8[a6KOQ]#XXKMYW/]ffZ.c'RZ6f3Z6]#[RT]ffZ2]#biS;_0XRo_0d'UTK:b1]#Xf#KP[Y[RoZ6f6jJLK
Ma6] q a6] q OPUT]ffMKc*Iq+]#X UceRZ6brKPXKZ.OQKOP_#Zd/KMR^W"UTV}O a._0X_#OQ[YKPXRTgPKcbrX]ff^[a6KOQ]#XXKMYW/]ffZ.c.RoZ6f3WK "N.RS
_#UTKZ.OQKXKU_0[RT]ffZ j88RZ'_#UUTV#`ffq:KRc.KZ[RTbrV&[a6KOQ]ff^W"UTK *R[V]#bBd/]#[aZ6]#[R]ffZ.M=]#bBWK "N.RTS0_#UTKZ.OQK4_#Z'cMa6] q
[a6K^ [Y]d/Ka._0Xc fi - OQ]ff^W"UTKP[YK j fiM_OQ]ffZ.MYWK "N6KZ.OQK#`"b1]#Xf#KP[Y[RZ6fS0_0XR_0d"UTKM(]#XUR[YKPX_#UM,q4R[a.RZh_
br]#X^}N'U_OP_#Z.Z.]#[d/K}_#O a.RTKPS#Kc RZWi]ffUVZ6]ff^R_#UB[R^K&RZ[a.K}f#KZ6KPX _#U9OP_#MYKN.Z'UTKMM[a.K}W/]ffUTV*Z6]ff^eR_#U
a.RTKPX _0XOaVOQ]ffUoU_0W'MYKM_0[[a6K X MY[UTKPS#KU1 j+JLK}_#UMY]Ma6] q [a._0[_W/]ffUTV*MRTgPK3W.X]#Wi]ffMRT[RT]ffZ._#UiXKPW.XKMYKZ*
[_0[RT]ffZ ]#b,b1]#Xf#KP[Y[RZ6fRoMS#KPXVN.Z'URT#KUTV[Y]K 6RMY[}RoZL[a6Kf#KZ.KPX_#U+OP_#MK#jhJLKZ6KPS#KPX[a6KUTKMM}W.XKMYKZ[
MY]ff^KXKMY[YXROQ[YKcMRT[N._0[RT]ffZ'M(q4a6KPXK?br]#Xf#KP[Y[RZ6fRM([YX_#OQ[_0d'UTK#j
KOQ[R]ffX
Z Ma6] q4M} SRZ.c6KPW/KZ.c.KZ.OQKOPUT]ffMYKUVLXKU_0[YKc [Y]Z6]#[R]ffZ.M]#b4RXXKUTKPS0_#Z.OQK_#UTXK_#c6VRZ*
[YX]*c.N.OQKcLRZ [a.KeURT[YKPX_0[N6XK&dVS;_0XR]ffN.M?_#N6[a6]#XM%
j KOQ[RT]ff
Z hc.RoMOPN.MMYKM]#[a6KPXXKU_0[YKcLq:]#XL_#Z.c
MY#KP[O a6KM3brN.X[a6KPX4K *[YKZ.MR]ffZ.M]#b\M]ff^K}Z6]#[R]ffZ.M_#Z'cXKMN'UT[M4MY[N'c.RTKcRoZ[a6K}W'_0W/KPXj8RZ._#UUTV#` KO
[RT]ffZ OQ]ffZ.OPUN.c.KM[a.K&W"_0WiKPX j =X]]#brM3]#b+[a6K^e_#RZW.X]#W/]ffMRT[R]ffZ.M_0XK&XKPWi]#X[YKcRoZ_#ZL_0W.W/KZ.c'R ij
fi fffUT]ffMM_0XV]#b[a6KZ6]#[_0[R]ffZ.MRM_0[4[a6K?KZ.ch]#b8[a.RM(W"_0WiKPX `X RTfffa[,d/KPbr]#XK?[a6Kd"RTd'URT]#f#X _0W'aV#j

\^]

fi

~33



s~$w

~ww$

8A H H OH 3
JLK XMY([ XKOP_#UU M]ff^Kd'_#MRoOZ.]#[RT]ffZ.M,brX]ff^ W.X]#Wi]ffMRT[RT]ffZ._#U/UT]#fffRO0`._#Z'chb1X]ff^ OQ]ff^W'UTK6RT[V[a6KP]#XV#j
7/lmk



=<

ru \u3uw{#z3Cy?u3|

;

@ KPff
[
fi d/K_ Z.RT[YKeMYKP[}]#b:W'X]#W/]ffMRT[RT]ffZ._#US0_0XR_0d'UKMPj

RM?[a6KeW'X]#W/]ffMRT[RT]ffZ._#UUo_#Z6fffN._0f#K
d'N.RoUT[N6Wb1X]ff^
fi:`i[a6K2OQ]ffZ.Z6KOQ[RTS#KM3_#Z.c[a6K A+]]ffUTK_#Z OQ]ffZ.MY[_#Z[M* &_#Z.c "&RZ[a6K}N'MN._#U
q(_V#j\6]#X,KPS#KPX+
V U!"
fi:#`

%$ c6KZ6]#[YKM:[a6K3MN6d"U_#Z6fffN._0f#K]#b&

f#KZ6KPX_0[YKcbrX]ff^ [a6K
S0_0XR_0d'UTKM3]#b U ]ffZ.UTV#j fi yvuQwY0/]#'b

%$ RM3KRT[a6KPX_hS0_0XR_0d"UTK2]#b U rW/]ffMRT[RTS#KURT[YKPX _#U14]#X[a6K
Z6KPfff_0[RT]ffZ]#b_}S0_0XR_0d'UTK4]#b U Z6KPfff_0[RTS#K?UR[YKPX_#U1 ja6KRTX:MYKP[(RM+c.KZ6]#[YK)
c (*$(`q4a.RU+K (*,$ rXKMYW -j (/$.
c6KZ6]#[YKM&[a6KMYKP[&]#b,Wi]ffMRT[RTS#KrXKMW jZ6KPfff_0[RTS#K URT[YKPX _#UMd'N'RUT[N6W b1X]ff^ Uj fi OPU_#N.MY)
K 0rXKMYWj9_
[YKPX2
^ 1 =]#%b
3
$ RM(_hrWi]ffMMRTd'UTVK^eW.[V. Z.RT[YK3c.RM FN.Z.OQ[R]ffZrXKMYWj*OQ]ffDZ FYN.Z'OQ[RT]ffZ"=]#b9URT[YKPX _#UM\]#b


%$(ffj fi ?54 rXKMYW j*_ 64=\b1]#X ^}N.Uo_]#&b

%$ RM:_ Z.RT[YKOQ]ffZ FN.Z.OQ[RT]ffZ]#bOPU_#N.MKM3rXKMYW j
c.R5M FYN.Z'OQ[RT]ffZ]#b:[YKPX^eM]#'b

%$,j fiMN.MN._#Um`/KPS#KPXV Z.RT[YK2MYKP[]#b:br]#X^}N'U_#M3b1X]ff7
^
3
% RM
Rc6KZ[R Kcq4R[ah[a6K?br]#X^}N'U_2[a._0[4RM([a.KOQ]ffZ FN.Z.OQ[RT]ffZ]#bRT[M(KUTK^eKZ[MPj
6X]ff^ Z6] q ]ffZBG` & c6KZ6]#[YKM\_W.X]#W/]ffMRT[RT]ffZ'_#Ubr]#X^&N.U_*`RmjK#jT`_^K^}d/KPX=]#8b
3
%ij U, . &RM
[a6KMYKP[\]#bBW.X]#Wi]ffMRT[RT]ffZ._#U*S0_0XR_0d'UKM=_0W.W/K_0XRZ6f}R%
Z &j8pb (9"(*iG` U,.: ((8RM=[a.KMYKP[+]#bBS;_0XRo_0d'UTKM
brX]ff;
^
fi N6W/]ffZ q4a.RoOa URT[YKPX_#UM]#
b ( _0XK d'N'RUT[Pj +UTK^KZ[M]#
b
fi _0XKLc6KZ6]#[YK=
c <'?
` >?
` @ KP[O0j
\UK^KZ[M:]#&b ( _0XK3c.KZ6]#[YK)
c #` ( #` - KP[O0j 6N6d'MYKP[M+]#&b
fi _0XK?c6KZ6]#[YKc UeB` A#` CKP[O0j=p%Z]#X c6KPX
[Y]MRo^W'URTbrVZ6]#[_0[R]ffZ.MP`q:K4_#MMR^eRU_0[YK,KPS#KPXV2MRZ6fffUTKP[Y]ff%
Z U !$#D< +q4RT[aRT[M=N.Z.8R "N6K(KUTK^eKZ-[ <"ja6K
Fy E u\]#b _}b1]#X ^}N.Uo_ &`*c6KZ6]#[YKcdVA &A
`*RM\[a6KZN.^}diKPX+]#bB]OPOPN.XXKZ.OQKM+]#b S0_0XR_0d'UTKM\RT[+OQ]ffZ[_#RZ.MPffj fi
W.X]#W/]ffMR[RT]ffZ._#UBbr]#X^&N.UT
_ & RMM_#Rc[Y]d/K}R
Z 44KPfff_0[R]ffG
Z 44]#X^_#U.]#X^ : 4?4=4Rb=_#Z.c]ffZ.UTVRTb]ffZ.UV
W.X]#W/]ffMR[RT]ffZ._#U8MYV*^d/]ffUM_0XKRZL[a6KMOQ]#W/Ke]#b_#ZL]*OPOPN6XXKZ.OQK]#bD: RZ &jp[}RM?q:KUU I*Z6] q4Z[a._0[
KPS#KPXVW.X]#Wi]ffMRT[RT]ffZ._#U*br]#X^&N.U_ & d'N.RUT[N6Wb1X]ff^ [a6K4OQ]ffZ'Z6KOQ[RTS#KMF/:B` H(` ::#` ]ffZ.UTV#`OP_#Zd/K[N.XZ6Kc
RZURZ6K_0X:[R^K?RZ[Y]2_#ZWK "N.RS;_#UTKZ5[ 4?4br]#X^&N.U_}dK
V J%W'N.Ma.RoZ6f}c6] q4MZ L}KPS#KPXV]OPOPN6XXKZ.OQK]#b<: RZ
RT[RmjK#jT`6K *W'UT]ffRT[RoZ6
f K ]#Xfff_#Z MUo_q:_#Z.cXK^] S*RZ6fc6]ffN6d"UTKZ.KPfff_0[RT]ffZ.MMRoZ.OQK: RM(RZS#]ffUoN6[RTS#K j
*URfffa[UTV _0d'N.MRZ6fhq:]#Xc.MP`q+KOP_#UU=[a.Kbr]#X^}N'U_hXKMN'UT[RZ6fhbrX]ff^ [a'RMZ6]#X ^e_#URTg_0[RT]ffZW.X]*OQKMMvr~6u
NON?P]#b & _#Z.chq:KZ6]#[YK ( 3 *P &+[a6KMYKP[4]#bUR[YKPX_#UM(brX]ffQ
^ (R]*OPOPN6XX RZ6fRZ[a6
K 4O4 ]#b &j=.]#X
RZ.M[_#Z.OQK#`0[a6'K 4O4]#b & !O:,Y :< T/ SPU H5V RoM: W HFX: SP/FY: V;a.KZ.OQK#`0q+K,a._ S#5K ( 3 *P &/ !$# % X: % Y: V +ffj
4]#[YK4[a._0[=[a.+K 4?4 ]#b/_?b1]#X ^}N.Uo_?c6KPW/KZ.c.M8]ffZeRT[M\MYVZ[_#OQ[ROP_#U"MY[YXN.OQ[N6XK#`RmjK#jT`ff[q+]}b1]#X ^}N.Uo_0K,[a._0[
_0XKMVZ.OQ[_0[RoOP_#UUTVc.:R /KPXKZ[,^e_ Vha._S#K&c.:R /KPXKZ/[ 4O4M4KPS#KZRTb9[a6KPVh_0XK?WK "N.RTS0_#UTKZ[Pj
.N'UU\RZ'MY[_#Z[Ro_0[RT]ffZ.M]#b4S;_0XRo_0d'UTKM]#.
b UZ2
fi _0XKOP_#UUTKX
c U| !0wTt; ( \[a6KPV_0XKc6KZ6]#[YKc dV
=%$ _#Z.c[a6KRTX?MYKP[?RMc6KZ6]#[YKG
c [/$,jJ a6K]
Z \ _#Z'_
c ^ _0XK2[q:]c'RM FY]ffRZ[MN6d'MKP[M]#*b
fi:` = ` / %=
c6KZ6]#[YKM:[a6O
K \ . ^}Iq:]#XUc[a._0[:OQ]ffRZ.OPRc.KM\q4R[a = `]ffb
Z \ _#Z.cqRT[a %= a]ffb
Z ^/j fiZRoZ[YKPXW'XKP[_0[RT]ffZ
= ] S#KP+X
3
%RoM FN.MY[(c
_
fi9Iq:]#XUcB`*_#Z.c= RM(M_#Rc[Y]2d/K3_2^]*c6KU"]#b & q4a.KZ6KPS#KPX,RT[,^e_0#KYM &
[YXN6K#j\JLKc6KZ6]#[Y
K f' e" &([a6KMYKP[]#b8^]*c6KUM(]#b &j
6]#XKPS#KPXVbr]#X^&N.U_ &s_#Z.cKPS#KPXVS;_0X R_0d'UTff
K >` &5gih / rXKMW j &'gih ( RM3[a6K2b1]#X ^}N.Uo_]#d'[_#RZ6Kc
dVLXKPW'U_#OPRZ.fhKPS#KPXV]*OPOPN6XXKZ.OQK]#Tb > RoX
Z &dVL[a6KOQ]ffZ.MY[_#Zc
[ "rXKMYW j * f ; j &5j h ( rXKMYW j
&5j h / \RoM,_#Zh_0d.d.XKPS*R_0[RT]ffZbr]#X &'gih ( rXKMYW 1
j &'gih / +qa6K)
Z 9RM,_2W/]ffMR[RTS#KUoRT[YKPX_#8U >_#Z.cbr]#X &'gih /
rXKMYW1j &'gih ( +q4a6Kk
Z 8RM,_Z6KPfff_0[RTS#K}UoRT[YKPX_#UM%: >9j

3RS#KZ_#ZRZ[YKPXW.XKP[_0[RT]ffZG= _#Z.c_hUoRT[YKPX_#X
U `q:KUTKP[&')l V>= % I?c.KZ6]#[YKe[a6KRoZ[YKPXW'XKP[_0[RT]ffZ
[a._0[fffRTS#KMe[a6KM_#^K[YX N6[a S0_#UN6K_#M= [Y] _#UUS;_0XRo_0d'UTKM2K 6OQKPW.[[a.KS;_0X R_0d'UTKh]#3
b `,_#Z.c MN.O
[a._0[&'"l V>= % !!j2p%ZL]#[a6KPXq:]#Xc.M`M&')l V >= % I3RM3[a6KeRZ[YKPXW.XKP[_0[RT]ffZLM_0[RMYbrV*RZ6m
f \[a'_0[RM

nporqtsuXvXwFxty{z}|~{z}u-|yT{||u~Ofz}{|TyD~iu|&yuzvTo
\^]i

fif.w~3}33f$3ws

[a6KOPU]ffMYKMY[?[Y] =,j.]#X}RZ.M[_#Z.OQK#` W.X] SRoc6Kc [a._0[
fi ! # % S>+_#Z.cG=4 6 ! =4SP! 0`q:Ka._ S#K
&')l V>= % X: SPQ 6!:_#Z'c &')lV >= % :XSPQSP! *j ?,UTK_0XUTV#` RTb6= !!:[a6KZG&'"lV>= % I!=,j2pb
(@! #i ( %('('('>% ) +}RoM,_eOQ]ffZ.MRM[YKZ[4MKP[]#bUoRT[YKPX_#UMP`*[a6KZ-&')fV>= % (:,RoM,c6K Z6Kch_#M
&')l V '('(' &')f V>= % ( %('('(' % ) '
@_#M[UTV#`*fffRTS#KZh_#ZhRZ[YKPXW.XKP[_0[RT]ffZ
= _#Z.ch_&S;_0X R_0d'UT?
K >`*q+KUKPT[ fi 3 * V9>= % >/(c.KZ6]#[YK?[a6K?RZ[YKPXW.XKQ
[_0[RT]ffZL[a'_0[fffRTS#KM[a.KeM_#^Ke[YXN.[a S;_#UN.Ke_#M = [Y]_#UU8S0_0XR_0d'UKM3K *OQKPW.
[ >`_#Z.c[a._0[fffRTS#KM?[Y] >
[a6KS0_#UN6K3]#W.W/]ffMR[YK?[Y]e[a._0[fffRTS#KZdV=,j
,q:]br]#X^&N.U_#
_#Z.c
_0XKM_#Roc [Y]d/K u M/*y100uQz'v}x !Dt /* !_b1]#X^&N.UX
_ & RTb3_#Z.c ]ffZ'UTV Rb
&
/ &G/
j
p%Z[a.RM(W'_0W/KPX,q:KN.MYK?[a.KOQ]ffZ.OQKPW.[M]#bW.XRo^K?R^W'URoOP_0[YKM:_#Z'cW.XR^K?R^eW'UROP_#Z[MPja6K?MYKP[]#b
W.XRo^K?R^W'URoOP_0[YKM(]#b_br]#X^&N.U_ &`.c.KZ6]#[YKchd

V
& `'RM4c6K Z6Kch_#MM C


&ff!$#02OPU_#N'MYKKA&OA ! &0 _#Z.c

4ff

0 ? OPU_#N'MYKMPj[Pj
& ! 0 ? _#Z.ck0 ? ! 0&_#Z.c 0 A4! 0 ? +
'

fi^]ffZ6fL_#UU:[a6KR^eW'UROP_0[YKM}]#
b & RmjK#jT`+[a6KhOPU_#N.MYKM2KZ[_#RUTKc dV#& `+[a6KW.XR^eKR^eW'UROP_0[YKM
]#b.&_0XK[a6K^eRZ.R^_#U8]ffZ6KMqjXj[Pj ! RIjK#jT`[a.KUT]#fffROP_#UoUTVM[YX]ffZ6f#KMY[&]ffZ6KM ja.KMYKP[&]#b:W'XR^K
R^W"UROP_#Z[M+]#b_br]#X^&N.U_ &`.c6KZ.]#[YKcdVb
fi & `'RM4c6K Z6Kchc.N'_#UUTV_#MMC


fi " &

!$#U1[YKPX

^ 1GA ! & _#Z.c 4 ff 1 ? [YKPX^ MPj[Pj#1 ? ! & _#Z.c)1 ! 1 ? _#Z.cb1 ? A4! 1*+ '
fi^]ffZ6fh_#UU[a6KR^W"UROP_#Z[M4]#b & RIjK#jT`B[a6K2[YKPX^eM?R^W"UTVRoZ6fL& `/[a6K2W.XRo^K&Ro^W'UROP_#Z[M]#b &
_0XK[a.K^e_ *Ro^e_#UB]ffZ6KM,qjXj[PjA ! RmjK#jT`'[a6KUT]#fffROP_#UoUTVq:K_0#KMY[4]ffZ.KM j
b+OQ]ffN6XMYK#`B[a6KMYKP[3]#b+W.XR^K&R^W'UoROP_#Z[M H;_0[YKM^_VOQ]ffZ[_#RZ WK "N.RTS0_#UTKZ[[YKPX^MIH;OPU_#N.MYKMjJLK
OP_#Z XKMY[YXROQ[]ffN6X_0[Y[YK^W.[RT]ffZ [Y]]ffZ6K[YKPXL
^ H;OPU_#N.MYKhbr]#XK_#O MYKP[e]#b3WK "N.RTS0_#UTKZ[[YKPX^eIM H;OPU_#N'MYKMPj
[_0[YKc ]#[a6KPXq4RoMYK#`,R9
Z
fi &_#Z'
c
& `,]ffZ.UTV ]ffZ6KXKPW.XKMYKZ[_0[RTS#KWiKPXWK "N.RS;_#UTKZ'OQKOPU_#MMRM
#KPW.[Pj
H_S % :<,_
/ V % e +~6uuPYv ! -"w yrxuy1.x -"5y #vu%
! & yo 1 P4
z3v <q
k uv & ! # ff
t;u
=z.yv5y !0z1


& !$#

H)S % H :XVXH % :Ye3H % eH :@ % 3H-:YV-H)e

+ '

J uv <mzuw{#z3 J uwv <q
a6KOQ]ff^W'UTK6RT[V&XKMN.UT[M\q+KfffRTS#KRoZe[a.RM\W'_0W/KPX\XKPbrKPX:[Y]}MY]ff^K3OQ]ff^W'UK*RT[VeOPU_#MMYKM+q4a.RoOaec6KMKPXS#K
MY]ff^K XKOP_#UoUMPj ]#XKLc6KP[_#RUMOP_#Z d/Kbr]ffN.Z.c RZ 8_0W'_#c.R^eR[YXRT]ffN M[ # <[YK [Yd/]]#"
j
3RTS#KZ _
W.X]#d"UTK^ `iq:K2c.KZ6]#[YK}dV [a6K2OQ]ff^W'UTK^KZ[_0XVW'X]#d'UTK^ ]#b j4JLK_#MMN.^K&[a._0[[a.K&OPU_#MMYKM
9` _#Z.c L_0XKZ.] q4Z[Y][a6K?XK_#c6KPXj+a6K?br]ffUUT] qRZ6f2OPU_#MMYKM4q4RUU/_#UMY]d/KOQ]ffZ.MRc6KPXKc C
B:RM([a6KOPU_#MM]#b8_#UoUBU_#Z6fffN._0f#K/M ( MN.O ah[a._0+[ ( ! ( ( )
fi ( - `6qa6KPXK
- _#UoMY]Z.] q4Z_#!
( ( RoMRZ _#Z.
c ( - RZ 9j a6K&OP_#Z6]ffZ.ROP_#U " - OQ]ff^W'UTKP[YK2W.X]#d'UTK^ RM!+$ #&%('*)M!$ #C,_
W"_#RTX]#b,br]#X^&N.U_#,
+ $ % .7 -}RM}RZ !+$ #$%('/)M!$ # RTb(_#Z.c ]ffZ.UTV RTYb $ RMM_0[RM _0d'UKe_#Z.c 7RMZ6]#[Pj
4a6KOQ]ff^W"UTK^KZ[_0XVeOPU_#MM " - RM\[a6K3OPU_#MM=]#b9_#UU'U_#Z.fffN._0f#K*M ( MN'Oa[a._0*[ ( ! ( ( . ( - `
qa6KPXK ( ( RoMRZ _#Z.c ( - RZ ja6KOP_#Z6]ffZ'ROP_#U " - OQ]ff^W'UKP[YKW.X]#d"UTK^ RM,!+$ #&0
+ $ % .7 -,RM(RZ !$ #(0 1/2 04'*)M!+$ #RTb_#Z.c]ffZ'UTVRTb $RM(M_0[RM _0d'UTK
132 04'*)M!+$ #C_&W'_#RTX(]#b9b1]#X^&N.U_#5
]#X7 RM4Z6]#[Pj
7/l87

\^]76

fi

~33



s~$w

~ww$

- ! RM[a6KOPUo_#MM]#b_#UoU\U_#Z6fffN'_0f#KM}XKOQ]#fffZ.RTg_0d'UTKRZW/]ffUTV*Z6]ff^eRo_#U8[R^KdV_c.KP[YKPXY
^RZ.RMY[RoO?9N6X RZ6fe^e_#O a.RZ6K}KW" N.RW.W/Kcq4RT[a_#Z L]#X_#OPUTK#`/RmjK#jT`/_c6KPS*ROQK&_0d'UTK[Y]MY]ffUTS#K2_#ZV

RoZ.MY[_#Z.OQK?]#b_#Z ]#X4_ W.X]#d"UTK^ RZhN.Z.RT[([R^eK#j - RM[a6KOQ]#XXKMYW/]ffZ.c'RZ6fOPU_#MM,]#b
bN.Z.OQ[R]ffZW.X]#d'UTK^MPj
& - ! RM4[a6K}OPUo_#MM]#b=_#UUU_#Z6fffN._0f#KMXKOQ]#fffZ.RTg_0d"UTK}RZWi]ffUVZ6]ff^R_#U/[R^K}dVh_Z.]ffZ.c6KQ
[YKPX ^eRZ.RM[RO?9N.XRZ6fe^e_#O a.RZ6K}WK "N'RTW.W/Kcq4RT[a_#Z ]#X_#OPUTK#j44a6KOP_#Z6]ffZ.RoOP_#U & - OQ]ff^W"UTKP[YK
W'X]#d'UTK^ ff
fi RM&[a6KMKP[]#b4_#UU:[YXRTW'UK

+:\ !=# ( %('''% + % ^ !=#S ( %('''% ) + %
-qa6KPXK
\ _#Z.c ^ _0XK[q+] c.R5M F%]ffRZ[MYKP[M]#bW'X]#W/]ffMRT[RT]ffZ._#U(S0_0XR_0d"UTKM_#Z.c
RM_ br]#X^}N'U_LbrX]ff^

3
%` a(j fi W/]ffMR[RTS#K}RZ'MY[_#Z.OQK2]#b\[a.RoMW'X]#d'UTK^ RM3_[YXRTW'UTK +:\ % ^ %
-br]#X3q4a.RO a[a6KPXK
K6RMY[M4_ \Iq:]#XUc = `MN.Oah[a'_0[b1]#X_#UWU ^}Iq+]#XUoc%= q:Ka._ S#K= `/
%= !
3j
U fi - OQ]ff^W'UTKP[YKW.X]#d'UTK^
fiRM}[a6KMYKP[2]#b4_#UU
fi - ! Q& - ! j a6KOP_#Z6]ffZ.RoOP_#
[YX RTW'UTKM +:\ ! # ( %('''% + % ^8! #S ( %('''% ) + %
-q4a.KPXff
K \ _#Z.G
c ^ _0XK[q:]c.RM FY]ffRZ[MYKP[M?]#b
W'X]#W/]ffMRT[RT]ffZ._#US0_0XR_0d'UTKM_#Z.c
RM_br]#X^}N'U_4brX]ff^

` /j fi Wi]ffMRT[RTS#K(RZ.MY[_#Z.OQK(]#b"[a.RM
W'X]#d'UTK^ RM3_h[YX RTW'UT
K +:\ % ^ %
-?MN.Oa [a'_0[b1]#X?KPS#KPX]
V \4Iq:]#XUc = ` [a6KPXKK 6RMY[Mm
_ ^}Iq:]#XUc
=Ya br]#Xq4a.RO a= `/
%= !
3j
& - _#Z.c fi - _0XKOQ]ff^W'UK*RT[VeOPU_#MMYKM:UT]*OP_0[YKc_0[:[a6KMY]0OP_#UUTKcMYKOQ]ffZ.cUTKPS#KU.]#bB[a.KW/]ffUTV*Z6]ff^eR_#U

a.RTKPX _0XOaV#`.q4a.RoOaW'U_ VM4_2W.X]ff^eRZ.KZ[(X]ffUTKRoZhZ.] q4UTKc.f#K?XKPW.XKMYKZ[_0[RT]ffZ_#Z'chXK_#MY]ffZ.RoZ6f6j

8A E RG 4H l W

F aE *G [H O* C -F -F B
6]#X^&N.U_;UoRT[YKPX_#U_#Z.c b1]#X^&N.U_;IS0_0XR_0d"UTKLRZ.c6KPW/KZ.c6KZ'OQKOP_0W.[N.XKMY]ff^Kb1]#X^M]#b2RoZ.c6KPW/KZ.c6KZ.OQK
d/KP[q:KPKZ[a6K2[YXN6[aS;_#UN.KM4]#b=S0_0XR_0d"UTKM4_#Z.c[a6K&W/]ffMMRTd"UTK?[YXN6[aS;_#UoN6KM4]#b+_br]#X^&N.U_*j E]ffN6fffa.UV
MYW/K_0*RZ6f6`&RoMc6KPW/KZ.c6KZ[]ffff
Z .d/KOP_#N.MK+RT[[YKUUM]ffZ6K:M]ff^KP[a.RZ6fW/]ffMRT[RTS#K:_0di]ffN.[ C9^]#XK+W.XKOPRMYKUTV#`
[a6KPXKRM_OQ]ffZ[YKMY[P`+RmjK#jT`_OQ]ffZ FN.Z.OQ[RT]ffZ]#bURT[YKPX_#UM` [a._0[P`_#c.c6Kc[Y][Y] &KZ._0d'UKM]ffZ6K[Y]RZ6brKPX
j6]#XRZ'MY[_#Z.OQK#` & ! k
SPRM3c6KPW/KZ.c6KZ[4]ffZ `BMRZ'OQc
K S}OP_#Z d/K&RZ.b1KPXXKcbrX]ff^ &sN.Z.c6KPX[a6K
_#MMN'^W.[RT]ffZ[a._0[6RM=[YXN.K#j b OQ]ffN6XMYK#`*q:KOP_#Z'Z6]#[:_#MMN.^KOQ]ffZ[YK *[M([a._0[,_0XK3RZ.OQ]ffZ.MRoMY[YKZ[\q4RT[a
&`:_#Z.c q+KOP_#Z'Z6]#[_#MMN'^m
K R[MYKUTbj fi b1]#X^&N.U_ & q4RoUU\d/KhOQ]ffZ.MRoc6KPXKc _#MeRZ'c6KPW/KZ.c6KZ[brX]ff^
S0_0XR_0d'UT
K >RTb=_#Z.c]ffZ.UVRTb\RT[3RMd/]#[aRoZ.c6KPW/KZ.c6KZ[4brX]ff
^ >_#Z.c RZ.c6KPW/KZ.c.KZ[brX]ff^ %: >9
j N'_#UUTV#`
q:K3OP_#ZhRoZ[YKPXW'XKP[+d/]#[abr]#X^eM:]#b9c6KPW/KZ.c.KZ.OQK_#M,_0d/]ffN6[Z.KMM:XKU_0[RT]ffZ.Mqa6K+
Z & RoM+c6KPW/KZ.c.KZ[:]ffZ
_eUR[YKPX_#WU `'RT[,[YKUUM(]ffZ.KMY]ff^KP[a.RoZ6fe_0d/]ffN6/[ `'_#Z.chq4a.KB
Z & RMc6KPW/KZ.c.KZ[,]ffZ_eS;_0XRo_0d'UT6
K >`'R[,[YKUUM
MY]ff^KP[a'RZ6fe_0d/]ffN6T[ >]#X_0d/]ffN6[%: >j




$ U

BH lmk 9 {z ; ; z3{MLq <\q{4L#q{ ; q
a6K2K_#MRKMY[?q:_ V[Y]c6K Z6K2c6KPW/KZ.c6KZ.OQK2d/KP[q:KPKZ_br]#X^&N.U_T&s_#Z.cL_hURT[YKPX_#UY:RM3dV_#MMN'^eRZ6f
[a._0[ &`q4a6KZ W'N6[?RZ[Yk
] 4O4:`OQ]ffZ[_#RZ.Mj EK^RZ.c.RZ.f[a._0[( 3 *P &RM3[a6KeMYKP[?]#b(URT[YKPX _#UM[a._0[
]*OPOPN6X4RZ[a6
K 4?4 ]#b &3`.[a.RM,OP_#ZdiK3br]#X^e_#UUVK*W.XKMMYKcdV[a6Kbr]ffUUT] q4RZ6fc6K Z'RT[RT]ffZC

[w !0x7

1/2
k " {z ; ; z3$Uy&%9'{MLqff<q{4Lq{ ; q(' uv & P uhNM!0wx /*TN
q!m{uw{ #
yrvuPw%0 ![+(* 1:0z"tff(I/=PuPv ![+(R
& yo}Q0ymthv ! P u?MYV*Z[_#OQ[ROP_#UUTV @9RT[%c6KPW/KZ.c6KZ[ !0z NJIwu - MVZ[_#OQ[ROP_#UUTV @9RT[%RZ.c.KPWiKZ'c6KZ[
w !02
x Key 0z"T
!0z' 4y /*)m( 3 *Q &4 JwYuQ - )k
4 ( 3 P* & K
\^],+

fif.w~3}33f$3ws

& yo&Q0ymtv ! PuMYV*Z[_#OQ[ROP_#UoUTV @9RT[%c6KPW/KZ.c6KZ[ 0! z_( 0z"t'!0z. 4hy vr~*uPwYuey1 ) ( / P~
vr~*#v.& y1 4;z"vIvy00r 4 yv5O%tu -6uQzituQz'v !0z ,vr~*uPw |y1Pu 1 & yoQ0ymtv ! PuMVZ[_#OQ[ROP_#UUTV
9@ RT[%RZ.c.KPWiKZ'c6KZ[ w 0! x2(



6 X]ff^ [a'RM+c.K Z.RT[RT]ffZRT[\br]ffUUT] q4M:R^e^Kc.Ro_0[YKUTV2[a._0[ & RM+MYV*Z[_#OQ[ROP_#UoUTV @R[%RZ.c6KPW/KZ.c6KZ[brX]ff^
( RTb?_#Z.c ]ffZ'UTV RTb3( 3 *P &6fiK( ! j aN.MP`,RZ ]#Xc6KPX[Y] c.KP[YKPX^eRZ6Kq4a6KP[a6KPX_br]#X^&N.U_ & RM
MYV*Z[_#OQ[RoOP_#UUTV%@9RT[%c6KPW/KZ.c6KZ[(]ffZh_MYKP[/( ]#b8URT[YKPX_#UoMP`R[(MN6OQKM,[Y]eO a6KOq4a6KP[a.KPX,[a6KPXK3K*RoMY[M_
URT[YKPX _#UBRm
Z ( [a._0[4]OPOPN6X MRZ[a6
K 4O4 ]#b &j




! :,YF/#P ~*uNON?P ![
y1 :,THG: P vr~6uQwu5M!0wYu 1
y1& 04 z'vIvy0#1 4
z3v <q 7 u v 0zit P
yv5OYtuR-6uPz"tuPz'v !0z 3P !#vr~
:,0z"t :YP 1\|8~yrTu}yv+yo3I40z'vIQvy00r 4 ry v5Oy1zituR-6uPz"tuPz'v=w !0x
fiM[a.RoMK *_#^W"UTKRUUN'MY[YX_0[YKMP`3_ W.X]#W/]ffMR[RT]ffZ._#Ub1]#X ^}N.Uo_ OP_#Z K_#MRUTV d/KMYV*Z[_#OQ[ROP_#UoUTV @9RT[%
RZ.c.KPWiKZ'c6KZ[&brX]ff^ _UR[YKPX_#U(q4a.RUKMYV*Z[_#OQ[ROP_#UUTV @R[%c6KPW/KZ.c6KZ[&]ffZ RT[MeZ6KPfff_0[RT]ffZ j a.RoM&RoMe_#M
K*WiKOQ[YKc `*MRZ.OQK & ^e_VR^W'UTVc RZMY]ff^K3OQ]ffZ[YK*[P`6q4a.RoUTKRT[+^_Ved/K_#Uq:_ VM:R^W/]ffMMRd'UTK([Y]&c.KPXRTS#K
Y: j(pZ]#[a6KPXq+]#Xc'MP`'[a6K&MYKP[4]#b=UoRT[YKPX_#U.M & RM4MVZ[_#OQ[ROP_#UUTT
V @9RT[%RZ.c6KPW/KZ.c.KZ[(brX]ff^ RMZ6]#[OPU]ffMYKc
N.Z.c.KPX+Z6KPfff_0[RT]ffZ jpZ[YKPXKMY[RZ.fffUTV#`6_}Z6]#[R]ffZ]#bMVZ[_#OQ[ROP_#U/br]#X^}N'U_;IS;_0X R_0d'UTK4RoZ.c6KPW/KZ.c6KZ.OQKOP_#Zd/K
c6K Z.Kcb1X]ff^ [a6K^]#XK?d"_#MRO?Z6]#[RT]ffZ]#bMYV*Z[_#OQ[ROP_#U @BRoZ.c6KPW/KZ.c6KZ.OQK#j
q!m{uw{ 7 " {z ; ; z3$ %9'{4#
L qff<q{ML q{ ; q(' uPv & PuM!0w xN/*TVw[!0xQ
3
% 1Y<
;#w ymQPQuN![+
fffiE1:0z"t U /PQPuv1![+
fffi
& y1P0yte v ! Pu(MVZ[_#OQ[ROP_#UUTVNS=_0XYc.KPWiKZ'c6KZ[ !0z < JIwu - (MYV*Z[_#OQ[ROP_#UoUTVNS=_0XYRZ.c6KPW/KZ.c.KZ[
w !0x <QKey #z"T
!0z. 4y T< )'U . & JwYuQ - T< )B
4 U, 6 &4 K
& yo}Q0ymt v !'PuMYVZ[_#OQ[ROP_#UUV S=_0XYc6KPW/KZ.c6KZ[ !0z U 0z"tB!#z. 4hy 2vr~*uQwuyoh;#w ymQPQu<
yr+
z U ov &yo
.0w O%tRu -6uPz"tuQz"v !0zyrv>1=y u I1y 0z"L
!0z. 4ey YU. & fi U ! 4 ,vr~*uPw |y1Pu 1 &
y1?Q#yt v ! PuMYV*Z[_#OQ[ROP_#UUTL
V S=_0XYRZ.c.KPWiKZ'c6KZ1[ w !0x U,



& ! D/ :-SQ &yoI40z'vI vy5 01 4 '0wIOYtu -6uQz"tuQz'v !0z L
0z"t%!0zbS#z"t 40z'vIMO
z3v < q H uv"
vy0 0r 4 .0w yrz"tu -6uQzituQz'vw 0! x V




V*Z[_#OQ[ROP_#U+ RZ.c6KPW/KZ.c.KZ.OQKeOP_#Zd/KK_#MRoUTV KW.XKMMYKc_#M}MYV*Z[_#OQ[ROP_#U: @BRZ'c6KPW/KZ.c6KZ.OQKC
& RM,MYV*Z[_#OQ[ROP_#UUTVLS=_0XYRZ.c.KPWiKZ'c6KZ[(brX]ff^:U RTb9_#Z.c]ffZ'UTVRTbRT[,RM,MYV*Z[_#OQ[RoOP_#UUTV%@9RT[%RZ.c.KPWiKZ'c6KZ[
brX]ff^:U . #):%> A> )BU +ffj1?(UTK_0X UTVeKZ6]ffN6fffa `d/]#[ahMYV*Z[_#OQ[ROP_#U br]#X^&N.U_;URT[YKPX _#U"RZ'c6KPW/KZ.c6KZ.OQK3_#Z.c
MYV*Z[_#OQ[RoOP_#U br]#X^}N'U_;IS;_0X R_0d'UTK?RZ.c.KPWiKZ'c6KZ.OQK3OP_#Zd/K?Oa6KO#KcRoZhURZ6K_0X,[R^eK#j
] q:KPS#KPX`[a.KMYK,d'_#MRO+br]#X^eM]#b"RZ'c6KPW/KZ.c6KZ.OQK\MN iKPX8brX]ff^[q:]R^W/]#X[_#Z[8c6X_q4d'_#O*MPj8RXMY[P`
[a6KPV c6] Z6]#[M_0[RMYbrV [a.KW.XRZ'OPRTW'UTK]#b2RXXKUTKPS0_#Z.OQKL]#b2MYVZ[_ C [q:] KW"N.RTS0_#UTKZ[hb1]#X ^}N.Uo_#M_0XK
Z6]#[e_#UTq(_V*MeMYV*Z[_#OQ[ROP_#UUTV RZ.c6KPW/KZ.c6KZ[brX]ff^ [a6KhM_#^eKURT[YKPX_#UM H S;_0XRo_0d'UTKMPj KOQ]ffZ'cB`+MYV*Z[_#OQ[R
OP_#UBc6KPW/KZ.c6KZ'OQK3c.]KM,Z6]#[_#Uq:_ VMOP_0W'[N6XK3[a6KRZ[N.RT[RTS#K3^K_#Z.RoZ6f2]#bc6KPW/KZ.c.KZ.OQK C8b1]#XRZ'MY[_#Z.OQK#`
& ! ,/ X
: S6/ c
H SPY3RoMMVZ[_#OQ[ROP_#UUTV @R[%c6KPW/KZ.c6KZ[]ffZ "` X: &` 9MRZ.OQKX: S}OP_#ZLd/K2c.KPXRTS#Kc
brX]ff^ &` &RM?_0d/]ffN6[X: S&RZLM]ff^KMYKZ.MK#j ?:]ffZ[YX_#MY[RZ6fffUV#`[a6KPXKRM?Z6]q(_V [Y]c6KPX RTS#
K S}b1X]ff^ &`
N.Z.UKMM(W.X]*c.N.OPRZ.f&_#ZRoZ.OQ]ffZ.MRM[YKZ.OQV#j
_#Z.c.URoZ6f&MN.Oah_MYKPW"_0X_0[RT]ffZXWK "N.RTXKM(_^]#XKX]#d'N.MY[,Z6]#[RT]ffZ]#bRZ.c6KPW/KZ.c.KZ.OQK#`[Y]d/K?RZ[YX]0
c.N.OQKcRZ[a6K?br]ffUUT] qRZ6fMYKOQ[RT]ffZBj
\^]^]

fi

~33



s~$w

~ww$

BH l87:9 qvxz3{ ; zw&{4L#qff<q{MLq{ ; q
JLKZ6] q fffRTS#K_PuQxe0z"vy5 06c6K Z.RT[R]ffZe]#b9RoZ.c6KPW/KZ.c6KZ.OQK#`q4a.RoOac6]KM,Z.]#[(MN iKPX(brX]ff^ [a6K?_0br]#XKQ
^KZ[RT]ffZ6Kc c.X_qd"_#O*MP`:RIjK#jT`+_c6K Z.RT[RT]ffZ [a._0[ec6]KMeZ6]#[ec.KPWiKZ'c ]ffZ [a6KMYV*Z[_#OQ[RoOP_#Ubr]#X^ RZ
q4a.RoOa br]#X^}N'U_#M2_0XKK *W.XKMMYKc j JLKqRUU+W.X] S#K[a._0[[a.RMMYK^_#Z[ROP_#U4c6K Z.RT[R]ffZ]#b3RZ.c6KPW/KZ*
c6KZ.OQKc.]KMeZ.]#[eMN /KPXb1X]ff^ [a6KMYKOQ]ffZ.c c.X_qd"_#O ]#bMVZ[_ RoZ.c6KPW/KZ.c6KZ.OQK#`+RmjK#jT`+_Lbr]#X^&N.U_
[a._0[RM,MYK^e_#Z[ROP_#UUTVhc6KPW/KZ.c.KZ[,]ffZ_eURT[YKPX_#UB_#Uq:_ VMKZ._0d'UTKM]ffZ6K[Y]c.KPXRTS#K?[a6KUoRT[YKPX_#U RZMY]ff^K
OQ]ffZ[YK [Pj
v & Pu M!0wN
x /T [w !#x
3
% 81 )
q!m{uw{ H " " qvxz3{ ; z3 ' $Uy&%9'{MLq <\q{4L#q{ ; q' u
(R 1(0z"fft ( /=PuP1v ! +(R
!0z' 4hy vr~*uQwu,u 2#y1vre
& yo&Q0ymt v !'Pu @RT[%RZ'c6KPW/KZ.c6KZ[ - [w !0x 14tuPz !#vut 4 &1,y 2#z"B
M!0wN
x /T
ov
& #z"t
yoI 40z'vI v5y 01 4 y5v Oyrz"tu -6uQzituQz'v w !0x ,vr~*uPw |y1Pu 1 & y1
P0ymt v !+P.u @9RT[%c6KPW/KZ.c6KZ[ !0)
z 1=tuQz !#vuc
&5 ~*uPu1v ![0rByrvuPw%0
![/( / P~vr~*#v
&y1tuQz !ffvuB
PM4
ffr ( 3 *Q &
( 4 &1By (0zit !0z. 4?y %(fi68 ( 3 *P & !
& yo+Q0ymt v ! P u @9RT[%RZ.c6KPW/KZ.c.KZ[ w !0x (F19tuQz !ffvu/
,vr~6uQw|you$1 & y1P0ymt v !+P u @RT[%c.KPWiKZ'c6KZ[ !0m
z ( 1+tuPz !#vut ( &5

*Ro^W'UTV}XKPqXRT[RoZ6f?[a6Kc.K Z.RT[RT]ffZ `ff& RM1@RT[%RoZ.c6KPW/KZ.c6KZ[b1X]ff^!( RTbB_#Z.ce]ffZ'UTVRTb/[a6KPXK4K6RMY[M:_
br]#X^}N'U_
LMj[Pj
&_#Z.c
LRM9MYVZ[_#OQ[ROP_#UUV@9RT[%RZ.c.KPWiKZ'c6KZ[/brX]ff^ (4j4aN.M`; @BRoZ.c6KPW/KZ.c6KZ.OQK
RM9Z6]#[_ /KOQ[YKc}dV?[a6K:MYVZ[_#OQ[RO\b1]#X^ RZ?q4a'ROa}_br]#X^}N'U_,RM K*W.XKMMYKcB`;[a._0[9RM` XKPW"U_#OPRZ6f.&Lq4RT[a
_#ZVh]#b=RT[MWK "N.RTS0_#UTKZ[b1]#X ^}N.Uo_#M4c6]KM4Z6]#[^]*c.RTbrV[a6K}XKU_0[RT]ffZ .
j *RZ.OQK & RM @9RT[%RZ.c.KPWiKZ'c6KZ[
brX]ff^ ( RTb_#Z.c]ffZ.UVRTb & OP_#Zd/K3^e_#c6K?MYV*Z[_#OQ[ROP_#UoUT%
V @9RT[%RZ.c6KPW/KZ.c.KZ[=brX]ff^ ( qa.RUTKW'XKMYKPXS*RZ6f
UT]#fffROP_#U=WK "N.RS;_#UTKZ'OQK#`9RT[br]ffUUT] q4M?[a._0[}MYVZ[_#OQ[ROP_#U @RT[%RoZ.c6KPW/KZ.c6KZ.OQK2R^W"URTK
@RT[%RoZ.c6KPW/KZ.c6KZ.OQK#`
d'N6[,[a.KOQ]ffZS#KPXMK}c6]KMZ6]#[4a.]ffUchRZ[a6K?f#KZ6KPX _#UOP_#MYK#j
& ! /G:XS6/ H]SPYu~00u
ffr( 3 *P & ! # % :-S&+]N !#vuvr~#vY& y1
z3v <q uv
! / :XSP 1=y1z 8
| ~y0Q~ St! u}z!#v(I--6u0w
yv5Oy1z"tuR-6uPz"tuQz"vw !0x S%P u3 D/Pu&yv=y1&u W/*y100TuPz'v:v !

-G;! yrvyr0uP 4
fiMRoZh[a6K2OP_#MYK]#b=MYV*Z[_#OQ[ROP_#U8RZ.c6KPW/KZ.c6KZ'OQK#`6q+K2OP_#Zbr]#X^e_#UoRTgPK[a6K}br_#OQ[[a._0[_b1]#X ^}N.Uo_%&
.a _#M8MY]ff^K:K /KOQ[M8]ffZ}[a.K+[YXN.[aS0_#UN6K+]#b'_4S0_0XR_0d"UTKR<"jp%Z.c6KPKc ` q:K,c6K Z6K:_Z6]#[R]ffZ]#b9MK^e_#Z[RoOP_#U1
br]#X^}N'U_;IS;_0X R_0d'UTKRZ.c.KPWiKZ'c6KZ.OQK#`q4a'ROaOP_#Z}_#UMY]d/KK_#MRoUTVc.K Z6Kc?brX]ff^ [a.KMYK^e_#Z[ROP_#U1/Z.]#[RT]ffZ
]#b @BRZ.c.KPWiKZ'c6KZ.OQK#j

!

" " qvxz3{ ; z3 ' $ '{MLqff<q{4Lq{ ; q(' u vG& P ,u !0wxN/* w !0x
3
1< )

q m{uw{


fiE1+#z"t

U I/=PuPv ![+
fi

& yoQ#ytv !%P u S=_0XYRoZ.c6KPW/KZ.c6KZ[ w !0x < 1+tuQz #! vut< 4 , &18y 0z"tL!0z. 4ey vr~*uPwYu2u,2#y1vr

M!0wxN/T
1v
&0z"t
sy14I40z'vIQvy00r 4 .0w Oyrz"tu -6. uQz"tuQz'v= w !0x < ,vr~6uQw|you$1&sy1
P0ymtv !'P u =S _0XYc6KPW/KZ.c6KZ[%!0z_<1tuPz!#vut< ,. 5
& utuQz!ffvuLPM4
ffU. &2vr~6u2uPv
!}
0r ;0wymQQP u+< /Q ~hvr~#v%< , &fi



.

fiffy{z ~u zY}y?yp~ ff{ fifx8u'x||Mz}u u zY}y/}su*ffD { }| yz}T%ytfff~iuluff~uffu*u| }|z}yp
ffyx ff"!ff?y}suz&x8yz ~ifff~iuluff~uffuY:#lu% $puff6{&u / ffU}|%&+~iu' | &ffO}su%z}u :y#}suYlu zo
Q)((

fif.w~3}33f$3ws

y1LQ0ymt v ! Pu S=_0XRZ.c6KPW/KZ.c6KZ[ w[!#x U 1tuPz!#vut6U 4 , &1y 0zit(!0z. 4 'U fi
U . &ff! ,vr~*uPw |y1Pu 1 & yo?P0ytv !TPu.S=_0Xc6KPW/KZ.c6KZ[ . !0z U 1+tuQz !#vut U ,. &5
?(UK_0XUTV#`& RM S=_0XYRoZ.c6KPW/KZ.c6KZ[(b1X]ff^ U RTb_#Z.ch]ffZ.UVRTb9[a6KPXK?K6RMY[M_br]#X^&N.U_
MPj[Pj
&
_#Z.c
RMMYV*Z[_#OQ[RoOP_#UUTV S=_0XYRZ'c6KPW/KZ.c6KZ[eb1X]ff^ Uj$]#XKP] S#KPX`.S=_0XYRZ.c.KPWiKZ'c6KZ.OQKRM[Y]X@9RT[%
RZ.c.KPWiKZ'c6KZ.OQK,_#M\MYV*Z[_#OQ[ROP_#=U S=_0XRZ.c6KPW/KZ.c6KZ'OQK(RoM[Y]}MYV*Z[_#OQ[ROP_#U @9RT[%RZ.c.KPWiKZ'c6KZ.OQK#ffRZ.c.KPKcB` &
RM S=_0XYRoZ.c6KPW/KZ.c6KZ[,b1X]ff:
^ U Rb9_#Z.ch]ffZ'UTVRb & RM @9RT[%RZ.c.KPWiKZ'c6KZ[:brX]ffQ
^ (*$,j
v &! Y/G: PE/ Y+ H u~#0u U . & ! # % S>+ N !#vuvr~#Yv & y1
z3v <q uY
.0w Oy1z"tRu -6uPz"tuQz"v w !0x
a.K3c.K Z.RT[RT]ffZ]#b8MYK^e_#Z[ROP_#U @BRoZ.c6KPW/KZ.c6KZ.OQK3RM(d'_#MKc]ffZh[a6KMYKP[]#b8URT[YKPX _#UM:]#b9br]#X^&N.U_#M
KW"N.RTS0_#UTKZ[,[Y+
] &j=p%Z[N.R[RTS#KUTV#`6[a.RM,RoM([a6KK_#MRTKM[q:_ Vh[Y]c6K Z.K_Z6]#[RT]ffZh]#bRZ.c.KPWiKZ'c6KZ.OQK[a._0[
RM}Z6]#[}c6KPW/KZ.c.KZ[]ffZ[a6KMVZ[_ ij4] q+KPS#KPX`\W.X] S*RZ6f[a6KP]#XK^eM&c.RTXKOQ[UVbrX]ff^ [a.RMc6K Z.RT[RT]ffZ
RM}Z6]#[}MY]K_#MYV#j.]#X&RZ'MY[_#Z.OQK#`8q+Kq4RUU8W'X] S#K[a._0[}c.KP[YKPX^eRZ.RoZ6fhq4a6KP[a6KPX&_br]#X^&N.U_ & RM @9RT[%
c6KPW/KZ.c6KZ[]ffZ URT[YKPX_#RU RMRoZ `d'N6[[a.RMXKMN.UT[OP_#Z'Z6]#[}d/Kt#y1w3u v 4W.X] S#Kc brX]ff=
^ K Z'RT[RT]ffZ
] &OP_#Z.Z6]#[d/Kc6]ffZ6Kq4RT[aL_hW/]ffUTV*Z6]ff^eR_#U
`9MRZ.OQKeOa.KO*RZ6f_#UU=Wi]ffMMRTd'UTK&br]#X^}N'U_#M3WK "N'RTS;_#UKZ[?[Y'
Z6]ffZ*c.KP[YKPX^eRZ.RoMY[RO=fffN.KMMRZ6f6jJLKfffRTS#KZ6] q _MK^e_#Z[RoOP_#U6Oa._0X_#OQ[YKPX RTg_0[RT]ffZ]#b" @BRZ'c6KPW/KZ.c6KZ.OQK#j
ru=<uwuw{
x /* &yo yr5v Oy1zitRu -6uPz"tuPz'=v w !0x yvuQwY0r ,y 0z"+
!0z' 4y 1 !#w}0z 4y1z'vuPIw
k !0wN
-"wuPvI#v0y !0z = )_[T 1=y =.A ! & vr~6uQz &')l V >= %
: IFA ! &5
fiM2_c'RTXKOQ[}OQ]#X]ffUU_0XV#`q:Kf#KP[&[a'_0[ & RM @R[%RZ.c6KPW/KZ.c6KZ[?brX]ff^ (RTb_#Z.c ]ffZ.UTVRTb,br]#X_#ZV
URT[YKPX _#WU ) ( _#Z.c_#ZVhRZ[YKPXW.XKP[_0[RT]ffZ= )_[Ti`'RTb4=;A ! & [a6KZ &'"l V>= % X: mDA ! &j
a'RM=W.X]#WiKPX[VfffRTS#KM,_#ZRc6K_]#ba6] q @ c6KPW/KZ.c6KZ.OQKq+]#X*MPjp%Z.c6KPKcB`*RTb & RM @RT[%c6KPW/KZ.c.KZ[
]ffZh_2URT[YKPX_#8U `*[a6KZ[a6KPXK3K *RoMY[M(_#ZhRZ[YKPXW.XKP[_0[RT]ffZ
= MN.Oa[a._0[ =;A ! & _#Z'c
&'"l V>= % X: A4! &`
q4a.RoOa^K_#Z.M([a._0[_6=;A ! 9_#Z.cLrdi\[a6K?UR[YKPX_#tU 9RZ
= Rc
J%XK_#UUTVZ6KPKc6KMc L&[Y]e^e_0#K = _2^]*c6KU
]#b &`6[a._0[4RoMP`*[a6KW'_0X[Ro_#UBRZ[YKPXW.XKP[_0[RT]ffZh]#d'[_#RZ6KchdVXK^] S*RZ6f 8RZ= c.]KMZ.]#[M_0[RMYbrT
V &3j
a'RMW.X]#W/KPX[V_#UMY]K *W'U_#RoZ.Mq4aVe @Bc6KPW/KZ.c6KZ'OQKb1]#X ^e_#URTgPKM\[a6KOQ]ffZ.OQKPW'[+]#/b J%[YXN.KRZMY]ff^K
OQ]ffZ[YK [ L*`_#MK *W'U_#RoZ6Kc_0[3[a6K2d/KPfffRZ.Z.RoZ6f]#b\[a.RoMMYKOQ[R]ffZBj3pZ.c.KPKcB` & R
@9RT[%c6KPW/KZ.c6KZ[4]ff]
Z \Rb
_#Z.c]ffZ.UTVhRTb8[a6KPXK2RM4M]ff^K}OQ]ffZ[YK [eOQ]ffZ.MRMY[YKZ[4q4RT[a &`"_#Z'c[a._0[c6]KMZ6]#[R^W'Ub
V `/RZhq4a.RoOa
& Ro^W'URTKT
j(a.RM4OP_#Zd/KW.X] S#KcbrX]ff^ [a6K}_0d/] S#K&W.X]#W/]ffMR[RT]ffZ C=RTb = RM4_#ZRZ[YKPXW.XKP[_0[R]ffZMN.O
[a._0[F=;A ! & d'N6[F&')l V>= % Y: A4! &`6[a6KZh[a6K[YKPXT
^ C
1 ! #D> )k
fiOA%=;A ! & b
/ > + . #)%: > > )k
fi e =;A ! & / %: >*+; #i +
RM=OQ]ffZ'MRMY[YKZ[=q4RT[L
& rdV2OQ]ffZ'MY[YXN.OQ[RT]ffZ ` 1hRMWK "N.RTS0_#UTKZ[[Y]}[a6K4c.RoM FYN'Z.OQ[RT]ffZ2]#bB_?[YKPX^ WK "N.RS;_#UTKZ[
[Y]= q4R[a_}[YKPX^ WK "N.RS;_#UTKZ[\[Y] &')l V>= % Y: IY .RT[:_#UMY]2a6]ffUc.M\[a._0R[ 1/ & ! `q4a.RUT/K 1 A4! `[a._0[
RMPB` 1 RM_OQ]ffZ[YK [RZhq4a'ROB
& Ro^W'URTK'M j
]#XKP] S#KPX
` =X]#Wi]ffMRT[RT]ffZ 2Ma.] q4M[a._0[3]ffN6X?Z6]#[RT]ffZ]#b @9RT[%RZ.c.KPWiKZ'c6KZ.OQKOQ]ffRZ'OPRc6KMq4RT[a[a6K
Z6]#[RT]ffZ]#b J0z'vy K x !0z !# v !#z.5y yr5v 4?5 EVff_#Z G` #G 0 ` # ff j=9]d/K\^]#XK+W.XKOPRMK#`;_OQ]ffZ'MRMY[YKZ[ Bbr]#X^&N.U_
RM M_#Rc[Y]diK+^]ffZ6]#[Y]ffZ.ROrXKMYW j_#Z[R^e]ffZ6]#[Y]ffZ.RO RZ?S0_0XR_0d'UTRK <RTb*_#Z.c]ffZ.UTV?RTb*RT[RM @9RT[%RZ.c.KPWiKZ'c6KZ[
brX]ff^ Y: < rXKMYW j b1X]ff^ <6 j p%Z[YKPXKMY[RZ6fffUTV#`_ MN.d/OPUo_#MMROP_#U 0 RoZ6b1KPXKZ.OQKXKUo_0[RT]ffZB`OP_#UUTKc z"#5v /*wY0
yrWz PuPwYuPz uP`4a._#Md/KPKZ c.K Z6Kc ]ffZ [a'RMef#X]ffN'Z.cs5 E4Vff_#ZB` #G 0` # ff
j A(_#MRoOP_#UUTV#`4_ b1]#X ^}N.Uo#
_ $
RMeOQ]ffZ'MRc6KPXKc _#M_ OQ]ffZ.MYWK "N6KZ.OQK]#b_b1]#X ^}N.Uo_ & RTb?_#Z.c ]ffZ'UTV RTbR[RM_UT]#fffROP_#U4OQ]ffZ'MYWK "N.KZ.OQK
&


iorqtsf&*z}u:z} }y ff3y #|{|BuffU {|TuffUfiff *o

Q)(

fi

~33



s~$w

~ww$

]#b}R[P`_#Z.c & @RT[%RoZ.c6KPW/KZ.c6KZ.OQK]#b}_ URT[YKPX _#UR^eW'URTKMRT[M $@9RT[%RZ.c6KPW/KZ.c.KZ.OQK#j fiOPOQ]#Xc.RoZ6fffUTV#`
Z._0[N6X _#URZ6brKPXKZ.OQKW.XKPS#KZ[MN.M4b1X]ff^ OQ]ffZ.MRc6KPXRZ.f He_#M_OQ]ffZ'MYKW"N.KZ.OQK]#b RT[RoM_XKUTKPS;_#Z[
R^W"UROP_0[RT]ffZ" j fiUoU*]ffN6X+O a._0X_#OQ[YKPXRTg_0[R]ffZXKMN.UT[M=_0d/]ffN6[ @9RT[%RZ.c6KPW/KZ.c.KZ.OQK#`ffRZ.OPUN'c.RZ6fOQ]ff^W'UTK6RT[V
XKMN'UT[MP`+a'_S#K_#Z R^e^Kc.Ro_0[YKRo^W'_#OQ[]ffZ MN'Oa _Z'_0[N6X_#URZ.b1KPXKZ'OQKXKU_0[RT]ffZ rKMYW/KOPR_#UoUTV#`\[a6KPV
c.RTXKOQ[UTVMa.] q [a._0[4[a6KOQ]ff^W'UK *RT[V]#bZ._0[N.X_#UBRZ6brKPXKZ.OQKRM,RoZ - j
\X]#W/]ffMRT[RT]ffZ ?RMK_#MRUTVK [YKZ.c.Kc[Y]ebr]#X^&N.U_;IS0_0XR_0d'UTK3RZ.c.KPWiKZ'c6KZ.OQK C

J

k
yrz'vuQw -"wuPvI#vy00! z

M!0wx */




& y1 '0wIOyrz"tuR-.uQz"tuPz'v w !0x ; 0wymQPQu< 0zit !0z. 4Ly 1 !0wh0z4
1=|+u~00u=;A ! &
0z"tT#! z. 4y ?fi 3 *V >= % <*A ! &5

= ) [/
a.Kbr]ffUUT] qRZ6fe^KP[_0[a6KP]#XKP[RO&W.X]#W/KPX[RTKM4]#b= @ RZ.c6KPW/KZ.c.KZ.OQK_0XK2N.MYKcRoZ[a6K}XKMY[]#b[a.RM
MYKOQ[RT]ffZ j
uwruz$r

ru=
< uwuw{ 7
JK
ffr( 3 *P &59( 3 *P &
JW
K &
1\vr~6uQz
ffr( 3 *Q &/!
ffr( 3 *P

J ,
K r( 3 *Q & /
' r( 3 *P & . r( 3 *Q
4
J ffP
K r( 3 *Q & H
' r( 3 *P & . r( 3 *P

Jff

K )-
ffr( 3 *P
&
#z"tT0! z. 4y :Y ) r( 3 *Q : &










SRZ.c6KPW/KZ.c6KZ'OQKK6a.RTd'RT[M4MR^eRUo_0X4W.X]#W/KPX[RKMP`'W'UoN.MZ6KPfff_0[RT]ffZLM[_0d'RURT[VrWi]ffRoZ[2 <d/KUT] q `
q4a.RoOahRMZ.]#[M_0[RM KcdV @BRZ.c.KPWiKZ'c6KZ.OQK#j


ru=
< uwuw{ H
JK
ffU . &5 U 6 &4
JW
K &
1\vr~6uQz
ffU. &/!.U .

J ,
K
U . & /
' r( 3 *Q &4 .
ffr( 3 *Q

J ffP
K
U . & H
' r( 3 *Q &4 .
ffr( 3 *Q

Jff

K
ff
U . :
& /!.U . &








A:KPV#]ffZ.c [a6KMYKW.X]#W/KPX[RTKMP`( @BRZ'c6KPW/KZ.c6KZ.OQK_#Z.c S4RZ'c6KPW/KZ.c6KZ.OQKc6] Z6]#[K6a.RTd"RT[e_#ZV
W'_0X[RoOPN.U_0XUTV RZ[YKPXKMY[RZ6fM[YXN.OQ[N6XK#j pZ W'_0X[ROPN.Uo_0X`: @ RZ.c6KPW/KZ.c6KZ'OQK_#Z'c S4RZ'c6KPW/KZ.c6KZ.OQK
Z6KRT[a.KPX_0XK+^e]ffZ6]#[Y]ffZ.RO=Z.]#X9_#Z[R ^]ffZ6]#[Y]ffZ.RoO=qjXj[Pj9K W"_#Z.MRT]ffZ?]#b& MY[YXKZ6f#[a.KZ.RZ6f,]#X9q+K_0#KZ.RoZ6f
& OP_#ZK_#MRUTV^e_0#K}RT[,Z6]UT]ffZ6f#KPX4RZ'c6KPW/KZ.c6KZ[+brX]ff^ _MYKP[4]#b8UoRT[YKPX_#UM(]#XS0_0XR_0d"UTKM j
4E KOP_#UU[a'_0[%(
& Rb._#Z.c]ffZ'UTV?RTbM(fi6r( 3 *Q 4
& ! 4 ja.RM ^eK_#Z.M[a._0[9[a.K1@ R[%c6KPW/KZ.c6KZ.OQK
]#b & ]ffZm( ]ffZ.UTVR^eW'URTKM\[a6KV@ RT[%c6KPW/KZ.c.KZ.OQK]ffZh_UoRT[YKPX_#U"]#b(`.Z.]#[(_GJ%bN.UU L @ R[%c6KPW/KZ.c6KZ.OQK]ffZ
_#ZVURT[YKPX_#U]#b(4j9p%Z]#[a.KPXq:]#Xc.M`ffRTb*q+K(q(_#Z[8[Y]3Oa6KO}q4a.KP[a6KPX_br]#X^&N.U_
& RM @ RT[%c.KPWiKZ'c6KZ[9]ffZ
0z3
4 URT[YKPX _#U.]#b&(4`q:K?Z6KPKc_2Z6]#[R]ffZMY[YX]ffZ6f#KPX([a._#Z @ c6KPW/KZ.c6KZ.OQK#`6OP_#UUTKcbN.UU. B@ c.KPWiKZ'c6KZ.OQK#j
a6KM_#^KOP_#Zhd/KM_#Rcbr]#X c6KPW/KZ.c6KZ.OQK#j

" >#'$Uy fi $ % L q <q{4L#q{ ; q' uPv & Pu !#w xN/* 1w[!#x

1( P uI/=PMO
q!m{uw{
Puv ! +(R 0z"t U P u} /PQPuv ![/
fffi
& y1brN.UoUTV @ R[%c6KPW/KZ.c6KZ[ !0zk(sy #z"tT!0z. 4y +(9
ffr( 3 *P &
U. &
& y1brN.UoUTV S=0_ XYc6KPW/KZ.c.KZ[ !0zBU 0z"t+!0z. 4y .U
Q)(*_

fif.w~3}33f$3ws



& ! /F:XS3/?SlHF:XSPY+y1 /*1 4 yv5O%tuR-6uPz"tuQz"v!0z # % :XS>+&#z"t /*1 4 .0w O%tuR-6uPz"tuQz"v
z3v < q "
!0z # % S&+ !0'z vwY;vyrz{# 4)1 & y1z!#vI/*r 4 yv5O%tu -6uQzituQz'v !0z # % S&+

?(UK_0XUTVKZ6]ffN6fffaB`iq4a6KZ.KPS#KPXV& RMbrN.UoUTVL@9RT[%c6KPW/KZ.c6KZ[]ffZ(`/RT[RoM_#UM]bN.UUTVLS=_0XYc6KPW/KZ.c6KZ[
]ffZ U.:(( j 4] q+KPS#KPX `"[a6K}OQ]ffZS#KPXMKc6]KMZ6]#[4a6]ffUocB`6_#M[a6KW'XKPSR]ffN.M:K*_#^W"UTKMa6] q4MPj
J a.RUTKhbN.UU, @ c6KPW/KZ.c6KZ.OQKrXKMW j bN.UU, Sc6KPW/KZ.c6KZ.OQK 2OP_#Z d/KOa6KO#Kc RZ URZ.K_0X[R^K
]ffZ.OQK
ffr ( 3 *P &rXKMYW jO U 6 &4YRMZ6] q4ZB`,_0[[a6KKZ.c ]#b?[a6KMKOQ[RT]ffZ q:KW'X] S#K[a._0[
c6KP[YKPX^RZ.RZ6f[a6KMYKhMYKP[MRM .a._0X cB`=_#Z.c [a._0[c6KOPRc.RoZ6fbN.UU+ @ c6KPW/KZ.c6KZ.OQK _#M2q+KUoU:_#M&bN.UU
S4c.KPWiKZ'c6KZ.OQK (RM 'OQ]ff^W'UTKP[YK#j
@KP[4N.M,Z6] q OQ]ffZ.MRc.KPX,[a6K?W'_0X[ROPN'U_0X,OP_#MYK]#bbrN.UoUi @ c6KPW/KZ.c6KZ.OQK3q4a6Km
Z ( ! ( 3 *Q & `']#X[a6K
bN.UU( S4c6KPW/KZ.c.KZ.OQKq4a6KZ U ! U 6 &4 j pbbrN.UoU:c.KPWiKZ'c6KZ.OQKha6]ffUc.M2RZ [a.KMYKOP_#MYKMP`(q:KM_V
[a._0.[ & RoM @9RT[%MR^eW'UR Kc `ff]#X S=_0XYMRo^W'UR KcB`XKMWiKOQ[RS#KUTV#j S=_0XYMR^eW'UR OP_0[R]ffZRoM:_#O a.RTKPS#Kcq4a6KZ
& OQ]ffZ[_#RZ'MZ6] ]OPOPN.XXKZ.OQK]#b_#ZV S;_0XRo_0d'UTKRT[RM S=_0XRZ.c6KPW/KZ.c6KZ[ebrX]ff^hj @9RT[%MR^W"UR OP_0[RT]ffZ
OQ]#XXKMWi]ffZ'c.M[Y][a6K^]#XKXKM[YXROQ[YKc MRT[N._0[RT]ffZ qa6KPXKh[a6K 4O4]#b & c6]KMeZ6]#[OQ]ffZ[_#RZ _#ZV
]*OPOPN6XXKZ.OQK]#b_eUoRT[YKPX_#UBRT[RM @9RT[%RZ.c.KPWiKZ'c6KZ[:brX]ff^hj
pb'_b1]#X^&N.U
_ & RMZ6]#[ @9RT[%MR^W"UR KcrXKMYWj S=_0XYMR^W'UR Kc" `;[a6KZ[a.KPXK:RoM9MY]ff^eK(UoRT[YKPX_#U"rXKMYW j
S0_0XR_0d'UTK [a._0[\]OPOPN6X MRZ2[a6/K 4O4 ]#b &`ffd'N.[ & RoMZ6]#[ @RT[%c.KPWiKZ'c6KZ[rXKMW j S=_0XYc6KPW/KZ.c6KZ[ 9]ffZ
RT[Pja.RoM\^K_#Z.M+[a._0[([a6KMYVZ[_#OQ[RObr]#X^ RoZeq4a.RoOL
& RM+K W'XKMMYKcOQ]ffZ[_#RoZ.M(_}UR[YKPX_#U.]#X:S;_0X R_0d'UTK
[a._0[4RoM,RZ.c6KPKchN.MKUTKMMPj

!

" 'v

<' !mq L > u3rffvz ' u v & Pu2.M!0w xN/*T w !0x
& y1Y@RT[%MRo^W'UR Kc 0zitL!#z. 4y /( 3 *P &ff!.8( 3 *P &
_0XYMR^W"UR KcLy
0z"tT#! z.
4 .,
U . &/!.U. &
& y1 =

q m{uw{


3
%


fiM[a6Khbr]ffUUT] q4RZ6f K6_#^W'UTKhRUUoN.MY[YX_0[YKMP`\KPS#KPXV b1]#X^&N.U_[a._0[eRoM @RT[%MRo^W'UR Kc_#UMY]RoMNS=_0XY
MR^eW'UR Kcd'N6[([a6K}OQ]ffZS#KPXMK}c6]KMZ6]#[a6]ffUochRZ[a6Kf#KZ6KPX _#U OP_#MYK#j



& ! </ :XS%/2SBH :XSP /2 %HOVY(z/uQyvr~*uQwy1 yv5Oy1x.-"y
:ut&z!#w .0w Oy1x.-"y
:ut ~6u
z3v <q "
u W/*y100TuPz'v!0wxN/* h / :XS</LSXH :XSPY?y1 .0w yrxY-i

:ut PM/6v=yv=y1z!#v yv5Oy1x.-"y
(ut +P\yrz"0r 4)1
vr~*uu M*/ y100uQz'v#! w xN*/ h / :XSPyo P,!#vr~ yv5Oy1x.-"y
:uth0zit .0w Oy1x.-"y
(ut





*Ro^W'UR Kcbr]#X^}N'U_#Mec6]Z6]#[RZ.OQ]#XW/]#X_0[YK_#ZV N.MYKUTKMMUoRT[YKPX_#UM2]#XeS0_0XR_0d"UTKMPj"fiM[a6KZ6K*[
W.X]#W/]ffMR[RT]ffZ2Ma6] qM\RT[P`ff[a.K4Z6]#[RT]ffZ]#bBMRo^W'UR Kcbr]#X^&N.U_?_#OQ[N._#UUV&RM=[a6K,W/]ffRZ[qa6KPXKMYV*Z[_#OQ[RoOP_#U

RZ.c.KPWiKZ'c6KZ.OQK3_#Z.cMYK^e_#Z[ROP_#U1,RZ.c6KPW/KZ.c6KZ'OQKOQ]ffRZ'OPRc6K#j


=<

ru uwuw{



uv &P u}.M!0wx /*T w !0x


3
%



& 1y yrv5O yrx.-"y
:uthy &0zit !0z. 4y 2vr~*u M!0r !0|yrz{ u W/yr;#TuPz u}~G!0 t0 M!0weuQ0uPwI4c(
& y1?I40z'vI vy5 01 4 yv5Oyrz"tu -6uQz"tuQz'v w[!0x (sy &0z"t+!0z. 4y /( 4 &~G!0 t0



& 1y .#wIO yrx.-"

:uthy }0z"t !0z. 4y vr~*u !#1 !0|yrz{u M/*y100uQzu}~ff!0Tt; !0wuQ0uPwI4 U
& y1?I40z'vI vy5 01 4 .0w Oyrz"tu -6uQz"tuQz'v w[!0x U 0z"tT!0z' 4y U 4 , & ff~ !0Tt;



.

( 1

fiE1

aN.MP`Bqa.RUTK&_b1]#X^&N.U_OP_#ZLK_#MRoUTVd/K @RT[%RZ'c6KPW/KZ.c6KZ[4brX]ff^ _hMYKP[?]#b+UR[YKPX_#UMq4RT[a6]ffN.[d/KQ
R Z6fMYV*Z[_#OQ[RoOP_#UUTV @9RT[%RZ.c.KPWiKZ'c6KZ[b1X]ff^ RT[P` MR^W"UR OP_0[RT]ffZRM3_q:_ V[Y] FY]ffRZ @RT[%RoZ.c6KPW/KZ.c6KZ.OQK
q4RT[a R[MeMYV*Z[_#OQ[ROP_#U4XKMY[YXRoOQ[RT]ffZ rq4a.RoOa RMK_#MRTKPXe[Y]f#X_#MW `,_#Z.c _#Meq:Kq4RUoU:MKPKMY]]ffZB`+K_#MRTKPX

Q)(^\

fi

~33



s~$w

~ww$

[Y]hOa6KORoZ[a6K2f#KZ6KPX _#UOP_#MK IC @9RT[%RZ.c6KPW/KZ.c.KZ.OQK_#Z.c MYV*Z[_#OQ[RoOP_#U @RT[%RZ'c6KPW/KZ.c6KZ.OQKOQ]ffRoZ.OPRc6K
]ffZ @9RT[%MR^W"UR Kc b1]#X ^}N.Uo_#MPj a6KM_#^eKa6]ffUc.Mbr]#X S=_0XYRoZ.c6KPW/KZ.c6KZ.OQKL_#Z.c MYVZ[_#OQ[ROP_#U S=_0XY
RZ.c.KPWiKZ'c6KZ.OQK#j
a.KeMY[YXKZ6f#[aL]#b([a6KZ6]#[RT]ffZ ]#b,MR^W"UR OP_0[RT]ffZURTKM?RoZ [a6Keb_#OQ[[a._0[KPS#KPXV br]#X^&N.U_hOP_#Zd/K
MR^eW'UR KcW.XKMYKPXSRZ.fRT[M?^e]c6KUoMPja.RoMRoM?N.MYKPbN.Um`B_#M?MR^W"UR Kcb1]#X^&N.U_#M?OP_#Z d/KMa6]#X[YKPX_#Z.c
K_#MRTKPX4[Y]N.Z.c6KPX MY[_#Z.c[a._#Zhbr]#X^&N.U_#M,OQ]ffZ[_#RZ.RZ.feN.MYKUTKMM4URT[YKPX_#UMj

P!0wuQ0uPwI4

=<



ru uwuw{

&
fi

&w[!0x7


1 vr~*uPwYuu32ffyoQvr yv5Oy1x.-"y
:ut !0wxN/*
ov

*RoZ.OQK @R[%MR^W'UoR Kc5 A(M4_0XK2_#UMY] S=_0XYMR^W"UR KcB`6[a'RMW.X]#Wi]ffMRT[RT]ffZh_#UMY]Ma6] q4M4[a'_0[4KPS#KPXV
OP_#Zd/KV=
_0XYMR^W'UR KcqRT[a6]ffN6[^]*c.RTbrV*RZ6f2RT[M,MYKP[]#b^]*c6KUMPj

%p Z[YKPXKMY[RZ6fffUTV#`di]#[a @ RZ.c6KPW/KZ.c.KZ.OQK&_#Z'c S4RZ'c6KPW/KZ.c6KZ.OQKOP_#ZLd/KeOa'_0X_#OQ[YKPXRTgPKcq4RT[a*
]ffN6[OQ]ffZ'MRc6KPXRoZ6f [a6KOQ]#XXKMWi]ffZ'c.RZ6fLMYV*Z[_#OQ[RoOZ6]#[RT]ffZ.Me]#b3RoZ.c6KPW/KZ.c6KZ.OQK#` FYN'MY[dV OQ]ff^W"_0XRZ6f
br]#X^}N'U_#M(]#d.[_#RZ6KcdVMYKP[Y[RZ6f[a6K?[YXN6[ahS0_#UN6K?]#bUR[YKPX_#UM:q+Kq:_#Z[[Y]O a6KOh[a6K}c6KPW/KZ.c6KZ.OQK#j
uPv& P u? M!0wx /*T w[!#x
vIffvuQxuQz'vr20wYuu M/*yr;0uQz"v
JK 4 &
JWK &5j h ( !
& jh /
J MK &OA ! 5
& jh /
Jff
K 5
& j h ( ! &fi
=<



ru uwuw{




3
0z"t3 P ?u 2yrvuPw%0 ![5( ~*u?ziu32vG!/w





a.K_0d/] S#KhW.X]#W/KPX[RTKM2OP_#Z d/KN.MYKc [Y]Oa.KO q4a6KP[a6KPXe_ br]#X^&N.U_RMN@RT[%c6KPW/KZ.c.KZ[&]ffZ _
URT[YKPX _#Um`6_#M[a6K?br]ffUUT] q4RZ6f2K6_#^W'UTKMa.] q4MPj
/GX: / S/HGX: SPYey1 yrv5Oy1zituR-6uPz"tuPz'v w[!0x yrz uwYu -" QPyrz{ P4
* f
z3v <q &!
|yvr~y1z & {ffy1#uwyouv ! 0z yrzI!0z6 y1vuPz'v M!0wxN/T !0z"vw%;Qvy1z{# 4"1 & y1 yrv5OYtu -6uQz"tuQz'v !#z :XS
yrz u?wuR-"Ty1z{S PM4 :)|yvr~yrzB& {#yr0uQ & h / .1|8~y0Q~y13z !#v+#v\Tu;v(;? !{#y00r 4evw !0z{
;vr~*u}yrz I!0z6 y1vuPz'v !#w xN/* T! PPvI0yrziut PM4wuR-"Ty1z{SLP4* f |yvr~yrz &fi



fi MRo^eRU_0XW.X]#Wi]ffMRT[RT]ffZa6]ffUc'M=br]#X+ 4
RoZ.c6KPW/KZ.c6KZ.OQK#`Oa._0X_#OQ[YKPX RTgRZ6f}[a6K4S0_0XR_0d'UKM\_br]#X^&N.U_
& c6KPW/KZ.c'M+]ffZ `'N.MRZ.f&[a.K?b1]#X^&N.U_#M &'gih / _#Z.cB&'gih ( j
ru=
< uwuw{ uPv & P u M0! wxN/T w[!0x
3
% #z"tb> Pu00wyQPPTu+!
fi ~*uziu,2ffv
M!D/*w?vI#vuPxuQz'vr&#wYueu M/*yr;0uQz'v
J K > 4 ,. &
J WK '& gih / '& gih (
J MK & '& gih /
ffJ
K & '& gih (







fiM\RZe[a6KOP_#MYK]#bBURT[YKPX_#U.c.KPWiKZ'c6KZ.OQK#`ff[a6K_0di] S#KW'X]#W/KPX[V2OP_#Zd/KN.MKce[Y]

_br]#X^&N.U_2RM S=_0XYc.KPWiKZ'c6KZ[,]ffZ_S;_0X R_0d'UTK#j


z3v

/ S8H
<q &"!

Z.c2]ffN6[\qa6KP[a6KPX

:XSPYy1 ' 0wIOyrz"tuR-.uQz"tuPz'v w[!#x!Sy1z u3|+u3~0#uY& h / & h ( .
Q)(+Q

fif.w~3}33f$3ws

p%Z[YKPXKMY[RZ6fffUTV#`& @BRZ.c.KPWiKZ'c6KZ.OQK_#Z.cs S4RoZ.c6KPW/KZ.c6KZ.OQK OP_#ZsdiK c6KP[YKPX^eRoZ6Kc RZs_#ZsKP
OPRTKZ[eq(_V q4a6KZ & RMfffRTS#KZ RZ MY]ff^eKMYW/KOPR OhZ6]#X ^e_#U,br]#X^eMP`(Z._#^KUTV#`:W.XRo^KR^W'UoROP_0[YKhZ6]#XY
^e_#Ubr]#X^ ]#X}W.XR^K2R^W"UROP_#Z[3Z.]#X^e_#U8br]#X^hje6]#X&MN.OaZ6]#X^e_#U8br]#X^eMP`@RT[%RZ'c6KPW/KZ.c6KZ.OQK2_#Z.c
S=_0XYRZ'c6KPW/KZ.c6KZ.OQK?OQ]ff^Kc.] q4Zh[Y][a6KRTX4OQ]#XXKMYW/]ffZ.c.RZ6f2MYV*Z[_#OQ[RoOP_#U br]#X^eMPj
Pu !0wxN/* Nw !0x7
3
% 0z"tm(:P uhI/=PuPvV![ff(R ~*uziu,2ffv
ru=<uwuw{ uPv &
vIffvuQxuQz'vr20wYuu M/*yr;0uQz"v




JK( 4 &
JW
K
fi " &T U# 19AB1 y1vuQwx vr~#v,t! uz!ffv I!0z'vI0yrz0z4
yvuQwY0Qw !0x2( +
J MK

& # 0Ar0y1}L /u}vr~#v,t! uQz!#v ,!0z"vI0y1z#z4yrvuPw%# w[!#x ( +



v & Pu !#w xN/* w !0x
3
% 0z"t U Pu /PQPuv ![ff
fffi ~*uziu,2ffv
ru=<uwuw{ uPY
vIffvuQxuQz'vr20wYuu M/*yr;0uQz"v




JK U 4 , &
JWK
fi " &. U# 19AB1 y1vuQwx vr~#v,t! uz!ffv I!0z'vI0yrz0z4;0wy PQu w !0x U +
J MK

& # 0Ar0y1}L /u}vr~#v,t! uQz!#v ,!0z"vI0y1z#z400w ymQPPTu w !0x U +



z3v <q k uPv& ! 0/D:XS /SHD:XSPY u,~0#u-
" &ff! # /:XSP +&0z"t
&ff!$# % :XS>+
J /*- v ! !{#y00=u W/*y100TuPz u[K u 0z u; yr 4T!QPQPuQw0uvr~#v & yo yrv5Oy1zituR-6uPz"tuPz'v w !0xQS !W! ;y1z{
#v/
" & 'J 0! w
& K u 0z 0 M! u; yr 4 QvI#vuvr~#v.& y1 yrv5OYtuR-.uQz"tuPz'v !0z :XS0z"t '0wIO
yrz"tuR.- uQz"tuPz'v w 0! x VLPM4%,0! z. ymtuQwy1z{0z4+![vr~*uQPu}z!0wxe0ff!0wx&



\X]#W/]ffMRT[RT]ffZ Ma6] qM[a._0[&_ AOP_#Z diKK_#MRUTV S=_0XYMR^eW'UR Kc RmjK#jT`8RZLW/]ffUTV*Z6]ff^eRo_#U8[R^K
#_ MMY]]ffZ_#M[a6KS0_0XR_0d'UKMRT[4RMYS=_0XYRZ.c.KPWiKZ'c6KZ[4b1X]ff^ a._S#K&d/KPKZc6KP[YKPX ^eRZ6KcBj(p%Z.c6KPKcB`'q+K2OP_#Z
K_#MRUV}c6KMRfffZ_?f#XKPKc6V_#UTf#]#XR[a.^b1]#X+MR^W'UoRTb1V*RZ6f A(MPja.RM8_#UTf#]#XR[a.^OQ]ffZ.MRM[M=RZOQ]ffZ.MRoc6KPXRZ6f
KPS#KPXVS;_0XRo_0d'UT
K >L]#b U . &4RZ_MN.OPOQKMMRTS#K2q:_ V#`Bq4a.RUKXKPW'Uo_#OPRZ6+
f & d'
V & gih / q4a6KZ6KPS#KPX & RM
S=_0XYRZ'c6KPW/KZ.c6KZ[:brX]ff^ >j\a'RM,_#UTf#]#XRT[a'^ XN.Z.M,RoZ[R^KW/]ffUTV*Z6]ff^eR_#U/RZ[a.KMRTgPK?]#b & ]ffZ.OQK}[a6K
S0_0XR_0d'UTKM & RM S=_0XRZ.c6KPW/KZ.c6KZ[,brX]ff^ a._ S#K}d/KPKZOQ]ff^W"N6[YKcBj fi([4[a6KKZ'cB`.[a6KXKMN.UT[RZ.f RM
S=_0XYMRo^W'UR KcBj
@9RT[%MR^W"URTbrVRZ.f_ ARM?Z6]#[}MY]hK_#MYVLRTb(Z6]_#MMN.^eW.[RT]ffZ.M3_0XK^_#c6K_0d/]ffN6[RT[M?MYV*Z[_ i`8c.N6K
[Y][a6K&br_#OQ[3[a._0[?URT[YKPX _#UM4MRfffZ.M_0XK&OQXN'OPR_#U9a.KPXK#j3pZ.c.KPKcB`iU]]#*RZ6f]ffZ.UTV_0[3[a6K&]OPOPN6XXKZ.OQK&]#b+_
S0_0XR_0d'UTK(RZ.MRc6K\_3br]#X^&N.U_RM8Z6]#[MN6OPRTKZ[8[Y]MY[_0[YK,q4a6KP[a.KPX]#X=Z.]#[[a'RM8RM8_3Wi]ffMRT[RTS#K:]OPOPN6XXKZ.OQK
r]#X=_?Z6KPfff_0[RTS#K,]ffZ.K j=6]#X[N.Z._0[YKUV#`ff[N6XZ.RoZ6f_3br]#X^&N.U_RZ[Y]?RT[XM 4O4RMOQ]ff^eW'N6[_0[RT]ffZ._#UoUTVK_#MYV_#M
UT]ffZ6f_#M8RT[9c6]KM8Z6]#[8OQ]ffZ[_#RZ2_#ZV]*OPOPN6XXKZ.OQK:]#b.OQ]ffZ.Z6KOQ[RS#KMURT#K ]#X _#Z.c}R[W.X] S#KM8MN6OPRTKZ[
[Y]c6KMRTfffZ_?f#XKPKc6V_#UTf#]#X RT[a.^br]#X @RT[%MR^W'URb1V*RZ6f4
_ q4a6KZ2[a6K4UoRT[YKPX_#UM8RT[=RM @9RT[%RZ.c.KPWiKZ'c6KZ[
brX]ff^ a._ S#Kd/KPKZRc6KZ[R Kc jpZ.c.KPKcB`.q4RT[a'RZ_#k
Z 4?4 br]#X^&N.U_*`6KPS#KPXVUR[YKPX_#UBOP_#Zd/KOQ]ffZ.MRoc6KPXKc
K_#MRUV_#M_#Z_0[Y]ff^eRO}]#Gd FYKOQ[Pj?a.RM_#UTf#]#XRT[a.^ OQ]ffZ.MRM[MRoZOQ]ffZ.MRoc6KPXRZ6fKPS#KPXVURT[YKPX _#&U =]#*b ( 3 *P &
RZ _MN.OPOQKMMRTS#K2q:_ V#` q4a.RUKXKPW'Uo_#OPRZ6fKPS#KPXV]*OPOPN6XXKZ.OQK2]#*b \RoZ &
V "2OQ]ffZ.MRc6KPXRZ.fKPS#KPXV
URT[YKPX _#UB]#-b ( 3 *P &_#M_#Z_0[Y]ff^hj [_0[YKc]#[a6KPXqRMYK#`'qa6KZ =RoM_W/]ffMR[RTS#KrXKMYW jZ.KPfff_0[RTS#K UoRT[YKPX_#U
> rXKMYW jF%: >/ `"XKPW'U_#OPRoZ6f 8dk
V "c6]KMZ6]#[^eK_#ZXKPW'Uo_#OPRZ6f %: > rXKMYW 'j >/(dV* C+]ffZ.UTV[a6K
]*OPOPN6XXKZ.OQKM:]#&b q4RT[a[a6KXRTfffa[+MRTfffZ_0XK?OQ]ffZ.MRoc6KPXKcBja.RoM\_#UTf#]#XR[a.^ X N.Z.M\RoZ[R^eKW/]ffUTV*Z6]ff^eR_#U
RZL[a.KMRTgPKe]#Yb &]ffZ.OQKe[a6KURT[YKPX_#UM & RM @9RT[%RZ.c6KPW/KZ.c.KZ[b1X]ff^ a._ S#Kd/KPKZOQ]ff^W'N.[YKcBj fi([}[a6K
KZ.cB`6[a.KXKMN.U[RZ6f RM @R[%MR^W'UoR KcBj

Q)(

fi



~33

HBlIHKJ

uv

<mq



s~$w

~ww$

[q

J a.RUTKMYV*Z[_#OQ[ROP_#U( @ _#Z.c 4S c.KPWiKZ'c6KZ.OQKOP_#Z d/KK_#MRUTVO a6KO#Kc ZURZ.K_0X}[R^eKRZ [a6K
MRTgPK}]#b=[a6K&RZ6W'N6[P`'[a.RMRMb_0XbrX]ff^ /d KRZ6feK*W/KOQ[YKcbr]#XeMYK^e_#Z[ROP_#U14 @ 6c KPW/KZ.c6KZ.OQK}_#Z.c
c6KPW/KZ.c6KZ'OQK3RoZ[a6Kf#KZ6KPX_#UOP_#MYK C

" ; < =>$ fi$ % L ff< ML ; (' ) )ff
1 fi )
ff )ff
1fffi 'ff ) )ff
0zit fi 'ff fiff ) ff )
0wYu O[I!0x.-"uPvu
=<



ru uwuw{

k



uv

mq



u

)y

#q q{ q{

q

0

aN.MP`,_#UT[a.]ffN6fffa [a6KPV UT]]# MR^eW'UTK#`\[a.KW.X]#d"UTK^eM]#bc6KP[YKPX ^eRZ.RZ.fqa6KP[a6KPX_b1]#X ^}N.Uo_RM
RZ.c.KPWiKZ'c6KZ[b1X]ff^ _hURT[YKPX_#U]#X_S0_0XR_0d"UTK&_0XKe_#Ma._0XcL_#MO a6KO*RZ6fhW'X]#W/]ffMRT[RT]ffZ._#UKZ[_#RU^KZ[Pj
p%Z[YKPXKM[RZ6fffUTV#` [a.KeOQ]ff^W'UTK 6RT[V]#b+d/]#[ac.KOPRMRT]ffZW.X]#d"UTK^eMbr_#UoUc6] q4Z [Y] q4a6KZ.KPS#KPXOa6KORoZ6f
RZ"c.KPWiKZ'c6KZ.OQK?d/KOQ]ff^KM[YX _#OQ[_0d'UTK#j fiW'_0X[brX]ff^ [a.KOP_#MYK&]#b8MVZ[_#OQ[ROP_#URZ.c6KPW/KZ.c6KZ'OQK#`.MY]ff^K
]#[a6KPXXKMY[YXROQ[RT]ffZ'M]ffZ &s^_0#KMRZ"c6KPW/KZ.c.KZ.OQK}[YKM[_0d'UTKeRZW/]ffUTV*Z6]ff^eR_#U[R^K#j2\MYW/KOPR_#UUV#`"q:K
f#KPM[ C

ru=
< uwuw{ k'k h~*uQziuP0uPw & P 0! z{0ev !'PT; ![ NOP M!0w xN/*T;vr~#vyovwYvIQPPTu.M!0w
P TD/Q# W/.uPwI420z6|+uQwy1z{BJIy ru 18vr~*uQwuu,2#y1vrY- !0 4#vyrxu0{Q!0wyvr~x v !tuPvuPw x2yrziu3|8~6uPvr~*uPw &OA !=1
M!0w&0z=4NOP M!0wxN/Tff1K0z"tQvIQPQu M!0w00wyQPPTuy1z.vI0z'vym#vy0!0z Jy u I1+wuR-"Ty1z{hy1z & ) 0z4
;#w ymQQP u PM2
4 [YXN6K !0w P42br_#UoMYKe{#yr0u2!#w xN/* vr~#v(Qvy1r PuQ !0z{#&v ! Kvr~6uQz ff ) )ff
1

)
fiff ff )
1 fi ' ff ) ff )ff
0z"t fi ' fi ) )ff
0wu}yrz


%p Z W"_0X[ROPN.U_0X `,q4a6KZ(& RMXKMY[YX ROQ[YKc [Y] _ XKZ._#^_0d'UTK]#XZ ?54 br]#X^&N.U_]#X[Y] d'RZ'_0XV
OPU_#N.MKM ?X]ff^ br]#X^&N.U_ `._#UU b1]ffN6Xc.KOPRMRT]ffZW.X]#d'UTK^eM,_0d/] S#KdiKU]ffZ6f[Y] 9j
JLKa._S#K_#UMY]RZS#KMY[RTfff_0[YKc[a6K4OQ]ff^W'UK*RT[V2]#biO a6KO*RZ6f}q4a6KP[a6KPX\_b1]#X^&N.U_3RM @RT[%MRo^W'UR Kc
_#Z.T
c S=_0XMR^W'UoR Kc"I C

0z"t fi 2 0 ! fi fi 132 '#wYu O[I!0x.-"uPvu
fiUU8[a6KMYKOQ]ff^W'UTK6RT[V XKMN.UT[M?a._ S#KMY]ff^KR^W'_#OQ[?]ffZL[a.K_0W.W.X]ff_#O a6KM[a'_0[KW"UROPRT[UTVZ6KPKc
OQ]ff^W'N.[RZ6f
ffU,. &:_#M4_W.XKPW.X]OQKMMRZ6f2[_#MYiRj 4_#^eKUTV#`.q:Ka._S#K}[a6K?br]ffUUT] qRZ6f2XKMN.UM[ C
=<

kff7

=<

k H



ru uwuw{



ru uwuw{

#(0 ! fi fi 132 '

2uvuQwx&yrz.yrz{h|8~6uPvr~*uPw
ffr( 3 P* &

! ( JI|8~*uPwY
u ( yoPuv ![&
yvuQwY0
K 130z"ttuPvuQwx2y1z'y1z{
|8~6uPvr~*uPwU. & !=A JI|8~*uPwYu?A y1}Puv ![;0wy PQu Key1 " - O[I!0x.-"uPvu
~6u&Pu0w Q~ -"w !QPPTuPx ,!0z6yoQvy1z{hyrzOQ]ff^W'N6[RZ.f
r( 3 *P &%JIwu -.u3vyr0uP 4 U . & Ky1
yrz - 0z"ty1 P3!#vr~ O~0wYt0zit O~0wYt

BH l ; #u{
a6KW.XKPS*RT]ffN.M&Oa._0X _#OQ[YKPXRTg_0[RT]ffZ.M_#Z'c OQ]ff^W"UTK*R[VLXKMN'UT[M}UK_#c[Y]LMYKPS#KPX_#U "N6KMY[RT]ffZ'MMCq4a6KZ RM
RT[q+]#X[aq4a'RUTK[Y]W.XKPW'X]OQKMM_Z.] q4UTKc.f#K}d'_#MK}dVOQ]ff^W'N.[RZ6fRoZ.c6KPW/KZ.c6KZ.OQKXKU_0[RT]ffZ.M ) 4] q
Ma6]ffN'Uc [a6KMYKRZ.c6KPW/KZ.c6KZ'OQK&XKU_0[RT]ffZ.M?d/KOQ]ff^eW'N6[YKc ) J a._0[}RoM?[a6KUKPS#KU=]#b(f#KZ6KPX_#UR[V ]#b,[a6K
c6K Z'RT[RT]ffZ.M(_#Z.chXKMN.UT[M(q:Kfff_S#K&RZ[a.RM4MYKOQ[RT]ffZ )

Q)(i

fif.w~3}33f$3ws

_#ZVWK "N.RTS0_#UTKZ[,O a._0X_#OQ[YKPXRTg_0[R]ffZ.M]#bb1]#X ^}N.Uo_;IS;_0XRo_0d'UTK3RZ.c6KPW/KZ.c6KZ'OQKa._ S#Kd/KPKZfffRTS#KZhRZ
[a6K,URT[YKPX _0[N6XK#`0K_#Oa2]#b"q4a.RO a}OQ]ffN.Uoc}MYKPXS#K(_#M_3c6K Z.RT[RT]ffZ K Z.RT[RT]ffZ<6` ?:]#X]ffUUo_0XV 0`ffK_#Oa2]#b"[a6K
MY[_0[YK^KZ[M3; ff `i 8_#Z.c <RZ =X]#W/]ffMR[RT]ffZ _#Z.c2]#b"[a.KMY[_0[YK^KZ[M;ff `/ 8RZ =X]#Wi]ffMRT[RT]ffZff `
MY]e]ffZ.K^e_Vq:]ffZ.c6KPXq4a'ROa]ffZ6K}a._#M,[Y]ed/KN.MYKchRoZhW.X_#OQ[ROQK#j
p%Z^_#ZVW"_0WiKPX M4XKPbrKPXXRoZ6feK *W'UROPRT[UV[Y]br]#X^}N'U_;IS;_0X R_0d'UTKRoZ.c6KPW/KZ.c6KZ.OQK#`'[a6K}W'XR^K&R^W'URT
OP_#ZI[ H;OP_0[YK2O a._0X_#OQ[YKPXRg_0[RT]ffZ 5 \X]#W/]ffMRT[RT]ffZffRM,N.MYKc_#M4_c.K Z.RT[RT]ffZL5 A:]ffN6[RUoRTKPX` # <6 ]ffa.KPX[V
KP[?_#UmjT` # ff j
KZ6KPX_#UUVMYW/K_0RZ.f6`"[a.RoMRMZ6]#[[a6K2Oa6K_0W/KMY[q:_ V[Y]hOQ]ff^W'N.[YK}[a6K2MYKP[]#b=S0_0XR
_0d'UTKM?_br]#X^&N.U_c6KPW/KZ.c.M]ffZB`MRZ.OQK&[a6KeMRTgPK2]#5b
fi " &RoMK *W/]ffZ6KZ[R_#URZ[a6KeMRTgPK2]#b &sRZ[a6K
q:]#XMY[OP_#MYK#ja.RM?O a._0X_#OQ[YKPXRg_0[RT]ffZ RoM3[Y]d/KeN.MYKcLRZW.X_#OQ[ROQKe]ffZ'UTVRTb:[a6KeMYV*Z[_#OQ[ROP_#U\br]#X^ ]#b
& RMMN.Oa [a._0[RT[MW.XR^KhR^eW'UROP_#Z[M&]#XW.XRo^KhR^W'URoOP_0[YKMOP_#Z d/KOQ]ff^W'N6[YKc K_#MRUTV b1X]ff^ RT[
r[a.RM4RM,[a6KOP_#MYK}b1]#XRZ.MY[_#Z.OQKq4a6KZ6KPS#KPX & RM,_ ?X]ff^ b1]#X ^}N.Uo_ 1j ?(UTK_0XUV#`6[a6KOa.K_0WiKM[4q(_V[Y]
OQ]ff^W'N.[YKb1]#X ^}N.Uo_;IS;_0XRo_0d'UTK,RZ.c6KPW/KZ.c.KZ.OQK,OQ]ffZ.MRMY[M+RZN.MRoZ6f_#ZV2]#b/[a6KWK "N.RTS0_#UTKZ[b1]#X ^}N.Uo_0[RT]ffZ.M
]#b =X]#W/]ffMR[RT]ffZ `.q4a.RO ah_#UUBOQ]ffZ.MRoMY[,]#b8S;_#URoc.RT[V[YKMY[MPj
?(a.KO*RZ6feq4a.KP[a6KPX4_ebr]#X^&N.U_ & RM S=_0XYRZ'c6KPW/KZ.c6KZ[,b1X]ff^ _S0_0XR_0d'UT3
K > RM 'OQ]ff^W'UKP[YK#`
q4a.RoOaR^W"URTKM[a._0[+MR^W'URb1V*RZ6f4_Z.] q4UTKc.f#K,d'_#MYKdV2f#KP[Y[RZ6fXRoc2]#biXKc.N.Z.c._#Z[S0_0XR_0d'UTKMZ.KPKc.M
U. &AffOP_#UUM=[Y]2_#Z ]#X_#OPUK#`*_#Z'cRM\[aN.M+RZ - _#Z.cZ6]#[\d/KUT] qsN.Z.UKMM ! B j6a.RM
^e_ VUT]]# W'_0X _#c6W] 6ROP_#U3_#Z.cMY]ff^eKP[R^KM&N.MYKUTKMM[Y]W.XKUR^eRZ'_0XRUTVOQ]ff^W"N6[YKMYKPS#KPX_#U:RZ.M[_#Z.OQKM
]#b4_ ]#ff
X .a'_0Xc RZ.c6KPW/KZ.c.KZ.OQKeW.X]#d"UTK^ [Y]La6KUW MY]ffUSRZ.f_ MRZ6fffUK ?RZ.M[_#Z.OQK]#b_
]#X .OQ]ff^eW'UTKP[YKLW.X]#d"UTK^hjC4] q+KPS#KPX `[a'RMZ.KPfff_0[RTS#KOQ]ff^e^KZ[a._#M_ f#KZ6KPX_#U?MOQ]#W/K]ffZ.UTV#`
_#Z.c RZ^e_#ZVLW'_0X[ROPN'U_0XOP_#MYKMP`[a.RoMOP_#ZW'X] S#L
K "N.R[YKeKPOPRTKZ[RZ'c6KPKcB`KPS#KZ q4a6K#
Z &a._#M}Z6]
W'_0X[RoOPN.U_0X?MYV*Z[_#OQ[ROP_#U8br]#X^h`B[a.KeM_0[RM _0d"RURT[Vh]#X?[a6KN.Z.M_0[RM _0d'RUR[V]#b &5gih / / : &'gih ( ^e_V
d/K4W'_0X[ROPN.U_0XUV}K_#MYV[Y]&O a6KO. j+'N6X[a6KPX^e]#XK#`RbB[a6K*Z6] q4UTKc6f#Kd'_#MYK & RM+[Y]2d/.
K "N6KPXRTKc^e_#ZV
[R^KM`4[a6KZ [a6KW.XKPW.X]OQKMMRZ6fW"a._#MYK OQ]ffZ.MRMY[RoZ6f RZ S=_0XYMRo^W'URTbrV*RZ6X
f & dV RTfffZ6]#XRoZ6f N.MKUTKMM
S0_0XR_0d'UTKM,RoM,URT#KUTV[Y]ed/K?q+]#X[aq4a.RoUTK#j

=A E ffffH
p%Z[a.RM(MYKOQ[RT]ffZB`6q:Kc6K Z.Kqa._0[(b1]#Xf#KP[Y[RoZ6feRMP`*W.XKMKZ[MY]ff^eK]#b8RT[M(W.X]#WiKPX[RTKMP`*_#Z.c Z._#UUVfffRTS#K
MY]ff^K}OQ]ff^W'UTK 6RT[VXKMN'UT[MPj

lmk

!

4L ru<qsrq
fi d'_#MRO:q(_V[Y]MR^W'URb1V_ qjXj[Pjff_MYKP[\]#b/UoRT[YKPX_#UM8]#X\_MYKP[=]#b/S;_0X R_0d'UTKMOQ]ffZ.MRMY[M=RZM!0wm{uvmvy1z{
URT[YKPX _#UMIH S0_0XR_0d'UTKMRZ&RT[Pj A+KPV#]ffZ'c[a6K,MR^W"UR OP_0[RT]ffZ[_#MYi`ffb1]#Xf#KP[Y[RZ6f?RM8_3q:_ V}[Y]?^e_0#K_3br]#X^&N.U_
RZ.c.KPWiKZ'c6KZ[:brX]ff^ URT[YKPX _#UIM H S0_0XR_0d'UTKMj @KP[4N.M X MY[,MY[_0X[q4R[ahURT[YKPX_#U/br]#Xf#KP[Y[RZ6 f C
q m{uw{#

z3{

" 'qrz31> uwr|wqf'{| ' u v1&:P u M!0w xN/*T w[!#x

#z"t ( P uI/=PuPv
![+(* &'))(%*( 3 *P & % ((?y1vr~*u1M!0w xN/*Ty1z"t/ vy1#uQ 4tu;
=ziut0 !#1 !0|8
&'")(%+* ( 3 *P & % ff ! &1
&'")(%+* ( 3 *P & % #i +;7! &Tj h ( HL :Y/ & 1
&'")(%+* ( 3 *P & % #i + . ((/!.&'))(%*( 3 *P &'))(%*( 3 *Q & % (( % #i +;

!

q m{uw{

Q)(76

fi

~33



s~$w

~ww$

a'RM}c.K Z.RT[RT]ffZ RM2MY]ffN.Z'c MRZ.OQK[a6K]#Xc6KPXRoZ6fRoZq4a'ROa URT[YKPX _#UM&]#b?( _0XKhOQ]ffZ.MRc6KPXKc c6]KM
Z6]#[4^_0[Y[YKPX 7 j\JLK&OP_#Z_#UMY]W.X] S#K[a._0[[a6Kc.K Z.RT[RT]ffZh_0d/] S#K}RM(KW"N.RTS0_#UTKZ[,[Y][a6K]ffZ.KRZq4a.RoOa
]ffRZ
[ j\RM(XKPW"U_#OQKchdV

&'))(%*( 3 *P & % #i +;1! &5j h ( HL :X2/B&5j h /
FN.MY[,d/KOP_#N.MYK & _#Z'c &5j h / _0XK?WK "N.RS;_#UTKZ[^]*c.N.UT]:Yj
@KP[(N'M+Z6] q fffRTS#K?_&MK^e_#Z[RoOP_#UiO a._0X_#OQ[YKPXRg_0[RT]ffZ]#b9UR[YKPX_#U.br]#Xf#KP[Y[RZ6f6j\pb&( !$#i +ff`*[a._0[,RMP`B(
RMOQ]ff^W/]ffMYKc]#b\_MRZ6fffUTKUoRT[YKPX_#Um`"[a6KZb1]#Xf#KP[Y[RoZ6b
f =b1X]ff^ _b1]#X ^}N.UoL
_ & _#^]ffN.Z[M[Y]RZ[YX]*c.N.OPRZ6f
[a6K^e]c6KU &'"lV>= % X: m(b1]#XK_#O a^e]c6KU = ]#b & MN'Oah[a._0[D=9A ! j
ru=<uwuw{ k
~*uuPv ![x !tuP ! D&'))(%* ( 3 *P & % #i +;N
#z P u23u 2 -iwYuQPut;
f' e" &'))(%+* ( 3 *Q & % #i +;Y ! f' e" & . # &')l V >= % Y: A2=;A ! & +
! #+= &')f V>= % mDA ! &+
fi MR^eRUo_0X:MY[_0[YK^eKZ[4OP_#Zd/KfffRTS#KZbr]#X,[a6K?OP_#MYKRZq4a.RO )
( RM(OQ]ff^W/]ffMYKc]#b9^e]#XK3[a._#Z]ffZ6K
URT[YKPX _#Umj8pZh[a'RMOP_#MYK#`.br]#XK_#O a^]*c6KU = ]#b &`.q:KOP_#Zbr]#XOQK_#ZVhMN6d'MKP[,]#bUR[YKPX_#UTM ( ( 9( MN.O
[a._0[F=;A ! ( ( [Y]_#MMN.^K?[a6KS0_#UN6K3b_#UMYK#j
=<



ru uwuw{

k

~*uuPv ![x !tuP ! D&'))(%*( 3 *P & % (
( 0z Pu2u32-"wuut0

'ei &'))(%*( 3 P* & % ((Y

&'"lV>= % ( ( FA ! & |8~*uQwu6( ( 9(
fiM_eOQ]#X]ffUoU_0XV#`.q:K]#d.[_#RZ[a.Kb1]ffUoUT] q4RoZ6f2W.X]#W/KPX[RTKM(]#b8URT[YKPX_#U/br]#Xf#KP[Y[RZ.f C
J

uwruz$r

7

!$#+=

uv &1
P u1!0wxN/* ;1 w !0x


3
% #z"tff( ( % ( - 9(R

+



! &'))(%*( 3 *P & % ( ( 3~ff!# t;
& A.
& !
~ff!0Tt; 1(vr~*uQz &'))(%*( 3 *Q & % ( ( F
!.&'))(%+* ( 3 *Q
% ( ( ?
~ff!0Tt;&;|+uP1

( ( "( - ~ff0! Tt; 1(vr~*uQz &'))(%+* ( 3 *Q & % ( ( !.&'")(%+* ( 3 *P & % ( - ?
~ff!0Tt;20|+uQr
?

@KP[4Z6] q OQ]ffZ.MRc6KPX_#ZhK*_#^eW'UTK#j



z3v

u~0#u&'))(%*( 3 *P & % #):< +; 3HbV0/S-HbVP
<q k"k uPv &"! :<H)SP0/L 3H)V

a.K?#KPVW'X]#W/]ffMRT[RT]ffZbr]#X[a6KZ6]#[R]ffZh]#b9br]#Xf#KP[Y[RZ.fRM,[a6K?br]ffUUT] q4RZ6f2]ffZ6KC

orqtsu%z}yUy My#}sW: {}u TuffU&{|Ty:&:z psU y{zxWz ~t|u luY x8y5|}uz |!
npo*
ff
fi 5 ff
~ ff
fi *}s'u ff "!#$%& "!#'$ff() +*+),* (.-0/+1 32 -541 76 $ffff789(
* -541 76 $ff
8
(.-0/+1 * 6 $ff: 8; 8;(
*
<=(.-0/+1 32 -54+1 >6 $ff 8?(.-54'1 * 6 $ff 8;(.-0/+1 * 6 $ff 8; 8;(
*8WTTuz}
ff ff~ !
Do* " @ @B}su ffA%3:!#$3:!#$ff()B#*+)C#* D$ff(.-E1 F6 $ffG8H(.-E1JI%*3* -E1KI 6 $8L$ff(.-E1 F6 $ffG8
(.-E1KI%*3* -E1JI&*M<=(.-E1 6 (.-E1JI- iTTu z}% ffNB fffN
~ !

ioR}suX{Ku Wz}D|
Q)(,+

fif.w~3}33f$3ws

& '))(%*( 3 P* & % ((3y1?vr~6u
uv & Pu} M!0wx */ T. w !0x!

0z"t (9"(*
ru=<uwuw{ k
!{#y00r 4 vw !0z{uQv , !0z6u W/.uPz uB![ & vr~#v?y1 yrv5Oy1zituR-6uPz"tuPz'v w[!0x ( J /*- v ! !ff{ y5 0u W/yr;O
uQz u K


a.Kbr]ffUUT] q4RZ6f2R^e^Kc'R_0[YKOQ]ffZ.MKW"N6KZ'OQK?]#b=X]#Wi]ffMRT[RT]ffZ'&KM[_0d'URMa.KM:M[YX]ffZ6f2XKU_0[RT]ffZ'Ma.RTW'M
d/KP[q:KPKZUR[YKPX_#U/b1]#Xf#KP[Y[RZ6f_#Z.cB@RT[%RZ'c6KPW/KZ.c6KZ.OQKC

J uwruz$r H uPv & Pu2.!#w xN/* w !0x
3
% #z"tff( "(*
(sy &0z"t+!0z. 4y .& .
&'")(%+* ( 3 P* & % (:~ff!0Tt;

Y& yo yrv5Oy1zituR-6uPz"tuPz'v w !0x

a.K?b1]ffUU] q4RZ.f&]ffZ.KfffRTS#KM_#ZR^e^Kc.Ro_0[YK3_0W'W'UROP_0[RT]ffZ]#b8URT[YKPX _#U/b1]#Xf#KP[Y[RoZ6f C
x /* $y1 y5v Oyrz"tu -6uQzituQz'v w !07
x ( 1vr~6uQz & !:$ff~ !# t;y 0z"t !0z' 4y
J uwruz$r !#w N
&'))(%* ( 3 *Q & % ((FA ! $.
a'RM:XKMN.UT[(W.X] S#KM[a'_0[,b1]#Xf#KP[Y[RoZ6feURT[YKPX_#UoM(b1X]ff^ ( c6]KM,Z6]#[_ iKOQ[KZ[_#RoU^KZ[,]#b9br]#X^&N.U_#M
[a._0[_0XK @9RT[%RZ.c6KPW/KZ.c.KZ[ brX]ff^ (4ja'RM9RoMRoZ}MY]ff^eKMYKZ.MYK,_#Z._#UT]#f#]ffN'M8[Y][a.K(OQ]ffZ'OQKPW.[]#b U[YX_0[RT]ffZ
RZ^]*c._#U9U]#fffROPMe
]ffUc6d"U_0[Y[P` # 9RZ.c.KPKcB`iRbq+K_0XKRZ[YKPXKMY[YKcLRZ*Z6] q4RoZ6fqa6KP[a6KPX & ! $
]ffZ.UTV2br]#X+br]#X^&N.U_#M $ [a._0[:_0XK @9RT[%RZ.c.KPWiKZ'c6KZ[brX]ff^ (`[a6KZ[a.KURT[YKPX _#UM=]#b ( OP_#ZdiKb1]#Xf#]#[Y[YKZ
RB
Z &j
@KP[N.MZ6] qRZS#KMY[RTfff_0[YK&[a6K}OQ]ff^W"N6[_0[RT]ffZ]#b &'")(%+* ( 3 *P & % (: j @KP[N.M XMY[OQ]ffZ'MRc6KPX O4
br]#X^}N'U_#M &j6]#Xf#KP[Y[RZ6f}URT[YKPX_#UMq4R[a.RZ 64 b1]#X ^}N.Uo_#MRoM_?OQ]ff^W'N6[_0[RT]ffZ'_#UUTVK_#MYV&[_#MYij Z2[a6K
]ffZ6K3a._#Z.cB`br]#Xf#KP[Y[RZ6fURT[YKPX _#UM=q4R[a.RZ_&c.R5M FYN.Z'OQ[RTS#K4br]#X^&N.U_OQ]ff^eKM,c6] q4Z[Y]&b1]#Xf#KP[Y[RZ6f2[a6K^ RZ
KPS#KPXVhc.R5M FYN.Z'OQM[ C
=<



ru uwuw{

k





0z"tff(="(R
& ')"( *( 3 *P & % :(

H &'))(%*( 3 *P
% (( '

uPv &1
Pu}v| ! M!0w xN/*T; w[!0x

&'))(%*( 3 Q* &KH
% (:"

Z [a6K]#[a6KPX:a._#Z.cB`ffbr]#Xf#KP[Y[RZ.fURT[YKPX_#UoM8q4RT[a.RZ_OQ]ffZ.MRMY[YKZ[=[YKPX^ MR^W"UTVOQ]ffZ.MRoMY[M\RZ2XK^]
e
RZ6f[a.K^ b1X]ff^ [a6K?[YKPX^TC
k uBv 1 P u I!0z6yoQvuQz'v vuPw x w !0x
3
% J yIuQ|+ut;(vr~6u:Puv![:yrvr:
yvuQwY0
K
0z"tc( "(R &'")(%+* ( 3 *P 1 % (: j
=<



ru uwuw{

UoRT[YKPX_#UM&OP_#Z d/Kbr]#Xf#]#[Y[YKZ brX]ff^ _
rb ]#X^&N.U_B&RoZ Wi]ffUVZ6]ff^R_#U[R^K#jep[RMMN.OPRTKZ[?[Y]c6KUTKP[YKeKPS#KPXV UoRT[YKPX_#U8]#bT( brX]ff^ K_#O
c.RM5FYN.Z'OQ[+]#b &RTb]ffZ6K?]#b8[a6Kc.RoM FYN'Z.OQ[M(d/KOQ]ff^KM,K^W.[V[a6KZ &'))(%*( 3 *Q & % (( 9* f ; j
a'RZ6fffMB_0XK:^]#XK\OQ]ff^W"UROP_0[YKcbr]#X9OQ]ffDZ FYN.Z'OQ[RTS#K=br]#X^}N'U_#M &/
j9\MYW/KOPR_#UUV#`[a6KPXK:RM Z6]XKMN.UT[
MR^RU_0XB[Y.] \X]#W/]ffMRT[RT]ffZ ^,b1]#XOQ]ffZ FN.Z.OQ[RTS#K=br]#X^&N.U_#MPj9J a'RUTK &'))(%* ( 3 *Q & % (( / &'))(%* ( 3 *P
% ((
RM_U]#fffROP_#U.OQ]ffZ.MYWK "N6KZ.OQK4]#b &'))(%+* ( 3 *Q &/
% (:(MKPK ?:]#X]ffUoU_0X
V ff `[a6KOQ]ffZS#KPXMYKc.]KM=Z.]#[=a6]ffUc
RZ[a6Kf#KZ6KPX_#U OP_#MYK#j
64

?:]ff^}d'RZ'RZ6f[a.K[q+]LW'XKPSR]ffN.MW'X]#W/]ffMRT[RT]ffZ.M}Ma6] q4Ma6] q




z3v <q kG7 uPv & !. 1
"!O:< 1+0z"tff( !$# + .y1z u 4
1=|+u~0#u&'))(%*( 3 *P
% ((

.yrz u
&'))(%+* ( 3 *Q & % (:yoh;#
ymt)12|+u~00u &'))(%+* ( 3 *Q & % (: / &'")(%+* ( 3 *P
% (:Y :<
5
.yrz uV&G/
y1y1z ,!0z6yoQvuQz'v>1<&'))(%*( 3 *P & /
% (:yoyrz,!#z6 y1vuPz'v:0|+uQr



ff

Q)(^]

fi

~33



s~$w

~ww$

`*_#ZVZ.]ffZ*IS;_#UoRcOPU_#N'MYK60RM @RT[%RoZ.c6KPW/KZ.c6KZ[=brX]ff^ ( RTb _#Z.c]ffZ.UTVeRTb( 3 *P0; fi
j *RZ.OQK[a6KOQ]ffZDFYN.Z'OQ[RT]ffZ ]#b?[q+] br]#X^}N'U_#Me[a._0[_0XK @RT[%RoZ.c6KPW/KZ.c6KZ[2b1X]ff^ ( RM @9RT[%
RZ.c.KPWiKZ'c6KZ[?brX]ff^ ( MKPKL\X]#W/]ffMRT[RT]ffZ ff `_#Z.c MRZ.OQKKPS#KPXVLbr]#X^}N'U_RMKW"N'RTS;_#UKZ[[Y] _ ?T4
br]#X^}N'U_*Q` =X]#Wi]ffMRT[RT]ffZ+&3Ma6] q4M &'))(%*( 3 *Q & % ((KW"N.RTS0_#UTKZ[[Y][a6KMYKP[]#bB_#UU*OPU_#N.MYKM*04[a'_0[\_0XK
KZ[_#RUTKc2dV & _#Z.c_0XK,b1X]ff^ #0OPU_#N'MYKA ( 3 *P0; fiO( ! +ffj A:KOP_#N.MYK#0OPU_#N.MKA( 3 *P0; fiO( !. +RM
OPUT]ffMYKcN.Z.c6KPXMN6d'MN.^eW.[RT]ffZ2RmjK#jT`#RT[ RMB_MY[_0d"UTK=W.X]*c.N.OQ[R]ffZ KUc" ` R[ RMBW/]ffMMRTd"UTK9[Y][_0#K+_#c6S0_#Z[_0f#K
]#b}OQ]ffZ'MYWK "N.KZ.OQK Z.c.RZ.f _#UTf#]#XR[a.^eM MYKPK _0IX "N.RoMP
` 0## `3[Y] c6KPXRTS#K "
_ ?54 XKPW'XKMYKZ[_0[RT]ffZ
]#b&')"( * ( 3 *P & % (: j \MWiKOPRo_#UUTV#`=RZ [a6KhOP_#MYKq4a6KPXK & RM_ ?54 br]#X^&N.U_*`=XKMY]ffUN6[RT]ffZ6Id'_#MYKc
OQ]ffZ.MYWK "N6KZ.OQK Z'c.RZ6fe_#UTf#]#X RT[a.^eMURT#K}[a6]ffMYK2XKPW/]#X[YKcRZ rp%Z6]ffN6K#` # ff]#Xec6KU S=_#Um` ##ffOP_#Z
d/KN.MYKcB6[a'RM,RM,Z6]#[S#KPXVMN6XW.XRoMRZ6fMRZ.OQK?XKMY]ffUoN6[RT]ffZhRM,Z6]#[a'RZ6fd'N6[300w ymQ PPTueuP
yrx2y1zi#v5y !#z.j
p%ZOQ]ffZ[YX_#MY[ [Y][a.K\c.RM FN.Z.OQ[RS#K9br]#X^&N.U_#M MR[N._0[RT]ffZB`[a.KPXK\RMBZ6],fffN'_0X_#Z[YKPK+[a._0[MN'OaOQ]ffZ.MWK "N6KZ'OQKQ
Z.c'RZ6f_#UTf#]#X RT[a.^eM+XN.ZRZ[Ro^K4W/]ffUTV*Z6]ff^eR_#U"RZe[a.K3RoZ6W'N6[\MRTgPK4q4a.KZ[a6K?RZ.W'N6[\RM:_&OQ]ffZ FYN'Z.OQ[RTS#K
br]#X^}N'U_r]#[a6KPXqRMYK#`9_#M}K *W'U_#RZ6KcRZL[a6Kebr]ffUUT] q4RZ6f6`9q+Kq+]ffN'Uca._ S#K ! B j 4KPS#KPX[a6KUTKMMP`
br]#Xf#KP[Y[RZ6fURT[YKPX_#UoM,q4RT[a.RoZ_OQ]ffZ FN.Z.OQ[RS#Kbr]#X^}N'U%
_ & OP_#Zd/KK_#MVRZMY]ff^eK}XKM[YXROQ[YKcOP_#MYKMP`iKM%
W/KOPR_#UUTVq4a6KZ & RM,fffRTS#KZdV[a.KMYKP[4]#bRT[M4W.XR^eKR^W'URoOP_0[YKMP.RZh[a.RoMMRT[N._0[R]ffZB`.RT[4RM4MN6OPRTKZ[
[Y]efffRTS#K}N6Wh[a6]ffMYKOPUo_#N.MYKMOQ]ffZ[_#RZ.RZ.fe_eURT[YKPX_#U/brX]ffQ
^ (4j
ru=<uwuw{ k
!0wN
x /* [w !#2
x

0z"c
( "(R
uPv & Pu&.

&')"( * ( 3 *P & % (:Y7
!$#0rA 0 )
&F e)( 3 *P 00M)
fi ( ! +'
a.K:Z6]#[R]ffZ}]#b"URT[YKPX_#Ub1]#Xf#KP[Y[RZ6f3f#KZ6KPX_#URgPKM8[a6K:Z.]#[RT]ffZ&]#b'S0_0XR_0d'UTK+KUR^eRoZ._0[RT]ffZbrX]ff^sW.X]#W/]0
MRT[R]ffZ._#U*UT]#fffRO?r[a._0[q(_#M=_#UTXK_#c6VZ6] q4Z2dV A:]]ffUK_#MKUR^eRoZ._0[RT]ffZ]#b/^eRc'c.UTK\[YKPX ^eM_#Z.ca._#M8d/KPKZ
f#KZ6KPX_#UoRTgPKc[Y][a6K X MY[%I]#Xc6KPXOP_#MKRZ_^]#XKXKOQKZ[&W'_#MY[dV @9RZ fi E4KRT[YKPX` # < jp%Z.c6KPKcB`
S0_0XR_0d'UTK}KUR^eRoZ._0[RT]ffZRoM_0d/]ffN6[&;#w ymQ PQu !0wm{uvmvy1z{#`RmjK#jT`/[a6K2]ffZ6K_#O a.RTKPS#KcLZ6]#[?OQ]ffZ.MRoc6KPXRZ6f[a6K
URT[YKPX _#UM,MRTfffZ.MWC
Pu !0wN
x /* w !0x

#z"tLuPYv U Pu
q!m{uw{ " nz$rffz$q'> uwr|wqf{#| ' uPv &
/=PQPuPv ![+
fi &')"( 3* U . & % U&?y1vr~*1
u !#w N
x /* yrz"Dt / vy1#uQ 4t;u
=ziuth0 !0r !0|8
! &1
&'")(%+* U, . & % ffff
! &'gih ( H &'gih / 1
&'")(%+* U, . & % #D> +;ff
! &')"( 3* U . &')"( 3* U . & % U& % #D> +;
&'")(%+* U, . & % #D> + . U}ff
H)SP0/L 3 H)V u~0#u&'))(%3* U,. & % # +; S-H)V
z3v <q k%H uPv &"! :<
fiM=_?c.RTXKOQ[8OQ]ffZ'MYWK "N.KZ.OQK,]#b"[a.Kc6K Z.RT[R]ffZB`)&'")(%+* U, . & % #D> ( %('''% > ) +;8RoM9WK "N.RTS0_#UTKZ[8[Y][a6K
"N._#Z[R Kcd/]]ffUTK_#Zb1]#X^&N.U_hN.MN._#UUTVq4RT[abrXKPK?S;_0X R_0d'UTKM
&c.KZ6]#[YKc ff > ( '('(' ff > ) &j
?(UK_0XUTV KZ6]ffN6fffaB`br]#Xf#KP[Y[RZ.f_S;_0X R_0d'UTK > _#^]ffN'Z[M&[Y] b1]#Xf#KP[Y[RZ6fdi]#[a[a6KURT[YKPX_#U
> _#Z.c
%: >9j
ru=<uwuw{ 7
!0wN
x /* [w !#2
x

0z"t U!"
fi u~00u
uPv & Pu&.
&'))(%3* U . & % U2" .&'))(%* ( 3 *Q & % ('$+
a'RMXKMN.UT[P`#[Y]#f#KP[a6KPX\q4RT[a&[a6K(W.XKPS*RT]ffN.M9XKMN.U[M9]ffZUoRT[YKPX_#Ub1]#Xf#KP[Y[RoZ6f6`fffffRTS#KMN.M[a6K(br]ffUUT] q4RZ6f
OQ]#X]ffUUo_0XRTKM(br]#XS;_0X R_0d'UTK?br]#Xf#KP[Y[RZ6f C

(

!

?(UK_0XUTVKZ6]ffN6fffa

Q (

fif.w~3}33f$3ws

J

uwruz$r



'ei &'))(%*3U. & % D# >*+;Y
J

'fe" & . #fi 3 * V >= % >B A2=;A ! &+ '
uPv &Pu2 M!0wx /*Th0z"t U2"
fffi F&'))(%+* U. & % U2yovr~6u& !{#y00r 4vw !0z{uQv
!


uwruz$r
,!#z6Pu M/'uQzuN![ & vr~#v:y1 .0w Oyrz"tu -6uQz"tuQz'v w[!0x U J /*-v ! !{#y00=u W/yr;#TuPz u[K



x /T $ y1 '0Iw Oyrz"tRu -.uQz"tuPz'v w !0x U 1vr~*uPz & ! $ 0z"
!0z. 4
J uwruz$r M!0wN
&'))(%*3U,. & % U&FA ! $
fi OQ]ffZ'MYWK "N.KZ.OQK(]#b.[a6K,U_0[Y[YKPX8XKMN.U[9RM9[a._0[8b1]#Xf#KP[Y[RZ6f3S;_0X R_0d'UTKM9RM9N'MYKPbrN'Uq4a.KZ]ffZ.UV_MN6d'MYKP[
]#b=S0_0XR_0d'UKM4_0XK&XK_#UUTVN'MYKcRZ[a6N
K "N.KPXRTKMPj44aN.M`"RT1b & XKPW.XKMKZ[M3MY]ff^K&W'RTKOQKM]#b=*Z6] qUTKc6f#K
_0d/]ffN6[=_?MOQKZ._0X RT]?]#biRoZ[YKPXKM[P`_#Z.c2q:K4_0XKRZ[YKPXKMY[YKcRZ&Z.] q4RZ.f?q4a6KP[a6KPX=_?b_#OQ[ $RM8[YXN.KRZ2[a6K
MOQKZ._0X RT]6`[a6KU]#fffROP_#U6]#W/KPX_0[RT]ffZ[Y]}c6]RM8[Y] "N6KPXV&q4a6KP[a.KPX &OA ! $\-j 4] q`RTb"[a.K,Wi]ffMMRTd'UTK:b_#OQ[M $
q:K_0XKRZ[YKPXKMY[YKcRoZhc6]eZ6]#[RZS#]ffUTS#KMY]ff^KS;_0XRo_0d'UTKM U`6[a6KZh[a6KMYK?S0_0XR_0d"UTKM,OP_#Zhd/K?b1]#Xf#]#[Y[YKZ
brX]ff^ &`._#.M "N6KPXVRZ.f&qa6KP[a6KP.X $ RMRo^W'URTKcOP_#Zd/K?c6]ffZ6K?]ffZ&'))(%3* U . & % U2:RZ.MY[YK_#c]#b &j
a.X]ffN6fffa2[a6K,W.XKPSRT]ffN'M9W'X]#W/]ffMRT[RT]ffZB`#MY]ff^eK4_#UTf#]#XRT[a'^eMb1]#X=br]#Xf#KP[Y[RZ.fS;_0X R_0d'UTKM8OP_#Zd/K,K_#MRUV
c6KPXRS#KcLb1X]ff^ _#UTf#]#XR[a.^eM?br]#Xbr]#Xf#KP[Y[RZ6fURT[YKPX_#UMMY]ff^Ke]#b,[a6K^ a._S#Kd/KPKZMY#KP[Oa.Kc d/KPbr]#XK j
W/KOPR OP_#UoUTV#`ffW/]ffUTV*Z6]ff^eR_#U'[R^K_#Uf#]#XRT[a.^eM+br]#X:br]#Xf#KP[Y[RZ.f}S0_0XR_0d'UKM\q4R[a.RZe_ 64b1]#X ^}N.Uo_]#X,_
br]#X^}N'U_fffRS#KZdVe[a.K3MKP[,]#b9RT[M:W.XRo^KR^eW'UROP_0[YKM:OP_#Zd/K]#d'[_#RZ6KcBj [a6KPX([YX_#OQ[_0d"UTKOPU_#MMYKM(]#b
W.X]#W/]ffMR[RT]ffZ._#U9b1]#X^&N.U_#Mbr]#X?S;_0X R_0d'UTK&b1]#Xf#KP[Y[RZ6fhK 6RMY[Pj}.]#X}RZ.M[_#Z.OQK#`B[_0RoZ6fh_#c6S;_#Z[_0f#Ke]#b:[a6K
b_#OQ[\[a._0[ &'")(%+* U, . &/
% U} &')"( 3* U . & % U2 / &'))(%+* U, 6
% U}qa6KZ6KPS#KPX U 6 &4 fi
U.
! a.]ffUc.MPff
` 3_0Xq4RoOa6K[ ##ffMa6] q:Kc [a._0[S0_0XR_0d'UKbr]#Xf#KP[Y[RZ6fRoZ _br]#X^&N.U_ & OP_#Z
d/Kec6]ffZ6KRoZLURZ6K_0X?[R^eKe_#MMY]]ffZ_#N
&RMRZ 2,u ,!0.
x -G!;PQ PQu N&uI{#v0y !0z N !0wxe0Y P!0wx 64?4= `
RmjK#jT`=_ fiY
4O4b1]#X^&N.U_RZ q4a.RO a[a6KhOQ]ffZ FN.Z.OQ[M&]#b4_#ZVOQ]ffZ FN.Z.OQ[RS#KMN.d.b1]#X ^}N.Uo_c6] Z6]#[
Ma._0XK_#ZVeS;_0X R_0d'UTK#jpZ[YKPXKMY[RoZ6fffUTV#`[a6K 64O4b1X _0fff^KZ[:]#b W.X]#Wi]ffMRT[RT]ffZ._#U.U]#fffRO4RM+MY[YXROQ[UVe^]#XK
MN.OPOPRoZ.OQ[[a._#Z&[a6K 64]ffZ6K?rKMYW/KOPR_#UUTV#`0MY]ff^K 64O4b1]#X^&N.U_#M9]ffZ.UTV_#c'^eRT[K *W/]ffZ6KZ[R_#UUTVU_0Xf#K
KW"N.RTS0_#UTKZ[ 64 b1]#X ^}N.Uo_#M 3 3_0Xq4RO a6K fi_0,X "N.RMP` ##ff j
p%Z[a6K}f#KZ6KPX_#U9OP_#MYK#` FN.MY[_#M4br]#X4[a6K&URT[YKPX_#UMRT[N._0[RT]ffZ `.[a6KPXKRoM4Z6]eq(_V[Y]br]#Xf#KP[4KPOPRKZ[UTV
RmjK#jT`6RZWi]ffUVZ6]ff^R_#U6[R^K \_&MYKP[+]#bBS0_0XR_0d"UTKM\qRT[a.RZe_}br]#X^}N'U_N.Z.UKMM ! / #j 4KPS#KPX[a6KUTKMMP`
[a6K+b1]ffUU] q4RZ.fc6KOQ]ff^W/]ffMRT[RT]ffZW.X]#W/KPX[V?OP_#Z}d/K\a6KUTW.bN.U0RZ}MY]ff^K+MRT[N._0[RT]ffZ.M+_#OQ[N._#UUTV#`#RT[RoMa6K_ SRUV
K*W'UT]ffRT[YKchRZ ]ffa.U_#M,KP[4_#UIjT` ##ff j


=<

ru uwuw{

U 4

7Bk

uv1&1
Puev| ! M!0wxN/T; w[!0xQ
3
% 1#z"t%U Pu /PQPuv ![O
fffi
& /&'")(%+* U 6
% U&

,. & 1\vr~*uPz&'")(%+* U, . &G/
% &U

4]#[YK[a._0[,[a6KOQ]#XXKMYW/]ffZ.c.RZ.fW.X]#W/KPX[Vbr]#XURT[YKPX_#Uibr]#Xf#KP[Y[RZ6fec.]KM,Z6]#[a.]ffUcL_#M_&W.XKPS*RT]ffN.M

K6_#^W'UTKMa.] q4M j
6]#Xf#KP[Y[RZ6f URT[YKPX_#UM]#X}S0_0XR_0d"UTKM?W.X] S#KM}a.KUTW.bN.URZS0_0XRT]ffN'MMYKP[Y[RZ.fffMrq:K_#UTXK_#c6VMY#KP[Oa.Kc
MY]ff^K ]#b}[a6K^ RZ [a6KLRZ[YX]c.N'OQ[RT]ffZ" j6]#XRZ.M[_#Z.OQK#`^eRoZ.R^e_#U^]c.KURoZ6b1KPXKZ.OQK r]#XOPRXOPN.^2
MOQXRW.[RT]ffZ >O ?(_0X[aV#` ff4OP_#Zd/K?K *W.XKMMKcN.MRoZ6feURT[YKPX_#U b1]#Xf#KP[Y[RoZ6frd'N6[Z6]#[c.RXKOQ[UTVN'MRZ6f
S0_0XR_0d'UTKb1]#Xf#KP[Y[RoZ6f6`"qa.ROaMa6] qM4[a6K&RZ[YKPXKMY[4]#b[a.K}^]#XK}f#KZ6KPX_#U9b1]#X ^ q:K}RZ[YX]*c.N.OQKc" j(p%Z*
c6KPKcB`6RT[:RM+q+KUUTIZ6] q4Z[a._0[,OPUT]ffMYKcq+]#X UcRoZ6b1KPXKZ.OQK4brX]ff^ _*Z6] q4UTKc6f#Kd'_#MYK & OP_#ZdiKUT]#fffROP_#UUV
Oa'_0X_#OQ[YKPXRTgPKc _#MOPU_#MMROP_#U4KZ[_#RU^eKZ[brX]ff^ & OQ]ff^W"UTKP[YKc q4RT[a M]ff^KL_#MMN.^W'[RT]ffZ.MPj p%Z [a6K
OPRTXOPN'^eMOQXRTW'[RT]ffZb1X_#^eKPq+]#X ; >O ?(_0X[aV#` ff `fffRTS#KZ _hW'_0X[RT[R]ff
Z +:
% % -?]#/b
fi:`9MN.Oa _#M%
MN.^eW.[RT]ffZ.M?_0XK[a6KZ6KPfff_0[R]ffZ.M]#b([a6Kb1]#X^&N.U_#
MPj[P
j c6]KMZ.]#[}OQ]ffZ[_#RZ_#ZV S;_0XRo_0d'UTKbrX]ff^

Q

fi

~33



s~$w

~ww$

K 1OQ]ffZ[_#RZ.RoZ6f2]ffZ.UTVW/]ffMR[RTS#K?URT[YKPX_#UM:d'N'RUT[(N6Whb1X]ff^
_#Z.chURT[YKPX _#UM:d'N.RUT[
_#Z.cb1]#X4KPS#KPXVhOPU_#N.MYO
6N WbrX]ff^ `'RTb & A4!=1La6]ffUc'MP`*[a6KZ'& A4! 1H a.]ffUc.M,_#Mq:KUUmj+ "N.RTS0_#UTKZ[UV#`: RoMOQ]ffZ.MRc.KPXKc_
XK_#MY]ffZ'_0d'UTK_#MMN'^W.[RT]ffZq4a.KZ6KPS#KPX4RT[RM}MYVZ[_#OQ[ROP_#UUV6 S=_0XRZ.c6KPW/KZ.c6KZ[(b1X]ff^ _#Z.cKW"_#Z.c*
RZ6%
f & q4RT[ahRT[4c.]KMZ.]#[4^]*c.RTbrVq4a._0[RoM_#UTXK_#c6V*Z6] q4Z_0di]ffN.[+(*, . ( j ?(UTK_0XUVKZ6]ffN6fffa `.[a6K
MRTfffZ'M4]#b:URT[YKPX_#UM4b1X]ff
^ (* XK_#UoUTV^e_0[Y[YKPXa6KPXK#jMRZ.f]ffN6X3W.XKPSRT]ffN'M4Z6]#[_0[RT]ffZ'MP`4: RM3_#MMN.^Kc
RTb8_#Z.ch]ffZ.UVRTb 4 ,. : _#Z.'
c & & / : \7j fiM4_eOQ]ffZ'MYWK "N.KZ.OQK#`'q:K}c6KPX RTS#K?[a6Kbr]ffUUT] q4RZ6f
Oa'_0X_#OQ[YKPXRTg_0[RT]ffZ]#b8OPRTXOPN.^eMOQXRTW.[RT]ffZ C


1 0z"tff
1 1 P u&vr~wuu2t0y1 M!0yrz'v
uPv &1
P u}v| !YM!0wxN/T; w !0x2
3
% +
Puvr ![00w ymQPPTuQ w !0x
fi mJ I/P~hvr~*#v U, . & . U.
'"
. . K v\~ff!0Tt;
4 ;0wy QP u w 0! x

t! uzff! v I0! z'vI0yrz0z
=<

ru uwuw{

7=7



& % +:
% % -YFA !

0z"t+!0z. 4y
&OA !.&'")(%+* ( 3 *P & /
% (/. . (fiff9


zLvr~*u3{uQziuPw%#;u


& % +:
% % -YFA !

0z"t+!0z. 4y
& !.&'))(%*( 3 *P & / :@&')"( * ( 3 *P & / :
% ( ff
.

( . % ( ff
.

( .

|8~*uPwYu

yo y1w M/*x&w -ivy0!0z;}tu;
=ziuty1z#J 0wQvr~Q4)1 IK
*Ro^eRU_0X3Oa._0X _#OQ[YKPXRTg_0[RT]ffZ.M}OP_#Zd/Kc6KPXRTS#Kc br]#X[a6K]#[a.KPXb1]#X ^eM?]#b(OPUT]ffMYKcLq:]#XUc XK_#M]ffZ.RZ6f
W/]ffRZ[YKc]ffN6[4MY]eb_0Xj
6]#Xf#KP[Y[RZ6f_#UM]eRM,_OQKZ[YX _#U OQ]ffZ.OQKPW.[qa6KZq+K_0XKOQ]ffZ.OQKPXZ6KchqRT[aT"N.KPXV_#Z.Mq+KPXRoZ6f2qjXj[Pj
_}XKMY[YXROQ[YKc[_0Xf#KP[(U_#Z6fffN._0f#K#j\pZ.c.KPKcB`RZ^e_#ZVW.X]#d'UTK^MP`[a6KPXKRM+_}MYKP[:]#bBS0_0XR_0d'UTKM\b1]#X:q4a.RoOa
q:K_0XKZ.]#[eRZ[YKPXKMY[YKc RZ [a6KRTX2[YXN6[a S0_#UN6KLMY] q+KOP_#Z br]#Xf#KP[[a6K^ j 6]#XeRZ.MY[_#Z'OQK#`\RZ [a6K
fi 1@*fiO4 b1X _#^KPq+]#XdV _#N.[Yg#` (O fiUoUTKMY[YKPX`_#Z.+
c *KU^e_#Z[ # ff `'OQ]ff^eW'RURZ.f_q(_V 'N.KZ[M+]#X
_#OQ[RT]ffZ.M,_#^e]ffN.Z[M[Y]b1]#Xf#KP[Y[RoZ6f2S;_0XRo_0d'UTKMPj *RZ'OQK[a6K?]ffZ'UTVeS0_0XR_0d'UTKM:q:K?_0XK?XK_#UUTVRZ[YKPXKMY[YKchRZ
q4RT[a'RZ_fffRTS#KZ2MYKP[8]#b"OPUo_#N.MYKMXKPW.XKMKZ[RZ.f_W'U_#Z'Z.RZ6fW'X]#d'UTK^sRZ.MY[_#Z'OQK:_0XK([a6]ffMK:XKPW.XKMYKZ[RZ6f
[a6KW'Uo_#Z.MP`Bq:KOP_#ZOQ]ff^W'RoUTK_q(_V_#ZV]#[a6KPXS;_0XRo_0d'UTK#`RTb\[a.RM?c6]KMZ6]#[RZ[YX]*c.N.OQK_#ZRZ'OQXK_#MYK
]#b9MRTgPK3]#b[a6K3XKMN'UT[RZ6f}b1]#X^&N.U_*ffj fiZ6]#[a6KPX,MR[N._0[RT]ffZq4a6KPXK?MN'Oa_2b1]#Xf#KP[Y[RZ6fZ._0[N6X_#UoUTV]OPOPN.XM
RM^e]c6KUTId'_#MYKcc.Ro_0fffZ6]ffMRMe5 E4KRT[YKPX` # \OQ]ff^W'RUoRZ6fh_q(_VKPS#KPXVS0_0XR_0d"UTKK *OQKPW'[[a6K_0d"Z6]#XY
^e_#UR[V]ffZ.KMc6]KMZ6]#[eXK^e] S#K_#ZV W"RTKOQKh]#bRoZ6b1]#X ^e_0[RT]ffZ XWK "N.RTXKc [Y]OQ]ff^eW'N6[YKh[a6KOQ]ff Z "ROQ[M
_#Z.c[a6Kc.R_0fffZ.]ffMYKM]#b=_eMVMY[YK^j(4aN.M` _0Xq4ROa.K[ # ffMa6] q4M4a6] q d/]#[a[a.KMYKP[4]#bOQ]ff Z "ROQ[M
_#Z.c[a6K}MYKP[]#bOQ]ffZ.MRMY[YKZ'OQVId'_#MKcc.Ro_0fffZ6]ffMYKM]#b=_MYV*MY[YK^ RoMOa._0X _#OQ[YKPXRTgPKcdV[a6K}b1]#X ^}N.Uo_]#d6
[_#RZ6Kc dVb1]#Xf#KP[Y[RoZ6fhKPS#KPXV S;_0X R_0d'UTK2K 6OQKPW.[?[a6Ke_0d'Z6]#X ^e_#URT[V]ffZ6KMRoZ [a6KeOQ]ffZ FN.Z.OQ[RT]ffZ ]#b:[a6K
MYV*MY[YK^ c6KMOQX RTW.[RT]ffZ _#Z.c [a6K_ S;_#RoU_0d'UTK]#d'MYKPXS0_0[RT]ffZ.Mj \X] S*Rc6Kc [a._0[2[a6KMYV*MY[YK^ c6KMOQX RTW.[RT]ffZ
a._#M XM[d/KPKZ[N6XZ6Kc RZ[Y] 64?4:`Bb1]#Xf#KP[Y[RoZ6fhOP_#Z diK2_#Oa'RTKPS#KcLRZ URZ6K_0X[R^K2_#Z.c c.R_0fffZ.]ffMYKM

Q_

fif.w~3}33f$3ws

OQ]ffZ[_#RZ.RZ6f_^eRZ'R^e_#UZN.^d/KPX]#b,b_#N.UT[VLOQ]ff^W/]ffZ6KZ[M}OP_#Zd/KeKZN.^KPX _0[YKc RZ r]ffN6[YW'N6[ ?Wi]ffUV
Z6]ff^eRo_#U\[R^eK#jp%Z[YKPXKMY[RZ6fffUTV#`8[a.RoMq:]#XMa.] q4M&[a._0[&[a6Kc.R_0fffZ6]ffMRoM[_#MY c6]KM2Z6]#[&XKW"N.RTXK[a6K
N.MN'_#UUTV K W/KZ.MRTS#K ?OQ]ff^W"N6[_0[RT]ffZ ]#bW.XR^eKR^W'UoROP_0[YKIM H;R^W"UROP_#Z[M?[Y]d/K_#Oa.RTKPS#Kc _#OQ[N._#UoUTV#`
OQ]ff^W'N.[RZ6f2W.XR^eKR^eW'UROP_0[YKIM H;Ro^W'UROP_#Z[M\RoM FN.MY[,_|\D 4?[Y]e_#O a.RTKPS#KS0_0XR_0d"UTKbr]#Xf#KP[Y[RZ.fe_#Z.chZ6]#[
_{ !0'RoZOQ]ffZ.MRM[YKZ.OQVId"_#MYKcc'R_0fffZ6]ffMRM j:6]#Xf#KP[Y[RZ6fKPS#KPXVhS;_0X R_0d'UTK?brX]ff^ _b1]#X ^}N.Uo_e_#UUT] q4Mbr]#X
OQ]ffZ.MRoMY[YKZ.OQVO a6KO*RZ6fMRoZ.OQK & RMOQ]ffZ.MRoMY[YKZ[RTb._#Z'c}]ffZ'UTVRTb&'))(%+* U, 6 & % U . &Y9RM9OQ]ffZ'MRMY[YKZ[Pj
a6Kq+KUUTIZ6] q4
Z 3_S*RM&_#Z.c +N6[Z._#^ _#UTf#]#XRT[a.^ b1]#X&M_0[RM _0d"RURT[V[YKMY[RoZ6f 3_S*RN
fi \N.[Z._#^h`
03rXKOQKZ[UTVXKPSRMRT[YKcedV KOa[YKPX4_#Z.L
c E4RMa[ # <N.Z'c6KPX,[a6K3Z._#^K3c.RTXKOQ[RT]ffZ'_#U.XKMY]ffUoN6[RT]ffZ"
d'_#MRoOP_#UUTVOQ]ffZ'MRMY[MRoZLOQ]ff^W'N6[RZ.f_OPU_#N.M_#U8XKPW.XKMYKZ[_0[RT]ffZ]#b &'))(%+* U. & % U, . &Yb1X]ff^ _
?546
& N.MRZ.f&XKMY]ffUN6[RT]ffZ *Rb[a6KK^eW.[VhOPU_#N.MKRM,Z6]#[f#KZ6KPX _0[YKcB`.[a6KZ & RM,OQ]ffZ.MRM[YKZ[4_#Z'ch[a6K
OQ]ffZS#KPXMYK}_#UoMY]ea6]ffUc.Mj
6]#Xf#KP[Y[RZ6f OP_#Z _#UM] d/KLN.MYKc _#M_ #KPV OQ]ffZ.OQKPW.[RZ ]#Xc.KPXh[Y] ]#Xfff_#Z.RTgPK *Z6] q4UKc6f#KLMY] _#M
[Y] XKPW'U_#OQK]ffZ.KfffUT]#d"_#U4RZ6brKPXKZ.OQKRZ[Y] _ZN.^}diKPX]#bUT]OP_#URZ6brKPXKZ.OQKM_#MMa.] q4Z_#^]ffZ6f ]#[a*
KPXM 3d
V ?]ffa'U_#M?KP[}_#UIj+[ ##ff}_#Z.c fi^eRTX_#Z'c OQp%UTX_#R[a ; 0## ff` OQp%UTX_#RT[a _#Z.
c fi^eRTX; 0# j
@ ]]ffMYKUTVMYW/K_0RoZ6f6` MN.O aL_0W.W.X]ff_#O a6KM?XKUTV]ffZL[a6KRc6K_[a'_0[?K W'U]ffRT[RZ6f_#UU[a6KW'RTKOQKM3]#b(RZ6br]#XY
^e_0[RT]ffZ fffRS#KZRoZ_*Z6] qUTKc6f#K2d'_#MYKRM[VW'ROP_#UoUTVZ6]#[3XWK "N.RTXKcbr]#X "N6KPXV_#Z.MYq:KPXRZ6f6j.]OPN.MRZ6f
]ffZ q4a._0[RMXKUTKPS0_#Z[[Y] [a6'
K "N6KPXV RMMN6OPRTKZ[Pj J a.RUKMN.O [YKOa.Z.8R "N6KMc6] Z6]#[UT] q:KPXh[a6K
OQ]ff^W'UK *RT[V ]#b2RZ6brKPXKZ.OQK brX]ff^ [a6KL[a6KP]#XKP[RoOP_#UMRc6K#`[a6KPV OP_#Z UTK_#c [Y] MRTfffZ'R OP_#Z[W.X _#OQ[ROP_#U
R^W'X] S#K^KZ[MPj 6]#XRoZ.MY[_#Z.OQK#`(_#MMN.^eK[a._0L
[ & OQ]ffZ.MRMY[Me]#b[a.XKPKbr]#X^}N'U_#M
( `
- `:_#Z'c
0 j
6]#X_#ZV "N6KPXV &`4UKPT
[ U ! 00 ( U.
10IY U, . j JLKLa._ S#K & ! RTb_#Z.c ]ffZ.UTV Rb
&'))(%3* U,. 00 (
10 % UFA !&j8pb U,.
0 %fi 0- ( U .
10mY ! `[a'RM\_#^]ffN'Z[M+[Y][YKMY[yrz"tu
-6uPz"tuQz"v 4eqa6KP[a6KPX&'))(%3* U,. 0- (
10 % UA ! a6]ffUc.M3]#X&'")(%+* U 6
0 % U=A ! a.]ffUc.MPj
a.RoMq(_V#`]ffZ6KfffUT]#d'_#URZ.b1KPXKZ'OQK&RM3XKPW'U_#OQKcdV[q:]UT]*OP_#URZ6brKPXKZ.OQKMPff
j 44] q`M&'))(%+* U, 6
( /

- % U=4RoMWK "N.RTS0_#UTKZ[3[Y] &')"( 3* U .
( /-&'))(%3* U,.
- % Ufi U .
- U.
( YY % U= j
fiOPOQ]#Xc.RZ6fffUV#`"KPS#KPXVS;_0X R_0d'UTK}b1X]ff^
- [a._0[?RM4Z6]#[?_S;_0X R_0d'UTK}]#
b
( ]#X?_S;_0X R_0d'UTK}]#b OP_#Z d/K
br]#Xf#]#[Y[YKZ XM[+q4R[a.RZ
- d/KOP_#N.MYK?RT[:fffRTS#KM,Z6]2RZ6br]#X^e_0[RT]ffZXKUTKPS0_#Z[:[Y]2[a6V
K "N6KPXVi*[aN.M`]ffZ'UTV_
brKPq W'RTKOQKM=]#bi*Z6] q4UTKc6f#K4a'_S#K4[Y]diK J%W'X]#W'_0fff_0[YKMc Lb1X]ff^
- [Y]
( d/KPbr]#XK_#Z.MYq:KPXRZ.f?[a6YK "N6KPXV#`
_#Z.chbr]#Xf#KP[Y[RZ.f_#UUT] q4M(b1]#XOa._0X _#OQ[YKPXRTgRZ6f[a.K^ K 6_#OQ[UTV#j
fiMKPS#]##KcRZ[a6K&RoZ[YX]*c.N.OQ[R]ffZB`"_#Z6]#[a.KPX3MOQKZ._0XRT]RZq4a.RO abr]#Xf#KP[Y[RZ6fhRMN.MYKPbN.U9RM4[a'_0[]#b
d/KURTKPb=N6WBc._0[YK#j3p%Z.c6KPKcB`i[a6KPXK_0XK^e_#ZVbr]#X^e_#URg_0[RT]ffZ.M]#b\d/KURTKPb=N6WBc._0[YK}[a._0[?_0XK2d'_#MYKc]ffZL_
br]#X^ ]#b\S0_0XR_0d'UK&br]#Xf#KP[Y[RZ.f6j&a.K&d"_#MRO2MOQKZ._0XR]RoM[a.Kb1]ffUU] q4RZ.f]ffZ6K C3q:Ka._S#K_br]#X^&N.UT
_ &
[a._0[XKPW.XKMKZ[M4]ffN6X*Z6] q4UTKc6f#K#i[a6KPXK&_0XK&M]ff^K}O a._#Z6f#KM3RZ[a.Kq:]#XUcB`'_#Z'cq4a'_0[q+K&*Z6] qRM
[a._0[&_0b1[YKPX&[a6K^ _b1]#X ^}N.Uo_ $ d/KOQ]ff^KM[YX N6K#jha6KMRo^W'UTKMY[3q(_V[Y]c6K_#U=qRT[aL[a6KN.W/c'_0[YKRM
[Y]_#MMN.^K}[a._0
[ $ XKPW.XKMYKZ[M_#UoUBq+K}Z.] q_0di]ffN.[[a6K[YX N6[aS0_#UN6K]#b[a.KS;_0X R_0d'UTKMRZ $\j fiM_
XKMN'UT[P`q:K3a._S#K?[YG
] J%br]#Xf#KP[ L2b1X]ff
^ & [a6KS;_#UoN6K]#b[a6K3S;_0XRo_0d'UTKM:RL
Z U, 6 $8 j=a.KPXK_0XKc.R iKPXKZ[
br]#X^e_#URTg_0[R]ffZ.M ]#b6[a.RoMMO a6K^e_*`0d'_#MYKc}]ffZqa6KP[a6KPXbr]#X^&N.U.
_ $hRMOQ]ffZ.MRc6KPXKc[Y]OP_0XXVRZ6br]#X^e_0[RT]ffZ
_0d/]ffN6[S0_0XR_0d'UTKM8RT[=^eKZ[RT]ffZ'MrJ RZ'MUTKP[Y[P=` #0]#X=]ffZ.UTV}]ffZ[a6K,S0_0XR_0d'UTKMR[8c.KPWiKZ'c.M]ffZ 4KPfffZ.KPX`
# `]#X=_#UoMY]3]ffZ2S;_0XRo_0d'UTKM9XKU_0[YKc2[Y]?c6KPW/KZ.c6KZ[9S0_0XR_0d"UTKMS*R_3_3c6KPW/KZ.c6KZ.OQK:bN.Z.OQ[RT]ffZ 4KPXgRTf6`
# ff j\a'RM*RZ.c&]#biN6WBc._0[YK,MOa6K^_*`ffq4a.RUK:UTKMM9*Z6] q4Z2[a._#Z2[a6K ]ffMMRd'UTK ]*c6KU/
fiW.W.X]ff_#O a2dV
J RZ.MUTKP[Y[[ #0 `/a._#M,W.X] S#Kch[Y]ed/K?MN.R[YKcb1]#X,XK_#M]ffZ.RZ6fe_0d/]ffN6[_#OQ[RT]ffZ'M ]ffa6KPX[VKP[4_#UIjT` #
KPXgRTB
f fi ER ` ##ff j'N6X[a6KPX^e]#XK#`[a6KW/]ffMMRTd'RUR[V[Y]br]#Xf#KP[URT[YKPX _#UMe_#Z.cLZ6]#[S0_0XR_0d"UTKM RM
_#UMY]3S0_#UN._0d'UK+RZ}[a.RMbrX_#^KPq:]#X[Y]?[_0#K_#OPOQ]ffN.Z[b1]#XW/KPXMRMY[YKZ[9RZ6br]#X^e_0[R]ffZB`#_#MMa6] qZ}XKOQKZ[UTV
dVMY]ff^K]#b4N.M KPXgRTfKP[_#UmjTff` 0# `\MRZ'OQK[a6KW/]ffU_0XRT[V]#bRZ6br]#X^e_0[RT]ffZRoM]#br[YKZ MRTfffZ.R OP_#Z[Pj
6]#X2RZ.MY[_#Z'OQK#`9q4a'RUTKbr]#Xf#KP[Y[RZ6f[a6K 'N.KZ[ 3 <%brX]ff^ _*Z6] q4UKc6f#Kd'_#MKRMZ.]#[W.X]#d"UTK^e_0[RO0`
br]#Xf#KP[Y[RZ6fe[a.K?WiKPX MRMY[YKZ[ 'N6KZ[:< 3 <%q+]ffN.UochMN6XKUTVd/KRZ._#c6WK "N._0[YK#j

Q I\

fi

~33



s~$w

~ww$

6]#Xf#KP[Y[RZ6f OP_#Z _#UM]d/KN.MYKc [Y] a._0X_#OQ[YKPXRgPK_ c6KPW/KZ.c6KZ.OQKXKU_0[RT]ffZ OP_#UoUTKc c6K Z._0d'RUR[V
5 @_#Z.f fi _0X,"N'RMP`N#;dih_#Mq+KUU?_#M[a6KMY[YX]ffZ.f#KMY[Z6KOQKMM_0XVrXKMYW j q:K_0#KMY[MN6OPRTKZ[
OQ]ffZ.c.R[RT]ffZ.M]#b:_W'X]#W/]ffMRT[RT]ffZ._#U S;_0XRo_0d'UTK]ffZ _MYKP[ U ]#b=S0_0XR_0d'UKM4fffRTS#KZ _[a6KP]#XV & 5@9RZB`0##*
]ffa6KPX[V#
` @N.;_#MYgPKPqROQg#` fi g_#U_#MP`90# j fiMMa6] q4Z RZ 5@_#Z6fBfi _0X,"N.RMP` #;d @RoZB` 0##*
]ffa6KPX[V}KP[_#UmjT` 0# `_#UU[a.KMYK,Z6]#[RT]ffZ.Ma._S#K^_#ZV&_0W.W'UROP_0[R]ffZ.MRZ}S0_0XRT]ffN.M fip KUc.M`;RZ'OPUN.c.RZ.f
aVW/]#[a6KMRoM,c.RMOQXRo^eRZ._0[RT]ffZ `_0f#KZ[OQ]ff^e^&N.Z.ROP_0[R]ffZB`6[a6KP]#XVh_0W.W.XW] 6R^e_0[RT]ffZh_#Z.c_0d/c'N.OQ[RT]ffZBj
8RZ._#UoUTV#`d"_#MYKch]ffZhURT[YKPX _#Ui_#Z'cS;_0XRo_0d'UTKb1]#Xf#KP[Y[RoZ6f6`6S;_#UoN._0d'UTK3WK "N.RTS0_#UTKZ.OQK3XKU_0[RT]ffZ'M+] S#KPX4br]#XY
^&N.U_#MOP_#Z_#UoMY]ed/K?c6K Z6Kc C

" yC %qsa1nz3q{ ; q pz3r %qa#1nz3q{ ; q(' uPv &1
P u:v| ! M!0w xN/*T;w[!#x=

1
(Pu2I/=PQPuPv [! +(* 1:0z"t U P u2e /=PPuv1![?
fi
& 0z"t
0 wu}Q#ytv !TPu @9RT[%IKW"N'RTS;_#UKZ[3{#yr0uQz)( 1+tuQz!#vut &
1=y #z"tT!0z. 4y
&'")(%+* ( 3 *P & % ( 3 *P & '(:.&'")(%+* ( 3 *P
% ( 3 *P
T(:
u S=_0XYIWK "N.RTS0_#UTKZ[3{ffy1#uQz U 1(tuQz!ffvut & 3$
1=y #z"t+!0z. 4y
& 0z"t
0wu}Q#yt v !TP.
&'")(%+* U, . & % U . & U& .&'))(%+* U, 6
% U .
U&

!

q m{uw{

SP4/S?I V20z"t

z3v <q k uPv & ! )
0z"t
0wu v5OYu M/*yr;0uQz'v8{#yr0uPzb(



!

e4/:e V uvX(

!#):< % V + &

*N'OaWK "N.RS;_#UTKZ'OQK}XKUo_0[RT]ffZ.MOP_0W.[N6XK2MY]ff^K2br]#X^eM]#b\c6KPW/KZ.c6KZ.OQK}d/KP[q:KPKZ b1]#X^&N.U_#Mja6KPV
0_ XK4N'MYKPbrN'URoZ2[a6K,S;_0X RT]ffN.MMRT[N'_0[RT]ffZ.M8q4a6KPXKRT[RM8XKW"N.RTXKc2[Y]br]#X^e_#UoUTVOa'_0X_#OQ[YKPXRTgPK[a6K,br_#OQ[\[a._0[
[q:]Z.] q4UTKc.f#K}d'_#MKMMa'_0XK&M]ff^K}[a.KP]#XK^eMPj3aN.MP`'[q+]br]#X^&N.U_#M_0XK @9RT[%IKW"N.RTS0_#UTKZ[4fffRTS#KZ](
q4a6KZ.KPS#KPXKPS#KPXVLOPU_#N.MYKOQ]ffZ[_#RZ.RZ.fURT[YKPX_#UMbrX]ff^ ( ]ffZ.UTVRoM?_hUT]#fffROP_#U=OQ]ffZ.MWK "N6KZ'OQK]#b+[a6K XMY[
br]#X^}N'U_Rb=_#Z.c]ffZ.UTVRTb+RT[RoM_UT]#fffRoOP_#UOQ]ffZ'MYWK "N.KZ.OQK2]#b\[a6KMYKOQ]ffZ.c br]#X^&N.U_*j3p%Z[a.K2M_#^K2S#KRZB`
[q:L
] S=_0XYIWK "N'RTS;_#UKZ[br]#X^&N.U_#M,fffRS#KZ U a._ S#K[a6K&M_#^KOPU_#N'M_#UOQ]ffZ.MWK "N6KZ'OQKM4d'N'RUT[,N6WbrX]ff^ Uej
?(UTK_0X UTV#` @RT[%IWK "N.RTS0_#UTKZ.OQKRM^]#XK Z6KQIf#X_#RZ.Kc [a._#Z S=_0XYIWK "N'RTS;_#UKZ.OQKRZ [a6KMYKZ'MYK[a._0[[q:]
br]#X^}N'U_#M S=_0XYIWK "N.RTS0_#UTKZ[fffRTS#KZ U _0XK_#UMY'
] @RT[%IWK "N.RTS0_#UTKZ[fffRTS#KZ (-!Q(*$(`8[a6KMYKP[]#b4UoRT[YKPX_#UM
d'N.RoUT[?N6W/]ffZ U`d'N6[?[a6KOQ]ffZS#KPX MYKc6]KMZ.]#[a6]ffUcRoZ [a6Kf#KZ6KPX _#U\OP_#MYK#j ]ff^K_0W'W'UROP_0[RT]ffZ'M_0XK
XKU_0[YKc[Y]*Z6] q4UTKc6f#K_0W'W.XW] 6R^e_0[R]ffZ
RoM_OQ]#XXKOQ[_0W.W'XW] 6R^e_0[RT]ffZ]#1b & ] S#KP6
X ( RTb8_#Z.c]ffZ.UV
RTb
_#Z.c & _0XN
K @R[%IWK "N.RS;_#UTKZ[4fffRS#K
Z (( `iZ.]#X^e_#URTg_0[R]ffZ r[N6X Z.RZ6f_br]#X^}N'UL
_ & RZ[Y]_ ?54

dVRZ[YX]*c.N.OPRZ6fZ6KPq MYV*^d/]ffUMRM?_#OPOQKPW.[_0d"UTKe_#M?UT]ffZ6fh_#M3[a6K[q+]hbr]#X^&N.U_#M3_0XKWK "N.RTS0_#UTKZ[3] S#KPX
[a6K]#X RTfffRZ._#U/U_#Z6fffN'_0f#K#`'RmjK#jT` & _#Z'c
_0XV
K S=_0XYIWK "N.RTS0_#UTKZ[fffRTS#KZ U-! U 6 &4Y `'_#Z.cMY]]ffZ j

l87 J

uv

<mq



[q

p[2RoM "N.RT[YKK_#MYV [Y]LW.X] S#K[a'_0[b1]#Xf#KP[Y[RoZ6fLRM2_LOQ]ff^W'N6[_0[RT]ffZ'_#UUTVK*W/KZ.MRTS#K]#W/KPX_0[RT]ffZ RZ [a6K
f#KZ6KPX_#U:OP_#MYK#jpZ'c6KPKcB`MRZ.OQK_br]#X^&N.U_'& RM}OQ]ffZ.MRMY[YKZ[2RTb_#Z.c]ffZ'UTVRTb &'))(%*( 3 *P & % ( 3 *Q &4Y
RM2OQ]ffZ.MRoMY[YKZ[_#Z.c MRoZ.OQK[a.KU_0[Y[YKPXbr]#X^&N.U_RMN@RT[%RoZ.c6KPW/KZ.c6KZ[brX]ff^ KPS#KPXV UR[YKPX_#URIjK#jT`+RT[2RM
KW"N.RTS0_#UTKZ[9[Y]* f +]#XWK "N.RS;_#UTKZ[[Y3
] :) `0[a6KPXK+RMZ6]4q(_V[Y]3OQ]ff^eW'N6[YK+_br]#X^}N'U_
LWK "N.RS;_#UTKZ[
[Y] &'))(%* ( 3 *Q & % ((3RZW/]ffUTV*Z6]ff^eR_#U9[R^K#`N'Z.UTKMM ! 9j fiOQ[N'_#UUTV#` q:KeOP_#Zc6KPXRS#K&[a.Ke^]#XK
OQ]ffZ.MY[YX _#RZ.RZ6f3XKMN.UT[P`ffMa6] q4RZ6f3[a._0[\[a6K3 Fy E u]#bi_#ZV2b1]#X^&N.U_WK "N.RTS0_#UTKZ[[Y],&')"( * ( 3 *P & % (:^e_V
d/KMN6W/KPXW/]ffUTV*Z6]ff^eR_#UoUTV&Uo_0Xf#KPX[a._#Zh[a.KMRTgPK?]#b &j


=<

ru uwuw{

7H

uPv1& P u !#w xN/* w[!0x


3
% 0z"tuPvX( P u
=z.yvu& /=PPuvY![3(R

u W/*y100TuPz'v,v ! &'")(%+* ( 3 *P & % :
( } ov

zvr~*u}{uPziuQwY0 0Pu$1vr~*uPwYuey1}z!N-"w[! -G!; yvy0!0z"0!0wxN/*
QQ

fif.w~3}33f$3ws

vr~*ue yFE u%![
yo.-G!0 40z!0x2y#1 4 P,!D/*z"tutyrz &ABA (A 1 /*z.u fi
,!#z6 ymtuQwuT
/z'
#uP 4eyrz ,!0x.-"u32ffyrv54vr~*u,!0wI4 K

JI|8~y0Q~Ly1

a'RMXKMN.UT[?Ma.] q4M3[a._0[OQ]ff^eW'N6[RZ6fh_#Z K*W'UROPR[XKPW'XKMYKZ[_0[RT]ffZL]#b &')"( *( 3 *P & % (:N'Z.c6KPX
[a6Kebr]#X^ ]#b(_W.X]#W/]ffMRT[R]ffZ._#Ub1]#X^&N.U_RMa._0Xc `KPS#KZ RZ_OQ]ff^W"RU_0[RT]ffZ*Id"_#MYKc_0W.W.X]ff_#Oaqa6KPXK
[a6K[Ro^KZ6KPKc6Kch[Y]c6KPXRTS#KMN'Oa_br]#X^&N.U_2RMZ.KPfffUTKOQ[YKcBj
8RZ._#UoUTV#`*q+Ka'_S#K}_#UoMY]ec6KPXRTS#Kc C
=<
#(0 / '


" ; uv

7


)ff


ru uwuw{



<mq u=>)yC fi pz3r %qa#1nz3q{ ; q('
0z"t fi 2 0 /'
ff)
0 wYu fi - ,!0x.-"uPvu

RG B3:H H6r}O B? F#H]}O B
p%Z[a'RM(MYKOQ[RT]ffZB`*q:K3Ma6] q [a._0[,MYKPS#KPX _#UBZ6]#[RT]ffZ.M:]#b9c.KPWiKZ'c6KZ.OQK3RZ[YX]c.N'OQKcRZ[a6K?UR[YKPX_0[N6XK3_0XK
KW"N.RTS0_#UTKZ[4[Y]6`i]#X3OP_#ZdiK}KW'XKMMYKcRZ[YKPX^M4]#b`iMK^e_#Z[RoOP_#U9RZ'c6KPW/KZ.c6KZ.OQK#j:pZW'_0X[ROPN'U_0X`.q:K
Ma6] q [a'_0[ A:]ffN6[RUoRTKPX+ M4c.K Z.RT[RT]ffZ]#b\R Z 'N.KZ.OQK_0d'RUR[V5 A:]ffN6[RoURTKPX` # <RM4RZbr_#OQ[WK "N.RTS0_#UTKZ[[Y]
MYK^e_#Z[ROP_#U1\ S4c.KPWiKZ'c6KZ.OQK#ja6Kc6K Z.RT[R]ffZ2]#bBXKUTKPS0_#Z.OQK_#M+fffRTS#KZdV @9_0#K^KPV#KPX[ # #:OP_#Z
_#UMY]d/K\W.X] S#Kc2[Y]diK:WK "N.RTS0_#UTKZ[9[Y]? Sc6KPW/KZ.c6KZ'OQK#j Z.K+]#b.[a.K+[q+]?c6K Z'RT[RT]ffZ.MfffRTS#KZ&dV @9_0#KQ
^KPV#KPX[ # #b1]#X3MY[YXRoOQ[XKUTKPS0_#Z.OQK2OP_#Z_#UM]d/KK *W.XKMMYKcRZ[YKPX ^eM4]#b= Sc6KPW/KZ.c6KZ.OQK#j4a6KMYK
XKMN'UT[M_#UUT] q b1]#X Z.c.RZ6f[a6KOQ]ff^W"UTK *R[V&]#bi_#UU*[a.KMYK,b1]#X ^eM8]#bBc6KPW/KZ.c6KZ.OQK(_#M\_?c.RXKOQ[=OQ]#X]ffUU_0XV
[Y][a.KOQ]ff^W'UK *RT[V XKMN.UT[MXKPW/]#X[YKcRZL[a.KW.XKPS*RT]ffN.MMYKOQ[RT]ffZBj6]#X&[a6KM_0#K]#bOQ]ff^W'UTKP[YKZ.KMMP`
q:K}_#UMY]fffRTS#K[a.K}OQ]ff^W'UK *RT[Vh]#b[a6K]#X RTfffRZ._#UBc6K Z.RT[RT]ffZh]#b=M[YXROQ[XKUKPS;_#Z.OQK5 @_0#K^KPV#KPX ` # ff
rq4a.RoOaLRMZ.]#[c.RTXKOQ[UVXKU_0[YKc[Y] S4c6KPW/KZ.c.KZ.OQK `q4a'ROa [N6X Z.M?]ffN6[?[Y]d/KeOQ]ff^W"N6[_0[RT]ffZ._#UUV
MR^eW'UTKPX([a._#Zh[a6K}MN6d'MYWK "N6KZ[,c6K Z.RT[R]ffZfffRS#KZdL
V @9_0#K^KPV#KPX2[ # # j
ff8AC;D fi

ml k {m#q{ ; qz$m'
A:]ffN6[RURKPX2[# <RZ[YX]c.N'OQKM_Z6]#[RT]ffZ ]#b:RZ 'N.KZ.OQK_0d'RUR[V#jE]ffN6fffa.UVMYW/K_0RoZ6f6`B_br]#X^&N.U_T&sRM
R Z "N6KZ.OQK_0d'UTKb1X]ff^ _MYKP[,]#bS0_0XR_0d'UKM U RTb [a.KPXK?K*RoMY[M,_2MOQKZ._0XRT]eRoZqa.ROa[a6K3[YXN.[aS;_#UN.K]#b
& c6KPW/KZ.c'M+]ffZ[a6K?S0_#UN6K?]#b8[a6K?S0_0XR_0d'UTKM,RoZBUej=4a.RM,Rc6K_OP_#ZdiK?br]#X^e_#UoRTgPKch_#Mbr]ffUUT] q4MPj
/=PPuv.![
k " '{<q{ ; qsz3'' ' uPv & PuVM!0wxN/T w !0x
3
0 z"t+U
& y1RZ'N6KZ.OQK_0d'UK w[!0x U 0 z"t6!#z. 4 vr~*uPwYu u32ffyoQvr ]
fi NU O| 0! wTtG= 10z"t v| !
U O| 0! wTt;D= ( 0z"t,= - 1v 6=/
= ( ! & 0 z"t=/= - !O: &~ff!0Tt


fi

!

q m{uw{

p%Z ]#[a6KPXq:]#Xc.MP`[a6KPXKLRM_ MOQKZ._0XR] = RZ q4a.RoOa [a6K b1]#X ^}N.Uo_ & OP_#Z d/K[YXN6K ]#Xhb_#UMYK#`
6c KPW/KZ.c.RoZ6f]ffZ[a6KS;_#UN.Ke]#b([a6KS0_0XR_0d'UKMRZ UejJ a.RoUTKeRZ 'N.KZ.OQK_0d'RUR[VU]]#*Mc.RiKPXKZ[?brX]ff^
[a6Kc.K Z.RT[RT]ffZ'MfffRS#KZRZL[a'RM3W'_0W/KPX`9R[OP_#Zd/KeMa6] q4Z[a._0[}RZ br_#OQ[&RZ 'N.KZ.OQK_0d'RUR[VOQ]ffRZ'OPRc6KM
q4RT[ah Sc6KPW/KZ.c6KZ.OQK#j
uPv & Pu M!0w xN/*T w !0x7
3
% 0z"t U I/=PQPuPv![
fffi B& yoeyrz /ffO
uQz u PQu1 w !0x U #z"tT!0z. 4y .& yo .0w OYtuR-6uPz"tuPz'v !0zBU
=<



ru uwuw{

7



fiM2_OQ]ffZ.MKW"N6KZ'OQK#`=_^e]c6KUTI[a6KP]#XKP[ROOa._0X_#OQ[YKPX RTg_0[RT]ffZ ]#b4RZ'N6KZ.OQK_0d'RoURT[V OP_#Z d/KK_#MRUV
c6KPXRS#KcLb1X]ff^ [a6Ke]ffZ6Kb1]#X&SRZ.c.KPWiKZ'c6KZ.OQK#ja.KeOQ]ff^W'UTK6RT[V ]#b,RZ "N6KZ.OQK_0d'RUoRT[VRoM_#ZLK_#MYV
OQ]#X]ffUUo_0XV[Y][a.RM(W.X]#W/KPX[VC ) fi ' )ff
ff
# RoM .OQ]ff^W"UTKP[YK#j

Q

fi



~33

s~$w

~ww$

8l 7 Kqqnz3{ ; q
@_0#K^eKPV#KPX}[#`##:RZ[YX]*c.N.OQKM:MYKPS#KPX_#U/br]#X^eM:]#bXKUKPS;_#Z.OQK#jJLK?Ma.] q a6] q [a.KMYK3b1]#X^M+]#b
XKUTKPS0_#Z.OQK_0XKeMY[YX]ffZ6fffUTVXKUo_0[YKc [Y] SRZ.c.KPWiKZ'c6KZ.OQK#jJLKe_#UM]OQ]ff^eW'UTKP[YK[a6K2XKMN'UT[MfffRTS#KZLRZ
5 @_0#K^eKPV#KPX` # # `dVK 6a.RTd'R[RZ6f[a.KeOQ]ff^W'N6[_0[RT]ffZ'_#UOQ]ff^W'UTK 6RT[V]#b:K_#Oabr]#X^ ]#b:XKUTKPS0_#Z.OQK
RZ[YX]*c.N.OQKchRZ5 @9_0#K^KPV#KPX` # # j

! '


# $# # 2
@_0#K^eKPV#KPX+ M,Z6]#[RT]ffZ]#b XKUTKPS0_#Z.OQK]#b_br]#X^&N.U_[Y]&_&MN6dGFYKOQ[(^e_0[Y[YKPX,OP_#Zd/Kc6K Z6KcRZe[YKPX^M+]#b
W.XRo^K?R^W'URoOP_0[YKM(]#b9[a6Kb1]#X^&N.U_*`._#Mb1]ffUU] q4MMKPK K Z.RT[RT]ffZeRT
Z @_0#K^KPV#KPX `##IC
q!m{uw{ k'k " rqqnz3{ ; q u z fiffq ; [vxzqsr' uPv & Pu M!0wx /*T w !0x
3
%0zit
U I/=PuPv ![c
fi & y1XKUTKPS0_#Z[&[Y] U h0z"t !0z. 4y vr~6uQwu,u 2#y1vrL
-"w yrxuyr.
x -"
0y ffvB
u ![ &
xuQz'vy0!0z.yrz{h;#w ymQPQu [w !#
x U





z3v

/)ff
1 fi fi 132 'ff

<q k

# 1

uPv &"! /)V#z"t U$! # % >S +Y& yowuQuQ00z'v(v ! U,

fiM_OQ]ffZ'MYWK "N.KZ.OQK#` @9_0#K^KPV#KPX+ M&Z6]#[RT]ffZ]#b:RTXXKUTKPS0_#Z.OQK]#b,_hb1]#X ^}N.Uo_[Y]_MN.dGF%KOQ[^_0[Y[YKPX
OQ]ffRZ.OPRoc6KM(q4RT[ah SRZ.c6KPW/KZ.c6KZ'OQK#j


uPv & P u&.!0wxN/* w[!#x2

0z"t U /PQPuv ![/
fffi &y1wuQuQ;#z'v
ru=<uwuw{ 7
v ! U 0z"tT!0z. 4y & oy .# wIOYtuR-.uQz"tuPz'v !0zBU


aN.MP`[a.K^e]c6KUTI[a6KP]#XKP[ROOa'_0X_#OQ[YKPXRTg_0[RT]ffZ ]#b S4RoZ.c6KPW/KZ.c6KZ.OQK_#UMY]L_0W.W"URTKM}[Y] RXXKUTKQ
S0_#Z.OQK2]#b\_b1]#X^&N.U_[Y]h_MN.dGF%KOQ[3^e_0[Y[YKPXj?JLK_#UM]a._ S#K[a._0[[a6KRTXXKUTKPS0_#Z.OQK}]#b\_b1]#X^&N.U_[Y]
_eMN.Gd F%KOQ[^_0[Y[YKPXOQ]ffRZ'OPRc6KM(q4RT[T
A:]ffN6[RoURTKPX+ M,c6K Z.RT[RT]ffZ]#b8R Z 'N.KZ.OQK_0d'RUR[V#j8RZ._#UUTV#`*[a6K}_0di] S#K
W.X]#W/]ffMR[RT]ffZ_#UUT] qM(b1]#X4_#ZK_#MYVW'X]]#b]#b8OQ]ff^W'UTK 6RT[Vbr]#XXKUTKPS0_#Z.OQK#`.Z._#^KUV#` 2 / )ff
1 fi-
fi 132 ' # 1 ;! '

# $ # # 2 RM .OQ]ff^W"UTKP[YK#j

! 'ff

# $# # 2
@_0#K^eKPV#KPX4a._#M:RZ[YX]c.N'OQKc[q+]2br]#X^eM:]#bvwy0vwuQuQ00z uPj=a6KOa6X]ffZ6]ffUT]#fffROP_#UUV6 XMY[+]ffZ6K3a._#M
d/KPKZhfffRTS#KZRoZ5@_0#K^KPV#KPX` #ff `"_#M4b1]ffUoUT] q4Mj
k ' uPv & Pu
q!m{uw{ kff7 " rff ; rqqnz3{ ; qu z fiffq ; Kv zqsr #y?zwqvxq qsr
M!0w N
x /*TN
w !0x
3
% 0z"t U /PQPuv ![
fi & y1MY[YXROQ[UTV XKUKPS;_#Z[[Y] U 0z"t !0z' 4y
uQ#uQw 4-"wy1xu&yr.x -"5y #vu ![ & ,!#z'vI0yrz6&;0wymQ PQ1u w !0x U,
@9_0#K^KPV#KPXa._#M_#UMY]LRZ[YX]c'N.OQKc _#Z6]#[a6KPXZ6]#[R]ffZ ]#bMY[YX ROQ[2XKUTKPS0_#Z.OQK5 @_0#K^KPV#KPX ` # # `
^]#XK}c6K^e_#Z.c.RoZ6f}[a'_#Zh[a6K]#XRfffRZ._#Ui]ffZ6K#j KPXKq:KOQ]ffZ.MRoc6KPX_#ZWK "N.RTS0_#UTKZ[c6K Z.RT[R]ffZBj
# 2


# 2 /)ff
1 fi fi 132 'ff

# 1

k (' uPv& P u
q!m{uw{ k H " rff ; rqqnz3{ ; qu z fiffq ; Kv zqsr #y?zwqvxq qsr
M!0w xN/*TN w !0x
3
0z"t U /PQPuv ![
fi & 1y MY[YXROQ[UTV XKUKPS;_#Z[[Y] U 0z"t !0z' 4y
vr~*uPwYu?u,#2 y1vr4 -iw yrxuyrx.-"y5 #vu![1& xeuPz'vy0!0z.yrz{200w ymQ PPTuw[!#x U 10z"t2uQ#uQw 4 -"wy1xuyrxY-i
y0#vu
![ & xuQz'vy00! z6N!0z. 4;#w ymQPQu1 w !0x U,

Q

fif.w~3}33f$3ws

A:]#[ac6K Z.RT[R]ffZ.MW.XKPS#KZ[\[_#N6[Y]ffUT]#fffRKM+_#Z.cOQ]ffZ[YX_#c'ROQ[Y]#XVbr]#X^}N'U_#MbrX]ff^d/KRZ6fMY[YX ROQ[UTV&XKUTKQ
S0_#Z[=[Y]}_#ZV2MYKP[=]#biS;_0X R_0d'UTKMPj8a6K(d'_#MRO,c.R:/KPXKZ.OQK(d/KP[q:KPKZe[a6KMK[q:]c6K Z'RT[RT]ffZ.M8RM8[a._0[+RZ2[a6K
XM[\]ffZ6K3q:Kq(_#Z[:[a'_0[+KPS#KPXVW.XR^eKR^W"UROP_0[YK4]#b & OQ]ffZ[_#RZ.M?#v=Tu;vB_}S;_0X R_0d'UTKb1X]ff^ Ue`*q4a.RUTK
RZ[a6K&MKOQ]ffZ.c OP_#MYK2q+K2R^W/]ffMYK}[a._0[KPS#KPXVW.XR^eK}R^W"UROP_0[YK]#b & ^&N.MY[3OQ]ffZ[_#RZ !0z' 4}S;_0XRo_0d'UTKM
brX]ff^ U > 7j fiM,[a.Kb1]ffUoUT] q4RoZ6f2K *_#^W"UTKMa6] q4MP`6[a6KPXK_0XKb1]#X ^}N.Uo_#M(b1]#Xqa.ROa[a.K[q:]c6K Z'RT[RT]ffZ.M
]#bMY[YXROQ[,XKUTKPS;_#Z'OQKc6]Z6]#[OQ]ffRZ'OPRc6K#j

uPvV& ! HKSQ0z"t U ! # + ~*uQwuy1 !0z. 4#!#ziu -"wy1xuyrx.-"
y0ffvu ![L&1
z"0xuP 4+HS .y1z uyrv ,!0z'vI#y1z6#v\Tu;v:e00wyQPPTu ![YU 1=yrv!0r !0|8vr~#v &y1Qvw y0v 4ewuQuQ;#z'v
v !%U | ow1v J #uPxu4 uQw 1 K !0|+uP0uQw 1( yrz uvr~*u-"wy1xuy1x.-"y0#vu, H_Syo&z!#v ,!0x.-G!;ut
]ffZ.UTV]#b400wyQPPTuQ ![VU J P u3 D/Pu3S ) 4 U K 1\yv !0r !0|8&vr~ffv & y1z!#v+Qvw y0v 4wuQuQ00z'v,v ! U | ow ov
J #uPxu4uQw 1 [K


z3v

<q k



a.X]ffN6fffa SRZ.c6KPW/KZ.c.KZ.OQK#` q:K+OP_#Z2c6KPXRS#K\_#Z}_#U[YKPXZ._0[RTS#K:Oa._0X_#OQ[YKPX RTg_0[RT]ffZ&]#b6[a6K+Z.]#[RT]ffZ]#b
vwy0v=wuQuQ00zu(RZ[YX]c'N.OQKcdV @9_0#K^KPV#KPX&[## j:p%Z.c6KPKcB`*_#M,_MY[YX_#RTfffa[Ybr]#Xq:_0X cOQ]ffZ'MYKW"N.KZ.OQK
]#b8[a6Kc6K Z'RT[RT]ffZB`q+K}a._S#K C
I/=PuPv ![6
fi & y1Qvw y0v 4
uv & Pu!#w xN/* w !0xQ

0zit%U
wuQuQ;#z'v9v !VU 40z"tN!0z. 4&y & yo .0w OYtuR-6uPz"tuPz'v !0z U 0 z"t .0w Oyrz"t u -6uQzituQz'vffw[!#x U,. & U
=<



ru uwuw{

7







J K&a._S#K&Rc6KZ[R Kc[a6K&OQ]ff^W'UTK6RT[V]#b8d/]#[ac6K Z'RT[RT]ffZ.M:]#bMY[YXROQ[4XKUTKPS0_#Z.OQK#`"_#Z.c[a6KPV[N6XZ
L
]ffN6[[Y]diK?c.RiKPXKZ[MC=[a6K XMY[c6K Z'RT[RT]ffZRM,a._0Xc.KPX[a._#Zh[a6KMKOQ]ffZ.c]ffZ6K#j

ru=<uwuw{ 7 " ; uv <mq u=>)r ; [rqqnz3{ ; q('
JK! # 2
# 2 /)ff
1 fi- fi 132 ff' # 1 ! 'ff

# $# # 2 J #uPxeuM4uQw 1 Ky1
fi - O[I!0x.-"Tuvu
J WG
K ! # 2
(# 2 /)ff
1 fi fi 132 ff' # 1 ! '


B
# D$# # 2 J #uQxuM4ffuPw 1 [K y1
" - O[I0! x."- uPvu


a.KMYKOQ]ff^W'UTK6RT[V XKMN.UT[MhR^eW.X] S#K4a6KP]#XK^ 0 b1X]ff^ 5@_0#K^KPV#KPX`L## `q4a'ROa ]ffZ.UV
W/]ffRZ[M]ffN.[[a.K 'a._0Xc.Z6KMM3]#b\RTXXKUKPS;_#Z.OQK2_#Z.c MY[YXRoOQ[3RXXKUTKPS0_#Z.OQK2_#M?c6K Z6KcRZ 5@_0#K^KPV#KPX `
# # j
F \G
-$mf 0HIE
p%Z [a'RM2MYKOQ[RT]ffZB`=q:K XMY[2c.RMOPN.MM}]#[a6KPXXKU_0[YKc q:]#Xi`=[a6KZ YM ]ff^KW/]ffMMRTd"UTKK*[YKZ.MRT]ffZ'M}]#b[a6K
Z6]#[RT]ffZ'M_#Z.cXKMN'UT[M,q:Ka._S#K}W.XKMYKZ[YKchd/KPb1]#XK#j

-$ ]
l'Ffiff E

8A




ml k NZ*?#qsr [qzq%L uwr
fiM&_#UXK_#c6VKPS#]##KcB`(RZ.c.KPWiKZ'c6KZ.OQKa._#M&d/KPKZ OQ]ffZ.MRc6KPXKc N'Z.c6KPXS0_0XRT]ffN'M}br]#X^eM2RZ S0_0XRT]ffN.Mfi4p
KUc'MPj

Dz} -z}u|u ffu+RffO$ $puTu'Uu z rn *-y |~|y lu+syx#ffc}yluT:z}y ff |ffz}u|{}u~}y3 ffUz}yp|| | fi
$8y }|uz n !ff !#"6z%$& n&''( *o


Q 6

fi

~33



s~$w

~ww$

) ) ff )ff
)

2 1 1 ! # 1 ) ff 1

a6KPXK&_0XK]#[a.KPX?b1]#X^M]#b:RZ.c6KPW/KZ.c.KZ.OQK}RZW.X]#Wi]ffMRT[RT]ffZ._#U9UT]#fffRO&[a._0[3q+Kea'_S#KeZ6]#[?OQ]ffZ.MRoc6KPXKc
RZ[a.RM_0X[ROPUTK#`8KMYW/KOPR_#UUTV#`8c6K Z'_0d'RURT[V#`9OQ]ffZ[YX]ffUU_0d"RURT[V 5 @9_#Z6f fi _0,X "N.RMP` # ;di}_#Mq:KUU:_#M
OQ]ffZ.c.R[RT]ffZ._#U#RZ.c.KPWiKZ'c6KZ.OQK 3_0Xq4RO a6K# ` # # jpb Al` C _#Z.c _0XK\[a6XKPK\c.RoM F%]ffRoZ[ MYKP[M]#b*S;_0XRo_0d'UTKM
_#Z.c & RM_*Z6] q4UTKc6f#K}d'_#MYK[a.KZ _#Z.
c C _0XK&OQ]ffZ'c.RT[RT]ffZ._#UoUTVRoZ.c6KPW/KZ.c6KZ[(qjXj[Pj *Z6] q4RZ6f
& RTb_#Z.c]ffZ.UVRbbr]#X3_#ZV Iq:]#XUc = ff8`i]ffZ.OQKq:K}*Z6] q = ff _#Z.c & `iUTK_0XZ.RZ.fMY]ff^KP[a.RoZ6f_0d/]ffN6[
OP_#Z.Z6]#[^e_0#K N.MhUTK_0XZ _#ZV[a'RZ6f Z6KPq _0d/]ffN6k
[ C _#Z.c 5y uL#uQw Q j a6KLOQ]ff^W'N6[_0[R]ffZ._#U
RMMN6KM2W/KPX[_#RZ.RZ.f[Y] OQ]ffZ.c.RT[RT]ffZ'_#U,RZ.c6KPW/KZ.c6KZ'OQK_#Z.c [Y] MY[YX]ffZ.f#KPXZ6]#[RT]ffZ'Me_#Meq:KUU,_#MeXKU_0[YKc
Z6]#[RT]ffZ'M:MN.Oa_#M(XKUTKPS0_#Z.OQK3d/KP[q:KPKZhMN6Gd FYKOQ[(^e_0[Y[YKPXM5 @9_0#K^KPV#KPX` # #(_#Z'cZ.] S#KUT[V
XKRZ6KPX
fi
3KZ6KMYKPXKP[aB ` `a'_S#K\d/KPKZK [YKZ.MRTS#KUTV?MY[N.c.RKcRZ_OQ]ff^W'_#Z.RT]ffZW'_0W/KPX+5 @_#Z6f6` @9RTd/KPX_0[Y]#XK#`
fi_0,X "N.RMP` 0# ff j



#

/ )
# ) )ff

KPS#KPX_#U6_0W'W.X]ff_#Oa.KM8[Y]?diKUoRTKPb.Oa._#Z.f#K^e_0#K,N.MYK(]#b"_K*W'UROPRT[c6KPW/KZ.c6KZ.OQK:XKU_0[R]ffZB`0q4a.RO a&^eK_#Z.M
[a._0[RT[(RM:W'_0X[(]#b9[a6K?RZ6W'N6[3rq4a.RUK]ffN6X M:RoM:Ro^W'UROPR[P`RmjK#jT`6c6KPXRS#KcbrX]ff^ [a6K?RZ.W'N6[ jaN.MP`*OQ]ff^2
W'N6[RoZ6fRZ.c.KPWiKZ'c6KZ.OQKhXKU_0[R]ffZ.MbrX]ff^ _*Z6] qUTKc6f#Kd'_#MYKOP_#Z d/KMKPKZ _#M_#Z N6W'MY[YXK_#^ [_#MY
KZ._0d'UoRZ6fN.M}[Y]LMYW/KOPRTbrV[a.K JYOQ]#XDK L ^eRoZ.R^e_#U1?RZ.c6KPW/KZ.c6KZ'OQKXKU_0[RT]ffZ N6W/]ffZq4a'ROa [a6KdiKUoRTKPb
Oa'_#Z6f#K2]#WiKPX _0[Y]#XRM4d"_#MYKcBB[a.RMOQ]#XKRZ.c.KPWiKZ'c6KZ.OQKXKUo_0[RT]ffZ OP_#Z[a.KZd/K2OQ]ff^W'UTKP[YKcdVMYW/KO
RTbrVRoZ6fK *W'UROPR[UTVMY]ff^K_#c.c'RT[RT]ffZ._#U:c6KPW/KZ.c6KZ.OPRKM}N.MRZ6fZ6] q4UTKc6f#Kh_0d/]ffN6[2[a6Kc6]ff^_#RZBX
j *N'Oa
_#Z_0W'W.X]ff_#Oa a._#MdiKPKZW.X]#W/]ffMYKcbr]#Xd/KURKPb\XKPS*RMRT]ffZLRoZ ._0X R Z' _#M}c6K1U ?:KPXX] fi 4KPXgRTf6` # ff `
br]#Xd/KURKPb=N6WBc._0[YK}RZ ; _0,X "N.RMP` # <3_#Z.c KPXgRTf6` # ff_#Z.cbr]#XXK_#MY]ffZ.RZ6f_0d/]ffN6[3_#OQ[RT]ffZLRZ
KPXgRT%
f fi ER ` ##ff j


ff
fi ) ) ff )ff


/)
1 )*# # !
?:]ffZ[YK[N'_#U,XK_#MY]ffZ.RoZ6f
?a.Rc.RZ'R fi
3RoN.Z.Oa'RTfffUR_*`ff0# 2a._#M2d/KPKZ RZ[YX]*c.N.OQKc br]#Xb1]#X^_#URTgRZ6f
c6]ff^e_#RoZ.MRZ2q4a.RoOa*Z6] qUTKc6f#KOP_#ZZ'_0[N6X_#UUTV}d/K(c'RTSRoc6Kc2RZ[Y]W'_0X[M4OQ]ffZ[YK[M j\\_#O aOQ]ffZ[YK[:RM
Oa'_0X_#OQ[YKPXRTgPKchdVRT[M(] q4ZU_#Z6fffN._0f#K?_#Z.c_#UTW"a._0d/KP[Pj84a6K3Z6] q4UTKc6f#Kd'_#MYK3]#b_&OQ]ffZ[YK *[4OQ]ffZ[_#RoZ.M
q4a._0[3RMXKUTKPS0_#Z[3[Y]_W'_0X[]#b=[a6K2c6]ff^e_#RZBj] q:KPS#KPX`RT[3RMZ6]#[fffN'_0X_#Z[YKPKc [a'_0[[a.K&c.R iKPXKZ[
W'_0X[M&]#b[a6Khc6]ff^e_#RZ c6]LZ6]#[RZ[YKPX_#OQ[P`\MY]LRZ.b1KPXKZ'OQKRZ ]ffZ6KhOQ]ffZ[YK [e^_V diK_ /KOQ[YKc dV [a6K
*Z6] q4UKc6f#K?]#bMY]ff^K]#[a6KPXOQ]ffZ[YK *[Pj
a.K^e_#RZ c.R iKPXKZ'OQKd/KP[q:KPKZ OQ]ffZ[YK [N._#UXK_#MY]ffZ'RZ6f_#Z.c RZ.c6KPW/KZ.c6KZ'OQKRoM[a._0[e[a6KU_0[%
[YKPX}RoM_MY[N.c.V]#b([a6KeXKUKPS;_#Z.OQKXKU_0[RT]ffZL[a'_0[OP_#Zd/Kec6X_ q4Z brX]ff^ "
_ J['_0[ L RmjK#jT`8Z6]#[c.RTS*Rc6Kc
RZ[Y]OQ]ffZ[YK [M \*Z6] qUTKc6f#Kd'_#MK#q4a.KPXK_#M+OQ]ffZ[YK *[N._#U'XK_#MY]ffZ.RZ6f}RM]ffZZ6] q4UTKc6f#K_0di]ffN.[\MYW/KOPR
OQ]ffZ[YK [MP`/[a._0[3RMP`"Z.] q4UTKc.f#K}RM4K W.XKMMYKcdVMYW/KOPRTbrVRoZ6fq4a.RO aOQ]ffZ[YK [?RT[4XKPb1KPX M4[Y]6jp%Z]#[a6KPX
q:]#Xc.MP` [a.KXKUTKPS0_#Z.OQKXKU_0[RT]ffZLRoM?_hXKMN.U[]#b:XK_#MY]ffZ'RZ6fh_0d/]ffN6[?Z.] q4UTKc.f#KeRZLMY[N.c6V*RZ6fc6KPW/KZ*
c6KZ.OQVi6]ffZ[a6K?]#[a6KPXa'_#Z.cB`6RT[,RM(]ffZ6K3]#b[a6Kc._0[_2[a._0[a._#M([Y]d/K3W.X] SRoc6Kcb1]#X,XK_#M]ffZ.RZ6f_0d/]ffN6[
OQ]ffZ[YK [MPj


fi ) # 1 ) 1 fi 2 2 3)ff

# ff



a6Kc6K Z.R[RT]ffZL]#bRTXXKUTKPS;_#Z'OQKfffRTS#KZ dV @KPSV#`=8RT#KM`_#Z.c *_0fffRTS [##&_#Ro^eM_0[&KMY[_0d'URoMa.RZ6f
q4a.RoOabr_#OQ[M]#b+_*Z6] q4UKc6f#K2d'_#MYK_0XKeRTXXKUTKPS;_#Z[[Y]h[a6Kc6KPXRTS0_0[RT]ffZ]#b+_T"N6KPXV#j}pZW'_0X[RoOPN.U_0X`
[a6KPVLOQ]ffZ.MRoc6KPX_ X MY[%I]#Xc6KPXUT]#fffRoOq4RT[aLZ6]brN.Z'OQ[RT]ffZLMYV*^d/]ffUM?_#Z.c _MYKP[]#b,RZ.b1KPXKZ'OQKXN.UTKMPj fi
*Z6] q4UKc6f#K4d'_#MKRM+_}MYKP[+]#bOPUT]ffMYKcbr]#X^}N'U_#Mrbr]#X^&N.U_#M=qRT[aZ6]}b1XKPK4S0_0XR_0d'UTKM j KPXRS;_0[RT]ffZ]#b_

Q +

fif.w~3}33f$3ws

"N6KPXV_#Z6]#[a6KPX:OPUT]ffMYKcebr]#X^&N.U_8RoM]#d.[_#RZ6KcdV_0W.W"UTVRoZ6f3[a6K4RZ6brKPXKZ.OQK4XN.UTKM[Y]}[a6K*Z6] qUTKc6f#K
d'_#MYK}_#Z.c[a6KUT]#fffRoOP_#U _ *R]ff^eM,]#b[a6K[a6KP]#XV#j
fi br]#X^&N.U
_ ]#b[a.K*Z6] q4UTKc6f#Kd'_#MYKRM2RTXXKUKPS;_#Z[[Y] [a6Kc6KPXRTS0_0[RT]ffZ ]#b4_#Z6]#[a6KPXbr]#X^&N.U_
7RTb c6]KMZ6]#_
[ J%W'_0X[ROPRTW"_0[YDK Lh[Y][a6KeW'X]OQKMM?]#b,RZ6brKPXXRZ6f
7 brX]ff^ [a6KZ.] q4UTKc.f#Ked'_#MYK#j.]#X
K6_#^W'UTK#`#RZ[a6K+*Z6] q4UTKc6f#K:d'_#MYK #i\&[ %
; ff % \& ALT ^h +ff`RT[RMOPUK_0X[a'_0%[ \2[ 9RMXKUTKPS;_#Z[
[Y] ^h[ `.q4a'RUTK
; ff(RoM,Z6]#[Pj
a'RMBc6K Z.R[RT]ffZdiKOQ]ff^eKM OQ]ff^W'URoOP_0[YKc?q4a6KZ?^]#XK\OQ]ff^W'UTK ?MOQKZ._0X RT]ffM _0XK=OQ]ffZ.MRc6KPXKcB%j 4_#^eKUTV#`
@ KPSVKP[4_#Umj\OQ]ffZ.MRc6KPX,[a6XKPKc':R iKPXKZ[ JYOQ]]#Xc.RZ'_0[YKM LGC XM[P`6q4a6KP[a6KPX_#UUBc.KPXRTS0_0[RT]ffZ.M,_0XKOQ]ffZ'MRc*
KPXKcL]#X FYN'MY[?]ffZ6K#MYKOQ]ffZ.cB`9q4a6KP[a6KPXq+KOQ]ffZ'MRc6KPX_#UoUc6KPXRTS0_0[RT]ffZ.M3]#X FYN.M[^eRZ.R^_#U9]ffZ.KMP8[a.RTXcB`
q4a6KP[a.KPXq+KOQ]ffZ.MRc6KPX}^K^d/KPXMa.RTW [Y][a6KW.X]]#b+]#X FYN.M[c6KPXRTS0_0d'RUR[VbrX]ff^ [a6Kb1]#X^&N.U_#M[a._0[
OQ]ff^W/]ffMYK[a.K?W.X]]#b(RZ[a'RMOP_#MYK#`.q:Ka._ S#Kbr]ffN6X,W/]ffMMRTd"UTKO a6]ffROQKM j
A:KMRc.KM[a6Kb_#OQ[}[a._0[&[a.RM}Z6]#[RT]ffZ ]#bRTXXKUKPS;_#Z.OQKRMd"_#MYKc]ffZ XM[%I]#Xc6KPX2UT]#fffRO0`8[a6KPXK_0XK
]#[a6KPX`^e]#XKMN6d"MY[_#Z[Ro_#Um`,c.:R /KPXKZ.OQKMd/KP[q:KPKZ RT[_#Z.c [a6KRc.K_#MRZS#KMY[RTfff_0[YKc RZ [a.RoMeW'_0W/KPXj
8RTXMY[P`iRT[RoM4_XKU_0[RT]ffZdiKP[q+KPKZ[q+]b1]#X ^}N.Uo_#MP`'fffRTS#KZ_d'_#Of#X]ffN.Z.c*Z6] q4UKc6f#Kd'_#MK#j fiMMN.O aB`
RT[RM4^]#XK}XKUo_0[YKc[Y]]#[a6KPX?Z6]#[RT]ffZ.M4]#b=XKUTKPS0_#Z.OQK&RZ[a6K2URT[YKPX _0[N6XK5 @9_#Z6+
f fi _0,X "N'RMP` # 0_ j
KOQ]ffZ.c `ffRT[RMd'_#MYKc2]ffZ2[a6K,OQ]ffZ.OQKPW.[]#b"W.X]]#b`#qa.ROa2RM8MY]ff^eKP[a.RZ6f?Z6]#[OQ]ff^W'UKP[YKUTV}c6KPW/KZ.c.KZ[]ffZ
[a6K2MYK^e_#Z[ROPMPj?6]#X?K 6_#^W'UTK#`iXKPW'Uo_#OPRZ6f[a.K&N.MN._#U^]*c.N.MW/]ffZ6KZ.M4q4RT[a[a6K&M[YX_#Z6f#KRZ6brKPXKZ.OQK
XN.UK %ff% 1 19`iq4a.RoOac6]KM4Z.]#[Oa'_#Z6f#K}[a.K}MYK^e_#Z[ROPM4]#b[a6K}UT]#fffRoOPMP`'[a6KZ[a6Kbr]#X^&N.U_

; ff]#b,[a6KZ6] q4UTKc6f#Kd'_#MYK_0di] S#Kd/KOQ]ff^KM&^e_0fffROP_#UoUTV XKUTKPS0_#Z[&[Y_
] ^h[ j4a.RMRMW/KPXb1KOQ[UV
XK_#MY]ffZ'_0d'UTK3RZ[a.K3_0W'W.X]ff_#Oad%
V @KPSVeKP[,_#UmjT`*q4a.KPXKRo^W.X] SRZ.fKPOPRTKZ'OQVN.MRZ.f}_2MYW/KOPR O4W.X]]#b
[a6KP]#XVhRM([a.K_#R^hj
8l 7 q{MLm'{|xuw#r u$u{ zw{ML [q
a6KZ.]#[RT]ffZ.M_#Z.cXKMN.UT[M(W.XKMYKZ[YKcRZ[a.RM(W"_0WiKPXOP_#Zd/K?K[YKZ.c.KcRZhMYKPS#KPX_#U9c.RTXKOQ[R]ffZ.MPj

'0 2
ff/)



fi 132 # # ) )

1/2
1/2

ff ) ff) 1 # 1 )M! 1 fi fi 1/2 '
) 2 ff ! # 2 'ff
# ' 2 !

0 2

ff
) ) )ff




p[ ^e_V3d/Kq+]#X[a?q+]ffZ'c6KPXRZ6f,_0d/]ffN6[ a6] q[a6K\Z.]#[RT]ffZ.MB]#b* @BRZ.c.KPWiKZ'c6KZ.OQK8_#Z.c S4RoZ.c6KPW/KZ.c6KZ.OQK
OP_#Zd/Kf#KZ6KPX _#URTgPKcL[Y][a6KeOP_#MYKqa6KPXK[a6Ke*Z6] q4UTKc6f#Ked"_#MYKRM?Z6]#[}_^KPXKeW'X]#W/]ffMRT[RT]ffZ._#Ubr]#XY
^&N.U_d"N6[+_}W.X]#d'_0d"RURT[V&c.RoMY[YXRTd'N.[RT]ffZ2] S#KP+X [Ti`]#X,_#ZRoZ.OQ]ff^W'UTKP[YKW.X]#d'_0d"RURT[Vr]#X(WK "N.RTS0_#UTKZ[UV
_MYKP[]#b+W.X]#d'_0d'RUR[Vc.RoMY[YXRTd'N.[RT]ffZ.M `/]#X_M[YX_0[R Kc *Z6] qUTKc6f#Ked'_#MK#`]#X_#ZV ]#[a6KPX]#Xc'RZ._#U]#X
ZN.^KPXROP_#UBM[YXN.OQ[N6XK#j
8RTXM[P`UTKP[:N.M\Z6]#[RoOQK4[a._0[(MY]ff^K]#bB]ffN6X:O a._0X_#OQ[YKPXRg_0[RT]ffZ.M(UTK_#ce[YN
] "N.RT[YK4RZ[N.RT[RS#K4_#Z.cef#KZ.KPX_#U
Rc6K_#Mj=]e[_0#K[a6KOP_#MYK]#b S4RoZ.c6KPW/KZ.c6KZ.OQK#`*q:Ka._S#K}Ma6] qZh[a._0[,[a6Kbr]ffUUT] q4RZ6f&[a6XKPKM[_0[YKQ
^KZ[M4_0XK?WK "N.RTS0_#UTKZ[,q4a6KZ & RM,_W.X]#W/]ffMR[RT]ffZ._#U"Z6] q4UTKc6f#Kd'_#MYK C
_ & c.]KMZ.]#[[YKUU _#ZV[a'RZ6f_0d/]ffN6/[ >`.RoZh_#ZVhOQ]ffZ[YK [P
rdi & OP_#Zd/K?XKPqXRT[Y[YKZWK "N.RTS0_#UTKZ[UTVRoZh_b1]#X ^}N.Uo_ & ? RoZq4a.RO )
>c6]KM4Z6]#[_0W'WiK_0X
K Z.RT[R]ff5
Z <
:br]#X_#ZV[q+]RZ[YKPXW.XKP[_0[RT]ffZ'M = _#Z.c = ? [a._0[4c.R iKPX]ffZ'UTVRZ[a.KS;_#UoN6K?fffRTS#KZh[Y] >9`.[a6KM[_0[N.M
]#b0= q4RT[aeXKMYW/KOQ[\[Y] & RmjK#jT`6^]*c6KU']#X:OQ]ffN.Z[YKPX^]*c6KU1=RM+[a6KM_#^eK_#M:[a._0[:]#b =@?9 ?:]#X]ffUoU_0XT
V j
fiM,[Y]eS0_0XR_0d'UTK?br]#Xf#KP[Y[RZ.f C
c" &'))(%*3U . & % U2RM+[a6K3^]ffMY[+f#KZ6KPX_#U/OQ]ffZ.MYKW"N6KZ.OQK]#b &
:? ]#X]ffUoU_0XV &ff j

Q I]

[a._0[:RoM S=_0XYRoZ.c6KPW/KZ.c6KZ[=brX]ff^U

fi

~33



s~$w

~ww$

4] q`6[a6KMKc6K Z.RT[R]ffZ.M+a'_S#K_MN6OPRTKZ[,UTKPS#KU/]#b9f#KZ6KPX_#UR[V[Y]diKK*[YKZ.c6Kch[Y][a6K?OP_#MYK?qa6KPXK
[a6K*Z6] q4UTKc6f#K?d'_#MK & RM,XKPW"U_#OQKchdV_#Z6]#[a.KPXMY[YXN'OQ[N6XK#j
aN.MP`MY]ff^eK]#bN.M}a'_S#KK[YKZ'c6Kc [a6KZ.]#[RT]ffZ]#bYS=_0XYRZ.c6KPW/KZ.c.KZ.OQKO a._0X_#OQ[YKPXRTgPKc N'MRZ6f
rdiY_#Z.ceS;_0XRo_0d'UTK:b1]#Xf#KP[Y[RoZ6f?[Y]]#Xc.RoZ._#U*OQ]ffZ.c.RT[RT]ffZ'_#UbN.Z.OQ[R]ffZ.M,rXKPW.XKMYKZ[YKce_#M+MY[YX_0[R Kc2d"_#MYKM
5 @_#Z.f6` _0,X "N'RMP` fi J RUUR_#^MP` 0# j a6Kd'_#MROW'N6XW/]ffMYKq(_#M[Y] K [YKZ.c [a6K J%br]#Xf#KP[_#Z.c
K*W'_#Z.Mc L _0W.W.X]ff_#O _0[hq+]#X b1]#XN.W/c'_0[RZ6f J['_0[ L *Z6] q4UTKc6f#K d'_#MYKML_#Mhd'XRTMK .V c.RoMOPN.MMYKc RZ
KOQ[RT]ffZ <:[Y]N6WBc._0[RZ.f2^e]#XKMY]#W'a.RoMY[ROP_0[YKchKPW'RoMY[YK^eRO3MY[_0[YKMPj
a.KOP_#MYK4]#bBRZ.OQ]ff^eW'UTKP[YK,W.X]#d"_0d'RURT[RKM9RM\_#UMY]RZ[YKPXKMY[RZ.fMRZ.OQK,f#KZ6KPX _#URTgRZ6f_ `Brdi8_#Z'cO
q4RUoUUTK_#c[Y][a6K2M_#^KRZ[N.RT[RTS#K&Z6]#[RT]ff
Z 0jfiM3[Y]S0_0XR_0d'UTK}b1]#Xf#KP[Y[RZ6f6` RT[3RMZ6]#[?a._0Xc[Y]Z6]#[ROQK
[a._0[4R[OQ]#XXKMYW/]ffZ.c.M([Y][a6Kq:KUU I*Z6] q4ZhZ.]#[RT]ffZh]#b:x#w{ffy1z"#
Fy E#v0y !0z.j

'ff 0 2 ff
) ff ) ff )
) ) 1 )ff
4! !
ff 2 1 1 ! # 1 ) ff 1
!
a6K&c6K Z.R[RT]ffZh]#b= @B,_#Z.c SRZ.c6KPW/KZ.c.KZ.OQK & OP_#Zd/K}XKPqXRT[Y[YKZKW"N'RTS;_#UKZ[UTVhRZ_br]#X^&N.U_
&6?,RZ qa.RO9
erXKMYW j=>/ec6]KMZ6]#[_0W.W/K_0XRM "N.RT[YKhf#KZ6KPX _#Um`RZ [a6KMYKZ.MYK[a'_0[[a6KU]#fffROP_#U
U_#Z6fffN'_0f#K0z"t !#w,[a6KOQ]ffZ.MYWK "N6KZ.OQKXKU_0[RT]ffZ_#Z.c[aN.M([a6KZ6]#[R]ffZh]#bU]#fffROP_#U/KW"N'RTS;_#UKZ.OQK +^e_V
S0_0XV#`\q4a'ROa KZ._0d'UKM&N'M2[Y] c.X_q brX]ff^ [a.RM&W.X RZ.OPRTW'UKZ6]#[RT]ffZ.M&]#b @ _#Z.c S4RZ'c6KPW/KZ.c6KZ.OQK
_#Z.c brX]ff^ [a6KZL]ffZ ` Z6]#[RT]ffZ.M3]#b(URT[YKPX_#U8_#Z.c S0_0XR_0d"UTK}br]#Xf#KP[Y[RZ.fb1]#XZ.]ffZ.OPU_#MMRoOP_#UU]#fffROPMPj2a.RM
RM(q4a'_0[a._#M(d/KPKZhc6]ffZ6K_0[4UTK_#M[,W'_0X[UTV.+RZL5 @_0#K^KPV#KPX` # # jEKPXKq:K?d.XRMK .VOQ]ffZ.MRoc6KPX,[q:]
OP_#MYKMMC
R1I /=P,PT;5y 0 !{#0y Qj\a6KMK3U]#fffROPM_0XK3d'N.RoUT[+]ffZh_OPUo_#MMROP_#UBU_#Z.fffN._0f#K?d'N6[,a._ S#K_2q+K_0#KPXOQ]ffZ*
MYWK "N6KZ.OQK&XKU_0[RT]ffZ[a._#Z OPU_#MMRoOP_#UUT]#fffRO0j6]#X?RZ.MY[_#Z'OQK#`iRZ^]ffMY[3^}N'UT[RTS0_#UN6KcUT]#fffRoOPMP`ic'N6K[Y][a6K
b_#OQ[&[a'_0[&[a.KK 6OPUN.c6Kc ^eRc'c.UTK
H :<6RoM&Z.]#[&_[a6KP]#XK^h`+_br]#X^&N.U_MN.Oa _#M
H X: SFG
/ SP
q4RUoU'c6KPW/KZ.cd/]#[a]ffZ_#Z.c]ffk
Z Srq4a6KPXK_#M,RT[:c.KPWiKZ'c.M\]ffZ'UTVe]ffZ eRZOPU_#MMROP_#UiUT]#fffRO `6d/KOP_#N.MYK3RT[
OP_#Z.Z6]#[+d/K4XKPqX RT[Y[YKZeWK "N.RTS0_#UTKZ[UTV&RoZ[Y]&_br]#X^}N'U_RZq4a.RO S,c6]KM+Z.]#[+_0W.W/K_0XRoZeW'_0X[RoOPN.U_0X`
RMZ6]#[=_#Uq:_ VM\WK "N.RS;_#UTKZ[8[Y]% H2 -: S%6
/ SP8RZMN.OaUT]#fffRoOPM ]ffZ[a.KOQ]ffZ[YX_0XV#`[a6K,br]#X^&N.U_% H2 <6/ SP
RM(WK "N.RTS0_#UTKZ[,[Y]RZhN.MN._#UB^&N.UT[RS;_#UN.KcU]#fffROPM_#Z.c[aN.Mc6KPW/KZ.c'M(]ffZ ]ffZ'UTV#j
RR1x !t09 !{ff5y P *j 4] q`.[a6KU_#Z.fffN._0f#KRM,]#d'[_#RZ6KchdVK *[YKZ.c.RoZ6fe_eOPU_#MMROP_#UBW.X]#W/]ffMR[RT]ffZ._#UiU_#Z*
fffN._0f#K?q4R[a]ffZ6K3]#X,^]#XK?^]*c._#UR[RTKMP`qa.RUTK[a.K3OQ]ffZ'MYWK "N.KZ.OQK3XKU_0[RT]ffZK *[YKZ.c.M:[a._0[(]#b9OPU_#MMROP_#U
UT]#fffRORZ[a6K2MYKZ.MYK&[a._0[?_^e]c._#UoRT[VIb1XKPK}br]#X^&N.U_RoM_[a6KP]#XK^ RTb+_#Z.c]ffZ'UTVRTb=RT[3RM_[a.KP]#XK^
]#bOPU_#MMRoOP_#U UT]#fffRO j:a6KPXKPbr]#XK#`.XKMN.UT[MMN'Oa_#M =X]#W/]ffMR[RT]ffZ.M _#Z.c 2MY[RUoUB^e_0#KMYKZ.MK_#Z.chq:K
OQ]ffZ FYKOQ[N6XK3[a._0[([a6KPV_0XKM[RUU.S0_#URc j89]2[_0#K_#ZK *_#^W"UTK#`RoZ[a6K?UT]#fffRo6
fi }q4a.KPX
K & & RM
_[a6KP]#XK^h`/_ebr]#X^&N.U_MN.Oa_#

& ff
/ & H
4,RMRZ.c6KPW/KZ.c6KZ[,brX]ff^
q4a.RoUTfi
K &
/ & H

RM,Z6]#[Pj




132

ff
! # 2
# / ' 2 ! /)
2
# 2 ! #
G 1 !



6]#Xf#KP[Y[RoZ6f_hMYKP[?]#b+S;_0XRo_0d'UTKM3^]*c.R KM3_*Z6] q4UKc6f#K2d'_#MYKq4a.RoUTKW.XKMYKPXS*RZ6fMY]ff^K]#b:[a6KOQ]ffZ*
MYWK "N6KZ.OQKMP`Z._#^KUTV#`B[a.]ffMYKed'N.RoUT[]ffZ S0_0XR_0d"UTKM3[a._0[_0XKZ.]#[?b1]#Xf#]#[Y[YKZ j [a6KPXbrX_#^KPq:]#X*M_0XK

iorqts ffy }suu yzB ff)p|u8iz}y | fi-~i:z} )}y ff xsuff-}su $&ffyx|u~)u f{u8z}uiz}uuffU}u~ Xz}y w
| - ~:z} }y ff $F * ~iyUu ffyB|u~Y}yffRu |u8~iu ff}y ff?$ lu u8 ||Uz}y | fiX~:z} }y ff
ff | xt 8}u ||lyTu }sff)'ly *! $ %*r ) u:}t}su~u ff }y ff )!G $#"$ !&%(' $) )& *3* *G $).*
xs |u~Y}y/}su'~uyTlyp}2 1|3547 6 + 5 xX218o z3947o 6 o, - /X/. ypUff -z}y | fi ~i:z} )4 }y ffy ffu~ z}yp
Tz}y f | ~:z} }y ff0
fffi
fff ~3}suRz}y f | ~:z} }y ff: ff*;<=5~u ffu~
4 $! * $ > 4 $ff *3*o $ *Xxty |~|up~ }y }suO}TuO~u ff }y ff" ffy}ff ff}s{/ ||iz}y f| fi ~:w
z} }y ff ff l u'u'i Bi18z}35u476 u~Tyz}u' ypTf{ }| ? fz}{|AO@ z}y f | ~:z} }y ff $ su z}u +iz}y | fi
~:z} }y ff
* z}yp xs R ff ~) u~
}suX/i uUff z}yp+ z}ff |upo
Q _&(

fif.w~3}33f$3ws

d'_#MYKce]ffZXKMY[YXRoOQ[RZ6f?[a6K,W/]ffMMRd'UTK "N6KPX RTKM=RZ2]#[a6KPX\q:_ VMP`*RmjK#jT`OQ]ffZ.MRc6KPX RZ6f]ffZ.UTVN"N6KPX RTKMRZ ]#XZ
br]#X^ _#N6[Yg#` ?K_0XZ.MP=` fi KU^e_#ZB` #ff j
E4K_#MY]ffZ.RZ6fq4RT[a}Oa._0X _#OQ[YKPXRMY[RO(^]*c6KUM: _#N6[Yg#` K_0XZ.MPD` fi *KU^e_#ZBG` # RM9d'_#MYKc&]ffZ}N'MRZ6f
]ffZ.UTVL_MN6d'MKP[]#b^]*c6KUM]#b,[a6K]#X RTfffRZ._#Ubr]#X^&N.U_*j fiM}b1]#X&b1]#Xf#KP[Y[RZ6f6`[a.RM}^e_V RZ.OQXK_#MYK[a6K
MRTgPK]#b[a6KXKPW.XKMKZ[_0[RT]ffZ ]#b_*Z6] q4UKc6f#Khd'_#MYKK *Wi]ffZ.KZ[R_#UoUTV#j a'_0Xc6]ffZ _#Z.c E]#[a [ # ff
a._ S#KMa6] q4Z [a._0[O a._0X_#OQ[YKPXRoMY[ROe^]*c6KUM?OP_#Zd/KeN.MYKc br]#XKPOPRTKZ[XK_#MY]ffZ'RZ6fh]ffZMY]ff^eKMYKP[M]#b
XKMY[YX ROQ[YKc "N6KPXRTKMPj
E #G+F\H ] <

JLKa._ S#KRZS#KMY[RTfff_0[YKc MKPS#KPX_#U,q(_V*Me]#b3_#Z.MYq:KPXRZ6f [a6Kh#KPV#"N.KMY[RT]ffZ ]#b3c6KP[YKPX^eRZ'RZ6fq4a._0[e_
W.X]#W/]ffMR[RT]ffZ._#U8*Z6] q4UKc6f#Ked'_#MYK[YKUUM}_0di]ffN.[[a6KRoZ"c6KPW/KZ.c6KZ.OPRKM3diKP[q+KPKZ S0_0XR_0d'UTKM_#Z.cbr]#XY
^&N.U_#MPj86]#X=K_#O ae]#b'[a.KZ6]#[RT]ffZ.MMY[N'c.RTKcB`0q:Ka._S#K,XKUo_0[YKceRT[8[Y]?]#[a6KPX=W.XKPSRT]ffN'MUTV?*Z6] q4ZZ.]#[RT]ffZ.M
_#Z.chq:Ka._ S#K}MY[N.c'RTKcRT[,b1X]ff^ _eOQ]ff^W'N6[_0[R]ffZ._#UBW/]ffRZ[:]#bS*RTKPq`6fffRTS*RZ6f2d/]#[ahOQ]ff^W'UTK 6RT[VXKMN.UT[M
_#Z.cO a._0X_#OQ[YKPXRTg_0[R]ffZXKMN.U[M9[Y]?d/K,N.MYKc2br]#XW.X_#OQ[RoOP_#UOQ]ff^eW'N6[_0[RT]ffZBj8p%Z2[a6K,URTfffa[8]#b']ffN6XXKMN.UT[MP`
RT[,_0W.W/K_0XM:[a._0[,[a6K3S0_0XRT]ffN.M(br]#X^eM:]#bUT]#fffROP_#UBRZ.c.KPWiKZ'c6KZ.OQK_0XKOPUT]ffMYKUTVOQ]ffZ'Z6KOQ[YKcBj++MYW/KOPR_#UUTV#`
MYKPS#KPX_#U=]#b:[a.K^ a._#c d/KPKZLW.X]#W/]ffMYKc dV c.:R /KPXKZ[?_#N6[a.]#XM?q4RT[a.]ffN6[3diKRoZ6fK W'UoROPRT[YKUTVXKU_0[YKcBj
A:]ffN6[RURKPX+ MR Z "N6KZ.OQK_0d'RUoRT[V_#Z'c @_0#K^KPV#KPX MXKUTKPS;_#Z'OQK]#b=_br]#X^}N'U_2[Y]_MN6Gd FYKOQ[4^e_0[Y[YKPX3_0XK
Rc6KZ[ROP_#U+[Y]L SRZ.c.KPWiKZ'c6KZ.OQK5 \X]#W/]ffMRT[RT]ffZ'
_#Z.c ff jLJLKh_#UMY]Lc.RMOPN'MMYKc^&N.O XKU_0[YKc
q:]#X"`_#Z.c MN6f#f#KMY[hMY]ff^KK [YKZ'MRT]ffZ.M[Y] ^e]#XKf#KZ.KPX_#Ub1X_#^eKPq+]#X [a'_#Z ^eKPXKW'X]#W/]ffMRT[RT]ffZ._#U
UT]#fffRO0j
a.K?b1]ffUU] q4RZ.f}[_0d'UK?fffRTS#KM_MYV*Z[a.KP[RO3SRKPq ]#b^e_#ZVZ6]#[RT]ffZ.M,_#c.c.XKMMYKchRZ[a'RM(W'_0W/KPX_#Z.c
[a6KOQ]#XXKMYW/]ffZ.c.RZ.f&OQ]ff^W"UTK *R[VXKMN.UT[Mj
\X]#d'UTK^
44]#[_0[R]ffZ
K Z.R[RT]ffZ
?:]ff^W'UTK 6RT[V
V*Z[Pj @RT[%RZ'c6KPW/KZ.c6KZ.OQK
( 3 *Q &40)
fi (@!O

@9RT[%RZ.c6KPW/KZ.c.KZ.OQK
( 4 &
fi (@!O 'OQ]ff^W'UKP[YK
ff
'
& % ( 3 *P
)
KPW/KZ.c6KZ[URT[YKPX_#UoM

ffr ( 3 *Q & #iDA #i + &+
" - OQ]ff^W'UTKP[YK
.N'UU @R[%RZ.c6KPW/KZ.c6KZ'OQK
(= r ( 3 *Q &4
'OQ]ff^W'UKP[YK
@9RT[%MR^W"UR Kc
8 ' #i + 4 & )k4 ( 3 *Q & 'OQ]ff^W'UKP[YK
@9RT[%IWK "N'RTS;_#UKZ.OQK
&

&'))(%+* ( 3 *Q & % ( 3 *P & T(:"
&'))(%+* ( 3 *Q
% ( 3 *P
T(:
fi - OQ]ff^W"UTKP[YK
\X]#d'UTK^eM(]ffZURT[YKPX_#UM,_#Z'c[a6KRTX4OQ]ff^W"UTK *R[V#j
\X]#d'UTK^
44]#[_0[RT]ffZ
K Z.RT[R]ffZ
?:]ff^W'UTK 6RT[V
V*Z[Pj S=_0XYRZ.c6KPW/KZ.c.KZ.OQK
U. & fi U !

S=_0XYRoZ.c6KPW/KZ.c6KZ.OQK
U 4 , &





&

U


.






fi
&
!


'OQ]ff^W'UKP[YK
ff '
%
.
KPW/KZ.c6KZ[,S;_0X R_0d'UTKM

ff U . & #D< < ,. &+
" - OQ]ff^W'UTKP[YK
.N'UU S=_0XYRZ'c6KPW/KZ.c6KZ.OQK
U!
ff U. &
'OQ]ff^W'UKP[YK
S=_0XYMR^W'UR Kc
r< ' #D<+ 4 ,. & < )B4 U, . & 'OQ]ff^W'UKP[YK
S=_0XYIWK "N.RTS0_#UTKZ.OQK
& 3$

&'))(%3* U. & % U. & U&"
&'))(%3* U.
% U.
U&
fi - OQ]ff^W"UTKP[YK
\X]#d'UTK^M(]ffZhS;_0X R_0d'UTKM,_#Z.c[a6KRTXOQ]ff^W'UK *RT[V#j

Q_

fi

~33



s~$w

~ww$

a.K}b_#OQ[3[a._0[3di]#[a Z6]#[R]ffZ.M]#b=b1]#X ^}N.Uo_;IS;_0XRo_0d'UTK}RoZ.c6KPW/KZ.c6KZ.OQK}_#Z.cb1]#Xf#KP[Y[RoZ6fha._S#Kd/KPKZ
N.MYKch_#M#KPVOQ]ffZ.OQKPW'[M4RZ^e_#ZV fip KUc.M?RZ.OPUN'c.RZ6f&_#N6[Y]ff^e_0[YKcXK_#MY]ffZ.RZ6f6`*d/KURTKPbXKPSRoMRT]ffZ_#Z.c
N6WBc._0[YK#`.c.Ro_0fffZ6]ffMRMP`6XK_#MY]ffZ.RZ6fe_0d/]ffN6[_#OQ[RT]ffZ.MKP[O0j
a._#M4diKPKZc.RMOPN.MMYKcd/KPb1]#XK *KOQ[RT]ffZ.M }_#Z.c
< `8MY]q:Keq4RUoU9XKPb1X_#RoZLb1X]ff^ XKPW/K_0[RZ6fR[a6KPXK#ja6Kfff_#RZ]#b:f#KZ.KPX_#URT[V] /KPXKcdV [a6KOQ]#XXKQ
MYW/]ffZ.c.RoZ6fhURT[YKPX_#U I]#X RTKZ[YKcZ6]#[RT]ffZ.MRoZ[YX]*c.N.OQKcRZL[a.RMW'_0W/KPX}a._#M}_#UMY]d/KPKZLKMY[_0d"URMa6Kc rK#jf6jT`
=X]#Wi]ffMRT[RT]ff
Z 0 `_#Z.c[a6KRTX?_0W.W'UoROP_0[RT]ffZ[Y]MYKPS#KPX_#/U fip4W.X]#d"UTK^eM2URT#KOPUT]ffMYKc*Iq:]#XUcXK_#M]ffZ.RZ6f
_#Z.chd/KURKPbN6WBc._0[YK :a._#M,d/KPKZM#KP[Oa6KcBj
\XR^e_0XRoUTV#`#]ffZ6K4]#bB[a.K^e_#RZ^]#[RTS0_0[RT]ffZ.M\b1]#X+[a6KZ6]#[R]ffZ.M=]#bBbr]#X^&N.U_;IS0_0XR_0d'UTKRoZ.c6KPW/KZ.c6KZ.OQK
_#Z.cb1]#Xf#KP[Y[RZ6f&q:_#M([Y]2R^W.X] S#K3RZ6brKPXKZ.OQK4brX]ff^ _}OQ]ff^eW'N6[_0[RT]ffZ._#UiMRc.K#`dVKZ._0d'URoZ6f[Y]2b1]*OPN.M+]ffZ
XKUTKPS0_#Z[=W'RTKOQKM]#b/*Z6] qUTKc6f#K#ja6KK *[YKZ[\[Y]q4a'ROa[a'RM8f#]ff_#U'OP_#ZdiK,XK_#Oa6KcOP_#Zed/Kc.RMOPN.MMYKc
_0[[a6K}URTfffa[:]#b8]ffN6XOQ]ff^W'UTK 6RT[VXKMN'UT[MM C
v JIyrz K0tRu -6uPz"tuQz uwYuP ffv5y !0z.?~00u&~y {#T
~ I!0.
x -"3u 2#y5v 4 :a6K3Z6]#[RT]ffZ.M(OQ]ffZ.Z6KOQ[YKc[Y]2
!;.
c.KPWiKZ'c6KZ.OQKe @Bc6KPW/KZ.c6KZ'OQK#`6brN.UoUi S+_#Z.ch @Bc.KPWiKZ'c6KZ.OQK#`.R Z "N6KZ.OQK_0d'RUoRT[V#`XKUTKPS0_#Z.OQK
[Y]_MN.Gd F%KOQ[?^e_0[Y[YKPX_#Z'cLMY[YXROQ[XKUTKPS0_#Z.OQKMYKOQ]ffZ.c br]#X^a._ S#Ke_OQ]ff^eW'UTK 6RT[V_0[?[a6K XMY[
UKPS#KU8]#b\[a6K&W/]ffUTVZ.]ff^eR_#Ua'RTKPX_0XO aV#`Bq4a'ROa ^K_#Z.M[a._0[?[a.KPVOP_#Z d/K&O a6KO#KcdV_M_0[RM%
_0d'RURT[V]#X H;_#Z'c_#ZN'Z.M_0[RM _0d'RURT[VMY]ffUTS#KPX j+a6KPVd/KOQ]ff^_
K J%[YX _#OQ[_0d'UTDK Leqa6KZMYV*Z[_#OQ[RoOP_#U
XKMY[YXROQ[RT]ffZ'M_0XK&^e_#c6Kh5 =X]#W/]ffMR[RT]ffZ j6]#Xf#KP[Y[RZ6fUR[YKPX_#UM]#XS0_0XR_0d'UKM (_#UMY]RMOQ]ff^2
W"N6[_0[RT]ffZ._#UUVK *W/KZ.MRTS#K#jha.KXK^e_#RoZ.RZ6fZ6]#[R]ffZ.M_0XKRZOQ]ff^eW'UTK 6RT[VOPU_#MMYKM}U]OP_0[YKc _0[
[a.K3MKOQ]ffZ.chUTKPS#KUi]#b[a6K3W/]ffUTV*Z6]ff^eR_#U"a.RTKPX_0X OaV#jJL]#XMYK#`.N.Z.c.KPX+[a6K?MY[_#Z'c._0Xc_#MMN.^eW.[RT]ffZ.M
]#b8OQ]ff^W'UK *RT[V[a.KP]#XV#`6[a6K?K *W'UROPRT[(OQ]ff^W'N.[_0[RT]ffZh]#b8URT[YKPX_#Ui]#XS0_0XR_0d'UKbr]#Xf#KP[Y[RZ6feOP_#Z'Z6]#[
d/K_#Oa.RKPS#Kc RZW/]ffUTV*Z6]ff^eR_#U+MYW'_#OQKRZ [a6Kf#KZ.KPX_#U(OP_#MYK5 =X]#W/]ffMR[RT]ffZ ja'RMW'N'Ma6KM
[Y] q:_0X c.M[a.KZ6KPfff_0[RTS#KOQ]ffZ.OPUN.MR]ffZ [a._0[_#UU[a.KMYKZ6]#[RT]ffZ'M_0XKa._0X cL[Y]d/KeOQ]ff^W'N6[YKc _0[
UK_#MY[RZ[a.K:q:]#XMY[8OP_#MYK 9K 6OQKPW.[=RTb6[a6K,MRgPK+]#X8[a6K,MYV*Z[_#OQ[RoOP_#U*b1]#X^s]#b.[a.K(RoZ6W'N6[ KZ'_0d'UTKM8RT[Pj
4a6Kb_#OQ[[a'_0[4[a6KMYK}W.X]#d'UK^eMb_#UU RZ[a6K}MKOQ]ffZ.cUKPS#KU]#b[a6K}W/]ffUTVZ.]ff^eR_#UBa.RTKPX _0XOaV_0XK
Z.]#[[a._0[MN6XW.XRMRoZ6f}MRoZ.OQK?[a.RM,RM(qa6KPXK_U_0Xf#K?W"_0X[RTb8Z6]#[,[a6K^e*_ FY]#XRT[V6+]#bR^eWi]#X[_#Z[
W'X]#d'UTK^eM,RoZZ6] q4UTKc6f#K?XKPW.XKMYKZ[_0[RT]ffZ b_#UUmj
x -iT,u 2#y5v 4 ! u z !#v2z/3u uQP0w yr 4'-"wYuP0uPz'v [w !0x -iw% v5y 00Q{ !DO
/6ve ~yT{0~ | !0wQ5v O[ ;Pu ,!#Y
wyvr~x& aN.MP*` fi^eRTX_#Z'
c OQp%UTX_#RT[aa._S#KMa6] q4Z[a6KeOQ]ff^W'N6[_0[R]ffZ._#Ud/KZ6K [M?[a'_0[OP_#Z
d/K&_#Oa.RTKPS#Kc dVMY[YXN'OQ[N6XRZ6f_ r[a6X]ffN6fffa[a6K&br]#Xf#KP[Y[RZ6f]#W/KPX_0[RT]ffZ"MY]_#M[Y]h_#Oa'RTKPS#K
RoZ6b1KPXKZ.OQK,_#Z.ceOQ]ffZ.MYWK "N6KZ.OQK Z.c.RZ.f^]#XK,KPOPRTKZ[UV fi^eRTX fi OQp%UTX_#RT[aB` 0##* OQpUX_#RT[a
fi fi^eRTX` 0# j fi MR^eRUo_0X9c.RMOQXKPW'_#Z.OQVd/KP[q+KPKZ2[a6K(q:]#XMY[8OP_#MYKMRT[N'_0[RT]ffZ}_#Z'c}[a.K:W'X_#OQ[R
OP_#U/]ffZ.KM,OP_#ZdiK]#d'MYKPXS#KchRoZ]#[a6KPXc.]ff^e_#RZ.MPKMYW/KOPR_#UUV#`M_0[RoM _0d'RUoRT[VId'_#MYKcOa6KO#KPXM,br]#X
"N._#Z[R Kc d/]]ffUTK_#Z b1]#X ^}N.Uo_#M25 A(RTKPXK#` ?(R^_0[Y[Rm9` ?(U_0X#K#`9.N FRT[_*` fi/aNB` ##8J RUoUR_#^eMP`
A(RTKPXK#` ?(U_0X#K#` fi
?N6W.[_*` 0##N.MKcbr]#X4br]#X^e_#U S#KPX R OP_0[RT]ffZW'N6XW/]ffMYKMrd/]ffN.Z'c6Kc^]*c6KU
a6KO*RZ6fK 6a.RTd"RT[4RZ[YKPXKMY[RZ.fOQ]ff^W"N6[_0[RT]ffZ._#Ud/Ka._S*RT]ffN6X M&_#OQ[N._#UoUTV#`B[a6KPV[VW'RoOP_#UUTVW/KPXY
br]#X^ diKP[Y[YKPX[a._#Z MYW/KOPR_#URTgPKc _#UTf#]#X RT[a.^eMP`(_#MMa6] qZ R6
Z ERZ[_#Z.KZB` 0# `4c6KMYW'R[YK[a6K
b_#OQ[[a._0[[a6KPV_0XKeOQ]ffZ6b1X]ffZ[YKcL[Y][a6KW.X]#d'UK^ ]#b+S0_0XR_0d'UK}br]#Xf#KP[Y[RZ6f RmjK#jT`KURo^eRZ._0[RT]ffZ
]#b8K 6RMY[YKZ[R_#UUTL
V "N'_#Z[R KcS;_0XRo_0d'UTKM j
x -G!0wQvI0z'v[w !0uQjJ a._0[q:K^K_#Zq4RT[a J%W.XKPW.X]0
!0w3u !0#uQw 1 -"wRu -i[w !Wu yrz{xeD 4 -"TD 4L0z y1.
OQKMMRZ6f L3XKPbrKPXM8[Y]?[a6K,[_#M}]#b/OQ]ff^W'N6[RoZ6feRZ"c6KPW/KZ.c6KZ'OQK+XKUo_0[RT]ffZ.M8_#Z.c2br]#Xf#KP[Y[RZ6%
f P 5u M!0wYu

s{- ~ }y ff""ffy ffTy ffy}y ff*ff) u z}uffu %lu|u8z}uDy ff%%lu|u' ~}u ypTu yz}T%y r| ff)ffff ? ff~
~u ff6/ $Dff io


Q _^_

fif.w~3}33f$3ws

W/KPXbr]#X^eRoZ6fh^]#XKeW.X]#d'UTK^2I]#XRKZ[YKcL[_#MM&MN.O a_#MOQ]ffZ'MYKW"N.KZ.OQK Z'c.RZ6f6` c.Ro_0fffZ6]ffMRMP`_#O
[R]ffZ H;N6WBc._0[YK#`=c6KOPRMRT]ffZ ^_0RZ.fKP[O0jaN.MP` @9RT[%MR^W"URTbrVRZ.f r]#X S=_0X MR^W'URb1V*RZ6f_
c'N6XRZ6f_W.XKUR^RZ._0XV] "UoRZ6K&W'a._#MYK2OP_#Z W.X] S#Kea6KUTW.bN.U br]#X?R^W.X] S*RZ6f]ffZ6URZ6K2RZ6brKPXKZ.OQK
MRZ.OQK2MR^W'UoR OP_0[RT]ffZZ6KPS#KPXRZ.OQXK_#MKM3[a6KMRTgPK2]#b+5
_ Aj fiM?Ma6] q4ZdV \X]#W/]ffMRT[RT]ff
Z `_
MR^eRU_0X=OQ]ffZ'OPUN.MRT]ffZOP_#Z.Z6]#[\d/Kc6X _q4Z[Y]q4a._0[+OQ]ffZ.OQKPXZ.M\b1]#Xf#KP[Y[RoZ6f6j=a.RM\MYKPK^eM=[Y]}d/K[a6K
W'XROQK\[Y]d/K\W'_#Roc[Y]d/KZ6K [brX]ff^ [a6K:Wi] q+KPX8]#b.br]#Xf#KP[Y[RZ.f6j ] q:KPS#KPX`[a'RMZ6KPfff_0[RS#K(OQ]ffZ'OPUN*
MRT]ffZ^}N'MY[d/K:[YK^eWiKPXKcdV}[a6K,[q:]br]ffUUT] q4RZ6f3OQ]ff^e^KZ[MPj Z2[a.K,]ffZ6Ka._#Z.cB`#br]#Xf#KP[Y[RZ.fRM
RoZ[YKPXKM[RZ6f -6uPw4uQR[\RMZ6]#[=]ffZ'UTV&_[Y]]ffU.[a._0[+OP_#Za6KUTWeR^W'X] S*RZ6f?RZ6brKPXKZ.OQKRoZeMY]ff^K4OP_#MKM
d"N6[_#UMY]e_f#]ff_#URZhMYKPS#KPX_#9U fi4p(_0W.W'URoOP_0[RT]ffZ.MPj Z[a6K]#[a6KPX4a._#Z.c `]ffN.X4OQ]ff^W'UTK 6RT[VXKMN.UT[M
XKU_0[YK3[Y][a6K3q+]#XM[(OP_#MK3MRT[N._0[RT]ffZB`]ffZ.UTV#`6_#Z.c `*_#M(KPS#]##KcdiKPbr]#XK#`*br]#Xf#KP[Y[RZ6fRM:brK_#MRTd'UTKRZ
^_#ZV}W.X_#OQ[ROP_#U6OP_#MYKMj88RZ'_#UUTV#`#UTKP[N.M8Z6]#[YK,[a._0[8[a6KPXK_0XK(MKPS#KPX_#U6OQ]ff^W'UTKP[YK,W'X]#W/]ffMRT[RT]ffZ._#U
brX_0fff^KZ[Mb1]#Xq4a.RO abr]#Xf#KP[Y[RZ6fRM4K_#MYV#j4\MWiKOPRo_#UUTV#`'_#M_#c6S#]*OP_0[YKcdV 3_0Xq4RO a6K[ ##ff `
OQ]ff^eW'RURZ.f_ RZ[Y]_ O4O4 br]#X^&N.U_c.N.XRZ6f_#Z ] iURZ6KMY[YKPW OP_#Z W.X] S#KW.X_#OQ[ROP_#UUV
S0_#UN._0d"UTK=[Y]3_#Oa.RTKPS#K(br]#Xf#KP[Y[RZ6f3RZ}_#ZKPOPRKZ[q:_ V#`ffW.X] SRoc6Kc[a._0[[a6K:MRTgPK\]#b'[a6K+OQ]ff^W"RUTKc
br]#X^ XK^e_#RZ.M4M^e_#UUBKZ.]ffN6fffa rq4a'ROaOP_#Z'Z6]#[4d/KfffN._0X _#Z[YKPKcRZh[a6K}q+]#X MY[4OP_#MYK .
j *RoZ.OQKRT[
RoMZ6]#[*Z6] qZq4a6KP[a.KPX[a6K 64O4 brX_0fff^KZ[}RoM?MY[YXROQ[UTV ^]#XKMN.OPOPRZ.OQ[[a._#ZL[a6KeW'XR^K
Ro^W'UROP_0[YKM9]ffZ6K? 3_0Xq4RO a6K fi _0,X "N.RMP ` ##ff `[a6K+W'XR^K:R^W'URoOP_0[YKM brX_0fff^KZ[8OP_#Z2_#UM]d/K
[_0Xf#KP[YKcLq4RT[aW.X] [_#M3_OQ]ff^eW'RU_0[RT]ffZU_#Z6fffN._0f#K2br]#X?MY]ff^K&Z6] q4UTKc6f#K&d'_#MYKMBKMYW/KOPR_#UUTV#`
M]ff^K2XKOQKZ[_0W'W.X]ff_#Oa.KM3[Y]h[a6KR^W'URoOPRT[,XKPW.XKMKZ[_0[RT]ffZ ]#b+W.XR^eK}R^W"UROP_0[YKM2 *R^]ffZ fi
c.KU S=_#UI` 0# K 6a.RTd"RT[4S#KPXVMRTfffZ.R OP_#Z[K^W'RTX ROP_#U W/KPXbr]#X^e_#Z.OQKM2r[a6KPVKZ._0d'UTK&[a6K2OQ]ff^2
W"N6[_0[RT]ffZ]#b9MYKP[M(]#bW.XR^KR^W'UoROP_0[YKM+OQ]ffZ[_#RZ.RoZ6f&N.W[YT
] P / OPU_#N.MKM ffj fiOPOQ]#X c.RZ6fffUTV#`*[a6KPV
OP_#ZW.X] S#KS;_#UoN._0d'UTK3br]#X[a6KW.X _#OQ[ROP_#U OQ]ff^W'N.[RZ6f2]#bRZ.c6KPW/KZ.c6KZ'OQK_#Z.cb1]#Xf#KP[Y[RoZ6f6j
E 'F &=
a6K&[a.RTX c_#N6[a6]#X?a._#Md/KPKZW'_0X[UTVMN6W.W/]#X[YKcdV[a.K}p c6KN@ KZ'MP`/[a6K Z.RS#KPXMRT[K2 c fi4X[Y]ffRMP`
[a6KYEKP fffRT]ff)
Z 44]#X+
c H8_#M%c6KQ ?(_#Uo_#RM+N'Z.c6KPX[a6K9 fi ?(,,p ? W.X] FYKOQ[P`_#Z.cdV2[a6K\N6X]#WiK_#Z ?:]ff^2
^&N.Z.RT[V87 1 E =X]#f#X_#^j *]ff^KXKMN.UT[M,]#b[a.RoM,W'_0W/KPX_#UTXK_#c6Vh_0W.W/K_0XKcR'
Z KOQ[RT]ffZ ]#b[a6K
W'_0W/KPX5 @_#Z.f fi _0,X "N'RMP` # 0_ J ?:]ff^W'UK *RT[VXKMN.UT[M3br]#XRZ.c.KPWiKZ'c6KZ.OQK2_#Z.cc6K Z'_0d'RURT[VRZ
W.X]#W/]ffMR[RT]ffZ._#U/UT]#fffRUO L*` ,[w !^ ![}vr~*u
z"vuQwz"#v0y !0z"0 !0Wz uQwuQz u !0ff
z (wyrz Py -"u ![ fi}z !0|,Tut{u
u -"wYuQPuPz'vI#v0y !0z 0z"
4u;M !0z.yrz{ Jfi K `'W"_0f#KM ` # j


Q _W\

fi

~33



s~$w

~ww$

&T

F\H ff E8E
ru=<uwuw{
M!0wx /*TV& y1 yrv5Oyrz"tuR-.uQz"tuPz'v w !0x 8y 40z"tN!0z' 4y 1Q!#w40z4yrz'vuQw -"wuPvI#vy0!0z
= ) [T 1=y F=;A ! & vr~*uPz&'"l V>= % :XmDA ! &5


fi MMN'^K[a._0[ & RM.@RT[%RoZ.c6KPW/KZ.c6KZ[,b1X]ff^ j4a6KZ `'[a6KPXK}K*RoMY[M4_b1]#X ^}N.Uo_
RoZk4?4
=>
[a._0[?RMKW"N.RTS0_#UTKZ[[Y] &B` _#Z.c c6]KM?Z6]#[?OQ]ffZ[_#RoZGj4a6KZB`/b1]#X_#ZV-= ) [ MN.Oa [a'_0[=BA !

q:K3a'_S#K &')lV >= % :YIDA !
3j 6 RZ.OQK
RoM\KW" N.RTS0_#UTKZ[+[Y]
& `*q:KOQ]ffZ.OPUoN.c6K[a._0[([a6K?M_#^K3W.X]#W/KPX[V
a6]ffUc'M(b1]#X 3
& j
fiMMN.^eKe[a._0[P`8b1]#X&_#ZVLRZ[YKPXW.XKP[_0[RT]ffZ = )9[/i`4= ! & R^W'URKM &')fV>= % :YI !
& jJLK
W.X] S#K[a._0[& RM 9@ RT[%RZ.c6KPW/KZ.c.KZ[:b1X]ff^Qj\p%Z.c6KPKcB`.UTKP[/1d/K?[a6K[YKPX ^ q4a6]ffMYK]ffZ.UTV^]c.KUBRM =,j
a6K?br]ffUUT] q4RZ6f2KW" N.RTS0_#UTKZ.OQKa6]ffUoc.MMC


ruHu

#U1
#U1


&






=;A ! & +
=;A ! & _#Z.c = A4! +
#U1 =;A ! & _#Z.c = 4! +

=;A! & _#Z.c
H 1
fiff j

. #U1
. #U1

+

1

=;A ! +
A%=;A ! & _#Z'c =;A ! +

a.K2Uo_0[Y[YKPXMY[YKPWOP_#ZLd/Kc6]ffZ6Kd/KOP_#N.MK= ! &sR^W'URKM4[a._0[&'"lV>= % :Xm?RM3_#UMY]_h^]*c6KU
]#b &j 44] q`Rb= A4! [a6KZ91 c6]KMZ.]#[OQ]ffZ[_#RZ j Z [a6K]#[a6KPXha._#Z.cB`RTb= ! `4[a6KZ
1Hk1 fiff + j 1 OP_#ZLd/KXKPqXRT[Y[YKZ_#M_OQ]ffZ FN.Z.OQ[R]ffZL]#b:UoRT[YKPX_#UM?Z6]#[}OQ]ffZ[_#RZ'RZ6fZ6KRT[a.KPX(Z6]#X
RT[M?Z6KPfff_0[R]ffZB
j fiM_XKMN.UT[P`B[a6K_0d/] S#Kebr]#X^&N.U_Lrq4a.RoOa RM?R]
Z 4O4=3c6]KM?Z6]#[OQ]ffZ[_#RZ `Bq4a.RoOa
^K_#Z.M[a._0[ & RYM @RT[%RZ'c6KPW/KZ.c6KZ[+brX]ff^ j

ru=
< uwuw{
JK
ffr( 3 *P &59( 3 *P &
JW
K &
1\vr~6uQz
ffr( 3 *Q &/!
ffr( 3 *P

J ,
K r( 3 *Q & /
' r( 3 *P & . r( 3 *Q
4
J ffP
K r( 3 *Q & H
' r( 3 *P & . r( 3 *P

Jff

K )-
ffr( 3 *P
&
#z"tT0! z. 4y :Y ) r( 3 *Q : &












=>

ruHu

0j49XRTS*R_#Umj

j+(

[a._0[3RM4KW"N.RS;_#UTKZ[4[Y] &`i_#Z.cMN.Oa[a._0[
& RTb_#Z.c]ffZ.UTVhRTb8[a6KPXK}K* RM[M_b1]#X^&N.U_
RMMYV*Z[_#OQ[RoOP_#UUTV+@RT[%RZ'c6KPW/KZ.c6KZ[+brX]ff^Q(4j1*RZ.OQK &
`.RT[,br]ffUUT] qM([a._0[
2j

j fi3d/K
_ 4O4 b1]#X^&N.U_KW"N.RTS0_#UTKZ[[Y] & rXKMYWj
48MPj[PjZ6]URT[YKPX _#U*]#bt(]OPOPN.XM
RoZRT[Pj=4a6KZ / fi rXKMYW j H fi3\RM(_br]#X^&N.U_}KW"N'RTS;_#UKZ[+[Y] &/
rXKMYW j1&_H
`*q4a.RoOa
RoMRm
Z 4O4:`'_#Z.cZ6]eURT[YKPX_#U/]#bY( ]OPOPN6X MRZhRT[Pj
6< j *[YX_#RTfffa[Yb1]#Xq(_0Xc b1X]ff^ [a6Kbr_#OQ[&[a._0[ 4_0W.W/K_0XMRZ _ 4O4 b1]#X ^}N.Uo_ &RTb,_#Z.c ]ffZ.UTVLRTbF:Y
_0W'WiK_0X MRZ[a6
K 4O4 b1]#X^ ]#b : &3j
j @KP[ rXKMW




Q _Q

fif.w~3}33f$3ws

ru=
< uwuw{
JK
ffU . &5 U 6 &4
JW
K &
1\vr~6uQz
ffU. &/!.U .

J ,
K
U . & /
' r( 3 *Q &4 .
ffr( 3 *Q

J ffP
K
U . & H
' r( 3 *Q &4 .
ffr( 3 *Q

Jff

K
ff
U . :
& /!.U . &










ruHu=> [ ?RM3[YXRSR_#UI+; ff3_#Z.c ?_0XKMR^RU_0X3[Y][a6KW.X]]#b:]#b+W/]ffRZ[Me;ff?_#Z'c 3]#b =X]#W/]0
MRT[R]ffZ `8XKPW'U_#OPRoZ6f9JYURT[YKPX _#UFLdV J%S;_0X R_0d'UTKDL*`X,dVG<'`_#Z.c
ffr( 3 *?dV U j fiM}[Y] <ICeRb
> )4
ffU . &+[a6KZh[a.KPXK?K*RoMY[M,_br]#X^}N'U_
KW"N'RTS;_#UKZ[([Y]L& RZqa.ROa)>c6]KM4Z6]#[_0W.W/K_0X
MRZ'OQ+K >hc6]KM+Z6]#[:_0W.W/K_0X:RoZ :
KRT[a6KPX`2:
RoM\_}b1]#X^&N.U_KW"N.RS;_#UTKZ[\[Y] : & RZeq4a'ROa >c.]KM:Z6]#[
_0W.W/K_0Xj



=<



uPv & P u&YM!0wxN/T w[!0x


y1 yrv5O yrx.-"y
:uthy &0zit !0z. 4y 2vr~*u M!0r !0|yrz{ u W/yr;#TuPz u}~G!0 t0 M!0weuQ0uPwI4c(
y1?I40z'vI v5y 01 4 y5v Oyrz"tu -6uQz"tuQz'v w[!0x (sy &0z"t+!0z. 4y /( 4 &~G!0 t0
y1 .#wIO yr.x -"

:uthy }0z"t !0z. 4y vr~*u !#1 !0|yrz{u M/*y100uQzu}~ff!0Tt; M!0wuQ0uPwI4 U
y1?I40z'vI v5y 01 4 .0w Oyrz"tu -6uQz"tuQz'v [w !0x U 0z"T
!0z' 4y U 4 ,. & ~ff!0Tt;

ru uwuw{

&
&

&
&

<

( 1

fiE1

=>
@9RT[%MR^eW'UR OP_0[R]ffZ



ruHu

C fiMMN.^KB& RMN@R[%MR^W'UoR Kc r[aN.M( 3 *P & ! r( 3 *Q &4Y_#Z'c UKP[c( (Rij
pb & R MMYVZ[_#OQ[ROP_#UUV6@RT[%RZ'c6KPW/KZ.c6KZ[&brX]ff^ (4`,[a6KZ9( fi ( 3 *P &5! `,[aN'M ( fi
8( 3 P* &ff! `"RmjK#jT`M( 4 &j
C5fiMMN'^K[a._0[L& RM2Z6]#[ @9RT[%MR^W"UR KcBj4a6KZ [a6KPXKhK6RMY[M ) ( 3 *Q &4&MPj[Pj1&
RoL
@9RT[%RZ.c.KPWiKZ'c6KZ[b1X]ff;
^ j J RT[a ( ! #i +ff`3RT[RoMOPUK_0Xh[a._0[B& RoMMVZ[_#OQ[ROP_#UUTV
@9RT[%c6KPW/KZ.c6KZ[(]ffZ (4`6q4a.RUT
K @R[%RZ.c6KPW/KZ.c6KZ[:b1X]ff^ RT[P`.OQ]ffZ[YX _#c.ROQ[RT]ffZBj
S=_0XMR^W'UoR OP_0[RT]ffZBj:a6KW'X]]#bRM4MR^eRUo_0X,[Y][a6K @RT[%MRo^W'UR OP_0[RT]ffZOP_#MYK#`"XKPW'U_#OPRZ6f J @9RT[%
RoZ.c6KPW/KZ.c6KZ[ LdK
V J[S=_0XRZ.c6KPW/KZ.c6KZ[ L*#` ( dT
V UeM` (Rd
V
fi:M` 9dV >M` ( 3 *P &\dV U . & j




=<



ru uwuw{

&
fi



P 0! wuQ0uPwI4T&(w !0x
3
1vr~*uPwYuhu,2#y1vr yv5Oy1x.-"y
:ut M!0wx */
ov

RoM @RT[%RZ'c6KPW/KZ.c6KZ[b1X]ff^ ( r( 3 *P &q+K *Z6] q [a'_0[L[a6KPXK K6RMY[ML_
ruHu=> *RoZ.OQK &
4O4 b1]#X^&N.U_

KW"N.RTS0_#UTKZ[}[Y] & MN.Oa [a._0[c( 3 *Q
@fi :( r( 3 *P &Y!K`=RmjK#jT`=MN'Oa [a._0[
( 3 *Q

ffr( 3 *P & j A:V W/]ffRZ[;ff2]#b=X]#W/]ffMRT[R]ffZ" q+Ka._S#K
ffr( 3 *P
! 8( 3 *P & j
aN.MP` r( 3 *Q
4 ( 3 *P
8( 3 *P & ! r( 3 *Q
4 `b1X]ff^ q4a.RoOa q:K OQ]ffZ.OPUN.c6K[a._0[
r( 3 *Q
4/! ( 3 *P
`'RIjK#jT`
RM @9RT[%MR^W"UR KcBj



ru=
< uwuw{ uv & P u M!0wxN/T w[!0x
M!D/*w?vI#vuPxuQz'vr&#wYueu M/*yr;0uQz'v



0z"tbNPu
yvuQwY0 ![(* ~*uziu,2ffv
Q_

fi



~33



JK 4 &
JWK &5j h ( !
& jh
J MK
& ! &5j h /
Jff
K 5
& j h ( A! fi
&



/

s~$w

~ww$



=>



ruHu

[ -I ; ff @ KP['<&[a.K4S0_0XR_0d'UTK4]#bB_#Z.c_#MMN.^K[a'_0[ &5j h ( A4! &5j h / `q4a.RoOa^eK_#Z.M=[a._0[:[a6KPXKRM
ff_
fi #D< +PIq+]#X Uc
= MN'Oa[a._0[E=;A ! &5j h ( / : &5j h / 6MRZ.OQKV& RM+KW"N.RTS0_#UTKZ[+[Y]: / &Tj h ( #H
X: / &Tj h ` q:K&a._ S#K = / #i +A !&5j h ( / ! & _#Z'c &'"lV>=G/#i + % :YI! = /#):Y +A !
&Tj h ( / : &Tj h / .a6KZ.OQK#` &'"lV>= / #i + % :YI A4! & _#Z.c[a6KPXKPbr]#XK & dVL\X]#W/]ffMRT[RT]ffZ 0j
;ff- fiMMN.^K &5j h ( ! &5j h / j=JLK&a._S#K[a6Kbr]ffUUT] qRZ6fOa._#RoZh]#bRo^W'UROP_0[R]ffZ.MMC

&

A!

&

&

A!

:/ 5& j h ( W HL :Y/ 5& j h /
:/ &5j h / W HL :Y/ &5j h /

&5j h

/

-I [ @ KP[?N.M3_#MMN.^eK}[a._0[ & ! 5& j h / ` _#Z.cW.X] S#K[a._0[3 4
& j3p%Z.c6KPKcB`/[a6K2_#MMN.^eW.[RT]ffZ
OP_#Zd/K?XKPqXRT[Y[YKZh_#MWC
= ) [/ ' > =;A ! & =;A ! &5j h /

4] q`0= !&5j h / RM4KW"N.RTS0_#UTKZ[3[Y]M_V[a'_0[Oa._#Z6fffRoZ6f[a6K2[YXN6[aS;_#UoN6K}]#b'=[Y]hb_#UMYK#` = RM
M[RUUB_^]*c6KUB]#b &jp%Zhb1]#X ^}N.Uo_#MP`

=) [/ ' >=9A !
&

&')fV>= % :YIFA ! &

4a.RM,RM(K6_#OQ[UTV[a6Kc6K Z.RT[RT]ffZ]#bX 4 &j
;ff-I < *_#^K_#M,[a.KW.X]]#b]#b;ff-I j
<-I [ *R^eRUo_0X:[Y][a6K?W.X]]#b9]#b, RI [ j



ru=
< uwuw{ uPv & PuM!0w xN/*TVw[!0xQ
3
% 0z"tc>(Pueh;0wy PQu ![6
fi ~6u2ziu,2ffv
M!D/*w?vI#vuPxuQz'vr&#wYueu M*/ yr;0uQz'v
J K > 4 ,. &
J WK '& gih / '& gih (
J MK & '& gih /
ffJ
K & '& gih (







=> C=\_#MYVeOQ]ffZ.MKW"N6KZ'OQK4]#bB[a6Kc6K Z.RT[R]ffZ]#b S4RZ'c6KPW/KZ.c6KZ.OQK & RM S=_0XRZ.c6KPW/KZ.c6KZ[brX]ff^



ruHu

>Rb_#Z.c]ffZ'UTVRb9RT[RMY@RT[%RZ'c6KPW/KZ.c6KZ[\brX]ff^ D# > % :Y> ;+ `"_#Z'c = X]#W/]ffMR[RT]ffZ ff j




v & PuVM!0w xN/*T w[!#x
3
% 0zit ( Pu /PQPuvY![3(R ~*ueziu,2ffv
uP1
ru=<uwuw{
vIffvuQxuQz'vr20wYuu M/*yr;0uQz"v

Q _D

fif.w~3}33f$3ws



JK( 4 &
JW
K
fi " &T U# 19AB1 y1vuQwx vr~#v,t! uz!ffv I!0z'vI0yrz0z4
yvuQwY0Qw !0x2( +
J MK

& # 0Ar0y1}L /u}vr~#v,t! uQz!#v ,!0z"vI0y1z#z4yrvuPw%# w[!#x ( +



=>



ruHu

[

;ffIC

9C pb& R @9RT[%RZ.c6KPW/KZ.c.KZ[9b1X]ff^ (4`ff[a6KZ2[a6KPXK,K6RMY[M8_34O4br]#X^&N.U_
KW"N.RS;_#UTKZ[
[Y] &sMPj[Pj( 3 *P
<fik( ! j ?(UTK_0XUVKZ6]ffN6fffa `B[a6KW.X]#W/KPX[V_( 3 *Q
<fi_( !RoM?MY[RUU
M_0[RM Kc RTb
RM[N.XZ6Kc RZ[Y] 6
4 :`+KMYW/KOPR_#UoUTVq4a.KZ
RoMe[N6XZ.Kc RZ[Y] RT[MW'XR^K
Ro^W'UROP_#Z[hZ6]#X^e_#U3br]#X^hj *RZ.OQK [q:] KW"N.RTS0_#UTKZ[hb1]#X ^}N.Uo_#Mha._S#K [a6KM_#^KLW'XR^K
Ro^W'UROP_#Z[MP`6Z6][YKPX^ ]#%b
" &(OQ]ffZ[_#RZ.M4_eURT[YKPX_#U/brX]ff^Q(4j
C=
fi &hRoM9
_ 4O4 b1]#X^&N.U_ [a._0[RMKW"N.RS;_#UTKZ[[Y](& _#Z.c MYVZ[_#OQ[ROP_#UUV @9RT[%
RoZ.c6KPW/KZ.c6KZ[+brX]ffQ
^ (4j KZ.OQK#` & RMY@RT[%RZ'c6KPW/KZ.c6KZ[+brX]ff^ (j


IC 6R^eRU_0X:[Y]e[a6KW.XR^K?R^eW'UROP_#Z[:MRT[N._0[RT]ffZB`.N'MRZ6f 5? 4 RZ.MY[YK_#ch]#b 6
4:j

[



uPv & Pu !#w xN/* w !0x

0z"tTU PuI/=PuPv ![
fi ~*uziu,2ffv
vIffvuQxuQz'vr20wYuu M/*yr;0uQz"v
=<



ru uwuw{



JK U 4 , &
JWK
fi " &. U# 19AB1 y1vuQwx vr~#v,t! uz!ffv I!0z'vI0yrz0z4;0wy PQu w !0x U +
J MK

& # 0Ar0y1}L /u}vr~#v,t! uQz!#v ,!0z"vI0y1z#z400w ymQPPTu w !0x U +



=> +_#MYV&OQ]ffZ'MYKW"N.KZ.OQK,]#b/[a6Kc6K Z.R[RT]ffZ]#b/ S4RoZ.c6KPW/KZ.c6KZ.OQK#`#W"UN.M =X]#W/]ffMR[RT]ffZ?_0d/] S#K#j



ruHu

=<





P

fiff ) ff )

=>
$ L < 4L
ru uwuw{

) )ff
1 fi ff ) ff )
1 fi ' ff ) )ff


0wYu O[I!0x.-"uPvu

0z"t fi '



ruHu

)y

q \q{ #q{

;
q

a.RTW j}pZ ]#X c6KPX?[Y]Ma6] q [a._0[ &sRMV@9RT[%c6KPW/KZ.c6KZ[]ffZ (`R[3RoM?MN6OPRTKZ[3[Y]
fffN.KMM_URT[YKPX_#UX(brX]ff^ (s_#Z.c_ U . & # U .:m +;Iq:]#XUc = [a._0[&RM_^]*c6KU]#b
&Tj h ( d'N.[4Z6]#[_^]*c6KUB]#b1&5j h / j4a6KMYK[YKMY[MOP_#ZdiK}_#Oa.RTKPS#KcRZh[Ro^KW/]ffUTV*Z6]ff^eR_#U
RoZ &A
j
_0Xc.Z.KMMP.j @KP[N'MOQ]ffZ.MRc6KPX4[a.K&^e_0W'W'RZ6fd MPj[PjOd & ! + & / - `Bqa6KPXK
RM(_2W.X]#Wi]ffMRT[RT]ffZ._#U'S;_0XRo_0d'UTK[a._0[c6]KM,Z6]#[(]OPOPN6XRoTZ &37j ?(UTK_0XUTVKZ6% ]ffN6fffaB` &
OP_#Zd/K(OQ]ff^eW'N6[YKceRZ2[Ro^K,W/]ffUTVZ.]ff^eR_#URZ-A &A
ffj ]#XKP] S#KPX` & RMM_0[RoM _0d'UTK,RTbi_#Z.c]ffZ.UV
Rb &G/ sRoM @RT[%c6KPW/KZ.c.KZ[,]ff
Z # +ffj



K^}diKPX

$

Lqff<q{4Lq{ ;
q

Q_6

fi

~33



s~$w

~ww$

K^}diKPX Ma.RTW j4pZ]#Xc6KPX[Y]Ma6] qs[a._0[ & RM.S=_0XYc6KPW/KZ.c.KZ[]ffZ Ue`BRT[RoM4MN6OPRTKZ[[Y]
fffN.KMM_S;_0X R_0d'UTK> brX]ff^ U _#Z'c_ U, . & #D>*+;Iq+]#X Uc-= [a._0[RoM4Z6]#[_^]*c6KU ]#b
[a.Kbr]#X^&N.U_ &'gih / &'g ( j=a.RoM=[YKMY[,OP_#Zd/K_#Oa'RTKPS#KchRZ[R^KWi]ffUVZ6]ff^R_#U.RZGA &A
j
_0Xc.Z.KMMPj *R^RU_0X[Y] [a6K a._0X c.Z6KMMW.X]]#be]#b @ c6KPW/KZ.c6KZ.OQK#`&XKPW'U_#OPRoZ62
f J @9RT[%
c.KPWiKZ'c6KZ[ L2dV J[S=_0XYc6KPW/KZ.c6KZ[ L*j

>#'$Uy

L qff<q{MLq{ ; q
#
K^}diKPX Ma.RTW jY& RMbN.UUV%@R[%c6KPW/KZ.c6KZ[]ffZ_( ! #i (&%('''% ),+&RTb_#Z.c]ffZ.UTVhRTb &5j h ( 4!
&Tj h / _#Z.cjTjTj_#Z.c &5j h ( A4! &5j h / a6]ffUc.MPj1"N'RTS;_#UKZ[UTV#`& RM4brN'UUTV+@RT[%c6KPW/KZ.c.KZ[
]ffZ ( ! #i ( %('''% ) +hRTb _#Z.c ]ffZ.UTV Rb,[a6Kbr]#X^&N.U_-3 0- ( &5j h ( / : &5j h / / ''' /
0 - ) &5j h ( / : &Tj h / \RM+M_0[RM _0d'UK#`q4a.KPXK4K_#O a3 0 -&0RM+_}XKZ._#^eRZ6f[a._0[
^_0W'MS0_0XR_0d'UKM?[Y]Z.KPq MYV*^d/]ffUMRZ_N'Z.RTbr]#X^ q:_ V6 j 6RZ.OQKe[a.RoM?b1]#X ^}N.Uo_OP_#Zd/K
OQ]ff^eW'N6[YKcRZ[Ro^K?W/]ffUTVZ.]ff^eR_#UiRZ &A UA
`6[a6K^K^}d/KPXMa.RTW]#*b fi 'ff ) 0
)ff
[Y] b1]ffUoUT] q4Mj
_0Xc.Z.KMMPj=.N.UoU' @Bc6KPW/KZ.c.KZ.OQK_#Z'c @Bc.KPWiKZ'c6KZ.OQK3OQ]ffRZ.OPRc6KRZe[a.KOP_#MYKRoZeq4a.RoOa
( RM3OQ]ff^W/]ffMYKc ]#b+_MRZ.fffUTK&UoRT[YKPX_#Umj *RoZ.OQK}[a.K 'a._0Xc.Z.KMM3]#b+ @Bc.KPWiKZ'c6KZ.OQK2a._#M
d/KPKZ W.X] S#KcN.MRZ6f_hMYKP
[ ( OQ]ff^W/]ffMYKc ]#b(_hMRZ.fffUTK&UoRT[YKPX_#Um`B[a6K 'a._0Xc.Z6KMM3]#b+bN.UU
@ c6KPW/KZ.c6KZ.OQK3br]ffUUT] q4MPj



>#'$

L q <q{4L#q{ ; q

K^}diKPX Ma.RTW jB& RMbN.UUVBS=_0XYc6KPW/KZ.c.KZ[}]ffZ#U ! #D> ( %('''% > ) +hRTb,_#Z.c]ffZ.UV Rb & 4
&5g h / _#Z.cjTjTj_#Z.c'& 4 &'g h / a6]ffUc.MPj,1"N.RS;_#UTKZ[UTV#` & RM4brN.UoUTV S=_0XYc.KPWiKZ'c6KZ[]ffZ
U-!$#D> ( %('''% > ) ++RTb*_#Z.c]ffZ'UTV Rb[a6K\b1]#X^&N.U_ 0- ( & &'g h / / ''' /< 0- ) &
&5g h / ,RoM4M_0[RM _0d'UTK#`.qa6KPXKK_#O 0 -& 0=RM4_XKZ._#^eRZ.f[a._0[^_0W'MS0_0XR_0d'UKM,[Y]
Z.KPq MYV*^d/]ffUMeRoZ_N.Z'RTb1]#X ^ q:_ V6 B
j *RZ'OQK[a.RM?br]#X^&N.U_hOP_#Zd/KOQ]ff^eW'N6[YKcRoZ [R^K
W/]ffUTV*Z6]ff^eRo_#URZ &A U
`#[a6K,^K^}d/KPXMa.RW]#b fi ' fi ) )ff
[Yff
] ebr]ffUUT] q4MPj
_0Xc.Z.KMMPj=.N.UoUi Sc6KPW/KZ.c6KZ.OQK?_#Z.c Sc6KPW/KZ.c6KZ.OQK?OQ]ffRZ.OPRoc6K?RT&b ( RM(OQ]ff^W/]ffMYKc]#b
_3MRoZ6fffUTK+UoRT[YKPX_#Umj *RZ.OQK+[a6K 'a._0Xc.Z.KMM]#b" S4c.KPWiKZ'c6KZ.OQK(a._#MdiKPKZ}W.X] S#KcN.MRZ.f_
MKPY[ (LOQ]ff^eWi]ffMKc}]#b"_MRZ6fffUTK:URT[YKPX_#Um`;[a6K .a'_0Xc.Z6KMM9]#b'bN.UU S4c6KPW/KZ.c.KZ.OQK+br]ffUUT] q4MPj



h~*uQziuP0uPw & P 0! z{0v ! PT; ![ N?P M!0wxN/T;vr~ffvy12vwYvI PQu M!0w
=<
PTD/ Q# W/.uPwI420z6|+uQwy1z{BJIy ru 18vr~*uQwuu,2#y1vrY- !0 4#vyrxu0{Q!0wyvr~x v !tuPvuPw x2yrziu3|8~6uPvr~*uPw &OA !=1
M0! w&0z=4NOP M!0wxN/Tff1K0z"tQvIQPQu M!0w00wyQPPTuy1z.vI0z'vym#vy0!0z Jy u I1+wuR-"Ty1z{hy1z & ) 0z4
;#w ymQQP u PM2
4 [YXN6K !0w P42br_#UoMYKe{#yr0u2!#w xN/* vr~#v(Qvy1r PuQ !0z{#&v ! Kvr~6uQz ff ) )ff
1
fiff ) ff )
1 fi ' ff ) ff )ff
0z"t fi ' fi ) )ff
0wu}yrz


ru uwuw{

K "N6KZ.OQK?]#b =X]#W/]ffMR[RT]ffZ.M 2_#Z.cBj=J a6KZB& d/KUT]ffZ6fffM:[Y]
ruHu=> a.RM(RM(_MY[YX_#Rfffa[Ybr]#Xq(_0XchOQ]ffZ.MYW
_OPU_#MM ]#b:br]#X^&N.U_#M?[a'_0[RM?[YX_#OQ[_0d"UTKebr]#X}OPU_#N.M_#U "N6KPXV_#Z.Mq+KPXRoZ6f_#Z.cMY[_0d"UTKebr]#XS;_0X R_0d'UTK
RZ.M[_#Z[R_0[R]ffZB`6q+KOP_#ZK_#MRUTVOa.KOhq4a6KP[a.KPX.&OA ! &'gih / _#Z.c'&'gih / ! & a6]ffUc'MPj



Q_+

fif.w~3}33f$3ws

=<



ru uwuw{


ruHu

=>



%

yC 'v

&

#(0 ! fi fi 132 'ff #z"t fi

<' ! ;

2 0 !

fi fi 1/2 '0wu

O[I!0x.-"Tuvu

zuw{

K^}diKPX Ma.RTW j +_#MYV OQ]ffZ.MYKW"N6KZ.OQK]#b3[a6Kbr_#OQ[e[a'_0[ #(0 ! fi fi 132 ' RM
_ XKMY[YX ROQ[RT]ffZ ]#b fi ' ) ff )ff
[a'_0[2RoMRZ _#Z.c RM}OPU]ffMYKc N'Z.c6KPX

W/]ffUTV*Z6]ff^eRo_#U"XKc.N.OQ[RT]ffZ.M j
_0Xc.Z.KMMPjJLK?W.X] S#K[a._0[,_2br]#X^}N'U_
`*d'N.RUT[+] S#KPX_#Zh_#UTW'a._0d/KP['A ! #D> ( %('('('>% > ) +ff`
RoMM_0[RM _0d'UTK?RTb9_#Z'ch]ffZ.UTVRTb9br]#X^&N.U_ & RYM @BMR^eW'UR Kc `q4a6KPXK

&"!


H
A3:%Ar0/ >
g

0

@0

qa6KPXK

A3:%AffRM:[a6K?b1]#X ^}N.Uo_]#d.[_#RoZ6KcdVXKPW'U_#OPRoZ6f&RoZ
K_#O a]*OPOPN6XXKZ'OQK]#b%> 0
rXKMYW j6:%>0:qRT[a-:%> 0,rXKMYWj-> 0I j
8RTX MY[P`:Rb
RoMZ6]#[M_0[RM _0d'UTK#`:Z6KRT[a6KPX
A3:%ARoMP`\[aN.M
=H
A3:%Ar2RoMeZ6]#[
M_0[RM _0d'UK#ffj fiM_2XKMN.UT[P` & RMZ6]#[M_0[RoM _0d'UTK#`6[aN.MR[RMZ6]#[ @9RT[%MR^W"UR KcB`d/KOP_#N.MYK
8 ( 3 *P &ff ! &d"N6.[ & ^KZ[RT]ffZ.M,S0_0XR_0d"UTK5M > 08_#Z.m
c @0j
fiMMN'^K
M_0[RM _0d'UTK#j ?(UTK_0XUV#G` & RM+M_0[RM _0d'UK4_#M:q+KU U CUTKP[E= d/K_^]*c6KU"]#
b &jJLK

W'X] S#K([a._0[ &RoM @9RT[%MR^W"UR Kc3dVMa6] q4RZ6f[a._0[R[RM @RT[%c.KPWiKZ'c6KZ[9]ffZK_#O aURT[YKPX_#URT[
OQ]ffZ[_#RZ.Mj,JLK&a._ S#ff
K ( 3 *P &7 ! #D> ( %('('(' % > ) % @ ( %('('('&% @ ) % %: > ( %('('('&% %: > ) % %: @ ( %('('('>% Y: @ ) +ffj
@KP+
[ 0 )k( 3 *P & j
[ 5
fiMMN'^K[a'_0[,= !Q 0j a6KZ `<&'"l V>= % X: 0 A4! &jpZ'c6KPKcB`UTKP[ U .: 0I
! >0
rXKMYW j @0mI C<= M_0[RM K*M > 0 @0 M]&O a._#Z6fffRZ6f&[a6K[YXN6[aS;_#UoN6K4]#b >0 ]ffZ.UTVrXKMYW j @0
]ffZ'UTV6:UK_#c.M,[Y]_e^e]c6KU/[a'_0[4c6]KMZ6]#[4M_0[RoMYb1
V > 0 @ 0j
; ff [a6KPXq4RMK#`q:Ka._S#K = ! X
: 0'
j E4KPW'U_#OPRZ6
f 0 dV Y: 0 RZ[a6KW.X]]#b,]#b4OP_#MYK[
KZ'_0d'UTKMc6KPX RTSRoZ6f}[a.KK W/KOQ[YKcOQ]ffZ.OPUN.MR]ffZBj

%

pz3r 'v

<' ! ;

zuw{



fi K^}diKPX Ma.RTW j=+_#MYVhOQ]ffZ.MYKW"N6KZ.OQK}]#b[a.Kbr_#OQ[[a._0[ fi 2 0 ! fi fi 132 '
RoM_XKMY[YXROQ[RT]ffZ]#bfi 'ff fi ) )ff
[a._0[&RMRZ _#Z'c RMOPU]ffMYKc
N'Z.c6KPX,W/]ffUTV*Z6]ff^eR_#UiXKc.N'OQ[RT]ffZ" j
fi _0Xc.Z.KMMPj94a6KW.X]]#bRMMR^eRUo_0Xi[Y]4[a6KW.X]]#b]#b 'a._0Xc.Z6KMM/]#b #(0 ! fi
fi 1/2 '`*XKPW'U_#OPRZ.]f J @9RT[%MR^eW'UR Kc Lq4RT[9
J[S=_0XYMR^W"UR KMc L*j


=<
2 uvuQwx&yrz.yrz{h|8~6uPvr~*uPw
ffr( 3 *P & !
|8~6uPvr~*uPw
U .
& !=A JI|8~*uPwYu?A

ru uwuw{

( IJ |8~*uPwYu ( yoPuv ![&
yvuQwY0
K 130z"ttuPvuQwx2y1z'y1z{



1y }Puv ![;0wy PQu Key1 " - O[I!0x.-"uPvu
~6u&Pu0w Q~ -"w !QPPTuPx ,!0z6yoQvy1z{hyrzOQ]ff^W'N6[RZ.f
r( 3 *P &%JIwu -.u3vyr0uP 4 U . & Ky1
yrz - 0z"ty1 P3!#vr~ 0z"t O~*0w%t

Q _W]

fi



~33



s~$w

~ww$

=> C

ruHu

KP[YKPX^RZ.RZ6fqa6KP[a6KPXFr( 3 Q* &4ff!

( RoM

" - OQ]ff^W'UTKP[YK#j

K^}diKPX Ma.RTW j
8( 3 *P & !

(RTb,_#Z.c ]ffZ.UTVLRTbR1 & a6]ffUc.Mb1]#X&KPS#KPXV )=(_#Z.c RR16 4 &
.a ]ffUc.Mb1]#X3KPS#KPXV] ) ( 3 *Q &4 +(B[a6KMYKP[?]#b+RZ.MY[_#Z.OQKM + & % ( -MN.O [a._0[eR1a6]ffUc.MRM
[a.K&N.Z'RT]ffZ]#b\_URoZ6K_0XZN.^}diKPX]#b=W.X]#d'UTK^eMRZ 9`i[aN.MRT[3RMRoZ BMRo^eRU_0XUV#`.[a6K
MKP[:]#bRZ.MY[_#Z'OQKM + & % ( -+MN.O a[a'_0[?RoR1=a.]ffUc.M:RM+_&W.X]#d'UTK^ RZ 9j.a.RM+W.X] S#KM([a6K
^eK^d/KPXMa'RTW[Y] " - ]#b8[a6K?W.X]#d'UK^ ]#bc6KP[YKPX ^eRZ.RZ.f&qa6KP[a6KPXFr( 3 *Q &4ff! (j
_0Xc.Z.KMMPj
@KPfi
[ +
% -\d/K_&W'_#RX+]#b9W.X]#W/]ffMRT[RT]ffZ'_#U.br]#X^}N'U_#MPj8J R[a6]ffN6[(UT]ffMM:]#bf#KZ6KPX _#URT[V#`*q:K?_#M%
MN.^K[a._0[
L_#Z.c c.]4Z6]#[Ma'_0XK=_#ZV3S0_0XR_0d'UK8_#Z'c?[a._0[ ! U.
/ !$#D> (&%('''% > )+ff`
U, . /
!$# ( %('''% +ffj8.N6X[a6KPX^]#XK(q:K,_#MMN.^K([a._0Y[ ! 4 2RTb'RT[q:KPXK,Z6]#[8[a6K,OP_#MYK
R[q:]ffN.Uc[a6KZ d/K2MN6OPRTKZ[3[a6KZ [Y]XKPW'U_#OQK
dV
/>Y* H: *4d/KPb1]#XK&W/KPXbr]#X^eRZ6f
[a.K?XKc.N.OQ[RT]ffZi jJLK?W.X] S#K?[a'_0[ +
% -:RM,_2W/]ffMR[RTS#KRoZ.MY[_#Z.OQK3]#b !$ #(04'*)M!$ #9`RmjK#jT`

RoMM_0[RM _0d'UK&_#Z.c RM3N.Z'M_0[RM _0d"UTK#`iRb=_#Z.c]ffZ.UTVRTbE
ffr ( 3 *P
/: ! ( 3 *Q &

qa6KPXK &?
/ !
H

A3%: Ar / g > 0 @ 0 _#M,RoZ_&W.XKPSRT]ffN'M\W.X]]#b+Z.]#[YK?[a._0[
&
(_#Z.c c6]Z6]#[Ma'_0XK_#ZVS0_0XR_0d'UKM j
RrRb
RMLM_0[RM _0d'UTK _#Z.c
RM N.Z.M_0[RM _0d'UK#`[a6KZ &?
4RoM @RT[%MRo^W'UR Kc _#O
OQ]#X c.RZ6f [Y] [a6KW.XKPS*RT]ffN.MW.X]]#b&_#Z.c [aN.M
ffr ( 3 *Q &?
4Y !;( 3 *Q &
Yq4a.KPXK_#M
8 ( 3 *P : !.`'q4a.RoOa[Y]#f#KP[a6KPXKZ[_#RU [a._0[Dr ( 3 *Q &
0/ : / ! ( 3 *Q &?
4Y j
RoR1 fiMMN.^eK[a._0[
RMN.Z.M_0[RoM _0d'UTK_#Z'cr ( 3 *P &?
0/: 1 ! ( 3 *P &?
ja6KZ
&
iRM Z6]#[ MR^W'UR Kc&rXKOP_#UU#[a._0[ U 6
4iRMBZ6]#[ K^W'[V?_#Z.c?a6KZ.OQK+MY]RWM ( 3 *Q &?
4YY `
[aN.M6
ffr ( 3 *Q &?
4Y "( 3 *Q &?
4Y -j 44] q`2
ffr ( 3 *P &?
/ : ff ! ( 3 *Q &
Y=Ro^W'URTKM
8 ( 3 *P &?
0/: M)
fi ( 3 *P 1 !O`iq4a.RoOaRMWi]ffMMRTd'UTK3]ffZ.UVRb RM4_e[_#N6[Y]ffUT]#f#V rd/KQ
OP_#N'MYB
K &?
?_#Z'c c6] Z6]#[2Ma._0XK_#ZVS;_0XRo_0d'UTKM =d"N6[}RZ[a.RM&OP_#MYK#` &?
4@/ : RM
RoZ.OQ]ffZ.MRM[YKZ[?_#Z.cL[aN.M r ( 3 *P &?
</ :
! `a6KZ.OQK#&` ( 3 *P &?
!`9q4a.RO aLRM
OQ]ffZ[YX_#c.RoOQ[Y]#XV#j
RoRR17 fiMMN.^K?[a._0[ RM,M_0[RoM _0d'UTK_#Z'c
ffr ( 3 *P &?
M/ : / ! ( 3 *P &?
j
4a6K MYKOQ]ffZ'csOQ]ffZ'c.RT[RT]ffZ OP_#Zsa.]ffUc ]ffZ.UV RTb &?
hRoMN.Z'M_0[RM _0d"UTK#`a6KZ.OQK Z6]#[ @9RT[%
MR^W'UR Kc MRoZ.OQG
K ( 3 *P &?
! 4 ff `?MY]
RMN.Z.M_0[RoM _0d'UTK_#Mhq:KUUm[a.RoM[_0#KMN.M
d"_#O[Y][a6KOP_#MKRR1 `6q4a'ROahUTK_#c'MN.M,[Y]e[a.KM_#^KOQ]ffZ[YX_#c.ROQ[R]ffZ_0fff_#RZBj

?(]ff^W'N6[RZ.f r( 3 *Q &44RoMRoZ - MRZ.OQK ff )
( 3 *P & a6KZ.OQK#`\RT[&RM2MN6OPRKZ[}[Y][YKM[&br]#X2KPS#KPXVK

ff )
RMRZ _#Z.c r( 3 *Q &46
)=( 3 *P &q4a6KP[a6KPX2]#XZ6]#[ & RM @9RT[%

RoZ.c6KPW/KZ.c6KZ[b1X]ff^ RT[ jp[+RM+_#UMY]}di]#[a .a._0X c_#Z.c .a._0X cBj .a._0X c.Z6KMM:RM\Ma6] q:Kc
dV [a6K br]ffUUT] q4RZ6f Wi]ffUVZ6]ff^R_#U,XKc.N'OQ[RT]ffZ b1X]ff^ !$#C fi ?54 br]#X^}N'U_ & RMM_0[RM _0d'UTK
Rb}_#Z.c ]ffZ.UTV RTb& RMS0_#URc ]#X r( 3 *P &} ! 4 &OPUTK_0XUTV KZ6]ffN6fffaB`S0_#URc ?54 br]#X^&N.U_#M
OP_#Z d/KXKOQ]#fffZ.RTgPKc RZLW/]ffUTV*Z6]ff^eRo_#U9[Ro^K#j4aN.M`<!$# OP_#ZdiKMY]ffUTS#KcRb+q:K*Z6] q a6] q [Y]
OQ]ff^eW'N6[YK
ffr ( 3 *Q &4br]#X?_#ZV &`/q4a.RO aMa6] q4M[a._0[?OQ]ff^W"N6[RZ6f
ffr( 3 *Q &4RM .a'_0XcBj
4a6K?W.X]]#b9]#b 'a._0Xc.Z6KMM4RMMR^eRU_0X & RMN.Z.M_0[RM _0d'UKRTb8_#Z.ch]ffZ'UTVRb4& RoMZ6]#[S0_#URc
_#Z'c
ffr ( 3 *Q &} ! ff j

Q*\(

fif.w~3}33f$3ws

KP[YKPX^RZ.RZ6fhqa6KP[a6KPXU 6 &4 ! U R
- OQ]ff^eW'UTKP[YK#j K^}diKPX Ma.RTWLbr]ffUUT] q4M?K_#MRUV
brX]ff^ [a6K+^K^}d/KPXMa.RW]#b6[a.K+OQ]#XXKMWi]ffZ'c.RZ6f(W.X]#d"UTK^ br]#X4r( 3 *Q 4& j _0Xc.Z6KMM RMMR^eRU_0X
[Y][a6Ka._0Xc'Z6KMM(W.X]]#bb1]#XD8( 3 *P & /! (4j
?(]ff^W'N6[RZ.fU . &RM=RoZ



- _#Z'ceRMd/]#[a 'a._0Xce_#Z.c .a._0X cBj *R^eRUo_0X[Y]}[a6K

OQ]#XXKMYW/]ffZ.c.RZ.f&XKMN.UT[(br]#XD
ffr( 3 Q* & j

=<



ru uwuw{

<



~*uPuv1![x !tuQ
N![F&'))(%+* ( 3 *Q & % #i +;N 0z Puu,2 -"wu Puth0

'fe" &'))(%+* ( 3 Q* & % i# +;Y

&')lV >= % :YI A2=;A ! & +
! #+= &')fV>= % mDA ! &+
ruHu=> a6K?W.X]]#b8RM(]#d.[_#RZ6KcR^e^Kc.Ro_0[YKUTVbrX]ff^
[a6Kc.K Z.RT[RT]ffZ j

ru=<uwuw{
W ~*uPu1
v ![x !tuQ
N
![F&'))(%+* ( 3 *Q & % (: 0z P u3u 2 -iwYuQPuth;
' ei &'))(%* ( 3 *P & % ((Y !$#+= A&'"l V>= % ( ( FA ! & |8~*uQw6u ( ( 9( +
ruHu=> A+VRZ.c.N'OQ[RT]ffZ]ffZ (A
j\a6K3d'_#MK3OP_#MKRZq4a.RO b
( RM(K^W.[VRM([YXRSR_#UIj @KP[Z6] q _#MMN.^K
[a._0[[a6KW.X]#WiKPX[Vha6]ffUc.Mb1]#X3_#Zk
V ( OQ]ff^W/]ffMYKc]#b hKUTK^KZ[MP`/_#Z.cW'X] S#K}[a._0[R[4a6]ffUc.M4_#M4q:KUU
br]#+X ( . #i +ffj
A:Vhc6K Z.R[RT]ffZB`
=;A !.&'))(%* ( 3 *P & % ( . #i +;
Rb9_#Z.ch]ffZ'UTVRTb =;A ! &')"( * ( 3 *P &'))(%* ( 3 *P & % (( % #i +;Y
RTb8_#Z.c]ffZ.UVRTb =;A ! &')"( * ( 3 *P & % (:,]#XD&')l V>= % IDA !.&'")(%+* ( 3 *P & % (:
RTb8_#Z.c]ffZ.UVRTb &'"l V>= % ( ? FA !.&'))(%* ( 3 *Q & % ((:q4a6KPX
K ( ? #i +
MRZ6f&[a6KRZ'c.N.OQ[RT]ffZaVW/]#[a6KMRMP`*q:K?OP_#ZhK W'XKMM:[a6KMYKP[(]#b9^e]c6KUoM+]#b<&'))(%* ( 3 *Q & % ((:_#M
[a6K^e]c6KUoM = ? MN'Oah[a._0[&')f V>= ? % ( ( ! &`.qa6KPX3
K ( ( RM,_#ZVhMN6d'MKP[,]#%b (4j fiM4_XKMN.U[P`
=;A !.&'))(%+* ( 3 *Q & % ( . #i +;
RTb9_#Z.c]ffZ.UTVRb &')f V>= % ( ? ff !9= ? _#Z.c &')l V>= ? % ( ( ! & % q4a6KPX
K ( ? #i +}_#Z.k
c ( ( (
RTb9_#Z.c]ffZ.UTVRb &')f V>= % ( ? ( ! & q4a6KPX
K ( ? ( "( . #i +
fiM_ XKMN.U[P`=[a6Kh^]*c6KUM&]#b&'")(%+* ( 3 *P & % (:&_0XKh[a.K^e]c6KUoM}[a'_0[eOP_#Z diKh^e_0W'WiKc RZ[Y]
^]*c6KUM(]#b & dVbr]#XOPRZ.fe_MN6d'MYKP[,]#bUR[YKPX_#UM(Rm
Z ( [Y]ed/KOQ]ff^K?[YXN6K#j



!

'fe" &

. #

(** &'))(%*( 3 *Q & % ((&y1
uPv &:Pu !0wxN/* w !0xQ

0zit (
vr~*u !{#y00r 4Qvw[!0z{uQv I!0z6u M/'uPz u ![.& vr~ #v+yo yrv5Oy1zituR-6uPz"tuPz'vw[!#x2( J /*-v ! !{ffy5 0u W/*y1*O
0uQzu K
=<

ru uwuw{

&

ruHu=> A:V RZ.c'N.OQ[RT]ffZ]ffZ (A
ja6Kd'_#MYKOP_#MYK (A !
RM}[YXRTS*R_#Umj @ KP[N.M2Z6] q _#MMN.^K[a._0[
[a6KeW'X]#W/]ffMRT[RT]ffZ a6]ffUc'M3b1]#X}KPS#KPXV (AL_#Z.cMa6] q [ a'_0[RT[XK^_#RZ.M3[YXN6Kqa6KZ;A (A ! 0j

Q*\

fi

~33



s~$w

~ww$

@ KP[m(=!

( ? . #i +ffj A+V [a6KLRZ.c.N'OQ[RT]ffZ aVWi]#[a.KMRMP`q:KLOP_#Z _#MMN.^eK[a._0[ &'")(%+* ( 3 *P & % ( ?o
R M[a6K ^]ffMY[Lf#KZ.KPX_#UOQ]ffZ.MYKW"N6KZ.OQK ]#bT& [a._0[LRM @RT[%RoZ.c6KPW/KZ.c6KZ[brX]ff^ ( ? j 6]#X[a6K M_0#K
]#beMR^eW'UROPRT[V#`?UTKP[ &6??c6KZ.]#[YK [a.RoMbr]#X^}N'U_*j p[XK^e_#RZ.M[Y] Ma.] q [a._0[&'))(%+* ( 3 *Q & % (: !
&'))(%* ( 3 *Q &'))(%+* ( 3 *Q & % ( ? % #i +;! &')"( *( 3 *P & ? % #i +;?RM3[a6K^]ffMY[?f#KZ6KPX_#U+OQ]ffZ.MYKW"N6KZ.OQKe]#b
&6?i[a._0[4RY
@RT[%RZ'c6KPW/KZ.c6KZ[+brX]ff^ j\,q:]OP_#MYKM_0XK[Y]ed/K?OQ]ffZ.MRc.KPXKcC
^ >RTb8_#Z.c]ffZ.UTVRTb
!=>9j &'))(%* ( 3 *Q &6? % >B(RM @R[%RZ.c6KPW/KZ.c6KZ[:b1X]ffQ
&'")(%+* ( 3 *P & ? % >/FA !.&'")(%+* ( 3 *P & ? % >/ gih / a6]ffUoc.MPj8JLKa._ S#K
& ?gih ( HL :%> /T& ? Ygih
/

&

?gih ( H & ?gih /

4a.RM/br]#X^}N'U_(OPUTK_0XUTV3RMB_UT]#fffRoOP_#U#OQ]ffZ.MYKW"N6KZ.OQK\]#b &'))(%*( 3 *Q & ? % #D>*+; j<KZ.OQK &'")(%+* ( 3 *P & ? % >/
RoM @RT[%RoZ.c6KPW/KZ.c6KZ[3b1X]ff^ >j
&')"( * ( 3 *P &6? % >/RM_UT]#fffRoOP_#U\OQ]ffZ.MYKW"N6KZ.OQK]#bY&6?1jp%Z.c6KPKcB`
br]#X:KPS#KPX+
V & ? )k

i` > )
fi:`*q+Ka._S#K & ? >/ & gi? h ( H Y: >/ & gi? h / jp[\XK^_#RZ.M
[Y] Ma6] q [a'_0[KPS#KPXVU]#fffROP_#U+OQ]ffZ'MYWK "N.KZ.OQK
]#.
b &6?[a._0[2RM @9RT[%RZ.c.KPWiKZ'c6KZ[3brX]ff^ > RoM_
U]#fffROP_#U+OQ]ffZ'MYWK "N.KZ.OQK]#bF&'")(%+* ( 3 *P &6? % >/ B
j @KP[
_#ZVLbr]#X^&N.U_Mj[P'
j &6?DA !
a6]ffUc.M}_#Z.c

!
'gih / j 6RZ.OQK & ? > B
/ & gi? h ( & HL %: > / & gi? h / ,a6]ffUc.MP`'q+K&a._S#K & ? !
RTb8_#Z.c]ffZ.UV
Rb,di]#[a >/ &6gi? h ( !
_#Z.c Y: >/ &6gi? h / !
a6]ffUc jaN.MP`RZ]#X c6KPX}[Y]LMa.] q [a._0[
&'")(%+* ( 3 *P & ? % >/A !
sa6]ffUc.MP`/RT[3RM3MN6OPRKZ[[Y]hW.X] S#K[a._0[ & gi? h ( !
a6]ffUc'MPj *N6W.W/]ffMYK
[a'_0[8RoM9Z6]#[8[a6K(OP_#MYK#j=a.KZB`0[a6KPXK:K *RM[M_#Z2R^eW'UROP_#Z[ 1e]#b & gi? h ( [a._0[RMZ6]#[_#Z2R^W'UoROP_#Z[
]#b
3j ] q:KPS#KPX`BMRZ'OQK >/ &6?gih ( !
a6]ffUc.MP`'q+K}Z6] q [a._0[ > b
/ 1BRM_#ZR^W'UoROP_#Z[,]#b

3j *RZ.OQK
RMWK "N'RTS;_#UKZ[[Y][a6K&OQ]ffZ FYN'Z.OQ[RT]ffZ]#b+RT[MW.X R^KR^eW'UROP_0[YKMP`'[a6KPXK}Z.KOQKMM_0XRUV
K6RMY[M,_&W.X R^KRo^W'UROP_0[YK]#b
MPj[Pj >
/ 1BFA !_#Z'c 1 A4! a6]ffUcBja'RM+Ro^W/]ffMYKM:[a._05[ >
d/KUT]ffZ.fffM=[Y]d'N6[+Z6]}UR[YKPX_#U6]#tb 1hd/KUT]ffZ6fffM=[Y]8j A:VOQ]ffZ.MY[YXN'OQ[RT]ffZB`gih / RM+_#ZR^eW'UROP_0[YK]#b

5gih / _#Z.cMgih / RM4M[YXROQ[UTVMY[YX]ffZ6f#KPX3[a._#Z8j *RZ'OQK
CA !
'gih / a.]ffUc.MP`
BA !Mgih / a.]ffUc.M
_#M4q+KUoUmj=a.RM(OQ]ffZ[YX_#c.ROQ[M4[a6Kb_#OQ[[a._0[ LRoM_2W.XR^eK3Ro^W'UROP_0[YK3]#b
j
: >j\a.K3c.K^]ffZ.MY[YX_0[R]ffZRMMRo^eRU_0X`iN
x /6vI#vyoN
x /6vI0z"t#yoj
!OY



=<



ru uwuw{

^



0z"tff(99(
& ')"( *( 3 *P & % :( H
&'))(%*( 3 *P
% (( '

uPv &1
Pu}v| ! M!0w xN/*T; w[!0x

&'))(%*( 3 Q* &KH
% (:"

^ ]c.KUM]#b
=> a6K PO U_#R^ OP_#Zd/KK_#MRoUTV W.X] S#Kcb1X]ff^Z\X]#W/]ffMRT[RT]ffZ W j p%Z.c6KPKcB`}[a6K
&'))(%*( 3 *Q
& H
% ((_0XK,[a6K^]*c6KUM<=MN.Oa2[a._0[ &'"lV>= % ( ( !
& H
`#qa6KPXK/( ( "(4jX44] q`
&')lV>= % ( ( !:& H
a6]ffUc.MRb:_#Z.c]ffZ.UTV RTb6&'"lV>= % ( ( ! &a6ff] Uoc.M?]#X,&'"lV>= % ( ( !



ruHu

a6]ffUc'MPj
Zh[a.K?]#[a6KPXa._#Z'cB`*[a6K^]*c6KUM(]#b<&'))(%*( 3 *P & % ((&H&'))(%+* ( 3 *Q
% (:(_0XK[a6]ffMYKMN'Oah[a._0[
&')l V>= % ( ( !& ]#X&'"l V>= % ( ( !
b1]#X?MY]ff^eKc( ( (j?a.RoM4RMKW"N.RTS0_#UTKZ[[Y][a6K_0di] S#K
OQ]ffZ.c.R[RT]ffZBj


Q*\*_

fif.w~3}33f$3ws

uP&v 1 Pu2+,!#z6 y1vuPz'v(vuQwx w[!0x

0z"tff(99(R
ru=<uwuw{ &
&'))(%*( 3 *Q 1 % (: ff j j



=> C\JLK X MY[,W.X] S#K[a6Kbr]ffUUT] q4RZ6f2UTK^e^e_GC



ruHu

y?qvv

z

#i +

k P !0w20z4LI!0z6yoQvuQz'v(vuQwx 141\|+u~0#u&'))(%*( 3 P* 1 % 1

,w[!W! %JIuQx2xe K C

;

z$q

;

z$q

;

z$q

k ))19` u o`B1 ! /1 ?1j
&'")(%+* ( 3 *P 1 % 1Bj h ( HL :X#Hb1B 1 ? =1 #i +ffj
: ))19`By u o`B1 !O:X /1 ?j
7
&'")(%+* ( 3 *P 1 % 9H1 1 91 #i +ffj
: ))
4 1_#Z.c
4 19j
H ))
&'")(%+* ( 3 *P 1 % 1 HL Y: MH1 1=1 #i +ffj

fiMY[YX_#Rfffa[Ybr]#Xq(_0XcRZ.c'N.OQ[RT]ffZ]ffZk(

=<



ru uwuw{



ruHu



&')"(

*(




OQ]ff^eW'UTKP[YKM[a.KW.X]]#bj

uPv &Pu&.!0wxN/* w[!#x2

0z"tff(=
3 *P & % (:Y7!$#0Ar0 )
&#z"tff( 3 *P0;4fi)(@!O +

(




=>

C @KP['0 )
&'))(%*( 3 *P & % ((Y j *RZ.OQK.& !.&'))(%*( 3 *P & % ((=_#Z.c &'))(%*( 3 *P & % ((FA !
0a6]ffUcB` 0RM\_#ZR^W'UoROP_0[YK,]#b&j@4KZ'OQK#`[a.KPXK4K6RMY[M+_W.X R^KR^W"UROP_0[YK+0 ? ]#b& Mj[PjR0 ? ! 0
a.]ffUc.MPj.*RoZ.OQK
0 c6]KM4Z.]#[OQ]ffZ[_#RZ_#ZVUoRT[YKPX_#UBbrX]ff^( `'[a'RM4RM_#UMY][a6K}OP_#MK}br]#X60 ?j4aN.MP`
0 ?RM_UT]#fffRoOP_#UOQ]ffZ.MYKW"N6KZ.OQK}]#b1& [a'_0[RM.@RT[%RZ'c6KPW/KZ.c6KZ[:brX]ff^ ( j fiM4_OQ]ffZ'MYKW"N.KZ.OQK}]#b
\X]#W/]ffMRT[RT]ffZ &`"RT[4^&N.MY[4diK[a6K}OP_#MYK}[a._0[&'")(%+* ( 3 *P & % :
( ! 0 ? j6KZ.OQK#`i[a6KPXK}K*RM[M4_
W'XR^KR^W"UROP_0[YK+0 ? ?]#b &')"( *( 3 *P & % :( ?MPj[Pj +0 ? ? ! 0 ?a6]ffUc.Mj&a'RM3R^W'URKM[a'_0[+0 ? ? !20

a.]ffUc.M_#Mq:KUUm`i_#Z.cMRZ.OQK&d/]#[aOPU_#N'MYKM_0XK}W.X R^K}Ro^W'UROP_0[YKM4]#b=[a6K2M_#^K&b1]#X ^}N.Uo_*`"[a6KPV
_0XKWK "N'RTS;_#UKZ[Pj A(N6[[a'RM,R^W'UoRTKM:[a._0?
[ 05 0 ?/a.]ffUc.MP`*q4a.RoOahOQ]ff^W'UKP[YKM[a6KW'X]]#bj
[ 0hd/K_W.XR^eKR^W'UoROP_0[YKe]#b & [a._0[2c6]KM&Z6]#[2OQ]ffZ[_#RoZ _#ZVUR[YKPX_#U=brX]ffZ
^ (G
j 0hRM
C @ KP
@9RT[%RZ.c.KPWiKZ'c6KZ[:brX]ffQ
^ (j *RZ.OQ
K 02RM,_#ZR^W'UoROP_0[YK3]#b &3`.RT[^}N'MY[4_#UMY]d/K_#ZR^W'URoOP_0[YK]#b
&'")(%+* ( 3 *P & % (: j 6N6d'MYWK "N6KZ[UTV#`"[a.KPXK}K 6RMY[M3_W.XRo^K}R^eW'UROP_0[Yc
K 0+?9]#bE&'))(%* ( 3 *Q & % ((
Mj[P
j 0 ? !20a6]ffUc.MPj *RZ.OQK & ! &'))(%+* ( 3 *Q & % (:3_#Z.cG&'")(%+* ( 3 *P & % (:A !20 ? d/]#[aLa6]ffUcB`
q:Ka._ S#+
K & !20 ?=_#Mq:KUUmj KZ.OQK#`9[a.KPXKeK 6RMY[M_hW'XR^KR^W"UROP_0[YK 0+? ?]#b &MPj[P)
j 0+? ?FA ! 0+?
a.]ffUc.MPja6KPXKPbr]#XK#` 0 ? ? ! 0a6]ffUc'M9_#Z.c2MRoZ.OQK+d/]#[a2OPU_#N.MKM_0XK:W'XR^K:R^W'URoOP_0[YKM]#b"[a6K,M_#^K
br]#X^&N.U_*`6[a6KPV_0XK?WK "N.RTS0_#UTKZ[Pj A:N.[,[a.RM,R^W"URTKM+[a._0?
[ 05 0 ?/a.]ffUc.MP`*q4a.RoOaOQ]ff^W'UTKP[YKM4[a6K
W'X]]#bj



Q*\^\

fi

~33

=<



ru uwuw{

0



s~$w

~ww$

"
fi
u~00u
&'))(%*3U . & % U2".&'))(%*( 3 Q* & % ( $

uPv &Pu&.!0wxN/* w[!#x2

0z"t U

=> A:VhRZ.c.N.OQ[R]ffZ]ffZ UA
j:4a6KW.X]#W/]ffMR[RT]ffZ[YXRTS*R_#UUTVa6]ffUc.M,br]#X U
! *j @ KP[N'M_#MMN.^eKRT[
RM([YXN.Kq4a6KZ6KPS#KPX U A! ij @ KP[ U !$#D< ( %('''% < , ( +ffj A:Vc.K Z.RT[RT]ffZ `q:Ka._ S#K


ruHu

& '))(%*3U. & % U2/!.&'))(%+* U, 6 &'")(%+* U, . & % #D< ( %('''% < +; % #D< , ( +;
A:Vh[a6KRoZ.c.N.OQ[RT]ffZhaVWi]#[a.KMRMP`&'))(%+* U, 6 & % U}RM,KW"N.RTS0_#UTKZ[4[Y] &'))(%*3U,.
% #D< , ( ;+ `
q4a6KPXK
RM,c6K Z.Kch_#MM C

"!.&'")(%+* ( 3 *P & % #D> > )#D< ( %('('('>% < ++ . #)%: >9 > ) #D< ( %('('('>% < ++;
JLK&a._S#K&'")(%+* U, . & % U} .&'))(%3* U,.
% #D< , ( +; j A:Vc.K Z.RT[RT]ffZ `
JLK&_#UMY]ea._ S#K

&'")(%+* U 6
% < , ( ff!
h / H
h

(

'

&'))(%*( 3 *Q
% #D< , ( % :%< , ( +;
! &'")(%+* ( 3 *P &')"( *( 3 *P
% #D< , ( +; % #):%< , ( +;
! &'")(%+* ( 3 *PY :%< , ( /
h / WH
h ( % #):%< , ( +;
!
< , ( /LY %: < , ( /
h / H
h ( h ( WHLY :Y< , ( /
h / WH
h ( h / '
a'RM2MR^W'UoR KM}[Y] < , ( /
h ( RH
h / H
h ( `\q4a.RoOa RM_#UM]LKW"N.RS;_#UTKZ[2[Y]

h / H
h ( `'a.KZ.OQK?WK "N'RTS;_#UKZ[,[Y]&'")(%+* U, .
% #D< , ( +; j ?:]ffZ.MYKW"N6KZ[UTV#`6q+K}a._S#K
&'))(%3* U,. & % U&
&'")(%+* ( 3 *P &')"( * ( 3 *P & % #D> > ) #D< (&%('('(' % < ++ . #)Y
: > > ) #D< (&%('('(' % <++; % #D< , ( % :%< , ( +;
&'")(%+* ( 3 *P & % U2 '




=<

ru uwuw{



U 4

G

uPv &1
:Puv| ! !#w xN/* 0 w[!#x
3
% 140z"tLU P ue /=PPuv ![6
fi
& /&'")(%+* U 6
% U&

,. & 1\vr~*uPz&'")(%+* U, . &G/
% &U

=> @ KP[N.MOQ]ffZ'MRc6KPX?[a6KeOP_#MKeq4a6KPXK U ! #D< +ffj A:V c.K Z.RT[RT]ffZ `iq:Kea._ S#K

ruHu

&'))(%*3U. & /


% #D< +; ! &9/
ph / H &./
ph ( j1"N'RTS;_#UKZ[UTV#` &'))(%+* U, 6 &./
% D# < +; &h / /

h / TH &h ( /

h ( j J a6KZ < 4 , &`4q:Ka._ S#KX& &h / &h (
j fiOPOQ]#Xc.RoZ6fffUTV#`
&'))(%*3U,. & /
% #D<+; &;/
h / H .
h ( & / &')"( *P
% #D<+; j@fi MYY[ X_#Rfffa[Ybr]#Xq(_0Xc





RZ.c'N.OQ[RT]ffZOQ]ff^W'UTKP[YKM4[a6K?W.X]]#bj

1 0zit
1 1 P u}vr~wYu ut0y1 M!0yrz'v
uPv &1
P u&v| !.!#w xN/* 0 w 0! x
3
% :
Puvr ![00w ymQPPTuQ w !0x
fi mJ I/P~hvr~*#v U, . & .
U .
'"
. . K v\~ff!0Tt;
=<

ru uwuw{



Q*\+Q

fif.w~3}33f$3ws




t! uz!ffv I!0z'vI0yrz0z4;0wy PQu w !0x




& % +:
% % -YFA !

0z"t+!0z. 4y
&OA !.&'")(%+* ( 3 *P & /
% ( . . (fiff9

zLvr~*u3{uQziuPw%#;u


& % +:
% % -YFA !

0z"t+!0z. 4y
& !.&'))(%*( 3 *P & / :@&')"( * ( 3 *P & / :
% (fiff
.

( . % (fiff
.

( .



|8~*uPwYu

yo y1w M/*x&w -ivy0!0z;}tu;
=ziuty1z#J 0wQvr~Q4)1 IK
=>

ruHu

0j44a.RMhRM_ OQ]ffZ'MYKW"N.KZ.OQK]#b2a6KP]#XK^

j brX]ff^ 5 =XgPV^&N.MRZ'MYRI` #ff j a.RM[a.KP]#XK^
M[_0[YKM[a._0[RTb
c.]KMZ.]#[OQ]ffZ[_#RoZ URT[YKPX _#UMb1X]ff^ `3[a6KZ

& % +:
% % -Y !

a.]ffUc.MRTb_#Z.c ]ffZ.UTV RTb?[a6KPXKRMZ6] OPU_#N.MYK_1 MPj[Pj 1 c6]KMZ6]#[OQ]ffZ[_#RZ _#ZV URT[YKPX _#UbrX]ff^
( . . (fiff _#Z'#
c & ! :
"H1 d'N6[ & A4! 1jLa.RM&RM}KW"N.RS;_#UTKZ[&[Y] M[_0[YKh[a._0[P`\RTb
c6]KM
Z.]#[&OQ]ffZ[_#RZ URT[YKPX_#UoMbrX]ff^ `8[a6KZ

& % +:
% % -Y !
a.]ffUc.MRb_#Z.c]ffZ'UTVRTb`9br]#X
KPS#KPXV OPU_#N.MYk
K 1 OQ]ffZ[_#RZ.RoZ6f]ffZ.UV UoRT[YKPX_#UMbrX]ff^ ( , . ( `,q:Ka'_S#K &;/
! 1 RTb?_#Z.c
]ffZ'UTVRT1b &CA ! 1j3p[?RMK_#MYV[Y]hMYKPK&[a._0[3[a6K2WK "N.RTS0_#UTKZ.OQK}RoM4W.XKMYKPXS#Kcq+]ffN'Uc_#ZVbr]#X^&N.U_
1 @R[%RZ.c6KPW/KZ.c6KZ[b1X]ff^ (T. . ( ff d/KOQ]ffZ.MRc.KPXKc _#ZVbr]#X^&N.U_hOP_#ZLd/K[N6X Z6KcRZ[Y]_#Z
WK "N.RTS0_#UTKZ1
[ ?54 b1]#X ^}N.Uo_ j84aN.M`a6KP]#XK
^ j OP_#Zd/K,XKPW'a6X _#MYKcRZeb1]#Xf#KP[Y[RoZ6f[YKPX^eWM C8Rb

c.]KM(Z6]#[,OQ]ffZ[_#RZhS0_0XR_0d'UTKM+brX]ff^ `[a.KZ

& % +:
% % -YFA !
a.]ffUc.M(RTb_#Z.c]ffZ.UV
Rb &G/
( & RTb_#Z.ch]ffZ.UVRTb & ! &'))(%+* ( 3 *Q & /
% ( . . ( ff9 j

j44a.RMhRM_

OQ]ffZ'MYKW"N.KZ.OQK]#b2a6KP]#XK^ j brX]ff^ 5=XgPV^&N.MRZ'MYRI` #ff j a.RM[a.KP]#XK^
[_0[YKM[a._0[

& % +:
% % -YA !
a6]ffUc.MRTb_#Z.c ]ffZ.UV RTbV& !
]#Xe[a6KPXKK*RoMY[Me_
br]#X^&N.U_ MPj[Pj, c6]KMZ6]#[OQ]ffZ[_#RZ_#ZV URT[YKPX_#UbrX]ff^7( . . ( ff` & !
H a6]ffUoc.M?_#Z.c


& % +:
% % -YFA ! :&jp[\RoMK_#MYV2[Y]MYKPK[a'_0[\MN.O a_?br]#X^&N.U_fi K6RMY[M=Rb"_#Z.c]ffZ'UTV&Rb
[a.K3OQ]ffDZ FYN.Z'OQ[RT]ffZ ]#b9_#UU"[a6K3br]#X^}N'U_#M. MN'Oa[a._0[ c6]KM(Z6]#[,OQ]ffZ[_#RZh_#ZVURT[YKPX_#U"brX]ff^
( . . (fiff_#Z.c &OA !
H a6]ffUc.M9RM9Mj[Pj

& % +:
% % -YFA ! : =j *RZ'OQK &OA !
H a.]ffUc.M
Rb"_#Z.c2]ffZ.UV}RTb & / :
! a6]ffUc'MP` RoM8WK "N.RS;_#UTKZ[8[Y]&'))(%* ( 3 *Q & / :
% ( . . ( ff9 jaN.MP`


& % +:
% % -Y !
a6]ffUc.MRTb=_#Z.c]ffZ.UTVRTb &CA !
a.]ffUc.M]#X

& % +:
% % -YA !
:@&')"( * ( 3 *P &;/ :
% (/. . ( ff92a.]ffUc.MPj p%Z [a6KOP_#MKq4a6KPXK & !
a6]ffUoc.MP` &;/ :
RM
RoZ.OQ]ffZ.MRM[YKZ[P`MY]RT[RM?_#UoMY][a6KOP_#MKe]#b &')"( * ( 3 *P & / :
% ( . . (fiff jaN.MP`RTb & !

a.]ffUc.MP`

& % +:
% % -Y ! :<&'))(%* ( 3 *Q &/ :
% ( . . ( ff /a6]ffUc'M _#M q:KUUm*j fiOPOQ]#Xc.RoZ6fffUTV#`


& % +:
% % -YA !
a6]ffUoc.M,RTb8_#Z.ch]ffZ.UTVRTb

& % +:
% % -YFA ! :<&'")(%+* ( 3 *P & /
:
% ( . . ( ff9a6]ffUc.MPj *RZ'OQK&')"( * ( 3 *P & /-:
% ( . . (fiff9c6]KM4Z6]#[OQ]ffZ[_#RZ_#ZVUoRT[YKPX_#U
brX]ff^ `6[a6KWi]ffRoZ[ FN.MY[_0d/] S#K}KZ._0d'UTKM,OQ]ffZ.OPUoN.c.RZ6f2[a6K?W'X]]#bj

Q*\

fi

~33



s~$w

~ww$


!#w N
x /* .
[w !#x

0z"tTuv&( Pu&eI/=PuPv ![/(* zvr~6u
uPv & P uY
ru=<uwuw{
{uPziuQwY0 0Pu$1=vr~*uPwYu?yoz!.-"w !I-G!0 yvy5!0zi0 M!0wxN/T
u M/*yr;0uQz'vv !&'))(%*( 3 *P & % ((1v vr~*uy E u
![
y1 -G0! 4;z !0x2y0r 4 P,!D/*z"tuty1z &A OA (A 1 /*z.u fi 9


=> a6K FN.MY[R OP_0[R]ffZhRM,[q:]#br]ffUcC
[
&'))(%*( 3 *Q & % ((RM[a6KUT]#fffROP_#UoUTV MY[YX]ffZ6f#KM[OQ]ffZ.MYKW"N6KZ.OQKL]#bN& [a'_0[RoML@9RT[%RZ.c.KPWiKZ'c6KZ[
brX]ff^ (j ?:]ffZ.MYKW" N6KZ[UTV#`(b1]#XKPS#KPXV b1]#X ^}N.Uo_1 )
3
%i`+q:Ka._ S#K & ! 1 RTb3_#Z.c ]ffZ'UTV Rb
&'))(%*( 3 *Q & % ((,A ! 19` qa6KPXK( !!( 3 *Q & +( 3 *P 1B jNA:KOP_#N.MYK&'))(%+* ( 3 *Q & % (:c6KPW/KZ.c.M]ffZ.UV
]ffZ URT[YKPX_#UoM]#bR( 3 *Q 4& 4fik( 3 *P 1B ` RT[RM_#Z yrz'vuPw -G!# 0z"v]#b & _#Z.ck1`BRmjK#jT`B_br]#X^&N.U_+$ MPj[Pj &CA !$
_#Z.c $ ! 1a6]ffUc [aN.M,q:Ka._ S#KNO
& ! &')"( *( 3 *P & % ( 3 *Q
& 5( 3 *P 1BYDA ! 19j
;ff9[a6K(K6 RMY[YKZ.OQK,]#bi_W'X]#W/]ffMRT[RT]ffZ._#Ubr]#X^}N'U_*`#RZ[YKPXWi]ffUo_#Z[]#b& _#Z.c 1`_#Z.c&]#biMRTgPK+W/]ffUTV*Z6]ff^eRo_#UUTV
d/]ffN.Z.c6Kc RZ9A
& 1@A q+]ffN'Uc Ro^W'UTV[a._0[ ;fi
5:
]#W.W'_#Z'_'fi * RTW"MYKPX` #0 `
q4a.RoOahRMOQ]ffZ'MRc6KPXKcS#KPXVN.Z'URT#KUTVRoZhOQ]ff^W'UTK6 RT[V[a6KP]#XV#j



ruHu



ru uwuw{


ruHu

=<

<

#(0 3' ff )ff


0z"t

=>
_0XIKW"N.RS;_#UTKZ'OQK#j
=

fi

2 0 3 ' ff )ff
0wu fi - O[I!0x.-"Tuvu

K^}diKPX Ma.RTW C8p%Z]#Xc6KPX,[Y]eOa.KO[a6K^K^}d/KPXMa.RTW[Y][a6KOQ]ff^W"UTK^KZ[_0XVW.X]#d'UTK^h`
fffN.KMMRZ6f_OPU_#N.MYK 1d'N'RUT[N.WbrX]ff^ U` _#Z'cO a6KO*RZ6f[a._0[ &A ! 1_#Z.c
A4! 1B4]#X
& A4! 1 _#Z.c
! 1B&RM2MN.OPRTKZ[Pja6KhOa6KO M[YKPW OP_#Z diKK_#MRUV_#OPOQ]ff^W'URoMa6Kc
RoZW/]ffUTV*Z6]ff^eRo_#U[R^eK&qa6KZ _#Z ]#X_#OPUTKeRoM_ S;_#RoU_0d'UTK#j4KZ.OQK#`[a6KeOQ]ff^W'UTK^eKZ[_0XV
W'X]#d'UTK^ d/KUT]ffZ6fffM([Y+
] & - j
_0Xc.Z.KMMM C @ KP
[ d/K[a6Ke^e_0W.W"RZ6f[a._0[_#MMY]*OPR_0[YKM[a6K[YXRTW'U
K + & % * f % \ -3[Y][a6K
"N._#Z[R Kc d/]]ffUTK_#Z br]#X^}N'U_ 8\ ff ^ & rqa6KPXK #i\ % ^ +RM_ W'_0X[RT[RT]ffZ ]#N
b U . &Y j
?,UTK_0XUTVKZ6]ffN6fffaBr
` RM(W/]ffUTV[R^K#j ]#XKP] S#KPX `'q:Ka._S#K C

8\ ff ^

& RoM,S;_#UoRc

RTb8_#Z.c]ffZ.UVRTb ! ff ^ ' &
RTb8_#Z.c]ffZ.UVRTb ! &')"( *3U . & % ^e
RTb8_#Z.c]ffZ.UVRTb & 6
` * f

6RZ.OQK[a6KS;_#UoRc.RT[VW.X]#d'UK^ br]#X
fi br]#X^}N'U_#M2RMfffi - OQ]ff^eW'UTKP[YK#`\[a'RM2W.X] S#KM[a6K

ff)
j

fi - a._0Xc'Z6KMM(]#b fi 2 0 / '
@9RT[%IKW"N.RTS0_#UTKZ.OQK#j

K^}diKPX Ma.RTW C KPK[a6Ke^K^}diKPX
JYMj[Pj*( 3 *Q 1 5"(RL*j

Ma.RTW W.X]]#b(_0di] S#K#`9XKPW'U_#OPRZ6f J%d'N'RUT[?N6WLbrX]ff^ U L0dV

_0Xc.Z.KMMM C@KP[Yd d/K\[a6K,^e_0W.W"RZ6f[a._0[_#MM]OPR_0[YKM + & %
% U - [Y] + & %
% ('$ - jff?(UTK_0XUV
KZ.]ffN6fffaB`-d + & %
% U -YOP_#Z d/KOQ]ff^W'N.[YKc RZ[R^KW/]ffUTV*Z6]ff^eRo_#U=RZ;A + & %
% U -A
jJLK
a'_S#KMa.] q4Zh[a'_0[.& _#Z.c
_0XKVS=_0XIKW"N.RS;_#UTKZ[,fffRTS#KZ U RTb_#Z.c]ffZ.UTVRTb & _#Z'c
_0XK
Q*\i

fif.w~3}33f$3ws

@9RT[%IKW"N.RTS0_#UTKZ[&fffRTS#KZ ('$(j KZ.OQK#`'d RM2_W/]ffUTV*Z6]ff^eRo_#U\^e_#ZVI]ffZ.KhXKc.N.OQ[RT]ffZ brX]ff^
fi 2 0 3' ff ff)
[Y] #(0 3' ff )ff
j *RoZ.OQK fi 2 0 /' ff )
RoM fi - a'_0XcB`
[a'RMRM,_#UM][a6KOP_#MYKbr]#X #(0 /' ff )
j



v & P u !0wxN/* w !0x
3
% 0z"tLU I/=PQPuPv.![3
fi & y1}yrz /ffO
u1
ru=<uwuw{
uQz u PQu1 w !0x U #z"tT!0z. 4y .& yo .0w OYtuR-6uPz"tuPz'v !0zBU


ruHu=> =X]#W/]ffMR[RT]ffZ <b1X]ff^
5 A:]ffN6[RURTKPX ` # <M[_0[YKM[a._0[N&RMRZ'N6KZ.OQK_0d'UK}brX]ff^ U TR b(_#Z.c
]ffZ.UTVRTb9[a6KPXKK6RMY[M_2W'XR^K?R^W"UROP_#Z[:]#b & [a._0[OQ]ffZ[_#RZ'M4_S0_0XR_0d'UKbrX]ff^ Ue`.q4a.KPXK U M,[a6K
MYKP[]#b8OQ]ffZ[YX]ffUU_0d'UK?S;_0XRo_0d'UTKMPj \X]#W/]ffMRT[RT]ffZhOQ]ff^W"UTKP[YKM,[a6KW'X]]#bj


uPv& Pu& M!0wx /*T. w !0x
3
%0z"tNU /=PPuv ![T
fi &yo3wuQuQ;#z'v
v ! U 0z"tT!0z. 4y & yo .#wIYO tuR-.uQz"tuPz'v !0zBU

=<



ru uwuw{







=> a6K?W.X]]#b8RM([YXRTS*R_#U/brX]ff^ =X]#Wi]ffMRT[RT]ffZhj



ruHu

uPv & P u2.!0wxN/* w !0x2
3
% #z"t U I/=PQPuPv ![+
fffi Y& yo?Qvw y0v 4
wuQuQ;#z'v9v !VU 40z"tN!0z. 4&y & yo .0w OYtuR-6uPz"tuPz'v !0z U 0z"t .0w Oyrz"tu -6uQzituQz'vffw[!#x U,. & U
=<



ru uwuw{







X]#W/]ffMR[RT]ffZ & RM S=_0XYc6KPW/KZ.c6KZ[
=> +_#MYVbrX]ff^ [a.Kc6K Z'RT[RT]ffZ]#b MY[YX ROQ[\XKUKPS;_#Z.OQK#`W'UN'M =
brX]ff^ KPS#KPXVS0_0XR_0d'UTK}]OPOPN.XXRZ6fRZ_W.X R^K}Ro^W'UROP_0[YK]#b & #_ Z.cBS=_0XRZ.c6KPW/KZ.c6KZ[4brX]ff^ _#UU9[a6K


ruHu



XK^e_#RoZ.RZ6f&S;_0X R_0d'UTKM j

ru=
< uwuw{
J K! # 2
# 2 3 )ff

,!#xY-iTuvu
J WK ! # 2
# 2 /)ff

,#! xYi- Tuvu




=>

ruHu



r

;

1 -fi fi 1/2 '
1 fi fi 132 '

# 1

!'

# 1

G! '




#GD$# # 2 J #uPxu4uQw 1 Keyo fi



(# $# # 2 J #uPxeuM4uQw 1 [Ky1 "

-
-



n ; q " y?z3qv qwqr k '
K^}diKPX Ma.RTW j @KP[2N'M&OQ]ffZ'MRc6KPX2[a6KhOQ]ff^W'UK^KZ[_0XVW.X]#d"UTK^hj
3N6KMM_ OPU_#N'MYKb19`
a6KO[a._0[,RT[(c6]KM:Z.]#[:OQ]ffZ[_#RZh_#ZVS0_0XR_0d'UTKb1X]ff^ U r[a.RM(OP_#ZdiK3_#Oa'RTKPS#KchRZ[R^K
W/]ffUTV*Z6]ff^eRo_#U=RZ 1@A U

`\a6KZ'OQKRZ[R^KW/]ffUTVZ.]ff^eR_#U=RZ &A U
AMRZ.OQKZ6]W'XR^K
Ro^W'UROP_0[YK4]#b & OP_#ZRZ.OPUN'c6K_S0_0XR_0d'UK[a._0[(c6]KM+Z6]#[:]OPOPN6X:RL
Z &4 j=a6KZO a6KO[a._0[
R[(RoM:_#ZhRo^W'UROP_0[YK]#b &r]ffZ6K?OP_#UU/[Y]_#Z ]#X_#OPUTK :_#Z.cOa.KO[a._0[,KPS#KPXVMN6dBOPU_#N.MYK
]#*b 1 ]#d'[_#RZ6KcdVXK^] SRoZ6fb1X]ff^ R[]ffZ.K]#b:RT[M3URT[YKPX_#UoMRoMZ.]#[_#ZR^W'UoROP_0[YK}]#b &
OP_#UoUM[Y]_#Z ]#X_#OPUTK j *RZ'OQK&]ffZ'UTV
OP_#UUoM[Y]MN.OaL_#Z ]#X_#OPUKe_0XKXWK "N.RTXKc
[Y]2Oa.KO[a'_0R[ 1RM+_W'XR^KR^eW'UROP_0[YK]#b &`[a.KOQ]ff^W'UK^KZ[_0XVeW.X]#d'UK^]#b ! # 2
(#
] & - j KZ.OQK#` ! # 2
# 2 / )ff
d/KUT]ffZ6fffM([Y] fi - j
2 / )ff
d/KUT]ffZ6fffM([YL
_0Xc.Z.KMMPj @ KP[ #i\ % ^ +}d/K_W'_0X[RT[R]ffZh]#b U . &?rbr]#X_#ZVb1]#X ^}N.Uo%
_ & j 8\ ff ^ & RM
S0_#URc RTb:_#Z.c ]ffZ.UTVRTb\KPS#KPXVW.X R^K2R^W'URoOP_0[YK&]#b &s[a._0[OQ]ffZ[_#RZ.M_S0_0XR_0d"UTK2b1X]ff7
^ \
[rqq z3{

Q*\76

fi

~33



s~$w

~ww$



_#UoMY]OQ]ffZ[_#RZ.M:_?S;_0X R_0d'UTK,brX]ff^!^Rbi_#Z.c]ffZ.UTV2RTbiKPS#KPXVW.XR^eKR^W'URoOP_0[YK,]#b & OQ]ffZ[_#RoZ.M
_2S0_0XR_0d"UTKbrX]ff^ ^ MRZ.OQK U. &/ ! \ . ^e\Rb_#Z.c]ffZ.UTVRTb & RM(MY[YX ROQ[UTVXKUTKPS;_#Z[([Y]
^j

r

;

n ; q " y?z3qv qwqr k '
K^}diKPX Ma.RTW C [YX _#RTfffa[Ybr]#Xq(_0XchbrX]ff^ \X]#W/]ffMRT[RT]ffZ.M 2_#Z'c P*j
_0Xc.Z.KMMM CA:VK6a.RTd"RT[RZ6f_W/]ffUTVZ.]ff^eR_#U#XKc'N.OQ[RT]ffZ}b1X]ff^C!$#(04'*)M!+$#&[Y] ! # 2
# 2 0
/ )
1 fi fi 1/2 ' # 1 .! '

# $ # # 2 j?9]_#ZVW"_#RTX + % 7 -]#b\W.X]#W/]0
MRT[RT]ffZ._#UBbr]#X^&N.U_#MP`iUTKP[D 0 ->7((d/K_b1]#X ^}N.Uo_]#d.[_#RZ6KcbrX]ff^ 7 dVhXKZ._#^eRZ.fRT[M
S0_0XR_0d"UTKMPj dSR]ffN.MUTV#`
Rr6 0 ->7(,RM,M_0[RM _0d'UTK?RTb8_#Z.c]ffZ.UTVRTbM7 RMPj
4] q`"UTKP[ d/K?_eZ6KPq S0_0XR_0d"UTK#`6UTKP[
&"! / / : 0 ->7,
_#Z'X
c U8! U, . . # +ffT
j A+V \X]#W/]ffMRT[RT]ff
Z ` &RV
S=_0Xc6KPW/KZ.c6KZ[]ffX
Z U RTb(_#Z.c
]ffZ'UTVRb[a6KPXKRoM,_W.XR^eK3Ro^W'UROP_#Z[:]#b & ^eKZ[RT]ffZ'RZ6f_S0_0XR_0d'UTKbrX]ff^ Ue`'RmjK#jT`.RTb8_#Z.c
]ffZ'UTVRb / : 0 ->7,(RM,M_0[RoM _0d'UTK#`6[aN.MP`.N'MRZ6fR1I C
RoR1 & RM S=_0XYc.KPWiKZ'c6KZ[4]ffZ U Rb_#Z.c]ffZ'UTVRbd/]#[a _#Z.c: 7 _0XKM_0[RoM _0d'UTK#j
4a6KZB`}_0fff_#RoZ _0br[YKPX =X]#W/]ffMR[RT]ffZ ` & RM S=_0XYRZ'c6KPW/KZ.c6KZ[brX]ff^ U 6 &4 U !
U, .>3 0 ->7(YRTb_#Z'c ]ffZ'UTV RTbZ.] W'XR^KR^W'URoOP_#Z[]#N
b & ^KZ[RT]ffZ.M_ S;_0X R_0d'UTK
brX]ff^ U .> 0 ->7(Y `6RmjK#jT`RTbB_#Z.ce]ffZ'UTVRTb 3 0 ->7(\RM=N.Z'M_0[RM _0d"UTK#`ff[aN.MP`N'MRZ6f
RrIC
RoRR1 & RM S=_0XYRoZ.c6KPW/KZ.c6KZ[,b1X]ff:
^ U . & U RTb9_#Z'ch]ffZ.UTVRTbM7 RM,M_0[RoM _0d'UTK#j
4aN.M`'brX]ff^ \X]#W/]ffMRT[RT]ffZ `8RRr,_#Z.c RRR1 `.q:K&f#KP[[a._0[ & RoM4MY[YXRoOQ[UTVhXKUTKPS0_#Z[[YT
] U
Rb_#Z.c]ffZ'UTVRb RM,M_0[RoM _0d'UTK?_#Z.c 3 0 ->7((RoMZ6]#[Pj
[rqq z3{



Q*\,+

fif.w~3}33f$3ws



&T F\H GE

ff



KPXKRM,_M^_#UU/fffUT]ffMM_0XV]#b8N.MYKPbN.Ui[YKPX^eM,qRT[a[a6K?W'U_#OQK?qa6KPXK3[a6KRTX4c.K Z.RT[RT]ffZOP_#Zd/K3br]ffN.Z.cBj


%$
W.X]#W/]ffMR[RT]ffZ._#UiU_#Z6fffN._0f#Kf#KZ.KPX_0[YKcdB
V U
*KOQ[RT]ffZ j
('$
MYKP[,]#bURT[YKPX _#UM(d'N.RU[:N6WhbrX]ff^ U
*KOQ[RT]ffZ j
(',$
MYKP[,]#b8W/]ffMRT[RTS#K?UR[YKPX_#UM(d'N.RoUT[:N.Wb1X]ff:
^ U
*KOQ[RT]ffZ j
( $.
MYKP[,]#bZ6KPfff_0[RTS#K&URT[YKPX_#UoM+d"N.RUT[(N6WbrX]ff^ U
*KOQ[RT]ffZ j
U. &
MYKP[,]#b8W.X]#W/]ffMR[RT]ffZ._#UiS;_0X R_0d'UTKM,_0W.W/K_0XRoZ6fRB
Z &
*KOQ[RT]ffZ j
4O4
Z6KPfff_0[RT]ffZZ6]#X^e_#UBbr]#X^
*KOQ[RT]ffZ j
( 3 *Q &4
MYKP[,]#bURT[YKPX _#UM(]OPOPN.XXRZ6fRZ[a.
K 4?4 ]#b &
*KOQ[RT]ffZ j
Y= $
_ UIq+]#X UcRZ.MY[_#Z[R_0[RT]ffZ'M,]#b_#UoU/S;_0XRo_0d'UTKM(]#b U} *KOQ[RT]ffZ j
[/$
MYKP[,]#b_#UU U?Iq+]#X Uc.M
*KOQ[RT]ffZ j
=
q:]#XUcrbN.UU/RZ.MY[_#Z'OPR_0[RT]ffZ"
*KOQ[RT]ffZ j
f' e" &
MYKP[,]#b^]*c6KUM(]#b &
*KOQ[RT]ffZ j
').} fi=
br]#X^}N'U_2MN.Oa[a._0?
[ ' ei &ff ! fi
*KOQ[RT]ffZ j
&'gih /
*KOQ[RT]ffZ j
&'gih (
*KOQ[RT]ffZ j
&5j h (
*KOQ[RT]ffZ j
&')l V>= %
*KOQ[RT]ffZ j

&
MYKP[,]#b8W.XRo^K?R^W'URoOP_0[YKM(]#b &
*KOQ[RT]ffZ j

fi &
MYKP[,]#b8W.XRo^K?R^W'URoOP_#Z[M:]#b &
*KOQ[RT]ffZ j
`

*KOQ[RT]ffZ j
" " *KOQ[RT]ffZ j
- ` & - ` fi MYV*Z[_#OQ[RoOP_#U @R[%c6KPW/KZ.c6KZ.OQK
K Z'RT[RT]ffZ
MYV*Z[_#OQ[RoOP_#U S=_0XYc6KPW/KZ.c.KZ.OQK
K Z'RT[RT]ffZ
&
MYK^e_#Z[ROP_#U1 @RT[%c6KPW/KZ.c.KZ.OQK
K Z'RT[RT]ffZ
r ( 3 *P &
URT[YKPX _#UM(MN.Oa[a._0+[ &
K Z'RT[RT]ffZ
< ,. &
MYK^e_#Z[ROP_#U1 S=_0XYc6KPW/KZ.c6KZ.OQK
K Z'RT[RT]ff5
Z <
r ( 3 *P &
S0_0XR_0d'UTKM,MN.Oah[a'_0+[ &
K Z'RT[RT]ff5
Z <
x -"

:ut
K Z'RT[RT]ffZ
yr5v yr.
.#Iw yr.x -"

:ut
K Z'RT[RT]ffZ
&'))(%+* ( 3 *Q & % (: URT[YKPX _#U"br]#Xf#KP[Y[RZ.f
K Z'RT[RT]ffB
Z

&'))(%+* U, 6 & % (: S0_0XR_0d'UTK3br]#Xf#KP[Y[RZ6f
K Z'RT[RT]ffZ
&

@R[%IWK "N.RS;_#UTKZ'OQK
K Z'RT[RT]ffZ
& $

S=_0XYIWK "N.RTS0_#UTKZ.OQK
K Z'RT[RT]ffZ
R Z "N6KZ.OQK_0d'RUoRT[V
K Z'RT[RT]ffZ P
XKUTKPS0_#Z.OQK?[Y]_MN6Gd FYKOQ[^e_0[Y[YKPX
K Z'RT[RT]ffZ
MY[YXRoOQ[,XKUTKPS0_#Z.OQK?[Y]_eMN.Gd F%KOQ[^_0[Y[YKPX
K Z'RT[RT]ffZ &

Q*\^]

fi

~33

]$ B 3



s~$w

~ww$



fi^eRTX`(jT`Yfi

OQpUTX

#_ RT[aB`Yij?;0## j _0X[RT[RT]ffZ*Id'_#MKc U]#fffROP_#U3XK_#MY]ffZ.RoZ6f6j p%Z ,w[!^ uut0yrz{0 ![
vr~6u
iuP0uPz'vr~ z'vuPw z"ffvy5!0zi0 !0zWuQwuQzu !#z (wy1z Py -"TuQ![ fi}z!0|,ut {u uR-"wuuQz'vIffvy5!0z0zit
4u;M!0z.yrz{ J fi IK `"W.W j # 5 <ff#*j
A(RTKPXK#` fi}jT` ?(Ro^e_0[Y[Rm` fi}jT` ?(U_0X#K#`4
j jT`4.N FRT[_*
` jT.
` fi BaNB`2j}[##ff j V*^d/]ffURO^]*c6KU
a6KO*RZ6f3N.MRoZ6f fi W.X]*OQKc.N6XKM9RZ.MY[YK_#c]#=b Mjp%Z ,[w !^ uut0yrz{0Y ![ 2u yT{#z /6 v !0xe#v5y !#z
!#zWPuPwYuPz Tu J K j
A:]#W.W'_#Z._*` Ej AjT` fi *RTW"MYKPX` j'[ #0 jBa6KOQ]ff^eW'UTK 6RT[V}]#b Z'RT[YK(brN.Z'OQ[RT]ffZ.MPj6p%ZS0_#Z @ KPKNq+KZB` 6j
+cBj
` 0ziQt P3!W! ! ~*,u !0wYuv5y 0 !0.
x -/6vuQw ymuPz uP` S]ffUI,j fi}`iO a._0W j <6ji+UMYKPS*RTKP
X 6OPRTKZ.OQK
+N6d'URoMa6KPXM3: 44]#X[a* 4]ffUoU_#Z.c" ` fi^eMY[YKPXc'_#^hj
A:]ffN6[RURKPX` ?3j\[ # < je] q:_0Xc _UT]#fffRO2br]#X "N._#UoRT[_0[RTS#Kc6KOPRMR]ffZ [a6KP]#XV#j&pZ ,[w !Wuut0y1z{0L
![evr~6u
P!D/*wvr~ z'vuQwz"#v0y !0z"# !0Wz uQwuQz u !0z vr~*u ,w yrz Py -"u ! fi}z !#|,Tut{u Ru -iwYuQPuQz"vI#v5y !#z 0zit
4u;M !0z.yrz{ J fi
DK `"W.W =
j 5 j
?(a6]#W'X_*
` ijT=` fi 8_0XRT*aB ` Ej[ ##ff 1j fiZhRZ.OQ]ffZ.MRMY[YKZ.OQV[Y]ffUTKPX_#Z[4^]*c6KUBbr]#Xd/KURTKPb XKPW'XKMYKZ[_0[RT]ffZ
_#Z'cd/KURKPbiXKPSRMRT]ffZBj p%
Z (w !W u ut0yrz{0 ! 3vr~6

u .y 2ffvu uQz'vr~ z'vuPw z"ffv5y !0zi0 !0y1z"v !0Wz uQwuQz u !#z
wvy
1Pym0 z"vuQr
yT{uPz %u J K `'W'W j 5 j
3_0Xq4RO a6K#` fi}j[ # # j fi U]#fffROP_#UBZ6]#[RT]ffZ]#b8OQ]ffZ.c.RT[RT]ffZ'_#UiRoZ.c6KPW/KZ.c6KZ.OQK CW.X]#W/KPX[RTKM(_#Z.ch_0W'W'UROP_;
[R]ffZ.MPj wQvy
Pym0 z'vuP1y {uQz uQ` /[ 5 ff ` <Q 5 j
3_0Xq4RO a6K#` fi}j[ # ff 1
j ]c6KUTId'_#MYKchc.R_0fffZ.]ffMRM,N.MRoZ6f&M[YXN.OQ[N6XKchMVMY[YK^ c.KMOQXRTW.[R]ffZ.MPj G!D/*wz"0
! wQvy
1y# z'vuQry {uQz
u 4uPu0w Q~` #` & 5 j
3_0Xq4RO a6K#*
` fi}j:[ ##ff j ?:]ff^eW'RURZ.f*Z6] qUTKc6f#KRZ[Y]c6KOQ]ff^eWi]ffM_0d'UTKZ6KPfff_0[R]ffZZ6]#X^_#Ub1]#X ^hjp%Z
,[w !^ uut0yrz{0 ![&vr~*u .y 2ffvu uQz'vr
~ z'vuQwz"#v0y !0z"0 !0yrz'v !0Wz uQwuQz u !0z wvy
1y0 z'vuQry {uQz u
J K `'W.W j <)5 #j
3_0Xq4RO a6K#` fi}jT1
` fi _0,X "N.RMP` j[ ##ff j fi W/KPXMYW/KOQ[RTS#Kh]ffZ Z6] q4UTKc6f#KOQ]ff^eW'RU_0[RT]ffZ j p%Z ,[w !DO
uut0y1z{0L
![vr~*u iuQ#uQz'vu uQz'vr~ z'vuPw zi#v5y !#z"0 G!0yrz'v !0Wz uQwuQz +
u !0z wQvy
1y# z'vuQry {uQz u
J K `'W.W j ^D 5 &j
3_S*RMP` jT` fi \N6[Z'_#^h` ji[ 0 *
j fi OQ]ff^W'N6[RZ.f?W.X]*OQKc.N6XK,br]#1X "N._#Z[R OP_0[RT]ffZ[a.KP]#XV# j G!D/*wz"0
! vr~*u L` P` 0 5 GWj
KOa[YKPX` EjTD` fi6E4RoMaB`Ppj[ # < j RXKOQ[RT]ffZ._#UXKMY]ffUN6[R]ffZBP[a6K+c'_S*RM%IW'N6[Z'_#^ W.X]*OQKc.N6XK#`PXKPSRoMRT[YKcBj
p%Z ,[w !^ uut0yrz{0V
![vr~*?u P !D/*wQvr~ z'vuPw z"ffv5y !0zi0 !0Wz uQwuQz u !0zvr~*u (wy1z -iTuQ ![ fi}z !0|,Tut{u
4Ru -"wuuQz'vI#v0y !0z 0z"t u0 !0z.yrz{ Jfi
DK;`'W.W
j <)5 <Qj
c6KU S=_#Um` fi}j:[ ##ff
j fi Z6KPq ^KP[a6]*cbr]#X2OQ]ffZ.MYWK "N6KZ.OQK Z.c.RZ.f_#Z'c OQ]ff^W"RU_0[RT]ffZRoZXKMY[YX ROQ[YKc
Uo_#Z6fffN._0f#K#j#p%Z (w !W u ut0yrz{# ![:vr~*u .y 2ffvu uQz'vr3
~ N#v0y !0z"# !0^z PuPwYuPz u !#z wvy
1y0 z'vuQry {uQz u
J K `.W.Wj # 5 <6` X U_#Z.c6] @ j
]ffa6KPX[V#
` jT` @N60_#MYgPKPq4ROQg#`iJsjT` fi _#c._#UoRZ.MY0_; A(N6fff*_ FQ`ij8[ # ff ja.K 7 fi_#Z.cXKU_0[RTS*RTgRZ6f
a._#Z6f#Kbr]#Xe_#OQ[RT]ffZ N.W/c'_0[YK#jpZ ,[w !^ uut0yrz{0 ![hvr~*u .y 2ffvr~ z'vuQwz"#v0y !0z"# !0Wz uQwuQz B
u !#z
,w yr
z -"u ! fi}z !0|,ut{u u -"wYuQPuPz'vI#v0y !0z 0z"
4u;M !0z.yrz{ Jfi K `'W'W j 5 #j
]ffa6KPX[V#1
` jT` @N.;_#MYgPKPqROQg#`J jT` fi g_#U_#MP` fi}j4; 0# j ?(]ff^W'N6[RZ.fMY[YX]ffZ6f#KMY[Z6KOQKMM_0XV _#Z.c
q:K_0#KMY[,MN6OPRTKZ[:OQ]ffZ.c.RT[R]ffZ.M]#b XM[%I]#Xc6KPX\br]#X^&N.U_#MPj/p%Z ,[w !Wuut0y1z{0 ![3vr~*u iuP0uQz"vuuQz"vr~
z"vuQwz"#v0y !0z"0
G!#y1z'v !0Wz uQwuQz u !0z wQvy
1Pym0 z'vuP1y {uQz Lu J K;`.W.W j <Q 5 WG0j

Q Q)(

fif.w~3}33f$3ws

._0XfffRKPX`6}jT` @_#Z6f6` 6jT` fi _0X,"N'RMP` j?;0## j \X]#W/]ffMRT[RT]ffZ._#U4UT]#fffRO_#Z'c ]ffZ6KQMY[_0f#KLc6KOPRoMRT]ffZ
^_0RZ.f6j p%Z (w !Wuut#y1z{# ![vr~*u iuQ#uQz'vr~ z'vuQwz"#vy0!0z"# !0zWuQwuQz uX!0z ,w yrzy -"u ![
fi}z !0|,Tut{u uR-"wuuQz'vIffvy5!0z 0z"tu;!0z'y1z{ Jfi IK;`'W.W j <<Q 5 <Qj
._0X R Z. _#Mec6KU ?(KPXX]6` @=jT` fi 4KPXgRf6` fij[#ff j A:KURTKPbOa._#Z.f#K_#Z.c c6KPW/KZ.c.KZ.OQK#j pZ ,w[!^ uutDO
yrz{#T
![vr~6u 'y 2vr~ !0^z PuPwYuPz '
u !0z ~*3u !0wuPv0y # -6,u vrB
![ u;!0z'y1z{ P3!D/6v fi}z !0|,Tut{u
J fi K;`'W.W j < +5 &G0j

KUTbr]ffZ.cB` jT` fi @RbrMO a.RT[Yg#
` S}j[ # j E4KPW.XKMYKZ[RZ6f_#OQ[RT]ffZ _#Z.c Oa._#Z6f#KdVUT]#fffROW.X]#f#X _#^eMPj
!D/*wz"0 ! !{ff5y ,[w !{#wY0x2x&yrz{ff` `
5j

3a.Roc.RZ.Rm` ?jT
` fi:
?RN.Z.O a.RTfffUR_*`/:j+; 0#
j @ ]*OP_#U=^]*c6KUMYK^e_#Z[ROPMP`]#X}OQ]ffZ[YK [N._#U\XK_#MY]ffZ.RoZ6f !
U]OP_#UR[
V OQ]ff^W'_0[RTd"RURT[V#j wvy
1Pym0 z"vuQr
yT{uPz uP` P` G 5 #j

]ffUc.d'U_0[Y[P1
` Ej3[ # j !{#0y Q ![ 9yrxuL0z"t !0.
x -/6vI#v0y !0z.` S]ffUIj ]#
b 3u 5v /wu N !#vuQ j
?(KZ[YKPXb1]#X[a.K [N.c6V]#b @9_#Z6fffN._0f#K&_#Z.cpZ.b1]#X^_0[RT]ffZB
` [_#Z6br]#XcB` ? fij

XKRoZ6KPX
` EjT` fi
KZ.KMYKPXKP[aBff` j Ej([ jLJ a._0[ MZ6KPq )_MYK^e_#Z[ROc6K Z.R[RT]ffZ]#b4Z.] S#KUT[V#j
p%Z ,[w !Wuut0y1z{0N
! }vr~*u,y {#~vr~ z'vuQwz"#v0y !0z"# !0yrz'v !0Wz uQwuQz N
u !0z wQvy
1y# z'vuQry {uQz u
J K `'W.W j <Q0"5 <Q <6j

XKRoZ6KPX` EjT` fi *N.d.X_#^e_#Z.Ro_#ZB` }j8[ # ff j =X]*OQKPKc.RZ.fffM,]#b[a6K fi fifip,b_#UUBMYV*^W/]ffMRN.^ ]ffZXKUTKQ
S0_#Z.OQK#jTj:KO a.Z.ROP_#U E4KPW/]#X[ <0 ,` fi fi fi4p =XKMMPj
KPfffZ6KPX` ij[ # j W/KOPR OP_0[R]ffZ_#Z.cR^W'UTK^eKZ[_0[RT]ffZ]#bW.X]#f#X_#^M4br]#XN.W/c'_0[RZ6fRZ'OQ]ff^W'UTKP[YK
RoZ6b1]#X ^e_0[RT]ffZec._0[_0d"_#MYKMPj/pZ (w !W u ut0yrz{0 ![vr~*u .y 2ffvr~
=4;.x -G!0 /x !0ffz ,w yrz Py -"u ![ }ffvIQ P;u 4;vuPx& J [K;`.W.W j < 5 Wj
KPXgRTf6` fi}ji[ # ff j4a6K 7 fi XKPSRoMRT[YKcBj"p
Z (w !W u ut0yrz{0V
![vr~6/u P\y Qvr
~ z'vuQwz"#v0y !0z"# !#Wz PuPwYuPz u
!#z vr~6
u (wy1z -iTuQ ![ fi}z !0|,ut {u u -"wuPuPz'vI#v0y !0z 0zi
u;M !0z.yrz{ J fi K `"W.W j <ff"ff5 0*j
KPXgRTf6` fijT` @9_#Z6f6` 6jT` _0,X "N.RM` jT` fi 9]ffUo_#OPMYKP"`B?j=; 0# j WBc._0[YKMP`B_#OQ[RT]ffZ.M`/_#Z'cW'Uo_#Z.Z.RZ6f6j
p%Z (w !W u ut0yrz{#%
![vr~*u /uQ0uPz'vuuPz'vr
~ z"vuQwz"#v0y !0z"0 !0yrz'v !0^z PuPwYuPz L
u !0z wvy
1y0 z'vuP
yT{uQz L
u J K `.W.Wj 5 & <6j
KPXgRTf6` fi}jT` fi E4R ` j"[ # ff j WBc._0[YK]#W/KPX_0[RT]ffZ.WM Cff_XKPS*RTKPqjipZ (w !W u ut0yrz{0 ![vr~*u ~yrwvu uQz'vr~
/*[w !I-.u0z !#Wz PuPwYuPz N
u !#z wvy
1y0 z"vuQr
yT{uPz L
u J K `.W.Wj 5 ^j
KPXgRTf6` fi}jT*` fi E4R ` j[ ##ff ffj \X]#W/]ffMRT[RT]ffZ'_#U0diKUoRTKPbd'_#MK\N6WBc._0[YK=_#Z.c}^eRZ.R^_#U;O a._#Z6f#K#j wvy
1y0
z"vuQr
yT{uPz uP` [ ` PQ +5 j
p%Z6]ffN6K#` j/[ # ff j @9RZ6K_0X\XKMY]ffUN6[RT]ffZRZOQ]ffZ.MYWK "N6KZ.OQK$5 Z'c.RZ6f6j wQvy
1Pym0 z'vuQr
yT{uPz uP` ; 5 `
5 j
_#N6[Yg#` }jTff
` ?K_0XZ'MPff` jT1` fi *KU^e_#ZB` Aj4[ # j EK_#MY]ffZ'RZ6f q4RT[a Oa'_0X_#OQ[YKPXRMY[RoOh^]c.KUMPjp%Z
,[w !^ uut0yrz{0V
![vr~*u,TuP0uPz'vrff
~ Nffv5y !0zi0 !0^z PuPwYuPz V
u !#z wvy
1y0 z'vuQr
yT{uPz u J MK `
W'W j <)5 j
_#N6[Yg#`F}jT` ?K_0X Z.MP` jT` fi KU^e_#ZB` Aj[ # ff j ]#XZ _0W.W.XW] 6R^e_0[RT]ffZ.M]#b}K^W'RTX ROP_#U3c._0[_*j
wvy
1Pym0 z"vuQr
yT{uPz uP`
:[ ` &# 5 <Qj
_#N6[Yg#` }jT7
` (O fiUoUTKMY[YKPXff` &jT1` fi KUo^e_#ZB` Aj4[ # ff j \Z'OQ]c.RoZ6fW"U_#Z.M2RZ W.X]#W/]ffMR[RT]ffZ._#U:UT]#fffRO0j
p%Z (w !W u ut0yrz{# ! &vr~*ff
u P\y Qvr
~ z"vuQwz"#v0y !0z"0 !0^z PuPwYuPz %
u !0z vr~6u (wyrz Py -"u ![fi}z !0|,Tut{u
4Ru -"wuuQz'vI#v0y !0z 0z"t u0 !0z.yrz{ Jfi K;`'W.W j <)5 <6j

QQ

fi

~33



s~$w

~ww$

c6]ffZB`EjT`fi E]#[a ` &j[#ff j EK_#M]ffZ.RZ6fq4RT[a^]c.KUMPj wvy
1Pym0 z'vuQr
yT{uPz uP` i[ 5 ff `
&+5 G j
?]ffa.Uo_#MP` 6jT` ]#X_#UI` ijT`fiC_0KZ.Z.RI`=Ej9[##ff j \X]#W/]ffMRT[RT]ffZ'_#UBRZ6br]#X^e_0[RT]ffZhMYV*MY[YK^eMj !D/*w z"# ![
!{#0y e0zit !#xY- /*vIffvy5!0z'` 0ff ` G 5 G0j
@_0#K^eKPV#KPX`
&j4[ # ff j fi UT]#fffROP_#U,_#OPOQ]ffN'Z[]#b4XKUTKPS0_#Z.OQK#j p%Z (w !W u ut0yrz{0 ! vr~*uP!D/*wvu uQz'vr~
z"vuQwz"#v0y !0z"0
G!#y1z'v !0Wz uQwuQz u !0z wQvy
1Pym0 z'vuP1y {uQz Lu J K;`.W.W j 5 #j
@_0#K^eKPV#KPX`
2j[ # # j EKUKPS;_#Z.OQKb1X]ff^ _#Z KPW'RoMY[YK^eROW/KPXMYW/KOQ[RTS#K#j wQvy
1y# z'vuQry {uQz uQ`
i[ 5 ff ` +5 &j
@_#Z.f6` .jT` @RdiKPX _0[Y]#XK#` jT` fi _0,X "N'RMP` j8; 0# ff j ?(]ffZ.c.RT[RT]ffZ'_#U RZ.c6KPW/KZ.c.KZ.OQKRZW'X]#W/]ffMRT[RT]ffZ._#U
U]#fffRO0j wQvy
Pym0 z'vuQry {uQz uQ`
9[ 5 ff ` 0 5 &G0j
@_#Z.f6` 6jT` fi _0,X "N'RMP` j\[ # 0_ j ?:]ff^W'UK *RT[VXKMN'UT[M3b1]#XRoZ.c6KPW/KZ.c6KZ.OQK&_#Z.cLc6K Z'_0d'RURT[VRZ
W'X]#W/]ffMRT[RT]ffZ._#UUT]#fffRO0j'p
Z (w !Wuut#y1z{# ![4vr~6u 'y 2vr~ z"vuQwz"#v0y !0z"0 !0Wz uQwuQz
u !0z (wy1z -iTuQ
! fi}z !0|,ut{u u -"wYuQPuPz'vI#v0y !0z 0z"
4u;M !0z.yrz{ Jfi K `'W'W j 5 j
@_#Z.f6

` 6jT` fi8_0,X "N'RMP` j:[ # ;di jh,q:]Z.]#[RT]ffZ.M?]#bc6KPW/KZ.c.KZ.OQKeRZLW.X]#Wi]ffMRT[RT]ffZ._#U8UT]#fffRDO C9OQ]ffZ*
[YX]ffUU_0d'RUoRT[V_#Z'cc6K Z'_0d'RURT[V#j2pZ ,[w !^ uut0yrz{0T
![vr~*
u P\y vu uQz'vr_
~ N}#v5y !#z"0 !#Wz PuPwYuPz +
u !#z
wvy
1Pym0 z"vuQr
yT{uPz %u J K;`.W.W j 5 j
@_#Z.f6` 6jT` fi _0,X "N.RMP` j"; 0# ff j EKMY]ffUSRZ.f3RoZ.OQ]ffZ.MRM[YKZ.OPRTKMdV&S0_0XR_0d'UTK(br]#Xf#KP[Y[RZ6f6j"pZ ,[w !^ uuDt
yrz{# ![2vr~*u (yT{0~vr~ z'vuQwz"#v0y !0z"# !0Wz uQwuQz u !#z (wyrz Py -"uN
! fi}z !0|,Tut{u u -"wYuQPuPz'vID
v0y !0z0z"
4u;M !0z.yrz{ Jfi WK `'W'W j 5 0*j
@_#Z.f6` 6jT` _0IX "N.RoMPQ` jTff` fi J RoUUR_#^eM` j fi}j/; 0# j 4WBc._0[RZ.f?KPW'RMY[YK^eRoOMY[_0[YKMPj p%Z ,[w !^ uut0yrz{0
! 2vr~6ff
u P!D/*wvu uQz'vr~ /vwY0y#z !0yrz'v !0Wz uQwuQz L
u !0z wvy
1Pym0 z'vuP1y {uQz u J K;`BW.W j
# +5 j
@ KPSV#` fijT`iR#KMP` EjT` fi *_0fffRTSi` 2j[ # # j W/KPKc.RZ6feN6WRZ6brKPXKZ.OQKMN.MRZ6fXKUTKPS;_#Z'OQKXK_#MY]ffZ'RZ6 f C
fisbr]#X^e_#URoM^ _#Z.c_#UTf#]#XR[a.^eMPj wQvy
1Pym0 z'vuP1y {uQ
z uQ` i[ ff ` 5 j
@RoZB`6+j; 0## j ZhMY[YX]ffZ6f#KMY[4Z6KOQKMM_0XV_#Z.chq:K_0#KMY[MN.OPRTKZ[(OQ]ffZ'c.RT[RT]ffZ.Mjp%ff
Z (w !Wuut#y1z{#N
![
vr~6

u iuP0uPz'vr~ z'vuPw z"ffv5y !0zi0 !0Wz uQwuQz u !#z (wy1z Py -"TuQ
![ fi}z !0|,ut {
u Ru -"wuuQz'vIffv5y !0z0zit
4u;M !0z.yrz{ J fi IK `"W.W
j &+5 ^Dj
@RoZB` :jT` fi E4KRT[YKPX` Ej:[ # < j6]#Xf#KP[2R[ Tjp%Z (w !Wuut#y1z{#+
![vr~*u P01 40Yx - !; /*x !#z
4uQuQ;#
z uP`'W.W j W <)5 W#j
_0,X "N'RMP` j?[ # < j ]ffMMRd'UTK^]*c6KUM_0W.W.X]ff_#O SR_RZ.c6KPW/KZ.c6KZ'OQV#j p%Z ,[w !^ uut0yrz{0 ![vr~6u
,TuP0uPz'vr~ /*[w ! -6u0
z !0Wz uQwuQz N
u !0z wvy
1y0 z'vuQr
yT{uPz %
u J
K `.W.Wj 5 <ff*j
_0,X "N'RMP` j+; 0## j ?:]ffZ.MYWK "N6KZ.OQK Z.c.RZ6f_#UTf#]#XR[a.^eMPjp%Z }0z"Qt P,!W! '!0z 25u u0 PQu 4u;M !0z
yrz{#z"
z uPwvI#y1z'5v 4 0z"{uQxuQz'v =4 QvuQx& 1 !0 /*xu { !0wyrvr~x& !0
w z uPwvI0yrz 0zit
20u Pu; PQu u0 !0z.yrz{ff`"Oa'_0W j `.W.Wj < 5 <Q,j UoNq:KPX fiOP_#c.K^eRO +N6d'URMa6KPXMPj
_0,X "N'RMP
` jT` fi:]#,X "N.KP[P%` 4}j:; 0## j KOQ]ff^eWi]ffMRZ6fW.X]#Wi]ffMRT[RT]ffZ._#U8*Z6] qUTKc6f#Kd"_#MYKM[a.X]ffN6fffa
[Y]#W"ROPM&rK *[YKZ.c6Kc_0d'MY[YX_#OQ[ j4pZ ,[w !^ uut0yrz{0 ![}vr~6u&xuuPvyrz{ !#
z #wvym0 ;z !0|,ut{ue0zit
/*z uQwQvI0yrz'5v 4 yrz"tRu -.uQz"tuPz u 1 I!0z"t0yv5y !#z.y1z{ 1+yrWz uQwuQz u j
>O ?(_0X[aV#` .j9[ ff
j fiW.W'URoOP_0[RT]ffZ.M(]#b=OPRTXOPN'^eMOQXRTW'[RT]ffZ[Y]br]#X^e_#URgRZ6fOQ]ff^e^]ffZ*MKZ.MYK*Z6] q4U
Kc.f#K#j wQvy
Pym0 z'vuQry {uQz uQ` ff` # 5 &j
a._0X

QQ_

fif.w~3}33f$3ws

OQpUTX

_#RT[aB` ijT` fi fi^eRX`:4j;0# j a6KP]#XK^ W.X] SRoZ6f q4RT[a MY[YXN.OQ[N.XKc [a6KP]#XRTKMPj pZ ,w[!DO
uut0y1z{0L![vr~*u iuQ#uQz'vu uQz'vr~ z'vuPw zi#vy5!#z"0G!0yrz'v !0zWuQwuQzu+!0z wQvy
1y# z'vuQry {uQzu
J K `'W.W j <)5 0j
8_0W'_#c.R^RT[YXRT]ffNB` ?j}j9[ # < j !0.
x -/6vI#v5y !#z"0 !0.
x -"3u 2#yv540j7fic.c.RM]ffZ*IJLKMUTKPV#j
8_0XRT*aB1
` Ej[ # ff j uQyI5u N
1 P uQym0u wuQ y1 0y !0z210z"t -"yrvmvyrz{ T0z{ /6 {u`(W.W 7j 5 j@]#fffRO0`
@9_#Z6fffN._0f#K&_#Z.c ?:]ff^W'N.[_0[RT]ffZBj ? G@1
p +N6d'UROP_0[R]ffZ.MPj
8_0Xi`*j .jT` fi
KUc6KPX` fi} j S}j [ # ff j 8_0X[RT[R]ffZ.RZ6f&^KP[a6]*c.M(b1]#X,M_0[RoM _0d'RUoRT[V[YKMY[RoZ6f2]ffZhU_0Xf#K
br]#X^&N.U_#MPjLp%Z (w !W u ut0yrz{0 ! vr~*u ~yrwvu uQz'vr~ z'vuQwz"#v0y !0z"# !0Wz uQwuQz B
u !#z /6 v !0xe#vut
2uDt /v0y !0z J K `.W'W j < G5 j
=XgPV^&N.MRZ'MYRI`/9
j ?j+[ #ff j fiZ_#UTf#]#XR[a.^ [Y]OQ]ff^eW'N6[YKOPRTX OPN.^eMOQXRW.[RT]ffZBj wQvy
Pym0 z'vuP1y
{uQz uQ` #` < G5 j
EKR[YKPX` Ej[ # j fi [a6KP]#XV]#bc.Ro_0fffZ6]ffMRM}b1X]ff^ X MY[}W'XRZ.OPRTW"UTKMPj wQvy
Pym0 z"vuQr
yT{uPz uP` ff`
+5 j
E4RoZ[_#Z6KZ ` 6j*; 0# j 8_0X[R_#UR^W'URoOPRT[BN.Z6br]ffUc.RZ6f,RZ[a6K _ SRoM% \N6[Z'_#^ W.X]OQKc.N.XK=br]#X "N._#Z[R Kc
d/]]ffUTK_#Zebr]#X^&N.U_0K#jipZ (w !W u ut0yrz{0 ![vr~*
u P B!0w G~ !I-L#v #`W.W j <)5 j
EVff_#Z /
` /j &j,[ #G @
j KPbr_#N.U[M&_#Z'c XKPSRMRT]ffZ RoZ MY[YX N.OQ[N6XKc [a6KP]#XRTKMjLpZ (w !W u ut0yrz{# ! vr~6u
'y 2vr~ 40.x -G!;y /*x !0z !{ff5y &yrz !0.x -/6vuQw PyIuQz %u J K `'W'W j 5 j
EVff_#Z 1
` 7j &j[ # ff j (wYtuPwYuB
-"wYuQPuPz'vI#v0y !0z6 ![vr~*,u !0w yIuj \aBj &j=[a.KMRMP`=p%^W/KPXR_#U ?(]ffUUTKPf#K#`
@]ffZ.c6]ffZBj
*_#Z.c.KPq:_#UUI`*4j[ # ff +
j Puff5v /wu20z"
P\ /'uQz"vr j br]#X Z'RTS#KPXMRT[L
V \XKMMPj
*RTKPf#KUI` j=[ # j u -"
w u PuPz'vI#v0y !0z uPv /6vyr
y1Q#v0y !0z tu ,!#z.z"0y1P0z uQuQz 0 M/* -"[w ! -G!; yv0y !0z.ziuP
j
4a K MYKc \ [_0[P` Z.RTS#KPXMR[ K c0 fiR 5 _0XMYKRUU
K jRZb1XKZ.Oa" j
*R^e]ffZB` @=jTY
` fi c6KU S=_#Um` fij&; 0# j =OPRTKZ[OQ]ffZ.MYWK "N6KZ.OQK Z'c.RZ6f6j pZ ,[w !^ uut0yrz{0 ![vr~6u
/uQ0uPz'vuuPz'vr~ z'vuQwz"#v0y !0z"0 G!#y1z'v !0Wz uQwuQz Nu !0z wvy
1y0 z'vuP1yT{uQz %u J K;`6W.W j
# 5 j
*N6d'X_#^e_#Z.R_#Z ` }jT`
XKRoZ6KPX` EjT` fi 9K_0X Um

` .j:[ # #
j fi4X[R OPR_#U=p%Z[YKUURTf#KZ.OQK #]ffN6XZ'_#0U C W/KOPR_#U
p%MMN.K?]ffZ EKUTKPS0_#Z.OQK#`/ h[ ff ` # j
_#ZB` ijT` fiK_0XUm` 6j[ # <
j W/KOPR OP_0[RT]ffZ_#Z'cKPS0_#UN._0[RT]ffZ]#bW.XKPbrKPXKZ.OQKMbr]#XW'U_#Z.Z.RoZ6f&N'Z.c6KPX
N'Z.OQKPX[_#RZ[V#j(p%Z (w !W u ut0yrz{# ![}vr~*
u P !/wQvr~ z'vuPw zi#v5y !#z"0 !0Wz uQwuQz u !0zvr~*u (wy1z -iTuQ
! fi}z !0|,ut{u u -"wYuQPuPz'vI#v0y !0z 0z"
4u;M !0z.yrz{ Jfi
K j
J RUUR_#^MPW` j;:jTD` A:RKPXK#` fi}jT` ?(U_0X#K#`;j jT` fi
3N.W.[_*` fi}j6; 0## j ?:]ff^d"RZ.RZ6f KOPRMRT]ff
Z 3R_0f#X _#^eM
_#Z'c fi \X]*OQKc.N6XKM}b1]#X\OPRTKZ[ V*^}di]ffUoRO ]c6KU ?(a.KO*RZ6f6jpZ (w !Wuut#y1z{#T
! vr~6u
9|+uP Qvr~ z'vuPw z"ffv5y !0zi0 !#Wz PuPwYuPz N
u !#z !#Yx - /*vuPw ymtu
"uQwy
1 #v0y !06
z J K j
J RZ.MUTKP[Y[P` j\[ #0 j -*t#vy1z{ !{#0y # &#vIQ P0Puj ?(_#^d'XRc6f#K2X _#OQ[MRZ a6KP]#XKP[RoOP_#U ?:]ff^2
W"N6[YKPX *OPRTKZ'OQK#j ?(_#^d'XRc6f#K Z.RTS#KPXMRT[L
V =XKMMj

Q Q*\

fiJournal Artificial Intelligence Research 18 (2003) 351-389

Submitted 10/02; published 5/03

New General Method Generate Random Modal Formulae
Testing Decision Procedures
Peter F. Patel-Schneider

PFPS @ RESEARCH . BELL - LABS . COM

Bell Labs Research
600 Mountain Ave. Murray Hill, NJ 07974, USA

Roberto Sebastiani

RSEBA @ DIT. UNITN .

Dip. di Informatica e Telecomunicazioni
Universita di Trento
via Sommarive 14, I-38050, Trento, Italy

Abstract
recent emergence heavily-optimized modal decision procedures highlighted key
role empirical testing domain. Unfortunately, introduction extensive empirical tests
modal logics recent, far none proposed test generators satisfactory.
cope fact, present new random generation method provides benefits previous methods generating empirical tests. fixes much generalizes one best-known
methods, random CNF test, allowing generating much wider variety problems, covering principle whole input space. new method produces much suitable test sets
current generation modal decision procedures. analyze features new method
means extensive collection empirical tests.

1. Motivation Goals
Heavily-optimized systems determining satisfiability formulae propositional modal logics available. systems, including DLP (Patel-Schneider, 1998), FACT (Horrocks,
1998), *SAT (Giunchiglia, Giunchiglia, & Tacchella, 2002), MSPASS (Hustadt, Schmidt, & Weidenbach, 1999), RACER (Haarslev & Moller, 2001), optimizations much
faster previous generation modal decision procedures, LEAN K (Beckert & Gore,

1997), L OGICS W ORKBENCH (Heuerding, Jager, Schwendimann, & Seyfreid, 1995), KE (Pitt &
Cunningham, 1996) K SAT (Giunchiglia & Sebastiani, 2000). 1
theorem proving problems, neither computational complexity asymptotic algorithmic complexity useful determining effectiveness optimizations,
effectiveness determined empirical testing (Horrocks, Patel-Schneider, & Sebastiani,
2000). Empirical testing directly gives resource consumption terms compute time memory
use; factors pieces system, basic algorithm itself. Empirical testing
used compare different systems, also tune system parameters
used modify performance; moreover, used show sort inputs
system handles well, sort inputs system handles poorly.
Unfortunately, introduction extensive empirical tests modal logics recent,
far none proposed test methodologies satisfactory. methods contain many



1. complete list see Renate Schmidts Web page listing theorem provers modal logics
http://www.cs.man.ac.uk/schmidt/tools/.
c 2003 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiPATEL -S CHNEIDER & EBASTIANI

formulae easy current heavily-optimized procedures. contain high rates
trivial insignificant tests. generate problems artificial and/or significant
sample input space. Finally, methods generate formulae big parsed
and/or handled.
reasons described above, presented (Horrocks et al., 2000) analytical survey
state-of-the art empirical testing modal decision procedures. instead present
new random generation method provides benefits previous methods generating empirical tests, built preliminary work (Horrocks et al., 2000). new method fixes much
generalizes 3CNF methodology randomly generating clausal formulae modal logics
(Giunchiglia & Sebastiani, 1996; Hustadt & Schmidt, 1999; Giunchiglia, Giunchiglia, Sebastiani,
& Tacchella, 2000) used many previous empirical tests modal decision procedures. eliminates drastically reduces influence major flaw previous method, 2 allows
generating much wider variety problems.
Section 2 recall list desirable features good test sets. Section 3 briefly
survey state-of-the-art test methods. Sections 4 5 present discuss basic
advanced versions new test method respectively, evaluate features presenting
large amount empirical results. Section 6 provide theoretical result showing
advanced version method, principle, cover whole input space. Section 7
discuss features new method, compare wrt. state-of-the-art methods.
Section 8 conclude indicate possible future research directions.
5-page system description random generator presented IJCAR2001 (PatelSchneider & Sebastiani, 2001).

2. Desirable Features Good Test Sets
benefits empirical testing depend characteristics inputs provided testing,
empirical testing provides data particular inputs. inputs typical
suitable, results empirical testing useful. means inputs
empirical testing must carefully chosen. Horrocks (Horrocks et al., 2000)
previously proposed motivated following key criteria creating good test sets.
Representativeness: ideal test set represent significant sample whole input
space. good empirical test set least cover large area inputs.
Difficulty: good empirical test set provide sufficient level difficulty system(s)
tested. (Some problems hard even state-of-the-art systems,
good benchmark forthcoming systems.)
Termination: practical use, tests terminate provide information within
reasonable amount time. inputs hard, system may able
provide answers within established time. inability system interest,
make system comparison impossible insignificant.
2. is, significant amount inadvertently trivial problems generated unless parameter p set 0 (Horrocks et al., 2000). See Section 4.1 full discussion point.

352

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Scalability: difficulty problems scale up, comparing absolute performances may
less significant comparing performances scale problems increasing
difficulty.
Valid vs. not-valid balance: good test set, valid not-valid problems
less equal number difficulty. Moreover, maximum uncertainty regarding
solution problems desirable.
Reproducibility: good test set allow easily reproducing results.
following criteria derive significant sub-cases main criteria above.
Parameterization: Parameterized inputs sufficient parameters degrees freedom allow
inputs range large portion input space.
Control: particular, useful parameters control monotonically key features input test set, like average difficulty valid vs. non-valid rate.
Modal vs. propositional balance: Reasoning modal logics involves alternating two orthogonal search efforts: pure modal reasoning pure propositional reasoning. good test
set challenging viewpoints.
Data organization: data summarizable make comparison possible
limited effort plottable enable qualitative behavior system(s)
highlighted.
Finally, particular care must taken avoid following problems.
Redundancy: Empirical test sets must carefully chosen include inadvertent redundancy. also chosen include small sub-inputs dictate result
entire input.
Triviality: good test set flawless, is, contain significant subsets
inadvertent trivial problems.
Artificiality: good empirical test set correspond closely inputs applications.
Over-size: single problems big w.r.t. difficulty, resources
required parsing data managing seriously influence total performance.
criteria, described motivated detail Horrocks et al. (2000),
proposed five-year debate empirical testing modal logics (Giunchiglia & Sebastiani,
1996; Heuerding & Schwendimann, 1996; Hustadt & Schmidt, 1999; Giunchiglia et al., 2000;
Horrocks & Patel-Schneider, 2002). (Notice criteria identical similar
suggested Heuerding & Schwendimann, 1996.)
criteria general, cases require interpretation. First,
implicitly interpreted unless user deliberately wants contrary
reason. instance, might case one wants deliberately generate easy problems,
e.g., sure tested procedure take much time solve them, redundant
353

fiPATEL -S CHNEIDER & EBASTIANI

problems, e.g., test effectiveness redundancy elimination technique, satisfiable
problems only, e.g., test incomplete procedures. extent, key issue
reasonable form control features, one address general-purpose
criteria, also specific desiderata.
Second, cases, may tradeoff two distinct criteria, may
necessary choose one them, make compromise. One example given
redundancy artificiality: real-world problems large parts knowledge base
irrelevant query, whose result determined small subpart input; sense
eliminating redundancies may make problems artificial.
Particular attention must paid problem triviality, claimed victims many
areas AI. fact, flaws (i.e., inadvertent trivial problems) detected random generators
SAT (Mitchell, Selman, & Levesque, 1992), CSP (Achlioptas, Kirousis, Kranakis, Krizanc, Molloy, & Stamatiou, 1997; Gent, MacIntyre, Prosser, Smith, & Walsh, 2001), modal reasoning (Hustadt & Schmidt, 1999) QBF (Gent & Walsh, 1999). Thus, notion trivial (and thus
flawed) deserves comment.
work Achlioptas et al. (1997) flawed problems solvable linear time
standard CSP procedures, due undesired presence implicit unary constraints causing
variables value inadmissible. similar notion holds SAT (Mitchell et al., 1992) QBF
(Gent & Walsh, 1999). literature modal reasoning, instead, typical flawed problems
whose (un)satisfiability verified directly propositional level, is, without
investigating modal successors; kind problems typically solved negligible time
w.r.t. problems similar size depth (Hustadt & Schmidt, 1999; Giunchiglia et al., 2000;
Horrocks et al., 2000).3 Thus, little abuse notation otherwise specified,
paper call trivially (un)satisfiable problems kind. 4

3. Overview State-of-the-art
Previous empirical tests mostly generated three methods: hand-generated formulae
(Heuerding & Schwendimann, 1996), randomly-generated clausal modal formulae (Giunchiglia &
Sebastiani, 1996; Hustadt & Schmidt, 1999; Giunchiglia et al., 2000), randomly-generated
quantified boolean formulae translated modal formulae (Massacci, 1999).
already presented detailed analysis three methods (Horrocks et al., 2000).
present quick overview latter two methods, refer following sections.5
3.1 3CNF Random Tests
3CNF test methodology (Giunchiglia & Sebastiani, 1996; Hustadt & Schmidt, 1999;
Giunchiglia et al., 2000), performance system evaluated sets randomly generated 3CNF formulae. CNF formula conjunction CNF clauses, clause
3. course modal implicitly assume modal depth strictly greater zero, is,
consider purely propositional formulas.
4. Notice use suitable expression propositionally (un)satisfiable latter
used different meaning literature modal reasoning (see, e.g., Giunchiglia & Sebastiani, 1996, 2000).
5. first method (Heuerding & Schwendimann, 1996) obsolete, formulae generated easy current
state-of-the-art deciders (Horrocks et al., 2000).

354

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

disjunction either propositional modal literals. literal either atom negation.

Modal atoms formulae form , CNF clause. 3CNF formula
CNF formula clauses exactly 3 literals.
3.1.1 R ANDOM G ENERATOR
3CNF formula randomly generated according five parameters: (maximum) modal
depth ; number clauses top-level conjunction ; number propositional variables

; number distinct box symbols ; probability atom occurring clause
depth purely propositional.
random 3CNF generator, final version (Giunchiglia et al., 2000), works follows:
3CNF formula depth produced randomly generating
depth , forming conjunction;



3CNF clause depth produced randomly generating three distinct, commutativity disjunction, 3CNF atoms depth , negating probability
0.5, forming disjunction;











propositional atom produced picking randomly element
uniform probability;

3CNF clauses

ff fifi



3CNF atom depth produced generating probability random
"!
"!
,
picked
propositional atom, probability 3CNF atom

"#

randomly ff

randomly generated 3CNF clause depth $% .

Recently Horrocks Patel-Schneider (2002) proposed variant 3CNF random
#
generator Giunchiglia et al. (2000). added four extra parameters: &(' & , representing
#
#",respectively probability propositional modal atom negated, ) +* )
,
representing respectively minimum maximum number modal literals clause,
equal probability number range. experiments, always set &.'0/1243
#
#",6and ) +* /5)
/57 . extent, 3CNF formulas generated generator
#
# +*
#",6Giunchiglia et al. (2000) setting & ' /8&
/9243 )
/:)
/97 .
3.1.2 EST ETHOD & DATA NALYSIS
3CNF test method works follows. typical problem set characterized fixed

, , : varied way empirically cover 100% satisfiable100%
unsatisfiable transition. Then, tuple parameters values (data point on)
problem set, certain number 3CNF formulae randomly generated, resulting
formulae given input procedure test, maximum time bound. Satisfiability
rates, median/percentile values CPU times, median/percentile values parameters,
e.g., number steps, memory, etc., plotted number clauses ratio

clauses propositional variables <; .
3.2 Random QBF Tests
QBF-based benchmarks (such part TANCS99 benchmarks (Massacci, 1999)), system performances evaluated sets random quantified boolean formulae, gener355

fiPATEL -S CHNEIDER & EBASTIANI

ated according method described Cadoli, Giovanardi, Schaerf (1998) Gent
Walsh (1999) converted modal logic using variant conversion Halpern
Moses (1992).
3.2.1 R ANDOM G ENERATOR





Random QBF formulae generated alternation depth

variables
alternation. matrix random propositional CNF formula clauses length ,
constraints number universally existentially quantified variables within
clause. (This avoids problem generating flawed random QBF formulae highlighted Gent
& Walsh, 1999.) instance, random QBF formula /97 , /
looks like:


ff
fi
ff


fi ff
fi ff

(1)
random CNF formula parameters , . denote
total number universally existentially quantified variables respectively. Clearly,
!#" . Moreover, $ modal formula resulting Halpern Moses %
conversion, depth number propositional variables $ also &'()" .






















3.2.2 EST ETHOD & DATA NALYSIS
test method, used TANCS competition(s) (Massacci, 1999), works follows.
tests performed single data points. data point, certain number QBF
formulae randomly generated, converted modal logics resulting formulae given
input procedure tested, maximum time bound. number tests
solved within time-limit geometrical mean time successful solutions
reported. Data rescaled abstract away machine run-dependent characteristics.
results typically collection tables presenting data pair system test, one data
point per row.

4. New CNF Generation Method: Basic Version
previous analysis (Horrocks et al., 2000) none current methods
completely satisfactory. cope fact, propose believe much satisfactory method randomly generating modal formulae. new method seen improved much general version random 3CNF generation method Giunchiglia
et al. (2000).
present new method introducing incrementally new features two main steps.
section introduce basic version method, wherein






provide new interpretation parameter (Section 4.1) allows varying
without causing flaws described Horrocks et al. (2000);
extend interpretation parameter (Section 4.3), providing fine-grained
way tuning difficulty generated formulae.

Section 5, present full, advanced version method, wherein
356

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE




extend parameters , allowing shaping explicitly probability
distribution propositional/modal rate clause length respectively (Section 5.1);




allow vary nesting depth subformulae (Section 5.2), allowing
different distributions different depths.

investigate properties CNF generator also present series experiments
appropriate settings either mimic previous generation methodologies produce improved
new kinds tests.
tests adopted testing criteria 3CNF method. test set,
fixed parameters except , varied span least satisfiability transition area.
(Because Valid vs. non-valid balance feature Section 2, consider transition area


interesting portion test set.) almost test sets varied ,



, , resulting integral values ;
ranging , 3 , .
3
value generated 100 formulae, sufficient number produce reasonably reliable data.
time limit 1000 seconds imposed attempt determine satisfiability status
formula. common practice, set number boxes throughout testing.
setting produces hardest formulae (Giunchiglia & Sebastiani, 1996; Hustadt & Schmidt,
1999; Giunchiglia et al., 2000). performed several test sets similar parameters, often,

always, varying .
tested formulae two systems, DLP version 4.1 (Patel-Schneider, 1998)
*SAT version 1.3 (Tacchella, 1999), two fastest modal decision procedures. available http://www.bell-labs.com/usr/pfps/dlp http://www.mrg.dist.unige.it/tac respectively.
code used generate tests available http://www.bell-labs.com/usr/pfps/dlp.
plotted results test groups (test sets similar parameters) six four plots.
Two plots devoted performance DLP, one showing median one showing

90th percentile time taken solve formulae value , plotted <; .
test groups ran *SAT also plotted median 90th percentile *SAT.
also plotted fraction formulae determined satisfiable unsatisfiable
DLP within time limit.6 save space, satisfiability unsatisfiability fractions plotted
together single plot. Satisfiability fractions higher left side plot unsatisfiability fractions higher right. multiple plotting obscure details,
information interested general behavior fractions,
obscured. fact, multiple plotting serves highlight crossover regions,
satisfiability unsatisfiability fractions roughly equal.
Finally, plotted fraction formulae DLP finds model determines
formula unsatisfiable without investigating modal successors. call fractions
trivial satisfiability trivial unsatisfiability fractions. last fractions estimate
number formulae satisfiable Kripke structure successors like, e.g.,
fi propositional valuations like, e.g., 6fi fi respecfi
tively. various reasons, discussed below, better indicators triviality








"







fi"

6. Notice two curves symmetric respect 0.5 test exceeds time limit. E.g.,
point 40% tests determined satisfiable DLP, 10% determined unsatisfiable
ff .
50% solved within time limit, two curves symmetric point,
fi

357

fiPATEL -S CHNEIDER & EBASTIANI

formal measures used previous papers. Again, trivial satisfiability unsatisfiability fractions
plotted together single plot.
reduce clutter plots, used line show results value tested.
distinguish various lines plot, plotted every five 10 data points
symbol, identified legend plot.
Running tests presented paper required months CPU time. this,
ran tests variety machines. machines range speed 296MHz SPARC
Ultra 2 400MHz SPARC Ultra 4 256MB 512MB main memory.
machines completely dedicated tests, otherwise lightly loaded. test
set run machines speed memory. Direct comparison different
groups tests thus take account differences various test machines.
4.1 Reinterpreting Parameter
One problem previous methods generating CNF formulae generated formulae contain pieces make entire formula easy solve. mostly results
presence strictly-propositional top-level clauses. small number propositional variables tests (required produce reasonable difficulty levels current systems),
strictly-propositional top-level clauses needed cover combinations propositional literals make entire formula unsatisfiable. Previous attempts eliminate trivial
unsatisfiability concentrated eliminating top-level propositional literals setting /5
(Hustadt & Schmidt, 1999; Giunchiglia et al., 2000). (Unfortunately choice forces
,
9 formulae hard state-of-the-art systems.) atom
clause generated independently atoms clause approach modifies
probability propositional atoms necessary eliminate problematic clauses.



first new idea approach, suggested previously (Horrocks et al., 2000), works
follows. Instead forbidding strictly-propositional clauses except maximum modal depth, ,
setting / , instead require ratio propositional atoms clause
clause size close possible propositional probability clauses maximum
modal depth . 7





clauses size , ; integral , results clauses modal
depth propositional atoms
modal atoms. values , allow
4
propositional atoms clause modal depth , probability
either 4


4 , respectively.8 instance, / 2 / 7 , clause
4
0
contains 1 propositional 1 modal literal, third propositional probability 0.8,


, eliminates possibility strictly
7
2 $
7 2
/
$9 /
2 .
9 ;
propositional clauses, main cause trivial unsatisfiability, except modal depth .






fiff fiff fi



fi

"

fiff

7. approaches eliminating propositional unsatisfiability possible. example, would possible
simply remove strictly-propositional clauses generation. However, technique would alter meaning
parameter , is, actual probability literal propositional would become strictly smaller
, control user.



.
8. Remember




!#"%$'&)( "+*-,+. /0 1 "2#"+$'&3( "+45,%.
358

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6
N=7
N=8
N=9

0.8

N=3
N=4
N=5
N=6
N=7
N=8
N=9

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60
L/N

80

100

120

20

DLP median times

40

60
L/N

80

100

120

DLP 90th percentile times

1000

1000

N=3
N=4
N=5
N=6
N=7
N=8
N=9

100

N=3
N=4
N=5
N=6
N=7
N=8
N=9

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60
L/N

80

100

120

20

*SAT median times

40

60
L/N

80

100

120

*SAT 90th percentile times

1000

1000

N=3
N=4
N=5
N=6
N=7
N=8
N=9

100

N=3
N=4
N=5
N=6
N=7
N=8
N=9

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60
L/N

80

Figure 1: Results

4.1.1 ODAL EPTH



100

/

7

120

,

/

,

/

20

40

,

/:243

60
L/N

80

100

120

(old method)



first experiments direct comparison previous tests. generated CNF formulae
/17 , / , / , / 243 , setting used past, one
exhibits problematic behavior. used new method old 3CNF generation
method Giunchiglia et al. (2000) briefly described Section 3.1 (the old method
on). also generated CNF formulae /17 , / , / , / , standard
method eliminating trivially unsatisfiable formulae. (At / new method
old 3CNF generation method.) results tests given Figures 1, 2, 3.
359

fiPATEL -S CHNEIDER & EBASTIANI

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6
N=7
N=8
N=9

0.8

N=3
N=4
N=5
N=6
N=7
N=8
N=9

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60
L/N

80

100

120

20

DLP median times
1000

60
L/N

80

100

120

DLP 90th percentile times
1000

N=3
N=4
N=5
N=6
N=7
N=8
N=9

100

40

N=3
N=4
N=5
N=6
N=7
N=8
N=9

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60
L/N

80

100

120

20

*SAT median times
1000

60
L/N

80

100

120

*SAT 90th percentile times
1000

N=3
N=4
N=5
N=6
N=7
N=8
N=9

100

40

N=3
N=4
N=5
N=6
N=7
N=8
N=9

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60
L/N

80

Figure 2: Results



100

/97

,

120

/

20

,

/

,

/:243

40

60
L/N

80

100

120

(our new method)

One aspect set tests three collections many trivially unsatisfiable formulae satisfiability transition area, even collection top-level propositional atoms.
trivial unsatisfiability occurs collection top-level propositional atoms

/
7 ) DLP *SAT detect
top-level modal atoms (e.g.,
clashes complementary modal literals without investigating modal successors.
presence large number trivially unsatisfiable formulae actually serious
problem tests. trivial unsatisfiability shows formulae almost

/
7 , trivial
unsatisfiable already easy solve. exception
solve anyway. However, new generation method considerably reduces number trivially
unsatisfiable formulae almost entirely removes satisfiable/unsatisfiable transition



360

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6

0.8

N=3
N=4
N=5
N=6

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60
L/N

80

100

120

20

DLP median times

40

60
L/N

80

100

120

DLP 90th percentile times

1000

1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60
L/N

80

100

120

20

*SAT median times

40

60
L/N

80

100

120

*SAT 90th percentile times

1000

1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60
L/N

80

Figure 3: Results



100

/97

120

,

/

20

,

/

,

40

/:

60
L/N

80

100

120

(either method).

area. trivially satisfiable formulae set tests, few,
smallest clause sizes. presence affect difficulty generated formulae.
two methods /:243 relatively close maximum difficulty, new method
generating somewhat harder formulae. However, method produces difficult formulae,

DLPand *SAT, much broader range <;
original method.
Changing / results formulae orders magnitude harder. good,
previous arguments contrary notwithstanding, would like significant number
reasonable test sets work with, / allows consideration values

formulae totally impossible solve current systems, resulting
reasonable test sets.
361

fiPATEL -S CHNEIDER & EBASTIANI

So, maximum modal depth %/ method results formulae similar
difficulty previously-generated formulae still trivially unsatisfiable formulae,
ones seriously affect difficulty test sets.
4.1.2 ODAL EPTH



Restricting attention maximum modal depth / useful. Formulae maximum modal depth representative modal formulae general, particularly
nested modal operators. Sticking maximum modal depth seriously limits
significance generated tests.
would thus like able perform interesting experiments larger maximum modal
depths. performed set experiments maximum modal depth /
. started
set tests corresponds previously-performed experiments.
depth /
, old method / 243 time curves dominated half-dome
shape, whose steep side shows number trivially unsatisfiable formulae becomes
large formulae become otherwise easy solve, shown Figure 4. fact, nearly
unsatisfiable formulae trivially unsatisfiable.
extremely serious flaw, difficulty test set drastically affected
trivially unsatisfiable formulae. Changing / viable solution
depth /
formulae much difficult solve, shown Figure 5, median
percentile exceeds timeout formulae determined unsatisfiable, even
3 propositional variables.
new method, shown Figure 6, formulae much difficult solve
old method, abrupt drop-off propositional unsatisfiability,
much easier solve generated / . Further, trivially unsatisfiable formulae
appear interesting portion test sets.
, /243 ) entirely suitable. formulae
Nevertheless choice parameters ( /
becoming hard much early. particular, unsatisfiable formulae

solved

7 , thus unsatisfiability plots cannot distinguished x axis
(recall Footnote 6). However, new method provide advantages already, providing
interesting new set tests, albeit one limited size.









4.2 Increasing



fiff

would like able produce better test sets depth 9/
greater. One way
increase propositional probability 243 something like 2 , increasing
number propositional atoms thus decreasing difficulty generated formulae.
would problematic previous generation methods would result trivially
unsatisfiable formulae determining results even smaller numbers clauses ,
method much problem.
investigate increasing propositional probability, ran collection tests
maximum modal depth /
propositional probability / 2 old method
new method. results tests given Figures 7 8. before, asymmetries

satisfiability unsatisfiability curves Figure 8 /93 due fact
many tests solved DLP within time limit (c.f., Footnote 6).

fiff



362

ff

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6

0.8

N=3
N=4
N=5
N=6

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80

100
L/N

120

140

160

180

200

20

DLP median times

40

60

80

100
L/N

120

140

160

180

200

DLP 90th percentile times

1000

1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

160

180

200

20

*SAT median times

40

60

80

100
L/N

120

140

160

180

200

180

200

*SAT 90th percentile times

1000

1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

Figure 4: Results



160

/

7

180

,

200

/

20

,

,
/

40



60

/:243

80

100
L/N

120

140

160

(old method)

expected, old method produces large numbers trivially unsatisfiable formulae.
trivially unsatisfiable formulae show much earlier /9243 , making tests considerably easier, especially *SAT.
new method produces hard formulae, ones quite bit easier / 243 .

/
particular, DLP solved instances within time limit
. Trivially unsatisfiable
formulae show up, well formulae already unsatisfiable,
significantly affect difficulty tests.
method allows creation more-interesting tests modal depths greater ,
simply adjusting value level difficulty appropriate. Trivial unsatisfiability
problem, whereas old method important feature test.
363

fiPATEL -S CHNEIDER & EBASTIANI

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

N=3
N=4
N=5

0
20

40

60

80

100
L/N

120

140

160

180

200

20

DLP median times

40

60

80

100
L/N

120

140

160

180

200

DLP 90th percentile times

1000

1000

N=3
N=4
N=5

100

100

10

10

1

1

0.1

0.1

0.01

N=3
N=4
N=5

0.01
20

40

60

80

100
L/N

120

140

160

180

200

20

*SAT median times

40

60

80

100
L/N

120

140

160

180

200

180

200

*SAT 90th percentile times

1000

1000

N=3
N=4
N=5

100

100

10

10

1

1

0.1

0.1

0.01

N=3
N=4
N=5

0.01
20

40

60

80

100
L/N

120

140

Figure 5: Results



160

/

7

180

,

200

/

20

,

,
/



40

60

/8

80

100
L/N

120

140

160

(either method)

4.3 Changing Size Clauses
problem increasing propositional probability formulae become propositional
is, source difficulty becomes propositional component problem, modal component. interested modal decision procedures,
want main (or only) source difficulty propositional reasoning.
decided, therefore, investigate different method modifying difficulty generated formulae. instead allow number literals clause vary manner similar
number propositional atoms. integer clause many literals. Otherwise, allow either literals clause, probability ,





364



fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6

0.8

N=3
N=4
N=5
N=6

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80

100
L/N

120

140

160

180

200

20

DLP median times

40

1000

80

100
L/N

120

140

160

180

200

DLP 90th percentile times
1000

N=3
N=4
N=5
N=6

100

60

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

160

180

200

20

*SAT median times

40

1000

80

100
L/N

120

140

160

180

200

180

200

*SAT 90th percentile times
1000

N=3
N=4
N=5
N=6

100

60

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

Figure 6: Results

140



160

/97

180

,

200

,

/

20

,
/



40

60

/:243

80

100
L/N

120

140

160

(our new method)

respectively. determine number propositional atoms clause based
number literals clause.
generated CNF formulae /
43 , /
, /
, /243 . change


/17
/
43 produces fewer disjunctive choices result easier formulae.
results tests given Figure 9.
formulae much easier generated / 7 , although still quite
hard form reasonable source testing data. Trivially unsatisfiable formulae appear large
numbers well formulae unsatisfiable relatively easy.
illustrate reduction difficulty smaller values generated formulae
3 ,
/ , / , /:243 . shown Figure 10, formulae even easier
using /







365

fiPATEL -S CHNEIDER & EBASTIANI

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6

0.8

N=3
N=4
N=5
N=6

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80

100
L/N

120

140

160

180

200

20

DLP median times

40

60

80

100
L/N

120

140

160

180

200

DLP 90th percentile times

1000

1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

160

180

200

20

*SAT median times

40

60

80

100
L/N

120

140

160

180

200

180

200

*SAT 90th percentile times

1000

1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

Figure 7: Results



160

/

7

180

,

200

/

20

,

,
/

40



60

80

fiff

/:2

100
L/N

120

140

160

(old method)



/
43 . Trivially unsatisfiable formulae appear, formulae
become unsatisfiable, formulae become easy, particularly *SAT.
3 reasonable set formulae maximum modal depth %/
/
.
maximum modal depth , formulae much representative formulae
maximum modal depth . formulae neither easy hard current modal
decision procedures satisfiability transition investigated significant numbers
propositional variables.
Further, new method provide collection test sets vary difficulty

varying . previous comparative test sets varied , problematic

interesting parameter sets become hard small values , range .







ff

366

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6

0.8

N=3
N=4
N=5
N=6

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80

100
L/N

120

140

160

180

200

20

DLP median times

40

1000

80

100
L/N

120

140

160

180

200

DLP 90th percentile times
1000

N=3
N=4
N=5
N=6

100

60

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

160

180

200

20

*SAT median times

40

1000

60

80

100
L/N

120

140

160

180

200

180

200

*SAT 90th percentile times
1000

N=3
N=4
N=5

100

100

10

10

1

1

0.1

0.1

0.01

N=3
N=4
N=5

0.01
20

40

60

80

100
L/N

120

140



Figure 8: Results

160

/97

180

,

200

/

,

20

,
/



40

60

fiff

/:2

80

100
L/N

120

140

160

(our new method)



/
illustrate effects varying generated formulae using
, / , /5 ,

. shown Figure 11, produces interesting set tests.
/:243 , varying
difficulty levels set appropriately. Trivially unsatisfiable formulae appear,
formulae become unsatisfiable anyway. Trivially unsatisfiable formulae influence
difficulty test.

fi

367

fiPATEL -S CHNEIDER & EBASTIANI

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6

0.8

N=3
N=4
N=5
N=6

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80

100
L/N

120

140

160

180

200

20

40

DLP median times

60

80

100
L/N

120

140

160

180

200

DLP 90th percentile times

1000

1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

160

180

200

20

*SAT median times

40

60

80

100
L/N

120

140

160

180

200

180

200

*SAT 90th percentile times

1000

1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

Figure 9: Results

4.3.1 ODAL EPTH



140

/

160



43

180

,

200

/

20

,

,
/



40

60

/:243

80

100
L/N

120

140

160

(our new method)

7

method used generate interesting test sets modal depth / 7 . depth
interesting previous methodseither formulae immensely difficult,
/: , behavior dominated trivial unsatisfiability, /:243 .
interesting levels difficulty, reduce values 43 . much
larger, formulae hard. However,
43 produce interesting test sets,
shown Figure 12. (The relevant asymmetry satisfiable unsatisfiable rates curves


3 due high amount tests exceeding time limit.) problems hard

3 doable, problems trivially (un)satisfiable formulas.
even





368



fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6
N=7

0.8

N=3
N=4
N=5
N=6
N=7

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80

100
L/N

120

140

160

180

200

20

DLP median times

40

60

80

100
L/N

120

140

160

180

200

DLP 90th percentile times

1000

1000

N=3
N=4
N=5
N=6
N=7

100

N=3
N=4
N=5
N=6
N=7

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

160

180

200

20

*SAT median times

40

60

80

100
L/N

120

140

160

180

200

180

200

*SAT 90th percentile times

1000

1000

N=3
N=4
N=5
N=6
N=7

100

N=3
N=4
N=5
N=6
N=7

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

Figure 10: Results



140

/

160




3

180

,

200

/

20

,

,
/



40

60

/:243

80

100
L/N

120

140

160

(our new method)

method allows us fine control difficulty tests. make test easier,
reduce size clauses reducing value(s) , increase propositional probability

. control missing previous method,
restricted integral value, and,
anyway, always set 7 making much different 2 resulted problems trivial
unsatisfiability maximum modal depths greater 1.

5. New CNF Generation Method: Advanced Version
Actually, generator much general described far. allow direct
specification probability distribution number propositional atoms clause,
369

fiPATEL -S CHNEIDER & EBASTIANI

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

C=2.2
C=2.4
C=2.6
C=2.8

0.8

C=2.2
C=2.4
C=2.6
C=2.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80
L/N

100

120

140

20

DLP median times

40

60

80
L/N

100

120

140

DLP 90th percentile times

1000

1000

C=2.2
C=2.4
C=2.6
C=2.8

100

C=2.2
C=2.4
C=2.6
C=2.8

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80
L/N

100

Figure 11: Results


/

120

140

,

/

20

,

,
/



40

/9243

60

80
L/N

100

120

140

(our new method)

allow distribution different modal depth top level . also allow
direct specification probability distribution number literals clause modal
depth. Thus, probability distribution number propositional atoms depends
modal depth number literals clause.
5.1 Generalization: Shaping Probability Distributions.
generator two parameters control shape formulae. first parameter, ,
list lists (e.g., [[0,0,1]]) telling many disjuncts put disjunction
modal level. internal list represents finite discrete probability distribution. instance,
[0,0,1] says ; disjunctions disjunct, ; disjuncts, ; 7
disjunctions (fixed length 3). one element list, frequency used
modal depth, last. possibilities are, e.g., [[1,1,1,1]] (maximum length 4
uniform distribution), [[16,8,4,2,1]] (maximum length 5 exponential distribution),
on.
second parameter, , list lists lists (e.g., [[[],[],[0,3,3,0]]]) controls propositional/modal rate. top-level elements modal depth (here
same). second-level elements disjunctions 1,2,3,... disjunctions (here third
matters disjunctions three disjuncts). instance, [0,3,3,0] says ;
disjunctions propositional atoms, 7 ; propositional atom, 7 ; propositional
atoms, ; 7 propositional atoms (that is, new scheme discussed paper



ff

ff

ff

370



ff

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N=3
N=4
N=5
N=6

0.8

N=3
N=4
N=5
N=6

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80

100
L/N

120

140

160

180

200

20

40

DLP median times
1000

100
L/N

120

140

160

180

200

DLP 90th percentile times
N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

160

180

200

20

*SAT median times
1000

40

60

80

100
L/N

120

140

160

180

200

180

200

*SAT 90th percentile times
1000

N=3
N=4
N=5
N=6

100

N=3
N=4
N=5
N=6

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80

100
L/N

120

140

160

Figure 12: Results



80

1000

N=3
N=4
N=5
N=6

100

60



180

200

20


/



3

,
/



,

40

/97

60

80

,

100
L/N

120

140

160

/:243

/
243 ; old scheme /
243 represented [[[],[],[1,3,3,1]]]). Notice
first element distributions represents value , whilst first element distributions represents value . Setting last element distribution zero [...,0]
eliminates strictly propositional clauses, main cause trivial unsatisfiability;


% ;
Section 4.1.
way implement constraint



"

371

fiPATEL -S CHNEIDER & EBASTIANI

1
2
3
4
5
6

function rnd CNF (d,m,L,N,p,C)
:= 1
repeat

:= rnd clause(d,m,N,p,C);
new(Cl );
return ;

/* generate distinct random clauses */

/* discards




already occurs */



7 function rnd clause(d,m,N,p,C)
8
:= rnd length(d,C);
/* select randomly clause length */
9
/* select randomly prop/modal rate */
:= rnd propnum(d,p,K);
10
repeat
11
j := 1
/* generate P distinct random prop. literals */


12
:= rnd sign() rnd atom(0,m,N,p,C);
/* generate K-P distinct random modal literals */
13
j := P+1

14
:= rnd sign() rnd atom(d,m,N,p,C);
fiff
15
/
;
/* discards Cl contains repeated atoms */
16
repeated atoms in(Cl);
17
return ;






"

18 function rnd atom(d,m,N,p,C)
19
d=0
20
return rnd propositional atom(N); /* select randomly prop. atom */
21
else
!
22
:= rand box(m);
/* select randomly indexed box */

23
:= rand clause(d-1,m,N,p,C);
"!
24
return ;
Figure 13: Schema new CNF random generator.
instance, plots Figures 1-12 obtained following choices C p:
Fig.
C
p
C (advanced version)
p (advanced version)
1, 4
3
0.5 (old) [[0,0,1]]
[[[],[],[1,3,3,1]]
2, 6
3
0.5 (new) [[0,0,1]]
[[[],[],[0,3,3,0]]
3, 5
3
0
[[0,0,1]]
[[[],[],[1,0,0,0]]
7
3
0.6 (old) [[0,0,1]]
[[[],[],[8,36,54,27]]
8
3
0.6 (new) [[0,0,1]]
[[[],[],[0,1,4,0]]
9
2.5
0.5 (new) [[0,1,1]]
[[[],[0,3,0],[0,3,3,0]]
10, 12 2.25
0.5 (new) [[0,2,1]]
[[[],[0,3,0],[0,3,3,0]]
11
2.2, 2.4, 0.5 (new) [[0,4,1]], [[0,3,2]] [[[],[0,3,0],[0,3,3,0]]
2.6, 2.8
[[0,2,3]], [[0,1,4]]
generator works described Figure 13. function new(Cl ) checks /
; rnd length(d,C) selects randomly clause length according -th dis

tribution (e.g, [[0,1,1][1,2][1]], returns probability ; 7



372

fiA N EW G ENERAL ETHOD







G ENERATE R ANDOM ODAL F ORMULAE









probability ; 7 ); rnd propnum(d,p,K) selects randomly number propositional

-th distribution (e.g, ,

atoms per clause according
[[[],[0,1,0],[0,1,0,0]] [[1,0][0,1,0]]], returns deterministically); rnd sign
selects randomly either positive negative sign equal probability; repeated atoms in(Cl)
checks clause contains repeated atom; Sort(Cl) returns clause sorted according

criterium; rnd propositional atom(N) selects uniform probability one propo !
sitional atoms fi ; rnd box(m) selects uniform probability one indexed boxes
.
eliminating duplicated atoms clause, take care disturb probabilities
first determining shape clause (rows 8-9 Figure 13), instantiating
propositional variables (rows 10-16 Figure 13). clause repeated atoms, either propositional modal, instantiation rejected another instantiation shape performed.
take care way would generate small atoms
fewer small atoms large atoms, resulting greater chance rejecting small atoms
repetition.
elimination duplicated atoms clause matter elimination redundancies, also elimination source flaws. fact, one might generate top-level clauses like


fi

fi fi
fi
, would make whole formula inconsistent.









"


"ff"
$

Example 5.1 try guess parameter set new random generator potentially
generate following CNF formula :




fi fi fi fi fi




fi
fi
fi

fi


(2)
fi fi fi














fi














fi







"


" fi"
"






"


" "
"

"

"



, /
, /
. top level 0 unary, 2 binary
quick look set / , /
2 ternary clauses; depth 1 2 unary 4 binary clauses; depth 2 6 unary
clauses. Thus, set
C = [[0,2,2],[2,4],[6]].
(3)
top level unary clauses (we represent fact empty list []), 2 binary clauses 1 propositional literal, 2 ternary clauses 1 propositional literal;
depth 1, 2 unary clauses 0 propositional literals, 4 binary clauses 1 propositional literal. (There need provide information depth 2, clauses purely
propositional.) Thus, set
p = [[[],[0,2,0],[0,2,0,0]] [[2,0],[0,4,0]]].

(4)

two expressions normalized into:
C = [[0,1,1],[1,2],[1]]
p = [[[],[0,1,0],[0,1,0,0]] [[1,0],[0,1,0]]].

(5)

Notice setting , obtained changing non-zero values (5)
non-zero values, turning zeros non-zeros (but vice versa!), work,
different probability. instance, turning first list [1,1,1] allows generating
also unary clauses top level; anyway, probability ; 7 generator may still produce

formulae binary ternary clauses top level.

"

373

fiPATEL -S CHNEIDER & EBASTIANI

Satisfiability Unsatisfiability Fractions
1

Trivial Satisfiability Unsatisfiability Fractions
1

N,d=3,3
N,d=4,3
N,d=3,4
N,d=4,4

0.8

N,d=3,3
N,d=4,3
N,d=3,4
N,d=4,4

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
20

40

60

80
L/N

100

120

140

20

DLP median times
1000

60

80
L/N

100

120

140

DLP 90th percentile times
1000

N,d=3,3
N,d=4,3
N,d=3,4
N,d=4,4

100

40

N,d=3,3
N,d=4,3
N,d=3,4
N,d=4,4

100

10

10

1

1

0.1

0.1

0.01

0.01
20

40

60

80
L/N

100

120

140

20

40

60

80
L/N

100

120

140



Figure 14: Results DLPwith /97 , /97 , / [[1,8,1]],
/ [[[1,0],[0,1,0],[0,1,1,0]]].

illustration general method, present set tests / , / 7 ,

,
/ [[1,8,1]], %/ [[[1,0],[0,1,0],[0,1,1,0]]]. set tests
introduces small fraction single-literal clauses contain modal literal (except greatest
modal depth, contain, course, single propositional literal). results tests
given Figure 14. Again, trivial instances occur interesting zone. generate
interesting test sets even modal depth .


/17

5.2 Varying Probability Distributions Depth
new method provides ability fine-tune distribution size propositional/modal rate clauses every depth. fine tuning results large number
parameters, far paper investigated distributions conform
scheme described ones correspond 3CNF generation method previously used.
give example vary probability distributions nesting depth


clauses, consider case /
63 ,
/
,
/7 63 ,
/ [[1,8,1],[1,2]],

/ [[[1,0],[0,1,0],[0,1,1,0]],[[1,0],[0,1,0]]]. results tests
given Figure 15.
parameter says probability distributions length clauses occurring
nesting depth [1,8,1] [1,2] respectively. (When explicitly specified,
374

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Satisfiability Unsatisfiability Fractions

Trivial Satisfiability Unsatisfiability Fractions

1

1

0.8

0.8

N,d=3,4
N,d=4,4
N,d=5,4
N,d=3,5
N,d=4,5
N,d=5,5

0.6

N,d=3,4
N,d=4,4
N,d=5,4
N,d=3,5
N,d=4,5
N,d=5,5

0.6

0.4

0.4

0.2

0.2

0

0
0

20

40

60

80

100

120

140

0

20

40

60

L/N

80

100

120

140

L/N

DLP median times
1000

DLP 90th percentile times
1000

N,d=3,4
N,d=4,4
N,d=5,4
N,d=3,5
N,d=4,5
N,d=5,5

100

N,d=3,4
N,d=4,4
N,d=5,4
N,d=3,5
N,d=4,5
N,d=5,5

100

10

10

1

1

0.1

0.1

0.01

0.01
0

20

40

60

80

100

120

140

0

20

L/N

40

60

80

100

120

140

L/N




Figure 15: Results DLPwith /
63 ,
/
,
/
7 63 ,
/ [[1,8,1],[1,2]],
/ [[[1,0],[0,1,0],[0,1,1,0]],[[1,0],[0,1,0]]].



considered last distribution default, case depth .) Thus, top-level clauses
average ; unary, ; binary ; ternary, clauses occurring depth
average ; 7 unary ; 7 binary.



parameter says lists probability distributions propositional/modal ratio
nesting depth [[1,0],[0,1,0],[0,1,1,0]] [[1,0],[0,1,0]] respectively. Thus, every depth, unary clauses propositional literal binary clauses
propositional modal literal. top-level ternary clauses either
propositional
literals, equal probability.



Notice top level distributions identical Figure 14, whilst depth
ternary clauses higher fraction unary clauses. slight modifica
tions allow reasonable test sets / 3
/
3 . Moreover, trivial instances nearly
disappeared.

6. Generality Method

%

already observed (Horrocks et al., 2000) normal modal logics,
upward,
loss restriction CNF formulae, equivalence arbitrary
375

fiPATEL -S CHNEIDER & EBASTIANI

normal modal formulae CNF formulae9 . may wonder well generation technique covers whole space CNF formulae, well approximate restricted
subclass space. Example 5.1 represents instance general property random
generation technique, present discuss below.
assume rnd CNF Figure 13 purely random generator, i.e., performs non-deterministic choices independently pure random way. (Of course pseudorandom generators approximate feature.) Moreover, loss generality, restrict
discussion CNF formulae repeated clauses top level repeated
atoms inside clause level, atoms sorted within clause, according generic function Sort() Figure 13. former allows considering formulae
already simplified out; latter allows considering one representative
class formulae equivalent modulo order permutations. discussed Giunchiglia


fi fi
et al. (2000), latter allows simplifying subformulae like, e.g., fi fi





fi
fi
fi
fi .




"

$





"
fi"



"

Let sorted CNF formula depth top-level clauses built

"#
propositional atoms ff fi fi modal boxes ff
, repeated
clause top level repeated atoms inside clause level. construct

that, , , :





(a) -th element -th sublist non-zero clause length
occurring depth ,

(b) -the element -th sub-sublist -th sublist non-zero

clause length occurring depth contains propositional literals.

$

One possible operative technique build works follows. Initialize list
sublists. Then, every depth level ff 2 , set -th sublist follows:



$






(i) set size sublist maximum size clauses occurring depth ;


(ii) 8ff , count number clauses length occurring depth ,
append result sublist.



Initialize list sublists sub-sublists. Then, every depth level
-th sublist follows:
(i) look
;
(ii)





: set size



ff







$

ff 2 8

sublist maximum size clauses occurring



$

, set

depth

, generate -th sub-sublist follows:



look : number clauses length occurring depth non-zero, set

length sub-sublist 8 , else set 0;



9. holds modal normal logics
upward, conversion works recursively depth
formula, leaves root, time applying sub-formulae propositional CNF conversion
transformation




ff fi



fi

preserves validity logics.

376




ff



fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE



$


occurring
ff 2

, count number clauses length
propositional literals, append result sub-sublist.



depth

Example 5.1 represents instance application technique construction
above,
. Notice parameters verify points
probability distributions mimic actual number occurrences different kinds
clauses.

$

"

"

$

Theorem 6.1 Let rnd CNF purely random generator Figure 13. Let sorted
CNF formula depth top-level clauses built propositional atoms

#
ff fi fi modal boxes ff

, repeated clause top level
repeated atoms inside clause level. Let built verify
above. Let obtained respectively substituting
points
zero-values non-zero values. have:

"

$

"

$

(i) rnd CNF (d,m,L,N,p,C) returns non-zero probability ;
(ii) rnd CNF (d,m,L,N,p,C) returns non-zero probability

$



.

$

Proof fully-detailed proof reported Appendix. sketch main steps.
following facts come straightforwardly induction structure :

$

1. every propositional atom occurring depth returned non-zero
probability rnd atom(0,m,N,p,C) rnd atom(0,m,N,p,C);

2. every modal atom occurring depth returned non-zero probability rnd atom(d-i,m,N,p,C), returned non-zero probability
rnd atom(d-i,m,N,p,C);

$







$




3. every clause occurring depth returned non-zero probability
rnd clause(d-i,m,N,p,C), returned non-zero probability
rnd clause(d-i,m,N,p,C).







Thus, every top level clause
returned rnd clause(d,m,N,p,C) rnd clause(d,m,N,p,C)
non-zero probabilities ff respectively, ff fi . fact, comes
straightforwardly returned rnd CNF (d,m,L,N,p,C) rnd CNF (d,m,L,N,p,C)
non-zero probabilities respectively, .
Q.E.D.
Q.E.D.
theoretical viewpoint, Theorem 6.1 shows generation technique
general, because, every CNF formula , exists choice parameters s.t. purely
random generator returns non-zero probability .
unique as,
course, choice criterium suggested points
example, setting obtained turning zeros non-zeros would match
requirements. extreme case, might think general choices like

$

"

$

$

C = [[1,1,1,...],...]

"

"

p = [[[[1,1],[1,1,1],[1,1,1,1]...]]].

(6)

guarantee every possible CNF formula within given bound clause size
non-zero probability. Anyway, Theorem 6.1 shows that, extending number non-zeros
values, probability generating decreases.

$

"

377

fiPATEL -S CHNEIDER & EBASTIANI

instance, consider Example 5.1. Turning first list (5) [1,1,1] would still
allow generating formula (2), would allow generating also unary clauses top level
probability
; 7 , converges quickly .

"

Usually interested randomly generating one precise formula non-zero
probability would rather small anyway rather randomly generate class formulae similar possible given target class formulae. Adding redundant non-zeros
would extend range shapes formulae, extending variance lowering resemblance
target class formulae.

7. Discussion
7.1 Basic Advanced Method
new testing method used two different levels, depending attitude
skills experience user.
basic usage clause length represented lists either one non-zero
element (e.g., [[0,0,1]], meaning clause length ) two adjacent non-zero elements
(e.g., [[0,2,1]], meaning clause length 7 , probability ; 7 ; 7 respectively);
similarly, propositional/modal rate represented lists either one non-zero element
(e.g., [[[],[],[0,1,0,0]]], meaning propositional literal per clause) two nonzero adjacent elements (e.g., [[[],[],[0,3,2,0]]], meaning either propositional
literals per clause, probability 7 ; 3 ; 3 respectively); distributions vary
depth.
basic way random generator used flawless 10 extension 3CNF
method Giunchiglia Sebastiani (1996), allows setting clause length either
fixed integer values non-integer average values. number parameters kept relatively
small, allow coarse-grained coverage significant subspace affordable number
tests.











advanced usage, possible apply finite probability distributions ;
moreover, possible use different distributions different depths. opens huge amount
possibilities, requires skills experience user: representation sophisticated multi-level distributions may rather complicated, may thus require practice;
moreover, usage complex distributions requires care, presence non-constant distributions clause length propositional/modal rate may significantly enlarge variance
features generated formulae, making effects tests unpredictable
instance-dependent.
order guide user, provide general suggestions choosing parameter sets
testing session. come theoretical issues practical experience using
generator.



Avoid generating purely propositional top-level clauses, is, set p = [[...,0],...].
See Sections 4.1 5.1. possible, avoid generating unary top-level clause, is, set C
= [[0,...],...]). See also Section 7.5.

10. sense free flaw highlighted work Hustadt Schmidt (1999) Giunchiglia
et al. (2000).

378

fiA N EW G ENERAL ETHOD






G ENERATE R ANDOM ODAL F ORMULAE

organizing testing session, fix parameter sets according following order
directives.
(i) Fix d. d=1 search mostly dominated propositional component,
d>2 tends dominated modal component. d=2 typically good start.
(ii) Fix m. substantially partitions problem independent problems. Increasing m,
samples tend likely-satisfiable. m=1 typically good start.
(iii) Set C. Increasing top level values C, samples tend likely-satisfiable
propositional component search increases, transition area moves
right hardness peaks grow. Average values 267 top level
distributions C typically good start.
(iv) Set p. Decreasing top level values p, modal component search increases.
top level distributions p, average half top-level atoms propositional (that is, /:243 Section 4) typically good start.
(v) choice parameters, increase N, starting (at least) maximum length C, desired level hardness reached.
(vi) Make L vary within satisfiability transition area.











dealing C p, focus top-level clause distributions first. Small variations
C p top level may cause big variations hardness satisfiability probability.
Variations lower levels typically cause much smaller effects.




Use convex distributions: e.g., [1,5,1] [5,1,5] mean value,
variance former much smaller latter.




keep L ranging satisfiability transition area: increasing L it, fraction
trivially unsatisfiable samples become relevant. determine satisfiability transition
area, make preliminary check samples per point (say, 10) using dichotomic search.
Unlike N (and m), parameters d, C, p make formulas vary shape. Thus,
suggest group together plots d, C p values increasing Ns.

whole, large number parameters makes impossible cover parameter space
reasonable amount testing. However, CNF formula shape generated
method described Section 6 used produce random formulae reasonably
similar formula(e) interest.
7.2 Comparison Old 3CNF Method
whole, new method inherits features old 3CNF method.


Scalability: Increasing , (and also average clause length ) difficulty generated
problems scales will. Thus possible compare performance different
systems scale problems increasing difficulty, source difficulty (e.g.,
size, depth, etc.).
Valid vs. not-valid balance: parameter allows tuning satisfiability rate formula
will. Moreover, always possible choose generate testbeds 50%satisfiable rate, allows maximum uncertainty.
379

fiPATEL -S CHNEIDER & EBASTIANI

Termination: new method allows generating test sets depth 3-4 run
state-of-the-art systems reasonable amount time.
Reproducibility: results testbed easy reproduce generators code
parameters values made publicly available.
Parameterization: random generation CNF formulae fully parametric.
Data organization: natural way use new random generator generate tests
plot data increasing values one two parameters. allows easy, quantitative
qualitative evaluations performances different procedures test.
Moreover, new method improves 3CNF method following features.
Representativeness: stated Section 6, CNF formulae represent formulae normal
upward, equivalence-preserving way converting
modal logics
modal formulae CNF . Theorem 6.1, new method allows finegrained sampling class CNF formulae.

%







Difficulty: random CNF formulae

provide challenging test sets


well considered
state-of-the art procedures. CNF formulae
challenges next-generation systems. (Of course, problem generate easy
problems too.)


Control: parameters , allow controlling monotonically difficulty test

set. (E.g., increase , reasonably sure mean/median CPU time plots
increase.) parameter allows controlling satisfiability rate. Monotonicity
allows controlling one feature simply increasing decreasing one value, thus
eliminating uninteresting areas input space.
Modal vs. propositional balance: size Kripke models spanned decision procedures increased exponentially higher modal depths reached new test sets;
moreover, probability repeated top-level atoms dramatically reduced. 11 Consequently, unlike tests Hustadt Schmidt (1999) Giunchiglia et al. (2000)
search longer dominated pure propositional component reasoning,
empirical results show large number modal successors explored.
Finally, new method completely removes drastically reduces effects following
problems.
Redundancy: Propositional modal redundancy already eliminated last versions
3CNF method (Giunchiglia et al., 2000). Moreover, new method allows
eliminating strictly propositional clauses.
Triviality: main cause trivial unsatisfiability removed, trivially unsatisfiable
formulae relegated transition areas experiments.
11. number possible distinct modal atoms increases hyper-exponentially

380



(Horrocks et al., 2000).

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Artificiality: method allows user shape test formulae maximize resemblance expected typical inputs his/her system(s). course, done within
limits imposed randomness: irregular typical input formulas, higher
variance randomly generated formulas, lower average resemblance
typical input formulas.
Over-size: new method allows generating extremely hard problems reasonable size.
comes analysis resulting data hard problems require big amounts
search branches modal successors generated, search dominated
parsing data managing.
generator presented Horrocks Patel-Schneider (2002), extends 3CNF generator Giunchiglia et al. (2000) too. However, new generator allows shaping probability
distributions C p, using different distributions every depth level. principle,
generator Horrocks Patel-Schneider (2002) allows also setting probabilities & '
#
&
propositional modal atoms negated. However, feature used
#
muchin experiments Horrocks Patel-Schneider (2002) & ' always 243 &
different 243 one experiment adds nothing generality generator,
new generator decided re-introduce it.
7.3 Comparison QBF-based Method
comparing new CNF generation method QBF-based generation method,
must notice that, far, used different ways, corresponding two different
test techniques briefly summarized Section 3.






TANCS competition(s) (Massacci, 1999), tests performed single
data points, results presented form big tables, entry consisting
number successful solutions rescaled geometrical mean CPU time
solutions. Two systems compared according number successful
solutions, considering geometrical mean CPU time value result even.
due fact comparison geometrical means possible
computed number successful values, or, accurate comparison,
successful values.12 method chosen guarantee fairness
comparison competitors, key requirement competition.
paper instead, focused highlighting qualitative quantitative
behavior system(s). Thus preferred plots tables, preferred
representing percentiles CPU times rather number successful solutions
geometrical mean times. fact, former require distinguish successful
non-successful solutions.13 Thus, much suitable plotting,
comparison geometrical means makes sense data points
number successful solutions, hard follow plot.

12. case tests exceeding timeout, geometrical means altered truncation introduced unsuccessful
solutions. Thus geometrical mean makes sense calculated successful results.
13. percentage successful solutions greater equal , value -th percentile influenced
truncation values introduced timeouts, otherwise equal timeout value.

381

fiPATEL -S CHNEIDER & EBASTIANI

course, generators used ways. (See Heguiabehere de Rijke (2001)
plots random QBF-based method.) Comparing two approaches
organizing presenting data one goals paper, restrict analysis
generation methods, independently used far.
QBF-based generation method Massacci (1999) shares new CNF generation
method several features particular Scalability, Valid vs. not-valid balance, Termination, Reproducibility, Parameterization, Data Organization, Difficulty, Modal vs. propositional balance, Redundancy Triviality considerations identical analogous

new method hold, consider parameters , instead parameters ,
. following features instead deserve discussion.





Control: parameters allow controlling monotonically difficulty test set.
parameter allows controlling satisfiability rate. However, unlike CNF
case, main parameters QBF generator (e.g., ) direct meaning
wrt. main characteristics resulting modal formulae like, e.g., modal depth
number propositional variables.



Representativeness: general QBF formulae good representatives whole class
quantified boolean formulae, way convert generic quantified boolean formula
QBF.14 (The randomly generated QBF formulae used Massacci (1999) restrict
fixed amount variables per alternation.) Nevertheless, class modalencoded QBF formulae restrict candidate Kripke structures
regular structure imposed QBF and/or binary search trees.



Artificiality: Unlike CNF case, main parameters QBF generator (e.g., )
direct meaning wrt. main characteristics resulting modal formulae.
Thus, hard choose parameters random QBF generator resemble
expected typical inputs system(s).
Over-size: One final problem random modal-encoded QBF formulae size. Initial versions
translation method produced test sets 1GB range, stressed much
data-storage retrieval portion provers. (For example, running DLP formulae resulted 1000s timeout without significant search.) Although encoding
significantly improved sense, current versions still produce large modal
formulae, mostly constrain Kripke structures.
Similar considerations recently presented Heguiabehere de Rijke (2001).
whole, believe QBF generation method still appealing, two
methods co-exist empirical test session.
14. Notice QBF denote class prenex CNF QBF formulae, given alternation quantification
variables ending existential one followed CNF propositional formula. conversion works lifting
quantifiers outside formula converting k-CNF [k-DNF] matrix innest quantifier [a ,
negating result pushing negation recursively]. conversion truth-preserving [truth-inverting].


382

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

7.4 Complexity Issues
purely theoretical viewpoint, remarked modal-encoded QBF formulae capture
problems , CNF formulae stuck NP (Massacci, 1999) 15 . statement
requires clarification.
First, test sets necessarily finite, therefore makes sense attribute complexity
class. Thus, speaking complexity classes test problems, refer test sets,
rather infinite sets formulae could generate could unbounded values (at
least one of) generation parameters. particular, statement means infinite set
QBF formulae unbounded number variables per alternation bounded alternation
depth complete (Garey & Johnson, 1979), infinite set CNF formulae
bounded depth unbounded number propositional variables NP (Halpern, 1995).
Secondly, alternation depth variable number per alternation QBFanalogous
modal depth variable number respectively, latter values
resulting modal formulae grow
. 16 fact, QBF formulae bounded alternation
depth unbounded number variables per alternation give rise modal formulae
unbounded depth unbounded number variables.
Finally, vs. NP issue Massacci (1999) matter generators, rather
matter generators used, results organized presented. fact,
far random CNF testbeds always organized fixing parameters except
(modal depth included!) making vary. choice, whose goal produce data plots
covering satisfiability transition area, causes testbed formulae stuck NP.
avoid fact, one may want make vary fix parameters,
satisfiability unbounded depth bounded number propositional variables PSPACEcomplete (Halpern, 1995).



%



& )"



%

7.5 Asymptotic Behavior
Achlioptas et al. (1997) presented study asymptotic behavior random CSP problems.
showed that, well-known random generation models (which reveal flaws

empirical tests) probability problems trivially unsatisfiable tends 1
,

number variables. Gent et al. (2001) lately explained discrepancy
theoretical empirical results showing phenomenon happens significant

probability values reach current CSP solvers.
problem due possible presence (implicit) unary constraints causing variables value inadmissible. occurs non-zero probability, non-zero
probability variable may values inadmissible. causes local inconsistency


whole problem, easily revealed solver.
fffi , probability
situation tends zero. Analogous problems revealed random
SAT problems generated constant probability generation model, unary clauses gen-



15. precisely, Massacci (1999) referred 3CNF formulae Giunchiglia et al. (2000). statement holds
also CNF formulae.
16. already noticed (Horrocks et al., 2000), better QBF-analogous modal depth total number
universally quantified variables (
case). fact, like modal
bounded depth,
class QBF formulae bounded complete NP, possible guess tree-like witness
nodes.






#


383



fiPATEL -S CHNEIDER & EBASTIANI

erated non-zero probability (Mitchell et al., 1992), random QBF problems, implicit
unit clauses, i.e., clauses containing one existential variable generated non-zero
probability (Gent & Walsh, 1999). random k-SAT model,
, problem
occur (Friedgut, 1998; Achlioptas et al., 1997).





generation model far complicated analyze models above. First, CNF
formulas much complicated structure random SAT, CSP QBF formulas, involving much wider number parameters. Second, unlike models discussed above,
(constraints described by) CNF clauses picked uniform way, probability
!
"
generating given CNF atom
varies strongly depth shape, typically
much smaller generating propositional atom fi .17 Thus, developing formal probabilistic analysis asymptotic behavior model reach (and scope)
paper. However, provide heuristic considerations.
simplest case allow generation unary clauses top level, is,
C = [[0,...],...], explicit unary constraints. may still
!
!

!

!
"
"
"
fi


.
implicit unary constraints like, e.g., fi
Anyway, simple heuristic consideration suggests that, given big numbers distinct CNF
modal atoms may potentially generated, situations unlikely
fi fi fi standard 2-SAT model,
implicit unit constraints like fi
free asymptotic local inconsistency problem.
critical case allow generation unary clauses top level,
is, C = [[x,...],...], . case generate unary clauses, thus
local inconsistencies, non-zero probability. Thus, simple way avoid problem
restrict values allow unary top-level clauses, is, always set C =
[[0,...],...]. Notice, however, hardly becomes problem practice respect condition described Sections 4.1 5.1 avoiding purely propositional top-level
clauses (that is, always set p = [[...,0],...]). fact, given big numbers distinct
CNF modal atoms may potentially generated, probability two contradic !
!
tory modal unit clauses
,
within formula becomes quickly negligible even
small depths.
Notice intentionally considered modal implicit unary constraints like,
!

fi
,
e.g., fi
, mutually inconsistent modal literals (e.g., /
!

/


). fact, detecting inconsistencies requires investigating recursively
modal successors, therefore trivial.



"







"
"
$ $ "

"

"

"

"

"



$

8. Conclusions Future Work
shown test sets new method, basic form, allows us generate wider
variety problems covering input space. better-tune difficulty problems
various parameter values, including first reasonable test sets maximum modal depths
7 . produce interesting scaling dimensions, varying number

propositional variables . example, vary propositional probability
size clauses vary difficulty interesting problems. neither restricted
integral values, extremely fine control difficulty test sets. Thus create





17. Again, recall number possible distinct CNF
depth (Horrocks et al., 2000).



384

atoms increases hyper-exponentially modal

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

interesting test sets satisfiable/unsatisfiable transition explorable current
decision procedures.
drastically reduced influence trivial unsatisfiability, flawed previous
CNF methodologies 0% . retain desirable features previous CNF methodologies. test sets easy reproduce large.
full methodology introduced possibility shaping distribution
size propositional/modal rate clauses. done level modal
depth. allows generating much wider variety problems, covering principle whole

input space. instance, produced full test set / 3 /93 (Figure 15).
moved closer application data, significant direct applications
modal decision procedures thus guidance sorts inputs would close
application inputs. case, believe moved closer ever possibility
approximating given classes input formulae.
still much work done using generation methodology. produce
test sets try test sets various modal decision procedures. may also want
uncover parameter settings full generality generation method needed produce
reasonable test sets.

Acknowledgments
would like thank Thomas Eiter three anonymous reviewers valuable comments helpful suggestions greatly improved quality paper. second author
supported MIUR COFIN02 project, code 2002097822 003, C ALCULEMUS !
IHP-RTN EC project, contract code HPRN-CT-2000-00102, thus benefited financial contribution Commission IHP programme.

Appendix A: Fully-detailed Proof Theorem 6.1

$

Theorem 6.1 Let rnd CNF purely random generator Figure 13. Let sorted
CNF formula depth top-level clauses built propositional atoms

#
ff fi fi modal boxes ff

, repeated clause top level
repeated atoms inside clause level. Let built verify
Section 6. Let obtained respectively substituting
points
zero-values non-zero values. have:

"

$

"

$

(i) rnd CNF (d,m,L,N,p,C) returns non-zero probability ;
(ii) rnd CNF (d,m,L,N,p,C) returns non-zero probability

$

$



.

Proof proof works induction structure . First, prove that:

$

1. every propositional atom occurring depth returned non-zero
probability rnd atom(0,m,N,p,C) rnd atom(0,m,N,p,C);


2. every modal atom occurring depth returned non-zero probability rnd atom(d-i,m,N,p,C), returned non-zero probability
rnd atom(d-i,m,N,p,C);




$




385




fiPATEL -S CHNEIDER & EBASTIANI

$

3. every clause occurring depth returned non-zero probability
rnd clause(d-i,m,N,p,C), returned non-zero probability
rnd clause(d-i,m,N,p,C).







point 3. every top level clause returned rnd clause(d,m,N,p,C)
.
rnd clause(d,m,N,p,C) probabilities respectively,
repeated clause, recalling property probabilities have:

$








"


" "
"






"








"

:





/



8



8





8



/

/









ff












"




(7)



8

"
(8)










(9)


Notice (8) strictly monotonic components. Thus,
need prove points 1, 2 3.



.

+

$

1. Let fi propositional atom ff fi fi occurring depth ,
.
rnd atom(0,m,N,p,C) rnd atom(0,m,N,p,C) invoke rnd propositional atom(N),

returns fi probability / ; .

2. Let
boxed clause occurring depth , 9 : .


occurs depth : . (Notice <% instead :
cannot occur
clause
depth , maximum depth .)

$

$



$

$

(i) inductive hypothesis, follows point 3. returned non-zero
probability rnd clause(d-i-1,m,N,p,C). , rnd atom(d-i,m,N,p,C) invokes

non-zero probrand box(m) rand clause(d-i-1,m,N,p,C), returns
/ ;
.
ability
(ii) inductive hypothesis, follows point 3. returned nonzero probability
rnd clause(d-i-1,m,N,p,C). rnd atom(d-i,m,N,p,C)

vokes rand box(m) rand clause(d-i-1,m,N,p,C), returns
non . Thus, .
zero probability / ;















propositional literals, occurs $ depth
3. Let clause length 5
, . $ sorted, represented " ,
denote modal literals.

ff denote propositional literals
(i) inductive hypothesis, follows point 1. propositional literal
fi rnd sign() rnd atom(0,m,N,p,C),
returned non-zero probability
follows point 2. modal literals
returned non-zero

fi rnd sign() rnd atom(d-i,m,N,p,C).
probability


<



%
!



243

243

386



!





!





!

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE





construction , -th element -th sublist non-zero; thus,
returned non-zero probability rnd length(d-i,C).

construction , -the element -th sub-sublist -th sublist
!
non-zero; thus, returned non-zero probability rnd propnum(d,p,j).18
Similarly (9), repeated atoms inside clause, returned
rnd clause(d-i,m,N,p,C) non-zero probability

$





!
/





"
243

!

fi
















!





fi

















fi

fi





(10)

(9), expression right (10) strictly monotonic terms ,
! , fi s, fi within domain definition.
(ii) inductive hypothesis, follows point 1. propositional literal
243
fi rnd sign()
returned non-zero probability 243 fi

rnd atom(0,m,N,p,C), follows point 2. modal literals



turned non-zero probability 243
fi %243 fi rnd sign() rnd atom(di,m,N,p,C).

construction , -th element -th sublist non-zero; thus,
returned non-zero probability rnd length(d-i,C). construction
, fi .

construction , -the element -th sub-sublist -th
!
sublist non-zero; thus, returned non-zero probability

!

!
rnd propnum(d,p,j). construction , .
repeated atoms inside clause, follows returned rnd clause(di,m,N,p,C) non-zero probability




















$


fi


/
243 "


fi



strict monotonicity (10) (11), .


!





!

fi




fi







!

(11)

Q.E.D.

References
Achlioptas, D., Kirousis, L. M., Kranakis, E., Krizanc, D., Molloy, M. S. O., & Stamatiou, Y. C.
(1997). Random constraint satisfaction: accurate picture. Smolka, G. (Ed.), Principles Practice Constraint Programming, Vol. 1330 Lecture Notes Computer
Science, pp. 107120, Berlin. Springer.
Beckert, B., & Gore, R. (1997). Free variable tableaux propositional modal logics. Automated
Reasoning Analytic Tableaux Related Methods: International Conference Tableaux97, Vol. 1227 Lecture Notes Artificial Intelligence, pp. 91106, Berlin. Springer.

ff



18. Notice conditioned probability, is, probability propositional literal provided
clause literals. matches fact input rnd propnum(d,p,j).

387

fiPATEL -S CHNEIDER & EBASTIANI

Cadoli, M., Giovanardi, A., & Schaerf, M. (1998). algorithm evaluate quantified Boolean
formulae. Proceedings 15th National Conference Artificial Intelligence (AAAI98), pp. 262267, Menlo Park, CA. AAAI Press.
Friedgut, E. (1998). Sharp thresholds graph properties, k-sat problem. Journal
American Mathematical Society, 12(4), 10171054.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman, New York.
Gent, I. P., MacIntyre, E., Prosser, P., Smith, B. M., & Walsh, T. (2001). Random constraint satisfaction: Flaws structure. Journal Constraints, 6(4), 345372.
Gent, I. P., & Walsh, T. (1999). Beyond NP: QSAT phase transition. Proceedings
Sixteenth National Conference Artificial Intelligence Eleventh Innovative Applications Artificial Intelligence Conference (AAAI-99), pp. 648653, Menlo Park, CA. AAAI
Press.
Giunchiglia, E., Giunchiglia, F., Sebastiani, R., & Tacchella, A. (2000). SAT vs. Translation based
decision procedures modal logics: comparative evaluation. Journal Applied NonClassical Logics, 10(2), 145172.
Giunchiglia, E., Giunchiglia, F., & Tacchella, A. (2002). SAT based decision procedures classical
modal logics. Journal Automated Reasoning, 28, 143171.
Giunchiglia, F., & Sebastiani, R. (1996). Building decision procedures modal logics propositional decision procedures - case study modal K. Proceedings Thirteenth
Conference Automated Deduction, Vol. 1104 Lecture Notes Artificial Intelligence,
pp. 583597, Berlin. Springer.
Giunchiglia, F., & Sebastiani, R. (2000). Building decision procedures modal logics propositional decision procedures - case study modal K(m). Information Computation,
162(1/2), 158178.
Haarslev, V., & Moller, R. (2001). RACER system description. Proceedings International Joint Conference Automated Reasoning, IJCAR2001, Vol. 2083 Lecture Notes
Computer Science, pp. 701705, Siena, Italy. Springer.
Halpern, J. Y. (1995). effect bounding number primitive propositions depth
nesting complexity modal logic. Artificial Intelligence, 75(3), 361372.
Halpern, J. Y., & Moses, Y. (1992). guide completeness complexity modal logics
knowledge belief. Artificial Intelligence, 54(3), 319379.
Heguiabehere, J., & de Rijke, M. (2001). random modal QBF test set. IJCAR2001 Workshop
Issues Design Experimental Evaluation System Modal Temporal
Logics, pp. 5867.
Heuerding, A., Jager, G., Schwendimann, S., & Seyfreid, M. (1995). Propositional logics
computer. Baumgartner, P., Hahnle, R., & Posegga, J. (Eds.), Automated Reasoning
Analytic Tableaux Related Methods: International Conference Tableaux95, Vol. 918
Lecture Notes Artificial Intelligence, pp. 310323, Berlin. Springer.
Heuerding, A., & Schwendimann, S. (1996). benchmark method propositional modal
logics K, KT, S4.. Tech. rep. IAM-96-015, University Bern, Switzerland.
388

fiA N EW G ENERAL ETHOD



G ENERATE R ANDOM ODAL F ORMULAE

Horrocks, I. (1998). Using expressive description logic: FaCT fiction?. Cohn, A. G., Schubert, L., & Shapiro, S. C. (Eds.), Principles Knowledge Representation Reasoning:
Proceedings Sixth International Conference (KR98), pp. 636647. Morgan Kaufmann
Publishers, San Francisco, California.

%

Horrocks, I., & Patel-Schneider, P. F. (2002). Evaluating optimised decision procedures propositional modal
satisfiability. Journal Automated Reasoning, 28(2), 173204.
Horrocks, I., Patel-Schneider, P. F., & Sebastiani, R. (2000). analysis empirical testing
modal decision procedures. Logic Journal IGPL, 8(3), 293323.
Hustadt, U., & Schmidt, R. A. (1999). empirical analysis modal theorem provers. Journal
Applied Non-Classical Logics, 9(4), 479522.
Hustadt, U., Schmidt, R. A., & Weidenbach, C. (1999). MSPASS: Subsumption testing SPASS.
Lambrix, P., Borgida, A., Lenzerini, M., Moller, R., & Patel-Schneider, P. (Eds.), Proceedings 1999 International Workshop Description Logics (DL99)., pp. 136137.
Massacci, F. (1999). Design results Tableaux-99 non-classical (modal) system competition.
Automated Reasoning Analytic Tableaux Related Methods: International Conference Tableaux99, Vol. 1617 Lecture Notes Artificial Intelligence, pp. 1418, Berlin.
Springer.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SAT problems.
Proceedings Tenth National Conference Artificial Intelligence, pp. 459465, San
Jose, California. American Association Artificial Intelligence.
Patel-Schneider, P. F. (1998). DLP system description. Franconi, E., Giacomo, G. D., MacGregor, R. M., Nutt, W., Welty, C. A., & Sebastiani, F. (Eds.), Collected Papers International Description Logics Workshop (DL98), pp. 8789. Available CEUR-WS/Vol-11
http://SunSITE.Informatik.RWTH-Aachen.DE/Publications/CEUR-WS.
Patel-Schneider, P. F., & Sebastiani, R. (2001). new system methodology generating random modal formulae. Proceedings International Joint Conference Automated
Reasoning, IJCAR2001, Vol. 2083 Lecture Notes Computer Science, pp. 464468,
Siena, Italy. Springer.
Pitt, J., & Cunningham, J. (1996). Distributed modal theorem proving KE. Minglioli, P.,
Moscato, U., Mindici, D., & Ornaghi, M. (Eds.), Automated Reasoning Analytic Tableaux Related Methods: International Conference Tableaux96, Vol. 1071 Lecture
Notes Artificial Intelligence, pp. 160176, Berlin. Springer.
Tacchella, A. (1999). *SAT system description. Lambrix, P., Borgida, A., Lenzerini, M., Moller,
R., & Patel-Schneider, P. (Eds.), Proceedings 1999 International Workshop Description Logics (DL99)., pp. 142144.

389

fiJournal Artificial Intelligence Research 18 (2003) 217-261

Submitted 8/02; published 3/03

Interactive Execution Monitoring Agent Teams
David E. Wilkins
Thomas J. Lee
Pauline Berry

WILKINS @ AI . SRI . COM
TOMLEE @ AI . SRI . COM
BERRY @ AI . SRI . COM

Artificial Intelligence Center, SRI International
333 Ravenswood Ave., Menlo Park, CA 94025 USA

Abstract
increasing need automated support humans monitoring activity
distributed teams cooperating agents, human machine. characterize domainindependent challenges posed problem, describe properties domains influence
challenges solutions. concentrate dynamic, data-rich domains humans ultimately responsible team behavior. Thus, automated aid interactively
support effective timely decision making human. present domain-independent
categorization types alerts plan-based monitoring system might issue user,
type generally requires different monitoring techniques. describe monitoring framework
integrating many domain-specific task-specific monitoring techniques using
concept value alert avoid operator overload.
use framework describe execution monitoring approach used implement Execution Assistants (EAs) two different dynamic, data-rich, real-world domains assist
human monitoring team behavior. One domain (Army small unit operations) hundreds
mobile, geographically distributed agents, combination humans, robots, vehicles.
domain (teams unmanned ground air vehicles) handful cooperating robots.
domains involve unpredictable adversaries vicinity. approach customizes monitoring behavior specific task, plan, situation, well user preferences.
EAs alert human controller reported events threaten plan execution physically threaten
team members. Alerts generated timely manner without inundating user
many alerts (less 10% alerts unwanted, judged domain experts).

1. Introduction
automation reliable, high-bandwidth communication networks become common, humans increasingly responsible monitoring controlling activity distributed teams
cooperating agents, human machine. control decisions many realistic domains
complex, require human experience judgment. vision human decision makers
able perform important tasks continuously monitoring incoming information
relying automated execution aid alert significant new information warrants
attention. primarily interested domains requiring human control describe
two domains. However, majority techniques analysis also apply completely
automated execution monitoring. fact, one domains interact human
controller autonomously adjust robot behavior plans.
rapidly make effective control decisions distributed agent teams, human needs automated support, several reasons. First, inexpensive sensors reliable, high-bandwidth communication networks provide large volumes pertinent data arriving sensors, team members,

c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiW ILKINS , L EE , & B ERRY

sources. Without automated support, human cannot cope volume incoming
information. Second, plans coordinate activity several team members, many several
hundred first domain, become complex monitor without automated help. Third,
addressing domains dynamic, sometimes requiring responses seconds less.
Fourth, automated team members (robots) complex, different failure modes recovery procedures, automated support controlling often essential. challenges
magnified tempo decision cycle increases user becomes stressed. Thus,
domains properties require interactive, automated assistant support humans
monitoring incoming information controlling agent teams.
concentrate dynamic, data-rich domains humans ultimately responsible
team behavior. Realistic domains often adversaries overcome. may range
fairly benign forces nature introduce uncertainty, intelligent adversaries trying
actively thwart plans. automated execution assistant interactively support effective
timely decision making human, interact human take advantage knowledge
human possesses explicitly modeled machine. Ideally, execution assistant
would allow human user to, among things:
Guide system minimal effort
Focus external events, assuming system alert user human attention
desirable
Understand, evaluate, modify plans/actions
Understand action decision taken/recommended/rejected
system
constant multimodal feedback
Recommend actions decisions violate constraints warranted
One key idea rich plan representations allow execution aid share context users,
understand semantics plans requests. Understanding plan key helping
user deal possible information glut created advanced information systems.
execution aid uses plan filter, interpret, react large volume incoming information,
alert user appropriately events threaten plan users physical existence.
user develops trust execution aid, reduction need human
monitoring display information system, simultaneously increasing amount
relevant information monitored aid analyzes every piece incoming data. Relying
alerts automated aid allows human pay attention important tasks
monitoring incoming data, attending display alerted execution aid.
next section, characterize domain-independent challenges posed problem,
concentrating unique interactive execution aids dynamic domains distributed
teams cooperating agents. Then, describe properties various domains influence
challenges solutions. Section 4, present domain-independent categorization
types alerts plan-based monitoring system might issue user. Next, describe concept
value information alerts key reducing unwanted alerts (alarms). Sections 6
218

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

7 describe Execution Assistants implemented small unit operations robotics
domains, respectively. Sections 6.8 7.5 contain results evaluations performed
domain. Finally, discuss related work present conclusions.

2. Interactive Monitoring Challenges
great interest plan generation algorithms, less work using plans dynamically control execution. Much execution monitoring work describes monitors specific domains,
first characterize domain-independent challenges monitoring agent teams.
several universal challenges execution monitoring particular dynamic, data-rich domains interactive monitoring. issues part monitoring
ontology addressed EAs, stress discussion
discussed elsewhere (Kaminka, Pynadath, & Tambe, 2001; Jonsson, Morris, Muscettola, & Rajan,
2000; Muscettola, Nayak, Pell, & Williams, 1998; Myers, 1999; Wilkins, Myers, Lowrance, &
Wesley, 1995; Coiera, 1993; Durfee, Huber, Kurnow, & Lee, 1997). issues include following:
Sensitivity monitor ability detect problems meet requirements. system
must remain reactive incoming data performing monitoring tasks.
Temporal reasoning temporal sensitivity. Execution takes place time plans specify future actions, thus making temporal reasoning central.
Concurrent temporal processes. Multiple tasks agents may executing concurrently.
Synchronization agents. execution assistant must get right information
right team members right time support cooperative activity specified plan.
domains, may require plan recognition team members (Kaminka
et al., 2001).
False redundant alarms. Unwanted alarms ubiquitous data-rich domains
medicine (Koski, Makivirta, Sukuvaara, & Kari, 1990; Tsien, 1997) domains described paper.
Combining event-driven goal-driven behavior. execution assistant must respond
unfolding events acceptable latency concurrently invoking actions continue execution (perhaps modified) plan satisfy user requests. Goal-driven tasks
include responses events, generating modified, new, contingency plans,
invoking standard operating procedures.
Adversarial reasoning, including plan pattern recognition. Many real-world domains
adversaries activity must closely monitored.
concerned execution monitoring agent teams, team members may
combination humans and/or machines. concentrate challenges unique
interactive execution aids dynamic domains, categorize challenges following
four categories.
Adaptivity. output execution assistant must meet human requirements preferences monitoring behavior, providing high-value alerts suggestions. execution
219

fiW ILKINS , L EE , & B ERRY

monitoring, sensitivity crucial, interactive monitoring sensitivity monitor must
also adaptable. addition adapting user preferences, analysis done execution
assistant level autonomy must adjustable operational tempo incoming data rate.
system ideally adapt output users capabilities cognitive load.
Plan situation-specific monitoring. Coordinating activities many teams members
requires plan shared team. assume plans contain partial orders tasks
team member, well necessary coordinating instructions commitments (Grosz &
Kraus, 1999). plan representation also encodes expected outcomes (effects) plan
execution, execution aids detect deviations. analysis done execution assistant
suggested responses must depend plan situation effective, events
often cause problem plans others. found monitoring algorithms
must often tailored specific tasks compose plans. facilitate interaction, plan
representations must understandable humans system, although human might
aided multiple plan views internal representation user-friendly interface.
Reactivity. execution monitor must react events uncertainty introduced environment. dynamic, data-rich domains, particular care must taken ensure system
remains reactive high rates incoming information fast decision cycles. Resources
generally available perform desired analyses every input example, projecting
future problems multiple simulation runs searching better plans may computationally
expensive. often obvious boundaries types support execution aid might
provide real-world domain. Therefore, balance must struck capabilities provided resources used. examples show types issues arise practice.
first domain, coarse terrain reasoning used, projections using fine-grained terrain data
computationally expensive. robot domain, adjust time quanta assigned
processes scheduler monitoring processes executed least every second. Finally, domains dangerous intelligent adversaries, reacting detected activity
becomes high priority. considerable research guaranteeing real-time response
(Ash, Gold, Seiver, & Hayes-Roth, 1993; Mouaddib & Zilberstein, 1995), tradeoffs generally different every application usually critical aspect design execution
assistant.
High-value, user-appropriate alerts. Alerting every occurrence monitored condition
possibly problem relatively easy; however, user would quickly ignore assistant
gave many alerts. challenge give false alarms inundate user
unwanted redundant alerts. system must estimate utility information alerts
user, give high-value alerts, present alerts manner appropriate value
users cognitive state. found common challenge avoid cascading alerts events get
progressively away expectations along number dimensions (such time,
space, resource availability). Another challenge discuss depth aggregating
lower-level data (e.g., sensor fusion), reduce number alerts consolidating inputs.
Estimates value alerts used adjust alerting behavior users cognitive load.
Interactive alerting execution naturally leads equally important challenging
topic human directing responses plan modifications. monitoring technologies
used continuous planning frameworks (Wilkins et al., 1995; Myers, 1999), limit
scope paper interactive alerting. briefly mention ongoing research
topic either using plan use conjunction execution aids.
220

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Agent systems interact humans active area research, issues discussed literature (Myers & Morley, 2001; Ferguson & Allen, 1998; Schreckenghost & et al.,
2001). Myers Morley (2001), example, describe Taskable Reactive Agent Communities
(TRAC) framework supports human supervisors directing agent teams. address topics
adjustable agent autonomy, permission requirements, consultation requirements,
ability communicate strategy preferences guidance. TRAC complementary execution
monitoring described paper.
Another active research area fits naturally execution monitoring approach theories collaboration. fact, use SharedPlans theory collaboration (Grosz & Kraus, 1999)
second domain (Ortiz & Hsu, 2002) direct agents conjunction execution monitor. theory models elements working together team well levels partial
information associated states evolving shared plan. Central theory SharedPlans
notion agents committed providing helpful support team members. Within
theory, notion helpful behavior formally defined (Ortiz, 1999). work
collaboration complimentary monitoring approach, discussed detail.

3. Monitoring Approach Determined Domain Features
domain features monitoring challenges concerned common many
domains addition robot teams small unit operations (SUO). example, occur
monitoring spacecraft (Bonasso, Kortenkamp, & Whitney, 1997; Muscettola et al., 1998)
monitoring medicine (Coiera, 1993) ICU patients anesthesia. domains also
data rich medical clinicians difficulty using vast amount information
presented current monitoring systems (Weigner & Englund, 1990; Coiera, 1993).
particular, problem flooding human users false redundant alarms ubiquitous
medical monitoring (Koski et al., 1990; Tsien, 1997). One study found 86% alarms
pediatric ICU false alarms (Tsien & Fackler, 1997). False alarms distract humans
important tasks. false alarm rate would likely make monitor useless fast-paced
operations. Research domains concentrated automated monitoring, little
emphasis interactive monitoring.
challenges described previous section apply interactive, dynamic domains, properties individual domains influence solutions. One brief case study shows
features communication system use legacy agents indicate different
monitoring approach two similar problems. Kaminka et al. (2001) address problem similar ours: many geographically distributed team members coordinating plan dynamic
environment. use approach based applying plan-recognition techniques observable actions team members, rather communicating state information among team members,
refer report-based monitoring.
list four problems report-based monitoring (Kaminka et al., 2001): (1) intrusive modifications required legacy agents report state, (2) necessary state information changes
monitoring task, (3) monitored agents communication lines heavy computational bandwidth burdens, (4) assumes completely reliable secure communication
team members. say (1) main concern, (3) next
important.

221

fiW ILKINS , L EE , & B ERRY

Plan constraint violated
Policy constraint violated
New opportunity detected
Adversarial activity detected
Constraint violation, opportunity, adversarial activity projected
Contingency plan suggested
System problem detected
Reporting requirement triggered
Figure 1: Top-level categories alert ontology.

domains, use report-based monitoring. agents already report state
easily modified so, example, attaching Global Positioning (GPS) devices.
monitoring tasks performed using reports already available, although one imagine
adding functionality would change reporting requirements. first domain,
reports distributed Situation Awareness Information Management (SAIM) system
high-bandwidth network. SAIM uses novel peer-to-peer (P2P) dissemination algorithms
forward fusion sensor reports, greatly reducing bandwidth requirements. P2P fault tolerant,
allowing node server. Dissemination based agents current task, geographic
location, relationship hierarchical organization team members.
summary, report-based monitoring works domains rely less unmodifiable legacy agents, reliable communications, enough bandwidth available
network dissemination algorithms. Kaminkas approach provides automated support,
must address problem modeling value information user. Kaminkas
system extended interact humans, believe alert ontology techniques
avoiding operator overload would applicable, whether alerts come sources based planrecognition reports. rely humans ultimately responsible team
behavior, require much state information complete reliability communication.
Unreliable communication degrade monitoring performance, human decision maker
must take missing inputs account making decision. execution assistant monitor
communications alert human possible communications problems.

4. Types Alerts
Alerts used focus users attention aspect situation execution aid
determined high value. discuss problem determining value information
alerts later sections, determines whether alert presented. alert may
indicate response required, may informative. Many different types alerts
given, useful categorize alerts, thus providing beginning reusable, domainindependent ontology execution monitoring.
Figure 1 shows top-level categories alerts identified starting superset categories found useful two domains generalizing cover
broad range domains. assumed execution directed plan shared
team. categories generally require different monitoring techniques different responses
222

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

detected problems. example, adversarial activity could subclass relevant
classes, requires different monitoring techniques. friendly location data precise (within
error GPS) trustworthy, adversarial data comes fusion engines running
data sensor networks. adversarial data highly uncertain, may come significantly different rates, generally different algorithms determining value information,
adversarial entities actively trying thwart plan perhaps trying kill you.
top-level categories ontology generally differ along following dimensions
important monitoring:
Properties data sources (such reliability uncertainty).
Rates incoming data
Method acquiring data (such receiving messages, pulling data databases,
plan recognition)
Monitoring algorithms, including tradeoff complexity analysis reactivity
Desired responses alerts
Value information algorithms
different monitoring techniques category often domain specific, even
task specific cases, adapting monitoring tasks plan executed.
monitoring framework integrates various techniques uses concept value
alert control interaction user.
briefly discuss top-level categories. provided next lower level
ontology space possibilities large, domain-specific concerns important.
example, adversarial alerts could include subclasses fixed mobile adversaries, size
capabilities adversarial team, alliance tightly coordinated adversarial team,
adversarial intent plan, forth. Later paper, describe alerts given
implemented execution assistants (EAs) fit categories.
Plan constraints. Plans provide expectations execution proceed,
category richest set alerts. fairly large hierarchical ontology could produced
describe different types alerts plan constraints. Gil Blythe (1999) present domainindependent ontology representing plans plan evaluations. concept evaluation
ontology could source alert evaluation becomes sufficiently important
user. Plans real-world domains often hierarchical, constraints different levels
layers may violated. may desirable customize alerts based hierarchical level
plan constraint question. indicate range possible alerts category, list
common examples:
coordinating team member (or agent) position late.
effects agents (or team members) actions achieved expected.
team member retracted commitment perform certain task, requiring reallocation
tasks resources.
223

fiW ILKINS , L EE , & B ERRY

Conditions required plan true expected.
Resources used plan available degraded.
Policy constraints. real-world domains persistent constraints policies
rules engagement must violated. could considered part
plan representing maintenance conditions extend entire plan,
significantly different practice often monitored different techniques, may
require additional domain knowledge specialized monitoring algorithms, must invoked
efficiently. example, domains, never want human team members killed
robots destroyed. Therefore, monitor physical safety agents times give
alerts user agent danger. Dangers adversarial agents covered
category. However, system also alert user threats team members
(fratricide) local agents actions (e.g., robots battery running low).
New opportunities. Even though current plan still executed without change, may
possible generate better plan current situation new opportunities arise. Determining
execution-time update world state permits desirable plan difficult problem
general, similar generating new plan new situation. However, real-world domains,
often methods detecting new opportunities indicate plan revision might cost
effective. example, certain key features (such pop-up targets military domains)
represent new opportunities, often encoded standard operating procedures (SOPs)
invoked triggered current situation improve plan and/or react
events. monitoring interactive, avoid difficult decision whether
search better plan alerting user high-value opportunities relying user
judge best response.
Adversarial activity. category assumes team members operating environments adversaries trying actively thwart team plans. adversaries dangerous
(e.g., worthy human opponents), reacting detected activity becomes top priority and,
experience, merits customized monitoring algorithms. Recognizing immediate threats team
members physical existence accomplishment plan obviously important. addition, information allows human discern patterns recognize opponents plan
intent valuable. EAs recognize physical threats adversarial activity expected
plan, currently perform automated plan intent recognition data adversaries.
automated plan recognition (Kaminka et al., 2001) inference adversarial intent (Franke,
Brown, Bell, & Mendenhall, 2000; Bell, Jr., & Brown, 2002) active areas research. algorithms developed reliably recognize adversarial plans intent using acceptable
computational resources, could easily invoked within monitoring framework.
Projections. Even though current plan still executed without change time
being, may possible predict future failure plan global constraints occur,
varying degrees certainty. example, suppose plan requires robot move location X
time T, robot getting progressively behind schedule course.
point T, system predict acceptable certainty location constraint
violated alert user, may revise plan. addition, new opportunities probable
adversarial activity could projected. Projection/simulation algorithms computationally
expensive, execution monitor must adjust calculation projections match available
resources constraints.
224

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Contingency plans. plan may specify contingency plans subplans,
invoked certain, specified conditions arise. execution monitor monitor conditions alert user contingency plan triggered. system also notify
team members automatically user decides switch execution contingency plan. Another desirable alert domains might suggestion system new contingency
plans generated certain situations events unfold unexpected manner. EAs
monitor triggering contingencies suggest generation.
System problems. Depending domain, user may want alerted problems
incoming data streams functioning execution assistant itself. example, data
arriving sensors, network team members, may crucial
helping user interpret situation system alerts.
Reporting requirements. One basic assumptions human user experience
knowledge modeled within system. Therefore, system cannot always recognize new piece information affect plan execution. information
trigger alerts might still valuable user. system given reporting requirements allow recognize information. One generally useful reporting requirement would
execution status, user quickly determine execution proceeding planned. Reporting requirements may take number forms, appropriate domain. comments
recognizing new opportunities apply domains might specify requirements SOPs,
key features, declarative statements, heuristic algorithms. Several things fall category,
information reduces uncertainty and/or indicates plan executing expected.
another example, robot might told immediately report murder fire witnesses
executing planned tasks.

5. Value Information Alerts
Algorithms alert constraint violations threats straightforward manner inundate
user dynamic domains. Unwanted alerts problem domains many
domains well, medical monitoring (Koski et al., 1990). aid gives alerts every
second quickly discarded user stressful situations (if immediately). useful,
execution aid must produce high-value, user-appropriate alerts. Alerts presentation may
also adjusted situation, including users cognitive state (or computational
state software agent). example, high-stress situations, tolerances could increased
certain types alerts might ignored postponed. section, provide conceptual
framework alerting algorithms monitoring framework domain-specific EAs.
approach grounded concept determining value alert. First, system
must estimate value new information user. Information theory derives communication theory work Shannon (1948). theory, value information refers
reduction uncertainty resulting receipt message, meaning
message (or uncertainty reduction) receiver (Weinberger, 2002). use term
value information (VOI) different sense, namely, pragmatic import information
relative receiver. (Of course, reduction uncertainty often pragmatic import.) Like
Weinberger (2002), assume practical value information derives usefulness
making informed decisions.

225

fiW ILKINS , L EE , & B ERRY

However, alerting user valuable information could negative impact certain
situations, alert distracts user important tasks, many
alerts overwhelm user. therefore introduce concept value alert (VOA),
pragmatic import (for making informed decisions) taking action focus users
attention piece information. VOA takes VOI account weighs costs
benefits interrupting user. user busy something significantly important,
issuing alert might valuable, even VOI high. VOA must generally estimate
users cognitive state current activities. VOA generally determine modality
qualities alert presentation (e.g., whether one flash red text computer display
issue loud audible warning).
VOI VOA highly correlated situations, general comments VOI
apply VOA well. However, VOA may low VOI high user highly stressed
preoccupied important tasks. also possible high VOA low VOI.
example, mission-specific monitors might alert user information known
time (and thus little value information) information crucial
upcoming decision user may forgotten it, may behaving way indicates
lack awareness.
Weinberger gives quantitative definition pragmatic information, assuming finite set
alternatives lead well-defined outcomes, value decision maker.
realistic domains like ours, alternatives outcomes precisely defined. Furthermore,
information decision theories (including Weinbergers) assume decision maker aware
(or processed) previous information devote sufficient resources analyzing
current information. assumptions unlimited processing power, VOA VOI
same. realistic domains, assumptions hold. Humans resource bounded and,
fast-paced operations, alerts information may ignored user may realize
implications information complex plan coordinates many team members.
5.1 Estimating VOI VOA
interactive, dynamic, real-world domains like SUO, cannot model alternatives, payoffs, knowledge probabilities required enough precision compute
theoretical VOI VOA. Much knowledge VOI resides human experts,
even might different preferences opinions VOI. example, SUO domain, user might concerned public-relations effects plan execution
reported international media. precisely humans knowledge modeled
system want execution assistants interactive. realistic domains,
generally obvious boundaries types support system provide,
precisely defined evaluation functions payoff matrixes. Thus, Weinbergers theory formal
techniques computing value information (Athey & Levin, 2001) cannot applied. Horty
Pollack (2001) develop foundations theory rational choice involves
estimating cost decisions context plans. approach comes closer addressing
concerns. However, determining costs utilities actions continue require human
judgment many domains, especially human lives put risk.
Therefore, developed algorithms heuristically estimate VOI using domain knowledge,
although quantitative VOI functions easily used framework. inputs al-

226

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

gorithms described Section 5.3. domain-specific algorithms are, must be, easily
customized tuned user preferences, well situation. invoked domainindependent ways variety purposes monitoring framework, developed
feedback domain experts. believe feasible use machine-learning techniques
replace supplement hand-coded heuristics VOI/VOA estimation and/or user preferences
affect it, explored.
VOI VOA computed qualitatively domains, using several domain-specific quantitative measures qualitative reasoning process. Issuing alert discrete event, generally
small number options presenting alert. Therefore, estimating VOA primarily problem categorizing potential alert small number alert presentation types
modalities. need determine VOA crosses thresholds (defined VOI/VOA
specification) indicating, example, valuable issue alert, alert
issued high-priority. framework, thresholds customizable user
mission specific, change automatically different missions plan executed.
VOI algorithms also determine information include alert.
Different alert presentations handled assigning qualitative priority alert. example, SUO EA divides alerts VOA four equivalence classes levels priority,
already defined SUO domain. priority presented differently user,
using different modalities simply using different colors sizes text graphics. Currently,
use three priority levels robotics domain, may add future collaborating team
members make use EA. priority levels used adjust alerting behavior
users cognitive load. example, fast-paced operations, highest-priority alerts
could presented.
several reasons preferring qualitative reasoning, draw Forbuss work
describing advantages (Donlon & Forbus, 1999; Forbus, 2002). Qualitative models fit perfectly
making decisions, discrete events, effectively divide continuous properties
important transitions. Thus, changes qualitative value generally indicate important changes
underlying situation. Qualitative models also facilitate communication built
reasoning human experts thus similar peoples understanding. example,
priority levels used VOA algorithms long named defined military.
Qualitative reasoning important framework integrating results various qualitative
computations way humans understand. Finally, precision quantitative models
serious weakness underlying models accurately reflect real-world situation.
Precise data lead precise incorrect results low-accuracy model, precise results
lead false sense security.
advantages qualitative reasoning apparent common sense military reasoning. Common sense reasoning continuous quantities often done qualitatively.
continuous value interest different action decision required. example,
ignore fuel gauge driving decided whether must refuel reaching destination. addition priorities already mentioned, military
quantizes many continuous properties used describe terrain ways relevant military
operations, creating phase lines, decision points, named areas interest, key terrain avenues
approach, forth. SUO EA incorporates quantizations reason terrains influence VOI VOA effectively communicate information alerts, military
used years facilitate communication, collaboration, decision making.
227

fiW ILKINS , L EE , & B ERRY

5.2 Properties VOI VOA
VOI VOA dynamic domain depends primarily whether information influence
decisions/responses. execution aid must also ensure human awareness high-value data
support decisions human user make. Thus, system must estimate model
human needs know (e.g., specifying reporting requirements), even system cannot predict
information might influence decision. example, emerging adversarial friendly
pattern might crucial. system human-level ability recognize plans
patterns, ensure human decision maker aware relevant data.
One obvious important property VOI zero user already aware
information. Another property information indicating plan execution proceeding
according plan valuable, influences decision continue planned.
value confirming information depends features domain information
valuable domains high uncertainty active adversaries.
Another feature may useful certain domains classifying responses suggested
piece information alert. example, new report may require significant plan
modification, minor plan modification, invocation contingency plan, application
standard operating procedure (SOP), identification new opportunity. However, type
response necessarily correlate VOI, minor plan modification might life saving,
major modification might simply reduce resource usage ten percent. distinction
important simpler responses likely handled automated fashion, thus
reducing need involve user.
Determining information present alert requires addressing human factors. Initially,
important present alert concisely human determine import glance,
assess whether divert attention tasks. EAs, user drill
detailed information alert order assess situation accurately.
Finally, domains may concerns making informed decisions. example,
emotional state user recording data scientific value might beneficial. particular,
concern analyzing debugging system performance rather making good execution
decisions, different VOI estimator used provide alerts system behavior.
5.3 VOI VOA Criteria
described above, VOI VOA algorithms generally heuristic, domain-specific,
user customizable. identify inputs applicable interactive,
dynamic domains. started superset VOI criteria found useful two domains
generalized domain independent. (The properties user listed
estimates system models user, users mental state accessible.)
plan
Policies
Users awareness current situation
Systems view current situation
Users cognitive load
228

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Resources, especially time, available analysis response
Information adversarial agents
Characterization uncertainty
Age information age users awareness
Source information
plan provides several VOI criteria: plan may provide explicit implicit decision
points, high-value places, times, team members, forth. value task, constraint,
adversarial action, team member often determined plan structure plan annotations.
tasks plan invoke task-specific VOI algorithms within monitoring framework,
described Section 6. Domain policies (or specialized reasoners implement them)
reporting requirements provide knowledge necessary determine value alerts
various types constraint violations reports. example, domains, monitor
physical safety agents. Alerts life-threatening situations highest priority.
noted VOI tends zero extent user already aware information. Thus,
determining VOI must access current view situation determine arriving reports offer
new information simply confirm existing view. data-rich domains, assume
execution aid may detailed description situation user (for aspects
situation described incoming data), user may performing tasks
monitoring situation alerted EA. Therefore, value alerting
user depend much new information differs users last situation update,
even system recent data differs slightly new information.
Ideally, would like model users cognitive load, give lower values noncritical
alerts user consumed addressing critical aspects situation. Similarly,
want overload systems computational resources ability remain reactive,
value certain information may depend time resources available analyze it.
determining value information adversaries, often useful compare
developing patterns information adversarys plans tendencies, could
obtained human intelligence analysts generated plan-recognition pattern-matching
algorithms. mentioned above, information reduces uncertainty valuable domains
high uncertainty active adversaries. VOI estimated characterization
uncertainty present current view situation.
age information also factor VOI outdated reports may zero value newer
information already arrived. modeling users awareness, elapsed time factor.
user aware alerts issued last minutes, may longer aware something
brought attention yesterday last week. Thus, value proposed new alert
may increase elapsed time since similar alert issued.
variety sources information exists, source factor VOI. Often, different
information sources inherently different levels certainty, authority, importance. example, SUO EA accepts reports human observers automated sensors. EA
inputs might want weigh human observations differently depending human
situation. later sections implemented EAs, describe domain-specific VOI/VOA
algorithms, inputs corresponding inputs listed above.
229

fiW ILKINS , L EE , & B ERRY

6. Implementing Execution Monitors Small Unit Operations
developed execution-monitoring framework easily adapted produce interactive monitors agent teams dynamic domains. support claim, describe two
dynamic, data-rich, real-world domains Execution Assistants (EAs) implemented
using framework. first domain, Army small unit operations (SUO), hundreds mobile,
geographically distributed agents, combination humans, robots, vehicles.
domain, UV-Robotics (Ortiz, Agno, Berry, & Vincent, 2002), described Section 7
teams composed handful cooperating, unmanned ground air vehicles (UGVs
UAVs) human controller. domains involve unpredictable adversaries vicinity
team members.
originally developed monitoring framework SUO domain using several personmonths effort, although majority effort knowledge acquisition modeling.
SUO monitoring framework, described below, designed modular support
easy insertion domain-specific (and user-customized) system components, task models,
monitoring algorithms, value-of-information estimators. design validated
implemented complex execution monitor UV-Robotics domain one person-week
(as described Section 7.2). UV EA uses plan representation basic architecture
SUO EA, inputs different tasks monitoring algorithms
respond inputs generate alerts.
majority framework also applies completely automated execution monitoring
demonstrated UV EA. UV EA runs robot team used autonomously
adjust robot control blending desired behaviors automatically revising plans execution. UV EA also provides alerts human controller monitoring robots.
framework described section general, follow domain-specific
details clarify concepts tradeoffs. details may interest readers.
6.1 SUO Problem Description
Small unit operations military involve hundreds mobile, geographically distributed soldiers
vehicles cooperatively executing fast-paced actions unpredictable adversary. Computational support bandwidth restricted must use lightweight portable devices. Currently,
planning decisions made humans, plans machine understandable.
implemented SUO EA part larger system: Situation Awareness Information Management (SAIM) system, distributes timely, consistent situation data friendly
agents. SAIM uses new technologies demonstrate new concept automated support (described
below) SUO domain. assume many small teams agents (human, vehicles, eventually robots), separated dispersed throughout large space, operating concert achieve
goals. assume agent equipment providing robust geolocation (GPS), computing,
communication capabilities. SAIM also assumes unpredictable adversary, fast-paced action,
rich population sensors controlled cooperating team members.
key innovations SAIM, addition EA, self-organizing peer-to-peer information architecture forward fusion tracking. Fusion information tracking distributed
done close source minimize latency, bandwidth requirements, ambiguity. Adjudication maintains consistency distributed databases. information architecture supports ad hoc
information dissemination based multicast groups centered mission, geography, command.
230

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Self-elected servers provide robustness information dissemination peer-to-peer
network brings transport layer.
SAIM provides large volumes geolocation data much information human controller monitor, particularly high-stress situations. EA alleviates problem using
machine-understandable plan filter information SAIM alert user events
threaten user execution plan. plan-aware, situation-aware, action-specific EA
alert appropriately situation, thus improving decision making enabling hands-free
operations, reducing need human monitoring, increasing amount relevant information
monitored, prompting user action required.
complexities plans, number agents, volume data pose challenge
existing execution-monitoring techniques. Unlike lot AI planning work, particularly robotics,
actions domain performed external agents, mostly humans, monitor
access state executing agents. Status information must obtained external inputs.
focus problem alerting human users situation requires attention;
assume human modify plan needed. done several reasons. First,
users unwilling cede decision making machine, first develop trust giving useful
alerts, capability well suited automation plan represented enough fidelity,
something provides obvious value dealing information glut. Second, mistakes
matter life death, systems must verifiably robust given decisionmaking power. Human decision makers must take imperfect information account, including
reports sensor networks, humans, execution assistants. Third, demonstrating
utility automated, plan-based monitoring large complex domain likely facilitate
future acceptance users plan-related automation.
name
Battalion
Company
Platoon

Abbrev
BN
CO
PLT

Entities controlled
400-600
100
30

Figure 2: Echelons command hierarchy EAs.

Execution monitoring requires coordination multiple echelons (levels hierarchy),
users know subordinates doing. Figure 2 shows echelons
demonstrated EA. Multiple agents echelon must coordinate fast-paced activities
wide area real time. task requires solution three difficult problems: handling large
volume incoming information, developing sufficiently rich plan representation capturing
tactical Army plans, determining alert user.
mentioned before, EA must give high-value alerts useful. example,
unit position late, system must recognize import condition
situation changed sufficiently issue another alert, without issuing many alerts.
Consider seemingly simple example plan specifying squad 10 agents move
Objective Golf 0700. location squad? obvious solution compute
centroid members location. However, one near centroid members
large semicircle centroid center (this situation arises squad follows
231

fiW ILKINS , L EE , & B ERRY

road around sweeping curve). one member immobile GPS still broadcasting,
centroid may seriously inaccurate. centroid need near Golf, one member near
Golf sufficient, must members near Golf? depends mission (task) situation.
mission observe valley, one member sufficient, might want members
attack. solution use mission-specific algorithms (specified mission model described
Section 6.5) reasoning location units.
EA must avoid cascading alerts events get progressively away expectations
along number dimensions (such time, space, resource availability).
example, close time 0700 squad problem achieving
plans objectives? Similarly, close distance Golf? Again, time distance thresholds
indicate problem depend mission situation. human uses background world
knowledge quickly determine delay affects plan, execution aids must much
knowledge encoded this. problems become exacerbated plans missions
become complex. Detecting friendly-fire (fratricide) risks poses even difficult issues,
typically many friendly units close proximity.
6.2 SUO Approach
Machine understanding plan key helping humans deal information glut created advanced situation-awareness systems like SAIM. plan specifies expectations
events unfold, EA compare actual events situations anticipated.
use rich, knowledge-based plan representations (Wilkins & desJardins, 2001) allow computers
share context users, understand semantics plans requests.
two tasks involving significant knowledge acquisition domain modeling: (1)
model SUO plans actions compose them, (2) model value
information various types alerts users. interacted several domain experts
develop models. tasks aided centuries analysis modeling
already done domain. task 1, Army already standard plan representation
called Operations Order, required structure, entries mostly free text.
Primitive actions domain referred missions, Army field manuals
describe missions detail. modeled missions hierarchical mission model. mission
model plans described Section 6.5. task 2, extensive accumulated experience
analysis errors opportunities arise execution SUO plans, many
tradeoffs made. tradeoffs models described Sections 6.4, 6.6, 6.7.
Mission-specific execution monitoring achieved novel integration mission knowledge
represented methods AI reactive control system. EA invokes methods appropriate
points plan execution. methods employ mission-specific algorithms turn invoke
EA capabilities mission-specific manner. Much domain mission knowledge encoded mission model explicitly represented plan itself, specifies partial
order missions team member. EA uses plan invoke knowledge
mission model appropriate time appropriate arguments.
Another feature approach, particularly terrain reasoning, pervasive use specialized programs, possibly external EA, perform complex computations important
system performance. using alternative specialized programs, EA easily adapt granularity reasoning improve performance better modules become available. example,

232

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

API functions design used terrain reasoning compute enemy strength
current tracks.
approach builds SRIs continuous planning technology (Wilkins & desJardins, 2001;
Wilkins & Myers, 1998; Wilkins et al., 1995) domain-independent Act formalism
(Wilkins & Myers, 1995). Act represents procedural knowledge plans Acts, provides
rich set goal modalities encoding activity (see Section 6.5), used several
institutions (Wilkins & Myers, 1998; Durfee et al., 1997). EA uses P RS (Georgeff & Ingrand,
1989; Wilkins et al., 1995) reactive control system (other reactive control systems similar capabilities, e.g., UM-PRS (Durfee et al., 1997)). P RS good framework constructing
EA supports parallel activities within agent, smoothly interleave responses
external requests events internal goal-driven activities uniform processing
goal- event-directed behavior. P RS uses procedures encoded Acts extensive graphical
tracing provides valuable insights EA operation.
6.3 SUO Architecture
architecture EA interactions SAIM system shown Figure 3.
developed two major modules, Planning Assistant (PA) Execution Assistant (EA),
assist user generating executing plans, respectively. implemented skeletal
PA produce machine-understandable plans, using IPE 2 hierarchical task network planner
(Wilkins et al., 1995). PA EA use Acts common knowledge base, ontology,
mission model object-based easily extended. Knowledge actions represented
mission model, knowledge plans, strategies, procedures represented Acts.
inputs EA plans execute, location reports, sensor tracks, messages
agents (e.g., reporting mission success failure, ordering execution new plans).
SAIM broadcasts up-to-date locations friendly agents, broadcasts tracks represent
results fusing sensor hits nonfriendly entities. SAIM provides EA supports rates
dozen inputs per second.
EA monitors current mission every immediate subordinate EA owner,
alerts threats subordinates (subordinate depth customizable). events threaten successful
execution plan, threaten user subordinate units, trigger planned contingencies,
EA issues alert user, depending value alert determined applying
VOA algorithms. user must decide respond. design technology also
suggest responses and/or plan modifications (Wilkins et al., 1995), left future work.
addition giving alerts, SUO EA dynamically change command hierarchy, abort
execution one plan switch monitoring new plan, reduce unwanted alerts avoid
inundating user.
EAs every unit every echelon process reports give alerts locally. SAIM provides
tactical picture EAs (modulo EAs registration SAIM multicast groups). Therefore,
necessary EA report new threat superior, superiors EA (as well
EA affected team members) information would already issued
similar alert. architecture fault tolerant EAs rely reports subordinates
determine alerts. Thus, EA maintains functionality even contact
EAs, long gets SAIM position reports one node.

233

fiW ILKINS , L EE , & B ERRY

PA

EA
PDA Domain KB

PDA Domain KB
Acts used
planning

Plan
Initializer

Cue:
ACT2
(TEST (ready unit1))
Cue:

ACT1
Answer query

Executable
Plan (Act)

Execution
Manager
Requests, updates

Executable
Plan

Cue:

ACT1
Answer query

Executable plan,
monitors

Advisable
Planner Agent
Partial plan
Task organization
Assets
Guidance

Cue:
ACT2
(TEST (ready unit1))

Common: ontology
mission model

PRS

Common: ontology
mission model

SIPE

Acts used
monitoring

Requests
Registrations
Notifications
Updates

SimFlex

Watchman
PRS

PRS

SAIM: Persistent Data Store (PDS), Disseminator, ...

Situation
Updates
Requests
Scripted Events

Figure 3: Internal architecture EA PA interaction SAIM. PDS archives
plans data continuously changing picture current situation.

shown Figure 3, EA implemented multiple asynchronous P RS agents (defined below) alleviate computational burden central EA Manager agent. Asynchronous agents
provide faster response better alerts would synchronous architecture, agents
always using latest information available without wait synchronize
agents. implement EA, extended P RS monitor temporal constraints batch
incoming facts could handle much higher data rates.
Internal EA agents (as opposed external team members) use Belief-Desire-Intention (BDI)
model agency (Rao & Georgeff, 1995). agent beliefs state world, desires
achieved, intentions representing actions agent adopted achieve desires.
EA agent controller process, operates database beliefs,
set intentions, monitors, set Acts encode procedural knowledge
accomplish goals, L ISP functions implement primitive actions
agent. EA agent continually applies Acts accomplish current intentions (tasks). EA
appears single agent SAIM outside world. following internal EA agents.
Plan Initializer. agent gets plan PA sends messages EA Manager
agent performing initializations necessary begin monitoring plan execution. Primarily,
involves creating loading plan monitors, posting facts EA Manager database.
Watchman. agent monitors incoming message traffic SAIM network, mainly
querying tracks information. filters irrelevant insignificantly changed reports,
sends message EA Manager report message requires attention.
simultaneously monitors files scripted events monitoring requested. Watchman
inserts events scripts appropriate times, interleaving live messages.

234

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

EA Manager. agent begins plan execution immediately receiving plan
Plan Initializer. agent implements core EA functionality compares reports
Watchman agent plan plan monitors, generates high-value alerts.
SimFlex. agent provides powerful flexible way define execution semantics
action using Acts (and thus full power PRS). SimFlex (simulated, flexible execution)
enables mission-specific execution monitoring (by Act mission) makes
system easily extendible. example, certain missions automatically command robotic
vehicles send messages EAs, actions could easily implemented SimFlex.
actions plans executed external human agents, case agent
little except perhaps prompt user. actions, reorganizations, automatically
executed SimFlex invoking Execute-Mission method defined mission model.
6.4 SUO Alert Types
extensive accumulated experience regarding execution SUO plans, selecting
types alerts detect involved trading several factors, whether alert
detected available data, utility alert user, cost implementation,
ability maintain reactivity given computational expense detecting alert. earlier gave
example balancing usefulness fine-grained terrain reasoning movement projection
computational impact reactivity. Thus, modeling value information types
alerts detected involved interaction domain experts system developers.
describe types alerts decided detect. details implement
model value information alerts given Sections 6.6 6.7.
Figure 4 describes 13 types alerts detected SUO EA.
time location checking. Comparing alerts categories Section 4, proximity
alerts instances adversarial activity detected. adversarial alerts also fit category
last three adversarial alerts also type plan constraint violated expectations requirements specified plan (such locations routes monitor) violated.
contingency alert, triggered either friendly hostile actions, type
contingency plan suggested. out-of-position, coordination, schedule alerts type plan
constraint violated, would type constraint violation projected violation projected. fratricide alert type policy constraint violated, unknown-position alert
type reporting requirement.
6.5 SUO Plans Mission Model
hierarchical mission model specifies ontology primitive actions, methods
encode domain knowledge constraints expected behaviors. Tailoring
monitoring mission crucial behaviors, even something simple denoting
location unit, mission specific. plan representation novel combination
mission model extended version Act formalism (Wilkins & Myers, 1995).1
1. EA plans represent plans expressed Army operations orders, parts current Army fiveparagraph order represented machine-understandable form. Primarily, task organization specific maneuver tasks coordinating instructions Execution Paragraph represented, aspects
encoded well.

235

fiW ILKINS , L EE , & B ERRY

Alert Type
fratricide
out-of-position
unknown-position
coordination
schedule
contingency
contingency
monitored
ave-of-approach
hostile-expected
contact
distance
strength
proximity

FRIENDLY ALERTS
Friendly units pose threat other.
Location constraints plan violated.
Unknown location subordinate/coordinating unit.
Coordinating units cannot synchronize planned.
Time constraint plan violated.
event triggered queued contingency.
ADVERSARIAL ALERTS
event triggered queued contingency.
Activity monitored map location.
Activity monitored route (avenue approach).
Expected hostile activity absent.
PROXIMITY ALERTS
friendly units first contact hostile entity.
Hostile entities closer since last alert.
Threat grown stronger since last alert.
merged alert one above.

Figure 4: Types alerts generated SUO EA.

Act formalism domain-independent AI language representing kinds knowledge activity used plan generation reactive execution systems. provides rich
set goal modalities encoding activity, including notions achievement, maintenance, testing, conclusion, waiting. expressiveness necessary representing SUO plans,
must coordinate distributed units, trigger preplanned contingencies, enforce variety execution constraints. basic unit representation Act, used encode plans,
strategies, standard operating procedures (SOPs).
EA monitor plan composed missions mission model. mission
model derived Army field manuals elaboration domain experts. includes set
mission templates (with associated parameters) units various echelons could ordered
perform, either written verbal order. Since mission model grounded field manuals,
first step toward formalizing plan representation meaningful end users yet amenable
execution monitoring AI-related capabilities (e.g., plan generation, replanning, course
action evaluation).
mission model class hierarchy (implemented L ISP CLOS, Common Lisp
Object System), inherited methods encode knowledge monitor particular
mission. leaf class corresponds monitorable action may occur plan; nonleaf
class encapsulates common parameters behaviors subclasses. mission model allows
aspects system behavior tailored mission-specific manner. Thus, specialized
methods mission model can, example, use mission-specific algorithms monitoring
progress movement. Methods invoked EA Manager turn invoke processing
EA Manager posting mission-specific facts invoke capabilities EA Manager
(there API facts, important facts described later).

236

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

mission model contains name parameters describe mission. example, mission model contains nonleaf movement-mission class, contains destination
parameter method checking executing unit arrived destination. Five
different movement missions inherit behavior. root class model mission class,
encapsulates parameters behaviors shared missions. missions inherit
start-time end-time scheduling constraints methods superclass.
Coverage. mission model formalizes substantial subset missions mentioned
Army field manuals. enumerated 62 mission classes, implemented 37 these,
superset required scenarios. mission model covers multiple echelons, emphasis battalion, company, platoon. model aspects missions,
SAIM provide monitoring data, is, related time location. example,
alert potential mission failure due casualties incurred.
Contingencies. mission model contains nonleaf contingent-mission class. class
leaf children classes used implement mission sequence part plan
executed certain conditions fulfilled. Domain experts term portions
plan branches sequels. missions contingent-mission contain parameters describe
condition, specified plan, activates contingency.
Dynamic resubordination. Army operations orders allow command hierarchy (termed
task organization) changed operation, although existing command control software support dynamic changes command hierarchy. reorganization-mission
class provides capability EA. reorganization mission executed, causes
EA update representation command hierarchy accordingly. substantial effect
EA behavior, many EA algorithms use command hierarchy.
Methods. mission provides several methods invoked appropriate times
EA monitor execution mission. set methods serves API mission-specific
execution monitoring semantics. following methods comprise bulk API:
Post-Execution-Constraints main API method invoked EA monitoring mission.
invokes methods post enforce various constraints.
Check-Initial-Location, Check-Final-Location confirm unit(s) positioned correctly
start end mission respectively.
Start-Time-Constraints, End-Time-Constraints check mission beginning ending
execution scheduled. methods usually post facts EA Manager invoke
Timed Monitor mechanisms.
Location-Constraints enforces location checking friendly units hostile tracks variety
missions.
Contingency-Satisfied determines whether contingent mission sequence executed.
Respond-To-Monitored-Red-Activity algorithm responding hostile activity places
plan calls monitoring activity.
Execute-Mission invokes processing required execute mission. invoked posting
goal SimFlex agent, internal agents continue P RS execution ExecuteMission running.
237

fiW ILKINS , L EE , & B ERRY

Compute-Priority computes priority alert.
Desired-Strength-Ratio heuristic expresses desired friendly:hostile ratio combat
power.
Red-Alert-Priority computes priority proximity alert, whether alert issued
all, based recent changes reported strengths friendly unit nearby hostile
tracks.
Wait-Until-Mission-Start, Wait-Until-Mission-End control interaction EA GUI regard mission start end times.
Specialization methods useful expressing desired behavior EA. example,
Location-Constraints method specialized movement-mission, coordination-mission,
several missions. movement missions, EA checks whether centroid moving
unit destination. coordination missions, EA checks whether elements two
coordinating units specified coordination point.
6.6 SUO Execution Monitoring
EA Manager continuously responds new goals facts posted database. Watchman agent asynchronously posting facts EA Manager database receives messages
SAIM. Facts posted include confirmations mission starts completions (from subordinate
EAs), orders aborting current plan executing new plan (from superior EA), sensor
tracks, calls fire, location reports (from SAIM network).
methods mission model post facts EA Manager invoke mission-specific
monitoring. Examples fact-invoked capabilities provided EA Manager include monitoring several types time constraints monitoring specified location activity (with options
friendly enemy, expected unexpected).
behavior EA Manager determined posted goals facts, relative timing, set Acts used respond. EA Manager switches focus highest-priority
task execution cycle goals facts generate responses acceptable latency
(Georgeff & Ingrand, 1989). Execution cycles order milliseconds. System behavior
nondeterministic depends exactly facts goals posted execution cycle, may turn depend CPU scheduling EA Manager, Watchman,
SAIM processes. number alerts rarely varies vary exact times
alerts (which vary seconds), hostile strengths reported (which change
Watchman agent gets fewer CPU cycles accumulate tracks EA Manager
executes).
EA Manager must constantly monitor status behavior currently executing missions, simultaneously monitoring dozen incoming facts per second determining
impact plan. monitoring plan, typically order 100 intentions
trying accomplish one time, 107 Acts (Procedures) apply intentions.
intentions cause alert generated. unprocessed report track forms intention. Typically, five subordinate missions executing simultaneously. produces multiple
intentions: least one detecting start end mission, time

238

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

location constraint (every mission least start time end time constraint). example, time constraint, EA Manager intentions monitor specified time
elapsed required event occurred.
plan-based monitoring EA viewed asynchronously simultaneously
interleaving following activities. describe detail mention
important design tradeoffs.
Initiating aborting plan execution upon request
Monitoring incoming location sensor reports
Monitoring progress missions time constraints specified executing plans
Responding types incoming requests
6.6.1 P LAN MONITORING
monitor plan, request goal posted database. invokes Initialize-Plan Act
computes conditions globally monitored plan posts facts EA
Manager database declaring current plan monitors. facts turn cause
Acts execute EA Manager, load execute plan. EA Manager traverses
parallel branches plan missions complete.
global monitors computed using API function compute-plan-monitoring-data,
specify domain-specific monitors. Domain-independent capabilities also available,
system determine predicates plan preconditions must true initially
(as opposed predicates achieved plan actions precede them). SUO domain,
compute-plan-monitoring-data finds decision points named areas interest specified
plan, sets monitors them. monitoring accomplished posting facts EA
Manager database cause EA notice adversarial activity locations.
EA abort monitoring one plan switch monitoring new plan. process
involves removing facts old missions monitors EA Manager database, aborting
execution Acts currently intended execution, posting goal execute new plan.
6.6.2 L OCATION REPORTS
Blue Report Act Figure 5 invoked every time location report posted EA Manager
database, happen several times second. However, Watchman agent filters location reports interest EA Manager (e.g., entities irrelevant plan
EA owner, change last report), updates representation
current situation EA. Blue Report Act specific SUO domain, framework
requires similar Act written type input actively monitored. example, similar UV-Robotics Act responds state updates (see Section 7.4). Acts
written using Act-Editor (Wilkins & Myers, 1995), tool graphically editing procedural
knowledge (Acts) intuitive user interface.
Act begins invoking domain-specific specialized reasoner check fratricide risk,
may side effect giving alert (using API function issue-alert). specialized reasoner easily replaced better fratricide detection algorithms future. Next,
Blue Report Act checks whether current plan expectations unit, so, calls
239

fiW ILKINS , L EE , & B ERRY

BLUE-REPORT fact: Check-blue-report
Cue:
(CONCLUDE
(Blue-report Unit.1 X.1 Y.1 Time.2))
Preconditions:
- entry Setting:
- entry Resources:
- entry Properties:
(Authoring-system Act-Editor)

N1:
(ACHIEVE (Check-fratricide-risk Unit.1 X.1 Y.1 Time.2))

N2:
(TEST
(Expected-location Unit.1 Id.1
Dest-map-object.1 Time.1 Loc-fuzz.1)

N4:
(TEST
(Not (Expected-location Unit.1 Id.1
Dest-map-object.1 Time.1 Loc-fuzz.1)))

Comment:

N3:

Act invoked every time
blue location report posted
database. invokes API
function check fratricide
risk, another check
units expected location
whenever database
expected location (from plan)
unit report.

(ACHIEVE
(Check-expected-location Unit.1 Id.1
Dest-map-object.1 Time.1 Loc-fuzz.1 :In-progress))

N5:
(RETRACT (Blue-report Unit.1 X.1 Y.1 Time.2))

Figure 5: Graphical representation Act responds every friendly location report.
API function check-expected-location compare current location expected location,
posting alert appropriate. Finally, report fact removed database.
Responding fused sensor track indicating adversarial activity controlled similar Red
Report Act, compares adversarial activity plan expectations. Instead analyzing fratricide
risk, Red Report Act invokes reasoner evaluating adversarial threats. described
Section 6.7, involves updating threat envelope friendly unit.
6.6.3 ISSION MONITORING
explain mission monitoring, give example move mission plan monitored.
move-mission ready execution following parameters:
(move-mission unit start-time-constraint start-time end-time-constraint end-time destination
route formation march-technique contingency contingency-satisfied).

EA Manager begins execution calling three methods defined mission model: StartTime-Constraints, End-Time-Constraints, Location-Constraints. posts facts
EA Manager database invoke mission-specific monitoring capabilities. example, LocationConstraints (which specialized class movement-mission) posts facts locations
mission expects friendly units occupy time (derived destination route
arguments), might also post facts locations mission expects adversarial activity
adversarial activity monitored/alerted.
EA receives confirmation mission start subordinate EA. Location reports
continuously posted Watchman, Act Figure 5 analyzes respect
location facts posted Location-Constraints. Sensor tracks similarly analyzed different
Act. Let us suppose point mission execution, track shows activity location monitored mission. EA would detect invoke mission-specific method
240

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Respond-To-Monitored-Red-Activity, describes mission respond
event. example, could issue alert, abort move, execute contingency plan, ask
user choose set options.
Type
ASAP
ON-ORDER
START-AT
START-NLT
START-NET
END-AT
END-NLT
END-NET

Meaning
start/end specified
start/end ordered
start exactly given time
start later given time
start earlier given time
end exactly given time
end later given time
end earlier given time

Figure 6: Temporal constraint types.

6.6.4 EMPORAL MONITORING
mission model includes starting ending time constraints every mission. time
constraint consists temporal constraint type absolute time. temporal constraint
types EA shown Figure 6. constraints require two types monitoring tasks:
detecting time constraints plan passed without met, detecting events
occur specified time.
extended P RS domain-independent Timed Monitor mechanism provides general
capability covering temporal monitoring requirements. capability implemented
form Acts, supporting L ISP code. Four special types timed monitors
provided, invoked posting facts predicates Check-Not-Later-Than, Check-Not-EarlierThan, Check-In-Window, Check-Near-Time. describe implementation one these;
others similar. Act Check-Near-Time checks event occurs within specified
threshold time point invoked fact form:
(Check-Near-Time event.1 time.1 mode.1 fuzz.1)
succeed, event.1 must occur within fuzz.1 seconds time.1, mode.1 indicating whether
time absolute relative (to time fact posted). Timed Monitor Act sets
timer expires given time, P RS reacts appropriately either expiration
timer occurrence event, posting facts database note success failure
temporal constraint. Acts fact invoked, mechanisms enable
establishment separate intentions perform timing, without blocking processing.
modularization enables triggers set independently respond timing results.
6.6.5 ESIGN TRADEOFFS
described Section 2, balance must struck capabilities provided resources
used. tradeoffs different every application usually critical aspect design
execution assistant. SUO domain, terrain reasoning key factor tradeoff. Using

241

fiW ILKINS , L EE , & B ERRY

fine-grained terrain data analyze progress project future failures overload computational
resources. Therefore, EA uses coarse terrain reasoning, design allows higher-fidelity
terrain reasoners respond defined set terrain analysis requests. feature allows
system adjust analysis tempo operations.
key features consider making tradeoffs reactivity capabilities
amount processing done mission-monitoring methods, report-monitoring Acts,
specialized reasoners (such terrain reasonsers) invoked methods Acts. user
adjust frequency monitoring time customizing parameter settings. Currently,
SUO EA computationally overburdened analyzing every report full, adding
computationally expensive projections alerts future could cause reconsideration
design decision. Finally, amount filtering incoming reports done Watchman
agent affects balance.
6.6.6

FEATURES IMPLEMENTATION

EA responds requests, calls fire, described Section 6.7. Several
capabilities implemented make EA easier use understand. Two briefly
mentioned here. implemented GUI, meant military users, rather facilitate evaluation understanding EA. GUI displays alerts different scrollable windows
priority level, current time, current mission subordinate EA owner.
user confirm mission starts ends locally, although might done voice
modality fielded system. confirmation arrives subordinate EA,
confirmation window mission destroyed. Thus, confirmations prompts given
locally received messages, seamless interleaving two types confirmation.
EA, PA, mission model, P RS IPE 2 implemented C OMMON L ISP, CLIM,
CLOS. EA also contains procedural knowledge form Acts. SAIM implemented
C++ Java, using ACE Object Request Broker CORBA. C++ used interface
EA SAIM CORBA.
6.7 Alert Detection VOI/VOA
central task EA notify user important changes situation may demand
attention. EA must also avoid excessive alerting; otherwise, user would abandon EA
nuisance. model users cognitive state respect awareness threats would
ideal, unavailable. described Section 5, developed algorithms heuristically
estimate VOI VOA using domain knowledge. inputs algorithms described
Section 5.3. avoid excessive alerts issuing high-VOA alerts. techniques include
Keeping event histories friendly unit, map coordinates important map
locations named plan (e.g., decision points).
alerts expire sense longer used suppress future alerts.
Using alert histories suppressing alerts time (similar alert given recently), strength
(threat significantly stronger), distance (threat significantly closer).
Merging several related alerts apply subordinates one alert common parent.

242

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Providing parameters user customize alerting behavior VOI/VOA estimates.
event histories currently model users cognitive state, except global
properties situation, operational tempo. VOA calculations take account
frequency timing alerts already given. histories include alerts
issued object history, may include additional events, described Section 7.4.
assume user aware information recently alerted.
idea behind alerts expire user may forgotten information provided
far past. Thus, EA use alerts older specified threshold reduce estimate
value giving alert now.
EAs behavior must easily customizable, users plan, users
different preferences situations impose different requirements. EA customized
many different ways. VOA algorithms, recommend alerts classify priority level, controlled thresholds repetition parameters, allow alerting behavior
customized user situation. Examples customizable VOA parameters alert
expiration periods described (default 12 minutes) alert suppression intervals (90 seconds
hostile alerts, 120 seconds alerts friendly team members) alerts
type objects suppressed given interval. terms VOA, another
fratricide alert value first 120 seconds user alerted fratricide
risk team member.
Examples customizable VOI parameters out-of-position distance threshold (150 m),
thresholds strength adversarial threats, time threshold schedule alerts (30
seconds). time threshold, example, would smaller tightly coordinated operations,
larger loosely coordinated plans. terms VOI, detecting team member late
significant value tardiness reaches given 30-second threshold. certain missions
plan change threshold, say 10 seconds, indicates information tardiness 10
30 seconds value context missions.
problem avoiding unnecessary repetition similar alerts occurs every type alert.
Schedule deviations become progressively schedule, position deviations become
progressively position, threats move progressively closer become progressively
stronger, fratricide threats persist time. EA must avoid cascading alerts
cases. framework, customizable thresholds often paired either customizable
ratios customizable sequence thresholds, control often repeat alert
mission deviates progressively expectations. Repeated alerts generally lower
VOA given lower priorities.
evaluation showed two types alerts SUO domain pose particular problems
avoiding inundation user. proximity alerts adversarial activity alerts
fratricide risks among team members. developed VOI/VOA algorithms especially
two types alerts.
6.7.1 P ROXIMITY

ALERTS

high volume sensor tracks near friendly units prior battle; would
overwhelm user see alert every change every track. keep threat envelope
friendly unit, consisting tracks close enough pose threat it. Tracks placed zero

243

fiW ILKINS , L EE , & B ERRY

threat envelopes appear move. significant changes strength
aggregate force envelope closeness nearest track causes alert.
6.7.2 F RATRICIDE RISKS
Fratricide one biggest dangers modern battlefield. risk increases range,
lethality, accuracy weapons increase. Increased range increases risk bigger
area every team member must correctly identified. Increased accuracy increases risk
incorrectly targeted team member likely suffer harm. Hopefully, tools like
EA SAIM increase situational awareness greatly reduce frequency incorrect
targeting. Usually, large number friendly entities close proximity, many potential
fratricide situations exist.
EA detects two types fratricide risks: (1) calls fire team members
(which appear messages SAIM), (2) friendly units near (which detected
geolocation data). first case, user issues call fire warned asked
confirmation team members within given threshold target. request confirmed,
SAIM message sent team members, EA entity within target threshold
immediately alerts owner risk planned fire.
second case produces far many alerts simple algorithms used. algorithms
based Armys notion unit boundaries, specified plan. two units
within boundaries, alert issued even within weapons range other.
Fratricide alerts issued one unit another units boundaries within weapons range
unit. handle numerous special cases, two units outside
boundaries within weapons range other. Detection fratricide situations left
future work (e.g., misoriented units within boundary).
6.8 SUO Evaluation
EA evaluated respect usefulness output, frequency unwanted alerts,
real-time performance realistic data streams. SAIM EA tested data
produced high-fidelity military simulator two scenarios. simulator detailed models
type vehicle sensor. One scenario lasted 13.5 hours, last 90 minutes
simulated high fidelity. (The first 12 hours file scripted events, dozen
tracks reports.) second scenario, terrain, simulated 20 minutes.
90-minute simulation 45,000 events passed Watchman SAIM,
13,000 passed EA Manager, monitors squad level (8 10 entities).
simulator run, scripted events also simulate messages team members
running live (such messages confirming mission starts completions). high fidelity
simulation provides realistic data rates inputs, thus providing evidence indicating
EA perform desired real world.
formal evaluation ran live SAIM, simulator, several team members, running copy SAIM EA different physical machines. shorter development
cycle, implemented event generator reproduces SAIM behavior, making SAIM network unnecessary. event generator creates messages files scripted events include
confirmations mission starts completions (that normally would come subordinate
EA), orders aborting current plan executing new plan (that normally would come

244

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

superior EA), sensor tracks location reports (that normally would come SAIM
network). event scripts contain messages captured run included simulator
SAIM.
6.8.1 Q UALITY

ALERTS

Figure 7 presents total number alerts type echelon typical run. Flash
highest four priorities, immediate second highest. Flash alerts generally life
threatening (first contact adversarial entities fratricide), lower-priority alerts
plan threatening.
analyzed evaluated alerts generated first challenging scenario.
Analysis SRI domain experts indicates important situations alerted. Less
10% alerts judged low value issued,
Flash alerts judged. Judging VOA alert subjective: different domain experts
may different alerting preferences, alert new information.
firm data number unwanted alerts would lead performance degradation
typical user (or would cause user shut EA). clear 86% false-alarm rate
found pediatric ICU (Tsien & Fackler, 1997) would acceptable battlefield.
judgment domain experts, rates low-value alerts achieved acceptable.
number alerts Figure 7 reasonable 90-minute interval fast-paced action,
elimination alerts risks missing high-value alert. purposefully erred side
missing alerts.
compared alerts generated EAs operating different echelons (running
different machines SAIM network) simulation. analysis shows
detect threat time tracks, threat relevant
plans. alerts show plan-specific mission-specific behavior expected.
nondeterminism inherent asynchronous agents, alerts always show exact
strength, bearing location threat. Figure 8 shows one example, BN CO alerts near
08:05. time, 2nd PLT, CO moving outside unit boundary specified plan,
hostile force appears north CO moving south. Note EAs issue flash fratricide
alerts 8:05. However, alerts different, specific plan owner EA,
would expect.
plan called Attack-By-Fire mission tracks observed location DP2 (a decision
point hostile activity calls human decision). immediate alert appears
BN EA (because contingent fire mission BN plan) notifies user hostile
entities entered DP2, triggering contingency. AA-Diamond route, defined BN
plan, along adversaries likely approach. second alert notifies BN user (only)
activity route reports number entities detected.
EAs independently identify fratricide risk 8:05, would EAs two platoons
involved. message details two platoons facilitate quick response. Next, BN EA
issues distance alert detecting tracks 450m SE Recon PLT, subordinated
BN earlier plan (so BN EA alerts). tracks closer
earlier first-contact alert issued. Finally, out-of-position alert 07:58 indicates 2 PLT
1 km south route specified move mission. (The 2 PLT EA simultaneously alerts
one subordinate squads position.)

245

fiW ILKINS , L EE , & B ERRY

Number
78
33
3
2
17
5
5
9
36
19
3
1
6
0
3
4
7
6
1
0

Type Alert
Battalion EA - 41 missions
total alerts 13.5 hrs, 26 flash
proximity alerts
schedule alerts
position alerts
avenue approach alerts
triggers contingency alerts
at-monitored alerts
fratricide alerts
CO EA - 11 missions
total alerts 1.5 hrs, 14 flash
proximity alerts
schedule alerts
position alert
avenue approach alerts
triggers contingency alerts
at-monitored alerts
fratricide alerts
3 PLT, CO EA - 6 missions
total alerts 1.5 hrs, 2 flash
proximity alerts
schedule alert
alerts

Figure 7: Number alerts type echelon. number missions echelon
indicates size plan. last 90 minutes 13.5-hour scenario
simulated high fidelity. 78 Battalion alerts, 5 issued last
90 minutes.

6.8.2 P ERFORMANCE
EA Manager must handle 100 simultaneous intentions, determining import
dozen new facts second checking alert histories redundancy. clear
system could still alert user within 5 seconds new fact arriving,
required users. tested EA scenarios determine met requirements.
real time, EA generated alerts less 2 seconds receipt new fact. found
EA keep up, run 10x 20x real time. (There may
anomalous schedule alerts granularity issues high time expansion rates.) Thus, current
data rates close stressing system 10x real time processing average 24
events per second 90-minute simulation, double design requirement dozen
events per second. determine multiple degradation would occur
difficult detect degradation complex system. establish EA, using

246

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

BN EA 0803-0805
DAY 2, 08:04 IMMEDIATE notification:
Red activity DP2 triggers contingency Attack-By-Fire
DAY 2, 08:05 ROUTINE notification:
Enemy activity ave approach AA-Diamond (8 vehicles)
DAY 2, 08:05 FLASH notification:
Fratricide risk 2 Plt, Co moved position near 3 Plt, B
DAY 2, 08:05 IMMEDIATE notification:
Closest threat (tracked) closer- 450m SE Recon PLT
CO EA 0758-0805
DAY 2, 07:58 IMMEDIATE notification:
2 PLT position Move mission GL180837, Line-0003 (1000 m. N 2 PLT)
DAY 2, 08:05 FLASH notification:
Fratricide risk - 2 PLT position near 3-3-B-2-66

Figure 8: BN CO alerts around 0805 Day 2. one CO alert 8:03
8:06, time several BN alerts.

100-meter map granularity, easily sufficient plan monitoring SAIM data rates (running
Sun Ultra 60s Solaris Pentium-based machines Linux).2
Prior implementation EA, performance evaluation P RS determine
could handle input data rates required EA. briefly describe results many
reactive control systems based P RS, e.g., UM-PRS (Durfee et al., 1997). found
could handle 12 facts per second without unacceptably long delays, using randomly
generated facts two predicates fact invoked trivial processing (incrementing
counter). determined effects combinatorial P RS algorithms could avoided
batching new facts time control loop. modified control loop so,
performance improved remarkably. test case 2,000 facts posted 1 second, reduced
time respond first (any) fact 84%, reduced time respond facts 72%,
reduced memory usage 83%. Experiments showed fact batch size near 55 optimal
reducing response time, value roughly 25 100 near optimal.
6.8.3 L IMITATIONS
EA limited modeled, low fidelity models heuristics,
scenario-specific population knowledge base. many aspects plan execution
currently monitor, although monitoring framework easily extended
aspects plans modeled. selected capabilities mostly function available
input data available funding modeling. EA monitor much broader range plans
used scenarios. fact, monitor plan composed partial order
defined missions team members.
2. performance data Sun Ultra 60 Solaris. product company names mentioned
document trademarks respective holders.

247

fiW ILKINS , L EE , & B ERRY

7. Monitoring Robot Teams
using team robots cooperatively track pursue enemy entities detected. Unmanned air vehicles (UAVs) unmanned combat air vehicles (UCAVs) growing
research interest (Musliner, Durfee, & Shin, 1993), led availability cheaper platforms
easier use. SRI UV-robotics project focuses building system carry mission
objective using team UGVs UAVs. UGV UAV autonomous agent
view world, onboard reasoning capabilities, set resources (such power,
computation, unique set sensors). mission, may limited opportunity
communicate human controller. Therefore, agents must rely one another complete mission. research concentrates providing reactive regulation low-level sensor
systems vehicle controllers attain high-level mission goals, reacting unforeseen
circumstances taking advantage evolving situation.
UV-robotics domain resembles SUO domain requires rapid assessment
operational situation, determination viability existing plans control policies,
modification goals objectives based findings available resources.
Unlike SUO domain, decisions made (automated) agents
agents must negotiate solutions cooperative fashion. One challenges UVs (or
physically mobile agent) need reactive system. Perception of, knowledge about,
events actions physical world generally imprecise. perform tasks reliably
repeatedly requires dynamic monitoring.
SUO EA filters alerts avoid overloading human decision maker, must also
filter alerts autonomous agent avoid overloading computational resources. Resources
always limited, particularly mobile platform, balance must struck usefulness
resources used. good example balance computational resources available
onboard robots. infinite number CPU cycles, would able generate large
numbers contingency plans evaluate simulation. However, 20%
CPU available robot control monitoring. Therefore, make design decisions
limit complexity control monitoring algorithms, possibly leaving extension
hooks anticipation greater processing power future.
7.1 UV-Robotics: Problem Description
long-term goal build, test validate architecture agent support multiple
goals dynamic environment cooperative mobile agents. Initial tasks teams include
surveillance reconnaissance, search destroy, pursuit, evasion. team robots would
expected perform tasks minimal supervision. Key components architecture
identified negotiation, strategic planning, execution tasking control, execution monitoring, recovery failure. challenge several robots working together
understand effects actions common team goals.
One challenge agent may working toward multiple, possibly conflicting, goals.
Thus, agent must constantly evaluating commitment actions, tasks, contribute
satisfaction goals. imprecision action sensory input taken
account, contribution toward satisfaction current goals plans assessed. addition,
user must kept informed progress team toward goals. user
want actively involved robot control, must able intervene necessary. Thus,
248

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

monitoring must ensure robust autonomous operation provide user window
operation team.
7.2 UV-Robotics: Architecture
SRI UV robot architecture based several years research SRI intelligent reactive
control, planning, negotiation, robot motion control (Wilkins & Myers, 1995; Myers, 1996;
Wilkins & Myers, 1998; Cheyer & Martin, 2001; Konolige & Myers, 1998). similar systems
like SAFER (Holness, Karuppiah, & Ravela, 2001) SRTA (Vincent, Horling, Lesser, & Wagner,
2001) ability deal multiple goals evaluate discard goals. Figure 9
shows Multi-Level Agent Adaptation (MLAA) architecture. Clearly, monitoring pervasive
serves layer architecture well user (not shown).
Agents
Uses
Coordination

Policy Maker
Update/Ask Achievable

Query

Uses

Uses

Strategic Planner

TEAM
LEVEL
STRATEGIC
LEVEL

Update
Update

Resource Mgr.

EA Watchman
Insert Goal
Update

Query

EA Plan Initializer
EA Plan Manager

Update

TACTICAL
LEVEL
(PRS)

Process
Query

Task Blender
Primitive Action
Executor

Update

CONTROL
LEVEL

Low-level Actions

Figure 9: Multi-level Agent Adaptation Architecture.
coordination module receives goal requests human commander agents.
agent participates negotiation process determine role achieving goal.
negotiation, agent consults strategic planner create plan, plan segment (referred
recipe), assess recipes viability given current commitments. negotiation process
results goal recipe accepted, EA Manager (see Figure 3) instantiates
recipe initiates execution. Plan Initializer also creates monitoring sentinels use
EA detect deviation recipe execution. execution recipe involves
activation tasks must blended active tasks maximize satisfaction
multiple goals. example, robot needs reach waypoint set time, take picture
location nearby, also remain concealed, task blender modifies path planner runtime

249

fiW ILKINS , L EE , & B ERRY

achieve three tasks. Finally, lowest layer architecture interface
tasking architecture physical, simulated, robot controller.
monitoring Figure 9 done UV EA, created using architecture
representations SUO EA. modular design SUO EA made adaptation
straightforward. architecture internal EA agents depicted Figure 3 used little
modification, plan representation techniques monitoring plans, applying
VOI VOA calculations, issuing alerts. implementation initial UV EA (using code
SUO EA) done one person-week, impressive result given complexity
task. implementation included connecting new data sources, parsing messages,
determining implementing valuable monitoring algorithms, integrating plans
missions already defined, writing domain-specific VOI/VOA algorithms. Achieving
missions requires recalculating waypoints least every second using 20% CPU,
trade speed complexity waypoint calculation monitoring.
initial version UV EA detected first five types alerts listed Section 7.4.
7.3 UV-Robotics: Execution Monitoring Issues
initial monitoring issues apparent within UV-Robotics domain divided following four categories:
Monitoring completion of, progress toward, basic action (e.g., go waypoint)
Monitoring satisfaction completion multiple tasks robot currently
committed (e.g., pursue evader, patrol area, photograph target every 2 hours)
Monitoring activity unknown adversarial entities
Monitoring state communication network, robot, team members (e.g.,
communication network quality integrity, robot mobility, battery level)
Comparing ontology Section 4, first two categories involve general alert
types plan constraint violated constraint violation projected. However, exist different
levels abstraction often different temporal impact associated monitoring requirements. third category cleanly fits adversarial activity detected alert type triggers alerts
autonomous control user reporting. fourth category essential team-based
automated operation effective user interaction, involves policy constraint violated alerts,
reporting requirement alerts, system problem detected alerts.
7.4 UV-Robotics Execution Assistant
Like SUO EA, robot controller uses rich plan representation allow team members
share context communicate user. Primitive actions domain basic motion control communication requests physical robot. goal request user decomposed
individual agent plans (recipes) intentions aid interact agents. Recipes
composed partially ordered sequences tasks turn evolve primitive actions.
UV EA uses internal architecture similar SUO EA, shown Figure 3.
SUO EA, EA Manager continually applies Acts respond new goals facts posted

250

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

database. Acts correspond algorithms monitoring requirements layer
MLAA architecture. implement user alerts others implement autonomous control.
inputs UV EA plans execute, policy declarations, status reports (including
location, speed orientation) sensor suite, messages agents.
messages include status reports agents, reports mission success failure, shared information, requests help. Depending communication conditions policy restrictions,
agent may, may not, receive team members status reports (up-to-date locations)
friendly agents entities within visual range. Sentinels extracted plans policy
declarations, evaluated status reports received, may produce alerts. alerts
produced designed serve autonomous control via plan manager component,
user, although needs vary considerably.
initial experimentation, monitoring alerts derived regular state messages
team member. state message reports current location, velocity, attitude, sensor
imprecision agent. UV-Robotics Act similar SUO Act Figure 5 invoked every
time location report posted EA Manager database. postings happen several times
second, robot receives two messages every second sensors
two team member, based network conditions. also receives similar state messages
entities within field vision. means team three robots agent
handling minimum least six state messages per second possibly many depending
environment. Also, messages agents sharing information,
currently considering except update state knowledge adversarial entities.
future, UV EA extended serve higher layers architecture
common SUO-EA alert types triggers.
initial implementation UV EA detects following types alerts. plan
implement additional monitoring project.
At-goal robot current waypoint
Stuck robot stuck current waypoint
Divergent robot diverging current waypoint
No-status robot longer reporting state
Target-visible robot target within sensor range
Lost-target robot lost track target pursue mission
Target-gone target moved assigned sector pursue mission
Collision robot anticipates hit nearby object next seconds
Handoff robot delegated/accepted task to/from another team member
UV EA uses techniques SUO EA (Section 6.7) estimating VOA
greatly reducing number low-value alerts. particular, UV EA keeps event histories
team member monitored. histories used determine value information
alerts, detect Stuck, Divergent, No-status alerts. example, history indicates
251

fiW ILKINS , L EE , & B ERRY

time robot location last progress check, current waypoint changed
robot away waypoint, value issuing Divergent alert
calculated.
value issuing alert takes consideration customizable latency thresholds repetition parameters, associated automated agent user.
agent parameters customized improve performance, others function behavior robot. example, value divergent alert function expected
velocity agent, agent traveling speed diverge quickly slow
agent. Similarly, change orientation influence value alert turning agent,
decreasing distance waypoint, may indeed making progress toward goal.
example monitoring used facilitate autonomous control illustrated
situation agent patrolling designated area. evader becomes visible, agent
receives Target-visible alert, type adversarial activity detected. Reacting either
high-priority policy pursue evaders explicit plan step, agent commits new goal
Pursue named-evader. goal achieved activation blending three tasks: Follow
named-evader, Relocate named-evader Search-for named-evader. Thus, robot maintain
pursuit even evader slips field vision.
users preferred strategy might report first sighting evader track
position, noting whenever disappears view. However, autonomous control requires notification likelihood recovering visual contact deteriorating robot searching
aimlessly. point, Target-Lost alert, type plan constraint violated, sent
agents EA Manager (and possibly user). example, policy exists reacting
type alert. cause pursuit goal dropped original Patrol plan resumed.
7.5 UV-Robotics: Evaluation
UV EA evaluated within SRI experimental framework called SRI Augmented
Reaility Simulator (SARS) (Ortiz et al., 2002). framework allows autonomous agent architecture software tested within entirely simulated environment, team physical
robots, mixture two. physical robots three pioneer robots equipped
GPS, shown Figure 10. Initial experiments carried simulated environment.
ran system entirely physical world team two cooperating robots searching
pursuing two independent evader robots. also run environments composed
combination physical robots simulated entities illustrate scalability operation
UAVs. monitoring technology effective ensuring robust execution environments,
giving human operators insight state activity robot. insight facilitated debugging process moving simulated world physical robots
problems quickly identified.
SARS specifically designed simulate robots UAVs. produces output terms
sensors, actuators, resources (battery status, communication range, forth). SARS
computation simulation based precise 3D model environment. SARS precise
enough mix physical robots moving real world virtual evaders see
physical robots following virtual evader thus, name augmented reality. Using SARS,
able simulate team UGVs moving and/or UAVs flying larger space
available. team UAVs may larger available physical UAVs, well.

252

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Figure 10: SRI experimental Pioneer UGV.
initial UV EA implementation evaluated respect usefulness output,
value alerts, real-time performance realistic data streams. analysis shows
important situations alerted simulated executions, tests actual robots,
never exactly reproducible.
No-status alerts proven useful human user, indicate hardware software
problem robot network. problems recognized immediately (after customizable interval noncommunication passed) UV EA, take considerably longer
detect without alerts EA. customizable threshold (which currently defaults 5 seconds)
determines value alert robot reported state certain interval.
At-goal, Stuck, Divergent essential alerts autonomous-control agent-navigation
system, well useful human user wants monitor activity single
robot. Knowing robot reached goal point, stopped making
progress toward goal point, diverging planned route essential robust
autonomous operation. Customizable intervals also control alerts. Subtleties domain
must considered avoid false alarms. example, robot may paused GPS
uncertainty GPS given time establish connection satellites. Also, robot
takes time turn thus regarded stuck divergent turns steering
adjustments time complete.
Target-visible, Target-lost, Handoff useful user autonomous controller, particularly task monitor pursue target. autonomous controller
requires immediate awareness loss sensor contact, adjust lower-level behavior
sensor parameters find evader. However, immediate alerts would unproductive
human user plan-level controller. customizable interval gives agent time relocate

253

fiW ILKINS , L EE , & B ERRY

evader, possibly avoiding alert human. types alerts time critical
evaluation domain.
Good tracking evader requires recalculating waypoints orientation least every second. UV EA able keep data inputs, detect occurrences types alerts
mentioned within 1 second, recalculate waypoint orientation twice per second. constraints difficult meet desktop machines, success UV EA
slower processors physical robot involved tradeoffs speed complexity waypoint
calculation monitoring. One useful technique using latest state report agent
one state report accumulated one cycle monitoring loop.
relative CPU access various agents processes also became important. example,
adjust time quantum given scheduler EA processes ensure
process receiving messages various P RS agent processes EA executed frequently
enough waypoint recalculation. problem alleviated recent upgrades
onboard computer, could recur computationally expensive projections alerts
added EA.

8. Related Work
Plan generation received lot attention recently, rarely plans used control
monitor execution. Even rarely plans monitored involve activity hundreds
agents requiring tight coordination. Previous work execution monitoring focused
models executor performs planned actions (e.g., robot controller) usually
direct access internal state information. SUO domain, actions performed
external agents, usually humans, monitor access state executing agents.
indirect execution requires different monitoring techniques, executor must use incoming
messages determine status agents activities whether actions initiated
completed. Continuous Planning Execution Framework (Myers, 1999) addressed
indirect execution problem, system builds ideas. However, domain requires
monitoring many constraints greater time sensitivity. much higher rates
incoming data, must customize monitoring action generate appropriate, high-value
alerts.
Robot designers often avoided plan representations used AI plan-generation
community restrictive assumptions (Pollack & McCarthy, 1999; Arkin, 1998).
domains required expressive plan representation, combination Act formalism
hierarchical, object-oriented mission model proved sufficiently expressive, providing rich
set goal modalities encoding activity, including notions achievement, maintenance, testing,
conclusion, waiting.
SAM system (Kaminka & Tambe, 1999) ISI addresses similar problem: automated
pilot agents battlefield. SAM direct access local automated agent much lower
incoming data rates EA. addresses difficult problem plan recognition (of plans
friendly agents). humans involved, SAM need produce alerts
tailored human cognitive capabilities. Experiments SAM showed distributed monitoring
outperformed centralized monitoring using simpler algorithms. EAs SAIM use
distributed design, building insights.

254

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

recent work ISI produced monitoring agent named OVERSEER (Kaminka et al.,
2001), also addresses problem similar ours: many geographically distributed team members coordinating plan dynamic environment. address problem modeling value
information user. OVERSEER use report-based monitoring approach adopted
EAs, must rely unmodifiable legacy agents sufficient bandwidth reliability communication. detailed analysis given Section 3.
NASAs Remote Agent Deep Space One (Jonsson et al., 2000; Muscettola et al., 1998)
autonomous execution monitoring spacecraft. domains many requirements NASAs, including core requirements concurrent temporal processes interacting
recoveries. However, NASAs remote agent fully automated, places heavier burden
module generates plans responses, alleviates burden address human
interaction issues considered VOA. Monitoring algorithms described detail, based procedural executive, assume similar procedural reactive
control system. NASAs domain, agents mechanical devices onboard spacecraft,
behaviors formally modeled. agents include humans, whose behaviors
easily modeled, EAs estimate value alerts interact human decision
maker, ultimately responsible control decisions.
Work rationale-based monitoring (Pollack & McCarthy, 1999; Veloso, Pollack, & Cox, 1998)
addressed problem monitoring world plan generation process (in causal-link
planners) see events invalidate plan generated. monitor subgoals, preconditions,
usability conditions, user preferences. monitored framework plans
executed, EAs additional capabilities, monitoring policy constraints applying mission-specific monitoring methods. rationale-based work address time-critical
monitoring execution time, monitoring large volumes incoming data, problem
alerting users without overwhelming them.
Doyle (1995) describes technique focus users attention anomalous system behavior,
particularly sensor behavior. work would applicable within lowest layer robotics
control module. uses causal modeling understand normal behavior sensor. Anomaly
detection based measures causal distance distance normal behavior. distance
measures related plan goals/actions; instead measure deviation typical behavior. user still relate reported sensor anomaly higher-level effects,
threat plan action execution. work provides monitoring technique specific sensor system types could easily incorporated monitoring framework. resulting
anomaly detection might give low-level alerts contributory factor reasoning process
higher-level alert classes.
Phoenix system uses concept plan envelope (Hart, Anderson, & Cohen, 1990)
represent priori expectations actions progress. Envelopes used action
executes time interrupted altered execution. envelope captures
range possible performance action successful execution. execution,
actual performance system recorded and, deviates predefined envelope,
possible failure detected. concept provides useful monitoring technique specific alerttypes, particularly concerning actions consume variable amount resources time.
Envelopes also identify action performing better required allowing opportunistic alerts. Envelopes could easily incorporated monitoring framework additional
monitoring technique, could useful higher levels domains.
255

fiW ILKINS , L EE , & B ERRY

SUO EA provides capability currently exist, machineunderstandable representation plan battlefield. Currently, small-unit warfighters must
monitor incoming information relevance, manual notification team members.
SUO EA also improves next-generation Army systems FBCB2 (Force XXI Battle
Command Brigade Below) (Garamone, 2001). Unlike FBCB2, EA alerts important
changes, automatically update areas monitored plan executed, dynamically change force structure, alert user many issues monitored
systems, fratricide risks, triggering contingencies, schedule, coordination
positional deviations plan.

9. Conclusions
characterized domain-independent challenges posed execution aid interactively
supports humans monitoring activity distributed teams cooperating agents, human
machine. important issues interactive monitoring adaptivity, plan- situationspecific monitoring, reactivity, high-value, user-appropriate alerts. showed properties
various domains influence challenges solutions. presented top-level
domain-independent categorization types alerts plan-based monitoring system might
issue user. different monitoring techniques generally required category often
domain specific task specific.
monitoring framework integrates various techniques uses concept
value alert control interaction user. conceptual framework facilitates integration new monitoring techniques provides domain-independent context future discussions monitoring systems. discussed various design tradeoffs must made
application monitoring framework domain (Sections 6.4 6.6).
use framework describe monitoring approach developed used implement Execution Assistants (EAs) two different dynamic, data-rich, real-world domains.
approach based rich plan representations, allow execution aid filter, interpret,
react large volume incoming information, alert user appropriately. expressive plan representation necessary representing SUO plans, must coordinate distributed
units, trigger contingencies, enforce variety constraints. equally important
representation monitorable machines meaningful humans. plan representation
mission model able model representative SUO scenario enough fidelity provide value (as judged domain experts) also sufficient plans UV-Robotics
domain.
developed sufficiently rich plan representation extending existing plan representation
hierarchical, object-oriented mission model encodes knowledge primitive actions
mission-specific monitoring methods. SUO EA implements novel integration
hierarchical monitoring methods reactive control system. EA invokes specific
methods defined hierarchy appropriate points monitoring.
One central challenge, domains well medical monitoring, avoid overwhelming
user unwanted alerts and/or false alarms. define concepts value information
value giving alert principles determining give alert. describe
properties VOI VOA, criteria computing them, advantages qualitative reasoning

256

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

domains, successful use concepts applications. VOI VOA algorithms
must customizable user, plan, situation.
using asynchronous multiagent architecture extended version P RS reactive
control system, monitored execution SUO UV-Robotics plans acceptable
latency, given dozen incoming events per second. P RS extensions include temporal monitors efficiency improvements. Methods mission model used throughout SUO
monitoring process action-specific monitoring. evaluation showed plan-aware EAs
generated appropriate alerts timely manner without overwhelming user many alerts,
although small percentage alerts unwanted. shown utility using advanced AI planning execution technologies small unit operations.
application UV-Robotics showed generality SUO framework monitoring
concepts. implemented complex execution assistant one person-week, using code
SUO EA. UV EA uses plan representation basic architecture SUO
EA, inputs different tasks algorithms respond inputs
generate alerts.
Future work. obvious area future work SUO domain incorporation
planning assistant complete loop continuous planning execution. integration
already accomplished UV-Robotics domain, difficulty SUO domain
interface allows soldier interact effectively planning tool, using wearable
computer battlefield situation. Several research programs addressing problem,
mentioned Section 2.
Within scope execution monitoring, future work EAs could model detect
types plan deviations (such loss surprise additional types fratricide risks), project
future failures, provide higher-fidelity specialized reasoners, particularly terrain reasoning.
Additional theoretical work VOI VOA would support better quantitative estimates VOI
VOA. SUO mission model already method projecting failures low-fidelity
projection capability could easily added. UV-Robotics domain, plan implement
additional types alerts near future, extend UV EA serve higher layers
architecture common SUO EA alert types triggers. fragility
UV communication network hostile domains provides set interesting monitoring challenges may result incorporation specific monitoring-related tasks within cooperative
team missions. Monitoring strategies uncertain communication environments important
research challenge UV-Robotics domain. Additional alerts considered future implementation include monitoring movement entities geographical sectors mentioned
plan, monitoring deterioration improvement communication conditions, monitoring actions intentions coordinating team members facilitate cooperative behavior.

257

fiW ILKINS , L EE , & B ERRY

ACKNOWLEDGMENTS
SUO research supported Contract F30602-95-C-0235 Defense Advanced Research Projects Agency (from DARPA Planning Decision Aids Program DARPA
Small Unit Operations Program), supervision Air Force Research Laboratory Rome.
UCAV research supported Office Naval Research Unmanned Combat Air Vehicles Program (Contract N00014-00-C-0304). SRI International Artificial Intelligence Center
supported writing paper. thank subject matter experts assisted us. primary collaborators evaluators Kenneth Sharpe SAIC Richard Diehl Institute
Defense Analyses. also used expertise Andy Fowles, Chris Kearns, David Miller
U.S. Army Dismounted Battlespace Battle Laboratory (DBBL) Fort Benning, CPT
Dan Ray Mounted Maneuver Battlespace Laboratory (MMBL) Fort Knox.

References
Arkin, R. (1998). Behavior-based robotics. MIT Press.
Ash, D., Gold, G., Seiver, A., & Hayes-Roth, B. (1993). Guaranteeing real-time response
limited resources. Artificial Intelligence Medicine, 5(1), 4966.
Athey, S., & Levin, J. (2001). value information monotone decision problems. Tech. rep.,
Stanford University, Stanford, CA.
Bell, B., Jr., E. S., & Brown, S. M. (2002). Making adversary decision modeling tractable intent
inference information fusion. Proc. 11th Conference Computer Generated
Forces Behavioral Representation, Orlando, FL.
Bonasso, R. P., Kortenkamp, D., & Whitney, T. (1997). Using robot control architecture automate space shuttle operations. Proc. 1997 National Conference Artificial Intelligence, pp. 949956, Providence, RI. AAAI Press.
Cheyer, A., & Martin, D. (2001). open agent architecture. Journal Autonomous Agents
Multi-Agent Systems, 4(1), 143148.
Coiera, E. (1993). Intelligent monitoring control dynamic physiological systems. Artificial
Intelligence Medicine, 5(1), 18.
Donlon, J., & Forbus, K. (1999). Using geographic information system qualitative spatial
reasoning trafficability. Proc. Qualitative Reasoning Workshop, Loch Awe,
Scotland.
Doyle, R. J. (1995). Determining loci anomalies using minimal causal models. Proc.
1995 International Joint Conference Artificial Intelligence, pp. 18211827, Montreal,
Quebec, Canada. Morgan Kaufmann Publishers Inc., San Francisco, CA.
Durfee, E. H., Huber, M. J., Kurnow, M., & Lee, J. (1997). TAIPE: Tactical assistants interaction
planning execution. Proc. Autonomous Agents 97. ACM Press, New York.
Ferguson, G., & Allen, J. (1998). TRIPS: integrated intelligent problem-solving assistant.
Proc. 1998 National Conference Artificial Intelligence, pp. 567572. AAAI Press.
Forbus, K. D. (2002). Towards Qualitative Modeling Battlespace. Technical report unpublished manuscript, Northwestern University, Evanston, IL.
258

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Franke, J., Brown, S. M., Bell, B., & Mendenhall, H. (2000). Enhancing teamwork teamlevel intent inference. Proc. 2000 International Conference Artificial Intelligence,
Las Vegas, NV.
Garamone, J. (2001). Digital world meets combat desert exercise. Tech. rep., American
Forces Information Service, www.defenselink.mil/news/Apr2001/.
Georgeff, M. P., & Ingrand, F. F. (1989). Decision-making embedded reasoning system.
Proc. 1989 International Joint Conference AI, pp. 972978, Detroit, MI. Morgan
Kaufmann Publishers Inc., San Francisco, CA.
Gil, Y., & Blythe, J. (1999). problem-solving method plan evaluation critiquing. Proc.
Tenth Banff Knowledge Acquisition Knowledge-Based Systems Workshop, Banff,
Alberta, Canada.
Grosz, B., & Kraus, S. (1999). evolution SharedPlans. Rao, A., & Wooldridge, M. (Eds.),
Foundations Theories Rational Agencies, pp. 227262.
Hart, D. M., Anderson, S. D., & Cohen, P. R. (1990). Envelopes vehicle improving
efficiency plan execution. Tech. rep. UM-CS-1990-021, University Massachusetts,
Amherst, MA.
Holness, G., Karuppiah, D.and Uppala, S., & Ravela, S. C. (2001). service paradigm reconfigurable agents. Proc. 2nd Workshop Infrastructure Agents, MAS, Scalable
MAS (Agents 2001), Montreal, Canada.
Horty, J., & Pollack, M. (2001). Evaluating new options context existing plans. Artificial
Intelligence, 127(2), 199220.
Jonsson, A., Morris, P., Muscettola, N., & Rajan, K. (2000). Planning interplanetary space:
Theory practice. Proc. 2000 International Conference AI Planning
Scheduling, pp. 177186, Breckenridge, CO. AAAI Press, Menlo Park, CA.
Kaminka, G., Pynadath, D., & Tambe, M. (2001). Monitoring deployed agent teams. Proc.
Autonomous Agents 01, pp. 308315, Montreal, Canada.
Kaminka, G., & Tambe, M. (1999). Experiments distributed centralized socially attentive
monitoring. Proc. Autonomous Agents 99, pp. 213220, Seattle, WA.
Konolige, K., & Myers, K. (1998). Artificial Intelligence Based Mobile Robots: Case studies
Successful Robot Systems, chap. Saphira architecture: design autonomy. MIT Press.
Koski, E., Makivirta, A., Sukuvaara, T., & Kari, A. (1990). Frequency reliability alarms
monitoring cardiac postoperative patients. International Journal Clinical Monitoring
Computing, 7, 129133.
Mouaddib, A.-I., & Zilberstein, S. (1995). Knowledge-based anytime computation. Proc.
1995 International Joint Conference Artificial Intelligence, pp. 775783. Morgan Kaufmann Publishers Inc., San Francisco, CA.
Muscettola, N., Nayak, P. P., Pell, B., & Williams, B. C. (1998). Remote agent: boldly go
AI system gone before. Artificial Intelligence, 103(1-2), 547.
Musliner, D. J., Durfee, E. H., & Shin, K. G. (1993). CIRCA: cooperative intelligent real-time
control architecture. IEEE Transactions Systems, Man, Cybernetics, 23(6).
259

fiW ILKINS , L EE , & B ERRY

Myers, K. L. (1996). procedural knowledge approach task-level control. Proc. 1996
International Conference AI Planning Systems. AAAI Press, Menlo Park, CA.
Myers, K. L., & Morley, D. N. (2001). Human directability agents. Proc. 1st International
Conference Knowledge Capture, Victoria, B.C.
Myers, K. L. (1999). CPEF: continuous planning execution framework. AI Magazine, 20,
6370.
Ortiz, C., Agno, A., Berry, P., & Vincent, R. (2002). Multilevel adaptation teams unmanned
air ground vehicles. First AIAA Unmanned Aerospace Vehicles, Systems, Technologies
Operations Conference.
Ortiz, C. L. (1999). Introspective elaborative processes rational agents. Annals Mathematics Artificial Intelligence, 25(12), 134.
Ortiz, C. L., & Hsu, E. (2002). Structured negotiation. Proc. First International Conference
Autonomous Agents Multiagent Systems.
Pollack, M. E., & McCarthy, C. (1999). Towards focused plan monitoring: technique
application mobile robots. Proc. IEEE International Symposium Computational
Intelligence Robotics Automation (CIRA), pp. 144149.
Rao, A. S., & Georgeff, M. P. (1995). BDI-agents: theory practice. Proc. First
Intl. Conference Multiagent Systems, San Francisco.
Schreckenghost, D., & et al. (2001). Adjustable control autonomy anomaly response spacebased life support systems. Proc. IJCAI Workshop Autonomy, Delegation,
Control.
Shannon, C. (1948). mathematical theory communication. Bell System Technical Journal, 27,
379423, 623656.
Tsien, C. (1997). Reducing false alarms intensive care unit: systematic comparison four
algorithms. Proc. American Medical Informatics Association Annual Fall Symposium.
Tsien, C., & Fackler, J. (1997). Poor prognosis existing monitors intensive care unit.
Critical Care Medicine, 25(4), 614619.
Veloso, M., Pollack, M., & Cox, M. (1998). Rationale-based monitoring planning dynamic
environments. Proc. 1998 International Conference AI Planning Systems, pp.
171180. AAAI Press, Menlo Park, CA.
Vincent, R., Horling, B., Lesser, V., & Wagner, T. (2001). Implementing soft real-time agent control.
Proceedings 5th International Conference Autonomous Agents. ACM Press.
Weigner, M. B., & Englund, C. E. (1990). Ergonomic human factors affecting anesthetic vigilance monitoring performance operating room environment. Anesthesiology, 73(5),
9951021.
Weinberger, E. (2002). theory pragmatic information application quasispecies
model biological evolution. Biosystems, 66(3), 105119.
Wilkins, D. E., & desJardins, M. (2001). call knowledge-based planning. AI Magazine, 22(1),
99115.
260

fiI NTERACTIVE E XECUTION ONITORING AGENT EAMS

Wilkins, D. E., & Myers, K. L. (1995). common knowledge representation plan generation
reactive execution. Journal Logic Computation, 5(6), 731761.
Wilkins, D. E., & Myers, K. L. (1998). multiagent planning architecture. Proc. 1998
International Conference AI Planning Systems, pp. 154162, Pittsburgh, PA.
Wilkins, D. E., Myers, K. L., Lowrance, J. D., & Wesley, L. P. (1995). Planning reacting
uncertain dynamic environments. Journal Experimental Theoretical AI, 7(1),
121152.

261

fiJournal Artificial Intelligence Research 18 (2003) 491-516

Submitted 11/02; published 6/03

Acquiring Correct Knowledge
Natural Language Generation
Ehud Reiter
Somayajulu G. Sripada

ereiter@csd.abdn.ac.uk
ssripada@csd.abdn.ac.uk

Department Computing Science,
University Aberdeen, Aberdeen AB24 3UE, UK

Roma Robertson

roma.robertson@ed.ac.uk

Division Community Health Sciences - General Practice Section
University Edinburgh
Edinburgh EH8 9DX, UK

Abstract
Natural language generation (nlg) systems computer software systems produce texts English human languages, often non-linguistic input data.
nlg systems, like ai systems, need substantial amounts knowledge. However,
experience two nlg projects suggests difficult acquire correct knowledge
nlg systems; indeed, every knowledge acquisition (ka) technique tried significant problems. general terms, problems due complexity, novelty,
poorly understood nature tasks systems attempted, worsened
fact people write differently. meant particular corpus-based ka
approaches suffered impossible assemble sizable corpus high-quality
consistent manually written texts domains; structured expert-oriented ka techniques suffered experts disagreed could get enough information
special unusual cases build robust systems. believe problems
likely affect many nlg systems well. long term, hope new
ka techniques may emerge help nlg system builders. shorter term, believe
understanding individual ka techniques fail, using mixture different
ka techniques different strengths weaknesses, help developers acquire nlg
knowledge mostly correct.

1. Introduction
Natural language generation (nlg) systems use artificial intelligence (ai) natural language processing techniques automatically generate texts English human
languages, typically non-linguistic input data (Reiter & Dale, 2000).
ai systems, essential part building nlg system knowledge acquisition (ka),
acquiring relevant knowledge domain, users, language used
texts, forth.
ka nlg based structured expert-oriented techniques, think-aloud
protocols sorting, machine learning corpus analysis, currently
popular areas Natural Language Processing. used types techniques two nlg projects included significant ka efforts stop (Reiter, Robertson, &
Osman, 2003), generated tailored smoking cessation letters, SumTime-Mousam
c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiReiter, Sripada, & Robertson

(Sripada, Reiter, Hunter, Yu, & Davy, 2001), generated weather forecasts.
projects, techniques tried, main problem turned knowledge quality;
evaluation validation exercises identified flaws knowledge acquired using every
technique. flaws due variety factors, perhaps basic underlying
reason nature writing tasks attempting automate.
were:
complex (as many tasks involve interacting humans): hence lot
knowledge needed cover numerous special cases unusual circumstances;
sometimes novel (not done humans): hence sometimes experts
task whole, existing corpora texts analyse;
poorly understood: hence good theoretical models structure
knowledge acquired, fill gaps knowledge acquired experts
corpora;
ambiguous (allowed multiple solutions): hence different experts corpus authors
produced different texts (solutions) input data.
problems course occur degree ka expert system natural
language processing tasks, believe may especially severe nlg.
good solution problems, indeed believe ka one
biggest problems applied nlg. all, point using ai techniques
build text-generation system cannot acquire knowledge needed ai
techniques.
longer term, basic research ka nlg badly needed. shorter
term, however, believe developers likely acquire correct knowledge
building nlg system understand likely types errors knowledge
acquired different ka techniques. Also, degree different ka techniques
tried complementary strengths weaknesses; suggests using variety
different techniques, weaknesses one technique compensated
strengths techniques.
remainder paper give background information nlg, ka,
systems; describe various ka techniques used build systems problems
encountered; discuss generally ka nlg difficult
different ka techniques combined.

2. Background
section give background information natural language generation
knowledge acquistion validation. also introduce briefly describe stop
SumTime-Mousam systems.

492

fiAcquiring Correct Knowledge NLG

2.1 Natural Language Generation
Natural Language Generation subfield artificial intelligence concerned
automatically generating written texts human languages, often non-linguistic input
data. nlg systems often three stages (Reiter & Dale, 2000):
Document Planning decides content structure generated text;
example smoking-cessation letter start section discusses
pros cons smoking.
Microplanning decides information structure expressed linguistically; example, phrase mid afternoon used weather
report refer time 1500.
Surface Realisation generates actual text according decisions made previous stages, ensuring text conforms grammar target language
(English systems).
nlg systems require many types knowledge order carry tasks. particular, Kittredge, Korelsky, Rambow (1991) point nlg systems need domain
knowledge (similar needed expert systems), communication knowledge (similar
needed Natural Language Processing systems), also domain communication knowledge (DCK). DCK knowledge information domain usually
communicated, including standard document structures, sublanguage grammars, specialised lexicons. DCK plays role aspects language technology (for example,
speech recogniser work better given domain trained corpus texts
domain), may especially important nlg.
2.2 Knowledge Acquisition Validation
Knowledge acquisition subfield artificial intelligence concerned acquiring knowledge needed build ai systems. Broadly speaking two common
types ka techniques are:
Techniques based working experts structured fashion, structured interviews, think-aloud protocols, sorting, laddered grids (Scott, Clayton,
& Gibson, 1991; Buchanan & Wilkins, 1993);
Techniques based learning data sets correct solutions (such text corpora);
currently popular natural language processing used many
different types knowledge, ranging grammar rules discourse models (for
overview, see Jurafsky & Martin, 2000).
course possible ka techniques well, including directly asking experts
knowledge, conducting scientific experiments. research done
evaluating comparing ka techniques, research difficult interpret
methodological problems (Shadbolt, OHara, & Crow, 1999).
Research also done verifying validating knowledge check
correct (Adelman & Riedel, 1997). Verification techniques focus detecting logical
493

fiReiter, Sripada, & Robertson

anomalies inconsistencies often reflect mistakes elicitation coding process;
discuss these, errors primary concern paper.
Validation techniques focus detecting whether knowledge acquired indeed correct
enable construction good system; relevant efforts
detect problems knowledge acquired nlg. Adelman Riedel (1997) describe two
general types validation techniques: (1) experts check acquired knowledge
built systems, (2) using library test cases known inputs outputs.
words, knowledge acquired experts data sets correct solutions,
knowledge also validated experts data sets correct solutions. Knowledge
also validated experimentally, determining system whole works
intended effect users. course care must taken validation process
uses different resources acquisition process. example, knowledge acquired
expert validated expert, knowledge learned data set
validated data set.
great deal previous research knowledge acquisition nlg;
Reiter, Robertson, Osman (2000) summarise previous efforts area. Generally
corpus analysis (analysis collections manually written texts) popular
ka technique nlg, areas Natural Language Processing, although sometimes
supplemented expert-oriented techniques (Goldberg, Driedger, & Kittredge, 1994;
McKeown, Kukich, & Shaw, 1994). Walker, Rambow, Rogati (2002) attempted
learn nlg rules user ratings generated texts, perhaps considered
type experiment-based ka.
2.3 STOP
stop (Reiter, Robertson, & Osman, 2003) nlg system generates tailored smokingcessation letters. Tailoring based 4-page multiple-choice questionnaire
smokers habits, health, concerns, forth. extract questionnaire shown
Figure 1, extract stop letter generated questionnaire shown
Figure 2 (we changed name smoker preserve confidentiality).
ka perspective, important knowledge needed stop content phrasing
appropriate individual smoker; example,
information given letter? example letter Figure 2,
instance, emphasises things smoker dislikes smoking, confidence building,
dealing stress weight gain; recommend specific techniques
stopping smoking.
letter adopt positive youll feel better stop tone (as done
letter Figure 2), adopt negative smoking killing tone?
stop never operationally deployed, tested real smokers clinical
trial, 857 smokers received stop letters (Lennox, Osman, Reiter, Robertson,
Friend, McCann, Skatun, & Donnan, 2001). evaluation, incidentally, showed stop
letters effective control non-tailored letters.

494

fiAcquiring Correct Knowledge NLG

SMOKING QUESTIONNAIRE

Please answer marking appropriate box question like this: _

Q1 smoked cigarette last week, even puff?
YES _
Please complete following questions

Please read questions carefully.
Q2

Home situation:
Live
_
alone





Please return questionnaire unanswered
envelope provided. Thank you.
sure answer, give best answer can.

Live

husband/wife/partner



Live
adults

0 boys

0. girls

Q3

Number children 16 living home

Q4

anyone else household smoke? (If so, please mark boxes apply)
husband/wife/partner
family member
others

Q5



Live
children

long smoked for? 20 years
Tick smoked less year


Q6

many cigarettes smoke day? (Please mark amount below)

Less 5
Q7

5 10

11 15 _

16 20

21 - 30

31

soon wake smoke first cigarette? (Please mark time below)

Within 5 minutes

6 - 30 minutes _

31 - 60 minutes

Q8

find difficult smoke places
forbidden eg church, library, cinema?

Q9

cigarette would hate give up?

Q10

smoke frequently first hours
waking rest day?

Q11 smoke ill bed
day?
Q12
intending stop
smoking next 6
months?

YES





_

60 minutes
YES

_NO

first one morning _
others
YES



_

YES



_

Q13 yes, intending stop smoking
within next month?
YES
Q14 no, would like stop smoking
easy?
YES Sure _





1

Figure 1: First page example smoker questionnaire

495

fiSmoking Information Heather Stewart
know make likely able stop.
people stop smoking good one attempt.

People stop smoking really want stop. encouraging
many good reasons stopping. scales show good
bad things smoking you. tipped favour.

Overcoming barriers stopping...

THINGS LIKE

it's relaxing
stops stress
enjoy
relieves boredom
stops weight gain
stops craving

THINGS DISLIKE
makes less fit
it's bad example kids
you're addicted
it's unpleasant others
people disapprove
it's smelly habit
it's bad
it's expensive
it's bad others' health

could it...
people really want stop eventually succeed. fact, 10
million people Britain stopped smoking - stayed stopped -
last 15 years. Many found much easier expected.
Although don't feel confident would able stop
try, several things favour.




stopped month.
good reasons stopping smoking.
expect support family, friends,
workmates.

said questionnaire might find difficult stop
smoking helps cope stress. Many people think
cigarettes help cope stress. However, taking cigarette
makes feel better short while. ex-smokers feel calmer
control smoking.
ideas coping stress back page leaflet.
also said might find difficult stop would put
weight. people put weight. stop smoking,
appetite would improve would taste food much better.
would wise plan advance you're
reaching biscuit tin time. Remember putting weight
overeating problem, no-smoking one. tackle later
diet exercise.

finally...
hope letter help feel confident giving
cigarettes. go, real chance succeeding.
best wishes,
Health Centre.

Reiter, Sripada, & Robertson

496

Figure 2: Extract letter generated Figure 1 questionnaire

good reasons stop...

fiAcquiring Correct Knowledge NLG

day

hour

12-06-02
12-06-02
12-06-02
12-06-02
12-06-02
12-06-02
13-06-02

6
9
12
15
18
21
0

wind
direction
WSW
WSW
WSW
WSW
SW
SSW
SSW

wind speed
(10m altitude)
10
9
7
7
7
8
10

wind speed
(50m alt)
12
11
9
9
9
10
12

Figure 3: Wind data extract 12-Jun-2002 numerical weather prediction
Knowledge acquisition stop primarily based structured expert-oriented ka
techniques, including particular sorting think-aloud protocols. Knowledge acquired five health professionals; three doctors, nurse, health psychologist.
experts knowledgeable smoking patient information,
experts writing tailored smoking-cessation letters. fact experts
task, since one manually writes tailored smoking-cessation letters.
unusual nlg system attempt task currently performed
human experts; examples include descriptions software models (Lavoie, Rambow,
& Reiter, 1997), customised descriptions museum items (Oberlander, ODonnell, Knott,
& Mellish, 1998), written feedback adult literacy students (Williams, Reiter, &
Osman, 2003). Knowledge validation stop mostly based feedback users
(smokers), results clinical trial.
2.4 SumTime-Mousam
SumTime-Mousam (Sripada, Reiter, Hunter, & Yu, 2002) nlg system generates
marine weather forecasts offshore oil rigs, numerical weather simulation data.
extract SumTime-Mousams input data shown Figure 3, extract
forecast generated data shown Figure 4. ka perspective, main
knowledge needed SumTime-Mousam content expression best
users; example,
changes meteorological parameter significant enough reported
text? forecast Figure 4, example, mentions changes wind direction
changes wind speed.
words phrases used communicate time? example,
1800 described early evening (as Figure 4) late afternoon?
SumTime-Mousam currently used operationally meteorological company,
generate draft forecasts post-edited human forecasters.
Knowledge acquisition SumTime-Mousam based corpus analysis
manually-written forecasts structured ka expert meteorologists. Unlike experts worked stop, meteorologists worked SumTime-Mousam

497

fiReiter, Sripada, & Robertson

FORECAST 6 - 24 GMT, Wed 12-Jun 2002
WIND(KTS)
10M: WSW 8-13 gradually backing SW early evening SSW
midnight.
50M: WSW 10-15 gradually backing SW early evening SSW
midnight.
WAVES(M)
SIG HT: 0.5-1.0 mainly SW swell.
MAX HT: 1.0-1.5 mainly SW swell.
PER(SEC)
WAVE PERIOD: Wind wave 3-5 mainly 6 second SW swell.
WINDWAVE PERIOD: 3-5.
SWELL PERIOD: 5-7.
WEATHER:
Partly cloudy becoming overcast light rain around midnight.
VIS(NM):
Greater 10 reduced 5-8 precipitation.
AIR TEMP(C): 8-10 rising 9-11 around midnight.
CLOUD(OKTAS/FT): 2-4 CU/SC 1300-1800 lowering 7-8 ST/SC 700-900 around
midnight.
Figure 4: Extract forecast generated 12-Jun-2002
experienced writing target texts (weather forecasts). forecast corpus included numerical weather simulation data forecasters used writing
forecasts, well actual forecast texts (Sripada, Reiter, Hunter, & Yu, 2003).
Knowledge validation SumTime-Mousam mostly conducted checking
knowledge acquired corpus experts, checking knowledge acquired
experts corpus. words, tried make validation
technique different possible acquisition technique. currently evaluating
SumTime-Mousam system measuring number edits forecasters make
computer-generated draft forecasts.

3. Knowledge Acquisition Techniques Tried
section summarise main ka techniques used stop SumTimeMousam. technique give example knowledge acquired, discuss
learned tried validate knowledge. Table 1 gives high level
overview major advantages disadvantages different techniques tried,
different techniques perhaps useful, types knowledge
best suited acquiring (using classification Section 2.1). table shows,
one technique clearly best; different strengths weaknesses. Probably
best overall ka strategy use mix different techniques; discuss
Section 5.

498

fiAcquiring Correct Knowledge NLG

Techniques

Advantages

Disadvantages

directly ask
experts
structured ka
experts
corpus
analysis

get big picture

many gaps, may
match practice
limited coverage,
experts variable
hard create,
texts inconsistent,
poor models nlg
local optimisation,
major changes

expert
revision

get details,
get rationale
get lots
knowledge
quickly
fix problems
knowledge


Useful
initial
prototype
flesh
prototype
robustness,
unusual cases

Types
Knowledge
domain,
DCK
depends
expert
DCK,
communication

improve
system



Table 1: Summary Evaluation ka techniques nlg
3.1 Directly Asking Experts Knowledge
simplest perhaps obvious ka technique nlg simply ask experts
write texts question. stop SumTime-Mousam, experts initially
gave us spreadsheets flowcharts describing thought texts generated.
projects, also turned experts description texts
generated fact match people actually wrote texts question.
common finding ka, partially due fact difficult experts
introspectively examine knowledge use practice (Anderson, 1995);
proponents expert-oriented ka prefer structured ka techniques.
example, beginning SumTime-Mousam, one meteorologists gave
us spreadsheet designed, essentially encoded thought
parts weather forecasts generated (the spreadsheet generate complete
weather forecast). analysed logic used spreadsheet, largely based first
version SumTime-Mousam logic.
One goal analysis create algorithm could decide change
parameter value significant enough mentioned weather
report. spreadsheet used context-dependent change thresholds make decision.
example, change wind speed would mentioned
change 10 knots more, final wind speed 15 knots less;
change 5 knots more, final wind speed 15 40
knots;
change 10 knots more, final wind speed 40 knots.
context-dependent thresholds reflect usage weather reports users (in
case, oil company staff making decisions related North Sea offshore oil rigs).
example, user deciding unload supply boat, moderate changes wind
speed dont matter low speeds (because light winds minimal impact supply
boat operations) high speeds (because boat wont even attempt unload
heavy winds), may affect decisions in-between speeds. context-dependent
499

fiReiter, Sripada, & Robertson

thresholds would expected vary according specific forecast recipient,
set consultation recipient.
perspective, two main pieces knowledge encoded algorithm:
1. absolute size change determines whether mentioned not,
2. threshold significance depends context ultimately user
use information.
3.1.1 Validation Direct Expert Knowledge
checked rules comparing observed corpus analysis
manually written forecasts (Section 3.3). suggested (2) probably
correct, (1) may incorrect. particular, linear segmentation model (Sripada et al.,
2002), basically looks changes slope rather changes absolute value
parameter, better matches corpus texts. expert designed spreadsheet model
agreed segmentation probably better approach. also essentially commented
one reason use absolute size model something
easily comprehensible someone neither programmer expert numerical
data analysis techniques.
words, addition problems introspecting knowledge, also perhaps
reasonable expect domain expert able write sophisticated data analysis
algorithm based expertise. issue knowledge needed purely
declarative, many ai applications; need procedural algorithmic
knowledge, must bear mind domain experts may sufficient computational
expertise express knowledge computer algorithm.
3.1.2 Role Directly Asking Experts Knowledge
Although experts spreadsheet SumTime-Mousam far ideal, extremely useful starting point. specified initial system could build fairly
easily, produced least vaguely plausible output. Much fact happened stop, one doctors gave us flowchart certainly many
weaknesses, useful initial specification relatively easy-to-build
somewhat plausible system. stop SumTime-Mousam, indeed nlg
projects involved in, initial prototype system working soon
possible useful developing ideas explaining domain experts
interested parties trying do.
terms types knowledge mentioned Section 2.1, stop flowchart
SumTime-Mousam spreadsheet specified domain knowledge (for example,
smokers categorised) domain communication knowledge (for example, use
ranges instead single numbers communicate wind speed). stop flowchart
specify generic communication knowledge English grammar morphology;
author probably believed knew things did. SumTimeMousam spreadsheet effect include English grammar rules,
get spreadsheet work, author much confidence them.
500

fiAcquiring Correct Knowledge NLG

summary, think directly asking experts knowledge excellent way
quickly build initial system, especially nlg developers supply communication
knowledge domain expert may possess. initial system place,
probably best use ka techniques, least poorly understood areas
nlg. However, applications solid theoretical basis, expert
simply say build system according theory X, experts direct knowledge may
perhaps needed.
3.2 Structured Expert-Oriented KA: Think-Aloud Protocols
numerous types structured expert-oriented ka techniques, including thinkaloud protocols, sorting, structured interviews (Scott et al., 1991). focus
think-aloud protocols, technique used most. tried
structured ka techniques well, sorting (Reiter et al., 2000);
describe here, broad conclusions structured ka techniques
similar conclusions think-aloud protocols.
think-aloud protocol, expert carries task question (in case, writing
text) thinking aloud audio (or video) recorder. used think-aloud
protocols stop SumTime-Mousam. especially important stop,
provided basis content phrasing rules.
simple example think-aloud process follows. One doctors wrote
letter smoker tried stop before, managed stop several weeks
starting again. doctor made following comments think-aloud transcript:
tried stop smoking before? Yes, longest managed
stop ticked one week right three months thats
encouraging managed stop least before,
always said people one two goes likely
succeed future.
also included following paragraph letter wrote smoker:
see managed stop smoking one two occasions
gone back smoking, glad know common
people finally stop smoking one two attempts
past finally succeed. show capable
stopping even short period, means much likely
able stop permanently somebody never ever stopped smoking
all.
analysing session, proposed two rules:
(previous attempt stop) (message: likely succeed)
(previous attempt stop) (message: people stop
unsuccessful attempts first)

501

fiReiter, Sripada, & Robertson

final system incorporated rule (based several ka sessions,
one) stated smoker tried stop before, letter included
section confidence building, confidence-building section include short
message previous attempts stop. smoker managed quit
one week, mentioned message; otherwise message mention
recency smokers previous cessation attempt within past 6 months.
actual text generated rule example letter Figure 2
Although dont feel confident would able stop
try, several things favour.
stopped month.
Note text produced actual stop code considerably simpler
text originally written expert. fairly common, simplifications
logic used decide whether include message letter not. many cases
due expert much knowledge expertise computer system
(Reiter & Dale, 2000, pp 3036). general, process deriving implementable rules
nlg systems think-aloud protocols perhaps art science,
least different experts often write texts different ways.
3.2.1 Validation Structured KA Knowledge
attempted verify rules acquired stop think-aloud sessions performing series small experiments asked smokers comment letter,
compare two versions letter. Many rules supported experiments example, people general liked recap smoking likes dislikes (see
good reasons stop. . . section Figure 2). However, one general negative finding
experiments tailoring rules insufficiently sensitive unusual
atypical aspects individual smokers; smokers probably unusual atypical
way. example, stop letters go medical details smoking (as
none think-aloud expert-written letters contained information),
seemed like right choice many smokers, smokers say would
liked see medical information smoking. Another example (again based
think-aloud sessions) adopted positive tone try scare smokers;
seemed right smokers, smokers said brutal
approach would effective them.
fact experts tailor letters ways may possibly reflect
fact tailoring would appropriate relatively small number
specific cases considered think-aloud sessions. 30 think-aloud sessions
experts, looked 24 different smoker questionnaires (6 questionnaires considered two experts). may sound like lot, drop ocean
consider tremendously variable people are.
Comments made smokers stop clinical trial (Reiter, Robertson, & Osman, 2003) also revealed problems think-aloud derived rules. example,
decided include practical how-to-stop information letters people currently intending stop smoking; smoker comments suggest mistake.
502

fiAcquiring Correct Knowledge NLG

fact, experts include information think-aloud letters people,
not. decision include information influenced Stages
Change theoretical model (Prochaska & diClemente, 1992) behaviour change,
states how-to-stop advice inappropriate people currently intending stop;
retrospect, decision probably mistake.
repeated two think-aloud exercises 15 months originally performed
them; is, went back one experts gave two questionnaires
analysed 15 months earlier, asked think aloud writing letters
based questionnaires. letters expert wrote second session
somewhat different ones originally written, preferred smokers
letters originally written (Reiter et al., 2000). suggests experts
static knowledge sources, learning task writing
tailored smoking-cessation letters course project. Perhaps
surprise given none experts ever attempted write letters
getting involved project.
3.2.2 Role Structured Expert-Oriented KA
Structured expert-oriented ka certainly useful way expand, refine, generally
improve initial prototypes constructed basis experts direct knowledge. focusing
actual cases structuring ka process, learned many things
experts mention directly. obtained types knowledge mentioned
Section 2.1, working experts relevant expertise. example stop
acquired domain knowledge (such medical effects smoking) doctors, domain
communication knowledge (such words use) psychologist expertise
writing patient information leaflets, communication knowledge graphic design
layout graphic designer.
However, structured expert-oriented ka problems, including particular coverage variability. mentioned above, 30 sessions examined 24 smoker
questionnaires could possibly give good coverage population smokers, given
complex variable people are. variation, fact different experts wrote
texts different ways made difficult extract rules think-aloud protocols.
undoubtably made mistakes regard, giving how-to-stop information people currently intending stop smoking. Perhaps focused
single expert order reduce variation. However, experiences suggested
different experts better different types information, also experts changed
time (so might see substantial variation even texts single author);
observations raise doubts wisdom usefulness single-expert strategy.
short, complexity nlg tasks means large number structured ka
sessions may needed get good coverage; fact numerous ways
write texts fulfill communicative goal means different experts tend write
differently, makes analysis structured ka sessions difficult.

503

fiReiter, Sripada, & Robertson

3.3 Corpus Analysis
recent years great interest Natural Language Processing areas
ai using machine learning techniques acquire knowledge relevant data sets.
example, instead building medical diagnosis system trying understand expert
doctors diagnose diseases, instead analyse data sets observed symptoms actual
diseases, use statistical machine learning techniques determine symptoms
predict disease. Similarly, instead building English grammar working
expert linguists, instead analyse large collections grammatical English texts
order learn allowable structures (grammar) texts. collections texts
called corpora Natural Language Processing.
growing interest applying techniques learn knowledge
needed nlg. example, Barzilay McKeown (2001) used corpus-based machine
learning learn paraphrase possibilities; Duboue McKeown (2001) used corpus-based
machine learning learn NP constituents ordered; Hardt Rambow
(2001) used corpus-based machine learning learn rules VP ellipsis.
nlg researchers, McKeown et al. (1994), used term corpus
analysis refer manual analysis (without using machine learning techniques)
small set texts written explicitly nlg project domain experts (and
hence naturally occurring). certainly valid valuable ka technique,
regard form structured expert-oriented ka, ways similar thinkaloud protocols. paper, corpus analysis refers use machine learning
statistical techniques analyse collections naturally occurring texts.
Corpus analysis sense word possible stop
collection naturally occurring texts (since doctors currently write personalised
smoking-cessation letters). briefly considered analysing example letters produced
think-aloud sessions machine learning techniques, 30
texts, believed would successful learning, especially given
high variability experts. words, perhaps primary strength corpus
analysis ability extract information large data sets; large
data sets extract information from, corpus analysis loses much value.
SumTime-Mousam, able acquire analyse substantial corpus 1099
human-written weather forecasts, along data files forecasters looked
writing forecasts (Sripada et al., 2003). Details corpus analysis procedures
results presented elsewhere (Reiter & Sripada, 2002a; Sripada et al., 2003),
repeated here.
3.3.1 Validation Corpus Analysis Knowledge
many rules acquired corpus analysis valid, rules
problematical, primarily due two factors: individual variations writers,
writers making choices appropriate humans nlg systems.
simple example individual variation problems causes follows. One
first things attempted learn corpus express numbers wind
statements. initially searching common textual realisation
number. resulted rules said 5 expressed 5, 6
504

fiAcquiring Correct Knowledge NLG

form
5
05
6
06

F1
0
0
0
0

F2
7
0
44
0

F3
0
1
0
364

F4
0
46
0
154

F5
122
0
89
0

unknown
4
2
2
13

total
133
49
135
531

Table 2: Usage 5, 05, 6, 06 wind statements, forecaster
expressed 06. probably acceptable forecast always include leading
zeros single digits (that is, use 05 06), never include leading zeros (that is,
use 5 6). However, probably acceptable mix two (that is, use 5 06
forecast), rules would led to.
usage 5, 05, 6, 06 individual forecaster shown Table 2.
table suggests, individual forecaster consistent; forecasters F3 F4 always
include leading zeros, forecasters F2 F5 never include leading zeros. F1 fact
also consistent always omits leading zeros; example uses 8 instead 08.
reason overall statistics favour 5 05 06 6 individuals also differ
descriptions wind speed prefer use. example, F1 never explicitly
mentions low wind speeds 5 6 knots, instead always uses generic phrases
10 LESS; F2, F4, F5 use mix generic phrases explicit numbers low
wind speeds; F3 always uses explicit numbers never uses generic phrases.
forecasters (especially F3) also strong preference even numbers. means
statistics 5 vs. 05 dominated F5 (the forecaster explicitly
mentions low wind speeds prefer even numbers); statistics 6 vs.
06 dominated F3 (who uses number lot avoids generic phrases
odd numbers). Hence somewhat odd result corpus overall favours 5
05 06 6.
example means unique. Reiter Sripada (2002b) explain
complex analysis using corpus, whose goal determine common time
phrase time, similarly led unacceptable rules, largely individual
differences forecasters.
obvious methods deal problems caused individual variation.
example, could restrict corpus texts one author; although
major drawback significantly reducing size corpus. could also use
sophisticated model, learning one rule single digit numbers expressed,
separate rules number. could analyse behaviour individuals
identify choices (such presence leading zero) vary individuals
consistently made given individual; make choices parameters
user nlg system specify. last option probably best nlg
systems (Reiter, Sripada, & Williams, 2003), one used SumTime-Mousam
leading-zero choice.
main point simply would trouble accepted
initial corpus-derived rules (use 5 06) without question. corpus researchers
course aware, result corpus analysis depends learned (for
example, rule realise 5, rule realise single-digit numbers)
505

fiReiter, Sripada, & Robertson

features used learning (for example, number, number
author). complex analyses, analysis time-phrase choice rules
(Reiter & Sripada, 2002b), result also depends algorithms used learning
alignment. dependence corpus analysis choices means results
particular analysis guaranteed correct need validated (checked)
like results ka techniques. Also, often best approach
nlg perspective, namely identifying individual variations letting user choose
variation prefers, requires analysing differences individual writers.
best knowledge published nl corpus analyses done this, perhaps
part many popular corpora include author information.
recurring problem corpus-derived rules cases writers
produced sub-optimal texts particular shorter been,
probably texts quicker write. instance, noticed
parameter changed less steady fashion throughout forecast period,
forecasters often omitted time phrase. example, wind rose steadily speed
10 20 course forecast period covering calendar day, forecasters
might write 8-12 RISING 18-22, instead 8-12 RISING 18-22 MIDNIGHT.
statistical corpus analysis showed null time phrase common one
contexts, used 33% cases. next common time phrase, later,
used 14% cases. Accordingly, programmed system omit time phrase
circumstances. However, asked experts comment revise
generated forecasts (Section 3.4), told us behaviour incorrect,
forecasts useful end users included explicit time phrases rely
readers remembering forecast periods ended. words, example
forecasters wrong thing, course meant rule produced
corpus analysis incorrect.
dont know forecasters this, discussions forecast managers
mistakes (such forecast authors describing wind speed direction
changing time, even actually predicted change different
times) suggested one possible cause desire write forecasts quickly. particular,
numerical weather predictions constantly updated, customers want
forecasts based up-to-date prediction; limit amount time
available write forecasts.
fact perfectly rational human writers cut corners time
limitations. forecasters believe, example, quickly writing forecast
last minute let use up-to-date prediction data; benefits
up-to-date data outweighs costs abbreviated texts, making right
decision write shorter-than-optimal texts. nlg system, however, faces
different set tradeoffs (for example, omitting time phrase unlikely speed
nlg system), means blindly imitate choices made human
writers.
problem perhaps fundamental one individual variation problem,
solved appropriate choices learned,
features considered, forth. Corpus analysis, however performed, learns
choice rules used human authors. rules inappropriate nlg system,
506

fiAcquiring Correct Knowledge NLG

rules learned corpus analysis inappropriate ones well, regardless
corpus analysis carried out.
general terms, corpus analysis certainly many strengths, looking
people practice, collecting large data sets statistically
analysed. pure corpus analysis perhaps suffer drawback gives
information experts made choices made, means blindly imitating
corpus lead inappropriate behaviour human writers face different set
constraints tradeoffs nlg system.
3.3.2 Role Corpus Analysis
Corpus analysis machine learning wonderful ways acquire knowledge
1. large data set (corpus) covers unusual boundary cases well
normal cases;
2. members data set (corpus) correct would like
software system produce;
3. members data set (corpus) consistent (modulo noise), example
given input generally leads output.
conditions probably satisfied learning rules medical diagnosis speech
recognition. However, satisfied projects. None conditions
satisfied stop, first satisfied SumTime-Mousam.
course, may ways alleviate problems. example, could
try acquire general communication knowledge domain dependent (such
English grammar) general corpora British National Corpus; could
argue certain aspects manually written texts (such lexical usage) unlikely
adversely affected time pressure hence probably correct; could analyse
behaviour individual authors order enhance consistency (in words, treat
author input feature par actual numerical semantic input data).
scope valuable research here, hope considered people interested
corpus-based techniques nlg.
primarily used corpus analysis SumTime-Mousam acquire domain communication knowledge, linguistically express numbers times weather
forecasts, elide information, sublanguage constraints grammar
weather forecasts. Corpus analysis course also used acquire generic communication knowledge English grammar, mentioned probably best
done large general corpus British National Corpus. use corpus
analysis acquire domain knowledge meteorology. Meteorological researchers fact
use machine learning techniques learn meteorology, analyse numeric
data sets actual predicted weather, analyse textual corpora.
summary, machine learning corpus-based techniques extremely valuable
conditions satisfied, particular offer cost-effective solution
problem acquiring large amount knowledge needed complex nlg applications
(Section 3.2.2). Acquiring large amounts knowledge using expert-oriented ka techniques
507

fiReiter, Sripada, & Robertson

expensive time-consuming requires many sessions experts; contrast,
large corpus consistent correct texts created, large amounts
knowledge extracted low marginal cost. like learning techniques,
corpus analysis vulnerable Garbage In, Garbage principle; corpus
small, incorrect, and/or inconsistent, results corpus analysis may
correct.
3.4 Expert Revision
stop SumTime-Mousam, made heavy use expert revision. is,
showed generated texts experts asked suggest changes would improve
them. sense, expert revision could considered type structured expertoriented ka, seems somewhat different strengths weaknesses
techniques mentioned Section 3.2, treat separately.
example expert revision, early version stop system used phrase
lots good reasons stopping. One experts commented revision
session phrasing changed emphasise reasons listed (in
particular section stop letter) ones smoker selected
questionnaire filled out. eventually led revised wording encouraging
many good reasons stopping, first paragraph example
letter Figure 2. example expert revision SumTime-Mousam mentioned
Section 3.3; showed experts generated texts omitted end-of-period time
phrases, told us incorrect, include time phrases.
stop, also tried revision sessions recipients (smokers). less successful
hoped. Part problem smokers knew little stop (unlike
experts, familiar project), often made comments
useful improving system, stop 10 days til daughter threw
wobbly wanted cigarette bought some. Also, comments came
well-educated articulate smokers, university students. harder get
feedback less well-educated smokers, single mothers living council (public
housing) estates. Hence unsure revision comments obtained generally
applicable not.
3.4.1 Validation Expert Revision Knowledge
validate expert revision knowledge techniques. Indeed,
initially regarded expert revision validation technique, ka technique, although
retrospect probably makes sense think ka technique.
qualitative level, though, expert revision certainly resulted lot useful
knowledge ideas changing texts, particular proved useful way
improving handling unusual boundary cases. example, changed way
described uneventful days SumTime-Mousam (when weather changed little
day) based revision sessions.
comment made stop revision best suggesting specific localised changes generated text, less useful suggesting larger changes system.
One stop experts suggested, system built, might
508

fiAcquiring Correct Knowledge NLG

able suggest larger changes explained systems reasoning him, instead
giving letter revise. words, asked experts think-aloud
wrote letters, order understand reasoning, could useful revision
sessions experts understood computer system thinking well
actually produced. Davis Lenat (1982, page 260) similarly pointed
explanations help experts debug improve knowledge-based systems.
3.4.2 Role Expert Revision
certainly found expert revision extremely useful technique improving
nlg systems; furthermore useful improving types knowledge (domain,
domain communication, communication). time revision seem
largely local optimisation technique. nlg system already generating reasonable
texts, revision good way adjusting systems knowledge rules improve
quality generated text. like local optimisation techniques, expert revision
may tend push systems towards local optimum, may less well suited finding
radically different solutions give better result.

4. Discussion: Problems Revisited
section 1 explained writing tasks difficult automate
complex, often novel, poorly understood, allow multiple solutions. section
discuss problems detail, based experiences stop
SumTime-Mousam.
4.1 Complexity
nlg systems communicate humans, need knowledge people, language, people communicate; since complex, means
general nlg systems need lot complex knowledge. one reasons knowledge acquisition nlg difficult. recall distinction Section 2.1
domain knowledge, domain communication knowledge, communication knowledge,
may communication knowledge (such grammar) generic hence acquired (perhaps corpus-based techniques) used many applications.
domain knowledge similar needed ai systems, problems acquiring
unique nlg. domain communication knowledge, optimal tone
smoking letter tone achieved, information weather
forecast elided, application dependent (and hence cannot acquired generically)
also knowledge language communication (and hence complex). Hence
ka nlg may always require acquiring complex knowledge.
experience, best way acquire complex knowledge robustly get information large number individual cases handled. done corpus
analysis suitable corpus created. also sometimes done expert revision, experts time look large number generated texts; regard
may useful tell comment major problems ignore minor
difficulties. however knowledge acquired, require substantial effort.

509

fiReiter, Sripada, & Robertson

4.2 Novelty
course, many ai systems need complex knowledge, comments hardly
unique nlg. one aspect nlg perhaps unusual many
tasks nlg systems expected perform novel tasks currently done
humans. ai expert systems attempt replicate performance human experts
areas medical diagnosis credit approval. Similarly, language technology
systems attempt replicate performance human language users tasks
speech recognition information retrieval. many nlg applications like stop,
attempt task human performs. Even SumTime-Mousam, argument
could made task humans actually perform writing weather forecasts
time constraints, fact different task performed SumTime-Mousam.
Novelty fundamental problem, means knowledge acquired
expert-oriented ka may reliable (since experts fact experts
actual nlg task), corpus manually-written texts probably exist.
means none ka techniques described likely work. Indeed,
acquiring novel knowledge almost definition scientific research, perhaps
way acquire knowledge conduct scientific research domain. course,
knowledge need acquired way, even novel application
likely much knowledge needed (such grammar morphology) novel.
hand, novelty perhaps also opportunity nlg. One drawbacks conventional expert systems performance often limited
human experts, case users may prefer consult actual experts instead computer
systems. experts task, nlg system may used even output
far ideal.
4.3 Poorly Understood Tasks
perhaps related problem good theoretical models many
choices nlg systems need make. example, ultimate goal stop
change peoples behaviour, number colleagues suggested base stop
argumentation theory, Grasso, Cawsey, Jones (2000) dietary advice
system. However, argumentation theory focuses persuading people change beliefs
desires, whereas goal stop encourage people act beliefs
desires already had. words, stops main goal encourage people
already wanted stop smoking make serious cessation attempt, convince people
desire quit change mind desirability
smoking. applicable theory could find Stages Change (Prochaska &
diClemente, 1992), indeed partially based stop theory. However, results
evaluation suggested choices rules based Stages
Change incorrect, mentioned Section 3.2.1.
Similarly, one problems SumTime-Mousam generating texts
interpreted correctly despite fact different readers different idiolects
particular probably interpret words different ways (Reiter & Sripada, 2002a; Roy, 2002).
Theoretical guidance would useful, able
find guidance.
510

fiAcquiring Correct Knowledge NLG

lack good theoretical models means nlg developers cannot use models
fill cracks knowledge acquired experts data sets,
done ai systems better understood areas scheduling configuring machinery.
turn means lot knowledge must acquired. applications
good theoretical basis, goal ka perhaps acquire limited amount high-level
information search strategies, taxonomies, best way represent knowledge, etc;
determined, details filled theoretical models.
applications details cannot filled theory need acquired, much
knowledge needed. Acquiring knowledge structured expert-oriented ka
could extremely expensive time consuming. Corpus-based techniques cheaper
large corpus available; however, lack good theoretical understanding perhaps
contributes problem know behaviour observe corpus
intended help reader (and hence copied nlg system)
behaviour intended help writer (and hence perhaps copied).
4.4 Expert Variation
Perhaps part lack good theories, stop SumTime-Mousam
observed considerable variation experts. words, different experts wrote
quite different texts input data. stop also discovered experts
changed wrote time (Section 3.2.1).
Variability caused problems structured expert-oriented ka (because different
experts told us different things) corpus analysis (because variation among corpus
authors made harder extract consistent set rules good coverage). However,
variation seems less problem revision. suspect
experts vary less confident particular decision; revision
experts tended focus things confident about, case
ka techniques.
sense variability may especially dangerous corpus analysis,
information corpus degree confidence authors individual decisions, also developers may even realise variability
authors, especially corpus include author information. contrast, structured expert-oriented techniques think-aloud sometimes give information
experts confidence, also variations experts usually obvious.
experimented various techniques resolving differences experts/authors,
group discussions focusing decisions made one particular expert. None
really satisfactory. Given experiences revision, perhaps best way
reduce variation develop ka techniques clearly distinguish decisions experts confident decisions less confidence in.

5. Development Methodology: Using Multiple KA Techniques
methodological perspective, fact different ka techniques different
strengths weaknesses suggests makes sense use mixture several different
ka techniques. example, structured expert-oriented ka corpus analysis
used, explanatory information expert-oriented ka used
511

fiReiter, Sripada, & Robertson

help identify decisions intended help reader intended
help writer, thus helping overcome problem corpus analysis; broader
coverage corpus analysis show unusual boundary cases handled,
thus overcoming problem expert-oriented ka.
also may make sense use different techniques different points development
process. example, directly asking experts knowledge could stressed initial
stages project, used build simple initial prototype; structured ka
experts corpus analysis could stressed middle phases project,
prototype fleshed converted something resembling real system;
revision could used later stages project, system refined
improved.
strategy, graphically shown Figure 5, basically one followed
stop SumTime-Mousam. Note suggests knowledge acquisition
something happens throughout development process. words, first
acquire knowledge build system; knowledge acquisition ongoing process
closely coupled general software development effort. course,
hardly novel observation, many development methodologies knowledgebased systems stress iterative development continual ka (Adelman & Riedel,
1997).
short term, believe using development methodology combines
different ka techniques manner, also validating knowledge much possible,
best strategies acquiring nlg knowledge. also believe whenever possible
knowledge acquired one way validated another way. words,
recommend validating corpus-acquired knowledge using corpus techniques (even
validation done held-out test set); validating expert-acquired knowledge
using expert-based validation (even validation done using different expert).
preferable (although always possible) validate corpus-acquired knowledge
experts, validate expert-acquired knowledge corpus.
Another issue related development methodology relationship knowledge acquisition system evaluation. Although usually considered separate activities, fact closely related. example, currently running
evaluation SumTime-Mousam based number edits forecasters
manually make computer-generated forecasts publishing them; similar
edit-cost evaluations machine translation systems (Jurafsky & Martin, 2000, page 823).
However, edits also excellent source data improving system via expert
revision. take one recent example, forecaster edited computer-generated text SSE
23-28 GRADUALLY BACKING SE 20-25 dropping last speed range, giving SSE
23-28 GRADUALLY BACKING SE. considered evaluation data (2 token
edits needed make text acceptable), ka data (we need adjust rules eliding
similar identical speed ranges).
words, real-world feedback effectiveness quality generated texts
often used either improve evaluate nlg system. data
used depends goals project. scientific projects whose goal test
hypotheses, may appropriate point stop improving system use new
effectiveness data purely evaluation hypothesis testing; sense analogous
512

fiAcquiring Correct Knowledge NLG

Directly Ask Experts
Knowledge
Initial prototype

Structured KA
Experts

Corpus Analysis

Initial version full system

Expert Revision

Final System
Figure 5: Methodology
holding back part corpus testing purposes. applied projects whose goal
build maximally useful system, however, may appropriate use
effectiveness data improve quality generated texts.

6. Conclusion
Acquiring correct knowledge nlg difficult, knowledge needed
largely knowledge people, language, communication, knowledge complex poorly understood. Furthermore, perhaps writing art
science, different people write differently, complicates knowledge acquisition process; many nlg systems attempt novel tasks currently done manually,
makes hard find knowledgeable experts good quality corpora. Perhaps
problems, every single ka technique tried stop SumTimeMousam major problems limitations.
easy solution problems. short term, believe useful
use mixture different ka techniques (since techniques different strengths
weaknesses), validate knowledge whenever possible, preferably using different tech-

513

fiReiter, Sripada, & Robertson

nique one used acquire knowledge. also helps developers understand
weaknesses different techniques, fact structured expert-oriented ka
may give good coverage complexities people language, fact
corpus-based ka distinguish behaviour intended help reader
behaviour intended help writer.
longer term, need research better ka techniques nlg. cannot
reliably acquire knowledge needed ai approaches text generation,
point using approaches, regardless clever algorithms models are.
first step towards developing better ka techniques acknowledge current ka
techniques working well, understand case; hope
paper constitutes useful step direction.

Acknowledgements
Numerous people given us valuable comments past five years struggled ka nlg, many acknowledge here. would like thank Sandra
Williams reading several drafts paper considering light experiences, thank anonymous reviewers helpful comments. would
also like thank experts worked stop SumTime-Mousam, without
work would possible. work supported UK Engineering
Physical Sciences Research Council (EPSRC), grants GR/L48812 GR/M76881,
Scottish Office Department Health grant K/OPR/2/2/D318.

References
Adelman, L., & Riedel, S. (1997). Handbook Evaluating Knowledge-Based Systems.
Kluwer.
Anderson, J. (1995). Cognitive Psychology Implications (Fourth edition). Freeman.
Barzilay, R., & McKeown, K. (2001). Extracting paraphrases parallel corporus.
Proceedings 39th Meeting Association Computation Linguistics
(ACL-01), pp. 5057.
Buchanan, B., & Wilkins, D. (Eds.). (1993). Readings Knowledge Acquisition Learning. Morgan Kaufmann.
Davis, R., & Lenat, D. (1982). Knowledge-Based Systems Artificial Intelligence. McGraw
Hill.
Duboue, P., & McKeown, K. (2001). Empirically estimating order constraints content
planning generation. Proceedings 39th Meeting Association
Computation Linguistics (ACL-01), pp. 172179.
Goldberg, E., Driedger, N., & Kittredge, R. (1994). Using natural-language processing
produce weather forecasts. IEEE Expert, 9 (2), 4553.
Grasso, F., Cawsey, A., & Jones, R. (2000). Dialectical argumentation solve conflicts
advice giving: case study promotion healthy nutrition. International
Journal Human Computer Studies, 53, 10771115.
514

fiAcquiring Correct Knowledge NLG

Hardt, D., & Rambow, O. (2001). Generation VP-ellipsis: corpus-based approach.
Proceedings 39th Meeting Association Computation Linguistics
(ACL-01), pp. 282289.
Jurafsky, D., & Martin, J. (2000). Speech Language Processing. Prentice-Hall.
Kittredge, R., Korelsky, T., & Rambow, O. (1991). need domain communication
language. Computational Intelligence, 7 (4), 305314.
Lavoie, B., Rambow, O., & Reiter, E. (1997). Customizable descriptions object-oriented
models. Proceedings Fifth Conference Applied Natural-Language Processing (ANLP-1997), pp. 253256.
Lennox, S., Osman, L., Reiter, E., Robertson, R., Friend, J., McCann, I., Skatun, D., & Donnan, P. (2001). cost-effectiveness computer-tailored non-tailored smoking
cessation letters general practice: randomised controlled study. British Medical
Journal, 322, 13961400.
McKeown, K., Kukich, K., & Shaw, J. (1994). Practical issues automatic document
generation. Proceedings Fourth Conference Applied Natural-Language
Processing (ANLP-1994), pp. 714.
Oberlander, J., ODonnell, M., Knott, A., & Mellish, C. (1998). Conversation museum: experiments dynamic hypermedia intelligent labelling explorer. New
Review Hypermedia Multimedia, 4, 1132.
Prochaska, J., & diClemente, C. (1992). Stages Change Modification Problem
Behaviors. Sage.
Reiter, E., & Dale, R. (2000). Building Natural Language Generation Systems. Cambridge
University Press.
Reiter, E., Robertson, R., & Osman, L. (2000). Knowledge acquisition natural language
generation. Proceedings First International Conference Natural Language
Generation, pp. 217215.
Reiter, E., Robertson, R., & Osman, L. (2003). Lessons failure: Generating tailored
smoking cessation letters. Artificial Intelligence, 144, 4158.
Reiter, E., & Sripada, S. (2002a). Human variation lexical choice. Computational
Linguistics, 28, 545553.
Reiter, E., & Sripada, S. (2002b). corpora texts gold standards NLG?.
Proceedings Second International Conference Natural Language Generation,
pp. 97104.
Reiter, E., Sripada, S., & Williams, S. (2003). Acquiring using limited user models
NLG. Proceedings 2003 European Workshop Natural Language Generation, pp. 8794.
Roy, D. (2002). Learning visually grounded words syntax scene description task.
Computer Speech Language, 16, 353385.
Scott, A. C., Clayton, J., & Gibson, E. (1991). Practical Guide Knowledge Acquisition.
Addison-Wesley.
515

fiReiter, Sripada, & Robertson

Shadbolt, N., OHara, K., & Crow, L. (1999). experimental evaluation knowledge acquisition techniques methods: History, problems new directions. International
Journal Human Computer Studies, 51, 729755.
Sripada, S., Reiter, E., Hunter, J., & Yu, J. (2002). Segmenting time series weather
forecasting. Applications Innovations Intelligent Systems X, pp. 105118.
Springer-Verlag.
Sripada, S., Reiter, E., Hunter, J., & Yu, J. (2003). Summarising neonatal time-series data.
Proceedings Research Note Sessions EACL-2003, pp. 167170.
Sripada, S., Reiter, E., Hunter, J., Yu, J., & Davy, I. (2001). Modelling task summarising time series data using KA techniques. Applications Innovations
Intelligent Systems IX, pp. 183196. Springer-Verlag.
Walker, M., Rambow, O., & Rogati, M. (2002). Training sentence planner spoken
dialogue using boosting. Computer Speech Language, 16, 409433.
Williams, S., Reiter, E., & Osman, L. (2003). Experiments discourse-level choices
readability. Proceedings 2003 European Workshop Natural Language
Generation, pp. 127134.

516

fiJournal Artificial Intelligence Research 18 (2003) 1-44

Submitted 5/02; published 1/03

Acquiring Word-Meaning Mappings
Natural Language Interfaces
Cynthia A. Thompson

cindi@cs.utah.edu

School Computing, University Utah
Salt Lake City, UT 84112-3320

Raymond J. Mooney

mooney@cs.utexas.edu

Department Computer Sciences, University Texas
Austin, TX 78712-1188

Abstract
paper focuses system, Wolfie (WOrd Learning Interpreted Examples), acquires semantic lexicon corpus sentences paired semantic
representations. lexicon learned consists phrases paired meaning representations. Wolfie part integrated system learns transform sentences
representations logical database queries.
Experimental results presented demonstrating Wolfies ability learn useful
lexicons database interface four different natural languages. usefulness
lexicons learned Wolfie compared acquired similar system,
results favorable Wolfie. second set experiments demonstrates Wolfies ability
scale larger difficult, albeit artificially generated, corpora.
natural language acquisition, difficult gather annotated data needed
supervised learning; however, unannotated data fairly plentiful. Active learning
methods attempt select annotation training informative examples,
therefore potentially useful natural language applications. However,
results date active learning considered standard classification tasks.
reduce annotation effort maintaining accuracy, apply active learning semantic
lexicons. show active learning significantly reduce number annotated
examples required achieve given level performance.

1. Introduction Overview
long-standing goal field artificial intelligence enable computer understanding human languages. Much progress made reaching goal, much also
remains done. artificial intelligence systems meet goal, first need
ability parse sentences, transform representation easily
manipulated computers. Several knowledge sources required parsing,
grammar, lexicon, parsing mechanism.
Natural language processing (NLP) researchers traditionally attempted build
knowledge sources hand, often resulting brittle, inefficient systems take
significant effort build. goal overcome knowledge acquisition
bottleneck applying methods machine learning. develop apply methods
empirical corpus-based NLP learn semantic lexicons, active learning
reduce annotation effort required learn them.

c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiThompson & Mooney

semantic lexicon one NLP component typically challenging time consuming construct update hand. notion semantic lexicon, formally defined
Section 3, list phrase-meaning pairs, meaning representation
determined language understanding task hand, taking compositional view sentence meaning (Partee, Meulen, & Wall, 1990). paper describes
system, Wolfie (WOrd Learning Interpreted Examples), acquires semantic
lexicon phrase-meaning pairs corpus sentences paired semantic representations. goal automate lexicon construction integrated NLP system
acquires semantic lexicons parsers natural language interfaces single
training set annotated sentences.
Although many others (Sebillot, Bouillon, & Fabre, 2000; Riloff & Jones, 1999; Siskind,
1996; Hastings, 1996; Grefenstette, 1994; Brent, 1991) presented systems learning
information lexical semantics, present system learning lexicons phrasemeaning pairs. Further, work unique combination several features, though
prior work included aspects. First, output used system,
Chill (Zelle & Mooney, 1996; Zelle, 1995), learns parse sentences semantic
representations. Second, uses fairly straightforward batch, greedy, heuristic learning
algorithm requires small number examples generalize well. Third,
easily extendible new representation formalisms. Fourth, requires prior knowledge
although exploit initial lexicon provided. Finally, simplifies learning
problem making several assumptions training data, described
Section 3.2.
test Wolfies ability acquire semantic lexicon natural language interface
geographical database using corpus queries collected human subjects
annotated logical form. test, Wolfie integrated Chill,
learns parsers requires semantic lexicon (previously built manually). results
demonstrate final acquired parser performs nearly accurately answering novel
questions using learned lexicon using hand-built lexicon. Wolfie
also compared alternative lexicon acquisition system developed Siskind (1996),
demonstrating superior performance task. Finally, corpus translated
Spanish, Japanese, Turkish, experiments conducted demonstrating ability
learn successful lexicons parsers variety languages.
second set experiments demonstrates Wolfies ability scale larger
difficult, albeit artificially generated, corpora. Overall, results demonstrate robust
ability acquire accurate lexicons directly usable semantic parsing.
integrated system, task building semantic parser new domain simplified.
single representative corpus sentence-representation pairs allows acquisition
semantic lexicon parser generalizes well novel sentences.
building annotated corpus arguably less work building entire NLP
system, still simple task. Redundancies errors may occur training data.
goal also minimize annotation effort, yet still achieve reasonable level
generalization performance. case natural language, frequently large
amount unannotated text available. would like automatically, intelligently,
choose available sentences annotate.

2

fiAcquiring Word-Meaning Mappings

using technique called active learning. Active learning research
area machine learning features systems automatically select informative examples annotation training (Cohn, Atlas, & Ladner, 1994). primary goal
active learning reduce number examples system trained on, thereby
reducing example annotation cost, maintaining accuracy acquired information. demonstrate usefulness active learning techniques, compared
accuracy parsers lexicons learned using examples chosen active learning
lexicon acquisition, learned using randomly chosen examples, finding active
learning saved significant annotation cost training randomly chosen examples.
savings demonstrated geography query domain.
summary, paper provides new statement lexicon acquisition problem
demonstrates machine learning technique solving problem. Next, combining previous research, show entire natural language interface
acquired one training corpus. Further, demonstrate application active
learning techniques minimize number sentences annotate training input
integrated learning system.
remainder paper organized follows. Section 2 gives background
information Chill introduces Siskinds lexicon acquisition system,
compare Wolfie Section 5. Sections 3 4 formally define learning problem
describe Wolfie algorithm detail. Section 5 present discuss experiments
evaluating Wolfies performance learning lexicons database query domain
artificial corpus. Next, Section 6 describes evaluates use active learning
techniques Wolfie. Sections 7 8 discuss related research future directions,
respectively. Finally, Section 9 summarizes research results.

2. Background
section give overview Chill, system research adds to. also
describe Jeff Siskinds lexicon acquisition system.
2.1 Chill
output produced Wolfie used assist larger language acquisition system;
particular, currently used part input parser acquisition system called
Chill (Constructive Heuristics Induction Language Learning). Chill uses inductive
logic programming (Muggleton, 1992; Lavrac & Dzeroski, 1994) learn deterministic
shift-reduce parser (Tomita, 1986) written Prolog. input Chill corpus
sentences paired semantic representations, input required Wolfie.
parser learned capable mapping sentences correct representations, well
generalizing well novel sentences. paper, limit discussion Chills
ability acquire parsers map natural language questions directly Prolog queries
executed produce answer (Zelle & Mooney, 1996). Following two
sample queries database U.S. geography, paired corresponding Prolog
query:

3

fiThompson & Mooney

<Sentence, Representation>
Training
Examples

WOLFIE

CHILL

Lexicon
<Phrase, Meaning>

Final
Parser
Prolog

Figure 1: Integrated System
capital state biggest population?
answer(C, (capital(S,C), largest(P, (state(S), population(S,P))))).
state Texarkana located in?
answer(S, (state(S), eq(C,cityid(texarkana, )), loc(C,S))).
Chill treats parser induction problem learning rules control actions
shift-reduce parser. parsing, current context maintained stack
buffer containing remaining input. parsing complete, stack contains
representation input sentence. three types operators parser uses
construct logical queries. One introduction onto stack predicate needed
sentence representation due phrases appearance front input buffer.
operators require semantic lexicon background knowledge. details
two parsing operators, see Zelle Mooney (1996). using Wolfie,
lexicon provided automatically. Figure 1 illustrates complete system.
2.2 Jeff Siskinds Lexicon Learning Research
closely related previous research automated lexicon acquisition
Siskind (1996), inspired work Rayner, Hugosson, Hagert (1988).
comparing system Section 5, describe main features
research section. goal one cognitive modeling childrens acquisition
lexicon, lexicon used comprehension generation. goal
machine learning engineering one, focuses lexicon comprehension
use parsing, using learning process claim cognitive plausibility,
goal learning lexicon generalizes well small number training
examples.
system takes incremental approach acquiring lexicon. Learning proceeds
two stages. first stage learns symbols representation used
4

fiAcquiring Word-Meaning Mappings

(capital, capital(_,_)),
(biggest, largest(_,_)),
(highest point, high_point(_,_)),
(through, traverse(_,_)),
(has, loc(_,_))

(state, state(_)),
(in, loc(_,_)),
(long, len(_,_)),
(capital, capital(_)),

Figure 2: Sample Semantic Lexicon
final conceptual expression represents meaning word, using versionspace approach. second stage learns symbols put together form
final representation. example, learning meaning word raise,
algorithm may learn set {CAUSE, GO, UP} first stage put together
form expression CAUSE(x, GO(y, UP)) second stage.
Siskind (1996) shows effectiveness approach series artificial corpora.
system handles noise, lexical ambiguity, referential uncertainty, large corpora, usefulness lexicons learned compared correct, artificial
lexicon. goal experiments presented evaluate correctness
completeness learned lexicons. Earlier work (Siskind, 1992) also evaluated versions
technique quite small corpus real English Japanese sentences. extend
evaluation demonstration systems usefulness performing real world natural
language processing tasks, using larger corpus real sentences.

3. Lexicon Acquisition Problem
Although end goal acquire entire natural language interface, currently
divide task two parts, lexicon acquisition component parser acquisition
component. section, discuss problem acquiring semantic lexicons
assist parsing acquisition parsers. training input consists natural language
sentences paired meaning representations. pairs extract lexicon
consisting phrases paired meaning representations. training pairs
given previous section, sample lexicon shown Figure 2.
3.1 Formal Definition
present learning problem formally, definitions needed.
following use terms string substring, extend straight-forwardly
natural language sentences phrases, respectively. also refer labeled trees, making
assumption semantic meanings interest represented such.
common representations recast labeled trees forests, formalism extends
easily latter.
Definition: Let V , E finite alphabets vertex labels edge labels, respectively.
Let V finite nonempty set vertices, l total function l : V V , E set unordered
pairs distinct vertices called edges, total function : E E . G = (V, l, E, a)
labeled graph.

5

fiThompson & Mooney

String 1: girl ate pasta cheese.
1 vertex edge labels:

Tree 1
1
2
4

ingest
patient
agent
person food
age type accomp
sex

3
5

6

7

female

child pasta

food

type
cheese

8

Interpretation f 1 1 t1 :
f 1 (girl) = 2
f 1 (ate") = 1
f 1 (pasta") = 3
f 1 (the cheese") = 7

Figure 3: Labeled Trees Interpretations
Definition: labeled tree connected, acyclic labeled graph.
Figure 3 shows labeled tree t1 (with vertices 1-8) left, associated vertex
edge labels right. function l is:1
{

(1, ingest), (2, person), (3, food), (4, female), (5, child), (6, pasta),
(7, food), (8, cheese) }.

tree t1 semantic representation sentence s1 : girl ate pasta
cheese. Using conceptual dependency (Schank, 1975) representation Prolog list form,
meaning is:
[ingest,

agent:[person, sex:female, age:child],
patient:[food, type:pasta, accomp:[food, type:cheese]]].

Definition: u-v path graph G finite alternating sequence vertices edges
G, vertex repeated, begins vertex u ends vertex v,
edge sequence connects vertex precedes sequence
vertex follows sequence.
Definition: directed, labeled tree = (V, l, E, a) labeled tree whose edges consist
ordered pairs vertices, distinguished vertex r, called root, property
every v V , directed r-v path , underlying
undirected unlabeled graph induced (V, E) connected, acyclic graph.
Definition: interpretation f finite string directed, labeled tree
one-to-one function mapping subset s0 substrings s, two strings
s0 overlap, vertices root range f .
1. omit enumeration function e could given similar manner, example ((1,2),
agent) element e.

6

fiAcquiring Word-Meaning Mappings

girl":

person
sex
age
female

pasta": food

type

child

pasta

cheese": food
type
cheese

ate": ingest

Figure 4: Meanings
interpretation provides information parts meaning sentence
originate phrases. Figure 3, show interpretation, f1 , s1 t1 .
Note domain f1 , since s0 subset substrings s, thus
allowing words meaning. disallow overlapping substrings
domain, cheese cheese could map vertices t1 .
Definition: Given interpretation f string tree t, element p domain
f , meaning p relative s, t, f connected subgraph whose vertices
include f (p) descendents except vertices range f
descendents.
Meanings sense concern lowest level phrasal meanings, occurring
terminal nodes semantic grammar, namely entries semantic lexicon.
grammar used construct meanings longer phrases entire sentences.
motivation previously stated constraint root must included
range f : want vertices sentence representation included
meaning phrase. Note meaning p also directed tree f (p)
root. Figure 4 shows meanings phrase domain interpretation function
f1 shown Figure 3. show labels vertices edges readability.
Definition: Given finite set ST F triples < s1 , t1 , f1 >, . . . , < sn , tn , fn >,
si finite string, ti directed, labeled tree, fi interpretation function
si ti , let language LST F = {p1 , . . . , pk } ST F union substrings2
occur domain fi . pj LST F , meaning set pj , denoted
MST F (pj ),3 set meanings pj relative si , ti , fi < si , ti , fi > ST F .
consider two meanings isomorphic trees taking labels
account.
example, given sentence s2 : man ate cheese, labeled tree t2 pictured
Figure 5, f2 defined as: f2 (ate) = 1, f2 (man) = 2, f2 (the cheese) = 3;
2. consider two substrings string contain characters order,
irrespective positions within larger string occur.
3. omit subscript set ST F obvious context.

7

fiThompson & Mooney

String s2 : man ate cheese."
Tree t2 :

t2 vertex edge labels:
ingest
patient
agent

1
2

4

3

person food
type
age
sex
6

5

male

adult

cheese

Figure 5: Second Tree
meaning set cheese respect ST F = {< s1 , t1 , f1 >, < s2 , t2 , f2 >} {[food,
type:cheese]}, one meaning though f1 f2 map cheese different vertices
two trees, subgraphs denoting meaning cheese two
functions isomorphic.
Definition: Given finite set ST F triples < s1 , t1 , f1 >, . . . , < sn , tn , fn >,
si finite string, ti directed, labeled tree, fi interpretation
function si ti , covering lexicon expressed ST F
{(p, m) : p LST F , (p)}.
covering lexicon L expressed ST F = {< s1 , t1 , f1 >, < s2 , t2 , f2 >} is:
{

(girl, [person, sex:female, age:child]),
(man, [person, sex:male, age:adult]),
(ate, [ingest]),
(pasta, [food, type:pasta]),
(the cheese, [food, type:cheese]) }.

idea covering lexicon provides, string (sentence) si , meaning
phrases sentence. Further, meanings trees whose labeled
vertices together include labeled vertices tree ti representing meaning
si , vertices duplicated, containing vertices ti . Edge labels may
may included, since idea due syntax,
parser provide; edges capturing lexical semantics lexicon. Note
include covering lexicon phrases (substrings) domains
fi s, words empty tree meaning included covering lexicon.
Note also general use phrase mean substrings sentences, whether
consist one word, one. Finally strings covering lexicon may
contain overlapping words even though domain individual interpretation
function must not, since overlapping words could occurred different sentences.
Finally, ready define learning problem hand.

8

fiAcquiring Word-Meaning Mappings

Lexicon Acquisition Problem:
Given: multiset strings = {s1 , . . . , sn } multiset labeled trees = {t1 , . . . , tn },
Find: multiset interpretation functions, F = {f1 , . . . , fn }, cardinality
covering lexicon expressed ST F = {< s1 , t1 , f1 >, . . . , < sn , tn , fn >} minimized.
set found, say found minimal set interpretations (or minimal
covering lexicon). 2
Less formally, learner presented multiset sentences (S) paired
meanings (T ); goal learning find smallest lexicon consistent data.
lexicon paired listing phrases occurring domain fi F
(where F multiset interpretation functions found) elements
meaning sets. motivation finding lexicon minimal size usual bias
towards simplicity representation generalization beyond training data.
definition allows phrases length, usually want limit length
phrases considered inclusion domain interpretation functions,
efficiency purposes.
determine set interpretation functions set strings trees,
one unique covering lexicon expressed ST F . However, might
set interpretation functions possible, may result lexicon smallest
cardinality. example, covering lexicon given previous example
minimal covering lexicon. two sentences given, could find minimal, though
rather degenerate, lexicons as:
{

(girl,
(man,

[ingest, agent:[person, sex:female, age:child],
patient:[food, type:pasta, accomp:[food, type:cheese]]]),
[ingest, agent:[person, sex:male, age:adult],
patient:[food, type:cheese]]) }

type lexicon becomes less likely size corpus grows.
3.2 Implications Definition
definition lexicon acquisition problem differs given authors,
including Riloff Jones (1999), Siskind (1996), Manning (1993), Brent (1991) others,
discussed Section 7. definition problem makes assumptions
training input. First, making f function instead relation, definition
assumes meaning phrase sentence appears representation
sentence, single-use assumption. Second, making f one-to-one, assumes
exclusivity, vertex sentences representation due one phrase
sentence. Third, assumes phrases meaning connected subgraph sentences
representation, distributed representation, connectedness assumption.
first assumption may hold representation languages, present
problem domains considered. second third assumptions perhaps
less problematic respect general language use.
definition also assumes compositionality: meaning sentence derived
meanings phrases contains, addition, perhaps connecting
information specific representation hand, derived external sources
9

fiThompson & Mooney

noise. words, vertices sentences representation included
within meaning word phrase sentence. assumption similar
linking rules Jackendoff (1990), used previous work grammar
language acquisition (e.g., Haas Jayaraman, 1997; Siskind, 19964 )
debate linguistics community ability compositional techniques
handle phenomena (Fillmore, 1988; Goldberg, 1995), making assumption simplifies
learning process works reasonably domains interest here. Also, since
allow multi-word phrases lexicon (e.g., (kick bucket, die( ))), one objection
compositionality addressed.
definition also allows training input which:
1. Words phrases multiple meanings. is, homonymy might occur
lexicon.
2. Several phrases map meaning. is, synonymy might occur
lexicon.
3. words sentence map meanings, leaving unused
assignment words meanings.5
4. Phrases contiguous words map parts sentences meaning representation.
particular note lexical ambiguity (1 above). Note could also derived
ambiguous lexicon as:
{

(girl, [person, sex:female, age:child]),
(ate, [ingest]),
(ate, [ingest, agent:[person, sex:male, age:adult]]),
(pasta, [food, type:pasta]),
(the cheese, [food, type:cheese]) }.

sample corpus. lexicon, ate ambiguous word. earlier example
minimizes ambiguity resulting alternative, intuitively pleasing lexicon.
problem definition first minimizes number entries lexicon, learning
algorithm also exploit preference minimizing ambiguity.
Also note definition allows training input sentences
ambiguous (paired one meaning), since given sentence (a multiset)
might appear multiple times appear one meaning. fact, training data
consider Section 5 ambiguous sentences.
definition lexicon acquisition problem fit cleanly traditional
definition learning classification. training example contains sentence
semantic parse, trying extract semantic information phrases
sentence. example potentially contains information multiple target
concepts (phrases), trying pick relevant features, vertices
4. fact, assumptions except single-use made Siskind (1996); see Section 7
details.
5. words may, however, serve cues parser assemble sentence meanings word
meanings.

10

fiAcquiring Word-Meaning Mappings

representation, corresponding correct meaning phrase. course, assumptions single-use, exclusivity, connectedness, compositionality impose additional
constraints. addition multiple examples one learning scenario,
access negative examples, derive implicit negatives,
possibility ambiguous synonymous phrases.
ways problem related clustering, also capable learning
multiple, potentially non-disjoint categories. However, clear clustering
system could made learn phrase-meaning mappings needed parsing. Finally,
current systems learn multiple concepts commonly use examples concepts
negative examples concept currently learned. implicit assumption made
concepts disjoint, unwarranted assumption presence
synonymy.

4. Wolfie Algorithm Example
section, first discuss issues considered design algorithm,
describe fully Section 4.2.
4.1 Solving Lexicon Acquisition Problem
first attempt solve Lexicon Acquisition Problem might examine interpretation functions across corpus, choose one(s) minimal lexicon size.
number possible interpretation functions given input pair dependent
size sentence representation. sentence w words, (w2 )
possible phrases, particular challenge.
However, number possible interpretation functions grows extremely quickly
size input. sentence p phrases associated tree n vertices,
number possible interpretation functions is:
c!(n 1)!

c
X
i=1

1
.
(i 1)!(n i)!(c i)!

(1)

c min(p, n). derivation formula follows. must choose
phrases use domain f , choose one phrase, two,
number min(p, n) (if n < p assign n phrases since f one-to-one),
p


!

=

p!
i!(p i)!

number phrases chosen. also permute phrases,
order assigned vertices different. i! permutations. must also choose vertices include range interpretation
function. choose root time, choosing vertices,
n 1 choose 1 vertices left choosing root,
n1
i1

!

=

(n 1)!
.
(i 1)!(n i)!
11

fiThompson & Mooney

full number possible interpretation functions then:
min(p,n)

X
i=1

p!
(n 1)!
i!
,
i!(p i)!
(i 1)!(n i)!

simplifies Equation 1. n = p, largest term equation c! =
p!, grows least exponentially p, general number interpretation
functions large allow enumeration. Therefore, finding lexicon examining
interpretations across corpus, choosing lexicon(s) minimum size, clearly
tractable.
Instead finding interpretations, one could find set candidate meanings
phrase, final meaning(s) phrase could chosen way
minimizes lexicon size. One way find candidate meanings fracture meanings
sentences phrase appears. Siskind (1993) defined fracturing (he also calls
Unlink* operation) terms result includes subterms
expression plus . representation formalism, corresponds finding possible
connected subgraphs meaning, adding empty graph. Like interpretation
function technique discussed, fracturing would also lead exponential blowup
number candidate meanings phrase: lower bound number connected
subgraphs full binary tree n vertices obtained noting subset
(n + 1)/2 leaves may deleted still maintain connectivity remaining tree.
Thus, counting ways leaves deleted gives us lower bound 2(n+1)/2
fractures.6 completely rule fracturing part technique lexicon
learning since trees tend get large, indeed Siskind uses many
systems, constraints help control search. However, wish avoid
chance exponential blowup preserve generality approach tasks.
Another option force Chill essentially induce lexicon own.
model, would provide Chill ambiguous lexicon phrase paired
every fracture every sentence appears. Chill would decide
set fractures leads correct parse training sentence, would
include final learned parser-lexicon combination. Thus search would
become exponential. Furthermore, even small representations, would likely lead
system poor generalization ability. Siskinds work (e.g., Siskind,
1992) took syntactic constraints account encounter difficulties,
versions handle lexical ambiguity.
could efficiently find good candidates, standard induction algorithm could
attempt use source training examples phrase. However,
attempt use list candidate meanings one phrase negative examples
another phrase would flawed. learner could know advance phrases
possibly synonymous, thus phrase lists use negative examples
phrase meanings. Also, many representation components would present lists
one phrase. source conflicting evidence learner, even without
presence synonymy. Since positive examples available, one might think
using specific conjunctive learning, finding intersection representations
6. Thanks net-citizen Dan Hirshberg help analysis.

12

fiAcquiring Word-Meaning Mappings

phrase, p (of two words):
1.1) Collect training examples p appears
1.2) Calculate LICS (sampled) pairs examples representations
1.3) l LICS, add (p, l) set candidate lexicon entries
input representations covered, candidate lexicon entries remain do:
2.1) Add best (phrase, meaning) pair candidate entries lexicon
2.2) Update candidate meanings phrases sentences phrase learned
Return lexicon learned (phrase, meaning) pairs.

Figure 6: Wolfie Algorithm Overview
phrase, proposed Anderson (1977). However, meanings ambiguous
phrase disjunctive, intersection would empty. similar difficulty would
expected positive-only compression Muggleton (1995).
4.2 Solution: Wolfie
analysis leads us believe Lexicon Acquisition Problem computationally intractable. Therefore, perform efficient search best lexicon.
use standard induction algorithm. Therefore, implemented Wolfie7 ,
outlined Figure 6, finds approximate solution Lexicon Acquisition Problem. approach generate set candidate lexicon entries, final
learned lexicon derived greedily choosing best lexicon item point,
hopes finding final (minimal) covering lexicon. actually learn interpretation
functions, guarantee find covering lexicon.8 Even
search interpretation functions, using greedy search would also guarantee covering
input, course also guarantee minimal lexicon found. However,
later present experimental results demonstrating greedy approach performs
well.
Wolfie first derives initial set candidate meanings phrase. algorithm
generating candidates, LICS, attempts find maximally common meaning
phrase, biases toward finding small lexicon covering many vertices tree
once, finding lexicon actually cover input. Second, Wolfie chooses
final lexicon entries candidate set, one time, updating candidate set
goes, taking account assumptions single-use, connectedness, exclusivity.
basic scheme choosing entries candidate set maximize prediction
meanings given phrases, also find general meanings. adds tension
LICS, cover many vertices, generality, biases towards fewer vertices. However, generality, like LICS, helps lead small lexicon since general meaning
likely apply widely across corpus.
7. code available upon request first author.
8. Though, course, interpretation functions way guarantee covering lexicon see
Siskind (1993) alternative.

13

fiThompson & Mooney

answer/2

1

2

2



2

state/1

eq/2

1

1


2

C

cityid/2

loc/2
2
1
C



1
texarkana
Figure 7: Tree Variables
Let us explain algorithm detail way example, using Spanish
instead English illustrate difficulty somewhat clearly. Consider following
corpus:
1. Cual es el capital del estado con la poblacion mas grande?
answer(C, (capital(S,C), largest(P, (state(S), population(S,P))))).
2. Cual es la punta mas alta del estado con la area mas grande?
answer(P, (high point(S,P), largest(A, (state(S), area(S,A))))).
3. En que estado se encuentra Texarkana?
answer(S, (state(S), eq(C,cityid(texarkana, )), loc(C,S))).
4. Que capital es la mas grande?
answer(A, largest(A, capital(A))).
5. Que es la area de los estados unitos?
answer(A, (area(C,A), eq(C,countryid(usa)))).
6. Cual es la poblacion de un estado que bordean Utah?
answer(P, (population(S,P), state(S), next to(S,M), eq(M,stateid(utah)))).
7. Que es la punta mas alta del estado con la capital Madison?
answer(C, (high point(B,C), loc(C,B), state(B),
capital(B,A), eq(A,cityid(madison, )))).

sentence representations slightly different tree representations given
problem definition, main difference addition existentially quantified
variables shared leaves representation tree. mentioned Section 2.1,
representations Prolog queries database. Given query, create
tree conforms formalism, addition quantified variables.
example shown Figure 7 representation third sentence. vertex
predicate name arity, Prolog style, e.g., state/1, quantified variables
leaves. outgoing edge (n, m) vertex n, edge labeled
argument position filled subtree rooted m. edge labeled
given argument position, argument free variable. vertex labeled
14

fiAcquiring Word-Meaning Mappings

variable (which occur leaves) existentially quantified variable whose scope
entire tree (or query). learned lexicon, however, need maintain
identity variables across distinct lexical entries.
Another representation difference strip answer predicate
input learner,9 thus allowing forest directed trees input rather single
tree. definition problem easily extends root tree
forest must domain interpretation function.
Evaluation system using representation given Section 5.1; evaluation
using representation without variables forests presented Section 5.2. previously
(Thompson, 1995) presented results demonstrating learning representations different
form, case-role representation (Fillmore, 1968) augmented Conceptual Dependency (Schank, 1975) information. last representation conforms directly
problem definition.
Now, continuing example solving Lexicon Acquisition Problem
corpus, let us also assume simplification, although required, sentences
stripped phrases know empty meanings (e.g., que, es, con, la).
similarly assume known phrases refer directly given database
constants (e.g., location names), remove phrases meaning
training input.
4.2.1 Candidate Generation Phase
Initial candidate meanings phrase produced computing maximally common
substructure(s) sampled pairs representations sentences contain it.
derive common substructure computing Largest Isomorphic Connected Subgraphs
(LICS) two labeled trees, taking labels account isomorphism. analogous
Largest Common Subgraph problem (Garey & Johnson, 1979) solvable polynomial
time if, assume, inputs trees K, number edges include,
given. Thus, start K set equal largest number edges two trees
compared, test common subgraph(s), iterate K = 1, stopping one
subgraphs found given K.
Prolog query representation, algorithm complicated bit variables.
Therefore, use LICS addition similar computing Least General Generalization first-order clauses (Plotkin, 1970). LGG two sets literals least
general set literals subsumes sets literals. add allowing
term argument literal conjunction, algorithm tries orderings
matching terms conjunction. Overall, algorithm finding LICS
two trees Prolog representation first finds common labeled edges
vertices usual LICS, treats variables equivalent. Then, computes
Least General Generalization, conjunction taken account, resulting trees
converted back literals. example, given two trees:

9. predicate omitted Chill initializes parse stack answer predicate, thus
word mapped it.

15

fiThompson & Mooney

Phrase
capital:

grande:
estado:

punta mas:
encuentra:

LICS
largest( , )
capital( , )
state( )
largest( ,state( ))
largest( , )
largest( ,state( ))
state( )
(population(S, ), state(S))
capital( , )
high point( , )
(state(S), loc( ,S))
high point( , )
state( )
(state(S), loc( ,S))

Sentences
1,4
1,7
1,7
1,2
1,4; 2,4
1,2
1,3; 1,7; 2,3; 2,6; 2,7; 3,6; 6,7
1,6
1,7
2,7
3,7
2,7
2,7
3

Table 1: Sample Candidate Lexical Entries Derivation
answer(C, (largest(P, (state(S), population(S,P))), capital(S,C))).
answer(P, (high point(S,P), largest(A, (state(S), area(S,A))))).,
common meaning answer( ,largest( ,state( )). Note LICS two trees
may unique: may multiple common subtrees contain
number edges; case LICS returns multiple answers.
sets initial candidate meanings phrases sample corpus
shown Table 1. example show LICS pairs phrase
appears in, actual algorithm randomly sample subset efficiency reasons,
Golem (Muggleton & Feng, 1990). phrases appearing one sentence
(e.g., encuentra), entire sentence representation (excluding database constant
given background knowledge) used initial candidate meaning. candidates
typically generalized step 2.2 algorithm correct portion
representation added lexicon; see example below.
4.2.2 Adding Final Lexicon
deriving initial candidates, greedy search begins. heuristic used evaluate
candidates attempts help assure small covering lexicon learned. heuristic
first looks weighted sum two components, p phrase candidate
meaning:
1. P (m | p) P (p | m) P (m) = P (p) P (m | p)2
2. generality
Then, ties value broken preferring less ambiguous (those fewer current
meanings) shorter phrases. first component analogous cluster evaluation
16

fiAcquiring Word-Meaning Mappings

heuristic used Cobweb (Fisher, 1987), measures utility clusters based
attribute-value pairs categories, instead meanings phrases. probabilities
estimated training data updated learning progresses account
phrases meanings already covered. see updating works
continue example algorithm. goal part heuristic
maximize probability predicting correct meaning randomly sampled
phrase. equality holds Bayes Theorem. Looking right side, P (m | p)2
expected probability meaning correctly guessed given phrase, p.
assumes strategy probability matching, meaning chosen p
probability P (m | p) correct probability. term, P (p), biases
component common phrase is. Interpreting left side equation,
first term biases towards lexicons low ambiguity, second towards low synonymy,
third towards frequent meanings.
second component heuristic, generality, computed negation
number vertices meanings tree structure, helps prefer smaller,
general meanings. example, candidate set above, else equal,
generality portion heuristic would prefer state( ), generality value -1,
largest( ,state( )) (state(S),loc( ,S)), generality value -2,
meaning estado. Learning meaning fewer terms helps evenly distribute
vertices sentences representation among meanings phrases sentence,
thus leads lexicon likely correct. see this, note
pairs words tend frequently co-occur (grande estado example),
joint representation (meaning) likely set candidate meanings
words. preferring general meaning, easily ignore incorrect joint
meanings.
example experiments, use weight 10 first component
heuristic, weight 1 second. first component smaller absolute
values therefore given higher weight. Modulo consideration, results
overly-sensitive weights automatically setting using cross-validation
training set (Kohavi & John, 1995) little effect overall performance. Table 2
illustrate calculation heuristic measure fourteen pairs,
value all. calculation shows sum multiplying 10 first component
heuristic multiplying 1 second component. first component simplified
follows:
| p | | p |2
| p |2
P (p) P (m | p)2 =


,

| p |2
|p|
| p | number times phrase p appears corpus, initial number
candidate phrases, | p | number times meaning paired
phrase p. ignore since number phrases corpus
pair, effect ranking. highest scoring pair (estado, state( )),
added lexicon.
Next candidate generalization step (2.2), described algorithmically Figure 8.
One key ideas algorithm phrase-meaning choice constrain
candidate meanings phrases yet learned. Given assumption portion
representation due one phrase sentence (exclusivity), part
17

fiThompson & Mooney

Candidate Lexicon Entry
(capital, largest( , )):
(capital, capital( , )):
(capital, state( , )):
(grande, largest( ,state( ))):
(grande, largest( , )):
(estado, largest( ,state( ))):
(estado, state( )):
(estado, (population(S, ), state(S)):
(estado, capital( , )):
(estado, high point( , )):
(estado, (state(S), loc( ,S))):
(punta mas, high point( , )):
(punta mas, state( )):
(encuentra, (state(S), loc( ,S))):

Heuristic Value
10(22 /3) + 1(1) = 12.33
12.33
12.33
10(22 /3) + 1(2) = 11.3
29
10(22 /5) + 1(2) = 6
10(52 /5) + 1(1) = 49
6
7
7
6
19
10(22 /2) + 1(1) = 19
10(12 /1) + 1(2) = 8

Table 2: Heuristic Value Sample Candidate Lexical Entries

Given: learned phrase-meaning pair (l, g)
sentence-representation pairs containing l g, mark covered.
candidate phrase-meaning pair (p, m):
p occurs training pairs (l, g)
vertices intersect vertices g
occurrences covered
Remove (p, m) set candidate pairs.
Else
Adjust heuristic value (p, m) needed account
newly covered nodes training representations.
Generalize remove covered nodes, obtaining m0 ,
Calculate heuristic value new candidate pair (p, m0 ).
candidate meanings remain uncovered phrase
Derive new LICS uncovered representations
calculate heuristic values.

Figure 8: Candidate Generalization Phase

18

fiAcquiring Word-Meaning Mappings

representation covered, phrase sentence paired meaning
(at least sentence). Therefore, step 2.2 candidate meanings words
sentences word learned generalized exclude representation
learned. use operation analogous set difference finding remaining
uncovered vertices representation generalizing meanings eliminate covered
vertices candidate pairs. example, meaning largest( , ) learned
phrase sentence 2, meaning left behind would forest consisting
trees high point(S, ) (state(S), area(S, )). Also, generalization results
empty tree, new LICS calculated. example, since state( ) covered
sentences 1, 2, 3, 6, 7, candidates several words sentences
generalized. example, meaning (state(S), loc( ,S)) encuentra,
generalized loc( , ), new heuristic value 10(12 /1) + 1(1) = 9. Also,
single-use assumption allows us remove candidate pairs containing estado
set candidate meanings, since learned pair covers occurrences estado
set.
Note pairwise matchings generate candidate items, together updating candidate set, enable multiple meanings learned ambiguous phrases,
makes algorithm less sensitive initial rate sampling LICS. example,
note capital ambiguous data set, though ambiguity artifact
way query language designed, one ordinarily think
ambiguous word. However, meanings learned: second pair added
final lexicon (grande, largest( , )), causes generalization empty
meaning first candidate entry Table 2, since new LICS sentence 4
generated, entire remaining meaning added candidate meaning set
capital mas.
Subsequently, greedy search continues resulting lexicon covers training
corpus, candidate phrase meanings remain. rare cases, learning errors occur
leave portions representations uncovered. example, following lexicon
learned:
(estado, state( )),
(grande, largest( )),
(area, area( )),
(punta, high point( , )),
(poblacion, population( , )),
(capital, capital( , )),
(encuentra, loc( , )),
(alta, loc( , )),
(bordean, next to( )),
(capital, capital( )).
next section, discuss ability Wolfie learn lexicons useful
parsers parser acquisition.

19

fiThompson & Mooney

5. Evaluation Wolfie
following two sections discuss experiments testing Wolfies success learning lexicons
real artificial corpora, comparing several cases previously developed
lexicon learning system.
5.1 Database Query Application
section describes experimental results database query application. first
corpus discussed contains 250 questions U.S. geography, paired Prolog
query extract answer question database. domain originally
chosen due availability hand-built natural language interface, Geobase,
database containing 800 facts. Geobase supplied Turbo Prolog 2.0
(Borland International, 1988), designed specifically domain. questions
corpus collected asking undergraduate students generate English questions
database, though given cursory knowledge database without
given chance use it. broaden test, 250 sentences translated
Spanish, Turkish, Japanese. Japanese translations word-segmented Roman
orthography. Translated questions paired appropriate logical queries
English corpus.
evaluate learned lexicons, measured utility background knowledge
Chill. performed choosing random set 25 test examples
learning lexicons parsers increasingly larger subsets remaining 225 examples
(increasing 50 examples time). training, test examples parsed using
learned parser. submit resulting queries database, compare
answers generated submitting correct representation database,
record percentage correct (matching) answers. using difficult gold standard
retrieving correct answer, avoid measures partial accuracy believe
adequately measure final utility. repeated process ten different random training
test sets evaluated performance differences using two-tailed, paired t-test
significance level p 0.05.
compared system incremental (on-line) lexicon learner developed Siskind
(1996). make equitable comparison batch algorithm, ran simulated batch mode, repeatedly presenting corpus 500 times, analogous running
500 epochs train neural network. actually add new kinds data
learn, allows algorithm perform inter-sentential inference directions corpus instead one. point compare accuracy
size training corpus, metric optimized Siskind. worried
difference execution time here,10 lexicons learned running Siskinds
system incremental mode (presenting corpus single time) resulted substantially
lower performance preliminary experiments data. also removed Wolfies
ability learn phrases one word, since current version Siskinds system
10. CPU times two system directly comparable since one written Prolog
Lisp. However, learning time two systems approximately Siskinds
system run incremental mode, seconds 225 training examples.

20

fiAcquiring Word-Meaning Mappings

90

80

70

Accuracy

60

50

40

30

CHILL+handbuilt
CHILL-testlex
CHILL+Wolfie
CHILL+Siskind
Geobase

20

10

0
0

50

100
150
Training Examples

200

250

Figure 9: Accuracy English Geography Corpus
ability. Finally, made comparisons parsers learned Chill
using hand-coded lexicon background knowledge.
similar applications, many terms, state city names,
whose meanings automatically extracted database. Therefore, tests
run names given learner initial lexicon; helpful
required. Section 5.2 gives results different task initial lexicon.
However, unless otherwise noted, tests within Section (5.1) strip
sentences phrases known empty meanings, unlike example Section 4.
5.1.1 Comparisons using English
first experiment comparison original English corpus. Figure 9 shows
learning curves Chill using lexicons learned Wolfie (CHILL+Wolfie)
Siskinds system (CHILL+Siskind). uppermost curve (CHILL+handbuilt) shows
Chills performance given hand-built lexicon. CHILL-testlex shows performance words never appear training data (e.g., test sentences)
deleted hand-built lexicon (since learning algorithm chance learning
these). Finally, horizontal line shows performance Geobase benchmark.
results show lexicon learned Wolfie led parsers almost
accurate generated using hand-built lexicon. best accuracy achieved
parsers using hand-built lexicon, followed hand-built lexicon words
test set removed, followed Wolfie, followed Siskinds system. systems
well better Geobase time reach 125 training examples.
differences Wolfie Siskinds system statistically significant training
21

fiThompson & Mooney

Lexicon
hand-built
Wolfie
Siskind

Coverage
100%
100%
94.4%

Ambiguity
1.2
1.1
1.7

Entries
88
56.5
154.8

Table 3: Lexicon Comparison
example sizes. results show Wolfie learn lexicons support learning
successful parsers, better perspective learned
competing system. Also, comparing CHILL-testlex curve, see
drop accuracy hand-built lexicon due words test set system
seen training. fact, none differences CHILL+Wolfie
CHILL-testlex statistically significant.
One implicit hypotheses problem definition coverage training
data implies good lexicon. results show coverage 100% 225 training examples Wolfie versus 94.4% Siskind. addition, lexicons learned Siskinds
system ambiguous larger learned Wolfie. Wolfies lexicons average 1.1 meanings per word, average size 56.5 entries (after
225 training examples) versus 1.7 meanings per word 154.8 entries Siskinds lexicons. comparison, hand-built lexicon 1.2 meanings per word 88 entries.
differences, summarized Table 3, undoubtedly contribute final performance
differences.
5.1.2 Performance Natural Languages
Next, examined performance two systems Spanish version corpus.
Figure 10 shows results. differences using Wolfie Siskinds learned
lexicons Chill statistically significant training set sizes. also
show performance hand-built lexicons, without phrases present
testing set. performance compared hand-built lexicon test-set phrases
removed still competitive, difference significant 225 examples.
Figure 11 shows accuracy learned parsers Wolfies learned lexicons
four languages. performance differences among four languages quite small,
demonstrating methods language dependent.
5.1.3 Larger Corpus
Next, present results larger, diverse corpus geography domain,
additional sentences collected computer science undergraduates
introductory AI course. set questions smaller corpus collected
students German class, special instructions complexity queries desired.
AI students tended ask complex diverse queries: task give five
interesting questions associated logical form homework assignment, though
direct access database. requested give least
one sentence whose representation included predicate containing embedded predicates,

22

fiAcquiring Word-Meaning Mappings

100
90
80
70

Accuracy

60
50
40
30

Span-CHILL+handbuilt
Span-CHILL-testlex
Span-CHILL+Wolfie
Span-CHILL+Siskind

20
10
0
0

50

100
150
Training Examples

200

250

200

250

Figure 10: Accuracy Spanish

100
90
80
70

Accuracy

60
50
40
30

English
Spanish
Japanese
Turkish

20
10
0
0

50

100
150
Training Examples

Figure 11: Accuracy Four Languages

23

fiThompson & Mooney

100
90
80
70

Accuracy

60
50
40
30

CHILL
WOLFIE
Geobase

20
10
0
0

50

100

150

200
250
Training Examples

300

350

400

450

Figure 12: Accuracy Larger Geography Corpus
example largest(S, state(S)), asked variety sentences.
221 new sentences, total 471 (including original 250 sentences).
experiments, split data 425 training sentences 46 test sentences, 10 random splits, trained Wolfie Chill before. goal
see whether Wolfie still effective difficult corpus, since
approximately 40 novel words new sentences. Therefore, tested performance Chill extended hand-built lexicon. test, stripped sentences
phrases known empty meanings, example Section 4.2. Again,
use phrases one word, since seem make significant
difference domain. results, compare Wolfies lexicons Chill using
hand-built lexicons without phrases appear test set.
Figure 12 shows resulting learning curves. differences Chill using
hand-built learned lexicons statistically significant 175, 225, 325, 425
examples (four nine data points). mixed results indicate
difficulty domain variable vocabulary. However, improvement
machine learning methods Geobase hand-built interface much dramatic
corpus.
5.1.4 LICS versus Fracturing
One component algorithm yet evaluated explicitly candidate generation
method. mentioned Section 4.1, could use fractures representations sentences
phrase appears generate candidate meanings phrase, instead
LICS. used approach compared previously described method
using largest isomorphic connected subgraphs sampled pairs representations

24

fiAcquiring Word-Meaning Mappings

100
90
80
70

Accuracy

60
50
40
30

fractWOLFIE
WOLFIE

20
10
0
0

50

100
150
Training Examples

200

250

Figure 13: Fracturing vs. LICS: Accuracy
candidate meanings. attempt fair comparison, also sampled representations
fracturing, using number source representations number pairs
sampled LICS.
accuracy Chill using resulting learned lexicons background knowledge shown Figure 13. Using fracturing (fractWOLFIE) shows little advantage;
none differences two systems statistically significant.
addition, number initial candidate lexicon entries choose
much larger fracturing LICS method, shown Figure 14. true even
though sampled number representations pairs LICS,
larger number fractures arbitrary representation number LICS
arbitrary pair. Finally, Wolfies learning time using fracturing greater
using LICS, shown Figure 15, CPU time shown seconds.
summary, differences show utility LICS method generating
candidates: thorough method result better performance, also results
longer learning times. One could claim handicapping fracturing since
sampling representations fracturing. may indeed help accuracy,
learning time number candidates would likely suffer even further. domain
larger representations, differences learning time would even dramatic.
5.2 Artificial Data
previous section showed Wolfie successfully learns lexicons natural corpus
realistic task. However, demonstrates success relatively small corpus
one representation formalism. show algorithm scales well
lexicon items learn, ambiguity, synonymy. factors

25

fiThompson & Mooney

600

Number Candidates

500

400

300

fractWOLFIE
WOLFIE

200

100

0
0

50

100
150
Training Examples

200

250

Figure 14: Fracturing vs. LICS: Number Candidates

4

3.5

Learning Time (sec)

3

2.5

2

1.5

1

0.5

fractWOLFIE
WOLFIE

0
0

50

100
150
Training Examples

200

Figure 15: Fracturing vs. LICS: Learning Time

26

250

fiAcquiring Word-Meaning Mappings

difficult control using real data input. Also, large corpora available
annotated semantic parses. therefore present experimental results
artificial corpus. corpus, sentences representations completely
artificial, sentence representation variable-free representation, suggested
work Jackendoff (1990) others.
corpus discussed below, random lexicon mapping words simulated meanings
first constructed.11 original lexicon used generate corpus random
utterances paired meaning representation. using corpus input
Wolfie12 , learned lexicon compared original lexicon, weighted precision
weighted recall learned lexicon measured. Precision measures percentage
lexicon entries (i.e., word-meaning pairs) system learns correct.
Recall measures percentage lexicon entries hand-built lexicon
correctly learned system:
precision =
recall =

# correct pairs
# pairs learned

# correct pairs
.
# pairs hand-built lexicon

get weighted precision recall measures, weight results pair
words frequency entire corpus (not training corpus). models
likely learned correct meaning arbitrarily chosen word
corpus.
generated several lexicons associated corpora, varying ambiguity rate (number meanings per word) synonymy rate (number words per meaning), Siskind
(1996). Meaning representations generated using set conceptual symbols
combined form meaning word. number conceptual symbols used
lexicon noted describe corpus below. lexicon, 47.5%
senses variable-free simulate noun-like meanings, 47.5% contained
one three variables denote open argument positions simulate verb-like meanings.
remainder words (the remaining 5%) empty meaning simulate function words. addition, functors meaning could depth two
arity two. example noun-like meaning f23(f2(f14)), verbmeaning f10(A,f15(B)); conceptual symbols example f23, f2, f14, f10,
f15. using multi-level meaning representations demonstrate learning
complex representations geography database domain: none
hand-built meanings phrases lexicon functors embedded arguments.
used grammar generate utterances meanings original lexicon,
terminal categories selected using distribution based Zipfs Law (Zipf, 1949).
Zipfs Law, occurrence frequency word inversely proportional ranking
occurrence.
started baseline corpus generated lexicon 100 words using 25 conceptual symbols ambiguity synonymy; 1949 sentence-meaning pairs generated.
11. Thanks Jeff Siskind initial corpus generation software, enhanced tests.
12. tests, allowed Wolfie learn phrases length two.

27

fiThompson & Mooney

100
90
80
70

Accuracy

60
50
40
30

Precision
Recall

20
10
0
0

200

400

600

800
1000
Training Examples

1200

1400

1600

1800

Figure 16: Baseline Artificial Corpus
split five training sets 1700 sentences each. Figure 16 shows weighted
precision recall curves initial test. demonstrates good scalability
slightly larger corpus lexicon U.S. geography query domain.
second corpus generated second lexicon, also 100 words using 25 conceptual symbols, increasing ambiguity 1.25 meanings per word. time, 1937 pairs
generated corpus split five sets 1700 training examples each. Weighted
precision 1650 examples drops 65.4% previous level 99.3%, weighted
recall 58.9% 99.3%. full learning curve shown Figure 17. quick comparison Siskinds performance corpus confirmed system achieved comparable
performance, showing current methods, close best performance
able obtain difficult corpus. One possible explanation smaller
performance difference two systems corpus versus geography domain domain, correct meaning word necessarily
general, terms number vertices, candidate meanings. Therefore,
generality portion heuristic may negatively influence performance Wolfie
domain.
Finally, show change performance increasing ambiguity increasing
synonymy, holding number words conceptual symbols constant. Figure 18 shows
weighted precision recall 1050 training examples increasing levels ambiguity, holding synonymy level constant. Figure 19 shows results increasing
levels synonymy, holding ambiguity constant. Increasing level synonymy
effect results much increasing level ambiguity, expected.
Holding corpus size constant increasing number competing meanings
word increases number candidate meanings created Wolfie decreasing
amount evidence available meaning (e.g., first component heuristic
28

fiAcquiring Word-Meaning Mappings

70

60

Accuracy

50

40

30

Precision
Recall

20

10

0
0

200

400

600

800
1000
Training Examples

1200

1400

1600

1800

Figure 17: Ambiguous Artificial Corpus
100

95

90

Recall
Precision

Accuracy

85

80

75

70

65

60
1

1.25

1.5
Number Meanings per Word

1.75

2

Figure 18: Increasing Level Ambiguity
measure) makes learning task difficult. hand, increasing
level synonymy potential mislead learner.
number training examples required reach certain level accuracy also
informative. Table 4, show point standard precision 75% first

29

fiThompson & Mooney

100

Accuracy

95

90

Recall
Precision

85

80
1

1.25

1.5
Number Words per Meaning

1.75

2

Figure 19: Increasing Level Synonymy
Ambiguity Level
1.0
1.25
2.0

Number Examples
150
450
1450

Table 4: Number Examples Reach 75% Precision
reached level ambiguity. Note, however, measured accuracy
set 100 training examples, numbers table approximate.
performed second test scalability two corpora generated lexicons
order magnitude larger tests. tests, use lexicon
containing 1000 words using 250 conceptual symbols. generated corpus
ambiguity, one lexicon ambiguity synonymy similar found
WordNet database (Beckwith, Fellbaum, Gross, & Miller, 1991); ambiguity
approximately 1.68 meanings per word synonymy 1.3 words per meaning.
corpora contained 9904 (no ambiguity) 9948 examples, respectively, split
data five sets 9000 training examples each. easier large corpus, maximum
average weighted precision recall 85.6%, 8100 training examples,
harder corpus, maximum average 63.1% 8600 training examples.

6. Active Learning
indicated previous sections, built integrated system language
acquisition flexible useful. However, major difficulty remains: construction
training corpora. Though annotating sentences still arguably less work building
30

fiAcquiring Word-Meaning Mappings

Apply learner n bootstrap examples, creating classifier.
examples remain annotator unwilling label examples, do:
Use recently learned classifier annotate unlabeled instance.
Find k instances lowest annotation certainty.
Annotate instances.
Train learner bootstrap examples examples annotated far.

Figure 20: Selective Sampling Algorithm
entire system hand, annotation task also time-consuming error-prone.
Further, training pairs often contain redundant information. would like minimize
amount annotation required still maintaining good generalization accuracy.
this, turned methods active learning. Active learning research area
machine learning features systems automatically select informative
examples annotation training (Angluin, 1988; Seung, Opper, & Sompolinsky, 1992),
rather relying benevolent teacher random sampling. primary goal
active learning reduce number examples system trained on,
maintaining accuracy acquired information. Active learning systems may construct examples, request certain types examples, determine set
unsupervised examples usefully labeled. last approach, selective sampling
(Cohn et al., 1994), particularly attractive natural language learning, since
abundance text, would like annotate informative sentences.
many language learning tasks, annotation particularly time-consuming since requires
specifying complex output rather category label, reducing number
training examples required greatly increase utility learning.
section, explore use active learning, specifically selective sampling,
lexicon acquisition, demonstrate active learning, fewer examples required
achieve accuracy obtained training randomly chosen examples.
basic algorithm selective sampling relatively simple. Learning begins
small pool annotated examples large pool unannotated examples, learner
attempts choose informative additional examples annotation. Existing work
area emphasized two approaches, certainty-based methods (Lewis & Catlett,
1994), committee-based methods (McCallum & Nigam, 1998; Freund, Seung, Shamir,
& Tishby, 1997; Liere & Tadepalli, 1997; Dagan & Engelson, 1995; Cohn et al., 1994);
focus former.
certainty-based paradigm, system trained small number annotated
examples learn initial classifier. Next, system examines unannotated examples,
attaches certainties predicted annotation examples. k examples
lowest certainties presented user annotation retraining. Many
methods attaching certainties used, typically attempt estimate
probability classifier consistent prior training data classify new
example correctly.

31

fiThompson & Mooney

Learn lexicon examples annotated far
1) phrase unannotated sentence:
entries learned lexicon
certainty average heuristic values entries
Else, one-word phrase
certainty zero
2) rank sentences use:
Total certainty phrases step 1
# phrases counted step 1

Figure 21: Active Learning Wolfie
Figure 20 presents abstract pseudocode certainty-based selective sampling.
ideal situation, batch size, k, would set one make intelligent decisions
future choices, efficiency reasons retraining batch learning algorithms,
frequently set higher. Results number classification tasks demonstrated
general approach effective reducing need labeled examples (see citations
above).
Applying certainty-based sample selection Wolfie requires determining certainty
complete annotation potential new training example, despite fact individual
learned lexical entries parsing operators perform part overall annotation task.
Therefore, general approach compute certainties pieces example,
case, phrases, combine obtain overall certainty example. Since lexicon
entries contain explicit uncertainty parameters, used Wolfies heuristic measure
estimate uncertainty.
choose sentences annotated round, first bootstrapped initial
lexicon small corpus, keeping track heuristic values learned items.
Then, unannotated sentence, took average heuristic values
lexicon entries learned phrases sentence, giving value zero unknown
words eliminating consideration words assume known advance,
database constants. Thus, longer sentences known phrases would
lower certainty shorter sentences number known phrases;
desirable since longer sentences informative lexicon learning point
view. sentences lowest values chosen annotation, added
bootstrap corpus, new lexicon learned. technique summarized Figure 21.
evaluate technique, compared active learning learning randomly selected examples, measuring effectiveness learned lexicons background knowledge Chill. used (smaller) U.S. Geography corpus, original
Wolfie tests, using lexicons background knowledge parser acquisition (and
using examples parser acquisition).
trial following experiments, first randomly divide data
training test set. Then, n = 25 bootstrap examples randomly selected

32

fiAcquiring Word-Meaning Mappings

100

80

Accuracy

60

40
WOLF+active
WOLFIE
Geobase
20

0
0

50

100
150
Training Examples

200

250

Figure 22: Using Lexicon Certainty Active Learning
training examples step active learning, least certain k = 10 examples
remaining training examples selected added training set. result
learning set evaluated step. accuracy resulting learned
parsers compared accuracy learned using randomly chosen examples
learn lexicons parsers, Section 5; words, think k examples
round chosen randomly.
Figure 22 shows accuracy unseen data parsers learned using lexicons learned
Wolfie examples chosen randomly actively. annotation
savings around 50 examples using active learning: maximum accuracy reached
175 examples, versus 225 random examples. advantage using active
learning clear beginning, though differences two curves
statistically significant 175 training examples. Since learning lexicons
parsers, choosing examples based Wolfies certainty measures, boost could
improved even Chill say examples chosen. See Thompson, Califf,
Mooney (1999) description active learning Chill.

7. Related Work
section, divide previous research related topics areas lexicon
acquisition active learning.
7.1 Lexicon Acquisition
Work automated lexicon language acquisition dates back Siklossy (1972),
demonstrated system learned transformation patterns logic back natural

33

fiThompson & Mooney

language. already noted, closely related work Jeff Siskind,
described briefly Section 2 whose system ran comparisons Section 5.
definition learning problem compared mapping problem (Siskind,
1993). formulation differs several respects. First, sentence representations terms instead trees. However, shown Figure 7, terms also
represented trees conform formalism minor additions. Next,
notion interpretation involve type tree, carries entire representation
sentence root. Also, clear would handle quantified variables
representation sentences. Skolemization possible, generalization across
sentences would require special handling. make single-use assumption
not. Another difference bias towards minimal number lexicon entries,
attempts find monosemous lexicon. later work (Siskind, 2000) relaxes allow
ambiguity noise, still biases towards minimizing ambiguity. However, formal
definition explicitly allow lexical ambiguity, handles heuristic manner.
This, though, may lead robustness method face noise. Finally,
definition allows phrasal lexicon entries.
Siskinds work topic explored many different variations along continuum
using many constraints requiring time incorporate new example (Siskind,
1993), versus constraints requiring training data (Siskind, 1996). Thus, perhaps earlier systems would able learn lexicons Section 5
quickly; crucially systems allow lexical ambiguity, thus also may
learned accurate lexicon. detailed comparisons versions
system outside scope paper. goal Wolfie learn possibly
ambiguous lexicon examples possible, thus made comparisons along
dimension alone.
Siskinds approach, like ours, takes account constraints word meanings
justified exclusivity compositionality assumptions. approach
somewhat general handles noise referential uncertainty (uncertainty
meaning sentence thus multiple possible candidates),
specialized applications meaning (or meanings) known. experimental
results Section 5 demonstrate advantage method application.
demonstrated system capable learning reasonably accurate lexicons large,
ambiguous, noisy artificial corpora, accuracy assured learning
algorithm converges, occur smaller corpus experiments ran.
Also, already noted, system operates incremental on-line fashion, discarding
sentence processes it, batch. addition, search word meanings
proceeds two stages, discussed Section 2.2. using common substructures,
combine two stages Wolfie. systems greedy aspects,
choice next best lexical entry, choice discard utterances noise create
homonymous lexical entry. Finally, system compute statistical correlations
words possible meanings, does.
Besides Siskinds work, others approach problem cognitive
perspective. example, De Marcken (1994) also uses child language learning motivation, approaches segmentation problem instead learning semantics.
training input, uses flat list tokens semantic representations,
34

fiAcquiring Word-Meaning Mappings

segment sentences words. uses variant expectation-maximization (Dempster,
Laird, & Rubin, 1977), together form parsing dictionary matching techniques,
segment sentences associate segments likely meaning.
Childes corpus, algorithm achieves high precision, recall provided.
Others taking cognitive approach demonstrate language understanding ability
carry task parsing. example, Nenov Dyer (1994) describe
neural network model map visual verbal-motor commands, Colunga
Gasser (1998) use neural network modeling techniques learning spatial concepts.
Feldman colleagues Berkeley (Feldman, Lakoff, & Shastri, 1995) actively
pursuing cognitive models acquisition semantic concepts. Another Berkeley effort,
system Regier (1996) given examples pictures paired natural language
descriptions apply picture, learns judge whether new sentence true
given picture.
Similar work Suppes, Liang, Bottner (1991) uses robots demonstrate lexicon learning. robot trained cognitive perceptual concepts associated
actions, learns execute simple commands. Along similar lines, Tishby Gorin
(1994) system learns associations words actions, use
statistical framework learn associations, handle structured representations. Similarly, Oates, Eyler-Walker, Cohen (1999) discuss acquisition lexical
hierarchies associated meaning defined sensory environment robot.
problem automatic construction translation lexicons (Smadja, McKeown, &
Hatzivassiloglou, 1996; Melamed, 1995; Wu & Xia, 1995; Kumano & Hirakawa, 1994; Catizone, Russell, & Warwick, 1993; Gale & Church, 1991; Brown & et al., 1990) definition
similar own. methods also compute association scores
pairs (in case, word-word pairs) use greedy algorithm choose best translation(s) word, take advantage constraints pairs. One
exception Melamed (2000); however, approach allow phrases lexicon synonymy within one text segment, does. Also, Yamazaki, Pazzani,
Merz (1995) learn translation rules semantic hierarchies parsed parallel
sentences Japanese English. course, main difference body
work paper map words semantic structures, words.
mentioned introduction, also large body work learning lexical
semantics using different problem formulations own. example, Collins
Singer (1999), Riloff Jones (1999), Roark Charniak (1998), Schneider (1998)
define semantic lexicons grouping words semantic categories, latter
case, add relational information. result typically applied semantic lexicon
information extraction entity tagging. Pedersen Chen (1995) describe method
acquiring syntactic semantic features unknown word, assuming access
initial concept hierarchy, give experimental results. Many systems (Fukumoto &
Tsujii, 1995; Haruno, 1995; Johnston, Boguraev, & Pustejovsky, 1995; Webster & Marcus,
1995) focus acquisition verbs nouns, rather types words. Also,
authors named either experimentally evaluate systems, show
usefulness learned lexicons specific application.
Several authors (Rooth, Riezler, Prescher, Carroll, & Beil, 1999; Collins, 1997; Ribas,
1994; Manning, 1993; Resnik, 1993; Brent, 1991) discuss acquisition subcategoriza35

fiThompson & Mooney

tion information verbs, others describe work learning selectional restrictions
(Manning, 1993; Brent, 1991). different information required
mapping semantic representation, could useful source information
constrain search. Li (1998) expands subcategorization work
inducing clustering information. Finally, several systems (Knight, 1996; Hastings, 1996;
Russell, 1993) learn new words context, assuming large initial lexicon
parsing system already available.
Another related body work grammar acquisition, especially areas tightly
integrate grammar lexicon, Categorial Grammars (Retore & Bonato,
2001; Dudau-Sofronie, Tellier, & Tommasi, 2001; Watkinson & Manandhar, 1999).
theory Categorial Grammar also ties lexical semantics, semantics
often used inference support high-level tasks database
retrieval. learning syntax semantics together arguably difficult task,
aforementioned work evaluated large corpora, presumably primarily
due difficulty annotation.
7.2 Active Learning
respect additional active learning techniques, Cohn et al. (1994) among
first discuss certainty-based active learning methods detail. focus neural
network approach active learning version-space concepts.
researchers applying machine learning natural language processing utilized active
learning (Hwa, 2001; Schohn & Cohn, 2000; Tong & Koller, 2000; Thompson et al., 1999;
Argamon-Engelson & Dagan, 1999; Liere & Tadepalli, 1997; Lewis & Catlett, 1994),
majority addressed classification tasks part speech tagging
text categorization. example, Liere Tadepalli (1997) apply active learning
committees problem text categorization. show improvements
active learning similar obtain, use committee Winnow-based
learners traditional classification task. Argamon-Engelson Dagan (1999) also
apply committee-based learning part-of-speech tagging. work, committee
hidden Markov models used select examples annotation. Lewis Catlett (1994)
use heterogeneous certainty-based methods, simple classifier used select
examples annotated presented powerful classifier.
However, many language learning tasks require annotating natural language text
complex output, parse tree, semantic representation, filled template.
application active learning tasks requiring complex outputs well
studied, exceptions Hwa (2001), Soderland (1999), Thompson et al. (1999).
latter two include work active learning applied information extraction, Thompson
et al. (1999) includes work active learning semantic parsing. Hwa (2001) describes
interesting method evaluating statistical parsers uncertainty, applied
syntactic parsing.

8. Future Work
Although Wolfies current greedy search method performed quite well, better search
heuristic alternative search strategy could result improvements. also
36

fiAcquiring Word-Meaning Mappings

thoroughly evaluate Wolfies ability learn long phrases, restricted ability
evaluations here. Another issue robustness face noise. current algorithm
guaranteed learn correct lexicon even noise-free corpus. addition noise
complicates analysis circumstances mistakes likely happen.
theoretical empirical analysis issues warranted.
Referential uncertainty could handled, increase complexity, forming
LICS pairs representations phrase appears,
alternative representations sentence. Then, pair added lexicon,
sentence containing word, representations eliminated
contain learned meaning, provided another representation contain (thus allowing
lexical ambiguity). plan flesh evaluate results.
different avenue exploration apply Wolfie corpus sentences paired
common query language, SQL. corpora easily constructible
recording queries submitted existing SQL applications along English forms,
translating existing lists SQL queries English (presumably easier direction
translate). fact training data used learn semantic
lexicon parser also helps limit overall burden constructing complete natural
language interface.
respect active learning, experiments additional corpora needed test
ability approach reduce annotation costs variety domains. would
also interesting explore active learning natural language processing problems
syntactic parsing, word-sense disambiguation, machine translation.
current results involved certainty-based approach; however, proponents
committee-based approaches convincing arguments theoretical advantages.
initial attempts adapting committee-based approaches systems
successful; however, additional research topic indicated. One critical problem
obtaining diverse committees properly sample version space (Cohn et al., 1994).

9. Conclusions
Acquiring semantic lexicon corpus sentences labeled representations
meaning important problem widely studied. present
formalism learning problem greedy algorithm find approximate solution
it. Wolfie demonstrates fairly simple, greedy, symbolic learning algorithm performs
well task obtains performance superior previous lexicon acquisition system
corpus geography queries. results also demonstrate methods extend
variety natural languages besides English, scale fairly well larger,
difficult corpora.
Active learning new area machine learning almost exclusively
applied classification tasks. demonstrated successful application
complex natural language mappings phrases semantic meanings, supporting
acquisition lexicons parsers. wealth unannotated natural language data,
along difficulty annotating data, make selective sampling potentially
invaluable technique natural language learning. results realistic corpora indicate
example annotations savings high 22% achieved employing active

37

fiThompson & Mooney

sample selection using simple certainty measures predictions unannotated data.
Improved sample selection methods applications important language problems
hold promise continued progress using machine learning construct effective
natural language processing systems.
experiments corpus-based natural language presented results
subtask natural language, results whether learned subsystems
successfully integrated build complete NLP system. experiments presented
paper demonstrated two learning systems, Wolfie Chill, successfully
integrated learn complete NLP system parsing database queries executable
logical form given single corpus annotated queries, demonstrated
potential active learning reduce annotation effort learning NLP.

Acknowledgments
would like thank Jeff Siskind providing us software, help
adapting use corpus. Thanks also Agapito Sustaita, Esra Erdem,
Marshall Mayberry translation efforts, three anonymous reviewers
comments helped improve paper. research supported
National Science Foundation grants IRI-9310819 IRI-9704943.

References
Anderson, J. R. (1977). Induction augmented transition networks. Cognitive Science, 1,
125157.
Angluin, D. (1988). Queries concept learning. Machine Learning, 2, 319342.
Argamon-Engelson, S., & Dagan, I. (1999). Committee-based sample selection probabilistic classifiers. Journal Artificial Intelligence Research, 11, 335360.
Beckwith, R., Fellbaum, C., Gross, D., & Miller, G. (1991). WordNet: lexical database
organized psycholinguistic principles. Zernik, U. (Ed.), Lexical Acquisition:
Exploiting On-Line Resources Build Lexicon, pp. 211232. Lawrence Erlbaum,
Hillsdale, NJ.
Borland International (1988). Turbo Prolog 2.0 Reference Guide. Borland International,
Scotts Valley, CA.
Brent, M. (1991). Automatic acquisition subcategorization frames untagged text.
Proceedings 29th Annual Meeting Association Computational Linguistics (ACL-91), pp. 209214.
Brown, P., & et al. (1990). statistical approach machine translation. Computational
Linguistics, 16 (2), 7985.
Catizone, R., Russell, G., & Warwick, S. (1993). Deriving translation data bilingual
texts. Proceedings First International Lexical Acquisition Workshop.
38

fiAcquiring Word-Meaning Mappings

Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.
Machine Learning, 15 (2), 201221.
Collins, M., & Singer, Y. (1999). Unsupervised models named entity classification.
Proceedings Conference Empirical Methods Natural Language Processing
Large Corpora (EMNLP/VLC-99) University Maryland.
Collins, M. J. (1997). Three generative, lexicalised models statistical parsing. Proceedings 35th Annual Meeting Association Computational Linguistics
(ACL-97), pp. 1623.
Colunga, E., & Gasser, M. (1998). Linguistic relativity word acquisition: computational approach. Proceedings Twenty First Annual Conference
Cognitive Science Society, pp. 244249.
Dagan, I., & Engelson, S. P. (1995). Committee-based sampling training probabilistic classifiers. Proceedings Twelfth International Conference Machine
Learning (ICML-95), pp. 150157 San Francisco, CA. Morgan Kaufman.
De Marcken, C. (1994). acquisition lexicon paired phoneme sequences
semantic representations. Lecture Notes Computer Science, Vol. 862, pp. 6677.
Springer-Verlag.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood incomplete data
via EM algorithm. Journal Royal Statistical Society B, 39, 138.
Dudau-Sofronie, Tellier, & Tommasi (2001). Learning categorial grammars semantic
types. Proceedings 13th Amsterdam Colloquium, pp. 7984.
Feldman, J., Lakoff, G., & Shastri, L. (1995). neural theory language project
http://www.icsi.berkeley.edu/ntl. International Computer Science Institute, University
California, Berkeley, CA.
Fillmore, C. (1968). case case. Bach, E., & Harms, R. T. (Eds.), Universals
Linguistic Theory. Holt, Reinhart Winston, New York.
Fillmore, C. (1988). mechanisms Construction Grammar. Axmaker, S., Jaisser,
A., & Singmeister, H. (Eds.), Proceedings Fourteenth Annual Meeting
Berkeley Linguistics Society, pp. 3555 Berkeley, CA.
Fisher, D. H. (1987). Knowledge acquisition via incremental conceptual clustering. Machine
Learning, 2, 139172.
Freund, Y., Seung, H. S., Shamir, E., & Tishby, N. (1997). Selective sampling using
query committee algorithm. Machine Learning, 28, 133168.
Fukumoto, F., & Tsujii, J. (1995). Representation acquisition verbal polysemy.
Papers 1995 AAAI Symposium Representation Acquisition
Lexical Knowledge: Polysemy, Ambiguity, Generativity, pp. 3944 Stanford, CA.

39

fiThompson & Mooney

Gale, W., & Church, K. (1991). Identifying word correspondences parallel texts.
Proceedings Fourth DARPA Speech Natural Language Workshop.
Garey, M., & Johnson, D. (1979). Computers Intractability: Guide Theory
NP-Completeness. Freeman, New York, NY.
Goldberg, A. (1995). Constructions: Construction Grammar Approach Argument
Structure. University Chicago Press.
Grefenstette, G. (1994). Sextant: Extracting semantics raw text, implementation
details. Integrated Computer-Aided Engineering, 6 (4).
Haas, J., & Jayaraman, B. (1997). context-free definite-clause grammars: typetheoretic approach. Journal Logic Programming, 30 (1), 123.
Haruno, M. (1995). case frame learning method Japanese polysemous verbs.
Papers 1995 AAAI Symposium Representation Acquisition
Lexical Knowledge: Polysemy, Ambiguity, Generativity, pp. 4550 Stanford, CA.
Hastings, P. (1996). Implications automatic lexical acquisition mechanism.
Wermter, S., Riloff, E., & Scheler, C. (Eds.), Connectionist, Statistical, Symbolic Approaches Learning natural language processing. Springer-Verlag, Berlin.
Hwa, R. (2001). minimizing training corpus parser acquisition. Proceedings
Fifth Computational Natural Language Learning Workshop.
Jackendoff, R. (1990). Semantic Structures. MIT Press, Cambridge, MA.
Johnston, M., Boguraev, B., & Pustejovsky, J. (1995). acquisition interpretation
complex nominals. Papers 1995 AAAI Symposium Representation
Acquisition Lexical Knowledge: Polysemy, Ambiguity, Generativity, pp.
6974 Stanford, CA.
Knight, K. (1996). Learning word meanings instruction. Proceedings Thirteenth
National Conference Artificial Intelligence (AAAI-96), pp. 447454 Portland, Or.
Kohavi, R., & John, G. (1995). Automatic parameter selection minimizing estimated
error. Proceedings Twelfth International Conference Machine Learning
(ICML-95), pp. 304312 Tahoe City, CA.
Kumano, A., & Hirakawa, H. (1994). Building MT dictionary parallel texts based
linguistic statistical information. Proceedings Fifteenth International
Conference Computational Linguistics, pp. 7681.
Lavrac, N., & Dzeroski, S. (1994). Inductive Logic Programming: Techniques Applications. Ellis Horwood.
Lewis, D. D., & Catlett, J. (1994). Heterogeneous uncertainty sampling supervised
learning. Proceedings Eleventh International Conference Machine Learning (ICML-94), pp. 148156 San Francisco, CA. Morgan Kaufman.
40

fiAcquiring Word-Meaning Mappings

Li, H. (1998). probabilistic approach lexical semantic knowledge acquisition structural disambiguation. Ph.D. thesis, University Tokyo.
Liere, R., & Tadepalli, P. (1997). Active learning committees text categorization.
Proceedings Fourteenth National Conference Artificial Intelligence (AAAI97), pp. 591596 Providence, RI.
Manning, C. D. (1993). Automatic acquisition large subcategorization dictionary
corpora. Proceedings 31st Annual Meeting Association Computational Linguistics (ACL-93), pp. 235242 Columbus, OH.
McCallum, A. K., & Nigam, K. (1998). Employing EM pool-based active learning
text classification. Proceedings Fifteenth International Conference
Machine Learning (ICML-98), pp. 350358 Madison, WI. Morgan Kaufman.
Melamed, I. D. (1995). Automatic evaluation uniform filter cascades inducing n-best
translation lexicons. Proceedings Third Workshop Large Corpora.
Melamed, I. D. (2000). Models translational equivalence among words. Computational
Linguistics, 26 (2), 221249.
Muggleton, S. (Ed.). (1992). Inductive Logic Programming. Academic Press, New York,
NY.
Muggleton, S. (1995). Inverse entailment Progol. New Generation Computing Journal,
13, 245286.
Muggleton, S., & Feng, C. (1990). Efficient induction logic programs. Proceedings
First Conference Algorithmic Learning Theory Tokyo, Japan. Ohmsha.
Nenov, V. I., & Dyer, M. G. (1994). Perceptually grounded language learning: Part 2
DETE: neural/procedural model. Connection Science, 6 (1), 341.
Oates, T., Eyler-Walker, Z., & Cohen, P. (1999). Using syntax learn semantics:
experiment language acquisition mobile robot. Tech. rep. 99-35, University
Massachusetts, Computer Science Department.
Partee, B., Meulen, A., & Wall, R. (1990). Mathematical Methods Linguistics. Kluwer
Academic Publishers, Dordrecht, Netherlands.
Pedersen, T., & Chen, W. (1995). Lexical acquisition via constraint solving. Papers
1995 AAAI Symposium Representation Acquisition Lexical
Knowledge: Polysemy, Ambiguity, Generativity, pp. 118122 Stanford, CA.
Plotkin, G. D. (1970). note inductive generalization. Meltzer, B., & Michie, D.
(Eds.), Machine Intelligence (Vol. 5). Elsevier North-Holland, New York.
Rayner, M., Hugosson, A., & Hagert, G. (1988). Using logic grammar learn lexicon.
Tech. rep. R88001, Swedish Institute Computer Science.

41

fiThompson & Mooney

Regier, T. (1996). human semantic potential: spatial language constrained connectionism. MIT Press.
Resnik, P. (1993). Selection information: class-based approach lexical relationships.
Ph.D. thesis, University Pennsylvania, CIS Department.
Retore, C., & Bonato, R. (2001). Learning rigid lambek grammars minimalist grammars
structured sentences. Proceedings Third Learning Language Logic
Workshop Strasbourg, France.
Ribas, F. (1994). experiment learning appropriate selectional restrictions
parsed corpus. Proceedings Fifteenth International Conference Computational Linguistics, pp. 769774.
Riloff, E., & Jones, R. (1999). Learning dictionaries information extraction multilevel bootstrapping. Proceedings Sixteenth National Conference Artificial
Intelligence (AAAI-99), pp. 10441049 Orlando, FL.
Roark, B., & Charniak, E. (1998). Noun-phrase co-occurrence statistics semi-automatic
semantic lexicon construction. Proceedings 36th Annual Meeting
Association Computational Linguistics COLING-98 (ACL/COLING-98), pp.
11101116.
Rooth, M., Riezler, S., Prescher, D., Carroll, G., & Beil, F. (1999). Inducing semantically
annotated lexicon via EM-based clustering. Proceedings 37th Annual Meeting
Association Computational Linguistics, pp. 104111.
Russell, D. (1993). Language Acquisition Unification-Based Grammar Processing System Using Real World Knowledge Base. Ph.D. thesis, University Illinois, Urbana,
IL.
Schank, R. C. (1975). Conceptual Information Processing. North-Holland, Oxford.
Schneider, R. (1998). lexically-intensive algorithm domain-specific knowledge acquisition. Proceedings Joint Conference New Methods Language Processing
Computational Natural Language Learning, pp. 1928.
Schohn, G., & Cohn, D. (2000). Less more: Active learning support vector machines. Proceedings Seventeenth International Conference Machine Learning (ICML-2000), pp. 839846 Stanford, CA.
Sebillot, P., Bouillon, P., & Fabre, C. (2000). Inductive logic programming corpus-based
acquisition semantic lexicons. Proceedings 2nd Learning Language Logic
(LLL) Workshop Lisbon, Portugal.
Seung, H. S., Opper, M., & Sompolinsky, H. (1992). Query committee. Proceedings
ACM Workshop Computational Learning Theory Pittsburgh, PA.
Siklossy, L. (1972). Natural language learning computer. Simon, H. A., & Siklossy,
L. (Eds.), Representation meaning: Experiments Information Processsing
Systems. Prentice Hall, Englewood Cliffs, NJ.
42

fiAcquiring Word-Meaning Mappings

Siskind, J. M. (2000). Learning word-to-meaning mappings. Broeder, P., & Murre, J.
(Eds.), Models Language Acquisition: Inductive Deductive Approaches. Oxford
University Press.
Siskind, J. M. (1992). Naive Physics, Event Perception, Lexical Semantics Language
Acquisition. Ph.D. thesis, Department Electrical Engineering Computer Science, Massachusetts Institute Technology, Cambridge, MA.
Siskind, J. M. (1996). computational study cross-situational techniques learning
word-to-meaning mappings. Cognition, 61 (1), 3991.
Siskind, J. M. (1993). Lexical acquisition constraint satisfaction. Tech. rep. IRCS-93-41,
University Pennsylvania.
Smadja, F., McKeown, K. R., & Hatzivassiloglou, V. (1996). Translating collocations
bilingual lexicons: statistical approach. Computational Linguistics, 22 (1), 138.
Soderland, S. (1999). Learning information extraction rules semi-structured free
text. Machine Learning, 34, 233272.
Suppes, P., Liang, L., & Bottner, M. (1991). Complexity issues robotic machine learning
natural language. Lam, L., & Naroditsky, V. (Eds.), Modeling Complex Phenomena, Proceedings 3rd Woodward Conference, pp. 102127. Springer-Verlag.
Thompson, C. A., Califf, M. E., & Mooney, R. J. (1999). Active learning natural language
parsing information extraction. Proceedings Sixteenth International
Conference Machine Learning (ICML-99), pp. 406414 Bled, Slovenia.
Thompson, C. A. (1995). Acquisition lexicon semantic representations sentences.
Proceedings 33rd Annual Meeting Association Computational Linguistics (ACL-95), pp. 335337 Cambridge, MA.
Tishby, N., & Gorin, A. (1994). Algebraic learning statistical associations language
acquisition. Computer Speech Language, 8, 5178.
Tomita, M. (1986). Efficient Parsing Natural Language. Kluwer Academic Publishers,
Boston.
Tong, S., & Koller, D. (2000). Support vector machine active learning applications
text classification. Proceedings Seventeenth International Conference
Machine Learning (ICML-2000), pp. 9991006 Stanford, CA.
Watkinson, S., & Manandhar, S. (1999). Unsupervised lexical learning categorial
grammars using lll corpus. Learning Language Logic (LLL) Workshop Bled,
Slovenia.
Webster, M., & Marcus, M. (1995). Automatic acquisition lexical semantics verbs
sentence frames. Proceedings 27th Annual Meeting Association
Computational Linguistics (ACL-89), pp. 177184.

43

fiThompson & Mooney

Wu, D., & Xia, X. (1995). Large-scale automatic extraction English-Chinese translation lexicon. Machine Translation, 9 (3-4), 285313.
Yamazaki, T., Pazzani, M., & Merz, C. (1995). Learning hierarchies ambiguous natural
language data. Proceedings Twelfth International Conference Machine
Learning (ICML-95), pp. 575583 San Francisco, CA. Morgan Kaufmann.
Zelle, J. M. (1995). Using Inductive Logic Programming Automate Construction
Natural Language Parsers. Ph.D. thesis, Department Computer Sciences, University Texas, Austin, TX. Also appears Artificial Intelligence Laboratory Technical
Report AI 96-249.
Zelle, J. M., & Mooney, R. J. (1996). Learning parse database queries using inductive
logic programming. Proceedings Thirteenth National Conference Artificial
Intelligence (AAAI-96), pp. 10501055 Portland, OR.
Zipf, G. (1949). Human behavior principle least effort. Addison-Wesley, New
York, NY.

44

fiJournal Artificial Intelligence Research 18 (2003) 315-349

Submitted 10/02; published 4/03

Structure Complexity Planning Unary Operators
Ronen I. Brafman
Carmel Domshlak

brafman@cs.bgu.ac.il
dcarmel@cs.bgu.ac.il

Department Computer Science
Ben-Gurion University
P.O. Box 653, 84105 Beer-Sheva, Israel

Abstract
Unary operator domains i.e., domains operators single effect arise
naturally many control problems. general form, problem strips planning unary operator domains known hard general strips planning
problem pspace-complete. However, unary operator domains induce natural
structure, called domains causal graph. graph relates preconditions
effect domain operator. Causal graphs exploited Williams Nayak
order analyze plan generation one controllers NASAs Deep-Space One
spacecraft. There, utilized fact graph acyclic, serialization
ordering subgoal obtained quickly. paper conduct comprehensive study relationship structure domains causal graph
complexity planning domain. positive side, show non-trivial
polynomial time plan generation algorithm exists domains whose causal graph induces
polytree constant bound node indegree. negative side, show
even plan existence hard graph directed-path singly connected DAG.
generally, show number paths causal graph closely related
complexity planning associated domain. Finally relate results
question complexity planning serializable subgoals.

1. Introduction
One first well formulated problems addressed AI researchers planning
problem. Simply stated, involves generation sequence system transformations,
taken given set system transformations (called actions plan operators), whose
combined effect move system given initial state one set
desired goal states. planning problem known intractable general (Chapman,
1987), tractable algorithms exist restrictive classes problems only.
discouraging fact deterred planning researchers. Indeed, many researchers believe
real-world problems properties, structure, could exploited, either
implicitly explicitly. paper attempt understand relationship
structure complexity planning problems action changes value
single variable.
study relation structure complexity class problems
must identify set parameters characterize it. case planning, number
problem properties studied past (which review detail
Section 6). properties mostly syntactical, i.e., involve restriction
operators, e.g., type number preconditions effects operators have.
c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBrafman & Domshlak

example, Bylander (1994) showed strips planning domains operator
restricted positive preconditions one postcondition tractable. Backstrom
Klein (1991b) considered other, global types syntactical restrictions, using
refined model two types preconditions considered: prevail conditions,
variable values required prior execution operator
affected operator, preconditions, affected operator.
example, shown operators single effect, two operators
effect, variable affected one context (of prevail conditions)
planning problem solved polynomial time. However, restrictions
strict, difficult find reasonable domains satisfying them.
paper concentrate global properties unary operator domains;
properties capture interactions different planning operators.
tool use study properties domains causal graph. causal graph
directed graph whose nodes stand domain propositions. edge (p, q) appears
causal graph operator changes value q prevail
condition involving p. problem structure introduced Knoblock (1994)
context automatically generating abstractions planning. Subsequently, Jonsson
Backstrom (1998b) introduced 3S class planning problems unary operators,
characterized acyclicity causal graph, restrictions
operator set. shown determining plan existence class problems
polynomial, plan generation provably intractable.
Complexity results unary operators would theoretical interest alone one
could supply interesting problems unary operators used. One interesting
application problem arises determination dominance relationship
different outcomes CP-net (Boutilier, Brafman, Hoos, & Poole, 1999).
problem reducible strips planning unary operators.
Another example, greater interest planning community, planning-based
reactive control system commands NASA Deep Space One autonomous spacecraft (Pell, Bernard, Chien, Gat, Muscettola, Nayak, Wagner, & Williams, 1997; Williams
& Nayak, 1996, 1997). system hailed Weld (1999) recent survey AI
planning one exciting recent developments area planning. Naturally, complete system (Pell et al., 1997) complex, however, configuration
planning execution subsystem particular interest us. context controlling Deep-Space One, Williams Nayak (1996, 1997) present reactive planner, Burton,
generates single control action main engine subsystem spacecraft,
compensates anomalies every step. Given high-level goal (for example, thrust
one engines), Burton continually tries transition system toward state
satisfies desired goal. particularly relevant us Burtons task
described strips planning problem operator affects single variable (hardware component) Williams Nayak (1997) argue physical hardware
usually case state variable commanded separately. However, Burton
based two additional important restrictions: First, planner explicitly supplied
serialization order satisfiable set goal. Second, operators must reversible.
One reasons cited designing Burton reactive planner generates
single action time potential intractability generating whole plans. Indeed,
316

fiStructure Complexity Planning Unary Operators

Williams Nayak pessimistic prospects generating whole plans quickly
even Burton, i.e., problem instances serializable sub-goals single-effect
operators. results show, pessimism fully justified.
work continues study planning unary operators. apparently easier
problem fact hard general strips planning problem (Bylander, 1994). However, obtain finer distinctions positive results pay closer attention
causal structure domain. example, easy show causal
graph tree, easy determine serializability ordering set sub-goals,
consequently, obtain plan polynomial time. paper analyze relationship domains causal graph complexity plan generation plan
existence. particular prove following results:
causal graph forms polytree (the induced undirected graph acyclic),
node indegree bounded constant, plan existence plan generation
polynomial.
causal graph directed-path singly connected (there one directed
path pair nodes), plan existence np-complete.
general, plan generation problems acyclic causal graphs provably
intractable, i.e., problem requires exponential time. corresponding claim
derived previous result Jonsson Backstrom (1998b). However,
show complexity plan generation problems bounded
function number paths within causal graph.
Note complexity problems polytree causal graphs unbounded
node indegree remains open problem still shown whether solved
polynomial time, np-complete.
Finally, relate results old open question: difficult generate
plans problems serializable subgoals (Korf, 1987)? question stated
Bylander (1992), different hypotheses raised different researchers. Here,
present clear, though somewhat disappointing answer: First, results suggest even
underlying causal graph problem acyclic (and thus problem known
serializable), finding serialization ordering problem subgoals may hard.
Second, show even actual serialization ordering subgoals known,
solving problem necessarily easy.
rest paper organized follows: Section 2 first introduce
basic formalism used paper, discuss, motivate illustrate notion causal
graph. Sections 3 4 present results relation form
causal graph complexity planning problem. Section 5 discuss
sub-goal serializability issue impact results it. Section 6 describe
related work complexity planning, connect work previous
results. summarize Section 7. Finally, Appendix provides short review
POP algorithm (Penberthy & Weld, 1992), Appendix B provides proofs.
317

fiBrafman & Domshlak

2. Basic Formalism Causal Graphs
paper consider propositional planning problems, using propositional
strips negative goals formalism (Bylander, 1994), positive negative
preconditions allowed. Following Backstrom Klein (1991b), distinguish
preconditions prevail conditions. former case variable involved changes
value operator executed, latter case value change.
post-condition operator expresses state variables changes values
variables executing operator. pre-condition specifies
values changed variables must operator executed. prevail
condition specifies unchanged variables must specific value
execution operator values are. Hence, prevail conditions,
visa, needed order apply operator, Enter-USA,
values change operator applied. Finally, assume operator
applicable pre- prevail conditions satisfied.
Formally, assume problem instance given quadruple = hV, , Init, Goali,
where:
V = {v1 , . . . , vn } set propositional state variables, one associated
binary domain D(vi ). domain D(vi ) variable vi induces extended domain
D+ (vi ) = D(vi ) {u}, u denotes unspecified value.
Init initial, fully specified state, i.e. Init D(v1 ) . . . D(vn ).
Goal set possible goal states. assume set specified partial
assignment V, thus Goal D+ (v1 ) . . . D+ (vn ).
= {A1 , . . . , } finite set operators form hpre, post, prvi,
pre, post, prv D+ (v1 ) . . . D+ (vn ) denote pre-, post-, prevail condition,
respectively. follows, pre(A), post(A), prv(A) denote corresponding conditions operator A, pre(A)[i], post(A)[i], prv(A)[i]
corresponding values variable vi .
every vi V, must either pre(A)[i] = u prv(A)[i] = u. Further,
post(A)[i] 6= u pre(A)[i] 6= u, case post(A)[i] 6= pre(A)[i].
paper analyse planning problems unary operators. Therefore,
follows, assume that, operator , that:
1. exists variable vi V, pre(A)[i] 6= u,
2. variable vj V {vi }, pre(A)[j] = u.
Note specifying pre- postconditions case propositional variables
redundant, use simplify presentation. Likewise, assumption
post(A) 6= u implies pre(A) 6= u different usual strips formalism, requires
exponential time translation general. However, case unary operators,
translation takes linear time.
318

fiStructure Complexity Planning Unary Operators

2.1 Causal Graphs
Causal graphs used Williams Nayak (1997) tool describing structure
planning domains unary operators. represent dependence relation
state variables domain. causal graph G directed graph whose nodes
correspond state variables. edge p q appears causal graph
operator changes value q prevail condition involving
value p. Hence immediate predecessors q G variables
affect ability change value q. problem structure introduced
Knoblock (1994) context automatic generation abstractions planning.
causal graph intuitive model easily constructed given planning problem.
Causal graphs graphical structure derived given
planning problem, effectively exploited solving it. instance, graphs
operators literals (and variables/propositions) represented nodes,
edges represent prevail preconditions introduced Etzioni (1993) Smith
Peot (1993). particular, problem space graphs Etzioni (1993) operator graphs
Smith Peot (1993) proposed mechanisms reduce number threats
arise total-order partial-order planning, respectively. However,
paper focus causal graphs, since shown especially informative
operators unary (Jonsson & Backstrom, 1998b; Williams & Nayak, 1997).
Causal graphs important potential role design autonomous industrial
systems, argued demonstrated Williams Nayak (1997): Unary operators
natural manipulated objects hardware components, since basic control
actions systems change state single hardware component. applicability
control actions state depends state affected component
well state related hardware components. naturally gives rise
planning domain unary operators. Moreover, since state variables correspond
hardware components, induced causal graph typically see prevail
dependencies variables usually implicitly entailed inter-composition
hardware components. Thus, causal graph domains resembles structure
relationships systems hardware components. resemblance
important practical ramifications system design given relationship causal
graph structure complexity plan generation: enables system designer
consider effect hardware design systems ability autonomously generate
control sequences.
case point planning problem studied Williams Nayak (1997),
number important features: operators unary reversible, causal
graph acyclic. Williams Nayak argued acyclic connectivity frequently occurs
designed systems. However, requirement operators reversible seems
us restrictive, important impact complexity problem.
case Burton planner (Williams & Nayak, 1997), good reasons make
assumption. Burtons reactive nature precludes extensive deliberation consequences
operators. Thus leaves open possibility operators may degrade systems
capabilities, leading dead-ends. case, restriction reversible operators
319

fiBrafman & Domshlak

required order achieve reliable system. show later, certain cases,
complete plans generated efficiently even operators reversible.
Williams Nayaks work another interesting aspect, noted Weld (1999).
long time, researchers known planning problems serializable subgoals
likely easier solve. Williams Nayak recognized spacecraft configuration task serializable (many real-world problems not), and, importantly,
developed fast algorithm computing correct order based fact
underlying causal graph acyclic. However, algorithm makes heavy use
fact operators reversible. Informally, reversibility implies solve
subgoals one one long consistent topological order causal
graph without taking account global considerations: side-effect always
undone. Without assumption operator reversibility, relatively easy show
Williams Nayaks algorithm works causal graph forms directed chain.
Even causal graph tree, although problem easy, one must take care
choice subgoal achieve next operators reversible. show
later, structure causal graph complicated directed tree
either problem hard or, not, sophisticated algorithm required.
Finally, note existence reversible operators might make problem seem
easier actually is. paper present example propositional planning
problem unary operators, acyclic causal graph, totally reversible operators,
minimal solution exponentially long size problems description.
2.2 Example
order illustrate notion causal graph, consider following example, inspired
work Williams Nayak (1997) controlling main engine subsystem
Cassini spacecraft, general, valve driver circuitry, particular.
valve V L (on/off) controlled valve driver V LD (open/close), safety
control unit SCU (safe/unsafe). driver controls exactly one valve, safety
control unit control several valves. Commands driver sent via driver
control unit, consist two switches, l r , either off.
activating states l r described below. valve reacts (by state change)
command driver (i) instruction actually involve state change
(i.e., open valve reopened), (ii) safety control unit indicates
manipulating valve safe. addition, valve closed safety control unit
indicates unsafe situation. simplicity presentation, Table 1 presents operator
set controlling valves valve drivers only. dashed boxes stand driver
control units, two switches each.
suppose valves V L1 V L2 , drivers V LD1 V LD2 , respectively, controlled shared safety control unit SCU . Given operator set
Table 1, causal graph controlling subsystem presented Figure 1.

3. Polytree Causal Graphs
Starting section, show how, bounding structural complexity causal
graph, bound complexity plan generation. Recall use propositional
320

fiStructure Complexity Planning Unary Operators

Affected component
V LD
VL

pre
close
open

f


post
open
close
f

f

prv
Sl = 1 Sr = 0
Sl = 0 Sr = 1
V LD = close SCU = saf e
V LD = open SCU = saf e
SCU = unsaf e

Table 1: subset operator set valve circuitry controller example.
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _




S1r

S1l




EE
ww
E

_ _ _ _ _EEE_ _ _ _ _ _www_w _ _ _ _
EE
w
w
E"
{ww

V LD1

GG
G#

SCU

HH
HH
HH
HH
H#



S2r
S2l G
G

G



_ _ _ _ _GGG_G _ _ _ _ _ yy_y _ _ _ _



w
ww
ww
w
w
w{ w

V LD2

GG
GG
GG
GG
G#

V L1

yy
|yy

vv
vv
v
vv
v{ v

V L2

Figure 1: Causal graph example.
language (binary variables) describe state world, operator described
prevail conditions, single precondition, single effect (or post-condition).
precondition effect two literals, one negation other.
causal graph forms polytree single path every pair nodes
induced undirected graph1 , i.e., induced undirected graph tree. example,
causal graph presented Figure 1 forms polytree. class problems present
planning algorithm polynomial indegree nodes causal graph
bounded constant. argue assumption reasonable prevail dependencies reflect inter-composition controlled hardware components (Williams &
Nayak, 1997).
Given propositional planning instance polytree causal graph, we:
1. Provide general upper bound number times variable may required
change value valid, irreducible plan.
2. Using general upper bound, provide polynomial time procedure, called determinemax-sequence, that, given variable v, determines actual maximal number
times v change value valid, irreducible plan.
3. Provide preprocessing algorithm that: (a) determines whether plan
given problem instance class exists, (b) performs substantial amount
1. graphs also known singly connected DAGs.

321

fiBrafman & Domshlak

preprocessing subsequent step plan generating. algorithm based
top-down execution determine-max-sequence variables given
problem instance.
4. answer plan existence check positive run particular deterministic instance POP algorithm2 (Penberthy & Weld, 1992), called pop-pcg,
generates required plan using information provided preprocessing
algorithm, without backtracking, linear time.
Informally, process based following properties planning problems
polytree causal graph. First, bound achieved step 1 necessary steps 2-3,
main steps technique. itself, bound valid
polytree, wider class directed-path singly connected causal graphs. However,
steps 2-3 valid polytree causal graphs only, following properties
form dependence relation variables:
(i) Given variable v V, changing value parent (immediate predecessor)
w pred(v) require changes neither parents v,
predecessors causal graph.
(ii) number times variable v able change value along valid
plan given problem instance depends directly numbers pred(v),
actual ordering value changes pred(v).
(iii) (i) follows possible orderings value changes pred(v)
legal. addition, shown chosing ordering value changes
pred(v) affect ability change value variable except v.
(iv) crucial part process (steps 2-3) basically finding right ordering
right number value changes pred(v) variable v V. synchronizing
changes vs parents appropriately, increase number possible
changes v.
start notation. First, valid plan P given planning instance
called irreducible subplan P 0 P plan , following sense:
Removal subset (not necessarily subsequent) actions P makes resulting
plan either illegal, initial state Init, goal state one states
specified Goal. notion irreducible plans introduced Kambhampati (1995),
exploited admissible pruning partial plans search3 .
2. short review POP algorithm, corresponding formalism provided Appendix A.
familiar algorithm, note one slight technical change, stemming use unary
operators. POP uses two fictitious actions A0 capture initial goal state, respectively.
Here, replace actions set actions, single effect. (fictitious) action
setting initial value variable vi denoted A0i fictitious action whose precondition
goal value variable vi denoted Ai .
3. Irreducible plans called (Kambhampati, 1995) minimal plans. However, decided change
name concept order prevent ambiguity minimal irreducible minimal
optimal.

322

fiStructure Complexity Planning Unary Operators

Now, given planning instance , let P set irreducible plans .
denote MaxReq(v) maximal number times variable v V changes value
course execution irreducible plan . Formally, let Req(P, v) number
times v changes value course execution plan P . Then,
MaxReq(v) = max{Req(P, v)}
P P

Observe that, planning problem unary operators, variable must change
value required change immediate successors causal
graph (in order satisfy necessary prevail conditions), order
obtain value requested goal. Thus, variables V, MaxReq(v) satisfies:
X
MaxReq(v) 1 +
MaxReq(u)
(1)
succ(v)

succ(v) denotes immediate successors v corresponding causal graph.
Adopting terminology (Domshlak & Shimony, 2003; Shimony & Domshlak, 2002),
directed acyclic graph G directed-path singly connected if, every pair nodes s, G,
one directed path t. following lemma shows causal
graph forms directed-path singly connected DAG bound MaxReq(v) n.
Clearly, polytrees directed-path singly connected DAGs, vice versa.
Lemma 1 solvable problem instance directed-path singly connected causal
graph n variables, variable v, MaxReq(v) n.
Proof: proof induction n. n = 1 obvious MaxReq(v) 1.
suppose |V| = n 1 v V,
MaxReq(v) n 1
Let 0 problem instance |V 0 | = n. Suppose variables V 0 =
{v1 , . . . vn } topologically ordered based domains causal graph. Clearly, vn
leaf node (i.e., succ (vn ) = ). denote problem instance obtained
removing vn domain, corresponding variable set V. According Eq. 1,
immediate predecessor v vn causal graph,
newMaxReq(v) MaxReq(v) + newMaxReq(vn ) MaxReq(v) + 1
newMaxReq(v) denotes MaxReq(v) respect 0 . Generally, since causal
graph directed-path singly connected, variable v V 0 ,

MaxReq(v) + 1, path v vn
newMaxReq(v)
(2)
MaxReq(v),
otherwise
thus, v V 0 , holds
newMaxReq(v) n

323

fiBrafman & Domshlak

Recall MaxReq(v) stands upper bound number value changes v
may required valid, irreducible plan. However, maximal achievable number
value changes v, denoted MaxPoss(v) greater less MaxReq(v).
example, v predecessors causal graph, two operators affecting
v differently, MaxPoss(v) = .
denote upper bound feasible number value changes v may
required valid, irreducible plan FMaxReq(v). Informally,
MaxPoss(v) value changes v required MaxReq(v) value changes
v required, thus
FMaxReq(v) = min(MaxPoss(v), MaxReq(v))

(3)

Determining FMaxReq(v) variables requires explicit examination given problem instance. Recall restrict causal graph form polytree.
simplify presentation, assume goal values specified state variables,
i.e. Goal D(v1 ) . . . D(vn ). Later show assumption affect
generality algorithm. Denote v 0 v initial goal values v ,
v set operators affecting v. First examine root variables
causal graph, analyze rest variables.
Denote pred(v) immediate predecessors v causal graph. pred(v) = ,
+
+

two operators
v , Av v : Av v postcondition,

Av reverse effect. Since operators prevail condition,
v
+
Av presented , applied one another infinite number
+
times. Therefore, Eq. 3, FMaxReq(v) = n. v 6= {A
v , Av } two cases:
initial goal values v same, cannot change value v
reconstruct later, thus FMaxReq(v) = 0. Alternatively, initial goal
values v different v = {A+
v } achieve goal value v
thus FMaxReq(v) = 1. Otherwise, goal value v unachievable, thus
given problem instance unsolvable. Table 2 summarize analysis.

v0
v0

=

v

6=

v

v

{Av , A+
v}
otherwise
+
{A
v , Av }
+
{Av }
otherwise

FMaxReq(v)
n
0
n
1
solution

Table 2: FMaxReq(v) values root variables causal graph.
consider variable v presented internal node causal graph:
pred(v) = {w1 , . . . , wk } =
6 . Observe number possible value changes v depends
on:
1. initial goal values v, i.e., v 0 v .
324

fiStructure Complexity Planning Unary Operators

2. set operators affecting v, i.e., v .
3. maximally possible (but still reasonable) number times predecessors v
change values, i.e., FMaxReq(w1 ), . . . , FMaxReq(wk ).
4. actual scheduling value changes predecessors v.
last point crucial means order determine FMaxReq(v) find
particular scheduling value changes pred(v) allows maximal number
value changes v. corresponding interleaving sequence vs values, starting
finishing v 0 v respectively, FMaxReq(v) value changes called maximal
denoted (v) (|(v)| = FMaxReq(v) + 1).
Lemma 1, 1 k, FMaxReq(wi ) n, thus number different
orderings value changes pred(v) exponential n. instance, when,
1 k, FMaxReq(wi ) = n, number different orderings expressed
as:


k1
n
YX
n 1 ni + 1
2nk
j
j1
i=1 j=1

correctness expression left side inequality shown Lemma 4
(see Appendix B, p. 347). Clearly, cannot check orderings naive manner.
Following, provide algorithm determines (v) time polynomial n.
clarity presentation want distinguish different elements
maximal sequence (v). Since variables binary, denote initial value v, v 0 ,
bv opposite value wv (black/white). Similarly, bi wi stand
corresponding values variable vi . so, think operators
described language. Likewise, sequentially number appearances
value v (v). example, biv stands ith appearance value bv along
(v). illustrate notation, suppose D(v) = {true, f alse}, initial value v
v 0 = true, FMaxReq(v) = 4. Then, have:
bv true
wv f alse
(v) = b1v wv1 b2v wv2 b3v
First, every variable v, every operator v extended set operators
explicitly specify prevail values parents v causal graph: |pred(v)| = k,
prevail condition specified terms 0 k 0 k parents4
0
v, extended set 2kk operators, operator extends
instantiation previously unspecified parents v. example, consider variable v
pred(v) = {u, w}, operator
= {pre : {bv }, post : {wv }, prv : {bu }},
4. every parent wj v, prv(A)[j] = u.

325

fiBrafman & Domshlak

prevail condition involve w. operator extended pair
operators:
A0 = {pre : {bv }, post : {wv }, prv : {bu , bw }}
A00 = {pre : {bv }, post : {wv }, prv : {bu , ww }}

corresponding possible values w. follows, refer operator set
resulting compilation ./ . Note that, assumption constantly
bounded maximal indegree causal graph, compiling ./ takes polynomial
+1 , thus |./ | = O(n2+1 ).
time, since, every variable v, |./
v |2
Given maximal sequences (w1 ), . . . , (wk ) operator set ./
v construct
0
directed graph (denoted Ge (v)) captures (and only) feasible sequences of,
n, value changes v, value change annotated corresponding
assignment pred(v). Although number captured sequences exponential
n, size G0e (v) polynomial n. respect graph, problem finding
maximal sequence (v) reduced problem finding longest path given
node arbitrary node directed acyclic graph.
graph G0e (v) created three incremental steps. first step, given
maximal sequences (w1 ), . . . , (wk ) operator set ./
v construct directed labeled
graph G(v) capturing information sequences assignments pred(v)
enable n less value flips v. graph G(v) defined follows:
1. G(v) consist nodes,

n, ((n = 2j) (v 0 = v ))
((n = 2j + 1) (v 0 6= v )), j N
=

n 1, otherwise
2. G(v) forms 2-colored multichain, i.e., (i) nodes graph colored black
white, starting black; (ii) two subsequent nodes
color; (iii) 1 1, edges node node + 1.
Observe construction G(v) promises color last node
consistent v .
3. nodes G(v) denoted precisely elements maximal sequence
(v), i.e., biv stands ith black node G(v).
4. Suppose operators ./
v change value v bv wv .

case, i, edges biv wvi , |./
v | edges wv
bi+1
v . edges labeled prevail conditions corresponding operators,
i.e., k-tuple values w1 , . . . , wk . tuple denoted l(e) (label
edge e) component, corresponding predecessor wi , denoted l(e)wi .
formal definition G(v) relatively complicated, thus provide demonstrating
example: Suppose given problem instance 5 variables, consider
326

fiStructure Complexity Planning Unary Operators

variable v pred(v) = {u, w}, v 0 = bv , v = wv . Recall every operator
./ presented three-tuple hpre, post, prvi pre-, post-, prevail conditions
operator respectively. Suppose that:
1
2
(u) = b1u wu1
(w) = b1w ww
b2w ww
1
Av = {pre : {bv }, post : {wv }, prv : {bu , ww }}
./
A2 = {pre : {wv }, post : {bv }, prv : {bu , bw }}
v =
v3
Av = {pre : {wv }, post : {bv }, prv : {wu , ww }}

case, graph G(v) presented Figure 2.
bu bw
bu ww /
b1v

wv1

bu bw

$
:

bu ww /
b2v

wv2

$

3 bu ww /

: bv

wv3

wu ww

wu ww

Figure 2: Example graph G(v).
constructed graph G(v) captures information potentially possible executions operators ./
v provide us MaxReq(v) less value changes v.
path, started source node G(v), uniquely corresponds execution.
Although number alternative executions may exponential n, graphical representation compact: number edges G(v) O(n |./
v |). Note
information number times operator ./

executed
v
captured G(v). following two steps add information indirectly exploit
find maximal sequence (v).
second step construction, expand G(v) respect maximal sequences (w1 ), . . . , (wk ) follows: edge e G(v) (which definition corresponds
operator ./
v ), replaced set edges labels correspond
possible assignments elements (w1 ), . . . , (wk ) l(e) (i.e., prv(A)). Likewise,
add dummy source node sv , edge sv original source node G(v)
labeled tuple first elements (w1 ), . . . , (wk ) (= initial values w1 , . . . , wk ).
Similarly, add dummy target node tv , edge original target node
G(v) tv labeled tuple last elements (w1 ), . . . , (wk ) (= goal values
w1 , . . . , wk ). denote extended graph G0 (v), Figure 3 illustrates G0 (v)
example above.
extended graph G0 (v) viewed projection maximal sequences (wi ),
1 k, graph G(v). edge G(v) may replaced O(nk ) edges G0 (v),
thus number edges G0 (v) O(nk+1 |./
v |).
easy see paths G0 (v) starting sv relevant. example,
G0 (v) above, operator instance prevailed b1u b2w performed operator
2 . Thus, faced problem finding longest
instance prevailed b1u ww
feasible path sv node G0 (v), label consistent v .
following (last) step provides reduction problem finding longest feasible path
sv v -colored node G0 (v) known problem finding longest path
327

fiBrafman & Domshlak

b1u b1w

b1u b1w
1
b1u ww

sv

b1u b1w

/ b1
v
2
b1u ww

&

b1u b2w
1
8 wv
1 w1
wu
w

%
2
9 bH v

1
b1u ww

2
b1u ww

1 w2
wu
w

&

b1u b2w
2
8 wv

%
3
9 bH v

1 w1
wu
w

1
b1u ww

&

3
8 wv

1 w2
wu
w

/ tv

2
b1u ww

1 w2
wu
w

Figure 3: Example graph G0 (v).
directed acyclic graph. Let graph G0e (v) edges G0 (v) nodes, let
edges defined allowed pairs immediately subsequent edges G0 (v): (e, e0 )
allowed if, 1 k, either l(e)wi = l(e0 )wi l(e0 )wi appears l(e)wi (wi ).
construction variant called edge graph known graph theory; addition
case exclusion non-allowed edges it. Clearly, G0e (v) constructed
2
time polynomial size G0 (v), number edges G0e (v) O(n2k+2 |./
v | ).
b1u b1w

b1 b1

2
wu1 ww

2
wu1 ww

u /w J
// JJ
// JJJ
// JJJJ
// JJJ
J
//
JJ
JJ
//
$
$
//
/
1
1
1
2
1
1
1
1
2
/
_
_
_
_
/
bu bw //
b1u ww
bu ww
bu ww
bu bw //
//77
77 /
JJ
7
//77
//
u:
JJ
77 //
7 /
u
//77
//77
JJ
u
/
/
77 /
7 /
JJ
// 77
// 77
u
J$
/
/
7
7
7
7
u
// 7
// 7
//
77 //
7
7
7
1
1
2
/
/
7
7
7
bu bw
wu1 ww
77 //
7 //
// 77
// 77
II
u:
77//
7 //
II
u
// 77
// 77
II
uu
77//
7 //
// 77
// 77
II
uu
u
/
/
7
7
7
7
I$
u
//
//

u

// w1 w1
// w1 w1
2
1 w2
1 w2
b1u ww
b
b
u wJ
u w
// u w
// u w
JJ
JJ
JJ
//
JJ
JJ ///
JJ /
JJ /
JJ /
J$
$

Figure 4: Example graph G0e (v).
Figure 4 presents G0e (v) example. dashed edges present longest path
dummy source node node corresponds value change v v
(from bv wv ). longest path G0e (v) describes maximal sequence value changes
(v), length actually FMaxReq(v) + 1. example, (v) = b1v wv1 b2v wv2 ,
FMaxReq(v) = 3. Note v 0 = v empty path also acceptable since,
general, v change value. case FMaxReq(v) = 0 (v)
consist one element corresponds initial (= goal) value v.
Observe longest path G0e (v) describes (v) also actual sequence
j
invocations operators ./
v provides (v). denote {A(bv )}
j
{A(wv )} sequences operator instances effects corresponding elements
sequences {bjv } {wvj } ({bjv } {wvj } = (v)) vs values, respectively.
follows, address sequences operator instances one sequence operator
328

fiStructure Complexity Planning Unary Operators

Procedure forward-check ()
1. Topologically sort variables V based causal graph.
2. variable v V, call determine-max-sequence(, v), respecting
ordering.
3. one calls determine-max-sequence return failure, return failure.
Otherwise return success.
Procedure determine-max-sequence (, v)
1. pred(v) =
(a) v 0 6= v A+
v 6 v , return failure.
(b) Otherwise, determine (v) according rules Table 2, return success.
2. Otherwise, pred(v) = {w1 , . . . , wk }
(a) Construct G(v) (based v 0 , v , ./
v ).
(b) Construct G0 (v) (from G(v), based (w1 ), . . . (wk )).
(c) Construct G0e (v) (from G0 (v), based (w1 ), . . . (wk )).
(d) Determine longest path G0e (v) node corresponding v -ended value
change, derive (v) corresponding sequence operators it.
(e) v 0 6= v FMaxReq(v) = 0, return failure. Otherwise, return success.
Figure 5: forward-check algorithm
FMaxReq(v)

instances v = {A(vi )}i=2

vi

=




, A(vi ) vi effect,
i+1

bv 2 ,

2

w ,
v

= 2k + 1

kN

= 2k

Procedure forward-check Figure 5 summarizes presented approach. Note
finding set longest paths node nodes directed acyclic graph
done time linear size graph (Wiest & Levy, 1969). Therefore,
time complexity call determine-max-sequence procedure variable v
2
bounded size constructed graph G0e (v) thus O(n2k+2 |./
v | ). forwardcheck calls determine-max-sequence n times. Therefore, maximal node indegree
bounded constant , overall complexity algorithm O(|V|2+3 22+2 ),
i.e., polynomial size problem description.
Theorem 1 given problem instance polytree causal graph solvable
if, v V, forward-check succeeds constructing maximal sequence (v).
forward-check fails least one calls determine-maxsequence procedure fails. turn, call determine-max-sequence variable v
329

fiBrafman & Domshlak

Algorithm: pop-pcg (hA, O, Li, agenda, )
1. Termination: agenda empty, return hA, O, Li
2. Goal selection: Let hi , Aneed rightmost pair agenda (by definition,
Aneed one pre/prevail conditions Aneed ).
3. Operator selection:
(a) Aneed 6= Ai (i = ij ) Aadd = A(ij ) {A0i }.
(b) Otherwise:
i. Let = max { j | A(ij ) A}.
ii. vi consistent im (both associated color {b, w})
Aadd = A(im ), else Aadd = A(im+1 ).


4. Plan updating: Let L = L {Aadd Aneed }, let = {Aadd < Aneed }.
Aadd newly instantiated, = {Aadd } = {A0i < Aadd < Ai }
(otherwise remain unchanged).
5. Update goal set: Let agenda = agenda - {hi , Aneed i}. Aadd newly instantiated,
pre/prevail conditions Q, add hQ, Aadd agenda.
6. Threat prevention: Aadd = A(ij ), j > 1, then, A, s.t. ij1 belongs
prevail conditions A, add {A < A(ij )} O.
7. Recursive invocation: pop-pcg(hA, O, Li, agenda, ), agenda topologically ordered (based causal graph respect precondition part
pair).
Figure 6: pop-pcg algorithm
fails initial goal values v different way
change value v even once. Thus, forward-check fails, plan exists.
prove opposite direction proceed follows: define pop-pcg algorithm
(POP polytree causal graphs) show succeed without backtracking
forward-check succeeds.5 pop-pcg described detail Figure 6, works
follows: First, let us expand sequence operator instances A(i1 ) (A(b1i ))
stand dummy operator A0i . (Recall now, operators
form A(ij ) j > 1 defined.) algorithm maintains goal agenda sorted based
causal graph structure: parent variables appear descendents.
point, next agenda item selected; requires achieving value vi add
corresponding operator plan desired effect (step 3a). Actually, would
ready accept plans possible redundant steps, omit next step 3b
algorithm assuming goal value variable v last element
5. short review POP algorithm, corresponding formalism, description initial
call algorithm, refer reader Appendix A.

330

fiStructure Complexity Planning Unary Operators

maximal sequence (v). However, would like plan irreducible, careful
decision really required number value changes variable required.
decision captured step 3b analysis value changes variable vi
found necessary previous iterations algorithm order satisfy
predecessors vi causal graph. Note agenda sorted respect
reverse topological ordering causal graph, thus operator affecting vi selected
agenda operator affecting predecessor vi causal graph
appear agenda end algorithm. threats arise pop-pcg,
ordering constraints consistent.
Lemma 2 forward-check successful pop-pcg return valid plan.
Proof:

lemma follow following claims:

1. every agenda item, exists operator effect.
2. threats output pop-pcg.
3. ordering constraints consistent.
4. agenda empty polynomial number steps.
proof see Appendix B, p. 343.
Recall that, simplicity presentation, assumed goal values specified
state variables (single goal state), i.e. Goal D(v1 ) . . . D(vn ). show
presented approach, minor modifications, works set possible goal states
well, set specified partial assignment V, i.e. Goal D+ (v1 ). . .D+ (vn ).
Note latter assumption widely accepted planning literature.
First, modifications done processing variables specified Goal.
Now, variable v, v specified Goal, modifications
follows:
1. graph G(v) consist exactly n nodes. correct since (i) according
Lemma 1, n changes v sufficient, (ii) value change v
last value change.
2. changes construction G0 (v) G0e (v).
3. procedure determine-max-sequence:
(a) step 2d, determine longest path dummy source node
node graph.
(b) step 2e, always return success.
Again, correct since value change v last value change, and,
particular, v may remain unchanged plan given problem.
Finally, pop-pcg algorithm starts null plan contains end operator
Ai vi specified Goal.
331

fiBrafman & Domshlak

4. Directed-Path Singly Connected General DAGs
section analyze planning complexity face complicated causal graphs.
First, show causal graph directed-path singly connected even plan
existence np-complete. Second, show general causal graphs situation
even worse. Finally, characterize important parameter causal graph affecting
planning complexity, allows us extend class problems np.
Theorem 2 Plan existence strips planning problems unary operators directedpath singly connected causal graph np-complete.
Proof:

proof see Appendix B, p. 346.

Note node indegree causal graph problem created proof
Theorem 2 bounded 6. hardness directed-path singly connected causal graphs
maximal indegree lower 6 thus open.
directed-path singly connected structure causal graph turns crucial
guaranteeing reasonable solution times. show, solvable propositional planning problems arbitrary acyclic (DAG) causal graph minimal
solutions exponential size. Analysis class problems points reason
provable intractability. allows us characterize important parameter causal
graph affecting planning complexity extend class problems np.
However, restricted problems still np-complete.
Theorem 3 Plan generation general strips planning problems unary operators
acyclic causal graph provably intractable, i.e. harder np.
theorem follows Theorem 5.4 (Jonsson & Backstrom, 1998b), shows
plan generation 3S problem class provably intractable. point
upper bound MinPlanSize, presented Eq. 5, exponential size input
case. First, show example upper bound achieved,
present analysis reasons intractability.
following example shows exponential upper bound achieved.
used proof Theorem 5.4 (Jonsson & Backstrom, 1998b), originally
presented different context Backstrom Nebel (1995). Consider propositional
planning problem |V| = n, where, 1 n, D(vi ) = {0, 1} pred(vi ) =
{v1 , . . . vi1 }. operator set consist 2n operators {A1 , A01 , . . . , A0n }
pre(Ai )[j] =

post(A0i )[j]


=

0 j =
u otherwise


1
pre(A0i )[j] = post(Ai )[j] =
u

0
0
1
prv(Ai )[j] = prv(Ai )[j] =

u
332

j =
otherwise
j < 1
j = 1
otherwise

fiStructure Complexity Planning Unary Operators

easy see causal graph problem forms DAG (see Figure 7),
instance planning problem initial state h0, . . . , 0i goal state
h0, . . . , 0, 1i unique minimal solution length 2n 1 corresponding Hamilton
path state space.
PQRS
WVUT
V1

PQRS
/ WVUT
V2

'

...

4

PQRS
WVUT
Vn1

&
PQRS
/ WVUT
Vn
7

Figure 7: Causal graph proof Theorem 3
show escalation complexity parametrized form
causal graph.
Lemma 3 solvable problem instance acyclic causal graph n variables, variable v, that:
MaxReq(vi ) 1 +

n
X

(vi , vj )

j=i+1

(vi , vj ) denotes total number different, necessary disjoint, paths vi
vj , variables ordered via topological sort causal graph.
Proof: proof induction i. = n obvious MaxReq(vn ) 1.
assume lemma holds > k, prove = k. Without loss
generality, assume succ(vk ) 6= . Otherwise, simply MaxReq(vk ) 1.
proof straightforward:
Eq. 1

MaxReq(vk )



X

1 +

MaxReq(vik )

vik succ(vk )
I.H.



X

1 + |succ(vk )| +

vik succ(vk )

=

1+

n
X

n
X

(vik , vj ) =

j=ik +1

(vk , vj )

j=k+1


Lemma 3 entails upper bound MinPlanSize() general planning problem
unary operators acyclic causal graph depends number different paths
nodes causal graph. immediate conclusion significant
class problems acyclic causal graph planning np. Let DAG
called max--connected number different directed paths every two nodes
graph bounded .
333

fiBrafman & Domshlak

Theorem 4 Plan generation strips planning problems unary operators max-connected causal graph np-complete polynomially bounded.
Proof: Membership np straightforward: variables given problem
considered topological ordering induced causal graph, Lemma 3 follows
that, variable vi , MaxReq(vi ) n. turn, follows MinPlanSize()
n2 , thus, polynomially bounded, guess minimal plan
could verified polynomial time.
hardness follows Theorem 2 shows even causal graph max-1connected (directed-path singly connected), plan existence (and thus plan generation)
hard.

5. Serializable Subgoals
set subgoals defined serializable (Korf, 1987) exists ordering among
subgoals subgoals always solved sequentially without ever violating
previously solved subgoal order. Naturally, collections subgoals
serializable sometimes may necessary interleave plans achieving different goals.
However, problem instance serially decomposable, possible design set
macro-operators respect subgoals serializable (Korf, 1985).
problem instance serially decomposable exists ordering state
variables effect operator state variable depends
state variable previous state variables ordering. Unfortunately, Bylander (1992)
shows determining serial decomposability problem pspace-complete.
One major open problem put forth Bylander context is: problem
known serially decomposable, difficult determine whether given instance
solvable? far know, work direction done Chalasani
et al. (1991), serial decomposability general permutation problem
considered. particular, showed problem np, unknown
whether np-hard. Recently, complementary results Bylanders question
presented Koehler Hoffmann (2000). results shed light question:
problem instance based unary operator domain whose causal graph acyclic
serially decomposable. Therefore, concluded finding solution serially
decomposable problems may require exponential time (i.e., problem exptime).
However, Bylanders question plan existence. case, Theorem 3
apply, apply np-hardness result (for directed-path singly-connected
graphs), since addresses plan existence well.
Weld (1999) hypothesized that: (1) underlying causal graph planning
problem acyclic, serialization ordering subgoals problem obvious;
(2) Serialized subgoals could solved extremely quickly backtracking required
them. Although first observation sounds intuitive, results suggest
rarely true. acyclicity causal graph implies serializability,
cases structure provide us sufficient information actual serialization
ordering. Even causal graph directed tree one must think first choosing
334

fiStructure Complexity Planning Unary Operators

ordering. Likewise, results imply causal graph form
undirected tree determining subgoal ordering np-complete, causal graph
directed-path singly connected, problem even complex.
second observation always true either. problem important
determine serialization ordering subgoals, also exact strategies
achieving them. showed, certain cases, problem n serializable subgoals
requires exponentially long solution. domain variables binary,
situation even worse corresponding complexity results derived
computational analysis Domshlak Dinitz (2001).

6. Connection Related Work Planning Complexity
idea analyzing exploiting structural properties new classical planning,
last years number important results emerged. Generating plans
context strips representation language shown Bylander (1994)
pspace-complete. Despite fact, existence many successful planning systems,
especially recent years, demonstrates planning possible practical wide list
domains. Bylander argues large gap theoretical hardness planning
practical success stems use domain-dependent problem analysis
algorithms. Consequently, various authors explored existence constrained
problem classes planning easier.
section shortly overview major, previous results complexity
planning, discuss relationship results presented paper.
detailed presentation previous results discussed refer reader
original papers.
6.1 Local Syntactical Restrictions
seminal paper, Bylander (1994) presents number complexity results propositional planning, analyzing different planning problems based type formulas used,
number type (positive/negative) operator pre- postconditions, etc. work
Bylander extended interesting, complementary results Erol al. (1995).
example, Bylander shows propositional planning domains operator
restricted positive preconditions one postcondition tractable. Generally, extremely severe restrictions operators required guarantee tractability,
even membership np. Note Bylander (1994) Erol et al. (1995) focuses local
syntactical properties operators, i.e., properties single operators.
syntactic restriction pose planning problems paper
unarity operators. Determining plan existence this, apparently easier class
problems shown Bylander hard general propositional planning, i.e.
pspace-complete. Note result entail Theorem 3, since
planning problems unary operators may induce causal graphs cycles. Therefore,
none results entailed results presented Bylander (1994) Erol et
al. (1995).
335

fiBrafman & Domshlak

6.2 Global Syntactical Restrictions
Backstrom Klein (1991a, 1991b), and, subsequently, Backstrom Nebel (1995),
consider types restrictions, using refined model (the SAS formalism)
which:
1. state variables multi-valued,
2. Two types preconditions considered: prevail conditions, variable
values required prior execution operator affected
operator, preconditions, affected operator.
general, four different restrictions considered works:
(P) Post-uniqueness: effect one operator achieves effect.
words, desired effects determine operators used plan. Formally,
problem instance post-unique if, vi V x D(vi ),
one operator post(A)[i] = x.
(S) Single-valuedness: one value state variable appears prevail
conditions operators. instance, certain operator requires light
(as prevail condition), operator use prevail condition
light off. Formally, problem instance single-valued iff exist
two operators A, A0 vi V prv(A)[i] 6= u, prv(A0 )[i] 6= u,
prv(A)[i] 6= prv(A0 )[i].
(U) Unariness: operator affects one state variable.
(B) Binariness: state variables exactly two possible values, i.e. state variables
propositional.
four properties syntactical. However, properties P differ
properties U B fact global nature: Post-uniqueness singlevaluedness restrict form operators, global property whole set
operators. Backstrom Nebel (1995) showed US (unariness single-valuedness)
extreme problem class plan generation polynomial. 6
problems analyzed paper belong problem class UB, definition. already mentioned, even determining plan existence class problems
pspace-complete. consider problem class PUB. Backstrom Nebel (1995)
showed that: (i) PUB instances exponentially long minimal solutions, thus plan
generation PUB requires exponential time; (ii) existence bounded length plans
PUB strongly np-hard; (iii) complexity general plan existence PUB still
open question. Informally means strengthening restrictions UB PUB
reduce complexity significantly, least practical point view.
Proposition 1 Every UB problem instance tree causal graph either post-unique,
transformed equivalent post-unique problem instance (low) polynomial
time. Thus, TreeUB PUB.
6. thorough analysis complexity SAS planning, refer Backstrom Nebel (1995).

336

fiStructure Complexity Planning Unary Operators

Proof: Consider UB problem tree causal graph, suppose postunique. means exist variable v V, D(v) = {v 0 , v 00 },
exist two operators A1 , A2 v change value v v 0 v 00 , prv(A1 ) 6=
prv(A2 ).
assumption causal graph forms tree follows |pred(v)| 1.
pred(v) = , easy see existence pair operators
simply impossible. Therefore, let pred(v) = {w}, D(w) = {w0 , w00 }. Without loss
generality assume prv(A1 )[w] = {w0 }, prv(A2 )[w] = {w00 }. Otherwise, if, instance,
prv(A1 )[w] = u, easy see A2 redundant operator.
Observe case, prevail dependence v w redundant: replace
pair operators A1 , A2 single operator changes value v
v 0 v 00 without prevail condition. replacement A1 , A2 brings us
equivalent problem instance operator set v post-unique. way
continue process iteratively problematic variables v arrive postunique problem instance.

Proposition 2 UB problem instances tree causal graph singlevalued, thus TreeUB 6 UBS.
Proof: proof Proposition 2 straightforward: Consider variable v V, D(v) =
{v 0 , v 00 }, succ(v) = {u, w}. case value change u
prevailed v 0 , value change w prevailed v 00 . Therefore, restricting
causal graphs even trees entail single-valuedness.7
Propositions 1 2 show TreeUB polynomial subclass PUB
entailed tractability results Backstrom Nebel (1995).
Proposition 3 UB problem instances polytree causal graph neither single-valued, post-unique.
Proof: proof straightforward: Consider planning problem polytree causal
graph, exist variable v V pred(v) = {u, w}, following
operator set v :
pre
v0
v0
v 00
v 00

post
v 00
v 00
v0
v0

prv
{u0 , w00 }
{u00 , w0 }
{u0 , w0 }
{u00 , w00 }

Clearly, problem instance v neither single-valued, postunique, since (i) one operator achieving value v, (ii)
values u (and values w) appear prevail conditions operators v . Note
7. Using simple construction technique proof Proposition 1 shown restricting
causal graphs directed chains entails single-valuedness. However, case restrictive.

337

fiBrafman & Domshlak

maximal indegree polytree minimal, i.e. equal 2. Thus,
proposition valid polytree tree.
Proposition 3 follows Theorems 1 4 introduce new polynomial
np-easy subclasses UB problem class, respectively.
6.3 Structural Restrictions Propositional Planning
Jonsson Backstrom (1998b) present 3S class planning problems. class
closely related problems examined paper, since defines special subclass
problems binary variables, unary operators acyclic causal graphs. 3S problem
class defined posing additional, relatively severe, restrictions problems
operator set: variable v 3S problem instance required either (i) static,
i.e., unchangeable; (ii) symmetrically reversible, i.e., operator affecting v,
exist operator A0 affecting v prevail conditions opposite effect;
(iii) splitting. formal definition splitting property refer Jonsson
Backstrom (1998b). Informally, binary variable v splitting problem
instance split three, well-defined subproblems solved independently.
class planning problems shown plan existence determined
polynomial time, plan generation provably intractable, since instances
3S exponentially long minimal solutions. particular, problem instance
used proof Theorem 3 3S.
complexity analysis Jnonsson Backstrom (1998b) somewhat unique
research complexity propositional planning, since, best knowledge,
attempt exploit syntactical restrictions operator set,
also structural restrictions interaction variables. analysis
seen continuing direction looking structural restrictions only.
believe eliminating marginal effect problem structure problems (potential) hardness allow us understand better connection component
interactions topology, potential complexity problem.
6.4 Structural Restrictions Multi-valued Formalisms
variables longer propositional, additional properties problems
identified, and, possibly, exploited. particular, additional internal structures
problem analysed.
Jonsson Backstrom (1998a) analyze different properties multi-valued problem
structure, called domain transition graph. structure defined
state variable problem, describes possible transitions different values
variable. domain transition graph state variable v directed labeled
graph Gv = (V, E), V associated vs set possible values, D(v),
(x, A, y) E operator applied state v = x,
application results state v = holds.
Jonsson Backstrom identify sets structural restrictions domain transition
graphs make planning instances tractable. Roughly, properties following:
(1) problem domain interference-safe, i.e., operator either unary irreplace338

fiStructure Complexity Planning Unary Operators

able respect every variable affects. operator irreplaceable respect
variable v removal edges Gv stem disconnects
weakly connected component Gv . (2) every variable v, graph Gv , restricted
set values appear prevail conditions operators, acyclic. (3)
sequence operators annotating path x domain transition graph v,
stronger shortest sequences connecting x y. Here, sequence A1 , . . . , Ak
stronger A01 , . . . , A0l subsequence Ai1 , . . . , Ail A1 , . . . , Ak
every 1 j l, prevail conditions A0j subset prevail conditions Aij .
Jonsson Backstrom present map computational complexity problems
different restrictions, displaying frontier tractable intractable cases.
domain transition graph combines structures influence many operators
particular variable. Therefore, provide us global picture operator
set alone. Hence, spite fact domain transition graphs capture relationship different variables, allow us express structural properties
address interactions variables (e.g., see property (2) above).
Observe domain transition graphs informative case propositional planning, since distinguish variables changed
one direction variables changed directions. Although
property domain transition graphs allows distinguish polynomial
planning positive postconditions, pspace-complete planning
positive negative postconditions (Bylander, 1994), seems helpful
hierarchical refinement propositional planning complexity. hand,
priori reason causal graphs informative multi-valued
case. Exploiting properties causal graphs, together properties domain
transition graphs, seems natural direction extend work presented paper.
recent work Domshlak Dinitz (2001) multi-entity off-line coordination
seen investigating connections structure causal graph, together
properties domain transition graphs, complexity corresponding
problems case multi-valued domains. best knowledge,
work done respect mixed structural analysis, lot work
remains done. instance, combining various properties domain transition
graphs studied Jonsson Backstrom (1998a), properties problems
causal graph direction research.

7. Summary Future Work
shown form causal graph strips planning problems unary
operators important factor determining computational complexity plan generation. particular, shown polynomial time algorithm exists
problem polytree causal graph node indegree bounded constant.
generally, result shows planning polytree causal graphs (what
often referred Bayes nets literature as) locally exponential, i.e., exponential maximal number parents node. Note hardware-control planning
problems maximal node indegree expected small, since prevail dependencies
variables reflect direct interconnections corresponding hard339

fiBrafman & Domshlak

ware components. Likewise shown problem directed-path singly
connected causal graph maximal plan length low order polynomial, problem
np-complete. generally, shown relation number paths variables causal graph computational complexity corresponding
planning problem. Finally presented impact results question
complexity planning problems serializable subgoals, connected work
previous results planning complexity.
work leaves number open questions respect purely syntactical,
mixture structural syntactical restrictions planning problems unary
operators. former case, one important directions analysis
causal graphs constantly bounded node indegree. turns complexity analysis class problems helpful understanding various computational
properties CP-nets (Boutilier et al., 1999). Although provided partial answer
question, general picture worst-case complexity class problems
clear. example, indegree causal graph known bounded
2, structural property causal graph, even clear whether
problem subclass np.
latter case, various syntactical restrictions analysed together form
causal graph. example, one may interested computational properties
problems acyclic causal graphs, restriction every operator
prevail conditions, bounded constant. This, well many
related questions respect various special cases planning unary operators
interest future work.

Acknowledgments
preliminary version paper appeared Sixth International Conference Artificial Intelligence Planning Scheduling, April, 2002. would like thank three
anonymous reviewers extremely helpful comments. Ronen Brafman supported
part Paul Ivanier Center Robotics Research Production Management.

340

fiStructure Complexity Planning Unary Operators

Appendix A. Short Review POP, Causal Links Threats
represent plan tuple: hA, O, Li, set unary operators, set
ordering constraints A, L set causal links. example, = {A1 , A2 , A3 }
might set {A1 < A3 , A2 < A3 }. constraints specify plan
A3 necessarily last operator, commit particular order A1 A2 .
Naturally, set ordering constraints must consistent, i.e., must exist

total order satisfying them. causal link form Ap Ac , Ap Ac
operators possible value propositional variable vi . denotes fact
Ap produces (i.e., postcondition) vi = consumed Ac (i.e., used
satisfy pre- prevail-condition Ac ). Causal links help us detect whether one operator
interferes work done enable execution operator Ac .
case, said constitute threat one A0c causal links. Formally, suppose


hA, O, Li plan, Ap Ac causal link L. Let different operator A.


say threatens Ap Ac following two criteria satisfied:
{Ap < < Ac } consistent,
effect.
partial order plan P contains threats, possible goal
achieved (or all) total order plans consistent P ordering constraints.
prevent this, plan generator must check threats remove adding one
two possible ordering constraints: < Ap (demotion) Ac < (promotion).
tutorial introduction POP algorithms found (Weld, 1994). POP
regressive framework partial order planning starts null plan continuously updates inserting new actions removing threats. process continues
precondition prevail conditions every operator plan supported
causal link threats exist. first argument POP plan second
argument agenda goals need supported causal links. item
agenda represented pair hi , Ai either pre- prevail condition plan
action A. last argument POP whole collection operators defined
planning instance. initial call POP contains null plan, specially initialized
agenda, operator set given problem.
paper introduce specialized, deterministic POP algorithm starts
planning process using variant null plan encodes planning problem.
particular, planning instance v1 , . . . , vn goal corresponding null
plan exactly 2n dummy unary operators, = {A01 , . . . , A0n , A1 , . . . , }, n ordering
constraints, = {{A01 < A1 }, . . . , {A0n < }}, causal links, L = {}. every
vi V, A0i corresponding start operator - neither pre- prevail conditions,
effect specifies value variable vi initial state, denoted
vi0 . Similarly, Ai end operator - effect, prevail conditions,
precondition set value vi goal state, turn denoted vi .8
8. Actually, goal state may specify values variables, thus number end
operators less n. However, clarity presentation, leave definition null
plan.

341

fiBrafman & Domshlak

description null plan modified Weld (1994) better suit
restriction unary operators. Likewise, initial call POP algorithm contains
agenda {hv1 , A1 i, . . . , hvn , i}.

342

fiStructure Complexity Planning Unary Operators

Appendix B. Proofs Auxiliary Results
Lemma 2 forward-check successful pop-pcg return valid plan.
Proof:

lemma follow following claims:

1. every agenda item, exists operator effect.
2. threats output pop-pcg.
3. ordering constraints consistent.
4. agenda empty polynomial number steps.
(1+4) first claim follows success forward-check procedure.
forward-check implies ij (vi ) operator instance A(ij )
{A0i }. Therefore, ij (vi ) existence appropriate Aadd promised.
Assume contrary ij 6 (vi ) and, without loss generality, assume
first iteration happens. so, variable u succ(vi ),
edge labeled ij graph G0 (u), created forward-check.
follows Aneed cannot ij prevail condition, thus Aneed affect
variable vi itself. case either Aneed = A(ij+1 ) Aneed = Ai .
Consider former case: Aneed = A(ij+1 ) ij+1 previously selected
agenda. assumption means ij+1 (vi ), contradicts assumption
ij 6 (vi ) since ij predecessor ij+1 (vi ).
consider last option Aneed = Ai . Aadd = A(ij ) goal value
variable vi consistent ij , A(ij1 ) (see Step 3(b)ii). A(ij1 )
ij1 previously selected agenda. assumption means
ij1 (vi ). However, contradicts assumption ij 6 (vi ) since (vi ),
definition, terminates node consistent goal value vi .
addition, since shown operators added
{A0i , Ai }, 1 n, agenda empty O(n2 ) steps.


(2) Suppose operator threatens Ap Ac , i.e.,
{Ap < < Ac } consistent,
effect.
given variable vi , pop-pcg forces operators affecting vi follows (Step 4):
A0i A(i1 ) < A(i2 ) < . . . < A(ix ),

x FMaxReq(vi )

(4)

Thus Ac operator prevail condition. Note Ap
affect variable vi . (1) already showed = ij (vi ).
case = A(il ), l > j. However, ij prevail condition Ac ordering
constraint {Ac < A(ij+1 )} added Step 6. Eq. 4, follows
343

fiBrafman & Domshlak

{A(il ) < A(ij+1 ), A(ij+1 ) < A(il )}, l > j, implied {Ap < < Ac },
contradicts assumption {Ap < < Ac } consistent.
(3) ordering constraints consistent two operators Ai Aj
implies {{Ai < Aj }, {Aj < Ai }}. follows, Ai used denote arbitrary
operator affecting variable vi .
First note ordering constraint added Step 4 Step 6 either
operators affecting variable operators affecting variable child
(with respect causal graph). particular, Ai < Aj added Step 4 either
vi = vj vi pred(vj ), whereas Ai < Aj added Step 6 vj pred(vi ).
Assume, contrary implies Ai < Aj Aj < Ai . argument
above, know a, possibly empty, path vi vj undirected
graph induced causal graph. structural assumption, know
undirected path vi vj unique, thus situation follows:
two chains operators
: Ai = A1i0 < . . . < Axi00 < A1i1 < . . . < Axi11 < . . . . . . < A1im < . . . < Aximm = Aj
: Ai = A1i0 > . . . > Ayi00 > A1i1 > . . . > Ayi11 > . . . . . . > A1im > . . . > Ayimm = Aj

that, 0 k m, xk 1 yk 1. corresponding unique undirected
path vi vj is:
vi = vi0 vi1 . . . vim1 vim = vj
Without loss generality, internal elements disjoint. Otherwise,
operator B belongs internal parts reduce
chains deduce Ai < B Ai > B.
proof consistency follows:
(a) prove exist least one least
one internal element.
(b) show useful property , exploited (c).
(c) show 0 k m, Axikk Ayikk different except x0 = y0 = 1.
Note (a) together (c) contradicts assumption Aximm = Ayimm .
(a) Assume, contrary, contain internal elements.
so, algorithm actually adds ordering constraints Ai < Aj Aj < Ai .
vi vj variable Ai < Aj stem Step 4
Ai precondition Aj effect. However, definition forwardcheck, Aj role w.r.t. Ai thus impossible Aj < Ai
added O. Alternatively, vi parent vj Ai < Aj stem Step 4
Ai prevail condition Aj effect. Suppose Ai = A(bji ) thus
bji prv(Aj ). turn, Aj < Ai added Step 6 Aj precondition
Ai prevail condition. bji prv(Aj ) Ai = A(wij ), contradicts
344

fiStructure Complexity Planning Unary Operators

assumption Ai = A(bji ). Alternatively, assume Ai = A(wij )
situation completely symmetric, thus result same. Hence proved
either contain least one internal element. particular means
next last elements different fact exploited later
proof.
(b) Consider subchains consist operators affecting one particular variable. subchain, i.e. 0 k m, 1 j xk 1, ordering
j
j+1
constraint Ajik < Aj+1
ik stem Step 4 Aik precondition Aik
effect. Thus, post(Ajik ) = pre(Aj+1
ik ). Similarly, subchains , 0 k
j
2 j yk , post(Aik ) = pre(Aj1
ik ). follows denote property
local monotonicity.
(c) First suppose either x0 > 1 y0 > 1, both. Consider following sequence:
: Ayi00 < Ayi00 1 < . . . < A1i0 = A1i0 < ... < Axi00
local monotonicity, construction forward-check, fact || 2
0
follows post(Ayi0 ) appears post(Axi00 ) maximal sequence vi0 . Continuing
1

next variable vi1 claim post(Ayi1 ) appear post(Axi11 ) vi1 .
(i) vi0 parent vi1 Axi00 < A1i1 stem Step 4 Axi00
prevail condition A1i1 effect. turn, Ayi00 > A1i1 stem Step 6
prevail condition A1i1 precondition Ayi00 . relation
Axi00 Ayi00 , construction G0e (vi1 ) forward-check, follows post(A1i1 )
appears post(A1i1 ) (vi1 ). Subsequently, local monotonicity follows
post(Ayi11 ) appears post(Axi11 ) (vi1 ).
(ii) Similarly, vi1 parent vi0 Ayi00 > A1i1 stem Step 4
A1i1 prevail condition Ayi00 effect, Axi00 < A1i1 stem Step 6
prevail condition Axi00 precondition A1i1 . relation
Axi00 Ayi00 , construction G0e (vi1 ) forward-check, follows post(A1i1 )
appears post(A1i1 ) (vi1 ), again, local monotonicity follows
post(Ayi11 ) appears post(Axi11 ) (vi1 ).
Alternatively, x0 = y0 = 1 Axi00 = Ayi00 = Ai . (a) immediately follows
A1i1 6= A1i1 , analysis similar shows post(Ayi11 ) appears
post(Axi11 ) (vi1 ).
established post(Ayi11 ) appears post(Axi11 ) (vi1 ), apparent
inductive argument allow us show k > 0 post(Ayikk )
appears post(Axikk ) (vik ). Note particular means operators
Axikk Ayikk different, contradicts assumption Aximm = Ayimm .

345

fiBrafman & Domshlak

Theorem 2
Plan existence strips planning problems unary operators
directed-path singly connected causal graph np-complete.
Proof: First show membership np. Let MinPlanSize() denote size
minimal plan problem instance . Using MaxReq property state variables,
following upper bound MinPlanSize() straightforward Lemma 1:
X
MinPlanSize()
MaxReq(v) n2
(5)
vV

Thus, guess minimal solution given solvable problem, verify low
polynomial time.
proof hardness polynomial reduction 3-sat corresponding
propositional plan generation problem directed-path singly connected causal graph.
3-sat problem finding satisfying assignment propositional formula conjunctive normal form conjunct (clause) three literals.
Let F = C1 . . .Cn propositional formula belonging 3-SAT, let X1 , . . . , Xm
variables used F. equivalent propositional planning problem directedpath singly connected causal graph constructed follows: variable set V =
{X1 , X1 , . . . , Xm , Xm } {C1 , . . . , Cn }. variables Xi Xi predecessors
causal graph, thus pred(Xi ) = pred(Xi ) = {}. turn, 1 n, pred(Ci ) =
{Xi1 , Xi1 , Xi2 , Xi2 , Xi3 , Xi3 }, Xi1 , Xi2 , Xi3 variables participate
ith clause F. Finally, Init Goal consist false true assignments
variables V, respectively.
Let every operator presented three-tuple h{pre}, {post}, {prv}i pre, post,
prevail conditions respectively. Then, corresponding operator set specified
follows:
Xi

={

h{f }, {t}, {}i }

Xi

={

h{f }, {t}, {}i }

Ci

={

h{f }, {t}, {1i }i, h{f }, {t}, {2i }i, h{f }, {t}, {3i }i



ji (1 j 3) corresponds truth assignment variable Xij satisfies
ith clause F. Let Ci = (X1 X2 X8 ). 1i = {X1 = t, X1 = f }, 2i = {X2 =
f, X2 = t}, 3i = {X8 = t, X8 = f }.
illustrate proposed reduction consider following example. Formula F consist
3 clauses: (x1 x2 x3 ) (x1 x2 x4 ) (x2 x3 x4 ). causal graph
corresponding planning problem follows:
@ABC
GFED
@ABC
@ABC
GFED
GFED
@ABC
@ABC
@ABC
GFED
@ABC
GFED
x2 F GFED
x3
x1 F GFED
x4
x
x1
x3
::
- F 2 :
-- FF
;
{
H

::
-- FFF
- F :
{; {; H x8 x8 x8
:

;
{
:
F
F
H

:
-FF
{;
-

x8 x8
:
F
FF :::
-{; {; x8 x8 H H
F
FF :
:


;
{
8
x

F
-H
F :

F : {; {; {; x8 x8 x8
H
FFFF :::
-:
F
8
x
H

;
{
x8
FFF ::
-H

{; x8 {; x8 F x8 F: :
FF:: -
H

;
{
--
8
x
F : H
FF::-
{;
F# { x {; x8 x8
F#
{ x
@ABC
GFED
@ABC
GFED
@ABC
GFED
C1
C2
C3
346

@ABC
GFED
x4
x8 8x



fiStructure Complexity Planning Unary Operators

propositional planning problem single-effect operators underlying
directed-path singly connected causal graph. Clearly, Goal reachable ( solvable)
satisfying assignment F found. Thus, plan existence propositional
planning problems directed-path singly connected causal graphs np-complete.

Lemma 4 Given k ordered sequences 1 , , k n elements each, number [k]
different merges 1 , , k , preserving orderings induced 1 , , k elements, given by:


k1
n
YX
n 1 ni + 1
[k] =
(6)
j1
j
i=1 j=1

Proof: Considering merge operation k sequences iterative merge ,
2 k, already merged sequences 1 , . . . , i1 , easy see (k)
expressed as:
(
[k 1] [n(k 1), n] , k > 1
[k] =
(7)
1,
k=1
S[x, y] stands number different, order preserving merges two ordered
sequences sizes x (without loss generality, assume x y).
consider process merging two ordered sequences 0 , || | 0 |, as:
(i) partition 0 j sub-sequences,
(ii) partition l sub-sequences, j 1 l j + 1,
(iii) interleaving order preserving concatenation sub-sequences 0 .
First, observe 0 partitioned 1 j | 0 | sub-sequences. Second,
0 |1
j, numbers different partitions corresponding steps (i) (ii) |j1


||+1
, respectively. Finally, given pair partitions 0 , exist exactly
j
one possible interleaving order preserving concatenation step (iii). Therefore,
have:



X
y1 x+1
S(x, y) =
(8)
j1
j
j=1

combining Eq. 7 Eq. 8, arrive Eq. 6.

347

fiBrafman & Domshlak

References
Backstrom, C., & Klein, I. (1991a). Parallel non-binary planning polynomial time.
Proceedings Twelfth International Joint Conference Artificial Intelligence, pp.
268273, Sydney, Australia. Morgan Kaufmann Publishers.
Backstrom, C., & Klein, I. (1991b). Planning polynomial time: SAS-PUBS class.
Computational Intelligence, 7 (3), 181197.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Boutilier, C., Brafman, R., Hoos, H., & Poole, D. (1999). Reasoning conditional ceteris
paribus preference statements. Proceedings Fifteenth Annual Conference
Uncertainty Artificial Intelligence, pp. 7180. Morgan Kaufmann Publishers.
Bylander, T. (1992). Complexity results serial decomposability. Proceedings
Tenth National Conference Artificial Intelligence, pp. 729734, San Jose, CL. AAAI
Press.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69 (1-2), 165204.
Chalasani, P., Etzioni, O., & Mount, J. (1991). Integrating efficient model-learning
problem-solving algorithms permutation environments. Proceedings Second
International Conference Principles Knowledge Representation Reasoning,
pp. 8998, Cambridge, MA. Morgan Kaufmann Publishers.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333377.
Domshlak, C., & Dinitz, Y. (2001). Multi-agent off-line coordination: Structure complexity. Proceedings Sixth European Conference Planning, Toledo, Spain.
Domshlak, C., & Shimony, S. E. (2003). Efficient probabilistic reasoning Bayes nets
mutual exclusion context specific independence. Proceedings Sixteenth International FLAIRS Conference, Special Track Uncertain Reasoning, St.
Augustine, FL. AAAI Press. appear.
Erol, K., Nau, D. S., & Subrahmanian, V. S. (1995). Complexity, decidability undecidability results domain-independent planning. Artificial Intelligence, Special Issue
Planning, 76 (12), 7588.
Etzioni, O. (1993). Acquiring search-control knowledge via static analysis. Artificial Intelligence, 62 (2), 255301.
Jonsson, P., & Backstrom, C. (1998a). State-variable planning structural restrictions:
Algorithms complexity. Artificial Intelligence, 100 (12), 125176.
Jonsson, P., & Backstrom, C. (1998b). Tractable plan existence imply tractable
plan generation. Annals Mathematics Artificial Intelligence, 22 (3-4), 281296.
Kambhampati, S. (1995). Admissible pruning strategies based plan minimality planspace planning. Proceedings Fourteenth International Joint Conference
Artificial Intelligence, pp. 16271635, Montreal, Canada.
348

fiStructure Complexity Planning Unary Operators

Knoblock, C. (1994). Automatically generating abstractions planning. Artificial Intelligence, 68 (2), 243302.
Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings use
agenda-driven planning algorithm. Journal Artificial Intelligence Research,
12, 338386.
Korf, R. (1985). Macro-operators: weak method learning. Artificial Intelligence, 26 (1),
3577.
Korf, R. (1987). Planning search: quantitative approach. Artificial Intelligence, 33 (1),
6588.
Pell, B., Bernard, D., Chien, S., Gat, E., Muscettola, N., Nayak, P., Wagner, M., & Williams,
B. (1997). autonomous spacecraft agent prototype. Proceedings First
International Conference Autonomous Agents, pp. 253261, Marina del Rey, CL.
ACM Press.
Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order planner
ADL. Proceedings Third International Conference Principles Knowledge Representation Reasoning, pp. 103114, Cambridge, MA. Morgan Kaufmann
Publishers.
Shimony, S. E., & Domshlak, C. (2002). Complexity probabilistic reasoning (directedpath) singly connected (not polytree!) Bayes networks. submitted publication.
Smith, D., & Peot, M. (1993). Postponing threats partial-order planning. Proceedings
Eleventh National Conference Artificial Intelligence, pp. 500506, Washington,
D.C. AAAI Press.
Weld, D. S. (1994). introduction least commitment planning. AI Magazine, 15 (4),
2761.
Weld, D. S. (1999). Recent advances AI planning. AI Magazine, 20 (2), 93123.
Wiest, J. D., & Levy, F. K. (1969). Management Guide PERT/CPM. Prentice Hall.
Williams, B., & Nayak, P. (1996). model-based approach reactive self-configuring systems. Proceedings Thirteenth National Conference Artificial Intelligence,
pp. 971977, Portland, OR. AAAI Press.
Williams, B., & Nayak, P. (1997). reactive planner model-based executive.
Proceedings Fifteenth International Joint Conference Artificial Intelligence,
pp. 11781185, Nagoya, Japan.

349

fiJournal Artificial Intelligence Research 18 (2003) 83-116

Submitted 07/02; published 1/03

Learning Order BDD Variables Verification
Orna Grumberg
Shlomi Livne
Shaul Markovitch

orna@cs.technion.ac.il
slivne@cs.technion.ac.il
shaulm@cs.technion.ac.il

Computer Science Department
Technion - Israel Institute Technology
Haifa 32000, Israel

Abstract
size complexity software hardware systems significantly increased
past years. result, harder guarantee correct behavior. One
successful methods automated verification finite-state systems model
checking. current model-checking systems use binary decision diagrams (BDDs)
representation tested model verification process properties.
Generally, BDDs allow canonical compact representation boolean function (given
order variables). compact BDD is, better performance one gets
verifier. However, finding optimal order BDD NP-complete problem.
Therefore, several heuristic methods based expert knowledge developed
variable ordering.
propose alternative approach variable ordering algorithm gains
ordering experience training models uses learned knowledge finding
good orders. methodology based offline learning pair precedence classifiers
training models, is, learning variable pair permutation likely
lead good order. training model, number training sequences evaluated.
Every training model variable pair permutation tagged based performance
evaluated orders. tagged permutations passed feature extractor
given examples classifier creation algorithm. Given model
order requested, ordering algorithm consults precedence classifier constructs
pair precedence table used create order.
algorithm integrated SMV, one widely used verification systems. Preliminary empirical evaluation methodology, using real benchmark
models, shows performance better random ordering competitive
existing algorithms use expert knowledge. believe sub-domains models
(alu, caches, etc.) system prove even valuable. features
ability learn sub-domain knowledge, something ordering algorithm does.

1. Introduction
size complexity software hardware systems significantly increased
past years. result, harder guarantee correct behavior. Thus, formal
methods, preferably computerized, needed task.
One successful methods automated verification finite-state systems
temporal logic model checking (Clarke, Emerson, & Sistla, 1986; Queille & Sifakis, 1981).
Temporal logics suitable formalisms describing behavior program time.
model checking procedure receives finite-state model system specification
c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiGrumberg, Livne, & Markovitch

written temporal logic formula. returns yes model satisfies formula
(meaning system behaves according specification). Otherwise, returns
no, along counter example demonstrates bad behavior.
Model checking successful finding subtle errors various systems.
currently recognized hardware industry important component
development phase new designs. However, model checking procedures often suffer
high space requirements, needed holding transition relation intermediate
results.
One promising solutions problem use binary decision diagrams (BDDs) (Akers, 1978; Bryant, 1986) basic data structure model checking.
BDDs canonical representations boolean functions often concise size.
conciseness also yields efficiency computation time. Since straightforward
represent transition relation intermediate results boolean functions, BDDs
particularly suitable model checking. Today, existing industrial BDD-based verifiers, IBMs RuleBase (Beer, Ben-David, Eisner, & Landver, 1996) Motorolas
Verdict (Kaufmann & Pixley, 1997) used many companies development
infrastructure.
size BDD given function sensitive ordering variables
BDD. However, finding optimal ordering, yields smallest BDD given
function, NP-complete problem (Bollig & Wegener, 1996). Therefore, several heuristic
algorithms based expert knowledge developed variable ordering
hope reducing BDD size. Unfortunately, spite resources invested,
algorithms produce good enough variable orders. reason may
general rules used domain-specific knowledge exploited.
goal research develop learning techniques acquiring using
domain-specific knowledge variable ordering. assume availability one
training models. training models used off-line acquisition ordering experience
used ordering variables previously unseen model.
first present method converting ordering learning task concept
learning problem. concept set ordered variable pairs right
order. examples ordered pairs variables given training model. show
statistical method tagging examples based evaluated training orders present
set variable-pair features. result standard concept learning problem.
apply decision tree learning generate decision tree training model. used
unseen model, combine trees generate partial order used
generating required order. also present extension algorithm learns
context-based precedence relations.
algorithm integrated SMV (McMillan, 1993), backbone
many verification systems. Empirical evaluation methodology, using real benchmark
models hardware designs, shows performance much better random ordering
competitive existing algorithms use expert knowledge.
Section 2 contains background model checking. Section 3 presents main algorithm
empirical evaluation. Section 4 shows context-based algorithm. conclusions
presented Section 5.
84

fiLearning Order BDD Variables Verification

2. Background
Model checking introduced Clarke Emerson (1986) Queille Sifakis
(1981) early 1980s. presented algorithms automatically reason
temporal properties finite state systems exploring state space. use binary
decision diagrams (BDDs) represent finite state systems perform symbolic state
traversal called symbolic model checking. use BDDs greatly extended
capacity model checkers. Models 2 100 states routinely verified.
BDDs introduced Akers (1978) compact representations boolean functions. Bryant (1986) proposed ordered binary decision diagrams (OBDDs) canonical
representations boolean functions. also showed algorithms computing boolean
operations efficiently OBDDs.
following subsection gives overview finite state systems represented
symbolic model checking. BDDs described variable ordering problem
defined. Existing algorithms static variable ordering algorithms reviewed. Finally,
brief description machine learning algorithms used ordering given.
2.1 Finite State Machines Symbolic Model Checking
Finite state systems (FSM) described defining set possible states
system transition relation states. state typically describes values
components (e.g., latches digital circuits), component represented
state variable. Let V = {v0 , v1 , ...vn1 } set variables system. Let K vi
set possible values variable v . state system described
assigning values variables V . set possible states
SA = Kv0 Kv1 .... Kvn1 .
state written using function true state:
Vn1
i=0

(vi == cj ),

cj Kvi value vi state. set states described function
disjunction functions represent states.
Figure 1 shows 3-bit counter. state 3-bit counter described
tuple gives assignment 3 variables v 2 , v1 , v0 . example, tuple h1, 0, 0i
represents state v2 = 1, v1 = 0, v0 = 0. corresponding boolean expression
state (v2 == 1) (v1 == 0) (v0 == 0).
order describe system, also need specify transition relation.
transition relation describes possible transitions system state. thus
described pairs states, hpresent state, next statei, next state system state
transition present state. variables V represent present state
variables, variable vi V define corresponding next state variable
vi0 V 0 . V 0 denote set next state variables.
example valid transition 3-bit counter h0, 0, 0i h0, 0, 1i.
boolean function represents transition (v 2 == 0) (v1 == 0) (v0 ==
0) (v20 == 0) (v10 == 0) (v00 == 1). transition relation represented
85

fiGrumberg, Livne, & Markovitch

V2

V1

V0

Figure 1: 3 bit counter
Present State
v2 v1
v0
0
0
0
0
0
1
0
1
0
0
1
1
1
0
0
1
0
1
1
1
0
1
1
1

Next State
v20 v10 v00
0
0
1
0
1
0
0
1
1
1
0
0
1
0
1
1
1
0
1
1
1
0
0
0

Table 1: 3-bit counter transition relation table
boolean function disjunction boolean functions transitions.
Table 1 shows transition relation 3-bit counter.
alternative method describing transition relation state variable
define valid next states. form known partitioned transition relation.
transition relation described set functions (instead one), one
variable. variable vi , boolean function Ti (V, vi0 ) defines next value vi , vi0 , given
current state system V .
synchronous systems, simultaneous transition system
components, transition relation

Vn1
i=0

Ti (V, vi0 ).

model checking common use partitioned transition relation form representation, since usually compact memory requirements thus allows handling
larger systems. 3-bit counter, next state boolean functions given below,
stands boolean operator Xor.

T0 (V, v00 ) : (v00 == v0 )
T1 (V, v10 ) : (v10 == (v0 v1 ))
T2 (V, v20 ) : (v20 == (v2 (v0 v1 ))).
86

fiLearning Order BDD Variables Verification

2.2 Binary Decision Diagrams
binary decision diagram (BDD) DAG (directed acyclic graph) representation
boolean function. BDD composed two sink nodes several non-sink nodes.
two sink nodes, labeled 0 1, represent corresponding boolean values. non-sink
node labeled boolean variable v two outgoing edges labeled 1 (or then)
0 (or else). non-sink node represents boolean function corresponding 1
edge v = 1, boolean function corresponding 0 edge v = 0.
ordered binary decision diagram (OBDD) BDD constraint
variables ordered, every root-to-sink path OBDD visits variables
ascending order.
reduced ordered binary decision diagram (ROBDD) OBDD node
represents distinct logic function. representation canonical BDD representation
compact representation possible given boolean function variable
ordering.
V2

V2

V2

V2

V1

V1

V1
V0
V0

0

0

0
0
0

0

0

1

0
1

0

0

0

0

1

0

0
1

0

0
1

0

0

0

0

1

1

0

0

V1
V0
V0

0
0

0

0

1

0
1

0

0

1

(a)

(b)

V2

V2

T2

V2

T2

V2

V1
V1
V0
V0

T1

V1

1

V1
V0
V0

T0
1
1
0

1

1

0

0

0

1

1

0

0
1

0

0
0

1

1
0

1

1

0

0

T1
T0
1
0
0

(c)

1

1

1

1

0

0

0

(d)

Figure 2: 3-bit counter transition relation (a),(b) partitioned transition relation (c),(d)

Figure 2 (a),(b) shows OBDD ROBDD (respectively) representations
transition relation function 3-bit counter. dashed lines 0 edges
solid lines 1 edges. ROBDDs two leaf nodes, one 1 one
0. drew several times enhance readability. ROBDDs also use complement
edges, produces even compact representation. use complement
edges, also reasons readability. Figure 2 (c),(d) shows OBDD ROBDD
representations partitioned transition relation 3-bit counter. variable
order v2 , v20 , v1 , v10 , v0 , v00 used representations. Variable ordering algorithms
model checking place next state variable v i0 adjacent present state variable v .
87

fiGrumberg, Livne, & Markovitch

rest document refer ROBDDs BDDs (unless explicitly state
otherwise).
Bollig Wegener (1996) proved finding optimal variable ordering NPcomplete problem. order optimal yields BDD smallest number
nodes. Bryant (1986) pointed variable ordering greatly influences size
BDD. showed boolean function, one variable ordering may yield BDD
exponential number variables, different ordering may yield BDD
polynomial size.
v1

v1

v3

v2

v2

v3

v4

v4

1

0

1

(a)

0
(b)

Figure 3: ROBDDs function F (v1, v2, v3, v4) = (v1 = v3) (v2 = v4)
Figure 3 gives example effect variable ordering BDD size function F (v1, v2, v3, v4) = (v1 = v3) (v2 = v4). (a) variable ordering v1, v3, v2, v4
(b) variable ordering v1, v2, v3, v4.
Various algorithms developed variable ordering. Exact algorithms (Ishiura,
Sawada, & Yajima, 1991; Drechsler, Drechsler, & Slobodova, 1998; Friedman & Supowit,
1987) algorithms find optimal order. algorithms use method similar
dynamic programming pruning find optimal order. Due complexity
problem, exact algorithms practical small cases, one usually
turn heuristic methods. heuristic methods roughly divided two
groups.
1. Static Ordering (Aziz, Tasiran, & Brayton, 1994; Butler, Ross, & Rohit Kapur, 1991;
Chung, Hajj, & Patel, 1993; Fujii, Ootomo, & Hori, 1993; Jain, Adams, & Fujita, 1998;
Fujita, Fujisawa, & Kawato, 1988; Malik, Wang, Brayton, & Sangiovanni-Vincentelli,
1988; Touati, Savoj, Lin, Brayton, & Sangiovanni-Vincetelli, 1990) try find
good ordering constructing BDD. algorithms based
topological structure verified system.
2. Dynamic Ordering (Rudell, 1993; Meinel & Slobodova, 1998; Bollig, Lobbing, & Wegener, 1995; Meinel & Slobodova, 1997; Meinel, Somenzi, & Theobald, 1997; Ishiura
et al., 1991; Bern, Meinel, & Slobodova, 1995; Fujita, Kukimoto, & Brayton, 1995;
Mercer, Kapur, & Ross, 1992; Zhuang, Benten, & Cheung, 1996; Drechsler, Becker,
88

fiLearning Order BDD Variables Verification

& Gockel, 1996; Panda & Somenzi, 1995; Panda, Somenzi, & Plessier, 1994),
given BDD variable order, reorder variables hope finding
smaller BDD.
model checking procedures, variable ordering central component. initial
phase model checking, system translated BDD representation, Static
Ordering used. order built stage greatly influences memory usage
whole computation. However, since model checking keeps producing eliminating
BDDs, variable order changed dynamically order effect size
current BDDs. Dynamic Ordering used order achieve goal. applied
model checking procedure whenever size BDDs reaches certain threshold.
Since work introduces static ordering algorithm based machine learning,
next subsection presents review existing static algorithms. algorithms
developed combinational circuits (i.e., models whose outputs depend
current inputs inputs previous cycles) described hardware
terminology. order simplify description, describe terminology
used far.
2.3 Static Ordering
Static ordering algorithms try find initial good order BDD. so,
extract topological data model use data determine order.
algorithms convert model, described set next state functions, directed
graph known model connectivity graph. Vertices graph variables
boolean operations (gates). variable vertex represents variable, gate vertex
represents function. edges ni nj graph ni , either
variable gate vertex, nj , gate vertex. edge ni nj placed
function represented ni operand (i.e., immediate subfunction) function
represented nj . divide static algorithms four groups differ
way use graph information.
2.3.1 Graph Search Algorithms
method suggested Malik et al. (1988) assigns vertex level metric orders
variables decreasing level value. level vertices edges set
zero level every vertex (v ) set level(vi ) = maxvj |vi vj (level(vj )+1).
method resembles BFS (breadth first search) originates nodes
edges, progresses backwards model. Fujita et al. (1988) proposed executing
DFS (depth first search) vertices edges, progressing backwards.
Variables algorithm added post order form.
algorithms Malik et al. Fujita et al. designed cases one
function represented BDD. hardly ever case model checking.
Butler et al. (1991) adapted algorithm Fujita et al. models multiple starting
points (that is, multiple vertices edges). heuristic guides algorithm
select first vertex vertex represents function depends
maximum number variables. heuristic also guides search advance (backwards)
89

fiGrumberg, Livne, & Markovitch

inner vertex vertex leads maximum number different variables.
tie breaking heuristic (Fujita, Fujisawa, & Matsunaga, 1993) enhanced algorithm
advises selecting (in case tie) vertex maximum number edges.
DFS-based methods append variables variable order. Another DFS-based
algorithm relies interleaving variables order (Fujii et al., 1993). algorithm
adds variable variable precedes DFS order.
2.3.2 Graph Evaluation Algorithms
Graph evaluation algorithms use model graph evaluate model variables
perform guided search based evaluation values. Minato et al. (1990) propagate
values backward graph, starting vertices edges, whose value
set 1. vertices boolean operations, values edges summed
value obtained divided equally edges. done recursively
vertex variable reached. variable vertices propagated values accumulated
variable evaluation value. order constructed iteratively adding variable
highest value, removing graph, updating values.
Chung et al.(1993) proposed two algorithm frameworks. first framework composed two sweeps. first sweep vertex assigned value. values set
propagating algorithm starts variable vertices edges advances
forward (by edges) vertices graph. second sweep guided
DFS initiated vertices edges executed. search executed backward
graph guided maximal value. means order traversal
among vertex ancestors according assigned value. number heuristics
compute values vertices proposed:
1. Level-Based sets value variables input edges zero. value
vertices set maximal vertex value inputs plus one.
2. Fanout-Based propagates two values graph (one boolean value).
boolean operation vertex values summed passed along. Rather,
computed according boolean operation vertex. initial values
variables input edges. value set number edges
variable has.
second framework proposed Chung et al., shortest distance
pair variables computed. total distance variable computed sum
distances variables. variable lowest total distance selected
first variable. next variable selected closest variable last ordered
variable. Ties broken according distance previous ordered variables.
graph evaluation algorithms try order variables variable
influences models next state functions first. algorithms differ
methodology use order variables. algorithms order
variables substantially influence models next-state functions placed higher
variable order (toward beginning order). algorithms place
variables according proximity previously ordered variables.
90

fiLearning Order BDD Variables Verification

2.3.3 Decomposition Algorithms
Decomposition algorithms break model parts. algorithms solve
two different problems. first finding good order part, second
finding order parts. order constructed combining solutions
two problems.
algorithm Malik et al. extended adapted finite-state machines (FSM)
Toutai et al. (1990). algorithm, model decomposed next state functions,
considered separately. Variables next state function ordered
according Malik et al. next state functions ordered cost function.
ordered functions many overlapping variables adjacent.
variable order obtained adding variables next state functions according
order parts, removing variables already exist.
algorithm Aziz et al. (1994) decomposes model different way. model
hierarchical composition constructed joining number internal parts
pass information among themselves. Usually, less communication among parts
within them. Variables internal part tend depend highly one another.
algorithm uses process communication graph (PCG), models hierarchical
structure model communication parts. PCG vertex
internal part, edge j connects vertex vertex j part j depends
bit part i. PCG parallel edges j, one bit value j depends
upon. Alternatively, edges could weighted.
Given order parts, upper bound BDD size model computed. computation based size parts amount communication
them. Heuristics guided upper bound applied order determine
order parts. order variables part decided one previous
ordering algorithms.
2.3.4 Sample-Based Algorithms
Sample-based static algorithms (Jain et al., 1998) real static algorithms
sense create order based information extracted model
description. Sample algorithms perform tests parts model (building transition
relations reachable states). part, number orders evaluated. good
orders merged create complete order model. Sampling algorithms use
traditional algorithms order find candidate orders parts. candidate
orders checked sampling algorithm.
2.3.5 Summary
majority graph search algorithms graph evaluation algorithms developed
problems adapted symbolic model checking. algorithms
developed context combinational circuits, others developed
simple case one function. symbolic model checking models rarely combinational
(their outputs almost always depend also inputs previous cycles),
one function display. Adapting existing algorithms conform needs
91

fiGrumberg, Livne, & Markovitch

symbolic model checking various degrees success. adapted algorithms
heuristic apply simple rule logical reasoning behind it.
decomposition algorithms either heuristic provide theoretical upper bound.
However, bounds use rarely realistic; models require much smaller
BDDs. algorithms also based decomposing model parts solving
ordering part using graph search algorithms. Thus, also inherit drawbacks
algorithms.
Despite efforts invested many algorithms
developed static ordering, results yet satisfactory. produced BDDs
large manipulate, dynamic ordering must applied. One problem
approaches generality: utilize domain-specific knowledge.
Domain-specific knowledge essential solving majority complex problems.
also difficult retrieve. next subsection discuss machine learning methods
acquiring domain-specific knowledge ordering tasks.
2.4 Learning Order Elements
Learning order elements done first trying induce partial order,
used generating total order. context, partial order usually called
preference predicate. Preference predicate induction based set tagged pairs
elements binary tag identifies preferred element. Broos Branting (1994)
present method inducing preference predicate using nearest neighbor classification.
distance untagged pair tagged pair computed sum
distances corresponding elements. closest tagged pair selected.
preferred element untagged pair one matching preferred element
tagged pair.
Utgoff Saxena (1987) represent pair A, B concatenated feature vector
ha1 , . . . , b1 , . . . bn i. preference predicate decision tree induced examples.
Utgoff Clouse (1991) represent preference predicate polynomial. Let =
ha1 , . . . , B = hb1 , . . . bn pair elements represented feature vectors. Let
w1 , . . . , wn set weights. preference predicate P defined follows:
P (A, B) =

(

n
1
i=1 wi (ai bi ) 0
0 otherwise

P

example represents linear constraint weights found solving set
constraints.
Cohen, Schapire Singer (1999) extended mechanism allowing
preference function fi instead (ai bi ) expressions. also present
two methods generating total order based induced preference predicate.
methods use preference predicate construct graph nodes elements
ordered directed edge placed two elements precedence
relation. Two algorithms inferring order graph given. first defines
node degree equals sum outgoing edges minus sum
incoming edges. order constructed selecting node greatest
92

fiLearning Order BDD Variables Verification

degree removing edges graph. second algorithm constructs order
two stages. first stage, strongly connected components graph
found, ordered according dependencies them. second
stage elements component ordered using first algorithm.

3. Learning Algorithm Static Variable Ordering
Producing good variable order requires extensive understanding BDDs relation
model represent. knowledge manually inserted human expert.
However, task complex large models. Therefore, rarely done. Existing
static ordering algorithms use relatively simple heuristic rules based expert
knowledge. rules look model structure compose ordering. Since
rules applied variables models, general thus limited
ability produce good orders. Alternatively, try build program
automatically acquires specific knowledge based ordering experience. section
present algorithm.
first step building learning algorithm deciding knowledge wish
acquire ordering experience. existing ordering algorithms demonstrate
precedence relation variables key consideration order creation.
graph search algorithms search-based graph evaluation algorithms try place
variable variables
influence next state value. Generally, variable order
n
n variables yields 2 precedence pairs. precedence pair v vj denotes variable
vi precede vj variable order. example, variable order a, b, c, yields
precedence pairs b, c, d, b c, b d, c d.
task learning precedence pairs transformed concept learning
task. concept learning task defined by:
universe X concept learned;
concept C subset items X want learn (usually marked
associated boolean characteristic function f c );
set examples pairs form hx, f c (x)i, x X;
set features functions X allow generalization.
many learning tasks difficult transform problem format listed
above. already clear discussion general concept wish
learn set variable pairs first precede second variable
ordering1 .
precisely, define universe concept learned set
pairs h(vi , vj ), i, (vi ,vj ) ordered variable pair comprised v vj ,
variables model . Since expect pairs preferred order,
define ternary instead binary concept. ternary concept following
classes:
1. practice, need small subset precedence pairs constructing total order.

93

fiGrumberg, Livne, & Markovitch

1. C+ , class h(vi , vj ), preferable place v prior vj
order get good initial order.
2. C , class h(vi , vj ), preferable place v vj order
get good initial order.
3. C? , class h(vi , vj ), placing vi vj likely lead
good variable order placing v vj .
following subsections describe algorithms learning using concept.
3.1 Algorithm Framework
start description general framework learning algorithm. goal
find variable orders yield BDDs small number nodes. Given training
model, algorithm first generates set orders variables. define utility
function u variable orders following. orders used initial order
building BDD representation model 2 . BDD (denoted M-BDD) includes
models partitioned transition relation set initial states. utility u
generated order defined reversely proportional number nodes
M-BDD constructed order.
subset consists variable pairs appear together next-state
function selected example extractor possible variable pairs. call
pairs interacting variable pairs. example, next(x) = z (y, z)
interacting variable pair. example tagger tags selected ordered pairs
one classes C+ , C , C? , based evaluated orders. tagged pairs
forwarded feature extractor which, based model, computes pair
feature vector. learner, ID3 (Quinlan, 1986) decision tree generator, uses
tagged feature vectors create pair precedence classifier.
Several training models used manner construct different pair precedence
classifiers. solving new unseen problem, pair precedence classifiers used
ordering algorithm create variable order.
learning framework creating pair precedence classifier training model
given Figure 4. complete data flow displayed Figure 5. following subsections
describe greater detail components framework.
3.2 Training Sequence Generator
goal training sequence generator produce orders high variance quality
exploited tagger (see Subsection 3.4). simplest strategy generating
sequences producing random orders. indeed strategy used
experiments described paper. One potential problem approach
domains good orders (or bad orders) rare. case, random generator
necessarily produce sequences desired diversity quality.
2. use SMV (McMillan, 1993) system purpose.

94

fiLearning Order BDD Variables Verification

Input : Training Model
Output : Precedence Classifier
1. Create sample orders.
2. Use SMV evaluate utility sample order M-BDD size.
3. Find interacting variable pairs training model.
4. Based evaluated sampled orders, tag ordered pair based
interacting variable pair.
5. Transform tagged pair tagged feature vector.
6. Create classifier based tagged feature vectors.
Figure 4: Training model precedence classifier construction

Training
Order
SMV

Training
Model

Evaluated
Orders

Tagged
Pairs

Example

Feature
Extractor

Tagger

M-BDD

Example

Interacting
Variable
Pairs

Learner

Extractor

Real
Model

Ordering
Algorithm

Classifier

Tagged
Feature
Vectors

Order

Figure 5: Data flow

alternative approach actively try producing orders good orders
bad, therefore creating large diversity quality. One way producing
good order taking orders result dynamic ordering process.
Another option using existing static ordering algorithm. One interesting idea
try bootstrap process using results adaptive ordering algorithm
training examples thus resulting progressively diverse input.
95

fiGrumberg, Livne, & Markovitch

3.3 Example Extractor
Given set n variables, extract n (n 1) example ordered pairs training.
actually use ordered pairs examples?
two main reasons selective examples use:
1. example carries computational costs associated tagging, feature extraction,
added computation induction procedure.
2. Noisy examples known harmful effect induction process.
process selecting subset examples, tagged, set untagged
examples called selective sampling. two common ways performing selective
sampling. One automatic methods use various general metrics selecting
informative examples (Lindenbaum, Markovitch, & Rusakov, 1999). way
using domain specific heuristics potential example informative.
work use second approach. Consider function f variables,
represented within BDD n variables (where n). number nodes used
represent f depends relative order variables. means changing
order n variables would influence BDD representation
function f .
BDD representation model checked consists initial states
model next-state functions variables. Since BDD representation
initial states typically small, take account. Therefore, looking
examples, consider next-state functions. Usually, function defined
subset model variables. Thus, order pair variables (v , vj ),
appear together next-state function less likely affect quality
generated order. therefore filter pairs.
3.4 Example Tagger
ordered variable pair (vi , vj ) tagged belonging C+ preferable
place vi vj . Let V = {v1 , . . . , vn } set variables given model. Let
set possible orderings V . Let vi vj set vi precedes
vj . ordered variable pair (vi , vj ) defined preferable (vj , vi )
Average{u(o)|o Ovj vi } Average{u(o)|o Ovi vj }.
Since feasible evaluate possible orders, sample space possible
orders, evaluate partition samples two sets above. averages
estimate real averages, replace term smaller definition
significantly smaller. determined unpaired t-test, tests
significance (with given confidence) difference averages two samples
two populations.
precisely, variable pair v , vj , set sampled orders partitioned two subsets Svi vj Ovi vj Svj vi Ovj vi . unpaired t-test
predetermined confidence level used check averages set utilities differ
significantly. do, ordered pair corresponding set smaller average
96

fiLearning Order BDD Variables Verification

tagged + ordered pair tagged - (meaning belong
C+ C , respectively). Otherwise, average difference significant,
ordered pairs tagged ? (meaning belong C ? ).
elaborative approach could use t-value weight important particular order is. weights could solve conflicts ordering process. scheme
would require, however, method incorporate weights induction algorithm. One
method trying induce continues function instead ternary function.
3.5 Feature Extractor
want generalize training models future unseen models, cannot represent
pairs variable names. Rather, use representation used
across models. induction algorithms require examples represented
feature vectors.
process constructing appropriate feature set crucial part applying
learning algorithm problem. common knowledge engineering process
domain expert comes set features might relevant. role
induction algorithm, then, find combination features relevant
specific problem.
come set features variable pairs. features extracted
model connectivity graph. attributes inspired traditional
static ordering algorithms. attributes categorized three groups:
Variable attributes defined single variable try capture characteristics
model. One example variable-dependence attribute, equals
number variables variable depends. attribute inspired
value used Butler et al. (1991) guide DFS search. higher value indicates
larger portion models variables needed determine variables
next-state value. Thus, higher value may indicate variable location
lower order. Another example variable-dependency, takes
complementary view variable-dependence. attribute equals number
variables depend given variable. higher value may indicate
variable placed higher variable order.
Symmetric pair attributes defined variable pair v , vj . attributes try
capture strength bond two variables, well
pair variables model. example, pair-minimal-distance
measures shortest path variables model connectivity graph.
shorter path indicate stronger bond variables. distance-based
ordering framework (Chung et al., 1993) uses similar feature order variables.
Another example pair-mutual-dependency, counts number variables
whose next-state function depends v vj .
Non-symmetric pair attributes try capture relationship two variables. example, pair-dependency-ratio ratio variabledependency values two variables. ratio relatively high low, may
indicate relative order two. pair-ns-distance evaluates influence one
97

fiGrumberg, Livne, & Markovitch

variable next state value other. measuring distance
variables subgraph represents next-state function.
complete list attributes found Appendix A.
3.6 Induction Algorithm
feature extraction phase, data represented set tagged feature vectors.
type representation used produce classifiers many induction algorithms,
including decision trees (Hunt, Marin, & Stone, 1966; Friedman, 1977; Quinlan, 1979;
Breiman, Frieman, Olshen, & Stone, 1984), neural networks (Widrow & Hoff, 1960; Parker,
1985; Rumelhart & McClelland, 1986) nearest neighbor (Cover & Hart, 1967; Duda &
Hart, 1973). decided use decision tree classifiers relatively fast
learning fast classification. Fast classification especially important since wish
competitive ordering algorithms number variable pairs need
classify large.
Decision trees researched thoroughly last decade, producing many
valuable extensions. One extension enables decision tree give
classification items also associate classification confidence estimation. used variant allow conflict resolution. described
Section 3.7.3.
3.7 Ordering Algorithm
outcome learning process described last four subsections set decision
trees, one training model.
could also generate one tree based union generated samples. One advantage
multiple-tree approach expect examples model
consistent, allowing generating compact trees. contrast, set examples coming
different models likely noisy, yielding large tree. addition, multiple-tree
version allows us using voting scheme ordering process, described below.
Given model M, algorithm first extracts interacting variable pairs.
classifiers applied feature vector representations pairs.
classifier, classifications pairs gathered form precedence table.
tables merged one table. order creation algorithm uses merged
precedence table construct models variable order. following subsections describe
components greater detail. Figure 6 shows data flow ordering algorithm.
3.7.1 Building Precedence Table
build precedence table based given classifier, algorithm asks two questions
interacting variable pair vi , vj :
1. vi vj ?
2. vj vi ?
98

fiLearning Order BDD Variables Verification

Pair
Precedence
Classifier
Pair
Precedence

Real

Pair

Feature

Problem

Extractor

Extractor

Classifier

Pair

Pair

Tree

Table

Pair

Pair

Tree

Table

Merger

Merged
Pair
Precedence
Classifier

Pair

Pair

Tree

Table

Table

Order
Creation
Algorithm

Variable
Order

Figure 6: Ordering algorithm data flow

1
2
3
4
5
6
7
8
9

vi v j ?



Yes
Yes
Yes
Unknown
Unknown
Unknown

vj vi ?

Yes
Unknown

Yes
Unknown

Yes
Unknown

vi , vj order
Unknown
v j vi
Unknown
v vj
Unknown
Unknown
Unknown
Unknown
Unknown

Table 2: Pair order table
two agree, pair order set agreed order. disagree, order
set unknown. Table 2 summarizes possible answers two questions
resulting pair order.
3.7.2 Merging Algorithm
constructing pair precedence tables training models classifiers, merge
tables using voting scheme. variable pair v , vj , count number tables
vote vi vj number tables vote vj vi . decide pair
order according majority (ignoring unknown votes).
Assuming majority vote chooses order v vj , confidence vote
conf (v v )conf (v v )
computed vote(vii vjj )+vote(vjjvii) , vote(vi vj ) number tables vote
99

fiGrumberg, Livne, & Markovitch

vi vj conf (vi vj ) sum confidence values votes. vote(v j vi )
conf (vj vi ) defined similarly. value turns lower 0.1, set
minimal value 0.1.
3.7.3 Cycle Resolution
order build total, strict order merged table, table must contain
cycle. However, algorithm guarantee this. therefore
apply cycle resolution algorithm makes table cycle-free.
precedence table seen directed graph nodes variables,
weighted edge vi vj vi vj . many possible ways
eliminate cycles directed graph. One reasonable bias removing least number
edges. problem known minimum feedback arc set proven NP-hard
(Karp, 1972). Approximation algorithms problem exist (Even, Naor, Schieber, &
Sudan, 1998), costly purposes.
use instead simple greedy algorithm solve problem. constraints
(edges) gathered list sorted decreasing order according weights
(i.e., confidence). graph initialized hold variable vertices. list
edges traversed edge added close cycle.
3.7.4 Pair Precedence Ordering
stage algorithm, hold acyclic merged precedence table. last step
ordering process convert partial order represented table total order.
done topological ordering. stage, algorithm finds minimal
variables, i.e., variables constrained follow unordered variable.
set, select variable vadd maximal fan-out add last ordered
variable. add variables larger v add appear
constraint unordered variable. desirable place
interacting variables near other. pair precedence ordering (PPO) algorithm
listed Figure 7. Figure 8 lists selection v add PPO .
One possible change ordering process delay cycle resolution last
stage. call version cycle resolution demand. modified algorithm
perform cycle resolution merged table. Instead, algorithm works
merged table may contain cycles. table contains cycle, algorithm must
reach stage variables ordered minimal variables.
case algorithm performs cycle resolution continues ordering
process.
3.8 Experiments
performed empirical evaluation PPO algorithm using models
ISCAS89 (Brglez, Bryan, & Kozminski, 1989) benchmark. ISCAS89 benchmark circuits
used empirically evaluate many algorithms deal various aspects
circuit design (Chamberlain, 1995; Wahba & Borrione, 1995; Nakamura, Takagi, Kimura,
& Watanabe, 1998; Long, Iyer, & Abramovici, 1995; Iyer & Abramovici, 1996; Konuk
& Larrabee, 1993). discovered circuits insensitive initial
100

fiLearning Order BDD Variables Verification

Input : merged pair precedence table.
Output : variable order.
Let V set variables.
Let before(v, V 0 ) = {v 0 V 0 |v v 0 }.
Let after(v, V 0 ) = {v 0 V 0 |v 0 v}.

1. VC = {vi |bef ore(vi , V ) 6= af ter(vi , V ) 6= }
VN C = V V C
2. VC 6=
(a) Vmin = {vi VC |af ter(vi , VC ) = }
(b) vadd = argmaxvi Vmin |bef ore(vi , VC )|
(c) order = order || vadd



b

(d) VC = VC {vadd }
(e) vi VC
af ter(vi , VC ) = bef ore(vi , VC ) =
order = order || vi , VC = VC {vi }
3. Add VN C end variable list.
a. one exists, select one.
b. Add variable order.

Figure 7: Pair precedence ordering
ordering. means entire sample initial orders yielded model BDDs similar
sizes. eliminated circuits set. remaining circuits selected
number variables SMV handle. ended following
five circuits: s1269 (55), s1423 (91), s1512(86), s4863 (153), s6669 (314). numbers
parentheses stand number variables model.
began offline learning session three smaller models (s1269, s1423,
s1512) used training models. models generated 200 random
orders extracted examples described previous section. algorithm
induced three precedence classifiers form decision trees.
number 200 selected since proved sufficiently large. real application
algorithm used anytime algorithm training sequences generated
long user willing wait offline learner. alternative approach would
keep aside validation set would used testing systems performance.
training could stopped learning curve flattens.
algorithm tested two larger models (s4863, s6669).
models, three learned decision trees used generate merged precedence table.
101

fiGrumberg, Livne, & Markovitch

Pair
Merged
Table

Minimal
Elements
Unordered
Variables

Find
Minimal

Filter
Maximal

Maximal
Minimal
Elements

Selected
Element
Select
One

Variable
Order

Figure 8: Pair precedence ordering v add selection

PPO algorithm (with cycle resolution demand) compared random
algorithm. addition, compared results two advanced graph search algorithms
static ordering: DFS append algorithm Fujita et al. (1988) interleave
algorithm Fujii et al. (1993). algorithms used adaptation multiple
starting points (Butler et al., 1991) expanded version, includes tie breaking
rule (Fujita et al., 1993). random results taken based 200 variable orders.
two algorithms run 10 times every model. performance
ordering algorithms measured number nodes model BDDs (partitioned
transition relation initial states).
Table 3 Figure 9 show results obtained. table shows model s6669,
PPO outperformed random order 300%. model s4863, PPO outperformed random order 5%.
PPO vs. Random

6

2.5

x 10

random
PPO

2

BDD nodes

1.5

1

0.5

0

s4863

Model

s6669

Figure 9: Comparative histogram PPO vs. Random

102

fiLearning Order BDD Variables Verification

Model
s4863
s6669

Random
Average
STD
849197
121376
2030880 1744493

PPO
Average
STD
807763 100754
713950
35446

Table 3: Comparative table PPO vs. Random
comparison algorithm two static algorithms given Figure 10.
results show learning algorithm, training, becomes competitive
existing ordering algorithms written experts.
5

10

x 10

Append
Interleave
PPO

9
8
7

BDD nodes

6
5
4
3
2
1
0

s4863

Model

s6669

Figure 10: Comparative histogram PPO vs. Static
evaluate utility learned knowledge would like compare performance ordering process without learned knowledge. Ordering without
learned knowledge equivalent random ordering. comparison results
random-ordering algorithm reveals learner indeed induced meaningful knowledge learning process. method also much stable random
ordering s6669 indicated comparing standard deviation. large variance
results random ordering indeed exploited tagging procedure explained Section 3.4. small variance results obtained random ordering
s4863 explain improvement obtained PPO algorithm much smaller
circuit. sophisticated training sequence generator, described
Section 3.2, might successful circuit.
comparison hand-crafted algorithms may look disappointing first look
since results learning system better existing algorithms. Recall,
however, comparing automated learning process human expertise.
works empirical machine learning make comparisons performance
various learning algorithms. common compare performance learning
103

fiGrumberg, Livne, & Markovitch

algorithm human expert expert system since cases clear handcrafted algorithms would outperform automated learning processes. Since hardly
learning systems built solve BDD variable ordering problem
could make common comparison learning systems.

4. Learning Context-Based Precedence Static Ordering
precedence relation one key considerations used traditional static ordering
algorithms. Another key consideration clustering variables subsequent
ordering. algorithms try place highly interacting variables near other.
effect variable clustering BDD seen simple example given
Figure 3. function, switching two variables v 2 v3 increases BDD size
3 nodes. function, orders variables two clusters,
v1 , v3 v2, , v4 , kept together yield minimal BDD representation. variable
orders yield less compact BDD. Thus, function, key consideration
compliance clustering (precedence taken account).
4.1 Variable Distance
discussion leads hypothesis distance variables important factor considering alternative orders. One way obtain distance information
learning distance function pairs variables. are, however, two
problems approach:
1. target distance function well-defined across models. example,
train small models, absolute distance function likely applicable
large models.
2. Information absolute distances variables sufficient construct
good ordering. absolute distance uniquely define
order variables. fact, defines two possible orders, one
reverse other.
example Figure 11 demonstrates order reverse yield BDDs
significantly different size. BDDs Figure 11 represents two
functions, f1 (a, b, c, d, e) = (a = b = c) (c = d) f2 (a, b, c, d, e) = (a = b =
c) (c = e). absolute distance variables orders clearly
same. However, upper BDD approximately double size lower one.
wanted check whether realistic examples reverse orders yield BDDs
significantly different size. tested models ISCAS89 benchmarks
created 5,000 variable orders model. order, compared
quality quality reversed order. found many cases one order
exceptionally good reversed one exceptionally bad. Thus, learning
absolute distance sufficient, information needed.
conclude problems inherent learning utilizing absolute
distances. Still, clustering key consideration pursued. suggest,
104

fiLearning Order BDD Variables Verification

f1



f2

b
c

e

1

1
0

1

1

1

1

0
0

1

1

0

(a)
f2

e
f1


c
b


1

1
0

0
0

1

1

0

(b)

Figure 11: ROBDDs functions f 1 (a, b, c, d, e) = (a = b = c) (c = d)
f2 (a, b, c, d, e) = (a = b = c) (c = e)

alternatively, learning relative distance determines, variables v , vj , vk ,
vj , vk closer vi , given vi precedes two.
remainder section describes method learning utilizing context-based
precedence infer relative distance variables.
4.2 Context-Based Precedence
context precedence relation triplet v vj vk : given vi precedes vj vk ,
variable vj come variable vk . Thus, context precedence relation adds
context pair ordering decisions.
pair precedence learning, define universe set pairs h(v , vj , vk ),
vi , vj , vk variables model . universe divided three classes,
C+ , C , C? , before. Examples classes drawn way. pair
precedence framework applied minor changes work context precedence
relations. minor changes described below.
4.3 Example Tagger
variable triplet (vi , vj , vk ) tagged C+ if, given vi precedes vj vk ,
preferable place vj vk (i.e., vi vj vk ). pair precedence learning, use
set evaluated variable orders tagging. set orders partitioned
three subsets, depending three variables first. Given partition defined
vi (for example), test order v j vk using t-test, described Section
105

fiGrumberg, Livne, & Markovitch

3.4. reduce number noisy examples, use partition yields
significant t-test results.
4.4 Feature Extractor
attributes triplet (vi , vj , vk ) computed based attributes two pairs
vi vj vi vk . attribute value division/subtraction two corresponding
attribute values two pair attributes.
precisely, assume pair v vj attributes f1 (vi , vj ), . . . , fn (vi , vj )
pair vi vk attributes f1 (vi , vk ), . . . , fn (vi , vk ). triple (vi , vj , vk )
attributes f1 (vi , vj )/f1 (vi , vk ), . . . , fn (vi , vj )/fn (vi , vk ). fl (vi , vk ) 0
corresponding attributes subtracted instead divided.
example consider attribute f l pair minimal distance (see Section 3.5).
fl (vi , vj )/fl (vi , vk ) greater 1 shortest path v vj larger
shortest path vi vk . attribute indicate v k appear
closer vi .
Similarly, fl pair mutual dependency fl (vi , vj )/fl (vi , vk ) > 1 indicates
number variables whose next-state function depends v vj greater
depending vi vk . may indicate preferable keep v
vj close together.
4.5 Ordering Algorithm
outcome learning phase set decision trees, one model.
case context-free pairs. subsection describe ways use
trees ordering.
4.5.1 Building Context Precedence Table
case pair precedence table size n 2 (where n number
variables), produce one table context variable. table
perform inconsistency elimination similar described Section 3.7.1. Here, however,
ask classifier two questions v j , vk vk , vj , add context variable
vi query.
4.5.2 Pair Precedence Ordering Context Precedence Filtering
ordering algorithm uses pair precedence table way PPO algorithm. However, often found case PPO algorithm several
minimal variables, even employing maximal fanout filter. use contextbased precedence table reduce size set minimal elements. use
variables already ordered sequence context variables look associated tables. set minimal elements contains pair variables constrained
vj vk one tables, eliminate vk set. Figure 12 lists code
added PPO algorithm, accepts variable set V add (from previously
selected randomly), returns one variable. call new algorithm PPO CPF .
Figure 13 lists selection vadd PPOCPF .
106

fiLearning Order BDD Variables Verification

Input : set candidate variables added, V add , merged context precedence
table.
Output : variable added.
Let after(v, Vi , Vj ) = {hvi , vj vi Vi , vj Vj |vi vj v}.
0
b.1 Vadd
= {vi Vadd |af ter(vi , VInOrder , Vadd ) = }
0
b.2 Vadd
6=
0
select randomly one variable V add
else select randomly one variable V add

Figure 12: Pair precedence ordering context precedence filtering
Context
Merged
Table

Pair
Merged
Table

Minimal
Elements
Unordered
Variables

Find
Minimal

Filter
Maximal

Maximal
Minimal
Elements

Filter
Context
Constrained

Unconstrained
Minimal
Elements

Selected
Element
Select
One

Variable
Order

Figure 13: Pair precedence ordering context precedence filtering v add selection

4.6 Experiments
evaluated performance PPO CPF , performing off-line learning
training models followed ordering test models. results shown Figure 14.
comparison also show performance PPO algorithm two expert
algorithms.
P P CP F algorithm outperforms algorithms two tested models.
results show context-based precedence relations add valuable information.
tested effect resources invested learning phase performance algorithms. Since learning examples tagged based evaluated training
orders, since evaluation training orders resource-consuming operation, used number orders resource estimator. Figure 15 shows
learning curves algorithms, is, shows system performance changes
according offline resources consumed (the number training orders evaluated).
Without testing random order, system knowledge build
precedence classifiers, thus performance equivalent random ordering.
107

fiGrumberg, Livne, & Markovitch

5

10

x 10

Append
Interleave
PPO
CPF
PPO

9
8
7

BDD nodes

6
5
4
3
2
1
0

s4863

Model

s6669

Figure 14: Comparative histogram ordering algorithms
6

2.2

x 10

s4863
s6669

2

1.8

bdd nodes

1.6

1.4

1.2

1

0.8

0.6
0

20

40

60

80
100
120
number examples

140

160

180

200

Figure 15: Learning curves PPO CPF algorithm two testing models

tagging based 20 orders noisy. improves performance s6669,
degrades performance s4863. Forty orders sufficient generate stable tagging,
yields improved classifiers therefore improved ordering quality.

5. Discussion
work described paper presents general framework using machine learning
methods solve static variable ordering problem. method assumes availability
108

fiLearning Order BDD Variables Verification

training models. training model, learning algorithm generates set
random orders evaluates building associated BDDs. ordered pair
interacting variables tagged good example appears frequently
highly valued orders. ordered pairs converted feature-based representations
given, associated tags, induction algorithm. ordering
variables new unseen model, resulting classifiers (one model) used
determine ordering variable pairs. also present extension method
learns context-based ordering.
algorithm empirically tested real models. performance significantly
better random ordering, meaning algorithm able acquire useful ordering
knowledge. results slightly better existing static ordering algorithms handcrafted experts. result significant compare applications learning
systems domains. would surely appreciate induction algorithm produces
classifier performance comparable expert system built medical
expert. chess learning program able learn evaluation function
equivalent power function produced expert similarly appreciated.
therefore claim ability learning algorithm achieve results
good manually designed algorithms indicates strong learning capabilities.
learning algorithms, expect get better performance testing
problems similar training problems. verification domain, expect get
good results testing training models come family similar models.
several occasions models similar enough considered family:
Models different versions design development; models reduced
versions design, respect different property; models designs
similar functionality like ALUs, arbiters, pipelines bus controllers. Unfortunately,
due difficulty obtaining suitable real models experiments, ended
experimenting training testing models related. expect achieve
much better results related models.
Compared previous work machine learning, precedence relations resemble Utgoff Saxena (1987). ordering approach, construct
total order elements finding precedence relation them, essence
Cohen, Schapire Singer (1999). Specifically, second ordering algorithm Cohen, Schapire Singer also uses topological ordering approach create
order. algorithm initially finds precedence graph connected components
and, ordering (using topological ordering), finds order connected
component. However, since quality final order determined sum constraints adhered to, topological orders theoretically quality. found
BDD variable ordering problem topological orders quality.
Thus, developed topological ordering takes consideration features
recognized true variable orders BDDs.
work also differs previous research introduces notion contextbased precedence. Using concept able create ordering algorithm
produces best results.
several directions extending work described here. One problem
current empirical evaluation small number models. spite extensive
109

fiGrumberg, Livne, & Markovitch

search efforts able find large set suitable examples. majority
known examples simple (compared real industry problems), producing small
model BDD representations little variance. currently process
approaching companies use model checking. way hope obtain additional
real models, preferably families designs described above.
attributes variable pairs partially based substantive research
field static algorithms. could find information base contextbased variable attributes. Thus, also based attributes variable
pairs. Nevertheless, believe human experts field may information
lead development better attributes. development attributes
help capture better way context-based precedence concept.
Given current results, immediate question whether concept precedence
pairs (context non-context) extended triplets, quadruples, etc. precedence relations take account larger part model thus may possess valuable
information. extension, however, could carry high cost learning and, even
worse, ordering.
framework solving static variable ordering problem shown valuable
model checking. Model checking one field verification BDDs used.
BDDs also used verification simulation equivalence checking. algorithm
applied problems well. unaware special static variable ordering
algorithms fields, exist, variable attributes based algorithms
added.
interesting future direction generalization framework
ordering problems. Ordering set objects common sub-task problem solving.
common approach tackling problem evaluate object using
utility function order objects according utilities. approach
taken, example, heuristic search algorithms. many problems, however,
much easier determine relative order two objects give object global
utility value. works applied learning ordering techniques utility
based (Cohen et al., 1999). algorithms described Section 3 Section 4
applied ordering problem method evaluating training orders available,
set meaningful pair features defined.
believe research presented paper contributes field
machine learning field formal verification. machine learning, presents
new methodology learning order elements. methodology applied
various kinds ordering problems. formal verification, presents new learning-based
techniques variable ordering. Finding good variable ordering techniques one
key problems field.

Appendix A. Variable Pair Attributes
following definitions symbols used attribute description:
N S(vi ) next state function variable v
vi . vj indicate variable vi depends variable vj value (vj NS(vi ))
110

fiLearning Order BDD Variables Verification

vi ./ vj indicate variable vi interacts variable vj (vi . vj and/or vj . vi )
# variables number variables model
A.1 Variable Attributes
attributes computed vi
1. Variable-dependence: number variables upon v depends (|{vj |vi . vj }|)
2. Variable-dependency: number variables depend v (|{vj |vj . vi }|)
3. Variable-dependency-size: sum function sizes depend v (

P

vj .vi

|{vk N S(vj )}|)

4. Variable-dependency-average-size:
average function size dependent v
!
P
vj .vi

|{vk N S(vj )}|

|{vj |vj .vi }|

5. Variable-dependence-dependency-ratio: proportion number vari!
ables vi depends number variables depend

|{vj |vi .vj }|
|{vj |vj .vi }|

6. Variable-interaction: number variables interacting v (|{vj |vi ./ vj }|)
7. Variable-dependence-percentage:
percentage model variables v de!
pends

|{vj |vi .vj }|
#variables

8. Variable-dependency-percentage:
percentage model variables depend v
!
|{vj |vj .vi }|
#variables

9. Variable-interaction-percentage:
percentage model variables interacting v
!
|{vj |vi ./vj }|
#variables

A.2 Variable Pair Attributes
attributes computed hvi , vj
Symmetric attributes
1. Pair-minimal-distance: minimal distance v ,vj model graph
2. Pair-minimal-distance-eval: minimal distance v ,vj model
graph divided number times appears
3. Pair-minimal-dependency: number variables depend pair
minimal distance
4. Pair-minimal-dependency-eval: minimal distance v ,vj model
graph divided number variables depend minimal distance
111

fiGrumberg, Livne, & Markovitch

5. Pair-minimal-connection-class: minimal distance v ,vj connection class (the operators applied two variables divided
classes operator connected two variables minimal distance
class extracted)
6. Pair-minimal-maximal: maximal sized NS(v k ) connecting pair minimal distance
7. Pair-minimal-maximal-eval: minimal distance v ,vj model
graph divided maximal sized NS(v k ) connecting pair minimal distance
8. Pair-sum-distance: sum distances v ,vj model graph
9. Pair-dependency-ns-size: sum NS(v k ) sizes dependent vi
P
vj ( vk .vi & vk .vj |vl N S(vk )|)

10. Pair-sum-distance-dependency-ratio: sum distances v ,vj
model graph divided sum NS(vk ) sizes dependent vi vj
11. Pair-mutual-dependence: number variables v ,vj depend
(|{vk |vi . vk & vj . vk }|)
12. Pair-mutual-dependency: number variables depend v vj
(|{vk |vk . vi & vk . vj }|)
13. Pair-mutual-interaction: number variables interact v vj
(|{vk |vi ./ vk & vi ./ vk }|)

14. Pair-mutual-ns-dependency: v depends vj vj depends vi - (vi . vj & vj . vi )
Non-Symmetric attributes ( computed pair hv , vj relevance vi )
1. Pair-ns-distance: distance v ,vj NS(vi )
2. Pair-dependence-ratio: ratio number variables !
v depends
number variables v j depends

|{vl |vi .vl }|
|{vm |vj .vm }|

3. Pair-dependency-ratio: ratio number variables
! depend
vi number variable depend v j

|{vl |vl .vi }|
|{vm |vm .vj }|

4. Pair-interaction-ratio: ratio number variables !interact
|{vl |vi ./vl }|
|{vm |vj ./vm }|

vi number variables interact v j

5. Pair-dependence-flag: number variables v depends
! compared
number variables vj depends

|{vl |vi .vl }|
|{vm |vj .vm }|

>= 1.0

6. Pair-interaction-flag: number variables interact v compared

!
number variables vj interacts

112

|{vl |vi ./vl }|
|{vm |vj ./vm }|

>= 1.0

fiLearning Order BDD Variables Verification

References
Akers, S. (1978). Binary decision diagrams. IEEE Transactions Computers, C-27 (6),
509516.
Aziz, A., Tasiran, S., & Brayton, R. (1994). BDD variable ordering interacting finite
state machines. Proceedings 31st Design Automation Conference (DAC), pp.
283288, San Diego, California.
Beer, I., Ben-David, S., Eisner, C., & Landver, A. (1996). RuleBase: industry-oriented
formal verification tool. Proceedings 33rd Design Automation Conference
(DAC), pp. 655660, Las Vegas, Nevada. IEEE Computer Society Press.
Bern, J., Meinel, C., & Slobodova, A. (1995). Efficient OBDD-based boolean manipulation CAD beyond current limits. Proceedings 32nd Design Automation
Conference (DAC), pp. 408413, San Francisco, California.
Bollig, B., Lobbing, M., & Wegener, I. (1995). Simulated annealing improve variable orderings OBDDs. Proceedings International Workshop Logic Synthesis,
pp. 5b:5.15.10, Granlibakken, California.
Bollig, B., & Wegener, I. (1996). Improving variable ordering OBDDs NP-complete.
IEEE Transactions Computers, 45 (9), 9931002.
Breiman, L., Frieman, J. H., Olshen, R. A., & Stone, C. J. (1984). Classification
Regression Trees. Wadsworth Publishing Company, Belmont, California, U.S.A.
Brglez, F., Bryan, D., & Kozminski, K. (1989). Combinational profiles sequential benchmark circuits. Proceedings International Symposium Circuits Systems,
pp. 19241934, Portland, Oregon.
Broos, P., & Branting, K. (1994). Compositional instance-based learning. Proceedings
12th National Conference Artificial Intelligence, pp. 651656, Menlo Park,
California. AAAI Press.
Bryant, R. (1986). Graph-based algorithms boolean function manipulation. IEEE Transactions Computers, C-35 (8), 677691.
Butler, K. M., Ross, D. E., & Rohit Kapur, a. M. R. M. (1991). Heuristics compute
variable orderings efficient manipulation ordered binary decision diagrams.
Proceedings 28th Design Automation Conference (DAC), pp. 417420, San Francisco, California.
Chamberlain, R. (1995). Parallel logic simulation VLSI systems. Proceedings
32nd Design Automation Conference (DAC), pp. 139143, San Francisco, California.
Chung, P., Hajj, I., & Patel, J. (1993). Efficient variable ordering heuristics shared
ROBDD. Proceedings International Symposium Circuits Systems,
pp. 16901693, Chicago, Illinois.
Clarke, E. M., Emerson, F. A., & Sistla, A. P. (1986). Automatic verification finite
state concurrent systems using temporal logic specifications. ACM Transactions
Programming Languages Systems, 8 (2), 244263.
113

fiGrumberg, Livne, & Markovitch

Cohen, W. W., Schapire, R. E., & Singer, Y. (1999). Learning order things. Journal
Artificial Intelligence Research, 10, 243270.
Cover, T. M., & Hart, P. E. (1967). Nearest neighbor pattern classification. IEEE Transactions Information Theory, 13, 2127.
Drechsler, R., Becker, B., & Gockel, N. (1996). Genetic algorithm variable ordering
OBDDs. IEEE Proceedings Computers Digital Techniques, 143 (6), 364368.
Drechsler, R., Drechsler, N., & Slobodova, A. (1998). Fast exact minimization BDDs.
Proceedings 35th Design Automation Conference (DAC), pp. 200205, San
Francisco, California.
Duda, R. O., & Hart, P. E. (1973). Pattern Classification Scene Analysis. John Wiley
Sons, New York.
Even, G., Naor, J., Schieber, B., & Sudan, M. (1998). Approximating minimum feedback
sets multi-cuts directed graphs. Algorithmica, 20, 151174.
Friedman, J. (1977). recursive partitioning decision rule nonparametric classification.
IEEE Transactions Computers, C-26 (4), 404408.
Friedman, S. J., & Supowit, K. J. (1987). Finding optimal variable ordering binary
decision diagrams. Proceedings 24th Design Automation Conference (DAC),
pp. 151174, Miami Beach, Florida.
Fujii, H., Ootomo, G., & Hori, C. (1993). Interleaving based variable ordering methods
ordered binary decision diagrams. Proceedings IEEE/ACM international
conference Computer-aided design, pp. 3841, Santa Clara, California.
Fujita, M., Fujisawa, H., & Kawato, N. (1988). Evaluation improvements boolean
comparison method based binary decision diagrams. Proceedings International Conference Computer-Aided Design, pp. 25, Santa Clara, California.
Fujita, M., Fujisawa, H., & Matsunaga, Y. (1993). Variable ordering algorithms ordered
binary decision diagrams evaluation. IEEE Transactions Computer-Aided
Design Integrated Circuits Systems, 12 (1), 612.
Fujita, M., Kukimoto, Y., & Brayton, R. (1995). BDD minimization truth table permutations. Proceedings International Workshop Logic Synthesis, pp. 596599,
Lake Tahoe, California.
Hunt, E., Marin, J., & Stone, P. (1966). Experiments Induction. Academic Press, New
York.
Ishiura, N., Sawada, H., & Yajima, S. (1991). Minimization binary decision diagrams
based exchanges variables. Proceedings International Conference
Computer-Aided Design, pp. 472475, Santa Clara, California.
Iyer, M., & Abramovici, M. (1996). FIRE: fault-independent combinational redundancy
identification algorithm. IEEE Transactions VLSI Systems, 4, 295301.
Jain, J., Adams, W., & Fujita, M. (1998). Sampling schemes computing variable orderings. Proceedings International Conference Computer-Aided Design, pp.
631638, San Jose, California.
114

fiLearning Order BDD Variables Verification

Karp, R. M. (1972). Reducibility among combinatorial problems. Miller, R., & Thatcher,
J. (Eds.), Complexity Computer Computations, pp. 85103, New York. Plenum
Press.
Kaufmann, M., & Pixley, C. (1997). Intertwined development formal verification
60x bus model. Proceedings International Conference Computer Design:
VLSI Computers Processors (ICCD 97), pp. 2530, Austin, Texas.
Konuk, H., & Larrabee, R. (1993). Explorations sequential atpg using boolean satisfiability. Proceedings 11th IEEE VLSI Test Symposium, pp. 8590.
Lindenbaum, M., Markovitch, S., & Rusakov, D. (1999). Selective sampling nearest
neighbor classifiers. Proceedings Sixteenth national confernce Artificial
Intelligence, pp. 366371, Orlando, Florida.
Long, D., Iyer, M., & Abramovici, M. (1995). Identifying sequentially untestable faults
using illegal states. Proceedings 13th IEEE VLSI Test Symposium, pp. 411,
Los Alamitos, California.
Malik, S., Wang, A., Brayton, R., & Sangiovanni-Vincentelli, A. (1988). Logic verification
using binary decision diagrams logic synthesis environment. Proceedings
International Conference Computer-Aided Design, pp. 69, Santa Clara, California.
McMillan, K. (1993). Symbolic Model Checking: Approach State Explosion Problem. Kluwer Academic Publisher.
Meinel, C., & Slobodova, A. (1997). Speeding variable ordering OBDDs. Proceedings International Conference Computer-Aided Design, pp. 338343, Austin,
Texas.
Meinel, C., & Slobodova, A. (1998). Sample method minimization OBDDs. Proceedings Conference Current Trends Theory Practice Informatics,
Vol. 1521 Lecture Notes Computer Science, pp. 419428. Springer-Verlag, New
York.
Meinel, C., Somenzi, F., & Theobald, T. (1997). Linear sifting decison diagrams.
Proceedings 34th Design Automation Conference (DAC), pp. 202207, Anaheim,
California.
Mercer, M. R., Kapur, R., & Ross, D. E. (1992). Functional approaches generating
orderings efficient symbolic representations. Proceedings 29th Design
Automation Conference (DAC).
Minato, S., Ishiura, N., & Yajima, S. (1990). Shared binary decision diagrams attributed edges efficient boolean function manipulation. Proceedings 27th
Design Automation Conference (DAC), pp. 5257, Orlando, Florida.
Nakamura, K., Takagi, K., Kimura, S., & Watanabe, K. (1998). Waiting false path analysis
sequential logic circuits performance optimization. Proceedings International Conference Computer-Aided Design, pp. 392395, San Jose, California.
Panda, S., & Somenzi, F. (1995). variables neighbourhood. Proceedings International Conference Computer-Aided Design, pp. 7477, San
Jose, California.
115

fiGrumberg, Livne, & Markovitch

Panda, S., Somenzi, F., & Plessier, B. F. (1994). Symmetry detection dynamic variable
ordering decision diagrams. Proceedings International Conference
Computer-Aided Design, pp. 628631, San Jose, California.
Parker, D. B. (1985). Learning logic. Tech. rep. TR-47, Center Computational Research
Economics Management Science, MIT, Cambridge, MA.
Queille, J., & Sifakis, J. (1981). Specification verification concurrent systems
cesar. Dezani-Ciancaglini, M., & Montanari, U. (Eds.), Proceedings 5th
International Symposium Programming, Vol. 137 Lecture Notes Computer
Science, pp. 337351. Springer-Verlag, New York.
Quinlan, J. R. (1979). Discovering rules induction large collections examples.
Expert Systems Micro Electronic Age, pp. 168201. Edinburgh University
Press.
Quinlan, J. R. (1986). Induction decision trees. Machine Learning, 1 (1), 81106.
Rudell, R. (1993). Dynamic variable ordering ordered binary decision diagrams.
Proceedings International Conference Computer-Aided Design, pp. 4247,
Santa Clara, California.
Rumelhart, D. E., & McClelland, J. L. (1986). Parallel distibuted processing: Exploration
microstructure cognition.. Vol. 1,2. MIT Press.
Touati, H., Savoj, H., Lin, B., Brayton, R., & Sangiovanni-Vincetelli, A. (1990). Implicit
state enumeration finite state machines using BDDs. Proceedings International Conference Computer-Aided Design, pp. 130133, Santa Clara, California.
Utgoff, P., & Clouse, J. (1991). Two kinds training information evaluation function
learning. Proceedings Ninth National Conference Artificial Intelligence,
pp. 596600, Anaheim, California.
Utgoff, P. E., & Saxena, S. (1987). Learning preference predicate. Proceedings
Fourth International Workshop Machine Learning, pp. 115121, Irvine, California.
Wahba, A., & Borrione, D. (1995). Design error diagnosis sequential circuits. Lecture
Notes Computer Science, 987, 171188.
Widrow, B., & Hoff, M. E. (1960). Adaptive switching circuits. 1960 IRE WESCON
Convention Record, pp. 96104, New York.
Zhuang, N., Benten, M., & Cheung, P. (1996). Improved variable ordering BDDs
novel genetic algorithm. Proceedings International Symposium Circuits
Systems., Vol. 3, pp. 414417, Atlanta, Georgia.

116

fiJournal Artificial Intelligence Research 18 (2003) 183-215

Submitted 9/01; published 2/03

Evolutionary Algorithm Advanced Goal Priority
Specification Multi-objective Optimization
Kay Chen Tan
Eik Fun Khor
Tong Heng Lee
Ramasubramanian Sathikannan

ELETANKC@NUS.EDU.SG
EIKFUN.KHOR@SEAGATE.COM
ELELEETH@NUS.EDU.SG
K.SATHI@GSK.COM

National University Singapore
4 Engineering Drive 3, Singapore 117576
Republic Singapore

Abstract
paper presents evolutionary algorithm new goal-sequence domination scheme
better decision support multi-objective optimization. approach allows inclusion
advanced hard/soft priority constraint information objective component, capable
incorporating multiple specifications overlapping non-overlapping objective functions via
logical connectives drive search towards multiple regions trade-off.
addition, propose dynamic sharing scheme simple adaptively estimated according
on-line population distribution without needing priori parameter setting. feature
proposed algorithm examined show respective contribution, performance
algorithm compared evolutionary optimization methods. shown proposed
algorithm performed well diversity evolutionary search uniform distribution
non-dominated individuals along final trade-offs, without significant computational effort.
algorithm also applied design optimization practical servo control system hard disk
drives single voice-coil-motor actuator. Results evolutionary designed servo control
system show superior closed-loop performance compared classical PID RPT approaches.

1. Introduction
Many real-world design tasks involve optimizing vector objective functions feasible
decision variable space. objective functions often non-commensurable
competition other, cannot simply aggregated scalar function
optimization. type problem known multi-objective (MO) optimization problem,
solution family points known Pareto-optimal set (Goldberg, 1989),
objective component member set improved degrading least one
objective components. obtain good solution via conventional MO optimization
techniques methods inequalities, goal attainment weighted sum approach,
continuous cost function and/or set precise settings weights goals required,
usually well manageable understood (Grace, 1992; Osyczka, 1984).
Emulating Darwinian-Wallace principle survival-of-the-fittest natural selection
genetics, evolutionary algorithms (EAs) (Holland, 1975) found effective
efficient solving complex problems conventional optimization tools fail work well.
2003 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiTAN, KHOR, LEE, & SATHIKANNAN

EAs evaluate performances candidate solutions multiple points simultaneously,
capable approaching global optimum noisy, poorly understood and/or non-differentiable
search space (Goldberg, 1989).
Since Schaffers work (1985), evolutionary algorithm-based search techniques MO
optimization gaining significant attention researchers various disciplines.
reflected high volume publications topic last years well first
international conference Evolutionary Multi-criteria Optimization (EMO01) held March
2001 Zurich, Switzerland. Readers may refer (Coello Coello, 1996; 1999; Deb, 2001;
Fonseca, 1995; Van Veldhuizen & Lamont, 1998; Zitzler & Thiele, 1999) detailed
implementation various evolutionary techniques MO optimization.
Unlike conventional methods linearly combine multiple attributes form composite
scalar objective function, concept Pareto's optimality modified selection scheme
incorporated evolutionary MO optimization evolve family solutions multiple points
along trade-off surface simultaneously (Fonseca & Fleming, 1993). Among various selection
techniques evolutionary MO optimization, Pareto-dominance scheme (Goldberg, 1989)
assigns equal rank non-dominated individuals effective approach comparing
strengths among different candidate solutions population (Fonseca & Fleming, 1993). Starting
principle, Fonseca Fleming (1993) proposed Pareto-based ranking scheme
include goal priority information MO optimization. underlying reason certain
user knowledge may available optimization problem, preferences and/or goals
achieved certain objective components. information could useful incorporated
means goal priority vectors, simplify optimization process allow
evolution directed towards certain concentrated regions trade-offs. Although
ranking scheme good approach, works single goal priority vector setting,
may difficult define accurately prior optimization process real-world
optimization problems. Moreover, scheme allow advanced specifications,
logical operations among multiple goals priorities.
Based Pareto-based domination approach, paper reformulates domination scheme
incorporate advanced specifications better decision support MO optimization. Besides
flexibility incorporating goal priority information objective component,
proposed domination scheme allows inclusion hard/soft priority constraint
specifications. addition, approach capable incorporating multiple specifications
overlapping non-overlapping objective functions via logical connectives
drive search towards multiple regions trade-off. paper also proposes dynamic
sharing scheme, computes sharing distance adaptively based upon on-line
population distribution objective domain without need priori parameter setting.
dynamic sharing approach essential since eliminates difficulty manually finding
appropriate sharing distance prior optimization process. choice distance would
sensitive size geometry discovered trade-offs (Coello Coello, 1999; Fonseca &
Fleming, 1993).
paper organized follows: formulation proposed domination scheme
better decision support presented Section 2. dynamic sharing scheme estimates
184

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

sharing distance adaptively based upon on-line population distribution described Section 3.
Section 4 examines usefulness contribution proposed feature algorithm.
performance comparison proposed algorithm evolutionary MO optimization
methods also shown section. Practical application proposed algorithm servo
control system design optimization given Section 5. Conclusions drawn Section 6.

2. Advanced Goal Priority Specifications MO Optimization
multi-objective optimization problem seeks optimize vector non-commensurable
often competing objectives, i.e., tends find parameter set P Min F ( P ) , P R n , P
P

= {p1, p2,, pn} n-dimensional vector n decision variables parameters, defines
feasible set P. F = {f1, f2,, fm} objective vector objectives minimized.
MO optimization problem simple goal priority specification objective function,
Pareto-based ranking scheme sufficient (Fonseca & Fleming, 1993). practice, however,
may difficult define accurate goal priority setting priori optimization process
real-world optimization problems. Besides goal priority information, could also
additional supporting specifications useful need satisfied evolutionary search,
optimization constraints feasibility solution. Moreover, Pareto-based ranking
scheme allow advanced specifications, logical operations
among multiple goals priorities better decision support complex MO optimization.
section, new goal-sequence Pareto-based domination scheme proposed address
issues provide hard/soft goal priority specifications better controls
evolutionary optimization process.
2.1 Pareto-based Domination Goal Information

section effective two-stage Pareto-based domination scheme MO optimization,
extended incorporate advanced soft/hard goal priority specifications. Consider
minimization problem. objective vector Fa said dominate another objective vector Fb
based idea Pareto dominance, denoted Fa Fb, iff f ,i f b,i {1,2,..., m}
f , j < f b, j j {1,2,..., m} . Adopting basic principle Pareto dominance, first

stage proposed domination approach ranks individuals satisfy goal setting
minimize objective functions much possible. assigns smallest cost
non-dominated individuals, dominated individuals ranked according many
individuals population dominate them. second stage ranks remaining individuals
meet goal setting based upon following extended domination scheme. Let Fa
Fb

)


)




denote component vector Fa Fb respectively, Fa meet
185

fiTAN, KHOR, LEE, & SATHIKANNAN

goal G . Fa Fb totally satisfy goal G , vector Fa said
dominate vector Fb (denoted Fa Fb ) iff
G

)


)


( Fa Fb ) (abs( Fa -G) abs( Fb -G))

(1)

this, rank begins one increment maximum rank value obtained first
stage cost assignment. Therefore individuals meet goal directed toward
goal infinum objective domain, satisfied goal
directed towards infinum. Note domination comparison operator
non-commutative ( Fa Fb Fb Fa ). Figure 1 shows optimization problem two
G

G

objectives f1 f2 minimized. arrows Figure 1 indicate transformation according
F' = F G objective function F F' individuals satisfy goal,
goal new reference point transformed objective domain. obvious
domination scheme simple efficient comparing strengths among partially totally
unsatisfactory individuals population. comparisons among totally satisfactory individuals,
basic Pareto-dominance sufficient.
study computational efficiency approach, population divided two
separate groups classified goal satisfaction, domination comparison performed
separately group individuals. total number domination comparisons
two-stage domination scheme Nc = [ nG( ( nG( -1)+ nG) ( nG) -1)] nG( number
individuals completely satisfy goal G nG) number individuals partially satisfy
completely satisfy goal G. Note nG( + nG) = N population size N. Hence,
generation, Nc always less equal total number domination comparisons
among individuals population (each individual population compared (N-1)
individuals), i.e., Nc Nnc = N ( N 1) . next section, two-stage Pareto-based
domination scheme extended incorporate soft/hard priority specifications advanced
MO optimization.

186

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

f2

6
6

6

5

5

5

G
4
1

6
2
1

6

f1

Figure 1: Advanced Pareto Domination Scheme Goal Information
2.2 Goal-Sequence Domination Scheme Soft/Hard Priority Specifications

One advanced capabilities evolutionary MO optimization incorporate cognitive
specification, priority information indicates relative importance multiple
tasks provide useful guidance optimization. Consider problem multiple
non-commensurable tasks, task assigned qualitative form priority indicating
relative importance. general, exist two alternatives accomplish tasks, i.e.,
consider one task time sequence according task priority accomplish tasks
considering individual task according task priority. Intuitively, former
approach provides good optimization performance tasks higher priority may result
relatively poor performance others. due fact optimizing higher priority
tasks may performance expense lower priority tasks. definition priority
denoted hard priority paper. hand, latter approach provides
distributed approach tasks aim compromise solution importance
priority individual task considered. defined "soft" priority. Similarly, priorities
different objective components MO optimization classified "hard" "soft" priority.
hard priorities, goal settings (if applicable) higher priority objective components must
satisfied first attaining goals lower priority. contrast, soft priorities first optimize
overall performance objective components, much possible, attaining goal
setting individual objective component sequence according priority vector.
achieve greater flexibility MO optimization, two-stage Pareto-based domination
scheme extended incorporate soft hard priority specifications without
goal information means new goal-sequence domination. Here, instead one priority
vector indicate priorities among multiple objective components (Fonseca & Fleming, 1998),
two kinds priority vectors used accommodate soft/hard priority information. Consider
objective priority vector, Pf 1xm goal priority vector, Pg 1xm, Pf(i) represents
priority ith objective component F(i) minimized; Pg(i) denotes priority
187

fiTAN, KHOR, LEE, & SATHIKANNAN

ith goal component G(i) attained; number objectives minimized
denotes natural numbers. elements vector Pf Pg take value
natural numbers, lower number representing higher priority zero representing dont
care priority assignment. Note repeated values among elements Pf Pg used
indicate equal priority provided Pf(i) Pg(i) {1, 2, , m}, avoiding contradiction
priority assignment. combination objective priority vector Pf goal priority
vector Pg, soft hard priorities defined provided one preference
among objective components given
{(Pf : Pf (j) > 1) (Pg : Pg (j) > 1)} j {1, 2, , m}
(2)
Based this, priority setting regarded soft iff
{1, 2, , m} {(Pf : Pf (i) = 1) (Pg : Pg (i) = 1)}
(3)
else, priority denoted hard.
example, settings Pf = [1, 1, 2, 2] Pg = [0, 0, 0, 0] 4-objective optimization
problem indicate first second objective components given top priority
minimized, much possible, considering minimization third fourth objective
components. Since elements Pg zeros (dont care), goal components considered
minimization case. hand, setting Pf = [0, 0, 0, 0] Pg = [1, 1, 2, 2]
imply first second objective components given first priority meet
respective goal components considering goal attainment third fourth
objective components. two different priority settings categorized hard
priorities since cases, objective components higher priority minimized
considering objective components lower priority. soft priority defined Eq. 3,
objective priority vector goal priority vector set Pg = [1, 1, 1, 1] Pf = [2, 2, 3, 3],
respectively. implies evolution directed towards minimizing objective
components goal region attempt minimize higher priority objective
components sequence defined priority vector.
systematically rank individuals population incorporate soft/hard priority
specifications, sequence goals corresponding priority information generated
represented goal-sequence matrix G kth row matrix represents goal vector
corresponding kth priority. number goal vectors generated depends last
level priority z, z maximum value one element Pg Pf given
z = max[Pg(i), Pf(j)]

i, j {1,2,..., m}

(4)

this, goal vectors kth priority goal-sequence matrix Gk(i) priority index k
= 1, 2,, z defined

G (i )

= 1,..., m, G k (i ) = min[F j =1,..., N (i )]
max[F
j =1,..., N (i )]


Pg (i ) = k
P f (i ) = k

(5)

otherwise

N denotes population size; min[F j =1,..., N (i )] max[F j =1,..., N (i )] represents
minimum maximum value ith objective function on-line population distribution,
188

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

respectively. Eq. 5, ith objective component k priority level, reason
assigning Gk(i) G(i) guide individuals towards goal regions; min[F j =1,..., N (i )]
minimize corresponding objective component much possible; max[F j =1,..., N (i )]
relax requirements individuals give objective components room
improvement. According Eq. 5, goal-sequence matrix Gk(i) dynamic generation,
values min[F j =1,..., N (i )] max[F j =1,..., N (i )] dynamically computed depending
on-line population distribution. computing sequence goals Gk k {1, 2,, z},
individuals first ranked according computed goal G1 first priority.
group individuals ranks compared ranked according next
goal G2 second priority evaluate individuals' domination population.
general, ranking process continues individual rank value
ranking goal Gz lowest priority goal-sequence matrix. Note individuals
rank value evaluated components dont care
assignments.
proposed goal-sequence domination scheme given Eq. 5, hard soft
priority specifications incorporated MO optimization. Without loss generality, consider
two-objective optimization problem, f1 higher priority f2, well goal
setting G = [g1, g2]. soft priority optimization defined Eq. 3, goal priority vector
objective priority vector set Pg = [1, 1] Pf = [2, 0], respectively. Let min[F(i)]
max[F(i)] denote minimum maximum value i-objective component F
population, respectively. relevant goals goal-sequence matrix priority level
defined Eq. 5 given G1 = G first priority G2 = {min[F(1)], max[F(2)]}
second priority. goal-sequence domination scheme two-objective minimization
problem illustrated Figure 2. Here, rank value individual denoted r1 r2,
r1 r2 rank value goal-sequence ranking first second priority,
respectively. preference setting indicates g1 g2 given priority
attained optimization individuals ranked according higher priority
f1. illustrated Figure 3a, shows location desired Pareto-front (represented
dark region) expected evolution direction (represented curved arrow)
objective domain example unfeasible goal setting G.
hard priority optimization defined Eqs. 2 3, goal priority vector objective
priority vector set Pg = [1, 2] Pf = [0, 0], respectively. According Eq. 5, gives
goal sequence G1 = [g1, max[F(2)] G2 = [max[F(1)], g2] first second priority,
respectively. implies g1 given higher priority g2 attained optimization.
Figure 3b shows location desired Pareto-front (represented dark region)
expected evolution direction (represented curved arrow) objective domain. compared
solutions obtained soft priority optimization, hard priority optimization attempts attain
first goal component leads solution better f1 (higher priority) worse f2 (lower
priority). mentioned setting soft/hard priority may subjective problem
189

fiTAN, KHOR, LEE, & SATHIKANNAN

dependent practice. general, hard priority optimization may appropriate problems
well-defined goals order avoid stagnation unfeasible goal settings. Soft priority
optimization suitable applications moderate performance among various
objective components desired. Besides soft/hard priority information, may additional
specifications optimization constraints required satisfied optimization.
specifications could easily incorporated MO optimization formulating
constraints additional objective components optimized (Fonseca & Fleming, 1998).
discussed next section.
f2
G'2

77
55
56

G'1

g2

4 4
11

78
23
12

g1

f1

Figure 2: Goal-sequence Domination Goal G = {g1, g2}, Priority Pg = [1, 1] Pf = [2, 0]

f2

f2

G2'

G '1

max[F(2)]

tinon


Evoluti

luo
EEvvooluti

n

desired solution
desired solution

g2

G
G '1

g2

Unfeasible
Region

G

G'2

Unfeasible
Region

g1

g1

f1

max[F(1)]

f1

(a) Soft priority f1 higher f2
(b) Hard priority f1 higher f2
Figure 3: Illustration Soft Hard Priority Unfeasible Goal Setting
2.3 Optimization Soft Hard Constraints

Constraints often exist practical optimization problems (Luus et al. 1995; Michalewicz &
Schoenauer, 1996). constraints often incorporated MO optimization function
190

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

one objective components optimized. could form "hard" constraint
optimization directed towards attaining threshold goal, optimization
meaningless desirable whenever goal satisfied. contrast, "soft" constraint
requires value objective component corresponding constraint optimized much
possible. easy approach deal hard soft constraints concurrently
evolutionary MO optimization given here. generation, updated objective function Fx#
concerning hard soft constraints individual x objective function Fx
computed priori goal-sequence domination scheme given
G (i ) [G (i) hard] & [F x (i) < G (i )]
#
F x (i) =
otherwise
F x (i )

= {1,..., m}

(6)

Eq. 6, objective component corresponds hard constraint assigned value
G(i) whenever hard constraint satisfied. underlying reason
ranking preference particular objective component value
evolutionary optimization process, thus evolution directed towards optimizing
soft constraints unattained hard constraints, desired.
2.4 Logical Connectives among Goal Priority Specifications

MO optimization problems single goal priority specification, decision maker often
needs guess appropriate initial goal priority vector manually observe
optimization progress. goal components stringent generous, goal
setting adjusted accordingly satisfactory solution obtained.
approach obviously requires extensive human observation intervention, tedious
inefficient practice. Marcu (1997) proposed method adapting goal values based upon
on-line population distribution every generation. However, adaptation goal values
formulated way search always uniformly directed towards middle region
trade-offs. restriction may undesirable many applications, trade-off
surface unknown search needs directed direction middle region
trade-off surface. reduce human interaction allow multiple sets goal priority
specifications direct evolutionary search towards different portion trade-off surface
single run, goal-sequence domination scheme extended section enable logical
statements ( ) ( ) operations among multiple goal priority
specifications.
logical operations built top goal-sequence domination procedure
specification. this, unified rank value individual determined taken
effect immediately evolution towards regions concerned. Consider ranking
objective vector Fx comparing rest individuals population reference
two different specification settings Si Sj, Si Sj specifications concerning
set objective functions without goals priorities. Let ranks denoted
rank(Fx, Si) rank(Fx, Sj), respectively. operations two goal
settings defined as,
191

fiTAN, KHOR, LEE, & SATHIKANNAN

rank ( Fx , j ) = min{rank ( Fx , ), rank ( Fx , j )}

(7a)

rank ( Fx , j ) = max{rank ( Fx , ), rank ( Fx , j )}

(7b)

According Eq. 7, rank value vector Fx operation two
specifications Si Sj takes minimum rank value respect two specification settings.
order evolve population towards one specifications objective
vector less strongly violated. contrast, operation takes maximum rank value
order direct evolutionary search towards minimizing amount violation
specifications concurrently. Clearly, operations Eq. 7 easily
extended include general logical specifications complex connectives, (Si
Sj) (Sk Sl), desired.

3. Dynamic Sharing Scheme MOEA Program Flowchart
3.1 Dynamic Sharing Scheme

Fitness sharing proposed Goldberg Richardson (1987) evolve equally distributed
population along Pareto-optimal front distribute population multiple optima
search space. method creates sub-divisions objective domain degrading individual
fitness upon existence individuals neighborhood defined sharing distance.
niche count, mi = Nj sh(d , j ) , calculated summing sharing function members
population, distance di,j represents distance individual j.
sharing function defined

i,j

sh(d , j ) = 1 share

0


, j < share

(8)

otherwise

parameter commonly set 1.
sharing function Eq. 8 requires good setting sharing distance share estimated
upon trade-off surface, usually unknown many optimization problems (Coello
Coello, 1999). Moreover, size objective space usually cannot predefined, exact
bounds objective space often undetermined. Fonseca Fleming (1993) proposed
method Kernel density estimation determine appropriate sharing distance MO
optimization. However, sharing process performed sphere space may
reflect actual objective space population expected uniformly distributed.
Miller Shaw (1996) proposed dynamic sharing method peaks parameter
domain dynamically detected recalculated every generation sharing distance
remains predefined. However, approach made assumption number niche
peaks estimated peaks minimum distance 2share other.
192

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Moreover, formulation defined parameter space handle multi-modal function
optimization, may appropriate distributing population uniformly along
Pareto-optimal front objective domain.
contrast existing approaches, propose dynamic sharing method adaptively
computes sharing distance share uniformly distribute individuals along Pareto-optimal
front generation. requires prior knowledge trade-off surface. Intuitively,
trade-offs m-objective optimization problem form (m-1) dimensional
hyper-volume (Tan et al. 1999), approximated hyper-volume Vpop(n)
hyper-sphere given by,

V pop

(n)

=

(n)


2
1

!
2

( 1) / 2

1

(9)

(n ) diameter hyper-sphere generation n. Note computation
diameter (n ) depends curvature trade-off curve formed non-dominated
individuals objective space. two-objective optimization problem, diameter (n )
equal interpolated distance trade-off curve covered non-dominated individuals
shown Figure 4. Although computation (n ) accurately represents interpolated
curvature non-dominated individuals distribution complex, estimated
average distance shortest longest possible diameter given dmin(n) dmax(n)
respectively (Tan et al. 1999). Let Fx Fy denote objective function two furthest
individuals population. dmin(n) equal minimum length Fx Fy,
dmax(n) estimated d1(n) + d2(n) shown Figure 4.
procedure also extended multi-dimensional objective space. achieve
uniformly distributed population along trade-off set, sharing distance share(n) could
computed half distance individual (m-1)-dimensional hyper-volume
Vpop(n) covered population size N generation n,
N

( 1) / 2
1

!
2

(n)
)
( share

1

(n)
= V pop

(10)

Substituting Eq. 9 Eq. 10 gives sharing distance share(n) generation n term
diameter (n ) population size N given
(n)
share
= N 1 /(1 )

(n)
2

(11)

Clearly, Eq. 11 provides simple computation share capable distributing
population evenly along Pareto front, without need prior knowledge usually
193

fiTAN, KHOR, LEE, & SATHIKANNAN

unknown fitness landscape. Moreover, adopting computation sharing distance
dynamically based upon population distribution generation also appropriate
effective method off-line estimation pre-assumed trade-off surface employed
existing sharing methods, since trade-off surface may changed time along
evolution whenever goal setting altered.
f2

Fx

dmin(n)
(n)

Discovered
trade-off curve

d1 (n)
Fy

d2 (n)

f1

Figure 4: Diameter (n ) Trade-off Curve
3.2 MOEA Program Flowchart

overall program flowchart papers multi-objective evolutionary algorithm (MOEA)
illustrated Figure 5. beginning evolution, population candidate solutions
initialized evaluated according vector objective functions. Based upon user-defined
specifications, goals, constraints, priorities logical operations, evaluated individuals
ranked according goal-sequence domination scheme (described Section 2) order
evolve search towards global trade-off surface. resulted rank values
refined dynamic sharing scheme (described Section 3.1) order distribute
non-dominated individuals uniformly along discovered Pareto-optimal front. stopping
criterion met, individuals undergo series genetic operations detailed
within genetic operations Figure 6. Here, simple genetic operations consisting
tournament selection (Tan et al. 1999), simple crossover mating restriction selects
individuals within sharing distance mating (Fonseca & Fleming, 1998) well simple
mutation performed reproduce offspring next generation.
genetic operations, newly evolved population evaluated combined
non-dominated individuals preserved previous generation. combined population
subjected domination comparison scheme pruned desired population size
according Switching Preserved Strategy (SPS) (Tan et al. 1999). maintains set
stable well-distributed non-dominated individuals along Pareto-optimal front. SPS,
number non-dominated individuals combined population less equal
desired population size, extra individuals removed according rank values order
promote stability evolutionary search towards final trade-offs. Otherwise,
194

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

non-dominated individuals high niched count value discarded order distribute
individuals uniformly along discovered Pareto-optimal front. process, remaining
individuals allowed survive next generation evolutionary cycle repeated
stopping criterion met.

P opulation initialization
Function evaluation
om ination com parison

es


stopping criterion
et?

non-dominated individuals

Final
population


G enetic operations
Function evaluation
evolved
population



new population

ynam ic sharing

com bined
population

om ination com parison

Size(nondom )
> popsize?



Filtering - based
P areto ranked cost

es
ynam ic sharing

Filtering - based
shared costs

Figure 5: Program Architecture MOEA
Genetic Operations MOEA:
Let,
pop(n) = population current generation n
Step 1) Perform tournament selection select individuals pop(n). selected population
called selpop(n).
Step 2) Perform simple crossover mating restriction selpop(n) using dynamic sharing
distance Step 1. resulted population called crosspop(n).
Step 3) Perform simple mutation crosspop(n). resulted population called evolpop(n).
Figure 6: Detailed procedure within box genetic operations Figure 5

195

fiTAN, KHOR, LEE, & SATHIKANNAN

4. Validation Results Benchmark Problems
section validates proposed algorithm two ways. first kind validation (presented
Section 4.1) illustrates proposed features, including goal-sequence domination
scheme, hard/soft goal priority specifications, logical operations among multiple goals
dynamic sharing, enhances performance MOEA MO optimization. shown Section
4.2, second type validation compares performance proposed MOEA various
evolutionary algorithms based upon benchmark problem. Various performance measures used
comparison results discussed.
4.1 Validation Proposed Features MOEA

section, various proposed features MOEA examined usefulness MO
optimization. study adopts simple two-objective minimization problem (Fonseca &
Fleming, 1993) allows easy visual observation optimization performance. function
large non-linear trade-off curve, challenges algorithms ability find
maintain entire Pareto-optimal front uniformly. two-objective functions, f1 f2,
minimized given
8
1

f1 ( x1 ,..., x8 ) = 1 exp xi
=1
8



2






2
8
1

f 2 ( x1 ,..., x8 ) = 1 exp xi +
=1
8


(12)

where, 2 xi < 2, = 1,2,...,8 . trade-off line shown curve Figure 7,
shaded region represents unfeasible area objective domain.

f

2

Trade-off
Curve

Unfeasible
Region

f

1

Figure 7: Pareto-optimal Front Objective Domain
196

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

simulations run 70 generations population size 100. Standard mutation
probability 0.01 standard two-point crossover probability 0.7 used. study
merit dynamic sharing scheme MOEA proposed Section 3.1, 4 different types
simulations performed. first type without fitness sharing. second third
employ fixed sharing distance 0.01 0.1, respectively. fourth uses dynamic sharing
scheme require predefined sharing distance setting. Figure 8 illustrates
respective population distribution objective domain end evolution.
observed four simulations able discover final trade-off,
performance difference terms closeness uniformity population distribution
along trade-off curve.
MOEA without fitness sharing shown Figure 8a, population tends converge
arbitrary part trade-off curve. agrees findings Fonseca Fleming,
(1993). MOEA fitness sharing, shown Figures 8b 8c, population
distributed along trade-off curve rather well, although sharing distance 0.01 provides
uniform distribution 0.1. indicates although fitness sharing contributes
population diversity distribution along trade-off curve, sharing distance
chosen carefully order ensure uniformity population distribution. often
involves tedious trial-and-error procedures order guess appropriate sharing distance,
since problem dependent based upon size discovered trade-offs well
number non-dominated individuals. difficulties solved proposed dynamic
sharing scheme, ability automatically adapt sharing distance along
evolution without need predefined parameter, shown Figure 8d.

(b) Sharing distance = 0.01

(a) sharing

197

fiTAN, KHOR, LEE, & SATHIKANNAN

(c) Sharing distance = 0.1
(d) Dynamic sharing
Figure 8: Performance Validation Dynamic Sharing Scheme MOEA

f2

f2

validate contribution switching preserved strategy (SPS) MOEA,
simulation repeated different scenarios settings. Figure 9a depicts simulation
result without implementation SPS, evolution faces difficulty converging
trade-off curve. solid dots represent non-dominated individuals empty circles
represent dominated individuals. seen, final population crowded
non-dominated individuals distributed distance away trade-off curve.
Figure 9b shows simulation result MOEA SPS filtering solely based upon
Pareto domination. final population managed converge Pareto-optimal front.
However, non-dominated individuals equally distributed diversity
population poor: concentrate portion entire trade-off curve (c.f. Figures 8d,
9b). results clearly show SPS MOEA necessary order achieve good stability
diversity population converging towards complete set trade-offs.

Unfeasible
region

Unfeasible
region

f1

f1

(b) SPS solely based Pareto ranked cost
(a) Without SPS
Figure 9: Performance Validation SPS MOEA

198

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

f2

f2

proposed goal-sequence domination scheme also validated problems different
goal settings, including feasible extreme goal setting (0.98, 0.2) unfeasible goal
setting (0.7, 0.4) shown Figures 10 11, respectively. desired, population seen
concentrate preferred region trade-off curve end evolution, regardless
unattainable extreme goal settings. shown Figures 10 11, MOEA capable
uniformly distributing non-dominated individuals along trade-offs size resulting
different goal settings, help dynamic sharing scheme automatically computes
suitable sharing distance optimal population distribution generation.

f1

f1

Figure 10: Feasible Extreme Goal Setting

Figure 11: Unfeasible Goal Setting

Figure 12 shows trace sharing distance evolution. thin thick lines
represent average sharing distance without goal setting (see Figure 8d corresponding
Pareto-front) goal setting (0.7, 0.4) (see Figure 11 corresponding
Pareto-front), respectively. Generally, MO optimization without goal setting initially small
size discovered Pareto-front, subsequently grows along evolution approach
cover entire trade-off region end evolution. behavior explained Figure 12
sharing distance increases asymptotically along evolution steady value
0.0138 reached. noted value close fixed sharing distance 0.01
Figure 8b, carefully chosen trial-and-error procedures. case MOEA
goal setting (0.7, 0.4), sharing distance increases initially subsequently decreases
0.0025 along evolution, lower value 0.0138 (without goal setting).
reason concentrated trade-off region within goal setting smaller entire
trade-off region (without goal setting), hence results smaller distance uniform sharing
non-dominated individuals. experiments show proposed dynamic sharing scheme
effectively auto-adapt sharing distance arrive appropriate value uniform
population distribution along discovered trade-off region different sizes, without need
priori parameter setting.

199

fiTAN, KHOR, LEE, & SATHIKANNAN

Figure 12: Trace Dynamic Sharing Distance Along Evolution

Non-dominated
individual

f2

f2

Figures 13 14 show MOEA simulation results case infeasible goal setting
soft hard priorities, respectively. figures, diamonds represent goals, small circles
represent non-dominated individuals solid dots represent dominated individuals. soft
priority setting Figure 13, goals treated first priority followed objective component
f1 second priority, i.e., Pg = [1, 1] Pf = [2, 0]. seen, provides distributive
optimization approach goals pushing population towards objective component
f1 higher priority, taking goal vector consideration (c.f. Figures 3a, 13b).
contrast, Figure 14 shows minimization results hard priority setting priority f1
higher f2, i.e., Pg = [1, 2] Pf = [0, 0]. Unlike soft priority optimization, hard priority
minimizes objective f1 relevant goal component g1 = 0.5 satisfied
attaining objective component f2 second goal component g2 = 0.5, shown
Figure 14 (c.f. Figures 3b, 14b). seen, objective values hard priority settings
better higher priority worse lower priority, compared solutions obtained
soft priority optimization (c.f. Figures 13b, 14b).

Non-dominated
individual

ff1

f1

(a) generation 5
(b) generation 70
Figure 13: MOEA Optimization Unfeasible Goal Setting: f1 Soft Priority Higher f2
200

fiNon-dominated
individual

f2

f2

EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Non-dominated
individual

ff11

f1

(a) generation 5
(b) generation 70
Figure 14: MOEA Optimization Unfeasible Goal Setting: f1 Hard Priority Higher f2

ff22

Figure 15 shows MOEA minimization result f1 hard constraint. population
continuously evolves towards minimizing f2 hard constraint f1 satisfied.
general, objective components hard constraints may assigned hard priorities order
meet hard constraints minimizing objective components.

Non-dominated
individuals

ff11

Figure 15: MOEA Minimization Hard Constraint f1
Figures 16 17 show MO optimization results include multiple goal settings specified
logical ( ) ( ) connectives, respectively. operation shown
Figure 16, population automatically distributed equally spread different
concentrated trade-off regions satisfy goal settings separately, regardless overlapping
feasibility goals. proposed dynamic sharing scheme, sub-population size
goal general based upon relative size concentrated trade-off surface goal,
201

fiTAN, KHOR, LEE, & SATHIKANNAN

thus individuals capable equally distributing along different concentrated
trade-off regions. operation illustrated Figure 17, whole population
evolves towards minimizing goals G1, G2 G3 simultaneously. result, individuals
equally distributed common concentrated trade-off surface formed three goals,
desired.
Pareto optimality observation

GG1 1

G
G22
f2

G3
G
3
GG4 4

f1

Figure 16: MOEA Minimization (G1 G2 G3 G4)
Pareto optimality observation

GG11

G22

f2

G
G33

f1

Figure 17: MOEA Minimization (G1 G2 G3)
4.2 Performance Comparisons MOEA

section studies compares performance proposed MOEA
multi-objective evolutionary optimization methods based upon benchmark MO optimization
problem. comprehensive comparison, various performance measures used
comparison results discussed section.
4.2.1 Test Problem
202

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

test problem used performance comparisons two-objective minimization problem
(Deb, 1999). problem chosen discontinuous Pareto-front challenges
evolutionary algorithms ability find maintain Pareto-optimal solutions
discontinuously spread search space. problem involves minimizing objective
functions f1 f2 given below,

f1 ( x1 ) = x1
g ( x2 ,..., x10 ) = 1 + 10
h( f 1 , g ) = 1 ( f 1 g )

0.25

(13a)

10
= 2 xi
,
10 1

( f1 g )sin (10f1 )

f 2 ( x1 ) = g ( x2 ,..., x10 )h( f1 , g )

(13b)
(13c)

(13d)

variables varied [0, 1] true Pareto-optimal solutions constituted xi = 0
= 2, , 10 discontinuous values x1 range [0, 1] (Deb, 1999). Figure 18
depicts discontinuous Pareto-optimal front (in bold). shaded region represents
unfeasible region search space.

Figure 18: Pareto-optimal Front Objective Domain
4.2.2 Current Evolutionary MO Optimization Methods

Besides MOEA, five well-known multi-objective evolutionary optimization methods used
comparison. approaches differ working principles
mechanisms widely cited applied real-world applications. algorithms
summarized readers may refer respective references detailed information.
(i) Fonseca Flemings Genetic Algorithm (FFGA): MO optimization, Fonseca
Fleming (1993) proposed multi-objective genetic algorithm (MOGA) Pareto-based ranking
scheme, rank individual based number individuals current

203

fiTAN, KHOR, LEE, & SATHIKANNAN

population dominate it. algorithm incorporated fitness sharing
mating restriction distribute population uniformly along Pareto-optimal front.
(ii) Niched Pareto Genetic Algorithm (NPGA): method NPGA (Horn & Nafpliotis, 1993)
works Pareto-dominance-based tournament selection scheme handle multiple objectives
simultaneously. reduce computational effort, pre-specified number individuals
picked comparison set help determine dominance. competitors end tie,
winner decided fitness sharing (Goldberg Richardson, 1987).
(iii) Strength Pareto Evolutionary Algorithm (SPEA): main features SPEA (Zitzler &
Thiele, 1999) usage two populations (P P) clustering. general,
non-dominated individual archived P dominated individual dominated
members P removed. number individuals P exceeds maximum value,
clustering adopted remove extra individuals P. Tournament selection applied
reproduce individuals P + P evolution proceeds next generation.
(iv) Non-Generational Genetic Algorithm (NGGA): NGGA (Borges & Barbosa, 2000), cost
function individual non-linear function domination measure density measure
individual. Instead evolving whole population iteration, pair parents
selected reproduce two offsprings. offspring replace worst individual population
offspring lower cost function worst individual.
(v) Murata Ishibuchis Genetic Algorithm (MIGA): Unlike evolutionary
optimization methods, MIGA (Murata & Ishibuchi, 1996) applies method weighted-sum
construct fitness individual population. keep diversity population
along Pareto-optimal front, weights randomly specified pair parent solutions
selected current population generating offspring.
4.2.3 Performance Measures

section considers three different performance measures complementary
other: Size space covered (SSC), uniform distribution (UD) index non-dominated individuals
number function evaluation (Neval).
(i) Size Space Covered (SSC): measure proposed Zitzler Thiele (1999)
measure quantify overall size phenotype space covered (SSC) population. general,
higher value SSC, larger space covered population hence better
optimization result.
(ii) Uniform Distribution (UD) Non-dominated Population: Besides size space covered
population, also essential examine ability evolutionary optimization
distribute non-dominated individuals uniformly possible along discovered
204

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Pareto-optimal front, unless prohibited geometry Pareto front. achieve
smooth transition one Pareto-optimal solution neighbors, thus facilitating
decision-maker choosing his/her final solution. Mathematically, UD(X') given set
non-dominated individuals X' population X, X' X, defined (Tan et al. 2001a),
UD(X' ) =

1
1 + nc

(14)

Snc standard deviation niche count overall set non-dominated individuals X'.
seen larger value UD(X) indicates uniform distribution vice versa.
(iii) Number Function Evaluation (Neval): computational effort required solve
optimization problem often important issue, especially limited computing
resources available. case fixed period CPU time allocated CPU time
function evaluation assumed equal, function evaluations
performed optimization indirectly indicates less additional computational effort required
algorithm.
4.2.4 Simulation Settings Comparison Results
decimal coding scheme (Tan et al. 1999) applied evolutionary methods studied
comparison, parameter coded 3-digit decimals parameters
concatenated together form chromosome. cases, two-point crossover probability
0.07 standard mutation probability 0.01 used. reproduction scheme applied
according method used original literature algorithm comparison.
population size 100 used FFGA, NPGA, NGGA MOEA, require single
population evolution. SPEA MIGA assigned population size 30 70
external/archive evolving population size, respectively, form overall population size
100. approaches comparison implemented common sub-functions
using programming language Matlab (The Math Works, 1998) Intel Pentium II
450 MHz computer. simulation terminated automatically fixed simulation period
180 seconds reached. simulation period determined, preliminary runs,
way different performance among algorithms could observed. avoid random effects,
30 independent simulation runs, randomly initialized population, performed
algorithm performance distributions visualized box plot format (Chambers
et al. 1983; Zitzler & Thiele, 1999).
Figure 19 displays performance SSC (size space covered) algorithm. general,
SPEA MOEA produce relatively high value SSC indicating ability
distributed discovered Pareto-optimal front and/or produce non-dominated solutions
nearer global trade-offs. also observed that, compared others, FFGA,
SPEA MOEA consistent performance SSC. performance UD
(uniform distribution) algorithms summarized Figure 20. general, UD
distributions mostly overlapping thus little evidence draw
205

fiTAN, KHOR, LEE, & SATHIKANNAN

strong conclusion. However, average performance concerned (see bold horizontal line
box plots), SPEA, MIGA MOEA outperform others slightly consistent
terms measure UD. Figure 21 shows distribution Neval (number function
evaluation) performed algorithm specified time. function evaluations fixed
CPU time indirectly indicates less CPU time required algorithm. Intuitively,
means less computational efforts required algorithm find trade-offs. shown
Figure 21, MIGA requires least algorithm effort performances FFGA, NPGA
MOEA moderate terms Neval. also observed SPEA NGGA suitable
problems time-consuming function evaluations: effects algorithm effort become less
significant problems. summary, results show MOEA requires moderate
computational effort exhibits relatively good performance terms SSC UD test
problem, compared MO evolutionary optimization methods study.

Figure 19: Box Plot SSC

Figure 20: Box Plot UD

206

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Figure 21: Box Plot Neval
Figure 22 shows distribution non-dominated individuals objective domain,
range axis identical range shown Figure 18. algorithm,
distribution best selected, among 30 independent runs, respect measure SSC.
seen Figure 22 MOEA benefits evolving non-dominated individuals
methods. MOEAs individuals also better distributed within trade-off region.

FFGA

NPGA

SPEA

NGGA

MIGA

MOEA

Figure 22: Best Selected Distribution Non-dominated Individuals Algorithm
Respect Measure SSC

207

fiTAN, KHOR, LEE, & SATHIKANNAN

5. Application Practical Servo Control System Design
5.1 Hard Disk Drive Servo System
typical plant model hard disk drive (HDD) servo system includes driver (power amplifier),
VCM (Voice Coil Motor) rotary actuator driven VCM. Figure 23 (Goh et al.
2001) shows basic schematic diagram head disk assembly (HDA), several rotating
disks stacked spindle motor shaft.
VOICE COIL MOTOR
ACTUATOR

DISK

ARM

SUSPENSION
RECORDING HEAD

DATA TRACK

Figure 23: HDD Single VCM Actuator Servo System
dynamics ideal VCM actuator often formulated second-order state-space model
(Weerasooriya, 1996),

y& 0 K 0
+ u
=
v& 0 0 v K v

(15)

u actuator input (in volts), v position (in tracks) velocity
R/W head, Kv acceleration constant Ky position measurement gain,
K = K Kt current-force conversion coefficient mass
VCM actuator. discrete-time HDD plant model used evolutionary servo controller
design study given (Tan et al. 2000),
1 1.664
1.384
x(k ) +


1.664 u
1
0



x(k + 1) =

(16)

5.2 Evolutionary HDD Controller Design Implementation

two-degree-of-freedom (2DOF) control structure adopted read/write head servo system
shown Figure 24. simplicity easy implementation, simple first-order discrete-time

208

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

controller sampling frequency 4 kHz used feedforward feedback controllers,
form
z + ff 1

K p = K f
z + ff 2

z + fb1

K = K b
z + fb2

(17)

respectively. control objective tracking HDD follow destination track
minimum tracking error. Note time domain performance specifications
considered paper, design task search set optimal controller parameters
{Kf, Kb, ff1, ff2, fb1, fb2} HDD servo system meets design requirements.
requirements overshoots undershoots step response kept less 5%
since head read write within 5% target; 5% settling time step
response less 2 milliseconds settle steady-state quickly possible
(Goh et al. 2001). Besides performance specifications, system also subject hard
constraint actuator saturation, i.e., control input exceed 2 volts due
physical constraint VCM actuator.

r

Kp

u

+-

VCM

Feedforward
controller



Plant
Ks
Feedback controller

Figure 24: Two Degree-of-freedom Servo Control System
multi-objective evolutionary algorithm (MOEA) proposed paper embedded
powerful GUI-based MOEA toolbox (Tan et al. 2001b) ease-of-use
straightforward application practical problems. toolbox developed Matlab (The
Math Works, 1998) programming environment, allows users make use versatile
Matlab functions useful toolboxes Simulink (The Math Works, 1999). allows
trade-off scenario MO design optimization examined effectively, aiding
decision-making global solution best meets design specifications. addition,
toolbox equipped powerful graphical user interface (GUI) ready immediate use
without much knowledge evolutionary computing programming Matlab. file handling
capability saving simulation results model files Mat-file format Matlab
text-file format software packages like Microsoft Excel also available toolbox.
GUI window MOEA toolbox, time domain design specifications conveniently set
depicted Figure 25, Tr, OS, Ts, SSE, u ue represents rise time, overshoot,
settling time, steady-state error, control input change control input, respectively.

209

fiTAN, KHOR, LEE, & SATHIKANNAN

Figure 25: MOEA GUI Window Settings Design Specifications
simulation adopts generation population size 200, design specifications
listed Figure 25 successfully satisfied end evolution. design trade-off
graph shown Figure 26, line representing solution found. x-axis shows
design specifications y-axis shows normalized cost objective. Clearly,
trade-offs adjacent specifications result crossing lines (e.g.,
steady-state error (SSE) control effort (u)), whereas concurrent lines cross
indicating specifications compete one another (e.g., overshoots (OS)
settling time (Ts)).

Figure 26: Trade-off Graph HDD Servo Control System Design

210

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

closed-loop step response overall system arbitrary selected set MOEA
designed 2DOF controller parameters given {Kf, Kb, ff1, ff2, fb1, fb2} = {0.029695, -0.58127,
0.90279, -0.3946, -0.70592, 0.83152} shown Figure 27. sampling frequency 4 kHz,
time domain closed-loop performance evolutionary designed controller
compared manually designed discrete-time PID controller given Eq. 18 (Goh et al.
2001) well Robust Perfect Tracking (RPT) controller (Goh et al. 2001) given Eq.
19,
0.13 z 2 0.23 z + 0.1
u=
(r )
(18)
z 2 1.25 z + 0.25
x(k + 1) = 0.04 x(k ) + 15179r (k ) 453681y (k )

(19)

u (k ) = 3.43 10 7 x(k ) + 0.04r (k ) 0.18 ( k )

seen Figure 27 evolutionary designed 2DOF controller outperformed
PID RPT controllers, fastest rise time, smallest overshoots shortest
settling time closed-loop response. control performance excellent destination
track crossover occurs approximately 1.8 milliseconds.
1.8
1 : MOEA Based 2DOF Controller

1.6

2

2 : PID Controller
3 : RPT Controller

Head Position (Tracks)

1.4
1.2
3

1

1

0.8
0.6
0.4
0.2
0

0

0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009

0.01

Time Seconds

Figure 27: Closed-loop Servo System Responses Evolutionary 2DOF, RPT PID
Controllers
performance evolutionary 2DOF servo control system verified tested
physical 3.5-inch HDD TMS320 digital signal processor (DSP) sampling rate
4 kHz. R/W head position measured using laser doppler vibrometer (LDV)
resolution used 1 m/volt. Real-time implementation result evolutionary HDD servo
control system given Figure 28, consistent simulated step response Figure
27, shows excellent closed-loop performance.

211

fiTAN, KHOR, LEE, & SATHIKANNAN

Output Response
1.4

Tracks ( Actuator Output )

1.2

1

0.8

0.6

0.4

0.2

0

0

0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009
Time Seconds

0.01

Figure 28: Real-time Implementation Response Evolutionary 2DOF Servo System

6. Conclusions
paper presented multi-objective evolutionary algorithm (MOEA) new
goal-sequence domination scheme allow advanced specifications hard/soft priorities
constraints incorporated better decision support multi-objective optimization.
addition, dynamic fitness sharing scheme simple computation adaptively based upon
on-line population distribution generation proposed. dynamic sharing
approach avoids need priori parameter settings user knowledge usually unknown
trade-off surface often required existing methods. effectiveness proposed features
MOEA demonstrated showing features contains specific merits
usage benefit performance MOEA. comparison existing evolutionary
approaches, simulation results show MOEA performed well diversity
evolutionary search uniform distribution non-dominated individuals along final
trade-offs, without significant computational effort. MOEA applied practical
engineering design problem HDD servo control system. Simulation real-time
implementation results show evolutionary designed servo system provides excellent
closed-loop transient tracking performance.

Acknowledgements
authors wish thank Andrew Moore anonymous reviewers valuable
comments helpful suggestions greatly improved paper quality.

212

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

References
Borges, C. C. H., & Barbosa, H. J.C. (2000). non-generational genetic algorithm
multiobjective optimization. IEEE Congress Evolutionary Computation, 1, 172-179.
Chambers, J. M., Cleveland, W. S., Kleiner, B., & Turkey, P. A. (1983). Graphical Methods
Data Analysis, Wadsworth & Brooks/Cole, Pacific CA.
Coello Coello, C. A. (1996). Empirical Study Evolutionary Techniques Multiobjective
Optimization Engineering Design, Ph.D. Thesis, Dept. Computer Science, Tulane University,
New Orleans, LA.
Coello Coello, C. A. (1999). Comprehensive Survey Evolutionary-Based Multiobjective
Optimization Techniques. Knowledge Information Systems, 1(3), 269-308.
Deb, K. (1999). Evolutionary algorithms multi-criterion optimization engineering design.
Miettinen. Evolutionary Algorithms Engineering Computer science: Recent Advances
Genetic Algorithms, Evolution Strategies, Evolutionary Programming, Genetic Programming,
Industrial Applications, Wiley, New York, 135-161.
Deb, K. (2001). Multi-objective Optimization using Evolutionary Algorithms. John Wiley & Sons,
London.
Fonseca, C. M. (1995). Multiobjective Genetic Algorithms Application Control Engineering
Problems. Ph.D. Thesis, Dept. Automatic Control Systems Engineering, University
Sheffield, UK.
Fonseca, C. M., & Fleming, P. J. (1993). Genetic algorithm multiobjective optimization,
formulation, discussion generalization. (Forrest, 1993), 416-423.
Fonseca, C. M. & Fleming, P. J., (1998). Multiobjective optimization multiple constraint
handling evolutionary algorithms Part I: unified formulation. IEEE Trans. System, Man,
Cybernetics-Part A: System Humans, 28(1), 26-37.
Goh, T. B., Li, Z. M., Chen, B. M., Lee, T. H., & Huang, T., (2001). Design implementation
hard disk drive servo system using robust perfect tracking approach. IEEE Trans. Control
Systems Technology, 9(2), 221-233.
Goldberg, D. E., & Richardson, J. (1987). Genetic algorithms sharing multimodal function
optimization. Proc. 2nd Int. Conf. Genetic Algorithms, 41-49.
Goldberg, D. E. (1989). Genetic Algorithms Search, Optimization Machine Learning.
Addison-Wesley, Reading, Massachusetts.
Grace, A. (1992). Optimisation Toolbox Users Guide, MathWorks, Inc.
Holland, J. H. (1975). Adaptation Natural Artificial Systems. University Michigan, Ann
Harbor.

213

fiTAN, KHOR, LEE, & SATHIKANNAN

Horn, J., & Nafpliotis, N. (1993). Multiobjective Optimization Using Niche Pareto Genetic
Algorithm. IlliGAL Report 93005, University Illinois, Urbana, Illinois, USA.
Luus, R., Hartig, F. & Keil, F. J., (1995). Optimal drug scheduling cancer chemotherapy
direct search optimization. Hungarian Journal Industrial Chemistry, 23, 55-58.
Marcu, T. (1997). Multiobjective evolutionary approach pattern recognition robust
diagnosis process faults. Proc. IFAC Fault Detection, Supervision Safety Technical
Process, UK, 1183-1188.
Michalewicz, Z., & Schoenauer, M., (1996). Evolutionary algorithms constrained parameter
optimization problems. Evolutionary Computation, 4(1), 1-32.
Miller, B. L., & Shaw, M. J. (1996). Genetic algorithms dynamic niche sharing multimodal
function optimization. IEEE Conf. Evolutionary Computation, Japan, 786-791.
Murata, T., & Ishibuchi, H., (1996). Multi-objective genetic algorithm applications
flowshop scheduling. Int. Journal Computers Engineering, 957-968.
Osyczka, A. (1984). Multicriterion Optimisation Engineering. Ellis Horwood, Chichester.
Schaffer, J. D. (1985). Multiple-objective optimization using genetic algorithm. Proc. first Int.
Conf. Genetic Algorithms, 93-100.
Tan, K. C., Lee, T. H., & Khor, E. F. (1999). Evolutionary algorithms goal priority
information multi-objective optimization. IEEE Congress Evolutionary Computation, 1,
106-113.
Tan, K. C., Sathikannan, R., Tan, W. W., Loh, A. P., Lee, T. H., & Mamun, A. Al. (2000)
Evolutionary Design Real-Time Implementation Hard Disk Drive Servo Control System.
Int. Conf. Control 2000, University Cambridge, UK, Section 6C.
Tan, K. C., Lee, T. H., & Khor, E. F., (2001a). Evolutionary algorithms multi-objective
optimization: Performance assessments comparisons. IEEE Congress Evolutionary
Computation, 2, 979-986.
Tan, K. C., Lee, T. H., Khoo, D., & Khor, E. F., (2001b). multi-objective evolutionary algorithm
toolbox computer-aided multi-objective optimization. IEEE Trans. Systems, Man
Cybernetics - Part B: Cybernetics, 31(4), 537-556.
Math Works, Inc. (1998). Using MATLAB, Version 5.
Math Works, Inc. (1999). Simulink: User's Guild, Version 3.
Van Veldhuizen, D. A., & Lamont, G. B. (1998). Multiobjective evolutionary algorithm research:
history analysis. Technical Report TR-98-03, Dept. Electrical Computer Eng.,
Graduate School Eng., Air Force Institute Technology, Wright-Patterson AFB, Ohio.

214

fiAN EVOLUTIONARY ALGORITHM MULTI-OBJECTIVE OPTIMIZATION

Weerasooriya, S. (1996). Basic Servo Problem: Technical Report. Data Storage Institute,
National University Singapore, Singapore.
Zitzler, E., & Thiele, L., (1999). Multiobjective evolutionary algorithms: comparative case
study strength Pareto approach. IEEE Trans. Evolutionary Computation, 3(4), 257-271.

215

fi
ff
fi
! #"$ %
'&)( *,+.-//021$332465327/

89:;< =>/
3?
/-!@BA: %&=C/42?
/0

DFEHGJILKNMPOQSRUTBV)IXWYG<Z[EH\]O2G^Q`_aEcbedfV[ILghDibIkjSKlbLjSILEH\mOQnb]MSEoDqpSGJK<ErV)T
Et\$b]IkO2KlbEtu`vwKcZFKHx9O2KayzGJIb]OG^xxZ|{}O2ILEHKlb]EHu~ILG^pPMS\


kN

$][e2L

C <#qH

ff[e2L

'i2'qF]2e2)PkBHe'2B >)
<e9292
^2
SFce
BF cB#H

>L
t6iBff66iC999626)c! .B2l6 6
6!> e6JB
!tB62!6PlF26t
!99929.$69 S6 2B !B

6B
96 B q2)ql
6 6S6 >9B

B

6iBJB6
9>ff9BL9B

26C6i 2 69292)
B
H C 2<9>> $
.2! H C9
B6 6 B$
B9
6F9B ! PB
l626$cBB
q9
6B
.i99##
6SYH !B

2ff 6i9i 99i96
2# <
69
2, i> B2#92l6S 62699H69 6292.^
669296
H C
.^cF)^ e6)2 6BC
6)9B

2J.<699ffH6 92 P9!B6 $69
[k92!6B6JHC9B) [<6c 6H !B

)26B6<6J
6t9 !B

2<.
FLiBff^9[!2. NBN,!6k 6,69
iFS S29tff9B$iB )
B9ffq96

2
,2
B!F696l CB 6J6996
q2ffqS9669 <i
26J#9'<qH.B6 P6 ff6SB6CB. 69!


fi


fi !"



fi





)



,&





$



%'&






ff








#



.-

/

(


*fi




+

20 1435 7698;t: 7<=6 5
>@?+AB#CDBFEHGJI*KLDMONDG!MJPQNDRTSDMFGG4?#P"UWVYX[Z\]QV#^_^`ZJaQbcYdfe+\OgQhiMFBYjR=IlkFm#n#n7oqpTSrjMJstjMFG!MFSuKpTS/vxwHS/?+A@RyMFC/v#M
A*pyKLzNDSD{ffMJjKB#pTS[K|E}B#SDCqMJ~}{JpyMFSuKjMFB#G!?7SDpTSDvpTGA*pTCDMFRyE4B#{J{ffMJsDK!MFC2B+E#MFGpTB#SS/MJK|A;?#jwz{ff?7SDGpTGKG;?#P
BNDB#RTpyKBYKpy#MstBYjKJIBxY] dZ+aZV7FX#F]#d!VftgQ*.ofI'B#StCBuNDB#SuKpyKBYKpy#M4?7SDM#I B{ff?7RTRyMF{ffKpy?7S?#P
SND4MJjpT{JB#RHsBYjB#4MJK!MJjGJIuNDGNDB#RTRTEl{ff?7SDCDpyKpT?7SDB#RHsDj?#tBYpTRTpyK|E.KBYtRyMFGJL/M(wHS/?%A*RyMFC/v#M(jMJstjMFG!MFSuK!MFCpTS
KL/Mv#jfBYstLDpT{JB#R#{ff?74s?7S/MFSuK pTGMffsDjMFGG!MFC.pTS.K!MJjG2?#P/C/MJsMFSDC/MFSt{ffMB#SDC.pTSDCDMJs`MFStC/MFSD{ffMjMFRTBYKpy?7StGLDpystG
MJKAMJMFSBYjfpTBYtRyMFGJ.*L/MFG!M"jMFRTBYKpy?7SDGLDpystG@BYjMMFSD{ff?CDMFCNDGpTS/vqKL/MsDjMFG!MFSt{ffM?#j.BYtGMFSD{ffM?#P;RTpTSDwG
MJKAMJMFSS/?HC/MFG.pSKL/Mv#jBYstLL/M4wHS/?+A*RTMFC/v#MjMJsDjMFG!MFS[K!MFCpTSKL/MSND4MJjp{JB#RstBYjKlNDB#SuKpyDMFG
KL/MC/MJsMFSDC/MFSD{ffMFG}MFSD{ff?CDMFCpTSKLDMv#jBYstLIB#SDCB#RTRT?+A*GqNDGK!?pTS[K!j?CDNt{ffMNDSD{ffMJjKB#pS[K|ErpTS[K!?KL/M
4?HC/MFR9WRTRtpTSqB#RTRIB+E#MFGpTB#SS/MJK|A;?#jwHGsDj?%pC/M*B#MJjE}pTSuKNDpyKpy#M*v#jBYstLDpT{JB#RtK!?u?7RP?#jjMJsDjMFG!MFSuKpTS/v
BFYB#pTRTBYRyMwSD?+A*RyMFCDv#M#
WS/?#KL/MJjBYK!K!jB#{ffKpT?7S?#P BFE#MFGpB#S S/MJKA?#jwHGpTG;KL/MFpyj(BYtpTRpyKE4K!?4MJ~}{JpTMFS[KRyE}s`MJjP ?#jjMFB#G?7SDpTS/v
KB#G!wHGg#MFSDG!MFSIlkFm#m#lhiMFBYjRI"kFm#n#n7ofL/MpTSDC/MJsMFSDC/MFSt{ffMFG4jMJsDjMFGMFS[K!MFCpTSKL/M*BYjMKL/M
w#MJEK!?KLtpTGBYtpTRTpyK|E#I*jMFCtND{JpTS/v{LDB#S/v#MFGpTSKLDMwS/?%A*RyMFC/v#MG!KBYK!MxK!?Ry?H{JB#R{ff?74stNDKBYKpy?7SDGJS
B#CDCDpTKpy?7S2IHpT4s?#jKB#SuKGBFHpTS/v7G(pTSG!K!?#jBYv#MljMFuNtpyjMF4MFSuKG(BYjMs?7GGpyRyM@GpSD{ffMWpSDC/MJsMFSDC/MFSD{ffMFGB#RTRy?%A
B4PQB#{ffK!?#jpyFBYKpy?7S?#P'KLDM.v7Ry?#tB#RSND4MJjfpT{JB#R`jMJsDjMFG!MFSuKBYKpy?7SgKL/M!?7pTS[K(stj?#tBYtpTRpyKE}CtpTG!K!jpyN/Kpy?7Sof












%

-//0l %% !=6^
= C2
L
!fi;H
:! %&% &2%% 2 =

fi X ttu
LDMJjM LDB#GMJMFSrBRy?#K?#P)A;?#jwpSjMF{ffMFSuK}E#MFBYjG}?7SrKL/MB#NDK!?7BYKpT{RTMFBYjSDpTS/v?#PBFE#MFGpB#S
/S MJK|A;?#jwHG@P j?7CDBYKBH*?7SDG!MFN/MFSuKRyE#ItKLDMJjMlBYjM"B4v#jMFBYK)B#S[ERyMFBYjfSDpTS/vB#Ryv#?#jfpyKLDG(A@LDpT{LBFE
GN/2CDpyHpTC/MFCpTSuK!?KA?v#MFS/MJjB#R@BYsDsDj?7B#{fL/MFGJMJKL/?CtG4tB#G!MFC?7ScY^#]aQ]cY^VYW]^[Z|DZff^[ZJ^fZ
aZ\ffa\gQB#RG!?{JB#RTRyMFCxfcY^/\aQd!VY]^taQV\FZ+ofIB#SDCMJKL/?CtG(tB#G!MFC?7SOBz\ffc#df]^uW^`FaQ]cY^ ( B#SDC Bz\FZVYd!ff
sDj?H{ffMFCDN/jM#
LDMB#Ryv#?#jpTKLDG(tB#GMFC?7SpTSDC/MJsMFSDCDMFSD{ffM)K!MFG!KGWs`MJjP ?#jB}NDB#RTpyKBYKpT#MG!KNDCDEz?#P9KLDMC/MJsMFSH
C/MFSD{ffMB#SDCpTSDCDMJs`MFStC/MFSD{ffMjMFRTBYKpT?7SDGLDpysG*B#4?7S/vzKL/M"BYjfpTBYtRyMFGWpTSOKL/M"CD?7B#pTS2IB#SDCBYK!K!MF4sDK)K!?
tSDCBqS/MJKA?#jwKLDBYK@jMJsDjMFG!MFSuKG(KL/MFGMljMFRTBYKpT?7SDGLDpysGB#G*PBYjWB#Gs?7GGpTtRyM#9L/MJEKL/MJjMJP?#jM.KBYw#MB
RTpTGK@?#P{ff?7SDCDpyKpy?7StB#R'pTStC/MJsMFSDC/MFSD{ffM.jMFRTBYKpy?7SDGLtpystGg?#tKB#pTS/MFCPj?7KL/M4CDBYKBuE4MFB#SDG)?#P{ff?7SDCDp
Kpy?7SDB#RupTSDC/MJsMFSDCDMFSD{ffMK!MFG!KGfo B#G KL/M;pTS/stN/KJIB#SDC.v#MFSDMJjBYK!MB@S/MJKA?#jwKLDBYK'jMJsDjMFGMFS[KGi4?7G!K'?#PKLDMFG!M
jMFRTBYKpT?7SDGLDpysGJ'LDM@{ff?74stNDKBYKpy?7SDB#R`{ff?7G!K;?#P2KLDMFG!MWB#RTv#?#jpyKLDG;pTGB#pTSDRyECDN/M@K!?KLDMWSND`MJjB#SDC
{ff?74stRTMffHpyK|EO?#PGND{fLK!MFG!KGJI'A*LDpT{fL{JB#SB#RTG? {JB#NDG!MNDS/jMFRTpTBYtRyM"jMFGNtRyKGJ?74M4?#PKL/MB#Ryv#?#jpTKLDG
tB#G!MFC?7SKLDpGWBYstsDj?7B#{L?#tKB#pTSGpT4sRTpyDMFC ?C/MFRGgQCDM(B#4s?7GJI9kFm#m#niC/MB#4s?7GWN/MJK!M#I
kFm#m7uiWMFpTv#MJjFIhBY4hiMFBYjRI9kFm#mYHIkFm#m# WN/MJK!MC/MB#s`?7GFIikFm#m#7ofIA@L/MJjMFB#GW?#KL/MJjBYjM4C/Mff
Gpyv7SDMFCP ?#j9v#MFS/MJjfB#R/*)G)gQC/M@B#4s?7G9_WN/MJK!M#IuY###BHtL/MFS/v/Iu;MFRRD pTN2I/kFm#m7uDMJMJwI`kFm#m#
stpTjK!MFGJIt)RyEH4?7N/j*/{L/MFpTSDMFGJIkFm#m#t9MJj}BqhiMFBYjRIkFm#mYH`MJj"N/KL'B#N/jpyK!JMFSIkFm#n#7of
LDMB#RTv#?#jpyKLDG"tB#GMFC?7SrBG{ff?#jpTSDvOPQNDSD{ffKpy?7SBYK!K!MFsDK4K!?tSDCBv#jBYstLKLtBYKBHppyJMFG
KL/MG!MFRTMF{ffK!MFCG{ff?#jM#KL/MG{ff?#jpTS/vPQNDSD{ffKpy?7SpGNDGNDB#RTRTEC/MJtS/MFCB#GB4MFB#GN/jM4?#PtK`MJK|A;MJMFSKL/M
v#jBYstLB#SDCKLDMCtBYKBHWRTRW?#PlKL/MFNDGMBG{ff?#jfpTS/vPNtSD{ffKpy?7SpTS{ff?7ltpSDBYKpy?7SA*pyKLBG!MFBYj{fL
4MJKL/?HCpTSr?#jCDMJj}K!?4MFB#GN/jMKL/MOv#?u?HCDS/MFGGq?#PMFB#{LMffHstRy?#jMFCG!K!jNt{ffKN/jMPj?7KL/MGstB#{ffMO?#P
PMFB#GpytRyMG!?7RTNDKpy?7SDGJiWNDjpTS/vWKL/MMffsRy?#jBYKpy?7SsDj?{ffMFGGFI#KL/M(G{ff?#jpTS/v)PQNDSD{ffKpy?7SpTGBYsDsRTpyMFC"pTS"?#jC/MJjK!?
MJYB#RTNDBYK!M(KL/M(DKSDMFGG9?#P`MFB#{L}{JB#StCDpTCDBYK!M(G!K!jNt{ffKN/jM(K!?KL/MCDBYKBH;B#{LB#RTv#?#jpyKLDpTG9{fLDBYjB#{ffK!MJjpTJMFC
EKL/MG!sMF{Jpyt{G{ff?#jpTSDvPNDSt{ffKpy?7S_B#SDC_G!MFBYj{fLsDj?{ffMFCDNDjMNDG!MFC2LDMxG{ff?#jpTS/vPQNDSD{ffKpT?7SDGBYjM
tB#G!MFC?7SCDpMJjMFSuKsDjfpTSD{JpystRTMFGJI GND{fLB#GMFSuK!j?#sEgQ@MJjG!w#?+HpyKG??#sMJjFI(kFm#mYH(LD?+A'pTN2I
kFm##nDC/M.B#4s?7GJI`kFm#m#ntMJtB#SDMWh'MFBYjfRI`kFm#n7#ofIB+E#MFGpTB#SBYsDstj?7B#{L/MFGgQNDSuKpTS/M#I`kFm#m/IkFm#m#
??#sMJjl*MJjGw#?+HpyKGJIkFm#m#9/jpTMFCDB#Sx?7RTRTMJjFIY##HDjpyMFCDB#SI>@B#{fLDB#ShiMMJ jFIkFm#m#m
WMFpyv#MJj*MF{w#MJjB#S2IqkFm#m#@MF{w#MJjfB#S2IkFm#m#@MF{w#MJjB#SIWMFpyv#MJjO(LDpT{w#MJjfpTS/v/IkFm#m#
OB#CDpyv7B#S,@BYP K!MJjE#IkFm#m/*B#4?7SDp.MJtB#G!KpTB#StpIkFm#m7uqK!MF{wIlY##[ofI?#j KL/MOpTSDpT"ND
WMFG{ffjpystKpy?7S_MFS/v#KLgQ;?7Nt{wYBYMJjKJI}kFm#m#4/jpyMFCtB#SW?7RTCtG!FpTC/KJI"kFm#m# B#B#{J{fLuNDGFI
kFm#m//N/FN/wHpI2kFm#m#I'kFm#m#pTB#S2IDY##[of
LDMJjM;BYjMB#RTG!?)LuEuDjfpTC.B#Ryv#?#jpTKLDGKLtBYKNtG!M;BW{ff?7lpTSDBYKpy?7S?#PD{ff?7SDG!K!jB#pS[K=tB#GMFC"B#StCG{ff?#jfpTS/vY
tB#G!MFC4MJKLD?CDGF S"GMJ#MJjB#RHA;?#jwG(g=HpTSDv7L"B#RyK!?#jKBHI`kFm#m#ItkFm#m#HHstpyjK!MFG_ MJMJw`ItkFm#m#H)B#GL
WjNDFC/JMFRIkFm#m#m;C/Mz(B#4s?7GJIiDMJjSB# SDC/MJff'NDSDBhNDMJjKBHIY#77oKL/MzpTSDC/MJsMFSDCDMFSD{ffMff=tB#G!MFC
B#SDCrG{ff?#jpTS/vY=tB#GMFCB#Ryv#?#jpTKLDGBYjMOB#pTSuKB#pTS/MFCrB#GzG!MJstBYjBYK!MOsDj?H{ffMFGG!MFGJIA*LDp{LrBYjM{ff?7lpTS/MFC
pTSG!?74M4ABFE#IA@L/MJjMFB#G)KL/M4LuEuDjfpTCDpyFBYKpy?7SsDj?#s?7G!MFCOuE@{JpCB#StCCDM(B#4s?7GgY##HIiY#/k+o)pTG
tB#G!MFCx?7SxKL/MC/MJ#MFRT?#st4MFSuK.?#P(B G{ff?#jpTSDvPNDSt{ffKpy?7SKLDBYKlNDB#SuKpyDMFGKL/MCtpTG{ffjMJstB#St{JpyMFG)MJKAMJMFS
KL/MpTSDC/MJsMFSDCDMFSD{ffMFG.CDpTGstRTBFE#MFCuEKLDMz{JB#SDCtpTCDBYK!MqSDMJKA?#jwB#SDCKL/MzCDBYKBYtB#G!M#IB#StCKL/MzG!MFBYj{fL
sDj?H{ffMFGGpG(RTpTpyK!MFCzEKL/MjMFGNDRTKG?#PG?74MlpTSDCDMJs`MFStC/MFSD{ffMWK!MFG!KGJ
SKLDpTG.stBYsMJjFI AM}P?{JNtG?7SxKL/MqG{ff?#jpTS/vuG!MFBYj{LBYsDsDj?7B#{fL2@RyKLD?7N/v7LxB#Ryv#?#jpTKLDG.pTSxKLDpTG
{JBYK!MJv#?#jELDBF#M4{ff?74?7StRyENDG!MFCRy?{JB#R'G!MFBYj{fLMJKL/?CtG"gQNDSuKpTS/M#IkFm#mHkY'??#s`MJj)@MJjG!w#?%pTKGJI
kFm#m#(LDpT{w#MJjfpTS/v/IWMFpyv#MJj4@MF{w#MJjB#SIkFm#m#;C/MB#4s?7G.MJK"B#RyIY#7;@MF{w#MJjB#SMJKB#RyI
kFm#m#7ofI@CtN/MK!?KLDM Mffs?7S/MFSuKpTB#RTRTERTBYjv#MOGpyJM?#PKL/MG!MFBYj{fLG!stB#{ffM#I(KL/MJjMOpTG}Bv#j?+A*pS/vpTSuK!MJj!
MFG!K4pTS?#KL/MJjL/MFN/jpG!KpT{G!MFBYjf{L4MJKL/?HCDGJI9pM#GpNDRBYK!MFCB#SDSDMFB#RTpTS/vg=(LDpT{w#MJjfpTS/vMJK"B#RyI@kFm#m#7ofI
`+f(%== f(=%i==|= ff
fi


fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



KBYtNG!MFBYj{LgQ?7ND{wYBYMJjKJI*kFm#m#NDSuK!MFSDB#NB#NIY##[ofI9DjfB#SD{LB#SDCx?7NDSDCrgQ*pTB#S2I9Y##[ofI
v#MFS/MJKpT{qB#Ryv#?#jpyKLtG.B#SDCMJ#?7RTN/Kpy?7SDBYjEstj?#v#jB#pS/vgQ BYjjf,B SD+ BYv7BHI9h'?#FBH.I -N/jjB#4MFSDCDp=IiON/jv7B
lNDp !s`MJjfGJI*kFm#m#. E#MJjfGJI B#G!w#MJE MJHpyK!KJIkFm#m#m)?7S/v/I B# MFNtS/v/IkFm#m#m7ofI@BYjw#?+
{LtB#pTS?7S[K!MxBYjRT?gQ?H{wYBB#G!K!MFRy?/I*Y#/kY.E#MJjG}MJKB#RyIkFm#m#m7ofI*YBYjpTBYRyM S/MFpyv7Lu?#jL/??C
G!MFBYj{fLrgQC/MB#4s?7GWh;N/MJjKBHIY#/kJBH hNDMJjKBHIY#/k+ofI B#S[K{ff?7Ry?7SuE ?#sDKppyFBYKpy?7SgQC/M}B#4s?7GJI
/MJjS*B# SDC/MJff NtSDBHIB# 4MJ*h;N/MJjKBHIuY#7HhNDMJjKBHIuY#/k+ofIv#jMJMFC/E"jB#SDC/?7pTJMFC"B#CtBYsDKpy#M(G!MFBYj{fL
sDj?H{ffMFCDN/jMFGgQC/MqB#4s?7GJI DMJjSB# SDC/MJff'NDSDB h;N/MJjKBHIiY#77ofIB#SDCMFGKpTBYKpy?7S?#P(CDpTGK!jpytN/KpT?7S
B#Ryv#?#jpTKLDG.gQRTB#SD{ff?/IS/FB BYjjB St+ BYv7BHIY#77of
WRTR9?#PKL/MFG!MqMF4stRy?%ECDpy`MJjMFSuK.G!MFBYj{fLMJKL/?CtGtN/KKL/MqGB#4M}G!MFBYjf{LGstB#{ffM#lKL/MqG!stB#{ffM}?#P
*)GFs?7GGpytRyMB#RyK!MJjfSDBYKpy#MpTGlKLDMqG!stB#{ffMz?#PKL/Mz?#jC/MJjfpTS/v7G.?#P(KLDMqYBYjpTBYtRTMFGqgQC/M B#4s?7GJI
B# 4MJ*h;N/MJjKBHI[Y#7HC/M*B#4s?7G9@NDMJK!M#IuY##YuCDM(B#4s?7Gh;N/MJjKBHI[Y#/kffH/jpTMFCDB#S
?7RRyMJjFItY##H BYjjB St+ BYv7BHIt.NDp !sMJjG(ON/jv7BHI kFm#m#7ofSKLDpTGstBYsMJjFIDLD?+AMJ#MJjFIAMlBYjM4?#jM
pTSuK!MJjMFG!K!MFCpTSOKL/M4G!stB#{ffM4?#P;MFuNtpyB#RTMFSD{ffM"{JRB#GG!MFG)?#P*GqgQhiMFBYjR9MJjBHIkFm#mY[ofIipM#l{JRTB#GG!MFG
?#P9*)GWA*pyKLMFB#{fLjMJsDjMFG!MFSuKpTS/vBCtp`MJjMFS[K*GMJK?#PsDj?#tBYtpRTpyKEqCDpTG!K!jpTtN/Kpy?7SDGF*L/MJjM.pTGB#RG!?}B
SNDlMJj;?#P RyMFBYjSDpS/vlB#Ryv#?#jpTKLDGKLtBYK{JBYjjE?7N/KKL/MWGMFBYj{LpTS}KLDpTGGstB#{ffMgQ@SDCDMJjGG!?7S2IHB#Ctpyv7B#S
hiMJjRB#S2I kFm#m7u LDp{w#MJjpTSDv/I kFm#m#2WB#GL@jfN/FC/JMFRI kFm#m#mOB#CDpyv7B#S2I`@StC/MJjG!?7S2Ih'MJjfRTB#S
9?7RTpTSDGwuE#I2kFm#m#`spyjK!MFG( MJMJw`I kFm#m#7of;*LDpTG;P MFBYKN/jMWjMFCDND{ffMFGKL/MGpyJM)?#P'KL/MG!MFBYj{LGstB#{ffM#I
B#RyKL/?7NDv7LjMF{ffMFSuK"jMFGNDRyKGg=)pTRRTpTG!stpTM4hiMJjRTB#SI9Y#/k+o{ff?7S/tj KLtBYKKLDpG.jMFCDNt{ffKpy?7SpTG"S/?#KB#G
pT4s?#jKB#SuK9pTSK!MJjG?#PKL/M**G!sB#{ffMB#G9sDjMJHpy?7NDGRTElL/?#sMFC gKL/M(jBYKpy??#P`KL/MSND`MJj9?#P*)G
K!?KL/MSuNDMJj?#PiMFuNDpTB#RyMFSt{ffM.{JRTB#GG!MFG@pTGRy?%A;MJj@KLDB#SP?7N/jofLDMsDjpT{ffMAMlLDB+#MlK!?}sBFEP ?#j*KLDpTG
jMFCDNt{ffKpy?7SpTG*KLDBYK*KLDMlMJYB#RTNDBYKpy?7SO?#P9KL/M{JB#StCDpTCDBYK!M"G!K!jND{ffKN/jMFG*C/?MFG*S/?#KWKBYw#MB#C/B#SuKBYv#M?#PB#S
pT4s?#jKB#SuKWsDj?#sMJjKE?#PB#SuEOG{ff?#jpS/vqPQNDSD{ffKpT?7SDGJISDB#4MFRyECDMF{ff?74s?7GBYtpTRTpTKE#I2B#SDCKL/MJjMJP?#jMKL/M
{ff?#jjMFGs`?7StCDpTS/vB#Ryv#?#jpyKLtGBYjM.RyMFGG(MJ~}{JpyMFSuKJ
SKLDpTGstBYsMJj"AMsDj?#s?7G!MBS/MJA G!MFBYj{LGstB#{ffMA*LDpT{fLpTG{JRy?7GMFRyExjMFRTBYK!MFCK!?KL/MG!sB#{ffMz?#P
MFNDpyYB#RyMFSD{ffM{JRTB#GGMFG?#P/*)GJI#B#SDC.A*LDpT{fLA;M;LDBF#M{JB#RTRyMFCKL/MGstB#{ffM?#P`d!Zff\aQd]Q+aZV7JX7J ]'HVYdffaQ]QV# X
Y]d!ZFaZ#d!Vft7\OgQ@h*)GofMC/MJtS/M BxRT?{JB#RGMFBYj{LB#Ryv#?#jpyKLDpTSKLDpTGGstB#{ffM#I(B#SDCrGL/?%A
KLDBYK4ENtGpTS/vBC/MF{ff?74s?7GBYRyMG{ff?#jpTS/vPQNDSD{ffKpy?7SIAM {JB#SMJB#RNDBYK!MRy?H{JB#RTRyExKLDM G{ff?#jM ?#PWKL/M
G!K!jNt{ffKN/jMFG9pTSKL/MS/MFpyv7Lu?#jL/??C?#PtKLDM{JNDjjMFSuK@h*I7KLuNtG?#DKB#pTSDpTSDvWB#SMJ~}{JpTMFS[KB#Ryv#?#jfpyKLD
A*LDpRyM}jMJKB#pSDpTS/vB#S[E?#P*KL/MB#C/YB#S[KBYv#MFG?#P@NDGpS/vMFNDpyYB#RyMFSD{ffM{JRTB#GG!MFG"?#PW*)GJ*PK!MJj4KL/M
?#jpyv7pSDB#R9GN/t}pTGGpy?7S?#P(KLDpGstBYsMJjFI(LDpT{w#MJjfpTS/vgY#77olsDj?#s?7G!MFCxB#SD?#KL/MJjRyMFBYjfSDpTS/v B#Ryv#?#jfpyKLD
KLDBYKzG!MFBYj{LDMFG}pTSKLDMG!stB#{ffMO?#PWMFNDpyYB#RyMFSD{ffM {JRB#GG!MFG?#P*GzB#StCA*LDpT{fLr{JB#SB#RG!?G{ff?#jMOKL/M
{JB#SDCDpCDBYK!MGK!jND{ffKN/jMFGRy?H{JB#RTRyE#I#NDGpTS/v@B){JB#S/?7StpT{JB#RjMJsDjMFG!MFSuKBYKpy?7S4G{fL/MF4MP?#j9MFuNDpTB#RyMFSt{ffM{JRTB#GG!MFGJI
{JB#RTRyMFCc /@TZJaZV7JX7J ]*HVYdffaQ]QVY X#] dZ+aZ4#d!Vft[\g=h*Gfof
LDM*jMFG!K;?#PKL/M@stBYsMJj;pTG?#jv7B#SDpyJMFCzB#GP ?7RTRT?+A*GJG!MF{ffKpy?7SCDpTG{JNDGG!MFGG!?7M*sDjMFRpTpTSDBYjfpyMFG9B#SDC
KL/M)B#C/YB#S[KBYv#MFGB#StCzCtpTGB#C/YB#S[KBYv#MFG?#Pi{JBYjjEHpTS/vl?7NDK;KL/MG!MFBYjf{LzsDj?H{ffMFGGpTSqKL/MWGstB#{ffMFG?#P *)G
B#SDCzMFNDpyYB#RyMFSD{ffM{JRTB#GG!MFG?#Pi*)GJ(MF{ffKpy?7S C/MFG{ffjpyMFGKLDMWv#jfBYstLDpT{JB#R`?#H!MF{ffKGJID*h;*)GJItKLDBYK
A*pTRR'MpTSt{JRTNDC/MFCpTSKL/M}sDj?#s?7G!MFCG!MFBYj{fLG!sB#{ffM#}SMF{ffKpy?7S/IB C/MJKB#pRyMFCC/MFG{ffjpTsDKpy?7S?#PKL/M
Ry?H{JB#RG!MFBYjf{L4MJKL/?HCNDGMFCxK!?MffHstRy?#jMKLDpTGG!stB#{ffMqpG.sDj?%pC/MFC2 MF{ffKpy?7S GL/?%A*G"L/?+AA;M{JB#S
MJYB#RTNDBYK!M)*h**)GMJ~}{JpyMFSuKRyENDGpTSDvlBlC/MF{ff?7s`?7GBYtRyM@G{ff?#jpTS/vPNDSt{ffKpy?7S2MF{ffKpy?7S.{ff?7SuKB#pTSDGKL/M
MffHs`MJjfpT4MFSuKB#R9jMFGNDRTKG)?#PKLDMMJB#RNDBYKpy?7Sx?#PKL/M}sDj?#s?7G!MFCB#Ryv#?#jpTKLD?7SxKLDM}@RBYjgQMFpTSDRTp{L2I
HN/MJjf4?7SDC/KJI.LDB+#MJ??#sMJjFI4kFm#n#m7ofI.StGN/jB#SD{ffMrgQpTSDCDMJjFI?7RTRyMJjFIW*NDGG!MFRTR..B#StBYFBFABHI
kFm#m7#oB#SDC@B#pTRTtSDC/MJj}gQ@DjB#G?7S2I9;j?+A*S2ION/jstLuExpTS/wHRyMJjFIkFm#m#7oS/MJKA?#jwHGJIB#G"A;MFRTR;B#G
?7SCDBYKBYtB#G!MFGP j?7KL/1
0OB#{LDpS/MMFBYjSDpS/vO*MJs`?7GpyK!?#jE#M B#RTG!?pTSD{JRNDC/MqB#SMF4spyjpT{JB#R
{ff?74stBYjfpTG!?7SA*pTKL?#KL/MJj@GKBYK!Mff=?#P=KL/MffBYjK)RTMFBYjSDpTS/v4B#Ryv#?#jfpyKLDGJpTSDB#RTRyE#IHMF{ffKpy?7SO4{ff?7SuKB#pTSDG*KL/M
{ff?7SD{JRTNtCDpTS/vjMFBYjwGB#StCG!?74M.sDj?#s`?7GB#RTGP ?#j*PN/KNDjM)A;?#jw`
2

fi X ttu
8 7%9:;< :=<;> 5 ?>A@B<Lff> D6 C 4 E6
1 6 5 8
L/MGMFBYj{LsDj?H{ffMFCDN/jMFGlNDG!MFCA*pTKLDpTSBFE#MFGpTB#SS/MJK|A;?#jwRTMFBYjSDpTS/v B#RTv#?#jpyKLDGlNDGNDB#RTRTE ?#sMJjBYK!M
?7SKL/M4G!sB#{ffM?#P**)GJ4SKLDpTG){ff?7S[K!MffHKJIiKL/M4sDj?#tRTMF{JB#Sx`MP?#jB#RTRTE MffstjMFGG!MFCB#GJpy#MFS
B{ff?74stRyMJK!MK!jB#pTStpTS/vG!MJK gQpM#AMCD?S/?#K{ff?7SDGpC/MJj"}pTGGpTSDv B#RN/MFGl?#j4RTBYK!MFSuKBYjfpTBYtRyMFGfGo FIH
J (KMLMLMLK ONGP.?#P9pTSDG!KB#St{ffMFG(?#PiBtSDpyK!MG!MJK?#R
P QYBYjpTBYtRTMFGJTI S4IDtSDCzKL/M*V
UW)GND{fLKLDBYK
U W HBYjvB
_g U`
Fo
gk+o
XZY[]\O^
3 54

A*L/MJjM ^ g_U`Fo;pTGBG{ff?#jpTS/v"PQNDSD{ffKpy?7S4MFB#GNDjpTS/vKL/M)DKS/MFGG?#P'B#SuEq{JB#StCDpTCDBYK!M*VUK!?4KL/M
CDBYKB#G!MJK*FIDB#StC1acbzpTGKL/M.PQB#pTRyEq?#PiB#RRKL/Ml*)G@A*pyKLBQxSD?C/MFG -
OB#S[E}?#P`KLDM@G!MFBYj{fLzsDj?H{ffMFCDN/jMFGJIupTSD{JRTNDCtpTS/vWKL/M@{ff?7?7SDRyE4NDG!MFCqRy?{JB#RG!MFBYj{fLzMJKL/?CtGJI[jMFRTE
?7SBS/MFpyv7Lu`?#jfL/?u?HCG!K!jNt{ffKN/jM4KLDBYK"C/MJtS/MFGKLDM}Ry?H{JB#RjNDRTMFGg?#s`MJjfBYK!?#jGfoNtG!MFCK!?O?+#M}A@pyKLDpTS
KL/M4G!MFBYj{fLG!stB#{ffM#lLDMG!KB#SDCtBYjCS/MFpyv7Lu`?#jfL/?u?HCpSKL/MG!stB#{ffM?#P*)G.NDGMFG@KLDM?#sMJjBYK!?#jG)?#P
BYj{@B#CDCDpyKpy?7SI[BYj{*CDMFRyMJKpy?7S}B#StC}BYj{*jMJ#MJjGB#RIKL/MJjMJEBF#?7pCDpTS/vgQpTS4KL/M@DjG!KB#StC}KL/M@KLDpyjC}{JB#G!M%o
KL/MlpSD{JRTNDGpT?7S}?#PCDpyjMF{ffK!MFC{ffE{JRyMFG@pTSKL/Mv#jBYsL2
LDMxB#Ryv#?#jpyKLD}GKLDBYKG!MFBYj{fL,pTSKLDMxG!stB#{ffMx?#P*)GNDGpTSDvRT?{JB#R4MJKLD?CDGBYjMMJ~}{JpyMFSuK
B#pTStRyEMF{JB#NDG!Mz?#P*KL/MC/MF{ff?74s?7GBYpTRTpyK|EsDj?#sMJjKEKLDBYK4B#S[EG{ff?#jpTSDvOPQNDSD{ffKpy?7StGlMff/LDpytpTKJ
G{ff?#jpS/vlPQNDSD{ffKpy?7S ^ pTGGB#pTCqK!?M4[Zfc /@Hc\JV[ffTZpTP2KL/MWG{ff?#jM)?#P B#S[EqB+E#MFGpTB#S SDMJKA?#jw}G!K!jNt{ffKN/jM
B+E4`M*MffsDjMFGG!MFC}B#GBsDj?CDNt{ffK@g?#jBlGNDpS4KL/M@RT?#vYG!stB#{ffM%o?#PRT?{JB#RG{ff?#jMFGpTS[#?7RTpTSDv?7SDRyE?7S/M
S/?HC/M.B#SDCpyKGstBYjMFSuKGJ
_g U`
Fdo Hfe ^Tj lg k KnmGo X lg kDo!o
g7o
^
g Yih

lg k KnmGo X glkDo!o]H
glk KnmGo X glk/o;p gq r=st + g 1
g7o
^
A*L/MJjMup gq r=svt + g 1 BYjM"KL/M4G!KBYKpTGKpT{JG)?#PKL/MYBYjpTBYtRyMFGwkOB#StC mxo X glk/o@pTSyFIp=M#KL/M4SuNDMJj@?#P
pTSDGKB#SD{ffMFGpTScFKLtBYK;BYK{fL}MFB#{fL}s?7GGpTtRyM(pTSDG!KB#SuKpTBYKpy?7S?#=P kB#StC mGo X glkDof mGo X glkDoA*pTRRCDMFS/?#K!M
KL/M.sBYjMFS[KGMJK?#PRkzpTSKLDM.*z
UIDpM# mGo X lg k/{o H J|(} S~ |{ k } UP7
sDj?H{ffMFCDN/jMKLDBYK;{LDB#S/v#MFG?7S/M*BYj{(BYKMFB#{L}?+#M@{JB#S}MJ~}{JpyMFSuKRyElMJYB#RTNDBYK!M*KL/M*pT4stj?+#MF4MFSuK
?#DKB#pTSDMFCEKLtpTGq{fLDB#S/v#M# HND{L_BsDj?{ffMFCDNDjMO{JB#SjMFNtG!MKL/M{ff?74stN/KBYKpy?7StGz{JBYjjpyMFC?7N/KBYK
sDjMJHpy?7NDG G!KBYv#MFGJI[B#SDCl?7SDRyE)KL/MG!KBYKpTG!KpT{JGi{ff?#jjMFGs`?7StCDpTS/vK!?WKL/MYBYjpTBYtRTMFGA*L/?7GMstBYjMFSuK'G!MJKGLDB+#M
MJMFS4?HCDpyDMFCS/MJMFC K!?4`MjMF{ff?74stN/K!MFC2;L/MB#CDCDpyKpT?7S?#j*C/MFRyMJKpy?7S?#P9B#S BYjf{ kpTSB*
U {JB#SzKL/MJjMJP?#jM)M@MJYB#RTNDBYK!MFCzE}{ff?74stNDKpTS/vl?7StRyE4?7S/MS/MJARy?{JB#RG{ff?#jM#I
lg k KnmGo X( lg kDo!o?#j
^
j
n
K
G


lg k
{ k4jMFNDpyjMFGKL/M
Xn lg k/o!ofIHjMFG!sMF{ffKpy#MFRTE#*L/M*MJYB#RTNDBYKpy?7Sq?#P2KL/M@jMJ#MJjGB#R`?#PB#SzBYj
^{ff?7
j 4stNDKBYKpy?7S?#PKA?qS/MJART?{JB#RG{ff?#jMFGJI
lg k Knmxo X(n lg k/o!o(B#SDC
lg KnmGo X lg 2o!of
KlGL/?7NtRTC`MSD?#K!MFCxKLDBYK.MFB#{fLGK!jND^{ffKj N/jMpSKL/M}*G!stB#{ffM}^ j pG.S/?#K.B#RyABFg EHGlCDpy`MJjMFSuKPj?7
KL/M?#KLDMJjGlpTSxK!MJjG.?#P(pyKGljMJsDjMFGMFS[KBYKpy?7S{JBYstBYtpTRpyKE`.pyPA;MzpTS[K!MJjsDjMJKKL/M}BYjf{JGpTSBO*B#G
{JB#NDGB#R/pS[K!MJjB#{ffKpT?7SDGMJKAMJMFSBYjpBYtRyMFGJIYKL/MFSMFB#{fL*jMJsDjMFG!MFSuKGBCDpMJjMFS[K4?HC/MFR7L/?%A;MJ#MJj+I
pyP2AMWGMJMWB"* B#GB"G!MJK;?#P'C/MJsMFSDC/MFSD{ffM pTStC/MJsMFSDC/MFSD{ffM(jMFRBYKpy?7SDGLDpTstG9MJKAMJMFSBYjfpTBYtRyMFGWgKLDBYK
sMJjpyKG;NDG;K!?"PQB#{ffK!?#jpyJMB?7pS[K;sDj?#tBYtpRTpyKE4CDpG!K!jpytNDKpy?7SofI#KL/MFSCDpMJjMFSuK;*G(BFEqjMJsDjMFG!MFSuK
KL/MGB#M4?CDMFR"#MFSpTSKL/M{JB#G!M4?#PNDGpS/vB{JB#NDGB#R9pTSuK!MJjsDjMJKBYKpT?7S2I pyPAM}NDGM"?#G!MJjYBYKpy?7SH
?7SDRyEzCDBYKBgQB#G*?#sDs?7G!MFCK!?MffHsMJjpT4MFSuKB#R2CDBYKB4A*LDMJjM.G!?74MYBYjpTBYtRTMFG(BFEM.B#SDpysNDRTBYK!MFCofIHpyK
F
'=!v %i ff % M=' ,% %D .=] v =" v ] = #v % ] D=)=%d ;
Dfff
#d + = wM
^j



fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



Tp G(NDpyK!M.{ff?7?7S P?#jKA?}BFE#MFGpB#SOS/MJK|A;?#jwG*K!?MMF4stpyjp{JB#RTRyEpTSDCtpTG!KpTS/v7NtpTGLDBYtRTM#2L/MFSKA?
*)GwU B#SDC1U{JB#SjMJstjMFG!MFSuKKLDM)GB#4MG!MJK(?#P'{ff?7SDCtpyKpy?7SDB#R`pTSDC/MJsMFSDCDMFSD{ffM@B#GGMJjKpy?7SDGJIHAMGBFE
KLDBYKKLDMFG!Ml*)GWBYjMzZ"JH]lVYTZff^ta 0 gQhiMFBYjR' 9MJjBHIikFm#mY[ofI`B#SDCAMlC/MFSD?#K!M.KLDpTG(B#GwUU
L/MFS RyMFBYjfSDpTS/vBFE#MFGpTB#SOS/MJKA?#jwHGPj?7 CDBYKB4NDGpTS/v4G{ff?#jpTSDv"PQNDSD{ffKpT?7SDGJIHKA?}CDpMJjMFSuK.gtN/K
MFNDpyYB#RyMFS[Kfo;*GBFEzMWpSDCDpTG!KpS/v7NDpTGLtBYtRyM#I7CDN/MWK!?4KL/M)Mff/pTG!K!MFSD{ffM)?#P'pS[YBYjpTB#SuKsDj?#sMJjKpyMFG;?7S
MFNDpyYB#RyMFS[KW*)GJI2EHpyMFRTCtpTS/v4MFNDB#R'G{ff?#jMFGJ*M{ff?7NDRTCOKBYw#M4B#C/YB#S[KBYv#M?#PKLDpG*pTS?#jC/MJjWK!?qv#MJKB
4?#jMljMFCDND{ffMFCG!sB#{ffM.?#P9G!K!jND{ffKN/jMFGK!?MMffstRT?#jMFC2
LDMWP?7RTRy?%A*pTS/vKL/MJ?#jMF stj?+HpTC/MFGBv#jBYstLtpT{JB#R{ffjpyK!MJjpy?7SzP?#jC/MJK!MJjpSDpTS/vKL/M)MFuNDpTB#RyMFSt{ffMW?#P
KA?q**)GJ
n[ff(ff=ff, b5
c 5;\.V#d!Z"Z JHl] VYTZff^ta;] VY^cY^tXz] aHZffX}V YZ
u ,
aHZl\JV /}Zl\e#ZJyZFa=cY^xVY^aHZl\JV /}Z +|\aQdDFaQHd!Zffi\
L/Ml\e7ZffTZJa=cY^4?#PB* pTG;KL/M)NDSDCDpTjMF{ffK!MFCv#jBYsL}KLDBYKjMFGNDRyKGPj?7pyv7S/?#jpS/vlKL/MWCDpyjMF{ffKpT?7SDB#RTpyK|E
?#PiMJ#MJjEMFC/v#M#;z
+|\aQdDFaQHd!ZpTSB*
UpTG(B#S?#jC/MJjMFCK!jpystRTMJK;?#P9S/?HC/MFGJIlg K k Kn ofI`GND{L KLDBYK

gk+{o U{ff?7S[KB#pTStGKL/M)BYj{JG kB#StcC k5 IHB#SDCg7o9KL/MWS/?HC/MF]G B#SDC BYjM@S/?#KB#CB#{ffMFS[KpTcS U
HZV7Ya=cY/ZV7.HV#aaZJdf^gQGL/?#jK!MFS/MFCLHLopTS}B*8
UpTG;B#S}?#jfC/MJjMFCqK!jpystRyMJK?#P S/?HC/MFGJI`lg K k Kn ofI
GND{fLKLtBY*K U{ff?7SuKB#pTSDG@KL/MBYj{J G k B#St
C k W>*?#K!M"KLDBYK)pTSB#SLHLOstBYK!K!MJjSlg K k Kn o*KL/M

S/?HC/MFffG B#SDC {JB#S`M.B#CY!B#{ffMFSuKJ
WS/?#KL/MJj"{LDBYjB#{ffK!MJjfpyFBYKpy?7Sx?#PMFNDpyYB#RyMFSuK.*)GAB#GlsDjMFG!MFSuK!MFCxE(LDpT{w#MJjfpTS/vxgkFm#m#7ofI9K!?Y
v#MJKL/MJjA*pTKLsDj?u?#PKLtBYK)GMJ#MJjB#R9G{ff?#jpTSDvqPQNDSD{ffKpy?7StG@NDGMFCOP?#j.RyMFBYjStpTS/v}BFE#MFGpTB#SxS/MJK|A;?#jwHG)Pj?7
CDBYKBv7py#MWKL/MWGB#4MWG{ff?#jM@K!?MFNDpyYB#RyMFSuK;G!K!jNt{ffKN/jMFG)gQGND{LqPQNDSD{ffKpy?7SDGBYjM){JB#RTRyMFC \ffc#d!ZnZ FH] YVYyZJ^ta
^`FaQ]cY^/\!of
LDM.{ff?7SD{ffMJsDK*?#PMFNDpyYB#RyMFSD{ffM?#P9*)G@stBYjKpTKpy?7SDG(KL/MG!stB#{ffM.?#P9*)GWpTSuK!?}BG!MJK*?#PiMFNDpyYB
RyMFSD{ffM{JRTB#GGMFGJ@L/MFS/MJ#MJj.BzG{ff?#jMMFNDpyYB#RyMFSuK*PQNDSD{ffKpy?7SpTG*NtG!MFC2IpyKWGMJMFG)SDBYKN/jB#R'K!?G!MFBYj{LP?#j
KL/MWMFG!K;{ff?7S/tv7N/jBYKpy?7SzpTSqKLDpTGS/MJAGstB#{ffM@?#P MFuNDpTB#RyMFSt{ffM@{JRTB#GGMFG;?#P'*)GJ*LDpTG{fLDB#S/v#MpTSqKL/M
G!MFBYj{fLG!sB#{ffMlBFEDjfpTS/v4G!MJ#MJjB#RB#CDB#SuKBYv#MFGJ
*L/M.G!stB#{ffM.?#PMFNDpyYB#RyMFSuK{JRTB#GG!MFGpG4?#jMjMFCtND{ffMFCKLDB#SKLDMlG!stB#{ffM.?#P*)GgQB#RyKL/?7NDv7L pyK
pGG!KpTRTRMFSD?#j4?7NDGfofM{ff?7NDRTC KL/MJjMJP?#jM.MffHs`MF{ffK*K!?}?#DKB#pTS `MJK!K!MJj*jMFGNDRyKGgA*pyKLKL/MGB#4M
GMFBYj{LMff`?#jKfof
WG"A;MC/?S/?#K"Gs`MFStCKpT4Mzv#MFS/MJjBYKpTSDvgQNDGpS/vKL/Mq?#sMJjBYK!?#jGC/MJtS/MFCK!??+#MMJKAMJMFS
SDMFpyv7L[?#jpS/v{ff?7S/Dv7N/jBYKpT?7SDGpTS_KL/MG!MFBYj{LG!stB#{ffM%oB#StC_MJB#RNDBYKpTS/v,gQNDGpTS/vKL/MxG{ff?#jfpTS/v
PQNDSD{ffKpT?7So`MFNDpyYB#RyMFS[Ki*)GJI#AM{ff?7NDRTC.?#tKB#pTSl4?#jMMJ~}{JpyMFSuKB#Ryv#?#jpyKLD}GJ'@?+AMJ#MJjFI[B#G'KL/M
jfBYKpy?l?#P2KL/MWSuNtlMJj?#P2MFNDpyYB#RyMFSD{ffM*{JRB#GG!MFG;K!?KL/M@SuNDMJj?#P*GGMJMFGWgMFstpyjpT{JB#RRyE/o
K!?OB#G!EsDK!?#K!M}K!?H#7g=)pTRRTpTG!stpTM" hiMJjRT}B#S2I'Y#/k+ofIKL/MMJ~}{JpTMFSD{ffEpT4sDj?%#MF4MFSuK.BFE
M.G}B#RTR
*L/MlG!MFBYj{fLpTS KL/MlG!stB#{ffMl?#P**)G@}BFEMMFB#GpTRyEzK!jBYsDsMFC pSBRy?H{JB#R2?#sDKpT"NDItB#StCKL/M
GpyKNDBYKpy?7SA?#jG!MFSDGB#GKL/M?#sMJjBYK!?#jGC/MJtSDMFCP?#jKLDpTG"G!stB#{ffM{JB#S4?%#M`MJK|A;MJMFS{ff?7SDDvY
NDjBYKpy?7SDG.{ff?#jjMFG!s?7SDCDpTSDvzK!?OMFuNtpyB#RTMFS[Kl**)GzgA@LDpT{LxA*pTRTRM4MJYB#RTNDBYK!MFCA*pyKLKL/MzGB#4M
G{ff?#jM%ofLDpG9CDpy~}{JNDRTKE{JB#S}MstBYjKpTB#RTRyE"BF#?7pTC/MFCzpyPAM@G!MFBYj{fLqpS4KL/M@GstB#{ffM*?#P2MFNDpyYB#RyMFSD{ffM
{JRB#GG!MFGJ
+`+ ffff+=f=if*=9==
Ti

TM


"v
fi [" )=; =%=|=
"; fi fi T" c
"v
fi
22f(O
fff !Q; %%; v % ,2= (f='=Q; |= f. %='=%'l ` Oi !" *= += J`=%
=f( %= Q; %%; v %ff ll=( ((v l =Y; u|=ft=% f; %;=ff =|= G
= yfff * %=Q; = *%; %ff f` Q; +; v +=l ( v %=" J . v +


fi X ttu
LDMzCDpGB#C/YB#S[KBYv#MFG4BYjMKLDBYKJI;pTSKLtpTGGstB#{ffM?#PMFuNtpyB#RTMFSD{ffMz{JRB#GG!MFGJIpTK"pTG"4?#jMMffHsMFSDGpy#M
K!?v#MFS/MJjfBYK!MlS/MFpyv7Lu?#jpTS/v{ff?7S/Dv7N/jfBYKpy?7SDGJI/MF{JB#NDG!MAM.B+EzMP?#j{ffMFCK!?4sMJjP?#j G!?74MlwpTStCq?#P
{ff?7SDGpG!K!MFSD{ffE{L/MF{wI7pS?#jC/MJjK!?@MFSDGN/jMKLDBYKKL/MFGM;{ff?7S/Dv7NDjBYKpy?7SDG2jMJsDjMFG!MFSuK MFNDpyYB#RyMFSD{ffM{JRTB#GG!MFG 3
pTSB#CDCDpTKpy?7S2I[KLDMWMJYB#RTNDBYKpT?7S?#P KL/MS/MFpyv7Lu?#jpTS/v"{ff?7S/Dv7N/jfBYKpy?7SDGBFEB#RTG!?"M4?#jM)MffsMFSDGpy#MWpTP
AMlBYjMlS/?#K@BYtRyMK!?KBYw#M"B#C/B#SuKBYv#M"?#P'KL/MC/MF{ff?74s?7GBYtpTRpyKEqsDj?#sMJjKEz?#PiKL/MlG{ff?#jpS/v4PNtSD{ffKpy?7S2
pTSDB#RTRTE#I KL/MS/MJAGMFBYj{LG!stB#{ffMpyv7LuKpS[K!j?HCDND{ffMqS/MJARy?H{JB#RBHpBKLDBYKBYjMS/?#KlsDjMFG!MFS[K"pTS
*G!stB#{ffM#
S?#jC/MJj4K!?xC/MFGpTv7SB#SMffHstRy?#jpS/vOstj?{ffMFGGP?#j4KL/MG!stB#{ffM?#P@MFuNtpyB#RTMFSD{ffMz{JRB#GG!MFGAM {ff?7NDRTC
NDG!MqKA?CDpTG!KpTSt{ffKlBYsDsDj?7B#{fL/MFGJKLDMqDjfG!K{ff?7SDGpTG!KG"pTS{ff?7SDGpTC/MJjpTSDv KLDBYKB#SMFNDpyYB#RyMFSD{ffM{JRTB#GG"pTG
jMJsDjMFG!MFS[K!MFCEqB#SuEz?#P'pyKG{ff?74s?7S/MFSuKGlgQpTSzKLDpTG{JB#G!M#IDpTKpGSDMF{ffMFGGBYjEzK!?BF#?7pTCMJYB#RTNDBYKpS/v44?#jM
KLDB#Sz?7S/M{ff?74s?7S/MFSuKs`MJj({JRTB#GGfofDB#SDCzKL/MG!MF{ff?7SDC{ff?7SDGpTG!KGpTSzNDGpTS/v"B4{JB#S/?7SDpT{JB#R`jMJstjMFG!MFSuKBYKpy?7S
G{fL/MF4M.P?#jKL/Ml{JRB#GG!MFGJ
LDMv#jfBYstLDpT{JB#RW?#H!MF{ffKG {ff?74?7StRyENDGMFCK!?jMJsDjMFG!MFSuKMFNDpyYB#RyMFSD{ffM{JRTB#GG!MFG?#P"*)GBYjM
V7FX#F]W/VYdaQ]VYX#] dZ+aZz#d!Vft7\"gQhiMFBYjR99MJjBHI9kFm#mY[ogwHS/?+A*SB#G { 5;\!of*LDMFG!Mv#jfBYstLDG
{ff?7SuKB#pTS`?#KLOCDpyjMF{ffK!MFCgQBYj{JGfo*B#SDCNDSDCDpTjMF{ffK!MFCgQRTpS/wGoMFC/v#MFGJItN/K@S/?zCtpyjMF{ffK!MFC{ffEH{JRyMFGJ)py#MFSB
h**
C/MJtS/MFC?7SB.tStpyK!MG!MJK?#P2S/?HC/MFDG SB#SDCBlSD?C/ffM k } S4IuKL/MP?7RTRy?%A*pTS/vGN/G!MJKG?#P2S/?HC/MFG
BYjMlCDMJtS/MFC2
mxo lg kD]
H J|ff} S~ |] k } P7ItKLDM.G!MJK?#P'HVYdZff^ta\(?#RP k`

lg kD]
H J|ff} S~k |} P7ItKLDM.G!MJK?#Pff[]yYd!ZJ^}?#RP k`
x

H J|ff} S~k` |} P7IDKLDMlG!MJK?#P^`ZJ]#HcYdf\?#.P k`
p lg kDd
lg kDff
H J|} S~ |Z k } K ?#Zj k |} ?# j k |} P7I2KL/MG!MJKW?#P@V7 JV7Zff^ta\WK!? k`
*
uHpy?7NDGRTE * lg k/{
H mGo? lg kDDo x lg kD=o Bpy lg k/of
WSOBYjx{ k pS Bq**
UpGTc /*DZffyZpyP9pyK@BYsDsMFBYjG@pTSMJ#MJjEO*MFRy?7S/v7pTS/v4K!?qKL/MGB#4M
MFNDpyYB#RyMFSD{ffM4{JRTB#GGB#G U"WSBYj{ kpT
UpGWGB#pTCK!?MqdiZ #Zffdf\f]=ffTZpyPpTK)pGS/?#K{ff?74sMFRTRyMFC2I
pM#.KLDMJjM4pTG)Bz**
U MFNDpyYB#RyMFS[KWK!
? UKLDBYK.{ff?7SuKB#pTSDG)KLDMBYjf{ k`lWG)MJ#MJjEO** pTSB
stBYjKp{JNDRTBYj*MFNDpyYB#RyMFSD{ffM"{JRTB#GGWLDB#GWKL/MGB#4M"GMJKW?#P{ff?7s`MFRRyMFCB#SDCOjMJ#MJjGpytRyM"BYj{JGJIBq{JB#S/?7StpT{JB#R
jMJsDjMFG!MFS[KBYKpT?7Sq?#PB#SzMFNDpyYB#RyMFSD{ffMW{JRTB#GGpTGKLDMWh;* {ff?7SDGpTGKpTS/vl?#PB#SBYj{@P?#j;MJ#MJjEz{ff?74sMFRTRyMFC
BYj{pTSzKL/M)MFNDpyYB#RyMFSD{ffM{JRTB#GGFIHB#StCB4RTpTS/w4P?#j(MJ#MJjEzjMJ#MJjGpyRyMWBYjf{YLDpTG;wHpTSDCq?#P'jMJstjMFG!MFSuKBYKpy?7S
LDB#GMJMFS}v7pT#MFSzGMJ#MJjB#RSDB#4MFGJiHV7aaZffd^Og=stpyjK!MFG; MJMJw`IkFm#m#7ofI'fc /@yZFaZ {w%Mg %o
g=LDp{w#MJjpTSDv/IkFm#m#7ofIWZff\\FZff^taQ]VYi7dVtgQ@StC/MJjGG!?7SxMJK"B#RyIkFm#m7u;)B#GL@jfN/FC/JMFRIkFm#m#m7ofOWG
B{ff?7StG!MFuNDMFSD{ffM}?#P(KL/MJ?#jMFkYIB{ff?74sRyMJK!MFCh;*s?7GG!MFGG!MFGB#SBYjc{ kpTPB#StC?7SDRyEpyP(B
K!jpysRyMJK;?#PiS/?HC/MFGlg K k Kn o;P ?#jfGB[G!K!jfND{ffKN/jMW?#j(KL/MBYj*{ k}pTGjMFNDpyjMFCqK!?4MWCDpTjMF{ffK!MFCCDN/M
K!??#KL/MJj*[G!K!jfND{ffKN/jMFGlgK!?qBF#?7pTCP ?#j}pTS/v4BS/MJA_uG!K!jND{ffKNDjM?#j*{ffjMFBYKpTSDv}BCDpyjMF{ffK!MFC{ffE{JRyM%o.gQG!MJM
pyv7N/jMk+of
>@?#K!MKLDBYKqB#SBYjtpTK!jBYjEh*C/?MFGzS/?#KzSDMF{ffMFGGBYjpTRTEjMJsDjMFG!MFSuKqG!?7MOMFNDpyYB#RyMFSD{ffM{JRB#GG
?#P**GJIB#RyKL/?7NDv7LKL/MJjMqpTG"B?7SDMff=K!?Y=?7S/M{ff?#jjMFG!s?7SDC/MFSt{ffM}MJKAMJMFS{ff?74stRyMJK!MFCh**)G4B#SDC
MFNDpyYB#RyMFSD{ffMl{JRTB#GG!MFG?#P*GJ>*MJ#MJjKL/MFRyMFGGJI`{ff?74stRyMJK!MFCh**)G@BYjM{ff?7SDGpC/MJjBYtRyE4?#jM{ff?7
stRTp{JBYK!MFCKLDB#Sv#MFS/MJjB#R9h;*)GJ{LDBYjfB#{ffK!MJjpyFBYKpy?7S?#PKL/MG!sMF{Jpy{lsDj?#s`MJjKpyMFGWKLDBYK.Bh*
"NDG!K(#MJjpyPEpTS?#jC/MJjK!?}`M.B}{ff?74stRyMJK!MFC h;*AB#G*?#DKB#pTS/MFCE@SDCDMJjGG!?7SMJK*B#R= gkFm#m7#of
,
i==Y=%v #=f= 'v ; v = ff|==f`" ; =%ff .O Y" @fG " v % Q=
T%%D
@= fd 9 ff (=Q=%9 % 9" ,= = *


fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $

z



z
x

u

x



u


w

w

(a)

(b)

pyv7N/jMkY"gQB[o)BYvB#SDCgo4{ff?74stRTMJK!MFCh;*"(L/MBYj{JG
{ff?74sMFRTRyMFC2HKL/MlBYjf{ k pTG(jMJ#MJjGpytRTM






ffk



_B#SDC




BYjM


#lBB lZ,, V %] \"Vc /@TZJaZ %] VY^ cY^tXz]
]Qa\JV#aQ]\
Z\la/Z;ffcYycYb9] ^ cY^`Y]aQ]cY^/\fiff
] \VffVY]^ #d!Vft _] QZ W]Qa;fcY^ta=VY]^/\l^`cyHVYdffaQ]QV# XY]dZFaZJX7JTZ\M
Z/+aZZ\tJ=#X7d!FVfyZ}tc]^yZJY^uD7faZ #ffdXqZV#iZ a#ZJZffddX}affVY^V#] cY^dqnZ c F/@DHVYc#9^`a=cZff^ta 4 aHcwZffdZzVY]\.d!Z}ffHaQbcYdc[VY^ cY^D]_!QZcY)^DcY\J^xZF/Zi#aQ] Zff#dZX4^`cF^`[YZ] \
fcY^D^`ZFaZ ffXzVq ] ^De
/ZcY^ i#HdV7aQ]QcY^ k 7c%Z\l^c7acFfJHdV\VY^] ^#/Z}\ft#d!Vftc %
ff]yY#ZJHdfdXZ VY d! VY\ VY ^] k^#} /ZqcF\fDJH#dfd!Vf\qt]^c!V7w a)%yZ V\a.cY^Zcqa/ZWffc#dcY^ '#Hd!V#aQ]Qc#^/\#]\V#X7Z]^

u ,

x

z

x

z

x

z







(a)

(b)

(c)

x


z

(d)

ipTv7N/jMlLDMP ?7N/j@CDpMJjMFS[K{ff?7SDDv7N/jBYKpy?7StG({ff?7S[KB#pTStpTS/vB#S BYj{G kpTSB{ff?7stRyMJK!MFC h;*
MJK;NDGpTRTRTNtG!K!jBYK!M(KL/MWB#C/B#SuKBYv#MFG?#PG!MFBYj{fLDpTS/v"pTSKL/MWG!stB#{ffM@?#P2MFuNDpTB#RyMFSt{ffM*{JRTB#GG!MFG;?#P*)G
jBYKL/MJjKLDB#SzKL/M)G!stB#{ffMW?#P *G(A*pyKLzBGpT4stRyM*MffHB#4sRyM#pyv7N/jM)CtpTG!stRTB+EGKL/M)G!MJK;?#P s`?7GGpytRyM
*)G4pS[#?7RyHpTS/vOKL/jMJMzS/?CDMFG J K k Kn P7I;A*pyKLBYj{JG"`MJK|A;MJMFS B#SDC IB#SDCMJKAMJMFS kB#SDC
L/M4tjG!K)KL/jMJM}**)GBYjMMFuNtpyB#RTMFS[KJSK!MJjG?#P(pTStC/MJsMFSDC/MFSD{ffMpTS/P?#jBYKpy?7SI2KL/MJERTMFB#CK!?
KL/M*GB#4M*pTSDCDMJs`MFStC/MFSD{ffMG!KBYK!MF4MFSu"K !`lg k Kn ~ 2olg k4B#SDC BYjM*{ff?7SDCtpyKpy?7SDB#RTRTElpTSDC/MJsMFSDCDMFS[Kv7py#MF%S 2ofI
A*L/MJjMFB#G.KL/M}GKBYK!MF4MFS[#K !lg k Kn ~ $7oqlg kB#StC BYjM}BYjv7pTStB#RTRyEOpSDC/MJsMFSDC/MFSuKfo@{ff?#jjMFG!s?7SDCDG)K!?OKL/M
P?7N/jKLO?7S/M#@LDMlP?7N/jW**)GBFE`M"GND}BYjpyJMFC E?7SDRyEK|A;?CDpy`MJjMFSuK@{ff?7stRyMJK!MFCh*)GFI
GL/?%A*S pTSpyv7NDjM/

&%



fi X ttu




x

x

z

z

(a)

(b)

x


z



z
x

(c)

(d)

pyv7N/jMlD?7N/j@CDpy`MJjMFSuK*)G@A*pyKLKLDjMJM.S/?HC/MFGB#SDCK|A;?qBYj{JG
x



z



z
x

(a)

(b)

ipTv7N/jM/(A?}CDpy`MJjMFSuKMFuNtpyB#RTMFSD{ffM.{JRTB#GG!MFG*?#Pi**)G
WGiA;M{JB#SG!MJM#IYKL/MGMFBYj{LG!stB#{ffM(B+E.MjMFCtND{ffMFC.ElNDGpS/v*h**)GK!?@jMJsDjMFG!MFSuK'KLDM{JRTB#GG!MFGJ
pTSl?7N/j'Mff/B#4stRTM#IK!?WKA?){JRTB#GG!MFGpTSDGK!MFB#C.?#PDP?7N/j'{ff?7SDDv7N/jBYKpy?7StGJ7pyK'{JB#SM;G!MJMFSgQWSDC/MJjGG?7SlMJKB#RyI
kFm#m7#olKLDBYKlKLDMjBYKpy?O?#P(KL/M}SNDlMJj?#P**)G"K!?OKL/MqSuNDMJjl?#P({JRTB#GGMFGpTG#( 'k#kqP?#j"KL/jMJM
S/?HC/MFGJI[( 'kFn#zP ?#jWP ?7NDjWS/?HC/MFG@B#SDCO#m##nH)k 'n7Ym# P ?#jWD#MS/?CDMFGJpTSO4?#jMv#MFS/MJjB#R'K!MJjGJI`KL/M
jMFGNtRyKG9?#DKB#pTSDMFCEq)pTRTRTpG!stpyMB#SDC}hiMJjRB#SgY#/k+o;pTSDCDp{JBYK!MKLDBYKKLtpTGjBYKpT?lBYsDsDj?7B#{fL/MFGB.YB#RTN/M
?#P'RTMFGGKLDB#SP?7N/jB#GKL/M.SNDlMJj?#P'SD?C/MFG(pSD{ffjMFB#G!MFGJ*L/MNDG!M)?#P MFNDpyYB#RyMFSD{ffM{JRTB#GGMFGKL/MJjMJP?#jM
MFSuKB#pTRTG}{ff?7Su#MFSDpyMFSuKqGBFHpTS/v7G}pSMffsRy?#jBYKpy?7SrB#StCrMJYB#RTNDBYKpy?7SMff`?#jKJIB#RTKL/?7N/v7LKL/MOv7B#pTSrpTGqS/?#K
G!sMF{ffKB#{JNDRTBYj+
SxKL/M?#KL/MJj"LDB#SDC2I'KL/M}NDG!M}?#PB{JB#S/?7SDpT{JB#RjMJsDjMFG!MFSuKBYKpy?7SG{L/MFM}B#RTRy?%A*GlNDG.K!? MffsRy?#jM
KL/MG!stB#{ffMsDj?#v#jMFGGpy#MFRyErB#StCGEG!K!MF}BYKpT{JB#RTRyE#I@A*pyKL/?7N/KzRy?7GpTSDvB#SuENDS/MffHstRy?#jMFC{ff?7S/Dv7NDjBYKpy?7S
NDSDSDMF{ffMFGGBYjpTRTE#"*MJKN/jSDpTSDvqK!? ?7NDj.MffHB#stRyM#I RyMJK.NtGGN/sDs?7G!M"KLDBYK.KL/M4K!jfN/M4?HC/MFR9pTG)KL/M*
CDpTGstRTBFE#MFCpTSpyv7N/jM/B#StCOAMG!KBYjKKLDMGMFBYj{LA@pyKLB#SMF4sDKEv#jBYstLgA*pTKLS/?BYj{JGfof MJK
NDG(B#RTG?B#GGND4M)KLDBYK*KL/M.G!MFBYj{fL B#Ryv#?#jpyKLt pTC/MFSuKpyDMFGKLDBYKB#SMFC/v#MMJK|A;MJMF
OB#SDBC kqsDj?HCDND{ffMFG
KL/M4v#jMFBYK!MFGKlpT4sDj?+#MF4MFSuK.pTSKL/M4G{ff?#jM#KKLtpTG4?74MFSuKJIKL/M4K|A;?B#RTK!MJjSDBYKpy#MFGJI kB#SDC

kgQ{JB#G!Mk}B#SDC{JB#G!MzpTSpyv7N/jMqIjMFG!sMF{ffKpy#MFRyEDofIiBYjM}MFNDpyYB#RyMFS[KJ MJKNDGS/?+AGN/sDs?7G!M
KLDBYK@A;MlCDMF{JpTC/M.K!?}{ff?7StS/MF{ffK*KL/MS/?CDMFZG B#SDC `BYv7B#pTS AMlLDB+#MK|A;?q?#sDKpy?7SDGJ{ ?#wj 1
>@MJ#MJjKL/MFRyMFGGFIYCDMJs`MFStCDpTS/v?7S.KL/MsDjMJHpy?7NDGG!MFRTMF{ffK!MFCl{ff?7S/Dv7NDjBYKpy?7S2IA;M?#DKB#pTS.CDpy`MJjMFSuK?7N/K{ff?7MFG
KLDBYK*BYjMlS/?Ry?7S/v#MJj*MFuNDpTB#RyMFSuKlgQG!MJMlpyv7NDjMl7of
P)A;MLtB#C{LD?7G!MFS{JB#G!MkgKLNDG?#tKB#pTSDpTS/vMFpyKLDMJjq{JB#G!MkYTk ?#jq{JB#GMkY7ofI(AMA?7NDRTCrLDB+#M
MFRTpT}pTSDBYK!MFCKL/M}s`?7GGpytpTRpyKE ?#P(MffHstRy?#jfpTS/vKL/M}** kIB#SDCKL/MJjMJP?#jM}KL/MqMffsRy?#jpTS/v
sDj?H{ffMFGGlA;?7NDRCLDB+#MqMJMFSxK!jfpT4MFC2WGlKLDM}K!jN/Mz4?HC/MFRpTGlsDjMF{JpTGMFRyEOKLtpTGl*gQ{JB#GMTkzpTS
pyv7N/jM}7ofIiKL/MFSKLDM}G!MFBYj{fLxsDj?H{ffMFGGlA;?7NDRCLDBF#MqK!?pTSD{JRTNtC/M4B#S/?#KL/MJjlBYj{q{ff?7SDS/MF{ffKpTSD1
v kB#StC
*F =(Yn " .1,ff [=#% 9J; +@ Mcv = ff # J* 9=%) = = ,f" % % =f- +M

/



fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



gQ{JB#G!MFGkYTkYTkYI;kYTk?#jkY7ofI'MF{JB#NDG!uM kB#SDC BYjM{ff?7SDCDpyKpy?7StB#RTRyEC/MJsMFSDC/MFSuK@v7pT#MFS'.K)KLDpTG
4?74MFSuKJI(B#S[ErRT?{JB#RGMFBYj{LsDj?H{ffMFGGA?7NDRTCrGK!?#s gQpTSBRy?{JB#R?#sDKpT"NDqofI`MF{JB#NtG!M MJ#MJjErRy?H{JB#R
{LtB#S/v#MzgQBYj{.jMJ#MJjGB#R2?#j@BYj{jMF4?%B#RoA;?7NtRTCBYw#MlKLDM.G{ff?#jM.A?#jG!M#
Case 1

z

x



Case 2

z

x



1.1

z

x



2.1

z

x



z

x



z

x



2.2

z

x



1.2.1

z

x



1.2.2

z

x



1.1.1
1.2

pyv7N/jMl;?H{JB#RG!MFBYj{fLpTSKLDM.G!stB#{ffM.?#P9*)GWpTGK!jBYsts`MFCBYK@BRy?H{JB#R2?#sDKpT"ND
?7StG!MFuNDMFS[KRyE#I?7N/jstN/js?7G!M@{ff?7SDGpTG!KGpTSqB#CDCDpTS/vl?#jjMF4?+HpTS/vMFC/v#MFGgMFpyKL/MJjRTpTS/wHG?#jBYj{JGfoK!?
KL/MWG!K!jND{ffKN/jM*A*pyKLD?7N/K9sDjNDStpTS/vKL/MWG!MFBYj{LzG!stB#{ffM)NDSDSDMF{ffMFGGBYjpTRTE#'M){ff?7NDRTC}KL/MJjMJP?#jM@pTSuK!j?HCDND{ffM
RTpTSDwGpSDG!K!MFB#Cq?#P BYj{JGgA*L/MFSqKL/MJjM)pTGS/?#K;MFSD?7N/v7LqpS/P ?#jfBYKpy?7SK!?CDpTGKpTS/v7NDpTGL`MJK|A;MJMFSCDpy`MJjMFSuK
stBYK!K!MJjStG ?#PtBYjf{JGfofI#A*LDpT{fL.A?7NDRTCG!MJj#MB#G'K!MFstRTBYK!MFG'?#jCDESDB#}pT{RTpTSDw#MJjGK!?WMFuNtpyB#RTMFSD{ffMstBYK!K!MJjfSDGJ
L/MJE"jMJsDjMFG!MFS[K;B#S[EYB#RTpTC4{ff?7tpTSDBYKpy?7S?#PBYjf{JGA*LDp{L4jMFGNDRyKG9pTS4B*_MFRy?7SDv7pTS/v)K!?lKL/M@GB#4M
MFNDpyYB#RyMFSD{ffM.{JRTB#GGF
?u?#wHpTS/vBYv7B#pTSOBYK*KL/MlsDjMJHpy?7NDG(Mff/B#4stRyM#ItA;M.A?7NDRTC sDj?H{ffMJMFC B#GP?7RTRy?%A*GJB#GGNDpTS/v4KLtBYK*pTS
?7N/jG!MFBYjf{LG!sB#{ffM(KL/M(?#sMJjBYK!?#jG9?#PRTpTS/w.B#CtCDpyKpy?7SB#SDC4{ffjMFBYKpT?7S4?#P`L/LstBYK!K!MJjSDG9BYjMB+B#pRTBYtRyM#I#AM
A?7NDRTCDjfG!K*pTSD{JRNDC/M)KL/MRpTS/cw k`G!MF{ff?7SDCtRyE#ItA*LDMFS{ff?7SDGpC/MJjpTS/vKL/M"pTSD{JRTNtGpy?7Sz?#PB}{ff?7SDSDMF{ffKpy?7S
MJKAMJMF%S qB#StC I7AM(A;?7NDRC4LDBF#MK|A;?l?#sDKpy?7SDGJI7GL/?+A*S4pS"pyv7NDjM/iKLDML/LstBYK!K!MJjS Bk
B#SDCKL/M.stBYK!K!MJjS kSKLDpTG@{JB#G!MlKL/MG{ff?#jpTS/v}PNDSt{ffKpy?7SA?7NDRTCB#GGpTv7S KL/M.v#jMFBYK!MFG!KWG{ff?#jM
K!?KL/MLHLstBYK!K!MJjS kI/KLNDG(?#tKB#pTSDpTS/vKL/M{ff?#jjMF{ffK**
[< T>t8 43H!<< 65S]7<=<<73 4 <`>T>t8 6 98:,
L/MG{fL/MF4Mz?#P*jMJsDjMFG!MFS[KBYKpT?7SKLtBYK"AMzA*pTRTR;NDG!MqpG"GRTpyv7LuKRyECDpMJjMFS[K"Pj?7 KLDMzP?#jB#RpTG ?#P
{ff?74stRTMJK!MFCh;*)GJO|KpTGlSD?#KS/MF{ffMFGGBYjEP ?#j"MFB#{L{ff?7S/tv7N/jBYKpy?7S?#P(?7N/jG!MFBYj{LG!stB#{ffMgA*LDp{L
{JB#RTR)d!Zff\aQd]Q+aZ
{w%?#<j ;Z{w%oK!?{ff?#jjMFG!s?7SDCK!?xBCDpMJjMFSuKMFuNDpTB#RyMFSt{ffM{JRB#GGJKA?
CDpMJjMFSuK@h*GBFEq{ff?#jjMFG!s?7SDCzK!?KL/M)GB#4M)MFuNtpyB#RTMFSD{ffMW{JRB#GGJ9L/M)B#pTSqjMFB#G!?7SP?#jKLDpTG
pTG"MJ~}{JpyMFSt{ffEEB#RTRy?%A*pTS/vB#SMFNDpyYB#RyMFSD{ffM{JRTB#GGK!?MjMJsDjMFGMFS[K!MFCg?7SDRTEpTSG!?74M{JB#G!MFGo"uE
CDpMJjMFSuK@h*GJIDAMA*pTRTRtv7B#pTSpTSqMJ~}{JpyMFSD{ffEqK!?4MffstRT?#jM@KLDM)GstB#{ffM#MJP ?#jMMffstRB#pTSDpTS/vlKLDpTGpTS
v#jMFBYK!MJj)C/MJKB#pTRI/RyMJK@NDG(C/MJtS/MKLDMl{ff?7SD{ffMJsDK?#P*h;*"
=cY^D? X}>@l] .A]Qa9B\JV#aQ]
\ Z\"aHZ;&ffc# ycYb9 ]^u= <c#C^Y ]QaQ]QcY^DF\ ff %V ]\ Vd!Zff\aQd]Q+aZE {w%D
;Z %E] VY^`
HG k } S2 mGo lg kDJo HKI $ML py lg k/do HK$!
7c%Z\l^c7afcY^ta=VY]^VY^DXY]d!ZFaZFX7JTZ

0121

>

N



fi X ttu

7c+Z\)^c#afcY^ta=VY]^V#^DXc @TZJaZJX4H^Y]dZFaZ}FX#FyZFi] QZ WVJX7JTZfcY^ta=VY]^D]^uqc#^DX ] ^De+\
ZP#] \a\.]^ aHZJ^Zff]QaHZffd g RQOcYd g oJSI $
u]\"fcY^Y]QaQ]cY^\a=V7aZ\"aHV#a(VY^VYd!
Z#P ] \a\l]^ cY^D Xq] .]Qa]\"ZJ]aHZJd(HV#dacVY^[|
/V#aaZffd^cYdla/ZffdZ"]\lVY^`c#aHZffd4VYd!<| cYd]y#]^V#aZOffXqVY^[|"HV#aaZJdf^&4 [cY]^uza=c


/







k





u~ mxo lk M~




k

mGo? l

H



!



u.

WG4B#S*h;* pTGBh**"IpyK4{ff?7NDRTCMz{ff?7StGpTC/MJjMFCK!?MBOjMJsDjMFG!MFSuKBYKpy?7S?#P@BG!MJK4?#P
g MFNDpyYB#RyMFS[Kfo*)GJM}KLDMJjMJP ?#jM}NtG!KlC/MJtSDM4A*LDpT{fLKL/M}G!MJK?#P**)GpGjMJsDjMFGMFS[K!MFCuEB
v7py#MFS@h*z"IDpM#L/?%ACDpyjMF{ffKpy?7SB+E}M)v7py#MFSK!?4KL/MRTpTSDwGpTS pTSz?#jC/MJj(K!?MffHK!MFSDC pyKK!?
B*L/MP?7RTRy?%A*pTS/v4C/MJSDpyKpy?7SzP?#jB#RTpyJMFGKLDpTG(pTC/MFBH
=[Z P[?aZff>@^/l\A]Qc#^BTc!* VUX] lWVY^`RNcY^D X} ] FBff Y) = C l] YZff^V { 5Z(b;Z\ffVYXaV#a@cV %U ]\"V#^
VY^` U V YZ"a/Zl\ffV /}Z\fe#ZffTZJa=c#^
k] \VY^xVYd!] ^ aHZffB^ k] \VY\JcVY^VYd!"] 1^ U\=^`czV#d] \d!ZY]d!ZFaZF
c#d[VYZJ^d" a=c.U d!cFV Y#DZzZ aHUZ\ff7V c+/}Zff\lZ^[c#|a}u/ZJV#^`aZffaZffd!dV#^/aZ\ ^`_]ZJQbZ ua/"Z)H`V#adacFZJdfZ^D\f]\\zc}Y]d!ZFaQ]^uaHZ} ] ^/e%\"]^ ]^
MA*pRTRtNDGXM ^x | ;g .o;K!?C/MFS/?#K!M)KL/MG!MJK?#P'**)GKLDBYK(BYjM)MffHK!MFSDGpy?7StG;?#PiB"v7py#MFSh*
"
GHABK_ ZJd
Z"VY`
^ ;Z %ff HZJB^ ff
V 6^xb;ZJ | !;g [.dZ ao HS^I Z$bTlVY^Z"[Z P7aZJ^[Z}a=cqc[Ja=VY]^V 5'] Z @a/ZZ P7aZff^D\f]cY^c.VYc^ ;Z{w%] \
e G JXU Z K P7U aZff ^`} Y] ^G^z | ];ga.VYod!Z}U nZ JH8l] UVYTZff ^=ga ] Z qVYaHZ}#] fWZJd!ZJ^ta w%;\aV#aWVY^Z}c[Ja=VY]^`Z.dTc /

hYi

GL

Qg B[o"WG LDB#G4S/?CDpTjMF{ffK!MFC{ffE{JRTMgQ{ff?7SDCDpyKpy?7SpTSWMJtSDpTKpy?7Sk+ofIKL/MFSMFpyKLDMJj pTG4B#RyjMFB#CDEB
*?#jpyKLtB#GlG!?74MRTpTSDwGJ MJKNDG"{ff?7SDGpTCDMJjB#SBYjtpyK!jBYjERTpS/wk`0@GpTS/v{ff?7SDCtpyKpy?7SkqpTS
WMJtSDpyKpT?7SkYIDS/MFpyKL/MJjffS/?#jZk{JB#S LDBF#MBstBYjMFSuKJMl{JB#S KLDMFS CDpyjMF{ffKKL/M.RpTS/w5kzpSqMFpTKL/MJj
CDpyjMF{ffKpy?7SA*pTKL/?7N/K{ffjMFBYKpS/v"B#SLHL}stBYK!K!MJjS29P2AMWCDpTjMF{ffKKL/MWRTpTS/w k}B#{G kB#SDcC k}pTGstBYjK
?#P9B#S/?#KL/MJj*RpTS/cw k` IDKLDMFSA;MCDpyjMF{ffKpyKB# G k gQpTS?#jCDMJjK!?}BF#?7pCBS/MJALHLstBYK!K!MJjSof;M
{JB#S{ff?7S[KpSuN/MCDpyjMF{ffKpTS/v KL/MRTpTSDwG.pSB{LDB#pTSpTSKLDpTGAB+E#IB#SDCKLDpTG.stj?{ffMFGG{JB#SDSD?#Kv#MFS/MJjfBYK!M
BxCDpTjMF{ffK!MFCr{ffEH{JRyM MF{JB#NDG!M#IB#{J{ff?#jCDpTSDvK!?{ff?7SDCDpTKpy?7SrpTSWMJtSDpTKpy?7S_kY LDB#GSD?x{ff?74stRyMJK!MFRyE
NDSDCtpyjMF{ffK!MFC{ffEH{JRyM#
g`o}L/MMffK!MFStGpy?7SsDj?H{ffMFGGq?#P C/?MFGzSD?#K?CDpTP EKL/MG!w#MFRyMJK!?7S_B#SDCC/?MFGzS/?#K{ffjMFBYK!MS/MJA
LHLsBYK!K!MJjSDGJL/MJjMJP?#jM#IB#RTRKL/MqMffK!MFSDGpy?7SDG?# P LDBF#MqKL/M}GB#4MzG!w#MFRyMJK!?7SB#SDCKL/MqGB#4M}u
G!K!jNt{ffKN/jMFGgQBuG!K!jNt{ffKN/jM pTG4BsBYjKpT{JNDRTBYj4{JB#G!M?#P)L/LstBYK!K!MJjSofI(L/MFSD{ffMKLDMJEBYjMMFuNDpTB#RyMFSuKJ
KGL/?7NDRCqMS/?#K!MFCKLtBYK*{ff?7SDCDpyKpT?7SqpS@MJSDpyKpy?7Sk.pTGS/?#K@S/MF{ffMFGGBYjEzK!?4sDj?%#M.KL/MjMFGNDRyKG
Tp Srhj?#s?7GpyKpy?7S,kYLDpTG{ff?7StCDpyKpy?7SrpGpTSD{JRTNtC/MFCK!?MFStGN/jMKLDBYKzKL/MOKEs`M?#P.h* NDG!MFCK!?
jMJsDjMFG!MFS[KGN/tG!MJKG(?#PMFNDpyYB#RyMFSuK*)GWpTG(B#Gv#MFS/MJjfB#RB#Gs?7GGpTtRyM#iS?#KLDMJjA;?#jfCDGJIt{ff?7SDCtpyKpy?7S


fi

f #%$ff&(' *)

$ ,.$ !

"$ !$ $



v7NDBYjB#SuK!MJMFGKLDBYKB#S*h** pTGBjMJsDjMFGMFS[KBYKpy?7Sz?#PKLDM@v#jMFBYK!MFGKSNDMJj?#PMFNDpyYB#RyMFSuK;*)GFI
GN//MF{ffKK!?qKL/MljMFG!K!jpT{ffKpy?7StGpT4s?7G!MFCE{ff?7SDCDpyKpy?7StG.k|}pS WMJtSDpyKpy?7SkY(WG*AM.A*pRTR2G!MJMpSKL/M
S/MffHKsDj?#s`?7GpyKpy?7S2I7KLtpTGpTGB#{LtpyMJ#MFCzuECDpTjMF{ffKpTS/v.KLDM@pTStpTNtSuNDMJj?#PMFCDv#MFGJ/?#jMffHB#stRyM#I

k A;?7NDRCS/?#K*M.BYB#RTpTC@h*`LDMl*h;*KLtBYK*AMlA?7NDRTCNDG!MpTSKLDpTG*{JB#G!M

pTG ! k`
GHABKj_ ZJZ
fZ
V { 5 YZJdf] X]^uaHZ cY^#]aQ]cY^/\ ]^ dZ ^D]QaQ]cY^ HZffdZz] \
aHZJ^V}\] ^u7yaZ ; { 5lk \/J aV#@a ^G | ;g .no ml^G | dg klio

h



L/M"sDj??#PpTG){ff?7SDGK!jND{ffKpy#M#MGLDB#RTR'tNDpTRC KL/M4*h;*okB#G)P?7RTRy?+A@GJ*KL/M4G!w#MFRTMJK!?7SB#SDCKL/M
LHLstBYK!K!MJjSDG*?#P(
k
BYjMlKLDMlGB#4M"B#G*KL/?7GMpTS WSBYjf{
pTS GLtB#RTRS/?%A,Ml{ff?7SDGpC/MJjMFC
GND{fL}KLtBYK
g Kl$ B#StC
g /o
gQpyPGND{fLqB#SBYj{WC/?MFG;SD?#K;Mff/pTG!KJIKL/MFS pyKG!MFRyPA?7NDRTC
MB#S*h;*.ofA;M@{ff?7S[#MJjK;KL/M*BYj{
4pTSuK!?KL/M*RTpS/w 9LDpGsDj?H{ffMFGGpTGKL/MFS}jMJsMFBYK!MFC2
pT?7NDGRyE#I`KL/M4h*p
k
?#tKB#pTS/MFCpTSOKLDpTGWABFELDB#GS/?CDpyjMF{ffK!MFC{ffEH{JRyM4B#SDC#MJjpyDMFG){ff?7SDCtpyKpy?7S
pTSWMJtStpyKpy?7SkYl ?#jMJ?%#MJjFIAM"{JB#StS/?#K)?#DKB#pTSBq{ff?7SDDv7N/jBYKpy?7S
kstBYjMFMFSu{JKfB#ofND9G!M SqB#CDCtpyg K2py?7o S2qIk $ {JgB#A;SDM4S/?#?7KStRyLDE BF#jMFM4B#?%Su#EM{ffK?7L/4MstCDRyMJpTjK!MFMF{ffRTEKpy?7NDSSDCD?#pyP;jMFBY{ffjK!{JMFG)C}A@{ffEHL/{J?7RyG!M@MpTMFSD{JpTKB#pTNDB#B#GRGM*S/BzMF?HpyGC/KN/L/MFDMJGjv#LDjfKB+BYL/#stM)MLBYS/j?#?{ P

pGS/?#K*sBYjK*?#PB#SuE {ffE{JRTMpTS ?#j@pTK@pTG(sBYjK*?#P9B}{ffEH{JRyM"pTS KLDBYK@"NDG!K@{ff?7S[KB#pTSBYK)RyMFB#G!K
?7S/MLHLstBYK!K!MJjfSxgQB#SDCKL/MCDpyjMF{ffKpT?7SDG?#P KL/MBYj{JG(pTSzKLDpG;sBYK!K!MJjSA*pTRTR`S/MJ#MJj(M)jMF4?%#MFCofrk pTG
KL/MJjMJP?#jMlB#S*h**"
MJK*NDG(S/?%AsDj?%#M.KLDBYKn^ g losmt^ gdlk ofpyP
^ g .oKL/MFS B#SDC LtBF#M.KL/MGB#4M
G!w#MFRyMJK!?7SB#SDCxLHLstBYK!K!MJjfSDGJI L/MFSt{ffM B#SDCu
k
B#RTG? LDBF#MKLDMGB#4MG!w#MFRyMJK!?7SB#SDCxLHLstBYK!K!MJjfSDGJ
?#jMJ?+#MJjFI'B#GWB#RRKL/MBYj{JG)pTSHkBYjMB#RTG!?BYj{JG)pTS "I2pyP
kKL/MFS ^ g lof I`A@LDpT{LOpTS
KN/jSp4stRTpyMFGKLDBYK
L/MJjMJP?#jM#IDB#{J{ff?#jCtpTS/v4K!?qWMJtStpyKpy?7S
pTSDB#RRyE#IRyMJKWNDGstj?+#M"KL/MNDSDpTN/MFS/MFGG?#P(k AMB#RyjMFB#C/EwHS/?+A KLDBYK)B#S[E?#KL/MJjW@h*-k
#MJjpyPEHpTS/v4KLDBYKX^ g .ovmw^ gdk o(LDB#GKL/M"GB#4MlGw#MFRyMJK!?7SOB#StCLHLsBYK!K!MJjSDGWB#Gvk@{J{ff?#jCtpTS/v
GL

mxo l {H



mGo? lk {H

Z

G



k



J DP





k

G!k







!

mGo? l wH





k



G | ;

k



x |

U

}

x | ;

U



5U

E





k

}

U

R



k

}





,U

}

k }
G | ;



G | ;

x |



K!?q{ff?7StCDpyKpy?7Sk.pS WMJtSDpyKpy?7SkYIKL/M.MFC/v#MFG*KLDBYK*BYjM"S/?#KstBYjK(?#PB#SuE?#PKL/MFG!MlL/LstBYK!K!MJjSDG*tN/K
BYjM}pSD{JpTC/MFSuKK!?KL/MqpTCDCDRTMSD?C/%M kpTSB#SuExLHLsBYK!K!MJj
kE NDGK.M}CDpyjMF{ffK!MFCBFABFE
Pj?7 kgQpS?#jC/MJj(K!?}B+#?7pTC S/MJALHL stBYK!K!MJjSDGfof*L/MjMFB#pTStpTS/v"MFC/v#MFG(KLDBYK*BYjM.S/?#K(stBYjK(?#PB#S[E
LHLstBYK!K!MJjSNDGKlM}NDSDCtpyjMF{ffK!MFC2IpTS?#jCDMJjK!?GBYKpTG!PEx{ff?7SDCDpyKpT?7SpSxWMJtSDpyKpy?7SkY L/MJjMzpTG
KL/MJjMJP?#jM?7SDRyE?7S/M4*h**KLDBYKBYK{LDMFG.Bzv7py#MFSG!w#MFRyMJK!?7SB#SDCBG!MJK)?#P;L/LOsBYK!K!MJjSDGJI2G!c
? k
pTGKLDM?7SDRyE*h;* #MJjfpyP EHpTS/vKLDBY#K ^G | ;g .#o mx^x | dg klofzpyv7NDjM}GL/?%A*GlB#SxMffHB#4sRyM?#PKL/M
{ff?7SDG!K!jfND{ffKpy?7SsDj?{ffMFGGF
LDMP ?7RTRT?+A*pTSDvstj?#s?7GpyKpy?7SMFSDGNDjMFG4KLDBYKKLDM {ff?7SD{ffMJsDK}?#P)*h;* B#RTRy?+A@GNDG4K!?CDMJtS/M B
stBYjKpTKpy?7SpTSKL/MlGstB#{ffM.?#P*)GJ
GHABTyz_ ZJd
VY^% ZaQbcY] fWZffdZff^t{a ;Z %;M\ /Zffc
^ ^G | ;g .)o |<^G | ;g ]o HS$!

hYi

MJK `MB#SuE*"HL/MFScUpTKG!MFRyPpTGBlh;*B#SDC4?#pT?7NDGRyEUHK^G | g_Uof;EBYststRyEHpTS/v)KL/M
jMFGNtRyKpTShj?#s`?7GpyKpy?7SIYA;M{JB#SB#GG!MJjK KLDBYKKL/MJjM;pTG2BGpTSDv7RyM*h;*rGND{fLKLDBYKOU}mt^G | g;lof
GL
(U

SKL/Mstj?#s?7GpyKpy?7SMFRy?+AlI AM}GL/?%AKL/MsDj?#s`MJjKpyMFG)A*LDpT{fLxBYjM}{ff?7}4?7SK!?OB#RRKL/M}*)G
MFRy?7S/v7pTSDv"K!?}KL/M.GB#4M.MffHK!MFSDGpT?7S?#P9B#S *h;*"


fi X ttu

b


b
c



b
c



b
c



c

x



x



x



x



e



e



e



e



(a)

(b)

(c)

(d)

pyv7N/jMl*RTRNDG!K!jBYKpTSDv*KL/M{ff?7SDGK!jND{ffKpy?7S4stj?{ffMFGG9pTS4hj?#s?7GpTKpy?7S"gQB[oih;*`g`oiNDStCDpyjMF{ffK
pTS/v4KL/M"BYj{ k`'gQ{+oNDSDCDpyjMF{ffKpTS/vKL/MlBYjx{ k gQCoNDStCDpyjMF{ffKpTSDv"KLDMlBYjG{ 7I
KLuNDG?#DKB#pTSDpTSDv"KLDMl*h;*~
k

B bxc %;\ZffycY^u}a=c4aHZ"[Z P[aZff^/\]QcY^cWa/ZW\ffVT/Z;Z{w%] )VY^qcY^D X"] @a/ZffX
V#Z"aHZl\ffVT/Zl\fe#ZJyZFa=cY^VY^zaHZl\JV/}Zl["HV7aaZffd^/\i

GH

h



L/MS/MF{ffMFGGBYjE{ff?7SDCDpTKpy?7SpGl?#pT?7NDGJMJK4NDGsDj?+#MKL/MGN/~q{JpyMFS[K{ff?7SDCDpTKpy?7S24RyMJK
GL

U
B#SD
C U
MK|A;? **)G.A*pTKLO{ff?7?7SG!w#MFRyMJK!?7SxB#SDCLHLstBYK!K!MJjfSDGJ.MGLtB#RTR'{ff?7StG!K!jND{ffKBh* B#G
P?7RTRy?+A@GJKLDMzG!w#MFRTMJK!?7SB#SDCKL/MzLHLxstBYK!K!MJjfSDG"?#wP BYjMzKL/MzGB#4MB#GlKL/?7GMzpTS UB#SDC U KL/M
MFC/v#MFGWKLDBYK)LDBF#M"KL/MGB#4M"?#jpyMFSuKBYKpy?7SpT
UB#SDy
C U BYjMCtpyjMF{ffK!MFCpTy
pTSKL/MGB#MABFE`2KL/M
?#KL/MJj@MFC/v#MFG*pT
jMFB#pTS NtSDCDpyjMF{ffK!MFCDj?7WMJtSDpTKpy?7S ItpyKpTG({JRTMFBYjKLDBY K U K U } ^x | ;g .of
LDB#GS/?4CDpTjMF{ffK!MFCq{ffEH{JRyMFGMF{JB#NDG!
U B#StC UtBYjM*GJ LDB#GS/?{ff?74stRTMJK!MFRyEqNDStCDpyjMF{ffK!MFC
{ffEH{JRyMFGJI.GpTSt{ffMB#RRKL/Mx{ffEH{JRyMFGpT
U B#SDC U GLDBYjMxBYKRTMFB#G!K KL/ML/LstBYK!K!MJjSDGJS_B#CDCtpyKpy?7S2I

k {JB#SDS/?#KMB*GN/Dv#jBYsL)?#
P MF{JB#NDG!MKLDpG2A;?7NtRTCpT4stRTE*KL/MMff/pTG!K!MFSt{ffM?#PHKL/MGN/tv#jBYstLDG
B#SDC
pc

k%
k
U B#SDC U IjMFG!sMF{ffKpy#MFRyE#I/B#SDCqKL/MJjMJP?#jMWKL/MFG!MWKA?4*)GA?7NDRTC
S/?#K*LtBF#M.KL/MGB#4MlLHLsBYK!K!MJjSDGJ
LDMJjMJP ?#jM#IKL/Mh* GBYKpTG!tMFG"{ff?7StCDpyKpy?7SDGzk|pTSWMJtSDpyKpT?7SkY;EBYsDstRyEHpTS/vOhj?#s?Y
GpyKpT?7S I4AMr{JB#SKL/MFS NDpTRTCB_GpTS/v7RyM*h;*
k GNt{LKLDBYu
K ^x | ;g .
m^x | dg klofIL/MFSD{ffM
K
}
|
U
U
^x dg klof
{LtBYjB#{ffK!MJjpyFBYKpy?7S?#PKL/MMffK!MFStGpy?7S?#P9B#S @h*KLDBYKA*pRTR``M.NtG!MJPNtR`RBYK!MJj@pTGJ
GHABK ] #Zff^V#6
^ ;Z % V#^OV %UMaHZffy
^ U ]\VY^Z P7aZJ^/\f]cY^c!G ] VY^`
cY^D X}] laHZ;JcYc#b9] ^ufcY^Y]QaQ]cY^/\lHcYff
VY^` U V YZ"a/Zl\ffV /}Z\fe#ZffTZJa=c#^
bG k } S2] mGo? lg kDXo HKI $a/Zff^ mGo X lg kDdo H mGo? lg k/io
6G k } S2] mGo? lg kDdo HK$OV#^ mGo X lg kDJo HKI $OaHZff^ ~ mGo X lg kDMo ~`H k



hYi

GL


ZZ\\JVYdXzc#^Y]QaQ]QcY^t


fi

f #%$ff&(' *)

$ ,.$ !

"$ !$ $



g /oq
$W MJK } mGo? glkDofI pM#yI= k } "LDMFS2IP j?7 {ff?7SDCtpyKpy?7SzpTS@MJSDpyKpy?7SI
ItpM#yI } mGo X glkDof?#jMJ?%#MJjFI } mGo? glk/o( kc pGB#SLHL stBYK!K!MJjSpS"
/j?7{ff?7SDCDpTKpy?7S pTS@MJSDpyKpy?7S IKLDpTG(?H{J{JN/jG@pyPiB#StC ?7SDRyEpyP. kc pTGB#SOLHLstBYK!K!MJjSOpTS
UIDA*LDpT{fLpTGMFNDpyYB#RyMFS[K(K!? } mGo X lg kDofLDMJjMJP ?#jM#I mGo X lg k/{
H mGo? glkDof
mxo lg kDG
G


G


KL/MFS k5Ho $ B#StpTG*C B#SLHX Llg kDso BYHoI K!K!MJ$j4SpTS MJK U B#} StCKL/X MJlgjkDMJPof?#jMl|PpyK@KL/pTGMJjB#MqRTG!pT?qG.B#B#SSD?#LHKL/LMJj"sBYSDK!?K!C/MJMjS pTS} mGIto A*X LDglpkD{ofL
{ff?7SuK!jB#CDpT{ffKGKL/M)PQB#{ffKKLDBYK mGo lg kDdo HK$H?/I kq{JB#SDS/?#K(LDBF#M.?#jM)KLDB#Sz?7S/M)stBYjMFSuKpS UI/L/MFSD{ffM
~ mGo X lg kDM
~H kY
F]ZJ^ta;fcY^Y]QaQ]Qc#^D
F
|ffP k } Uk } KL/MFS mxo lg kDo HI $/j?7 {ff?7SDCtpyKpy?7SAMzLDB+#M mxo X lg k/o H mxo lg kDofIL/MFSD{ffM
KL/|MJOP jMJ P?# jGM k5 k5pTG B#S LHpTG(LzB#SOstBYLHK!K!LMJjstSBYK!pTS K!MJ"jSOIHpT?71S SD{ffUM. BYv7B#pSqPj?7{ff?7SDCDpTKpy?7SI mxo X lg k/do H mGo lg kDoB#SDC
{ff?7|SDffP CDpTKpy?7SxkI' ?#DpTG"KB#B#pSS LHmGo?Lx slg BYkDK!o K!MJHI jS$pTSB#SDUCIIP KjL/?7MFS {ff~ ?7mGSDo CDX pyKlg pTkD?7MoS~nH mGkqo?B# StlgC kD*o mGH X mxlg k/o `o X HIlg k/of$zxL/?/MJIjMJPjP?#?7j
pTGB#S L/LstBYK!K!MJjSp

k%
"





mGo? lk
H

k } U

x &
L



= <C B


?

NYqc



= C




MJK(NDGS/?%A_MffHB#}pTS/MWKL/MB#pTSCDpMJjMFSD{ffMFGMJKAMJMFSKL/MCDpMJjMFSuK;jMJstjMFG!MFSuKBYKpy?7SDGJB"jMJsDjMFG!MFSH
KBYKpy?7SB#G!MFC?7Sh*G.MFSDGNDjMFG)KLDBYKMJ#MJjEMFuNtpyB#RTMFSD{ffM4{JRTB#GGLDB#GBNDStpTuNDMjMJstjMFG!MFSuKBYKpy?7S2I
tN/K(KLDMJjM.BYjMlh;*)G@KLDBYK@C/?SD?#K*{ff?#jjMFG!s?7SDCK!?qB#S[EMFNDpyYB#RyMFSD{ffM.{JRTB#GGgQpTS?#KL/MJjA?#jCDGFIDKL/M
BYsDspTS/vP j?7 MFNDpyYB#RyMFSD{ffM{JRTB#GGMFG.K!?h;*)GpTGpTS!MF{ffKpy#M%of SKL/M?#KLDMJj"LDB#StC2I?7N/j.jMJsDjMff
G!MFSuKBYKpy?7StB#GMFC?7S *h;*)Gv7NtBYjB#S[K!MJMFG*KLDBYK(MJ#MJjE*h;*{ff?#jjMFG!s?7SDCDGK!?B#SMFNDpyYB#RyMFSD{ffM
{JRTB#GGgsDj?#s`?7GpyKpy?7Sk+otN/KC/?MFGSD?#K;MFSDGN/jM*KLtBYK;MJ#MJjEqMFuNtpyB#RTMFSD{ffM@{JRTB#GGLtB#GB"GpTSDv7RyMjMJsDjMFG!MFSH
KBYKpy?7SgKL/M}BYsDstpTS/vPj?7MFNDpyYB#RyMFSD{ffM{JRTB#GG!MFG*K!?z@h*)GWpTG*?7S[K!?uof@?+AMJ#MJjFIKL/M}BYsDstpTS/v
Pj?7 MFuNtpyB#RTMFSD{ffM4{JRTB#GG!MFGK!?h*GlpTGWtp !MF{ffKpy#M#4pyv7N/jMFGluBHI9uB#SDCu{GL/?+AKLDM4KL/jMJM
*h;*)G{ff?#jjMFG!s?7SDCDpTS/v4K!?zKL/MGB#4MMFuNDpTB#RyMFSt{ffM{JRTB#GGFKL/MB#GG!?H{JpTBYK!MFC{ff?74stRTMJK!MFCOh;*pTG
GL/?%A*S pTSpyv7NDjMuC2SKLDpTGMff/B#4stRyM#ItKL/M.SuNtlMJj(?#P9*)GWpTSKL/M.MFNDpyYB#RyMFSD{ffM{JRTB#GG*pTGkF

(a)

(b)

(c)

(d)

pyv7N/jMu"gQB[ofI g`oB#StCgQ{+o;LDjMJMW@h*G({ff?#jjMFG!s?7SDCDpS/v.K!?KL/MGB#4MWMFuNtpyB#RTMFSD{ffMW{JRB#GGJgQCo
KL/MlB#GG!?H{JpTBYK!MFC {ff?7stRyMJK!MFCh;*
WG AM;{JB#S"G!MJM#IYKL/MCDpMJjMFSD{ffMBYsDsMFBYjG A*L/MFSlKL/MJjM;BYjMK!jpTB#SDv7NDRTBYj G!K!jfND{ffKN/jMFGJ'|PHAM;{ff?74sBYjM
KL/M*CDMJtSDpyKpy?7S?#P2@h*gQWMJtSDpyKpT?7S k+oA*pTKL4KL/M*{fLDBYjB#{ffK!MJjpyFBYKpT?7S}?#P h;*)GgQL/MJ?#jMF7ofI
2

fi X ttu
AM"B+E ?#tG!MJj#MlKLDBYKWKL/M"MFGG!MFSuKpTB#R'Ctp`MJjMFSD{ffMlpTG@KLDBYK@Bh;*BFEOLDBF#M{ff?74stRyMJK!MFRTE NDSDCDp
jMF{ffK!MFC{ffEH{JRyMFGJI[tN/KKL/MFG!M{ffEH{JRyMFG"NDG!KM.ffcYd!7VY S*h;*)GJIHNDSDCDpTjMF{ffK!MFC{ffE{JRyMFGBYjMKL/MJjMJP?#jM
P?#jtpTCDCDMFS2IuA@L/MJjMFB#GpTS(h*)GWNDSDCtpyjMF{ffK!MFCS/?7SH{fL/?#jCDB#R2{ffEH{JRyMFG@BYjM.P?#jtpTCDCDMFS2
K@GLD?7NDRTCMlS/?#K!MFCKLDBYK*AM{ff?7NDRC B#RTG!?zC/MJtS/M.@h*)GWEjMJstRTB#{JpTSDv{ff?7SDCDpyKpy?7SOpTS WMJP
pTSDpTKpy?7Sxk.P?#jpyKGMFNDpyYB#RyMFSuKJ HZ"\D#d!Vft] ^#/ZJXiZ YZJdfXffHVY] ^c /@HcY^Zff^taWc ] \"VaQdZZ
gA*LDp{LrpTG4BG!sMF{Jpyt{zKEsM ?#PW{fL/?#jCDB#R*v#jBYstLofSKLDpGAB+E#I(KL/MGpT}pTRTBYjpyKpTMFGB#SDCCDpMJjMFSD{ffMFG
MJKAMJMFSh;*)GWB#SDC @h*)GWBYjM.MJ#MFSO{JRyMFBYjMJjF;@SuEq?#PKL/M*h**)G@pSKL/MlGB#4MlMFuNDpT[
B#RyMFSD{ffMO{JRTB#GG}pG4?#DKB#pTS/MFCP j?7KL/M{ff?#jjMFG!s?7SDCDpTS/vh;* uEjMF?+HpTS/vxG!?74MO?#P)KL/MRTpTSDwG
gQ{ff?7Su#MJjKpTS/vqKL/MFpTSuK!?BYj{JGfopS?#jC/MJjK!??#tKB#pTS B4K!jMJMG!K!jND{ffKN/jM#
HB#pSDpTS/vzKL/MsDj?#tRyMFP j?7 B#S/?#KL/MJjs`MJjfG!sMF{ffKpy#M#I2P j?7 L/MJ?#jMFkB#SDChj?#s`?7GpyKpy?7S
AMl{JB#SG!MJMKLDBYKKL/Mlj?7RyMstRTB+E#MFC EKL/M.uG!K!jND{ffKN/jMFGpTSOh;*)GWpTGKL/MlGB#4MB#G*KLDBYKstRTB+E#MFC
EqKL/MLHLstBYK!K!MJjSDG@pTS*h;*)GJ
KWpG*B#RTG!?zpTSuK!MJjMFG!KpTS/vqK!?zSD?#K!MKLDBYKWKL/M"SuNDMJj@?#P**)G)A*LDpT{fLBYjM"MffHK!MFSDGpy?7SDG@?#PBqv7py#MFS
*h;*"I ID{JB#S`M{JB#RT{JNtRTBYK!MFC#MJjEzMFB#GpTRyE`KL/MGN/Dv#jBYsLzpSDCDND{ffMFCquEqMFB#{L {fLDB#pTS{ff?74s?7S/MFSuK
?#DP _pTG9B)K!jMJM#IHB#SDCKLDpGK!jMJM*{JB#S4MCDpyjMF{ffK!MFC4pTS4CDpMJjMFSuK9AB+EG9EG!MFRyMF{ffKpTS/v.B#SuE?#PKLDMS/?CDMFGB#G
KL/M@j?u?#KS/?HC/M#?#jMJ?%#MJjFI/A;MW{JB#S}stj?{ffMJMFCqpTSDC/MJsMFSDCDMFS[KRyEA*pyKLDpSMFB#{L{LDB#pS}{ff?74s?7S/MFSuKJ9L/M
SNDlMJj?#P2*GpS ^G | ;g .opTG9KLDMJjMJP ?#jM*MFNDB#RDK!?KL/MsDj?HCDND{ffK?#P`KLDM@SNDlMJj?#P2S/?HC/MFG9A@pyKLDpTS
MFB#{L{LtB#pTSx{ff?74s?7S/MFSuK.?# P "MJv7BYjCDpS/vKL/M}SND`MJj?#P(@h*)GKLDBYKjMJsDjMFG!MFSuK.KL/MqGB#4M
MFNDpyYB#RyMFSD{ffM4{JRTB#GGJI2KLtpTG)SuNDMJj@v#j?+A*GMffHs?7S/MFSuKpTB#RTRyEA*pTKLOKLDMGpyJM?#P;KL/M4NDStCDpyjMF{ffK!MFC{JRTpTN/MFG
pTSKLDM"h**"`D?#j@Mff/B#4stRyM#I`pyPiKL/MlGN/tv#jBYstL pTStCDND{ffMFCEBq{LDB#pS{ff?74s?7S/MFSuK*pTS Bh**
{ff?7SDGpG!KG?#P'Bl{ff?74stRTMJK!MWGNDDv#jBYstL}?#P S/?HC/MFGJIKL/MFSqKL/M)SuNDMJj?#P@h*jMJstjMFG!MFSuKBYKpy?7SDGpTG
Nn LtpTG?#pT?7NDGRyE C/?MFG)S/?#K4MFB#SKLDBYKBqGMFBYj{L4MJKLD?CtB#G!MFC?7S*h;*)G"NDG!KWMffsRy?#jM
B#- RTRKL/MFGM.MFuNtpyB#RTMFS[K(jMJstjMFG!MFSuKBYKpy?7SDGJ
NDjjMFB#G!?7SP?#jNDGpTS/v*h;*)G@pTGB#RT4?7G!K(Mff/{JRTNDGpT#MFRyEsDjB#{ffKp{JB#R9SPQB#{ffKJID*h;*)G@C/?S/?#K
LDB+#M*B){JRyMFBYjG!MFB#SuKpT{JGgKL/MJEBYjMBG!?7MJA*LDBYKLuEuDjfpTC{ffjMFBYKN/jM#I7MJKAMJMFS*GB#SDC4{ff?74sRyMJK!MFC
h**)GfofM {JB#S?7SDRyEGBFEKLDBYK4*h**)GA?7NDRTC{ff?#jjMFGs`?7StCK!?xG!MJKG?#P*MFNDpyYB#RyMFS[K*)G
A*LDp{L GLtBYjMB#RTRKL/M{JB#NDGB#R stBYK!K!MJjfSDGA*LDMJjMlB#SOMff`MF{ffK)S/?HC/MlLDB#G@BYKWRyMFB#GKKA?z{JB#NtG!MFG"gQB#StC?7SDRTE
KL/Mz{JB#NDGB#RstBYK!K!MJjSDGA*L/MJjMqBGpTS/v7RyM}{JB#NtG!Mqstj?+#?#w#MFG4B#SMff`MF{ffK4BYjMS/?#K"C/MJK!MJjpTSDMFCof LDpTGpTG
S/?#K)sDj?#RyMFBYKpT{A*L/MFSAMBYjMs`MJjP ?#j}pTS/vq?C/MFR;\FZffTZFaQ]cY^ N/KWpTKWMF{ff?74MFG{ffjfpyKpT{JB#RpyPAMBYjM
C/?7pTSDv}4?HC/MFR;V #Zffd!VF#]^u7(A*pyKL/?7N/K@B}G!MFB#SuKpT{NDSDC/MJjGKB#SDCDpTS/v4?#P9KLDM{JRTB#GG@?#P*h;*)GJI2pyK@A*pTRTR
M.uNtpyK!M.CDpy~}{JNtRyK;K!?qB#GGpyv7S Bstjpy?#j(K!?KL/MF
NDjWpTSuK!MFSuKpy?7SOpG*K!?K!jB#C/M"KL/MNDSDpTN/MFS/MFGG(?#PKL/MjMJsDjMFG!MFS[KBYKpT?7SO?#PMFuNDpTB#RyMFSt{ffM{JRTB#GGMFG@?#P
*)Gg=(h*)GoP?#jB}4?#jM"B#StBYv#MFBYtRyM"?7S/MgQ@h*Gfof*K!MFG!KpS/v}A*LDMJKL/MJjWBqv7py#MFSh*
pTGWB#S@h* pTG*MFB#GpyMJj)KLDB#SK!MFGKpTS/vzA*L/MJKL/MJx
j pTGWBq{ff?74sRyMJK!MFCh*"2SOKL/MtjG!K){JB#G!M#I
KL/M*{ff?7StGpTG!K!MFSD{ffE4{fL/MF{wpTSu#?7Ry#MFGK!MFG!KpTS/v.P?#jKL/M@BYtG!MFSD{ffM@?#PCtpyjMF{ffK!MFCB#SDC}{ff?74stRyMJK!MFRyE4NDStCDpyjMF{ffK!MFC
{ffEH{JRyMFGWgKLDMW{ff?74sRyMffHpTKE4?#P2KL/MFG!MWK!MFG!KGB#SDCqKL/?7G!M@SDMF{ffMFGGBYjEK!?"#MJjpyPEA*L/MJKL/MJjBlCtpyjMF{ffK!MFCv#jfBYstL
pTG.B*pGMffHB#{ffKRTEKLDM}GB#4M%ofIiA*L/MJjMFB#GlpTSKL/MG!MF{ff?7StC{JB#G!M#IpTSB#CDCDpTKpy?7SK!?K!MFG!KpS/vP ?#jKL/M
BYtG!MFSt{ffM"?#PCDpyjMF{ffK!MFCB#SDCstBYjKpTB#RTRyECDpyjMF{ffK!MFC{ffEH{JRyMFGJI2AM4B#RTG!?S/MJMFCK!?sMJjP?#j{fL/?#jCDB#RpyKE K!MFGKG
B#SDC{fL/MF{wzKLDBYK(MFB#{LBYj{pTGstBYjK?#P ?7SDM?#P KL/MpTSDCtND{ffMFCqGN/Dv#jBYstLtGCtpTG!stRTB+E#MFCqpSzpyv7NDjM.L/M
sDjp{ffM"AM}LDB+#MK!? stB+EOP?#jlNDGpTS/v*h;*)GlpG)KLDBYK.AM}BFE?H{J{JB#Gpy?7SDB#RTRTES/MJMFCK!?MJB#RTNtBYK!M}B#S
MFNDpyYB#RyMFSD{ffM{JRB#GG@?#jMlKLDB#S?7SD{ffM#@SOKL/M"S/MffK)G!MF{ffKpy?7SIAMA@pTRTRMff/B#pTS/ML/?+A BzRy?{JB#R'G!MFBYj{fL
4MJKL/?HCA*LDp{LNDG!MFG(@h*G*{JB#S B#RTG?4KBYw#MlB#C/YB#S[KBYv#M?#P'KL/M.CDMF{ff?74s?7GBYtpTRTpTKEsDj?#s`MJjKE}?#PB
G{ff?#jpS/v4PNtSD{ffKpy?7SpTS?#jCDMJjK!?MJ~}{JpyMFSuKRyEzMJB#RNDBYK!MlS/MFpyv7Lu?#jpTS/vG!K!jNt{ffKN/jMFGJ


fi

f #%$ff&(' *)

$ ,.$ !

"$ !$ $



1 : w ?:x :698
]>

.>$]

>

MlA@pTRTR2NDG!MB}Ry?H{JB#R4MJKL/?HC K!?qMffsRy?#jM.KL/MG!MFBYj{LG!stB#{ffM?#P*h;*)GJLDM.G!KBYjKpTS/v}s`?7pS[K?#P
KL/M)G!MFBYj{fLsDj?H{ffMFGGA*pTRTRt`MWB#SzMF4sDKEz*h;* gQ{ff?#jjMFGs`?7StCDpTS/v.K!?4B#SzMF4sDK|Eq*lofD>*MJ#MJjKLDMff
RyMFGGFIDA;M{ff?7NDRTCGKBYjKPj?7B#S/?#KLDMJj@{ff?7S/Dv7NDjBYKpy?7SpTP'AMlLDB+#M"G!?7M.sDjpy?#j*wS/?%A*RyMFC/v#MBY`?7NDKKL/M
sDjMFGMFSD{ffM4?#jlBYtG!MFSt{ffM4?#PG?74M4MFC/v#MFG.?#jl[G!K!jfND{ffKN/jMFGJM}"NDG!KKLDMFSxC/MJtS/MKL/M4?#sMJjBYK!?#jfGK!?
4?%#MlPj?7 ?7S/M.{ff?7S/tv7N/jBYKpy?7SK!?qB#S/?#KL/MJj@SDMFpyv7L[?#jpS/v"{ff?7SDDv7N/jBYKpy?7S

-
k

?

PN

N/j(B#GpT{)?#sMJjBYK!?#jGBYjM.KL/M.pTSD{JRNDGpy?7Sq?#P9B#SMFC/v#M.MJKAMJMFSBsB#pyj(?#P9S/?7SHB#CB#{ffMFS[K@S/?CDMFGB#SDC
KL/M;jMF4?+YB#Ru?#PDB#S.Mff/pTG!KpTS/v*MFC/v#M;MJK|A;MJMFS"BstB#pTj ?#P/B#CB#{ffMFS[KS/?HC/MFG pTSlKL/M;{JNDjjMFSuK {ff?7S/Dv7N/jfBYKpy?7S2
L/MFGMMFC/v#MFG*B+E`MMFpTKL/MJj*CDpyjMF{ffK!MFC?#j@NDSDCtpyjMF{ffK!MFC2
LDM"pTSt{JRTNDGpy?7S?#PB#SpTG!?7RBYK!MFCRpTS/Bw !kOA*pTRTR G!MJj#MB#G)BzK!MF4stRTBYK!MP?#jKL/M"BYjf{JG kB#SDC
B
k[LD?+AMJ#MJjFI[KL/M(RTpS/
w !kK!?#v#MJKL/MJjA*pTKL"B#SD?#KL/MJjRTpTS/w jMJsDjMFGMFS[K9B#SuE"{ff?7tpTSDBYKpT?7S?#P
BYj{JG MffH{ffMJsDK'KL/?7G!MKLtBYK {ffjMFBYK!M;SDMJALHLstBYK!K!MJjfSDG;gKL/M;*)G(gQB[ofIHgoB#SDC}gQ{+opTSpyv7N/jM;7ofiSKL/M
{JB#G!M?#PB#CtCDpTS/vWB#S"BYjf{YI#A;M(B+El?#DKB#pTSG!MJ#MJjfB#RCtp`MJjMFS[KS/MFpyv7Lu?#jpTS/v*{ff?7SDDv7N/jBYKpy?7StGJI#C/MJsMFSDCDpTS/v
?7SKL/MlK!?#s`?7RT?#v#Eq?#PKL/M.{JN/jjMFS[K@h*B#SDCKLDM.CDpyjMF{ffKpy?7S?#PiKL/MlBYjf{)`MFpS/v4pTSD{JRTNDCDMFC2iWG(AM
A*pTRRG!MJM#IpyPAMzBYjMzK!MFG!KpTSDvOKL/MzpTSD{JRTNtGpy?7S?#PB#SMFC/v#MzMJKAMJMFSK|A;?S/?HC/MFxG rB#SDC k`IKLDpTGBFE
pTSu#?7Ry#MK!MFG!KpS/vOG!?7M}?#PKL/MqCtp`MJjMFS[KYB#RTpTCx{ff?7SDDv7N/jBYKpy?7StG.?#DKB#pTSDMFCuEKLDM}pTSD{JRTNtGpy?7S?#P(KL/M
RTpTSD
w !k`IKL/MqBYj{ kI KL/M}BYj{ k`IKL/M}L/LstBYK!K!MJjE
ky ?#j.KL/MLHLsBYK!K!MJjS



kgA@L/MJjM
pTSKLDMRB#G!KK|A;?x{JB#GMFG4A;?7NtRTCMB#S[ES/?HC/MzGND{LKLDBYKMFpyKL/MJjKL/MRTpS/w
k` ?#jzKL/MORpTS/w Mff/pTG!KGzpTSKLDM{JN/jjMFSuKq{ff?7SDDv7N/jBYKpy?7S`of@?+AMJ#MJjFI*KLDMjMF4?%B#R*?#P.B#S
MFC/v#M.A@pTRTR`B#RyAB+EGjMFGNDRyK(pTS?7StRyE}?7S/M.SDMFpyv7L[?#jpS/v"{ff?7SDDv7N/jBYKpy?7S KL/MJj(?#sMJjBYK!?#jGJIGND{LB#G@BYj{
jMJ#MJjGB#Rg=LDpT{w#MJjpTS/v/IkFm#m#7ofIA*pTRTRS/?#K(M)NtG!MFCzuEz?7N/jG!MFBYj{fL 4MJKL/?HC2LDM)GMJK(?#P'S/MFpyv7Lu?#jpTS/v
{ff?7S/Dv7NDjBYKpy?7SDG@?#P;Bqv7py#MFS*h;*
A*pTRRKL/MJjMJP?#jM"MKL/MG!MJK)?#PB#RTR'KL/M4CDpMJjMFSuK@@h*)G
?#DKB#pTSDMFCP j?7 EB#CtCDpTS/v?#j*C/MFRTMJKpTS/v4BGpTSDv7RyM)MFC/v#MqgMFpyKL/MJj@CDpyjMF{ffK!MFC?#jWNDSDCDpTjMF{ffK!MFCof
MJP?#jMMffHstRTB#pTSDpS/v}KL/MCDMJKB#pTRTGW?#P;KLDMG!MFBYj{L4MJKL/?HC2IRyMJK.NDGpTRRTNDG!K!jBYK!M"KL/MB#pSpC/MFB#G)uE
4MFB#SDG"?#P(KL/MzP?7RTRy?+A@pTS/v Mff/B#4stRyM#{ff?7StGpTC/MJj"KL/M*h**pTSpyv7N/jMnI9A*LtpT{LjMJsDjMFG!MFSuKG"KL/M
{JN/jjMFS[K{ff?7S/tv7N/jBYKpy?7S?#P`KL/MG!MFBYj{fLsDj?{ffMFGGgKLtpTG9Dv7N/jM?7StRyECDpG!stRTB+EGiKL/M(stBYjK9?#PKL/M@h*
{ff?#jjMFGs`?7StCDpTS/vK!?KL/M@S/MFpTv7L[?#jL/??HC4?#PKL/M@S/?HC/MF{G B#St5C kDofIB#SDCqB#GGNDM*KLDBYK;A;MWGLDB#RTRDpSD{JRTNDC/M
B#SMFC/v#Ml`MJK|A;MJMFSKL/MlS/?HC/MFG B#SDBC k`

x



pyv7N/jMln@>*?HC/MuxLDB#GW?7S/MstBYjMFSuKWB#SDC?7S/M4{fLDpTRTC2IkC/?MFG)S/?#KLDBF#M4B#SuEstBYjMFSuKG)B#SDCLDB#GWKA?
S/MFpyv7Lu`?#jfG
SKLtpTGlGpTKNDBYKpy?7S2IiA;M{JB#SDS/?#KpTSuK!j?HCDND{ffMKL/MRTpTSD
w kMF{JB#NDG!MzA;MqA;?7NDRCHpy?7RTBYK!Mq?7S/Mq?#P
KL/M}{ff?7StCDpyKpy?7SDGCDMJtSDpTS/v*h;*)GgQ{ff?7SDCDpTKpy?7Sk+of}MzBFEpTSuK!j?HCDND{ffM4KL/MBYj{5 kB#StCxpTS
KLDpTG({JB#GM#IBYv7B#pTSOpTS?#jC/MJjK!?}sDjMFG!MJj#M{ff?7SDCDpyKpy?7SkYIKL/MKA?qSDMFpyv7L[?#jG?#RP kNtG!KM{ff?7S[#MJjK!MFC


fi X ttu
pTSuK!?"{fLDpTRTCDjMFS2iM){JB#SB#RTG?"pTSt{JRTNDC/MKLDMWBYj{wBk9pTSDB#RRyE#I[AMBFE}pSD{JRTNDC/M*KA?Ctp`MJjMFS[KLHL
stBYK!K!MJjStG k5 I/A*LDMJjM pGBS/MFpTv7L[?#j?#POkgKLDMW?#KLDMJjS/MFpyv7Lu`?#j"NDG!KMW{ff?7Su#MJjK!MFC pTSuK!?
Bl{fLDpTRTCI[?7SD{ffMWBYv7B#pTSqpS?#jC/MJj;K!?stjMFG!MJj#MW{ff?7SDCDpyKpy?7SOk+ofL/MFG!M@P ?7NDj;CDpMJjMFSuK{ff?7S/Dv7NDjBYKpy?7SDGBYjM
CDpTGstRTBFE#MFCpSipTv7N/jMlm
x



x



x



x



pyv7N/jMlm@>*MFpyv7Lu?#jpTS/v.{ff?7SDDv7N/jBYKpy?7StG9?#DKB#pTS/MFC}uE4pTSt{JRTNDCDpTSDvWB#S}MFC/v#MMJKAMJMFScB#SDCckpS4KL/M
{ff?7S/Dv7N/jBYKpT?7S?#Pipyv/`n

-
9
E B)>
k





,ff

N

q

S?#jC/MJjK!?CDMFGpyv7SxBG!EHG!K!MFBYKp{4AB+EK!?C/MJK!MJjpS/M4A*LDpT{fLS/MFpyv7Lu?#jpTS/v*h;*)G"BYjpTG!MPj?7
KL/M)pTSD{JRTNtGpy?7S4?#jKL/MWjMF4?%B#R`?#P B#SzMFC/v#MpTSqB#Sz@h*IDpyK;pTGGN/~q{JpyMFS[KK!?{ff?7SDGpTC/MJjG!?74MRy?H{JB#R
stBYjB#MJK!MJjG?#P`KL/MK|A;?lSD?C/MFGK!?.M{ff?7SDS/MF{ffK!MFC29pyjG!KJIuG!?74M*B#CDCtpyKpy?7SDB#RHS/?#KBYKpy?7SqpTG9pTSuK!j?HCDND{ffMFC2
ffP ~~ujMJsDjMFG!MFSuKGKL/M.{JBYjfCDpTSDB#RTpTKE}?#P9B4G!MJKJItv7py#MFSBSD?C/M pTSB4h**z
"IA;M.CDMJtS/M#







g 2o
g
lg 2o]HV~ p lg oM~I

l ]HV~ mGo? l M~
Q






g
g 2o
o? lg 2o]HV~
lg 2oM~
*
l ]HV~
l M~
x

tGMJj#MKLDBYKP?#j*B#SuE@h*f"IDKLDM.P ?7RRy?+A*pS/vKA?sDj?#sMJjKpyMFG(LD?7RTC2
lg 2o

lg Q lg 2]o H lg
lg
H
Z LQ lg {o HgQL/MFSD{ffM lg 2o lg H lg 2o!o
pTP

BdS)
)tEEh

L/MSNDMJjB#SDCKEsM?#P`SDMFpyv7L[?#jpS/vW{ff?7SDDv7N/jBYKpy?7StG9KLDBYK{JB#S4M(?#DKB#pS/MFC4Pj?7KL/MpTSt{JRTNDGpy?7S
pTS}KL/MW{JNDjjMFSuK@h*?#P B#SqMFC/v#MWMJKAMJMFBS B#StcC k}{JB#SqM@C/MJK!MJjfpTS/MFCqP j?7KL/MWstBYjB#MJK!MJjG
BY?+#M#,*L/MjMFGNDRyKB#SuK}{JB#GNDpTGK!jEBFErM jMFCDND{ffMFCrK!?G!MJ#MFSG!KBYK!MFGJIA@LDpT{LrA;MLDBF#MRTBYMFRyMFC


fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



Pj?7 K!?1"WS?#jCDMJjWK!?zPQB#{JpTRTpyKBYK!MpyKGWC/MFG{ffjpystKpy?7S2IDAM"GLDB#RTR NtG!MKLDM"C/MF{JpGpy?7S K!jMJM"GLD?+A*SpTS
pyv7N/jMkJ&Y
None

nG(x)=0 nG(y)=0?



Yes

nG(x)=0 nG(y)=0

nG(x)0 nG(y)0

pG(x)=0 pG(y)=0 ?

pG(x)=0 pG(y)=0 ?



Yes

nG(x)=0 nG(y)=0
pG(x)=0 pG(y)=0

nG(x)=0 nG(y)=0
pG(x)0 pG(y)0

nG(x)0 nG(y)0

State

C



nG(x)=0 nG(y)0

pG(x)=0 pG(y)0
nG(x)0 nG(y)=0

State F

State G

pG(x)0 pG(y)= 0

pG(x)=0 pG(y)=0
nG(x)0 xor nG(y)0

nG(x)0 nG(y)0

n G ( x) = 0 ?
Yes



Yes

pG(x)=0 pG(y)=0

nG(x)0 nG(y)0
pG(x)0 pG(y)0

pG(x)=0 pG(y)=0
nG(x)0 nG(y)0 ?

State B

State



Yes

n G ( x) = 0 ?


Yes

pG(x)=0 pG(y)=0
nG(x)=0 nG(y)0

pG(x)=0 pG(y)=0
nG(x)0 nG(y)=0

State

State E

pyv7N/jMkJH@L/M.K!jMJM"?#Ps?7GGpytRTM)GKBYK!MFG@KLtBYK@B+EjMFGNDRyK(E B#CDCDpS/vB#S MFC/v#MMJKAMJMFSOS/?HC/MFG
B#SDC1k

+BQ=fB=' f ff| +#=f , %'7== J2= ')| =% W = f 2%= = ff' =W9=e% % = J) = [9 ! l /= += J
%



*

;

*
.


ff n




;

ff w
R
; v

; "





fi X ttu
S"KLDpTGiK!jMJM#I[KLDMRT?+AMJj9`?+?#PMFB#{LS/?7S/=K!MJjpTSDB#Ru#MJjK!Mff{ff?7SuKB#pTSDG9BWK!MFG!K*gQBY?7N/KKL/M(SuNtlMJj
?#PstBYjMFS[KG)?#j)KL/M4SNDlMJjW?#PS/MFpyv7Lu?#jG@?#PS/?HC/MFG*xB#SDCkDof.L/MRy?%A;MJj)?F?#PMFB#{LK!MJj}pTSDB#R
#MJjK!Mff}{ff?7SuKB#pTSDG9KLDM*RTBYMFRH?#PKL/M*G!KBYK!MjMFGNDRyKpTSDvWPj?7P?7RTRy?%A*pTS/v)KL/M*stBYKL4Pj?7KL/Mj?u?#KK!?lKLDBYK
K!MJjpSDB#Rt#MJjK!Mff`*L/MC/MFG{ffjpystKpy?7S?#P'MFB#{L G!KBYK!M}gQp=M#9KL/MCDpMJjMFS[KS/MFpyv7Lu?#jpTS/v"{ff?7S/Dv7N/jfBYKpy?7SDG
KLDBYK4{JB#SMq?#tKB#pTS/MFCpTSKLDpTG"{JB#G!M%o"{JB#S`MzP?7NDSDCpTSiBYtRyMkYxLDMzN/sts`MJj?FHMFG?#P*B#RTRKL/M
#MJjKpT{ffMFGpTSKL/MK!jMJM}GL/?%AKL/MjMFGK!jpT{ffKpy?7SDGp4s?7G!MFC?7SxMFB#{LpTSuK!MJj4MFCDpTBYK!M4?#jlK!MJjpTSDB#R9GKBYK!M#
/?#j4Mff/B#4stRyM#I;G!KBYK!M {ff?#jjMFG!s?7SDCDG"K!?BGpyKNDBYKpy?7SA*LDMJjMq?#KLS/?HC/MFuG B#SDC kC/?S/?#K4LDB+#M
S/MFpyv7Lu?#jG(B#SDC BYK@RyMFB#G!K?7S/Ml?#P'KL/MFLDB#GG!?7M.stBYjMFSuKJ;WRyKL/?7N/v7LKLDM.K!jMJMlLDB#G*G!MJ#MFSCDpy`MJjMFSuK
G!KBYK!MFGJI2KLDMJjM4BYjM?7StRyE D#M"K!jNDRyE Ctp`MJjMFS[K)G!KBYK!MFGJIGpSD{ffM"GKBYK!MFGB#SDCI2B#SDCG!KBYK!MFG.B#SDCx
BYjMlGEMJK!jpT{JB#R
KBYK!M


@> NtlMJj(?#P
{ff?7S/Dv7N/jBYKpT?7SDG
k





g 2o





gk+o(?7SDRyEqpTP
g7o(?7SDRyEqpTP

!k



k

Bk
!k


k
5



k

g /o k

Q l

)pyjMF{ffK!MFC 0@StCDpyjMF{ffK!MFC ?7stRyMJKpTS/v
EH{JRyMFG E{JRTMFG
>*?
>@?
>@?
-MFG +(1
>@?
>@?
.
+
2
1
>@?
>@?
-MFG
>*?
>@?
-MFG
.
+
2
0
1
-MFG
>@?
-MFG +021
>@?
-MFG +31
-F
G +31
>@?
>*?
>@?
>*?
>@?
-MFG +021
>@?
>*?
>@?
>*?
>@?
-MFG +31
>*?
>@?
>@?
-MFG
-MFG
>@?
>@?
-MFG +.021
-MFG +021
>*?
>@?
>@?
-MFG
-MFG
>@?
>@?
-MFG +31
-MFG +31
g7o(?7SDRyEzpyPOQ glkDoQ
guo(?7SDRyEzpyOP Q glosQ

@CtC/MFCMFC/v#MFG

Q lk

Q lk

!k

k5

Q

g Dok
glok

!k

k

g

Bk

k

g



Q lk




k5






k
Bk

k

Q l

gg 2DoXoXII B#B#SDSDCC gg 2DoJoJII
l
lk

H

H

lk

l

H
H

' BYRyMkYiBYtRyM?#P9G!KBYK!MFG@KLDBYKBFEjMFGNDRyK(EzB#CDCtpTS/v4B#SMFC/v#M.MJK|A;MJMFSOS/?CDMFGffOB#SDCk
iBYtRyM}kYIMFB#{LOj?+A {ff?#jjMFG!s?7SDCDGK!?}B}G!KBYK!M#KL/M.tjG!K{ff?7RTND}S {ff?7S[KB#pSDGKL/MRTBYMFRTG(?#PKL/M
G!KBYK!MFGJtKL/MG!MF{ff?7SDC{ff?7RTNDSCDpG!stRTB+EGKL/M)K!?#KB#RSuNtlMJj?#P'S/MFpyv7Lu?#jpTS/v{ff?7S/Dv7N/jBYKpT?7SDGKLDBYK{JB#S
M}?#DKB#pS/MFCP?#j"MFB#{LG!KBYK!M#KL/MzKLDpyjC{ff?7RTNDSGL/?+A@GlKL/MCDpMJjMFSuKlK|EusMFG"?#PMFC/v#MFG"KLDBYKJI9P?#j
MFB#{LGKBYK!M#I{JB#SMzB#CDC/MFCK!?OKL/Mz{JN/jjMFSuK{ff?7S/Dv7N/jBYKpT?7S2{ff?7RTNDStG.P?7N/jFID#MB#SDCGpyxA*pTRTR9M
CDpTG{JNDGG!MFCRTBYK!MJjF
0WGpTS/vzKL/MMff/B#4stRyMpTSpyv7N/jM4nI2A;M4GLtB#RTR MffHstRTB#pSKL/M4NDGM"?#PKL/M4C/MF{JpTGpy?7SK!jMJM4B#G)AMFRTRB#G
KL/M"pTSDG!KB#SuKpTBYKpy?7S?#P9KLDMlpTS/P?#jBYKpy?7SpTS iBYtRyM}kY/?7RRy?+A*pS/vKL/MlCDMF{JpTGpy?7SK!jMJM#I`BYKWRyMJ#MFR;kqgKL/M
j??#K*#MJjK!MfftofI`KL/MlK!MFG!K)pTG(PQB#RTG!M"GpTSD{ffM k LtB#GKA?S/MFpyv7Lu`?#jfGJKWRyMJ#MFRItKL/MK!MFG!K@pTG@B#RTG!?PQB#RTG!M"B#G
LDB#GW?7S/MlsBYjMFS[KJ)K)RyMJ#MFRi}KL/M"K!MFG!K)pTGK!jNDM#I`GpSD{ffx
xLDB#GWS/?zS/MFpyv7Lu`?#j+*KWRTMJ#MFR zA;M"jMFB#{fL

/



fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



BOK!MJjpTSDB#R;#MJjK!Mff N/j{JN/jjMFSuK"{ff?7SDDv7N/jBYKpy?7SKL/MJjMJP?#jM{ff?#jjMFG!s?7SDCtGlK!?G!KBYK!M i*L/MFS2IuE
Mff/B#pTSDpTSDv G!KBYK!Mz,pTSxiBYtRyMkYIAMq{JB#S{ff?7S/Dj KLDBYKlAM}jMFB#{fLP ?7N/j"CDpMJjMFSuKl{ff?7S/Dv7N/jfBYKpy?7SDG
lg Q lg k/{
H_7ofd J kP7I c J kPA@pyKL/?7N/KS/MJALHL"stBYK!K!MJjSDGJI7B#StClK|A;? J k% P
A*LDp{Lstj?CtND{ffM@S/MJALHLqstBYK!K!MJjSDGF;?/IuKLDMFG!MWBYjM@KL/MW?7SDRyEGK!jND{ffKN/jMFG;KLDBYK?7N/jB#Ryv#?#jpyKLD"NDG!K
MJYB#RTNDBYK!MA*L/MFS{ff?7SDGpTC/MJjpTSDvlKL/MpTSD{JRNDGpy?7S}?#P KL/M{JB#SDCDpCDBYK!M)MFC/v#M ! k`Szpyv7NDjM"kff/ItA;MGL/?%A
B#SMffHB#4sRyMqP?#j"MFB#{L?#P(KL/MzD#MS/?7SHG!EH4MJK!jp{JB#RG!KBYK!MFG g?7SD{ffMBYv7B#pTS2I9KLDMFG!MqMff/B#4stRTMFGl?7SDRTE
CDpTGstRTBFE4KLDM@stBYjK?#P'KL/M)*h**)G{ff?#jjMFGs`?7StCDpTS/vK!?"KLDM)SDMFpyv7L[?#jLD?u?HC?#P'KL/MWSD?C/MF(G B#StC kDof
MKL/MJjMJP ?#jMLDB+#M.B4G!EHG!K!MFBYKpT{WABFEzK!?"MffHstRy?#jM)B#RRtKL/MS/MFpTv7L[?#jpTSDv{ff?7S/Dv7NDjBYKpy?7SDGA*LDp{L
jMFGNtRyK}Pj?7 B#CDCDpTS/vB#SMFC/v#M#*?%A;MJ#MJjFI)pyKzA*pTRTR*G!?74MJKpT4MFGzMOSDMF{ffMFGGBYjErK!?sMJjP?#j G!?74M
B#CDCDpTKpy?7SDB#RG!K!MJstG@GpTSD{ffM)KL/Ml{ff?7SDDv7N/jBYKpy?7StG?#DKB#pTS/MFC "NDG!K(M.@h*)GF
lg k/c
HI H
L Q lg k/Go H[of K"pTG.KL/MJjMJP?#jM
pyjfG!KJI'AMNDGKB#pTSuKB#pTSKL/Mq{ff?7SDCtpyKpy?7Srkg
SDMF{ffMFGGBYjEK!?Ofc /@TZJaZ@KL/Ml{ff?7SDDv7N/jBYKpy?7S P ?#jWG!?74M.?#PKL/M"C/MFG{ffjpyMFCG!KBYK!MFGJIpM#G!?74Ml?#P
KLDMqRTpTSDwG"NDG!K.M}{ff?7Su#MJjK!MFCpTSuK!?BYj{JGJLDM}{ff?74stRyMJKpS/v sDj?H{ffMFGG{ff?7SDGpTG!KGlpTSDjpS/v B#S
?#jfpyMFS[KBYKpT?7SpTS {JB#G{JB#C/M#I`GKBYjKpTS/v4Pj?7KLDMlRTpTS/wHG k` | GND{LKLDBYK*KL/MBYj{NDG!K*pTSuK!j?HCDND{ffMFC
pwG k"MJKNDG){ff?7SDGpTCDMJjWKLDMGpyKNDBYKpy?7SpTSpyv7N/jMk#kYIA@L/MJjMA;MAB#S[KK!? {ff?7StS/MF{ffKKL/M
SD?C/MF]G qB#SD%C k`I[B.{JB#GM@{ff?#jjMFGs`?7StCDpTS/vWK!?lG!KBYK!MWu@4?7SDv.KL/M(KL/jMJM*s`?7GGpytRyMS/MFpyv7Lu?#jpTS/v
{ff?7SDDv7N/jBYKpy?7StGJIiRTMJKlNDG.GNDsDs?7G!M4KLDBYKlAMqBYjM}K!MFG!KpTSDv KL/M?7S/MqA*LDpT{fLxpTSuK!j?HCDND{ffMFGKL/MzLHL
sBYK!K!MJj
k1 .L/M*h;*?#DKB#pTSDMFCOPj?7KL/M4{ff?74stRTMJKpTS/vzsDj?H{ffMFGG)pTG)B#RTG!?CDpTG
sRTBFE#MFCzpTS}pyv7NDjMlk#kYLDM*GpHKL}{ff?7RTNtS}pTS}'BYtRTMk*GL/?+A*G;A*LDp{L}GKBYK!MFGB#StC}S/MFpyv7Lu?#jpTS/v
{ff?7SDDv7N/jBYKpy?7StGBFEjMFNDpyjMWKLDM.{ff?74stRyMJKpTSDv4sDj?H{ffMFGGJ

x



x



w

w

z

z

pyv7N/jMk#kY@ j B#StG!P ?#jfBYKpy?7S?#P(B {ff?7S/tv7N/jBYKpy?7SBYP K!MJj"pTSD{JRTNDCtpTS/v}KLDMstBYK!K!MJjS
{ff?74stRyMJKpTSDv






k



B#SDC

HMF{ff?7SDCDRyE#IYpyK pTGs`?7GGpytRyMKLDBYKiG!?74M;?#PKLDM;S/MFpyv7Lu?#jpTS/v({ff?7S/tv7N/jBYKpy?7SDG'NtG!KMjM!MF{ffK!MFC2I#B#G
KLDMJEv7py#MWjpTG!M@K!?"CDpTjMF{ffK!MFC}?#j({ff?74sRyMJK!MFRyENDSDCtpyjMF{ffK!MFC}{ffEH{JRyMFGgQ{ff?7SDCDpTKpy?7SDG;B#SDClCDMJtSDpTS/v
@h*Gfof4/?#j.Mff/B#4stRyM#IRyMJKNDG){ff?7SDGpTC/MJjKL/M4GpyKNtBYKpy?7SCDpTG!stRBFE#MFCpTSipTv7N/jMkFIA*LDp{L
{ff?#jjMFG!s?7SDCDGK!?xG!KBYK!M SKLDpTG"{JB#G!M#I;KL/M{ff?7S/Dv7N/jBYKpT?7S?#tKB#pTS/MFCBYP K!MJjpSD{JRTNDCDpS/vKL/M
BYjf{ kB#SDC{ff?74stRyMJKpTSDv}A?7NDRTCOv#MFS/MJjBYK!M4BCDpyjMF{ffK!MFC{ffE{JRTM#)*LDpTG*{ff?7SDDv7N/jBYKpy?7S"NDG!K
KLDMJjMJP ?#jM}MjM!MF{ffK!MFC2L/M}{ff?7RNDSDGP?7N/jlB#StCxD#M}pSx'BYRyMk}GL/?+AA*LDpT{fLxG!KBYK!MFGB#SDC
{ff?7SDDv7N/jBYKpy?7StG4BFEjMFuNtpyjMBC/MJK!MF{ffKpy?7S?#P)CDpyjMF{ffK!MFC?#j{ff?74stRTMJK!MFRyENDStCDpyjMF{ffK!MFC{ffE{JRTMFGJI
jMFG!sMF{ffKpy#MFRyE#

N



fi X ttu

x



x



ipTv7N/jMkF>@MFpyv7Lu`?#jfpTS/v4{ff?7S/Dv7N/jfBYKpy?7SKLDBYKv7pT#MFGjpTGMWK!?qBCDpyjMF{ffK!MFC{ffE{JRyM

BzhB
)tEEh

L/Ml?#KL/MJj@B#GpT{?#sMJjBYK!?#jFIKL/MljMF4?+YB#R?#PB#SMFC/v#MgMFpTKL/MJj@RTpS/w}?#j)BYj{+o(pG*"ND{LOGpT4stRTMJj(KLDB#S
KL/MB#CDCDpTKpy?7S?#PB#SMFC/v#M#I)GpTSD{ffM?7SDRTEr?7S/MS/MFpyv7Lu?#jpTS/v{ff?7S/Dv7N/jBYKpT?7S_pTGz?#DKB#pTS/MFCA*L/MFSAM
C/MFRyMJK!M"B#SMFCDv#M#W?#jMJ?+#MJjFIpTK@pTG@S/?#K@S/MF{ffMFGGBYjE K!?zsMJjP ?#jfB#S[EK!MFG!K@P?#j)C/MJK!MF{ffKpTS/vzCDpyjMF{ffK!MFCO?#j
NDSDCtpyjMF{ffK!MFC{ffE{JRTMFGJ@?+AMJ#MJjFIpTSKLDpTG){JB#G!MAM4S/MJMFCK!?sDjMFGMJj#M4{ff?7SDCDpyKpy?7S pTSKL/M4C/MJSDpyKpy?7S
?#P;@h* gQpy]P k Mff/pTG!KG)pTE
qL ~ mxo lg kDMo ~9Q,q?#j mGo? lg 2o Hx

7ofIKLtBYK){ff?7NtRTCM"pT?7RTBYK!MFC
$
BYPK!MJjB#SBYjf{}pTG.CDMFRyMJK!MFC2q*LDpTGGpyKNtBYKpy?7SxB+EBYsts`MFBYjl?7SDRyEA*L/MFSAMqBYjM}v#?7pTS/v K!?OjMF4?+#MzB#S
BYj{ k B#SDCOMFpyKL/MJj mGo lg kDffo H J DP?#j mGo lg kDo H J K P7*pTSOKL/MlDjfG!K@{JB#G!M#IB#RRKL/M{LDpRTC/jMFS
?#.P k}KLDBYK*CD?SD?#KLDBF#M.?#KLDMJjstBYjMFSuKG(KLDB#1
kzNtG!K(M){ff?7Su#MJjK!MFCOpTS[K!?SDMFpyv7L[?#jG?#.P kIDB#StCKLDpTG
sDj?H{ffMFGGWpTGjMJs`MFBYK!MFCG!KBYjKpS/vPj?7MFB#{fL?#P9KL/MFG!M{LDpTRC/jMFS2tpSKL/MGMF{ff?7SDCO{JB#GM#IpTP mxo g Hj$
KL/MFSpTSB#CtCDpyKpy?7SK!?KL/MqsDjMJHpy?7NDG.stj?{ffMFGGJIKL/MqBYj{ kx"NDG!KlMz{ff?7S[#MJjK!MFCpS[K!?OKL/MqRTpS/w
kpyv7NDjMkF4pTRTRNDG!K!jBYK!MFGKL/MFGMlGpyKNDBYKpT?7SDGJLDpGsDj?H{ffMFCDN/jM)?#PK!jB#SDG!P?#jpS/v4BYj{JG*pTSuK!?RTpTSDwG
pTGMff/B#{ffKRyEKL/M.GB#MlB#GKL/M?7SDMlC/MFG{ffjpT`MFCpTSKLDM.sDj??#P ?#P9hj?#s`?7GpyKpy?7S

x



x

u


u

pyv7N/jM4kF jB#StG!P ?#jfpTS/v4BYj{JGpS[K!?}RpTS/wHGBYPK!MJj*jMF4?+HpTS/v4KL/M.BYjf{

u
k

u

H


k

W RyKL/?7N/v7LKL/MsDjMJpy?7NtGqC/MFG{ffjpysDKpy?7S?#P"KL/M?#s`MJjfBYK!?#jGKLDBYK C/MJtSDMKLDMSDMFpyv7L[?#jLD?u?HC?#P"B#S
*h;*pTG)NDpyK!M{ff?7S[#MFStpyMFS[KPj?7 BzsDjB#{ffKpT{JB#R(gQpTstRyMF4MFSuKBYKpy?7Sos?7pTS[KW?#PHpyMJA.IP?#j)KL/M4GBYw#M
?#P9{JRTBYjpyK|E#I/A;MGLDB#RTR2C/MFG{ffjpyM)KL/MFpTSB#S/?#KLDMJjAB+E#;SPQB#{ffKJItAMlGLDB#RTRNDGMD#M.?#sMJjBYK!?#jGJ
lg K kDofIB#CDCtpyKpy?7Sz?#P9B#S BYj
{ k




fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



x



x



B

x



x



C

x



x



x


D, analogous E

x




F, analogous G

x







x





x







x



x





x



x



x





x



x





x





pyv7N/jMkff/@/?#j}MFB#{fLrG!KBYK!M ?#PWKL/MC/MF{JpTGpT?7SK!jMJMpTSpyv/(kJHIB#SMff/B#4stRTMz?#P@KL/M S/MFpyv7Lu?#jpTS/v
{ff?7S/Dv7N/jBYKpT?7SDG9?#P2B#S}@h*KLDBYK;{JB#S}M(?#DKB#pTS/MFCBYPK!MJj;B#CtCDpTS/vB#SMFCDv#MMJKAMJMFS
S/?CDMFffG OB#SD
C k


fi X ttu

)2g
g
)2 g

DofIB#CDCDpTKpy?7Sz?#PB}RTpTS/w5k`

l K kDofItC/MFRyMJKpT?7S?#PiB#SBYj{
k
F
Q l K kDofItC/MFRyMJKpy?7S ?#PiBRpTS/5
w k
F
K Kn ofIB#CDCDpTKpy?7S?#PiB#SzBYjfw
{ k}B#StCz{ffjMFBYKpy?7S?#P KL/M)LHLzstBYK!K!MJjSB k5 uE
, gl k

K!jfB#SDG!P?#jpTS/vKL/MRTpTS/5w k` pS[K!?KLDM.BYj{ k5
LDM.{ff?7SDCDpyKpy?7StGKLDBYKKL/Ml{JNDjjMFSuK**h;*z
NtG!K(#MJjpyPEzG?KLDBYKMFB#{fL?#PKL/MFG!Ml?#s`MJjfBYK!?#jG
{JB#SMWBYststRTpyMFCqpTS}?#jfC/MJj(K!??#DKB#pTSB"B#RTpCqS/MFpTv7L[?#jpTSDvl*h;* BYjMGL/?%A*SpTSz'BYtRTM*L/MFG!M
{ff?7SDCDpTKpy?7SDG{JB#SzM*MFB#GpTRyE4C/MJjpy#MFCqPj?7KLDM@pTS/P?#jBYKpT?7S}pTSqipTv7N/jMkJ"B#SDCz'BYRyMkY9SqiBYtRyM)I
! kllg !pTSKkDL/o`MjMJ{JstNDjjMFjMFG!MFSuSuKiK@G hB(K!MF*G!K'"P ?#7ji>@C/?#MJK!M(K!MFK{ffLDKpTBYS/KivWA;{ffM(?74{JB#stS"RyMJsK!MJMFjRTPEW?#NDj,StCDKpyLtjMFpTG{ffK!K!MFMFC.GKi{ff#EHMJ{JjRyMFElG'MFBYB#P GK!pTMJRTjEpTA*SDG!pyKMJL/jK?7pTN/S/KivB#K{ffL/KMNDRTB#pRTS/RyEw
pTSDGMJjKpTS/vKL/MzRTpTS/w`pyKlpTGl?7SDRyExS/MF{ffMFGGBYjEK!?{fL/MF{wKL/M}Mff/pTG!K!MFSt{ffM}?#P*BstBYKLMJK|A;MJMFS B#SD
C k
Mff/{JRTNDGpy#MFRTE4P ?#jMFC}EKL/M)RTpTS/wHGJHpTpRTBYjRyE#`I F lg kDoB#SDC F lg k% ojMJsDjMFG!MFSuK;K!MFGKG
P?#jC/MJK!MF{ffKpTS/v"CDpyjMF{ffK!MFC}{ffE{JRyMFG;BYP K!MJjpTSDG!MJjKpTS/v)KL/M*BYjZ{ k4B#SDC4KLDM*LHL4stBYK!K!MJjf5S k% pTS
KL/M4{JN/jjMFS[K)*h;*"I2jMFG!sMF{ffKpy#MFRTEgQB#SDCsMJjLDBYstG@{ff?74stRyMJKpTSDvuof|K)GL/?7NDRCOB#RTG?qMS/?#K!MFCKLDBYK
AMz{JB#SsMJjP?#j KL/MFGMqK!MFG!KG"A*pTKL/?7N/KlpTStG!MJjKpTS/vKL/MzBYjf{}?#j"KL/MLHLxstBYK!K!MJjfS2pTSKLDpTGl{JB#GMqAM
?7SDRyES/MJMFCOK!?q{fL/MF{wOKL/MlMff/pTG!K!MFSt{ffMl?#PB}stBYKLPj?7 kK!c? {ff?7S[KB#pSDpTS/vq?7SDRyEMFpyKL/MJjWRTpTS/wHG(?#j)BYj{JG
CDpyjMF{ffK!MFCB+AB+EPj?7
kgQBstBYjKpTB#RTRTECtpyjMF{ffK!MFCstBYKLP j?7
kK!
? ofiBYtRyMOB#RG!?GL/?+A*GA*LDp{L
?#sMJjBYK!?#jGzBFEjMFuNtpyjMBs?7G!K=sDj?H{ffMFGGpTSDvG!K!MJspTSr?#jCDMJj}K!?MFSDGN/jMOKLDBYKzKL/MO{ff?#jjMFG!s?7SDCDpTS/v
S/MFpyv7Lu?#jpTS/v{ff?7SDDv7N/jBYKpy?7S?#P pG*B#S@h*`SiBYtRyM"I | ulg k/oB#SDb
C *Q lg kDojMJPMJj
K!?}KLDMlsDj?H{ffMFCDN/jMFG(KLDBYKWsDjMFG!MJj#M{ff?7SDCDpyKpy?7StG.klB#SDCqpTSOWMJtSDpyKpy?7SkYItjMFG!sMF{ffKpy#MFRTE#>@?#K!M"KLDBYK
?#K
L lg k/oB#SDC B | [lg kDo9KBYw#M)KpT4aM g o9pSKL/MWA;?#jfG!K;{JB#G!M#I/A@L/MJjM pGKL/MWSuNtlMJj
?#PDRTpTSDwGpSKL/M;GN/Dv#jBYstLlpTSDCDND{ffMFC.uEKL/M{LDB#pS{ff?74g s?7S/MFSuK ?#P rKLDBYKi{ff?7S[KB#pTStOG k`g R wQ ? lg kDoKBYw#MFG
KpT4M }g g oipTSKL/M(A?#jG!K{JB#G!M#IA*L/MJjM g pTGKL/MSNDMJj9?#P`BYj{JGpTSKL/MGN/tv#jBYstL4pTSDCtND{ffMFC"uE"KL/M
G!MJKW?#PC/MFG{ffMFStCDB#S[KGW?#]P kOpT
KLDBYKW?7SDRyE LtBF#M?7S/MstBYjMFSuKJ= F lg k/o*B#SD
C F lg k1
?#KLKBYw#MKpT4M }g g oWpTSKL/MA;?#jfG!K.{JB#G!M#I A@L/MJjM g pTG)KL/M4SNDlMJj)?#PMFC/v#MFG}gMFpyKL/MJj.BYjf{JG?#j
RTpTSDwGfo(pTSKLDM"GNDDv#jBYstLOpTSDCDND{ffMFCuEKL/M"SD?C/MFGWpTSOKL/M{LDB#pTS{ff?74s?7S/MFSuKW?#(P KLDBYK{ff?7S[KB#pTStwG k
K!?#v#MJKL/MJjWA*pyKLKL/MFpTjC/MFG{ffMFSDCDB#SuKGJ


Q

l K k

1 : #@8 =6 u< 5( 5

76
5 8m:]> 7:]=<:t7<6 5 6OC%@ 5 8;<8tT>#[:,7:H>
L/M@G!MFBYj{L4MJKLD?C}A;MWLDBF#M)C/MFG{ffjpT`MFC4}BFEM*BYsDsRTpyMFC4pTSq{ff?7ltpSDBYKpy?7SA@pyKLB#SuEG{ff?#jMWMFuNDpT[
B#RyMFSuKPQNDSD{ffKpy?7S gP ?#jqMffHB#4sRyMKL/M@!)I!WIO)B#StCr@MG{ff?#jpTSDvPNDSt{ffKpy?7SDG4BYjMG{ff?#jM
MFNDpyYB#RyMFS[KfofW^ SMFB#G!E,gtN/KzpTS/MJ~}{JpyMFSuKfo"ABFErK!?pTSuK!MJv#jBYK!M?7N/jqG!MFBYjf{L4MJKL/?HCrA*pTKLBG{ff?#jM
MFNDpyYB#RyMFS[KlPNDSt{ffKpy?7SA?7NDRTCM}B#GP ?7RRy?+A*GFlv7py#MFSB#S@h*
K!?MMJYB#RTNDBYK!MFC2IG!MFRyMF{ffKB#S[E
MffHK!MFSDGpy?7SBU ?#Pd B#SDC{ff?74stNDK!M ^ _g U FofM.{ff?7NDRCqB#RTG?NtG!M)?#KL/MJjlgQS/?7SH=MFNDpyYB#RyMFSuKfoG{ff?#jfpTS/v
PQNDSD{ffKpy?7SDGFIHB#RTKL/?7N/v7LKL/MG{ff?#jM.?#]P A?7NDRTCC/MJsMFSDC?7S KL/MlG!MFRyMF{ffK!MFC MffK!MFSDGpy?7S2
@?+AMJ#MJjFIRyMJK.NDG){ff?7SDGpTCDMJjKL/M{JB#G!M4?#PBC/MF{ff?74s?7GBYtRyM4G{ff?#jfpTS/vPNtSD{ffKpy?7S ^ KL/M4*?#/
KB#pTS/MFCluEB#CDCtpTS/v?#j'jMF4?+HpTS/vWB#SlBYj{P j?7KL/M{JN/jjMFSuK *
U{JB#S`MMJB#RTNtBYK!MFClE.4?HCDpyPEpTSDv
?7SDRyEq?7S/MlRy?H{JB#RG{ff?#jM#
_g U J
kP.`
Fdo H ^ _g U` Fo ^ j lg k KnmGo X lg kDo!o ^ j lg k KnmGo X lg k/Oo J DPo
^
_g Uo J
kP.`
Fdo H ^ _g U` Fo ^ j lg k KnmGo X lg kDo!o ^ j lg k KnmGo X lg kDo J DPo
^
]>

7

(< k

<?>ff



fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



?7SDCDpyKpT?7SDG
hi?7G!K=stj?{ffMFGGpTS/v



} * lg kDof
gloJH_

glk/oJH_

H
pTP gloaH

B Q glk/oJH_

o? gl K k/o
lg 2J
glk/oaH
glkDoJH
|

p

P
g


H


g


Q

[

!



K
/
L
F




u

l
g
/
k











F lg k/od HK 7

B
KL/MF
} * lg kDof lg ]
H_ B glk/o]H_H
K k/o
lg
)
Q
2

l
g


p

P
g
l
Q


H



[o
>@?7S/M
B Q lg kDoJH



KL/MF6
lg ! kD]o HT 7
F o? gl K k/o
} mGo? lg k/o
pTP glkDo
KL/MFS6wQ ? glk/o
F
Q)2gl K kDo
} p lg kDo
>@?7S/M
} * lg kDof } p lg kDof
K Kn
gl k
pyP lg lgQ k/ lg HkDo QB Q lg g kD Jo HIlg Hao HI Q lg Xo HI [oo pTPQ KL/ MFglS k/osaQ B | uglk/o
KL/MF
F lg k% ]o HT 7
iBYtRyMl;L/M?#sMJjBYK!?#jGJItKL/MFpyj{ff?7SDCDpTKpy?7SDG?#P9BYsDstRTp{JBYtpTRTpyK|E#IB#StCs`?7GK=sDj?H{ffMFGGpTS/v4jMFuNDpTjMF4MFSuKG


sMJjBYK!?#j

0WGpTS/vC/MF{ff?74s?7GBYtRyMOG{ff?#jpTS/vPNDSt{ffKpy?7SDGJIKL/Mstj?{ffMFGG?#P.G!MFRyMF{ffKpS/v/I(v7py#MFSB#S*h;*"I(B
jMJsDjMFG!MFS[KBYKpT#Mq*B#SDCKL/MFSxMJYB#RTNDBYKpS/vpyKl}BFEM}NDpyK!M}pTSDMJ~}{JpyMFSuKJIiGpSD{ffM4A;MqA;?7NtRTCLDB+#M
K!?jMF{ff?74stN/K!MqKL/MqRy?H{JB#RG{ff?#jMFGlP?#jB#RTRKL/MqS/?CDMFGlpTSDGK!MFB#Cx?#P(?7SDRyE?7S/MzRy?H{JB#RG{ff?#jM# *LDpTGPQB#{ffK
{JB#SBYw#MqBORyMFBYjSDpTSDv B#Ryv#?#jpyKLD KLDBYKGMFBYj{L/MFG"pTSKL/M}G!stB#{ffMq?#P(MFuNtpyB#RTMFSD{ffM}{JRTB#GGMFGl?#P(*)G
{ff?7SDGpC/MJjBYtRyEqGRy?+AMJj*KLtB#S B#S B#Ryv#?#jpTKLDKLDBYK*G!MFBYjf{L/MFGWpTSKL/M.G!sB#{ffM.?#Pi**)G"gKLtpTGpTGKL/M{JB#G!M
?#PKL/M.B#Ryv#?#jpTKLDsDj?#s?7G!MFCE LDpT{w#MJjpTS/v/I2kFm#m#7of
NDjG!MFBYj{fLzMJKL/?Cq{JB#SM*NDGMFCP?#j;C/MF{ff?74s?7GBYRyM*G{ff?#jpS/v.PQNDSD{ffKpy?7SDGG!?lKLDBYKJgk+opyKpTG;S/?#K
S/MF{ffMFGGBYjExK!?K!jB#SDG!P?#j KL/Mz@h*pS[K!?BO**"I9KL/M*h**{JB#SMqMJB#RTNtBYK!MFCCtpyjMF{ffKRyE#I
B#SDCg7o*KL/M4G{ff?#jM"?#P;B#SuEOS/MFpTv7L[?#jpTSDv}*h;*{JB#SM?#DKB#pS/MFCEO{ff?7stN/KpTS/vzBYK4?7G!K)KA?
Ry?H{JB#RG{ff?#jMFGFWRTR2KL/MB#C/B#SuKBYv#MFGW?#PKL/MlG!MFBYj{fLOMJKL/?CtG(?7S KL/MG!stB#{ffM.?#P9*)G)BYjMlKL/MJjMJP?#jM
jMJKB#pTSDMFC2I/tN/KB44?#jM.jMFCDND{ffMFCB#SDCj?#tNDGKG!MFBYj{LOG!stB#{ffMlpG(NDG!MFC2
MJP?#jM@KLDMFG!MWB#GG!MJjKpy?7SDGBYjM@sDj?+#MFCIRyMJKNDG;MffHB#pS/M@B#SqMffHB#stRyM#?7SDGpC/MJjKL/M)*h;*
pTSzpyv7N/jMkF"B#SDCzKL/M)KL/jMJM)S/MFpyv7Lu`?#jfpTS/v{ff?7SDDv7N/jBYKpy?7StGsDj?CDNt{ffMFC}EKL/MpTSD{JRNDGpy?7S4?#PiB#SzMFC/v#M
MJKAMJMF
B#SD1
C k`I ( - B#SDy
C 0 gQB#RTG!?}CtpTG!stRTB+E#MFCpTSpyv7N/jMkF7of

b

x

b
c




x

b
c





x

b
c




x

c










G

G1

G2

G3

ipTv7N/jMkF;WS @h*f B#SDCKLDjMJMlS/MFpyv7Lu?#jpTS/v{ff?7S/Dv7NDjBYKpy?7SDGw ( - B#SDC
2

0

fi X ttu
LDMG{ff?#jM?#P@MFB#{fL?#PWKL/MFG!M *h;*)GqpTG"MFuNDB#RK!?KLDM G{ff?#jM?#P@B#SuE?#P@KL/MFpTj"MffHK!MFSDGpT?7SDGJ
pyv7N/jMkFCDpTG!stRBFEHG?7S/MMffK!MFStGpy?7SP?#jMFB#{LS/MFpyv7Lu?#jpTS/v{ff?7S/Dv7NDjBYKpy?7S2
b

b


c

x

b





c

x





c

x









H1

H2

H3

pyv7N/jMkF9HK!MFSDGpy?7StGZU
M"{JB#SKL/MJjMJP?#jM.AjfpyK!M#
Av,l) ,l

AsCl) JCl

AsCl) JCl




( U
-

B#SDC1U 0 ?#PiKL/Ml@h*G ( - B#SDC 0 pTSpyv/'kF

AAfifi]]77tt

RR?t
ffD
?]7?e%

Afie%
R[?FJD
?]7



/?#j@MFB#{LOMffK!MFStGpy?7S 2i?#P9B#S[ES/MFpTv7L[?#jpTSDv"{ff?7S/tv7N/jBYKpy?7S J|ItpTKpTG(B#RyABFEHGs?7GGpyRyM@K!?}tSDC
B#S MffHK!MFSDGpT?7S i?#P9KL/Ml{JN/jjMFS[K@*h** GND{fLKLDBYK*KLDMlG{ff?#jMFG@?#P 29B#SDC ?7SDRyECDpMJj


U

Be+D

Be+D

Be+D


4444FFffffDD


44Fff



AAFFeett


AFe



U





z

dU

U

pTS?7S/MRy?{JB#R2G{ff?#jMqgQpyv7N/jMqk+CDpTG!sRTBFEHGKL/MFG!M.MffHK!MFSDGpy?7StGfofMl{JB#SKL/MFSAjpTK!M#

J hhee%%tt


l h e%t










C



C

44[[44JJHH


4[4J H



b

x

]]77DD


e+



b
c



AAfifitt


Afi




x

RReY+Dt

A?]7+
ReD
A7


b
c






x

c








H G1

H G2

H G3

ipTv7N/jMk+u;*L/jMJM.CDpMJjMFSuKMffK!MFSDGpy?7SDGZU ( I,U - B#StCU 0 ?#PKL/M.*h;*zpTSpyv/ kF
iBYwpS/vpTSuK!?}B#{J{ff?7NDSuKKL/M.sDjMJpy?7NtGMffsDjMFGGpy?7SDGFIAM.?#DKB#pS2
;g (
Fo H ^ ;g Fo ^ j lg k K $7o ^ j glk K
^


fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



g; - Fo H ^ g;Fo ^ j glk K ^ j glk K J Po
g; 0 Fo H ^ g;Fo ^ j glk K ^ j glk K J Po
^
LDMJjMJP ?#jM#IKL/MG{ff?#jM4?#PB#SuES/MFpTv7L[?#jpTSDvq{ff?7S/Dv7NDjBYKpy?7SB+EOM?#DKB#pTS/MFCPj?7 KL/MG{ff?#jM
?#P E{ff?74stN/KpTSDv?7SDRyEKA?ORy?H{JB#RG{ff?#jMFGFz>@?#K!M}KLDBYKG!?74M}?#PKL/MFGM}Ry?H{JB#RG{ff?#jMFGBFExLDB+#M
B#RyjMFB#CDE MJMFS{ff?74stN/K!MFCBYKsDjMJHpy?7NDGWpyK!MJjBYKpT?7SDG)?#PKL/M4G!MFBYjf{LsDj?H{ffMFGGJWP?#jMffHB#4sRyM#I ^ j glk K $7o
LDB#CK!?MqNDG!MFCK!?G{ff?#jMKL/MpTSDpTKpTB#RMF4stKE@h*"I;B#SDCMFpTKL/MJj ^Tj lg k K o?#j ^Tj lg k K o"{ff?7NDRTC
LDB+#MlMJMFS{ff?74stN/K!MFC A*L/MFSKL/M.RpTS/cw k` ?#Zj k AB#G@pTSDG!MJjK!MFCpS[K!?4KL/MG!K!jND{ffKN/jM#
GHABTz_ ZJG
fZVY
^ ;Z{w%VY^
ZVY^tb
X ;Z %c[Ja=V#] ^`ZffXVf7`XY]^ucY^Z
c}a/Zcf/ZJdV#a=c#d\[Zff\ffJd]=Z]^ VuffTZ a=
c % _ ZJa ^ ZVO\fffcYdZ nZ Fl] V#yZJ^taWV#^x[Zc /@Hc\JV[ffTZ
^`FaQ]cY^
V uO aHZcf/ZJdV#a=c#d"] \
Q)2lg K k/olaHZff^
;g `
Fdo H ^ ;g ` Fo ^ j lg k K $7o ^ j lg k K J OPo
^
^

ebO aHZcf/ZJdV#a=c#d"] \ ? g




g; Fo]H

^

bO aHZcf/ZJdV#a=c#d"] \

/olaHZJ^
g;Fo

l K k

g

^

^ j

glk

o"aHZJ^
;g `FodH
;g Fo{
^

^

uO aHZcf/ZJdV#a=c#d"] \
)2g

g

KnmGo lk =

ZebO aHZcf/ZJdV#a=c#d"] \ ? g


g; FodH

glk



K J P

^Tj

glk

K J Kn P

^ j

glk K $7o

l K k

Q

^

hYi

^Tj

DoaHZff^
g; `Fdo H ^ g;`Fo

ZF

^

glk

^ j



J OP

K Kn
l k



ZF

g Do!o

KnmGo? lk

/oaHZJ^
g;`Fo

^ j

glk



K J DP

l K k
^

^ j

glk

g Do!o

KnmGo? lk

^ j

glk



g /o)

KnmGo? lk



J DP

GL

gk+oipTjG!KJI[AM@GLDB#RTR/sDj?+#MWKLDBYKAM@{JB#Sz{ff?7SDG!K!jNt{ffK;B#SqMffK!MFSDGpy?7ScU ?#P B#SDCqB#S/?#KL/MJjMffK!MFSDGpy?7S
?#]P ItGND{fLKLDBY K UB#SD
C U`Ctp`MJj@pTS?7SDRyEq?7S/MlBYj{}gKLtpTG(BYj{MFpTS/v k/of
?7SDGpTCDMJjKL/M){JB#G!MFG.gQB[ofI g`ofIHB#SDCgQ{+ofIHA*LDpT{fLq{ff?#jjMFG!s?7SDCK!?KL/M)B#CDCDpyKpT?7S?#P B#SzMFC/v#MWMJKAMJMFS
B#SD%
C k`ipTS4{JB#GM"gQB[ofI H J !kP@B#SDCRTMJ]K U MB#SMffHK!MFSDGpy?7S?#DP KLDBYK{ff?7SuKB#pTSDGKLDM*BYj{

k[pS{JB#G!MlgofI#A*L/MJjZ
*,H J k,P7IuB#SDCpTS{JB#GMlgQ{+ofI7A*L/MJjZM *,H;g J k` Po J

k5
P7IHRyMJ
K U `M@B#S[E4MffHK!MFSDGpy?7S}?#OP gA*LDpT{fLA*pRTRH{ff?7S[KB#pTSqKL/MWBYjff{ k/ofS}B#RTRDKL/jMJM@{JB#GMFGJI
RyMJZK U HU J kP7MGLDB#RTRsDj?%#M.KLDBY K UpTG(B#SMffK!MFSDGpy?7S?#]P "
MFpyjf{ffG!?7KJStIDCDpyKRyE#pTIHGpyP?#}pT?7ND G(} KLDBY*K gQpTSzB#MFSDpyK1C L/MJUj({JLDB#BFG!#M MlKL/}MlGB#H4I G! w#MFRykDMJofK!IH?7S2KL/ MFS B}B} WffG U pTGB#S
MffHK!MFSDGpy?7S?#dP *QIKLDMFS 1}} U IDB#SDCKLtpTGpT4stRTpTMFGKLDBYK 1}} ULDMJjMJP ?#jM#IHB#RRKLDM.BYj{JG
U



fi X ttu
pT
BYjM.B#RTG!?BYj{JGpS1U*LDpTGjMFGNDRTKB#RG!?MFSDGN/jMFGKLtBYKMJ#MJjELHLstBYK!K!MJjSpTS pTG(B#RTG?B#S LHL
stBYK!K!MJjSpTSU
ofLDI2pyKjfL/CDMFRyE#S ypyP f } UpTG" B# SSDLH{ffMLBYstv7BYB#K!pTS2K!MJI2jB#SGpTUS U pG@gQB#pTSxSMffMFHpyKK!LDMFMJSDj"Gpy{J?7B#SOG!M ?#P( *\QI`A; M4 {JB#S G!HMJI M" KLD BYK
kB
B
8} IDB#SDC KL/MFS B
8} "?/
B#SD
C U LDB+#MlKL/M.GB#4MlLHLsBYK!K!MJjSDGJ
UpTGiKL/MJjMJP?#jMB#SMffK!MFStGpy?7S?#D
P "I[B#{J{ff?#jCDpS/v)K!?.@MJSDpyKpy?7S49>*?#K!M(KLtBYK G H

k mGo X g ]
oH
mGo
G


G



H X( lg k/o J DP7
X lg kD]
X( g oB#StC
{ff?7SDGpTC/MJj {JB#GMFGgQCozB#SDCgM%ofIA@LDpT{L_{ff?#jjMFG!s?7SDCK!?rKL/MxC/MFRTMJKpy?7S?#P"B#SMFC/v#M
MJKONDGS/?+A
MJKAMJMFy
B#St
C kgMFpTKL/MJjWBzRTpTSDwq?#jB#SBYj{YIjMFG!sMF{ffKpy#MFRyEDof(pTS{JB#G!M gQCofIRyMJK UMB#SOMffK!MFSDGpy?7S
?#{P {ff?7SuKB#pTSDpS/v4KL/MlBYjx{ k`tpTS {JB#G!MgM%ofIRyMJwK U MlB#SuEMffK!MFStGpy?7S ?#{P "S?#KL{JB#G!MFGJI`RyMJK
U!HUp J
kP7MlA*pRTRtstj?+#MKLDBYZ
K U2pTG(B#SMffK!MFStGpy?7S?#]P *Q
MFpyjf{ffG!?7KJStIDCDpyKRyE#pTI G(py{JP RyMF BYj@KLDBY*K } * B#gQSDS/1C ?#K!U M4 KLDLDBFBY#K KL/M.G B#4HI G!w# MFRyMJkDK!?7ofI S2K L/MFS } WGG UpTGB#S
MffHK!MFSDGpy?7S?#P "ItKL/MFS 1} UIB#StC KL/MJjMJP?#jM } U *?/I`B#RTR2KL/M"BYj{JG*p
BYjM"B#RTG!?
BYj{JG@pT1
U ;?#jMJ?+#MJj+ItMJ#MJjELHLsBYK!K!MJjSpT
pG(B#RTG!?B#SL/LstBYK!K!MJjSp1
U
LDpyjfCDRyE#I pyP pTGB#SLHLstBYK!K!MJjSpT
U gQB#SDCA;MqwSD?+AKLDBYK H

ofI'KLDMFS
} U4WG

ky
G UpGB#SMffK!MFStGpy?7S?#ZP "I KL/MFS } "
L/MJjMJP ?#jM#I } gKL/M.jMF4?%B#R'?#PKL/MlBYjx{ k{JB#SDS/?#K*CDMFG!K!j?+E B#SuELHL sBYK!K!MJjS
A*L/MJjM kpTGS/?#KpS[#?7Ry#MFC`of?/I B#SD
C U LDBF#MKL/M.GB#4MLHLstBYK!K!MJjStGJ
SxKLDpGAB+E#dI UpTGlB#SxMffHK!MFSDGpy?7S?#wP * ?#jMJ?+#MJj+I9A;Mz{JB#SG!MJMqKLDBYK G Hf

k mGo X g G
H
mGo
G


G



J
H X lg kDo DP7
X g oB#SDC
Xr lg kD]
g7o*L/MlG{ff?#jMFG*?#{P B#SDy
C *BYjMlKL/M"GB#4MB#G@KL/MlG{ff?#jMFG*?#]P UB#St
C U2jMFG!sMF{ffKpy#MFRyE#IGpTSD{ffM ^ pTG
G{ff?#jMlMFuNDpTB#RyMFSuKJ?#jMJ?+#MJjFIB#G ^ pTGC/MF{ff?74s?7GBYRyM#I/A;M{JB#SAjpyK!M
;g
F]o H ^ _g U ` Fdo HSu ^ j g KnmGo Xr g o!]o HSb4 g ^ j g KnmGo Xr g o!o ^ j lg k KnmGo X( lg k/o!o H
^
6R g ^ j g KnmGo X g o!bo ^ j g lg k KnKnmGmGoo X glg k/o!o!{o@o ^ j lglg kk KnKnmGmGoo X lglg kDkDo!o!oo ^ j lglg kk KnKnmGmGoo X lglg k/k/o!o!oo HH
X
X
X(
^ j
^ j lg k KnmGo
^ j lg k KnmGo
_g U

F@


oH
X lg kDo!o
X( lg k/o!
^
^T j
;g

F{

lg k KnmGo X lg kDo!o^ j
lg k KnmGo Xr lg kDo!o
^
^ j
^ j
guo
MJK*NDGS/?%A,{ff?7SDGpC/MJj(KL/M.D#MCDpMJjMFS[K({JB#G!MFGF
gQB[oSKLtpTG*{JB#G!M#I`AMlwHS/?+AP j?7'BYRyM4KLtBYK mGo? lg k/o H$*?#jMJ?%#MJjFI mGo lg k/(o H$OgMF{JB#NDG!M
AMBYjM4pTSDG!MJjKpS/vqBRTpS/w/oB#SDC mGo X( lg k/o Hq
$gMF{JB#NDG!5M U ~ mxpTG)o B#Slg MffkDHMo K!~MFHSDGpykY?7IiSp?#M#ffP mG KLDBYlg K.kD*o {ff?7H S[KJB#OpSDP7G
KL/MBYj5{ kDofL/MFS2I2Pj?7 hj?#s?7GpyKpy?7SzAM4?#DKB#pT
Xr
Xr
?#jMJ?+#MJjFI mGo X lg kD]o H mGo Xr lg k/)o J DPHS$?/It;t guoMF{ff?74MFG
;g
F]o H ^ ;g ` Fo ^ j lg k K $7o ^ j lg k K J OPo
^
g`oDj?7iBYtRyMlAM.v#MJK mxo lg kDXo HK

?#j mxo lg ao HK
$


$
G




G


P
lg kDa
H

ItPj?7hj?#s?7GpyKpy?7S A;M?#DKB#pTS X lg k/o H mGo? lg k/of?#jMJ?+#MJjFI mGo Xr lg k/o H
$
mGo
J OPH mGo? lg k/Do J DP7
X lg kDD
x

P lg kDo H$KL/MFS mGo lg k/o H J DPgMF{JB#NDGM A;MBYjMB#CDCtpTS/vKL/MBYj
{ kDof/j?7
G


x


x




hj?#s`?7GpyKpy?7SA;M"?#DKB#pTS Xr lg kD(o H lg kDo H J OPH
lg kDO
J OP7@?#jMJ?+#MJjFI mxo X lg k/(o H
mGo
J DPHK$H mGo? lg kDof
X lg k/
2M

fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $



SMFpyKL/MJj@{JB#G!M#It'guoMF{ff?74MFG
;g `
Fdo H ^ ;g Fo@ ^ j glk KnmGo? glk/o!o ^ j glk KnmGo? glk/oD J OPo
^
gQ{+oS.KLtpTG{JB#G!M#I mGo? lg k/{o HK$B#SDC mGo glk/o{H J Kn P79/j?7hj?#s?7GpyKpy?7S.A;M;?#DKB#pTS mxo X glkDodH
J Kn P7?#jMJ?+#MJjFI mGo X lg kD]
H mGo Xr lg kDo J DPH J P7;LDMFS2ID guoMF{ff?74MFG
;g
F]o H ^ ;g ` Fo ^ j glk K J Poi ^ j glk K J Kn Po
^
gQCoiWG mGo? lg kD]o HK$)B#St%C UpTGB#S4MffHK!MFSDGpT?7S?#=P {ff?7SuKB#pTSDpS/v)KL/MBYj{ kI7Pj?7hj?#s?7GpyKpy?7S4
AMv#MJK mxo X lg k/]o H J DP7 ?#jMJ?+#MJjFI mGo Xr lg kD]o H mxo X lg k/o J DPxHK$S"KLDpTGi{JB#G!M;t/guo'MF{ff?74MFG
;g
F]o H ^ ;g ` Fo ^ j lg k K J DPo' ^ j lg k K $7o
^
gM%o@SKLDpTG){JB#G!M#I'B#G mxo lg kD2o Hq

hj?#s?7GpTKpy?7SB#GG!MJjKG)KLDBYK mxo X lg k/*o H mGo lg k/of?#jMJ?+#MJj+I
$
mGo
G


G



H X lg kDo J DPH lg kDo J OP7L/MJjMJP?#jM#It;t guo(MF{ff?74MFG
X lg k/d
;g `
Fdo H ^ ;g F@o ^Tj lg k KnmGo lg kDo!o ^j lg k Knmxo lg kDo J DPo
^



]

Bt 2

qlffB



#.$

W GA;MLtBF#M}B#RyjMFB#C/EO4MFSuKpy?7S/MFCIKL/MJjMBYjMGMJ#MJjB#R9A?#jwGCDMJ#?#K!MFCxK!? RyMFBYjStpTS/vBFE#MFGpTB#SS/MJK
A?#jwGFI#A*pyKLDpTSlKL/M(G{ff?#jM%)GMFBYj{L4BYsDstj?7B#{L2I[A*LDpT{fLNDGM;KL/M(G!sB#{ffM?#P{ff?74stRyMJK!MFC4h;*)G9K!?{JBYjjE
?7N/KKL/M.G!MFBYjf{LsDj?H{ffMFGGJ*L/MJjMpTGB4GRTpyv7LuKCDpMJjMFSD{ffM)MJKAMJMFSKL/M?#sMJjBYK!?#jG({ff?7SDGpC/MJjMFCpTSzKL/M
CDpMJjMFSuKA?#jwGF;KL/MB#CDCDpyKpy?7SB#SDCC/MFRTMJKpy?7S ?#PMFC/v#MFGWpTG*{ff?7StGpTC/MJjMFC uE OB#CDpyv7B#SOMJK@B#R'gkFm#m#7ofI
A*pyKLtpTSBBYjw#?+LDB#pSx ?7SuK!MBYjfRy?sDj?H{ffMFGGJIA@LDpT{LB#RTG!?sMJjP?#jG.?7S[K!MBYjRy? GB#stRTpTS/v
Pj?7KLDMWG!sB#{ffMW?#P KL/M@?#jfC/MJjpTS/v7G?#PKL/MWBYjfpTBYtRyMFG;{ff?74stBYKpytRTM*A*pyKLqKL/M){JN/jjMFSuK(h*"D;C/v#M
B#CDCDpTKpy?7SqB#StCC/MFRyMJKpy?7SpTGB#RTG!?4NDGMFCqEHstpyjK!MFGB#SDC MJMJwgkFm#m#7ofItN/KA*pyKLDpTSzB"v#jMJMFC/EqsDj?H{ffMFGG
KLDBYKDjfG!K)v#j?+A*G.KL/MG!K!jND{ffKNDjMuEB#CDCDpTS/vzMFC/v#MFG.B#StCKL/MFSKLDpTSDG)pyK)ECDMFRyMJKpTS/vzMFC/v#MFGJ4WCDCDp
Kpy?7SDB#R`?#sMJjBYK!?#jGBYjM{ff?7SDGpTC/MJjMFCquELDpT{w#MJjpTS/vgkFm#m#7ofIpTSt{JRTNDCDpTSDv.BYj{WjMJ#MJjGB#RB#SDC{ffjMFBYKpy?7S?#P
uG!K!jND{ffKN/jMFGJ
WRTR'KL/MFG!M44MJKL/?HCDGW4?+#M4KL/j?7N/v7LKLDMGstB#{ffM?#P{ff?74stRyMJK!MFCh;*)G.pTSOKL/M"P ?7RRy?+A*pS/v}ABFE`
v7py#MFSKLDMl{JN/jjMFSuK@h;*
"IBYP K!MJjWG!MFRyMF{ffKpTS/vB#S ?#s`MJjfBYK!?#jFItBYsDstRTEpTSDv"pyK(K!? B#SDC?#DKB#pSDpTS/v4B
S/MFpyv7Lu?#jpTS/v"h*f
*I/KL/MJEzv#MFS/MJjBYK!MlB fcY^/\f] \aZJ^ta([Z P7aZJ^/\f]cYc^ U`?#dP *9gQB4*`MFRT?7S/v7pTS/v"K!?
KL/M)MFNDpyYB#RyMFSD{ffM){JRTB#GGjMJsDjMFGMFS[K!MFCzE}KL/M)h*lofItpyP?7S/MWMff/pTG!KGJ9PKLDpTGpTGKL/M{JB#G!Mg?#KL/MJjA@pTG!M
*7pTG S/?#K'B(YB#RTpTCl{ff?7S/Dv7N/jBYKpT?7SofI%KLDMFu
*7pTGMJB#RTNtBYK!MFC.E){ff?7stN/KpTS/v*KL/MG{ff?#jM;?#!P UI _g U` Fof
L/M"{ff?74stRyMJK!MFCh**jMJsDjMFG!MFSuKBYKpy?7SO?#(P pGKL/MFSOjMF{ff?+#MJjMFCP j?7pyKGW{ff?7SDGpTGK!MFS[K@^ MffK!MFSDGpy?7S
U
LDM9sDj?H{ffMFGG2?#P/{L/MF{wpS/vKL/MMff/pTG!K!MFSt{ffM9?#PHB*{ff?7SDGpTG!K!MFSuKMffHK!MFSDGpy?7SlB#SDCv#MFS/MJjBYKpS/vpyKpTG{JBYjjpyMFC
?7N/KA@pyKL4B)sDj?H{ffMFCDN/jM{JB#RRyMFcC {w%a=c# w%gQW?#j_'BYjfGpIDkFm#m#7ofIHA*LDpT{fLjNDSDG9pSKpT4M lg Qao
pTSKLDMlA?#jG!K@{JB#GM#IA*LDMJjM "C/MFS/?#K!MFG@KL/MSNDMJj?#P9MFC/v#MFGWpTSKL/M"h*"WS/?#KL/MJjWsDj?H{ffMFCDN/jM#I
{JB#RTRyMF
C %a=cY; {w%I2pTG.pTSu#?#w#MFCpSx?#jC/MJjK!??#DKB#pSxKL/Mz{ff?74stRyMJK!MFCh*jMJstjMFG!MFSuKBYKpy?7S
?#P"KL/MxS/MJA YB#RTpTC{ff?7S/Dv7NDjBYKpy?7S2L/MJjMxBYjMxCDpMJjMFS[KpTstRyMF4MFSuKBYKpy?7SDG?#P*@=K!?Yh;*
gQWSDC/MJjGG?7SMJK;B#R=yIkFm#m7uLDp{w#MJjpTSDv/ItkFm#m#t MJMJw`I2kFm#m#/h'MFBYjfR`9MJjBHIkFm#mY[of;/?#jMffHB#stRyM#I
KL/MWKpT4M){ff?74stRyMff/pyK|E4?#P KL/M)B#Ryv#?#jpyKLtsDj?#s`?7GMFCEzLDpT{w#MJjpTS/vgkFm#m#7opTsG g o9?7SzKL/M)BF#MJjBYv#M
B#SD
C }lg Qc%opSKL/M.A?#jG!K*{JB#G!M#
NDjGMFBYj{L4MJKLD?CC/?MFG(S/?#K(S/MJMFCzK!?NDG!M)B#S[Eq?#P KL/MFGMWK|A;?}sDj?H{ffMFCDN/jMFGJpTSz?#jC/MJjK!?4{LDMF{w
KL/M4YB#RTpTCDpTKE ?#PBS/MFpyv7Lu?#jpTS/vz{ff?7S/Dv7N/jBYKpT?7S?#PB#Sx@h* "I'pTK)pG)?7SDRyES/MF{ffMFGGBYjE#I'pSG!?74M

%

2

fi X ttu
{JB#G!MFGJI;K!?s`MJjP ?#jBK!MFG!KK!?xC/MJK!MF{ffK4MFpyKL/MJj4B#SNDSDCtpyjMF{ffK!MFCstBYKL?#jBOsBYjKpTB#RTRyECDpTjMF{ffK!MFCstBYKL
MJKAMJMFSK|A;?S/?HC/MFG*pSygQpT4stRyMFMFS[K!MFCuEsDj?H{ffMFCDN/jMFGa g=o(B#SDCF g=opTSMF{ffKpy?7S /7of
KL/M?#KL/MJjLtB#SDC2IY?7SD{ffM(KL/M(G!MFBYj{fL4sDj?H{ffMFGG9LDB#GMffHstRy?#jMFCKLDMSDMFpyv7L[?#jLD?u?HCl?#P=B#SDCC/MJK!MJj}pTS/MFC
KL/M.MFG!K(S/MFpTv7L[?#jpTSDv{ff?7SDDv7N/jBYKpy?7
*2pTG(S/?#KB#RyABFEHG*B#SO*h**"IB#SDCAMl"NDG!K(v#MFS/MJjfBYK!M
pyKG"*h;*jMJsDjMFG!MFS[KBYKpT?7S2*LDpTG.v#MFSDMJjBYKpy?7SsDj?H{ffMFCDN/jMzpTG"B#RTG!?#MJjEGpTstRyM#4pyK{ff?7StGpTG!KG"pTS
DjpS/v/IGKBYjKpTS/vPj?7 BGpTS/v7RyM)S/?HC/M kI/B4{JB#G{JB#CDMFCsDj?H{ffMFGGKLDBYK(MFpyKLDMJjCDpyjMF{ffKGRTpTSDwGBFABFEPj?7
k?#j4NDSDCDpTjMF{ffKGlBYj{JGgQpT4sRyMF4MFSuK!MFCEsDj?H{ffMFCDN/jMFG B | [g=olB#SDw
C wQ ? g=olpTSMF{ffKpy?7S/7of
>@?#K!MKLDBYK4B#RTRKLDMFG!MsDj?H{ffMFCDN/jMFG"NDG!MFCEx?7N/j4G!MFBYj{fL4MJKL/?HCBYjMRTMFGG"KpT4Mff{ff?7SDGNtpTS/vOKLDB#S
h**@=K!?Y*B#SDC*@=K!?Yh**"
?#jMpT4s?#jKB#SuKRyE#I?7N/jG!MFBYj{fLMJKL/?C{JB#SKBYw#MB#C/B#SuKBYv#M?#P.KL/MC/MF{ff?74s?7GBYpTRTpyK|E?#P
B#SuErG{ff?#jpTSDvxPNtSD{ffKpy?7SDGJIB#SDCMFB#{L*h**gMff/{ffMJsDKzKL/MOpSDpyKpTB#R?7S/M%o{JB#SrM MJYB#RTNDBYK!MFCuE
{ff?74stNDKpTS/v?7SDRTEzK|A;?Ry?H{JB#R G{ff?#jMFGJ*@?+AMJ#MJjFI2KL/M"4MJKL/?HCDGtB#GMFC?7S{ff?74stRyMJK!MFCh**)G)S/MJMFC
K!?zjMF{ff?74stN/K!M"B#RTRKLDMRy?H{JB#R G{ff?#jMFGJI2B#RyKL/?7N/v7LKL/MB#Ryv#?#jfpyKLDstj?#s?7G!MFC ENtS[K!MFSDB#NB#SDCB#N
gY##[ofI A@LDpT{L?#sMJjBYK!MFG)?7S{ff?74sRyMJK!MFCh*)GB#SDCNDG!MFGWKL/jMJM4pTStG!MJjKpy?7SO?#sMJjBYK!?#jGgP?#j)BYjf{JGJI
RTpTSDwGWB#SDCuG!K!jND{ffKN/jMFGfo@pTGB#RTG!?BYtRyMK!? G{ff?#jMB#S[ES/MFpyv7Lu?#jpTS/vz{ff?7S/Dv7N/jBYKpT?7SNDGpTS/vzKA?Ry?H{JB#R
G{ff?#jMFGFtL/?+AMJ#MJjFIKL/M.YB#RTpTCDpyK|E}{ff?7SDCDpTKpy?7SDG?#P9G!?74M.?#PiKL/MFG!Ml?#s`MJjfBYK!?#jG*BYjM.SD?#K*{ff?#jjMF{ffKJ
pTSDB#RRyE#ILtpT{w#MJjpS/vgY#77o zC/MFG{ffjpT`MFGlB#SB#Ryv#?#jpTKLD KLDBYKG!MFBYj{fL/MFG"pTSxKL/MzG!stB#{ffMq?#P{ff?7
stRyMJK!MFCh;*)GlB#StCpGB#RTG!?BYtRyM"K!?MJB#RNDBYK!M{ff?7S/Dv7N/jfBYKpy?7SDGWuE{ff?74stN/KpS/vq?7StRyEgQN/sK!?P?7N/jo
Ry?H{JB#R'G{ff?#jMFGJ*K)NDG!MFGWGp?#sMJjBYK!?#jGJI2RTpTSDwzB#SDCBYj{"B#CDCDpyKpT?7S2ItRTpTSDwB#StCOBYj{"C/MFRyMJKpT?7S2I{ffjMFBYKpT?7SO?#P
uG!K!jND{ffKN/jMFG(uECDpTjMF{ffKpTS/vKA?B#RyjMFB#C/EzMffHpG!KpTS/vRTpS/wGFIHB#StCjMJ#MJjGB#R?#PBYjf{JGJ;WRTR2KL/Ml?#s`MJjfBYK!?#jG
{JB#SMMJYB#RTNDBYK!MFCNtGpTS/vqKA? Ry?{JB#RG{ff?#jMFGJI2MffH{ffMJstKjMJ#MJjGB#R9B#SDC{ffjMFBYKpT?7S?#PuG!K!jND{ffKN/jMFGJIKLDBYK
jMFNDpyjM(P?7N/jRy?{JB#RG{ff?#jMFGJ*L/MYB#RTpTCDpyK|E"{ff?7StCDpyKpy?7SDG?#PKL/M*?#sMJjBYK!?#jGBYjM@MFG!KBYtRTpTGL/MFC4MFGG!MFSuKpTB#RTRTE
pTSK!MJj}G?#PKA?{ff?7SDCDpyKpT?7SDGJgk+o)KL/MBYG!MFSD{ffM?#PG!MFpCtpyjMF{ffK!MFC?#jNtSDCDpyjMF{ffK!MFCstBYKLtGMJKAMJMFS
KA?}S/?HC/MFG(KLtBYKC/?S/?#KstB#GG(KL/j?7N/v7L{ffMJjKB#pTS G!MJK?#PS/?HC/MFGJhI ItB#StCxg7oKL/M.PQB#{ffKKLDBYK*B4{ffMJjKB#pTS
G!MJK?#P2S/?HC/MFGP?#jGBl{JRTpTN/M#i'pTS/w"pTSDG!MJjKpT?7S"B#StC{ffjMFBYKpy?7S}?#PuG!K!jND{ffKNDjMFGS/MJMFCKL/M(DjG!K9K|EusM?#P
{ff?7SDCDpTKpy?7S2IuRpTS/w4B#SDCBYj{WC/MFRyMJKpy?7SzS/MJMFCzKL/M)G!MF{ff?7SDCz?7S/M#IHA*L/MJjMFB#GBYj{WpTSDGMJjKpy?7S}B#StCzBYjf{*jMJ#MJjfGB#R
jMFNDpyjM?#KLO{ff?7SDCtpyKpy?7SDGJWL/H
stBYKL qB#RTpCDpyKE {ff?7StCDpyKpy?7SDG*KBYw#M4KpT42M ng ~Z~
o*pSKL/M"A?#jG!K
{JB#G!M#I`B#SDCKL/`
!{JRTpuN/M 4{ff?7StCDpyKpy?7SDGKBYw#MKpT4ZM }ng ~Z~ ofItB#RTG!?pSKL/M.A?#jG!K*{JB#G!M#;LDpTG(B#Ryv#?#jfpyKLD
B#RTG!?4jMFuNDpTjMFGKL/uM %a=cY; %B#SD
C 5a=cY; {w%sDj?H{ffMFCDN/jMFGK!?MNDG!MFC
?/IB#RyKLD?7N/v7L_KL/MxYB#RTpTCtpyKE{ff?7StCDpyKpy?7SDG?#PKL/M?#sMJjBYK!?#jfGpTS,LtpT{w#MJjpS/v GB#Ryv#?#jpyKLt B#SDC
KL/MFpyjzs?7G!K!sDj?H{ffMFGGpS/vBYjMG!?7MJA*LDBYK4?#jM{ff?74stRyMffKLDB#S?7N/jGJIKLDMB#CDB#SuKBYv#MxpTGqKLDBYKKLDpTG
B#Ryv#?#jpTKLDC/?MFGS/?#K*LtBF#MlB#SuECDN/stRTp{JBYK!MWjMJsDjMFG!MFSuKBYKpy?7SDG*?#PiKLDMMFuNDpTB#RyMFSt{ffM.{JRTB#GG!MFGJ;LDMJKL/MJj
KL/M{ff?74stN/KBYKpT?7SDB#RH{ff?7G!K?#P4?%#MFG9pTSlKLDM(h*G!sB#{ffM{JB#S{ff?74sMFSDGBYK!MP?#jKL/MRTBYjv#MJj9SuNtlMJj
?#P*h;*)G)gQB#SDCKLDM@RTBYjv#MJjSuNtlMJj?#PRy?H{JB#RDG{ff?#jMFGK!?`M@{ff?74stN/K!MFCo9pTGB.}BYK!K!MJj?#PMF4spyjpT{JB#R
MJYB#RTNDBYKpy?7S2I'KLDBYKlA@pTRTRs?7GGpyRyEC/MJsMFSDC?7SKL/
!G!sBYjG!MFS/MFGG ?#PKL/MqG!sMF{Jpy{4C/?7B#pTSstj?#tRyMF
{ff?7SDGpC/MJjMFC2
1 7#{8ff>$[<> 5 =< 1 >Y: <
SKLDpTGGMF{ffKpy?7S.AMGLDB#RR#C/MFG{ffjpyM9KL/MMffsMJjpTMFS[KG2{JBYjjfpyMFC?7N/K'A*pyKL)?7N/j B#RTv#?#jpyKLDIKL/M?#tKB#pTS/MFC
jMFGNtRyKGJIuB#StC}Bl{ff?7stBYjBYKpy#M)G!KNDC/EA*pTKL4?#KL/MJjB#Ryv#?#jpyKLD}GP?#j;RyMFBYjStpTS/vlBFE#MFGpTB#SS/MJKA?#jwHGJ9M
LDB+#MG!MFRyMF{ffK!MFCSDpTS/MCDpMJjMFSuK'sDj?#tRyMFG'K!?)K!MFG!K?7N/j9B#Ryv#?#jpyKLD IYB#RR[?#PDA@LDpT{L?7SDRyE{ff?7S[KB#pTSCDpG{ffjMJK!M
YBYjpTBYtRyMFGFiWRTBYjgQipTv7N/jMkFn7ofIHSDGN/jfB#SD{ffMgQpyv7N/jM"kFm7ofI/@B#pTRTtSDC/MJj*gQpyv7N/jMWY[ofI/jMFB#G!KB#SD{ffMJj+I
{ffj!ItRTBYjM+It@?7NDG!Mff=9?#K!MFGFIONDGL/j?u?7I/B#SDC>@N/jfG!MJjE#
FB
= ; W" #!= )n ==if; ,vYH %ff W" /= #|!

/

2

fi

f #%$ff&(' *)

$ ,.$ !

"$ !$ $



LDMWRTBYjSDMJKA?#jw"CtpTG!stRTB+EGiKL/MjMFRTMJB#SuK9BYjfpTBYtRyMFGB#SDCjMFRBYKpy?7SDGLDpTstG P?#j9KL/MWRTBYj?7SH
yp K!?#jpS/vEHG!K!MF gQMFpTSDRTpT{fL}MJK(B#RyIkFm#n#m7ofItB"CDpTBYv7S/?7GKpT{*BYsDsRTpT{JBYKpy?7SqP ?#jstBYKpyMFSuK4?7SDpyK!?#jpS/v/9LDpTG
S/MJK|A;?#jw`I`A*LDpT{fL {ff?7S[KB#pSDGW74BYjfpTBYtRyMFG@B#SDC [}BYj{JGJILtB#G*MJMFS {ff?7SDGpTC/MJjMFCOB#G@B}`MFSt{LDBYjwqP?#j
MJYB#RTNDBYKpTS/vB+E#MFGpTB#SS/MJKA?#jwRyMFBYjSDpS/v4B#Ryv#?#jpyKLD}GJL/M.pTSDstN/K(CDBYKB{ff?7?7SDRyENDG!MFC BYjMGN//
G!MJKG?#PKL/MWRTBYjCDBYKBYtB#G!MNDpTRyKiuE@MJjG!w#?+HpyKGWgkFm#mHk+ofIA@LDpT{L4{ff?7SuKB#pTSDG;Y###{JB#G!MFGKLDBYK9AMJjM
G!K!?H{LDB#GKpT{JB#RTRyEzv#MFS/MJjBYK!MFCNDGpTSDv"KLDMl@RBYj S/MJKA?#jw`;S?7N/jMffHsMJjpT4MFSuKGJI/AMlLDB+#MNDG!MFC KL/jMJM
CDBYKBYtB#GMFG(?#PiCtp`MJjMFS[K(GpyJMFG.gKLDMDjG!sK {JB#G!MFGpTSKLDM)WRTBYj CtBYKBYtB#G!M#IDP?#vj 5H_Y## K Y##B#SDC
kJ###[of
10

21

19

20

31

4

27

11

28

29

7

8

13

22
15

6

17

25

18

26

1

2

3

5

23

32

34

35

12

9

16

36

37

24

33

14

30

pyv7NDjM4kFn;L/M.WRTBYj SDMJKA?#jw
SDGN/jfB#SD{ffMgQpTSDC/MJjMJKqB#RyIkFm#m7#opTG}BxS/MJKA?#jwP?#j}MJYB#RTNDBYKpTSDvx{JBYjqpTSDGN/jB#SD{ffMjpG!wGFrL/M
SDGN/jB#St{ffM@S/MJK|A;?#jwz{ff?7S[KB#pSDG(7.YBYjpTBYRyMFG;B#StCz#"BYj{JGJ9Sq?7N/jMffsMJjpTMFS[KGJIAMWLDB+#MNDG!MFCzD#M
CDBYKBYtB#GMFG*{ff?7SuKB#pTSDpTS/v kJ###z{JB#G!MFGJItv#MFS/MJjBYK!MFCOP j?7KLDM.StGN/jB#SD{ffMBFE#MFGpTB#SOSDMJKA?#jw
WB#pTRytStC/MJjlgQ*tjB#G!?7SMJK*B#RyI'kFm#m#7o*pTGBqS/?#jBYKpT#MlG!EHG!K!MFKLDBYK@P ?#jMF{JB#G!KG@GMJ#MJjMGNt4MJj
LDB#pTR/pSS/?#jKL/MFB#GK!MJjSz?7RT?#jB#C/?/9L/MWB#pTRytStC/MJj9S/MJKA?#jw{ff?7SuKB#pTSDG;#.BYjfpTBYtRyMFG9B#SDCz#BYj{JGJ9S
KLDpTG@{JB#G!M#I`A;M"LDBF#MB#RTG!?zNDG!MFC t#MCDBYKBYtB#GMFG*A*pTKLkJ###{JB#G!MFG@v#MFS/MJjBYK!MFCP j?7KL/M"@B#pTRTtSDC/MJj
S/MJK|A;?#jw`
jMFB#G!K(B#SD{ffMJjFI{ffj!I2iRBYjM+I2*?7NDGMff=9?#K!MFGJIiONDGL/j?u?7I`B#SDC>@NDjG!MJjE BYjMCDBYKBYtB#GMFGBFYB#pTR
BYtRyM}P j?7 KL/M 0B#{fLDpTS/MzMFBYjSDpS/v MJs?7GpyK!?#jE#zjMFB#G!K(B#SD{ffMJj"{ff?7SuKB#pTSDGqkJ YBYjpTBYtRTMFG}gm
BYK!K!jpyN/K!MFGJI7K|A;??#P`A@LDpT{L4LtBF#M@}pTGGpTSDv@YB#RTN/MFGJIuB#SDCBtpSDBYjE{JRB#GG9YBYjpTBYtRyM%o'B#SDCq#n#.pTSDGKB#SD{ffMFGJ
L/M{ffj!CDBYKBYtB#G!M4{ff?7SD{ffMJjStG{ffjMFCDpyK){JBYjCBYsDstRpT{JBYKpy?7SDGJWK)LtB#G@[mY{JB#GMFG.B#SDCkFqBYjpBYtRyMFG4gkF
BYK!K!jpyN/K!MFG@B#StCBz{JRTB#GGWYBYjpTBYtRTM%ofIB#SDCG!MJ#MFSYBYjpTBYtRyMFGWLDB+#M}pTGGpTSDv4B#RTNDMFGJ)?#jMJ?%#MJjFI Gp ?#P
KL/MYBYjpTBYtRyMFGipTSKL/M({ffj!CDBYKBYB#G!MBYjM({ff?7S[KpSuN/?7NtGiB#StCAMJjM(CDpTG{ffjMJKpyJMFC"NDGpTS/vWKL/M(.G!EHG
K!MF gQ?7LtBFHpID#?7LDS2I/ ?7S/v/ItB#StRyMJEz h DMJv#MJjFIkFm#muof;RTBYjM+NDG!MFG)kF"BYjfpTBYtRyMFGgkJ4BYK!K!jpyN/K!MFG
B#SDCx{JRTB#GG)BYjpBYtRyMFGJI2?7S/M4P?#jKL/MSND`MJj)?#PKpT4MFGB{ffMJjKB#pSKEsM"?#PG!?7RTBYj BYjM4?{J{JNDjMFCpTS
BYL/?7N/j*s`MJjfpy?C`oB#StC{ff?7S[KB#pTStG.kJ7#pTStG!KB#SD{ffMFGJI/A*pTKL/?7N/KpTGGpS/vYB#RTN/MFGF*?7NDGMff=9?#K!MFG@G!K!?#jMFG
KL/M@#?#K!MFGP?#j;MFB#{fL}?#P2KLD 0lu@?7NDG!M?#P*MJsDjMFG!MFSuKBYKpy#MFG(?7S/v#jMFGG4MFS?7SOkF.w#MJE4#?#K!MFGJ/pyK;LDB#G
k+qYBYjpTBYtRyMFG)B#SDC[#jMF{ff?#jCDGB#SDCB#RTRiKL/MYBYjpTBYtRyMFGWMff/{ffMJsDKKA?LDB+#MpTGGpTS/v}YB#RTN/MFGFNtGLH
j??7{ff?7SuKB#pTSDGnHkF4{JB#G!MFG{ff?#jjMFG!s?7SDCtpTS/vK!?G!sMF{JpyMFG?#Pv7pRTRyMFC"NDGL/j?u?7G;pTS4KL/M)@v7BYjpT{JNDGB#SDC
MJspy?#KBDB#pTRTEKLDMJjM4BYjM}#zBYjfpTBYtRyMFG4gQB{JRTB#GG)YBYjpTBYRyM#IG!KBYKpTS/vA*LDMJKL/MJjKL/M"NDGL/j??7 pTG
MFCDpyRyM?#js?7pTG?7S/?7NDGJI2B#SDCx#BYK!K!jpTtN/K!MBYjfpTBYtRyMFGfo*B#SDC?7SDRTE ?7S/M4YBYjpTBYtRyMLDB#GpGGpTS/vqB#RN/MFGJ

fiN

2

fi X ttu

Age

SocioEcon

GoodStudent

AntiTheft

OtherCar

RiskAversion

HomeBase

Mileage

CarValue

SeniorTrain

VehicleYear

RuggedAuto

Theft

MakeModel

Antilock

Accident

ThisCarDam

OtherCarCost

DrivingSkill

Airbag

DrivQuality

DrivHist

Cushioning

ILiCost

MedCost

ThisCarCost

PropCost

pyv7N/jMkFmL/MSDGN/jfB#SD{ffMS/MJKA?#jw
>WN/jG!MJjE{ff?7SuKB#pTSDGCDBYKB.jMFRBYKpy#MK!?"KL/MMJYB#RTNDBYKpy?7S}?#PBYststRTpT{JBYKpy?7StG9P ?#jSuNDjG!MJjEG{LD?u?7RTGFIuB#SDCqLDB#G
m4YBYjpTBYRyMFGB#SDCkF#m#Yz{JB#GMFGJIA@pyKL/?7N/KpGGpTS/v4YB#RTN/MFGF;SB#RTR ?#PKL/M{JB#G!MFGFI`pGGpTS/v4YB#RTN/MFG@BYjM
S/?#K*CtpTG{JBYjC/MFCztNDK(K!jMFBYK!MFCB#G@BCDpTG!KpSD{ffK(G!KBYK!M#
S}KLDM*DjGKG!MJjpyMFG;?#P2MffHs`MJjfpT4MFSuKGJI[AMWB#pK!?{ff?74stBYjMWKL/M*MFLDB+pT?#j?#P?7N/j*h;*@=tB#G!MFC
Ry?H{JB#R9G!MFBYj{fLx4MJKL/?HCrg
fiff'o@A@pyKLKL/M{JRTB#GGp{JB#R9Ry?{JB#R9GMFBYj{LxpSOKLDMG!stB#{ffM4?#P*)Gq7g fiffiof
L/MG{ff?#jpS/v}PQNDSD{ffKpy?7SG!MFRyMF{ffK!MFCpG@WMFNgQ*MF{w#MJjB#SxMJK)B#RyI9kFm#m#7ogA*LDp{LpTGWG{ff?#jM"MFuNDpTB#RyMFSuK
B#SDCC/MF{ff?7s`?7GBYtRyM%ofIA*pTKLKLDMstBYjB#4MJK!MJj4jMJstjMFG!MFSuKpTS/vKL/MMFuNtpyB#RTMFS[K4GB#4sRyMGpyJMG!MJK4K!?rk
B#SDCB4NDStpyP ?#jfG!K!jfND{ffKN/jM)sDjpT?#jFi*L/MG!KBYjKpTS/vs?7pTSuK?#P KL/M.G!MFBYjf{L pTGKL/MMFsDKEzv#jBYstLpTSz?#KL
{JB#G!MFGJ
M"LDBF#Ml{ff?7RRyMF{ffK!MFC KL/MlP ?7RTRT?+A*pTSDv"pTSDP ?#j}BYKpy?7SBY?7N/K(KL/M.MffHsMJjpT4MFSuKGJ
= L/M.WMFNG{ff?#jMqgQRy?#v#MJjfGpy?7So;?#PiKL/MlRyMFBYjfS/MFCS/MJKA?#jw`
UEN L/M.SNDlMJj(?#PMFC/v#MFG@pTSD{JRTNDCDMFCqpTSKLDMlRyMFBYjS/MFCSDMJKA?#jw
LDMzWB#pTSDvCDpG!KB#SD{ffM#I
H)).WfI9pM#KL/MSuNDMJj?#PWCDpMJjMFSuKMFC/v#MFGFI;B#CDC/MFC_gQofI
CDMFRyMJK!MFCgQ.ofI?#j;A*j?7S/v7RyE"?#jpyMFSuK!MFCgA@pyKL/?7N/KKBYwHpTS/v"pTSuK!?B#{J{ff?7NDSuK;KLDM@CDpMJjMFSD{ffMFGMJKAMJMFS
MFNDpyYB#RyMFSuK.G!K!jND{ffKNDjMFGfogofI'pTSKL/MRTMFBYjS/MFCxS/MJK|A;?#jwA@pyKLjMFG!sMF{ffK.K!? KLDMv#?7RTCxG!KB#StCDBYjC
SDMJKA?#jwrgKL/M4?#jpyv7pTStB#R'4?HC/MFR of"LDpTG)4MFB#GN/jM4pTG)?7SDRyE{ff?74stN/K!MFCP?#jKL/M4KL/jMJM"K!MFGKlC/?Y
}B#pTSDGA*L/MJjM.B4v#?7RTC G!KB#StCDBYjCMff/pTG!KGJ
LDMSuNDMJj?#P2pyK!MJjBYKpy?7StG{JBYjjpTMFC4?7N/KEKL/M*B#Ryv#?#jpTKLDK!?ljMFB#{LqKL/MMFG!KS/MJK|A;?#jwIHpM#
KLDMlSuNtlMJj(?#Pi?#s`MJjfBYK!?#jG*NDGMFCK!?K!jB#SDGP ?#jKLDMlpTSDpyKpB#Rv#jfBYstLpTSuK!?}B4Ry?H{JB#R2?#sDKpT"ND
#t L/M.SNDMJj(?#PpSDCDpyHpTCDNDB#RG*gMFpyKL/MJj***)G*?#jW*h;*)Gfo(MJB#RTNtBYK!MFC EqKL/M.B#RTv#?#jpyKLD
2i

fi

$ ,.$ !

f #%$ff&(' *)

"$ !$ $

QGVertMotion

N0_7muVerMo



SubjVertMo

CombVerMo

RaoContMoist

AreaMeso_ALS

CombMoisture

AreaMoDryAir

AMInstabMt

CldShadeConv

ScenRelAMIns

LLIW

LatestCIN

CurPropConv

MountainFcst

SfcWndShfDis

ScenRel3_4

RHRatio

AMDewptCalPl

WindFieldPln

TempDis

SynForcng

MeanRH

CombClouds

OutflowFrMt

Boundaries

LowLLapse

WindFieldMt

WindAloft

AMInsWliScen

ScnRelPlFcst

IRCloudCover

WndHodograph

MorningBound

Scenario

VISCloudCov

CldShadeOth

InsInMt

Date

SatContMoist

MvmtFeatures

MidLLapse

LIfr12ZDENSd

LoLevMoistAd

InsChange

InsSclInScen

MorningCIN

ScenRelAMCIN

AMCINInScen

Dewpoints

CompPlFcst

CapChange

CapInScen

PlainsFcst

N34StarFcst

R5Fcst

U fiU


pyv7N/jMlYHL/M.WB#pTRytStC/MJj(S/MJKA?#jw

L/MSuNtlMJj?#PiY] fWZJd!ZJ^taHG!KBYKpTG!KpT{JGMJYB#RTNDBYK!MFC4CtN/jpTS/v@KL/MMffMF{JNDKpy?7S?#PtKL/M(B#Ryv#?#jfpyKLD
*LDpTG"pTGBNDG!MJPQNDRYB#RTN/MzK!?x4MFB#GNDjMqKLDMzMJ~q{JpyMFSD{ffE?#P@KL/M B#Ryv#?#jpTKLDGJI9MF{JB#NDG!M4?7GK"?#P

<

2

fi X ttu
KLDM4jNDSDSDpS/vqKp4M?#PB G{ff?#jpTS/vY=tB#GMFCRyMFBYjSDpTSDvzB#Ryv#?#jfpyKLDpTGG!sMFSuK.pTSKL/M4MJYB#RTNDBYKpy?7S?#P
GKBYKpTG!KpT{JG*P j?7KLDMlCDBYKBYtB#G!M#
U L/M"K!?#KB#R9SuNDMJj@?#PG!KBYKpTG!Kp{JGWNtG!MFCuE KLDMB#RTv#?#jpyKLD>@?#K!M4KLDBYK)KLDpTGWSuNtlMJj{JB#S
M{ff?7SDGpTC/MJjBYtRTE v#jMFBYK!MJjlKLtB#SxG!KENDGpS/vzLtB#GLDpTS/vK!MF{fLDSDpTN/MFGAM{JB#SG!K!?#jM}B#SDC
MJ~q{JpyMFS[KRTE4jMJK!jpyMJ#M)B#S[E4stjMJpT?7NDGRyE{JB#RT{JNDRTBYK!MFCzG!KBYKpTGKpT{JGJ|KpTG;S/?#KKL/MJjMJP ?#jM)S/MF{ffMFGGBYjE4K!?
jMF{ff?74stN/K!M.KLDMF uEB#{J{ffMFGGpTS/v4KL/MlCtBYKBYtB#G!M#ItKLNDG(v7B#pSDpTS/v4pTSMJ~}{JpTMFSD{ffE#
,YB#RTN/MF*G L/p M@B+#MJjBYv#M.pTSuSzNtlMJjg7?#o!Po;{ffBY?7jf4pTBYstN/RyMFK!MFGC2KLDBYKLDppS[GK!YMJB#j#RTN/MFMWSDMWpTG;pTSqB#RKG!L/?"M)p4CDps?#MJjjKMFB#SuS[K;KG!KBYMFK{JpTB#GNDKpTG!{JMWGKgQL/pMWM#9KpTK4L/MM
jMFuNDpTjMFCgK!q ?r=sv{fft?74g sN/K!M"BG!KBYKpG!KpT{"pTSD{ffjMFB#G!MFGWMffHs?7S/MFS[KpB#RTRyEA*pyKLOKL/MSuNDMJj@?#PBYjpBYtRyMFG
pS[#?7Ry#MFC
LDMKpTM#I4MFB#GN/jMFCpTS\JZcY^`\fIMFstRy?+E#MFCEKLDM"B#Ryv#?#jfpyKLDK!?RyMFBYjSKL/M4S/MJKA?#jw`
N/j.pT4stRTMF4MFS[KBYKpT?7SxpTG)AjpTK!K!MFSxpTSKL/M}[ sDj?#v#jB#}pTS/vRTB#S/v7NDBYv#MqB#SDCjNDStGWNtSDC/MJj
'pTSNH`LDpTGYB#RTN/MpTG"?7SDRyEBj?7N/v7L4MFB#GNDjM?#P*KL/MMJ~}{JpTMFSD{ffE?#PWKL/MB#Ryv#?#jpyKLtGJIMff
{JB#NtG!MKL/MJjMBYjMB#S[E{Jpyj{JNDGKB#SD{ffMFG"KLDBYK"}BFEpS tN/MFSD{ffM}KL/MjNDSDSDpS/vKpT4MgMffK!MJjfSDB#R
RT?7B#CDpTS/vpTSBS/MJK|A;?#jw#MFCr{ff?74stN/K!MJj+I{JB#{LDpTSDv?#j4B#SuE?#KL/MJjB#Gs`MF{ffK"?#P*KLDMz{ff?74sN/K!MJjBYj!
{fLDpyK!MF{ffKN/jM#I4MF?#jEstBYv7pS/v/INDG!M?#PWpTjKNDB#R4MF4?#jE#I;KL/jMFB#CDpTSDv/ICDpMJjMFSuK{ff?HC/M#I;MJK{Yof
>@MJ#MJjKL/MFRTMFGGJIAM LDB+#MK!jpyMFCK!?MFSDGN/jMqKLDBYKKL/MK|A;?B#RTv#?#jpyKLDGjNDSNDStC/MJjKLDM GB#4M
{ff?7StCDpyKpy?7SDGB#G"PBYjB#G"s`?7GGpytRyM#I'B#SDCKLDMqK|A;?pT4sRyMF4MFSuKBYKpy?7SDG.GLtBYjMz?7G!Kl?#PKLDMq{ff?HC/M#
SzPB#{ffKJI/KLDMWK|A;?B#RTv#?#jpyKLDGLDB+#MMJMFSzpS[K!MJv#jBYK!MFCpS[K!?KL/MRTpyjfB.stB#{wBYv#MqgQB+B#pRTBYtRyM)BYK
"!#!!%$'&#(#)*$+-,#./$ (-0213(4&65873.-9
/?#jKL/M4SDGN/jB#St{ffMB#StC@B#pTRTtSDC/MJjC/?7B#pSDGJI2KL/M4jMJs?#jK!MFCxjMFGNDRyKG)BYjM}KL/MBF#MJjBYv#MzYB#RTN/MFG
B#{ffj?7GGKL/M)D#M.CDBYKBYtB#G!MFG({ff?7StGpTC/MJjMFCL/MWjMFGNDRyKG?#Pi?7N/jMffsMJjp4MFS[KGP?#jG!EHS[KL/MJKp{WCtBYKBHItpM#
WRTBYjIHSDGN/jB#St{ffMWB#SDCWB#pTRytStC/MJjFIuBYjM.CDpTG!stRBFE#MFCpTSz'BYtRTMFGI/B#StC I/jMFG!sMF{ffKpy#MFRyE#IHA*L/MJjM@AM
B#RTG!?GL/?+AKL/M*WMFNYB#RTN/MFG9P?#jKL/M*K!jN/Ml;g :
<9o9B#SDC4KL/MMFsDKE 7g $6<oiS/MJKA?#jwHGWgA@pyKL4stBYjB#MJK!MJjG
jMff=K!jB#pS/MFCPj?7KL/M}{ff?#jjMFG!s?7SDCDpTSDvCtBYKBYtB#G!cM FofI'A@LDpT{L}BFEG!MJj#MzB#GlBwHpTSDC?#PG{JB#RyM#zL/M
jMFGNtRyKG?#DKB#pTS/MFC P ?#jjMFB#RCDBYKBBYjMCDpTG!stRBFE#MFCpTSiBYtRyMl
WGWA;M{ff?7SDGpTCDMJj@KL/MJjMK!?MB{JRyMFBYjCDpMJjMFSD{ffMMJKAMJMFSOKLDM"jMFGNDRyKG*?#DKB#pTS/MFCP?#j@KL/MG!EHSH
KL/MJKpT{lB#SDCKL/xM 0C/?7B#pTSDGFIAMlGLtB#RTR2CDpTG{JNtGGKL/MFG!MJsBYjBYK!MFRyE#
D?#j*KL/MlGESuKL/MJKpT{C/?7}B#pTSDG.gQiBYtRyMFG@ItB#SDC7of
N/j*h**@=tB#G!MFCB#Ryv#?#jpyKLD?7N/K!sMJjP?#jGWKL/M**@=tB#G!MFC?7S/MA*pyKLjMFG!sMF{ffK)K!?
=
KLDMYB#RTN/M?#PHKL/MG{ff?#jpTS/v*PNDSt{ffKpy?7S.NDG!MFClK!?*v7NDpC/M9KL/M;GMFBYj{L2'A;MB#RyABFEHG ?#DKB#pS.MJK!K!MJj
jMFGNDRyKG?7SxKL/MD#M}CtBYKBYtB#G!MFGl{ff?7StGpTC/MJjMFC>*?#K!MqKLDBYK.AM}BYjM}NDGpTS/vB Ry?#v7BYjpTKLDpT{
#MJjfGpy?7S?#PKL/MOG{ff?#jfpTS/vxPQNDSD{ffKpy?7SIG!?KLDBYKzKL/MOCDpy`MJjMFSt{ffMFG}BYjMND{fLv#jMFBYK!MJjpSB
SD?7SHRy?#v7BYjpyKLtpT{)G{JB#RyM#L/MFG!MjMFGNDRyKGGN/sDs?#jKKL/MlpTCDMFBKLDBYK**h;*)G)BYjMlBYRyMK!?
SDC}S/MJAB#SDCq`MJK!K!MJjRy?H{JB#RtB/pTBlA*pyKLDpSKL/M@G{ff?#jM%)G!MFBYj{fLzBYstsDj?7B#{LzP?#jRTMFBYjSDpTS/v
B+E#MFGpTB#SS/MJKA?#jwHG*pTSKLDpGKEs`Ml?#PiLDpTv7LDRyEqGK!jND{ffKN/jMFCCD?7B#pTSDGJ
N/j4G!MFBYj{L4MJKL/?HCpTGB#RTG!?sDjMJPMJjBYtRyMzPj?7KL/Ms?7pTS[K"?#PWpyMJA?#P@KL/M @B#}pTS/v
=
CtpTG!KB#SD{ffMFGJIA*LDpT{fLBYjM"B#RyABFEHG@{ff?7SDGpTC/MJjBYtRTEzRy?%A;MJjWKLDB#SKL/Ml?7S/MFG@?#DKB#pTSDMFC ENtGpTS/v
KLDMl*G!stB#{ffM#
?#jMJ?%#MJjFI/?7N/j;GMFBYj{Lz4MJKL/?HC}pTGv#MFS/MJjB#RTRTE"4?#jM*MJ~}{JpyMFSuKJ9pyK{JBYjjfpyMFG?7NDKP MJAMJjpyK!MJj!
=
BYKpT?7SDG4g?7SKL/M"D#M{JB#G!MFGfofIMJYB#RTNDBYK!MFGWP MJAMJjpTSDCDpTpTCtNDB#RTGg?7SP?7N/j){JB#G!MFGfofI{ff?74sN/K!MFG
2M

fi

f #%$ff&(' *)

$ ,.$ !

fi

t9

W-X <-Y8Z
< Y8Z
-



[3\

b[
UElKm m]n

[3\

W-X <-Y8Z
<-Y8Z

UEl ["_o\

[3\

UEl [ m^l \
UEl ["_]_[

l [

cYedgf hjiRq

W-X <-Y8Z
<-Y8Z
U

cYedgf hji%sut

U

Yedgf h;i%sut

U

U

[ l

n a^a]\^a
n a][ l

l

m]m^m

% N%

[3\

n

[

\

K[

%%

n
_

_ ]\

># >k

@A>CBED

][


b[K[][

FGIHKJ

@LMON

n

[

\ ]a]\

\

\ n

_o\

n^n]n^n

n

[3a

l

\ n

]\

%%%% %

` ^a
` a^a

_

\

m^n

_ l^lKn [

` _

pa6_



% %%

PRQSHKJTMrU

^\3_

./ /&%F/ NN NN / % %% /N/ % N // N %%

PRQSHKJTMVUl]n]n]n



p\

n



]a

% / % %%

[3\

n a][

'

PRQSHKJTMVU

_

n

Um]m^m

Yedgf h;iRq





["_

U

Yedgf h;iRk






U

fi




N
/ N% /% /
N/ %/ NN NN %% /N ?% //
?

NNNN%% %
NN%%
%
N
%% N./ /
%% / /
U

c Yedgf hjiRk



>#

"$ !$ $

l ]\]\

NN / %% / %F/ % //
n^n [

K\][

K[][

l

_

`

l

` _
` [

[

NN

K[^\
]a n

n

vCw6x8y{z}|~zKb-y{%j"z}Vyw6b-w6w6x8w"'zK

Nb
W-X <-Y8Z
<-Y8Z
c{j h
{; h

>C"

p^ n _
p^ Kn3l
p^ n [ n

?

P



[ l
[


[

^l



n
[

n
_

DNpJ
[^a
l




\3_ ^
n
\ _Ka

>BuDT>I

@A>CBED

FGIHKJ

@LMON

m^m]n

\ m^m \ l
_ ^l \]\

`3
l
`n

]n^
[

Kn [

l]

l] _Ka

n

vw6x2y{z~*"zobw6"zzK2y{%;"zT2bw"-z-w"w"V-w6w6x2w"zK"{ozo"""

jzo/zo*-SfizozK#R'w6'oA;bz-w6w6x2w"zKrj-zozow"'zKpp-'zKAjzo/zo*'w6o
j-zV2"zOow"zKpp-w"-b--*w"''zo}j;-/ow"'zKp%Oz'pw6"-zOwK"zobw6"z
-xfizo"6w6bw6x8y{zK#"y{"zKz'w6'oy{#y{"zKw6'zoj;row"'zKpp
"z}/%w"2vCw6x2yz}p~


vzAzK-y
-
ow"zw6z"Cw"-oy2{"zRw6xfi
zRw"6w"#w6"zKC"zrV
x8w"'zKzo-{zKezK'}zVrEx2w"'zKzr'zob"
zezK"zKzKo~Axfi"

Np
W2X Y8Z
Y8Z
cef
8f

[
_ a6_
[ m^l
l]n n
\ _oa \


\6_
_ l

?

P


[
[ l



n

p





DNpJ


^

\]a




l
_ [
[ n

BuDT
n
_[ ]
_ p

@ABuD

FRGIH]J

@LMVN

[ l]m [ \
[^a Kn \

` m^

aK["_


`a

\^\
n

vw6x2y{z}~*"zobw6"zzK2y{%;"z}Vw"y{2--zo%-w"w"V-w6w6x2w"'zKr"{ozo"""

[6_]_

fi{22#8

Np
R PR
PR
R PR
PR
R PR
PR
R PR
PR

"

DNbJ

CBED



]
[^a
a][^a

JTNpH^BED E H
NpJ
_
\
_
\
\
\

l \
l _



\3_
\3_ ]

l
p

[^\ Km
[^\][

]




]n

J
l

]n

[ l]lKm

\

QH]JN
\ _

[

]n
NpB
BN G

\ _ n
[

\ n]m [
#BuJ 6

[
m^m [][


R PR
PR

_^_
_^_ ]n

m^
a3_

_
n

R PR
PR

]
l _ _
]l _ _







FJ BuNpJ
[ l
\ ]

l
[3a

@ACBED

FRGIH]J

@LMON



` \

n ` \6_

` \

n ` \^a]\

aK[

l [ l
l n

n]n3Kn

`g_ l

m^]n

`\

`n
`a l

]

n

[^a^a3_
[ n^m

`g_

` \]\
`

lKm

\

] ^

]

`a n
` \]\

` n
`

p
_

l
_oaK[ K
n _ l

` m]m
`m \

[
[^[

] l
p^

n
\

`g_ l
` lKm

^ `
` lKn

`[ l

vw6x2y{z}~*zK-y{%j"zO/%-w6w6x2w"zK

w"y""b{-zKw"bz}w"z'y{u/ow"'zK;Sfi2
-fiIxezo''zo-w"
fiIbzozow"'zKo8w"2fi
%xfizo''zozow"'z"
{zK'fizK'zzo{zK-"z*w"y{""b-o%z



-zK{zow"y{""b-

oy{zKw6by{

{-w6{

'fizoj"bOz"-zo{zKezK'

w"

yw6K~
"*-z-"z

zo{zK-zKw"bzK--zozK




w'zK-

*

'zop{zK"}zfizobzKo/zw"

'2w"zzK

''zK'z

xfizK-wK4{""}z

zKw6bb



z

2'zKx22w6{w'zKw6pbzKb-p"zfi]/zo-y

-w"wV2yzR"zozK}zKw6bb
Av-z*zKp'*'zKy{zK'zK
fiff EOy{]"zo]2/-3w6zobo
"p
-b'p{zK'zKow6fiz;

wy{ow"yw3-

x'zKy{zK-w'y-w6O-w"yy{

zKzKw"zKC-z6w"yz"-z*"b--{3zK-w6'z*zu'zKy{zK{"z/y{ow"yw3--'
4{'zK/-zo"zK#'zKxw"w"-wy'/"y{-/-w6w6bz;"x8-zK
#z'6uow"yy{zK

!
"$#&% ew"y{-;"-bw"ow"yzKw"--z*w6x2y'''"zKj"x22zK"fizobw6'"b"'y-{-o6w"-
-'z
' zK#y{"#y{-R-p-wK"zV"RxfizozK4{'zK-bzo{2y{wKw"y'xfizKz;"x8-zK8p

z2wK"z2y{zKzK#'zKu/}2y{z"zop{-A"ew6x2'zKw6pb
~)(+*!,
-fiIw"--(.*,fi
R"-b

z42y{"z-z*
w"2
'2w"zKKCzKezK"zKy{"C-bzbw"z"fizobw6'"bw"}zKz
'fizK{"z"zozK"zob{2o
zw6x2

vz2w6bw"zo'zob-'zKxzK'zw"y""b{-w6zzy{zK-"0/121"

y'Vw"--z-xezo3/465
/ "'zobw6{-rz'-{zK'''"z'zKw6bp

z4ezopzK#o6zK'z%3w"yzK-wK"zxfizozK4zKw"jyy{^o~/121798w"2:/;465

-4zKo



/<7=8>83?]p@8xfizKrz

-}xfizo*"
3w6bw6x2y{zKzOw"Iv-zr"b}--{w"-zr2{w"y"bw68w6zVzOw"z
w"-bzo{2*z4fizobzK#ow"/zKyyfiw"zyyzK'zKezob;"bw"-zzKw"zKK{zzzo
{
~w"rz#-xfizo"R{'zopw6{-V^

-zKj'zo!7A/465
/ p8/z2'zz'zobw6{rzoz

[6_oa

fiB CD-FEHGJI*LKebSHEME-ONQPCSR

zxfizK'O"bw62%w"j--
vw6x2y{zK3]#fiHw"-

NSCQT2QNSTUCOFEMNSD-p-HV
WYX[ZA\O

2/'zoO-''zKw"Iv-zbzK-y{V"/zK'zz4ezopzK#Vw6bz-'2ywK"zK

o4

Nb

"

P




^H_`W-X4 Y8Z
^H_` Y8Z

^ n
^] l

[^\
l

^H_`W-X4 Y8Z
^H_` Y8Z

l 6
[ _o\
l [6_o\

[^\

^H_`W-X4 Y8Z
^H_` Y8Z

n K
[
n K
[][

[ l
lKn




^






n

_ Kn
n]n]n^n

PRQSHKJTM



n

l

\

n

[6_
n

aK[

vw6x2y{z:]#~*zK-y;"zryw6b

Nb

^H_`W-X4 Y8Z
^H_` Y8Z

p^ n _ n
p _oa^a

"
[ l
[6_

P






l

m3lKm \
l n

n ^
[ [ m3
\K[ lKn]m

`\
` l]m

a]\


p aK[ m]m]n

n [6_
^]
]

n \^\
_]_ \K[

`\
`l

[

K
_ \K[3\3_ n
p l]n \ l

n 3
\ _
n [
]

n^]n \ l
_]_ _ 3
l

` \^\
`\ n

_ l

n

[

BuDT

l [

a]\

-w6w6x2w"zK-vCw6x2bazKw6bb

DNpJ


n
[



@LMON

^
[^a
_ _ _[6_

p K


K
n \ \
PRQSHKJTM l]n]n^n
_^_ m3l _
n
[^a



[6_

FGIHKJ



n]n^n

n


_






@ACBED

DNpJ


PRQSHKJTM

l
[ l



[ l _
l^ ]l

BuDTI

l [ l

@ABuD

FRGIH]J

@LMVN

_ l l^l
]l
_ n \ ^

` [][
[` \


[

vw6x2y{zc~*"zobw6"zzK-y%;"rzT2bw"-zw"-vCw6x2da4zKw6bb

Nb

^H_`W-X4 Y8Z
^H_` Y8Z

[
_ a3_
[ n _

"
\3_
_ n



P


[



n



l

_



l

DNpJ



CBED

@ABuD

FRGIH]J

@LMON

\3_
\

3
l] \
_ l ] [

m^m
] a][

` l^] ] a6_ _
` l]n \K[ K _

[` n _
[` n _

\ K
l n

[ l p

vw6x2y{zc~*"zobw6"zzK-y;"zrw"y{2-zow"-vw6x2Ma4zKw6bb
"z'#zow"2oC w"yyRzow"'zKoAzzo- z"z--bw"-z-w6w6x2w"zKo
zbzK-y{A"x2w"zKxe(.*,
-fiIw"-
-fiIw6zzw"z"Rv-2zK-zKw"y}w6-fizKw6b
j"zO/-w6w6x2w"'zKo*zoz-y

u/-w6w6x2w"'zK-#zKe(+*!,
-fiI

-]"zzzKb-y{

"
-fiIAvzozoj"z"I-zvCw6x2a4zKw6bb-#zK-"'bx2'z{-2ow"y'2]4z
"zozKzKw6bb-zr*

'2w"zw6/y{zKw"*-zrzKy{zK'zK6w"yzK;"*z8w6bw"zo'zobf/g121

w"-h/;45
/ pRv-*%#'bw"'{z-w6{z
zzK-y"x-w"-zKx
Vyw6b|6""

fiIA8{-zzzo-{

'2w"z"rzoz(.*,fi


-^"zK

"Au/O%-w6w6x2w"'zKjz'-w"ybzK-y{pw"-

jzoz}fiIezob;"b%xezo''zo-w"d(+*!,fiICp

w"2i
(.*,fi
RI/z'yy-bzoc
(+*!,


-fiI'xezO-bzo;zobw6x8y{zO'-(+*!,fiIz#zow"-ow"y{--%ow"'zj(+*!,fiI
{

zKezK'-z2w6b'xfizou/zozK0(+*!,
-fiI

fizoj"b%xfizo''zoz}-bbw"-zw"
"Vz}/%-w6w6x2w"'zKK2zu/w"y{""b-fizo'
j"b byw6py{8~fizKw"pw"y""b{-Cxezo''zo-w"z/"zo*w"-o6w"-xe"w"y{""b-

[6_

fi{22#8



Np

DNbJ

BuDTI



JTNpH^BED E H NpJ

@)k R
C PR
@)k PR

]
[^a
a][^a
\

\

a^\

\

\

\^a n \

@)k R
C PR
@)k PR

l \
l \





\ ] _ l

]n

]m

[^[ lKn _

@)k R
C PR
@)k PR

\3_
\3_ \

l

@)k R
C PR
@)k PR

[^\ ]
[^\

[

@ABuD

FRGIHKJ

@LMON

[ l
\


[ K
n^m
3



`n
` a6_

`m \
`m

m]n
] _o\

l _o[
_ [

` ]n
` _

` \
`

\ \

_ m^n

\]\]\ l

` ["_
` _

`_ n
n `\ n

] ]
[ [
p \K[

K
n \
m]3
]
n l

`
` ]m

] ` [
l ` n

Kn^m^l]l \
l _ n

n
[ 3
[ l]l

]
l n \ ^
l
lKm _ l

[#`
[#` l _

a]a
_ ^l

FJ BuNpJ
l
[ ^



]l
_

l ^l
\ ]
_ m]m

` n^m
` m3l

a` n3l
\` ]n

J

l

QH]JN
] \
]m
n]m

BN G DTNpB
l

_ l \

n
l^
]



l \ l _ n
#BuJ 6



@)k R
C PR
@)k PR

_]_ n^n^
_]_ n _

m^m
m^n

[ m3l
[ l]n

@)k R
C PR
@)k PR

]
l _ _
]l _ _





\
]

vw6x2y{zo4~/zK-y%;"-z}O%/-w6w6x8w"'zK-bvCw6x8MazKw6bp

fizoj"b

z'-w"yy-zrzKw"-u/w"-K<(+*,'
2fi


(+*!,fiI

r{zK'fizK'b2--z"

*'zo-w6"zVzo{zK#%-w"

z-w]"zow6b{zKw-b 'zop{zK"zfizobzK' 2w6zy{zKw6b2w"y{""p{-

x2w"'zK*Or{"-zorw"y{""b-j"y{zKw6b2
%wK"zKw" zo*" 4o/T-ow"'z"8z
2w6p'-y{#'zK-zK'zKw"bzz:'-w"yu"zy{zKw6pzKzo*" e w"--{'
zVEx2w"'zKy{ow"yw"2w6x2'zKw6bp-zo4{-y}--zozK
"/z-wK"zw"y'-'zKz%jyy{^
w"y{""b-o~
l
H
a2{'zKzow"y{
"|pVw" w"y""b{-
x2w"'zK --zoezK2zK-z'zK'o
z-'zK w"

-zofizK-zK-z%'zK'x2w"'zKzzKw"bz"e2-{{-w"y-w"y2j"bw6{2m2yy{x2w"8


"pe{wzK2zK-zyzo"zKy
z'#2w"y
'4n
vz:mco'zKw6bp


zoE/"fizoqp

zop;"]4{oAopI

}x2-w6{

{-z:%VzK

b"bj-2{sr)tpAur"'z-w6qr)tzozK-Vw""b-zob"z}6w6bw6x2yzKw"Vz2o
z-'zKw""bzob-2''zK#{-z'"ey"""z}"bzK'fi---zo*"o



V"zoCw"y{""b{-vwuC^*zoA/-''p-'"*sxfiyIlfip^2w6I-'zKI2zofizK-zK-z'zK'*EzK
zorw"y{O]QfizKU/zKyyzp|{C

p

vzru/-zofizK-zK2zEx2w"'zKw"y{""p{-o4lw"-}xHyl"fizobw6'zV-zr'2w"zV"Iz'-{6w"y{zK-z
oyw"zKozobzKw"~r<tz42y{"bzKAz'2w"z"e2bw6z2w6{x2y{zr{w{"zK"b-zob
z-wK"z2oy-zK-z*w"y{""b-r)tz%2w6p'
6--rwV"zK"bzob-rw"-z%w"z


"b--{
zo

ow"

w"z*
'fizoj"b

w"-rEx2w"'zK

-zzK-y"x-w"zK

[^a n

'zKw6pbzo4-oe"b-zo''zK'rrzozo
{

w"zj"bzK

w"y""b{-

vz

fiB CD-FEHGJI*LKebSHEME-ONQPCSR

zK2y{j"}zw"y""b{-lw"-r)t

NSCQT2QNSTUCOFEMNSD-p-HV
WYX[ZA\O

-wK"zxfizozK

"x-w"-zK--]r

8y{zKzK#w6{-

j-bw6zw"y'-oy2zK zjy{4{bw'"ju%w6z^p "cxfiyIlfi/z2'zK-z";/w6z8w" 6w6"z
wK6w"yw6x8y{zw6wSQY;LQYsH@OU)U@Sv@UL+Lw
v-z'zK'w"2-oy-zK}zK'z/zfizobzKCw6z%ryw6p^ --bw"-z"6w"-Vw"y{8-zoKI
w"--{}'-zw%VzK6w"yzKo"-z%-xfizo"8zK"zKAzy{zKw6b-zK-zou/" w"-zrw"
-w"-zKo/z}-wK"zyy{zK'zK*w"--{-w"yeezob;"bw"-zzKw"bzKo~

j@$

vz6w"yz"*z
/

2/w]"zKw"

Tj"bw6

%b{'zob{e"pj-2{

4
b#/w6b"

O]Lj"r-zy{zKw6b-zKzou/" ev-3w"yz}zKw"-zK-z:'-w"y{"A-zzo*" 2
yF"zKy4w"-wfizK-w"yu'zobwu"'z-w6A*

w34-

w"y'"zEz'-{6w"y{zKVw"-

-zKfiw6x2y{z"

d3$

vz~m}-yy{x2w"{zK{x2y{zoI2'w"-zO EzK#'"*2m-yyx2w" e"xfizou/zozKz-b"x2w6x2yS
u-'b{x2
8w"'4ow6'zK'z-w6w6x2w"'zjz}zK8{bow"yfijz'zK--''p{x2{e
w"2z-"x2w6x8y{-''bx2{w"b'ow6'zK
2zKw"bz
w"Oow"yo-yw6'zK

'zy{zKw6b-zK

-zou/" 8*ju"z-w6

w"-w"yy-z

w"zw"z y{"-"x2w6x8y{ "z -w6w4
z-wK"z

wzKbzKw""'-yzKw6'bw"-'j"bw6{"Az:m}-yy{x2w"{zK{x2y{zo

2'w"-z"xfizKow"-'zO-*-z-w"%zfizK#w"yfi2yz4{w"--zV'pw"-'j"bw6{ow"xfiz
"zozozKy{e~Ow

2'zK

-zou/" 0zKz-m{

Ozq'O-b"x2w6x2yu-''b{x2-{w"ow6'zK

2'w"-zow"

'w

xfizb{''zKzjyy{^%wKz%w"fio

.{w"p|%w"ob-oC3#p~

J 2Y R)7?/+|

>z >fi'


+H
L!
6.


e%>fi<?

L!

rzozYe
zK"'zKfa42w"-zK'b"#{zKezK'-z-''bx2{:
zo"
6w6bw6x2y{zK[
-zu/

w"-



;"R-zx

>z >fi'RRzVzKw"bz"I--w"y-j"bw6xfizou/zozK

zo}"%6w6bw6x2y{zK
w"2i/>
pr}z-p'u/'zob}"%zz4-zKb{

w6xfi^"z}"zofizK--z"bw62d--'bw"-'j"bw6{2'ow"yo-yw6-y
z#
' 2w6{ p
z#'zo-zow6 "-'bw"2';"pw6{"z
m}-yy{x2w"{zK{x2y{zor-'w"-zo~%z-{zoV-3w"yzK8zxfizo''zoV-zzo*"-Vz
2w6w4Vr]/zo"zoK
-VzKw"-z--yxfiz-w"--y{zK{ow"-{

-zw-dm
{ 6w"yz
wKw"y'--ow6'z^"zo-' w-zou/"
w" zK"zKyyI-"x8w6x2y{-w]"zw-{
mc
{ 6w"yz^p

-z-b'zob

Vy{j"zw"y{""p{-}'z"w"y/'
zKw"yy

zzo'b-w6-yxez2'zK

m{xezKow"2'z*

"-{ozz-%w]"zKw"

"z")%VzK

'zo6w"y-w6'zzK*z2wK"zw"y'2-'zK/'

"/-zw"y{""b{2-zozK-z-zofizK--zK-z'zK'-''zKw"

w"-

"w"p

--{

v-zbzK-y{"VzK'zz4ezopzK#w6z-'8ywK"zKvw6x2y{z
fizoj"bw"-zzKw"zw"2zKw"b-w6w6x8w"'zb{''zK

"6

vzxfizK'3w"y-zj"zKw"p

xfiy
w"2z'zK-xfizK'}3w"y-z

{w"yoovzK'zzKb-y{--ow6'z-w6**zKw6bbzo4zr

'2w"z"4}x2-w6{

{zj/VzK"b--{I2Vfizo{{"z}r{zKezKV'"zow"y{""b{-o~*2y{z

(+*!,fiIw"y{""p{-"2b-'zKAw"zfi]/zoj2yfiw"2"z2-w6{-w"yy{'zK2{"z^C'zKw6bp
zKp'}z '2w"z""w"-I^'Vwy{zKzoz4'zKo"z*"z*;"pzKcr)r
w"y{""b{2]fizoj"b
xfizo''zor2w"
-fiI'zow"'zKorOx2'zo"z2w6xfi"M(+*!
, fiIw"-Mr)
fizoj"b xfizo''zor-w"

-fiI 'zob"m{ ;-ow"'zKj2"z"
[^a

fi{22#8

Np




PRQSHKJTM

R PR
PR
P
k R

F


;QL
6@66
]] l
\ [^\

] [ ]

] _

Q
v6v6

v$@vv6

` 3
n \
` n [6_

^ \
\]\
l _
[ l

a` n K
\ ["_ l
` ^ n

LQ

PRQSHKJTM
R PR
PR
P
k R

F


OS

l [ m^l \

!

\ [ \
l]l ]]
l [3a n _

` ^l _ n
` ^l \

l^l

v6Q

v$L

\ ]

l^l n [
l^lKm l

F


P
R R
PR
P
k R

F


P
R R
PR
P
k R

F


QQ

n a^a]\^a

_"` l [ l
` \3_Ka3_

Q

v6O

] K
_ \]\
n]m \][
n l
p] n _
p] Kn3l

6 6

p n
p ["_ \

LU

T^ n^l _

]
l
[ [ ^
lKn _

6

gQ

l ]
l \ n

lKm K
l n _
lKn [][ n
[ [

v$

J H N
l n^
a` ]
a` _ m]n

v L

[ [
l

LQ

Q6@

` _[
a` _ n [
` a]a^aK[

T^ _ [
n]m _
n]m \][6_

UO

[ m3l

n^n]n^n
` _ m^

QQ

66v66

l l
_"`_ ]
_ [
a` \ n \

l a]a]\



l p _









[^\
[6_

l

n

[^\



[^\
l [

[
[

n ` l ]
]



\3_

[

n
_

n
[


n

l



]n






n



n




]



\

^

l

n




_


l

l

^






n



n
[

\

\K[

l
n






lKn

n






[

n



l

]l

_ n




n



[ l
l

n

[

_

[ l
[



n
[

n



\3_
_ l

\



\

]

]n ` l \K[
]n ` [^a l]n

n

n




L

$O

n




p

[][

` \ lKm




n

[



n





[^\

_

l




[

[6_
]





[6_







\

lKn








\

U

L6F66

n

n


_



[6_


[ l
l]







]

_
[

HKLQn "NbJ

6 v6

P


l]n]n]n

;QQ

PRQSHKJTM
P
R R
PR
P
k R


"

n]n]n




n

vw6x2y{z"6~zoj"bw"-zzKw"zK;"r-SfizozKyzKw6b-w"y{""b-

v-z;-

'zop{zK"z4fizobzK#w6''zK-'

b{2w-w6w"'zor-b
"bzo'

V-SfizozK#rj

zo3w"y2w6'zzxfizK-wK4{""zw"zw"y{"6

z'bw"-'zo-zK'y{zKw6pzzo*"8

'R/z2wK"z2-'zK-zh%VzK
f/Vw"-m{

3w"y-zK"zzou/" 'b-

zyzKw6bzK-w-w6w6x2w"'z"2{zK'fizK'w-SfizozK-w6w6x8w"'z"~j"zVyw6b

-w"


z'bw"-'zoO-zVyw6b|6""-w6w6x2w"z2'zK-bzo{2y{"8w"2z'zK''zoOj"bzK
z|6""z4row"zKrzVyw6b-w6w6x2w"'zfij"xfi" -pw"-z}w"-
z"Rz}2"z-w6w6x2w"zKr2w6r/z-w]"zxfizozK
-w6w6x2w"zKw"z'zK'zoo

x#

rw"y2-zoK4/z'zKyzK'zK

--w"z'bw"2'zoOw"-w"-"zor"A-zK'z

vzzKb-y{w6z^vCw6x8y{zo
[^a



zow"

"x8'zo"z2w6zo

fiB CD-FEHGJI*LKebSHEME-ONQPCSR

NSCQT2QNSTUCOFEMNSD-p-HV
WYX[ZA\O

w6z}w"2w"y{""-'zzKb-y{"x-w"zKvw6x2y{z"68zoz-z}w"z}2w6w6x2w"'zKr*zoz-'zKj"
'bw"2w"2'zK'^*zo"zoK

-Oow"'z
2fi


w"y'fizo;"pVxezo''zo2w"i(.*,fi


r)t'zob"<m{R8vzozoj"z"-z"#4xfizK-w]{"r"rw"y{""p{-

w"-

ow"--"xfiz}w6''b{x2-'zK'

]"zob-'

PRQSHKJTM
PR
PR
P
k R

F


P
R
PR
P
k R

F


P
R
R
P


P
k R

F






Nb

n]n]n


vv6

;Q
v !

vv66v

Km3l

[ \ l

$UQ

J H N
K
p ]
_ l
[ [6_
T] n^n [
p [ m^l^

U
v 6

K
6
[ _
\ ]
\
]] n]m

` l ^
[ a^a
` l ^
[ \ l
a` l]] _

] _
\^\
l]n^l

L U

U

6v6

Qv6

[ n a]\
lKn3Km

` l _K\

a` [^[ l
_"`_ n
a` n \

[ n ^

p \ ^l

a` [^[^\3_

HKLQn "NbJ
l ] \ l
QQ
[ l l
l

Q v6

L6F6
Kn ` [ _ n
Kn ` l^l [ ]
n
` \^a ]l \

;QQ

l 3
_ n^
l]n \]\^a n
[ ^

l a][

ULQ

6

l p l \

Kn ` l _oa3_K\

vw6x2y{zo~*zoj"bw"2z}zKw"bzK;"z}y{zKw6b2w"y{""b{---w2SezobzK'zK'r'zo
'2w6bz
-w"yy{"
*z-wK"zow6bb{zK w"-"zo'zop{zKO"%zfizobzKo
r-b w"

-fiI w"y""b{-
{ zw"y""b{-
-"fi'zK x - "zop so6"OopC-w6zKw6bbzK z
%*
j-b

'8w"z" -ow"z"*/z-wK"z
/zoz

u/"z

'zKy{zK'zK

--{{



- "zop#p

-w6w"'zo-'zKx#

fizobzK#w"yA--{-O'zzKb{xfizK

-zr-'z
"'zKw"-



T"bzo'w6-2Kw6'z

- "zopSgO/" 8C*z2'zK

w-p{"z'-{6w"y{zK#rw"8y{zoz"A'zK

w"-

--#
ze%VzK

z
"p

w''b-bz-p{""g"-8rzoz

}-z-xfizo"jzoz2w6bw"zo'zobz"zo^"zoK/z-'zK-"zbw"-

"-z"p{-w"y-w6w6x2w"'zKK
zKw"b#w"--w6-2Kw6'zKy{]3
j"Vr-'z
"'zKw"-

w"-

-x2'zo

"z'"w"yA-w6w|66ow"zK

"";"2pvw6x2y{zK|-'8ywK4zwK"zobw6"z6w"yzKrw"Vz

-"z2w6w"'zo"%zzKyw6{"z2]"zKzK#"%zfizo'uow"'zb"z"x-w"-zK
fizo'uow"'z"z"%fiIA
w"O/zKyyw"Ozbw6{"zz'fizK#Ox#

fiI

x#


-fiI

'z

'-zz'fizKVx#


-fiIR
zw"y'-]
vw6x2y{zK|z}"zKe2-6w"yzK"x2w"zKx%-"zob2

-y{z}-w6w"zop%j"z}8w6b'xfizou/zozK2le-fiIw"y{""p{-w"-fiIR
zw]}"x2zo"z%-w6z*xfizK-w]""fi
-fiIw"-ele-fiI'zo-w6A-{ezozK#o~Cw"y

xfi"w"y{""b-w6z"bzzo{zK#-w" fiIRC{'zozK'-2w6:l82fi
b-2Ojw"''zo}-w"

-fiIR


{bzK'fizK'

zfizK{"zKzKKxfi"


-fiI
[^a

w"-le-fiI

"x-w"zw"y{zw"z

fi{22#8

PR]NpJ
NbQSHL]N

N
HTH
N G TN

MqJ `






J 6



C PR


PR
LMVN
H L
`n [
` n]n3l

n ` n]n^n]n
n `n l

MAJ `


PR
LMON
L
HT

n ` n]n^n]n
n `n

`a

^NbJ

NbQSHL]N

` _

vw6x2y{zK|~/2w6b'{%2 "zobSg%*"2y{zo'zK*O

'y-{

w"fi


"zow"I
-fiI
fizoj"b/"b'z-w"

r-'z
"'zK-w"

z

'fizo;"p}fiIj
fiIR%T

-

2]"zKzK#pO]/zo"zoKz

zKyw6"z

z-"z-w6w"zo2zozKeVzozKw"jle-fiI

w"ow"'z"fiz-SfizozK-zKrw6zw"yyjzo-yxfiz}wbzK-y{"

-SfizozK-zKzzfizobzKw"yAzoeVw"-w-p"z'4''zKw6zfizobzKw6{
zK'zw"y{""b{-O*-yxez-zKzKw6"bzo}'zK'w6x2y"zKzobw"yR2oy-{2w6xe-zK{
2w6pw6{"zxfizK-wK4{"K

h-~Sf~ ff
fi
z-wK"z


zo"zKy{"fizKwzo

y{4ow"y'zKw6pb

%wK"zKw"zou/"

y{zKw6b2

-w6{zK"'zKw6bb
zK''p'zK

w"y{""b{-/r{-z

''b2zKj


"zvO'zKw6pb

-w6w6x8w"'zKov-zw"jzKw6z"/}w"y{""p{-

z'8w"z"VOo/x2-'zKwzoj"b

Oo%-w6w"yy]2'

w6--w"pj"

'zKw6bp

zo{zK#y{
w

'2w"z

"zo2zK'zK#w6{


yw6'

z'2w"z"

z'-{6w"y{zK-zoyw"'zK"/o
--{
'2w"z
w"#

ow"

"z{2w6{ -pwzKfiw6x2y{z"p
-zK
2z'zoV"A"fizobw6'"bV-w6r-zo2z}-zzK{#xfi"b''b-bz}"RV'zKw6bp
xfiz"zKyow"yy

zK{#xe"p

/zw"#w"

zK''p'zK

w"-w6-fizK-z2w"z"OppEz"
*

x#

z2w6-w"yzo{zK-

z"A/zz2y"zw

*z

2w6*y{4ow"y"zKK

"zzK-2zK'zKw6pb

ow"

zo3w"y-w6'z

T-/w]"

-w6z'8w"z"/6fizobw"-
Iw6-zw"z
'2w"z"Ar{w

"zoyw"-2ow6fiz"r-bwK"-

'zVzKw6by{zKo{-zK"zO-{bzK{-ovzK'zVb-w6pw"'zob'o%w]zKy{'-zKzV'zKw6bp
-4zK'^/w6p-xfizo''zor-zou/" ''b-bzKo
v-zzfizobzKw"yfizKb-y{%^

-w6zKw6bb

zo{zK#y{w"-w"oobw6'zKybzK]"zoO2y{z

zo4x2w"'zKbzK''b'zK*OVow"

%wK"zKw"

zou/" ''b2zK%j

-w6w42w"2ow"

fizo'z%{'zo"zobw"y4'w6'z"--z%w6b%wK"zKbw"zo*" y{zKw6b-w"y{""b-o"w"y{-CzK
"{2{2ow"#y{-b]"zzKOOz4fizobzK#rJazKIw"O*zKyyw"O'z-2-'zK
x%2 "zobso6"Oop4zozK'fi#-A-w6'zKw6bpw"y{""p{-x2w"zK*ow""x2w"
yy{}xezo''zoAbzK-y{o6bzK'fizK'xfi"zfizK{"zKzKw"-zo{zK-"-w"'zKw6bpzo4-
x2w"'zK

Oo
zK'fizKow"yyj"r--y{''b-bzK4zKyz"{ezKy-w6Oow"xfizw"y'p

fizojzKy{zo-zK'zK#'zKx#
-b

w6z2yz

wp

#w"

w"#



zxfizKy{zo"z-w6*Oow"w"y'xfiz2'zoj2yRw"-
6w6bw6x8y{zKw"-

2yow6'zK

zofizK-zK-z2w6''zob2pw"-

'2w6p'zjzo-zKzKw"-zofizK--zK-zrbzKyw6{-2{2pp
"%zrzK'zKw6bp
4*zOw6zV2yw"-2'#'zo"bw6'zr-zr'zKp--'zK/zo"zKy{"fizK-R2w6fizo
{2"zfi]/zoj2y
'zKw6bbzo4-o--pw"z-zK--zozKx#}%yw"-zow"yso6"|p
zVw"fiRzo%w"y8so6"Oo"/-zV%w"fiw"2-zowso6"owp/r-2{{-w"yy"zVy{#R"
z
zK2y{%"x-w"zKxzo4x2-w6{vw6x2dazKw6bp
2{wKxez'zozK'
-"be"pw6'zVw""-zo"ezopw6'"K-p-yzK{zo%xfizVwoyw"bow"yfiw6bOzo"zobbw"yfi"%z-"

[^aK[

fiB CD-FEHGJI*LKebSHEME-ONQPCSR

'fizKo{2"fizobw6'"'

zK']

w6-2yow6{"w"y{""b-

NSCQT2QNSTUCOFEMNSD-p-HV
WYX[ZA\O

zw"y#'zK- '/"
zw"-w6-w6{w"-

'zKw"yI-"x2y{zK/z-zKy"oyw"b{2ow6{


4u

8w6''zob-o

fi<~MH
wsvr

v-/" 2w"%xezozKb-fi"'zKx#zca2w"-bh

-'zob{-z{zK-owvCzKoy{"

w"-z

w"-p-w--zo%R@'zK%vYo6"oO]6|^T^

-#wz%-2-w"zK/z%w"'yyw3{w:

w"-~*uOo^u"OoCzK'fizK{"zKy{"

"z


zw6z"bw6'zo-y'yy{zKw6z


#3w"y-w6x2y{zzKy{r{z}2y{zKzK#w6{"A'zo"zopw"yw"y{""b-o


zozw"4-zozo*zob;"2'zoj2y
zK#w"-b""zK'{-K


zobwj"-

zw6z}w"y'"bw6'zo-yI'z

!
f"
#

rx-bw"'IV{<*b]
{<-2#"C{<p
''zK
Vo
zae{p

z%w"fio.{RRso6""pj{IzKw6b2p{O{ozK

87zff 62;ff:9 (

#x-bzo4y{"""
Vo
.afi{fip

Uy{zo]C{R* "pVw"y{8-zoK~



ff$&%ff!'%H #)( %H " *"( '%H +" (-,.(

j";"bzKow"''zo"zobz//zKw6zoK

ff %#

%<;A! # =

%wK"zKw"

%0/21324#O]65]6

xfizKy{zoR-zou/" OxzKw"2O"*w

$&%ff ">"$# / ff>%Hff'13 ? 30@3fi|6OA5|4K

z%w"fiofi{R.Aso6"]pr##x2bzo-y"";"Oy{zKw6b-xfizKy{zozou/" 4o~

/zKzK2oB$&%ff&%HO C# ( %fi "*D( '%H "E(-,

V-zob
ae{w"2{w"
-{Hp

;BFGFH (AH#JI

;O%%H "%P(!,

/zK-yb
*p{3a4zop-o/}8{%-wK"zo"rf
-{'"b-''zK~

S$&% Tw ( ffffVU #
# #fi
% ffoo3Q]65o""

-zou/" K

OffLKff %>(

zobyw"I O]"p%

yzK-z}oyw"zK;"rw"oy-{"bw68-o

\ Vff U

# "

ff % #

% # 0% /M14NKHo"|"A5o"o

-w6bw"'zob{Kw6"

H #&% # %

1Q4R6e6A53-6

w6 "^z'-{6w3

/"fizoK r p vzw"yw6b
ow"'zV'-{*-"x8w6x2y-;zozK2z'zKb--&'#zKR;"*xezKy{zo

% (!,
%0/ W

{p

>ffYXw ( FSff 2%[Z

( % , ff! ff>%fiff ( % ;A! # =

# "

$&%ff " "$# Q/ ff>%fiff # %

%-zo]{myyzoK#{4-zKyyafi{p mw"-w6KwK%w4mfi O]"pV-w6-"z-"x8w6x2y%zou/" 4
r{---zK6w6bw6x8y{zKo \ ! # %fiff]7zffL&% # %0/M140?"Ho4K|A5o3"
{w6bbw^ w6w4Cso6"|p{zKw6b--}%w]"zKw" -zou/" }z'2w"z"
'b-zKVxzK'w6 "*-''bx2{w"y{""p{-o:$&%ff&
%HO #C( %fi "*"( '%H "(!, $&%ff " "$#`_
/ff>%f % ff I% 1B3Mbfi6o A5o6o 4

%yw"-}{ Kw4I{p

/- 6w6zoo}3}4 "|pH*zKy{zo-zou/" 4-''b-2-z/--
2b-o{8y{z"7ff 62 ff9 ( ff %# %cZ (MI Ffiffc H # ffd%Hff>1eNVfgNo8-&5
/- 6w6zoo}
"pihA2aff %# 2%

ff "# ff

, %fiffCj ( l k >% m8, 2(


(%

% 2U #)(

zKp{-{y{zK"

% ( # % , ff;ffd%Hffo
g

-zKo-V-{"zobb{u"r'zKpo

%-#z"

% (!,
n$&%TY ( fffflU # 0% /
$&%ff ">"# Q/ ffd%Hffo2oA564

2 4]pIvzo"zo2zKzKA".%wK"zKw"zo*" 4o

Z ( % , ff;ffd%Hff ( %qp%Hff!! # % Ca # r
% ;A # =

# "

%-#z" *
3#pOezopw6{-V;"y{zKw6b--r{
$&%Hff ">"# /Qdff %HffKff % ffL 14KA5oo"
[^a l

"bw62-ow"yAzKyo

>ff3 fiffdoLffd%>

*"( '%H
" (-, ;A # =

# "

fi{22#8

%-#z"

$-XXQX


"p

% O6 #C(

U2%



%

2z'zVy{'zobw6bzy{zKw6b---"x2w6x8y'/-zou/" /j

%i(

%rsP% ( j " ffVUA/Qff
2%tUiu Xv%0/ # fi% ffff! # 0% /M1Qb""A5o4o4

-w6w4

%zK- {z/zKyyE}{p

{I * O]"pr w"y""b{- j"c%wK"zKw"xfizKy{zo-zou/"
2w6w4B$&%rTw (
ffffVU # %0/ %i(!, ;O$2%+Uh 0;]w ?DNofi"|A564

'b-{j

4

v

-{
/zKyy*{
p
{
V
p

{IzKw6b2i
%wK"zKw" -zou/"
j
-w6w4~ V
zo{zKrw6--w"px2w"'zKj"bw6{-zo""vCzKb
-bzoI{2V-{"zobu"AVy{xfizow4

%zK-

%- "zob-2fi

"pr

%- "zob-%w "p{zKw6b-

jfff " , >zZ

>Sff

%- "zob-%wso6"Oop{zKw6b-

*D( '%H E" (-, \

%- "zob-^v

# fi
% ff]7zff &% #

{"VzK"zoK3{Op

zo2Vw"2

( l k

%^eV{.p

z'#-3w"y{zK2zoyw"'zK"%wK"zKw"

# "

-zou/"

( % , ff! ff>%Hff ( %{pE%Hff # % Ca #
% ;A # =

z'#-3w"y{zK2zoyw"'zK"%wK"zKw"

% ffL;! 184-"A5

# "

-zou/"

zo

# "

''b--zKo

$&%ff ">"$# / ff>%Hff
''b--zKo

rzK "zobw"
"4 "pQ{zKw6b-Y%wK"zKbw"-zou/" K~azKw6bp

# %HL'a~T&FSff! %}(!,
L$&%w
ff "$#J
$&%ff ">"$# / ff>%Hff:M%+Uh # % # % "oA58o

z4fizobzK#w"yzK-yo

( F ( %r;A! # =

%

%0/}Kff

( % , ff! ff>%Hff ( %WpE%Hff # % Ca # P
% ;A # =

>ffX " ffdoLff>%H>xZ

$&%Hff ">"# /Qffd%HffoHO]65
% (!,
$&%TY ( fffflU # 0% /
K6|8
5 KO]#

"Az'#2{3w"yzK%w]"zKw"

'pw"-'j"bw6{-w"yb-w6bw"'zop{Kw6{

% (-,
G$&%PTw ( ffffVU # 0% / v

/" ''b2zKo

. # , ><$&%ff&%fi #C( H% "
>ff )

{C
8V "p-2Kw6--zo'z}-"x2w6x2y{u-''p{x2{2*r{zofizK4
% ( %r$&% ,>( )# ( %9zff ( ' a|1v3df-A
8$-XQXQX2;2 % % )# ( %
5O#
]

-zK-z'zozKo

/"fizoK" {p rzob;"^{KO op
-zou/" ;b
-w6w4
O! # fiff ff L

\

Ow"
{Qp

Vb-KozKy

zKyj

#

%r;A! # =

# "

% ]7

2 pe

x-bw"##zw"y{""b{-j"Az-''p-{"8ow"2w"y

% (!,
2w6b'z-w6w4O$&%Y
( fffflU # % /
$&%ff ">"# Q/ ffd%HffooA58

zw"fio{% p -zofizK-zK-
2zK'zK

%wK"zKbw"zo4j"Cz/--2{O"-"x2w6x8y'

'% # 0% /21v?68|6OA5|3

zou/" 4o

30@3e4"&53







zff

Kff d% ( % # 0% /21vG36Ho4&5|4"6



r$&%

(

ff # "
; ! # = # "

$&%ff " "$# Q/ ff>%fiff'1

2 so6"OopVy
&%fi #C( H% "8*"( '%H "8(!, ;8F FH (6H#JI ff

{
z b w"--zo{--w4 L{ w"zo" -^{Op
"2{Kw6{ ;"
y{zKw6b- %wK"zKw"zo*"o
ff

e

( % , ff! ff>%fiff ( %p%fiff!! # % Ca

zKyw6{2-{2Ow"-y{zKw6b-w"y{""b{2j"-y{

*D( &%fi
" (!, X H FUff! `# >ff %H " 2%+U



z/w"fio@{@

. # , ffffd%>Z
>ff ~

-zow4 -@

n

zw"fioH{H{ zob w"-zo{2-w4 -fi {fip
*zow4 H so6"OopA{I4ow"y'zKw6pbzo4-
j"}y{zKw6p-}
%wK"zKw"zou/" 4}-bw4-{-zKzK{#xfi"b z2w"z"/2w6o

7ff 62 ff:9 (

z

ff %#

%w"fio{Rw{
zKw6bb

w"y{""p{-

%Z (2I FHSff!c fi # ff>%Hff'140R24+NoCoA58o


e



-zow4 wso6"|pr {'zobw6'zK y{4ow"y
zob w"2zo{-2w4 Y{3p
;"y{zKw6b2d%wK"zKbw" zou/" 4{zK'w6x2w"zK-2{{-w"y

v$&%ff!'%H #)( %H " *D( &%fi " (!, $&%Hff ">"# Q/ ffd%~

-zofizK-zK-zV'zK'o

[^a]\

% ff
%

183Mb"fioo4&5o"|"

fiB CD-FEHGJI*LKebSHEME-ONQPCSR

z%w"fio{fi

w" zo"ff-8{.p

{


xw"y{#"-bw6{
~

Z (MI Ffi # %0/

n

zow4 fiA-bzKpp{IzKw6p-e%wK"zKbw"zou/" 4

azKw6bb2u/

Q

z%w"fio<{R<{~p

NSCQT2QNSTUCOFEMNSD-p-HV
WYX[ZA\O

-{ezozK#'2w"zKo

\

>Gj~L ffJ2%+U

(!,



Vzo'z" % O]"p Oz2'z"-zofizK-zK-zbzKyw6{-2{2j"
yzKw6b-8y{-zKxfizKyzo-zou/" K
ff! H # H "
H "
ff " "$# ff w % ff %


P$&%

A5

" oo
z%w"fioO{O{Qp

'%

)( % Q*"( '% (!, $&%

13M4

/ >%

"
zo w6--w"pj"Ry{zKw6b--xfizKy{zo-zo*"R2
$&%ff!'%H #)( %H " *D( &%fi "E(!, ;BF Ffi (6HO#`I ffPKff %>( % # %0/M14Af"&5|O]#

Vzo'z" 2so6""pe

-zofizK-zK-zOb{'zopw4
z%w"fio<{R<{~p
-zou/" -b

Q

Vzo'z" so6""p r
--]4w6ow"-bw"y"b-zob};"
%wK"zKw"
"zKzo w"y{""b{2w"-
-yw6'zKw"2zKw"y
w ffff # %
>Sff

$&%T ( VU %0/ W(!,

X # / Q>x$-T \ pZ ( % , ff! ff>%Hff8|"|"|A5|34

z%w"eKz{Rz

#

{p*zow4 z

*so6"]p}a'4b2w"'y{4ow"yAw"-2''b{x8'zK

zKw6bbw"y{"6

g$&%TY ( fffflU # %/ %](-, >ff8$-$-$$&%Hff!'%H #)( %H " F (@%#
I%>m X8o (L" #)( %HL'aZ (MI Ffi #C( % 2%tU~TY ( #>"$#&% # W[;&F # " \ ( Uff "

p{-j"y{zKw6b-rxfizKyzo2zou/" 4o

( %W;UO&Ffi # oLff
A5

% ff

oO 8"K



zw"fio{{)pzow4 %so6"]pMa'p-w"'y{4ow"yR'zKw6bpw"y{""p{-j"yzKw6b4

}7zff2;ff9 (

xfizKy{zozo*"o~jazKw6bb2z'2w"z"%"bzobo

$&%Hff ">"# Q/ ffd%Hff>1Q403dffiooA5o"|

V"K{p

vw6bEz op

8y{zw"y{""p{-

ff %j#

%y;A # =

# "

'-''p-w-'zKz4'zK-{"%w

8w6w"yy{V"b{zK#'zK"pw62
vCzKb
3zoI]b"#/"-{"z[a4''zKz{Cw6xfi"bw6'"""Vzo2w6zK#
"/2'zo3a4o{zK2z"2OY{
bzK-w"
Uu{Hp

Vy-'K-oC "pw{IzKw6p-
%wK"zKw"

% (!,
$&%TY ( fffflU # 0% /
o"oA
5 o"o

jfff " , >zZ

>Sff

zo*"{y{4ow"yI''b2z"

( % , ff! ff>%Hff ( %{pE%Hff # % Ca #
% ;A # =

# "

$&%ff ">"$# / ff>%Hff

myy{zoK8so6""p/zK-c%wK"zKw"w6xfiRzou/" ''p-z"n$&%TY ( fffflU #
>ff: #H ffff>%>Z ( % , ff;ffd%Hff ( %qpE%Hff # %Ca # %;A! # = # " $&%ff " "$# /Qff>%fifffio6&5o4o4

bzK-w"
u{p

(-,



z zoK
pA{IzKw6b-%wK"zKw"
bzK-w"
u{.urw"p-w"
ep{.p
w"{"z-w6w"'zoo~v-z "'2w6bzow"---w6'z w"y{""p{-
w

L

Z ( % , ff;ffd%Hff ( %qp%Hff!! # % Ca # r
% ;A # =

VzK{"zo]fi{+p

rzK "zopw"
"p

# "

# "

$&%Hff

zKw6by"2 6pz{zKw6b--Oow"2w"y-'zozK;b
% (-, ;;O;$ _ ?G@3H]]3|5]]6
$&%rTY ( fffflU # % /

VzK{"zo]#{w6"4}{p

#
*D( '%H E" (-, $&%ff ">"$# / ff>%~ % ff I% 1Bb"Ho"|4&5o3Q]#

>ffOX " ff>off>%>Z

( % , ff;ffd%Hff

zofizK-zK2z%;"pw6{


x$&%ff&%fi #C( %H

VzK{"zo]C{w6"}{pzKw6by "|p}{IzKw6b-2yzow"2w"yR''b2zKo

[^a3_

. # , ffff>%H>
>ff )

"RzVbb2y{zo-'b{x2{

% (!,
$&%~TY ( fffflU # 0% / L
">"# /Qffd%Hffo"A
5 o6]#

w622yow6{'y{zKw6b--c%wK"zKw"-zou/" K

( % pE%Hff!! # H% Ca #
% ;q # =

%

-zou/" ''b--zj

% (-,
6
e$&%YT ( ffffVU # 0% /
$&%ff ">"# Q/ ffd%Hffoo6A5o4K

p-w6bw"'zobw6{

%0/

"

fi{22#8

Oyy'2z"wae[r{qp

zobyw"


/so6"]p|-zobw6-

% (!,
w"4oy2{"bw62-4zKyo+$&%Tw ( ffffVU # 0
%/]
# %r;A! # = # " $&%ff ">"# /Qffd%Hffo6]&8
5 6]]#



w6 "]

z'#-3w"y{zK2z

oyw"zK"

>Sff3 fiff>off>%ffff>%><Z ( % , ff! ff>%Hff ( %cp%fiff!! #
% Ca

:QKA ; *D( '%H E" (-, Z (2I FHS # %/21B36C6|5o6

Oy{^"zoK pvw6x2'zKw6bp
8w6
rzK "zobw"I*% "p0/w]"zKw"

zo*"j"4^y{zK"z-^"zo"

*w6'zo;ga-w62{a4#
4r#-b-w"

ff&a}2%+Uu

\ # % # 0% /"8w"}x-p"z"~~Tv

rzK "zobw"I8{eVzK{"zo]-{fip

+;eUMo@2%Hff

22op

A5

Tn wKw"


%sP% ( j " ffVU6/ff]u

%q#

zKooO]6| |6

%-"zobH

\

O! # fi
% ff7ff L'% #

Z (2I FHSff! _ % Vff UrFH ( Q #>"# % #
%fiffCj
zK-ow"yITj"bw6da4o{zK-zKo.aw"j"br2{"zob{"

rzob;"]4{oY 4]p

( l k



%


(%

%0/214@3CO]65o3|

% 2U6 #C( 2
%
g

/"fizoKR 6pbm}w6 ~rzK#'"##ub"zK'4''zK
'b-{"A-"x2w6x2y'Vz4fizo'4''zKr;b-w6w6x2w"zKo
w ffff #

Z ( % , ff;ffd%Hff ( %qp%Hff!! # % Ca # r
% ;A # =

8
z %w"fiof{R) "|p
Z M( Ffiffc H # ffd%Hff>1eNVfgNo6|58"

Vzo'z" - {wp

"zK2'zK


{zKw6b--

-zKo

;"z4

% (-,
O$&%YT ( VU %0/

$&%ff ">"# Q/ ffd%Hffo235o

# "

(o_

"pf{zKw6b-
%wK"zKbw"zo*"o~*vz

x22w6{"^y{zK"zw"-'w6ow"yI-w6w4

rzob;"]4{o){)p

#%

>ff #H >

7zff2 ff~9 (

ow"-bw"yfiy{#'bzozKo

v;]%$&%2 ( ULU6 #C( %0 ( hA2aff %# 2%r9:ffCj ( l k

UC "p

ff %h#

%

% /Ow{RzKbo

m4 6w4
v{.p%w"'zKy{e}so6"]p -b]"zK y{zKw6b--"~%wK"zKw" zou/" K$&%TY ( fffflU #
(-, >ff: fidff oL>ff %Hff>ff %H>y
Z ( % , ff;d
ff %Hff ( %qp%Hff!! # %Ca # %r;A # = # " $&%ff ">"# /Qffd%Hffoo"A5oO]6

%0/
%

m-w]EC{"2
{{I-}{ w"-y{zo"{pQ-zo"zoKm* 3#pdM{c~} w"b2z
yzKw6b-y{x-bw6 c
$&%Tw ( ffffVU # %0/ %(!, >ffM #H >$&%ff&%HO #C( %fi " Z ( % , ff;ffd%Hff ( %
(6(L"% j # >x
;A! # = # " $&%ff ">"$# />ff %Hff H]^|5]^|
m-yy{x2w" eae "p$&%
{w"

,>(

#)( 9
% zff

( ' a}2%tUh # %

# % *r^"zox2yow6{


{p%w"ob-o 3#p~{zKw6b-%wK"zKw"xezKy{zoIzou/" 4o-Vw62-w"bx2w"'zK
-z:q{-b2o{2y{z"
HS # H " ff ">"$# ff Hff
3fio" o"|

]Z (2I F

C( %

$&%

/ >% '13G@

A5

{w6bbw^ w6w4%C{/"Kw4w {Q-bw"zK-2#{w-w4*}{[p m- fizoboV "p a'p-z
yzKw6b-%"S%
wK"zKw"zo*"x#O"zKzow"y{""b{-o~Iezob;"bw"-zRw"-w"y{4fi"4'by
% ( %TOsff!' %;O%H " %# % 2
8w6bw"zo'zobo$-XQXQX
U;2
% % )# ( % <
%+U \ O! # %fi}
ff $&%ff ">"# /Qd
ff %H>ff 13 b"

4
5"

{w6bbw^ w6w4R{)m- 'fizoboAV{~p

w4R}/ "pi{zKw6b-M/w]"zKw"

zo*"''b2zK

$-XQXX

xzKw6bb-;"zxfizK'"bzob"zK-zow"y{""b{-o



% ff

1 \ 2 %i2%+UWZEaff&%fiff # % Q
1 4"3-O]65"|

S;2% % #)(

w"-{w"
e{er2zob'
Hafi2}{ezobyw"
fie{.p|Ay-;"eV2v "p%wK"zKw"
w]"zobw6

Z (MII " %

w"-

# #)(

%

4zKy'zKy{zK

%# J
% #&% # %L

;"bw6 "^

zSff ( '

[^a]a

2%+U

\

z'#2{3w"yzK-z

ff>

% ( %
%

4zKy

oyw"'zK"w"4oy-"bw62-o

(U%
1 40R6fio3"|A5o"o64

fiB CD-FEHGJI*LKebSHEME-ONQPCSR



w"-{w"
e{.p

rw6;'zo"fi 3#p3-zKy'zKy{zKw"-

g-]}

"bw68-ow"ye-zKy%-Ooow"

# #C(

NSCQT2QNSTUCOFEMNSD-p-HV
WYX[ZA\O

%1bG?6K"|"A58K3

w"o-j"r4zKyC--zow"#u

*"( '%H " (!,

>ffO;



; %%>(2_

ff! # 2%M # % # %

zoz8VOr
"p
w"2w"y-;zozK2zw"-ow"2w"yz42yw"2w6{
%
2
x w" "-24]ry{zK"z"
% (!, >ff}X " ffdoLffd%>Z ( % , ff! ff>%Hff ( %p%fiff!! # %Ca # %;q # = # " $&%ff ">"$# /ff>%Hff
$&%cTw ( ffffVU # %0/ <

A5

| -o4



-'zK2w"
R{fp

%w]"zKw"
"zobo

w"
R%so6""p~o{zK#b"zEx2w"'zKy{zKw6b2"rz'#-3w"y{zK2zoyw"zK"

B7zff2 ff:9 (

zou/" 4o

ff %#

# "

$&%ff " "$# / ff>%Hff'1B3G? 3G@3."A58o

{U{w";"zo"UmV{p{Izo4{'ovfi p){zKw6b--%wK"zKbw"zou/" 4%;b

8y{zo'z}-w6wr{''4b-w"'zKw6bp

( % pE%Hff!! # H% Ca # <
% ;q # =

ffd%Hff

: pTY (
$&% , ff;ffd%Hffo[a4w"d

zKw6by

G
(-,

%r;A! # =

# "

% (!,
$&%<TY ( fffflU # 0% /
">"# /Qffd%HffoQ]6A
5 "

w"y""b{-K

$&%Hff

%>m
# "$#&% # yKff %d( % # %0/ # %$&%ff ">"# Q
/ ffd%
% ff
w6'zo~w"w"Mmw"w"-


. # , ffff>%>Z
>ff ~

% (!,
9:ffCj ( l k

-

( % , ff _

" L %# " ff

$&%iTY ( fffflU # 0% /

zKw6by -{pAzopw4vOae 6pH~'-{6w"y{zK-z/w"-'4zKb"eow"-w"y44zKyo

>ff: #H >Z



-zow4 @

( % , ff;ffd%Hff ( %qpE%Hff # % Ca #
% ;A! # =

# "

$&%ff " "$# Q/ ff>%fiffoo6|5ooO]#

%

\[ff ( U (@%Y"( " ff % a:U #&% 2 # ! # U (@% FL; " c ( % % 2U # ( %UffY;fflUff % Uff ffff>%fi #
aWU # % Ij# % a2w"-8pIgCzKKVzo2w6bzK"V/2'zojao{zK-z

so6"]p

ff % # %

w"2b{2ow"yfi 'zKyy{"zK-z"-V-{"zobb{u"RObw"-w"-w4

azox8w"'w"-
O]"p
{ zKw6p-%wK"zKw"-zou/" ;

% (!, > ffz # ffff>%>Z ( % , ff;ffd%Hff ( %zpE%Hff # %Ca
2w6w6x2w"'zKox$&%yTw ( ffV
ff U # %0/ x
$&%Hff ">"# /Qffd%Hoff -&5O

w"-

{dp

22y{zo'z

#

%y;A # =

# "

zKw6byffC O"
] prvzzK^"zo"Row"-w"yfiy{E'bzozKj'w6'ow"y2w6w4/
{ u}Um}w"-w"yvaeS{Izo4{'o- S{zKzo}22opvp%fiff!! # %Ca # %;q # = # " $&%ff " "$# /Qff>%fiffL"
V''zop-w"~~r
u "4uryyw"-ISoooA5oo

zox8w"z"fi{.p

a4p%w6"2
O]Lp*'w6zO-zK2{"Iw4zKy;O%%fi "n%(!, # % # %
a4-
{qp Rw"y{'"bw4q "|p V w"y{""b{2 j"-z -'b-{
/"
'b-zK/j -w6w4$&%Tw ( ffffVU # %0/ %P(-, >ffO9 # %>WZ ( % , ff! ff>%Hff
;q # = # " $&%Hff ">"# /Qdff %Hffoo"A5o""
a4-
U{pRw"y'"w4fi


%d(

1B64&53

"%wK"zKw"

( %pE%Hff # % Ca # %

C "p%%-''b-"%w]"zKw"-zou/" ''b-bzK%;-w6w4~

$&%ff!'%H #)( %H " *"( '%H " (-, ;BF Ffi (6HO#`I

x-b{zoIb"zow"2w"zo{zKw"y{""p{-

% # 0% /218324C""&58K|46

a2'zKo{2Oy{4K4V{pa4b-zKzKoe "|pZ<L % C# (
u "'zKVd
r
w6'o4
6r
u zoR" e
~[
-p"zowAzobyw6
a2'zKo{<p

zo

zoz8RV* "p

{zKw6b-

%1TY;fflU

# #)( b
% 2%tUj fiff {zKz

%w]"zKw"zou/" 4{

-zo'z3w6bw6x2y{zKOj

x$&%WTY ( fffflU # %/ %~(!, >Sff .~# % 8$&%Hff!'%H #)( %H " Z ( % , ff! ff>%Hff ( %WsP% ( j " fflU6/Qffu
M%+Uu \ # % # %/"o35o

2w6w4

[^a

ffKff

#%

( oLff&a

_

fi{22#8

a'zK8so6""p8O}z*2'z"-;"zKyzo'-zK}yzKw6b-c%wK"zKw"-zou/" KD$&%TY ( fffflU #
(-, >ff: # H ff>ff %>
Z ( % , ff;d
ff %Hff ( %qpE%Hff # %C # %;A! # = # " $&%ff " "$# /Q>ff %fiff e"A
5""
a4KU- "|p/-''b2{"/w]"zKw"
% (!, >O
2b-o{8y{z"$&%TY ( ffl
ff U # %/ P
ff 9 # %>W
Z
/>ff %Hff H"o "A5oO6] |

zou/" 4j

-w6w6x2w"zKx2w"'zKzc

( % , ff! ff>%Hff ( %pE%Hff # % Ca #
% ;q # =

%0/
%

A{

$&%ff " "$#`_

# "

a4KU% "pi{IzKw6b2M%w]"zKw"xfizKy{zozou/" 4x2w"'zK -z--
zKp{-{
yzK" -b-o2y{z"~%r zo{zK#Ow"y{""b{-
-bz
Yp 'zKb--&'#z"L$&%TY (
fffflU # %0/ %x(!,
>Sff z # !ffd
ff %>
$&%ff& %fi C# ( %H " Z ( % , ff;d
ff %Hff ( % \ # %.
ff 7zff & % # %0/-A
5Q3
] 4

E
% (!,
( fffflU # 0% /


vw"I /so6""p
O]#

x2bw"-buw"-4Exfi--

>ff3 #H ffff>%H>YZ

w"y{""p{-

j"

q{

y{zKw6p-

( % , ff! ff>%Hff ( %pE%Hff # % Ca # }
% ;A! # =

%wK"zKbw"-zo*" 4o<$&%
# " $&%ff " "$# /Q>ff %fiff 6
|5

Azobw4Av{<p CzKw6py#-/ 6p w"-w"y-zou/" K~ea4zKw"ow"- z2zK{"zK-zKoTg
a-w"b#'zoKvae{zo{'oq{R umw"-w"yE]- 3{IzKzo2-oppE%Hff # %Ca # %;A # = # "
$&%Hff ">"# /Qdff %H>ff 1f2V''zob2w"~)
u "b4uyyw"-
2A5]6


zob
Au}{p





Bh )# (2I

w6x8y{zKo

+{R{+{w"

-

U;2%

{w"b'ozK
Aae "|p
ff2 # k
1Nd4fi"|O6
] 5"o


zKp{-{

% #)(

%

%i(

{zp

Vpw62-ow"yVw"-

zKobb{"z

{IzK2+m+afi przo"y{-w]

y{zK"

zKyj"-"zK-z

2-w6{w"-4

L$-XQXX

-b2o{2y{zOj"O2w6w-"*-"x2w6x8y'34^y{zK"z"

%YTsff&%r;O%H " %# % 2%+U

\

[ m]n

O! # %fiff$&%ff " "$# /Qff>%fiff'1436C6]^586]L

fiJournal Artificial Intelligence Research 18 (2003) 263-313

Submitted 08/02; published 04/03

Exploiting Contextual Independence Probabilistic Inference
David Poole

poole@cs.ubc.ca

Department Computer Science,
University British Columbia,
2366 Main Mall, Vancouver, B.C., Canada V6T 1Z4
http://www.cs.ubc.ca/spider/

Nevin Lianwen Zhang

lzhang@cs.ust.hk

Department Computer Science,
Hong Kong University Science Technology, Hong Kong,
http://www.cs.ust.hk/lzhang/

Abstract
Bayesian belief networks grown prominence provide compact representations many problems probabilistic inference appropriate, algorithms
exploit compactness. next step allow compact representations conditional
probabilities variable given parents. paper present representation
exploits contextual independence terms parent contexts; variables act parents may
depend value variables. internal representation terms contextual factors (confactors) simply pair context table. algorithm, contextual variable
elimination, based standard variable elimination algorithm eliminates non-query
variables turn, eliminating variable, tables need multiplied depend
context. algorithm reduces standard variable elimination contextual
independence structure exploit. show much efficient variable
elimination structure exploit. explain new method exploit
structure previous methods structured belief network inference analogous algorithm
uses trees.

1. Introduction
Probabilistic inference important many applications diagnosis, perception, user modelling,
anywhere uncertainty state world observations. Unfortunately
general probabilistic inference difficult computationally terms number probabilities need specified. Belief (Bayesian) networks (Pearl, 1988) representation
independence amongst random variables. interest independence useful
many domains, allow compact representations many practical problems,
algorithms exploit compact representations. Note even approximate inference
computationally difficult worst case (Dagum Luby, 1993).
Recently work extend belief networks allowing structured representations conditional probability variable given parents (DAmbrosio, 1995).
terms either causal independencies (Heckerman Breese, 1994; Zhang Poole, 1996), parametric forms sigmoidal Bayesian networks (Neal, 1992; Saul, Jaakkola Jordan, 1996),
exploiting contextual independencies inherent stating conditional probabilities terms
rules (Poole, 1993) trees (Smith, Holtzman Matheson, 1993; Boutilier, Friedman, Goldszmidt
Koller, 1996). paper show algorithm exploits conditional independence
2003 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiPOOLE & ZHANG

efficient inference belief networks extended also exploit contextual independence.
Poole (1997) provides earlier, less efficient, version terms rules. Zhang Poole (1999)
give abstract mathematical analysis contextual independence exploited inference.
Section 2 introduces belief networks algorithm, variable elimination (VE) (Zhang
Poole, 1994) Bucket Elimination belief assessment (Dechter, 1996), computing posterior
probabilities belief based nonlinear dynamic programming (Bertel Brioschi, 1972).
Section 3 presents representation conditional probabilities lets us state contextual independence terms confactors. Section 4 shows algorithm extended exploit
contextual independence confactors. Section 5 shows improve efficiency
reducing amount splitting. Section 6 gives empirical results standard random
networks. details experiments given Appendix A. Section 7 gives comparisons
proposals exploiting contextual independencies. Section 8 presents conclusions future
work.

2. Background
section present belief networks algorithm, variable elimination, compute
posterior probability set query variables given evidence.
2.1 Belief Networks
treat random variables primitive. use upper case letters denote random variables.
domain random variable X, written dom(X), set values. X random variable
v dom(X), write X=v mean proposition X value v. function dom
extended tuples variables. write tuples variables upper-case bold font. X tuple
variables, X1 , . . . , Xk , dom(X) cross product domains variables.
write X1 , . . . , Xk = v1 , . . . , vk X1 = v1 . . . Xk = vk . called instantiation X.
paper assume finite number random variables, domain finite.
start total ordering X1 , . . . , Xn random variables.
Definition 1 parents random variable Xi , written Xi , minimal1 set predecessors
Xi total ordering predecessors Xi independent Xi given Xi .
Xi {X1 , . . . , Xi1 } P(Xi |Xi1 . . . X1 ) = P(Xi |Xi ).
belief network (Pearl, 1988) acyclic directed graph, nodes random variables2 . use terms node random variable interchangeably. arc
element Xi Xi . Associated belief network set probabilities form
P(X|X ), conditional probability variable given parents (this includes prior probabilities variables parents).
chain rule conjunctions independence assumption:
n

P(X1 , . . . , Xn ) =
P(Xi |Xi1 . . . X1 )
i=1

1. one minimal set, minimal set chosen parents. one minimal
set predecessors deterministic functions others.
2. people like say nodes labelled random variables. definition graph, set nodes
set, particular, set random variables. set arcs set ordered pairs random
variables.

264

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE





Z

B

C



E



















B
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b
b

C
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c



















P(e|ABCD)
0.55
0.55
0.55
0.55
0.3
0.3
0.3
0.3
0.08
0.08
0.025
0.5
0.08
0.08
0.85
0.5

Figure 1: simple belief network conditional probability table E.

=

n


P(Xi |Xi )

(1)

i=1

factorization joint probability distribution often given formal definition
belief network.
Example 1 Consider belief network Figure 1. represents factorization joint
probability distribution:
P(A, B, C, D, E, , Z)
= P(E|ABCD)P(A|YZ)P(B|YZ)P(C|YZ)P(D|YZ)P(Y )P(Z)
variables binary3 , first term, P(E|ABCD), requires probability E 16 cases
assignments values A, B, C, D. One table given Figure 1.
2.2 Belief Network Inference
task probabilistic inference determine posterior probability variable variables
given observations. section outline simple algorithm belief net inference called
variable elimination (VE) (Zhang Poole, 1994; Zhang Poole, 1996) bucket elimination
belief assessment (BEBA) (Dechter, 1996), based ideas nonlinear dynamic
programming (Bertel Brioschi, 1972)4 closely related SPI (Shachter, DAmbrosio
3. subsequent examples, assume variables Boolean (i.e., domain {true, false}). X
variable, X=true written x X=false written x, similarly variables. theory
implementations restricted binary variables.
4. Bertel Brioschi (1972) give essentially algorithm, optimization problem finding minimization sums. VE, use algorithm finding sum products. named links

265

fiPOOLE & ZHANG

Del Favero, 1990). query oriented algorithm exploits conditional independence
inherent network structure efficient inference, similar clique tree propagation
exploits structure (Lauritzen Spiegelhalter, 1988; Jensen, Lauritzen Olesen, 1990).
Suppose observe variables E1 , . . . , Es corresponding values o1 . . . os . want determine posterior probability variable X, query variable, given evidence E1 =o1 . . .Es =os :
P(X|E1 =o1 . . . Es =os ) =

P(X E1 =o1 . . . Es =os )
P(E1 =o1 . . . Es =os )

denominator, P(E1 =o1 . . . Es =os ), normalizing factor:

P(X=v E1 =o1 . . . Es =os )
P(E1 =o1 . . . Es =os ) =
vdom(X)

problem probabilistic inference thus reduced problem computing probability conjunctions.
Let = {Y1 , . . . , Yk } non-query, non-observed variables (i.e., = {X1 , . . . , Xn } {X}
{E1 , . . . , Es }). compute marginal distribution, sum Yi s:
P(X E1 =o1 . . . Es =os )



P(X1 , . . . , Xn ){E1 =o1 ...Es =os }
=
Yk

=


Yk

Y1



n


P(Xi |Xi ){E1 =o1 ...Es =os }

Y1 i=1

subscripted probabilities mean associated variables assigned corresponding
values.
Thus probabilistic inference reduces problem summing variables product
functions. solve efficiently use distribution law learned high school:
compute sum products xy + xz efficiently, distribute common factors
(which x) results x(y + z). essence algorithm. call
elements multiplied together factors use term mathematics. Initially
factors represent conditional probability tables, intermediate factors functions
variables created adding multiplying factors.
factor variables V1 , . . . , Vd representation function dom(V1 ) . . . dom(Vd )
real numbers.
Suppose Yi ordered according elimination ordering. sum
variables one time.
sum variable Yi product, distribute factors dont involve Yi
sum. Suppose f1 , . . . , fk functions variables multiplied together
(initially conditional probabilities),


f1 . . . fk = f1 . . . fm
fm+1 . . . fk
Yi

Yi

algorithm Bertel Brioschi (1972); refer basic algorithm elimination variables one
one, exactly do. Bertel Brioschi (1972) also describe good elimination ordering heuristics
refinements eliminating variables blocks forms conditioning dont consider here.
difference BEBA BEBA requires priori elimination ordering (and exploits
prior ordering efficiency), whereas allows dynamic selection variable eliminate next.

266

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

compute P(X|E1 =o1 . . . Es =os )
Let F factors obtained original conditional probabilities.
1. Replace f F involves Ei f{E1 =o1 ,...,Es =os } .
2. factor involving non-query variable
Select non-query variable eliminate
Set F = eliminate(Y , F).
3. Return renormalize(F)
Procedure eliminate(Y, F):
Partition F
{f1 , . . . , fm } dont contain
{fm+1
, . . . , fr } contain
Compute f = fm+1 . . . fr
Return {f1 , . . . , fm , f }
Procedure renormalize({f1 , . . . , fr }):
Compute f = f
1 . . . fr
Compute c = X f
Return f /c

% c normalizing constant
% divide element f c

Figure 2: tabular algorithm
f1 . . . fm functions dont involve Yi , f
m+1 . . . fk involve Yi .
explicitly construct representation new function Yi fm+1 . . . fk , continue summing
remaining variables. Yi summed out, result function X
proportional Xs posterior distribution.
tabular implementation algorithm (Figure 2), function discrete variables
V1 , . . . , Vd , represented d-dimensional table (which implemented, example,
d-dimensional array, tree depth d, or, implementation, 1-dimensional array based
lexicographic ordering variables). f table, let variables(f ) = {V1 , . . . , Vd }.
sometimes write f f [V1 , . . . , Vd ] make variables explicit. f said involve Vi
Vi variables(f ).
three primitive operations tables: setting variables, forming product tables,
summing variable table.
Definition 2 Suppose C set variables, c assignment C = v, f factor variables
X. Let = X C, let Z = X C, let Z = v assignment values Z assigns
values elements Z c does. Define set(f , c) factor given by:
set(f , c)(Y) = f (Y, Z=v ).
is, set(f , c) function Y, variables f c, like f ,
values already assigned. Note that, special case this, c doesnt involve variable f
set(f , c) = f .
Example 2 Consider factor f (A, B, C, D, E) defined table Figure 1. examples
value function f (a, b, c, d, e) = 0.55, f (a, b, c, d, e) = 1 0.08 = 0.92.
set(f , b e) function C defined table:
267

fiPOOLE & ZHANG

C
c
c
c
c







value
0.08
0.08
0.025
0.5

Definition 3 product tables f1 f2 , written f1 f2 table union variables
f1 f2 (i.e., variables(f1 f2 ) = variables(f1 ) variables(f2 )) defined by:
(f1 f2 )(X, Y, Z) = f1 (X, Y)f2 (Y, Z)
variables(f1 ) variables(f2 ), X variables(f1 ) variables(f2 ), Z variables(f2 )
variables(f1 ).
Note associative commutative.
construct product tables, fm+1 fk , union variables fm+1 . . . fk , say
X1 , . . . , Xr . construct r-dimensional table entry table
combination v1 , . . . , vr vi dom(Xi ). value entry corresponding v1 , . . . , vr
obtained multiplying values obtained fi applied projection v1 , . . . , vr
onto variables fi .

Definition 4 summing variable table f , written f table variables
Z = variables(f ) {Y } that5


(
f )(Z) =
f (Z =vi )


vi dom(Y )

dom(Y ) = {v1 , . . . , vs }.
Thus, sum , reduce dimensionality table one (removing dimension),
values resulting table obtained adding values table value .
Example 3 Consider eliminating B factors Example 1 (representing belief network
Figure 1), variables Boolean. factors contain B, namely factors
represent P(E|ABCD) P(B|YZ), removed set factors. construct factor
f1 (A, B, C, D, E, , Z) = P(E|A, B, C, D) P(B|Y , Z), thus, example,
f1 (a, b, c, d, e, y, z) = P(e|a b c d)P(b|y z)
f1 (a, b, c, d, e, y, z) = P(e|a b c d)P(b|y z)
f1 (a, b, c, d, e, y, z) = P(e|a b c d)P(b|y z)
f1 (a, b, c, d, e, y, z) = P(e|a b c d)P(b|y z)
similarly values . . . Z. need sum B f1 , producing
f2 (A, C, D, E, , Z) where, example,
f2 (a, c, d, e, y, z) = f1 (a, b, c, d, e, y, z) + f1 (a, b, c, d, e, y, z).
f2 added set factors. Note construction f1 exposition only; dont
necessarily construct table explicitly.
5. may look like circular definition, left side defines summing tables, whereas right side
summing numbers.

268

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

3. Contextual Independence
section give formalization contextual independence. notion first introduced
influence diagram literature (Smith et al., 1993). base definitions work
Boutilier et al. (1996).
Definition 5 Given set variables C, context C assignment one value variable
C. Usually C left implicit, simply talk context. would say C
variables context. Two contexts incompatible exists variable assigned
different values contexts; otherwise compatible. write empty context true.
Definition 6 (Boutilier et al., 1996) Suppose X, Y, Z C sets variables. X
contextually independent given Z context C=c, c dom(C),
P(X|Y=y1 Z=z1 C=c) = P(X|Y=y2 Z=z1 C=c)
y1 , y2 dom(Y) z1 dom(Z) P(Y=y1 Z=z1 C=c) > 0 P(Y=y2
Z=z1 C=c) > 0.
also say X contextually independent given Z context C=c. Often
refer simpler case set variables Z empty; case say X
contextually independent given context C=c.
Example 4 Given belief network conditional probability table Figure 1,
E contextually independent {C, D, , Z} given context b.
E contextually independent {C, D, , Z} given {B} context a.
E contextually independent {C, D, , Z} given {A, B} empty context true.
E contextually independent {B, D, , Z} given context c.
E contextually independent {A, B, C, D, , Z} given B context c d.
3.1 Contextual Independence Arise?
examples paper abstract designed show various features
algorithms show pathological cases. section give examples show
natural examples. claiming contextual independence always present able
exploited. Exploiting contextual independence seen one tools solve large
probabilistic reasoning tasks.
Example 5 child goes emergency ward staff may want determine
likely carrier chicken pox (in order keep away children). havent
exposed chicken pox within previous weeks, unlikely carrier. Thus
whether carrier independent background conditions given havent
exposed. exposed, chicken pox likely
carrier. Thus whether carrier independent background conditions given
exposed havent chicken pox before. case involve many
variables (e.g., severity age last time chicken pox) determine likely
child carrier.
269

fiPOOLE & ZHANG

Example 6 Many engineered systems designed insulate something conditions.
classic example central air conditioning (heating and/or cooling house). temperature inside
house depends outside temperature air conditioning off. air conditioning on,
temperature depends setting thermostat outside temperature. Thus
inside temperature contextually independent outside temperature given air conditioning
contextually independent thermostat setting given air conditioning off.
Example 7 Consider case someone make decision based questionnaire
questions asked depend previous answers. case decision6 contextually independent
answers questions asked given context questions asked.
example, consider questionnaire determine bank customer get loan starts
asking customer rent current home. own, asked number
questions value house asked rent. probability get
loan contextually independent value home (and information
available decision maker) given applicant rents home.
Example 8 learning decision network data, often advantageous build decision
tree variable given parents (Friedman Goldszmidt, 1996; Chickering, Heckerman
Meek, 1997). decision trees provide contextual independence (a variable independent
predecessors given context along path leaf tree). reason
good representation learn fewer parameters fine control adding
parameters; splitting leaf adds many fewer parameters adding new parent (adding new
variable every context).
3.2 Parent Contexts Contextual Belief Networks
use notion contextual independence representation looks like belief network,
finer-grain independence exploited efficient inference contextual variable
elimination algorithm.
definition belief network, lets assume total ordering variables,
X 1 , . . . , Xn .
Definition 7 Given variable Xi , say C=c, C {Xi1 . . . X1 } c dom(C),
parent context Xi Xi contextually independent predecessors Xi (namely {Xi1 . . . X1 })
given C=c.
relationship belief network? belief network, rows conditional probability
table variables form set parent contexts variable. However, often much
smaller set smaller parent contexts covers cases.
Example 9 Consider belief network conditional probability table Figure 1. predecessors variable E A, B, C, D, , Z. set minimal parent contexts E {{a, b}, {a, b},
{a, c}, {a, c, d, b}, {a, c, d, b}, {a, c, d}}. mutually exclusive exhaustive set parent
contexts. probability E given values predecessors reduced probability
6. make probabilistic problem, decision problem, consider probability third party
determine probability distribution possible decisions. similar analysis carried exploit
contextual independence decisions (Poole, 1995). decision makers decisions cant depend information
doesnt have.

270

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE


A=true


A=false

B

0.55

Y=true

C

Z


0.3 0.08

Y=false

0.77

0.27

0.17

P(b)
B

0.025

0.5
0.85

Z
Z=true

Z=false

0.29



P(e)
0.79

0.59

P(d)
Figure 3: Tree-structured representations conditional probabilities E, B, given
parents. Left branches correspond true right branches false. Thus, example,
P(e|a b) = 0.55, P(e|a b) = 0.3, P(e|a c b) = 0.025 etc.

E given parent context. example:
P(e|a, b, c, d, y, z) = P(e|a, b)
P(e|a, b, c, d, y, z) = P(e|a, c)
.P(e|a, b, c, d, y, z) = P(e|a, c)
belief network, parents E A, B, C, D. specify conditional probability E
given parents, traditional tabular representation (as Figure 1) require 24 = 16 numbers
instead 6 needed use parent contexts above. Adding extra variable
parent E doubles size tabular representation, relevant single context
may increase number parent contexts one.
often (but always) represent contextual independence terms trees. left side
Figure 3 gives tree-based representation conditional probability E given parents.
tree, internal nodes labelled parents E belief network. left child node
corresponds variable labelling node true, right child variable
false. leaves labelled probability E true. example P(e|a b) = 0.3,
irrespectively value C D. tree-based representation variable (E case)
271

fiPOOLE & ZHANG

contextually independent predecessors given context defined path tree.
paths tree correspond parent contexts.
showing structure parent contexts exploited inference,
properties note:
elements mutually exclusive exhaustive set parent contexts always
minimal parent contexts. example, suppose variable parents B C,
Boolean. Suppose probability p1 B C true
probability p2 otherwise. One mutually exclusive exhaustive set parent contexts
{b c, b c, b}. b c minimal c also parent context. Another mutually
exclusive exhaustive set parent contexts example {b c, b c, c}. set
minimal parent contexts, {b c, b, c}, isnt mutually exclusive exhaustive set
elements pairwise incompatible.
One could imagine using arbitrary Boolean formulae contexts. done
would entail using theorem proving (or sophisticated subsumption algorithm)
inference. doubt would worth extra overhead limited savings.
compact decision tree representation conditional probability tables (Boutilier et al., 1996)
always corresponds compact set parent contexts (one context path
tree). However, mutually exclusive exhaustive set parent contexts cannot always
directly represented decision tree (as isnt always single variable split on). example, mutually exclusive exhaustive set contexts {{a, b}, {a, c}, {b, c}, {a, b, c}, {a, b, c}}
doesnt directly translate decision tree. importantly, operations perform
dont necessarily preserve tree structure. Section 4.12 shows much better
analogous tree-based formulation inference algorithm.
Definition 8 contextual belief network acyclic directed graph nodes random
variables. Associated node Xi mutually exclusive exhaustive set parent contexts,
, and, , probability distribution P(Xi | ) Xi . Thus contextual belief network
like belief network, specify probabilities parent contexts.
variable Xi assignment Xi1 =vi1 , . . . , X1 =v1 values preceding
v ...v1
variables, compatible parent context Xi1
. probability complete context (an

assignment value variable) given by:
P(X1 =v1 , . . . , Xn =vn )
n

P(Xi =vn |Xi1 =vi1 , . . . , X1 =v1 )
=
i=1

=

n


v

P(Xi =vi |Xi1


...v1

)

(2)

i=1

looks like definition belief network (equation (1)), variables act parents
depends values. numbers required probability variable element
mutually exclusive exhaustive set parent contexts. many fewer
number assignments parents belief network. one extreme,
number; extreme exponentially many assignments values parents
number elements mutually exclusive exhaustive set parent contexts.
272

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

3.3 Parent Skeletons
Although definition contextual belief network specifies contextual independence
want, doesnt give us way organize parent contexts (in much way belief
network doesnt specify representation conditional probability table). use concept
parent skeleton way organize parent contexts; want use indexing provided
tables still allowing ability express context-specific independence.
notion parent context fine-grained parent (the set parents
corresponds many parent contexts). context-specific independence, would
like consider parent contexts explicitly, consider parents. use
parent skeleton cover parents parent contexts special cases, interpolate
them, independence depends context well values variables.
Definition 9 parent skeletal pair variable X pair c, V c context
predecessors X V set predecessors X X contextually independent
predecessors given V context c. Note
context c V = v. parent skeleton
parent

variable X set parent skeletal pairs, { cj , Vj : 0 < j k}, cj mutually exclusive

exhaustive (i.e., ci cj incompatible
= j, kj=1 cj true).
Example 10 parent skeleton E Example 9 {a, {B}, c, {}, c d, {B},
c d, {} .
Parent skeletons form basis representation contextual belief networks.



variable, X, select parent skeleton parent skeleton pair cj , Vj parent
context, cj Vj = vj parent context X. parent context pair specify
probability distribution P(X|cj Vj = vj ).
3.4 Contextual Factors
Whereas algorithm uses tables representation conditional probabilities
intermediate representations, contextual variable elimination algorithm defined uses
hybrid tables rules (Poole, 1997) call contextual factors confactors. Confactors
cover tables rules special cases.
Definition 10 contextual factor confactor pair form:
c,
c context, say X1 =vk . . . Xk =vk , table represents function variables
Xk+1 , . . . , Xm , {X1 , . . . , Xk } {Xk+1 , . . . , Xm } disjoint sets variables. c called
body confactor called table confactor.
confactor represents partial function (Zhang Poole, 1999) union variables.
function value context true, value function obtained
looking value table.
tables used represent conditional probabilities, confactors used represent
conditional probabilities context-specific independence. particular, set parent
contexts represented set confactors mutually exclusive exhaustive bodies.
Given parent skeleton variable X construct set confactors X follows:
c, V parent skeleton X, construct confactor c, t({X} V ) t({X = x} V =
v) = P(X = x|V = v c).
273

fiPOOLE & ZHANG

Definition 11 confactor applicable context body confactor compatible
context.
Definition 12 Given confactor r = X1 =vk . . . Xk =vk , t[Xk+1 , . . . , Xm ] context c
assigns least variables X1 . . . Xm , r applicable c, value context c respect
confactor r value t[Xk+1 = vk+1 , . . . , Xm = vm ] vk+1 , . . . , vm values
assigned Xk+1 , . . . , Xm c.
Definition 13 set R confactors represents conditional probability P(Xi |X1 . . . Xi1 )
bodies confactors mutually exclusive exhaustive, P(Xi = vi |X1 = v1 . . .
Xi1 = vi1 ) equal value context X1 = v1 . . . Xi1 = vi1 Xi = vi respect
(unique) confactor R applicable context.
Intuitively, confactors represent contextual belief network way organize
parent contexts. idea represent parent contexts tables context-specific
independence, variables independent predecessors context,
context made body confactors.
Example 11 Consider conditional probabilities represented Figure 3. E independent
predecessors given {B} context a. leads confactor:
a, t1 [B, E]

(3)

E independent predecessors given context c. leads confactor:
c, t2 [E]

(4)

E independent predecessors given {B} context c D. leads confactor:
c d, t3 [B, E]

(5)

E independent predecessors given context c d. leads confactor:
c d, t4 [E]

(6)

full multiset confactors corresponding trees Figure 3 given Figure 4.
fifth sixth confactors give conditional probability B, last two confactors give
conditional probability D.
rewrite definition contextual belief network terms confactors:
every conditional probability represented set confactors, probability
complete context, c product values c respect confactors
applicable c. complete context variable one
confactor containing variable applicable context.

4. Contextual Variable Elimination
general idea contextual variable elimination (CVE) represent conditional probabilities
terms confactors, use algorithm confactor representation rather
tables. units manipulation thus finer grained factors members
buckets BEBA; analogous factor member bucket consists multisets
confactors. Given variable eliminate, ignore (distribute out) confactors dont
274

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE




















P(E|A, B, C, D)

P(B|Y , Z)





ff








B
true
a, true
false
false

ff






ff






c d,








B
true
y, true
false
false

Z
true
false
true
false

E
true
false
true
false

B
true
true
false
false

Value
0.55 fi
0.45
0.3
0.7

E
true
false
true
false

ff

E
Value fi
c, true 0.08
false 0.92

Value
E
Value fi
0.025 fi ff
c d, true 0.5
0.975
0.85
false 0.5
0.15

Value
Value fi
0.77 fi ff B
y, true 0.27
0.17
0.23
false 0.73
0.83






fi ff true
ff

Value

z, true
P(D|Y , Z)
z, true 0.29



false
0.71
false


false


true
false
true
false

Value
0.79 fi
0.59
0.21
0.41

Figure 4: confactors corresponding trees Figure 3

275

fiPOOLE & ZHANG

involve variable. contextual independence goes beyond conditional
independence variables, savings substantial. contextual independence,
confactors empty contexts, algorithm reduces VE.
section introduces abstract nondeterministic version CVE. Section 5 presents
concrete version explain resolve much nondeterminism.
input CVE is:
multiset confactors consists union confactors represent conditional
probability distribution variable given predecessors
set query variables
observation conjunction assignments values variables
first consider case observations. Observations considered Section 4.7.
Initially elimination variable, maintain multiset confactors
following program invariant:
probability context c non-eliminated variables obtained multiplying values context c associated confactors applicable context c.
complete context non-eliminated variables variable
least one confactor containing variable applicable context7 .
algorithm sum variable contexts one step. Rather sum variable
different contexts separately. Intermediate fully summed out, variable summed
contexts others. remaining variables interpreted relative
whether variable summed context c.
Like VE, abstract algorithm made primitive operations summing variable
multiplying confactors, also includes primitive operation confactor splitting enables
two operations. operations locally preserve program invariant.
described next subsections.
4.1 Multiplying Contextual Factors
two confactors context:
b, t1
b, t2
replace product:
b, t1 t2 .
7. second part invariant may intuitive, important. example, Example 11, one may
tempted reduce confactor (6) c d, 0.5 (i.e., table function variables) contribution
confactors independent value E (the table t4 [E] value 0.5 value E
confactor (6)). first part invariant isnt violated. However, confactors containing
E applicable c true, summing E, want confactor c d, 1,
summing E want confactor c d, 0.5 order maintain first part invariant. would
like maintain property consider confactors containing E eliminating E. second part
invariant allows us without treating special case algorithm.

276

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

program invariant maintained, context incompatible b isnt affected
operation. context compatible b, product values t1 t2 context
value t1 t2 context. completeness part invariant isnt
affected multiplying.
4.2 Summing Variable Appears Table
Suppose eliminating , confactor:
b,
table involves , confactor compatible b contains ,
replace confactor

b,



Note operation summed context b.
Correctness: see correct, consider context c remaining variables (c doesnt
give value ). c isnt compatible b, isnt affected operation. compatible
b, elementary probability theory:

P(c) =
P(c =vi )


program invariant, confactors containing compatible
c, P(c =vi ) = pi p, product p contributions confactors dont involve
Y.
Exactly confactors used different values . Thus P(c) = p( pi ),
maintained first part program invariant. second part program
invariant trivially maintained.
4.3 Summing Variable Body Confactors
Suppose eliminating , domain {v1 , . . . , vk }, confactors:
b =v1 , T1
...
b =vk , Tk
confactors contain whose context compatible b.
replace confactors confactor:
b, T1 . . . Tk
additive analogue . is, follows definition 3, using addition
values instead multiplication.
Note operation summed context b.
Correctness: see correct, consider context c remaining variables (c doesnt
give value ). c isnt compatible b, isnt affected operation. compatible
b, elementary probability theory:

P(c) =
P(c =vi )


277

fiPOOLE & ZHANG

distribute confactors product thus first part invariant
maintained. Note operation equivalent enlarging table include union
variables tables, changing values, pointwise adding
values resulting tables. second part trivially maintained.
second part program invariant implies cannot confactor form
b =vi , pi without corresponding confactor =vj ,
= j.
4.4 Confactor Splitting
order satisfy prerequisites able multiply confactors sum variables, sometimes
need split confactors.
confactor
b,
replace result splitting non-eliminated variable , domain {v1 , . . . , vk }.
doesnt appear t, splitting results set confactors:
b =v1 ,
...
b =vk ,
appear t, result set confactors:
b =v1 , set(t, =v1 )
...
b =vk , set(t, =vk )
set defined Definition 2.
Correctness: program invariant maintained one new confactors used
complete context instead original confactor. give contribution.
Example 12 Splitting first confactor P(E|A, B, C, D) Figure 4 gives two confactors:
B
true
y, true
false
false

E
true
false
true
false

Value
0.55 fi
0.45
0.3
0.7

(7)

B
true
y, true
false
false

E
true
false
true
false

Value
0.55 fi
0.45
0.3
0.7

(8)

ff

ff

278

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

Example 13 Splitting first confactor P(B|Y , Z) Figure 4 gives two confactors:
B
true
y, true
false
false

Z
true
false
true
false

Value
0.77 fi
0.17
0.23
0.83

(9)

B
true
y, true
false
false

Z
true
false
true
false

Value
0.77 fi
0.17
0.23
0.83

(10)

ff

ff

reason may want two splits multiply confactors (7)
(9).
4.5 Examples Eliminating Variables
four operations needed eliminate variable. variable eliminated
summed contexts.
Example 14 eliminate B confactors Figure 4, need consider
four confactors contain B. preconditions summing B multiplying
satisfied, need split. split first confactor P(E|A, B, C, D) (as Example
12) split first confactor P(B|Y , Z) (as Example 13), produce two confactors,
(7) (9), multiplied producing:
B
true
true
ff
true
y, true
false
false
false
false

E
true
true
false
false
true
true
false
false

Z
true
false
true
false
true
false
true
false

Value
0.4235
0.0935
0.3465 fi
0.0765
0.069
0.249
0.161
0.581

(11)

confactor contains B applicable context y, sum
B table, producing confactor:
ff

E
true
y, true
false
false

Z
true
false
true
false

Value
0.4925 fi
0.3425
0.5075
0.6575

(12)

nontrivial confactors produced summing B are:
ff
E
Value fi
y, true 0.3675
false 0.6325

(13)

279

fiPOOLE & ZHANG

E
true
c y, true
false
false

Value
0.21475 fi
0.70975
0.78525
0.29025
ff
fi
E
Value
c y, true 0.62725
false 0.37275
ff

Z
true
false
true
false

(14)

(15)

See Example 19 trivial confactors produced avoid them.
confactors contrasted factor A, C, D, E, , Z (of size 32)
produced eliminating B VE.
Example 15 Suppose instead eliminate confactors Figure 4.
example differs previous example appear bodies well tables.
two confactors P(E|A, B, C, D) contain D, namely c d, t3 [B, E] (confactor
(5)), c d, t4 [E] (confactor (6)) compatible confactors P(D|Y , Z).
cannot sum variable multiply confactors.
order able multiply confactors, split confactor (5) Z producing:
c z, t3 [B, E]

(16)

c z, t3 [B, E]

(17)

confactors P(D|Y , Z) z, t7 [D] z, t8 [D, ]. split first
producing
z, t7 [D]

(18)

z, t7 [D]

(19)

confactors containing context compatible confactor (18).
prerequisite required sum context z satisfied. results confactor
z, 1 1 factor variables value 1. removed product
1 doesnt change anything. Intuitively justified context true
children. detect case improve efficiency (see Section 4.10).
confactor (19) split C, producing
c z, t7 [D]

(20)

c z, t7 [D]

(21)

sum confactor (20), producing c z, 1, previous case.
split confactor (21) producing:
c z, 0.29

(22)

c z, 0.71

(23)

0.29 0.71 corresponding values t7 [D]. functions variables,
numbers.
multiply confactor (22) (16), producing:
c z, 0.29t3 [B, E]

(24)

0.29t3 [B, E] table obtained multiplying element t3 [B, E] 0.29.
280

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

also split confactor (6) Z, producing:
c z, t4 [E]

(25)

c z, t4 [E]

(26)

multiply confactors (23) (25), producing:
c z, 0.71t4 [E]

(27)

complementary confactors context c z, namely confactors
(24) (27) sum-out context resulting
c z, t9 [B, E]

(28)

t9 [B, E] 0.29t3 [B, E] 0.71t4 [E]. full form is:
ff

B
true
c z, true
false
false

E
true
false
true
false

Value
0.36225 fi
0.63775
0.6015
0.3985

(29)

confactor produced summing is:
B
true
true
ff
true
c z, true
false
false
false
false

E
true
true
false
false
true
true
false
false


true
false
true
false
true
false
true
false

Value
0.12475
0.21975
0.87525 fi
0.78025
0.7765
0.7065
0.2235
0.2935

(30)

4.6 Split
Confactor splitting makes multiset confactors complicated, careful
apply operation judiciously. need carry confactor splitting order make identical
complementary contexts carry operations summing variable multiplying
confactors. cases need split.
Definition 14 Given confactor r1 = c1 , T1 context c, c1 c compatible,
split r1 c means split r1 sequentially variables assigned c arent
assigned c1 .
split r1 c, end single confactor context compatible
c; contexts confactors produced splitting incompatible
c. confactors incompatible c called residual confactors.
formally, recursively define residual(r1 , c), r1 = c1 , t1 c c1
compatible, by:
residual(r1 , c) = {} c c1
281

fiPOOLE & ZHANG

Else c
c1 , select variable X assigned c c1 .
residual(r1 , c) = {c1 X=vi , set(t1 , X=vi ) : vi dom(X)&vi
= cX }
residual(c1 X=cX , set(t1 , X=cX ), c)
cX value assigned X context c. Recall (Definition 2) set(t, X=vi )
doesnt involve X selection X=vi values table, followed
projection onto remaining variables, involve X.
results splitting confactor context set confactors:
split(c1 , t1 , c) = residual(c1 , t1 , c) {c1 c, t1 }.
Example 16 Consider residual(a b, t1 [C, D], c e). Suppose split C first, E.
results two residual confactors: b c, t2 [D] b c e, t3 [D]. Note t2 [D]
projection t1 [C, D] onto C=false t3 [D] projection t1 [C, D] onto C=true.
non-residual confactor want split b c e, t3 [D].
instead split E C, get residual confactors: b e, t1 [C, D]
b c e, t2 [D], non-residual confactor.
Note result depend order variables selected (see
useful splitting heuristics). algorithms use split correct matter order
variables selected, however orderings may result splitting subsequent operations.
Example 16 highlights one heuristic seems generally applicable. split
confactor variables appear body variables table, better split
variables table first, simplify confactors need subsequently split.
use notion residual split two rules compatible, need multiplied.
Suppose confactors r1 = c1 , t1 r2 = c2 , t2 , contain variable
eliminated c1 c2 compatible contexts. split r1 c2 , split r2 c1 ,
end two confactors whose contexts identical. Thus prerequisite needed
multiplying.
Example 17 Suppose confactors r1 = b c, t1 r2 = d, t2 contain
variable eliminated. split r1 body r2 , namely d, producing
confactors
b c d, t1

(31)

b c d, t1
first compatible r2 . second confactor residual confactor.
split r2 body r1 , namely b c, first splitting r2 B, C, producing
confactors:
b c d, t2
b c d, t2

(32)

b d, t2
second confactor (confactor (32))is compatible r1 residual confactors
produced splitting r1 . Confactors (31) (32) identical contexts multiplied.
282

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

Suppose confactors r1 = c1 =vi , t1 r2 = c2 =vj , t2 , c1 c2
compatible contexts, vi
= vj . split r1 c2 , split r2 c1 , end two
confactors whose contexts identical except complementary values . exactly
need summing .
binary domain {vi , vj }, confactors r1 = c1 =vi , t1 r2 =
c2 =vj , t2 , c1 c2 compatible contexts, confactor contains
compatible c1 c2 , summing context c1 c2 results confactors:
residual(r1 , c2 ) residual(r2 , c1 ) {c1 c2 , t1 t2 }.
two values domain, may need split pair confactors, always
using results previous splits subsequent splits.
Proposition 1 Splitting confactor c1 , t1 c creates

(|dom(X)| 1)
Xvars(c)vars(c1 )

extra confactors, independently order variables selected split,
vars(c) set variables assigned context c.
split, choice variable split first. choice
influence number confactors created single split, influence number
confactors created total subsequent splitting. One heuristic given above. Another
useful heuristic seems be: given confactor multiple possible splits, look
confactors need combined confactor enable multiplication addition,
split variable appears most. cases conditional probability forms
tree structure, tend split root tree first.
4.7 Evidence
VE, evidence simplifies knowledge base. Suppose E1 =o1 . . . Es =os observed.
three steps absorbing evidence:
Remove confactor whose context contains Ei =o , oi
= .
Remove term Ei =oi context confactor.
Replace table set(t, E1 =o1 . . . Es =os ) (as tabular algorithm).
note incorporating evidence simplifies confactor base.
evidence incorporated confactor-base, program invariant becomes:
probability evidence conjoined context c non-eliminated, nonobserved variables equal product probabilities confactors
applicable context c. context c non-eliminated, non-observed
variables variable X least one confactor containing X
applicable context c.
probabilistic inference, normalise end, remove confactor
doesnt involve variable (i.e., empty context single number table) result
second third cases. is, remove confactor observed variables.
need replace equal proportional program invariant.
283

fiPOOLE & ZHANG

Example 18 Suppose z observed given confactors Figure 4. first two confactors
P(E|A, B, C, D) dont involve Z affected observation. third confactor
removed body incompatible observation. fourth confactor replaced by:
ff
E
Value fi
c, true 0.5
false 0.5
first confactor P(B|Y , Z) replaced
ff B
Value fi
y, true 0.17
false 0.83
first confactor P(D|Y , Z) removed second replaced
ff

Value fi
true, true 0.21
false 0.41
true represents empty context.
4.8 Extracting Answer
Suppose single query variable X. setting evidence variables, eliminating
remaining variables, end confactors form:
{X=vi }, pi
form
{}, ti [X]
e evidence probability X=vi e proportional product contributions
confactors context X=vi selection X=vi value table. Thus


pi
ti [vi ].
P(X=vi e)
X=vi ,pi

{},ti [X]

have:
P(X=vi e)
.
P(X=vi |e) =
vj P(X=vj e)
Notice constants proportionality evidence removing constants (confactors
variables) cancel division.
multiple query variables (i.e., wanted marginal posterior), still
multiply remaining confactors renormalise.
4.9 Abstract Contextual Variable Elimination Algorithm
contextual variable elimination algorithm, given Figure 5. refined version
less splitting given Section 5.
elimination procedure called non-query, non-observed variable. order
variables selected called elimination ordering. algorithm imply
284

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

compute P(X|E1 =o1 . . . Es =os )
Given multiset R confactors
1. Incorporate evidence Section 4.7.
2. non-query variable eliminated
{
Select non-query variable eliminate;
Call R := eliminate(Y , R);
}
3. Compute posterior probability X Section 4.8
Procedure eliminate(Y, R):
partition R into:
R = confactors R dont involve ;
R = {r R : r involves };
{b1 , T1 , b2 , T2 } R b1 b2 compatible,
{
remove b1 , T1 b2 , T2 R ;
split b1 , T1 b2 putting residual confactors R ;
split b2 , T2 b1 , putting residual confactors R ;
add b1 b2 , T1 T2 R ;
}
every b, R appears
{
remove
b, R ;
add b, R ;
}
R empty
{
{b =v1 , T1 , . . . , b =vk , Tk } R
{
remove b =v1 , T1 , . . . , b =vk , Tk R ;
add b, T1 . . . Tk R ;
}
else {b1 =vi , T1 , b2 =vj , T2 } R b1 b2 compatible b1
= b2
{
remove b1 =vi , T1 b2 =vj , T2 R ;
split b1 =vi , T1 b2 , putting created confactors R ;
split b2 =vj , T2 b1 , putting created confactors R ;
}
}
Return R .
defined Section 2.2.
defined Section 4.3.
set operations assumed multisets.
Figure 5: Contextual Variable Elimination
285

fiPOOLE & ZHANG

elimination ordering given priori. choice points order
multiplication, splitting ordering.
Note eliminate algorithm, set operations assumed multisets.
possible, uncommon, get multiple copies confactor. One example
happens naive Bayes model variable C parents, variables
Y1 , . . . , Yn C parent. Often conditional probabilities Yi
represent repeated identical sensors. identical sensors observe
value, get identical confactors, none removed without affecting
answer.
see correctness procedure, note local operations preserve program
invariants; still need check algorithm halts. first while-loop eliminate,
contexts confactors R mutually exclusive covering second part loop
invariant. complete contexts variables remain eliminated, either
compatible confactor table, compatible confactor = vi every
value vi . splitting second loop eliminate preserves mutual exclusiveness
bodies confactors R splitting confactor, set created confactors covers
context original confactor. confactors R , if-condition
hold, must pair confactors else-if condition holds. Thus, time
second while-loop, number confactors R increases number confactors
R increases bounded size size corresponding factor. Thus
eliminate must stop, eliminated contexts.
4.10 Ones
Bayesian network remove non-observed, non-query node children without
changing conditional probability query variable. carried
recursively.
VE, eliminate variables, create factors ones (as X P(X|Y ) = 1).
contextual VE, subtle version variable may children
contexts, even children another context.
Example 19 Consider eliminating B Example 14 belief network given Figure
1 structured conditional probabilities given Figure 3). context c,
confactors applicable define P(B|YZ). stated, contextual algorithm,
following three confactors created:
c y, 1[Z]
c y, 1
1[Z] function Z value 1 everywhere 1 function variables
value 1.
Confactors contribution 1 removed without affecting correctness
algorithms (as long confactors arent confactors contain variable
context). easy show first part program invariant maintained multiplying
1 doesnt affect number. second part invariant also maintained, always
confactors child (E case) dont depend variable eliminated,
well confactors parents variable eliminated.
286

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

...

...

...

FT

FB

OT

...

...

MB

MT

FH

MH

...

...

Figure 6: fragment belief network: OT eliminate.
however probably better never construct confactors rather construct
throw away. show done Section 5.1.
4.11 Multi-Valued Variables
presented algorithm allows multi-valued variables, splitting operation
creates number confactors values domain variable split.
alternate method using multi-valued variables. extend notion
context allow membership set values. is, context could conjunction terms
form X set values. original version equality form X=v
X {v}. Splitting done efficiently one residual confactor
split. Effectively treat multiset confactors unit.
examples representation much efficient, makes
algorithm much complicated explain. also examples binary splitting
less efficient needs splits get result.
4.12 CVE Representing Factors Trees
may seem CVE confactor based representation factors, much way
trees structured policy iteration (Boutilier, Dearden Goldszmidt, 1995) solving MDPs.
section present detailed example explains CVE much efficient
tree-based representation factors.
Example 20 Figure 6 shows fragment belief network. elaboration Example 6,
affects inside temperature depends whether air conditioning broken
working. variables Boolean. use following interpretation:
287

fiPOOLE & ZHANG

true

FB

FT

OT
p1

MB

false

p2

p3

MT

OT
p4

p5

P(fh)

p6

p7

p8

P(mh)

Figure 7: Tree-structured conditional probability tables B. Left branches correspond
true right branches false. Thus p1 = P(a|d e), p2 = P(a|d e), etc.

FB Freds air conditioning broken
FT Freds thermostat setting high
OT Outside temperature hot
FH Freds house hot
MB Marys air conditioning broken
MT Marys thermostat setting high
MH Marys house hot
Season, true Summer
ancestors FT , FB, S, MB, MT shown. multiply connected.
Similarly, descendants FH MH shown. multiply connected.
outside temperature (OT ) relevant Freds house hot (FH) Freds air
conditioner broken (FB true) case Freds thermostat setting (FT ) relevant. Freds
thermostat setting (FT ) relevant Freds house hot (FH) Freds air conditioner
working (FB false), case outside (OT ) relevant. similarly Marys
house. See Figure 7. important note FH MH dependent,
air conditioners broken, case thermostat settings irrelevant.
Suppose sum OT VE. OT eliminated, FH MH become dependent. bucket elimination form factor f (FH, MH, FT , FB, MB, MT , S) containing
remaining variables. factor represents P(FH, MH|FT , FB, MB, MT , S) (unless
pathological case MT MB descendent FH, FT FB descendent
MH). One could imagine version builds tree-based representation factor.
show confactor-based version exploiting structure this.
288

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

take contextual independence account, need consider dependence
FH MH FB MB true (in case FT MT irrelevant).
contexts, treat FH MH independent. algorithm CVE
automatically.
conditional probabilities Figures 6 7 represented following confactors:
FH
true
fb, true
false
false

OT
true
false
true
false

Value
fi
p1
p2
1 p1
1 p2

(33)

FH
true
fb, true
false
false

FT
true
false
true
false

Value
fi
p3
p4
1 p3
1 p4

(34)

ff

ff

MH
true
mb, true
false
false

OT
true
false
true
false

Value
fi
p5
p6
1 p5
1 p6

(35)

MH
true
mb, true
false
false

MT
true
false
true
false

Value
fi
p7
p8
1 p7
1 p8

(36)

ff

ff

OT
true
true
false
false


true
false
true
false

Value
p9
p10
1 p9
1 p10

(37)

Eliminating OT confactors results six confactors:
FH
true
true
ff
true
fb mb, true
false
false
false
false

MH
true
true
mbalse
mbalse
true
true
false
false


true
false
true
false
true
false
true
false

Value
p9 (p5 p1 ) + (1 p9 ) (p6 p2 )
p10 (p5 p1 ) + (1 p10 ) (p6 p2 )
fi
p9 ((1 p5 ) p1 ) + (1 p9 ) ((1 p6 ) p2 )
p10 ((1 p5 ) p1 ) + (1 p10 ) ((1 p6 ) p2 )
p9 (p5 (1 p1 )) + (1 p9 ) (p6 (1 p2 ))
p10 (p5 (1 p1 )) + (1 p10 ) (p6 (1 p2 ))
p9 ((1 p5 ) (1 p1 )) + (1 p9 ) ((1 p6 ) (1 p2 ))
p10 ((1 p5 ) (1 p1 )) + (1 p10 ) ((1 p6 ) (1 p2 ))
289

fiPOOLE & ZHANG

FH
true
fb mb, true
false
false

ff

ff

FH
true
fb, true
false
false

FT
true
false
true
false

Value
fi
p9 p1 + (1 p9 ) p2
p10 p1 + (1 p10 ) p2
p9 (1 p1 ) + (1 p9 ) (1 p2 )
p10 (1 p1 ) + (1 p10 ) (1 p2 )

Value
fi
p3
p4
1 p3
1 p4

Value
fi
p9 p5 + (1 p9 ) p6
p10 p5 + (1 p10 ) p6
p9 (1 p5 ) + (1 p9 ) (1 p6 )
p10 (1 p5 ) + (1 p10 ) (1 p6 )
ff
fi

Value
fb mb, true p9 + (1 p9 )
false p10 + (1 p10 )
ff

ff

MH
true
fb mb, true
false
false


true
false
true
false

MH
true
mb, true
false
false

MT
true
false
true
false


true
false
true
false

Value
fi
p7
p8
1 p7
1 p8

Note third sixth confactors originally affected
eliminating OT .
resultant confactors encode probabilities {FH, MH} context fb mb.
contexts, CVE considers FH MH separately. total table size confactors
OT eliminated 24.
Unlike BEBA, need combined effect FH MH contexts OT
relevant FH MH. contexts, dont need combine confactors
FH MH. important, combining confactors primary source combinatorial
explosion. avoiding combining confactors, potentially huge saving
variable summed appears contexts.
4.13 CVE Compared
interesting see relationship confactors generated factors
belief network, query observations elimination ordering.
two aspects comparison, first exploitation contexts, second idea
multiplying confactors unless need to. section, introduce tree-based variable
elimination algorithm (TVE) uses confactors doesnt property example
confactors multiplied would multiply corresponding factors.
order understand relationship CVE query
elimination order, consider derivation tree final answer. tree contains
290

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

initial intermediate factors created VE. parents tree factor factors
multiplied variable summed produce factor. Note tree
(each factor one child) factor used VE; multiplied
variable summed it, removed.
node tree created multiplying two factors, number multiplications equal table size resulting factor. factor created summing
variable, number additions equal size parent minus size.
define tree-based variable elimination (TVE) composite CVE. uses
confactors CVE. Associated factor derivation tree set confactors.
WhenVE multiplies two factors, TVE multiplies (and requisite splitting) compatible
confactors associated factors multiplied. TVE essentially tree-based
merging Boutilier (1997) (but Boutilier also maximization decisions).
Whenever multiplies two factors, TVE multiplies confactors associated
factors. TVE confactors associated factors always total table size
less equal factor size. TVE maintains set confactors mutually exclusive
covering contexts. number multiplications equal resulting table size
pairwise multiplication (as entry computed multiplying two numbers). easy see
TVE always fewer equal number multiplications VE.
CVE like TVE except CVE doesnt multiply confactors multiplies
two factors. delays multiplications need done. relies hope
confactors separately simplified need multiplied. hope
unjustified eliminating variable means factors need multiplied
confactors, need multiplied other.
Example 21 use TVE Example 20, OT eliminated, TVE builds tree
representing probability FH MH. entails multiplying confactors
combined CVE, example multiplying third, fifth sixth factors theresult
Example 20, produces confactor form f b mb, t(FH, FT , MH, MT , S) . Eliminating OT results set confactors total table size 72, compared 24 VE. Without
contextual structure, builds table 27 = 128 values.
possible multiplying compatible confactors earlier means eventually
multiplications. following example simplest example could find
CVE multiplications TVE. Slight variations structure example,
however result CVE fewer multiplications.
Example 22 Consider belief network shown Figure 8(a). First sum variable, A,
create two confactors multiplied CVE multiplied TVE. multiply
one confactors another factor summing second variable, B. force
multiplication eliminating C.
Suppose variables binary except variable W domain size 1000. (The
counter example doesnt rely non-binary variables; could B 10 binary parents,
makes arithmetic less clear). analysis discuss multiplications
involve W , multiplications sum less hundred, dominated
multiplications involve W .
Suppose following confactors S:
x, t1 (A, B, C, S)

(38)
291

fiPOOLE & ZHANG

W

W

X

C

B



C

B






(a)

(b)

Figure 8: Belief network Example 22.
x, t2 (B, C, S)

(39)

Suppose following confactors :
x, t3 (A, B, C, )

(40)

x, t4 (C, )

(41)

Suppose first observed. confactors replaced by:
x, t5 (A, B, C)

(42)

x, t6 (C)

(43)

Lets eliminate A. CVE TVE, confactors (38) (42) prior
multiplied together, summed resulting in:
x, t7 (B, C, S)

(44)

TVE, confactors (39) (43) also multiplied together resulting in:
x, t8 (B, C, S)

(45)

Next eliminate B. CVE TVE, confactor (44) multiplied factors representing
P(C|B) P(B|W ). assume factor representing P(B|W ) multiplied last
minimises number multiplications. involves 8008 multiplications (as product
table size 8000 intermediate table size 8). B summed resulting
factor:
x, t9 (C, S, W )

(46)

CVE, confactor (39) multiplied factors representing P(C|B) P(B|W ). also
involves 8008 multiplications. B summed product resulting in:
x, t10 (C, S, W )

(47)

TVE, confactor (45) multiplied factors representing P(C|B) P(B|W ). also
involves 8008 multiplications. B summed product resulting in:
x, t11 (C, S, W )

(48)
292

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

C eliminated, TVE requires multiplications. sums C table
confactor (48). However CVE, need multiply confactors (43) (47), involves 4000
multiplications. resulting confactors CVE TVE identical.
Thus CVE requires 20000 multiplications, TVE requires 16000 multiplications. VE,
elimination order, requires 16000 multiplications.
surprising, particularly realise optimal. given
elimination ordering, sometimes optimal multiply factors actually multiplies them,
following example shows:
Example 23 Consider belief network Figure 8(b), domain sizes
previous example. factors represent P(W ), P(B|W ), P(C), P(S|BC). eliminate B
C, efficient preemptively multiply P(C) P(S|BC) delay multiplication
till summing B (as does).
may seem negative show CVE doesnt always fewer multiplications
overhead maintaining contexts. However, seems reason preemptive
multiplication TVE optimal either. One possibility treat multiply
sum variables secondary optimisation problem (Bertel Brioschi, 1972; Shachter
et al., 1990; DAmbrosio, 1995); unfortunately optimization also computationally difficult
(DAmbrosio, 1995). This, however beyond scope paper.

5. Avoiding Splitting
5.1 Absorption
section characterize case dont need split multiplication. Note
result eliminating variable exactly before; saving dont
create residuals, rather use original confactor.
Definition 15 multiset confactors R complete contexts confactors mutually
exclusive covering.
multiset R confactors complete, means dont split
confactors r may need multiplied confactors R. residual r,
another element R compatible. Instead splitting r,
multiply element R. intuition behind absorption. Note may need
split elements R multiplication.
Suppose complete multiset confactors R another confactor r1 = c1 , t1 . Define
absorb(R, c1 , t1 )
= {ci , pi R : incompatible(ci , c1 )}


(residual(ci , ti , c1 ) {c1 ci , set(t1 , ci ) set(ti , c1 )})
ci , ti R
compatible(c1 , ci )
table multiplication (Definition 3).
293

fiPOOLE & ZHANG

Correctness: replace R {r1 } absorb(R, r1 ) program invariant preserved.
First note confactors absorb(R, r1 ) complete (and second part invariant
holds). see first part invariant preserved, consider complete context c.
c compatible c1 , original confactors, use one confactor R well
r1 . revised confactor base use appropriate confactor product original
probabilities. c incompatible c1 compatible one element c2 , p2 R.
c2 incompatible c1 , confactor used original confactor, c2 compatible
c1 , use residual confactor. case get contributions R {r1 }
absorb(R, r1 ).
Example 24 eliminate B confactors Figure 4 (as example 14),
treat two confactors P(B|Y , Z) complete multiset confactors. means
dont need split confactors .
Note try use confactors E complete set confactors eliminating
B, dont split confactors A, C D, consider confactors dont
involve B eliminating B, end multiplying confactors dont need multiplied.
Note R cannot represented decision tree (e.g., R confactors corresponding
contexts {{a, b}, {a, c}, {b, c}, {a, b, c}, {a, b, c}}), possible way split r1
results compact representation results absorb(R, r1 ).
seems though useful multiset confactors complete,
much use cannot easily find set. First note multiset R confactors
complete, absorb(R, r1 ) also multiset confactors complete, can,
turn, used combine another confactor.
Initially, variable X, confactors represent conditional probability table
P(X|X ) complete. Moreover contain X need involved eliminating
X. used initial seed absorbing confactors. Unfortunately,
eliminated variables, confactors define initial conditional probability tables
variable X dont exist anymore; split, multiplied confactors added
confactors. However, variable X, still extract useful multiset confactors
contain X complete empty context (i.e., mutually exclusive covering).
called confactors X, correspond confactors X head
earlier version contextual variable elimination (Poole, 1997).
Definition 16 X variable, confactors X subset confactor base defined by:
Initially confactors X confactors define conditional probability P(X|X ).
split confactor X, confactors created also confactors X. Note
cover case splitting confactor confactor X.
multiply confactor X another confactor, confactor created confactor
X.
add confactor X another confactor (when eliminating another variable ,
example), resulting confactor also confactor X.
Proposition 2 confactors X stage contextual variable elimination complete.
294

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

show this, show three basic operations preserve property.
splitting preserves property, resulting confactors exclusive cover context
confactor split.
multiplication preserves property as, variable X, one confactors involved
multiplication confactor X (as confactors X mutually exclusive)
set contexts covered confactors isnt changed multiplication. argument
also holds absorption.
addition, note that, variable X, either confactors none confactors
involved addition confactors X summing . show suppose
r1 = c = v1 , p1 r2 = c = v2 , p2 confactor r1 confactor
X confactor r2 isnt. confactors X mutually exclusive covering,
must confactor covered X applicable context c = v2
applicable. confactor cannot mention , otherwise addition isnt applicable,
must also applicable c = v1 true, contradicts mutual exclusiveness
confactors X. easy see addition preserves property
confactors summed cover contexts resulting confactor.
also use idea confactors X recognise summing variable
create table 1s removed (see Section 4.10). First note original confactors
X, if, eliminating X, dont multiply confactors (i.e.,
children context), know summing X produce table 1s.
better recognising produce ones. use one bit information
encode whether confactor X pure X. Initially confactors X pure
X. confactor X pure X, and, eliminating absorbed confactors
pure , resulting confactor pure X. every case confactor
X multiplied another confactor, result pure X. summing X,
absorption, remove confactors X pure X. correct
maintained invariant sum X table confactor X pure X
create table ones. Note procedure generalises idea recursively
remove variables children neither observed queried.
idea absorption rules variable eliminated described section
seen heuristic avoid splitting. necessarily reduce amount
work. First note variable elimination choice order multiply
factors. Multiplication factors associative commutative, however, order
multiplication carried affects efficiency, following example shows.
Example 25 Suppose variable B one parent, two children C D,
B parent. eliminating B multiply factors representing P(B|A), P(C|B)
P(D|B). Suppose B, C binary, domain size 1000.
multiplying two factors number multiplications required equal size resulting
factor. save intermediate results, multiply order (P(B|A)t P(C|B))t P(D|B),
12000 multiplications. save intermediate results, multiply order
P(B|A) (P(C|B) P(D|B)), 8008 multiplications. dont save intermediate
tables, instead recompute every product, 16000 multiplications.
295

fiPOOLE & ZHANG

need multiply k > 1 factors, size resulting factor, number
multiplications bounded k 2 + (as final product requires multiplications
requires least one multiplication) bounded (k 1) (as k 1
factor multiplications requires multiplications).
associative ordering imposed absorption rules variable eliminated
(which example implies absorbing P(C|B) P(D|B) P(B|A)) may
optimal multiplication ordering. absorption ordering (that saves reduced splitting)
seen heuristic; may worthwhile meta-level analysis determine
order multiply (Bertel Brioschi, 1972; Shachter et al., 1990; DAmbrosio, 1995),
beyond scope paper.
5.2 Summing Variable
Suppose eliminating , absorbed confactors contain
confactors . two confactors R contain incompatible contexts.
contexts confactors contain table disjoint contexts confactors
contain body.
Summing confactor contains table proceeds before. use
similar trick absorption avoid splitting adding confactors contain
body.
Suppose domain {v1 , . . . , vs }. contexts confactors =vi body
exclusive disjunct logically equivalent disjunct confactors =vj body
value vj .
1 s, let Ri = {b, : b =vi , R+ }. Thus Ri confactor = vi
context, = vi omitted context. combine Ri using binary
operation:
R1 g R2 = {c1 c2 , set(t1 , c2 ) set(t2 , c1 ) : c1 , t1 R1 , c2 , t2 R2 , compatible(c1 , c2 )}
addition operation defined tables identical product Definition
3 except adds values instead multiplying them.
R1 g R2 g . . . g Rs result summing confactors
body.
5.3 Contextual Variable Elimination Absorption
version contextual variable elimination uses absorption, given Figure 9.
algorithm used experimental results Section 6.
elimination procedure called non-query, non-observed variable. order
variables selected called elimination ordering. algorithm imply
elimination ordering given priori.
One main issues implementing algorithm efficient indexing confactors.
want able quickly find confactors , confactors contain , compatible
confactors addition absorption. given prior elimination ordering, use
idea bucket elimination (Dechter, 1996), namely confactor placed bucket
earliest variable elimination ordering. eliminate , confactors
contain bucket. dont prior elimination ordering, keep inverted
296

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

compute P(X|E1 =o1 . . . Es =os )
Given
multiset contextual contribution confactors
1. Incorporate evidence Section 4.7.
2. factor involving non-query variable
Select non-query variable eliminate;
Call eliminate(Y ).
3. Compute posterior probability X Section 4.8
Procedure eliminate(Y):
partition confactorbase R into:
R confactors dont involve
R+ = {r R : r confactor }
R = {r R : r involves r confactor };
r R
R+ absorb(R+ , r);
partition R+ into:
Rt = {r R+ : table r}
Ri = {b, : b =vi , R+ } 1
s, dom(Y ) = {v1 , . . . , vs }.
Return confactorbase R (R1 g g Rs ) {bi , ti : bi , ti Rt }.
absorb(R, r) defined Section 5.1.
R1 g R2 defined Section 5.2.
Figure 9: Contextual Variable Elimination Absorption

297

fiPOOLE & ZHANG

list confactors (for variable, list confactors variable
list confactors contain variable). maintain lists
create new confactors delete old ones. also want able index confactors
quickly find confactors contain variable eliminated compatible
contexts. implementation, compared confactors contain variable
eliminated, rejected incompatible contexts. Ideally, able better
this, open question.
number choice points algorithm:
elimination ordering.
splitting ordering; computing residuals, order variables split on.
discussed Section 4.4.
order elements R absorbed. impact similar choice
multiplication ordering (when multiply number factors, order
done); sometimes smaller intermediate factors choice
done appropriately.

6. Empirical Results
interesting question whether real examples advantage exploiting contextual independence outweighs overhead maintaining confactors.
easily generate synthetic examples exponentially worse contextual
variable elimination (for example, consider single variable n, otherwise unconnected, parents,
decision tree variable one instance parent variable,
eliminate leaves). another extreme, contexts empty, get
little overhead. However, little bit CSI, possible need overhead
reasoning variables contexts, get additional savings. role empirical
results investigate whether ever worthwhile trying exploit context-specific independence,
features problem lead efficient inference.
6.1 Pseudo-Natural Example
may seem able test whether CVE worthwhile natural examples
comparing standard examples, isnt obvious meaningful. tablebased representations, huge overhead adding new parent variable, however
overhead making complex function variable depends existing parents. Thus,
without availability effective algorithms exploit contextual independence
small overhead adding variable restricted contexts, arguable builders models
tend reluctant add variables, tend overfit function variable depends
parents. models approximations makes sense consider approximations standard
models. testing approximations (Dearden Boutilier, 1997; Poole, 1998),
pretend real models.
section produce evidence exists networks CVE better
VE. sole purpose experiment demonstrate potentially problems
worthwhile using CVE. use instance water network (Jensen, Kjrulff, Olesen
298

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

100
0 observations
5 observations
10 observations
CVE=VE

runtime (secs)

10

1

0.1

0.01

0.001
0.001

0.01

0.1
1
CVE runtime (secs)

10

100

Figure 10: Scatterplot runtimes (in msecs) CVE (x-axis) (y-axis) water network.
Full details Appendix A.

Pedersen, 1989) Bayesian network repository8 approximated conditional
probabilities create contextual independencies. Full details examples constructed
Appendix A. collapsed probabilities within 0.05 create confactors.
water network 32 variables tabular representation table size 11018 (after
removing variables tables made difference less 0.05). contextual belief
network representation constructed 41 confactors total table size 5834.
Figure 10 shows scatter plot 60 runs random queries9 . 20 runs 0,
5 10 observed variables. raw data presented Appendix A. first thing notice
that, number observations increases, inference becomes much faster. CVE often
significantly faster VE. cases CVE much worse VE; essentially,
given elimination ordering, context-specific independence didnt save us anything
example, pay overhead variables context.
8. http://www.cs.huji.ac.il/labs/compbio/Repository/
9. Note results statistically significant degree. least significant 10 observations,
that, using matched-sample t-test (also known paired t-test), significant 0.2 level logarithm
runtimes. others significant way 0.001 level. logarithm appropriate difference
logarithms corresponds multiplicative speedup.

299

fiPOOLE & ZHANG

6.2 Randomised Networks
order see algorithm depends structure inherent network, constructed
number parametrized classes networks. explicitly constructed networks display
contextual independence, contextual independence algorithm degenerates
VE.
following parameters building random networks:
n number variables
number splits (so n + confactors).
p probability predecessor variable isnt context confactor
table confactor.
exact algorithm constructing examples given Appendix A.
variable controls number confactors, p controls (probabilistically) size
tables. Figure 1110 shows scatter plot comparing runtimes CVE n = 30
p = 0.2 three different values s, 5, 10, 15.
may look reasonable, noticed number splits number
different variables splits strongly correlated examples (see Appendix details).
However, one properties CVE variable appear body
confactor, never added context constructed confactor. is, variable
appears tables, always stays tables. Thus may conjectured fewer variables
appearing contexts may good efficiency.
carried another experiment test hypothesis. experiment, networks
generated before, however, went split context attempted first split using
variable appears different context using variable didnt appear context.
full details algorithms generate examples example data given Appendix A.
Figure 12 shows scatter plot comparing run times CVE generated
examples. class networks CVE significantly faster VE.

7. Comparison Proposals
section compare CVE proposals exploiting context-specific information.
belief network conditional probability table Figure 1 (i.e., contextual
independence shown Figure 4) particularly illuminating algorithms badly
it. elimination ordering B, D, C, A, , Z, find marginal E, complicated
confactor multiset created confactor multiset E eliminating B (see Example 14)
total table size 16. Observations simplify algorithm mean fewer partial evaluations.
contrast, requires factor table size 64 B eliminated. Clique tree propagation
constructs two cliques, one containing , Z, A, B, C, size 26 = 64, containing
A, B, C, D, E size 32. Neither takes structure conditional probabilities account.
Note however, clique tree propagation manipulate tables indexed much
faster manipulate confactors. cases total size tables
10. Note results statistically significant. least significant = 10 plot that, using matchedsample t-test (also known paired t-test), significant 0.05 level logarithm runtimes.
logarithm appropriate difference logarithms corresponds multiplicative speedup.

300

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

1000
s=5
s=10
s=15
CVE=VE

runtime (secs)

100

10

1

0.1
0.1

1

10
CVE runtime (secs)

100

1000

Figure 11: Scatterplot runtimes (in seconds) CVE (x-axis) (y-axis) randomised
networks

301

fiPOOLE & ZHANG

1000
s=5
s=10
s=15
CVE=VE

runtime (secs)

100

10

1

0.1
0.1

1

10
CVE runtime (secs)

100

1000

Figure 12: Scatterplot runtimes (in seconds) CVE (x-axis) (y-axis) random networks
biased towards fewer different variables contexts.

302

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

confactors exponentially smaller tables (where added variables relevant narrow
contexts). cases table size confactors table size
VE, overhead manipulating contexts make CVE competitive
table-based methods.
Boutilier et al. (1996) present two algorithms exploit structure. network transformation
clustering method, example Figure 1 worst case; structure exploited
triangulation resulting graph. (The tree E Figure 3 structurally identical tree
X(1) Figure 2 (Boutilier et al., 1996)). structured cutset conditioning algorithm
well example. However, example changed multiple (disconnected)
copies graph, cutset conditioning algorithm exponential number copies,
whereas probabilistic partial evaluation algorithm linear11 .
algorithm closely related tree-based algorithms solving MDPs (Boutilier
et al., 1995), work much restricted networks stringent assumptions
observable. CVE simpler analogous algorithm Boutilier (1997) structured
MDP correlated action effects represents conditional probabilities trees. Section 4.12
shows better tree-based algorithms.
Poole (1997) gave earlier version rule-based VE, complicated
distinguished head body rules part inference (although confactors
X correspond rules X head). CVE much efficient rule-based
allows faster indexing tables. notion absorption introduced Zhang (1998),
motivated work different way. Zhang Poole (1999) give mathematical
analysis context-specific independence exploited terms partial functions.
union-product formalization operation using confactors. current paper
extends giving specific algorithm showing combine confactors tables,
gives general analysis need confactor splitting dont need to,
gives sophisticated method initialize absorption (maintaining confactors variable)
gives much detailed empirical evaluation (with new implementation). ability
handle ones also improved.
Finally representation contrasted Geiger Heckerman (1996).
use similarity network gives global decomposition belief network; different
contexts allow different belief networks. allow local decomposition conditional
probabilities. algorithms similar.

8. Conclusion
paper presented method computing posterior probabilities belief networks exhibit
context-specific independence. algorithm instance variable elimination,
sum variable tables produced may depend different sets variables different contexts.
main open problem finding good heuristics elimination orderings (Bertel
Brioschi, 1972). Finding good elimination ordering related finding good triangulations
building compact junction trees, good heuristics (Kjrulff, 1990; Becker
Geiger, 1996). directly applicable contextual variable elimination (although
11. mean conditioning algorithms need suffer this. conjecture conditioning
algorithm extend contextual save space, bucket elimination algorithms (Dechter, 1996)
relevant cutsets probabilistic inference (Darwiche, 1995; Dez, 1996).

303

fiPOOLE & ZHANG

analogous heuristics applicable), important criteria case exact form
confactors, graphical structure belief network. means
feasible compute elimination ordering priori. also investigating anarchic orderings
eliminate variable contexts, without eliminating every context
partially eliminate another variable. believe opportunistic elimination variables
contexts much potential improve efficiency without affecting correctness.
One main potential benefits algorithm approximation algorithms,
confactors allow fine-grained control distinctions. Complementary confactors similar
probabilities collapsed simpler confactor. potentially lead compact
confactor bases, reasonable posterior ranges (Dearden Boutilier, 1997; Poole, 1998).
work reported paper followed number researchers. Tung (2002)
shown exploit context-specific independence clique trees. Guestrin, Venkataraman
Koller (2002) extended contextual variable elimination multi-agent coordination planning.

Acknowledgements
work supported Institute Robotics Intelligent Systems, Natural Sciences
Engineering Research Council Canada Research Grant OGPOO44121 Hong Kong Research
Grants Council grant HKUST6093/99E. Thanks Rita Sharma, Holger Hoos, Michael Horsch
anonymous reviewers valuable comments, Valerie McRae careful proofreading.
code available first author.

Appendix A. Details experiments
A.1 Water Network
order construct pseudo-natural example, used water network Bayesian
network repository12 modified let exhibit context-specific independence. table,
variable declared redundant differences probabilities values variable
less threshold 0.05 (thus, chose midpoint reduced
table, original probabilities less 0.025 midpoint). order discover
context-specific independence, carried greedy top-down algorithm build decision tree.
building conditional variable Xi , chose variable split results
maximum number pairs numbers values Xi within threshold 0.05
other. recursively remove redundant variables side, keep splitting.
built tree, node, decide whether use tabular representation factored
representation. experiments, committed context-based representation
total size context-based representation (obtained simply summing sizes tables)
less 51% tabular representation.
noted thresholds chosen arbitrarily. used 0.03 instead
0.05, didnt find context-specific independence. chose 0.07 instead 0.05,
tabular representation collapses. chose 80% 99% instead 51% threshold
accepting change, got smaller tables, much larger run times.
12. http://www.cs.huji.ac.il/labs/compbio/Repository/

304

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

CVE
Query Var
#11(CKND_12_15)
#13(CBODN_12_15)
#27(CKND_12_45)
#25(CKNI_12_45)
#22(CKNN_12_30)
#21(CBODN_12_30)
#17(CKNI_12_30)
#22(CKNN_12_30)
#19(CKND_12_30)
#15(CNON_12_15)
#12(CNOD_12_15)
#3(CKND_12_00)
#16(C_NI_12_30)
#30(CKNN_12_45)
#4(CNOD_12_00)
#21(CBODN_12_30)
#5(CBODN_12_00)
#19(CKND_12_30)
#11(CKND_12_15)
#23(CNON_12_30)

Time
15039
620
3808
1708
367
7953
742
363
7939
8177
618
419
429
2902
2496
8042
992
7936
16290
604

Size
1327104
16384
186624
36864
16128
193536
48384
16128
774144
193536
37044
29376
28224
112896
110592
193536
112320
774144
1327104
37044


Time
25368
4552
53965
57414
3821
13997
3677
3846
26654
14599
4264
9414
3799
52648
42270
13619
3334
25637
24753
3535

Size
5308416
442368
15925248
7077888
442368
1769472
442368
442368
2359296
1769472
442368
1327104
442368
15925248
5308416
1769472
442368
2359296
5308416
442368

Figure 13: Data random queries observed variables water network
Figure 13 shows details data observations. Figures 14 15
shows details data 5 10 observation respectively. make
data shown Figure 10 main paper. show index variable given ordering
repository (we started counting 0).
times milliseconds Java implementation running 700 MHz Pentium
running Linux 768 megabytes memory. order allow variation run times due
garbage collection evaluation run three times smallest time returned.
space maximum table created maximum size sum confactors
created elimination one variable.
A.2 Randomised Experiments
following procedure used generate random networks. Given n variables,
impose total ordering. build decision tree variable. leaves decision trees
correspond contexts variable tree for. start empty decision tree
variable. randomly (with uniform probability) choose leaf variable. variable
possible split (i.e., predecessor total ordering variable leaf
context corresponding leaf doesnt commit value variable), split leaf
variable. repeated n + leaves. leaf, built confactor
context predecessor variable leaf included
305

fiPOOLE & ZHANG

Observed
#1=2 #2=2 #26=2 #28=1 #30=1
#6=2 #8=1 #11=2 #14=2 #24=1
#8=3 #14=0 #15=3 #18=3 #20=2
#5=1 #9=0 #12=2 #15=0 #16=3
#6=1 #7=0 #11=1 #13=3 #25=2
#2=1 #6=0 #13=0 #19=1 #25=0
#0=3 #2=1 #18=2 #20=1 #23=1
#4=3 #10=3 #12=3 #17=0 #28=2
#3=1 #11=1 #19=1 #25=1 #31=3
#10=3 #19=0 #21=0 #26=0 #27=0
#11=1 #13=0 #21=1 #25=2 #29=2
#3=0 #23=1 #26=1 #27=0 #28=3
#9=2 #10=1 #13=1 #25=2 #26=1
#9=1 #11=0 #14=2 #15=1 #27=0
#2=0 #10=2 #15=2 #17=1 #24=1
#2=0 #7=3 #15=1 #21=2 #27=2
#0=3 #2=0 #6=0 #7=2 #16=2
#2=2 #20=2 #24=2 #25=0 #30=0
#8=2 #11=2 #19=2 #25=1 #29=3
#9=1 #12=3 #13=0 #19=2 #21=3

Query Var
#8(C_NI_12_15)
#22(CKNN_12_30)
#6(CKNN_12_00)
#10(CBODD_12_15)
#27(CKND_12_45)
#18(CBODD_12_30)
#17(CKNI_12_30)
#6(CKNN_12_00)
#14(CKNN_12_15)
#16(C_NI_12_30)
#24(C_NI_12_45)
#15(CNON_12_15)
#30(CKNN_12_45)
#25(CKNI_12_45)
#8(C_NI_12_15)
#16(C_NI_12_30)
#29(CBODN_12_45)
#21(CBODN_12_30)
#9(CKNI_12_15)
#26(CBODD_12_45)

CVE
Time
Size
84
9216
15
816
9
336
54
576
1184
28224
123
9216
16
1728
284
6912
1450
36864
1076
49152
353
28080
14258 193536
75
9216
65
4096
12
576
29
1008
7
336
453
49152
76
9216
31
1024


Time
579
156
26
71
3210
224
87
162
1041
521
13928
2600
2646
120
767
531
1304
877
216
440

Size
36864
9216
2304
6912
147456
12288
5184
20736
147456
49152
1327104
442368
248832
4096
110592
82944
147456
49152
9216
49152

Figure 14: Data random queries 5 randomly observed variables water network

306

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

Observed
#2=3 #3=0 #7=2 #12=1 #13=2
#19=1 #21=2 #22=2 #26=1 #30=1
#0=0 #3=0 #8=3 #12=3 #13=0
#16=2 #18=2 #26=3 #27=2 #28=1
#1=2 #6=0 #8=0 #11=2 #17=0
#20=3 #22=1 #23=1 #24=2 #26=2
#2=2 #5=3 #8=0 #9=1 #10=1
#17=2 #18=1 #22=2 #28=0 #30=1
#4=2 #7=1 #8=2 #12=1 #13=2
#15=3 #17=0 #19=0 #22=2 #31=2
#1=1 #7=1 #9=1 #10=0 #11=0
#13=3 #14=1 #23=1 #24=1 #30=2
#2=1 #4=0 #6=0 #15=0 #18=0
#22=2 #23=3 #24=2 #29=2 #30=1
#3=0 #10=0 #14=1 #16=3 #19=0
#24=1 #25=2 #28=3 #30=1 #31=1
#1=2 #2=3 #3=1 #9=2 #10=0
#14=0 #16=3 #25=1 #28=3 #30=2
#2=3 #5=1 #6=0 #11=2 #12=0
#17=1 #22=0 #24=3 #27=0 #28=1
#8=3 #9=2 #10=0 #11=1 #12=1
#14=2 #15=3 #19=0 #22=2 #26=3
#1=0 #7=2 #8=2 #13=0 #15=3
#17=2 #20=3 #26=1 #27=0 #31=3
#4=2 #5=3 #6=1 #9=1 #10=0
#12=2 #17=0 #19=1 #25=0 #29=0
#0=0 #2=1 #11=1 #13=1 #17=2
#21=3 #22=1 #23=1 #24=2 #30=2
#4=1 #9=0 #10=0 #11=1 #12=2
#23=1 #25=2 #29=1 #30=0 #31=2
#1=2 #6=0 #7=1 #10=3 #12=1
#15=3 #16=1 #17=2 #23=2 #24=1
#1=2 #2=2 #3=2 #5=2 #9=2
#13=1 #15=0 #22=1 #25=2 #30=0
#0=3 #1=1 #5=1 #6=0 #7=1
#8=2 #15=3 #17=0 #24=3 #25=0
#0=2 #6=1 #8=0 #9=2 #10=2
#16=0 #18=0 #19=0 #21=0 #26=0
#1=1 #3=0 #4=2 #9=1 #10=3
#13=0 #14=2 #22=0 #23=0 #30=2

Query

CVE
Time Size


Time

Size

#14

30

2304

40

2304

#7

14

256

17

768

#25

7

256

7

256

#23

4

192

4

192

#28

10

256

8

256

#22

9

336

10

768

#25

14

768

31

2304

#7

544

9216

121

9216

#8

10

1024

16

1024

#25

22

768

22

768

#5

3

84

4

192

#24

11

256

8

256

#23

6

256

23

1024

#27

10

576

18

768

#5

77

4096

141

12288

#27

3

64

4

144

#18

4

112

65

12288

#21

76

768

16

1024

#13

7

576

12

768

#6

37

768

17

768

Figure 15: Data random queries 10 randomly observed variables water network

307

fiPOOLE & ZHANG

generate_random_CBN(n, s, p) :
create n Boolean variables X1 , . . . , Xn
Let = {{}, Xi : n}
{S set context-variable pairs}
repeat
choose random c, Xi
choose random j 1 j < n
j < Xj doesnt appear c:



replace c, Xi c Xj = true, Xi c Xj = false, Xi
n + elements
c, Xi
Let V = {Xi }
j <
Xj doesnt appear c
probability p add Xj V
create random table variables V
add confactor c, contextual belief network
Figure 16: Algorithm constructing randomised examples
confactor probability p. variable leaf also confactor. assign
random numbers probabilities (these numbers wont affect anything results assuming
times operations floating point numbers isnt affected actual values numbers).
algorithm construct random examples used Section 6.2 given Figure 16. Note
choose random means choose randomly uniform distribution.
examples biased towards using fewer variables, replaced line:




replace c, Xi c Xj = true, Xi c Xj = false, Xi

k < Xk doesnt appear c Xk used another context

replace c, Xi c Xk = true, Xi c Xk = false, Xi
else




replace c, Xi c Xj = true, Xi c Xj = false, Xi
where, one k exists, k chosen uniformly values satisfy
condition.
Figure 17 shows details data shown Figure 11. times
Java implementation running 700 MHz Pentium running Linux 768 megabytes
memory. order allow variation run times due garbage collection, evaluation
run three times smallest time returned.
generated example, table Figure 17 shows
n number variables
308

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

n



p

30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30

5 (5)
5 (5)
5 (5)
5 (5)
5 (5)
5 (5)
5 (5)
5 (4)
5 (4)
5 (3)
10 (9)
10 (9)
10 (10)
10 (8)
10 (7)
10 (8)
10 (9)
10 (8)
10 (9)
10 (8)
15 (10)
15 (11)
15 (11)
15 (12)
15 (11)
15 (11)
15 (13)
15 (12)
15 (12)
15 (10)

0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2

CBN
Size
10922
1846
1964
1600
1668
904
1738
1744
3060
2692
3842
1262
3908
4904
10456
1790
2054
3608
6392
6180
2724
5896
2096
3674
2388
1938
4188
2806
3512
1700

BN
Size
8398266
132692
13456
4908
8292
1906
10786
18538
87292
69602
530622
36070
80704
33568176
314126
28758
24452
58352
1188654
42344
2104338
8425520
2239982
39928
552768
49388
351374
111632
126464
541498

CVE
Time
MTS
31388 2097152
9653
393216
2022
131072
3922
196608
60304
614400
637
32768
720
42048
2223
131072
11681
524288
5325
262144
22288
524288
4063
147456
112537 1966080
81450 5111808
31627
589824
1590
98304
13642
262144
24948
819200
403347 5767168
10078
253952
56636 1572864
185925 6389760
27065
825344
6393
360448
8623
425984
11299
438272
18602
432776
3213
138240
16118
258048
5986
172032


Time
84801
12418
3748
5572
61612
1005
1340
2546
12298
9530
31835
11038
31214
203284
44079
2974
5253
18574
359992
17501
49316
260645
42180
9631
13641
27303
38843
5463
11479
8414

Figure 17: Comparisons random networks exhibit CSI.

309

MTS
4194304
524288
131072
524288
2097152
65536
131072
262144
1048576
524288
2097152
524288
4194304
16777216
2097152
262144
262144
1048576
33554432
1048576
2097152
16777216
2097152
524288
524288
2097152
2097152
1048576
1048576
524288

fiPOOLE & ZHANG

number splits and, parentheses, number different variables splits
occur (different leaves split variable).
p probability splitting variable possible split on.
CBN size: total size (summing size tables) contextual belief network
representation.
BN size: total size factors corresponding belief network (i.e., assuming
probabilities stored tables).
CVE time runtime (in msecs) contextual variable elimination CVE MTS
maximum sum table sizes created elimination single variable.
time: runtime (in msecs) variable elimination MTS maximum table
size created elimination single variable.

References
Becker, A. Geiger, D. (1996). sufficiently fast algorithm finding close optimal junction trees, E. Horvitz F. Jensen (eds), Proc. Twelfth Conf. Uncertainty Artificial
Intelligence (UAI-96), Portland, OR, pp. 8189.
Bertel, U. Brioschi, F. (1972). Nonserial dynamic programming, Vol. 91 Mathematics
Science Engineering, Academic Press.
Boutilier, C. (1997). Correlated action effects decision theoretic regression, Dan Geger
Prakash Shenoy (ed.), Proceedings Thirteenth Annual Conference Uncertainty
Artificial Intelligence (UAI97), Providence, Rhode Island, pp. 3037.
Boutilier, C., Dearden, R. Goldszmidt, M. (1995). Exploiting structure policy construction,
Proc. 14th International Joint Conf. Artificial Intelligence (IJCAI-95), Montral, Qubec,
pp. 11041111.
Boutilier, C., Friedman, N., Goldszmidt, M. Koller, D. (1996). Context-specific independence
Bayesian networks, E. Horvitz F. Jensen (eds), Proc. Twelfth Conf. Uncertainty
Artificial Intelligence (UAI-96), Portland, OR, pp. 115123.
Chickering, D. M., Heckerman, D. Meek, C. (1997). Bayesian approach learning Bayesian
networks local structure, Proc. Thirteenth Conf. Uncertainty Artificial Intelligence
(UAI-97), pp. 8089.
Dagum, P. Luby, M. (1993). Approximating probabilistic inference Bayesian belief networks
NP-hard, Artificial Intelligence 60(1): 141153.
DAmbrosio (1995). Local expression languages probabilistic dependence, International Journal
Approximate Reasoning 13(1): 6181.
310

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

n



p

30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30
30

5 (3)
5 (2)
5 (2)
5 (2)
5 (1)
5 (2)
5 (2)
5 (1)
5 (3)
5 (2)
10 (3)
10 (3)
10 (2)
10 (3)
10 (2)
10 (2)
10 (3)
10 (2)
10 (2)
10 (3)
15 (2)
15 (3)
15 (3)
15 (2)
15 (3)
15 (4)
15 (3)
15 (3)
15 (3)
15 (2)

0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2
0.2

CBN
Size
1602
6108
17526
892
1540
1156
2344
1406
7740
4184
3038
888
3372
2240
1106
778
1888
9740
1102
4078
2710
1246
2046
1588
2260
2842
3074
1834
4362
3142

BN
Size
3658
7240
19632
4164
2640
5572
68676
7284
209652
8838
1119562
5176
4222408
30968
11660
4582
72260
413892
7744
298438
50698
84836
75956
138888
20230
67385366
533738
278426
209186
151160

CVE
Time
662
1583
6754
1604
261
608
12462
2197
17736
8053
30669
565
21834
20308
741
274
6659
11271
313
61140
8845
1935
54571
14280
522
322274
85480
18560
22872
4476

MTS
49152
131072
393216
81920
16512
40960
1048576
81920
851968
528384
1048576
24576
917504
524800
32768
18432
262144
868352
16384
1048576
524288
90112
1310720
458752
28672
10485760
2752512
753664
1441792
164096


Time
604
1945
8833
3119
457
816
9370
4021
18279
16437
53732
2625
108732
129885
433
656
11986
179564
1395
79858
39265
3652
141386
43059
1815
726989
89431
43554
131704
26426

MTS
65536
131072
1048576
131072
32768
65536
1048576
262144
2097152
1048576
2097152
131072
4194304
4194304
65536
65536
524288
8388608
65536
4194304
2097152
262144
8388608
2097152
131072
33554432
8388608
1048576
4194304
1048576

Figure 18: details data Figure 12 (biased towards fewer different variables)

311

fiPOOLE & ZHANG

Darwiche, A. (1995). Conditioning algorithms exact approximate inference causal networks, P. Besnard S. Hanks (ed.), Proc. Eleventh Conf. Uncertainty Artificial
Intelligence (UAI-95), Montreal, Quebec, pp. 99107.
Dearden, R. Boutilier, C. (1997). Abstraction approximate decision theoretic planning,
Artificial Intelligence 89(1): 219283.
Dechter, R. (1996). Bucket elimination: unifying framework probabilistic inference,
E. Horvitz F. Jensen (eds), Proc. Twelfth Conf. Uncertainty Artificial Intelligence
(UAI-96), Portland, OR, pp. 211219.
Dez, F. (1996). Local conditioning Bayesian networks, Artificial Intelligence 87(12): 120.
Friedman, N. Goldszmidt, M. (1996). Learning Bayesian networks local structure, Proc.
Twelfth Conf. Uncertainty Artificial Intelligence (UAI-96), pp. 252262.
Geiger, D. Heckerman, D. (1996). Knowledge representation inference similarity networks
Bayesian multinets, Artificial Intelligence 82: 4574.
Guestrin, C., Venkataraman, S. Koller, D. (2002). Context specific multiagent coordination
planning factored MDPs, Eighteenth National Conference Artificial Intelligence
(AAAI-2002), Edmonton, Canada.
Heckerman, D. Breese, J. (1994). new look causal independence, Proc. Tenth
Conference Uncertainty Artificial Intelligence, pp. 286292.
Jensen, F. V., Kjrulff, U., Olesen, K. G. Pedersen, J. (1989). Et forprojekt til et ekspertsystem
drift af spildevandsrensning (an expert system control waste water treatment
pilot project), Technical report, Judex Datasystemer A/S, Aalborg, Denmark. Danish.
Jensen, F. V., Lauritzen, S. L. Olesen, K. G. (1990). Bayesian updating causal probabilistic
networks local computations, Computational Statistics Quarterly 4: 269282.
Kjrulff, U. (1990). Triangulation graphs - algorithms giving small total state space, Technical
Report R 90-09, Department Mathematics Computer Science, Strandvejen, DK 9000
Aalborg, Denmark.
Lauritzen, S. L. Spiegelhalter, D. J. (1988). Local computations probabilities graphical
structures application expert systems, Journal Royal Statistical Society, Series
B 50(2): 157224.
Neal, R. (1992). Connectionist learning belief networks, Artificial Intelligence 56: 71113.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference,
Morgan Kaufmann, San Mateo, CA.
Poole, D. (1993). Probabilistic Horn abduction Bayesian networks, Artificial Intelligence
64(1): 81129.
312

fiEXPLOITING CONTEXTUAL INDEPENDENCE PROBABILISTIC INFERENCE

Poole, D. (1995). Exploiting rule structure decision making within independent choice
logic, P. Besnard S. Hanks (eds), Proc. Eleventh Conf. Uncertainty Artificial
Intelligence (UAI-95), Montral, Qubec, pp. 454463.
Poole, D. (1997). Probabilistic partial evaluation: Exploiting rule structure probabilistic inference, Proc. 15th International Joint Conf. Artificial Intelligence (IJCAI-97), Nagoya, Japan,
pp. 12841291.
Poole, D. (1998). Context-specific approximation probabilistic inference, G.F. Cooper
S. Moral (ed.), Proc. Fourteenth Conf. Uncertainty Artificial Intelligence, Madison, WI,
pp. 447454.
Saul, L., Jaakkola, T. Jordan, M. (1996). Mean field theory sigmoid belief networks, Journal
Artificial Intelligence Research 4: 6176.
Shachter, R. D., DAmbrosio, B. D. Del Favero, B. D. (1990). Symbolic probabilistic inference
belief networks, Proc. 8th National Conference Artificial Intelligence, MIT Press, Boston,
pp. 126131.
Smith, J. E., Holtzman, S. Matheson, J. E. (1993). Structuring conditional relationships
influence diagrams, Operations Research 41(2): 280297.
Tung, L. (2002). clique tree algorithm exploiting context-specific independence, Masters thesis,
Department Computer Science, University British Columbia.
Zhang, N. L. (1998). Inference Bayesian networks: role context-specific independence,
Technical Report HKUST-CS98-09, Department Computer Science, Hong Kong University
Science Technology.
Zhang, N. L. Poole, D. (1999). role context-specific independence probabilistic
reasoning, Proc. 16th International Joint Conf. Artificial Intelligence (IJCAI-99), Stockholm,
Sweden, pp. 12881293.
Zhang, N. Poole, D. (1994). simple approach Bayesian network computations, Proc.
Tenth Canadian Conference Artificial Intelligence, pp. 171178.
Zhang, N. Poole, D. (1996). Exploiting causal independence Bayesian network inference,
Journal Artificial Intelligence Research 5: 301328.

313

fiJournal Artificial Intelligence Research 18 (2003) 117-147

Submitted 7/02; published 2/03

Translation Pronominal Anaphora English
Spanish: Discrepancies Evaluation
Jesus Peral

jperal@dlsi.ua.es

Dept. Lenguajes Sistemas Informaticos
University Alicante
Alicante, SPAIN

Antonio Ferrandez

antonio@dlsi.ua.es

Dept. Lenguajes Sistemas Informaticos
University Alicante
Alicante, SPAIN

Abstract
paper evaluates different tasks carried translation pronominal
anaphora machine translation (MT) system. MT interlingua approach named
AGIR (Anaphora Generation Interlingua Representation) improves upon
proposals presented date able translate intersentential anaphors, detect co-reference chains, translate Spanish zero pronouns Englishissues hardly
considered systems. paper presents resolution evaluation
anaphora problems AGIR use different kinds knowledge (lexical, morphological, syntactic, semantic). translation English Spanish anaphoric
third-person personal pronouns (including Spanish zero pronouns) target language
evaluated unrestricted corpora. obtained precision 80.4%
84.8% translation Spanish English pronouns, respectively. Although
studied Spanish English languages, approach easily extended
languages Portuguese, Italian, Japanese.

1. Introduction
anaphora phenomenon considered one difficult problems natural
language processing (NLP). etymology term anaphora originates Ancient
Greek word anaphora (o), made separate words, (back,
upstream, back upward direction) (the act carrying),
denotes act carrying back upstream.
Presently, various definitions term anaphora exist, concept underlies
them. Halliday & Hassan (1976) defined anaphora cohesion (presupposition)
points back previous item. formal definition proposed Hirst
(1981), defined anaphora device making abbreviated reference (containing
fewer bits disambiguating information, rather lexically phonetically shorter)
entity (or entities) expectation receiver discourse able
disabbreviate reference and, thereby, determine identity entity. Hirst
refers entity anaphor, entity refers antecedent:
[Mary]i went cinema Thursday. Shei didnt like film.
c
2003
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiPeral & Ferrandez

example, pronoun anaphor noun phrase Mary
antecedent. type anaphora common type, so-called pronominal
anaphora.
anaphora phenomenon broken two processes:
resolution generation. Resolution refers process determining antecedent
anaphor; generation process creating references discourse entity.
context machine translation, resolution anaphoric expressions crucial
importance order translate/generate correctly target language (Mitkov
& Schmidt, 1998). Solving anaphora extracting antecedent key issues
correct translation target language. instance, translating languages
mark gender pronouns, resolution anaphoric relation essential. Unfortunately, majority MT systems deal anaphora resolution,
successful operation usually go beyond sentence level.
employed computational system focuses anaphora resolution order
improve MT quality measured improvements. SUPAR (Slot
Unification Parser Anaphora Resolution) system presented work Ferrandez,
Palomar, & Moreno (1999). system deal several kinds anaphora
good results. example, system resolves pronominal anaphora Spanish
precision rate 76.8% (Palomar et al., 2001); resolves one-anaphora Spanish dialogues
precision rate 81.5% (Palomar & Martnez-Barco, 2001), resolves definite
descriptions Spanish direct anaphora bridging references precision rates 83.4%
63.3%, respectively (Munoz, Palomar, & Ferrandez, 2000). work presented here,
used MT system exclusively pronominal anaphora resolution translation.
kind anaphora usually taken account MT systems,
therefore pronouns usually translated incorrectly target language. Although
focused pronominal anaphora, approach easily extended
kinds anaphora, one-anaphora definite descriptions previously resolved
SUPAR system.
important emphasize work resolve translate personal
pronouns third person whose antecedents appear anaphorthat is,
anaphoric relation pronoun antecedent established, cataphoric
relations (in antecedent appears anaphor) taken account.
paper focuses evaluation different tasks carried approach
lead final task: translation pronominal anaphora target
language. main contributions work presentation evaluation
multilingual anaphora resolution module (English Spanish) exhaustive evaluation pronominal anaphora translation languages.
paper organized follows: Section 2 shows anaphora-resolution needs MT
deficiencies traditional MT systems resolve phenomenon conveniently.
Section 3 presents analysis module approach. Section 4, identify
evaluate NLP problems related pronominal anaphora resolved system. Section
5 presents generation module system. Section 6, generation module
evaluated order measure efficiency proposal. Finally, present
conclusions.
118

fiTranslation Pronominal Anaphora English Spanish

2. Anaphora Resolution Importance MT
noted earlier, anaphora resolution crucial importance order translate anaphoric
expressions correctly target language. Let us consider sentences (Hutchins &
Somers, 1992):
1. [The monkey]i ate banana iti hungry.
2. monkey ate [the banana]i iti ripe.
3. monkey ate banana tea-time.
sentence pronoun refers something different: sentence (1), refers
monkey, sentence (2) banana, sentence (3), abstract notion
time. wish translate sentences Spanish German (languages
mark gender pronouns), anaphora resolution absolutely essential since,
languages, pronouns take gender antecedents. Therefore, Spanish,
would obtain following pronouns: (1) este (in masculine form since antecedent
monkeyis masculine), (2) esta (femininethe banana), (3) omitted pronoun
(since second clause sentence impersonal Spanish need
subject). hand, German would obtain: (1) er (masculine antecedent),
(2) sie (feminine antecedent), (3) es (neutral).
Besides problems, originated gender anaphoric expressions different
languages, differences (that named discrepancies) influence
process translation expressions. discrepancies previously
studied authors. Mitkov & Schmidt (1998) present several problems taken
account translation pronominal anaphors different languages (German, French, English, Malay, Korean); Nakaiwa & Ikeara (1992) treat problem
translation elliptical constructions JapaneseEnglish MT system; Mitkov et
al. (1994) Geldbach (1999) present discrepancies EnglishKorean MT system
RussianGerman MT system, respectively.
Another difference languages number discrepancies, certain
nouns referred singular pronoun one language plural noun
other. example, word people plural English, whereas Spanish German
singular. Hence, translations English Spanish, English German,
plural pronoun become singular pronoun.
hand, although majority cases language-pairs pronouns
source language translated target-language pronouns correspond antecedent anaphor, exceptions. cases, pronominal
anaphors simply omitted target language. instance, translations
English Spanish, pronouns frequently translated typical Spanish
elliptical zero-subject construction. languages typical zero constructions
Japanese, Italian, Thai, Chinese.
languages, however, pronoun directly translated antecedent.
example, EnglishMalay translations tendency replace pronoun
antecedent, case translator must first able identify antecedent.
119

fiPeral & Ferrandez

languages translate pronouns different expressions, depending syntactic
semantic information antecedent. example, EnglishKorean translation
pronouns elliptically omitted, translated definite noun phrases,
antecedent, different Korean pronouns.
above-mentioned problems translation anaphoric expressions
target language show important carry detailed analysis
expressions (including resolution identification antecedent).
majority MT systems handle one-sentence input, usually cannot
deal anaphora resolution, do, successful operation usually go
beyond sentence level. order assess deficiencies MT systems, analyzed
characteristics different MT systems, emphasis characteristics related
anaphora resolution translation target language. overview analysis
seen Table 1.
MT system
Systran
Meteo
SUSY
Ariane
Eurotra
METAL
Candide
Inter-Nostrum
IXA
Episteme
KANT
DLT
DLT (BKB)
Rosetta
CREST
kosmos
a.
b.
c.
d.
e.
f.

Strategya
Direct
Direct
Transfer
Transfer
Transfer
Transfer
Transfer
Transfer
Transfer
Transfer
Interlingua
Interlingua
Interlingua
Interlingua
Interlingua
Interlingua

Restrictb

Yes




Yes
Yes


Yes



Yes
Yes

Partialc
Yes




Yes

Yes
Yes








Anaphord
Yes

Yes
Yes

Yes




Yes

Yes

Yes


Corefere














Yes


Zerof
Yes


Yes

Yes




Yes



Yes


Strategy translation: direct, transfer, interlingua.
Restricted domain.
Partial parsing.
Resolution intersentential anaphora.
Identification co-reference chains.
Translation zero pronouns target language.

Table 1: Characteristics main MT systems
table reflects number different system characteristics.
1. MT system. MT systems studied included Systran (Toma, 1977; Wheeler,
1987); Meteo (Chandioux, 1976, 1989); SUSY (Maas, 1977, 1987); Ariane (Boitet &
Nedobejkine, 1981; Boitet, 1989); Eurotra (Varile & Lau, 1988; Allegranza, Krauwer,
& Steiner, 1991); METAL (Bennet & Slocum, 1985; Thurmair, 1990); Candide (Berger
120

fiTranslation Pronominal Anaphora English Spanish

et al., 1994); Inter-Nostrum (Canals-Marote et al., 2001a, 2001b); IXA (Daz-Ilarraza,
Mayor, & Sarasola, 2000, 2001); Episteme (Amores & Quesada, 1997; Quesada &
Amores, 2000); KANT (Goodman, 1989; Nirenburg, 1989; Mitamura, Nyberg, & Carbonell, 1991); DLT (Witkam, 1983; Schubert, 1986); DLT Bilingual Knowledge
Bank (BKB) (Sadler, 1989); Rosetta (Appelo & Landsbergen, 1986; Landsbergen,
1987); CREST (Farwell & Helmreich, 2000); kosmos (Mahesh & Nirenburg,
1995a, 1995b).
2. Strategy translation. characteristic indicates strategy used MT system accordance existence intermediate representations: direct, transfer,
interlingua.
3. Restricted domain. characteristic tells texts source language
specific domain (restricted domain).
4. Partial parsing. characteristic indicates MT system carries partial parsing source text identifying constituents (noun phrases,
prepositional phrases, etc.) relations them.
5. Resolution intersentential anaphora. characteristic indicates whether MT
system resolves intersentential anaphora. not, anaphoric expressions
antecedents previous sentences incorrectly translated
target language, cases.
6. Identification co-reference chains. characteristic tells us co-reference
chains source text identified resolving intersentential anaphora.
7. Translation zero pronouns. characteristic indicates MT system detects
resolves omitted pronouns (zero pronouns1 ) source language compulsory target language.
analyzing characteristics primary commercial MT systems, concluded
MT system work unrestricted texts, resolve intersentential
anaphora, identify co-reference chains text, translate zero pronouns
target language carrying partial parsing source text.
Unlike systems, KANT interlingua system, Meteo system,
Candide system, among others, designed well-defined domains, interlingua
MT approach, called AGIR (Anaphora Generation Interlingua Representation),
works unrestricted texts. Although could applied full parsing texts,
instead utilized partial parsing, due unavoidable incompleteness grammar.
main difference system interlingua systems,
DLT system (which based modification Esperanto), Rosetta system (which
experiments Montague semantics basis interlingua), KANT system,
others.
parsing solving pronominal anaphora, interlingua representation
entire text obtained. this, sentences split clauses, complex feature
1. kind pronouns presented detail Section 4.1.

121

fiPeral & Ferrandez

structure based semantic roles (agent, theme, etc.) generated one.
clause, different semantic roles appear identified linked one entity
text. anaphor text, linked entity represents
antecedent. AGIRs interlingua representation presented detail
(Peral, Palomar, & Ferrandez, 1999; Peral & Ferrandez, 2000a).
interlingua representation, translation anaphor (including intersentential anaphor), detection co-reference chains whole text, translation Spanish zero pronouns English carried out. AGIR designed deal issues hardly considered real MT
systems. Furthermore, approach used applications, example,
cross-language information retrieval, summarization, etc.
important note although above-mentioned MT systems resolve
different problems, zero pronouns pronominal anaphora, results
satisfactory. Furthermore, present examples (extracted corpora used
evaluation approachsee Section 4) incorrect SpanishEnglishSpanish
translations pronouns done Systran2 AGIR correctly3 :
(S) Siempre cre que lo que yo aspiraba era la comunicacion perfecta con un
hombre, o, mejor dicho, con el hombre, con ese prncipe azul de los suenos de infancia,
un ser que sabra adivinarme hasta en los mas menudos pliegues interiores. Ahora
aprendido solo que [esa fusion]i es imposible, sino ademas que es probablemente
indeseable.
(E) always thought aspired perfect communication
man, or, rather, man, blue prince childhood dreams,
would know guess slightest fold interiors.
learned fusion impossible, addition probably
undesirable.
example, Systran incorrectly translates English zero pronoun
last sentence paragraph, proposing pronoun instead pronoun (the
antecedent noun phrase esa fusionthat fusion). system proposed correct
pronoun. important note although zero pronoun identified Systran,
incorrectly solved subsequently incorrectly translated.
(S) Al pasar de [la luminosidad]i de la calle, tal vez por contraste con ellai , impresionaba la oscuridad interior el vaco de la Catedral, en la que apenas haba la
vista cuatro cinco personas.
(E) happening luminosity street, perhaps contrast
her, impressed inner dark emptiness Cathedral, soon
sight four five people.
2. free trial commercial product SYSTRANLinks (copyright 2002 SYSTRAN S.A.)
used translate English Spanish languages corpora used evaluation
approach. (URL = http://w4.systranlinks.com/config, visited 06/22/2002).
3. paper, used symbols (S) (E) represent Spanish English texts, respectively.
symbol indicates presence omitted pronoun. examples, pronoun
antecedent index; co-indexing indicates co-reference them.

122

fiTranslation Pronominal Anaphora English Spanish

case, Systran incorrectly translates English pronoun ella (with antecedent
la luminosidad luminosity), proposing pronoun instead it.
(E) already done so, unpack [your printer]i accessory kit
came iti .
(S) Si usted ha hecho ya pues, desempaquete su impresora el kit de accesorios
eso vino con el.
example shows incorrect EnglishSpanish translation pronoun it.
case, pronoun incorrectly solved (the antecedent noun phrase printer,
feminine) incorrectly translated (pronoun el masculineinstead pronoun
estafeminine).
examples illustrate translation pronouns could notably
improved antecedents correctly identified and, subsequently, pronouns
translated target language.

3. AGIRs Analysis Module
AGIR system architecture based general architecture MT system uses
interlingua strategy. Translation carried two stages: (1) source language
interlingua, (2) interlingua target language. Modules
analysis independent modules generation. Although present work
studied Spanish English languages, approach easily extended
languages, exampe, multilingual system, sense analysis module
linked generation module.
AGIR analysis carried using SUPAR (slot unification parser anaphora
resolution) (Ferrandez et al., 1999). SUPAR computational system focuses
anaphora resolution. deal several kinds anaphora, pronominal
anaphora, one-anaphora, definite descriptions4 . SUPARs input grammar defined means grammatical formalism SUG (slot unification grammar ). translator
transforms SUG rules Prolog clauses developed. translator provides
Prolog program parse sentence. SUPAR perform either full partial parsing text parser grammar. study, partial-parsing
techniques utilized due unavoidable incompleteness grammar
use unrestricted texts (corpora) input.
analysis source text carried several steps. first step
analysis module lexical morphological analysis input text.
use unrestricted texts input, system obtains lexical morphological
information texts lexical units output part-of-speech (POS) tagger.
word appears corpus, lemma, POS tag (with morphological
information) supplied lexical unit corpus.
4. One-anaphora following structure English: determiner pronoun one
premodifiers postmodifiers (the red one; one blue bow ). kind anaphors Spanish
consists noun phrases noun omitted (el rojo; el que tiene el lazo azul ).
definite descriptions, anaphors formed definite noun phrases refer objects usually
uniquely determined context.

123

fiPeral & Ferrandez

next step parsing text (which includes lexical morphological information extracted previous stage). applying parsing, text
split sentences. output slot structure (SS) stores necessary
information5 subsequent stages.
third step, module word-sense disambiguation (WSD) used obtain
single sense different texts lexical units. lexical resources, WordNet (Miller,
Beckwith, Fellbaum, Gross, & Miller, 1990) EuroWordNet (Vossen, 1998),
used stage6 .
SS, enriched information previous steps, input
next step, NLP problems (anaphora, extraposition, ellipsis, etc.) treated
solved. work, focused resolution NLP problems related
pronominal anaphora. step, new slot structure (SS) obtained. new
structure, correct antecedentchosen possible candidates applying
method based constraints preferences (Ferrandez et al., 1999)for anaphoric
expression stored along morphological semantic information. new
structure SS input final step analysis module.
last step, AGIR generates interlingua representation entire text.
main difference AGIR MT systems, process input text
sentence sentence. interlingua representation allow correct translation
intersentential intrasentential pronominal anaphora target language. Moreover, AGIR allows identification co-reference chains text subsequent
translation target language.
interlingua representation input text based clause main unit
representation. text split clauses, AGIR uses complex
feature structure clause. structure composed semantic roles features
extracted SS clause. notation used based one used
KANT interlingua.
important emphasize interlingua lexical unit represented
AGIR using word correct sense WordNet. accessing ILI (interlingual-index) module EuroWordNet, able generate lexical unit
target language.
semantic roles identified, interlingua representation store
clauses features, different entities appeared text
relations (such anaphoric relations). representation input
generation module.
5. SS stores following information constituent: constituent name (NP, PP, etc.), semantic
morphological information, discourse marker (identifier entity discourse object),
SS subconstituents.
6. evaluation approach, used English corpus (SemCor) content words
annotated WordNet sense; sense used identify semantic category
word. remaining corpora information senses content words; therefore,
set heuristics used identify semantic categories. Currently, WSD module (Montoyo
& Palomar, 2000) developed Research Group, incorporated system
future.

124

fiTranslation Pronominal Anaphora English Spanish

4. Resolution NLP Problems AGIR
fourth stage AGIRs analysis module allows resolution NLP problems. present work focuses resolution NLP problems related pronominal
anaphora source language translate anaphoric expressions correctly
target language. describing translation anaphoric, third-person,
personal pronouns target language. Therefore, focused discrepancies Spanish English treatment pronouns. next
two subsections, describe syntactic discrepancies treated solved AGIR
(Spanish zero pronouns) anaphora resolution module system.
4.1 Elliptical Zero-Subject Constructions (Zero Pronouns)
Spanish language allows omission pronominal subject sentences.
omitted pronouns usually called zero pronouns. Whereas languages (e.g.,
Japanese), zero pronouns may appear either subjects objects grammatical
position, Spanish texts zero pronouns appear position subject.
MT systems, correct detection resolution zero pronouns source
language crucial importance pronouns compulsory target language.
following example, Spanish sentence contains zero pronoun translation
English equivalent compulsory pronoun shown.
(S) [Ese hombre]i era un boxeador profesional. Perdio unicamente dos combates.
(E) [That man]i professional boxer. Hei lost two fights.
remark zero pronouns also occur English, although appear
less frequently, since usually used coordinated sentences zero pronoun usually refers subject sentence. Although zero pronouns already
studied languages, Japanesewith resolution percentage 78%
work (Okumura & Tamura, 1996), yet studied Spanish texts.
(Ferrandez & Peral, 2000) presented first algorithm Spanish zero-pronoun resolution. Basically, order translate Spanish zero pronouns English, must first
located text (ellipsis detection) resolved (anaphora resolution) (Peral &
Ferrandez, 2000b):
Zero-pronoun detection. order detect zero pronouns, sentences divided
clauses, since subject appear clause constituents.
that, noun-phrase (NP) pronoun sought, clause, clause
constituents lefthand side verb, unless imperative impersonal.
NP pronoun must agree person number verb clause.
Zero-pronoun resolution. zero pronoun detected, computational
system inserts pronoun position omitted. pronoun
detected resolved following module anaphora resolution. Person
number information obtained clause verb. Sometimes, Spanish,
gender information pronoun obtained object verb
125

fiPeral & Ferrandez

copulative. cases, subject must agree gender number
object whenever object either masculine feminine linguistic form.
4.1.1 Evaluation
evaluate task, two experiments performed: evaluation zero-pronoun
detection evaluation zero-pronoun resolution. experiments method
tested two kinds corpora. first instance, used portion LEXESP7
corpus contains set thirty-one documents (38,999 words) different genres
written different authors. LEXESP corpus contains texts different styles
different topics (newspaper articles politics, sports, etc.; narratives specific
topics; novel fragments; etc.). second instance, method tested fragment
Spanish version Blue Book (BB) corpus (15,571 words), technical manual
contains handbook International Telecommunications Union (CCITT) published
English, French, Spanish. corpora automatically tagged different taggers.
randomly selected subset LEXESP corpus (three documents 6,457 words)
fragment Blue Book corpus (4,723 words) training corpora. remaining
fragments corpora reserved test data.
important emphasize tasks presented paper automatically
evaluated annotation pronoun (including zero pronouns). so,
anaphoric, third-person, personal pronoun annotated information
antecedent translation target language. Furthermore, co-reference chains
identified. annotation phase accomplished following manner: (1)
two annotators (native speakers) selected language, (2) agreement
reached annotators regard annotation scheme, (3) annotator
annotated corpora, (4) reliability test (Carletta et al., 1997) done
annotation order guarantee results. reliability test used kappa statistic
measures agreement annotations two annotators making judgments
categories. way, annotation considered classification task consisting
defining adequate solution among candidate list. According Carletta et al. (1997),
k measurement 0.68 < k < 0.80 allows us draw encouraging conclusions,
measurement k > 0.80 means total reliability results two
annotators. tests, obtained kappa measurement 0.83. Therefore, consider
annotation obtained evaluation totally reliable.
4.1.2 Evaluation Zero-Pronoun Detection
evaluation zero-pronoun detection, training phase used carry modifications grammar order improve processes partial parsing clause
splitting. training, conducted blind test entire test corpus.
achieve sort evaluation, several different subtasks may considered. First,
verb must detected. task easily accomplished since corpora pre7. LEXESP corpus belongs project name, carried Psychology Department
University Oviedo developed Computational Linguistics Group University
Barcelona, collaboration Language Processing Group Catalonia University
Technology, Spain.

126

fiTranslation Pronominal Anaphora English Spanish

viously tagged. second task classify verbs two categories: (a) verbs whose
subjects omitted, (b) verbs whose subjects not. obtained results
LEXESP Blue Book corpora appear Table 2.

LX
BB

1st
240
0

Verbs subject omitted
Verbs subject omitted
P(%) 2nd P(%)
3rd
P(%) 1st P(%) 2nd P(%)
3rd
P(%)
96.7
54
98.1 1,227 97.1 31
71
17
94.1 1,085 83.3
PRECISION = 97.1%
PRECISION = 83.1%
0
0
0
121
97.5
0
0
0
0
351
82
PRECISION = 97.5%
PRECISION = 82.0%
GLOBAL PRECISION = 90.4%
Table 2: Zero-pronoun detection, evaluation phase

table divided two parts, corresponding categories (a) (b) previously
mentioned. category, number verbs first, second, third person,
together precision (P), represented. Precision defined number
verbs correctly classified (subject omitted not) divided total number verb
classifications attempted type. example, LEXESP corpus 1,227 verbs
third person subjects omitted classified, precision obtained
97.1%.
Discussion. detection zero pronouns following results obtained:
LEXESP corpus, precisions 97.1% 83.1% obtained verbs whose subjects
omitted omitted, respectively; BB corpus, precisions 97.5%
82% obtained. corpora, overall precision 90.4% (2,825 total
3,126) obtained task.
results, extracted following conclusions:
meaningful differences results obtained corpus.
BB corpus verbs either first second person. explained
considering style corpus: technical manual usually consists
series isolated definitions done writer.
rate precision detection verbs whose subjects omitted
lower (approximately 15%) detection verbs whose subjects omitted.
several reasons this:
POS tagger identify impersonal verbs. problem
partly resolved heuristically, choice impersonal verbs (e.g., llover
rain), cannot resolved impersonal verbs. example, verb
ser (to be) usually impersonal, certain constructions (e.g.,
Es hora de desayunar time breakfast).
ambiguity unavoidable incompleteness grammar affects
process clause splitting, therefore affects detection possible
subject clause lefthand side verb.
127

fiPeral & Ferrandez

Since first study done specifically Spanish texts since design
detection stage mainly depends upon structure language question,
compared results published works. comparisons would
prove insignificant8 .
Finally, important emphasize importance phenomenon Spanish.
Specifically, corpora, subject omitted 52.5% (1,642 3,126)
verbs. Furthermore, phenomenon even important narrative texts (57.3%
LEXESP corpus) technical manuals (25.6% BB corpus).
percentages show importance correctly detecting kinds pronouns MT
system conveniently translate target language.
4.1.3 Evaluation Zero-Pronoun Resolution
zero pronouns detected, resolved subsequent module
anaphora resolution (explained following subsection). Basically, algorithm
combines different kinds knowledge distinguishing constraints preferences
used (Ferrandez et al., 1999; Palomar et al., 2001).
set constraints preferences presents two basic differences zeropronoun pronominal anaphora resolution:
1. Zero-pronoun resolution constraint agreement person number,
whereas pronominal anaphora resolution also requires gender agreement.
2. Two new preferences solve zero pronouns used: (a) preference given
candidates sentence anaphor also solution
zero pronoun sentence anaphor, (b) case zero
pronoun gender information, preference given candidates agree
gender.
evaluating zero-pronoun resolution obtain best order preferences (one
produces best performance), used training phase identify importance
kind knowledge. this, analyzed antecedent pronoun
training corpora, identified configurational characteristics reference
pronoun (e.g., antecedent proper noun, antecedent indefinite
NP, antecedent occupied position reference verb anaphor
after, etc.). Subsequently, constructed table showed often
configurational characteristic valid solution particular pronoun (e.g.,
solution zero pronoun proper noun 63% time, reflexive pronoun,
proper noun 53% time, etc.). way, able define different
patterns Spanish pronoun resolution apply order obtain evaluation
results presented paper. order importance determined first
sorting preferences according percentage configurational characteristic;
8. order compare system systems, Section 6.2 evaluate pronoun translation
(including zero pronouns) Spanish English using commercial product SYSTRANLinks
Spanish LEXESP corpus. evaluation highlights deficiencies zero-pronoun detection,
resolution, translation (out 559 anaphoric, third-person, zero pronouns LEXESP corpus,
266 correctly translated Englisha precision 47.6%).

128

fiTranslation Pronominal Anaphora English Spanish

is, preferences higher percentages considered important
lower percentages. several experiments training corpora, optimal order
type anaphora obtained. Since phase processed texts different
genres different authors, state final set preferences obtained
order application used confidence Spanish text.
training, conducted blind test entire test corpus, results
shown Table 3.
Cataphoric
LEXESP
BB
TOTAL

640
76
716

Exophoric
28
8
36

Anaphoric
Correct Total
455
559
30
37
485
596

P(%)
81.4
81.1
81.4

Table 3: Zero-pronoun resolution, evaluation phase
important mention 3,126 verbs corpora, 1,348 (Table
2) zero pronouns third person resolved. Table 3 present
classification third-person zero pronouns, conveniently divided
three categories:
1. Cataphoric. category comprised zero pronouns whose antecedents,
is, clause subjects, come verb. instance, following Spanish
sentence Compro [un nino]i en el supermercado ([A boy]i bought supermarket), subject, un nino (a boy), appears verb, compro (bought).
kinds verbs quite common Spanish (P = 53.1%, 716 1,348),
seen Table 3, represents one main difficulties resolving anaphora
Spanish: structure sentence flexible English. represent
intonationally marked sentences, subject occupy usual position
sentence, is, verb. Cataphoric zero pronouns resolved AGIR, since semantic information needed able discard
antecedents give preference appear within sentence
clause verb.
example, sentence Compro un regalo en el supermercado ([He] bought
present supermarket) syntactic structure previous sentence,
i.e., verb, NP, PP, object function NP distinguished
subject means semantic knowledge.
2. Exophoric. category consists zero pronouns whose antecedents
appear linguistically text (they refer items external world rather
things referred text). Exophoric zero pronouns resolved
system.
3. Anaphoric. category comprised zero pronouns whose antecedents
found verb. kinds pronouns resolved system.
129

fiPeral & Ferrandez

Table 3 numbers cataphoric, exophoric, anaphoric zero pronouns
corpus shown. anaphoric pronouns, number pronouns correctly solved
well obtained precision, P (number pronouns correctly solved divided
number solved pronouns) presented. example, LEXESP corpus,
640 cataphoric, 28 exophoric, 559 anaphoric zero pronouns. anaphoric
pronouns, 455 correctly solved, giving precision 81.4%.
Discussion. zero-pronoun resolution, following results obtained: LEXESP corpus, P = 81.4%; BB corpus, P = 81.1%. combined corpora, overall
precision task 81.4% (485 596) obtained. overall recall, R (the
number pronouns correctly solved divided number real pronouns) obtained
79.1% (485 613).
results, extracted following conclusions:
meaningful differences results obtained corpus.
Errors zero-pronoun-resolution stage originated different causes:
exceptions application preferences imply selection incorrect antecedent solution zero pronoun (64% global mistakes)
lack semantic information9 , causing error rate 32.4%
mistakes POS tagging (3.6%)
Since results provided works obtained different languages
(English), texts, sorts knowledge (e.g., Hobbs Lappin full parse text), direct
comparisons possible. Therefore, order accomplish comparison,
implemented approaches SUPAR10 , adapting partial parsing
Spanish texts. Although approaches proposed zero pronouns
comparison fully fair, implemented since way
compare proposal directly well-known anaphora-resolution algorithms.
also compared system typical baseline proximity preference
(i.e., antecedent appears closest anaphora chosen among
satisfy constraintsmorphological agreement syntactic conditions). also
compared system baseline presented Hobbs (1978)11 Lappin & Leass
method (Lappin & Leass, 1994). Moreover, also compared proposal centering
approach implementing functional centering (Strube & Hahn, 1999). precisions
obtained different approaches AGIR shown Table 4. seen,
precision obtained AGIR better obtained using proposals.
9. important mention semantic information available Spanish corpora.
10. detailed study implementations SUPAR presented Palomar et al. (2001).
11. Hobbss baseline frequently used compare work accomplished anaphora resolution.
Hobbss algorithm work well carries full parsing text. Furthermore, manner syntactic tree explored using Hobbss algorithm best one
Spanish, since nearly free-word-order language.

130

fiTranslation Pronominal Anaphora English Spanish

LEXESP
BB

Proximity
54.9
48.6

Hobbs
60.4
62.2

Lappin
66.0
67.6

Strube
59.7
59.5

AGIR
81.4
81.1

Table 4: Zero-pronoun resolution Spanish, comparison AGIR approaches

4.2 Anaphora-Resolution Module
anaphora-resolution module used AGIR based module presented (Ferrandez et al., 1999; Palomar et al., 2001) SUPAR system. algorithm identifies
noun phrase (NP) antecedents personal, demonstrative, reflexive, zero pronouns
Spanish. identifies intrasentential intersentential antecedents applied
syntactic analysis generated SUPAR. also combines different forms knowledge
distinguishing constraints preferences. Whereas constraints used
combinations several kinds knowledge (lexical, morphological, syntactic), preferences defined combination heuristic rules extracted study different
corpora.
constraint defines property must satisfied order candidate
considered possible solution anaphor. constraints used algorithm
following: morphological agreement (person, gender, number) syntactic
conditions NP-pronoun non-co-reference.
preference characteristic always satisfied solution anaphor.
application preferences usually involves use heuristic rules order obtain
ranked list candidates. examples preferences used system following:
(a) antecedents sentence anaphor, (b) antecedents
repeated text, (c) antecedents appear verbs
(i.e., verb clause antecedent appears), (d) antecedents
proper nouns, (e) antecedents indefinite NP, on.
order solve pronominal anaphors, must first located text (anaphora
detection) resolved (anaphora resolution):

Anaphora detection. algorithm, types anaphors identified
left right appear sentences slot structure obtained partial
parsing. identify type pronoun, information stored POS tags
used. particular case zero pronouns, detected
previous stage, previously described.
Anaphora resolution. anaphor detected, corresponding method,
based constraints preferences, applied solve it. type anaphor
set constraints preferences, although follow general
algorithm: constraints applied first, followed preferences. Constraints discard
candidates, whereas preferences simply sort remaining candidates.
131

fiPeral & Ferrandez

4.2.1 Evaluation
evaluating algorithm anaphora resolution12 , looked pronominal anaphora
resolution Spanish English, respectively. Spanish evaluation, method
tested portion LEXESP corpus previously used evaluate zero-pronoun
detection resolution. English, tested method two kinds corpora.
first instance, used portion SemCor collectionpresented (Landes, Leacock,
& Tengi, 1998)which contains set eleven documents (23,788 words)
content words annotated appropriate WordNet sense. SemCor corpus
contains texts different topics (law, sports, religion, nature, etc.) written
different authors. second instance, method tested portion
MTI13 corpus, contains seven documents (101,843 words). MTI corpus contains
computer science manuals different topics (commercial applications, word processing
applications, device instructions, etc.). English corpora automatically tagged
different taggers.
randomly selected subset SemCor corpus (three documents6,473 words)
another subset MTI corpus (two documents24,264 words) training corpus.
remaining fragments corpora reserved test data.
two tasks, training phase used identify importance kind
knowledge obtain optimal order preferences.
4.2.2 Evaluation Anaphora Resolution Spanish
evaluation algorithm anaphora resolution Spanish given detail
work Palomar et al. (2001). paper, present obtained results
evaluation task AGIR different portion LEXESP corpus. Furthermore,
non-anaphoric complement pronouns, is, complement pronouns appear next
previous indirect object moved theoretical place
verb (A Pedroi lei vi ayer saw Pedro yesterday), resolved kind
pronoun appear English translation. reasons, results
two works slightly different.
training phase, algorithm evaluated test corpus.
evaluation, lexical, morphological, syntactic information used. Table 5 shows
results evaluation.

LEXESP

Comp

P(%)

Ref

P(%)

98

82.6

105

92.4

PP
notPP
71

P(%)
70.4

PP
inPP
46

P(%)

Total

76.1

320

P(%)
Total
82.2

Table 5: Anaphora resolution Spanish, evaluation phase
12. previously mentioned, anaphoric, third-person, personal pronouns resolved order
translate target language.
13. corpus provided Computational Linguistics Research Group School Humanities,
Languages Social Studies, University Wolverhampton, England. corpus anaphorically
annotated indicating anaphors correct antecedents.

132

fiTranslation Pronominal Anaphora English Spanish

Table 5 occurrences personal pronouns LEXESP corpus shown.
different types are: Comp (complement personal pronouns), Ref (reflexive pronouns), PPnotPP (personal pronouns included prepositional phrase), PPinPP (personal
pronouns included prepositional phrase). type, obtained precision, P (the
number pronouns correctly solved divided number solved pronouns), shown.
last two columns represent total number personal pronouns obtained
precision.
Discussion. pronominal anaphora resolution Spanish, obtained precision
82.2% (263 320). recall, R (number pronouns correctly solved divided
number real pronouns), obtained 79% (263 333).
analyzing results, following conclusions extracted:
resolution reflexive pronouns, high precision (92.4%) obtained.
higher percentage antecedent pronouns usually closest NP
pronoun sentence. Therefore, applying preferences,
errors produced.
Analyzing errors remaining pronouns, important mention complexity LEXESP corpus itself. consists several narrative documents, sometimes complex style, long sentences (with average 24.6 words
per sentence). implies large number candidates per anaphor applying
constraints (an average 16.6).
Errors originated different causes:
exceptions application preferences (66.7% global mistakes)
lack semantic information (29.8%)
mistakes POS tagging (3.5%)
compared proposal approaches previously presented evaluation
zero-pronoun resolution. shown Table 6, precision obtained using AGIR
better proposals.

LEXESP

Proximity
52.5

Hobbs
65.3

Lappin
73.3

Strube
68.3

AGIR
82.2

Table 6: Anaphora resolution Spanish, comparison AGIR approaches

4.2.3 Evaluation Anaphora Resolution English
algorithm anaphora resolution English based one developed Spanish,
conveniently adapted English. main difference two
algorithms consists different order preferences obtained training phase.
phase, extracted following conclusions:
133

fiPeral & Ferrandez

Spanish morphological information English. consequence, morphological constraints Spanish discard candidates constraints English.
Spanish nearly free-order language, different constituents sentence
(subject, object, etc.) appear almost position. reason, preference syntactic parallelism important role anaphora-resolution
method English Spanish.
Spanish sentences usually longer English ones. fact implies candidates Spanish anaphors English ones.
training phase, algorithm evaluated test corpus.
evaluation phase, two experiments carried out. first experiment, lexical,
morphological, syntactic information used. obtained results SemCor
MTI corpora appear Table 7.
SEMCOR
MTI


116
1


10
0


38
347


50
56


34
0


0
0


6
66

Corr
175
361

Total
254
470

P(%)
68.9
76.8

Table 7: Anaphora resolution English, evaluation phase: experiment 1
table shows number pronouns (classified type) different corpora.
last three columns represent number correctly solved pronouns, total number
pronouns, obtained precision, respectively. instance, MTI corpus
precision 76.8% obtained.
Discussion. pronominal anaphora resolution English, following results
obtained first experiment: SemCor corpus, P = 68.9%, R = 66%; MTI corpus, P =
76.8%, R = 72.9%.
results, extracted following conclusions:
types pronouns vary considerably according corpus. SemCor
corpus, 15% pronouns occurrences pronoun, whereas MTI
corpus percentage 73.8%. fact explained kind domain
corpus. SemCor corpus narrative style contains lot
person entities14 referred text use personal pronouns
(he, she, they). hand, MTI corpus collection technical
manuals contains almost person entities. Rather, references object
entities, using pronouns.
SemCor corpus, errors originated different causes:
lack semantic information caused 57% global mistakes.
seventeen mistakes resolution pronouns, system proposed
14. use basic ontology based semantic features, top level, entities could classified
three main categories: person, animal, object.

134

fiTranslation Pronominal Anaphora English Spanish

person entity solutions pronouns. hand, twenty-eight
occurrences pronouns he, she, him, incorrectly solved due
system proposing object animal entity solution.
exceptions applications preferences (38%), mainly due
existence large number candidates compatible anaphor15 .
mistakes POS tagging (5%).
MTI corpus, errors mainly produced resolution pronouns
(73.4% global mistakes). pronoun lacks gender information (it valid
masculine feminine) subsequently lot candidates per anaphor16 .
fact originates errors application preferences. remaining errors
originated lack semantic information.
analyzing results, observed precision SemCor corpus
approximately 8% lower MTI corpus. errors SemCor corpus
mainly originated lack semantic information. Therefore, order improve
obtained results, second experiment carried addition semantic
information.
modifications second experiment following:
Two new semantic constraintspresented (Saiz-Noeda, Peral, & Suarez, 2000)
added morphological syntactic constraints:
1. pronouns he, she, him, must antecedents person entities.
2. pronoun must antecedent non-person entity.
apply new constraints, twenty-five top concepts WordNet (the concepts
top level ontology) grouped three categories: person, animal,
object. Subsequently, WordNet consulted head candidate,
thus semantic category antecedent obtained.
experiment exclusively carried SemCor corpus
one content words annotated WordNet sense.
Table 8 shows number pronouns (classified type) different corpora
changes incorporated.
shown Table 8, addition two simple semantic constraints resulted
considerable improvement obtained precision (approximately 18%) SemCor
corpus. concluded use semantic information (such new constraints
preferences) process anaphora resolution improve results obtained.
15. sentences SemCor corpus long (with average 24.3 words per sentence).
fact implies large number candidates per anaphor (an average 15.2) applying constraints.
16. sentences MTI corpus long (with average 15.5 words per sentence). However,
candidates per anaphor, applying constraints, high (an average 13.6).

135

fiPeral & Ferrandez

SEMCOR
MTI


116
1


10
0


38
347


50
56


34
0


0
0


6
66

Corr
220
361

Total
254
470

P(%)
86.6
76.8

Table 8: Anaphora resolution English, evaluation phase: experiment 2
Finally, Table 9 compares anaphora resolution using AGIR approaches
previously presented17 . important emphasize high percentages obtained using
system Hobbss method SemCor corpus; systems incorporate semantic information18 methods using semantic constraints (selectional restrictions),
whereas none authors incorporate semantics approaches.
SEMCOR
MTI

Proximity
37.0
54.9

Hobbs
81.9
66.0

Lappin
59.4
75.1

Strube
59.4
63.2

AGIR
86.6
76.8

Table 9: Anaphora resolution English, comparison AGIR approaches

5. AGIRs Generation Module
interlingua representation source text taken input generation module.
output module target text, is, representation source texts
meaning words target language.
generation phase split two modules: syntactic generation morphological
generation. Although approach presented multilingual, focused
generation Spanish English languages.
5.1 Syntactic Generation
syntactic generation, interlingua representation converted transformational rules
ordered surface-structure tree, appropriate labeling leaves target
language grammatical functions features. basic task syntactic generation
order constituents correct sequence target language. However, aim
work translation pronominal anaphora target language,
focused discrepancies Spanish English languages
translation pronoun.
syntactic generation, Spanish elliptical zero-subject constructions studied.
phenomenon conveniently treated solved analysis module. Therefore,
17. mentioned earlier, results presented automatically obtained anaphoric
annotation pronoun. tagging partial parsing source text, pronominal
anaphora resolved translated target language. None intermediate outputs needed
adjusted manually order processed subsequently.
18. Hobbs proposed use semantic information using selectional restrictions straightforward extension method order improve obtained results anaphora resolution.

136

fiTranslation Pronominal Anaphora English Spanish

necessary information translate constructions stored interlingua
representation.
5.2 Morphological Generation
final stage generation module morphological generation, mainly
treat solve number gender discrepancies translation pronouns.
5.2.1 Number Discrepancies
problem generated discrepancy words different languages
express concept. words referred singular pronoun source
language plural pronoun target language. order take account
number discrepancies translation pronoun English Spanish, set
morphological (number) rules constructed. lefthand side number rule contains
interlingua representation pronoun, whereas righthand side contains
pronoun target language.
5.2.2 Gender Discrepancies
Gender discrepancies come existing morphological differences different languages. instance, English less morphological information Spanish. English
plural personal pronoun translated Spanish pronouns ellos (masculine)
ellas (feminine); singular personal pronoun translated el/este (masculine) ella/esta (feminine), etc. order take account gender discrepancies
translation pronoun English Spanish, set morphological (gender)
rules constructed.

6. Evaluation Generation Module
step, tested AGIRs generation module evaluating translation
English pronouns Spanish, translation Spanish pronouns English.
mentioned earlier, generation module takes interlingua representation
input. Previously, Spanish zero pronouns detected (90.4% P) resolved (81.4%
P), anaphoric third-person personal pronouns resolved Spanish (82.2% P)
English (86.6% P SemCor corpus semantic information, 76.8% P
MTI corpus without semantic information). Non-referential uses pronouns
automatically detected, obtaining 88.7% P unrestricted texts19 .
19. order detect pleonastic pronouns AGIR, set rules, based pattern recognition,
allow identification type pronoun constructed. rules based work
(Lappin & Leass, 1994; Paice & Husk, 1987; Denber, 1998), dealt problem similar
way. used information provided POS tagger order improve detection
different patterns. evaluated method using journalistic texts portion Federal
Register corpus contains set 313 documents (156,831 words). detection pleonastic
pronouns 88.7% P (568 640) obtained. Finally, important point high
percentage pronouns test corpus pleonastic (32.9%). fact demonstrates
importance correct detection kind pronoun MT system.

137

fiPeral & Ferrandez

interlingua representation obtained, method proposed pronominal
anaphora translation target language based treatment number
gender discrepancies.
6.1 Pronominal Anaphora Translation Spanish
experiment, translation English, third-person, personal pronouns Spanish
evaluated.
tested method portions SemCor MTI corpora used previously
process anaphora resolution. training corpus used improving
number gender rules. remaining fragments corpora reserved test
data.
needed know semantic category (person, animal, object) grammatical gender (masculine feminine) pronouns antecedent order apply
number gender rules. SemCor corpus, WordNet sense used identify antecedents semantic category. MTI corpus, due lack semantic
information, set heuristics used determine antecedents semantic category.
regard information antecedents gender, EnglishSpanish electronic dictionary used since POS tag usually provide gender number
information. dictionary incorporated system database.
English word, dictionary provides translation Spanish, words gender
number Spanish.
number gender rules applied using morphological semantic information. conducted blind test entire test corpus, obtained results
appear Table 10.

SEMCOR
MTI
TOTAL

Subject
197
239
436

Compl
47
231
288

Correct
229
353
582

Total
254
470
724

P(%)
90.2
75.1
80.4

Table 10: Translation pronominal anaphora Spanish, evaluation phase

evaluation task automatically carried anaphoric annotation pronoun. annotation included information antecedent
translation target language anaphor. so, human annotators translated anaphors according criteria established morphological rules.
example, pronoun subject function translated Spanish pronoun el
antecedent animal type masculine; hand, antecedent
object type masculine, translated Spanish pronoun este;
on. SpanishEnglish translation, pronoun el subject function
translated English pronoun antecedent person type masculine;
138

fiTranslation Pronominal Anaphora English Spanish

hand, antecedent object/animal type masculine/feminine,
translated English pronoun it; on20 .
Table 10 shows anaphoric pronouns corpus classified grammatical function: subject complement (direct indirect object). last three columns represent
number pronouns successfully solved, total number solved pronouns,
obtained precision, respectively. instance, SemCor corpus contains 197 pronouns
subject function 47 complement pronouns. precision obtained corpus
90.2% (229 254).
Discussion. translation English personal pronouns third person
Spanish, overall precision 80.4% (582 724) obtained. Specifically, 90.2% P
75.1% P obtained SemCor MTI corpora, respectively.
results, extracted following conclusions:
SemCor corpus, instances English pronouns he, she, him,
correctly translated Spanish. two reasons this:
semantic roles pronouns correctly identified cases.
pronouns contain necessary grammatical information (gender
number) allows correct translation Spanish, independent
antecedent proposed solution AGIR system.
errors translation pronouns it, they, originated
following different causes:
mistakes anaphora-resolution stage, is, antecedent
proposed system correct one (44.4% global mistakes).
caused incorrect translation Spanish mainly due fact
proposed antecedent correct one different grammatical genders.
mistakes identification semantic role pronouns
caused application incorrect morphological rule (44.4%).
mistakes mainly originated incorrect process clause splitting.
mistakes originated EnglishSpanish electronic dictionary
(11.2%). Two circumstances could occur: (a) word appear
dictionary; (b) words gender dictionary different
real words gender, since word different meanings.
MTI corpus, nearly pronouns it, they, (96.2% total
pronouns). errors translation pronouns originated
causes SemCor corpus, although percentages different:
mistakes anaphora-resolution stage (22.9% mistakes).
mistakes identification pronouns semantic role (62.9%).
20. automatic evaluation, pronoun considered correctly translated pronoun proposed
system proposed human annotator. criterion, evaluated
correct application corresponding morphological rule.

139

fiPeral & Ferrandez

mistakes originated EnglishSpanish dictionary (14.2%).
corpus, large number technical words appear
electronic dictionary.
analyzing results, observed precision SemCor corpus
approximately 15% higher obtained MTI corpus. lower
percentage obtained MTI corpus result corpus (most
pronouns corpus it, they, them), lack semantic
information.
order measure efficiency proposal, compared system one
representative MT systems moment: Systran. Systran designed
built thirty years ago, continually modified order improve
translation quality. Moreover, easily accessible Internet users service
MT webBABELFISH21 provides free translations different
languages. regard problem pronominal anaphora resolution translation,
Systran one best MT systems studied (see Section 2) because, like system,
treats problems intersentential pronominal anaphora Spanish zero pronouns
unrestricted texts carrying partial parsing source text. mentioned
Section 2, free trial commercial product SYSTRANLinks22 used translate
English Spanish languages evaluation corpora. results appear
Table 11.
SEMCOR
MTI

SYSTRANLinks
75.4
58.1

AGIR
82.5
69.3

Table 11: Translation pronominal anaphora (complement pronouns only) Spanish,
SYSTRANLinks AGIR
evaluation SYSTRANLinks output carried human translator
hand. Pronouns judged acceptable translator considered correctly translated;
otherwise, considered incorrectly translated.
Table 11 shows evaluation English complement pronoun translation
Spanish Systran translate subject pronouns Spanish. analyzing Systran outputs corpora, extracted following conclusions:
instances English pronouns (always subject function)
correctly translated Spanish equivalents el ella.
instances English pronouns subject function
omitted Spanishzero pronouns. pronouns resolved English,
subsequently translated Spanish.
21. URL = http://www.babelfish.altavista.com (visited 03/11/2002).
22. URL = http://w4.systranlinks.com/config (visited 06/22/2002).

140

fiTranslation Pronominal Anaphora English Spanish

hand, AGIR system, evaluated correct application
morphological rule translate source pronouns target pronouns. subsequent
task must decide pronoun target language (a) must generated system
proposes, (b) must substituted another kind pronoun (e.g., possessive pronoun),
(c) must eliminated (i.e., Spanish zero pronouns). Therefore, taken
account complement pronoun translation order make fair comparison
two systems.
shown Table 11, precision obtained using AGIR approximately 711% higher
(depending corpus) one obtained using Systran. errors Systran originated mistakes anaphora-resolution stage caused incorrect translations, since
proposed antecedents correct ones different grammatical gender.
errors occur intrasentential anaphors (as presented Section 2) intersentential
anaphors, following example extracted corpora:
(E) [This information]i valid Linux Intel platform. Much iti
applicable Linux processor architectures, first
hand experience information.
(S) Esta informacion es solamente valida para Linux en la plataforma de Intel. Mucho
de el debe ser aplicable Linux en otras configuraciones del procesador, pero tengo
ninguna experiencia informacion de primera mano.
example shows incorrect EnglishSpanish translation pronoun done
Systran. case, antecedent (this information, feminine) previous sentence
anaphor. incorrectly solved, incorrectly translated (the pronoun
el masculineinstead pronoun estafeminine).
6.2 Pronominal Anaphora Translation English
experiment, translation Spanish, third-person, personal pronouns zero
pronouns (excluding reflexive pronouns) English evaluated. tested method
portion LEXESP corpus previously used process anaphora
resolution.
needed know semantic category grammatical gender pronouns
antecedent order apply number gender rules. LEXESP corpus, due
lack semantic information, set heuristics used determine antecedents
semantic category. hand, information antecedents gender
provided POS tag antecedents head. conducted blind test
entire test corpus, results appear Table 12.

LEXESP

Subject
630

Compl
145

Correct
657

Total
775

P(%)
84.8

Table 12: Translation pronominal anaphora English, evaluation phase
141

fiPeral & Ferrandez

Discussion. translation Spanish personal pronouns third person
English, overall precision 84.8% (657 775) obtained. results,
extracted following conclusions:
instances Spanish plural pronouns (ellos, ellas, les, los, las,
zero pronouns plural corresponding English pronouns them),
correctly translated English. two reasons this:
semantic roles pronouns correctly identified cases.
equivalent English pronouns (they them) lack gender information,
is, valid masculine feminine. Therefore, antecedents gender
influence translation pronouns.
errors occurred translation Spanish singular pronouns (el, ella, le,
lo, la, zero pronouns singular corresponding English pronouns he, she,
it, him, ). different causes errors:
mistakes anaphora-resolution stage (79.7% global mistakes), caused incorrect translation Spanish, mainly due
proposed antecedent correct one different grammatical gender.
Sometimes gender, different semantic categories.
mistakes application heuristic used identify antecedents semantic category (20.3%). involved application incorrect
morphological rule.
proposal compared SYSTRANLinks output. shown Table 13,
precision obtained AGIR system approximately 28% higher obtained
Systran.

LEXESP

SYSTRANLinks
56.9

AGIR
84.8

Table 13: Translation pronominal anaphora English, SYSTRANLinks AGIR

low results obtained Systran mainly result errors occurred
translation Spanish zero pronouns. Specifically, 775 Spanish pronouns, 334 errors
occurred, 293 (87.7% global errors) originated translation zero
pronouns, whereas remainder (12.3%) originated translation remaining
not-omitted pronouns. errors translation zero pronouns mainly originated
incorrect resolution.

142

fiTranslation Pronominal Anaphora English Spanish

7. Conclusion
paper evaluated different tasks carried MT approach (for
Spanish English languages) allowed correct pronominal anaphora translation
target language. shown importance resolution anaphoric
expressions MT system correct translations target language,
main MT systems conveniently resolve phenomenon.
approach, called AGIR, works unrestricted texts partial-parsing techniques applied. parsing solving NLP problems, interlingua representation entire text obtained. fact one main advantages system
since several problems (hardly solved majority MT systems) treated
solved. problems translation intersentential anaphora, detection
co-reference chains, translation Spanish zero pronouns English.
evaluation, obtained precision 80.4% 84.8% translation
Spanish English pronominal anaphora, respectively. Previously, Spanish zero pronouns
resolved (with precision 81.4%) anaphoric personal pronouns
resolved English (with precisions 86.6% 76.8% SemCor corpus semantic
information MTI corpus without it, respectively) Spanish (with precision
82.2%).
addition, carried exhaustive comparison well-known anaphoraresolution algorithms. Finally, also compared pronoun translation one
representative MT systems moment: Systran. comparisons, AGIR
shown perform better.
important conclusion extracted evaluation phase: adding semantic information improves precision anaphora-resolution process considerably,
therefore corresponding precision anaphora-translation process. Currently,
addition kind information different stages AGIR system
studied order improve overall performance system.
resolution translation new types references, definite descriptions
anaphora originated demonstrative pronouns, studied future. Moreover,
addition new languages interlingua approach taken account.

Acknowledgments
authors wish thank Manuel Palomar helpful revisions paper; Ferran
Pla, Ruslan Mitkov, Richard Evans contributed corpora; Rafael
Munoz, Maximiliano Saiz-Noeda, Patricio Martnez-Barco, Juan Carlos Trujillo
suggestions willingness help task related paper. also
grateful helpful comments anonymous reviewers several conference papers
presented preliminary work.
research supported Spanish Government, projects TIC20000664-C02-02 FIT-150500-2002-416.
143

fiPeral & Ferrandez

References
Allegranza, V., Krauwer, S., & Steiner, E. (1991). Introduction. Machine Translation
(Eurotra Special Issue), 6 (2), 6171.
Amores, J., & Quesada, J. (1997). Episteme. Procesamiento del Lenguaje Natural, 21, 115.
Appelo, L., & Landsbergen, J. (1986). machine translation project Rosetta. Gerhardt, T. (Ed.), I. International Conference State Art Machine Translation America, Asia Europe: Proceedings IAI-MT86, IAI/EUROTRA-D,
pp. 3451 Saarbrucken (Germany).
Bennet, W., & Slocum, J. (1985). LRC machine translation system. Computational
Linguistics, 11, 111121.
Berger, A., et al. (1994). Candide system Machine Translation. Proceedings
ARPA Workshop Speech Natural Language, pp. 157163 Morgan Kaufman
Publishers.
Boitet, C. (1989). Geta project. Nagao, M. (Ed.), Machine Translation Summit, pp.
5465. Ohmsha, Tokyo.
Boitet, C., & Nedobejkine, N. (1981). Recent developments Russian-French machine
translation Grenoble. Linguistics, 19, 199271.
Canals-Marote, R., et al. (2001a). El sistema de traduccion automatica castellano-catalan
interNOSTRUM. Procesamiento del Lenguaje Natural, 27, 151156.
Canals-Marote, R., et al. (2001b). Spanish-Catalan machine translation system interNOSTRUM. Proceedings Machine Translation Summit VIII, pp. 7376 Santiago
de Compostela (Spain).
Carletta, J., et al. (1997). Reliability Dialogue Structure Coding Scheme. Computational Linguistics, 23 (1), 1332.
Chandioux, J. (1976). METEO: un systeme operationnel pour la traduction automatique
des bulletins metereologiques destines au grand public. META, 21, 127133.
Chandioux, J. (1989). Meteo: 100 million words later. Hammond, D. (Ed.), American Translators Association Conference 1989: Coming Age, pp. 449453. Learned
Information, Medford, NJ.
Daz-Ilarraza, A., Mayor, A., & Sarasola, K. (2000). Reusability wide-coverage linguistic
resources construction multilingual machine translation system. Proceedings Machine Translation multilingual applications new millennium
(MT2000), pp. 12.112.9 Exeter (UK).
Daz-Ilarraza, A., Mayor, A., & Sarasola, K. (2001). Inclusion del par castellano-euskara
en un prototipo de traduccion automatica multilingue. Proceedings Second
International Workshop Spanish Language Processing Language Technologies
(SLPLT-2), pp. 107111 Jaen (Spain).
144

fiTranslation Pronominal Anaphora English Spanish

Denber, M. (1998). Automatic Resolution Anaphora English. Eastman Kodak Co.,
Imaging Science Division.
Farwell, D., & Helmreich, S. (2000). interlingual-based approach reference resolution. Proceedings Third AMTA/SIG-IL Workshop Applied Interlinguas:
Practical Applications Interlingual Approaches NLP (ANLP/NAACL2000), pp.
111 Seattle, Washington (USA).
Ferrandez, A., Palomar, M., & Moreno, L. (1999). empirical approach Spanish
anaphora resolution. Machine Translation, 14 (3/4), 191216.
Ferrandez, A., & Peral, J. (2000). computational approach zero-pronouns Spanish. Proceedings 38th Annual Meeting Association Computational
Linguistics (ACL2000), pp. 166172 Hong Kong (China).
Geldbach, S. (1999). Anaphora Translation Discrepancies Russian-German MT.
Machine Translation, 14 (3/4), 217230.
Goodman, K. (1989). Special Issues Knowledge-Based Machine Translation, Parts
II. Machine Translation, 4 (1/2).
Halliday, M., & Hasan, R. (1976). Cohesion English. Longman English Language Series
9. Longman, London.
Hirst, G. (1981). Anaphora Natural Language Understanding. Springer-Verlag, Berlin.
Hobbs, J. (1978). Resolving pronoun references. Lingua, 44, 311338.
Hutchins, W., & Somers, H. (1992). Introduction Machine Translation. Academic
Press Limited, London.
Landes, S., Leacock, C., & Tengi, R. (1998). Building semantic concordances. Fellbaum, C. (Ed.), WordNet: Electronic Lexical Database, pp. 199216. MIT Press,
Cambridge, Mass.
Landsbergen, J. (1987). Montague grammar machine translation. Whitelock, P.,
Wood, M., Somers, H., Johnson, R., & Bennet, P. (Eds.), Linguistic theory computer applications, pp. 113147. Academic Press, London.
Lappin, S., & Leass, H. (1994). algorithm pronominal anaphora resolution. Computational Linguistics, 20 (4), 535561.
Maas, H. (1977). Saarbrucken automatic translation system (SUSY). Proceedings
Third European Congress Information Systems Networks, Overcoming
language barrier, pp. 585592 Munchen (Germany).
Maas, H. (1987). MT system SUSY. King, M. (Ed.), Machine translation today:
state art, Edinburgh Information Technology Series 2, pp. 209246. Edinburgh
University Press.
145

fiPeral & Ferrandez

Mahesh, K., & Nirenburg, S. (1995a). situated ontology practical NLP. Proceedings
Workshop basic ontological issues knowledge sharing (IJCAI95) Montreal
(Canada).
Mahesh, K., & Nirenburg, S. (1995b). Semantic classification practical Natural Language Processing. Proceedings Sixth ASIS SIG/CR Classification Research
Workshop: interdisciplinary meeting, pp. 7994 Chicago, Illinois (USA).
Miller, G., Beckwith, R., Fellbaum, C., Gross, D., & Miller, K. (1990). WordNet: on-line
lexical database. International journal lexicography, 3 (4), 235244.
Mitamura, T., Nyberg, E., & Carbonell, J. (1991). efficient interlingua translation
system multi-lingual document production. Proceedings Machine Translation
Summit III Washington, DC (USA).
Mitkov, R., Kim, H., Lee, H., & Choi, K. (1994). Lexical transfer resolution pronominal anaphors Machine Translation: English-to-Korean case. Procesamiento del
Lenguaje Natural, 15, 2337 (Grupo 2. Traduccion Automatica e Interfaces).
Mitkov, R., & Schmidt, P. (1998). complexity pronominal anaphora resolution
machine translation. Martn-Vide, C. (Ed.), Mathematical computational
analysis natural language. John Benjamins Publishers, Amsterdam.
Montoyo, A., & Palomar, M. (2000). WSD algorithm applied NLP system.
Bouzeghoub, M., Kedad, Z., & Metais, E. (Eds.), Natural Language Processing
Information Systems, Vol. 1959 Lecture Notes Computer Science, pp. 5465
Versailles (France). Springer-Verlag.
Munoz, R., Palomar, M., & Ferrandez, A. (2000). Processing Spanish Definite Descriptions. Cairo, O., Sucar, L., & Cantu, F. (Eds.), MICAI 2000: Advances Artificial
Intelligence, Vol. 1793 Lecture Notes Artificial Intelligence, pp. 526537 Acapulco
(Mexico). Springer-Verlag.
Nakaiwa, H., & Ikehara, S. (1992). Zero pronoun resolution Japanese-to-English Machine Translation system using verbal semantic attributes. Proceedings
Third Conference Applied Natural Language Processing (ANLP92), pp. 201208
Trento (Italy).
Nirenburg, S. (1989). Knowledge-based machine translation. Machine Translation, 4, 524.
Okumura, M., & Tamura, K. (1996). Zero pronoun resolution Japanese discourse based
centering theory. Proceedings 16th International Conference Computational Linguistics (COLING96), pp. 871876 Copenhagen (Denmark).
Paice, C., & Husk, G. (1987). Towards automatic recognition anaphoric features
English text: impersonal pronoun it. Computer Speech Language, 2,
109132.
Palomar, M., & Martnez-Barco, P. (2001). Computational approach anaphora resolution
Spanish dialogues. Journal Artificial Intelligence Research, 15, 263287.
146

fiTranslation Pronominal Anaphora English Spanish

Palomar, M., et al. (2001). algorithm anaphora resolution Spanish texts. Computational Linguistics, 27 (4), 545567.
Peral, J., & Ferrandez, A. (2000a). application Interlingua System ISS SpanishEnglish pronominal anaphora generation. Proceedings Third AMTA/SIG-IL
Workshop Applied Interlinguas: Practical Applications Interlingual Approaches
NLP (ANLP/NAACL2000), pp. 4251 Seattle, Washington (USA).
Peral, J., & Ferrandez, A. (2000b). Generation Spanish zero-pronouns English.
Christodoulakis, D. (Ed.), Natural Language Processing - NLP 2000, Vol. 1835
Lecture Notes Artificial Intelligence, pp. 252260 Patras (Greece). Springer-Verlag.
Peral, J., Palomar, M., & Ferrandez, A. (1999). Coreference-oriented Interlingual Slot
Structure Machine Translation. Proceedings ACL Workshop Coreference
Applications, pp. 6976 College Park, Maryland (USA).
Quesada, J., & Amores, J. (2000). Diseno e implementacion de sistemas de Traduccion
Automatica. Universidad de Sevilla. Secretariado de publicaciones, Sevilla.
Sadler, V. (1989). Working analogical semantics: disambiguation techniques DLT.
Distributed Language Translation 5. Foris, Dordrecht.
Saiz-Noeda, M., Peral, J., & Suarez, A. (2000). Semantic compatibility techniques
anaphora resolution. Proceedings ACIDCA2000, pp. 4348 Monastir (Tunisia).
Schubert, K. (1986). Linguistic extra-linguistic knowledge. Computers Translation,
1, 125152.
Strube, M., & Hahn, U. (1999). Functional Centering - Grounding Referential Coherence
Information Structure. Computational Linguistics, 25 (5), 309344.
Thurmair, G. (1990). Complex lexical transfer METAL. Proceedings TMI90, pp.
91107 Austin, Texas (USA).
Toma, P. (1977). Systran multilingual machine translation system. Proceedings
Third European Congress Information Systems Networks, Overcoming
language barrier, pp. 569581 Munchen (Germany).
Varile, G., & Lau, P. (1988). Eurotra: practical experience multilingual machine
translation system development. Proceedings Second Conference
Applied Natural Language Processing (ANLP88), pp. 160167 Austin, Texas (USA).
Vossen, P. (1998). EuroWordNet: Building Multilingual Database WordNets
European Languages. ELRA Newsletter, 3 (1), 712.
Wheeler, P. (1987). Systran. King, M. (Ed.), Machine translation today: state
art, Edinburgh Information Technology Series 2, pp. 192208. Edinburgh University
Press.
Witkam, A. (1983). Distributed language translation: feasibility study multilingual facility
videotex information networks. BSO, Utrecht.

147

fiJournal Artificial Intelligence Research 18 (2003) 45-81

Submitted 08/02; published 01/03

Monte Carlo Methods Tempo Tracking
Rhythm Quantization
Ali Taylan Cemgil
Bert Kappen

SNN, Geert Grooteplein 21 cpk1 - 231, University Nijmegen
NL 6525 EZ Nijmegen, Netherlands

cemgil@snn.kun.nl
bert@snn.kun.nl

Abstract

present probabilistic generative model timing deviations expressive music performance. structure proposed model equivalent switching state
space model. switch variables correspond discrete note locations musical
score. continuous hidden variables denote tempo. formulate two well known
music recognition problems, namely tempo tracking automatic transcription (rhythm
quantization) filtering maximum posteriori (MAP) state estimation tasks. Exact computation posterior features MAP state intractable model
class, introduce Monte Carlo methods integration optimization. compare
Markov Chain Monte Carlo (MCMC) methods (such Gibbs sampling, simulated annealing iterative improvement) sequential Monte Carlo methods (particle filters).
simulation results suggest better results sequential methods. methods
applied online batch scenarios tempo tracking transcription
thus potentially useful number music applications adaptive automatic
accompaniment, score typesetting music information retrieval.
1. Introduction
Automatic music transcription refers extraction human readable interpretable
description recording musical performance. Traditional music notation
description lists pitch levels (notes) corresponding timestamps.
Ideally, one would like recover score directly audio signal. representation surface structure music would useful music information retrieval
(Music-IR) content description musical material large audio databases. However,
operating sampled audio data polyphonic acoustical signals, extraction
score-like description challenging auditory scene analysis task (Vercoe, Gardner,
& Scheirer, 1998).
paper, focus subproblem music-ir, assume exact timing
information notes available, example stream MIDI1 events digital
keyboard.
model tempo tracking transcription MIDI-like music representation
useful broad spectrum applications. One example automatic score typesetting,
1. Musical Instruments Digital Interface. standard communication protocol especially designed digital
instruments keyboards. time key pressed, MIDI keyboard generates short message
containing pitch key velocity. computer tag received message timestamp real-time
processing and/or recording file.

c 2003 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiCemgil & Kappen
musical analog word processing. Almost score typesetting applications provide
means automatic generation conventional music notation MIDI data.
conventional music notation, onset time note implicitly represented
cumulative sum durations previous notes. Durations encoded simple rational
numbers (e.g., quarter note, eighth note), consequently events music placed
discrete grid. basic task MIDI transcription associate onset times
discrete grid locations, i.e., quantization.
However, unless music performed mechanical precision, identification
correct association becomes dicult. due fact musicians introduce
intentional (and unintentional) deviations mechanical prescription. example
timing events deliberately delayed pushed. Moreover, tempo uctuate
slowing accelerating. fact, deviations natural aspects expressive
performance; absence these, music tends sound rather dull mechanical.
hand, deviations accounted transcription, resulting
scores often poor quality.
Robust fast quantization tempo tracking also important requirement
interactive performance systems; applications \listen" performer generating
accompaniment improvisation real time (Raphael, 2001b; Thom, 2000). last,
models also useful musicology systematic study characterization expressive
timing principled analysis existing performance data.
theoretical perspective, simultaneous quantization tempo tracking
\chicken-and-egg" problem: quantization depends upon intended tempo interpretation tempo interpretation depends upon quantization. Apparently, human
listeners resolve ambiguity (in cases) without effort. Even persons without
musical training able determine beat tempo rapidly. However,
still unclear precisely constitutes tempo relates perception
beat, rhythmical structure, pitch, style music etc. Tempo perceptual construct
cannot directly measured performance.
goal understanding tempo perception stimulated significant body research psychological computational modeling aspects tempo tracking
beat induction, e.g., see (Desain & Honing, 1994; Large & Jones, 1999; Toiviainen, 1999).
papers assume events presented onset list. Attempts also made
deal directly audio signal (Goto & Muraoka, 1998; Scheirer, 1998; Dixon &
Cambouropoulos, 2000).
Another class tempo tracking models developed context interactive
performance systems score following. models make use prior knowledge
form annotated score (Dannenberg, 1984; Vercoe & Puckette, 1985). recently,
Raphael (2001b) demonstrated interactive real-time system follows solo player
schedules accompaniment events according player's tempo interpretation.
Tempo tracking crucial quantization, since one uniquely quantize onsets
without estimate tempo beat. converse, quantization
help identification correct tempo interpretation already noted Desain
Honing (1991). Here, one defines correct tempo one results simpler
quantization. However, schema never fully implemented practice due
computational complexity obtaining perceptually plausible quantization. Hence

46

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
quantization methods proposed literature either estimate tempo using simple
heuristics (Longuet-Higgins, 1987; Pressing & Lawrence, 1993; Agon, Assayag, Fineberg,
& Rueda, 1994) assume tempo known constant (Desain & Honing, 1991;
Cambouropoulos, 2000; Hamanaka, Goto, Asoh, & Otsu, 2001).
approach transcription tempo tracking probabilistic, i.e., Bayesian
modeling perspective. Cemgil et al. (2000), introduced probabilistic approach
perceptually realistic quantization. work also assumed tempo known
estimated external procedure. tempo tracking, introduced Kalman filter
model (Cemgil, Kappen, Desain, & Honing, 2001). approach, modeled tempo
smoothly varying hidden state variable stochastic dynamical system.
current paper, integrate quantization tempo tracking. Basically,
model balances score complexity versus smoothness tempo deviations. correct tempo
interpretation results simple quantization correct quantization results
smooth tempo uctuation. essentially similar model proposed recently also Raphael
(2001a). However, Raphael uses inference technique applies small models;
namely continuous hidden state one dimensional. severely restricts
models one consider. current paper, survey general widely used state-ofthe-art techniques inference.
outline paper follows: Section 2, propose probabilistic model
timing deviations expressive music performance. Given model, define tempo
tracking quantization inference posterior quantities. turn model
switching state space model computation exact probabilities becomes intractable. Section 3, introduce approximation techniques based simulation,
namely Markov Chain Monte Carlo (MCMC) sequential Monte Carlo (SMC) (Doucet,
de Freitas, & Gordon, 2001; Andrieu, de Freitas, Doucet, & Jordan, 2002). approaches
provide exible powerful inference methods successfully applied diverse fields applied sciences robotics (Fox, Burgard, & Thrun, 1999), aircraft
tracking (Gordon, Salmond, & Smith, 1993), computer vision (Isard & Blake, 1996), econometrics (Tanizaki, 2001). Finally present simulation results conclusions.

2. Model
Assume pianist improvising recording exact onset times key
presses performance. denote observed onset times y0 ; y1 ; y2 : : :
yk : : : yK compactly y0:K . neither access musical notation
piece know initial tempo started performance with. Moreover,
pianist allowed freely change tempo introduce expression. Given onset
time information y0:K , wish find score 1:K track tempo uctuations z0:K .
refine meaning z later.
problem apparently ill-posed. pianist allowed change tempo
arbitrarily possible assign \correct" score given performance.
words performance y0:K represented using suitable combination
arbitrary score arbitrary tempo trajectory. Fortunately, Bayes theorem provides
elegant principled guideline formulate problem. Given onsets y0:K ,
best score 1:K tempo trajectory z0:K derived posterior distribution

47

fiCemgil & Kappen
given
1
p(y j ; z )p( ; z )
p(y0:K ) 0:K 1:K 0:K 1:K 0:K
quantity, proportional product likelihood term p(y0:K j 1:K ; z0:K )
prior term p( 1:K ; z0:K ).
rhythm transcription tempo tracking, prior encodes background knowledge nature musical scores tempo deviations. example, construct prior prefers \simple" scores smooth tempo variations.
likelihood term relates tempo score actual observed onset times.
respect, likelihood model short time expressive timing deviations motor
errors introduced performer.

p( 1:K ; z0:K jy0:K ) =

/ c1
/ c2
/ : : :F
/ ck
EE
FF
CC
F
EE
EE
CC
FF
EE
EE
CC
FF
EE
EE
CC
FF
CC
E"
E"
#
!: : :

c0 EE

1

k 1

2

/ :::
/ 1
/ 2
BB
@@
BB
BB
@@
BB
BB
@@
BB
BB
@@
BB
B
@@
B!
B!
/ 1
/ 2
/ :::

0 B

0


y0



y1



y2

/ :::
CC Quantization
CC
HH
CC
HH
CC
HH
CC
H#
!
/ ck

1 HH

k

Score

/ k
/ :Tempo
::
Trajectory
@@
EE
@
EE
@@
EE
@@
EE
@@
E"
@
/ k
/ : :Noiseless
:
onsets

k 1E
/

/



k 1


:::

:::

Locations



yk 1

yk

: Observed
::
Onsets

Figure 1: Graphical Model. Square oval nodes correspond discrete continuous
variables respectively. text, sometimes refer continuous hidden
variables (k ; k ) zk . dependence c deterministic.
c, , hidden; onsets observed.

2.1 Score prior
define score 1:K , first introduce sequence quantization locations c0:K .
quantization location ck specifies score time k'th onset. let k denote
interval quantization locations two consecutive onsets
k = ck

ck 1

(1)

example consider conventional music notation
encodes score 1:3 =
[1 0:5 0:5]. Corresponding quantization locations c0:3 = [0 1 1:5 2].
One simple way defining prior distribution quantization locations p(ck ) specifying table probabilities ck mod 1 (the fraction ck ). example wish


48





fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
allow scores sixteenth notes triplets, define table probabilities
states c mod 1 = f0; 0:25; 0:5; 0:75g[f0; 0:33; 0:67g. Technically, resulting prior
p(ck ) periodic improper (since ck principle unbounded normalize
distribution).
However, number states ck mod 1 large, may dicult estimate
parameters prior reliably. situations propose \generic" prior follows:
define probability, k'th onset gets quantized location ck , p(ck ) /
exp( d(ck )) d(ck ) number significant digits binary expansion ck
mod 1. example d(1) = 0, d(1:5) = 1, d(7 + 9=32) = 5 etc. positive parameter
used penalize quantization locations require bits represented. Assuming
quantization locations onsets independent a-priori, (besides increasing
k, i.e., ck ck 1 ), P
prior probability sequence quantization locations given
p(c0:K ) / exp( K
k=0 d(ck )). assume c0 2 [0; 1). One check
) < p(
). generalize
prior prefers simpler notations, e.g., p(
prior subdivisions triplets quintiplets Appendix A.
Formally, given distribution c0:K , prior score 1:K given






6

p( 1:K ) =

X

c0:K











6

p( 1:K jc0:K )p(c0:K )

(2)

Since relationship c0:K 1:K deterministic, p( 1:K jc0:K ) degenerate
given c0:K ,

p( 1:K ) / exp



K
k
X
X

!

d( k0 )
(3)
=1 k0 =1
One might tempted specify prior directly 1:K get rid c0:K entirely.
However, simpler approach easy devise realistic priors. example,
consider sequence note durations [1 1=16 1 1 1 : : : ]. Assuming factorized prior
penalizes short note durations, rhythm would relatively high probability
whereas quite uncommon conventional music.
k

2.2 Tempo prior
represent tempo terms inverse, i.e., period, denote .
example tempo 120 beats per minute (bpm) corresponds = 60=120 = 0:5 seconds.
onset tempo changes unknown amount k . assume change k
iid N (0; Q ). 2 assume first order Gauss-Markov process tempo
k = k 1 + k
(4)
Eq. 4 defines distribution tempo sequences 0:K . Given tempo sequence,
\ideal" \intended" time k next onset given

k = k 1 + k k 1 + k

(5)

2. denote (scalar multivariate) Gaussian distribution p(x) mean vector covariance
1
matrix P N (; P )=
^ j2P j 2 exp( 21 (x )T P 1 (x )).

49

fiCemgil & Kappen
noise term k denotes amount accentuation (that deliberately playing
note ahead back time) without causing tempo changed. assume k
N (0; Q ). Ideal onsets actually observed \noisy" onsets related

yk = k + k

(6)

noise term k models small scale expressive deviations motor errors timing individual notes. paper assume k Gaussian distribution parameterized
N (0; R).
initial tempo distribution p(0 ) specifies range reasonable tempi given
Gaussian broad variance. assume uninformative ( at) prior 0 .
conditional independence structure given graphical model Figure 1. Table 1
shows possible realization model.
note model particular instance well known switching state space
model (also known conditionally linear dynamical system, jump Markov linear system,
switching Kalman filter) (See, e.g., Bar-Shalom & Li, 1993; Doucet & Andrieu, 2001;
Murphy, 2002).

k 0
1
2
3
k
...
ck 0 1/2 3/2 2 . . .
k 0.5 0.6 0.7 . . . . . .
k 0 0.25 0.85 1.20 . . .
yk 0 0.23 0.88 1.24 . . .


(





(

Table 1: possible realization model: ritardando. clarity assume = 0.
following sections, sometimes refer use zk = (k ; k )T refer z0:K
tempo trajectory. Given definition, compactly represent Eq. 4 Eq. 5

zk =



1 k
0 1



zk 1 + k

(7)

k = (k ; k ).

2.3 Extensions
several possible extensions basic parameterization. example, one could
represent period logarithmic scale. warping ensures positivity seems
perceptually plausible since promotes equal relative changes tempo rather
absolute scale (Grubb, 1998; Cemgil et al., 2001). Although resulting model
becomes nonlinear, approximated fairly well extended Kalman filter (BarShalom & Li, 1993).
simple random walk model tempo uctuations Eq. 7 seems
realistic. would expect tempo deviations structured smoother.

50

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
dynamical system framework smooth deviations modeled increasing
dimensionality z include higher order \inertia" variables (Cemgil et al., 2001).
example consider following model,

0
k
B
1;k
B
B
2;k
B
B
@ ...

1;k

1
0
10
1 k k 0 : : : 0
k 1
C
B
C
B
0 1 0 0 : : : 0 C B 1;k 1
C
B
C
B
C
B
2;k 1
= B0 0
C
C
B
C
B
C
B
.
.
..

@ .. ..
A@

.
0 0

1;k 1

1
C
C
C
+ k
C
C


(8)

choose particular parameterization wish interpret 1 slowly
varying \average" tempo 2 temporary change tempo. model useful
situations performer uctuates around almost constant tempo; random
walk model sucient case forgets initial values. Additional state
variables 3 ; : : : ; 1 act like additional \memory" elements. choosing parameter
matrix noise covariance matrix Q, one model rich range temporal structures
expressive timing deviations.
score prior improved using richer model. example allow
different time signatures alternative rhythmic subdivisions, one introduce additional
hidden variables (See Cemgil et al. (2000) Appendix A) use Markov chain (Raphael,
2001a). Potentially, extensions make easier capture additional structure musical
rhythm (such \weak" positions followed likely \strong" positions).
hand, number model parameters rapidly increases one
cautious order avoid overfitting.
score typesetting, need quantize note durations well, i.e., associate note
offsets quantization locations. simple way accomplishing define
indicator sequence u0:K identifies whether yk onset (uk = 1) offset (uk =
0). Given uk , redefine observation model p(yk jk ; uk ) = uk N (0; R) + (1
uk )N (0; Roff ) Roff observation noise associated offsets. typical model
would Roff R. Roff ! 1, offsets would effect tempo process.
Moreover, since uk always observed, extension requires simple lookup.
principle, one must allow arbitrary long intervals onsets, hence k
drawn infinite (but discrete) set. subsequent derivations, assume
number possible intervals fixed a-priori. Given estimate zk 1 observation yk ,
almost virtually infinite number choices k almost zero probability
easy identify candidates would significant probability mass.
Conceptually, listed extensions easy incorporate model
none introduces fundamental computational diculty basic problems
quantization tempo tracking.

51

fiCemgil & Kappen
2.4 Problem Definition
Given model, define rhythm transcription, i.e., quantization MAP state estimation problem
1: K = argmax p( 1:K jy0:K )
(9)
p( 1:K jy0:K ) =

Z 1:K

dz0:K p( 1:K ; z0:K jy0:K )

tempo tracking filtering problem
X
zk = argmax p( 1:k ; zk jy0:k )
zk

1:k

(10)

quantization problem smoothing problem: wish find likely score

1:K given onsets performance. useful \oine" applications
score typesetting.
real-time interaction, need online estimate tempo/beat zk .
information carried forth filtering density p( 1:k ; zk jy0:k ) Eq.10.
definition best tempo zk maximum somewhat arbitrary. Depending upon
requirements application, P
one make use features filtering
density. example, variance 1:k p( 1:k ; zk jy0:k ) used estimate \amount
confidence" tempo interpretation arg maxzk ; 1:k p( 1:k ; zk jy0:k ) estimate
likely score-tempo pair far.
Unfortunately, quantities Eq. 9 Eq. 10 intractable due explosion
number mixture components required represent exact posterior step k
(See Figure 2). example, calculate exact posterior Eq. 9 need evaluate
following expression:
Z
1
dz0:K p(y0:K jz0:K ; 1:K )p(z0:K j 1:K )p( 1:K )
(11)
p( 1:K jy0:K ) =

Z
1
= p(y0:K j 1:K )p( 1:K )
(12)
Z
P
normalization constant given Z = p(y0:K ) = 1:K p(y0:K j 1:K )p( 1:K ).
trajectory 1:K , integral z0:K computed stepwise k Kalman
filter (See appendix B.1). However, find MAP state Eq. 11, need evaluate
p(y0:K j 1:K ) independently exponentially many trajectories. Consequently,
quantization problem Eq. 9 solved approximately.
accurate approximation, wish exploit inherent independence structure
exact posterior. Unfortunately, since z c integrated over, k become coupled
general p( 1:K jy0:K ) possess conditional independence structure (e.g.,
Markov chain) would facilitate ecient calculation. Consequently, resort
numerical approximation techniques.

3. Monte Carlo Simulation
Consider high dimensional probability distribution
1
p(x) = p (x)
Z

52

(13)

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

0.6

0.6

0.4

0.4

0.2

0.2

2.2769

0

0

4.6765
10.5474





2.6972

0.2

0.2
3.2828
5.0002

0.4

0.4

0.6

0.8
0.5

0.6

0

0.5

1

1.5


2

2.5

3

3.5

(a)

0.8
0.5

0

0.5

1

3

3.5

1.5


2

2.5

3

3.5

(b)

0.6

0.4
0.4593
0.2

7.9036
10.3422
6.6343



0

0.2

10.1982
0.76292
2.393

0.4

2.7957

0.6

0.8
0.5

Figure 2:

0

0.5

1

1.5


2

2.5

(c)

Example demonstrating explosion number components represent
exact posterior. Ellipses denote conditional marginals p(k ; !k jc0:k ; y0:k ). (We show
period logarithmic scale !k = log2 k ). toy example, assume
score consists notes length , i.e., k either 1=2 1.
(a) start unimodal posterior p(0 ; !0 jc0 ; y0 ), e.g., Gaussian centered
(; !) = (0; 0). Since assume score consist eight- quarter
notes, i.e., k 2 f1=2; 1g. predictive distribution p(1 ; !1jc0:1; y0) bimodal
modes centered (0:5; 0) (1; 0) respectively (shown dashed contour
line). next observation y1 observed (shown dashed vertical line around
= 0:5), predictive distribution updated yield p(1 ; !1 jc0:1 ; y0:1 ). numbers
denote respective log-posterior weight mixture component. (b) predictive
distribution p(2 ; !2jc0:1; y0:1) step k = 2 4 modes, two component
p(1; !1jc0:1; y0:1). (c) number components grows exponentially k.




53

(

fiCemgil & Kappen
R
normalization constant Z = dxp (x) known p (x) evaluated
particular x. Suppose want estimate expectation function f (x)
distribution p(x) denoted
Z

hf (x)ip(x) = dxf (x)p(x)
e.g., mean x p(x) given hxi. intractable integration approximated average find N points x(i) , = 1 : : : N p(x)

hf (x)ip(x) N1

N
X

=1



f (x(i) )

(14)

x(i) generated independently sampling p(x), shown N
approaches infinity, approximation becomes exact.
However, generating independent samples p(x) dicult task high dimensions usually easier generate dependent samples, generate x(i+1)
making use x(i) . somewhat surprising, even x(i) x(i+1) correlated
(and provided ergodicity conditions satisfied), Eq. 14 remains still valid estimated
quantities converge true values number samples N goes infinity.
sequence dependent samples x(i) generated using Markov chain
stationary distribution p(x). chain defined collection transition probabilities, i.e., transition kernel (x(i+1) jx(i) ). definition kernel implicit,
sense one defines procedure generate x(i+1) given x(i) . Metropolis
algorithm (Metropolis & Ulam, 1949; Metropolis, Rosenbluth, Rosenbluth, Teller, & Teller,
1953) provides simple way defining ergodic kernel desired stationary
distribution p(x). Suppose sample x(i) . candidate x0 generated sampling symmetric proposal distribution q(x0 jx(i) ) (for example Gaussian centered
x(i) ). candidate x0 accepted next sample x(i+1) p(x0 ) > p(x(i) ). x0
lower probability, still accepted, probability p(x0 )=p(x(i) ).
algorithm initialized generating first sample x(0) according (arbitrary)
proposal distribution.
However given transition kernel , hard assess time required converge
stationary distribution practice one run simulation large
number samples obtained, (see e.g., Roberts & Rosenthal, 1998). choice
proposal distribution q also critical. poor choice may lead rejection
many candidates x0 hence resulting slow convergence stationary distribution.
large class probability models, full posterior p(x) intractable, one
still eciently compute marginals form p(xk jx k ), x k = x1 : : : xk 1 ; xk+1 ; : : : xK
exactly. case one apply specialized Markov chain Monte Carlo (MCMC)
algorithm, Gibbs sampler given below.
1. Initialize x(0)
1:K sampling proposal q(x1:K )
2. = 0 : : : N

1

54

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

k = 1; : : : ; K , Sample

(i)
x(ki+1) p(xk jx(1:i+1)
(15)
k 1 ; xk+1:K )
contrast Metropolis algorithm, new candidate vector x0 ,
Gibbs sampler uses exact marginal p(xk jx k ) proposal distribution.
step, sampler updates one coordinate current state x, namely xk ,
new candidate guaranteed accepted.
Note that, principle don't need sample xk sequentially, i.e., choose k
randomly provided slice visited equally often limit. However, deterministic scan algorithm k = 1; : : : K , provides important time savings type
models consider here.
3.1 Simulated Annealing Iterative Improvement
shift focus sampling MAP state estimation. principle, one use
samples generated sampling algorithm (Metropolis-Hastings Gibbs) estimate
MAP state x p(x) argmax p(x(i) ). However, unless posterior much
i=1:N
concentrated around MAP state, sampler may visit x even though samples
x(i) obtained stationary distribution. case, problem simply
reformulated sample p(x) distribution concentrated local
maxima p(x). One class distributions given pj (x) / p(x)j . sequence
exponents 1 < 2 < < j < : : : called cooling schedule annealing schedule
owing inverse temperature interpretation j statistical mechanics, hence
name Simulated Annealing (SA) (Aarts & van Laarhoven, 1985). j ! 1 suciently
slowly j , cascade MCMC samplers stationary distribution pj (x)
guaranteed (in limit) converge global maximum p(x). Unfortunately,
convergence result hold, cooling schedule must go slowly (in fact, logarithmically)
infinity. practice, faster cooling schedules must employed.
Iterative improvement (II) (Aarts & van Laarhoven, 1985) heuristic simulated annealing algorithm fast cooling schedule. fact, j = 1 j . eventual
advantage greedy algorithm converges iterations local maximum. restarting many times different initial configurations x, one hopes find
different local maxima p(x) eventually visit MAP state x . practice, using
II heuristic one may find better solutions SA limited computation time.
implementation point view, trivial convert MCMC code SA (or II)
code. example, consider Gibbs sampler. implement SA, need construct
cascade Gibbs samplers, stationary distribution p(x)j . exact one time
slice marginal distribution p(xk jx k )j . So, SA samples actual
(temperature=1) marginal p(xk jx k ) raised power j .
3.2 Switching State Space Model MAP Estimation
solve rhythm quantization problem, need calculate MAP state
posterior Eq. 11
p( 1:K jy0:K )

Z

/ p( 1:K ) dz0:K p(y0:K jz0:K ; 1:K )p(z0:K j 1:K )
55

(16)

fiCemgil & Kappen
combinatorial optimization problem: seek maximum function p( 1:K jy0:K )
associates number discrete configurations 1:K . Since feasible
visit exponentially many configurations find maximizing configuration
1: K , resort stochastic search algorithms simulated annealing (SA)
iterative improvement (II). Due strong relationship Gibbs sampler
SA (or II), first review Gibbs sampler switching state space model.
first important observation that, conditioned 1:K , model becomes linear
state space model integration z0:K computed analytically using Kalman
filtering equations. Consequently, one sample 1:K integrate z .
analytical marginalization, called Rao-Blackwellization (Casella & Robert, 1996), improves
eciency sampler (e.g., see Doucet, de Freitas, Murphy, & Russell, 2000a).
Suppose switch variable k distinct states wish
) ; = 1 : : : N g. naive implementation
generate N samples (i.e trajectories) f 1:(iK
Gibbs sampler requires step k run Kalman filter times whole
observation sequence y0:K compute proposal p( k j 1:(ik) 1 ; k(i+1:1)K ; y0:K ). would
result algorithm time complexity O(NK 2 ) prohibitively slow K
large. Carter Kohn (1996) proposed much time ecient deterministic scan
Gibbs sampler circumvents need run Kalman filtering equations
step k whole observation sequence y0:K . See also (Doucet & Andrieu, 2001; Murphy,
2002).
method based observation proposal distribution p( k j )
factorized product terms either depend past observations y0:k
future observations yk+1:K . contribution future computed a-priori
backward filtering pass. Subsequently, proposal computed samples k(i)
generated forward pass. sampling distribution given

p( k j k ; y0:K ) / p( k j k )p(y0:K j 1:K )

(17)

first term proportional joint prior p( k j k ) / p( k ; k ). second
term decomposed

p(y0:K j 1:K ) =
=

Z
Z

dzk p(yk+1:K jy0:k ; zk ; 1:K )p(y0:k ; zk j 1:K )

(18)

dzk p(yk+1:K jzk ; k+1:K )p(y0:k ; zk j 1:k )

(19)

terms (unnormalized) Gaussian potentials hence integral evaluated
analytically. term p(yk+1:K jzk ; k+1:K ) unnormalized Gaussian potential zk
computed backwards filtering. second term filtering distribution
p(zk jy0:k ; 1:k ) scaled likelihood p(y0:k j 1:k ) computed forward
filtering. outline algorithm given below, see appendix B.1 details.
1. Initialize 1:(0)K sampling proposal q( 1:K )
2. = 1 : : : N

k = K 1; : : : ; 0,
56

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization



{ Compute p(yk+1:K jzk ; k(i+1:1)K )
k = 1; : : : ; K ,
{ = 1 : : :
Compute proposal
p( k = sj ) / p( k = s; k )

Z

dzk p(y0:k ; zk j 1:(ik) 1 ; k = s)p(yk+1:K jzk ; k(i+1:1)K )

{ Sample k(i) p( k j )
resulting algorithm time complexity O(NKS ), important saving terms
time. However, space complexity increases O(1) O(K ) since expectations
computed backward pass need stored.
step, Gibbs sampler generates sample single time slice k.
certain types \sticky" models, dependence k k+1
strong, sampler may get stuck one configuration, moving rarely. due
fact singleton ips end low probability configurations due strong
dependence adjacent time slices. example, consider quantization model
two configurations [: : : k ; k+1 : : : ] = [: : : 1; 1 : : : ] [: : : 3=2; 1=2 : : : ]. updating
single slice, may dicult move two configurations. Consider
intermediate configuration [: : : 3=2; 1 : : : ]. Since duration ( k + k+1 ) increases,
future quantization locations ck:K shifted 1=2. may correspond score
heavily penalized prior, thus \blocking" path.
allow sampler move freely, i.e., allow global jumps, one
sample L slices jointly. case proposal distribution takes form
p( k:k+L 1j ) / p( k:k+L 1; (k:k+L 1))
Z
dzk+L 1 p(y0:k+L 1; zk+L 1 j 1:(ik) 1 ; k:k+L 1)p(yk+L:K jzk+L 1 ; k(i+L1):K )
Similar one slice case, terms integral unnormalized Gaussian potentials
(on zk+L 1 ) representing contribution past future observations. Since k:k+L 1
L states, resulting time complexity generating N samples O(NKS L ), thus
practice L must kept rather small. One remedy would use Metropolis-Hastings
algorithm heuristic proposal distribution q( k:k+L 1jy0:K ) circumvent exact calculation, obvious construct q.
One shortcoming Gibbs sampler (and related MCMC methods)
algorithm standard form inherently oine; need access
observations y0:K start simulation. certain applications, e.g., automatic score
typesetting, batch algorithm might still feasible. However scenarios require
real-time interaction, interactive music performance tempo tracking, online
methods must used.
3.3 Sequential Monte Carlo
Sequential Monte Carlo, a.k.a. particle filtering, powerful alternative MCMC
generating samples target posterior distribution. SMC especially suitable
application dynamical systems, observations arrive sequentially.

57

fiCemgil & Kappen
basic idea SMC represent posterior p(x0:k 1 jy0:k 1 ) time k 1
(possibly weighted) set samples fx(0:i)k 1 ; = 1 : : : N g extend representation
f(x(0:i)k 1 ; x(ki) ); = 1 : : : N g observation yk becomes available time k.
common practice use importance sampling.
3.3.1 Importance Sampling

Consider high dimensional probability distribution p(x) = p (x)=Z unknown
normalization constant. Suppose given proposal distribution q(x) close
p(x) high probability regions distributions fairly overlap.
P generate
independent samples, i.e., particles, x(i) proposal q(x) Ni=1 (x
x(i) )=N . approximate
1 p (x)
q(x)
(20)
p(x) =
Z q(x)
N

X
Z1 pq((xx)) N1 (x x(i) )
(21)
i=1
N
X
w(i)

(22)
PN (j) (x x(i) )
j =1 w
i=1
w(i) = p (x(i) )=q(x(i) ) importance weights. One interpret w(i) correction factors compensate fact sampled \incorrect" distribution q(x). Given approximation Eq.22 estimate expectations weighted
averages
N
X
hf (x)ip(x)
w~ (i) f (x(i) )

w~ (i) = w(i) =

PN
j

=1

(23)



=1 w

(j ) normalized importance weights.

3.3.2 Sequential Importance Sampling

wish apply importance sampling dynamical model

p(x0:K jy0:K )

/

K

k

=0

p(yk jxk )p(xk jx0:k 1 )

(24)

x = fz; g. principle one naively apply standard importance sampling using
arbitrary proposal distribution q(x0:K ). However finding good proposal distribution
hard K 1. key idea sequential importance sampling sequential
construction proposal distribution, possibly using available observations y0:k , i.e.,

q(x0:K jy0:K ) =

K

k

=0

58

q(xk jx0:k 1 ; y0:k )

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
Given sequentially constructed proposal distribution, one compute importance
weight recursively

p (x(0:i)k jy0:k ) p(yk jx(ki) )p(x(ki) jx(0:i)k 1 ; y0:k 1 ) p(y0:k 1 jx(0:i)k 1 )p(x(0:i)k 1 )
=
(25)
q(x(0:i)k jy0:k )
q(x(ki) jx(0:i)k 1 y0:k )
q(x(0:i)k 1 jy0:k 1 )
p(yk jx(ki) )p(x(ki) jx(0:i)k 1 ; y0:k 1 ) (i)
=
wk 1
(26)
q(x(ki) jx(0:i)k 1 y0:k )

wk(i) =

sequential update schema potentially accurate naive importance sampling since step k, one generate particle fairly accurate proposal
distribution takes current observation yk account. natural choice
proposal distribution filtering distribution given

q(xk jx(0:i)k 1 y0:k ) = p(xk jx(0:i)k 1 ; y0:k )

(27)

case weight update rule Eq. 26 simplifies

wk(i) = p(yk jx(0:i)k 1 )wk(i) 1
fact, provided proposal distribution q constructed sequentially past sampled trajectories updated, filtering distribution optimal choice sense
minimizing variance importance weights w(i) (Doucet, Godsill, & Andrieu, 2000b).
Note Eq. 27 identical proposal distribution used Gibbs sampling k = K
(Eq 15). k < K , SMC proposal take future observations account;
introduce discount factors wk compensate sampling wrong distribution.
3.3.3 Selection

Unfortunately, sequential importance sampling may degenerate, fact,
shown variance wk(i) increases k. practice, iterations
algorithm, one particle almost probability mass
computation time wasted updating particles negligible probability.
avoid undesired degeneracy problem, several heuristic approaches proposed
literature. basic idea duplicate discard particles according
normalized importance weights. selection procedure deterministic stochastic. Deterministic selection usually greedy; one chooses N particles highest
importance weights. stochastic case, called resampling, particles drawn
probability proportional importance weight wk(i) . Recall normalized weights
fw~k(i) ; = 1 : : : N g interpreted discrete distribution particle labels (i).

3.4 SMC Switching State Space Model
SIS algorithm directly applied switching state space model sampling
directly xk = (zk ; k ). However, particulate approximation quite poor z

59

fiCemgil & Kappen
0.6

0.4

0.2



0

0.2

0.4

0.6

0.8
0.5

0

0.5

1

1.5


2

2.5

3

3.5

Figure 3: Outline algorithm. ellipses correspond conditionals
p(zk j k(i) ; y0:k ). Vertical dotted lines denote observations yk . step
k, particles low likelihood discarded. Surviving particles linked
parents.

high dimensional. Hence, many particles may needed accurately represent
posterior.
Similar MCMC methods introduced previous section, eciency
improved analytically integrating z0:k sampling 1:k . fact,
form Rao-Blackwellization reported give superior results compared standard
particle filtering z sampled jointly (Chen & Liu, 2000; Doucet et al.,
2000b). improvement perhaps surprising, since importance sampling performs
best sampled space low dimensional.
algorithm intuitive interpretation terms randomized breadth first tree
search procedure: new step k, expand N kernels obtain N new kernels.
Consequently, avoid explosion number branches, select N N
branches proportional likelihood, See Figure 3. derivation technical details
algorithm given Appendix C.
tree search interpretation immediately suggests deterministic version algorithm one selects (without replacement) N branches highest weight.
refer method greedy filter (GF). method also known split-track
filter (Chen & Liu, 2000) closely related Multiple Hypothesis Tracking (MHT)
(Bar-Shalom & Fortmann, 1988). One problem greedy selection schema GF
loss particle diversity. Even particles initialized different locations z0 ,
(e.g., different initial tempi), mainly due discrete nature state space k ,
particles become identical steps k. Consequently, results
improved increasing number particles N . Nevertheless,
particles used, say e.g., real time application, GF may still viable choice.

60

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

(i) optimal.
Figure 4: hypothetical situation neither two particles 1:5
would obtain eventually higher likelihood configuration interchanging 3
particles.
3.5 SMC estimation MAP trajectory
Like MCMC, SMC sampling method. Hence comments made Section 3.1
) jy )
eventual suboptimality estimating MAP trajectory particles arg max p( 1:(iK
0:K
also apply here. hypothetical situation shown figure 4.
One obvious solution employ SA \trick" raise proposal distribution
power p( k j) . However, proposal peaked time
slice. Consequently, particles become identical time algorithm
eventually degenerates greedy filtering.
algorithm estimating MAP trajectory set SMC samples recently
proposed literature (Godsill, Doucet, & West, 2001). algorithm relies
observation particles x(ki) sampled forward pass, one left
N
discrete distribution defined (discrete) supportN
X1:K = K
k=1 Xk . Xk denotes
support filtering distribution time k Cartesian product

sets. Formally, Xk set distinct samples time k given Xk = fx(ki) g.
distribution p(X1:K jy1:K )3 Markovian original state transition model
Markovian, i.e., posterior represented exactly
p(X1:K jy1:K ) /

K


p(yk jXk )p(Xk jXk 1 )
=1
Consequently, one find best MAP trajectory arg max p(X1:K ) using algorithm
analogous Viterbi algorithm hidden Markov models (Rabiner, 1989).
However, idea carry directly case one applies Rao-Blackwellization. general, subset hidden variables
NisK integrated out,Sall time
slices posterior p( 1:K jy1:k ) coupled, 1:K = k=1 k k = f k(i) g.
One still employ chain approximation run Viterbi, (e.g., Cemgil & Kappen,
2002), guarantee find arg max p( 1:K jy1:k ).
hand, k(i) drawn discrete set, several particles become
identical k usually small cardinality compared number particles
N . Consequently, becomes feasible employ SA II reduced state space 1:K ;
possibly using proposal distribution extends several time slices L.
k

3. slight abuse notation use symbol Xk set general element used
argument density, p(yk jXk ) means p(yk jxk ) s.t. xk 2 Xk

61

fiCemgil & Kappen
) ; = 1 : : : N g,
practice, finding MAP solution particle set f 1:(iK
) )p( (i) ) apply iterative
propose find best trajectory = arg maxi p(y0:K j 1:(iK
1:K

improvement starting initial configuration 1:(iK) .

4. Simulations
compared inference methods terms quality solution execution time. tests carried artificial real data.
Given true notation 1:true
K , measure quality solution terms
log-likelihood difference
L = log

p(y0:K j 1:K )p( 1:K )
true
p(y0:K j 1:true
K )p( 1:K )

terms edit distance

e( 1:K ) =

K
X

(1 ( k

ktrue ))

=1
edit distance e( 1:K ) gives simply number notes quantized wrongly.
k

4.1 Artificial data: Clave pattern
(c = [1, 2, 4, 5:5,
synthetic example repeating \son-clave" pattern
7 : : : ]) uctuating tempo. repeat pattern 6 times obtain score 1:K
K = 30.
syncopated rhythms usually hard transcribe make dicult track
tempo even experienced human listeners. Moreover, since onsets absent
prominent beat locations, standard beat tracking algorithms usually loose track.
Given score 1:K , generated 100 observation sequences y0:K sampling
tempo model Eq. 7. parameterized observation noise variance4
Q = k Qa + Qb . formulation, variance depends length interval
consecutive onsets; longer notes score allow tempo timing
uctuation. tests clave example used prior model ects
true source statistics, instead, used generic prior model defined Section 2.1
= 1.
example cases sampled score (clave pattern). However, due
use generic prior (that capture exact source statistics well)
relatively broad noise model, MAP trajectory 1: K given y0:K always identical
;i
original clave pattern. i'th example, defined \ground truth" 1:true
K
highest likelihood solution found using sampling technique independent
run. Although definition ground truth introduces bias, found
exercise realistic well discriminative among various methods
compared to, e.g.,, using dataset essentially shorter sequences exact MAP
7

7



>









>

4. noise covariance parameters R = 0:022 , Qa = 0:062 Qb = 0:022 . 2 2 identity
matrix.

62

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
trajectory computed exhaustive enumeration. wish stress main
aim simulations synthetic dataset compare effectiveness different inference
techniques; postpone actual test whether model good one simulations
real data.
tested MCMC methods, namely Gibbs sampling (Gibbs), simulated annealing (SA) iterative improvement (II) one two time slice optimal proposal
10 50 sweeps. onset yk , optimal proposal p( k j) computed
always fixed set, = f0; 1=4; 2=4 : : : 3g. Figure 6 shows typical run MCMC.
Similarly, implemented SMC N = f1; 5; 10; 50; 100g particles.
selection schema random drawing optimal proposal p( k j) computed using
one two time slices. special case greedy filtering (GF), i.e., N = 1,
selected switch maximum probability. example run shown Figure 5.
observe average SMC results superior MCMC (Figure 7). observe
that, increasing number sweeps MCMC improve solution significantly.
hand, increasing number particles seems improve quality
SMC solution monotonically. Moreover, results suggest sampling two time
slices jointly (with exception SA ) big effect. GF outperforms
particle filter 5 particles draws randomly proposal. suggests
PF small number particles N , may desirable use hybrid selection
schema selects particle maximum weight automatically randomly selects
remaining N 1.
compare inference methods terms execution time quality solutions (as
measured edit distance). Figure 8 suggests, using two slice proposal justified.
Moreover seems comparable computational effort, SMC tends outperform
MCMC methods.

4.2 Real Data: Beatles
evaluate performance model polyphonic piano performances. 12 pianists
invited play two Beatles songs, Michelle Yesterday. pieces relatively
simple rhythmic structure ample opportunity add expressiveness uctuating
tempo. original score shown Figure 9(a). subjects different musical education background: four professional jazz players, four professional classical performers
four amateur classical pianists. arrangement played three tempo
conditions, three repetitions per tempo condition. tempo conditions normal, slow
fast tempo, musically realistic range according judgment
performer. details reported (Cemgil et al., 2001).
4.2.1 Preprocessing

original performances contained several errors, missing notes additional notes
original score. errors eliminated using matching technique (Heijink, Desain, & Honing, 2000) based dynamical programming. However, visual
inspection resulting dataset suggested still several matching errors interpret
outliers. remove outliers, extended quantization model two
state switching observation model, i.e., discrete space consists ( k ; ik ). simple

63

fiCemgil & Kappen

1

0.8

0.6

0.4



0.2

0

0.2

0.4

0.6

0.8

1

0

2

4

6

8


10

12

14

16

Figure 5: Particle filtering clave example 4 particles. circle denotes mean
(k(n) ; !k(n) ) !k(n) = log2 k . diameter particle proportional
normalized importance weight generation. '*' denote true
(; !) pairs; modulated tempo deterministically according
!k = 0:3 sin(2ck =32), observation noise variance R = 0:0252 .

64

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

0

Log Likelihood

10

20
Gibbs
SA
II
GF
Desired

30

40

Figure 6:

1

10

20
30
Gibbs Sweep

40

50

Typical runs Gibbs sampling, Simulated Annealing (SA) Iterative Improvement
(II) clave example. algorithms initialized greedy filter solution.
annealing schedule SA linear 1 = 0:1 33 = 10 proceeding deterministically 34:50 = 1. SA II converge configuration, reinitialize
particle filter one particle draws randomly proportional optimal
proposal. Sharp drops likelihood correspond reinitializations. see that,
first sweep, greedy filter solution slightly improved II. Consequently sampler reinitializes. likelihood SA drops considerably, mainly due
high temperature, consequently stabilizes suboptimal solution. Gibbs
sampler seems explore support posterior able visit MAP
state run.

65

fiCemgil & Kappen

Log Likelihood Difference

0

5

10

15

20
1 Slice
2 Slice
25

SA

Gibbs

II

GF

PF

(a) Likelihood Difference
30

1 Slice
2 Slice

Edit Distance

25
20
15
10
5
0
SA

Gibbs

II

GF

PF

(b) Edit Distance. MCMC results 10 sweeps omitted.

Figure 7:

Comparison inference methods clave data. squares ovals denote
median vertical bars correspond interval %25 %75 quantiles.
tested MCMC methods (Gibbs, SA II) independently 10 50
(shown left right). SMC methods greedy filter (GF) particle filter
(PF). tested filters N = f5; 10; 50; 100g particles independently (shown
left right.).

66

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

SA1

SA2

Median Edit Distance

20

15

PF25

PF15

PF110

10
GF1

II1 PF210

GF2

Gi1

Gi2
II2

5

0

PF150

PF1100

PF250
PF2100

Flops (log scale)

Figure 8:

Comparison execution time terms oating point operations. methods,
first number (1 2) denotes number slices used optimal proposal distribution.
particle filter (PF), second number denotes number particles.
dashed lines merely used connect related methods.

outlier detection mechanism, switch ik binary indicator variable specifying whether
onset yk outlier not. assume indicators independent a-priori
uniform prior. observation model given p(yk jik ; k ) = N (0; Rik ) 5 .
Since score 1:K known, unknown discrete quantities indicators i0:K .
used greedy filtering followed iterative improvement find MAP state
indicators i0:K eliminated outliers studies. many performances,
around 2 4 outliers, less 1% notes. resulting dataset
downloaded url http://www.snn.kun.nl/cemgil.
4.2.2 Parameter Estimation

trained tempo tracking models different dimensionality D, denotes
dimension hidden variable z . models, use transition matrix
form Eq. 8.
Since true score known, i.e., quantization location ck onset yk given,
clamp discrete variables model. Consequently, estimate
observation noise variance R, transition noise variance Q transition matrix
coecients data.
optimized parameters Expectation-Maximization (EM) linear
dynamical systems (Shumway & Stoffer, 1982; Ghahramani & Hinton, 1996) using perfor5. took Rik =0 = 0:002 Rik =1 = 2.

67

fiCemgil & Kappen
mances \Yesterday" training data. Similarly, score prior parameters estimated
frequency counts score \Yesterday" 6 . tests carried \Michelle".
4.2.3 Results

Figure 9 show result typesetting performance without tempo
tracking. Due uctuations tempo, quality automatically generated score
poor. quality significantly improved using model.
Figure 10 shows tempo tracking examples Michelle dataset pianists
different background training. observe cases results satisfactory.
Figure 11, give summary test results Michelle data terms loglikelihood edit distance function model order number particles used
inference. Figure 11(a) shows median likelihood test data increasing
model order. suggests higher order filter able capture structure pianists' expressive timing. Moreover, sythetic data, see somewhat monotonic
increase likelihood solutions found using particles.
edit distance original score estimates given Figure 11(b).
Since pieces arranged piano, due polyphony, many onsets
associated quantization location. Consequently, many ktrue original
score effectively zero. cases, typically, corresponding inter onset interval
yk yk 1 also small correct quantization (namely k = 0) identified
even tempo estimate completely wrong. consequence, edit distance remains
small. make task slightly challenging, exclude onsets ktrue = 0
edit distance calculation.
observe extra prediction ability obtained using higher order model
directly translate better transcription. errors around 5% models.
hand, variance edit distance higher order models smaller.
suggests higher order models tend robust divergence
original tempo track.

5. Discussion
presented switching state space model joint rhythm quantization tempo
tracking. model describes rhythmic structure musical pieces prior distribution quantization locations. representation, easy construct generic
prior prefers simpler notations learn parameters data set. prior
quantization locations c0:K translates non-Markovian distribution score 1:K .
Timing deviations introduced performers (tempo uctuation, accentuations motor errors) modeled independent Gaussian noise sources. Performer specific timing
preferences captured parameters distributions.
Given model, formulated rhythm quantization MAP state estimation
problem tempo tracking filtering problem. introduced Markov chain
6. maximum likelihood parameters model dimension = 3 found be: = 0:072, R =
0:0132 q = 0:0082 , q1 = 0:0072 q2 = 0:0502 . prior p(c) p(0) = 0:80, p(1=3) = 0:0082,
p(1=2) = 0:15 p(5=6) = 0:0418. Remaining p(c) set 10 6 .

68

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

Michelle
Lennon/McCartney

bb 4




& b b 4 n n ww n


w
? b b b 44
w



w
b


1

Piano







6

bb
& b b

? bb
bb



n


n


bb
& b b n


? bb

bb





6

11







n



n

n n . w n
. J



n
n n


n


n





3

n n


n

n

n






































































































10

3

13

17
3

bb
& b b . n.
.
? bb
bb
16

n n


bb
& b b

J
? bb
bb
n

21

bb
& b b n w
w
? bb
bb

3

j

.. .


b ..

..





j
.
..






n









n



j
ww
w



.



n




j











20

24








27

26



n ww
w

n n

w



(a) Original Score






































(b) Typesetting without
processing model.
Due uctuations
tempo, quality
score poor.

Figure 9:

























q = 130

6

11

16

3












3






3








































































20



24

(c) Typesetting tempo
tracking quantization
particle filter.

Results Typesetting scores.

69























fiCemgil & Kappen

0

0
Estimated
Original

Estimated
Original

0.4

0.4
2

log

2

log

k

0.2

k

0.2

0.6

0.6

0.8

0.8

1

0

10

20

30



40

50

60

1
10

70

0

10

20

30

k



40

50

60

70

80

k

(a) Professional Jazz Pianist

(b) Amateur

0

0
Estimated
Original

Estimated
Original

0.2

0.2

0.4
0.6

2

log

2

log

k

0.8

k

0.4

0.6

1

1.2
1.4

0.8

1.6
1.8

1
10

0

10

20

30



40

50

60

70

80

k

0

10

20

30



40

50

60

70

k

(c) Professional Classical Pianist.
filter temporarily loses track.

Figure 10:

2

(d) Tracking twice rate
original tempo.

Examples filtered estimates
z0:K = [k ; k ]T Beatles data set. Circles
original
denote mean p(zk j 1:k ; y0:k ) \x" denote mean p(zk j 1: k ; y0:k ) obtained
SMC. interesting note different timing characteristics. example classical
pianist uses lot tempo uctuation professional jazz pianist. Jazz pianist
slows dramatically end piece, amateur \rushes", i.e., constantly
accelerates beginning. tracking quantization results (a) (b)
satisfactory. (a), filter loses track last two notes, pianist
dramatically slows down. (c), filter loses track catches again. (d),
filter jumps metrical level twice fast original performance.
would translate duplication note durations only.

70

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

500

480

Likelihood

460

440

420

400

380

360

2

3
Model Dimension

4

(a) Likelihood. dashed horizontal line shows median
likelihood original score Michelle model.
50

45

40

Percent Edit Distance

35

30

25

20

15

10

5

0

2

3
Model Dimension

4

(b) Edit Distance

Figure 11:

SMC results test data (108 performances Michelle). model show
results obtained N = 1; 10; 20 50 particles. \-" show median
best particle \x" denote median applying iterative improvement.
vertical bars correspond interval %25 %75 quantiles.
71

fiCemgil & Kappen
Monte Carlo (MCMC) sequential Monte Carlo (SMC) approximate respective
distributions.
quantization model propose similar (Raphael, 2001a). transcription, Raphael proposes compute arg max p(c0:K ; z0:K jy0:K ) uses message propagation scheme essentially analogous Rao-Blackwellized particle filtering. prevent
number kernels explosion, uses deterministic selection method, called
\thinning". advantage Raphael's approach joint MAP trajectory
computed exactly, provided continuous hidden state z one dimensional
model parameter regime keeps number propagated Gaussian kernels
limited, e.g., R small, thinning eliminate many kernels. One disadvantage
number kernels varies depending upon features filtering distribution;
dicult implement scheme real time. Perhaps importantly, simple extensions increasing dimensionality z introducing nonlinearities
transition model would render approach quickly invalid. contrast, Monte Carlo
methods provide generic inference technique allow great exibility models one
employ.
tested method challenging artificial problem (clave example). SMC
outperformed MCMC terms quality solutions, measured terms
likelihood well edit distance. propose use SMC problems.
finding MAP quantization, propose apply iterative improvement (II) SMC
solution reduced configuration space.
correct choice score prior important overall performance
system. music pieces tend certain rhythmical vocabulary, certain
rhythmical motives reoccur several times given piece. rhythmic structure depends
mostly upon musical genre composer. seems rather dicult devise
general prior model would work well large spectrum styles. Nevertheless,
given genre, expect simple prior capture enough structure sucient good
transcription. example, Beatles dataset, estimated prior counting
original score \Yesterday". statistics fairly close \Michelle".
good results test set partially accounted fact pieces
similar rhythmical structure.
Conditioned score, tempo tracking model linear dynamical system.
optimized several tempo models using EM varied dimension
tempo variables z . test results suggest increasing dimensionality z improves
likelihood. However, increase likelihood whole dataset translate
directly overall better quantization results (as measured edit distance). observe
models trained whole training data fail consistently subjects, especially
professional classical pianists. Perhaps interestingly, train \custom" models specifically
optimized subjects, improve results significantly also test cases.
observation suggests kind multimodality parameter space modes
correspond different performer regimes. seems Kalman filter able capture
structure expressive timing deviations. However, averaged subjects,
details tend wiped out, suggested quantization results
vary significantly among models different dimensions.

72

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
related problem edit distance measure \average" model,
likelihood desired score (e.g., original score \Michelle") may lower likelihood
solution found inference method. cases increasing likelihood may
even decrease edit distance. test cases even observe solutions higher
likelihood original notation notes wrong. cases,
tempo trajectory solution correspond half twice original tempo
consequently note durations halved doubled (e.g., whole notes notated
half notes, half notes quarters e.t.c.). Considering fact model \self
initializing" tempo, assume broad uncertainty a-priori, results still
satisfactory practical application perspective.
One potential shortcoming model takes timing information onsets
account. reality, believe pitch melodic grouping well articulation
(duration note onsets offsets) dynamics (louder softer) provide useful
additional information tempo tracking well quantization. Moreover, current model
assumes onsets equally relevant estimation. probably general
true: example, kick-drum provide information tempo
ute. hand, simulations suggest even limited model one
obtain quite satisfactory results, least simple piano music.
somewhat surprising, SMC, basically method samples filtering
distribution outperforms MCMC method SA specifically designed
finding MAP solution given observations. intuitive explanation relatively
poorer MCMC results MCMC proceeds first proposing global solution
tries improve local adjustments. human transcriber, hand, would
listen shorter segments music gradually write score. respect,
sequential update schema SMC seems natural rhythm transcription problem. Similar results, SMC outperforms MCMC already reported
literature, e.g., so-called \Growth Monte Carlo" generating self-avoiding random
walks (Liu, Chen, & Logvinenko, 2001). seems large class dynamical problems, including rhythm transcription, sequential updating preferable batch methods.
note theoretical convergence results SA require use logarithmic
cooling schedule. seems cooling schedule fast meet requirement;
one still careful interpreting poor performance negative SA result.
maintain using richer neighborhood structure configuration space (e.g.,
using block proposal distribution) slower cooling schedule, SA results
improved significantly. Moreover, MCMC methods also modified operate
sequentially, example see (Marthi, Pasula, Russell, & Peres, 2002).
Another family inference methods switching state space models rely deterministic approximate methods. family includes variational approximations (Ghahramani &
Hinton, 1998) expectation propagation (Heskes, 2002). remains interesting open
question whether deterministic approximation methods provide advantage terms
computation time accuracy; particular quantization problem
switching state space models. potential application deterministic approximation
techniques MCMC schema designing proposal distributions extend
several time slices. schema would circumvent burden computing optimal
proposal distribution exhaustively hence allowing global moves sampler.

73

fiCemgil & Kappen
current results suggest superiority SMC problem. Perhaps
important advantage SMC essentially \anytime" algorithm;
faster computer increase number particles make use additional
computational power. computing time becomes short one decrease number
samples. features make SMC attractive real-time applications one
easily tune quality/computation-time tradeoff.
Motivated practical advantages SMC positive simulation results,
implemented prototype SMC method real-time. current computer system
(a 800 MHz P3 laptop PC running MS Windows) allows us use 5 particles
almost delay even busy passages. expect significantly improve eciency
translating MATLAB c constructs native C code. Hence, method used
tempo tracker automatic interactive performance system quantizer
automatic score typesetting program.

Acknowledgments
research supported Technology Foundation STW, applied science division
NWO technology programme Dutch Ministry Economic Affairs.
would like thank associate editor Daphne Koller anonymous reviewers
comments helped us significantly improve article. would also like
thank Ric Ashley, Peter Desain, Henkjan Honing Paul Trilsbeek suggestions
contributions data collection. Moreover gratefully acknowledge pianists
Northwestern University Nijmegen University excellent performances.

Appendix A. generic prior model quantization locations c
traditional western music notation, note durations generated recursive subdivisions
starting whole note, hence also convenient generate quantization locations
similar fashion regular subdivisions. decompose quantization location
integer part fraction: c = bcc + (c mod 1). defining prior, use
fraction.
set fractions generated recursively subdividing unit interval
[0; 1). let = [si ] denote subdivision schema, [si ] (finite) sequence
arbitrary integers (usually small primes 2,3 5). choice particular
depends mainly assumed time signature. generate set fractions C
follows: first iteration, divide unit interval s1 intervals equal length
append endpoints c0 resulting intervals set C . following iteration i,
subdivide intervals generated previous iteration si equal parts append
resulting endpoints C . Note thisQprocedure generates regular grid two
neighboring grid points distance 1= si . denote iteration number
endpoint c0 first inserted C depth c0 (with respect ). number
denoted d(c0 jS ). easy see definition coincides number
significant bits represent c mod 1 = [2; 2; : : : ].
illustirative example consider subdivision = [3; 2]. first iteration,
unit interval divided s1 = 3 equal intervals, resulting endpoints 0, 1=3,

74

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
2=3 inserted C depths d(0) = d(1=3) = d(2=3) = 1. second iteration,
new endpoints 1=6, 3=6 5=6 inserted C assigned depth 2.
Given , define distribution quantization locations

p(ck jS ) / exp( d(ck mod 1jS ))
wish consider several time signatures, i.e., different subdivision schemata,
interpret hidden indicator variable define
P prior p(S ). case, prior
becomes multinomial mixture given p(ck ) = p(ck jS )p(S ). details
empirical results justifying choice see (Cemgil et al., 2000).

Appendix B. Derivation two pass Kalman filtering Equations
Consider Gaussian potential mean covariance defined domain
indexed x.
1
1
(28)
(x) = Z N (; ) = Z j2j 2 exp( (x )T 1 (x ))
2
R
dx(x) = Z > 0. Z = 1 potential normalized. exponent Eq. 28
quadratic form potential written
1
x Kx)
(29)
(x) = exp(g + hT x
2

1
K 1 1
K= 1
h= 1
g = log Z + log j j
h K h
2
2 2
denote potential canonical form use notation

(x) = Z N (; ) [h; K; g]
refer g, h K canonical parameters. consider Gaussian
potential (x1 ; x2 )T . canonical representation

(x1 ; x2 ) =



h1
h2


;

K11 K12
K21 K22


;g

models several variables interacting, one find desired quantities applying
three basic operations defined Gaussian potentials. multiplication, conditioning, marginalization. multiplication two Gaussian potentials index
set x follows directly Eq. 29 given
0 (x) = (x) b (x)
[h0 ; K 0 ; g0 ] = [ha ; Ka ; ga ] [hb ; Kb ; gb ] = [ha + hb ; Ka + Kb ; ga + gb ]
domain b overlaps subset, potentials extended
appropriate domain appending zeros corresponding dimensions.

75

fiCemgil & Kappen
marginalization operation given

(x1 ) =

Z

K12 K221 h2 ; K11

(x1 ; x2 ) = [h1

x2

K12 K221 K21 ; g0 ]

g0 = g 21 log jK22 =2 j + 21 h2 (K22 ) 1 h2 g initial constant term (x1 ; x2 ).
conditioning operation given
(x1 ; x2 = x^2 ) = [h1 K12 x^2 ; K11 ; g0 ]

1 x^T K22 x^2 .
2 2

g0 = g + hT2 x^2

B.1 Kalman Filter Recursions
Suppose given following linear model subject noise
zk = Azk 1 + k
yk = Czk + k
C constant matrices, k N (0; Q) k N (0; R)
model encodes joint distribution
K


p(yk jzk )p(zk jzk 1 )
=1
p(z1 jz0 ) = p(z1 )

p(z1:K ; y1:K ) =

k

(30)
(31)

1
1 1
p(z1 ) = [P 1 ; P 1 ; log j2P j
P ]
2
T2 1

TR 1
1
0
C
R
C
C
p(y1 jz1 ) =
;
; log j2Rj
0
R 1C
R 1
2
1
1 1
p(y1 = y^1 jz1 ) = [0 + C R 1 y^1 ; C R 1 C; log j2Rj
y^ R y^1 ]
2
2 1

1

TQ 1
1
0

Q


p(z2 jz1 ) =
; log j2Qj
0 ;
Q 1A
Q 1
2
:::
B.1.1 Forward Message Passing

Suppose wish compute likelihood

p(y1:K ) =

Z

zK

p(yK jzK ) : : :

Z

z2

p(z3 jz2 )p(y2 jz2 )

Z
z1

p(z2 jz1 )p(y1 jz1 )p(z1 )

7 compute integral starting z1 proceeding zK . define forward
\messages" ff
R
R
7. let z dz

76

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

ff1j0 = p(z1 )
k=1:K
{ ffkjk = p(yk = y^k jzk )ffkjk 1
R
{ ffk+1jk = zk p(zk+1 jzk )ffkjk
forward recursion given
ff1j0 = [P 1 ; P 1; 12 log j2P j
k = 1:::K

1 P 1 ]
2

{ ffkjk = [hkjk ; Kkjk ; gkjk ]
hkjk = C R 1 y^k + hkjk 1
Kkjk = C R 1 C + Kkjk 1
gkjk = gkjk 1 21 log j2Rj 12 y^1T R 1 y^k
{ ffk+1jk = [hk+1jk ; Kk+1jk ; gk+1jk ]
Mk = (AT Q 1 + Kkjk ) 1
hk+1jk = Q 1 AMk hkjk
Kk+1jk = Q 1 Q 1 AMk Q 1
gk+1jk = gkjk 21 log j2Qj + 12 log j2Mk j + 12 hTkjk Mk hkjk
B.1.2 Backward Message Passing

compute likelihood also starting yK .

p(y1:K ) =

Z

z1

p(z1 )p(y1 jz1 )

Z

z2

p(z2 jz1 )p(y2 jz2 ) : : :

Z
zK

case backward propagation summarized

fiK jK +1 = 1
k = K :::1
{ fikjk = p(yk = y^k jzk )fikjk+1
R
{ fik 1jk = zk p(zk jzk 1 )fikjk
recursion given

[hK jK +1; KK jK +1; gK jK +1] = [0; 0; 0]
k = K :::1
{ fikjk = [hkjk ; Kkjk ; gkjk ]
hkjk = C R 1 y^k + hkjk+1
Kkjk = C R 1 C + Kkjk+1

77

p(zK jzK 1 )p(yK jzK )

fiCemgil & Kappen
gkjk = 21 log j2Rj 12 y^kT R 1 y^k + gkjk+1
{ fik 1jk = [hk 1jk ; Kk 1jk ; gk 1jk ]
Mk = (Q 1 + Kkjk ) 1
hk 1jk = Q 1 Mk hkjk
Kk 1jk = Q 1 (Q Mk )Q 1
gk 1jk = gkjk 21 log j2Qj + 12 log j2Mk j + 12 h Tkjk Mk hkjk
B.2 Kalman Smoothing
Suppose wish find distribution particular zk given observations y1:K .
combine forward backward messages
p(zk jy1:K )

/ p(yk+1:K ; zk ; y1:k )

= p(y1:k ; zk )p(yk+1:K jzk )
= ffkjk fikjk+1
= [hkjk + hkjk+1 ; Kkjk + Kkjk+1; gkjk + gkjk+1]

Appendix C. Rao-Blackwellized SMC Switching State space
Model
let = 1 : : : N index particles = 1 : : : index states .
denote (unnormalized) filtering distribution time k 1
(ki) 1 =^ p(y0:k 1; zk 1 j 1:(ik) 1 )
Since y0:k 1 observed, (ki) 1 Gaussian potential zk 1 parameters Zk(i) 1
N
((i) ; (i) ). Note normalization constant Zk(i) 1 data likelihood p(y0:k 1j 1:(ik) 1 ) =
R k (1i) k 1
dzk k 1 . Similarly, denote filtered distribution next slice conditioned
k =

(ksji) =
^

Z

dzk 1 p(yk jzk )p(zk jzk 1 ; k = s)(ki) 1
(32)
= p(y0:k ; zk j 1:(ik) 1 ; k = s)
denote normalization constant (ksji) Zk(sji). Hence joint proposal
(i) given
qk(sji) =

Z

dzk (ksji) p( k = s; 1:(ik) 1 )
= p( k = s; 1:(ik) 1 ; y0:k )

outline algorithm given below:
Initialize. = 1 : : : N , (0i) p(y0; x0)

78

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization

k = 1 : : : K
{ = 1 : : : N , = 1 : : :
Compute (ksji) (ki) 1 using Eq.32.
qk(sji) Zk(sji) p( k = s; 1:(ik) 1 )
{ = 1 : : : N
Select tuple (sjj ) qk
1:(ik) ( 1:(jk) 1 ; k = s)
(ki) (ksjj )
P (sjj)
wk(i)
qk
Note procedure \built-in" resampling schema eliminating particles
small importance weight. Sampling jointly (sji) equivalent sampling single
resampling according weights wk(i) . One also check that,
since using optimal proposal distribution Eq.27, weight step
given wk(i) = p( 1:(ik) 1 ; y0:k ).

References

Aarts, E. H. L., & van Laarhoven, P. J. M. (1985). Statistical cooling: general approach
combinatorial optimization problems. Philips Journal Research, 40 (4), 193{226.
Agon, C., Assayag, G., Fineberg, J., & Rueda, C. (1994). Kant: critique pure quantification.
Proceedings International Computer Music Conference, pp. 52{9, Aarhus, Denmark.
International Computer Music Association.
Andrieu, C., de Freitas, N., Doucet, A., & Jordan, M. I. (2002). introduction MCMC
machine learning. Machine Learning, appear.
Bar-Shalom, Y., & Fortmann, T. E. (1988). Tracking Data Association. Academic Press.
Bar-Shalom, Y., & Li, X.-R. (1993). Estimation Tracking: Principles, Techniques Software.
Artech House, Boston.
Cambouropoulos, E. (2000). MIDI traditional musical notation. Proceedings AAAI
Workshop Artificial Intelligence Music: Towards Formal Models Composition, Performance Analysis, Austin, Texas.
Carter, C. K., & Kohn, R. (1996). Markov Chain Monte Carlo conditionally Gaussian state space
models. Biometrika, 83 (3), 589{601.
Casella, G., & Robert, C. P. (1996). Rao-Blackwellisation sampling schemas. Biometrika, 83,
81{94.
Cemgil, A. T., Desain, P., & Kappen, H. J. (2000). Rhythm quantization transcription. Computer
Music Journal, 24:2, 60{76.
Cemgil, A. T., & Kappen, H. J. (2002). Rhythm quantization tempo tracking sequential
Monte Carlo. Dietterich, T. G., Becker, S., & Ghahramani, Z. (Eds.), Advances Neural
Information Processing Systems 14. MIT Press.
Cemgil, A. T., Kappen, H. J., Desain, P., & Honing, H. (2001). tempo tracking: Tempogram
representation Kalman filtering. Journal New Music Research, 28:4, 259{273.
Chen, R., & Liu, J. S. (2000). Mixture Kalman filters. J. R. Statist. Soc., 10.
79

fiCemgil & Kappen
Dannenberg, R. (1984). on-line algorithm real-time accompaniment. Proceedings ICMC,
pp. 193{198, San Francisco.
Desain, P., & Honing, H. (1991). Quantization musical time: connectionist approach. Todd,
P. M., & Loy, D. G. (Eds.), Music Connectionism., pp. 150{167. MIT Press., Cambridge,
Mass.
Desain, P., & Honing, H. (1994). brief introduction beat induction. Proceedings ICMC,
San Francisco.
Dixon, S., & Cambouropoulos, E. (2000). Beat tracking musical knowledge. Horn, W. (Ed.),
Proceedings ECAI 2000 (14th European Conference Artificial Intelligence), Amsterdam.
Doucet, A., & Andrieu, C. (2001). Iterative algorithms state estimation jump Markov linear
systems. IEEE Trans. Signal Processing, 49 (6), 1216{1227.
Doucet, A., de Freitas, N., & Gordon, N. J. (Eds.). (2001). Sequential Monte Carlo Methods
Practice. Springer-Verlag, New York.
Doucet, A., de Freitas, N., Murphy, K., & Russell, S. (2000a). Rao-Blackwellised particle filtering
dynamic Bayesian networks. Uncertainty Artificial Intelligence.
Doucet, A., Godsill, S., & Andrieu, C. (2000b). sequential Monte Carlo sampling methods
Bayesian filtering. Statistics Computing, 10 (3), 197{208.
Fox, D., Burgard, W., & Thrun, S. (1999). Markov localization mobile robots dynamic
environments. Journal Artificial Intelligence Research (JAIR), 11.
Ghahramani, Z., & Hinton, G. (1998). Variational learning switching state-space models. Neural
Computation, 12 (4), 963{996.
Ghahramani, Z., & Hinton, G. E. (1996). Parameter estimation linear dynamical systems. (crgtr-96-2). Tech. rep., University Totronto. Dept. Computer Science.
Godsill, S., Doucet, A., & West, M. (2001). Maximum posteriori sequence estimation using Monte
Carlo particle filters. Annals Institute Statistical Mathematics, 52 (1), 82{96.
Gordon, N. J., Salmond, D. J., & Smith, A. F. M. (1993). Novel approach nonlinear/nonGaussian Bayesian state estimation. IEE Proceedings Part F, Radar Signal Processing,
Vol. 140(2), pp. 107{113.
Goto, M., & Muraoka, Y. (1998). Music understanding beat level: Real-time beat tracking
audio signals. Rosenthal, D. F., & Okuno, H. G. (Eds.), Computational Auditory Scene
Analysis.
Grubb, L. (1998). Probabilistic Method Tracking Vocalist. Ph.D. thesis, School Computer
Science, Carnegie Mellon University, Pittsburgh, PA.
Hamanaka, M., Goto, M., Asoh, H., & Otsu, N. (2001). learning-based quantization: Estimation
onset times musical score. Proceedings 5th World Multi-conference Systemics,
Cybernetics Informatics (SCI 2001), Vol. X, pp. 374{379.
Heijink, H., Desain, P., & Honing, H. (2000). Make match: evaluation different approaches
score-performance matching. Computer Music Journal, 24(1), 43{56.
Heskes, T. Zoeter, O. (2002). Expectation propagation approximate inference dynamic
Bayesian networks. Proceedings UAI.
Isard, M., & Blake, A. (1996). Contour tracking stochastic propagation conditional density.
ECCV (1), pp. 343{356.
Large, E. W., & Jones, M. R. (1999). dynamics attending: track time-varying events.
Psychological Review, 106, 119{159.
Liu, J. S., Chen, R., & Logvinenko, T. (2001). theoretical framework sequential importance
sampling resaampling. Doucet, A., de Freitas, N., & Gordon, N. J. (Eds.), Sequential
Monte Carlo Methods Practice, pp. 225{246. Springer Verlag.
80

fiMonte Carlo Methods Tempo Tracking Rhythm Quantization
Longuet-Higgins, H. C. (1987). Mental Processes: Studies Cognitive Science. MIT Press, Cambridge. 424p.
Marthi, B., Pasula, H., Russell, S., & Peres, Y. (2002). Decayed MCMC filtering. Proceedings
UAI.
Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., & Teller, E. (1953). Equations state
calculations fast computing machines. Journal Chemical Physics, 21, 1087{1091.
Metropolis, N., & Ulam, S. (1949). Monte Carlo method. Journal American Statistical
Assoc., 44(247), 335{341.
Murphy, K. P. (2002). Dynamic Bayesian Networks: Representation, Inference Learning. Ph.D.
thesis, University California, Berkeley.
Pressing, J., & Lawrence, P. (1993). Transcribe: comprehensive autotranscription program..
Proceedings International Computer Music Conference, pp. 343{345, Tokyo. Computer
Music Association.
Rabiner, L. R. (1989). tutorial hidden Markov models selected applications speech
recognation. Proc. IEEE, 77 (2), 257{286.
Raphael, C. (2001a). mixed graphical model rhythmic parsing. Proc. 17th Conf.
Uncertainty Artif. Int. Morgan Kaufmann.
Raphael, C. (2001b). probabilistic expert system automatic musical accompaniment. Journal
Computational Graphical Statistics, 10 (3), 467{512.
Roberts, G. O., & Rosenthal, J. S. (1998). Markov Chain Monte Carlo: practical implications
theoretical results. Canadian Journal Statistics, 26, 5{31.
Scheirer, E. D. (1998). Tempo beat analysis acoustic musical signals. Journal Acoustical
Society America, 103:1, 588{601.
Shumway, R. H., & Stoffer, D. S. (1982). approach time series smoothing forecasting
using em algorithm. J. Time Series Analysis, 3 (4), 253{264.
Tanizaki, H. (2001). Nonlinear non-Gaussian state-space modeling Monte Carlo techniques:
survey comparative study. Rao, C., & Shanbhag, D. (Eds.), Handbook Statistics,
Vol.21: Stochastic Processes: Modeling Simulation. North-Holland.
Thom, B. (2000). Unsupervised learning interactive jazz/blues improvisation. Proceedings
AAAI2000. AAAI Press.
Toiviainen, P. (1999). interactive midi accompanist. Computer Music Journal, 22:4, 63{75.
Vercoe, B., & Puckette, M. (1985). synthetic rehearsal: Training synthetic performer.
Proceedings ICMC, pp. 275{278, San Francisco. International Computer Music Association.
Vercoe, B. L., Gardner, W. G., & Scheirer, E. D. (1998). Structured audio: Creation, transmission,
rendering parametric sound representations. Proc. IEEE, 86:5, 922{940.

81

fi
